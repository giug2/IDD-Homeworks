<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[1909.09145] Detailed comparison of communication efficiency of split learning and federated learning</title><meta property="og:description" content="We compare communication efficiencies of two compelling distributed machine learning approaches of split learning and federated learning. We show useful settings under which each method outperforms the other in terms o…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Detailed comparison of communication efficiency of split learning and federated learning">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Detailed comparison of communication efficiency of split learning and federated learning">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/1909.09145">

<!--Generated on Sun Mar  3 22:28:34 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Detailed comparison of communication efficiency of split learning and federated learning</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Abhishek Singh, Praneeth Vepakomma, Otkrist Gupta, Ramesh Raskar 
<br class="ltx_break">Massachusetts Institute of Technology
<br class="ltx_break">Cambridge, MA 02139 
<br class="ltx_break"><span id="id1.1.id1" class="ltx_text ltx_font_typewriter">vepakom@mit.edu</span> 
<br class="ltx_break">
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id2.id1" class="ltx_p">We compare communication efficiencies of two compelling distributed machine learning approaches of split learning and federated learning. We show useful settings under which each method outperforms the other in terms of communication efficiency. We consider various practical scenarios of distributed learning setup and juxtapose the two methods under various real-life scenarios. We consider settings of small and large number of clients as well as small models (1M - 6M parameters), large models (10M - 200M parameters) and very large models (1 Billion-100 Billion parameters). We show that increasing number of clients or increasing model size favors split learning setup over the federated while increasing the number of data samples while keeping the number of clients or model size low makes federated learning more communication efficient.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Recent advances in deep learning has enabled ubiquitous applications in society and rapid growth of devices, data has ushered the need for distributed machine learning. Federated learning <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al., <a href="#bib.bib4" title="" class="ltx_ref">2016</a>; Konečnỳ et al., <a href="#bib.bib3" title="" class="ltx_ref">2016</a>)</cite> and Split learning <cite class="ltx_cite ltx_citemacro_citep">(Gupta &amp; Raskar, <a href="#bib.bib1" title="" class="ltx_ref">2018</a>; Vepakomma et al., <a href="#bib.bib5" title="" class="ltx_ref">2018</a>, <a href="#bib.bib6" title="" class="ltx_ref">2019</a>)</cite> are two methods which allow to train a model collectively from various distributed data sources without sharing raw data. However, with such increasing number of devices (data sources) and increasing model complexity it is important to understand the role of these factors on communication efficiency of these distributed learning algorithms.</p>
</div>
<figure id="S1.fig1" class="ltx_figure ltx_align_floatright">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S1.fig1.1.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S1.fig1.2.2" class="ltx_text" style="font-size:90%;">Vanilla split learning setup showing distribution of layers across client and server.</span></figcaption>
</figure>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">In this work, we compare the communication efficiency of federated learning and split learning that allow training of deep neural networks from multiple data sources in a distributed fashion while not sharing the raw data in data sensitive applications.
Let us for example consider a network of data sources such as smart watches, hospitals, word corpus models or biobanks.
Each of these entities have varying amounts of labeled data which we would like to use to train a deep learning pipeline. We ask ourselves on how one can train in a distributed setting without using too much communication bandwidth or computational burden at each of these locations? We now describe split learning, federated learning in sections 1.1 and 1.2 and then compare in detail the communication efficiencies of both these approached in section 2 followed by further analysis of these efficiencies with various dataset sizes, increasing number of clients and model sizes in section 3.</p>
</div>
<section id="S1.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.1 </span>Split learning</h3>

<div id="S1.SS1.p1" class="ltx_para">
<p id="S1.SS1.p1.1" class="ltx_p">The method for training split learning has two main parts, a.) the topology step and b.) the training step. The topology step involves dividing the neural network into two separate parts comprised of some layers in the beginning and remaining layers at the end as shown in Figure <span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:splitfig1</span>
.</p>
</div>
<figure id="S1.F2" class="ltx_figure ltx_align_floatright"><img src="/html/1909.09145/assets/split_full.png" id="S1.F2.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="334" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S1.F2.3.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S1.F2.4.2" class="ltx_text" style="font-size:90%;">Split learning setup with multiple clients and a server with dotted green line showing the split between the client’s share of layers and the server’s share of layers. Activations from only the split layer (last layer of client) are shared during forward propagation and gradients from only first layer of server are shared with client during backpropagation.</span></figcaption>
</figure>
<div id="S1.SS1.p2" class="ltx_para">
<p id="S1.SS1.p2.3" class="ltx_p">Both sides initialize network randomly and proceed to the following training steps.
The training steps involve forward propagation of data through the beginning layers by data source. In the simplest of configurations, the output tensor from these layers and the corresponding label is then transmitted over to the cloud. The cloud continues the forward propagation by processing the output tensor through its remaining layers. The cloud then computes gradients using the transmitted label and propagates the gradient backward. The gradient generated at the first layer of server is then transmitted back to client (data source) and these steps are repeated until convergence. By following these steps we can actually train the deep network without requiring sharing of raw data by client, or any details of the part of the model held by client or server. More advanced configurations of split learning where there is no label sharing or configurations for multi-task learning with vertically partitioned data, or multi-hop ’Tor’ like communication are detailed in <cite class="ltx_cite ltx_citemacro_cite">Vepakomma et al. (<a href="#bib.bib5" title="" class="ltx_ref">2018</a>)</cite>. In the case of multiple clients and one server, there are two approaches of training, one with weight synhcronization between any client <math id="S1.SS1.p2.1.m1.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S1.SS1.p2.1.m1.1a"><mi id="S1.SS1.p2.1.m1.1.1" xref="S1.SS1.p2.1.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S1.SS1.p2.1.m1.1b"><ci id="S1.SS1.p2.1.m1.1.1.cmml" xref="S1.SS1.p2.1.m1.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.SS1.p2.1.m1.1c">i</annotation></semantics></math> and the next client <math id="S1.SS1.p2.2.m2.1" class="ltx_Math" alttext="i+1" display="inline"><semantics id="S1.SS1.p2.2.m2.1a"><mrow id="S1.SS1.p2.2.m2.1.1" xref="S1.SS1.p2.2.m2.1.1.cmml"><mi id="S1.SS1.p2.2.m2.1.1.2" xref="S1.SS1.p2.2.m2.1.1.2.cmml">i</mi><mo id="S1.SS1.p2.2.m2.1.1.1" xref="S1.SS1.p2.2.m2.1.1.1.cmml">+</mo><mn id="S1.SS1.p2.2.m2.1.1.3" xref="S1.SS1.p2.2.m2.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S1.SS1.p2.2.m2.1b"><apply id="S1.SS1.p2.2.m2.1.1.cmml" xref="S1.SS1.p2.2.m2.1.1"><plus id="S1.SS1.p2.2.m2.1.1.1.cmml" xref="S1.SS1.p2.2.m2.1.1.1"></plus><ci id="S1.SS1.p2.2.m2.1.1.2.cmml" xref="S1.SS1.p2.2.m2.1.1.2">𝑖</ci><cn type="integer" id="S1.SS1.p2.2.m2.1.1.3.cmml" xref="S1.SS1.p2.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.SS1.p2.2.m2.1c">i+1</annotation></semantics></math> after client <math id="S1.SS1.p2.3.m3.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S1.SS1.p2.3.m3.1a"><mi id="S1.SS1.p2.3.m3.1.1" xref="S1.SS1.p2.3.m3.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S1.SS1.p2.3.m3.1b"><ci id="S1.SS1.p2.3.m3.1.1.cmml" xref="S1.SS1.p2.3.m3.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.SS1.p2.3.m3.1c">i</annotation></semantics></math> completes an epoch or across batches, and the other approach is without any client weight synchronization where clients take turns with alternating epochs in working with the server.</p>
</div>
</section>
<section id="S1.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.2 </span>Federated learning</h3>

<div id="S1.SS2.p1" class="ltx_para">
<p id="S1.SS2.p1.1" class="ltx_p">In this other approach for distributed learning, every client runs a copy of the entire model on its own data. The server receives the weight updates from every client and averages them to get the updated weights from the server.</p>
</div>
<figure id="S1.F3" class="ltx_figure ltx_align_floatright"><img src="/html/1909.09145/assets/Pic0.png" id="S1.F3.1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="150" height="180" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S1.F3.3.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S1.F3.4.2" class="ltx_text" style="font-size:90%;">Hyperbola dividing the regions where one technique perfors better over the other and both the feasible regions are shown in this theoretical schematic cartoon. Real instances of this equation are shown in the Analysis section.</span></figcaption>
</figure>
<div id="S1.SS2.p2" class="ltx_para">
<p id="S1.SS2.p2.1" class="ltx_p">The updated weights are then downloaded by the clients and the process continues until convergence.</p>
</div>
</section>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Communication efficiency</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.12" class="ltx_p">In this section we describe our calculations of the communication efficiency for both of the distributed learning setups of split learning and federated learning. For analyzing the communication efficiency, we consider the amount of data transferred by every client for the training and client weight synchronization since rest of the factors affecting the communication rate is dependent on the setup of training cluster and is independent of the distributed learning setup. We use the following notation to mathematically measure the communication efficiencies, <span id="S2.p1.12.1" class="ltx_text ltx_font_bold">Notation:</span> <math id="S2.p1.1.m1.1" class="ltx_Math" alttext="K=" display="inline"><semantics id="S2.p1.1.m1.1a"><mrow id="S2.p1.1.m1.1.1" xref="S2.p1.1.m1.1.1.cmml"><mi id="S2.p1.1.m1.1.1.2" xref="S2.p1.1.m1.1.1.2.cmml">K</mi><mo id="S2.p1.1.m1.1.1.1" xref="S2.p1.1.m1.1.1.1.cmml">=</mo><mi id="S2.p1.1.m1.1.1.3" xref="S2.p1.1.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.1.m1.1b"><apply id="S2.p1.1.m1.1.1.cmml" xref="S2.p1.1.m1.1.1"><eq id="S2.p1.1.m1.1.1.1.cmml" xref="S2.p1.1.m1.1.1.1"></eq><ci id="S2.p1.1.m1.1.1.2.cmml" xref="S2.p1.1.m1.1.1.2">𝐾</ci><csymbol cd="latexml" id="S2.p1.1.m1.1.1.3.cmml" xref="S2.p1.1.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.1.m1.1c">K=</annotation></semantics></math> # clients, <math id="S2.p1.2.m2.1" class="ltx_Math" alttext="N=" display="inline"><semantics id="S2.p1.2.m2.1a"><mrow id="S2.p1.2.m2.1.1" xref="S2.p1.2.m2.1.1.cmml"><mi id="S2.p1.2.m2.1.1.2" xref="S2.p1.2.m2.1.1.2.cmml">N</mi><mo id="S2.p1.2.m2.1.1.1" xref="S2.p1.2.m2.1.1.1.cmml">=</mo><mi id="S2.p1.2.m2.1.1.3" xref="S2.p1.2.m2.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.2.m2.1b"><apply id="S2.p1.2.m2.1.1.cmml" xref="S2.p1.2.m2.1.1"><eq id="S2.p1.2.m2.1.1.1.cmml" xref="S2.p1.2.m2.1.1.1"></eq><ci id="S2.p1.2.m2.1.1.2.cmml" xref="S2.p1.2.m2.1.1.2">𝑁</ci><csymbol cd="latexml" id="S2.p1.2.m2.1.1.3.cmml" xref="S2.p1.2.m2.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.2.m2.1c">N=</annotation></semantics></math> # model parameters, <math id="S2.p1.3.m3.1" class="ltx_Math" alttext="p=" display="inline"><semantics id="S2.p1.3.m3.1a"><mrow id="S2.p1.3.m3.1.1" xref="S2.p1.3.m3.1.1.cmml"><mi id="S2.p1.3.m3.1.1.2" xref="S2.p1.3.m3.1.1.2.cmml">p</mi><mo id="S2.p1.3.m3.1.1.1" xref="S2.p1.3.m3.1.1.1.cmml">=</mo><mi id="S2.p1.3.m3.1.1.3" xref="S2.p1.3.m3.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.3.m3.1b"><apply id="S2.p1.3.m3.1.1.cmml" xref="S2.p1.3.m3.1.1"><eq id="S2.p1.3.m3.1.1.1.cmml" xref="S2.p1.3.m3.1.1.1"></eq><ci id="S2.p1.3.m3.1.1.2.cmml" xref="S2.p1.3.m3.1.1.2">𝑝</ci><csymbol cd="latexml" id="S2.p1.3.m3.1.1.3.cmml" xref="S2.p1.3.m3.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.3.m3.1c">p=</annotation></semantics></math> total dataset size, <math id="S2.p1.4.m4.1" class="ltx_Math" alttext="q=" display="inline"><semantics id="S2.p1.4.m4.1a"><mrow id="S2.p1.4.m4.1.1" xref="S2.p1.4.m4.1.1.cmml"><mi id="S2.p1.4.m4.1.1.2" xref="S2.p1.4.m4.1.1.2.cmml">q</mi><mo id="S2.p1.4.m4.1.1.1" xref="S2.p1.4.m4.1.1.1.cmml">=</mo><mi id="S2.p1.4.m4.1.1.3" xref="S2.p1.4.m4.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.4.m4.1b"><apply id="S2.p1.4.m4.1.1.cmml" xref="S2.p1.4.m4.1.1"><eq id="S2.p1.4.m4.1.1.1.cmml" xref="S2.p1.4.m4.1.1.1"></eq><ci id="S2.p1.4.m4.1.1.2.cmml" xref="S2.p1.4.m4.1.1.2">𝑞</ci><csymbol cd="latexml" id="S2.p1.4.m4.1.1.3.cmml" xref="S2.p1.4.m4.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.4.m4.1c">q=</annotation></semantics></math> size of the smashed layer, <math id="S2.p1.5.m5.1" class="ltx_Math" alttext="\eta" display="inline"><semantics id="S2.p1.5.m5.1a"><mi id="S2.p1.5.m5.1.1" xref="S2.p1.5.m5.1.1.cmml">η</mi><annotation-xml encoding="MathML-Content" id="S2.p1.5.m5.1b"><ci id="S2.p1.5.m5.1.1.cmml" xref="S2.p1.5.m5.1.1">𝜂</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.5.m5.1c">\eta</annotation></semantics></math> = fraction of model parameters (weights) with client and therefore <math id="S2.p1.6.m6.1" class="ltx_Math" alttext="1-\eta" display="inline"><semantics id="S2.p1.6.m6.1a"><mrow id="S2.p1.6.m6.1.1" xref="S2.p1.6.m6.1.1.cmml"><mn id="S2.p1.6.m6.1.1.2" xref="S2.p1.6.m6.1.1.2.cmml">1</mn><mo id="S2.p1.6.m6.1.1.1" xref="S2.p1.6.m6.1.1.1.cmml">−</mo><mi id="S2.p1.6.m6.1.1.3" xref="S2.p1.6.m6.1.1.3.cmml">η</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.6.m6.1b"><apply id="S2.p1.6.m6.1.1.cmml" xref="S2.p1.6.m6.1.1"><minus id="S2.p1.6.m6.1.1.1.cmml" xref="S2.p1.6.m6.1.1.1"></minus><cn type="integer" id="S2.p1.6.m6.1.1.2.cmml" xref="S2.p1.6.m6.1.1.2">1</cn><ci id="S2.p1.6.m6.1.1.3.cmml" xref="S2.p1.6.m6.1.1.3">𝜂</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.6.m6.1c">1-\eta</annotation></semantics></math> is fraction of parameters with server. In Table 1 we show the communication required per client per one epoch as well as total communication required across all clients per one epoch. As there are <math id="S2.p1.7.m7.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S2.p1.7.m7.1a"><mi id="S2.p1.7.m7.1.1" xref="S2.p1.7.m7.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S2.p1.7.m7.1b"><ci id="S2.p1.7.m7.1.1.cmml" xref="S2.p1.7.m7.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.7.m7.1c">K</annotation></semantics></math> clients, when size of the training dataset across each client is the same, there would be <math id="S2.p1.8.m8.1" class="ltx_Math" alttext="p/K" display="inline"><semantics id="S2.p1.8.m8.1a"><mrow id="S2.p1.8.m8.1.1" xref="S2.p1.8.m8.1.1.cmml"><mi id="S2.p1.8.m8.1.1.2" xref="S2.p1.8.m8.1.1.2.cmml">p</mi><mo id="S2.p1.8.m8.1.1.1" xref="S2.p1.8.m8.1.1.1.cmml">/</mo><mi id="S2.p1.8.m8.1.1.3" xref="S2.p1.8.m8.1.1.3.cmml">K</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.8.m8.1b"><apply id="S2.p1.8.m8.1.1.cmml" xref="S2.p1.8.m8.1.1"><divide id="S2.p1.8.m8.1.1.1.cmml" xref="S2.p1.8.m8.1.1.1"></divide><ci id="S2.p1.8.m8.1.1.2.cmml" xref="S2.p1.8.m8.1.1.2">𝑝</ci><ci id="S2.p1.8.m8.1.1.3.cmml" xref="S2.p1.8.m8.1.1.3">𝐾</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.8.m8.1c">p/K</annotation></semantics></math> data records per client in split learning. Therefore during forward propagation the size of the activations that are communicated per client in split learning is <math id="S2.p1.9.m9.1" class="ltx_Math" alttext="(p/K)q" display="inline"><semantics id="S2.p1.9.m9.1a"><mrow id="S2.p1.9.m9.1.1" xref="S2.p1.9.m9.1.1.cmml"><mrow id="S2.p1.9.m9.1.1.1.1" xref="S2.p1.9.m9.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.p1.9.m9.1.1.1.1.2" xref="S2.p1.9.m9.1.1.1.1.1.cmml">(</mo><mrow id="S2.p1.9.m9.1.1.1.1.1" xref="S2.p1.9.m9.1.1.1.1.1.cmml"><mi id="S2.p1.9.m9.1.1.1.1.1.2" xref="S2.p1.9.m9.1.1.1.1.1.2.cmml">p</mi><mo id="S2.p1.9.m9.1.1.1.1.1.1" xref="S2.p1.9.m9.1.1.1.1.1.1.cmml">/</mo><mi id="S2.p1.9.m9.1.1.1.1.1.3" xref="S2.p1.9.m9.1.1.1.1.1.3.cmml">K</mi></mrow><mo stretchy="false" id="S2.p1.9.m9.1.1.1.1.3" xref="S2.p1.9.m9.1.1.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S2.p1.9.m9.1.1.2" xref="S2.p1.9.m9.1.1.2.cmml">​</mo><mi id="S2.p1.9.m9.1.1.3" xref="S2.p1.9.m9.1.1.3.cmml">q</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.9.m9.1b"><apply id="S2.p1.9.m9.1.1.cmml" xref="S2.p1.9.m9.1.1"><times id="S2.p1.9.m9.1.1.2.cmml" xref="S2.p1.9.m9.1.1.2"></times><apply id="S2.p1.9.m9.1.1.1.1.1.cmml" xref="S2.p1.9.m9.1.1.1.1"><divide id="S2.p1.9.m9.1.1.1.1.1.1.cmml" xref="S2.p1.9.m9.1.1.1.1.1.1"></divide><ci id="S2.p1.9.m9.1.1.1.1.1.2.cmml" xref="S2.p1.9.m9.1.1.1.1.1.2">𝑝</ci><ci id="S2.p1.9.m9.1.1.1.1.1.3.cmml" xref="S2.p1.9.m9.1.1.1.1.1.3">𝐾</ci></apply><ci id="S2.p1.9.m9.1.1.3.cmml" xref="S2.p1.9.m9.1.1.3">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.9.m9.1c">(p/K)q</annotation></semantics></math> and during backward propagation the size of gradients communicated per client is also <math id="S2.p1.10.m10.1" class="ltx_Math" alttext="(p/K)q" display="inline"><semantics id="S2.p1.10.m10.1a"><mrow id="S2.p1.10.m10.1.1" xref="S2.p1.10.m10.1.1.cmml"><mrow id="S2.p1.10.m10.1.1.1.1" xref="S2.p1.10.m10.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.p1.10.m10.1.1.1.1.2" xref="S2.p1.10.m10.1.1.1.1.1.cmml">(</mo><mrow id="S2.p1.10.m10.1.1.1.1.1" xref="S2.p1.10.m10.1.1.1.1.1.cmml"><mi id="S2.p1.10.m10.1.1.1.1.1.2" xref="S2.p1.10.m10.1.1.1.1.1.2.cmml">p</mi><mo id="S2.p1.10.m10.1.1.1.1.1.1" xref="S2.p1.10.m10.1.1.1.1.1.1.cmml">/</mo><mi id="S2.p1.10.m10.1.1.1.1.1.3" xref="S2.p1.10.m10.1.1.1.1.1.3.cmml">K</mi></mrow><mo stretchy="false" id="S2.p1.10.m10.1.1.1.1.3" xref="S2.p1.10.m10.1.1.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S2.p1.10.m10.1.1.2" xref="S2.p1.10.m10.1.1.2.cmml">​</mo><mi id="S2.p1.10.m10.1.1.3" xref="S2.p1.10.m10.1.1.3.cmml">q</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.10.m10.1b"><apply id="S2.p1.10.m10.1.1.cmml" xref="S2.p1.10.m10.1.1"><times id="S2.p1.10.m10.1.1.2.cmml" xref="S2.p1.10.m10.1.1.2"></times><apply id="S2.p1.10.m10.1.1.1.1.1.cmml" xref="S2.p1.10.m10.1.1.1.1"><divide id="S2.p1.10.m10.1.1.1.1.1.1.cmml" xref="S2.p1.10.m10.1.1.1.1.1.1"></divide><ci id="S2.p1.10.m10.1.1.1.1.1.2.cmml" xref="S2.p1.10.m10.1.1.1.1.1.2">𝑝</ci><ci id="S2.p1.10.m10.1.1.1.1.1.3.cmml" xref="S2.p1.10.m10.1.1.1.1.1.3">𝐾</ci></apply><ci id="S2.p1.10.m10.1.1.3.cmml" xref="S2.p1.10.m10.1.1.3">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.10.m10.1c">(p/K)q</annotation></semantics></math>. In the case where there is client weight sharing, passing on the weights to next client would involve a communication of <math id="S2.p1.11.m11.1" class="ltx_Math" alttext="\eta N" display="inline"><semantics id="S2.p1.11.m11.1a"><mrow id="S2.p1.11.m11.1.1" xref="S2.p1.11.m11.1.1.cmml"><mi id="S2.p1.11.m11.1.1.2" xref="S2.p1.11.m11.1.1.2.cmml">η</mi><mo lspace="0em" rspace="0em" id="S2.p1.11.m11.1.1.1" xref="S2.p1.11.m11.1.1.1.cmml">​</mo><mi id="S2.p1.11.m11.1.1.3" xref="S2.p1.11.m11.1.1.3.cmml">N</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.11.m11.1b"><apply id="S2.p1.11.m11.1.1.cmml" xref="S2.p1.11.m11.1.1"><times id="S2.p1.11.m11.1.1.1.cmml" xref="S2.p1.11.m11.1.1.1"></times><ci id="S2.p1.11.m11.1.1.2.cmml" xref="S2.p1.11.m11.1.1.2">𝜂</ci><ci id="S2.p1.11.m11.1.1.3.cmml" xref="S2.p1.11.m11.1.1.3">𝑁</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.11.m11.1c">\eta N</annotation></semantics></math>.
In federated learning the communication of weights/gradients during upload of individual client weights and download of averaged weights are both of size <math id="S2.p1.12.m12.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S2.p1.12.m12.1a"><mi id="S2.p1.12.m12.1.1" xref="S2.p1.12.m12.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S2.p1.12.m12.1b"><ci id="S2.p1.12.m12.1.1.cmml" xref="S2.p1.12.m12.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.12.m12.1c">N</annotation></semantics></math> each.</p>
</div>
<figure id="S2.T1" class="ltx_table">
<table id="S2.T1.6" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S2.T1.6.7.1" class="ltx_tr">
<th id="S2.T1.6.7.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Method</th>
<th id="S2.T1.6.7.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">Communication per client</th>
<th id="S2.T1.6.7.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">Total communication</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S2.T1.2.2" class="ltx_tr">
<th id="S2.T1.2.2.3" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Split learning with client weight sharing</th>
<td id="S2.T1.1.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><math id="S2.T1.1.1.1.m1.2" class="ltx_Math" alttext="(p/K)q+(p/K)q+\eta N" display="inline"><semantics id="S2.T1.1.1.1.m1.2a"><mrow id="S2.T1.1.1.1.m1.2.2" xref="S2.T1.1.1.1.m1.2.2.cmml"><mrow id="S2.T1.1.1.1.m1.1.1.1" xref="S2.T1.1.1.1.m1.1.1.1.cmml"><mrow id="S2.T1.1.1.1.m1.1.1.1.1.1" xref="S2.T1.1.1.1.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.T1.1.1.1.m1.1.1.1.1.1.2" xref="S2.T1.1.1.1.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.T1.1.1.1.m1.1.1.1.1.1.1" xref="S2.T1.1.1.1.m1.1.1.1.1.1.1.cmml"><mi id="S2.T1.1.1.1.m1.1.1.1.1.1.1.2" xref="S2.T1.1.1.1.m1.1.1.1.1.1.1.2.cmml">p</mi><mo id="S2.T1.1.1.1.m1.1.1.1.1.1.1.1" xref="S2.T1.1.1.1.m1.1.1.1.1.1.1.1.cmml">/</mo><mi id="S2.T1.1.1.1.m1.1.1.1.1.1.1.3" xref="S2.T1.1.1.1.m1.1.1.1.1.1.1.3.cmml">K</mi></mrow><mo stretchy="false" id="S2.T1.1.1.1.m1.1.1.1.1.1.3" xref="S2.T1.1.1.1.m1.1.1.1.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S2.T1.1.1.1.m1.1.1.1.2" xref="S2.T1.1.1.1.m1.1.1.1.2.cmml">​</mo><mi id="S2.T1.1.1.1.m1.1.1.1.3" xref="S2.T1.1.1.1.m1.1.1.1.3.cmml">q</mi></mrow><mo id="S2.T1.1.1.1.m1.2.2.3" xref="S2.T1.1.1.1.m1.2.2.3.cmml">+</mo><mrow id="S2.T1.1.1.1.m1.2.2.2" xref="S2.T1.1.1.1.m1.2.2.2.cmml"><mrow id="S2.T1.1.1.1.m1.2.2.2.1.1" xref="S2.T1.1.1.1.m1.2.2.2.1.1.1.cmml"><mo stretchy="false" id="S2.T1.1.1.1.m1.2.2.2.1.1.2" xref="S2.T1.1.1.1.m1.2.2.2.1.1.1.cmml">(</mo><mrow id="S2.T1.1.1.1.m1.2.2.2.1.1.1" xref="S2.T1.1.1.1.m1.2.2.2.1.1.1.cmml"><mi id="S2.T1.1.1.1.m1.2.2.2.1.1.1.2" xref="S2.T1.1.1.1.m1.2.2.2.1.1.1.2.cmml">p</mi><mo id="S2.T1.1.1.1.m1.2.2.2.1.1.1.1" xref="S2.T1.1.1.1.m1.2.2.2.1.1.1.1.cmml">/</mo><mi id="S2.T1.1.1.1.m1.2.2.2.1.1.1.3" xref="S2.T1.1.1.1.m1.2.2.2.1.1.1.3.cmml">K</mi></mrow><mo stretchy="false" id="S2.T1.1.1.1.m1.2.2.2.1.1.3" xref="S2.T1.1.1.1.m1.2.2.2.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S2.T1.1.1.1.m1.2.2.2.2" xref="S2.T1.1.1.1.m1.2.2.2.2.cmml">​</mo><mi id="S2.T1.1.1.1.m1.2.2.2.3" xref="S2.T1.1.1.1.m1.2.2.2.3.cmml">q</mi></mrow><mo id="S2.T1.1.1.1.m1.2.2.3a" xref="S2.T1.1.1.1.m1.2.2.3.cmml">+</mo><mrow id="S2.T1.1.1.1.m1.2.2.4" xref="S2.T1.1.1.1.m1.2.2.4.cmml"><mi id="S2.T1.1.1.1.m1.2.2.4.2" xref="S2.T1.1.1.1.m1.2.2.4.2.cmml">η</mi><mo lspace="0em" rspace="0em" id="S2.T1.1.1.1.m1.2.2.4.1" xref="S2.T1.1.1.1.m1.2.2.4.1.cmml">​</mo><mi id="S2.T1.1.1.1.m1.2.2.4.3" xref="S2.T1.1.1.1.m1.2.2.4.3.cmml">N</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.T1.1.1.1.m1.2b"><apply id="S2.T1.1.1.1.m1.2.2.cmml" xref="S2.T1.1.1.1.m1.2.2"><plus id="S2.T1.1.1.1.m1.2.2.3.cmml" xref="S2.T1.1.1.1.m1.2.2.3"></plus><apply id="S2.T1.1.1.1.m1.1.1.1.cmml" xref="S2.T1.1.1.1.m1.1.1.1"><times id="S2.T1.1.1.1.m1.1.1.1.2.cmml" xref="S2.T1.1.1.1.m1.1.1.1.2"></times><apply id="S2.T1.1.1.1.m1.1.1.1.1.1.1.cmml" xref="S2.T1.1.1.1.m1.1.1.1.1.1"><divide id="S2.T1.1.1.1.m1.1.1.1.1.1.1.1.cmml" xref="S2.T1.1.1.1.m1.1.1.1.1.1.1.1"></divide><ci id="S2.T1.1.1.1.m1.1.1.1.1.1.1.2.cmml" xref="S2.T1.1.1.1.m1.1.1.1.1.1.1.2">𝑝</ci><ci id="S2.T1.1.1.1.m1.1.1.1.1.1.1.3.cmml" xref="S2.T1.1.1.1.m1.1.1.1.1.1.1.3">𝐾</ci></apply><ci id="S2.T1.1.1.1.m1.1.1.1.3.cmml" xref="S2.T1.1.1.1.m1.1.1.1.3">𝑞</ci></apply><apply id="S2.T1.1.1.1.m1.2.2.2.cmml" xref="S2.T1.1.1.1.m1.2.2.2"><times id="S2.T1.1.1.1.m1.2.2.2.2.cmml" xref="S2.T1.1.1.1.m1.2.2.2.2"></times><apply id="S2.T1.1.1.1.m1.2.2.2.1.1.1.cmml" xref="S2.T1.1.1.1.m1.2.2.2.1.1"><divide id="S2.T1.1.1.1.m1.2.2.2.1.1.1.1.cmml" xref="S2.T1.1.1.1.m1.2.2.2.1.1.1.1"></divide><ci id="S2.T1.1.1.1.m1.2.2.2.1.1.1.2.cmml" xref="S2.T1.1.1.1.m1.2.2.2.1.1.1.2">𝑝</ci><ci id="S2.T1.1.1.1.m1.2.2.2.1.1.1.3.cmml" xref="S2.T1.1.1.1.m1.2.2.2.1.1.1.3">𝐾</ci></apply><ci id="S2.T1.1.1.1.m1.2.2.2.3.cmml" xref="S2.T1.1.1.1.m1.2.2.2.3">𝑞</ci></apply><apply id="S2.T1.1.1.1.m1.2.2.4.cmml" xref="S2.T1.1.1.1.m1.2.2.4"><times id="S2.T1.1.1.1.m1.2.2.4.1.cmml" xref="S2.T1.1.1.1.m1.2.2.4.1"></times><ci id="S2.T1.1.1.1.m1.2.2.4.2.cmml" xref="S2.T1.1.1.1.m1.2.2.4.2">𝜂</ci><ci id="S2.T1.1.1.1.m1.2.2.4.3.cmml" xref="S2.T1.1.1.1.m1.2.2.4.3">𝑁</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.1.1.1.m1.2c">(p/K)q+(p/K)q+\eta N</annotation></semantics></math></td>
<td id="S2.T1.2.2.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><math id="S2.T1.2.2.2.m1.1" class="ltx_Math" alttext="2pq+\eta NK" display="inline"><semantics id="S2.T1.2.2.2.m1.1a"><mrow id="S2.T1.2.2.2.m1.1.1" xref="S2.T1.2.2.2.m1.1.1.cmml"><mrow id="S2.T1.2.2.2.m1.1.1.2" xref="S2.T1.2.2.2.m1.1.1.2.cmml"><mn id="S2.T1.2.2.2.m1.1.1.2.2" xref="S2.T1.2.2.2.m1.1.1.2.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S2.T1.2.2.2.m1.1.1.2.1" xref="S2.T1.2.2.2.m1.1.1.2.1.cmml">​</mo><mi id="S2.T1.2.2.2.m1.1.1.2.3" xref="S2.T1.2.2.2.m1.1.1.2.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.T1.2.2.2.m1.1.1.2.1a" xref="S2.T1.2.2.2.m1.1.1.2.1.cmml">​</mo><mi id="S2.T1.2.2.2.m1.1.1.2.4" xref="S2.T1.2.2.2.m1.1.1.2.4.cmml">q</mi></mrow><mo id="S2.T1.2.2.2.m1.1.1.1" xref="S2.T1.2.2.2.m1.1.1.1.cmml">+</mo><mrow id="S2.T1.2.2.2.m1.1.1.3" xref="S2.T1.2.2.2.m1.1.1.3.cmml"><mi id="S2.T1.2.2.2.m1.1.1.3.2" xref="S2.T1.2.2.2.m1.1.1.3.2.cmml">η</mi><mo lspace="0em" rspace="0em" id="S2.T1.2.2.2.m1.1.1.3.1" xref="S2.T1.2.2.2.m1.1.1.3.1.cmml">​</mo><mi id="S2.T1.2.2.2.m1.1.1.3.3" xref="S2.T1.2.2.2.m1.1.1.3.3.cmml">N</mi><mo lspace="0em" rspace="0em" id="S2.T1.2.2.2.m1.1.1.3.1a" xref="S2.T1.2.2.2.m1.1.1.3.1.cmml">​</mo><mi id="S2.T1.2.2.2.m1.1.1.3.4" xref="S2.T1.2.2.2.m1.1.1.3.4.cmml">K</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.T1.2.2.2.m1.1b"><apply id="S2.T1.2.2.2.m1.1.1.cmml" xref="S2.T1.2.2.2.m1.1.1"><plus id="S2.T1.2.2.2.m1.1.1.1.cmml" xref="S2.T1.2.2.2.m1.1.1.1"></plus><apply id="S2.T1.2.2.2.m1.1.1.2.cmml" xref="S2.T1.2.2.2.m1.1.1.2"><times id="S2.T1.2.2.2.m1.1.1.2.1.cmml" xref="S2.T1.2.2.2.m1.1.1.2.1"></times><cn type="integer" id="S2.T1.2.2.2.m1.1.1.2.2.cmml" xref="S2.T1.2.2.2.m1.1.1.2.2">2</cn><ci id="S2.T1.2.2.2.m1.1.1.2.3.cmml" xref="S2.T1.2.2.2.m1.1.1.2.3">𝑝</ci><ci id="S2.T1.2.2.2.m1.1.1.2.4.cmml" xref="S2.T1.2.2.2.m1.1.1.2.4">𝑞</ci></apply><apply id="S2.T1.2.2.2.m1.1.1.3.cmml" xref="S2.T1.2.2.2.m1.1.1.3"><times id="S2.T1.2.2.2.m1.1.1.3.1.cmml" xref="S2.T1.2.2.2.m1.1.1.3.1"></times><ci id="S2.T1.2.2.2.m1.1.1.3.2.cmml" xref="S2.T1.2.2.2.m1.1.1.3.2">𝜂</ci><ci id="S2.T1.2.2.2.m1.1.1.3.3.cmml" xref="S2.T1.2.2.2.m1.1.1.3.3">𝑁</ci><ci id="S2.T1.2.2.2.m1.1.1.3.4.cmml" xref="S2.T1.2.2.2.m1.1.1.3.4">𝐾</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.2.2.2.m1.1c">2pq+\eta NK</annotation></semantics></math></td>
</tr>
<tr id="S2.T1.4.4" class="ltx_tr">
<th id="S2.T1.4.4.3" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Split learning with no client weight sharing</th>
<td id="S2.T1.3.3.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><math id="S2.T1.3.3.1.m1.2" class="ltx_Math" alttext="(p/K)q+(p/K)q" display="inline"><semantics id="S2.T1.3.3.1.m1.2a"><mrow id="S2.T1.3.3.1.m1.2.2" xref="S2.T1.3.3.1.m1.2.2.cmml"><mrow id="S2.T1.3.3.1.m1.1.1.1" xref="S2.T1.3.3.1.m1.1.1.1.cmml"><mrow id="S2.T1.3.3.1.m1.1.1.1.1.1" xref="S2.T1.3.3.1.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.T1.3.3.1.m1.1.1.1.1.1.2" xref="S2.T1.3.3.1.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.T1.3.3.1.m1.1.1.1.1.1.1" xref="S2.T1.3.3.1.m1.1.1.1.1.1.1.cmml"><mi id="S2.T1.3.3.1.m1.1.1.1.1.1.1.2" xref="S2.T1.3.3.1.m1.1.1.1.1.1.1.2.cmml">p</mi><mo id="S2.T1.3.3.1.m1.1.1.1.1.1.1.1" xref="S2.T1.3.3.1.m1.1.1.1.1.1.1.1.cmml">/</mo><mi id="S2.T1.3.3.1.m1.1.1.1.1.1.1.3" xref="S2.T1.3.3.1.m1.1.1.1.1.1.1.3.cmml">K</mi></mrow><mo stretchy="false" id="S2.T1.3.3.1.m1.1.1.1.1.1.3" xref="S2.T1.3.3.1.m1.1.1.1.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S2.T1.3.3.1.m1.1.1.1.2" xref="S2.T1.3.3.1.m1.1.1.1.2.cmml">​</mo><mi id="S2.T1.3.3.1.m1.1.1.1.3" xref="S2.T1.3.3.1.m1.1.1.1.3.cmml">q</mi></mrow><mo id="S2.T1.3.3.1.m1.2.2.3" xref="S2.T1.3.3.1.m1.2.2.3.cmml">+</mo><mrow id="S2.T1.3.3.1.m1.2.2.2" xref="S2.T1.3.3.1.m1.2.2.2.cmml"><mrow id="S2.T1.3.3.1.m1.2.2.2.1.1" xref="S2.T1.3.3.1.m1.2.2.2.1.1.1.cmml"><mo stretchy="false" id="S2.T1.3.3.1.m1.2.2.2.1.1.2" xref="S2.T1.3.3.1.m1.2.2.2.1.1.1.cmml">(</mo><mrow id="S2.T1.3.3.1.m1.2.2.2.1.1.1" xref="S2.T1.3.3.1.m1.2.2.2.1.1.1.cmml"><mi id="S2.T1.3.3.1.m1.2.2.2.1.1.1.2" xref="S2.T1.3.3.1.m1.2.2.2.1.1.1.2.cmml">p</mi><mo id="S2.T1.3.3.1.m1.2.2.2.1.1.1.1" xref="S2.T1.3.3.1.m1.2.2.2.1.1.1.1.cmml">/</mo><mi id="S2.T1.3.3.1.m1.2.2.2.1.1.1.3" xref="S2.T1.3.3.1.m1.2.2.2.1.1.1.3.cmml">K</mi></mrow><mo stretchy="false" id="S2.T1.3.3.1.m1.2.2.2.1.1.3" xref="S2.T1.3.3.1.m1.2.2.2.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S2.T1.3.3.1.m1.2.2.2.2" xref="S2.T1.3.3.1.m1.2.2.2.2.cmml">​</mo><mi id="S2.T1.3.3.1.m1.2.2.2.3" xref="S2.T1.3.3.1.m1.2.2.2.3.cmml">q</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.T1.3.3.1.m1.2b"><apply id="S2.T1.3.3.1.m1.2.2.cmml" xref="S2.T1.3.3.1.m1.2.2"><plus id="S2.T1.3.3.1.m1.2.2.3.cmml" xref="S2.T1.3.3.1.m1.2.2.3"></plus><apply id="S2.T1.3.3.1.m1.1.1.1.cmml" xref="S2.T1.3.3.1.m1.1.1.1"><times id="S2.T1.3.3.1.m1.1.1.1.2.cmml" xref="S2.T1.3.3.1.m1.1.1.1.2"></times><apply id="S2.T1.3.3.1.m1.1.1.1.1.1.1.cmml" xref="S2.T1.3.3.1.m1.1.1.1.1.1"><divide id="S2.T1.3.3.1.m1.1.1.1.1.1.1.1.cmml" xref="S2.T1.3.3.1.m1.1.1.1.1.1.1.1"></divide><ci id="S2.T1.3.3.1.m1.1.1.1.1.1.1.2.cmml" xref="S2.T1.3.3.1.m1.1.1.1.1.1.1.2">𝑝</ci><ci id="S2.T1.3.3.1.m1.1.1.1.1.1.1.3.cmml" xref="S2.T1.3.3.1.m1.1.1.1.1.1.1.3">𝐾</ci></apply><ci id="S2.T1.3.3.1.m1.1.1.1.3.cmml" xref="S2.T1.3.3.1.m1.1.1.1.3">𝑞</ci></apply><apply id="S2.T1.3.3.1.m1.2.2.2.cmml" xref="S2.T1.3.3.1.m1.2.2.2"><times id="S2.T1.3.3.1.m1.2.2.2.2.cmml" xref="S2.T1.3.3.1.m1.2.2.2.2"></times><apply id="S2.T1.3.3.1.m1.2.2.2.1.1.1.cmml" xref="S2.T1.3.3.1.m1.2.2.2.1.1"><divide id="S2.T1.3.3.1.m1.2.2.2.1.1.1.1.cmml" xref="S2.T1.3.3.1.m1.2.2.2.1.1.1.1"></divide><ci id="S2.T1.3.3.1.m1.2.2.2.1.1.1.2.cmml" xref="S2.T1.3.3.1.m1.2.2.2.1.1.1.2">𝑝</ci><ci id="S2.T1.3.3.1.m1.2.2.2.1.1.1.3.cmml" xref="S2.T1.3.3.1.m1.2.2.2.1.1.1.3">𝐾</ci></apply><ci id="S2.T1.3.3.1.m1.2.2.2.3.cmml" xref="S2.T1.3.3.1.m1.2.2.2.3">𝑞</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.3.3.1.m1.2c">(p/K)q+(p/K)q</annotation></semantics></math></td>
<td id="S2.T1.4.4.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><math id="S2.T1.4.4.2.m1.1" class="ltx_Math" alttext="2pq" display="inline"><semantics id="S2.T1.4.4.2.m1.1a"><mrow id="S2.T1.4.4.2.m1.1.1" xref="S2.T1.4.4.2.m1.1.1.cmml"><mn id="S2.T1.4.4.2.m1.1.1.2" xref="S2.T1.4.4.2.m1.1.1.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S2.T1.4.4.2.m1.1.1.1" xref="S2.T1.4.4.2.m1.1.1.1.cmml">​</mo><mi id="S2.T1.4.4.2.m1.1.1.3" xref="S2.T1.4.4.2.m1.1.1.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.T1.4.4.2.m1.1.1.1a" xref="S2.T1.4.4.2.m1.1.1.1.cmml">​</mo><mi id="S2.T1.4.4.2.m1.1.1.4" xref="S2.T1.4.4.2.m1.1.1.4.cmml">q</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.T1.4.4.2.m1.1b"><apply id="S2.T1.4.4.2.m1.1.1.cmml" xref="S2.T1.4.4.2.m1.1.1"><times id="S2.T1.4.4.2.m1.1.1.1.cmml" xref="S2.T1.4.4.2.m1.1.1.1"></times><cn type="integer" id="S2.T1.4.4.2.m1.1.1.2.cmml" xref="S2.T1.4.4.2.m1.1.1.2">2</cn><ci id="S2.T1.4.4.2.m1.1.1.3.cmml" xref="S2.T1.4.4.2.m1.1.1.3">𝑝</ci><ci id="S2.T1.4.4.2.m1.1.1.4.cmml" xref="S2.T1.4.4.2.m1.1.1.4">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.4.4.2.m1.1c">2pq</annotation></semantics></math></td>
</tr>
<tr id="S2.T1.6.6" class="ltx_tr">
<th id="S2.T1.6.6.3" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t">Federated learning</th>
<td id="S2.T1.5.5.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t"><math id="S2.T1.5.5.1.m1.1" class="ltx_Math" alttext="2N" display="inline"><semantics id="S2.T1.5.5.1.m1.1a"><mrow id="S2.T1.5.5.1.m1.1.1" xref="S2.T1.5.5.1.m1.1.1.cmml"><mn id="S2.T1.5.5.1.m1.1.1.2" xref="S2.T1.5.5.1.m1.1.1.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S2.T1.5.5.1.m1.1.1.1" xref="S2.T1.5.5.1.m1.1.1.1.cmml">​</mo><mi id="S2.T1.5.5.1.m1.1.1.3" xref="S2.T1.5.5.1.m1.1.1.3.cmml">N</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.T1.5.5.1.m1.1b"><apply id="S2.T1.5.5.1.m1.1.1.cmml" xref="S2.T1.5.5.1.m1.1.1"><times id="S2.T1.5.5.1.m1.1.1.1.cmml" xref="S2.T1.5.5.1.m1.1.1.1"></times><cn type="integer" id="S2.T1.5.5.1.m1.1.1.2.cmml" xref="S2.T1.5.5.1.m1.1.1.2">2</cn><ci id="S2.T1.5.5.1.m1.1.1.3.cmml" xref="S2.T1.5.5.1.m1.1.1.3">𝑁</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.5.5.1.m1.1c">2N</annotation></semantics></math></td>
<td id="S2.T1.6.6.2" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t"><math id="S2.T1.6.6.2.m1.1" class="ltx_Math" alttext="2KN" display="inline"><semantics id="S2.T1.6.6.2.m1.1a"><mrow id="S2.T1.6.6.2.m1.1.1" xref="S2.T1.6.6.2.m1.1.1.cmml"><mn id="S2.T1.6.6.2.m1.1.1.2" xref="S2.T1.6.6.2.m1.1.1.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S2.T1.6.6.2.m1.1.1.1" xref="S2.T1.6.6.2.m1.1.1.1.cmml">​</mo><mi id="S2.T1.6.6.2.m1.1.1.3" xref="S2.T1.6.6.2.m1.1.1.3.cmml">K</mi><mo lspace="0em" rspace="0em" id="S2.T1.6.6.2.m1.1.1.1a" xref="S2.T1.6.6.2.m1.1.1.1.cmml">​</mo><mi id="S2.T1.6.6.2.m1.1.1.4" xref="S2.T1.6.6.2.m1.1.1.4.cmml">N</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.T1.6.6.2.m1.1b"><apply id="S2.T1.6.6.2.m1.1.1.cmml" xref="S2.T1.6.6.2.m1.1.1"><times id="S2.T1.6.6.2.m1.1.1.1.cmml" xref="S2.T1.6.6.2.m1.1.1.1"></times><cn type="integer" id="S2.T1.6.6.2.m1.1.1.2.cmml" xref="S2.T1.6.6.2.m1.1.1.2">2</cn><ci id="S2.T1.6.6.2.m1.1.1.3.cmml" xref="S2.T1.6.6.2.m1.1.1.3">𝐾</ci><ci id="S2.T1.6.6.2.m1.1.1.4.cmml" xref="S2.T1.6.6.2.m1.1.1.4">𝑁</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.6.6.2.m1.1c">2KN</annotation></semantics></math></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S2.T1.8.1.1" class="ltx_text" style="font-size:90%;">Table 1</span>: </span><span id="S2.T1.9.2" class="ltx_text" style="font-size:90%;">Communication per client and total communication for the distributed learning setup as measured by the data transferred by all of the nodes in the learning setup.</span></figcaption>
</figure>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.8" class="ltx_p">The split learning setup has two variants where one involves weight sharing among clients while the other variant does not. Sharing weights among clients helps in the synchronization among the clients but at the same time leaks more information as held by the weights of the model. Weight sharing among client adds extra communication overhead where the amount of overhead depends upon the model size (<math id="S2.p2.1.m1.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S2.p2.1.m1.1a"><mi id="S2.p2.1.m1.1.1" xref="S2.p2.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S2.p2.1.m1.1b"><ci id="S2.p2.1.m1.1.1.cmml" xref="S2.p2.1.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.1.m1.1c">N</annotation></semantics></math>) and the size of the smashed layer (<math id="S2.p2.2.m2.1" class="ltx_Math" alttext="q" display="inline"><semantics id="S2.p2.2.m2.1a"><mi id="S2.p2.2.m2.1.1" xref="S2.p2.2.m2.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S2.p2.2.m2.1b"><ci id="S2.p2.2.m2.1.1.cmml" xref="S2.p2.2.m2.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.2.m2.1c">q</annotation></semantics></math>). The variant that does not involve weight sharing is based on alternating turns of epochs taken by the clients in working with the server.
The communication efficiency computed as ratio of data transfers of federated learning and split learning therefore is given by

<math id="S2.p2.3.m3.1" class="ltx_Math" alttext="\rho=\frac{2NK}{2pq+\eta NK}" display="inline"><semantics id="S2.p2.3.m3.1a"><mrow id="S2.p2.3.m3.1.1" xref="S2.p2.3.m3.1.1.cmml"><mi id="S2.p2.3.m3.1.1.2" xref="S2.p2.3.m3.1.1.2.cmml">ρ</mi><mo id="S2.p2.3.m3.1.1.1" xref="S2.p2.3.m3.1.1.1.cmml">=</mo><mfrac id="S2.p2.3.m3.1.1.3" xref="S2.p2.3.m3.1.1.3.cmml"><mrow id="S2.p2.3.m3.1.1.3.2" xref="S2.p2.3.m3.1.1.3.2.cmml"><mn id="S2.p2.3.m3.1.1.3.2.2" xref="S2.p2.3.m3.1.1.3.2.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S2.p2.3.m3.1.1.3.2.1" xref="S2.p2.3.m3.1.1.3.2.1.cmml">​</mo><mi id="S2.p2.3.m3.1.1.3.2.3" xref="S2.p2.3.m3.1.1.3.2.3.cmml">N</mi><mo lspace="0em" rspace="0em" id="S2.p2.3.m3.1.1.3.2.1a" xref="S2.p2.3.m3.1.1.3.2.1.cmml">​</mo><mi id="S2.p2.3.m3.1.1.3.2.4" xref="S2.p2.3.m3.1.1.3.2.4.cmml">K</mi></mrow><mrow id="S2.p2.3.m3.1.1.3.3" xref="S2.p2.3.m3.1.1.3.3.cmml"><mrow id="S2.p2.3.m3.1.1.3.3.2" xref="S2.p2.3.m3.1.1.3.3.2.cmml"><mn id="S2.p2.3.m3.1.1.3.3.2.2" xref="S2.p2.3.m3.1.1.3.3.2.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S2.p2.3.m3.1.1.3.3.2.1" xref="S2.p2.3.m3.1.1.3.3.2.1.cmml">​</mo><mi id="S2.p2.3.m3.1.1.3.3.2.3" xref="S2.p2.3.m3.1.1.3.3.2.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.p2.3.m3.1.1.3.3.2.1a" xref="S2.p2.3.m3.1.1.3.3.2.1.cmml">​</mo><mi id="S2.p2.3.m3.1.1.3.3.2.4" xref="S2.p2.3.m3.1.1.3.3.2.4.cmml">q</mi></mrow><mo id="S2.p2.3.m3.1.1.3.3.1" xref="S2.p2.3.m3.1.1.3.3.1.cmml">+</mo><mrow id="S2.p2.3.m3.1.1.3.3.3" xref="S2.p2.3.m3.1.1.3.3.3.cmml"><mi id="S2.p2.3.m3.1.1.3.3.3.2" xref="S2.p2.3.m3.1.1.3.3.3.2.cmml">η</mi><mo lspace="0em" rspace="0em" id="S2.p2.3.m3.1.1.3.3.3.1" xref="S2.p2.3.m3.1.1.3.3.3.1.cmml">​</mo><mi id="S2.p2.3.m3.1.1.3.3.3.3" xref="S2.p2.3.m3.1.1.3.3.3.3.cmml">N</mi><mo lspace="0em" rspace="0em" id="S2.p2.3.m3.1.1.3.3.3.1a" xref="S2.p2.3.m3.1.1.3.3.3.1.cmml">​</mo><mi id="S2.p2.3.m3.1.1.3.3.3.4" xref="S2.p2.3.m3.1.1.3.3.3.4.cmml">K</mi></mrow></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S2.p2.3.m3.1b"><apply id="S2.p2.3.m3.1.1.cmml" xref="S2.p2.3.m3.1.1"><eq id="S2.p2.3.m3.1.1.1.cmml" xref="S2.p2.3.m3.1.1.1"></eq><ci id="S2.p2.3.m3.1.1.2.cmml" xref="S2.p2.3.m3.1.1.2">𝜌</ci><apply id="S2.p2.3.m3.1.1.3.cmml" xref="S2.p2.3.m3.1.1.3"><divide id="S2.p2.3.m3.1.1.3.1.cmml" xref="S2.p2.3.m3.1.1.3"></divide><apply id="S2.p2.3.m3.1.1.3.2.cmml" xref="S2.p2.3.m3.1.1.3.2"><times id="S2.p2.3.m3.1.1.3.2.1.cmml" xref="S2.p2.3.m3.1.1.3.2.1"></times><cn type="integer" id="S2.p2.3.m3.1.1.3.2.2.cmml" xref="S2.p2.3.m3.1.1.3.2.2">2</cn><ci id="S2.p2.3.m3.1.1.3.2.3.cmml" xref="S2.p2.3.m3.1.1.3.2.3">𝑁</ci><ci id="S2.p2.3.m3.1.1.3.2.4.cmml" xref="S2.p2.3.m3.1.1.3.2.4">𝐾</ci></apply><apply id="S2.p2.3.m3.1.1.3.3.cmml" xref="S2.p2.3.m3.1.1.3.3"><plus id="S2.p2.3.m3.1.1.3.3.1.cmml" xref="S2.p2.3.m3.1.1.3.3.1"></plus><apply id="S2.p2.3.m3.1.1.3.3.2.cmml" xref="S2.p2.3.m3.1.1.3.3.2"><times id="S2.p2.3.m3.1.1.3.3.2.1.cmml" xref="S2.p2.3.m3.1.1.3.3.2.1"></times><cn type="integer" id="S2.p2.3.m3.1.1.3.3.2.2.cmml" xref="S2.p2.3.m3.1.1.3.3.2.2">2</cn><ci id="S2.p2.3.m3.1.1.3.3.2.3.cmml" xref="S2.p2.3.m3.1.1.3.3.2.3">𝑝</ci><ci id="S2.p2.3.m3.1.1.3.3.2.4.cmml" xref="S2.p2.3.m3.1.1.3.3.2.4">𝑞</ci></apply><apply id="S2.p2.3.m3.1.1.3.3.3.cmml" xref="S2.p2.3.m3.1.1.3.3.3"><times id="S2.p2.3.m3.1.1.3.3.3.1.cmml" xref="S2.p2.3.m3.1.1.3.3.3.1"></times><ci id="S2.p2.3.m3.1.1.3.3.3.2.cmml" xref="S2.p2.3.m3.1.1.3.3.3.2">𝜂</ci><ci id="S2.p2.3.m3.1.1.3.3.3.3.cmml" xref="S2.p2.3.m3.1.1.3.3.3.3">𝑁</ci><ci id="S2.p2.3.m3.1.1.3.3.3.4.cmml" xref="S2.p2.3.m3.1.1.3.3.3.4">𝐾</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.3.m3.1c">\rho=\frac{2NK}{2pq+\eta NK}</annotation></semantics></math>.
Split learning wins in terems of communication efficiency in scenarios when <math id="S2.p2.4.m4.1" class="ltx_Math" alttext="\rho&gt;1" display="inline"><semantics id="S2.p2.4.m4.1a"><mrow id="S2.p2.4.m4.1.1" xref="S2.p2.4.m4.1.1.cmml"><mi id="S2.p2.4.m4.1.1.2" xref="S2.p2.4.m4.1.1.2.cmml">ρ</mi><mo id="S2.p2.4.m4.1.1.1" xref="S2.p2.4.m4.1.1.1.cmml">&gt;</mo><mn id="S2.p2.4.m4.1.1.3" xref="S2.p2.4.m4.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.p2.4.m4.1b"><apply id="S2.p2.4.m4.1.1.cmml" xref="S2.p2.4.m4.1.1"><gt id="S2.p2.4.m4.1.1.1.cmml" xref="S2.p2.4.m4.1.1.1"></gt><ci id="S2.p2.4.m4.1.1.2.cmml" xref="S2.p2.4.m4.1.1.2">𝜌</ci><cn type="integer" id="S2.p2.4.m4.1.1.3.cmml" xref="S2.p2.4.m4.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.4.m4.1c">\rho&gt;1</annotation></semantics></math> and federated learning wins when <math id="S2.p2.5.m5.1" class="ltx_Math" alttext="\rho&lt;1" display="inline"><semantics id="S2.p2.5.m5.1a"><mrow id="S2.p2.5.m5.1.1" xref="S2.p2.5.m5.1.1.cmml"><mi id="S2.p2.5.m5.1.1.2" xref="S2.p2.5.m5.1.1.2.cmml">ρ</mi><mo id="S2.p2.5.m5.1.1.1" xref="S2.p2.5.m5.1.1.1.cmml">&lt;</mo><mn id="S2.p2.5.m5.1.1.3" xref="S2.p2.5.m5.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.p2.5.m5.1b"><apply id="S2.p2.5.m5.1.1.cmml" xref="S2.p2.5.m5.1.1"><lt id="S2.p2.5.m5.1.1.1.cmml" xref="S2.p2.5.m5.1.1.1"></lt><ci id="S2.p2.5.m5.1.1.2.cmml" xref="S2.p2.5.m5.1.1.2">𝜌</ci><cn type="integer" id="S2.p2.5.m5.1.1.3.cmml" xref="S2.p2.5.m5.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.5.m5.1c">\rho&lt;1</annotation></semantics></math>. Upon rearranging the terms, and expressing it as an equality, and dividing the numerator and denominator by <math id="S2.p2.6.m6.1" class="ltx_Math" alttext="NK" display="inline"><semantics id="S2.p2.6.m6.1a"><mrow id="S2.p2.6.m6.1.1" xref="S2.p2.6.m6.1.1.cmml"><mi id="S2.p2.6.m6.1.1.2" xref="S2.p2.6.m6.1.1.2.cmml">N</mi><mo lspace="0em" rspace="0em" id="S2.p2.6.m6.1.1.1" xref="S2.p2.6.m6.1.1.1.cmml">​</mo><mi id="S2.p2.6.m6.1.1.3" xref="S2.p2.6.m6.1.1.3.cmml">K</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.p2.6.m6.1b"><apply id="S2.p2.6.m6.1.1.cmml" xref="S2.p2.6.m6.1.1"><times id="S2.p2.6.m6.1.1.1.cmml" xref="S2.p2.6.m6.1.1.1"></times><ci id="S2.p2.6.m6.1.1.2.cmml" xref="S2.p2.6.m6.1.1.2">𝑁</ci><ci id="S2.p2.6.m6.1.1.3.cmml" xref="S2.p2.6.m6.1.1.3">𝐾</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.6.m6.1c">NK</annotation></semantics></math> we get the equation of a rectangular hyperbola as <math id="S2.p2.7.m7.1" class="ltx_Math" alttext="N=\frac{2pq}{((2-\eta)K)}" display="inline"><semantics id="S2.p2.7.m7.1a"><mrow id="S2.p2.7.m7.1.2" xref="S2.p2.7.m7.1.2.cmml"><mi id="S2.p2.7.m7.1.2.2" xref="S2.p2.7.m7.1.2.2.cmml">N</mi><mo id="S2.p2.7.m7.1.2.1" xref="S2.p2.7.m7.1.2.1.cmml">=</mo><mfrac id="S2.p2.7.m7.1.1" xref="S2.p2.7.m7.1.1.cmml"><mrow id="S2.p2.7.m7.1.1.3" xref="S2.p2.7.m7.1.1.3.cmml"><mn id="S2.p2.7.m7.1.1.3.2" xref="S2.p2.7.m7.1.1.3.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S2.p2.7.m7.1.1.3.1" xref="S2.p2.7.m7.1.1.3.1.cmml">​</mo><mi id="S2.p2.7.m7.1.1.3.3" xref="S2.p2.7.m7.1.1.3.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.p2.7.m7.1.1.3.1a" xref="S2.p2.7.m7.1.1.3.1.cmml">​</mo><mi id="S2.p2.7.m7.1.1.3.4" xref="S2.p2.7.m7.1.1.3.4.cmml">q</mi></mrow><mrow id="S2.p2.7.m7.1.1.1.1" xref="S2.p2.7.m7.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.p2.7.m7.1.1.1.1.2" xref="S2.p2.7.m7.1.1.1.1.1.cmml">(</mo><mrow id="S2.p2.7.m7.1.1.1.1.1" xref="S2.p2.7.m7.1.1.1.1.1.cmml"><mrow id="S2.p2.7.m7.1.1.1.1.1.1.1" xref="S2.p2.7.m7.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.p2.7.m7.1.1.1.1.1.1.1.2" xref="S2.p2.7.m7.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.p2.7.m7.1.1.1.1.1.1.1.1" xref="S2.p2.7.m7.1.1.1.1.1.1.1.1.cmml"><mn id="S2.p2.7.m7.1.1.1.1.1.1.1.1.2" xref="S2.p2.7.m7.1.1.1.1.1.1.1.1.2.cmml">2</mn><mo id="S2.p2.7.m7.1.1.1.1.1.1.1.1.1" xref="S2.p2.7.m7.1.1.1.1.1.1.1.1.1.cmml">−</mo><mi id="S2.p2.7.m7.1.1.1.1.1.1.1.1.3" xref="S2.p2.7.m7.1.1.1.1.1.1.1.1.3.cmml">η</mi></mrow><mo stretchy="false" id="S2.p2.7.m7.1.1.1.1.1.1.1.3" xref="S2.p2.7.m7.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S2.p2.7.m7.1.1.1.1.1.2" xref="S2.p2.7.m7.1.1.1.1.1.2.cmml">​</mo><mi id="S2.p2.7.m7.1.1.1.1.1.3" xref="S2.p2.7.m7.1.1.1.1.1.3.cmml">K</mi></mrow><mo stretchy="false" id="S2.p2.7.m7.1.1.1.1.3" xref="S2.p2.7.m7.1.1.1.1.1.cmml">)</mo></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S2.p2.7.m7.1b"><apply id="S2.p2.7.m7.1.2.cmml" xref="S2.p2.7.m7.1.2"><eq id="S2.p2.7.m7.1.2.1.cmml" xref="S2.p2.7.m7.1.2.1"></eq><ci id="S2.p2.7.m7.1.2.2.cmml" xref="S2.p2.7.m7.1.2.2">𝑁</ci><apply id="S2.p2.7.m7.1.1.cmml" xref="S2.p2.7.m7.1.1"><divide id="S2.p2.7.m7.1.1.2.cmml" xref="S2.p2.7.m7.1.1"></divide><apply id="S2.p2.7.m7.1.1.3.cmml" xref="S2.p2.7.m7.1.1.3"><times id="S2.p2.7.m7.1.1.3.1.cmml" xref="S2.p2.7.m7.1.1.3.1"></times><cn type="integer" id="S2.p2.7.m7.1.1.3.2.cmml" xref="S2.p2.7.m7.1.1.3.2">2</cn><ci id="S2.p2.7.m7.1.1.3.3.cmml" xref="S2.p2.7.m7.1.1.3.3">𝑝</ci><ci id="S2.p2.7.m7.1.1.3.4.cmml" xref="S2.p2.7.m7.1.1.3.4">𝑞</ci></apply><apply id="S2.p2.7.m7.1.1.1.1.1.cmml" xref="S2.p2.7.m7.1.1.1.1"><times id="S2.p2.7.m7.1.1.1.1.1.2.cmml" xref="S2.p2.7.m7.1.1.1.1.1.2"></times><apply id="S2.p2.7.m7.1.1.1.1.1.1.1.1.cmml" xref="S2.p2.7.m7.1.1.1.1.1.1.1"><minus id="S2.p2.7.m7.1.1.1.1.1.1.1.1.1.cmml" xref="S2.p2.7.m7.1.1.1.1.1.1.1.1.1"></minus><cn type="integer" id="S2.p2.7.m7.1.1.1.1.1.1.1.1.2.cmml" xref="S2.p2.7.m7.1.1.1.1.1.1.1.1.2">2</cn><ci id="S2.p2.7.m7.1.1.1.1.1.1.1.1.3.cmml" xref="S2.p2.7.m7.1.1.1.1.1.1.1.1.3">𝜂</ci></apply><ci id="S2.p2.7.m7.1.1.1.1.1.3.cmml" xref="S2.p2.7.m7.1.1.1.1.1.3">𝐾</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.7.m7.1c">N=\frac{2pq}{((2-\eta)K)}</annotation></semantics></math> in the case of client weight sharing and <math id="S2.p2.8.m8.1" class="ltx_Math" alttext="N=\frac{pq}{K}" display="inline"><semantics id="S2.p2.8.m8.1a"><mrow id="S2.p2.8.m8.1.1" xref="S2.p2.8.m8.1.1.cmml"><mi id="S2.p2.8.m8.1.1.2" xref="S2.p2.8.m8.1.1.2.cmml">N</mi><mo id="S2.p2.8.m8.1.1.1" xref="S2.p2.8.m8.1.1.1.cmml">=</mo><mfrac id="S2.p2.8.m8.1.1.3" xref="S2.p2.8.m8.1.1.3.cmml"><mrow id="S2.p2.8.m8.1.1.3.2" xref="S2.p2.8.m8.1.1.3.2.cmml"><mi id="S2.p2.8.m8.1.1.3.2.2" xref="S2.p2.8.m8.1.1.3.2.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.p2.8.m8.1.1.3.2.1" xref="S2.p2.8.m8.1.1.3.2.1.cmml">​</mo><mi id="S2.p2.8.m8.1.1.3.2.3" xref="S2.p2.8.m8.1.1.3.2.3.cmml">q</mi></mrow><mi id="S2.p2.8.m8.1.1.3.3" xref="S2.p2.8.m8.1.1.3.3.cmml">K</mi></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S2.p2.8.m8.1b"><apply id="S2.p2.8.m8.1.1.cmml" xref="S2.p2.8.m8.1.1"><eq id="S2.p2.8.m8.1.1.1.cmml" xref="S2.p2.8.m8.1.1.1"></eq><ci id="S2.p2.8.m8.1.1.2.cmml" xref="S2.p2.8.m8.1.1.2">𝑁</ci><apply id="S2.p2.8.m8.1.1.3.cmml" xref="S2.p2.8.m8.1.1.3"><divide id="S2.p2.8.m8.1.1.3.1.cmml" xref="S2.p2.8.m8.1.1.3"></divide><apply id="S2.p2.8.m8.1.1.3.2.cmml" xref="S2.p2.8.m8.1.1.3.2"><times id="S2.p2.8.m8.1.1.3.2.1.cmml" xref="S2.p2.8.m8.1.1.3.2.1"></times><ci id="S2.p2.8.m8.1.1.3.2.2.cmml" xref="S2.p2.8.m8.1.1.3.2.2">𝑝</ci><ci id="S2.p2.8.m8.1.1.3.2.3.cmml" xref="S2.p2.8.m8.1.1.3.2.3">𝑞</ci></apply><ci id="S2.p2.8.m8.1.1.3.3.cmml" xref="S2.p2.8.m8.1.1.3.3">𝐾</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.8.m8.1c">N=\frac{pq}{K}</annotation></semantics></math> in the case of no client weight sharing with alternating epochs. This hyperbola divides the regions where one technique perfors better over the other and both the feasible regions are shown in the theoretical schematic cartoon in Figure 3.
</p>
</div>
<figure id="S2.F6" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S2.F6.1" class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_middle" style="width:138.8pt;"><img src="/html/1909.09145/assets/x1.png" id="S2.F6.1.g1" class="ltx_graphics ltx_img_square" width="461" height="461" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S2.F6.1.1.1.1" class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span id="S2.F6.1.2.2" class="ltx_text" style="font-size:90%;">Use case corresponding to smart watches. Case-1 refers to a big model and high number of client setting. Case-2 refers to a relatively small model and Case-3 refers to even smaller model as well as low number of parameters.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S2.F6.2" class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_middle" style="width:138.8pt;"><img src="/html/1909.09145/assets/x2.png" id="S2.F6.2.g1" class="ltx_graphics ltx_img_square" width="461" height="461" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S2.F6.2.1.1.1" class="ltx_text" style="font-size:90%;">Figure 5</span>: </span><span id="S2.F6.2.2.2" class="ltx_text" style="font-size:90%;">Use case for the healthcare scenario. Case-1 refers to a big model size and small number of clients. Case-2 has slightly higher number of clients and rest everything is same. Case-3 has bigger dataset and less number of clients.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S2.F6.3" class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_middle" style="width:138.8pt;"><img src="/html/1909.09145/assets/x3.png" id="S2.F6.3.g1" class="ltx_graphics ltx_img_square" width="461" height="461" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S2.F6.3.1.1.1" class="ltx_text" style="font-size:90%;">Figure 6</span>: </span><span id="S2.F6.3.2.2" class="ltx_text" style="font-size:90%;">Amount of data transfer required for completing one round of training is shown for both split learning and federated learning like in adjacent figures and lower value on the y-axis means higher communication efficiency.</span></figcaption>
</figure>
</div>
</div>
</figure>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Analysis</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">We consider some of the real-life use cases which depict the relative efficacy of the two methods of split learning and federated learning.
<br class="ltx_break">First case is motivated by the scenario where the number of clients is in the range of millions. One concrete use case is smart watches (edge devices) which comprises of users in a diverse range from hundreds to millions. Figure( <a href="#S2.F6" title="Figure 6 ‣ 2 Communication efficiency ‣ Detailed comparison of communication efficiency of split learning and federated learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>) presents all the three cases for the training under three different scenarios. Starting from the case-1, split learning setup has relatively lower data transfer due to the high number of model parameters and high number of clients. As we reduce the model parameters and number of clients in the case-3, the federated learning setup is relatively more communication efficient.
Second case, Figure( <a href="#S2.F6" title="Figure 6 ‣ 2 Communication efficiency ‣ Detailed comparison of communication efficiency of split learning and federated learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>) is inspired from the healthcare setting where the clients are hospitals with large models but the number of clients is limited. In this case federated learning and split learning perform roughly same except the case three where federated performs better when dataset size is bigger and the number of clients is small.
<br class="ltx_break">Third case, Figure( <a href="#S2.F6" title="Figure 6 ‣ 2 Communication efficiency ‣ Detailed comparison of communication efficiency of split learning and federated learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>) covers the use case for bigger institutions like biobanks where all the three parameters are in a high number. In case-1 and case-2, split learning setup outperforms the distributed learning because it scales well with the number of clients and the model parameters.
<br class="ltx_break">Figure( <a href="#S3.F7" title="Figure 7 ‣ 3 Analysis ‣ Detailed comparison of communication efficiency of split learning and federated learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>) provides more practical scenarios of feasible curve of effeciency across a broad spectrum of parameters.</p>
</div>
<figure id="S3.F7" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S3.F7.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/1909.09145/assets/clients_in_practical_parameter_scenario.png" id="S3.F7.sf1.g1" class="ltx_graphics ltx_img_square" width="181" height="197" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F7.sf1.4.2.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S3.F7.sf1.2.1" class="ltx_text" style="font-size:90%;">Number of clients in a setting where the number of parameters for the model is in the range of <math id="S3.F7.sf1.2.1.m1.1" class="ltx_Math" alttext="10M-200M" display="inline"><semantics id="S3.F7.sf1.2.1.m1.1b"><mrow id="S3.F7.sf1.2.1.m1.1.1" xref="S3.F7.sf1.2.1.m1.1.1.cmml"><mrow id="S3.F7.sf1.2.1.m1.1.1.2" xref="S3.F7.sf1.2.1.m1.1.1.2.cmml"><mn id="S3.F7.sf1.2.1.m1.1.1.2.2" xref="S3.F7.sf1.2.1.m1.1.1.2.2.cmml">10</mn><mo lspace="0em" rspace="0em" id="S3.F7.sf1.2.1.m1.1.1.2.1" xref="S3.F7.sf1.2.1.m1.1.1.2.1.cmml">​</mo><mi id="S3.F7.sf1.2.1.m1.1.1.2.3" xref="S3.F7.sf1.2.1.m1.1.1.2.3.cmml">M</mi></mrow><mo id="S3.F7.sf1.2.1.m1.1.1.1" xref="S3.F7.sf1.2.1.m1.1.1.1.cmml">−</mo><mrow id="S3.F7.sf1.2.1.m1.1.1.3" xref="S3.F7.sf1.2.1.m1.1.1.3.cmml"><mn id="S3.F7.sf1.2.1.m1.1.1.3.2" xref="S3.F7.sf1.2.1.m1.1.1.3.2.cmml">200</mn><mo lspace="0em" rspace="0em" id="S3.F7.sf1.2.1.m1.1.1.3.1" xref="S3.F7.sf1.2.1.m1.1.1.3.1.cmml">​</mo><mi id="S3.F7.sf1.2.1.m1.1.1.3.3" xref="S3.F7.sf1.2.1.m1.1.1.3.3.cmml">M</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.F7.sf1.2.1.m1.1c"><apply id="S3.F7.sf1.2.1.m1.1.1.cmml" xref="S3.F7.sf1.2.1.m1.1.1"><minus id="S3.F7.sf1.2.1.m1.1.1.1.cmml" xref="S3.F7.sf1.2.1.m1.1.1.1"></minus><apply id="S3.F7.sf1.2.1.m1.1.1.2.cmml" xref="S3.F7.sf1.2.1.m1.1.1.2"><times id="S3.F7.sf1.2.1.m1.1.1.2.1.cmml" xref="S3.F7.sf1.2.1.m1.1.1.2.1"></times><cn type="integer" id="S3.F7.sf1.2.1.m1.1.1.2.2.cmml" xref="S3.F7.sf1.2.1.m1.1.1.2.2">10</cn><ci id="S3.F7.sf1.2.1.m1.1.1.2.3.cmml" xref="S3.F7.sf1.2.1.m1.1.1.2.3">𝑀</ci></apply><apply id="S3.F7.sf1.2.1.m1.1.1.3.cmml" xref="S3.F7.sf1.2.1.m1.1.1.3"><times id="S3.F7.sf1.2.1.m1.1.1.3.1.cmml" xref="S3.F7.sf1.2.1.m1.1.1.3.1"></times><cn type="integer" id="S3.F7.sf1.2.1.m1.1.1.3.2.cmml" xref="S3.F7.sf1.2.1.m1.1.1.3.2">200</cn><ci id="S3.F7.sf1.2.1.m1.1.1.3.3.cmml" xref="S3.F7.sf1.2.1.m1.1.1.3.3">𝑀</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F7.sf1.2.1.m1.1d">10M-200M</annotation></semantics></math>.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S3.F7.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/1909.09145/assets/small_clients_large_model_scenario.png" id="S3.F7.sf2.g1" class="ltx_graphics ltx_img_square" width="181" height="197" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F7.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S3.F7.sf2.3.2" class="ltx_text" style="font-size:90%;">Small client setting where massive models can be fit like Transformers and AmoebaNet( <cite class="ltx_cite ltx_citemacro_cite">Huang et al. (<a href="#bib.bib2" title="" class="ltx_ref">2018</a>)</cite>).</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S3.F7.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/1909.09145/assets/large_clients_small_model_scenario.png" id="S3.F7.sf3.g1" class="ltx_graphics ltx_img_square" width="181" height="197" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F7.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="S3.F7.sf3.3.2" class="ltx_text" style="font-size:90%;"> Large client setting which allows a big range from tiny to large models to fit in is shown in this subfigure.</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F7.2.1.1" class="ltx_text" style="font-size:90%;">Figure 7</span>: </span><span id="S3.F7.3.2" class="ltx_text" style="font-size:90%;">Curve for comparing effeciency of Split learning and Federated learning setup. Similar to the figure <a href="#S1.F3" title="Figure 3 ‣ 1.2 Federated learning ‣ 1 Introduction ‣ Detailed comparison of communication efficiency of split learning and federated learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, upper half region shows the feasible region for relatively higher communication efficiency for Split Learning. The three curves in all three figures refer to the change in the position of split layer. We consider the size of commonly used activations in the CNN models during early layers.</span></figcaption>
</figure>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Conclusion and future work</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">Our analysis suggests that the split learning setup becomes more communication efficient with increasing number of clients and is highly scalable with number of model parameters. Federated learning becomes more efficient with increasing the number of data samples especially when the number of clients is small or model size is small. In this work we also identify some of the use-cases where one would be more effective than the other in terms of communication efficiency. The analysis and discussion presented in this work would be benefecial for the distributed learning community to understand the potential benefits of both methods. This work could be extended by analyzing the resource utilization and number of epochs required for convergance of both distributed learning setups under different practical scenarios. <cite class="ltx_cite ltx_citemacro_citep">(Gupta &amp; Raskar, <a href="#bib.bib1" title="" class="ltx_ref">2018</a>; Vepakomma et al., <a href="#bib.bib5" title="" class="ltx_ref">2018</a>)</cite> shows that split learning converges drastically quicker than federated learning.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gupta &amp; Raskar (2018)</span>
<span class="ltx_bibblock">
Gupta, O. and Raskar, R.

</span>
<span class="ltx_bibblock">Distributed learning of deep neural network over multiple agents.

</span>
<span class="ltx_bibblock"><em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/1810.06060, 2018.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="http://arxiv.org/abs/1810.06060" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/1810.06060</a>.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et al. (2018)</span>
<span class="ltx_bibblock">
Huang, Y., Cheng, Y., Chen, D., Lee, H., Ngiam, J., Le, Q. V., and Chen, Z.

</span>
<span class="ltx_bibblock">Gpipe: Efficient training of giant neural networks using pipeline
parallelism.

</span>
<span class="ltx_bibblock"><em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/1811.06965, 2018.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="http://arxiv.org/abs/1811.06965" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/1811.06965</a>.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Konečnỳ et al. (2016)</span>
<span class="ltx_bibblock">
Konečnỳ, J., McMahan, H. B., Yu, F. X., Richtárik, P., Suresh,
A. T., and Bacon, D.

</span>
<span class="ltx_bibblock">Federated learning: Strategies for improving communication
efficiency.

</span>
<span class="ltx_bibblock"><em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1610.05492</em>, 2016.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McMahan et al. (2016)</span>
<span class="ltx_bibblock">
McMahan, H. B., Moore, E., Ramage, D., and y Arcas, B. A.

</span>
<span class="ltx_bibblock">Federated learning of deep networks using model averaging.

</span>
<span class="ltx_bibblock"><em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/1602.05629, 2016.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="http://arxiv.org/abs/1602.05629" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/1602.05629</a>.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vepakomma et al. (2018)</span>
<span class="ltx_bibblock">
Vepakomma, P., Gupta, O., Swedish, T., and Raskar, R.

</span>
<span class="ltx_bibblock">Split learning for health: Distributed deep learning without sharing
raw patient data.

</span>
<span class="ltx_bibblock"><em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/1812.00564, 2018.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="http://arxiv.org/abs/1812.00564" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/1812.00564</a>.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vepakomma et al. (2019)</span>
<span class="ltx_bibblock">
Vepakomma, P., Gupta, O., Dubey, A., and Raskar, R.

</span>
<span class="ltx_bibblock">Reducing leakage in distributed deep learning for sensitive health
data.

</span>
<span class="ltx_bibblock"><em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1812.00564</em>, 2019.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/1909.09144" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/1909.09145" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+1909.09145">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/1909.09145" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/1909.09146" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sun Mar  3 22:28:34 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
