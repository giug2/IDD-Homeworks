<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2006.02931] Federated Learning for 6G Communications: Challenges, Methods, and Future Directions</title><meta property="og:description" content="As the 5G communication networks are being widely deployed worldwide, both industry and academia have started to move beyond 5G and explore 6G communications. It is generally believed that 6G will be established on ubi…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Federated Learning for 6G Communications: Challenges, Methods, and Future Directions">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Federated Learning for 6G Communications: Challenges, Methods, and Future Directions">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2006.02931">

<!--Generated on Tue Feb 27 04:47:50 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="
6G communication,  federated learning,  security and privacy protection
">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Federated Learning for 6G Communications: Challenges, Methods, and Future Directions</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yi Liu,
Xingliang Yuan, 
Zehui Xiong,  Jiawen Kang,  Xiaofei Wang, 
Dusit Niyato
</span><span class="ltx_author_notes">Yi Liu is with School of Data Science of Technology, Heilongjiang University, Harbin, China (97liuyi@ieee.org).Xingliang Yuan is with Faculty of Information Technology, Monash University, Clayton VIC, 3800, Australia (e-mail: xingliang.yuan@monash.edu).Zehui Xiong and Dusit Niyato are with School of Computer Science and Engineering, Nanyang Technological University, Singapore. (e-mail: zxiong002@e.ntu.edu.sg, dniyato@ntu.edu.sg).Xiaofei Wang is with the College of Intelligence and Computing, Tianjin University, Tianjin, China. (e-mail: xiaofeiwang@tju.edu.cn).Jiawen Kang is with Energy Research Institute, Nanyang Technological University, Singapore (e-mail: kavinkang@ntu.edu.sg).</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">As the 5G communication networks are being widely deployed worldwide, both industry and academia have started to move beyond 5G and explore 6G communications. It is generally believed that 6G will be established on ubiquitous Artificial Intelligence (AI) to achieve data-driven Machine Learning (ML) solutions in heterogeneous and massive-scale networks. However, traditional ML techniques require centralized data collection and processing by a central server, which is becoming a bottleneck of large-scale implementation in daily life due to significantly increasing privacy concerns. Federated learning, as an emerging distributed AI approach with privacy preservation nature, is particularly attractive for various wireless applications, especially being treated as one of the vital solutions to achieve ubiquitous AI in 6G. In this article, we first introduce the integration of 6G and federated learning and provide potential federated learning applications for 6G. We then describe key technical challenges, the corresponding federated learning methods, and open problems for future research on federated learning in the context of 6G communications.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
6G communication, federated learning, security and privacy protection

</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">The rapid development of wireless communication techniques with numerous technological innovations for decades has greatly improved people’s lives and promoting the development of the industry. As shown in Fig. <a href="#S1.F1" title="Figure 1 ‣ I Introduction ‣ Federated Learning for 6G Communications: Challenges, Methods, and Future Directions" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, the current Fourth-generation (4G) LTE network has created an era of mobile internet with Web search services, multimedia services, and APPs as core functions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. The upcoming Fifth-generation (5G) system is designed to support a wider range of services, such as Augmented Reality/Virtual Reality (AR/VR), large-scale Internet of Things (IoT), and autonomous driving <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. Specifically, the 5G system includes three technical characteristics: enhanced Mobile BroadBand (eMBB), massive Machine-Type-Communications (mMTC), ultra-Reliable Low-Latency Communications (uRLLC). Since 5G brings unprecedented benefits to humans and is being actively deployed around the world, both industry and academia have begun to move towards the next generation of wireless technology, i.e., Sixth-generation (6G) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">The 5G system represents a new wireless communication paradigm that adopts a service-based architecture (SBA) instead of a communication-oriented architecture (COA) to achieve “connected things”. In contrast to previous generations, 6G with transformative technologies will revolutionize the development of wireless communication from “connected things” to “connected intelligence” <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. Specifically, 6G will revolutionize technology in three areas: new media, new services, and new infrastructures. It is expected that the 6G system will adopt advanced artificial intelligence (AI) technologies in these fields, and promptly and efficiently collect, transmit, and learn data anytime, anywhere to generate a large number of innovative applications and intelligent services <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>. In particular, ubiquitous AI will empower the promising 6G, a hyper-flexible architecture that brings human-centric development concepts to all aspects of network systems, instead of data-centric, machine-centric, and application-centric <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>. Therefore, 6G communications have higher-level security and stronger privacy protection requirements.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">However, traditional Machine Learning (ML) empowered frameworks based on a central server are suffering from critical privacy and security challenges, e.g., single point of failure, which is not able to enable ubiquitous and secure AI for 6G. Moreover, due to large overhead caused by centralized data aggregation and processing, traditional centralized ML schemes might not be suitable for ubiquitous ML <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>. Thereby, decentralized ML solutions, in which all private data is kept in training devices locally, are becoming increasingly essential for 6G. Recently, Federated Learning (FL) as an emerging decentralized ML solution has attracted particular attention from academia and industry <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>.
In FL, participating devices collaboratively train a shared model through their local data, and thus only upload model updates instead of raw data to centralized parameter servers <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Although FL brings high potential for AI-empowered 6G and significantly improves privacy-sensitive applications with 6G communication, FL is still in the early stages of development and is facing new challenges in 6G scenarios. In this paper, we first introduce the core challenges of FL in 6G communications including (i) large communication cost due to multiple communication rounds for model updates and aggregation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>; (ii) security problems caused by heterogeneous and diverse participating entities, e.g., poisoning attacks and backdoor attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>; (iii) privacy problems resulted from gradient leakage attacks and membership inference attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>; (iv) model training and inference efficiency problems among massive-scale 6G networks. We then propose advanced federated learning methods to address the above challenges from different perspectives. Finally, we describe the open research topics and future directions of FL in 6G communications.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2006.02931/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="259" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Key services and roadmap for 6G <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>.</figcaption>
</figure>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Preliminaries and Overview</span>
</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS1.5.1.1" class="ltx_text">II-A</span> </span><span id="S2.SS1.6.2" class="ltx_text ltx_font_italic">Key 6G Requirements and Use Cases</span>
</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Unlike 5G communications, 6G has prominent features to ensure ubiquitous, seamless, intelligent, high-performance connectivity and networking with security and privacy protection. More specifically, we will introduce the performance requirements of 6G communications as follows.</p>
</div>
<section id="S2.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S2.SS1.SSS1.5.1.1" class="ltx_text">II-A</span>1 </span><span id="S2.SS1.SSS1.6.2" class="ltx_text ltx_font_bold">High Performance Networking</span>
</h4>

<div id="S2.SS1.SSS1.p1" class="ltx_para">
<p id="S2.SS1.SSS1.p1.1" class="ltx_p">It is commonly believed that 6G is a complex networking system with many heterogeneous space-air-ground-underwater communication networks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>. The three-dimensional super-connectivity networks provide worldwide connectivity and integrated networking to enable different types of network services and dense coverage through sub-networks and sub-systems, e.g., satellite communication networks, underwater-land communications. With the help of massive-scale heterogeneous networks, 6G communications can achieve up to 1 Tbps data rate per user, ultra-low end-to-end delay, superior end-to-end reliability, and high energy efficiency networking <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. Compared with 5G communications, 6G communications support networking and connecting the majority not only in dense areas but also the less dense areas, such as the underwater environment, in an efficient and low overhead manner <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>. 6G communications employ novel communication networks to support highly diversified data, e.g., audio, video, AR/VR data, which reaches new communication experience with virtual networking existence and involvement anywhere <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>.</p>
</div>
</section>
<section id="S2.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S2.SS1.SSS2.5.1.1" class="ltx_text">II-A</span>2 </span><span id="S2.SS1.SSS2.6.2" class="ltx_text ltx_font_bold">Higher Energy Efficiency</span>
</h4>

<div id="S2.SS1.SSS2.p1" class="ltx_para">
<p id="S2.SS1.SSS2.p1.1" class="ltx_p">In the 6G era, there exist higher energy efficiency requirements for wireless devices with charging constraints and battery life limitations. Therefore, long battery life and low energy consumption are two popular research topics for 6G communications. To address the energy problems of wireless devices, especially smartphones, existing studies have proposed energy harvesting technology, wireless power transfer technology, and green communication to improve energy efficiency and extend the working time of wireless devices <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>.
Especially, the wireless devices can harvest energy from ambient radio-frequency, solar, geothermal energy, and wind energy by using different energy harvesting technologies, which can prolong the battery life. Similarly, the wireless devices with wireless charging equipment can obtain energy supplement from dense network infrastructures or mobile charging stations, e.g., Unmanned Aerial Vehicle (UAV), Electric Vehicles (EVs), through wireless power transfer technology.</p>
</div>
<div id="S2.SS1.SSS2.p2" class="ltx_para">
<p id="S2.SS1.SSS2.p2.1" class="ltx_p">Recently, to address energy problems for wireless devices, and emerging technology named symbiotic radio (SR) is introduced to integrate passive backscatter devices with an active transmission system <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>. A typical example of SR is ambient backscatter communication, that enables network devices to utilize ambient RF signals to transmit information without requiring active RF transmission, making battery-free communication possible <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. Smart energy management is another promising mechanism with the goal of dynamically optimizing the balance between energy demand and supply <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>.</p>
</div>
<div id="S2.SS1.SSS2.p3" class="ltx_para">
<p id="S2.SS1.SSS2.p3.1" class="ltx_p">For green communication techniques, AI-based solutions are quite important to optimize energy usage and energy scheduling for wireless devices in a dynamic environment and complex optimization goals. Advanced machine learning techniques, such as deep reinforcement learning, can be utilized to optimize the computation task offloading decision of a wireless device, and also make the best scheduling solution of working and sleeping time, which can lower energy consumption and enhance energy efficiency. The AI-based solutions can be also applied in multi-hop information routing in cooperative relay communication and communication infrastructure deployment in network-densification 6G scenarios, which significantly reduces the transmit power of the wireless devices without long propagation distance thus enabling high-efficiency communication <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>.</p>
</div>
</section>
<section id="S2.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S2.SS1.SSS3.5.1.1" class="ltx_text">II-A</span>3 </span><span id="S2.SS1.SSS3.6.2" class="ltx_text ltx_font_bold">High Security and Privacy</span>
</h4>

<div id="S2.SS1.SSS3.p1" class="ltx_para">
<p id="S2.SS1.SSS3.p1.1" class="ltx_p">Existing research mainly focuses on network throughput, reliability, and delay in 4G and 5G communications <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>. However, in the past few decades, wireless communication security and privacy issues have been ignored to some extent. Since data security and privacy issues are closely related to users’ lives, protecting data security and privacy has become a very important part of human-centric 6G communications. Meanwhile, communication/data service providers legally collect a large amount of user information, which leads to frequent leakage of privacy data. In order to solve this problem, it is envisaged that FL techniuqes can be used to achieve privacy-enhanced deep learning in 6G networks.</p>
</div>
</section>
<section id="S2.SS1.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S2.SS1.SSS4.5.1.1" class="ltx_text">II-A</span>4 </span><span id="S2.SS1.SSS4.6.2" class="ltx_text ltx_font_bold">High Intelligence</span>
</h4>

<div id="S2.SS1.SSS4.p1" class="ltx_para">
<p id="S2.SS1.SSS4.p1.1" class="ltx_p">The high intelligence of 6G will be beneficial to provide users with high-quality, personalized, and intelligent services. High-intelligent 6G includes operational intelligence, application intelligence, and service intelligence as follows.</p>
</div>
<div id="S2.SS1.SSS4.p2" class="ltx_para">
<ul id="S2.I1" class="ltx_itemize">
<li id="S2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i1.p1" class="ltx_para">
<p id="S2.I1.i1.p1.1" class="ltx_p"><span id="S2.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Operational Intelligence.</span> Traditional network operations involve a series of resource optimization and multi-objective performance optimization problems <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. In order to achieve a satisfactory level of network operation, optimization methods based on game theory, contract theory, etc. are widely used. However, these optimization theories may not obtain the optimal solution in large-scale time-varying variables and multi-objective scenarios. With the development of deep learning technologies, the above can be solved by using advanced machine learning technologies. On the other hand, the emergence of federated learning has transformed the multi-objective linear optimization problems into a nonlinear optimization problem, thus finding out the best solution for complex and time-varying decisions in operational intelligence <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>.</p>
</div>
</li>
<li id="S2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i2.p1" class="ltx_para">
<p id="S2.I1.i2.p1.1" class="ltx_p"><span id="S2.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Application Intelligence.</span> At present, applications related to 5G networks are gradually becoming intelligent. For 6G networks, intelligent applications are one baseline of application requirements <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>. FL empowered wireless communication technologies to enable devices to connect with 6G networks to run a variety of intelligent applications. For example, in the future, users may need intelligent voice assistants to complete their daily schedules <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>. The 6G network ubiquitous AI will provide users with highly intelligent applications.</p>
</div>
</li>
<li id="S2.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i3.p1" class="ltx_para">
<p id="S2.I1.i3.p1.1" class="ltx_p"><span id="S2.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">Service Intelligence</span> Furthermore, as a human-centric network, the high intelligence of the 6G network will provide intelligent services in a satisfactory and personalized manner <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>. For example, FL provides users with personalized healthcare services, personalized recommendation services, and personalized intelligent voice services in a distributed learning manner. In the future, intelligent services will be tightly integrated with the 6G networks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2.SS1.SSS5" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S2.SS1.SSS5.5.1.1" class="ltx_text">II-A</span>5 </span><span id="S2.SS1.SSS5.6.2" class="ltx_text ltx_font_bold">Increased Device Density</span>
</h4>

<div id="S2.SS1.SSS5.p1" class="ltx_para">
<p id="S2.SS1.SSS5.p1.1" class="ltx_p">Compared with 5G, the 6G has much higher transmission rates and shorter delay, greater device density, and the integration of Artificial Intelligence (AI). With the increased device density and explosive increasing data traffic, it is more and more important to solve the network capacity challenges. One of the potential solutions is to provide increasingly more but smaller radio cells that can transmit data quickly and energy-efficiently. These cells are required to be connected as seamlessly as possible to the fiber-optic core networks via high-performance transmission links. An important goal is to connect these wireless transmission links directly to fiber-optic networks without complex electronics. Thus the fiber optic networks can provide extremely high transmission capacity and reliability for massive devices with insignificant latency through flexible and ubiquitous wireless networks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>.</p>
</div>
</section>
<section id="S2.SS1.SSS6" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S2.SS1.SSS6.5.1.1" class="ltx_text">II-A</span>6 </span><span id="S2.SS1.SSS6.6.2" class="ltx_text ltx_font_bold">Green Communication</span>
</h4>

<div id="S2.SS1.SSS6.p1" class="ltx_para">
<p id="S2.SS1.SSS6.p1.1" class="ltx_p">It is significant for green communication to make good decisions for optimizing resource utilization and communication efficiency. In 6G communication scenarios, due to massive network traffic, innumerable network devices, and dynamic network environments, there exist more and more complex resource optimization problems, e.g., green communication optimization and offloading decision, that traditional mathematical programming techniques and optimization solutions cannot tackle. Recently, data science and AI-based optimization have also largely been used to solve problems related to resource optimization, task assignment in distributed systems, because of its advantages of data-driven decision, dynamic flexibility, and self-adjustment.</p>
</div>
</section>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS2.5.1.1" class="ltx_text">II-B</span> </span><span id="S2.SS2.6.2" class="ltx_text ltx_font_italic">Typical Use Scenarios</span>
</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">Compared with previous generations, the 5G service model has been transformed into a service-based architecture, and its user cases include: enhanced Mobile Broad Band (eMBB), massive Machine-Type-Communications (mMTC), and ultra-Reliable Low-Latency Communications (uRLLC). As shown in Fig. <a href="#S2.F2" title="Figure 2 ‣ II-B Typical Use Scenarios ‣ II Preliminaries and Overview ‣ Federated Learning for 6G Communications: Challenges, Methods, and Future Directions" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, driven by Industry 5.0 and deep learning technologies, 6G will provide the following new service types:</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<ul id="S2.I2" class="ltx_itemize">
<li id="S2.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I2.i1.p1" class="ltx_para">
<p id="S2.I2.i1.p1.1" class="ltx_p"><span id="S2.I2.i1.p1.1.1" class="ltx_text ltx_font_bold">New Media.</span> With the rapid development of wireless network communication technologies, it can be expected that the form of information interaction will gradually evolve from AR/VR to high fidelity extended reality (XR) interaction after 10 years, and even realizing wireless holographic communication <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>. Users can enjoy the new services brought by holographic communication and holographic display anytime and anywhere, such as virtual education, virtual tourism, virtual sports, virtual painting, virtual concerts, and other fully immersive holographic experiences.</p>
</div>
</li>
<li id="S2.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I2.i2.p1" class="ltx_para">
<p id="S2.I2.i2.p1.1" class="ltx_p"><span id="S2.I2.i2.p1.1.1" class="ltx_text ltx_font_bold">New Services.</span> According to ITU-T’s 6G communication technology white paper, beyond and high-precision teleport technology will provide users with a variety of new services <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>. Holographic teleport, quantum communication, visible light communication (VLC), and other communication technologies have subverted the traditional service model. For example, industries such as remote surgery <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>, cloud PLC <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>, and intelligent transportation systems <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> will be empowered by the new service model to provide users with better services. The goal of these new technologies is to provide high-precision services, deterministic service, and best-guaranteed services.</p>
</div>
</li>
<li id="S2.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I2.i3.p1" class="ltx_para">
<p id="S2.I2.i3.p1.1" class="ltx_p"><span id="S2.I2.i3.p1.1.1" class="ltx_text ltx_font_bold">New Infrastructure.</span> With the development of deep learning technologies, the 6G communication system has spawned many emerging infrastructures such as Integrated Terrestrial and Space <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>, federated learning networks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>, decentralized infrastructures <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>, and trustable infrastructure <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>. In particular, the FL network benefits from the high bandwidth and low latency of the 6G network, which has brought many emerging intelligent applications to cities, factories, and people.</p>
</div>
</li>
</ul>
</div>
<figure id="S2.F2" class="ltx_figure"><img src="/html/2006.02931/assets/x2.png" id="S2.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="259" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Key services and roadmap for 6G <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>, <a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>.</figcaption>
</figure>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS3.5.1.1" class="ltx_text">II-C</span> </span><span id="S2.SS3.6.2" class="ltx_text ltx_font_italic">Federated Learning</span>
</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">In this subsection, we introduce an FL-based distributed learning architecture in 6G. In this architecture, a large number of decentralized devices associated with different services can collaboratively train a shared global model (e.g., anomaly detection, recommendation system, next-word prediction, etc.) by using locally collected datasets.</p>
</div>
<div id="S2.SS3.p2" class="ltx_para">
<p id="S2.SS3.p2.16" class="ltx_p">As shown in Fig. <a href="#S2.F3" title="Figure 3 ‣ II-C Federated Learning ‣ II Preliminaries and Overview ‣ Federated Learning for 6G Communications: Challenges, Methods, and Future Directions" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, the procedure of FL-based architecture is divided into three phases: the initialization, the training, and the aggregation phase. In the initialization phase, a device will evaluate its service requests, needs, and connection conditions, and decides whether to register with the nearest cloud to join the training of the shared global model via a wired or wireless connection (e.g., 6G). Then, the cloud acting as task publisher will randomly select a subset of devices from the registered devices to participate in this round of training, and reject the remaining registered devices. The cloud will also send initialized or pre-trained global model <math id="S2.SS3.p2.1.m1.1" class="ltx_Math" alttext="{\omega_{t}}" display="inline"><semantics id="S2.SS3.p2.1.m1.1a"><msub id="S2.SS3.p2.1.m1.1.1" xref="S2.SS3.p2.1.m1.1.1.cmml"><mi id="S2.SS3.p2.1.m1.1.1.2" xref="S2.SS3.p2.1.m1.1.1.2.cmml">ω</mi><mi id="S2.SS3.p2.1.m1.1.1.3" xref="S2.SS3.p2.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.1.m1.1b"><apply id="S2.SS3.p2.1.m1.1.1.cmml" xref="S2.SS3.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS3.p2.1.m1.1.1.1.cmml" xref="S2.SS3.p2.1.m1.1.1">subscript</csymbol><ci id="S2.SS3.p2.1.m1.1.1.2.cmml" xref="S2.SS3.p2.1.m1.1.1.2">𝜔</ci><ci id="S2.SS3.p2.1.m1.1.1.3.cmml" xref="S2.SS3.p2.1.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.1.m1.1c">{\omega_{t}}</annotation></semantics></math> to each selected device (steps \scriptsize1⃝, \scriptsize2⃝). In the training phase, each selected device trains global model <math id="S2.SS3.p2.2.m2.1" class="ltx_Math" alttext="\omega_{t}^{k}\leftarrow{\omega_{t}}" display="inline"><semantics id="S2.SS3.p2.2.m2.1a"><mrow id="S2.SS3.p2.2.m2.1.1" xref="S2.SS3.p2.2.m2.1.1.cmml"><msubsup id="S2.SS3.p2.2.m2.1.1.2" xref="S2.SS3.p2.2.m2.1.1.2.cmml"><mi id="S2.SS3.p2.2.m2.1.1.2.2.2" xref="S2.SS3.p2.2.m2.1.1.2.2.2.cmml">ω</mi><mi id="S2.SS3.p2.2.m2.1.1.2.2.3" xref="S2.SS3.p2.2.m2.1.1.2.2.3.cmml">t</mi><mi id="S2.SS3.p2.2.m2.1.1.2.3" xref="S2.SS3.p2.2.m2.1.1.2.3.cmml">k</mi></msubsup><mo stretchy="false" id="S2.SS3.p2.2.m2.1.1.1" xref="S2.SS3.p2.2.m2.1.1.1.cmml">←</mo><msub id="S2.SS3.p2.2.m2.1.1.3" xref="S2.SS3.p2.2.m2.1.1.3.cmml"><mi id="S2.SS3.p2.2.m2.1.1.3.2" xref="S2.SS3.p2.2.m2.1.1.3.2.cmml">ω</mi><mi id="S2.SS3.p2.2.m2.1.1.3.3" xref="S2.SS3.p2.2.m2.1.1.3.3.cmml">t</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.2.m2.1b"><apply id="S2.SS3.p2.2.m2.1.1.cmml" xref="S2.SS3.p2.2.m2.1.1"><ci id="S2.SS3.p2.2.m2.1.1.1.cmml" xref="S2.SS3.p2.2.m2.1.1.1">←</ci><apply id="S2.SS3.p2.2.m2.1.1.2.cmml" xref="S2.SS3.p2.2.m2.1.1.2"><csymbol cd="ambiguous" id="S2.SS3.p2.2.m2.1.1.2.1.cmml" xref="S2.SS3.p2.2.m2.1.1.2">superscript</csymbol><apply id="S2.SS3.p2.2.m2.1.1.2.2.cmml" xref="S2.SS3.p2.2.m2.1.1.2"><csymbol cd="ambiguous" id="S2.SS3.p2.2.m2.1.1.2.2.1.cmml" xref="S2.SS3.p2.2.m2.1.1.2">subscript</csymbol><ci id="S2.SS3.p2.2.m2.1.1.2.2.2.cmml" xref="S2.SS3.p2.2.m2.1.1.2.2.2">𝜔</ci><ci id="S2.SS3.p2.2.m2.1.1.2.2.3.cmml" xref="S2.SS3.p2.2.m2.1.1.2.2.3">𝑡</ci></apply><ci id="S2.SS3.p2.2.m2.1.1.2.3.cmml" xref="S2.SS3.p2.2.m2.1.1.2.3">𝑘</ci></apply><apply id="S2.SS3.p2.2.m2.1.1.3.cmml" xref="S2.SS3.p2.2.m2.1.1.3"><csymbol cd="ambiguous" id="S2.SS3.p2.2.m2.1.1.3.1.cmml" xref="S2.SS3.p2.2.m2.1.1.3">subscript</csymbol><ci id="S2.SS3.p2.2.m2.1.1.3.2.cmml" xref="S2.SS3.p2.2.m2.1.1.3.2">𝜔</ci><ci id="S2.SS3.p2.2.m2.1.1.3.3.cmml" xref="S2.SS3.p2.2.m2.1.1.3.3">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.2.m2.1c">\omega_{t}^{k}\leftarrow{\omega_{t}}</annotation></semantics></math> by using local dataset to obtain the updated global model <math id="S2.SS3.p2.3.m3.1" class="ltx_Math" alttext="\omega_{t+1}^{k}" display="inline"><semantics id="S2.SS3.p2.3.m3.1a"><msubsup id="S2.SS3.p2.3.m3.1.1" xref="S2.SS3.p2.3.m3.1.1.cmml"><mi id="S2.SS3.p2.3.m3.1.1.2.2" xref="S2.SS3.p2.3.m3.1.1.2.2.cmml">ω</mi><mrow id="S2.SS3.p2.3.m3.1.1.2.3" xref="S2.SS3.p2.3.m3.1.1.2.3.cmml"><mi id="S2.SS3.p2.3.m3.1.1.2.3.2" xref="S2.SS3.p2.3.m3.1.1.2.3.2.cmml">t</mi><mo id="S2.SS3.p2.3.m3.1.1.2.3.1" xref="S2.SS3.p2.3.m3.1.1.2.3.1.cmml">+</mo><mn id="S2.SS3.p2.3.m3.1.1.2.3.3" xref="S2.SS3.p2.3.m3.1.1.2.3.3.cmml">1</mn></mrow><mi id="S2.SS3.p2.3.m3.1.1.3" xref="S2.SS3.p2.3.m3.1.1.3.cmml">k</mi></msubsup><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.3.m3.1b"><apply id="S2.SS3.p2.3.m3.1.1.cmml" xref="S2.SS3.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS3.p2.3.m3.1.1.1.cmml" xref="S2.SS3.p2.3.m3.1.1">superscript</csymbol><apply id="S2.SS3.p2.3.m3.1.1.2.cmml" xref="S2.SS3.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS3.p2.3.m3.1.1.2.1.cmml" xref="S2.SS3.p2.3.m3.1.1">subscript</csymbol><ci id="S2.SS3.p2.3.m3.1.1.2.2.cmml" xref="S2.SS3.p2.3.m3.1.1.2.2">𝜔</ci><apply id="S2.SS3.p2.3.m3.1.1.2.3.cmml" xref="S2.SS3.p2.3.m3.1.1.2.3"><plus id="S2.SS3.p2.3.m3.1.1.2.3.1.cmml" xref="S2.SS3.p2.3.m3.1.1.2.3.1"></plus><ci id="S2.SS3.p2.3.m3.1.1.2.3.2.cmml" xref="S2.SS3.p2.3.m3.1.1.2.3.2">𝑡</ci><cn type="integer" id="S2.SS3.p2.3.m3.1.1.2.3.3.cmml" xref="S2.SS3.p2.3.m3.1.1.2.3.3">1</cn></apply></apply><ci id="S2.SS3.p2.3.m3.1.1.3.cmml" xref="S2.SS3.p2.3.m3.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.3.m3.1c">\omega_{t+1}^{k}</annotation></semantics></math> in each iteration. In particular, for the <math id="S2.SS3.p2.4.m4.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S2.SS3.p2.4.m4.1a"><mi id="S2.SS3.p2.4.m4.1.1" xref="S2.SS3.p2.4.m4.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.4.m4.1b"><ci id="S2.SS3.p2.4.m4.1.1.cmml" xref="S2.SS3.p2.4.m4.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.4.m4.1c">k</annotation></semantics></math>-th device (<math id="S2.SS3.p2.5.m5.4" class="ltx_Math" alttext="k\in\{1,2,\ldots,K\}" display="inline"><semantics id="S2.SS3.p2.5.m5.4a"><mrow id="S2.SS3.p2.5.m5.4.5" xref="S2.SS3.p2.5.m5.4.5.cmml"><mi id="S2.SS3.p2.5.m5.4.5.2" xref="S2.SS3.p2.5.m5.4.5.2.cmml">k</mi><mo id="S2.SS3.p2.5.m5.4.5.1" xref="S2.SS3.p2.5.m5.4.5.1.cmml">∈</mo><mrow id="S2.SS3.p2.5.m5.4.5.3.2" xref="S2.SS3.p2.5.m5.4.5.3.1.cmml"><mo stretchy="false" id="S2.SS3.p2.5.m5.4.5.3.2.1" xref="S2.SS3.p2.5.m5.4.5.3.1.cmml">{</mo><mn id="S2.SS3.p2.5.m5.1.1" xref="S2.SS3.p2.5.m5.1.1.cmml">1</mn><mo id="S2.SS3.p2.5.m5.4.5.3.2.2" xref="S2.SS3.p2.5.m5.4.5.3.1.cmml">,</mo><mn id="S2.SS3.p2.5.m5.2.2" xref="S2.SS3.p2.5.m5.2.2.cmml">2</mn><mo id="S2.SS3.p2.5.m5.4.5.3.2.3" xref="S2.SS3.p2.5.m5.4.5.3.1.cmml">,</mo><mi mathvariant="normal" id="S2.SS3.p2.5.m5.3.3" xref="S2.SS3.p2.5.m5.3.3.cmml">…</mi><mo id="S2.SS3.p2.5.m5.4.5.3.2.4" xref="S2.SS3.p2.5.m5.4.5.3.1.cmml">,</mo><mi id="S2.SS3.p2.5.m5.4.4" xref="S2.SS3.p2.5.m5.4.4.cmml">K</mi><mo stretchy="false" id="S2.SS3.p2.5.m5.4.5.3.2.5" xref="S2.SS3.p2.5.m5.4.5.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.5.m5.4b"><apply id="S2.SS3.p2.5.m5.4.5.cmml" xref="S2.SS3.p2.5.m5.4.5"><in id="S2.SS3.p2.5.m5.4.5.1.cmml" xref="S2.SS3.p2.5.m5.4.5.1"></in><ci id="S2.SS3.p2.5.m5.4.5.2.cmml" xref="S2.SS3.p2.5.m5.4.5.2">𝑘</ci><set id="S2.SS3.p2.5.m5.4.5.3.1.cmml" xref="S2.SS3.p2.5.m5.4.5.3.2"><cn type="integer" id="S2.SS3.p2.5.m5.1.1.cmml" xref="S2.SS3.p2.5.m5.1.1">1</cn><cn type="integer" id="S2.SS3.p2.5.m5.2.2.cmml" xref="S2.SS3.p2.5.m5.2.2">2</cn><ci id="S2.SS3.p2.5.m5.3.3.cmml" xref="S2.SS3.p2.5.m5.3.3">…</ci><ci id="S2.SS3.p2.5.m5.4.4.cmml" xref="S2.SS3.p2.5.m5.4.4">𝐾</ci></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.5.m5.4c">k\in\{1,2,\ldots,K\}</annotation></semantics></math>), the loss function needs to be optimized as follows: <math id="S2.SS3.p2.6.m6.5" class="ltx_Math" alttext="\arg\mathop{\min}\limits_{\omega\in\mathbb{R}}{F_{k}}(\omega),{F_{k}}(\omega)=\frac{1}{{{D_{k}}}}\sum\nolimits_{i\in{D_{k}}}{{f_{i}}}(\omega)" display="inline"><semantics id="S2.SS3.p2.6.m6.5a"><mrow id="S2.SS3.p2.6.m6.5.5" xref="S2.SS3.p2.6.m6.5.5.cmml"><mrow id="S2.SS3.p2.6.m6.5.5.2.2" xref="S2.SS3.p2.6.m6.5.5.2.3.cmml"><mrow id="S2.SS3.p2.6.m6.4.4.1.1.1" xref="S2.SS3.p2.6.m6.4.4.1.1.1.cmml"><mi id="S2.SS3.p2.6.m6.4.4.1.1.1.2" xref="S2.SS3.p2.6.m6.4.4.1.1.1.2.cmml">arg</mi><mo lspace="0.167em" rspace="0em" id="S2.SS3.p2.6.m6.4.4.1.1.1.1" xref="S2.SS3.p2.6.m6.4.4.1.1.1.1.cmml">​</mo><mrow id="S2.SS3.p2.6.m6.4.4.1.1.1.3" xref="S2.SS3.p2.6.m6.4.4.1.1.1.3.cmml"><munder id="S2.SS3.p2.6.m6.4.4.1.1.1.3.1" xref="S2.SS3.p2.6.m6.4.4.1.1.1.3.1.cmml"><mo movablelimits="false" rspace="0.167em" id="S2.SS3.p2.6.m6.4.4.1.1.1.3.1.2" xref="S2.SS3.p2.6.m6.4.4.1.1.1.3.1.2.cmml">min</mo><mrow id="S2.SS3.p2.6.m6.4.4.1.1.1.3.1.3" xref="S2.SS3.p2.6.m6.4.4.1.1.1.3.1.3.cmml"><mi id="S2.SS3.p2.6.m6.4.4.1.1.1.3.1.3.2" xref="S2.SS3.p2.6.m6.4.4.1.1.1.3.1.3.2.cmml">ω</mi><mo id="S2.SS3.p2.6.m6.4.4.1.1.1.3.1.3.1" xref="S2.SS3.p2.6.m6.4.4.1.1.1.3.1.3.1.cmml">∈</mo><mi id="S2.SS3.p2.6.m6.4.4.1.1.1.3.1.3.3" xref="S2.SS3.p2.6.m6.4.4.1.1.1.3.1.3.3.cmml">ℝ</mi></mrow></munder><mrow id="S2.SS3.p2.6.m6.4.4.1.1.1.3.2" xref="S2.SS3.p2.6.m6.4.4.1.1.1.3.2.cmml"><msub id="S2.SS3.p2.6.m6.4.4.1.1.1.3.2.2" xref="S2.SS3.p2.6.m6.4.4.1.1.1.3.2.2.cmml"><mi id="S2.SS3.p2.6.m6.4.4.1.1.1.3.2.2.2" xref="S2.SS3.p2.6.m6.4.4.1.1.1.3.2.2.2.cmml">F</mi><mi id="S2.SS3.p2.6.m6.4.4.1.1.1.3.2.2.3" xref="S2.SS3.p2.6.m6.4.4.1.1.1.3.2.2.3.cmml">k</mi></msub><mo lspace="0em" rspace="0em" id="S2.SS3.p2.6.m6.4.4.1.1.1.3.2.1" xref="S2.SS3.p2.6.m6.4.4.1.1.1.3.2.1.cmml">​</mo><mrow id="S2.SS3.p2.6.m6.4.4.1.1.1.3.2.3.2" xref="S2.SS3.p2.6.m6.4.4.1.1.1.3.2.cmml"><mo stretchy="false" id="S2.SS3.p2.6.m6.4.4.1.1.1.3.2.3.2.1" xref="S2.SS3.p2.6.m6.4.4.1.1.1.3.2.cmml">(</mo><mi id="S2.SS3.p2.6.m6.1.1" xref="S2.SS3.p2.6.m6.1.1.cmml">ω</mi><mo stretchy="false" id="S2.SS3.p2.6.m6.4.4.1.1.1.3.2.3.2.2" xref="S2.SS3.p2.6.m6.4.4.1.1.1.3.2.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S2.SS3.p2.6.m6.5.5.2.2.3" xref="S2.SS3.p2.6.m6.5.5.2.3.cmml">,</mo><mrow id="S2.SS3.p2.6.m6.5.5.2.2.2" xref="S2.SS3.p2.6.m6.5.5.2.2.2.cmml"><msub id="S2.SS3.p2.6.m6.5.5.2.2.2.2" xref="S2.SS3.p2.6.m6.5.5.2.2.2.2.cmml"><mi id="S2.SS3.p2.6.m6.5.5.2.2.2.2.2" xref="S2.SS3.p2.6.m6.5.5.2.2.2.2.2.cmml">F</mi><mi id="S2.SS3.p2.6.m6.5.5.2.2.2.2.3" xref="S2.SS3.p2.6.m6.5.5.2.2.2.2.3.cmml">k</mi></msub><mo lspace="0em" rspace="0em" id="S2.SS3.p2.6.m6.5.5.2.2.2.1" xref="S2.SS3.p2.6.m6.5.5.2.2.2.1.cmml">​</mo><mrow id="S2.SS3.p2.6.m6.5.5.2.2.2.3.2" xref="S2.SS3.p2.6.m6.5.5.2.2.2.cmml"><mo stretchy="false" id="S2.SS3.p2.6.m6.5.5.2.2.2.3.2.1" xref="S2.SS3.p2.6.m6.5.5.2.2.2.cmml">(</mo><mi id="S2.SS3.p2.6.m6.2.2" xref="S2.SS3.p2.6.m6.2.2.cmml">ω</mi><mo stretchy="false" id="S2.SS3.p2.6.m6.5.5.2.2.2.3.2.2" xref="S2.SS3.p2.6.m6.5.5.2.2.2.cmml">)</mo></mrow></mrow></mrow><mo id="S2.SS3.p2.6.m6.5.5.3" xref="S2.SS3.p2.6.m6.5.5.3.cmml">=</mo><mrow id="S2.SS3.p2.6.m6.5.5.4" xref="S2.SS3.p2.6.m6.5.5.4.cmml"><mfrac id="S2.SS3.p2.6.m6.5.5.4.2" xref="S2.SS3.p2.6.m6.5.5.4.2.cmml"><mn id="S2.SS3.p2.6.m6.5.5.4.2.2" xref="S2.SS3.p2.6.m6.5.5.4.2.2.cmml">1</mn><msub id="S2.SS3.p2.6.m6.5.5.4.2.3" xref="S2.SS3.p2.6.m6.5.5.4.2.3.cmml"><mi id="S2.SS3.p2.6.m6.5.5.4.2.3.2" xref="S2.SS3.p2.6.m6.5.5.4.2.3.2.cmml">D</mi><mi id="S2.SS3.p2.6.m6.5.5.4.2.3.3" xref="S2.SS3.p2.6.m6.5.5.4.2.3.3.cmml">k</mi></msub></mfrac><mo lspace="0em" rspace="0em" id="S2.SS3.p2.6.m6.5.5.4.1" xref="S2.SS3.p2.6.m6.5.5.4.1.cmml">​</mo><mrow id="S2.SS3.p2.6.m6.5.5.4.3" xref="S2.SS3.p2.6.m6.5.5.4.3.cmml"><msub id="S2.SS3.p2.6.m6.5.5.4.3.1" xref="S2.SS3.p2.6.m6.5.5.4.3.1.cmml"><mo id="S2.SS3.p2.6.m6.5.5.4.3.1.2" xref="S2.SS3.p2.6.m6.5.5.4.3.1.2.cmml">∑</mo><mrow id="S2.SS3.p2.6.m6.5.5.4.3.1.3" xref="S2.SS3.p2.6.m6.5.5.4.3.1.3.cmml"><mi id="S2.SS3.p2.6.m6.5.5.4.3.1.3.2" xref="S2.SS3.p2.6.m6.5.5.4.3.1.3.2.cmml">i</mi><mo id="S2.SS3.p2.6.m6.5.5.4.3.1.3.1" xref="S2.SS3.p2.6.m6.5.5.4.3.1.3.1.cmml">∈</mo><msub id="S2.SS3.p2.6.m6.5.5.4.3.1.3.3" xref="S2.SS3.p2.6.m6.5.5.4.3.1.3.3.cmml"><mi id="S2.SS3.p2.6.m6.5.5.4.3.1.3.3.2" xref="S2.SS3.p2.6.m6.5.5.4.3.1.3.3.2.cmml">D</mi><mi id="S2.SS3.p2.6.m6.5.5.4.3.1.3.3.3" xref="S2.SS3.p2.6.m6.5.5.4.3.1.3.3.3.cmml">k</mi></msub></mrow></msub><mrow id="S2.SS3.p2.6.m6.5.5.4.3.2" xref="S2.SS3.p2.6.m6.5.5.4.3.2.cmml"><msub id="S2.SS3.p2.6.m6.5.5.4.3.2.2" xref="S2.SS3.p2.6.m6.5.5.4.3.2.2.cmml"><mi id="S2.SS3.p2.6.m6.5.5.4.3.2.2.2" xref="S2.SS3.p2.6.m6.5.5.4.3.2.2.2.cmml">f</mi><mi id="S2.SS3.p2.6.m6.5.5.4.3.2.2.3" xref="S2.SS3.p2.6.m6.5.5.4.3.2.2.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S2.SS3.p2.6.m6.5.5.4.3.2.1" xref="S2.SS3.p2.6.m6.5.5.4.3.2.1.cmml">​</mo><mrow id="S2.SS3.p2.6.m6.5.5.4.3.2.3.2" xref="S2.SS3.p2.6.m6.5.5.4.3.2.cmml"><mo stretchy="false" id="S2.SS3.p2.6.m6.5.5.4.3.2.3.2.1" xref="S2.SS3.p2.6.m6.5.5.4.3.2.cmml">(</mo><mi id="S2.SS3.p2.6.m6.3.3" xref="S2.SS3.p2.6.m6.3.3.cmml">ω</mi><mo stretchy="false" id="S2.SS3.p2.6.m6.5.5.4.3.2.3.2.2" xref="S2.SS3.p2.6.m6.5.5.4.3.2.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.6.m6.5b"><apply id="S2.SS3.p2.6.m6.5.5.cmml" xref="S2.SS3.p2.6.m6.5.5"><eq id="S2.SS3.p2.6.m6.5.5.3.cmml" xref="S2.SS3.p2.6.m6.5.5.3"></eq><list id="S2.SS3.p2.6.m6.5.5.2.3.cmml" xref="S2.SS3.p2.6.m6.5.5.2.2"><apply id="S2.SS3.p2.6.m6.4.4.1.1.1.cmml" xref="S2.SS3.p2.6.m6.4.4.1.1.1"><times id="S2.SS3.p2.6.m6.4.4.1.1.1.1.cmml" xref="S2.SS3.p2.6.m6.4.4.1.1.1.1"></times><arg id="S2.SS3.p2.6.m6.4.4.1.1.1.2.cmml" xref="S2.SS3.p2.6.m6.4.4.1.1.1.2"></arg><apply id="S2.SS3.p2.6.m6.4.4.1.1.1.3.cmml" xref="S2.SS3.p2.6.m6.4.4.1.1.1.3"><apply id="S2.SS3.p2.6.m6.4.4.1.1.1.3.1.cmml" xref="S2.SS3.p2.6.m6.4.4.1.1.1.3.1"><csymbol cd="ambiguous" id="S2.SS3.p2.6.m6.4.4.1.1.1.3.1.1.cmml" xref="S2.SS3.p2.6.m6.4.4.1.1.1.3.1">subscript</csymbol><min id="S2.SS3.p2.6.m6.4.4.1.1.1.3.1.2.cmml" xref="S2.SS3.p2.6.m6.4.4.1.1.1.3.1.2"></min><apply id="S2.SS3.p2.6.m6.4.4.1.1.1.3.1.3.cmml" xref="S2.SS3.p2.6.m6.4.4.1.1.1.3.1.3"><in id="S2.SS3.p2.6.m6.4.4.1.1.1.3.1.3.1.cmml" xref="S2.SS3.p2.6.m6.4.4.1.1.1.3.1.3.1"></in><ci id="S2.SS3.p2.6.m6.4.4.1.1.1.3.1.3.2.cmml" xref="S2.SS3.p2.6.m6.4.4.1.1.1.3.1.3.2">𝜔</ci><ci id="S2.SS3.p2.6.m6.4.4.1.1.1.3.1.3.3.cmml" xref="S2.SS3.p2.6.m6.4.4.1.1.1.3.1.3.3">ℝ</ci></apply></apply><apply id="S2.SS3.p2.6.m6.4.4.1.1.1.3.2.cmml" xref="S2.SS3.p2.6.m6.4.4.1.1.1.3.2"><times id="S2.SS3.p2.6.m6.4.4.1.1.1.3.2.1.cmml" xref="S2.SS3.p2.6.m6.4.4.1.1.1.3.2.1"></times><apply id="S2.SS3.p2.6.m6.4.4.1.1.1.3.2.2.cmml" xref="S2.SS3.p2.6.m6.4.4.1.1.1.3.2.2"><csymbol cd="ambiguous" id="S2.SS3.p2.6.m6.4.4.1.1.1.3.2.2.1.cmml" xref="S2.SS3.p2.6.m6.4.4.1.1.1.3.2.2">subscript</csymbol><ci id="S2.SS3.p2.6.m6.4.4.1.1.1.3.2.2.2.cmml" xref="S2.SS3.p2.6.m6.4.4.1.1.1.3.2.2.2">𝐹</ci><ci id="S2.SS3.p2.6.m6.4.4.1.1.1.3.2.2.3.cmml" xref="S2.SS3.p2.6.m6.4.4.1.1.1.3.2.2.3">𝑘</ci></apply><ci id="S2.SS3.p2.6.m6.1.1.cmml" xref="S2.SS3.p2.6.m6.1.1">𝜔</ci></apply></apply></apply><apply id="S2.SS3.p2.6.m6.5.5.2.2.2.cmml" xref="S2.SS3.p2.6.m6.5.5.2.2.2"><times id="S2.SS3.p2.6.m6.5.5.2.2.2.1.cmml" xref="S2.SS3.p2.6.m6.5.5.2.2.2.1"></times><apply id="S2.SS3.p2.6.m6.5.5.2.2.2.2.cmml" xref="S2.SS3.p2.6.m6.5.5.2.2.2.2"><csymbol cd="ambiguous" id="S2.SS3.p2.6.m6.5.5.2.2.2.2.1.cmml" xref="S2.SS3.p2.6.m6.5.5.2.2.2.2">subscript</csymbol><ci id="S2.SS3.p2.6.m6.5.5.2.2.2.2.2.cmml" xref="S2.SS3.p2.6.m6.5.5.2.2.2.2.2">𝐹</ci><ci id="S2.SS3.p2.6.m6.5.5.2.2.2.2.3.cmml" xref="S2.SS3.p2.6.m6.5.5.2.2.2.2.3">𝑘</ci></apply><ci id="S2.SS3.p2.6.m6.2.2.cmml" xref="S2.SS3.p2.6.m6.2.2">𝜔</ci></apply></list><apply id="S2.SS3.p2.6.m6.5.5.4.cmml" xref="S2.SS3.p2.6.m6.5.5.4"><times id="S2.SS3.p2.6.m6.5.5.4.1.cmml" xref="S2.SS3.p2.6.m6.5.5.4.1"></times><apply id="S2.SS3.p2.6.m6.5.5.4.2.cmml" xref="S2.SS3.p2.6.m6.5.5.4.2"><divide id="S2.SS3.p2.6.m6.5.5.4.2.1.cmml" xref="S2.SS3.p2.6.m6.5.5.4.2"></divide><cn type="integer" id="S2.SS3.p2.6.m6.5.5.4.2.2.cmml" xref="S2.SS3.p2.6.m6.5.5.4.2.2">1</cn><apply id="S2.SS3.p2.6.m6.5.5.4.2.3.cmml" xref="S2.SS3.p2.6.m6.5.5.4.2.3"><csymbol cd="ambiguous" id="S2.SS3.p2.6.m6.5.5.4.2.3.1.cmml" xref="S2.SS3.p2.6.m6.5.5.4.2.3">subscript</csymbol><ci id="S2.SS3.p2.6.m6.5.5.4.2.3.2.cmml" xref="S2.SS3.p2.6.m6.5.5.4.2.3.2">𝐷</ci><ci id="S2.SS3.p2.6.m6.5.5.4.2.3.3.cmml" xref="S2.SS3.p2.6.m6.5.5.4.2.3.3">𝑘</ci></apply></apply><apply id="S2.SS3.p2.6.m6.5.5.4.3.cmml" xref="S2.SS3.p2.6.m6.5.5.4.3"><apply id="S2.SS3.p2.6.m6.5.5.4.3.1.cmml" xref="S2.SS3.p2.6.m6.5.5.4.3.1"><csymbol cd="ambiguous" id="S2.SS3.p2.6.m6.5.5.4.3.1.1.cmml" xref="S2.SS3.p2.6.m6.5.5.4.3.1">subscript</csymbol><sum id="S2.SS3.p2.6.m6.5.5.4.3.1.2.cmml" xref="S2.SS3.p2.6.m6.5.5.4.3.1.2"></sum><apply id="S2.SS3.p2.6.m6.5.5.4.3.1.3.cmml" xref="S2.SS3.p2.6.m6.5.5.4.3.1.3"><in id="S2.SS3.p2.6.m6.5.5.4.3.1.3.1.cmml" xref="S2.SS3.p2.6.m6.5.5.4.3.1.3.1"></in><ci id="S2.SS3.p2.6.m6.5.5.4.3.1.3.2.cmml" xref="S2.SS3.p2.6.m6.5.5.4.3.1.3.2">𝑖</ci><apply id="S2.SS3.p2.6.m6.5.5.4.3.1.3.3.cmml" xref="S2.SS3.p2.6.m6.5.5.4.3.1.3.3"><csymbol cd="ambiguous" id="S2.SS3.p2.6.m6.5.5.4.3.1.3.3.1.cmml" xref="S2.SS3.p2.6.m6.5.5.4.3.1.3.3">subscript</csymbol><ci id="S2.SS3.p2.6.m6.5.5.4.3.1.3.3.2.cmml" xref="S2.SS3.p2.6.m6.5.5.4.3.1.3.3.2">𝐷</ci><ci id="S2.SS3.p2.6.m6.5.5.4.3.1.3.3.3.cmml" xref="S2.SS3.p2.6.m6.5.5.4.3.1.3.3.3">𝑘</ci></apply></apply></apply><apply id="S2.SS3.p2.6.m6.5.5.4.3.2.cmml" xref="S2.SS3.p2.6.m6.5.5.4.3.2"><times id="S2.SS3.p2.6.m6.5.5.4.3.2.1.cmml" xref="S2.SS3.p2.6.m6.5.5.4.3.2.1"></times><apply id="S2.SS3.p2.6.m6.5.5.4.3.2.2.cmml" xref="S2.SS3.p2.6.m6.5.5.4.3.2.2"><csymbol cd="ambiguous" id="S2.SS3.p2.6.m6.5.5.4.3.2.2.1.cmml" xref="S2.SS3.p2.6.m6.5.5.4.3.2.2">subscript</csymbol><ci id="S2.SS3.p2.6.m6.5.5.4.3.2.2.2.cmml" xref="S2.SS3.p2.6.m6.5.5.4.3.2.2.2">𝑓</ci><ci id="S2.SS3.p2.6.m6.5.5.4.3.2.2.3.cmml" xref="S2.SS3.p2.6.m6.5.5.4.3.2.2.3">𝑖</ci></apply><ci id="S2.SS3.p2.6.m6.3.3.cmml" xref="S2.SS3.p2.6.m6.3.3">𝜔</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.6.m6.5c">\arg\mathop{\min}\limits_{\omega\in\mathbb{R}}{F_{k}}(\omega),{F_{k}}(\omega)=\frac{1}{{{D_{k}}}}\sum\nolimits_{i\in{D_{k}}}{{f_{i}}}(\omega)</annotation></semantics></math>, where <math id="S2.SS3.p2.7.m7.1" class="ltx_Math" alttext="D_{k}" display="inline"><semantics id="S2.SS3.p2.7.m7.1a"><msub id="S2.SS3.p2.7.m7.1.1" xref="S2.SS3.p2.7.m7.1.1.cmml"><mi id="S2.SS3.p2.7.m7.1.1.2" xref="S2.SS3.p2.7.m7.1.1.2.cmml">D</mi><mi id="S2.SS3.p2.7.m7.1.1.3" xref="S2.SS3.p2.7.m7.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.7.m7.1b"><apply id="S2.SS3.p2.7.m7.1.1.cmml" xref="S2.SS3.p2.7.m7.1.1"><csymbol cd="ambiguous" id="S2.SS3.p2.7.m7.1.1.1.cmml" xref="S2.SS3.p2.7.m7.1.1">subscript</csymbol><ci id="S2.SS3.p2.7.m7.1.1.2.cmml" xref="S2.SS3.p2.7.m7.1.1.2">𝐷</ci><ci id="S2.SS3.p2.7.m7.1.1.3.cmml" xref="S2.SS3.p2.7.m7.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.7.m7.1c">D_{k}</annotation></semantics></math> denotes the size of local dataset that contains input-output vector pairs <math id="S2.SS3.p2.8.m8.2" class="ltx_Math" alttext="(x_{i},y_{i})" display="inline"><semantics id="S2.SS3.p2.8.m8.2a"><mrow id="S2.SS3.p2.8.m8.2.2.2" xref="S2.SS3.p2.8.m8.2.2.3.cmml"><mo stretchy="false" id="S2.SS3.p2.8.m8.2.2.2.3" xref="S2.SS3.p2.8.m8.2.2.3.cmml">(</mo><msub id="S2.SS3.p2.8.m8.1.1.1.1" xref="S2.SS3.p2.8.m8.1.1.1.1.cmml"><mi id="S2.SS3.p2.8.m8.1.1.1.1.2" xref="S2.SS3.p2.8.m8.1.1.1.1.2.cmml">x</mi><mi id="S2.SS3.p2.8.m8.1.1.1.1.3" xref="S2.SS3.p2.8.m8.1.1.1.1.3.cmml">i</mi></msub><mo id="S2.SS3.p2.8.m8.2.2.2.4" xref="S2.SS3.p2.8.m8.2.2.3.cmml">,</mo><msub id="S2.SS3.p2.8.m8.2.2.2.2" xref="S2.SS3.p2.8.m8.2.2.2.2.cmml"><mi id="S2.SS3.p2.8.m8.2.2.2.2.2" xref="S2.SS3.p2.8.m8.2.2.2.2.2.cmml">y</mi><mi id="S2.SS3.p2.8.m8.2.2.2.2.3" xref="S2.SS3.p2.8.m8.2.2.2.2.3.cmml">i</mi></msub><mo stretchy="false" id="S2.SS3.p2.8.m8.2.2.2.5" xref="S2.SS3.p2.8.m8.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.8.m8.2b"><interval closure="open" id="S2.SS3.p2.8.m8.2.2.3.cmml" xref="S2.SS3.p2.8.m8.2.2.2"><apply id="S2.SS3.p2.8.m8.1.1.1.1.cmml" xref="S2.SS3.p2.8.m8.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS3.p2.8.m8.1.1.1.1.1.cmml" xref="S2.SS3.p2.8.m8.1.1.1.1">subscript</csymbol><ci id="S2.SS3.p2.8.m8.1.1.1.1.2.cmml" xref="S2.SS3.p2.8.m8.1.1.1.1.2">𝑥</ci><ci id="S2.SS3.p2.8.m8.1.1.1.1.3.cmml" xref="S2.SS3.p2.8.m8.1.1.1.1.3">𝑖</ci></apply><apply id="S2.SS3.p2.8.m8.2.2.2.2.cmml" xref="S2.SS3.p2.8.m8.2.2.2.2"><csymbol cd="ambiguous" id="S2.SS3.p2.8.m8.2.2.2.2.1.cmml" xref="S2.SS3.p2.8.m8.2.2.2.2">subscript</csymbol><ci id="S2.SS3.p2.8.m8.2.2.2.2.2.cmml" xref="S2.SS3.p2.8.m8.2.2.2.2.2">𝑦</ci><ci id="S2.SS3.p2.8.m8.2.2.2.2.3.cmml" xref="S2.SS3.p2.8.m8.2.2.2.2.3">𝑖</ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.8.m8.2c">(x_{i},y_{i})</annotation></semantics></math>, <math id="S2.SS3.p2.9.m9.2" class="ltx_Math" alttext="{x_{i}},{y_{i}}\in\mathbb{R}" display="inline"><semantics id="S2.SS3.p2.9.m9.2a"><mrow id="S2.SS3.p2.9.m9.2.2" xref="S2.SS3.p2.9.m9.2.2.cmml"><mrow id="S2.SS3.p2.9.m9.2.2.2.2" xref="S2.SS3.p2.9.m9.2.2.2.3.cmml"><msub id="S2.SS3.p2.9.m9.1.1.1.1.1" xref="S2.SS3.p2.9.m9.1.1.1.1.1.cmml"><mi id="S2.SS3.p2.9.m9.1.1.1.1.1.2" xref="S2.SS3.p2.9.m9.1.1.1.1.1.2.cmml">x</mi><mi id="S2.SS3.p2.9.m9.1.1.1.1.1.3" xref="S2.SS3.p2.9.m9.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S2.SS3.p2.9.m9.2.2.2.2.3" xref="S2.SS3.p2.9.m9.2.2.2.3.cmml">,</mo><msub id="S2.SS3.p2.9.m9.2.2.2.2.2" xref="S2.SS3.p2.9.m9.2.2.2.2.2.cmml"><mi id="S2.SS3.p2.9.m9.2.2.2.2.2.2" xref="S2.SS3.p2.9.m9.2.2.2.2.2.2.cmml">y</mi><mi id="S2.SS3.p2.9.m9.2.2.2.2.2.3" xref="S2.SS3.p2.9.m9.2.2.2.2.2.3.cmml">i</mi></msub></mrow><mo id="S2.SS3.p2.9.m9.2.2.3" xref="S2.SS3.p2.9.m9.2.2.3.cmml">∈</mo><mi id="S2.SS3.p2.9.m9.2.2.4" xref="S2.SS3.p2.9.m9.2.2.4.cmml">ℝ</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.9.m9.2b"><apply id="S2.SS3.p2.9.m9.2.2.cmml" xref="S2.SS3.p2.9.m9.2.2"><in id="S2.SS3.p2.9.m9.2.2.3.cmml" xref="S2.SS3.p2.9.m9.2.2.3"></in><list id="S2.SS3.p2.9.m9.2.2.2.3.cmml" xref="S2.SS3.p2.9.m9.2.2.2.2"><apply id="S2.SS3.p2.9.m9.1.1.1.1.1.cmml" xref="S2.SS3.p2.9.m9.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS3.p2.9.m9.1.1.1.1.1.1.cmml" xref="S2.SS3.p2.9.m9.1.1.1.1.1">subscript</csymbol><ci id="S2.SS3.p2.9.m9.1.1.1.1.1.2.cmml" xref="S2.SS3.p2.9.m9.1.1.1.1.1.2">𝑥</ci><ci id="S2.SS3.p2.9.m9.1.1.1.1.1.3.cmml" xref="S2.SS3.p2.9.m9.1.1.1.1.1.3">𝑖</ci></apply><apply id="S2.SS3.p2.9.m9.2.2.2.2.2.cmml" xref="S2.SS3.p2.9.m9.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.SS3.p2.9.m9.2.2.2.2.2.1.cmml" xref="S2.SS3.p2.9.m9.2.2.2.2.2">subscript</csymbol><ci id="S2.SS3.p2.9.m9.2.2.2.2.2.2.cmml" xref="S2.SS3.p2.9.m9.2.2.2.2.2.2">𝑦</ci><ci id="S2.SS3.p2.9.m9.2.2.2.2.2.3.cmml" xref="S2.SS3.p2.9.m9.2.2.2.2.2.3">𝑖</ci></apply></list><ci id="S2.SS3.p2.9.m9.2.2.4.cmml" xref="S2.SS3.p2.9.m9.2.2.4">ℝ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.9.m9.2c">{x_{i}},{y_{i}}\in\mathbb{R}</annotation></semantics></math>, <math id="S2.SS3.p2.10.m10.1" class="ltx_Math" alttext="\omega" display="inline"><semantics id="S2.SS3.p2.10.m10.1a"><mi id="S2.SS3.p2.10.m10.1.1" xref="S2.SS3.p2.10.m10.1.1.cmml">ω</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.10.m10.1b"><ci id="S2.SS3.p2.10.m10.1.1.cmml" xref="S2.SS3.p2.10.m10.1.1">𝜔</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.10.m10.1c">\omega</annotation></semantics></math> is local model parameter, and <math id="S2.SS3.p2.11.m11.1" class="ltx_Math" alttext="{f_{i}}(\omega)" display="inline"><semantics id="S2.SS3.p2.11.m11.1a"><mrow id="S2.SS3.p2.11.m11.1.2" xref="S2.SS3.p2.11.m11.1.2.cmml"><msub id="S2.SS3.p2.11.m11.1.2.2" xref="S2.SS3.p2.11.m11.1.2.2.cmml"><mi id="S2.SS3.p2.11.m11.1.2.2.2" xref="S2.SS3.p2.11.m11.1.2.2.2.cmml">f</mi><mi id="S2.SS3.p2.11.m11.1.2.2.3" xref="S2.SS3.p2.11.m11.1.2.2.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S2.SS3.p2.11.m11.1.2.1" xref="S2.SS3.p2.11.m11.1.2.1.cmml">​</mo><mrow id="S2.SS3.p2.11.m11.1.2.3.2" xref="S2.SS3.p2.11.m11.1.2.cmml"><mo stretchy="false" id="S2.SS3.p2.11.m11.1.2.3.2.1" xref="S2.SS3.p2.11.m11.1.2.cmml">(</mo><mi id="S2.SS3.p2.11.m11.1.1" xref="S2.SS3.p2.11.m11.1.1.cmml">ω</mi><mo stretchy="false" id="S2.SS3.p2.11.m11.1.2.3.2.2" xref="S2.SS3.p2.11.m11.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.11.m11.1b"><apply id="S2.SS3.p2.11.m11.1.2.cmml" xref="S2.SS3.p2.11.m11.1.2"><times id="S2.SS3.p2.11.m11.1.2.1.cmml" xref="S2.SS3.p2.11.m11.1.2.1"></times><apply id="S2.SS3.p2.11.m11.1.2.2.cmml" xref="S2.SS3.p2.11.m11.1.2.2"><csymbol cd="ambiguous" id="S2.SS3.p2.11.m11.1.2.2.1.cmml" xref="S2.SS3.p2.11.m11.1.2.2">subscript</csymbol><ci id="S2.SS3.p2.11.m11.1.2.2.2.cmml" xref="S2.SS3.p2.11.m11.1.2.2.2">𝑓</ci><ci id="S2.SS3.p2.11.m11.1.2.2.3.cmml" xref="S2.SS3.p2.11.m11.1.2.2.3">𝑖</ci></apply><ci id="S2.SS3.p2.11.m11.1.1.cmml" xref="S2.SS3.p2.11.m11.1.1">𝜔</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.11.m11.1c">{f_{i}}(\omega)</annotation></semantics></math> is a local loss function (e.g., <math id="S2.SS3.p2.12.m12.2" class="ltx_Math" alttext="{f_{i}}(\omega)=\frac{1}{2}({x_{i}}^{T}\omega-{y_{i}})" display="inline"><semantics id="S2.SS3.p2.12.m12.2a"><mrow id="S2.SS3.p2.12.m12.2.2" xref="S2.SS3.p2.12.m12.2.2.cmml"><mrow id="S2.SS3.p2.12.m12.2.2.3" xref="S2.SS3.p2.12.m12.2.2.3.cmml"><msub id="S2.SS3.p2.12.m12.2.2.3.2" xref="S2.SS3.p2.12.m12.2.2.3.2.cmml"><mi id="S2.SS3.p2.12.m12.2.2.3.2.2" xref="S2.SS3.p2.12.m12.2.2.3.2.2.cmml">f</mi><mi id="S2.SS3.p2.12.m12.2.2.3.2.3" xref="S2.SS3.p2.12.m12.2.2.3.2.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S2.SS3.p2.12.m12.2.2.3.1" xref="S2.SS3.p2.12.m12.2.2.3.1.cmml">​</mo><mrow id="S2.SS3.p2.12.m12.2.2.3.3.2" xref="S2.SS3.p2.12.m12.2.2.3.cmml"><mo stretchy="false" id="S2.SS3.p2.12.m12.2.2.3.3.2.1" xref="S2.SS3.p2.12.m12.2.2.3.cmml">(</mo><mi id="S2.SS3.p2.12.m12.1.1" xref="S2.SS3.p2.12.m12.1.1.cmml">ω</mi><mo stretchy="false" id="S2.SS3.p2.12.m12.2.2.3.3.2.2" xref="S2.SS3.p2.12.m12.2.2.3.cmml">)</mo></mrow></mrow><mo id="S2.SS3.p2.12.m12.2.2.2" xref="S2.SS3.p2.12.m12.2.2.2.cmml">=</mo><mrow id="S2.SS3.p2.12.m12.2.2.1" xref="S2.SS3.p2.12.m12.2.2.1.cmml"><mfrac id="S2.SS3.p2.12.m12.2.2.1.3" xref="S2.SS3.p2.12.m12.2.2.1.3.cmml"><mn id="S2.SS3.p2.12.m12.2.2.1.3.2" xref="S2.SS3.p2.12.m12.2.2.1.3.2.cmml">1</mn><mn id="S2.SS3.p2.12.m12.2.2.1.3.3" xref="S2.SS3.p2.12.m12.2.2.1.3.3.cmml">2</mn></mfrac><mo lspace="0em" rspace="0em" id="S2.SS3.p2.12.m12.2.2.1.2" xref="S2.SS3.p2.12.m12.2.2.1.2.cmml">​</mo><mrow id="S2.SS3.p2.12.m12.2.2.1.1.1" xref="S2.SS3.p2.12.m12.2.2.1.1.1.1.cmml"><mo stretchy="false" id="S2.SS3.p2.12.m12.2.2.1.1.1.2" xref="S2.SS3.p2.12.m12.2.2.1.1.1.1.cmml">(</mo><mrow id="S2.SS3.p2.12.m12.2.2.1.1.1.1" xref="S2.SS3.p2.12.m12.2.2.1.1.1.1.cmml"><mrow id="S2.SS3.p2.12.m12.2.2.1.1.1.1.2" xref="S2.SS3.p2.12.m12.2.2.1.1.1.1.2.cmml"><mmultiscripts id="S2.SS3.p2.12.m12.2.2.1.1.1.1.2.2" xref="S2.SS3.p2.12.m12.2.2.1.1.1.1.2.2.cmml"><mi id="S2.SS3.p2.12.m12.2.2.1.1.1.1.2.2.2.2" xref="S2.SS3.p2.12.m12.2.2.1.1.1.1.2.2.2.2.cmml">x</mi><mi id="S2.SS3.p2.12.m12.2.2.1.1.1.1.2.2.2.3" xref="S2.SS3.p2.12.m12.2.2.1.1.1.1.2.2.2.3.cmml">i</mi><mrow id="S2.SS3.p2.12.m12.2.2.1.1.1.1.2.2a" xref="S2.SS3.p2.12.m12.2.2.1.1.1.1.2.2.cmml"></mrow><mrow id="S2.SS3.p2.12.m12.2.2.1.1.1.1.2.2b" xref="S2.SS3.p2.12.m12.2.2.1.1.1.1.2.2.cmml"></mrow><mi id="S2.SS3.p2.12.m12.2.2.1.1.1.1.2.2.3" xref="S2.SS3.p2.12.m12.2.2.1.1.1.1.2.2.3.cmml">T</mi></mmultiscripts><mo lspace="0em" rspace="0em" id="S2.SS3.p2.12.m12.2.2.1.1.1.1.2.1" xref="S2.SS3.p2.12.m12.2.2.1.1.1.1.2.1.cmml">​</mo><mi id="S2.SS3.p2.12.m12.2.2.1.1.1.1.2.3" xref="S2.SS3.p2.12.m12.2.2.1.1.1.1.2.3.cmml">ω</mi></mrow><mo id="S2.SS3.p2.12.m12.2.2.1.1.1.1.1" xref="S2.SS3.p2.12.m12.2.2.1.1.1.1.1.cmml">−</mo><msub id="S2.SS3.p2.12.m12.2.2.1.1.1.1.3" xref="S2.SS3.p2.12.m12.2.2.1.1.1.1.3.cmml"><mi id="S2.SS3.p2.12.m12.2.2.1.1.1.1.3.2" xref="S2.SS3.p2.12.m12.2.2.1.1.1.1.3.2.cmml">y</mi><mi id="S2.SS3.p2.12.m12.2.2.1.1.1.1.3.3" xref="S2.SS3.p2.12.m12.2.2.1.1.1.1.3.3.cmml">i</mi></msub></mrow><mo stretchy="false" id="S2.SS3.p2.12.m12.2.2.1.1.1.3" xref="S2.SS3.p2.12.m12.2.2.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.12.m12.2b"><apply id="S2.SS3.p2.12.m12.2.2.cmml" xref="S2.SS3.p2.12.m12.2.2"><eq id="S2.SS3.p2.12.m12.2.2.2.cmml" xref="S2.SS3.p2.12.m12.2.2.2"></eq><apply id="S2.SS3.p2.12.m12.2.2.3.cmml" xref="S2.SS3.p2.12.m12.2.2.3"><times id="S2.SS3.p2.12.m12.2.2.3.1.cmml" xref="S2.SS3.p2.12.m12.2.2.3.1"></times><apply id="S2.SS3.p2.12.m12.2.2.3.2.cmml" xref="S2.SS3.p2.12.m12.2.2.3.2"><csymbol cd="ambiguous" id="S2.SS3.p2.12.m12.2.2.3.2.1.cmml" xref="S2.SS3.p2.12.m12.2.2.3.2">subscript</csymbol><ci id="S2.SS3.p2.12.m12.2.2.3.2.2.cmml" xref="S2.SS3.p2.12.m12.2.2.3.2.2">𝑓</ci><ci id="S2.SS3.p2.12.m12.2.2.3.2.3.cmml" xref="S2.SS3.p2.12.m12.2.2.3.2.3">𝑖</ci></apply><ci id="S2.SS3.p2.12.m12.1.1.cmml" xref="S2.SS3.p2.12.m12.1.1">𝜔</ci></apply><apply id="S2.SS3.p2.12.m12.2.2.1.cmml" xref="S2.SS3.p2.12.m12.2.2.1"><times id="S2.SS3.p2.12.m12.2.2.1.2.cmml" xref="S2.SS3.p2.12.m12.2.2.1.2"></times><apply id="S2.SS3.p2.12.m12.2.2.1.3.cmml" xref="S2.SS3.p2.12.m12.2.2.1.3"><divide id="S2.SS3.p2.12.m12.2.2.1.3.1.cmml" xref="S2.SS3.p2.12.m12.2.2.1.3"></divide><cn type="integer" id="S2.SS3.p2.12.m12.2.2.1.3.2.cmml" xref="S2.SS3.p2.12.m12.2.2.1.3.2">1</cn><cn type="integer" id="S2.SS3.p2.12.m12.2.2.1.3.3.cmml" xref="S2.SS3.p2.12.m12.2.2.1.3.3">2</cn></apply><apply id="S2.SS3.p2.12.m12.2.2.1.1.1.1.cmml" xref="S2.SS3.p2.12.m12.2.2.1.1.1"><minus id="S2.SS3.p2.12.m12.2.2.1.1.1.1.1.cmml" xref="S2.SS3.p2.12.m12.2.2.1.1.1.1.1"></minus><apply id="S2.SS3.p2.12.m12.2.2.1.1.1.1.2.cmml" xref="S2.SS3.p2.12.m12.2.2.1.1.1.1.2"><times id="S2.SS3.p2.12.m12.2.2.1.1.1.1.2.1.cmml" xref="S2.SS3.p2.12.m12.2.2.1.1.1.1.2.1"></times><apply id="S2.SS3.p2.12.m12.2.2.1.1.1.1.2.2.cmml" xref="S2.SS3.p2.12.m12.2.2.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S2.SS3.p2.12.m12.2.2.1.1.1.1.2.2.1.cmml" xref="S2.SS3.p2.12.m12.2.2.1.1.1.1.2.2">superscript</csymbol><apply id="S2.SS3.p2.12.m12.2.2.1.1.1.1.2.2.2.cmml" xref="S2.SS3.p2.12.m12.2.2.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S2.SS3.p2.12.m12.2.2.1.1.1.1.2.2.2.1.cmml" xref="S2.SS3.p2.12.m12.2.2.1.1.1.1.2.2">subscript</csymbol><ci id="S2.SS3.p2.12.m12.2.2.1.1.1.1.2.2.2.2.cmml" xref="S2.SS3.p2.12.m12.2.2.1.1.1.1.2.2.2.2">𝑥</ci><ci id="S2.SS3.p2.12.m12.2.2.1.1.1.1.2.2.2.3.cmml" xref="S2.SS3.p2.12.m12.2.2.1.1.1.1.2.2.2.3">𝑖</ci></apply><ci id="S2.SS3.p2.12.m12.2.2.1.1.1.1.2.2.3.cmml" xref="S2.SS3.p2.12.m12.2.2.1.1.1.1.2.2.3">𝑇</ci></apply><ci id="S2.SS3.p2.12.m12.2.2.1.1.1.1.2.3.cmml" xref="S2.SS3.p2.12.m12.2.2.1.1.1.1.2.3">𝜔</ci></apply><apply id="S2.SS3.p2.12.m12.2.2.1.1.1.1.3.cmml" xref="S2.SS3.p2.12.m12.2.2.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.SS3.p2.12.m12.2.2.1.1.1.1.3.1.cmml" xref="S2.SS3.p2.12.m12.2.2.1.1.1.1.3">subscript</csymbol><ci id="S2.SS3.p2.12.m12.2.2.1.1.1.1.3.2.cmml" xref="S2.SS3.p2.12.m12.2.2.1.1.1.1.3.2">𝑦</ci><ci id="S2.SS3.p2.12.m12.2.2.1.1.1.1.3.3.cmml" xref="S2.SS3.p2.12.m12.2.2.1.1.1.1.3.3">𝑖</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.12.m12.2c">{f_{i}}(\omega)=\frac{1}{2}({x_{i}}^{T}\omega-{y_{i}})</annotation></semantics></math>). Each selected device uploads the model updates to the cloud (steps \scriptsize3⃝, \scriptsize4⃝, \scriptsize5⃝). In the aggregation phase, the cloud receives model updates of all selected devices for aggregation to obtain a new global model <math id="S2.SS3.p2.13.m13.1" class="ltx_Math" alttext="\omega_{t+1}" display="inline"><semantics id="S2.SS3.p2.13.m13.1a"><msub id="S2.SS3.p2.13.m13.1.1" xref="S2.SS3.p2.13.m13.1.1.cmml"><mi id="S2.SS3.p2.13.m13.1.1.2" xref="S2.SS3.p2.13.m13.1.1.2.cmml">ω</mi><mrow id="S2.SS3.p2.13.m13.1.1.3" xref="S2.SS3.p2.13.m13.1.1.3.cmml"><mi id="S2.SS3.p2.13.m13.1.1.3.2" xref="S2.SS3.p2.13.m13.1.1.3.2.cmml">t</mi><mo id="S2.SS3.p2.13.m13.1.1.3.1" xref="S2.SS3.p2.13.m13.1.1.3.1.cmml">+</mo><mn id="S2.SS3.p2.13.m13.1.1.3.3" xref="S2.SS3.p2.13.m13.1.1.3.3.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.13.m13.1b"><apply id="S2.SS3.p2.13.m13.1.1.cmml" xref="S2.SS3.p2.13.m13.1.1"><csymbol cd="ambiguous" id="S2.SS3.p2.13.m13.1.1.1.cmml" xref="S2.SS3.p2.13.m13.1.1">subscript</csymbol><ci id="S2.SS3.p2.13.m13.1.1.2.cmml" xref="S2.SS3.p2.13.m13.1.1.2">𝜔</ci><apply id="S2.SS3.p2.13.m13.1.1.3.cmml" xref="S2.SS3.p2.13.m13.1.1.3"><plus id="S2.SS3.p2.13.m13.1.1.3.1.cmml" xref="S2.SS3.p2.13.m13.1.1.3.1"></plus><ci id="S2.SS3.p2.13.m13.1.1.3.2.cmml" xref="S2.SS3.p2.13.m13.1.1.3.2">𝑡</ci><cn type="integer" id="S2.SS3.p2.13.m13.1.1.3.3.cmml" xref="S2.SS3.p2.13.m13.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.13.m13.1c">\omega_{t+1}</annotation></semantics></math> for the next iteration, i.e., <math id="S2.SS3.p2.14.m14.1" class="ltx_Math" alttext="{\omega_{t+1}}\leftarrow{\omega_{t}}-\frac{1}{K}\sum\limits_{k=1}^{K}{{F_{k}}(\omega)}" display="inline"><semantics id="S2.SS3.p2.14.m14.1a"><mrow id="S2.SS3.p2.14.m14.1.2" xref="S2.SS3.p2.14.m14.1.2.cmml"><msub id="S2.SS3.p2.14.m14.1.2.2" xref="S2.SS3.p2.14.m14.1.2.2.cmml"><mi id="S2.SS3.p2.14.m14.1.2.2.2" xref="S2.SS3.p2.14.m14.1.2.2.2.cmml">ω</mi><mrow id="S2.SS3.p2.14.m14.1.2.2.3" xref="S2.SS3.p2.14.m14.1.2.2.3.cmml"><mi id="S2.SS3.p2.14.m14.1.2.2.3.2" xref="S2.SS3.p2.14.m14.1.2.2.3.2.cmml">t</mi><mo id="S2.SS3.p2.14.m14.1.2.2.3.1" xref="S2.SS3.p2.14.m14.1.2.2.3.1.cmml">+</mo><mn id="S2.SS3.p2.14.m14.1.2.2.3.3" xref="S2.SS3.p2.14.m14.1.2.2.3.3.cmml">1</mn></mrow></msub><mo stretchy="false" id="S2.SS3.p2.14.m14.1.2.1" xref="S2.SS3.p2.14.m14.1.2.1.cmml">←</mo><mrow id="S2.SS3.p2.14.m14.1.2.3" xref="S2.SS3.p2.14.m14.1.2.3.cmml"><msub id="S2.SS3.p2.14.m14.1.2.3.2" xref="S2.SS3.p2.14.m14.1.2.3.2.cmml"><mi id="S2.SS3.p2.14.m14.1.2.3.2.2" xref="S2.SS3.p2.14.m14.1.2.3.2.2.cmml">ω</mi><mi id="S2.SS3.p2.14.m14.1.2.3.2.3" xref="S2.SS3.p2.14.m14.1.2.3.2.3.cmml">t</mi></msub><mo id="S2.SS3.p2.14.m14.1.2.3.1" xref="S2.SS3.p2.14.m14.1.2.3.1.cmml">−</mo><mrow id="S2.SS3.p2.14.m14.1.2.3.3" xref="S2.SS3.p2.14.m14.1.2.3.3.cmml"><mfrac id="S2.SS3.p2.14.m14.1.2.3.3.2" xref="S2.SS3.p2.14.m14.1.2.3.3.2.cmml"><mn id="S2.SS3.p2.14.m14.1.2.3.3.2.2" xref="S2.SS3.p2.14.m14.1.2.3.3.2.2.cmml">1</mn><mi id="S2.SS3.p2.14.m14.1.2.3.3.2.3" xref="S2.SS3.p2.14.m14.1.2.3.3.2.3.cmml">K</mi></mfrac><mo lspace="0em" rspace="0em" id="S2.SS3.p2.14.m14.1.2.3.3.1" xref="S2.SS3.p2.14.m14.1.2.3.3.1.cmml">​</mo><mrow id="S2.SS3.p2.14.m14.1.2.3.3.3" xref="S2.SS3.p2.14.m14.1.2.3.3.3.cmml"><munderover id="S2.SS3.p2.14.m14.1.2.3.3.3.1" xref="S2.SS3.p2.14.m14.1.2.3.3.3.1.cmml"><mo movablelimits="false" id="S2.SS3.p2.14.m14.1.2.3.3.3.1.2.2" xref="S2.SS3.p2.14.m14.1.2.3.3.3.1.2.2.cmml">∑</mo><mrow id="S2.SS3.p2.14.m14.1.2.3.3.3.1.2.3" xref="S2.SS3.p2.14.m14.1.2.3.3.3.1.2.3.cmml"><mi id="S2.SS3.p2.14.m14.1.2.3.3.3.1.2.3.2" xref="S2.SS3.p2.14.m14.1.2.3.3.3.1.2.3.2.cmml">k</mi><mo id="S2.SS3.p2.14.m14.1.2.3.3.3.1.2.3.1" xref="S2.SS3.p2.14.m14.1.2.3.3.3.1.2.3.1.cmml">=</mo><mn id="S2.SS3.p2.14.m14.1.2.3.3.3.1.2.3.3" xref="S2.SS3.p2.14.m14.1.2.3.3.3.1.2.3.3.cmml">1</mn></mrow><mi id="S2.SS3.p2.14.m14.1.2.3.3.3.1.3" xref="S2.SS3.p2.14.m14.1.2.3.3.3.1.3.cmml">K</mi></munderover><mrow id="S2.SS3.p2.14.m14.1.2.3.3.3.2" xref="S2.SS3.p2.14.m14.1.2.3.3.3.2.cmml"><msub id="S2.SS3.p2.14.m14.1.2.3.3.3.2.2" xref="S2.SS3.p2.14.m14.1.2.3.3.3.2.2.cmml"><mi id="S2.SS3.p2.14.m14.1.2.3.3.3.2.2.2" xref="S2.SS3.p2.14.m14.1.2.3.3.3.2.2.2.cmml">F</mi><mi id="S2.SS3.p2.14.m14.1.2.3.3.3.2.2.3" xref="S2.SS3.p2.14.m14.1.2.3.3.3.2.2.3.cmml">k</mi></msub><mo lspace="0em" rspace="0em" id="S2.SS3.p2.14.m14.1.2.3.3.3.2.1" xref="S2.SS3.p2.14.m14.1.2.3.3.3.2.1.cmml">​</mo><mrow id="S2.SS3.p2.14.m14.1.2.3.3.3.2.3.2" xref="S2.SS3.p2.14.m14.1.2.3.3.3.2.cmml"><mo stretchy="false" id="S2.SS3.p2.14.m14.1.2.3.3.3.2.3.2.1" xref="S2.SS3.p2.14.m14.1.2.3.3.3.2.cmml">(</mo><mi id="S2.SS3.p2.14.m14.1.1" xref="S2.SS3.p2.14.m14.1.1.cmml">ω</mi><mo stretchy="false" id="S2.SS3.p2.14.m14.1.2.3.3.3.2.3.2.2" xref="S2.SS3.p2.14.m14.1.2.3.3.3.2.cmml">)</mo></mrow></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.14.m14.1b"><apply id="S2.SS3.p2.14.m14.1.2.cmml" xref="S2.SS3.p2.14.m14.1.2"><ci id="S2.SS3.p2.14.m14.1.2.1.cmml" xref="S2.SS3.p2.14.m14.1.2.1">←</ci><apply id="S2.SS3.p2.14.m14.1.2.2.cmml" xref="S2.SS3.p2.14.m14.1.2.2"><csymbol cd="ambiguous" id="S2.SS3.p2.14.m14.1.2.2.1.cmml" xref="S2.SS3.p2.14.m14.1.2.2">subscript</csymbol><ci id="S2.SS3.p2.14.m14.1.2.2.2.cmml" xref="S2.SS3.p2.14.m14.1.2.2.2">𝜔</ci><apply id="S2.SS3.p2.14.m14.1.2.2.3.cmml" xref="S2.SS3.p2.14.m14.1.2.2.3"><plus id="S2.SS3.p2.14.m14.1.2.2.3.1.cmml" xref="S2.SS3.p2.14.m14.1.2.2.3.1"></plus><ci id="S2.SS3.p2.14.m14.1.2.2.3.2.cmml" xref="S2.SS3.p2.14.m14.1.2.2.3.2">𝑡</ci><cn type="integer" id="S2.SS3.p2.14.m14.1.2.2.3.3.cmml" xref="S2.SS3.p2.14.m14.1.2.2.3.3">1</cn></apply></apply><apply id="S2.SS3.p2.14.m14.1.2.3.cmml" xref="S2.SS3.p2.14.m14.1.2.3"><minus id="S2.SS3.p2.14.m14.1.2.3.1.cmml" xref="S2.SS3.p2.14.m14.1.2.3.1"></minus><apply id="S2.SS3.p2.14.m14.1.2.3.2.cmml" xref="S2.SS3.p2.14.m14.1.2.3.2"><csymbol cd="ambiguous" id="S2.SS3.p2.14.m14.1.2.3.2.1.cmml" xref="S2.SS3.p2.14.m14.1.2.3.2">subscript</csymbol><ci id="S2.SS3.p2.14.m14.1.2.3.2.2.cmml" xref="S2.SS3.p2.14.m14.1.2.3.2.2">𝜔</ci><ci id="S2.SS3.p2.14.m14.1.2.3.2.3.cmml" xref="S2.SS3.p2.14.m14.1.2.3.2.3">𝑡</ci></apply><apply id="S2.SS3.p2.14.m14.1.2.3.3.cmml" xref="S2.SS3.p2.14.m14.1.2.3.3"><times id="S2.SS3.p2.14.m14.1.2.3.3.1.cmml" xref="S2.SS3.p2.14.m14.1.2.3.3.1"></times><apply id="S2.SS3.p2.14.m14.1.2.3.3.2.cmml" xref="S2.SS3.p2.14.m14.1.2.3.3.2"><divide id="S2.SS3.p2.14.m14.1.2.3.3.2.1.cmml" xref="S2.SS3.p2.14.m14.1.2.3.3.2"></divide><cn type="integer" id="S2.SS3.p2.14.m14.1.2.3.3.2.2.cmml" xref="S2.SS3.p2.14.m14.1.2.3.3.2.2">1</cn><ci id="S2.SS3.p2.14.m14.1.2.3.3.2.3.cmml" xref="S2.SS3.p2.14.m14.1.2.3.3.2.3">𝐾</ci></apply><apply id="S2.SS3.p2.14.m14.1.2.3.3.3.cmml" xref="S2.SS3.p2.14.m14.1.2.3.3.3"><apply id="S2.SS3.p2.14.m14.1.2.3.3.3.1.cmml" xref="S2.SS3.p2.14.m14.1.2.3.3.3.1"><csymbol cd="ambiguous" id="S2.SS3.p2.14.m14.1.2.3.3.3.1.1.cmml" xref="S2.SS3.p2.14.m14.1.2.3.3.3.1">superscript</csymbol><apply id="S2.SS3.p2.14.m14.1.2.3.3.3.1.2.cmml" xref="S2.SS3.p2.14.m14.1.2.3.3.3.1"><csymbol cd="ambiguous" id="S2.SS3.p2.14.m14.1.2.3.3.3.1.2.1.cmml" xref="S2.SS3.p2.14.m14.1.2.3.3.3.1">subscript</csymbol><sum id="S2.SS3.p2.14.m14.1.2.3.3.3.1.2.2.cmml" xref="S2.SS3.p2.14.m14.1.2.3.3.3.1.2.2"></sum><apply id="S2.SS3.p2.14.m14.1.2.3.3.3.1.2.3.cmml" xref="S2.SS3.p2.14.m14.1.2.3.3.3.1.2.3"><eq id="S2.SS3.p2.14.m14.1.2.3.3.3.1.2.3.1.cmml" xref="S2.SS3.p2.14.m14.1.2.3.3.3.1.2.3.1"></eq><ci id="S2.SS3.p2.14.m14.1.2.3.3.3.1.2.3.2.cmml" xref="S2.SS3.p2.14.m14.1.2.3.3.3.1.2.3.2">𝑘</ci><cn type="integer" id="S2.SS3.p2.14.m14.1.2.3.3.3.1.2.3.3.cmml" xref="S2.SS3.p2.14.m14.1.2.3.3.3.1.2.3.3">1</cn></apply></apply><ci id="S2.SS3.p2.14.m14.1.2.3.3.3.1.3.cmml" xref="S2.SS3.p2.14.m14.1.2.3.3.3.1.3">𝐾</ci></apply><apply id="S2.SS3.p2.14.m14.1.2.3.3.3.2.cmml" xref="S2.SS3.p2.14.m14.1.2.3.3.3.2"><times id="S2.SS3.p2.14.m14.1.2.3.3.3.2.1.cmml" xref="S2.SS3.p2.14.m14.1.2.3.3.3.2.1"></times><apply id="S2.SS3.p2.14.m14.1.2.3.3.3.2.2.cmml" xref="S2.SS3.p2.14.m14.1.2.3.3.3.2.2"><csymbol cd="ambiguous" id="S2.SS3.p2.14.m14.1.2.3.3.3.2.2.1.cmml" xref="S2.SS3.p2.14.m14.1.2.3.3.3.2.2">subscript</csymbol><ci id="S2.SS3.p2.14.m14.1.2.3.3.3.2.2.2.cmml" xref="S2.SS3.p2.14.m14.1.2.3.3.3.2.2.2">𝐹</ci><ci id="S2.SS3.p2.14.m14.1.2.3.3.3.2.2.3.cmml" xref="S2.SS3.p2.14.m14.1.2.3.3.3.2.2.3">𝑘</ci></apply><ci id="S2.SS3.p2.14.m14.1.1.cmml" xref="S2.SS3.p2.14.m14.1.1">𝜔</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.14.m14.1c">{\omega_{t+1}}\leftarrow{\omega_{t}}-\frac{1}{K}\sum\limits_{k=1}^{K}{{F_{k}}(\omega)}</annotation></semantics></math>, where <math id="S2.SS3.p2.15.m15.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S2.SS3.p2.15.m15.1a"><mi id="S2.SS3.p2.15.m15.1.1" xref="S2.SS3.p2.15.m15.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.15.m15.1b"><ci id="S2.SS3.p2.15.m15.1.1.cmml" xref="S2.SS3.p2.15.m15.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.15.m15.1c">K</annotation></semantics></math> denotes the number of edge nodes. In the next round, the device selected by the cloud downloads the current latest global model <math id="S2.SS3.p2.16.m16.1" class="ltx_Math" alttext="\omega_{t+1}" display="inline"><semantics id="S2.SS3.p2.16.m16.1a"><msub id="S2.SS3.p2.16.m16.1.1" xref="S2.SS3.p2.16.m16.1.1.cmml"><mi id="S2.SS3.p2.16.m16.1.1.2" xref="S2.SS3.p2.16.m16.1.1.2.cmml">ω</mi><mrow id="S2.SS3.p2.16.m16.1.1.3" xref="S2.SS3.p2.16.m16.1.1.3.cmml"><mi id="S2.SS3.p2.16.m16.1.1.3.2" xref="S2.SS3.p2.16.m16.1.1.3.2.cmml">t</mi><mo id="S2.SS3.p2.16.m16.1.1.3.1" xref="S2.SS3.p2.16.m16.1.1.3.1.cmml">+</mo><mn id="S2.SS3.p2.16.m16.1.1.3.3" xref="S2.SS3.p2.16.m16.1.1.3.3.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.16.m16.1b"><apply id="S2.SS3.p2.16.m16.1.1.cmml" xref="S2.SS3.p2.16.m16.1.1"><csymbol cd="ambiguous" id="S2.SS3.p2.16.m16.1.1.1.cmml" xref="S2.SS3.p2.16.m16.1.1">subscript</csymbol><ci id="S2.SS3.p2.16.m16.1.1.2.cmml" xref="S2.SS3.p2.16.m16.1.1.2">𝜔</ci><apply id="S2.SS3.p2.16.m16.1.1.3.cmml" xref="S2.SS3.p2.16.m16.1.1.3"><plus id="S2.SS3.p2.16.m16.1.1.3.1.cmml" xref="S2.SS3.p2.16.m16.1.1.3.1"></plus><ci id="S2.SS3.p2.16.m16.1.1.3.2.cmml" xref="S2.SS3.p2.16.m16.1.1.3.2">𝑡</ci><cn type="integer" id="S2.SS3.p2.16.m16.1.1.3.3.cmml" xref="S2.SS3.p2.16.m16.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.16.m16.1c">\omega_{t+1}</annotation></semantics></math> from the cloud. The device will use the received new global model to update its respective model. In the next round of training, the cloud will randomly select a new device subset and repeat the above process until the trained model converges or meets the stopping criteria (step \scriptsize6⃝).</p>
</div>
<figure id="S2.F3" class="ltx_figure"><img src="/html/2006.02931/assets/x3.png" id="S2.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="247" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>An overview of federated learning process in 6G <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>.</figcaption>
</figure>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Core Challenges for Federated Learning in 6G</span>
</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">In this section, we introduce the core challenges of FL, which are the main bottleneck problem before large-scale deployment of FL in 6G applications.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS1.5.1.1" class="ltx_text">III-A</span> </span><span id="S3.SS1.6.2" class="ltx_text ltx_font_italic">Challenge 1: Expensive Communication</span>
</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">Since the FL involves thousands of devices participating during model training, communication is a critical bottleneck for FL being widely used in 6G <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>. Previous studies <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib25" title="" class="ltx_ref">25</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>, <a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite> has made many efforts to improve the communication efficiency of FL system. Furthermore, it is challenging for FL networks to achieve communication in the FL networks is synchronized with the local calculation of the device <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>. To make the FL model suitable for 6G networks with massive, heterogeneous devices and networks, it is necessary to develop a communication-efficient method, which can greatly reduce the number of gradients exchanged between the devices and the cloud instead of all gradients information. In order to further reduce communication overhead in this setting, two key aspects need to be considered: (i) reducing the total number of communication rounds, or (ii) reducing the number of gradients in each communication round.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS2.5.1.1" class="ltx_text">III-B</span> </span><span id="S3.SS2.6.2" class="ltx_text ltx_font_italic">Challenge 2: Security Problems</span>
</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">Since 6G networks can provide ubiquitous services across a wider geographic area, the computing and communication capabilities of each device in the network may vary due to changes in hardware (CPU, GPU), network connectivity (4G, 5G, 6G, WiFi), and energy (battery level). Obviously, the system heterogeneity between the devices will bring some confusion and faults to the FL model and 6G network <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>. Additionally, there may be unreliable devices in the FL, which may cause the Byzantine failure of the system. Similarly, adversaries may launch active learning-based attacks (like poisoning attacks and backdoor attacks) on heterogeneous devices and cause errors in the FL system. The security vulnerabilities of these FL systems greatly exacerbate challenges such as mitigating attacks, tolerance, and faults. Therefore, developing a secure and robust FL must: (i) defend against malicious attacks, (ii) tolerate heterogeneous hardware, and (iii) achieve robust aggregation algorithms.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS3.5.1.1" class="ltx_text">III-C</span> </span><span id="S3.SS3.6.2" class="ltx_text ltx_font_italic">Challenge 3: Privacy Concerns</span>
</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">Although FL protects the privacy of each device by sharing model updates (e.g., gradients information) instead of the raw data, the private data will still be disclosed during the interaction between the device and the cloud <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>. For example, adversaries will launch <span id="S3.SS3.p1.1.1" class="ltx_text ltx_font_bold">membership inference</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> or <span id="S3.SS3.p1.1.2" class="ltx_text ltx_font_bold">gradient leakage attacks</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite> to steal local training data from the devices. Previous work has focused on using tools such as secure multi-party (SMC) computing or homomorphic encryption (HE) to enhance the privacy of FL, but these methods cannot address the above malicious attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>. SMC and HE can only prevent data breach problems and cannot resist member inference attacks and gradient leak attacks. Therefore, it is very urgent for the FL system to develop new privacy-enhancing techniques to resist or mitigate the aforementioned malicious attacks.</p>
</div>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS4.5.1.1" class="ltx_text">III-D</span> </span><span id="S3.SS4.6.2" class="ltx_text ltx_font_italic">Challenge 4: Effective Issues</span>
</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p">Deploying FL models to devices generally involves model training and inference <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>. If the speed of model training and reasoning is relatively slow, users will not be able to experience real-time intelligent services <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>. Therefore, when FL systems are widely deployed in 6G networks, they will encounter the following challenges: (i) the size of the FL model is too large to adapt to a single device; (ii) the FL model training is too slow to meet the delay requirements of the 6G network; (iii) the FL model inference is too slow to satisfy the user’ real-time demand. Efficient training and inference are necessary for the perfect integration of FL and 6G networks. However, it is challenging for FL systems to achieve efficient model training and inference in a massive, heterogeneous network.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Advanced Federated Learning Methods For 6G</span>
</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">To address the aforementioned challenges, we propose advanced federated learning systems through different emerging technologies or methods to enable communication-efficient, secure, and privacy-enhanced federated learning, respectively.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS1.5.1.1" class="ltx_text">IV-A</span> </span><span id="S4.SS1.6.2" class="ltx_text ltx_font_italic">Communication-efficient Federated Learning For 6G</span>
</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">In 6G, it is challenging for devices that span a larger geographic area to obtain a better global model but with huge communication overhead. The communication overhead will affect the gradient exchange between the devices and the cloud, thus affecting the model aggregation at the cloud. Therefore, we need to find a more efficient way to achieve FL training. In this subsection, we will explain communication-efficient FL from the perspectives of system-level and algorithm level, which promotes a wider-range FL deployment and usage for 6G communications.</p>
</div>
<section id="S4.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS1.SSS1.5.1.1" class="ltx_text">IV-A</span>1 </span><span id="S4.SS1.SSS1.6.2" class="ltx_text ltx_font_bold">Communication-efficient FL: System Level</span>
</h4>

<div id="S4.SS1.SSS1.p1" class="ltx_para">
<p id="S4.SS1.SSS1.p1.1" class="ltx_p">From a system perspective, data distribution (e.g., non-independent and identical distribution), device distribution (e.g., heterogeneous devices across regions and networks), computation methods (e.g., decentralized and centralized), and communication mechanisms (e.g., synchronous and asynchronous scheme) have different impacts on communication efficiency in different application scenarios <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>.</p>
<ul id="S4.I1" class="ltx_itemize">
<li id="S4.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i1.p1" class="ltx_para">
<p id="S4.I1.i1.p1.6" class="ltx_p"><span id="S4.I1.i1.p1.6.1" class="ltx_text ltx_font_bold">Asynchronous FL System:</span> As shown in Fig. <a href="#S4.F4" title="Figure 4 ‣ IV-A2 Communication-efficient FL: Algorithm Level ‣ IV-A Communication-efficient Federated Learning For 6G ‣ IV Advanced Federated Learning Methods For 6G ‣ Federated Learning for 6G Communications: Challenges, Methods, and Future Directions" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, AFLS can reduce the computation time of the devices by asynchronously aggregating the model updates, thereby improving the communication efficiency of FL. Let <math id="S4.I1.i1.p1.1.m1.1" class="ltx_Math" alttext="\kappa=\frac{{Comm}}{{Comp+Comm}}" display="inline"><semantics id="S4.I1.i1.p1.1.m1.1a"><mrow id="S4.I1.i1.p1.1.m1.1.1" xref="S4.I1.i1.p1.1.m1.1.1.cmml"><mi id="S4.I1.i1.p1.1.m1.1.1.2" xref="S4.I1.i1.p1.1.m1.1.1.2.cmml">κ</mi><mo id="S4.I1.i1.p1.1.m1.1.1.1" xref="S4.I1.i1.p1.1.m1.1.1.1.cmml">=</mo><mfrac id="S4.I1.i1.p1.1.m1.1.1.3" xref="S4.I1.i1.p1.1.m1.1.1.3.cmml"><mrow id="S4.I1.i1.p1.1.m1.1.1.3.2" xref="S4.I1.i1.p1.1.m1.1.1.3.2.cmml"><mi id="S4.I1.i1.p1.1.m1.1.1.3.2.2" xref="S4.I1.i1.p1.1.m1.1.1.3.2.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S4.I1.i1.p1.1.m1.1.1.3.2.1" xref="S4.I1.i1.p1.1.m1.1.1.3.2.1.cmml">​</mo><mi id="S4.I1.i1.p1.1.m1.1.1.3.2.3" xref="S4.I1.i1.p1.1.m1.1.1.3.2.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.I1.i1.p1.1.m1.1.1.3.2.1a" xref="S4.I1.i1.p1.1.m1.1.1.3.2.1.cmml">​</mo><mi id="S4.I1.i1.p1.1.m1.1.1.3.2.4" xref="S4.I1.i1.p1.1.m1.1.1.3.2.4.cmml">m</mi><mo lspace="0em" rspace="0em" id="S4.I1.i1.p1.1.m1.1.1.3.2.1b" xref="S4.I1.i1.p1.1.m1.1.1.3.2.1.cmml">​</mo><mi id="S4.I1.i1.p1.1.m1.1.1.3.2.5" xref="S4.I1.i1.p1.1.m1.1.1.3.2.5.cmml">m</mi></mrow><mrow id="S4.I1.i1.p1.1.m1.1.1.3.3" xref="S4.I1.i1.p1.1.m1.1.1.3.3.cmml"><mrow id="S4.I1.i1.p1.1.m1.1.1.3.3.2" xref="S4.I1.i1.p1.1.m1.1.1.3.3.2.cmml"><mi id="S4.I1.i1.p1.1.m1.1.1.3.3.2.2" xref="S4.I1.i1.p1.1.m1.1.1.3.3.2.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S4.I1.i1.p1.1.m1.1.1.3.3.2.1" xref="S4.I1.i1.p1.1.m1.1.1.3.3.2.1.cmml">​</mo><mi id="S4.I1.i1.p1.1.m1.1.1.3.3.2.3" xref="S4.I1.i1.p1.1.m1.1.1.3.3.2.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.I1.i1.p1.1.m1.1.1.3.3.2.1a" xref="S4.I1.i1.p1.1.m1.1.1.3.3.2.1.cmml">​</mo><mi id="S4.I1.i1.p1.1.m1.1.1.3.3.2.4" xref="S4.I1.i1.p1.1.m1.1.1.3.3.2.4.cmml">m</mi><mo lspace="0em" rspace="0em" id="S4.I1.i1.p1.1.m1.1.1.3.3.2.1b" xref="S4.I1.i1.p1.1.m1.1.1.3.3.2.1.cmml">​</mo><mi id="S4.I1.i1.p1.1.m1.1.1.3.3.2.5" xref="S4.I1.i1.p1.1.m1.1.1.3.3.2.5.cmml">p</mi></mrow><mo id="S4.I1.i1.p1.1.m1.1.1.3.3.1" xref="S4.I1.i1.p1.1.m1.1.1.3.3.1.cmml">+</mo><mrow id="S4.I1.i1.p1.1.m1.1.1.3.3.3" xref="S4.I1.i1.p1.1.m1.1.1.3.3.3.cmml"><mi id="S4.I1.i1.p1.1.m1.1.1.3.3.3.2" xref="S4.I1.i1.p1.1.m1.1.1.3.3.3.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S4.I1.i1.p1.1.m1.1.1.3.3.3.1" xref="S4.I1.i1.p1.1.m1.1.1.3.3.3.1.cmml">​</mo><mi id="S4.I1.i1.p1.1.m1.1.1.3.3.3.3" xref="S4.I1.i1.p1.1.m1.1.1.3.3.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.I1.i1.p1.1.m1.1.1.3.3.3.1a" xref="S4.I1.i1.p1.1.m1.1.1.3.3.3.1.cmml">​</mo><mi id="S4.I1.i1.p1.1.m1.1.1.3.3.3.4" xref="S4.I1.i1.p1.1.m1.1.1.3.3.3.4.cmml">m</mi><mo lspace="0em" rspace="0em" id="S4.I1.i1.p1.1.m1.1.1.3.3.3.1b" xref="S4.I1.i1.p1.1.m1.1.1.3.3.3.1.cmml">​</mo><mi id="S4.I1.i1.p1.1.m1.1.1.3.3.3.5" xref="S4.I1.i1.p1.1.m1.1.1.3.3.3.5.cmml">m</mi></mrow></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S4.I1.i1.p1.1.m1.1b"><apply id="S4.I1.i1.p1.1.m1.1.1.cmml" xref="S4.I1.i1.p1.1.m1.1.1"><eq id="S4.I1.i1.p1.1.m1.1.1.1.cmml" xref="S4.I1.i1.p1.1.m1.1.1.1"></eq><ci id="S4.I1.i1.p1.1.m1.1.1.2.cmml" xref="S4.I1.i1.p1.1.m1.1.1.2">𝜅</ci><apply id="S4.I1.i1.p1.1.m1.1.1.3.cmml" xref="S4.I1.i1.p1.1.m1.1.1.3"><divide id="S4.I1.i1.p1.1.m1.1.1.3.1.cmml" xref="S4.I1.i1.p1.1.m1.1.1.3"></divide><apply id="S4.I1.i1.p1.1.m1.1.1.3.2.cmml" xref="S4.I1.i1.p1.1.m1.1.1.3.2"><times id="S4.I1.i1.p1.1.m1.1.1.3.2.1.cmml" xref="S4.I1.i1.p1.1.m1.1.1.3.2.1"></times><ci id="S4.I1.i1.p1.1.m1.1.1.3.2.2.cmml" xref="S4.I1.i1.p1.1.m1.1.1.3.2.2">𝐶</ci><ci id="S4.I1.i1.p1.1.m1.1.1.3.2.3.cmml" xref="S4.I1.i1.p1.1.m1.1.1.3.2.3">𝑜</ci><ci id="S4.I1.i1.p1.1.m1.1.1.3.2.4.cmml" xref="S4.I1.i1.p1.1.m1.1.1.3.2.4">𝑚</ci><ci id="S4.I1.i1.p1.1.m1.1.1.3.2.5.cmml" xref="S4.I1.i1.p1.1.m1.1.1.3.2.5">𝑚</ci></apply><apply id="S4.I1.i1.p1.1.m1.1.1.3.3.cmml" xref="S4.I1.i1.p1.1.m1.1.1.3.3"><plus id="S4.I1.i1.p1.1.m1.1.1.3.3.1.cmml" xref="S4.I1.i1.p1.1.m1.1.1.3.3.1"></plus><apply id="S4.I1.i1.p1.1.m1.1.1.3.3.2.cmml" xref="S4.I1.i1.p1.1.m1.1.1.3.3.2"><times id="S4.I1.i1.p1.1.m1.1.1.3.3.2.1.cmml" xref="S4.I1.i1.p1.1.m1.1.1.3.3.2.1"></times><ci id="S4.I1.i1.p1.1.m1.1.1.3.3.2.2.cmml" xref="S4.I1.i1.p1.1.m1.1.1.3.3.2.2">𝐶</ci><ci id="S4.I1.i1.p1.1.m1.1.1.3.3.2.3.cmml" xref="S4.I1.i1.p1.1.m1.1.1.3.3.2.3">𝑜</ci><ci id="S4.I1.i1.p1.1.m1.1.1.3.3.2.4.cmml" xref="S4.I1.i1.p1.1.m1.1.1.3.3.2.4">𝑚</ci><ci id="S4.I1.i1.p1.1.m1.1.1.3.3.2.5.cmml" xref="S4.I1.i1.p1.1.m1.1.1.3.3.2.5">𝑝</ci></apply><apply id="S4.I1.i1.p1.1.m1.1.1.3.3.3.cmml" xref="S4.I1.i1.p1.1.m1.1.1.3.3.3"><times id="S4.I1.i1.p1.1.m1.1.1.3.3.3.1.cmml" xref="S4.I1.i1.p1.1.m1.1.1.3.3.3.1"></times><ci id="S4.I1.i1.p1.1.m1.1.1.3.3.3.2.cmml" xref="S4.I1.i1.p1.1.m1.1.1.3.3.3.2">𝐶</ci><ci id="S4.I1.i1.p1.1.m1.1.1.3.3.3.3.cmml" xref="S4.I1.i1.p1.1.m1.1.1.3.3.3.3">𝑜</ci><ci id="S4.I1.i1.p1.1.m1.1.1.3.3.3.4.cmml" xref="S4.I1.i1.p1.1.m1.1.1.3.3.3.4">𝑚</ci><ci id="S4.I1.i1.p1.1.m1.1.1.3.3.3.5.cmml" xref="S4.I1.i1.p1.1.m1.1.1.3.3.3.5">𝑚</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i1.p1.1.m1.1c">\kappa=\frac{{Comm}}{{Comp+Comm}}</annotation></semantics></math>, where <math id="S4.I1.i1.p1.2.m2.1" class="ltx_Math" alttext="\kappa" display="inline"><semantics id="S4.I1.i1.p1.2.m2.1a"><mi id="S4.I1.i1.p1.2.m2.1.1" xref="S4.I1.i1.p1.2.m2.1.1.cmml">κ</mi><annotation-xml encoding="MathML-Content" id="S4.I1.i1.p1.2.m2.1b"><ci id="S4.I1.i1.p1.2.m2.1.1.cmml" xref="S4.I1.i1.p1.2.m2.1.1">𝜅</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i1.p1.2.m2.1c">\kappa</annotation></semantics></math> represents communication efficiency, <math id="S4.I1.i1.p1.3.m3.1" class="ltx_Math" alttext="Comm" display="inline"><semantics id="S4.I1.i1.p1.3.m3.1a"><mrow id="S4.I1.i1.p1.3.m3.1.1" xref="S4.I1.i1.p1.3.m3.1.1.cmml"><mi id="S4.I1.i1.p1.3.m3.1.1.2" xref="S4.I1.i1.p1.3.m3.1.1.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S4.I1.i1.p1.3.m3.1.1.1" xref="S4.I1.i1.p1.3.m3.1.1.1.cmml">​</mo><mi id="S4.I1.i1.p1.3.m3.1.1.3" xref="S4.I1.i1.p1.3.m3.1.1.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.I1.i1.p1.3.m3.1.1.1a" xref="S4.I1.i1.p1.3.m3.1.1.1.cmml">​</mo><mi id="S4.I1.i1.p1.3.m3.1.1.4" xref="S4.I1.i1.p1.3.m3.1.1.4.cmml">m</mi><mo lspace="0em" rspace="0em" id="S4.I1.i1.p1.3.m3.1.1.1b" xref="S4.I1.i1.p1.3.m3.1.1.1.cmml">​</mo><mi id="S4.I1.i1.p1.3.m3.1.1.5" xref="S4.I1.i1.p1.3.m3.1.1.5.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.I1.i1.p1.3.m3.1b"><apply id="S4.I1.i1.p1.3.m3.1.1.cmml" xref="S4.I1.i1.p1.3.m3.1.1"><times id="S4.I1.i1.p1.3.m3.1.1.1.cmml" xref="S4.I1.i1.p1.3.m3.1.1.1"></times><ci id="S4.I1.i1.p1.3.m3.1.1.2.cmml" xref="S4.I1.i1.p1.3.m3.1.1.2">𝐶</ci><ci id="S4.I1.i1.p1.3.m3.1.1.3.cmml" xref="S4.I1.i1.p1.3.m3.1.1.3">𝑜</ci><ci id="S4.I1.i1.p1.3.m3.1.1.4.cmml" xref="S4.I1.i1.p1.3.m3.1.1.4">𝑚</ci><ci id="S4.I1.i1.p1.3.m3.1.1.5.cmml" xref="S4.I1.i1.p1.3.m3.1.1.5">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i1.p1.3.m3.1c">Comm</annotation></semantics></math> is the communication time, and <math id="S4.I1.i1.p1.4.m4.1" class="ltx_Math" alttext="Comp" display="inline"><semantics id="S4.I1.i1.p1.4.m4.1a"><mrow id="S4.I1.i1.p1.4.m4.1.1" xref="S4.I1.i1.p1.4.m4.1.1.cmml"><mi id="S4.I1.i1.p1.4.m4.1.1.2" xref="S4.I1.i1.p1.4.m4.1.1.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S4.I1.i1.p1.4.m4.1.1.1" xref="S4.I1.i1.p1.4.m4.1.1.1.cmml">​</mo><mi id="S4.I1.i1.p1.4.m4.1.1.3" xref="S4.I1.i1.p1.4.m4.1.1.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.I1.i1.p1.4.m4.1.1.1a" xref="S4.I1.i1.p1.4.m4.1.1.1.cmml">​</mo><mi id="S4.I1.i1.p1.4.m4.1.1.4" xref="S4.I1.i1.p1.4.m4.1.1.4.cmml">m</mi><mo lspace="0em" rspace="0em" id="S4.I1.i1.p1.4.m4.1.1.1b" xref="S4.I1.i1.p1.4.m4.1.1.1.cmml">​</mo><mi id="S4.I1.i1.p1.4.m4.1.1.5" xref="S4.I1.i1.p1.4.m4.1.1.5.cmml">p</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.I1.i1.p1.4.m4.1b"><apply id="S4.I1.i1.p1.4.m4.1.1.cmml" xref="S4.I1.i1.p1.4.m4.1.1"><times id="S4.I1.i1.p1.4.m4.1.1.1.cmml" xref="S4.I1.i1.p1.4.m4.1.1.1"></times><ci id="S4.I1.i1.p1.4.m4.1.1.2.cmml" xref="S4.I1.i1.p1.4.m4.1.1.2">𝐶</ci><ci id="S4.I1.i1.p1.4.m4.1.1.3.cmml" xref="S4.I1.i1.p1.4.m4.1.1.3">𝑜</ci><ci id="S4.I1.i1.p1.4.m4.1.1.4.cmml" xref="S4.I1.i1.p1.4.m4.1.1.4">𝑚</ci><ci id="S4.I1.i1.p1.4.m4.1.1.5.cmml" xref="S4.I1.i1.p1.4.m4.1.1.5">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i1.p1.4.m4.1c">Comp</annotation></semantics></math> is the computation time. It can be seen from Fig. <a href="#S4.F4" title="Figure 4 ‣ IV-A2 Communication-efficient FL: Algorithm Level ‣ IV-A Communication-efficient Federated Learning For 6G ‣ IV Advanced Federated Learning Methods For 6G ‣ Federated Learning for 6G Communications: Challenges, Methods, and Future Directions" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> that the <math id="S4.I1.i1.p1.5.m5.1" class="ltx_Math" alttext="Comp" display="inline"><semantics id="S4.I1.i1.p1.5.m5.1a"><mrow id="S4.I1.i1.p1.5.m5.1.1" xref="S4.I1.i1.p1.5.m5.1.1.cmml"><mi id="S4.I1.i1.p1.5.m5.1.1.2" xref="S4.I1.i1.p1.5.m5.1.1.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S4.I1.i1.p1.5.m5.1.1.1" xref="S4.I1.i1.p1.5.m5.1.1.1.cmml">​</mo><mi id="S4.I1.i1.p1.5.m5.1.1.3" xref="S4.I1.i1.p1.5.m5.1.1.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.I1.i1.p1.5.m5.1.1.1a" xref="S4.I1.i1.p1.5.m5.1.1.1.cmml">​</mo><mi id="S4.I1.i1.p1.5.m5.1.1.4" xref="S4.I1.i1.p1.5.m5.1.1.4.cmml">m</mi><mo lspace="0em" rspace="0em" id="S4.I1.i1.p1.5.m5.1.1.1b" xref="S4.I1.i1.p1.5.m5.1.1.1.cmml">​</mo><mi id="S4.I1.i1.p1.5.m5.1.1.5" xref="S4.I1.i1.p1.5.m5.1.1.5.cmml">p</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.I1.i1.p1.5.m5.1b"><apply id="S4.I1.i1.p1.5.m5.1.1.cmml" xref="S4.I1.i1.p1.5.m5.1.1"><times id="S4.I1.i1.p1.5.m5.1.1.1.cmml" xref="S4.I1.i1.p1.5.m5.1.1.1"></times><ci id="S4.I1.i1.p1.5.m5.1.1.2.cmml" xref="S4.I1.i1.p1.5.m5.1.1.2">𝐶</ci><ci id="S4.I1.i1.p1.5.m5.1.1.3.cmml" xref="S4.I1.i1.p1.5.m5.1.1.3">𝑜</ci><ci id="S4.I1.i1.p1.5.m5.1.1.4.cmml" xref="S4.I1.i1.p1.5.m5.1.1.4">𝑚</ci><ci id="S4.I1.i1.p1.5.m5.1.1.5.cmml" xref="S4.I1.i1.p1.5.m5.1.1.5">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i1.p1.5.m5.1c">Comp</annotation></semantics></math> of asynchronous model update scheme is shorter than that of synchronous one, so the communication efficiency <math id="S4.I1.i1.p1.6.m6.1" class="ltx_Math" alttext="\kappa" display="inline"><semantics id="S4.I1.i1.p1.6.m6.1a"><mi id="S4.I1.i1.p1.6.m6.1.1" xref="S4.I1.i1.p1.6.m6.1.1.cmml">κ</mi><annotation-xml encoding="MathML-Content" id="S4.I1.i1.p1.6.m6.1b"><ci id="S4.I1.i1.p1.6.m6.1.1.cmml" xref="S4.I1.i1.p1.6.m6.1.1">𝜅</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i1.p1.6.m6.1c">\kappa</annotation></semantics></math> of the asynchronous model update scheme is higher than that of the synchronous one.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S4.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS1.SSS2.5.1.1" class="ltx_text">IV-A</span>2 </span><span id="S4.SS1.SSS2.6.2" class="ltx_text ltx_font_bold">Communication-efficient FL: Algorithm Level</span>
</h4>

<div id="S4.SS1.SSS2.p1" class="ltx_para">
<p id="S4.SS1.SSS2.p1.1" class="ltx_p">At the algorithm level, achieving communication-efficient FL can reduce the communication rounds of training a model by accelerating convergence <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> and reduce the communication cost of each round by using gradient compression techniques <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> (e.g., sparsification, quantization, etc.). More details are described below.</p>
<ul id="S4.I2" class="ltx_itemize">
<li id="S4.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i1.p1" class="ltx_para">
<p id="S4.I2.i1.p1.1" class="ltx_p"><span id="S4.I2.i1.p1.1.1" class="ltx_text ltx_font_bold">Accelerating Model Convergence:</span> Stochastic gradient descent (SGD) algorithms based on zero-order, first-order, second-order, and federated optimization are used to reduce the number of rounds of model training <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>. Since the federated optimization method can protect the private data on each device, it is very popular with this unique motivation in accelerating training model convergence.</p>
</div>
</li>
<li id="S4.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i2.p1" class="ltx_para">
<p id="S4.I2.i2.p1.1" class="ltx_p"><span id="S4.I2.i2.p1.1.1" class="ltx_text ltx_font_bold">Reducing Communication Overhead:</span> Gradient sparsification and gradient quantization can greatly reduce the large number of gradients exchanged between the devices and the cloud to achieve communication-efficient FL. Lin <span id="S4.I2.i2.p1.1.2" class="ltx_text ltx_font_italic">et al.</span> in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> proposed a Top-k selection-based gradient compression scheme to improve communication efficiency. In this scheme, the authors can compress the gradient 300 times to reduce the number of gradients without compromising accuracy.</p>
</div>
</li>
</ul>
</div>
<figure id="S4.F4" class="ltx_figure"><img src="/html/2006.02931/assets/x4.png" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="190" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>The overview of the synchronous and asynchronous FL.</figcaption>
</figure>
</section>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS2.5.1.1" class="ltx_text">IV-B</span> </span><span id="S4.SS2.6.2" class="ltx_text ltx_font_italic">Secure Federated Learning For 6G</span>
</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">Due to the wide range of 6G network connections, FL will suffer malicious attacks from heterogeneous networks, heterogeneous devices, and malicious participants during the training process <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>. To alleviate this problem, researchers have proposed many different defense solutions from three perspectives: aggregation algorithm, detection mechanism, and reputation management.</p>
</div>
<section id="S4.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS2.SSS1.5.1.1" class="ltx_text">IV-B</span>1 </span><span id="S4.SS2.SSS1.6.2" class="ltx_text ltx_font_bold">Robust Aggregation Algorithm</span>
</h4>

<div id="S4.SS2.SSS1.p1" class="ltx_para">
<p id="S4.SS2.SSS1.p1.1" class="ltx_p">Aggregation is a very important operation in the FL training process that directly affects the results of model convergence. The motivation of the robust aggregation algorithm is to greatly reduce the impact of low-quality model updates generated by malicious devices (i.e., poisoning attacks) on global model training. Furthermore, this method can make the cloud tolerate Byzantine failures of some devices <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>, <a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>. For example, Ang <span id="S4.SS2.SSS1.p1.1.1" class="ltx_text ltx_font_italic">et al.</span> in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> proposed the regularizer approximation method to reduce the noise interference of heterogeneous devices and heterogeneous networks.</p>
</div>
</section>
<section id="S4.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS2.SSS2.5.1.1" class="ltx_text">IV-B</span>2 </span><span id="S4.SS2.SSS2.6.2" class="ltx_text ltx_font_bold">Robust Detection Mechanism</span>
</h4>

<div id="S4.SS2.SSS2.p1" class="ltx_para">
<p id="S4.SS2.SSS2.p1.1" class="ltx_p">Another intuitive idea is to detect malicious devices to prevent them from participating in FL training. Such a mechanism has generally utilized the accuracy of the sub-model generated by the device as an evaluation metric to detect malicious devices. Liu <span id="S4.SS2.SSS2.p1.1.1" class="ltx_text ltx_font_italic">et al.</span> in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> utilized the smart contract techniques in the blockchain to design a malicious device detection mechanism to alleviate the malicious attack problems.</p>
</div>
</section>
<section id="S4.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS2.SSS3.5.1.1" class="ltx_text">IV-B</span>3 </span><span id="S4.SS2.SSS3.6.2" class="ltx_text ltx_font_bold">Reliable Reputation Management</span>
</h4>

<div id="S4.SS2.SSS3.p1" class="ltx_para">
<p id="S4.SS2.SSS3.p1.1" class="ltx_p">The historical behaviors of the devices can be used as a key indicator to evaluate its reliability and trustworthiness by a metric named reputation. The high reputation value indicates more reliable devices. Inspired by this, establishing a reputation management scheme for device historical behaviors in FL can also prevent malicious devices from damaging the global model. Kang <span id="S4.SS2.SSS3.p1.1.1" class="ltx_text ltx_font_italic">et al.</span> in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> proposed a reputation management scheme to calculate the historical reputation of the devices to achieve a robust FL with high-reputation devices.</p>
</div>
</section>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS3.5.1.1" class="ltx_text">IV-C</span> </span><span id="S4.SS3.6.2" class="ltx_text ltx_font_italic">Privacy-preserving Federated Learning For 6G</span>
</h3>

<section id="S4.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS3.SSS1.5.1.1" class="ltx_text">IV-C</span>1 </span><span id="S4.SS3.SSS1.6.2" class="ltx_text ltx_font_bold">Differentially Privacy</span>
</h4>

<div id="S4.SS3.SSS1.p1" class="ltx_para">
<p id="S4.SS3.SSS1.p1.1" class="ltx_p">Differential privacy (DP) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite> techniques are proposed to protect the privacy of gradient information, thereby achieving cloud-level privacy protection. Geyer <span id="S4.SS3.SSS1.p1.1.1" class="ltx_text ltx_font_italic">et al.</span> in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite> applied the DP technique in FL system that protects cloud-level privacy. Similarly, in order to protect user-level privacy, the local differential privacy (LDP) techniques achieve this goal by disturbing the gradients uploaded by the devices <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>. However, DP and LDP technologies enhance FL privacy at the expense of model performance. Therefore, there are currently advanced methods that balance privacy and performance as described below.</p>
</div>
</section>
<section id="S4.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS3.SSS2.5.1.1" class="ltx_text">IV-C</span>2 </span><span id="S4.SS3.SSS2.6.2" class="ltx_text ltx_font_bold">Deep Net Pruning</span>
</h4>

<div id="S4.SS3.SSS2.p1" class="ltx_para">
<p id="S4.SS3.SSS2.p1.1" class="ltx_p">Neural network pruning is a technique of deep learning whose goal is to develop a smaller and more efficient neural network. Recently, Huang <span id="S4.SS3.SSS2.p1.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite> utilized pruning as an equivalent technique of DP to protect the privacy of the FL system while ensuring the model performance. Such a method creates a new idea of using model pruning to be equivalent to DP techniques, which provides new opportunities for balancing utility and privacy.</p>
</div>
</section>
<section id="S4.SS3.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS3.SSS3.5.1.1" class="ltx_text">IV-C</span>3 </span><span id="S4.SS3.SSS3.6.2" class="ltx_text ltx_font_bold">Gradient Compression</span>
</h4>

<div id="S4.SS3.SSS3.p1" class="ltx_para">
<p id="S4.SS3.SSS3.p1.1" class="ltx_p">The reason why adversaries can infer the local data of the devices is that the gradient information contains rich semantic information <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>. Inspired by the above, an intuitive idea is that the methods that disrupt the distribution of gradient information thus protecting the gradient privacy. Zhu <span id="S4.SS3.SSS3.p1.1.1" class="ltx_text ltx_font_italic">et al.</span> in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite> proved that gradient compression can defend against gradient leakage attacks without compromising accuracy and the defense effect is better than that of DP.</p>
</div>
</section>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS4.5.1.1" class="ltx_text">IV-D</span> </span><span id="S4.SS4.6.2" class="ltx_text ltx_font_italic">Effective Federated Learning For 6G</span>
</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p">The long-term goal of human-centric communication services in 6G networks is to handle user needs in real time. Therefore, it is necessary to achieve efficient FL from training and inference.</p>
</div>
<section id="S4.SS4.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS4.SSS1.5.1.1" class="ltx_text">IV-D</span>1 </span><span id="S4.SS4.SSS1.6.2" class="ltx_text ltx_font_bold">Efficient Training</span>
</h4>

<div id="S4.SS4.SSS1.p1" class="ltx_para">
<p id="S4.SS4.SSS1.p1.1" class="ltx_p">Efficient training can greatly reduce the training time of mobile devices to achieve efficient FL. The advanced training methods are summarized as follows.</p>
</div>
<div id="S4.SS4.SSS1.p2" class="ltx_para">
<ul id="S4.I3" class="ltx_itemize">
<li id="S4.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I3.i1.p1" class="ltx_para">
<p id="S4.I3.i1.p1.1" class="ltx_p"><span id="S4.I3.i1.p1.1.1" class="ltx_text ltx_font_bold">Federated Parallelization:</span> Data and model parallelization are generally used to accelerate model training. Data parallization achieves efficient training by running multiple training samples in parallel <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>, <a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>. Model parallelization accelerates model training by splitting the model over multiple processors <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>.</p>
</div>
</li>
<li id="S4.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I3.i2.p1" class="ltx_para">
<p id="S4.I3.i2.p1.1" class="ltx_p"><span id="S4.I3.i2.p1.1.1" class="ltx_text ltx_font_bold">Federated Distillation:</span> Model distillation adopts transfer learning to utilize the output of a pre-trained complex model (i.e., Teacher model) as a supervised signal to train another simple network, i.e., Student model. Such a way can train student models to improve the efficiency of model training. Jeong <span id="S4.I3.i2.p1.1.2" class="ltx_text ltx_font_italic">et al.</span> in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite> proposed federated distillation (FD), an efficient distributed model training algorithm, whose training efficiency is much smaller than the FL benchmark scheme, especially when the model size is large.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S4.SS4.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS4.SSS2.5.1.1" class="ltx_text">IV-D</span>2 </span><span id="S4.SS4.SSS2.6.2" class="ltx_text ltx_font_bold">Efficient Inference:</span>
</h4>

<div id="S4.SS4.SSS2.p1" class="ltx_para">
<p id="S4.SS4.SSS2.p1.1" class="ltx_p">The size of the existing FL model is too large to realize real-time inference on the devices. Efficient inference can be achieved in the following ways.</p>
</div>
<div id="S4.SS4.SSS2.p2" class="ltx_para">
<ul id="S4.I4" class="ltx_itemize">
<li id="S4.I4.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I4.i1.p1" class="ltx_para">
<p id="S4.I4.i1.p1.1" class="ltx_p"><span id="S4.I4.i1.p1.1.1" class="ltx_text ltx_font_bold">Pruning:</span> The pruning technique is a model optimization technique that includes removing excess weights in the weight tensor. The compressed neural network not only runs faster but also reduces the computational cost of the training network, which is a critical step in deploying the model to mobile phones or other edge devices.</p>
</div>
</li>
<li id="S4.I4.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I4.i2.p1" class="ltx_para">
<p id="S4.I4.i2.p1.1" class="ltx_p"><span id="S4.I4.i2.p1.1.1" class="ltx_text ltx_font_bold">Weight Sharing.</span> Weight sharing reduces the number of model parameters by sharing weights, thereby achieving efficient model inference. The reason is that the fewer the parameters of the model, the smaller the model size. Tran <span id="S4.I4.i2.p1.1.2" class="ltx_text ltx_font_italic">et al.</span> in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> utilized weight sharing approach for wireless networks to improve model inference efficiency.</p>
</div>
</li>
</ul>
</div>
</section>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Open Research Topics And Future Directions</span>
</h2>

<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS1.5.1.1" class="ltx_text">V-A</span> </span><span id="S5.SS1.6.2" class="ltx_text ltx_font_italic">Trustworthy Federated Learning</span>
</h3>

<section id="S5.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S5.SS1.SSS1.5.1.1" class="ltx_text">V-A</span>1 </span><span id="S5.SS1.SSS1.6.2" class="ltx_text ltx_font_bold">Privacy-enhanced Federated Learning</span>
</h4>

<div id="S5.SS1.SSS1.p1" class="ltx_para">
<p id="S5.SS1.SSS1.p1.1" class="ltx_p">Previous work about FL has covered user or cloud-level privacy for all devices in the 6G networks. However, in practice, the previous schemes provide strict privacy restrictions at the expense of accuracy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>. It is essential for FL to develop privacy-enhanced techniques that do not compromise accuracy to provide strict privacy guarantees because the industry is very concerned about the accuracy of the FL model. To this end, few studies are exploring potential solutions. For example, Huang <span id="S5.SS1.SSS1.p1.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite> recently proposed a net pruning technique to provide strict privacy guarantees by replacing pruning with DP technique, and also to improve the training efficiency of the model. It is an interesting and ongoing direction to developing methods that can balance efficiency and privacy restrictions in future work.</p>
</div>
</section>
<section id="S5.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S5.SS1.SSS2.5.1.1" class="ltx_text">V-A</span>2 </span><span id="S5.SS1.SSS2.6.2" class="ltx_text ltx_font_bold">Security-enhanced Federated Learning</span>
</h4>

<div id="S5.SS1.SSS2.p1" class="ltx_para">
<p id="S5.SS1.SSS2.p1.1" class="ltx_p">Since the FL systems normally involve multiple entities of devices, cloud, and machine learning model providers, it is vulnerable to malicious attacks from adversaries against different entities. Although existing work has made a lot of efforts to provide strong security protection for the FL systems, there is little work to defend or mitigate these malicious attacks from the system perspective. Bonawitz <span id="S5.SS1.SSS2.p1.1.1" class="ltx_text ltx_font_italic">et al.</span> in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite> explored several more secure and robust aggregation algorithms and fault tolerance mechanisms from the perspective of system design. The serurity-enhanced techniques are designed from a system perspective so that FL can develop more practical industrial applications with the help of 6G networks.</p>
</div>
</section>
<section id="S5.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S5.SS1.SSS3.5.1.1" class="ltx_text">V-A</span>3 </span><span id="S5.SS1.SSS3.6.2" class="ltx_text ltx_font_bold">Fair Federated Learning</span>
</h4>

<div id="S5.SS1.SSS3.p1" class="ltx_para">
<p id="S5.SS1.SSS3.p1.1" class="ltx_p">FL involves thousands of devices training a shared global model in massive, heterogeneous networks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>. Naive optimizing the global model in such a network may be unfair to some devices by causing disproportionate advantages or disadvantages. Obviously, FL towards fairness is an indispensable requirement for human-centric 6G communication services. Specifically, a fair FL in a wireless network involves fair resource allocation and a reasonable incentive mechanism. How to allocate computing and communication resources accurately and fairly in massive, heterogeneous networks has become a critical challenge that needs to be solved urgently. Some pioneering work, Li <span id="S5.SS1.SSS3.p1.1.1" class="ltx_text ltx_font_italic">et al.</span> in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite> proposed q-Fair FL (q-FFL), which is a new aggregation algorithm to achieve a fair allocation of resources and accuracy.</p>
</div>
</section>
<section id="S5.SS1.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S5.SS1.SSS4.5.1.1" class="ltx_text">V-A</span>4 </span><span id="S5.SS1.SSS4.6.2" class="ltx_text ltx_font_bold">Explainable Federated Learning</span>
</h4>

<div id="S5.SS1.SSS4.p1" class="ltx_para">
<p id="S5.SS1.SSS4.p1.1" class="ltx_p">The vast majority of FL models are black-box models (i.e., without interpretability), which makes users unable to understand what kind of services the model provides for themselves. In a complex 6G network system, the unexplainable predictions or decisions output by the black-box model may cause huge losses to users. For example, 6G-supported self-driving relies on an on-vehicle visual recognition model to determine whether the vehicle is running or stopped. Since the on-vehicle model has no interpretability, the driver cannot understand the decision of the vehicle model output. In 2018, the self-driving vehicle developed by Uber caused a car accident due to the wrong output of the on-vehicle black-box model <span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a target="_blank" href="http://tech.sina.com.cn/zt_d/uberincident/" title="" class="ltx_ref ltx_href">http://tech.sina.com.cn/zt_d/uberincident/</a></span></span></span>. Therefore, in the context of a complex network system, such as 6G, the development of an interpretable FL model is the necessary way to human-centric communication services.</p>
</div>
</section>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS2.5.1.1" class="ltx_text">V-B</span> </span><span id="S5.SS2.6.2" class="ltx_text ltx_font_italic">Efficient and Effective Federated Learning</span>
</h3>

<section id="S5.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S5.SS2.SSS1.5.1.1" class="ltx_text">V-B</span>1 </span><span id="S5.SS2.SSS1.6.2" class="ltx_text ltx_font_bold">Novel Asynchronous System</span>
</h4>

<div id="S5.SS2.SSS1.p1" class="ltx_para">
<p id="S5.SS2.SSS1.p1.1" class="ltx_p">Even though the 6G network can bring the advantage of extremely low latency to the FL systems, the communication overhead is still the bottleneck of the FL systems being widely used <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>. As described in Section <a href="#S4.SS1.SSS1" title="IV-A1 Communication-efficient FL: System Level ‣ IV-A Communication-efficient Federated Learning For 6G ‣ IV Advanced Federated Learning Methods For 6G ‣ Federated Learning for 6G Communications: Challenges, Methods, and Future Directions" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">IV-A</span>1</span></a>, the two most commonly studied communication optimization schemes in distributed machine learning systems are the batch synchronous method and the asynchronous method (where the delay of the model update is assumed to be bounded) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>. Indeed, asynchronous communication schemes involve scheduler, coordinator, worker, and updater, so there are several optimization problems for these roles that can be considered in the future: i) how the scheduler reasonably schedule the communication and computing resources in the systems; ii) how the coordinator efficiently control the working state and idle state of the devices; iii) how workers and updaters optimize hyperparameters for model updates. These optimization problems are worth studying in future work in order to develop novel asynchronous systems.</p>
</div>
</section>
<section id="S5.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S5.SS2.SSS2.5.1.1" class="ltx_text">V-B</span>2 </span><span id="S5.SS2.SSS2.6.2" class="ltx_text ltx_font_bold">Neural Architecture Search</span>
</h4>

<div id="S5.SS2.SSS2.p1" class="ltx_para">
<p id="S5.SS2.SSS2.p1.1" class="ltx_p">The structure of the current FL models is generally predefined, but this predefined architecture may not be the best choice because it may not be suitable for non-independent and identical distribution (non-IID) data. Therefore, the Neural Architecture Search (NAS)-based Automating FL (AutoFL) schemes may be a promising solution to this problem. For example, a study in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite> proposed a federated NAS (FedNAS) algorithm to help distributed devices collaborate to find a better architecture with higher accuracy. NAS provides opportunities for seeking a better FL model architecture in the future.</p>
</div>
</section>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS3.5.1.1" class="ltx_text">V-C</span> </span><span id="S5.SS3.6.2" class="ltx_text ltx_font_italic">Towards Incentive Federated Learning</span>
</h3>

<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.1" class="ltx_p">Existing studies mainly focus on enhancing the performance of FL algorithms, e.g., accuracy and training time. Nevertheless, an optimistic assumption, that all the data owners are willing to join the FL anytime and anywhere, is not practical in 6G scenarios with massive self-interest devices. As a result, incentive mechanisms for honest and active participation are a core and urgent research topic <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib25" title="" class="ltx_ref">25</a>, <a href="#bib.bib43" title="" class="ltx_ref">43</a>, <a href="#bib.bib44" title="" class="ltx_ref">44</a>, <a href="#bib.bib45" title="" class="ltx_ref">45</a>, <a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite>.
Some interesting topics include: i) Due to information asymmetric between task publishers and participating devices, e.g., information about time-varying available resources, unfixed working periods and changeable participation willingness, it is still an open issue to design effective online-learning based incentive mechanisms to remove the impacts of both information asymmetric and time-varying factors, and also ensure efficient federated learning in 6G scenarios; ii) Considering heterogeneous and massive devices with diverse hardware equipment in 6G scenarios, the data quality of the devices is diverse. But the data quality plays an important role in learning performance. It is a challenging problem how to design data quality-based incentive mechanisms to motivate more devices with high-quality data to participate in federated learning and obtain higher rewards for their high-quality data contributions, thus improving both the system reliability and the learning performance <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib43" title="" class="ltx_ref">43</a>, <a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite>.</p>
</div>
</section>
<section id="S5.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS4.5.1.1" class="ltx_text">V-D</span> </span><span id="S5.SS4.6.2" class="ltx_text ltx_font_italic">Towards Personalized Federated Learning</span>
</h3>

<div id="S5.SS4.p1" class="ltx_para">
<p id="S5.SS4.p1.1" class="ltx_p">It is challenging for the FL system in the 6G network to provide users with personalized services. Prior studies <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>, <a href="#bib.bib48" title="" class="ltx_ref">48</a>, <a href="#bib.bib49" title="" class="ltx_ref">49</a>, <a href="#bib.bib50" title="" class="ltx_ref">50</a>]</cite> adopt different personalized techniques to provide users with real-time personalized services, which is a solid step towards personalized FL. However, personalized FL still faces challenges from non-IID data, system heterogeneity, and network heterogeneity. Personalized service is a very important part of the human-centric 6G services. Therefore, it is an interesting and meaningful topic for FL to seek novel ways to address the above challenges.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span id="S6.1.1" class="ltx_text ltx_font_smallcaps">Conclusion</span>
</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">In this article, we provided an overview of integrating federated learning into 6G communications. We discussed the requirements of 6G communication and core challenges of federated learning for 6G applications. For the above challenges, we provided a comprehensive introduction of the emerging advanced federated learning methods for 6G communications, which including communication-efficient federated learning, secure federated learning, and effective federated learning. Finally, we outlined out a handful of open problems and directions worth future research efforts.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
K. B. Letaief, W. Chen, Y. Shi, J. Zhang, and Y.-J. A. Zhang, “The roadmap to
6g: Ai empowered wireless networks,” <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">IEEE Communications Magazine</em>,
vol. 57, no. 8, pp. 84–90, 2019.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Y. Xiao, G. Shi, and M. Krunz, “Towards ubiquitous ai in 6g with federated
learning,” <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2004.13563</em>, 2020.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
K. David and H. Berndt, “6g vision and requirements: Is there any need for
beyond 5g?” <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">IEEE Vehicular Technology Magazine</em>, vol. 13, no. 3, pp.
72–80, 2018.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
S. Dang, O. Amin, B. Shihada, and M.-S. Alouini, “What should 6g be?”
<em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Nature Electronics</em>, vol. 3, no. 1, pp. 20–29, 2020.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
S. Niknam, H. S. Dhillon, and J. H. Reed, “Federated learning for wireless
communications: Motivation, opportunities and challenges,” <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">arXiv
preprint arXiv:1908.06847</em>, 2019.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
J. Konečnỳ, H. B. McMahan, F. X. Yu, P. Richtárik, A. T. Suresh,
and D. Bacon, “Federated learning: Strategies for improving communication
efficiency,” <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1610.05492</em>, 2016.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
J. Kang, Z. Xiong, D. Niyato, S. Xie, and J. Zhang, “Incentive mechanism for
reliable federated learning: A joint optimization approach to combining
reputation and contract theory,” <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">IEEE Internet of Things Journal</em>,
vol. 6, no. 6, pp. 10 700–10 714, 2019.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Y. Shi, K. Yang, T. Jiang, J. Zhang, and K. B. Letaief,
“Communication-efficient edge ai: Algorithms and systems,” <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">arXiv
preprint arXiv:2002.09668</em>, 2020.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Y. Liu, J. Peng, J. Kang, A. M. Iliyasu, D. Niyato, and A. A. A. El-Latif, “A
secure federated learning framework for 5g networks,” <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:2005.05752</em>, 2020.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Y. Lin, S. Han, H. Mao, Y. Wang, and B. Dally, “Deep gradient compression:
Reducing the communication bandwidth for distributed training,” in
<em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations</em>, 2018. [Online].
Available: <a target="_blank" href="https://openreview.net/forum?id=SkhQHMW0W" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openreview.net/forum?id=SkhQHMW0W</a>

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
T. Huang, W. Yang, J. Wu, J. Ma, X. Zhang, and D. Zhang, “A survey on green 6g
network: Architecture and technologies,” <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">IEEE Access</em>, vol. 7, pp.
175 758–175 768, 2019.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
R. Long, H. Guo, L. Zhang, and Y.-C. Liang, “Full-duplex backscatter
communications in symbiotic radio systems,” <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">IEEE Access</em>, vol. 7, pp.
21 597–21 608, 2019.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
G. Yang, Q. Zhang, and Y.-C. Liang, “Cooperative ambient backscatter
communications for green internet-of-things,” <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">IEEE Internet of Things
Journal</em>, vol. 5, no. 2, pp. 1116–1130, 2018.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
T. Li, A. K. Sahu, A. Talwalkar, and V. Smith, “Federated learning:
Challenges, methods, and future directions,” <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">IEEE Signal Processing
Magazine</em>, vol. 37, no. 3, pp. 50–60, 2020.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
J. Kang, Z. Xiong, D. Niyato, Y. Zou, Y. Zhang, and M. Guizani, “Reliable
federated learning for mobile networks,” <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">IEEE Wireless
Communications</em>, vol. 27, no. 2, pp. 72–80, 2020.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
M. Giordani, M. Polese, M. Mezzavilla, S. Rangan, and M. Zorzi, “Toward 6g
networks: Use cases and technologies,” <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">IEEE Communications Magazine</em>,
vol. 58, no. 3, pp. 55–61, 2020.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Z. Zhang, Y. Xiao, Z. Ma, M. Xiao, Z. Ding, X. Lei, G. K. Karagiannidis, and
P. Fan, “6g wireless networks: Vision, requirements, architecture, and key
technologies,” <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">IEEE Vehicular Technology Magazine</em>, vol. 14, no. 3,
pp. 28–41, 2019.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
S. Nayak and R. Patgiri, “6g communication technology: A vision on intelligent
healthcare,” <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2005.07532</em>, 2020.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
M. Giordani, M. Polese, M. Mezzavilla, S. Rangan, and M. Zorzi, “Toward 6g
networks: Use cases and technologies,” <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">IEEE Communications Magazine</em>,
vol. 58, no. 3, pp. 55–61, 2020.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Y. Liu, J. J. Q. Yu, J. Kang, D. Niyato, and S. Zhang,
“Privacy-preserving traffic flow prediction: A federated learning
approach,” <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">IEEE Internet of Things Journal</em>, pp. 1–1, 2020.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
S. Gu, J. Jiao, Z. Huang, S. Wu, and Q. Zhang, “Arma-based adaptive
coding transmission over millimeter-wave channel for integrated
satellite-terrestrial networks,” <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">IEEE Access</em>, vol. 6, pp.
21 635–21 645, 2018.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
M. Chen, Z. Yang, W. Saad, C. Yin, H. V. Poor, and S. Cui, “A joint learning
and communications framework for federated learning over wireless networks,”
<em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1909.07972</em>, 2019.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
A. Souri, A. Hussien, M. Hoseyninezhad, and M. Norouzi, “A systematic review
of iot communication strategies for an efficient smart environment,”
<em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">Transactions on Emerging Telecommunications Technologies</em>, p. e3736,
2019.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
L. U. Khan, N. H. Tran, S. R. Pandey, W. Saad, Z. Han, M. N. Nguyen, and C. S.
Hong, “Federated learning for edge networks: Resource optimization and
incentive mechanism,” <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1911.05642</em>, 2019.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
J. Kang, Z. Xiong, D. Niyato, H. Yu, Y.-C. Liang, and D. I. Kim, “Incentive
design for efficient federated learning in mobile networks: A contract theory
approach,” in <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">2019 IEEE VTS Asia Pacific Wireless Communications
Symposium (APWCS)</em>.   IEEE, 2019, pp.
1–5.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
E. Jeong, S. Oh, H. Kim, J. Park, M. Bennis, and S.-L. Kim,
“Communication-efficient on-device machine learning: Federated distillation
and augmentation under non-iid private data,” <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:1811.11479</em>, 2018.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
N. H. Tran, W. Bao, A. Zomaya, N. M. NH, and C. S. Hong, “Federated learning
over wireless networks: Optimization model design and analysis,” in
<em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">IEEE INFOCOM 2019-IEEE Conference on Computer Communications</em>.   IEEE, 2019, pp. 1387–1395.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
K. Bonawitz, H. Eichner, W. Grieskamp, D. Huba, A. Ingerman, V. Ivanov, C. M.
Kiddon, J. Konečný, S. Mazzocchi, B. McMahan, T. V. Overveldt, D. Petrou,
D. Ramage, and J. Roselander, “Towards federated learning at scale: System
design,” in <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">SysML 2019</em>, 2019, to appear. [Online]. Available:
<a target="_blank" href="https://arxiv.org/abs/1902.01046" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/1902.01046</a>

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
A. F. Atiya and A. G. Parlos, “New results on recurrent network training:
unifying the algorithms and accelerating convergence,” <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">IEEE
transactions on neural networks</em>, vol. 11, no. 3, pp. 697–709, 2000.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
Z. Wang, M. Song, Z. Zhang, Y. Song, Q. Wang, and H. Qi, “Beyond inferring
class representatives: User-level privacy leakage from federated learning,”
in <em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">IEEE INFOCOM 2019-IEEE Conference on Computer Communications</em>.   IEEE, 2019, pp. 2512–2520.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
L. Zhu, Z. Liu, and S. Han, “Deep leakage from gradients,” in <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">Advances
in Neural Information Processing Systems</em>, 2019, pp. 14 747–14 756.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
L. Li, H. Xiong, Z. Guo, J. Wang, and C.-Z. Xu, “Smartpc: Hierarchical pace
control in real-time federated learning system,” in <em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">2019 IEEE
Real-Time Systems Symposium (RTSS)</em>.   IEEE, 2019, pp. 406–418.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
A. Portnoy and D. Hendler, “Towards realistic byzantine-robust federated
learning,” <em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2004.04986</em>, 2020.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
S. Guo, T. Zhang, X. Xie, L. Ma, T. Xiang, and Y. Liu, “Towards
byzantine-resilient learning in decentralized systems,” <em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:2002.08569</em>, 2020.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
F. Ang, L. Chen, N. Zhao, Y. Chen, W. Wang, and F. R. Yu, “Robust federated
learning with noisy communication,” <em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on
Communications</em>, 2020.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
M. Abadi, A. Chu, I. Goodfellow, H. B. McMahan, I. Mironov, K. Talwar, and
L. Zhang, “Deep learning with differential privacy,” in <em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">Proceedings
of the 2016 ACM SIGSAC Conference on Computer and Communications Security</em>,
2016, pp. 308–318.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
R. C. Geyer, T. Klein, and M. Nabi, “Differentially private federated
learning: A client level perspective,” <em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:1712.07557</em>, 2017.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
Y. Huang, Y. Su, S. Ravi, Z. Song, S. Arora, and K. Li, “Privacy-preserving
learning via deep net pruning,” <em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2003.01876</em>,
2020.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
T.-D. Cao, T. Truong-Huu, H. Tran, and K. Tran, “A federated learning
framework for privacy-preserving and parallel training,” <em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">arXiv
preprint arXiv:2001.09782</em>, 2020.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
Z. Jiang, A. Balu, C. Hegde, and S. Sarkar, “Collaborative deep learning in
fixed topology networks,” in <em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing
Systems</em>, 2017, pp. 5904–5914.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
T. Li, M. Sanjabi, A. Beirami, and V. Smith, “Fair resource allocation in
federated learning,” in <em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning
Representations</em>, 2020. [Online]. Available:
<a target="_blank" href="https://openreview.net/forum?id=ByexElSYDr" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openreview.net/forum?id=ByexElSYDr</a>

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
C. He, M. Annavaram, and S. Avestimehr, “Fednas: Federated deep learning via
neural architecture search,” <em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2004.08546</em>, 2020.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
L. U. Khan, N. H. Tran, S. R. Pandey, W. Saad, Z. Han, M. N. Nguyen, and C. S.
Hong, “Federated learning for edge networks: Resource optimization and
incentive mechanism,” <em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1911.05642</em>, 2019.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
J. Weng, J. Weng, J. Zhang, M. Li, Y. Zhang, and W. Luo, “Deepchain: Auditable
and privacy-preserving deep learning with blockchain-based incentive,”
<em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Dependable and Secure Computing</em>, 2019.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
Y. Zhan, P. Li, Z. Qu, D. Zeng, and S. Guo, “A learning-based incentive
mechanism for federated learning,” <em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">IEEE Internet of Things Journal</em>,
2020.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
H. Yu, Z. Liu, Y. Liu, T. Chen, M. Cong, X. Weng, D. Niyato, and Q. Yang, “A
fairness-aware incentive scheme for federated learning,” in
<em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society</em>,
2020, pp. 393–399.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
A. Fallah, A. Mokhtari, and A. Ozdaglar, “Personalized federated learning: A
meta-learning approach,” <em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2002.07948</em>, 2020.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
Q. Wu, K. He, and X. Chen, “Personalized federated learning for
intelligent iot applications: A cloud-edge based framework,” <em id="bib.bib48.1.1" class="ltx_emph ltx_font_italic">IEEE Open
Journal of the Computer Society</em>, pp. 1–1, 2020.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
R. Hu, Y. Guo, H. Li, Q. Pei, and Y. Gong, “Personalized federated learning
with differential privacy,” <em id="bib.bib49.1.1" class="ltx_emph ltx_font_italic">IEEE Internet of Things Journal</em>, 2020.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
V. Kulkarni, M. Kulkarni, and A. Pant, “Survey of personalization techniques
for federated learning,” <em id="bib.bib50.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2003.08673</em>, 2020.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2006.02930" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2006.02931" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2006.02931">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2006.02931" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2006.02932" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Tue Feb 27 04:47:50 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
