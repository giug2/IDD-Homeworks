<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>MLRS-PDS: A Meta-learning recommendation of dynamic ensemble selection pipelines</title>
<!--Generated on Wed Jul 10 10:29:16 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="
Machine learning,  Ensemble of classifiers,  dynamic ensemble selection,  Meta-learning,  Data complexity,  AutoML
" lang="en" name="keywords"/>
<base href="/html/2407.07528v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#S1" title="In MLRS-PDS: A Meta-learning recommendation of dynamic ensemble selection pipelines"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">I </span><span class="ltx_text ltx_font_smallcaps">Introduction</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#S2" title="In MLRS-PDS: A Meta-learning recommendation of dynamic ensemble selection pipelines"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">II </span><span class="ltx_text ltx_font_smallcaps">Related work</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#S3" title="In MLRS-PDS: A Meta-learning recommendation of dynamic ensemble selection pipelines"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">III </span><span class="ltx_text ltx_font_smallcaps">The Proposed Multi-label meta-learning recommendation (MLRS)</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#S3.SS1" title="In III The Proposed Multi-label meta-learning recommendation (MLRS) ‣ MLRS-PDS: A Meta-learning recommendation of dynamic ensemble selection pipelines"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-A</span> </span><span class="ltx_text ltx_font_italic">MLRS Training process</span></span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#S3.SS1.SSS1" title="In III-A MLRS Training process ‣ III The Proposed Multi-label meta-learning recommendation (MLRS) ‣ MLRS-PDS: A Meta-learning recommendation of dynamic ensemble selection pipelines"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-A</span>1 </span>Meta-features</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#S3.SS2" title="In III The Proposed Multi-label meta-learning recommendation (MLRS) ‣ MLRS-PDS: A Meta-learning recommendation of dynamic ensemble selection pipelines"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-B</span> </span><span class="ltx_text ltx_font_italic">Meta-learning recommendation</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#S4" title="In MLRS-PDS: A Meta-learning recommendation of dynamic ensemble selection pipelines"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">IV </span><span class="ltx_text ltx_font_smallcaps">Experimental setup</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#S4.SS1" title="In IV Experimental setup ‣ MLRS-PDS: A Meta-learning recommendation of dynamic ensemble selection pipelines"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-A</span> </span><span class="ltx_text ltx_font_italic">Pool generation schemes</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#S4.SS2" title="In IV Experimental setup ‣ MLRS-PDS: A Meta-learning recommendation of dynamic ensemble selection pipelines"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-B</span> </span><span class="ltx_text ltx_font_italic">DS Techniques</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#S4.SS3" title="In IV Experimental setup ‣ MLRS-PDS: A Meta-learning recommendation of dynamic ensemble selection pipelines"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-C</span> </span><span class="ltx_text ltx_font_italic">Datasets</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#S4.SS4" title="In IV Experimental setup ‣ MLRS-PDS: A Meta-learning recommendation of dynamic ensemble selection pipelines"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-D</span> </span><span class="ltx_text ltx_font_italic">Experimental setup</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#S4.SS5" title="In IV Experimental setup ‣ MLRS-PDS: A Meta-learning recommendation of dynamic ensemble selection pipelines"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-E</span> </span><span class="ltx_text ltx_font_italic">Meta-learner definition</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#S5" title="In MLRS-PDS: A Meta-learning recommendation of dynamic ensemble selection pipelines"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">V </span><span class="ltx_text ltx_font_smallcaps">Results</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#S5.SS1" title="In V Results ‣ MLRS-PDS: A Meta-learning recommendation of dynamic ensemble selection pipelines"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-A</span> </span><span class="ltx_text ltx_font_italic">Scenario I: meta-learning for recommending the best pool generation scheme</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#S5.SS2" title="In V Results ‣ MLRS-PDS: A Meta-learning recommendation of dynamic ensemble selection pipelines"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-B</span> </span><span class="ltx_text ltx_font_italic">Scenario II: meta-learning for recommending the best DS model</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#S5.SS3" title="In V Results ‣ MLRS-PDS: A Meta-learning recommendation of dynamic ensemble selection pipelines"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-C</span> </span><span class="ltx_text ltx_font_italic">Scenario III: meta-learning for recommending the pool and DS algorithm</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#S5.SS4" title="In V Results ‣ MLRS-PDS: A Meta-learning recommendation of dynamic ensemble selection pipelines"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-D</span> </span><span class="ltx_text ltx_font_italic">Recommendation analysis</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#S6" title="In MLRS-PDS: A Meta-learning recommendation of dynamic ensemble selection pipelines"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">VI </span><span class="ltx_text ltx_font_smallcaps">Conclusion</span></span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">MLRS-PDS: A Meta-learning recommendation of dynamic ensemble selection pipelines
<br class="ltx_break"/>
</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Hesam Jalalian and Rafael M. O. Cruz
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">École de Technologie Supérieure, Université du Québec, Montréal (QC), Canada
<br class="ltx_break"/>Email: hesam.jalalian.1@ens.etsmtl.ca, rafael.menelau-cruz@etsmtl.ca
</span></span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id1.id1">Dynamic Selection (DS), where base classifiers are chosen from a classifier’s pool for each new instance at test time, has shown to be highly effective in pattern recognition.
However, instability and redundancy in the classifier pools can impede computational efficiency and accuracy in dynamic ensemble selection. This paper introduces a meta-learning recommendation system (MLRS) to recommend the optimal pool generation scheme for DES methods tailored to individual datasets. The system employs a meta-model built from dataset meta-features to predict the most suitable pool generation scheme and DES method for a given dataset. Through an extensive experimental study encompassing 288 datasets, we demonstrate that this meta-learning recommendation system outperforms traditional fixed pool or DES method selection strategies, highlighting the efficacy of a meta-learning approach in refining DES method selection. The source code, datasets, and supplementary results can be found in this project’s GitHub repository: <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://github.com/Menelau/MLRS-PDS</span>.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
Machine learning, Ensemble of classifiers, dynamic ensemble selection, Meta-learning, Data complexity, AutoML

</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span class="ltx_text ltx_font_smallcaps" id="S1.1.1">Introduction</span>
</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Automated decision-making frequently utilizes Multiple Classifier Systems (MCS), wherein individual classifiers’ collective predictions enhance overall prediction accuracy <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib1" title="">1</a>]</cite>. The process of MCS unfolds in three key stages: generation, involving the formation of a pool of classifiers; selection, which entails either a static or dynamic choice among these classifiers; and aggregation, where the outputs from the selected experts are combined to formulate the final decision <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib2" title="">2</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Dynamic selection techniques (DS) within Multiple Classifier Systems (MCS) are characterized by their approach of selecting classifiers during test time, considering the characteristics of each specific instance to improve prediction accuracy. Such methods are based on the assumption that each base classifier is an expert in a different local region of the feature space, and only the classifiers that are experts in the local region where the test instance is located should be used to predict its label <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib2" title="">2</a>]</cite>. They operate under the locality assumption, suggesting that similar instances should share the same set of expert classifiers <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib3" title="">3</a>]</cite>. DS has become increasingly prominent in various pattern recognition contexts. These include imbalanced learning <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib4" title="">4</a>]</cite>, handling noisy data <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib5" title="">5</a>]</cite>, and adapting to concept drift <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib6" title="">6</a>]</cite>, showing its broad impact.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">For optimal performance, DS requires a well-suited pool of classifiers that effectively covers the entire feature space and that for each instance there exists, enabling the DS method to accurately identify the best classifiers for any given instance <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib7" title="">7</a>]</cite>. However, the literature offers limited guidance on selecting or training these classifier pools specifically for DS algorithms, with only a few studies addressing this gap <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib8" title="">8</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib9" title="">9</a>]</cite>. While several DS studies have utilized conventional pool generation schemes such as Bagging <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib10" title="">10</a>]</cite>, Boosting <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib11" title="">11</a>]</cite> and Random Forests <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib12" title="">12</a>]</cite>, these methods were originally designed for static combinations and may not fully align with the local assumptions of DS models, potentially leading to gaps in expert coverage across the feature space <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib13" title="">13</a>]</cite>. Current research predominantly focuses on refining competence level estimation, ensemble selection, or defining regions of competence to boost performance. This trend often suggests an assumption that classifier pools generated by classical ensemble techniques like Bagging or Boosting are universally effective for all classification challenges, ignoring the crucial role played by the composition of the classifier pool.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">We hypothesize that the pool generation scheme plays a crucial role in the performance of DS methods and should not be neglected. Furthermore, the choice of pool generation scheme must consider the dataset’s properties and the dynamic selection technique used for classification since distinct DS techniques are based on different local assumptions. Specifically, this research addresses the following question: <em class="ltx_emph ltx_font_italic" id="S1.p4.1.1">What are the consequences of neglecting the selection of either the DS method or the pool generation scheme on the performance of the dynamic selection pipeline? Furthermore, is it possible to automate this selection process?</em></p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">In this paper, we propose a novel meta-learning recommendation system (MLRS) designed to enhance the performance of Dynamic Selection (DS) methods while reducing the complexity of finding optimal solutions. It employs meta-learning to extract dataset characteristics (i.e., meta-features) alongside the performance evaluation data from various classifier pools used as input for DS algorithms to learn how to recommend the best pool and/or DS algorithm given a new dataset.</p>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">We propose three distinct MLRS variants operating in three scenarios: 1) MLRS-P that recommends the best pool generation scheme based on the problem’s characteristics and a user-specified DS model; 2) MLRS-DS that recommends the most effective DS method for a given problem, conditioned on a predefined existing pool specified; and 3) MLRS-PDS that automatically recommend the optimal (DS, Pool) pair solely based on the problem characteristics. MLRS-PDS first identifies the most suitable pool of classifiers according to the dataset characteristics. Then, it uses the information from the selected pool to condition the more suitable DS model recommendation. Thereby offering a fully automated meta-learning recommendation model for dynamic selection pipelines without requiring expert intervention.</p>
</div>
<div class="ltx_para" id="S1.p7">
<p class="ltx_p" id="S1.p7.1">To assess the efficacy of our proposed MLRS, we carried out extensive experiments using 288 datasets with varied complexity levels. The results consistently showed that relying on a fixed combination leads to sub-optimal results. Also, one needs to take into account the dependencies between data characteristics, the pool generation scheme, and the DS model, as the best choices can significantly change according to these parameters. In addition, our MLRS, in all its formulations, can recommend optimal solutions, being much more efficient than existing baselines.</p>
</div>
<div class="ltx_para" id="S1.p8">
<p class="ltx_p" id="S1.p8.1">The contributions of this work are summarized as follows:</p>
</div>
<div class="ltx_para" id="S1.p9">
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">It highlights the limitations of relying on either a fixed pool generation scheme or a fixed DS method, emphasizing the need to carefully optimize these steps.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">We propose a Meta-Learning Recommendation System (MLRS) for various use cases: recommending the most suitable pool generation scheme and DS method based on the unique characteristics of each dataset.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">We demonstrate that our proposed MLRS-PDS, which recommends both the pool generation scheme and the DS method simultaneously, leads to more optimal solutions than fixing either the pool or the DS method.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i4.p1">
<p class="ltx_p" id="S1.I1.i4.p1.1">An extensive analysis was conducted across 288 datasets with varying levels of complexity, revealing the advantages of our approach over traditional fixed pool and DS method selection strategies.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span class="ltx_text ltx_font_smallcaps" id="S2.1.1">Related work</span>
</h2>
<div class="ltx_para ltx_noindent" id="S2.p1">
<p class="ltx_p" id="S2.p1.1"><span class="ltx_text ltx_font_bold" id="S2.p1.1.1">Pool generation scheme.</span> The performance of DS methods hinges on a proper pool of classifiers, ensuring a diverse and complementary set of models is available that covers the whole feature space <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib14" title="">14</a>]</cite>. Pool generation can be broadly categorized into global and local perspectives. The Global pool generation scheme employs techniques that take a broad view of the problem and try to generate classifiers that model the whole data distribution. They initially proposed for static selection methods such as Bagging <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib10" title="">10</a>]</cite>, Boosting <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib11" title="">11</a>]</cite>, and Random Forests <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib15" title="">15</a>]</cite>. In contrast, local pool generation schemes involve techniques that explicitly train classifiers that focus on modeling local regions of the feature space. Thus, methods with expertise in distinct feature space regions are obtained. These include Forest of Local Trees (FLT)<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib16" title="">16</a>]</cite> and the Locally Independent Training (LIT) technique<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib17" title="">17</a>]</cite>. While most DS research favors global schemes, local perspective utilization is less common.</p>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">Monteiro et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib9" title="">9</a>]</cite> introduced a pool generation method focusing on diversity from data complexity and classifier decisions. This approach assesses the variability of complexity measures and employs an evolutionary algorithm to optimize complexity and decision diversity. The method trains classifiers on subsets of varying complexity and aims to produce classifiers with diverse error types. This global perspective pool generation method positively impacts DS methods by generating more diverse local experts through subsets of varying complexities. However, the framework lacks an automated process for selecting a base model suitable for the specific dataset. Moreover, the generated pool is not optimized for a particular DS method.</p>
</div>
<div class="ltx_para" id="S2.p3">
<p class="ltx_p" id="S2.p3.1">An online pool generation method <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib8" title="">8</a>]</cite> creates local perspective pools for challenging feature space regions, employing specialized classifiers for instances prone to misclassification. This Local Pool (LP) approach uses Dynamic Classifier Selection (DCS) techniques to select competent classifiers for each instance located in class overlap regions. If a query instance falls in a complex region, an LP is dynamically generated for labeling; otherwise, a simple nearest neighbors rule is applied. These approaches, however, do not explore meta-learning, with the former focusing on a global pool generation perspective and the latter focusing on online learning and limited to DCS models.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.p4">
<p class="ltx_p" id="S2.p4.1"><span class="ltx_text ltx_font_bold" id="S2.p4.1.1">Meta-learning.</span> Conventional approaches for the algorithm selection problem <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib18" title="">18</a>]</cite> rely on extensive expert knowledge and trial and error. However, they are extremely limited as trial and error is time-consuming and computationally expensive, making it impossible to cover all possible algorithm combinations. This problem led to a growing interest in machine learning systems that automate algorithm selection to address these challenges. One such approach is meta-learning-based algorithm recommendation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib19" title="">19</a>]</cite>, which treats algorithm selection as a typical learning problem. In meta-learning, dataset characteristics (meta-features) are the independent variables, and the target variable corresponds to the estimation of algorithm performance. This approach has found success in various domains, including classification <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib20" title="">20</a>]</cite>, clustering <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib21" title="">21</a>]</cite>, and regression <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib22" title="">22</a>]</cite>. By automating algorithm selection, these systems significantly reduce the computational cost required to tune solutions and empower non-experts to apply machine learning more independently <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib23" title="">23</a>]</cite>.</p>
</div>
<figure class="ltx_figure" id="S2.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="200" id="S2.F1.g1" src="x1.png" width="747"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Overview of the meta-training process. In the first step, the meta-features, <math alttext="mf" class="ltx_Math" display="inline" id="S2.F1.6.m1.1"><semantics id="S2.F1.6.m1.1b"><mrow id="S2.F1.6.m1.1.1" xref="S2.F1.6.m1.1.1.cmml"><mi id="S2.F1.6.m1.1.1.2" xref="S2.F1.6.m1.1.1.2.cmml">m</mi><mo id="S2.F1.6.m1.1.1.1" xref="S2.F1.6.m1.1.1.1.cmml">⁢</mo><mi id="S2.F1.6.m1.1.1.3" xref="S2.F1.6.m1.1.1.3.cmml">f</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.F1.6.m1.1c"><apply id="S2.F1.6.m1.1.1.cmml" xref="S2.F1.6.m1.1.1"><times id="S2.F1.6.m1.1.1.1.cmml" xref="S2.F1.6.m1.1.1.1"></times><ci id="S2.F1.6.m1.1.1.2.cmml" xref="S2.F1.6.m1.1.1.2">𝑚</ci><ci id="S2.F1.6.m1.1.1.3.cmml" xref="S2.F1.6.m1.1.1.3">𝑓</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F1.6.m1.1d">mf</annotation><annotation encoding="application/x-llamapun" id="S2.F1.6.m1.1e">italic_m italic_f</annotation></semantics></math>, are extracted from the training datasets to generate its representation <math alttext="x^{\prime}_{i}" class="ltx_Math" display="inline" id="S2.F1.7.m2.1"><semantics id="S2.F1.7.m2.1b"><msubsup id="S2.F1.7.m2.1.1" xref="S2.F1.7.m2.1.1.cmml"><mi id="S2.F1.7.m2.1.1.2.2" xref="S2.F1.7.m2.1.1.2.2.cmml">x</mi><mi id="S2.F1.7.m2.1.1.3" xref="S2.F1.7.m2.1.1.3.cmml">i</mi><mo id="S2.F1.7.m2.1.1.2.3" xref="S2.F1.7.m2.1.1.2.3.cmml">′</mo></msubsup><annotation-xml encoding="MathML-Content" id="S2.F1.7.m2.1c"><apply id="S2.F1.7.m2.1.1.cmml" xref="S2.F1.7.m2.1.1"><csymbol cd="ambiguous" id="S2.F1.7.m2.1.1.1.cmml" xref="S2.F1.7.m2.1.1">subscript</csymbol><apply id="S2.F1.7.m2.1.1.2.cmml" xref="S2.F1.7.m2.1.1"><csymbol cd="ambiguous" id="S2.F1.7.m2.1.1.2.1.cmml" xref="S2.F1.7.m2.1.1">superscript</csymbol><ci id="S2.F1.7.m2.1.1.2.2.cmml" xref="S2.F1.7.m2.1.1.2.2">𝑥</ci><ci id="S2.F1.7.m2.1.1.2.3.cmml" xref="S2.F1.7.m2.1.1.2.3">′</ci></apply><ci id="S2.F1.7.m2.1.1.3.cmml" xref="S2.F1.7.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F1.7.m2.1d">x^{\prime}_{i}</annotation><annotation encoding="application/x-llamapun" id="S2.F1.7.m2.1e">italic_x start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>. In step 2, the set of pools and DS methods are evaluated. Then, based on the highest accuracy, the meta-target, <math alttext="y^{\prime}" class="ltx_Math" display="inline" id="S2.F1.8.m3.1"><semantics id="S2.F1.8.m3.1b"><msup id="S2.F1.8.m3.1.1" xref="S2.F1.8.m3.1.1.cmml"><mi id="S2.F1.8.m3.1.1.2" xref="S2.F1.8.m3.1.1.2.cmml">y</mi><mo id="S2.F1.8.m3.1.1.3" xref="S2.F1.8.m3.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S2.F1.8.m3.1c"><apply id="S2.F1.8.m3.1.1.cmml" xref="S2.F1.8.m3.1.1"><csymbol cd="ambiguous" id="S2.F1.8.m3.1.1.1.cmml" xref="S2.F1.8.m3.1.1">superscript</csymbol><ci id="S2.F1.8.m3.1.1.2.cmml" xref="S2.F1.8.m3.1.1.2">𝑦</ci><ci id="S2.F1.8.m3.1.1.3.cmml" xref="S2.F1.8.m3.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F1.8.m3.1d">y^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S2.F1.8.m3.1e">italic_y start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT</annotation></semantics></math>, is defined (step 3). In step 4, the meta-dataset, <math alttext="MT" class="ltx_Math" display="inline" id="S2.F1.9.m4.1"><semantics id="S2.F1.9.m4.1b"><mrow id="S2.F1.9.m4.1.1" xref="S2.F1.9.m4.1.1.cmml"><mi id="S2.F1.9.m4.1.1.2" xref="S2.F1.9.m4.1.1.2.cmml">M</mi><mo id="S2.F1.9.m4.1.1.1" xref="S2.F1.9.m4.1.1.1.cmml">⁢</mo><mi id="S2.F1.9.m4.1.1.3" xref="S2.F1.9.m4.1.1.3.cmml">T</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.F1.9.m4.1c"><apply id="S2.F1.9.m4.1.1.cmml" xref="S2.F1.9.m4.1.1"><times id="S2.F1.9.m4.1.1.1.cmml" xref="S2.F1.9.m4.1.1.1"></times><ci id="S2.F1.9.m4.1.1.2.cmml" xref="S2.F1.9.m4.1.1.2">𝑀</ci><ci id="S2.F1.9.m4.1.1.3.cmml" xref="S2.F1.9.m4.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F1.9.m4.1d">MT</annotation><annotation encoding="application/x-llamapun" id="S2.F1.9.m4.1e">italic_M italic_T</annotation></semantics></math>, is constructed, and then it is used to train a meta-model, <math alttext="\lambda" class="ltx_Math" display="inline" id="S2.F1.10.m5.1"><semantics id="S2.F1.10.m5.1b"><mi id="S2.F1.10.m5.1.1" xref="S2.F1.10.m5.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S2.F1.10.m5.1c"><ci id="S2.F1.10.m5.1.1.cmml" xref="S2.F1.10.m5.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.F1.10.m5.1d">\lambda</annotation><annotation encoding="application/x-llamapun" id="S2.F1.10.m5.1e">italic_λ</annotation></semantics></math> (Step 5)</figcaption>
</figure>
<div class="ltx_para" id="S2.p5">
<p class="ltx_p" id="S2.p5.1">Several works in meta-learning have been conducted recently, focusing on recommending different aspects of a machine-learning pipeline. In <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib24" title="">24</a>]</cite>, the authors proposed a meta-learning framework to recommend the hyperparameters of an SVM classifier. Garcia et al.<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib20" title="">20</a>]</cite> explored the use of complexity measures in meta-learning to differentiate classifier performance effectively. Their study demonstrated that it is possible to accurately predict expected classifier performances using meta-regressors and use such information to recommend the most appropriate models. Focusing on the preprocessing steps of an ML solution, Amorim et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib25" title="">25</a>]</cite> proposed a meta-learning framework called Meta-Scaler to recommend the most appropriate scaling-transform technique according to the dataset characteristics and the classifier specified by the user. Building on this idea of meta-learning in the context of ensemble models, Pinto et al.<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib26" title="">26</a>]</cite> proposed an automated bagging system using a meta-learning-based ranking approach learned from metadata. However, their focus was primarily on using bagging as a global perspective pool generation scheme without delving into the potential of local perspective pool generation schemes.</p>
</div>
<div class="ltx_para" id="S2.p6">
<p class="ltx_p" id="S2.p6.1">Regarding meta-learning recommendations for DS, the only work that can be found is based on meta-regression models for predicting the number of estimators required when applying a DS model <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib27" title="">27</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib28" title="">28</a>]</cite>, demonstrating that often the best classification performance can be obtained by generating different pool sizes. However, this method is based on a fixed Bagging technique as a pool generation scheme and can only predict the pool size, thus leading to sub-optimal results. In contrast, our proposal recommends the pool generation algorithm instead of the pool size since the pool size does not significantly impact performance <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib29" title="">29</a>]</cite>. It also performs a chained recommendation model in which the system can recommend the pool generation algorithm and DS model together to obtain a final DS pipeline, differing from most current works in meta-learning that focus on predicting a single pipeline step.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span class="ltx_text ltx_font_smallcaps" id="S3.1.1">The Proposed Multi-label meta-learning recommendation (MLRS)</span>
</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.11">Before delving into the details of the proposed meta-learning recommendation system for DS methods, it is essential to define the basic concepts and mathematical notation used in this study. A dataset is represented by <math alttext="\mathcal{D}" class="ltx_Math" display="inline" id="S3.p1.1.m1.1"><semantics id="S3.p1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S3.p1.1.m1.1.1" xref="S3.p1.1.m1.1.1.cmml">𝒟</mi><annotation-xml encoding="MathML-Content" id="S3.p1.1.m1.1b"><ci id="S3.p1.1.m1.1.1.cmml" xref="S3.p1.1.m1.1.1">𝒟</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.1.m1.1c">\mathcal{D}</annotation><annotation encoding="application/x-llamapun" id="S3.p1.1.m1.1d">caligraphic_D</annotation></semantics></math>, where each dataset is a combination of a training partition <math alttext="\mathcal{T}_{r}" class="ltx_Math" display="inline" id="S3.p1.2.m2.1"><semantics id="S3.p1.2.m2.1a"><msub id="S3.p1.2.m2.1.1" xref="S3.p1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.p1.2.m2.1.1.2" xref="S3.p1.2.m2.1.1.2.cmml">𝒯</mi><mi id="S3.p1.2.m2.1.1.3" xref="S3.p1.2.m2.1.1.3.cmml">r</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p1.2.m2.1b"><apply id="S3.p1.2.m2.1.1.cmml" xref="S3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.p1.2.m2.1.1.1.cmml" xref="S3.p1.2.m2.1.1">subscript</csymbol><ci id="S3.p1.2.m2.1.1.2.cmml" xref="S3.p1.2.m2.1.1.2">𝒯</ci><ci id="S3.p1.2.m2.1.1.3.cmml" xref="S3.p1.2.m2.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.2.m2.1c">\mathcal{T}_{r}</annotation><annotation encoding="application/x-llamapun" id="S3.p1.2.m2.1d">caligraphic_T start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT</annotation></semantics></math> and a test partition <math alttext="\mathcal{T}_{e}" class="ltx_Math" display="inline" id="S3.p1.3.m3.1"><semantics id="S3.p1.3.m3.1a"><msub id="S3.p1.3.m3.1.1" xref="S3.p1.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.p1.3.m3.1.1.2" xref="S3.p1.3.m3.1.1.2.cmml">𝒯</mi><mi id="S3.p1.3.m3.1.1.3" xref="S3.p1.3.m3.1.1.3.cmml">e</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p1.3.m3.1b"><apply id="S3.p1.3.m3.1.1.cmml" xref="S3.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.p1.3.m3.1.1.1.cmml" xref="S3.p1.3.m3.1.1">subscript</csymbol><ci id="S3.p1.3.m3.1.1.2.cmml" xref="S3.p1.3.m3.1.1.2">𝒯</ci><ci id="S3.p1.3.m3.1.1.3.cmml" xref="S3.p1.3.m3.1.1.3">𝑒</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.3.m3.1c">\mathcal{T}_{e}</annotation><annotation encoding="application/x-llamapun" id="S3.p1.3.m3.1d">caligraphic_T start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT</annotation></semantics></math>. A set of datasets is symbolized by <math alttext="\mathbb{D}=\{\mathcal{D}_{1},\ldots,\mathcal{D}_{Z}\}" class="ltx_Math" display="inline" id="S3.p1.4.m4.3"><semantics id="S3.p1.4.m4.3a"><mrow id="S3.p1.4.m4.3.3" xref="S3.p1.4.m4.3.3.cmml"><mi id="S3.p1.4.m4.3.3.4" xref="S3.p1.4.m4.3.3.4.cmml">𝔻</mi><mo id="S3.p1.4.m4.3.3.3" xref="S3.p1.4.m4.3.3.3.cmml">=</mo><mrow id="S3.p1.4.m4.3.3.2.2" xref="S3.p1.4.m4.3.3.2.3.cmml"><mo id="S3.p1.4.m4.3.3.2.2.3" stretchy="false" xref="S3.p1.4.m4.3.3.2.3.cmml">{</mo><msub id="S3.p1.4.m4.2.2.1.1.1" xref="S3.p1.4.m4.2.2.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.p1.4.m4.2.2.1.1.1.2" xref="S3.p1.4.m4.2.2.1.1.1.2.cmml">𝒟</mi><mn id="S3.p1.4.m4.2.2.1.1.1.3" xref="S3.p1.4.m4.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S3.p1.4.m4.3.3.2.2.4" xref="S3.p1.4.m4.3.3.2.3.cmml">,</mo><mi id="S3.p1.4.m4.1.1" mathvariant="normal" xref="S3.p1.4.m4.1.1.cmml">…</mi><mo id="S3.p1.4.m4.3.3.2.2.5" xref="S3.p1.4.m4.3.3.2.3.cmml">,</mo><msub id="S3.p1.4.m4.3.3.2.2.2" xref="S3.p1.4.m4.3.3.2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.p1.4.m4.3.3.2.2.2.2" xref="S3.p1.4.m4.3.3.2.2.2.2.cmml">𝒟</mi><mi id="S3.p1.4.m4.3.3.2.2.2.3" xref="S3.p1.4.m4.3.3.2.2.2.3.cmml">Z</mi></msub><mo id="S3.p1.4.m4.3.3.2.2.6" stretchy="false" xref="S3.p1.4.m4.3.3.2.3.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.4.m4.3b"><apply id="S3.p1.4.m4.3.3.cmml" xref="S3.p1.4.m4.3.3"><eq id="S3.p1.4.m4.3.3.3.cmml" xref="S3.p1.4.m4.3.3.3"></eq><ci id="S3.p1.4.m4.3.3.4.cmml" xref="S3.p1.4.m4.3.3.4">𝔻</ci><set id="S3.p1.4.m4.3.3.2.3.cmml" xref="S3.p1.4.m4.3.3.2.2"><apply id="S3.p1.4.m4.2.2.1.1.1.cmml" xref="S3.p1.4.m4.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.p1.4.m4.2.2.1.1.1.1.cmml" xref="S3.p1.4.m4.2.2.1.1.1">subscript</csymbol><ci id="S3.p1.4.m4.2.2.1.1.1.2.cmml" xref="S3.p1.4.m4.2.2.1.1.1.2">𝒟</ci><cn id="S3.p1.4.m4.2.2.1.1.1.3.cmml" type="integer" xref="S3.p1.4.m4.2.2.1.1.1.3">1</cn></apply><ci id="S3.p1.4.m4.1.1.cmml" xref="S3.p1.4.m4.1.1">…</ci><apply id="S3.p1.4.m4.3.3.2.2.2.cmml" xref="S3.p1.4.m4.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.p1.4.m4.3.3.2.2.2.1.cmml" xref="S3.p1.4.m4.3.3.2.2.2">subscript</csymbol><ci id="S3.p1.4.m4.3.3.2.2.2.2.cmml" xref="S3.p1.4.m4.3.3.2.2.2.2">𝒟</ci><ci id="S3.p1.4.m4.3.3.2.2.2.3.cmml" xref="S3.p1.4.m4.3.3.2.2.2.3">𝑍</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.4.m4.3c">\mathbb{D}=\{\mathcal{D}_{1},\ldots,\mathcal{D}_{Z}\}</annotation><annotation encoding="application/x-llamapun" id="S3.p1.4.m4.3d">blackboard_D = { caligraphic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , caligraphic_D start_POSTSUBSCRIPT italic_Z end_POSTSUBSCRIPT }</annotation></semantics></math>, where <math alttext="Z" class="ltx_Math" display="inline" id="S3.p1.5.m5.1"><semantics id="S3.p1.5.m5.1a"><mi id="S3.p1.5.m5.1.1" xref="S3.p1.5.m5.1.1.cmml">Z</mi><annotation-xml encoding="MathML-Content" id="S3.p1.5.m5.1b"><ci id="S3.p1.5.m5.1.1.cmml" xref="S3.p1.5.m5.1.1">𝑍</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.5.m5.1c">Z</annotation><annotation encoding="application/x-llamapun" id="S3.p1.5.m5.1d">italic_Z</annotation></semantics></math> represents the number of datasets. The meta-feature vector (i.e., dataset characteristics) extracted from a dataset is denoted by <math alttext="\mathbf{x^{\prime}}=\{mf_{1},\ldots,mf_{d}\}" class="ltx_Math" display="inline" id="S3.p1.6.m6.3"><semantics id="S3.p1.6.m6.3a"><mrow id="S3.p1.6.m6.3.3" xref="S3.p1.6.m6.3.3.cmml"><msup id="S3.p1.6.m6.3.3.4" xref="S3.p1.6.m6.3.3.4.cmml"><mi id="S3.p1.6.m6.3.3.4.2" xref="S3.p1.6.m6.3.3.4.2.cmml">𝐱</mi><mo id="S3.p1.6.m6.3.3.4.3" xref="S3.p1.6.m6.3.3.4.3.cmml">′</mo></msup><mo id="S3.p1.6.m6.3.3.3" xref="S3.p1.6.m6.3.3.3.cmml">=</mo><mrow id="S3.p1.6.m6.3.3.2.2" xref="S3.p1.6.m6.3.3.2.3.cmml"><mo id="S3.p1.6.m6.3.3.2.2.3" stretchy="false" xref="S3.p1.6.m6.3.3.2.3.cmml">{</mo><mrow id="S3.p1.6.m6.2.2.1.1.1" xref="S3.p1.6.m6.2.2.1.1.1.cmml"><mi id="S3.p1.6.m6.2.2.1.1.1.2" xref="S3.p1.6.m6.2.2.1.1.1.2.cmml">m</mi><mo id="S3.p1.6.m6.2.2.1.1.1.1" xref="S3.p1.6.m6.2.2.1.1.1.1.cmml">⁢</mo><msub id="S3.p1.6.m6.2.2.1.1.1.3" xref="S3.p1.6.m6.2.2.1.1.1.3.cmml"><mi id="S3.p1.6.m6.2.2.1.1.1.3.2" xref="S3.p1.6.m6.2.2.1.1.1.3.2.cmml">f</mi><mn id="S3.p1.6.m6.2.2.1.1.1.3.3" xref="S3.p1.6.m6.2.2.1.1.1.3.3.cmml">1</mn></msub></mrow><mo id="S3.p1.6.m6.3.3.2.2.4" xref="S3.p1.6.m6.3.3.2.3.cmml">,</mo><mi id="S3.p1.6.m6.1.1" mathvariant="normal" xref="S3.p1.6.m6.1.1.cmml">…</mi><mo id="S3.p1.6.m6.3.3.2.2.5" xref="S3.p1.6.m6.3.3.2.3.cmml">,</mo><mrow id="S3.p1.6.m6.3.3.2.2.2" xref="S3.p1.6.m6.3.3.2.2.2.cmml"><mi id="S3.p1.6.m6.3.3.2.2.2.2" xref="S3.p1.6.m6.3.3.2.2.2.2.cmml">m</mi><mo id="S3.p1.6.m6.3.3.2.2.2.1" xref="S3.p1.6.m6.3.3.2.2.2.1.cmml">⁢</mo><msub id="S3.p1.6.m6.3.3.2.2.2.3" xref="S3.p1.6.m6.3.3.2.2.2.3.cmml"><mi id="S3.p1.6.m6.3.3.2.2.2.3.2" xref="S3.p1.6.m6.3.3.2.2.2.3.2.cmml">f</mi><mi id="S3.p1.6.m6.3.3.2.2.2.3.3" xref="S3.p1.6.m6.3.3.2.2.2.3.3.cmml">d</mi></msub></mrow><mo id="S3.p1.6.m6.3.3.2.2.6" stretchy="false" xref="S3.p1.6.m6.3.3.2.3.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.6.m6.3b"><apply id="S3.p1.6.m6.3.3.cmml" xref="S3.p1.6.m6.3.3"><eq id="S3.p1.6.m6.3.3.3.cmml" xref="S3.p1.6.m6.3.3.3"></eq><apply id="S3.p1.6.m6.3.3.4.cmml" xref="S3.p1.6.m6.3.3.4"><csymbol cd="ambiguous" id="S3.p1.6.m6.3.3.4.1.cmml" xref="S3.p1.6.m6.3.3.4">superscript</csymbol><ci id="S3.p1.6.m6.3.3.4.2.cmml" xref="S3.p1.6.m6.3.3.4.2">𝐱</ci><ci id="S3.p1.6.m6.3.3.4.3.cmml" xref="S3.p1.6.m6.3.3.4.3">′</ci></apply><set id="S3.p1.6.m6.3.3.2.3.cmml" xref="S3.p1.6.m6.3.3.2.2"><apply id="S3.p1.6.m6.2.2.1.1.1.cmml" xref="S3.p1.6.m6.2.2.1.1.1"><times id="S3.p1.6.m6.2.2.1.1.1.1.cmml" xref="S3.p1.6.m6.2.2.1.1.1.1"></times><ci id="S3.p1.6.m6.2.2.1.1.1.2.cmml" xref="S3.p1.6.m6.2.2.1.1.1.2">𝑚</ci><apply id="S3.p1.6.m6.2.2.1.1.1.3.cmml" xref="S3.p1.6.m6.2.2.1.1.1.3"><csymbol cd="ambiguous" id="S3.p1.6.m6.2.2.1.1.1.3.1.cmml" xref="S3.p1.6.m6.2.2.1.1.1.3">subscript</csymbol><ci id="S3.p1.6.m6.2.2.1.1.1.3.2.cmml" xref="S3.p1.6.m6.2.2.1.1.1.3.2">𝑓</ci><cn id="S3.p1.6.m6.2.2.1.1.1.3.3.cmml" type="integer" xref="S3.p1.6.m6.2.2.1.1.1.3.3">1</cn></apply></apply><ci id="S3.p1.6.m6.1.1.cmml" xref="S3.p1.6.m6.1.1">…</ci><apply id="S3.p1.6.m6.3.3.2.2.2.cmml" xref="S3.p1.6.m6.3.3.2.2.2"><times id="S3.p1.6.m6.3.3.2.2.2.1.cmml" xref="S3.p1.6.m6.3.3.2.2.2.1"></times><ci id="S3.p1.6.m6.3.3.2.2.2.2.cmml" xref="S3.p1.6.m6.3.3.2.2.2.2">𝑚</ci><apply id="S3.p1.6.m6.3.3.2.2.2.3.cmml" xref="S3.p1.6.m6.3.3.2.2.2.3"><csymbol cd="ambiguous" id="S3.p1.6.m6.3.3.2.2.2.3.1.cmml" xref="S3.p1.6.m6.3.3.2.2.2.3">subscript</csymbol><ci id="S3.p1.6.m6.3.3.2.2.2.3.2.cmml" xref="S3.p1.6.m6.3.3.2.2.2.3.2">𝑓</ci><ci id="S3.p1.6.m6.3.3.2.2.2.3.3.cmml" xref="S3.p1.6.m6.3.3.2.2.2.3.3">𝑑</ci></apply></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.6.m6.3c">\mathbf{x^{\prime}}=\{mf_{1},\ldots,mf_{d}\}</annotation><annotation encoding="application/x-llamapun" id="S3.p1.6.m6.3d">bold_x start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT = { italic_m italic_f start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_m italic_f start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT }</annotation></semantics></math> where each <math alttext="mf" class="ltx_Math" display="inline" id="S3.p1.7.m7.1"><semantics id="S3.p1.7.m7.1a"><mrow id="S3.p1.7.m7.1.1" xref="S3.p1.7.m7.1.1.cmml"><mi id="S3.p1.7.m7.1.1.2" xref="S3.p1.7.m7.1.1.2.cmml">m</mi><mo id="S3.p1.7.m7.1.1.1" xref="S3.p1.7.m7.1.1.1.cmml">⁢</mo><mi id="S3.p1.7.m7.1.1.3" xref="S3.p1.7.m7.1.1.3.cmml">f</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.7.m7.1b"><apply id="S3.p1.7.m7.1.1.cmml" xref="S3.p1.7.m7.1.1"><times id="S3.p1.7.m7.1.1.1.cmml" xref="S3.p1.7.m7.1.1.1"></times><ci id="S3.p1.7.m7.1.1.2.cmml" xref="S3.p1.7.m7.1.1.2">𝑚</ci><ci id="S3.p1.7.m7.1.1.3.cmml" xref="S3.p1.7.m7.1.1.3">𝑓</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.7.m7.1c">mf</annotation><annotation encoding="application/x-llamapun" id="S3.p1.7.m7.1d">italic_m italic_f</annotation></semantics></math> represent a meta-feature extracted from a dataset. The meta-target is indicated by <math alttext="y^{\prime}" class="ltx_Math" display="inline" id="S3.p1.8.m8.1"><semantics id="S3.p1.8.m8.1a"><msup id="S3.p1.8.m8.1.1" xref="S3.p1.8.m8.1.1.cmml"><mi id="S3.p1.8.m8.1.1.2" xref="S3.p1.8.m8.1.1.2.cmml">y</mi><mo id="S3.p1.8.m8.1.1.3" xref="S3.p1.8.m8.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S3.p1.8.m8.1b"><apply id="S3.p1.8.m8.1.1.cmml" xref="S3.p1.8.m8.1.1"><csymbol cd="ambiguous" id="S3.p1.8.m8.1.1.1.cmml" xref="S3.p1.8.m8.1.1">superscript</csymbol><ci id="S3.p1.8.m8.1.1.2.cmml" xref="S3.p1.8.m8.1.1.2">𝑦</ci><ci id="S3.p1.8.m8.1.1.3.cmml" xref="S3.p1.8.m8.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.8.m8.1c">y^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S3.p1.8.m8.1d">italic_y start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT</annotation></semantics></math>. Finally, the meta-dataset is defined as <math alttext="MT=\{(\mathbf{x}^{\prime}_{1},y^{\prime}_{1}),\ldots,(\mathbf{x}^{\prime}_{Z},%
y_{Z}^{\prime})\}" class="ltx_Math" display="inline" id="S3.p1.9.m9.3"><semantics id="S3.p1.9.m9.3a"><mrow id="S3.p1.9.m9.3.3" xref="S3.p1.9.m9.3.3.cmml"><mrow id="S3.p1.9.m9.3.3.4" xref="S3.p1.9.m9.3.3.4.cmml"><mi id="S3.p1.9.m9.3.3.4.2" xref="S3.p1.9.m9.3.3.4.2.cmml">M</mi><mo id="S3.p1.9.m9.3.3.4.1" xref="S3.p1.9.m9.3.3.4.1.cmml">⁢</mo><mi id="S3.p1.9.m9.3.3.4.3" xref="S3.p1.9.m9.3.3.4.3.cmml">T</mi></mrow><mo id="S3.p1.9.m9.3.3.3" xref="S3.p1.9.m9.3.3.3.cmml">=</mo><mrow id="S3.p1.9.m9.3.3.2.2" xref="S3.p1.9.m9.3.3.2.3.cmml"><mo id="S3.p1.9.m9.3.3.2.2.3" stretchy="false" xref="S3.p1.9.m9.3.3.2.3.cmml">{</mo><mrow id="S3.p1.9.m9.2.2.1.1.1.2" xref="S3.p1.9.m9.2.2.1.1.1.3.cmml"><mo id="S3.p1.9.m9.2.2.1.1.1.2.3" stretchy="false" xref="S3.p1.9.m9.2.2.1.1.1.3.cmml">(</mo><msubsup id="S3.p1.9.m9.2.2.1.1.1.1.1" xref="S3.p1.9.m9.2.2.1.1.1.1.1.cmml"><mi id="S3.p1.9.m9.2.2.1.1.1.1.1.2.2" xref="S3.p1.9.m9.2.2.1.1.1.1.1.2.2.cmml">𝐱</mi><mn id="S3.p1.9.m9.2.2.1.1.1.1.1.3" xref="S3.p1.9.m9.2.2.1.1.1.1.1.3.cmml">1</mn><mo id="S3.p1.9.m9.2.2.1.1.1.1.1.2.3" xref="S3.p1.9.m9.2.2.1.1.1.1.1.2.3.cmml">′</mo></msubsup><mo id="S3.p1.9.m9.2.2.1.1.1.2.4" xref="S3.p1.9.m9.2.2.1.1.1.3.cmml">,</mo><msubsup id="S3.p1.9.m9.2.2.1.1.1.2.2" xref="S3.p1.9.m9.2.2.1.1.1.2.2.cmml"><mi id="S3.p1.9.m9.2.2.1.1.1.2.2.2.2" xref="S3.p1.9.m9.2.2.1.1.1.2.2.2.2.cmml">y</mi><mn id="S3.p1.9.m9.2.2.1.1.1.2.2.3" xref="S3.p1.9.m9.2.2.1.1.1.2.2.3.cmml">1</mn><mo id="S3.p1.9.m9.2.2.1.1.1.2.2.2.3" xref="S3.p1.9.m9.2.2.1.1.1.2.2.2.3.cmml">′</mo></msubsup><mo id="S3.p1.9.m9.2.2.1.1.1.2.5" stretchy="false" xref="S3.p1.9.m9.2.2.1.1.1.3.cmml">)</mo></mrow><mo id="S3.p1.9.m9.3.3.2.2.4" xref="S3.p1.9.m9.3.3.2.3.cmml">,</mo><mi id="S3.p1.9.m9.1.1" mathvariant="normal" xref="S3.p1.9.m9.1.1.cmml">…</mi><mo id="S3.p1.9.m9.3.3.2.2.5" xref="S3.p1.9.m9.3.3.2.3.cmml">,</mo><mrow id="S3.p1.9.m9.3.3.2.2.2.2" xref="S3.p1.9.m9.3.3.2.2.2.3.cmml"><mo id="S3.p1.9.m9.3.3.2.2.2.2.3" stretchy="false" xref="S3.p1.9.m9.3.3.2.2.2.3.cmml">(</mo><msubsup id="S3.p1.9.m9.3.3.2.2.2.1.1" xref="S3.p1.9.m9.3.3.2.2.2.1.1.cmml"><mi id="S3.p1.9.m9.3.3.2.2.2.1.1.2.2" xref="S3.p1.9.m9.3.3.2.2.2.1.1.2.2.cmml">𝐱</mi><mi id="S3.p1.9.m9.3.3.2.2.2.1.1.3" xref="S3.p1.9.m9.3.3.2.2.2.1.1.3.cmml">Z</mi><mo id="S3.p1.9.m9.3.3.2.2.2.1.1.2.3" xref="S3.p1.9.m9.3.3.2.2.2.1.1.2.3.cmml">′</mo></msubsup><mo id="S3.p1.9.m9.3.3.2.2.2.2.4" xref="S3.p1.9.m9.3.3.2.2.2.3.cmml">,</mo><msubsup id="S3.p1.9.m9.3.3.2.2.2.2.2" xref="S3.p1.9.m9.3.3.2.2.2.2.2.cmml"><mi id="S3.p1.9.m9.3.3.2.2.2.2.2.2.2" xref="S3.p1.9.m9.3.3.2.2.2.2.2.2.2.cmml">y</mi><mi id="S3.p1.9.m9.3.3.2.2.2.2.2.2.3" xref="S3.p1.9.m9.3.3.2.2.2.2.2.2.3.cmml">Z</mi><mo id="S3.p1.9.m9.3.3.2.2.2.2.2.3" xref="S3.p1.9.m9.3.3.2.2.2.2.2.3.cmml">′</mo></msubsup><mo id="S3.p1.9.m9.3.3.2.2.2.2.5" stretchy="false" xref="S3.p1.9.m9.3.3.2.2.2.3.cmml">)</mo></mrow><mo id="S3.p1.9.m9.3.3.2.2.6" stretchy="false" xref="S3.p1.9.m9.3.3.2.3.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.9.m9.3b"><apply id="S3.p1.9.m9.3.3.cmml" xref="S3.p1.9.m9.3.3"><eq id="S3.p1.9.m9.3.3.3.cmml" xref="S3.p1.9.m9.3.3.3"></eq><apply id="S3.p1.9.m9.3.3.4.cmml" xref="S3.p1.9.m9.3.3.4"><times id="S3.p1.9.m9.3.3.4.1.cmml" xref="S3.p1.9.m9.3.3.4.1"></times><ci id="S3.p1.9.m9.3.3.4.2.cmml" xref="S3.p1.9.m9.3.3.4.2">𝑀</ci><ci id="S3.p1.9.m9.3.3.4.3.cmml" xref="S3.p1.9.m9.3.3.4.3">𝑇</ci></apply><set id="S3.p1.9.m9.3.3.2.3.cmml" xref="S3.p1.9.m9.3.3.2.2"><interval closure="open" id="S3.p1.9.m9.2.2.1.1.1.3.cmml" xref="S3.p1.9.m9.2.2.1.1.1.2"><apply id="S3.p1.9.m9.2.2.1.1.1.1.1.cmml" xref="S3.p1.9.m9.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.p1.9.m9.2.2.1.1.1.1.1.1.cmml" xref="S3.p1.9.m9.2.2.1.1.1.1.1">subscript</csymbol><apply id="S3.p1.9.m9.2.2.1.1.1.1.1.2.cmml" xref="S3.p1.9.m9.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.p1.9.m9.2.2.1.1.1.1.1.2.1.cmml" xref="S3.p1.9.m9.2.2.1.1.1.1.1">superscript</csymbol><ci id="S3.p1.9.m9.2.2.1.1.1.1.1.2.2.cmml" xref="S3.p1.9.m9.2.2.1.1.1.1.1.2.2">𝐱</ci><ci id="S3.p1.9.m9.2.2.1.1.1.1.1.2.3.cmml" xref="S3.p1.9.m9.2.2.1.1.1.1.1.2.3">′</ci></apply><cn id="S3.p1.9.m9.2.2.1.1.1.1.1.3.cmml" type="integer" xref="S3.p1.9.m9.2.2.1.1.1.1.1.3">1</cn></apply><apply id="S3.p1.9.m9.2.2.1.1.1.2.2.cmml" xref="S3.p1.9.m9.2.2.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.p1.9.m9.2.2.1.1.1.2.2.1.cmml" xref="S3.p1.9.m9.2.2.1.1.1.2.2">subscript</csymbol><apply id="S3.p1.9.m9.2.2.1.1.1.2.2.2.cmml" xref="S3.p1.9.m9.2.2.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.p1.9.m9.2.2.1.1.1.2.2.2.1.cmml" xref="S3.p1.9.m9.2.2.1.1.1.2.2">superscript</csymbol><ci id="S3.p1.9.m9.2.2.1.1.1.2.2.2.2.cmml" xref="S3.p1.9.m9.2.2.1.1.1.2.2.2.2">𝑦</ci><ci id="S3.p1.9.m9.2.2.1.1.1.2.2.2.3.cmml" xref="S3.p1.9.m9.2.2.1.1.1.2.2.2.3">′</ci></apply><cn id="S3.p1.9.m9.2.2.1.1.1.2.2.3.cmml" type="integer" xref="S3.p1.9.m9.2.2.1.1.1.2.2.3">1</cn></apply></interval><ci id="S3.p1.9.m9.1.1.cmml" xref="S3.p1.9.m9.1.1">…</ci><interval closure="open" id="S3.p1.9.m9.3.3.2.2.2.3.cmml" xref="S3.p1.9.m9.3.3.2.2.2.2"><apply id="S3.p1.9.m9.3.3.2.2.2.1.1.cmml" xref="S3.p1.9.m9.3.3.2.2.2.1.1"><csymbol cd="ambiguous" id="S3.p1.9.m9.3.3.2.2.2.1.1.1.cmml" xref="S3.p1.9.m9.3.3.2.2.2.1.1">subscript</csymbol><apply id="S3.p1.9.m9.3.3.2.2.2.1.1.2.cmml" xref="S3.p1.9.m9.3.3.2.2.2.1.1"><csymbol cd="ambiguous" id="S3.p1.9.m9.3.3.2.2.2.1.1.2.1.cmml" xref="S3.p1.9.m9.3.3.2.2.2.1.1">superscript</csymbol><ci id="S3.p1.9.m9.3.3.2.2.2.1.1.2.2.cmml" xref="S3.p1.9.m9.3.3.2.2.2.1.1.2.2">𝐱</ci><ci id="S3.p1.9.m9.3.3.2.2.2.1.1.2.3.cmml" xref="S3.p1.9.m9.3.3.2.2.2.1.1.2.3">′</ci></apply><ci id="S3.p1.9.m9.3.3.2.2.2.1.1.3.cmml" xref="S3.p1.9.m9.3.3.2.2.2.1.1.3">𝑍</ci></apply><apply id="S3.p1.9.m9.3.3.2.2.2.2.2.cmml" xref="S3.p1.9.m9.3.3.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.p1.9.m9.3.3.2.2.2.2.2.1.cmml" xref="S3.p1.9.m9.3.3.2.2.2.2.2">superscript</csymbol><apply id="S3.p1.9.m9.3.3.2.2.2.2.2.2.cmml" xref="S3.p1.9.m9.3.3.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.p1.9.m9.3.3.2.2.2.2.2.2.1.cmml" xref="S3.p1.9.m9.3.3.2.2.2.2.2">subscript</csymbol><ci id="S3.p1.9.m9.3.3.2.2.2.2.2.2.2.cmml" xref="S3.p1.9.m9.3.3.2.2.2.2.2.2.2">𝑦</ci><ci id="S3.p1.9.m9.3.3.2.2.2.2.2.2.3.cmml" xref="S3.p1.9.m9.3.3.2.2.2.2.2.2.3">𝑍</ci></apply><ci id="S3.p1.9.m9.3.3.2.2.2.2.2.3.cmml" xref="S3.p1.9.m9.3.3.2.2.2.2.2.3">′</ci></apply></interval></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.9.m9.3c">MT=\{(\mathbf{x}^{\prime}_{1},y^{\prime}_{1}),\ldots,(\mathbf{x}^{\prime}_{Z},%
y_{Z}^{\prime})\}</annotation><annotation encoding="application/x-llamapun" id="S3.p1.9.m9.3d">italic_M italic_T = { ( bold_x start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_y start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) , … , ( bold_x start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_Z end_POSTSUBSCRIPT , italic_y start_POSTSUBSCRIPT italic_Z end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ) }</annotation></semantics></math>, where each tuple <math alttext="(\mathbf{x^{\prime}_{i}},y^{\prime}_{i})" class="ltx_Math" display="inline" id="S3.p1.10.m10.2"><semantics id="S3.p1.10.m10.2a"><mrow id="S3.p1.10.m10.2.2.2" xref="S3.p1.10.m10.2.2.3.cmml"><mo id="S3.p1.10.m10.2.2.2.3" stretchy="false" xref="S3.p1.10.m10.2.2.3.cmml">(</mo><msubsup id="S3.p1.10.m10.1.1.1.1" xref="S3.p1.10.m10.1.1.1.1.cmml"><mi id="S3.p1.10.m10.1.1.1.1.2.2" xref="S3.p1.10.m10.1.1.1.1.2.2.cmml">𝐱</mi><mi id="S3.p1.10.m10.1.1.1.1.3" xref="S3.p1.10.m10.1.1.1.1.3.cmml">𝐢</mi><mo id="S3.p1.10.m10.1.1.1.1.2.3" xref="S3.p1.10.m10.1.1.1.1.2.3.cmml">′</mo></msubsup><mo id="S3.p1.10.m10.2.2.2.4" xref="S3.p1.10.m10.2.2.3.cmml">,</mo><msubsup id="S3.p1.10.m10.2.2.2.2" xref="S3.p1.10.m10.2.2.2.2.cmml"><mi id="S3.p1.10.m10.2.2.2.2.2.2" xref="S3.p1.10.m10.2.2.2.2.2.2.cmml">y</mi><mi id="S3.p1.10.m10.2.2.2.2.3" xref="S3.p1.10.m10.2.2.2.2.3.cmml">i</mi><mo id="S3.p1.10.m10.2.2.2.2.2.3" xref="S3.p1.10.m10.2.2.2.2.2.3.cmml">′</mo></msubsup><mo id="S3.p1.10.m10.2.2.2.5" stretchy="false" xref="S3.p1.10.m10.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.10.m10.2b"><interval closure="open" id="S3.p1.10.m10.2.2.3.cmml" xref="S3.p1.10.m10.2.2.2"><apply id="S3.p1.10.m10.1.1.1.1.cmml" xref="S3.p1.10.m10.1.1.1.1"><csymbol cd="ambiguous" id="S3.p1.10.m10.1.1.1.1.1.cmml" xref="S3.p1.10.m10.1.1.1.1">subscript</csymbol><apply id="S3.p1.10.m10.1.1.1.1.2.cmml" xref="S3.p1.10.m10.1.1.1.1"><csymbol cd="ambiguous" id="S3.p1.10.m10.1.1.1.1.2.1.cmml" xref="S3.p1.10.m10.1.1.1.1">superscript</csymbol><ci id="S3.p1.10.m10.1.1.1.1.2.2.cmml" xref="S3.p1.10.m10.1.1.1.1.2.2">𝐱</ci><ci id="S3.p1.10.m10.1.1.1.1.2.3.cmml" xref="S3.p1.10.m10.1.1.1.1.2.3">′</ci></apply><ci id="S3.p1.10.m10.1.1.1.1.3.cmml" xref="S3.p1.10.m10.1.1.1.1.3">𝐢</ci></apply><apply id="S3.p1.10.m10.2.2.2.2.cmml" xref="S3.p1.10.m10.2.2.2.2"><csymbol cd="ambiguous" id="S3.p1.10.m10.2.2.2.2.1.cmml" xref="S3.p1.10.m10.2.2.2.2">subscript</csymbol><apply id="S3.p1.10.m10.2.2.2.2.2.cmml" xref="S3.p1.10.m10.2.2.2.2"><csymbol cd="ambiguous" id="S3.p1.10.m10.2.2.2.2.2.1.cmml" xref="S3.p1.10.m10.2.2.2.2">superscript</csymbol><ci id="S3.p1.10.m10.2.2.2.2.2.2.cmml" xref="S3.p1.10.m10.2.2.2.2.2.2">𝑦</ci><ci id="S3.p1.10.m10.2.2.2.2.2.3.cmml" xref="S3.p1.10.m10.2.2.2.2.2.3">′</ci></apply><ci id="S3.p1.10.m10.2.2.2.2.3.cmml" xref="S3.p1.10.m10.2.2.2.2.3">𝑖</ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.10.m10.2c">(\mathbf{x^{\prime}_{i}},y^{\prime}_{i})</annotation><annotation encoding="application/x-llamapun" id="S3.p1.10.m10.2d">( bold_x start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT bold_i end_POSTSUBSCRIPT , italic_y start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math> corresponding to the meta-features and meta-target extracted from a training dataset <math alttext="\mathcal{D}_{i}" class="ltx_Math" display="inline" id="S3.p1.11.m11.1"><semantics id="S3.p1.11.m11.1a"><msub id="S3.p1.11.m11.1.1" xref="S3.p1.11.m11.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.p1.11.m11.1.1.2" xref="S3.p1.11.m11.1.1.2.cmml">𝒟</mi><mi id="S3.p1.11.m11.1.1.3" xref="S3.p1.11.m11.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p1.11.m11.1b"><apply id="S3.p1.11.m11.1.1.cmml" xref="S3.p1.11.m11.1.1"><csymbol cd="ambiguous" id="S3.p1.11.m11.1.1.1.cmml" xref="S3.p1.11.m11.1.1">subscript</csymbol><ci id="S3.p1.11.m11.1.1.2.cmml" xref="S3.p1.11.m11.1.1.2">𝒟</ci><ci id="S3.p1.11.m11.1.1.3.cmml" xref="S3.p1.11.m11.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.11.m11.1c">\mathcal{D}_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.p1.11.m11.1d">caligraphic_D start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS1.4.1.1">III-A</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS1.5.2">MLRS Training process</span>
</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.4">The meta-training stage is a crucial step within the meta-learning framework. Its objective is to create a meta-model, <math alttext="\lambda" class="ltx_Math" display="inline" id="S3.SS1.p1.1.m1.1"><semantics id="S3.SS1.p1.1.m1.1a"><mi id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><ci id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">\lambda</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.1.m1.1d">italic_λ</annotation></semantics></math>, that learns the relationship between the characteristics of a dataset and the performance of multiple models evaluated over it (Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#S2.F1" title="Figure 1 ‣ II Related work ‣ MLRS-PDS: A Meta-learning recommendation of dynamic ensemble selection pipelines"><span class="ltx_text ltx_ref_tag">1</span></a>. The training phase of the meta-learning recommendation system is detailed in Algorithm <a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#alg1" title="Algorithm 1 ‣ III-A MLRS Training process ‣ III The Proposed Multi-label meta-learning recommendation (MLRS) ‣ MLRS-PDS: A Meta-learning recommendation of dynamic ensemble selection pipelines"><span class="ltx_text ltx_ref_tag">1</span></a>. The algorithm takes inputs: the set of datasets, <math alttext="\mathbb{D}" class="ltx_Math" display="inline" id="S3.SS1.p1.2.m2.1"><semantics id="S3.SS1.p1.2.m2.1a"><mi id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml">𝔻</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><ci id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">𝔻</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">\mathbb{D}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.2.m2.1d">blackboard_D</annotation></semantics></math>, a set of pool generation scheme <math alttext="\mathbb{P}" class="ltx_Math" display="inline" id="S3.SS1.p1.3.m3.1"><semantics id="S3.SS1.p1.3.m3.1a"><mi id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml">ℙ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><ci id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">ℙ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">\mathbb{P}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.3.m3.1d">blackboard_P</annotation></semantics></math>, and a set of DS algorithms <math alttext="\mathbb{DS}" class="ltx_Math" display="inline" id="S3.SS1.p1.4.m4.1"><semantics id="S3.SS1.p1.4.m4.1a"><mrow id="S3.SS1.p1.4.m4.1.1" xref="S3.SS1.p1.4.m4.1.1.cmml"><mi id="S3.SS1.p1.4.m4.1.1.2" xref="S3.SS1.p1.4.m4.1.1.2.cmml">𝔻</mi><mo id="S3.SS1.p1.4.m4.1.1.1" xref="S3.SS1.p1.4.m4.1.1.1.cmml">⁢</mo><mi id="S3.SS1.p1.4.m4.1.1.3" xref="S3.SS1.p1.4.m4.1.1.3.cmml">𝕊</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.1b"><apply id="S3.SS1.p1.4.m4.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1"><times id="S3.SS1.p1.4.m4.1.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1.1"></times><ci id="S3.SS1.p1.4.m4.1.1.2.cmml" xref="S3.SS1.p1.4.m4.1.1.2">𝔻</ci><ci id="S3.SS1.p1.4.m4.1.1.3.cmml" xref="S3.SS1.p1.4.m4.1.1.3">𝕊</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.1c">\mathbb{DS}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.4.m4.1d">blackboard_D blackboard_S</annotation></semantics></math>.</p>
</div>
<figure class="ltx_float ltx_float_algorithm ltx_framed ltx_framed_top" id="alg1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_bold" id="alg1.2.1.1">Algorithm 1</span> </span> MLRS training phase</figcaption>
<div class="ltx_listing ltx_listing" id="alg1.3">
<div class="ltx_listingline" id="alg1.l1">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l1.1.1.1" style="font-size:80%;">1:</span></span>A set of training datasets, <math alttext="\mathbb{D}" class="ltx_Math" display="inline" id="alg1.l1.m1.1"><semantics id="alg1.l1.m1.1a"><mi id="alg1.l1.m1.1.1" xref="alg1.l1.m1.1.1.cmml">𝔻</mi><annotation-xml encoding="MathML-Content" id="alg1.l1.m1.1b"><ci id="alg1.l1.m1.1.1.cmml" xref="alg1.l1.m1.1.1">𝔻</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m1.1c">\mathbb{D}</annotation><annotation encoding="application/x-llamapun" id="alg1.l1.m1.1d">blackboard_D</annotation></semantics></math>, a set of DS methods, <math alttext="\mathbb{DS}" class="ltx_Math" display="inline" id="alg1.l1.m2.1"><semantics id="alg1.l1.m2.1a"><mrow id="alg1.l1.m2.1.1" xref="alg1.l1.m2.1.1.cmml"><mi id="alg1.l1.m2.1.1.2" xref="alg1.l1.m2.1.1.2.cmml">𝔻</mi><mo id="alg1.l1.m2.1.1.1" xref="alg1.l1.m2.1.1.1.cmml">⁢</mo><mi id="alg1.l1.m2.1.1.3" xref="alg1.l1.m2.1.1.3.cmml">𝕊</mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.l1.m2.1b"><apply id="alg1.l1.m2.1.1.cmml" xref="alg1.l1.m2.1.1"><times id="alg1.l1.m2.1.1.1.cmml" xref="alg1.l1.m2.1.1.1"></times><ci id="alg1.l1.m2.1.1.2.cmml" xref="alg1.l1.m2.1.1.2">𝔻</ci><ci id="alg1.l1.m2.1.1.3.cmml" xref="alg1.l1.m2.1.1.3">𝕊</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m2.1c">\mathbb{DS}</annotation><annotation encoding="application/x-llamapun" id="alg1.l1.m2.1d">blackboard_D blackboard_S</annotation></semantics></math>, a set of pools, <math alttext="\mathbb{P}" class="ltx_Math" display="inline" id="alg1.l1.m3.1"><semantics id="alg1.l1.m3.1a"><mi id="alg1.l1.m3.1.1" xref="alg1.l1.m3.1.1.cmml">ℙ</mi><annotation-xml encoding="MathML-Content" id="alg1.l1.m3.1b"><ci id="alg1.l1.m3.1.1.cmml" xref="alg1.l1.m3.1.1">ℙ</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m3.1c">\mathbb{P}</annotation><annotation encoding="application/x-llamapun" id="alg1.l1.m3.1d">blackboard_P</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg1.l2">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l2.1.1.1" style="font-size:80%;">2:</span></span>Meta-model, <math alttext="\lambda" class="ltx_Math" display="inline" id="alg1.l2.m1.1"><semantics id="alg1.l2.m1.1a"><mi id="alg1.l2.m1.1.1" xref="alg1.l2.m1.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="alg1.l2.m1.1b"><ci id="alg1.l2.m1.1.1.cmml" xref="alg1.l2.m1.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l2.m1.1c">\lambda</annotation><annotation encoding="application/x-llamapun" id="alg1.l2.m1.1d">italic_λ</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg1.l3">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l3.1.1.1" style="font-size:80%;">3:</span></span>Initialize: <math alttext="MT=\emptyset" class="ltx_Math" display="inline" id="alg1.l3.m1.1"><semantics id="alg1.l3.m1.1a"><mrow id="alg1.l3.m1.1.1" xref="alg1.l3.m1.1.1.cmml"><mrow id="alg1.l3.m1.1.1.2" xref="alg1.l3.m1.1.1.2.cmml"><mi id="alg1.l3.m1.1.1.2.2" xref="alg1.l3.m1.1.1.2.2.cmml">M</mi><mo id="alg1.l3.m1.1.1.2.1" xref="alg1.l3.m1.1.1.2.1.cmml">⁢</mo><mi id="alg1.l3.m1.1.1.2.3" xref="alg1.l3.m1.1.1.2.3.cmml">T</mi></mrow><mo id="alg1.l3.m1.1.1.1" xref="alg1.l3.m1.1.1.1.cmml">=</mo><mi id="alg1.l3.m1.1.1.3" mathvariant="normal" xref="alg1.l3.m1.1.1.3.cmml">∅</mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.l3.m1.1b"><apply id="alg1.l3.m1.1.1.cmml" xref="alg1.l3.m1.1.1"><eq id="alg1.l3.m1.1.1.1.cmml" xref="alg1.l3.m1.1.1.1"></eq><apply id="alg1.l3.m1.1.1.2.cmml" xref="alg1.l3.m1.1.1.2"><times id="alg1.l3.m1.1.1.2.1.cmml" xref="alg1.l3.m1.1.1.2.1"></times><ci id="alg1.l3.m1.1.1.2.2.cmml" xref="alg1.l3.m1.1.1.2.2">𝑀</ci><ci id="alg1.l3.m1.1.1.2.3.cmml" xref="alg1.l3.m1.1.1.2.3">𝑇</ci></apply><emptyset id="alg1.l3.m1.1.1.3.cmml" xref="alg1.l3.m1.1.1.3"></emptyset></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l3.m1.1c">MT=\emptyset</annotation><annotation encoding="application/x-llamapun" id="alg1.l3.m1.1d">italic_M italic_T = ∅</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg1.l4">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l4.1.1.1" style="font-size:80%;">4:</span></span><span class="ltx_text ltx_font_bold" id="alg1.l4.2">for</span> each <math alttext="\mathcal{D}_{i}" class="ltx_Math" display="inline" id="alg1.l4.m1.1"><semantics id="alg1.l4.m1.1a"><msub id="alg1.l4.m1.1.1" xref="alg1.l4.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="alg1.l4.m1.1.1.2" xref="alg1.l4.m1.1.1.2.cmml">𝒟</mi><mi id="alg1.l4.m1.1.1.3" xref="alg1.l4.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l4.m1.1b"><apply id="alg1.l4.m1.1.1.cmml" xref="alg1.l4.m1.1.1"><csymbol cd="ambiguous" id="alg1.l4.m1.1.1.1.cmml" xref="alg1.l4.m1.1.1">subscript</csymbol><ci id="alg1.l4.m1.1.1.2.cmml" xref="alg1.l4.m1.1.1.2">𝒟</ci><ci id="alg1.l4.m1.1.1.3.cmml" xref="alg1.l4.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l4.m1.1c">\mathcal{D}_{i}</annotation><annotation encoding="application/x-llamapun" id="alg1.l4.m1.1d">caligraphic_D start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> in <math alttext="\mathbb{D}" class="ltx_Math" display="inline" id="alg1.l4.m2.1"><semantics id="alg1.l4.m2.1a"><mi id="alg1.l4.m2.1.1" xref="alg1.l4.m2.1.1.cmml">𝔻</mi><annotation-xml encoding="MathML-Content" id="alg1.l4.m2.1b"><ci id="alg1.l4.m2.1.1.cmml" xref="alg1.l4.m2.1.1">𝔻</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l4.m2.1c">\mathbb{D}</annotation><annotation encoding="application/x-llamapun" id="alg1.l4.m2.1d">blackboard_D</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="alg1.l4.3">do</span>
</div>
<div class="ltx_listingline" id="alg1.l5">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l5.1.1.1" style="font-size:80%;">5:</span></span>     Extract meta-feature vector, <math alttext="\mathbf{x}^{\prime}_{i}" class="ltx_Math" display="inline" id="alg1.l5.m1.1"><semantics id="alg1.l5.m1.1a"><msubsup id="alg1.l5.m1.1.1" xref="alg1.l5.m1.1.1.cmml"><mi id="alg1.l5.m1.1.1.2.2" xref="alg1.l5.m1.1.1.2.2.cmml">𝐱</mi><mi id="alg1.l5.m1.1.1.3" xref="alg1.l5.m1.1.1.3.cmml">i</mi><mo id="alg1.l5.m1.1.1.2.3" xref="alg1.l5.m1.1.1.2.3.cmml">′</mo></msubsup><annotation-xml encoding="MathML-Content" id="alg1.l5.m1.1b"><apply id="alg1.l5.m1.1.1.cmml" xref="alg1.l5.m1.1.1"><csymbol cd="ambiguous" id="alg1.l5.m1.1.1.1.cmml" xref="alg1.l5.m1.1.1">subscript</csymbol><apply id="alg1.l5.m1.1.1.2.cmml" xref="alg1.l5.m1.1.1"><csymbol cd="ambiguous" id="alg1.l5.m1.1.1.2.1.cmml" xref="alg1.l5.m1.1.1">superscript</csymbol><ci id="alg1.l5.m1.1.1.2.2.cmml" xref="alg1.l5.m1.1.1.2.2">𝐱</ci><ci id="alg1.l5.m1.1.1.2.3.cmml" xref="alg1.l5.m1.1.1.2.3">′</ci></apply><ci id="alg1.l5.m1.1.1.3.cmml" xref="alg1.l5.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l5.m1.1c">\mathbf{x}^{\prime}_{i}</annotation><annotation encoding="application/x-llamapun" id="alg1.l5.m1.1d">bold_x start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>, from the dataset <math alttext="\mathcal{T}_{r}^{(i)}" class="ltx_Math" display="inline" id="alg1.l5.m2.1"><semantics id="alg1.l5.m2.1a"><msubsup id="alg1.l5.m2.1.2" xref="alg1.l5.m2.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="alg1.l5.m2.1.2.2.2" xref="alg1.l5.m2.1.2.2.2.cmml">𝒯</mi><mi id="alg1.l5.m2.1.2.2.3" xref="alg1.l5.m2.1.2.2.3.cmml">r</mi><mrow id="alg1.l5.m2.1.1.1.3" xref="alg1.l5.m2.1.2.cmml"><mo id="alg1.l5.m2.1.1.1.3.1" stretchy="false" xref="alg1.l5.m2.1.2.cmml">(</mo><mi id="alg1.l5.m2.1.1.1.1" xref="alg1.l5.m2.1.1.1.1.cmml">i</mi><mo id="alg1.l5.m2.1.1.1.3.2" stretchy="false" xref="alg1.l5.m2.1.2.cmml">)</mo></mrow></msubsup><annotation-xml encoding="MathML-Content" id="alg1.l5.m2.1b"><apply id="alg1.l5.m2.1.2.cmml" xref="alg1.l5.m2.1.2"><csymbol cd="ambiguous" id="alg1.l5.m2.1.2.1.cmml" xref="alg1.l5.m2.1.2">superscript</csymbol><apply id="alg1.l5.m2.1.2.2.cmml" xref="alg1.l5.m2.1.2"><csymbol cd="ambiguous" id="alg1.l5.m2.1.2.2.1.cmml" xref="alg1.l5.m2.1.2">subscript</csymbol><ci id="alg1.l5.m2.1.2.2.2.cmml" xref="alg1.l5.m2.1.2.2.2">𝒯</ci><ci id="alg1.l5.m2.1.2.2.3.cmml" xref="alg1.l5.m2.1.2.2.3">𝑟</ci></apply><ci id="alg1.l5.m2.1.1.1.1.cmml" xref="alg1.l5.m2.1.1.1.1">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l5.m2.1c">\mathcal{T}_{r}^{(i)}</annotation><annotation encoding="application/x-llamapun" id="alg1.l5.m2.1d">caligraphic_T start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_i ) end_POSTSUPERSCRIPT</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg1.l6">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l6.1.1.1" style="font-size:80%;">6:</span></span>     <span class="ltx_text ltx_font_bold" id="alg1.l6.2">for</span> each <math alttext="DS_{j}\in\mathbb{DS}" class="ltx_Math" display="inline" id="alg1.l6.m1.1"><semantics id="alg1.l6.m1.1a"><mrow id="alg1.l6.m1.1.1" xref="alg1.l6.m1.1.1.cmml"><mrow id="alg1.l6.m1.1.1.2" xref="alg1.l6.m1.1.1.2.cmml"><mi id="alg1.l6.m1.1.1.2.2" xref="alg1.l6.m1.1.1.2.2.cmml">D</mi><mo id="alg1.l6.m1.1.1.2.1" xref="alg1.l6.m1.1.1.2.1.cmml">⁢</mo><msub id="alg1.l6.m1.1.1.2.3" xref="alg1.l6.m1.1.1.2.3.cmml"><mi id="alg1.l6.m1.1.1.2.3.2" xref="alg1.l6.m1.1.1.2.3.2.cmml">S</mi><mi id="alg1.l6.m1.1.1.2.3.3" xref="alg1.l6.m1.1.1.2.3.3.cmml">j</mi></msub></mrow><mo id="alg1.l6.m1.1.1.1" xref="alg1.l6.m1.1.1.1.cmml">∈</mo><mrow id="alg1.l6.m1.1.1.3" xref="alg1.l6.m1.1.1.3.cmml"><mi id="alg1.l6.m1.1.1.3.2" xref="alg1.l6.m1.1.1.3.2.cmml">𝔻</mi><mo id="alg1.l6.m1.1.1.3.1" xref="alg1.l6.m1.1.1.3.1.cmml">⁢</mo><mi id="alg1.l6.m1.1.1.3.3" xref="alg1.l6.m1.1.1.3.3.cmml">𝕊</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l6.m1.1b"><apply id="alg1.l6.m1.1.1.cmml" xref="alg1.l6.m1.1.1"><in id="alg1.l6.m1.1.1.1.cmml" xref="alg1.l6.m1.1.1.1"></in><apply id="alg1.l6.m1.1.1.2.cmml" xref="alg1.l6.m1.1.1.2"><times id="alg1.l6.m1.1.1.2.1.cmml" xref="alg1.l6.m1.1.1.2.1"></times><ci id="alg1.l6.m1.1.1.2.2.cmml" xref="alg1.l6.m1.1.1.2.2">𝐷</ci><apply id="alg1.l6.m1.1.1.2.3.cmml" xref="alg1.l6.m1.1.1.2.3"><csymbol cd="ambiguous" id="alg1.l6.m1.1.1.2.3.1.cmml" xref="alg1.l6.m1.1.1.2.3">subscript</csymbol><ci id="alg1.l6.m1.1.1.2.3.2.cmml" xref="alg1.l6.m1.1.1.2.3.2">𝑆</ci><ci id="alg1.l6.m1.1.1.2.3.3.cmml" xref="alg1.l6.m1.1.1.2.3.3">𝑗</ci></apply></apply><apply id="alg1.l6.m1.1.1.3.cmml" xref="alg1.l6.m1.1.1.3"><times id="alg1.l6.m1.1.1.3.1.cmml" xref="alg1.l6.m1.1.1.3.1"></times><ci id="alg1.l6.m1.1.1.3.2.cmml" xref="alg1.l6.m1.1.1.3.2">𝔻</ci><ci id="alg1.l6.m1.1.1.3.3.cmml" xref="alg1.l6.m1.1.1.3.3">𝕊</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l6.m1.1c">DS_{j}\in\mathbb{DS}</annotation><annotation encoding="application/x-llamapun" id="alg1.l6.m1.1d">italic_D italic_S start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ∈ blackboard_D blackboard_S</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="alg1.l6.3">do</span>
</div>
<div class="ltx_listingline" id="alg1.l7">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l7.1.1.1" style="font-size:80%;">7:</span></span>         <span class="ltx_text ltx_font_bold" id="alg1.l7.2">for</span> each <math alttext="P_{k}\in\mathbb{P}" class="ltx_Math" display="inline" id="alg1.l7.m1.1"><semantics id="alg1.l7.m1.1a"><mrow id="alg1.l7.m1.1.1" xref="alg1.l7.m1.1.1.cmml"><msub id="alg1.l7.m1.1.1.2" xref="alg1.l7.m1.1.1.2.cmml"><mi id="alg1.l7.m1.1.1.2.2" xref="alg1.l7.m1.1.1.2.2.cmml">P</mi><mi id="alg1.l7.m1.1.1.2.3" xref="alg1.l7.m1.1.1.2.3.cmml">k</mi></msub><mo id="alg1.l7.m1.1.1.1" xref="alg1.l7.m1.1.1.1.cmml">∈</mo><mi id="alg1.l7.m1.1.1.3" xref="alg1.l7.m1.1.1.3.cmml">ℙ</mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.l7.m1.1b"><apply id="alg1.l7.m1.1.1.cmml" xref="alg1.l7.m1.1.1"><in id="alg1.l7.m1.1.1.1.cmml" xref="alg1.l7.m1.1.1.1"></in><apply id="alg1.l7.m1.1.1.2.cmml" xref="alg1.l7.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.l7.m1.1.1.2.1.cmml" xref="alg1.l7.m1.1.1.2">subscript</csymbol><ci id="alg1.l7.m1.1.1.2.2.cmml" xref="alg1.l7.m1.1.1.2.2">𝑃</ci><ci id="alg1.l7.m1.1.1.2.3.cmml" xref="alg1.l7.m1.1.1.2.3">𝑘</ci></apply><ci id="alg1.l7.m1.1.1.3.cmml" xref="alg1.l7.m1.1.1.3">ℙ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l7.m1.1c">P_{k}\in\mathbb{P}</annotation><annotation encoding="application/x-llamapun" id="alg1.l7.m1.1d">italic_P start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ∈ blackboard_P</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="alg1.l7.3">do</span>
</div>
<div class="ltx_listingline" id="alg1.l8">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l8.1.1.1" style="font-size:80%;">8:</span></span>              Assess the performance of <math alttext="DS_{j}" class="ltx_Math" display="inline" id="alg1.l8.m1.1"><semantics id="alg1.l8.m1.1a"><mrow id="alg1.l8.m1.1.1" xref="alg1.l8.m1.1.1.cmml"><mi id="alg1.l8.m1.1.1.2" xref="alg1.l8.m1.1.1.2.cmml">D</mi><mo id="alg1.l8.m1.1.1.1" xref="alg1.l8.m1.1.1.1.cmml">⁢</mo><msub id="alg1.l8.m1.1.1.3" xref="alg1.l8.m1.1.1.3.cmml"><mi id="alg1.l8.m1.1.1.3.2" xref="alg1.l8.m1.1.1.3.2.cmml">S</mi><mi id="alg1.l8.m1.1.1.3.3" xref="alg1.l8.m1.1.1.3.3.cmml">j</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="alg1.l8.m1.1b"><apply id="alg1.l8.m1.1.1.cmml" xref="alg1.l8.m1.1.1"><times id="alg1.l8.m1.1.1.1.cmml" xref="alg1.l8.m1.1.1.1"></times><ci id="alg1.l8.m1.1.1.2.cmml" xref="alg1.l8.m1.1.1.2">𝐷</ci><apply id="alg1.l8.m1.1.1.3.cmml" xref="alg1.l8.m1.1.1.3"><csymbol cd="ambiguous" id="alg1.l8.m1.1.1.3.1.cmml" xref="alg1.l8.m1.1.1.3">subscript</csymbol><ci id="alg1.l8.m1.1.1.3.2.cmml" xref="alg1.l8.m1.1.1.3.2">𝑆</ci><ci id="alg1.l8.m1.1.1.3.3.cmml" xref="alg1.l8.m1.1.1.3.3">𝑗</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l8.m1.1c">DS_{j}</annotation><annotation encoding="application/x-llamapun" id="alg1.l8.m1.1d">italic_D italic_S start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math> using <math alttext="P_{k}" class="ltx_Math" display="inline" id="alg1.l8.m2.1"><semantics id="alg1.l8.m2.1a"><msub id="alg1.l8.m2.1.1" xref="alg1.l8.m2.1.1.cmml"><mi id="alg1.l8.m2.1.1.2" xref="alg1.l8.m2.1.1.2.cmml">P</mi><mi id="alg1.l8.m2.1.1.3" xref="alg1.l8.m2.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l8.m2.1b"><apply id="alg1.l8.m2.1.1.cmml" xref="alg1.l8.m2.1.1"><csymbol cd="ambiguous" id="alg1.l8.m2.1.1.1.cmml" xref="alg1.l8.m2.1.1">subscript</csymbol><ci id="alg1.l8.m2.1.1.2.cmml" xref="alg1.l8.m2.1.1.2">𝑃</ci><ci id="alg1.l8.m2.1.1.3.cmml" xref="alg1.l8.m2.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l8.m2.1c">P_{k}</annotation><annotation encoding="application/x-llamapun" id="alg1.l8.m2.1d">italic_P start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg1.l9">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l9.1.1.1" style="font-size:80%;">9:</span></span>         <span class="ltx_text ltx_font_bold" id="alg1.l9.2">end</span> <span class="ltx_text ltx_font_bold" id="alg1.l9.3">for</span>
</div>
<div class="ltx_listingline" id="alg1.l10">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l10.1.1.1" style="font-size:80%;">10:</span></span>     <span class="ltx_text ltx_font_bold" id="alg1.l10.2">end</span> <span class="ltx_text ltx_font_bold" id="alg1.l10.3">for</span>
</div>
<div class="ltx_listingline" id="alg1.l11">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l11.1.1.1" style="font-size:80%;">11:</span></span>     Define the configuration with the highest performance as <math alttext="y^{\prime}_{i}" class="ltx_Math" display="inline" id="alg1.l11.m1.1"><semantics id="alg1.l11.m1.1a"><msubsup id="alg1.l11.m1.1.1" xref="alg1.l11.m1.1.1.cmml"><mi id="alg1.l11.m1.1.1.2.2" xref="alg1.l11.m1.1.1.2.2.cmml">y</mi><mi id="alg1.l11.m1.1.1.3" xref="alg1.l11.m1.1.1.3.cmml">i</mi><mo id="alg1.l11.m1.1.1.2.3" xref="alg1.l11.m1.1.1.2.3.cmml">′</mo></msubsup><annotation-xml encoding="MathML-Content" id="alg1.l11.m1.1b"><apply id="alg1.l11.m1.1.1.cmml" xref="alg1.l11.m1.1.1"><csymbol cd="ambiguous" id="alg1.l11.m1.1.1.1.cmml" xref="alg1.l11.m1.1.1">subscript</csymbol><apply id="alg1.l11.m1.1.1.2.cmml" xref="alg1.l11.m1.1.1"><csymbol cd="ambiguous" id="alg1.l11.m1.1.1.2.1.cmml" xref="alg1.l11.m1.1.1">superscript</csymbol><ci id="alg1.l11.m1.1.1.2.2.cmml" xref="alg1.l11.m1.1.1.2.2">𝑦</ci><ci id="alg1.l11.m1.1.1.2.3.cmml" xref="alg1.l11.m1.1.1.2.3">′</ci></apply><ci id="alg1.l11.m1.1.1.3.cmml" xref="alg1.l11.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l11.m1.1c">y^{\prime}_{i}</annotation><annotation encoding="application/x-llamapun" id="alg1.l11.m1.1d">italic_y start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg1.l12">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l12.1.1.1" style="font-size:80%;">12:</span></span>     <math alttext="MT=MT\cup(\mathbf{x}^{\prime}_{i},y^{\prime}_{i})" class="ltx_Math" display="inline" id="alg1.l12.m1.2"><semantics id="alg1.l12.m1.2a"><mrow id="alg1.l12.m1.2.2" xref="alg1.l12.m1.2.2.cmml"><mrow id="alg1.l12.m1.2.2.4" xref="alg1.l12.m1.2.2.4.cmml"><mi id="alg1.l12.m1.2.2.4.2" xref="alg1.l12.m1.2.2.4.2.cmml">M</mi><mo id="alg1.l12.m1.2.2.4.1" xref="alg1.l12.m1.2.2.4.1.cmml">⁢</mo><mi id="alg1.l12.m1.2.2.4.3" xref="alg1.l12.m1.2.2.4.3.cmml">T</mi></mrow><mo id="alg1.l12.m1.2.2.3" xref="alg1.l12.m1.2.2.3.cmml">=</mo><mrow id="alg1.l12.m1.2.2.2" xref="alg1.l12.m1.2.2.2.cmml"><mrow id="alg1.l12.m1.2.2.2.4" xref="alg1.l12.m1.2.2.2.4.cmml"><mi id="alg1.l12.m1.2.2.2.4.2" xref="alg1.l12.m1.2.2.2.4.2.cmml">M</mi><mo id="alg1.l12.m1.2.2.2.4.1" xref="alg1.l12.m1.2.2.2.4.1.cmml">⁢</mo><mi id="alg1.l12.m1.2.2.2.4.3" xref="alg1.l12.m1.2.2.2.4.3.cmml">T</mi></mrow><mo id="alg1.l12.m1.2.2.2.3" xref="alg1.l12.m1.2.2.2.3.cmml">∪</mo><mrow id="alg1.l12.m1.2.2.2.2.2" xref="alg1.l12.m1.2.2.2.2.3.cmml"><mo id="alg1.l12.m1.2.2.2.2.2.3" stretchy="false" xref="alg1.l12.m1.2.2.2.2.3.cmml">(</mo><msubsup id="alg1.l12.m1.1.1.1.1.1.1" xref="alg1.l12.m1.1.1.1.1.1.1.cmml"><mi id="alg1.l12.m1.1.1.1.1.1.1.2.2" xref="alg1.l12.m1.1.1.1.1.1.1.2.2.cmml">𝐱</mi><mi id="alg1.l12.m1.1.1.1.1.1.1.3" xref="alg1.l12.m1.1.1.1.1.1.1.3.cmml">i</mi><mo id="alg1.l12.m1.1.1.1.1.1.1.2.3" xref="alg1.l12.m1.1.1.1.1.1.1.2.3.cmml">′</mo></msubsup><mo id="alg1.l12.m1.2.2.2.2.2.4" xref="alg1.l12.m1.2.2.2.2.3.cmml">,</mo><msubsup id="alg1.l12.m1.2.2.2.2.2.2" xref="alg1.l12.m1.2.2.2.2.2.2.cmml"><mi id="alg1.l12.m1.2.2.2.2.2.2.2.2" xref="alg1.l12.m1.2.2.2.2.2.2.2.2.cmml">y</mi><mi id="alg1.l12.m1.2.2.2.2.2.2.3" xref="alg1.l12.m1.2.2.2.2.2.2.3.cmml">i</mi><mo id="alg1.l12.m1.2.2.2.2.2.2.2.3" xref="alg1.l12.m1.2.2.2.2.2.2.2.3.cmml">′</mo></msubsup><mo id="alg1.l12.m1.2.2.2.2.2.5" stretchy="false" xref="alg1.l12.m1.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l12.m1.2b"><apply id="alg1.l12.m1.2.2.cmml" xref="alg1.l12.m1.2.2"><eq id="alg1.l12.m1.2.2.3.cmml" xref="alg1.l12.m1.2.2.3"></eq><apply id="alg1.l12.m1.2.2.4.cmml" xref="alg1.l12.m1.2.2.4"><times id="alg1.l12.m1.2.2.4.1.cmml" xref="alg1.l12.m1.2.2.4.1"></times><ci id="alg1.l12.m1.2.2.4.2.cmml" xref="alg1.l12.m1.2.2.4.2">𝑀</ci><ci id="alg1.l12.m1.2.2.4.3.cmml" xref="alg1.l12.m1.2.2.4.3">𝑇</ci></apply><apply id="alg1.l12.m1.2.2.2.cmml" xref="alg1.l12.m1.2.2.2"><union id="alg1.l12.m1.2.2.2.3.cmml" xref="alg1.l12.m1.2.2.2.3"></union><apply id="alg1.l12.m1.2.2.2.4.cmml" xref="alg1.l12.m1.2.2.2.4"><times id="alg1.l12.m1.2.2.2.4.1.cmml" xref="alg1.l12.m1.2.2.2.4.1"></times><ci id="alg1.l12.m1.2.2.2.4.2.cmml" xref="alg1.l12.m1.2.2.2.4.2">𝑀</ci><ci id="alg1.l12.m1.2.2.2.4.3.cmml" xref="alg1.l12.m1.2.2.2.4.3">𝑇</ci></apply><interval closure="open" id="alg1.l12.m1.2.2.2.2.3.cmml" xref="alg1.l12.m1.2.2.2.2.2"><apply id="alg1.l12.m1.1.1.1.1.1.1.cmml" xref="alg1.l12.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="alg1.l12.m1.1.1.1.1.1.1.1.cmml" xref="alg1.l12.m1.1.1.1.1.1.1">subscript</csymbol><apply id="alg1.l12.m1.1.1.1.1.1.1.2.cmml" xref="alg1.l12.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="alg1.l12.m1.1.1.1.1.1.1.2.1.cmml" xref="alg1.l12.m1.1.1.1.1.1.1">superscript</csymbol><ci id="alg1.l12.m1.1.1.1.1.1.1.2.2.cmml" xref="alg1.l12.m1.1.1.1.1.1.1.2.2">𝐱</ci><ci id="alg1.l12.m1.1.1.1.1.1.1.2.3.cmml" xref="alg1.l12.m1.1.1.1.1.1.1.2.3">′</ci></apply><ci id="alg1.l12.m1.1.1.1.1.1.1.3.cmml" xref="alg1.l12.m1.1.1.1.1.1.1.3">𝑖</ci></apply><apply id="alg1.l12.m1.2.2.2.2.2.2.cmml" xref="alg1.l12.m1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="alg1.l12.m1.2.2.2.2.2.2.1.cmml" xref="alg1.l12.m1.2.2.2.2.2.2">subscript</csymbol><apply id="alg1.l12.m1.2.2.2.2.2.2.2.cmml" xref="alg1.l12.m1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="alg1.l12.m1.2.2.2.2.2.2.2.1.cmml" xref="alg1.l12.m1.2.2.2.2.2.2">superscript</csymbol><ci id="alg1.l12.m1.2.2.2.2.2.2.2.2.cmml" xref="alg1.l12.m1.2.2.2.2.2.2.2.2">𝑦</ci><ci id="alg1.l12.m1.2.2.2.2.2.2.2.3.cmml" xref="alg1.l12.m1.2.2.2.2.2.2.2.3">′</ci></apply><ci id="alg1.l12.m1.2.2.2.2.2.2.3.cmml" xref="alg1.l12.m1.2.2.2.2.2.2.3">𝑖</ci></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l12.m1.2c">MT=MT\cup(\mathbf{x}^{\prime}_{i},y^{\prime}_{i})</annotation><annotation encoding="application/x-llamapun" id="alg1.l12.m1.2d">italic_M italic_T = italic_M italic_T ∪ ( bold_x start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_y start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg1.l13">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l13.1.1.1" style="font-size:80%;">13:</span></span><span class="ltx_text ltx_font_bold" id="alg1.l13.2">end</span> <span class="ltx_text ltx_font_bold" id="alg1.l13.3">for</span>
</div>
<div class="ltx_listingline" id="alg1.l14">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l14.1.1.1" style="font-size:80%;">14:</span></span>Train the meta-model, <math alttext="\lambda" class="ltx_Math" display="inline" id="alg1.l14.m1.1"><semantics id="alg1.l14.m1.1a"><mi id="alg1.l14.m1.1.1" xref="alg1.l14.m1.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="alg1.l14.m1.1b"><ci id="alg1.l14.m1.1.1.cmml" xref="alg1.l14.m1.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l14.m1.1c">\lambda</annotation><annotation encoding="application/x-llamapun" id="alg1.l14.m1.1d">italic_λ</annotation></semantics></math>, on the meta-dataset, <math alttext="MT" class="ltx_Math" display="inline" id="alg1.l14.m2.1"><semantics id="alg1.l14.m2.1a"><mrow id="alg1.l14.m2.1.1" xref="alg1.l14.m2.1.1.cmml"><mi id="alg1.l14.m2.1.1.2" xref="alg1.l14.m2.1.1.2.cmml">M</mi><mo id="alg1.l14.m2.1.1.1" xref="alg1.l14.m2.1.1.1.cmml">⁢</mo><mi id="alg1.l14.m2.1.1.3" xref="alg1.l14.m2.1.1.3.cmml">T</mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.l14.m2.1b"><apply id="alg1.l14.m2.1.1.cmml" xref="alg1.l14.m2.1.1"><times id="alg1.l14.m2.1.1.1.cmml" xref="alg1.l14.m2.1.1.1"></times><ci id="alg1.l14.m2.1.1.2.cmml" xref="alg1.l14.m2.1.1.2">𝑀</ci><ci id="alg1.l14.m2.1.1.3.cmml" xref="alg1.l14.m2.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l14.m2.1c">MT</annotation><annotation encoding="application/x-llamapun" id="alg1.l14.m2.1d">italic_M italic_T</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg1.l15">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l15.1.1.1" style="font-size:80%;">15:</span></span><span class="ltx_text ltx_font_bold" id="alg1.l15.2">Return</span> <math alttext="\lambda" class="ltx_Math" display="inline" id="alg1.l15.m1.1"><semantics id="alg1.l15.m1.1a"><mi id="alg1.l15.m1.1.1" xref="alg1.l15.m1.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="alg1.l15.m1.1b"><ci id="alg1.l15.m1.1.1.cmml" xref="alg1.l15.m1.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l15.m1.1c">\lambda</annotation><annotation encoding="application/x-llamapun" id="alg1.l15.m1.1d">italic_λ</annotation></semantics></math>
</div>
</div>
</figure>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.6">The algorithm then iterates over each dataset <math alttext="\mathcal{D}_{i}\in\mathbb{D}" class="ltx_Math" display="inline" id="S3.SS1.p2.1.m1.1"><semantics id="S3.SS1.p2.1.m1.1a"><mrow id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml"><msub id="S3.SS1.p2.1.m1.1.1.2" xref="S3.SS1.p2.1.m1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p2.1.m1.1.1.2.2" xref="S3.SS1.p2.1.m1.1.1.2.2.cmml">𝒟</mi><mi id="S3.SS1.p2.1.m1.1.1.2.3" xref="S3.SS1.p2.1.m1.1.1.2.3.cmml">i</mi></msub><mo id="S3.SS1.p2.1.m1.1.1.1" xref="S3.SS1.p2.1.m1.1.1.1.cmml">∈</mo><mi id="S3.SS1.p2.1.m1.1.1.3" xref="S3.SS1.p2.1.m1.1.1.3.cmml">𝔻</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><apply id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1"><in id="S3.SS1.p2.1.m1.1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1.1"></in><apply id="S3.SS1.p2.1.m1.1.1.2.cmml" xref="S3.SS1.p2.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p2.1.m1.1.1.2.1.cmml" xref="S3.SS1.p2.1.m1.1.1.2">subscript</csymbol><ci id="S3.SS1.p2.1.m1.1.1.2.2.cmml" xref="S3.SS1.p2.1.m1.1.1.2.2">𝒟</ci><ci id="S3.SS1.p2.1.m1.1.1.2.3.cmml" xref="S3.SS1.p2.1.m1.1.1.2.3">𝑖</ci></apply><ci id="S3.SS1.p2.1.m1.1.1.3.cmml" xref="S3.SS1.p2.1.m1.1.1.3">𝔻</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">\mathcal{D}_{i}\in\mathbb{D}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.1.m1.1d">caligraphic_D start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∈ blackboard_D</annotation></semantics></math>. For each iteration, the algorithm extracts the meta-features vector, <math alttext="\mathbf{x}_{i}^{\prime}" class="ltx_Math" display="inline" id="S3.SS1.p2.2.m2.1"><semantics id="S3.SS1.p2.2.m2.1a"><msubsup id="S3.SS1.p2.2.m2.1.1" xref="S3.SS1.p2.2.m2.1.1.cmml"><mi id="S3.SS1.p2.2.m2.1.1.2.2" xref="S3.SS1.p2.2.m2.1.1.2.2.cmml">𝐱</mi><mi id="S3.SS1.p2.2.m2.1.1.2.3" xref="S3.SS1.p2.2.m2.1.1.2.3.cmml">i</mi><mo id="S3.SS1.p2.2.m2.1.1.3" xref="S3.SS1.p2.2.m2.1.1.3.cmml">′</mo></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.1b"><apply id="S3.SS1.p2.2.m2.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.2.m2.1.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1">superscript</csymbol><apply id="S3.SS1.p2.2.m2.1.1.2.cmml" xref="S3.SS1.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.2.m2.1.1.2.1.cmml" xref="S3.SS1.p2.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.p2.2.m2.1.1.2.2.cmml" xref="S3.SS1.p2.2.m2.1.1.2.2">𝐱</ci><ci id="S3.SS1.p2.2.m2.1.1.2.3.cmml" xref="S3.SS1.p2.2.m2.1.1.2.3">𝑖</ci></apply><ci id="S3.SS1.p2.2.m2.1.1.3.cmml" xref="S3.SS1.p2.2.m2.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.1c">\mathbf{x}_{i}^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.2.m2.1d">bold_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT</annotation></semantics></math>, capturing the characteristics of the training partition of the dataset <math alttext="\mathcal{D}_{i}" class="ltx_Math" display="inline" id="S3.SS1.p2.3.m3.1"><semantics id="S3.SS1.p2.3.m3.1a"><msub id="S3.SS1.p2.3.m3.1.1" xref="S3.SS1.p2.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p2.3.m3.1.1.2" xref="S3.SS1.p2.3.m3.1.1.2.cmml">𝒟</mi><mi id="S3.SS1.p2.3.m3.1.1.3" xref="S3.SS1.p2.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.3.m3.1b"><apply id="S3.SS1.p2.3.m3.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m3.1.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.p2.3.m3.1.1.2.cmml" xref="S3.SS1.p2.3.m3.1.1.2">𝒟</ci><ci id="S3.SS1.p2.3.m3.1.1.3.cmml" xref="S3.SS1.p2.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.3.m3.1c">\mathcal{D}_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.3.m3.1d">caligraphic_D start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> denoted by <math alttext="\mathcal{T}_{r}^{(i)}" class="ltx_Math" display="inline" id="S3.SS1.p2.4.m4.1"><semantics id="S3.SS1.p2.4.m4.1a"><msubsup id="S3.SS1.p2.4.m4.1.2" xref="S3.SS1.p2.4.m4.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p2.4.m4.1.2.2.2" xref="S3.SS1.p2.4.m4.1.2.2.2.cmml">𝒯</mi><mi id="S3.SS1.p2.4.m4.1.2.2.3" xref="S3.SS1.p2.4.m4.1.2.2.3.cmml">r</mi><mrow id="S3.SS1.p2.4.m4.1.1.1.3" xref="S3.SS1.p2.4.m4.1.2.cmml"><mo id="S3.SS1.p2.4.m4.1.1.1.3.1" stretchy="false" xref="S3.SS1.p2.4.m4.1.2.cmml">(</mo><mi id="S3.SS1.p2.4.m4.1.1.1.1" xref="S3.SS1.p2.4.m4.1.1.1.1.cmml">i</mi><mo id="S3.SS1.p2.4.m4.1.1.1.3.2" stretchy="false" xref="S3.SS1.p2.4.m4.1.2.cmml">)</mo></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.4.m4.1b"><apply id="S3.SS1.p2.4.m4.1.2.cmml" xref="S3.SS1.p2.4.m4.1.2"><csymbol cd="ambiguous" id="S3.SS1.p2.4.m4.1.2.1.cmml" xref="S3.SS1.p2.4.m4.1.2">superscript</csymbol><apply id="S3.SS1.p2.4.m4.1.2.2.cmml" xref="S3.SS1.p2.4.m4.1.2"><csymbol cd="ambiguous" id="S3.SS1.p2.4.m4.1.2.2.1.cmml" xref="S3.SS1.p2.4.m4.1.2">subscript</csymbol><ci id="S3.SS1.p2.4.m4.1.2.2.2.cmml" xref="S3.SS1.p2.4.m4.1.2.2.2">𝒯</ci><ci id="S3.SS1.p2.4.m4.1.2.2.3.cmml" xref="S3.SS1.p2.4.m4.1.2.2.3">𝑟</ci></apply><ci id="S3.SS1.p2.4.m4.1.1.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1.1.1">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.4.m4.1c">\mathcal{T}_{r}^{(i)}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.4.m4.1d">caligraphic_T start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_i ) end_POSTSUPERSCRIPT</annotation></semantics></math> (Section <a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#S3.SS1.SSS1" title="III-A1 Meta-features ‣ III-A MLRS Training process ‣ III The Proposed Multi-label meta-learning recommendation (MLRS) ‣ MLRS-PDS: A Meta-learning recommendation of dynamic ensemble selection pipelines"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-A</span>1</span></a>). Then, the combinations of pool and DS methods are assessed using its test partition denoted by <math alttext="\mathcal{T}_{e}^{(i)}" class="ltx_Math" display="inline" id="S3.SS1.p2.5.m5.1"><semantics id="S3.SS1.p2.5.m5.1a"><msubsup id="S3.SS1.p2.5.m5.1.2" xref="S3.SS1.p2.5.m5.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p2.5.m5.1.2.2.2" xref="S3.SS1.p2.5.m5.1.2.2.2.cmml">𝒯</mi><mi id="S3.SS1.p2.5.m5.1.2.2.3" xref="S3.SS1.p2.5.m5.1.2.2.3.cmml">e</mi><mrow id="S3.SS1.p2.5.m5.1.1.1.3" xref="S3.SS1.p2.5.m5.1.2.cmml"><mo id="S3.SS1.p2.5.m5.1.1.1.3.1" stretchy="false" xref="S3.SS1.p2.5.m5.1.2.cmml">(</mo><mi id="S3.SS1.p2.5.m5.1.1.1.1" xref="S3.SS1.p2.5.m5.1.1.1.1.cmml">i</mi><mo id="S3.SS1.p2.5.m5.1.1.1.3.2" stretchy="false" xref="S3.SS1.p2.5.m5.1.2.cmml">)</mo></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.5.m5.1b"><apply id="S3.SS1.p2.5.m5.1.2.cmml" xref="S3.SS1.p2.5.m5.1.2"><csymbol cd="ambiguous" id="S3.SS1.p2.5.m5.1.2.1.cmml" xref="S3.SS1.p2.5.m5.1.2">superscript</csymbol><apply id="S3.SS1.p2.5.m5.1.2.2.cmml" xref="S3.SS1.p2.5.m5.1.2"><csymbol cd="ambiguous" id="S3.SS1.p2.5.m5.1.2.2.1.cmml" xref="S3.SS1.p2.5.m5.1.2">subscript</csymbol><ci id="S3.SS1.p2.5.m5.1.2.2.2.cmml" xref="S3.SS1.p2.5.m5.1.2.2.2">𝒯</ci><ci id="S3.SS1.p2.5.m5.1.2.2.3.cmml" xref="S3.SS1.p2.5.m5.1.2.2.3">𝑒</ci></apply><ci id="S3.SS1.p2.5.m5.1.1.1.1.cmml" xref="S3.SS1.p2.5.m5.1.1.1.1">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.5.m5.1c">\mathcal{T}_{e}^{(i)}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.5.m5.1d">caligraphic_T start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_i ) end_POSTSUPERSCRIPT</annotation></semantics></math>. The configuration that obtains the highest performance is used to define the meta-target <math alttext="y_{i}^{\prime}" class="ltx_Math" display="inline" id="S3.SS1.p2.6.m6.1"><semantics id="S3.SS1.p2.6.m6.1a"><msubsup id="S3.SS1.p2.6.m6.1.1" xref="S3.SS1.p2.6.m6.1.1.cmml"><mi id="S3.SS1.p2.6.m6.1.1.2.2" xref="S3.SS1.p2.6.m6.1.1.2.2.cmml">y</mi><mi id="S3.SS1.p2.6.m6.1.1.2.3" xref="S3.SS1.p2.6.m6.1.1.2.3.cmml">i</mi><mo id="S3.SS1.p2.6.m6.1.1.3" xref="S3.SS1.p2.6.m6.1.1.3.cmml">′</mo></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.6.m6.1b"><apply id="S3.SS1.p2.6.m6.1.1.cmml" xref="S3.SS1.p2.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.6.m6.1.1.1.cmml" xref="S3.SS1.p2.6.m6.1.1">superscript</csymbol><apply id="S3.SS1.p2.6.m6.1.1.2.cmml" xref="S3.SS1.p2.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.6.m6.1.1.2.1.cmml" xref="S3.SS1.p2.6.m6.1.1">subscript</csymbol><ci id="S3.SS1.p2.6.m6.1.1.2.2.cmml" xref="S3.SS1.p2.6.m6.1.1.2.2">𝑦</ci><ci id="S3.SS1.p2.6.m6.1.1.2.3.cmml" xref="S3.SS1.p2.6.m6.1.1.2.3">𝑖</ci></apply><ci id="S3.SS1.p2.6.m6.1.1.3.cmml" xref="S3.SS1.p2.6.m6.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.6.m6.1c">y_{i}^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.6.m6.1d">italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT</annotation></semantics></math>.</p>
</div>
<div class="ltx_para" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.6">Then, a meta-dataset, <math alttext="MT" class="ltx_Math" display="inline" id="S3.SS1.p3.1.m1.1"><semantics id="S3.SS1.p3.1.m1.1a"><mrow id="S3.SS1.p3.1.m1.1.1" xref="S3.SS1.p3.1.m1.1.1.cmml"><mi id="S3.SS1.p3.1.m1.1.1.2" xref="S3.SS1.p3.1.m1.1.1.2.cmml">M</mi><mo id="S3.SS1.p3.1.m1.1.1.1" xref="S3.SS1.p3.1.m1.1.1.1.cmml">⁢</mo><mi id="S3.SS1.p3.1.m1.1.1.3" xref="S3.SS1.p3.1.m1.1.1.3.cmml">T</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.1.m1.1b"><apply id="S3.SS1.p3.1.m1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1"><times id="S3.SS1.p3.1.m1.1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1.1"></times><ci id="S3.SS1.p3.1.m1.1.1.2.cmml" xref="S3.SS1.p3.1.m1.1.1.2">𝑀</ci><ci id="S3.SS1.p3.1.m1.1.1.3.cmml" xref="S3.SS1.p3.1.m1.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.1.m1.1c">MT</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.1.m1.1d">italic_M italic_T</annotation></semantics></math>, is constructed using the meta-feature vector, <math alttext="\mathbf{x}_{i}^{\prime}" class="ltx_Math" display="inline" id="S3.SS1.p3.2.m2.1"><semantics id="S3.SS1.p3.2.m2.1a"><msubsup id="S3.SS1.p3.2.m2.1.1" xref="S3.SS1.p3.2.m2.1.1.cmml"><mi id="S3.SS1.p3.2.m2.1.1.2.2" xref="S3.SS1.p3.2.m2.1.1.2.2.cmml">𝐱</mi><mi id="S3.SS1.p3.2.m2.1.1.2.3" xref="S3.SS1.p3.2.m2.1.1.2.3.cmml">i</mi><mo id="S3.SS1.p3.2.m2.1.1.3" xref="S3.SS1.p3.2.m2.1.1.3.cmml">′</mo></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.2.m2.1b"><apply id="S3.SS1.p3.2.m2.1.1.cmml" xref="S3.SS1.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.2.m2.1.1.1.cmml" xref="S3.SS1.p3.2.m2.1.1">superscript</csymbol><apply id="S3.SS1.p3.2.m2.1.1.2.cmml" xref="S3.SS1.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.2.m2.1.1.2.1.cmml" xref="S3.SS1.p3.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.p3.2.m2.1.1.2.2.cmml" xref="S3.SS1.p3.2.m2.1.1.2.2">𝐱</ci><ci id="S3.SS1.p3.2.m2.1.1.2.3.cmml" xref="S3.SS1.p3.2.m2.1.1.2.3">𝑖</ci></apply><ci id="S3.SS1.p3.2.m2.1.1.3.cmml" xref="S3.SS1.p3.2.m2.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.2.m2.1c">\mathbf{x}_{i}^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.2.m2.1d">bold_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT</annotation></semantics></math>, and the meta-target, <math alttext="y_{i}^{\prime}" class="ltx_Math" display="inline" id="S3.SS1.p3.3.m3.1"><semantics id="S3.SS1.p3.3.m3.1a"><msubsup id="S3.SS1.p3.3.m3.1.1" xref="S3.SS1.p3.3.m3.1.1.cmml"><mi id="S3.SS1.p3.3.m3.1.1.2.2" xref="S3.SS1.p3.3.m3.1.1.2.2.cmml">y</mi><mi id="S3.SS1.p3.3.m3.1.1.2.3" xref="S3.SS1.p3.3.m3.1.1.2.3.cmml">i</mi><mo id="S3.SS1.p3.3.m3.1.1.3" xref="S3.SS1.p3.3.m3.1.1.3.cmml">′</mo></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.3.m3.1b"><apply id="S3.SS1.p3.3.m3.1.1.cmml" xref="S3.SS1.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.3.m3.1.1.1.cmml" xref="S3.SS1.p3.3.m3.1.1">superscript</csymbol><apply id="S3.SS1.p3.3.m3.1.1.2.cmml" xref="S3.SS1.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.3.m3.1.1.2.1.cmml" xref="S3.SS1.p3.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.p3.3.m3.1.1.2.2.cmml" xref="S3.SS1.p3.3.m3.1.1.2.2">𝑦</ci><ci id="S3.SS1.p3.3.m3.1.1.2.3.cmml" xref="S3.SS1.p3.3.m3.1.1.2.3">𝑖</ci></apply><ci id="S3.SS1.p3.3.m3.1.1.3.cmml" xref="S3.SS1.p3.3.m3.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.3.m3.1c">y_{i}^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.3.m3.1d">italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT</annotation></semantics></math>, extracted from all training datasets. Subsequently, a meta-model <math alttext="\lambda" class="ltx_Math" display="inline" id="S3.SS1.p3.4.m4.1"><semantics id="S3.SS1.p3.4.m4.1a"><mi id="S3.SS1.p3.4.m4.1.1" xref="S3.SS1.p3.4.m4.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.4.m4.1b"><ci id="S3.SS1.p3.4.m4.1.1.cmml" xref="S3.SS1.p3.4.m4.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.4.m4.1c">\lambda</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.4.m4.1d">italic_λ</annotation></semantics></math> is trained using the meta-dataset, <math alttext="MT" class="ltx_Math" display="inline" id="S3.SS1.p3.5.m5.1"><semantics id="S3.SS1.p3.5.m5.1a"><mrow id="S3.SS1.p3.5.m5.1.1" xref="S3.SS1.p3.5.m5.1.1.cmml"><mi id="S3.SS1.p3.5.m5.1.1.2" xref="S3.SS1.p3.5.m5.1.1.2.cmml">M</mi><mo id="S3.SS1.p3.5.m5.1.1.1" xref="S3.SS1.p3.5.m5.1.1.1.cmml">⁢</mo><mi id="S3.SS1.p3.5.m5.1.1.3" xref="S3.SS1.p3.5.m5.1.1.3.cmml">T</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.5.m5.1b"><apply id="S3.SS1.p3.5.m5.1.1.cmml" xref="S3.SS1.p3.5.m5.1.1"><times id="S3.SS1.p3.5.m5.1.1.1.cmml" xref="S3.SS1.p3.5.m5.1.1.1"></times><ci id="S3.SS1.p3.5.m5.1.1.2.cmml" xref="S3.SS1.p3.5.m5.1.1.2">𝑀</ci><ci id="S3.SS1.p3.5.m5.1.1.3.cmml" xref="S3.SS1.p3.5.m5.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.5.m5.1c">MT</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.5.m5.1d">italic_M italic_T</annotation></semantics></math>, to learn the mapping between the dataset characteristics and which models are more likely to obtain higher performance. The MLRS allows us to investigate three possible recommendation scenarios, each one generating a different meta-learning model <math alttext="\lambda" class="ltx_Math" display="inline" id="S3.SS1.p3.6.m6.1"><semantics id="S3.SS1.p3.6.m6.1a"><mi id="S3.SS1.p3.6.m6.1.1" xref="S3.SS1.p3.6.m6.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.6.m6.1b"><ci id="S3.SS1.p3.6.m6.1.1.cmml" xref="S3.SS1.p3.6.m6.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.6.m6.1c">\lambda</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.6.m6.1d">italic_λ</annotation></semantics></math> for the given task:</p>
</div>
<div class="ltx_para" id="S3.SS1.p4">
<ul class="ltx_itemize" id="S3.I1">
<li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I1.i1.p1">
<p class="ltx_p" id="S3.I1.i1.p1.3"><span class="ltx_text ltx_font_bold" id="S3.I1.i1.p1.3.1">Scenario I, MLRS-P:</span> The system is trained to recommend an optimal pool generation scheme conditioned to a specific DS method. In this meta-learning scenario, the meta-target <math alttext="y^{\prime}=y^{\prime}_{pool}" class="ltx_Math" display="inline" id="S3.I1.i1.p1.1.m1.1"><semantics id="S3.I1.i1.p1.1.m1.1a"><mrow id="S3.I1.i1.p1.1.m1.1.1" xref="S3.I1.i1.p1.1.m1.1.1.cmml"><msup id="S3.I1.i1.p1.1.m1.1.1.2" xref="S3.I1.i1.p1.1.m1.1.1.2.cmml"><mi id="S3.I1.i1.p1.1.m1.1.1.2.2" xref="S3.I1.i1.p1.1.m1.1.1.2.2.cmml">y</mi><mo id="S3.I1.i1.p1.1.m1.1.1.2.3" xref="S3.I1.i1.p1.1.m1.1.1.2.3.cmml">′</mo></msup><mo id="S3.I1.i1.p1.1.m1.1.1.1" xref="S3.I1.i1.p1.1.m1.1.1.1.cmml">=</mo><msubsup id="S3.I1.i1.p1.1.m1.1.1.3" xref="S3.I1.i1.p1.1.m1.1.1.3.cmml"><mi id="S3.I1.i1.p1.1.m1.1.1.3.2.2" xref="S3.I1.i1.p1.1.m1.1.1.3.2.2.cmml">y</mi><mrow id="S3.I1.i1.p1.1.m1.1.1.3.3" xref="S3.I1.i1.p1.1.m1.1.1.3.3.cmml"><mi id="S3.I1.i1.p1.1.m1.1.1.3.3.2" xref="S3.I1.i1.p1.1.m1.1.1.3.3.2.cmml">p</mi><mo id="S3.I1.i1.p1.1.m1.1.1.3.3.1" xref="S3.I1.i1.p1.1.m1.1.1.3.3.1.cmml">⁢</mo><mi id="S3.I1.i1.p1.1.m1.1.1.3.3.3" xref="S3.I1.i1.p1.1.m1.1.1.3.3.3.cmml">o</mi><mo id="S3.I1.i1.p1.1.m1.1.1.3.3.1a" xref="S3.I1.i1.p1.1.m1.1.1.3.3.1.cmml">⁢</mo><mi id="S3.I1.i1.p1.1.m1.1.1.3.3.4" xref="S3.I1.i1.p1.1.m1.1.1.3.3.4.cmml">o</mi><mo id="S3.I1.i1.p1.1.m1.1.1.3.3.1b" xref="S3.I1.i1.p1.1.m1.1.1.3.3.1.cmml">⁢</mo><mi id="S3.I1.i1.p1.1.m1.1.1.3.3.5" xref="S3.I1.i1.p1.1.m1.1.1.3.3.5.cmml">l</mi></mrow><mo id="S3.I1.i1.p1.1.m1.1.1.3.2.3" xref="S3.I1.i1.p1.1.m1.1.1.3.2.3.cmml">′</mo></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S3.I1.i1.p1.1.m1.1b"><apply id="S3.I1.i1.p1.1.m1.1.1.cmml" xref="S3.I1.i1.p1.1.m1.1.1"><eq id="S3.I1.i1.p1.1.m1.1.1.1.cmml" xref="S3.I1.i1.p1.1.m1.1.1.1"></eq><apply id="S3.I1.i1.p1.1.m1.1.1.2.cmml" xref="S3.I1.i1.p1.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.I1.i1.p1.1.m1.1.1.2.1.cmml" xref="S3.I1.i1.p1.1.m1.1.1.2">superscript</csymbol><ci id="S3.I1.i1.p1.1.m1.1.1.2.2.cmml" xref="S3.I1.i1.p1.1.m1.1.1.2.2">𝑦</ci><ci id="S3.I1.i1.p1.1.m1.1.1.2.3.cmml" xref="S3.I1.i1.p1.1.m1.1.1.2.3">′</ci></apply><apply id="S3.I1.i1.p1.1.m1.1.1.3.cmml" xref="S3.I1.i1.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.I1.i1.p1.1.m1.1.1.3.1.cmml" xref="S3.I1.i1.p1.1.m1.1.1.3">subscript</csymbol><apply id="S3.I1.i1.p1.1.m1.1.1.3.2.cmml" xref="S3.I1.i1.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.I1.i1.p1.1.m1.1.1.3.2.1.cmml" xref="S3.I1.i1.p1.1.m1.1.1.3">superscript</csymbol><ci id="S3.I1.i1.p1.1.m1.1.1.3.2.2.cmml" xref="S3.I1.i1.p1.1.m1.1.1.3.2.2">𝑦</ci><ci id="S3.I1.i1.p1.1.m1.1.1.3.2.3.cmml" xref="S3.I1.i1.p1.1.m1.1.1.3.2.3">′</ci></apply><apply id="S3.I1.i1.p1.1.m1.1.1.3.3.cmml" xref="S3.I1.i1.p1.1.m1.1.1.3.3"><times id="S3.I1.i1.p1.1.m1.1.1.3.3.1.cmml" xref="S3.I1.i1.p1.1.m1.1.1.3.3.1"></times><ci id="S3.I1.i1.p1.1.m1.1.1.3.3.2.cmml" xref="S3.I1.i1.p1.1.m1.1.1.3.3.2">𝑝</ci><ci id="S3.I1.i1.p1.1.m1.1.1.3.3.3.cmml" xref="S3.I1.i1.p1.1.m1.1.1.3.3.3">𝑜</ci><ci id="S3.I1.i1.p1.1.m1.1.1.3.3.4.cmml" xref="S3.I1.i1.p1.1.m1.1.1.3.3.4">𝑜</ci><ci id="S3.I1.i1.p1.1.m1.1.1.3.3.5.cmml" xref="S3.I1.i1.p1.1.m1.1.1.3.3.5">𝑙</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i1.p1.1.m1.1c">y^{\prime}=y^{\prime}_{pool}</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i1.p1.1.m1.1d">italic_y start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT = italic_y start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_p italic_o italic_o italic_l end_POSTSUBSCRIPT</annotation></semantics></math> is the pool generation scheme that achieved the highest classification performance when used with the predefined DS method specified by the user. In this case, <math alttext="\mathbb{DS}" class="ltx_Math" display="inline" id="S3.I1.i1.p1.2.m2.1"><semantics id="S3.I1.i1.p1.2.m2.1a"><mrow id="S3.I1.i1.p1.2.m2.1.1" xref="S3.I1.i1.p1.2.m2.1.1.cmml"><mi id="S3.I1.i1.p1.2.m2.1.1.2" xref="S3.I1.i1.p1.2.m2.1.1.2.cmml">𝔻</mi><mo id="S3.I1.i1.p1.2.m2.1.1.1" xref="S3.I1.i1.p1.2.m2.1.1.1.cmml">⁢</mo><mi id="S3.I1.i1.p1.2.m2.1.1.3" xref="S3.I1.i1.p1.2.m2.1.1.3.cmml">𝕊</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.I1.i1.p1.2.m2.1b"><apply id="S3.I1.i1.p1.2.m2.1.1.cmml" xref="S3.I1.i1.p1.2.m2.1.1"><times id="S3.I1.i1.p1.2.m2.1.1.1.cmml" xref="S3.I1.i1.p1.2.m2.1.1.1"></times><ci id="S3.I1.i1.p1.2.m2.1.1.2.cmml" xref="S3.I1.i1.p1.2.m2.1.1.2">𝔻</ci><ci id="S3.I1.i1.p1.2.m2.1.1.3.cmml" xref="S3.I1.i1.p1.2.m2.1.1.3">𝕊</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i1.p1.2.m2.1c">\mathbb{DS}</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i1.p1.2.m2.1d">blackboard_D blackboard_S</annotation></semantics></math> consists of a single model, that is, the predefined DS, and the meta-classifier <math alttext="\lambda_{pool}" class="ltx_Math" display="inline" id="S3.I1.i1.p1.3.m3.1"><semantics id="S3.I1.i1.p1.3.m3.1a"><msub id="S3.I1.i1.p1.3.m3.1.1" xref="S3.I1.i1.p1.3.m3.1.1.cmml"><mi id="S3.I1.i1.p1.3.m3.1.1.2" xref="S3.I1.i1.p1.3.m3.1.1.2.cmml">λ</mi><mrow id="S3.I1.i1.p1.3.m3.1.1.3" xref="S3.I1.i1.p1.3.m3.1.1.3.cmml"><mi id="S3.I1.i1.p1.3.m3.1.1.3.2" xref="S3.I1.i1.p1.3.m3.1.1.3.2.cmml">p</mi><mo id="S3.I1.i1.p1.3.m3.1.1.3.1" xref="S3.I1.i1.p1.3.m3.1.1.3.1.cmml">⁢</mo><mi id="S3.I1.i1.p1.3.m3.1.1.3.3" xref="S3.I1.i1.p1.3.m3.1.1.3.3.cmml">o</mi><mo id="S3.I1.i1.p1.3.m3.1.1.3.1a" xref="S3.I1.i1.p1.3.m3.1.1.3.1.cmml">⁢</mo><mi id="S3.I1.i1.p1.3.m3.1.1.3.4" xref="S3.I1.i1.p1.3.m3.1.1.3.4.cmml">o</mi><mo id="S3.I1.i1.p1.3.m3.1.1.3.1b" xref="S3.I1.i1.p1.3.m3.1.1.3.1.cmml">⁢</mo><mi id="S3.I1.i1.p1.3.m3.1.1.3.5" xref="S3.I1.i1.p1.3.m3.1.1.3.5.cmml">l</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.I1.i1.p1.3.m3.1b"><apply id="S3.I1.i1.p1.3.m3.1.1.cmml" xref="S3.I1.i1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.I1.i1.p1.3.m3.1.1.1.cmml" xref="S3.I1.i1.p1.3.m3.1.1">subscript</csymbol><ci id="S3.I1.i1.p1.3.m3.1.1.2.cmml" xref="S3.I1.i1.p1.3.m3.1.1.2">𝜆</ci><apply id="S3.I1.i1.p1.3.m3.1.1.3.cmml" xref="S3.I1.i1.p1.3.m3.1.1.3"><times id="S3.I1.i1.p1.3.m3.1.1.3.1.cmml" xref="S3.I1.i1.p1.3.m3.1.1.3.1"></times><ci id="S3.I1.i1.p1.3.m3.1.1.3.2.cmml" xref="S3.I1.i1.p1.3.m3.1.1.3.2">𝑝</ci><ci id="S3.I1.i1.p1.3.m3.1.1.3.3.cmml" xref="S3.I1.i1.p1.3.m3.1.1.3.3">𝑜</ci><ci id="S3.I1.i1.p1.3.m3.1.1.3.4.cmml" xref="S3.I1.i1.p1.3.m3.1.1.3.4">𝑜</ci><ci id="S3.I1.i1.p1.3.m3.1.1.3.5.cmml" xref="S3.I1.i1.p1.3.m3.1.1.3.5">𝑙</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i1.p1.3.m3.1c">\lambda_{pool}</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i1.p1.3.m3.1d">italic_λ start_POSTSUBSCRIPT italic_p italic_o italic_o italic_l end_POSTSUBSCRIPT</annotation></semantics></math> is specifically trained to make recommendations for it.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I1.i2.p1">
<p class="ltx_p" id="S3.I1.i2.p1.3"><span class="ltx_text ltx_font_bold" id="S3.I1.i2.p1.3.1">Scenario II, MLRS-DS:</span> The system is trained to recommend an optimal DS method given a specific pool generation scheme. Here, the meta-target <math alttext="y^{\prime}=y^{\prime}_{DS}" class="ltx_Math" display="inline" id="S3.I1.i2.p1.1.m1.1"><semantics id="S3.I1.i2.p1.1.m1.1a"><mrow id="S3.I1.i2.p1.1.m1.1.1" xref="S3.I1.i2.p1.1.m1.1.1.cmml"><msup id="S3.I1.i2.p1.1.m1.1.1.2" xref="S3.I1.i2.p1.1.m1.1.1.2.cmml"><mi id="S3.I1.i2.p1.1.m1.1.1.2.2" xref="S3.I1.i2.p1.1.m1.1.1.2.2.cmml">y</mi><mo id="S3.I1.i2.p1.1.m1.1.1.2.3" xref="S3.I1.i2.p1.1.m1.1.1.2.3.cmml">′</mo></msup><mo id="S3.I1.i2.p1.1.m1.1.1.1" xref="S3.I1.i2.p1.1.m1.1.1.1.cmml">=</mo><msubsup id="S3.I1.i2.p1.1.m1.1.1.3" xref="S3.I1.i2.p1.1.m1.1.1.3.cmml"><mi id="S3.I1.i2.p1.1.m1.1.1.3.2.2" xref="S3.I1.i2.p1.1.m1.1.1.3.2.2.cmml">y</mi><mrow id="S3.I1.i2.p1.1.m1.1.1.3.3" xref="S3.I1.i2.p1.1.m1.1.1.3.3.cmml"><mi id="S3.I1.i2.p1.1.m1.1.1.3.3.2" xref="S3.I1.i2.p1.1.m1.1.1.3.3.2.cmml">D</mi><mo id="S3.I1.i2.p1.1.m1.1.1.3.3.1" xref="S3.I1.i2.p1.1.m1.1.1.3.3.1.cmml">⁢</mo><mi id="S3.I1.i2.p1.1.m1.1.1.3.3.3" xref="S3.I1.i2.p1.1.m1.1.1.3.3.3.cmml">S</mi></mrow><mo id="S3.I1.i2.p1.1.m1.1.1.3.2.3" xref="S3.I1.i2.p1.1.m1.1.1.3.2.3.cmml">′</mo></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S3.I1.i2.p1.1.m1.1b"><apply id="S3.I1.i2.p1.1.m1.1.1.cmml" xref="S3.I1.i2.p1.1.m1.1.1"><eq id="S3.I1.i2.p1.1.m1.1.1.1.cmml" xref="S3.I1.i2.p1.1.m1.1.1.1"></eq><apply id="S3.I1.i2.p1.1.m1.1.1.2.cmml" xref="S3.I1.i2.p1.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.I1.i2.p1.1.m1.1.1.2.1.cmml" xref="S3.I1.i2.p1.1.m1.1.1.2">superscript</csymbol><ci id="S3.I1.i2.p1.1.m1.1.1.2.2.cmml" xref="S3.I1.i2.p1.1.m1.1.1.2.2">𝑦</ci><ci id="S3.I1.i2.p1.1.m1.1.1.2.3.cmml" xref="S3.I1.i2.p1.1.m1.1.1.2.3">′</ci></apply><apply id="S3.I1.i2.p1.1.m1.1.1.3.cmml" xref="S3.I1.i2.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.I1.i2.p1.1.m1.1.1.3.1.cmml" xref="S3.I1.i2.p1.1.m1.1.1.3">subscript</csymbol><apply id="S3.I1.i2.p1.1.m1.1.1.3.2.cmml" xref="S3.I1.i2.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.I1.i2.p1.1.m1.1.1.3.2.1.cmml" xref="S3.I1.i2.p1.1.m1.1.1.3">superscript</csymbol><ci id="S3.I1.i2.p1.1.m1.1.1.3.2.2.cmml" xref="S3.I1.i2.p1.1.m1.1.1.3.2.2">𝑦</ci><ci id="S3.I1.i2.p1.1.m1.1.1.3.2.3.cmml" xref="S3.I1.i2.p1.1.m1.1.1.3.2.3">′</ci></apply><apply id="S3.I1.i2.p1.1.m1.1.1.3.3.cmml" xref="S3.I1.i2.p1.1.m1.1.1.3.3"><times id="S3.I1.i2.p1.1.m1.1.1.3.3.1.cmml" xref="S3.I1.i2.p1.1.m1.1.1.3.3.1"></times><ci id="S3.I1.i2.p1.1.m1.1.1.3.3.2.cmml" xref="S3.I1.i2.p1.1.m1.1.1.3.3.2">𝐷</ci><ci id="S3.I1.i2.p1.1.m1.1.1.3.3.3.cmml" xref="S3.I1.i2.p1.1.m1.1.1.3.3.3">𝑆</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i2.p1.1.m1.1c">y^{\prime}=y^{\prime}_{DS}</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i2.p1.1.m1.1d">italic_y start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT = italic_y start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_D italic_S end_POSTSUBSCRIPT</annotation></semantics></math> is the DS method that exhibited the highest classification performance with the predetermined pool generation scheme. In this scenario, <math alttext="\mathbb{P}" class="ltx_Math" display="inline" id="S3.I1.i2.p1.2.m2.1"><semantics id="S3.I1.i2.p1.2.m2.1a"><mi id="S3.I1.i2.p1.2.m2.1.1" xref="S3.I1.i2.p1.2.m2.1.1.cmml">ℙ</mi><annotation-xml encoding="MathML-Content" id="S3.I1.i2.p1.2.m2.1b"><ci id="S3.I1.i2.p1.2.m2.1.1.cmml" xref="S3.I1.i2.p1.2.m2.1.1">ℙ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i2.p1.2.m2.1c">\mathbb{P}</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i2.p1.2.m2.1d">blackboard_P</annotation></semantics></math> consists of a single pool generation scheme, and the meta-classifier <math alttext="\lambda_{DS}" class="ltx_Math" display="inline" id="S3.I1.i2.p1.3.m3.1"><semantics id="S3.I1.i2.p1.3.m3.1a"><msub id="S3.I1.i2.p1.3.m3.1.1" xref="S3.I1.i2.p1.3.m3.1.1.cmml"><mi id="S3.I1.i2.p1.3.m3.1.1.2" xref="S3.I1.i2.p1.3.m3.1.1.2.cmml">λ</mi><mrow id="S3.I1.i2.p1.3.m3.1.1.3" xref="S3.I1.i2.p1.3.m3.1.1.3.cmml"><mi id="S3.I1.i2.p1.3.m3.1.1.3.2" xref="S3.I1.i2.p1.3.m3.1.1.3.2.cmml">D</mi><mo id="S3.I1.i2.p1.3.m3.1.1.3.1" xref="S3.I1.i2.p1.3.m3.1.1.3.1.cmml">⁢</mo><mi id="S3.I1.i2.p1.3.m3.1.1.3.3" xref="S3.I1.i2.p1.3.m3.1.1.3.3.cmml">S</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.I1.i2.p1.3.m3.1b"><apply id="S3.I1.i2.p1.3.m3.1.1.cmml" xref="S3.I1.i2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.I1.i2.p1.3.m3.1.1.1.cmml" xref="S3.I1.i2.p1.3.m3.1.1">subscript</csymbol><ci id="S3.I1.i2.p1.3.m3.1.1.2.cmml" xref="S3.I1.i2.p1.3.m3.1.1.2">𝜆</ci><apply id="S3.I1.i2.p1.3.m3.1.1.3.cmml" xref="S3.I1.i2.p1.3.m3.1.1.3"><times id="S3.I1.i2.p1.3.m3.1.1.3.1.cmml" xref="S3.I1.i2.p1.3.m3.1.1.3.1"></times><ci id="S3.I1.i2.p1.3.m3.1.1.3.2.cmml" xref="S3.I1.i2.p1.3.m3.1.1.3.2">𝐷</ci><ci id="S3.I1.i2.p1.3.m3.1.1.3.3.cmml" xref="S3.I1.i2.p1.3.m3.1.1.3.3">𝑆</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i2.p1.3.m3.1c">\lambda_{DS}</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i2.p1.3.m3.1d">italic_λ start_POSTSUBSCRIPT italic_D italic_S end_POSTSUBSCRIPT</annotation></semantics></math> is specifically trained to make recommendations for it.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I1.i3.p1">
<p class="ltx_p" id="S3.I1.i3.p1.4"><span class="ltx_text ltx_font_bold" id="S3.I1.i3.p1.4.1">Scenario III, MLRS-PDS:</span> The system is trained to recommend an optimal pair (Pool, DS) based solely on the problem characteristics. The meta-target in this context is the tuple <math alttext="(y^{\prime}_{pool},y^{\prime}_{DS})" class="ltx_Math" display="inline" id="S3.I1.i3.p1.1.m1.2"><semantics id="S3.I1.i3.p1.1.m1.2a"><mrow id="S3.I1.i3.p1.1.m1.2.2.2" xref="S3.I1.i3.p1.1.m1.2.2.3.cmml"><mo id="S3.I1.i3.p1.1.m1.2.2.2.3" stretchy="false" xref="S3.I1.i3.p1.1.m1.2.2.3.cmml">(</mo><msubsup id="S3.I1.i3.p1.1.m1.1.1.1.1" xref="S3.I1.i3.p1.1.m1.1.1.1.1.cmml"><mi id="S3.I1.i3.p1.1.m1.1.1.1.1.2.2" xref="S3.I1.i3.p1.1.m1.1.1.1.1.2.2.cmml">y</mi><mrow id="S3.I1.i3.p1.1.m1.1.1.1.1.3" xref="S3.I1.i3.p1.1.m1.1.1.1.1.3.cmml"><mi id="S3.I1.i3.p1.1.m1.1.1.1.1.3.2" xref="S3.I1.i3.p1.1.m1.1.1.1.1.3.2.cmml">p</mi><mo id="S3.I1.i3.p1.1.m1.1.1.1.1.3.1" xref="S3.I1.i3.p1.1.m1.1.1.1.1.3.1.cmml">⁢</mo><mi id="S3.I1.i3.p1.1.m1.1.1.1.1.3.3" xref="S3.I1.i3.p1.1.m1.1.1.1.1.3.3.cmml">o</mi><mo id="S3.I1.i3.p1.1.m1.1.1.1.1.3.1a" xref="S3.I1.i3.p1.1.m1.1.1.1.1.3.1.cmml">⁢</mo><mi id="S3.I1.i3.p1.1.m1.1.1.1.1.3.4" xref="S3.I1.i3.p1.1.m1.1.1.1.1.3.4.cmml">o</mi><mo id="S3.I1.i3.p1.1.m1.1.1.1.1.3.1b" xref="S3.I1.i3.p1.1.m1.1.1.1.1.3.1.cmml">⁢</mo><mi id="S3.I1.i3.p1.1.m1.1.1.1.1.3.5" xref="S3.I1.i3.p1.1.m1.1.1.1.1.3.5.cmml">l</mi></mrow><mo id="S3.I1.i3.p1.1.m1.1.1.1.1.2.3" xref="S3.I1.i3.p1.1.m1.1.1.1.1.2.3.cmml">′</mo></msubsup><mo id="S3.I1.i3.p1.1.m1.2.2.2.4" xref="S3.I1.i3.p1.1.m1.2.2.3.cmml">,</mo><msubsup id="S3.I1.i3.p1.1.m1.2.2.2.2" xref="S3.I1.i3.p1.1.m1.2.2.2.2.cmml"><mi id="S3.I1.i3.p1.1.m1.2.2.2.2.2.2" xref="S3.I1.i3.p1.1.m1.2.2.2.2.2.2.cmml">y</mi><mrow id="S3.I1.i3.p1.1.m1.2.2.2.2.3" xref="S3.I1.i3.p1.1.m1.2.2.2.2.3.cmml"><mi id="S3.I1.i3.p1.1.m1.2.2.2.2.3.2" xref="S3.I1.i3.p1.1.m1.2.2.2.2.3.2.cmml">D</mi><mo id="S3.I1.i3.p1.1.m1.2.2.2.2.3.1" xref="S3.I1.i3.p1.1.m1.2.2.2.2.3.1.cmml">⁢</mo><mi id="S3.I1.i3.p1.1.m1.2.2.2.2.3.3" xref="S3.I1.i3.p1.1.m1.2.2.2.2.3.3.cmml">S</mi></mrow><mo id="S3.I1.i3.p1.1.m1.2.2.2.2.2.3" xref="S3.I1.i3.p1.1.m1.2.2.2.2.2.3.cmml">′</mo></msubsup><mo id="S3.I1.i3.p1.1.m1.2.2.2.5" stretchy="false" xref="S3.I1.i3.p1.1.m1.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.I1.i3.p1.1.m1.2b"><interval closure="open" id="S3.I1.i3.p1.1.m1.2.2.3.cmml" xref="S3.I1.i3.p1.1.m1.2.2.2"><apply id="S3.I1.i3.p1.1.m1.1.1.1.1.cmml" xref="S3.I1.i3.p1.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.I1.i3.p1.1.m1.1.1.1.1.1.cmml" xref="S3.I1.i3.p1.1.m1.1.1.1.1">subscript</csymbol><apply id="S3.I1.i3.p1.1.m1.1.1.1.1.2.cmml" xref="S3.I1.i3.p1.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.I1.i3.p1.1.m1.1.1.1.1.2.1.cmml" xref="S3.I1.i3.p1.1.m1.1.1.1.1">superscript</csymbol><ci id="S3.I1.i3.p1.1.m1.1.1.1.1.2.2.cmml" xref="S3.I1.i3.p1.1.m1.1.1.1.1.2.2">𝑦</ci><ci id="S3.I1.i3.p1.1.m1.1.1.1.1.2.3.cmml" xref="S3.I1.i3.p1.1.m1.1.1.1.1.2.3">′</ci></apply><apply id="S3.I1.i3.p1.1.m1.1.1.1.1.3.cmml" xref="S3.I1.i3.p1.1.m1.1.1.1.1.3"><times id="S3.I1.i3.p1.1.m1.1.1.1.1.3.1.cmml" xref="S3.I1.i3.p1.1.m1.1.1.1.1.3.1"></times><ci id="S3.I1.i3.p1.1.m1.1.1.1.1.3.2.cmml" xref="S3.I1.i3.p1.1.m1.1.1.1.1.3.2">𝑝</ci><ci id="S3.I1.i3.p1.1.m1.1.1.1.1.3.3.cmml" xref="S3.I1.i3.p1.1.m1.1.1.1.1.3.3">𝑜</ci><ci id="S3.I1.i3.p1.1.m1.1.1.1.1.3.4.cmml" xref="S3.I1.i3.p1.1.m1.1.1.1.1.3.4">𝑜</ci><ci id="S3.I1.i3.p1.1.m1.1.1.1.1.3.5.cmml" xref="S3.I1.i3.p1.1.m1.1.1.1.1.3.5">𝑙</ci></apply></apply><apply id="S3.I1.i3.p1.1.m1.2.2.2.2.cmml" xref="S3.I1.i3.p1.1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S3.I1.i3.p1.1.m1.2.2.2.2.1.cmml" xref="S3.I1.i3.p1.1.m1.2.2.2.2">subscript</csymbol><apply id="S3.I1.i3.p1.1.m1.2.2.2.2.2.cmml" xref="S3.I1.i3.p1.1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S3.I1.i3.p1.1.m1.2.2.2.2.2.1.cmml" xref="S3.I1.i3.p1.1.m1.2.2.2.2">superscript</csymbol><ci id="S3.I1.i3.p1.1.m1.2.2.2.2.2.2.cmml" xref="S3.I1.i3.p1.1.m1.2.2.2.2.2.2">𝑦</ci><ci id="S3.I1.i3.p1.1.m1.2.2.2.2.2.3.cmml" xref="S3.I1.i3.p1.1.m1.2.2.2.2.2.3">′</ci></apply><apply id="S3.I1.i3.p1.1.m1.2.2.2.2.3.cmml" xref="S3.I1.i3.p1.1.m1.2.2.2.2.3"><times id="S3.I1.i3.p1.1.m1.2.2.2.2.3.1.cmml" xref="S3.I1.i3.p1.1.m1.2.2.2.2.3.1"></times><ci id="S3.I1.i3.p1.1.m1.2.2.2.2.3.2.cmml" xref="S3.I1.i3.p1.1.m1.2.2.2.2.3.2">𝐷</ci><ci id="S3.I1.i3.p1.1.m1.2.2.2.2.3.3.cmml" xref="S3.I1.i3.p1.1.m1.2.2.2.2.3.3">𝑆</ci></apply></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i3.p1.1.m1.2c">(y^{\prime}_{pool},y^{\prime}_{DS})</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i3.p1.1.m1.2d">( italic_y start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_p italic_o italic_o italic_l end_POSTSUBSCRIPT , italic_y start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_D italic_S end_POSTSUBSCRIPT )</annotation></semantics></math> that delivered the best performance compared to other configurations, representing a multi-label meta-learning recommendation problem. A classifier chain <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib30" title="">30</a>]</cite> is employed to train the meta-classifier for this task, with the prediction order being recommending pool first, then recommending DS method conditioned on the first recommendation. As this scenario is fully automated and considers all possible configurations, both <math alttext="\mathbb{P}" class="ltx_Math" display="inline" id="S3.I1.i3.p1.2.m2.1"><semantics id="S3.I1.i3.p1.2.m2.1a"><mi id="S3.I1.i3.p1.2.m2.1.1" xref="S3.I1.i3.p1.2.m2.1.1.cmml">ℙ</mi><annotation-xml encoding="MathML-Content" id="S3.I1.i3.p1.2.m2.1b"><ci id="S3.I1.i3.p1.2.m2.1.1.cmml" xref="S3.I1.i3.p1.2.m2.1.1">ℙ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i3.p1.2.m2.1c">\mathbb{P}</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i3.p1.2.m2.1d">blackboard_P</annotation></semantics></math> and <math alttext="\mathbb{DS}" class="ltx_Math" display="inline" id="S3.I1.i3.p1.3.m3.1"><semantics id="S3.I1.i3.p1.3.m3.1a"><mrow id="S3.I1.i3.p1.3.m3.1.1" xref="S3.I1.i3.p1.3.m3.1.1.cmml"><mi id="S3.I1.i3.p1.3.m3.1.1.2" xref="S3.I1.i3.p1.3.m3.1.1.2.cmml">𝔻</mi><mo id="S3.I1.i3.p1.3.m3.1.1.1" xref="S3.I1.i3.p1.3.m3.1.1.1.cmml">⁢</mo><mi id="S3.I1.i3.p1.3.m3.1.1.3" xref="S3.I1.i3.p1.3.m3.1.1.3.cmml">𝕊</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.I1.i3.p1.3.m3.1b"><apply id="S3.I1.i3.p1.3.m3.1.1.cmml" xref="S3.I1.i3.p1.3.m3.1.1"><times id="S3.I1.i3.p1.3.m3.1.1.1.cmml" xref="S3.I1.i3.p1.3.m3.1.1.1"></times><ci id="S3.I1.i3.p1.3.m3.1.1.2.cmml" xref="S3.I1.i3.p1.3.m3.1.1.2">𝔻</ci><ci id="S3.I1.i3.p1.3.m3.1.1.3.cmml" xref="S3.I1.i3.p1.3.m3.1.1.3">𝕊</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i3.p1.3.m3.1c">\mathbb{DS}</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i3.p1.3.m3.1d">blackboard_D blackboard_S</annotation></semantics></math> consist of multiple elements to generate the meta-training data <math alttext="MT" class="ltx_Math" display="inline" id="S3.I1.i3.p1.4.m4.1"><semantics id="S3.I1.i3.p1.4.m4.1a"><mrow id="S3.I1.i3.p1.4.m4.1.1" xref="S3.I1.i3.p1.4.m4.1.1.cmml"><mi id="S3.I1.i3.p1.4.m4.1.1.2" xref="S3.I1.i3.p1.4.m4.1.1.2.cmml">M</mi><mo id="S3.I1.i3.p1.4.m4.1.1.1" xref="S3.I1.i3.p1.4.m4.1.1.1.cmml">⁢</mo><mi id="S3.I1.i3.p1.4.m4.1.1.3" xref="S3.I1.i3.p1.4.m4.1.1.3.cmml">T</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.I1.i3.p1.4.m4.1b"><apply id="S3.I1.i3.p1.4.m4.1.1.cmml" xref="S3.I1.i3.p1.4.m4.1.1"><times id="S3.I1.i3.p1.4.m4.1.1.1.cmml" xref="S3.I1.i3.p1.4.m4.1.1.1"></times><ci id="S3.I1.i3.p1.4.m4.1.1.2.cmml" xref="S3.I1.i3.p1.4.m4.1.1.2">𝑀</ci><ci id="S3.I1.i3.p1.4.m4.1.1.3.cmml" xref="S3.I1.i3.p1.4.m4.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i3.p1.4.m4.1c">MT</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i3.p1.4.m4.1d">italic_M italic_T</annotation></semantics></math>.</p>
</div>
</li>
</ul>
</div>
<section class="ltx_subsubsection" id="S3.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span class="ltx_text" id="S3.SS1.SSS1.4.1.1">III-A</span>1 </span>Meta-features</h4>
<div class="ltx_para" id="S3.SS1.SSS1.p1">
<p class="ltx_p" id="S3.SS1.SSS1.p1.2">A crucial step in the meta-training stage is the extraction of meta-features, denoted as <math alttext="mf" class="ltx_Math" display="inline" id="S3.SS1.SSS1.p1.1.m1.1"><semantics id="S3.SS1.SSS1.p1.1.m1.1a"><mrow id="S3.SS1.SSS1.p1.1.m1.1.1" xref="S3.SS1.SSS1.p1.1.m1.1.1.cmml"><mi id="S3.SS1.SSS1.p1.1.m1.1.1.2" xref="S3.SS1.SSS1.p1.1.m1.1.1.2.cmml">m</mi><mo id="S3.SS1.SSS1.p1.1.m1.1.1.1" xref="S3.SS1.SSS1.p1.1.m1.1.1.1.cmml">⁢</mo><mi id="S3.SS1.SSS1.p1.1.m1.1.1.3" xref="S3.SS1.SSS1.p1.1.m1.1.1.3.cmml">f</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p1.1.m1.1b"><apply id="S3.SS1.SSS1.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS1.p1.1.m1.1.1"><times id="S3.SS1.SSS1.p1.1.m1.1.1.1.cmml" xref="S3.SS1.SSS1.p1.1.m1.1.1.1"></times><ci id="S3.SS1.SSS1.p1.1.m1.1.1.2.cmml" xref="S3.SS1.SSS1.p1.1.m1.1.1.2">𝑚</ci><ci id="S3.SS1.SSS1.p1.1.m1.1.1.3.cmml" xref="S3.SS1.SSS1.p1.1.m1.1.1.3">𝑓</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p1.1.m1.1c">mf</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS1.p1.1.m1.1d">italic_m italic_f</annotation></semantics></math>, from a collection of datasets, represented by <math alttext="\mathbb{D}" class="ltx_Math" display="inline" id="S3.SS1.SSS1.p1.2.m2.1"><semantics id="S3.SS1.SSS1.p1.2.m2.1a"><mi id="S3.SS1.SSS1.p1.2.m2.1.1" xref="S3.SS1.SSS1.p1.2.m2.1.1.cmml">𝔻</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p1.2.m2.1b"><ci id="S3.SS1.SSS1.p1.2.m2.1.1.cmml" xref="S3.SS1.SSS1.p1.2.m2.1.1">𝔻</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p1.2.m2.1c">\mathbb{D}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS1.p1.2.m2.1d">blackboard_D</annotation></semantics></math>. These meta-features serve as descriptors characterizing each dataset. In our study, we use a comprehensive set of 129 meta-features to capture the essential characteristics of the dataset, as suggested by Rivolli et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib31" title="">31</a>]</cite>. These categories include Statistical, Information-theoretic, Model-based, Relative Landmarking <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib32" title="">32</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib33" title="">33</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib31" title="">31</a>]</cite>, Clustering-based <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib21" title="">21</a>]</cite>, Concept <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib31" title="">31</a>]</cite>, Itemset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib34" title="">34</a>]</cite>, and Complexity <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib35" title="">35</a>]</cite>. These meta-features were computed using the PyMFE library <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib36" title="">36</a>]</cite>, version 0.4.2. A complete list of these meta-features, their respective groups, and brief descriptions can be found in the supplementary material in the project’s GitHub repository <span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://github.com/Menelau/MLRS-PDS</span></span></span></span>. Moreover, a comprehensive review of these meta-features is available in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib36" title="">36</a>]</cite>.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS2.4.1.1">III-B</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS2.5.2">Meta-learning recommendation</span>
</h3>
<figure class="ltx_figure" id="S3.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="326" id="S3.F2.g1" src="x2.png" width="498"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>The meta-learning recommendation process for the three distinct scenarios. The red arrow indicates the inputs (choices) provided by the user. In Scenario I, a pool generation scheme is recommended based on the dataset characteristics, conditional on the DS model specified by the user. Scenario II recommends a DS method based on the dataset characteristics and the pre-selected pool generation scheme. Scenario III recommends the best pair of (Pool, DS) without requiring user input. It is crucial to note that only the training set partition of the new query dataset <math alttext="\mathbf{Q}" class="ltx_Math" display="inline" id="S3.F2.2.m1.1"><semantics id="S3.F2.2.m1.1b"><mi id="S3.F2.2.m1.1.1" xref="S3.F2.2.m1.1.1.cmml">𝐐</mi><annotation-xml encoding="MathML-Content" id="S3.F2.2.m1.1c"><ci id="S3.F2.2.m1.1.1.cmml" xref="S3.F2.2.m1.1.1">𝐐</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.2.m1.1d">\mathbf{Q}</annotation><annotation encoding="application/x-llamapun" id="S3.F2.2.m1.1e">bold_Q</annotation></semantics></math> is used for extracting meta-features, thereby preventing any data leakage from the test data.</figcaption>
</figure>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.4">Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#S3.F2" title="Figure 2 ‣ III-B Meta-learning recommendation ‣ III The Proposed Multi-label meta-learning recommendation (MLRS) ‣ MLRS-PDS: A Meta-learning recommendation of dynamic ensemble selection pipelines"><span class="ltx_text ltx_ref_tag">2</span></a> depicts the recommendation phase of MLRS. It solely involves extracting the meta-feature representation of a query dataset and applying the meta-learner to predict the most suitable models. Consequently, our proposed system eliminates the need for extensive model selection evaluations, like grid search procedures, thereby significantly reducing computational demands. This process begins by considering a query dataset <math alttext="\mathbf{Q}" class="ltx_Math" display="inline" id="S3.SS2.p1.1.m1.1"><semantics id="S3.SS2.p1.1.m1.1a"><mi id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml">𝐐</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><ci id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">𝐐</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">\mathbf{Q}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.1.m1.1d">bold_Q</annotation></semantics></math>, from which we extract its meta-feature representations, <math alttext="\mathbf{x}^{\prime}_{\mathbf{Q}}" class="ltx_Math" display="inline" id="S3.SS2.p1.2.m2.1"><semantics id="S3.SS2.p1.2.m2.1a"><msubsup id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml"><mi id="S3.SS2.p1.2.m2.1.1.2.2" xref="S3.SS2.p1.2.m2.1.1.2.2.cmml">𝐱</mi><mi id="S3.SS2.p1.2.m2.1.1.3" xref="S3.SS2.p1.2.m2.1.1.3.cmml">𝐐</mi><mo id="S3.SS2.p1.2.m2.1.1.2.3" xref="S3.SS2.p1.2.m2.1.1.2.3.cmml">′</mo></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><apply id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.2.m2.1.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">subscript</csymbol><apply id="S3.SS2.p1.2.m2.1.1.2.cmml" xref="S3.SS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.2.m2.1.1.2.1.cmml" xref="S3.SS2.p1.2.m2.1.1">superscript</csymbol><ci id="S3.SS2.p1.2.m2.1.1.2.2.cmml" xref="S3.SS2.p1.2.m2.1.1.2.2">𝐱</ci><ci id="S3.SS2.p1.2.m2.1.1.2.3.cmml" xref="S3.SS2.p1.2.m2.1.1.2.3">′</ci></apply><ci id="S3.SS2.p1.2.m2.1.1.3.cmml" xref="S3.SS2.p1.2.m2.1.1.3">𝐐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">\mathbf{x}^{\prime}_{\mathbf{Q}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.2.m2.1d">bold_x start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT bold_Q end_POSTSUBSCRIPT</annotation></semantics></math> based on its available training set partition <math alttext="\mathcal{T}_{r}^{\mathbf{Q}}" class="ltx_Math" display="inline" id="S3.SS2.p1.3.m3.1"><semantics id="S3.SS2.p1.3.m3.1a"><msubsup id="S3.SS2.p1.3.m3.1.1" xref="S3.SS2.p1.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p1.3.m3.1.1.2.2" xref="S3.SS2.p1.3.m3.1.1.2.2.cmml">𝒯</mi><mi id="S3.SS2.p1.3.m3.1.1.2.3" xref="S3.SS2.p1.3.m3.1.1.2.3.cmml">r</mi><mi id="S3.SS2.p1.3.m3.1.1.3" xref="S3.SS2.p1.3.m3.1.1.3.cmml">𝐐</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m3.1b"><apply id="S3.SS2.p1.3.m3.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.3.m3.1.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1">superscript</csymbol><apply id="S3.SS2.p1.3.m3.1.1.2.cmml" xref="S3.SS2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.3.m3.1.1.2.1.cmml" xref="S3.SS2.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS2.p1.3.m3.1.1.2.2.cmml" xref="S3.SS2.p1.3.m3.1.1.2.2">𝒯</ci><ci id="S3.SS2.p1.3.m3.1.1.2.3.cmml" xref="S3.SS2.p1.3.m3.1.1.2.3">𝑟</ci></apply><ci id="S3.SS2.p1.3.m3.1.1.3.cmml" xref="S3.SS2.p1.3.m3.1.1.3">𝐐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m3.1c">\mathcal{T}_{r}^{\mathbf{Q}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.3.m3.1d">caligraphic_T start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT start_POSTSUPERSCRIPT bold_Q end_POSTSUPERSCRIPT</annotation></semantics></math>. This step is crucial for avoiding bias, specifically data leakage from the test distribution, in our meta-learning recommendation procedure. Following this, we utilize our trained meta-model, <math alttext="\lambda" class="ltx_Math" display="inline" id="S3.SS2.p1.4.m4.1"><semantics id="S3.SS2.p1.4.m4.1a"><mi id="S3.SS2.p1.4.m4.1.1" xref="S3.SS2.p1.4.m4.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.4.m4.1b"><ci id="S3.SS2.p1.4.m4.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.4.m4.1c">\lambda</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.4.m4.1d">italic_λ</annotation></semantics></math>, to make dataset-specific recommendations. These recommendations correspond to one of the three recommendation scenarios:</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<ul class="ltx_itemize" id="S3.I2">
<li class="ltx_item" id="S3.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I2.i1.p1">
<p class="ltx_p" id="S3.I2.i1.p1.2"><span class="ltx_text ltx_font_bold" id="S3.I2.i1.p1.2.1">Scenario I, MLRS-P:</span> The meta-learning recommendation system proposes a pool generation scheme while the DS method is fixed. It uses the meta-classifier <math alttext="\lambda_{Pool}" class="ltx_Math" display="inline" id="S3.I2.i1.p1.1.m1.1"><semantics id="S3.I2.i1.p1.1.m1.1a"><msub id="S3.I2.i1.p1.1.m1.1.1" xref="S3.I2.i1.p1.1.m1.1.1.cmml"><mi id="S3.I2.i1.p1.1.m1.1.1.2" xref="S3.I2.i1.p1.1.m1.1.1.2.cmml">λ</mi><mrow id="S3.I2.i1.p1.1.m1.1.1.3" xref="S3.I2.i1.p1.1.m1.1.1.3.cmml"><mi id="S3.I2.i1.p1.1.m1.1.1.3.2" xref="S3.I2.i1.p1.1.m1.1.1.3.2.cmml">P</mi><mo id="S3.I2.i1.p1.1.m1.1.1.3.1" xref="S3.I2.i1.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.I2.i1.p1.1.m1.1.1.3.3" xref="S3.I2.i1.p1.1.m1.1.1.3.3.cmml">o</mi><mo id="S3.I2.i1.p1.1.m1.1.1.3.1a" xref="S3.I2.i1.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.I2.i1.p1.1.m1.1.1.3.4" xref="S3.I2.i1.p1.1.m1.1.1.3.4.cmml">o</mi><mo id="S3.I2.i1.p1.1.m1.1.1.3.1b" xref="S3.I2.i1.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.I2.i1.p1.1.m1.1.1.3.5" xref="S3.I2.i1.p1.1.m1.1.1.3.5.cmml">l</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.I2.i1.p1.1.m1.1b"><apply id="S3.I2.i1.p1.1.m1.1.1.cmml" xref="S3.I2.i1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.I2.i1.p1.1.m1.1.1.1.cmml" xref="S3.I2.i1.p1.1.m1.1.1">subscript</csymbol><ci id="S3.I2.i1.p1.1.m1.1.1.2.cmml" xref="S3.I2.i1.p1.1.m1.1.1.2">𝜆</ci><apply id="S3.I2.i1.p1.1.m1.1.1.3.cmml" xref="S3.I2.i1.p1.1.m1.1.1.3"><times id="S3.I2.i1.p1.1.m1.1.1.3.1.cmml" xref="S3.I2.i1.p1.1.m1.1.1.3.1"></times><ci id="S3.I2.i1.p1.1.m1.1.1.3.2.cmml" xref="S3.I2.i1.p1.1.m1.1.1.3.2">𝑃</ci><ci id="S3.I2.i1.p1.1.m1.1.1.3.3.cmml" xref="S3.I2.i1.p1.1.m1.1.1.3.3">𝑜</ci><ci id="S3.I2.i1.p1.1.m1.1.1.3.4.cmml" xref="S3.I2.i1.p1.1.m1.1.1.3.4">𝑜</ci><ci id="S3.I2.i1.p1.1.m1.1.1.3.5.cmml" xref="S3.I2.i1.p1.1.m1.1.1.3.5">𝑙</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i1.p1.1.m1.1c">\lambda_{Pool}</annotation><annotation encoding="application/x-llamapun" id="S3.I2.i1.p1.1.m1.1d">italic_λ start_POSTSUBSCRIPT italic_P italic_o italic_o italic_l end_POSTSUBSCRIPT</annotation></semantics></math> trained explicitly for this task. This scenario is applicable when a specific DS method must be used, and an optimal pool generation scheme, <math alttext="P_{o}" class="ltx_Math" display="inline" id="S3.I2.i1.p1.2.m2.1"><semantics id="S3.I2.i1.p1.2.m2.1a"><msub id="S3.I2.i1.p1.2.m2.1.1" xref="S3.I2.i1.p1.2.m2.1.1.cmml"><mi id="S3.I2.i1.p1.2.m2.1.1.2" xref="S3.I2.i1.p1.2.m2.1.1.2.cmml">P</mi><mi id="S3.I2.i1.p1.2.m2.1.1.3" xref="S3.I2.i1.p1.2.m2.1.1.3.cmml">o</mi></msub><annotation-xml encoding="MathML-Content" id="S3.I2.i1.p1.2.m2.1b"><apply id="S3.I2.i1.p1.2.m2.1.1.cmml" xref="S3.I2.i1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.I2.i1.p1.2.m2.1.1.1.cmml" xref="S3.I2.i1.p1.2.m2.1.1">subscript</csymbol><ci id="S3.I2.i1.p1.2.m2.1.1.2.cmml" xref="S3.I2.i1.p1.2.m2.1.1.2">𝑃</ci><ci id="S3.I2.i1.p1.2.m2.1.1.3.cmml" xref="S3.I2.i1.p1.2.m2.1.1.3">𝑜</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i1.p1.2.m2.1c">P_{o}</annotation><annotation encoding="application/x-llamapun" id="S3.I2.i1.p1.2.m2.1d">italic_P start_POSTSUBSCRIPT italic_o end_POSTSUBSCRIPT</annotation></semantics></math>, is required.</p>
</div>
</li>
<li class="ltx_item" id="S3.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I2.i2.p1">
<p class="ltx_p" id="S3.I2.i2.p1.2"><span class="ltx_text ltx_font_bold" id="S3.I2.i2.p1.2.1">Scenario II, MLRS-DS:</span> In this scenario, the meta-learning recommendation system suggests a DS method that complements a predetermined or pre-trained pool generation scheme. It employs the meta-classifier <math alttext="\lambda_{DS}" class="ltx_Math" display="inline" id="S3.I2.i2.p1.1.m1.1"><semantics id="S3.I2.i2.p1.1.m1.1a"><msub id="S3.I2.i2.p1.1.m1.1.1" xref="S3.I2.i2.p1.1.m1.1.1.cmml"><mi id="S3.I2.i2.p1.1.m1.1.1.2" xref="S3.I2.i2.p1.1.m1.1.1.2.cmml">λ</mi><mrow id="S3.I2.i2.p1.1.m1.1.1.3" xref="S3.I2.i2.p1.1.m1.1.1.3.cmml"><mi id="S3.I2.i2.p1.1.m1.1.1.3.2" xref="S3.I2.i2.p1.1.m1.1.1.3.2.cmml">D</mi><mo id="S3.I2.i2.p1.1.m1.1.1.3.1" xref="S3.I2.i2.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.I2.i2.p1.1.m1.1.1.3.3" xref="S3.I2.i2.p1.1.m1.1.1.3.3.cmml">S</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.I2.i2.p1.1.m1.1b"><apply id="S3.I2.i2.p1.1.m1.1.1.cmml" xref="S3.I2.i2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.I2.i2.p1.1.m1.1.1.1.cmml" xref="S3.I2.i2.p1.1.m1.1.1">subscript</csymbol><ci id="S3.I2.i2.p1.1.m1.1.1.2.cmml" xref="S3.I2.i2.p1.1.m1.1.1.2">𝜆</ci><apply id="S3.I2.i2.p1.1.m1.1.1.3.cmml" xref="S3.I2.i2.p1.1.m1.1.1.3"><times id="S3.I2.i2.p1.1.m1.1.1.3.1.cmml" xref="S3.I2.i2.p1.1.m1.1.1.3.1"></times><ci id="S3.I2.i2.p1.1.m1.1.1.3.2.cmml" xref="S3.I2.i2.p1.1.m1.1.1.3.2">𝐷</ci><ci id="S3.I2.i2.p1.1.m1.1.1.3.3.cmml" xref="S3.I2.i2.p1.1.m1.1.1.3.3">𝑆</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i2.p1.1.m1.1c">\lambda_{DS}</annotation><annotation encoding="application/x-llamapun" id="S3.I2.i2.p1.1.m1.1d">italic_λ start_POSTSUBSCRIPT italic_D italic_S end_POSTSUBSCRIPT</annotation></semantics></math>, which was trained to recommend the best DS method for this predefined pool. This approach is beneficial when a particular pool generation scheme needs to be used, requiring identifying the most suitable DS method (<math alttext="DS_{o}" class="ltx_Math" display="inline" id="S3.I2.i2.p1.2.m2.1"><semantics id="S3.I2.i2.p1.2.m2.1a"><mrow id="S3.I2.i2.p1.2.m2.1.1" xref="S3.I2.i2.p1.2.m2.1.1.cmml"><mi id="S3.I2.i2.p1.2.m2.1.1.2" xref="S3.I2.i2.p1.2.m2.1.1.2.cmml">D</mi><mo id="S3.I2.i2.p1.2.m2.1.1.1" xref="S3.I2.i2.p1.2.m2.1.1.1.cmml">⁢</mo><msub id="S3.I2.i2.p1.2.m2.1.1.3" xref="S3.I2.i2.p1.2.m2.1.1.3.cmml"><mi id="S3.I2.i2.p1.2.m2.1.1.3.2" xref="S3.I2.i2.p1.2.m2.1.1.3.2.cmml">S</mi><mi id="S3.I2.i2.p1.2.m2.1.1.3.3" xref="S3.I2.i2.p1.2.m2.1.1.3.3.cmml">o</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.I2.i2.p1.2.m2.1b"><apply id="S3.I2.i2.p1.2.m2.1.1.cmml" xref="S3.I2.i2.p1.2.m2.1.1"><times id="S3.I2.i2.p1.2.m2.1.1.1.cmml" xref="S3.I2.i2.p1.2.m2.1.1.1"></times><ci id="S3.I2.i2.p1.2.m2.1.1.2.cmml" xref="S3.I2.i2.p1.2.m2.1.1.2">𝐷</ci><apply id="S3.I2.i2.p1.2.m2.1.1.3.cmml" xref="S3.I2.i2.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.I2.i2.p1.2.m2.1.1.3.1.cmml" xref="S3.I2.i2.p1.2.m2.1.1.3">subscript</csymbol><ci id="S3.I2.i2.p1.2.m2.1.1.3.2.cmml" xref="S3.I2.i2.p1.2.m2.1.1.3.2">𝑆</ci><ci id="S3.I2.i2.p1.2.m2.1.1.3.3.cmml" xref="S3.I2.i2.p1.2.m2.1.1.3.3">𝑜</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i2.p1.2.m2.1c">DS_{o}</annotation><annotation encoding="application/x-llamapun" id="S3.I2.i2.p1.2.m2.1d">italic_D italic_S start_POSTSUBSCRIPT italic_o end_POSTSUBSCRIPT</annotation></semantics></math>) to obtain the best accuracy possible from this pool.</p>
</div>
</li>
<li class="ltx_item" id="S3.I2.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I2.i3.p1">
<p class="ltx_p" id="S3.I2.i3.p1.2"><span class="ltx_text ltx_font_bold" id="S3.I2.i3.p1.2.1">Scenario III, MLRS-PDS:</span> This scenario involves the system recommending a pool and a DS model solely based on the dataset’s characteristics. MLRS-PDS initially employs a classifier chain in a chained recommendation model to predict the optimal pool generation scheme using the meta-features. Subsequently, the selected pool’s choice is incorporated as an input feature to aid in recommending the most suitable DS model contingent on it. This process automates the identification of the optimal Pool and DS pair (<math alttext="P_{o}" class="ltx_Math" display="inline" id="S3.I2.i3.p1.1.m1.1"><semantics id="S3.I2.i3.p1.1.m1.1a"><msub id="S3.I2.i3.p1.1.m1.1.1" xref="S3.I2.i3.p1.1.m1.1.1.cmml"><mi id="S3.I2.i3.p1.1.m1.1.1.2" xref="S3.I2.i3.p1.1.m1.1.1.2.cmml">P</mi><mi id="S3.I2.i3.p1.1.m1.1.1.3" xref="S3.I2.i3.p1.1.m1.1.1.3.cmml">o</mi></msub><annotation-xml encoding="MathML-Content" id="S3.I2.i3.p1.1.m1.1b"><apply id="S3.I2.i3.p1.1.m1.1.1.cmml" xref="S3.I2.i3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.I2.i3.p1.1.m1.1.1.1.cmml" xref="S3.I2.i3.p1.1.m1.1.1">subscript</csymbol><ci id="S3.I2.i3.p1.1.m1.1.1.2.cmml" xref="S3.I2.i3.p1.1.m1.1.1.2">𝑃</ci><ci id="S3.I2.i3.p1.1.m1.1.1.3.cmml" xref="S3.I2.i3.p1.1.m1.1.1.3">𝑜</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i3.p1.1.m1.1c">P_{o}</annotation><annotation encoding="application/x-llamapun" id="S3.I2.i3.p1.1.m1.1d">italic_P start_POSTSUBSCRIPT italic_o end_POSTSUBSCRIPT</annotation></semantics></math>, <math alttext="DS_{o}" class="ltx_Math" display="inline" id="S3.I2.i3.p1.2.m2.1"><semantics id="S3.I2.i3.p1.2.m2.1a"><mrow id="S3.I2.i3.p1.2.m2.1.1" xref="S3.I2.i3.p1.2.m2.1.1.cmml"><mi id="S3.I2.i3.p1.2.m2.1.1.2" xref="S3.I2.i3.p1.2.m2.1.1.2.cmml">D</mi><mo id="S3.I2.i3.p1.2.m2.1.1.1" xref="S3.I2.i3.p1.2.m2.1.1.1.cmml">⁢</mo><msub id="S3.I2.i3.p1.2.m2.1.1.3" xref="S3.I2.i3.p1.2.m2.1.1.3.cmml"><mi id="S3.I2.i3.p1.2.m2.1.1.3.2" xref="S3.I2.i3.p1.2.m2.1.1.3.2.cmml">S</mi><mi id="S3.I2.i3.p1.2.m2.1.1.3.3" xref="S3.I2.i3.p1.2.m2.1.1.3.3.cmml">o</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.I2.i3.p1.2.m2.1b"><apply id="S3.I2.i3.p1.2.m2.1.1.cmml" xref="S3.I2.i3.p1.2.m2.1.1"><times id="S3.I2.i3.p1.2.m2.1.1.1.cmml" xref="S3.I2.i3.p1.2.m2.1.1.1"></times><ci id="S3.I2.i3.p1.2.m2.1.1.2.cmml" xref="S3.I2.i3.p1.2.m2.1.1.2">𝐷</ci><apply id="S3.I2.i3.p1.2.m2.1.1.3.cmml" xref="S3.I2.i3.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.I2.i3.p1.2.m2.1.1.3.1.cmml" xref="S3.I2.i3.p1.2.m2.1.1.3">subscript</csymbol><ci id="S3.I2.i3.p1.2.m2.1.1.3.2.cmml" xref="S3.I2.i3.p1.2.m2.1.1.3.2">𝑆</ci><ci id="S3.I2.i3.p1.2.m2.1.1.3.3.cmml" xref="S3.I2.i3.p1.2.m2.1.1.3.3">𝑜</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i3.p1.2.m2.1c">DS_{o}</annotation><annotation encoding="application/x-llamapun" id="S3.I2.i3.p1.2.m2.1d">italic_D italic_S start_POSTSUBSCRIPT italic_o end_POSTSUBSCRIPT</annotation></semantics></math>), effectively modeling the interdependencies between these two design choices and leading to an entire DS pipeline.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.3">After executing the meta-learning recommendation process, the resultant tuple (Pool, DS) is employed to construct the DS pipeline. The selected pool generation scheme and the DS algorithm are trained using <math alttext="\mathbf{Q}" class="ltx_Math" display="inline" id="S3.SS2.p3.1.m1.1"><semantics id="S3.SS2.p3.1.m1.1a"><mi id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml">𝐐</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><ci id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1">𝐐</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">\mathbf{Q}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.1.m1.1d">bold_Q</annotation></semantics></math> training partition (<math alttext="\mathcal{T}_{r}^{(\mathbf{Q})}" class="ltx_Math" display="inline" id="S3.SS2.p3.2.m2.1"><semantics id="S3.SS2.p3.2.m2.1a"><msubsup id="S3.SS2.p3.2.m2.1.2" xref="S3.SS2.p3.2.m2.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p3.2.m2.1.2.2.2" xref="S3.SS2.p3.2.m2.1.2.2.2.cmml">𝒯</mi><mi id="S3.SS2.p3.2.m2.1.2.2.3" xref="S3.SS2.p3.2.m2.1.2.2.3.cmml">r</mi><mrow id="S3.SS2.p3.2.m2.1.1.1.3" xref="S3.SS2.p3.2.m2.1.2.cmml"><mo id="S3.SS2.p3.2.m2.1.1.1.3.1" stretchy="false" xref="S3.SS2.p3.2.m2.1.2.cmml">(</mo><mi id="S3.SS2.p3.2.m2.1.1.1.1" xref="S3.SS2.p3.2.m2.1.1.1.1.cmml">𝐐</mi><mo id="S3.SS2.p3.2.m2.1.1.1.3.2" stretchy="false" xref="S3.SS2.p3.2.m2.1.2.cmml">)</mo></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m2.1b"><apply id="S3.SS2.p3.2.m2.1.2.cmml" xref="S3.SS2.p3.2.m2.1.2"><csymbol cd="ambiguous" id="S3.SS2.p3.2.m2.1.2.1.cmml" xref="S3.SS2.p3.2.m2.1.2">superscript</csymbol><apply id="S3.SS2.p3.2.m2.1.2.2.cmml" xref="S3.SS2.p3.2.m2.1.2"><csymbol cd="ambiguous" id="S3.SS2.p3.2.m2.1.2.2.1.cmml" xref="S3.SS2.p3.2.m2.1.2">subscript</csymbol><ci id="S3.SS2.p3.2.m2.1.2.2.2.cmml" xref="S3.SS2.p3.2.m2.1.2.2.2">𝒯</ci><ci id="S3.SS2.p3.2.m2.1.2.2.3.cmml" xref="S3.SS2.p3.2.m2.1.2.2.3">𝑟</ci></apply><ci id="S3.SS2.p3.2.m2.1.1.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1.1.1">𝐐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m2.1c">\mathcal{T}_{r}^{(\mathbf{Q})}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.2.m2.1d">caligraphic_T start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( bold_Q ) end_POSTSUPERSCRIPT</annotation></semantics></math>). They are then applied in the generalization phase over the test dataset <math alttext="\mathcal{T}_{e}^{(\mathbf{Q})}" class="ltx_Math" display="inline" id="S3.SS2.p3.3.m3.1"><semantics id="S3.SS2.p3.3.m3.1a"><msubsup id="S3.SS2.p3.3.m3.1.2" xref="S3.SS2.p3.3.m3.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p3.3.m3.1.2.2.2" xref="S3.SS2.p3.3.m3.1.2.2.2.cmml">𝒯</mi><mi id="S3.SS2.p3.3.m3.1.2.2.3" xref="S3.SS2.p3.3.m3.1.2.2.3.cmml">e</mi><mrow id="S3.SS2.p3.3.m3.1.1.1.3" xref="S3.SS2.p3.3.m3.1.2.cmml"><mo id="S3.SS2.p3.3.m3.1.1.1.3.1" stretchy="false" xref="S3.SS2.p3.3.m3.1.2.cmml">(</mo><mi id="S3.SS2.p3.3.m3.1.1.1.1" xref="S3.SS2.p3.3.m3.1.1.1.1.cmml">𝐐</mi><mo id="S3.SS2.p3.3.m3.1.1.1.3.2" stretchy="false" xref="S3.SS2.p3.3.m3.1.2.cmml">)</mo></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.3.m3.1b"><apply id="S3.SS2.p3.3.m3.1.2.cmml" xref="S3.SS2.p3.3.m3.1.2"><csymbol cd="ambiguous" id="S3.SS2.p3.3.m3.1.2.1.cmml" xref="S3.SS2.p3.3.m3.1.2">superscript</csymbol><apply id="S3.SS2.p3.3.m3.1.2.2.cmml" xref="S3.SS2.p3.3.m3.1.2"><csymbol cd="ambiguous" id="S3.SS2.p3.3.m3.1.2.2.1.cmml" xref="S3.SS2.p3.3.m3.1.2">subscript</csymbol><ci id="S3.SS2.p3.3.m3.1.2.2.2.cmml" xref="S3.SS2.p3.3.m3.1.2.2.2">𝒯</ci><ci id="S3.SS2.p3.3.m3.1.2.2.3.cmml" xref="S3.SS2.p3.3.m3.1.2.2.3">𝑒</ci></apply><ci id="S3.SS2.p3.3.m3.1.1.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1.1.1">𝐐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.3.m3.1c">\mathcal{T}_{e}^{(\mathbf{Q})}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.3.m3.1d">caligraphic_T start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( bold_Q ) end_POSTSUPERSCRIPT</annotation></semantics></math> for labeling its instances.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span class="ltx_text ltx_font_smallcaps" id="S4.1.1">Experimental setup</span>
</h2>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS1.4.1.1">IV-A</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS1.5.2">Pool generation schemes</span>
</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">We explore seven distinct pool generation schemes, each carefully selected to represent pools of diverse natures. We consider the Bagging technique with linear Perceptrons (BP) and decision trees (BDT) as base models for global pool generation. Additionally, we employ Perceptrons and Decision Trees in conjunction with Adaboost, resulting in the BSP and BSDT pools, respectively. The Random Forest model (RF) was also included as another widely recognized global pool generation scheme in DS literature <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib12" title="">12</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib37" title="">37</a>]</cite>. These models are frequently utilized in various studies as pool generation methods, as evidenced by multiple references <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib3" title="">3</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib38" title="">38</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib39" title="">39</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib9" title="">9</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib40" title="">40</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib37" title="">37</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib41" title="">41</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib12" title="">12</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib42" title="">42</a>]</cite>. Thus encompassing a range of pool generation algorithms prominently featured in recent DS publications.</p>
</div>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1">As local pool generation, we consider two methods: Forest of Local Trees (FLT) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib16" title="">16</a>]</cite> and Locally Independent Training (LIT) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib17" title="">17</a>]</cite>. Notably, DS methods have not previously used local pool generation schemes in their conception. Given that DS methods rely on the local expert assumption, we hypothesize that such methods could present a viable alternative as pool generation algorithms for DS, potentially enhancing their classification performance. Including these methods thus broadens the scope of our MLRS, providing a more comprehensive examination of pool generation possibilities. The pool of classifiers in all simulations consists of <math alttext="100" class="ltx_Math" display="inline" id="S4.SS1.p2.1.m1.1"><semantics id="S4.SS1.p2.1.m1.1a"><mn id="S4.SS1.p2.1.m1.1.1" xref="S4.SS1.p2.1.m1.1.1.cmml">100</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.1b"><cn id="S4.SS1.p2.1.m1.1.1.cmml" type="integer" xref="S4.SS1.p2.1.m1.1.1">100</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.1.m1.1c">100</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p2.1.m1.1d">100</annotation></semantics></math> base classifiers, following the recommendation in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib29" title="">29</a>]</cite>. This uniform pool size ensures a fair comparison across all pool generation schemes.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS2.4.1.1">IV-B</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS2.5.2">DS Techniques</span>
</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">In this research, we utilized seven dynamic selection algorithms from the DESlib version 0.3.5 DS library <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib43" title="">43</a>]</cite>, incorporating a mix of two Dynamic Classifier Selection (DCS) and five Dynamic Ensemble Selection (DES) methods to ensure diverse and meaningful results. The DCS methods included Overall Local Accuracy (OLA) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib44" title="">44</a>]</cite> and Modified Local Accuracy (MLA) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib45" title="">45</a>]</cite>, while the DES methods encompassed KNORA-E <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib46" title="">46</a>]</cite>, KNORA-U <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib46" title="">46</a>]</cite>, Meta-learning for dynamic ensemble selection (META-DES) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib47" title="">47</a>]</cite>, Multiclass Imbalance (DES-MI) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib40" title="">40</a>]</cite>, and Dynamic Ensemble Selection performance (DES-P) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib48" title="">48</a>]</cite>. All these techniques rely on the K-Nearest Neighbors (KNN) method with a region of competence size (K) set to 7, as per <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib47" title="">47</a>]</cite>. Specifically for the META-DES algorithm, we use the configuration proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib39" title="">39</a>]</cite> comprising of the Naive Bayes algorithm for the meta-level and using a total of five output profiles.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS3.4.1.1">IV-C</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS3.5.2">Datasets</span>
</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">Relying on a standard test bed without considering the diversity of dataset characteristics can lead to incomplete evaluations of learning algorithms. This limitation is particularly pronounced in meta-learning, where constructing a robust meta-classifier and comprehensively evaluating the meta-learning model require a diverse dataset collection. Hence, in this work, we considered the datasets from the Landscape Contest at ICPR 2010 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib49" title="">49</a>]</cite>, which consists of 301 datasets specially crafted to cover the space of dataset complexity <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib50" title="">50</a>]</cite>. Therefore, offering a well-rounded and comprehensive basis for addressing our research questions.</p>
</div>
<div class="ltx_para" id="S4.SS3.p2">
<p class="ltx_p" id="S4.SS3.p2.1">In this study, 13 datasets were excluded from the original 301 due to issues with the AdaBoost algorithm using a Perceptron as the base estimator. These datasets, specifically numbered 216, 219, 220, 221, 252, 253, 254, 255, 257, 258, 260, 262, and 263, were problematic because AdaBoost, requiring a diverse set of classifiers, could only generate one classifier for each, failing to generate multiple models. .</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS4.4.1.1">IV-D</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS4.5.2">Experimental setup</span>
</h3>
<div class="ltx_para" id="S4.SS4.p1">
<p class="ltx_p" id="S4.SS4.p1.5">For this experiment, we employed the leave-one-dataset-out (LODO) procedure, where, at each iteration, one dataset (<math alttext="\mathbf{Q}" class="ltx_Math" display="inline" id="S4.SS4.p1.1.m1.1"><semantics id="S4.SS4.p1.1.m1.1a"><mi id="S4.SS4.p1.1.m1.1.1" xref="S4.SS4.p1.1.m1.1.1.cmml">𝐐</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.1.m1.1b"><ci id="S4.SS4.p1.1.m1.1.1.cmml" xref="S4.SS4.p1.1.m1.1.1">𝐐</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.1.m1.1c">\mathbf{Q}</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p1.1.m1.1d">bold_Q</annotation></semantics></math>) is left for testing, and the remaining ones are used as training datasets (<math alttext="\mathbb{D}" class="ltx_Math" display="inline" id="S4.SS4.p1.2.m2.1"><semantics id="S4.SS4.p1.2.m2.1a"><mi id="S4.SS4.p1.2.m2.1.1" xref="S4.SS4.p1.2.m2.1.1.cmml">𝔻</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.2.m2.1b"><ci id="S4.SS4.p1.2.m2.1.1.cmml" xref="S4.SS4.p1.2.m2.1.1">𝔻</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.2.m2.1c">\mathbb{D}</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p1.2.m2.1d">blackboard_D</annotation></semantics></math>). In other words, for each simulation, 287 datasets were considered for training the meta-learning framework, while one was considered as the test dataset <math alttext="\mathbf{Q}" class="ltx_Math" display="inline" id="S4.SS4.p1.3.m3.1"><semantics id="S4.SS4.p1.3.m3.1a"><mi id="S4.SS4.p1.3.m3.1.1" xref="S4.SS4.p1.3.m3.1.1.cmml">𝐐</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.3.m3.1b"><ci id="S4.SS4.p1.3.m3.1.1.cmml" xref="S4.SS4.p1.3.m3.1.1">𝐐</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.3.m3.1c">\mathbf{Q}</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p1.3.m3.1d">bold_Q</annotation></semantics></math> used to evaluate its generalization performance. We divided each dataset into 75% of the data used for training (<math alttext="\mathcal{T}_{r}" class="ltx_Math" display="inline" id="S4.SS4.p1.4.m4.1"><semantics id="S4.SS4.p1.4.m4.1a"><msub id="S4.SS4.p1.4.m4.1.1" xref="S4.SS4.p1.4.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS4.p1.4.m4.1.1.2" xref="S4.SS4.p1.4.m4.1.1.2.cmml">𝒯</mi><mi id="S4.SS4.p1.4.m4.1.1.3" xref="S4.SS4.p1.4.m4.1.1.3.cmml">r</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.4.m4.1b"><apply id="S4.SS4.p1.4.m4.1.1.cmml" xref="S4.SS4.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS4.p1.4.m4.1.1.1.cmml" xref="S4.SS4.p1.4.m4.1.1">subscript</csymbol><ci id="S4.SS4.p1.4.m4.1.1.2.cmml" xref="S4.SS4.p1.4.m4.1.1.2">𝒯</ci><ci id="S4.SS4.p1.4.m4.1.1.3.cmml" xref="S4.SS4.p1.4.m4.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.4.m4.1c">\mathcal{T}_{r}</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p1.4.m4.1d">caligraphic_T start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT</annotation></semantics></math>) and the remaining 25% for the data used for testing (<math alttext="\mathcal{T}_{e}" class="ltx_Math" display="inline" id="S4.SS4.p1.5.m5.1"><semantics id="S4.SS4.p1.5.m5.1a"><msub id="S4.SS4.p1.5.m5.1.1" xref="S4.SS4.p1.5.m5.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS4.p1.5.m5.1.1.2" xref="S4.SS4.p1.5.m5.1.1.2.cmml">𝒯</mi><mi id="S4.SS4.p1.5.m5.1.1.3" xref="S4.SS4.p1.5.m5.1.1.3.cmml">e</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.5.m5.1b"><apply id="S4.SS4.p1.5.m5.1.1.cmml" xref="S4.SS4.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S4.SS4.p1.5.m5.1.1.1.cmml" xref="S4.SS4.p1.5.m5.1.1">subscript</csymbol><ci id="S4.SS4.p1.5.m5.1.1.2.cmml" xref="S4.SS4.p1.5.m5.1.1.2">𝒯</ci><ci id="S4.SS4.p1.5.m5.1.1.3.cmml" xref="S4.SS4.p1.5.m5.1.1.3">𝑒</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.5.m5.1c">\mathcal{T}_{e}</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p1.5.m5.1d">caligraphic_T start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT</annotation></semantics></math>) using a stratified holdout split. Datasets were normalized using the Z-score normalization, also known as Standard Scaler <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib51" title="">51</a>]</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS5.4.1.1">IV-E</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS5.5.2">Meta-learner definition</span>
</h3>
<div class="ltx_para" id="S4.SS5.p1">
<p class="ltx_p" id="S4.SS5.p1.3">For each recommendation scenario, three algorithms, including Random Forests (RF), K Nearest Neighbors (KNN), and Support Vector Machine (SVM), were initially evaluated as the meta-modal. Their choices were based on previous meta-learning studies <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib23" title="">23</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib31" title="">31</a>]</cite>. The hyperparameter tuning procedure was conducted through a 10-fold cross-validation with a grid search. For K Nearest Neighbors, values of K ranging from 2 to 7 were evaluated, while for Random Forests, Max Depth values of 2 to 5 were tried. The hyperparameter chosen for the Support Vector Machine was gamma equal and cost varying between 0.01, 0.1, and 1. The best meta-model configuration found were RF with a Max_Depth = 5 and 100 trees for Scenario I (<math alttext="\lambda_{Pool})" class="ltx_math_unparsed" display="inline" id="S4.SS5.p1.1.m1.1"><semantics id="S4.SS5.p1.1.m1.1a"><mrow id="S4.SS5.p1.1.m1.1b"><msub id="S4.SS5.p1.1.m1.1.1"><mi id="S4.SS5.p1.1.m1.1.1.2">λ</mi><mrow id="S4.SS5.p1.1.m1.1.1.3"><mi id="S4.SS5.p1.1.m1.1.1.3.2">P</mi><mo id="S4.SS5.p1.1.m1.1.1.3.1">⁢</mo><mi id="S4.SS5.p1.1.m1.1.1.3.3">o</mi><mo id="S4.SS5.p1.1.m1.1.1.3.1a">⁢</mo><mi id="S4.SS5.p1.1.m1.1.1.3.4">o</mi><mo id="S4.SS5.p1.1.m1.1.1.3.1b">⁢</mo><mi id="S4.SS5.p1.1.m1.1.1.3.5">l</mi></mrow></msub><mo id="S4.SS5.p1.1.m1.1.2" stretchy="false">)</mo></mrow><annotation encoding="application/x-tex" id="S4.SS5.p1.1.m1.1c">\lambda_{Pool})</annotation><annotation encoding="application/x-llamapun" id="S4.SS5.p1.1.m1.1d">italic_λ start_POSTSUBSCRIPT italic_P italic_o italic_o italic_l end_POSTSUBSCRIPT )</annotation></semantics></math> and KNN with K = 2 and using the Euclidean distance for Scenarios II and III (<math alttext="\lambda_{DS}" class="ltx_Math" display="inline" id="S4.SS5.p1.2.m2.1"><semantics id="S4.SS5.p1.2.m2.1a"><msub id="S4.SS5.p1.2.m2.1.1" xref="S4.SS5.p1.2.m2.1.1.cmml"><mi id="S4.SS5.p1.2.m2.1.1.2" xref="S4.SS5.p1.2.m2.1.1.2.cmml">λ</mi><mrow id="S4.SS5.p1.2.m2.1.1.3" xref="S4.SS5.p1.2.m2.1.1.3.cmml"><mi id="S4.SS5.p1.2.m2.1.1.3.2" xref="S4.SS5.p1.2.m2.1.1.3.2.cmml">D</mi><mo id="S4.SS5.p1.2.m2.1.1.3.1" xref="S4.SS5.p1.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S4.SS5.p1.2.m2.1.1.3.3" xref="S4.SS5.p1.2.m2.1.1.3.3.cmml">S</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS5.p1.2.m2.1b"><apply id="S4.SS5.p1.2.m2.1.1.cmml" xref="S4.SS5.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS5.p1.2.m2.1.1.1.cmml" xref="S4.SS5.p1.2.m2.1.1">subscript</csymbol><ci id="S4.SS5.p1.2.m2.1.1.2.cmml" xref="S4.SS5.p1.2.m2.1.1.2">𝜆</ci><apply id="S4.SS5.p1.2.m2.1.1.3.cmml" xref="S4.SS5.p1.2.m2.1.1.3"><times id="S4.SS5.p1.2.m2.1.1.3.1.cmml" xref="S4.SS5.p1.2.m2.1.1.3.1"></times><ci id="S4.SS5.p1.2.m2.1.1.3.2.cmml" xref="S4.SS5.p1.2.m2.1.1.3.2">𝐷</ci><ci id="S4.SS5.p1.2.m2.1.1.3.3.cmml" xref="S4.SS5.p1.2.m2.1.1.3.3">𝑆</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p1.2.m2.1c">\lambda_{DS}</annotation><annotation encoding="application/x-llamapun" id="S4.SS5.p1.2.m2.1d">italic_λ start_POSTSUBSCRIPT italic_D italic_S end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="\lambda_{Pool,DS})" class="ltx_math_unparsed" display="inline" id="S4.SS5.p1.3.m3.2"><semantics id="S4.SS5.p1.3.m3.2a"><mrow id="S4.SS5.p1.3.m3.2b"><msub id="S4.SS5.p1.3.m3.2.3"><mi id="S4.SS5.p1.3.m3.2.3.2">λ</mi><mrow id="S4.SS5.p1.3.m3.2.2.2.2"><mrow id="S4.SS5.p1.3.m3.1.1.1.1.1"><mi id="S4.SS5.p1.3.m3.1.1.1.1.1.2">P</mi><mo id="S4.SS5.p1.3.m3.1.1.1.1.1.1">⁢</mo><mi id="S4.SS5.p1.3.m3.1.1.1.1.1.3">o</mi><mo id="S4.SS5.p1.3.m3.1.1.1.1.1.1a">⁢</mo><mi id="S4.SS5.p1.3.m3.1.1.1.1.1.4">o</mi><mo id="S4.SS5.p1.3.m3.1.1.1.1.1.1b">⁢</mo><mi id="S4.SS5.p1.3.m3.1.1.1.1.1.5">l</mi></mrow><mo id="S4.SS5.p1.3.m3.2.2.2.2.3">,</mo><mrow id="S4.SS5.p1.3.m3.2.2.2.2.2"><mi id="S4.SS5.p1.3.m3.2.2.2.2.2.2">D</mi><mo id="S4.SS5.p1.3.m3.2.2.2.2.2.1">⁢</mo><mi id="S4.SS5.p1.3.m3.2.2.2.2.2.3">S</mi></mrow></mrow></msub><mo id="S4.SS5.p1.3.m3.2.4" stretchy="false">)</mo></mrow><annotation encoding="application/x-tex" id="S4.SS5.p1.3.m3.2c">\lambda_{Pool,DS})</annotation><annotation encoding="application/x-llamapun" id="S4.SS5.p1.3.m3.2d">italic_λ start_POSTSUBSCRIPT italic_P italic_o italic_o italic_l , italic_D italic_S end_POSTSUBSCRIPT )</annotation></semantics></math>.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span class="ltx_text ltx_font_smallcaps" id="S5.1.1">Results</span>
</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">This experimental study primarily aims to evaluate the performance of the three variants of our meta-learning recommendation system (MLRS) in recommending the best pool generation scheme, the best DS algorithm, and the entire pipeline. It is essential to highlight that this is the first work proposing automated algorithm selection for this task. Hence, we use established baselines from the Meta-learning literature, specifically a model that always recommends the majority class, i.e., the technique with the highest number of wins, for the entire testbed (Majority), and the average between all possible configurations which are common approaches to demonstrate the need for a recommendation system in meta-learning <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib19" title="">19</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#bib.bib22" title="">22</a>]</cite>. We also present a statistical comparison between our meta-learning approach against all possible configurations for the pool and DS algorithm (a total of 49 configurations) in the supplementary material.</p>
</div>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.3">Due to the vast amount of datasets and techniques involved (<math alttext="7" class="ltx_Math" display="inline" id="S5.p2.1.m1.1"><semantics id="S5.p2.1.m1.1a"><mn id="S5.p2.1.m1.1.1" xref="S5.p2.1.m1.1.1.cmml">7</mn><annotation-xml encoding="MathML-Content" id="S5.p2.1.m1.1b"><cn id="S5.p2.1.m1.1.1.cmml" type="integer" xref="S5.p2.1.m1.1.1">7</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.1.m1.1c">7</annotation><annotation encoding="application/x-llamapun" id="S5.p2.1.m1.1d">7</annotation></semantics></math> pool generation schemes <math alttext="\times" class="ltx_Math" display="inline" id="S5.p2.2.m2.1"><semantics id="S5.p2.2.m2.1a"><mo id="S5.p2.2.m2.1.1" xref="S5.p2.2.m2.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.p2.2.m2.1b"><times id="S5.p2.2.m2.1.1.cmml" xref="S5.p2.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.2.m2.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.p2.2.m2.1d">×</annotation></semantics></math> <math alttext="7" class="ltx_Math" display="inline" id="S5.p2.3.m3.1"><semantics id="S5.p2.3.m3.1a"><mn id="S5.p2.3.m3.1.1" xref="S5.p2.3.m3.1.1.cmml">7</mn><annotation-xml encoding="MathML-Content" id="S5.p2.3.m3.1b"><cn id="S5.p2.3.m3.1.1.cmml" type="integer" xref="S5.p2.3.m3.1.1">7</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.3.m3.1c">7</annotation><annotation encoding="application/x-llamapun" id="S5.p2.3.m3.1d">7</annotation></semantics></math> DS methods), we only present a synthesis of the results in the following sections. Classification accuracy of the corresponding recommended configuration for the base-level performance per dataset is detailed as supplementary material in the project’s GitHub repository.</p>
</div>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S5.SS1.4.1.1">V-A</span> </span><span class="ltx_text ltx_font_italic" id="S5.SS1.5.2">Scenario I: meta-learning for recommending the best pool generation scheme</span>
</h3>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">In the first scenario, the MLRS-P recommends a pool generation scheme while the DS method is fixed. This recommendation scenario is applicable when a specific DS method should be used, requiring an optimized pool generation scheme for a given query dataset, <math alttext="\mathbf{Q}" class="ltx_Math" display="inline" id="S5.SS1.p1.1.m1.1"><semantics id="S5.SS1.p1.1.m1.1a"><mi id="S5.SS1.p1.1.m1.1.1" xref="S5.SS1.p1.1.m1.1.1.cmml">𝐐</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.1.m1.1b"><ci id="S5.SS1.p1.1.m1.1.1.cmml" xref="S5.SS1.p1.1.m1.1.1">𝐐</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.1.m1.1c">\mathbf{Q}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p1.1.m1.1d">bold_Q</annotation></semantics></math>. This formulation has use cases, such as when performing a fair comparison between DS algorithms so that each one is optimized before evaluation or when a particular DS model needs to be used due to other constraints.</p>
</div>
<div class="ltx_para" id="S5.SS1.p2">
<p class="ltx_p" id="S5.SS1.p2.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#S5.T1" title="TABLE I ‣ V-A Scenario I: meta-learning for recommending the best pool generation scheme ‣ V Results ‣ MLRS-PDS: A Meta-learning recommendation of dynamic ensemble selection pipelines"><span class="ltx_text ltx_ref_tag">I</span></a> compares the performance of DS methods employing a pool generation scheme recommended by MLRS-P against baseline approaches. Each row in the table pits MLRS-P against the Majority baseline — the pool generation scheme achieving the highest number of wins for the respective DS method — as well as against the average result across all possible combinations. The number of datasets for which the corresponding technique recommended the optimal method is indicated in parentheses.</p>
</div>
<div class="ltx_para" id="S5.SS1.p3">
<p class="ltx_p" id="S5.SS1.p3.1">When considering META-DES as the DS algorithm, the pool generation scheme recommended by MLRS-P was the top performer in 207 out of 288 datasets, accounting for 71.87%, while for the KNORA-E method, MLRS-P recommends the optimal pool for 228 datasets (79.15%). In contrast, the majority baseline, which consistently uses the RF model, was only optimal for 90 datasets (31.25%). The distribution of the best pool generation scheme for the META-DES dataset is presented in Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#S5.F3" title="Figure 3 ‣ V-A Scenario I: meta-learning for recommending the best pool generation scheme ‣ V Results ‣ MLRS-PDS: A Meta-learning recommendation of dynamic ensemble selection pipelines"><span class="ltx_text ltx_ref_tag">3</span></a> a) <span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>Figures showing the best pool generation method distribution for other DS algorithms are available in the project’s GitHub repository as supplementary material</span></span></span>.</p>
</div>
<div class="ltx_para" id="S5.SS1.p4">
<p class="ltx_p" id="S5.SS1.p4.1">Our MLRS-P’s performance in recommending suitable classifier pools for specific DS methods significantly surpasses the baselines. Moreover, the result is also much higher than the random prediction, which corresponds to 1/7 in this multi-class classification context. This confirms MLRS-P’s ability to effectively model the relationship between meta-features and pool generation schemes for DS methods. Importantly, the optimal pool generation scheme varies notably with the DS model used. For instance, while RF achieved the highest number of wins with META-DES, other DS methods like OLA and MLA found the most success with BP (Bagging with Perceptron), and KNORA-E and KNORA-U with BDT (Bagging with Decision Trees). This highlights the pivotal role of the pool generation scheme in dynamic selection and that their choice must be taken into account based on the dataset characteristics and the DS method employed.</p>
</div>
<figure class="ltx_table" id="S5.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE I: </span>Comparison of pool recommendation accuracy between MLRS-P, majority-based, and average combination methods across different DS algorithms. Values represent the accuracy, and the number in parentheses indicates the total datasets where each method successfully recommends the optimal pool generation scheme.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T1.1" style="width:173.4pt;height:97.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-41.1pt,23.1pt) scale(0.678476557612986,0.678476557612986) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.T1.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T1.1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t" id="S5.T1.1.1.1.1.1">DS Method</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S5.T1.1.1.1.1.2">MLRS-P</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S5.T1.1.1.1.1.3">Majority</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S5.T1.1.1.1.1.4">Average</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T1.1.1.2.1">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S5.T1.1.1.2.1.1">KNORA-E</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T1.1.1.2.1.2"><span class="ltx_text ltx_font_bold" id="S5.T1.1.1.2.1.2.1">79.16 (228)</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T1.1.1.2.1.3">31.25 (90)</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T1.1.1.2.1.4">21.92 (43.00)</td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.1.3.2">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="S5.T1.1.1.3.2.1">META-DES</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T1.1.1.3.2.2"><span class="ltx_text ltx_font_bold" id="S5.T1.1.1.3.2.2.1">71.87 (207)</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T1.1.1.3.2.3">31.25 (90)</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T1.1.1.3.2.4">24.84 (44.86)</td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.1.4.3">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="S5.T1.1.1.4.3.1">KNORA-U</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T1.1.1.4.3.2"><span class="ltx_text ltx_font_bold" id="S5.T1.1.1.4.3.2.1">70.13 (202)</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T1.1.1.4.3.3">36.11 (104)</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T1.1.1.4.3.4">25.04 (48.29)</td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.1.5.4">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="S5.T1.1.1.5.4.1">DES-MI</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T1.1.1.5.4.2"><span class="ltx_text ltx_font_bold" id="S5.T1.1.1.5.4.2.1">78.12 (225)</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T1.1.1.5.4.3">38.19 (110)</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T1.1.1.5.4.4">22.26 (42.86)</td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.1.6.5">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="S5.T1.1.1.6.5.1">DES-P</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T1.1.1.6.5.2"><span class="ltx_text ltx_font_bold" id="S5.T1.1.1.6.5.2.1">71.52 (206)</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T1.1.1.6.5.3">35.41 (102)</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T1.1.1.6.5.4">25.24 (45.29)</td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.1.7.6">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="S5.T1.1.1.7.6.1">MLA</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T1.1.1.7.6.2"><span class="ltx_text ltx_font_bold" id="S5.T1.1.1.7.6.2.1">66.66 (192)</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T1.1.1.7.6.3">26.38 (76)</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T1.1.1.7.6.4">24.65 (48.14)</td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.1.8.7">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r" id="S5.T1.1.1.8.7.1">OLA</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S5.T1.1.1.8.7.2"><span class="ltx_text ltx_font_bold" id="S5.T1.1.1.8.7.2.1">62.84 (181)</span></td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S5.T1.1.1.8.7.3">48.26 (139)</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S5.T1.1.1.8.7.4">20.83 (42.71)</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure class="ltx_figure" id="S5.F3">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F3.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="150" id="S5.F3.1.g1" src="extracted/5722432/fig/METADES.png" width="234"/>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F3.2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="149" id="S5.F3.2.g1" src="extracted/5722432/fig/BP.png" width="234"/>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Number of occurrences where each configuration attained the best result. a) Best pool generation schemes for the fixed META-DES technique. b) Best DS method for the fixed BP pool generation scheme.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S5.SS2.4.1.1">V-B</span> </span><span class="ltx_text ltx_font_italic" id="S5.SS2.5.2">Scenario II: meta-learning for recommending the best DS model</span>
</h3>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">As the second type of recommendation evaluated in this work, MLRS-DS suggests a DS algorithm while a pool generation scheme is fixed. This is a critical use case for applications where a user already has a pre-trained pool of classifiers and wants to select the one more likely to maximize accuracy <math alttext="(DS_{o})" class="ltx_Math" display="inline" id="S5.SS2.p1.1.m1.1"><semantics id="S5.SS2.p1.1.m1.1a"><mrow id="S5.SS2.p1.1.m1.1.1.1" xref="S5.SS2.p1.1.m1.1.1.1.1.cmml"><mo id="S5.SS2.p1.1.m1.1.1.1.2" stretchy="false" xref="S5.SS2.p1.1.m1.1.1.1.1.cmml">(</mo><mrow id="S5.SS2.p1.1.m1.1.1.1.1" xref="S5.SS2.p1.1.m1.1.1.1.1.cmml"><mi id="S5.SS2.p1.1.m1.1.1.1.1.2" xref="S5.SS2.p1.1.m1.1.1.1.1.2.cmml">D</mi><mo id="S5.SS2.p1.1.m1.1.1.1.1.1" xref="S5.SS2.p1.1.m1.1.1.1.1.1.cmml">⁢</mo><msub id="S5.SS2.p1.1.m1.1.1.1.1.3" xref="S5.SS2.p1.1.m1.1.1.1.1.3.cmml"><mi id="S5.SS2.p1.1.m1.1.1.1.1.3.2" xref="S5.SS2.p1.1.m1.1.1.1.1.3.2.cmml">S</mi><mi id="S5.SS2.p1.1.m1.1.1.1.1.3.3" xref="S5.SS2.p1.1.m1.1.1.1.1.3.3.cmml">o</mi></msub></mrow><mo id="S5.SS2.p1.1.m1.1.1.1.3" stretchy="false" xref="S5.SS2.p1.1.m1.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.1.m1.1b"><apply id="S5.SS2.p1.1.m1.1.1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1.1"><times id="S5.SS2.p1.1.m1.1.1.1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1.1.1.1"></times><ci id="S5.SS2.p1.1.m1.1.1.1.1.2.cmml" xref="S5.SS2.p1.1.m1.1.1.1.1.2">𝐷</ci><apply id="S5.SS2.p1.1.m1.1.1.1.1.3.cmml" xref="S5.SS2.p1.1.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S5.SS2.p1.1.m1.1.1.1.1.3.1.cmml" xref="S5.SS2.p1.1.m1.1.1.1.1.3">subscript</csymbol><ci id="S5.SS2.p1.1.m1.1.1.1.1.3.2.cmml" xref="S5.SS2.p1.1.m1.1.1.1.1.3.2">𝑆</ci><ci id="S5.SS2.p1.1.m1.1.1.1.1.3.3.cmml" xref="S5.SS2.p1.1.m1.1.1.1.1.3.3">𝑜</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.1.m1.1c">(DS_{o})</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p1.1.m1.1d">( italic_D italic_S start_POSTSUBSCRIPT italic_o end_POSTSUBSCRIPT )</annotation></semantics></math> from the set of possible DS models.</p>
</div>
<div class="ltx_para" id="S5.SS2.p2">
<p class="ltx_p" id="S5.SS2.p2.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#S5.T2" title="TABLE II ‣ V-B Scenario II: meta-learning for recommending the best DS model ‣ V Results ‣ MLRS-PDS: A Meta-learning recommendation of dynamic ensemble selection pipelines"><span class="ltx_text ltx_ref_tag">II</span></a> presents a comparison between the performance of MLRS-DS against the majority selection and average baselines. Each row in the table corresponds to a fixed pool generation scheme that the recommendation algorithm takes as input to recommend the most appropriate DS model. It can be seen that MLRS-DS generally obtains much higher accuracy than the Majority and Average baselines. Taking BP as a fixed pool generation scheme model, for example, we observe that MLRS-DS can successfully predict the optimal DS method in 182 datasets, corresponding to 63.19% accuracy. The distribution of DS algorithms for the BP pool dataset is presented in Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#S5.F3" title="Figure 3 ‣ V-A Scenario I: meta-learning for recommending the best pool generation scheme ‣ V Results ‣ MLRS-PDS: A Meta-learning recommendation of dynamic ensemble selection pipelines"><span class="ltx_text ltx_ref_tag">3</span></a> b).</p>
</div>
<div class="ltx_para" id="S5.SS2.p3">
<p class="ltx_p" id="S5.SS2.p3.1">A similar behavior occurs when the recommendation system is analyzed using different fixed pool generation schemes, such as LIT (best recommendation in 207 datasets). In contrast, the accuracy of the majority recommender is 30.55% (88 datasets) and 31.25% (90 datasets) for LIT and BP, respectively. Thus, the results help us further confirm the hypothesis that some pools of classifiers are better suited for different DS models, and we cannot simply rely on always using a fixed top-performing DS model.</p>
</div>
<div class="ltx_para" id="S5.SS2.p4">
<p class="ltx_p" id="S5.SS2.p4.1">Another observation is that although the recommendation performance is higher than the majority, average, and random baselines, the overall MLRS-DS accuracy is lower than Scenario I, indicating that recommending the best DS model is more challenging than recommending the pool.</p>
</div>
<figure class="ltx_table" id="S5.T2">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE II: </span>Comparison of MLRS-DS performance against the majority method and average baseline across 288 datasets. Values represent the accuracy, and the number in parentheses indicates the total datasets where each method successfully recommends the optimal DS algorithm.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T2.1" style="width:173.4pt;height:101.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-36.3pt,21.2pt) scale(0.705100726202795,0.705100726202795) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.T2.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T2.1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t" id="S5.T2.1.1.1.1.1">Pool Gen.</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S5.T2.1.1.1.1.2">MLRS-DS</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S5.T2.1.1.1.1.3">Majority</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S5.T2.1.1.1.1.4">Average</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T2.1.1.2.1">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S5.T2.1.1.2.1.1">LIT</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T2.1.1.2.1.2"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.2.1.2.1">71.87 (207)</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T2.1.1.2.1.3">30.55 (88)</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T2.1.1.2.1.4">21.87 (42.71)</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.3.2">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="S5.T2.1.1.3.2.1">BP</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.1.1.3.2.2"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.3.2.2.1">63.19 (182)</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.1.1.3.2.3">31.25 (90)</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.1.1.3.2.4">30.25 (66.57)</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.4.3">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="S5.T2.1.1.4.3.1">BDT</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.1.1.4.3.2"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.4.3.2.1">62.50 (180)</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.1.1.4.3.3">59.02 (170)</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.1.1.4.3.4">26.98 (49.14)</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.5.4">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="S5.T2.1.1.5.4.1">BSDT</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.1.1.5.4.2"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.5.4.2.1">61.11 (176)</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.1.1.5.4.3">57.29 (165)</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.1.1.5.4.4">22.17 (45.14)</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.6.5">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="S5.T2.1.1.6.5.1">BSP</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.1.1.6.5.2"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.6.5.2.1">63.88 (184)</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.1.1.6.5.3">33.68 (97)</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.1.1.6.5.4">20.83 (43.00)</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.7.6">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="S5.T2.1.1.7.6.1">RF</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.1.1.7.6.2"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.7.6.2.1">59.37 (171)</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.1.1.7.6.3">50.00 (144)</td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.1.1.7.6.4">27.03 (52.85)</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.8.7">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r" id="S5.T2.1.1.8.7.1">FLT</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S5.T2.1.1.8.7.2"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.8.7.2.1">57.63 (166)</span></td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S5.T2.1.1.8.7.3">31.25 (90)</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S5.T2.1.1.8.7.4">23.90 (43.28)</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S5.SS3.4.1.1">V-C</span> </span><span class="ltx_text ltx_font_italic" id="S5.SS3.5.2">Scenario III: meta-learning for recommending the pool and DS algorithm</span>
</h3>
<div class="ltx_para" id="S5.SS3.p1">
<p class="ltx_p" id="S5.SS3.p1.2">Scenario III, called MLRS-PDS, performs a chained recommendation. It first recommends the more suitable pool generation scheme, <math alttext="C_{o}" class="ltx_Math" display="inline" id="S5.SS3.p1.1.m1.1"><semantics id="S5.SS3.p1.1.m1.1a"><msub id="S5.SS3.p1.1.m1.1.1" xref="S5.SS3.p1.1.m1.1.1.cmml"><mi id="S5.SS3.p1.1.m1.1.1.2" xref="S5.SS3.p1.1.m1.1.1.2.cmml">C</mi><mi id="S5.SS3.p1.1.m1.1.1.3" xref="S5.SS3.p1.1.m1.1.1.3.cmml">o</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.1.m1.1b"><apply id="S5.SS3.p1.1.m1.1.1.cmml" xref="S5.SS3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS3.p1.1.m1.1.1.1.cmml" xref="S5.SS3.p1.1.m1.1.1">subscript</csymbol><ci id="S5.SS3.p1.1.m1.1.1.2.cmml" xref="S5.SS3.p1.1.m1.1.1.2">𝐶</ci><ci id="S5.SS3.p1.1.m1.1.1.3.cmml" xref="S5.SS3.p1.1.m1.1.1.3">𝑜</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.1.m1.1c">C_{o}</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p1.1.m1.1d">italic_C start_POSTSUBSCRIPT italic_o end_POSTSUBSCRIPT</annotation></semantics></math>, according to the meta-feature, then recommends the DS method, <math alttext="DS_{o}" class="ltx_Math" display="inline" id="S5.SS3.p1.2.m2.1"><semantics id="S5.SS3.p1.2.m2.1a"><mrow id="S5.SS3.p1.2.m2.1.1" xref="S5.SS3.p1.2.m2.1.1.cmml"><mi id="S5.SS3.p1.2.m2.1.1.2" xref="S5.SS3.p1.2.m2.1.1.2.cmml">D</mi><mo id="S5.SS3.p1.2.m2.1.1.1" xref="S5.SS3.p1.2.m2.1.1.1.cmml">⁢</mo><msub id="S5.SS3.p1.2.m2.1.1.3" xref="S5.SS3.p1.2.m2.1.1.3.cmml"><mi id="S5.SS3.p1.2.m2.1.1.3.2" xref="S5.SS3.p1.2.m2.1.1.3.2.cmml">S</mi><mi id="S5.SS3.p1.2.m2.1.1.3.3" xref="S5.SS3.p1.2.m2.1.1.3.3.cmml">o</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.2.m2.1b"><apply id="S5.SS3.p1.2.m2.1.1.cmml" xref="S5.SS3.p1.2.m2.1.1"><times id="S5.SS3.p1.2.m2.1.1.1.cmml" xref="S5.SS3.p1.2.m2.1.1.1"></times><ci id="S5.SS3.p1.2.m2.1.1.2.cmml" xref="S5.SS3.p1.2.m2.1.1.2">𝐷</ci><apply id="S5.SS3.p1.2.m2.1.1.3.cmml" xref="S5.SS3.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S5.SS3.p1.2.m2.1.1.3.1.cmml" xref="S5.SS3.p1.2.m2.1.1.3">subscript</csymbol><ci id="S5.SS3.p1.2.m2.1.1.3.2.cmml" xref="S5.SS3.p1.2.m2.1.1.3.2">𝑆</ci><ci id="S5.SS3.p1.2.m2.1.1.3.3.cmml" xref="S5.SS3.p1.2.m2.1.1.3.3">𝑜</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.2.m2.1c">DS_{o}</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p1.2.m2.1d">italic_D italic_S start_POSTSUBSCRIPT italic_o end_POSTSUBSCRIPT</annotation></semantics></math>, conditional to the first choice. Thus, it consists of a multi-label prediction that recommends the whole DS pipeline in an end-to-end fashion.</p>
</div>
<div class="ltx_para" id="S5.SS3.p2">
<p class="ltx_p" id="S5.SS3.p2.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#S5.T3" title="TABLE III ‣ V-C Scenario III: meta-learning for recommending the pool and DS algorithm ‣ V Results ‣ MLRS-PDS: A Meta-learning recommendation of dynamic ensemble selection pipelines"><span class="ltx_text ltx_ref_tag">III</span></a> showcases a comparison of MLRS-PDS against MLRS-P, MLRS-DS, as well as the top-4 performing pairs of pool and DS models (i.e., the ones with the highest amount of top results across the 288 datasets). Notably, in the case of MLRS-P for this analysis, the selection was based on the fixed META-DES, which was identified as the most effective dynamic selection scheme across all datasets. Similarly, for MLRS-DS, the RF model was chosen as the fixed pool generation scheme since it presented the highest number of wins among other methods. The results of each possible configuration (7 pool generation schemes <math alttext="\times" class="ltx_Math" display="inline" id="S5.SS3.p2.1.m1.1"><semantics id="S5.SS3.p2.1.m1.1a"><mo id="S5.SS3.p2.1.m1.1.1" xref="S5.SS3.p2.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.1.m1.1b"><times id="S5.SS3.p2.1.m1.1.1.cmml" xref="S5.SS3.p2.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p2.1.m1.1d">×</annotation></semantics></math> 7 DS models) per dataset can be found as supplementary material on the project’s GitHub page.</p>
</div>
<figure class="ltx_table" id="S5.T3">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE III: </span>The comparison between the three versions of MLRS and the baselines among 288 datasets. MLRS-P with META-DES recommends pools with a fixed META-DES DS method. MLRS-DS with RF recommends DS methods with RF as the fixed pool scheme. The four combinations below the horizontal line correspond to the top 4 (Pool, DS) configurations among the 49 possible ones.</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S5.T3.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T3.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t" id="S5.T3.1.1.1.1"><span class="ltx_text" id="S5.T3.1.1.1.1.1" style="font-size:90%;">Algorithm</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S5.T3.1.1.1.2"><span class="ltx_text" id="S5.T3.1.1.1.2.1" style="font-size:90%;">Accuracy (wins)</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T3.1.2.1">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S5.T3.1.2.1.1"><span class="ltx_text" id="S5.T3.1.2.1.1.1" style="font-size:90%;">MLRS-PDS</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T3.1.2.1.2"><span class="ltx_text ltx_font_bold" id="S5.T3.1.2.1.2.1" style="font-size:90%;">64.93 (187)</span></td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.3.2">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="S5.T3.1.3.2.1"><span class="ltx_text" id="S5.T3.1.3.2.1.1" style="font-size:90%;">MLRS-P with META-DES</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T3.1.3.2.2"><span class="ltx_text" id="S5.T3.1.3.2.2.1" style="font-size:90%;">10.06 (29)</span></td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.4.3">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="S5.T3.1.4.3.1"><span class="ltx_text" id="S5.T3.1.4.3.1.1" style="font-size:90%;">MLRS-DS with RF</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T3.1.4.3.2"><span class="ltx_text" id="S5.T3.1.4.3.2.1" style="font-size:90%;">27.08 (78)</span></td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.5.4">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S5.T3.1.5.4.1"><span class="ltx_text" id="S5.T3.1.5.4.1.1" style="font-size:90%;">(RF, META-DES)</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T3.1.5.4.2"><span class="ltx_text" id="S5.T3.1.5.4.2.1" style="font-size:90%;">21.52 (62)</span></td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.6.5">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="S5.T3.1.6.5.1"><span class="ltx_text" id="S5.T3.1.6.5.1.1" style="font-size:90%;">(BP, DES-MI)</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T3.1.6.5.2"><span class="ltx_text" id="S5.T3.1.6.5.2.1" style="font-size:90%;">11.80 (34)</span></td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.7.6">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r" id="S5.T3.1.7.6.1"><span class="ltx_text" id="S5.T3.1.7.6.1.1" style="font-size:90%;">(BP, META-DES)</span></td>
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T3.1.7.6.2"><span class="ltx_text" id="S5.T3.1.7.6.2.1" style="font-size:90%;">10.06 (29)</span></td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.8.7">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r" id="S5.T3.1.8.7.1"><span class="ltx_text" id="S5.T3.1.8.7.1.1" style="font-size:90%;">(BSDT, KNORA-U)</span></td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r" id="S5.T3.1.8.7.2"><span class="ltx_text" id="S5.T3.1.8.7.2.1" style="font-size:90%;">4.51 (13)</span></td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para" id="S5.SS3.p3">
<p class="ltx_p" id="S5.SS3.p3.1">Several conclusions can be drawn from these analyses. First, when seeking the optimal solution, opting for the multi-label formulation (MLRS-PDS) and predicting both pipeline stages is advantageous. The results indicate that, for a significant number of datasets, either fixing the pool and letting the MLRS-DS suggest the DS method or fixing the DS and letting MLRS-P recommend the optimal pool generation scheme leads to a sub-optimal outcome, as it considerably limits the search space to just one decision step. Therefore, modeling the entire process through meta-learning is essential to maximize performance. Second, relying on robust, pre-existing pairs proves to be insufficient. The configuration that obtains the overall best results among the 49 possible ones (RF, META-DES) is the optimal choice for just 62 out of 288 datasets (21.52% of the total). This analysis demonstrates that the pool generation scheme choices and their relationship with the problem characteristics and the DS model employed should not be overlooked.</p>
</div>
<figure class="ltx_figure" id="S5.F4">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F4.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="162" id="S5.F4.1.g1" src="extracted/5722432/fig/MLRS_PDS_Pool.png" width="210"/>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F4.2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="163" id="S5.F4.2.g1" src="extracted/5722432/fig/MLRS_PDS_DS.png" width="210"/>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Number of occurrences that each configuration attains the best result.</figcaption>
</figure>
<div class="ltx_para" id="S5.SS3.p4">
<p class="ltx_p" id="S5.SS3.p4.1">Therefore, researchers and practitioners must avoid relying on a single, predefined pool generation scheme when comparing various DS models. Different models are based on different local assumptions and require distinct pools of classifiers to achieve optimal performance. Moreover, our proposed MLRS-PDS can be an interesting tool for practitioners who want to obtain the best performance possible using DS methods without needing to evaluate all possible configurations.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S5.SS4.4.1.1">V-D</span> </span><span class="ltx_text ltx_font_italic" id="S5.SS4.5.2">Recommendation analysis</span>
</h3>
<div class="ltx_para" id="S5.SS4.p1">
<p class="ltx_p" id="S5.SS4.p1.1">Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.07528v1#S5.F4" title="Figure 4 ‣ V-C Scenario III: meta-learning for recommending the pool and DS algorithm ‣ V Results ‣ MLRS-PDS: A Meta-learning recommendation of dynamic ensemble selection pipelines"><span class="ltx_text ltx_ref_tag">4</span></a> shows the frequency of recommended methods by the MLRS-PDS model. We can see that although some techniques are more often recommended, such as RF as the pool generation scheme and META-DES as the best DS model, there is a diversity in the recommendation scheme, demonstrating that the proposed MLRS-PDS model indeed changes its recommendation according to the problem’s characteristics instead of relying on fixed robust configurations such as (RF, META-DES) that works well across the majority of cases.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span class="ltx_text ltx_font_smallcaps" id="S6.1.1">Conclusion</span>
</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">This paper investigates two crucial yet often overlooked questions in DS research: 1) the impact of the pool generation scheme on a DS pipeline’s performance, considering dataset characteristics and the DS method; and 2) a methodology for determining an optimal DS pipeline for specific datasets. In response, we present a meta-learning recommendation system that enhances dynamic selection (DS) implementation by advising on its essential design steps, namely pool generation and DS algorithm, tailored to each dataset’s unique features. We developed a meta-model based on dataset-specific meta-features and a meta-target that indicates the optimal DES algorithm’s performance. We propose and analyze distinct recommendation modes for user convenience: 1) MLRS-P, which recommends the best pool generation scheme when the user prefers a specific DS method, thereby optimizing its performance; 2) MLRS-DS, which suggests the most suitable DS method for a predefined pool, which is ideal for users with an existing pool model seeking the best DS technique. 3) MLRS-PDS automatically selects the optimal pair of pool and DS methods based solely on the meta-features, streamlining the design process by eliminating manual decision-making.</p>
</div>
<div class="ltx_para" id="S6.p2">
<p class="ltx_p" id="S6.p2.1">Our extensive empirical study on 288 diverse datasets demonstrates that MLRS recommends the correct algorithm for the three evaluated scenarios with much higher prediction performance than the usual baselines. This study demonstrates the importance of aligning classifier pools with each dataset’s unique characteristics and the corresponding DS method, thereby highlighting the limitations of a one-size-fits-all strategy. Additionally, the results reveal that pool generation and its synergy with the DS method employed must not be neglected. As such, practitioners in the field must consider these conclusions when conducting further development and comparison of DS algorithms and when applying DS solutions to solve real-world problems.</p>
</div>
<div class="ltx_para" id="S6.p3">
<p class="ltx_p" id="S6.p3.1">Additionally, this study highlights the effectiveness of meta-learning in developing machine learning solutions, particularly in scenarios with significant interdependence between components, where the multi-label recommendation through chained prediction can model the relationship between each design step. Future work will focus on enhancing the meta-learning framework by including recommendations for the hyperparameters of the DS models and pool generation schemes. We also aim to explore other alternatives for the meta-feature extraction process.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
R. Polikar, “Ensemble based systems in decision making,” <em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">IEEE Circuits and systems magazine</em>, vol. 6, no. 3, pp. 21–45, 2006.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
R. M. Cruz, R. Sabourin, and G. D. Cavalcanti, “Dynamic classifier selection: Recent advances and perspectives,” <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">Information Fusion</em>, vol. 41, pp. 195–216, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
M. A. Souza, R. Sabourin, G. D. Cavalcanti, and R. M. Cruz, “A dynamic multiple classifier system using graph neural network for high dimensional overlapped data,” <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Information Fusion</em>, vol. 103, p. 102145, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
A. Roy, R. M. Cruz, R. Sabourin, and G. D. Cavalcanti, “A study on combining dynamic selection and data preprocessing for imbalance learning,” <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">Neurocomputing</em>, vol. 286, pp. 179–192, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
F. N. Walmsley, G. D. Cavalcanti, R. Sabourin, and R. M. Cruz, “An investigation into the effects of label noise on dynamic selection algorithms,” <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">Information Fusion</em>, vol. 80, pp. 104–120, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
P. R. Almeida, L. S. Oliveira, A. S. Britto Jr, and R. Sabourin, “Adapting dynamic classifier selection for concept drift,” <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">Expert Systems with Applications</em>, vol. 104, pp. 67–85, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
R. M. Cruz, D. V. Oliveira, G. D. Cavalcanti, and R. Sabourin, “FIRE-DES++: Enhanced online pruning of base classifiers for dynamic ensemble selection,” <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">Pattern Recognition</em>, vol. 85, pp. 149–160, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
M. A. Souza, G. D. Cavalcanti, R. M. Cruz, and R. Sabourin, “Online local pool generation for dynamic classifier selection,” <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">Pattern Recognition</em>, vol. 85, pp. 132–148, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
M. Monteiro Jr, A. S. Britto Jr, J. P. Barddal, L. S. Oliveira, and R. Sabourin, “Exploring diversity in data complexity and classifier decision spaces for pool generation,” <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">Information Fusion</em>, vol. 89, pp. 567–587, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
L. Breiman, “Bagging predictors,” <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">Machine learning</em>, vol. 24, no. 2, pp. 123–140, 1996.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Y. Freund and R. E. Schapire, “A decision-theoretic generalization of on-line learning and an application to boosting,” <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">Journal of computer and system sciences</em>, vol. 55, no. 1, pp. 119–139, 1997.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
W. M. Rodrigues, F. N. Walmsley, G. D. Cavalcanti, and R. M. Cruz, “Security relevant methods of android’s api classification: A machine learning empirical evaluation,” <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">IEEE Transactions on Computers</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
D. V. Oliveira, G. D. Cavalcanti, and R. Sabourin, “Online pruning of base classifiers for dynamic ensemble selection,” <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">Pattern Recognition</em>, vol. 72, pp. 44–58, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
M. A. Souza, G. D. Cavalcanti, R. M. Cruz, and R. Sabourin, “On the characterization of the oracle for dynamic classifier selection,” in <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">2017 International Joint Conference on Neural Networks (IJCNN)</em>.   IEEE, 2017, pp. 332–339.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
L. Breiman, “Random forests,” <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">Machine learning</em>, vol. 45, no. 1, pp. 5–32, 2001.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
G. Armano and E. Tamponi, “Building forests of local trees,” <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">Pattern Recognition</em>, vol. 76, pp. 380–390, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
A. Ross, W. Pan, L. Celi, and F. Doshi-Velez, “Ensembles of locally independent prediction models,” in <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">Proceedings of the AAAI Conference on Artificial Intelligence</em>, vol. 34, no. 04, 2020, pp. 5527–5536.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
J. R. Rice, “The algorithm selection problem,” in <em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">Advances in computers</em>.   Elsevier, 1976, vol. 15, pp. 65–118.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
P. Brazdil, J. N. van Rijn, C. Soares, and J. Vanschoren, <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">Metalearning: applications to automated machine learning and data mining</em>.   Springer Nature, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
L. P. Garcia, A. C. Lorena, M. C. de Souto, and T. K. Ho, “Classifier recommendation using data complexity measures,” in <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">2018 24th International Conference on Pattern Recognition (ICPR)</em>.   IEEE, 2018, pp. 874–879.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
B. A. Pimentel and A. C. De Carvalho, “A new data characterization for selecting clustering algorithms using meta-learning,” <em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">Information Sciences</em>, vol. 477, pp. 203–219, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
G. J. Aguiar, E. J. Santana, A. C. de Carvalho, and S. B. Junior, “Using meta-learning for multi-target regression,” <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">Information Sciences</em>, vol. 584, pp. 665–684, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
I. Khan, X. Zhang, M. Rehman, and R. Ali, “A literature survey and empirical study of meta-learning for classifier selection,” <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">IEEE Access</em>, vol. 8, pp. 10 262–10 281, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
T. A. Gomes, R. B. Prudêncio, C. Soares, A. L. Rossi, and A. Carvalho, “Combining meta-learning and search techniques to select parameters for support vector machines,” <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">Neurocomputing</em>, vol. 75, no. 1, pp. 3–13, 2012.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
L. B. de Amorim, G. D. Cavalcanti, and R. M. Cruz, “Meta-scaler: A meta-learning framework for the selection of scaling techniques,” <em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">IEEE Transactions on Neural Networks and Learning Systems</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
F. Pinto, V. Cerqueira, C. Soares, and J. Mendes-Moreira, “autobagging: Learning to rank bagging workflows with metalearning,” <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">arXiv preprint arXiv:1706.09367</em>, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
A. Roy, R. M. Cruz, R. Sabourin, and G. D. Cavalcanti, “Meta-learning recommendation of default size of classifier pool for meta-des,” <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">Neurocomputing</em>, vol. 216, pp. 351–362, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
——, “Meta-regression based pool size prediction scheme for dynamic selection of classifiers,” in <em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">2016 23rd International Conference on Pattern Recognition (ICPR)</em>.   IEEE, 2016, pp. 216–221.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
R. M. Cruz, R. Sabourin, and G. D. Cavalcanti, “A deep analysis of the META-DES framework for dynamic selection of ensemble of classifiers,” <em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">arXiv preprint arXiv:1509.00825</em>, 2015.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
J. Read, B. Pfahringer, G. Holmes, and E. Frank, “Classifier chains for multi-label classification,” <em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">Machine learning</em>, vol. 85, pp. 333–359, 2011.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
A. Rivolli, L. P. Garcia, C. Soares, J. Vanschoren, and A. C. de Carvalho, “Meta-features for meta-learning,” <em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">Knowledge-Based Systems</em>, vol. 240, p. 108101, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
M. Reif, F. Shafait, M. Goldstein, T. Breuel, and A. Dengel, “Automatic classifier selection for non-experts,” <em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">Pattern Analysis and Applications</em>, vol. 17, pp. 83–96, 2014.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
K. A. Smith-Miles, “Cross-disciplinary perspectives on meta-learning for algorithm selection,” <em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">ACM Computing Surveys (CSUR)</em>, vol. 41, no. 1, pp. 1–25, 2009.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
Q. Song, G. Wang, and C. Wang, “Automatic recommendation of classification algorithms based on data set characteristics,” <em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">Pattern recognition</em>, vol. 45, no. 7, pp. 2672–2689, 2012.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
T. K. Ho and M. Basu, “Complexity measures of supervised classification problems,” <em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">IEEE transactions on pattern analysis and machine intelligence</em>, vol. 24, no. 3, pp. 289–300, 2002.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
E. Alcobaça, F. Siqueira, A. Rivolli, L. P. Garcia, J. T. Oliva, and A. C. De Carvalho, “Mfe: Towards reproducible meta-feature extraction,” <em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">The Journal of Machine Learning Research</em>, vol. 21, no. 1, pp. 4503–4507, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
M. Z. Islam, J. Liu, J. Li, L. Liu, and W. Kang, “A semantics aware random forest for text classification,” in <em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">Proceedings of the 28th ACM International Conference on Information and Knowledge Management</em>, 2019, pp. 1061–1070.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
M. A. Souza, R. Sabourin, G. D. Cavalcanti, and R. M. Cruz, “Olp++: An online local classifier for high dimensional data,” <em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">Information Fusion</em>, vol. 90, pp. 120–137, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
R. M. Cruz, R. Sabourin, and G. D. Cavalcanti, “META-DES. Oracle: Meta-learning and feature selection for dynamic ensemble selection,” <em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">Information fusion</em>, vol. 38, pp. 84–103, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
S. García, Z.-L. Zhang, A. Altalhi, S. Alshomrani, and F. Herrera, “Dynamic ensemble selection for multi-class imbalanced datasets,” <em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">Information Sciences</em>, vol. 445, pp. 22–37, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
J. Elmi and M. Eftekhari, “Multi-layer selector (mls): Dynamic selection based on filtering some competence measures,” <em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">Applied Soft Computing</em>, vol. 104, p. 107257, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
R. Davtalab, R. M. Cruz, and R. Sabourin, “A scalable dynamic ensemble selection using fuzzy hyperboxes,” <em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">Information Fusion</em>, vol. 102, p. 102036, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
R. M. Cruz, L. G. Hafemann, R. Sabourin, and G. D. Cavalcanti, “DESlib: A dynamic ensemble selection library in python,” <em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">The Journal of Machine Learning Research</em>, vol. 21, no. 1, pp. 283–287, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
K. Woods, W. P. Kegelmeyer, and K. Bowyer, “Combination of multiple classifiers using local accuracy estimates,” <em class="ltx_emph ltx_font_italic" id="bib.bib44.1.1">IEEE transactions on pattern analysis and machine intelligence</em>, vol. 19, no. 4, pp. 405–410, 1997.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
P. C. Smits, “Multiple classifier systems for supervised remote sensing image classification based on dynamic classifier selection,” <em class="ltx_emph ltx_font_italic" id="bib.bib45.1.1">IEEE Trans. on Geoscience and Remote Sensing</em>, vol. 40, no. 4, pp. 801–813, 2002.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
A. H. Ko, R. Sabourin, and A. S. Britto Jr, “From dynamic classifier selection to dynamic ensemble selection,” <em class="ltx_emph ltx_font_italic" id="bib.bib46.1.1">Pattern recognition</em>, vol. 41, no. 5, pp. 1718–1731, 2008.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
R. M. Cruz, R. Sabourin, G. D. Cavalcanti, and T. I. Ren, “META-DES: A dynamic ensemble selection framework using meta-learning,” <em class="ltx_emph ltx_font_italic" id="bib.bib47.1.1">Pattern recognition</em>, vol. 48, no. 5, pp. 1925–1935, 2015.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
T. Woloszynski, M. Kurzynski, P. Podsiadlo, and G. W. Stachowiak, “A measure of competence based on random classification for dynamic ensemble selection,” <em class="ltx_emph ltx_font_italic" id="bib.bib48.1.1">Information Fusion</em>, vol. 13, no. 3, pp. 207–213, 2012.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
N. Macià, T. K. Ho, A. Orriols-Puig, and E. Bernadó-Mansilla, “The landscape contest at icpr 2010,” in <em class="ltx_emph ltx_font_italic" id="bib.bib49.1.1">International Conference on Pattern Recognition</em>.   Springer, 2010, pp. 29–45.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
T. K. Ho, “A data complexity analysis of comparative advantages of decision forest constructors,” <em class="ltx_emph ltx_font_italic" id="bib.bib50.1.1">Pattern Analysis &amp; Applications</em>, vol. 5, no. 2, pp. 102–112, 2002.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
L. B. de Amorim, G. D. Cavalcanti, and R. M. Cruz, “The choice of scaling technique matters for classification performance,” <em class="ltx_emph ltx_font_italic" id="bib.bib51.1.1">Applied Soft Computing</em>, vol. 133, p. 109924, 2023.

</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Wed Jul 10 10:29:16 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
