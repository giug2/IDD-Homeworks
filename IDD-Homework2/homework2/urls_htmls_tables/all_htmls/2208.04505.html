<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2208.04505] Towards Energy-Aware Federated Learning on Battery-Powered Clients</title><meta property="og:description" content="Federated learning (FL) is a newly emerged branch of AI that facilitates edge devices to collaboratively train a global machine learning model without centralizing data and with privacy by default. However, despite the…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Towards Energy-Aware Federated Learning on Battery-Powered Clients">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Towards Energy-Aware Federated Learning on Battery-Powered Clients">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2208.04505">

<!--Generated on Wed Mar 13 20:00:49 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno" lang="en">
<h1 class="ltx_title ltx_title_document">Towards Energy-Aware Federated Learning on Battery-Powered Clients</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Amna Arouj
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id2.1.id1" class="ltx_text ltx_affiliation_institution">Queen Mary University of London</span><span id="id3.2.id2" class="ltx_text ltx_affiliation_country">United Kingdom</span>
</span></span></span>
<span class="ltx_author_before"> and </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Ahmed M. Abdelmoniem
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id4.1.id1" class="ltx_text ltx_affiliation_institution">Queen Mary University of London</span><span id="id5.2.id2" class="ltx_text ltx_affiliation_country">United Kingdom</span>
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p id="id1.1" class="ltx_p"><span id="id1.1.1" class="ltx_text">Federated learning (FL) is a newly emerged branch of AI that facilitates edge devices to collaboratively train a global machine learning model without centralizing data and with privacy by default. However, despite the remarkable advancement, this paradigm comes with various challenges. Specifically, in large-scale deployments, client heterogeneity is the norm which impacts training quality such as accuracy, fairness, and time. Moreover, energy consumption across these battery-constrained devices is largely unexplored and a limitation for wide-adoption of FL. To address this issue, we develop EAFL, an energy-aware FL selection method that considers energy consumption to maximize the participation of heterogeneous target devices. <span id="id1.1.1.1" class="ltx_text ltx_font_italic">EAFL</span> is a power-aware training algorithm that cherry-picks clients with higher battery levels in conjunction with its ability to maximize the system efficiency.
Our design jointly minimizes the time-to-accuracy and maximizes the remaining on-device battery levels. <span id="id1.1.1.2" class="ltx_text ltx_font_italic">EAFL</span> improves the testing model accuracy by up to 85% and decreases the drop-out of clients by up to 2.45<math id="id1.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="id1.1.1.m1.1a"><mo id="id1.1.1.m1.1.1" xref="id1.1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="id1.1.1.m1.1b"><times id="id1.1.1.m1.1.1.cmml" xref="id1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="id1.1.1.m1.1c">\times</annotation></semantics></math>.<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Accepted to appear in FedEgde Workshop of ACM MobiCom 2022
<br class="ltx_break">Code and scripts are available at <a target="_blank" href="https://github.com/SAYED-Sys-Lab/EAFL" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/SAYED-Sys-Lab/EAFL</a></span></span></span></span></p>
</div>
<div class="ltx_keywords">
<span id="id6.id1" class="ltx_text">Federated Learning, Heterogeneity, Performance, Fairness</span>
</div>
<span id="id1" class="ltx_note ltx_note_frontmatter ltx_role_copyright"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">copyright: </span>none</span></span></span>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Due to the advancements in technology and the wireless industry’s growth, a wealth of data is born at the edge every day. We are connecting more devices and crunching data faster than ever before and by 2025 the number of smartphones and wearable devices will reach 7.33 and 1 billion, respectively <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:80%;">Exchange</span>, <a href="#bib.bib17" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2022</span></a>)</cite>.
To draw useful information from this geographically distributed data, a prominent paradigm known as federated learning (FL) has emerged that allows the end devices to learn a shared ML model while preserving the user’s data privacy. Ideally, a cluster of users run stochastic gradient descent (SGD) locally and aggregate their updated models via the server to obtain a new global model.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Lately, the advancements in the powerful mobile System-on-Chips (SoCs) further foster the adoption of FL for collaborative learning on edge devices such as smartphones, smart-wear, IoT devices, etc. These devices are now equipped with high-performance central processing units (CPUs) and graphics processing units (GPUs) to operate intensive computations for AI/ML-based applications. Due to the technical abilities and implementation ease, FL has recently seen wins in several applications like power keyboard predictions(Gboard), vocal/face classifiers (Face ID and Siri), virtual assistants, smart cities and augmented reality <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:80%;">Kim and Wu</span>, <a href="#bib.bib24" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2021</span></a>)</cite>.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Although on-device inference comes with promising deployment in exciting applications, improved latency, work offline, privacy advantages, and better battery life, however, implementing FL on mobile devices brings severe challenges, of which energy consumption is a primary concern. Common characteristics of these devices are that they have limited energy, storage, and computing resources; thus, because of these constraints, optimizing the energy efficiency of the ML inference while fulfilling the Quality-of-Service (QoS) requirements is essential for these services.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Although existing FL solutions have shown significant progress in overcoming the challenges encountered in the FL design space, most of them, however, given a pool of participants, focus either on optimizing <span id="S1.p4.1.1" class="ltx_text ltx_font_italic">statistical model efficiency</span> (i.e., improving training accuracy with lesser training rounds) <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:80%;">Li et al</span><span class="ltx_text" style="font-size:80%;">.</span>, <a href="#bib.bib30" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2020</span></a>; <span class="ltx_text" style="font-size:80%;">Peng
et al</span><span class="ltx_text" style="font-size:80%;">.</span>, <a href="#bib.bib36" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2020</span></a>)</cite> or <span id="S1.p4.1.2" class="ltx_text ltx_font_italic">system efficiency</span> (i.e., shorter training rounds) <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:80%;">McMahan et al</span><span class="ltx_text" style="font-size:80%;">.</span>, <a href="#bib.bib32" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2017</span></a>; <span class="ltx_text" style="font-size:80%;">Suresh
et al</span><span class="ltx_text" style="font-size:80%;">.</span>, <a href="#bib.bib44" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2017</span></a>)</cite> while other mechanisms have been proposed to guarantee privacy and robustness <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:80%;">et al.</span>, <a href="#bib.bib16" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2017</span></a>; <span class="ltx_text" style="font-size:80%;">Geyer
et al</span><span class="ltx_text" style="font-size:80%;">.</span>, <a href="#bib.bib20" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2017</span></a>)</cite>. As adopted in Oort, the designer makes all efforts to optimize the system efficiency, ignoring the diversity of the clients’ data <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:80%;">Lai
et al</span><span class="ltx_text" style="font-size:80%;">.</span>, <a href="#bib.bib28" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2021</span></a>)</cite>. This level of unfairness results in a less robust model toward data heterogeneity and, therefore, results in</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">Executing intensive on-device computation for long periods can quickly drain the battery or burn the device, leading to client dropouts <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:80%;">Lai et al</span><span class="ltx_text" style="font-size:80%;">.</span>, <a href="#bib.bib27" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2022</span></a>)</cite>. Hence, we deem <span id="S1.p5.1.1" class="ltx_text ltx_font_italic">a power-aware FL training is an open problem</span>. In this work, we introduce <span id="S1.p5.1.2" class="ltx_text ltx_font_italic">EAFL</span>, a novel, user-friendly training algorithm that picks high remaining power learners to increase the participation level in FL training and reduce the energy impact on user’s devices. Our results show that <span id="S1.p5.1.3" class="ltx_text ltx_font_italic">EAFL</span> delivers significant accuracy benefits over the state-of-the-art while reducing drop-outs due to battery drainage, hence preserving the user experience. In this work, we make the following contributions:</p>
<ol id="S1.I1" class="ltx_enumerate">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(1)</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">We consider a more practical FL scenario on battery-powered devices where heavy computations during FL training may lead to performance degradation while accounting for the heterogeneity in the system.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(2)</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">Based on studying various energy-consumption models of real mobile devices, we present a power-aware design that intelligently improves the FL performance in battery-powered scenarios through reduced client dropouts and increased participation levels.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(3)</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">We show, via experiments on real FL benchmark in battery-powered scenario, that <span id="S1.I1.i3.p1.1.1" class="ltx_text ltx_font_italic">EAFL</span> produces models of high quality compared to state-of-art solutions.</p>
</div>
</li>
</ol>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Background and Motivation</h2>

<figure id="S2.F1" class="ltx_figure"><img src="/html/2208.04505/assets/x1.png" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="233" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F1.2.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>. </span><span id="S2.F1.3.2" class="ltx_text" style="font-size:90%;">The various phases in training rounds of FL.</span></figcaption>
</figure>
<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">We start with a quick overview of the FL system design, followed by
highlighting the key limitations in the existing solutions that motivate our work.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1. </span>Federated learning</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Federated learning, an emerging networking paradigm, runs machine learning on decentralized data. It takes advantage of the available computing resources across a massive pool of edge devices. More specifically, all clients collectively train on one global learning model and perform regular model parameter updates by continuous interactions.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">Two main entities are in the core of FL design —<em id="S2.SS1.p2.1.1" class="ltx_emph ltx_font_italic">Clients</em>, the data owners (e.g. smartphones, tablets, laptops, auto-vehicles, etc.) and — <em id="S2.SS1.p2.1.2" class="ltx_emph ltx_font_italic">Aggregator</em>, the model owner (e.g. server). Training of the global model takes place by specifying the number of epochs <span id="S2.SS1.p2.1.3" class="ltx_text ltx_font_bold">E</span> (rounds) until the model converges. Other parameters like minibatch size <span id="S2.SS1.p2.1.4" class="ltx_text ltx_font_bold">B</span>, and participants per round <span id="S2.SS1.p2.1.5" class="ltx_text ltx_font_bold">K</span> are also specified and are determined by the FL-based services <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:80%;">Bonawitz et al</span><span class="ltx_text" style="font-size:80%;">.</span>, <a href="#bib.bib12" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2019</span></a>; <span class="ltx_text" style="font-size:80%;">Kim and Wu</span>, <a href="#bib.bib24" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2021</span></a>)</cite>. As depicted in <a href="#S2.F1" title="In 2. Background and Motivation ‣ Towards Energy-Aware Federated Learning on Battery-Powered Clients" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">1</span></a>, at the start of each training round, the aggregator selects <span id="S2.SS1.p2.1.6" class="ltx_text ltx_font_bold">K</span> participants among <span id="S2.SS1.p2.1.7" class="ltx_text ltx_font_bold">N</span> available devices depending on given criteria. <em id="S2.SS1.p2.1.8" class="ltx_emph ltx_font_italic">(Step 1)</em> Server broadcasts the model’s current version and other necessary hyper-parameters to the selected devices. <em id="S2.SS1.p2.1.9" class="ltx_emph ltx_font_italic">(Step 2)</em> Each participant trains the model by performing <span id="S2.SS1.p2.1.10" class="ltx_text ltx_font_bold">E</span> local optimization steps with a batch size of <span id="S2.SS1.p2.1.11" class="ltx_text ltx_font_bold">B</span>. <em id="S2.SS1.p2.1.12" class="ltx_emph ltx_font_italic">(Step 3)</em> Learners send their computed model updates back to the server.<em id="S2.SS1.p2.1.13" class="ltx_emph ltx_font_italic">(Step 4)</em>The server collects the model updates from the participants for aggregation and checkpoints it. <em id="S2.SS1.p2.1.14" class="ltx_emph ltx_font_italic">(Step 5)</em> The stages are repeated until the desired accuracy is achieved.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2. </span>Motivation</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">In this part, we try to motivate our work.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para ltx_noindent">
<p id="S2.SS2.p2.1" class="ltx_p"><span id="S2.SS2.p2.1.1" class="ltx_text ltx_font_bold">FL considerations in mobile environment:</span>  Existing FL solutions have simply failed to notice the consequences resulting in the interplay of client devices and training speed (e.g., using significant local steps to save communication) <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:80%;">McMahan et al</span><span class="ltx_text" style="font-size:80%;">.</span>, <a href="#bib.bib32" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2017</span></a>)</cite> leads to intensive on-device computation for extended periods, resulting in the sudden drain of the battery or even burning of the device hence leading to unavailability of the client. However, the possibility of redeeming these disadvantages by implementing a <em id="S2.SS2.p2.1.2" class="ltx_emph ltx_font_italic">power-aware training algorithm</em> has been incredibly overlooked <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:80%;">Lai et al</span><span class="ltx_text" style="font-size:80%;">.</span>, <a href="#bib.bib27" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2022</span></a>)</cite>.</p>
</div>
<div id="S2.SS2.p3" class="ltx_para">
<p id="S2.SS2.p3.1" class="ltx_p">Furthermore, very less work is presented in the <em id="S2.SS2.p3.1.1" class="ltx_emph ltx_font_italic">energy efficiency</em> optimization domain. Most prior work supposes that FL training is activated once smartphones are plugged into a power-point because of the significant energy consumption during FL training <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:80%;">Wang
et al</span><span class="ltx_text" style="font-size:80%;">.</span>, <a href="#bib.bib45" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2021</span></a>; <span class="ltx_text" style="font-size:80%;">Qiu et al</span><span class="ltx_text" style="font-size:80%;">.</span>, <a href="#bib.bib37" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2020</span></a>)</cite>. Unfortunately, this has restricted the practical implementation of FL, resulting in incorrect model accuracy and long convergence times. Energy-efficient federated learning can facilitate on-device training with better accuracy, model quality, and user experience. Through <span id="S2.SS2.p3.1.2" class="ltx_text ltx_font_italic">EAFL</span>, we aim to present solutions to simultaneously achieve system and energy conservation, embracing the opportunities presented by earlier work.</p>
</div>
<div id="S2.SS2.p4" class="ltx_para ltx_noindent">
<p id="S2.SS2.p4.1" class="ltx_p"><span id="S2.SS2.p4.1.1" class="ltx_text ltx_font_bold">System heterogeneity and client drop-outs:</span>  Edge and IoT devices differ in underlying architectures (CPU, design, or memory). These devices function on different battery levels and use different communication mediums (e.g., Wi-Fi or 4G/5G). Hence, each device differs in computational storage and communication capacities. These differences in system configurations introduce problems to FL schemes especially when entry-level edge devices with low battery power and bandwidth are involved. This is because these devices are more susceptible to dropouts during training when they run out of battery at any time.</p>
</div>
<div id="S2.SS2.p5" class="ltx_para">
<p id="S2.SS2.p5.1" class="ltx_p">Client drop-out is synonymous with the straggler issue in FL training, in which some clients delay the uploading of the local model <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:80%;">McMahan et al</span><span class="ltx_text" style="font-size:80%;">.</span>, <a href="#bib.bib32" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2017</span></a>)</cite>. Many solutions exist to mitigate the straggler issue <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:80%;">Xie
et al</span><span class="ltx_text" style="font-size:80%;">.</span>, <a href="#bib.bib48" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2019</span></a>; <span class="ltx_text" style="font-size:80%;">Reisizadeh et al</span><span class="ltx_text" style="font-size:80%;">.</span>, <a href="#bib.bib40" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">[n.d.]</span></a>)</cite>. A straggler-resilient design is proposed in <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:80%;">Reisizadeh et al</span><span class="ltx_text" style="font-size:80%;">.</span>, <a href="#bib.bib40" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">[n.d.]</span></a>)</cite> that adaptively selects clients by incorporating the statistical characteristics of the client’s data. However, client drop-out is a more severe case because dropout clients cannot upload their model in the current round and are likely to remain unavailable for some period of time; thus, existing schemes to mitigate the straggler issue do not work <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:80%;">Wang and Xu</span>, <a href="#bib.bib46" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2021</span></a>)</cite>.</p>
</div>
<div id="S2.SS2.p6" class="ltx_para">
<p id="S2.SS2.p6.1" class="ltx_p">For the aforementioned reasons, system heterogeneity introduces unexplored challenges in FL. We introduce the notion of power-aware training which mitigates client drop-out and improves FL performance. Our design goal is to trade-off remaining power with time which reduces the clients’ dropouts and hence improves the model quality.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>EAFL Design Overview</h2>

<figure id="S3.F2" class="ltx_figure"><img src="/html/2208.04505/assets/x2.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="282" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F2.3.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>. </span><span id="S3.F2.4.2" class="ltx_text" style="font-size:90%;">High-level Architectural Design of <span id="S3.F2.4.2.1" class="ltx_text ltx_font_italic">EAFL</span>.</span></figcaption>
</figure>
<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p"><span id="S3.p1.1.1" class="ltx_text ltx_font_italic">EAFL</span>’s goal is to jointly reconcile the demand for power-aware FL training and optimization of system/statistical efficiency over heterogeneous battery-powered edge devices. To illustrate and study the heterogeneity impact on
model quality and client drop-outs, we follow the experimental
design approach <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:80%;">Fisher</span>, <a href="#bib.bib18" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">1971</span></a>)</cite> and raise the following questions:</p>
</div>
<div id="S3.p2" class="ltx_para">
<ol id="S3.I1" class="ltx_enumerate">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(1)</span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.p1.1" class="ltx_p">To what extent do client dropouts due to battery-constraints impact the convergence of FL?</p>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(2)</span> 
<div id="S3.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i2.p1.1" class="ltx_p">What is the trade-off between model quality and energy efficiency of the system?</p>
</div>
</li>
</ol>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1. </span>Architecture</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p"><a href="#S3.F2" title="In 3. EAFL Design Overview ‣ Towards Energy-Aware Federated Learning on Battery-Powered Clients" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">2</span></a> shows the high-level architecture of <span id="S3.SS1.p1.1.1" class="ltx_text ltx_font_italic">EAFL</span> and the interactions between <span id="S3.SS1.p1.1.2" class="ltx_text ltx_font_italic">EAFL</span>, the FL developer and server and the edge devices. The developer submits the task to the FL coordinator, and then the coordinator registers each client’s profile (e.g., battery level, workload, RAM, etc.) and forwards the characteristics to the server running <span id="S3.SS1.p1.1.3" class="ltx_text ltx_font_italic">EAFL</span>. Based on the feedback from the earlier rounds and client profiles, <span id="S3.SS1.p1.1.4" class="ltx_text ltx_font_italic">EAFL</span> associates a utility with each client and selects the group of participants for the upcoming training round according to the selection mechanism. Next, the coordinator distributes the relevant model profiles to each selected participant, who computes results on their local data individually. The coordinator then collects the updates from the participants to aggregate. Furthermore, the steps from selection to aggregation are repeated until the desired accuracy is achieved.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">In <span id="S3.SS1.p2.1.1" class="ltx_text ltx_font_italic">EAFL</span>, the algorithm identifies and favours participants with higher utilities. The reward function calculates the utility of each client which consists of two parts. One part is a function for jointly measuring the system and statistical utility and the other part is a function of the remaining battery level of the client’s device. We test our scheme under different scenarios by giving different weights to each function in the utility definition. We elaborate more on client utility in <a href="#S4" title="4. Federated Model Training ‣ Towards Energy-Aware Federated Learning on Battery-Powered Clients" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">4</span></a>. In our scheme, we preferentially select clients with higher power values by controlling the weights in the utility function. We use different models for the power consumption based on devices’ system configuration which accounts for idle and normal usage states of the devices.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>Federated Model Training</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In this section, we explain how <span id="S4.p1.1.1" class="ltx_text ltx_font_italic">EAFL</span> quantifies the client utility, how it selects high-utility clients as training unwinds, and then discuss the energy consumption models.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1. </span>Clients utility definition</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">The reward function comprises two parts, seeking to reconcile the demand for time-to-accuracy and energy conservation. We modify the current reward function proposed in Oort <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:80%;">Lai
et al</span><span class="ltx_text" style="font-size:80%;">.</span>, <a href="#bib.bib28" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2021</span></a>)</cite> by replacing it for client <span id="S4.SS1.p1.1.1" class="ltx_text ltx_font_italic">i</span> as:</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<table id="S4.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(1)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E1.m1.3" class="ltx_Math" alttext="reward=f\times Util(i)+(1-f)\times power(i)," display="block"><semantics id="S4.E1.m1.3a"><mrow id="S4.E1.m1.3.3.1" xref="S4.E1.m1.3.3.1.1.cmml"><mrow id="S4.E1.m1.3.3.1.1" xref="S4.E1.m1.3.3.1.1.cmml"><mrow id="S4.E1.m1.3.3.1.1.3" xref="S4.E1.m1.3.3.1.1.3.cmml"><mi id="S4.E1.m1.3.3.1.1.3.2" xref="S4.E1.m1.3.3.1.1.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.3.3.1.1.3.1" xref="S4.E1.m1.3.3.1.1.3.1.cmml">​</mo><mi id="S4.E1.m1.3.3.1.1.3.3" xref="S4.E1.m1.3.3.1.1.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.3.3.1.1.3.1a" xref="S4.E1.m1.3.3.1.1.3.1.cmml">​</mo><mi id="S4.E1.m1.3.3.1.1.3.4" xref="S4.E1.m1.3.3.1.1.3.4.cmml">w</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.3.3.1.1.3.1b" xref="S4.E1.m1.3.3.1.1.3.1.cmml">​</mo><mi id="S4.E1.m1.3.3.1.1.3.5" xref="S4.E1.m1.3.3.1.1.3.5.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.3.3.1.1.3.1c" xref="S4.E1.m1.3.3.1.1.3.1.cmml">​</mo><mi id="S4.E1.m1.3.3.1.1.3.6" xref="S4.E1.m1.3.3.1.1.3.6.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.3.3.1.1.3.1d" xref="S4.E1.m1.3.3.1.1.3.1.cmml">​</mo><mi id="S4.E1.m1.3.3.1.1.3.7" xref="S4.E1.m1.3.3.1.1.3.7.cmml">d</mi></mrow><mo id="S4.E1.m1.3.3.1.1.2" xref="S4.E1.m1.3.3.1.1.2.cmml">=</mo><mrow id="S4.E1.m1.3.3.1.1.1" xref="S4.E1.m1.3.3.1.1.1.cmml"><mrow id="S4.E1.m1.3.3.1.1.1.3" xref="S4.E1.m1.3.3.1.1.1.3.cmml"><mrow id="S4.E1.m1.3.3.1.1.1.3.2" xref="S4.E1.m1.3.3.1.1.1.3.2.cmml"><mi id="S4.E1.m1.3.3.1.1.1.3.2.2" xref="S4.E1.m1.3.3.1.1.1.3.2.2.cmml">f</mi><mo lspace="0.222em" rspace="0.222em" id="S4.E1.m1.3.3.1.1.1.3.2.1" xref="S4.E1.m1.3.3.1.1.1.3.2.1.cmml">×</mo><mi id="S4.E1.m1.3.3.1.1.1.3.2.3" xref="S4.E1.m1.3.3.1.1.1.3.2.3.cmml">U</mi></mrow><mo lspace="0em" rspace="0em" id="S4.E1.m1.3.3.1.1.1.3.1" xref="S4.E1.m1.3.3.1.1.1.3.1.cmml">​</mo><mi id="S4.E1.m1.3.3.1.1.1.3.3" xref="S4.E1.m1.3.3.1.1.1.3.3.cmml">t</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.3.3.1.1.1.3.1a" xref="S4.E1.m1.3.3.1.1.1.3.1.cmml">​</mo><mi id="S4.E1.m1.3.3.1.1.1.3.4" xref="S4.E1.m1.3.3.1.1.1.3.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.3.3.1.1.1.3.1b" xref="S4.E1.m1.3.3.1.1.1.3.1.cmml">​</mo><mi id="S4.E1.m1.3.3.1.1.1.3.5" xref="S4.E1.m1.3.3.1.1.1.3.5.cmml">l</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.3.3.1.1.1.3.1c" xref="S4.E1.m1.3.3.1.1.1.3.1.cmml">​</mo><mrow id="S4.E1.m1.3.3.1.1.1.3.6.2" xref="S4.E1.m1.3.3.1.1.1.3.cmml"><mo stretchy="false" id="S4.E1.m1.3.3.1.1.1.3.6.2.1" xref="S4.E1.m1.3.3.1.1.1.3.cmml">(</mo><mi id="S4.E1.m1.1.1" xref="S4.E1.m1.1.1.cmml">i</mi><mo stretchy="false" id="S4.E1.m1.3.3.1.1.1.3.6.2.2" xref="S4.E1.m1.3.3.1.1.1.3.cmml">)</mo></mrow></mrow><mo id="S4.E1.m1.3.3.1.1.1.2" xref="S4.E1.m1.3.3.1.1.1.2.cmml">+</mo><mrow id="S4.E1.m1.3.3.1.1.1.1" xref="S4.E1.m1.3.3.1.1.1.1.cmml"><mrow id="S4.E1.m1.3.3.1.1.1.1.1" xref="S4.E1.m1.3.3.1.1.1.1.1.cmml"><mrow id="S4.E1.m1.3.3.1.1.1.1.1.1.1" xref="S4.E1.m1.3.3.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.E1.m1.3.3.1.1.1.1.1.1.1.2" xref="S4.E1.m1.3.3.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.E1.m1.3.3.1.1.1.1.1.1.1.1" xref="S4.E1.m1.3.3.1.1.1.1.1.1.1.1.cmml"><mn id="S4.E1.m1.3.3.1.1.1.1.1.1.1.1.2" xref="S4.E1.m1.3.3.1.1.1.1.1.1.1.1.2.cmml">1</mn><mo id="S4.E1.m1.3.3.1.1.1.1.1.1.1.1.1" xref="S4.E1.m1.3.3.1.1.1.1.1.1.1.1.1.cmml">−</mo><mi id="S4.E1.m1.3.3.1.1.1.1.1.1.1.1.3" xref="S4.E1.m1.3.3.1.1.1.1.1.1.1.1.3.cmml">f</mi></mrow><mo rspace="0.055em" stretchy="false" id="S4.E1.m1.3.3.1.1.1.1.1.1.1.3" xref="S4.E1.m1.3.3.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo rspace="0.222em" id="S4.E1.m1.3.3.1.1.1.1.1.2" xref="S4.E1.m1.3.3.1.1.1.1.1.2.cmml">×</mo><mi id="S4.E1.m1.3.3.1.1.1.1.1.3" xref="S4.E1.m1.3.3.1.1.1.1.1.3.cmml">p</mi></mrow><mo lspace="0em" rspace="0em" id="S4.E1.m1.3.3.1.1.1.1.2" xref="S4.E1.m1.3.3.1.1.1.1.2.cmml">​</mo><mi id="S4.E1.m1.3.3.1.1.1.1.3" xref="S4.E1.m1.3.3.1.1.1.1.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.3.3.1.1.1.1.2a" xref="S4.E1.m1.3.3.1.1.1.1.2.cmml">​</mo><mi id="S4.E1.m1.3.3.1.1.1.1.4" xref="S4.E1.m1.3.3.1.1.1.1.4.cmml">w</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.3.3.1.1.1.1.2b" xref="S4.E1.m1.3.3.1.1.1.1.2.cmml">​</mo><mi id="S4.E1.m1.3.3.1.1.1.1.5" xref="S4.E1.m1.3.3.1.1.1.1.5.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.3.3.1.1.1.1.2c" xref="S4.E1.m1.3.3.1.1.1.1.2.cmml">​</mo><mi id="S4.E1.m1.3.3.1.1.1.1.6" xref="S4.E1.m1.3.3.1.1.1.1.6.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.3.3.1.1.1.1.2d" xref="S4.E1.m1.3.3.1.1.1.1.2.cmml">​</mo><mrow id="S4.E1.m1.3.3.1.1.1.1.7.2" xref="S4.E1.m1.3.3.1.1.1.1.cmml"><mo stretchy="false" id="S4.E1.m1.3.3.1.1.1.1.7.2.1" xref="S4.E1.m1.3.3.1.1.1.1.cmml">(</mo><mi id="S4.E1.m1.2.2" xref="S4.E1.m1.2.2.cmml">i</mi><mo stretchy="false" id="S4.E1.m1.3.3.1.1.1.1.7.2.2" xref="S4.E1.m1.3.3.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S4.E1.m1.3.3.1.2" xref="S4.E1.m1.3.3.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E1.m1.3b"><apply id="S4.E1.m1.3.3.1.1.cmml" xref="S4.E1.m1.3.3.1"><eq id="S4.E1.m1.3.3.1.1.2.cmml" xref="S4.E1.m1.3.3.1.1.2"></eq><apply id="S4.E1.m1.3.3.1.1.3.cmml" xref="S4.E1.m1.3.3.1.1.3"><times id="S4.E1.m1.3.3.1.1.3.1.cmml" xref="S4.E1.m1.3.3.1.1.3.1"></times><ci id="S4.E1.m1.3.3.1.1.3.2.cmml" xref="S4.E1.m1.3.3.1.1.3.2">𝑟</ci><ci id="S4.E1.m1.3.3.1.1.3.3.cmml" xref="S4.E1.m1.3.3.1.1.3.3">𝑒</ci><ci id="S4.E1.m1.3.3.1.1.3.4.cmml" xref="S4.E1.m1.3.3.1.1.3.4">𝑤</ci><ci id="S4.E1.m1.3.3.1.1.3.5.cmml" xref="S4.E1.m1.3.3.1.1.3.5">𝑎</ci><ci id="S4.E1.m1.3.3.1.1.3.6.cmml" xref="S4.E1.m1.3.3.1.1.3.6">𝑟</ci><ci id="S4.E1.m1.3.3.1.1.3.7.cmml" xref="S4.E1.m1.3.3.1.1.3.7">𝑑</ci></apply><apply id="S4.E1.m1.3.3.1.1.1.cmml" xref="S4.E1.m1.3.3.1.1.1"><plus id="S4.E1.m1.3.3.1.1.1.2.cmml" xref="S4.E1.m1.3.3.1.1.1.2"></plus><apply id="S4.E1.m1.3.3.1.1.1.3.cmml" xref="S4.E1.m1.3.3.1.1.1.3"><times id="S4.E1.m1.3.3.1.1.1.3.1.cmml" xref="S4.E1.m1.3.3.1.1.1.3.1"></times><apply id="S4.E1.m1.3.3.1.1.1.3.2.cmml" xref="S4.E1.m1.3.3.1.1.1.3.2"><times id="S4.E1.m1.3.3.1.1.1.3.2.1.cmml" xref="S4.E1.m1.3.3.1.1.1.3.2.1"></times><ci id="S4.E1.m1.3.3.1.1.1.3.2.2.cmml" xref="S4.E1.m1.3.3.1.1.1.3.2.2">𝑓</ci><ci id="S4.E1.m1.3.3.1.1.1.3.2.3.cmml" xref="S4.E1.m1.3.3.1.1.1.3.2.3">𝑈</ci></apply><ci id="S4.E1.m1.3.3.1.1.1.3.3.cmml" xref="S4.E1.m1.3.3.1.1.1.3.3">𝑡</ci><ci id="S4.E1.m1.3.3.1.1.1.3.4.cmml" xref="S4.E1.m1.3.3.1.1.1.3.4">𝑖</ci><ci id="S4.E1.m1.3.3.1.1.1.3.5.cmml" xref="S4.E1.m1.3.3.1.1.1.3.5">𝑙</ci><ci id="S4.E1.m1.1.1.cmml" xref="S4.E1.m1.1.1">𝑖</ci></apply><apply id="S4.E1.m1.3.3.1.1.1.1.cmml" xref="S4.E1.m1.3.3.1.1.1.1"><times id="S4.E1.m1.3.3.1.1.1.1.2.cmml" xref="S4.E1.m1.3.3.1.1.1.1.2"></times><apply id="S4.E1.m1.3.3.1.1.1.1.1.cmml" xref="S4.E1.m1.3.3.1.1.1.1.1"><times id="S4.E1.m1.3.3.1.1.1.1.1.2.cmml" xref="S4.E1.m1.3.3.1.1.1.1.1.2"></times><apply id="S4.E1.m1.3.3.1.1.1.1.1.1.1.1.cmml" xref="S4.E1.m1.3.3.1.1.1.1.1.1.1"><minus id="S4.E1.m1.3.3.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E1.m1.3.3.1.1.1.1.1.1.1.1.1"></minus><cn type="integer" id="S4.E1.m1.3.3.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E1.m1.3.3.1.1.1.1.1.1.1.1.2">1</cn><ci id="S4.E1.m1.3.3.1.1.1.1.1.1.1.1.3.cmml" xref="S4.E1.m1.3.3.1.1.1.1.1.1.1.1.3">𝑓</ci></apply><ci id="S4.E1.m1.3.3.1.1.1.1.1.3.cmml" xref="S4.E1.m1.3.3.1.1.1.1.1.3">𝑝</ci></apply><ci id="S4.E1.m1.3.3.1.1.1.1.3.cmml" xref="S4.E1.m1.3.3.1.1.1.1.3">𝑜</ci><ci id="S4.E1.m1.3.3.1.1.1.1.4.cmml" xref="S4.E1.m1.3.3.1.1.1.1.4">𝑤</ci><ci id="S4.E1.m1.3.3.1.1.1.1.5.cmml" xref="S4.E1.m1.3.3.1.1.1.1.5">𝑒</ci><ci id="S4.E1.m1.3.3.1.1.1.1.6.cmml" xref="S4.E1.m1.3.3.1.1.1.1.6">𝑟</ci><ci id="S4.E1.m1.2.2.cmml" xref="S4.E1.m1.2.2">𝑖</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E1.m1.3c">reward=f\times Util(i)+(1-f)\times power(i),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S4.SS1.p2.2" class="ltx_p">where, <math id="S4.SS1.p2.1.m1.2" class="ltx_Math" alttext="f\in[0,1]" display="inline"><semantics id="S4.SS1.p2.1.m1.2a"><mrow id="S4.SS1.p2.1.m1.2.3" xref="S4.SS1.p2.1.m1.2.3.cmml"><mi id="S4.SS1.p2.1.m1.2.3.2" xref="S4.SS1.p2.1.m1.2.3.2.cmml">f</mi><mo id="S4.SS1.p2.1.m1.2.3.1" xref="S4.SS1.p2.1.m1.2.3.1.cmml">∈</mo><mrow id="S4.SS1.p2.1.m1.2.3.3.2" xref="S4.SS1.p2.1.m1.2.3.3.1.cmml"><mo stretchy="false" id="S4.SS1.p2.1.m1.2.3.3.2.1" xref="S4.SS1.p2.1.m1.2.3.3.1.cmml">[</mo><mn id="S4.SS1.p2.1.m1.1.1" xref="S4.SS1.p2.1.m1.1.1.cmml">0</mn><mo id="S4.SS1.p2.1.m1.2.3.3.2.2" xref="S4.SS1.p2.1.m1.2.3.3.1.cmml">,</mo><mn id="S4.SS1.p2.1.m1.2.2" xref="S4.SS1.p2.1.m1.2.2.cmml">1</mn><mo stretchy="false" id="S4.SS1.p2.1.m1.2.3.3.2.3" xref="S4.SS1.p2.1.m1.2.3.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.2b"><apply id="S4.SS1.p2.1.m1.2.3.cmml" xref="S4.SS1.p2.1.m1.2.3"><in id="S4.SS1.p2.1.m1.2.3.1.cmml" xref="S4.SS1.p2.1.m1.2.3.1"></in><ci id="S4.SS1.p2.1.m1.2.3.2.cmml" xref="S4.SS1.p2.1.m1.2.3.2">𝑓</ci><interval closure="closed" id="S4.SS1.p2.1.m1.2.3.3.1.cmml" xref="S4.SS1.p2.1.m1.2.3.3.2"><cn type="integer" id="S4.SS1.p2.1.m1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1">0</cn><cn type="integer" id="S4.SS1.p2.1.m1.2.2.cmml" xref="S4.SS1.p2.1.m1.2.2">1</cn></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.1.m1.2c">f\in[0,1]</annotation></semantics></math> and <a href="#S4.E1" title="In 4.1. Clients utility definition ‣ 4. Federated Model Training ‣ Towards Energy-Aware Federated Learning on Battery-Powered Clients" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Eq.</span> <span class="ltx_text ltx_ref_tag">1</span></a> will naturally give high-priority to the high-power clients as <math id="S4.SS1.p2.2.m2.1" class="ltx_Math" alttext="f\rightarrow 0" display="inline"><semantics id="S4.SS1.p2.2.m2.1a"><mrow id="S4.SS1.p2.2.m2.1.1" xref="S4.SS1.p2.2.m2.1.1.cmml"><mi id="S4.SS1.p2.2.m2.1.1.2" xref="S4.SS1.p2.2.m2.1.1.2.cmml">f</mi><mo stretchy="false" id="S4.SS1.p2.2.m2.1.1.1" xref="S4.SS1.p2.2.m2.1.1.1.cmml">→</mo><mn id="S4.SS1.p2.2.m2.1.1.3" xref="S4.SS1.p2.2.m2.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.2.m2.1b"><apply id="S4.SS1.p2.2.m2.1.1.cmml" xref="S4.SS1.p2.2.m2.1.1"><ci id="S4.SS1.p2.2.m2.1.1.1.cmml" xref="S4.SS1.p2.2.m2.1.1.1">→</ci><ci id="S4.SS1.p2.2.m2.1.1.2.cmml" xref="S4.SS1.p2.2.m2.1.1.2">𝑓</ci><cn type="integer" id="S4.SS1.p2.2.m2.1.1.3.cmml" xref="S4.SS1.p2.2.m2.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.2.m2.1c">f\rightarrow 0</annotation></semantics></math>. For example, to prioritize the clients with high-battery levels we use:</p>
<table id="S4.Ex1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.Ex1.m1.3" class="ltx_Math" alttext="power(i)=cur\_battery\_level(i)-battery\_used(i)" display="block"><semantics id="S4.Ex1.m1.3a"><mrow id="S4.Ex1.m1.3.4" xref="S4.Ex1.m1.3.4.cmml"><mrow id="S4.Ex1.m1.3.4.2" xref="S4.Ex1.m1.3.4.2.cmml"><mi id="S4.Ex1.m1.3.4.2.2" xref="S4.Ex1.m1.3.4.2.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S4.Ex1.m1.3.4.2.1" xref="S4.Ex1.m1.3.4.2.1.cmml">​</mo><mi id="S4.Ex1.m1.3.4.2.3" xref="S4.Ex1.m1.3.4.2.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.Ex1.m1.3.4.2.1a" xref="S4.Ex1.m1.3.4.2.1.cmml">​</mo><mi id="S4.Ex1.m1.3.4.2.4" xref="S4.Ex1.m1.3.4.2.4.cmml">w</mi><mo lspace="0em" rspace="0em" id="S4.Ex1.m1.3.4.2.1b" xref="S4.Ex1.m1.3.4.2.1.cmml">​</mo><mi id="S4.Ex1.m1.3.4.2.5" xref="S4.Ex1.m1.3.4.2.5.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.Ex1.m1.3.4.2.1c" xref="S4.Ex1.m1.3.4.2.1.cmml">​</mo><mi id="S4.Ex1.m1.3.4.2.6" xref="S4.Ex1.m1.3.4.2.6.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.Ex1.m1.3.4.2.1d" xref="S4.Ex1.m1.3.4.2.1.cmml">​</mo><mrow id="S4.Ex1.m1.3.4.2.7.2" xref="S4.Ex1.m1.3.4.2.cmml"><mo stretchy="false" id="S4.Ex1.m1.3.4.2.7.2.1" xref="S4.Ex1.m1.3.4.2.cmml">(</mo><mi id="S4.Ex1.m1.1.1" xref="S4.Ex1.m1.1.1.cmml">i</mi><mo stretchy="false" id="S4.Ex1.m1.3.4.2.7.2.2" xref="S4.Ex1.m1.3.4.2.cmml">)</mo></mrow></mrow><mo id="S4.Ex1.m1.3.4.1" xref="S4.Ex1.m1.3.4.1.cmml">=</mo><mrow id="S4.Ex1.m1.3.4.3" xref="S4.Ex1.m1.3.4.3.cmml"><mrow id="S4.Ex1.m1.3.4.3.2" xref="S4.Ex1.m1.3.4.3.2.cmml"><mi id="S4.Ex1.m1.3.4.3.2.2" xref="S4.Ex1.m1.3.4.3.2.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.Ex1.m1.3.4.3.2.1" xref="S4.Ex1.m1.3.4.3.2.1.cmml">​</mo><mi id="S4.Ex1.m1.3.4.3.2.3" xref="S4.Ex1.m1.3.4.3.2.3.cmml">u</mi><mo lspace="0em" rspace="0em" id="S4.Ex1.m1.3.4.3.2.1a" xref="S4.Ex1.m1.3.4.3.2.1.cmml">​</mo><mi id="S4.Ex1.m1.3.4.3.2.4" xref="S4.Ex1.m1.3.4.3.2.4.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.Ex1.m1.3.4.3.2.1b" xref="S4.Ex1.m1.3.4.3.2.1.cmml">​</mo><mi mathvariant="normal" id="S4.Ex1.m1.3.4.3.2.5" xref="S4.Ex1.m1.3.4.3.2.5.cmml">_</mi><mo lspace="0em" rspace="0em" id="S4.Ex1.m1.3.4.3.2.1c" xref="S4.Ex1.m1.3.4.3.2.1.cmml">​</mo><mi id="S4.Ex1.m1.3.4.3.2.6" xref="S4.Ex1.m1.3.4.3.2.6.cmml">b</mi><mo lspace="0em" rspace="0em" id="S4.Ex1.m1.3.4.3.2.1d" xref="S4.Ex1.m1.3.4.3.2.1.cmml">​</mo><mi id="S4.Ex1.m1.3.4.3.2.7" xref="S4.Ex1.m1.3.4.3.2.7.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.Ex1.m1.3.4.3.2.1e" xref="S4.Ex1.m1.3.4.3.2.1.cmml">​</mo><mi id="S4.Ex1.m1.3.4.3.2.8" xref="S4.Ex1.m1.3.4.3.2.8.cmml">t</mi><mo lspace="0em" rspace="0em" id="S4.Ex1.m1.3.4.3.2.1f" xref="S4.Ex1.m1.3.4.3.2.1.cmml">​</mo><mi id="S4.Ex1.m1.3.4.3.2.9" xref="S4.Ex1.m1.3.4.3.2.9.cmml">t</mi><mo lspace="0em" rspace="0em" id="S4.Ex1.m1.3.4.3.2.1g" xref="S4.Ex1.m1.3.4.3.2.1.cmml">​</mo><mi id="S4.Ex1.m1.3.4.3.2.10" xref="S4.Ex1.m1.3.4.3.2.10.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.Ex1.m1.3.4.3.2.1h" xref="S4.Ex1.m1.3.4.3.2.1.cmml">​</mo><mi id="S4.Ex1.m1.3.4.3.2.11" xref="S4.Ex1.m1.3.4.3.2.11.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.Ex1.m1.3.4.3.2.1i" xref="S4.Ex1.m1.3.4.3.2.1.cmml">​</mo><mi id="S4.Ex1.m1.3.4.3.2.12" xref="S4.Ex1.m1.3.4.3.2.12.cmml">y</mi><mo lspace="0em" rspace="0em" id="S4.Ex1.m1.3.4.3.2.1j" xref="S4.Ex1.m1.3.4.3.2.1.cmml">​</mo><mi mathvariant="normal" id="S4.Ex1.m1.3.4.3.2.13" xref="S4.Ex1.m1.3.4.3.2.13.cmml">_</mi><mo lspace="0em" rspace="0em" id="S4.Ex1.m1.3.4.3.2.1k" xref="S4.Ex1.m1.3.4.3.2.1.cmml">​</mo><mi id="S4.Ex1.m1.3.4.3.2.14" xref="S4.Ex1.m1.3.4.3.2.14.cmml">l</mi><mo lspace="0em" rspace="0em" id="S4.Ex1.m1.3.4.3.2.1l" xref="S4.Ex1.m1.3.4.3.2.1.cmml">​</mo><mi id="S4.Ex1.m1.3.4.3.2.15" xref="S4.Ex1.m1.3.4.3.2.15.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.Ex1.m1.3.4.3.2.1m" xref="S4.Ex1.m1.3.4.3.2.1.cmml">​</mo><mi id="S4.Ex1.m1.3.4.3.2.16" xref="S4.Ex1.m1.3.4.3.2.16.cmml">v</mi><mo lspace="0em" rspace="0em" id="S4.Ex1.m1.3.4.3.2.1n" xref="S4.Ex1.m1.3.4.3.2.1.cmml">​</mo><mi id="S4.Ex1.m1.3.4.3.2.17" xref="S4.Ex1.m1.3.4.3.2.17.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.Ex1.m1.3.4.3.2.1o" xref="S4.Ex1.m1.3.4.3.2.1.cmml">​</mo><mi id="S4.Ex1.m1.3.4.3.2.18" xref="S4.Ex1.m1.3.4.3.2.18.cmml">l</mi><mo lspace="0em" rspace="0em" id="S4.Ex1.m1.3.4.3.2.1p" xref="S4.Ex1.m1.3.4.3.2.1.cmml">​</mo><mrow id="S4.Ex1.m1.3.4.3.2.19.2" xref="S4.Ex1.m1.3.4.3.2.cmml"><mo stretchy="false" id="S4.Ex1.m1.3.4.3.2.19.2.1" xref="S4.Ex1.m1.3.4.3.2.cmml">(</mo><mi id="S4.Ex1.m1.2.2" xref="S4.Ex1.m1.2.2.cmml">i</mi><mo stretchy="false" id="S4.Ex1.m1.3.4.3.2.19.2.2" xref="S4.Ex1.m1.3.4.3.2.cmml">)</mo></mrow></mrow><mo id="S4.Ex1.m1.3.4.3.1" xref="S4.Ex1.m1.3.4.3.1.cmml">−</mo><mrow id="S4.Ex1.m1.3.4.3.3" xref="S4.Ex1.m1.3.4.3.3.cmml"><mi id="S4.Ex1.m1.3.4.3.3.2" xref="S4.Ex1.m1.3.4.3.3.2.cmml">b</mi><mo lspace="0em" rspace="0em" id="S4.Ex1.m1.3.4.3.3.1" xref="S4.Ex1.m1.3.4.3.3.1.cmml">​</mo><mi id="S4.Ex1.m1.3.4.3.3.3" xref="S4.Ex1.m1.3.4.3.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.Ex1.m1.3.4.3.3.1a" xref="S4.Ex1.m1.3.4.3.3.1.cmml">​</mo><mi id="S4.Ex1.m1.3.4.3.3.4" xref="S4.Ex1.m1.3.4.3.3.4.cmml">t</mi><mo lspace="0em" rspace="0em" id="S4.Ex1.m1.3.4.3.3.1b" xref="S4.Ex1.m1.3.4.3.3.1.cmml">​</mo><mi id="S4.Ex1.m1.3.4.3.3.5" xref="S4.Ex1.m1.3.4.3.3.5.cmml">t</mi><mo lspace="0em" rspace="0em" id="S4.Ex1.m1.3.4.3.3.1c" xref="S4.Ex1.m1.3.4.3.3.1.cmml">​</mo><mi id="S4.Ex1.m1.3.4.3.3.6" xref="S4.Ex1.m1.3.4.3.3.6.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.Ex1.m1.3.4.3.3.1d" xref="S4.Ex1.m1.3.4.3.3.1.cmml">​</mo><mi id="S4.Ex1.m1.3.4.3.3.7" xref="S4.Ex1.m1.3.4.3.3.7.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.Ex1.m1.3.4.3.3.1e" xref="S4.Ex1.m1.3.4.3.3.1.cmml">​</mo><mi id="S4.Ex1.m1.3.4.3.3.8" xref="S4.Ex1.m1.3.4.3.3.8.cmml">y</mi><mo lspace="0em" rspace="0em" id="S4.Ex1.m1.3.4.3.3.1f" xref="S4.Ex1.m1.3.4.3.3.1.cmml">​</mo><mi mathvariant="normal" id="S4.Ex1.m1.3.4.3.3.9" xref="S4.Ex1.m1.3.4.3.3.9.cmml">_</mi><mo lspace="0em" rspace="0em" id="S4.Ex1.m1.3.4.3.3.1g" xref="S4.Ex1.m1.3.4.3.3.1.cmml">​</mo><mi id="S4.Ex1.m1.3.4.3.3.10" xref="S4.Ex1.m1.3.4.3.3.10.cmml">u</mi><mo lspace="0em" rspace="0em" id="S4.Ex1.m1.3.4.3.3.1h" xref="S4.Ex1.m1.3.4.3.3.1.cmml">​</mo><mi id="S4.Ex1.m1.3.4.3.3.11" xref="S4.Ex1.m1.3.4.3.3.11.cmml">s</mi><mo lspace="0em" rspace="0em" id="S4.Ex1.m1.3.4.3.3.1i" xref="S4.Ex1.m1.3.4.3.3.1.cmml">​</mo><mi id="S4.Ex1.m1.3.4.3.3.12" xref="S4.Ex1.m1.3.4.3.3.12.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.Ex1.m1.3.4.3.3.1j" xref="S4.Ex1.m1.3.4.3.3.1.cmml">​</mo><mi id="S4.Ex1.m1.3.4.3.3.13" xref="S4.Ex1.m1.3.4.3.3.13.cmml">d</mi><mo lspace="0em" rspace="0em" id="S4.Ex1.m1.3.4.3.3.1k" xref="S4.Ex1.m1.3.4.3.3.1.cmml">​</mo><mrow id="S4.Ex1.m1.3.4.3.3.14.2" xref="S4.Ex1.m1.3.4.3.3.cmml"><mo stretchy="false" id="S4.Ex1.m1.3.4.3.3.14.2.1" xref="S4.Ex1.m1.3.4.3.3.cmml">(</mo><mi id="S4.Ex1.m1.3.3" xref="S4.Ex1.m1.3.3.cmml">i</mi><mo stretchy="false" id="S4.Ex1.m1.3.4.3.3.14.2.2" xref="S4.Ex1.m1.3.4.3.3.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.Ex1.m1.3b"><apply id="S4.Ex1.m1.3.4.cmml" xref="S4.Ex1.m1.3.4"><eq id="S4.Ex1.m1.3.4.1.cmml" xref="S4.Ex1.m1.3.4.1"></eq><apply id="S4.Ex1.m1.3.4.2.cmml" xref="S4.Ex1.m1.3.4.2"><times id="S4.Ex1.m1.3.4.2.1.cmml" xref="S4.Ex1.m1.3.4.2.1"></times><ci id="S4.Ex1.m1.3.4.2.2.cmml" xref="S4.Ex1.m1.3.4.2.2">𝑝</ci><ci id="S4.Ex1.m1.3.4.2.3.cmml" xref="S4.Ex1.m1.3.4.2.3">𝑜</ci><ci id="S4.Ex1.m1.3.4.2.4.cmml" xref="S4.Ex1.m1.3.4.2.4">𝑤</ci><ci id="S4.Ex1.m1.3.4.2.5.cmml" xref="S4.Ex1.m1.3.4.2.5">𝑒</ci><ci id="S4.Ex1.m1.3.4.2.6.cmml" xref="S4.Ex1.m1.3.4.2.6">𝑟</ci><ci id="S4.Ex1.m1.1.1.cmml" xref="S4.Ex1.m1.1.1">𝑖</ci></apply><apply id="S4.Ex1.m1.3.4.3.cmml" xref="S4.Ex1.m1.3.4.3"><minus id="S4.Ex1.m1.3.4.3.1.cmml" xref="S4.Ex1.m1.3.4.3.1"></minus><apply id="S4.Ex1.m1.3.4.3.2.cmml" xref="S4.Ex1.m1.3.4.3.2"><times id="S4.Ex1.m1.3.4.3.2.1.cmml" xref="S4.Ex1.m1.3.4.3.2.1"></times><ci id="S4.Ex1.m1.3.4.3.2.2.cmml" xref="S4.Ex1.m1.3.4.3.2.2">𝑐</ci><ci id="S4.Ex1.m1.3.4.3.2.3.cmml" xref="S4.Ex1.m1.3.4.3.2.3">𝑢</ci><ci id="S4.Ex1.m1.3.4.3.2.4.cmml" xref="S4.Ex1.m1.3.4.3.2.4">𝑟</ci><ci id="S4.Ex1.m1.3.4.3.2.5.cmml" xref="S4.Ex1.m1.3.4.3.2.5">_</ci><ci id="S4.Ex1.m1.3.4.3.2.6.cmml" xref="S4.Ex1.m1.3.4.3.2.6">𝑏</ci><ci id="S4.Ex1.m1.3.4.3.2.7.cmml" xref="S4.Ex1.m1.3.4.3.2.7">𝑎</ci><ci id="S4.Ex1.m1.3.4.3.2.8.cmml" xref="S4.Ex1.m1.3.4.3.2.8">𝑡</ci><ci id="S4.Ex1.m1.3.4.3.2.9.cmml" xref="S4.Ex1.m1.3.4.3.2.9">𝑡</ci><ci id="S4.Ex1.m1.3.4.3.2.10.cmml" xref="S4.Ex1.m1.3.4.3.2.10">𝑒</ci><ci id="S4.Ex1.m1.3.4.3.2.11.cmml" xref="S4.Ex1.m1.3.4.3.2.11">𝑟</ci><ci id="S4.Ex1.m1.3.4.3.2.12.cmml" xref="S4.Ex1.m1.3.4.3.2.12">𝑦</ci><ci id="S4.Ex1.m1.3.4.3.2.13.cmml" xref="S4.Ex1.m1.3.4.3.2.13">_</ci><ci id="S4.Ex1.m1.3.4.3.2.14.cmml" xref="S4.Ex1.m1.3.4.3.2.14">𝑙</ci><ci id="S4.Ex1.m1.3.4.3.2.15.cmml" xref="S4.Ex1.m1.3.4.3.2.15">𝑒</ci><ci id="S4.Ex1.m1.3.4.3.2.16.cmml" xref="S4.Ex1.m1.3.4.3.2.16">𝑣</ci><ci id="S4.Ex1.m1.3.4.3.2.17.cmml" xref="S4.Ex1.m1.3.4.3.2.17">𝑒</ci><ci id="S4.Ex1.m1.3.4.3.2.18.cmml" xref="S4.Ex1.m1.3.4.3.2.18">𝑙</ci><ci id="S4.Ex1.m1.2.2.cmml" xref="S4.Ex1.m1.2.2">𝑖</ci></apply><apply id="S4.Ex1.m1.3.4.3.3.cmml" xref="S4.Ex1.m1.3.4.3.3"><times id="S4.Ex1.m1.3.4.3.3.1.cmml" xref="S4.Ex1.m1.3.4.3.3.1"></times><ci id="S4.Ex1.m1.3.4.3.3.2.cmml" xref="S4.Ex1.m1.3.4.3.3.2">𝑏</ci><ci id="S4.Ex1.m1.3.4.3.3.3.cmml" xref="S4.Ex1.m1.3.4.3.3.3">𝑎</ci><ci id="S4.Ex1.m1.3.4.3.3.4.cmml" xref="S4.Ex1.m1.3.4.3.3.4">𝑡</ci><ci id="S4.Ex1.m1.3.4.3.3.5.cmml" xref="S4.Ex1.m1.3.4.3.3.5">𝑡</ci><ci id="S4.Ex1.m1.3.4.3.3.6.cmml" xref="S4.Ex1.m1.3.4.3.3.6">𝑒</ci><ci id="S4.Ex1.m1.3.4.3.3.7.cmml" xref="S4.Ex1.m1.3.4.3.3.7">𝑟</ci><ci id="S4.Ex1.m1.3.4.3.3.8.cmml" xref="S4.Ex1.m1.3.4.3.3.8">𝑦</ci><ci id="S4.Ex1.m1.3.4.3.3.9.cmml" xref="S4.Ex1.m1.3.4.3.3.9">_</ci><ci id="S4.Ex1.m1.3.4.3.3.10.cmml" xref="S4.Ex1.m1.3.4.3.3.10">𝑢</ci><ci id="S4.Ex1.m1.3.4.3.3.11.cmml" xref="S4.Ex1.m1.3.4.3.3.11">𝑠</ci><ci id="S4.Ex1.m1.3.4.3.3.12.cmml" xref="S4.Ex1.m1.3.4.3.3.12">𝑒</ci><ci id="S4.Ex1.m1.3.4.3.3.13.cmml" xref="S4.Ex1.m1.3.4.3.3.13">𝑑</ci><ci id="S4.Ex1.m1.3.3.cmml" xref="S4.Ex1.m1.3.3">𝑖</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.Ex1.m1.3c">power(i)=cur\_battery\_level(i)-battery\_used(i)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div id="S4.SS1.p3" class="ltx_para ltx_noindent">
<p id="S4.SS1.p3.1" class="ltx_p"><span id="S4.SS1.p3.1.1" class="ltx_text ltx_font_bold">Trade-off between system and statistical efficiency: </span>  the first part of the reward function of <a href="#S4.E1" title="In 4.1. Clients utility definition ‣ 4. Federated Model Training ‣ Towards Energy-Aware Federated Learning on Battery-Powered Clients" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Eq.</span> <span class="ltx_text ltx_ref_tag">1</span></a> influences the time-to-accuracy metric of the FL process. It relies on two factors: (i) <span id="S4.SS1.p3.1.2" class="ltx_text ltx_font_bold">system efficiency</span>: completion time of each training round, and (ii) <span id="S4.SS1.p3.1.3" class="ltx_text ltx_font_bold">statistical efficiency</span>: the number of rounds completed to reach the desired accuracy. Both forms of efficiencies are considered jointly for better time-to-accuracy performance. Oort <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:80%;">Lai
et al</span><span class="ltx_text" style="font-size:80%;">.</span>, <a href="#bib.bib28" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2021</span></a>)</cite> finds a sweet spot in the trade-off by attaching a utility with every client that optimizes each form of efficiency. In Oort, a high statistical utility may lead to longer rounds especially if the client becomes a bottleneck for the aggregation round; moreover, on the other hand, a high system utility may reduce each round’s duration and can lead to more rounds as the fastest clients are exclusively picked who become over-represented. The utility of each client <math id="S4.SS1.p3.1.m1.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S4.SS1.p3.1.m1.1a"><mi id="S4.SS1.p3.1.m1.1.1" xref="S4.SS1.p3.1.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.1.m1.1b"><ci id="S4.SS1.p3.1.m1.1.1.cmml" xref="S4.SS1.p3.1.m1.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.1.m1.1c">i</annotation></semantics></math> is formulated by a utility calculated after each training round and is given by <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:80%;">Lai
et al</span><span class="ltx_text" style="font-size:80%;">.</span>, <a href="#bib.bib28" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2021</span></a>)</cite>:</p>
</div>
<div id="S4.SS1.p4" class="ltx_para">
<table id="S4.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(2)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E2.m1.6" class="ltx_Math" alttext="Util(i)=|B_{i}|\sqrt{\frac{1}{|B_{i}|}\sum_{kEB_{i}}Loss(k^{2})}\times(\frac{T}{t_{i}})^{1(T&lt;t_{i})\times a}" display="block"><semantics id="S4.E2.m1.6a"><mrow id="S4.E2.m1.6.6" xref="S4.E2.m1.6.6.cmml"><mrow id="S4.E2.m1.6.6.3" xref="S4.E2.m1.6.6.3.cmml"><mi id="S4.E2.m1.6.6.3.2" xref="S4.E2.m1.6.6.3.2.cmml">U</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.6.6.3.1" xref="S4.E2.m1.6.6.3.1.cmml">​</mo><mi id="S4.E2.m1.6.6.3.3" xref="S4.E2.m1.6.6.3.3.cmml">t</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.6.6.3.1a" xref="S4.E2.m1.6.6.3.1.cmml">​</mo><mi id="S4.E2.m1.6.6.3.4" xref="S4.E2.m1.6.6.3.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.6.6.3.1b" xref="S4.E2.m1.6.6.3.1.cmml">​</mo><mi id="S4.E2.m1.6.6.3.5" xref="S4.E2.m1.6.6.3.5.cmml">l</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.6.6.3.1c" xref="S4.E2.m1.6.6.3.1.cmml">​</mo><mrow id="S4.E2.m1.6.6.3.6.2" xref="S4.E2.m1.6.6.3.cmml"><mo stretchy="false" id="S4.E2.m1.6.6.3.6.2.1" xref="S4.E2.m1.6.6.3.cmml">(</mo><mi id="S4.E2.m1.4.4" xref="S4.E2.m1.4.4.cmml">i</mi><mo stretchy="false" id="S4.E2.m1.6.6.3.6.2.2" xref="S4.E2.m1.6.6.3.cmml">)</mo></mrow></mrow><mo id="S4.E2.m1.6.6.2" xref="S4.E2.m1.6.6.2.cmml">=</mo><mrow id="S4.E2.m1.6.6.1" xref="S4.E2.m1.6.6.1.cmml"><mrow id="S4.E2.m1.6.6.1.1" xref="S4.E2.m1.6.6.1.1.cmml"><mrow id="S4.E2.m1.6.6.1.1.1.1" xref="S4.E2.m1.6.6.1.1.1.2.cmml"><mo stretchy="false" id="S4.E2.m1.6.6.1.1.1.1.2" xref="S4.E2.m1.6.6.1.1.1.2.1.cmml">|</mo><msub id="S4.E2.m1.6.6.1.1.1.1.1" xref="S4.E2.m1.6.6.1.1.1.1.1.cmml"><mi id="S4.E2.m1.6.6.1.1.1.1.1.2" xref="S4.E2.m1.6.6.1.1.1.1.1.2.cmml">B</mi><mi id="S4.E2.m1.6.6.1.1.1.1.1.3" xref="S4.E2.m1.6.6.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S4.E2.m1.6.6.1.1.1.1.3" xref="S4.E2.m1.6.6.1.1.1.2.1.cmml">|</mo></mrow><mo lspace="0em" rspace="0em" id="S4.E2.m1.6.6.1.1.2" xref="S4.E2.m1.6.6.1.1.2.cmml">​</mo><msqrt id="S4.E2.m1.2.2" xref="S4.E2.m1.2.2.cmml"><mrow id="S4.E2.m1.2.2.2" xref="S4.E2.m1.2.2.2.cmml"><mfrac id="S4.E2.m1.1.1.1.1" xref="S4.E2.m1.1.1.1.1.cmml"><mn id="S4.E2.m1.1.1.1.1.3" xref="S4.E2.m1.1.1.1.1.3.cmml">1</mn><mrow id="S4.E2.m1.1.1.1.1.1.1" xref="S4.E2.m1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S4.E2.m1.1.1.1.1.1.1.2" xref="S4.E2.m1.1.1.1.1.1.2.1.cmml">|</mo><msub id="S4.E2.m1.1.1.1.1.1.1.1" xref="S4.E2.m1.1.1.1.1.1.1.1.cmml"><mi id="S4.E2.m1.1.1.1.1.1.1.1.2" xref="S4.E2.m1.1.1.1.1.1.1.1.2.cmml">B</mi><mi id="S4.E2.m1.1.1.1.1.1.1.1.3" xref="S4.E2.m1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S4.E2.m1.1.1.1.1.1.1.3" xref="S4.E2.m1.1.1.1.1.1.2.1.cmml">|</mo></mrow></mfrac><mo lspace="0em" rspace="0em" id="S4.E2.m1.2.2.2.3" xref="S4.E2.m1.2.2.2.3.cmml">​</mo><mrow id="S4.E2.m1.2.2.2.2" xref="S4.E2.m1.2.2.2.2.cmml"><munder id="S4.E2.m1.2.2.2.2.2" xref="S4.E2.m1.2.2.2.2.2.cmml"><mo movablelimits="false" id="S4.E2.m1.2.2.2.2.2.2" xref="S4.E2.m1.2.2.2.2.2.2.cmml">∑</mo><mrow id="S4.E2.m1.2.2.2.2.2.3" xref="S4.E2.m1.2.2.2.2.2.3.cmml"><mi id="S4.E2.m1.2.2.2.2.2.3.2" xref="S4.E2.m1.2.2.2.2.2.3.2.cmml">k</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.2.2.2.2.2.3.1" xref="S4.E2.m1.2.2.2.2.2.3.1.cmml">​</mo><mi id="S4.E2.m1.2.2.2.2.2.3.3" xref="S4.E2.m1.2.2.2.2.2.3.3.cmml">E</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.2.2.2.2.2.3.1a" xref="S4.E2.m1.2.2.2.2.2.3.1.cmml">​</mo><msub id="S4.E2.m1.2.2.2.2.2.3.4" xref="S4.E2.m1.2.2.2.2.2.3.4.cmml"><mi id="S4.E2.m1.2.2.2.2.2.3.4.2" xref="S4.E2.m1.2.2.2.2.2.3.4.2.cmml">B</mi><mi id="S4.E2.m1.2.2.2.2.2.3.4.3" xref="S4.E2.m1.2.2.2.2.2.3.4.3.cmml">i</mi></msub></mrow></munder><mrow id="S4.E2.m1.2.2.2.2.1" xref="S4.E2.m1.2.2.2.2.1.cmml"><mi id="S4.E2.m1.2.2.2.2.1.3" xref="S4.E2.m1.2.2.2.2.1.3.cmml">L</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.2.2.2.2.1.2" xref="S4.E2.m1.2.2.2.2.1.2.cmml">​</mo><mi id="S4.E2.m1.2.2.2.2.1.4" xref="S4.E2.m1.2.2.2.2.1.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.2.2.2.2.1.2a" xref="S4.E2.m1.2.2.2.2.1.2.cmml">​</mo><mi id="S4.E2.m1.2.2.2.2.1.5" xref="S4.E2.m1.2.2.2.2.1.5.cmml">s</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.2.2.2.2.1.2b" xref="S4.E2.m1.2.2.2.2.1.2.cmml">​</mo><mi id="S4.E2.m1.2.2.2.2.1.6" xref="S4.E2.m1.2.2.2.2.1.6.cmml">s</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.2.2.2.2.1.2c" xref="S4.E2.m1.2.2.2.2.1.2.cmml">​</mo><mrow id="S4.E2.m1.2.2.2.2.1.1.1" xref="S4.E2.m1.2.2.2.2.1.1.1.1.cmml"><mo stretchy="false" id="S4.E2.m1.2.2.2.2.1.1.1.2" xref="S4.E2.m1.2.2.2.2.1.1.1.1.cmml">(</mo><msup id="S4.E2.m1.2.2.2.2.1.1.1.1" xref="S4.E2.m1.2.2.2.2.1.1.1.1.cmml"><mi id="S4.E2.m1.2.2.2.2.1.1.1.1.2" xref="S4.E2.m1.2.2.2.2.1.1.1.1.2.cmml">k</mi><mn id="S4.E2.m1.2.2.2.2.1.1.1.1.3" xref="S4.E2.m1.2.2.2.2.1.1.1.1.3.cmml">2</mn></msup><mo stretchy="false" id="S4.E2.m1.2.2.2.2.1.1.1.3" xref="S4.E2.m1.2.2.2.2.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow></msqrt></mrow><mo lspace="0.222em" rspace="0.222em" id="S4.E2.m1.6.6.1.2" xref="S4.E2.m1.6.6.1.2.cmml">×</mo><msup id="S4.E2.m1.6.6.1.3" xref="S4.E2.m1.6.6.1.3.cmml"><mrow id="S4.E2.m1.6.6.1.3.2.2" xref="S4.E2.m1.5.5.cmml"><mo stretchy="false" id="S4.E2.m1.6.6.1.3.2.2.1" xref="S4.E2.m1.5.5.cmml">(</mo><mfrac id="S4.E2.m1.5.5" xref="S4.E2.m1.5.5.cmml"><mi id="S4.E2.m1.5.5.2" xref="S4.E2.m1.5.5.2.cmml">T</mi><msub id="S4.E2.m1.5.5.3" xref="S4.E2.m1.5.5.3.cmml"><mi id="S4.E2.m1.5.5.3.2" xref="S4.E2.m1.5.5.3.2.cmml">t</mi><mi id="S4.E2.m1.5.5.3.3" xref="S4.E2.m1.5.5.3.3.cmml">i</mi></msub></mfrac><mo stretchy="false" id="S4.E2.m1.6.6.1.3.2.2.2" xref="S4.E2.m1.5.5.cmml">)</mo></mrow><mrow id="S4.E2.m1.3.3.1" xref="S4.E2.m1.3.3.1.cmml"><mrow id="S4.E2.m1.3.3.1.1" xref="S4.E2.m1.3.3.1.1.cmml"><mn id="S4.E2.m1.3.3.1.1.3" xref="S4.E2.m1.3.3.1.1.3.cmml">1</mn><mo lspace="0em" rspace="0em" id="S4.E2.m1.3.3.1.1.2" xref="S4.E2.m1.3.3.1.1.2.cmml">​</mo><mrow id="S4.E2.m1.3.3.1.1.1.1" xref="S4.E2.m1.3.3.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.E2.m1.3.3.1.1.1.1.2" xref="S4.E2.m1.3.3.1.1.1.1.1.cmml">(</mo><mrow id="S4.E2.m1.3.3.1.1.1.1.1" xref="S4.E2.m1.3.3.1.1.1.1.1.cmml"><mi id="S4.E2.m1.3.3.1.1.1.1.1.2" xref="S4.E2.m1.3.3.1.1.1.1.1.2.cmml">T</mi><mo id="S4.E2.m1.3.3.1.1.1.1.1.1" xref="S4.E2.m1.3.3.1.1.1.1.1.1.cmml">&lt;</mo><msub id="S4.E2.m1.3.3.1.1.1.1.1.3" xref="S4.E2.m1.3.3.1.1.1.1.1.3.cmml"><mi id="S4.E2.m1.3.3.1.1.1.1.1.3.2" xref="S4.E2.m1.3.3.1.1.1.1.1.3.2.cmml">t</mi><mi id="S4.E2.m1.3.3.1.1.1.1.1.3.3" xref="S4.E2.m1.3.3.1.1.1.1.1.3.3.cmml">i</mi></msub></mrow><mo rspace="0.055em" stretchy="false" id="S4.E2.m1.3.3.1.1.1.1.3" xref="S4.E2.m1.3.3.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo rspace="0.222em" id="S4.E2.m1.3.3.1.2" xref="S4.E2.m1.3.3.1.2.cmml">×</mo><mi id="S4.E2.m1.3.3.1.3" xref="S4.E2.m1.3.3.1.3.cmml">a</mi></mrow></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E2.m1.6b"><apply id="S4.E2.m1.6.6.cmml" xref="S4.E2.m1.6.6"><eq id="S4.E2.m1.6.6.2.cmml" xref="S4.E2.m1.6.6.2"></eq><apply id="S4.E2.m1.6.6.3.cmml" xref="S4.E2.m1.6.6.3"><times id="S4.E2.m1.6.6.3.1.cmml" xref="S4.E2.m1.6.6.3.1"></times><ci id="S4.E2.m1.6.6.3.2.cmml" xref="S4.E2.m1.6.6.3.2">𝑈</ci><ci id="S4.E2.m1.6.6.3.3.cmml" xref="S4.E2.m1.6.6.3.3">𝑡</ci><ci id="S4.E2.m1.6.6.3.4.cmml" xref="S4.E2.m1.6.6.3.4">𝑖</ci><ci id="S4.E2.m1.6.6.3.5.cmml" xref="S4.E2.m1.6.6.3.5">𝑙</ci><ci id="S4.E2.m1.4.4.cmml" xref="S4.E2.m1.4.4">𝑖</ci></apply><apply id="S4.E2.m1.6.6.1.cmml" xref="S4.E2.m1.6.6.1"><times id="S4.E2.m1.6.6.1.2.cmml" xref="S4.E2.m1.6.6.1.2"></times><apply id="S4.E2.m1.6.6.1.1.cmml" xref="S4.E2.m1.6.6.1.1"><times id="S4.E2.m1.6.6.1.1.2.cmml" xref="S4.E2.m1.6.6.1.1.2"></times><apply id="S4.E2.m1.6.6.1.1.1.2.cmml" xref="S4.E2.m1.6.6.1.1.1.1"><abs id="S4.E2.m1.6.6.1.1.1.2.1.cmml" xref="S4.E2.m1.6.6.1.1.1.1.2"></abs><apply id="S4.E2.m1.6.6.1.1.1.1.1.cmml" xref="S4.E2.m1.6.6.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E2.m1.6.6.1.1.1.1.1.1.cmml" xref="S4.E2.m1.6.6.1.1.1.1.1">subscript</csymbol><ci id="S4.E2.m1.6.6.1.1.1.1.1.2.cmml" xref="S4.E2.m1.6.6.1.1.1.1.1.2">𝐵</ci><ci id="S4.E2.m1.6.6.1.1.1.1.1.3.cmml" xref="S4.E2.m1.6.6.1.1.1.1.1.3">𝑖</ci></apply></apply><apply id="S4.E2.m1.2.2.cmml" xref="S4.E2.m1.2.2"><root id="S4.E2.m1.2.2a.cmml" xref="S4.E2.m1.2.2"></root><apply id="S4.E2.m1.2.2.2.cmml" xref="S4.E2.m1.2.2.2"><times id="S4.E2.m1.2.2.2.3.cmml" xref="S4.E2.m1.2.2.2.3"></times><apply id="S4.E2.m1.1.1.1.1.cmml" xref="S4.E2.m1.1.1.1.1"><divide id="S4.E2.m1.1.1.1.1.2.cmml" xref="S4.E2.m1.1.1.1.1"></divide><cn type="integer" id="S4.E2.m1.1.1.1.1.3.cmml" xref="S4.E2.m1.1.1.1.1.3">1</cn><apply id="S4.E2.m1.1.1.1.1.1.2.cmml" xref="S4.E2.m1.1.1.1.1.1.1"><abs id="S4.E2.m1.1.1.1.1.1.2.1.cmml" xref="S4.E2.m1.1.1.1.1.1.1.2"></abs><apply id="S4.E2.m1.1.1.1.1.1.1.1.cmml" xref="S4.E2.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E2.m1.1.1.1.1.1.1.1.1.cmml" xref="S4.E2.m1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S4.E2.m1.1.1.1.1.1.1.1.2.cmml" xref="S4.E2.m1.1.1.1.1.1.1.1.2">𝐵</ci><ci id="S4.E2.m1.1.1.1.1.1.1.1.3.cmml" xref="S4.E2.m1.1.1.1.1.1.1.1.3">𝑖</ci></apply></apply></apply><apply id="S4.E2.m1.2.2.2.2.cmml" xref="S4.E2.m1.2.2.2.2"><apply id="S4.E2.m1.2.2.2.2.2.cmml" xref="S4.E2.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="S4.E2.m1.2.2.2.2.2.1.cmml" xref="S4.E2.m1.2.2.2.2.2">subscript</csymbol><sum id="S4.E2.m1.2.2.2.2.2.2.cmml" xref="S4.E2.m1.2.2.2.2.2.2"></sum><apply id="S4.E2.m1.2.2.2.2.2.3.cmml" xref="S4.E2.m1.2.2.2.2.2.3"><times id="S4.E2.m1.2.2.2.2.2.3.1.cmml" xref="S4.E2.m1.2.2.2.2.2.3.1"></times><ci id="S4.E2.m1.2.2.2.2.2.3.2.cmml" xref="S4.E2.m1.2.2.2.2.2.3.2">𝑘</ci><ci id="S4.E2.m1.2.2.2.2.2.3.3.cmml" xref="S4.E2.m1.2.2.2.2.2.3.3">𝐸</ci><apply id="S4.E2.m1.2.2.2.2.2.3.4.cmml" xref="S4.E2.m1.2.2.2.2.2.3.4"><csymbol cd="ambiguous" id="S4.E2.m1.2.2.2.2.2.3.4.1.cmml" xref="S4.E2.m1.2.2.2.2.2.3.4">subscript</csymbol><ci id="S4.E2.m1.2.2.2.2.2.3.4.2.cmml" xref="S4.E2.m1.2.2.2.2.2.3.4.2">𝐵</ci><ci id="S4.E2.m1.2.2.2.2.2.3.4.3.cmml" xref="S4.E2.m1.2.2.2.2.2.3.4.3">𝑖</ci></apply></apply></apply><apply id="S4.E2.m1.2.2.2.2.1.cmml" xref="S4.E2.m1.2.2.2.2.1"><times id="S4.E2.m1.2.2.2.2.1.2.cmml" xref="S4.E2.m1.2.2.2.2.1.2"></times><ci id="S4.E2.m1.2.2.2.2.1.3.cmml" xref="S4.E2.m1.2.2.2.2.1.3">𝐿</ci><ci id="S4.E2.m1.2.2.2.2.1.4.cmml" xref="S4.E2.m1.2.2.2.2.1.4">𝑜</ci><ci id="S4.E2.m1.2.2.2.2.1.5.cmml" xref="S4.E2.m1.2.2.2.2.1.5">𝑠</ci><ci id="S4.E2.m1.2.2.2.2.1.6.cmml" xref="S4.E2.m1.2.2.2.2.1.6">𝑠</ci><apply id="S4.E2.m1.2.2.2.2.1.1.1.1.cmml" xref="S4.E2.m1.2.2.2.2.1.1.1"><csymbol cd="ambiguous" id="S4.E2.m1.2.2.2.2.1.1.1.1.1.cmml" xref="S4.E2.m1.2.2.2.2.1.1.1">superscript</csymbol><ci id="S4.E2.m1.2.2.2.2.1.1.1.1.2.cmml" xref="S4.E2.m1.2.2.2.2.1.1.1.1.2">𝑘</ci><cn type="integer" id="S4.E2.m1.2.2.2.2.1.1.1.1.3.cmml" xref="S4.E2.m1.2.2.2.2.1.1.1.1.3">2</cn></apply></apply></apply></apply></apply></apply><apply id="S4.E2.m1.6.6.1.3.cmml" xref="S4.E2.m1.6.6.1.3"><csymbol cd="ambiguous" id="S4.E2.m1.6.6.1.3.1.cmml" xref="S4.E2.m1.6.6.1.3">superscript</csymbol><apply id="S4.E2.m1.5.5.cmml" xref="S4.E2.m1.6.6.1.3.2.2"><divide id="S4.E2.m1.5.5.1.cmml" xref="S4.E2.m1.6.6.1.3.2.2"></divide><ci id="S4.E2.m1.5.5.2.cmml" xref="S4.E2.m1.5.5.2">𝑇</ci><apply id="S4.E2.m1.5.5.3.cmml" xref="S4.E2.m1.5.5.3"><csymbol cd="ambiguous" id="S4.E2.m1.5.5.3.1.cmml" xref="S4.E2.m1.5.5.3">subscript</csymbol><ci id="S4.E2.m1.5.5.3.2.cmml" xref="S4.E2.m1.5.5.3.2">𝑡</ci><ci id="S4.E2.m1.5.5.3.3.cmml" xref="S4.E2.m1.5.5.3.3">𝑖</ci></apply></apply><apply id="S4.E2.m1.3.3.1.cmml" xref="S4.E2.m1.3.3.1"><times id="S4.E2.m1.3.3.1.2.cmml" xref="S4.E2.m1.3.3.1.2"></times><apply id="S4.E2.m1.3.3.1.1.cmml" xref="S4.E2.m1.3.3.1.1"><times id="S4.E2.m1.3.3.1.1.2.cmml" xref="S4.E2.m1.3.3.1.1.2"></times><cn type="integer" id="S4.E2.m1.3.3.1.1.3.cmml" xref="S4.E2.m1.3.3.1.1.3">1</cn><apply id="S4.E2.m1.3.3.1.1.1.1.1.cmml" xref="S4.E2.m1.3.3.1.1.1.1"><lt id="S4.E2.m1.3.3.1.1.1.1.1.1.cmml" xref="S4.E2.m1.3.3.1.1.1.1.1.1"></lt><ci id="S4.E2.m1.3.3.1.1.1.1.1.2.cmml" xref="S4.E2.m1.3.3.1.1.1.1.1.2">𝑇</ci><apply id="S4.E2.m1.3.3.1.1.1.1.1.3.cmml" xref="S4.E2.m1.3.3.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E2.m1.3.3.1.1.1.1.1.3.1.cmml" xref="S4.E2.m1.3.3.1.1.1.1.1.3">subscript</csymbol><ci id="S4.E2.m1.3.3.1.1.1.1.1.3.2.cmml" xref="S4.E2.m1.3.3.1.1.1.1.1.3.2">𝑡</ci><ci id="S4.E2.m1.3.3.1.1.1.1.1.3.3.cmml" xref="S4.E2.m1.3.3.1.1.1.1.1.3.3">𝑖</ci></apply></apply></apply><ci id="S4.E2.m1.3.3.1.3.cmml" xref="S4.E2.m1.3.3.1.3">𝑎</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E2.m1.6c">Util(i)=|B_{i}|\sqrt{\frac{1}{|B_{i}|}\sum_{kEB_{i}}Loss(k^{2})}\times(\frac{T}{t_{i}})^{1(T&lt;t_{i})\times a}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div id="S4.SS1.p5" class="ltx_para">
<p id="S4.SS1.p5.4" class="ltx_p">where, in <a href="#S4.E2" title="In 4.1. Clients utility definition ‣ 4. Federated Model Training ‣ Towards Energy-Aware Federated Learning on Battery-Powered Clients" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Eq.</span> <span class="ltx_text ltx_ref_tag">2</span></a>, <math id="S4.SS1.p5.1.m1.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S4.SS1.p5.1.m1.1a"><mi id="S4.SS1.p5.1.m1.1.1" xref="S4.SS1.p5.1.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p5.1.m1.1b"><ci id="S4.SS1.p5.1.m1.1.1.cmml" xref="S4.SS1.p5.1.m1.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p5.1.m1.1c">T</annotation></semantics></math> is the duration of each round, <math id="S4.SS1.p5.2.m2.1" class="ltx_Math" alttext="t_{i}" display="inline"><semantics id="S4.SS1.p5.2.m2.1a"><msub id="S4.SS1.p5.2.m2.1.1" xref="S4.SS1.p5.2.m2.1.1.cmml"><mi id="S4.SS1.p5.2.m2.1.1.2" xref="S4.SS1.p5.2.m2.1.1.2.cmml">t</mi><mi id="S4.SS1.p5.2.m2.1.1.3" xref="S4.SS1.p5.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p5.2.m2.1b"><apply id="S4.SS1.p5.2.m2.1.1.cmml" xref="S4.SS1.p5.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS1.p5.2.m2.1.1.1.cmml" xref="S4.SS1.p5.2.m2.1.1">subscript</csymbol><ci id="S4.SS1.p5.2.m2.1.1.2.cmml" xref="S4.SS1.p5.2.m2.1.1.2">𝑡</ci><ci id="S4.SS1.p5.2.m2.1.1.3.cmml" xref="S4.SS1.p5.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p5.2.m2.1c">t_{i}</annotation></semantics></math> is the time taken by the client to process the training, and <math id="S4.SS1.p5.3.m3.1" class="ltx_Math" alttext="1(x)" display="inline"><semantics id="S4.SS1.p5.3.m3.1a"><mrow id="S4.SS1.p5.3.m3.1.2" xref="S4.SS1.p5.3.m3.1.2.cmml"><mn id="S4.SS1.p5.3.m3.1.2.2" xref="S4.SS1.p5.3.m3.1.2.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="S4.SS1.p5.3.m3.1.2.1" xref="S4.SS1.p5.3.m3.1.2.1.cmml">​</mo><mrow id="S4.SS1.p5.3.m3.1.2.3.2" xref="S4.SS1.p5.3.m3.1.2.cmml"><mo stretchy="false" id="S4.SS1.p5.3.m3.1.2.3.2.1" xref="S4.SS1.p5.3.m3.1.2.cmml">(</mo><mi id="S4.SS1.p5.3.m3.1.1" xref="S4.SS1.p5.3.m3.1.1.cmml">x</mi><mo stretchy="false" id="S4.SS1.p5.3.m3.1.2.3.2.2" xref="S4.SS1.p5.3.m3.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p5.3.m3.1b"><apply id="S4.SS1.p5.3.m3.1.2.cmml" xref="S4.SS1.p5.3.m3.1.2"><times id="S4.SS1.p5.3.m3.1.2.1.cmml" xref="S4.SS1.p5.3.m3.1.2.1"></times><cn type="integer" id="S4.SS1.p5.3.m3.1.2.2.cmml" xref="S4.SS1.p5.3.m3.1.2.2">1</cn><ci id="S4.SS1.p5.3.m3.1.1.cmml" xref="S4.SS1.p5.3.m3.1.1">𝑥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p5.3.m3.1c">1(x)</annotation></semantics></math> is an indicator function that is 1 if <math id="S4.SS1.p5.4.m4.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S4.SS1.p5.4.m4.1a"><mi id="S4.SS1.p5.4.m4.1.1" xref="S4.SS1.p5.4.m4.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p5.4.m4.1b"><ci id="S4.SS1.p5.4.m4.1.1.cmml" xref="S4.SS1.p5.4.m4.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p5.4.m4.1c">x</annotation></semantics></math> is true and 0 otherwise. More details are given in <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:80%;">Lai
et al</span><span class="ltx_text" style="font-size:80%;">.</span>, <a href="#bib.bib28" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2021</span></a>)</cite>.</p>
</div>
<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S4.T1.6.3.1" class="ltx_text" style="font-size:90%;">Table 1</span>. </span><span id="S4.T1.4.2" class="ltx_text" style="font-size:90%;">Comm. energy consumption (<math id="S4.T1.3.1.m1.1" class="ltx_Math" alttext="y" display="inline"><semantics id="S4.T1.3.1.m1.1b"><mi id="S4.T1.3.1.m1.1.1" xref="S4.T1.3.1.m1.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S4.T1.3.1.m1.1c"><ci id="S4.T1.3.1.m1.1.1.cmml" xref="S4.T1.3.1.m1.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.3.1.m1.1d">y</annotation></semantics></math>) given duration (<math id="S4.T1.4.2.m2.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S4.T1.4.2.m2.1b"><mi id="S4.T1.4.2.m2.1.1" xref="S4.T1.4.2.m2.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S4.T1.4.2.m2.1c"><ci id="S4.T1.4.2.m2.1.1.cmml" xref="S4.T1.4.2.m2.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.4.2.m2.1d">x</annotation></semantics></math>)</span></figcaption>
<table id="S4.T1.7" class="ltx_tabular ltx_align_middle">
<tr id="S4.T1.7.1" class="ltx_tr">
<td id="S4.T1.7.1.1" class="ltx_td ltx_border_l ltx_border_r ltx_border_t"></td>
<td id="S4.T1.7.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T1.7.1.2.1" class="ltx_text ltx_font_bold">Download</span></td>
<td id="S4.T1.7.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.7.1.3.1" class="ltx_text ltx_font_bold">Upload</span></td>
</tr>
<tr id="S4.T1.7.2" class="ltx_tr">
<td id="S4.T1.7.2.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">WIFI</td>
<td id="S4.T1.7.2.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">y = 18.09x + 0.17</td>
<td id="S4.T1.7.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">y = 21.24x - 2.68</td>
</tr>
<tr id="S4.T1.7.3" class="ltx_tr">
<td id="S4.T1.7.3.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t">3G</td>
<td id="S4.T1.7.3.2" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">y = 20.59x - 1.09</td>
<td id="S4.T1.7.3.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">y = 15.31x + 2.67</td>
</tr>
</table>
</figure>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2. </span>Energy consumption model</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">The energy consumption in the second part of <a href="#S4.E1" title="In 4.1. Clients utility definition ‣ 4. Federated Model Training ‣ Towards Energy-Aware Federated Learning on Battery-Powered Clients" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Eq.</span> <span class="ltx_text ltx_ref_tag">1</span></a> comes from the local computations executed during training and the wireless transmissions of the model updates.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para ltx_noindent">
<p id="S4.SS2.p2.3" class="ltx_p"><span id="S4.SS2.p2.3.1" class="ltx_text ltx_font_bold">Computation:</span>  The energy consumed by a selected device for a local iteration can be determined by taking the product of execution time and the run-time power such as <math id="S4.SS2.p2.1.m1.1" class="ltx_Math" alttext="E_{comp}=P\times t" display="inline"><semantics id="S4.SS2.p2.1.m1.1a"><mrow id="S4.SS2.p2.1.m1.1.1" xref="S4.SS2.p2.1.m1.1.1.cmml"><msub id="S4.SS2.p2.1.m1.1.1.2" xref="S4.SS2.p2.1.m1.1.1.2.cmml"><mi id="S4.SS2.p2.1.m1.1.1.2.2" xref="S4.SS2.p2.1.m1.1.1.2.2.cmml">E</mi><mrow id="S4.SS2.p2.1.m1.1.1.2.3" xref="S4.SS2.p2.1.m1.1.1.2.3.cmml"><mi id="S4.SS2.p2.1.m1.1.1.2.3.2" xref="S4.SS2.p2.1.m1.1.1.2.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p2.1.m1.1.1.2.3.1" xref="S4.SS2.p2.1.m1.1.1.2.3.1.cmml">​</mo><mi id="S4.SS2.p2.1.m1.1.1.2.3.3" xref="S4.SS2.p2.1.m1.1.1.2.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p2.1.m1.1.1.2.3.1a" xref="S4.SS2.p2.1.m1.1.1.2.3.1.cmml">​</mo><mi id="S4.SS2.p2.1.m1.1.1.2.3.4" xref="S4.SS2.p2.1.m1.1.1.2.3.4.cmml">m</mi><mo lspace="0em" rspace="0em" id="S4.SS2.p2.1.m1.1.1.2.3.1b" xref="S4.SS2.p2.1.m1.1.1.2.3.1.cmml">​</mo><mi id="S4.SS2.p2.1.m1.1.1.2.3.5" xref="S4.SS2.p2.1.m1.1.1.2.3.5.cmml">p</mi></mrow></msub><mo id="S4.SS2.p2.1.m1.1.1.1" xref="S4.SS2.p2.1.m1.1.1.1.cmml">=</mo><mrow id="S4.SS2.p2.1.m1.1.1.3" xref="S4.SS2.p2.1.m1.1.1.3.cmml"><mi id="S4.SS2.p2.1.m1.1.1.3.2" xref="S4.SS2.p2.1.m1.1.1.3.2.cmml">P</mi><mo lspace="0.222em" rspace="0.222em" id="S4.SS2.p2.1.m1.1.1.3.1" xref="S4.SS2.p2.1.m1.1.1.3.1.cmml">×</mo><mi id="S4.SS2.p2.1.m1.1.1.3.3" xref="S4.SS2.p2.1.m1.1.1.3.3.cmml">t</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.1.m1.1b"><apply id="S4.SS2.p2.1.m1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1"><eq id="S4.SS2.p2.1.m1.1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1.1"></eq><apply id="S4.SS2.p2.1.m1.1.1.2.cmml" xref="S4.SS2.p2.1.m1.1.1.2"><csymbol cd="ambiguous" id="S4.SS2.p2.1.m1.1.1.2.1.cmml" xref="S4.SS2.p2.1.m1.1.1.2">subscript</csymbol><ci id="S4.SS2.p2.1.m1.1.1.2.2.cmml" xref="S4.SS2.p2.1.m1.1.1.2.2">𝐸</ci><apply id="S4.SS2.p2.1.m1.1.1.2.3.cmml" xref="S4.SS2.p2.1.m1.1.1.2.3"><times id="S4.SS2.p2.1.m1.1.1.2.3.1.cmml" xref="S4.SS2.p2.1.m1.1.1.2.3.1"></times><ci id="S4.SS2.p2.1.m1.1.1.2.3.2.cmml" xref="S4.SS2.p2.1.m1.1.1.2.3.2">𝑐</ci><ci id="S4.SS2.p2.1.m1.1.1.2.3.3.cmml" xref="S4.SS2.p2.1.m1.1.1.2.3.3">𝑜</ci><ci id="S4.SS2.p2.1.m1.1.1.2.3.4.cmml" xref="S4.SS2.p2.1.m1.1.1.2.3.4">𝑚</ci><ci id="S4.SS2.p2.1.m1.1.1.2.3.5.cmml" xref="S4.SS2.p2.1.m1.1.1.2.3.5">𝑝</ci></apply></apply><apply id="S4.SS2.p2.1.m1.1.1.3.cmml" xref="S4.SS2.p2.1.m1.1.1.3"><times id="S4.SS2.p2.1.m1.1.1.3.1.cmml" xref="S4.SS2.p2.1.m1.1.1.3.1"></times><ci id="S4.SS2.p2.1.m1.1.1.3.2.cmml" xref="S4.SS2.p2.1.m1.1.1.3.2">𝑃</ci><ci id="S4.SS2.p2.1.m1.1.1.3.3.cmml" xref="S4.SS2.p2.1.m1.1.1.3.3">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.1.m1.1c">E_{comp}=P\times t</annotation></semantics></math> where <math id="S4.SS2.p2.2.m2.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S4.SS2.p2.2.m2.1a"><mi id="S4.SS2.p2.2.m2.1.1" xref="S4.SS2.p2.2.m2.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.2.m2.1b"><ci id="S4.SS2.p2.2.m2.1.1.cmml" xref="S4.SS2.p2.2.m2.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.2.m2.1c">t</annotation></semantics></math> is the time spent in the training on CPU/GPU and <math id="S4.SS2.p2.3.m3.1" class="ltx_Math" alttext="P" display="inline"><semantics id="S4.SS2.p2.3.m3.1a"><mi id="S4.SS2.p2.3.m3.1.1" xref="S4.SS2.p2.3.m3.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.3.m3.1b"><ci id="S4.SS2.p2.3.m3.1.1.cmml" xref="S4.SS2.p2.3.m3.1.1">𝑃</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.3.m3.1c">P</annotation></semantics></math> are the power consumption at average usage during the training. Here, we assume that the mobile devices are equipped with GPUs and hence we inherit the GPU power model as in <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:80%;">Ding and Hu</span>, <a href="#bib.bib14" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2017</span></a>)</cite>. The run-time power in the busy state is calculated for each category of edge devices (high-end, mid-end or low-end devices) and is dependent on the device-specific parameters (detail of the device categories and specifications is mentioned in <a href="#S5" title="5. Evaluation ‣ Towards Energy-Aware Federated Learning on Battery-Powered Clients" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">5</span></a>).</p>
</div>
<div id="S4.SS2.p3" class="ltx_para ltx_noindent">
<p id="S4.SS2.p3.2" class="ltx_p"><span id="S4.SS2.p3.2.1" class="ltx_text ltx_font_bold">Communication:</span> 
The mobile devices participating in a particular round of the FL training transmit their model aggregates to the server via wireless transmissions, corresponding to the communication energy consumption. We follow a simple linear energy model proposed in <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:80%;">Kalic
et al</span><span class="ltx_text" style="font-size:80%;">.</span>, <a href="#bib.bib23" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2012</span></a>)</cite>. <a href="#S4.T1" title="In 4.1. Clients utility definition ‣ 4. Federated Model Training ‣ Towards Energy-Aware Federated Learning on Battery-Powered Clients" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">1</span></a> shows the energy consumption functions for the elapsed time (communication latency) while using WiFi or 3G communication technologies to upload and download data. These functions compute the percentage of battery consumed by smartphones (<math id="S4.SS2.p3.1.m1.1" class="ltx_Math" alttext="y" display="inline"><semantics id="S4.SS2.p3.1.m1.1a"><mi id="S4.SS2.p3.1.m1.1.1" xref="S4.SS2.p3.1.m1.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.1.m1.1b"><ci id="S4.SS2.p3.1.m1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.1.m1.1c">y</annotation></semantics></math>) when using the respective mediums for <math id="S4.SS2.p3.2.m2.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S4.SS2.p3.2.m2.1a"><mi id="S4.SS2.p3.2.m2.1.1" xref="S4.SS2.p3.2.m2.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.2.m2.1b"><ci id="S4.SS2.p3.2.m2.1.1.cmml" xref="S4.SS2.p3.2.m2.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.2.m2.1c">x</annotation></semantics></math> hours. Their measurements were conducted on HTC Desire HD smartphone running Android OS version 2.3 <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:80%;">Kalic
et al</span><span class="ltx_text" style="font-size:80%;">.</span>, <a href="#bib.bib23" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2012</span></a>)</cite>.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Evaluation</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">We evaluate <span id="S5.p1.1.1" class="ltx_text ltx_font_italic">EAFL</span> against Oort and Random selection.</p>
</div>
<div id="S5.p2" class="ltx_para ltx_noindent">
<p id="S5.p2.1" class="ltx_p"><span id="S5.p2.1.1" class="ltx_text ltx_font_bold">Experimental Setup</span> 
In the experiments, we simulate an FL benchmark for speech recognition task that uses the Google Speech dataset <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:80%;">Warden</span>, <a href="#bib.bib47" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2018</span></a>)</cite> and ResNet model <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:80%;">He
et al</span><span class="ltx_text" style="font-size:80%;">.</span>, <a href="#bib.bib22" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2016</span></a>)</cite>. Learners are assigned real-world devices and network capability profiles from the AI Benchmark <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:80%;">Benchmark</span>, <a href="#bib.bib11" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2021</span></a>)</cite> and MobiPerf Trace <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:80%;">M-Lab</span>, <a href="#bib.bib31" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2021</span></a>)</cite>, respectively. This is an event-driven simulation with time calculated based on the completion time of the learners. To train the model, we use a cluster of GPU servers and interleave the time between individual learners. We assigned 4 GPUs per experiment. We use Fedscale as the training framework <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:80%;">Lai et al</span><span class="ltx_text" style="font-size:80%;">.</span>, <a href="#bib.bib27" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2022</span></a>)</cite> and YoGi as the aggregation algorithm <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:80%;">Ramaswamy et al</span><span class="ltx_text" style="font-size:80%;">.</span>, <a href="#bib.bib38" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2020</span></a>)</cite>. The hyper-parameters are set to 0.05, 500, and 20 for learning rate, # of epochs, and batch size, respectively. For each training round, the target number of learners to be selected is 10, and we make the clients available all the time. For the selected devices, we calculate energy consumption during training using the power model <a href="#S4.E1" title="In 4.1. Clients utility definition ‣ 4. Federated Model Training ‣ Towards Energy-Aware Federated Learning on Battery-Powered Clients" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Eq.</span> <span class="ltx_text ltx_ref_tag">1</span></a>; however, for unselected devices, we deduce the energy consumed for being in a combination of idle or busy states.</p>
</div>
<div id="S5.p3" class="ltx_para ltx_noindent">
<p id="S5.p3.1" class="ltx_p"><span id="S5.p3.1.1" class="ltx_text ltx_font_bold">Data Partitioning:</span> 
The client to data mappings used in Oort <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:80%;">Lai
et al</span><span class="ltx_text" style="font-size:80%;">.</span>, <a href="#bib.bib28" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2021</span></a>)</cite> is close to an IID distribution, so we introduce a more realistic non-IID distribution. The learners are assigned data samples from a random 10% of the labels (4 out of 35) while the data points per learner are sampled uniformly.</p>
</div>
<figure id="S5.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S5.T2.2.1.1" class="ltx_text" style="font-size:90%;">Table 2</span>. </span><span id="S5.T2.3.2" class="ltx_text" style="font-size:90%;">Mobile device specification</span></figcaption>
<div id="S5.T2.4" class="ltx_inline-block ltx_transformed_outer" style="width:433.6pt;height:166.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(1.7pt,-0.7pt) scale(1.00799369077274,1.00799369077274) ;">
<table id="S5.T2.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T2.4.1.1" class="ltx_tr">
<td id="S5.T2.4.1.1.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t"><span id="S5.T2.4.1.1.1.1" class="ltx_text ltx_font_bold">Device</span></td>
<td id="S5.T2.4.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S5.T2.4.1.1.2.1" class="ltx_text"></span><span id="S5.T2.4.1.1.2.2" class="ltx_text ltx_font_bold"> <span id="S5.T2.4.1.1.2.2.1" class="ltx_text">
<span id="S5.T2.4.1.1.2.2.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T2.4.1.1.2.2.1.1.1" class="ltx_tr">
<span id="S5.T2.4.1.1.2.2.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Average</span></span>
<span id="S5.T2.4.1.1.2.2.1.1.2" class="ltx_tr">
<span id="S5.T2.4.1.1.2.2.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">Power (W)</span></span>
</span></span><span id="S5.T2.4.1.1.2.2.2" class="ltx_text"></span></span>
</td>
<td id="S5.T2.4.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T2.4.1.1.3.1" class="ltx_text ltx_font_bold">Perf/W</span></td>
<td id="S5.T2.4.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T2.4.1.1.4.1" class="ltx_text ltx_font_bold">Memory</span></td>
<td id="S5.T2.4.1.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S5.T2.4.1.1.5.1" class="ltx_text"></span><span id="S5.T2.4.1.1.5.2" class="ltx_text ltx_font_bold"> <span id="S5.T2.4.1.1.5.2.1" class="ltx_text">
<span id="S5.T2.4.1.1.5.2.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T2.4.1.1.5.2.1.1.1" class="ltx_tr">
<span id="S5.T2.4.1.1.5.2.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Battery</span></span>
<span id="S5.T2.4.1.1.5.2.1.1.2" class="ltx_tr">
<span id="S5.T2.4.1.1.5.2.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">Capacity</span></span>
</span></span><span id="S5.T2.4.1.1.5.2.2" class="ltx_text"></span></span>
</td>
</tr>
<tr id="S5.T2.4.1.2" class="ltx_tr">
<td id="S5.T2.4.1.2.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">
<table id="S5.T2.4.1.2.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T2.4.1.2.1.1.1" class="ltx_tr">
<td id="S5.T2.4.1.2.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S5.T2.4.1.2.1.1.1.1.1" class="ltx_text ltx_font_bold">Huawei Mate 10 (Kirin 970)</span></td>
</tr>
<tr id="S5.T2.4.1.2.1.1.2" class="ltx_tr">
<td id="S5.T2.4.1.2.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S5.T2.4.1.2.1.1.2.1.1" class="ltx_text ltx_font_bold">(High-end)</span></td>
</tr>
</table>
</td>
<td id="S5.T2.4.1.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">6.33</td>
<td id="S5.T2.4.1.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">5.94 fps/W</td>
<td id="S5.T2.4.1.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">4GB(RAM)</td>
<td id="S5.T2.4.1.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">4000mAh</td>
</tr>
<tr id="S5.T2.4.1.3" class="ltx_tr">
<td id="S5.T2.4.1.3.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">
<table id="S5.T2.4.1.3.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T2.4.1.3.1.1.1" class="ltx_tr">
<td id="S5.T2.4.1.3.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S5.T2.4.1.3.1.1.1.1.1" class="ltx_text ltx_font_bold">Nexus 6P (Snapdragon 810 v2.1)</span></td>
</tr>
<tr id="S5.T2.4.1.3.1.1.2" class="ltx_tr">
<td id="S5.T2.4.1.3.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S5.T2.4.1.3.1.1.2.1.1" class="ltx_text ltx_font_bold">(Mid-range)</span></td>
</tr>
</table>
</td>
<td id="S5.T2.4.1.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">5.44</td>
<td id="S5.T2.4.1.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">4.03 fps/W</td>
<td id="S5.T2.4.1.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">3GB(RAM)</td>
<td id="S5.T2.4.1.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">3450mAh</td>
</tr>
<tr id="S5.T2.4.1.4" class="ltx_tr">
<td id="S5.T2.4.1.4.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t">
<table id="S5.T2.4.1.4.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T2.4.1.4.1.1.1" class="ltx_tr">
<td id="S5.T2.4.1.4.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S5.T2.4.1.4.1.1.1.1.1" class="ltx_text ltx_font_bold">Huawei P9 (Kirin 955)</span></td>
</tr>
<tr id="S5.T2.4.1.4.1.1.2" class="ltx_tr">
<td id="S5.T2.4.1.4.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S5.T2.4.1.4.1.1.2.1.1" class="ltx_text ltx_font_bold">(Low-end)</span></td>
</tr>
</table>
</td>
<td id="S5.T2.4.1.4.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">2.98</td>
<td id="S5.T2.4.1.4.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">3.55 fps/W</td>
<td id="S5.T2.4.1.4.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">3GB(RAM)</td>
<td id="S5.T2.4.1.4.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">3000mAh</td>
</tr>
</table>
</span></div>
</figure>
<div id="S5.p4" class="ltx_para ltx_noindent">
<p id="S5.p4.1" class="ltx_p"><span id="S5.p4.1.1" class="ltx_text ltx_font_bold">Device Profiles:</span>  We evaluate each device’s communication and computation profiles using the real device measurements from AI benchmark  <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:80%;">Benchmark</span>, <a href="#bib.bib11" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2021</span></a>)</cite> and MobiPerf <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:80%;">M-Lab</span>, <a href="#bib.bib31" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2021</span></a>)</cite> benchmark. However, for energy consumption, there is no such information widely available hence we cluster these profiles into three main performance categories (high, mid, and low) and map each device to one of them. We select three smartphones to represent the high, mid and low-end categories. Their average power consumption measurements from GFXBench <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:80%;">GFXBench</span>, <a href="#bib.bib21" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2022</span></a>)</cite> along with device specifications are shown in <a href="#S5.T2" title="In 5. Evaluation ‣ Towards Energy-Aware Federated Learning on Battery-Powered Clients" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<figure id="S5.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S5.F3.sf1" class="ltx_figure ltx_figure_panel"><img src="/html/2208.04505/assets/x3.png" id="S5.F3.sf1.g1" class="ltx_graphics ltx_img_landscape" width="461" height="273" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F3.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S5.F3.sf1.3.2" class="ltx_text" style="font-size:90%;">Test accuracy vs time</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S5.F3.sf2" class="ltx_figure ltx_figure_panel"><img src="/html/2208.04505/assets/x4.png" id="S5.F3.sf2.g1" class="ltx_graphics ltx_img_landscape" width="461" height="273" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F3.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S5.F3.sf2.3.2" class="ltx_text" style="font-size:90%;">Training loss vs time</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S5.F3.sf3" class="ltx_figure ltx_figure_panel"><img src="/html/2208.04505/assets/x5.png" id="S5.F3.sf3.g1" class="ltx_graphics ltx_img_landscape" width="461" height="273" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F3.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="S5.F3.sf3.3.2" class="ltx_text" style="font-size:90%;">Jain’s fairness index vs time</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F3.3.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>. </span><span id="S5.F3.4.2" class="ltx_text" style="font-size:90%;">Performance of Oort and <span id="S5.F3.4.2.1" class="ltx_text ltx_font_italic">EAFL</span> in terms of (a) test accuracy, (b) train loss, (c) Jain’s fairness index in a Non-IID case.</span></figcaption>
</figure>
<figure id="S5.F4" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F4.sf1" class="ltx_figure ltx_figure_panel"><img src="/html/2208.04505/assets/x6.png" id="S5.F4.sf1.g1" class="ltx_graphics ltx_img_landscape" width="461" height="273" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F4.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S5.F4.sf1.3.2" class="ltx_text" style="font-size:90%;">Clients running out of battery</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F4.sf2" class="ltx_figure ltx_figure_panel"><img src="/html/2208.04505/assets/x7.png" id="S5.F4.sf2.g1" class="ltx_graphics ltx_img_landscape" width="461" height="273" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F4.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S5.F4.sf2.3.2" class="ltx_text" style="font-size:90%;">Round duration</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F4.3.1.1" class="ltx_text" style="font-size:90%;">Figure 4</span>. </span><span id="S5.F4.4.2" class="ltx_text" style="font-size:90%;">Comparison of client dropouts due to running out of Battery between Oort and <span id="S5.F4.4.2.1" class="ltx_text ltx_font_italic">EAFL</span>.</span></figcaption>
</figure>
<div id="S5.p5" class="ltx_para ltx_noindent">
<p id="S5.p5.1" class="ltx_p"><span id="S5.p5.1.1" class="ltx_text ltx_font_bold">Experimental Results:</span>  To evaluate the performance of <span id="S5.p5.1.2" class="ltx_text ltx_font_italic">EAFL</span>, we compare it with Oort and a random sampler (Random). We run the experiments in non-iid settings. We use the value of <math id="S5.p5.1.m1.1" class="ltx_Math" alttext="f=0.25" display="inline"><semantics id="S5.p5.1.m1.1a"><mrow id="S5.p5.1.m1.1.1" xref="S5.p5.1.m1.1.1.cmml"><mi id="S5.p5.1.m1.1.1.2" xref="S5.p5.1.m1.1.1.2.cmml">f</mi><mo id="S5.p5.1.m1.1.1.1" xref="S5.p5.1.m1.1.1.1.cmml">=</mo><mn id="S5.p5.1.m1.1.1.3" xref="S5.p5.1.m1.1.1.3.cmml">0.25</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.p5.1.m1.1b"><apply id="S5.p5.1.m1.1.1.cmml" xref="S5.p5.1.m1.1.1"><eq id="S5.p5.1.m1.1.1.1.cmml" xref="S5.p5.1.m1.1.1.1"></eq><ci id="S5.p5.1.m1.1.1.2.cmml" xref="S5.p5.1.m1.1.1.2">𝑓</ci><cn type="float" id="S5.p5.1.m1.1.1.3.cmml" xref="S5.p5.1.m1.1.1.3">0.25</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p5.1.m1.1c">f=0.25</annotation></semantics></math> in <a href="#S4.E1" title="In 4.1. Clients utility definition ‣ 4. Federated Model Training ‣ Towards Energy-Aware Federated Learning on Battery-Powered Clients" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Eq.</span> <span class="ltx_text ltx_ref_tag">1</span></a> to calculate the reward function for <span id="S5.p5.1.3" class="ltx_text ltx_font_italic">EAFL</span> to give more weight to the high-power clients (i.e., higher remaining battery). This allows more clients to stay and reduces dropouts due to running out of battery.</p>
</div>
<div id="S5.p6" class="ltx_para">
<p id="S5.p6.1" class="ltx_p">As shown <a href="#S5.F4.sf1" title="In Figure 4 ‣ 5. Evaluation ‣ Towards Energy-Aware Federated Learning on Battery-Powered Clients" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">4(a)</span></a>, compared to other methods, Oort shows a significant increase in battery run-outs as the training progresses, highlighting the impact of not being energy-aware unlike <span id="S5.p6.1.1" class="ltx_text ltx_font_italic">EAFL</span> and random with low drop-outs. <span id="S5.p6.1.2" class="ltx_text ltx_font_italic">EAFL</span>, to conserve energy, it trades-off time and selects high-power clients and hence sees fewer drop-outs over the training. Random has low dropouts as it selects clients uniformly at random because it distributes the consumption over more clients, however, its consumption supersedes <span id="S5.p6.1.3" class="ltx_text ltx_font_italic">EAFL</span> after 40 hours of training. <a href="#S5.F4.sf2" title="In Figure 4 ‣ 5. Evaluation ‣ Towards Energy-Aware Federated Learning on Battery-Powered Clients" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">4(b)</span></a> shows Random results in significantly higher round duration compared to the other methods. We note the per-round duration for Oort and <span id="S5.p6.1.4" class="ltx_text ltx_font_italic">EAFL</span> is almost the same, but further in time, the duration increases to compensate for low statistical efficiency (Oort) or high energy consumption (<span id="S5.p6.1.5" class="ltx_text ltx_font_italic">EAFL</span>). Oort experiences a low participation rate and round failures due to significant numbers of dropouts which explains its low-round duration at the end. <span id="S5.p6.1.6" class="ltx_text ltx_font_italic">EAFL</span> is able to maintain low client drop-outs due to its energy-aware selection which increases the participation rate in the training.</p>
</div>
<div id="S5.p7" class="ltx_para">
<p id="S5.p7.1" class="ltx_p"><a href="#S5.F3.sf1" title="In Figure 3 ‣ 5. Evaluation ‣ Towards Energy-Aware Federated Learning on Battery-Powered Clients" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">3(a)</span></a> and <a href="#S5.F3.sf2" title="In Figure 3 ‣ 5. Evaluation ‣ Towards Energy-Aware Federated Learning on Battery-Powered Clients" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">3(b)</span></a> present the achieved accuracy and training loss for all methods, respectively. <span id="S5.p7.1.1" class="ltx_text ltx_font_italic">EAFL</span> achieves the best results in both metrics showing the benefits of its selection method (esp. for battery-powered scenarios) which maintains high levels of participation in the training. <a href="#S5.F3.sf3" title="In Figure 3 ‣ 5. Evaluation ‣ Towards Energy-Aware Federated Learning on Battery-Powered Clients" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">3(c)</span></a> shows Jain’s fairness index for device selection which measures if users are getting a fair opportunity to participate in the training. The results suggest that <span id="S5.p7.1.2" class="ltx_text ltx_font_italic">EAFL</span> enjoys high levels of fairness similar to Random. Oort initially enjoys the same levels of fairness but then due to high dropouts and low participation, its fairness degrades severely.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6. </span>Related Work</h2>

<div id="S6.p1" class="ltx_para ltx_noindent">
<p id="S6.p1.1" class="ltx_p"><span id="S6.p1.1.1" class="ltx_text ltx_font_bold">Federated Learning (FL):</span>  is a new distributed machine learning method which is increasingly becoming popular for its privacy-preservation and low-communication features. This motivated the growing adoption of FL to improve the end-user experience (e.g., the search suggestion quality of virtual keyboards <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:80%;">Yang et al</span><span class="ltx_text" style="font-size:80%;">.</span>, <a href="#bib.bib50" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2018</span></a>)</cite>). Moreover, to encourage and speed up experimentation of new ideas, many FL frameworks were recently developed <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:80%;">Caldas et al</span><span class="ltx_text" style="font-size:80%;">.</span>, <a href="#bib.bib13" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2018</span></a>; <span class="ltx_text" style="font-size:80%;">Ryffel et al</span><span class="ltx_text" style="font-size:80%;">.</span>, <a href="#bib.bib42" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2018</span></a>)</cite>. In FL, the training of a global model is assigned to a sub-population of decentralized devices such as mobile or IoT sensor devices. These devices possess private data samples and engage in training the model on their local data <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:80%;">Li et al</span><span class="ltx_text" style="font-size:80%;">.</span>, <a href="#bib.bib29" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2014</span></a>; <span class="ltx_text" style="font-size:80%;">McMahan et al</span><span class="ltx_text" style="font-size:80%;">.</span>, <a href="#bib.bib32" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2017</span></a>)</cite>.</p>
</div>
<div id="S6.p2" class="ltx_para ltx_noindent">
<p id="S6.p2.1" class="ltx_p"><span id="S6.p2.1.1" class="ltx_text ltx_font_bold">System heterogeneity:</span>  One of the major contributors to system performance unpredictability is the heterogeneity inherent in many of the distributed systems. Mainly, in FL context, the heterogeneity of devices’ system configurations (e.g., computation, communication, battery, etc) results in unpredictable performance. For instance, the stragglers (i.e., slow workers) can halt the training process for a prolonged duration <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:80%;">Li et al</span><span class="ltx_text" style="font-size:80%;">.</span>, <a href="#bib.bib30" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2020</span></a>; <span class="ltx_text" style="font-size:80%;">Abdelmoniem and
Canini</span>, <a href="#bib.bib4" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2021b</span></a>)</cite>.
Several solutions exist that address this problem through system and algorithmic solutions <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:80%;">Abdelmoniem and
Bensaou</span>, <a href="#bib.bib2" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2015</span></a>; <span class="ltx_text" style="font-size:80%;">Abu
et al</span><span class="ltx_text" style="font-size:80%;">.</span>, <a href="#bib.bib9" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2016</span></a>; <span class="ltx_text" style="font-size:80%;">Li et al</span><span class="ltx_text" style="font-size:80%;">.</span>, <a href="#bib.bib30" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2020</span></a>; <span class="ltx_text" style="font-size:80%;">Ruan
et al</span><span class="ltx_text" style="font-size:80%;">.</span>, <a href="#bib.bib41" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2021</span></a>; <span class="ltx_text" style="font-size:80%;">Abdelmoniem and
Canini</span>, <a href="#bib.bib4" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2021b</span></a>)</cite>. Moreover, in FL, the heterogeneity is also a byproduct of other artifacts other than the devices. For example, the learner data distributions, the participants’ selection method, and the behaviour of the device’s owner are common sources of heterogeneity in FL setting <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:80%;">Abdelmoniem et al</span><span class="ltx_text" style="font-size:80%;">.</span>, <a href="#bib.bib6" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2021b</span></a>, <a href="#bib.bib7" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2022</span></a>)</cite>.</p>
</div>
<div id="S6.p3" class="ltx_para ltx_noindent">
<p id="S6.p3.1" class="ltx_p"><span id="S6.p3.1.1" class="ltx_text ltx_font_bold">Energy-conservation:</span>  Considering the uncertainties in the mobile environment, several energy management techniques have been proposed <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:80%;">Ding and Hu</span>, <a href="#bib.bib14" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2017</span></a>)</cite>. Other works for energy efficiency optimization in the mobile environment use computation offloading techniques. Finally, few works focused on energy-efficient FL training <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:80%;">Kim and Wu</span>, <a href="#bib.bib24" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2021</span></a>, <a href="#bib.bib25" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2020</span></a>)</cite>. <span id="S6.p3.1.2" class="ltx_text ltx_font_italic">EAFL</span> aims for energy conservation to mitigate client dropouts which is the major contributor to the degraded FL model qualities.</p>
</div>
<div id="S6.p4" class="ltx_para ltx_noindent">
<p id="S6.p4.1" class="ltx_p"><span id="S6.p4.1.1" class="ltx_text ltx_font_bold">Improvements in FL:</span> 
In FL, several works aim to improve the time-to-accuracy of training by leveraging techniques such as periodic updates, compression, and layer-wise asynchronous updates
<cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:80%;">Konečný et al</span><span class="ltx_text" style="font-size:80%;">.</span>, <a href="#bib.bib26" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2016</span></a>; <span class="ltx_text" style="font-size:80%;">Bonawitz et al</span><span class="ltx_text" style="font-size:80%;">.</span>, <a href="#bib.bib12" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2019</span></a>; <span class="ltx_text" style="font-size:80%;">Dutta et al</span><span class="ltx_text" style="font-size:80%;">.</span>, <a href="#bib.bib15" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2020</span></a>; <span class="ltx_text" style="font-size:80%;">Reisizadeh et al</span><span class="ltx_text" style="font-size:80%;">.</span>, <a href="#bib.bib39" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2020</span></a>; <span class="ltx_text" style="font-size:80%;">Abdelmoniem and
Canini</span>, <a href="#bib.bib3" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2021a</span></a>; <span class="ltx_text" style="font-size:80%;">Abdelmoniem et al</span><span class="ltx_text" style="font-size:80%;">.</span>, <a href="#bib.bib8" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2021c</span></a>, <a href="#bib.bib5" title="" class="ltx_ref">a</a>; <span class="ltx_text" style="font-size:80%;">Gajjala et al</span><span class="ltx_text" style="font-size:80%;">.</span>, <a href="#bib.bib19" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2020</span></a>; <span class="ltx_text" style="font-size:80%;">Xu et al</span><span class="ltx_text" style="font-size:80%;">.</span>, <a href="#bib.bib49" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2021</span></a>; <span class="ltx_text" style="font-size:80%;">Sahu et al</span><span class="ltx_text" style="font-size:80%;">.</span>, <a href="#bib.bib43" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2021</span></a>)</cite>. Other proposals aimed at righting the privacy guarantees of FL settings <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:80%;">Melis et al</span><span class="ltx_text" style="font-size:80%;">.</span>, <a href="#bib.bib33" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2019</span></a>; <span class="ltx_text" style="font-size:80%;">Bonawitz et al</span><span class="ltx_text" style="font-size:80%;">.</span>, <a href="#bib.bib12" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2019</span></a>; <span class="ltx_text" style="font-size:80%;">Nasr
et al</span><span class="ltx_text" style="font-size:80%;">.</span>, <a href="#bib.bib35" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2019</span></a>; <span class="ltx_text" style="font-size:80%;">Bagdasaryan et al</span><span class="ltx_text" style="font-size:80%;">.</span>, <a href="#bib.bib10" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2020</span></a>)</cite>. Moreover, the bias in FL is studied to ensure fair participation in the training process <cite class="ltx_cite ltx_citemacro_citep">(<span class="ltx_text" style="font-size:80%;">Mohri
et al</span><span class="ltx_text" style="font-size:80%;">.</span>, <a href="#bib.bib34" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2019</span></a>; <span class="ltx_text" style="font-size:80%;">Li et al</span><span class="ltx_text" style="font-size:80%;">.</span>, <a href="#bib.bib30" title="" class="ltx_ref"><span class="ltx_text" style="font-size:80%;">2020</span></a>)</cite>.</p>
</div>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7. </span>Conclusion</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">We present our preliminary work on studying a practical federated learning scenario where the participants are battery-powered and they need to collaboratively learn a new global model. We find that the existing state-of-the-art methods, aiming to minimize the time-to-accuracy, fail to achieve satisfactory performance as they ignore the factor of energy consumption on the devices. Therefore, we present <span id="S7.p1.1.1" class="ltx_text ltx_font_italic">EAFL</span>, to enable power-aware FL training on battery-powered devices. Our algorithm intelligently selects the participants to maintain low time-to-accuracy while conserving energy. It shows up to 85% improvement in model accuracy and 2.45<math id="S7.p1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S7.p1.1.m1.1a"><mo id="S7.p1.1.m1.1.1" xref="S7.p1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S7.p1.1.m1.1b"><times id="S7.p1.1.m1.1.1.cmml" xref="S7.p1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S7.p1.1.m1.1c">\times</annotation></semantics></math> decrease in drop-out of clients proving to be a practical FL solution for battery-powered scenarios.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:80%;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib1.2.2.1" class="ltx_text" style="font-size:80%;">(1)</span></span>
<span class="ltx_bibblock"><span id="bib.bib1.3.1" class="ltx_text" style="font-size:80%;">        



</span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib2.5.5.1" class="ltx_text" style="font-size:80%;">Abdelmoniem and
Bensaou (2015)</span></span>
<span class="ltx_bibblock"><span id="bib.bib2.7.1" class="ltx_text" style="font-size:80%;">
Ahmed M. Abdelmoniem and
Brahim Bensaou. 2015.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.8.1" class="ltx_text" style="font-size:80%;">Efficient Switch-Assisted Congestion Control for
Data Centers: an Implementation and Evaluation. In
</span><em id="bib.bib2.9.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">IEEE International Performance Computing and
Communications Conference (IPCCC)</em><span id="bib.bib2.10.3" class="ltx_text" style="font-size:80%;">.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib3.5.5.1" class="ltx_text" style="font-size:80%;">Abdelmoniem and
Canini (2021a)</span></span>
<span class="ltx_bibblock"><span id="bib.bib3.7.1" class="ltx_text" style="font-size:80%;">
Ahmed M. Abdelmoniem and
Marco Canini. 2021a.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.8.1" class="ltx_text" style="font-size:80%;">DC2: Delay-aware Compression Control for
Distributed Machine Learning. In </span><em id="bib.bib3.9.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">IEEE
INFOCOM</em><span id="bib.bib3.10.3" class="ltx_text" style="font-size:80%;">.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib4.5.5.1" class="ltx_text" style="font-size:80%;">Abdelmoniem and
Canini (2021b)</span></span>
<span class="ltx_bibblock"><span id="bib.bib4.7.1" class="ltx_text" style="font-size:80%;">
Ahmed M. Abdelmoniem and
Marco Canini. 2021b.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.8.1" class="ltx_text" style="font-size:80%;">Towards Mitigating Device Heterogeneity in
Federated Learning via Adaptive Model Quantization. In
</span><em id="bib.bib4.9.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">ACM EuroMLSys</em><span id="bib.bib4.10.3" class="ltx_text" style="font-size:80%;">.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib5.6.6.1" class="ltx_text" style="font-size:80%;">Abdelmoniem et al</span><span id="bib.bib5.7.7.2" class="ltx_text" style="font-size:80%;">.</span><span id="bib.bib5.8.8.3" class="ltx_text" style="font-size:80%;"> (2021a)</span></span>
<span class="ltx_bibblock"><span id="bib.bib5.10.1" class="ltx_text" style="font-size:80%;">
Ahmed M. Abdelmoniem,
Ahmed Elzanaty, Mohamed-Slim Alouini,
and Marco Canini. 2021a.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.11.1" class="ltx_text" style="font-size:80%;">An Efficient Statistical-based Gradient
Compression Technique for Distributed Training Systems. In
</span><em id="bib.bib5.12.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">MLSys</em><span id="bib.bib5.13.3" class="ltx_text" style="font-size:80%;">.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib6.6.6.1" class="ltx_text" style="font-size:80%;">Abdelmoniem et al</span><span id="bib.bib6.7.7.2" class="ltx_text" style="font-size:80%;">.</span><span id="bib.bib6.8.8.3" class="ltx_text" style="font-size:80%;"> (2021b)</span></span>
<span class="ltx_bibblock"><span id="bib.bib6.10.1" class="ltx_text" style="font-size:80%;">
Ahmed M. Abdelmoniem,
Chen-Yu Ho, Pantelis Papageorgiou,
Muhammad Bilal, and Marco Canini.
2021b.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.11.1" class="ltx_text" style="font-size:80%;">On the Impact of Device and Behavioral
Heterogeneity in Federated Learning.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib6.12.1" class="ltx_emph ltx_font_italic" style="font-size:80%;">arXiv 2102.07500</em><span id="bib.bib6.13.2" class="ltx_text" style="font-size:80%;"> (2021).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib7.6.6.1" class="ltx_text" style="font-size:80%;">Abdelmoniem et al</span><span id="bib.bib7.7.7.2" class="ltx_text" style="font-size:80%;">.</span><span id="bib.bib7.8.8.3" class="ltx_text" style="font-size:80%;"> (2022)</span></span>
<span class="ltx_bibblock"><span id="bib.bib7.10.1" class="ltx_text" style="font-size:80%;">
Ahmed M. Abdelmoniem,
Chen-Yu Ho, Pantelis Papageorgiou, and
Marco Canini. 2022.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.11.1" class="ltx_text" style="font-size:80%;">Empirical Analysis of Federated Learning in
Heterogeneous Environments. In </span><em id="bib.bib7.12.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">ACM EuroMLSys</em><span id="bib.bib7.13.3" class="ltx_text" style="font-size:80%;">.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib8.6.6.1" class="ltx_text" style="font-size:80%;">Abdelmoniem et al</span><span id="bib.bib8.7.7.2" class="ltx_text" style="font-size:80%;">.</span><span id="bib.bib8.8.8.3" class="ltx_text" style="font-size:80%;"> (2021c)</span></span>
<span class="ltx_bibblock"><span id="bib.bib8.10.1" class="ltx_text" style="font-size:80%;">
Ahmed M. Abdelmoniem,
Atal Narayan Sahu, Marco Canini, and
Suhaib A. Fahmy. 2021c.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.11.1" class="ltx_text" style="font-size:80%;">Resource-Efficient Federated Learning.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib8.12.1" class="ltx_emph ltx_font_italic" style="font-size:80%;">arXiv 2111.01108</em><span id="bib.bib8.13.2" class="ltx_text" style="font-size:80%;"> (2021).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib9.6.6.1" class="ltx_text" style="font-size:80%;">Abu
et al</span><span id="bib.bib9.7.7.2" class="ltx_text" style="font-size:80%;">.</span><span id="bib.bib9.8.8.3" class="ltx_text" style="font-size:80%;"> (2016)</span></span>
<span class="ltx_bibblock"><span id="bib.bib9.10.1" class="ltx_text" style="font-size:80%;">
Amuda James Abu, Brahim
Bensaou, and Ahmed M. Abdelmoniem.
2016.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.11.1" class="ltx_text" style="font-size:80%;">A Markov Model of CCN Pending Interest Table
Occupancy with Interest Timeout and Retries. In
</span><em id="bib.bib9.12.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">IEEE International Confereence on Communications
(ICC)</em><span id="bib.bib9.13.3" class="ltx_text" style="font-size:80%;">.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib10.6.6.1" class="ltx_text" style="font-size:80%;">Bagdasaryan et al</span><span id="bib.bib10.7.7.2" class="ltx_text" style="font-size:80%;">.</span><span id="bib.bib10.8.8.3" class="ltx_text" style="font-size:80%;"> (2020)</span></span>
<span class="ltx_bibblock"><span id="bib.bib10.10.1" class="ltx_text" style="font-size:80%;">
Eugene Bagdasaryan,
Andreas Veit, Yiqing Hua,
Deborah Estrin, and Vitaly Shmatikov.
2020.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.11.1" class="ltx_text" style="font-size:80%;">How To Backdoor Federated Learning. In
</span><em id="bib.bib10.12.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">AISTATS</em><span id="bib.bib10.13.3" class="ltx_text" style="font-size:80%;">.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib11.5.5.1" class="ltx_text" style="font-size:80%;">Benchmark (2021)</span></span>
<span class="ltx_bibblock"><span id="bib.bib11.7.1" class="ltx_text" style="font-size:80%;">
AI Benchmark.
2021.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.8.1" class="ltx_text" style="font-size:80%;">Performance Ranking.
</span>
</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock"><span id="bib.bib11.9.1" class="ltx_text" style="font-size:80%;">
</span><a target="_blank" href="https://ai-benchmark.com/ranking.html" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:80%;">https://ai-benchmark.com/ranking.html</a><span id="bib.bib11.10.2" class="ltx_text" style="font-size:80%;">
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib12.6.6.1" class="ltx_text" style="font-size:80%;">Bonawitz et al</span><span id="bib.bib12.7.7.2" class="ltx_text" style="font-size:80%;">.</span><span id="bib.bib12.8.8.3" class="ltx_text" style="font-size:80%;"> (2019)</span></span>
<span class="ltx_bibblock"><span id="bib.bib12.10.1" class="ltx_text" style="font-size:80%;">
Keith Bonawitz, Hubert
Eichner, Wolfgang Grieskamp, Dzmitry
Huba, Alex Ingerman, Vladimir Ivanov,
Chloe Kiddon, Jakub Konečný,
Stefano Mazzocchi, H. Brendan McMahan,
Timon Van Overveldt, David Petrou,
Daniel Ramage, and Jason Roselander.
2019.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.11.1" class="ltx_text" style="font-size:80%;">Towards Federated Learning at Scale: System
Design. In </span><em id="bib.bib12.12.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">MLSys</em><span id="bib.bib12.13.3" class="ltx_text" style="font-size:80%;">.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib13.6.6.1" class="ltx_text" style="font-size:80%;">Caldas et al</span><span id="bib.bib13.7.7.2" class="ltx_text" style="font-size:80%;">.</span><span id="bib.bib13.8.8.3" class="ltx_text" style="font-size:80%;"> (2018)</span></span>
<span class="ltx_bibblock"><span id="bib.bib13.10.1" class="ltx_text" style="font-size:80%;">
Sebastian Caldas, Sai
Meher Karthik Duddu, Peter Wu, Tian Li,
Jakub Konečný, H. Brendan McMahan,
Virginia Smith, and Ameet Talwalkar.
2018.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.11.1" class="ltx_text" style="font-size:80%;">LEAF: A Benchmark for Federated Settings.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib13.12.1" class="ltx_emph ltx_font_italic" style="font-size:80%;">arXiv 1812.01097</em><span id="bib.bib13.13.2" class="ltx_text" style="font-size:80%;"> (2018).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib14.5.5.1" class="ltx_text" style="font-size:80%;">Ding and Hu (2017)</span></span>
<span class="ltx_bibblock"><span id="bib.bib14.7.1" class="ltx_text" style="font-size:80%;">
Ning Ding and Y. Charlie
Hu. 2017.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.8.1" class="ltx_text" style="font-size:80%;">GfxDoctor: A Holistic Graphics Energy Profiler for
Mobile Devices. In </span><em id="bib.bib14.9.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">Proceedings of the European
Conference on Computer Systems (EuroSys)</em><span id="bib.bib14.10.3" class="ltx_text" style="font-size:80%;">.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib15.6.6.1" class="ltx_text" style="font-size:80%;">Dutta et al</span><span id="bib.bib15.7.7.2" class="ltx_text" style="font-size:80%;">.</span><span id="bib.bib15.8.8.3" class="ltx_text" style="font-size:80%;"> (2020)</span></span>
<span class="ltx_bibblock"><span id="bib.bib15.10.1" class="ltx_text" style="font-size:80%;">
Aritra Dutta, El Houcine
Bergou, Ahmed M. Abdelmoniem, Chen-Yu
Ho, Atal Narayan Sahu, Marco Canini,
and Panos Kalnis. 2020.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.11.1" class="ltx_text" style="font-size:80%;">On the Discrepancy between the Theoretical Analysis
and Practical Implementations of Compressed Communication for Distributed
Deep Learning. In </span><em id="bib.bib15.12.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">The AAAI Conference on
Artificial Intelligence</em><span id="bib.bib15.13.3" class="ltx_text" style="font-size:80%;">. Association for the
Advancement of Artificial Intelligence (AAAI).
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.14.1" class="ltx_text" style="font-size:80%;">

</span><a target="_blank" href="https://doi.org/10.1609/aaai.v34i04.5793" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:80%;">https://doi.org/10.1609/aaai.v34i04.5793</a><span id="bib.bib15.15.2" class="ltx_text" style="font-size:80%;">
</span>
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib16.5.5.1" class="ltx_text" style="font-size:80%;">et al. (2017)</span></span>
<span class="ltx_bibblock"><span id="bib.bib16.7.1" class="ltx_text" style="font-size:80%;">
Keith Bonawitz et al.
2017.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.8.1" class="ltx_text" style="font-size:80%;">Practical Secure Aggregation for Privacy-Preserving
Machine Learning. In </span><em id="bib.bib16.9.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">In Proceedings of the 2017
ACM SIGSAC Conference on Computer and Communications Security (CCS)</em><span id="bib.bib16.10.3" class="ltx_text" style="font-size:80%;">.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib17.5.5.1" class="ltx_text" style="font-size:80%;">Exchange (2022)</span></span>
<span class="ltx_bibblock"><span id="bib.bib17.7.1" class="ltx_text" style="font-size:80%;">
Chip 1 Exchange.
2022.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.8.1" class="ltx_text" style="font-size:80%;">The Wave of Wearables.
</span>
</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib18.5.5.1" class="ltx_text" style="font-size:80%;">Fisher (1971)</span></span>
<span class="ltx_bibblock"><span id="bib.bib18.7.1" class="ltx_text" style="font-size:80%;">
Ronald Fisher.
1971.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib18.8.1" class="ltx_emph ltx_font_italic" style="font-size:80%;">The Design of Experiments</em><span id="bib.bib18.9.2" class="ltx_text" style="font-size:80%;">
(9 ed.).
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.10.1" class="ltx_text" style="font-size:80%;">Macmillan.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib19.6.6.1" class="ltx_text" style="font-size:80%;">Gajjala et al</span><span id="bib.bib19.7.7.2" class="ltx_text" style="font-size:80%;">.</span><span id="bib.bib19.8.8.3" class="ltx_text" style="font-size:80%;"> (2020)</span></span>
<span class="ltx_bibblock"><span id="bib.bib19.10.1" class="ltx_text" style="font-size:80%;">
Rishikesh R. Gajjala,
Shashwat Banchhor, Ahmed M. Abdelmoniem,
Aritra Dutta, Marco Canini, and
Panos Kalnis. 2020.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.11.1" class="ltx_text" style="font-size:80%;">Huffman Coding Based Encoding Techniques for Fast
Distributed Deep Learning. In </span><em id="bib.bib19.12.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">Workshop on
Distributed Machine Learning</em><span id="bib.bib19.13.3" class="ltx_text" style="font-size:80%;">.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib20.6.6.1" class="ltx_text" style="font-size:80%;">Geyer
et al</span><span id="bib.bib20.7.7.2" class="ltx_text" style="font-size:80%;">.</span><span id="bib.bib20.8.8.3" class="ltx_text" style="font-size:80%;"> (2017)</span></span>
<span class="ltx_bibblock"><span id="bib.bib20.10.1" class="ltx_text" style="font-size:80%;">
Robin C. Geyer, Tassilo
Klein, and Moin Nabi. 2017.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.11.1" class="ltx_text" style="font-size:80%;">Differentially Private Federated Learning: A
Client Level Perspective.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib20.12.1" class="ltx_emph ltx_font_italic" style="font-size:80%;">ArXiv 1712.07557</em><span id="bib.bib20.13.2" class="ltx_text" style="font-size:80%;"> (2017).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib21.5.5.1" class="ltx_text" style="font-size:80%;">GFXBench (2022)</span></span>
<span class="ltx_bibblock"><span id="bib.bib21.7.1" class="ltx_text" style="font-size:80%;">
GFXBench. 2022.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.8.1" class="ltx_text" style="font-size:80%;">GFXBench 5.0.
</span>
</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock"><a target="_blank" href="https://gfxbench.com/result.jsp" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:80%;">https://gfxbench.com/result.jsp</a><span id="bib.bib21.9.1" class="ltx_text" style="font-size:80%;">.
</span>
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib22.6.6.1" class="ltx_text" style="font-size:80%;">He
et al</span><span id="bib.bib22.7.7.2" class="ltx_text" style="font-size:80%;">.</span><span id="bib.bib22.8.8.3" class="ltx_text" style="font-size:80%;"> (2016)</span></span>
<span class="ltx_bibblock"><span id="bib.bib22.10.1" class="ltx_text" style="font-size:80%;">
Kaiming He, Xiangyu
Zhang, Shaoqing Ren, and Jian Sun.
2016.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.11.1" class="ltx_text" style="font-size:80%;">Deep Residual Learning for Image Recognition. In
</span><em id="bib.bib22.12.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">CVPR</em><span id="bib.bib22.13.3" class="ltx_text" style="font-size:80%;">.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib23.6.6.1" class="ltx_text" style="font-size:80%;">Kalic
et al</span><span id="bib.bib23.7.7.2" class="ltx_text" style="font-size:80%;">.</span><span id="bib.bib23.8.8.3" class="ltx_text" style="font-size:80%;"> (2012)</span></span>
<span class="ltx_bibblock"><span id="bib.bib23.10.1" class="ltx_text" style="font-size:80%;">
Goran Kalic, Iva Bojic,
and Mario Kusek. 2012.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.11.1" class="ltx_text" style="font-size:80%;">Energy consumption in android phones when using
wireless communication technologies. In </span><em id="bib.bib23.12.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">2012
Proceedings of the 35th International Convention MIPRO</em><span id="bib.bib23.13.3" class="ltx_text" style="font-size:80%;">.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib24.5.5.1" class="ltx_text" style="font-size:80%;">Kim and Wu (2021)</span></span>
<span class="ltx_bibblock"><span id="bib.bib24.7.1" class="ltx_text" style="font-size:80%;">
Young Geun Kim and
Carole-Jean Wu. 2021.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.8.1" class="ltx_text" style="font-size:80%;">AutoFL: Enabling Heterogeneity-Aware Energy
Efficient Federated Learning.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib24.9.1" class="ltx_emph ltx_font_italic" style="font-size:80%;">ArXiv 2107.08147</em><span id="bib.bib24.10.2" class="ltx_text" style="font-size:80%;"> (2021).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib25.5.5.1" class="ltx_text" style="font-size:80%;">Kim and Wu (2020)</span></span>
<span class="ltx_bibblock"><span id="bib.bib25.7.1" class="ltx_text" style="font-size:80%;">
Young Geun Kim and
Carole-Jean Wu. 2020.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.8.1" class="ltx_text" style="font-size:80%;">AutoScale: Energy Efficiency Optimization for
Stochastic Edge Inference Using Reinforcement Learning. In
</span><em id="bib.bib25.9.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">IEEE/ACM International Symposium on
Microarchitecture (MICRO)</em><span id="bib.bib25.10.3" class="ltx_text" style="font-size:80%;">.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib26.6.6.1" class="ltx_text" style="font-size:80%;">Konečný et al</span><span id="bib.bib26.7.7.2" class="ltx_text" style="font-size:80%;">.</span><span id="bib.bib26.8.8.3" class="ltx_text" style="font-size:80%;"> (2016)</span></span>
<span class="ltx_bibblock"><span id="bib.bib26.10.1" class="ltx_text" style="font-size:80%;">
Jakub Konečný,
H. Brendan McMahan, Felix X. Yu,
Peter Richtarik, Ananda Theertha Suresh,
and Dave Bacon. 2016.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.11.1" class="ltx_text" style="font-size:80%;">Federated Learning: Strategies for Improving
Communication Efficiency. In </span><em id="bib.bib26.12.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">Workshop on Private
Multi-Party Machine Learning - NeurIPS</em><span id="bib.bib26.13.3" class="ltx_text" style="font-size:80%;">.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib27.6.6.1" class="ltx_text" style="font-size:80%;">Lai et al</span><span id="bib.bib27.7.7.2" class="ltx_text" style="font-size:80%;">.</span><span id="bib.bib27.8.8.3" class="ltx_text" style="font-size:80%;"> (2022)</span></span>
<span class="ltx_bibblock"><span id="bib.bib27.10.1" class="ltx_text" style="font-size:80%;">
Fan Lai, Yinwei Dai,
Sanjay S. Singapuram, Jiachen Liu,
Xiangfeng Zhu, Harsha V. Madhyastha,
and Mosharaf Chowdhury. 2022.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.11.1" class="ltx_text" style="font-size:80%;">FedScale: Benchmarking Model and System
Performance of Federated Learning at Scale. In
</span><em id="bib.bib27.12.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">International Conference on Machine Learning
(ICML)</em><span id="bib.bib27.13.3" class="ltx_text" style="font-size:80%;">.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib28.6.6.1" class="ltx_text" style="font-size:80%;">Lai
et al</span><span id="bib.bib28.7.7.2" class="ltx_text" style="font-size:80%;">.</span><span id="bib.bib28.8.8.3" class="ltx_text" style="font-size:80%;"> (2021)</span></span>
<span class="ltx_bibblock"><span id="bib.bib28.10.1" class="ltx_text" style="font-size:80%;">
Fan Lai, Xiangfeng Zhu,
Harsha V. Madhyastha, and Mosharaf
Chowdhury. 2021.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.11.1" class="ltx_text" style="font-size:80%;">Efficient Federated Learning via Guided
Participant Selection. In </span><em id="bib.bib28.12.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">USENIX OSDI</em><span id="bib.bib28.13.3" class="ltx_text" style="font-size:80%;">.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib29.6.6.1" class="ltx_text" style="font-size:80%;">Li et al</span><span id="bib.bib29.7.7.2" class="ltx_text" style="font-size:80%;">.</span><span id="bib.bib29.8.8.3" class="ltx_text" style="font-size:80%;"> (2014)</span></span>
<span class="ltx_bibblock"><span id="bib.bib29.10.1" class="ltx_text" style="font-size:80%;">
Mu Li, David G. Andersen,
Jun Woo Park, Alexander J. Smola,
Amr Ahmed, Vanja Josifovski,
James Long, Eugene J. Shekita, and
Bor-Yiing Su. 2014.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.11.1" class="ltx_text" style="font-size:80%;">Scaling Distributed Machine Learning with the
Parameter Server. In </span><em id="bib.bib29.12.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">OSDI</em><span id="bib.bib29.13.3" class="ltx_text" style="font-size:80%;">.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib30.6.6.1" class="ltx_text" style="font-size:80%;">Li et al</span><span id="bib.bib30.7.7.2" class="ltx_text" style="font-size:80%;">.</span><span id="bib.bib30.8.8.3" class="ltx_text" style="font-size:80%;"> (2020)</span></span>
<span class="ltx_bibblock"><span id="bib.bib30.10.1" class="ltx_text" style="font-size:80%;">
Tian Li, Anit Kumar Sahu,
Manzil Zaheer, Maziar Sanjabi,
Ameet Talwalkar, and Virginia Smith.
2020.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.11.1" class="ltx_text" style="font-size:80%;">Federated Optimization in Heterogeneous Networks.
In </span><em id="bib.bib30.12.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">MLSys</em><span id="bib.bib30.13.3" class="ltx_text" style="font-size:80%;">.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib31.5.5.1" class="ltx_text" style="font-size:80%;">M-Lab (2021)</span></span>
<span class="ltx_bibblock"><span id="bib.bib31.7.1" class="ltx_text" style="font-size:80%;">
M-Lab. 2021.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.8.1" class="ltx_text" style="font-size:80%;">MobiPerf: an open source application for measuring
network performance on mobile platforms.
</span>
</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock"><span id="bib.bib31.9.1" class="ltx_text" style="font-size:80%;">
</span><a target="_blank" href="https://www.measurementlab.net/tests/mobiperf/" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:80%;">https://www.measurementlab.net/tests/mobiperf/</a><span id="bib.bib31.10.2" class="ltx_text" style="font-size:80%;">
</span>
</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib32.6.6.1" class="ltx_text" style="font-size:80%;">McMahan et al</span><span id="bib.bib32.7.7.2" class="ltx_text" style="font-size:80%;">.</span><span id="bib.bib32.8.8.3" class="ltx_text" style="font-size:80%;"> (2017)</span></span>
<span class="ltx_bibblock"><span id="bib.bib32.10.1" class="ltx_text" style="font-size:80%;">
H. Brendan McMahan, Eider
Moore, Daniel Ramage, Seth Hampson,
and Blaise Agüera y Arcas.
2017.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.11.1" class="ltx_text" style="font-size:80%;">Communication-Efficient Learning of Deep Networks
from Decentralized Data. In </span><em id="bib.bib32.12.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">AISTATS</em><span id="bib.bib32.13.3" class="ltx_text" style="font-size:80%;">.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib33.6.6.1" class="ltx_text" style="font-size:80%;">Melis et al</span><span id="bib.bib33.7.7.2" class="ltx_text" style="font-size:80%;">.</span><span id="bib.bib33.8.8.3" class="ltx_text" style="font-size:80%;"> (2019)</span></span>
<span class="ltx_bibblock"><span id="bib.bib33.10.1" class="ltx_text" style="font-size:80%;">
Luca Melis, Congzheng
Song, Emiliano De Cristofaro, and
Vitaly Shmatikov. 2019.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.11.1" class="ltx_text" style="font-size:80%;">Exploiting Unintended Feature Leakage in
Collaborative Learning. In </span><em id="bib.bib33.12.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">IEEE Symposium on
Security and Privacy (SP)</em><span id="bib.bib33.13.3" class="ltx_text" style="font-size:80%;">.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib34.6.6.1" class="ltx_text" style="font-size:80%;">Mohri
et al</span><span id="bib.bib34.7.7.2" class="ltx_text" style="font-size:80%;">.</span><span id="bib.bib34.8.8.3" class="ltx_text" style="font-size:80%;"> (2019)</span></span>
<span class="ltx_bibblock"><span id="bib.bib34.10.1" class="ltx_text" style="font-size:80%;">
Mehryar Mohri, Gary
Sivek, and Ananda Theertha Suresh.
2019.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.11.1" class="ltx_text" style="font-size:80%;">Agnostic Federated Learning. In
</span><em id="bib.bib34.12.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">ICML</em><span id="bib.bib34.13.3" class="ltx_text" style="font-size:80%;">.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib35.6.6.1" class="ltx_text" style="font-size:80%;">Nasr
et al</span><span id="bib.bib35.7.7.2" class="ltx_text" style="font-size:80%;">.</span><span id="bib.bib35.8.8.3" class="ltx_text" style="font-size:80%;"> (2019)</span></span>
<span class="ltx_bibblock"><span id="bib.bib35.10.1" class="ltx_text" style="font-size:80%;">
Milad Nasr, Reza Shokri,
and Amir Houmansadr. 2019.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.11.1" class="ltx_text" style="font-size:80%;">Comprehensive privacy analysis of deep learning:
Passive and active white-box inference attacks against centralized and
federated learning. In </span><em id="bib.bib35.12.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">IEEE Symposium on Security
and Privacy (SP)</em><span id="bib.bib35.13.3" class="ltx_text" style="font-size:80%;">.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib36.6.6.1" class="ltx_text" style="font-size:80%;">Peng
et al</span><span id="bib.bib36.7.7.2" class="ltx_text" style="font-size:80%;">.</span><span id="bib.bib36.8.8.3" class="ltx_text" style="font-size:80%;"> (2020)</span></span>
<span class="ltx_bibblock"><span id="bib.bib36.10.1" class="ltx_text" style="font-size:80%;">
Xingchao Peng, Zijun
Huang, Yizhe Zhu, and Kate Saenko.
2020.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.11.1" class="ltx_text" style="font-size:80%;">Federated Adversarial Domain Adaptation. In
</span><em id="bib.bib36.12.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">International Conference on Learning
Representations (ICLR)</em><span id="bib.bib36.13.3" class="ltx_text" style="font-size:80%;">.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib37.6.6.1" class="ltx_text" style="font-size:80%;">Qiu et al</span><span id="bib.bib37.7.7.2" class="ltx_text" style="font-size:80%;">.</span><span id="bib.bib37.8.8.3" class="ltx_text" style="font-size:80%;"> (2020)</span></span>
<span class="ltx_bibblock"><span id="bib.bib37.10.1" class="ltx_text" style="font-size:80%;">
Xinchi Qiu, Titouan
Parcollet, Daniel J. Beutel, Taner
Topal, Akhil Mathur, and Nicholas D.
Lane. 2020.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.11.1" class="ltx_text" style="font-size:80%;">A first look into the carbon footprint of federated
learning.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib37.12.1" class="ltx_emph ltx_font_italic" style="font-size:80%;">ArXiv 2010.06537</em><span id="bib.bib37.13.2" class="ltx_text" style="font-size:80%;"> (2020).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib38.6.6.1" class="ltx_text" style="font-size:80%;">Ramaswamy et al</span><span id="bib.bib38.7.7.2" class="ltx_text" style="font-size:80%;">.</span><span id="bib.bib38.8.8.3" class="ltx_text" style="font-size:80%;"> (2020)</span></span>
<span class="ltx_bibblock"><span id="bib.bib38.10.1" class="ltx_text" style="font-size:80%;">
Swaroop Ramaswamy, Om
Thakkar, Rajiv Mathews, Galen Andrew,
H. Brendan McMahan, and Françoise
Beaufays. 2020.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.11.1" class="ltx_text" style="font-size:80%;">Training Production Language Models without
Memorizing User Data.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib38.12.1" class="ltx_emph ltx_font_italic" style="font-size:80%;">arXiv 2009.10031</em><span id="bib.bib38.13.2" class="ltx_text" style="font-size:80%;"> (2020).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib39.6.6.1" class="ltx_text" style="font-size:80%;">Reisizadeh et al</span><span id="bib.bib39.7.7.2" class="ltx_text" style="font-size:80%;">.</span><span id="bib.bib39.8.8.3" class="ltx_text" style="font-size:80%;"> (2020)</span></span>
<span class="ltx_bibblock"><span id="bib.bib39.10.1" class="ltx_text" style="font-size:80%;">
Amirhossein Reisizadeh,
Aryan Mokhtari, Hamed Hassani,
Ali Jadbabaie, and Ramtin Pedarsani.
2020.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.11.1" class="ltx_text" style="font-size:80%;">FedPAQ: A Communication-Efficient Federated
Learning Method with Periodic Averaging and Quantization. In
</span><em id="bib.bib39.12.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">AISTATS</em><span id="bib.bib39.13.3" class="ltx_text" style="font-size:80%;">.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib40.6.6.1" class="ltx_text" style="font-size:80%;">Reisizadeh et al</span><span id="bib.bib40.7.7.2" class="ltx_text" style="font-size:80%;">.</span><span id="bib.bib40.8.8.3" class="ltx_text" style="font-size:80%;"> ([n.d.])</span></span>
<span class="ltx_bibblock"><span id="bib.bib40.10.1" class="ltx_text" style="font-size:80%;">
Amirhossein Reisizadeh,
Isidoros Tziotis, Hamed Hassani,
Aryan Mokhtari, and Ramtin Pedarsani.
[n.d.].
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.11.1" class="ltx_text" style="font-size:80%;">Straggler-Resilient Federated Learning: Leveraging
the Interplay Between Statistical Accuracy and System Heterogeneity.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib40.12.1" class="ltx_emph ltx_font_italic" style="font-size:80%;">ArXiv 2012.14453</em><span id="bib.bib40.13.2" class="ltx_text" style="font-size:80%;">
([n. d.]).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib41.6.6.1" class="ltx_text" style="font-size:80%;">Ruan
et al</span><span id="bib.bib41.7.7.2" class="ltx_text" style="font-size:80%;">.</span><span id="bib.bib41.8.8.3" class="ltx_text" style="font-size:80%;"> (2021)</span></span>
<span class="ltx_bibblock"><span id="bib.bib41.10.1" class="ltx_text" style="font-size:80%;">
Yichen Ruan, Xiaoxi
Zhang, Shu-Che Liang, and Carlee
Joe-Wong. 2021.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.11.1" class="ltx_text" style="font-size:80%;"> Towards Flexible Device Participation in
Federated Learning . In </span><em id="bib.bib41.12.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">AISTATS</em><span id="bib.bib41.13.3" class="ltx_text" style="font-size:80%;">.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib42.6.6.1" class="ltx_text" style="font-size:80%;">Ryffel et al</span><span id="bib.bib42.7.7.2" class="ltx_text" style="font-size:80%;">.</span><span id="bib.bib42.8.8.3" class="ltx_text" style="font-size:80%;"> (2018)</span></span>
<span class="ltx_bibblock"><span id="bib.bib42.10.1" class="ltx_text" style="font-size:80%;">
Theo Ryffel, Andrew
Trask, Morten Dahl, Bobby Wagner,
Jason Mancuso, Daniel Rueckert, and
Jonathan Passerat-Palmbach.
2018.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.11.1" class="ltx_text" style="font-size:80%;">A generic framework for privacy preserving deep
learning.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib42.12.1" class="ltx_emph ltx_font_italic" style="font-size:80%;">arXiv 1811.04017</em><span id="bib.bib42.13.2" class="ltx_text" style="font-size:80%;"> (2018).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib43.6.6.1" class="ltx_text" style="font-size:80%;">Sahu et al</span><span id="bib.bib43.7.7.2" class="ltx_text" style="font-size:80%;">.</span><span id="bib.bib43.8.8.3" class="ltx_text" style="font-size:80%;"> (2021)</span></span>
<span class="ltx_bibblock"><span id="bib.bib43.10.1" class="ltx_text" style="font-size:80%;">
Atal Sahu, Aritra Dutta,
Ahmed M. Abdelmoniem, Trambak Banerjee,
Marco Canini, and Panos Kalnis.
2021.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.11.1" class="ltx_text" style="font-size:80%;">Rethinking gradient sparsification as total error
minimization. In </span><em id="bib.bib43.12.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">NeurIPS</em><span id="bib.bib43.13.3" class="ltx_text" style="font-size:80%;">.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib44.6.6.1" class="ltx_text" style="font-size:80%;">Suresh
et al</span><span id="bib.bib44.7.7.2" class="ltx_text" style="font-size:80%;">.</span><span id="bib.bib44.8.8.3" class="ltx_text" style="font-size:80%;"> (2017)</span></span>
<span class="ltx_bibblock"><span id="bib.bib44.10.1" class="ltx_text" style="font-size:80%;">
Ananda Theertha Suresh,
Felix X. Yu, H. Brendan McMahan, and
Sanjiv Kumar. 2017.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib44.11.1" class="ltx_text" style="font-size:80%;">Distributed Mean Estimation with Limited
Communication. In </span><em id="bib.bib44.12.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">International Conference on
Machine Learning</em><span id="bib.bib44.13.3" class="ltx_text" style="font-size:80%;">.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib44.14.1" class="ltx_text" style="font-size:80%;">
</span><a target="_blank" href="https://arxiv.org/abs/1611.00429" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:80%;">https://arxiv.org/abs/1611.00429</a><span id="bib.bib44.15.2" class="ltx_text" style="font-size:80%;">
</span>
</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib45.6.6.1" class="ltx_text" style="font-size:80%;">Wang
et al</span><span id="bib.bib45.7.7.2" class="ltx_text" style="font-size:80%;">.</span><span id="bib.bib45.8.8.3" class="ltx_text" style="font-size:80%;"> (2021)</span></span>
<span class="ltx_bibblock"><span id="bib.bib45.10.1" class="ltx_text" style="font-size:80%;">
C. Wang, Y. Yang, and
P. Zhou. 2021.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib45.11.1" class="ltx_text" style="font-size:80%;">Towards Efficient Scheduling of Federated Mobile
Devices Under Computational and Statistical Heterogeneity.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib45.12.1" class="ltx_emph ltx_font_italic" style="font-size:80%;">IEEE Transactions on Parallel &amp; Distributed
Systems</em><span id="bib.bib45.13.2" class="ltx_text" style="font-size:80%;"> 32, 02 (2021),
394–410.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib46.5.5.1" class="ltx_text" style="font-size:80%;">Wang and Xu (2021)</span></span>
<span class="ltx_bibblock"><span id="bib.bib46.7.1" class="ltx_text" style="font-size:80%;">
Heqiang Wang and Jie
Xu. 2021.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib46.8.1" class="ltx_text" style="font-size:80%;">Friends to Help: Saving Federated Learning from
Client Dropout.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib46.9.1" class="ltx_emph ltx_font_italic" style="font-size:80%;">ArXiv 2205.13222</em><span id="bib.bib46.10.2" class="ltx_text" style="font-size:80%;"> (2021).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib47.5.5.1" class="ltx_text" style="font-size:80%;">Warden (2018)</span></span>
<span class="ltx_bibblock"><span id="bib.bib47.7.1" class="ltx_text" style="font-size:80%;">
P. Warden.
2018.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib47.8.1" class="ltx_text" style="font-size:80%;">Speech Commands: A Dataset for Limited-Vocabulary
Speech Recognition.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib47.9.1" class="ltx_emph ltx_font_italic" style="font-size:80%;">ArXiv 1804.03209</em><span id="bib.bib47.10.2" class="ltx_text" style="font-size:80%;"> (2018).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib48.6.6.1" class="ltx_text" style="font-size:80%;">Xie
et al</span><span id="bib.bib48.7.7.2" class="ltx_text" style="font-size:80%;">.</span><span id="bib.bib48.8.8.3" class="ltx_text" style="font-size:80%;"> (2019)</span></span>
<span class="ltx_bibblock"><span id="bib.bib48.10.1" class="ltx_text" style="font-size:80%;">
Cong Xie, Sanmi Koyejo,
and Indranil Gupta. 2019.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib48.11.1" class="ltx_text" style="font-size:80%;">Asynchronous Federated Optimization.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib48.12.1" class="ltx_emph ltx_font_italic" style="font-size:80%;">ArXiv 1903.03934</em><span id="bib.bib48.13.2" class="ltx_text" style="font-size:80%;"> (2019).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib49.6.6.1" class="ltx_text" style="font-size:80%;">Xu et al</span><span id="bib.bib49.7.7.2" class="ltx_text" style="font-size:80%;">.</span><span id="bib.bib49.8.8.3" class="ltx_text" style="font-size:80%;"> (2021)</span></span>
<span class="ltx_bibblock"><span id="bib.bib49.10.1" class="ltx_text" style="font-size:80%;">
Hang Xu, Chen-Yu Ho,
Ahmed M. Abdelmoniem, Aritra Dutta,
El Houcine Bergou, Konstantinos
Karatsenidis, Marco Canini, and Panos
Kalnis. 2021.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib49.11.1" class="ltx_text" style="font-size:80%;">GRACE: A Compressed Communication Framework for
Distributed Machine Learning. In </span><em id="bib.bib49.12.2" class="ltx_emph ltx_font_italic" style="font-size:80%;">ICDCS</em><span id="bib.bib49.13.3" class="ltx_text" style="font-size:80%;">.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib50.6.6.1" class="ltx_text" style="font-size:80%;">Yang et al</span><span id="bib.bib50.7.7.2" class="ltx_text" style="font-size:80%;">.</span><span id="bib.bib50.8.8.3" class="ltx_text" style="font-size:80%;"> (2018)</span></span>
<span class="ltx_bibblock"><span id="bib.bib50.10.1" class="ltx_text" style="font-size:80%;">
Timothy Yang, Galen
Andrew, Hubert Eichner, Haicheng Sun,
Wei Li, Nicholas Kong,
Daniel Ramage, and Françoise
Beaufays. 2018.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib50.11.1" class="ltx_text" style="font-size:80%;">Applied Federated Learning: Improving Google
Keyboard Query Suggestions.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib50.12.1" class="ltx_emph ltx_font_italic" style="font-size:80%;">arXiv 1812.02903</em><span id="bib.bib50.13.2" class="ltx_text" style="font-size:80%;"> (2018).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2208.04504" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2208.04505" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2208.04505">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2208.04505" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2208.04506" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Wed Mar 13 20:00:49 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
