<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Textual Similarity as a Key Metric in Machine Translation Quality Estimation</title>
<!--Generated on Mon Jul  1 09:30:32 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2406.07440v2/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#S1" title="In Textual Similarity as a Key Metric in Machine Translation Quality Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#S2" title="In Textual Similarity as a Key Metric in Machine Translation Quality Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Methods</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#S2.SS1" title="In 2 Methods ‣ Textual Similarity as a Key Metric in Machine Translation Quality Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Dataset</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#S2.SS2" title="In 2 Methods ‣ Textual Similarity as a Key Metric in Machine Translation Quality Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Textual similarity</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#S2.SS3" title="In 2 Methods ‣ Textual Similarity as a Key Metric in Machine Translation Quality Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Regression statistical analysis</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#S3" title="In Textual Similarity as a Key Metric in Machine Translation Quality Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Results</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#S3.SS1" title="In 3 Results ‣ Textual Similarity as a Key Metric in Machine Translation Quality Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Result 1: Correlations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#S3.SS2" title="In 3 Results ‣ Textual Similarity as a Key Metric in Machine Translation Quality Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Result 2: Cross language pairs</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#S3.SS3" title="In 3 Results ‣ Textual Similarity as a Key Metric in Machine Translation Quality Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Result 3: Individual language pair</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#S4" title="In Textual Similarity as a Key Metric in Machine Translation Quality Estimation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Discussion</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document" style="font-size:173%;">Textual Similarity as a Key Metric in Machine Translation Quality Estimation</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span class="ltx_text" id="id1.1.id1" style="font-size:80%;">Kun Sun</span>
</span><span class="ltx_author_notes"><span class="ltx_text ltx_font_typewriter" id="id2.2.id1" style="font-size:80%;">kun.sun@uni-tuebingen.de</span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text" id="id3.3.id1" style="font-size:80%;">Department of Linguistics, University of Tübingen, Germany</span>
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span class="ltx_text" id="id4.1.id1" style="font-size:80%;">Rong Wang</span>
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Institute of Natural Language Processing, Stuttgart University, Stuttgart, Germany
</span></span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id5.id1"><span class="ltx_text" id="id5.id1.1" lang="en" style="font-size:80%;">Machine Translation (MT) Quality Estimation (QE) assesses translation reliability without reference texts. This study introduces “textual similarity” as a new metric for QE, using sentence transformers and cosine similarity to measure semantic closeness. Analyzing data from the MLQE-PE dataset, we found that textual similarity exhibits stronger correlations with human scores than traditional metrics (hter, model evaluation, sentence probability etc.). Employing GAMMs as a statistical tool, we demonstrated that textual similarity consistently outperforms other metrics across multiple language pairs in predicting human scores. We also found that “hter” actually failed to predict human scores in QE. Our findings highlight the effectiveness of textual similarity as a robust QE metric, recommending its integration with other metrics into QE frameworks and MT system training for improved accuracy and usability.</span></p>
</div>
<div class="ltx_para" id="p1">
<p class="ltx_p" id="p1.1"><span class="ltx_text ltx_font_bold" id="p1.1.1" lang="en" style="font-size:90%;">Keywords:<span class="ltx_text ltx_font_medium" id="p1.1.1.1"> translation quality evaluation, sentence transformers, cosine similarity, regression analysis, key metric</span></span></p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_section" id="S1" lang="en">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1"><span class="ltx_text" id="S1.p1.1.1" style="font-size:90%;">There are two kinds of quality evaluations in machine translation (MT): “MT quality evaluation” and “MT quality estimation” </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S1.p1.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#bib.bib13" title=""><span class="ltx_text" style="font-size:90%;">13</span></a><span class="ltx_text" id="S1.p1.1.3.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S1.p1.1.4" style="font-size:90%;">. Each field has distinct standards and applications, ensuring comprehensive translation quality assessment. The former is used to compare the quality of translated texts when the reference translations are available. In contrast, the latter, also named as MT “quality estimation (QE)”, involves assessing the quality of MT outputs without reference translations </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S1.p1.1.5.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#bib.bib10" title=""><span class="ltx_text" style="font-size:90%;">10</span></a><span class="ltx_text" id="S1.p1.1.6.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S1.p1.1.7" style="font-size:90%;">. QE is essential for various applications, such as determining whether an automatically translated sentence or document is ready for the end user or requires human post-editing. It can flag passages with critical errors, serve as a quality metric when reference translations are unavailable, and assist in computer-aided translation interfaces by highlighting text needing human revision and estimating the required human effort. The current study focuses on the latter, quality estimation.</span></p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1"><span class="ltx_text" id="S1.p2.1.1" style="font-size:90%;">“MT quality evaluation” involves using various automatic metrics to assess translation accuracy and effort. Common metrics include BLEU, which measures n-gram overlap with reference translations and applies a brevity penalty; METEOR, which considers precision, recall, synonyms, and stemming; TER, which calculates the number of edits needed to match a reference translation; chrF, which evaluates character n-grams, useful for morphologically rich languages; and BERTScore, which uses pre-trained embeddings to assess semantic similarity. Moreover, supervised metrics, trained using human-judged data often show a higher correlation with human evaluations, and some metrics were used such as BEER, BLEND </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S1.p2.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#bib.bib8" title=""><span class="ltx_text" style="font-size:90%;">8</span></a><span class="ltx_text" id="S1.p2.1.3.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S1.p2.1.4" style="font-size:90%;">.</span></p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1"><span class="ltx_text" id="S1.p3.1.1" style="font-size:90%;">However, in MT QE, several features play pivotal roles in both quality estimation and enhancing the overall translation process. The “model eveluation” (ML_eval) quantifies the MT model’s confidence in its translations. This metric is typically derived from the log-likelihood of the translation given the source sentence. Higher scores reflect greater confidence, indicating that the translation aligns well with the model’s learned patterns from the training data. These scores are crucial for quality estimation TM systems, helping to predict the reliability of translations from TM models and highlight areas that may require further human intervention or correction </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S1.p3.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#bib.bib2" title=""><span class="ltx_text" style="font-size:90%;">2</span></a><span class="ltx_text" id="S1.p3.1.3.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S1.p3.1.4" style="font-size:90%;">, </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S1.p3.1.5.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#bib.bib6" title=""><span class="ltx_text" style="font-size:90%;">6</span></a><span class="ltx_text" id="S1.p3.1.6.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S1.p3.1.7" style="font-size:90%;">. Moreover, in many cases, sentences with higher probabilities from n-gram models do tend to be more natural-sounding. This is because these models are trained on large corpora of text, capturing common patterns in language use. Sentence probabilities for translated texts are also used to evaluate translation quality without reference translations.</span></p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1"><span class="ltx_text" id="S1.p4.1.1" style="font-size:90%;">Another significant feature is “human translation edit rate” (hter) </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S1.p4.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#bib.bib12" title=""><span class="ltx_text" style="font-size:90%;">12</span></a><span class="ltx_text" id="S1.p4.1.3.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S1.p4.1.4" style="font-size:90%;">, and it measures the number of edits required to correct a translation output from MT to match a human reference. It accounts for insertions, deletions, substitutions, and shifts, providing a quantitative measure of the effort needed for post-editing. This makes </span><span class="ltx_text ltx_font_typewriter" id="S1.p4.1.5" style="font-size:90%;">hter</span><span class="ltx_text" id="S1.p4.1.6" style="font-size:90%;"> a practical metric for assessing the quality of MT systems, as it directly correlates with the human effort required to produce accurate translations.</span></p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1"><span class="ltx_text" id="S1.p5.1.1" style="font-size:90%;">In MT quality estimation, “ML_eval” often serve as one key feature in helping to gauge the reliability and quality of TM systems when the reference translations are not available. The metric of “ML_eval”, combined with linguistic features and contextual embeddings, enhance the accuracy of TM quality assessments. They help identify translations that may require human review or post-editing. Further, in the training or fine-tuning of NMT (neural machine translation) or LLMs-based TM models, the metric of “ML_eval” still plays an important role, such as on optimizing translation performance by leveraging large parallel corpora, word alignments, and contextual learning techniques </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S1.p5.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#bib.bib7" title=""><span class="ltx_text" style="font-size:90%;">7</span></a><span class="ltx_text" id="S1.p5.1.3.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S1.p5.1.4" style="font-size:90%;">, </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S1.p5.1.5.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#bib.bib9" title=""><span class="ltx_text" style="font-size:90%;">9</span></a><span class="ltx_text" id="S1.p5.1.6.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S1.p5.1.7" style="font-size:90%;">. Even if the metric is not directly used in training or fine-tuning, it still could provide valuable feedback on the translation quality, guiding iterative improvements and fine-tuning of the model. This distinction underscores the dual role of “ML_eval” in both evaluating and enhancing translation quality.</span></p>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1"><span class="ltx_text" id="S1.p6.1.1" style="font-size:90%;">While “ML_eval” provides valuable insights into QE, the metric has certain limitations. One significant issue is the tendency to overestimate confidence in poor translations, often due to overfitting or a lack of diverse training data. This overconfidence can lead to inaccuracies in QE. Moreover, the metric is sensitive to the training data distribution, and meaning biases or gaps in the data can skew the scores. Third, this metric may also fail to capture contextual meaning and subtle semantic differences that human evaluators can detect, leading to discrepancies between model scores and perceived translation quality. Additionally, although higher probability from an n-gram model often correlates with more natural-sounding sentences, this metric may not be a ideal indicator. The reason for this is that the relationship between statistical probability and perceived naturalness is complex and influenced by many factors beyond n-gram probabilities.</span></p>
</div>
<div class="ltx_para" id="S1.p7">
<p class="ltx_p" id="S1.p7.1"><span class="ltx_text" id="S1.p7.1.1" style="font-size:90%;">The metric, “hter”, has also some weaknesses. First, the variability in human editing styles and preferences can lead to inconsistent hter scores, making it challenging to standardize quality assessments. Additionally, “hter” focuses on the number of edits rather than the nature of the changes, failing to differentiate between minor stylistic tweaks and substantial corrections. This can skew the perception of translation quality. Furthermore, the metric relies on the availability of high-quality reference translations, which may not always be accessible, limiting its applicability in certain contexts. These limitations suggest that while “hter” is useful, it should be complemented with other evaluation methods for a more comprehensive assessment of translation quality.</span></p>
</div>
<div class="ltx_para" id="S1.p8">
<p class="ltx_p" id="S1.p8.1"><span class="ltx_text" id="S1.p8.1.1" style="font-size:90%;">We have identified some limitations in the two key metrics used in Quality Estimation (QE). Despite these, traditional QE methods face a significant, often overlooked problem: the reliance on </span><span class="ltx_text ltx_font_bold" id="S1.p8.1.2" style="font-size:90%;">correlation</span><span class="ltx_text" id="S1.p8.1.3" style="font-size:90%;"> statistical analysis for evaluation. Correlation is primarily used to understand the relationship between two data sets. Correlation only indicates the degree to which two sets of data are related, but it does not establish a relationship between them. However, to determine the effect of one variable on another, regression analysis is essential. For a deeper insight into key features affecting machine learning quality estimation data, regression analysis provides a more robust approach. For example, if we want to determine whether “hter” has an effect on human scores, regression analysis is necessary. The correlation between “hter” and human scores does not provide this level of insight.</span></p>
</div>
<div class="ltx_para" id="S1.p9">
<p class="ltx_p" id="S1.p9.1"><span class="ltx_text" id="S1.p9.1.1" style="font-size:90%;">To address these weaknesses, it is crucial to complement existing metrics with additional features, continuously update and diversify training data, and incorporate new features to enhance the reliability and usability of QE. Upgrading statistical analysis methods is also necessary to gain deeper insights. This study proposes that “textual similarity” could be considered a key feature in MT quality estimation and training. Using existing MT quality estimation datasets, we employed advanced statistical methods to compare this new metric with existing features and explore their advantages.</span></p>
</div>
</section>
<section class="ltx_section" id="S2" lang="en">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">2 </span>Methods</h2>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Dataset</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1"><span class="ltx_text" id="S2.SS1.p1.1.1" style="font-size:90%;">This study utilized two distinct datasets. The first dataset, </span><span class="ltx_text ltx_font_typewriter" id="S2.SS1.p1.1.2" style="font-size:90%;">MLQE-PE</span><span class="ltx_text" id="S2.SS1.p1.1.3" style="font-size:90%;"> </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S2.SS1.p1.1.4.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#bib.bib6" title=""><span class="ltx_text" style="font-size:90%;">6</span></a><span class="ltx_text" id="S2.SS1.p1.1.5.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S2.SS1.p1.1.6" style="font-size:90%;">, and the second dataset, used in </span><span class="ltx_text ltx_font_typewriter" id="S2.SS1.p1.1.7" style="font-size:90%;">PreQuEL</span><span class="ltx_text" id="S2.SS1.p1.1.8" style="font-size:90%;"> </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S2.SS1.p1.1.9.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#bib.bib5" title=""><span class="ltx_text" style="font-size:90%;">5</span></a><span class="ltx_text" id="S2.SS1.p1.1.10.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S2.SS1.p1.1.11" style="font-size:90%;">. Although the datasets differ in size, they can both be effectively employed for cross-validation purposes.</span></p>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1"><span class="ltx_text ltx_font_typewriter" id="S2.SS1.p2.1.1" style="font-size:90%;">MLQE-PE</span><span class="ltx_text" id="S2.SS1.p2.1.2" style="font-size:90%;"> is a comprehensive dataset for MT QE and Automatic Post-Editing, covering eleven language pairs, including both high- and low-resource languages </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S2.SS1.p2.1.3.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#bib.bib6" title=""><span class="ltx_text" style="font-size:90%;">6</span></a><span class="ltx_text" id="S2.SS1.p2.1.4.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S2.SS1.p2.1.5" style="font-size:90%;">. The dataset features up to 10,000 translations per language pair, annotated with sentence-level direct assessments, post-editing effort, and word-level binary good/bad labels. Each source-translation pair includes the post-edited sentence, article titles, and details of the neural MT models used. The dataset is thoroughly documented and analyzed, and the information on the baseline system performances is included.</span></p>
</div>
<div class="ltx_para" id="S2.SS1.p3">
<p class="ltx_p" id="S2.SS1.p3.1"><span class="ltx_text" id="S2.SS1.p3.1.1" style="font-size:90%;">The main variables in the </span><span class="ltx_text ltx_font_typewriter" id="S2.SS1.p3.1.2" style="font-size:90%;">MLQE-PE</span><span class="ltx_text" id="S2.SS1.p3.1.3" style="font-size:90%;"> includes:
original (original sentence), translation (MT output),
scores (list of DA [direct assessment] scores by all annotators - the number of annotators may vary), mean (average of DA scores),
z_scores (list of z-standardized DA scores), z_mean (average of z-standardized DA scores), model_scores (NMT model score for sentence). The other information on sentence translation such as “hter” (human translation edit rate) is also included in the dataset. Note that “model_scores” is the the MT model’s confidence in its translation. According to MLQE-PE, these MT systems are SOTA ones, representing the recent advancements in MT models. In this way, “model_scores” signifies a direct indication of the translation’s reliability from MT, that is, the translation quality assessment. The higher scores represents the higher translation quality. Conversely, a lower “hter” indicates that a translation needs more human efforts to post-edit, that is, the translation quality is higher. Moreover, we also created some factors. For instance, the standard variation (sd) of different human scores for the same translation, and the human annotator number.</span></p>
</div>
<div class="ltx_para" id="S2.SS1.p4">
<p class="ltx_p" id="S2.SS1.p4.1"><span class="ltx_text" id="S2.SS1.p4.1.1" style="font-size:90%;">There are 11 language pairs available: English-German (en-de), English-Chinese (en-zh), Romanian-English (ro-en), Estonian-English (et-en), Nepalese-English (ne-en), Sinhala-English (si-en), and Russian-English (ru-en). </span><span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Although the paper on MLQE-PE claimed that their dataset also includes other language pairs, the dataset on these language pairs in the <span class="ltx_text ltx_font_typewriter" id="footnote1.1">github</span> they provided is not available.</span></span></span><span class="ltx_text" id="S2.SS1.p4.1.2" style="font-size:90%;"></span></p>
</div>
<div class="ltx_para" id="S2.SS1.p5">
<p class="ltx_p" id="S2.SS1.p5.1"><span class="ltx_text ltx_font_typewriter" id="S2.SS1.p5.1.1" style="font-size:90%;">PreQuEL</span><span class="ltx_text" id="S2.SS1.p5.1.2" style="font-size:90%;"> </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S2.SS1.p5.1.3.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#bib.bib5" title=""><span class="ltx_text" style="font-size:90%;">5</span></a><span class="ltx_text" id="S2.SS1.p5.1.4.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S2.SS1.p5.1.5" style="font-size:90%;"> includes a variety of datasets. However, we selected only the datasets for evaluating machine translation quality without reference translations. In this case, there are two language pairs: English-Chinese and English-German. The dataset includes the following variables: n-gram sentence probability, language model score, HTER, and human score (z_mean). “Sentence probability” refers to the likelihood of a particular sequence of words (sentence) occurring. This can be computed using n-grams. For example, if bi-grams are used, it is termed “bi-gram sentence probability”, and if tri-grams are used, it is “tri-gram sentence probability”. </span><span class="ltx_text ltx_font_typewriter" id="S2.SS1.p5.1.6" style="font-size:90%;">PreQuEL</span><span class="ltx_text" id="S2.SS1.p5.1.7" style="font-size:90%;"> provides five types of sentence probabilities using 1-5 grams.
The “language model score” is a metric related to the language probability score (“lan” is indicated in the </span><span class="ltx_text ltx_font_typewriter" id="S2.SS1.p5.1.8" style="font-size:90%;">PreQuEL</span><span class="ltx_text" id="S2.SS1.p5.1.9" style="font-size:90%;">). This score is part of the quality estimation process that evaluates how likely a translation is accurate based on linguistic features and models, without referencing the actual translated text. </span><span class="ltx_text ltx_font_typewriter" id="S2.SS1.p5.1.10" style="font-size:90%;">PreQuEL</span><span class="ltx_text" id="S2.SS1.p5.1.11" style="font-size:90%;"> also provides “hter”, which is computed using the same method as in </span><span class="ltx_text ltx_font_typewriter" id="S2.SS1.p5.1.12" style="font-size:90%;">MLQE-PE</span><span class="ltx_text" id="S2.SS1.p5.1.13" style="font-size:90%;">. Additionally, </span><span class="ltx_text ltx_font_typewriter" id="S2.SS1.p5.1.14" style="font-size:90%;">PreQuEL</span><span class="ltx_text" id="S2.SS1.p5.1.15" style="font-size:90%;"> provides only the “human score (z_mean)”.</span></p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Textual similarity</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1"><span class="ltx_text" id="S2.SS2.p1.1.1" style="font-size:90%;">Textual similarity (or sentence similarity) measures how similar or different two pieces of text are semantically. This can involve comparing sentences, paragraphs, or entire documents to see how closely they match in meaning or content. It can be calculated using various techniques, such as comparing word overlaps, semantic similarity, or using machine learning models to assess how alike the texts are. However, after transformers revolutionized deep learning, textual similarity can now be effectively measured using existing language models. </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S2.SS2.p1.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#bib.bib14" title=""><span class="ltx_text" style="font-size:90%;">14</span></a><span class="ltx_text" id="S2.SS2.p1.1.3.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S2.SS2.p1.1.4" style="font-size:90%;">, </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S2.SS2.p1.1.5.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#bib.bib4" title=""><span class="ltx_text" style="font-size:90%;">4</span></a><span class="ltx_text" id="S2.SS2.p1.1.6.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S2.SS2.p1.1.7" style="font-size:90%;">, </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S2.SS2.p1.1.8.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#bib.bib15" title=""><span class="ltx_text" style="font-size:90%;">15</span></a><span class="ltx_text" id="S2.SS2.p1.1.9.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S2.SS2.p1.1.10" style="font-size:90%;"></span></p>
</div>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1"><span class="ltx_text" id="S2.SS2.p2.1.1" style="font-size:90%;">Pretrained </span><span class="ltx_text ltx_font_typewriter" id="S2.SS2.p2.1.2" style="font-size:90%;">sentence transformers</span><span class="ltx_text" id="S2.SS2.p2.1.3" style="font-size:90%;"> are highly effective for generating sentence or textual embeddings due to their ability to capture deep semantic meanings </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S2.SS2.p2.1.4.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#bib.bib11" title=""><span class="ltx_text" style="font-size:90%;">11</span></a><span class="ltx_text" id="S2.SS2.p2.1.5.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S2.SS2.p2.1.6" style="font-size:90%;">. By leveraging the Transformer architecture, these models encode sentences into high-dimensional vectors that reflect their contextual and semantic content, rather than merely their lexical features. This allows for accurate comparisons of semantic similarity between sentences or texts, which is crucial for tasks like paraphrase detection, information retrieval, and clustering.</span></p>
</div>
<div class="ltx_para" id="S2.SS2.p3">
<p class="ltx_p" id="S2.SS2.p3.1"><span class="ltx_text" id="S2.SS2.p3.1.1" style="font-size:90%;">The “sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2” model creates dense vector representations of sentences, capturing the semantic essence of the text. These vectors are placed in a shared embedding space where similar meanings are mapped to nearby points. The model’s fine-tuning for tasks like paraphrase identification ensures that sentences with similar meanings are close in this space. The use of sentence transformers is particularly valuable in multilingual contexts, as they support multiple languages and capture semantic nuances effectively. The task in the current study is to understand the source text in one language and the translated texts in the other language. The capability of multilingual sentence transformer models is essential for applications to explore the semantic similarity among languages. The current study employs this multilingual sentence transformer model to compute semantic similarity for one source sentence and its translation. Our fundamental approach involves using the sentence transformer to generate text embeddings and then calculating their similarity using the cosine method. We applied the method to process the two datasets to compute “textual similarity” between a source text and its translated text. </span></p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Regression statistical analysis</h3>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1"><span class="ltx_text" id="S2.SS3.p1.1.1" style="font-size:90%;">We applied Generalized Additive Mixed Models (</span><span class="ltx_text ltx_font_bold" id="S2.SS3.p1.1.2" style="font-size:90%;">GAMM</span><span class="ltx_text" id="S2.SS3.p1.1.3" style="font-size:90%;">) in analyzing how factors influence human scores. GAMMs incorporate non-linear relationships between the dependent and independent variables through smooth functions </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S2.SS3.p1.1.4.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#bib.bib16" title=""><span class="ltx_text" style="font-size:90%;">16</span></a><span class="ltx_text" id="S2.SS3.p1.1.5.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S2.SS3.p1.1.6" style="font-size:90%;">. GAMMs allow for both fixed and random effects, accommodating complex variations within hierarchical data structures. The “additive” part of GAMM means that the model expresses the dependent variable as a sum of smooth functions of predictors, along with any random effects and an error term. This flexibility makes GAMMs particularly useful for modeling non-linear trends in data, where the effect of variables is not strictly linear and may vary by group or over time.</span></p>
</div>
<div class="ltx_para" id="S2.SS3.p2">
<p class="ltx_p" id="S2.SS3.p2.1"><span class="ltx_text" id="S2.SS3.p2.1.1" style="font-size:90%;">GAMM could leverage the function </span><span class="ltx_text ltx_font_typewriter" id="S2.SS3.p2.1.2" style="font-size:90%;">s()</span><span class="ltx_text" id="S2.SS3.p2.1.3" style="font-size:90%;">. This smooth function better gets model fittings for some factors, and the interaction smooth could find the interaction among some given factors. Some random variables could play a very important role, such as different language pairs in TM. The role of such random variables could be well explored by using GAMMs. GAMMs are friendly to make model comparison by referring to </span><span class="ltx_text ltx_font_typewriter" id="S2.SS3.p2.1.4" style="font-size:90%;">AIC</span><span class="ltx_text" id="S2.SS3.p2.1.5" style="font-size:90%;"> (Akaike information criterion is an estimator of prediction error).</span></p>
</div>
<div class="ltx_para" id="S2.SS3.p3">
<p class="ltx_p" id="S2.SS3.p3.1"><span class="ltx_text" id="S2.SS3.p3.1.1" style="font-size:90%;">In GAMM setups, the independent variable is “human score”, and other metrics are dependent variables. Some random factors, such as human evaluator number, different language pairs (source language - target language), could play an essential role </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" id="S2.SS3.p3.1.2.1" style="font-size:90%;">[</span><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#bib.bib1" title=""><span class="ltx_text" style="font-size:90%;">1</span></a><span class="ltx_text" id="S2.SS3.p3.1.3.2" style="font-size:90%;">]</span></cite><span class="ltx_text" id="S2.SS3.p3.1.4" style="font-size:90%;">. A GAMM fitting should include a number of factors. The reason for this is that various metrics or factor could predict human score or take effect on human score, and these factors co-work to play a role. The purpose of using GAMM fitting is to better explore how these factors take effects on human scores.</span></p>
</div>
</section>
</section>
<section class="ltx_section" id="S3" lang="en">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">3 </span>Results</h2>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Result 1: Correlations</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1"><span class="ltx_text" id="S3.SS1.p1.1.1" style="font-size:90%;">We plotted the Pearson correlations among various factors for </span><span class="ltx_text ltx_font_typewriter" id="S3.SS1.p1.1.2" style="font-size:90%;">MLQE-PE</span><span class="ltx_text" id="S3.SS1.p1.1.3" style="font-size:90%;">, as shown in Fig. </span><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#S3.F1" style="font-size:90%;" title="Figure 1 ‣ 3.1 Result 1: Correlations ‣ 3 Results ‣ Textual Similarity as a Key Metric in Machine Translation Quality Estimation"><span class="ltx_text ltx_ref_tag">1</span></a><span class="ltx_text" id="S3.SS1.p1.1.4" style="font-size:90%;">. The results indicate that “ML_eval” is correlated with the human score (mean) at 0.15, with “hter” at 0.06, and with the human score (z-mean) at 0.3. “Textual similarity” shows a correlation of 0.47 with the human score (mean), -0.06 with the human score (z-mean), -0.45 with “hter”, and -0.21 with “ML_eval”. Overall, “textual similarity” exhibits stronger correlations with other factors compared to “ML_eval”.</span></p>
</div>
<figure class="ltx_figure" id="S3.F1"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="817" id="S3.F1.g1" src="x1.png" width="817"/>
<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>correlations among various factors in <span class="ltx_text ltx_font_typewriter" id="S3.F1.5.1">MLQE-PE</span> </figcaption>
</figure>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1"><span class="ltx_text" id="S3.SS1.p2.1.1" style="font-size:90%;">Similarly, we plotted the correlation among various factors for </span><span class="ltx_text ltx_font_typewriter" id="S3.SS1.p2.1.2" style="font-size:90%;">PreQuEL</span><span class="ltx_text" id="S3.SS1.p2.1.3" style="font-size:90%;">, as shown in Fig </span><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#Ax1.F4" style="font-size:90%;" title="Figure 4 ‣ Appendix ‣ Textual Similarity as a Key Metric in Machine Translation Quality Estimation"><span class="ltx_text ltx_ref_tag">4</span></a><span class="ltx_text" id="S3.SS1.p2.1.4" style="font-size:90%;"> (see the Appendix). The three variables: “n-gram sentence probability”, “hter”, and “textual similarity”, show similar correlation values with the “human score (z_mean)”, each approximately 0.15.</span></p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Result 2: Cross language pairs</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1"><span class="ltx_text" id="S3.SS2.p1.1.1" style="font-size:90%;">We established three types of GAMM fittings for </span><span class="ltx_text ltx_font_typewriter" id="S3.SS2.p1.1.2" style="font-size:90%;">MLQE-PE</span><span class="ltx_text" id="S3.SS2.p1.1.3" style="font-size:90%;">, where “human score (mean)” is the independent variable, and other factors include “ML_eval”, “textual similarity”, “sd of human scores”. “human evaluator number”, “language pairs (langs)” are incorporated as random variables. We chose “human score (mean)” over “human score (z-mean)” as the independent variable primarily because “human score (mean)” closely follows a normal distribution. The GAMM setups are detailed below, and the results are presented in Table </span><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#S3.T1" style="font-size:90%;" title="Table 1 ‣ 3.2 Result 2: Cross language pairs ‣ 3 Results ‣ Textual Similarity as a Key Metric in Machine Translation Quality Estimation"><span class="ltx_text ltx_ref_tag">1</span></a><span class="ltx_text" id="S3.SS2.p1.1.4" style="font-size:90%;">.</span></p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<ul class="ltx_itemize" id="S3.I1">
<li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I1.i1.p1">
<p class="ltx_p" id="S3.I1.i1.p1.1"><span class="ltx_text" id="S3.I1.i1.p1.1.1" style="font-size:90%;">base model = bam(human score </span><math alttext="\sim" class="ltx_Math" display="inline" id="S3.I1.i1.p1.1.m1.1"><semantics id="S3.I1.i1.p1.1.m1.1a"><mo id="S3.I1.i1.p1.1.m1.1.1" mathsize="90%" xref="S3.I1.i1.p1.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S3.I1.i1.p1.1.m1.1b"><csymbol cd="latexml" id="S3.I1.i1.p1.1.m1.1.1.cmml" xref="S3.I1.i1.p1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i1.p1.1.m1.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i1.p1.1.m1.1d">∼</annotation></semantics></math><span class="ltx_text" id="S3.I1.i1.p1.1.2" style="font-size:90%;"> s(ML_eval)+s(textual similarity)+s(sd)+</span>
<br class="ltx_break"/><span class="ltx_text" id="S3.I1.i1.p1.1.3" style="font-size:90%;">s(hter)+s(evaluator num, bs=“re”)+s(langs, bs=“re”))</span></p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I1.i2.p1">
<p class="ltx_p" id="S3.I1.i2.p1.1"><span class="ltx_text" id="S3.I1.i2.p1.1.1" style="font-size:90%;">m1=bam(human score </span><math alttext="\sim" class="ltx_Math" display="inline" id="S3.I1.i2.p1.1.m1.1"><semantics id="S3.I1.i2.p1.1.m1.1a"><mo id="S3.I1.i2.p1.1.m1.1.1" mathsize="90%" xref="S3.I1.i2.p1.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S3.I1.i2.p1.1.m1.1b"><csymbol cd="latexml" id="S3.I1.i2.p1.1.m1.1.1.cmml" xref="S3.I1.i2.p1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i2.p1.1.m1.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i2.p1.1.m1.1d">∼</annotation></semantics></math><span class="ltx_text" id="S3.I1.i2.p1.1.2" style="font-size:90%;"> s(ML_eval)+s(sd)+s(hter)+s(evaluator num, bs=“re”)</span>
<br class="ltx_break"/><span class="ltx_text" id="S3.I1.i2.p1.1.3" style="font-size:90%;">+s(langs, bs=“re”))</span></p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I1.i3.p1">
<p class="ltx_p" id="S3.I1.i3.p1.1"><span class="ltx_text" id="S3.I1.i3.p1.1.1" style="font-size:90%;">m2=bam(human score </span><math alttext="\sim" class="ltx_Math" display="inline" id="S3.I1.i3.p1.1.m1.1"><semantics id="S3.I1.i3.p1.1.m1.1a"><mo id="S3.I1.i3.p1.1.m1.1.1" mathsize="90%" xref="S3.I1.i3.p1.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S3.I1.i3.p1.1.m1.1b"><csymbol cd="latexml" id="S3.I1.i3.p1.1.m1.1.1.cmml" xref="S3.I1.i3.p1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i3.p1.1.m1.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i3.p1.1.m1.1d">∼</annotation></semantics></math><span class="ltx_text" id="S3.I1.i3.p1.1.2" style="font-size:90%;"> s(textual similarity)+s(sd)+s(hter)+s(evaluato num, bs=“re”)+s(langs, bs=“re”))</span></p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I1.i4.p1">
<p class="ltx_p" id="S3.I1.i4.p1.1"><span class="ltx_text" id="S3.I1.i4.p1.1.1" style="font-size:90%;">m3=bam(human score </span><math alttext="\sim" class="ltx_Math" display="inline" id="S3.I1.i4.p1.1.m1.1"><semantics id="S3.I1.i4.p1.1.m1.1a"><mo id="S3.I1.i4.p1.1.m1.1.1" mathsize="90%" xref="S3.I1.i4.p1.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S3.I1.i4.p1.1.m1.1b"><csymbol cd="latexml" id="S3.I1.i4.p1.1.m1.1.1.cmml" xref="S3.I1.i4.p1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i4.p1.1.m1.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S3.I1.i4.p1.1.m1.1d">∼</annotation></semantics></math><span class="ltx_text" id="S3.I1.i4.p1.1.2" style="font-size:90%;"> s(ML_eval)+s(textual similarity)+s(sd)+s(evaluator num, bs=“re”)+s(langs, bs=“re”))</span></p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.3"><span class="ltx_text" id="S3.SS2.p3.3.1" style="font-size:90%;">The base model demonstrates the best performance when all factors are included. However, each of the remaining models includes only a subset of these factors. The Akaike Information Criterion (AIC) is used to represent the performance of this GAMM fitting. The base model has the lowest AIC. When the AIC of model </span><math alttext="m1" class="ltx_Math" display="inline" id="S3.SS2.p3.1.m1.1"><semantics id="S3.SS2.p3.1.m1.1a"><mrow id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml"><mi id="S3.SS2.p3.1.m1.1.1.2" mathsize="90%" xref="S3.SS2.p3.1.m1.1.1.2.cmml">m</mi><mo id="S3.SS2.p3.1.m1.1.1.1" xref="S3.SS2.p3.1.m1.1.1.1.cmml">⁢</mo><mn id="S3.SS2.p3.1.m1.1.1.3" mathsize="90%" xref="S3.SS2.p3.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><apply id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1"><times id="S3.SS2.p3.1.m1.1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1.1"></times><ci id="S3.SS2.p3.1.m1.1.1.2.cmml" xref="S3.SS2.p3.1.m1.1.1.2">𝑚</ci><cn id="S3.SS2.p3.1.m1.1.1.3.cmml" type="integer" xref="S3.SS2.p3.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">m1</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.1.m1.1d">italic_m 1</annotation></semantics></math><span class="ltx_text" id="S3.SS2.p3.3.2" style="font-size:90%;"> is subtracted from the AIC of the base model, the resulting </span><math alttext="\Delta" class="ltx_Math" display="inline" id="S3.SS2.p3.2.m2.1"><semantics id="S3.SS2.p3.2.m2.1a"><mi id="S3.SS2.p3.2.m2.1.1" mathsize="90%" mathvariant="normal" xref="S3.SS2.p3.2.m2.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m2.1b"><ci id="S3.SS2.p3.2.m2.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m2.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.2.m2.1d">roman_Δ</annotation></semantics></math><span class="ltx_text" id="S3.SS2.p3.3.3" style="font-size:90%;">AIC indicates the contribution of “textual similarity”, as “m1” does not include “textual similarity” compared to the base model. A smaller </span><math alttext="\Delta" class="ltx_Math" display="inline" id="S3.SS2.p3.3.m3.1"><semantics id="S3.SS2.p3.3.m3.1a"><mi id="S3.SS2.p3.3.m3.1.1" mathsize="90%" mathvariant="normal" xref="S3.SS2.p3.3.m3.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.3.m3.1b"><ci id="S3.SS2.p3.3.m3.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.3.m3.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.3.m3.1d">roman_Δ</annotation></semantics></math><span class="ltx_text" id="S3.SS2.p3.3.4" style="font-size:90%;">AIC also indicates better performance and greater contribution for a given factor. The results are shown in Table </span><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#S3.T1" style="font-size:90%;" title="Table 1 ‣ 3.2 Result 2: Cross language pairs ‣ 3 Results ‣ Textual Similarity as a Key Metric in Machine Translation Quality Estimation"><span class="ltx_text ltx_ref_tag">1</span></a><span class="ltx_text" id="S3.SS2.p3.3.5" style="font-size:90%;">.</span></p>
</div>
<figure class="ltx_table" id="S3.T1">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 1: </span><math alttext="\Delta" class="ltx_Math" display="inline" id="S3.T1.3.m1.1"><semantics id="S3.T1.3.m1.1b"><mi id="S3.T1.3.m1.1.1" mathvariant="normal" xref="S3.T1.3.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S3.T1.3.m1.1c"><ci id="S3.T1.3.m1.1.1.cmml" xref="S3.T1.3.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.3.m1.1d">\Delta</annotation><annotation encoding="application/x-llamapun" id="S3.T1.3.m1.1e">roman_Δ</annotation></semantics></math>AIC for different GAMM fittings for <span class="ltx_text ltx_font_typewriter" id="S3.T1.11.1">MLQE-PE</span>. A smaller <math alttext="\Delta" class="ltx_Math" display="inline" id="S3.T1.4.m2.1"><semantics id="S3.T1.4.m2.1b"><mi id="S3.T1.4.m2.1.1" mathvariant="normal" xref="S3.T1.4.m2.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S3.T1.4.m2.1c"><ci id="S3.T1.4.m2.1.1.cmml" xref="S3.T1.4.m2.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.4.m2.1d">\Delta</annotation><annotation encoding="application/x-llamapun" id="S3.T1.4.m2.1e">roman_Δ</annotation></semantics></math>AIC indicates better performance (n=45886)</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S3.T1.5">
<tr class="ltx_tr" id="S3.T1.5.1">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.5.1.2"><span class="ltx_text" id="S3.T1.5.1.2.1" style="font-size:90%;">factor (contribution)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.5.1.1">
<math alttext="\Delta" class="ltx_Math" display="inline" id="S3.T1.5.1.1.m1.1"><semantics id="S3.T1.5.1.1.m1.1a"><mi id="S3.T1.5.1.1.m1.1.1" mathsize="90%" mathvariant="normal" xref="S3.T1.5.1.1.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S3.T1.5.1.1.m1.1b"><ci id="S3.T1.5.1.1.m1.1.1.cmml" xref="S3.T1.5.1.1.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.5.1.1.m1.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="S3.T1.5.1.1.m1.1d">roman_Δ</annotation></semantics></math><span class="ltx_text" id="S3.T1.5.1.1.1" style="font-size:90%;">AIC</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T1.5.2">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_tt" id="S3.T1.5.2.1"><span class="ltx_text" id="S3.T1.5.2.1.1" style="font-size:90%;">(m1- base model) contribution of textual similarity</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S3.T1.5.2.2"><span class="ltx_text" id="S3.T1.5.2.2.1" style="font-size:90%;">848.87</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.5.3">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.5.3.1"><span class="ltx_text" id="S3.T1.5.3.1.1" style="font-size:90%;">(m2- base model) contribution of ML_eval</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.5.3.2"><span class="ltx_text" id="S3.T1.5.3.2.1" style="font-size:90%;">8785.82</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.5.4">
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.5.4.1"><span class="ltx_text" id="S3.T1.5.4.1.1" style="font-size:90%;">(m3-base model) contribution of hter</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T1.5.4.2"><span class="ltx_text" id="S3.T1.5.4.2.1" style="font-size:90%;">586.3</span></td>
</tr>
</table>
</figure>
<div class="ltx_para" id="S3.SS2.p4">
<p class="ltx_p" id="S3.SS2.p4.1"><span class="ltx_text" id="S3.SS2.p4.1.1" style="font-size:90%;">The contribution from “textual similarity” outperforms that from “ML_eval”. However, the contribution of “hter” shows the best performance overall. This trend holds for all language pairs. Despite this, it is important to examine the performance for individual language pairs. The next section explores the performance of these factors in each language pair.</span></p>
</div>
<div class="ltx_para" id="S3.SS2.p5">
<p class="ltx_p" id="S3.SS2.p5.1"><span class="ltx_text" id="S3.SS2.p5.1.1" style="font-size:90%;">Next, we used similar GAMM methods to explore how different metrics affect human scores for </span><span class="ltx_text ltx_font_typewriter" id="S3.SS2.p5.1.2" style="font-size:90%;">PreQuEL</span><span class="ltx_text" id="S3.SS2.p5.1.3" style="font-size:90%;">. In the </span><span class="ltx_text ltx_font_typewriter" id="S3.SS2.p5.1.4" style="font-size:90%;">PreQuEL</span><span class="ltx_text" id="S3.SS2.p5.1.5" style="font-size:90%;"> dataset, “human score (z_mean)” is the dependent variable </span><span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>In this dataset, “human score (mean)” is not available.</span></span></span><span class="ltx_text" id="S3.SS2.p5.1.6" style="font-size:90%;">, and other factors include “n-gram sentence probability”, “language model score”, “hter”, and “textual similarity”. In this dataset, “language model score” (“lm_score”) has four values, so we treat it as a random factor, and “language pairs” (“langs”) are incorporated as a random variable. There are five types of “n-gram sentence probability”; however, we chose the optimal one, “trigram sentence probability”,"for the GAMM fittings. The GAMM setups are detailed below, and the results are presented in Table </span><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#S3.T2" style="font-size:90%;" title="Table 2 ‣ 3.2 Result 2: Cross language pairs ‣ 3 Results ‣ Textual Similarity as a Key Metric in Machine Translation Quality Estimation"><span class="ltx_text ltx_ref_tag">2</span></a><span class="ltx_text" id="S3.SS2.p5.1.7" style="font-size:90%;">.</span></p>
</div>
<div class="ltx_para" id="S3.SS2.p6">
<ul class="ltx_itemize" id="S3.I2">
<li class="ltx_item" id="S3.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I2.i1.p1">
<p class="ltx_p" id="S3.I2.i1.p1.1"><span class="ltx_text" id="S3.I2.i1.p1.1.1" style="font-size:90%;">base model = bam(human score </span><math alttext="\sim" class="ltx_Math" display="inline" id="S3.I2.i1.p1.1.m1.1"><semantics id="S3.I2.i1.p1.1.m1.1a"><mo id="S3.I2.i1.p1.1.m1.1.1" mathsize="90%" xref="S3.I2.i1.p1.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S3.I2.i1.p1.1.m1.1b"><csymbol cd="latexml" id="S3.I2.i1.p1.1.m1.1.1.cmml" xref="S3.I2.i1.p1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i1.p1.1.m1.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S3.I2.i1.p1.1.m1.1d">∼</annotation></semantics></math><span class="ltx_text" id="S3.I2.i1.p1.1.2" style="font-size:90%;"> s(trigram sent prob)+s(textual </span>
<br class="ltx_break"/><span class="ltx_text" id="S3.I2.i1.p1.1.3" style="font-size:90%;">similarity)+s(hter) +s(lm_score, bs=“re”)+s(langs, bs=“re”))</span></p>
</div>
</li>
<li class="ltx_item" id="S3.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I2.i2.p1">
<p class="ltx_p" id="S3.I2.i2.p1.1"><span class="ltx_text" id="S3.I2.i2.p1.1.1" style="font-size:90%;">t1=bam(human score </span><math alttext="\sim" class="ltx_Math" display="inline" id="S3.I2.i2.p1.1.m1.1"><semantics id="S3.I2.i2.p1.1.m1.1a"><mo id="S3.I2.i2.p1.1.m1.1.1" mathsize="90%" xref="S3.I2.i2.p1.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S3.I2.i2.p1.1.m1.1b"><csymbol cd="latexml" id="S3.I2.i2.p1.1.m1.1.1.cmml" xref="S3.I2.i2.p1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i2.p1.1.m1.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S3.I2.i2.p1.1.m1.1d">∼</annotation></semantics></math><span class="ltx_text" id="S3.I2.i2.p1.1.2" style="font-size:90%;"> s(trigram sent prob)+s(hter)+s(lm_score, bs=“re”)</span>
<br class="ltx_break"/><span class="ltx_text" id="S3.I2.i2.p1.1.3" style="font-size:90%;">+s(langs, bs=“re”))</span></p>
</div>
</li>
<li class="ltx_item" id="S3.I2.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I2.i3.p1">
<p class="ltx_p" id="S3.I2.i3.p1.1"><span class="ltx_text" id="S3.I2.i3.p1.1.1" style="font-size:90%;">t2=bam(human score </span><math alttext="\sim" class="ltx_Math" display="inline" id="S3.I2.i3.p1.1.m1.1"><semantics id="S3.I2.i3.p1.1.m1.1a"><mo id="S3.I2.i3.p1.1.m1.1.1" mathsize="90%" xref="S3.I2.i3.p1.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S3.I2.i3.p1.1.m1.1b"><csymbol cd="latexml" id="S3.I2.i3.p1.1.m1.1.1.cmml" xref="S3.I2.i3.p1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i3.p1.1.m1.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S3.I2.i3.p1.1.m1.1d">∼</annotation></semantics></math><span class="ltx_text" id="S3.I2.i3.p1.1.2" style="font-size:90%;"> s(textual similarity)+s(hter)+s(lm_score, bs=“re”)</span>
<br class="ltx_break"/><span class="ltx_text" id="S3.I2.i3.p1.1.3" style="font-size:90%;">+s(langs, bs=“re”))</span></p>
</div>
</li>
<li class="ltx_item" id="S3.I2.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I2.i4.p1">
<p class="ltx_p" id="S3.I2.i4.p1.1"><span class="ltx_text" id="S3.I2.i4.p1.1.1" style="font-size:90%;">t3=bam(human score </span><math alttext="\sim" class="ltx_Math" display="inline" id="S3.I2.i4.p1.1.m1.1"><semantics id="S3.I2.i4.p1.1.m1.1a"><mo id="S3.I2.i4.p1.1.m1.1.1" mathsize="90%" xref="S3.I2.i4.p1.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S3.I2.i4.p1.1.m1.1b"><csymbol cd="latexml" id="S3.I2.i4.p1.1.m1.1.1.cmml" xref="S3.I2.i4.p1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.I2.i4.p1.1.m1.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S3.I2.i4.p1.1.m1.1d">∼</annotation></semantics></math><span class="ltx_text" id="S3.I2.i4.p1.1.2" style="font-size:90%;"> s(trigram sent prob)+s(textual similarity)</span>
<br class="ltx_break"/><span class="ltx_text" id="S3.I2.i4.p1.1.3" style="font-size:90%;">+s(lm_score, bs=“re”)+s(langs, bs=“re”))</span></p>
</div>
</li>
</ul>
</div>
<figure class="ltx_table" id="S3.T2">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 2: </span><math alttext="\Delta" class="ltx_Math" display="inline" id="S3.T2.3.m1.1"><semantics id="S3.T2.3.m1.1b"><mi id="S3.T2.3.m1.1.1" mathvariant="normal" xref="S3.T2.3.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S3.T2.3.m1.1c"><ci id="S3.T2.3.m1.1.1.cmml" xref="S3.T2.3.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.3.m1.1d">\Delta</annotation><annotation encoding="application/x-llamapun" id="S3.T2.3.m1.1e">roman_Δ</annotation></semantics></math>AIC for different GAMM fittings for <span class="ltx_text ltx_font_typewriter" id="S3.T2.11.1">PreQuEL</span>. A smaller <math alttext="\Delta" class="ltx_Math" display="inline" id="S3.T2.4.m2.1"><semantics id="S3.T2.4.m2.1b"><mi id="S3.T2.4.m2.1.1" mathvariant="normal" xref="S3.T2.4.m2.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S3.T2.4.m2.1c"><ci id="S3.T2.4.m2.1.1.cmml" xref="S3.T2.4.m2.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.4.m2.1d">\Delta</annotation><annotation encoding="application/x-llamapun" id="S3.T2.4.m2.1e">roman_Δ</annotation></semantics></math>AIC indicates better performance (n=14706)</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S3.T2.5">
<tr class="ltx_tr" id="S3.T2.5.1">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.5.1.2"><span class="ltx_text" id="S3.T2.5.1.2.1" style="font-size:90%;">factor (contribution)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.5.1.1">
<math alttext="\Delta" class="ltx_Math" display="inline" id="S3.T2.5.1.1.m1.1"><semantics id="S3.T2.5.1.1.m1.1a"><mi id="S3.T2.5.1.1.m1.1.1" mathsize="90%" mathvariant="normal" xref="S3.T2.5.1.1.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S3.T2.5.1.1.m1.1b"><ci id="S3.T2.5.1.1.m1.1.1.cmml" xref="S3.T2.5.1.1.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.5.1.1.m1.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="S3.T2.5.1.1.m1.1d">roman_Δ</annotation></semantics></math><span class="ltx_text" id="S3.T2.5.1.1.1" style="font-size:90%;">AIC</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T2.5.2">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_tt" id="S3.T2.5.2.1"><span class="ltx_text" id="S3.T2.5.2.1.1" style="font-size:90%;">(t1- base model) contribution of textual similarity</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S3.T2.5.2.2"><span class="ltx_text" id="S3.T2.5.2.2.1" style="font-size:90%;">237.11</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.5.3">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.5.3.1"><span class="ltx_text" id="S3.T2.5.3.1.1" style="font-size:90%;">(t2- base model) contribution of trigram sentence probability</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.5.3.2"><span class="ltx_text" id="S3.T2.5.3.2.1" style="font-size:90%;">232.16</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.5.4">
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="S3.T2.5.4.1"><span class="ltx_text" id="S3.T2.5.4.1.1" style="font-size:90%;">(t3-base model) contribution of hter</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T2.5.4.2"><span class="ltx_text" id="S3.T2.5.4.2.1" style="font-size:90%;">424.29</span></td>
</tr>
</table>
</figure>
<div class="ltx_para" id="S3.SS2.p7">
<p class="ltx_p" id="S3.SS2.p7.1"><span class="ltx_text" id="S3.SS2.p7.1.1" style="font-size:90%;">The contribution of “textual similarity” outperforms that of “hter”. However, the contribution of “trigram sentence probability” shows a similar performance to “textual similarity”, with “trigram sentence probability” demonstrating the best performance overall. The next section examines the performance for individual language pairs.</span></p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection" style="font-size:90%;">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Result 3: Individual language pair</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1"><span class="ltx_text" id="S3.SS3.p1.1.1" style="font-size:90%;">Using a similar GAMM setup as the base model, we explore how these factors perform across seven language pairs for </span><span class="ltx_text ltx_font_typewriter" id="S3.SS3.p1.1.2" style="font-size:90%;">MLQE-PE</span><span class="ltx_text" id="S3.SS3.p1.1.3" style="font-size:90%;">. For each language pair, we established the same GAMM and plotted the partial effects for each factor of interest, as shown in Figure </span><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#S3.F2" style="font-size:90%;" title="Figure 2 ‣ 3.3 Result 3: Individual language pair ‣ 3 Results ‣ Textual Similarity as a Key Metric in Machine Translation Quality Estimation"><span class="ltx_text ltx_ref_tag">2</span></a><span class="ltx_text" id="S3.SS3.p1.1.4" style="font-size:90%;">. When the </span><span class="ltx_text ltx_font_italic" id="S3.SS3.p1.1.5" style="font-size:90%;">p</span><span class="ltx_text" id="S3.SS3.p1.1.6" style="font-size:90%;">-value is greater than 0.05, the plot is not significant. Within the same language pair, a smaller </span><math alttext="\Delta" class="ltx_Math" display="inline" id="S3.SS3.p1.1.m1.1"><semantics id="S3.SS3.p1.1.m1.1a"><mi id="S3.SS3.p1.1.m1.1.1" mathsize="90%" mathvariant="normal" xref="S3.SS3.p1.1.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><ci id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.1.m1.1d">roman_Δ</annotation></semantics></math><span class="ltx_text" id="S3.SS3.p1.1.7" style="font-size:90%;">AIC indicates better performance. Clearly, all cases for “ML_eval” are significant, and there is only one insignificant case for “textual similarity”. In contrast, “hter” has only two significant cases, indicating five insignificant cases.</span></p>
</div>
<div class="ltx_para" id="S3.SS3.p2">
<p class="ltx_p" id="S3.SS3.p2.1"><span class="ltx_text" id="S3.SS3.p2.1.1" style="font-size:90%;">Compared with “ML_eval”, “textual similarity” outperforms in the cases of “German-English”, "English-Chinese”, “Romanian-English”, “Russian-English” and “Sinhala-English”. Generally, “textual similarity” demonstrates the best performance across individual language pairs.</span></p>
</div>
<figure class="ltx_figure" id="S3.F2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="504" id="S3.F2.g1" src="x2.png" width="904"/>
<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>The partial effects on human score from different factors for <span class="ltx_text ltx_font_typewriter" id="S3.F2.11.1">MLQE-PE</span>. The <span class="ltx_text ltx_font_italic" id="S3.F2.12.2">x</span>-axis represents the specific metric being analyzed, while the <span class="ltx_text ltx_font_italic" id="S3.F2.13.3">y</span>-axis indicates human score. Each curve within a plot illustrates the relationship between a predictor variable (plotted on the <span class="ltx_text ltx_font_italic" id="S3.F2.14.4">x</span>-axis) and the response variable. Steeper slopes on these curves indicate a stronger influence of the predictor variable on human score. Conversely, gentler slopes imply a weaker influence, indicating that changes in the predictor variable have a less pronounced effect on human score. Such plots could give deep insights on the relationship between one given metric and human score.
</figcaption>
</figure>
<div class="ltx_para" id="S3.SS3.p3">
<p class="ltx_p" id="S3.SS3.p3.1"><span class="ltx_text" id="S3.SS3.p3.1.1" style="font-size:90%;">Adopting the similar GAMM fittings for </span><span class="ltx_text ltx_font_typewriter" id="S3.SS3.p3.1.2" style="font-size:90%;">PreQuEL</span><span class="ltx_text" id="S3.SS3.p3.1.3" style="font-size:90%;">, we explored the performance for each variable of our interest in each language pair, and plotted the partial effects for each factor of interest, as shown in Figure </span><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#S3.F3" style="font-size:90%;" title="Figure 3 ‣ 3.3 Result 3: Individual language pair ‣ 3 Results ‣ Textual Similarity as a Key Metric in Machine Translation Quality Estimation"><span class="ltx_text ltx_ref_tag">3</span></a><span class="ltx_text" id="S3.SS3.p3.1.4" style="font-size:90%;">. Figure </span><a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#S3.F3" style="font-size:90%;" title="Figure 3 ‣ 3.3 Result 3: Individual language pair ‣ 3 Results ‣ Textual Similarity as a Key Metric in Machine Translation Quality Estimation"><span class="ltx_text ltx_ref_tag">3</span></a><span class="ltx_text" id="S3.SS3.p3.1.5" style="font-size:90%;"> shows that “ textual similariy” has the best performance in each individual language pair.</span></p>
</div>
<figure class="ltx_figure" id="S3.F3"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="549" id="S3.F3.g1" src="x3.png" width="686"/>
<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>The partial effects on human score from different factors for <span class="ltx_text ltx_font_typewriter" id="S3.F3.17.1">PreQuEL</span>. The <span class="ltx_text ltx_font_italic" id="S3.F3.18.2">x</span>-axis represents the specific metric being analyzed, while the <span class="ltx_text ltx_font_italic" id="S3.F3.19.3">y</span>-axis indicates the human score. The interpretation of the curve is the same as in Fig <a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#S3.F2" title="Figure 2 ‣ 3.3 Result 3: Individual language pair ‣ 3 Results ‣ Textual Similarity as a Key Metric in Machine Translation Quality Estimation"><span class="ltx_text ltx_ref_tag">2</span></a>. The layout here differs slightly from that in Fig <a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#S3.F2" title="Figure 2 ‣ 3.3 Result 3: Individual language pair ‣ 3 Results ‣ Textual Similarity as a Key Metric in Machine Translation Quality Estimation"><span class="ltx_text ltx_ref_tag">2</span></a>. <math alttext="\Delta" class="ltx_Math" display="inline" id="S3.F3.3.m1.1"><semantics id="S3.F3.3.m1.1b"><mi id="S3.F3.3.m1.1.1" mathvariant="normal" xref="S3.F3.3.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S3.F3.3.m1.1c"><ci id="S3.F3.3.m1.1.1.cmml" xref="S3.F3.3.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.3.m1.1d">\Delta</annotation><annotation encoding="application/x-llamapun" id="S3.F3.3.m1.1e">roman_Δ</annotation></semantics></math>AIC values are compared among three plots for the same language pairs. A lower <math alttext="\Delta" class="ltx_Math" display="inline" id="S3.F3.4.m2.1"><semantics id="S3.F3.4.m2.1b"><mi id="S3.F3.4.m2.1.1" mathvariant="normal" xref="S3.F3.4.m2.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S3.F3.4.m2.1c"><ci id="S3.F3.4.m2.1.1.cmml" xref="S3.F3.4.m2.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.4.m2.1d">\Delta</annotation><annotation encoding="application/x-llamapun" id="S3.F3.4.m2.1e">roman_Δ</annotation></semantics></math>AIC value indicates better performance.</figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S4" lang="en">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">
<span class="ltx_tag ltx_tag_section">4 </span>Discussion</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1"><span class="ltx_text" id="S4.p1.1.1" style="font-size:90%;">Considering the correlation in </span><span class="ltx_text ltx_font_typewriter" id="S4.p1.1.2" style="font-size:90%;">MLQE-PE</span><span class="ltx_text" id="S4.p1.1.3" style="font-size:90%;">, we found that “textual similarity” exhibits a strong correlation with human scores, “ML_eval”, and “hter”. In contrast, “ML_eval” shows a weaker correlation with the human score (mean). When examining the GAMM fittings across various language pairs and in each case of language pair, the performance of “textual similarity” surpasses that of “ML_eval”. On an individual language pair basis, “textual similarity” also outperforms both “ML_eval” and “hter”. In </span><span class="ltx_text ltx_font_typewriter" id="S4.p1.1.4" style="font-size:90%;">PreQuEL</span><span class="ltx_text" id="S4.p1.1.5" style="font-size:90%;">, due to the smaller sample size, the differences in correlation are not obvious. In short, “textual similarity” as a metric could be closely correlated with human score, and is highly capable of predicting human score.</span></p>
</div>
<div class="ltx_para" id="S4.p2">
<p class="ltx_p" id="S4.p2.1"><span class="ltx_text" id="S4.p2.1.1" style="font-size:90%;">The following provides a detailed analysis of each metric in </span><span class="ltx_text ltx_font_typewriter" id="S4.p2.1.2" style="font-size:90%;">MLQE-PE</span><span class="ltx_text" id="S4.p2.1.3" style="font-size:90%;">. “ML_eval” demonstrates a significant impact across all language pairs, indicating that this metric is both useful and effective for QE. However, “hter” does not show a significant impact on human scores in the most cases, suggesting that this metric may not be suitable for evaluating MT quality in certain language pairs. On the other hand, “textual similarity” predicts human scores in the majority of language pairs, highlighting its potential as an effective metric for QE.</span></p>
</div>
<div class="ltx_para" id="S4.p3">
<p class="ltx_p" id="S4.p3.1"><span class="ltx_text" id="S4.p3.1.1" style="font-size:90%;">The present study underscores the importance of selecting appropriate metrics for QE. “Textual similarity”, in particular, emerges as a robust and reliable metric that consistently correlates with human evaluation scores and effectively predict human scores, making it a valuable tool for improving the accuracy of QE. In contrast, while “ML_eval” remains a useful metric, its effectiveness varies across different language pairs. “hter”, despite being commonly used, may not be sufficient in some cases, necessitating the consideration of alternative or supplementary metrics like textual similarity.</span></p>
</div>
<div class="ltx_para" id="S4.p4">
<p class="ltx_p" id="S4.p4.1"><span class="ltx_text" id="S4.p4.1.1" style="font-size:90%;">Next, we analyzed the performance of “textual similarity” in </span><span class="ltx_text ltx_font_typewriter" id="S4.p4.1.2" style="font-size:90%;">PreQuEL</span><span class="ltx_text" id="S4.p4.1.3" style="font-size:90%;">. “textual similarity” outperforms “hter” consistently across language and within invidiual languages. However, “textual similarity” has the similar performance with “n-gram sentence probability”. It also reveals that “n-gram sentence probability” may be a useful metric in evaluating MT QE.</span></p>
</div>
<div class="ltx_para" id="S4.p5">
<p class="ltx_p" id="S4.p5.1"><span class="ltx_text" id="S4.p5.1.1" style="font-size:90%;">It is easy to understand why textual similarity is such an effective metric. When a translated text is semantically close to the source text, it indicates that the translation meets a crucial standard of quality: the meaning of the translation should closely match the original text. In contrast, the “hter” metric often fails for most language pairs because post-editing efforts do not necessarily reflect changes in meaning. For example, a translation may be very close in meaning to the original text but contain some misspellings. Humans may still consider the translation to be good, even though the post-edit rate is low due to the necessary corrections. Conversely, minor edits to core verbs or key words in a translation text may require minimal edit effort but significantly alter the meaning. However, such a translation text does not necessarily meet the standard of good translation. This discrepancy shows that post-edit rate does not always correlate with translation quality.</span></p>
</div>
<div class="ltx_para" id="S4.p6">
<p class="ltx_p" id="S4.p6.1"><span class="ltx_text" id="S4.p6.1.1" style="font-size:90%;">Therefore, exploring the cognitive recognition of what constitutes a good translation for different language users is worthwhile. Understanding this can significantly enhance both machine translation and quality estimation processes by aligning them more closely with human judgments of translation quality. For instance, "n-gram sentence probability" can provide an initial impression of the naturalness or readability of translated texts. If this metric is low, human evaluators might rate the quality of the translations poorly, regardless of how closely they match the original meaning. Simple yet effective metrics should be considered in evaluating machine translation quality, incorporating factors that align with human translation assessment standards and processes. This approach can lead to substantial progress in machine translation quality estimation (MT QE).</span></p>
</div>
<div class="ltx_para" id="S4.p7">
<p class="ltx_p" id="S4.p7.1"><span class="ltx_text" id="S4.p7.1.1" style="font-size:90%;">To date, “textual similarity” has not been proposed as a metric in QE </span><span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>Although some studies have proposed using semantic similarity to evaluate MT quality, they have only applied this method in cases where reference translations are provided <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#bib.bib3" title=""><span class="ltx_text" style="font-size:90%;">3</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2406.07440v2#bib.bib17" title=""><span class="ltx_text" style="font-size:90%;">17</span></a>]</cite>. Specifically, these studies compared the semantic similarity between a candidate translation and a reference translation. In contrast, our study employed cross-lingual the semantic similarity between a text in the source language and its translated text in the target language.</span></span></span><span class="ltx_text" id="S4.p7.1.2" style="font-size:90%;">. Our study applied a variety of statistical methods to analyze data from established QE datasets, demonstrating that this metric is both reliable and effective compared to commonly used metrics in QE. Our findings provide strong evidence that “textual similarity” is a robust metric, making it a valuable addition to the existing suite of QE metrics. Given its proven effectiveness, “textual similarity” should be included as a key metric in QE and incorporated into the training of machine translation (MT) systems. This integration can enhance the accuracy and reliability of MT quality assessments, ultimately improving the performance and usability of MT systems.</span></p>
</div>
</section>
<section class="ltx_bibliography" id="bib" lang="en">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib1.2.2.1" style="font-size:90%;">[1]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib1.4.1" style="font-size:90%;">
Dale J Barr, Roger Levy, Christoph Scheepers, and Harry J Tily.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib1.5.1" style="font-size:90%;">Random effects structure for confirmatory hypothesis testing: Keep it
maximal.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib1.6.1" style="font-size:90%;">Journal of Memory and Language</span><span class="ltx_text" id="bib.bib1.7.2" style="font-size:90%;">, 68(3):255–278, 2013.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib2.2.2.1" style="font-size:90%;">[2]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib2.4.1" style="font-size:90%;">
Frederic Blain, Chrysoula Zerva, Ricardo Rei, Nuno M Guerreiro, Diptesh
Kanojia, José GC de Souza, Beatriz Silva, Tânia Vaz, Yan Jingxuan,
Fatemeh Azadi, et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib2.5.1" style="font-size:90%;">Findings of the wmt 2023 shared task on quality estimation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib2.6.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib2.7.2" style="font-size:90%;">Proceedings of the Eighth Conference on Machine Translation</span><span class="ltx_text" id="bib.bib2.8.3" style="font-size:90%;">,
pages 629–653, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib3.2.2.1" style="font-size:90%;">[3]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib3.4.1" style="font-size:90%;">
Julio Castillo and Paula Estrella.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib3.5.1" style="font-size:90%;">Semantic textual similarity for mt evaluation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib3.6.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib3.7.2" style="font-size:90%;">Proceedings of the Seventh Workshop on Statistical Machine
Translation</span><span class="ltx_text" id="bib.bib3.8.3" style="font-size:90%;">, pages 52–58, 2012.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib4.2.2.1" style="font-size:90%;">[4]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib4.4.1" style="font-size:90%;">
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib4.5.1" style="font-size:90%;">Bert: Pre-training of deep bidirectional transformers for language
understanding.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib4.6.1" style="font-size:90%;">arXiv preprint arXiv:1810.04805</span><span class="ltx_text" id="bib.bib4.7.2" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib5.2.2.1" style="font-size:90%;">[5]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib5.4.1" style="font-size:90%;">
Shachar Don-Yehiya, Leshem Choshen, and Omri Abend.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib5.5.1" style="font-size:90%;">Prequel: Quality estimation of machine translation outputs in
advance.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib5.6.1" style="font-size:90%;">arXiv preprint arXiv:2205.09178</span><span class="ltx_text" id="bib.bib5.7.2" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib6.2.2.1" style="font-size:90%;">[6]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib6.4.1" style="font-size:90%;">
Marina Fomicheva, Shuo Sun, Erick Fonseca, Chrysoula Zerva, Frédéric
Blain, Vishrav Chaudhary, Francisco Guzmán, Nina Lopatina, Lucia Specia,
and André FT Martins.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib6.5.1" style="font-size:90%;">Mlqe-pe: A multilingual quality estimation and post-editing dataset.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib6.6.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib6.7.2" style="font-size:90%;">Proceedings of the Thirteenth Language Resources and
Evaluation Conference</span><span class="ltx_text" id="bib.bib6.8.3" style="font-size:90%;">, pages 4963–4974, 2022.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib7.2.2.1" style="font-size:90%;">[7]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib7.4.1" style="font-size:90%;">
Francisco Guzmán, Peng-Jen Chen, Myle Ott, Juan Pino, Guillaume Lample,
Philipp Koehn, Vishrav Chaudhary, and Marc’Aurelio Ranzato.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib7.5.1" style="font-size:90%;">The flores evaluation datasets for low-resource machine translation:
Nepali-english and sinhala-english.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib7.6.1" style="font-size:90%;">arXiv preprint arXiv:1902.01382</span><span class="ltx_text" id="bib.bib7.7.2" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib8.2.2.1" style="font-size:90%;">[8]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib8.4.1" style="font-size:90%;">
Seungjun Lee, Jungseob Lee, Hyeonseok Moon, Chanjun Park, Jaehyung Seo,
Sugyeong Eo, Seonmin Koo, and Heuiseok Lim.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib8.5.1" style="font-size:90%;">A survey on evaluation metrics for machine translation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib8.6.1" style="font-size:90%;">Mathematics</span><span class="ltx_text" id="bib.bib8.7.2" style="font-size:90%;">, 11(4):1006, 2023.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib9.2.2.1" style="font-size:90%;">[9]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib9.4.1" style="font-size:90%;">
Myle Ott, Sergey Edunov, Alexei Baevski, Angela Fan, Sam Gross, Nathan Ng,
David Grangier, and Michael Auli.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib9.5.1" style="font-size:90%;">Fairseq: A fast, extensible toolkit for sequence modeling.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib9.6.1" style="font-size:90%;">arXiv preprint arXiv:1904.01038</span><span class="ltx_text" id="bib.bib9.7.2" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib10.2.2.1" style="font-size:90%;">[10]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib10.4.1" style="font-size:90%;">
Tharindu Ranasinghe, Constantin Orasan, and Ruslan Mitkov.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib10.5.1" style="font-size:90%;">Transquest: Translation quality estimation with cross-lingual
transformers.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib10.6.1" style="font-size:90%;">arXiv preprint arXiv:2011.01536</span><span class="ltx_text" id="bib.bib10.7.2" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib11.2.2.1" style="font-size:90%;">[11]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib11.4.1" style="font-size:90%;">
Nils Reimers and Iryna Gurevych.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib11.5.1" style="font-size:90%;">Sentence-bert: Sentence embeddings using siamese bert-networks.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib11.6.1" style="font-size:90%;">arXiv preprint arXiv:1908.10084</span><span class="ltx_text" id="bib.bib11.7.2" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib12.2.2.1" style="font-size:90%;">[12]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib12.4.1" style="font-size:90%;">
Matthew Snover, Bonnie Dorr, Richard Schwartz, Linnea Micciulla, and John
Makhoul.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib12.5.1" style="font-size:90%;">A study of translation edit rate with targeted human annotation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib12.6.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib12.7.2" style="font-size:90%;">Proceedings of the 7th Conference of the Association for
Machine Translation in the Americas: Technical Papers</span><span class="ltx_text" id="bib.bib12.8.3" style="font-size:90%;">, pages 223–231, 2006.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib13.2.2.1" style="font-size:90%;">[13]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib13.4.1" style="font-size:90%;">
Lucia Specia, Dhwaj Raj, and Marco Turchi.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib13.5.1" style="font-size:90%;">Machine translation evaluation versus quality estimation.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib13.6.1" style="font-size:90%;">Machine Translation</span><span class="ltx_text" id="bib.bib13.7.2" style="font-size:90%;">, 24:39–50, 2010.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib14.2.2.1" style="font-size:90%;">[14]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib14.4.1" style="font-size:90%;">
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib14.5.1" style="font-size:90%;">Attention is all you need.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib14.6.1" style="font-size:90%;">Advances in Neural Information Processing Systems</span><span class="ltx_text" id="bib.bib14.7.2" style="font-size:90%;">, 30, 2017.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib15.2.2.1" style="font-size:90%;">[15]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib15.4.1" style="font-size:90%;">
Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue,
Anthony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz,
et al.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib15.5.1" style="font-size:90%;">Transformers: State-of-the-art natural language processing.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib15.6.1" style="font-size:90%;">In </span><span class="ltx_text ltx_font_italic" id="bib.bib15.7.2" style="font-size:90%;">Proceedings of the 2020 conference on empirical methods in
natural language processing: system demonstrations</span><span class="ltx_text" id="bib.bib15.8.3" style="font-size:90%;">, pages 38–45, 2020.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib16.2.2.1" style="font-size:90%;">[16]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib16.4.1" style="font-size:90%;">
Simon N Wood.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib16.5.1" style="font-size:90%;">Generalized additive models: an introduction with R</span><span class="ltx_text" id="bib.bib16.6.2" style="font-size:90%;">.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib16.7.1" style="font-size:90%;">Chapman and Hall/CRC, 2017.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib17.2.2.1" style="font-size:90%;">[17]</span></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib17.4.1" style="font-size:90%;">
Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q Weinberger, and Yoav Artzi.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib17.5.1" style="font-size:90%;">Bertscore: Evaluating text generation with bert.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib17.6.1" style="font-size:90%;">arXiv preprint arXiv:1904.09675</span><span class="ltx_text" id="bib.bib17.7.2" style="font-size:90%;">, 2019.
</span>
</span>
</li>
</ul>
</section>
<section class="ltx_appendix" id="Ax1" lang="en">
<h2 class="ltx_title ltx_title_appendix" style="font-size:90%;">Appendix</h2>
<figure class="ltx_figure" id="Ax1.F4"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="817" id="Ax1.F4.g1" src="x4.png" width="817"/>
<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>correlations among various factors in <span class="ltx_text ltx_font_typewriter" id="Ax1.F4.5.1">PreQuEL</span> </figcaption>
</figure>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Mon Jul  1 09:30:32 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
