<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2408.13598] Advancing Gamma-Ray Burst Identification through Transfer Learning with Convolutional Neural Networks</title><meta property="og:description" content="The Rapid and accurate identification of Gamma-Ray Bursts (GRBs) is crucial
for unraveling their origins. However, current burst search algorithms
frequently miss low-threshold signals or lack universality for observat…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Advancing Gamma-Ray Burst Identification through Transfer Learning with Convolutional Neural Networks">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Advancing Gamma-Ray Burst Identification through Transfer Learning with Convolutional Neural Networks">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2408.13598">

<!--Generated on Thu Sep  5 12:19:46 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div id="p1" class="ltx_para">
<span id="p1.1" class="ltx_ERROR undefined">\volnopage</span>
<p id="p1.2" class="ltx_p"><span id="p1.2.1" class="ltx_text ltx_font_bold">20XX</span> Vol. <span id="p1.2.2" class="ltx_text ltx_font_bold">X</span> No. <span id="p1.2.3" class="ltx_text ltx_font_bold">XX</span>, 000–000</p>
</div>
<span id="id1" class="ltx_note ltx_role_institutetext"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">institutetext: </span>
College of Electronic and Information Engineering, Tongji University, Shanghai 201804, China; rzgui@tongji.edu.cn
<br class="ltx_break"></span></span></span><span id="id2" class="ltx_note ltx_role_institutetext"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_note_type">institutetext: </span>Particle Astrophysics Division, Institute of High Energy Physics, Chinese Academy of Sciences, Beijing 100049, People’s Republic of China; libing@ihep.ac.cn
<br class="ltx_break"></span></span></span><span id="id3" class="ltx_note ltx_role_institutetext"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_note_type">institutetext: </span>Guangxi Key Laboratory for Relativistic Astrophysics, Nanning 530004, People’s Republic of China
<br class="ltx_break"></span></span></span><span id="id4" class="ltx_note ltx_role_institutetext"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_note_type">institutetext: </span>Key Laboratory of Particle Astrophysics, Chinese Academy of Sciences, Beijing 100049, China; xiongsl@ihep.ac.cn
<br class="ltx_break"></span></span></span><span id="id5" class="ltx_note ltx_role_institutetext"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_note_type">institutetext: </span>ICRA, Dip. di Fisica, Sapienza Università di Roma, Piazzale Aldo Moro 5, I-00185 Roma, Italy
</span></span></span><span id="id6" class="ltx_note ltx_role_institutetext"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_note_type">institutetext: </span>ICRANet, Piazza della Repubblica 10, 65122 Pescara, Italy
</span></span></span><span id="id7" class="ltx_note ltx_role_institutetext"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_note_type">institutetext: </span>INAF – Osservatorio Astronomico d’Abruzzo, Via M. Maggini snc, I-64100, Teramo, Italy
</span></span></span><span id="id8" class="ltx_note ltx_role_institutetext"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_note_type">institutetext: </span>University of Chinese Academy of Sciences, Beijing 100049, China
</span></span></span><span id="id9" class="ltx_note ltx_role_institutetext"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_note_type">institutetext: </span>School of Physics and Physical Engineering, Qufu Normal University, Qufu, Shandong 273165, China
<br class="ltx_break"></span></span></span>
<h1 class="ltx_title ltx_title_document">Advancing Gamma-Ray Burst Identification through Transfer Learning with Convolutional Neural Networks</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Peng Zhang
</span><span class="ltx_author_notes">1122</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Bing Li
</span><span class="ltx_author_notes">2233</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Ren-zhou Gui
</span><span class="ltx_author_notes">11</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Shao-lin Xiong
</span><span class="ltx_author_notes">2244</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Yu Wang
</span><span class="ltx_author_notes">556677</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Yan-qiu Zhang
</span><span class="ltx_author_notes">2288</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Chen-wei Wang
</span><span class="ltx_author_notes">2288</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Jia-cong Liu
</span><span class="ltx_author_notes">2288</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Wang-chen Xue
</span><span class="ltx_author_notes">2288</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Chao Zheng
</span><span class="ltx_author_notes">2288</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Zheng-hang Yu
</span><span class="ltx_author_notes">2288</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Wen-long Zhang
</span><span class="ltx_author_notes">2299</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">The Rapid and accurate identification of Gamma-Ray Bursts (GRBs) is crucial
for unraveling their origins. However, current burst search algorithms
frequently miss low-threshold signals or lack universality for observations.
In this study, we propose a novel approach utilizing transfer learning
experiment based on convolutional neural network (CNN) to establish a
universal GRB identification method, which validated successfully using
GECAM-B data. By employing data augmentation techniques, we enhance
the diversity and quantity of the GRB sample. We develop a 1D CNN model
with a multi-scale feature cross fusion module (MSCFM) to extract
features from samples and perform classification. The comparative
results demonstrated significant performance improvements following
pre-training and transferring on a large-scale dataset.
Our optimal model achieved an impressive accuracy of 96.41% on the
source dataset of GECAM-B, and identified three previously undiscovered
GRBs by contrast with manual analysis of GECAM-B observations.
These innovative transfer learning and data augmentation methods presented
in this work hold promise for applications in multi-satellite exploration
scenarios characterized by limited data sets and a scarcity of labeled
samples in high-energy astronomy.</p>
</div>
<div class="ltx_classification">
<h6 class="ltx_title ltx_title_classification">keywords: </h6>High energy astrophysics — Gamma-ray bursts — Convolutional neural networks — Astronomy data analysis
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Gamma-ray Bursts (GRBs) release immense amounts of energy in a remarkably
short time frame, predominantly in the form of gamma rays band.
To date, the origins of gamma-ray bursts remain unknown and the
classification of GRBs still is a crucial research endeavor, making them
a continuing research hotspot in the field of astronomy
<cite class="ltx_cite ltx_citemacro_citep">(Zhang <a href="#bib.bib48" title="" class="ltx_ref">2011</a>; Kumar &amp; Zhang <a href="#bib.bib23" title="" class="ltx_ref">2015</a>; Mészáros <a href="#bib.bib28" title="" class="ltx_ref">2019</a>; Sun et al. <a href="#bib.bib37" title="" class="ltx_ref">2023</a>; Wang et al. <a href="#bib.bib42" title="" class="ltx_ref">2024b</a>)</cite>.
As more high-quality space probes for exploring GRBs are in orbit, e.g., Swift/BAT <cite class="ltx_cite ltx_citemacro_citep">(Krimm et al. <a href="#bib.bib22" title="" class="ltx_ref">2013</a>)</cite>, Fermi/GBM <cite class="ltx_cite ltx_citemacro_citep">(Meegan et al. <a href="#bib.bib27" title="" class="ltx_ref">2009</a>)</cite>, GECAM/GRD
 <cite class="ltx_cite ltx_citemacro_citep">(Li et al. <a href="#bib.bib25" title="" class="ltx_ref">2020</a>)</cite>, SVOM/GRM <cite class="ltx_cite ltx_citemacro_citep">(Zhao et al. <a href="#bib.bib51" title="" class="ltx_ref">2012</a>)</cite>, rapid and accurate identification of
gamma-ray burst events becomes especially important.
And with the leapfrogging of multi-messenger, multi-band astronomy, the rapid
identifying GRBs from detectors of space-based missions is advantageous for
guiding other telescopes to conduct joint or follow-up observations for
studying afterglows, locating host galaxies, hunting other counterparts and
intrinsic information. The light curves of GRBs exhibit irregular and
multi-peaked, and these shapes undoubtedly contain wealth of physical
characteristics.
Traditional burst search algorithms capture signals in multiple time-bin
light curves with signal-to-noise ratios (SNRs) above a predefined threshold
exceeded the background <cite class="ltx_cite ltx_citemacro_citep">(Band <a href="#bib.bib7" title="" class="ltx_ref">2002</a>; Blackburn et al. <a href="#bib.bib10" title="" class="ltx_ref">2013</a>; Cai et al. <a href="#bib.bib11" title="" class="ltx_ref">2021</a>)</cite>.
However, these methods are challenging to accurately estimate the background
level and set appropriate thresholds.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">As a sub-field of artificial intelligence, Machine Learning (ML) is routinely
used today for a wide range of purposes. ML techniques are exploit only to
process, visualize, and make predictions from big data, but also to make
data-driven discoveries. The operational capability of ML algorithms for
autonomously learning, adapting, and improving from data were impressively
demonstrated. The information content of a dataset is organised, and the
knowledge of internal samples could be extracted through unsupervised,
semi-supervised, or supervised learning approaches.
The applications of such methods are becoming commonplace and growing rapidly
in modern domain of astronomy and astrophysics.
For a graphical overview of heavy use in extragalactic astronomy see
<cite class="ltx_cite ltx_citemacro_citep">(Fotopoulou <a href="#bib.bib17" title="" class="ltx_ref">2024</a>)</cite>.
ML along with its subset, deep learning (DL), have revolutionized the astronomy
domain by providing powerful tools for data analysis and pattern recognition
in recent years, and the application of such techniques in astronomical
researches have gained significant attention and
traction <cite class="ltx_cite ltx_citemacro_citep">(Baron <a href="#bib.bib9" title="" class="ltx_ref">2019</a>; Djorgovski et al. <a href="#bib.bib14" title="" class="ltx_ref">2022</a>)</cite>.
The utilization of machine learning methods showed great potential in enhancing
the detection and classification of fast transient events <cite class="ltx_cite ltx_citemacro_citep">(du Buisson et al. <a href="#bib.bib16" title="" class="ltx_ref">2015</a>; Wagstaff et al. <a href="#bib.bib40" title="" class="ltx_ref">2016</a>; Sooknunan et al. <a href="#bib.bib36" title="" class="ltx_ref">2021</a>; Alves et al. <a href="#bib.bib2" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">ML has been also applied as a method for the discovery of GRBs experimentally.
By combining density-based spatial clustering and dynamic time warping for
template matching, <cite class="ltx_cite ltx_citemacro_cite">Abraham et al. (<a href="#bib.bib1" title="" class="ltx_ref">2021</a>)</cite> developed a ML algorithm for
automated detection of GRB-like events using the AstroSat/CZTI data,
which demonstrated various resourcefulness of this method for robust GRB
identification. As a specialized type of DL algorithm, Convolutional Neural
Networks (CNNs) mainly designed for tasks that necessitate object recognition,
including image classification, object detection, and segmentation (for review
see <cite class="ltx_cite ltx_citemacro_citep">(Alzubaidi et al. <a href="#bib.bib3" title="" class="ltx_ref">2021</a>; Taye <a href="#bib.bib38" title="" class="ltx_ref">2023</a>)</cite>.
CNNs are employed in a variety of practical scenarios in astronomy for working
and processing with variety data from observations, such as light curves,
images, and spectra. They have brought about revolutionary changes in data
analysis by efficiently automating the extraction of complex features from
astronomical datasets.
<cite class="ltx_cite ltx_citemacro_cite">Parmiggiani et al. (<a href="#bib.bib31" title="" class="ltx_ref">2021</a>)</cite> develop an automated real-time analysis
pipeline that consisted of a new approach of CNN to classify the intensity
maps acquired by AGILE-GRID. In a recent paper, a quantum CNN was implemented
to detect GRBs from sky maps or light curves of this telescope,
which achieved considerable improvements of accuracy of recognition
<cite class="ltx_cite ltx_citemacro_citep">(Rizzo et al. <a href="#bib.bib34" title="" class="ltx_ref">2024</a>)</cite>. These improving of GRB detection capability and
effective were demonstrated obviously.
<cite class="ltx_cite ltx_citemacro_citet">Parmiggiani et al. (<a href="#bib.bib32" title="" class="ltx_ref">2023</a>)</cite> apply a CNN-based auto-encoder to
reconstruct background light curves and detect GRBs by exceeding the threshold
reconstruction error. Their approach successfully identified 72 GRBs that
were not listed in the AGILE catalog. In addition, A deep neural network
was trained with a vast amount of AGILE orbital and attitude parameters to
predict the background count rates, yielding promising results and enabling
the development of an anomaly detection method for detecting GRBs <cite class="ltx_cite ltx_citemacro_citep">(Parmiggiani et al. <a href="#bib.bib33" title="" class="ltx_ref">2024</a>)</cite>.
<cite class="ltx_cite ltx_citemacro_citet">Crupi et al. (<a href="#bib.bib13" title="" class="ltx_ref">2023</a>)</cite> employ neural networks to estimate the
long-term background level using orbital and spatial environmental information.
Combining the trigger search algorithm based on SNR, seven suspected long
faint bursts were identified.
The training of DL models rely on a significant amount of well-annotated data,
while the detected bursting events of astronomical transients are exceedingly
limited. A wealth of experimental or validation operations of such methods
are indeed available at present. However, it is undeniable that the dataset
embedded with rich features and diversity is still limited, which still leads
to many questionable applications and results.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Transfer learning (TL) is proposed to alleviate the issue of insufficient
generalization capability of models due to limited samples.
TL leverages knowledge learned from source task to improve learning and
generalization on target task, offering benefits such as faster convergence,
improved performance, and reduced data requirements <cite class="ltx_cite ltx_citemacro_citep">(Pan &amp; Yang <a href="#bib.bib30" title="" class="ltx_ref">2010</a>; Yosinski et al. <a href="#bib.bib47" title="" class="ltx_ref">2014</a>; Kim et al. <a href="#bib.bib20" title="" class="ltx_ref">2021</a>)</cite>.
DL algorithms for galaxy morphological classification have achieved
remarkable success, but their reliance on large labelled training samples
raises the problem of transfer ability to new datasets <cite class="ltx_cite ltx_citemacro_citep">(Barchi et al. <a href="#bib.bib8" title="" class="ltx_ref">2020</a>)</cite>.
<cite class="ltx_cite ltx_citemacro_cite">Domínguez Sánchez et al. (<a href="#bib.bib15" title="" class="ltx_ref">2019</a>)</cite> demonstrates that transfer learning, by pre-training
CNN model with Sloan Digital Sky Survey data and adapting them to Dark Energy
Survey data through parameter fine-tuning.
This method significantly improves classification accuracy and completeness,
reducing the required training sample size.
<cite class="ltx_cite ltx_citemacro_cite">Awang Iskandar et al. (<a href="#bib.bib6" title="" class="ltx_ref">2020</a>)</cite> assesses the efficacy of CNN for planetary nebulae
classification, focusing on distinguishing such objects from their morphology.
Utilizing transfer learning with pre-trained algorithms,
the study achieved high success in differentiating True PNe without parameter fine-tuning.
<cite class="ltx_cite ltx_citemacro_cite">Cavuoti et al. (<a href="#bib.bib12" title="" class="ltx_ref">2024</a>)</cite> presents a novel outlier detection method in astronomical
time series, highlighting the effectiveness of transfer learning using a CNN
model pre-trained on ImageNet dataset.
Application of transfer learning to VLT Survey Telescope data demonstrates
its practicality in artifact identification and removal, showcasing its
potential for enhancing data quality and reliability.
The transfer learning alleviates the challenges posed by limited labeled
data and model generalization.
It also demonstrates its capability to enhance the reliability, stability,
and accuracy of models across various astronomical tasks.
Current deep learning methods for GRB searches are customized to a single
satellite, and the effective transfer to satellites with limited observation
is equally crucial.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">In our previous studies, <cite class="ltx_cite ltx_citemacro_citet">Zhang et al. (<a href="#bib.bib49" title="" class="ltx_ref">2024</a>)</cite> adopt multilayer
CNNs to distinguish GRBs from observation data of Fermi/GBM. As input data,
the count maps contain abundant features, including light curves and spectral
information in a wide-bandwidth, which were successfully utilized to train
models. These processing methods achieved high accuracy and demonstrated
their effectiveness through feature visualization and classification.
Applying the optimal model to one year observations, it achieves results
comparable to manual analysis,and furthermore, it shows remarkable capacity
for identification of sub-threshold GRBs.
These outstanding results are mainly attributed to the relatively large
labeled samples of GRBs observed by Fermi/GBM.
Undoubtedly, the current limited quantity of labeled samples of GRBs makes
it challenging to fully harness the potential of neural networks.
Especially for telescopes with a short time in orbit, e.g., ravitational wave
high-energy Electromagnetic Counterpart All-sky Monitor (GECAM, <cite class="ltx_cite ltx_citemacro_cite">Li et al. (<a href="#bib.bib25" title="" class="ltx_ref">2020</a>)</cite>), The Space-based multi-band astronomical Variable Objects Monitor
(SVOM, <cite class="ltx_cite ltx_citemacro_cite">Atteia et al. (<a href="#bib.bib5" title="" class="ltx_ref">2022</a>)</cite> )
Hence the transfer learning caught our attention due to its ability to address
data limitations by leveraging knowledge learned from related tasks or domains.
The main datasets employed in our study comes from the gamma-ray detectors
(GRDs) onboard GECAM-B satellite that in orbit for three years.
As a purpose for exploring how to transfer models trained on large-scale datasets, we utilized source datasets referenced to <cite class="ltx_cite ltx_citemacro_citet">Zhang et al. (<a href="#bib.bib49" title="" class="ltx_ref">2024</a>)</cite>.
The dataset, data augmentation, and data pre-processing are presented
in Section <a href="#S2" title="2 Dataset ‣ Advancing Gamma-Ray Burst Identification through Transfer Learning with Convolutional Neural Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
The Section <a href="#S3" title="3 Model architecture, training, and extension ‣ Advancing Gamma-Ray Burst Identification through Transfer Learning with Convolutional Neural Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> shows transfer learning model structure,
pre-training and fine-tuning in detail.
The performance of the model and the recovered GRBs are shown in Section <a href="#S4" title="4 Result ‣ Advancing Gamma-Ray Burst Identification through Transfer Learning with Convolutional Neural Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.
Section <a href="#S5" title="5 Discussion and Conclusion ‣ Advancing Gamma-Ray Burst Identification through Transfer Learning with Convolutional Neural Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> discusses the performance of the model, the practical implications of the new approach.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Dataset</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">Benefiting from the wide energy band, large field of view, and high sensitivity
of gamma-ray detectors of GRD, the GECAM-B satellite has detected more than
300 GRBs since its launch in December 10, 2020.
These 25 GRDs have demonstrated strong capabilities in detecting gamma rays and
particles, as well as determined the locations of GRBs roughly <cite class="ltx_cite ltx_citemacro_citep">(An et al. <a href="#bib.bib4" title="" class="ltx_ref">2021</a>)</cite>.
We constructed a target dataset based on the observed data from GECAM-B,
which includes categories for both GRB and non-GRB samples.
In order to obtain valid GRB category samples, we screened the GRBs detected
by the GECAM-B/GRD. Through manual analysis, there are 219 GRBs
with precise location between 01/01/2021 and 02/01/2024.
Corresponding to these GRBs that triggered by no fewer than three detectors,
along with their location and direction of every GRD detector, we calculated
the incidence angles of every GRB source for detectors.
The extraction of light curves from GECAM data is facilitated through GECAMTools<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a target="_blank" href="https://github.com/zhangpeng-sci/GECAMTools-Public/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/zhangpeng-sci/GECAMTools-Public/</a></span></span></span>.
Considering the requisite for high statistical light curves of GRB samples,
we only extracted event data from the three detectors that with relatively
small incidence angles for each event. This process resulted in 657 light
curves that were collected to augment for GRB category samples.
Each GRB sample was set to a duration of 120 seconds, with a minimum of 10
seconds of background data before and after the burst to ensure the integrity
of the burst shape.
For the non-GRB category data from GCEAM-B, we randomly sampled 1,500 daily
observational files from non-burst time periods.
From each file, twenty 120-second segments were extracted without overlap
for additional analysis, this gives us 11,000 non-GRB samples.
The non-GRB category data are shown in the table <a href="#S2.T1" title="Table 1 ‣ 2 Dataset ‣ Advancing Gamma-Ray Burst Identification through Transfer Learning with Convolutional Neural Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
We select photons recommended in all gain types without distinguishing
in the high gain or low gain.
These photons are utilized to generate light curves with a time bin of
64 ms from both GRB and non-GRB data.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">To facilitate the pre-training of our model, we build the Fermi/GBM dataset
(source dataset). As of July 2023, Fermi/GBM has manually identified over
3500 GRBs. Following the GRB category and non-GRB category data extraction
methods presented in <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al. <a href="#bib.bib49" title="" class="ltx_ref">2024</a>)</cite>,
we have made updates to the time range of the data selection from July 14,
2008 to June 31, 2023. We initially achieved 6,189 GRB samples and 108,000
non-GRB samples.
Relatively speaking, a small time-bin light curve provides deeper and detailed
information that is more favorable identifying GRBs <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al. <a href="#bib.bib49" title="" class="ltx_ref">2024</a>)</cite>.
The energy band of all light curves are binned into 9 universal bins
(25-50 keV, 50-100 keV, 50-300 keV, 100-300 keV, 100-500 keV, 100-900 keV,
300-500 keV, 300-900 keV, and 500-900 keV), refereed to the trigger search
algorithm of the Fermi/GBM <cite class="ltx_cite ltx_citemacro_citep">(von Kienlin et al. <a href="#bib.bib39" title="" class="ltx_ref">2020</a>; Cai et al. <a href="#bib.bib11" title="" class="ltx_ref">2021</a>)</cite>.
The majority of GRB photons are distributed across these energy bands,
and the energy band binning enhances the intensity of the burst signal in
the light curves.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">Normalization and standardization are common techniques used in data
pre-processing to scale and transform the features of a dataset.
Normalization involves rescaling the values of a feature to a specific range,
typically between 0 and 1.
This is achieved by subtracting the minimum value of the feature and dividing
by the range (maximum value minus minimum value).
On the other hand, standardization transforms the values of a feature to have
a mean of 0 and a standard deviation of 1.
This process involves subtracting the mean value of the feature from each
value and dividing by the standard deviation.
Both normalization and standardization are employed to ensure that the
features in a dataset are on a similar scale.
The ResNet model, as proposed by <cite class="ltx_cite ltx_citemacro_cite">He et al. (<a href="#bib.bib19" title="" class="ltx_ref">2016</a>)</cite>, is a widely used
model in deep learning.
In this study, we employed the ResNet model to evaluate and compare
the impact of various pre-processing methods on performance.
The results of the performance evaluation on the source test set
using these two methods are summarized in Table <a href="#S2.T2" title="Table 2 ‣ 2 Dataset ‣ Advancing Gamma-Ray Burst Identification through Transfer Learning with Convolutional Neural Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
Given that standardizing samples leads to the highest accuracy for each
energy band,
we have decided to adopt standardizing method for pre-processing the samples
in source and target dataset.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p">Data augmentation has emerged as a widely adopted technique for improving
the generalization capabilities of deep learning models.
The diversity of the data influences the model’s ability to generalize.
Additionally, overfitting or underfitting occurs when a model has learned
limited flexibility from the dataset, either due to a lack of features or
excessive regularization.
One effective way to prevent these issues is by considering not only the
quantity aspect but also the similarity and diversity aspects of data.
While it may not be a guarantee, training with a larger quantity of data can
assist deep learning algorithms in better detecting signals.
In this study, we experimentally present a data augmentation technique for
the light curves of GRB category data. The GRB signals utilized in this
dataset have been manually analyzed, resulting in overwhelmingly high
SNR throughout the distribution.
This prevalence of high SNR signals has led to a scarcity of samples with
relatively lower SNRs, and a notable shortage of of sub-threshold
samples within our GRB category data.
</p>
</div>
<div id="S2.p5" class="ltx_para">
<p id="S2.p5.1" class="ltx_p">Our objective is to create a substantial amount of mocked GRB signals with
lower SNRs and sub-threshold levels based on the existing light curves of GRBs.
We consider an idea in which the SNR of each individually primary GRB is
randomly decreased multiple times by reducing counts in each bin according
to a stochastic proportion.
This idea bears a resemblance to the scaling or resizing method of affine transformations used for augmenting image data. Despite the simplicity of
these affine techniques, several studies have indicated that they are
highly effective in various machine learning tasks <cite class="ltx_cite ltx_citemacro_citep">(Mumuni &amp; Mumuni <a href="#bib.bib29" title="" class="ltx_ref">2022</a>; Kumar et al. <a href="#bib.bib24" title="" class="ltx_ref">2023</a>; Wang et al. <a href="#bib.bib44" title="" class="ltx_ref">2024d</a>)</cite>.
The negative samples (i.e. non-GRBs) we utilize that are extracted directly
from observations in non-burst regions, representing the background level of
the detectors in orbit. Therefore, the method of randomly reducing counts on
a random scale may pose a challenge, as it could lower the background level
to an unrealistic extent, potentially complicating signal detection and
identification.
Our data augmentation approach involves reducing the counts of each individual
GRB light curve while maintaining the background level, as illustrated in
Figure <a href="#S2.F1" title="Figure 1 ‣ 2 Dataset ‣ Advancing Gamma-Ray Burst Identification through Transfer Learning with Convolutional Neural Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<figure id="S2.F1" class="ltx_figure"><img src="/html/2408.13598/assets/x1.png" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="292" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F1.4.2.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S2.F1.2.1" class="ltx_text" style="font-size:90%;">Illustration of our data augmentation.
The top panel displays the the primary light curve of GRB 210606B in total
energy channel (detected by GECAM-B/GRD02). The SNR for this sample is
14.73 <math id="S2.F1.2.1.m1.1" class="ltx_Math" alttext="\sigma" display="inline"><semantics id="S2.F1.2.1.m1.1b"><mi id="S2.F1.2.1.m1.1.1" xref="S2.F1.2.1.m1.1.1.cmml">σ</mi><annotation-xml encoding="MathML-Content" id="S2.F1.2.1.m1.1c"><ci id="S2.F1.2.1.m1.1.1.cmml" xref="S2.F1.2.1.m1.1.1">𝜎</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.F1.2.1.m1.1d">\sigma</annotation></semantics></math>. The red dotted line represents the background fitted with a
polynomial function, and the background level approximately equal
to 52 counts per bin. The shaded region corresponds to the primary GRB region.
The bottom three panels respectively show the light curves after reducing
the counts of each bin by proportionally about 20%, 50% and 80%, followed
by back-filling the background by overlaying counts sampled from a Poisson
distribution with a mean value equal to the reduced background counts.
Their respective SNRs are marked.</span></figcaption>
</figure>
<div id="S2.p6" class="ltx_para">
<p id="S2.p6.3" class="ltx_p">To implement this method, we initially select the stable background level
both in the preceding and the subsequent of the burst and derive the
background light curve <math id="S2.p6.1.m1.1" class="ltx_Math" alttext="Lc_{bg}" display="inline"><semantics id="S2.p6.1.m1.1a"><mrow id="S2.p6.1.m1.1.1" xref="S2.p6.1.m1.1.1.cmml"><mi id="S2.p6.1.m1.1.1.2" xref="S2.p6.1.m1.1.1.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S2.p6.1.m1.1.1.1" xref="S2.p6.1.m1.1.1.1.cmml">​</mo><msub id="S2.p6.1.m1.1.1.3" xref="S2.p6.1.m1.1.1.3.cmml"><mi id="S2.p6.1.m1.1.1.3.2" xref="S2.p6.1.m1.1.1.3.2.cmml">c</mi><mrow id="S2.p6.1.m1.1.1.3.3" xref="S2.p6.1.m1.1.1.3.3.cmml"><mi id="S2.p6.1.m1.1.1.3.3.2" xref="S2.p6.1.m1.1.1.3.3.2.cmml">b</mi><mo lspace="0em" rspace="0em" id="S2.p6.1.m1.1.1.3.3.1" xref="S2.p6.1.m1.1.1.3.3.1.cmml">​</mo><mi id="S2.p6.1.m1.1.1.3.3.3" xref="S2.p6.1.m1.1.1.3.3.3.cmml">g</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.p6.1.m1.1b"><apply id="S2.p6.1.m1.1.1.cmml" xref="S2.p6.1.m1.1.1"><times id="S2.p6.1.m1.1.1.1.cmml" xref="S2.p6.1.m1.1.1.1"></times><ci id="S2.p6.1.m1.1.1.2.cmml" xref="S2.p6.1.m1.1.1.2">𝐿</ci><apply id="S2.p6.1.m1.1.1.3.cmml" xref="S2.p6.1.m1.1.1.3"><csymbol cd="ambiguous" id="S2.p6.1.m1.1.1.3.1.cmml" xref="S2.p6.1.m1.1.1.3">subscript</csymbol><ci id="S2.p6.1.m1.1.1.3.2.cmml" xref="S2.p6.1.m1.1.1.3.2">𝑐</ci><apply id="S2.p6.1.m1.1.1.3.3.cmml" xref="S2.p6.1.m1.1.1.3.3"><times id="S2.p6.1.m1.1.1.3.3.1.cmml" xref="S2.p6.1.m1.1.1.3.3.1"></times><ci id="S2.p6.1.m1.1.1.3.3.2.cmml" xref="S2.p6.1.m1.1.1.3.3.2">𝑏</ci><ci id="S2.p6.1.m1.1.1.3.3.3.cmml" xref="S2.p6.1.m1.1.1.3.3.3">𝑔</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p6.1.m1.1c">Lc_{bg}</annotation></semantics></math> by fitting the background using a
polynomial function.
Subsequently, we subtract counts from the primary light curve <math id="S2.p6.2.m2.1" class="ltx_Math" alttext="Lc" display="inline"><semantics id="S2.p6.2.m2.1a"><mrow id="S2.p6.2.m2.1.1" xref="S2.p6.2.m2.1.1.cmml"><mi id="S2.p6.2.m2.1.1.2" xref="S2.p6.2.m2.1.1.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S2.p6.2.m2.1.1.1" xref="S2.p6.2.m2.1.1.1.cmml">​</mo><mi id="S2.p6.2.m2.1.1.3" xref="S2.p6.2.m2.1.1.3.cmml">c</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.p6.2.m2.1b"><apply id="S2.p6.2.m2.1.1.cmml" xref="S2.p6.2.m2.1.1"><times id="S2.p6.2.m2.1.1.1.cmml" xref="S2.p6.2.m2.1.1.1"></times><ci id="S2.p6.2.m2.1.1.2.cmml" xref="S2.p6.2.m2.1.1.2">𝐿</ci><ci id="S2.p6.2.m2.1.1.3.cmml" xref="S2.p6.2.m2.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p6.2.m2.1c">Lc</annotation></semantics></math> based on
a specified <math id="S2.p6.3.m3.1" class="ltx_Math" alttext="crop\_factor" display="inline"><semantics id="S2.p6.3.m3.1a"><mrow id="S2.p6.3.m3.1.1" xref="S2.p6.3.m3.1.1.cmml"><mi id="S2.p6.3.m3.1.1.2" xref="S2.p6.3.m3.1.1.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S2.p6.3.m3.1.1.1" xref="S2.p6.3.m3.1.1.1.cmml">​</mo><mi id="S2.p6.3.m3.1.1.3" xref="S2.p6.3.m3.1.1.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S2.p6.3.m3.1.1.1a" xref="S2.p6.3.m3.1.1.1.cmml">​</mo><mi id="S2.p6.3.m3.1.1.4" xref="S2.p6.3.m3.1.1.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S2.p6.3.m3.1.1.1b" xref="S2.p6.3.m3.1.1.1.cmml">​</mo><mi id="S2.p6.3.m3.1.1.5" xref="S2.p6.3.m3.1.1.5.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.p6.3.m3.1.1.1c" xref="S2.p6.3.m3.1.1.1.cmml">​</mo><mi mathvariant="normal" id="S2.p6.3.m3.1.1.6" xref="S2.p6.3.m3.1.1.6.cmml">_</mi><mo lspace="0em" rspace="0em" id="S2.p6.3.m3.1.1.1d" xref="S2.p6.3.m3.1.1.1.cmml">​</mo><mi id="S2.p6.3.m3.1.1.7" xref="S2.p6.3.m3.1.1.7.cmml">f</mi><mo lspace="0em" rspace="0em" id="S2.p6.3.m3.1.1.1e" xref="S2.p6.3.m3.1.1.1.cmml">​</mo><mi id="S2.p6.3.m3.1.1.8" xref="S2.p6.3.m3.1.1.8.cmml">a</mi><mo lspace="0em" rspace="0em" id="S2.p6.3.m3.1.1.1f" xref="S2.p6.3.m3.1.1.1.cmml">​</mo><mi id="S2.p6.3.m3.1.1.9" xref="S2.p6.3.m3.1.1.9.cmml">c</mi><mo lspace="0em" rspace="0em" id="S2.p6.3.m3.1.1.1g" xref="S2.p6.3.m3.1.1.1.cmml">​</mo><mi id="S2.p6.3.m3.1.1.10" xref="S2.p6.3.m3.1.1.10.cmml">t</mi><mo lspace="0em" rspace="0em" id="S2.p6.3.m3.1.1.1h" xref="S2.p6.3.m3.1.1.1.cmml">​</mo><mi id="S2.p6.3.m3.1.1.11" xref="S2.p6.3.m3.1.1.11.cmml">o</mi><mo lspace="0em" rspace="0em" id="S2.p6.3.m3.1.1.1i" xref="S2.p6.3.m3.1.1.1.cmml">​</mo><mi id="S2.p6.3.m3.1.1.12" xref="S2.p6.3.m3.1.1.12.cmml">r</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.p6.3.m3.1b"><apply id="S2.p6.3.m3.1.1.cmml" xref="S2.p6.3.m3.1.1"><times id="S2.p6.3.m3.1.1.1.cmml" xref="S2.p6.3.m3.1.1.1"></times><ci id="S2.p6.3.m3.1.1.2.cmml" xref="S2.p6.3.m3.1.1.2">𝑐</ci><ci id="S2.p6.3.m3.1.1.3.cmml" xref="S2.p6.3.m3.1.1.3">𝑟</ci><ci id="S2.p6.3.m3.1.1.4.cmml" xref="S2.p6.3.m3.1.1.4">𝑜</ci><ci id="S2.p6.3.m3.1.1.5.cmml" xref="S2.p6.3.m3.1.1.5">𝑝</ci><ci id="S2.p6.3.m3.1.1.6.cmml" xref="S2.p6.3.m3.1.1.6">_</ci><ci id="S2.p6.3.m3.1.1.7.cmml" xref="S2.p6.3.m3.1.1.7">𝑓</ci><ci id="S2.p6.3.m3.1.1.8.cmml" xref="S2.p6.3.m3.1.1.8">𝑎</ci><ci id="S2.p6.3.m3.1.1.9.cmml" xref="S2.p6.3.m3.1.1.9">𝑐</ci><ci id="S2.p6.3.m3.1.1.10.cmml" xref="S2.p6.3.m3.1.1.10">𝑡</ci><ci id="S2.p6.3.m3.1.1.11.cmml" xref="S2.p6.3.m3.1.1.11">𝑜</ci><ci id="S2.p6.3.m3.1.1.12.cmml" xref="S2.p6.3.m3.1.1.12">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p6.3.m3.1c">crop\_factor</annotation></semantics></math>, and then reintroduce the corresponding
Poisson-sampled background ratio.</p>
<table id="S2.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E1.m1.2" class="ltx_Math" alttext="Lc_{new}=Lc\times(1-crop\_factor)+random\_possion(Lc_{bg}\times crop\_factor)" display="block"><semantics id="S2.E1.m1.2a"><mrow id="S2.E1.m1.2.2" xref="S2.E1.m1.2.2.cmml"><mrow id="S2.E1.m1.2.2.4" xref="S2.E1.m1.2.2.4.cmml"><mi id="S2.E1.m1.2.2.4.2" xref="S2.E1.m1.2.2.4.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.2.4.1" xref="S2.E1.m1.2.2.4.1.cmml">​</mo><msub id="S2.E1.m1.2.2.4.3" xref="S2.E1.m1.2.2.4.3.cmml"><mi id="S2.E1.m1.2.2.4.3.2" xref="S2.E1.m1.2.2.4.3.2.cmml">c</mi><mrow id="S2.E1.m1.2.2.4.3.3" xref="S2.E1.m1.2.2.4.3.3.cmml"><mi id="S2.E1.m1.2.2.4.3.3.2" xref="S2.E1.m1.2.2.4.3.3.2.cmml">n</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.2.4.3.3.1" xref="S2.E1.m1.2.2.4.3.3.1.cmml">​</mo><mi id="S2.E1.m1.2.2.4.3.3.3" xref="S2.E1.m1.2.2.4.3.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.2.4.3.3.1a" xref="S2.E1.m1.2.2.4.3.3.1.cmml">​</mo><mi id="S2.E1.m1.2.2.4.3.3.4" xref="S2.E1.m1.2.2.4.3.3.4.cmml">w</mi></mrow></msub></mrow><mo id="S2.E1.m1.2.2.3" xref="S2.E1.m1.2.2.3.cmml">=</mo><mrow id="S2.E1.m1.2.2.2" xref="S2.E1.m1.2.2.2.cmml"><mrow id="S2.E1.m1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.cmml"><mrow id="S2.E1.m1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.3.cmml"><mi id="S2.E1.m1.1.1.1.1.3.2" xref="S2.E1.m1.1.1.1.1.3.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.3.1" xref="S2.E1.m1.1.1.1.1.3.1.cmml">​</mo><mi id="S2.E1.m1.1.1.1.1.3.3" xref="S2.E1.m1.1.1.1.1.3.3.cmml">c</mi></mrow><mo lspace="0.222em" rspace="0.222em" id="S2.E1.m1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.2.cmml">×</mo><mrow id="S2.E1.m1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E1.m1.1.1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.E1.m1.1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.1.1.cmml"><mn id="S2.E1.m1.1.1.1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.1.1.1.2.cmml">1</mn><mo id="S2.E1.m1.1.1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.1.1.1.cmml">−</mo><mrow id="S2.E1.m1.1.1.1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.1.1.1.3.cmml"><mi id="S2.E1.m1.1.1.1.1.1.1.1.3.2" xref="S2.E1.m1.1.1.1.1.1.1.1.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.1.1.1.3.1" xref="S2.E1.m1.1.1.1.1.1.1.1.3.1.cmml">​</mo><mi id="S2.E1.m1.1.1.1.1.1.1.1.3.3" xref="S2.E1.m1.1.1.1.1.1.1.1.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.1.1.1.3.1a" xref="S2.E1.m1.1.1.1.1.1.1.1.3.1.cmml">​</mo><mi id="S2.E1.m1.1.1.1.1.1.1.1.3.4" xref="S2.E1.m1.1.1.1.1.1.1.1.3.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.1.1.1.3.1b" xref="S2.E1.m1.1.1.1.1.1.1.1.3.1.cmml">​</mo><mi id="S2.E1.m1.1.1.1.1.1.1.1.3.5" xref="S2.E1.m1.1.1.1.1.1.1.1.3.5.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.1.1.1.3.1c" xref="S2.E1.m1.1.1.1.1.1.1.1.3.1.cmml">​</mo><mi mathvariant="normal" id="S2.E1.m1.1.1.1.1.1.1.1.3.6" xref="S2.E1.m1.1.1.1.1.1.1.1.3.6.cmml">_</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.1.1.1.3.1d" xref="S2.E1.m1.1.1.1.1.1.1.1.3.1.cmml">​</mo><mi id="S2.E1.m1.1.1.1.1.1.1.1.3.7" xref="S2.E1.m1.1.1.1.1.1.1.1.3.7.cmml">f</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.1.1.1.3.1e" xref="S2.E1.m1.1.1.1.1.1.1.1.3.1.cmml">​</mo><mi id="S2.E1.m1.1.1.1.1.1.1.1.3.8" xref="S2.E1.m1.1.1.1.1.1.1.1.3.8.cmml">a</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.1.1.1.3.1f" xref="S2.E1.m1.1.1.1.1.1.1.1.3.1.cmml">​</mo><mi id="S2.E1.m1.1.1.1.1.1.1.1.3.9" xref="S2.E1.m1.1.1.1.1.1.1.1.3.9.cmml">c</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.1.1.1.3.1g" xref="S2.E1.m1.1.1.1.1.1.1.1.3.1.cmml">​</mo><mi id="S2.E1.m1.1.1.1.1.1.1.1.3.10" xref="S2.E1.m1.1.1.1.1.1.1.1.3.10.cmml">t</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.1.1.1.3.1h" xref="S2.E1.m1.1.1.1.1.1.1.1.3.1.cmml">​</mo><mi id="S2.E1.m1.1.1.1.1.1.1.1.3.11" xref="S2.E1.m1.1.1.1.1.1.1.1.3.11.cmml">o</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.1.1.1.3.1i" xref="S2.E1.m1.1.1.1.1.1.1.1.3.1.cmml">​</mo><mi id="S2.E1.m1.1.1.1.1.1.1.1.3.12" xref="S2.E1.m1.1.1.1.1.1.1.1.3.12.cmml">r</mi></mrow></mrow><mo stretchy="false" id="S2.E1.m1.1.1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.E1.m1.2.2.2.3" xref="S2.E1.m1.2.2.2.3.cmml">+</mo><mrow id="S2.E1.m1.2.2.2.2" xref="S2.E1.m1.2.2.2.2.cmml"><mi id="S2.E1.m1.2.2.2.2.3" xref="S2.E1.m1.2.2.2.2.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.2.2.2.2" xref="S2.E1.m1.2.2.2.2.2.cmml">​</mo><mi id="S2.E1.m1.2.2.2.2.4" xref="S2.E1.m1.2.2.2.2.4.cmml">a</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.2.2.2.2a" xref="S2.E1.m1.2.2.2.2.2.cmml">​</mo><mi id="S2.E1.m1.2.2.2.2.5" xref="S2.E1.m1.2.2.2.2.5.cmml">n</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.2.2.2.2b" xref="S2.E1.m1.2.2.2.2.2.cmml">​</mo><mi id="S2.E1.m1.2.2.2.2.6" xref="S2.E1.m1.2.2.2.2.6.cmml">d</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.2.2.2.2c" xref="S2.E1.m1.2.2.2.2.2.cmml">​</mo><mi id="S2.E1.m1.2.2.2.2.7" xref="S2.E1.m1.2.2.2.2.7.cmml">o</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.2.2.2.2d" xref="S2.E1.m1.2.2.2.2.2.cmml">​</mo><mi id="S2.E1.m1.2.2.2.2.8" xref="S2.E1.m1.2.2.2.2.8.cmml">m</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.2.2.2.2e" xref="S2.E1.m1.2.2.2.2.2.cmml">​</mo><mi mathvariant="normal" id="S2.E1.m1.2.2.2.2.9" xref="S2.E1.m1.2.2.2.2.9.cmml">_</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.2.2.2.2f" xref="S2.E1.m1.2.2.2.2.2.cmml">​</mo><mi id="S2.E1.m1.2.2.2.2.10" xref="S2.E1.m1.2.2.2.2.10.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.2.2.2.2g" xref="S2.E1.m1.2.2.2.2.2.cmml">​</mo><mi id="S2.E1.m1.2.2.2.2.11" xref="S2.E1.m1.2.2.2.2.11.cmml">o</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.2.2.2.2h" xref="S2.E1.m1.2.2.2.2.2.cmml">​</mo><mi id="S2.E1.m1.2.2.2.2.12" xref="S2.E1.m1.2.2.2.2.12.cmml">s</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.2.2.2.2i" xref="S2.E1.m1.2.2.2.2.2.cmml">​</mo><mi id="S2.E1.m1.2.2.2.2.13" xref="S2.E1.m1.2.2.2.2.13.cmml">s</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.2.2.2.2j" xref="S2.E1.m1.2.2.2.2.2.cmml">​</mo><mi id="S2.E1.m1.2.2.2.2.14" xref="S2.E1.m1.2.2.2.2.14.cmml">i</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.2.2.2.2k" xref="S2.E1.m1.2.2.2.2.2.cmml">​</mo><mi id="S2.E1.m1.2.2.2.2.15" xref="S2.E1.m1.2.2.2.2.15.cmml">o</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.2.2.2.2l" xref="S2.E1.m1.2.2.2.2.2.cmml">​</mo><mi id="S2.E1.m1.2.2.2.2.16" xref="S2.E1.m1.2.2.2.2.16.cmml">n</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.2.2.2.2m" xref="S2.E1.m1.2.2.2.2.2.cmml">​</mo><mrow id="S2.E1.m1.2.2.2.2.1.1" xref="S2.E1.m1.2.2.2.2.1.1.1.cmml"><mo stretchy="false" id="S2.E1.m1.2.2.2.2.1.1.2" xref="S2.E1.m1.2.2.2.2.1.1.1.cmml">(</mo><mrow id="S2.E1.m1.2.2.2.2.1.1.1" xref="S2.E1.m1.2.2.2.2.1.1.1.cmml"><mrow id="S2.E1.m1.2.2.2.2.1.1.1.2" xref="S2.E1.m1.2.2.2.2.1.1.1.2.cmml"><mrow id="S2.E1.m1.2.2.2.2.1.1.1.2.2" xref="S2.E1.m1.2.2.2.2.1.1.1.2.2.cmml"><mi id="S2.E1.m1.2.2.2.2.1.1.1.2.2.2" xref="S2.E1.m1.2.2.2.2.1.1.1.2.2.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.2.2.2.1.1.1.2.2.1" xref="S2.E1.m1.2.2.2.2.1.1.1.2.2.1.cmml">​</mo><msub id="S2.E1.m1.2.2.2.2.1.1.1.2.2.3" xref="S2.E1.m1.2.2.2.2.1.1.1.2.2.3.cmml"><mi id="S2.E1.m1.2.2.2.2.1.1.1.2.2.3.2" xref="S2.E1.m1.2.2.2.2.1.1.1.2.2.3.2.cmml">c</mi><mrow id="S2.E1.m1.2.2.2.2.1.1.1.2.2.3.3" xref="S2.E1.m1.2.2.2.2.1.1.1.2.2.3.3.cmml"><mi id="S2.E1.m1.2.2.2.2.1.1.1.2.2.3.3.2" xref="S2.E1.m1.2.2.2.2.1.1.1.2.2.3.3.2.cmml">b</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.2.2.2.1.1.1.2.2.3.3.1" xref="S2.E1.m1.2.2.2.2.1.1.1.2.2.3.3.1.cmml">​</mo><mi id="S2.E1.m1.2.2.2.2.1.1.1.2.2.3.3.3" xref="S2.E1.m1.2.2.2.2.1.1.1.2.2.3.3.3.cmml">g</mi></mrow></msub></mrow><mo lspace="0.222em" rspace="0.222em" id="S2.E1.m1.2.2.2.2.1.1.1.2.1" xref="S2.E1.m1.2.2.2.2.1.1.1.2.1.cmml">×</mo><mi id="S2.E1.m1.2.2.2.2.1.1.1.2.3" xref="S2.E1.m1.2.2.2.2.1.1.1.2.3.cmml">c</mi></mrow><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.2.2.2.1.1.1.1" xref="S2.E1.m1.2.2.2.2.1.1.1.1.cmml">​</mo><mi id="S2.E1.m1.2.2.2.2.1.1.1.3" xref="S2.E1.m1.2.2.2.2.1.1.1.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.2.2.2.1.1.1.1a" xref="S2.E1.m1.2.2.2.2.1.1.1.1.cmml">​</mo><mi id="S2.E1.m1.2.2.2.2.1.1.1.4" xref="S2.E1.m1.2.2.2.2.1.1.1.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.2.2.2.1.1.1.1b" xref="S2.E1.m1.2.2.2.2.1.1.1.1.cmml">​</mo><mi id="S2.E1.m1.2.2.2.2.1.1.1.5" xref="S2.E1.m1.2.2.2.2.1.1.1.5.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.2.2.2.1.1.1.1c" xref="S2.E1.m1.2.2.2.2.1.1.1.1.cmml">​</mo><mi mathvariant="normal" id="S2.E1.m1.2.2.2.2.1.1.1.6" xref="S2.E1.m1.2.2.2.2.1.1.1.6.cmml">_</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.2.2.2.1.1.1.1d" xref="S2.E1.m1.2.2.2.2.1.1.1.1.cmml">​</mo><mi id="S2.E1.m1.2.2.2.2.1.1.1.7" xref="S2.E1.m1.2.2.2.2.1.1.1.7.cmml">f</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.2.2.2.1.1.1.1e" xref="S2.E1.m1.2.2.2.2.1.1.1.1.cmml">​</mo><mi id="S2.E1.m1.2.2.2.2.1.1.1.8" xref="S2.E1.m1.2.2.2.2.1.1.1.8.cmml">a</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.2.2.2.1.1.1.1f" xref="S2.E1.m1.2.2.2.2.1.1.1.1.cmml">​</mo><mi id="S2.E1.m1.2.2.2.2.1.1.1.9" xref="S2.E1.m1.2.2.2.2.1.1.1.9.cmml">c</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.2.2.2.1.1.1.1g" xref="S2.E1.m1.2.2.2.2.1.1.1.1.cmml">​</mo><mi id="S2.E1.m1.2.2.2.2.1.1.1.10" xref="S2.E1.m1.2.2.2.2.1.1.1.10.cmml">t</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.2.2.2.1.1.1.1h" xref="S2.E1.m1.2.2.2.2.1.1.1.1.cmml">​</mo><mi id="S2.E1.m1.2.2.2.2.1.1.1.11" xref="S2.E1.m1.2.2.2.2.1.1.1.11.cmml">o</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.2.2.2.1.1.1.1i" xref="S2.E1.m1.2.2.2.2.1.1.1.1.cmml">​</mo><mi id="S2.E1.m1.2.2.2.2.1.1.1.12" xref="S2.E1.m1.2.2.2.2.1.1.1.12.cmml">r</mi></mrow><mo stretchy="false" id="S2.E1.m1.2.2.2.2.1.1.3" xref="S2.E1.m1.2.2.2.2.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.2b"><apply id="S2.E1.m1.2.2.cmml" xref="S2.E1.m1.2.2"><eq id="S2.E1.m1.2.2.3.cmml" xref="S2.E1.m1.2.2.3"></eq><apply id="S2.E1.m1.2.2.4.cmml" xref="S2.E1.m1.2.2.4"><times id="S2.E1.m1.2.2.4.1.cmml" xref="S2.E1.m1.2.2.4.1"></times><ci id="S2.E1.m1.2.2.4.2.cmml" xref="S2.E1.m1.2.2.4.2">𝐿</ci><apply id="S2.E1.m1.2.2.4.3.cmml" xref="S2.E1.m1.2.2.4.3"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.4.3.1.cmml" xref="S2.E1.m1.2.2.4.3">subscript</csymbol><ci id="S2.E1.m1.2.2.4.3.2.cmml" xref="S2.E1.m1.2.2.4.3.2">𝑐</ci><apply id="S2.E1.m1.2.2.4.3.3.cmml" xref="S2.E1.m1.2.2.4.3.3"><times id="S2.E1.m1.2.2.4.3.3.1.cmml" xref="S2.E1.m1.2.2.4.3.3.1"></times><ci id="S2.E1.m1.2.2.4.3.3.2.cmml" xref="S2.E1.m1.2.2.4.3.3.2">𝑛</ci><ci id="S2.E1.m1.2.2.4.3.3.3.cmml" xref="S2.E1.m1.2.2.4.3.3.3">𝑒</ci><ci id="S2.E1.m1.2.2.4.3.3.4.cmml" xref="S2.E1.m1.2.2.4.3.3.4">𝑤</ci></apply></apply></apply><apply id="S2.E1.m1.2.2.2.cmml" xref="S2.E1.m1.2.2.2"><plus id="S2.E1.m1.2.2.2.3.cmml" xref="S2.E1.m1.2.2.2.3"></plus><apply id="S2.E1.m1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1"><times id="S2.E1.m1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.2"></times><apply id="S2.E1.m1.1.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.3"><times id="S2.E1.m1.1.1.1.1.3.1.cmml" xref="S2.E1.m1.1.1.1.1.3.1"></times><ci id="S2.E1.m1.1.1.1.1.3.2.cmml" xref="S2.E1.m1.1.1.1.1.3.2">𝐿</ci><ci id="S2.E1.m1.1.1.1.1.3.3.cmml" xref="S2.E1.m1.1.1.1.1.3.3">𝑐</ci></apply><apply id="S2.E1.m1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1"><minus id="S2.E1.m1.1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1"></minus><cn type="integer" id="S2.E1.m1.1.1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.2">1</cn><apply id="S2.E1.m1.1.1.1.1.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.3"><times id="S2.E1.m1.1.1.1.1.1.1.1.3.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.3.1"></times><ci id="S2.E1.m1.1.1.1.1.1.1.1.3.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.3.2">𝑐</ci><ci id="S2.E1.m1.1.1.1.1.1.1.1.3.3.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.3.3">𝑟</ci><ci id="S2.E1.m1.1.1.1.1.1.1.1.3.4.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.3.4">𝑜</ci><ci id="S2.E1.m1.1.1.1.1.1.1.1.3.5.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.3.5">𝑝</ci><ci id="S2.E1.m1.1.1.1.1.1.1.1.3.6.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.3.6">_</ci><ci id="S2.E1.m1.1.1.1.1.1.1.1.3.7.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.3.7">𝑓</ci><ci id="S2.E1.m1.1.1.1.1.1.1.1.3.8.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.3.8">𝑎</ci><ci id="S2.E1.m1.1.1.1.1.1.1.1.3.9.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.3.9">𝑐</ci><ci id="S2.E1.m1.1.1.1.1.1.1.1.3.10.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.3.10">𝑡</ci><ci id="S2.E1.m1.1.1.1.1.1.1.1.3.11.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.3.11">𝑜</ci><ci id="S2.E1.m1.1.1.1.1.1.1.1.3.12.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.3.12">𝑟</ci></apply></apply></apply><apply id="S2.E1.m1.2.2.2.2.cmml" xref="S2.E1.m1.2.2.2.2"><times id="S2.E1.m1.2.2.2.2.2.cmml" xref="S2.E1.m1.2.2.2.2.2"></times><ci id="S2.E1.m1.2.2.2.2.3.cmml" xref="S2.E1.m1.2.2.2.2.3">𝑟</ci><ci id="S2.E1.m1.2.2.2.2.4.cmml" xref="S2.E1.m1.2.2.2.2.4">𝑎</ci><ci id="S2.E1.m1.2.2.2.2.5.cmml" xref="S2.E1.m1.2.2.2.2.5">𝑛</ci><ci id="S2.E1.m1.2.2.2.2.6.cmml" xref="S2.E1.m1.2.2.2.2.6">𝑑</ci><ci id="S2.E1.m1.2.2.2.2.7.cmml" xref="S2.E1.m1.2.2.2.2.7">𝑜</ci><ci id="S2.E1.m1.2.2.2.2.8.cmml" xref="S2.E1.m1.2.2.2.2.8">𝑚</ci><ci id="S2.E1.m1.2.2.2.2.9.cmml" xref="S2.E1.m1.2.2.2.2.9">_</ci><ci id="S2.E1.m1.2.2.2.2.10.cmml" xref="S2.E1.m1.2.2.2.2.10">𝑝</ci><ci id="S2.E1.m1.2.2.2.2.11.cmml" xref="S2.E1.m1.2.2.2.2.11">𝑜</ci><ci id="S2.E1.m1.2.2.2.2.12.cmml" xref="S2.E1.m1.2.2.2.2.12">𝑠</ci><ci id="S2.E1.m1.2.2.2.2.13.cmml" xref="S2.E1.m1.2.2.2.2.13">𝑠</ci><ci id="S2.E1.m1.2.2.2.2.14.cmml" xref="S2.E1.m1.2.2.2.2.14">𝑖</ci><ci id="S2.E1.m1.2.2.2.2.15.cmml" xref="S2.E1.m1.2.2.2.2.15">𝑜</ci><ci id="S2.E1.m1.2.2.2.2.16.cmml" xref="S2.E1.m1.2.2.2.2.16">𝑛</ci><apply id="S2.E1.m1.2.2.2.2.1.1.1.cmml" xref="S2.E1.m1.2.2.2.2.1.1"><times id="S2.E1.m1.2.2.2.2.1.1.1.1.cmml" xref="S2.E1.m1.2.2.2.2.1.1.1.1"></times><apply id="S2.E1.m1.2.2.2.2.1.1.1.2.cmml" xref="S2.E1.m1.2.2.2.2.1.1.1.2"><times id="S2.E1.m1.2.2.2.2.1.1.1.2.1.cmml" xref="S2.E1.m1.2.2.2.2.1.1.1.2.1"></times><apply id="S2.E1.m1.2.2.2.2.1.1.1.2.2.cmml" xref="S2.E1.m1.2.2.2.2.1.1.1.2.2"><times id="S2.E1.m1.2.2.2.2.1.1.1.2.2.1.cmml" xref="S2.E1.m1.2.2.2.2.1.1.1.2.2.1"></times><ci id="S2.E1.m1.2.2.2.2.1.1.1.2.2.2.cmml" xref="S2.E1.m1.2.2.2.2.1.1.1.2.2.2">𝐿</ci><apply id="S2.E1.m1.2.2.2.2.1.1.1.2.2.3.cmml" xref="S2.E1.m1.2.2.2.2.1.1.1.2.2.3"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.2.2.1.1.1.2.2.3.1.cmml" xref="S2.E1.m1.2.2.2.2.1.1.1.2.2.3">subscript</csymbol><ci id="S2.E1.m1.2.2.2.2.1.1.1.2.2.3.2.cmml" xref="S2.E1.m1.2.2.2.2.1.1.1.2.2.3.2">𝑐</ci><apply id="S2.E1.m1.2.2.2.2.1.1.1.2.2.3.3.cmml" xref="S2.E1.m1.2.2.2.2.1.1.1.2.2.3.3"><times id="S2.E1.m1.2.2.2.2.1.1.1.2.2.3.3.1.cmml" xref="S2.E1.m1.2.2.2.2.1.1.1.2.2.3.3.1"></times><ci id="S2.E1.m1.2.2.2.2.1.1.1.2.2.3.3.2.cmml" xref="S2.E1.m1.2.2.2.2.1.1.1.2.2.3.3.2">𝑏</ci><ci id="S2.E1.m1.2.2.2.2.1.1.1.2.2.3.3.3.cmml" xref="S2.E1.m1.2.2.2.2.1.1.1.2.2.3.3.3">𝑔</ci></apply></apply></apply><ci id="S2.E1.m1.2.2.2.2.1.1.1.2.3.cmml" xref="S2.E1.m1.2.2.2.2.1.1.1.2.3">𝑐</ci></apply><ci id="S2.E1.m1.2.2.2.2.1.1.1.3.cmml" xref="S2.E1.m1.2.2.2.2.1.1.1.3">𝑟</ci><ci id="S2.E1.m1.2.2.2.2.1.1.1.4.cmml" xref="S2.E1.m1.2.2.2.2.1.1.1.4">𝑜</ci><ci id="S2.E1.m1.2.2.2.2.1.1.1.5.cmml" xref="S2.E1.m1.2.2.2.2.1.1.1.5">𝑝</ci><ci id="S2.E1.m1.2.2.2.2.1.1.1.6.cmml" xref="S2.E1.m1.2.2.2.2.1.1.1.6">_</ci><ci id="S2.E1.m1.2.2.2.2.1.1.1.7.cmml" xref="S2.E1.m1.2.2.2.2.1.1.1.7">𝑓</ci><ci id="S2.E1.m1.2.2.2.2.1.1.1.8.cmml" xref="S2.E1.m1.2.2.2.2.1.1.1.8">𝑎</ci><ci id="S2.E1.m1.2.2.2.2.1.1.1.9.cmml" xref="S2.E1.m1.2.2.2.2.1.1.1.9">𝑐</ci><ci id="S2.E1.m1.2.2.2.2.1.1.1.10.cmml" xref="S2.E1.m1.2.2.2.2.1.1.1.10">𝑡</ci><ci id="S2.E1.m1.2.2.2.2.1.1.1.11.cmml" xref="S2.E1.m1.2.2.2.2.1.1.1.11">𝑜</ci><ci id="S2.E1.m1.2.2.2.2.1.1.1.12.cmml" xref="S2.E1.m1.2.2.2.2.1.1.1.12">𝑟</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.2c">Lc_{new}=Lc\times(1-crop\_factor)+random\_possion(Lc_{bg}\times crop\_factor)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S2.p6.5" class="ltx_p">where <math id="S2.p6.4.m1.1" class="ltx_Math" alttext="Lc_{new}" display="inline"><semantics id="S2.p6.4.m1.1a"><mrow id="S2.p6.4.m1.1.1" xref="S2.p6.4.m1.1.1.cmml"><mi id="S2.p6.4.m1.1.1.2" xref="S2.p6.4.m1.1.1.2.cmml">L</mi><mo lspace="0em" rspace="0em" id="S2.p6.4.m1.1.1.1" xref="S2.p6.4.m1.1.1.1.cmml">​</mo><msub id="S2.p6.4.m1.1.1.3" xref="S2.p6.4.m1.1.1.3.cmml"><mi id="S2.p6.4.m1.1.1.3.2" xref="S2.p6.4.m1.1.1.3.2.cmml">c</mi><mrow id="S2.p6.4.m1.1.1.3.3" xref="S2.p6.4.m1.1.1.3.3.cmml"><mi id="S2.p6.4.m1.1.1.3.3.2" xref="S2.p6.4.m1.1.1.3.3.2.cmml">n</mi><mo lspace="0em" rspace="0em" id="S2.p6.4.m1.1.1.3.3.1" xref="S2.p6.4.m1.1.1.3.3.1.cmml">​</mo><mi id="S2.p6.4.m1.1.1.3.3.3" xref="S2.p6.4.m1.1.1.3.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S2.p6.4.m1.1.1.3.3.1a" xref="S2.p6.4.m1.1.1.3.3.1.cmml">​</mo><mi id="S2.p6.4.m1.1.1.3.3.4" xref="S2.p6.4.m1.1.1.3.3.4.cmml">w</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.p6.4.m1.1b"><apply id="S2.p6.4.m1.1.1.cmml" xref="S2.p6.4.m1.1.1"><times id="S2.p6.4.m1.1.1.1.cmml" xref="S2.p6.4.m1.1.1.1"></times><ci id="S2.p6.4.m1.1.1.2.cmml" xref="S2.p6.4.m1.1.1.2">𝐿</ci><apply id="S2.p6.4.m1.1.1.3.cmml" xref="S2.p6.4.m1.1.1.3"><csymbol cd="ambiguous" id="S2.p6.4.m1.1.1.3.1.cmml" xref="S2.p6.4.m1.1.1.3">subscript</csymbol><ci id="S2.p6.4.m1.1.1.3.2.cmml" xref="S2.p6.4.m1.1.1.3.2">𝑐</ci><apply id="S2.p6.4.m1.1.1.3.3.cmml" xref="S2.p6.4.m1.1.1.3.3"><times id="S2.p6.4.m1.1.1.3.3.1.cmml" xref="S2.p6.4.m1.1.1.3.3.1"></times><ci id="S2.p6.4.m1.1.1.3.3.2.cmml" xref="S2.p6.4.m1.1.1.3.3.2">𝑛</ci><ci id="S2.p6.4.m1.1.1.3.3.3.cmml" xref="S2.p6.4.m1.1.1.3.3.3">𝑒</ci><ci id="S2.p6.4.m1.1.1.3.3.4.cmml" xref="S2.p6.4.m1.1.1.3.3.4">𝑤</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p6.4.m1.1c">Lc_{new}</annotation></semantics></math> represents the newly generated light curve.
The <math id="S2.p6.5.m2.1" class="ltx_Math" alttext="crop\_factor" display="inline"><semantics id="S2.p6.5.m2.1a"><mrow id="S2.p6.5.m2.1.1" xref="S2.p6.5.m2.1.1.cmml"><mi id="S2.p6.5.m2.1.1.2" xref="S2.p6.5.m2.1.1.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S2.p6.5.m2.1.1.1" xref="S2.p6.5.m2.1.1.1.cmml">​</mo><mi id="S2.p6.5.m2.1.1.3" xref="S2.p6.5.m2.1.1.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S2.p6.5.m2.1.1.1a" xref="S2.p6.5.m2.1.1.1.cmml">​</mo><mi id="S2.p6.5.m2.1.1.4" xref="S2.p6.5.m2.1.1.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S2.p6.5.m2.1.1.1b" xref="S2.p6.5.m2.1.1.1.cmml">​</mo><mi id="S2.p6.5.m2.1.1.5" xref="S2.p6.5.m2.1.1.5.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.p6.5.m2.1.1.1c" xref="S2.p6.5.m2.1.1.1.cmml">​</mo><mi mathvariant="normal" id="S2.p6.5.m2.1.1.6" xref="S2.p6.5.m2.1.1.6.cmml">_</mi><mo lspace="0em" rspace="0em" id="S2.p6.5.m2.1.1.1d" xref="S2.p6.5.m2.1.1.1.cmml">​</mo><mi id="S2.p6.5.m2.1.1.7" xref="S2.p6.5.m2.1.1.7.cmml">f</mi><mo lspace="0em" rspace="0em" id="S2.p6.5.m2.1.1.1e" xref="S2.p6.5.m2.1.1.1.cmml">​</mo><mi id="S2.p6.5.m2.1.1.8" xref="S2.p6.5.m2.1.1.8.cmml">a</mi><mo lspace="0em" rspace="0em" id="S2.p6.5.m2.1.1.1f" xref="S2.p6.5.m2.1.1.1.cmml">​</mo><mi id="S2.p6.5.m2.1.1.9" xref="S2.p6.5.m2.1.1.9.cmml">c</mi><mo lspace="0em" rspace="0em" id="S2.p6.5.m2.1.1.1g" xref="S2.p6.5.m2.1.1.1.cmml">​</mo><mi id="S2.p6.5.m2.1.1.10" xref="S2.p6.5.m2.1.1.10.cmml">t</mi><mo lspace="0em" rspace="0em" id="S2.p6.5.m2.1.1.1h" xref="S2.p6.5.m2.1.1.1.cmml">​</mo><mi id="S2.p6.5.m2.1.1.11" xref="S2.p6.5.m2.1.1.11.cmml">o</mi><mo lspace="0em" rspace="0em" id="S2.p6.5.m2.1.1.1i" xref="S2.p6.5.m2.1.1.1.cmml">​</mo><mi id="S2.p6.5.m2.1.1.12" xref="S2.p6.5.m2.1.1.12.cmml">r</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.p6.5.m2.1b"><apply id="S2.p6.5.m2.1.1.cmml" xref="S2.p6.5.m2.1.1"><times id="S2.p6.5.m2.1.1.1.cmml" xref="S2.p6.5.m2.1.1.1"></times><ci id="S2.p6.5.m2.1.1.2.cmml" xref="S2.p6.5.m2.1.1.2">𝑐</ci><ci id="S2.p6.5.m2.1.1.3.cmml" xref="S2.p6.5.m2.1.1.3">𝑟</ci><ci id="S2.p6.5.m2.1.1.4.cmml" xref="S2.p6.5.m2.1.1.4">𝑜</ci><ci id="S2.p6.5.m2.1.1.5.cmml" xref="S2.p6.5.m2.1.1.5">𝑝</ci><ci id="S2.p6.5.m2.1.1.6.cmml" xref="S2.p6.5.m2.1.1.6">_</ci><ci id="S2.p6.5.m2.1.1.7.cmml" xref="S2.p6.5.m2.1.1.7">𝑓</ci><ci id="S2.p6.5.m2.1.1.8.cmml" xref="S2.p6.5.m2.1.1.8">𝑎</ci><ci id="S2.p6.5.m2.1.1.9.cmml" xref="S2.p6.5.m2.1.1.9">𝑐</ci><ci id="S2.p6.5.m2.1.1.10.cmml" xref="S2.p6.5.m2.1.1.10">𝑡</ci><ci id="S2.p6.5.m2.1.1.11.cmml" xref="S2.p6.5.m2.1.1.11">𝑜</ci><ci id="S2.p6.5.m2.1.1.12.cmml" xref="S2.p6.5.m2.1.1.12">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p6.5.m2.1c">crop\_factor</annotation></semantics></math> for each data augmentation is randomly sampled from a
log-normal distribution with a mean of -2 and a variance of 0.6.</p>
</div>
<div id="S2.p7" class="ltx_para">
<p id="S2.p7.1" class="ltx_p">To enhance the diversity of the training set, we augmented the GRB category
data either GRBs selected form GECAM-B/GRD or GRBs selected form Fermi/GBM.
The former supplies initial 657 light curves of GRBs, and the latter provides
initial 6189 light curves of GRBs.
After data augmentation handling discussed above, they were successfully multipled about 23 times, resulting in a sizeable GRB category samples both on target dataset and source dataset finally.
The GRB category samples and non-GRB category samples are divided into respective training set, validation set, and test set based on time period. This is very helpful in avoiding data confusion. The ratio of positive and negative sample numbers in these three data sets is roughly comparable and reasonable. Details are described in the table <a href="#S2.T1" title="Table 1 ‣ 2 Dataset ‣ Advancing Gamma-Ray Burst Identification through Transfer Learning with Convolutional Neural Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<figure id="S2.T1" class="ltx_table">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_1">
<div id="S2.T1.2" class="ltx_block ltx_figure_panel">
<span id="S2.T1.2.1" class="ltx_ERROR undefined">\bc</span>
<figure id="S2.T1.fig1" class="ltx_figure ltx_minipage ltx_align_middle" style="width:284.5pt;">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S2.T1.fig1.1.1.1" class="ltx_text" style="font-size:90%;">Table 1</span>: </span><span id="S2.T1.fig1.2.2" class="ltx_text" style="font-size:90%;">Description of the target and source dataset.</span></figcaption>
</figure>
</div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div id="S2.T1.3" class="ltx_block ltx_figure_panel">
<table id="S2.T1.3.1" class="ltx_tabular ltx_figure_panel ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S2.T1.3.1.1.1" class="ltx_tr">
<th id="S2.T1.3.1.1.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S2.T1.3.1.1.1.1.1" class="ltx_text" style="font-size:90%;">Dataset</span></th>
<th id="S2.T1.3.1.1.1.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S2.T1.3.1.1.1.2.1" class="ltx_text" style="font-size:90%;">Partition</span></th>
<th id="S2.T1.3.1.1.1.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S2.T1.3.1.1.1.3.1" class="ltx_text" style="font-size:90%;">Nu. of GRB</span></th>
<th id="S2.T1.3.1.1.1.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S2.T1.3.1.1.1.4.1" class="ltx_text" style="font-size:90%;">Nu. of non-GRB</span></th>
<th id="S2.T1.3.1.1.1.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S2.T1.3.1.1.1.5.1" class="ltx_text" style="font-size:90%;">Data Period Definition (UTC)</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S2.T1.3.1.2.1" class="ltx_tr">
<td id="S2.T1.3.1.2.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;" rowspan="3"><span id="S2.T1.3.1.2.1.1.1" class="ltx_text" style="font-size:90%;">Target dataset</span></td>
<td id="S2.T1.3.1.2.1.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S2.T1.3.1.2.1.2.1" class="ltx_text" style="font-size:90%;">Training set</span></td>
<td id="S2.T1.3.1.2.1.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S2.T1.3.1.2.1.3.1" class="ltx_text" style="font-size:90%;">10005</span></td>
<td id="S2.T1.3.1.2.1.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S2.T1.3.1.2.1.4.1" class="ltx_text" style="font-size:90%;">10000</span></td>
<td id="S2.T1.3.1.2.1.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S2.T1.3.1.2.1.5.1" class="ltx_text" style="font-size:90%;">01/01/2021 - 11/30/2022</span></td>
</tr>
<tr id="S2.T1.3.1.3.2" class="ltx_tr">
<td id="S2.T1.3.1.3.2.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S2.T1.3.1.3.2.1.1" class="ltx_text" style="font-size:90%;">Validation set</span></td>
<td id="S2.T1.3.1.3.2.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S2.T1.3.1.3.2.2.1" class="ltx_text" style="font-size:90%;">108</span></td>
<td id="S2.T1.3.1.3.2.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S2.T1.3.1.3.2.3.1" class="ltx_text" style="font-size:90%;">500</span></td>
<td id="S2.T1.3.1.3.2.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S2.T1.3.1.3.2.4.1" class="ltx_text" style="font-size:90%;">01/12/2023 - 05/31/2023</span></td>
</tr>
<tr id="S2.T1.3.1.4.3" class="ltx_tr">
<td id="S2.T1.3.1.4.3.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S2.T1.3.1.4.3.1.1" class="ltx_text" style="font-size:90%;">Test set</span></td>
<td id="S2.T1.3.1.4.3.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S2.T1.3.1.4.3.2.1" class="ltx_text" style="font-size:90%;">114</span></td>
<td id="S2.T1.3.1.4.3.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S2.T1.3.1.4.3.3.1" class="ltx_text" style="font-size:90%;">500</span></td>
<td id="S2.T1.3.1.4.3.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S2.T1.3.1.4.3.4.1" class="ltx_text" style="font-size:90%;">06/01/2023 - 31/01/2024</span></td>
</tr>
<tr id="S2.T1.3.1.5.4" class="ltx_tr">
<td id="S2.T1.3.1.5.4.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;" rowspan="3"><span id="S2.T1.3.1.5.4.1.1" class="ltx_text" style="font-size:90%;">Source dataset</span></td>
<td id="S2.T1.3.1.5.4.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S2.T1.3.1.5.4.2.1" class="ltx_text" style="font-size:90%;">Training set</span></td>
<td id="S2.T1.3.1.5.4.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S2.T1.3.1.5.4.3.1" class="ltx_text" style="font-size:90%;">105213</span></td>
<td id="S2.T1.3.1.5.4.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S2.T1.3.1.5.4.4.1" class="ltx_text" style="font-size:90%;">100000</span></td>
<td id="S2.T1.3.1.5.4.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S2.T1.3.1.5.4.5.1" class="ltx_text" style="font-size:90%;">07/14/2008 - 31/12/2016</span></td>
</tr>
<tr id="S2.T1.3.1.6.5" class="ltx_tr">
<td id="S2.T1.3.1.6.5.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S2.T1.3.1.6.5.1.1" class="ltx_text" style="font-size:90%;">Validation set</span></td>
<td id="S2.T1.3.1.6.5.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S2.T1.3.1.6.5.2.1" class="ltx_text" style="font-size:90%;">2333</span></td>
<td id="S2.T1.3.1.6.5.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S2.T1.3.1.6.5.3.1" class="ltx_text" style="font-size:90%;">4000</span></td>
<td id="S2.T1.3.1.6.5.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S2.T1.3.1.6.5.4.1" class="ltx_text" style="font-size:90%;">01/01/2017 - 12/31/2019</span></td>
</tr>
<tr id="S2.T1.3.1.7.6" class="ltx_tr">
<td id="S2.T1.3.1.7.6.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S2.T1.3.1.7.6.1.1" class="ltx_text" style="font-size:90%;">Test set</span></td>
<td id="S2.T1.3.1.7.6.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S2.T1.3.1.7.6.2.1" class="ltx_text" style="font-size:90%;">2776</span></td>
<td id="S2.T1.3.1.7.6.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S2.T1.3.1.7.6.3.1" class="ltx_text" style="font-size:90%;">4000</span></td>
<td id="S2.T1.3.1.7.6.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S2.T1.3.1.7.6.4.1" class="ltx_text" style="font-size:90%;">01/01/2020 - 06/31/2023</span></td>
</tr>
</tbody>
</table>
<span id="S2.T1.3.2" class="ltx_ERROR undefined">\ec</span>
</div>
</div>
</div>
</figure>
<figure id="S2.T2" class="ltx_table">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_1">
<div id="S2.T2.2" class="ltx_block ltx_figure_panel">
<span id="S2.T2.2.1" class="ltx_ERROR undefined">\bc</span>
<figure id="S2.T2.fig1" class="ltx_figure ltx_minipage ltx_align_middle" style="width:284.5pt;">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S2.T2.fig1.1.1.1" class="ltx_text" style="font-size:90%;">Table 2</span>: </span><span id="S2.T2.fig1.2.2" class="ltx_text" style="font-size:90%;">The difference of the data pre-process methods.</span></figcaption>
</figure>
</div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div id="S2.T2.3" class="ltx_block ltx_figure_panel">
<table id="S2.T2.3.1" class="ltx_tabular ltx_figure_panel ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S2.T2.3.1.1.1" class="ltx_tr">
<th id="S2.T2.3.1.1.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S2.T2.3.1.1.1.1.1" class="ltx_text" style="font-size:90%;">Model</span></th>
<th id="S2.T2.3.1.1.1.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S2.T2.3.1.1.1.2.1" class="ltx_text" style="font-size:90%;">Pre-process</span></th>
<th id="S2.T2.3.1.1.1.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="S2.T2.3.1.1.1.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Accuracy</span><span id="S2.T2.3.1.1.1.3.2" class="ltx_text" style="font-size:90%;"> (%)</span>
</th>
<th id="S2.T2.3.1.1.1.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="S2.T2.3.1.1.1.4.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Precision</span><span id="S2.T2.3.1.1.1.4.2" class="ltx_text" style="font-size:90%;"> (%)</span>
</th>
<th id="S2.T2.3.1.1.1.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="S2.T2.3.1.1.1.5.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Recall</span><span id="S2.T2.3.1.1.1.5.2" class="ltx_text" style="font-size:90%;"> (%)</span>
</th>
<th id="S2.T2.3.1.1.1.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="S2.T2.3.1.1.1.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">F1-score</span><span id="S2.T2.3.1.1.1.6.2" class="ltx_text" style="font-size:90%;"> (%)</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S2.T2.3.1.2.1" class="ltx_tr">
<th id="S2.T2.3.1.2.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;" rowspan="4"><span id="S2.T2.3.1.2.1.1.1" class="ltx_text" style="font-size:90%;">ResNet</span></th>
<th id="S2.T2.3.1.2.1.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S2.T2.3.1.2.1.2.1" class="ltx_text" style="font-size:90%;">Norm</span></th>
<td id="S2.T2.3.1.2.1.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S2.T2.3.1.2.1.3.1" class="ltx_text" style="font-size:90%;">94.86</span></td>
<td id="S2.T2.3.1.2.1.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S2.T2.3.1.2.1.4.1" class="ltx_text" style="font-size:90%;">98.61</span></td>
<td id="S2.T2.3.1.2.1.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S2.T2.3.1.2.1.5.1" class="ltx_text" style="font-size:90%;">90.23</span></td>
<td id="S2.T2.3.1.2.1.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S2.T2.3.1.2.1.6.1" class="ltx_text" style="font-size:90%;">94.24</span></td>
</tr>
<tr id="S2.T2.3.1.3.2" class="ltx_tr">
<th id="S2.T2.3.1.3.2.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S2.T2.3.1.3.2.1.1" class="ltx_text" style="font-size:90%;">Norm each channel</span></th>
<td id="S2.T2.3.1.3.2.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S2.T2.3.1.3.2.2.1" class="ltx_text" style="font-size:90%;">95.82</span></td>
<td id="S2.T2.3.1.3.2.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S2.T2.3.1.3.2.3.1" class="ltx_text" style="font-size:90%;">98.29</span></td>
<td id="S2.T2.3.1.3.2.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S2.T2.3.1.3.2.4.1" class="ltx_text" style="font-size:90%;">91.39</span></td>
<td id="S2.T2.3.1.3.2.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S2.T2.3.1.3.2.5.1" class="ltx_text" style="font-size:90%;">94.71</span></td>
</tr>
<tr id="S2.T2.3.1.4.3" class="ltx_tr">
<th id="S2.T2.3.1.4.3.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S2.T2.3.1.4.3.1.1" class="ltx_text" style="font-size:90%;">Standard</span></th>
<td id="S2.T2.3.1.4.3.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S2.T2.3.1.4.3.2.1" class="ltx_text" style="font-size:90%;">96.75</span></td>
<td id="S2.T2.3.1.4.3.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S2.T2.3.1.4.3.3.1" class="ltx_text" style="font-size:90%;">98.22</span></td>
<td id="S2.T2.3.1.4.3.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S2.T2.3.1.4.3.4.1" class="ltx_text" style="font-size:90%;">93.76</span></td>
<td id="S2.T2.3.1.4.3.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S2.T2.3.1.4.3.5.1" class="ltx_text" style="font-size:90%;">95.94</span></td>
</tr>
<tr id="S2.T2.3.1.5.4" class="ltx_tr">
<th id="S2.T2.3.1.5.4.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_b" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S2.T2.3.1.5.4.1.1" class="ltx_text" style="font-size:90%;">Standard each channel</span></th>
<td id="S2.T2.3.1.5.4.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S2.T2.3.1.5.4.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">97.15</span></td>
<td id="S2.T2.3.1.5.4.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S2.T2.3.1.5.4.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">98.42</span></td>
<td id="S2.T2.3.1.5.4.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S2.T2.3.1.5.4.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">94.56</span></td>
<td id="S2.T2.3.1.5.4.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S2.T2.3.1.5.4.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">96.45</span></td>
</tr>
</tbody>
</table>
<span id="S2.T2.3.2" class="ltx_ERROR undefined">\ec</span><span id="S2.T2.3.3" class="ltx_ERROR undefined">\tablecomments</span>
</div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="S2.T2.4" class="ltx_p ltx_figure_panel"><span id="S2.T2.4.1" class="ltx_text" style="font-size:90%;">0.86Bold text represents that the model performs optimally on that metric.</span></p>
</div>
</div>
</figure>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Model architecture, training, and extension</h2>

<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Architecture of Neural Networks</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">Each sample within our dataset comprises light curves across nine distinct energy bands,
making them suitable for treatment as time series data using a 1D convolutional neural network.
Our model’s foundation is based on ResNet <cite class="ltx_cite ltx_citemacro_citep">(He et al. <a href="#bib.bib19" title="" class="ltx_ref">2016</a>)</cite>, which leverages
a series of four convolutional units (Conv Units) to extract features from the data.
ResNet introduces residual connection to address the issue of gradient vanishing in deep neural networks.
Following feature extraction by the convolutional layers, the extracted features are passed through two fully connected layers (FC) for classification after global average pooling.
To prevent over-fitting, a dropout layer with a 50% probability is incorporated
between the global average pooling and the fully connected layer.
The comprehensive architecture of our model is depicted in Figure <a href="#S3.F2" title="Figure 2 ‣ 3.1 Architecture of Neural Networks ‣ 3 Model architecture, training, and extension ‣ Advancing Gamma-Ray Burst Identification through Transfer Learning with Convolutional Neural Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<figure id="S3.F2" class="ltx_figure">
<p id="S3.F2.1.1" class="ltx_p ltx_minipage ltx_align_middle" style="width:433.6pt;"><span id="S3.F2.1.1.1" class="ltx_text"><img src="/html/2408.13598/assets/x2.png" id="S3.F2.1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="461" height="232" alt="Refer to caption"></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F2.3.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S3.F2.4.2" class="ltx_text" style="font-size:90%;">Schematic diagram of model architecture and process of layers’ transfer. The numbers in the convolutional units indicate changes of the size and dimensions of the features. The purple module represents the MSCFM module, with the detailed implementation of this module shown in the sub-graph at the bottom.</span></figcaption>
</figure>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.3" class="ltx_p">Building upon the ResNet architecture, we introduce a novel
multi-scale feature cross fusion module (MSCFM) designed to
enhance the representation of multi-scale features.
Motivated by the distinct behavior of GRB light curves across various time scales,
we incorporate MSFM modules to extract and fuse features at different scales
within our deep learning model.
This approach enables the model to capture the detailed characteristics
of the burst event across multiple scales, enhancing robustness and accuracy.
To facilitate multi-scale feature extraction, we initially employ
a <math id="S3.SS1.p2.1.m1.1" class="ltx_Math" alttext="1\times 1" display="inline"><semantics id="S3.SS1.p2.1.m1.1a"><mrow id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml"><mn id="S3.SS1.p2.1.m1.1.1.2" xref="S3.SS1.p2.1.m1.1.1.2.cmml">1</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p2.1.m1.1.1.1" xref="S3.SS1.p2.1.m1.1.1.1.cmml">×</mo><mn id="S3.SS1.p2.1.m1.1.1.3" xref="S3.SS1.p2.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><apply id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1"><times id="S3.SS1.p2.1.m1.1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1.1"></times><cn type="integer" id="S3.SS1.p2.1.m1.1.1.2.cmml" xref="S3.SS1.p2.1.m1.1.1.2">1</cn><cn type="integer" id="S3.SS1.p2.1.m1.1.1.3.cmml" xref="S3.SS1.p2.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">1\times 1</annotation></semantics></math> convolutional layer to reduce feature dimensionality,
thereby reducing the number of parameters and computational load.
Subsequently, we stack three convolutional layers with a kernel size
of <math id="S3.SS1.p2.2.m2.1" class="ltx_Math" alttext="1\times 3" display="inline"><semantics id="S3.SS1.p2.2.m2.1a"><mrow id="S3.SS1.p2.2.m2.1.1" xref="S3.SS1.p2.2.m2.1.1.cmml"><mn id="S3.SS1.p2.2.m2.1.1.2" xref="S3.SS1.p2.2.m2.1.1.2.cmml">1</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p2.2.m2.1.1.1" xref="S3.SS1.p2.2.m2.1.1.1.cmml">×</mo><mn id="S3.SS1.p2.2.m2.1.1.3" xref="S3.SS1.p2.2.m2.1.1.3.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.1b"><apply id="S3.SS1.p2.2.m2.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1"><times id="S3.SS1.p2.2.m2.1.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1.1"></times><cn type="integer" id="S3.SS1.p2.2.m2.1.1.2.cmml" xref="S3.SS1.p2.2.m2.1.1.2">1</cn><cn type="integer" id="S3.SS1.p2.2.m2.1.1.3.cmml" xref="S3.SS1.p2.2.m2.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.1c">1\times 3</annotation></semantics></math> to extract features at larger scales,
leveraging the increased receptive field of deeper convolutions.
The features extracted at three distinct scales are then cross-fused with
the primary features, and the resulting cross-fused features are restored
to their original dimensions using a <math id="S3.SS1.p2.3.m3.1" class="ltx_Math" alttext="1\times 1" display="inline"><semantics id="S3.SS1.p2.3.m3.1a"><mrow id="S3.SS1.p2.3.m3.1.1" xref="S3.SS1.p2.3.m3.1.1.cmml"><mn id="S3.SS1.p2.3.m3.1.1.2" xref="S3.SS1.p2.3.m3.1.1.2.cmml">1</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p2.3.m3.1.1.1" xref="S3.SS1.p2.3.m3.1.1.1.cmml">×</mo><mn id="S3.SS1.p2.3.m3.1.1.3" xref="S3.SS1.p2.3.m3.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.3.m3.1b"><apply id="S3.SS1.p2.3.m3.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1"><times id="S3.SS1.p2.3.m3.1.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1.1"></times><cn type="integer" id="S3.SS1.p2.3.m3.1.1.2.cmml" xref="S3.SS1.p2.3.m3.1.1.2">1</cn><cn type="integer" id="S3.SS1.p2.3.m3.1.1.3.cmml" xref="S3.SS1.p2.3.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.3.m3.1c">1\times 1</annotation></semantics></math> convolutional layer.
By incorporating these cross-fusion features into the original features
through a residual structure, we obtain multi-scale cross-fusion features.
The MSCFM module is integrated into each convolutional unit of the model,
as indicated by the purple module in Figure <a href="#S3.F2" title="Figure 2 ‣ 3.1 Architecture of Neural Networks ‣ 3 Model architecture, training, and extension ‣ Advancing Gamma-Ray Burst Identification through Transfer Learning with Convolutional Neural Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
This innovative approach enhances the model’s ability to capture and leverage
multi-scale information, ultimately improving its performance
in GRB identification tasks.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.1" class="ltx_p">Optimizing hyper-parameters in deep learning models is essential for enhancing
model performance and generalization by improving data fitting and preventing over-fitting.
By adjusting hyper-parameters, we could expedite model training and ensure optimal performance.
In our work, we conduct a detailed analysis to evaluate the impact of different hyper-parameter
choices on the test set of the source dataset, as referenced in <cite class="ltx_cite ltx_citemacro_citep">(Ma et al. <a href="#bib.bib26" title="" class="ltx_ref">2023</a>)</cite>.
Through this analysis, we identify the hyper-parameter set that yields the best-performing models.
The hyper-parameter configurations that result in the best models are highlighted in bold in Table <a href="#S3.T3" title="Table 3 ‣ 3.1 Architecture of Neural Networks ‣ 3 Model architecture, training, and extension ‣ Advancing Gamma-Ray Burst Identification through Transfer Learning with Convolutional Neural Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.
This systematic evaluation of hyper-parameters allows us to improve our model and enhance its effectiveness in identifying GRBs.</p>
</div>
<figure id="S3.T3" class="ltx_table">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_1">
<div id="S3.T3.2" class="ltx_block ltx_figure_panel">
<span id="S3.T3.2.1" class="ltx_ERROR undefined">\bc</span>
<figure id="S3.T3.fig1" class="ltx_figure ltx_minipage ltx_align_middle" style="width:284.5pt;">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.T3.fig1.1.1.1" class="ltx_text" style="font-size:90%;">Table 3</span>: </span><span id="S3.T3.fig1.2.2" class="ltx_text" style="font-size:90%;">Hyper-parameter selection.</span></figcaption>
</figure>
</div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div id="S3.T3.3" class="ltx_block ltx_figure_panel">
<table id="S3.T3.3.1" class="ltx_tabular ltx_figure_panel ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T3.3.1.1.1" class="ltx_tr">
<th id="S3.T3.3.1.1.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T3.3.1.1.1.1.1" class="ltx_text" style="font-size:90%;">Parameters</span></th>
<th id="S3.T3.3.1.1.1.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T3.3.1.1.1.2.1" class="ltx_text" style="font-size:90%;">Values</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T3.3.1.2.1" class="ltx_tr">
<th id="S3.T3.3.1.2.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T3.3.1.2.1.1.1" class="ltx_text" style="font-size:90%;">Number of ConvUnit</span></th>
<td id="S3.T3.3.1.2.1.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="S3.T3.3.1.2.1.2.1" class="ltx_text" style="font-size:90%;">2, </span><span id="S3.T3.3.1.2.1.2.2" class="ltx_text ltx_font_bold" style="font-size:90%;">4</span><span id="S3.T3.3.1.2.1.2.3" class="ltx_text" style="font-size:90%;">, 8, 16</span>
</td>
</tr>
<tr id="S3.T3.3.1.3.2" class="ltx_tr">
<th id="S3.T3.3.1.3.2.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T3.3.1.3.2.1.1" class="ltx_text" style="font-size:90%;">Number of Conv in ConvUnit</span></th>
<td id="S3.T3.3.1.3.2.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="S3.T3.3.1.3.2.2.1" class="ltx_text" style="font-size:90%;">1, 2, </span><span id="S3.T3.3.1.3.2.2.2" class="ltx_text ltx_font_bold" style="font-size:90%;">3</span><span id="S3.T3.3.1.3.2.2.3" class="ltx_text" style="font-size:90%;">, 4</span>
</td>
</tr>
<tr id="S3.T3.3.1.4.3" class="ltx_tr">
<th id="S3.T3.3.1.4.3.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T3.3.1.4.3.1.1" class="ltx_text" style="font-size:90%;">First ConvUnit filter size</span></th>
<td id="S3.T3.3.1.4.3.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="S3.T3.3.1.4.3.2.1" class="ltx_text" style="font-size:90%;">64, </span><span id="S3.T3.3.1.4.3.2.2" class="ltx_text ltx_font_bold" style="font-size:90%;">128</span><span id="S3.T3.3.1.4.3.2.3" class="ltx_text" style="font-size:90%;">, 256, 512</span>
</td>
</tr>
<tr id="S3.T3.3.1.5.4" class="ltx_tr">
<th id="S3.T3.3.1.5.4.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T3.3.1.5.4.1.1" class="ltx_text" style="font-size:90%;">Second ConvUnit filter size</span></th>
<td id="S3.T3.3.1.5.4.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="S3.T3.3.1.5.4.2.1" class="ltx_text" style="font-size:90%;">64, </span><span id="S3.T3.3.1.5.4.2.2" class="ltx_text ltx_font_bold" style="font-size:90%;">128</span><span id="S3.T3.3.1.5.4.2.3" class="ltx_text" style="font-size:90%;">, 256, 512</span>
</td>
</tr>
<tr id="S3.T3.3.1.6.5" class="ltx_tr">
<th id="S3.T3.3.1.6.5.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T3.3.1.6.5.1.1" class="ltx_text" style="font-size:90%;">Third ConvUnit filter size</span></th>
<td id="S3.T3.3.1.6.5.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="S3.T3.3.1.6.5.2.1" class="ltx_text" style="font-size:90%;">64, </span><span id="S3.T3.3.1.6.5.2.2" class="ltx_text ltx_font_bold" style="font-size:90%;">128</span><span id="S3.T3.3.1.6.5.2.3" class="ltx_text" style="font-size:90%;">, 256, 512</span>
</td>
</tr>
<tr id="S3.T3.3.1.7.6" class="ltx_tr">
<th id="S3.T3.3.1.7.6.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T3.3.1.7.6.1.1" class="ltx_text" style="font-size:90%;">Fourth ConvUnit filter size</span></th>
<td id="S3.T3.3.1.7.6.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="S3.T3.3.1.7.6.2.1" class="ltx_text" style="font-size:90%;">64, </span><span id="S3.T3.3.1.7.6.2.2" class="ltx_text ltx_font_bold" style="font-size:90%;">128</span><span id="S3.T3.3.1.7.6.2.3" class="ltx_text" style="font-size:90%;">, 256, 512</span>
</td>
</tr>
<tr id="S3.T3.3.1.8.7" class="ltx_tr">
<th id="S3.T3.3.1.8.7.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T3.3.1.8.7.1.1" class="ltx_text" style="font-size:90%;">Norm function</span></th>
<td id="S3.T3.3.1.8.7.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="S3.T3.3.1.8.7.2.1" class="ltx_text" style="font-size:90%;">InstaceNorm, </span><span id="S3.T3.3.1.8.7.2.2" class="ltx_text ltx_font_bold" style="font-size:90%;">BatchNorm</span>
</td>
</tr>
<tr id="S3.T3.3.1.9.8" class="ltx_tr">
<th id="S3.T3.3.1.9.8.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T3.3.1.9.8.1.1" class="ltx_text" style="font-size:90%;">Activation function</span></th>
<td id="S3.T3.3.1.9.8.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="S3.T3.3.1.9.8.2.1" class="ltx_text" style="font-size:90%;">Sigmoid, </span><span id="S3.T3.3.1.9.8.2.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Relu</span>
</td>
</tr>
<tr id="S3.T3.3.1.10.9" class="ltx_tr">
<th id="S3.T3.3.1.10.9.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T3.3.1.10.9.1.1" class="ltx_text" style="font-size:90%;">FC neurons</span></th>
<td id="S3.T3.3.1.10.9.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="S3.T3.3.1.10.9.2.1" class="ltx_text" style="font-size:90%;">32, </span><span id="S3.T3.3.1.10.9.2.2" class="ltx_text ltx_font_bold" style="font-size:90%;">64</span><span id="S3.T3.3.1.10.9.2.3" class="ltx_text" style="font-size:90%;">, 128</span>
</td>
</tr>
<tr id="S3.T3.3.1.11.10" class="ltx_tr">
<th id="S3.T3.3.1.11.10.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T3.3.1.11.10.1.1" class="ltx_text" style="font-size:90%;">Dropout rate</span></th>
<td id="S3.T3.3.1.11.10.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="S3.T3.3.1.11.10.2.1" class="ltx_text" style="font-size:90%;">0.3, </span><span id="S3.T3.3.1.11.10.2.2" class="ltx_text ltx_font_bold" style="font-size:90%;">0.5</span><span id="S3.T3.3.1.11.10.2.3" class="ltx_text" style="font-size:90%;">, 0.8</span>
</td>
</tr>
<tr id="S3.T3.3.1.12.11" class="ltx_tr">
<th id="S3.T3.3.1.12.11.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T3.3.1.12.11.1.1" class="ltx_text" style="font-size:90%;">Initial learning rate</span></th>
<td id="S3.T3.3.1.12.11.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="S3.T3.3.1.12.11.2.1" class="ltx_text" style="font-size:90%;">1e-3, 1e-4, </span><span id="S3.T3.3.1.12.11.2.2" class="ltx_text ltx_font_bold" style="font-size:90%;">1e-5</span><span id="S3.T3.3.1.12.11.2.3" class="ltx_text" style="font-size:90%;">, 1e-6</span>
</td>
</tr>
<tr id="S3.T3.3.1.13.12" class="ltx_tr">
<th id="S3.T3.3.1.13.12.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T3.3.1.13.12.1.1" class="ltx_text" style="font-size:90%;">Batch size</span></th>
<td id="S3.T3.3.1.13.12.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="S3.T3.3.1.13.12.2.1" class="ltx_text" style="font-size:90%;">512, </span><span id="S3.T3.3.1.13.12.2.2" class="ltx_text ltx_font_bold" style="font-size:90%;">1024</span><span id="S3.T3.3.1.13.12.2.3" class="ltx_text" style="font-size:90%;">, 2048</span>
</td>
</tr>
<tr id="S3.T3.3.1.14.13" class="ltx_tr">
<th id="S3.T3.3.1.14.13.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T3.3.1.14.13.1.1" class="ltx_text" style="font-size:90%;">Patience of reduce learning rate</span></th>
<td id="S3.T3.3.1.14.13.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="S3.T3.3.1.14.13.2.1" class="ltx_text" style="font-size:90%;">5, </span><span id="S3.T3.3.1.14.13.2.2" class="ltx_text ltx_font_bold" style="font-size:90%;">10</span><span id="S3.T3.3.1.14.13.2.3" class="ltx_text" style="font-size:90%;">, 15</span>
</td>
</tr>
<tr id="S3.T3.3.1.15.14" class="ltx_tr">
<th id="S3.T3.3.1.15.14.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_b" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T3.3.1.15.14.1.1" class="ltx_text" style="font-size:90%;">Patience of early stop</span></th>
<td id="S3.T3.3.1.15.14.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="S3.T3.3.1.15.14.2.1" class="ltx_text" style="font-size:90%;">10, </span><span id="S3.T3.3.1.15.14.2.2" class="ltx_text ltx_font_bold" style="font-size:90%;">20</span><span id="S3.T3.3.1.15.14.2.3" class="ltx_text" style="font-size:90%;">, 40, 60</span>
</td>
</tr>
</tbody>
</table>
<span id="S3.T3.3.2" class="ltx_ERROR undefined">\ec</span><span id="S3.T3.3.3" class="ltx_ERROR undefined">\tablecomments</span>
</div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="S3.T3.4" class="ltx_p ltx_figure_panel"><span id="S3.T3.4.1" class="ltx_text" style="font-size:90%;">0.86Bold text represents the selected hyper-parameter.</span></p>
</div>
</div>
</figure>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Model Pre-training on Fermi/GBM dataset</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">To initiate the training of our deep learning model, we initialize the model parameters
using the truncated normal distribution method proposed by <cite class="ltx_cite ltx_citemacro_citep">(He et al. <a href="#bib.bib18" title="" class="ltx_ref">2015</a>)</cite>.
The batch size for model training is set to 1024, and the cross-entropy loss function
is employed as the supervised model’s loss function to measure the disparity between
the predicted and actual label of the data.
For model optimization, we utilize the Adam optimizer <cite class="ltx_cite ltx_citemacro_citep">(Kingma &amp; Ba <a href="#bib.bib21" title="" class="ltx_ref">2014</a>)</cite>,
which updates the model parameters to minimize the loss during neural network training.
The initial learning rate of the model is established at 1e-5.
In the training process, if the validation loss fails to decrease for 10 consecutive epochs,
we reduce the learning rate by a factor of 2.
To prevent over-fitting, we implement an early stopping mechanism,
terminating the training process when the validation accuracy does not improve for 20 consecutive epochs.
The selection of hyper-parameters such as batch size, initial learning rate, and early stopping criteria
are detailed in Table <a href="#S3.T3" title="Table 3 ‣ 3.1 Architecture of Neural Networks ‣ 3 Model architecture, training, and extension ‣ Advancing Gamma-Ray Burst Identification through Transfer Learning with Convolutional Neural Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.
The parameters from the epochs with the highest accuracy in the validation set are
utilized as the optimal model parameters.
Our model is implemented using the Pytorch framework on a single GPU (NVIDIA RTX-4090).
The evaluation metrics for our model, including
<span id="S3.SS2.p1.1.1" class="ltx_text ltx_font_italic">Accuracy</span>, <span id="S3.SS2.p1.1.2" class="ltx_text ltx_font_italic">Precision</span>, <span id="S3.SS2.p1.1.3" class="ltx_text ltx_font_italic">Recall</span>, and <span id="S3.SS2.p1.1.4" class="ltx_text ltx_font_italic">F1-score</span>,
are consistent with those described in <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al. <a href="#bib.bib49" title="" class="ltx_ref">2024</a>)</cite>.</p>
</div>
<figure id="S3.T4" class="ltx_table">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_1">
<div id="S3.T4.2" class="ltx_block ltx_figure_panel">
<span id="S3.T4.2.1" class="ltx_ERROR undefined">\bc</span>
<figure id="S3.T4.fig1" class="ltx_figure ltx_minipage ltx_align_middle" style="width:284.5pt;">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.T4.fig1.1.1.1" class="ltx_text" style="font-size:90%;">Table 4</span>: </span><span id="S3.T4.fig1.2.2" class="ltx_text" style="font-size:90%;">Model performance on Fermi/GBM dataset.</span></figcaption>
</figure>
</div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div id="S3.T4.3" class="ltx_block ltx_figure_panel">
<table id="S3.T4.3.1" class="ltx_tabular ltx_figure_panel ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T4.3.1.1.1" class="ltx_tr">
<th id="S3.T4.3.1.1.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T4.3.1.1.1.1.1" class="ltx_text" style="font-size:90%;">Model</span></th>
<th id="S3.T4.3.1.1.1.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="S3.T4.3.1.1.1.2.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Accuracy</span><span id="S3.T4.3.1.1.1.2.2" class="ltx_text" style="font-size:90%;"> (%)</span>
</th>
<th id="S3.T4.3.1.1.1.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="S3.T4.3.1.1.1.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Precision</span><span id="S3.T4.3.1.1.1.3.2" class="ltx_text" style="font-size:90%;"> (%)</span>
</th>
<th id="S3.T4.3.1.1.1.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="S3.T4.3.1.1.1.4.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Recall</span><span id="S3.T4.3.1.1.1.4.2" class="ltx_text" style="font-size:90%;"> (%)</span>
</th>
<th id="S3.T4.3.1.1.1.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="S3.T4.3.1.1.1.5.1" class="ltx_text ltx_font_italic" style="font-size:90%;">F1-score</span><span id="S3.T4.3.1.1.1.5.2" class="ltx_text" style="font-size:90%;"> (%)</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T4.3.1.2.1" class="ltx_tr">
<th id="S3.T4.3.1.2.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T4.3.1.2.1.1.1" class="ltx_text" style="font-size:90%;">ResNet</span></th>
<td id="S3.T4.3.1.2.1.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T4.3.1.2.1.2.1" class="ltx_text" style="font-size:90%;">97.15</span></td>
<td id="S3.T4.3.1.2.1.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T4.3.1.2.1.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">98.42</span></td>
<td id="S3.T4.3.1.2.1.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T4.3.1.2.1.4.1" class="ltx_text" style="font-size:90%;">94.56</span></td>
<td id="S3.T4.3.1.2.1.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T4.3.1.2.1.5.1" class="ltx_text" style="font-size:90%;">96.45</span></td>
</tr>
<tr id="S3.T4.3.1.3.2" class="ltx_tr">
<th id="S3.T4.3.1.3.2.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row ltx_border_b" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T4.3.1.3.2.1.1" class="ltx_text" style="font-size:90%;">ResNet+MSCFM</span></th>
<td id="S3.T4.3.1.3.2.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T4.3.1.3.2.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">97.37</span></td>
<td id="S3.T4.3.1.3.2.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T4.3.1.3.2.3.1" class="ltx_text" style="font-size:90%;">97.96</span></td>
<td id="S3.T4.3.1.3.2.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T4.3.1.3.2.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">95.56</span></td>
<td id="S3.T4.3.1.3.2.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T4.3.1.3.2.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">96.75</span></td>
</tr>
</tbody>
</table>
<span id="S3.T4.3.2" class="ltx_ERROR undefined">\ec</span><span id="S3.T4.3.3" class="ltx_ERROR undefined">\tablecomments</span>
</div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="S3.T4.4" class="ltx_p ltx_figure_panel"><span id="S3.T4.4.1" class="ltx_text" style="font-size:90%;">0.86Bold text represents that the model performs optimally on that metric.</span></p>
</div>
</div>
</figure>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Transfer Model to GECAM dataset</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">To enhance the performance of our model in identifying GRBs,
we initially binned the energy bands of the light curves into nine distinct bands for pre-training on the GBM dataset.
This approach enables us to easily transfer the model to the GECAM satellite
by binning the energy ranges of the observed light curves to the similar energy range.
Subsequently, we collected GECAM-B observations to construct the target dataset.
Leveraging the pre-trained model on the source dataset, we fine-tuned the model using the target dataset.
During fine-tuning, we opted to freeze all parameters of the convolutional layer
and solely adjusted the parameters of the fully connected layer.
This indicates that we maintain the feature extraction capability of the model
and only update the classifier to suit the new data.
The learning rate was set to a small value of 1e-6 to facilitate the fine-tuning process,
ensuring gradual adjustments to the model’s performance.
The training settings for the model remained consistent with Section <a href="#S3.SS2" title="3.2 Model Pre-training on Fermi/GBM dataset ‣ 3 Model architecture, training, and extension ‣ Advancing Gamma-Ray Burst Identification through Transfer Learning with Convolutional Neural Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a>.
Furthermore, we conducted an investigation to ascertain whether the model effectively
extracted the key features of the GRBs.
To elucidate the model’s decision-making process, we employed the
Grad-CAM (Gradient-weighted Class Activation Mapping) method, as detailed in <cite class="ltx_cite ltx_citemacro_citep">(Selvaraju et al. <a href="#bib.bib35" title="" class="ltx_ref">2017</a>)</cite>.
This method visually highlights the features that the model focuses on during prediction,
providing valuable insights into the model’s decision-making rationale.</p>
</div>
<figure id="S3.T5" class="ltx_table">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_1">
<div id="S3.T5.2" class="ltx_block ltx_figure_panel">
<span id="S3.T5.2.1" class="ltx_ERROR undefined">\bc</span>
<figure id="S3.T5.fig1" class="ltx_figure ltx_minipage ltx_align_middle" style="width:284.5pt;">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.T5.fig1.1.1.1" class="ltx_text" style="font-size:90%;">Table 5</span>: </span><span id="S3.T5.fig1.2.2" class="ltx_text" style="font-size:90%;">Model performance on GECAM dataset.</span></figcaption>
</figure>
</div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div id="S3.T5.3" class="ltx_block ltx_figure_panel">
<table id="S3.T5.3.1" class="ltx_tabular ltx_figure_panel ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T5.3.1.1.1" class="ltx_tr">
<th id="S3.T5.3.1.1.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T5.3.1.1.1.1.1" class="ltx_text" style="font-size:90%;">Model</span></th>
<th id="S3.T5.3.1.1.1.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T5.3.1.1.1.2.1" class="ltx_text" style="font-size:90%;">Pre-train</span></th>
<th id="S3.T5.3.1.1.1.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T5.3.1.1.1.3.1" class="ltx_text" style="font-size:90%;">Fine-tune</span></th>
<th id="S3.T5.3.1.1.1.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="S3.T5.3.1.1.1.4.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Accuracy</span><span id="S3.T5.3.1.1.1.4.2" class="ltx_text" style="font-size:90%;"> (%)</span>
</th>
<th id="S3.T5.3.1.1.1.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="S3.T5.3.1.1.1.5.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Precision</span><span id="S3.T5.3.1.1.1.5.2" class="ltx_text" style="font-size:90%;"> (%)</span>
</th>
<th id="S3.T5.3.1.1.1.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="S3.T5.3.1.1.1.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Recall</span><span id="S3.T5.3.1.1.1.6.2" class="ltx_text" style="font-size:90%;"> (%)</span>
</th>
<th id="S3.T5.3.1.1.1.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="S3.T5.3.1.1.1.7.1" class="ltx_text ltx_font_italic" style="font-size:90%;">F1-score</span><span id="S3.T5.3.1.1.1.7.2" class="ltx_text" style="font-size:90%;"> (%)</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T5.3.1.2.1" class="ltx_tr">
<td id="S3.T5.3.1.2.1.1" class="ltx_td ltx_nopad_l ltx_nopad_r" style="padding-left:1.0pt;padding-right:1.0pt;"></td>
<th id="S3.T5.3.1.2.1.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T5.3.1.2.1.2.1" class="ltx_text" style="font-size:90%;">dataset</span></th>
<th id="S3.T5.3.1.2.1.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T5.3.1.2.1.3.1" class="ltx_text" style="font-size:90%;">dataset</span></th>
<th id="S3.T5.3.1.2.1.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_th ltx_th_column" style="padding-left:1.0pt;padding-right:1.0pt;"></th>
<th id="S3.T5.3.1.2.1.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_th ltx_th_column" style="padding-left:1.0pt;padding-right:1.0pt;"></th>
<th id="S3.T5.3.1.2.1.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_th ltx_th_column" style="padding-left:1.0pt;padding-right:1.0pt;"></th>
<td id="S3.T5.3.1.2.1.7" class="ltx_td ltx_nopad_l ltx_nopad_r" style="padding-left:1.0pt;padding-right:1.0pt;"></td>
</tr>
<tr id="S3.T5.3.1.3.2" class="ltx_tr">
<td id="S3.T5.3.1.3.2.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;" rowspan="3"><span id="S3.T5.3.1.3.2.1.1" class="ltx_text" style="font-size:90%;">ResNet-MSCFM</span></td>
<td id="S3.T5.3.1.3.2.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T5.3.1.3.2.2.1" class="ltx_text" style="font-size:90%;">GECAM</span></td>
<td id="S3.T5.3.1.3.2.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T5.3.1.3.2.3.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S3.T5.3.1.3.2.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T5.3.1.3.2.4.1" class="ltx_text" style="font-size:90%;">95.44</span></td>
<td id="S3.T5.3.1.3.2.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T5.3.1.3.2.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">95.74</span></td>
<td id="S3.T5.3.1.3.2.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T5.3.1.3.2.6.1" class="ltx_text" style="font-size:90%;">78.94</span></td>
<td id="S3.T5.3.1.3.2.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T5.3.1.3.2.7.1" class="ltx_text" style="font-size:90%;">86.54</span></td>
</tr>
<tr id="S3.T5.3.1.4.3" class="ltx_tr">
<td id="S3.T5.3.1.4.3.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T5.3.1.4.3.1.1" class="ltx_text" style="font-size:90%;">Fermi/GBM</span></td>
<td id="S3.T5.3.1.4.3.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T5.3.1.4.3.2.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S3.T5.3.1.4.3.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T5.3.1.4.3.3.1" class="ltx_text" style="font-size:90%;">96.25</span></td>
<td id="S3.T5.3.1.4.3.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T5.3.1.4.3.4.1" class="ltx_text" style="font-size:90%;">90.99</span></td>
<td id="S3.T5.3.1.4.3.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T5.3.1.4.3.5.1" class="ltx_text" style="font-size:90%;">88.59</span></td>
<td id="S3.T5.3.1.4.3.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T5.3.1.4.3.6.1" class="ltx_text" style="font-size:90%;">89.77</span></td>
</tr>
<tr id="S3.T5.3.1.5.4" class="ltx_tr">
<td id="S3.T5.3.1.5.4.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T5.3.1.5.4.1.1" class="ltx_text" style="font-size:90%;">Fermi/GBM</span></td>
<td id="S3.T5.3.1.5.4.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T5.3.1.5.4.2.1" class="ltx_text" style="font-size:90%;">GECAM</span></td>
<td id="S3.T5.3.1.5.4.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T5.3.1.5.4.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">96.41</span></td>
<td id="S3.T5.3.1.5.4.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T5.3.1.5.4.4.1" class="ltx_text" style="font-size:90%;">91.07</span></td>
<td id="S3.T5.3.1.5.4.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T5.3.1.5.4.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">89.47</span></td>
<td id="S3.T5.3.1.5.4.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_b" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="S3.T5.3.1.5.4.6.1" class="ltx_text ltx_font_bold" style="font-size:90%;">90.26</span></td>
</tr>
</tbody>
</table>
<span id="S3.T5.3.2" class="ltx_ERROR undefined">\ec</span><span id="S3.T5.3.3" class="ltx_ERROR undefined">\tablecomments</span>
</div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="S3.T5.4" class="ltx_p ltx_figure_panel"><span id="S3.T5.4.1" class="ltx_text" style="font-size:90%;">0.86Bold text represents that the model performs optimally on that metric.</span></p>
</div>
</div>
</figure>
<figure id="S3.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<div id="S3.F3.1" class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" style="width:212.5pt;">
<img src="/html/2408.13598/assets/x3.png" id="S3.F3.1.g1" class="ltx_graphics ltx_img_landscape" width="461" height="352" alt="Refer to caption">
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<div id="S3.F3.2" class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" style="width:212.5pt;">
<img src="/html/2408.13598/assets/x4.png" id="S3.F3.2.g1" class="ltx_graphics ltx_img_landscape" width="461" height="347" alt="Refer to caption">
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.4.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S3.F3.5.2" class="ltx_text" style="font-size:90%;">The learning curves for model pre-training and fine-tuning. The left figure represents the pre-training of the ResNet-MSCFM model on the source dataset. The right figure represents fine-tuning of the pre-trained model on the target dataset. The early stopping mechanism leads to variations in the number of training epochs for the model.</span></figcaption>
</figure>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.1" class="ltx_p">Both the GECAM and Fermi satellites possess wide fields of view for observing GRBs.
In typical observation scenarios without obstruction, the same burst may be detected by both satellites.
However, there were 122 GRBs in the years 2022 and 2023 that were present in the
Fermi burst catalog but absent from the GECAM catalog.
To analysis this discrepancy, we extracted the light curves observed
by GECAM at the corresponding trigger times for these bursts.
Subsequently, we applied the best-performing model trained on the GECAM dataset
to identify the missing burst events.
To validate the accuracy of the identified bursts, a manual assessment was conducted,
incorporating factors such as satellite positions, earth occultation, and energy spectra.
This comprehensive assessment process aims to determine the authenticity of the
identified bursts and ensure the reliability of the classification results.</p>
</div>
<figure id="S3.F4" class="ltx_figure">
<div id="S3.F4.2" class="ltx_block ltx_minipage ltx_align_middle" style="width:433.6pt;">
<p id="S3.F4.1.1" class="ltx_p ltx_align_center"><span id="S3.F4.1.1.1" class="ltx_text"><img src="/html/2408.13598/assets/x5.png" id="S3.F4.1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="461" height="146" alt="Refer to caption"></span></p>
<p id="S3.F4.2.2" class="ltx_p ltx_align_center"><span id="S3.F4.2.2.1" class="ltx_text"><img src="/html/2408.13598/assets/x6.png" id="S3.F4.2.2.1.g1" class="ltx_graphics ltx_img_landscape" width="461" height="146" alt="Refer to caption"></span></p>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F4.6.2.1" class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span id="S3.F4.4.1" class="ltx_text" style="font-size:90%;">Feature visualization of two representative GRBs. The long GRB with complex structure (GRB 230307A, GRD06, <cite class="ltx_cite ltx_citemacro_cite">Yi et al. (<a href="#bib.bib46" title="" class="ltx_ref">2023</a>)</cite>) and short GRB (GRB 240112A, GRD07, <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a href="#bib.bib41" title="" class="ltx_ref">2024a</a>)</cite>) are represented. The gray area indicates <math id="S3.F4.4.1.m1.1" class="ltx_Math" alttext="T_{90}" display="inline"><semantics id="S3.F4.4.1.m1.1b"><msub id="S3.F4.4.1.m1.1.1" xref="S3.F4.4.1.m1.1.1.cmml"><mi id="S3.F4.4.1.m1.1.1.2" xref="S3.F4.4.1.m1.1.1.2.cmml">T</mi><mn id="S3.F4.4.1.m1.1.1.3" xref="S3.F4.4.1.m1.1.1.3.cmml">90</mn></msub><annotation-xml encoding="MathML-Content" id="S3.F4.4.1.m1.1c"><apply id="S3.F4.4.1.m1.1.1.cmml" xref="S3.F4.4.1.m1.1.1"><csymbol cd="ambiguous" id="S3.F4.4.1.m1.1.1.1.cmml" xref="S3.F4.4.1.m1.1.1">subscript</csymbol><ci id="S3.F4.4.1.m1.1.1.2.cmml" xref="S3.F4.4.1.m1.1.1.2">𝑇</ci><cn type="integer" id="S3.F4.4.1.m1.1.1.3.cmml" xref="S3.F4.4.1.m1.1.1.3">90</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F4.4.1.m1.1d">T_{90}</annotation></semantics></math>.</span></figcaption>
</figure>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Result</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">The target and source datasets utilized in our study were constructed using GRBs
detected by the GECAM-B and Fermi/GBM, respectively, as shown in Table <a href="#S2.T1" title="Table 1 ‣ 2 Dataset ‣ Advancing Gamma-Ray Burst Identification through Transfer Learning with Convolutional Neural Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
Light curves with a time bin of 64 ms were extracted and binned into 9 energy bands
to capture the photon distribution characteristics specific to GRBs.
To enhance the diversity and richness of burst signals within the datasets,
we proposed a data augmentation method, the efficacy of which is visually demonstrated in Figure <a href="#S2.F1" title="Figure 1 ‣ 2 Dataset ‣ Advancing Gamma-Ray Burst Identification through Transfer Learning with Convolutional Neural Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
This augmentation technique significantly increased the number of training samples
for the GRB categories in the target and source datasets, expanding the samples
from 435 to 10,005 and from 6,189 to 105,213, respectively.
Following a comparative analysis of data pre-processing methods detailed in Table <a href="#S2.T2" title="Table 2 ‣ 2 Dataset ‣ Advancing Gamma-Ray Burst Identification through Transfer Learning with Convolutional Neural Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>,
we opted to standardize the light curve for each energy band.
This standardized approach ensures uniform representation of the data across
different energy bands, facilitating consistent model training and evaluation.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p">We employed a 1D convolutional neural network to classify samples belonging to
GRB and non-GRB categories in a supervised learning framework.
To enhance feature extraction capabilities, we integrated a multi-scale feature
cross fusion module (MSCFM) into the commonly used ResNet model.
The hyper-parameter choices for the model are listed in Table <a href="#S3.T3" title="Table 3 ‣ 3.1 Architecture of Neural Networks ‣ 3 Model architecture, training, and extension ‣ Advancing Gamma-Ray Burst Identification through Transfer Learning with Convolutional Neural Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.
Table <a href="#S3.T4" title="Table 4 ‣ 3.2 Model Pre-training on Fermi/GBM dataset ‣ 3 Model architecture, training, and extension ‣ Advancing Gamma-Ray Burst Identification through Transfer Learning with Convolutional Neural Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> presents the performance comparison between
the baseline model and the model incorporating the MSCFM module on the source dataset.
The results demonstrate that the inclusion of the MSCFM module significantly enhances the model’s performance.
Specifically, the ResNet+MSCFM model, pre-trained on the source dataset,
achieved an impressive accuracy of 97.37%.
Furthermore, Table <a href="#S3.T5" title="Table 5 ‣ 3.3 Transfer Model to GECAM dataset ‣ 3 Model architecture, training, and extension ‣ Advancing Gamma-Ray Burst Identification through Transfer Learning with Convolutional Neural Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> showcases the performance metrics
of the model trained directly on the target dataset, solely on the source dataset,
and through transfer learning to the target dataset.
Notably, by transferring the pre-trained model, the model achieved a high accuracy
of 96.41% on the target test set.
The learning curves for model pre-training and fine-tuning are illustrated in Figure <a href="#S3.F3" title="Figure 3 ‣ 3.3 Transfer Model to GECAM dataset ‣ 3 Model architecture, training, and extension ‣ Advancing Gamma-Ray Burst Identification through Transfer Learning with Convolutional Neural Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>,
providing insights into the model’s training progress.
Additionally, through feature visualization techniques, we observed that the model effectively
extracted and focused on the key features of GRBs, as depicted in Figure <a href="#S3.F4" title="Figure 4 ‣ 3.3 Transfer Model to GECAM dataset ‣ 3 Model architecture, training, and extension ‣ Advancing Gamma-Ray Burst Identification through Transfer Learning with Convolutional Neural Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.
These findings illustrate the model’s ability to discern and focus on essential features
for accurate GRB identification.</p>
</div>
<div id="S4.p3" class="ltx_para">
<p id="S4.p3.1" class="ltx_p">We utilized the model with the highest performance on the target dataset to identify
previously undiscovered GRBs in the GECAM observations.
To establish a baseline for comparison, we selected GRBs detected by Fermi/GBM in 2022 and 2023,
excluding those already identified by the GECAM trigger search algorithm.
The light curves of GECAM corresponding to these burst periods were extracted
using a sliding window approach.
Through a combination of manual analysis, we successfully recovered three GRBs,
as depicted in Figure <a href="#S4.F5" title="Figure 5 ‣ 4 Result ‣ Advancing Gamma-Ray Burst Identification through Transfer Learning with Convolutional Neural Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>,
Figure <a href="#S4.F6" title="Figure 6 ‣ 4 Result ‣ Advancing Gamma-Ray Burst Identification through Transfer Learning with Convolutional Neural Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>, and Figure <a href="#S4.F7" title="Figure 7 ‣ 4 Result ‣ Advancing Gamma-Ray Burst Identification through Transfer Learning with Convolutional Neural Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>.
Visualizations of the extracted features revealed that the most prominent burst
signals detected by more than two detectors align closely with the GRBs identified by Fermi/GBM.
This consistency in signal characteristics across multiple detectors further validates
the effectiveness of our model in accurately identifying and recovering GRBs in the GECAM observations.</p>
</div>
<figure id="S4.F5" class="ltx_figure"><img src="/html/2408.13598/assets/x7.png" id="S4.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="298" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.2.1.1" class="ltx_text" style="font-size:90%;">Figure 5</span>: </span><span id="S4.F5.3.2" class="ltx_text" style="font-size:90%;">Recovered GECAM-B GRB matched with the GRB220829610 of Fermi/GBM. The arrangement of the sub-graphs is based on the direction of the detectors. The green background indicates that the model predicts an burst signal during this time. The color represents the specific burst characteristics that the model focuses on.</span></figcaption>
</figure>
<figure id="S4.F6" class="ltx_figure"><img src="/html/2408.13598/assets/x8.png" id="S4.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="298" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F6.2.1.1" class="ltx_text" style="font-size:90%;">Figure 6</span>: </span><span id="S4.F6.3.2" class="ltx_text" style="font-size:90%;">Recovered GECAM-B GRB matched with the GRB220915218 of Fermi/GBM.</span></figcaption>
</figure>
<figure id="S4.F7" class="ltx_figure"><img src="/html/2408.13598/assets/x9.png" id="S4.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="298" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F7.2.1.1" class="ltx_text" style="font-size:90%;">Figure 7</span>: </span><span id="S4.F7.3.2" class="ltx_text" style="font-size:90%;">Recovered GECAM-B GRB matched with the GRB221203537 of Fermi/GBM.</span></figcaption>
</figure>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Discussion and Conclusion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In traditional analytical methods, researchers strive to swiftly and precisely extract
crucial information from GRBs by analyzing their light curves and spectra.
In this work, we utilized supervised deep learning techniques to detect GRBs from GECAM-B observations.
Our primary objective was to investigate the synergistic effects of data augmentation
methods and transfer learning in enhancing the efficiency of GRB recognition,
particularly when dealing with constraints imposed by limited observation samples.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">In Table <a href="#S2.T1" title="Table 1 ‣ 2 Dataset ‣ Advancing Gamma-Ray Burst Identification through Transfer Learning with Convolutional Neural Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, we have built target and source datasets derived
from GECAM and Fermi/GBM observations, respectively.
To address the challenge posed by a limited sample size of GRBs,
we opted to bin the energy bands of the light curves to align with the
energy bands commonly associated with generic burst identifications.
This alignment facilitates the seamless transfer of models trained on
large-scale data, enhancing the model’s adaptability to new datasets.
Moreover, our proposed data augmentation method has proven to be instrumental
in augmenting the diversity of burst samples significantly.
By reducing the prominence of the burst signal while maintaining a consistent
background level, as exemplified in Figure <a href="#S2.F1" title="Figure 1 ‣ 2 Dataset ‣ Advancing Gamma-Ray Burst Identification through Transfer Learning with Convolutional Neural Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>,
this method has effectively expanded the number of training samples
from a modest few thousand to a substantial hundred thousand.
The integration of data augmentation techniques has mitigated the challenge
of limited training samples in deep learning applications for GRB identification,
thereby improving the model’s generalization capabilities.</p>
</div>
<div id="S5.p3" class="ltx_para">
<p id="S5.p3.1" class="ltx_p">We selected ResNet as the benchmark model for GRB identification due to its robustness
and versatility in deep learning applications.
To enhance the model’s multi-scale feature extraction capabilities,
we introduced a multi-scale feature cross fusion module (MSCFM).
The detailed structure of the model, including the implementation of the MSCFM module,
is illustrated in Figure <a href="#S3.F2" title="Figure 2 ‣ 3.1 Architecture of Neural Networks ‣ 3 Model architecture, training, and extension ‣ Advancing Gamma-Ray Burst Identification through Transfer Learning with Convolutional Neural Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
Table <a href="#S3.T3" title="Table 3 ‣ 3.1 Architecture of Neural Networks ‣ 3 Model architecture, training, and extension ‣ Advancing Gamma-Ray Burst Identification through Transfer Learning with Convolutional Neural Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> provides a comprehensive evaluation
of hyper-parameter selection, assessing the impact of hyper-parameters and optimizing the model.
Our approach involved pre-training the model on the source dataset, as shown in Table <a href="#S3.T4" title="Table 4 ‣ 3.2 Model Pre-training on Fermi/GBM dataset ‣ 3 Model architecture, training, and extension ‣ Advancing Gamma-Ray Burst Identification through Transfer Learning with Convolutional Neural Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.
Incorporating the MSCFM module led to a noticeable improvement in the accuracy of the ResNet model,
indicating that the fusion of multi-scale features enabled the model to capture
richer information and enhance its generalization capacity.
Table <a href="#S3.T5" title="Table 5 ‣ 3.3 Transfer Model to GECAM dataset ‣ 3 Model architecture, training, and extension ‣ Advancing Gamma-Ray Burst Identification through Transfer Learning with Convolutional Neural Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> presents the performance comparison of models with
and without pre-training and fine-tuning.
We observed that pre-trained models, particularly those trained on extensive datasets,
exhibited superior generalization abilities.
Fine-tuning the parameters of pre-trained models on the target dataset
further enhanced their adaptability, highlighting the efficiency of
transfer learning in handling limited data scenarios.
The learning curve depicted in Figure <a href="#S3.F3" title="Figure 3 ‣ 3.3 Transfer Model to GECAM dataset ‣ 3 Model architecture, training, and extension ‣ Advancing Gamma-Ray Burst Identification through Transfer Learning with Convolutional Neural Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> demonstrates
the model’s effective training process,
with the early stopping mechanism preventing over-fitting.
Additionally, the visualization of key features in Figure <a href="#S3.F4" title="Figure 4 ‣ 3.3 Transfer Model to GECAM dataset ‣ 3 Model architecture, training, and extension ‣ Advancing Gamma-Ray Burst Identification through Transfer Learning with Convolutional Neural Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>
showcases the model’s ability to focus on essential burst characteristics,
aligning with human expertise in GRB recognition.
Furthermore, Figures <a href="#S4.F5" title="Figure 5 ‣ 4 Result ‣ Advancing Gamma-Ray Burst Identification through Transfer Learning with Convolutional Neural Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, <a href="#S4.F6" title="Figure 6 ‣ 4 Result ‣ Advancing Gamma-Ray Burst Identification through Transfer Learning with Convolutional Neural Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>, and <a href="#S4.F7" title="Figure 7 ‣ 4 Result ‣ Advancing Gamma-Ray Burst Identification through Transfer Learning with Convolutional Neural Networks" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>
illustrate the successful recovery of three GRBs in real GECAM-B
observations using the optimized model. T
his achievement can be attributed to the synergistic effects of our data augmentation
algorithms, model enhancements, and transfer learning strategies.
The accurate identification of GRBs holds significant importance, as they may potentially
correspond to gravitational waves, fast radio bursts, or other transient
astronomical phenomena <cite class="ltx_cite ltx_citemacro_citep">(Yang et al. <a href="#bib.bib45" title="" class="ltx_ref">2020</a>)</cite>.</p>
</div>
<div id="S5.p4" class="ltx_para">
<p id="S5.p4.1" class="ltx_p">Transfer learning shows as a valuable strategy for addressing the challenge of
limited data samples, thereby enhancing the generalization capacity of deep learning models.
The integration of a 1D convolutional neural network with a multi-scale feature cross
fusion module yielded notable performance improvements following pre-training on a comprehensive dataset.
This enhancement not only bolstered the model’s generalization capabilities but
also facilitated seamless adaptation to GECAM data.
This is demonstrated by the model’s precise identification of burst events,
in alignment with expert human analysis.
In the future, we plan to incorporate this refined methodology into the GECAM data
analysis pipeline to streamline the identification of GRBs.
Furthermore, the scalability of this approach allows for potential extension to other
satellite missions in the future, such as GECAM-C (HEBS, <cite class="ltx_cite ltx_citemacro_cite">Zheng et al. (<a href="#bib.bib52" title="" class="ltx_ref">2024</a>)</cite>),
GECEM-D (DRO/GTM, <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a href="#bib.bib43" title="" class="ltx_ref">2024c</a>)</cite>), HXMT <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al. <a href="#bib.bib50" title="" class="ltx_ref">2020</a>)</cite>, and SVOM/GRM <cite class="ltx_cite ltx_citemacro_citep">(Zhao et al. <a href="#bib.bib51" title="" class="ltx_ref">2012</a>)</cite>.
By leveraging data from multiple satellites, a collaborative multi-satellite analysis
could be pursued to enhance GRB searches, potentially enabling follow-up observations
across various wavelength bands.
This collaborative effort holds promise for capturing the elusive early afterglow
of GRBs, underscoring the significance of interdisciplinary cooperation in advancing
our understanding of these transient astronomical phenomena.</p>
</div>
<div class="ltx_acknowledgements">
<h6 class="ltx_title ltx_title_acknowledgements">Acknowledgements.</h6>
We would like to thank Prof XXX,Prof. Rui Luo, Dr. Crupi, Riccardo and
Dr. Yi Yang for helpful discussion.
We thank Sheng-lun Xie, Yue Wang for sharing of data analyzing.
This study is supported by the National Natural Science Foundation
of China (grant Nos. 12103055, 12273042, 12133007, 41827807, and 61271351) and
by the National Key R&amp;D Program of China (2021YFA0718500).
This work is also partially supported by the Strategic Priority Research
Program of the CAS under grant No. XDA15360300. B. L. acknowledges support
from the National Astronomical Science Data Center Young Data Scientist
Program (grant No. NADC2023YDS-04).

</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abraham et al. (2021)</span>
<span class="ltx_bibblock">
Abraham, S., Mukund, N., Vibhute, A., et al. 2021, MNRAS, 504, 3084

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Alves et al. (2022)</span>
<span class="ltx_bibblock">
Alves, C. S., Peiris, H. V., Lochner, M., et al. 2022, ApJS, 258, 23

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Alzubaidi et al. (2021)</span>
<span class="ltx_bibblock">
Alzubaidi, L., Zhang, J., Humaidi, A. J., et al. 2021, Journal of Big Data, 8

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">An et al. (2021)</span>
<span class="ltx_bibblock">
An, Z. H., Sun, X. L., Zhang, D. L., et al. 2021, arXiv e-prints, arXiv:2112.04774

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Atteia et al. (2022)</span>
<span class="ltx_bibblock">
Atteia, J. L., Cordier, B., &amp; Wei, J. 2022, International Journal of Modern Physics D, 31, 2230008

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Awang Iskandar et al. (2020)</span>
<span class="ltx_bibblock">
Awang Iskandar, D. N. F., Zijlstra, A. A., McDonald, I., et al. 2020, Galaxies, 8, 88

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Band (2002)</span>
<span class="ltx_bibblock">
Band, D. L. 2002, ApJ, 578, 806

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Barchi et al. (2020)</span>
<span class="ltx_bibblock">
Barchi, P. H., de Carvalho, R. R., Rosa, R. R., et al. 2020, Astronomy and Computing, 30, 100334

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Baron (2019)</span>
<span class="ltx_bibblock">
Baron, D. 2019, arXiv e-prints, arXiv:1904.07248

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Blackburn et al. (2013)</span>
<span class="ltx_bibblock">
Blackburn, L., Briggs, M. S., Camp, J., et al. 2013, arXiv e-prints, arXiv:1303.2174

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cai et al. (2021)</span>
<span class="ltx_bibblock">
Cai, C., Xiong, S. L., Li, C. K., et al. 2021, MNRAS, 508, 3910

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cavuoti et al. (2024)</span>
<span class="ltx_bibblock">
Cavuoti, S., De Cicco, D., Doorenbos, L., et al. 2024, A&amp;A, 687, A246

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Crupi et al. (2023)</span>
<span class="ltx_bibblock">
Crupi, R., Dilillo, G., Bissaldi, E., et al. 2023, Experimental Astronomy, 56, 421

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Djorgovski et al. (2022)</span>
<span class="ltx_bibblock">
Djorgovski, S. G., Mahabal, A. A., Graham, M. J., Polsterer, K., &amp; Krone-Martins, A. 2022, arXiv e-prints, arXiv:2212.01493

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Domínguez Sánchez et al. (2019)</span>
<span class="ltx_bibblock">
Domínguez Sánchez, H., Huertas-Company, M., Bernardi, M., et al. 2019, MNRAS, 484, 93

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">du Buisson et al. (2015)</span>
<span class="ltx_bibblock">
du Buisson, L., Sivanandam, N., Bassett, B. A., &amp; Smith, M. 2015, MNRAS, 454, 2026

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fotopoulou (2024)</span>
<span class="ltx_bibblock">
Fotopoulou, S. 2024, Astronomy and Computing, 48, 100851

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et al. (2015)</span>
<span class="ltx_bibblock">
He, K., Zhang, X., Ren, S., &amp; Sun, J. 2015, in Proceedings of the 2015 IEEE International Conference on Computer Vision (ICCV), ICCV ’15 (USA: IEEE Computer Society), 1026–1034

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et al. (2016)</span>
<span class="ltx_bibblock">
He, K., Zhang, X., Ren, S., &amp; Sun, J. 2016, in Proceedings of 2016 IEEE Conference on Computer Vision and Pattern Recognition, CVPR ’16 (IEEE), 770

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim et al. (2021)</span>
<span class="ltx_bibblock">
Kim, D.-W., Yeo, D., Bailer-Jones, C. A. L., &amp; Lee, G. 2021, A&amp;A, 653, A22

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kingma &amp; Ba (2014)</span>
<span class="ltx_bibblock">
Kingma, D. P., &amp; Ba, J. 2014, arXiv e-prints, arXiv:1412.6980

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Krimm et al. (2013)</span>
<span class="ltx_bibblock">
Krimm, H. A., Holland, S. T., Corbet, R. H. D., et al. 2013, ApJS, 209, 14

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kumar &amp; Zhang (2015)</span>
<span class="ltx_bibblock">
Kumar, P., &amp; Zhang, B. 2015, Phys. Rep., 561, 1

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kumar et al. (2023)</span>
<span class="ltx_bibblock">
Kumar, T., Mileo, A., Brennan, R., &amp; Bendechache, M. 2023, arXiv e-prints, arXiv:2301.02830

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2020)</span>
<span class="ltx_bibblock">
Li, Y., Wen, X., Sun, X., et al. 2020, Scientia Sinica Physica, Mechanica &amp; Astronomica, 50, 129508

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ma et al. (2023)</span>
<span class="ltx_bibblock">
Ma, P. X., Ng, C., Rizk, L., et al. 2023, Nature Astronomy, 7, 492

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Meegan et al. (2009)</span>
<span class="ltx_bibblock">
Meegan, C., Lichti, G., Bhat, P. N., et al. 2009, ApJ, 702, 791

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mészáros (2019)</span>
<span class="ltx_bibblock">
Mészáros, P. 2019, MmSAI, 90, 57

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mumuni &amp; Mumuni (2022)</span>
<span class="ltx_bibblock">
Mumuni, A. G., &amp; Mumuni, F. 2022, Array, 16, 100258

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pan &amp; Yang (2010)</span>
<span class="ltx_bibblock">
Pan, S. J., &amp; Yang, Q. 2010, IEEE Transactions on Knowledge and Data Engineering, 22, 1345

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Parmiggiani et al. (2021)</span>
<span class="ltx_bibblock">
Parmiggiani, N., Bulgarelli, A., Fioretti, V., et al. 2021, APJ, 914, 67

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Parmiggiani et al. (2023)</span>
<span class="ltx_bibblock">
Parmiggiani, N., Bulgarelli, A., Ursi, A., et al. 2023, APJ, 945, 106

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Parmiggiani et al. (2024)</span>
<span class="ltx_bibblock">
Parmiggiani, N., Bulgarelli, A., Macaluso, A., et al. 2024, arXiv e-prints, arXiv:2404.02107

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rizzo et al. (2024)</span>
<span class="ltx_bibblock">
Rizzo, A., Parmiggiani, N., Bulgarelli, A., et al. 2024, arXiv e-prints, arXiv:2404.14133

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Selvaraju et al. (2017)</span>
<span class="ltx_bibblock">
Selvaraju, R. R., Cogswell, M., Das, A., et al. 2017, in 2017 IEEE International Conference on Computer Vision (ICCV), Venice, Italy, 618

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sooknunan et al. (2021)</span>
<span class="ltx_bibblock">
Sooknunan, K., Lochner, M., Bassett, B. A., et al. 2021, MNRAS, 502, 206

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et al. (2023)</span>
<span class="ltx_bibblock">
Sun, H., Wang, C. W., Yang, J., et al. 2023, arXiv e-prints, arXiv:2307.05689

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Taye (2023)</span>
<span class="ltx_bibblock">
Taye, M. M. 2023, computation, 11, 52

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">von Kienlin et al. (2020)</span>
<span class="ltx_bibblock">
von Kienlin, A., Meegan, C. A., Paciesas, W. S., et al. 2020, ApJ, 893, 46

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wagstaff et al. (2016)</span>
<span class="ltx_bibblock">
Wagstaff, K. L., Tang, B., Thompson, D. R., et al. 2016, PASP, 128, 084503

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2024a)</span>
<span class="ltx_bibblock">
Wang, C.-W., Xiong, S.-L., &amp; GECAM Team. 2024a, GRB Coordinates Network, 35520, 1

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2024b)</span>
<span class="ltx_bibblock">
Wang, C.-W., Tan, W.-J., Xiong, S.-L., et al. 2024b, arXiv e-prints, arXiv:2407.02376

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2024c)</span>
<span class="ltx_bibblock">
Wang, C., Zhang, J., Zheng, S., et al. 2024c, Experimental Astronomy, 57, 26

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2024d)</span>
<span class="ltx_bibblock">
Wang, Z., Wang, P., Liu, K., et al. 2024d, arXiv e-prints, arXiv:2405.09591

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al. (2020)</span>
<span class="ltx_bibblock">
Yang, Y.-S., Zhong, S.-Q., Zhang, B.-B., et al. 2020, APJ, 899, 60

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yi et al. (2023)</span>
<span class="ltx_bibblock">
Yi, S. X., Wang, C. W., Shao, X. Y., et al. 2023, arXiv e-prints, arXiv:2310.07205

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yosinski et al. (2014)</span>
<span class="ltx_bibblock">
Yosinski, J., Clune, J., Bengio, Y., &amp; Lipson, H. 2014, arXiv e-prints, arXiv:1411.1792

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang (2011)</span>
<span class="ltx_bibblock">
Zhang, B. 2011, Comptes Rendus Physique, 12, 206

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2024)</span>
<span class="ltx_bibblock">
Zhang, P., Li, B., Gui, R., et al. 2024, ApJS, 272, 4

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2020)</span>
<span class="ltx_bibblock">
Zhang, S.-N., Li, T., Lu, F., et al. 2020, Science China Physics, Mechanics, and Astronomy, 63, 249502

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al. (2012)</span>
<span class="ltx_bibblock">
Zhao, D., Cordier, B., Sizun, P., et al. 2012, Experimental Astronomy, 34, 705

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zheng et al. (2024)</span>
<span class="ltx_bibblock">
Zheng, C., An, Z.-H., Peng, W.-X., et al. 2024, Nuclear Instruments and Methods in Physics Research A, 1059, 169009

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2408.13597" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2408.13598" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2408.13598">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2408.13598" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2408.13599" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Sep  5 12:19:46 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
