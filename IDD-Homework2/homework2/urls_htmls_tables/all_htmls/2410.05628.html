<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Versatile Motion-Language Models for Multi-turn Interactive Agents</title>
<!--Generated on Mon Oct 14 11:44:43 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2410.05628v2/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#S1" title="In Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#S2" title="In Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#S2.SS0.SSS0.Px1" title="In 2 Related Work ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_title">Human Motion Modeling &amp; Control</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#S2.SS0.SSS0.Px2" title="In 2 Related Work ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_title">Motion Language Model</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#S2.SS0.SSS0.Px3" title="In 2 Related Work ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_title">Human-Human Interactive Motion Modeling</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#S3" title="In Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span><math alttext="\text{Inter}\text{-MT}^{2}" class="ltx_Math" display="inline"><semantics><msup><mrow><mtext>Inter</mtext><mtext>-MT</mtext></mrow><mn>2</mn></msup><annotation-xml encoding="MathML-Content"><apply><csymbol cd="ambiguous">superscript</csymbol><ci><mrow><mtext>Inter</mtext><mtext>-MT</mtext></mrow></ci><cn type="integer">2</cn></apply></annotation-xml><annotation encoding="application/x-tex">\text{Inter}\text{-MT}^{2}</annotation><annotation encoding="application/x-llamapun">roman_Inter -MT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math>: Interactive multi-turn motion-text dataset</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#S4" title="In Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>VIM: Versatile Interactive Motion-Language Model</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#S4.SS1" title="In 4 VIM: Versatile Interactive Motion-Language Model ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Notations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#S4.SS2" title="In 4 VIM: Versatile Interactive Motion-Language Model ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Architecture</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#S4.SS3" title="In 4 VIM: Versatile Interactive Motion-Language Model ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Training</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#S4.SS3.SSS0.Px1" title="In 4.3 Training ‣ 4 VIM: Versatile Interactive Motion-Language Model ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_title">Motion Tokenizer</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#S4.SS3.SSS0.Px2" title="In 4.3 Training ‣ 4 VIM: Versatile Interactive Motion-Language Model ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_title">Pre-training Strategy</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#S4.SS3.SSS0.Px3" title="In 4.3 Training ‣ 4 VIM: Versatile Interactive Motion-Language Model ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_title">Instruction-tunning with <span class="ltx_text ltx_markedasmath ltx_font_smallcaps">Inter</span><span class="ltx_text ltx_font_smallcaps">-<math alttext="\text{MT}^{2}" class="ltx_Math" display="inline"><semantics><msup><mtext class="ltx_font_smallcaps">MT</mtext><mn>2</mn></msup><annotation-xml encoding="MathML-Content"><apply><csymbol cd="ambiguous">superscript</csymbol><ci><mtext class="ltx_font_smallcaps">MT</mtext></ci><cn type="integer">2</cn></apply></annotation-xml><annotation encoding="application/x-tex">\text{MT}^{2}</annotation><annotation encoding="application/x-llamapun">MT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math></span> Data</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#S4.SS4" title="In 4 VIM: Versatile Interactive Motion-Language Model ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4 </span>Advanced Downstream Interactive Motion Tasks</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#S5" title="In Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#S5.SS1" title="In 5 Experiments ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Evaluation Tasks and Baselines</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#S5.SS1.SSS0.Px1" title="In 5.1 Evaluation Tasks and Baselines ‣ 5 Experiments ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_title">Motion Reasoning</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#S5.SS1.SSS0.Px2" title="In 5.1 Evaluation Tasks and Baselines ‣ 5 Experiments ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_title">Motion Editing</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#S5.SS1.SSS0.Px3" title="In 5.1 Evaluation Tasks and Baselines ‣ 5 Experiments ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_title">Traditional Motion Relevant Tasks</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#S5.SS1.SSS0.Px4" title="In 5.1 Evaluation Tasks and Baselines ‣ 5 Experiments ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_title">Baselines</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#S5.SS2" title="In 5 Experiments ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Motion Reasoning</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#S5.SS3" title="In 5 Experiments ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3 </span>Motion Editing</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#S5.SS4" title="In 5 Experiments ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.4 </span>Traditional Motion Related Tasks</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#S5.SS5" title="In 5 Experiments ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.5 </span>Ablation Studies on Motion Tokenizer</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#S6" title="In Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Conclusion and Discussions</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#S6.SS0.SSS0.Px1" title="In 6 Conclusion and Discussions ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_title">Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#S6.SS0.SSS0.Px2" title="In 6 Conclusion and Discussions ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_title">Limitations and Impact Statement</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#A1" title="In Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Appendix</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#A1.SS1" title="In Appendix A Appendix ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.1 </span>Motion Representation and Motion Token Representation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#A1.SS2" title="In Appendix A Appendix ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.2 </span>Data Sample Visualization</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#A1.SS3" title="In Appendix A Appendix ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.3 </span><span class="ltx_text ltx_markedasmath ltx_font_smallcaps">Inter</span><span class="ltx_text ltx_font_smallcaps">-<math alttext="\text{MT}^{2}" class="ltx_Math" display="inline"><semantics><msup><mtext class="ltx_font_smallcaps">MT</mtext><mn>2</mn></msup><annotation-xml encoding="MathML-Content"><apply><csymbol cd="ambiguous">superscript</csymbol><ci><mtext class="ltx_font_smallcaps">MT</mtext></ci><cn type="integer">2</cn></apply></annotation-xml><annotation encoding="application/x-tex">\text{MT}^{2}</annotation><annotation encoding="application/x-llamapun">MT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math></span> Statistics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#A1.SS4" title="In Appendix A Appendix ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.4 </span>Detailed Task Explanations</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#A1.SS4.SSS0.Px1" title="In A.4 Detailed Task Explanations ‣ Appendix A Appendix ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_title">Motion Editing</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#A1.SS4.SSS0.Px2" title="In A.4 Detailed Task Explanations ‣ Appendix A Appendix ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_title">Motion Reasoning</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#A1.SS5" title="In Appendix A Appendix ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.5 </span>Ablation Studies on Pretraining Method</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#A1.SS6" title="In Appendix A Appendix ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.6 </span>Qualitative Results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#A1.SS7" title="In Appendix A Appendix ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.7 </span>Implementation details for MotionGPT<sup class="ltx_sup">∗</sup></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#A1.SS8" title="In Appendix A Appendix ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.8 </span>Detailed Explanation about Two-stage Baselines</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#A1.SS8.SSS0.Px1" title="In A.8 Detailed Explanation about Two-stage Baselines ‣ Appendix A Appendix ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_title">Motion Editing</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#A1.SS8.SSS0.Px2" title="In A.8 Detailed Explanation about Two-stage Baselines ‣ Appendix A Appendix ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_title">Motion Reasoning</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#A1.SS9" title="In Appendix A Appendix ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.9 </span>Template Forms for Pre-training and Instruction Tuning</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#A1.SS9.SSS0.Px1" title="In A.9 Template Forms for Pre-training and Instruction Tuning ‣ Appendix A Appendix ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_title">Pre-training Templates</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#A1.SS9.SSS0.Px2" title="In A.9 Template Forms for Pre-training and Instruction Tuning ‣ Appendix A Appendix ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_title">Instruction-Tuning Templates</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#A1.SS10" title="In Appendix A Appendix ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.10 </span>Implementation Details</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#A1.SS11" title="In Appendix A Appendix ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.11 </span>More details about Evaluation Metric for Traditional Motion Related Tasks</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#A1.SS11.SSS0.Px1" title="In A.11 More details about Evaluation Metric for Traditional Motion Related Tasks ‣ Appendix A Appendix ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_title">Motion Quality</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#A1.SS11.SSS0.Px2" title="In A.11 More details about Evaluation Metric for Traditional Motion Related Tasks ‣ Appendix A Appendix ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_title">Motion Diversity</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#A1.SS11.SSS0.Px3" title="In A.11 More details about Evaluation Metric for Traditional Motion Related Tasks ‣ Appendix A Appendix ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_title">Condition Matching</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#A1.SS12" title="In Appendix A Appendix ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.12 </span>User Subject Studies Protocols for motion editing</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#A1.SS12.SSS1" title="In A.12 User Subject Studies Protocols for motion editing ‣ Appendix A Appendix ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.12.1 </span>Instructions</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#A1.SS12.SSS2" title="In A.12 User Subject Studies Protocols for motion editing ‣ Appendix A Appendix ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.12.2 </span>Qualifying test</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#A1.SS12.SSS3" title="In A.12 User Subject Studies Protocols for motion editing ‣ Appendix A Appendix ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.12.3 </span>Detailed Survey Format</span></a>
<ol class="ltx_toclist ltx_toclist_subsubsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#A1.SS12.SSS3.Px1" title="In A.12.3 Detailed Survey Format ‣ A.12 User Subject Studies Protocols for motion editing ‣ Appendix A Appendix ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_title">Main Survey Structure</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#A1.SS12.SSS3.Px2" title="In A.12.3 Detailed Survey Format ‣ A.12 User Subject Studies Protocols for motion editing ‣ Appendix A Appendix ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_title">Evaluation Metrics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#A1.SS12.SSS3.Px3" title="In A.12.3 Detailed Survey Format ‣ A.12 User Subject Studies Protocols for motion editing ‣ Appendix A Appendix ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_title">Exclusion Criteria</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#A1.SS13" title="In Appendix A Appendix ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.13 </span>Prompts for Data collection in <span class="ltx_text ltx_markedasmath ltx_font_smallcaps">Inter</span><span class="ltx_text ltx_font_smallcaps">-<math alttext="\text{MT}^{2}" class="ltx_Math" display="inline"><semantics><msup><mtext class="ltx_font_smallcaps">MT</mtext><mn>2</mn></msup><annotation-xml encoding="MathML-Content"><apply><csymbol cd="ambiguous">superscript</csymbol><ci><mtext class="ltx_font_smallcaps">MT</mtext></ci><cn type="integer">2</cn></apply></annotation-xml><annotation encoding="application/x-tex">\text{MT}^{2}</annotation><annotation encoding="application/x-llamapun">MT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math></span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#A1.SS14" title="In Appendix A Appendix ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.14 </span>Prompts for LLM-Assisted Evaluation</span></a></li>
</ol>
</li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line" lang="en">
<h1 class="ltx_title ltx_title_document">Versatile Motion-Language Models for 
<br class="ltx_break"/>Multi-turn Interactive Agents</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jeongeun Park<sup class="ltx_sup" id="id10.6.id1">1</sup>  , Sungjoon Choi<sup class="ltx_sup" id="id11.7.id2"><span class="ltx_text ltx_font_italic" id="id11.7.id2.1">1†</span></sup> &amp; Sangdoo Yun<sup class="ltx_sup" id="id12.8.id3">2</sup>
<br class="ltx_break"/><sup class="ltx_sup" id="id13.9.id4">1</sup>Korea University, <sup class="ltx_sup" id="id14.10.id5">2</sup> NAVER AI Lab
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id15.11.id6">{baro0906,sungjoon-choi}@korea.ac.kr</span>, <span class="ltx_text ltx_font_typewriter" id="id16.12.id7">sangdoo.yun@navercorp.com</span>
<br class="ltx_break"/>
</span><span class="ltx_author_notes">This research was conducted as part of an internship at NAVER AI Lab, 2024Corresponding authors</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id9.4"><span class="ltx_text" id="id9.4.4">Recent advancements in large language models (LLMs) have greatly enhanced their ability to generate natural and contextually relevant text, making AI interactions more human-like. However, generating and understanding interactive human-like motion, where two individuals engage in coordinated movements, remains a challenge due to the complexity of modeling these coordinated interactions. Furthermore, a versatile model is required to handle diverse interactive scenarios, such as chat systems that follow user instructions or adapt to their assigned role while adjusting interaction dynamics.
To tackle this problem, we introduce <span class="ltx_text ltx_font_bold ltx_font_smallcaps" id="id9.4.4.3">VIM</span>, short for the Versatile Interactive Motion language model, which integrates both language and motion modalities to effectively understand, generate, and control interactive motions in multi-turn conversational contexts.
To address the scarcity of multi-turn interactive motion data, we introduce a synthetic dataset called <span class="ltx_text ltx_markedasmath ltx_font_bold ltx_font_smallcaps" id="id9.4.4.4">Inter</span><span class="ltx_text ltx_font_bold ltx_font_smallcaps" id="id7.2.2.1">-<math alttext="\text{MT}^{2}" class="ltx_Math" display="inline" id="id7.2.2.1.m1.1"><semantics id="id7.2.2.1.m1.1a"><msup id="id7.2.2.1.m1.1.1" xref="id7.2.2.1.m1.1.1.cmml"><mtext class="ltx_font_smallcaps" id="id7.2.2.1.m1.1.1.2" xref="id7.2.2.1.m1.1.1.2a.cmml">MT</mtext><mn id="id7.2.2.1.m1.1.1.3" xref="id7.2.2.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="id7.2.2.1.m1.1b"><apply id="id7.2.2.1.m1.1.1.cmml" xref="id7.2.2.1.m1.1.1"><csymbol cd="ambiguous" id="id7.2.2.1.m1.1.1.1.cmml" xref="id7.2.2.1.m1.1.1">superscript</csymbol><ci id="id7.2.2.1.m1.1.1.2a.cmml" xref="id7.2.2.1.m1.1.1.2"><mtext class="ltx_font_smallcaps" id="id7.2.2.1.m1.1.1.2.cmml" xref="id7.2.2.1.m1.1.1.2">MT</mtext></ci><cn id="id7.2.2.1.m1.1.1.3.cmml" type="integer" xref="id7.2.2.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id7.2.2.1.m1.1c">\text{MT}^{2}</annotation><annotation encoding="application/x-llamapun" id="id7.2.2.1.m1.1d">MT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math></span>; where we utilize pre-trained models to create diverse instructional datasets with interactive motion.
Our approach first trains a motion tokenizer that encodes interactive motions into residual discrete tokens.
In the pre-training stage, the model learns to align motion and text representations with these discrete tokens. During the instruction fine-tuning stage, <span class="ltx_text ltx_font_smallcaps" id="id9.4.4.5">VIM</span> adapts to multi-turn conversations using <span class="ltx_text ltx_markedasmath ltx_font_smallcaps" id="id9.4.4.6">Inter</span><span class="ltx_text ltx_font_smallcaps" id="id9.4.4.2">-<math alttext="\text{MT}^{2}" class="ltx_Math" display="inline" id="id9.4.4.2.m1.1"><semantics id="id9.4.4.2.m1.1a"><msup id="id9.4.4.2.m1.1.1" xref="id9.4.4.2.m1.1.1.cmml"><mtext class="ltx_font_smallcaps" id="id9.4.4.2.m1.1.1.2" xref="id9.4.4.2.m1.1.1.2a.cmml">MT</mtext><mn id="id9.4.4.2.m1.1.1.3" xref="id9.4.4.2.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="id9.4.4.2.m1.1b"><apply id="id9.4.4.2.m1.1.1.cmml" xref="id9.4.4.2.m1.1.1"><csymbol cd="ambiguous" id="id9.4.4.2.m1.1.1.1.cmml" xref="id9.4.4.2.m1.1.1">superscript</csymbol><ci id="id9.4.4.2.m1.1.1.2a.cmml" xref="id9.4.4.2.m1.1.1.2"><mtext class="ltx_font_smallcaps" id="id9.4.4.2.m1.1.1.2.cmml" xref="id9.4.4.2.m1.1.1.2">MT</mtext></ci><cn id="id9.4.4.2.m1.1.1.3.cmml" type="integer" xref="id9.4.4.2.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id9.4.4.2.m1.1c">\text{MT}^{2}</annotation><annotation encoding="application/x-llamapun" id="id9.4.4.2.m1.1d">MT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math></span>.
We evaluate the versatility of our method across motion-related tasks—motion-to-text, text-to-motion, reaction generation, motion editing, and reasoning about motion sequences. The results highlight <span class="ltx_text ltx_font_smallcaps" id="id9.4.4.7">VIM</span>’s versatility and effectiveness in handling complex interactive motion synthesis.</span></p>
</div>
<div class="ltx_para" id="p1">
<p class="ltx_p ltx_align_center" id="p1.1"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://vim-motion-language.github.io/" title="">https://vim-motion-language.github.io/</a></p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para ltx_noindent" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Agents that reflect how humans communicate and interact with each other through motion have the potential to revolutionize our interaction with technology.
By capturing the subtleties of human communication, including gestures, expressions, and interactive behaviors, these agents can offer more intuitive and natural interfaces. This holistic understanding enables technology to adjust its responses and behaviors based on the user’s physical motions and situational context, leading to more personalized and engaging interactions. Such capabilities are crucial for enhancing support across various domains, including robotics, virtual humans, entertainment, and more.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Recent advancements in large language models (LLMs) <cite class="ltx_cite ltx_citemacro_citep">(Dubey et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib9" title="">2024</a>; Team et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib35" title="">2024</a>; Yang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib42" title="">2024</a>)</cite> have demonstrated significant potential in generating human-like text and understanding complex linguistic interactions.
They have even extended their capability to multi-modal contexts, successfully integrating various input sources such as images, speech, and videos <cite class="ltx_cite ltx_citemacro_citep">(Ge et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib11" title="">2024</a>; Liu et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib25" title="">2024</a>; Chen et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib7" title="">2024b</a>; Tang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib34" title="">2024</a>; Shu et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib33" title="">2023</a>)</cite>.
Building upon these developments, there is a growing interest in incorporating human (or robot) motion as a new modality <cite class="ltx_cite ltx_citemacro_citep">(Jiang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib19" title="">2024</a>; Chen et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib6" title="">2024a</a>)</cite>, leading to the emergence of the “motion-language models” (MLM). However, existing approaches <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib44" title="">2023</a>; Guo et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib15" title="">2024a</a>; <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib14" title="">2022</a>; Zhang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib48" title="">2024d</a>; Cai et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib5" title="">2024</a>)</cite> often focus on single tasks, such as text-to-motion or motion-to-text translation, and consider only single motions without interactions. This limitation hinders the agents’ ability to handle scenarios involving multi-agents, complex interactions, and multi-turn conversations.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Beyond modeling the motion of a single person, interactive motion, where two individuals participate in interactions, allows the model to learn about social behavior. Modeling such interactions requires versatility to effectively control interactions, allowing users to provide instructions, assign roles, or modify behaviors.
In this paper, we aim to build a unified yet versatile motion-language model designed to generate, control, and comprehend sophisticated interactive motions.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">One of the primary challenges in developing these interactive agents is the lack of multi-turn interactive motion data. Datasets containing motions of two individuals interacting with each other, along with multi-turn conversational instructions, are scarce and challenging to collect. This makes it difficult for models to learn the nuances of interactive motions and multi-turn dynamics.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p5">
<p class="ltx_p" id="S1.p5.2">To address this, we present a new synthesized dataset called <span class="ltx_text ltx_markedasmath ltx_font_bold ltx_font_smallcaps" id="S1.p5.2.2">Inter</span><span class="ltx_text ltx_font_bold ltx_font_smallcaps" id="S1.p5.2.1">-<math alttext="\text{MT}^{2}" class="ltx_Math" display="inline" id="S1.p5.2.1.m1.1"><semantics id="S1.p5.2.1.m1.1a"><msup id="S1.p5.2.1.m1.1.1" xref="S1.p5.2.1.m1.1.1.cmml"><mtext class="ltx_font_smallcaps" id="S1.p5.2.1.m1.1.1.2" xref="S1.p5.2.1.m1.1.1.2a.cmml">MT</mtext><mn id="S1.p5.2.1.m1.1.1.3" xref="S1.p5.2.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S1.p5.2.1.m1.1b"><apply id="S1.p5.2.1.m1.1.1.cmml" xref="S1.p5.2.1.m1.1.1"><csymbol cd="ambiguous" id="S1.p5.2.1.m1.1.1.1.cmml" xref="S1.p5.2.1.m1.1.1">superscript</csymbol><ci id="S1.p5.2.1.m1.1.1.2a.cmml" xref="S1.p5.2.1.m1.1.1.2"><mtext class="ltx_font_smallcaps" id="S1.p5.2.1.m1.1.1.2.cmml" xref="S1.p5.2.1.m1.1.1.2">MT</mtext></ci><cn id="S1.p5.2.1.m1.1.1.3.cmml" type="integer" xref="S1.p5.2.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p5.2.1.m1.1c">\text{MT}^{2}</annotation><annotation encoding="application/x-llamapun" id="S1.p5.2.1.m1.1d">MT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math></span>, which includes various instructions about the interactive motions, in a multi-turn conversational format. We utilize a large language model to produce diverse instructions with motion captions and a diffusion-based text-to-motion model to generate corresponding motions.
We expect that leveraging such foundation models to construct training data allows the model to generalize more effectively with prior knowledge.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p6">
<p class="ltx_p" id="S1.p6.2">Building upon our synthesized dataset, we present <span class="ltx_text ltx_font_bold ltx_font_smallcaps" id="S1.p6.2.2">VIM</span>, a <span class="ltx_text ltx_font_smallcaps" id="S1.p6.2.3">V</span>ersatile <span class="ltx_text ltx_font_smallcaps" id="S1.p6.2.4">I</span>nteractive <span class="ltx_text ltx_font_smallcaps" id="S1.p6.2.5">M</span>otion-language model designed for multi-turn conversations involving interactive motions.
We pursue the versatility of <span class="ltx_text ltx_font_smallcaps" id="S1.p6.2.6">VIM</span> through a unified architecture that can simultaneously input and output both motion and text modalities. Based on the pre-trained LLMs, our training process can be divided into three stages: (1) training of the interaction motion tokenizer, (2) pre-training for motion and text representation alignment, and (3) instruction tuning with our synthesized dataset, <span class="ltx_text ltx_markedasmath ltx_font_smallcaps" id="S1.p6.2.7">Inter</span><span class="ltx_text ltx_font_smallcaps" id="S1.p6.2.1">-<math alttext="\text{MT}^{2}" class="ltx_Math" display="inline" id="S1.p6.2.1.m1.1"><semantics id="S1.p6.2.1.m1.1a"><msup id="S1.p6.2.1.m1.1.1" xref="S1.p6.2.1.m1.1.1.cmml"><mtext class="ltx_font_smallcaps" id="S1.p6.2.1.m1.1.1.2" xref="S1.p6.2.1.m1.1.1.2a.cmml">MT</mtext><mn id="S1.p6.2.1.m1.1.1.3" xref="S1.p6.2.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S1.p6.2.1.m1.1b"><apply id="S1.p6.2.1.m1.1.1.cmml" xref="S1.p6.2.1.m1.1.1"><csymbol cd="ambiguous" id="S1.p6.2.1.m1.1.1.1.cmml" xref="S1.p6.2.1.m1.1.1">superscript</csymbol><ci id="S1.p6.2.1.m1.1.1.2a.cmml" xref="S1.p6.2.1.m1.1.1.2"><mtext class="ltx_font_smallcaps" id="S1.p6.2.1.m1.1.1.2.cmml" xref="S1.p6.2.1.m1.1.1.2">MT</mtext></ci><cn id="S1.p6.2.1.m1.1.1.3.cmml" type="integer" xref="S1.p6.2.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p6.2.1.m1.1c">\text{MT}^{2}</annotation><annotation encoding="application/x-llamapun" id="S1.p6.2.1.m1.1d">MT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math></span>, to handle more complex and multi-turn instructions.
This enables <span class="ltx_text ltx_font_smallcaps" id="S1.p6.2.8">VIM</span> to effectively comprehend, generate, and control interactive motions, as illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_tag">1</span></a>. To assess <span class="ltx_text ltx_font_smallcaps" id="S1.p6.2.9">VIM</span>’s capabilities, we introduce new evaluation protocols that evaluate its performance across various motion-related tasks. This include editing motions and reasoning about motion sequences based on contextual cues, highlighting its versatility and effectiveness in complex motion interaction scenarios.</p>
</div>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="394" id="S1.F1.g1" src="x1.png" width="789"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>We introduce <span class="ltx_text ltx_font_smallcaps" id="S1.F1.2.1">VIM</span>, a versatile interactive motion language model. Left: reaction generation, motion reasoning, and generation. Right top: text-to-motion generation. Right bottom: Motion editing and motion understanding. </figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S1.p7">
<p class="ltx_p" id="S1.p7.2">In summary, the main contributions of this paper are threefold:
(1) We propose <span class="ltx_text ltx_font_smallcaps" id="S1.p7.2.2">VIM</span> that can simultaneously process and generate both motion and text modalities, along with a three-stage training pipeline consisting of motion tokenizer training, pre-training for modality alignment, and instruction tuning.
(2) We present <span class="ltx_text ltx_markedasmath ltx_font_smallcaps" id="S1.p7.2.3">Inter</span><span class="ltx_text ltx_font_smallcaps" id="S1.p7.2.1">-<math alttext="\text{MT}^{2}" class="ltx_Math" display="inline" id="S1.p7.2.1.m1.1"><semantics id="S1.p7.2.1.m1.1a"><msup id="S1.p7.2.1.m1.1.1" xref="S1.p7.2.1.m1.1.1.cmml"><mtext class="ltx_font_smallcaps" id="S1.p7.2.1.m1.1.1.2" xref="S1.p7.2.1.m1.1.1.2a.cmml">MT</mtext><mn id="S1.p7.2.1.m1.1.1.3" xref="S1.p7.2.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S1.p7.2.1.m1.1b"><apply id="S1.p7.2.1.m1.1.1.cmml" xref="S1.p7.2.1.m1.1.1"><csymbol cd="ambiguous" id="S1.p7.2.1.m1.1.1.1.cmml" xref="S1.p7.2.1.m1.1.1">superscript</csymbol><ci id="S1.p7.2.1.m1.1.1.2a.cmml" xref="S1.p7.2.1.m1.1.1.2"><mtext class="ltx_font_smallcaps" id="S1.p7.2.1.m1.1.1.2.cmml" xref="S1.p7.2.1.m1.1.1.2">MT</mtext></ci><cn id="S1.p7.2.1.m1.1.1.3.cmml" type="integer" xref="S1.p7.2.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p7.2.1.m1.1c">\text{MT}^{2}</annotation><annotation encoding="application/x-llamapun" id="S1.p7.2.1.m1.1d">MT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math></span>, a multi-turn interactive motion-text dataset, to address the lack of multi-turn interactive motion data.
(3) We introduced a new evaluation protocol to evaluate the performance of motion-language models on complex motion interaction scenarios.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Human Motion Modeling &amp; Control</h5>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px1.p1.1">Advancements in human motion modeling have driven significant progress in both motion generation and control. Diffusion-based methods, such as MDM <cite class="ltx_cite ltx_citemacro_citep">(Tevet et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib36" title="">2023</a>)</cite>, FG-T2M <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib38" title="">2023</a>)</cite>, and MotionDiffuse <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib45" title="">2024a</a>)</cite> excel at synthesizing realistic human motions from the text. Transformer-based models with vector quantization, such as TM2T <cite class="ltx_cite ltx_citemacro_citep">(Guo et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib14" title="">2022</a>)</cite> and T2M-GPT <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib44" title="">2023</a>)</cite>, effectively capture complex motion patterns.
MoMASK <cite class="ltx_cite ltx_citemacro_citep">(Guo et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib15" title="">2024a</a>)</cite> improves motion granularity with residual tokenizers.
For motion editing, some approaches focus on style transfer <cite class="ltx_cite ltx_citemacro_citep">(Aberman et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib1" title="">2020</a>; Guo et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib16" title="">2024b</a>)</cite> or specific body part modifications <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib45" title="">2024a</a>; Kim et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib20" title="">2023</a>)</cite>. FineMoGEN <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib47" title="">2024c</a>)</cite> offers fine-grained motion synthesis based on user instructions. MEOs (<cite class="ltx_cite ltx_citemacro_cite">Goel et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib13" title="">2024</a>)</cite>) use captions and large language models to identify frames and body parts to edit, while MotionFix (<cite class="ltx_cite ltx_citemacro_cite">Athanasiou et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib2" title="">2024</a>)</cite>) conditions diffusion models on both source motion and edit text for seamless motion edits.
However, these models usually target single tasks (<span class="ltx_text ltx_font_italic" id="S2.SS0.SSS0.Px1.p1.1.1">e.g.</span>, text-to-motion, or motion editing) and lack versatility in handling input and output of both motion and text simultaneously in a unified architecture.</p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">Motion Language Model</h5>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px2.p1.3">Recent developments in motion language models have aimed to achieve versatility across various motion-related tasks.
MotionGPT <cite class="ltx_cite ltx_citemacro_citep">(Jiang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib18" title="">2023</a>)</cite> demonstrates versatility in motion comprehension and generation based on a unified framework. MotionChain <cite class="ltx_cite ltx_citemacro_citep">(Jiang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib19" title="">2024</a>)</cite> introduces a multi-turn conversational system for interpreting and generating motions within dialogue contexts, including image inputs. <cite class="ltx_cite ltx_citemacro_cite">Zhou et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib49" title="">2024</a>)</cite> introduces AvatarGPT integrating motion generation and planning ability in motion large language model.
Some studies, like <cite class="ltx_cite ltx_citemacro_cite">Chen et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib6" title="">2024a</a>)</cite>, expand modalities into speech, music, and videos but focus primarily on comprehension rather than generation. <cite class="ltx_cite ltx_citemacro_cite">Zhang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib46" title="">2024b</a>)</cite> proposed unified models for generating motion from various input modalities. M<sup class="ltx_sup" id="S2.SS0.SSS0.Px2.p1.3.2">3</sup>-GPT, from <cite class="ltx_cite ltx_citemacro_cite">Luo et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib26" title="">2024</a>)</cite>, models speech, music, text, and motion interchangeably. However, modeling <span class="ltx_text ltx_font_italic" id="S2.SS0.SSS0.Px2.p1.3.3">interactive motions</span> in versatile large models remains under-explored. While some efforts, such as <cite class="ltx_cite ltx_citemacro_cite">Wu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib39" title="">2024</a>)</cite>, address this direction, they often lack multi-turn interactions and complex reasoning abilities.
Our work addresses this gap with a model trained on our synthesized <span class="ltx_text ltx_markedasmath ltx_font_smallcaps" id="S2.SS0.SSS0.Px2.p1.3.4">Inter</span><span class="ltx_text ltx_font_smallcaps" id="S2.SS0.SSS0.Px2.p1.3.1">-<math alttext="\text{MT}^{2}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px2.p1.3.1.m1.1"><semantics id="S2.SS0.SSS0.Px2.p1.3.1.m1.1a"><msup id="S2.SS0.SSS0.Px2.p1.3.1.m1.1.1" xref="S2.SS0.SSS0.Px2.p1.3.1.m1.1.1.cmml"><mtext class="ltx_font_smallcaps" id="S2.SS0.SSS0.Px2.p1.3.1.m1.1.1.2" xref="S2.SS0.SSS0.Px2.p1.3.1.m1.1.1.2a.cmml">MT</mtext><mn id="S2.SS0.SSS0.Px2.p1.3.1.m1.1.1.3" xref="S2.SS0.SSS0.Px2.p1.3.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p1.3.1.m1.1b"><apply id="S2.SS0.SSS0.Px2.p1.3.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.3.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px2.p1.3.1.m1.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.3.1.m1.1.1">superscript</csymbol><ci id="S2.SS0.SSS0.Px2.p1.3.1.m1.1.1.2a.cmml" xref="S2.SS0.SSS0.Px2.p1.3.1.m1.1.1.2"><mtext class="ltx_font_smallcaps" id="S2.SS0.SSS0.Px2.p1.3.1.m1.1.1.2.cmml" xref="S2.SS0.SSS0.Px2.p1.3.1.m1.1.1.2">MT</mtext></ci><cn id="S2.SS0.SSS0.Px2.p1.3.1.m1.1.1.3.cmml" type="integer" xref="S2.SS0.SSS0.Px2.p1.3.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p1.3.1.m1.1c">\text{MT}^{2}</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px2.p1.3.1.m1.1d">MT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math></span> dataset, enabling the understanding and generation of interactive motions in multi-turn conversations with advanced reasoning capabilities. This approach facilitates more nuanced, context-aware motion generation in complex interactive behaviors.</p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px3">
<h5 class="ltx_title ltx_title_paragraph">Human-Human Interactive Motion Modeling</h5>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px3.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px3.p1.2">Modeling human-human interactions has garnered increasing attention in recent research. Several multi-person interaction datasets <cite class="ltx_cite ltx_citemacro_citep">(Ng et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib27" title="">2020</a>; Fieraru et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib10" title="">2020</a>; Yin et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib43" title="">2023</a>)</cite> have been developed, and recent efforts like Inter-X <cite class="ltx_cite ltx_citemacro_citep">(Xu et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib40" title="">2024a</a>)</cite> and InterHuman <cite class="ltx_cite ltx_citemacro_citep">(Liang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib22" title="">2024</a>)</cite> have collected interactive motions paired with textual descriptions for text-based motion control.
In text-to-motion tasks, InterGEN <cite class="ltx_cite ltx_citemacro_citep">(Xu et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib40" title="">2024a</a>)</cite> introduces a diffusion-based model with spatial constraint loss. PriorMDM <cite class="ltx_cite ltx_citemacro_citep">(Shafir et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib32" title="">2024</a>)</cite> leverages pre-trained motion diffusion models with slim communication blocks.
For reaction generation, ReMoS <cite class="ltx_cite ltx_citemacro_cite">Ghosh et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib12" title="">2023</a>)</cite> synthesizes reactive motion using spatio-temporal cross-attention, while ReGenNet <cite class="ltx_cite ltx_citemacro_cite">Xu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib41" title="">2024b</a>)</cite> employs a transformer-based model with distance-based interaction loss to predict human reactions.
While existing models have advanced interactive motion modeling, they lack versatility and focus on specific tasks, failing to capture complex multi-turn dynamics. To address this, we introduce <span class="ltx_text ltx_markedasmath ltx_font_smallcaps" id="S2.SS0.SSS0.Px3.p1.2.2">Inter</span><span class="ltx_text ltx_font_smallcaps" id="S2.SS0.SSS0.Px3.p1.2.1">-<math alttext="\text{MT}^{2}" class="ltx_Math" display="inline" id="S2.SS0.SSS0.Px3.p1.2.1.m1.1"><semantics id="S2.SS0.SSS0.Px3.p1.2.1.m1.1a"><msup id="S2.SS0.SSS0.Px3.p1.2.1.m1.1.1" xref="S2.SS0.SSS0.Px3.p1.2.1.m1.1.1.cmml"><mtext class="ltx_font_smallcaps" id="S2.SS0.SSS0.Px3.p1.2.1.m1.1.1.2" xref="S2.SS0.SSS0.Px3.p1.2.1.m1.1.1.2a.cmml">MT</mtext><mn id="S2.SS0.SSS0.Px3.p1.2.1.m1.1.1.3" xref="S2.SS0.SSS0.Px3.p1.2.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px3.p1.2.1.m1.1b"><apply id="S2.SS0.SSS0.Px3.p1.2.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px3.p1.2.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px3.p1.2.1.m1.1.1.1.cmml" xref="S2.SS0.SSS0.Px3.p1.2.1.m1.1.1">superscript</csymbol><ci id="S2.SS0.SSS0.Px3.p1.2.1.m1.1.1.2a.cmml" xref="S2.SS0.SSS0.Px3.p1.2.1.m1.1.1.2"><mtext class="ltx_font_smallcaps" id="S2.SS0.SSS0.Px3.p1.2.1.m1.1.1.2.cmml" xref="S2.SS0.SSS0.Px3.p1.2.1.m1.1.1.2">MT</mtext></ci><cn id="S2.SS0.SSS0.Px3.p1.2.1.m1.1.1.3.cmml" type="integer" xref="S2.SS0.SSS0.Px3.p1.2.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px3.p1.2.1.m1.1c">\text{MT}^{2}</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px3.p1.2.1.m1.1d">MT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math></span>, enabling agents to generate sophisticated motions, respond to instructions, adapt roles, and adjust behaviors based on context.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span><math alttext="\text{Inter}\text{-MT}^{2}" class="ltx_Math" display="inline" id="S3.1.m1.1"><semantics id="S3.1.m1.1b"><msup id="S3.1.m1.1.1" xref="S3.1.m1.1.1.cmml"><mrow id="S3.1.m1.1.1.2" xref="S3.1.m1.1.1.2c.cmml"><mtext id="S3.1.m1.1.1.2b" xref="S3.1.m1.1.1.2c.cmml">Inter</mtext><mtext id="S3.1.m1.1.1.2c" xref="S3.1.m1.1.1.2c.cmml">-MT</mtext></mrow><mn id="S3.1.m1.1.1.3" xref="S3.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S3.1.m1.1c"><apply id="S3.1.m1.1.1.cmml" xref="S3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.1.m1.1.1.1.cmml" xref="S3.1.m1.1.1">superscript</csymbol><ci id="S3.1.m1.1.1.2c.cmml" xref="S3.1.m1.1.1.2"><mrow id="S3.1.m1.1.1.2.cmml" xref="S3.1.m1.1.1.2"><mtext id="S3.1.m1.1.1.2a.cmml" xref="S3.1.m1.1.1.2">Inter</mtext><mtext id="S3.1.m1.1.1.2b.cmml" xref="S3.1.m1.1.1.2">-MT</mtext></mrow></ci><cn id="S3.1.m1.1.1.3.cmml" type="integer" xref="S3.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.1.m1.1d">\text{Inter}\text{-MT}^{2}</annotation><annotation encoding="application/x-llamapun" id="S3.1.m1.1e">roman_Inter -MT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math>: Interactive multi-turn motion-text dataset </h2>
<div class="ltx_para ltx_noindent" id="S3.p1">
<p class="ltx_p" id="S3.p1.2">Current datasets <cite class="ltx_cite ltx_citemacro_citep">(Yin et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib43" title="">2023</a>; Liang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib22" title="">2024</a>; Xu et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib40" title="">2024a</a>)</cite> for modeling interactive motions lack sufficient diversity in instructions and do not include multi-turn conversations. To address this gap, we introduce <span class="ltx_text ltx_markedasmath ltx_font_bold ltx_font_smallcaps" id="S3.p1.2.2">Inter</span><span class="ltx_text ltx_font_bold ltx_font_smallcaps" id="S3.p1.2.1">-<math alttext="\text{MT}^{2}" class="ltx_Math" display="inline" id="S3.p1.2.1.m1.1"><semantics id="S3.p1.2.1.m1.1a"><msup id="S3.p1.2.1.m1.1.1" xref="S3.p1.2.1.m1.1.1.cmml"><mtext class="ltx_font_smallcaps" id="S3.p1.2.1.m1.1.1.2" xref="S3.p1.2.1.m1.1.1.2a.cmml">MT</mtext><mn id="S3.p1.2.1.m1.1.1.3" xref="S3.p1.2.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S3.p1.2.1.m1.1b"><apply id="S3.p1.2.1.m1.1.1.cmml" xref="S3.p1.2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.p1.2.1.m1.1.1.1.cmml" xref="S3.p1.2.1.m1.1.1">superscript</csymbol><ci id="S3.p1.2.1.m1.1.1.2a.cmml" xref="S3.p1.2.1.m1.1.1.2"><mtext class="ltx_font_smallcaps" id="S3.p1.2.1.m1.1.1.2.cmml" xref="S3.p1.2.1.m1.1.1.2">MT</mtext></ci><cn id="S3.p1.2.1.m1.1.1.3.cmml" type="integer" xref="S3.p1.2.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.2.1.m1.1c">\text{MT}^{2}</annotation><annotation encoding="application/x-llamapun" id="S3.p1.2.1.m1.1d">MT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math></span>: <span class="ltx_text ltx_font_bold ltx_font_smallcaps" id="S3.p1.2.3">inter</span>active <span class="ltx_text ltx_font_bold ltx_font_smallcaps" id="S3.p1.2.4">muti</span>-<span class="ltx_text ltx_font_bold ltx_font_smallcaps" id="S3.p1.2.5">t</span>urn <span class="ltx_text ltx_font_bold ltx_font_smallcaps" id="S3.p1.2.6">m</span>otion-<span class="ltx_text ltx_font_bold ltx_font_smallcaps" id="S3.p1.2.7">t</span>ext dataset. This dataset covers a variety of interactive motion scenarios with multi-turn conversations, diverse instructions, and spatiotemporally aligned motions between two individuals.</p>
</div>
<figure class="ltx_figure" id="S3.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="293" id="S3.F2.g1" src="x2.png" width="822"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Overview of synthetic data generation for multi-turn conversations with interactive motions. (a) Motion captions and instructions are generated using GPT-4 based on interactions between two characters, followed by (b) the corresponding motion being synthesized using the InterGEN.
</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S3.p2">
<p class="ltx_p" id="S3.p2.1">Collecting diverse instructional data for interactive motions and multi-turn conversation samples poses significant challenges. The first challenge is obtaining instruction and conversational data that encompass complex reasoning and generation capabilities. Leveraging pre-trained foundation models to generate a broad range of instructions can enrich the dataset with diverse and intricate examples. The second challenge is acquiring motion data that aligns with these text instructions. Functional approaches using rule-based methods may struggle to maintain spatial and temporal constraints in complex interactive scenarios, while retrieval-based methods are limited by dependence on existing cases and lack diversity. Alternatively, generative approaches using pre-trained models show promise in producing diverse, complex text-to-motion sequences, offering more flexibility for modeling interactive motions.
</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.p3">
<p class="ltx_p" id="S3.p3.1">We utilize the Inter-X <cite class="ltx_cite ltx_citemacro_citep">(Xu et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib40" title="">2024a</a>)</cite> and InterHuman <cite class="ltx_cite ltx_citemacro_citep">(Liang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib22" title="">2024</a>)</cite> datasets as the foundation for building our datasets. We further employ GPT-4o <cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib28" title="">2024</a>)</cite> to generate motion captions and conversational instructions for a variety of tasks, such as motion editing, reasoning, and story generation, enhancing the model’s versatility. Motion captions are sourced from these base datasets or generated by large language models (LLMs). We utilize the state-of-the-art text-to-motion diffusion model, InterGEN <cite class="ltx_cite ltx_citemacro_citep">(Liang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib22" title="">2024</a>)</cite>, to generate corresponding motions that align with the generated caption from LLMs. Our data collection pipeline, shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#S3.F2" title='Figure 2 ‣ 3 "Inter-MT"²: Interactive multi-turn motion-text dataset ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents'><span class="ltx_text ltx_ref_tag">2</span></a>, comprises 82K samples of multi-turn conversational data involving interactive motions, including 96K of synthesized interactive motions and 56K motions from the source dataset.</p>
</div>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>VIM: Versatile Interactive Motion-Language Model</h2>
<div class="ltx_para ltx_noindent" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">In this section, we introduce <span class="ltx_text ltx_font_smallcaps" id="S4.p1.1.1">VIM</span>, a versatile interactive motion language model, designed to incorporate multi-turn conversations considering both language and interactive motion as input or output modality. First, we will explain the underlying philosophy behind our design choices for the model architectures, followed by a detailed description of the training methodologies. Then, we introduce advanced interactive motion tasks in multi-turn conversations.</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Notations</h3>
<div class="ltx_para ltx_noindent" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.10">Formally, we denote interactive motion from two individual <math alttext="a" class="ltx_Math" display="inline" id="S4.SS1.p1.1.m1.1"><semantics id="S4.SS1.p1.1.m1.1a"><mi id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml">a</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><ci id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1">𝑎</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">a</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.1.m1.1d">italic_a</annotation></semantics></math> and <math alttext="b" class="ltx_Math" display="inline" id="S4.SS1.p1.2.m2.1"><semantics id="S4.SS1.p1.2.m2.1a"><mi id="S4.SS1.p1.2.m2.1.1" xref="S4.SS1.p1.2.m2.1.1.cmml">b</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.2.m2.1b"><ci id="S4.SS1.p1.2.m2.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1">𝑏</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.2.m2.1c">b</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.2.m2.1d">italic_b</annotation></semantics></math> as <math alttext="\{\mathbf{m}_{a},\mathbf{m}_{b}\}" class="ltx_Math" display="inline" id="S4.SS1.p1.3.m3.2"><semantics id="S4.SS1.p1.3.m3.2a"><mrow id="S4.SS1.p1.3.m3.2.2.2" xref="S4.SS1.p1.3.m3.2.2.3.cmml"><mo id="S4.SS1.p1.3.m3.2.2.2.3" stretchy="false" xref="S4.SS1.p1.3.m3.2.2.3.cmml">{</mo><msub id="S4.SS1.p1.3.m3.1.1.1.1" xref="S4.SS1.p1.3.m3.1.1.1.1.cmml"><mi id="S4.SS1.p1.3.m3.1.1.1.1.2" xref="S4.SS1.p1.3.m3.1.1.1.1.2.cmml">𝐦</mi><mi id="S4.SS1.p1.3.m3.1.1.1.1.3" xref="S4.SS1.p1.3.m3.1.1.1.1.3.cmml">a</mi></msub><mo id="S4.SS1.p1.3.m3.2.2.2.4" xref="S4.SS1.p1.3.m3.2.2.3.cmml">,</mo><msub id="S4.SS1.p1.3.m3.2.2.2.2" xref="S4.SS1.p1.3.m3.2.2.2.2.cmml"><mi id="S4.SS1.p1.3.m3.2.2.2.2.2" xref="S4.SS1.p1.3.m3.2.2.2.2.2.cmml">𝐦</mi><mi id="S4.SS1.p1.3.m3.2.2.2.2.3" xref="S4.SS1.p1.3.m3.2.2.2.2.3.cmml">b</mi></msub><mo id="S4.SS1.p1.3.m3.2.2.2.5" stretchy="false" xref="S4.SS1.p1.3.m3.2.2.3.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.3.m3.2b"><set id="S4.SS1.p1.3.m3.2.2.3.cmml" xref="S4.SS1.p1.3.m3.2.2.2"><apply id="S4.SS1.p1.3.m3.1.1.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.3.m3.1.1.1.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1.1.1">subscript</csymbol><ci id="S4.SS1.p1.3.m3.1.1.1.1.2.cmml" xref="S4.SS1.p1.3.m3.1.1.1.1.2">𝐦</ci><ci id="S4.SS1.p1.3.m3.1.1.1.1.3.cmml" xref="S4.SS1.p1.3.m3.1.1.1.1.3">𝑎</ci></apply><apply id="S4.SS1.p1.3.m3.2.2.2.2.cmml" xref="S4.SS1.p1.3.m3.2.2.2.2"><csymbol cd="ambiguous" id="S4.SS1.p1.3.m3.2.2.2.2.1.cmml" xref="S4.SS1.p1.3.m3.2.2.2.2">subscript</csymbol><ci id="S4.SS1.p1.3.m3.2.2.2.2.2.cmml" xref="S4.SS1.p1.3.m3.2.2.2.2.2">𝐦</ci><ci id="S4.SS1.p1.3.m3.2.2.2.2.3.cmml" xref="S4.SS1.p1.3.m3.2.2.2.2.3">𝑏</ci></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.3.m3.2c">\{\mathbf{m}_{a},\mathbf{m}_{b}\}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.3.m3.2d">{ bold_m start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT , bold_m start_POSTSUBSCRIPT italic_b end_POSTSUBSCRIPT }</annotation></semantics></math>, following non-canonical representation from <cite class="ltx_cite ltx_citemacro_cite">Liang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib22" title="">2024</a>)</cite> based on SMPL-X structure <cite class="ltx_cite ltx_citemacro_citep">(Pavlakos et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib29" title="">2019</a>)</cite>. Each timestep of the motion <math alttext="\mathbf{m}^{i}=[\mathbf{j}_{g}^{p},\mathbf{j}_{g}^{v},\mathbf{j}^{r},\mathbf{c%
}^{f}]" class="ltx_Math" display="inline" id="S4.SS1.p1.4.m4.4"><semantics id="S4.SS1.p1.4.m4.4a"><mrow id="S4.SS1.p1.4.m4.4.4" xref="S4.SS1.p1.4.m4.4.4.cmml"><msup id="S4.SS1.p1.4.m4.4.4.6" xref="S4.SS1.p1.4.m4.4.4.6.cmml"><mi id="S4.SS1.p1.4.m4.4.4.6.2" xref="S4.SS1.p1.4.m4.4.4.6.2.cmml">𝐦</mi><mi id="S4.SS1.p1.4.m4.4.4.6.3" xref="S4.SS1.p1.4.m4.4.4.6.3.cmml">i</mi></msup><mo id="S4.SS1.p1.4.m4.4.4.5" xref="S4.SS1.p1.4.m4.4.4.5.cmml">=</mo><mrow id="S4.SS1.p1.4.m4.4.4.4.4" xref="S4.SS1.p1.4.m4.4.4.4.5.cmml"><mo id="S4.SS1.p1.4.m4.4.4.4.4.5" stretchy="false" xref="S4.SS1.p1.4.m4.4.4.4.5.cmml">[</mo><msubsup id="S4.SS1.p1.4.m4.1.1.1.1.1" xref="S4.SS1.p1.4.m4.1.1.1.1.1.cmml"><mi id="S4.SS1.p1.4.m4.1.1.1.1.1.2.2" xref="S4.SS1.p1.4.m4.1.1.1.1.1.2.2.cmml">𝐣</mi><mi id="S4.SS1.p1.4.m4.1.1.1.1.1.2.3" xref="S4.SS1.p1.4.m4.1.1.1.1.1.2.3.cmml">g</mi><mi id="S4.SS1.p1.4.m4.1.1.1.1.1.3" xref="S4.SS1.p1.4.m4.1.1.1.1.1.3.cmml">p</mi></msubsup><mo id="S4.SS1.p1.4.m4.4.4.4.4.6" xref="S4.SS1.p1.4.m4.4.4.4.5.cmml">,</mo><msubsup id="S4.SS1.p1.4.m4.2.2.2.2.2" xref="S4.SS1.p1.4.m4.2.2.2.2.2.cmml"><mi id="S4.SS1.p1.4.m4.2.2.2.2.2.2.2" xref="S4.SS1.p1.4.m4.2.2.2.2.2.2.2.cmml">𝐣</mi><mi id="S4.SS1.p1.4.m4.2.2.2.2.2.2.3" xref="S4.SS1.p1.4.m4.2.2.2.2.2.2.3.cmml">g</mi><mi id="S4.SS1.p1.4.m4.2.2.2.2.2.3" xref="S4.SS1.p1.4.m4.2.2.2.2.2.3.cmml">v</mi></msubsup><mo id="S4.SS1.p1.4.m4.4.4.4.4.7" xref="S4.SS1.p1.4.m4.4.4.4.5.cmml">,</mo><msup id="S4.SS1.p1.4.m4.3.3.3.3.3" xref="S4.SS1.p1.4.m4.3.3.3.3.3.cmml"><mi id="S4.SS1.p1.4.m4.3.3.3.3.3.2" xref="S4.SS1.p1.4.m4.3.3.3.3.3.2.cmml">𝐣</mi><mi id="S4.SS1.p1.4.m4.3.3.3.3.3.3" xref="S4.SS1.p1.4.m4.3.3.3.3.3.3.cmml">r</mi></msup><mo id="S4.SS1.p1.4.m4.4.4.4.4.8" xref="S4.SS1.p1.4.m4.4.4.4.5.cmml">,</mo><msup id="S4.SS1.p1.4.m4.4.4.4.4.4" xref="S4.SS1.p1.4.m4.4.4.4.4.4.cmml"><mi id="S4.SS1.p1.4.m4.4.4.4.4.4.2" xref="S4.SS1.p1.4.m4.4.4.4.4.4.2.cmml">𝐜</mi><mi id="S4.SS1.p1.4.m4.4.4.4.4.4.3" xref="S4.SS1.p1.4.m4.4.4.4.4.4.3.cmml">f</mi></msup><mo id="S4.SS1.p1.4.m4.4.4.4.4.9" stretchy="false" xref="S4.SS1.p1.4.m4.4.4.4.5.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.4.m4.4b"><apply id="S4.SS1.p1.4.m4.4.4.cmml" xref="S4.SS1.p1.4.m4.4.4"><eq id="S4.SS1.p1.4.m4.4.4.5.cmml" xref="S4.SS1.p1.4.m4.4.4.5"></eq><apply id="S4.SS1.p1.4.m4.4.4.6.cmml" xref="S4.SS1.p1.4.m4.4.4.6"><csymbol cd="ambiguous" id="S4.SS1.p1.4.m4.4.4.6.1.cmml" xref="S4.SS1.p1.4.m4.4.4.6">superscript</csymbol><ci id="S4.SS1.p1.4.m4.4.4.6.2.cmml" xref="S4.SS1.p1.4.m4.4.4.6.2">𝐦</ci><ci id="S4.SS1.p1.4.m4.4.4.6.3.cmml" xref="S4.SS1.p1.4.m4.4.4.6.3">𝑖</ci></apply><list id="S4.SS1.p1.4.m4.4.4.4.5.cmml" xref="S4.SS1.p1.4.m4.4.4.4.4"><apply id="S4.SS1.p1.4.m4.1.1.1.1.1.cmml" xref="S4.SS1.p1.4.m4.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.4.m4.1.1.1.1.1.1.cmml" xref="S4.SS1.p1.4.m4.1.1.1.1.1">superscript</csymbol><apply id="S4.SS1.p1.4.m4.1.1.1.1.1.2.cmml" xref="S4.SS1.p1.4.m4.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.4.m4.1.1.1.1.1.2.1.cmml" xref="S4.SS1.p1.4.m4.1.1.1.1.1">subscript</csymbol><ci id="S4.SS1.p1.4.m4.1.1.1.1.1.2.2.cmml" xref="S4.SS1.p1.4.m4.1.1.1.1.1.2.2">𝐣</ci><ci id="S4.SS1.p1.4.m4.1.1.1.1.1.2.3.cmml" xref="S4.SS1.p1.4.m4.1.1.1.1.1.2.3">𝑔</ci></apply><ci id="S4.SS1.p1.4.m4.1.1.1.1.1.3.cmml" xref="S4.SS1.p1.4.m4.1.1.1.1.1.3">𝑝</ci></apply><apply id="S4.SS1.p1.4.m4.2.2.2.2.2.cmml" xref="S4.SS1.p1.4.m4.2.2.2.2.2"><csymbol cd="ambiguous" id="S4.SS1.p1.4.m4.2.2.2.2.2.1.cmml" xref="S4.SS1.p1.4.m4.2.2.2.2.2">superscript</csymbol><apply id="S4.SS1.p1.4.m4.2.2.2.2.2.2.cmml" xref="S4.SS1.p1.4.m4.2.2.2.2.2"><csymbol cd="ambiguous" id="S4.SS1.p1.4.m4.2.2.2.2.2.2.1.cmml" xref="S4.SS1.p1.4.m4.2.2.2.2.2">subscript</csymbol><ci id="S4.SS1.p1.4.m4.2.2.2.2.2.2.2.cmml" xref="S4.SS1.p1.4.m4.2.2.2.2.2.2.2">𝐣</ci><ci id="S4.SS1.p1.4.m4.2.2.2.2.2.2.3.cmml" xref="S4.SS1.p1.4.m4.2.2.2.2.2.2.3">𝑔</ci></apply><ci id="S4.SS1.p1.4.m4.2.2.2.2.2.3.cmml" xref="S4.SS1.p1.4.m4.2.2.2.2.2.3">𝑣</ci></apply><apply id="S4.SS1.p1.4.m4.3.3.3.3.3.cmml" xref="S4.SS1.p1.4.m4.3.3.3.3.3"><csymbol cd="ambiguous" id="S4.SS1.p1.4.m4.3.3.3.3.3.1.cmml" xref="S4.SS1.p1.4.m4.3.3.3.3.3">superscript</csymbol><ci id="S4.SS1.p1.4.m4.3.3.3.3.3.2.cmml" xref="S4.SS1.p1.4.m4.3.3.3.3.3.2">𝐣</ci><ci id="S4.SS1.p1.4.m4.3.3.3.3.3.3.cmml" xref="S4.SS1.p1.4.m4.3.3.3.3.3.3">𝑟</ci></apply><apply id="S4.SS1.p1.4.m4.4.4.4.4.4.cmml" xref="S4.SS1.p1.4.m4.4.4.4.4.4"><csymbol cd="ambiguous" id="S4.SS1.p1.4.m4.4.4.4.4.4.1.cmml" xref="S4.SS1.p1.4.m4.4.4.4.4.4">superscript</csymbol><ci id="S4.SS1.p1.4.m4.4.4.4.4.4.2.cmml" xref="S4.SS1.p1.4.m4.4.4.4.4.4.2">𝐜</ci><ci id="S4.SS1.p1.4.m4.4.4.4.4.4.3.cmml" xref="S4.SS1.p1.4.m4.4.4.4.4.4.3">𝑓</ci></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.4.m4.4c">\mathbf{m}^{i}=[\mathbf{j}_{g}^{p},\mathbf{j}_{g}^{v},\mathbf{j}^{r},\mathbf{c%
}^{f}]</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.4.m4.4d">bold_m start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT = [ bold_j start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT , bold_j start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_v end_POSTSUPERSCRIPT , bold_j start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT , bold_c start_POSTSUPERSCRIPT italic_f end_POSTSUPERSCRIPT ]</annotation></semantics></math> is composed of global joint positions <math alttext="\mathbf{j}_{g}^{p}\in\mathbb{R}^{3N_{j}}" class="ltx_Math" display="inline" id="S4.SS1.p1.5.m5.1"><semantics id="S4.SS1.p1.5.m5.1a"><mrow id="S4.SS1.p1.5.m5.1.1" xref="S4.SS1.p1.5.m5.1.1.cmml"><msubsup id="S4.SS1.p1.5.m5.1.1.2" xref="S4.SS1.p1.5.m5.1.1.2.cmml"><mi id="S4.SS1.p1.5.m5.1.1.2.2.2" xref="S4.SS1.p1.5.m5.1.1.2.2.2.cmml">𝐣</mi><mi id="S4.SS1.p1.5.m5.1.1.2.2.3" xref="S4.SS1.p1.5.m5.1.1.2.2.3.cmml">g</mi><mi id="S4.SS1.p1.5.m5.1.1.2.3" xref="S4.SS1.p1.5.m5.1.1.2.3.cmml">p</mi></msubsup><mo id="S4.SS1.p1.5.m5.1.1.1" xref="S4.SS1.p1.5.m5.1.1.1.cmml">∈</mo><msup id="S4.SS1.p1.5.m5.1.1.3" xref="S4.SS1.p1.5.m5.1.1.3.cmml"><mi id="S4.SS1.p1.5.m5.1.1.3.2" xref="S4.SS1.p1.5.m5.1.1.3.2.cmml">ℝ</mi><mrow id="S4.SS1.p1.5.m5.1.1.3.3" xref="S4.SS1.p1.5.m5.1.1.3.3.cmml"><mn id="S4.SS1.p1.5.m5.1.1.3.3.2" xref="S4.SS1.p1.5.m5.1.1.3.3.2.cmml">3</mn><mo id="S4.SS1.p1.5.m5.1.1.3.3.1" xref="S4.SS1.p1.5.m5.1.1.3.3.1.cmml">⁢</mo><msub id="S4.SS1.p1.5.m5.1.1.3.3.3" xref="S4.SS1.p1.5.m5.1.1.3.3.3.cmml"><mi id="S4.SS1.p1.5.m5.1.1.3.3.3.2" xref="S4.SS1.p1.5.m5.1.1.3.3.3.2.cmml">N</mi><mi id="S4.SS1.p1.5.m5.1.1.3.3.3.3" xref="S4.SS1.p1.5.m5.1.1.3.3.3.3.cmml">j</mi></msub></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.5.m5.1b"><apply id="S4.SS1.p1.5.m5.1.1.cmml" xref="S4.SS1.p1.5.m5.1.1"><in id="S4.SS1.p1.5.m5.1.1.1.cmml" xref="S4.SS1.p1.5.m5.1.1.1"></in><apply id="S4.SS1.p1.5.m5.1.1.2.cmml" xref="S4.SS1.p1.5.m5.1.1.2"><csymbol cd="ambiguous" id="S4.SS1.p1.5.m5.1.1.2.1.cmml" xref="S4.SS1.p1.5.m5.1.1.2">superscript</csymbol><apply id="S4.SS1.p1.5.m5.1.1.2.2.cmml" xref="S4.SS1.p1.5.m5.1.1.2"><csymbol cd="ambiguous" id="S4.SS1.p1.5.m5.1.1.2.2.1.cmml" xref="S4.SS1.p1.5.m5.1.1.2">subscript</csymbol><ci id="S4.SS1.p1.5.m5.1.1.2.2.2.cmml" xref="S4.SS1.p1.5.m5.1.1.2.2.2">𝐣</ci><ci id="S4.SS1.p1.5.m5.1.1.2.2.3.cmml" xref="S4.SS1.p1.5.m5.1.1.2.2.3">𝑔</ci></apply><ci id="S4.SS1.p1.5.m5.1.1.2.3.cmml" xref="S4.SS1.p1.5.m5.1.1.2.3">𝑝</ci></apply><apply id="S4.SS1.p1.5.m5.1.1.3.cmml" xref="S4.SS1.p1.5.m5.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.p1.5.m5.1.1.3.1.cmml" xref="S4.SS1.p1.5.m5.1.1.3">superscript</csymbol><ci id="S4.SS1.p1.5.m5.1.1.3.2.cmml" xref="S4.SS1.p1.5.m5.1.1.3.2">ℝ</ci><apply id="S4.SS1.p1.5.m5.1.1.3.3.cmml" xref="S4.SS1.p1.5.m5.1.1.3.3"><times id="S4.SS1.p1.5.m5.1.1.3.3.1.cmml" xref="S4.SS1.p1.5.m5.1.1.3.3.1"></times><cn id="S4.SS1.p1.5.m5.1.1.3.3.2.cmml" type="integer" xref="S4.SS1.p1.5.m5.1.1.3.3.2">3</cn><apply id="S4.SS1.p1.5.m5.1.1.3.3.3.cmml" xref="S4.SS1.p1.5.m5.1.1.3.3.3"><csymbol cd="ambiguous" id="S4.SS1.p1.5.m5.1.1.3.3.3.1.cmml" xref="S4.SS1.p1.5.m5.1.1.3.3.3">subscript</csymbol><ci id="S4.SS1.p1.5.m5.1.1.3.3.3.2.cmml" xref="S4.SS1.p1.5.m5.1.1.3.3.3.2">𝑁</ci><ci id="S4.SS1.p1.5.m5.1.1.3.3.3.3.cmml" xref="S4.SS1.p1.5.m5.1.1.3.3.3.3">𝑗</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.5.m5.1c">\mathbf{j}_{g}^{p}\in\mathbb{R}^{3N_{j}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.5.m5.1d">bold_j start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT 3 italic_N start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT end_POSTSUPERSCRIPT</annotation></semantics></math>, global joint velocities <math alttext="\mathbf{j}_{g}^{v}\in\mathbb{R}^{3N_{j}}" class="ltx_Math" display="inline" id="S4.SS1.p1.6.m6.1"><semantics id="S4.SS1.p1.6.m6.1a"><mrow id="S4.SS1.p1.6.m6.1.1" xref="S4.SS1.p1.6.m6.1.1.cmml"><msubsup id="S4.SS1.p1.6.m6.1.1.2" xref="S4.SS1.p1.6.m6.1.1.2.cmml"><mi id="S4.SS1.p1.6.m6.1.1.2.2.2" xref="S4.SS1.p1.6.m6.1.1.2.2.2.cmml">𝐣</mi><mi id="S4.SS1.p1.6.m6.1.1.2.2.3" xref="S4.SS1.p1.6.m6.1.1.2.2.3.cmml">g</mi><mi id="S4.SS1.p1.6.m6.1.1.2.3" xref="S4.SS1.p1.6.m6.1.1.2.3.cmml">v</mi></msubsup><mo id="S4.SS1.p1.6.m6.1.1.1" xref="S4.SS1.p1.6.m6.1.1.1.cmml">∈</mo><msup id="S4.SS1.p1.6.m6.1.1.3" xref="S4.SS1.p1.6.m6.1.1.3.cmml"><mi id="S4.SS1.p1.6.m6.1.1.3.2" xref="S4.SS1.p1.6.m6.1.1.3.2.cmml">ℝ</mi><mrow id="S4.SS1.p1.6.m6.1.1.3.3" xref="S4.SS1.p1.6.m6.1.1.3.3.cmml"><mn id="S4.SS1.p1.6.m6.1.1.3.3.2" xref="S4.SS1.p1.6.m6.1.1.3.3.2.cmml">3</mn><mo id="S4.SS1.p1.6.m6.1.1.3.3.1" xref="S4.SS1.p1.6.m6.1.1.3.3.1.cmml">⁢</mo><msub id="S4.SS1.p1.6.m6.1.1.3.3.3" xref="S4.SS1.p1.6.m6.1.1.3.3.3.cmml"><mi id="S4.SS1.p1.6.m6.1.1.3.3.3.2" xref="S4.SS1.p1.6.m6.1.1.3.3.3.2.cmml">N</mi><mi id="S4.SS1.p1.6.m6.1.1.3.3.3.3" xref="S4.SS1.p1.6.m6.1.1.3.3.3.3.cmml">j</mi></msub></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.6.m6.1b"><apply id="S4.SS1.p1.6.m6.1.1.cmml" xref="S4.SS1.p1.6.m6.1.1"><in id="S4.SS1.p1.6.m6.1.1.1.cmml" xref="S4.SS1.p1.6.m6.1.1.1"></in><apply id="S4.SS1.p1.6.m6.1.1.2.cmml" xref="S4.SS1.p1.6.m6.1.1.2"><csymbol cd="ambiguous" id="S4.SS1.p1.6.m6.1.1.2.1.cmml" xref="S4.SS1.p1.6.m6.1.1.2">superscript</csymbol><apply id="S4.SS1.p1.6.m6.1.1.2.2.cmml" xref="S4.SS1.p1.6.m6.1.1.2"><csymbol cd="ambiguous" id="S4.SS1.p1.6.m6.1.1.2.2.1.cmml" xref="S4.SS1.p1.6.m6.1.1.2">subscript</csymbol><ci id="S4.SS1.p1.6.m6.1.1.2.2.2.cmml" xref="S4.SS1.p1.6.m6.1.1.2.2.2">𝐣</ci><ci id="S4.SS1.p1.6.m6.1.1.2.2.3.cmml" xref="S4.SS1.p1.6.m6.1.1.2.2.3">𝑔</ci></apply><ci id="S4.SS1.p1.6.m6.1.1.2.3.cmml" xref="S4.SS1.p1.6.m6.1.1.2.3">𝑣</ci></apply><apply id="S4.SS1.p1.6.m6.1.1.3.cmml" xref="S4.SS1.p1.6.m6.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.p1.6.m6.1.1.3.1.cmml" xref="S4.SS1.p1.6.m6.1.1.3">superscript</csymbol><ci id="S4.SS1.p1.6.m6.1.1.3.2.cmml" xref="S4.SS1.p1.6.m6.1.1.3.2">ℝ</ci><apply id="S4.SS1.p1.6.m6.1.1.3.3.cmml" xref="S4.SS1.p1.6.m6.1.1.3.3"><times id="S4.SS1.p1.6.m6.1.1.3.3.1.cmml" xref="S4.SS1.p1.6.m6.1.1.3.3.1"></times><cn id="S4.SS1.p1.6.m6.1.1.3.3.2.cmml" type="integer" xref="S4.SS1.p1.6.m6.1.1.3.3.2">3</cn><apply id="S4.SS1.p1.6.m6.1.1.3.3.3.cmml" xref="S4.SS1.p1.6.m6.1.1.3.3.3"><csymbol cd="ambiguous" id="S4.SS1.p1.6.m6.1.1.3.3.3.1.cmml" xref="S4.SS1.p1.6.m6.1.1.3.3.3">subscript</csymbol><ci id="S4.SS1.p1.6.m6.1.1.3.3.3.2.cmml" xref="S4.SS1.p1.6.m6.1.1.3.3.3.2">𝑁</ci><ci id="S4.SS1.p1.6.m6.1.1.3.3.3.3.cmml" xref="S4.SS1.p1.6.m6.1.1.3.3.3.3">𝑗</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.6.m6.1c">\mathbf{j}_{g}^{v}\in\mathbb{R}^{3N_{j}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.6.m6.1d">bold_j start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_v end_POSTSUPERSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT 3 italic_N start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT end_POSTSUPERSCRIPT</annotation></semantics></math>, 6D representation of local rotations <math alttext="\mathbf{j}^{r}\in\mathbb{R}^{6N_{j}}" class="ltx_Math" display="inline" id="S4.SS1.p1.7.m7.1"><semantics id="S4.SS1.p1.7.m7.1a"><mrow id="S4.SS1.p1.7.m7.1.1" xref="S4.SS1.p1.7.m7.1.1.cmml"><msup id="S4.SS1.p1.7.m7.1.1.2" xref="S4.SS1.p1.7.m7.1.1.2.cmml"><mi id="S4.SS1.p1.7.m7.1.1.2.2" xref="S4.SS1.p1.7.m7.1.1.2.2.cmml">𝐣</mi><mi id="S4.SS1.p1.7.m7.1.1.2.3" xref="S4.SS1.p1.7.m7.1.1.2.3.cmml">r</mi></msup><mo id="S4.SS1.p1.7.m7.1.1.1" xref="S4.SS1.p1.7.m7.1.1.1.cmml">∈</mo><msup id="S4.SS1.p1.7.m7.1.1.3" xref="S4.SS1.p1.7.m7.1.1.3.cmml"><mi id="S4.SS1.p1.7.m7.1.1.3.2" xref="S4.SS1.p1.7.m7.1.1.3.2.cmml">ℝ</mi><mrow id="S4.SS1.p1.7.m7.1.1.3.3" xref="S4.SS1.p1.7.m7.1.1.3.3.cmml"><mn id="S4.SS1.p1.7.m7.1.1.3.3.2" xref="S4.SS1.p1.7.m7.1.1.3.3.2.cmml">6</mn><mo id="S4.SS1.p1.7.m7.1.1.3.3.1" xref="S4.SS1.p1.7.m7.1.1.3.3.1.cmml">⁢</mo><msub id="S4.SS1.p1.7.m7.1.1.3.3.3" xref="S4.SS1.p1.7.m7.1.1.3.3.3.cmml"><mi id="S4.SS1.p1.7.m7.1.1.3.3.3.2" xref="S4.SS1.p1.7.m7.1.1.3.3.3.2.cmml">N</mi><mi id="S4.SS1.p1.7.m7.1.1.3.3.3.3" xref="S4.SS1.p1.7.m7.1.1.3.3.3.3.cmml">j</mi></msub></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.7.m7.1b"><apply id="S4.SS1.p1.7.m7.1.1.cmml" xref="S4.SS1.p1.7.m7.1.1"><in id="S4.SS1.p1.7.m7.1.1.1.cmml" xref="S4.SS1.p1.7.m7.1.1.1"></in><apply id="S4.SS1.p1.7.m7.1.1.2.cmml" xref="S4.SS1.p1.7.m7.1.1.2"><csymbol cd="ambiguous" id="S4.SS1.p1.7.m7.1.1.2.1.cmml" xref="S4.SS1.p1.7.m7.1.1.2">superscript</csymbol><ci id="S4.SS1.p1.7.m7.1.1.2.2.cmml" xref="S4.SS1.p1.7.m7.1.1.2.2">𝐣</ci><ci id="S4.SS1.p1.7.m7.1.1.2.3.cmml" xref="S4.SS1.p1.7.m7.1.1.2.3">𝑟</ci></apply><apply id="S4.SS1.p1.7.m7.1.1.3.cmml" xref="S4.SS1.p1.7.m7.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.p1.7.m7.1.1.3.1.cmml" xref="S4.SS1.p1.7.m7.1.1.3">superscript</csymbol><ci id="S4.SS1.p1.7.m7.1.1.3.2.cmml" xref="S4.SS1.p1.7.m7.1.1.3.2">ℝ</ci><apply id="S4.SS1.p1.7.m7.1.1.3.3.cmml" xref="S4.SS1.p1.7.m7.1.1.3.3"><times id="S4.SS1.p1.7.m7.1.1.3.3.1.cmml" xref="S4.SS1.p1.7.m7.1.1.3.3.1"></times><cn id="S4.SS1.p1.7.m7.1.1.3.3.2.cmml" type="integer" xref="S4.SS1.p1.7.m7.1.1.3.3.2">6</cn><apply id="S4.SS1.p1.7.m7.1.1.3.3.3.cmml" xref="S4.SS1.p1.7.m7.1.1.3.3.3"><csymbol cd="ambiguous" id="S4.SS1.p1.7.m7.1.1.3.3.3.1.cmml" xref="S4.SS1.p1.7.m7.1.1.3.3.3">subscript</csymbol><ci id="S4.SS1.p1.7.m7.1.1.3.3.3.2.cmml" xref="S4.SS1.p1.7.m7.1.1.3.3.3.2">𝑁</ci><ci id="S4.SS1.p1.7.m7.1.1.3.3.3.3.cmml" xref="S4.SS1.p1.7.m7.1.1.3.3.3.3">𝑗</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.7.m7.1c">\mathbf{j}^{r}\in\mathbb{R}^{6N_{j}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.7.m7.1d">bold_j start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT 6 italic_N start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT end_POSTSUPERSCRIPT</annotation></semantics></math>, with the number of joints <math alttext="N_{j}" class="ltx_Math" display="inline" id="S4.SS1.p1.8.m8.1"><semantics id="S4.SS1.p1.8.m8.1a"><msub id="S4.SS1.p1.8.m8.1.1" xref="S4.SS1.p1.8.m8.1.1.cmml"><mi id="S4.SS1.p1.8.m8.1.1.2" xref="S4.SS1.p1.8.m8.1.1.2.cmml">N</mi><mi id="S4.SS1.p1.8.m8.1.1.3" xref="S4.SS1.p1.8.m8.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.8.m8.1b"><apply id="S4.SS1.p1.8.m8.1.1.cmml" xref="S4.SS1.p1.8.m8.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.8.m8.1.1.1.cmml" xref="S4.SS1.p1.8.m8.1.1">subscript</csymbol><ci id="S4.SS1.p1.8.m8.1.1.2.cmml" xref="S4.SS1.p1.8.m8.1.1.2">𝑁</ci><ci id="S4.SS1.p1.8.m8.1.1.3.cmml" xref="S4.SS1.p1.8.m8.1.1.3">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.8.m8.1c">N_{j}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.8.m8.1d">italic_N start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math>, and binary ground contact features <math alttext="\mathbf{c}^{f}\in\mathbb{R}^{4}" class="ltx_Math" display="inline" id="S4.SS1.p1.9.m9.1"><semantics id="S4.SS1.p1.9.m9.1a"><mrow id="S4.SS1.p1.9.m9.1.1" xref="S4.SS1.p1.9.m9.1.1.cmml"><msup id="S4.SS1.p1.9.m9.1.1.2" xref="S4.SS1.p1.9.m9.1.1.2.cmml"><mi id="S4.SS1.p1.9.m9.1.1.2.2" xref="S4.SS1.p1.9.m9.1.1.2.2.cmml">𝐜</mi><mi id="S4.SS1.p1.9.m9.1.1.2.3" xref="S4.SS1.p1.9.m9.1.1.2.3.cmml">f</mi></msup><mo id="S4.SS1.p1.9.m9.1.1.1" xref="S4.SS1.p1.9.m9.1.1.1.cmml">∈</mo><msup id="S4.SS1.p1.9.m9.1.1.3" xref="S4.SS1.p1.9.m9.1.1.3.cmml"><mi id="S4.SS1.p1.9.m9.1.1.3.2" xref="S4.SS1.p1.9.m9.1.1.3.2.cmml">ℝ</mi><mn id="S4.SS1.p1.9.m9.1.1.3.3" xref="S4.SS1.p1.9.m9.1.1.3.3.cmml">4</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.9.m9.1b"><apply id="S4.SS1.p1.9.m9.1.1.cmml" xref="S4.SS1.p1.9.m9.1.1"><in id="S4.SS1.p1.9.m9.1.1.1.cmml" xref="S4.SS1.p1.9.m9.1.1.1"></in><apply id="S4.SS1.p1.9.m9.1.1.2.cmml" xref="S4.SS1.p1.9.m9.1.1.2"><csymbol cd="ambiguous" id="S4.SS1.p1.9.m9.1.1.2.1.cmml" xref="S4.SS1.p1.9.m9.1.1.2">superscript</csymbol><ci id="S4.SS1.p1.9.m9.1.1.2.2.cmml" xref="S4.SS1.p1.9.m9.1.1.2.2">𝐜</ci><ci id="S4.SS1.p1.9.m9.1.1.2.3.cmml" xref="S4.SS1.p1.9.m9.1.1.2.3">𝑓</ci></apply><apply id="S4.SS1.p1.9.m9.1.1.3.cmml" xref="S4.SS1.p1.9.m9.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.p1.9.m9.1.1.3.1.cmml" xref="S4.SS1.p1.9.m9.1.1.3">superscript</csymbol><ci id="S4.SS1.p1.9.m9.1.1.3.2.cmml" xref="S4.SS1.p1.9.m9.1.1.3.2">ℝ</ci><cn id="S4.SS1.p1.9.m9.1.1.3.3.cmml" type="integer" xref="S4.SS1.p1.9.m9.1.1.3.3">4</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.9.m9.1c">\mathbf{c}^{f}\in\mathbb{R}^{4}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.9.m9.1d">bold_c start_POSTSUPERSCRIPT italic_f end_POSTSUPERSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT</annotation></semantics></math>. We aim to train a motion language model <math alttext="p_{\theta}" class="ltx_Math" display="inline" id="S4.SS1.p1.10.m10.1"><semantics id="S4.SS1.p1.10.m10.1a"><msub id="S4.SS1.p1.10.m10.1.1" xref="S4.SS1.p1.10.m10.1.1.cmml"><mi id="S4.SS1.p1.10.m10.1.1.2" xref="S4.SS1.p1.10.m10.1.1.2.cmml">p</mi><mi id="S4.SS1.p1.10.m10.1.1.3" xref="S4.SS1.p1.10.m10.1.1.3.cmml">θ</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.10.m10.1b"><apply id="S4.SS1.p1.10.m10.1.1.cmml" xref="S4.SS1.p1.10.m10.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.10.m10.1.1.1.cmml" xref="S4.SS1.p1.10.m10.1.1">subscript</csymbol><ci id="S4.SS1.p1.10.m10.1.1.2.cmml" xref="S4.SS1.p1.10.m10.1.1.2">𝑝</ci><ci id="S4.SS1.p1.10.m10.1.1.3.cmml" xref="S4.SS1.p1.10.m10.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.10.m10.1c">p_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.10.m10.1d">italic_p start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math> which can model texts and motions for both inputs and outputs. We define input as an instruction or previous context and output as an answer,
with the template below</p>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="A1.EGx1">
<tbody id="S4.Ex1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle\text{User}:X^{1}_{u}\ \texttt{&lt;Instruction&gt;}\quad\text{Assistant%
}:X^{1}_{a}\ \texttt{&lt;Answer&gt;}" class="ltx_Math" display="inline" id="S4.Ex1.m1.2"><semantics id="S4.Ex1.m1.2a"><mrow id="S4.Ex1.m1.2.2" xref="S4.Ex1.m1.2.2.cmml"><mtext id="S4.Ex1.m1.2.2.3" xref="S4.Ex1.m1.2.2.3a.cmml">User</mtext><mo id="S4.Ex1.m1.2.2.4" lspace="0.278em" rspace="0.278em" xref="S4.Ex1.m1.2.2.4.cmml">:</mo><mrow id="S4.Ex1.m1.2.2.1.1" xref="S4.Ex1.m1.2.2.1.2.cmml"><mrow id="S4.Ex1.m1.2.2.1.1.1" xref="S4.Ex1.m1.2.2.1.1.1.cmml"><msubsup id="S4.Ex1.m1.2.2.1.1.1.2" xref="S4.Ex1.m1.2.2.1.1.1.2.cmml"><mi id="S4.Ex1.m1.2.2.1.1.1.2.2.2" xref="S4.Ex1.m1.2.2.1.1.1.2.2.2.cmml">X</mi><mi id="S4.Ex1.m1.2.2.1.1.1.2.3" xref="S4.Ex1.m1.2.2.1.1.1.2.3.cmml">u</mi><mn id="S4.Ex1.m1.2.2.1.1.1.2.2.3" xref="S4.Ex1.m1.2.2.1.1.1.2.2.3.cmml">1</mn></msubsup><mo id="S4.Ex1.m1.2.2.1.1.1.1" xref="S4.Ex1.m1.2.2.1.1.1.1.cmml">⁢</mo><mtext class="ltx_mathvariant_monospace" id="S4.Ex1.m1.2.2.1.1.1.3" xref="S4.Ex1.m1.2.2.1.1.1.3a.cmml">&lt;Instruction&gt;</mtext></mrow><mspace id="S4.Ex1.m1.2.2.1.1.2" width="1em" xref="S4.Ex1.m1.2.2.1.2.cmml"></mspace><mtext id="S4.Ex1.m1.1.1" xref="S4.Ex1.m1.1.1a.cmml">Assistant</mtext></mrow><mo id="S4.Ex1.m1.2.2.5" lspace="0.278em" rspace="0.278em" xref="S4.Ex1.m1.2.2.5.cmml">:</mo><mrow id="S4.Ex1.m1.2.2.6" xref="S4.Ex1.m1.2.2.6.cmml"><msubsup id="S4.Ex1.m1.2.2.6.2" xref="S4.Ex1.m1.2.2.6.2.cmml"><mi id="S4.Ex1.m1.2.2.6.2.2.2" xref="S4.Ex1.m1.2.2.6.2.2.2.cmml">X</mi><mi id="S4.Ex1.m1.2.2.6.2.3" xref="S4.Ex1.m1.2.2.6.2.3.cmml">a</mi><mn id="S4.Ex1.m1.2.2.6.2.2.3" xref="S4.Ex1.m1.2.2.6.2.2.3.cmml">1</mn></msubsup><mo id="S4.Ex1.m1.2.2.6.1" xref="S4.Ex1.m1.2.2.6.1.cmml">⁢</mo><mtext class="ltx_mathvariant_monospace" id="S4.Ex1.m1.2.2.6.3" xref="S4.Ex1.m1.2.2.6.3a.cmml">&lt;Answer&gt;</mtext></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.Ex1.m1.2b"><apply id="S4.Ex1.m1.2.2.cmml" xref="S4.Ex1.m1.2.2"><and id="S4.Ex1.m1.2.2a.cmml" xref="S4.Ex1.m1.2.2"></and><apply id="S4.Ex1.m1.2.2b.cmml" xref="S4.Ex1.m1.2.2"><ci id="S4.Ex1.m1.2.2.4.cmml" xref="S4.Ex1.m1.2.2.4">:</ci><ci id="S4.Ex1.m1.2.2.3a.cmml" xref="S4.Ex1.m1.2.2.3"><mtext id="S4.Ex1.m1.2.2.3.cmml" xref="S4.Ex1.m1.2.2.3">User</mtext></ci><list id="S4.Ex1.m1.2.2.1.2.cmml" xref="S4.Ex1.m1.2.2.1.1"><apply id="S4.Ex1.m1.2.2.1.1.1.cmml" xref="S4.Ex1.m1.2.2.1.1.1"><times id="S4.Ex1.m1.2.2.1.1.1.1.cmml" xref="S4.Ex1.m1.2.2.1.1.1.1"></times><apply id="S4.Ex1.m1.2.2.1.1.1.2.cmml" xref="S4.Ex1.m1.2.2.1.1.1.2"><csymbol cd="ambiguous" id="S4.Ex1.m1.2.2.1.1.1.2.1.cmml" xref="S4.Ex1.m1.2.2.1.1.1.2">subscript</csymbol><apply id="S4.Ex1.m1.2.2.1.1.1.2.2.cmml" xref="S4.Ex1.m1.2.2.1.1.1.2"><csymbol cd="ambiguous" id="S4.Ex1.m1.2.2.1.1.1.2.2.1.cmml" xref="S4.Ex1.m1.2.2.1.1.1.2">superscript</csymbol><ci id="S4.Ex1.m1.2.2.1.1.1.2.2.2.cmml" xref="S4.Ex1.m1.2.2.1.1.1.2.2.2">𝑋</ci><cn id="S4.Ex1.m1.2.2.1.1.1.2.2.3.cmml" type="integer" xref="S4.Ex1.m1.2.2.1.1.1.2.2.3">1</cn></apply><ci id="S4.Ex1.m1.2.2.1.1.1.2.3.cmml" xref="S4.Ex1.m1.2.2.1.1.1.2.3">𝑢</ci></apply><ci id="S4.Ex1.m1.2.2.1.1.1.3a.cmml" xref="S4.Ex1.m1.2.2.1.1.1.3"><mtext class="ltx_mathvariant_monospace" id="S4.Ex1.m1.2.2.1.1.1.3.cmml" xref="S4.Ex1.m1.2.2.1.1.1.3">&lt;Instruction&gt;</mtext></ci></apply><ci id="S4.Ex1.m1.1.1a.cmml" xref="S4.Ex1.m1.1.1"><mtext id="S4.Ex1.m1.1.1.cmml" xref="S4.Ex1.m1.1.1">Assistant</mtext></ci></list></apply><apply id="S4.Ex1.m1.2.2c.cmml" xref="S4.Ex1.m1.2.2"><ci id="S4.Ex1.m1.2.2.5.cmml" xref="S4.Ex1.m1.2.2.5">:</ci><share href="https://arxiv.org/html/2410.05628v2#S4.Ex1.m1.2.2.1.cmml" id="S4.Ex1.m1.2.2d.cmml" xref="S4.Ex1.m1.2.2"></share><apply id="S4.Ex1.m1.2.2.6.cmml" xref="S4.Ex1.m1.2.2.6"><times id="S4.Ex1.m1.2.2.6.1.cmml" xref="S4.Ex1.m1.2.2.6.1"></times><apply id="S4.Ex1.m1.2.2.6.2.cmml" xref="S4.Ex1.m1.2.2.6.2"><csymbol cd="ambiguous" id="S4.Ex1.m1.2.2.6.2.1.cmml" xref="S4.Ex1.m1.2.2.6.2">subscript</csymbol><apply id="S4.Ex1.m1.2.2.6.2.2.cmml" xref="S4.Ex1.m1.2.2.6.2"><csymbol cd="ambiguous" id="S4.Ex1.m1.2.2.6.2.2.1.cmml" xref="S4.Ex1.m1.2.2.6.2">superscript</csymbol><ci id="S4.Ex1.m1.2.2.6.2.2.2.cmml" xref="S4.Ex1.m1.2.2.6.2.2.2">𝑋</ci><cn id="S4.Ex1.m1.2.2.6.2.2.3.cmml" type="integer" xref="S4.Ex1.m1.2.2.6.2.2.3">1</cn></apply><ci id="S4.Ex1.m1.2.2.6.2.3.cmml" xref="S4.Ex1.m1.2.2.6.2.3">𝑎</ci></apply><ci id="S4.Ex1.m1.2.2.6.3a.cmml" xref="S4.Ex1.m1.2.2.6.3"><mtext class="ltx_mathvariant_monospace" id="S4.Ex1.m1.2.2.6.3.cmml" xref="S4.Ex1.m1.2.2.6.3">&lt;Answer&gt;</mtext></ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.Ex1.m1.2c">\displaystyle\text{User}:X^{1}_{u}\ \texttt{&lt;Instruction&gt;}\quad\text{Assistant%
}:X^{1}_{a}\ \texttt{&lt;Answer&gt;}</annotation><annotation encoding="application/x-llamapun" id="S4.Ex1.m1.2d">User : italic_X start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT &lt;Instruction&gt; Assistant : italic_X start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT &lt;Answer&gt;</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="S4.Ex2"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle\text{User}:X^{2}_{u}\ \texttt{&lt;Instruction&gt;}\quad\text{Assistant%
}:X^{2}_{a}\ \texttt{&lt;Answer&gt;}\quad\cdots" class="ltx_Math" display="inline" id="S4.Ex2.m1.4"><semantics id="S4.Ex2.m1.4a"><mrow id="S4.Ex2.m1.4.4" xref="S4.Ex2.m1.4.4.cmml"><mtext id="S4.Ex2.m1.4.4.4" xref="S4.Ex2.m1.4.4.4a.cmml">User</mtext><mo id="S4.Ex2.m1.4.4.5" lspace="0.278em" rspace="0.278em" xref="S4.Ex2.m1.4.4.5.cmml">:</mo><mrow id="S4.Ex2.m1.3.3.1.1" xref="S4.Ex2.m1.3.3.1.2.cmml"><mrow id="S4.Ex2.m1.3.3.1.1.1" xref="S4.Ex2.m1.3.3.1.1.1.cmml"><msubsup id="S4.Ex2.m1.3.3.1.1.1.2" xref="S4.Ex2.m1.3.3.1.1.1.2.cmml"><mi id="S4.Ex2.m1.3.3.1.1.1.2.2.2" xref="S4.Ex2.m1.3.3.1.1.1.2.2.2.cmml">X</mi><mi id="S4.Ex2.m1.3.3.1.1.1.2.3" xref="S4.Ex2.m1.3.3.1.1.1.2.3.cmml">u</mi><mn id="S4.Ex2.m1.3.3.1.1.1.2.2.3" xref="S4.Ex2.m1.3.3.1.1.1.2.2.3.cmml">2</mn></msubsup><mo id="S4.Ex2.m1.3.3.1.1.1.1" xref="S4.Ex2.m1.3.3.1.1.1.1.cmml">⁢</mo><mtext class="ltx_mathvariant_monospace" id="S4.Ex2.m1.3.3.1.1.1.3" xref="S4.Ex2.m1.3.3.1.1.1.3a.cmml">&lt;Instruction&gt;</mtext></mrow><mspace id="S4.Ex2.m1.3.3.1.1.2" width="1em" xref="S4.Ex2.m1.3.3.1.2.cmml"></mspace><mtext id="S4.Ex2.m1.1.1" xref="S4.Ex2.m1.1.1a.cmml">Assistant</mtext></mrow><mo id="S4.Ex2.m1.4.4.6" lspace="0.278em" rspace="0.278em" xref="S4.Ex2.m1.4.4.6.cmml">:</mo><mrow id="S4.Ex2.m1.4.4.2.1" xref="S4.Ex2.m1.4.4.2.2.cmml"><mrow id="S4.Ex2.m1.4.4.2.1.1" xref="S4.Ex2.m1.4.4.2.1.1.cmml"><msubsup id="S4.Ex2.m1.4.4.2.1.1.2" xref="S4.Ex2.m1.4.4.2.1.1.2.cmml"><mi id="S4.Ex2.m1.4.4.2.1.1.2.2.2" xref="S4.Ex2.m1.4.4.2.1.1.2.2.2.cmml">X</mi><mi id="S4.Ex2.m1.4.4.2.1.1.2.3" xref="S4.Ex2.m1.4.4.2.1.1.2.3.cmml">a</mi><mn id="S4.Ex2.m1.4.4.2.1.1.2.2.3" xref="S4.Ex2.m1.4.4.2.1.1.2.2.3.cmml">2</mn></msubsup><mo id="S4.Ex2.m1.4.4.2.1.1.1" xref="S4.Ex2.m1.4.4.2.1.1.1.cmml">⁢</mo><mtext class="ltx_mathvariant_monospace" id="S4.Ex2.m1.4.4.2.1.1.3" xref="S4.Ex2.m1.4.4.2.1.1.3a.cmml">&lt;Answer&gt;</mtext></mrow><mspace id="S4.Ex2.m1.4.4.2.1.2" width="1em" xref="S4.Ex2.m1.4.4.2.2.cmml"></mspace><mi id="S4.Ex2.m1.2.2" mathvariant="normal" xref="S4.Ex2.m1.2.2.cmml">⋯</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.Ex2.m1.4b"><apply id="S4.Ex2.m1.4.4.cmml" xref="S4.Ex2.m1.4.4"><and id="S4.Ex2.m1.4.4a.cmml" xref="S4.Ex2.m1.4.4"></and><apply id="S4.Ex2.m1.4.4b.cmml" xref="S4.Ex2.m1.4.4"><ci id="S4.Ex2.m1.4.4.5.cmml" xref="S4.Ex2.m1.4.4.5">:</ci><ci id="S4.Ex2.m1.4.4.4a.cmml" xref="S4.Ex2.m1.4.4.4"><mtext id="S4.Ex2.m1.4.4.4.cmml" xref="S4.Ex2.m1.4.4.4">User</mtext></ci><list id="S4.Ex2.m1.3.3.1.2.cmml" xref="S4.Ex2.m1.3.3.1.1"><apply id="S4.Ex2.m1.3.3.1.1.1.cmml" xref="S4.Ex2.m1.3.3.1.1.1"><times id="S4.Ex2.m1.3.3.1.1.1.1.cmml" xref="S4.Ex2.m1.3.3.1.1.1.1"></times><apply id="S4.Ex2.m1.3.3.1.1.1.2.cmml" xref="S4.Ex2.m1.3.3.1.1.1.2"><csymbol cd="ambiguous" id="S4.Ex2.m1.3.3.1.1.1.2.1.cmml" xref="S4.Ex2.m1.3.3.1.1.1.2">subscript</csymbol><apply id="S4.Ex2.m1.3.3.1.1.1.2.2.cmml" xref="S4.Ex2.m1.3.3.1.1.1.2"><csymbol cd="ambiguous" id="S4.Ex2.m1.3.3.1.1.1.2.2.1.cmml" xref="S4.Ex2.m1.3.3.1.1.1.2">superscript</csymbol><ci id="S4.Ex2.m1.3.3.1.1.1.2.2.2.cmml" xref="S4.Ex2.m1.3.3.1.1.1.2.2.2">𝑋</ci><cn id="S4.Ex2.m1.3.3.1.1.1.2.2.3.cmml" type="integer" xref="S4.Ex2.m1.3.3.1.1.1.2.2.3">2</cn></apply><ci id="S4.Ex2.m1.3.3.1.1.1.2.3.cmml" xref="S4.Ex2.m1.3.3.1.1.1.2.3">𝑢</ci></apply><ci id="S4.Ex2.m1.3.3.1.1.1.3a.cmml" xref="S4.Ex2.m1.3.3.1.1.1.3"><mtext class="ltx_mathvariant_monospace" id="S4.Ex2.m1.3.3.1.1.1.3.cmml" xref="S4.Ex2.m1.3.3.1.1.1.3">&lt;Instruction&gt;</mtext></ci></apply><ci id="S4.Ex2.m1.1.1a.cmml" xref="S4.Ex2.m1.1.1"><mtext id="S4.Ex2.m1.1.1.cmml" xref="S4.Ex2.m1.1.1">Assistant</mtext></ci></list></apply><apply id="S4.Ex2.m1.4.4c.cmml" xref="S4.Ex2.m1.4.4"><ci id="S4.Ex2.m1.4.4.6.cmml" xref="S4.Ex2.m1.4.4.6">:</ci><share href="https://arxiv.org/html/2410.05628v2#S4.Ex2.m1.3.3.1.cmml" id="S4.Ex2.m1.4.4d.cmml" xref="S4.Ex2.m1.4.4"></share><list id="S4.Ex2.m1.4.4.2.2.cmml" xref="S4.Ex2.m1.4.4.2.1"><apply id="S4.Ex2.m1.4.4.2.1.1.cmml" xref="S4.Ex2.m1.4.4.2.1.1"><times id="S4.Ex2.m1.4.4.2.1.1.1.cmml" xref="S4.Ex2.m1.4.4.2.1.1.1"></times><apply id="S4.Ex2.m1.4.4.2.1.1.2.cmml" xref="S4.Ex2.m1.4.4.2.1.1.2"><csymbol cd="ambiguous" id="S4.Ex2.m1.4.4.2.1.1.2.1.cmml" xref="S4.Ex2.m1.4.4.2.1.1.2">subscript</csymbol><apply id="S4.Ex2.m1.4.4.2.1.1.2.2.cmml" xref="S4.Ex2.m1.4.4.2.1.1.2"><csymbol cd="ambiguous" id="S4.Ex2.m1.4.4.2.1.1.2.2.1.cmml" xref="S4.Ex2.m1.4.4.2.1.1.2">superscript</csymbol><ci id="S4.Ex2.m1.4.4.2.1.1.2.2.2.cmml" xref="S4.Ex2.m1.4.4.2.1.1.2.2.2">𝑋</ci><cn id="S4.Ex2.m1.4.4.2.1.1.2.2.3.cmml" type="integer" xref="S4.Ex2.m1.4.4.2.1.1.2.2.3">2</cn></apply><ci id="S4.Ex2.m1.4.4.2.1.1.2.3.cmml" xref="S4.Ex2.m1.4.4.2.1.1.2.3">𝑎</ci></apply><ci id="S4.Ex2.m1.4.4.2.1.1.3a.cmml" xref="S4.Ex2.m1.4.4.2.1.1.3"><mtext class="ltx_mathvariant_monospace" id="S4.Ex2.m1.4.4.2.1.1.3.cmml" xref="S4.Ex2.m1.4.4.2.1.1.3">&lt;Answer&gt;</mtext></ci></apply><ci id="S4.Ex2.m1.2.2.cmml" xref="S4.Ex2.m1.2.2">⋯</ci></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.Ex2.m1.4c">\displaystyle\text{User}:X^{2}_{u}\ \texttt{&lt;Instruction&gt;}\quad\text{Assistant%
}:X^{2}_{a}\ \texttt{&lt;Answer&gt;}\quad\cdots</annotation><annotation encoding="application/x-llamapun" id="S4.Ex2.m1.4d">User : italic_X start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT &lt;Instruction&gt; Assistant : italic_X start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT &lt;Answer&gt; ⋯</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S4.SS1.p1.12">where <math alttext="X_{u}" class="ltx_Math" display="inline" id="S4.SS1.p1.11.m1.1"><semantics id="S4.SS1.p1.11.m1.1a"><msub id="S4.SS1.p1.11.m1.1.1" xref="S4.SS1.p1.11.m1.1.1.cmml"><mi id="S4.SS1.p1.11.m1.1.1.2" xref="S4.SS1.p1.11.m1.1.1.2.cmml">X</mi><mi id="S4.SS1.p1.11.m1.1.1.3" xref="S4.SS1.p1.11.m1.1.1.3.cmml">u</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.11.m1.1b"><apply id="S4.SS1.p1.11.m1.1.1.cmml" xref="S4.SS1.p1.11.m1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.11.m1.1.1.1.cmml" xref="S4.SS1.p1.11.m1.1.1">subscript</csymbol><ci id="S4.SS1.p1.11.m1.1.1.2.cmml" xref="S4.SS1.p1.11.m1.1.1.2">𝑋</ci><ci id="S4.SS1.p1.11.m1.1.1.3.cmml" xref="S4.SS1.p1.11.m1.1.1.3">𝑢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.11.m1.1c">X_{u}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.11.m1.1d">italic_X start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="X_{a}" class="ltx_Math" display="inline" id="S4.SS1.p1.12.m2.1"><semantics id="S4.SS1.p1.12.m2.1a"><msub id="S4.SS1.p1.12.m2.1.1" xref="S4.SS1.p1.12.m2.1.1.cmml"><mi id="S4.SS1.p1.12.m2.1.1.2" xref="S4.SS1.p1.12.m2.1.1.2.cmml">X</mi><mi id="S4.SS1.p1.12.m2.1.1.3" xref="S4.SS1.p1.12.m2.1.1.3.cmml">a</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.12.m2.1b"><apply id="S4.SS1.p1.12.m2.1.1.cmml" xref="S4.SS1.p1.12.m2.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.12.m2.1.1.1.cmml" xref="S4.SS1.p1.12.m2.1.1">subscript</csymbol><ci id="S4.SS1.p1.12.m2.1.1.2.cmml" xref="S4.SS1.p1.12.m2.1.1.2">𝑋</ci><ci id="S4.SS1.p1.12.m2.1.1.3.cmml" xref="S4.SS1.p1.12.m2.1.1.3">𝑎</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.12.m2.1c">X_{a}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.12.m2.1d">italic_X start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT</annotation></semantics></math> are composed of both a mixture of text modalities and motion modalities.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Architecture</h3>
<div class="ltx_para ltx_noindent" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.8">Our architecture for modeling and generating interactive motions consists of three primary components: encoders (tokenizers), a large language model block, and decoders. This design allows for the integration of both motion and text data within a unified framework.
For motion, we use a residual vector quantized variational auto-encoder (RQ-VAE <cite class="ltx_cite ltx_citemacro_citep">(Lee et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib21" title="">2022</a>; Guo et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib15" title="">2024a</a>)</cite>) as a tokenizer. Vector quantized variational auto-encoders <cite class="ltx_cite ltx_citemacro_citep">(Van Den Oord et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib37" title="">2017</a>)</cite> are effective, but their quantization causes information loss and reduces reconstruction quality, which is critical for accurately modeling interactive motions.
The motion encoder <math alttext="\mathcal{E}_{M}" class="ltx_Math" display="inline" id="S4.SS2.p1.1.m1.1"><semantics id="S4.SS2.p1.1.m1.1a"><msub id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS2.p1.1.m1.1.1.2" xref="S4.SS2.p1.1.m1.1.1.2.cmml">ℰ</mi><mi id="S4.SS2.p1.1.m1.1.1.3" xref="S4.SS2.p1.1.m1.1.1.3.cmml">M</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><apply id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.1.m1.1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1">subscript</csymbol><ci id="S4.SS2.p1.1.m1.1.1.2.cmml" xref="S4.SS2.p1.1.m1.1.1.2">ℰ</ci><ci id="S4.SS2.p1.1.m1.1.1.3.cmml" xref="S4.SS2.p1.1.m1.1.1.3">𝑀</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">\mathcal{E}_{M}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.1.m1.1d">caligraphic_E start_POSTSUBSCRIPT italic_M end_POSTSUBSCRIPT</annotation></semantics></math> applies 2D convolutions to motion features along the time axis, converting motion pairs <math alttext="{\mathbf{m}_{a},\mathbf{m}_{b}}" class="ltx_Math" display="inline" id="S4.SS2.p1.2.m2.2"><semantics id="S4.SS2.p1.2.m2.2a"><mrow id="S4.SS2.p1.2.m2.2.2.2" xref="S4.SS2.p1.2.m2.2.2.3.cmml"><msub id="S4.SS2.p1.2.m2.1.1.1.1" xref="S4.SS2.p1.2.m2.1.1.1.1.cmml"><mi id="S4.SS2.p1.2.m2.1.1.1.1.2" xref="S4.SS2.p1.2.m2.1.1.1.1.2.cmml">𝐦</mi><mi id="S4.SS2.p1.2.m2.1.1.1.1.3" xref="S4.SS2.p1.2.m2.1.1.1.1.3.cmml">a</mi></msub><mo id="S4.SS2.p1.2.m2.2.2.2.3" xref="S4.SS2.p1.2.m2.2.2.3.cmml">,</mo><msub id="S4.SS2.p1.2.m2.2.2.2.2" xref="S4.SS2.p1.2.m2.2.2.2.2.cmml"><mi id="S4.SS2.p1.2.m2.2.2.2.2.2" xref="S4.SS2.p1.2.m2.2.2.2.2.2.cmml">𝐦</mi><mi id="S4.SS2.p1.2.m2.2.2.2.2.3" xref="S4.SS2.p1.2.m2.2.2.2.2.3.cmml">b</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m2.2b"><list id="S4.SS2.p1.2.m2.2.2.3.cmml" xref="S4.SS2.p1.2.m2.2.2.2"><apply id="S4.SS2.p1.2.m2.1.1.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.2.m2.1.1.1.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1.1.1">subscript</csymbol><ci id="S4.SS2.p1.2.m2.1.1.1.1.2.cmml" xref="S4.SS2.p1.2.m2.1.1.1.1.2">𝐦</ci><ci id="S4.SS2.p1.2.m2.1.1.1.1.3.cmml" xref="S4.SS2.p1.2.m2.1.1.1.1.3">𝑎</ci></apply><apply id="S4.SS2.p1.2.m2.2.2.2.2.cmml" xref="S4.SS2.p1.2.m2.2.2.2.2"><csymbol cd="ambiguous" id="S4.SS2.p1.2.m2.2.2.2.2.1.cmml" xref="S4.SS2.p1.2.m2.2.2.2.2">subscript</csymbol><ci id="S4.SS2.p1.2.m2.2.2.2.2.2.cmml" xref="S4.SS2.p1.2.m2.2.2.2.2.2">𝐦</ci><ci id="S4.SS2.p1.2.m2.2.2.2.2.3.cmml" xref="S4.SS2.p1.2.m2.2.2.2.2.3">𝑏</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m2.2c">{\mathbf{m}_{a},\mathbf{m}_{b}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.2.m2.2d">bold_m start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT , bold_m start_POSTSUBSCRIPT italic_b end_POSTSUBSCRIPT</annotation></semantics></math> into latent vectors <math alttext="\{\mathbf{z}^{1:L}_{a},\mathbf{z}^{1:L}_{b}\}=\mathcal{E}_{M}(\{\mathbf{m}^{1:%
M}_{a},\mathbf{m}^{1:M}_{b}\})" class="ltx_Math" display="inline" id="S4.SS2.p1.3.m3.3"><semantics id="S4.SS2.p1.3.m3.3a"><mrow id="S4.SS2.p1.3.m3.3.3" xref="S4.SS2.p1.3.m3.3.3.cmml"><mrow id="S4.SS2.p1.3.m3.2.2.2.2" xref="S4.SS2.p1.3.m3.2.2.2.3.cmml"><mo id="S4.SS2.p1.3.m3.2.2.2.2.3" stretchy="false" xref="S4.SS2.p1.3.m3.2.2.2.3.cmml">{</mo><msubsup id="S4.SS2.p1.3.m3.1.1.1.1.1" xref="S4.SS2.p1.3.m3.1.1.1.1.1.cmml"><mi id="S4.SS2.p1.3.m3.1.1.1.1.1.2.2" xref="S4.SS2.p1.3.m3.1.1.1.1.1.2.2.cmml">𝐳</mi><mi id="S4.SS2.p1.3.m3.1.1.1.1.1.3" xref="S4.SS2.p1.3.m3.1.1.1.1.1.3.cmml">a</mi><mrow id="S4.SS2.p1.3.m3.1.1.1.1.1.2.3" xref="S4.SS2.p1.3.m3.1.1.1.1.1.2.3.cmml"><mn id="S4.SS2.p1.3.m3.1.1.1.1.1.2.3.2" xref="S4.SS2.p1.3.m3.1.1.1.1.1.2.3.2.cmml">1</mn><mo id="S4.SS2.p1.3.m3.1.1.1.1.1.2.3.1" lspace="0.278em" rspace="0.278em" xref="S4.SS2.p1.3.m3.1.1.1.1.1.2.3.1.cmml">:</mo><mi id="S4.SS2.p1.3.m3.1.1.1.1.1.2.3.3" xref="S4.SS2.p1.3.m3.1.1.1.1.1.2.3.3.cmml">L</mi></mrow></msubsup><mo id="S4.SS2.p1.3.m3.2.2.2.2.4" xref="S4.SS2.p1.3.m3.2.2.2.3.cmml">,</mo><msubsup id="S4.SS2.p1.3.m3.2.2.2.2.2" xref="S4.SS2.p1.3.m3.2.2.2.2.2.cmml"><mi id="S4.SS2.p1.3.m3.2.2.2.2.2.2.2" xref="S4.SS2.p1.3.m3.2.2.2.2.2.2.2.cmml">𝐳</mi><mi id="S4.SS2.p1.3.m3.2.2.2.2.2.3" xref="S4.SS2.p1.3.m3.2.2.2.2.2.3.cmml">b</mi><mrow id="S4.SS2.p1.3.m3.2.2.2.2.2.2.3" xref="S4.SS2.p1.3.m3.2.2.2.2.2.2.3.cmml"><mn id="S4.SS2.p1.3.m3.2.2.2.2.2.2.3.2" xref="S4.SS2.p1.3.m3.2.2.2.2.2.2.3.2.cmml">1</mn><mo id="S4.SS2.p1.3.m3.2.2.2.2.2.2.3.1" lspace="0.278em" rspace="0.278em" xref="S4.SS2.p1.3.m3.2.2.2.2.2.2.3.1.cmml">:</mo><mi id="S4.SS2.p1.3.m3.2.2.2.2.2.2.3.3" xref="S4.SS2.p1.3.m3.2.2.2.2.2.2.3.3.cmml">L</mi></mrow></msubsup><mo id="S4.SS2.p1.3.m3.2.2.2.2.5" stretchy="false" xref="S4.SS2.p1.3.m3.2.2.2.3.cmml">}</mo></mrow><mo id="S4.SS2.p1.3.m3.3.3.4" xref="S4.SS2.p1.3.m3.3.3.4.cmml">=</mo><mrow id="S4.SS2.p1.3.m3.3.3.3" xref="S4.SS2.p1.3.m3.3.3.3.cmml"><msub id="S4.SS2.p1.3.m3.3.3.3.3" xref="S4.SS2.p1.3.m3.3.3.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS2.p1.3.m3.3.3.3.3.2" xref="S4.SS2.p1.3.m3.3.3.3.3.2.cmml">ℰ</mi><mi id="S4.SS2.p1.3.m3.3.3.3.3.3" xref="S4.SS2.p1.3.m3.3.3.3.3.3.cmml">M</mi></msub><mo id="S4.SS2.p1.3.m3.3.3.3.2" xref="S4.SS2.p1.3.m3.3.3.3.2.cmml">⁢</mo><mrow id="S4.SS2.p1.3.m3.3.3.3.1.1" xref="S4.SS2.p1.3.m3.3.3.3.cmml"><mo id="S4.SS2.p1.3.m3.3.3.3.1.1.2" stretchy="false" xref="S4.SS2.p1.3.m3.3.3.3.cmml">(</mo><mrow id="S4.SS2.p1.3.m3.3.3.3.1.1.1.2" xref="S4.SS2.p1.3.m3.3.3.3.1.1.1.3.cmml"><mo id="S4.SS2.p1.3.m3.3.3.3.1.1.1.2.3" stretchy="false" xref="S4.SS2.p1.3.m3.3.3.3.1.1.1.3.cmml">{</mo><msubsup id="S4.SS2.p1.3.m3.3.3.3.1.1.1.1.1" xref="S4.SS2.p1.3.m3.3.3.3.1.1.1.1.1.cmml"><mi id="S4.SS2.p1.3.m3.3.3.3.1.1.1.1.1.2.2" xref="S4.SS2.p1.3.m3.3.3.3.1.1.1.1.1.2.2.cmml">𝐦</mi><mi id="S4.SS2.p1.3.m3.3.3.3.1.1.1.1.1.3" xref="S4.SS2.p1.3.m3.3.3.3.1.1.1.1.1.3.cmml">a</mi><mrow id="S4.SS2.p1.3.m3.3.3.3.1.1.1.1.1.2.3" xref="S4.SS2.p1.3.m3.3.3.3.1.1.1.1.1.2.3.cmml"><mn id="S4.SS2.p1.3.m3.3.3.3.1.1.1.1.1.2.3.2" xref="S4.SS2.p1.3.m3.3.3.3.1.1.1.1.1.2.3.2.cmml">1</mn><mo id="S4.SS2.p1.3.m3.3.3.3.1.1.1.1.1.2.3.1" lspace="0.278em" rspace="0.278em" xref="S4.SS2.p1.3.m3.3.3.3.1.1.1.1.1.2.3.1.cmml">:</mo><mi id="S4.SS2.p1.3.m3.3.3.3.1.1.1.1.1.2.3.3" xref="S4.SS2.p1.3.m3.3.3.3.1.1.1.1.1.2.3.3.cmml">M</mi></mrow></msubsup><mo id="S4.SS2.p1.3.m3.3.3.3.1.1.1.2.4" xref="S4.SS2.p1.3.m3.3.3.3.1.1.1.3.cmml">,</mo><msubsup id="S4.SS2.p1.3.m3.3.3.3.1.1.1.2.2" xref="S4.SS2.p1.3.m3.3.3.3.1.1.1.2.2.cmml"><mi id="S4.SS2.p1.3.m3.3.3.3.1.1.1.2.2.2.2" xref="S4.SS2.p1.3.m3.3.3.3.1.1.1.2.2.2.2.cmml">𝐦</mi><mi id="S4.SS2.p1.3.m3.3.3.3.1.1.1.2.2.3" xref="S4.SS2.p1.3.m3.3.3.3.1.1.1.2.2.3.cmml">b</mi><mrow id="S4.SS2.p1.3.m3.3.3.3.1.1.1.2.2.2.3" xref="S4.SS2.p1.3.m3.3.3.3.1.1.1.2.2.2.3.cmml"><mn id="S4.SS2.p1.3.m3.3.3.3.1.1.1.2.2.2.3.2" xref="S4.SS2.p1.3.m3.3.3.3.1.1.1.2.2.2.3.2.cmml">1</mn><mo id="S4.SS2.p1.3.m3.3.3.3.1.1.1.2.2.2.3.1" lspace="0.278em" rspace="0.278em" xref="S4.SS2.p1.3.m3.3.3.3.1.1.1.2.2.2.3.1.cmml">:</mo><mi id="S4.SS2.p1.3.m3.3.3.3.1.1.1.2.2.2.3.3" xref="S4.SS2.p1.3.m3.3.3.3.1.1.1.2.2.2.3.3.cmml">M</mi></mrow></msubsup><mo id="S4.SS2.p1.3.m3.3.3.3.1.1.1.2.5" stretchy="false" xref="S4.SS2.p1.3.m3.3.3.3.1.1.1.3.cmml">}</mo></mrow><mo id="S4.SS2.p1.3.m3.3.3.3.1.1.3" stretchy="false" xref="S4.SS2.p1.3.m3.3.3.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.3.m3.3b"><apply id="S4.SS2.p1.3.m3.3.3.cmml" xref="S4.SS2.p1.3.m3.3.3"><eq id="S4.SS2.p1.3.m3.3.3.4.cmml" xref="S4.SS2.p1.3.m3.3.3.4"></eq><set id="S4.SS2.p1.3.m3.2.2.2.3.cmml" xref="S4.SS2.p1.3.m3.2.2.2.2"><apply id="S4.SS2.p1.3.m3.1.1.1.1.1.cmml" xref="S4.SS2.p1.3.m3.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.3.m3.1.1.1.1.1.1.cmml" xref="S4.SS2.p1.3.m3.1.1.1.1.1">subscript</csymbol><apply id="S4.SS2.p1.3.m3.1.1.1.1.1.2.cmml" xref="S4.SS2.p1.3.m3.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.3.m3.1.1.1.1.1.2.1.cmml" xref="S4.SS2.p1.3.m3.1.1.1.1.1">superscript</csymbol><ci id="S4.SS2.p1.3.m3.1.1.1.1.1.2.2.cmml" xref="S4.SS2.p1.3.m3.1.1.1.1.1.2.2">𝐳</ci><apply id="S4.SS2.p1.3.m3.1.1.1.1.1.2.3.cmml" xref="S4.SS2.p1.3.m3.1.1.1.1.1.2.3"><ci id="S4.SS2.p1.3.m3.1.1.1.1.1.2.3.1.cmml" xref="S4.SS2.p1.3.m3.1.1.1.1.1.2.3.1">:</ci><cn id="S4.SS2.p1.3.m3.1.1.1.1.1.2.3.2.cmml" type="integer" xref="S4.SS2.p1.3.m3.1.1.1.1.1.2.3.2">1</cn><ci id="S4.SS2.p1.3.m3.1.1.1.1.1.2.3.3.cmml" xref="S4.SS2.p1.3.m3.1.1.1.1.1.2.3.3">𝐿</ci></apply></apply><ci id="S4.SS2.p1.3.m3.1.1.1.1.1.3.cmml" xref="S4.SS2.p1.3.m3.1.1.1.1.1.3">𝑎</ci></apply><apply id="S4.SS2.p1.3.m3.2.2.2.2.2.cmml" xref="S4.SS2.p1.3.m3.2.2.2.2.2"><csymbol cd="ambiguous" id="S4.SS2.p1.3.m3.2.2.2.2.2.1.cmml" xref="S4.SS2.p1.3.m3.2.2.2.2.2">subscript</csymbol><apply id="S4.SS2.p1.3.m3.2.2.2.2.2.2.cmml" xref="S4.SS2.p1.3.m3.2.2.2.2.2"><csymbol cd="ambiguous" id="S4.SS2.p1.3.m3.2.2.2.2.2.2.1.cmml" xref="S4.SS2.p1.3.m3.2.2.2.2.2">superscript</csymbol><ci id="S4.SS2.p1.3.m3.2.2.2.2.2.2.2.cmml" xref="S4.SS2.p1.3.m3.2.2.2.2.2.2.2">𝐳</ci><apply id="S4.SS2.p1.3.m3.2.2.2.2.2.2.3.cmml" xref="S4.SS2.p1.3.m3.2.2.2.2.2.2.3"><ci id="S4.SS2.p1.3.m3.2.2.2.2.2.2.3.1.cmml" xref="S4.SS2.p1.3.m3.2.2.2.2.2.2.3.1">:</ci><cn id="S4.SS2.p1.3.m3.2.2.2.2.2.2.3.2.cmml" type="integer" xref="S4.SS2.p1.3.m3.2.2.2.2.2.2.3.2">1</cn><ci id="S4.SS2.p1.3.m3.2.2.2.2.2.2.3.3.cmml" xref="S4.SS2.p1.3.m3.2.2.2.2.2.2.3.3">𝐿</ci></apply></apply><ci id="S4.SS2.p1.3.m3.2.2.2.2.2.3.cmml" xref="S4.SS2.p1.3.m3.2.2.2.2.2.3">𝑏</ci></apply></set><apply id="S4.SS2.p1.3.m3.3.3.3.cmml" xref="S4.SS2.p1.3.m3.3.3.3"><times id="S4.SS2.p1.3.m3.3.3.3.2.cmml" xref="S4.SS2.p1.3.m3.3.3.3.2"></times><apply id="S4.SS2.p1.3.m3.3.3.3.3.cmml" xref="S4.SS2.p1.3.m3.3.3.3.3"><csymbol cd="ambiguous" id="S4.SS2.p1.3.m3.3.3.3.3.1.cmml" xref="S4.SS2.p1.3.m3.3.3.3.3">subscript</csymbol><ci id="S4.SS2.p1.3.m3.3.3.3.3.2.cmml" xref="S4.SS2.p1.3.m3.3.3.3.3.2">ℰ</ci><ci id="S4.SS2.p1.3.m3.3.3.3.3.3.cmml" xref="S4.SS2.p1.3.m3.3.3.3.3.3">𝑀</ci></apply><set id="S4.SS2.p1.3.m3.3.3.3.1.1.1.3.cmml" xref="S4.SS2.p1.3.m3.3.3.3.1.1.1.2"><apply id="S4.SS2.p1.3.m3.3.3.3.1.1.1.1.1.cmml" xref="S4.SS2.p1.3.m3.3.3.3.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.3.m3.3.3.3.1.1.1.1.1.1.cmml" xref="S4.SS2.p1.3.m3.3.3.3.1.1.1.1.1">subscript</csymbol><apply id="S4.SS2.p1.3.m3.3.3.3.1.1.1.1.1.2.cmml" xref="S4.SS2.p1.3.m3.3.3.3.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.3.m3.3.3.3.1.1.1.1.1.2.1.cmml" xref="S4.SS2.p1.3.m3.3.3.3.1.1.1.1.1">superscript</csymbol><ci id="S4.SS2.p1.3.m3.3.3.3.1.1.1.1.1.2.2.cmml" xref="S4.SS2.p1.3.m3.3.3.3.1.1.1.1.1.2.2">𝐦</ci><apply id="S4.SS2.p1.3.m3.3.3.3.1.1.1.1.1.2.3.cmml" xref="S4.SS2.p1.3.m3.3.3.3.1.1.1.1.1.2.3"><ci id="S4.SS2.p1.3.m3.3.3.3.1.1.1.1.1.2.3.1.cmml" xref="S4.SS2.p1.3.m3.3.3.3.1.1.1.1.1.2.3.1">:</ci><cn id="S4.SS2.p1.3.m3.3.3.3.1.1.1.1.1.2.3.2.cmml" type="integer" xref="S4.SS2.p1.3.m3.3.3.3.1.1.1.1.1.2.3.2">1</cn><ci id="S4.SS2.p1.3.m3.3.3.3.1.1.1.1.1.2.3.3.cmml" xref="S4.SS2.p1.3.m3.3.3.3.1.1.1.1.1.2.3.3">𝑀</ci></apply></apply><ci id="S4.SS2.p1.3.m3.3.3.3.1.1.1.1.1.3.cmml" xref="S4.SS2.p1.3.m3.3.3.3.1.1.1.1.1.3">𝑎</ci></apply><apply id="S4.SS2.p1.3.m3.3.3.3.1.1.1.2.2.cmml" xref="S4.SS2.p1.3.m3.3.3.3.1.1.1.2.2"><csymbol cd="ambiguous" id="S4.SS2.p1.3.m3.3.3.3.1.1.1.2.2.1.cmml" xref="S4.SS2.p1.3.m3.3.3.3.1.1.1.2.2">subscript</csymbol><apply id="S4.SS2.p1.3.m3.3.3.3.1.1.1.2.2.2.cmml" xref="S4.SS2.p1.3.m3.3.3.3.1.1.1.2.2"><csymbol cd="ambiguous" id="S4.SS2.p1.3.m3.3.3.3.1.1.1.2.2.2.1.cmml" xref="S4.SS2.p1.3.m3.3.3.3.1.1.1.2.2">superscript</csymbol><ci id="S4.SS2.p1.3.m3.3.3.3.1.1.1.2.2.2.2.cmml" xref="S4.SS2.p1.3.m3.3.3.3.1.1.1.2.2.2.2">𝐦</ci><apply id="S4.SS2.p1.3.m3.3.3.3.1.1.1.2.2.2.3.cmml" xref="S4.SS2.p1.3.m3.3.3.3.1.1.1.2.2.2.3"><ci id="S4.SS2.p1.3.m3.3.3.3.1.1.1.2.2.2.3.1.cmml" xref="S4.SS2.p1.3.m3.3.3.3.1.1.1.2.2.2.3.1">:</ci><cn id="S4.SS2.p1.3.m3.3.3.3.1.1.1.2.2.2.3.2.cmml" type="integer" xref="S4.SS2.p1.3.m3.3.3.3.1.1.1.2.2.2.3.2">1</cn><ci id="S4.SS2.p1.3.m3.3.3.3.1.1.1.2.2.2.3.3.cmml" xref="S4.SS2.p1.3.m3.3.3.3.1.1.1.2.2.2.3.3">𝑀</ci></apply></apply><ci id="S4.SS2.p1.3.m3.3.3.3.1.1.1.2.2.3.cmml" xref="S4.SS2.p1.3.m3.3.3.3.1.1.1.2.2.3">𝑏</ci></apply></set></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.3.m3.3c">\{\mathbf{z}^{1:L}_{a},\mathbf{z}^{1:L}_{b}\}=\mathcal{E}_{M}(\{\mathbf{m}^{1:%
M}_{a},\mathbf{m}^{1:M}_{b}\})</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.3.m3.3d">{ bold_z start_POSTSUPERSCRIPT 1 : italic_L end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT , bold_z start_POSTSUPERSCRIPT 1 : italic_L end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_b end_POSTSUBSCRIPT } = caligraphic_E start_POSTSUBSCRIPT italic_M end_POSTSUBSCRIPT ( { bold_m start_POSTSUPERSCRIPT 1 : italic_M end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT , bold_m start_POSTSUPERSCRIPT 1 : italic_M end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_b end_POSTSUBSCRIPT } )</annotation></semantics></math>, where <math alttext="M" class="ltx_Math" display="inline" id="S4.SS2.p1.4.m4.1"><semantics id="S4.SS2.p1.4.m4.1a"><mi id="S4.SS2.p1.4.m4.1.1" xref="S4.SS2.p1.4.m4.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.4.m4.1b"><ci id="S4.SS2.p1.4.m4.1.1.cmml" xref="S4.SS2.p1.4.m4.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.4.m4.1c">M</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.4.m4.1d">italic_M</annotation></semantics></math> is a motion length and <math alttext="L=M/l" class="ltx_Math" display="inline" id="S4.SS2.p1.5.m5.1"><semantics id="S4.SS2.p1.5.m5.1a"><mrow id="S4.SS2.p1.5.m5.1.1" xref="S4.SS2.p1.5.m5.1.1.cmml"><mi id="S4.SS2.p1.5.m5.1.1.2" xref="S4.SS2.p1.5.m5.1.1.2.cmml">L</mi><mo id="S4.SS2.p1.5.m5.1.1.1" xref="S4.SS2.p1.5.m5.1.1.1.cmml">=</mo><mrow id="S4.SS2.p1.5.m5.1.1.3" xref="S4.SS2.p1.5.m5.1.1.3.cmml"><mi id="S4.SS2.p1.5.m5.1.1.3.2" xref="S4.SS2.p1.5.m5.1.1.3.2.cmml">M</mi><mo id="S4.SS2.p1.5.m5.1.1.3.1" xref="S4.SS2.p1.5.m5.1.1.3.1.cmml">/</mo><mi id="S4.SS2.p1.5.m5.1.1.3.3" xref="S4.SS2.p1.5.m5.1.1.3.3.cmml">l</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.5.m5.1b"><apply id="S4.SS2.p1.5.m5.1.1.cmml" xref="S4.SS2.p1.5.m5.1.1"><eq id="S4.SS2.p1.5.m5.1.1.1.cmml" xref="S4.SS2.p1.5.m5.1.1.1"></eq><ci id="S4.SS2.p1.5.m5.1.1.2.cmml" xref="S4.SS2.p1.5.m5.1.1.2">𝐿</ci><apply id="S4.SS2.p1.5.m5.1.1.3.cmml" xref="S4.SS2.p1.5.m5.1.1.3"><divide id="S4.SS2.p1.5.m5.1.1.3.1.cmml" xref="S4.SS2.p1.5.m5.1.1.3.1"></divide><ci id="S4.SS2.p1.5.m5.1.1.3.2.cmml" xref="S4.SS2.p1.5.m5.1.1.3.2">𝑀</ci><ci id="S4.SS2.p1.5.m5.1.1.3.3.cmml" xref="S4.SS2.p1.5.m5.1.1.3.3">𝑙</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.5.m5.1c">L=M/l</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.5.m5.1d">italic_L = italic_M / italic_l</annotation></semantics></math> with down-sample rate <math alttext="l" class="ltx_Math" display="inline" id="S4.SS2.p1.6.m6.1"><semantics id="S4.SS2.p1.6.m6.1a"><mi id="S4.SS2.p1.6.m6.1.1" xref="S4.SS2.p1.6.m6.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.6.m6.1b"><ci id="S4.SS2.p1.6.m6.1.1.cmml" xref="S4.SS2.p1.6.m6.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.6.m6.1c">l</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.6.m6.1d">italic_l</annotation></semantics></math>.
Then the latent vectors <math alttext="\mathbf{z}" class="ltx_Math" display="inline" id="S4.SS2.p1.7.m7.1"><semantics id="S4.SS2.p1.7.m7.1a"><mi id="S4.SS2.p1.7.m7.1.1" xref="S4.SS2.p1.7.m7.1.1.cmml">𝐳</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.7.m7.1b"><ci id="S4.SS2.p1.7.m7.1.1.cmml" xref="S4.SS2.p1.7.m7.1.1">𝐳</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.7.m7.1c">\mathbf{z}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.7.m7.1d">bold_z</annotation></semantics></math> are quantized by RQ-VAE as an ordered <math alttext="D" class="ltx_Math" display="inline" id="S4.SS2.p1.8.m8.1"><semantics id="S4.SS2.p1.8.m8.1a"><mi id="S4.SS2.p1.8.m8.1.1" xref="S4.SS2.p1.8.m8.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.8.m8.1b"><ci id="S4.SS2.p1.8.m8.1.1.cmml" xref="S4.SS2.p1.8.m8.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.8.m8.1c">D</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.8.m8.1d">italic_D</annotation></semantics></math> discrete codes:</p>
<table class="ltx_equation ltx_eqn_table" id="S4.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{RQ}(\mathbf{z}^{i};\mathcal{C},D)=(k^{i}_{1},\cdots,k^{i}_{D})\in[K]^%
{D}" class="ltx_Math" display="block" id="S4.E1.m1.7"><semantics id="S4.E1.m1.7a"><mrow id="S4.E1.m1.7.7" xref="S4.E1.m1.7.7.cmml"><mrow id="S4.E1.m1.5.5.1" xref="S4.E1.m1.5.5.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E1.m1.5.5.1.3" xref="S4.E1.m1.5.5.1.3.cmml">ℛ</mi><mo id="S4.E1.m1.5.5.1.2" xref="S4.E1.m1.5.5.1.2.cmml">⁢</mo><mi class="ltx_font_mathcaligraphic" id="S4.E1.m1.5.5.1.4" xref="S4.E1.m1.5.5.1.4.cmml">𝒬</mi><mo id="S4.E1.m1.5.5.1.2a" xref="S4.E1.m1.5.5.1.2.cmml">⁢</mo><mrow id="S4.E1.m1.5.5.1.1.1" xref="S4.E1.m1.5.5.1.1.2.cmml"><mo id="S4.E1.m1.5.5.1.1.1.2" stretchy="false" xref="S4.E1.m1.5.5.1.1.2.cmml">(</mo><msup id="S4.E1.m1.5.5.1.1.1.1" xref="S4.E1.m1.5.5.1.1.1.1.cmml"><mi id="S4.E1.m1.5.5.1.1.1.1.2" xref="S4.E1.m1.5.5.1.1.1.1.2.cmml">𝐳</mi><mi id="S4.E1.m1.5.5.1.1.1.1.3" xref="S4.E1.m1.5.5.1.1.1.1.3.cmml">i</mi></msup><mo id="S4.E1.m1.5.5.1.1.1.3" xref="S4.E1.m1.5.5.1.1.2.cmml">;</mo><mi class="ltx_font_mathcaligraphic" id="S4.E1.m1.1.1" xref="S4.E1.m1.1.1.cmml">𝒞</mi><mo id="S4.E1.m1.5.5.1.1.1.4" xref="S4.E1.m1.5.5.1.1.2.cmml">,</mo><mi id="S4.E1.m1.2.2" xref="S4.E1.m1.2.2.cmml">D</mi><mo id="S4.E1.m1.5.5.1.1.1.5" stretchy="false" xref="S4.E1.m1.5.5.1.1.2.cmml">)</mo></mrow></mrow><mo id="S4.E1.m1.7.7.5" xref="S4.E1.m1.7.7.5.cmml">=</mo><mrow id="S4.E1.m1.7.7.3.2" xref="S4.E1.m1.7.7.3.3.cmml"><mo id="S4.E1.m1.7.7.3.2.3" stretchy="false" xref="S4.E1.m1.7.7.3.3.cmml">(</mo><msubsup id="S4.E1.m1.6.6.2.1.1" xref="S4.E1.m1.6.6.2.1.1.cmml"><mi id="S4.E1.m1.6.6.2.1.1.2.2" xref="S4.E1.m1.6.6.2.1.1.2.2.cmml">k</mi><mn id="S4.E1.m1.6.6.2.1.1.3" xref="S4.E1.m1.6.6.2.1.1.3.cmml">1</mn><mi id="S4.E1.m1.6.6.2.1.1.2.3" xref="S4.E1.m1.6.6.2.1.1.2.3.cmml">i</mi></msubsup><mo id="S4.E1.m1.7.7.3.2.4" xref="S4.E1.m1.7.7.3.3.cmml">,</mo><mi id="S4.E1.m1.3.3" mathvariant="normal" xref="S4.E1.m1.3.3.cmml">⋯</mi><mo id="S4.E1.m1.7.7.3.2.5" xref="S4.E1.m1.7.7.3.3.cmml">,</mo><msubsup id="S4.E1.m1.7.7.3.2.2" xref="S4.E1.m1.7.7.3.2.2.cmml"><mi id="S4.E1.m1.7.7.3.2.2.2.2" xref="S4.E1.m1.7.7.3.2.2.2.2.cmml">k</mi><mi id="S4.E1.m1.7.7.3.2.2.3" xref="S4.E1.m1.7.7.3.2.2.3.cmml">D</mi><mi id="S4.E1.m1.7.7.3.2.2.2.3" xref="S4.E1.m1.7.7.3.2.2.2.3.cmml">i</mi></msubsup><mo id="S4.E1.m1.7.7.3.2.6" stretchy="false" xref="S4.E1.m1.7.7.3.3.cmml">)</mo></mrow><mo id="S4.E1.m1.7.7.6" xref="S4.E1.m1.7.7.6.cmml">∈</mo><msup id="S4.E1.m1.7.7.7" xref="S4.E1.m1.7.7.7.cmml"><mrow id="S4.E1.m1.7.7.7.2.2" xref="S4.E1.m1.7.7.7.2.1.cmml"><mo id="S4.E1.m1.7.7.7.2.2.1" stretchy="false" xref="S4.E1.m1.7.7.7.2.1.1.cmml">[</mo><mi id="S4.E1.m1.4.4" xref="S4.E1.m1.4.4.cmml">K</mi><mo id="S4.E1.m1.7.7.7.2.2.2" stretchy="false" xref="S4.E1.m1.7.7.7.2.1.1.cmml">]</mo></mrow><mi id="S4.E1.m1.7.7.7.3" xref="S4.E1.m1.7.7.7.3.cmml">D</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.E1.m1.7b"><apply id="S4.E1.m1.7.7.cmml" xref="S4.E1.m1.7.7"><and id="S4.E1.m1.7.7a.cmml" xref="S4.E1.m1.7.7"></and><apply id="S4.E1.m1.7.7b.cmml" xref="S4.E1.m1.7.7"><eq id="S4.E1.m1.7.7.5.cmml" xref="S4.E1.m1.7.7.5"></eq><apply id="S4.E1.m1.5.5.1.cmml" xref="S4.E1.m1.5.5.1"><times id="S4.E1.m1.5.5.1.2.cmml" xref="S4.E1.m1.5.5.1.2"></times><ci id="S4.E1.m1.5.5.1.3.cmml" xref="S4.E1.m1.5.5.1.3">ℛ</ci><ci id="S4.E1.m1.5.5.1.4.cmml" xref="S4.E1.m1.5.5.1.4">𝒬</ci><list id="S4.E1.m1.5.5.1.1.2.cmml" xref="S4.E1.m1.5.5.1.1.1"><apply id="S4.E1.m1.5.5.1.1.1.1.cmml" xref="S4.E1.m1.5.5.1.1.1.1"><csymbol cd="ambiguous" id="S4.E1.m1.5.5.1.1.1.1.1.cmml" xref="S4.E1.m1.5.5.1.1.1.1">superscript</csymbol><ci id="S4.E1.m1.5.5.1.1.1.1.2.cmml" xref="S4.E1.m1.5.5.1.1.1.1.2">𝐳</ci><ci id="S4.E1.m1.5.5.1.1.1.1.3.cmml" xref="S4.E1.m1.5.5.1.1.1.1.3">𝑖</ci></apply><ci id="S4.E1.m1.1.1.cmml" xref="S4.E1.m1.1.1">𝒞</ci><ci id="S4.E1.m1.2.2.cmml" xref="S4.E1.m1.2.2">𝐷</ci></list></apply><vector id="S4.E1.m1.7.7.3.3.cmml" xref="S4.E1.m1.7.7.3.2"><apply id="S4.E1.m1.6.6.2.1.1.cmml" xref="S4.E1.m1.6.6.2.1.1"><csymbol cd="ambiguous" id="S4.E1.m1.6.6.2.1.1.1.cmml" xref="S4.E1.m1.6.6.2.1.1">subscript</csymbol><apply id="S4.E1.m1.6.6.2.1.1.2.cmml" xref="S4.E1.m1.6.6.2.1.1"><csymbol cd="ambiguous" id="S4.E1.m1.6.6.2.1.1.2.1.cmml" xref="S4.E1.m1.6.6.2.1.1">superscript</csymbol><ci id="S4.E1.m1.6.6.2.1.1.2.2.cmml" xref="S4.E1.m1.6.6.2.1.1.2.2">𝑘</ci><ci id="S4.E1.m1.6.6.2.1.1.2.3.cmml" xref="S4.E1.m1.6.6.2.1.1.2.3">𝑖</ci></apply><cn id="S4.E1.m1.6.6.2.1.1.3.cmml" type="integer" xref="S4.E1.m1.6.6.2.1.1.3">1</cn></apply><ci id="S4.E1.m1.3.3.cmml" xref="S4.E1.m1.3.3">⋯</ci><apply id="S4.E1.m1.7.7.3.2.2.cmml" xref="S4.E1.m1.7.7.3.2.2"><csymbol cd="ambiguous" id="S4.E1.m1.7.7.3.2.2.1.cmml" xref="S4.E1.m1.7.7.3.2.2">subscript</csymbol><apply id="S4.E1.m1.7.7.3.2.2.2.cmml" xref="S4.E1.m1.7.7.3.2.2"><csymbol cd="ambiguous" id="S4.E1.m1.7.7.3.2.2.2.1.cmml" xref="S4.E1.m1.7.7.3.2.2">superscript</csymbol><ci id="S4.E1.m1.7.7.3.2.2.2.2.cmml" xref="S4.E1.m1.7.7.3.2.2.2.2">𝑘</ci><ci id="S4.E1.m1.7.7.3.2.2.2.3.cmml" xref="S4.E1.m1.7.7.3.2.2.2.3">𝑖</ci></apply><ci id="S4.E1.m1.7.7.3.2.2.3.cmml" xref="S4.E1.m1.7.7.3.2.2.3">𝐷</ci></apply></vector></apply><apply id="S4.E1.m1.7.7c.cmml" xref="S4.E1.m1.7.7"><in id="S4.E1.m1.7.7.6.cmml" xref="S4.E1.m1.7.7.6"></in><share href="https://arxiv.org/html/2410.05628v2#S4.E1.m1.7.7.3.cmml" id="S4.E1.m1.7.7d.cmml" xref="S4.E1.m1.7.7"></share><apply id="S4.E1.m1.7.7.7.cmml" xref="S4.E1.m1.7.7.7"><csymbol cd="ambiguous" id="S4.E1.m1.7.7.7.1.cmml" xref="S4.E1.m1.7.7.7">superscript</csymbol><apply id="S4.E1.m1.7.7.7.2.1.cmml" xref="S4.E1.m1.7.7.7.2.2"><csymbol cd="latexml" id="S4.E1.m1.7.7.7.2.1.1.cmml" xref="S4.E1.m1.7.7.7.2.2.1">delimited-[]</csymbol><ci id="S4.E1.m1.4.4.cmml" xref="S4.E1.m1.4.4">𝐾</ci></apply><ci id="S4.E1.m1.7.7.7.3.cmml" xref="S4.E1.m1.7.7.7.3">𝐷</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E1.m1.7c">\mathcal{RQ}(\mathbf{z}^{i};\mathcal{C},D)=(k^{i}_{1},\cdots,k^{i}_{D})\in[K]^%
{D}</annotation><annotation encoding="application/x-llamapun" id="S4.E1.m1.7d">caligraphic_R caligraphic_Q ( bold_z start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT ; caligraphic_C , italic_D ) = ( italic_k start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , ⋯ , italic_k start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_D end_POSTSUBSCRIPT ) ∈ [ italic_K ] start_POSTSUPERSCRIPT italic_D end_POSTSUPERSCRIPT</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S4.SS2.p1.14">where <math alttext="\mathcal{C}" class="ltx_Math" display="inline" id="S4.SS2.p1.9.m1.1"><semantics id="S4.SS2.p1.9.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS2.p1.9.m1.1.1" xref="S4.SS2.p1.9.m1.1.1.cmml">𝒞</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.9.m1.1b"><ci id="S4.SS2.p1.9.m1.1.1.cmml" xref="S4.SS2.p1.9.m1.1.1">𝒞</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.9.m1.1c">\mathcal{C}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.9.m1.1d">caligraphic_C</annotation></semantics></math> is the codebook, <math alttext="K=|C|" class="ltx_Math" display="inline" id="S4.SS2.p1.10.m2.1"><semantics id="S4.SS2.p1.10.m2.1a"><mrow id="S4.SS2.p1.10.m2.1.2" xref="S4.SS2.p1.10.m2.1.2.cmml"><mi id="S4.SS2.p1.10.m2.1.2.2" xref="S4.SS2.p1.10.m2.1.2.2.cmml">K</mi><mo id="S4.SS2.p1.10.m2.1.2.1" xref="S4.SS2.p1.10.m2.1.2.1.cmml">=</mo><mrow id="S4.SS2.p1.10.m2.1.2.3.2" xref="S4.SS2.p1.10.m2.1.2.3.1.cmml"><mo id="S4.SS2.p1.10.m2.1.2.3.2.1" stretchy="false" xref="S4.SS2.p1.10.m2.1.2.3.1.1.cmml">|</mo><mi id="S4.SS2.p1.10.m2.1.1" xref="S4.SS2.p1.10.m2.1.1.cmml">C</mi><mo id="S4.SS2.p1.10.m2.1.2.3.2.2" stretchy="false" xref="S4.SS2.p1.10.m2.1.2.3.1.1.cmml">|</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.10.m2.1b"><apply id="S4.SS2.p1.10.m2.1.2.cmml" xref="S4.SS2.p1.10.m2.1.2"><eq id="S4.SS2.p1.10.m2.1.2.1.cmml" xref="S4.SS2.p1.10.m2.1.2.1"></eq><ci id="S4.SS2.p1.10.m2.1.2.2.cmml" xref="S4.SS2.p1.10.m2.1.2.2">𝐾</ci><apply id="S4.SS2.p1.10.m2.1.2.3.1.cmml" xref="S4.SS2.p1.10.m2.1.2.3.2"><abs id="S4.SS2.p1.10.m2.1.2.3.1.1.cmml" xref="S4.SS2.p1.10.m2.1.2.3.2.1"></abs><ci id="S4.SS2.p1.10.m2.1.1.cmml" xref="S4.SS2.p1.10.m2.1.1">𝐶</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.10.m2.1c">K=|C|</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.10.m2.1d">italic_K = | italic_C |</annotation></semantics></math>, and <math alttext="k^{i}_{d}" class="ltx_Math" display="inline" id="S4.SS2.p1.11.m3.1"><semantics id="S4.SS2.p1.11.m3.1a"><msubsup id="S4.SS2.p1.11.m3.1.1" xref="S4.SS2.p1.11.m3.1.1.cmml"><mi id="S4.SS2.p1.11.m3.1.1.2.2" xref="S4.SS2.p1.11.m3.1.1.2.2.cmml">k</mi><mi id="S4.SS2.p1.11.m3.1.1.3" xref="S4.SS2.p1.11.m3.1.1.3.cmml">d</mi><mi id="S4.SS2.p1.11.m3.1.1.2.3" xref="S4.SS2.p1.11.m3.1.1.2.3.cmml">i</mi></msubsup><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.11.m3.1b"><apply id="S4.SS2.p1.11.m3.1.1.cmml" xref="S4.SS2.p1.11.m3.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.11.m3.1.1.1.cmml" xref="S4.SS2.p1.11.m3.1.1">subscript</csymbol><apply id="S4.SS2.p1.11.m3.1.1.2.cmml" xref="S4.SS2.p1.11.m3.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.11.m3.1.1.2.1.cmml" xref="S4.SS2.p1.11.m3.1.1">superscript</csymbol><ci id="S4.SS2.p1.11.m3.1.1.2.2.cmml" xref="S4.SS2.p1.11.m3.1.1.2.2">𝑘</ci><ci id="S4.SS2.p1.11.m3.1.1.2.3.cmml" xref="S4.SS2.p1.11.m3.1.1.2.3">𝑖</ci></apply><ci id="S4.SS2.p1.11.m3.1.1.3.cmml" xref="S4.SS2.p1.11.m3.1.1.3">𝑑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.11.m3.1c">k^{i}_{d}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.11.m3.1d">italic_k start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT</annotation></semantics></math> is code of <math alttext="\mathbf{z}" class="ltx_Math" display="inline" id="S4.SS2.p1.12.m4.1"><semantics id="S4.SS2.p1.12.m4.1a"><mi id="S4.SS2.p1.12.m4.1.1" xref="S4.SS2.p1.12.m4.1.1.cmml">𝐳</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.12.m4.1b"><ci id="S4.SS2.p1.12.m4.1.1.cmml" xref="S4.SS2.p1.12.m4.1.1">𝐳</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.12.m4.1c">\mathbf{z}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.12.m4.1d">bold_z</annotation></semantics></math> at timestep <math alttext="i" class="ltx_Math" display="inline" id="S4.SS2.p1.13.m5.1"><semantics id="S4.SS2.p1.13.m5.1a"><mi id="S4.SS2.p1.13.m5.1.1" xref="S4.SS2.p1.13.m5.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.13.m5.1b"><ci id="S4.SS2.p1.13.m5.1.1.cmml" xref="S4.SS2.p1.13.m5.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.13.m5.1c">i</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.13.m5.1d">italic_i</annotation></semantics></math> and depth <math alttext="d" class="ltx_Math" display="inline" id="S4.SS2.p1.14.m6.1"><semantics id="S4.SS2.p1.14.m6.1a"><mi id="S4.SS2.p1.14.m6.1.1" xref="S4.SS2.p1.14.m6.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.14.m6.1b"><ci id="S4.SS2.p1.14.m6.1.1.cmml" xref="S4.SS2.p1.14.m6.1.1">𝑑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.14.m6.1c">d</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.14.m6.1d">italic_d</annotation></semantics></math>.
These discrete codes form a motion vocabulary. For text, we use a standard text tokenizer to process textual instructions and descriptions into tokens.
</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.5">Tokens are then proceeded to the language model block, which serves as the central processing unit.
In this work, we have utilized the LLaMA-3.1-8B <cite class="ltx_cite ltx_citemacro_citep">(Dubey et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib9" title="">2024</a>)</cite> model as a base model. We integrate motion tokens with text tokens using a unified vocabulary, which combines both the text and motion vocabularies into one, with special tokens added to mark the start and end of the motion sequences. This shared token space enables the model to efficiently process and generate both modalities for motion-related tasks.
Interactive motion is represented as <math alttext="X_{m}=\{k^{1;a}_{1:D},k^{1;b}_{1:D},\cdots,k^{L;a}_{1:D},k^{L;b}_{1:D}\}" class="ltx_Math" display="inline" id="S4.SS2.p2.1.m1.13"><semantics id="S4.SS2.p2.1.m1.13a"><mrow id="S4.SS2.p2.1.m1.13.13" xref="S4.SS2.p2.1.m1.13.13.cmml"><msub id="S4.SS2.p2.1.m1.13.13.6" xref="S4.SS2.p2.1.m1.13.13.6.cmml"><mi id="S4.SS2.p2.1.m1.13.13.6.2" xref="S4.SS2.p2.1.m1.13.13.6.2.cmml">X</mi><mi id="S4.SS2.p2.1.m1.13.13.6.3" xref="S4.SS2.p2.1.m1.13.13.6.3.cmml">m</mi></msub><mo id="S4.SS2.p2.1.m1.13.13.5" xref="S4.SS2.p2.1.m1.13.13.5.cmml">=</mo><mrow id="S4.SS2.p2.1.m1.13.13.4.4" xref="S4.SS2.p2.1.m1.13.13.4.5.cmml"><mo id="S4.SS2.p2.1.m1.13.13.4.4.5" stretchy="false" xref="S4.SS2.p2.1.m1.13.13.4.5.cmml">{</mo><msubsup id="S4.SS2.p2.1.m1.10.10.1.1.1" xref="S4.SS2.p2.1.m1.10.10.1.1.1.cmml"><mi id="S4.SS2.p2.1.m1.10.10.1.1.1.2.2" xref="S4.SS2.p2.1.m1.10.10.1.1.1.2.2.cmml">k</mi><mrow id="S4.SS2.p2.1.m1.10.10.1.1.1.3" xref="S4.SS2.p2.1.m1.10.10.1.1.1.3.cmml"><mn id="S4.SS2.p2.1.m1.10.10.1.1.1.3.2" xref="S4.SS2.p2.1.m1.10.10.1.1.1.3.2.cmml">1</mn><mo id="S4.SS2.p2.1.m1.10.10.1.1.1.3.1" lspace="0.278em" rspace="0.278em" xref="S4.SS2.p2.1.m1.10.10.1.1.1.3.1.cmml">:</mo><mi id="S4.SS2.p2.1.m1.10.10.1.1.1.3.3" xref="S4.SS2.p2.1.m1.10.10.1.1.1.3.3.cmml">D</mi></mrow><mrow id="S4.SS2.p2.1.m1.2.2.2.4" xref="S4.SS2.p2.1.m1.2.2.2.3.cmml"><mn id="S4.SS2.p2.1.m1.1.1.1.1" xref="S4.SS2.p2.1.m1.1.1.1.1.cmml">1</mn><mo id="S4.SS2.p2.1.m1.2.2.2.4.1" xref="S4.SS2.p2.1.m1.2.2.2.3.cmml">;</mo><mi id="S4.SS2.p2.1.m1.2.2.2.2" xref="S4.SS2.p2.1.m1.2.2.2.2.cmml">a</mi></mrow></msubsup><mo id="S4.SS2.p2.1.m1.13.13.4.4.6" xref="S4.SS2.p2.1.m1.13.13.4.5.cmml">,</mo><msubsup id="S4.SS2.p2.1.m1.11.11.2.2.2" xref="S4.SS2.p2.1.m1.11.11.2.2.2.cmml"><mi id="S4.SS2.p2.1.m1.11.11.2.2.2.2.2" xref="S4.SS2.p2.1.m1.11.11.2.2.2.2.2.cmml">k</mi><mrow id="S4.SS2.p2.1.m1.11.11.2.2.2.3" xref="S4.SS2.p2.1.m1.11.11.2.2.2.3.cmml"><mn id="S4.SS2.p2.1.m1.11.11.2.2.2.3.2" xref="S4.SS2.p2.1.m1.11.11.2.2.2.3.2.cmml">1</mn><mo id="S4.SS2.p2.1.m1.11.11.2.2.2.3.1" lspace="0.278em" rspace="0.278em" xref="S4.SS2.p2.1.m1.11.11.2.2.2.3.1.cmml">:</mo><mi id="S4.SS2.p2.1.m1.11.11.2.2.2.3.3" xref="S4.SS2.p2.1.m1.11.11.2.2.2.3.3.cmml">D</mi></mrow><mrow id="S4.SS2.p2.1.m1.4.4.2.4" xref="S4.SS2.p2.1.m1.4.4.2.3.cmml"><mn id="S4.SS2.p2.1.m1.3.3.1.1" xref="S4.SS2.p2.1.m1.3.3.1.1.cmml">1</mn><mo id="S4.SS2.p2.1.m1.4.4.2.4.1" xref="S4.SS2.p2.1.m1.4.4.2.3.cmml">;</mo><mi id="S4.SS2.p2.1.m1.4.4.2.2" xref="S4.SS2.p2.1.m1.4.4.2.2.cmml">b</mi></mrow></msubsup><mo id="S4.SS2.p2.1.m1.13.13.4.4.7" xref="S4.SS2.p2.1.m1.13.13.4.5.cmml">,</mo><mi id="S4.SS2.p2.1.m1.9.9" mathvariant="normal" xref="S4.SS2.p2.1.m1.9.9.cmml">⋯</mi><mo id="S4.SS2.p2.1.m1.13.13.4.4.8" xref="S4.SS2.p2.1.m1.13.13.4.5.cmml">,</mo><msubsup id="S4.SS2.p2.1.m1.12.12.3.3.3" xref="S4.SS2.p2.1.m1.12.12.3.3.3.cmml"><mi id="S4.SS2.p2.1.m1.12.12.3.3.3.2.2" xref="S4.SS2.p2.1.m1.12.12.3.3.3.2.2.cmml">k</mi><mrow id="S4.SS2.p2.1.m1.12.12.3.3.3.3" xref="S4.SS2.p2.1.m1.12.12.3.3.3.3.cmml"><mn id="S4.SS2.p2.1.m1.12.12.3.3.3.3.2" xref="S4.SS2.p2.1.m1.12.12.3.3.3.3.2.cmml">1</mn><mo id="S4.SS2.p2.1.m1.12.12.3.3.3.3.1" lspace="0.278em" rspace="0.278em" xref="S4.SS2.p2.1.m1.12.12.3.3.3.3.1.cmml">:</mo><mi id="S4.SS2.p2.1.m1.12.12.3.3.3.3.3" xref="S4.SS2.p2.1.m1.12.12.3.3.3.3.3.cmml">D</mi></mrow><mrow id="S4.SS2.p2.1.m1.6.6.2.4" xref="S4.SS2.p2.1.m1.6.6.2.3.cmml"><mi id="S4.SS2.p2.1.m1.5.5.1.1" xref="S4.SS2.p2.1.m1.5.5.1.1.cmml">L</mi><mo id="S4.SS2.p2.1.m1.6.6.2.4.1" xref="S4.SS2.p2.1.m1.6.6.2.3.cmml">;</mo><mi id="S4.SS2.p2.1.m1.6.6.2.2" xref="S4.SS2.p2.1.m1.6.6.2.2.cmml">a</mi></mrow></msubsup><mo id="S4.SS2.p2.1.m1.13.13.4.4.9" xref="S4.SS2.p2.1.m1.13.13.4.5.cmml">,</mo><msubsup id="S4.SS2.p2.1.m1.13.13.4.4.4" xref="S4.SS2.p2.1.m1.13.13.4.4.4.cmml"><mi id="S4.SS2.p2.1.m1.13.13.4.4.4.2.2" xref="S4.SS2.p2.1.m1.13.13.4.4.4.2.2.cmml">k</mi><mrow id="S4.SS2.p2.1.m1.13.13.4.4.4.3" xref="S4.SS2.p2.1.m1.13.13.4.4.4.3.cmml"><mn id="S4.SS2.p2.1.m1.13.13.4.4.4.3.2" xref="S4.SS2.p2.1.m1.13.13.4.4.4.3.2.cmml">1</mn><mo id="S4.SS2.p2.1.m1.13.13.4.4.4.3.1" lspace="0.278em" rspace="0.278em" xref="S4.SS2.p2.1.m1.13.13.4.4.4.3.1.cmml">:</mo><mi id="S4.SS2.p2.1.m1.13.13.4.4.4.3.3" xref="S4.SS2.p2.1.m1.13.13.4.4.4.3.3.cmml">D</mi></mrow><mrow id="S4.SS2.p2.1.m1.8.8.2.4" xref="S4.SS2.p2.1.m1.8.8.2.3.cmml"><mi id="S4.SS2.p2.1.m1.7.7.1.1" xref="S4.SS2.p2.1.m1.7.7.1.1.cmml">L</mi><mo id="S4.SS2.p2.1.m1.8.8.2.4.1" xref="S4.SS2.p2.1.m1.8.8.2.3.cmml">;</mo><mi id="S4.SS2.p2.1.m1.8.8.2.2" xref="S4.SS2.p2.1.m1.8.8.2.2.cmml">b</mi></mrow></msubsup><mo id="S4.SS2.p2.1.m1.13.13.4.4.10" stretchy="false" xref="S4.SS2.p2.1.m1.13.13.4.5.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.1.m1.13b"><apply id="S4.SS2.p2.1.m1.13.13.cmml" xref="S4.SS2.p2.1.m1.13.13"><eq id="S4.SS2.p2.1.m1.13.13.5.cmml" xref="S4.SS2.p2.1.m1.13.13.5"></eq><apply id="S4.SS2.p2.1.m1.13.13.6.cmml" xref="S4.SS2.p2.1.m1.13.13.6"><csymbol cd="ambiguous" id="S4.SS2.p2.1.m1.13.13.6.1.cmml" xref="S4.SS2.p2.1.m1.13.13.6">subscript</csymbol><ci id="S4.SS2.p2.1.m1.13.13.6.2.cmml" xref="S4.SS2.p2.1.m1.13.13.6.2">𝑋</ci><ci id="S4.SS2.p2.1.m1.13.13.6.3.cmml" xref="S4.SS2.p2.1.m1.13.13.6.3">𝑚</ci></apply><set id="S4.SS2.p2.1.m1.13.13.4.5.cmml" xref="S4.SS2.p2.1.m1.13.13.4.4"><apply id="S4.SS2.p2.1.m1.10.10.1.1.1.cmml" xref="S4.SS2.p2.1.m1.10.10.1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p2.1.m1.10.10.1.1.1.1.cmml" xref="S4.SS2.p2.1.m1.10.10.1.1.1">subscript</csymbol><apply id="S4.SS2.p2.1.m1.10.10.1.1.1.2.cmml" xref="S4.SS2.p2.1.m1.10.10.1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p2.1.m1.10.10.1.1.1.2.1.cmml" xref="S4.SS2.p2.1.m1.10.10.1.1.1">superscript</csymbol><ci id="S4.SS2.p2.1.m1.10.10.1.1.1.2.2.cmml" xref="S4.SS2.p2.1.m1.10.10.1.1.1.2.2">𝑘</ci><list id="S4.SS2.p2.1.m1.2.2.2.3.cmml" xref="S4.SS2.p2.1.m1.2.2.2.4"><cn id="S4.SS2.p2.1.m1.1.1.1.1.cmml" type="integer" xref="S4.SS2.p2.1.m1.1.1.1.1">1</cn><ci id="S4.SS2.p2.1.m1.2.2.2.2.cmml" xref="S4.SS2.p2.1.m1.2.2.2.2">𝑎</ci></list></apply><apply id="S4.SS2.p2.1.m1.10.10.1.1.1.3.cmml" xref="S4.SS2.p2.1.m1.10.10.1.1.1.3"><ci id="S4.SS2.p2.1.m1.10.10.1.1.1.3.1.cmml" xref="S4.SS2.p2.1.m1.10.10.1.1.1.3.1">:</ci><cn id="S4.SS2.p2.1.m1.10.10.1.1.1.3.2.cmml" type="integer" xref="S4.SS2.p2.1.m1.10.10.1.1.1.3.2">1</cn><ci id="S4.SS2.p2.1.m1.10.10.1.1.1.3.3.cmml" xref="S4.SS2.p2.1.m1.10.10.1.1.1.3.3">𝐷</ci></apply></apply><apply id="S4.SS2.p2.1.m1.11.11.2.2.2.cmml" xref="S4.SS2.p2.1.m1.11.11.2.2.2"><csymbol cd="ambiguous" id="S4.SS2.p2.1.m1.11.11.2.2.2.1.cmml" xref="S4.SS2.p2.1.m1.11.11.2.2.2">subscript</csymbol><apply id="S4.SS2.p2.1.m1.11.11.2.2.2.2.cmml" xref="S4.SS2.p2.1.m1.11.11.2.2.2"><csymbol cd="ambiguous" id="S4.SS2.p2.1.m1.11.11.2.2.2.2.1.cmml" xref="S4.SS2.p2.1.m1.11.11.2.2.2">superscript</csymbol><ci id="S4.SS2.p2.1.m1.11.11.2.2.2.2.2.cmml" xref="S4.SS2.p2.1.m1.11.11.2.2.2.2.2">𝑘</ci><list id="S4.SS2.p2.1.m1.4.4.2.3.cmml" xref="S4.SS2.p2.1.m1.4.4.2.4"><cn id="S4.SS2.p2.1.m1.3.3.1.1.cmml" type="integer" xref="S4.SS2.p2.1.m1.3.3.1.1">1</cn><ci id="S4.SS2.p2.1.m1.4.4.2.2.cmml" xref="S4.SS2.p2.1.m1.4.4.2.2">𝑏</ci></list></apply><apply id="S4.SS2.p2.1.m1.11.11.2.2.2.3.cmml" xref="S4.SS2.p2.1.m1.11.11.2.2.2.3"><ci id="S4.SS2.p2.1.m1.11.11.2.2.2.3.1.cmml" xref="S4.SS2.p2.1.m1.11.11.2.2.2.3.1">:</ci><cn id="S4.SS2.p2.1.m1.11.11.2.2.2.3.2.cmml" type="integer" xref="S4.SS2.p2.1.m1.11.11.2.2.2.3.2">1</cn><ci id="S4.SS2.p2.1.m1.11.11.2.2.2.3.3.cmml" xref="S4.SS2.p2.1.m1.11.11.2.2.2.3.3">𝐷</ci></apply></apply><ci id="S4.SS2.p2.1.m1.9.9.cmml" xref="S4.SS2.p2.1.m1.9.9">⋯</ci><apply id="S4.SS2.p2.1.m1.12.12.3.3.3.cmml" xref="S4.SS2.p2.1.m1.12.12.3.3.3"><csymbol cd="ambiguous" id="S4.SS2.p2.1.m1.12.12.3.3.3.1.cmml" xref="S4.SS2.p2.1.m1.12.12.3.3.3">subscript</csymbol><apply id="S4.SS2.p2.1.m1.12.12.3.3.3.2.cmml" xref="S4.SS2.p2.1.m1.12.12.3.3.3"><csymbol cd="ambiguous" id="S4.SS2.p2.1.m1.12.12.3.3.3.2.1.cmml" xref="S4.SS2.p2.1.m1.12.12.3.3.3">superscript</csymbol><ci id="S4.SS2.p2.1.m1.12.12.3.3.3.2.2.cmml" xref="S4.SS2.p2.1.m1.12.12.3.3.3.2.2">𝑘</ci><list id="S4.SS2.p2.1.m1.6.6.2.3.cmml" xref="S4.SS2.p2.1.m1.6.6.2.4"><ci id="S4.SS2.p2.1.m1.5.5.1.1.cmml" xref="S4.SS2.p2.1.m1.5.5.1.1">𝐿</ci><ci id="S4.SS2.p2.1.m1.6.6.2.2.cmml" xref="S4.SS2.p2.1.m1.6.6.2.2">𝑎</ci></list></apply><apply id="S4.SS2.p2.1.m1.12.12.3.3.3.3.cmml" xref="S4.SS2.p2.1.m1.12.12.3.3.3.3"><ci id="S4.SS2.p2.1.m1.12.12.3.3.3.3.1.cmml" xref="S4.SS2.p2.1.m1.12.12.3.3.3.3.1">:</ci><cn id="S4.SS2.p2.1.m1.12.12.3.3.3.3.2.cmml" type="integer" xref="S4.SS2.p2.1.m1.12.12.3.3.3.3.2">1</cn><ci id="S4.SS2.p2.1.m1.12.12.3.3.3.3.3.cmml" xref="S4.SS2.p2.1.m1.12.12.3.3.3.3.3">𝐷</ci></apply></apply><apply id="S4.SS2.p2.1.m1.13.13.4.4.4.cmml" xref="S4.SS2.p2.1.m1.13.13.4.4.4"><csymbol cd="ambiguous" id="S4.SS2.p2.1.m1.13.13.4.4.4.1.cmml" xref="S4.SS2.p2.1.m1.13.13.4.4.4">subscript</csymbol><apply id="S4.SS2.p2.1.m1.13.13.4.4.4.2.cmml" xref="S4.SS2.p2.1.m1.13.13.4.4.4"><csymbol cd="ambiguous" id="S4.SS2.p2.1.m1.13.13.4.4.4.2.1.cmml" xref="S4.SS2.p2.1.m1.13.13.4.4.4">superscript</csymbol><ci id="S4.SS2.p2.1.m1.13.13.4.4.4.2.2.cmml" xref="S4.SS2.p2.1.m1.13.13.4.4.4.2.2">𝑘</ci><list id="S4.SS2.p2.1.m1.8.8.2.3.cmml" xref="S4.SS2.p2.1.m1.8.8.2.4"><ci id="S4.SS2.p2.1.m1.7.7.1.1.cmml" xref="S4.SS2.p2.1.m1.7.7.1.1">𝐿</ci><ci id="S4.SS2.p2.1.m1.8.8.2.2.cmml" xref="S4.SS2.p2.1.m1.8.8.2.2">𝑏</ci></list></apply><apply id="S4.SS2.p2.1.m1.13.13.4.4.4.3.cmml" xref="S4.SS2.p2.1.m1.13.13.4.4.4.3"><ci id="S4.SS2.p2.1.m1.13.13.4.4.4.3.1.cmml" xref="S4.SS2.p2.1.m1.13.13.4.4.4.3.1">:</ci><cn id="S4.SS2.p2.1.m1.13.13.4.4.4.3.2.cmml" type="integer" xref="S4.SS2.p2.1.m1.13.13.4.4.4.3.2">1</cn><ci id="S4.SS2.p2.1.m1.13.13.4.4.4.3.3.cmml" xref="S4.SS2.p2.1.m1.13.13.4.4.4.3.3">𝐷</ci></apply></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.1.m1.13c">X_{m}=\{k^{1;a}_{1:D},k^{1;b}_{1:D},\cdots,k^{L;a}_{1:D},k^{L;b}_{1:D}\}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p2.1.m1.13d">italic_X start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT = { italic_k start_POSTSUPERSCRIPT 1 ; italic_a end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 : italic_D end_POSTSUBSCRIPT , italic_k start_POSTSUPERSCRIPT 1 ; italic_b end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 : italic_D end_POSTSUBSCRIPT , ⋯ , italic_k start_POSTSUPERSCRIPT italic_L ; italic_a end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 : italic_D end_POSTSUBSCRIPT , italic_k start_POSTSUPERSCRIPT italic_L ; italic_b end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 : italic_D end_POSTSUBSCRIPT }</annotation></semantics></math>, where <math alttext="X_{m}" class="ltx_Math" display="inline" id="S4.SS2.p2.2.m2.1"><semantics id="S4.SS2.p2.2.m2.1a"><msub id="S4.SS2.p2.2.m2.1.1" xref="S4.SS2.p2.2.m2.1.1.cmml"><mi id="S4.SS2.p2.2.m2.1.1.2" xref="S4.SS2.p2.2.m2.1.1.2.cmml">X</mi><mi id="S4.SS2.p2.2.m2.1.1.3" xref="S4.SS2.p2.2.m2.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.2.m2.1b"><apply id="S4.SS2.p2.2.m2.1.1.cmml" xref="S4.SS2.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.p2.2.m2.1.1.1.cmml" xref="S4.SS2.p2.2.m2.1.1">subscript</csymbol><ci id="S4.SS2.p2.2.m2.1.1.2.cmml" xref="S4.SS2.p2.2.m2.1.1.2">𝑋</ci><ci id="S4.SS2.p2.2.m2.1.1.3.cmml" xref="S4.SS2.p2.2.m2.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.2.m2.1c">X_{m}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p2.2.m2.1d">italic_X start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT</annotation></semantics></math> is a sequence of motion represented in unified vocabulary and <math alttext="k^{i;a}_{1:D}\in[K]^{D}" class="ltx_Math" display="inline" id="S4.SS2.p2.3.m3.3"><semantics id="S4.SS2.p2.3.m3.3a"><mrow id="S4.SS2.p2.3.m3.3.4" xref="S4.SS2.p2.3.m3.3.4.cmml"><msubsup id="S4.SS2.p2.3.m3.3.4.2" xref="S4.SS2.p2.3.m3.3.4.2.cmml"><mi id="S4.SS2.p2.3.m3.3.4.2.2.2" xref="S4.SS2.p2.3.m3.3.4.2.2.2.cmml">k</mi><mrow id="S4.SS2.p2.3.m3.3.4.2.3" xref="S4.SS2.p2.3.m3.3.4.2.3.cmml"><mn id="S4.SS2.p2.3.m3.3.4.2.3.2" xref="S4.SS2.p2.3.m3.3.4.2.3.2.cmml">1</mn><mo id="S4.SS2.p2.3.m3.3.4.2.3.1" lspace="0.278em" rspace="0.278em" xref="S4.SS2.p2.3.m3.3.4.2.3.1.cmml">:</mo><mi id="S4.SS2.p2.3.m3.3.4.2.3.3" xref="S4.SS2.p2.3.m3.3.4.2.3.3.cmml">D</mi></mrow><mrow id="S4.SS2.p2.3.m3.2.2.2.4" xref="S4.SS2.p2.3.m3.2.2.2.3.cmml"><mi id="S4.SS2.p2.3.m3.1.1.1.1" xref="S4.SS2.p2.3.m3.1.1.1.1.cmml">i</mi><mo id="S4.SS2.p2.3.m3.2.2.2.4.1" xref="S4.SS2.p2.3.m3.2.2.2.3.cmml">;</mo><mi id="S4.SS2.p2.3.m3.2.2.2.2" xref="S4.SS2.p2.3.m3.2.2.2.2.cmml">a</mi></mrow></msubsup><mo id="S4.SS2.p2.3.m3.3.4.1" xref="S4.SS2.p2.3.m3.3.4.1.cmml">∈</mo><msup id="S4.SS2.p2.3.m3.3.4.3" xref="S4.SS2.p2.3.m3.3.4.3.cmml"><mrow id="S4.SS2.p2.3.m3.3.4.3.2.2" xref="S4.SS2.p2.3.m3.3.4.3.2.1.cmml"><mo id="S4.SS2.p2.3.m3.3.4.3.2.2.1" stretchy="false" xref="S4.SS2.p2.3.m3.3.4.3.2.1.1.cmml">[</mo><mi id="S4.SS2.p2.3.m3.3.3" xref="S4.SS2.p2.3.m3.3.3.cmml">K</mi><mo id="S4.SS2.p2.3.m3.3.4.3.2.2.2" stretchy="false" xref="S4.SS2.p2.3.m3.3.4.3.2.1.1.cmml">]</mo></mrow><mi id="S4.SS2.p2.3.m3.3.4.3.3" xref="S4.SS2.p2.3.m3.3.4.3.3.cmml">D</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.3.m3.3b"><apply id="S4.SS2.p2.3.m3.3.4.cmml" xref="S4.SS2.p2.3.m3.3.4"><in id="S4.SS2.p2.3.m3.3.4.1.cmml" xref="S4.SS2.p2.3.m3.3.4.1"></in><apply id="S4.SS2.p2.3.m3.3.4.2.cmml" xref="S4.SS2.p2.3.m3.3.4.2"><csymbol cd="ambiguous" id="S4.SS2.p2.3.m3.3.4.2.1.cmml" xref="S4.SS2.p2.3.m3.3.4.2">subscript</csymbol><apply id="S4.SS2.p2.3.m3.3.4.2.2.cmml" xref="S4.SS2.p2.3.m3.3.4.2"><csymbol cd="ambiguous" id="S4.SS2.p2.3.m3.3.4.2.2.1.cmml" xref="S4.SS2.p2.3.m3.3.4.2">superscript</csymbol><ci id="S4.SS2.p2.3.m3.3.4.2.2.2.cmml" xref="S4.SS2.p2.3.m3.3.4.2.2.2">𝑘</ci><list id="S4.SS2.p2.3.m3.2.2.2.3.cmml" xref="S4.SS2.p2.3.m3.2.2.2.4"><ci id="S4.SS2.p2.3.m3.1.1.1.1.cmml" xref="S4.SS2.p2.3.m3.1.1.1.1">𝑖</ci><ci id="S4.SS2.p2.3.m3.2.2.2.2.cmml" xref="S4.SS2.p2.3.m3.2.2.2.2">𝑎</ci></list></apply><apply id="S4.SS2.p2.3.m3.3.4.2.3.cmml" xref="S4.SS2.p2.3.m3.3.4.2.3"><ci id="S4.SS2.p2.3.m3.3.4.2.3.1.cmml" xref="S4.SS2.p2.3.m3.3.4.2.3.1">:</ci><cn id="S4.SS2.p2.3.m3.3.4.2.3.2.cmml" type="integer" xref="S4.SS2.p2.3.m3.3.4.2.3.2">1</cn><ci id="S4.SS2.p2.3.m3.3.4.2.3.3.cmml" xref="S4.SS2.p2.3.m3.3.4.2.3.3">𝐷</ci></apply></apply><apply id="S4.SS2.p2.3.m3.3.4.3.cmml" xref="S4.SS2.p2.3.m3.3.4.3"><csymbol cd="ambiguous" id="S4.SS2.p2.3.m3.3.4.3.1.cmml" xref="S4.SS2.p2.3.m3.3.4.3">superscript</csymbol><apply id="S4.SS2.p2.3.m3.3.4.3.2.1.cmml" xref="S4.SS2.p2.3.m3.3.4.3.2.2"><csymbol cd="latexml" id="S4.SS2.p2.3.m3.3.4.3.2.1.1.cmml" xref="S4.SS2.p2.3.m3.3.4.3.2.2.1">delimited-[]</csymbol><ci id="S4.SS2.p2.3.m3.3.3.cmml" xref="S4.SS2.p2.3.m3.3.3">𝐾</ci></apply><ci id="S4.SS2.p2.3.m3.3.4.3.3.cmml" xref="S4.SS2.p2.3.m3.3.4.3.3">𝐷</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.3.m3.3c">k^{i;a}_{1:D}\in[K]^{D}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p2.3.m3.3d">italic_k start_POSTSUPERSCRIPT italic_i ; italic_a end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 : italic_D end_POSTSUBSCRIPT ∈ [ italic_K ] start_POSTSUPERSCRIPT italic_D end_POSTSUPERSCRIPT</annotation></semantics></math> is the <math alttext="i" class="ltx_Math" display="inline" id="S4.SS2.p2.4.m4.1"><semantics id="S4.SS2.p2.4.m4.1a"><mi id="S4.SS2.p2.4.m4.1.1" xref="S4.SS2.p2.4.m4.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.4.m4.1b"><ci id="S4.SS2.p2.4.m4.1.1.cmml" xref="S4.SS2.p2.4.m4.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.4.m4.1c">i</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p2.4.m4.1d">italic_i</annotation></semantics></math>-th token of motion <math alttext="a" class="ltx_Math" display="inline" id="S4.SS2.p2.5.m5.1"><semantics id="S4.SS2.p2.5.m5.1a"><mi id="S4.SS2.p2.5.m5.1.1" xref="S4.SS2.p2.5.m5.1.1.cmml">a</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.5.m5.1b"><ci id="S4.SS2.p2.5.m5.1.1.cmml" xref="S4.SS2.p2.5.m5.1.1">𝑎</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.5.m5.1c">a</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p2.5.m5.1d">italic_a</annotation></semantics></math>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p3">
<p class="ltx_p" id="S4.SS2.p3.3">Finally, the decoding stage reverses the encoding process. For motion, the decoder <math alttext="\mathcal{D}_{M}" class="ltx_Math" display="inline" id="S4.SS2.p3.1.m1.1"><semantics id="S4.SS2.p3.1.m1.1a"><msub id="S4.SS2.p3.1.m1.1.1" xref="S4.SS2.p3.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS2.p3.1.m1.1.1.2" xref="S4.SS2.p3.1.m1.1.1.2.cmml">𝒟</mi><mi id="S4.SS2.p3.1.m1.1.1.3" xref="S4.SS2.p3.1.m1.1.1.3.cmml">M</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.1.m1.1b"><apply id="S4.SS2.p3.1.m1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p3.1.m1.1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1">subscript</csymbol><ci id="S4.SS2.p3.1.m1.1.1.2.cmml" xref="S4.SS2.p3.1.m1.1.1.2">𝒟</ci><ci id="S4.SS2.p3.1.m1.1.1.3.cmml" xref="S4.SS2.p3.1.m1.1.1.3">𝑀</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.1.m1.1c">\mathcal{D}_{M}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p3.1.m1.1d">caligraphic_D start_POSTSUBSCRIPT italic_M end_POSTSUBSCRIPT</annotation></semantics></math> projects the quantized features <math alttext="\hat{\mathbf{z}}^{i}=\sum_{d=1}^{D}\mathbf{e}(k_{d}^{i})" class="ltx_Math" display="inline" id="S4.SS2.p3.2.m2.1"><semantics id="S4.SS2.p3.2.m2.1a"><mrow id="S4.SS2.p3.2.m2.1.1" xref="S4.SS2.p3.2.m2.1.1.cmml"><msup id="S4.SS2.p3.2.m2.1.1.3" xref="S4.SS2.p3.2.m2.1.1.3.cmml"><mover accent="true" id="S4.SS2.p3.2.m2.1.1.3.2" xref="S4.SS2.p3.2.m2.1.1.3.2.cmml"><mi id="S4.SS2.p3.2.m2.1.1.3.2.2" xref="S4.SS2.p3.2.m2.1.1.3.2.2.cmml">𝐳</mi><mo id="S4.SS2.p3.2.m2.1.1.3.2.1" xref="S4.SS2.p3.2.m2.1.1.3.2.1.cmml">^</mo></mover><mi id="S4.SS2.p3.2.m2.1.1.3.3" xref="S4.SS2.p3.2.m2.1.1.3.3.cmml">i</mi></msup><mo id="S4.SS2.p3.2.m2.1.1.2" rspace="0.111em" xref="S4.SS2.p3.2.m2.1.1.2.cmml">=</mo><mrow id="S4.SS2.p3.2.m2.1.1.1" xref="S4.SS2.p3.2.m2.1.1.1.cmml"><msubsup id="S4.SS2.p3.2.m2.1.1.1.2" xref="S4.SS2.p3.2.m2.1.1.1.2.cmml"><mo id="S4.SS2.p3.2.m2.1.1.1.2.2.2" xref="S4.SS2.p3.2.m2.1.1.1.2.2.2.cmml">∑</mo><mrow id="S4.SS2.p3.2.m2.1.1.1.2.2.3" xref="S4.SS2.p3.2.m2.1.1.1.2.2.3.cmml"><mi id="S4.SS2.p3.2.m2.1.1.1.2.2.3.2" xref="S4.SS2.p3.2.m2.1.1.1.2.2.3.2.cmml">d</mi><mo id="S4.SS2.p3.2.m2.1.1.1.2.2.3.1" xref="S4.SS2.p3.2.m2.1.1.1.2.2.3.1.cmml">=</mo><mn id="S4.SS2.p3.2.m2.1.1.1.2.2.3.3" xref="S4.SS2.p3.2.m2.1.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S4.SS2.p3.2.m2.1.1.1.2.3" xref="S4.SS2.p3.2.m2.1.1.1.2.3.cmml">D</mi></msubsup><mrow id="S4.SS2.p3.2.m2.1.1.1.1" xref="S4.SS2.p3.2.m2.1.1.1.1.cmml"><mi id="S4.SS2.p3.2.m2.1.1.1.1.3" xref="S4.SS2.p3.2.m2.1.1.1.1.3.cmml">𝐞</mi><mo id="S4.SS2.p3.2.m2.1.1.1.1.2" xref="S4.SS2.p3.2.m2.1.1.1.1.2.cmml">⁢</mo><mrow id="S4.SS2.p3.2.m2.1.1.1.1.1.1" xref="S4.SS2.p3.2.m2.1.1.1.1.1.1.1.cmml"><mo id="S4.SS2.p3.2.m2.1.1.1.1.1.1.2" stretchy="false" xref="S4.SS2.p3.2.m2.1.1.1.1.1.1.1.cmml">(</mo><msubsup id="S4.SS2.p3.2.m2.1.1.1.1.1.1.1" xref="S4.SS2.p3.2.m2.1.1.1.1.1.1.1.cmml"><mi id="S4.SS2.p3.2.m2.1.1.1.1.1.1.1.2.2" xref="S4.SS2.p3.2.m2.1.1.1.1.1.1.1.2.2.cmml">k</mi><mi id="S4.SS2.p3.2.m2.1.1.1.1.1.1.1.2.3" xref="S4.SS2.p3.2.m2.1.1.1.1.1.1.1.2.3.cmml">d</mi><mi id="S4.SS2.p3.2.m2.1.1.1.1.1.1.1.3" xref="S4.SS2.p3.2.m2.1.1.1.1.1.1.1.3.cmml">i</mi></msubsup><mo id="S4.SS2.p3.2.m2.1.1.1.1.1.1.3" stretchy="false" xref="S4.SS2.p3.2.m2.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.2.m2.1b"><apply id="S4.SS2.p3.2.m2.1.1.cmml" xref="S4.SS2.p3.2.m2.1.1"><eq id="S4.SS2.p3.2.m2.1.1.2.cmml" xref="S4.SS2.p3.2.m2.1.1.2"></eq><apply id="S4.SS2.p3.2.m2.1.1.3.cmml" xref="S4.SS2.p3.2.m2.1.1.3"><csymbol cd="ambiguous" id="S4.SS2.p3.2.m2.1.1.3.1.cmml" xref="S4.SS2.p3.2.m2.1.1.3">superscript</csymbol><apply id="S4.SS2.p3.2.m2.1.1.3.2.cmml" xref="S4.SS2.p3.2.m2.1.1.3.2"><ci id="S4.SS2.p3.2.m2.1.1.3.2.1.cmml" xref="S4.SS2.p3.2.m2.1.1.3.2.1">^</ci><ci id="S4.SS2.p3.2.m2.1.1.3.2.2.cmml" xref="S4.SS2.p3.2.m2.1.1.3.2.2">𝐳</ci></apply><ci id="S4.SS2.p3.2.m2.1.1.3.3.cmml" xref="S4.SS2.p3.2.m2.1.1.3.3">𝑖</ci></apply><apply id="S4.SS2.p3.2.m2.1.1.1.cmml" xref="S4.SS2.p3.2.m2.1.1.1"><apply id="S4.SS2.p3.2.m2.1.1.1.2.cmml" xref="S4.SS2.p3.2.m2.1.1.1.2"><csymbol cd="ambiguous" id="S4.SS2.p3.2.m2.1.1.1.2.1.cmml" xref="S4.SS2.p3.2.m2.1.1.1.2">superscript</csymbol><apply id="S4.SS2.p3.2.m2.1.1.1.2.2.cmml" xref="S4.SS2.p3.2.m2.1.1.1.2"><csymbol cd="ambiguous" id="S4.SS2.p3.2.m2.1.1.1.2.2.1.cmml" xref="S4.SS2.p3.2.m2.1.1.1.2">subscript</csymbol><sum id="S4.SS2.p3.2.m2.1.1.1.2.2.2.cmml" xref="S4.SS2.p3.2.m2.1.1.1.2.2.2"></sum><apply id="S4.SS2.p3.2.m2.1.1.1.2.2.3.cmml" xref="S4.SS2.p3.2.m2.1.1.1.2.2.3"><eq id="S4.SS2.p3.2.m2.1.1.1.2.2.3.1.cmml" xref="S4.SS2.p3.2.m2.1.1.1.2.2.3.1"></eq><ci id="S4.SS2.p3.2.m2.1.1.1.2.2.3.2.cmml" xref="S4.SS2.p3.2.m2.1.1.1.2.2.3.2">𝑑</ci><cn id="S4.SS2.p3.2.m2.1.1.1.2.2.3.3.cmml" type="integer" xref="S4.SS2.p3.2.m2.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="S4.SS2.p3.2.m2.1.1.1.2.3.cmml" xref="S4.SS2.p3.2.m2.1.1.1.2.3">𝐷</ci></apply><apply id="S4.SS2.p3.2.m2.1.1.1.1.cmml" xref="S4.SS2.p3.2.m2.1.1.1.1"><times id="S4.SS2.p3.2.m2.1.1.1.1.2.cmml" xref="S4.SS2.p3.2.m2.1.1.1.1.2"></times><ci id="S4.SS2.p3.2.m2.1.1.1.1.3.cmml" xref="S4.SS2.p3.2.m2.1.1.1.1.3">𝐞</ci><apply id="S4.SS2.p3.2.m2.1.1.1.1.1.1.1.cmml" xref="S4.SS2.p3.2.m2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p3.2.m2.1.1.1.1.1.1.1.1.cmml" xref="S4.SS2.p3.2.m2.1.1.1.1.1.1">superscript</csymbol><apply id="S4.SS2.p3.2.m2.1.1.1.1.1.1.1.2.cmml" xref="S4.SS2.p3.2.m2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p3.2.m2.1.1.1.1.1.1.1.2.1.cmml" xref="S4.SS2.p3.2.m2.1.1.1.1.1.1">subscript</csymbol><ci id="S4.SS2.p3.2.m2.1.1.1.1.1.1.1.2.2.cmml" xref="S4.SS2.p3.2.m2.1.1.1.1.1.1.1.2.2">𝑘</ci><ci id="S4.SS2.p3.2.m2.1.1.1.1.1.1.1.2.3.cmml" xref="S4.SS2.p3.2.m2.1.1.1.1.1.1.1.2.3">𝑑</ci></apply><ci id="S4.SS2.p3.2.m2.1.1.1.1.1.1.1.3.cmml" xref="S4.SS2.p3.2.m2.1.1.1.1.1.1.1.3">𝑖</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.2.m2.1c">\hat{\mathbf{z}}^{i}=\sum_{d=1}^{D}\mathbf{e}(k_{d}^{i})</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p3.2.m2.1d">over^ start_ARG bold_z end_ARG start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT = ∑ start_POSTSUBSCRIPT italic_d = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_D end_POSTSUPERSCRIPT bold_e ( italic_k start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT )</annotation></semantics></math>, where <math alttext="\mathbf{e}" class="ltx_Math" display="inline" id="S4.SS2.p3.3.m3.1"><semantics id="S4.SS2.p3.3.m3.1a"><mi id="S4.SS2.p3.3.m3.1.1" xref="S4.SS2.p3.3.m3.1.1.cmml">𝐞</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.3.m3.1b"><ci id="S4.SS2.p3.3.m3.1.1.cmml" xref="S4.SS2.p3.3.m3.1.1">𝐞</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.3.m3.1c">\mathbf{e}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p3.3.m3.1d">bold_e</annotation></semantics></math> is codebook embedding, back into motion sequences using 1D convolution. Text decoding follows standard language model decoding procedures.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Training</h3>
<figure class="ltx_figure" id="S4.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="370" id="S4.F3.g1" src="x3.png" width="789"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Method Overview. Stage 1 involves training a motion tokenizer that encodes and decodes interactive motion data. In Stage 2, we pre-train the model by integrating motion and text data, allowing it to learn the alignment between text and motion. Stage 3 focuses on Instruction Tuning, fine-tuning the model to follow instructions and improve its responsiveness to conversational cues.</figcaption>
</figure>
<section class="ltx_paragraph" id="S4.SS3.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Motion Tokenizer</h5>
<div class="ltx_para ltx_noindent" id="S4.SS3.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS3.SSS0.Px1.p1.1">The first stage is to train a motion tokenizer composed of an encoder, decoder, and quantizer. We followed the original objective functions from <cite class="ltx_cite ltx_citemacro_cite">Lee et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib21" title="">2022</a>)</cite> to train this model, minimizing the reconstruction loss, the codebook loss to align the encoder’s outputs with the codebook, and the commitment loss to ensure encoder consistency.
Once the encoder and decoder are optimized, we maintain this model freezed during the rest of the training stage.
</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS3.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">Pre-training Strategy</h5>
<div class="ltx_para ltx_noindent" id="S4.SS3.SSS0.Px2.p1">
<p class="ltx_p" id="S4.SS3.SSS0.Px2.p1.6">In the pre-training stage, we train a pre-trained large language model to align motion representations with textual representations. We design tasks including motion-to-text, text-to-motion, motion prediction, and reaction generation to train the model, leveraging paired datasets like Inter-X <cite class="ltx_cite ltx_citemacro_citep">(Xu et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib40" title="">2024a</a>)</cite> and InterHuman <cite class="ltx_cite ltx_citemacro_citep">(Liang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib22" title="">2024</a>)</cite>. Using the template from <cite class="ltx_cite ltx_citemacro_cite">Jiang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib18" title="">2023</a>)</cite>, we create input sequences <math alttext="y" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px2.p1.1.m1.1"><semantics id="S4.SS3.SSS0.Px2.p1.1.m1.1a"><mi id="S4.SS3.SSS0.Px2.p1.1.m1.1.1" xref="S4.SS3.SSS0.Px2.p1.1.m1.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px2.p1.1.m1.1b"><ci id="S4.SS3.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S4.SS3.SSS0.Px2.p1.1.m1.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px2.p1.1.m1.1c">y</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.SSS0.Px2.p1.1.m1.1d">italic_y</annotation></semantics></math> from motion sequences <math alttext="X_{m}" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px2.p1.2.m2.1"><semantics id="S4.SS3.SSS0.Px2.p1.2.m2.1a"><msub id="S4.SS3.SSS0.Px2.p1.2.m2.1.1" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1.cmml"><mi id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.2" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1.2.cmml">X</mi><mi id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.3" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px2.p1.2.m2.1b"><apply id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.1.cmml" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1">subscript</csymbol><ci id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.2.cmml" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1.2">𝑋</ci><ci id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.3.cmml" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px2.p1.2.m2.1c">X_{m}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.SSS0.Px2.p1.2.m2.1d">italic_X start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT</annotation></semantics></math> and the corresponding motion caption.
Since both motion tokens and text tokens are discrete, we train our model with the general language modeling next-token prediction objective: <math alttext="\mathcal{L}=-\log\sum^{T}p_{\theta}(y_{i}|y_{&lt;i})" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px2.p1.3.m3.1"><semantics id="S4.SS3.SSS0.Px2.p1.3.m3.1a"><mrow id="S4.SS3.SSS0.Px2.p1.3.m3.1.1" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.3" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.3.cmml">ℒ</mi><mo id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.2" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.2.cmml">=</mo><mrow id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.cmml"><mo id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1a" rspace="0.167em" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.cmml">−</mo><mrow id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.cmml"><mi id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.3" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.3.cmml">log</mi><mo id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.2" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.2.cmml">⁢</mo><mrow id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.cmml"><msup id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.2" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.2.cmml"><mo id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.2.2" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.2.2.cmml">∑</mo><mi id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.2.3" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.2.3.cmml">T</mi></msup><mrow id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.cmml"><msub id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.3" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.3.cmml"><mi id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.3.2" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.3.2.cmml">p</mi><mi id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.3.3" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.3.3.cmml">θ</mi></msub><mo id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.2" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.1.1" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.1.1.1.cmml"><mo id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.1.1.1" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.1.1.1.cmml"><msub id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.1.1.1.2" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.1.1.1.2.2" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.1.1.1.2.2.cmml">y</mi><mi id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.1.1.1.2.3" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.1.1.1.2.3.cmml">i</mi></msub><mo fence="false" id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.1.1.1.1" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.1.1.1.1.cmml">|</mo><msub id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.1.1.1.3" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.1.1.1.3.2" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.1.1.1.3.2.cmml">y</mi><mrow id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.1.1.1.3.3" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.1.1.1.3.3.cmml"><mi id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.1.1.1.3.3.2" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.1.1.1.3.3.2.cmml"></mi><mo id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.1.1.1.3.3.1" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.1.1.1.3.3.1.cmml">&lt;</mo><mi id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.1.1.1.3.3.3" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.1.1.1.3.3.3.cmml">i</mi></mrow></msub></mrow><mo id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px2.p1.3.m3.1b"><apply id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.cmml" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1"><eq id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.2.cmml" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.2"></eq><ci id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.3.cmml" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.3">ℒ</ci><apply id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.cmml" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1"><minus id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.2.cmml" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1"></minus><apply id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.cmml" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1"><times id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.2.cmml" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.2"></times><log id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.3.cmml" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.3"></log><apply id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.cmml" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1"><apply id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.2.cmml" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.2.1.cmml" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.2">superscript</csymbol><sum id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.2.2.cmml" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.2.2"></sum><ci id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.2.3.cmml" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.2.3">𝑇</ci></apply><apply id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.cmml" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1"><times id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.2.cmml" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.2"></times><apply id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.3.cmml" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.3.1.cmml" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.3">subscript</csymbol><ci id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.3.2.cmml" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.3.2">𝑝</ci><ci id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.3.3.cmml" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.3.3">𝜃</ci></apply><apply id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.1.1.1.cmml" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.1.1.1.1">conditional</csymbol><apply id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.1.1.1.2.2">𝑦</ci><ci id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.1.1.1.2.3">𝑖</ci></apply><apply id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.1.1.1.3.cmml" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.1.1.1.3.2">𝑦</ci><apply id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.1.1.1.3.3"><lt id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.1.1.1.3.3.1.cmml" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.1.1.1.3.3.1"></lt><csymbol cd="latexml" id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.1.1.1.3.3.2.cmml" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.1.1.1.3.3.2">absent</csymbol><ci id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.1.1.1.3.3.3.cmml" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.1.1.1.3.3.3">𝑖</ci></apply></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px2.p1.3.m3.1c">\mathcal{L}=-\log\sum^{T}p_{\theta}(y_{i}|y_{&lt;i})</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.SSS0.Px2.p1.3.m3.1d">caligraphic_L = - roman_log ∑ start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT italic_p start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | italic_y start_POSTSUBSCRIPT &lt; italic_i end_POSTSUBSCRIPT )</annotation></semantics></math>, where <math alttext="T" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px2.p1.4.m4.1"><semantics id="S4.SS3.SSS0.Px2.p1.4.m4.1a"><mi id="S4.SS3.SSS0.Px2.p1.4.m4.1.1" xref="S4.SS3.SSS0.Px2.p1.4.m4.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px2.p1.4.m4.1b"><ci id="S4.SS3.SSS0.Px2.p1.4.m4.1.1.cmml" xref="S4.SS3.SSS0.Px2.p1.4.m4.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px2.p1.4.m4.1c">T</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.SSS0.Px2.p1.4.m4.1d">italic_T</annotation></semantics></math> is the length of the multi-modal sequence and <math alttext="i" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px2.p1.5.m5.1"><semantics id="S4.SS3.SSS0.Px2.p1.5.m5.1a"><mi id="S4.SS3.SSS0.Px2.p1.5.m5.1.1" xref="S4.SS3.SSS0.Px2.p1.5.m5.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px2.p1.5.m5.1b"><ci id="S4.SS3.SSS0.Px2.p1.5.m5.1.1.cmml" xref="S4.SS3.SSS0.Px2.p1.5.m5.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px2.p1.5.m5.1c">i</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.SSS0.Px2.p1.5.m5.1d">italic_i</annotation></semantics></math> only counts when the text token appears at position <math alttext="i" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px2.p1.6.m6.1"><semantics id="S4.SS3.SSS0.Px2.p1.6.m6.1a"><mi id="S4.SS3.SSS0.Px2.p1.6.m6.1.1" xref="S4.SS3.SSS0.Px2.p1.6.m6.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px2.p1.6.m6.1b"><ci id="S4.SS3.SSS0.Px2.p1.6.m6.1.1.cmml" xref="S4.SS3.SSS0.Px2.p1.6.m6.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px2.p1.6.m6.1c">i</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.SSS0.Px2.p1.6.m6.1d">italic_i</annotation></semantics></math>.
To improve training efficiency, we train the LLM using a low-rank adaptor (LoRA) <cite class="ltx_cite ltx_citemacro_citep">(Hu et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib17" title="">2022</a>)</cite>, similar to <cite class="ltx_cite ltx_citemacro_cite">Ge et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib11" title="">2024</a>)</cite>. We then merged the LoRA parameters to the LLM backbone for further training. Furthermore, due to a limited number of interactive motion data, we also leverage larger single motion-text datasets from Motion-X <cite class="ltx_cite ltx_citemacro_citep">(Lin et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib24" title="">2024</a>)</cite>. This offers prior knowledge of how individual motions are described in language, enhancing the model’s ability to align motions with corresponding textual descriptions.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS3.SSS0.Px3">
<h5 class="ltx_title ltx_title_paragraph">Instruction-tunning with <span class="ltx_text ltx_markedasmath ltx_font_smallcaps" id="S4.SS3.SSS0.Px3.3.2">Inter</span><span class="ltx_text ltx_font_smallcaps" id="S4.SS3.SSS0.Px3.2.1">-<math alttext="\text{MT}^{2}" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px3.2.1.m1.1"><semantics id="S4.SS3.SSS0.Px3.2.1.m1.1b"><msup id="S4.SS3.SSS0.Px3.2.1.m1.1.1" xref="S4.SS3.SSS0.Px3.2.1.m1.1.1.cmml"><mtext class="ltx_font_smallcaps" id="S4.SS3.SSS0.Px3.2.1.m1.1.1.2" xref="S4.SS3.SSS0.Px3.2.1.m1.1.1.2a.cmml">MT</mtext><mn id="S4.SS3.SSS0.Px3.2.1.m1.1.1.3" xref="S4.SS3.SSS0.Px3.2.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px3.2.1.m1.1c"><apply id="S4.SS3.SSS0.Px3.2.1.m1.1.1.cmml" xref="S4.SS3.SSS0.Px3.2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS3.SSS0.Px3.2.1.m1.1.1.1.cmml" xref="S4.SS3.SSS0.Px3.2.1.m1.1.1">superscript</csymbol><ci id="S4.SS3.SSS0.Px3.2.1.m1.1.1.2a.cmml" xref="S4.SS3.SSS0.Px3.2.1.m1.1.1.2"><mtext class="ltx_font_smallcaps" id="S4.SS3.SSS0.Px3.2.1.m1.1.1.2.cmml" xref="S4.SS3.SSS0.Px3.2.1.m1.1.1.2">MT</mtext></ci><cn id="S4.SS3.SSS0.Px3.2.1.m1.1.1.3.cmml" type="integer" xref="S4.SS3.SSS0.Px3.2.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px3.2.1.m1.1d">\text{MT}^{2}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.SSS0.Px3.2.1.m1.1e">MT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math></span> Data</h5>
<div class="ltx_para ltx_noindent" id="S4.SS3.SSS0.Px3.p1">
<p class="ltx_p" id="S4.SS3.SSS0.Px3.p1.4">In this stage, we aim to enhance the model’s ability to follow a wide range of instructions presented in a conversational format. We utilize <span class="ltx_text ltx_markedasmath ltx_font_smallcaps" id="S4.SS3.SSS0.Px3.p1.4.2">Inter</span><span class="ltx_text ltx_font_smallcaps" id="S4.SS3.SSS0.Px3.p1.2.1">-<math alttext="\text{MT}^{2}" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px3.p1.2.1.m1.1"><semantics id="S4.SS3.SSS0.Px3.p1.2.1.m1.1a"><msup id="S4.SS3.SSS0.Px3.p1.2.1.m1.1.1" xref="S4.SS3.SSS0.Px3.p1.2.1.m1.1.1.cmml"><mtext class="ltx_font_smallcaps" id="S4.SS3.SSS0.Px3.p1.2.1.m1.1.1.2" xref="S4.SS3.SSS0.Px3.p1.2.1.m1.1.1.2a.cmml">MT</mtext><mn id="S4.SS3.SSS0.Px3.p1.2.1.m1.1.1.3" xref="S4.SS3.SSS0.Px3.p1.2.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px3.p1.2.1.m1.1b"><apply id="S4.SS3.SSS0.Px3.p1.2.1.m1.1.1.cmml" xref="S4.SS3.SSS0.Px3.p1.2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS3.SSS0.Px3.p1.2.1.m1.1.1.1.cmml" xref="S4.SS3.SSS0.Px3.p1.2.1.m1.1.1">superscript</csymbol><ci id="S4.SS3.SSS0.Px3.p1.2.1.m1.1.1.2a.cmml" xref="S4.SS3.SSS0.Px3.p1.2.1.m1.1.1.2"><mtext class="ltx_font_smallcaps" id="S4.SS3.SSS0.Px3.p1.2.1.m1.1.1.2.cmml" xref="S4.SS3.SSS0.Px3.p1.2.1.m1.1.1.2">MT</mtext></ci><cn id="S4.SS3.SSS0.Px3.p1.2.1.m1.1.1.3.cmml" type="integer" xref="S4.SS3.SSS0.Px3.p1.2.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px3.p1.2.1.m1.1c">\text{MT}^{2}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.SSS0.Px3.p1.2.1.m1.1d">MT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math></span> dataset combined with single-turn data from prior interactive motion datasets <cite class="ltx_cite ltx_citemacro_citep">(Xu et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib40" title="">2024a</a>; Liang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib22" title="">2024</a>)</cite>. We follow instruction templates from MotionGPT <cite class="ltx_cite ltx_citemacro_citep">(Jiang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib18" title="">2023</a>)</cite>, to format the input and output for single-turn data.
The multi-modal sequence <math alttext="y" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px3.p1.3.m2.1"><semantics id="S4.SS3.SSS0.Px3.p1.3.m2.1a"><mi id="S4.SS3.SSS0.Px3.p1.3.m2.1.1" xref="S4.SS3.SSS0.Px3.p1.3.m2.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px3.p1.3.m2.1b"><ci id="S4.SS3.SSS0.Px3.p1.3.m2.1.1.cmml" xref="S4.SS3.SSS0.Px3.p1.3.m2.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px3.p1.3.m2.1c">y</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.SSS0.Px3.p1.3.m2.1d">italic_y</annotation></semantics></math> consists of user instructions and corresponding responses, formatted as <math alttext="y=(X^{1}_{u},X^{1}_{a},X^{2}_{u},X^{2}_{a},\cdots)" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px3.p1.4.m3.5"><semantics id="S4.SS3.SSS0.Px3.p1.4.m3.5a"><mrow id="S4.SS3.SSS0.Px3.p1.4.m3.5.5" xref="S4.SS3.SSS0.Px3.p1.4.m3.5.5.cmml"><mi id="S4.SS3.SSS0.Px3.p1.4.m3.5.5.6" xref="S4.SS3.SSS0.Px3.p1.4.m3.5.5.6.cmml">y</mi><mo id="S4.SS3.SSS0.Px3.p1.4.m3.5.5.5" xref="S4.SS3.SSS0.Px3.p1.4.m3.5.5.5.cmml">=</mo><mrow id="S4.SS3.SSS0.Px3.p1.4.m3.5.5.4.4" xref="S4.SS3.SSS0.Px3.p1.4.m3.5.5.4.5.cmml"><mo id="S4.SS3.SSS0.Px3.p1.4.m3.5.5.4.4.5" stretchy="false" xref="S4.SS3.SSS0.Px3.p1.4.m3.5.5.4.5.cmml">(</mo><msubsup id="S4.SS3.SSS0.Px3.p1.4.m3.2.2.1.1.1" xref="S4.SS3.SSS0.Px3.p1.4.m3.2.2.1.1.1.cmml"><mi id="S4.SS3.SSS0.Px3.p1.4.m3.2.2.1.1.1.2.2" xref="S4.SS3.SSS0.Px3.p1.4.m3.2.2.1.1.1.2.2.cmml">X</mi><mi id="S4.SS3.SSS0.Px3.p1.4.m3.2.2.1.1.1.3" xref="S4.SS3.SSS0.Px3.p1.4.m3.2.2.1.1.1.3.cmml">u</mi><mn id="S4.SS3.SSS0.Px3.p1.4.m3.2.2.1.1.1.2.3" xref="S4.SS3.SSS0.Px3.p1.4.m3.2.2.1.1.1.2.3.cmml">1</mn></msubsup><mo id="S4.SS3.SSS0.Px3.p1.4.m3.5.5.4.4.6" xref="S4.SS3.SSS0.Px3.p1.4.m3.5.5.4.5.cmml">,</mo><msubsup id="S4.SS3.SSS0.Px3.p1.4.m3.3.3.2.2.2" xref="S4.SS3.SSS0.Px3.p1.4.m3.3.3.2.2.2.cmml"><mi id="S4.SS3.SSS0.Px3.p1.4.m3.3.3.2.2.2.2.2" xref="S4.SS3.SSS0.Px3.p1.4.m3.3.3.2.2.2.2.2.cmml">X</mi><mi id="S4.SS3.SSS0.Px3.p1.4.m3.3.3.2.2.2.3" xref="S4.SS3.SSS0.Px3.p1.4.m3.3.3.2.2.2.3.cmml">a</mi><mn id="S4.SS3.SSS0.Px3.p1.4.m3.3.3.2.2.2.2.3" xref="S4.SS3.SSS0.Px3.p1.4.m3.3.3.2.2.2.2.3.cmml">1</mn></msubsup><mo id="S4.SS3.SSS0.Px3.p1.4.m3.5.5.4.4.7" xref="S4.SS3.SSS0.Px3.p1.4.m3.5.5.4.5.cmml">,</mo><msubsup id="S4.SS3.SSS0.Px3.p1.4.m3.4.4.3.3.3" xref="S4.SS3.SSS0.Px3.p1.4.m3.4.4.3.3.3.cmml"><mi id="S4.SS3.SSS0.Px3.p1.4.m3.4.4.3.3.3.2.2" xref="S4.SS3.SSS0.Px3.p1.4.m3.4.4.3.3.3.2.2.cmml">X</mi><mi id="S4.SS3.SSS0.Px3.p1.4.m3.4.4.3.3.3.3" xref="S4.SS3.SSS0.Px3.p1.4.m3.4.4.3.3.3.3.cmml">u</mi><mn id="S4.SS3.SSS0.Px3.p1.4.m3.4.4.3.3.3.2.3" xref="S4.SS3.SSS0.Px3.p1.4.m3.4.4.3.3.3.2.3.cmml">2</mn></msubsup><mo id="S4.SS3.SSS0.Px3.p1.4.m3.5.5.4.4.8" xref="S4.SS3.SSS0.Px3.p1.4.m3.5.5.4.5.cmml">,</mo><msubsup id="S4.SS3.SSS0.Px3.p1.4.m3.5.5.4.4.4" xref="S4.SS3.SSS0.Px3.p1.4.m3.5.5.4.4.4.cmml"><mi id="S4.SS3.SSS0.Px3.p1.4.m3.5.5.4.4.4.2.2" xref="S4.SS3.SSS0.Px3.p1.4.m3.5.5.4.4.4.2.2.cmml">X</mi><mi id="S4.SS3.SSS0.Px3.p1.4.m3.5.5.4.4.4.3" xref="S4.SS3.SSS0.Px3.p1.4.m3.5.5.4.4.4.3.cmml">a</mi><mn id="S4.SS3.SSS0.Px3.p1.4.m3.5.5.4.4.4.2.3" xref="S4.SS3.SSS0.Px3.p1.4.m3.5.5.4.4.4.2.3.cmml">2</mn></msubsup><mo id="S4.SS3.SSS0.Px3.p1.4.m3.5.5.4.4.9" xref="S4.SS3.SSS0.Px3.p1.4.m3.5.5.4.5.cmml">,</mo><mi id="S4.SS3.SSS0.Px3.p1.4.m3.1.1" mathvariant="normal" xref="S4.SS3.SSS0.Px3.p1.4.m3.1.1.cmml">⋯</mi><mo id="S4.SS3.SSS0.Px3.p1.4.m3.5.5.4.4.10" stretchy="false" xref="S4.SS3.SSS0.Px3.p1.4.m3.5.5.4.5.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px3.p1.4.m3.5b"><apply id="S4.SS3.SSS0.Px3.p1.4.m3.5.5.cmml" xref="S4.SS3.SSS0.Px3.p1.4.m3.5.5"><eq id="S4.SS3.SSS0.Px3.p1.4.m3.5.5.5.cmml" xref="S4.SS3.SSS0.Px3.p1.4.m3.5.5.5"></eq><ci id="S4.SS3.SSS0.Px3.p1.4.m3.5.5.6.cmml" xref="S4.SS3.SSS0.Px3.p1.4.m3.5.5.6">𝑦</ci><vector id="S4.SS3.SSS0.Px3.p1.4.m3.5.5.4.5.cmml" xref="S4.SS3.SSS0.Px3.p1.4.m3.5.5.4.4"><apply id="S4.SS3.SSS0.Px3.p1.4.m3.2.2.1.1.1.cmml" xref="S4.SS3.SSS0.Px3.p1.4.m3.2.2.1.1.1"><csymbol cd="ambiguous" id="S4.SS3.SSS0.Px3.p1.4.m3.2.2.1.1.1.1.cmml" xref="S4.SS3.SSS0.Px3.p1.4.m3.2.2.1.1.1">subscript</csymbol><apply id="S4.SS3.SSS0.Px3.p1.4.m3.2.2.1.1.1.2.cmml" xref="S4.SS3.SSS0.Px3.p1.4.m3.2.2.1.1.1"><csymbol cd="ambiguous" id="S4.SS3.SSS0.Px3.p1.4.m3.2.2.1.1.1.2.1.cmml" xref="S4.SS3.SSS0.Px3.p1.4.m3.2.2.1.1.1">superscript</csymbol><ci id="S4.SS3.SSS0.Px3.p1.4.m3.2.2.1.1.1.2.2.cmml" xref="S4.SS3.SSS0.Px3.p1.4.m3.2.2.1.1.1.2.2">𝑋</ci><cn id="S4.SS3.SSS0.Px3.p1.4.m3.2.2.1.1.1.2.3.cmml" type="integer" xref="S4.SS3.SSS0.Px3.p1.4.m3.2.2.1.1.1.2.3">1</cn></apply><ci id="S4.SS3.SSS0.Px3.p1.4.m3.2.2.1.1.1.3.cmml" xref="S4.SS3.SSS0.Px3.p1.4.m3.2.2.1.1.1.3">𝑢</ci></apply><apply id="S4.SS3.SSS0.Px3.p1.4.m3.3.3.2.2.2.cmml" xref="S4.SS3.SSS0.Px3.p1.4.m3.3.3.2.2.2"><csymbol cd="ambiguous" id="S4.SS3.SSS0.Px3.p1.4.m3.3.3.2.2.2.1.cmml" xref="S4.SS3.SSS0.Px3.p1.4.m3.3.3.2.2.2">subscript</csymbol><apply id="S4.SS3.SSS0.Px3.p1.4.m3.3.3.2.2.2.2.cmml" xref="S4.SS3.SSS0.Px3.p1.4.m3.3.3.2.2.2"><csymbol cd="ambiguous" id="S4.SS3.SSS0.Px3.p1.4.m3.3.3.2.2.2.2.1.cmml" xref="S4.SS3.SSS0.Px3.p1.4.m3.3.3.2.2.2">superscript</csymbol><ci id="S4.SS3.SSS0.Px3.p1.4.m3.3.3.2.2.2.2.2.cmml" xref="S4.SS3.SSS0.Px3.p1.4.m3.3.3.2.2.2.2.2">𝑋</ci><cn id="S4.SS3.SSS0.Px3.p1.4.m3.3.3.2.2.2.2.3.cmml" type="integer" xref="S4.SS3.SSS0.Px3.p1.4.m3.3.3.2.2.2.2.3">1</cn></apply><ci id="S4.SS3.SSS0.Px3.p1.4.m3.3.3.2.2.2.3.cmml" xref="S4.SS3.SSS0.Px3.p1.4.m3.3.3.2.2.2.3">𝑎</ci></apply><apply id="S4.SS3.SSS0.Px3.p1.4.m3.4.4.3.3.3.cmml" xref="S4.SS3.SSS0.Px3.p1.4.m3.4.4.3.3.3"><csymbol cd="ambiguous" id="S4.SS3.SSS0.Px3.p1.4.m3.4.4.3.3.3.1.cmml" xref="S4.SS3.SSS0.Px3.p1.4.m3.4.4.3.3.3">subscript</csymbol><apply id="S4.SS3.SSS0.Px3.p1.4.m3.4.4.3.3.3.2.cmml" xref="S4.SS3.SSS0.Px3.p1.4.m3.4.4.3.3.3"><csymbol cd="ambiguous" id="S4.SS3.SSS0.Px3.p1.4.m3.4.4.3.3.3.2.1.cmml" xref="S4.SS3.SSS0.Px3.p1.4.m3.4.4.3.3.3">superscript</csymbol><ci id="S4.SS3.SSS0.Px3.p1.4.m3.4.4.3.3.3.2.2.cmml" xref="S4.SS3.SSS0.Px3.p1.4.m3.4.4.3.3.3.2.2">𝑋</ci><cn id="S4.SS3.SSS0.Px3.p1.4.m3.4.4.3.3.3.2.3.cmml" type="integer" xref="S4.SS3.SSS0.Px3.p1.4.m3.4.4.3.3.3.2.3">2</cn></apply><ci id="S4.SS3.SSS0.Px3.p1.4.m3.4.4.3.3.3.3.cmml" xref="S4.SS3.SSS0.Px3.p1.4.m3.4.4.3.3.3.3">𝑢</ci></apply><apply id="S4.SS3.SSS0.Px3.p1.4.m3.5.5.4.4.4.cmml" xref="S4.SS3.SSS0.Px3.p1.4.m3.5.5.4.4.4"><csymbol cd="ambiguous" id="S4.SS3.SSS0.Px3.p1.4.m3.5.5.4.4.4.1.cmml" xref="S4.SS3.SSS0.Px3.p1.4.m3.5.5.4.4.4">subscript</csymbol><apply id="S4.SS3.SSS0.Px3.p1.4.m3.5.5.4.4.4.2.cmml" xref="S4.SS3.SSS0.Px3.p1.4.m3.5.5.4.4.4"><csymbol cd="ambiguous" id="S4.SS3.SSS0.Px3.p1.4.m3.5.5.4.4.4.2.1.cmml" xref="S4.SS3.SSS0.Px3.p1.4.m3.5.5.4.4.4">superscript</csymbol><ci id="S4.SS3.SSS0.Px3.p1.4.m3.5.5.4.4.4.2.2.cmml" xref="S4.SS3.SSS0.Px3.p1.4.m3.5.5.4.4.4.2.2">𝑋</ci><cn id="S4.SS3.SSS0.Px3.p1.4.m3.5.5.4.4.4.2.3.cmml" type="integer" xref="S4.SS3.SSS0.Px3.p1.4.m3.5.5.4.4.4.2.3">2</cn></apply><ci id="S4.SS3.SSS0.Px3.p1.4.m3.5.5.4.4.4.3.cmml" xref="S4.SS3.SSS0.Px3.p1.4.m3.5.5.4.4.4.3">𝑎</ci></apply><ci id="S4.SS3.SSS0.Px3.p1.4.m3.1.1.cmml" xref="S4.SS3.SSS0.Px3.p1.4.m3.1.1">⋯</ci></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px3.p1.4.m3.5c">y=(X^{1}_{u},X^{1}_{a},X^{2}_{u},X^{2}_{a},\cdots)</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.SSS0.Px3.p1.4.m3.5d">italic_y = ( italic_X start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT , italic_X start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT , italic_X start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT , italic_X start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT , ⋯ )</annotation></semantics></math>. The training objective remains the same as in the pre-training stage, with user instructions omitted in the loss function.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Advanced Downstream Interactive Motion Tasks</h3>
<div class="ltx_para ltx_noindent" id="S4.SS4.p1">
<p class="ltx_p" id="S4.SS4.p1.1">After training, our model can perform complex reasoning and generate interactive motions within multi-turn conversations. To verify this, we introduce two additional tasks requiring advanced capabilities: motion reasoning and editing.
Motion reasoning involves predicting past or future events, or reasoning about current motions, based on prior conversational data.
This task requires the model to understand the context of the conversation, interpret how the given motion fits within that context, and adjust its reasoning accordingly.
In the motion editing task, we focus on altering a person’s persona or shifting scenarios, such as emotions or relationship dynamics. This adds complexity, as changes to one person’s behavior affect the other’s motion. The model must edit the target motion while maintaining contextual coherence, requiring a deep understanding of social dynamics.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Experiments</h2>
<div class="ltx_para ltx_noindent" id="S5.p1">
<p class="ltx_p" id="S5.p1.2">In our experiments, we evaluated <span class="ltx_text ltx_font_smallcaps" id="S5.p1.2.2">VIM</span>’s ability to generate detailed motion-based chat responses, requiring complex reasoning about interactive motions, alongside traditional motion-related tasks.
We focused on two main questions: first, whether the model can reason effectively about interactive motions, such as refining motions in editing tasks or generating contextually accurate narratives in motion reasoning. Second, we evaluated whether the training with <span class="ltx_text ltx_markedasmath ltx_font_smallcaps" id="S5.p1.2.3">Inter</span><span class="ltx_text ltx_font_smallcaps" id="S5.p1.2.1">-<math alttext="\text{MT}^{2}" class="ltx_Math" display="inline" id="S5.p1.2.1.m1.1"><semantics id="S5.p1.2.1.m1.1a"><msup id="S5.p1.2.1.m1.1.1" xref="S5.p1.2.1.m1.1.1.cmml"><mtext class="ltx_font_smallcaps" id="S5.p1.2.1.m1.1.1.2" xref="S5.p1.2.1.m1.1.1.2a.cmml">MT</mtext><mn id="S5.p1.2.1.m1.1.1.3" xref="S5.p1.2.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S5.p1.2.1.m1.1b"><apply id="S5.p1.2.1.m1.1.1.cmml" xref="S5.p1.2.1.m1.1.1"><csymbol cd="ambiguous" id="S5.p1.2.1.m1.1.1.1.cmml" xref="S5.p1.2.1.m1.1.1">superscript</csymbol><ci id="S5.p1.2.1.m1.1.1.2a.cmml" xref="S5.p1.2.1.m1.1.1.2"><mtext class="ltx_font_smallcaps" id="S5.p1.2.1.m1.1.1.2.cmml" xref="S5.p1.2.1.m1.1.1.2">MT</mtext></ci><cn id="S5.p1.2.1.m1.1.1.3.cmml" type="integer" xref="S5.p1.2.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.2.1.m1.1c">\text{MT}^{2}</annotation><annotation encoding="application/x-llamapun" id="S5.p1.2.1.m1.1d">MT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math></span> dataset improves the model’s performance in text-to-motion, motion-to-text, and reaction generation tasks.</p>
</div>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Evaluation Tasks and Baselines</h3>
<section class="ltx_paragraph" id="S5.SS1.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Motion Reasoning</h5>
<div class="ltx_para ltx_noindent" id="S5.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="S5.SS1.SSS0.Px1.p1.2">Motion reasoning involves predicting past or future events or interpreting current motions using prior conversational context.
We utilize powerful LLMs, i.e., GPT-4o <cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib28" title="">2024</a>)</cite> to assess the content alignment, naturalness, and logical coherence of the generated textual responses. Content alignment evaluates how accurately the text reflects the given motion data, logical coherence checks the consistency and reasoning accuracy of inferences made about past or future events, and naturalness evaluates the fluency of generated texts, with rating each metric on a 10-point scale.
In addition, we utilized linguistic metrics like Rouge-L (<cite class="ltx_cite ltx_citemacro_cite">Lin (<a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib23" title="">2004</a>)</cite>), METEOR (<cite class="ltx_cite ltx_citemacro_cite">Banerjee &amp; Lavie (<a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib4" title="">2005</a>)</cite>), and MAUVE (<cite class="ltx_cite ltx_citemacro_cite">Pillutla et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib31" title="">2021</a>)</cite>), to quantitatively assess the relevance, accuracy, and naturalness of the generated responses compared with labeled texts in <span class="ltx_text ltx_markedasmath ltx_font_smallcaps" id="S5.SS1.SSS0.Px1.p1.2.2">Inter</span><span class="ltx_text ltx_font_smallcaps" id="S5.SS1.SSS0.Px1.p1.2.1">-<math alttext="\text{MT}^{2}" class="ltx_Math" display="inline" id="S5.SS1.SSS0.Px1.p1.2.1.m1.1"><semantics id="S5.SS1.SSS0.Px1.p1.2.1.m1.1a"><msup id="S5.SS1.SSS0.Px1.p1.2.1.m1.1.1" xref="S5.SS1.SSS0.Px1.p1.2.1.m1.1.1.cmml"><mtext class="ltx_font_smallcaps" id="S5.SS1.SSS0.Px1.p1.2.1.m1.1.1.2" xref="S5.SS1.SSS0.Px1.p1.2.1.m1.1.1.2a.cmml">MT</mtext><mn id="S5.SS1.SSS0.Px1.p1.2.1.m1.1.1.3" xref="S5.SS1.SSS0.Px1.p1.2.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px1.p1.2.1.m1.1b"><apply id="S5.SS1.SSS0.Px1.p1.2.1.m1.1.1.cmml" xref="S5.SS1.SSS0.Px1.p1.2.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS1.SSS0.Px1.p1.2.1.m1.1.1.1.cmml" xref="S5.SS1.SSS0.Px1.p1.2.1.m1.1.1">superscript</csymbol><ci id="S5.SS1.SSS0.Px1.p1.2.1.m1.1.1.2a.cmml" xref="S5.SS1.SSS0.Px1.p1.2.1.m1.1.1.2"><mtext class="ltx_font_smallcaps" id="S5.SS1.SSS0.Px1.p1.2.1.m1.1.1.2.cmml" xref="S5.SS1.SSS0.Px1.p1.2.1.m1.1.1.2">MT</mtext></ci><cn id="S5.SS1.SSS0.Px1.p1.2.1.m1.1.1.3.cmml" type="integer" xref="S5.SS1.SSS0.Px1.p1.2.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px1.p1.2.1.m1.1c">\text{MT}^{2}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS0.Px1.p1.2.1.m1.1d">MT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math></span> test dataset.
We present the results on motion reasoning in §<a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#S5.SS2" title="5.2 Motion Reasoning ‣ 5 Experiments ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_tag">5.2</span></a>.</p>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS1.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">Motion Editing</h5>
<div class="ltx_para ltx_noindent" id="S5.SS1.SSS0.Px2.p1">
<p class="ltx_p" id="S5.SS1.SSS0.Px2.p1.2">The goal of motion editing is to modify a reference motion based on user instructions. We conducted within-subject user studies to compare edited motion samples, with participants rating them on three metrics: content similarity, instruction alignment, and motion quality, using a 5-point Likert scale, following <cite class="ltx_cite ltx_citemacro_cite">Goel et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib13" title="">2024</a>)</cite>.
Content similarity evaluates whether the edited motion preserves the original meaning of the source motion, while instruction alignment assesses how accurately the edited motion follows the given command.
The study involved 30 participants, each evaluating five samples from a set of 30 randomly selected test samples.
Participants evaluated four baselines and our method, viewing randomly shuffled motion outputs side by side and providing feedback on all metrics. We also employed data-driven metrics, such as Frechet Inception Distance (FID) and mean per joint position error (MPJPE) in meters, to evaluate the quality of the generated edited motion against the labeled motions in the <span class="ltx_text ltx_markedasmath ltx_font_smallcaps" id="S5.SS1.SSS0.Px2.p1.2.2">Inter</span><span class="ltx_text ltx_font_smallcaps" id="S5.SS1.SSS0.Px2.p1.2.1">-<math alttext="\text{MT}^{2}" class="ltx_Math" display="inline" id="S5.SS1.SSS0.Px2.p1.2.1.m1.1"><semantics id="S5.SS1.SSS0.Px2.p1.2.1.m1.1a"><msup id="S5.SS1.SSS0.Px2.p1.2.1.m1.1.1" xref="S5.SS1.SSS0.Px2.p1.2.1.m1.1.1.cmml"><mtext class="ltx_font_smallcaps" id="S5.SS1.SSS0.Px2.p1.2.1.m1.1.1.2" xref="S5.SS1.SSS0.Px2.p1.2.1.m1.1.1.2a.cmml">MT</mtext><mn id="S5.SS1.SSS0.Px2.p1.2.1.m1.1.1.3" xref="S5.SS1.SSS0.Px2.p1.2.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px2.p1.2.1.m1.1b"><apply id="S5.SS1.SSS0.Px2.p1.2.1.m1.1.1.cmml" xref="S5.SS1.SSS0.Px2.p1.2.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS1.SSS0.Px2.p1.2.1.m1.1.1.1.cmml" xref="S5.SS1.SSS0.Px2.p1.2.1.m1.1.1">superscript</csymbol><ci id="S5.SS1.SSS0.Px2.p1.2.1.m1.1.1.2a.cmml" xref="S5.SS1.SSS0.Px2.p1.2.1.m1.1.1.2"><mtext class="ltx_font_smallcaps" id="S5.SS1.SSS0.Px2.p1.2.1.m1.1.1.2.cmml" xref="S5.SS1.SSS0.Px2.p1.2.1.m1.1.1.2">MT</mtext></ci><cn id="S5.SS1.SSS0.Px2.p1.2.1.m1.1.1.3.cmml" type="integer" xref="S5.SS1.SSS0.Px2.p1.2.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px2.p1.2.1.m1.1c">\text{MT}^{2}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS0.Px2.p1.2.1.m1.1d">MT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math></span> test set, following <cite class="ltx_cite ltx_citemacro_cite">Goel et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib13" title="">2024</a>)</cite>.
The results on motion editing is shown in §<a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#S5.SS3" title="5.3 Motion Editing ‣ 5 Experiments ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_tag">5.3</span></a>.</p>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS1.SSS0.Px3">
<h5 class="ltx_title ltx_title_paragraph">Traditional Motion Relevant Tasks</h5>
<div class="ltx_para ltx_noindent" id="S5.SS1.SSS0.Px3.p1">
<p class="ltx_p" id="S5.SS1.SSS0.Px3.p1.1">For standard motion-related tasks, we evaluated the proposed method in three traditional motion-relevant tasks in interactive motions: motion-to-text, text-to-motion, and reaction generation, in the union of the test set in InterHuman <cite class="ltx_cite ltx_citemacro_citep">(Liang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib22" title="">2024</a>)</cite> and Inter-X <cite class="ltx_cite ltx_citemacro_citep">(Xu et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib40" title="">2024a</a>)</cite> datasets. To evaluate the text-motion matching score, we report the retrieval precision based on the feature space of retrieval models (<cite class="ltx_cite ltx_citemacro_cite">Petrovich et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib30" title="">2023</a>)</cite>). This evaluates the accuracy of matching between texts and motions using Top 3 retrieval accuracy with a fixed batch of 32. The quality of motion was measured by Frechet Inception Distance (FID), which measures the distance of feature distribution between motion data and generated motion. In addition, we measure the mean per joint position error (MPJPE) in meters to evaluate the accuracy of the reaction motion.
The results on motion-related tasks are shown in §<a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#S5.SS4" title="5.4 Traditional Motion Related Tasks ‣ 5 Experiments ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_tag">5.4</span></a>.</p>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS1.SSS0.Px4">
<h5 class="ltx_title ltx_title_paragraph">Baselines</h5>
<div class="ltx_para ltx_noindent" id="S5.SS1.SSS0.Px4.p1">
<p class="ltx_p" id="S5.SS1.SSS0.Px4.p1.9">Since our interactive multi-turn scenarios and tasks are novel, there is no exact comparison method. We consider and compare reasonable baselines that handle both motion and texts as input and output. We first employ a <span class="ltx_text ltx_font_italic" id="S5.SS1.SSS0.Px4.p1.9.4">two-stage approach</span> using off-the-shelf methods. For the motion reasoning task, we convert all motions into text descriptions using the state-of-the-art motion-to-text method TM2T <cite class="ltx_cite ltx_citemacro_citep">(Guo et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib14" title="">2022</a>)</cite>. These textual descriptions are then used for text-based reasoning with large language models such as GPT-4o <cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib28" title="">2024</a>)</cite> and LLaMA-3.1-8B <cite class="ltx_cite ltx_citemacro_citep">(Dubey et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib9" title="">2024</a>)</cite>. For the motion editing task, we combine the text converted by TM2T with the editing text command, and generate the edited motion using the off-the-shelf text-to-motion method InterGen <cite class="ltx_cite ltx_citemacro_citep">(Liang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib22" title="">2024</a>)</cite>.
As baselines for the <span class="ltx_text ltx_font_italic" id="S5.SS1.SSS0.Px4.p1.9.5">unified approach</span>, we leverage MotionGPT <cite class="ltx_cite ltx_citemacro_citep">(Jiang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib18" title="">2023</a>)</cite> framework with the following configurations:
(1) <math alttext="\text{MotionGPT}^{*}" class="ltx_Math" display="inline" id="S5.SS1.SSS0.Px4.p1.1.m1.1"><semantics id="S5.SS1.SSS0.Px4.p1.1.m1.1a"><msup id="S5.SS1.SSS0.Px4.p1.1.m1.1.1" xref="S5.SS1.SSS0.Px4.p1.1.m1.1.1.cmml"><mtext id="S5.SS1.SSS0.Px4.p1.1.m1.1.1.2" xref="S5.SS1.SSS0.Px4.p1.1.m1.1.1.2a.cmml">MotionGPT</mtext><mo id="S5.SS1.SSS0.Px4.p1.1.m1.1.1.3" xref="S5.SS1.SSS0.Px4.p1.1.m1.1.1.3.cmml">∗</mo></msup><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px4.p1.1.m1.1b"><apply id="S5.SS1.SSS0.Px4.p1.1.m1.1.1.cmml" xref="S5.SS1.SSS0.Px4.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS1.SSS0.Px4.p1.1.m1.1.1.1.cmml" xref="S5.SS1.SSS0.Px4.p1.1.m1.1.1">superscript</csymbol><ci id="S5.SS1.SSS0.Px4.p1.1.m1.1.1.2a.cmml" xref="S5.SS1.SSS0.Px4.p1.1.m1.1.1.2"><mtext id="S5.SS1.SSS0.Px4.p1.1.m1.1.1.2.cmml" xref="S5.SS1.SSS0.Px4.p1.1.m1.1.1.2">MotionGPT</mtext></ci><times id="S5.SS1.SSS0.Px4.p1.1.m1.1.1.3.cmml" xref="S5.SS1.SSS0.Px4.p1.1.m1.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px4.p1.1.m1.1c">\text{MotionGPT}^{*}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS0.Px4.p1.1.m1.1d">MotionGPT start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT</annotation></semantics></math>: a modified MotionGPT fine-tuned on interaction data with instruction templates; (2) <math alttext="\text{MotionGPT}^{*}_{I}" class="ltx_Math" display="inline" id="S5.SS1.SSS0.Px4.p1.2.m2.1"><semantics id="S5.SS1.SSS0.Px4.p1.2.m2.1a"><msubsup id="S5.SS1.SSS0.Px4.p1.2.m2.1.1" xref="S5.SS1.SSS0.Px4.p1.2.m2.1.1.cmml"><mtext id="S5.SS1.SSS0.Px4.p1.2.m2.1.1.2.2" xref="S5.SS1.SSS0.Px4.p1.2.m2.1.1.2.2a.cmml">MotionGPT</mtext><mi id="S5.SS1.SSS0.Px4.p1.2.m2.1.1.3" xref="S5.SS1.SSS0.Px4.p1.2.m2.1.1.3.cmml">I</mi><mo id="S5.SS1.SSS0.Px4.p1.2.m2.1.1.2.3" xref="S5.SS1.SSS0.Px4.p1.2.m2.1.1.2.3.cmml">∗</mo></msubsup><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px4.p1.2.m2.1b"><apply id="S5.SS1.SSS0.Px4.p1.2.m2.1.1.cmml" xref="S5.SS1.SSS0.Px4.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS1.SSS0.Px4.p1.2.m2.1.1.1.cmml" xref="S5.SS1.SSS0.Px4.p1.2.m2.1.1">subscript</csymbol><apply id="S5.SS1.SSS0.Px4.p1.2.m2.1.1.2.cmml" xref="S5.SS1.SSS0.Px4.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS1.SSS0.Px4.p1.2.m2.1.1.2.1.cmml" xref="S5.SS1.SSS0.Px4.p1.2.m2.1.1">superscript</csymbol><ci id="S5.SS1.SSS0.Px4.p1.2.m2.1.1.2.2a.cmml" xref="S5.SS1.SSS0.Px4.p1.2.m2.1.1.2.2"><mtext id="S5.SS1.SSS0.Px4.p1.2.m2.1.1.2.2.cmml" xref="S5.SS1.SSS0.Px4.p1.2.m2.1.1.2.2">MotionGPT</mtext></ci><times id="S5.SS1.SSS0.Px4.p1.2.m2.1.1.2.3.cmml" xref="S5.SS1.SSS0.Px4.p1.2.m2.1.1.2.3"></times></apply><ci id="S5.SS1.SSS0.Px4.p1.2.m2.1.1.3.cmml" xref="S5.SS1.SSS0.Px4.p1.2.m2.1.1.3">𝐼</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px4.p1.2.m2.1c">\text{MotionGPT}^{*}_{I}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS0.Px4.p1.2.m2.1d">MotionGPT start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_I end_POSTSUBSCRIPT</annotation></semantics></math>:
<math alttext="\text{MotionGPT}^{*}" class="ltx_Math" display="inline" id="S5.SS1.SSS0.Px4.p1.3.m3.1"><semantics id="S5.SS1.SSS0.Px4.p1.3.m3.1a"><msup id="S5.SS1.SSS0.Px4.p1.3.m3.1.1" xref="S5.SS1.SSS0.Px4.p1.3.m3.1.1.cmml"><mtext id="S5.SS1.SSS0.Px4.p1.3.m3.1.1.2" xref="S5.SS1.SSS0.Px4.p1.3.m3.1.1.2a.cmml">MotionGPT</mtext><mo id="S5.SS1.SSS0.Px4.p1.3.m3.1.1.3" xref="S5.SS1.SSS0.Px4.p1.3.m3.1.1.3.cmml">∗</mo></msup><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px4.p1.3.m3.1b"><apply id="S5.SS1.SSS0.Px4.p1.3.m3.1.1.cmml" xref="S5.SS1.SSS0.Px4.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S5.SS1.SSS0.Px4.p1.3.m3.1.1.1.cmml" xref="S5.SS1.SSS0.Px4.p1.3.m3.1.1">superscript</csymbol><ci id="S5.SS1.SSS0.Px4.p1.3.m3.1.1.2a.cmml" xref="S5.SS1.SSS0.Px4.p1.3.m3.1.1.2"><mtext id="S5.SS1.SSS0.Px4.p1.3.m3.1.1.2.cmml" xref="S5.SS1.SSS0.Px4.p1.3.m3.1.1.2">MotionGPT</mtext></ci><times id="S5.SS1.SSS0.Px4.p1.3.m3.1.1.3.cmml" xref="S5.SS1.SSS0.Px4.p1.3.m3.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px4.p1.3.m3.1c">\text{MotionGPT}^{*}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS0.Px4.p1.3.m3.1d">MotionGPT start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT</annotation></semantics></math> enhanced with <span class="ltx_text ltx_markedasmath ltx_font_smallcaps" id="S5.SS1.SSS0.Px4.p1.9.6">Inter</span><span class="ltx_text ltx_font_smallcaps" id="S5.SS1.SSS0.Px4.p1.5.1">-<math alttext="\text{MT}^{2}" class="ltx_Math" display="inline" id="S5.SS1.SSS0.Px4.p1.5.1.m1.1"><semantics id="S5.SS1.SSS0.Px4.p1.5.1.m1.1a"><msup id="S5.SS1.SSS0.Px4.p1.5.1.m1.1.1" xref="S5.SS1.SSS0.Px4.p1.5.1.m1.1.1.cmml"><mtext class="ltx_font_smallcaps" id="S5.SS1.SSS0.Px4.p1.5.1.m1.1.1.2" xref="S5.SS1.SSS0.Px4.p1.5.1.m1.1.1.2a.cmml">MT</mtext><mn id="S5.SS1.SSS0.Px4.p1.5.1.m1.1.1.3" xref="S5.SS1.SSS0.Px4.p1.5.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px4.p1.5.1.m1.1b"><apply id="S5.SS1.SSS0.Px4.p1.5.1.m1.1.1.cmml" xref="S5.SS1.SSS0.Px4.p1.5.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS1.SSS0.Px4.p1.5.1.m1.1.1.1.cmml" xref="S5.SS1.SSS0.Px4.p1.5.1.m1.1.1">superscript</csymbol><ci id="S5.SS1.SSS0.Px4.p1.5.1.m1.1.1.2a.cmml" xref="S5.SS1.SSS0.Px4.p1.5.1.m1.1.1.2"><mtext class="ltx_font_smallcaps" id="S5.SS1.SSS0.Px4.p1.5.1.m1.1.1.2.cmml" xref="S5.SS1.SSS0.Px4.p1.5.1.m1.1.1.2">MT</mtext></ci><cn id="S5.SS1.SSS0.Px4.p1.5.1.m1.1.1.3.cmml" type="integer" xref="S5.SS1.SSS0.Px4.p1.5.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px4.p1.5.1.m1.1c">\text{MT}^{2}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS0.Px4.p1.5.1.m1.1d">MT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math></span> dataset; (3) <span class="ltx_text ltx_font_smallcaps" id="S5.SS1.SSS0.Px4.p1.9.7">VIM</span> w/o <span class="ltx_text ltx_markedasmath ltx_font_smallcaps" id="S5.SS1.SSS0.Px4.p1.9.8">Inter</span><span class="ltx_text ltx_font_smallcaps" id="S5.SS1.SSS0.Px4.p1.7.2">-<math alttext="\text{MT}^{2}" class="ltx_Math" display="inline" id="S5.SS1.SSS0.Px4.p1.7.2.m1.1"><semantics id="S5.SS1.SSS0.Px4.p1.7.2.m1.1a"><msup id="S5.SS1.SSS0.Px4.p1.7.2.m1.1.1" xref="S5.SS1.SSS0.Px4.p1.7.2.m1.1.1.cmml"><mtext class="ltx_font_smallcaps" id="S5.SS1.SSS0.Px4.p1.7.2.m1.1.1.2" xref="S5.SS1.SSS0.Px4.p1.7.2.m1.1.1.2a.cmml">MT</mtext><mn id="S5.SS1.SSS0.Px4.p1.7.2.m1.1.1.3" xref="S5.SS1.SSS0.Px4.p1.7.2.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px4.p1.7.2.m1.1b"><apply id="S5.SS1.SSS0.Px4.p1.7.2.m1.1.1.cmml" xref="S5.SS1.SSS0.Px4.p1.7.2.m1.1.1"><csymbol cd="ambiguous" id="S5.SS1.SSS0.Px4.p1.7.2.m1.1.1.1.cmml" xref="S5.SS1.SSS0.Px4.p1.7.2.m1.1.1">superscript</csymbol><ci id="S5.SS1.SSS0.Px4.p1.7.2.m1.1.1.2a.cmml" xref="S5.SS1.SSS0.Px4.p1.7.2.m1.1.1.2"><mtext class="ltx_font_smallcaps" id="S5.SS1.SSS0.Px4.p1.7.2.m1.1.1.2.cmml" xref="S5.SS1.SSS0.Px4.p1.7.2.m1.1.1.2">MT</mtext></ci><cn id="S5.SS1.SSS0.Px4.p1.7.2.m1.1.1.3.cmml" type="integer" xref="S5.SS1.SSS0.Px4.p1.7.2.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px4.p1.7.2.m1.1c">\text{MT}^{2}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS0.Px4.p1.7.2.m1.1d">MT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math></span>: our method fine-tuned with instruction templates from MotionGPT, but without <span class="ltx_text ltx_markedasmath ltx_font_smallcaps" id="S5.SS1.SSS0.Px4.p1.9.9">Inter</span><span class="ltx_text ltx_font_smallcaps" id="S5.SS1.SSS0.Px4.p1.9.3">-<math alttext="\text{MT}^{2}" class="ltx_Math" display="inline" id="S5.SS1.SSS0.Px4.p1.9.3.m1.1"><semantics id="S5.SS1.SSS0.Px4.p1.9.3.m1.1a"><msup id="S5.SS1.SSS0.Px4.p1.9.3.m1.1.1" xref="S5.SS1.SSS0.Px4.p1.9.3.m1.1.1.cmml"><mtext class="ltx_font_smallcaps" id="S5.SS1.SSS0.Px4.p1.9.3.m1.1.1.2" xref="S5.SS1.SSS0.Px4.p1.9.3.m1.1.1.2a.cmml">MT</mtext><mn id="S5.SS1.SSS0.Px4.p1.9.3.m1.1.1.3" xref="S5.SS1.SSS0.Px4.p1.9.3.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px4.p1.9.3.m1.1b"><apply id="S5.SS1.SSS0.Px4.p1.9.3.m1.1.1.cmml" xref="S5.SS1.SSS0.Px4.p1.9.3.m1.1.1"><csymbol cd="ambiguous" id="S5.SS1.SSS0.Px4.p1.9.3.m1.1.1.1.cmml" xref="S5.SS1.SSS0.Px4.p1.9.3.m1.1.1">superscript</csymbol><ci id="S5.SS1.SSS0.Px4.p1.9.3.m1.1.1.2a.cmml" xref="S5.SS1.SSS0.Px4.p1.9.3.m1.1.1.2"><mtext class="ltx_font_smallcaps" id="S5.SS1.SSS0.Px4.p1.9.3.m1.1.1.2.cmml" xref="S5.SS1.SSS0.Px4.p1.9.3.m1.1.1.2">MT</mtext></ci><cn id="S5.SS1.SSS0.Px4.p1.9.3.m1.1.1.3.cmml" type="integer" xref="S5.SS1.SSS0.Px4.p1.9.3.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px4.p1.9.3.m1.1c">\text{MT}^{2}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.SSS0.Px4.p1.9.3.m1.1d">MT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math></span> data.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Motion Reasoning</h3>
<figure class="ltx_table" id="S5.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Evaluation on Motion Reasoning task with <span class="ltx_text ltx_markedasmath ltx_font_smallcaps" id="S5.T1.15.2">Inter</span><span class="ltx_text ltx_font_smallcaps" id="S5.T1.4.1">-<math alttext="\text{MT}^{2}" class="ltx_Math" display="inline" id="S5.T1.4.1.m1.1"><semantics id="S5.T1.4.1.m1.1b"><msup id="S5.T1.4.1.m1.1.1" xref="S5.T1.4.1.m1.1.1.cmml"><mtext class="ltx_font_smallcaps" id="S5.T1.4.1.m1.1.1.2" xref="S5.T1.4.1.m1.1.1.2a.cmml">MT</mtext><mn id="S5.T1.4.1.m1.1.1.3" xref="S5.T1.4.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S5.T1.4.1.m1.1c"><apply id="S5.T1.4.1.m1.1.1.cmml" xref="S5.T1.4.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T1.4.1.m1.1.1.1.cmml" xref="S5.T1.4.1.m1.1.1">superscript</csymbol><ci id="S5.T1.4.1.m1.1.1.2a.cmml" xref="S5.T1.4.1.m1.1.1.2"><mtext class="ltx_font_smallcaps" id="S5.T1.4.1.m1.1.1.2.cmml" xref="S5.T1.4.1.m1.1.1.2">MT</mtext></ci><cn id="S5.T1.4.1.m1.1.1.3.cmml" type="integer" xref="S5.T1.4.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.4.1.m1.1d">\text{MT}^{2}</annotation><annotation encoding="application/x-llamapun" id="S5.T1.4.1.m1.1e">MT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math></span> test set. Coh., Align., and Nat. denote logical coherence, content alignment, and naturalness, respectively. <span class="ltx_text ltx_font_bold" id="S5.T1.16.3">Bold</span> indicates best performance and <span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T1.17.4">underline</span> denotes the second best performance.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T1.11" style="width:357.7pt;height:156.5pt;vertical-align:-0.9pt;"><span class="ltx_transformed_inner" style="transform:translate(-28.0pt,12.2pt) scale(0.864525617449446,0.864525617449446) ;">
<table class="ltx_tabular ltx_align_middle" id="S5.T1.11.7">
<tr class="ltx_tr" id="S5.T1.11.7.8">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S5.T1.11.7.8.1">Methods</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="3" id="S5.T1.11.7.8.2">LLM-Assisted</td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="S5.T1.11.7.8.3">Linguistic Metrics</td>
</tr>
<tr class="ltx_tr" id="S5.T1.7.3.3">
<td class="ltx_td ltx_border_r" id="S5.T1.7.3.3.4"></td>
<td class="ltx_td ltx_align_center" id="S5.T1.5.1.1.1">Coh. <math alttext="\uparrow" class="ltx_Math" display="inline" id="S5.T1.5.1.1.1.m1.1"><semantics id="S5.T1.5.1.1.1.m1.1a"><mo id="S5.T1.5.1.1.1.m1.1.1" stretchy="false" xref="S5.T1.5.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S5.T1.5.1.1.1.m1.1b"><ci id="S5.T1.5.1.1.1.m1.1.1.cmml" xref="S5.T1.5.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.5.1.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S5.T1.5.1.1.1.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="S5.T1.6.2.2.2">Align. <math alttext="\uparrow" class="ltx_Math" display="inline" id="S5.T1.6.2.2.2.m1.1"><semantics id="S5.T1.6.2.2.2.m1.1a"><mo id="S5.T1.6.2.2.2.m1.1.1" stretchy="false" xref="S5.T1.6.2.2.2.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S5.T1.6.2.2.2.m1.1b"><ci id="S5.T1.6.2.2.2.m1.1.1.cmml" xref="S5.T1.6.2.2.2.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.6.2.2.2.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S5.T1.6.2.2.2.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T1.7.3.3.3">Nat. <math alttext="\uparrow" class="ltx_Math" display="inline" id="S5.T1.7.3.3.3.m1.1"><semantics id="S5.T1.7.3.3.3.m1.1a"><mo id="S5.T1.7.3.3.3.m1.1.1" stretchy="false" xref="S5.T1.7.3.3.3.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S5.T1.7.3.3.3.m1.1b"><ci id="S5.T1.7.3.3.3.m1.1.1.cmml" xref="S5.T1.7.3.3.3.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.7.3.3.3.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S5.T1.7.3.3.3.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="S5.T1.7.3.3.5">ROUGE-L</td>
<td class="ltx_td ltx_align_center" id="S5.T1.7.3.3.6">METEOR</td>
<td class="ltx_td ltx_align_center" id="S5.T1.7.3.3.7">MAUVE</td>
</tr>
<tr class="ltx_tr" id="S5.T1.11.7.9">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T1.11.7.9.1"><span class="ltx_text ltx_font_italic" id="S5.T1.11.7.9.1.1" style="color:#808080;">two-stage approach</span></td>
<td class="ltx_td ltx_border_t" id="S5.T1.11.7.9.2"></td>
<td class="ltx_td ltx_border_t" id="S5.T1.11.7.9.3"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="S5.T1.11.7.9.4"></td>
<td class="ltx_td ltx_border_t" id="S5.T1.11.7.9.5"></td>
<td class="ltx_td ltx_border_t" id="S5.T1.11.7.9.6"></td>
<td class="ltx_td ltx_border_t" id="S5.T1.11.7.9.7"></td>
</tr>
<tr class="ltx_tr" id="S5.T1.11.7.10">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T1.11.7.10.1">TM2T + LLaMA-3.1-8B</td>
<td class="ltx_td ltx_align_center" id="S5.T1.11.7.10.2">3.852</td>
<td class="ltx_td ltx_align_center" id="S5.T1.11.7.10.3">3.050</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T1.11.7.10.4">6.348</td>
<td class="ltx_td ltx_align_center" id="S5.T1.11.7.10.5">0.158</td>
<td class="ltx_td ltx_align_center" id="S5.T1.11.7.10.6">0.226</td>
<td class="ltx_td ltx_align_center" id="S5.T1.11.7.10.7">0.009</td>
</tr>
<tr class="ltx_tr" id="S5.T1.11.7.11">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T1.11.7.11.1">TM2T + GPT-4o</td>
<td class="ltx_td ltx_align_center" id="S5.T1.11.7.11.2"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T1.11.7.11.2.1">4.266</span></td>
<td class="ltx_td ltx_align_center" id="S5.T1.11.7.11.3"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T1.11.7.11.3.1">3.455</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T1.11.7.11.4"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T1.11.7.11.4.1">6.790</span></td>
<td class="ltx_td ltx_align_center" id="S5.T1.11.7.11.5">0.162</td>
<td class="ltx_td ltx_align_center" id="S5.T1.11.7.11.6">0.227</td>
<td class="ltx_td ltx_align_center" id="S5.T1.11.7.11.7">0.019</td>
</tr>
<tr class="ltx_tr" id="S5.T1.11.7.12">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T1.11.7.12.1"><span class="ltx_text ltx_font_italic" id="S5.T1.11.7.12.1.1" style="color:#808080;">unified approach</span></td>
<td class="ltx_td ltx_border_t" id="S5.T1.11.7.12.2"></td>
<td class="ltx_td ltx_border_t" id="S5.T1.11.7.12.3"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="S5.T1.11.7.12.4"></td>
<td class="ltx_td ltx_border_t" id="S5.T1.11.7.12.5"></td>
<td class="ltx_td ltx_border_t" id="S5.T1.11.7.12.6"></td>
<td class="ltx_td ltx_border_t" id="S5.T1.11.7.12.7"></td>
</tr>
<tr class="ltx_tr" id="S5.T1.8.4.4">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T1.8.4.4.1"><math alttext="\text{MotionGPT}^{*}" class="ltx_Math" display="inline" id="S5.T1.8.4.4.1.m1.1"><semantics id="S5.T1.8.4.4.1.m1.1a"><msup id="S5.T1.8.4.4.1.m1.1.1" xref="S5.T1.8.4.4.1.m1.1.1.cmml"><mtext id="S5.T1.8.4.4.1.m1.1.1.2" xref="S5.T1.8.4.4.1.m1.1.1.2a.cmml">MotionGPT</mtext><mo id="S5.T1.8.4.4.1.m1.1.1.3" xref="S5.T1.8.4.4.1.m1.1.1.3.cmml">∗</mo></msup><annotation-xml encoding="MathML-Content" id="S5.T1.8.4.4.1.m1.1b"><apply id="S5.T1.8.4.4.1.m1.1.1.cmml" xref="S5.T1.8.4.4.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T1.8.4.4.1.m1.1.1.1.cmml" xref="S5.T1.8.4.4.1.m1.1.1">superscript</csymbol><ci id="S5.T1.8.4.4.1.m1.1.1.2a.cmml" xref="S5.T1.8.4.4.1.m1.1.1.2"><mtext id="S5.T1.8.4.4.1.m1.1.1.2.cmml" xref="S5.T1.8.4.4.1.m1.1.1.2">MotionGPT</mtext></ci><times id="S5.T1.8.4.4.1.m1.1.1.3.cmml" xref="S5.T1.8.4.4.1.m1.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.8.4.4.1.m1.1c">\text{MotionGPT}^{*}</annotation><annotation encoding="application/x-llamapun" id="S5.T1.8.4.4.1.m1.1d">MotionGPT start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S5.T1.8.4.4.2">1.855</td>
<td class="ltx_td ltx_align_center" id="S5.T1.8.4.4.3">1.303</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T1.8.4.4.4">3.574</td>
<td class="ltx_td ltx_align_center" id="S5.T1.8.4.4.5">0.113</td>
<td class="ltx_td ltx_align_center" id="S5.T1.8.4.4.6">0.096</td>
<td class="ltx_td ltx_align_center" id="S5.T1.8.4.4.7">0.005</td>
</tr>
<tr class="ltx_tr" id="S5.T1.9.5.5">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T1.9.5.5.1"><math alttext="\text{MotionGPT}^{*}_{I}" class="ltx_Math" display="inline" id="S5.T1.9.5.5.1.m1.1"><semantics id="S5.T1.9.5.5.1.m1.1a"><msubsup id="S5.T1.9.5.5.1.m1.1.1" xref="S5.T1.9.5.5.1.m1.1.1.cmml"><mtext id="S5.T1.9.5.5.1.m1.1.1.2.2" xref="S5.T1.9.5.5.1.m1.1.1.2.2a.cmml">MotionGPT</mtext><mi id="S5.T1.9.5.5.1.m1.1.1.3" xref="S5.T1.9.5.5.1.m1.1.1.3.cmml">I</mi><mo id="S5.T1.9.5.5.1.m1.1.1.2.3" xref="S5.T1.9.5.5.1.m1.1.1.2.3.cmml">∗</mo></msubsup><annotation-xml encoding="MathML-Content" id="S5.T1.9.5.5.1.m1.1b"><apply id="S5.T1.9.5.5.1.m1.1.1.cmml" xref="S5.T1.9.5.5.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T1.9.5.5.1.m1.1.1.1.cmml" xref="S5.T1.9.5.5.1.m1.1.1">subscript</csymbol><apply id="S5.T1.9.5.5.1.m1.1.1.2.cmml" xref="S5.T1.9.5.5.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T1.9.5.5.1.m1.1.1.2.1.cmml" xref="S5.T1.9.5.5.1.m1.1.1">superscript</csymbol><ci id="S5.T1.9.5.5.1.m1.1.1.2.2a.cmml" xref="S5.T1.9.5.5.1.m1.1.1.2.2"><mtext id="S5.T1.9.5.5.1.m1.1.1.2.2.cmml" xref="S5.T1.9.5.5.1.m1.1.1.2.2">MotionGPT</mtext></ci><times id="S5.T1.9.5.5.1.m1.1.1.2.3.cmml" xref="S5.T1.9.5.5.1.m1.1.1.2.3"></times></apply><ci id="S5.T1.9.5.5.1.m1.1.1.3.cmml" xref="S5.T1.9.5.5.1.m1.1.1.3">𝐼</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.9.5.5.1.m1.1c">\text{MotionGPT}^{*}_{I}</annotation><annotation encoding="application/x-llamapun" id="S5.T1.9.5.5.1.m1.1d">MotionGPT start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_I end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S5.T1.9.5.5.2">3.690</td>
<td class="ltx_td ltx_align_center" id="S5.T1.9.5.5.3">3.160</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T1.9.5.5.4">5.291</td>
<td class="ltx_td ltx_align_center" id="S5.T1.9.5.5.5"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T1.9.5.5.5.1">0.207</span></td>
<td class="ltx_td ltx_align_center" id="S5.T1.9.5.5.6"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T1.9.5.5.6.1">0.218</span></td>
<td class="ltx_td ltx_align_center" id="S5.T1.9.5.5.7"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T1.9.5.5.7.1">0.417</span></td>
</tr>
<tr class="ltx_tr" id="S5.T1.11.7.7">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T1.11.7.7.2">VIM w/o <span class="ltx_text ltx_markedasmath ltx_font_smallcaps" id="S5.T1.11.7.7.2.2">Inter</span><span class="ltx_text ltx_font_smallcaps" id="S5.T1.11.7.7.2.1">-<math alttext="\text{MT}^{2}" class="ltx_Math" display="inline" id="S5.T1.11.7.7.2.1.m1.1"><semantics id="S5.T1.11.7.7.2.1.m1.1a"><msup id="S5.T1.11.7.7.2.1.m1.1.1" xref="S5.T1.11.7.7.2.1.m1.1.1.cmml"><mtext class="ltx_font_smallcaps" id="S5.T1.11.7.7.2.1.m1.1.1.2" xref="S5.T1.11.7.7.2.1.m1.1.1.2a.cmml">MT</mtext><mn id="S5.T1.11.7.7.2.1.m1.1.1.3" xref="S5.T1.11.7.7.2.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S5.T1.11.7.7.2.1.m1.1b"><apply id="S5.T1.11.7.7.2.1.m1.1.1.cmml" xref="S5.T1.11.7.7.2.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T1.11.7.7.2.1.m1.1.1.1.cmml" xref="S5.T1.11.7.7.2.1.m1.1.1">superscript</csymbol><ci id="S5.T1.11.7.7.2.1.m1.1.1.2a.cmml" xref="S5.T1.11.7.7.2.1.m1.1.1.2"><mtext class="ltx_font_smallcaps" id="S5.T1.11.7.7.2.1.m1.1.1.2.cmml" xref="S5.T1.11.7.7.2.1.m1.1.1.2">MT</mtext></ci><cn id="S5.T1.11.7.7.2.1.m1.1.1.3.cmml" type="integer" xref="S5.T1.11.7.7.2.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.11.7.7.2.1.m1.1c">\text{MT}^{2}</annotation><annotation encoding="application/x-llamapun" id="S5.T1.11.7.7.2.1.m1.1d">MT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math></span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T1.11.7.7.3">2.770</td>
<td class="ltx_td ltx_align_center" id="S5.T1.11.7.7.4">2.141</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T1.11.7.7.5">4.968</td>
<td class="ltx_td ltx_align_center" id="S5.T1.11.7.7.6">0.155</td>
<td class="ltx_td ltx_align_center" id="S5.T1.11.7.7.7">0.145</td>
<td class="ltx_td ltx_align_center" id="S5.T1.11.7.7.8">0.004</td>
</tr>
<tr class="ltx_tr" id="S5.T1.11.7.13">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" id="S5.T1.11.7.13.1"><span class="ltx_text ltx_font_bold" id="S5.T1.11.7.13.1.1">VIM (Ours)</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T1.11.7.13.2"><span class="ltx_text ltx_font_bold" id="S5.T1.11.7.13.2.1">5.252</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T1.11.7.13.3"><span class="ltx_text ltx_font_bold" id="S5.T1.11.7.13.3.1">4.511</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S5.T1.11.7.13.4"><span class="ltx_text ltx_font_bold" id="S5.T1.11.7.13.4.1">6.981</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T1.11.7.13.5"><span class="ltx_text ltx_font_bold" id="S5.T1.11.7.13.5.1">0.239</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T1.11.7.13.6"><span class="ltx_text ltx_font_bold" id="S5.T1.11.7.13.6.1">0.260</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T1.11.7.13.7"><span class="ltx_text ltx_font_bold" id="S5.T1.11.7.13.7.1">0.794</span></td>
</tr>
</table>
</span></div>
</figure>
<figure class="ltx_figure" id="S5.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="308" id="S5.F4.g1" src="x4.png" width="822"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Generated samples for interactive motion reasoning task. This example shows how <span class="ltx_text ltx_font_smallcaps" id="S5.F4.2.1">VIM</span> explains behaviors and their motivations, demonstrating a deeper understanding of scenarios by incorporating context from prior interactions.
</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.8">In the motion reasoning task, conversations about two interactive motions are examined to assess the model’s ability to deduce past or future events and comprehend the motivations driving the motions.
The experimental results in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#S5.T1" title="Table 1 ‣ 5.2 Motion Reasoning ‣ 5 Experiments ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_tag">1</span></a> demonstrate that our unified model, <span class="ltx_text ltx_font_smallcaps" id="S5.SS2.p1.8.4">VIM</span>, significantly outperforms two-stage approaches across all LLM-assisted and linguistic metrics. Specifically, <span class="ltx_text ltx_font_smallcaps" id="S5.SS2.p1.8.5">VIM</span> achieves improvements with performance increases exceeding 1.9 points in logical coherence, 1.1 points in content alignment, and nearly 0.2 points in naturalness compared to the best two-stage model.
The baseline models trained solely on text-motion pair datasets, such as <span class="ltx_text ltx_font_smallcaps" id="S5.SS2.p1.8.6">VIM</span> w/o <span class="ltx_text ltx_markedasmath ltx_font_smallcaps" id="S5.SS2.p1.8.7">Inter</span><span class="ltx_text ltx_font_smallcaps" id="S5.SS2.p1.2.1">-<math alttext="\text{MT}^{2}" class="ltx_Math" display="inline" id="S5.SS2.p1.2.1.m1.1"><semantics id="S5.SS2.p1.2.1.m1.1a"><msup id="S5.SS2.p1.2.1.m1.1.1" xref="S5.SS2.p1.2.1.m1.1.1.cmml"><mtext class="ltx_font_smallcaps" id="S5.SS2.p1.2.1.m1.1.1.2" xref="S5.SS2.p1.2.1.m1.1.1.2a.cmml">MT</mtext><mn id="S5.SS2.p1.2.1.m1.1.1.3" xref="S5.SS2.p1.2.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.2.1.m1.1b"><apply id="S5.SS2.p1.2.1.m1.1.1.cmml" xref="S5.SS2.p1.2.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS2.p1.2.1.m1.1.1.1.cmml" xref="S5.SS2.p1.2.1.m1.1.1">superscript</csymbol><ci id="S5.SS2.p1.2.1.m1.1.1.2a.cmml" xref="S5.SS2.p1.2.1.m1.1.1.2"><mtext class="ltx_font_smallcaps" id="S5.SS2.p1.2.1.m1.1.1.2.cmml" xref="S5.SS2.p1.2.1.m1.1.1.2">MT</mtext></ci><cn id="S5.SS2.p1.2.1.m1.1.1.3.cmml" type="integer" xref="S5.SS2.p1.2.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.2.1.m1.1c">\text{MT}^{2}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p1.2.1.m1.1d">MT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math></span> and <math alttext="\text{MotionGPT}^{*}" class="ltx_Math" display="inline" id="S5.SS2.p1.3.m2.1"><semantics id="S5.SS2.p1.3.m2.1a"><msup id="S5.SS2.p1.3.m2.1.1" xref="S5.SS2.p1.3.m2.1.1.cmml"><mtext id="S5.SS2.p1.3.m2.1.1.2" xref="S5.SS2.p1.3.m2.1.1.2a.cmml">MotionGPT</mtext><mo id="S5.SS2.p1.3.m2.1.1.3" xref="S5.SS2.p1.3.m2.1.1.3.cmml">∗</mo></msup><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.3.m2.1b"><apply id="S5.SS2.p1.3.m2.1.1.cmml" xref="S5.SS2.p1.3.m2.1.1"><csymbol cd="ambiguous" id="S5.SS2.p1.3.m2.1.1.1.cmml" xref="S5.SS2.p1.3.m2.1.1">superscript</csymbol><ci id="S5.SS2.p1.3.m2.1.1.2a.cmml" xref="S5.SS2.p1.3.m2.1.1.2"><mtext id="S5.SS2.p1.3.m2.1.1.2.cmml" xref="S5.SS2.p1.3.m2.1.1.2">MotionGPT</mtext></ci><times id="S5.SS2.p1.3.m2.1.1.3.cmml" xref="S5.SS2.p1.3.m2.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.3.m2.1c">\text{MotionGPT}^{*}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p1.3.m2.1d">MotionGPT start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT</annotation></semantics></math>, show limited reasoning capabilities. Although <math alttext="\text{MotionGPT}^{*}_{I}" class="ltx_Math" display="inline" id="S5.SS2.p1.4.m3.1"><semantics id="S5.SS2.p1.4.m3.1a"><msubsup id="S5.SS2.p1.4.m3.1.1" xref="S5.SS2.p1.4.m3.1.1.cmml"><mtext id="S5.SS2.p1.4.m3.1.1.2.2" xref="S5.SS2.p1.4.m3.1.1.2.2a.cmml">MotionGPT</mtext><mi id="S5.SS2.p1.4.m3.1.1.3" xref="S5.SS2.p1.4.m3.1.1.3.cmml">I</mi><mo id="S5.SS2.p1.4.m3.1.1.2.3" xref="S5.SS2.p1.4.m3.1.1.2.3.cmml">∗</mo></msubsup><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.4.m3.1b"><apply id="S5.SS2.p1.4.m3.1.1.cmml" xref="S5.SS2.p1.4.m3.1.1"><csymbol cd="ambiguous" id="S5.SS2.p1.4.m3.1.1.1.cmml" xref="S5.SS2.p1.4.m3.1.1">subscript</csymbol><apply id="S5.SS2.p1.4.m3.1.1.2.cmml" xref="S5.SS2.p1.4.m3.1.1"><csymbol cd="ambiguous" id="S5.SS2.p1.4.m3.1.1.2.1.cmml" xref="S5.SS2.p1.4.m3.1.1">superscript</csymbol><ci id="S5.SS2.p1.4.m3.1.1.2.2a.cmml" xref="S5.SS2.p1.4.m3.1.1.2.2"><mtext id="S5.SS2.p1.4.m3.1.1.2.2.cmml" xref="S5.SS2.p1.4.m3.1.1.2.2">MotionGPT</mtext></ci><times id="S5.SS2.p1.4.m3.1.1.2.3.cmml" xref="S5.SS2.p1.4.m3.1.1.2.3"></times></apply><ci id="S5.SS2.p1.4.m3.1.1.3.cmml" xref="S5.SS2.p1.4.m3.1.1.3">𝐼</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.4.m3.1c">\text{MotionGPT}^{*}_{I}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p1.4.m3.1d">MotionGPT start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_I end_POSTSUBSCRIPT</annotation></semantics></math>, which incorporates <span class="ltx_text ltx_markedasmath ltx_font_smallcaps" id="S5.SS2.p1.8.8">Inter</span><span class="ltx_text ltx_font_smallcaps" id="S5.SS2.p1.6.2">-<math alttext="\text{MT}^{2}" class="ltx_Math" display="inline" id="S5.SS2.p1.6.2.m1.1"><semantics id="S5.SS2.p1.6.2.m1.1a"><msup id="S5.SS2.p1.6.2.m1.1.1" xref="S5.SS2.p1.6.2.m1.1.1.cmml"><mtext class="ltx_font_smallcaps" id="S5.SS2.p1.6.2.m1.1.1.2" xref="S5.SS2.p1.6.2.m1.1.1.2a.cmml">MT</mtext><mn id="S5.SS2.p1.6.2.m1.1.1.3" xref="S5.SS2.p1.6.2.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.6.2.m1.1b"><apply id="S5.SS2.p1.6.2.m1.1.1.cmml" xref="S5.SS2.p1.6.2.m1.1.1"><csymbol cd="ambiguous" id="S5.SS2.p1.6.2.m1.1.1.1.cmml" xref="S5.SS2.p1.6.2.m1.1.1">superscript</csymbol><ci id="S5.SS2.p1.6.2.m1.1.1.2a.cmml" xref="S5.SS2.p1.6.2.m1.1.1.2"><mtext class="ltx_font_smallcaps" id="S5.SS2.p1.6.2.m1.1.1.2.cmml" xref="S5.SS2.p1.6.2.m1.1.1.2">MT</mtext></ci><cn id="S5.SS2.p1.6.2.m1.1.1.3.cmml" type="integer" xref="S5.SS2.p1.6.2.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.6.2.m1.1c">\text{MT}^{2}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p1.6.2.m1.1d">MT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math></span> datasets, exhibits improved performance compared to baselines trained without <span class="ltx_text ltx_markedasmath ltx_font_smallcaps" id="S5.SS2.p1.8.9">Inter</span><span class="ltx_text ltx_font_smallcaps" id="S5.SS2.p1.8.3">-<math alttext="\text{MT}^{2}" class="ltx_Math" display="inline" id="S5.SS2.p1.8.3.m1.1"><semantics id="S5.SS2.p1.8.3.m1.1a"><msup id="S5.SS2.p1.8.3.m1.1.1" xref="S5.SS2.p1.8.3.m1.1.1.cmml"><mtext class="ltx_font_smallcaps" id="S5.SS2.p1.8.3.m1.1.1.2" xref="S5.SS2.p1.8.3.m1.1.1.2a.cmml">MT</mtext><mn id="S5.SS2.p1.8.3.m1.1.1.3" xref="S5.SS2.p1.8.3.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.8.3.m1.1b"><apply id="S5.SS2.p1.8.3.m1.1.1.cmml" xref="S5.SS2.p1.8.3.m1.1.1"><csymbol cd="ambiguous" id="S5.SS2.p1.8.3.m1.1.1.1.cmml" xref="S5.SS2.p1.8.3.m1.1.1">superscript</csymbol><ci id="S5.SS2.p1.8.3.m1.1.1.2a.cmml" xref="S5.SS2.p1.8.3.m1.1.1.2"><mtext class="ltx_font_smallcaps" id="S5.SS2.p1.8.3.m1.1.1.2.cmml" xref="S5.SS2.p1.8.3.m1.1.1.2">MT</mtext></ci><cn id="S5.SS2.p1.8.3.m1.1.1.3.cmml" type="integer" xref="S5.SS2.p1.8.3.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.8.3.m1.1c">\text{MT}^{2}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p1.8.3.m1.1d">MT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math></span>, it still does not match the effectiveness of the two-stage approaches.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS2.p2">
<p class="ltx_p" id="S5.SS2.p2.1">The improved performance of our unified model, <span class="ltx_text ltx_font_smallcaps" id="S5.SS2.p2.1.1">VIM</span>, over two-stage approaches, appears to result from two key factors: error accumulation and interpretation ambiguity.
First, in two-stage models, errors can accumulate; if the motion captioning model generates incorrect motion captions, those mistakes carry over to the second stage, reducing content alignment and coherence. In contrast, VIM’s unified architecture integrates motion encoding and reasoning in a single framework, minimizing error propagation.
Second, interpreting motions is not always straightforward, with multiple ways to understand and describe the same motion. In two-stage models, mapping the motion to a single caption for the second stage can lead to more contextually accurate reasoning of the given scenarios or contexts. Our unified model, however, is built to recognize these varied interpretations and generate reasoning that is more contextually accurate. Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#S5.F4" title="Figure 4 ‣ 5.2 Motion Reasoning ‣ 5 Experiments ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_tag">4</span></a> showcases it’s ability to dynamically adjust interpretations and responses by incorporating context from previous conversations.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Motion Editing</h3>
<figure class="ltx_table" id="S5.T2">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_bottom" id="S5.T2.10" style="width:173.4pt;">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Table 2: </span>Data-driven evaluation in motion editing in <span class="ltx_text ltx_markedasmath ltx_font_smallcaps" id="S5.T2.10.12.2">Inter</span><span class="ltx_text ltx_font_smallcaps" id="S5.T2.4.4.1">-<math alttext="\text{MT}^{2}" class="ltx_Math" display="inline" id="S5.T2.4.4.1.m1.1"><semantics id="S5.T2.4.4.1.m1.1b"><msup id="S5.T2.4.4.1.m1.1.1" xref="S5.T2.4.4.1.m1.1.1.cmml"><mtext class="ltx_font_smallcaps" id="S5.T2.4.4.1.m1.1.1.2" xref="S5.T2.4.4.1.m1.1.1.2a.cmml">MT</mtext><mn id="S5.T2.4.4.1.m1.1.1.3" xref="S5.T2.4.4.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S5.T2.4.4.1.m1.1c"><apply id="S5.T2.4.4.1.m1.1.1.cmml" xref="S5.T2.4.4.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T2.4.4.1.m1.1.1.1.cmml" xref="S5.T2.4.4.1.m1.1.1">superscript</csymbol><ci id="S5.T2.4.4.1.m1.1.1.2a.cmml" xref="S5.T2.4.4.1.m1.1.1.2"><mtext class="ltx_font_smallcaps" id="S5.T2.4.4.1.m1.1.1.2.cmml" xref="S5.T2.4.4.1.m1.1.1.2">MT</mtext></ci><cn id="S5.T2.4.4.1.m1.1.1.3.cmml" type="integer" xref="S5.T2.4.4.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.4.4.1.m1.1d">\text{MT}^{2}</annotation><annotation encoding="application/x-llamapun" id="S5.T2.4.4.1.m1.1e">MT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math></span> test set. </figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T2.10.10" style="width:433.6pt;height:318pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(118.6pt,-87.0pt) scale(2.20865042807888,2.20865042807888) ;">
<table class="ltx_tabular ltx_align_top" id="S5.T2.10.10.6">
<tr class="ltx_tr" id="S5.T2.6.6.2.2">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="S5.T2.6.6.2.2.3">Methods</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.5.5.1.1.1">FID <math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T2.5.5.1.1.1.m1.1"><semantics id="S5.T2.5.5.1.1.1.m1.1a"><mo id="S5.T2.5.5.1.1.1.m1.1.1" stretchy="false" xref="S5.T2.5.5.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T2.5.5.1.1.1.m1.1b"><ci id="S5.T2.5.5.1.1.1.m1.1.1.cmml" xref="S5.T2.5.5.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.5.5.1.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T2.5.5.1.1.1.m1.1d">↓</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.6.6.2.2.2">MPJPE <math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T2.6.6.2.2.2.m1.1"><semantics id="S5.T2.6.6.2.2.2.m1.1a"><mo id="S5.T2.6.6.2.2.2.m1.1.1" stretchy="false" xref="S5.T2.6.6.2.2.2.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T2.6.6.2.2.2.m1.1b"><ci id="S5.T2.6.6.2.2.2.m1.1.1.cmml" xref="S5.T2.6.6.2.2.2.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.6.6.2.2.2.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T2.6.6.2.2.2.m1.1d">↓</annotation></semantics></math>
</td>
</tr>
<tr class="ltx_tr" id="S5.T2.10.10.6.7">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T2.10.10.6.7.1"><span class="ltx_text ltx_font_italic" id="S5.T2.10.10.6.7.1.1" style="color:#808080;">two-stage approach</span></td>
<td class="ltx_td ltx_border_t" id="S5.T2.10.10.6.7.2"></td>
<td class="ltx_td ltx_border_t" id="S5.T2.10.10.6.7.3"></td>
</tr>
<tr class="ltx_tr" id="S5.T2.10.10.6.8">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.10.10.6.8.1">TM2T + InterGen</td>
<td class="ltx_td ltx_align_center" id="S5.T2.10.10.6.8.2">0.110</td>
<td class="ltx_td ltx_align_center" id="S5.T2.10.10.6.8.3"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.10.10.6.8.3.1">0.811</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.10.10.6.9">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T2.10.10.6.9.1"><span class="ltx_text ltx_font_italic" id="S5.T2.10.10.6.9.1.1" style="color:#808080;">unified approach</span></td>
<td class="ltx_td ltx_border_t" id="S5.T2.10.10.6.9.2"></td>
<td class="ltx_td ltx_border_t" id="S5.T2.10.10.6.9.3"></td>
</tr>
<tr class="ltx_tr" id="S5.T2.7.7.3.3">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.7.7.3.3.1"><math alttext="\text{MotionGPT}^{*}" class="ltx_Math" display="inline" id="S5.T2.7.7.3.3.1.m1.1"><semantics id="S5.T2.7.7.3.3.1.m1.1a"><msup id="S5.T2.7.7.3.3.1.m1.1.1" xref="S5.T2.7.7.3.3.1.m1.1.1.cmml"><mtext id="S5.T2.7.7.3.3.1.m1.1.1.2" xref="S5.T2.7.7.3.3.1.m1.1.1.2a.cmml">MotionGPT</mtext><mo id="S5.T2.7.7.3.3.1.m1.1.1.3" xref="S5.T2.7.7.3.3.1.m1.1.1.3.cmml">∗</mo></msup><annotation-xml encoding="MathML-Content" id="S5.T2.7.7.3.3.1.m1.1b"><apply id="S5.T2.7.7.3.3.1.m1.1.1.cmml" xref="S5.T2.7.7.3.3.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T2.7.7.3.3.1.m1.1.1.1.cmml" xref="S5.T2.7.7.3.3.1.m1.1.1">superscript</csymbol><ci id="S5.T2.7.7.3.3.1.m1.1.1.2a.cmml" xref="S5.T2.7.7.3.3.1.m1.1.1.2"><mtext id="S5.T2.7.7.3.3.1.m1.1.1.2.cmml" xref="S5.T2.7.7.3.3.1.m1.1.1.2">MotionGPT</mtext></ci><times id="S5.T2.7.7.3.3.1.m1.1.1.3.cmml" xref="S5.T2.7.7.3.3.1.m1.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.7.7.3.3.1.m1.1c">\text{MotionGPT}^{*}</annotation><annotation encoding="application/x-llamapun" id="S5.T2.7.7.3.3.1.m1.1d">MotionGPT start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S5.T2.7.7.3.3.2">0.251</td>
<td class="ltx_td ltx_align_center" id="S5.T2.7.7.3.3.3">4.002</td>
</tr>
<tr class="ltx_tr" id="S5.T2.8.8.4.4">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.8.8.4.4.1"><math alttext="\text{MotionGPT}^{*}_{I}" class="ltx_Math" display="inline" id="S5.T2.8.8.4.4.1.m1.1"><semantics id="S5.T2.8.8.4.4.1.m1.1a"><msubsup id="S5.T2.8.8.4.4.1.m1.1.1" xref="S5.T2.8.8.4.4.1.m1.1.1.cmml"><mtext id="S5.T2.8.8.4.4.1.m1.1.1.2.2" xref="S5.T2.8.8.4.4.1.m1.1.1.2.2a.cmml">MotionGPT</mtext><mi id="S5.T2.8.8.4.4.1.m1.1.1.3" xref="S5.T2.8.8.4.4.1.m1.1.1.3.cmml">I</mi><mo id="S5.T2.8.8.4.4.1.m1.1.1.2.3" xref="S5.T2.8.8.4.4.1.m1.1.1.2.3.cmml">∗</mo></msubsup><annotation-xml encoding="MathML-Content" id="S5.T2.8.8.4.4.1.m1.1b"><apply id="S5.T2.8.8.4.4.1.m1.1.1.cmml" xref="S5.T2.8.8.4.4.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T2.8.8.4.4.1.m1.1.1.1.cmml" xref="S5.T2.8.8.4.4.1.m1.1.1">subscript</csymbol><apply id="S5.T2.8.8.4.4.1.m1.1.1.2.cmml" xref="S5.T2.8.8.4.4.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T2.8.8.4.4.1.m1.1.1.2.1.cmml" xref="S5.T2.8.8.4.4.1.m1.1.1">superscript</csymbol><ci id="S5.T2.8.8.4.4.1.m1.1.1.2.2a.cmml" xref="S5.T2.8.8.4.4.1.m1.1.1.2.2"><mtext id="S5.T2.8.8.4.4.1.m1.1.1.2.2.cmml" xref="S5.T2.8.8.4.4.1.m1.1.1.2.2">MotionGPT</mtext></ci><times id="S5.T2.8.8.4.4.1.m1.1.1.2.3.cmml" xref="S5.T2.8.8.4.4.1.m1.1.1.2.3"></times></apply><ci id="S5.T2.8.8.4.4.1.m1.1.1.3.cmml" xref="S5.T2.8.8.4.4.1.m1.1.1.3">𝐼</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.8.8.4.4.1.m1.1c">\text{MotionGPT}^{*}_{I}</annotation><annotation encoding="application/x-llamapun" id="S5.T2.8.8.4.4.1.m1.1d">MotionGPT start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_I end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.8.4.4.2">0.161</td>
<td class="ltx_td ltx_align_center" id="S5.T2.8.8.4.4.3">3.982</td>
</tr>
<tr class="ltx_tr" id="S5.T2.10.10.6.6">
<td class="ltx_td ltx_align_left ltx_border_r" id="S5.T2.10.10.6.6.2">VIM w/o <span class="ltx_text ltx_markedasmath ltx_font_smallcaps" id="S5.T2.10.10.6.6.2.2">Inter</span><span class="ltx_text ltx_font_smallcaps" id="S5.T2.10.10.6.6.2.1">-<math alttext="\text{MT}^{2}" class="ltx_Math" display="inline" id="S5.T2.10.10.6.6.2.1.m1.1"><semantics id="S5.T2.10.10.6.6.2.1.m1.1a"><msup id="S5.T2.10.10.6.6.2.1.m1.1.1" xref="S5.T2.10.10.6.6.2.1.m1.1.1.cmml"><mtext class="ltx_font_smallcaps" id="S5.T2.10.10.6.6.2.1.m1.1.1.2" xref="S5.T2.10.10.6.6.2.1.m1.1.1.2a.cmml">MT</mtext><mn id="S5.T2.10.10.6.6.2.1.m1.1.1.3" xref="S5.T2.10.10.6.6.2.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S5.T2.10.10.6.6.2.1.m1.1b"><apply id="S5.T2.10.10.6.6.2.1.m1.1.1.cmml" xref="S5.T2.10.10.6.6.2.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T2.10.10.6.6.2.1.m1.1.1.1.cmml" xref="S5.T2.10.10.6.6.2.1.m1.1.1">superscript</csymbol><ci id="S5.T2.10.10.6.6.2.1.m1.1.1.2a.cmml" xref="S5.T2.10.10.6.6.2.1.m1.1.1.2"><mtext class="ltx_font_smallcaps" id="S5.T2.10.10.6.6.2.1.m1.1.1.2.cmml" xref="S5.T2.10.10.6.6.2.1.m1.1.1.2">MT</mtext></ci><cn id="S5.T2.10.10.6.6.2.1.m1.1.1.3.cmml" type="integer" xref="S5.T2.10.10.6.6.2.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.10.10.6.6.2.1.m1.1c">\text{MT}^{2}</annotation><annotation encoding="application/x-llamapun" id="S5.T2.10.10.6.6.2.1.m1.1d">MT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math></span>
</td>
<td class="ltx_td ltx_align_center" id="S5.T2.10.10.6.6.3"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T2.10.10.6.6.3.1">0.080</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.10.10.6.6.4">0.908</td>
</tr>
<tr class="ltx_tr" id="S5.T2.10.10.6.10">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" id="S5.T2.10.10.6.10.1"><span class="ltx_text ltx_font_bold" id="S5.T2.10.10.6.10.1.1">VIM (Ours)</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.10.10.6.10.2"><span class="ltx_text ltx_font_bold" id="S5.T2.10.10.6.10.2.1">0.064</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.10.10.6.10.3"><span class="ltx_text ltx_font_bold" id="S5.T2.10.10.6.10.3.1">0.758</span></td>
</tr>
</table>
</span></div>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center ltx_align_bottom" id="S5.F5" style="width:260.2pt;"><img alt="Refer to caption" class="ltx_graphics ltx_figure_panel ltx_img_landscape" height="225" id="S5.T2.11.g1" src="extracted/5925138/figures/output.png" width="568"/>
<br class="ltx_break ltx_break"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>User subject study results for motion editing. </figcaption>
</figure>
</div>
</div>
</figure>
<div class="ltx_para ltx_noindent" id="S5.SS3.p1">
<p class="ltx_p" id="S5.SS3.p1.4">We aim to validate the hypothesis that people will perceive the generated edited interactive motion from the proposed method to be more content-consistent, instruction-aligned, and better quality, through user subject studies. To analyze the results, we conducted a repeated-measures multivariate analysis of variance on the rated measures. We observed that methods significantly affect the user’s perception of all dimensions; <math alttext="F(4)=4.591,p=0.002,\eta^{2}=0.137" class="ltx_Math" display="inline" id="S5.SS3.p1.1.m1.3"><semantics id="S5.SS3.p1.1.m1.3a"><mrow id="S5.SS3.p1.1.m1.3.3.2" xref="S5.SS3.p1.1.m1.3.3.3.cmml"><mrow id="S5.SS3.p1.1.m1.2.2.1.1" xref="S5.SS3.p1.1.m1.2.2.1.1.cmml"><mrow id="S5.SS3.p1.1.m1.2.2.1.1.2" xref="S5.SS3.p1.1.m1.2.2.1.1.2.cmml"><mi id="S5.SS3.p1.1.m1.2.2.1.1.2.2" xref="S5.SS3.p1.1.m1.2.2.1.1.2.2.cmml">F</mi><mo id="S5.SS3.p1.1.m1.2.2.1.1.2.1" xref="S5.SS3.p1.1.m1.2.2.1.1.2.1.cmml">⁢</mo><mrow id="S5.SS3.p1.1.m1.2.2.1.1.2.3.2" xref="S5.SS3.p1.1.m1.2.2.1.1.2.cmml"><mo id="S5.SS3.p1.1.m1.2.2.1.1.2.3.2.1" stretchy="false" xref="S5.SS3.p1.1.m1.2.2.1.1.2.cmml">(</mo><mn id="S5.SS3.p1.1.m1.1.1" xref="S5.SS3.p1.1.m1.1.1.cmml">4</mn><mo id="S5.SS3.p1.1.m1.2.2.1.1.2.3.2.2" stretchy="false" xref="S5.SS3.p1.1.m1.2.2.1.1.2.cmml">)</mo></mrow></mrow><mo id="S5.SS3.p1.1.m1.2.2.1.1.1" xref="S5.SS3.p1.1.m1.2.2.1.1.1.cmml">=</mo><mn id="S5.SS3.p1.1.m1.2.2.1.1.3" xref="S5.SS3.p1.1.m1.2.2.1.1.3.cmml">4.591</mn></mrow><mo id="S5.SS3.p1.1.m1.3.3.2.3" xref="S5.SS3.p1.1.m1.3.3.3a.cmml">,</mo><mrow id="S5.SS3.p1.1.m1.3.3.2.2.2" xref="S5.SS3.p1.1.m1.3.3.2.2.3.cmml"><mrow id="S5.SS3.p1.1.m1.3.3.2.2.1.1" xref="S5.SS3.p1.1.m1.3.3.2.2.1.1.cmml"><mi id="S5.SS3.p1.1.m1.3.3.2.2.1.1.2" xref="S5.SS3.p1.1.m1.3.3.2.2.1.1.2.cmml">p</mi><mo id="S5.SS3.p1.1.m1.3.3.2.2.1.1.1" xref="S5.SS3.p1.1.m1.3.3.2.2.1.1.1.cmml">=</mo><mn id="S5.SS3.p1.1.m1.3.3.2.2.1.1.3" xref="S5.SS3.p1.1.m1.3.3.2.2.1.1.3.cmml">0.002</mn></mrow><mo id="S5.SS3.p1.1.m1.3.3.2.2.2.3" xref="S5.SS3.p1.1.m1.3.3.2.2.3a.cmml">,</mo><mrow id="S5.SS3.p1.1.m1.3.3.2.2.2.2" xref="S5.SS3.p1.1.m1.3.3.2.2.2.2.cmml"><msup id="S5.SS3.p1.1.m1.3.3.2.2.2.2.2" xref="S5.SS3.p1.1.m1.3.3.2.2.2.2.2.cmml"><mi id="S5.SS3.p1.1.m1.3.3.2.2.2.2.2.2" xref="S5.SS3.p1.1.m1.3.3.2.2.2.2.2.2.cmml">η</mi><mn id="S5.SS3.p1.1.m1.3.3.2.2.2.2.2.3" xref="S5.SS3.p1.1.m1.3.3.2.2.2.2.2.3.cmml">2</mn></msup><mo id="S5.SS3.p1.1.m1.3.3.2.2.2.2.1" xref="S5.SS3.p1.1.m1.3.3.2.2.2.2.1.cmml">=</mo><mn id="S5.SS3.p1.1.m1.3.3.2.2.2.2.3" xref="S5.SS3.p1.1.m1.3.3.2.2.2.2.3.cmml">0.137</mn></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.1.m1.3b"><apply id="S5.SS3.p1.1.m1.3.3.3.cmml" xref="S5.SS3.p1.1.m1.3.3.2"><csymbol cd="ambiguous" id="S5.SS3.p1.1.m1.3.3.3a.cmml" xref="S5.SS3.p1.1.m1.3.3.2.3">formulae-sequence</csymbol><apply id="S5.SS3.p1.1.m1.2.2.1.1.cmml" xref="S5.SS3.p1.1.m1.2.2.1.1"><eq id="S5.SS3.p1.1.m1.2.2.1.1.1.cmml" xref="S5.SS3.p1.1.m1.2.2.1.1.1"></eq><apply id="S5.SS3.p1.1.m1.2.2.1.1.2.cmml" xref="S5.SS3.p1.1.m1.2.2.1.1.2"><times id="S5.SS3.p1.1.m1.2.2.1.1.2.1.cmml" xref="S5.SS3.p1.1.m1.2.2.1.1.2.1"></times><ci id="S5.SS3.p1.1.m1.2.2.1.1.2.2.cmml" xref="S5.SS3.p1.1.m1.2.2.1.1.2.2">𝐹</ci><cn id="S5.SS3.p1.1.m1.1.1.cmml" type="integer" xref="S5.SS3.p1.1.m1.1.1">4</cn></apply><cn id="S5.SS3.p1.1.m1.2.2.1.1.3.cmml" type="float" xref="S5.SS3.p1.1.m1.2.2.1.1.3">4.591</cn></apply><apply id="S5.SS3.p1.1.m1.3.3.2.2.3.cmml" xref="S5.SS3.p1.1.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="S5.SS3.p1.1.m1.3.3.2.2.3a.cmml" xref="S5.SS3.p1.1.m1.3.3.2.2.2.3">formulae-sequence</csymbol><apply id="S5.SS3.p1.1.m1.3.3.2.2.1.1.cmml" xref="S5.SS3.p1.1.m1.3.3.2.2.1.1"><eq id="S5.SS3.p1.1.m1.3.3.2.2.1.1.1.cmml" xref="S5.SS3.p1.1.m1.3.3.2.2.1.1.1"></eq><ci id="S5.SS3.p1.1.m1.3.3.2.2.1.1.2.cmml" xref="S5.SS3.p1.1.m1.3.3.2.2.1.1.2">𝑝</ci><cn id="S5.SS3.p1.1.m1.3.3.2.2.1.1.3.cmml" type="float" xref="S5.SS3.p1.1.m1.3.3.2.2.1.1.3">0.002</cn></apply><apply id="S5.SS3.p1.1.m1.3.3.2.2.2.2.cmml" xref="S5.SS3.p1.1.m1.3.3.2.2.2.2"><eq id="S5.SS3.p1.1.m1.3.3.2.2.2.2.1.cmml" xref="S5.SS3.p1.1.m1.3.3.2.2.2.2.1"></eq><apply id="S5.SS3.p1.1.m1.3.3.2.2.2.2.2.cmml" xref="S5.SS3.p1.1.m1.3.3.2.2.2.2.2"><csymbol cd="ambiguous" id="S5.SS3.p1.1.m1.3.3.2.2.2.2.2.1.cmml" xref="S5.SS3.p1.1.m1.3.3.2.2.2.2.2">superscript</csymbol><ci id="S5.SS3.p1.1.m1.3.3.2.2.2.2.2.2.cmml" xref="S5.SS3.p1.1.m1.3.3.2.2.2.2.2.2">𝜂</ci><cn id="S5.SS3.p1.1.m1.3.3.2.2.2.2.2.3.cmml" type="integer" xref="S5.SS3.p1.1.m1.3.3.2.2.2.2.2.3">2</cn></apply><cn id="S5.SS3.p1.1.m1.3.3.2.2.2.2.3.cmml" type="float" xref="S5.SS3.p1.1.m1.3.3.2.2.2.2.3">0.137</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.1.m1.3c">F(4)=4.591,p=0.002,\eta^{2}=0.137</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p1.1.m1.3d">italic_F ( 4 ) = 4.591 , italic_p = 0.002 , italic_η start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT = 0.137</annotation></semantics></math> for content similarity, <math alttext="F(4)=7.134,p=0.000,\eta^{2}=0.197" class="ltx_Math" display="inline" id="S5.SS3.p1.2.m2.3"><semantics id="S5.SS3.p1.2.m2.3a"><mrow id="S5.SS3.p1.2.m2.3.3.2" xref="S5.SS3.p1.2.m2.3.3.3.cmml"><mrow id="S5.SS3.p1.2.m2.2.2.1.1" xref="S5.SS3.p1.2.m2.2.2.1.1.cmml"><mrow id="S5.SS3.p1.2.m2.2.2.1.1.2" xref="S5.SS3.p1.2.m2.2.2.1.1.2.cmml"><mi id="S5.SS3.p1.2.m2.2.2.1.1.2.2" xref="S5.SS3.p1.2.m2.2.2.1.1.2.2.cmml">F</mi><mo id="S5.SS3.p1.2.m2.2.2.1.1.2.1" xref="S5.SS3.p1.2.m2.2.2.1.1.2.1.cmml">⁢</mo><mrow id="S5.SS3.p1.2.m2.2.2.1.1.2.3.2" xref="S5.SS3.p1.2.m2.2.2.1.1.2.cmml"><mo id="S5.SS3.p1.2.m2.2.2.1.1.2.3.2.1" stretchy="false" xref="S5.SS3.p1.2.m2.2.2.1.1.2.cmml">(</mo><mn id="S5.SS3.p1.2.m2.1.1" xref="S5.SS3.p1.2.m2.1.1.cmml">4</mn><mo id="S5.SS3.p1.2.m2.2.2.1.1.2.3.2.2" stretchy="false" xref="S5.SS3.p1.2.m2.2.2.1.1.2.cmml">)</mo></mrow></mrow><mo id="S5.SS3.p1.2.m2.2.2.1.1.1" xref="S5.SS3.p1.2.m2.2.2.1.1.1.cmml">=</mo><mn id="S5.SS3.p1.2.m2.2.2.1.1.3" xref="S5.SS3.p1.2.m2.2.2.1.1.3.cmml">7.134</mn></mrow><mo id="S5.SS3.p1.2.m2.3.3.2.3" xref="S5.SS3.p1.2.m2.3.3.3a.cmml">,</mo><mrow id="S5.SS3.p1.2.m2.3.3.2.2.2" xref="S5.SS3.p1.2.m2.3.3.2.2.3.cmml"><mrow id="S5.SS3.p1.2.m2.3.3.2.2.1.1" xref="S5.SS3.p1.2.m2.3.3.2.2.1.1.cmml"><mi id="S5.SS3.p1.2.m2.3.3.2.2.1.1.2" xref="S5.SS3.p1.2.m2.3.3.2.2.1.1.2.cmml">p</mi><mo id="S5.SS3.p1.2.m2.3.3.2.2.1.1.1" xref="S5.SS3.p1.2.m2.3.3.2.2.1.1.1.cmml">=</mo><mn id="S5.SS3.p1.2.m2.3.3.2.2.1.1.3" xref="S5.SS3.p1.2.m2.3.3.2.2.1.1.3.cmml">0.000</mn></mrow><mo id="S5.SS3.p1.2.m2.3.3.2.2.2.3" xref="S5.SS3.p1.2.m2.3.3.2.2.3a.cmml">,</mo><mrow id="S5.SS3.p1.2.m2.3.3.2.2.2.2" xref="S5.SS3.p1.2.m2.3.3.2.2.2.2.cmml"><msup id="S5.SS3.p1.2.m2.3.3.2.2.2.2.2" xref="S5.SS3.p1.2.m2.3.3.2.2.2.2.2.cmml"><mi id="S5.SS3.p1.2.m2.3.3.2.2.2.2.2.2" xref="S5.SS3.p1.2.m2.3.3.2.2.2.2.2.2.cmml">η</mi><mn id="S5.SS3.p1.2.m2.3.3.2.2.2.2.2.3" xref="S5.SS3.p1.2.m2.3.3.2.2.2.2.2.3.cmml">2</mn></msup><mo id="S5.SS3.p1.2.m2.3.3.2.2.2.2.1" xref="S5.SS3.p1.2.m2.3.3.2.2.2.2.1.cmml">=</mo><mn id="S5.SS3.p1.2.m2.3.3.2.2.2.2.3" xref="S5.SS3.p1.2.m2.3.3.2.2.2.2.3.cmml">0.197</mn></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.2.m2.3b"><apply id="S5.SS3.p1.2.m2.3.3.3.cmml" xref="S5.SS3.p1.2.m2.3.3.2"><csymbol cd="ambiguous" id="S5.SS3.p1.2.m2.3.3.3a.cmml" xref="S5.SS3.p1.2.m2.3.3.2.3">formulae-sequence</csymbol><apply id="S5.SS3.p1.2.m2.2.2.1.1.cmml" xref="S5.SS3.p1.2.m2.2.2.1.1"><eq id="S5.SS3.p1.2.m2.2.2.1.1.1.cmml" xref="S5.SS3.p1.2.m2.2.2.1.1.1"></eq><apply id="S5.SS3.p1.2.m2.2.2.1.1.2.cmml" xref="S5.SS3.p1.2.m2.2.2.1.1.2"><times id="S5.SS3.p1.2.m2.2.2.1.1.2.1.cmml" xref="S5.SS3.p1.2.m2.2.2.1.1.2.1"></times><ci id="S5.SS3.p1.2.m2.2.2.1.1.2.2.cmml" xref="S5.SS3.p1.2.m2.2.2.1.1.2.2">𝐹</ci><cn id="S5.SS3.p1.2.m2.1.1.cmml" type="integer" xref="S5.SS3.p1.2.m2.1.1">4</cn></apply><cn id="S5.SS3.p1.2.m2.2.2.1.1.3.cmml" type="float" xref="S5.SS3.p1.2.m2.2.2.1.1.3">7.134</cn></apply><apply id="S5.SS3.p1.2.m2.3.3.2.2.3.cmml" xref="S5.SS3.p1.2.m2.3.3.2.2.2"><csymbol cd="ambiguous" id="S5.SS3.p1.2.m2.3.3.2.2.3a.cmml" xref="S5.SS3.p1.2.m2.3.3.2.2.2.3">formulae-sequence</csymbol><apply id="S5.SS3.p1.2.m2.3.3.2.2.1.1.cmml" xref="S5.SS3.p1.2.m2.3.3.2.2.1.1"><eq id="S5.SS3.p1.2.m2.3.3.2.2.1.1.1.cmml" xref="S5.SS3.p1.2.m2.3.3.2.2.1.1.1"></eq><ci id="S5.SS3.p1.2.m2.3.3.2.2.1.1.2.cmml" xref="S5.SS3.p1.2.m2.3.3.2.2.1.1.2">𝑝</ci><cn id="S5.SS3.p1.2.m2.3.3.2.2.1.1.3.cmml" type="float" xref="S5.SS3.p1.2.m2.3.3.2.2.1.1.3">0.000</cn></apply><apply id="S5.SS3.p1.2.m2.3.3.2.2.2.2.cmml" xref="S5.SS3.p1.2.m2.3.3.2.2.2.2"><eq id="S5.SS3.p1.2.m2.3.3.2.2.2.2.1.cmml" xref="S5.SS3.p1.2.m2.3.3.2.2.2.2.1"></eq><apply id="S5.SS3.p1.2.m2.3.3.2.2.2.2.2.cmml" xref="S5.SS3.p1.2.m2.3.3.2.2.2.2.2"><csymbol cd="ambiguous" id="S5.SS3.p1.2.m2.3.3.2.2.2.2.2.1.cmml" xref="S5.SS3.p1.2.m2.3.3.2.2.2.2.2">superscript</csymbol><ci id="S5.SS3.p1.2.m2.3.3.2.2.2.2.2.2.cmml" xref="S5.SS3.p1.2.m2.3.3.2.2.2.2.2.2">𝜂</ci><cn id="S5.SS3.p1.2.m2.3.3.2.2.2.2.2.3.cmml" type="integer" xref="S5.SS3.p1.2.m2.3.3.2.2.2.2.2.3">2</cn></apply><cn id="S5.SS3.p1.2.m2.3.3.2.2.2.2.3.cmml" type="float" xref="S5.SS3.p1.2.m2.3.3.2.2.2.2.3">0.197</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.2.m2.3c">F(4)=7.134,p=0.000,\eta^{2}=0.197</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p1.2.m2.3d">italic_F ( 4 ) = 7.134 , italic_p = 0.000 , italic_η start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT = 0.197</annotation></semantics></math> for instruction alignment, and <math alttext="F(4)=4.781,p=0.001,\eta^{2}=0.142" class="ltx_Math" display="inline" id="S5.SS3.p1.3.m3.3"><semantics id="S5.SS3.p1.3.m3.3a"><mrow id="S5.SS3.p1.3.m3.3.3.2" xref="S5.SS3.p1.3.m3.3.3.3.cmml"><mrow id="S5.SS3.p1.3.m3.2.2.1.1" xref="S5.SS3.p1.3.m3.2.2.1.1.cmml"><mrow id="S5.SS3.p1.3.m3.2.2.1.1.2" xref="S5.SS3.p1.3.m3.2.2.1.1.2.cmml"><mi id="S5.SS3.p1.3.m3.2.2.1.1.2.2" xref="S5.SS3.p1.3.m3.2.2.1.1.2.2.cmml">F</mi><mo id="S5.SS3.p1.3.m3.2.2.1.1.2.1" xref="S5.SS3.p1.3.m3.2.2.1.1.2.1.cmml">⁢</mo><mrow id="S5.SS3.p1.3.m3.2.2.1.1.2.3.2" xref="S5.SS3.p1.3.m3.2.2.1.1.2.cmml"><mo id="S5.SS3.p1.3.m3.2.2.1.1.2.3.2.1" stretchy="false" xref="S5.SS3.p1.3.m3.2.2.1.1.2.cmml">(</mo><mn id="S5.SS3.p1.3.m3.1.1" xref="S5.SS3.p1.3.m3.1.1.cmml">4</mn><mo id="S5.SS3.p1.3.m3.2.2.1.1.2.3.2.2" stretchy="false" xref="S5.SS3.p1.3.m3.2.2.1.1.2.cmml">)</mo></mrow></mrow><mo id="S5.SS3.p1.3.m3.2.2.1.1.1" xref="S5.SS3.p1.3.m3.2.2.1.1.1.cmml">=</mo><mn id="S5.SS3.p1.3.m3.2.2.1.1.3" xref="S5.SS3.p1.3.m3.2.2.1.1.3.cmml">4.781</mn></mrow><mo id="S5.SS3.p1.3.m3.3.3.2.3" xref="S5.SS3.p1.3.m3.3.3.3a.cmml">,</mo><mrow id="S5.SS3.p1.3.m3.3.3.2.2.2" xref="S5.SS3.p1.3.m3.3.3.2.2.3.cmml"><mrow id="S5.SS3.p1.3.m3.3.3.2.2.1.1" xref="S5.SS3.p1.3.m3.3.3.2.2.1.1.cmml"><mi id="S5.SS3.p1.3.m3.3.3.2.2.1.1.2" xref="S5.SS3.p1.3.m3.3.3.2.2.1.1.2.cmml">p</mi><mo id="S5.SS3.p1.3.m3.3.3.2.2.1.1.1" xref="S5.SS3.p1.3.m3.3.3.2.2.1.1.1.cmml">=</mo><mn id="S5.SS3.p1.3.m3.3.3.2.2.1.1.3" xref="S5.SS3.p1.3.m3.3.3.2.2.1.1.3.cmml">0.001</mn></mrow><mo id="S5.SS3.p1.3.m3.3.3.2.2.2.3" xref="S5.SS3.p1.3.m3.3.3.2.2.3a.cmml">,</mo><mrow id="S5.SS3.p1.3.m3.3.3.2.2.2.2" xref="S5.SS3.p1.3.m3.3.3.2.2.2.2.cmml"><msup id="S5.SS3.p1.3.m3.3.3.2.2.2.2.2" xref="S5.SS3.p1.3.m3.3.3.2.2.2.2.2.cmml"><mi id="S5.SS3.p1.3.m3.3.3.2.2.2.2.2.2" xref="S5.SS3.p1.3.m3.3.3.2.2.2.2.2.2.cmml">η</mi><mn id="S5.SS3.p1.3.m3.3.3.2.2.2.2.2.3" xref="S5.SS3.p1.3.m3.3.3.2.2.2.2.2.3.cmml">2</mn></msup><mo id="S5.SS3.p1.3.m3.3.3.2.2.2.2.1" xref="S5.SS3.p1.3.m3.3.3.2.2.2.2.1.cmml">=</mo><mn id="S5.SS3.p1.3.m3.3.3.2.2.2.2.3" xref="S5.SS3.p1.3.m3.3.3.2.2.2.2.3.cmml">0.142</mn></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.3.m3.3b"><apply id="S5.SS3.p1.3.m3.3.3.3.cmml" xref="S5.SS3.p1.3.m3.3.3.2"><csymbol cd="ambiguous" id="S5.SS3.p1.3.m3.3.3.3a.cmml" xref="S5.SS3.p1.3.m3.3.3.2.3">formulae-sequence</csymbol><apply id="S5.SS3.p1.3.m3.2.2.1.1.cmml" xref="S5.SS3.p1.3.m3.2.2.1.1"><eq id="S5.SS3.p1.3.m3.2.2.1.1.1.cmml" xref="S5.SS3.p1.3.m3.2.2.1.1.1"></eq><apply id="S5.SS3.p1.3.m3.2.2.1.1.2.cmml" xref="S5.SS3.p1.3.m3.2.2.1.1.2"><times id="S5.SS3.p1.3.m3.2.2.1.1.2.1.cmml" xref="S5.SS3.p1.3.m3.2.2.1.1.2.1"></times><ci id="S5.SS3.p1.3.m3.2.2.1.1.2.2.cmml" xref="S5.SS3.p1.3.m3.2.2.1.1.2.2">𝐹</ci><cn id="S5.SS3.p1.3.m3.1.1.cmml" type="integer" xref="S5.SS3.p1.3.m3.1.1">4</cn></apply><cn id="S5.SS3.p1.3.m3.2.2.1.1.3.cmml" type="float" xref="S5.SS3.p1.3.m3.2.2.1.1.3">4.781</cn></apply><apply id="S5.SS3.p1.3.m3.3.3.2.2.3.cmml" xref="S5.SS3.p1.3.m3.3.3.2.2.2"><csymbol cd="ambiguous" id="S5.SS3.p1.3.m3.3.3.2.2.3a.cmml" xref="S5.SS3.p1.3.m3.3.3.2.2.2.3">formulae-sequence</csymbol><apply id="S5.SS3.p1.3.m3.3.3.2.2.1.1.cmml" xref="S5.SS3.p1.3.m3.3.3.2.2.1.1"><eq id="S5.SS3.p1.3.m3.3.3.2.2.1.1.1.cmml" xref="S5.SS3.p1.3.m3.3.3.2.2.1.1.1"></eq><ci id="S5.SS3.p1.3.m3.3.3.2.2.1.1.2.cmml" xref="S5.SS3.p1.3.m3.3.3.2.2.1.1.2">𝑝</ci><cn id="S5.SS3.p1.3.m3.3.3.2.2.1.1.3.cmml" type="float" xref="S5.SS3.p1.3.m3.3.3.2.2.1.1.3">0.001</cn></apply><apply id="S5.SS3.p1.3.m3.3.3.2.2.2.2.cmml" xref="S5.SS3.p1.3.m3.3.3.2.2.2.2"><eq id="S5.SS3.p1.3.m3.3.3.2.2.2.2.1.cmml" xref="S5.SS3.p1.3.m3.3.3.2.2.2.2.1"></eq><apply id="S5.SS3.p1.3.m3.3.3.2.2.2.2.2.cmml" xref="S5.SS3.p1.3.m3.3.3.2.2.2.2.2"><csymbol cd="ambiguous" id="S5.SS3.p1.3.m3.3.3.2.2.2.2.2.1.cmml" xref="S5.SS3.p1.3.m3.3.3.2.2.2.2.2">superscript</csymbol><ci id="S5.SS3.p1.3.m3.3.3.2.2.2.2.2.2.cmml" xref="S5.SS3.p1.3.m3.3.3.2.2.2.2.2.2">𝜂</ci><cn id="S5.SS3.p1.3.m3.3.3.2.2.2.2.2.3.cmml" type="integer" xref="S5.SS3.p1.3.m3.3.3.2.2.2.2.2.3">2</cn></apply><cn id="S5.SS3.p1.3.m3.3.3.2.2.2.2.3.cmml" type="float" xref="S5.SS3.p1.3.m3.3.3.2.2.2.2.3">0.142</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.3.m3.3c">F(4)=4.781,p=0.001,\eta^{2}=0.142</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p1.3.m3.3d">italic_F ( 4 ) = 4.781 , italic_p = 0.001 , italic_η start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT = 0.142</annotation></semantics></math> for motion quality, with all <math alttext="\alpha=0.05" class="ltx_Math" display="inline" id="S5.SS3.p1.4.m4.1"><semantics id="S5.SS3.p1.4.m4.1a"><mrow id="S5.SS3.p1.4.m4.1.1" xref="S5.SS3.p1.4.m4.1.1.cmml"><mi id="S5.SS3.p1.4.m4.1.1.2" xref="S5.SS3.p1.4.m4.1.1.2.cmml">α</mi><mo id="S5.SS3.p1.4.m4.1.1.1" xref="S5.SS3.p1.4.m4.1.1.1.cmml">=</mo><mn id="S5.SS3.p1.4.m4.1.1.3" xref="S5.SS3.p1.4.m4.1.1.3.cmml">0.05</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.4.m4.1b"><apply id="S5.SS3.p1.4.m4.1.1.cmml" xref="S5.SS3.p1.4.m4.1.1"><eq id="S5.SS3.p1.4.m4.1.1.1.cmml" xref="S5.SS3.p1.4.m4.1.1.1"></eq><ci id="S5.SS3.p1.4.m4.1.1.2.cmml" xref="S5.SS3.p1.4.m4.1.1.2">𝛼</ci><cn id="S5.SS3.p1.4.m4.1.1.3.cmml" type="float" xref="S5.SS3.p1.4.m4.1.1.3">0.05</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.4.m4.1c">\alpha=0.05</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p1.4.m4.1d">italic_α = 0.05</annotation></semantics></math>. The estimated marginal mean of the rated score is reported in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#S5.F5" title="Figure 5 ‣ Table 2 ‣ 5.3 Motion Editing ‣ 5 Experiments ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_tag">5</span></a><span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>We plotted the difference in a post hoc pairwise comparison of the proposed method only. We denote * as <math alttext="0.01&lt;p&lt;0.05" class="ltx_Math" display="inline" id="footnote1.m1.1"><semantics id="footnote1.m1.1b"><mrow id="footnote1.m1.1.1" xref="footnote1.m1.1.1.cmml"><mn id="footnote1.m1.1.1.2" xref="footnote1.m1.1.1.2.cmml">0.01</mn><mo id="footnote1.m1.1.1.3" xref="footnote1.m1.1.1.3.cmml">&lt;</mo><mi id="footnote1.m1.1.1.4" xref="footnote1.m1.1.1.4.cmml">p</mi><mo id="footnote1.m1.1.1.5" xref="footnote1.m1.1.1.5.cmml">&lt;</mo><mn id="footnote1.m1.1.1.6" xref="footnote1.m1.1.1.6.cmml">0.05</mn></mrow><annotation-xml encoding="MathML-Content" id="footnote1.m1.1c"><apply id="footnote1.m1.1.1.cmml" xref="footnote1.m1.1.1"><and id="footnote1.m1.1.1a.cmml" xref="footnote1.m1.1.1"></and><apply id="footnote1.m1.1.1b.cmml" xref="footnote1.m1.1.1"><lt id="footnote1.m1.1.1.3.cmml" xref="footnote1.m1.1.1.3"></lt><cn id="footnote1.m1.1.1.2.cmml" type="float" xref="footnote1.m1.1.1.2">0.01</cn><ci id="footnote1.m1.1.1.4.cmml" xref="footnote1.m1.1.1.4">𝑝</ci></apply><apply id="footnote1.m1.1.1c.cmml" xref="footnote1.m1.1.1"><lt id="footnote1.m1.1.1.5.cmml" xref="footnote1.m1.1.1.5"></lt><share href="https://arxiv.org/html/2410.05628v2#footnote1.m1.1.1.4.cmml" id="footnote1.m1.1.1d.cmml" xref="footnote1.m1.1.1"></share><cn id="footnote1.m1.1.1.6.cmml" type="float" xref="footnote1.m1.1.1.6">0.05</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="footnote1.m1.1d">0.01&lt;p&lt;0.05</annotation><annotation encoding="application/x-llamapun" id="footnote1.m1.1e">0.01 &lt; italic_p &lt; 0.05</annotation></semantics></math>, ** as <math alttext="p&lt;0.01" class="ltx_Math" display="inline" id="footnote1.m2.1"><semantics id="footnote1.m2.1b"><mrow id="footnote1.m2.1.1" xref="footnote1.m2.1.1.cmml"><mi id="footnote1.m2.1.1.2" xref="footnote1.m2.1.1.2.cmml">p</mi><mo id="footnote1.m2.1.1.1" xref="footnote1.m2.1.1.1.cmml">&lt;</mo><mn id="footnote1.m2.1.1.3" xref="footnote1.m2.1.1.3.cmml">0.01</mn></mrow><annotation-xml encoding="MathML-Content" id="footnote1.m2.1c"><apply id="footnote1.m2.1.1.cmml" xref="footnote1.m2.1.1"><lt id="footnote1.m2.1.1.1.cmml" xref="footnote1.m2.1.1.1"></lt><ci id="footnote1.m2.1.1.2.cmml" xref="footnote1.m2.1.1.2">𝑝</ci><cn id="footnote1.m2.1.1.3.cmml" type="float" xref="footnote1.m2.1.1.3">0.01</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="footnote1.m2.1d">p&lt;0.01</annotation><annotation encoding="application/x-llamapun" id="footnote1.m2.1e">italic_p &lt; 0.01</annotation></semantics></math>, and *** as <math alttext="p&lt;0.001" class="ltx_Math" display="inline" id="footnote1.m3.1"><semantics id="footnote1.m3.1b"><mrow id="footnote1.m3.1.1" xref="footnote1.m3.1.1.cmml"><mi id="footnote1.m3.1.1.2" xref="footnote1.m3.1.1.2.cmml">p</mi><mo id="footnote1.m3.1.1.1" xref="footnote1.m3.1.1.1.cmml">&lt;</mo><mn id="footnote1.m3.1.1.3" xref="footnote1.m3.1.1.3.cmml">0.001</mn></mrow><annotation-xml encoding="MathML-Content" id="footnote1.m3.1c"><apply id="footnote1.m3.1.1.cmml" xref="footnote1.m3.1.1"><lt id="footnote1.m3.1.1.1.cmml" xref="footnote1.m3.1.1.1"></lt><ci id="footnote1.m3.1.1.2.cmml" xref="footnote1.m3.1.1.2">𝑝</ci><cn id="footnote1.m3.1.1.3.cmml" type="float" xref="footnote1.m3.1.1.3">0.001</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="footnote1.m3.1d">p&lt;0.001</annotation><annotation encoding="application/x-llamapun" id="footnote1.m3.1e">italic_p &lt; 0.001</annotation></semantics></math>. The error bars represent 95% confidence intervals. </span></span></span>. The results show that the proposed method had better instruction alignment, quality, and content consistency across other baselines with significant differences.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS3.p2">
<p class="ltx_p" id="S5.SS3.p2.2">During post hoc pairwise comparisons, we identified a significant difference, with our proposed method outperforming the two-stage model (TM2T <cite class="ltx_cite ltx_citemacro_citep">(Guo et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib14" title="">2022</a>)</cite> with InterGEN <cite class="ltx_cite ltx_citemacro_citep">(Liang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib22" title="">2024</a>)</cite>) in content similarity (<math alttext="p=0.017" class="ltx_Math" display="inline" id="S5.SS3.p2.1.m1.1"><semantics id="S5.SS3.p2.1.m1.1a"><mrow id="S5.SS3.p2.1.m1.1.1" xref="S5.SS3.p2.1.m1.1.1.cmml"><mi id="S5.SS3.p2.1.m1.1.1.2" xref="S5.SS3.p2.1.m1.1.1.2.cmml">p</mi><mo id="S5.SS3.p2.1.m1.1.1.1" xref="S5.SS3.p2.1.m1.1.1.1.cmml">=</mo><mn id="S5.SS3.p2.1.m1.1.1.3" xref="S5.SS3.p2.1.m1.1.1.3.cmml">0.017</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.1.m1.1b"><apply id="S5.SS3.p2.1.m1.1.1.cmml" xref="S5.SS3.p2.1.m1.1.1"><eq id="S5.SS3.p2.1.m1.1.1.1.cmml" xref="S5.SS3.p2.1.m1.1.1.1"></eq><ci id="S5.SS3.p2.1.m1.1.1.2.cmml" xref="S5.SS3.p2.1.m1.1.1.2">𝑝</ci><cn id="S5.SS3.p2.1.m1.1.1.3.cmml" type="float" xref="S5.SS3.p2.1.m1.1.1.3">0.017</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.1.m1.1c">p=0.017</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p2.1.m1.1d">italic_p = 0.017</annotation></semantics></math>) and instruction alignment (<math alttext="p=0.010" class="ltx_Math" display="inline" id="S5.SS3.p2.2.m2.1"><semantics id="S5.SS3.p2.2.m2.1a"><mrow id="S5.SS3.p2.2.m2.1.1" xref="S5.SS3.p2.2.m2.1.1.cmml"><mi id="S5.SS3.p2.2.m2.1.1.2" xref="S5.SS3.p2.2.m2.1.1.2.cmml">p</mi><mo id="S5.SS3.p2.2.m2.1.1.1" xref="S5.SS3.p2.2.m2.1.1.1.cmml">=</mo><mn id="S5.SS3.p2.2.m2.1.1.3" xref="S5.SS3.p2.2.m2.1.1.3.cmml">0.010</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.2.m2.1b"><apply id="S5.SS3.p2.2.m2.1.1.cmml" xref="S5.SS3.p2.2.m2.1.1"><eq id="S5.SS3.p2.2.m2.1.1.1.cmml" xref="S5.SS3.p2.2.m2.1.1.1"></eq><ci id="S5.SS3.p2.2.m2.1.1.2.cmml" xref="S5.SS3.p2.2.m2.1.1.2">𝑝</ci><cn id="S5.SS3.p2.2.m2.1.1.3.cmml" type="float" xref="S5.SS3.p2.2.m2.1.1.3">0.010</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.2.m2.1c">p=0.010</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p2.2.m2.1d">italic_p = 0.010</annotation></semantics></math>).
The two-stage model showed lower content similarity due to motion-to-text conversion errors, leading to unintended motions, whereas our unified framework avoids such error accumulation. Additionally, the two-stage model struggled with instruction alignment because InterGEN was trained to generate motions from captions, limiting its ability to adapt to varying personas or contexts. In contrast, our method, trained on diverse instructions and tasks, demonstrated superior reasoning and adaptability, resulting in more accurate motion generation based on instructions and source motions.</p>
</div>
<figure class="ltx_figure" id="S5.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="283" id="S5.F6.g1" src="x5.png" width="764"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Generated samples for interactive motion editing. The proposed method excels in capturing nuances, outperforming alternatives in content similarity and instruction alignment.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S5.SS3.p3">
<p class="ltx_p" id="S5.SS3.p3.10">In post hoc pairwise comparisons with <math alttext="\text{MotionGPT}^{*}_{I}" class="ltx_Math" display="inline" id="S5.SS3.p3.1.m1.1"><semantics id="S5.SS3.p3.1.m1.1a"><msubsup id="S5.SS3.p3.1.m1.1.1" xref="S5.SS3.p3.1.m1.1.1.cmml"><mtext id="S5.SS3.p3.1.m1.1.1.2.2" xref="S5.SS3.p3.1.m1.1.1.2.2a.cmml">MotionGPT</mtext><mi id="S5.SS3.p3.1.m1.1.1.3" xref="S5.SS3.p3.1.m1.1.1.3.cmml">I</mi><mo id="S5.SS3.p3.1.m1.1.1.2.3" xref="S5.SS3.p3.1.m1.1.1.2.3.cmml">∗</mo></msubsup><annotation-xml encoding="MathML-Content" id="S5.SS3.p3.1.m1.1b"><apply id="S5.SS3.p3.1.m1.1.1.cmml" xref="S5.SS3.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS3.p3.1.m1.1.1.1.cmml" xref="S5.SS3.p3.1.m1.1.1">subscript</csymbol><apply id="S5.SS3.p3.1.m1.1.1.2.cmml" xref="S5.SS3.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS3.p3.1.m1.1.1.2.1.cmml" xref="S5.SS3.p3.1.m1.1.1">superscript</csymbol><ci id="S5.SS3.p3.1.m1.1.1.2.2a.cmml" xref="S5.SS3.p3.1.m1.1.1.2.2"><mtext id="S5.SS3.p3.1.m1.1.1.2.2.cmml" xref="S5.SS3.p3.1.m1.1.1.2.2">MotionGPT</mtext></ci><times id="S5.SS3.p3.1.m1.1.1.2.3.cmml" xref="S5.SS3.p3.1.m1.1.1.2.3"></times></apply><ci id="S5.SS3.p3.1.m1.1.1.3.cmml" xref="S5.SS3.p3.1.m1.1.1.3">𝐼</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p3.1.m1.1c">\text{MotionGPT}^{*}_{I}</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p3.1.m1.1d">MotionGPT start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_I end_POSTSUBSCRIPT</annotation></semantics></math>, we observed significant differences, with our proposed method performing better in content similarity (<math alttext="p=0.005" class="ltx_Math" display="inline" id="S5.SS3.p3.2.m2.1"><semantics id="S5.SS3.p3.2.m2.1a"><mrow id="S5.SS3.p3.2.m2.1.1" xref="S5.SS3.p3.2.m2.1.1.cmml"><mi id="S5.SS3.p3.2.m2.1.1.2" xref="S5.SS3.p3.2.m2.1.1.2.cmml">p</mi><mo id="S5.SS3.p3.2.m2.1.1.1" xref="S5.SS3.p3.2.m2.1.1.1.cmml">=</mo><mn id="S5.SS3.p3.2.m2.1.1.3" xref="S5.SS3.p3.2.m2.1.1.3.cmml">0.005</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p3.2.m2.1b"><apply id="S5.SS3.p3.2.m2.1.1.cmml" xref="S5.SS3.p3.2.m2.1.1"><eq id="S5.SS3.p3.2.m2.1.1.1.cmml" xref="S5.SS3.p3.2.m2.1.1.1"></eq><ci id="S5.SS3.p3.2.m2.1.1.2.cmml" xref="S5.SS3.p3.2.m2.1.1.2">𝑝</ci><cn id="S5.SS3.p3.2.m2.1.1.3.cmml" type="float" xref="S5.SS3.p3.2.m2.1.1.3">0.005</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p3.2.m2.1c">p=0.005</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p3.2.m2.1d">italic_p = 0.005</annotation></semantics></math>), instruction alignment (<math alttext="p&lt;0.0005" class="ltx_Math" display="inline" id="S5.SS3.p3.3.m3.1"><semantics id="S5.SS3.p3.3.m3.1a"><mrow id="S5.SS3.p3.3.m3.1.1" xref="S5.SS3.p3.3.m3.1.1.cmml"><mi id="S5.SS3.p3.3.m3.1.1.2" xref="S5.SS3.p3.3.m3.1.1.2.cmml">p</mi><mo id="S5.SS3.p3.3.m3.1.1.1" xref="S5.SS3.p3.3.m3.1.1.1.cmml">&lt;</mo><mn id="S5.SS3.p3.3.m3.1.1.3" xref="S5.SS3.p3.3.m3.1.1.3.cmml">0.0005</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p3.3.m3.1b"><apply id="S5.SS3.p3.3.m3.1.1.cmml" xref="S5.SS3.p3.3.m3.1.1"><lt id="S5.SS3.p3.3.m3.1.1.1.cmml" xref="S5.SS3.p3.3.m3.1.1.1"></lt><ci id="S5.SS3.p3.3.m3.1.1.2.cmml" xref="S5.SS3.p3.3.m3.1.1.2">𝑝</ci><cn id="S5.SS3.p3.3.m3.1.1.3.cmml" type="float" xref="S5.SS3.p3.3.m3.1.1.3">0.0005</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p3.3.m3.1c">p&lt;0.0005</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p3.3.m3.1d">italic_p &lt; 0.0005</annotation></semantics></math>), and motion quality (<math alttext="p=0.009" class="ltx_Math" display="inline" id="S5.SS3.p3.4.m4.1"><semantics id="S5.SS3.p3.4.m4.1a"><mrow id="S5.SS3.p3.4.m4.1.1" xref="S5.SS3.p3.4.m4.1.1.cmml"><mi id="S5.SS3.p3.4.m4.1.1.2" xref="S5.SS3.p3.4.m4.1.1.2.cmml">p</mi><mo id="S5.SS3.p3.4.m4.1.1.1" xref="S5.SS3.p3.4.m4.1.1.1.cmml">=</mo><mn id="S5.SS3.p3.4.m4.1.1.3" xref="S5.SS3.p3.4.m4.1.1.3.cmml">0.009</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p3.4.m4.1b"><apply id="S5.SS3.p3.4.m4.1.1.cmml" xref="S5.SS3.p3.4.m4.1.1"><eq id="S5.SS3.p3.4.m4.1.1.1.cmml" xref="S5.SS3.p3.4.m4.1.1.1"></eq><ci id="S5.SS3.p3.4.m4.1.1.2.cmml" xref="S5.SS3.p3.4.m4.1.1.2">𝑝</ci><cn id="S5.SS3.p3.4.m4.1.1.3.cmml" type="float" xref="S5.SS3.p3.4.m4.1.1.3">0.009</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p3.4.m4.1c">p=0.009</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p3.4.m4.1d">italic_p = 0.009</annotation></semantics></math>). This suggests that the VQ-VAE-based tokenizer and conditional generation model negatively impacted performance. Additionally, compared to <span class="ltx_text ltx_font_smallcaps" id="S5.SS3.p3.10.3">VIM</span> w/o <span class="ltx_text ltx_markedasmath ltx_font_smallcaps" id="S5.SS3.p3.10.4">Inter</span><span class="ltx_text ltx_font_smallcaps" id="S5.SS3.p3.6.1">-<math alttext="\text{MT}^{2}" class="ltx_Math" display="inline" id="S5.SS3.p3.6.1.m1.1"><semantics id="S5.SS3.p3.6.1.m1.1a"><msup id="S5.SS3.p3.6.1.m1.1.1" xref="S5.SS3.p3.6.1.m1.1.1.cmml"><mtext class="ltx_font_smallcaps" id="S5.SS3.p3.6.1.m1.1.1.2" xref="S5.SS3.p3.6.1.m1.1.1.2a.cmml">MT</mtext><mn id="S5.SS3.p3.6.1.m1.1.1.3" xref="S5.SS3.p3.6.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S5.SS3.p3.6.1.m1.1b"><apply id="S5.SS3.p3.6.1.m1.1.1.cmml" xref="S5.SS3.p3.6.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS3.p3.6.1.m1.1.1.1.cmml" xref="S5.SS3.p3.6.1.m1.1.1">superscript</csymbol><ci id="S5.SS3.p3.6.1.m1.1.1.2a.cmml" xref="S5.SS3.p3.6.1.m1.1.1.2"><mtext class="ltx_font_smallcaps" id="S5.SS3.p3.6.1.m1.1.1.2.cmml" xref="S5.SS3.p3.6.1.m1.1.1.2">MT</mtext></ci><cn id="S5.SS3.p3.6.1.m1.1.1.3.cmml" type="integer" xref="S5.SS3.p3.6.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p3.6.1.m1.1c">\text{MT}^{2}</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p3.6.1.m1.1d">MT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math></span>, there were significant differences in content similarity (<math alttext="p=0.010" class="ltx_Math" display="inline" id="S5.SS3.p3.7.m6.1"><semantics id="S5.SS3.p3.7.m6.1a"><mrow id="S5.SS3.p3.7.m6.1.1" xref="S5.SS3.p3.7.m6.1.1.cmml"><mi id="S5.SS3.p3.7.m6.1.1.2" xref="S5.SS3.p3.7.m6.1.1.2.cmml">p</mi><mo id="S5.SS3.p3.7.m6.1.1.1" xref="S5.SS3.p3.7.m6.1.1.1.cmml">=</mo><mn id="S5.SS3.p3.7.m6.1.1.3" xref="S5.SS3.p3.7.m6.1.1.3.cmml">0.010</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p3.7.m6.1b"><apply id="S5.SS3.p3.7.m6.1.1.cmml" xref="S5.SS3.p3.7.m6.1.1"><eq id="S5.SS3.p3.7.m6.1.1.1.cmml" xref="S5.SS3.p3.7.m6.1.1.1"></eq><ci id="S5.SS3.p3.7.m6.1.1.2.cmml" xref="S5.SS3.p3.7.m6.1.1.2">𝑝</ci><cn id="S5.SS3.p3.7.m6.1.1.3.cmml" type="float" xref="S5.SS3.p3.7.m6.1.1.3">0.010</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p3.7.m6.1c">p=0.010</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p3.7.m6.1d">italic_p = 0.010</annotation></semantics></math>) and instruction alignment (<math alttext="p=0.001" class="ltx_Math" display="inline" id="S5.SS3.p3.8.m7.1"><semantics id="S5.SS3.p3.8.m7.1a"><mrow id="S5.SS3.p3.8.m7.1.1" xref="S5.SS3.p3.8.m7.1.1.cmml"><mi id="S5.SS3.p3.8.m7.1.1.2" xref="S5.SS3.p3.8.m7.1.1.2.cmml">p</mi><mo id="S5.SS3.p3.8.m7.1.1.1" xref="S5.SS3.p3.8.m7.1.1.1.cmml">=</mo><mn id="S5.SS3.p3.8.m7.1.1.3" xref="S5.SS3.p3.8.m7.1.1.3.cmml">0.001</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p3.8.m7.1b"><apply id="S5.SS3.p3.8.m7.1.1.cmml" xref="S5.SS3.p3.8.m7.1.1"><eq id="S5.SS3.p3.8.m7.1.1.1.cmml" xref="S5.SS3.p3.8.m7.1.1.1"></eq><ci id="S5.SS3.p3.8.m7.1.1.2.cmml" xref="S5.SS3.p3.8.m7.1.1.2">𝑝</ci><cn id="S5.SS3.p3.8.m7.1.1.3.cmml" type="float" xref="S5.SS3.p3.8.m7.1.1.3">0.001</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p3.8.m7.1c">p=0.001</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p3.8.m7.1d">italic_p = 0.001</annotation></semantics></math>), indicating that without <span class="ltx_text ltx_markedasmath ltx_font_smallcaps" id="S5.SS3.p3.10.5">Inter</span><span class="ltx_text ltx_font_smallcaps" id="S5.SS3.p3.10.2">-<math alttext="\text{MT}^{2}" class="ltx_Math" display="inline" id="S5.SS3.p3.10.2.m1.1"><semantics id="S5.SS3.p3.10.2.m1.1a"><msup id="S5.SS3.p3.10.2.m1.1.1" xref="S5.SS3.p3.10.2.m1.1.1.cmml"><mtext class="ltx_font_smallcaps" id="S5.SS3.p3.10.2.m1.1.1.2" xref="S5.SS3.p3.10.2.m1.1.1.2a.cmml">MT</mtext><mn id="S5.SS3.p3.10.2.m1.1.1.3" xref="S5.SS3.p3.10.2.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S5.SS3.p3.10.2.m1.1b"><apply id="S5.SS3.p3.10.2.m1.1.1.cmml" xref="S5.SS3.p3.10.2.m1.1.1"><csymbol cd="ambiguous" id="S5.SS3.p3.10.2.m1.1.1.1.cmml" xref="S5.SS3.p3.10.2.m1.1.1">superscript</csymbol><ci id="S5.SS3.p3.10.2.m1.1.1.2a.cmml" xref="S5.SS3.p3.10.2.m1.1.1.2"><mtext class="ltx_font_smallcaps" id="S5.SS3.p3.10.2.m1.1.1.2.cmml" xref="S5.SS3.p3.10.2.m1.1.1.2">MT</mtext></ci><cn id="S5.SS3.p3.10.2.m1.1.1.3.cmml" type="integer" xref="S5.SS3.p3.10.2.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p3.10.2.m1.1c">\text{MT}^{2}</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p3.10.2.m1.1d">MT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math></span> data, the model struggles to control motion based on context and instructions.
We also evaluated the proposed method using data-driven metrics, including FID and MPJPE, as shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#S5.T2" title="Table 2 ‣ 5.3 Motion Editing ‣ 5 Experiments ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_tag">2</span></a>. The proposed method outperforms the baselines on both measures, which is consistent with the results from user studies. Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#S5.F6" title="Figure 6 ‣ 5.3 Motion Editing ‣ 5 Experiments ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_tag">6</span></a> illustrates the generated edited motions based on the source motion and instruction.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4 </span>Traditional Motion Related Tasks</h3>
<figure class="ltx_table" id="S5.T3">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Comparisons for three motion-related tasks on Inter-X and InterHuman datasets. M2T denotes motion-to-text, T2M for text-to-motion, and Reaction Gen. for reaction generation.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T3.9" style="width:278.2pt;height:103.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-30.2pt,11.2pt) scale(0.821447350330415,0.821447350330415) ;">
<table class="ltx_tabular ltx_align_middle" id="S5.T3.9.9">
<tr class="ltx_tr" id="S5.T3.9.9.10">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S5.T3.9.9.10.1" rowspan="2"><span class="ltx_text" id="S5.T3.9.9.10.1.1">Methods</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S5.T3.9.9.10.2">M2T</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2" id="S5.T3.9.9.10.3">T2M</td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S5.T3.9.9.10.4">Reaction Gen.</td>
</tr>
<tr class="ltx_tr" id="S5.T3.5.5.5">
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.1.1.1.1">R Top3 <math alttext="\uparrow" class="ltx_Math" display="inline" id="S5.T3.1.1.1.1.m1.1"><semantics id="S5.T3.1.1.1.1.m1.1a"><mo id="S5.T3.1.1.1.1.m1.1.1" stretchy="false" xref="S5.T3.1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S5.T3.1.1.1.1.m1.1b"><ci id="S5.T3.1.1.1.1.m1.1.1.cmml" xref="S5.T3.1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.1.1.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S5.T3.1.1.1.1.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="S5.T3.2.2.2.2">R Top3 <math alttext="\uparrow" class="ltx_Math" display="inline" id="S5.T3.2.2.2.2.m1.1"><semantics id="S5.T3.2.2.2.2.m1.1a"><mo id="S5.T3.2.2.2.2.m1.1.1" stretchy="false" xref="S5.T3.2.2.2.2.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S5.T3.2.2.2.2.m1.1b"><ci id="S5.T3.2.2.2.2.m1.1.1.cmml" xref="S5.T3.2.2.2.2.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.2.2.2.2.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S5.T3.2.2.2.2.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.3.3.3.3">FID <math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T3.3.3.3.3.m1.1"><semantics id="S5.T3.3.3.3.3.m1.1a"><mo id="S5.T3.3.3.3.3.m1.1.1" stretchy="false" xref="S5.T3.3.3.3.3.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T3.3.3.3.3.m1.1b"><ci id="S5.T3.3.3.3.3.m1.1.1.cmml" xref="S5.T3.3.3.3.3.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.3.3.3.3.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T3.3.3.3.3.m1.1d">↓</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="S5.T3.4.4.4.4">MPJPE <math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T3.4.4.4.4.m1.1"><semantics id="S5.T3.4.4.4.4.m1.1a"><mo id="S5.T3.4.4.4.4.m1.1.1" stretchy="false" xref="S5.T3.4.4.4.4.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T3.4.4.4.4.m1.1b"><ci id="S5.T3.4.4.4.4.m1.1.1.cmml" xref="S5.T3.4.4.4.4.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.4.4.4.4.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T3.4.4.4.4.m1.1d">↓</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="S5.T3.5.5.5.5">FID <math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T3.5.5.5.5.m1.1"><semantics id="S5.T3.5.5.5.5.m1.1a"><mo id="S5.T3.5.5.5.5.m1.1.1" stretchy="false" xref="S5.T3.5.5.5.5.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T3.5.5.5.5.m1.1b"><ci id="S5.T3.5.5.5.5.m1.1.1.cmml" xref="S5.T3.5.5.5.5.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.5.5.5.5.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T3.5.5.5.5.m1.1d">↓</annotation></semantics></math>
</td>
</tr>
<tr class="ltx_tr" id="S5.T3.9.9.11">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.9.9.11.1">Real</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.9.9.11.2">0.867</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.9.9.11.3">0.869</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.9.9.11.4">0.00</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.9.9.11.5">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.9.9.11.6">0.00</td>
</tr>
<tr class="ltx_tr" id="S5.T3.6.6.6">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.6.6.6.1"><math alttext="\text{MotionGPT}^{*}" class="ltx_Math" display="inline" id="S5.T3.6.6.6.1.m1.1"><semantics id="S5.T3.6.6.6.1.m1.1a"><msup id="S5.T3.6.6.6.1.m1.1.1" xref="S5.T3.6.6.6.1.m1.1.1.cmml"><mtext id="S5.T3.6.6.6.1.m1.1.1.2" xref="S5.T3.6.6.6.1.m1.1.1.2a.cmml">MotionGPT</mtext><mo id="S5.T3.6.6.6.1.m1.1.1.3" xref="S5.T3.6.6.6.1.m1.1.1.3.cmml">∗</mo></msup><annotation-xml encoding="MathML-Content" id="S5.T3.6.6.6.1.m1.1b"><apply id="S5.T3.6.6.6.1.m1.1.1.cmml" xref="S5.T3.6.6.6.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T3.6.6.6.1.m1.1.1.1.cmml" xref="S5.T3.6.6.6.1.m1.1.1">superscript</csymbol><ci id="S5.T3.6.6.6.1.m1.1.1.2a.cmml" xref="S5.T3.6.6.6.1.m1.1.1.2"><mtext id="S5.T3.6.6.6.1.m1.1.1.2.cmml" xref="S5.T3.6.6.6.1.m1.1.1.2">MotionGPT</mtext></ci><times id="S5.T3.6.6.6.1.m1.1.1.3.cmml" xref="S5.T3.6.6.6.1.m1.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.6.6.6.1.m1.1c">\text{MotionGPT}^{*}</annotation><annotation encoding="application/x-llamapun" id="S5.T3.6.6.6.1.m1.1d">MotionGPT start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.6.6.6.2">0.494</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.6.6.6.3">0.328</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.6.6.6.4">0.123</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.6.6.6.5">3.444</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.6.6.6.6">0.355</td>
</tr>
<tr class="ltx_tr" id="S5.T3.7.7.7">
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.7.7.7.1"><math alttext="\text{MotionGPT}^{*}_{I}" class="ltx_Math" display="inline" id="S5.T3.7.7.7.1.m1.1"><semantics id="S5.T3.7.7.7.1.m1.1a"><msubsup id="S5.T3.7.7.7.1.m1.1.1" xref="S5.T3.7.7.7.1.m1.1.1.cmml"><mtext id="S5.T3.7.7.7.1.m1.1.1.2.2" xref="S5.T3.7.7.7.1.m1.1.1.2.2a.cmml">MotionGPT</mtext><mi id="S5.T3.7.7.7.1.m1.1.1.3" xref="S5.T3.7.7.7.1.m1.1.1.3.cmml">I</mi><mo id="S5.T3.7.7.7.1.m1.1.1.2.3" xref="S5.T3.7.7.7.1.m1.1.1.2.3.cmml">∗</mo></msubsup><annotation-xml encoding="MathML-Content" id="S5.T3.7.7.7.1.m1.1b"><apply id="S5.T3.7.7.7.1.m1.1.1.cmml" xref="S5.T3.7.7.7.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T3.7.7.7.1.m1.1.1.1.cmml" xref="S5.T3.7.7.7.1.m1.1.1">subscript</csymbol><apply id="S5.T3.7.7.7.1.m1.1.1.2.cmml" xref="S5.T3.7.7.7.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T3.7.7.7.1.m1.1.1.2.1.cmml" xref="S5.T3.7.7.7.1.m1.1.1">superscript</csymbol><ci id="S5.T3.7.7.7.1.m1.1.1.2.2a.cmml" xref="S5.T3.7.7.7.1.m1.1.1.2.2"><mtext id="S5.T3.7.7.7.1.m1.1.1.2.2.cmml" xref="S5.T3.7.7.7.1.m1.1.1.2.2">MotionGPT</mtext></ci><times id="S5.T3.7.7.7.1.m1.1.1.2.3.cmml" xref="S5.T3.7.7.7.1.m1.1.1.2.3"></times></apply><ci id="S5.T3.7.7.7.1.m1.1.1.3.cmml" xref="S5.T3.7.7.7.1.m1.1.1.3">𝐼</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.7.7.7.1.m1.1c">\text{MotionGPT}^{*}_{I}</annotation><annotation encoding="application/x-llamapun" id="S5.T3.7.7.7.1.m1.1d">MotionGPT start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_I end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.7.7.7.2">0.503</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.7.7.3">0.331</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T3.7.7.7.4">0.118</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.7.7.5">1.436</td>
<td class="ltx_td ltx_align_center" id="S5.T3.7.7.7.6">0.380</td>
</tr>
<tr class="ltx_tr" id="S5.T3.9.9.9">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.9.9.9.2">VIM w/o <span class="ltx_text ltx_markedasmath ltx_font_smallcaps" id="S5.T3.9.9.9.2.2">Inter</span><span class="ltx_text ltx_font_smallcaps" id="S5.T3.9.9.9.2.1">-<math alttext="\text{MT}^{2}" class="ltx_Math" display="inline" id="S5.T3.9.9.9.2.1.m1.1"><semantics id="S5.T3.9.9.9.2.1.m1.1a"><msup id="S5.T3.9.9.9.2.1.m1.1.1" xref="S5.T3.9.9.9.2.1.m1.1.1.cmml"><mtext class="ltx_font_smallcaps" id="S5.T3.9.9.9.2.1.m1.1.1.2" xref="S5.T3.9.9.9.2.1.m1.1.1.2a.cmml">MT</mtext><mn id="S5.T3.9.9.9.2.1.m1.1.1.3" xref="S5.T3.9.9.9.2.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S5.T3.9.9.9.2.1.m1.1b"><apply id="S5.T3.9.9.9.2.1.m1.1.1.cmml" xref="S5.T3.9.9.9.2.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T3.9.9.9.2.1.m1.1.1.1.cmml" xref="S5.T3.9.9.9.2.1.m1.1.1">superscript</csymbol><ci id="S5.T3.9.9.9.2.1.m1.1.1.2a.cmml" xref="S5.T3.9.9.9.2.1.m1.1.1.2"><mtext class="ltx_font_smallcaps" id="S5.T3.9.9.9.2.1.m1.1.1.2.cmml" xref="S5.T3.9.9.9.2.1.m1.1.1.2">MT</mtext></ci><cn id="S5.T3.9.9.9.2.1.m1.1.1.3.cmml" type="integer" xref="S5.T3.9.9.9.2.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.9.9.9.2.1.m1.1c">\text{MT}^{2}</annotation><annotation encoding="application/x-llamapun" id="S5.T3.9.9.9.2.1.m1.1d">MT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.9.9.9.3"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.9.9.9.3.1">0.894</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.9.9.9.4"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.9.9.9.4.1">0.561</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T3.9.9.9.5"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.9.9.9.5.1">0.082</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.9.9.9.6"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.9.9.9.6.1">0.984</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.9.9.9.7"><span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T3.9.9.9.7.1">0.031</span></td>
</tr>
<tr class="ltx_tr" id="S5.T3.9.9.12">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S5.T3.9.9.12.1"><span class="ltx_text ltx_font_bold" id="S5.T3.9.9.12.1.1">VIM (Ours)</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S5.T3.9.9.12.2"><span class="ltx_text ltx_font_bold" id="S5.T3.9.9.12.2.1">0.901</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.9.9.12.3"><span class="ltx_text ltx_font_bold" id="S5.T3.9.9.12.3.1">0.568</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S5.T3.9.9.12.4"><span class="ltx_text ltx_font_bold" id="S5.T3.9.9.12.4.1">0.059</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.9.9.12.5"><span class="ltx_text ltx_font_bold" id="S5.T3.9.9.12.5.1">0.691</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T3.9.9.12.6"><span class="ltx_text ltx_font_bold" id="S5.T3.9.9.12.6.1">0.019</span></td>
</tr>
</table>
</span></div>
</figure>
<div class="ltx_para ltx_noindent" id="S5.SS4.p1">
<p class="ltx_p" id="S5.SS4.p1.15">The results in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#A1.T7" title="Table 7 ‣ A.5 Ablation Studies on Pretraining Method ‣ Appendix A Appendix ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_tag">7</span></a> support our hypothesis that utilizing the <span class="ltx_text ltx_markedasmath ltx_font_smallcaps" id="S5.SS4.p1.15.7">Inter</span><span class="ltx_text ltx_font_smallcaps" id="S5.SS4.p1.2.1">-<math alttext="\text{MT}^{2}" class="ltx_Math" display="inline" id="S5.SS4.p1.2.1.m1.1"><semantics id="S5.SS4.p1.2.1.m1.1a"><msup id="S5.SS4.p1.2.1.m1.1.1" xref="S5.SS4.p1.2.1.m1.1.1.cmml"><mtext class="ltx_font_smallcaps" id="S5.SS4.p1.2.1.m1.1.1.2" xref="S5.SS4.p1.2.1.m1.1.1.2a.cmml">MT</mtext><mn id="S5.SS4.p1.2.1.m1.1.1.3" xref="S5.SS4.p1.2.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S5.SS4.p1.2.1.m1.1b"><apply id="S5.SS4.p1.2.1.m1.1.1.cmml" xref="S5.SS4.p1.2.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS4.p1.2.1.m1.1.1.1.cmml" xref="S5.SS4.p1.2.1.m1.1.1">superscript</csymbol><ci id="S5.SS4.p1.2.1.m1.1.1.2a.cmml" xref="S5.SS4.p1.2.1.m1.1.1.2"><mtext class="ltx_font_smallcaps" id="S5.SS4.p1.2.1.m1.1.1.2.cmml" xref="S5.SS4.p1.2.1.m1.1.1.2">MT</mtext></ci><cn id="S5.SS4.p1.2.1.m1.1.1.3.cmml" type="integer" xref="S5.SS4.p1.2.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p1.2.1.m1.1c">\text{MT}^{2}</annotation><annotation encoding="application/x-llamapun" id="S5.SS4.p1.2.1.m1.1d">MT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math></span> dataset enhances the model’s performance in traditional motion tasks like motion-to-text (M2T), text-to-motion (T2M), and reaction generation. The first row (“Real”) shows retrieval accuracy, and FID scores from the dataset labels. Note that both <span class="ltx_text ltx_font_smallcaps" id="S5.SS4.p1.15.8">VIM</span> w/o <span class="ltx_text ltx_markedasmath ltx_font_smallcaps" id="S5.SS4.p1.15.9">Inter</span><span class="ltx_text ltx_font_smallcaps" id="S5.SS4.p1.4.2">-<math alttext="\text{MT}^{2}" class="ltx_Math" display="inline" id="S5.SS4.p1.4.2.m1.1"><semantics id="S5.SS4.p1.4.2.m1.1a"><msup id="S5.SS4.p1.4.2.m1.1.1" xref="S5.SS4.p1.4.2.m1.1.1.cmml"><mtext class="ltx_font_smallcaps" id="S5.SS4.p1.4.2.m1.1.1.2" xref="S5.SS4.p1.4.2.m1.1.1.2a.cmml">MT</mtext><mn id="S5.SS4.p1.4.2.m1.1.1.3" xref="S5.SS4.p1.4.2.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S5.SS4.p1.4.2.m1.1b"><apply id="S5.SS4.p1.4.2.m1.1.1.cmml" xref="S5.SS4.p1.4.2.m1.1.1"><csymbol cd="ambiguous" id="S5.SS4.p1.4.2.m1.1.1.1.cmml" xref="S5.SS4.p1.4.2.m1.1.1">superscript</csymbol><ci id="S5.SS4.p1.4.2.m1.1.1.2a.cmml" xref="S5.SS4.p1.4.2.m1.1.1.2"><mtext class="ltx_font_smallcaps" id="S5.SS4.p1.4.2.m1.1.1.2.cmml" xref="S5.SS4.p1.4.2.m1.1.1.2">MT</mtext></ci><cn id="S5.SS4.p1.4.2.m1.1.1.3.cmml" type="integer" xref="S5.SS4.p1.4.2.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p1.4.2.m1.1c">\text{MT}^{2}</annotation><annotation encoding="application/x-llamapun" id="S5.SS4.p1.4.2.m1.1d">MT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math></span> and MotionGPT<sup class="ltx_sup" id="S5.SS4.p1.15.10">∗</sup> were trained on all of these tasks for fair comparison.
Comparing the <span class="ltx_text ltx_font_smallcaps" id="S5.SS4.p1.15.11">VIM</span> w/o <span class="ltx_text ltx_markedasmath ltx_font_smallcaps" id="S5.SS4.p1.15.12">Inter</span><span class="ltx_text ltx_font_smallcaps" id="S5.SS4.p1.7.3">-<math alttext="\text{MT}^{2}" class="ltx_Math" display="inline" id="S5.SS4.p1.7.3.m1.1"><semantics id="S5.SS4.p1.7.3.m1.1a"><msup id="S5.SS4.p1.7.3.m1.1.1" xref="S5.SS4.p1.7.3.m1.1.1.cmml"><mtext class="ltx_font_smallcaps" id="S5.SS4.p1.7.3.m1.1.1.2" xref="S5.SS4.p1.7.3.m1.1.1.2a.cmml">MT</mtext><mn id="S5.SS4.p1.7.3.m1.1.1.3" xref="S5.SS4.p1.7.3.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S5.SS4.p1.7.3.m1.1b"><apply id="S5.SS4.p1.7.3.m1.1.1.cmml" xref="S5.SS4.p1.7.3.m1.1.1"><csymbol cd="ambiguous" id="S5.SS4.p1.7.3.m1.1.1.1.cmml" xref="S5.SS4.p1.7.3.m1.1.1">superscript</csymbol><ci id="S5.SS4.p1.7.3.m1.1.1.2a.cmml" xref="S5.SS4.p1.7.3.m1.1.1.2"><mtext class="ltx_font_smallcaps" id="S5.SS4.p1.7.3.m1.1.1.2.cmml" xref="S5.SS4.p1.7.3.m1.1.1.2">MT</mtext></ci><cn id="S5.SS4.p1.7.3.m1.1.1.3.cmml" type="integer" xref="S5.SS4.p1.7.3.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p1.7.3.m1.1c">\text{MT}^{2}</annotation><annotation encoding="application/x-llamapun" id="S5.SS4.p1.7.3.m1.1d">MT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math></span> to the version trained with <span class="ltx_text ltx_markedasmath ltx_font_smallcaps" id="S5.SS4.p1.15.13">Inter</span><span class="ltx_text ltx_font_smallcaps" id="S5.SS4.p1.9.4">-<math alttext="\text{MT}^{2}" class="ltx_Math" display="inline" id="S5.SS4.p1.9.4.m1.1"><semantics id="S5.SS4.p1.9.4.m1.1a"><msup id="S5.SS4.p1.9.4.m1.1.1" xref="S5.SS4.p1.9.4.m1.1.1.cmml"><mtext class="ltx_font_smallcaps" id="S5.SS4.p1.9.4.m1.1.1.2" xref="S5.SS4.p1.9.4.m1.1.1.2a.cmml">MT</mtext><mn id="S5.SS4.p1.9.4.m1.1.1.3" xref="S5.SS4.p1.9.4.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S5.SS4.p1.9.4.m1.1b"><apply id="S5.SS4.p1.9.4.m1.1.1.cmml" xref="S5.SS4.p1.9.4.m1.1.1"><csymbol cd="ambiguous" id="S5.SS4.p1.9.4.m1.1.1.1.cmml" xref="S5.SS4.p1.9.4.m1.1.1">superscript</csymbol><ci id="S5.SS4.p1.9.4.m1.1.1.2a.cmml" xref="S5.SS4.p1.9.4.m1.1.1.2"><mtext class="ltx_font_smallcaps" id="S5.SS4.p1.9.4.m1.1.1.2.cmml" xref="S5.SS4.p1.9.4.m1.1.1.2">MT</mtext></ci><cn id="S5.SS4.p1.9.4.m1.1.1.3.cmml" type="integer" xref="S5.SS4.p1.9.4.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p1.9.4.m1.1c">\text{MT}^{2}</annotation><annotation encoding="application/x-llamapun" id="S5.SS4.p1.9.4.m1.1d">MT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math></span> (“Ours”), we see improvements across all tasks.
In M2T, Top-3 retrieval accuracy rose from 0.894 to 0.901. For T2M, Top-3 retrieval accuracy increased from 0.561 to 0.568, with FID dropping from 0.082 to 0.059, indicating better motion generation. In reaction generation, MPJPE dropped from 0.984 to 0.691, and FID from 0.031 to 0.019, confirming that multi-turn datasets improve motion comprehension and generation.
Using the <span class="ltx_text ltx_markedasmath ltx_font_smallcaps" id="S5.SS4.p1.15.14">Inter</span><span class="ltx_text ltx_font_smallcaps" id="S5.SS4.p1.11.5">-<math alttext="\text{MT}^{2}" class="ltx_Math" display="inline" id="S5.SS4.p1.11.5.m1.1"><semantics id="S5.SS4.p1.11.5.m1.1a"><msup id="S5.SS4.p1.11.5.m1.1.1" xref="S5.SS4.p1.11.5.m1.1.1.cmml"><mtext class="ltx_font_smallcaps" id="S5.SS4.p1.11.5.m1.1.1.2" xref="S5.SS4.p1.11.5.m1.1.1.2a.cmml">MT</mtext><mn id="S5.SS4.p1.11.5.m1.1.1.3" xref="S5.SS4.p1.11.5.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S5.SS4.p1.11.5.m1.1b"><apply id="S5.SS4.p1.11.5.m1.1.1.cmml" xref="S5.SS4.p1.11.5.m1.1.1"><csymbol cd="ambiguous" id="S5.SS4.p1.11.5.m1.1.1.1.cmml" xref="S5.SS4.p1.11.5.m1.1.1">superscript</csymbol><ci id="S5.SS4.p1.11.5.m1.1.1.2a.cmml" xref="S5.SS4.p1.11.5.m1.1.1.2"><mtext class="ltx_font_smallcaps" id="S5.SS4.p1.11.5.m1.1.1.2.cmml" xref="S5.SS4.p1.11.5.m1.1.1.2">MT</mtext></ci><cn id="S5.SS4.p1.11.5.m1.1.1.3.cmml" type="integer" xref="S5.SS4.p1.11.5.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p1.11.5.m1.1c">\text{MT}^{2}</annotation><annotation encoding="application/x-llamapun" id="S5.SS4.p1.11.5.m1.1d">MT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math></span> dataset provides diverse, context-rich examples, helping the model learn more nuanced relationships between text and motion.
Additionally, incorporating <span class="ltx_text ltx_markedasmath ltx_font_smallcaps" id="S5.SS4.p1.15.15">Inter</span><span class="ltx_text ltx_font_smallcaps" id="S5.SS4.p1.13.6">-<math alttext="\text{MT}^{2}" class="ltx_Math" display="inline" id="S5.SS4.p1.13.6.m1.1"><semantics id="S5.SS4.p1.13.6.m1.1a"><msup id="S5.SS4.p1.13.6.m1.1.1" xref="S5.SS4.p1.13.6.m1.1.1.cmml"><mtext class="ltx_font_smallcaps" id="S5.SS4.p1.13.6.m1.1.1.2" xref="S5.SS4.p1.13.6.m1.1.1.2a.cmml">MT</mtext><mn id="S5.SS4.p1.13.6.m1.1.1.3" xref="S5.SS4.p1.13.6.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S5.SS4.p1.13.6.m1.1b"><apply id="S5.SS4.p1.13.6.m1.1.1.cmml" xref="S5.SS4.p1.13.6.m1.1.1"><csymbol cd="ambiguous" id="S5.SS4.p1.13.6.m1.1.1.1.cmml" xref="S5.SS4.p1.13.6.m1.1.1">superscript</csymbol><ci id="S5.SS4.p1.13.6.m1.1.1.2a.cmml" xref="S5.SS4.p1.13.6.m1.1.1.2"><mtext class="ltx_font_smallcaps" id="S5.SS4.p1.13.6.m1.1.1.2.cmml" xref="S5.SS4.p1.13.6.m1.1.1.2">MT</mtext></ci><cn id="S5.SS4.p1.13.6.m1.1.1.3.cmml" type="integer" xref="S5.SS4.p1.13.6.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p1.13.6.m1.1c">\text{MT}^{2}</annotation><annotation encoding="application/x-llamapun" id="S5.SS4.p1.13.6.m1.1d">MT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math></span> in <math alttext="\text{MotionGPT}^{*}" class="ltx_Math" display="inline" id="S5.SS4.p1.14.m8.1"><semantics id="S5.SS4.p1.14.m8.1a"><msup id="S5.SS4.p1.14.m8.1.1" xref="S5.SS4.p1.14.m8.1.1.cmml"><mtext id="S5.SS4.p1.14.m8.1.1.2" xref="S5.SS4.p1.14.m8.1.1.2a.cmml">MotionGPT</mtext><mo id="S5.SS4.p1.14.m8.1.1.3" xref="S5.SS4.p1.14.m8.1.1.3.cmml">∗</mo></msup><annotation-xml encoding="MathML-Content" id="S5.SS4.p1.14.m8.1b"><apply id="S5.SS4.p1.14.m8.1.1.cmml" xref="S5.SS4.p1.14.m8.1.1"><csymbol cd="ambiguous" id="S5.SS4.p1.14.m8.1.1.1.cmml" xref="S5.SS4.p1.14.m8.1.1">superscript</csymbol><ci id="S5.SS4.p1.14.m8.1.1.2a.cmml" xref="S5.SS4.p1.14.m8.1.1.2"><mtext id="S5.SS4.p1.14.m8.1.1.2.cmml" xref="S5.SS4.p1.14.m8.1.1.2">MotionGPT</mtext></ci><times id="S5.SS4.p1.14.m8.1.1.3.cmml" xref="S5.SS4.p1.14.m8.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p1.14.m8.1c">\text{MotionGPT}^{*}</annotation><annotation encoding="application/x-llamapun" id="S5.SS4.p1.14.m8.1d">MotionGPT start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT</annotation></semantics></math>, denoted as <math alttext="\text{MotionGPT}^{*}_{I}" class="ltx_Math" display="inline" id="S5.SS4.p1.15.m9.1"><semantics id="S5.SS4.p1.15.m9.1a"><msubsup id="S5.SS4.p1.15.m9.1.1" xref="S5.SS4.p1.15.m9.1.1.cmml"><mtext id="S5.SS4.p1.15.m9.1.1.2.2" xref="S5.SS4.p1.15.m9.1.1.2.2a.cmml">MotionGPT</mtext><mi id="S5.SS4.p1.15.m9.1.1.3" xref="S5.SS4.p1.15.m9.1.1.3.cmml">I</mi><mo id="S5.SS4.p1.15.m9.1.1.2.3" xref="S5.SS4.p1.15.m9.1.1.2.3.cmml">∗</mo></msubsup><annotation-xml encoding="MathML-Content" id="S5.SS4.p1.15.m9.1b"><apply id="S5.SS4.p1.15.m9.1.1.cmml" xref="S5.SS4.p1.15.m9.1.1"><csymbol cd="ambiguous" id="S5.SS4.p1.15.m9.1.1.1.cmml" xref="S5.SS4.p1.15.m9.1.1">subscript</csymbol><apply id="S5.SS4.p1.15.m9.1.1.2.cmml" xref="S5.SS4.p1.15.m9.1.1"><csymbol cd="ambiguous" id="S5.SS4.p1.15.m9.1.1.2.1.cmml" xref="S5.SS4.p1.15.m9.1.1">superscript</csymbol><ci id="S5.SS4.p1.15.m9.1.1.2.2a.cmml" xref="S5.SS4.p1.15.m9.1.1.2.2"><mtext id="S5.SS4.p1.15.m9.1.1.2.2.cmml" xref="S5.SS4.p1.15.m9.1.1.2.2">MotionGPT</mtext></ci><times id="S5.SS4.p1.15.m9.1.1.2.3.cmml" xref="S5.SS4.p1.15.m9.1.1.2.3"></times></apply><ci id="S5.SS4.p1.15.m9.1.1.3.cmml" xref="S5.SS4.p1.15.m9.1.1.3">𝐼</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p1.15.m9.1c">\text{MotionGPT}^{*}_{I}</annotation><annotation encoding="application/x-llamapun" id="S5.SS4.p1.15.m9.1d">MotionGPT start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_I end_POSTSUBSCRIPT</annotation></semantics></math>, improved retrieval precision accuracy for M2T and T2M tasks, and joint position error in reaction generation.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.5 </span>Ablation Studies on Motion Tokenizer</h3>
<figure class="ltx_table" id="S5.T4">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>Ablation Studies on motion tokenizer. </figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T4.10" style="width:397.5pt;height:55pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-61.5pt,8.5pt) scale(0.763781070452635,0.763781070452635) ;">
<table class="ltx_tabular ltx_align_middle" id="S5.T4.10.10">
<tr class="ltx_tr" id="S5.T4.10.10.11">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S5.T4.10.10.11.1" rowspan="2"><span class="ltx_text" id="S5.T4.10.10.11.1.1">Methods</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="3" id="S5.T4.10.10.11.2">Reasoning</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2" id="S5.T4.10.10.11.3">Editing</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S5.T4.10.10.11.4">M2T</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2" id="S5.T4.10.10.11.5">T2M</td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S5.T4.10.10.11.6">Reaction Gen.</td>
</tr>
<tr class="ltx_tr" id="S5.T4.10.10.10">
<td class="ltx_td ltx_align_center" id="S5.T4.1.1.1.1">Coh. <math alttext="\uparrow" class="ltx_Math" display="inline" id="S5.T4.1.1.1.1.m1.1"><semantics id="S5.T4.1.1.1.1.m1.1a"><mo id="S5.T4.1.1.1.1.m1.1.1" stretchy="false" xref="S5.T4.1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S5.T4.1.1.1.1.m1.1b"><ci id="S5.T4.1.1.1.1.m1.1.1.cmml" xref="S5.T4.1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.1.1.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S5.T4.1.1.1.1.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="S5.T4.2.2.2.2">Align. <math alttext="\uparrow" class="ltx_Math" display="inline" id="S5.T4.2.2.2.2.m1.1"><semantics id="S5.T4.2.2.2.2.m1.1a"><mo id="S5.T4.2.2.2.2.m1.1.1" stretchy="false" xref="S5.T4.2.2.2.2.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S5.T4.2.2.2.2.m1.1b"><ci id="S5.T4.2.2.2.2.m1.1.1.cmml" xref="S5.T4.2.2.2.2.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.2.2.2.2.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S5.T4.2.2.2.2.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.3.3.3.3">Nat.<math alttext="\uparrow" class="ltx_Math" display="inline" id="S5.T4.3.3.3.3.m1.1"><semantics id="S5.T4.3.3.3.3.m1.1a"><mo id="S5.T4.3.3.3.3.m1.1.1" stretchy="false" xref="S5.T4.3.3.3.3.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S5.T4.3.3.3.3.m1.1b"><ci id="S5.T4.3.3.3.3.m1.1.1.cmml" xref="S5.T4.3.3.3.3.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.3.3.3.3.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S5.T4.3.3.3.3.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="S5.T4.4.4.4.4">MPJPE <math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T4.4.4.4.4.m1.1"><semantics id="S5.T4.4.4.4.4.m1.1a"><mo id="S5.T4.4.4.4.4.m1.1.1" stretchy="false" xref="S5.T4.4.4.4.4.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T4.4.4.4.4.m1.1b"><ci id="S5.T4.4.4.4.4.m1.1.1.cmml" xref="S5.T4.4.4.4.4.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.4.4.4.4.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T4.4.4.4.4.m1.1d">↓</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.5.5.5.5">FID <math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T4.5.5.5.5.m1.1"><semantics id="S5.T4.5.5.5.5.m1.1a"><mo id="S5.T4.5.5.5.5.m1.1.1" stretchy="false" xref="S5.T4.5.5.5.5.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T4.5.5.5.5.m1.1b"><ci id="S5.T4.5.5.5.5.m1.1.1.cmml" xref="S5.T4.5.5.5.5.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.5.5.5.5.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T4.5.5.5.5.m1.1d">↓</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.6.6.6.6">R Top3 <math alttext="\uparrow" class="ltx_Math" display="inline" id="S5.T4.6.6.6.6.m1.1"><semantics id="S5.T4.6.6.6.6.m1.1a"><mo id="S5.T4.6.6.6.6.m1.1.1" stretchy="false" xref="S5.T4.6.6.6.6.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S5.T4.6.6.6.6.m1.1b"><ci id="S5.T4.6.6.6.6.m1.1.1.cmml" xref="S5.T4.6.6.6.6.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.6.6.6.6.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S5.T4.6.6.6.6.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="S5.T4.7.7.7.7">R Top3 <math alttext="\uparrow" class="ltx_Math" display="inline" id="S5.T4.7.7.7.7.m1.1"><semantics id="S5.T4.7.7.7.7.m1.1a"><mo id="S5.T4.7.7.7.7.m1.1.1" stretchy="false" xref="S5.T4.7.7.7.7.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S5.T4.7.7.7.7.m1.1b"><ci id="S5.T4.7.7.7.7.m1.1.1.cmml" xref="S5.T4.7.7.7.7.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.7.7.7.7.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S5.T4.7.7.7.7.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T4.8.8.8.8">FID <math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T4.8.8.8.8.m1.1"><semantics id="S5.T4.8.8.8.8.m1.1a"><mo id="S5.T4.8.8.8.8.m1.1.1" stretchy="false" xref="S5.T4.8.8.8.8.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T4.8.8.8.8.m1.1b"><ci id="S5.T4.8.8.8.8.m1.1.1.cmml" xref="S5.T4.8.8.8.8.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.8.8.8.8.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T4.8.8.8.8.m1.1d">↓</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="S5.T4.9.9.9.9">MPJPE <math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T4.9.9.9.9.m1.1"><semantics id="S5.T4.9.9.9.9.m1.1a"><mo id="S5.T4.9.9.9.9.m1.1.1" stretchy="false" xref="S5.T4.9.9.9.9.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T4.9.9.9.9.m1.1b"><ci id="S5.T4.9.9.9.9.m1.1.1.cmml" xref="S5.T4.9.9.9.9.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.9.9.9.9.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T4.9.9.9.9.m1.1d">↓</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="S5.T4.10.10.10.10">FID <math alttext="\downarrow" class="ltx_Math" display="inline" id="S5.T4.10.10.10.10.m1.1"><semantics id="S5.T4.10.10.10.10.m1.1a"><mo id="S5.T4.10.10.10.10.m1.1.1" stretchy="false" xref="S5.T4.10.10.10.10.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T4.10.10.10.10.m1.1b"><ci id="S5.T4.10.10.10.10.m1.1.1.cmml" xref="S5.T4.10.10.10.10.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.10.10.10.10.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T4.10.10.10.10.m1.1d">↓</annotation></semantics></math>
</td>
</tr>
<tr class="ltx_tr" id="S5.T4.10.10.12">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.10.10.12.1">VIM-VQ</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.10.10.12.2">5.004</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.10.10.12.3">4.256</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.10.10.12.4">6.915</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.10.10.12.5">0.892</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.10.10.12.6">0.128</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.10.10.12.7">0.861</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.10.10.12.8"><span class="ltx_text ltx_font_bold" id="S5.T4.10.10.12.8.1">0.601</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T4.10.10.12.9">0.101</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.10.10.12.10">1.109</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.10.10.12.11">0.055</td>
</tr>
<tr class="ltx_tr" id="S5.T4.10.10.13">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S5.T4.10.10.13.1"><span class="ltx_text ltx_font_bold" id="S5.T4.10.10.13.1.1">VIM (Ours)</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.10.10.13.2"><span class="ltx_text ltx_font_bold" id="S5.T4.10.10.13.2.1">5.252</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.10.10.13.3"><span class="ltx_text ltx_font_bold" id="S5.T4.10.10.13.3.1">4.511</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S5.T4.10.10.13.4"><span class="ltx_text ltx_font_bold" id="S5.T4.10.10.13.4.1">6.981</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.10.10.13.5"><span class="ltx_text ltx_font_bold" id="S5.T4.10.10.13.5.1">0.758</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S5.T4.10.10.13.6"><span class="ltx_text ltx_font_bold" id="S5.T4.10.10.13.6.1">0.064</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S5.T4.10.10.13.7"><span class="ltx_text ltx_font_bold" id="S5.T4.10.10.13.7.1">0.901</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.10.10.13.8">0.568</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S5.T4.10.10.13.9"><span class="ltx_text ltx_font_bold" id="S5.T4.10.10.13.9.1">0.059</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.10.10.13.10"><span class="ltx_text ltx_font_bold" id="S5.T4.10.10.13.10.1">0.691</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.10.10.13.11"><span class="ltx_text ltx_font_bold" id="S5.T4.10.10.13.11.1">0.019</span></td>
</tr>
</table>
</span></div>
</figure>
<div class="ltx_para ltx_noindent" id="S5.SS5.p1">
<p class="ltx_p" id="S5.SS5.p1.1">We conducted ablation studies comparing the VQ-VAE-based model with our RQ-VAE-based approach, as shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#S5.T4" title="Table 4 ‣ 5.5 Ablation Studies on Motion Tokenizer ‣ 5 Experiments ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_tag">4</span></a>. The RQ-VAE-based motion tokenizer outperformed the VQ-VAE model in motion reasoning tasks, achieving higher scores in coherence, alignment, and naturalness. This improvement is attributed to reduced information loss, allowing our model to capture finer motion details while also enhancing its motion-to-text retrieval precision. For generation and editing tasks, the VQ-VAE model achieved slightly better text-to-motion retrieval accuracy but performed worse in FID and MPJPE across editing, reaction generation, and T2M tasks, indicating degraded motion quality and less precise motion details. In contrast, our approach reduced MPJPE by 0.055 for reaction generation, preserving joint dynamics and producing more realistic and natural motions. VQ-VAE’s limitations are especially problematic for modeling interactive motions, where precise relative positioning is crucial, making its information loss and reconstruction quality more evident.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion and Discussions</h2>
<section class="ltx_paragraph" id="S6.SS0.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Conclusion</h5>
<div class="ltx_para ltx_noindent" id="S6.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S6.SS0.SSS0.Px1.p1.2">In this paper, we introduced <span class="ltx_text ltx_font_smallcaps" id="S6.SS0.SSS0.Px1.p1.2.2">VIM</span>, a versatile motion-language model designed to model, understand, and reason about interactive motions. We outlined its architecture and provided detailed training strategies to create a unified framework integrating large language models with interactive motion modality. To enhance the model’s reasoning capabilities and versatility, we presented a specialized dataset, <span class="ltx_text ltx_markedasmath ltx_font_smallcaps" id="S6.SS0.SSS0.Px1.p1.2.3">Inter</span><span class="ltx_text ltx_font_smallcaps" id="S6.SS0.SSS0.Px1.p1.2.1">-<math alttext="\text{MT}^{2}" class="ltx_Math" display="inline" id="S6.SS0.SSS0.Px1.p1.2.1.m1.1"><semantics id="S6.SS0.SSS0.Px1.p1.2.1.m1.1a"><msup id="S6.SS0.SSS0.Px1.p1.2.1.m1.1.1" xref="S6.SS0.SSS0.Px1.p1.2.1.m1.1.1.cmml"><mtext class="ltx_font_smallcaps" id="S6.SS0.SSS0.Px1.p1.2.1.m1.1.1.2" xref="S6.SS0.SSS0.Px1.p1.2.1.m1.1.1.2a.cmml">MT</mtext><mn id="S6.SS0.SSS0.Px1.p1.2.1.m1.1.1.3" xref="S6.SS0.SSS0.Px1.p1.2.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S6.SS0.SSS0.Px1.p1.2.1.m1.1b"><apply id="S6.SS0.SSS0.Px1.p1.2.1.m1.1.1.cmml" xref="S6.SS0.SSS0.Px1.p1.2.1.m1.1.1"><csymbol cd="ambiguous" id="S6.SS0.SSS0.Px1.p1.2.1.m1.1.1.1.cmml" xref="S6.SS0.SSS0.Px1.p1.2.1.m1.1.1">superscript</csymbol><ci id="S6.SS0.SSS0.Px1.p1.2.1.m1.1.1.2a.cmml" xref="S6.SS0.SSS0.Px1.p1.2.1.m1.1.1.2"><mtext class="ltx_font_smallcaps" id="S6.SS0.SSS0.Px1.p1.2.1.m1.1.1.2.cmml" xref="S6.SS0.SSS0.Px1.p1.2.1.m1.1.1.2">MT</mtext></ci><cn id="S6.SS0.SSS0.Px1.p1.2.1.m1.1.1.3.cmml" type="integer" xref="S6.SS0.SSS0.Px1.p1.2.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS0.SSS0.Px1.p1.2.1.m1.1c">\text{MT}^{2}</annotation><annotation encoding="application/x-llamapun" id="S6.SS0.SSS0.Px1.p1.2.1.m1.1d">MT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math></span>, which incorporates a variety of reasoning tasks set within multi-turn conversations centered on interactive motions. Our experiments demonstrated <span class="ltx_text ltx_font_smallcaps" id="S6.SS0.SSS0.Px1.p1.2.4">VIM</span>’s ability to effectively follow instructions, edit motions, and reason about interactive motions.</p>
</div>
</section>
<section class="ltx_paragraph" id="S6.SS0.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">Limitations and Impact Statement</h5>
<div class="ltx_para ltx_noindent" id="S6.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S6.SS0.SSS0.Px2.p1.1">There are several limitations that warrant attention. First, the model’s expressiveness remains limited when handling complex or previously unseen actions, indicating a need for further diverse motion source data in its ability to generalize across diverse motion scenarios. Second, the sequence length becomes excessively long as we flatten the residual motion tokens, which can impact efficiency and computational resources. Leveraging additional transformer models to predict the residual token can reduce this work.
Lastly, our method faces challenges in personalization and interpretability, as motion is inherently ambiguous and users may interpret the same motion in different ways. Addressing this issue will require incorporating more tailored approaches that adapt to individual user preferences and expectations through further human-in-the-loop feedback and refinement processes.
In terms of broader impact, <span class="ltx_text ltx_font_smallcaps" id="S6.SS0.SSS0.Px2.p1.1.1">VIM</span> opens up new possibilities for interactive motion modeling and understanding in AI, potentially benefiting fields like robotics, virtual environments, and human-computer interaction. However, careful consideration of ethical concerns, such as misinterpretation of motions or unintended behavioral biases, is crucial as the model evolves.</p>
</div>
</section>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Aberman et al. (2020)</span>
<span class="ltx_bibblock">
Kfir Aberman, Yijia Weng, Dani Lischinski, Daniel Cohen-Or, and Baoquan Chen.

</span>
<span class="ltx_bibblock">Unpaired motion style transfer from video to animation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">ACM Transactions on Graphics (TOG)</em>, 39(4):64–1, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Athanasiou et al. (2024)</span>
<span class="ltx_bibblock">
Nikos Athanasiou, Alpár Ceske, Markos Diomataris, Michael J Black, and
Gül Varol.

</span>
<span class="ltx_bibblock">MotionFix: Text-driven 3d human motion editing.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">arXiv preprint arXiv:2408.00712</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(3)</span>
<span class="ltx_bibblock">
AWS.

</span>
<span class="ltx_bibblock">Amazon mechanical turk.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.mturk.com/" title="">https://www.mturk.com/</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Banerjee &amp; Lavie (2005)</span>
<span class="ltx_bibblock">
Satanjeev Banerjee and Alon Lavie.

</span>
<span class="ltx_bibblock">METEOR: An automatic metric for MT evaluation with improved
correlation with human judgments.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">Proc. of the ACL Workshop on Intrinsic and Extrinsic
Evaluation Measures for Machine Translation and/or Summarization</em>, pp. 65–72, Ann Arbor, Michigan, June 2005. Association for Computational
Linguistics.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.aclweb.org/anthology/W05-0909" title="">https://www.aclweb.org/anthology/W05-0909</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cai et al. (2024)</span>
<span class="ltx_bibblock">
Zhongang Cai, Jianping Jiang, Zhongfei Qing, Xinying Guo, Mingyuan Zhang,
Zhengyu Lin, Haiyi Mei, Chen Wei, Ruisi Wang, Wanqi Yin, Liang Pan, Xiangyu
Fan, Han Du, Peng Gao, Zhitao Yang, Yang Gao, Jiaqi Li, Tianxiang Ren, Yukun
Wei, Xiaogang Wang, Chen Change Loy, Lei Yang, and Ziwei Liu.

</span>
<span class="ltx_bibblock">Digital life project: Autonomous 3d characters with social
intelligence.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">Proc. of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition (CVPR)</em>, pp.  582–592, June 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2024a)</span>
<span class="ltx_bibblock">
Ling-Hao Chen, Shunlin Lu, Ailing Zeng, Hao Zhang, Benyou Wang, Ruimao Zhang,
and Lei Zhang.

</span>
<span class="ltx_bibblock">Motionllm: Understanding human behaviors from human motions and
videos.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">arxiv:2405.20340</em>, 2024a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2024b)</span>
<span class="ltx_bibblock">
Wei Chen, Lin Li, Yongqi Yang, Bin Wen, Fan Yang, Tingting Gao, Yu Wu, and Long
Chen.

</span>
<span class="ltx_bibblock">CoMM: A coherent interleaved image-text dataset for multimodal
understanding and generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">arXiv preprint arXiv:2406.10462</em>, 2024b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chung et al. (2024)</span>
<span class="ltx_bibblock">
Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus,
Yunxuan Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et al.

</span>
<span class="ltx_bibblock">Scaling instruction-finetuned language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">Journal of Machine Learning Research</em>, 25(70):1–53, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dubey et al. (2024)</span>
<span class="ltx_bibblock">
Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad
Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan,
et al.

</span>
<span class="ltx_bibblock">The llama 3 herd of models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">arXiv preprint arXiv:2407.21783</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fieraru et al. (2020)</span>
<span class="ltx_bibblock">
Mihai Fieraru, Mihai Zanfir, Elisabeta Oneata, Alin-Ionut Popa, Vlad Olaru, and
Cristian Sminchisescu.

</span>
<span class="ltx_bibblock">Three-dimensional reconstruction of human interactions.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">Proc. of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition (CVPR)</em>, pp.  7214–7223, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ge et al. (2024)</span>
<span class="ltx_bibblock">
Yuying Ge, Sijie Zhao, Jinguo Zhu, Yixiao Ge, Kun Yi, Lin Song, Chen Li,
Xiaohan Ding, and Ying Shan.

</span>
<span class="ltx_bibblock">SEED-X: Multimodal models with unified multi-granularity
comprehension and generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">arXiv preprint arXiv:2404.14396</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ghosh et al. (2023)</span>
<span class="ltx_bibblock">
Anindita Ghosh, Rishabh Dabral, Vladislav Golyanik, Christian Theobalt, and
Philipp Slusallek.

</span>
<span class="ltx_bibblock">ReMos: Reactive 3d motion synthesis for two-person interactions.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">arXiv preprint arXiv:2311.17057</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Goel et al. (2024)</span>
<span class="ltx_bibblock">
Purvi Goel, Kuan-Chieh Wang, C. Karen Liu, and Kayvon Fatahalian.

</span>
<span class="ltx_bibblock">Iterative motion editing with natural language.

</span>
<span class="ltx_bibblock">New York, NY, USA, 2024. Association for Computing Machinery.

</span>
<span class="ltx_bibblock">ISBN 9798400705250.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1145/3641519.3657447</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3641519.3657447" title="">https://doi.org/10.1145/3641519.3657447</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guo et al. (2022)</span>
<span class="ltx_bibblock">
Chuan Guo, Xinxin Zuo, Sen Wang, and Li Cheng.

</span>
<span class="ltx_bibblock">TM2T: Stochastic and tokenized modeling for the reciprocal
generation of 3d human motions and texts.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">Proc. of the European Conference on Computer Vision
(ECCV)</em>, pp.  580–597. Springer, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guo et al. (2024a)</span>
<span class="ltx_bibblock">
Chuan Guo, Yuxuan Mu, Muhammad Gohar Javed, Sen Wang, and Li Cheng.

</span>
<span class="ltx_bibblock">Momask: Generative masked modeling of 3d human motions.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">Proc. of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition (CVPR)</em>, pp.  1900–1910, 2024a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guo et al. (2024b)</span>
<span class="ltx_bibblock">
Chuan Guo, Yuxuan Mu, Xinxin Zuo, Peng Dai, Youliang Yan, Juwei Lu, and
Li Cheng.

</span>
<span class="ltx_bibblock">Generative human motion stylization in latent space.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">Proc. of the Twelfth International Conference on Learning
Representations (ICLR)</em>, 2024b.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/forum?id=daEqXJ0yZo" title="">https://openreview.net/forum?id=daEqXJ0yZo</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et al. (2022)</span>
<span class="ltx_bibblock">
Edward J Hu, yelong shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean
Wang, Lu Wang, and Weizhu Chen.

</span>
<span class="ltx_bibblock">LoRA: Low-rank adaptation of large language models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">Proc. of the International Conference on Learning
Representations (ICLR)</em>, 2022.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/forum?id=nZeVKeeFYf9" title="">https://openreview.net/forum?id=nZeVKeeFYf9</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et al. (2023)</span>
<span class="ltx_bibblock">
Biao Jiang, Xin Chen, Wen Liu, Jingyi Yu, Gang Yu, and Tao Chen.

</span>
<span class="ltx_bibblock">MotionGPT: Human motion as a foreign language.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">Proc. of the Advances in Neural Information Processing Systems
(NEURIPS)</em>, 36:20067–20079, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et al. (2024)</span>
<span class="ltx_bibblock">
Biao Jiang, Xin Chen, Chi Zhang, Fukun Yin, Zhuoyuan Li, Gang Yu, and Jiayuan
Fan.

</span>
<span class="ltx_bibblock">MotionChain: Conversational motion controllers via multimodal
prompts.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">arXiv preprint arXiv:2404.01700</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim et al. (2023)</span>
<span class="ltx_bibblock">
Jihoon Kim, Jiseob Kim, and Sungjoon Choi.

</span>
<span class="ltx_bibblock">Flame: Free-form language-based motion synthesis &amp; editing.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">Proc. of the AAAI Conference on Artificial Intelligence
(AAAI)</em>, volume 37, pp.  8255–8263, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee et al. (2022)</span>
<span class="ltx_bibblock">
Doyup Lee, Chiheon Kim, Saehoon Kim, Minsu Cho, and Wook-Shin Han.

</span>
<span class="ltx_bibblock">Autoregressive image generation using residual quantization.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">Proc. of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition (CVPR)</em>, pp.  11523–11532, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liang et al. (2024)</span>
<span class="ltx_bibblock">
Han Liang, Wenqian Zhang, Wenxuan Li, Jingyi Yu, and Lan Xu.

</span>
<span class="ltx_bibblock">Intergen: Diffusion-based multi-human motion generation under complex
interactions.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">International Journal of Computer Vision</em>, pp.  1–21, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin (2004)</span>
<span class="ltx_bibblock">
Chin-Yew Lin.

</span>
<span class="ltx_bibblock">ROUGE: A package for automatic evaluation of summaries.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">Text Summarization Branches Out</em>, pp.  74–81, Barcelona,
Spain, July 2004. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.aclweb.org/anthology/W04-1013" title="">https://www.aclweb.org/anthology/W04-1013</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et al. (2024)</span>
<span class="ltx_bibblock">
Jing Lin, Ailing Zeng, Shunlin Lu, Yuanhao Cai, Ruimao Zhang, Haoqian Wang, and
Lei Zhang.

</span>
<span class="ltx_bibblock">Motion-X: A large-scale 3d expressive whole-body human motion
dataset.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">Proc. of the Advances in Neural Information Processing Systems
(NEURIPS)</em>, 36, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2024)</span>
<span class="ltx_bibblock">
Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong Jae Lee.

</span>
<span class="ltx_bibblock">Visual instruction tuning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">Proc. of the Advances in neural information processing systems
(NEURIPS)</em>, 36, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Luo et al. (2024)</span>
<span class="ltx_bibblock">
Mingshuang Luo, Ruibing Hou, Hong Chang, Zimo Liu, Yaowei Wang, and Shiguang
Shan.

</span>
<span class="ltx_bibblock">M3 GPT: An advanced multimodal, multitask framework for motion
comprehension and generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">arXiv preprint arXiv:2405.16273</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ng et al. (2020)</span>
<span class="ltx_bibblock">
Evonne Ng, Donglai Xiang, Hanbyul Joo, and Kristen Grauman.

</span>
<span class="ltx_bibblock">You2me: Inferring body pose in egocentric video via first and second
person interactions.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">Proc. of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition (CVPR)</em>, pp.  9890–9900, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2024)</span>
<span class="ltx_bibblock">
OpenAI.

</span>
<span class="ltx_bibblock">Hello gpt-4o.

</span>
<span class="ltx_bibblock">2024.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openai.com/index/hello-gpt-4o/" title="">https://openai.com/index/hello-gpt-4o/</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pavlakos et al. (2019)</span>
<span class="ltx_bibblock">
Georgios Pavlakos, Vasileios Choutas, Nima Ghorbani, Timo Bolkart, Ahmed A. A.
Osman, Dimitrios Tzionas, and Michael J. Black.

</span>
<span class="ltx_bibblock">Expressive body capture: 3D hands, face, and body from a single
image.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">Proc.of the IEEE Conf. on Computer Vision and Pattern
Recognition (CVPR)</em>, pp.  10975–10985, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Petrovich et al. (2023)</span>
<span class="ltx_bibblock">
Mathis Petrovich, Michael J. Black, and Gül Varol.

</span>
<span class="ltx_bibblock">TMR: Text-to-motion retrieval using contrastive 3D human motion
synthesis.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">Proc. of the International Conference on Computer Vision
(ICCV)</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pillutla et al. (2021)</span>
<span class="ltx_bibblock">
Krishna Pillutla, Swabha Swayamdipta, Rowan Zellers, John Thickstun, Sean
Welleck, Yejin Choi, and Zaid Harchaoui.

</span>
<span class="ltx_bibblock">MAUVE: Measuring the gap between neural text and human text using
divergence frontiers.

</span>
<span class="ltx_bibblock">In A. Beygelzimer, Y. Dauphin, P. Liang, and J. Wortman Vaughan
(eds.), <em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">Proc. of the Advances in Neural Information Processing Systems
(NEURIPS)</em>, 2021.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/forum?id=Tqx7nJp7PR" title="">https://openreview.net/forum?id=Tqx7nJp7PR</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shafir et al. (2024)</span>
<span class="ltx_bibblock">
Yoni Shafir, Guy Tevet, Roy Kapon, and Amit Haim Bermano.

</span>
<span class="ltx_bibblock">Human motion diffusion as a generative prior.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">Proc. of the Twelfth International Conference on Learning
Representations (ICLR)</em>, 2024.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/forum?id=dTpbEdN9kr" title="">https://openreview.net/forum?id=dTpbEdN9kr</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shu et al. (2023)</span>
<span class="ltx_bibblock">
Yu Shu, Siwei Dong, Guangyao Chen, Wenhao Huang, Ruihua Zhang, Daochen Shi,
Qiqi Xiang, and Yemin Shi.

</span>
<span class="ltx_bibblock">Llasm: Large language and speech model.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">arXiv preprint arXiv:2308.15930</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tang et al. (2024)</span>
<span class="ltx_bibblock">
Changli Tang, Wenyi Yu, Guangzhi Sun, Xianzhao Chen, Tian Tan, Wei Li, Lu Lu,
Zejun MA, and Chao Zhang.

</span>
<span class="ltx_bibblock">SALMONN: Towards generic hearing abilities for large language
models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">Proc. of the Twelfth International Conference on Learning
Representations (ICLR)</em>, 2024.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/forum?id=14rn7HpKVk" title="">https://openreview.net/forum?id=14rn7HpKVk</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Team et al. (2024)</span>
<span class="ltx_bibblock">
Gemma Team, Morgane Riviere, Shreya Pathak, Pier Giuseppe Sessa, Cassidy
Hardin, Surya Bhupatiraju, Léonard Hussenot, Thomas Mesnard, Bobak
Shahriari, Alexandre Ramé, et al.

</span>
<span class="ltx_bibblock">Gemma 2: Improving open language models at a practical size.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">arXiv preprint arXiv:2408.00118</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tevet et al. (2023)</span>
<span class="ltx_bibblock">
Guy Tevet, Sigal Raab, Brian Gordon, Yoni Shafir, Daniel Cohen-or, and
Amit Haim Bermano.

</span>
<span class="ltx_bibblock">Human motion diffusion model.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">Proc. of the Eleventh International Conference on Learning
Representations (ICLR)</em>, 2023.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/forum?id=SJ1kSyO2jwu" title="">https://openreview.net/forum?id=SJ1kSyO2jwu</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Van Den Oord et al. (2017)</span>
<span class="ltx_bibblock">
Aaron Van Den Oord, Oriol Vinyals, et al.

</span>
<span class="ltx_bibblock">Neural discrete representation learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">Proc. of the Advances in neural information processing systems
(NEURIPS)</em>, 30, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2023)</span>
<span class="ltx_bibblock">
Yin Wang, Zhiying Leng, Frederick WB Li, Shun-Cheng Wu, and Xiaohui Liang.

</span>
<span class="ltx_bibblock">Fg-t2m: Fine-grained text-driven human motion generation via
diffusion model.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">Proc. of the IEEE/CVF International Conference on Computer
Vision (CVPR)</em>, pp.  22035–22044, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al. (2024)</span>
<span class="ltx_bibblock">
Qi Wu, Yubo Zhao, Yifan Wang, Yu-Wing Tai, and Chi-Keung Tang.

</span>
<span class="ltx_bibblock">Motionllm: Multimodal motion-language learning with large language
models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">arXiv preprint arXiv:2405.17013</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al. (2024a)</span>
<span class="ltx_bibblock">
Liang Xu, Xintao Lv, Yichao Yan, Xin Jin, Shuwen Wu, Congsheng Xu, Yifan Liu,
Yizhou Zhou, Fengyun Rao, Xingdong Sheng, et al.

</span>
<span class="ltx_bibblock">Inter-x: Towards versatile human-human interaction analysis.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition (CVPR)</em>, pp.  22260–22271, 2024a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al. (2024b)</span>
<span class="ltx_bibblock">
Liang Xu, Yizhou Zhou, Yichao Yan, Xin Jin, Wenhan Zhu, Fengyun Rao, Xiaokang
Yang, and Wenjun Zeng.

</span>
<span class="ltx_bibblock">ReGenNet: Towards human action-reaction synthesis.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">Proc. of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition (CVPR)</em>, pp.  1759–1769, June 2024b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al. (2024)</span>
<span class="ltx_bibblock">
An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng
Li, Chengyuan Li, Dayiheng Liu, Fei Huang, et al.

</span>
<span class="ltx_bibblock">Qwen2 technical report.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">arXiv preprint arXiv:2407.10671</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yin et al. (2023)</span>
<span class="ltx_bibblock">
Yifei Yin, Chen Guo, Manuel Kaufmann, Juan Jose Zarate, Jie Song, and Otmar
Hilliges.

</span>
<span class="ltx_bibblock">Hi4d: 4d instance segmentation of close human interaction.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">Proc. of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition (CVPR)</em>, pp.  17016–17027, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2023)</span>
<span class="ltx_bibblock">
Jianrong Zhang, Yangsong Zhang, Xiaodong Cun, Yong Zhang, Hongwei Zhao, Hongtao
Lu, Xi Shen, and Ying Shan.

</span>
<span class="ltx_bibblock">Generating human motion from textual descriptions with discrete
representations.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib44.1.1">Proceedings of the IEEE/CVF conference on computer vision
and pattern recognition (CVPR)</em>, pp.  14730–14740, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2024a)</span>
<span class="ltx_bibblock">
Mingyuan Zhang, Zhongang Cai, Liang Pan, Fangzhou Hong, Xinying Guo, Lei Yang,
and Ziwei Liu.

</span>
<span class="ltx_bibblock">Motiondiffuse: Text-driven human motion generation with diffusion
model.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib45.1.1">IEEE Transactions on Pattern Analysis and Machine
Intelligence</em>, 2024a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2024b)</span>
<span class="ltx_bibblock">
Mingyuan Zhang, Daisheng Jin, Chenyang Gu, Fangzhou Hong, Zhongang Cai,
Jingfang Huang, Chongzhi Zhang, Xinying Guo, Lei Yang, Ying He, et al.

</span>
<span class="ltx_bibblock">Large motion model for unified multi-modal motion generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib46.1.1">arXiv preprint arXiv:2404.01284</em>, 2024b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2024c)</span>
<span class="ltx_bibblock">
Mingyuan Zhang, Huirong Li, Zhongang Cai, Jiawei Ren, Lei Yang, and Ziwei Liu.

</span>
<span class="ltx_bibblock">Finemogen: Fine-grained spatio-temporal motion generation and
editing.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib47.1.1">Proc. of the Advances in Neural Information Processing
Systems (NEURIPS)</em>, volume 36, 2024c.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2024d)</span>
<span class="ltx_bibblock">
Yaqi Zhang, Di Huang, Bin Liu, Shixiang Tang, Yan Lu, Lu Chen, Lei Bai, Qi Chu,
Nenghai Yu, and Wanli Ouyang.

</span>
<span class="ltx_bibblock">Motiongpt: Finetuned llms are general-purpose motion generators.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib48.1.1">Proc. of the AAAI Conference on Artificial Intelligence
(AAAI)</em>, volume 38, pp.  7368–7376, 2024d.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al. (2024)</span>
<span class="ltx_bibblock">
Zixiang Zhou, Yu Wan, and Baoyuan Wang.

</span>
<span class="ltx_bibblock">AvatarGPT: All-in-one framework for motion understanding planning
generation and beyond.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib49.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition (CVPR)</em>, pp.  1357–1366, June 2024.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Appendix</h2>
<div class="ltx_para ltx_noindent" id="A1.p1">
<p class="ltx_p" id="A1.p1.3">This appendix provides a comprehensive set of supplementary materials that reinforce the main findings of the research. It covers key areas such as motion representation (Sec. <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#A1.SS1" title="A.1 Motion Representation and Motion Token Representation ‣ Appendix A Appendix ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_tag">A.1</span></a>) and <span class="ltx_text ltx_markedasmath ltx_font_smallcaps" id="A1.p1.3.2">Inter</span><span class="ltx_text ltx_font_smallcaps" id="A1.p1.2.1">-<math alttext="\text{MT}^{2}" class="ltx_Math" display="inline" id="A1.p1.2.1.m1.1"><semantics id="A1.p1.2.1.m1.1a"><msup id="A1.p1.2.1.m1.1.1" xref="A1.p1.2.1.m1.1.1.cmml"><mtext class="ltx_font_smallcaps" id="A1.p1.2.1.m1.1.1.2" xref="A1.p1.2.1.m1.1.1.2a.cmml">MT</mtext><mn id="A1.p1.2.1.m1.1.1.3" xref="A1.p1.2.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="A1.p1.2.1.m1.1b"><apply id="A1.p1.2.1.m1.1.1.cmml" xref="A1.p1.2.1.m1.1.1"><csymbol cd="ambiguous" id="A1.p1.2.1.m1.1.1.1.cmml" xref="A1.p1.2.1.m1.1.1">superscript</csymbol><ci id="A1.p1.2.1.m1.1.1.2a.cmml" xref="A1.p1.2.1.m1.1.1.2"><mtext class="ltx_font_smallcaps" id="A1.p1.2.1.m1.1.1.2.cmml" xref="A1.p1.2.1.m1.1.1.2">MT</mtext></ci><cn id="A1.p1.2.1.m1.1.1.3.cmml" type="integer" xref="A1.p1.2.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.2.1.m1.1c">\text{MT}^{2}</annotation><annotation encoding="application/x-llamapun" id="A1.p1.2.1.m1.1d">MT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math></span> dataset sample visualization (Sec. <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#A1.SS2" title="A.2 Data Sample Visualization ‣ Appendix A Appendix ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_tag">A.2</span></a>), with accompanying dataset statistics (Sec. <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#A1.SS3" title='A.3 Inter-"MT"² Statistics ‣ Appendix A Appendix ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents'><span class="ltx_text ltx_ref_tag">A.3</span></a>). In-depth task explanations are included (Sec. <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#A1.SS4" title="A.4 Detailed Task Explanations ‣ Appendix A Appendix ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_tag">A.4</span></a>), alongside ablation studies that examine various pretraining methods (Sec. <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#A1.SS5" title="A.5 Ablation Studies on Pretraining Method ‣ Appendix A Appendix ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_tag">A.5</span></a>). The appendix also contains qualitative results (Sec. <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#A1.SS6" title="A.6 Qualitative Results ‣ Appendix A Appendix ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_tag">A.6</span></a>) and thorough explanations of two-stage baselines (Sec. <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#A1.SS8" title="A.8 Detailed Explanation about Two-stage Baselines ‣ Appendix A Appendix ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_tag">A.8</span></a>). Additionally, it provides template forms for pre-training and instruction tuning (Sec. <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#A1.SS9" title="A.9 Template Forms for Pre-training and Instruction Tuning ‣ Appendix A Appendix ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_tag">A.9</span></a>). We also report implementation details for MotionGPT<sup class="ltx_sup" id="A1.p1.3.3">∗</sup> (Sec. <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#A1.SS7" title="A.7 Implementation details for MotionGPT∗ ‣ Appendix A Appendix ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_tag">A.7</span></a>), with implementation details for the proposed method (Sec. <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#A1.SS10" title="A.10 Implementation Details ‣ Appendix A Appendix ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_tag">A.10</span></a>), detailed metrics explanation (Sec. <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#A1.SS11" title="A.11 More details about Evaluation Metric for Traditional Motion Related Tasks ‣ Appendix A Appendix ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_tag">A.11</span></a>), protocols for user subject studies (Sec. <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#A1.SS12" title="A.12 User Subject Studies Protocols for motion editing ‣ Appendix A Appendix ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_tag">A.12</span></a>) focused on motion editing, prompts for data collection within the dataset (Sec. <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#A1.SS13" title='A.13 Prompts for Data collection in Inter-"MT"² ‣ Appendix A Appendix ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents'><span class="ltx_text ltx_ref_tag">A.13</span></a>), and guidelines for LLM-assisted evaluation processes (Sec. <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#A1.SS14" title="A.14 Prompts for LLM-Assisted Evaluation ‣ Appendix A Appendix ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_tag">A.14</span></a>).</p>
</div>
<section class="ltx_subsection" id="A1.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1 </span>Motion Representation and Motion Token Representation</h3>
<div class="ltx_para ltx_noindent" id="A1.SS1.p1">
<p class="ltx_p" id="A1.SS1.p1.9">For two persons <math alttext="a" class="ltx_Math" display="inline" id="A1.SS1.p1.1.m1.1"><semantics id="A1.SS1.p1.1.m1.1a"><mi id="A1.SS1.p1.1.m1.1.1" xref="A1.SS1.p1.1.m1.1.1.cmml">a</mi><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.1.m1.1b"><ci id="A1.SS1.p1.1.m1.1.1.cmml" xref="A1.SS1.p1.1.m1.1.1">𝑎</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.1.m1.1c">a</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p1.1.m1.1d">italic_a</annotation></semantics></math> and <math alttext="b" class="ltx_Math" display="inline" id="A1.SS1.p1.2.m2.1"><semantics id="A1.SS1.p1.2.m2.1a"><mi id="A1.SS1.p1.2.m2.1.1" xref="A1.SS1.p1.2.m2.1.1.cmml">b</mi><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.2.m2.1b"><ci id="A1.SS1.p1.2.m2.1.1.cmml" xref="A1.SS1.p1.2.m2.1.1">𝑏</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.2.m2.1c">b</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p1.2.m2.1d">italic_b</annotation></semantics></math>,
we denote the interactive motion as <math alttext="\{\mathbf{m}_{a},\mathbf{m}_{b}\}" class="ltx_Math" display="inline" id="A1.SS1.p1.3.m3.2"><semantics id="A1.SS1.p1.3.m3.2a"><mrow id="A1.SS1.p1.3.m3.2.2.2" xref="A1.SS1.p1.3.m3.2.2.3.cmml"><mo id="A1.SS1.p1.3.m3.2.2.2.3" stretchy="false" xref="A1.SS1.p1.3.m3.2.2.3.cmml">{</mo><msub id="A1.SS1.p1.3.m3.1.1.1.1" xref="A1.SS1.p1.3.m3.1.1.1.1.cmml"><mi id="A1.SS1.p1.3.m3.1.1.1.1.2" xref="A1.SS1.p1.3.m3.1.1.1.1.2.cmml">𝐦</mi><mi id="A1.SS1.p1.3.m3.1.1.1.1.3" xref="A1.SS1.p1.3.m3.1.1.1.1.3.cmml">a</mi></msub><mo id="A1.SS1.p1.3.m3.2.2.2.4" xref="A1.SS1.p1.3.m3.2.2.3.cmml">,</mo><msub id="A1.SS1.p1.3.m3.2.2.2.2" xref="A1.SS1.p1.3.m3.2.2.2.2.cmml"><mi id="A1.SS1.p1.3.m3.2.2.2.2.2" xref="A1.SS1.p1.3.m3.2.2.2.2.2.cmml">𝐦</mi><mi id="A1.SS1.p1.3.m3.2.2.2.2.3" xref="A1.SS1.p1.3.m3.2.2.2.2.3.cmml">b</mi></msub><mo id="A1.SS1.p1.3.m3.2.2.2.5" stretchy="false" xref="A1.SS1.p1.3.m3.2.2.3.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.3.m3.2b"><set id="A1.SS1.p1.3.m3.2.2.3.cmml" xref="A1.SS1.p1.3.m3.2.2.2"><apply id="A1.SS1.p1.3.m3.1.1.1.1.cmml" xref="A1.SS1.p1.3.m3.1.1.1.1"><csymbol cd="ambiguous" id="A1.SS1.p1.3.m3.1.1.1.1.1.cmml" xref="A1.SS1.p1.3.m3.1.1.1.1">subscript</csymbol><ci id="A1.SS1.p1.3.m3.1.1.1.1.2.cmml" xref="A1.SS1.p1.3.m3.1.1.1.1.2">𝐦</ci><ci id="A1.SS1.p1.3.m3.1.1.1.1.3.cmml" xref="A1.SS1.p1.3.m3.1.1.1.1.3">𝑎</ci></apply><apply id="A1.SS1.p1.3.m3.2.2.2.2.cmml" xref="A1.SS1.p1.3.m3.2.2.2.2"><csymbol cd="ambiguous" id="A1.SS1.p1.3.m3.2.2.2.2.1.cmml" xref="A1.SS1.p1.3.m3.2.2.2.2">subscript</csymbol><ci id="A1.SS1.p1.3.m3.2.2.2.2.2.cmml" xref="A1.SS1.p1.3.m3.2.2.2.2.2">𝐦</ci><ci id="A1.SS1.p1.3.m3.2.2.2.2.3.cmml" xref="A1.SS1.p1.3.m3.2.2.2.2.3">𝑏</ci></apply></set></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.3.m3.2c">\{\mathbf{m}_{a},\mathbf{m}_{b}\}</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p1.3.m3.2d">{ bold_m start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT , bold_m start_POSTSUBSCRIPT italic_b end_POSTSUBSCRIPT }</annotation></semantics></math>, following non-canonical representation from <cite class="ltx_cite ltx_citemacro_cite">Liang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib22" title="">2024</a>)</cite>. Each timestep of the motion <math alttext="\mathbf{m}^{i}=[\mathbf{j}_{g}^{p},\mathbf{j}_{g}^{v},\mathbf{j}^{r},\mathbf{c%
}^{f}]" class="ltx_Math" display="inline" id="A1.SS1.p1.4.m4.4"><semantics id="A1.SS1.p1.4.m4.4a"><mrow id="A1.SS1.p1.4.m4.4.4" xref="A1.SS1.p1.4.m4.4.4.cmml"><msup id="A1.SS1.p1.4.m4.4.4.6" xref="A1.SS1.p1.4.m4.4.4.6.cmml"><mi id="A1.SS1.p1.4.m4.4.4.6.2" xref="A1.SS1.p1.4.m4.4.4.6.2.cmml">𝐦</mi><mi id="A1.SS1.p1.4.m4.4.4.6.3" xref="A1.SS1.p1.4.m4.4.4.6.3.cmml">i</mi></msup><mo id="A1.SS1.p1.4.m4.4.4.5" xref="A1.SS1.p1.4.m4.4.4.5.cmml">=</mo><mrow id="A1.SS1.p1.4.m4.4.4.4.4" xref="A1.SS1.p1.4.m4.4.4.4.5.cmml"><mo id="A1.SS1.p1.4.m4.4.4.4.4.5" stretchy="false" xref="A1.SS1.p1.4.m4.4.4.4.5.cmml">[</mo><msubsup id="A1.SS1.p1.4.m4.1.1.1.1.1" xref="A1.SS1.p1.4.m4.1.1.1.1.1.cmml"><mi id="A1.SS1.p1.4.m4.1.1.1.1.1.2.2" xref="A1.SS1.p1.4.m4.1.1.1.1.1.2.2.cmml">𝐣</mi><mi id="A1.SS1.p1.4.m4.1.1.1.1.1.2.3" xref="A1.SS1.p1.4.m4.1.1.1.1.1.2.3.cmml">g</mi><mi id="A1.SS1.p1.4.m4.1.1.1.1.1.3" xref="A1.SS1.p1.4.m4.1.1.1.1.1.3.cmml">p</mi></msubsup><mo id="A1.SS1.p1.4.m4.4.4.4.4.6" xref="A1.SS1.p1.4.m4.4.4.4.5.cmml">,</mo><msubsup id="A1.SS1.p1.4.m4.2.2.2.2.2" xref="A1.SS1.p1.4.m4.2.2.2.2.2.cmml"><mi id="A1.SS1.p1.4.m4.2.2.2.2.2.2.2" xref="A1.SS1.p1.4.m4.2.2.2.2.2.2.2.cmml">𝐣</mi><mi id="A1.SS1.p1.4.m4.2.2.2.2.2.2.3" xref="A1.SS1.p1.4.m4.2.2.2.2.2.2.3.cmml">g</mi><mi id="A1.SS1.p1.4.m4.2.2.2.2.2.3" xref="A1.SS1.p1.4.m4.2.2.2.2.2.3.cmml">v</mi></msubsup><mo id="A1.SS1.p1.4.m4.4.4.4.4.7" xref="A1.SS1.p1.4.m4.4.4.4.5.cmml">,</mo><msup id="A1.SS1.p1.4.m4.3.3.3.3.3" xref="A1.SS1.p1.4.m4.3.3.3.3.3.cmml"><mi id="A1.SS1.p1.4.m4.3.3.3.3.3.2" xref="A1.SS1.p1.4.m4.3.3.3.3.3.2.cmml">𝐣</mi><mi id="A1.SS1.p1.4.m4.3.3.3.3.3.3" xref="A1.SS1.p1.4.m4.3.3.3.3.3.3.cmml">r</mi></msup><mo id="A1.SS1.p1.4.m4.4.4.4.4.8" xref="A1.SS1.p1.4.m4.4.4.4.5.cmml">,</mo><msup id="A1.SS1.p1.4.m4.4.4.4.4.4" xref="A1.SS1.p1.4.m4.4.4.4.4.4.cmml"><mi id="A1.SS1.p1.4.m4.4.4.4.4.4.2" xref="A1.SS1.p1.4.m4.4.4.4.4.4.2.cmml">𝐜</mi><mi id="A1.SS1.p1.4.m4.4.4.4.4.4.3" xref="A1.SS1.p1.4.m4.4.4.4.4.4.3.cmml">f</mi></msup><mo id="A1.SS1.p1.4.m4.4.4.4.4.9" stretchy="false" xref="A1.SS1.p1.4.m4.4.4.4.5.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.4.m4.4b"><apply id="A1.SS1.p1.4.m4.4.4.cmml" xref="A1.SS1.p1.4.m4.4.4"><eq id="A1.SS1.p1.4.m4.4.4.5.cmml" xref="A1.SS1.p1.4.m4.4.4.5"></eq><apply id="A1.SS1.p1.4.m4.4.4.6.cmml" xref="A1.SS1.p1.4.m4.4.4.6"><csymbol cd="ambiguous" id="A1.SS1.p1.4.m4.4.4.6.1.cmml" xref="A1.SS1.p1.4.m4.4.4.6">superscript</csymbol><ci id="A1.SS1.p1.4.m4.4.4.6.2.cmml" xref="A1.SS1.p1.4.m4.4.4.6.2">𝐦</ci><ci id="A1.SS1.p1.4.m4.4.4.6.3.cmml" xref="A1.SS1.p1.4.m4.4.4.6.3">𝑖</ci></apply><list id="A1.SS1.p1.4.m4.4.4.4.5.cmml" xref="A1.SS1.p1.4.m4.4.4.4.4"><apply id="A1.SS1.p1.4.m4.1.1.1.1.1.cmml" xref="A1.SS1.p1.4.m4.1.1.1.1.1"><csymbol cd="ambiguous" id="A1.SS1.p1.4.m4.1.1.1.1.1.1.cmml" xref="A1.SS1.p1.4.m4.1.1.1.1.1">superscript</csymbol><apply id="A1.SS1.p1.4.m4.1.1.1.1.1.2.cmml" xref="A1.SS1.p1.4.m4.1.1.1.1.1"><csymbol cd="ambiguous" id="A1.SS1.p1.4.m4.1.1.1.1.1.2.1.cmml" xref="A1.SS1.p1.4.m4.1.1.1.1.1">subscript</csymbol><ci id="A1.SS1.p1.4.m4.1.1.1.1.1.2.2.cmml" xref="A1.SS1.p1.4.m4.1.1.1.1.1.2.2">𝐣</ci><ci id="A1.SS1.p1.4.m4.1.1.1.1.1.2.3.cmml" xref="A1.SS1.p1.4.m4.1.1.1.1.1.2.3">𝑔</ci></apply><ci id="A1.SS1.p1.4.m4.1.1.1.1.1.3.cmml" xref="A1.SS1.p1.4.m4.1.1.1.1.1.3">𝑝</ci></apply><apply id="A1.SS1.p1.4.m4.2.2.2.2.2.cmml" xref="A1.SS1.p1.4.m4.2.2.2.2.2"><csymbol cd="ambiguous" id="A1.SS1.p1.4.m4.2.2.2.2.2.1.cmml" xref="A1.SS1.p1.4.m4.2.2.2.2.2">superscript</csymbol><apply id="A1.SS1.p1.4.m4.2.2.2.2.2.2.cmml" xref="A1.SS1.p1.4.m4.2.2.2.2.2"><csymbol cd="ambiguous" id="A1.SS1.p1.4.m4.2.2.2.2.2.2.1.cmml" xref="A1.SS1.p1.4.m4.2.2.2.2.2">subscript</csymbol><ci id="A1.SS1.p1.4.m4.2.2.2.2.2.2.2.cmml" xref="A1.SS1.p1.4.m4.2.2.2.2.2.2.2">𝐣</ci><ci id="A1.SS1.p1.4.m4.2.2.2.2.2.2.3.cmml" xref="A1.SS1.p1.4.m4.2.2.2.2.2.2.3">𝑔</ci></apply><ci id="A1.SS1.p1.4.m4.2.2.2.2.2.3.cmml" xref="A1.SS1.p1.4.m4.2.2.2.2.2.3">𝑣</ci></apply><apply id="A1.SS1.p1.4.m4.3.3.3.3.3.cmml" xref="A1.SS1.p1.4.m4.3.3.3.3.3"><csymbol cd="ambiguous" id="A1.SS1.p1.4.m4.3.3.3.3.3.1.cmml" xref="A1.SS1.p1.4.m4.3.3.3.3.3">superscript</csymbol><ci id="A1.SS1.p1.4.m4.3.3.3.3.3.2.cmml" xref="A1.SS1.p1.4.m4.3.3.3.3.3.2">𝐣</ci><ci id="A1.SS1.p1.4.m4.3.3.3.3.3.3.cmml" xref="A1.SS1.p1.4.m4.3.3.3.3.3.3">𝑟</ci></apply><apply id="A1.SS1.p1.4.m4.4.4.4.4.4.cmml" xref="A1.SS1.p1.4.m4.4.4.4.4.4"><csymbol cd="ambiguous" id="A1.SS1.p1.4.m4.4.4.4.4.4.1.cmml" xref="A1.SS1.p1.4.m4.4.4.4.4.4">superscript</csymbol><ci id="A1.SS1.p1.4.m4.4.4.4.4.4.2.cmml" xref="A1.SS1.p1.4.m4.4.4.4.4.4.2">𝐜</ci><ci id="A1.SS1.p1.4.m4.4.4.4.4.4.3.cmml" xref="A1.SS1.p1.4.m4.4.4.4.4.4.3">𝑓</ci></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.4.m4.4c">\mathbf{m}^{i}=[\mathbf{j}_{g}^{p},\mathbf{j}_{g}^{v},\mathbf{j}^{r},\mathbf{c%
}^{f}]</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p1.4.m4.4d">bold_m start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT = [ bold_j start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT , bold_j start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_v end_POSTSUPERSCRIPT , bold_j start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT , bold_c start_POSTSUPERSCRIPT italic_f end_POSTSUPERSCRIPT ]</annotation></semantics></math> is composed of global joint positions <math alttext="\mathbf{j}_{g}^{p}\in\mathbb{R}^{3N_{j}}" class="ltx_Math" display="inline" id="A1.SS1.p1.5.m5.1"><semantics id="A1.SS1.p1.5.m5.1a"><mrow id="A1.SS1.p1.5.m5.1.1" xref="A1.SS1.p1.5.m5.1.1.cmml"><msubsup id="A1.SS1.p1.5.m5.1.1.2" xref="A1.SS1.p1.5.m5.1.1.2.cmml"><mi id="A1.SS1.p1.5.m5.1.1.2.2.2" xref="A1.SS1.p1.5.m5.1.1.2.2.2.cmml">𝐣</mi><mi id="A1.SS1.p1.5.m5.1.1.2.2.3" xref="A1.SS1.p1.5.m5.1.1.2.2.3.cmml">g</mi><mi id="A1.SS1.p1.5.m5.1.1.2.3" xref="A1.SS1.p1.5.m5.1.1.2.3.cmml">p</mi></msubsup><mo id="A1.SS1.p1.5.m5.1.1.1" xref="A1.SS1.p1.5.m5.1.1.1.cmml">∈</mo><msup id="A1.SS1.p1.5.m5.1.1.3" xref="A1.SS1.p1.5.m5.1.1.3.cmml"><mi id="A1.SS1.p1.5.m5.1.1.3.2" xref="A1.SS1.p1.5.m5.1.1.3.2.cmml">ℝ</mi><mrow id="A1.SS1.p1.5.m5.1.1.3.3" xref="A1.SS1.p1.5.m5.1.1.3.3.cmml"><mn id="A1.SS1.p1.5.m5.1.1.3.3.2" xref="A1.SS1.p1.5.m5.1.1.3.3.2.cmml">3</mn><mo id="A1.SS1.p1.5.m5.1.1.3.3.1" xref="A1.SS1.p1.5.m5.1.1.3.3.1.cmml">⁢</mo><msub id="A1.SS1.p1.5.m5.1.1.3.3.3" xref="A1.SS1.p1.5.m5.1.1.3.3.3.cmml"><mi id="A1.SS1.p1.5.m5.1.1.3.3.3.2" xref="A1.SS1.p1.5.m5.1.1.3.3.3.2.cmml">N</mi><mi id="A1.SS1.p1.5.m5.1.1.3.3.3.3" xref="A1.SS1.p1.5.m5.1.1.3.3.3.3.cmml">j</mi></msub></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.5.m5.1b"><apply id="A1.SS1.p1.5.m5.1.1.cmml" xref="A1.SS1.p1.5.m5.1.1"><in id="A1.SS1.p1.5.m5.1.1.1.cmml" xref="A1.SS1.p1.5.m5.1.1.1"></in><apply id="A1.SS1.p1.5.m5.1.1.2.cmml" xref="A1.SS1.p1.5.m5.1.1.2"><csymbol cd="ambiguous" id="A1.SS1.p1.5.m5.1.1.2.1.cmml" xref="A1.SS1.p1.5.m5.1.1.2">superscript</csymbol><apply id="A1.SS1.p1.5.m5.1.1.2.2.cmml" xref="A1.SS1.p1.5.m5.1.1.2"><csymbol cd="ambiguous" id="A1.SS1.p1.5.m5.1.1.2.2.1.cmml" xref="A1.SS1.p1.5.m5.1.1.2">subscript</csymbol><ci id="A1.SS1.p1.5.m5.1.1.2.2.2.cmml" xref="A1.SS1.p1.5.m5.1.1.2.2.2">𝐣</ci><ci id="A1.SS1.p1.5.m5.1.1.2.2.3.cmml" xref="A1.SS1.p1.5.m5.1.1.2.2.3">𝑔</ci></apply><ci id="A1.SS1.p1.5.m5.1.1.2.3.cmml" xref="A1.SS1.p1.5.m5.1.1.2.3">𝑝</ci></apply><apply id="A1.SS1.p1.5.m5.1.1.3.cmml" xref="A1.SS1.p1.5.m5.1.1.3"><csymbol cd="ambiguous" id="A1.SS1.p1.5.m5.1.1.3.1.cmml" xref="A1.SS1.p1.5.m5.1.1.3">superscript</csymbol><ci id="A1.SS1.p1.5.m5.1.1.3.2.cmml" xref="A1.SS1.p1.5.m5.1.1.3.2">ℝ</ci><apply id="A1.SS1.p1.5.m5.1.1.3.3.cmml" xref="A1.SS1.p1.5.m5.1.1.3.3"><times id="A1.SS1.p1.5.m5.1.1.3.3.1.cmml" xref="A1.SS1.p1.5.m5.1.1.3.3.1"></times><cn id="A1.SS1.p1.5.m5.1.1.3.3.2.cmml" type="integer" xref="A1.SS1.p1.5.m5.1.1.3.3.2">3</cn><apply id="A1.SS1.p1.5.m5.1.1.3.3.3.cmml" xref="A1.SS1.p1.5.m5.1.1.3.3.3"><csymbol cd="ambiguous" id="A1.SS1.p1.5.m5.1.1.3.3.3.1.cmml" xref="A1.SS1.p1.5.m5.1.1.3.3.3">subscript</csymbol><ci id="A1.SS1.p1.5.m5.1.1.3.3.3.2.cmml" xref="A1.SS1.p1.5.m5.1.1.3.3.3.2">𝑁</ci><ci id="A1.SS1.p1.5.m5.1.1.3.3.3.3.cmml" xref="A1.SS1.p1.5.m5.1.1.3.3.3.3">𝑗</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.5.m5.1c">\mathbf{j}_{g}^{p}\in\mathbb{R}^{3N_{j}}</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p1.5.m5.1d">bold_j start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_p end_POSTSUPERSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT 3 italic_N start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT end_POSTSUPERSCRIPT</annotation></semantics></math>, global joint velocities <math alttext="\mathbf{j}_{g}^{v}\in\mathbb{R}^{3N_{j}}" class="ltx_Math" display="inline" id="A1.SS1.p1.6.m6.1"><semantics id="A1.SS1.p1.6.m6.1a"><mrow id="A1.SS1.p1.6.m6.1.1" xref="A1.SS1.p1.6.m6.1.1.cmml"><msubsup id="A1.SS1.p1.6.m6.1.1.2" xref="A1.SS1.p1.6.m6.1.1.2.cmml"><mi id="A1.SS1.p1.6.m6.1.1.2.2.2" xref="A1.SS1.p1.6.m6.1.1.2.2.2.cmml">𝐣</mi><mi id="A1.SS1.p1.6.m6.1.1.2.2.3" xref="A1.SS1.p1.6.m6.1.1.2.2.3.cmml">g</mi><mi id="A1.SS1.p1.6.m6.1.1.2.3" xref="A1.SS1.p1.6.m6.1.1.2.3.cmml">v</mi></msubsup><mo id="A1.SS1.p1.6.m6.1.1.1" xref="A1.SS1.p1.6.m6.1.1.1.cmml">∈</mo><msup id="A1.SS1.p1.6.m6.1.1.3" xref="A1.SS1.p1.6.m6.1.1.3.cmml"><mi id="A1.SS1.p1.6.m6.1.1.3.2" xref="A1.SS1.p1.6.m6.1.1.3.2.cmml">ℝ</mi><mrow id="A1.SS1.p1.6.m6.1.1.3.3" xref="A1.SS1.p1.6.m6.1.1.3.3.cmml"><mn id="A1.SS1.p1.6.m6.1.1.3.3.2" xref="A1.SS1.p1.6.m6.1.1.3.3.2.cmml">3</mn><mo id="A1.SS1.p1.6.m6.1.1.3.3.1" xref="A1.SS1.p1.6.m6.1.1.3.3.1.cmml">⁢</mo><msub id="A1.SS1.p1.6.m6.1.1.3.3.3" xref="A1.SS1.p1.6.m6.1.1.3.3.3.cmml"><mi id="A1.SS1.p1.6.m6.1.1.3.3.3.2" xref="A1.SS1.p1.6.m6.1.1.3.3.3.2.cmml">N</mi><mi id="A1.SS1.p1.6.m6.1.1.3.3.3.3" xref="A1.SS1.p1.6.m6.1.1.3.3.3.3.cmml">j</mi></msub></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.6.m6.1b"><apply id="A1.SS1.p1.6.m6.1.1.cmml" xref="A1.SS1.p1.6.m6.1.1"><in id="A1.SS1.p1.6.m6.1.1.1.cmml" xref="A1.SS1.p1.6.m6.1.1.1"></in><apply id="A1.SS1.p1.6.m6.1.1.2.cmml" xref="A1.SS1.p1.6.m6.1.1.2"><csymbol cd="ambiguous" id="A1.SS1.p1.6.m6.1.1.2.1.cmml" xref="A1.SS1.p1.6.m6.1.1.2">superscript</csymbol><apply id="A1.SS1.p1.6.m6.1.1.2.2.cmml" xref="A1.SS1.p1.6.m6.1.1.2"><csymbol cd="ambiguous" id="A1.SS1.p1.6.m6.1.1.2.2.1.cmml" xref="A1.SS1.p1.6.m6.1.1.2">subscript</csymbol><ci id="A1.SS1.p1.6.m6.1.1.2.2.2.cmml" xref="A1.SS1.p1.6.m6.1.1.2.2.2">𝐣</ci><ci id="A1.SS1.p1.6.m6.1.1.2.2.3.cmml" xref="A1.SS1.p1.6.m6.1.1.2.2.3">𝑔</ci></apply><ci id="A1.SS1.p1.6.m6.1.1.2.3.cmml" xref="A1.SS1.p1.6.m6.1.1.2.3">𝑣</ci></apply><apply id="A1.SS1.p1.6.m6.1.1.3.cmml" xref="A1.SS1.p1.6.m6.1.1.3"><csymbol cd="ambiguous" id="A1.SS1.p1.6.m6.1.1.3.1.cmml" xref="A1.SS1.p1.6.m6.1.1.3">superscript</csymbol><ci id="A1.SS1.p1.6.m6.1.1.3.2.cmml" xref="A1.SS1.p1.6.m6.1.1.3.2">ℝ</ci><apply id="A1.SS1.p1.6.m6.1.1.3.3.cmml" xref="A1.SS1.p1.6.m6.1.1.3.3"><times id="A1.SS1.p1.6.m6.1.1.3.3.1.cmml" xref="A1.SS1.p1.6.m6.1.1.3.3.1"></times><cn id="A1.SS1.p1.6.m6.1.1.3.3.2.cmml" type="integer" xref="A1.SS1.p1.6.m6.1.1.3.3.2">3</cn><apply id="A1.SS1.p1.6.m6.1.1.3.3.3.cmml" xref="A1.SS1.p1.6.m6.1.1.3.3.3"><csymbol cd="ambiguous" id="A1.SS1.p1.6.m6.1.1.3.3.3.1.cmml" xref="A1.SS1.p1.6.m6.1.1.3.3.3">subscript</csymbol><ci id="A1.SS1.p1.6.m6.1.1.3.3.3.2.cmml" xref="A1.SS1.p1.6.m6.1.1.3.3.3.2">𝑁</ci><ci id="A1.SS1.p1.6.m6.1.1.3.3.3.3.cmml" xref="A1.SS1.p1.6.m6.1.1.3.3.3.3">𝑗</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.6.m6.1c">\mathbf{j}_{g}^{v}\in\mathbb{R}^{3N_{j}}</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p1.6.m6.1d">bold_j start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_v end_POSTSUPERSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT 3 italic_N start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT end_POSTSUPERSCRIPT</annotation></semantics></math>, 6D representation of local rotations <math alttext="\mathbf{j}^{r}\in\mathbb{R}^{6N_{j}}" class="ltx_Math" display="inline" id="A1.SS1.p1.7.m7.1"><semantics id="A1.SS1.p1.7.m7.1a"><mrow id="A1.SS1.p1.7.m7.1.1" xref="A1.SS1.p1.7.m7.1.1.cmml"><msup id="A1.SS1.p1.7.m7.1.1.2" xref="A1.SS1.p1.7.m7.1.1.2.cmml"><mi id="A1.SS1.p1.7.m7.1.1.2.2" xref="A1.SS1.p1.7.m7.1.1.2.2.cmml">𝐣</mi><mi id="A1.SS1.p1.7.m7.1.1.2.3" xref="A1.SS1.p1.7.m7.1.1.2.3.cmml">r</mi></msup><mo id="A1.SS1.p1.7.m7.1.1.1" xref="A1.SS1.p1.7.m7.1.1.1.cmml">∈</mo><msup id="A1.SS1.p1.7.m7.1.1.3" xref="A1.SS1.p1.7.m7.1.1.3.cmml"><mi id="A1.SS1.p1.7.m7.1.1.3.2" xref="A1.SS1.p1.7.m7.1.1.3.2.cmml">ℝ</mi><mrow id="A1.SS1.p1.7.m7.1.1.3.3" xref="A1.SS1.p1.7.m7.1.1.3.3.cmml"><mn id="A1.SS1.p1.7.m7.1.1.3.3.2" xref="A1.SS1.p1.7.m7.1.1.3.3.2.cmml">6</mn><mo id="A1.SS1.p1.7.m7.1.1.3.3.1" xref="A1.SS1.p1.7.m7.1.1.3.3.1.cmml">⁢</mo><msub id="A1.SS1.p1.7.m7.1.1.3.3.3" xref="A1.SS1.p1.7.m7.1.1.3.3.3.cmml"><mi id="A1.SS1.p1.7.m7.1.1.3.3.3.2" xref="A1.SS1.p1.7.m7.1.1.3.3.3.2.cmml">N</mi><mi id="A1.SS1.p1.7.m7.1.1.3.3.3.3" xref="A1.SS1.p1.7.m7.1.1.3.3.3.3.cmml">j</mi></msub></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.7.m7.1b"><apply id="A1.SS1.p1.7.m7.1.1.cmml" xref="A1.SS1.p1.7.m7.1.1"><in id="A1.SS1.p1.7.m7.1.1.1.cmml" xref="A1.SS1.p1.7.m7.1.1.1"></in><apply id="A1.SS1.p1.7.m7.1.1.2.cmml" xref="A1.SS1.p1.7.m7.1.1.2"><csymbol cd="ambiguous" id="A1.SS1.p1.7.m7.1.1.2.1.cmml" xref="A1.SS1.p1.7.m7.1.1.2">superscript</csymbol><ci id="A1.SS1.p1.7.m7.1.1.2.2.cmml" xref="A1.SS1.p1.7.m7.1.1.2.2">𝐣</ci><ci id="A1.SS1.p1.7.m7.1.1.2.3.cmml" xref="A1.SS1.p1.7.m7.1.1.2.3">𝑟</ci></apply><apply id="A1.SS1.p1.7.m7.1.1.3.cmml" xref="A1.SS1.p1.7.m7.1.1.3"><csymbol cd="ambiguous" id="A1.SS1.p1.7.m7.1.1.3.1.cmml" xref="A1.SS1.p1.7.m7.1.1.3">superscript</csymbol><ci id="A1.SS1.p1.7.m7.1.1.3.2.cmml" xref="A1.SS1.p1.7.m7.1.1.3.2">ℝ</ci><apply id="A1.SS1.p1.7.m7.1.1.3.3.cmml" xref="A1.SS1.p1.7.m7.1.1.3.3"><times id="A1.SS1.p1.7.m7.1.1.3.3.1.cmml" xref="A1.SS1.p1.7.m7.1.1.3.3.1"></times><cn id="A1.SS1.p1.7.m7.1.1.3.3.2.cmml" type="integer" xref="A1.SS1.p1.7.m7.1.1.3.3.2">6</cn><apply id="A1.SS1.p1.7.m7.1.1.3.3.3.cmml" xref="A1.SS1.p1.7.m7.1.1.3.3.3"><csymbol cd="ambiguous" id="A1.SS1.p1.7.m7.1.1.3.3.3.1.cmml" xref="A1.SS1.p1.7.m7.1.1.3.3.3">subscript</csymbol><ci id="A1.SS1.p1.7.m7.1.1.3.3.3.2.cmml" xref="A1.SS1.p1.7.m7.1.1.3.3.3.2">𝑁</ci><ci id="A1.SS1.p1.7.m7.1.1.3.3.3.3.cmml" xref="A1.SS1.p1.7.m7.1.1.3.3.3.3">𝑗</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.7.m7.1c">\mathbf{j}^{r}\in\mathbb{R}^{6N_{j}}</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p1.7.m7.1d">bold_j start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT 6 italic_N start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT end_POSTSUPERSCRIPT</annotation></semantics></math>, with the number of joints <math alttext="N_{j}" class="ltx_Math" display="inline" id="A1.SS1.p1.8.m8.1"><semantics id="A1.SS1.p1.8.m8.1a"><msub id="A1.SS1.p1.8.m8.1.1" xref="A1.SS1.p1.8.m8.1.1.cmml"><mi id="A1.SS1.p1.8.m8.1.1.2" xref="A1.SS1.p1.8.m8.1.1.2.cmml">N</mi><mi id="A1.SS1.p1.8.m8.1.1.3" xref="A1.SS1.p1.8.m8.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.8.m8.1b"><apply id="A1.SS1.p1.8.m8.1.1.cmml" xref="A1.SS1.p1.8.m8.1.1"><csymbol cd="ambiguous" id="A1.SS1.p1.8.m8.1.1.1.cmml" xref="A1.SS1.p1.8.m8.1.1">subscript</csymbol><ci id="A1.SS1.p1.8.m8.1.1.2.cmml" xref="A1.SS1.p1.8.m8.1.1.2">𝑁</ci><ci id="A1.SS1.p1.8.m8.1.1.3.cmml" xref="A1.SS1.p1.8.m8.1.1.3">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.8.m8.1c">N_{j}</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p1.8.m8.1d">italic_N start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math>, and binary ground contact features <math alttext="\mathbf{c}^{f}\in\mathbb{R}^{4}" class="ltx_Math" display="inline" id="A1.SS1.p1.9.m9.1"><semantics id="A1.SS1.p1.9.m9.1a"><mrow id="A1.SS1.p1.9.m9.1.1" xref="A1.SS1.p1.9.m9.1.1.cmml"><msup id="A1.SS1.p1.9.m9.1.1.2" xref="A1.SS1.p1.9.m9.1.1.2.cmml"><mi id="A1.SS1.p1.9.m9.1.1.2.2" xref="A1.SS1.p1.9.m9.1.1.2.2.cmml">𝐜</mi><mi id="A1.SS1.p1.9.m9.1.1.2.3" xref="A1.SS1.p1.9.m9.1.1.2.3.cmml">f</mi></msup><mo id="A1.SS1.p1.9.m9.1.1.1" xref="A1.SS1.p1.9.m9.1.1.1.cmml">∈</mo><msup id="A1.SS1.p1.9.m9.1.1.3" xref="A1.SS1.p1.9.m9.1.1.3.cmml"><mi id="A1.SS1.p1.9.m9.1.1.3.2" xref="A1.SS1.p1.9.m9.1.1.3.2.cmml">ℝ</mi><mn id="A1.SS1.p1.9.m9.1.1.3.3" xref="A1.SS1.p1.9.m9.1.1.3.3.cmml">4</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.9.m9.1b"><apply id="A1.SS1.p1.9.m9.1.1.cmml" xref="A1.SS1.p1.9.m9.1.1"><in id="A1.SS1.p1.9.m9.1.1.1.cmml" xref="A1.SS1.p1.9.m9.1.1.1"></in><apply id="A1.SS1.p1.9.m9.1.1.2.cmml" xref="A1.SS1.p1.9.m9.1.1.2"><csymbol cd="ambiguous" id="A1.SS1.p1.9.m9.1.1.2.1.cmml" xref="A1.SS1.p1.9.m9.1.1.2">superscript</csymbol><ci id="A1.SS1.p1.9.m9.1.1.2.2.cmml" xref="A1.SS1.p1.9.m9.1.1.2.2">𝐜</ci><ci id="A1.SS1.p1.9.m9.1.1.2.3.cmml" xref="A1.SS1.p1.9.m9.1.1.2.3">𝑓</ci></apply><apply id="A1.SS1.p1.9.m9.1.1.3.cmml" xref="A1.SS1.p1.9.m9.1.1.3"><csymbol cd="ambiguous" id="A1.SS1.p1.9.m9.1.1.3.1.cmml" xref="A1.SS1.p1.9.m9.1.1.3">superscript</csymbol><ci id="A1.SS1.p1.9.m9.1.1.3.2.cmml" xref="A1.SS1.p1.9.m9.1.1.3.2">ℝ</ci><cn id="A1.SS1.p1.9.m9.1.1.3.3.cmml" type="integer" xref="A1.SS1.p1.9.m9.1.1.3.3">4</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.9.m9.1c">\mathbf{c}^{f}\in\mathbb{R}^{4}</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p1.9.m9.1d">bold_c start_POSTSUPERSCRIPT italic_f end_POSTSUPERSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT</annotation></semantics></math>. This non-canonical representation is applied for both interactive motions and single-person motions.
All the motions are represented in an SMPL-X <cite class="ltx_cite ltx_citemacro_citep">(Pavlakos et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib29" title="">2019</a>)</cite> format.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS1.p2">
<p class="ltx_p" id="A1.SS1.p2.2">Motion tokenizer encodes the interactive motion into discrete residual tokens in depth <math alttext="D" class="ltx_Math" display="inline" id="A1.SS1.p2.1.m1.1"><semantics id="A1.SS1.p2.1.m1.1a"><mi id="A1.SS1.p2.1.m1.1.1" xref="A1.SS1.p2.1.m1.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="A1.SS1.p2.1.m1.1b"><ci id="A1.SS1.p2.1.m1.1.1.cmml" xref="A1.SS1.p2.1.m1.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p2.1.m1.1c">D</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p2.1.m1.1d">italic_D</annotation></semantics></math>, based on latent vector <math alttext="\mathbf{z}" class="ltx_Math" display="inline" id="A1.SS1.p2.2.m2.1"><semantics id="A1.SS1.p2.2.m2.1a"><mi id="A1.SS1.p2.2.m2.1.1" xref="A1.SS1.p2.2.m2.1.1.cmml">𝐳</mi><annotation-xml encoding="MathML-Content" id="A1.SS1.p2.2.m2.1b"><ci id="A1.SS1.p2.2.m2.1.1.cmml" xref="A1.SS1.p2.2.m2.1.1">𝐳</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p2.2.m2.1c">\mathbf{z}</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p2.2.m2.1d">bold_z</annotation></semantics></math>.</p>
<table class="ltx_equation ltx_eqn_table" id="A1.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{RQ}(\mathbf{z}^{i};\mathcal{C},D)=(k^{i}_{1},\cdots,k^{i}_{D})\in[K]^%
{D}" class="ltx_Math" display="block" id="A1.E2.m1.7"><semantics id="A1.E2.m1.7a"><mrow id="A1.E2.m1.7.7" xref="A1.E2.m1.7.7.cmml"><mrow id="A1.E2.m1.5.5.1" xref="A1.E2.m1.5.5.1.cmml"><mi class="ltx_font_mathcaligraphic" id="A1.E2.m1.5.5.1.3" xref="A1.E2.m1.5.5.1.3.cmml">ℛ</mi><mo id="A1.E2.m1.5.5.1.2" xref="A1.E2.m1.5.5.1.2.cmml">⁢</mo><mi class="ltx_font_mathcaligraphic" id="A1.E2.m1.5.5.1.4" xref="A1.E2.m1.5.5.1.4.cmml">𝒬</mi><mo id="A1.E2.m1.5.5.1.2a" xref="A1.E2.m1.5.5.1.2.cmml">⁢</mo><mrow id="A1.E2.m1.5.5.1.1.1" xref="A1.E2.m1.5.5.1.1.2.cmml"><mo id="A1.E2.m1.5.5.1.1.1.2" stretchy="false" xref="A1.E2.m1.5.5.1.1.2.cmml">(</mo><msup id="A1.E2.m1.5.5.1.1.1.1" xref="A1.E2.m1.5.5.1.1.1.1.cmml"><mi id="A1.E2.m1.5.5.1.1.1.1.2" xref="A1.E2.m1.5.5.1.1.1.1.2.cmml">𝐳</mi><mi id="A1.E2.m1.5.5.1.1.1.1.3" xref="A1.E2.m1.5.5.1.1.1.1.3.cmml">i</mi></msup><mo id="A1.E2.m1.5.5.1.1.1.3" xref="A1.E2.m1.5.5.1.1.2.cmml">;</mo><mi class="ltx_font_mathcaligraphic" id="A1.E2.m1.1.1" xref="A1.E2.m1.1.1.cmml">𝒞</mi><mo id="A1.E2.m1.5.5.1.1.1.4" xref="A1.E2.m1.5.5.1.1.2.cmml">,</mo><mi id="A1.E2.m1.2.2" xref="A1.E2.m1.2.2.cmml">D</mi><mo id="A1.E2.m1.5.5.1.1.1.5" stretchy="false" xref="A1.E2.m1.5.5.1.1.2.cmml">)</mo></mrow></mrow><mo id="A1.E2.m1.7.7.5" xref="A1.E2.m1.7.7.5.cmml">=</mo><mrow id="A1.E2.m1.7.7.3.2" xref="A1.E2.m1.7.7.3.3.cmml"><mo id="A1.E2.m1.7.7.3.2.3" stretchy="false" xref="A1.E2.m1.7.7.3.3.cmml">(</mo><msubsup id="A1.E2.m1.6.6.2.1.1" xref="A1.E2.m1.6.6.2.1.1.cmml"><mi id="A1.E2.m1.6.6.2.1.1.2.2" xref="A1.E2.m1.6.6.2.1.1.2.2.cmml">k</mi><mn id="A1.E2.m1.6.6.2.1.1.3" xref="A1.E2.m1.6.6.2.1.1.3.cmml">1</mn><mi id="A1.E2.m1.6.6.2.1.1.2.3" xref="A1.E2.m1.6.6.2.1.1.2.3.cmml">i</mi></msubsup><mo id="A1.E2.m1.7.7.3.2.4" xref="A1.E2.m1.7.7.3.3.cmml">,</mo><mi id="A1.E2.m1.3.3" mathvariant="normal" xref="A1.E2.m1.3.3.cmml">⋯</mi><mo id="A1.E2.m1.7.7.3.2.5" xref="A1.E2.m1.7.7.3.3.cmml">,</mo><msubsup id="A1.E2.m1.7.7.3.2.2" xref="A1.E2.m1.7.7.3.2.2.cmml"><mi id="A1.E2.m1.7.7.3.2.2.2.2" xref="A1.E2.m1.7.7.3.2.2.2.2.cmml">k</mi><mi id="A1.E2.m1.7.7.3.2.2.3" xref="A1.E2.m1.7.7.3.2.2.3.cmml">D</mi><mi id="A1.E2.m1.7.7.3.2.2.2.3" xref="A1.E2.m1.7.7.3.2.2.2.3.cmml">i</mi></msubsup><mo id="A1.E2.m1.7.7.3.2.6" stretchy="false" xref="A1.E2.m1.7.7.3.3.cmml">)</mo></mrow><mo id="A1.E2.m1.7.7.6" xref="A1.E2.m1.7.7.6.cmml">∈</mo><msup id="A1.E2.m1.7.7.7" xref="A1.E2.m1.7.7.7.cmml"><mrow id="A1.E2.m1.7.7.7.2.2" xref="A1.E2.m1.7.7.7.2.1.cmml"><mo id="A1.E2.m1.7.7.7.2.2.1" stretchy="false" xref="A1.E2.m1.7.7.7.2.1.1.cmml">[</mo><mi id="A1.E2.m1.4.4" xref="A1.E2.m1.4.4.cmml">K</mi><mo id="A1.E2.m1.7.7.7.2.2.2" stretchy="false" xref="A1.E2.m1.7.7.7.2.1.1.cmml">]</mo></mrow><mi id="A1.E2.m1.7.7.7.3" xref="A1.E2.m1.7.7.7.3.cmml">D</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="A1.E2.m1.7b"><apply id="A1.E2.m1.7.7.cmml" xref="A1.E2.m1.7.7"><and id="A1.E2.m1.7.7a.cmml" xref="A1.E2.m1.7.7"></and><apply id="A1.E2.m1.7.7b.cmml" xref="A1.E2.m1.7.7"><eq id="A1.E2.m1.7.7.5.cmml" xref="A1.E2.m1.7.7.5"></eq><apply id="A1.E2.m1.5.5.1.cmml" xref="A1.E2.m1.5.5.1"><times id="A1.E2.m1.5.5.1.2.cmml" xref="A1.E2.m1.5.5.1.2"></times><ci id="A1.E2.m1.5.5.1.3.cmml" xref="A1.E2.m1.5.5.1.3">ℛ</ci><ci id="A1.E2.m1.5.5.1.4.cmml" xref="A1.E2.m1.5.5.1.4">𝒬</ci><list id="A1.E2.m1.5.5.1.1.2.cmml" xref="A1.E2.m1.5.5.1.1.1"><apply id="A1.E2.m1.5.5.1.1.1.1.cmml" xref="A1.E2.m1.5.5.1.1.1.1"><csymbol cd="ambiguous" id="A1.E2.m1.5.5.1.1.1.1.1.cmml" xref="A1.E2.m1.5.5.1.1.1.1">superscript</csymbol><ci id="A1.E2.m1.5.5.1.1.1.1.2.cmml" xref="A1.E2.m1.5.5.1.1.1.1.2">𝐳</ci><ci id="A1.E2.m1.5.5.1.1.1.1.3.cmml" xref="A1.E2.m1.5.5.1.1.1.1.3">𝑖</ci></apply><ci id="A1.E2.m1.1.1.cmml" xref="A1.E2.m1.1.1">𝒞</ci><ci id="A1.E2.m1.2.2.cmml" xref="A1.E2.m1.2.2">𝐷</ci></list></apply><vector id="A1.E2.m1.7.7.3.3.cmml" xref="A1.E2.m1.7.7.3.2"><apply id="A1.E2.m1.6.6.2.1.1.cmml" xref="A1.E2.m1.6.6.2.1.1"><csymbol cd="ambiguous" id="A1.E2.m1.6.6.2.1.1.1.cmml" xref="A1.E2.m1.6.6.2.1.1">subscript</csymbol><apply id="A1.E2.m1.6.6.2.1.1.2.cmml" xref="A1.E2.m1.6.6.2.1.1"><csymbol cd="ambiguous" id="A1.E2.m1.6.6.2.1.1.2.1.cmml" xref="A1.E2.m1.6.6.2.1.1">superscript</csymbol><ci id="A1.E2.m1.6.6.2.1.1.2.2.cmml" xref="A1.E2.m1.6.6.2.1.1.2.2">𝑘</ci><ci id="A1.E2.m1.6.6.2.1.1.2.3.cmml" xref="A1.E2.m1.6.6.2.1.1.2.3">𝑖</ci></apply><cn id="A1.E2.m1.6.6.2.1.1.3.cmml" type="integer" xref="A1.E2.m1.6.6.2.1.1.3">1</cn></apply><ci id="A1.E2.m1.3.3.cmml" xref="A1.E2.m1.3.3">⋯</ci><apply id="A1.E2.m1.7.7.3.2.2.cmml" xref="A1.E2.m1.7.7.3.2.2"><csymbol cd="ambiguous" id="A1.E2.m1.7.7.3.2.2.1.cmml" xref="A1.E2.m1.7.7.3.2.2">subscript</csymbol><apply id="A1.E2.m1.7.7.3.2.2.2.cmml" xref="A1.E2.m1.7.7.3.2.2"><csymbol cd="ambiguous" id="A1.E2.m1.7.7.3.2.2.2.1.cmml" xref="A1.E2.m1.7.7.3.2.2">superscript</csymbol><ci id="A1.E2.m1.7.7.3.2.2.2.2.cmml" xref="A1.E2.m1.7.7.3.2.2.2.2">𝑘</ci><ci id="A1.E2.m1.7.7.3.2.2.2.3.cmml" xref="A1.E2.m1.7.7.3.2.2.2.3">𝑖</ci></apply><ci id="A1.E2.m1.7.7.3.2.2.3.cmml" xref="A1.E2.m1.7.7.3.2.2.3">𝐷</ci></apply></vector></apply><apply id="A1.E2.m1.7.7c.cmml" xref="A1.E2.m1.7.7"><in id="A1.E2.m1.7.7.6.cmml" xref="A1.E2.m1.7.7.6"></in><share href="https://arxiv.org/html/2410.05628v2#A1.E2.m1.7.7.3.cmml" id="A1.E2.m1.7.7d.cmml" xref="A1.E2.m1.7.7"></share><apply id="A1.E2.m1.7.7.7.cmml" xref="A1.E2.m1.7.7.7"><csymbol cd="ambiguous" id="A1.E2.m1.7.7.7.1.cmml" xref="A1.E2.m1.7.7.7">superscript</csymbol><apply id="A1.E2.m1.7.7.7.2.1.cmml" xref="A1.E2.m1.7.7.7.2.2"><csymbol cd="latexml" id="A1.E2.m1.7.7.7.2.1.1.cmml" xref="A1.E2.m1.7.7.7.2.2.1">delimited-[]</csymbol><ci id="A1.E2.m1.4.4.cmml" xref="A1.E2.m1.4.4">𝐾</ci></apply><ci id="A1.E2.m1.7.7.7.3.cmml" xref="A1.E2.m1.7.7.7.3">𝐷</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.E2.m1.7c">\mathcal{RQ}(\mathbf{z}^{i};\mathcal{C},D)=(k^{i}_{1},\cdots,k^{i}_{D})\in[K]^%
{D}</annotation><annotation encoding="application/x-llamapun" id="A1.E2.m1.7d">caligraphic_R caligraphic_Q ( bold_z start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT ; caligraphic_C , italic_D ) = ( italic_k start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , ⋯ , italic_k start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_D end_POSTSUBSCRIPT ) ∈ [ italic_K ] start_POSTSUPERSCRIPT italic_D end_POSTSUPERSCRIPT</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="A1.SS1.p2.9">where <math alttext="\mathcal{C}" class="ltx_Math" display="inline" id="A1.SS1.p2.3.m1.1"><semantics id="A1.SS1.p2.3.m1.1a"><mi class="ltx_font_mathcaligraphic" id="A1.SS1.p2.3.m1.1.1" xref="A1.SS1.p2.3.m1.1.1.cmml">𝒞</mi><annotation-xml encoding="MathML-Content" id="A1.SS1.p2.3.m1.1b"><ci id="A1.SS1.p2.3.m1.1.1.cmml" xref="A1.SS1.p2.3.m1.1.1">𝒞</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p2.3.m1.1c">\mathcal{C}</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p2.3.m1.1d">caligraphic_C</annotation></semantics></math> is the codebook, <math alttext="K=|C|" class="ltx_Math" display="inline" id="A1.SS1.p2.4.m2.1"><semantics id="A1.SS1.p2.4.m2.1a"><mrow id="A1.SS1.p2.4.m2.1.2" xref="A1.SS1.p2.4.m2.1.2.cmml"><mi id="A1.SS1.p2.4.m2.1.2.2" xref="A1.SS1.p2.4.m2.1.2.2.cmml">K</mi><mo id="A1.SS1.p2.4.m2.1.2.1" xref="A1.SS1.p2.4.m2.1.2.1.cmml">=</mo><mrow id="A1.SS1.p2.4.m2.1.2.3.2" xref="A1.SS1.p2.4.m2.1.2.3.1.cmml"><mo id="A1.SS1.p2.4.m2.1.2.3.2.1" stretchy="false" xref="A1.SS1.p2.4.m2.1.2.3.1.1.cmml">|</mo><mi id="A1.SS1.p2.4.m2.1.1" xref="A1.SS1.p2.4.m2.1.1.cmml">C</mi><mo id="A1.SS1.p2.4.m2.1.2.3.2.2" stretchy="false" xref="A1.SS1.p2.4.m2.1.2.3.1.1.cmml">|</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.p2.4.m2.1b"><apply id="A1.SS1.p2.4.m2.1.2.cmml" xref="A1.SS1.p2.4.m2.1.2"><eq id="A1.SS1.p2.4.m2.1.2.1.cmml" xref="A1.SS1.p2.4.m2.1.2.1"></eq><ci id="A1.SS1.p2.4.m2.1.2.2.cmml" xref="A1.SS1.p2.4.m2.1.2.2">𝐾</ci><apply id="A1.SS1.p2.4.m2.1.2.3.1.cmml" xref="A1.SS1.p2.4.m2.1.2.3.2"><abs id="A1.SS1.p2.4.m2.1.2.3.1.1.cmml" xref="A1.SS1.p2.4.m2.1.2.3.2.1"></abs><ci id="A1.SS1.p2.4.m2.1.1.cmml" xref="A1.SS1.p2.4.m2.1.1">𝐶</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p2.4.m2.1c">K=|C|</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p2.4.m2.1d">italic_K = | italic_C |</annotation></semantics></math>, <math alttext="D" class="ltx_Math" display="inline" id="A1.SS1.p2.5.m3.1"><semantics id="A1.SS1.p2.5.m3.1a"><mi id="A1.SS1.p2.5.m3.1.1" xref="A1.SS1.p2.5.m3.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="A1.SS1.p2.5.m3.1b"><ci id="A1.SS1.p2.5.m3.1.1.cmml" xref="A1.SS1.p2.5.m3.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p2.5.m3.1c">D</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p2.5.m3.1d">italic_D</annotation></semantics></math> is a depth, and <math alttext="k^{i}_{d}" class="ltx_Math" display="inline" id="A1.SS1.p2.6.m4.1"><semantics id="A1.SS1.p2.6.m4.1a"><msubsup id="A1.SS1.p2.6.m4.1.1" xref="A1.SS1.p2.6.m4.1.1.cmml"><mi id="A1.SS1.p2.6.m4.1.1.2.2" xref="A1.SS1.p2.6.m4.1.1.2.2.cmml">k</mi><mi id="A1.SS1.p2.6.m4.1.1.3" xref="A1.SS1.p2.6.m4.1.1.3.cmml">d</mi><mi id="A1.SS1.p2.6.m4.1.1.2.3" xref="A1.SS1.p2.6.m4.1.1.2.3.cmml">i</mi></msubsup><annotation-xml encoding="MathML-Content" id="A1.SS1.p2.6.m4.1b"><apply id="A1.SS1.p2.6.m4.1.1.cmml" xref="A1.SS1.p2.6.m4.1.1"><csymbol cd="ambiguous" id="A1.SS1.p2.6.m4.1.1.1.cmml" xref="A1.SS1.p2.6.m4.1.1">subscript</csymbol><apply id="A1.SS1.p2.6.m4.1.1.2.cmml" xref="A1.SS1.p2.6.m4.1.1"><csymbol cd="ambiguous" id="A1.SS1.p2.6.m4.1.1.2.1.cmml" xref="A1.SS1.p2.6.m4.1.1">superscript</csymbol><ci id="A1.SS1.p2.6.m4.1.1.2.2.cmml" xref="A1.SS1.p2.6.m4.1.1.2.2">𝑘</ci><ci id="A1.SS1.p2.6.m4.1.1.2.3.cmml" xref="A1.SS1.p2.6.m4.1.1.2.3">𝑖</ci></apply><ci id="A1.SS1.p2.6.m4.1.1.3.cmml" xref="A1.SS1.p2.6.m4.1.1.3">𝑑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p2.6.m4.1c">k^{i}_{d}</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p2.6.m4.1d">italic_k start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_d end_POSTSUBSCRIPT</annotation></semantics></math> is code of <math alttext="\mathbf{z}" class="ltx_Math" display="inline" id="A1.SS1.p2.7.m5.1"><semantics id="A1.SS1.p2.7.m5.1a"><mi id="A1.SS1.p2.7.m5.1.1" xref="A1.SS1.p2.7.m5.1.1.cmml">𝐳</mi><annotation-xml encoding="MathML-Content" id="A1.SS1.p2.7.m5.1b"><ci id="A1.SS1.p2.7.m5.1.1.cmml" xref="A1.SS1.p2.7.m5.1.1">𝐳</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p2.7.m5.1c">\mathbf{z}</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p2.7.m5.1d">bold_z</annotation></semantics></math> at timestep <math alttext="i" class="ltx_Math" display="inline" id="A1.SS1.p2.8.m6.1"><semantics id="A1.SS1.p2.8.m6.1a"><mi id="A1.SS1.p2.8.m6.1.1" xref="A1.SS1.p2.8.m6.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="A1.SS1.p2.8.m6.1b"><ci id="A1.SS1.p2.8.m6.1.1.cmml" xref="A1.SS1.p2.8.m6.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p2.8.m6.1c">i</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p2.8.m6.1d">italic_i</annotation></semantics></math> with depth <math alttext="d" class="ltx_Math" display="inline" id="A1.SS1.p2.9.m7.1"><semantics id="A1.SS1.p2.9.m7.1a"><mi id="A1.SS1.p2.9.m7.1.1" xref="A1.SS1.p2.9.m7.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="A1.SS1.p2.9.m7.1b"><ci id="A1.SS1.p2.9.m7.1.1.cmml" xref="A1.SS1.p2.9.m7.1.1">𝑑</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p2.9.m7.1c">d</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p2.9.m7.1d">italic_d</annotation></semantics></math>.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS1.p3">
<p class="ltx_p" id="A1.SS1.p3.5">The interactive motion token sequence is represented as <math alttext="X_{m}=\{k^{1;a}_{1:D},k^{1;b}_{1:D},\cdots,k^{L;a}_{1:D},k^{L;b}_{1:D}\}" class="ltx_Math" display="inline" id="A1.SS1.p3.1.m1.13"><semantics id="A1.SS1.p3.1.m1.13a"><mrow id="A1.SS1.p3.1.m1.13.13" xref="A1.SS1.p3.1.m1.13.13.cmml"><msub id="A1.SS1.p3.1.m1.13.13.6" xref="A1.SS1.p3.1.m1.13.13.6.cmml"><mi id="A1.SS1.p3.1.m1.13.13.6.2" xref="A1.SS1.p3.1.m1.13.13.6.2.cmml">X</mi><mi id="A1.SS1.p3.1.m1.13.13.6.3" xref="A1.SS1.p3.1.m1.13.13.6.3.cmml">m</mi></msub><mo id="A1.SS1.p3.1.m1.13.13.5" xref="A1.SS1.p3.1.m1.13.13.5.cmml">=</mo><mrow id="A1.SS1.p3.1.m1.13.13.4.4" xref="A1.SS1.p3.1.m1.13.13.4.5.cmml"><mo id="A1.SS1.p3.1.m1.13.13.4.4.5" stretchy="false" xref="A1.SS1.p3.1.m1.13.13.4.5.cmml">{</mo><msubsup id="A1.SS1.p3.1.m1.10.10.1.1.1" xref="A1.SS1.p3.1.m1.10.10.1.1.1.cmml"><mi id="A1.SS1.p3.1.m1.10.10.1.1.1.2.2" xref="A1.SS1.p3.1.m1.10.10.1.1.1.2.2.cmml">k</mi><mrow id="A1.SS1.p3.1.m1.10.10.1.1.1.3" xref="A1.SS1.p3.1.m1.10.10.1.1.1.3.cmml"><mn id="A1.SS1.p3.1.m1.10.10.1.1.1.3.2" xref="A1.SS1.p3.1.m1.10.10.1.1.1.3.2.cmml">1</mn><mo id="A1.SS1.p3.1.m1.10.10.1.1.1.3.1" lspace="0.278em" rspace="0.278em" xref="A1.SS1.p3.1.m1.10.10.1.1.1.3.1.cmml">:</mo><mi id="A1.SS1.p3.1.m1.10.10.1.1.1.3.3" xref="A1.SS1.p3.1.m1.10.10.1.1.1.3.3.cmml">D</mi></mrow><mrow id="A1.SS1.p3.1.m1.2.2.2.4" xref="A1.SS1.p3.1.m1.2.2.2.3.cmml"><mn id="A1.SS1.p3.1.m1.1.1.1.1" xref="A1.SS1.p3.1.m1.1.1.1.1.cmml">1</mn><mo id="A1.SS1.p3.1.m1.2.2.2.4.1" xref="A1.SS1.p3.1.m1.2.2.2.3.cmml">;</mo><mi id="A1.SS1.p3.1.m1.2.2.2.2" xref="A1.SS1.p3.1.m1.2.2.2.2.cmml">a</mi></mrow></msubsup><mo id="A1.SS1.p3.1.m1.13.13.4.4.6" xref="A1.SS1.p3.1.m1.13.13.4.5.cmml">,</mo><msubsup id="A1.SS1.p3.1.m1.11.11.2.2.2" xref="A1.SS1.p3.1.m1.11.11.2.2.2.cmml"><mi id="A1.SS1.p3.1.m1.11.11.2.2.2.2.2" xref="A1.SS1.p3.1.m1.11.11.2.2.2.2.2.cmml">k</mi><mrow id="A1.SS1.p3.1.m1.11.11.2.2.2.3" xref="A1.SS1.p3.1.m1.11.11.2.2.2.3.cmml"><mn id="A1.SS1.p3.1.m1.11.11.2.2.2.3.2" xref="A1.SS1.p3.1.m1.11.11.2.2.2.3.2.cmml">1</mn><mo id="A1.SS1.p3.1.m1.11.11.2.2.2.3.1" lspace="0.278em" rspace="0.278em" xref="A1.SS1.p3.1.m1.11.11.2.2.2.3.1.cmml">:</mo><mi id="A1.SS1.p3.1.m1.11.11.2.2.2.3.3" xref="A1.SS1.p3.1.m1.11.11.2.2.2.3.3.cmml">D</mi></mrow><mrow id="A1.SS1.p3.1.m1.4.4.2.4" xref="A1.SS1.p3.1.m1.4.4.2.3.cmml"><mn id="A1.SS1.p3.1.m1.3.3.1.1" xref="A1.SS1.p3.1.m1.3.3.1.1.cmml">1</mn><mo id="A1.SS1.p3.1.m1.4.4.2.4.1" xref="A1.SS1.p3.1.m1.4.4.2.3.cmml">;</mo><mi id="A1.SS1.p3.1.m1.4.4.2.2" xref="A1.SS1.p3.1.m1.4.4.2.2.cmml">b</mi></mrow></msubsup><mo id="A1.SS1.p3.1.m1.13.13.4.4.7" xref="A1.SS1.p3.1.m1.13.13.4.5.cmml">,</mo><mi id="A1.SS1.p3.1.m1.9.9" mathvariant="normal" xref="A1.SS1.p3.1.m1.9.9.cmml">⋯</mi><mo id="A1.SS1.p3.1.m1.13.13.4.4.8" xref="A1.SS1.p3.1.m1.13.13.4.5.cmml">,</mo><msubsup id="A1.SS1.p3.1.m1.12.12.3.3.3" xref="A1.SS1.p3.1.m1.12.12.3.3.3.cmml"><mi id="A1.SS1.p3.1.m1.12.12.3.3.3.2.2" xref="A1.SS1.p3.1.m1.12.12.3.3.3.2.2.cmml">k</mi><mrow id="A1.SS1.p3.1.m1.12.12.3.3.3.3" xref="A1.SS1.p3.1.m1.12.12.3.3.3.3.cmml"><mn id="A1.SS1.p3.1.m1.12.12.3.3.3.3.2" xref="A1.SS1.p3.1.m1.12.12.3.3.3.3.2.cmml">1</mn><mo id="A1.SS1.p3.1.m1.12.12.3.3.3.3.1" lspace="0.278em" rspace="0.278em" xref="A1.SS1.p3.1.m1.12.12.3.3.3.3.1.cmml">:</mo><mi id="A1.SS1.p3.1.m1.12.12.3.3.3.3.3" xref="A1.SS1.p3.1.m1.12.12.3.3.3.3.3.cmml">D</mi></mrow><mrow id="A1.SS1.p3.1.m1.6.6.2.4" xref="A1.SS1.p3.1.m1.6.6.2.3.cmml"><mi id="A1.SS1.p3.1.m1.5.5.1.1" xref="A1.SS1.p3.1.m1.5.5.1.1.cmml">L</mi><mo id="A1.SS1.p3.1.m1.6.6.2.4.1" xref="A1.SS1.p3.1.m1.6.6.2.3.cmml">;</mo><mi id="A1.SS1.p3.1.m1.6.6.2.2" xref="A1.SS1.p3.1.m1.6.6.2.2.cmml">a</mi></mrow></msubsup><mo id="A1.SS1.p3.1.m1.13.13.4.4.9" xref="A1.SS1.p3.1.m1.13.13.4.5.cmml">,</mo><msubsup id="A1.SS1.p3.1.m1.13.13.4.4.4" xref="A1.SS1.p3.1.m1.13.13.4.4.4.cmml"><mi id="A1.SS1.p3.1.m1.13.13.4.4.4.2.2" xref="A1.SS1.p3.1.m1.13.13.4.4.4.2.2.cmml">k</mi><mrow id="A1.SS1.p3.1.m1.13.13.4.4.4.3" xref="A1.SS1.p3.1.m1.13.13.4.4.4.3.cmml"><mn id="A1.SS1.p3.1.m1.13.13.4.4.4.3.2" xref="A1.SS1.p3.1.m1.13.13.4.4.4.3.2.cmml">1</mn><mo id="A1.SS1.p3.1.m1.13.13.4.4.4.3.1" lspace="0.278em" rspace="0.278em" xref="A1.SS1.p3.1.m1.13.13.4.4.4.3.1.cmml">:</mo><mi id="A1.SS1.p3.1.m1.13.13.4.4.4.3.3" xref="A1.SS1.p3.1.m1.13.13.4.4.4.3.3.cmml">D</mi></mrow><mrow id="A1.SS1.p3.1.m1.8.8.2.4" xref="A1.SS1.p3.1.m1.8.8.2.3.cmml"><mi id="A1.SS1.p3.1.m1.7.7.1.1" xref="A1.SS1.p3.1.m1.7.7.1.1.cmml">L</mi><mo id="A1.SS1.p3.1.m1.8.8.2.4.1" xref="A1.SS1.p3.1.m1.8.8.2.3.cmml">;</mo><mi id="A1.SS1.p3.1.m1.8.8.2.2" xref="A1.SS1.p3.1.m1.8.8.2.2.cmml">b</mi></mrow></msubsup><mo id="A1.SS1.p3.1.m1.13.13.4.4.10" stretchy="false" xref="A1.SS1.p3.1.m1.13.13.4.5.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.p3.1.m1.13b"><apply id="A1.SS1.p3.1.m1.13.13.cmml" xref="A1.SS1.p3.1.m1.13.13"><eq id="A1.SS1.p3.1.m1.13.13.5.cmml" xref="A1.SS1.p3.1.m1.13.13.5"></eq><apply id="A1.SS1.p3.1.m1.13.13.6.cmml" xref="A1.SS1.p3.1.m1.13.13.6"><csymbol cd="ambiguous" id="A1.SS1.p3.1.m1.13.13.6.1.cmml" xref="A1.SS1.p3.1.m1.13.13.6">subscript</csymbol><ci id="A1.SS1.p3.1.m1.13.13.6.2.cmml" xref="A1.SS1.p3.1.m1.13.13.6.2">𝑋</ci><ci id="A1.SS1.p3.1.m1.13.13.6.3.cmml" xref="A1.SS1.p3.1.m1.13.13.6.3">𝑚</ci></apply><set id="A1.SS1.p3.1.m1.13.13.4.5.cmml" xref="A1.SS1.p3.1.m1.13.13.4.4"><apply id="A1.SS1.p3.1.m1.10.10.1.1.1.cmml" xref="A1.SS1.p3.1.m1.10.10.1.1.1"><csymbol cd="ambiguous" id="A1.SS1.p3.1.m1.10.10.1.1.1.1.cmml" xref="A1.SS1.p3.1.m1.10.10.1.1.1">subscript</csymbol><apply id="A1.SS1.p3.1.m1.10.10.1.1.1.2.cmml" xref="A1.SS1.p3.1.m1.10.10.1.1.1"><csymbol cd="ambiguous" id="A1.SS1.p3.1.m1.10.10.1.1.1.2.1.cmml" xref="A1.SS1.p3.1.m1.10.10.1.1.1">superscript</csymbol><ci id="A1.SS1.p3.1.m1.10.10.1.1.1.2.2.cmml" xref="A1.SS1.p3.1.m1.10.10.1.1.1.2.2">𝑘</ci><list id="A1.SS1.p3.1.m1.2.2.2.3.cmml" xref="A1.SS1.p3.1.m1.2.2.2.4"><cn id="A1.SS1.p3.1.m1.1.1.1.1.cmml" type="integer" xref="A1.SS1.p3.1.m1.1.1.1.1">1</cn><ci id="A1.SS1.p3.1.m1.2.2.2.2.cmml" xref="A1.SS1.p3.1.m1.2.2.2.2">𝑎</ci></list></apply><apply id="A1.SS1.p3.1.m1.10.10.1.1.1.3.cmml" xref="A1.SS1.p3.1.m1.10.10.1.1.1.3"><ci id="A1.SS1.p3.1.m1.10.10.1.1.1.3.1.cmml" xref="A1.SS1.p3.1.m1.10.10.1.1.1.3.1">:</ci><cn id="A1.SS1.p3.1.m1.10.10.1.1.1.3.2.cmml" type="integer" xref="A1.SS1.p3.1.m1.10.10.1.1.1.3.2">1</cn><ci id="A1.SS1.p3.1.m1.10.10.1.1.1.3.3.cmml" xref="A1.SS1.p3.1.m1.10.10.1.1.1.3.3">𝐷</ci></apply></apply><apply id="A1.SS1.p3.1.m1.11.11.2.2.2.cmml" xref="A1.SS1.p3.1.m1.11.11.2.2.2"><csymbol cd="ambiguous" id="A1.SS1.p3.1.m1.11.11.2.2.2.1.cmml" xref="A1.SS1.p3.1.m1.11.11.2.2.2">subscript</csymbol><apply id="A1.SS1.p3.1.m1.11.11.2.2.2.2.cmml" xref="A1.SS1.p3.1.m1.11.11.2.2.2"><csymbol cd="ambiguous" id="A1.SS1.p3.1.m1.11.11.2.2.2.2.1.cmml" xref="A1.SS1.p3.1.m1.11.11.2.2.2">superscript</csymbol><ci id="A1.SS1.p3.1.m1.11.11.2.2.2.2.2.cmml" xref="A1.SS1.p3.1.m1.11.11.2.2.2.2.2">𝑘</ci><list id="A1.SS1.p3.1.m1.4.4.2.3.cmml" xref="A1.SS1.p3.1.m1.4.4.2.4"><cn id="A1.SS1.p3.1.m1.3.3.1.1.cmml" type="integer" xref="A1.SS1.p3.1.m1.3.3.1.1">1</cn><ci id="A1.SS1.p3.1.m1.4.4.2.2.cmml" xref="A1.SS1.p3.1.m1.4.4.2.2">𝑏</ci></list></apply><apply id="A1.SS1.p3.1.m1.11.11.2.2.2.3.cmml" xref="A1.SS1.p3.1.m1.11.11.2.2.2.3"><ci id="A1.SS1.p3.1.m1.11.11.2.2.2.3.1.cmml" xref="A1.SS1.p3.1.m1.11.11.2.2.2.3.1">:</ci><cn id="A1.SS1.p3.1.m1.11.11.2.2.2.3.2.cmml" type="integer" xref="A1.SS1.p3.1.m1.11.11.2.2.2.3.2">1</cn><ci id="A1.SS1.p3.1.m1.11.11.2.2.2.3.3.cmml" xref="A1.SS1.p3.1.m1.11.11.2.2.2.3.3">𝐷</ci></apply></apply><ci id="A1.SS1.p3.1.m1.9.9.cmml" xref="A1.SS1.p3.1.m1.9.9">⋯</ci><apply id="A1.SS1.p3.1.m1.12.12.3.3.3.cmml" xref="A1.SS1.p3.1.m1.12.12.3.3.3"><csymbol cd="ambiguous" id="A1.SS1.p3.1.m1.12.12.3.3.3.1.cmml" xref="A1.SS1.p3.1.m1.12.12.3.3.3">subscript</csymbol><apply id="A1.SS1.p3.1.m1.12.12.3.3.3.2.cmml" xref="A1.SS1.p3.1.m1.12.12.3.3.3"><csymbol cd="ambiguous" id="A1.SS1.p3.1.m1.12.12.3.3.3.2.1.cmml" xref="A1.SS1.p3.1.m1.12.12.3.3.3">superscript</csymbol><ci id="A1.SS1.p3.1.m1.12.12.3.3.3.2.2.cmml" xref="A1.SS1.p3.1.m1.12.12.3.3.3.2.2">𝑘</ci><list id="A1.SS1.p3.1.m1.6.6.2.3.cmml" xref="A1.SS1.p3.1.m1.6.6.2.4"><ci id="A1.SS1.p3.1.m1.5.5.1.1.cmml" xref="A1.SS1.p3.1.m1.5.5.1.1">𝐿</ci><ci id="A1.SS1.p3.1.m1.6.6.2.2.cmml" xref="A1.SS1.p3.1.m1.6.6.2.2">𝑎</ci></list></apply><apply id="A1.SS1.p3.1.m1.12.12.3.3.3.3.cmml" xref="A1.SS1.p3.1.m1.12.12.3.3.3.3"><ci id="A1.SS1.p3.1.m1.12.12.3.3.3.3.1.cmml" xref="A1.SS1.p3.1.m1.12.12.3.3.3.3.1">:</ci><cn id="A1.SS1.p3.1.m1.12.12.3.3.3.3.2.cmml" type="integer" xref="A1.SS1.p3.1.m1.12.12.3.3.3.3.2">1</cn><ci id="A1.SS1.p3.1.m1.12.12.3.3.3.3.3.cmml" xref="A1.SS1.p3.1.m1.12.12.3.3.3.3.3">𝐷</ci></apply></apply><apply id="A1.SS1.p3.1.m1.13.13.4.4.4.cmml" xref="A1.SS1.p3.1.m1.13.13.4.4.4"><csymbol cd="ambiguous" id="A1.SS1.p3.1.m1.13.13.4.4.4.1.cmml" xref="A1.SS1.p3.1.m1.13.13.4.4.4">subscript</csymbol><apply id="A1.SS1.p3.1.m1.13.13.4.4.4.2.cmml" xref="A1.SS1.p3.1.m1.13.13.4.4.4"><csymbol cd="ambiguous" id="A1.SS1.p3.1.m1.13.13.4.4.4.2.1.cmml" xref="A1.SS1.p3.1.m1.13.13.4.4.4">superscript</csymbol><ci id="A1.SS1.p3.1.m1.13.13.4.4.4.2.2.cmml" xref="A1.SS1.p3.1.m1.13.13.4.4.4.2.2">𝑘</ci><list id="A1.SS1.p3.1.m1.8.8.2.3.cmml" xref="A1.SS1.p3.1.m1.8.8.2.4"><ci id="A1.SS1.p3.1.m1.7.7.1.1.cmml" xref="A1.SS1.p3.1.m1.7.7.1.1">𝐿</ci><ci id="A1.SS1.p3.1.m1.8.8.2.2.cmml" xref="A1.SS1.p3.1.m1.8.8.2.2">𝑏</ci></list></apply><apply id="A1.SS1.p3.1.m1.13.13.4.4.4.3.cmml" xref="A1.SS1.p3.1.m1.13.13.4.4.4.3"><ci id="A1.SS1.p3.1.m1.13.13.4.4.4.3.1.cmml" xref="A1.SS1.p3.1.m1.13.13.4.4.4.3.1">:</ci><cn id="A1.SS1.p3.1.m1.13.13.4.4.4.3.2.cmml" type="integer" xref="A1.SS1.p3.1.m1.13.13.4.4.4.3.2">1</cn><ci id="A1.SS1.p3.1.m1.13.13.4.4.4.3.3.cmml" xref="A1.SS1.p3.1.m1.13.13.4.4.4.3.3">𝐷</ci></apply></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p3.1.m1.13c">X_{m}=\{k^{1;a}_{1:D},k^{1;b}_{1:D},\cdots,k^{L;a}_{1:D},k^{L;b}_{1:D}\}</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p3.1.m1.13d">italic_X start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT = { italic_k start_POSTSUPERSCRIPT 1 ; italic_a end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 : italic_D end_POSTSUBSCRIPT , italic_k start_POSTSUPERSCRIPT 1 ; italic_b end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 : italic_D end_POSTSUBSCRIPT , ⋯ , italic_k start_POSTSUPERSCRIPT italic_L ; italic_a end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 : italic_D end_POSTSUBSCRIPT , italic_k start_POSTSUPERSCRIPT italic_L ; italic_b end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 : italic_D end_POSTSUBSCRIPT }</annotation></semantics></math>, where <math alttext="X_{m}" class="ltx_Math" display="inline" id="A1.SS1.p3.2.m2.1"><semantics id="A1.SS1.p3.2.m2.1a"><msub id="A1.SS1.p3.2.m2.1.1" xref="A1.SS1.p3.2.m2.1.1.cmml"><mi id="A1.SS1.p3.2.m2.1.1.2" xref="A1.SS1.p3.2.m2.1.1.2.cmml">X</mi><mi id="A1.SS1.p3.2.m2.1.1.3" xref="A1.SS1.p3.2.m2.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="A1.SS1.p3.2.m2.1b"><apply id="A1.SS1.p3.2.m2.1.1.cmml" xref="A1.SS1.p3.2.m2.1.1"><csymbol cd="ambiguous" id="A1.SS1.p3.2.m2.1.1.1.cmml" xref="A1.SS1.p3.2.m2.1.1">subscript</csymbol><ci id="A1.SS1.p3.2.m2.1.1.2.cmml" xref="A1.SS1.p3.2.m2.1.1.2">𝑋</ci><ci id="A1.SS1.p3.2.m2.1.1.3.cmml" xref="A1.SS1.p3.2.m2.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p3.2.m2.1c">X_{m}</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p3.2.m2.1d">italic_X start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT</annotation></semantics></math> is a sequence of motion represented in unified vocabulary and <math alttext="k^{i;a}_{1:D}\in[K]^{D}" class="ltx_Math" display="inline" id="A1.SS1.p3.3.m3.3"><semantics id="A1.SS1.p3.3.m3.3a"><mrow id="A1.SS1.p3.3.m3.3.4" xref="A1.SS1.p3.3.m3.3.4.cmml"><msubsup id="A1.SS1.p3.3.m3.3.4.2" xref="A1.SS1.p3.3.m3.3.4.2.cmml"><mi id="A1.SS1.p3.3.m3.3.4.2.2.2" xref="A1.SS1.p3.3.m3.3.4.2.2.2.cmml">k</mi><mrow id="A1.SS1.p3.3.m3.3.4.2.3" xref="A1.SS1.p3.3.m3.3.4.2.3.cmml"><mn id="A1.SS1.p3.3.m3.3.4.2.3.2" xref="A1.SS1.p3.3.m3.3.4.2.3.2.cmml">1</mn><mo id="A1.SS1.p3.3.m3.3.4.2.3.1" lspace="0.278em" rspace="0.278em" xref="A1.SS1.p3.3.m3.3.4.2.3.1.cmml">:</mo><mi id="A1.SS1.p3.3.m3.3.4.2.3.3" xref="A1.SS1.p3.3.m3.3.4.2.3.3.cmml">D</mi></mrow><mrow id="A1.SS1.p3.3.m3.2.2.2.4" xref="A1.SS1.p3.3.m3.2.2.2.3.cmml"><mi id="A1.SS1.p3.3.m3.1.1.1.1" xref="A1.SS1.p3.3.m3.1.1.1.1.cmml">i</mi><mo id="A1.SS1.p3.3.m3.2.2.2.4.1" xref="A1.SS1.p3.3.m3.2.2.2.3.cmml">;</mo><mi id="A1.SS1.p3.3.m3.2.2.2.2" xref="A1.SS1.p3.3.m3.2.2.2.2.cmml">a</mi></mrow></msubsup><mo id="A1.SS1.p3.3.m3.3.4.1" xref="A1.SS1.p3.3.m3.3.4.1.cmml">∈</mo><msup id="A1.SS1.p3.3.m3.3.4.3" xref="A1.SS1.p3.3.m3.3.4.3.cmml"><mrow id="A1.SS1.p3.3.m3.3.4.3.2.2" xref="A1.SS1.p3.3.m3.3.4.3.2.1.cmml"><mo id="A1.SS1.p3.3.m3.3.4.3.2.2.1" stretchy="false" xref="A1.SS1.p3.3.m3.3.4.3.2.1.1.cmml">[</mo><mi id="A1.SS1.p3.3.m3.3.3" xref="A1.SS1.p3.3.m3.3.3.cmml">K</mi><mo id="A1.SS1.p3.3.m3.3.4.3.2.2.2" stretchy="false" xref="A1.SS1.p3.3.m3.3.4.3.2.1.1.cmml">]</mo></mrow><mi id="A1.SS1.p3.3.m3.3.4.3.3" xref="A1.SS1.p3.3.m3.3.4.3.3.cmml">D</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.p3.3.m3.3b"><apply id="A1.SS1.p3.3.m3.3.4.cmml" xref="A1.SS1.p3.3.m3.3.4"><in id="A1.SS1.p3.3.m3.3.4.1.cmml" xref="A1.SS1.p3.3.m3.3.4.1"></in><apply id="A1.SS1.p3.3.m3.3.4.2.cmml" xref="A1.SS1.p3.3.m3.3.4.2"><csymbol cd="ambiguous" id="A1.SS1.p3.3.m3.3.4.2.1.cmml" xref="A1.SS1.p3.3.m3.3.4.2">subscript</csymbol><apply id="A1.SS1.p3.3.m3.3.4.2.2.cmml" xref="A1.SS1.p3.3.m3.3.4.2"><csymbol cd="ambiguous" id="A1.SS1.p3.3.m3.3.4.2.2.1.cmml" xref="A1.SS1.p3.3.m3.3.4.2">superscript</csymbol><ci id="A1.SS1.p3.3.m3.3.4.2.2.2.cmml" xref="A1.SS1.p3.3.m3.3.4.2.2.2">𝑘</ci><list id="A1.SS1.p3.3.m3.2.2.2.3.cmml" xref="A1.SS1.p3.3.m3.2.2.2.4"><ci id="A1.SS1.p3.3.m3.1.1.1.1.cmml" xref="A1.SS1.p3.3.m3.1.1.1.1">𝑖</ci><ci id="A1.SS1.p3.3.m3.2.2.2.2.cmml" xref="A1.SS1.p3.3.m3.2.2.2.2">𝑎</ci></list></apply><apply id="A1.SS1.p3.3.m3.3.4.2.3.cmml" xref="A1.SS1.p3.3.m3.3.4.2.3"><ci id="A1.SS1.p3.3.m3.3.4.2.3.1.cmml" xref="A1.SS1.p3.3.m3.3.4.2.3.1">:</ci><cn id="A1.SS1.p3.3.m3.3.4.2.3.2.cmml" type="integer" xref="A1.SS1.p3.3.m3.3.4.2.3.2">1</cn><ci id="A1.SS1.p3.3.m3.3.4.2.3.3.cmml" xref="A1.SS1.p3.3.m3.3.4.2.3.3">𝐷</ci></apply></apply><apply id="A1.SS1.p3.3.m3.3.4.3.cmml" xref="A1.SS1.p3.3.m3.3.4.3"><csymbol cd="ambiguous" id="A1.SS1.p3.3.m3.3.4.3.1.cmml" xref="A1.SS1.p3.3.m3.3.4.3">superscript</csymbol><apply id="A1.SS1.p3.3.m3.3.4.3.2.1.cmml" xref="A1.SS1.p3.3.m3.3.4.3.2.2"><csymbol cd="latexml" id="A1.SS1.p3.3.m3.3.4.3.2.1.1.cmml" xref="A1.SS1.p3.3.m3.3.4.3.2.2.1">delimited-[]</csymbol><ci id="A1.SS1.p3.3.m3.3.3.cmml" xref="A1.SS1.p3.3.m3.3.3">𝐾</ci></apply><ci id="A1.SS1.p3.3.m3.3.4.3.3.cmml" xref="A1.SS1.p3.3.m3.3.4.3.3">𝐷</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p3.3.m3.3c">k^{i;a}_{1:D}\in[K]^{D}</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p3.3.m3.3d">italic_k start_POSTSUPERSCRIPT italic_i ; italic_a end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 : italic_D end_POSTSUBSCRIPT ∈ [ italic_K ] start_POSTSUPERSCRIPT italic_D end_POSTSUPERSCRIPT</annotation></semantics></math> is the <math alttext="i" class="ltx_Math" display="inline" id="A1.SS1.p3.4.m4.1"><semantics id="A1.SS1.p3.4.m4.1a"><mi id="A1.SS1.p3.4.m4.1.1" xref="A1.SS1.p3.4.m4.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="A1.SS1.p3.4.m4.1b"><ci id="A1.SS1.p3.4.m4.1.1.cmml" xref="A1.SS1.p3.4.m4.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p3.4.m4.1c">i</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p3.4.m4.1d">italic_i</annotation></semantics></math>-th token of motion <math alttext="a" class="ltx_Math" display="inline" id="A1.SS1.p3.5.m5.1"><semantics id="A1.SS1.p3.5.m5.1a"><mi id="A1.SS1.p3.5.m5.1.1" xref="A1.SS1.p3.5.m5.1.1.cmml">a</mi><annotation-xml encoding="MathML-Content" id="A1.SS1.p3.5.m5.1b"><ci id="A1.SS1.p3.5.m5.1.1.cmml" xref="A1.SS1.p3.5.m5.1.1">𝑎</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p3.5.m5.1c">a</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p3.5.m5.1d">italic_a</annotation></semantics></math>. In particular, the motion token is represented as below:</p>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="A1.EGx2">
<tbody id="A1.Ex3"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle X_{m}=\{" class="ltx_math_unparsed" display="inline" id="A1.Ex3.m1.1"><semantics id="A1.Ex3.m1.1a"><mrow id="A1.Ex3.m1.1b"><msub id="A1.Ex3.m1.1.1"><mi id="A1.Ex3.m1.1.1.2">X</mi><mi id="A1.Ex3.m1.1.1.3">m</mi></msub><mo id="A1.Ex3.m1.1.2">=</mo><mo id="A1.Ex3.m1.1.3" stretchy="false">{</mo></mrow><annotation encoding="application/x-tex" id="A1.Ex3.m1.1c">\displaystyle X_{m}=\{</annotation><annotation encoding="application/x-llamapun" id="A1.Ex3.m1.1d">italic_X start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT = {</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle\texttt{&lt;motion\_token\_start&gt;}," class="ltx_Math" display="inline" id="A1.Ex3.m2.1"><semantics id="A1.Ex3.m2.1a"><mrow id="A1.Ex3.m2.1.2.2" xref="A1.Ex3.m2.1.1a.cmml"><mtext class="ltx_mathvariant_monospace" id="A1.Ex3.m2.1.1" xref="A1.Ex3.m2.1.1.cmml">&lt;motion_token_start&gt;</mtext><mo id="A1.Ex3.m2.1.2.2.1" xref="A1.Ex3.m2.1.1a.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="A1.Ex3.m2.1b"><ci id="A1.Ex3.m2.1.1a.cmml" xref="A1.Ex3.m2.1.2.2"><mtext class="ltx_mathvariant_monospace" id="A1.Ex3.m2.1.1.cmml" xref="A1.Ex3.m2.1.1">&lt;motion_token_start&gt;</mtext></ci></annotation-xml><annotation encoding="application/x-tex" id="A1.Ex3.m2.1c">\displaystyle\texttt{&lt;motion\_token\_start&gt;},</annotation><annotation encoding="application/x-llamapun" id="A1.Ex3.m2.1d">&lt;motion_token_start&gt; ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright" colspan="3"></td>
</tr></tbody>
<tbody id="A1.Ex4"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle\texttt{&lt;motion\_token\_a\_start&gt;}," class="ltx_Math" display="inline" id="A1.Ex4.m1.1"><semantics id="A1.Ex4.m1.1a"><mrow id="A1.Ex4.m1.1.2.2" xref="A1.Ex4.m1.1.1a.cmml"><mtext class="ltx_mathvariant_monospace" id="A1.Ex4.m1.1.1" xref="A1.Ex4.m1.1.1.cmml">&lt;motion_token_a_start&gt;</mtext><mo id="A1.Ex4.m1.1.2.2.1" xref="A1.Ex4.m1.1.1a.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="A1.Ex4.m1.1b"><ci id="A1.Ex4.m1.1.1a.cmml" xref="A1.Ex4.m1.1.2.2"><mtext class="ltx_mathvariant_monospace" id="A1.Ex4.m1.1.1.cmml" xref="A1.Ex4.m1.1.1">&lt;motion_token_a_start&gt;</mtext></ci></annotation-xml><annotation encoding="application/x-tex" id="A1.Ex4.m1.1c">\displaystyle\texttt{&lt;motion\_token\_a\_start&gt;},</annotation><annotation encoding="application/x-llamapun" id="A1.Ex4.m1.1d">&lt;motion_token_a_start&gt; ,</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle k^{1;a}_{1},\cdots,k^{1;a}_{D},\quad" class="ltx_Math" display="inline" id="A1.Ex4.m2.6"><semantics id="A1.Ex4.m2.6a"><mrow id="A1.Ex4.m2.6.6.1"><mrow id="A1.Ex4.m2.6.6.1.1.2" xref="A1.Ex4.m2.6.6.1.1.3.cmml"><msubsup id="A1.Ex4.m2.6.6.1.1.1.1" xref="A1.Ex4.m2.6.6.1.1.1.1.cmml"><mi id="A1.Ex4.m2.6.6.1.1.1.1.2.2" xref="A1.Ex4.m2.6.6.1.1.1.1.2.2.cmml">k</mi><mn id="A1.Ex4.m2.6.6.1.1.1.1.3" xref="A1.Ex4.m2.6.6.1.1.1.1.3.cmml">1</mn><mrow id="A1.Ex4.m2.2.2.2.4" xref="A1.Ex4.m2.2.2.2.3.cmml"><mn id="A1.Ex4.m2.1.1.1.1" xref="A1.Ex4.m2.1.1.1.1.cmml">1</mn><mo id="A1.Ex4.m2.2.2.2.4.1" xref="A1.Ex4.m2.2.2.2.3.cmml">;</mo><mi id="A1.Ex4.m2.2.2.2.2" xref="A1.Ex4.m2.2.2.2.2.cmml">a</mi></mrow></msubsup><mo id="A1.Ex4.m2.6.6.1.1.2.3" xref="A1.Ex4.m2.6.6.1.1.3.cmml">,</mo><mi id="A1.Ex4.m2.5.5" mathvariant="normal" xref="A1.Ex4.m2.5.5.cmml">⋯</mi><mo id="A1.Ex4.m2.6.6.1.1.2.4" xref="A1.Ex4.m2.6.6.1.1.3.cmml">,</mo><msubsup id="A1.Ex4.m2.6.6.1.1.2.2" xref="A1.Ex4.m2.6.6.1.1.2.2.cmml"><mi id="A1.Ex4.m2.6.6.1.1.2.2.2.2" xref="A1.Ex4.m2.6.6.1.1.2.2.2.2.cmml">k</mi><mi id="A1.Ex4.m2.6.6.1.1.2.2.3" xref="A1.Ex4.m2.6.6.1.1.2.2.3.cmml">D</mi><mrow id="A1.Ex4.m2.4.4.2.4" xref="A1.Ex4.m2.4.4.2.3.cmml"><mn id="A1.Ex4.m2.3.3.1.1" xref="A1.Ex4.m2.3.3.1.1.cmml">1</mn><mo id="A1.Ex4.m2.4.4.2.4.1" xref="A1.Ex4.m2.4.4.2.3.cmml">;</mo><mi id="A1.Ex4.m2.4.4.2.2" xref="A1.Ex4.m2.4.4.2.2.cmml">a</mi></mrow></msubsup></mrow><mo id="A1.Ex4.m2.6.6.1.2">,</mo></mrow><annotation-xml encoding="MathML-Content" id="A1.Ex4.m2.6b"><list id="A1.Ex4.m2.6.6.1.1.3.cmml" xref="A1.Ex4.m2.6.6.1.1.2"><apply id="A1.Ex4.m2.6.6.1.1.1.1.cmml" xref="A1.Ex4.m2.6.6.1.1.1.1"><csymbol cd="ambiguous" id="A1.Ex4.m2.6.6.1.1.1.1.1.cmml" xref="A1.Ex4.m2.6.6.1.1.1.1">subscript</csymbol><apply id="A1.Ex4.m2.6.6.1.1.1.1.2.cmml" xref="A1.Ex4.m2.6.6.1.1.1.1"><csymbol cd="ambiguous" id="A1.Ex4.m2.6.6.1.1.1.1.2.1.cmml" xref="A1.Ex4.m2.6.6.1.1.1.1">superscript</csymbol><ci id="A1.Ex4.m2.6.6.1.1.1.1.2.2.cmml" xref="A1.Ex4.m2.6.6.1.1.1.1.2.2">𝑘</ci><list id="A1.Ex4.m2.2.2.2.3.cmml" xref="A1.Ex4.m2.2.2.2.4"><cn id="A1.Ex4.m2.1.1.1.1.cmml" type="integer" xref="A1.Ex4.m2.1.1.1.1">1</cn><ci id="A1.Ex4.m2.2.2.2.2.cmml" xref="A1.Ex4.m2.2.2.2.2">𝑎</ci></list></apply><cn id="A1.Ex4.m2.6.6.1.1.1.1.3.cmml" type="integer" xref="A1.Ex4.m2.6.6.1.1.1.1.3">1</cn></apply><ci id="A1.Ex4.m2.5.5.cmml" xref="A1.Ex4.m2.5.5">⋯</ci><apply id="A1.Ex4.m2.6.6.1.1.2.2.cmml" xref="A1.Ex4.m2.6.6.1.1.2.2"><csymbol cd="ambiguous" id="A1.Ex4.m2.6.6.1.1.2.2.1.cmml" xref="A1.Ex4.m2.6.6.1.1.2.2">subscript</csymbol><apply id="A1.Ex4.m2.6.6.1.1.2.2.2.cmml" xref="A1.Ex4.m2.6.6.1.1.2.2"><csymbol cd="ambiguous" id="A1.Ex4.m2.6.6.1.1.2.2.2.1.cmml" xref="A1.Ex4.m2.6.6.1.1.2.2">superscript</csymbol><ci id="A1.Ex4.m2.6.6.1.1.2.2.2.2.cmml" xref="A1.Ex4.m2.6.6.1.1.2.2.2.2">𝑘</ci><list id="A1.Ex4.m2.4.4.2.3.cmml" xref="A1.Ex4.m2.4.4.2.4"><cn id="A1.Ex4.m2.3.3.1.1.cmml" type="integer" xref="A1.Ex4.m2.3.3.1.1">1</cn><ci id="A1.Ex4.m2.4.4.2.2.cmml" xref="A1.Ex4.m2.4.4.2.2">𝑎</ci></list></apply><ci id="A1.Ex4.m2.6.6.1.1.2.2.3.cmml" xref="A1.Ex4.m2.6.6.1.1.2.2.3">𝐷</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="A1.Ex4.m2.6c">\displaystyle k^{1;a}_{1},\cdots,k^{1;a}_{D},\quad</annotation><annotation encoding="application/x-llamapun" id="A1.Ex4.m2.6d">italic_k start_POSTSUPERSCRIPT 1 ; italic_a end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , ⋯ , italic_k start_POSTSUPERSCRIPT 1 ; italic_a end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_D end_POSTSUBSCRIPT ,</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle\texttt{&lt;motion\_token\_a\_end&gt;}," class="ltx_Math" display="inline" id="A1.Ex4.m3.1"><semantics id="A1.Ex4.m3.1a"><mrow id="A1.Ex4.m3.1.2.2" xref="A1.Ex4.m3.1.1a.cmml"><mtext class="ltx_mathvariant_monospace" id="A1.Ex4.m3.1.1" xref="A1.Ex4.m3.1.1.cmml">&lt;motion_token_a_end&gt;</mtext><mo id="A1.Ex4.m3.1.2.2.1" xref="A1.Ex4.m3.1.1a.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="A1.Ex4.m3.1b"><ci id="A1.Ex4.m3.1.1a.cmml" xref="A1.Ex4.m3.1.2.2"><mtext class="ltx_mathvariant_monospace" id="A1.Ex4.m3.1.1.cmml" xref="A1.Ex4.m3.1.1">&lt;motion_token_a_end&gt;</mtext></ci></annotation-xml><annotation encoding="application/x-tex" id="A1.Ex4.m3.1c">\displaystyle\texttt{&lt;motion\_token\_a\_end&gt;},</annotation><annotation encoding="application/x-llamapun" id="A1.Ex4.m3.1d">&lt;motion_token_a_end&gt; ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="A1.Ex5"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle\texttt{&lt;motion\_token\_b\_start&gt;}," class="ltx_Math" display="inline" id="A1.Ex5.m1.1"><semantics id="A1.Ex5.m1.1a"><mrow id="A1.Ex5.m1.1.2.2" xref="A1.Ex5.m1.1.1a.cmml"><mtext class="ltx_mathvariant_monospace" id="A1.Ex5.m1.1.1" xref="A1.Ex5.m1.1.1.cmml">&lt;motion_token_b_start&gt;</mtext><mo id="A1.Ex5.m1.1.2.2.1" xref="A1.Ex5.m1.1.1a.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="A1.Ex5.m1.1b"><ci id="A1.Ex5.m1.1.1a.cmml" xref="A1.Ex5.m1.1.2.2"><mtext class="ltx_mathvariant_monospace" id="A1.Ex5.m1.1.1.cmml" xref="A1.Ex5.m1.1.1">&lt;motion_token_b_start&gt;</mtext></ci></annotation-xml><annotation encoding="application/x-tex" id="A1.Ex5.m1.1c">\displaystyle\texttt{&lt;motion\_token\_b\_start&gt;},</annotation><annotation encoding="application/x-llamapun" id="A1.Ex5.m1.1d">&lt;motion_token_b_start&gt; ,</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle k^{1;b}_{1},\cdots,k^{1;b}_{D},\quad" class="ltx_Math" display="inline" id="A1.Ex5.m2.6"><semantics id="A1.Ex5.m2.6a"><mrow id="A1.Ex5.m2.6.6.1"><mrow id="A1.Ex5.m2.6.6.1.1.2" xref="A1.Ex5.m2.6.6.1.1.3.cmml"><msubsup id="A1.Ex5.m2.6.6.1.1.1.1" xref="A1.Ex5.m2.6.6.1.1.1.1.cmml"><mi id="A1.Ex5.m2.6.6.1.1.1.1.2.2" xref="A1.Ex5.m2.6.6.1.1.1.1.2.2.cmml">k</mi><mn id="A1.Ex5.m2.6.6.1.1.1.1.3" xref="A1.Ex5.m2.6.6.1.1.1.1.3.cmml">1</mn><mrow id="A1.Ex5.m2.2.2.2.4" xref="A1.Ex5.m2.2.2.2.3.cmml"><mn id="A1.Ex5.m2.1.1.1.1" xref="A1.Ex5.m2.1.1.1.1.cmml">1</mn><mo id="A1.Ex5.m2.2.2.2.4.1" xref="A1.Ex5.m2.2.2.2.3.cmml">;</mo><mi id="A1.Ex5.m2.2.2.2.2" xref="A1.Ex5.m2.2.2.2.2.cmml">b</mi></mrow></msubsup><mo id="A1.Ex5.m2.6.6.1.1.2.3" xref="A1.Ex5.m2.6.6.1.1.3.cmml">,</mo><mi id="A1.Ex5.m2.5.5" mathvariant="normal" xref="A1.Ex5.m2.5.5.cmml">⋯</mi><mo id="A1.Ex5.m2.6.6.1.1.2.4" xref="A1.Ex5.m2.6.6.1.1.3.cmml">,</mo><msubsup id="A1.Ex5.m2.6.6.1.1.2.2" xref="A1.Ex5.m2.6.6.1.1.2.2.cmml"><mi id="A1.Ex5.m2.6.6.1.1.2.2.2.2" xref="A1.Ex5.m2.6.6.1.1.2.2.2.2.cmml">k</mi><mi id="A1.Ex5.m2.6.6.1.1.2.2.3" xref="A1.Ex5.m2.6.6.1.1.2.2.3.cmml">D</mi><mrow id="A1.Ex5.m2.4.4.2.4" xref="A1.Ex5.m2.4.4.2.3.cmml"><mn id="A1.Ex5.m2.3.3.1.1" xref="A1.Ex5.m2.3.3.1.1.cmml">1</mn><mo id="A1.Ex5.m2.4.4.2.4.1" xref="A1.Ex5.m2.4.4.2.3.cmml">;</mo><mi id="A1.Ex5.m2.4.4.2.2" xref="A1.Ex5.m2.4.4.2.2.cmml">b</mi></mrow></msubsup></mrow><mo id="A1.Ex5.m2.6.6.1.2">,</mo></mrow><annotation-xml encoding="MathML-Content" id="A1.Ex5.m2.6b"><list id="A1.Ex5.m2.6.6.1.1.3.cmml" xref="A1.Ex5.m2.6.6.1.1.2"><apply id="A1.Ex5.m2.6.6.1.1.1.1.cmml" xref="A1.Ex5.m2.6.6.1.1.1.1"><csymbol cd="ambiguous" id="A1.Ex5.m2.6.6.1.1.1.1.1.cmml" xref="A1.Ex5.m2.6.6.1.1.1.1">subscript</csymbol><apply id="A1.Ex5.m2.6.6.1.1.1.1.2.cmml" xref="A1.Ex5.m2.6.6.1.1.1.1"><csymbol cd="ambiguous" id="A1.Ex5.m2.6.6.1.1.1.1.2.1.cmml" xref="A1.Ex5.m2.6.6.1.1.1.1">superscript</csymbol><ci id="A1.Ex5.m2.6.6.1.1.1.1.2.2.cmml" xref="A1.Ex5.m2.6.6.1.1.1.1.2.2">𝑘</ci><list id="A1.Ex5.m2.2.2.2.3.cmml" xref="A1.Ex5.m2.2.2.2.4"><cn id="A1.Ex5.m2.1.1.1.1.cmml" type="integer" xref="A1.Ex5.m2.1.1.1.1">1</cn><ci id="A1.Ex5.m2.2.2.2.2.cmml" xref="A1.Ex5.m2.2.2.2.2">𝑏</ci></list></apply><cn id="A1.Ex5.m2.6.6.1.1.1.1.3.cmml" type="integer" xref="A1.Ex5.m2.6.6.1.1.1.1.3">1</cn></apply><ci id="A1.Ex5.m2.5.5.cmml" xref="A1.Ex5.m2.5.5">⋯</ci><apply id="A1.Ex5.m2.6.6.1.1.2.2.cmml" xref="A1.Ex5.m2.6.6.1.1.2.2"><csymbol cd="ambiguous" id="A1.Ex5.m2.6.6.1.1.2.2.1.cmml" xref="A1.Ex5.m2.6.6.1.1.2.2">subscript</csymbol><apply id="A1.Ex5.m2.6.6.1.1.2.2.2.cmml" xref="A1.Ex5.m2.6.6.1.1.2.2"><csymbol cd="ambiguous" id="A1.Ex5.m2.6.6.1.1.2.2.2.1.cmml" xref="A1.Ex5.m2.6.6.1.1.2.2">superscript</csymbol><ci id="A1.Ex5.m2.6.6.1.1.2.2.2.2.cmml" xref="A1.Ex5.m2.6.6.1.1.2.2.2.2">𝑘</ci><list id="A1.Ex5.m2.4.4.2.3.cmml" xref="A1.Ex5.m2.4.4.2.4"><cn id="A1.Ex5.m2.3.3.1.1.cmml" type="integer" xref="A1.Ex5.m2.3.3.1.1">1</cn><ci id="A1.Ex5.m2.4.4.2.2.cmml" xref="A1.Ex5.m2.4.4.2.2">𝑏</ci></list></apply><ci id="A1.Ex5.m2.6.6.1.1.2.2.3.cmml" xref="A1.Ex5.m2.6.6.1.1.2.2.3">𝐷</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="A1.Ex5.m2.6c">\displaystyle k^{1;b}_{1},\cdots,k^{1;b}_{D},\quad</annotation><annotation encoding="application/x-llamapun" id="A1.Ex5.m2.6d">italic_k start_POSTSUPERSCRIPT 1 ; italic_b end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , ⋯ , italic_k start_POSTSUPERSCRIPT 1 ; italic_b end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_D end_POSTSUBSCRIPT ,</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle\texttt{&lt;motion\_token\_b\_end&gt;}," class="ltx_Math" display="inline" id="A1.Ex5.m3.1"><semantics id="A1.Ex5.m3.1a"><mrow id="A1.Ex5.m3.1.2.2" xref="A1.Ex5.m3.1.1a.cmml"><mtext class="ltx_mathvariant_monospace" id="A1.Ex5.m3.1.1" xref="A1.Ex5.m3.1.1.cmml">&lt;motion_token_b_end&gt;</mtext><mo id="A1.Ex5.m3.1.2.2.1" xref="A1.Ex5.m3.1.1a.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="A1.Ex5.m3.1b"><ci id="A1.Ex5.m3.1.1a.cmml" xref="A1.Ex5.m3.1.2.2"><mtext class="ltx_mathvariant_monospace" id="A1.Ex5.m3.1.1.cmml" xref="A1.Ex5.m3.1.1">&lt;motion_token_b_end&gt;</mtext></ci></annotation-xml><annotation encoding="application/x-tex" id="A1.Ex5.m3.1c">\displaystyle\texttt{&lt;motion\_token\_b\_end&gt;},</annotation><annotation encoding="application/x-llamapun" id="A1.Ex5.m3.1d">&lt;motion_token_b_end&gt; ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="A1.Ex6"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle\cdots" class="ltx_Math" display="inline" id="A1.Ex6.m1.1"><semantics id="A1.Ex6.m1.1a"><mi id="A1.Ex6.m1.1.1" mathvariant="normal" xref="A1.Ex6.m1.1.1.cmml">⋯</mi><annotation-xml encoding="MathML-Content" id="A1.Ex6.m1.1b"><ci id="A1.Ex6.m1.1.1.cmml" xref="A1.Ex6.m1.1.1">⋯</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.Ex6.m1.1c">\displaystyle\cdots</annotation><annotation encoding="application/x-llamapun" id="A1.Ex6.m1.1d">⋯</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright" colspan="3"></td>
</tr></tbody>
<tbody id="A1.Ex7"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle\texttt{&lt;motion\_token\_a\_start&gt;}," class="ltx_Math" display="inline" id="A1.Ex7.m1.1"><semantics id="A1.Ex7.m1.1a"><mrow id="A1.Ex7.m1.1.2.2" xref="A1.Ex7.m1.1.1a.cmml"><mtext class="ltx_mathvariant_monospace" id="A1.Ex7.m1.1.1" xref="A1.Ex7.m1.1.1.cmml">&lt;motion_token_a_start&gt;</mtext><mo id="A1.Ex7.m1.1.2.2.1" xref="A1.Ex7.m1.1.1a.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="A1.Ex7.m1.1b"><ci id="A1.Ex7.m1.1.1a.cmml" xref="A1.Ex7.m1.1.2.2"><mtext class="ltx_mathvariant_monospace" id="A1.Ex7.m1.1.1.cmml" xref="A1.Ex7.m1.1.1">&lt;motion_token_a_start&gt;</mtext></ci></annotation-xml><annotation encoding="application/x-tex" id="A1.Ex7.m1.1c">\displaystyle\texttt{&lt;motion\_token\_a\_start&gt;},</annotation><annotation encoding="application/x-llamapun" id="A1.Ex7.m1.1d">&lt;motion_token_a_start&gt; ,</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle k^{L;a}_{1},\cdots,k^{L;a}_{D},\quad" class="ltx_Math" display="inline" id="A1.Ex7.m2.6"><semantics id="A1.Ex7.m2.6a"><mrow id="A1.Ex7.m2.6.6.1"><mrow id="A1.Ex7.m2.6.6.1.1.2" xref="A1.Ex7.m2.6.6.1.1.3.cmml"><msubsup id="A1.Ex7.m2.6.6.1.1.1.1" xref="A1.Ex7.m2.6.6.1.1.1.1.cmml"><mi id="A1.Ex7.m2.6.6.1.1.1.1.2.2" xref="A1.Ex7.m2.6.6.1.1.1.1.2.2.cmml">k</mi><mn id="A1.Ex7.m2.6.6.1.1.1.1.3" xref="A1.Ex7.m2.6.6.1.1.1.1.3.cmml">1</mn><mrow id="A1.Ex7.m2.2.2.2.4" xref="A1.Ex7.m2.2.2.2.3.cmml"><mi id="A1.Ex7.m2.1.1.1.1" xref="A1.Ex7.m2.1.1.1.1.cmml">L</mi><mo id="A1.Ex7.m2.2.2.2.4.1" xref="A1.Ex7.m2.2.2.2.3.cmml">;</mo><mi id="A1.Ex7.m2.2.2.2.2" xref="A1.Ex7.m2.2.2.2.2.cmml">a</mi></mrow></msubsup><mo id="A1.Ex7.m2.6.6.1.1.2.3" xref="A1.Ex7.m2.6.6.1.1.3.cmml">,</mo><mi id="A1.Ex7.m2.5.5" mathvariant="normal" xref="A1.Ex7.m2.5.5.cmml">⋯</mi><mo id="A1.Ex7.m2.6.6.1.1.2.4" xref="A1.Ex7.m2.6.6.1.1.3.cmml">,</mo><msubsup id="A1.Ex7.m2.6.6.1.1.2.2" xref="A1.Ex7.m2.6.6.1.1.2.2.cmml"><mi id="A1.Ex7.m2.6.6.1.1.2.2.2.2" xref="A1.Ex7.m2.6.6.1.1.2.2.2.2.cmml">k</mi><mi id="A1.Ex7.m2.6.6.1.1.2.2.3" xref="A1.Ex7.m2.6.6.1.1.2.2.3.cmml">D</mi><mrow id="A1.Ex7.m2.4.4.2.4" xref="A1.Ex7.m2.4.4.2.3.cmml"><mi id="A1.Ex7.m2.3.3.1.1" xref="A1.Ex7.m2.3.3.1.1.cmml">L</mi><mo id="A1.Ex7.m2.4.4.2.4.1" xref="A1.Ex7.m2.4.4.2.3.cmml">;</mo><mi id="A1.Ex7.m2.4.4.2.2" xref="A1.Ex7.m2.4.4.2.2.cmml">a</mi></mrow></msubsup></mrow><mo id="A1.Ex7.m2.6.6.1.2">,</mo></mrow><annotation-xml encoding="MathML-Content" id="A1.Ex7.m2.6b"><list id="A1.Ex7.m2.6.6.1.1.3.cmml" xref="A1.Ex7.m2.6.6.1.1.2"><apply id="A1.Ex7.m2.6.6.1.1.1.1.cmml" xref="A1.Ex7.m2.6.6.1.1.1.1"><csymbol cd="ambiguous" id="A1.Ex7.m2.6.6.1.1.1.1.1.cmml" xref="A1.Ex7.m2.6.6.1.1.1.1">subscript</csymbol><apply id="A1.Ex7.m2.6.6.1.1.1.1.2.cmml" xref="A1.Ex7.m2.6.6.1.1.1.1"><csymbol cd="ambiguous" id="A1.Ex7.m2.6.6.1.1.1.1.2.1.cmml" xref="A1.Ex7.m2.6.6.1.1.1.1">superscript</csymbol><ci id="A1.Ex7.m2.6.6.1.1.1.1.2.2.cmml" xref="A1.Ex7.m2.6.6.1.1.1.1.2.2">𝑘</ci><list id="A1.Ex7.m2.2.2.2.3.cmml" xref="A1.Ex7.m2.2.2.2.4"><ci id="A1.Ex7.m2.1.1.1.1.cmml" xref="A1.Ex7.m2.1.1.1.1">𝐿</ci><ci id="A1.Ex7.m2.2.2.2.2.cmml" xref="A1.Ex7.m2.2.2.2.2">𝑎</ci></list></apply><cn id="A1.Ex7.m2.6.6.1.1.1.1.3.cmml" type="integer" xref="A1.Ex7.m2.6.6.1.1.1.1.3">1</cn></apply><ci id="A1.Ex7.m2.5.5.cmml" xref="A1.Ex7.m2.5.5">⋯</ci><apply id="A1.Ex7.m2.6.6.1.1.2.2.cmml" xref="A1.Ex7.m2.6.6.1.1.2.2"><csymbol cd="ambiguous" id="A1.Ex7.m2.6.6.1.1.2.2.1.cmml" xref="A1.Ex7.m2.6.6.1.1.2.2">subscript</csymbol><apply id="A1.Ex7.m2.6.6.1.1.2.2.2.cmml" xref="A1.Ex7.m2.6.6.1.1.2.2"><csymbol cd="ambiguous" id="A1.Ex7.m2.6.6.1.1.2.2.2.1.cmml" xref="A1.Ex7.m2.6.6.1.1.2.2">superscript</csymbol><ci id="A1.Ex7.m2.6.6.1.1.2.2.2.2.cmml" xref="A1.Ex7.m2.6.6.1.1.2.2.2.2">𝑘</ci><list id="A1.Ex7.m2.4.4.2.3.cmml" xref="A1.Ex7.m2.4.4.2.4"><ci id="A1.Ex7.m2.3.3.1.1.cmml" xref="A1.Ex7.m2.3.3.1.1">𝐿</ci><ci id="A1.Ex7.m2.4.4.2.2.cmml" xref="A1.Ex7.m2.4.4.2.2">𝑎</ci></list></apply><ci id="A1.Ex7.m2.6.6.1.1.2.2.3.cmml" xref="A1.Ex7.m2.6.6.1.1.2.2.3">𝐷</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="A1.Ex7.m2.6c">\displaystyle k^{L;a}_{1},\cdots,k^{L;a}_{D},\quad</annotation><annotation encoding="application/x-llamapun" id="A1.Ex7.m2.6d">italic_k start_POSTSUPERSCRIPT italic_L ; italic_a end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , ⋯ , italic_k start_POSTSUPERSCRIPT italic_L ; italic_a end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_D end_POSTSUBSCRIPT ,</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle\texttt{&lt;motion\_token\_a\_end&gt;}," class="ltx_Math" display="inline" id="A1.Ex7.m3.1"><semantics id="A1.Ex7.m3.1a"><mrow id="A1.Ex7.m3.1.2.2" xref="A1.Ex7.m3.1.1a.cmml"><mtext class="ltx_mathvariant_monospace" id="A1.Ex7.m3.1.1" xref="A1.Ex7.m3.1.1.cmml">&lt;motion_token_a_end&gt;</mtext><mo id="A1.Ex7.m3.1.2.2.1" xref="A1.Ex7.m3.1.1a.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="A1.Ex7.m3.1b"><ci id="A1.Ex7.m3.1.1a.cmml" xref="A1.Ex7.m3.1.2.2"><mtext class="ltx_mathvariant_monospace" id="A1.Ex7.m3.1.1.cmml" xref="A1.Ex7.m3.1.1">&lt;motion_token_a_end&gt;</mtext></ci></annotation-xml><annotation encoding="application/x-tex" id="A1.Ex7.m3.1c">\displaystyle\texttt{&lt;motion\_token\_a\_end&gt;},</annotation><annotation encoding="application/x-llamapun" id="A1.Ex7.m3.1d">&lt;motion_token_a_end&gt; ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="A1.Ex8"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle\texttt{&lt;motion\_token\_b\_start&gt;}," class="ltx_Math" display="inline" id="A1.Ex8.m1.1"><semantics id="A1.Ex8.m1.1a"><mrow id="A1.Ex8.m1.1.2.2" xref="A1.Ex8.m1.1.1a.cmml"><mtext class="ltx_mathvariant_monospace" id="A1.Ex8.m1.1.1" xref="A1.Ex8.m1.1.1.cmml">&lt;motion_token_b_start&gt;</mtext><mo id="A1.Ex8.m1.1.2.2.1" xref="A1.Ex8.m1.1.1a.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="A1.Ex8.m1.1b"><ci id="A1.Ex8.m1.1.1a.cmml" xref="A1.Ex8.m1.1.2.2"><mtext class="ltx_mathvariant_monospace" id="A1.Ex8.m1.1.1.cmml" xref="A1.Ex8.m1.1.1">&lt;motion_token_b_start&gt;</mtext></ci></annotation-xml><annotation encoding="application/x-tex" id="A1.Ex8.m1.1c">\displaystyle\texttt{&lt;motion\_token\_b\_start&gt;},</annotation><annotation encoding="application/x-llamapun" id="A1.Ex8.m1.1d">&lt;motion_token_b_start&gt; ,</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle k^{L;b}_{1},\cdots,k^{:;b}_{D},\quad" class="ltx_Math" display="inline" id="A1.Ex8.m2.6"><semantics id="A1.Ex8.m2.6a"><mrow id="A1.Ex8.m2.6.6.1"><mrow id="A1.Ex8.m2.6.6.1.1.2" xref="A1.Ex8.m2.6.6.1.1.3.cmml"><msubsup id="A1.Ex8.m2.6.6.1.1.1.1" xref="A1.Ex8.m2.6.6.1.1.1.1.cmml"><mi id="A1.Ex8.m2.6.6.1.1.1.1.2.2" xref="A1.Ex8.m2.6.6.1.1.1.1.2.2.cmml">k</mi><mn id="A1.Ex8.m2.6.6.1.1.1.1.3" xref="A1.Ex8.m2.6.6.1.1.1.1.3.cmml">1</mn><mrow id="A1.Ex8.m2.2.2.2.4" xref="A1.Ex8.m2.2.2.2.3.cmml"><mi id="A1.Ex8.m2.1.1.1.1" xref="A1.Ex8.m2.1.1.1.1.cmml">L</mi><mo id="A1.Ex8.m2.2.2.2.4.1" xref="A1.Ex8.m2.2.2.2.3.cmml">;</mo><mi id="A1.Ex8.m2.2.2.2.2" xref="A1.Ex8.m2.2.2.2.2.cmml">b</mi></mrow></msubsup><mo id="A1.Ex8.m2.6.6.1.1.2.3" xref="A1.Ex8.m2.6.6.1.1.3.cmml">,</mo><mi id="A1.Ex8.m2.5.5" mathvariant="normal" xref="A1.Ex8.m2.5.5.cmml">⋯</mi><mo id="A1.Ex8.m2.6.6.1.1.2.4" xref="A1.Ex8.m2.6.6.1.1.3.cmml">,</mo><msubsup id="A1.Ex8.m2.6.6.1.1.2.2" xref="A1.Ex8.m2.6.6.1.1.2.2.cmml"><mi id="A1.Ex8.m2.6.6.1.1.2.2.2.2" xref="A1.Ex8.m2.6.6.1.1.2.2.2.2.cmml">k</mi><mi id="A1.Ex8.m2.6.6.1.1.2.2.3" xref="A1.Ex8.m2.6.6.1.1.2.2.3.cmml">D</mi><mrow id="A1.Ex8.m2.4.4.2.4" xref="A1.Ex8.m2.4.4.2.3.cmml"><mo id="A1.Ex8.m2.3.3.1.1" rspace="0em" xref="A1.Ex8.m2.3.3.1.1.cmml">:</mo><mo id="A1.Ex8.m2.4.4.2.4.1" xref="A1.Ex8.m2.4.4.2.3.cmml">;</mo><mi id="A1.Ex8.m2.4.4.2.2" xref="A1.Ex8.m2.4.4.2.2.cmml">b</mi></mrow></msubsup></mrow><mo id="A1.Ex8.m2.6.6.1.2">,</mo></mrow><annotation-xml encoding="MathML-Content" id="A1.Ex8.m2.6b"><list id="A1.Ex8.m2.6.6.1.1.3.cmml" xref="A1.Ex8.m2.6.6.1.1.2"><apply id="A1.Ex8.m2.6.6.1.1.1.1.cmml" xref="A1.Ex8.m2.6.6.1.1.1.1"><csymbol cd="ambiguous" id="A1.Ex8.m2.6.6.1.1.1.1.1.cmml" xref="A1.Ex8.m2.6.6.1.1.1.1">subscript</csymbol><apply id="A1.Ex8.m2.6.6.1.1.1.1.2.cmml" xref="A1.Ex8.m2.6.6.1.1.1.1"><csymbol cd="ambiguous" id="A1.Ex8.m2.6.6.1.1.1.1.2.1.cmml" xref="A1.Ex8.m2.6.6.1.1.1.1">superscript</csymbol><ci id="A1.Ex8.m2.6.6.1.1.1.1.2.2.cmml" xref="A1.Ex8.m2.6.6.1.1.1.1.2.2">𝑘</ci><list id="A1.Ex8.m2.2.2.2.3.cmml" xref="A1.Ex8.m2.2.2.2.4"><ci id="A1.Ex8.m2.1.1.1.1.cmml" xref="A1.Ex8.m2.1.1.1.1">𝐿</ci><ci id="A1.Ex8.m2.2.2.2.2.cmml" xref="A1.Ex8.m2.2.2.2.2">𝑏</ci></list></apply><cn id="A1.Ex8.m2.6.6.1.1.1.1.3.cmml" type="integer" xref="A1.Ex8.m2.6.6.1.1.1.1.3">1</cn></apply><ci id="A1.Ex8.m2.5.5.cmml" xref="A1.Ex8.m2.5.5">⋯</ci><apply id="A1.Ex8.m2.6.6.1.1.2.2.cmml" xref="A1.Ex8.m2.6.6.1.1.2.2"><csymbol cd="ambiguous" id="A1.Ex8.m2.6.6.1.1.2.2.1.cmml" xref="A1.Ex8.m2.6.6.1.1.2.2">subscript</csymbol><apply id="A1.Ex8.m2.6.6.1.1.2.2.2.cmml" xref="A1.Ex8.m2.6.6.1.1.2.2"><csymbol cd="ambiguous" id="A1.Ex8.m2.6.6.1.1.2.2.2.1.cmml" xref="A1.Ex8.m2.6.6.1.1.2.2">superscript</csymbol><ci id="A1.Ex8.m2.6.6.1.1.2.2.2.2.cmml" xref="A1.Ex8.m2.6.6.1.1.2.2.2.2">𝑘</ci><list id="A1.Ex8.m2.4.4.2.3.cmml" xref="A1.Ex8.m2.4.4.2.4"><ci id="A1.Ex8.m2.3.3.1.1.cmml" xref="A1.Ex8.m2.3.3.1.1">:</ci><ci id="A1.Ex8.m2.4.4.2.2.cmml" xref="A1.Ex8.m2.4.4.2.2">𝑏</ci></list></apply><ci id="A1.Ex8.m2.6.6.1.1.2.2.3.cmml" xref="A1.Ex8.m2.6.6.1.1.2.2.3">𝐷</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="A1.Ex8.m2.6c">\displaystyle k^{L;b}_{1},\cdots,k^{:;b}_{D},\quad</annotation><annotation encoding="application/x-llamapun" id="A1.Ex8.m2.6d">italic_k start_POSTSUPERSCRIPT italic_L ; italic_b end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , ⋯ , italic_k start_POSTSUPERSCRIPT : ; italic_b end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_D end_POSTSUBSCRIPT ,</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle\texttt{&lt;motion\_token\_b\_end&gt;}," class="ltx_Math" display="inline" id="A1.Ex8.m3.1"><semantics id="A1.Ex8.m3.1a"><mrow id="A1.Ex8.m3.1.2.2" xref="A1.Ex8.m3.1.1a.cmml"><mtext class="ltx_mathvariant_monospace" id="A1.Ex8.m3.1.1" xref="A1.Ex8.m3.1.1.cmml">&lt;motion_token_b_end&gt;</mtext><mo id="A1.Ex8.m3.1.2.2.1" xref="A1.Ex8.m3.1.1a.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="A1.Ex8.m3.1b"><ci id="A1.Ex8.m3.1.1a.cmml" xref="A1.Ex8.m3.1.2.2"><mtext class="ltx_mathvariant_monospace" id="A1.Ex8.m3.1.1.cmml" xref="A1.Ex8.m3.1.1">&lt;motion_token_b_end&gt;</mtext></ci></annotation-xml><annotation encoding="application/x-tex" id="A1.Ex8.m3.1c">\displaystyle\texttt{&lt;motion\_token\_b\_end&gt;},</annotation><annotation encoding="application/x-llamapun" id="A1.Ex8.m3.1d">&lt;motion_token_b_end&gt; ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="A1.Ex9"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle\texttt{&lt;motion\_token\_end}\}" class="ltx_math_unparsed" display="inline" id="A1.Ex9.m1.1"><semantics id="A1.Ex9.m1.1a"><mrow id="A1.Ex9.m1.1b"><mtext class="ltx_mathvariant_monospace" id="A1.Ex9.m1.1.1">&lt;motion_token_end</mtext><mo id="A1.Ex9.m1.1.2" stretchy="false">}</mo></mrow><annotation encoding="application/x-tex" id="A1.Ex9.m1.1c">\displaystyle\texttt{&lt;motion\_token\_end}\}</annotation><annotation encoding="application/x-llamapun" id="A1.Ex9.m1.1d">&lt;motion_token_end }</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright" colspan="3"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="A1.SS1.p3.6">where <span class="ltx_text ltx_font_typewriter" id="A1.SS1.p3.6.1">&lt;motion_token_start&gt;</span>, <span class="ltx_text ltx_font_typewriter" id="A1.SS1.p3.6.2">&lt;motion_token_a_start&gt;</span>, <span class="ltx_text ltx_font_typewriter" id="A1.SS1.p3.6.3">&lt;motion_token_b_start&gt;</span>, <span class="ltx_text ltx_font_typewriter" id="A1.SS1.p3.6.4">&lt;motion_token_a_end&gt;</span>, <span class="ltx_text ltx_font_typewriter" id="A1.SS1.p3.6.5">&lt;motion_token_b_end&gt;</span>, and <span class="ltx_text ltx_font_typewriter" id="A1.SS1.p3.6.6">&lt;motion_token_end&gt;</span>
is a special token added to the unified vocabulary.</p>
</div>
</section>
<section class="ltx_subsection" id="A1.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.2 </span>Data Sample Visualization</h3>
<div class="ltx_para" id="A1.SS2.p1">
<p class="ltx_p" id="A1.SS2.p1.2">The samples from the synthesized dataset, <span class="ltx_text ltx_markedasmath ltx_font_smallcaps" id="A1.SS2.p1.2.2">Inter</span><span class="ltx_text ltx_font_smallcaps" id="A1.SS2.p1.2.1">-<math alttext="\text{MT}^{2}" class="ltx_Math" display="inline" id="A1.SS2.p1.2.1.m1.1"><semantics id="A1.SS2.p1.2.1.m1.1a"><msup id="A1.SS2.p1.2.1.m1.1.1" xref="A1.SS2.p1.2.1.m1.1.1.cmml"><mtext class="ltx_font_smallcaps" id="A1.SS2.p1.2.1.m1.1.1.2" xref="A1.SS2.p1.2.1.m1.1.1.2a.cmml">MT</mtext><mn id="A1.SS2.p1.2.1.m1.1.1.3" xref="A1.SS2.p1.2.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="A1.SS2.p1.2.1.m1.1b"><apply id="A1.SS2.p1.2.1.m1.1.1.cmml" xref="A1.SS2.p1.2.1.m1.1.1"><csymbol cd="ambiguous" id="A1.SS2.p1.2.1.m1.1.1.1.cmml" xref="A1.SS2.p1.2.1.m1.1.1">superscript</csymbol><ci id="A1.SS2.p1.2.1.m1.1.1.2a.cmml" xref="A1.SS2.p1.2.1.m1.1.1.2"><mtext class="ltx_font_smallcaps" id="A1.SS2.p1.2.1.m1.1.1.2.cmml" xref="A1.SS2.p1.2.1.m1.1.1.2">MT</mtext></ci><cn id="A1.SS2.p1.2.1.m1.1.1.3.cmml" type="integer" xref="A1.SS2.p1.2.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p1.2.1.m1.1c">\text{MT}^{2}</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.p1.2.1.m1.1d">MT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math></span>, are illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#A1.F7" title="Figure 7 ‣ A.2 Data Sample Visualization ‣ Appendix A Appendix ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_tag">7</span></a>.</p>
</div>
<figure class="ltx_figure" id="A1.F7"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="692" id="A1.F7.g1" src="x6.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Sample from <span class="ltx_text ltx_markedasmath ltx_font_smallcaps" id="A1.F7.6.2">Inter</span><span class="ltx_text ltx_font_smallcaps" id="A1.F7.4.1">-<math alttext="\text{MT}^{2}" class="ltx_Math" display="inline" id="A1.F7.4.1.m1.1"><semantics id="A1.F7.4.1.m1.1b"><msup id="A1.F7.4.1.m1.1.1" xref="A1.F7.4.1.m1.1.1.cmml"><mtext class="ltx_font_smallcaps" id="A1.F7.4.1.m1.1.1.2" xref="A1.F7.4.1.m1.1.1.2a.cmml">MT</mtext><mn id="A1.F7.4.1.m1.1.1.3" xref="A1.F7.4.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="A1.F7.4.1.m1.1c"><apply id="A1.F7.4.1.m1.1.1.cmml" xref="A1.F7.4.1.m1.1.1"><csymbol cd="ambiguous" id="A1.F7.4.1.m1.1.1.1.cmml" xref="A1.F7.4.1.m1.1.1">superscript</csymbol><ci id="A1.F7.4.1.m1.1.1.2a.cmml" xref="A1.F7.4.1.m1.1.1.2"><mtext class="ltx_font_smallcaps" id="A1.F7.4.1.m1.1.1.2.cmml" xref="A1.F7.4.1.m1.1.1.2">MT</mtext></ci><cn id="A1.F7.4.1.m1.1.1.3.cmml" type="integer" xref="A1.F7.4.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.F7.4.1.m1.1d">\text{MT}^{2}</annotation><annotation encoding="application/x-llamapun" id="A1.F7.4.1.m1.1e">MT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math></span> datset. The left column visualizes samples of motion editing, and the right column shows the examples from motion reasoning task. </figcaption>
</figure>
</section>
<section class="ltx_subsection" id="A1.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.3 </span><span class="ltx_text ltx_markedasmath ltx_font_smallcaps" id="A1.SS3.3.2">Inter</span><span class="ltx_text ltx_font_smallcaps" id="A1.SS3.2.1">-<math alttext="\text{MT}^{2}" class="ltx_Math" display="inline" id="A1.SS3.2.1.m1.1"><semantics id="A1.SS3.2.1.m1.1b"><msup id="A1.SS3.2.1.m1.1.1" xref="A1.SS3.2.1.m1.1.1.cmml"><mtext class="ltx_font_smallcaps" id="A1.SS3.2.1.m1.1.1.2" xref="A1.SS3.2.1.m1.1.1.2a.cmml">MT</mtext><mn id="A1.SS3.2.1.m1.1.1.3" xref="A1.SS3.2.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="A1.SS3.2.1.m1.1c"><apply id="A1.SS3.2.1.m1.1.1.cmml" xref="A1.SS3.2.1.m1.1.1"><csymbol cd="ambiguous" id="A1.SS3.2.1.m1.1.1.1.cmml" xref="A1.SS3.2.1.m1.1.1">superscript</csymbol><ci id="A1.SS3.2.1.m1.1.1.2a.cmml" xref="A1.SS3.2.1.m1.1.1.2"><mtext class="ltx_font_smallcaps" id="A1.SS3.2.1.m1.1.1.2.cmml" xref="A1.SS3.2.1.m1.1.1.2">MT</mtext></ci><cn id="A1.SS3.2.1.m1.1.1.3.cmml" type="integer" xref="A1.SS3.2.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.2.1.m1.1d">\text{MT}^{2}</annotation><annotation encoding="application/x-llamapun" id="A1.SS3.2.1.m1.1e">MT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math></span> Statistics</h3>
<figure class="ltx_table" id="A1.T5">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>Statistics on <span class="ltx_text ltx_markedasmath ltx_font_smallcaps" id="A1.T5.6.2">Inter</span><span class="ltx_text ltx_font_smallcaps" id="A1.T5.4.1">-<math alttext="\text{MT}^{2}" class="ltx_Math" display="inline" id="A1.T5.4.1.m1.1"><semantics id="A1.T5.4.1.m1.1b"><msup id="A1.T5.4.1.m1.1.1" xref="A1.T5.4.1.m1.1.1.cmml"><mtext class="ltx_font_smallcaps" id="A1.T5.4.1.m1.1.1.2" xref="A1.T5.4.1.m1.1.1.2a.cmml">MT</mtext><mn id="A1.T5.4.1.m1.1.1.3" xref="A1.T5.4.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="A1.T5.4.1.m1.1c"><apply id="A1.T5.4.1.m1.1.1.cmml" xref="A1.T5.4.1.m1.1.1"><csymbol cd="ambiguous" id="A1.T5.4.1.m1.1.1.1.cmml" xref="A1.T5.4.1.m1.1.1">superscript</csymbol><ci id="A1.T5.4.1.m1.1.1.2a.cmml" xref="A1.T5.4.1.m1.1.1.2"><mtext class="ltx_font_smallcaps" id="A1.T5.4.1.m1.1.1.2.cmml" xref="A1.T5.4.1.m1.1.1.2">MT</mtext></ci><cn id="A1.T5.4.1.m1.1.1.3.cmml" type="integer" xref="A1.T5.4.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T5.4.1.m1.1d">\text{MT}^{2}</annotation><annotation encoding="application/x-llamapun" id="A1.T5.4.1.m1.1e">MT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math></span>. </figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A1.T5.7">
<tr class="ltx_tr" id="A1.T5.7.1">
<td class="ltx_td ltx_border_l ltx_border_r ltx_border_t" id="A1.T5.7.1.1"></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T5.7.1.2">Total</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T5.7.1.3">Train</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T5.7.1.4">Val.</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T5.7.1.5">Test</td>
</tr>
<tr class="ltx_tr" id="A1.T5.7.2">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="A1.T5.7.2.1"># of Samples</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T5.7.2.2">82736</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T5.7.2.3">66194</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T5.7.2.4">4141</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T5.7.2.5">12401</td>
</tr>
<tr class="ltx_tr" id="A1.T5.7.3">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="A1.T5.7.3.1"># of Motions</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T5.7.3.2">317749</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T5.7.3.3">132388</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T5.7.3.4">8282</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T5.7.3.5">24802</td>
</tr>
<tr class="ltx_tr" id="A1.T5.7.4">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r" id="A1.T5.7.4.1">From Dataset</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T5.7.4.2">56395</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T5.7.4.3">50258</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T5.7.4.4">3142</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T5.7.4.5">2995</td>
</tr>
<tr class="ltx_tr" id="A1.T5.7.5">
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r" id="A1.T5.7.5.1">Synthesized</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="A1.T5.7.5.2">96676</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="A1.T5.7.5.3">82130</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="A1.T5.7.5.4">5140</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r" id="A1.T5.7.5.5">9406</td>
</tr>
</table>
</figure>
<figure class="ltx_table" id="A1.T6">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 6: </span>Comparison of retrieval precision, motion diversity (Div.), and motion quality metrics (MMDist. and FID) across synthesized and source motions. The synthesized motion dataset (96K pairs) shows a Top 3 retrieval precision of 0.668, comparable to the InterGEN model’s precision (0.645) on the InterX+H dataset, indicating competitive text-to-motion matching quality.</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A1.T6.1">
<tr class="ltx_tr" id="A1.T6.1.1">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="A1.T6.1.1.1" rowspan="2"><span class="ltx_text" id="A1.T6.1.1.1.1">Source</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T6.1.1.2" rowspan="2"><span class="ltx_text" id="A1.T6.1.1.2.1"># of pairs</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3" id="A1.T6.1.1.3">Retrieval Precision</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T6.1.1.4" rowspan="2"><span class="ltx_text" id="A1.T6.1.1.4.1">MMDist.</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T6.1.1.5" rowspan="2"><span class="ltx_text" id="A1.T6.1.1.5.1">Div.</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T6.1.1.6" rowspan="2"><span class="ltx_text" id="A1.T6.1.1.6.1">FID</span></td>
</tr>
<tr class="ltx_tr" id="A1.T6.1.2">
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T6.1.2.1">Top1</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T6.1.2.2">Top2</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T6.1.2.3">Top3</td>
</tr>
<tr class="ltx_tr" id="A1.T6.1.3">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="A1.T6.1.3.1">InterX+H</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T6.1.3.2">18K</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T6.1.3.3">0.645</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T6.1.3.4">0.804</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T6.1.3.5">0.870</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T6.1.3.6">1.072</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T6.1.3.7">0.997</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T6.1.3.8">-</td>
</tr>
<tr class="ltx_tr" id="A1.T6.1.4">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r" id="A1.T6.1.4.1">Synthesized Motion</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T6.1.4.2">96K</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T6.1.4.3">0.480</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T6.1.4.4">0.595</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T6.1.4.5">0.668</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T6.1.4.6">1.102</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T6.1.4.7">0.824</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T6.1.4.8">-</td>
</tr>
<tr class="ltx_tr" id="A1.T6.1.5">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_tt" id="A1.T6.1.5.1">Model</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="A1.T6.1.5.2">Dataset</td>
<td class="ltx_td ltx_border_tt" id="A1.T6.1.5.3"></td>
<td class="ltx_td ltx_border_tt" id="A1.T6.1.5.4"></td>
<td class="ltx_td ltx_border_tt" id="A1.T6.1.5.5"></td>
<td class="ltx_td ltx_border_tt" id="A1.T6.1.5.6"></td>
<td class="ltx_td ltx_border_tt" id="A1.T6.1.5.7"></td>
<td class="ltx_td ltx_border_tt" id="A1.T6.1.5.8"></td>
</tr>
<tr class="ltx_tr" id="A1.T6.1.6">
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="A1.T6.1.6.1">InterGEN <cite class="ltx_cite ltx_citemacro_cite">Liang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib22" title="">2024</a>)</cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="A1.T6.1.6.2">InterX+H</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="A1.T6.1.6.3">0.403</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="A1.T6.1.6.4">0.552</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="A1.T6.1.6.5">0.645</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="A1.T6.1.6.6">1.115</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="A1.T6.1.6.7">0.953</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="A1.T6.1.6.8">0.078</td>
</tr>
</table>
</figure>
<div class="ltx_para ltx_noindent" id="A1.SS3.p1">
<p class="ltx_p" id="A1.SS3.p1.1">We collected 82K samples of multi-turn conversational data, each involving interactive motions. Of these, 30K samples focus on motion editing, 30K on reasoning about past or future scenarios, and 12K on story generation. Each sample includes four to eight conversation turns and two distinct motions. The dataset contains 96K motions generated using a text-to-motion diffusion model, while 56K motions come from the original source dataset. The train-validation-test set is randomly splitted by the ratio 0.8:0.05:0.15.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS3.p2">
<p class="ltx_p" id="A1.SS3.p2.3">The quality of these motions is detailed in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#A1.T6" title='Table 6 ‣ A.3 Inter-"MT"² Statistics ‣ Appendix A Appendix ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents'><span class="ltx_text ltx_ref_tag">6</span></a>. From the generated caption from a large language model, we evaluate the text-motion matching score based on retrieval precision based on the feature space of retrieval models from <cite class="ltx_cite ltx_citemacro_cite">Petrovich et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib30" title="">2023</a>)</cite>. This evaluates the accuracy of matching between texts and motions using Top 3 retrieval accuracy with a fixed batch of 32. The table’s first row shows the retrieval models’ performance, with a Top 3 retrieval precision of <math alttext="0.870" class="ltx_Math" display="inline" id="A1.SS3.p2.1.m1.1"><semantics id="A1.SS3.p2.1.m1.1a"><mn id="A1.SS3.p2.1.m1.1.1" xref="A1.SS3.p2.1.m1.1.1.cmml">0.870</mn><annotation-xml encoding="MathML-Content" id="A1.SS3.p2.1.m1.1b"><cn id="A1.SS3.p2.1.m1.1.1.cmml" type="float" xref="A1.SS3.p2.1.m1.1.1">0.870</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.p2.1.m1.1c">0.870</annotation><annotation encoding="application/x-llamapun" id="A1.SS3.p2.1.m1.1d">0.870</annotation></semantics></math>. We found that the synthesized motions achieve a Top 3 retrieval precision of <math alttext="0.668" class="ltx_Math" display="inline" id="A1.SS3.p2.2.m2.1"><semantics id="A1.SS3.p2.2.m2.1a"><mn id="A1.SS3.p2.2.m2.1.1" xref="A1.SS3.p2.2.m2.1.1.cmml">0.668</mn><annotation-xml encoding="MathML-Content" id="A1.SS3.p2.2.m2.1b"><cn id="A1.SS3.p2.2.m2.1.1.cmml" type="float" xref="A1.SS3.p2.2.m2.1.1">0.668</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.p2.2.m2.1c">0.668</annotation><annotation encoding="application/x-llamapun" id="A1.SS3.p2.2.m2.1d">0.668</annotation></semantics></math>, closely aligning with the reported precision of <math alttext="0.645" class="ltx_Math" display="inline" id="A1.SS3.p2.3.m3.1"><semantics id="A1.SS3.p2.3.m3.1a"><mn id="A1.SS3.p2.3.m3.1.1" xref="A1.SS3.p2.3.m3.1.1.cmml">0.645</mn><annotation-xml encoding="MathML-Content" id="A1.SS3.p2.3.m3.1b"><cn id="A1.SS3.p2.3.m3.1.1.cmml" type="float" xref="A1.SS3.p2.3.m3.1.1">0.645</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.p2.3.m3.1c">0.645</annotation><annotation encoding="application/x-llamapun" id="A1.SS3.p2.3.m3.1d">0.645</annotation></semantics></math> from the text-to-motion diffusion model (<cite class="ltx_cite ltx_citemacro_cite">Liang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib22" title="">2024</a>)</cite>). This demonstrates that the synthesized motions maintain a high level of quality, making the dataset valuable and suitable for further training and development.</p>
</div>
</section>
<section class="ltx_subsection" id="A1.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.4 </span>Detailed Task Explanations</h3>
<section class="ltx_paragraph" id="A1.SS4.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Motion Editing</h5>
<div class="ltx_para ltx_noindent" id="A1.SS4.SSS0.Px1.p1">
<p class="ltx_p" id="A1.SS4.SSS0.Px1.p1.1">Standard motion editing tasks typically involve modifying the motion of a single person based on physical descriptions, such as ”raise higher” or ”move faster.” However, in this task, we focus on editing interactive motions involving two people based on their personas, such as emotions or relationships, by modifying just one person’s persona. The primary challenge in motion editing for two people is that when the motion of one person changes, the motion of the second person, which is correlated, also needs to be adjusted. This requires more complex reasoning about social interactions. Specifically, we define the task as “<span class="ltx_text ltx_font_typewriter" id="A1.SS4.SSS0.Px1.p1.1.1">USER:{scene_information}, {reference_motion}. ASSISTANT: {motion_caption}. USER: {editing_command}. ASSISTANT: {edited_motion}.</span>” The editing command could be defined as asking the model to change the persona of a person, like “Make one person shy.” We let our model generate motion caption in the middle to let the chain-of-thoughts technique improve the reasoning ability.</p>
</div>
</section>
<section class="ltx_paragraph" id="A1.SS4.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">Motion Reasoning</h5>
<div class="ltx_para ltx_noindent" id="A1.SS4.SSS0.Px2.p1">
<p class="ltx_p" id="A1.SS4.SSS0.Px2.p1.1">Motion reasoning involves predicting future motions or inferring past events based on the current motion context. This task requires understanding the sequence of motions and making logical inferences about the preceding or subsequent events. For instance, given a motion of an ongoing interaction between two individuals, the model needs to deduce what might have happened before this moment or predict what will likely occur next.
This is crucial for applications requiring a temporal understanding of motions, such as surveillance analysis, animation, or human-robot interactions. We define the input sequence as follows: “<span class="ltx_text ltx_font_typewriter" id="A1.SS4.SSS0.Px2.p1.1.1">USER:{question_1}, {motion_1}. ASSISTANT: {answer_1}. USER: {question_2}, {motion_2}.</span>”, where the model has to predict “<span class="ltx_text ltx_font_typewriter" id="A1.SS4.SSS0.Px2.p1.1.2">ASSISTANT: {answer_2}</span>”.
The inference question could involve queries like ”Can you tell me what happened before?” or ”What do you think will happen next in this scenario?”. This task demands high-level reasoning and comprehension of motion sequences, enabling the model to generate plausible and coherent motion narratives based on the given context.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="A1.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.5 </span>Ablation Studies on Pretraining Method</h3>
<figure class="ltx_table" id="A1.T7">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 7: </span>Ablation studies in pertaining stage for three motion-related tasks on InterX and Interhuman dataset.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A1.T7.6" style="width:397.5pt;height:106.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-36.1pt,9.7pt) scale(0.84639676210441,0.84639676210441) ;">
<table class="ltx_tabular ltx_align_middle" id="A1.T7.6.6">
<tr class="ltx_tr" id="A1.T7.6.6.7">
<td class="ltx_td ltx_align_center ltx_border_tt" id="A1.T7.6.6.7.1" rowspan="2"><span class="ltx_text" id="A1.T7.6.6.7.1.1">Methods</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A1.T7.6.6.7.2" rowspan="2"><span class="ltx_text" id="A1.T7.6.6.7.2.1">Data</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="A1.T7.6.6.7.3">Trainable</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="A1.T7.6.6.7.4">M2T</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2" id="A1.T7.6.6.7.5">T2M</td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="A1.T7.6.6.7.6">Reaction Gen.</td>
</tr>
<tr class="ltx_tr" id="A1.T7.5.5.5">
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T7.5.5.5.6">Params</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T7.1.1.1.1">R Top3 <math alttext="\uparrow" class="ltx_Math" display="inline" id="A1.T7.1.1.1.1.m1.1"><semantics id="A1.T7.1.1.1.1.m1.1a"><mo id="A1.T7.1.1.1.1.m1.1.1" stretchy="false" xref="A1.T7.1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A1.T7.1.1.1.1.m1.1b"><ci id="A1.T7.1.1.1.1.m1.1.1.cmml" xref="A1.T7.1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T7.1.1.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A1.T7.1.1.1.1.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A1.T7.2.2.2.2">R Top3 <math alttext="\uparrow" class="ltx_Math" display="inline" id="A1.T7.2.2.2.2.m1.1"><semantics id="A1.T7.2.2.2.2.m1.1a"><mo id="A1.T7.2.2.2.2.m1.1.1" stretchy="false" xref="A1.T7.2.2.2.2.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A1.T7.2.2.2.2.m1.1b"><ci id="A1.T7.2.2.2.2.m1.1.1.cmml" xref="A1.T7.2.2.2.2.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T7.2.2.2.2.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A1.T7.2.2.2.2.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T7.3.3.3.3">FID <math alttext="\downarrow" class="ltx_Math" display="inline" id="A1.T7.3.3.3.3.m1.1"><semantics id="A1.T7.3.3.3.3.m1.1a"><mo id="A1.T7.3.3.3.3.m1.1.1" stretchy="false" xref="A1.T7.3.3.3.3.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="A1.T7.3.3.3.3.m1.1b"><ci id="A1.T7.3.3.3.3.m1.1.1.cmml" xref="A1.T7.3.3.3.3.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T7.3.3.3.3.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="A1.T7.3.3.3.3.m1.1d">↓</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A1.T7.4.4.4.4">MPJPE <math alttext="\downarrow" class="ltx_Math" display="inline" id="A1.T7.4.4.4.4.m1.1"><semantics id="A1.T7.4.4.4.4.m1.1a"><mo id="A1.T7.4.4.4.4.m1.1.1" stretchy="false" xref="A1.T7.4.4.4.4.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="A1.T7.4.4.4.4.m1.1b"><ci id="A1.T7.4.4.4.4.m1.1.1.cmml" xref="A1.T7.4.4.4.4.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T7.4.4.4.4.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="A1.T7.4.4.4.4.m1.1d">↓</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A1.T7.5.5.5.5">FID <math alttext="\downarrow" class="ltx_Math" display="inline" id="A1.T7.5.5.5.5.m1.1"><semantics id="A1.T7.5.5.5.5.m1.1a"><mo id="A1.T7.5.5.5.5.m1.1.1" stretchy="false" xref="A1.T7.5.5.5.5.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="A1.T7.5.5.5.5.m1.1b"><ci id="A1.T7.5.5.5.5.m1.1.1.cmml" xref="A1.T7.5.5.5.5.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T7.5.5.5.5.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="A1.T7.5.5.5.5.m1.1d">↓</annotation></semantics></math>
</td>
</tr>
<tr class="ltx_tr" id="A1.T7.6.6.8">
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T7.6.6.8.1">Real</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T7.6.6.8.2">-</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T7.6.6.8.3">-</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T7.6.6.8.4">0.867</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T7.6.6.8.5">0.869</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T7.6.6.8.6">0.00</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T7.6.6.8.7">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T7.6.6.8.8">0.00</td>
</tr>
<tr class="ltx_tr" id="A1.T7.6.6.6">
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T7.6.6.6.1"><math alttext="\text{MotionGPT}^{*}" class="ltx_Math" display="inline" id="A1.T7.6.6.6.1.m1.1"><semantics id="A1.T7.6.6.6.1.m1.1a"><msup id="A1.T7.6.6.6.1.m1.1.1" xref="A1.T7.6.6.6.1.m1.1.1.cmml"><mtext id="A1.T7.6.6.6.1.m1.1.1.2" xref="A1.T7.6.6.6.1.m1.1.1.2a.cmml">MotionGPT</mtext><mo id="A1.T7.6.6.6.1.m1.1.1.3" xref="A1.T7.6.6.6.1.m1.1.1.3.cmml">∗</mo></msup><annotation-xml encoding="MathML-Content" id="A1.T7.6.6.6.1.m1.1b"><apply id="A1.T7.6.6.6.1.m1.1.1.cmml" xref="A1.T7.6.6.6.1.m1.1.1"><csymbol cd="ambiguous" id="A1.T7.6.6.6.1.m1.1.1.1.cmml" xref="A1.T7.6.6.6.1.m1.1.1">superscript</csymbol><ci id="A1.T7.6.6.6.1.m1.1.1.2a.cmml" xref="A1.T7.6.6.6.1.m1.1.1.2"><mtext id="A1.T7.6.6.6.1.m1.1.1.2.cmml" xref="A1.T7.6.6.6.1.m1.1.1.2">MotionGPT</mtext></ci><times id="A1.T7.6.6.6.1.m1.1.1.3.cmml" xref="A1.T7.6.6.6.1.m1.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T7.6.6.6.1.m1.1c">\text{MotionGPT}^{*}</annotation><annotation encoding="application/x-llamapun" id="A1.T7.6.6.6.1.m1.1d">MotionGPT start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T7.6.6.6.2">InterX+H</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T7.6.6.6.3">248M</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T7.6.6.6.4">0.518</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T7.6.6.6.5">0.280</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T7.6.6.6.6">0.178</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T7.6.6.6.7">1.338</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T7.6.6.6.8">0.364</td>
</tr>
<tr class="ltx_tr" id="A1.T7.6.6.9">
<td class="ltx_td ltx_align_center" id="A1.T7.6.6.9.1">VIM-VQ</td>
<td class="ltx_td ltx_align_center" id="A1.T7.6.6.9.2">InterX+H</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T7.6.6.9.3">726M</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T7.6.6.9.4">0.709</td>
<td class="ltx_td ltx_align_center" id="A1.T7.6.6.9.5"><span class="ltx_text ltx_font_bold" id="A1.T7.6.6.9.5.1">0.511</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T7.6.6.9.6">0.181</td>
<td class="ltx_td ltx_align_center" id="A1.T7.6.6.9.7">1.750</td>
<td class="ltx_td ltx_align_center" id="A1.T7.6.6.9.8">0.181</td>
</tr>
<tr class="ltx_tr" id="A1.T7.6.6.10">
<td class="ltx_td ltx_align_center" id="A1.T7.6.6.10.1">VIM (Ours)</td>
<td class="ltx_td ltx_align_center" id="A1.T7.6.6.10.2">InterX+H</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T7.6.6.10.3">726M</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T7.6.6.10.4">0.721</td>
<td class="ltx_td ltx_align_center" id="A1.T7.6.6.10.5">0.427</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T7.6.6.10.6"><span class="ltx_text ltx_font_bold" id="A1.T7.6.6.10.6.1">0.161</span></td>
<td class="ltx_td ltx_align_center" id="A1.T7.6.6.10.7">1.494</td>
<td class="ltx_td ltx_align_center" id="A1.T7.6.6.10.8">0.157</td>
</tr>
<tr class="ltx_tr" id="A1.T7.6.6.11">
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T7.6.6.11.1">
<span class="ltx_text ltx_font_bold" id="A1.T7.6.6.11.1.1">VIM</span> (Ours)</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T7.6.6.11.2">InterX+H + MotionX</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="A1.T7.6.6.11.3">726M</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="A1.T7.6.6.11.4"><span class="ltx_text ltx_font_bold" id="A1.T7.6.6.11.4.1">0.729</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T7.6.6.11.5">0.464</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="A1.T7.6.6.11.6">0.172</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T7.6.6.11.7"><span class="ltx_text ltx_font_bold" id="A1.T7.6.6.11.7.1">1.236</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T7.6.6.11.8"><span class="ltx_text ltx_font_bold" id="A1.T7.6.6.11.8.1">0.131</span></td>
</tr>
</table>
</span></div>
</figure>
<div class="ltx_para ltx_noindent" id="A1.SS5.p1">
<p class="ltx_p" id="A1.SS5.p1.2">We conducted ablation studies on the pertaining method. All the baselines are pre-trained models, not including the fine-tuning stage.
To evaluate the effectiveness of our pretraining approach, we conducted ablation studies comparing different methods on three motion-related tasks: Motion-to-Text (M2T), Text-to-Motion (T2M), and Reaction Generation. As shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#A1.T7" title="Table 7 ‣ A.5 Ablation Studies on Pretraining Method ‣ Appendix A Appendix ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_tag">7</span></a>, we compared our proposed method, VIM, against MotionGPT<sup class="ltx_sup" id="A1.SS5.p1.2.1">∗</sup> and VIM-VQ, using the InterX <cite class="ltx_cite ltx_citemacro_citep">(Xu et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib40" title="">2024a</a>)</cite> and Interhuman (H) datasets <cite class="ltx_cite ltx_citemacro_citep">(Liang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib22" title="">2024</a>)</cite>. MotionGPT<sup class="ltx_sup" id="A1.SS5.p1.2.2">∗</sup> serves as a baseline with 248M trainable parameters, achieving a retrieval Top3 score of 0.518 in M2T and 0.280 in T2M, with corresponding FID scores of 0.178 and 1.338 for T2M and Reaction Generation, respectively. VIM-VQ, with 726M parameters, improves the M2T retrieval Top3 to 0.709 and T2M retrieval Top3 to 0.511, while maintaining competitive FID scores.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS5.p2">
<p class="ltx_p" id="A1.SS5.p2.1">Our method, VIM, further enhances performance by achieving a retrieval Top3 of 0.721 in M2T and reducing the T2M FID to 0.161, alongside an MPJPE of 1.494 and FID of 0.157 in Reaction Generation. Notably, when incorporating the additional MotionX <cite class="ltx_cite ltx_citemacro_citep">(Lin et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib24" title="">2024</a>)</cite> dataset, VIM achieves the highest M2T R Top3 of 0.729 and the lowest FID scores of 0.172 in T2M and 0.131 in Reaction Generation, demonstrating the substantial benefits of our comprehensive pretraining strategy. These results indicate that our approach not only outperforms existing models in generating accurate and high-quality motions but also effectively leverages additional data to enhance interactive motion understanding and generation. The ablation studies highlight the critical role of our pretraining methodology and the integration of diverse datasets in achieving superior performance across multiple interactive tasks.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_subsection" id="A1.SS6">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.6 </span>Qualitative Results</h3>
<div class="ltx_para" id="A1.SS6.p1">
<p class="ltx_p" id="A1.SS6.p1.1">We visualize our result gallery on motion editing in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#A1.F8" title="Figure 8 ‣ A.6 Qualitative Results ‣ Appendix A Appendix ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_tag">8</span></a> and on motion reasoning in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#A1.F9" title="Figure 9 ‣ A.6 Qualitative Results ‣ Appendix A Appendix ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_tag">9</span></a>.
Furthermore, the results for motion-to-text (Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#A1.F10" title="Figure 10 ‣ A.6 Qualitative Results ‣ Appendix A Appendix ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_tag">10</span></a>), text-to-motion (Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#A1.F11" title="Figure 11 ‣ A.6 Qualitative Results ‣ Appendix A Appendix ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_tag">11</span></a>), and reaction generation (Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#A1.F12" title="Figure 12 ‣ A.6 Qualitative Results ‣ Appendix A Appendix ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_tag">12</span></a>) are demonstrated.</p>
</div>
<figure class="ltx_figure" id="A1.F8"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="996" id="A1.F8.g1" src="x7.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Generated motion from source and editing command. </figcaption>
</figure>
<figure class="ltx_figure" id="A1.F9"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_portrait" height="1107" id="A1.F9.g1" src="x8.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>Generated responses based on the previous conversations for motion reasoning task. </figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
<figure class="ltx_figure" id="A1.F10"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="259" id="A1.F10.g1" src="x9.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 10: </span>Motion-to-text results. The blue part is generated motion captions from source motions. </figcaption>
</figure>
<figure class="ltx_figure" id="A1.F11"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="259" id="A1.F11.g1" src="x10.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 11: </span>Text-to-motion results. The blue part is generated motions from the motion caption. </figcaption>
</figure>
<figure class="ltx_figure" id="A1.F12"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="259" id="A1.F12.g1" src="x11.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 12: </span>Reaction Generation. The input motion is orange, while the generated reactive motion is colored blue. </figcaption>
</figure>
</section>
<section class="ltx_subsection" id="A1.SS7">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.7 </span>Implementation details for MotionGPT<sup class="ltx_sup" id="A1.SS7.2.1">∗</sup>
</h3>
<div class="ltx_para ltx_noindent" id="A1.SS7.p1">
<p class="ltx_p" id="A1.SS7.p1.1">For training MotionGPT <cite class="ltx_cite ltx_citemacro_citep">(Jiang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib18" title="">2023</a>)</cite> in the interactive motion dataset, we have utilized the Flan-T5-base model <cite class="ltx_cite ltx_citemacro_citep">(Chung et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib8" title="">2024</a>)</cite> as a base large language model. We trained the model with Interhuman <cite class="ltx_cite ltx_citemacro_citep">(Liang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib22" title="">2024</a>)</cite> and InterX <cite class="ltx_cite ltx_citemacro_citep">(Xu et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib40" title="">2024a</a>)</cite> dataset, with the non-canonical representation, same as the proposed method. Although scaling up the model can improve the performance, we conducted the experiment with the same base model as the original paper from MotionGPT <cite class="ltx_cite ltx_citemacro_citep">(Jiang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib18" title="">2023</a>)</cite> and Motionchain <cite class="ltx_cite ltx_citemacro_citep">(Jiang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib19" title="">2024</a>)</cite>. The original paper reported that increasing the model size did not significantly improved the model’s performance.</p>
</div>
</section>
<section class="ltx_subsection" id="A1.SS8">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.8 </span>Detailed Explanation about Two-stage Baselines</h3>
<div class="ltx_para ltx_noindent" id="A1.SS8.p1">
<p class="ltx_p" id="A1.SS8.p1.1">In Section 5.2 and Section 5.3, we have compared the proposed method with two-stage models. In particular, we have utilized TM2T <cite class="ltx_cite ltx_citemacro_citep">(Guo et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib14" title="">2022</a>)</cite> for the motion captioner and InterGEN <cite class="ltx_cite ltx_citemacro_citep">(Liang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib22" title="">2024</a>)</cite> for the text-to-motion generation model.</p>
</div>
<section class="ltx_paragraph" id="A1.SS8.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Motion Editing</h5>
<div class="ltx_para ltx_noindent" id="A1.SS8.SSS0.Px1.p1">
<p class="ltx_p" id="A1.SS8.SSS0.Px1.p1.1">In the motion editing task, the two-stage approach first uses the motion-to-text (TM2T; <cite class="ltx_cite ltx_citemacro_cite">Guo et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib14" title="">2022</a>)</cite>) model to generate a caption from the source motion and append the editing command. Then, the text-to-motion (InterGen; <cite class="ltx_cite ltx_citemacro_cite">Liang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib22" title="">2024</a>)</cite>) model produces the edited motion based on this caption and command. In particular, the input for text-to-motion model is ”<span class="ltx_text ltx_font_typewriter" id="A1.SS8.SSS0.Px1.p1.1.1">[motion caption]. [editing command]</span>”.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS8.SSS0.Px1.p2">
<p class="ltx_p" id="A1.SS8.SSS0.Px1.p2.6">We first trained TM2T model with the InterHuman dataset <cite class="ltx_cite ltx_citemacro_citep">(Liang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib22" title="">2024</a>)</cite>and the InterX <cite class="ltx_cite ltx_citemacro_cite">Xu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib40" title="">2024a</a>)</cite> dataset, which we denote as TM2T<math alttext="{}^{*}*" class="ltx_math_unparsed" display="inline" id="A1.SS8.SSS0.Px1.p2.1.m1.1"><semantics id="A1.SS8.SSS0.Px1.p2.1.m1.1a"><mmultiscripts id="A1.SS8.SSS0.Px1.p2.1.m1.1.1"><mo id="A1.SS8.SSS0.Px1.p2.1.m1.1.1.2">∗</mo><mprescripts id="A1.SS8.SSS0.Px1.p2.1.m1.1.1a"></mprescripts><mrow id="A1.SS8.SSS0.Px1.p2.1.m1.1.1b"></mrow><mo id="A1.SS8.SSS0.Px1.p2.1.m1.1.1.3">∗</mo></mmultiscripts><annotation encoding="application/x-tex" id="A1.SS8.SSS0.Px1.p2.1.m1.1b">{}^{*}*</annotation><annotation encoding="application/x-llamapun" id="A1.SS8.SSS0.Px1.p2.1.m1.1c">start_FLOATSUPERSCRIPT ∗ end_FLOATSUPERSCRIPT ∗</annotation></semantics></math>. The performance is shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#A1.T8" title="Table 8 ‣ Motion Editing ‣ A.8 Detailed Explanation about Two-stage Baselines ‣ Appendix A Appendix ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_tag">8</span></a>. The TM2T<sup class="ltx_sup" id="A1.SS8.SSS0.Px1.p2.6.1">∗</sup> model shows substantial improvements over the baseline MotionGPT<sup class="ltx_sup" id="A1.SS8.SSS0.Px1.p2.6.2">∗</sup> models across all evaluation metrics. Specifically, TM2T<sup class="ltx_sup" id="A1.SS8.SSS0.Px1.p2.6.3">∗</sup> achieves Retriveal Precision scores of 0.413 (Top1), 0.589 (Top2), and 0.696 (Top3), along with BLEU, METEOR, and Rouge-L scores of 0.192, 0.386, and 0.395, respectively. These results indicate that the task-specific TM2T<sup class="ltx_sup" id="A1.SS8.SSS0.Px1.p2.6.4">∗</sup> model effectively generates accurate and relevant motion captions, making it a reliable choice for motion editing tasks. Although there remains a performance gap compared to the proposed method, the TM2T<sup class="ltx_sup" id="A1.SS8.SSS0.Px1.p2.6.5">∗</sup> model provides a robust foundation for generating moderate-quality motion captions.</p>
</div>
<figure class="ltx_table" id="A1.T8">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 8: </span>Motion-to-Text performance for TM2T</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A1.T8.9" style="width:357.7pt;height:125.1pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-27.0pt,9.4pt) scale(0.869046932842232,0.869046932842232) ;">
<table class="ltx_tabular ltx_align_middle" id="A1.T8.9.9">
<tr class="ltx_tr" id="A1.T8.3.3.3">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="A1.T8.3.3.3.4">Methods</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="3" id="A1.T8.3.3.3.5">Ret. Precision</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="A1.T8.1.1.1.1" rowspan="2"><span class="ltx_text" id="A1.T8.1.1.1.1.1">BLEU <math alttext="\uparrow" class="ltx_Math" display="inline" id="A1.T8.1.1.1.1.1.m1.1"><semantics id="A1.T8.1.1.1.1.1.m1.1a"><mo id="A1.T8.1.1.1.1.1.m1.1.1" stretchy="false" xref="A1.T8.1.1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A1.T8.1.1.1.1.1.m1.1b"><ci id="A1.T8.1.1.1.1.1.m1.1.1.cmml" xref="A1.T8.1.1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T8.1.1.1.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A1.T8.1.1.1.1.1.m1.1d">↑</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="A1.T8.2.2.2.2" rowspan="2"><span class="ltx_text" id="A1.T8.2.2.2.2.1">METEOR <math alttext="\uparrow" class="ltx_Math" display="inline" id="A1.T8.2.2.2.2.1.m1.1"><semantics id="A1.T8.2.2.2.2.1.m1.1a"><mo id="A1.T8.2.2.2.2.1.m1.1.1" stretchy="false" xref="A1.T8.2.2.2.2.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A1.T8.2.2.2.2.1.m1.1b"><ci id="A1.T8.2.2.2.2.1.m1.1.1.cmml" xref="A1.T8.2.2.2.2.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T8.2.2.2.2.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A1.T8.2.2.2.2.1.m1.1d">↑</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A1.T8.3.3.3.3" rowspan="2"><span class="ltx_text" id="A1.T8.3.3.3.3.1">Rouge-L <math alttext="\uparrow" class="ltx_Math" display="inline" id="A1.T8.3.3.3.3.1.m1.1"><semantics id="A1.T8.3.3.3.3.1.m1.1a"><mo id="A1.T8.3.3.3.3.1.m1.1.1" stretchy="false" xref="A1.T8.3.3.3.3.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A1.T8.3.3.3.3.1.m1.1b"><ci id="A1.T8.3.3.3.3.1.m1.1.1.cmml" xref="A1.T8.3.3.3.3.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T8.3.3.3.3.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A1.T8.3.3.3.3.1.m1.1d">↑</annotation></semantics></math></span></td>
</tr>
<tr class="ltx_tr" id="A1.T8.6.6.6">
<td class="ltx_td ltx_border_r" id="A1.T8.6.6.6.4"></td>
<td class="ltx_td ltx_align_center" id="A1.T8.4.4.4.1">Top1 <math alttext="\uparrow" class="ltx_Math" display="inline" id="A1.T8.4.4.4.1.m1.1"><semantics id="A1.T8.4.4.4.1.m1.1a"><mo id="A1.T8.4.4.4.1.m1.1.1" stretchy="false" xref="A1.T8.4.4.4.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A1.T8.4.4.4.1.m1.1b"><ci id="A1.T8.4.4.4.1.m1.1.1.cmml" xref="A1.T8.4.4.4.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T8.4.4.4.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A1.T8.4.4.4.1.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A1.T8.5.5.5.2">Top2 <math alttext="\uparrow" class="ltx_Math" display="inline" id="A1.T8.5.5.5.2.m1.1"><semantics id="A1.T8.5.5.5.2.m1.1a"><mo id="A1.T8.5.5.5.2.m1.1.1" stretchy="false" xref="A1.T8.5.5.5.2.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A1.T8.5.5.5.2.m1.1b"><ci id="A1.T8.5.5.5.2.m1.1.1.cmml" xref="A1.T8.5.5.5.2.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T8.5.5.5.2.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A1.T8.5.5.5.2.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T8.6.6.6.3">Top3 <math alttext="\uparrow" class="ltx_Math" display="inline" id="A1.T8.6.6.6.3.m1.1"><semantics id="A1.T8.6.6.6.3.m1.1a"><mo id="A1.T8.6.6.6.3.m1.1.1" stretchy="false" xref="A1.T8.6.6.6.3.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A1.T8.6.6.6.3.m1.1b"><ci id="A1.T8.6.6.6.3.m1.1.1.cmml" xref="A1.T8.6.6.6.3.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T8.6.6.6.3.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A1.T8.6.6.6.3.m1.1d">↑</annotation></semantics></math>
</td>
</tr>
<tr class="ltx_tr" id="A1.T8.9.9.10">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T8.9.9.10.1"><span class="ltx_text ltx_font_italic" id="A1.T8.9.9.10.1.1" style="color:#808080;">unified approach</span></td>
<td class="ltx_td ltx_border_t" id="A1.T8.9.9.10.2"></td>
<td class="ltx_td ltx_border_t" id="A1.T8.9.9.10.3"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A1.T8.9.9.10.4"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A1.T8.9.9.10.5"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A1.T8.9.9.10.6"></td>
<td class="ltx_td ltx_border_t" id="A1.T8.9.9.10.7"></td>
</tr>
<tr class="ltx_tr" id="A1.T8.7.7.7">
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T8.7.7.7.1">MotionGPT<sup class="ltx_sup" id="A1.T8.7.7.7.1.1">∗</sup>
</td>
<td class="ltx_td ltx_align_center" id="A1.T8.7.7.7.2">0.288</td>
<td class="ltx_td ltx_align_center" id="A1.T8.7.7.7.3">0.405</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T8.7.7.7.4">0.494</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T8.7.7.7.5">0.000</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T8.7.7.7.6">0.000</td>
<td class="ltx_td ltx_align_center" id="A1.T8.7.7.7.7">0.00</td>
</tr>
<tr class="ltx_tr" id="A1.T8.8.8.8">
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T8.8.8.8.1">MotionGPT<math alttext="{}^{*}_{I}" class="ltx_Math" display="inline" id="A1.T8.8.8.8.1.m1.1"><semantics id="A1.T8.8.8.8.1.m1.1a"><mmultiscripts id="A1.T8.8.8.8.1.m1.1.1" xref="A1.T8.8.8.8.1.m1.1.1.cmml"><mi id="A1.T8.8.8.8.1.m1.1.1.2.2" xref="A1.T8.8.8.8.1.m1.1.1.2.2.cmml"></mi><mprescripts id="A1.T8.8.8.8.1.m1.1.1a" xref="A1.T8.8.8.8.1.m1.1.1.cmml"></mprescripts><mi id="A1.T8.8.8.8.1.m1.1.1.3" xref="A1.T8.8.8.8.1.m1.1.1.3.cmml">I</mi><mrow id="A1.T8.8.8.8.1.m1.1.1b" xref="A1.T8.8.8.8.1.m1.1.1.cmml"></mrow><mrow id="A1.T8.8.8.8.1.m1.1.1c" xref="A1.T8.8.8.8.1.m1.1.1.cmml"></mrow><mo id="A1.T8.8.8.8.1.m1.1.1.2.3" xref="A1.T8.8.8.8.1.m1.1.1.2.3.cmml">∗</mo></mmultiscripts><annotation-xml encoding="MathML-Content" id="A1.T8.8.8.8.1.m1.1b"><apply id="A1.T8.8.8.8.1.m1.1.1.cmml" xref="A1.T8.8.8.8.1.m1.1.1"><csymbol cd="ambiguous" id="A1.T8.8.8.8.1.m1.1.1.1.cmml" xref="A1.T8.8.8.8.1.m1.1.1">subscript</csymbol><apply id="A1.T8.8.8.8.1.m1.1.1.2.cmml" xref="A1.T8.8.8.8.1.m1.1.1"><csymbol cd="ambiguous" id="A1.T8.8.8.8.1.m1.1.1.2.1.cmml" xref="A1.T8.8.8.8.1.m1.1.1">superscript</csymbol><csymbol cd="latexml" id="A1.T8.8.8.8.1.m1.1.1.2.2.cmml" xref="A1.T8.8.8.8.1.m1.1.1.2.2">absent</csymbol><times id="A1.T8.8.8.8.1.m1.1.1.2.3.cmml" xref="A1.T8.8.8.8.1.m1.1.1.2.3"></times></apply><ci id="A1.T8.8.8.8.1.m1.1.1.3.cmml" xref="A1.T8.8.8.8.1.m1.1.1.3">𝐼</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T8.8.8.8.1.m1.1c">{}^{*}_{I}</annotation><annotation encoding="application/x-llamapun" id="A1.T8.8.8.8.1.m1.1d">start_FLOATSUPERSCRIPT ∗ end_FLOATSUPERSCRIPT start_POSTSUBSCRIPT italic_I end_POSTSUBSCRIPT</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A1.T8.8.8.8.2">0.282</td>
<td class="ltx_td ltx_align_center" id="A1.T8.8.8.8.3">0.423</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T8.8.8.8.4">0.503</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T8.8.8.8.5">0.000</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T8.8.8.8.6">0.000</td>
<td class="ltx_td ltx_align_center" id="A1.T8.8.8.8.7">0.00</td>
</tr>
<tr class="ltx_tr" id="A1.T8.9.9.11">
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T8.9.9.11.1">
<span class="ltx_text ltx_font_bold" id="A1.T8.9.9.11.1.1">VIM</span> (Ours)</td>
<td class="ltx_td ltx_align_center" id="A1.T8.9.9.11.2"><span class="ltx_text ltx_font_bold" id="A1.T8.9.9.11.2.1">0.669</span></td>
<td class="ltx_td ltx_align_center" id="A1.T8.9.9.11.3"><span class="ltx_text ltx_font_bold" id="A1.T8.9.9.11.3.1">0.842</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T8.9.9.11.4"><span class="ltx_text ltx_font_bold" id="A1.T8.9.9.11.4.1">0.903</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T8.9.9.11.5"><span class="ltx_text ltx_font_bold" id="A1.T8.9.9.11.5.1">0.230</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T8.9.9.11.6"><span class="ltx_text ltx_font_bold" id="A1.T8.9.9.11.6.1">0.441</span></td>
<td class="ltx_td ltx_align_center" id="A1.T8.9.9.11.7"><span class="ltx_text ltx_font_bold" id="A1.T8.9.9.11.7.1">0.420</span></td>
</tr>
<tr class="ltx_tr" id="A1.T8.9.9.12">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T8.9.9.12.1"><span class="ltx_text ltx_font_italic" id="A1.T8.9.9.12.1.1" style="color:#808080;">task-specific approach</span></td>
<td class="ltx_td ltx_border_t" id="A1.T8.9.9.12.2"></td>
<td class="ltx_td ltx_border_t" id="A1.T8.9.9.12.3"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A1.T8.9.9.12.4"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A1.T8.9.9.12.5"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A1.T8.9.9.12.6"></td>
<td class="ltx_td ltx_border_t" id="A1.T8.9.9.12.7"></td>
</tr>
<tr class="ltx_tr" id="A1.T8.9.9.9">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="A1.T8.9.9.9.1">TM2T<sup class="ltx_sup" id="A1.T8.9.9.9.1.1">∗</sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T8.9.9.9.2"><span class="ltx_text ltx_framed ltx_framed_underline" id="A1.T8.9.9.9.2.1">0.413</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T8.9.9.9.3"><span class="ltx_text ltx_framed ltx_framed_underline" id="A1.T8.9.9.9.3.1">0.589</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="A1.T8.9.9.9.4"><span class="ltx_text ltx_framed ltx_framed_underline" id="A1.T8.9.9.9.4.1">0.696</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="A1.T8.9.9.9.5"><span class="ltx_text ltx_framed ltx_framed_underline" id="A1.T8.9.9.9.5.1">0.192</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="A1.T8.9.9.9.6"><span class="ltx_text ltx_framed ltx_framed_underline" id="A1.T8.9.9.9.6.1">0.386</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T8.9.9.9.7"><span class="ltx_text ltx_framed ltx_framed_underline" id="A1.T8.9.9.9.7.1">0.395</span></td>
</tr>
</table>
</span></div>
</figure>
<figure class="ltx_table" id="A1.T9">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 9: </span>Text-to-Motion performance for InterGEN</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A1.T9.9" style="width:357.7pt;height:152.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-31.7pt,13.5pt) scale(0.849555242404051,0.849555242404051) ;">
<table class="ltx_tabular ltx_align_middle" id="A1.T9.9.9">
<tr class="ltx_tr" id="A1.T9.3.3.3">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="A1.T9.3.3.3.4">Methods</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="3" id="A1.T9.3.3.3.5">Ret. Precision</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="A1.T9.1.1.1.1" rowspan="2"><span class="ltx_text" id="A1.T9.1.1.1.1.1">FID <math alttext="\downarrow" class="ltx_Math" display="inline" id="A1.T9.1.1.1.1.1.m1.1"><semantics id="A1.T9.1.1.1.1.1.m1.1a"><mo id="A1.T9.1.1.1.1.1.m1.1.1" stretchy="false" xref="A1.T9.1.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="A1.T9.1.1.1.1.1.m1.1b"><ci id="A1.T9.1.1.1.1.1.m1.1.1.cmml" xref="A1.T9.1.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T9.1.1.1.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="A1.T9.1.1.1.1.1.m1.1d">↓</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="A1.T9.2.2.2.2" rowspan="2"><span class="ltx_text" id="A1.T9.2.2.2.2.1">Diversity <math alttext="\rightarrow" class="ltx_Math" display="inline" id="A1.T9.2.2.2.2.1.m1.1"><semantics id="A1.T9.2.2.2.2.1.m1.1a"><mo id="A1.T9.2.2.2.2.1.m1.1.1" stretchy="false" xref="A1.T9.2.2.2.2.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="A1.T9.2.2.2.2.1.m1.1b"><ci id="A1.T9.2.2.2.2.1.m1.1.1.cmml" xref="A1.T9.2.2.2.2.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T9.2.2.2.2.1.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="A1.T9.2.2.2.2.1.m1.1d">→</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A1.T9.3.3.3.3" rowspan="2"><span class="ltx_text" id="A1.T9.3.3.3.3.1">MMDist <math alttext="\downarrow" class="ltx_Math" display="inline" id="A1.T9.3.3.3.3.1.m1.1"><semantics id="A1.T9.3.3.3.3.1.m1.1a"><mo id="A1.T9.3.3.3.3.1.m1.1.1" stretchy="false" xref="A1.T9.3.3.3.3.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="A1.T9.3.3.3.3.1.m1.1b"><ci id="A1.T9.3.3.3.3.1.m1.1.1.cmml" xref="A1.T9.3.3.3.3.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T9.3.3.3.3.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="A1.T9.3.3.3.3.1.m1.1d">↓</annotation></semantics></math></span></td>
</tr>
<tr class="ltx_tr" id="A1.T9.6.6.6">
<td class="ltx_td ltx_border_r" id="A1.T9.6.6.6.4"></td>
<td class="ltx_td ltx_align_center" id="A1.T9.4.4.4.1">R Top1 <math alttext="\uparrow" class="ltx_Math" display="inline" id="A1.T9.4.4.4.1.m1.1"><semantics id="A1.T9.4.4.4.1.m1.1a"><mo id="A1.T9.4.4.4.1.m1.1.1" stretchy="false" xref="A1.T9.4.4.4.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A1.T9.4.4.4.1.m1.1b"><ci id="A1.T9.4.4.4.1.m1.1.1.cmml" xref="A1.T9.4.4.4.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T9.4.4.4.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A1.T9.4.4.4.1.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A1.T9.5.5.5.2">R Top2 <math alttext="\uparrow" class="ltx_Math" display="inline" id="A1.T9.5.5.5.2.m1.1"><semantics id="A1.T9.5.5.5.2.m1.1a"><mo id="A1.T9.5.5.5.2.m1.1.1" stretchy="false" xref="A1.T9.5.5.5.2.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A1.T9.5.5.5.2.m1.1b"><ci id="A1.T9.5.5.5.2.m1.1.1.cmml" xref="A1.T9.5.5.5.2.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T9.5.5.5.2.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A1.T9.5.5.5.2.m1.1d">↑</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T9.6.6.6.3">R Top3<math alttext="\uparrow" class="ltx_Math" display="inline" id="A1.T9.6.6.6.3.m1.1"><semantics id="A1.T9.6.6.6.3.m1.1a"><mo id="A1.T9.6.6.6.3.m1.1.1" stretchy="false" xref="A1.T9.6.6.6.3.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="A1.T9.6.6.6.3.m1.1b"><ci id="A1.T9.6.6.6.3.m1.1.1.cmml" xref="A1.T9.6.6.6.3.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T9.6.6.6.3.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="A1.T9.6.6.6.3.m1.1d">↑</annotation></semantics></math>
</td>
</tr>
<tr class="ltx_tr" id="A1.T9.9.9.10">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T9.9.9.10.1">Real</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T9.9.9.10.2">0.649</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T9.9.9.10.3">0.807</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T9.9.9.10.4">0.878</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T9.9.9.10.5">0.00</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T9.9.9.10.6">0.988</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T9.9.9.10.7">1.072</td>
</tr>
<tr class="ltx_tr" id="A1.T9.9.9.11">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T9.9.9.11.1"><span class="ltx_text ltx_font_italic" id="A1.T9.9.9.11.1.1" style="color:#808080;">unified approach</span></td>
<td class="ltx_td ltx_border_t" id="A1.T9.9.9.11.2"></td>
<td class="ltx_td ltx_border_t" id="A1.T9.9.9.11.3"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A1.T9.9.9.11.4"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A1.T9.9.9.11.5"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A1.T9.9.9.11.6"></td>
<td class="ltx_td ltx_border_t" id="A1.T9.9.9.11.7"></td>
</tr>
<tr class="ltx_tr" id="A1.T9.7.7.7">
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T9.7.7.7.1">MotionGPT<sup class="ltx_sup" id="A1.T9.7.7.7.1.1">∗</sup>
</td>
<td class="ltx_td ltx_align_center" id="A1.T9.7.7.7.2">0.180</td>
<td class="ltx_td ltx_align_center" id="A1.T9.7.7.7.3">0.262</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T9.7.7.7.4">0.328</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T9.7.7.7.5">0.123</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T9.7.7.7.6">0.898</td>
<td class="ltx_td ltx_align_center" id="A1.T9.7.7.7.7">1.167</td>
</tr>
<tr class="ltx_tr" id="A1.T9.8.8.8">
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T9.8.8.8.1">MotionGPT<math alttext="{}^{*}_{I}" class="ltx_Math" display="inline" id="A1.T9.8.8.8.1.m1.1"><semantics id="A1.T9.8.8.8.1.m1.1a"><mmultiscripts id="A1.T9.8.8.8.1.m1.1.1" xref="A1.T9.8.8.8.1.m1.1.1.cmml"><mi id="A1.T9.8.8.8.1.m1.1.1.2.2" xref="A1.T9.8.8.8.1.m1.1.1.2.2.cmml"></mi><mprescripts id="A1.T9.8.8.8.1.m1.1.1a" xref="A1.T9.8.8.8.1.m1.1.1.cmml"></mprescripts><mi id="A1.T9.8.8.8.1.m1.1.1.3" xref="A1.T9.8.8.8.1.m1.1.1.3.cmml">I</mi><mrow id="A1.T9.8.8.8.1.m1.1.1b" xref="A1.T9.8.8.8.1.m1.1.1.cmml"></mrow><mrow id="A1.T9.8.8.8.1.m1.1.1c" xref="A1.T9.8.8.8.1.m1.1.1.cmml"></mrow><mo id="A1.T9.8.8.8.1.m1.1.1.2.3" xref="A1.T9.8.8.8.1.m1.1.1.2.3.cmml">∗</mo></mmultiscripts><annotation-xml encoding="MathML-Content" id="A1.T9.8.8.8.1.m1.1b"><apply id="A1.T9.8.8.8.1.m1.1.1.cmml" xref="A1.T9.8.8.8.1.m1.1.1"><csymbol cd="ambiguous" id="A1.T9.8.8.8.1.m1.1.1.1.cmml" xref="A1.T9.8.8.8.1.m1.1.1">subscript</csymbol><apply id="A1.T9.8.8.8.1.m1.1.1.2.cmml" xref="A1.T9.8.8.8.1.m1.1.1"><csymbol cd="ambiguous" id="A1.T9.8.8.8.1.m1.1.1.2.1.cmml" xref="A1.T9.8.8.8.1.m1.1.1">superscript</csymbol><csymbol cd="latexml" id="A1.T9.8.8.8.1.m1.1.1.2.2.cmml" xref="A1.T9.8.8.8.1.m1.1.1.2.2">absent</csymbol><times id="A1.T9.8.8.8.1.m1.1.1.2.3.cmml" xref="A1.T9.8.8.8.1.m1.1.1.2.3"></times></apply><ci id="A1.T9.8.8.8.1.m1.1.1.3.cmml" xref="A1.T9.8.8.8.1.m1.1.1.3">𝐼</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T9.8.8.8.1.m1.1c">{}^{*}_{I}</annotation><annotation encoding="application/x-llamapun" id="A1.T9.8.8.8.1.m1.1d">start_FLOATSUPERSCRIPT ∗ end_FLOATSUPERSCRIPT start_POSTSUBSCRIPT italic_I end_POSTSUBSCRIPT</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="A1.T9.8.8.8.2">0.175</td>
<td class="ltx_td ltx_align_center" id="A1.T9.8.8.8.3">0.264</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T9.8.8.8.4">0.331</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T9.8.8.8.5">0.118</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T9.8.8.8.6">0.900</td>
<td class="ltx_td ltx_align_center" id="A1.T9.8.8.8.7">1.176</td>
</tr>
<tr class="ltx_tr" id="A1.T9.9.9.12">
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T9.9.9.12.1">
<span class="ltx_text ltx_font_bold" id="A1.T9.9.9.12.1.1">VIM</span>(Ours)</td>
<td class="ltx_td ltx_align_center" id="A1.T9.9.9.12.2"><span class="ltx_text ltx_framed ltx_framed_underline" id="A1.T9.9.9.12.2.1">0.318</span></td>
<td class="ltx_td ltx_align_center" id="A1.T9.9.9.12.3"><span class="ltx_text ltx_framed ltx_framed_underline" id="A1.T9.9.9.12.3.1">0.469</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T9.9.9.12.4"><span class="ltx_text ltx_framed ltx_framed_underline" id="A1.T9.9.9.12.4.1">0.568</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T9.9.9.12.5"><span class="ltx_text ltx_font_bold" id="A1.T9.9.9.12.5.1">0.059</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T9.9.9.12.6"><span class="ltx_text ltx_framed ltx_framed_underline" id="A1.T9.9.9.12.6.1">0.945</span></td>
<td class="ltx_td ltx_align_center" id="A1.T9.9.9.12.7"><span class="ltx_text ltx_framed ltx_framed_underline" id="A1.T9.9.9.12.7.1">1.126</span></td>
</tr>
<tr class="ltx_tr" id="A1.T9.9.9.13">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T9.9.9.13.1"><span class="ltx_text ltx_font_italic" id="A1.T9.9.9.13.1.1" style="color:#808080;">task-specific approach</span></td>
<td class="ltx_td ltx_border_t" id="A1.T9.9.9.13.2"></td>
<td class="ltx_td ltx_border_t" id="A1.T9.9.9.13.3"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A1.T9.9.9.13.4"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A1.T9.9.9.13.5"></td>
<td class="ltx_td ltx_border_r ltx_border_t" id="A1.T9.9.9.13.6"></td>
<td class="ltx_td ltx_border_t" id="A1.T9.9.9.13.7"></td>
</tr>
<tr class="ltx_tr" id="A1.T9.9.9.9">
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T9.9.9.9.1">TM2T<sup class="ltx_sup" id="A1.T9.9.9.9.1.1">∗</sup>
</td>
<td class="ltx_td ltx_align_center" id="A1.T9.9.9.9.2">0.276</td>
<td class="ltx_td ltx_align_center" id="A1.T9.9.9.9.3">0.437</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T9.9.9.9.4">0.534</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T9.9.9.9.5">0.300</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A1.T9.9.9.9.6">0.676</td>
<td class="ltx_td ltx_align_center" id="A1.T9.9.9.9.7">1.130</td>
</tr>
<tr class="ltx_tr" id="A1.T9.9.9.14">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="A1.T9.9.9.14.1">InterGEN</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T9.9.9.14.2"><span class="ltx_text ltx_font_bold" id="A1.T9.9.9.14.2.1">0.403</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T9.9.9.14.3"><span class="ltx_text ltx_font_bold" id="A1.T9.9.9.14.3.1">0.557</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="A1.T9.9.9.14.4"><span class="ltx_text ltx_font_bold" id="A1.T9.9.9.14.4.1">0.645</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="A1.T9.9.9.14.5"><span class="ltx_text ltx_framed ltx_framed_underline" id="A1.T9.9.9.14.5.1">0.078</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="A1.T9.9.9.14.6"><span class="ltx_text ltx_font_bold" id="A1.T9.9.9.14.6.1">0.957</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T9.9.9.14.7"><span class="ltx_text ltx_font_bold" id="A1.T9.9.9.14.7.1">1.115</span></td>
</tr>
</table>
</span></div>
</figure>
<div class="ltx_para ltx_noindent" id="A1.SS8.SSS0.Px1.p3">
<p class="ltx_p" id="A1.SS8.SSS0.Px1.p3.1">Next, we trained the text-to-motion diffusion model, InterGEN for the second stage. The performance of this model is reported in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#A1.T9" title="Table 9 ‣ Motion Editing ‣ A.8 Detailed Explanation about Two-stage Baselines ‣ Appendix A Appendix ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_tag">9</span></a>. InterGEN exhibits strong performance across all evaluation metrics, validating its effectiveness as the second stage in our two-stage approach. Specifically, InterGEN achieves Retrieval Precision scores of 0.403 (Top1), 0.557 (Top2), and 0.645 (Top3), which are substantially higher than those of the baseline MotionGPT<sup class="ltx_sup" id="A1.SS8.SSS0.Px1.p3.1.1">∗</sup> (0.180, 0.262, 0.328) and our unified VIM model (0.318, 0.469, 0.568). Additionally, InterGEN excels in Diversity with a score of 0.957 and maintains a low Maximum Mean Discrepancy (MMDist) of 1.115, indicating high-quality and varied motion generation. Its FID score of 0.078 is notably competitive, reflecting the realism and coherence of the generated motions.
These results validate the use of InterGEN as the second stage in our framework.</p>
</div>
</section>
<section class="ltx_paragraph" id="A1.SS8.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">Motion Reasoning</h5>
<div class="ltx_para ltx_noindent" id="A1.SS8.SSS0.Px2.p1">
<p class="ltx_p" id="A1.SS8.SSS0.Px2.p1.1">In the motion reasoning task, the two-stage model integrates TM2T with large language models such as GPT-4o <cite class="ltx_cite ltx_citemacro_cite">OpenAI (<a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib28" title="">2024</a>)</cite> and LLaMA-3.1-8B <cite class="ltx_cite ltx_citemacro_cite">Dubey et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib9" title="">2024</a>)</cite>. Here, the motion components in the conversational data are replaced with captions generated by TM2T, which are then fed into the LLM for reasoning and response generation. In particular, the original input for the motion-language model was “<span class="ltx_text ltx_font_typewriter" id="A1.SS8.SSS0.Px2.p1.1.1">USER:{question_1}, {motion_1}. ASSISTANT: {answer_1}. USER: {question_2}, {motion_2}.</span>”, where the model has to predict “<span class="ltx_text ltx_font_typewriter" id="A1.SS8.SSS0.Px2.p1.1.2">ASSISTANT: {answer_2}</span>”. We replaced the motion into motion caption obtained by motion captioner for the input for LLM like “<span class="ltx_text ltx_font_typewriter" id="A1.SS8.SSS0.Px2.p1.1.3">USER:{question_1}, {motion_caption_1}. ASSISTANT: {answer_1}. USER: {question_2}, {motion_caption_2}.</span>”. Again, we utilized TM2T<sup class="ltx_sup" id="A1.SS8.SSS0.Px2.p1.1.4">∗</sup> for the motion captioner mentioned in the previous section.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="A1.SS9">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.9 </span>Template Forms for Pre-training and Instruction Tuning</h3>
<figure class="ltx_table" id="A1.T10">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 10: </span>Template for Pretraining</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A1.T10.1">
<tr class="ltx_tr" id="A1.T10.1.1">
<td class="ltx_td ltx_align_center ltx_border_tt" id="A1.T10.1.1.1">Task</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A1.T10.1.1.2">Sequence</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A1.T10.1.1.3">Label</td>
</tr>
<tr class="ltx_tr" id="A1.T10.1.2">
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T10.1.2.1">Text-to-Motion</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T10.1.2.2">Generate caption from motion: [motion] [caption]</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T10.1.2.3">[caption]</td>
</tr>
<tr class="ltx_tr" id="A1.T10.1.3">
<td class="ltx_td ltx_align_center" id="A1.T10.1.3.1">Motion-to-Text</td>
<td class="ltx_td ltx_align_center" id="A1.T10.1.3.2">Generate motion from caption: [caption][motion]</td>
<td class="ltx_td ltx_align_center" id="A1.T10.1.3.3">[motion]</td>
</tr>
<tr class="ltx_tr" id="A1.T10.1.4">
<td class="ltx_td ltx_align_center" id="A1.T10.1.4.1">Reaction Generation</td>
<td class="ltx_td ltx_align_center" id="A1.T10.1.4.2">Generate reaction motion: [motion]</td>
<td class="ltx_td ltx_align_center" id="A1.T10.1.4.3">[motion B]</td>
</tr>
<tr class="ltx_tr" id="A1.T10.1.5">
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T10.1.5.1">Motion Prediction</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T10.1.5.2">Predict motion: [motion]</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T10.1.5.3">[Last 75%motion]</td>
</tr>
</table>
</figure>
<figure class="ltx_table" id="A1.T11">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 11: </span>Template for Instruction Tunning</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A1.T11.2" style="width:397.5pt;height:186.4pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-89.1pt,41.8pt) scale(0.690543129626863,0.690543129626863) ;">
<table class="ltx_tabular ltx_align_middle" id="A1.T11.2.2">
<tr class="ltx_tr" id="A1.T11.2.2.3">
<td class="ltx_td ltx_align_center ltx_border_tt" id="A1.T11.2.2.3.1">Task</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A1.T11.2.2.3.2">User</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A1.T11.2.2.3.3">Assistant</td>
</tr>
<tr class="ltx_tr" id="A1.T11.2.2.4">
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T11.2.2.4.1">Text-to-Motion</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T11.2.2.4.2">Demonstrate a sequence of movements that symbolizes the sentiment of [caption]</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T11.2.2.4.3">[motion]</td>
</tr>
<tr class="ltx_tr" id="A1.T11.2.2.5">
<td class="ltx_td" id="A1.T11.2.2.5.1"></td>
<td class="ltx_td ltx_align_center" id="A1.T11.2.2.5.2">Please create a motion that represents the power of [caption]</td>
<td class="ltx_td ltx_align_center" id="A1.T11.2.2.5.3">The motion is [motion]</td>
</tr>
<tr class="ltx_tr" id="A1.T11.2.2.6">
<td class="ltx_td" id="A1.T11.2.2.6.1"></td>
<td class="ltx_td ltx_align_center" id="A1.T11.2.2.6.2">I need a motion that represents the power of [caption]</td>
<td class="ltx_td ltx_align_center" id="A1.T11.2.2.6.3">Sure, [motion]</td>
</tr>
<tr class="ltx_tr" id="A1.T11.2.2.7">
<td class="ltx_td" id="A1.T11.2.2.7.1"></td>
<td class="ltx_td ltx_align_center" id="A1.T11.2.2.7.2">Show me a gesture that conveys [caption]</td>
<td class="ltx_td" id="A1.T11.2.2.7.3"></td>
</tr>
<tr class="ltx_tr" id="A1.T11.2.2.8">
<td class="ltx_td" id="A1.T11.2.2.8.1"></td>
<td class="ltx_td ltx_align_center" id="A1.T11.2.2.8.2">Produce a motion that matches [caption]</td>
<td class="ltx_td" id="A1.T11.2.2.8.3"></td>
</tr>
<tr class="ltx_tr" id="A1.T11.1.1.1">
<td class="ltx_td" id="A1.T11.1.1.1.2"></td>
<td class="ltx_td ltx_align_center" id="A1.T11.1.1.1.1"><math alttext="\cdots" class="ltx_Math" display="inline" id="A1.T11.1.1.1.1.m1.1"><semantics id="A1.T11.1.1.1.1.m1.1a"><mi id="A1.T11.1.1.1.1.m1.1.1" mathvariant="normal" xref="A1.T11.1.1.1.1.m1.1.1.cmml">⋯</mi><annotation-xml encoding="MathML-Content" id="A1.T11.1.1.1.1.m1.1b"><ci id="A1.T11.1.1.1.1.m1.1.1.cmml" xref="A1.T11.1.1.1.1.m1.1.1">⋯</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T11.1.1.1.1.m1.1c">\cdots</annotation><annotation encoding="application/x-llamapun" id="A1.T11.1.1.1.1.m1.1d">⋯</annotation></semantics></math></td>
<td class="ltx_td" id="A1.T11.1.1.1.3"></td>
</tr>
<tr class="ltx_tr" id="A1.T11.2.2.9">
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T11.2.2.9.1">Motion-to-Text</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T11.2.2.9.2">Describe the motion represented by [motion]</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T11.2.2.9.3">[caption]</td>
</tr>
<tr class="ltx_tr" id="A1.T11.2.2.10">
<td class="ltx_td" id="A1.T11.2.2.10.1"></td>
<td class="ltx_td ltx_align_center" id="A1.T11.2.2.10.2">Provide a summary of the action depicted in [motion]</td>
<td class="ltx_td" id="A1.T11.2.2.10.3"></td>
</tr>
<tr class="ltx_tr" id="A1.T11.2.2.11">
<td class="ltx_td" id="A1.T11.2.2.11.1"></td>
<td class="ltx_td ltx_align_center" id="A1.T11.2.2.11.2">Explain the motion shown in [motion]</td>
<td class="ltx_td" id="A1.T11.2.2.11.3"></td>
</tr>
<tr class="ltx_tr" id="A1.T11.2.2.12">
<td class="ltx_td" id="A1.T11.2.2.12.1"></td>
<td class="ltx_td ltx_align_center" id="A1.T11.2.2.12.2">Provide a text-based explanation of the action being shown in [motion]</td>
<td class="ltx_td" id="A1.T11.2.2.12.3"></td>
</tr>
<tr class="ltx_tr" id="A1.T11.2.2.13">
<td class="ltx_td" id="A1.T11.2.2.13.1"></td>
<td class="ltx_td ltx_align_center" id="A1.T11.2.2.13.2">Please provide a description of the motion in [motion]</td>
<td class="ltx_td" id="A1.T11.2.2.13.3"></td>
</tr>
<tr class="ltx_tr" id="A1.T11.2.2.2">
<td class="ltx_td" id="A1.T11.2.2.2.2"></td>
<td class="ltx_td ltx_align_center" id="A1.T11.2.2.2.1"><math alttext="\cdots" class="ltx_Math" display="inline" id="A1.T11.2.2.2.1.m1.1"><semantics id="A1.T11.2.2.2.1.m1.1a"><mi id="A1.T11.2.2.2.1.m1.1.1" mathvariant="normal" xref="A1.T11.2.2.2.1.m1.1.1.cmml">⋯</mi><annotation-xml encoding="MathML-Content" id="A1.T11.2.2.2.1.m1.1b"><ci id="A1.T11.2.2.2.1.m1.1.1.cmml" xref="A1.T11.2.2.2.1.m1.1.1">⋯</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T11.2.2.2.1.m1.1c">\cdots</annotation><annotation encoding="application/x-llamapun" id="A1.T11.2.2.2.1.m1.1d">⋯</annotation></semantics></math></td>
<td class="ltx_td" id="A1.T11.2.2.2.3"></td>
</tr>
<tr class="ltx_tr" id="A1.T11.2.2.14">
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T11.2.2.14.1">Motion Prediction</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T11.2.2.14.2">Predict motion: [first 25%motion]</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T11.2.2.14.3">[Last 75%motion]</td>
</tr>
<tr class="ltx_tr" id="A1.T11.2.2.15">
<td class="ltx_td ltx_border_bb" id="A1.T11.2.2.15.1"></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T11.2.2.15.2">Do the motion prediction task for [first 25%motion]</td>
<td class="ltx_td ltx_border_bb" id="A1.T11.2.2.15.3"></td>
</tr>
</table>
</span></div>
</figure>
<div class="ltx_para ltx_noindent" id="A1.SS9.p1">
<p class="ltx_p" id="A1.SS9.p1.1">We will detail the template forms utilized during the pre-training and instruction-tuning stages of our model development. Tables <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#A1.T10" title="Table 10 ‣ A.9 Template Forms for Pre-training and Instruction Tuning ‣ Appendix A Appendix ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_tag">10</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#A1.T11" title="Table 11 ‣ A.9 Template Forms for Pre-training and Instruction Tuning ‣ Appendix A Appendix ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_tag">11</span></a> illustrate the specific formats employed in each stage, providing a structured approach to aligning motion data with textual descriptions and enhancing the model’s interactive capabilities. All the templates are from MotionGPT <cite class="ltx_cite ltx_citemacro_citep">(Jiang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib18" title="">2023</a>)</cite>.</p>
</div>
<section class="ltx_paragraph" id="A1.SS9.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Pre-training Templates</h5>
<div class="ltx_para ltx_noindent" id="A1.SS9.SSS0.Px1.p1">
<p class="ltx_p" id="A1.SS9.SSS0.Px1.p1.1">During the pre-training stage, our objective is to align motion and language representations by leveraging large language models (LLMs). We design tasks such as Text-to-Motion, Motion-to-Text, Reaction Generation, and Motion Prediction using paired datasets like InterX <cite class="ltx_cite ltx_citemacro_cite">Xu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib40" title="">2024a</a>)</cite> and Interhuman <cite class="ltx_cite ltx_citemacro_cite">Liang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib22" title="">2024</a>)</cite>. The pre-training templates involve generating captions from motion sequences, creating motions based on textual descriptions, producing reaction motions in response to initial motions, and predicting subsequent motions from partial sequences, as summarized in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#A1.T10" title="Table 10 ‣ A.9 Template Forms for Pre-training and Instruction Tuning ‣ Appendix A Appendix ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_tag">10</span></a>. For single-person motion, we utilized text-to-motion, motion-to-text and motion prediction task during training.</p>
</div>
</section>
<section class="ltx_paragraph" id="A1.SS9.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">Instruction-Tuning Templates</h5>
<div class="ltx_para ltx_noindent" id="A1.SS9.SSS0.Px2.p1">
<p class="ltx_p" id="A1.SS9.SSS0.Px2.p1.1">In the instruction-tuning stage, we enhance the model’s ability to follow diverse instructions presented in a conversational format. Utilizing the INTER2-MT dataset alongside single-turn data from previous interactive motion datasets, we format user instructions and assistant responses to facilitate multi-turn interactions. Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#A1.T11" title="Table 11 ‣ A.9 Template Forms for Pre-training and Instruction Tuning ‣ Appendix A Appendix ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_tag">11</span></a> outlines the templates used for tasks such as generating motions from user prompts, describing motions based on user queries, and predicting motion continuations. By structuring the interactions in this manner, the model becomes adept at understanding and responding to various motion-related commands, thereby improving its performance in interactive scenarios.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="A1.SS10">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.10 </span>Implementation Details</h3>
<div class="ltx_para ltx_noindent" id="A1.SS10.p1">
<p class="ltx_p" id="A1.SS10.p1.9">We set the codebook of the motion tokenizer as <math alttext="K\in R^{512\times 512}" class="ltx_Math" display="inline" id="A1.SS10.p1.1.m1.1"><semantics id="A1.SS10.p1.1.m1.1a"><mrow id="A1.SS10.p1.1.m1.1.1" xref="A1.SS10.p1.1.m1.1.1.cmml"><mi id="A1.SS10.p1.1.m1.1.1.2" xref="A1.SS10.p1.1.m1.1.1.2.cmml">K</mi><mo id="A1.SS10.p1.1.m1.1.1.1" xref="A1.SS10.p1.1.m1.1.1.1.cmml">∈</mo><msup id="A1.SS10.p1.1.m1.1.1.3" xref="A1.SS10.p1.1.m1.1.1.3.cmml"><mi id="A1.SS10.p1.1.m1.1.1.3.2" xref="A1.SS10.p1.1.m1.1.1.3.2.cmml">R</mi><mrow id="A1.SS10.p1.1.m1.1.1.3.3" xref="A1.SS10.p1.1.m1.1.1.3.3.cmml"><mn id="A1.SS10.p1.1.m1.1.1.3.3.2" xref="A1.SS10.p1.1.m1.1.1.3.3.2.cmml">512</mn><mo id="A1.SS10.p1.1.m1.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="A1.SS10.p1.1.m1.1.1.3.3.1.cmml">×</mo><mn id="A1.SS10.p1.1.m1.1.1.3.3.3" xref="A1.SS10.p1.1.m1.1.1.3.3.3.cmml">512</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="A1.SS10.p1.1.m1.1b"><apply id="A1.SS10.p1.1.m1.1.1.cmml" xref="A1.SS10.p1.1.m1.1.1"><in id="A1.SS10.p1.1.m1.1.1.1.cmml" xref="A1.SS10.p1.1.m1.1.1.1"></in><ci id="A1.SS10.p1.1.m1.1.1.2.cmml" xref="A1.SS10.p1.1.m1.1.1.2">𝐾</ci><apply id="A1.SS10.p1.1.m1.1.1.3.cmml" xref="A1.SS10.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="A1.SS10.p1.1.m1.1.1.3.1.cmml" xref="A1.SS10.p1.1.m1.1.1.3">superscript</csymbol><ci id="A1.SS10.p1.1.m1.1.1.3.2.cmml" xref="A1.SS10.p1.1.m1.1.1.3.2">𝑅</ci><apply id="A1.SS10.p1.1.m1.1.1.3.3.cmml" xref="A1.SS10.p1.1.m1.1.1.3.3"><times id="A1.SS10.p1.1.m1.1.1.3.3.1.cmml" xref="A1.SS10.p1.1.m1.1.1.3.3.1"></times><cn id="A1.SS10.p1.1.m1.1.1.3.3.2.cmml" type="integer" xref="A1.SS10.p1.1.m1.1.1.3.3.2">512</cn><cn id="A1.SS10.p1.1.m1.1.1.3.3.3.cmml" type="integer" xref="A1.SS10.p1.1.m1.1.1.3.3.3">512</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS10.p1.1.m1.1c">K\in R^{512\times 512}</annotation><annotation encoding="application/x-llamapun" id="A1.SS10.p1.1.m1.1d">italic_K ∈ italic_R start_POSTSUPERSCRIPT 512 × 512 end_POSTSUPERSCRIPT</annotation></semantics></math> for most
comparisons, with residual depth <math alttext="4" class="ltx_Math" display="inline" id="A1.SS10.p1.2.m2.1"><semantics id="A1.SS10.p1.2.m2.1a"><mn id="A1.SS10.p1.2.m2.1.1" xref="A1.SS10.p1.2.m2.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="A1.SS10.p1.2.m2.1b"><cn id="A1.SS10.p1.2.m2.1.1.cmml" type="integer" xref="A1.SS10.p1.2.m2.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS10.p1.2.m2.1c">4</annotation><annotation encoding="application/x-llamapun" id="A1.SS10.p1.2.m2.1d">4</annotation></semantics></math>. The motion encoder <math alttext="\mathcal{E}" class="ltx_Math" display="inline" id="A1.SS10.p1.3.m3.1"><semantics id="A1.SS10.p1.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="A1.SS10.p1.3.m3.1.1" xref="A1.SS10.p1.3.m3.1.1.cmml">ℰ</mi><annotation-xml encoding="MathML-Content" id="A1.SS10.p1.3.m3.1b"><ci id="A1.SS10.p1.3.m3.1.1.cmml" xref="A1.SS10.p1.3.m3.1.1">ℰ</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS10.p1.3.m3.1c">\mathcal{E}</annotation><annotation encoding="application/x-llamapun" id="A1.SS10.p1.3.m3.1d">caligraphic_E</annotation></semantics></math> incorporates a temporal downsampling rate <math alttext="l" class="ltx_Math" display="inline" id="A1.SS10.p1.4.m4.1"><semantics id="A1.SS10.p1.4.m4.1a"><mi id="A1.SS10.p1.4.m4.1.1" xref="A1.SS10.p1.4.m4.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="A1.SS10.p1.4.m4.1b"><ci id="A1.SS10.p1.4.m4.1.1.cmml" xref="A1.SS10.p1.4.m4.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS10.p1.4.m4.1c">l</annotation><annotation encoding="application/x-llamapun" id="A1.SS10.p1.4.m4.1d">italic_l</annotation></semantics></math> of 4. We utilize LLaMA-3.1-8B <cite class="ltx_cite ltx_citemacro_cite">Dubey et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib9" title="">2024</a>)</cite> as the underlying architecture for our language model. During the pertaining, we train the large language model (LLM) using a low-rank adaptor (LoRA) <cite class="ltx_cite ltx_citemacro_citep">(Hu et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib17" title="">2022</a>)</cite>, including the embedding layer and the decoder head. The rank was set as <math alttext="r=8" class="ltx_Math" display="inline" id="A1.SS10.p1.5.m5.1"><semantics id="A1.SS10.p1.5.m5.1a"><mrow id="A1.SS10.p1.5.m5.1.1" xref="A1.SS10.p1.5.m5.1.1.cmml"><mi id="A1.SS10.p1.5.m5.1.1.2" xref="A1.SS10.p1.5.m5.1.1.2.cmml">r</mi><mo id="A1.SS10.p1.5.m5.1.1.1" xref="A1.SS10.p1.5.m5.1.1.1.cmml">=</mo><mn id="A1.SS10.p1.5.m5.1.1.3" xref="A1.SS10.p1.5.m5.1.1.3.cmml">8</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS10.p1.5.m5.1b"><apply id="A1.SS10.p1.5.m5.1.1.cmml" xref="A1.SS10.p1.5.m5.1.1"><eq id="A1.SS10.p1.5.m5.1.1.1.cmml" xref="A1.SS10.p1.5.m5.1.1.1"></eq><ci id="A1.SS10.p1.5.m5.1.1.2.cmml" xref="A1.SS10.p1.5.m5.1.1.2">𝑟</ci><cn id="A1.SS10.p1.5.m5.1.1.3.cmml" type="integer" xref="A1.SS10.p1.5.m5.1.1.3">8</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS10.p1.5.m5.1c">r=8</annotation><annotation encoding="application/x-llamapun" id="A1.SS10.p1.5.m5.1d">italic_r = 8</annotation></semantics></math>, <math alttext="\alpha=16" class="ltx_Math" display="inline" id="A1.SS10.p1.6.m6.1"><semantics id="A1.SS10.p1.6.m6.1a"><mrow id="A1.SS10.p1.6.m6.1.1" xref="A1.SS10.p1.6.m6.1.1.cmml"><mi id="A1.SS10.p1.6.m6.1.1.2" xref="A1.SS10.p1.6.m6.1.1.2.cmml">α</mi><mo id="A1.SS10.p1.6.m6.1.1.1" xref="A1.SS10.p1.6.m6.1.1.1.cmml">=</mo><mn id="A1.SS10.p1.6.m6.1.1.3" xref="A1.SS10.p1.6.m6.1.1.3.cmml">16</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS10.p1.6.m6.1b"><apply id="A1.SS10.p1.6.m6.1.1.cmml" xref="A1.SS10.p1.6.m6.1.1"><eq id="A1.SS10.p1.6.m6.1.1.1.cmml" xref="A1.SS10.p1.6.m6.1.1.1"></eq><ci id="A1.SS10.p1.6.m6.1.1.2.cmml" xref="A1.SS10.p1.6.m6.1.1.2">𝛼</ci><cn id="A1.SS10.p1.6.m6.1.1.3.cmml" type="integer" xref="A1.SS10.p1.6.m6.1.1.3">16</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS10.p1.6.m6.1c">\alpha=16</annotation><annotation encoding="application/x-llamapun" id="A1.SS10.p1.6.m6.1d">italic_α = 16</annotation></semantics></math>, with the dropout rate set as <math alttext="0.05" class="ltx_Math" display="inline" id="A1.SS10.p1.7.m7.1"><semantics id="A1.SS10.p1.7.m7.1a"><mn id="A1.SS10.p1.7.m7.1.1" xref="A1.SS10.p1.7.m7.1.1.cmml">0.05</mn><annotation-xml encoding="MathML-Content" id="A1.SS10.p1.7.m7.1b"><cn id="A1.SS10.p1.7.m7.1.1.cmml" type="float" xref="A1.SS10.p1.7.m7.1.1">0.05</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS10.p1.7.m7.1c">0.05</annotation><annotation encoding="application/x-llamapun" id="A1.SS10.p1.7.m7.1d">0.05</annotation></semantics></math>. During the instruction fine-tuning stage, we trained all the parameters. The learning rate was set as <math alttext="0.0001" class="ltx_Math" display="inline" id="A1.SS10.p1.8.m8.1"><semantics id="A1.SS10.p1.8.m8.1a"><mn id="A1.SS10.p1.8.m8.1.1" xref="A1.SS10.p1.8.m8.1.1.cmml">0.0001</mn><annotation-xml encoding="MathML-Content" id="A1.SS10.p1.8.m8.1b"><cn id="A1.SS10.p1.8.m8.1.1.cmml" type="float" xref="A1.SS10.p1.8.m8.1.1">0.0001</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS10.p1.8.m8.1c">0.0001</annotation><annotation encoding="application/x-llamapun" id="A1.SS10.p1.8.m8.1d">0.0001</annotation></semantics></math>, and the warm-up ratio as <math alttext="0.01" class="ltx_Math" display="inline" id="A1.SS10.p1.9.m9.1"><semantics id="A1.SS10.p1.9.m9.1a"><mn id="A1.SS10.p1.9.m9.1.1" xref="A1.SS10.p1.9.m9.1.1.cmml">0.01</mn><annotation-xml encoding="MathML-Content" id="A1.SS10.p1.9.m9.1b"><cn id="A1.SS10.p1.9.m9.1.1.cmml" type="float" xref="A1.SS10.p1.9.m9.1.1">0.01</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS10.p1.9.m9.1c">0.01</annotation><annotation encoding="application/x-llamapun" id="A1.SS10.p1.9.m9.1d">0.01</annotation></semantics></math>, the learning rate scheduler with cosine decay, and the AdamW optimizer.</p>
</div>
</section>
<section class="ltx_subsection" id="A1.SS11">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.11 </span>More details about Evaluation Metric for Traditional Motion Related Tasks</h3>
<section class="ltx_paragraph" id="A1.SS11.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Motion Quality</h5>
<div class="ltx_para ltx_noindent" id="A1.SS11.SSS0.Px1.p1">
<p class="ltx_p" id="A1.SS11.SSS0.Px1.p1.1">The Frechet Inception Distance (FID) is used to assess the similarity between the distributions of generated and real motions, utilizing an appropriate feature extractor tailored to each dataset. In addition, we use well-known motion capture metrics, MPJPE to quantify global and local errors in meters.</p>
</div>
</section>
<section class="ltx_paragraph" id="A1.SS11.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">Motion Diversity</h5>
<div class="ltx_para ltx_noindent" id="A1.SS11.SSS0.Px2.p1">
<p class="ltx_p" id="A1.SS11.SSS0.Px2.p1.1">We have utilized diversity to evaluate the diversity of the motion following previous work <cite class="ltx_cite ltx_citemacro_citep">(Jiang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib18" title="">2023</a>; Petrovich et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib30" title="">2023</a>)</cite>.
To evaluate Diversity, the generated motions are split into two equal-sized subsets, and the Diversity metric is calculated as the average distance between motions within these subsets.</p>
</div>
</section>
<section class="ltx_paragraph" id="A1.SS11.SSS0.Px3">
<h5 class="ltx_title ltx_title_paragraph">Condition Matching</h5>
<div class="ltx_para ltx_noindent" id="A1.SS11.SSS0.Px3.p1">
<p class="ltx_p" id="A1.SS11.SSS0.Px3.p1.1">TMR <cite class="ltx_cite ltx_citemacro_citep">(Petrovich et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib30" title="">2023</a>)</cite> offers motion/text feature extractors that produce geometrically coherent features for aligned text-motion pairs and vice versa. In this feature space, we evaluate motion-retrieval precision (R Precision) by combining the generated motion with 31 mismatched motions and calculating the top-1/2/3 matching accuracy between the text and motion. Furthermore, we assess the Multi-modal Distance (MM Dist), which measures the distance between the generated motions and their corresponding text.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="A1.SS12">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.12 </span>User Subject Studies Protocols for motion editing</h3>
<div class="ltx_para ltx_noindent" id="A1.SS12.p1">
<p class="ltx_p" id="A1.SS12.p1.1">We conducted user subject studies using the platform on the Mechanical Turk service from AWS <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib3" title="">AWS, </a>)</cite>.</p>
</div>
<section class="ltx_subsubsection" id="A1.SS12.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">A.12.1 </span>Instructions</h4>
<div class="ltx_para" id="A1.SS12.SSS1.p1">
<p class="ltx_p" id="A1.SS12.SSS1.p1.1">The summary given to the user is as follows:</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS12.SSS1.p2">
<p class="ltx_p" id="A1.SS12.SSS1.p2.1"><span class="ltx_text" id="A1.SS12.SSS1.p2.1.1">
<span class="ltx_inline-block ltx_minipage ltx_align_middle" id="A1.SS12.SSS1.p2.1.1.1" style="width:389.5pt;background-color:#E6E6E6;">
<span class="ltx_p" id="A1.SS12.SSS1.p2.1.1.1.1"><span class="ltx_text ltx_font_sansserif" id="A1.SS12.SSS1.p2.1.1.1.1.1" style="color:#808080;">We are conducting an academic survey about the quality of generated motions.
We need to understand your opinion about the motion quality and ability to follow the editing commands.
Please evaluate each motions based on the given criteria.</span></span>
<span class="ltx_p" id="A1.SS12.SSS1.p2.1.1.1.2"><span class="ltx_text ltx_font_sansserif" id="A1.SS12.SSS1.p2.1.1.1.2.1" style="color:#808080;">You will be presented with multiple instruction samples.
After completing the evaluations on each page, click ”Next” to proceed.
On the last page, click ”Submit” to complete the survey.</span></span>
</span></span></p>
</div>
<div class="ltx_para" id="A1.SS12.SSS1.p3">
<p class="ltx_p" id="A1.SS12.SSS1.p3.1">The detailed instruction is as follows:</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS12.SSS1.p4">
<p class="ltx_p" id="A1.SS12.SSS1.p4.1"><span class="ltx_text" id="A1.SS12.SSS1.p4.1.1">
<span class="ltx_inline-block ltx_minipage ltx_align_middle" id="A1.SS12.SSS1.p4.1.1.1" style="width:389.5pt;background-color:#E6E6E6;">
<span class="ltx_p" id="A1.SS12.SSS1.p4.1.1.1.1"><span class="ltx_text ltx_font_sansserif" id="A1.SS12.SSS1.p4.1.1.1.1.1" style="color:#808080;">Objective:
We are conducting a survey to evaluate how well AI-generated motions follow given instructions and how natural they appear. Your feedback is important to help us improve the AI’s ability to create realistic movements that match specific editing commands.</span></span>
<span class="ltx_p" id="A1.SS12.SSS1.p4.1.1.1.2"><span class="ltx_text ltx_font_sansserif" id="A1.SS12.SSS1.p4.1.1.1.2.1" style="color:#808080;">Survey Overview:
You will be shown a source motion and an edited motion. Your task is to evaluate both based on specific criteria. After evaluating a few examples, you will also rate multiple edited motions generated from the same source motion using different methods. The survey is divided into multiple pages, and you can move through the pages using ”Next” or ”Previous” buttons. You must complete all fields on each page before proceeding.</span></span>
<span class="ltx_p" id="A1.SS12.SSS1.p4.1.1.1.3"><span class="ltx_text ltx_font_sansserif" id="A1.SS12.SSS1.p4.1.1.1.3.1" style="color:#808080;">Evaluation Criteria:
For each pair of videos (source and edited), you will be asked to rate them based on:</span></span>
<span class="ltx_p" id="A1.SS12.SSS1.p4.1.1.1.4"><span class="ltx_text ltx_font_sansserif" id="A1.SS12.SSS1.p4.1.1.1.4.1" style="color:#808080;">Content Similarity:
Does the edited motion stay true to the original motion?
Rating scale: 1 (Strongly Disagree) to 5 (Strongly Agree)</span></span>
<span class="ltx_p" id="A1.SS12.SSS1.p4.1.1.1.5"><span class="ltx_text ltx_font_sansserif" id="A1.SS12.SSS1.p4.1.1.1.5.1" style="color:#808080;">Alignment with Instruction:
Does the edited motion follow the instructions given?
Rating scale: 1 (Strongly Disagree) to 5 (Strongly Agree)</span></span>
<span class="ltx_p" id="A1.SS12.SSS1.p4.1.1.1.6"><span class="ltx_text ltx_font_sansserif" id="A1.SS12.SSS1.p4.1.1.1.6.1" style="color:#808080;">Motion Quality:
Is the quality of the edited motion good, and does it look natural?
Rating scale: 1 (Strongly Disagree) to 5 (Strongly Agree)</span></span>
<span class="ltx_p" id="A1.SS12.SSS1.p4.1.1.1.7"><span class="ltx_text ltx_font_sansserif" id="A1.SS12.SSS1.p4.1.1.1.7.1" style="color:#808080;">Survey Structure:</span></span>
<span class="ltx_p" id="A1.SS12.SSS1.p4.1.1.1.8"><span class="ltx_text ltx_font_sansserif" id="A1.SS12.SSS1.p4.1.1.1.8.1" style="color:#808080;">Evaluation of Pre-selected Motion Examples:
In the first section, you will review hand-picked video pairs. Each page will show a source video and its edited version. You will rate how similar they are, how well the editing follows instructions and the overall quality of the motion.</span></span>
<span class="ltx_p" id="A1.SS12.SSS1.p4.1.1.1.9"><span class="ltx_text ltx_font_sansserif" id="A1.SS12.SSS1.p4.1.1.1.9.1" style="color:#808080;">Evaluation of Randomly Selected Motion Samples:
In the second section, you will see five different edited motions for each scenario. These motions are created using different methods. You will rate each one based on content similarity, alignment with instructions, and motion quality.</span></span>
<span class="ltx_p" id="A1.SS12.SSS1.p4.1.1.1.10"><span class="ltx_text ltx_font_sansserif" id="A1.SS12.SSS1.p4.1.1.1.10.1" style="color:#808080;">Instructions:</span></span>
<span class="ltx_p" id="A1.SS12.SSS1.p4.1.1.1.11"><span class="ltx_text ltx_font_sansserif" id="A1.SS12.SSS1.p4.1.1.1.11.1" style="color:#808080;">Review the motion examples:
Each page will show a description, editing instruction, and two videos (source and edited). Watch the videos and rate them using radio buttons based on the three criteria. Click ”Next” to move to the next example.</span></span>
<span class="ltx_p" id="A1.SS12.SSS1.p4.1.1.1.12"><span class="ltx_text ltx_font_sansserif" id="A1.SS12.SSS1.p4.1.1.1.12.1" style="color:#808080;">Evaluate random scenarios:
You will be shown five edited motions per scenario. Review and rate them on the same criteria as before. Use ”Next” and ”Previous” to navigate.</span></span>
<span class="ltx_p" id="A1.SS12.SSS1.p4.1.1.1.13"><span class="ltx_text ltx_font_sansserif" id="A1.SS12.SSS1.p4.1.1.1.13.1" style="color:#808080;">Completion:
Once all evaluations are finished, click ”Submit” to complete the survey.</span></span>
<span class="ltx_p" id="A1.SS12.SSS1.p4.1.1.1.14"><span class="ltx_text ltx_font_sansserif" id="A1.SS12.SSS1.p4.1.1.1.14.1" style="color:#808080;">Tips:</span></span>
<span class="ltx_p" id="A1.SS12.SSS1.p4.1.1.1.15"><span class="ltx_text ltx_font_sansserif" id="A1.SS12.SSS1.p4.1.1.1.15.1" style="color:#808080;">Watch both videos completely before deciding.
If you’re unsure, select ”Neutral.”
All fields must be filled before you can move forward or submit the survey.</span></span>
</span></span></p>
</div>
<div class="ltx_para" id="A1.SS12.SSS1.p5">
<p class="ltx_p" id="A1.SS12.SSS1.p5.1">The examples of ratings given to the user are shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#A1.F13" title="Figure 13 ‣ A.12.1 Instructions ‣ A.12 User Subject Studies Protocols for motion editing ‣ Appendix A Appendix ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_tag">13</span></a>.</p>
</div>
<figure class="ltx_figure" id="A1.F13"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="356" id="A1.F13.g1" src="extracted/5925138/figures/user_ex.png" width="479"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 13: </span>The examples of ratings given to the user</figcaption>
</figure>
</section>
<section class="ltx_subsubsection" id="A1.SS12.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">A.12.2 </span>Qualifying test</h4>
<div class="ltx_para ltx_noindent" id="A1.SS12.SSS2.p1">
<p class="ltx_p" id="A1.SS12.SSS2.p1.1">Before participating in the main user studies, all participants must pass a qualifying test to ensure they understand the evaluation criteria. In this test, participants are asked to assess four samples based on three metrics: Content Alignment, Fidelity of Motion, and Quality of Motion. Among the four samples, two are high-quality and derived from the ground-truth dataset, while the other two are low-quality—one is a mismatched motion with a single instruction, and the other is generated by the least effective model, MotionGPT<sup class="ltx_sup" id="A1.SS12.SSS2.p1.1.1">∗</sup>. Participants must rate the low-quality samples lower than the high-quality ones in each of the three metrics. If any of the low-quality samples receive ratings that are equal to or higher than the high-quality samples in Content Alignment, Fidelity, or Quality of Motion, the participant will receive an error message and will need to adjust their ratings accordingly. This ensures that only participants who can accurately distinguish between high and low-quality motions based on the defined metrics proceed to the main study. The example of the qualifying test is demonstrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#A1.F14" title="Figure 14 ‣ A.12.2 Qualifying test ‣ A.12 User Subject Studies Protocols for motion editing ‣ Appendix A Appendix ‣ Versatile Motion-Language Models for Multi-turn Interactive Agents"><span class="ltx_text ltx_ref_tag">14</span></a></p>
</div>
<figure class="ltx_figure" id="A1.F14"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="385" id="A1.F14.g1" src="extracted/5925138/figures/user_pre.png" width="538"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 14: </span>Qualifying test in user subject studies</figcaption>
</figure>
</section>
<section class="ltx_subsubsection" id="A1.SS12.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">A.12.3 </span>Detailed Survey Format</h4>
<figure class="ltx_figure" id="A1.F15"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="385" id="A1.F15.g1" src="extracted/5925138/figures/user_2.png" width="538"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 15: </span>Caption</figcaption>
</figure>
<section class="ltx_paragraph" id="A1.SS12.SSS3.Px1">
<h5 class="ltx_title ltx_title_paragraph">Main Survey Structure</h5>
<div class="ltx_para ltx_noindent" id="A1.SS12.SSS3.Px1.p1">
<p class="ltx_p" id="A1.SS12.SSS3.Px1.p1.4">In the main survey, each participant was randomly assigned 5 samples from a larger pool of 30 diverse motion sequences. This random sampling strategy was employed to ensure a broad and representative evaluation, minimizing any potential selection bias. For each of these selected samples, participants were asked to evaluate five baseline methods, including our proposed model (VIM), VIM w/o <span class="ltx_text ltx_markedasmath ltx_font_smallcaps" id="A1.SS12.SSS3.Px1.p1.4.2">Inter</span><span class="ltx_text ltx_font_smallcaps" id="A1.SS12.SSS3.Px1.p1.2.1">-<math alttext="\text{MT}^{2}" class="ltx_Math" display="inline" id="A1.SS12.SSS3.Px1.p1.2.1.m1.1"><semantics id="A1.SS12.SSS3.Px1.p1.2.1.m1.1a"><msup id="A1.SS12.SSS3.Px1.p1.2.1.m1.1.1" xref="A1.SS12.SSS3.Px1.p1.2.1.m1.1.1.cmml"><mtext class="ltx_font_smallcaps" id="A1.SS12.SSS3.Px1.p1.2.1.m1.1.1.2" xref="A1.SS12.SSS3.Px1.p1.2.1.m1.1.1.2a.cmml">MT</mtext><mn id="A1.SS12.SSS3.Px1.p1.2.1.m1.1.1.3" xref="A1.SS12.SSS3.Px1.p1.2.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="A1.SS12.SSS3.Px1.p1.2.1.m1.1b"><apply id="A1.SS12.SSS3.Px1.p1.2.1.m1.1.1.cmml" xref="A1.SS12.SSS3.Px1.p1.2.1.m1.1.1"><csymbol cd="ambiguous" id="A1.SS12.SSS3.Px1.p1.2.1.m1.1.1.1.cmml" xref="A1.SS12.SSS3.Px1.p1.2.1.m1.1.1">superscript</csymbol><ci id="A1.SS12.SSS3.Px1.p1.2.1.m1.1.1.2a.cmml" xref="A1.SS12.SSS3.Px1.p1.2.1.m1.1.1.2"><mtext class="ltx_font_smallcaps" id="A1.SS12.SSS3.Px1.p1.2.1.m1.1.1.2.cmml" xref="A1.SS12.SSS3.Px1.p1.2.1.m1.1.1.2">MT</mtext></ci><cn id="A1.SS12.SSS3.Px1.p1.2.1.m1.1.1.3.cmml" type="integer" xref="A1.SS12.SSS3.Px1.p1.2.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS12.SSS3.Px1.p1.2.1.m1.1c">\text{MT}^{2}</annotation><annotation encoding="application/x-llamapun" id="A1.SS12.SSS3.Px1.p1.2.1.m1.1d">MT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math></span>, MotionGPT<sup class="ltx_sup" id="A1.SS12.SSS3.Px1.p1.4.3">∗</sup>, MotionGPT<math alttext="{}^{*}_{I}" class="ltx_Math" display="inline" id="A1.SS12.SSS3.Px1.p1.4.m3.1"><semantics id="A1.SS12.SSS3.Px1.p1.4.m3.1a"><mmultiscripts id="A1.SS12.SSS3.Px1.p1.4.m3.1.1" xref="A1.SS12.SSS3.Px1.p1.4.m3.1.1.cmml"><mi id="A1.SS12.SSS3.Px1.p1.4.m3.1.1.2.2" xref="A1.SS12.SSS3.Px1.p1.4.m3.1.1.2.2.cmml"></mi><mprescripts id="A1.SS12.SSS3.Px1.p1.4.m3.1.1a" xref="A1.SS12.SSS3.Px1.p1.4.m3.1.1.cmml"></mprescripts><mi id="A1.SS12.SSS3.Px1.p1.4.m3.1.1.3" xref="A1.SS12.SSS3.Px1.p1.4.m3.1.1.3.cmml">I</mi><mrow id="A1.SS12.SSS3.Px1.p1.4.m3.1.1b" xref="A1.SS12.SSS3.Px1.p1.4.m3.1.1.cmml"></mrow><mrow id="A1.SS12.SSS3.Px1.p1.4.m3.1.1c" xref="A1.SS12.SSS3.Px1.p1.4.m3.1.1.cmml"></mrow><mo id="A1.SS12.SSS3.Px1.p1.4.m3.1.1.2.3" xref="A1.SS12.SSS3.Px1.p1.4.m3.1.1.2.3.cmml">∗</mo></mmultiscripts><annotation-xml encoding="MathML-Content" id="A1.SS12.SSS3.Px1.p1.4.m3.1b"><apply id="A1.SS12.SSS3.Px1.p1.4.m3.1.1.cmml" xref="A1.SS12.SSS3.Px1.p1.4.m3.1.1"><csymbol cd="ambiguous" id="A1.SS12.SSS3.Px1.p1.4.m3.1.1.1.cmml" xref="A1.SS12.SSS3.Px1.p1.4.m3.1.1">subscript</csymbol><apply id="A1.SS12.SSS3.Px1.p1.4.m3.1.1.2.cmml" xref="A1.SS12.SSS3.Px1.p1.4.m3.1.1"><csymbol cd="ambiguous" id="A1.SS12.SSS3.Px1.p1.4.m3.1.1.2.1.cmml" xref="A1.SS12.SSS3.Px1.p1.4.m3.1.1">superscript</csymbol><csymbol cd="latexml" id="A1.SS12.SSS3.Px1.p1.4.m3.1.1.2.2.cmml" xref="A1.SS12.SSS3.Px1.p1.4.m3.1.1.2.2">absent</csymbol><times id="A1.SS12.SSS3.Px1.p1.4.m3.1.1.2.3.cmml" xref="A1.SS12.SSS3.Px1.p1.4.m3.1.1.2.3"></times></apply><ci id="A1.SS12.SSS3.Px1.p1.4.m3.1.1.3.cmml" xref="A1.SS12.SSS3.Px1.p1.4.m3.1.1.3">𝐼</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS12.SSS3.Px1.p1.4.m3.1c">{}^{*}_{I}</annotation><annotation encoding="application/x-llamapun" id="A1.SS12.SSS3.Px1.p1.4.m3.1d">start_FLOATSUPERSCRIPT ∗ end_FLOATSUPERSCRIPT start_POSTSUBSCRIPT italic_I end_POSTSUBSCRIPT</annotation></semantics></math>, and two-stage model based on TM2T <cite class="ltx_cite ltx_citemacro_citep">(Guo et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib14" title="">2022</a>)</cite> and InterGEN <cite class="ltx_cite ltx_citemacro_citep">(Liang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib22" title="">2024</a>)</cite>.
To eliminate ordering effects and ensure that the evaluation was solely based on the quality of the motions rather than their presentation order, the order of the baseline methods was randomly shuffled for each participant. This randomization was crucial in preventing any unintended bias that might arise from the sequence in which the methods were presented.</p>
</div>
</section>
<section class="ltx_paragraph" id="A1.SS12.SSS3.Px2">
<h5 class="ltx_title ltx_title_paragraph">Evaluation Metrics</h5>
<div class="ltx_para ltx_noindent" id="A1.SS12.SSS3.Px2.p1">
<p class="ltx_p" id="A1.SS12.SSS3.Px2.p1.1">Participants assessed each motion sample using three evaluation metrics, which provided a multidimensional view of each model’s performance:</p>
<ul class="ltx_itemize" id="A1.I1">
<li class="ltx_item" id="A1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i1.p1">
<p class="ltx_p" id="A1.I1.i1.p1.1">Content Similarity: The edited motion is still maintaining the original content.</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i2.p1">
<p class="ltx_p" id="A1.I1.i2.p1.1">Alignment with Instruction: The edited motion is following the editing command properly.</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="A1.I1.i3.p1">
<p class="ltx_p" id="A1.I1.i3.p1.1">Motion Quality: The quality of the generated motion is good, and the motion seems natural The motion is fluid without any noises in there.</p>
</div>
</li>
</ul>
<p class="ltx_p" id="A1.SS12.SSS3.Px2.p1.2">We leveraged a 5-scale Likert scale, 1 from strongly disagree to 5 for strongly agree.</p>
</div>
</section>
<section class="ltx_paragraph" id="A1.SS12.SSS3.Px3">
<h5 class="ltx_title ltx_title_paragraph">Exclusion Criteria</h5>
<div class="ltx_para ltx_noindent" id="A1.SS12.SSS3.Px3.p1">
<p class="ltx_p" id="A1.SS12.SSS3.Px3.p1.1">To maintain high data quality and ensure meaningful results, we implemented strict exclusion criteria. Participants who assigned the same rating across all evaluation metrics for every sample were excluded, as such uniformity indicated a lack of genuine engagement or understanding of the evaluation process. Additionally, those who provided identical ratings across all comparison methods for a given sample were also omitted. This approach ensured that only participants who thoughtfully differentiated between the methods based on their performance were included in the final analysis. These exclusion rules were essential in filtering out unreliable data and ensuring that the survey results accurately reflected the participants’ true assessments of each model’s performance.</p>
</div>
</section>
</section>
</section>
<section class="ltx_subsection" id="A1.SS13">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.13 </span>Prompts for Data collection in <span class="ltx_text ltx_markedasmath ltx_font_smallcaps" id="A1.SS13.3.2">Inter</span><span class="ltx_text ltx_font_smallcaps" id="A1.SS13.2.1">-<math alttext="\text{MT}^{2}" class="ltx_Math" display="inline" id="A1.SS13.2.1.m1.1"><semantics id="A1.SS13.2.1.m1.1b"><msup id="A1.SS13.2.1.m1.1.1" xref="A1.SS13.2.1.m1.1.1.cmml"><mtext class="ltx_font_smallcaps" id="A1.SS13.2.1.m1.1.1.2" xref="A1.SS13.2.1.m1.1.1.2a.cmml">MT</mtext><mn id="A1.SS13.2.1.m1.1.1.3" xref="A1.SS13.2.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="A1.SS13.2.1.m1.1c"><apply id="A1.SS13.2.1.m1.1.1.cmml" xref="A1.SS13.2.1.m1.1.1"><csymbol cd="ambiguous" id="A1.SS13.2.1.m1.1.1.1.cmml" xref="A1.SS13.2.1.m1.1.1">superscript</csymbol><ci id="A1.SS13.2.1.m1.1.1.2a.cmml" xref="A1.SS13.2.1.m1.1.1.2"><mtext class="ltx_font_smallcaps" id="A1.SS13.2.1.m1.1.1.2.cmml" xref="A1.SS13.2.1.m1.1.1.2">MT</mtext></ci><cn id="A1.SS13.2.1.m1.1.1.3.cmml" type="integer" xref="A1.SS13.2.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS13.2.1.m1.1d">\text{MT}^{2}</annotation><annotation encoding="application/x-llamapun" id="A1.SS13.2.1.m1.1e">MT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math></span>
</h3>
<div class="ltx_para ltx_noindent" id="A1.SS13.p1">
<p class="ltx_p" id="A1.SS13.p1.1">We have utilized two different prompts in the data collection pipeline. One is generating two different motion captions with conversational data. The other one is generating one motion and conversational data based on the sample motion and corresponding caption from the base dataset, Inter-X <cite class="ltx_cite ltx_citemacro_citep">(Xu et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib40" title="">2024a</a>)</cite> and InterHuman <cite class="ltx_cite ltx_citemacro_cite">Liang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05628v2#bib.bib22" title="">2024</a>)</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS13.p2">
<p class="ltx_p" id="A1.SS13.p2.1">Motion editing prompts without base sample is constructed as follows:</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS13.p3">
<br class="ltx_break"/>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS13.p4">
<p class="ltx_p" id="A1.SS13.p4.1"><span class="ltx_text" id="A1.SS13.p4.1.1">
<span class="ltx_inline-block ltx_minipage ltx_align_middle" id="A1.SS13.p4.1.1.1" style="width:389.5pt;background-color:#E6E6E6;">
<span class="ltx_p" id="A1.SS13.p4.1.1.1.1"><span class="ltx_text ltx_font_sansserif" id="A1.SS13.p4.1.1.1.1.1" style="color:#808080;">You are an AI visual assistant, and you are seeing a motion.
Design a conversation between you and a person building a conversation about editing this motion.
In conversations, you should indicate who said using ”User:”, and”AI:” in the beginning but these two words
do not occur in sentences.
The answers should be in a tone that an AI visual assistant is seeing the motion and answering the
question. The scenario should always contain two people in the scene.
Generate a conversation about building a story from two different motions.
The flow of the conversation is as follows:
1. Creating a scenario. REMBER to make a story in this.
2. Change the emotion or persona of just one person.
3. Describe how the motion will be changed, with one person maintaining the same motion.
”””Example:
User: Let’s create a story starting from [Two individuals sitting across from each other, with one person extending his/her left hand and the other person extending their left hand. They proceed to participate in a wrist-wrestling competition].
AI: Two people are doing an arm-wrestling match, and each person is grabbing the right hand of the other person while sitting.
User: The next scene is [Two individuals sit across from each other, with one person extending his/her left hand and the other person extending both hands. They proceed to participate in a wrist-wrestling competition, where the second person utilizes both hands in an attempt to defeat the first person’s left hand.].
AI: The one person kept losing the game, which made him competitive to win the game.”””,
”””Example:
User: Two friends are doing an arm-wrestling match.
AI: [Two individuals sit across from each other, with one person extending his/her left hand and the other person extending left hand. They proceed to participate in a wrist-wrestling competition]
User: One person got competitive.
AI: [Two individuals sit across from each other, with one person extending his/her left hand and the other person extending both hands. They proceed to participate in a wrist-wrestling competition, where the second person utilizes both hands in an attempt to defeat the first person’s left hand.].
User: Explain the reason for the motion.
AI: The one person kept losing the game, which made him cheat to win the game.”””,
”””Example:
User: Two friends are doing an arm-wrestling match, like [Two individuals sit across from each other, with one person extending his/her left hand and the other person extending left hand. They proceed to participate in a wrist-wrestling competition].
AI: Two people are doing an arm-wrestling match, each person is grabbing the right hand of the other person, while sitting.
User: The one person kept losing the game, which made him competitive to win the game. Can you generate a motion of what would happen then?
AI: [Two individuals sit across from each other, with one person extending his/her left hand and the other person extending both hands. They proceed to participate in a wrist-wrestling competition, where the second person utilizes both hands in an attempt to defeat the first person’s left hand.]”””,
”””Example:
User: Let’s start making a story. Two friends are doing an arm-wrestling match, like [Two individuals sit across from each other, with one person extending his/her left hand and the other person extending their left hand. They proceed to participate in a wrist-wrestling competition].
AI: The one person kept losing the game, which made him competitive to win the game.
User: Sounds interesting. Can you visualize it?
AI: [Two individuals sit across from each other, with one person extending his/her left hand and the other person extending both hands. They proceed to participate in a wrist-wrestling competition, where the second person utilizes both hands in an attempt to defeat the first person’s left hand.]”””
===========
Example format for the [motion caption]:
- One person approaches, raises his/her right hand to grab the other person’s right forearm, places his/her left hand on it, and walks in the direction the grabbed person is facing.
- Two people face each other, one person lifts his/her right leg and walks towards the other person, stopping half a meter away.
- A person falls and braces himself/herself on the ground with his/her right hand. Another person approaches, squats down, and grabs his/her left arm with both hands to assist him/her in standing up.
The content inside the bracket ([]) is a caption for the motion. This is for visualizing the motion, which is not given in textual form during inference.
I will denote this as [motion caption].
Please denote [motion caption] when AI or the user has to answer in the motion sequence.
</span></span>
</span></span></p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS13.p5">
<br class="ltx_break"/>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS13.p6">
<p class="ltx_p" id="A1.SS13.p6.1"><span class="ltx_text" id="A1.SS13.p6.1.1">
<span class="ltx_inline-block ltx_minipage ltx_align_middle" id="A1.SS13.p6.1.1.1" style="width:389.5pt;background-color:#E6E6E6;">
<span class="ltx_p" id="A1.SS13.p6.1.1.1.1"><span class="ltx_text ltx_font_sansserif" id="A1.SS13.p6.1.1.1.1.1" style="color:#808080;">.. (continuing)
Please make [motion caption] that is similar to the following action labels: <span class="ltx_text" id="A1.SS13.p6.1.1.1.1.1.1" style="color:#800080;">[Action LABELS]</span>, and other motions like everyday routines (e.g., passing objects, greeting, communicating, etc.), and professional motions (e.g., Taekwondo, Latin dance, boxing, etc.)
but still not necessary. Be creative too!
Do not put [motion caption] in the same round, the user can also give motion to AI to reason from it too.
Also, do not directly put [motion caption] twice in the round. You should put in only once, regarding both User and AI.
[motion caption] are motion strings with skeleton information, which is for generating the motion. Do not repeat the caption.
If you want to refer to these motions, just refer to it as the ’first motion’. But this motion string should be contained in the former to refer to.
Try to make [motion caption] in details that do not require the previous context to generate the motion physically.
** Instead of the user fully describing what to do next, be more implicit, especially for the second motion, focusing more on the story. **
questions-answers not limited to the above examples.
Questions should not be yes-no questions but wh-questions.
The User-AI round should design at most 2. [motion caption] should appear only twice.
Do not generate any new objects. Please follow the template from the example.
It is better to keep the questions and answers concise.
Try to be rational and keep in mind to make everything in sense, and the story smooth enough.
Do not mention facial expressions or hands. Make the [motion caption] only ”twice” in the conversation.
[motion caption] should always contain a description of two people.
[motion caption] should have enough details for the motion, letting the model generate a correct motion by only accessing this caption without the previous context.
Do not change the style of the motion caption.
Do not make big and sudden changes in scenarios.
REMEMBER: Try to make a description of the second motion that can be inferred by seeing the first motion.
DO NOT GENERATE conversations that can be understandable without the previous context.
FOCUS on **editing** the motion based on the emotion or personas.
Users should NEVER ask AI to generate the motion giving details about what to do. LET AI infer about what to do based on the change of emotion.
t is better to keep the questions and answers concise, with strictly following the format. Do not explain too much when generation motion.
You are making a conversation about how the motion of the one person will change based on the persona, instead of keeping the story going on.
The motion should be changed via body movement, not with facial expressions or hands.
Do not directly [motion caption], this is just the format to guide you to fill the description there. Strictly follow the format.
Generating **two** captions, with the changing persona for the motion. For the second caption, just change the motion of the second person.
Do NOT LEAVE the [motion caption] holder!
Do not put something like slightly, small, etc. It won’t be able to be visualized!
Try to make a [motion caption] with the change of meaning of the motion, while maintaining a high-level scenario. Try to change the motion of the person dramatically, instead of changing just a few words.</span></span>
</span></span></p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS13.p7">
<p class="ltx_p" id="A1.SS13.p7.1">Action labels contain all the action labels in the dataset, which bounds the captions to be inside the trained data from the text-to-motion model.</p>
</div>
<div class="ltx_para" id="A1.SS13.p8">
<p class="ltx_p" id="A1.SS13.p8.1">Next, prompts for motion reasoning and story generation without caption sample is as follows:</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS13.p9">
<p class="ltx_p" id="A1.SS13.p9.1"><span class="ltx_text" id="A1.SS13.p9.1.1">
<span class="ltx_inline-block ltx_minipage ltx_align_middle" id="A1.SS13.p9.1.1.1" style="width:389.5pt;background-color:#E6E6E6;">
<span class="ltx_p" id="A1.SS13.p9.1.1.1.1"><span class="ltx_text ltx_font_sansserif" id="A1.SS13.p9.1.1.1.1.1" style="color:#808080;">You are an AI visual assistant, and you are seeing a motion.
Design a conversation between you and a person building a conversation about reasoning this motion.
In conversations, you should indicate who said using ”User:”, ”AI:” in the beginning but these two words
do not occur in sentences.
The answers should be in a tone that an AI assistant is seeing the motion and answering the
question. The scenario should always contain two people in the scene.
Generate a conversation about building a story from two different motions.
The flow of the conversation is as follows:
1. Creating a scenario. REMBER to make a story in this.
2. Reason about the motion or generate motion caption based on the scenario
”””Example:
User: The current scene is [Two individuals sitting across from each other, with one person extending his/her left hand and the other person extending their left hand. They proceed to participate in a wrist-wrestling competition]. Can you tell me what happened before?
AI: Two people are doing arm-wrestling match, before that, two people will be doing fist dumps for fair play.
User: Show me what will happen after that in motion format.
AI: [One person is conducting a v-sign while the other stands still.]”””,
”””Example:
User: Two friends are doing an arm-wrestling match, show me the motion of that.
AI: [Two individuals sit across from each other, with one person extending his/her left hand and the other person extending left hand. They proceed to participate in a wrist-wrestling competition]
User: Show me what happened before that in motion format.
AI: [two people are doing fist dumps].
User: Why are they doing the fist dumps?
AI: They are exchanging fist dumps to play a fair game in arm-wrestling.”””,
”””Example:
User: The current scene is [Two individuals sitting across from each other, with one person extending his/her left hand and the other person extending their left hand. They proceed to participate in a wrist-wrestling competition]. Can you tell me what happened before?.
AI: Two people are doing arm-wrestling match, before that, two people will be doing fist dumps for fair play.
User: The next scene is [One person is conducting a v-sign while the other stands still.]. Explain the reason for this motion.
AI: After the arm-wrestling match, one person won the game. The person is showing this happiness to the audience.”””
===========
Example format for the [motion caption]:
- One person approaches, raises his/her right hand to grab the other person’s right forearm, places his/her left hand on it, and walks in the direction the grabbed person is facing.
- Two people face each other, one person lifts his/her right leg and walks towards the other person, stopping half a meter away.
- A person falls and braces himself/herself on the ground with his/her right hand. Another person approaches, squats down, and grabs his/her left arm with both hands to assist him/her in standing up.
The content inside the bracket ([]) is a caption for the motion. This is for visualizing the motion, which is not given in textual form during inference.
I will denote this as [motion caption].
Please denote [motion caption] when AI or the user has to answer in the motion sequence.
Please make [motion caption] that is similar to the following action labels: <span class="ltx_text" id="A1.SS13.p9.1.1.1.1.1.1" style="color:#800080;">[Action LABELS]</span>, and other motions like everyday routines (e.g., passing objects, greeting, communicating, etc.), and professional motions (e.g., Taekwondo, Latin dance, boxing, etc.)
but still not necessary. Be creative too!
Do not put [motion caption] in the same round, the user can also give motion to AI to reason from it too.
Also, do not directly put [motion caption] twice in the round. You should put in only once, regarding both User and AI.
[motion caption] are motion strings with skeleton information, which is for generating the motion. Do not repeat the caption.
If you want to refer to these motions, just refer to it as the ’first motion’. But this motion string should be contained in the former to refer to.
Try to make [motion caption] in details that do not require the previous context to generate the motion physically.
** Instead of the user fully describing what to do next, be more implicit, especially for the second motion, focusing more on the story. **
questions-answers not limited to the above examples.
Questions should not be yes-no questions but wh-questions.
The User-AI round should design at most 2. [motion caption] should appear only twice.
Do not generate any new objects. Please follow the template from the example.
It is better to keep the questions and answers concise.
Try to be rational and keep in mind to make everything in sense, and the story smooth enough.
Do not mention facial expressions or hands. Make the [motion caption] only ”twice” in the conversation.
[motion caption] should always contain a description of two people.
[motion caption] should have enough details for the motion, letting the model generate a correct motion by only accessing this caption without the previous context.
Do not make the conversation more than three rounds.</span></span>
</span></span></p>
</div>
<div class="ltx_para" id="A1.SS13.p10">
<p class="ltx_p" id="A1.SS13.p10.1">Using the sample from the prior dataset, we have prompted the sampled motion and its corresponding caption to generate a multi-turn conversation that contains the sample motion.
For motion reasoning and story generation tasks, we have prompted a large language model to generate a second motion caption and corresponding conversational data. Prompts are as follows:</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS13.p11">
<p class="ltx_p" id="A1.SS13.p11.1"><span class="ltx_text" id="A1.SS13.p11.1.1">
<span class="ltx_inline-block ltx_minipage ltx_align_middle" id="A1.SS13.p11.1.1.1" style="width:389.5pt;background-color:#E6E6E6;">
<span class="ltx_p" id="A1.SS13.p11.1.1.1.1"><span class="ltx_text ltx_font_sansserif" id="A1.SS13.p11.1.1.1.1.1" style="color:#808080;">You are an AI visual assistant, and you are seeing a motion.
Design a conversation between you and a person building a conversation about reasoning this motion.
In conversations you should indicate who said using ”User:”, and” AI:” in the beginning but these two words
do not occur in sentences.
The answers should be in a tone that an AI visual assistant is seeing the motion and answering the
question. The scenario should always contain two people in the scene.
Generate a conversation about building a story from two different motions.
The flow of the conversation is as follows:
1. Creating a scenario. REMBER to make a story in this.
2. Reason about the motion or generate motion caption based on the scenario
=====================
Motion 1:[Two individuals sit across from each other, with one person extending his/her left hand and the other person extending left hand. They proceed to participate in a wrist-wrestling competition]
”””Example:
User: The current scene is [motion_placeholder_1]. Can you tell me what happened before?
AI: Two people are doing arm-wrestling match, before that, two people will be doing fist dumps for fair play.
User: Show me what will happen after that in motion format.
AI: [One person is conducting a v-sign while the other stands still.]”””,
”””Example:
User: Two friends are doing an arm-wrestling match, show me the motion of that.
AI: [motion_placeholder_1]
User: Show me what happened before that in motion format.
AI: [two people are doing fist dumps].
User: Why are they doing the fist dumps?
AI: They are exchanging fist dumps to play a fair game in arm-wrestling.”””,
”””Example:
User: The current scene is [motion_placeholder_1]. Can you tell me what happened before?.
AI: Two people are doing arm-wrestling match, before that, two people will be doing fist dumps for fair play.
User: The next scene is [One person is conducting a v-sign while the other stands still.]. Explain the reason for this motion.
AI: After the arm-wrestling match, one person won the game. The person is showing this happiness to audience.”””,
=====================
lease denote [motion_placeholder] is when AI or the user has to answer in the motion sequence.
Example format for the [motion caption]:
- One person approaches, raises his/her right hand to grab the other person’s right forearm, places his/her left hand on it, and walks in the direction the grabbed person is facing.
- Two people face each other, one person lifts his/her right leg and walks towards the other person, stopping half a meter away.
- A person falls and braces himself/herself on the ground with his/her right hand. Another person approaches, squats down, and grabs his/her left arm with both hands to assist him/her in standing up.
The content inside the bracket ([]) is a caption for the motion. This is for visualizing the motion, which is not given in textual form during inference.
I will denote this as [motion caption].
Please denote [motion caption] when AI or the user has to answer in the motion sequence.
Please make [motion caption] that is similar to the following action labels: <span class="ltx_text" id="A1.SS13.p11.1.1.1.1.1.1" style="color:#800080;">[Action LABELS]</span>, and other motions like everyday routines (e.g., passing objects, greeting, communicating, etc.), and professional motions (e.g., Taekwondo, Latin dance, boxing, etc.)
but still not necessary. Be creative too!
!! Motion 1 is the description of [motion_placeholder_1]. Do not generate as [motion caption] for the first motion, rather just use [motion_placeholder_1].
DO NOT REPAT the given description, just use the [motion_placeholder_1]
For the second motion, make it as [description of motion that you want].
[motion caption] should always contain a description of two people.
[motion caption] should have enough details for the motion, letting the model generate a correct motion by only accessing this caption without the previous context.
Do not make the conversation more than three rounds.
Strictly follow the format of the given example. But not the motion inside there be creative.
=====================
Motion1:<span class="ltx_text" id="A1.SS13.p11.1.1.1.1.1.2" style="color:#800080;">[Motion caption from prior dataset]</span></span></span>
</span></span></p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS13.p12">
<p class="ltx_p" id="A1.SS13.p12.1">For the motion editing task, we have divided prompts into two parts. We first generate an edited motion caption with reasoning steps by prompting the large language model as follows:</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS13.p13">
<br class="ltx_break"/>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS13.p14">
<p class="ltx_p" id="A1.SS13.p14.1"><span class="ltx_text" id="A1.SS13.p14.1.1">
<span class="ltx_inline-block ltx_minipage ltx_align_middle" id="A1.SS13.p14.1.1.1" style="width:389.5pt;background-color:#E6E6E6;">
<span class="ltx_p" id="A1.SS13.p14.1.1.1.1"><span class="ltx_text ltx_font_sansserif" id="A1.SS13.p14.1.1.1.1.1" style="color:#808080;">First, let’s edit the motion description. The provided motion descriptions represent the same motion.
The motion content you are seeing is provided as follows:
Motion1:
<span class="ltx_text" id="A1.SS13.p14.1.1.1.1.1.1" style="color:#800080;">Motion caption from prior dataset</span>
Focus on editing the motion based on the emotion, or based on persona like relationship or personality.
Remember that you cannot edit the motion related to face or hands. Just edit the body motion.
**Do not put something like slightly, small, etc. It won’t be able to be visualized!**
Try to make a the meaning of the motion, while maintaing high-level scenario.
Format:
Motion 2: []
Do not put adjective in new motion description, description would be about the movement without any styles of motion.
Instead of changing the style or size of the motion description, always change the motion itself that has different meaning.
Just generate it based on choosing one of the motion description, not all of them.
Try to change the motion of the person dramatically, instead of changing just few words.
But still maintain the high-level action label of this motion. DO not change the whole scenario.</span></span>
</span></span></p>
</div>
<div class="ltx_para" id="A1.SS13.p15">
<p class="ltx_p" id="A1.SS13.p15.1">Based on this generated edited motion caption and corresponding reasoning steps are then conditioned to the next prompts to generate the conversational data.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS13.p16">
<p class="ltx_p" id="A1.SS13.p16.1"><span class="ltx_text" id="A1.SS13.p16.1.1">
<span class="ltx_inline-block ltx_minipage ltx_align_middle" id="A1.SS13.p16.1.1.1" style="width:389.5pt;background-color:#E6E6E6;">
<span class="ltx_p" id="A1.SS13.p16.1.1.1.1"><span class="ltx_text ltx_font_sansserif" id="A1.SS13.p16.1.1.1.1.1" style="color:#808080;">You are an AI visual assistant, and you are seeing a motion.
Design a conversation between you and a person building a conversation about editing this motion.
In conversations, you should indicate who said using ”User:”, and ”AI:” in the beginning but these two words
do not occur in sentences.
The answers should be in a tone that an AI visual assistant is seeing the motion and answering the
question. The scenario should always contain two people in the scene.
Generate a conversation about editing the motion based on two different given motions.
The flow of the conversation is as follows:
1. Creating a scenario.
2. Change the emotion or persona of just one person.
3. Describe how the motion will be changed.
=====================
Motion 1: [Two individuals sit across from each other, with one person extending his/her left hand and the other person extending both hands. They proceed to participate in a wrist-wrestling competition, where the second person utilizes both hands in an attempt to defeat the first person’s left hand.].
Motion 2: [They sit across from each other, with one person extending his/her left hand and the other person extending both hands. They proceed to participate in a wrist-wrestling competition].
”””Example:
User: Let’s create a story starting from [motion_placeholder_1].
AI: The one person kept losing the game, which made him competitive to win the game, like using his/her hands.
User: The next scene is [motion_placeholder_2].
AI: Now, the person got a warning from the referee, leading him/her to just use one hand.”””,
”””Example:
User: Two friends are doing an arm-wrestling match.
AI: [motion_placeholder_1]
User: Okay one person looks too competitive in there. Can you make one person have more sportsmanship?
AI: [motion_placeholder_2].
User: Explain the reason for the motion.
AI: One person may have gotten a warning from the referee..”””,
”””Example:
User: Two friends are doing an arm-wrestling match, like [motion_placeholder_1].
AI: Two people are doing an arm-wrestling match, while one person is grabbing the other’s left hand, one person is using both hands.
User: Okay one person looks too competitive in there. Can you make one person have more sportsmanship?
AI: [motion_placeholder_2]”””,
”””Example:
User: Let’s start making a story. Two friends are doing an arm-wrestling match, like [motion_placeholder_1].
AI: The other person got a warning from the referee, leading him/her to just use one hand.
User: Sounds interesting. Can you visualize it?
AI: [motion_placeholder_2]”””
=====================
Please denote [motion_placeholder] when AI or the user has to answer in the motion sequence.
[motion_placeholder_1] denotes Motion1, [motion_placeholder_2] denotes Motion2. Just use this term.
Do not put [motion_placeholder]s in the same round, the user can also give motion to AI to reason from it too.
Always follow the flow that motion 1 comes first.
If you want to refer to these motions, just refer to it as the ’first motion’. But this motion string should be contained in the former to refer to.
questions-answers not limited to the above examples.
** Instead of the user fully describing what to do next, be more implicit, especially for the second motion. **
questions-answers not limited to the above examples.
Questions should not be yes-no questions but wh-questions.
The User-AI round should design at most 2.
Do not generate any new objects. Please follow the template from the example.
It is better to keep the questions and answers concise.
Try to be rational and keep in mind to make everything in sense.
Do not mention facial expressions or hands.
Do not make a big and sudden change in scenarios.
REMEMBER: Try to make a description of the second motion that can be inferred by seeing the first motion.
DO NOT GENERATE conversations that can be understandable without the previous context.
FOCUS on **editing** the motion based on the emotion or personas.
Users should NEVER ask AI to generate the motion giving details about what to do.
LET AI infer about what to do based on the change of emotion.
**Focus on the change of persona.**
Strictly follow the format of the given example.
Put [motion_placeholder_1] and [motion_placeholder_2] each once in total conversation.
The motion content you are seeing is provided as follows:
Motion1:
<span class="ltx_text" id="A1.SS13.p16.1.1.1.1.1.1" style="color:#800080;">Motion caption from prior dataset</span>
Motion2:
<span class="ltx_text" id="A1.SS13.p16.1.1.1.1.1.2" style="color:#800080;">Generated Motion caption</span></span></span>
</span></span></p>
</div>
</section>
<section class="ltx_subsection" id="A1.SS14">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.14 </span>Prompts for LLM-Assisted Evaluation</h3>
<div class="ltx_para ltx_noindent" id="A1.SS14.p1">
<p class="ltx_p" id="A1.SS14.p1.1">To evaluate the reasoning ability of the proposed method, we have utilized LLM-assisted evaluation as shown in Section 5.2. The prompts used to evaluate such ability is as follows:</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS14.p2">
<br class="ltx_break"/>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS14.p3">
<p class="ltx_p" id="A1.SS14.p3.1"><span class="ltx_text" id="A1.SS14.p3.1.1">
<span class="ltx_inline-block ltx_minipage ltx_align_middle" id="A1.SS14.p3.1.1.1" style="width:389.5pt;background-color:#E6E6E6;">
<span class="ltx_p" id="A1.SS14.p3.1.1.1.1"><span class="ltx_text ltx_font_sansserif" id="A1.SS14.p3.1.1.1.1.1" style="color:#808080;">We are evaluating the results of a model designed for generating interleaved motion-text documents.
The model’s input, starting with ”INPUT:”, can either be the beginning of a text-motion interleaved document or a specified topic.
Its output, starting with ”OUTPUT:”, will then be either a continuation of the document or content generated based on the given topic.
The motion is given as ground truth captions denoted as [c1, c2, c3] where all captions are describing the same motion.
Please remember that it is the caption of the motion, while there are many ways to describe the same motion. The provided caption is just part of it.
As an expert in multimodal evaluation, your task is to assess the quality of the output that is describe as text.</span></span>
<span class="ltx_p" id="A1.SS14.p3.1.1.1.2"><span class="ltx_text ltx_font_sansserif" id="A1.SS14.p3.1.1.1.2.1" style="color:#808080;">Scoring Guidelines:</span></span>
<span class="ltx_p" id="A1.SS14.p3.1.1.1.3"><span class="ltx_text ltx_font_sansserif" id="A1.SS14.p3.1.1.1.3.1" style="color:#808080;">- 0-3: Major deficiencies, misalignment, or inconsistency</span></span>
<span class="ltx_p" id="A1.SS14.p3.1.1.1.4"><span class="ltx_text ltx_font_sansserif" id="A1.SS14.p3.1.1.1.4.1" style="color:#808080;">- 4-7: Minor gaps, misalignment, or inconsistency</span></span>
<span class="ltx_p" id="A1.SS14.p3.1.1.1.5"><span class="ltx_text ltx_font_sansserif" id="A1.SS14.p3.1.1.1.5.1" style="color:#808080;">- 8-10: Complete and thorough alignment, strong consistency</span></span>
<span class="ltx_p" id="A1.SS14.p3.1.1.1.6"><span class="ltx_text ltx_font_sansserif" id="A1.SS14.p3.1.1.1.6.1" style="color:#808080;">Scoring Criteria:</span></span>
<span class="ltx_p" id="A1.SS14.p3.1.1.1.7"><span class="ltx_text ltx_font_sansserif" id="A1.SS14.p3.1.1.1.7.1" style="color:#808080;">1. Logical Coherence:</span></span>
<span class="ltx_p" id="A1.SS14.p3.1.1.1.8"><span class="ltx_text ltx_font_sansserif" id="A1.SS14.p3.1.1.1.8.1" style="color:#808080;">- Evaluates the logical consistency and reasoning accuracy of the generated text</span></span>
<span class="ltx_p" id="A1.SS14.p3.1.1.1.9"><span class="ltx_text ltx_font_sansserif" id="A1.SS14.p3.1.1.1.9.1" style="color:#808080;">- Key Aspects:</span></span>
<span class="ltx_p" id="A1.SS14.p3.1.1.1.10"><span class="ltx_text ltx_font_sansserif" id="A1.SS14.p3.1.1.1.10.1" style="color:#808080;">- Causal Relationships: Are the cause-and-effect relationships in the story or reasoning clear and sensible?</span></span>
<span class="ltx_p" id="A1.SS14.p3.1.1.1.11"><span class="ltx_text ltx_font_sansserif" id="A1.SS14.p3.1.1.1.11.1" style="color:#808080;">- Temporal Consistency: Does the timeline of events flow logically, without jumps or anachronisms?</span></span>
<span class="ltx_p" id="A1.SS14.p3.1.1.1.12"><span class="ltx_text ltx_font_sansserif" id="A1.SS14.p3.1.1.1.12.1" style="color:#808080;">- Character and Event Consistency: Do the actions of characters or descriptions of events remain consistent throughout the text?</span></span>
<span class="ltx_p" id="A1.SS14.p3.1.1.1.13"><span class="ltx_text ltx_font_sansserif" id="A1.SS14.p3.1.1.1.13.1" style="color:#808080;">- Plausibility: Does the explanation or story feel plausible, given the context of the motion data?</span></span>
<span class="ltx_p" id="A1.SS14.p3.1.1.1.14"><span class="ltx_text ltx_font_sansserif" id="A1.SS14.p3.1.1.1.14.1" style="color:#808080;">2. Content Alignment</span></span>
<span class="ltx_p" id="A1.SS14.p3.1.1.1.15"><span class="ltx_text ltx_font_sansserif" id="A1.SS14.p3.1.1.1.15.1" style="color:#808080;">- Evaluate how accurately the generated text reflects the context of the given motion data</span></span>
<span class="ltx_p" id="A1.SS14.p3.1.1.1.16"><span class="ltx_text ltx_font_sansserif" id="A1.SS14.p3.1.1.1.16.1" style="color:#808080;">- Key Aspects:</span></span>
<span class="ltx_p" id="A1.SS14.p3.1.1.1.17"><span class="ltx_text ltx_font_sansserif" id="A1.SS14.p3.1.1.1.17.1" style="color:#808080;">- Relevance: Does the generated text accurately respond to the motion data, staying relevant to the scenario presented by the input?</span></span>
<span class="ltx_p" id="A1.SS14.p3.1.1.1.18"><span class="ltx_text ltx_font_sansserif" id="A1.SS14.p3.1.1.1.18.1" style="color:#808080;">- Accuracy: Are the details and context derived from the motion data correctly reflected in the text?</span></span>
<span class="ltx_p" id="A1.SS14.p3.1.1.1.19"><span class="ltx_text ltx_font_sansserif" id="A1.SS14.p3.1.1.1.19.1" style="color:#808080;">- Interpretation: Does the text offer a reasonable interpretation or explanation of the motion, fitting within the implied scenario?</span></span>
<span class="ltx_p" id="A1.SS14.p3.1.1.1.20"><span class="ltx_text ltx_font_sansserif" id="A1.SS14.p3.1.1.1.20.1" style="color:#808080;">3. Naturalness:
- Evaluate the quality of the output texts</span></span>
<span class="ltx_p" id="A1.SS14.p3.1.1.1.21"><span class="ltx_text ltx_font_sansserif" id="A1.SS14.p3.1.1.1.21.1" style="color:#808080;">- Key Aspects:</span></span>
<span class="ltx_p" id="A1.SS14.p3.1.1.1.22"><span class="ltx_text ltx_font_sansserif" id="A1.SS14.p3.1.1.1.22.1" style="color:#808080;">- Fluency: Is the text grammatically correct, with smooth sentence structures?</span></span>
<span class="ltx_p" id="A1.SS14.p3.1.1.1.23"><span class="ltx_text ltx_font_sansserif" id="A1.SS14.p3.1.1.1.23.1" style="color:#808080;">- Readability: Does the text flow well, without awkward phrasing or confusing syntax?</span></span>
<span class="ltx_p" id="A1.SS14.p3.1.1.1.24"><span class="ltx_text ltx_font_sansserif" id="A1.SS14.p3.1.1.1.24.1" style="color:#808080;">- Tone and Style: Is the tone appropriate for the context? Does it match human-like writing in terms of style and nuance?</span></span>
<span class="ltx_p" id="A1.SS14.p3.1.1.1.25"><span class="ltx_text ltx_font_sansserif" id="A1.SS14.p3.1.1.1.25.1" style="color:#808080;">- Engagement: Is the text engaging and interesting to read?</span></span>
<span class="ltx_p" id="A1.SS14.p3.1.1.1.26"><span class="ltx_text ltx_font_sansserif" id="A1.SS14.p3.1.1.1.26.1" style="color:#808080;">JSON Output Structure:</span></span>
<span class="ltx_p" id="A1.SS14.p3.1.1.1.27"><span class="ltx_text ltx_font_sansserif" id="A1.SS14.p3.1.1.1.27.1" style="color:#808080;">{</span></span>
<span class="ltx_p" id="A1.SS14.p3.1.1.1.28"><span class="ltx_text ltx_font_sansserif" id="A1.SS14.p3.1.1.1.28.1" style="color:#808080;">”scores”: {</span></span>
<span class="ltx_p" id="A1.SS14.p3.1.1.1.29"><span class="ltx_text ltx_font_sansserif" id="A1.SS14.p3.1.1.1.29.1" style="color:#808080;">”Logical Coherence”: {</span></span>
<span class="ltx_p" id="A1.SS14.p3.1.1.1.30"><span class="ltx_text ltx_font_sansserif" id="A1.SS14.p3.1.1.1.30.1" style="color:#808080;">”Justification”: ”brief justification of any deficiencies in image quality”,</span></span>
<span class="ltx_p" id="A1.SS14.p3.1.1.1.31"><span class="ltx_text ltx_font_sansserif" id="A1.SS14.p3.1.1.1.31.1" style="color:#808080;">”Score”: 0-10
},</span></span>
<span class="ltx_p" id="A1.SS14.p3.1.1.1.32"><span class="ltx_text ltx_font_sansserif" id="A1.SS14.p3.1.1.1.32.1" style="color:#808080;">”Content Alignment”:{</span></span>
<span class="ltx_p" id="A1.SS14.p3.1.1.1.33"><span class="ltx_text ltx_font_sansserif" id="A1.SS14.p3.1.1.1.33.1" style="color:#808080;">”Justification”: ”brief justification of any deficiencies in image quality”,</span></span>
<span class="ltx_p" id="A1.SS14.p3.1.1.1.34"><span class="ltx_text ltx_font_sansserif" id="A1.SS14.p3.1.1.1.34.1" style="color:#808080;">”Score”: 0-10 },</span></span>
<span class="ltx_p" id="A1.SS14.p3.1.1.1.35"><span class="ltx_text ltx_font_sansserif" id="A1.SS14.p3.1.1.1.35.1" style="color:#808080;">”Naturalness”:{</span></span>
<span class="ltx_p" id="A1.SS14.p3.1.1.1.36"><span class="ltx_text ltx_font_sansserif" id="A1.SS14.p3.1.1.1.36.1" style="color:#808080;">”Justification”: ”brief justification of any deficiencies in image quality”,</span></span>
<span class="ltx_p" id="A1.SS14.p3.1.1.1.37"><span class="ltx_text ltx_font_sansserif" id="A1.SS14.p3.1.1.1.37.1" style="color:#808080;">”Score”: 0-10
}</span></span>
<span class="ltx_p" id="A1.SS14.p3.1.1.1.38"><span class="ltx_text ltx_font_sansserif" id="A1.SS14.p3.1.1.1.38.1" style="color:#808080;">}</span></span>
<span class="ltx_p" id="A1.SS14.p3.1.1.1.39"><span class="ltx_text ltx_font_sansserif" id="A1.SS14.p3.1.1.1.39.1" style="color:#808080;">}</span></span>
<span class="ltx_p" id="A1.SS14.p3.1.1.1.40"><span class="ltx_text ltx_font_sansserif" id="A1.SS14.p3.1.1.1.40.1" style="color:#808080;">Data to Review:</span></span>
</span></span></p>
</div>
</section>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Mon Oct 14 11:44:43 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
