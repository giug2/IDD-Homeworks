<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2306.17675] Multimodal Prompt Retrieval for Generative Visual Question Answering</title><meta property="og:description" content="Recent years have witnessed impressive results of pre-trained vision-language models on knowledge-intensive tasks such as visual question answering (VQA). Despite the recent advances in VQA, existing methods mainly ado…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Multimodal Prompt Retrieval for Generative Visual Question Answering">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Multimodal Prompt Retrieval for Generative Visual Question Answering">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2306.17675">

<!--Generated on Wed Feb 28 21:54:46 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Multimodal Prompt Retrieval for Generative Visual Question Answering</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Timothy Ossowski<sup id="id5.5.id1" class="ltx_sup">1</sup>, Junjie Hu<sup id="id6.6.id2" class="ltx_sup"><span id="id6.6.id2.1" class="ltx_text ltx_font_italic">1,2</span></sup>
<br class="ltx_break"><sup id="id7.7.id3" class="ltx_sup">1</sup>Department of Computer Science, <sup id="id8.8.id4" class="ltx_sup">2</sup>Department of Biostatistics and Medical Informatics
<br class="ltx_break">University of Wisconsin, Madison, WI, USA
<br class="ltx_break"><span id="id9.9.id5" class="ltx_text ltx_font_typewriter">ossowski@wisc.edu</span>, <span id="id10.10.id6" class="ltx_text ltx_font_typewriter">junjie.hu@wisc.edu</span>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id11.id1" class="ltx_p">Recent years have witnessed impressive results of pre-trained vision-language models on knowledge-intensive tasks such as visual question answering (VQA). Despite the recent advances in VQA, existing methods mainly adopt a discriminative formulation that predicts answers within a pre-defined label set, leading to easy overfitting on low-resource domains with limited labeled data (e.g., medicine) and poor generalization under domain shift to another dataset. To tackle this limitation, we propose a novel generative model enhanced by multimodal prompt retrieval (<span id="id11.id1.1" class="ltx_text ltx_font_smallcaps">MPR</span>) that integrates retrieved prompts and multimodal features to generate answers in free text. Our generative model enables rapid zero-shot dataset adaptation to unseen data distributions and open-set answer labels across datasets. Our experiments on medical VQA tasks show that <span id="id11.id1.2" class="ltx_text ltx_font_smallcaps">MPR</span> outperforms its non-retrieval counterpart by up to 30% accuracy points in
a few-shot domain adaptation setting.<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Our code is publicly available at <a target="_blank" href="https://github.com/tossowski/MultimodalPromptRetrieval" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/tossowski/MultimodalPromptRetrieval</a></span></span></span></p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Visual question answering (VQA) is a popular multimodal machine learning problem that challenges a model to answer a question posed about an image. As encouraged by recent advances in VQA, pioneering studies have investigated the application of VQA systems to low-resourced, knowledge-intensive domains such as medicine <cite class="ltx_cite ltx_citemacro_cite">Lin et al. (<a href="#bib.bib23" title="" class="ltx_ref">2021</a>)</cite>, where collecting domain-specific annotations is extremely costly and time-consuming. In particular, medical VQA has attracted increasing research interests <cite class="ltx_cite ltx_citemacro_cite">Hasan et al. (<a href="#bib.bib11" title="" class="ltx_ref">2018</a>)</cite>, with the target of supporting clinical decision-making such as acting as an auxiliary virtual “diagnostic radiologist” <cite class="ltx_cite ltx_citemacro_cite">Kovaleva et al. (<a href="#bib.bib17" title="" class="ltx_ref">2020</a>)</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Despite recent progress in general VQA leveraging pre-training <cite class="ltx_cite ltx_citemacro_cite">Chen et al. (<a href="#bib.bib4" title="" class="ltx_ref">2022</a>)</cite>, retrieval <cite class="ltx_cite ltx_citemacro_cite">Wu et al. (<a href="#bib.bib41" title="" class="ltx_ref">2022</a>)</cite>, or knowledge bases <cite class="ltx_cite ltx_citemacro_cite">Narasimhan and Schwing (<a href="#bib.bib29" title="" class="ltx_ref">2018</a>); Shevchenko et al. (<a href="#bib.bib37" title="" class="ltx_ref">2021</a>)</cite>, several challenges still exist for medical VQA. First, medical VQA systems still suffer from a stark lack of high-quality labeled data. As a result, it is essential to leverage domain adaptation techniques <cite class="ltx_cite ltx_citemacro_cite">Zhou et al. (<a href="#bib.bib44" title="" class="ltx_ref">2019</a>)</cite> that rapidly adapt models trained from a similar dataset to a target dataset. Second, as the medical domain covers a wide variety of complex diseases, there exists a large distribution shift across medical datasets, significantly increasing the complexity of learning medical images and texts by deep neural models. However, many existing medical VQA methods mainly focus on in-domain evaluation, testing systems on a held-out test set under the same data distribution of the training data. Moreover, these methods often augment their model architecture with dataset-specific components such as an answer-type classifier <cite class="ltx_cite ltx_citemacro_cite">Zhan et al. (<a href="#bib.bib43" title="" class="ltx_ref">2020</a>)</cite>, separate models for each question-type <cite class="ltx_cite ltx_citemacro_cite">Khare et al. (<a href="#bib.bib14" title="" class="ltx_ref">2021</a>)</cite>, or specific pre-trained medical encoders <cite class="ltx_cite ltx_citemacro_cite">Moon et al. (<a href="#bib.bib28" title="" class="ltx_ref">2022</a>)</cite>. These dataset-specific designs hinder the application of these medical VQA models across datasets in new domains. Furthermore, existing medical VQA approaches <cite class="ltx_cite ltx_citemacro_cite">Tanwani et al. (<a href="#bib.bib39" title="" class="ltx_ref">2022</a>); Eslami et al. (<a href="#bib.bib6" title="" class="ltx_ref">2021</a>)</cite> often adopt a discriminative model architecture that predicts a fixed set of answers, limiting model generalization to different answer sets.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">To tackle these challenges, we propose a domain-agnostic generative VQA model with multimodal prompt retrieval (MPR) that retrieves relevant VQA examples to construct multimodal prompts and generates arbitrary free text as the answers, removing the restriction of predicting a fixed label set. To augment the retrieval data, we also investigate a data augmentation strategy to create a synthetic medical VQA dataset from medical image-captioning data. Our experiments on two medical VQA datasets demonstrate the effective adaptation of our proposed method to a new target medical dataset, while also showing similar in-domain performance of our models to existing discriminative baselines.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Our contributions are summarized below:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">We introduce a multimodal prompt retrieval module that improves VQA generalization across different data distributions even with noisy synthetic data and smaller retrieval datasets.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;padding-top:-2.0pt;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">We investigate a zero-shot dataset adaptation setting for medical VQA systems across datasets, encouraging future research on in-context prediction of VQA systems for dataset adaptation.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;padding-top:-2.0pt;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">We propose a novel prompt-based generative VQA model, which enables more flexible answer outputs and controllable generation guided by multimodal prompts.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Preliminaries</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">This section provides descriptions of the VQA task and the challenges faced in the medical domain.</p>
</div>
<section id="S2.SS0.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Problem Setup</h4>

<div id="S2.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S2.SS0.SSS0.Px1.p1.9" class="ltx_p">Formally, given a VQA dataset of <math id="S2.SS0.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S2.SS0.SSS0.Px1.p1.1.m1.1a"><mi id="S2.SS0.SSS0.Px1.p1.1.m1.1.1" xref="S2.SS0.SSS0.Px1.p1.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p1.1.m1.1b"><ci id="S2.SS0.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p1.1.m1.1c">n</annotation></semantics></math> tuples <math id="S2.SS0.SSS0.Px1.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{D}=\{(v_{i},x_{i},y_{i})\}_{i=1}^{n}" display="inline"><semantics id="S2.SS0.SSS0.Px1.p1.2.m2.1a"><mrow id="S2.SS0.SSS0.Px1.p1.2.m2.1.1" xref="S2.SS0.SSS0.Px1.p1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS0.SSS0.Px1.p1.2.m2.1.1.3" xref="S2.SS0.SSS0.Px1.p1.2.m2.1.1.3.cmml">𝒟</mi><mo id="S2.SS0.SSS0.Px1.p1.2.m2.1.1.2" xref="S2.SS0.SSS0.Px1.p1.2.m2.1.1.2.cmml">=</mo><msubsup id="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1" xref="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.cmml"><mrow id="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.1.1" xref="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.2" xref="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.1.2.cmml">{</mo><mrow id="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.3" xref="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.4.cmml"><mo stretchy="false" id="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.3.4" xref="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.4.cmml">(</mo><msub id="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.1.1" xref="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.1.1.2" xref="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.1.1.2.cmml">v</mi><mi id="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.1.1.3" xref="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.3.5" xref="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.4.cmml">,</mo><msub id="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.2.2" xref="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.2.2.cmml"><mi id="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.2.2.2" xref="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.2.2.2.cmml">x</mi><mi id="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.2.2.3" xref="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.2.2.3.cmml">i</mi></msub><mo id="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.3.6" xref="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.4.cmml">,</mo><msub id="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.3.3" xref="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.3.3.cmml"><mi id="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.3.3.2" xref="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.3.3.2.cmml">y</mi><mi id="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.3.3.3" xref="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.3.3.3.cmml">i</mi></msub><mo stretchy="false" id="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.3.7" xref="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.4.cmml">)</mo></mrow><mo stretchy="false" id="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.3" xref="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.3" xref="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.3.cmml"><mi id="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.3.2" xref="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.3.2.cmml">i</mi><mo id="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.3.1" xref="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.3.1.cmml">=</mo><mn id="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.3.3" xref="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.3.3.cmml">1</mn></mrow><mi id="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.3" xref="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.3.cmml">n</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p1.2.m2.1b"><apply id="S2.SS0.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.2.m2.1.1"><eq id="S2.SS0.SSS0.Px1.p1.2.m2.1.1.2.cmml" xref="S2.SS0.SSS0.Px1.p1.2.m2.1.1.2"></eq><ci id="S2.SS0.SSS0.Px1.p1.2.m2.1.1.3.cmml" xref="S2.SS0.SSS0.Px1.p1.2.m2.1.1.3">𝒟</ci><apply id="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.2.cmml" xref="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1">superscript</csymbol><apply id="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.2.cmml" xref="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1">subscript</csymbol><set id="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.1.2.cmml" xref="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.1.1"><vector id="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.4.cmml" xref="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.3"><apply id="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.1.1.2">𝑣</ci><ci id="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.1.1.3">𝑖</ci></apply><apply id="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.2.2.cmml" xref="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.2.2.1.cmml" xref="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.2.2">subscript</csymbol><ci id="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.2.2.2.cmml" xref="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.2.2.2">𝑥</ci><ci id="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.2.2.3.cmml" xref="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.2.2.3">𝑖</ci></apply><apply id="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.3.3.cmml" xref="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.3.3.1.cmml" xref="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.3.3">subscript</csymbol><ci id="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.3.3.2.cmml" xref="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.3.3.2">𝑦</ci><ci id="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.3.3.3.cmml" xref="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.3.3.3">𝑖</ci></apply></vector></set><apply id="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.3.cmml" xref="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.3"><eq id="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.3.1.cmml" xref="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.3.1"></eq><ci id="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.3.2.cmml" xref="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.3.2">𝑖</ci><cn type="integer" id="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.3.3.cmml" xref="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.1.3.3">1</cn></apply></apply><ci id="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.3.cmml" xref="S2.SS0.SSS0.Px1.p1.2.m2.1.1.1.3">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p1.2.m2.1c">\mathcal{D}=\{(v_{i},x_{i},y_{i})\}_{i=1}^{n}</annotation></semantics></math>, we aim to learn a model to predict an answer <math id="S2.SS0.SSS0.Px1.p1.3.m3.1" class="ltx_Math" alttext="y_{i}" display="inline"><semantics id="S2.SS0.SSS0.Px1.p1.3.m3.1a"><msub id="S2.SS0.SSS0.Px1.p1.3.m3.1.1" xref="S2.SS0.SSS0.Px1.p1.3.m3.1.1.cmml"><mi id="S2.SS0.SSS0.Px1.p1.3.m3.1.1.2" xref="S2.SS0.SSS0.Px1.p1.3.m3.1.1.2.cmml">y</mi><mi id="S2.SS0.SSS0.Px1.p1.3.m3.1.1.3" xref="S2.SS0.SSS0.Px1.p1.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p1.3.m3.1b"><apply id="S2.SS0.SSS0.Px1.p1.3.m3.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px1.p1.3.m3.1.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.3.m3.1.1">subscript</csymbol><ci id="S2.SS0.SSS0.Px1.p1.3.m3.1.1.2.cmml" xref="S2.SS0.SSS0.Px1.p1.3.m3.1.1.2">𝑦</ci><ci id="S2.SS0.SSS0.Px1.p1.3.m3.1.1.3.cmml" xref="S2.SS0.SSS0.Px1.p1.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p1.3.m3.1c">y_{i}</annotation></semantics></math> given a question <math id="S2.SS0.SSS0.Px1.p1.4.m4.1" class="ltx_Math" alttext="x_{i}" display="inline"><semantics id="S2.SS0.SSS0.Px1.p1.4.m4.1a"><msub id="S2.SS0.SSS0.Px1.p1.4.m4.1.1" xref="S2.SS0.SSS0.Px1.p1.4.m4.1.1.cmml"><mi id="S2.SS0.SSS0.Px1.p1.4.m4.1.1.2" xref="S2.SS0.SSS0.Px1.p1.4.m4.1.1.2.cmml">x</mi><mi id="S2.SS0.SSS0.Px1.p1.4.m4.1.1.3" xref="S2.SS0.SSS0.Px1.p1.4.m4.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p1.4.m4.1b"><apply id="S2.SS0.SSS0.Px1.p1.4.m4.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px1.p1.4.m4.1.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.4.m4.1.1">subscript</csymbol><ci id="S2.SS0.SSS0.Px1.p1.4.m4.1.1.2.cmml" xref="S2.SS0.SSS0.Px1.p1.4.m4.1.1.2">𝑥</ci><ci id="S2.SS0.SSS0.Px1.p1.4.m4.1.1.3.cmml" xref="S2.SS0.SSS0.Px1.p1.4.m4.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p1.4.m4.1c">x_{i}</annotation></semantics></math> and an image <math id="S2.SS0.SSS0.Px1.p1.5.m5.1" class="ltx_Math" alttext="v_{i}" display="inline"><semantics id="S2.SS0.SSS0.Px1.p1.5.m5.1a"><msub id="S2.SS0.SSS0.Px1.p1.5.m5.1.1" xref="S2.SS0.SSS0.Px1.p1.5.m5.1.1.cmml"><mi id="S2.SS0.SSS0.Px1.p1.5.m5.1.1.2" xref="S2.SS0.SSS0.Px1.p1.5.m5.1.1.2.cmml">v</mi><mi id="S2.SS0.SSS0.Px1.p1.5.m5.1.1.3" xref="S2.SS0.SSS0.Px1.p1.5.m5.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p1.5.m5.1b"><apply id="S2.SS0.SSS0.Px1.p1.5.m5.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px1.p1.5.m5.1.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.5.m5.1.1">subscript</csymbol><ci id="S2.SS0.SSS0.Px1.p1.5.m5.1.1.2.cmml" xref="S2.SS0.SSS0.Px1.p1.5.m5.1.1.2">𝑣</ci><ci id="S2.SS0.SSS0.Px1.p1.5.m5.1.1.3.cmml" xref="S2.SS0.SSS0.Px1.p1.5.m5.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p1.5.m5.1c">v_{i}</annotation></semantics></math>. Conventionally, a model consists of an image and text encoder that maps the inputs <math id="S2.SS0.SSS0.Px1.p1.6.m6.1" class="ltx_Math" alttext="v_{i}" display="inline"><semantics id="S2.SS0.SSS0.Px1.p1.6.m6.1a"><msub id="S2.SS0.SSS0.Px1.p1.6.m6.1.1" xref="S2.SS0.SSS0.Px1.p1.6.m6.1.1.cmml"><mi id="S2.SS0.SSS0.Px1.p1.6.m6.1.1.2" xref="S2.SS0.SSS0.Px1.p1.6.m6.1.1.2.cmml">v</mi><mi id="S2.SS0.SSS0.Px1.p1.6.m6.1.1.3" xref="S2.SS0.SSS0.Px1.p1.6.m6.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p1.6.m6.1b"><apply id="S2.SS0.SSS0.Px1.p1.6.m6.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px1.p1.6.m6.1.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.6.m6.1.1">subscript</csymbol><ci id="S2.SS0.SSS0.Px1.p1.6.m6.1.1.2.cmml" xref="S2.SS0.SSS0.Px1.p1.6.m6.1.1.2">𝑣</ci><ci id="S2.SS0.SSS0.Px1.p1.6.m6.1.1.3.cmml" xref="S2.SS0.SSS0.Px1.p1.6.m6.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p1.6.m6.1c">v_{i}</annotation></semantics></math> and <math id="S2.SS0.SSS0.Px1.p1.7.m7.1" class="ltx_Math" alttext="x_{i}" display="inline"><semantics id="S2.SS0.SSS0.Px1.p1.7.m7.1a"><msub id="S2.SS0.SSS0.Px1.p1.7.m7.1.1" xref="S2.SS0.SSS0.Px1.p1.7.m7.1.1.cmml"><mi id="S2.SS0.SSS0.Px1.p1.7.m7.1.1.2" xref="S2.SS0.SSS0.Px1.p1.7.m7.1.1.2.cmml">x</mi><mi id="S2.SS0.SSS0.Px1.p1.7.m7.1.1.3" xref="S2.SS0.SSS0.Px1.p1.7.m7.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p1.7.m7.1b"><apply id="S2.SS0.SSS0.Px1.p1.7.m7.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px1.p1.7.m7.1.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.7.m7.1.1">subscript</csymbol><ci id="S2.SS0.SSS0.Px1.p1.7.m7.1.1.2.cmml" xref="S2.SS0.SSS0.Px1.p1.7.m7.1.1.2">𝑥</ci><ci id="S2.SS0.SSS0.Px1.p1.7.m7.1.1.3.cmml" xref="S2.SS0.SSS0.Px1.p1.7.m7.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p1.7.m7.1c">x_{i}</annotation></semantics></math> to the latent space of <math id="S2.SS0.SSS0.Px1.p1.8.m8.1" class="ltx_Math" alttext="\mathcal{V}" display="inline"><semantics id="S2.SS0.SSS0.Px1.p1.8.m8.1a"><mi class="ltx_font_mathcaligraphic" id="S2.SS0.SSS0.Px1.p1.8.m8.1.1" xref="S2.SS0.SSS0.Px1.p1.8.m8.1.1.cmml">𝒱</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p1.8.m8.1b"><ci id="S2.SS0.SSS0.Px1.p1.8.m8.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.8.m8.1.1">𝒱</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p1.8.m8.1c">\mathcal{V}</annotation></semantics></math> and <math id="S2.SS0.SSS0.Px1.p1.9.m9.1" class="ltx_Math" alttext="\mathcal{X}" display="inline"><semantics id="S2.SS0.SSS0.Px1.p1.9.m9.1a"><mi class="ltx_font_mathcaligraphic" id="S2.SS0.SSS0.Px1.p1.9.m9.1.1" xref="S2.SS0.SSS0.Px1.p1.9.m9.1.1.cmml">𝒳</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p1.9.m9.1b"><ci id="S2.SS0.SSS0.Px1.p1.9.m9.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.9.m9.1.1">𝒳</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p1.9.m9.1c">\mathcal{X}</annotation></semantics></math> respectively:</p>
<table id="A4.EGx1" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S2.E1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S2.E1.m1.1" class="ltx_Math" alttext="\displaystyle\mathbf{v}_{i}" display="inline"><semantics id="S2.E1.m1.1a"><msub id="S2.E1.m1.1.1" xref="S2.E1.m1.1.1.cmml"><mi id="S2.E1.m1.1.1.2" xref="S2.E1.m1.1.1.2.cmml">𝐯</mi><mi id="S2.E1.m1.1.1.3" xref="S2.E1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.E1.m1.1b"><apply id="S2.E1.m1.1.1.cmml" xref="S2.E1.m1.1.1"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.cmml" xref="S2.E1.m1.1.1">subscript</csymbol><ci id="S2.E1.m1.1.1.2.cmml" xref="S2.E1.m1.1.1.2">𝐯</ci><ci id="S2.E1.m1.1.1.3.cmml" xref="S2.E1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.1c">\displaystyle\mathbf{v}_{i}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S2.E1.m2.1" class="ltx_Math" alttext="\displaystyle=\text{ImgEncoder}(v_{i})\in\mathcal{V}" display="inline"><semantics id="S2.E1.m2.1a"><mrow id="S2.E1.m2.1.1" xref="S2.E1.m2.1.1.cmml"><mi id="S2.E1.m2.1.1.3" xref="S2.E1.m2.1.1.3.cmml"></mi><mo id="S2.E1.m2.1.1.4" xref="S2.E1.m2.1.1.4.cmml">=</mo><mrow id="S2.E1.m2.1.1.1" xref="S2.E1.m2.1.1.1.cmml"><mtext id="S2.E1.m2.1.1.1.3" xref="S2.E1.m2.1.1.1.3a.cmml">ImgEncoder</mtext><mo lspace="0em" rspace="0em" id="S2.E1.m2.1.1.1.2" xref="S2.E1.m2.1.1.1.2.cmml">​</mo><mrow id="S2.E1.m2.1.1.1.1.1" xref="S2.E1.m2.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E1.m2.1.1.1.1.1.2" xref="S2.E1.m2.1.1.1.1.1.1.cmml">(</mo><msub id="S2.E1.m2.1.1.1.1.1.1" xref="S2.E1.m2.1.1.1.1.1.1.cmml"><mi id="S2.E1.m2.1.1.1.1.1.1.2" xref="S2.E1.m2.1.1.1.1.1.1.2.cmml">v</mi><mi id="S2.E1.m2.1.1.1.1.1.1.3" xref="S2.E1.m2.1.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S2.E1.m2.1.1.1.1.1.3" xref="S2.E1.m2.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.E1.m2.1.1.5" xref="S2.E1.m2.1.1.5.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S2.E1.m2.1.1.6" xref="S2.E1.m2.1.1.6.cmml">𝒱</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m2.1b"><apply id="S2.E1.m2.1.1.cmml" xref="S2.E1.m2.1.1"><and id="S2.E1.m2.1.1a.cmml" xref="S2.E1.m2.1.1"></and><apply id="S2.E1.m2.1.1b.cmml" xref="S2.E1.m2.1.1"><eq id="S2.E1.m2.1.1.4.cmml" xref="S2.E1.m2.1.1.4"></eq><csymbol cd="latexml" id="S2.E1.m2.1.1.3.cmml" xref="S2.E1.m2.1.1.3">absent</csymbol><apply id="S2.E1.m2.1.1.1.cmml" xref="S2.E1.m2.1.1.1"><times id="S2.E1.m2.1.1.1.2.cmml" xref="S2.E1.m2.1.1.1.2"></times><ci id="S2.E1.m2.1.1.1.3a.cmml" xref="S2.E1.m2.1.1.1.3"><mtext id="S2.E1.m2.1.1.1.3.cmml" xref="S2.E1.m2.1.1.1.3">ImgEncoder</mtext></ci><apply id="S2.E1.m2.1.1.1.1.1.1.cmml" xref="S2.E1.m2.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E1.m2.1.1.1.1.1.1.1.cmml" xref="S2.E1.m2.1.1.1.1.1">subscript</csymbol><ci id="S2.E1.m2.1.1.1.1.1.1.2.cmml" xref="S2.E1.m2.1.1.1.1.1.1.2">𝑣</ci><ci id="S2.E1.m2.1.1.1.1.1.1.3.cmml" xref="S2.E1.m2.1.1.1.1.1.1.3">𝑖</ci></apply></apply></apply><apply id="S2.E1.m2.1.1c.cmml" xref="S2.E1.m2.1.1"><in id="S2.E1.m2.1.1.5.cmml" xref="S2.E1.m2.1.1.5"></in><share href="#S2.E1.m2.1.1.1.cmml" id="S2.E1.m2.1.1d.cmml" xref="S2.E1.m2.1.1"></share><ci id="S2.E1.m2.1.1.6.cmml" xref="S2.E1.m2.1.1.6">𝒱</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m2.1c">\displaystyle=\text{ImgEncoder}(v_{i})\in\mathcal{V}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
<tbody id="S2.E2"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S2.E2.m1.1" class="ltx_Math" alttext="\displaystyle\mathbf{x}_{i}" display="inline"><semantics id="S2.E2.m1.1a"><msub id="S2.E2.m1.1.1" xref="S2.E2.m1.1.1.cmml"><mi id="S2.E2.m1.1.1.2" xref="S2.E2.m1.1.1.2.cmml">𝐱</mi><mi id="S2.E2.m1.1.1.3" xref="S2.E2.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.E2.m1.1b"><apply id="S2.E2.m1.1.1.cmml" xref="S2.E2.m1.1.1"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.cmml" xref="S2.E2.m1.1.1">subscript</csymbol><ci id="S2.E2.m1.1.1.2.cmml" xref="S2.E2.m1.1.1.2">𝐱</ci><ci id="S2.E2.m1.1.1.3.cmml" xref="S2.E2.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E2.m1.1c">\displaystyle\mathbf{x}_{i}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S2.E2.m2.1" class="ltx_Math" alttext="\displaystyle=\text{TextEncoder}(x_{i})\in\mathcal{X}" display="inline"><semantics id="S2.E2.m2.1a"><mrow id="S2.E2.m2.1.1" xref="S2.E2.m2.1.1.cmml"><mi id="S2.E2.m2.1.1.3" xref="S2.E2.m2.1.1.3.cmml"></mi><mo id="S2.E2.m2.1.1.4" xref="S2.E2.m2.1.1.4.cmml">=</mo><mrow id="S2.E2.m2.1.1.1" xref="S2.E2.m2.1.1.1.cmml"><mtext id="S2.E2.m2.1.1.1.3" xref="S2.E2.m2.1.1.1.3a.cmml">TextEncoder</mtext><mo lspace="0em" rspace="0em" id="S2.E2.m2.1.1.1.2" xref="S2.E2.m2.1.1.1.2.cmml">​</mo><mrow id="S2.E2.m2.1.1.1.1.1" xref="S2.E2.m2.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E2.m2.1.1.1.1.1.2" xref="S2.E2.m2.1.1.1.1.1.1.cmml">(</mo><msub id="S2.E2.m2.1.1.1.1.1.1" xref="S2.E2.m2.1.1.1.1.1.1.cmml"><mi id="S2.E2.m2.1.1.1.1.1.1.2" xref="S2.E2.m2.1.1.1.1.1.1.2.cmml">x</mi><mi id="S2.E2.m2.1.1.1.1.1.1.3" xref="S2.E2.m2.1.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S2.E2.m2.1.1.1.1.1.3" xref="S2.E2.m2.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.E2.m2.1.1.5" xref="S2.E2.m2.1.1.5.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S2.E2.m2.1.1.6" xref="S2.E2.m2.1.1.6.cmml">𝒳</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.E2.m2.1b"><apply id="S2.E2.m2.1.1.cmml" xref="S2.E2.m2.1.1"><and id="S2.E2.m2.1.1a.cmml" xref="S2.E2.m2.1.1"></and><apply id="S2.E2.m2.1.1b.cmml" xref="S2.E2.m2.1.1"><eq id="S2.E2.m2.1.1.4.cmml" xref="S2.E2.m2.1.1.4"></eq><csymbol cd="latexml" id="S2.E2.m2.1.1.3.cmml" xref="S2.E2.m2.1.1.3">absent</csymbol><apply id="S2.E2.m2.1.1.1.cmml" xref="S2.E2.m2.1.1.1"><times id="S2.E2.m2.1.1.1.2.cmml" xref="S2.E2.m2.1.1.1.2"></times><ci id="S2.E2.m2.1.1.1.3a.cmml" xref="S2.E2.m2.1.1.1.3"><mtext id="S2.E2.m2.1.1.1.3.cmml" xref="S2.E2.m2.1.1.1.3">TextEncoder</mtext></ci><apply id="S2.E2.m2.1.1.1.1.1.1.cmml" xref="S2.E2.m2.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E2.m2.1.1.1.1.1.1.1.cmml" xref="S2.E2.m2.1.1.1.1.1">subscript</csymbol><ci id="S2.E2.m2.1.1.1.1.1.1.2.cmml" xref="S2.E2.m2.1.1.1.1.1.1.2">𝑥</ci><ci id="S2.E2.m2.1.1.1.1.1.1.3.cmml" xref="S2.E2.m2.1.1.1.1.1.1.3">𝑖</ci></apply></apply></apply><apply id="S2.E2.m2.1.1c.cmml" xref="S2.E2.m2.1.1"><in id="S2.E2.m2.1.1.5.cmml" xref="S2.E2.m2.1.1.5"></in><share href="#S2.E2.m2.1.1.1.cmml" id="S2.E2.m2.1.1d.cmml" xref="S2.E2.m2.1.1"></share><ci id="S2.E2.m2.1.1.6.cmml" xref="S2.E2.m2.1.1.6">𝒳</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E2.m2.1c">\displaystyle=\text{TextEncoder}(x_{i})\in\mathcal{X}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
<div id="S2.SS0.SSS0.Px1.p2" class="ltx_para">
<p id="S2.SS0.SSS0.Px1.p2.7" class="ltx_p">Most prior works learn a discriminative model <math id="S2.SS0.SSS0.Px1.p2.1.m1.1" class="ltx_Math" alttext="f_{\theta}" display="inline"><semantics id="S2.SS0.SSS0.Px1.p2.1.m1.1a"><msub id="S2.SS0.SSS0.Px1.p2.1.m1.1.1" xref="S2.SS0.SSS0.Px1.p2.1.m1.1.1.cmml"><mi id="S2.SS0.SSS0.Px1.p2.1.m1.1.1.2" xref="S2.SS0.SSS0.Px1.p2.1.m1.1.1.2.cmml">f</mi><mi id="S2.SS0.SSS0.Px1.p2.1.m1.1.1.3" xref="S2.SS0.SSS0.Px1.p2.1.m1.1.1.3.cmml">θ</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p2.1.m1.1b"><apply id="S2.SS0.SSS0.Px1.p2.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px1.p2.1.m1.1.1.1.cmml" xref="S2.SS0.SSS0.Px1.p2.1.m1.1.1">subscript</csymbol><ci id="S2.SS0.SSS0.Px1.p2.1.m1.1.1.2.cmml" xref="S2.SS0.SSS0.Px1.p2.1.m1.1.1.2">𝑓</ci><ci id="S2.SS0.SSS0.Px1.p2.1.m1.1.1.3.cmml" xref="S2.SS0.SSS0.Px1.p2.1.m1.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p2.1.m1.1c">f_{\theta}</annotation></semantics></math> that directly estimates a probability distribution over all possible answers in a pre-defined label set, i.e., <math id="S2.SS0.SSS0.Px1.p2.2.m2.2" class="ltx_Math" alttext="f_{\theta}:\mathcal{V},\mathcal{X}\rightarrow\mathcal{Y}" display="inline"><semantics id="S2.SS0.SSS0.Px1.p2.2.m2.2a"><mrow id="S2.SS0.SSS0.Px1.p2.2.m2.2.3" xref="S2.SS0.SSS0.Px1.p2.2.m2.2.3.cmml"><msub id="S2.SS0.SSS0.Px1.p2.2.m2.2.3.2" xref="S2.SS0.SSS0.Px1.p2.2.m2.2.3.2.cmml"><mi id="S2.SS0.SSS0.Px1.p2.2.m2.2.3.2.2" xref="S2.SS0.SSS0.Px1.p2.2.m2.2.3.2.2.cmml">f</mi><mi id="S2.SS0.SSS0.Px1.p2.2.m2.2.3.2.3" xref="S2.SS0.SSS0.Px1.p2.2.m2.2.3.2.3.cmml">θ</mi></msub><mo lspace="0.278em" rspace="0.278em" id="S2.SS0.SSS0.Px1.p2.2.m2.2.3.1" xref="S2.SS0.SSS0.Px1.p2.2.m2.2.3.1.cmml">:</mo><mrow id="S2.SS0.SSS0.Px1.p2.2.m2.2.3.3" xref="S2.SS0.SSS0.Px1.p2.2.m2.2.3.3.cmml"><mrow id="S2.SS0.SSS0.Px1.p2.2.m2.2.3.3.2.2" xref="S2.SS0.SSS0.Px1.p2.2.m2.2.3.3.2.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS0.SSS0.Px1.p2.2.m2.1.1" xref="S2.SS0.SSS0.Px1.p2.2.m2.1.1.cmml">𝒱</mi><mo id="S2.SS0.SSS0.Px1.p2.2.m2.2.3.3.2.2.1" xref="S2.SS0.SSS0.Px1.p2.2.m2.2.3.3.2.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS0.SSS0.Px1.p2.2.m2.2.2" xref="S2.SS0.SSS0.Px1.p2.2.m2.2.2.cmml">𝒳</mi></mrow><mo stretchy="false" id="S2.SS0.SSS0.Px1.p2.2.m2.2.3.3.1" xref="S2.SS0.SSS0.Px1.p2.2.m2.2.3.3.1.cmml">→</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS0.SSS0.Px1.p2.2.m2.2.3.3.3" xref="S2.SS0.SSS0.Px1.p2.2.m2.2.3.3.3.cmml">𝒴</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p2.2.m2.2b"><apply id="S2.SS0.SSS0.Px1.p2.2.m2.2.3.cmml" xref="S2.SS0.SSS0.Px1.p2.2.m2.2.3"><ci id="S2.SS0.SSS0.Px1.p2.2.m2.2.3.1.cmml" xref="S2.SS0.SSS0.Px1.p2.2.m2.2.3.1">:</ci><apply id="S2.SS0.SSS0.Px1.p2.2.m2.2.3.2.cmml" xref="S2.SS0.SSS0.Px1.p2.2.m2.2.3.2"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px1.p2.2.m2.2.3.2.1.cmml" xref="S2.SS0.SSS0.Px1.p2.2.m2.2.3.2">subscript</csymbol><ci id="S2.SS0.SSS0.Px1.p2.2.m2.2.3.2.2.cmml" xref="S2.SS0.SSS0.Px1.p2.2.m2.2.3.2.2">𝑓</ci><ci id="S2.SS0.SSS0.Px1.p2.2.m2.2.3.2.3.cmml" xref="S2.SS0.SSS0.Px1.p2.2.m2.2.3.2.3">𝜃</ci></apply><apply id="S2.SS0.SSS0.Px1.p2.2.m2.2.3.3.cmml" xref="S2.SS0.SSS0.Px1.p2.2.m2.2.3.3"><ci id="S2.SS0.SSS0.Px1.p2.2.m2.2.3.3.1.cmml" xref="S2.SS0.SSS0.Px1.p2.2.m2.2.3.3.1">→</ci><list id="S2.SS0.SSS0.Px1.p2.2.m2.2.3.3.2.1.cmml" xref="S2.SS0.SSS0.Px1.p2.2.m2.2.3.3.2.2"><ci id="S2.SS0.SSS0.Px1.p2.2.m2.1.1.cmml" xref="S2.SS0.SSS0.Px1.p2.2.m2.1.1">𝒱</ci><ci id="S2.SS0.SSS0.Px1.p2.2.m2.2.2.cmml" xref="S2.SS0.SSS0.Px1.p2.2.m2.2.2">𝒳</ci></list><ci id="S2.SS0.SSS0.Px1.p2.2.m2.2.3.3.3.cmml" xref="S2.SS0.SSS0.Px1.p2.2.m2.2.3.3.3">𝒴</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p2.2.m2.2c">f_{\theta}:\mathcal{V},\mathcal{X}\rightarrow\mathcal{Y}</annotation></semantics></math>. In contrast, we adopt a generative model <math id="S2.SS0.SSS0.Px1.p2.3.m3.1" class="ltx_Math" alttext="g_{\phi}" display="inline"><semantics id="S2.SS0.SSS0.Px1.p2.3.m3.1a"><msub id="S2.SS0.SSS0.Px1.p2.3.m3.1.1" xref="S2.SS0.SSS0.Px1.p2.3.m3.1.1.cmml"><mi id="S2.SS0.SSS0.Px1.p2.3.m3.1.1.2" xref="S2.SS0.SSS0.Px1.p2.3.m3.1.1.2.cmml">g</mi><mi id="S2.SS0.SSS0.Px1.p2.3.m3.1.1.3" xref="S2.SS0.SSS0.Px1.p2.3.m3.1.1.3.cmml">ϕ</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p2.3.m3.1b"><apply id="S2.SS0.SSS0.Px1.p2.3.m3.1.1.cmml" xref="S2.SS0.SSS0.Px1.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px1.p2.3.m3.1.1.1.cmml" xref="S2.SS0.SSS0.Px1.p2.3.m3.1.1">subscript</csymbol><ci id="S2.SS0.SSS0.Px1.p2.3.m3.1.1.2.cmml" xref="S2.SS0.SSS0.Px1.p2.3.m3.1.1.2">𝑔</ci><ci id="S2.SS0.SSS0.Px1.p2.3.m3.1.1.3.cmml" xref="S2.SS0.SSS0.Px1.p2.3.m3.1.1.3">italic-ϕ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p2.3.m3.1c">g_{\phi}</annotation></semantics></math> that predicts words in a vocabulary <math id="S2.SS0.SSS0.Px1.p2.4.m4.1" class="ltx_Math" alttext="\Sigma" display="inline"><semantics id="S2.SS0.SSS0.Px1.p2.4.m4.1a"><mi mathvariant="normal" id="S2.SS0.SSS0.Px1.p2.4.m4.1.1" xref="S2.SS0.SSS0.Px1.p2.4.m4.1.1.cmml">Σ</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p2.4.m4.1b"><ci id="S2.SS0.SSS0.Px1.p2.4.m4.1.1.cmml" xref="S2.SS0.SSS0.Px1.p2.4.m4.1.1">Σ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p2.4.m4.1c">\Sigma</annotation></semantics></math> to generate a varying length text string <math id="S2.SS0.SSS0.Px1.p2.5.m5.1" class="ltx_Math" alttext="z\in\Sigma^{+}" display="inline"><semantics id="S2.SS0.SSS0.Px1.p2.5.m5.1a"><mrow id="S2.SS0.SSS0.Px1.p2.5.m5.1.1" xref="S2.SS0.SSS0.Px1.p2.5.m5.1.1.cmml"><mi id="S2.SS0.SSS0.Px1.p2.5.m5.1.1.2" xref="S2.SS0.SSS0.Px1.p2.5.m5.1.1.2.cmml">z</mi><mo id="S2.SS0.SSS0.Px1.p2.5.m5.1.1.1" xref="S2.SS0.SSS0.Px1.p2.5.m5.1.1.1.cmml">∈</mo><msup id="S2.SS0.SSS0.Px1.p2.5.m5.1.1.3" xref="S2.SS0.SSS0.Px1.p2.5.m5.1.1.3.cmml"><mi mathvariant="normal" id="S2.SS0.SSS0.Px1.p2.5.m5.1.1.3.2" xref="S2.SS0.SSS0.Px1.p2.5.m5.1.1.3.2.cmml">Σ</mi><mo id="S2.SS0.SSS0.Px1.p2.5.m5.1.1.3.3" xref="S2.SS0.SSS0.Px1.p2.5.m5.1.1.3.3.cmml">+</mo></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p2.5.m5.1b"><apply id="S2.SS0.SSS0.Px1.p2.5.m5.1.1.cmml" xref="S2.SS0.SSS0.Px1.p2.5.m5.1.1"><in id="S2.SS0.SSS0.Px1.p2.5.m5.1.1.1.cmml" xref="S2.SS0.SSS0.Px1.p2.5.m5.1.1.1"></in><ci id="S2.SS0.SSS0.Px1.p2.5.m5.1.1.2.cmml" xref="S2.SS0.SSS0.Px1.p2.5.m5.1.1.2">𝑧</ci><apply id="S2.SS0.SSS0.Px1.p2.5.m5.1.1.3.cmml" xref="S2.SS0.SSS0.Px1.p2.5.m5.1.1.3"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px1.p2.5.m5.1.1.3.1.cmml" xref="S2.SS0.SSS0.Px1.p2.5.m5.1.1.3">superscript</csymbol><ci id="S2.SS0.SSS0.Px1.p2.5.m5.1.1.3.2.cmml" xref="S2.SS0.SSS0.Px1.p2.5.m5.1.1.3.2">Σ</ci><plus id="S2.SS0.SSS0.Px1.p2.5.m5.1.1.3.3.cmml" xref="S2.SS0.SSS0.Px1.p2.5.m5.1.1.3.3"></plus></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p2.5.m5.1c">z\in\Sigma^{+}</annotation></semantics></math>, and apply a deterministic function to map the answer string <math id="S2.SS0.SSS0.Px1.p2.6.m6.1" class="ltx_Math" alttext="z" display="inline"><semantics id="S2.SS0.SSS0.Px1.p2.6.m6.1a"><mi id="S2.SS0.SSS0.Px1.p2.6.m6.1.1" xref="S2.SS0.SSS0.Px1.p2.6.m6.1.1.cmml">z</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p2.6.m6.1b"><ci id="S2.SS0.SSS0.Px1.p2.6.m6.1.1.cmml" xref="S2.SS0.SSS0.Px1.p2.6.m6.1.1">𝑧</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p2.6.m6.1c">z</annotation></semantics></math> to the closest answer label <math id="S2.SS0.SSS0.Px1.p2.7.m7.1" class="ltx_Math" alttext="y\in\mathcal{Y}" display="inline"><semantics id="S2.SS0.SSS0.Px1.p2.7.m7.1a"><mrow id="S2.SS0.SSS0.Px1.p2.7.m7.1.1" xref="S2.SS0.SSS0.Px1.p2.7.m7.1.1.cmml"><mi id="S2.SS0.SSS0.Px1.p2.7.m7.1.1.2" xref="S2.SS0.SSS0.Px1.p2.7.m7.1.1.2.cmml">y</mi><mo id="S2.SS0.SSS0.Px1.p2.7.m7.1.1.1" xref="S2.SS0.SSS0.Px1.p2.7.m7.1.1.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S2.SS0.SSS0.Px1.p2.7.m7.1.1.3" xref="S2.SS0.SSS0.Px1.p2.7.m7.1.1.3.cmml">𝒴</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p2.7.m7.1b"><apply id="S2.SS0.SSS0.Px1.p2.7.m7.1.1.cmml" xref="S2.SS0.SSS0.Px1.p2.7.m7.1.1"><in id="S2.SS0.SSS0.Px1.p2.7.m7.1.1.1.cmml" xref="S2.SS0.SSS0.Px1.p2.7.m7.1.1.1"></in><ci id="S2.SS0.SSS0.Px1.p2.7.m7.1.1.2.cmml" xref="S2.SS0.SSS0.Px1.p2.7.m7.1.1.2">𝑦</ci><ci id="S2.SS0.SSS0.Px1.p2.7.m7.1.1.3.cmml" xref="S2.SS0.SSS0.Px1.p2.7.m7.1.1.3">𝒴</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p2.7.m7.1c">y\in\mathcal{Y}</annotation></semantics></math>.</p>
</div>
</section>
<section id="S2.SS0.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Dataset Adaptation:</h4>

<div id="S2.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S2.SS0.SSS0.Px2.p1.6" class="ltx_p">We also focus on a dataset adaptation setting where a model is trained on a source labeled dataset <math id="S2.SS0.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{D}_{\text{src}}" display="inline"><semantics id="S2.SS0.SSS0.Px2.p1.1.m1.1a"><msub id="S2.SS0.SSS0.Px2.p1.1.m1.1.1" xref="S2.SS0.SSS0.Px2.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS0.SSS0.Px2.p1.1.m1.1.1.2" xref="S2.SS0.SSS0.Px2.p1.1.m1.1.1.2.cmml">𝒟</mi><mtext id="S2.SS0.SSS0.Px2.p1.1.m1.1.1.3" xref="S2.SS0.SSS0.Px2.p1.1.m1.1.1.3a.cmml">src</mtext></msub><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p1.1.m1.1b"><apply id="S2.SS0.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.1.m1.1.1">subscript</csymbol><ci id="S2.SS0.SSS0.Px2.p1.1.m1.1.1.2.cmml" xref="S2.SS0.SSS0.Px2.p1.1.m1.1.1.2">𝒟</ci><ci id="S2.SS0.SSS0.Px2.p1.1.m1.1.1.3a.cmml" xref="S2.SS0.SSS0.Px2.p1.1.m1.1.1.3"><mtext mathsize="70%" id="S2.SS0.SSS0.Px2.p1.1.m1.1.1.3.cmml" xref="S2.SS0.SSS0.Px2.p1.1.m1.1.1.3">src</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p1.1.m1.1c">\mathcal{D}_{\text{src}}</annotation></semantics></math> and further adapted to a target dataset <math id="S2.SS0.SSS0.Px2.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{D}_{\text{tgt}}" display="inline"><semantics id="S2.SS0.SSS0.Px2.p1.2.m2.1a"><msub id="S2.SS0.SSS0.Px2.p1.2.m2.1.1" xref="S2.SS0.SSS0.Px2.p1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS0.SSS0.Px2.p1.2.m2.1.1.2" xref="S2.SS0.SSS0.Px2.p1.2.m2.1.1.2.cmml">𝒟</mi><mtext id="S2.SS0.SSS0.Px2.p1.2.m2.1.1.3" xref="S2.SS0.SSS0.Px2.p1.2.m2.1.1.3a.cmml">tgt</mtext></msub><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p1.2.m2.1b"><apply id="S2.SS0.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px2.p1.2.m2.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.2.m2.1.1">subscript</csymbol><ci id="S2.SS0.SSS0.Px2.p1.2.m2.1.1.2.cmml" xref="S2.SS0.SSS0.Px2.p1.2.m2.1.1.2">𝒟</ci><ci id="S2.SS0.SSS0.Px2.p1.2.m2.1.1.3a.cmml" xref="S2.SS0.SSS0.Px2.p1.2.m2.1.1.3"><mtext mathsize="70%" id="S2.SS0.SSS0.Px2.p1.2.m2.1.1.3.cmml" xref="S2.SS0.SSS0.Px2.p1.2.m2.1.1.3">tgt</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p1.2.m2.1c">\mathcal{D}_{\text{tgt}}</annotation></semantics></math> with a different label set, i.e., <math id="S2.SS0.SSS0.Px2.p1.3.m3.1" class="ltx_Math" alttext="\mathcal{Y}_{\text{src}}\neq\mathcal{Y}_{\text{tgt}}" display="inline"><semantics id="S2.SS0.SSS0.Px2.p1.3.m3.1a"><mrow id="S2.SS0.SSS0.Px2.p1.3.m3.1.1" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.cmml"><msub id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.2" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.2.2" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.2.2.cmml">𝒴</mi><mtext id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.2.3" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.2.3a.cmml">src</mtext></msub><mo id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.cmml">≠</mo><msub id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.3" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.3.2" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.3.2.cmml">𝒴</mi><mtext id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.3.3" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.3.3a.cmml">tgt</mtext></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p1.3.m3.1b"><apply id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1"><neq id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1"></neq><apply id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.2.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.2"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.2.1.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.2">subscript</csymbol><ci id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.2.2.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.2.2">𝒴</ci><ci id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.2.3a.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.2.3"><mtext mathsize="70%" id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.2.3.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.2.3">src</mtext></ci></apply><apply id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.3.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.3"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.3.1.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.3">subscript</csymbol><ci id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.3.2.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.3.2">𝒴</ci><ci id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.3.3a.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.3.3"><mtext mathsize="70%" id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.3.3.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.3.3">tgt</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p1.3.m3.1c">\mathcal{Y}_{\text{src}}\neq\mathcal{Y}_{\text{tgt}}</annotation></semantics></math>. Thus, it is nontrivial for a discriminative model <math id="S2.SS0.SSS0.Px2.p1.4.m4.1" class="ltx_Math" alttext="f_{\theta}" display="inline"><semantics id="S2.SS0.SSS0.Px2.p1.4.m4.1a"><msub id="S2.SS0.SSS0.Px2.p1.4.m4.1.1" xref="S2.SS0.SSS0.Px2.p1.4.m4.1.1.cmml"><mi id="S2.SS0.SSS0.Px2.p1.4.m4.1.1.2" xref="S2.SS0.SSS0.Px2.p1.4.m4.1.1.2.cmml">f</mi><mi id="S2.SS0.SSS0.Px2.p1.4.m4.1.1.3" xref="S2.SS0.SSS0.Px2.p1.4.m4.1.1.3.cmml">θ</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p1.4.m4.1b"><apply id="S2.SS0.SSS0.Px2.p1.4.m4.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px2.p1.4.m4.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.4.m4.1.1">subscript</csymbol><ci id="S2.SS0.SSS0.Px2.p1.4.m4.1.1.2.cmml" xref="S2.SS0.SSS0.Px2.p1.4.m4.1.1.2">𝑓</ci><ci id="S2.SS0.SSS0.Px2.p1.4.m4.1.1.3.cmml" xref="S2.SS0.SSS0.Px2.p1.4.m4.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p1.4.m4.1c">f_{\theta}</annotation></semantics></math> to perform adaptation over different label sets. For adaptation with generative models, we consider two strategies of using target labeled data for (a) in-context prediction without updating the source-trained models <math id="S2.SS0.SSS0.Px2.p1.5.m5.1" class="ltx_Math" alttext="g_{\phi}" display="inline"><semantics id="S2.SS0.SSS0.Px2.p1.5.m5.1a"><msub id="S2.SS0.SSS0.Px2.p1.5.m5.1.1" xref="S2.SS0.SSS0.Px2.p1.5.m5.1.1.cmml"><mi id="S2.SS0.SSS0.Px2.p1.5.m5.1.1.2" xref="S2.SS0.SSS0.Px2.p1.5.m5.1.1.2.cmml">g</mi><mi id="S2.SS0.SSS0.Px2.p1.5.m5.1.1.3" xref="S2.SS0.SSS0.Px2.p1.5.m5.1.1.3.cmml">ϕ</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p1.5.m5.1b"><apply id="S2.SS0.SSS0.Px2.p1.5.m5.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px2.p1.5.m5.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.5.m5.1.1">subscript</csymbol><ci id="S2.SS0.SSS0.Px2.p1.5.m5.1.1.2.cmml" xref="S2.SS0.SSS0.Px2.p1.5.m5.1.1.2">𝑔</ci><ci id="S2.SS0.SSS0.Px2.p1.5.m5.1.1.3.cmml" xref="S2.SS0.SSS0.Px2.p1.5.m5.1.1.3">italic-ϕ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p1.5.m5.1c">g_{\phi}</annotation></semantics></math> and (b) continued fine-tuning <math id="S2.SS0.SSS0.Px2.p1.6.m6.1" class="ltx_Math" alttext="g_{\phi}" display="inline"><semantics id="S2.SS0.SSS0.Px2.p1.6.m6.1a"><msub id="S2.SS0.SSS0.Px2.p1.6.m6.1.1" xref="S2.SS0.SSS0.Px2.p1.6.m6.1.1.cmml"><mi id="S2.SS0.SSS0.Px2.p1.6.m6.1.1.2" xref="S2.SS0.SSS0.Px2.p1.6.m6.1.1.2.cmml">g</mi><mi id="S2.SS0.SSS0.Px2.p1.6.m6.1.1.3" xref="S2.SS0.SSS0.Px2.p1.6.m6.1.1.3.cmml">ϕ</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p1.6.m6.1b"><apply id="S2.SS0.SSS0.Px2.p1.6.m6.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px2.p1.6.m6.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.6.m6.1.1">subscript</csymbol><ci id="S2.SS0.SSS0.Px2.p1.6.m6.1.1.2.cmml" xref="S2.SS0.SSS0.Px2.p1.6.m6.1.1.2">𝑔</ci><ci id="S2.SS0.SSS0.Px2.p1.6.m6.1.1.3.cmml" xref="S2.SS0.SSS0.Px2.p1.6.m6.1.1.3">italic-ϕ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p1.6.m6.1c">g_{\phi}</annotation></semantics></math>. While our method focuses on in-context prediction (§<a href="#S3" title="3 Methods ‣ Multimodal Prompt Retrieval for Generative Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>), we also compare these two strategies in our experiments (§<a href="#S5" title="5 Results and Analysis ‣ Multimodal Prompt Retrieval for Generative Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>).</p>
</div>
</section>
<section id="S2.SS0.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Types of Medical VQA:</h4>

<div id="S2.SS0.SSS0.Px3.p1" class="ltx_para">
<p id="S2.SS0.SSS0.Px3.p1.2" class="ltx_p">According to the annotations of popular medical VQA tasks (e.g., SLAKE <cite class="ltx_cite ltx_citemacro_cite">Liu et al. (<a href="#bib.bib24" title="" class="ltx_ref">2021</a>)</cite> and VQA-RAD <cite class="ltx_cite ltx_citemacro_cite">Lau et al. (<a href="#bib.bib18" title="" class="ltx_ref">2018</a>)</cite>), there are two answer types <math id="S2.SS0.SSS0.Px3.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{A}_{\text{type}}" display="inline"><semantics id="S2.SS0.SSS0.Px3.p1.1.m1.1a"><msub id="S2.SS0.SSS0.Px3.p1.1.m1.1.1" xref="S2.SS0.SSS0.Px3.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS0.SSS0.Px3.p1.1.m1.1.1.2" xref="S2.SS0.SSS0.Px3.p1.1.m1.1.1.2.cmml">𝒜</mi><mtext id="S2.SS0.SSS0.Px3.p1.1.m1.1.1.3" xref="S2.SS0.SSS0.Px3.p1.1.m1.1.1.3a.cmml">type</mtext></msub><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px3.p1.1.m1.1b"><apply id="S2.SS0.SSS0.Px3.p1.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px3.p1.1.m1.1.1.1.cmml" xref="S2.SS0.SSS0.Px3.p1.1.m1.1.1">subscript</csymbol><ci id="S2.SS0.SSS0.Px3.p1.1.m1.1.1.2.cmml" xref="S2.SS0.SSS0.Px3.p1.1.m1.1.1.2">𝒜</ci><ci id="S2.SS0.SSS0.Px3.p1.1.m1.1.1.3a.cmml" xref="S2.SS0.SSS0.Px3.p1.1.m1.1.1.3"><mtext mathsize="70%" id="S2.SS0.SSS0.Px3.p1.1.m1.1.1.3.cmml" xref="S2.SS0.SSS0.Px3.p1.1.m1.1.1.3">type</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px3.p1.1.m1.1c">\mathcal{A}_{\text{type}}</annotation></semantics></math>: <span id="S2.SS0.SSS0.Px3.p1.2.1" class="ltx_text ltx_font_italic">closed</span> answers where the set of possible answers are disclosed in a question (e.g., yes-no questions); and <span id="S2.SS0.SSS0.Px3.p1.2.2" class="ltx_text ltx_font_italic">open</span> answers that can be free-form texts. Besides, there are multiple different question types <math id="S2.SS0.SSS0.Px3.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{Q}_{\text{type}}" display="inline"><semantics id="S2.SS0.SSS0.Px3.p1.2.m2.1a"><msub id="S2.SS0.SSS0.Px3.p1.2.m2.1.1" xref="S2.SS0.SSS0.Px3.p1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS0.SSS0.Px3.p1.2.m2.1.1.2" xref="S2.SS0.SSS0.Px3.p1.2.m2.1.1.2.cmml">𝒬</mi><mtext id="S2.SS0.SSS0.Px3.p1.2.m2.1.1.3" xref="S2.SS0.SSS0.Px3.p1.2.m2.1.1.3a.cmml">type</mtext></msub><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px3.p1.2.m2.1b"><apply id="S2.SS0.SSS0.Px3.p1.2.m2.1.1.cmml" xref="S2.SS0.SSS0.Px3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px3.p1.2.m2.1.1.1.cmml" xref="S2.SS0.SSS0.Px3.p1.2.m2.1.1">subscript</csymbol><ci id="S2.SS0.SSS0.Px3.p1.2.m2.1.1.2.cmml" xref="S2.SS0.SSS0.Px3.p1.2.m2.1.1.2">𝒬</ci><ci id="S2.SS0.SSS0.Px3.p1.2.m2.1.1.3a.cmml" xref="S2.SS0.SSS0.Px3.p1.2.m2.1.1.3"><mtext mathsize="70%" id="S2.SS0.SSS0.Px3.p1.2.m2.1.1.3.cmml" xref="S2.SS0.SSS0.Px3.p1.2.m2.1.1.3">type</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px3.p1.2.m2.1c">\mathcal{Q}_{\text{type}}</annotation></semantics></math> such as organ, abnormality, or modality, indicating the medicinal category for which the question is intended. Prior medical VQA models <cite class="ltx_cite ltx_citemacro_cite">Zhan et al. (<a href="#bib.bib43" title="" class="ltx_ref">2020</a>); Eslami et al. (<a href="#bib.bib6" title="" class="ltx_ref">2021</a>)</cite> use a binary classifier to distinguish the two answer types based on questions and apply two discriminative models to predict answers, while we propose to predict both types of answers by a single generative model in this work.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Methods</h2>

<figure id="S3.F1" class="ltx_figure"><img src="/html/2306.17675/assets/x1.png" id="S3.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="298" height="138" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>An overview of multimodal prompt retrieval (MPR). There are three primary components of the prompt we use for the encoder indicated by the three yellow boxes contained in the T5 encoder block. These components can be optionally omitted or further extended with additional data.</figcaption>
</figure>
<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">In this section, we start by introducing the text and image encoding for retrieval (§<a href="#S3.SS1" title="3.1 Multimodal Prompt Encoding ‣ 3 Methods ‣ Multimodal Prompt Retrieval for Generative Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a>), then describe the prompt construction from retrieval (§<a href="#S3.SS3" title="3.3 Prompt Construction ‣ 3 Methods ‣ Multimodal Prompt Retrieval for Generative Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3</span></a>), and prompt integration in our generative model (§<a href="#S3.SS4" title="3.4 Generative Visual Question Answering ‣ 3 Methods ‣ Multimodal Prompt Retrieval for Generative Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.4</span></a>).</p>
</div>
<section id="S3.SS0.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Overview:</h4>

<div id="S3.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS0.SSS0.Px1.p1.6" class="ltx_p">For each <math id="S3.SS0.SSS0.Px1.p1.1.m1.3" class="ltx_Math" alttext="(v,x,y)\in\mathcal{D}_{\text{src}}" display="inline"><semantics id="S3.SS0.SSS0.Px1.p1.1.m1.3a"><mrow id="S3.SS0.SSS0.Px1.p1.1.m1.3.4" xref="S3.SS0.SSS0.Px1.p1.1.m1.3.4.cmml"><mrow id="S3.SS0.SSS0.Px1.p1.1.m1.3.4.2.2" xref="S3.SS0.SSS0.Px1.p1.1.m1.3.4.2.1.cmml"><mo stretchy="false" id="S3.SS0.SSS0.Px1.p1.1.m1.3.4.2.2.1" xref="S3.SS0.SSS0.Px1.p1.1.m1.3.4.2.1.cmml">(</mo><mi id="S3.SS0.SSS0.Px1.p1.1.m1.1.1" xref="S3.SS0.SSS0.Px1.p1.1.m1.1.1.cmml">v</mi><mo id="S3.SS0.SSS0.Px1.p1.1.m1.3.4.2.2.2" xref="S3.SS0.SSS0.Px1.p1.1.m1.3.4.2.1.cmml">,</mo><mi id="S3.SS0.SSS0.Px1.p1.1.m1.2.2" xref="S3.SS0.SSS0.Px1.p1.1.m1.2.2.cmml">x</mi><mo id="S3.SS0.SSS0.Px1.p1.1.m1.3.4.2.2.3" xref="S3.SS0.SSS0.Px1.p1.1.m1.3.4.2.1.cmml">,</mo><mi id="S3.SS0.SSS0.Px1.p1.1.m1.3.3" xref="S3.SS0.SSS0.Px1.p1.1.m1.3.3.cmml">y</mi><mo stretchy="false" id="S3.SS0.SSS0.Px1.p1.1.m1.3.4.2.2.4" xref="S3.SS0.SSS0.Px1.p1.1.m1.3.4.2.1.cmml">)</mo></mrow><mo id="S3.SS0.SSS0.Px1.p1.1.m1.3.4.1" xref="S3.SS0.SSS0.Px1.p1.1.m1.3.4.1.cmml">∈</mo><msub id="S3.SS0.SSS0.Px1.p1.1.m1.3.4.3" xref="S3.SS0.SSS0.Px1.p1.1.m1.3.4.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS0.Px1.p1.1.m1.3.4.3.2" xref="S3.SS0.SSS0.Px1.p1.1.m1.3.4.3.2.cmml">𝒟</mi><mtext id="S3.SS0.SSS0.Px1.p1.1.m1.3.4.3.3" xref="S3.SS0.SSS0.Px1.p1.1.m1.3.4.3.3a.cmml">src</mtext></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p1.1.m1.3b"><apply id="S3.SS0.SSS0.Px1.p1.1.m1.3.4.cmml" xref="S3.SS0.SSS0.Px1.p1.1.m1.3.4"><in id="S3.SS0.SSS0.Px1.p1.1.m1.3.4.1.cmml" xref="S3.SS0.SSS0.Px1.p1.1.m1.3.4.1"></in><vector id="S3.SS0.SSS0.Px1.p1.1.m1.3.4.2.1.cmml" xref="S3.SS0.SSS0.Px1.p1.1.m1.3.4.2.2"><ci id="S3.SS0.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.1.m1.1.1">𝑣</ci><ci id="S3.SS0.SSS0.Px1.p1.1.m1.2.2.cmml" xref="S3.SS0.SSS0.Px1.p1.1.m1.2.2">𝑥</ci><ci id="S3.SS0.SSS0.Px1.p1.1.m1.3.3.cmml" xref="S3.SS0.SSS0.Px1.p1.1.m1.3.3">𝑦</ci></vector><apply id="S3.SS0.SSS0.Px1.p1.1.m1.3.4.3.cmml" xref="S3.SS0.SSS0.Px1.p1.1.m1.3.4.3"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px1.p1.1.m1.3.4.3.1.cmml" xref="S3.SS0.SSS0.Px1.p1.1.m1.3.4.3">subscript</csymbol><ci id="S3.SS0.SSS0.Px1.p1.1.m1.3.4.3.2.cmml" xref="S3.SS0.SSS0.Px1.p1.1.m1.3.4.3.2">𝒟</ci><ci id="S3.SS0.SSS0.Px1.p1.1.m1.3.4.3.3a.cmml" xref="S3.SS0.SSS0.Px1.p1.1.m1.3.4.3.3"><mtext mathsize="70%" id="S3.SS0.SSS0.Px1.p1.1.m1.3.4.3.3.cmml" xref="S3.SS0.SSS0.Px1.p1.1.m1.3.4.3.3">src</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p1.1.m1.3c">(v,x,y)\in\mathcal{D}_{\text{src}}</annotation></semantics></math> during training, we propose to retrieve similar tuples from the training dataset <math id="S3.SS0.SSS0.Px1.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{D}_{\text{src}}" display="inline"><semantics id="S3.SS0.SSS0.Px1.p1.2.m2.1a"><msub id="S3.SS0.SSS0.Px1.p1.2.m2.1.1" xref="S3.SS0.SSS0.Px1.p1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS0.Px1.p1.2.m2.1.1.2" xref="S3.SS0.SSS0.Px1.p1.2.m2.1.1.2.cmml">𝒟</mi><mtext id="S3.SS0.SSS0.Px1.p1.2.m2.1.1.3" xref="S3.SS0.SSS0.Px1.p1.2.m2.1.1.3a.cmml">src</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p1.2.m2.1b"><apply id="S3.SS0.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px1.p1.2.m2.1.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS0.SSS0.Px1.p1.2.m2.1.1.2.cmml" xref="S3.SS0.SSS0.Px1.p1.2.m2.1.1.2">𝒟</ci><ci id="S3.SS0.SSS0.Px1.p1.2.m2.1.1.3a.cmml" xref="S3.SS0.SSS0.Px1.p1.2.m2.1.1.3"><mtext mathsize="70%" id="S3.SS0.SSS0.Px1.p1.2.m2.1.1.3.cmml" xref="S3.SS0.SSS0.Px1.p1.2.m2.1.1.3">src</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p1.2.m2.1c">\mathcal{D}_{\text{src}}</annotation></semantics></math>, integrate the retrieved tuples for prediction, and update the model. We also assume to have access to a target labeled dataset <math id="S3.SS0.SSS0.Px1.p1.3.m3.1" class="ltx_Math" alttext="\mathcal{D}_{\text{tgt}}" display="inline"><semantics id="S3.SS0.SSS0.Px1.p1.3.m3.1a"><msub id="S3.SS0.SSS0.Px1.p1.3.m3.1.1" xref="S3.SS0.SSS0.Px1.p1.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS0.Px1.p1.3.m3.1.1.2" xref="S3.SS0.SSS0.Px1.p1.3.m3.1.1.2.cmml">𝒟</mi><mtext id="S3.SS0.SSS0.Px1.p1.3.m3.1.1.3" xref="S3.SS0.SSS0.Px1.p1.3.m3.1.1.3a.cmml">tgt</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p1.3.m3.1b"><apply id="S3.SS0.SSS0.Px1.p1.3.m3.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px1.p1.3.m3.1.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS0.SSS0.Px1.p1.3.m3.1.1.2.cmml" xref="S3.SS0.SSS0.Px1.p1.3.m3.1.1.2">𝒟</ci><ci id="S3.SS0.SSS0.Px1.p1.3.m3.1.1.3a.cmml" xref="S3.SS0.SSS0.Px1.p1.3.m3.1.1.3"><mtext mathsize="70%" id="S3.SS0.SSS0.Px1.p1.3.m3.1.1.3.cmml" xref="S3.SS0.SSS0.Px1.p1.3.m3.1.1.3">tgt</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p1.3.m3.1c">\mathcal{D}_{\text{tgt}}</annotation></semantics></math> for dataset adaptation. Note that we mainly describe the in-context prediction using <math id="S3.SS0.SSS0.Px1.p1.4.m4.1" class="ltx_Math" alttext="\mathcal{D}_{\text{tgt}}" display="inline"><semantics id="S3.SS0.SSS0.Px1.p1.4.m4.1a"><msub id="S3.SS0.SSS0.Px1.p1.4.m4.1.1" xref="S3.SS0.SSS0.Px1.p1.4.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS0.Px1.p1.4.m4.1.1.2" xref="S3.SS0.SSS0.Px1.p1.4.m4.1.1.2.cmml">𝒟</mi><mtext id="S3.SS0.SSS0.Px1.p1.4.m4.1.1.3" xref="S3.SS0.SSS0.Px1.p1.4.m4.1.1.3a.cmml">tgt</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p1.4.m4.1b"><apply id="S3.SS0.SSS0.Px1.p1.4.m4.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px1.p1.4.m4.1.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.4.m4.1.1">subscript</csymbol><ci id="S3.SS0.SSS0.Px1.p1.4.m4.1.1.2.cmml" xref="S3.SS0.SSS0.Px1.p1.4.m4.1.1.2">𝒟</ci><ci id="S3.SS0.SSS0.Px1.p1.4.m4.1.1.3a.cmml" xref="S3.SS0.SSS0.Px1.p1.4.m4.1.1.3"><mtext mathsize="70%" id="S3.SS0.SSS0.Px1.p1.4.m4.1.1.3.cmml" xref="S3.SS0.SSS0.Px1.p1.4.m4.1.1.3">tgt</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p1.4.m4.1c">\mathcal{D}_{\text{tgt}}</annotation></semantics></math> here and leave the discussion of fine-tuning on <math id="S3.SS0.SSS0.Px1.p1.5.m5.1" class="ltx_Math" alttext="\mathcal{D}_{\text{tgt}}" display="inline"><semantics id="S3.SS0.SSS0.Px1.p1.5.m5.1a"><msub id="S3.SS0.SSS0.Px1.p1.5.m5.1.1" xref="S3.SS0.SSS0.Px1.p1.5.m5.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS0.Px1.p1.5.m5.1.1.2" xref="S3.SS0.SSS0.Px1.p1.5.m5.1.1.2.cmml">𝒟</mi><mtext id="S3.SS0.SSS0.Px1.p1.5.m5.1.1.3" xref="S3.SS0.SSS0.Px1.p1.5.m5.1.1.3a.cmml">tgt</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p1.5.m5.1b"><apply id="S3.SS0.SSS0.Px1.p1.5.m5.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px1.p1.5.m5.1.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.5.m5.1.1">subscript</csymbol><ci id="S3.SS0.SSS0.Px1.p1.5.m5.1.1.2.cmml" xref="S3.SS0.SSS0.Px1.p1.5.m5.1.1.2">𝒟</ci><ci id="S3.SS0.SSS0.Px1.p1.5.m5.1.1.3a.cmml" xref="S3.SS0.SSS0.Px1.p1.5.m5.1.1.3"><mtext mathsize="70%" id="S3.SS0.SSS0.Px1.p1.5.m5.1.1.3.cmml" xref="S3.SS0.SSS0.Px1.p1.5.m5.1.1.3">tgt</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p1.5.m5.1c">\mathcal{D}_{\text{tgt}}</annotation></semantics></math> to the experiments. When predicting a target test example at test time, we directly apply our source-trained model to retrieve labeled tuples from <math id="S3.SS0.SSS0.Px1.p1.6.m6.1" class="ltx_Math" alttext="\mathcal{D}_{\text{tgt}}" display="inline"><semantics id="S3.SS0.SSS0.Px1.p1.6.m6.1a"><msub id="S3.SS0.SSS0.Px1.p1.6.m6.1.1" xref="S3.SS0.SSS0.Px1.p1.6.m6.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS0.Px1.p1.6.m6.1.1.2" xref="S3.SS0.SSS0.Px1.p1.6.m6.1.1.2.cmml">𝒟</mi><mtext id="S3.SS0.SSS0.Px1.p1.6.m6.1.1.3" xref="S3.SS0.SSS0.Px1.p1.6.m6.1.1.3a.cmml">tgt</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p1.6.m6.1b"><apply id="S3.SS0.SSS0.Px1.p1.6.m6.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px1.p1.6.m6.1.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.6.m6.1.1">subscript</csymbol><ci id="S3.SS0.SSS0.Px1.p1.6.m6.1.1.2.cmml" xref="S3.SS0.SSS0.Px1.p1.6.m6.1.1.2">𝒟</ci><ci id="S3.SS0.SSS0.Px1.p1.6.m6.1.1.3a.cmml" xref="S3.SS0.SSS0.Px1.p1.6.m6.1.1.3"><mtext mathsize="70%" id="S3.SS0.SSS0.Px1.p1.6.m6.1.1.3.cmml" xref="S3.SS0.SSS0.Px1.p1.6.m6.1.1.3">tgt</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p1.6.m6.1c">\mathcal{D}_{\text{tgt}}</annotation></semantics></math> and perform prediction. The key insight is that even if the source-trained model is not directly trained on target data, the retrieved tuples may contain the correct answer to the given target question, potentially improving model predictions in the target dataset.</p>
</div>
</section>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Multimodal Prompt Encoding</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">For a VQA dataset, we can easily construct a mapping by using the image-question pair as the key and the answer as the value. Therefore we can use a multimodal encoder to encode the image-question pairs into multimodal features and perform K-Nearest Neighbors (KNN) search to find the most similar VQA tuples in the feature space.</p>
</div>
<section id="S3.SS1.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Question-Image Encoding:</h4>

<div id="S3.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS1.SSS0.Px1.p1.9" class="ltx_p">Before model training, we use a pre-trained CLIP model <cite class="ltx_cite ltx_citemacro_cite">Radford et al. (<a href="#bib.bib33" title="" class="ltx_ref">2021</a>)</cite> to encode image-question pairs in a retrieval dataset <math id="S3.SS1.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{R}" display="inline"><semantics id="S3.SS1.SSS0.Px1.p1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.SSS0.Px1.p1.1.m1.1.1" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1.cmml">ℛ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.1.m1.1b"><ci id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1">ℛ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.1.m1.1c">\mathcal{R}</annotation></semantics></math>, where <math id="S3.SS1.SSS0.Px1.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{R}=\mathcal{D}_{\text{src}}" display="inline"><semantics id="S3.SS1.SSS0.Px1.p1.2.m2.1a"><mrow id="S3.SS1.SSS0.Px1.p1.2.m2.1.1" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.2" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.2.cmml">ℛ</mi><mo id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.1" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.1.cmml">=</mo><msub id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3.2" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3.2.cmml">𝒟</mi><mtext id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3.3" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3.3a.cmml">src</mtext></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.2.m2.1b"><apply id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1"><eq id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.1"></eq><ci id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.2">ℛ</ci><apply id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3.cmml" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3.1.cmml" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3">subscript</csymbol><ci id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3.2.cmml" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3.2">𝒟</ci><ci id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3.3a.cmml" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3.3"><mtext mathsize="70%" id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3.3.cmml" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3.3">src</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.2.m2.1c">\mathcal{R}=\mathcal{D}_{\text{src}}</annotation></semantics></math> during training and <math id="S3.SS1.SSS0.Px1.p1.3.m3.1" class="ltx_Math" alttext="\mathcal{R}=\mathcal{D}_{\text{tgt}}" display="inline"><semantics id="S3.SS1.SSS0.Px1.p1.3.m3.1a"><mrow id="S3.SS1.SSS0.Px1.p1.3.m3.1.1" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.2" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.2.cmml">ℛ</mi><mo id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.1" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.1.cmml">=</mo><msub id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.2" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.2.cmml">𝒟</mi><mtext id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.3" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.3a.cmml">tgt</mtext></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.3.m3.1b"><apply id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1"><eq id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.1"></eq><ci id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.2">ℛ</ci><apply id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.cmml" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.1.cmml" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3">subscript</csymbol><ci id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.2.cmml" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.2">𝒟</ci><ci id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.3a.cmml" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.3"><mtext mathsize="70%" id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.3.cmml" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.3">tgt</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.3.m3.1c">\mathcal{R}=\mathcal{D}_{\text{tgt}}</annotation></semantics></math> at testing. Specifically, we first preprocess each image by downsampling it to the <math id="S3.SS1.SSS0.Px1.p1.4.m4.1" class="ltx_Math" alttext="224\times 224" display="inline"><semantics id="S3.SS1.SSS0.Px1.p1.4.m4.1a"><mrow id="S3.SS1.SSS0.Px1.p1.4.m4.1.1" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1.cmml"><mn id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.2" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1.2.cmml">224</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.1" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1.1.cmml">×</mo><mn id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.3" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1.3.cmml">224</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.4.m4.1b"><apply id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1"><times id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1.1"></times><cn type="integer" id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1.2">224</cn><cn type="integer" id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.3.cmml" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1.3">224</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.4.m4.1c">224\times 224</annotation></semantics></math> resolution and adopt CLIP’s vision transformer <cite class="ltx_cite ltx_citemacro_cite">Dosovitskiy et al. (<a href="#bib.bib5" title="" class="ltx_ref">2021</a>)</cite> to obtain image features <math id="S3.SS1.SSS0.Px1.p1.5.m5.1" class="ltx_Math" alttext="\mathbf{v}_{\texttt{CLS}}" display="inline"><semantics id="S3.SS1.SSS0.Px1.p1.5.m5.1a"><msub id="S3.SS1.SSS0.Px1.p1.5.m5.1.1" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.cmml"><mi id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.2" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.2.cmml">𝐯</mi><mtext class="ltx_mathvariant_monospace" id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.3" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.3a.cmml">CLS</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.5.m5.1b"><apply id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.2">𝐯</ci><ci id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.3a.cmml" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.3"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.3.cmml" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.3">CLS</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.5.m5.1c">\mathbf{v}_{\texttt{CLS}}</annotation></semantics></math> of the image patch <span id="S3.SS1.SSS0.Px1.p1.9.1" class="ltx_text ltx_font_typewriter">[CLS]</span> token that summarizes the image content. Similarly, we process each question using CLIP’s corresponding text transformer to obtain question features <math id="S3.SS1.SSS0.Px1.p1.6.m6.1" class="ltx_Math" alttext="\mathbf{x}_{\texttt{EOT}}" display="inline"><semantics id="S3.SS1.SSS0.Px1.p1.6.m6.1a"><msub id="S3.SS1.SSS0.Px1.p1.6.m6.1.1" xref="S3.SS1.SSS0.Px1.p1.6.m6.1.1.cmml"><mi id="S3.SS1.SSS0.Px1.p1.6.m6.1.1.2" xref="S3.SS1.SSS0.Px1.p1.6.m6.1.1.2.cmml">𝐱</mi><mtext class="ltx_mathvariant_monospace" id="S3.SS1.SSS0.Px1.p1.6.m6.1.1.3" xref="S3.SS1.SSS0.Px1.p1.6.m6.1.1.3a.cmml">EOT</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.6.m6.1b"><apply id="S3.SS1.SSS0.Px1.p1.6.m6.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px1.p1.6.m6.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.6.m6.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px1.p1.6.m6.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.6.m6.1.1.2">𝐱</ci><ci id="S3.SS1.SSS0.Px1.p1.6.m6.1.1.3a.cmml" xref="S3.SS1.SSS0.Px1.p1.6.m6.1.1.3"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S3.SS1.SSS0.Px1.p1.6.m6.1.1.3.cmml" xref="S3.SS1.SSS0.Px1.p1.6.m6.1.1.3">EOT</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.6.m6.1c">\mathbf{x}_{\texttt{EOT}}</annotation></semantics></math> from the <span id="S3.SS1.SSS0.Px1.p1.9.2" class="ltx_text ltx_font_typewriter">[EOT]</span> token. These question and image features are concatenated to form a holistic vector representation <math id="S3.SS1.SSS0.Px1.p1.7.m7.2" class="ltx_Math" alttext="\mathbf{p}=[\mathbf{v}_{\texttt{CLS}};\mathbf{x}_{\texttt{EOT}}]" display="inline"><semantics id="S3.SS1.SSS0.Px1.p1.7.m7.2a"><mrow id="S3.SS1.SSS0.Px1.p1.7.m7.2.2" xref="S3.SS1.SSS0.Px1.p1.7.m7.2.2.cmml"><mi id="S3.SS1.SSS0.Px1.p1.7.m7.2.2.4" xref="S3.SS1.SSS0.Px1.p1.7.m7.2.2.4.cmml">𝐩</mi><mo id="S3.SS1.SSS0.Px1.p1.7.m7.2.2.3" xref="S3.SS1.SSS0.Px1.p1.7.m7.2.2.3.cmml">=</mo><mrow id="S3.SS1.SSS0.Px1.p1.7.m7.2.2.2.2" xref="S3.SS1.SSS0.Px1.p1.7.m7.2.2.2.3.cmml"><mo stretchy="false" id="S3.SS1.SSS0.Px1.p1.7.m7.2.2.2.2.3" xref="S3.SS1.SSS0.Px1.p1.7.m7.2.2.2.3.cmml">[</mo><msub id="S3.SS1.SSS0.Px1.p1.7.m7.1.1.1.1.1" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.1.1.1.1.cmml"><mi id="S3.SS1.SSS0.Px1.p1.7.m7.1.1.1.1.1.2" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.1.1.1.1.2.cmml">𝐯</mi><mtext class="ltx_mathvariant_monospace" id="S3.SS1.SSS0.Px1.p1.7.m7.1.1.1.1.1.3" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.1.1.1.1.3a.cmml">CLS</mtext></msub><mo id="S3.SS1.SSS0.Px1.p1.7.m7.2.2.2.2.4" xref="S3.SS1.SSS0.Px1.p1.7.m7.2.2.2.3.cmml">;</mo><msub id="S3.SS1.SSS0.Px1.p1.7.m7.2.2.2.2.2" xref="S3.SS1.SSS0.Px1.p1.7.m7.2.2.2.2.2.cmml"><mi id="S3.SS1.SSS0.Px1.p1.7.m7.2.2.2.2.2.2" xref="S3.SS1.SSS0.Px1.p1.7.m7.2.2.2.2.2.2.cmml">𝐱</mi><mtext class="ltx_mathvariant_monospace" id="S3.SS1.SSS0.Px1.p1.7.m7.2.2.2.2.2.3" xref="S3.SS1.SSS0.Px1.p1.7.m7.2.2.2.2.2.3a.cmml">EOT</mtext></msub><mo stretchy="false" id="S3.SS1.SSS0.Px1.p1.7.m7.2.2.2.2.5" xref="S3.SS1.SSS0.Px1.p1.7.m7.2.2.2.3.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.7.m7.2b"><apply id="S3.SS1.SSS0.Px1.p1.7.m7.2.2.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m7.2.2"><eq id="S3.SS1.SSS0.Px1.p1.7.m7.2.2.3.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m7.2.2.3"></eq><ci id="S3.SS1.SSS0.Px1.p1.7.m7.2.2.4.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m7.2.2.4">𝐩</ci><list id="S3.SS1.SSS0.Px1.p1.7.m7.2.2.2.3.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m7.2.2.2.2"><apply id="S3.SS1.SSS0.Px1.p1.7.m7.1.1.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px1.p1.7.m7.1.1.1.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px1.p1.7.m7.1.1.1.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.1.1.1.1.2">𝐯</ci><ci id="S3.SS1.SSS0.Px1.p1.7.m7.1.1.1.1.1.3a.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.1.1.1.1.3"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S3.SS1.SSS0.Px1.p1.7.m7.1.1.1.1.1.3.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m7.1.1.1.1.1.3">CLS</mtext></ci></apply><apply id="S3.SS1.SSS0.Px1.p1.7.m7.2.2.2.2.2.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m7.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px1.p1.7.m7.2.2.2.2.2.1.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m7.2.2.2.2.2">subscript</csymbol><ci id="S3.SS1.SSS0.Px1.p1.7.m7.2.2.2.2.2.2.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m7.2.2.2.2.2.2">𝐱</ci><ci id="S3.SS1.SSS0.Px1.p1.7.m7.2.2.2.2.2.3a.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m7.2.2.2.2.2.3"><mtext class="ltx_mathvariant_monospace" mathsize="70%" id="S3.SS1.SSS0.Px1.p1.7.m7.2.2.2.2.2.3.cmml" xref="S3.SS1.SSS0.Px1.p1.7.m7.2.2.2.2.2.3">EOT</mtext></ci></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.7.m7.2c">\mathbf{p}=[\mathbf{v}_{\texttt{CLS}};\mathbf{x}_{\texttt{EOT}}]</annotation></semantics></math> of a question-image pair. These question-image vectors are paired along with the corresponding answers to construct the retrieval mapping set <math id="S3.SS1.SSS0.Px1.p1.8.m8.1" class="ltx_Math" alttext="\mathcal{M}=\{(\mathbf{p}_{i},y_{i})\}_{i=1}^{m}" display="inline"><semantics id="S3.SS1.SSS0.Px1.p1.8.m8.1a"><mrow id="S3.SS1.SSS0.Px1.p1.8.m8.1.1" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.3" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1.3.cmml">ℳ</mi><mo id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.2" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1.2.cmml">=</mo><msubsup id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.cmml"><mrow id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.1.1" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.1.1.2" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.1.2.cmml">{</mo><mrow id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.1.1.1.2" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.1.1.1.3.cmml"><mo stretchy="false" id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.1.1.1.2.3" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.1.1.1.3.cmml">(</mo><msub id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.1.1.1.1.1" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.1.1.1.1.1.2" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.1.1.1.1.1.2.cmml">𝐩</mi><mi id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.1.1.1.1.1.3" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.1.1.1.2.4" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.1.1.1.3.cmml">,</mo><msub id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.1.1.1.2.2" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.1.1.1.2.2.cmml"><mi id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.1.1.1.2.2.2" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.1.1.1.2.2.2.cmml">y</mi><mi id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.1.1.1.2.2.3" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.1.1.1.2.2.3.cmml">i</mi></msub><mo stretchy="false" id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.1.1.1.2.5" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.1.1.1.3.cmml">)</mo></mrow><mo stretchy="false" id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.1.1.3" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.3" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.3.cmml"><mi id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.3.2" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.3.2.cmml">i</mi><mo id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.3.1" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.3.1.cmml">=</mo><mn id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.3.3" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.3.3.cmml">1</mn></mrow><mi id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.3" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.3.cmml">m</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.8.m8.1b"><apply id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1"><eq id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1.2"></eq><ci id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.3.cmml" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1.3">ℳ</ci><apply id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1">superscript</csymbol><apply id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1">subscript</csymbol><set id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.1.1"><interval closure="open" id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.1.1.1.3.cmml" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.1.1.1.2"><apply id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.1.1.1.1.1.2">𝐩</ci><ci id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.1.1.1.1.1.3">𝑖</ci></apply><apply id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.1.1.1.2.2.cmml" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.1.1.1.2.2.1.cmml" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.1.1.1.2.2">subscript</csymbol><ci id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.1.1.1.2.2.2">𝑦</ci><ci id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.1.1.1.2.2.3.cmml" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.1.1.1.2.2.3">𝑖</ci></apply></interval></set><apply id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.3.cmml" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.3"><eq id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.3.1.cmml" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.3.1"></eq><ci id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.3.2.cmml" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.3.2">𝑖</ci><cn type="integer" id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.3.3.cmml" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.1.3.3">1</cn></apply></apply><ci id="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.3.cmml" xref="S3.SS1.SSS0.Px1.p1.8.m8.1.1.1.3">𝑚</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.8.m8.1c">\mathcal{M}=\{(\mathbf{p}_{i},y_{i})\}_{i=1}^{m}</annotation></semantics></math> of <math id="S3.SS1.SSS0.Px1.p1.9.m9.1" class="ltx_Math" alttext="m" display="inline"><semantics id="S3.SS1.SSS0.Px1.p1.9.m9.1a"><mi id="S3.SS1.SSS0.Px1.p1.9.m9.1.1" xref="S3.SS1.SSS0.Px1.p1.9.m9.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.9.m9.1b"><ci id="S3.SS1.SSS0.Px1.p1.9.m9.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.9.m9.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.9.m9.1c">m</annotation></semantics></math> items.</p>
</div>
</section>
<section id="S3.SS1.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Retrieval Set Augmentation on Image-Caption Data:</h4>

<div id="S3.SS1.SSS0.Px2.p1" class="ltx_para">
<p id="S3.SS1.SSS0.Px2.p1.9" class="ltx_p">As many VQA datasets in a low-resourced target domain (e.g., medicine) often contain a limited amount of labeled examples, we propose a data augmentation method to create a synthetic VQA set <math id="S3.SS1.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{D}_{\text{syn}}" display="inline"><semantics id="S3.SS1.SSS0.Px2.p1.1.m1.1a"><msub id="S3.SS1.SSS0.Px2.p1.1.m1.1.1" xref="S3.SS1.SSS0.Px2.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.SSS0.Px2.p1.1.m1.1.1.2" xref="S3.SS1.SSS0.Px2.p1.1.m1.1.1.2.cmml">𝒟</mi><mtext id="S3.SS1.SSS0.Px2.p1.1.m1.1.1.3" xref="S3.SS1.SSS0.Px2.p1.1.m1.1.1.3a.cmml">syn</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p1.1.m1.1b"><apply id="S3.SS1.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px2.p1.1.m1.1.1.2.cmml" xref="S3.SS1.SSS0.Px2.p1.1.m1.1.1.2">𝒟</ci><ci id="S3.SS1.SSS0.Px2.p1.1.m1.1.1.3a.cmml" xref="S3.SS1.SSS0.Px2.p1.1.m1.1.1.3"><mtext mathsize="70%" id="S3.SS1.SSS0.Px2.p1.1.m1.1.1.3.cmml" xref="S3.SS1.SSS0.Px2.p1.1.m1.1.1.3">syn</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p1.1.m1.1c">\mathcal{D}_{\text{syn}}</annotation></semantics></math> from image-caption pairs and augment the retrieval set <math id="S3.SS1.SSS0.Px2.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{R}" display="inline"><semantics id="S3.SS1.SSS0.Px2.p1.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.SSS0.Px2.p1.2.m2.1.1" xref="S3.SS1.SSS0.Px2.p1.2.m2.1.1.cmml">ℛ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p1.2.m2.1b"><ci id="S3.SS1.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S3.SS1.SSS0.Px2.p1.2.m2.1.1">ℛ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p1.2.m2.1c">\mathcal{R}</annotation></semantics></math>. First, we determine a desired set of question types <math id="S3.SS1.SSS0.Px2.p1.3.m3.1" class="ltx_Math" alttext="\mathcal{Q}_{\text{type}}" display="inline"><semantics id="S3.SS1.SSS0.Px2.p1.3.m3.1a"><msub id="S3.SS1.SSS0.Px2.p1.3.m3.1.1" xref="S3.SS1.SSS0.Px2.p1.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.SSS0.Px2.p1.3.m3.1.1.2" xref="S3.SS1.SSS0.Px2.p1.3.m3.1.1.2.cmml">𝒬</mi><mtext id="S3.SS1.SSS0.Px2.p1.3.m3.1.1.3" xref="S3.SS1.SSS0.Px2.p1.3.m3.1.1.3a.cmml">type</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p1.3.m3.1b"><apply id="S3.SS1.SSS0.Px2.p1.3.m3.1.1.cmml" xref="S3.SS1.SSS0.Px2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px2.p1.3.m3.1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px2.p1.3.m3.1.1.2.cmml" xref="S3.SS1.SSS0.Px2.p1.3.m3.1.1.2">𝒬</ci><ci id="S3.SS1.SSS0.Px2.p1.3.m3.1.1.3a.cmml" xref="S3.SS1.SSS0.Px2.p1.3.m3.1.1.3"><mtext mathsize="70%" id="S3.SS1.SSS0.Px2.p1.3.m3.1.1.3.cmml" xref="S3.SS1.SSS0.Px2.p1.3.m3.1.1.3">type</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p1.3.m3.1c">\mathcal{Q}_{\text{type}}</annotation></semantics></math> and answer types <math id="S3.SS1.SSS0.Px2.p1.4.m4.1" class="ltx_Math" alttext="\mathcal{A}_{\text{type}}" display="inline"><semantics id="S3.SS1.SSS0.Px2.p1.4.m4.1a"><msub id="S3.SS1.SSS0.Px2.p1.4.m4.1.1" xref="S3.SS1.SSS0.Px2.p1.4.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.SSS0.Px2.p1.4.m4.1.1.2" xref="S3.SS1.SSS0.Px2.p1.4.m4.1.1.2.cmml">𝒜</mi><mtext id="S3.SS1.SSS0.Px2.p1.4.m4.1.1.3" xref="S3.SS1.SSS0.Px2.p1.4.m4.1.1.3a.cmml">type</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p1.4.m4.1b"><apply id="S3.SS1.SSS0.Px2.p1.4.m4.1.1.cmml" xref="S3.SS1.SSS0.Px2.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px2.p1.4.m4.1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p1.4.m4.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px2.p1.4.m4.1.1.2.cmml" xref="S3.SS1.SSS0.Px2.p1.4.m4.1.1.2">𝒜</ci><ci id="S3.SS1.SSS0.Px2.p1.4.m4.1.1.3a.cmml" xref="S3.SS1.SSS0.Px2.p1.4.m4.1.1.3"><mtext mathsize="70%" id="S3.SS1.SSS0.Px2.p1.4.m4.1.1.3.cmml" xref="S3.SS1.SSS0.Px2.p1.4.m4.1.1.3">type</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p1.4.m4.1c">\mathcal{A}_{\text{type}}</annotation></semantics></math> described in §<a href="#S2.SS0.SSS0.Px3" title="Types of Medical VQA: ‣ 2 Preliminaries ‣ Multimodal Prompt Retrieval for Generative Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. For each combination of question and answer types <math id="S3.SS1.SSS0.Px2.p1.5.m5.1" class="ltx_Math" alttext="t\in\mathcal{Q}_{\text{type}}\times\mathcal{A}_{\text{type}}" display="inline"><semantics id="S3.SS1.SSS0.Px2.p1.5.m5.1a"><mrow id="S3.SS1.SSS0.Px2.p1.5.m5.1.1" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1.cmml"><mi id="S3.SS1.SSS0.Px2.p1.5.m5.1.1.2" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1.2.cmml">t</mi><mo id="S3.SS1.SSS0.Px2.p1.5.m5.1.1.1" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1.1.cmml">∈</mo><mrow id="S3.SS1.SSS0.Px2.p1.5.m5.1.1.3" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1.3.cmml"><msub id="S3.SS1.SSS0.Px2.p1.5.m5.1.1.3.2" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.SSS0.Px2.p1.5.m5.1.1.3.2.2" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1.3.2.2.cmml">𝒬</mi><mtext id="S3.SS1.SSS0.Px2.p1.5.m5.1.1.3.2.3" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1.3.2.3a.cmml">type</mtext></msub><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.SSS0.Px2.p1.5.m5.1.1.3.1" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1.3.1.cmml">×</mo><msub id="S3.SS1.SSS0.Px2.p1.5.m5.1.1.3.3" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.SSS0.Px2.p1.5.m5.1.1.3.3.2" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1.3.3.2.cmml">𝒜</mi><mtext id="S3.SS1.SSS0.Px2.p1.5.m5.1.1.3.3.3" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1.3.3.3a.cmml">type</mtext></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p1.5.m5.1b"><apply id="S3.SS1.SSS0.Px2.p1.5.m5.1.1.cmml" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1"><in id="S3.SS1.SSS0.Px2.p1.5.m5.1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1.1"></in><ci id="S3.SS1.SSS0.Px2.p1.5.m5.1.1.2.cmml" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1.2">𝑡</ci><apply id="S3.SS1.SSS0.Px2.p1.5.m5.1.1.3.cmml" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1.3"><times id="S3.SS1.SSS0.Px2.p1.5.m5.1.1.3.1.cmml" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1.3.1"></times><apply id="S3.SS1.SSS0.Px2.p1.5.m5.1.1.3.2.cmml" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1.3.2"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px2.p1.5.m5.1.1.3.2.1.cmml" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1.3.2">subscript</csymbol><ci id="S3.SS1.SSS0.Px2.p1.5.m5.1.1.3.2.2.cmml" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1.3.2.2">𝒬</ci><ci id="S3.SS1.SSS0.Px2.p1.5.m5.1.1.3.2.3a.cmml" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1.3.2.3"><mtext mathsize="70%" id="S3.SS1.SSS0.Px2.p1.5.m5.1.1.3.2.3.cmml" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1.3.2.3">type</mtext></ci></apply><apply id="S3.SS1.SSS0.Px2.p1.5.m5.1.1.3.3.cmml" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1.3.3"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px2.p1.5.m5.1.1.3.3.1.cmml" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1.3.3">subscript</csymbol><ci id="S3.SS1.SSS0.Px2.p1.5.m5.1.1.3.3.2.cmml" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1.3.3.2">𝒜</ci><ci id="S3.SS1.SSS0.Px2.p1.5.m5.1.1.3.3.3a.cmml" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1.3.3.3"><mtext mathsize="70%" id="S3.SS1.SSS0.Px2.p1.5.m5.1.1.3.3.3.cmml" xref="S3.SS1.SSS0.Px2.p1.5.m5.1.1.3.3.3">type</mtext></ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p1.5.m5.1c">t\in\mathcal{Q}_{\text{type}}\times\mathcal{A}_{\text{type}}</annotation></semantics></math>, we manually prepare a collection of question templates <math id="S3.SS1.SSS0.Px2.p1.6.m6.1" class="ltx_Math" alttext="{\mathcal{T}}_{t}" display="inline"><semantics id="S3.SS1.SSS0.Px2.p1.6.m6.1a"><msub id="S3.SS1.SSS0.Px2.p1.6.m6.1.1" xref="S3.SS1.SSS0.Px2.p1.6.m6.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.SSS0.Px2.p1.6.m6.1.1.2" xref="S3.SS1.SSS0.Px2.p1.6.m6.1.1.2.cmml">𝒯</mi><mi id="S3.SS1.SSS0.Px2.p1.6.m6.1.1.3" xref="S3.SS1.SSS0.Px2.p1.6.m6.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p1.6.m6.1b"><apply id="S3.SS1.SSS0.Px2.p1.6.m6.1.1.cmml" xref="S3.SS1.SSS0.Px2.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px2.p1.6.m6.1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p1.6.m6.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px2.p1.6.m6.1.1.2.cmml" xref="S3.SS1.SSS0.Px2.p1.6.m6.1.1.2">𝒯</ci><ci id="S3.SS1.SSS0.Px2.p1.6.m6.1.1.3.cmml" xref="S3.SS1.SSS0.Px2.p1.6.m6.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p1.6.m6.1c">{\mathcal{T}}_{t}</annotation></semantics></math>
along with a corresponding collection of keywords <math id="S3.SS1.SSS0.Px2.p1.7.m7.1" class="ltx_Math" alttext="\mathcal{W}_{t}" display="inline"><semantics id="S3.SS1.SSS0.Px2.p1.7.m7.1a"><msub id="S3.SS1.SSS0.Px2.p1.7.m7.1.1" xref="S3.SS1.SSS0.Px2.p1.7.m7.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.SSS0.Px2.p1.7.m7.1.1.2" xref="S3.SS1.SSS0.Px2.p1.7.m7.1.1.2.cmml">𝒲</mi><mi id="S3.SS1.SSS0.Px2.p1.7.m7.1.1.3" xref="S3.SS1.SSS0.Px2.p1.7.m7.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p1.7.m7.1b"><apply id="S3.SS1.SSS0.Px2.p1.7.m7.1.1.cmml" xref="S3.SS1.SSS0.Px2.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px2.p1.7.m7.1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p1.7.m7.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px2.p1.7.m7.1.1.2.cmml" xref="S3.SS1.SSS0.Px2.p1.7.m7.1.1.2">𝒲</ci><ci id="S3.SS1.SSS0.Px2.p1.7.m7.1.1.3.cmml" xref="S3.SS1.SSS0.Px2.p1.7.m7.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p1.7.m7.1c">\mathcal{W}_{t}</annotation></semantics></math>. We then iterate through all the image-caption pairs and identify if the caption contains any keywords <math id="S3.SS1.SSS0.Px2.p1.8.m8.1" class="ltx_Math" alttext="w\in\mathcal{W}_{t}" display="inline"><semantics id="S3.SS1.SSS0.Px2.p1.8.m8.1a"><mrow id="S3.SS1.SSS0.Px2.p1.8.m8.1.1" xref="S3.SS1.SSS0.Px2.p1.8.m8.1.1.cmml"><mi id="S3.SS1.SSS0.Px2.p1.8.m8.1.1.2" xref="S3.SS1.SSS0.Px2.p1.8.m8.1.1.2.cmml">w</mi><mo id="S3.SS1.SSS0.Px2.p1.8.m8.1.1.1" xref="S3.SS1.SSS0.Px2.p1.8.m8.1.1.1.cmml">∈</mo><msub id="S3.SS1.SSS0.Px2.p1.8.m8.1.1.3" xref="S3.SS1.SSS0.Px2.p1.8.m8.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.SSS0.Px2.p1.8.m8.1.1.3.2" xref="S3.SS1.SSS0.Px2.p1.8.m8.1.1.3.2.cmml">𝒲</mi><mi id="S3.SS1.SSS0.Px2.p1.8.m8.1.1.3.3" xref="S3.SS1.SSS0.Px2.p1.8.m8.1.1.3.3.cmml">t</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p1.8.m8.1b"><apply id="S3.SS1.SSS0.Px2.p1.8.m8.1.1.cmml" xref="S3.SS1.SSS0.Px2.p1.8.m8.1.1"><in id="S3.SS1.SSS0.Px2.p1.8.m8.1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p1.8.m8.1.1.1"></in><ci id="S3.SS1.SSS0.Px2.p1.8.m8.1.1.2.cmml" xref="S3.SS1.SSS0.Px2.p1.8.m8.1.1.2">𝑤</ci><apply id="S3.SS1.SSS0.Px2.p1.8.m8.1.1.3.cmml" xref="S3.SS1.SSS0.Px2.p1.8.m8.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px2.p1.8.m8.1.1.3.1.cmml" xref="S3.SS1.SSS0.Px2.p1.8.m8.1.1.3">subscript</csymbol><ci id="S3.SS1.SSS0.Px2.p1.8.m8.1.1.3.2.cmml" xref="S3.SS1.SSS0.Px2.p1.8.m8.1.1.3.2">𝒲</ci><ci id="S3.SS1.SSS0.Px2.p1.8.m8.1.1.3.3.cmml" xref="S3.SS1.SSS0.Px2.p1.8.m8.1.1.3.3">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p1.8.m8.1c">w\in\mathcal{W}_{t}</annotation></semantics></math>. If any keywords match, we create a question by sampling a template from <math id="S3.SS1.SSS0.Px2.p1.9.m9.1" class="ltx_Math" alttext="{\mathcal{T}}_{t}" display="inline"><semantics id="S3.SS1.SSS0.Px2.p1.9.m9.1a"><msub id="S3.SS1.SSS0.Px2.p1.9.m9.1.1" xref="S3.SS1.SSS0.Px2.p1.9.m9.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.SSS0.Px2.p1.9.m9.1.1.2" xref="S3.SS1.SSS0.Px2.p1.9.m9.1.1.2.cmml">𝒯</mi><mi id="S3.SS1.SSS0.Px2.p1.9.m9.1.1.3" xref="S3.SS1.SSS0.Px2.p1.9.m9.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px2.p1.9.m9.1b"><apply id="S3.SS1.SSS0.Px2.p1.9.m9.1.1.cmml" xref="S3.SS1.SSS0.Px2.p1.9.m9.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px2.p1.9.m9.1.1.1.cmml" xref="S3.SS1.SSS0.Px2.p1.9.m9.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px2.p1.9.m9.1.1.2.cmml" xref="S3.SS1.SSS0.Px2.p1.9.m9.1.1.2">𝒯</ci><ci id="S3.SS1.SSS0.Px2.p1.9.m9.1.1.3.cmml" xref="S3.SS1.SSS0.Px2.p1.9.m9.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px2.p1.9.m9.1c">{\mathcal{T}}_{t}</annotation></semantics></math> uniformly at random and filling it with the matched keyword as the answer. Example templates from several question and answer types can be found in Appendix <a href="#A1" title="Appendix A Templates ‣ Multimodal Prompt Retrieval for Generative Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A</span></a>.</p>
</div>
</section>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Multimodal Embedding Retrieval</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.11" class="ltx_p">To answer a question <math id="S3.SS2.p1.1.m1.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S3.SS2.p1.1.m1.1a"><mi id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><ci id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">x</annotation></semantics></math> about an image <math id="S3.SS2.p1.2.m2.1" class="ltx_Math" alttext="v" display="inline"><semantics id="S3.SS2.p1.2.m2.1a"><mi id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml">v</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><ci id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">𝑣</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">v</annotation></semantics></math>, we propose to retrieve its top-<math id="S3.SS2.p1.3.m3.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS2.p1.3.m3.1a"><mi id="S3.SS2.p1.3.m3.1.1" xref="S3.SS2.p1.3.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m3.1b"><ci id="S3.SS2.p1.3.m3.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m3.1c">k</annotation></semantics></math> most similar examples from the retrieval mapping set <math id="S3.SS2.p1.4.m4.1" class="ltx_Math" alttext="\mathcal{M}" display="inline"><semantics id="S3.SS2.p1.4.m4.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p1.4.m4.1.1" xref="S3.SS2.p1.4.m4.1.1.cmml">ℳ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.4.m4.1b"><ci id="S3.SS2.p1.4.m4.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1">ℳ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.4.m4.1c">\mathcal{M}</annotation></semantics></math> (as constructed in §<a href="#S3.SS1" title="3.1 Multimodal Prompt Encoding ‣ 3 Methods ‣ Multimodal Prompt Retrieval for Generative Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a>). Specifically, we first encode the query question-image pair into an embedding <math id="S3.SS2.p1.5.m5.1" class="ltx_Math" alttext="\mathbf{p}" display="inline"><semantics id="S3.SS2.p1.5.m5.1a"><mi id="S3.SS2.p1.5.m5.1.1" xref="S3.SS2.p1.5.m5.1.1.cmml">𝐩</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.5.m5.1b"><ci id="S3.SS2.p1.5.m5.1.1.cmml" xref="S3.SS2.p1.5.m5.1.1">𝐩</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.5.m5.1c">\mathbf{p}</annotation></semantics></math> by the CLIP model and compute the cosine similarity between the query embedding <math id="S3.SS2.p1.6.m6.1" class="ltx_Math" alttext="\mathbf{p}" display="inline"><semantics id="S3.SS2.p1.6.m6.1a"><mi id="S3.SS2.p1.6.m6.1.1" xref="S3.SS2.p1.6.m6.1.1.cmml">𝐩</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.6.m6.1b"><ci id="S3.SS2.p1.6.m6.1.1.cmml" xref="S3.SS2.p1.6.m6.1.1">𝐩</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.6.m6.1c">\mathbf{p}</annotation></semantics></math> and each question-image embedding in <math id="S3.SS2.p1.7.m7.1" class="ltx_Math" alttext="\mathcal{M}" display="inline"><semantics id="S3.SS2.p1.7.m7.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p1.7.m7.1.1" xref="S3.SS2.p1.7.m7.1.1.cmml">ℳ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.7.m7.1b"><ci id="S3.SS2.p1.7.m7.1.1.cmml" xref="S3.SS2.p1.7.m7.1.1">ℳ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.7.m7.1c">\mathcal{M}</annotation></semantics></math>. Therefore, we can obtain the <math id="S3.SS2.p1.8.m8.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS2.p1.8.m8.1a"><mi id="S3.SS2.p1.8.m8.1.1" xref="S3.SS2.p1.8.m8.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.8.m8.1b"><ci id="S3.SS2.p1.8.m8.1.1.cmml" xref="S3.SS2.p1.8.m8.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.8.m8.1c">k</annotation></semantics></math> nearest neighbors of image-question pairs in <math id="S3.SS2.p1.9.m9.1" class="ltx_Math" alttext="\mathcal{M}" display="inline"><semantics id="S3.SS2.p1.9.m9.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p1.9.m9.1.1" xref="S3.SS2.p1.9.m9.1.1.cmml">ℳ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.9.m9.1b"><ci id="S3.SS2.p1.9.m9.1.1.cmml" xref="S3.SS2.p1.9.m9.1.1">ℳ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.9.m9.1c">\mathcal{M}</annotation></semantics></math>, denoted as <math id="S3.SS2.p1.10.m10.1" class="ltx_Math" alttext="\mathcal{K}=\{(\mathbf{p}_{i},y_{i})\}_{i=1}^{k}" display="inline"><semantics id="S3.SS2.p1.10.m10.1a"><mrow id="S3.SS2.p1.10.m10.1.1" xref="S3.SS2.p1.10.m10.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p1.10.m10.1.1.3" xref="S3.SS2.p1.10.m10.1.1.3.cmml">𝒦</mi><mo id="S3.SS2.p1.10.m10.1.1.2" xref="S3.SS2.p1.10.m10.1.1.2.cmml">=</mo><msubsup id="S3.SS2.p1.10.m10.1.1.1" xref="S3.SS2.p1.10.m10.1.1.1.cmml"><mrow id="S3.SS2.p1.10.m10.1.1.1.1.1.1" xref="S3.SS2.p1.10.m10.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.SS2.p1.10.m10.1.1.1.1.1.1.2" xref="S3.SS2.p1.10.m10.1.1.1.1.1.2.cmml">{</mo><mrow id="S3.SS2.p1.10.m10.1.1.1.1.1.1.1.2" xref="S3.SS2.p1.10.m10.1.1.1.1.1.1.1.3.cmml"><mo stretchy="false" id="S3.SS2.p1.10.m10.1.1.1.1.1.1.1.2.3" xref="S3.SS2.p1.10.m10.1.1.1.1.1.1.1.3.cmml">(</mo><msub id="S3.SS2.p1.10.m10.1.1.1.1.1.1.1.1.1" xref="S3.SS2.p1.10.m10.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.SS2.p1.10.m10.1.1.1.1.1.1.1.1.1.2" xref="S3.SS2.p1.10.m10.1.1.1.1.1.1.1.1.1.2.cmml">𝐩</mi><mi id="S3.SS2.p1.10.m10.1.1.1.1.1.1.1.1.1.3" xref="S3.SS2.p1.10.m10.1.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.SS2.p1.10.m10.1.1.1.1.1.1.1.2.4" xref="S3.SS2.p1.10.m10.1.1.1.1.1.1.1.3.cmml">,</mo><msub id="S3.SS2.p1.10.m10.1.1.1.1.1.1.1.2.2" xref="S3.SS2.p1.10.m10.1.1.1.1.1.1.1.2.2.cmml"><mi id="S3.SS2.p1.10.m10.1.1.1.1.1.1.1.2.2.2" xref="S3.SS2.p1.10.m10.1.1.1.1.1.1.1.2.2.2.cmml">y</mi><mi id="S3.SS2.p1.10.m10.1.1.1.1.1.1.1.2.2.3" xref="S3.SS2.p1.10.m10.1.1.1.1.1.1.1.2.2.3.cmml">i</mi></msub><mo stretchy="false" id="S3.SS2.p1.10.m10.1.1.1.1.1.1.1.2.5" xref="S3.SS2.p1.10.m10.1.1.1.1.1.1.1.3.cmml">)</mo></mrow><mo stretchy="false" id="S3.SS2.p1.10.m10.1.1.1.1.1.1.3" xref="S3.SS2.p1.10.m10.1.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S3.SS2.p1.10.m10.1.1.1.1.3" xref="S3.SS2.p1.10.m10.1.1.1.1.3.cmml"><mi id="S3.SS2.p1.10.m10.1.1.1.1.3.2" xref="S3.SS2.p1.10.m10.1.1.1.1.3.2.cmml">i</mi><mo id="S3.SS2.p1.10.m10.1.1.1.1.3.1" xref="S3.SS2.p1.10.m10.1.1.1.1.3.1.cmml">=</mo><mn id="S3.SS2.p1.10.m10.1.1.1.1.3.3" xref="S3.SS2.p1.10.m10.1.1.1.1.3.3.cmml">1</mn></mrow><mi id="S3.SS2.p1.10.m10.1.1.1.3" xref="S3.SS2.p1.10.m10.1.1.1.3.cmml">k</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.10.m10.1b"><apply id="S3.SS2.p1.10.m10.1.1.cmml" xref="S3.SS2.p1.10.m10.1.1"><eq id="S3.SS2.p1.10.m10.1.1.2.cmml" xref="S3.SS2.p1.10.m10.1.1.2"></eq><ci id="S3.SS2.p1.10.m10.1.1.3.cmml" xref="S3.SS2.p1.10.m10.1.1.3">𝒦</ci><apply id="S3.SS2.p1.10.m10.1.1.1.cmml" xref="S3.SS2.p1.10.m10.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.10.m10.1.1.1.2.cmml" xref="S3.SS2.p1.10.m10.1.1.1">superscript</csymbol><apply id="S3.SS2.p1.10.m10.1.1.1.1.cmml" xref="S3.SS2.p1.10.m10.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.10.m10.1.1.1.1.2.cmml" xref="S3.SS2.p1.10.m10.1.1.1">subscript</csymbol><set id="S3.SS2.p1.10.m10.1.1.1.1.1.2.cmml" xref="S3.SS2.p1.10.m10.1.1.1.1.1.1"><interval closure="open" id="S3.SS2.p1.10.m10.1.1.1.1.1.1.1.3.cmml" xref="S3.SS2.p1.10.m10.1.1.1.1.1.1.1.2"><apply id="S3.SS2.p1.10.m10.1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS2.p1.10.m10.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.10.m10.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS2.p1.10.m10.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p1.10.m10.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.SS2.p1.10.m10.1.1.1.1.1.1.1.1.1.2">𝐩</ci><ci id="S3.SS2.p1.10.m10.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.SS2.p1.10.m10.1.1.1.1.1.1.1.1.1.3">𝑖</ci></apply><apply id="S3.SS2.p1.10.m10.1.1.1.1.1.1.1.2.2.cmml" xref="S3.SS2.p1.10.m10.1.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.SS2.p1.10.m10.1.1.1.1.1.1.1.2.2.1.cmml" xref="S3.SS2.p1.10.m10.1.1.1.1.1.1.1.2.2">subscript</csymbol><ci id="S3.SS2.p1.10.m10.1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.SS2.p1.10.m10.1.1.1.1.1.1.1.2.2.2">𝑦</ci><ci id="S3.SS2.p1.10.m10.1.1.1.1.1.1.1.2.2.3.cmml" xref="S3.SS2.p1.10.m10.1.1.1.1.1.1.1.2.2.3">𝑖</ci></apply></interval></set><apply id="S3.SS2.p1.10.m10.1.1.1.1.3.cmml" xref="S3.SS2.p1.10.m10.1.1.1.1.3"><eq id="S3.SS2.p1.10.m10.1.1.1.1.3.1.cmml" xref="S3.SS2.p1.10.m10.1.1.1.1.3.1"></eq><ci id="S3.SS2.p1.10.m10.1.1.1.1.3.2.cmml" xref="S3.SS2.p1.10.m10.1.1.1.1.3.2">𝑖</ci><cn type="integer" id="S3.SS2.p1.10.m10.1.1.1.1.3.3.cmml" xref="S3.SS2.p1.10.m10.1.1.1.1.3.3">1</cn></apply></apply><ci id="S3.SS2.p1.10.m10.1.1.1.3.cmml" xref="S3.SS2.p1.10.m10.1.1.1.3">𝑘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.10.m10.1c">\mathcal{K}=\{(\mathbf{p}_{i},y_{i})\}_{i=1}^{k}</annotation></semantics></math>. Note that if the size of <math id="S3.SS2.p1.11.m11.1" class="ltx_Math" alttext="\mathcal{M}" display="inline"><semantics id="S3.SS2.p1.11.m11.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p1.11.m11.1.1" xref="S3.SS2.p1.11.m11.1.1.cmml">ℳ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.11.m11.1b"><ci id="S3.SS2.p1.11.m11.1.1.cmml" xref="S3.SS2.p1.11.m11.1.1">ℳ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.11.m11.1c">\mathcal{M}</annotation></semantics></math> is large, KNN search can be implemented with efficient algorithms such as Maximum Inner Product Search <cite class="ltx_cite ltx_citemacro_cite">Shrivastava and Li (<a href="#bib.bib38" title="" class="ltx_ref">2014</a>)</cite>. The retrieved pairs are used to construct the retrieval prompt (detailed in §<a href="#S3.SS3" title="3.3 Prompt Construction ‣ 3 Methods ‣ Multimodal Prompt Retrieval for Generative Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3</span></a>).</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Prompt Construction</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">Inspired by the prompt tuning method <cite class="ltx_cite ltx_citemacro_cite">Lester et al. (<a href="#bib.bib19" title="" class="ltx_ref">2021</a>)</cite> that appends several prompt embeddings to the original input before feeding to the transformer layers of the encoder, we propose to construct multimodal prompt embeddings to augment a question input, as shown in Figure <a href="#S3.F1" title="Figure 1 ‣ 3 Methods ‣ Multimodal Prompt Retrieval for Generative Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. Specifically, given an image-question pair, the inputs to our model consist of three main components: image, question, and retrieval embeddings. Our model concatenates these embeddings as inputs to the subsequent stack of encoder layers in a T5 model <cite class="ltx_cite ltx_citemacro_cite">Raffel et al. (<a href="#bib.bib34" title="" class="ltx_ref">2020</a>)</cite>. We begin the prompt with the image embedding, followed by the question and retrieval embeddings, leaving experimentation with alternative concatenation orders to Appendix <a href="#A2" title="Appendix B Prompt Variations ‣ Multimodal Prompt Retrieval for Generative Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">B</span></a>.</p>
</div>
<section id="S3.SS3.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Image Embedding:</h4>

<div id="S3.SS3.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS3.SSS0.Px1.p1.2" class="ltx_p">The image embedding is obtained using the same vision transformer of CLIP applied to construct the retrieval dataset. However, instead of using the <span id="S3.SS3.SSS0.Px1.p1.2.1" class="ltx_text ltx_font_typewriter">[CLS]</span> token which summarizes the image content, we use the intermediate output of the penultimate layer to obtain a collection of image token embeddings <math id="S3.SS3.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="\mathbf{v}_{p}\in\mathbb{R}^{l_{v}\times d}" display="inline"><semantics id="S3.SS3.SSS0.Px1.p1.1.m1.1a"><mrow id="S3.SS3.SSS0.Px1.p1.1.m1.1.1" xref="S3.SS3.SSS0.Px1.p1.1.m1.1.1.cmml"><msub id="S3.SS3.SSS0.Px1.p1.1.m1.1.1.2" xref="S3.SS3.SSS0.Px1.p1.1.m1.1.1.2.cmml"><mi id="S3.SS3.SSS0.Px1.p1.1.m1.1.1.2.2" xref="S3.SS3.SSS0.Px1.p1.1.m1.1.1.2.2.cmml">𝐯</mi><mi id="S3.SS3.SSS0.Px1.p1.1.m1.1.1.2.3" xref="S3.SS3.SSS0.Px1.p1.1.m1.1.1.2.3.cmml">p</mi></msub><mo id="S3.SS3.SSS0.Px1.p1.1.m1.1.1.1" xref="S3.SS3.SSS0.Px1.p1.1.m1.1.1.1.cmml">∈</mo><msup id="S3.SS3.SSS0.Px1.p1.1.m1.1.1.3" xref="S3.SS3.SSS0.Px1.p1.1.m1.1.1.3.cmml"><mi id="S3.SS3.SSS0.Px1.p1.1.m1.1.1.3.2" xref="S3.SS3.SSS0.Px1.p1.1.m1.1.1.3.2.cmml">ℝ</mi><mrow id="S3.SS3.SSS0.Px1.p1.1.m1.1.1.3.3" xref="S3.SS3.SSS0.Px1.p1.1.m1.1.1.3.3.cmml"><msub id="S3.SS3.SSS0.Px1.p1.1.m1.1.1.3.3.2" xref="S3.SS3.SSS0.Px1.p1.1.m1.1.1.3.3.2.cmml"><mi id="S3.SS3.SSS0.Px1.p1.1.m1.1.1.3.3.2.2" xref="S3.SS3.SSS0.Px1.p1.1.m1.1.1.3.3.2.2.cmml">l</mi><mi id="S3.SS3.SSS0.Px1.p1.1.m1.1.1.3.3.2.3" xref="S3.SS3.SSS0.Px1.p1.1.m1.1.1.3.3.2.3.cmml">v</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.SSS0.Px1.p1.1.m1.1.1.3.3.1" xref="S3.SS3.SSS0.Px1.p1.1.m1.1.1.3.3.1.cmml">×</mo><mi id="S3.SS3.SSS0.Px1.p1.1.m1.1.1.3.3.3" xref="S3.SS3.SSS0.Px1.p1.1.m1.1.1.3.3.3.cmml">d</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS0.Px1.p1.1.m1.1b"><apply id="S3.SS3.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S3.SS3.SSS0.Px1.p1.1.m1.1.1"><in id="S3.SS3.SSS0.Px1.p1.1.m1.1.1.1.cmml" xref="S3.SS3.SSS0.Px1.p1.1.m1.1.1.1"></in><apply id="S3.SS3.SSS0.Px1.p1.1.m1.1.1.2.cmml" xref="S3.SS3.SSS0.Px1.p1.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.SSS0.Px1.p1.1.m1.1.1.2.1.cmml" xref="S3.SS3.SSS0.Px1.p1.1.m1.1.1.2">subscript</csymbol><ci id="S3.SS3.SSS0.Px1.p1.1.m1.1.1.2.2.cmml" xref="S3.SS3.SSS0.Px1.p1.1.m1.1.1.2.2">𝐯</ci><ci id="S3.SS3.SSS0.Px1.p1.1.m1.1.1.2.3.cmml" xref="S3.SS3.SSS0.Px1.p1.1.m1.1.1.2.3">𝑝</ci></apply><apply id="S3.SS3.SSS0.Px1.p1.1.m1.1.1.3.cmml" xref="S3.SS3.SSS0.Px1.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.SSS0.Px1.p1.1.m1.1.1.3.1.cmml" xref="S3.SS3.SSS0.Px1.p1.1.m1.1.1.3">superscript</csymbol><ci id="S3.SS3.SSS0.Px1.p1.1.m1.1.1.3.2.cmml" xref="S3.SS3.SSS0.Px1.p1.1.m1.1.1.3.2">ℝ</ci><apply id="S3.SS3.SSS0.Px1.p1.1.m1.1.1.3.3.cmml" xref="S3.SS3.SSS0.Px1.p1.1.m1.1.1.3.3"><times id="S3.SS3.SSS0.Px1.p1.1.m1.1.1.3.3.1.cmml" xref="S3.SS3.SSS0.Px1.p1.1.m1.1.1.3.3.1"></times><apply id="S3.SS3.SSS0.Px1.p1.1.m1.1.1.3.3.2.cmml" xref="S3.SS3.SSS0.Px1.p1.1.m1.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.SS3.SSS0.Px1.p1.1.m1.1.1.3.3.2.1.cmml" xref="S3.SS3.SSS0.Px1.p1.1.m1.1.1.3.3.2">subscript</csymbol><ci id="S3.SS3.SSS0.Px1.p1.1.m1.1.1.3.3.2.2.cmml" xref="S3.SS3.SSS0.Px1.p1.1.m1.1.1.3.3.2.2">𝑙</ci><ci id="S3.SS3.SSS0.Px1.p1.1.m1.1.1.3.3.2.3.cmml" xref="S3.SS3.SSS0.Px1.p1.1.m1.1.1.3.3.2.3">𝑣</ci></apply><ci id="S3.SS3.SSS0.Px1.p1.1.m1.1.1.3.3.3.cmml" xref="S3.SS3.SSS0.Px1.p1.1.m1.1.1.3.3.3">𝑑</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS0.Px1.p1.1.m1.1c">\mathbf{v}_{p}\in\mathbb{R}^{l_{v}\times d}</annotation></semantics></math>, where <math id="S3.SS3.SSS0.Px1.p1.2.m2.1" class="ltx_Math" alttext="l_{v}" display="inline"><semantics id="S3.SS3.SSS0.Px1.p1.2.m2.1a"><msub id="S3.SS3.SSS0.Px1.p1.2.m2.1.1" xref="S3.SS3.SSS0.Px1.p1.2.m2.1.1.cmml"><mi id="S3.SS3.SSS0.Px1.p1.2.m2.1.1.2" xref="S3.SS3.SSS0.Px1.p1.2.m2.1.1.2.cmml">l</mi><mi id="S3.SS3.SSS0.Px1.p1.2.m2.1.1.3" xref="S3.SS3.SSS0.Px1.p1.2.m2.1.1.3.cmml">v</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS0.Px1.p1.2.m2.1b"><apply id="S3.SS3.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S3.SS3.SSS0.Px1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS0.Px1.p1.2.m2.1.1.1.cmml" xref="S3.SS3.SSS0.Px1.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS3.SSS0.Px1.p1.2.m2.1.1.2.cmml" xref="S3.SS3.SSS0.Px1.p1.2.m2.1.1.2">𝑙</ci><ci id="S3.SS3.SSS0.Px1.p1.2.m2.1.1.3.cmml" xref="S3.SS3.SSS0.Px1.p1.2.m2.1.1.3">𝑣</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS0.Px1.p1.2.m2.1c">l_{v}</annotation></semantics></math> denotes the number of image tokens.</p>
</div>
</section>
<section id="S3.SS3.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Question Embedding:</h4>

<div id="S3.SS3.SSS0.Px2.p1" class="ltx_para">
<p id="S3.SS3.SSS0.Px2.p1.1" class="ltx_p">To encode a question corresponding to an image, we use the embedding matrix of a pre-trained T5 encoder. Following the practice of T5, we include a short text snippet (e.g., “Answer the abnormality question:”) at the beginning of the question to instruct the model to perform a QA task. The combined text is first tokenized according to T5’s subword tokenization, followed by an embedding lookup to fetch the corresponding embedding vectors <math id="S3.SS3.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="\mathbf{x}_{q}\in\mathbb{R}^{l_{q}\times d}" display="inline"><semantics id="S3.SS3.SSS0.Px2.p1.1.m1.1a"><mrow id="S3.SS3.SSS0.Px2.p1.1.m1.1.1" xref="S3.SS3.SSS0.Px2.p1.1.m1.1.1.cmml"><msub id="S3.SS3.SSS0.Px2.p1.1.m1.1.1.2" xref="S3.SS3.SSS0.Px2.p1.1.m1.1.1.2.cmml"><mi id="S3.SS3.SSS0.Px2.p1.1.m1.1.1.2.2" xref="S3.SS3.SSS0.Px2.p1.1.m1.1.1.2.2.cmml">𝐱</mi><mi id="S3.SS3.SSS0.Px2.p1.1.m1.1.1.2.3" xref="S3.SS3.SSS0.Px2.p1.1.m1.1.1.2.3.cmml">q</mi></msub><mo id="S3.SS3.SSS0.Px2.p1.1.m1.1.1.1" xref="S3.SS3.SSS0.Px2.p1.1.m1.1.1.1.cmml">∈</mo><msup id="S3.SS3.SSS0.Px2.p1.1.m1.1.1.3" xref="S3.SS3.SSS0.Px2.p1.1.m1.1.1.3.cmml"><mi id="S3.SS3.SSS0.Px2.p1.1.m1.1.1.3.2" xref="S3.SS3.SSS0.Px2.p1.1.m1.1.1.3.2.cmml">ℝ</mi><mrow id="S3.SS3.SSS0.Px2.p1.1.m1.1.1.3.3" xref="S3.SS3.SSS0.Px2.p1.1.m1.1.1.3.3.cmml"><msub id="S3.SS3.SSS0.Px2.p1.1.m1.1.1.3.3.2" xref="S3.SS3.SSS0.Px2.p1.1.m1.1.1.3.3.2.cmml"><mi id="S3.SS3.SSS0.Px2.p1.1.m1.1.1.3.3.2.2" xref="S3.SS3.SSS0.Px2.p1.1.m1.1.1.3.3.2.2.cmml">l</mi><mi id="S3.SS3.SSS0.Px2.p1.1.m1.1.1.3.3.2.3" xref="S3.SS3.SSS0.Px2.p1.1.m1.1.1.3.3.2.3.cmml">q</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.SSS0.Px2.p1.1.m1.1.1.3.3.1" xref="S3.SS3.SSS0.Px2.p1.1.m1.1.1.3.3.1.cmml">×</mo><mi id="S3.SS3.SSS0.Px2.p1.1.m1.1.1.3.3.3" xref="S3.SS3.SSS0.Px2.p1.1.m1.1.1.3.3.3.cmml">d</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS0.Px2.p1.1.m1.1b"><apply id="S3.SS3.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S3.SS3.SSS0.Px2.p1.1.m1.1.1"><in id="S3.SS3.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="S3.SS3.SSS0.Px2.p1.1.m1.1.1.1"></in><apply id="S3.SS3.SSS0.Px2.p1.1.m1.1.1.2.cmml" xref="S3.SS3.SSS0.Px2.p1.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.SSS0.Px2.p1.1.m1.1.1.2.1.cmml" xref="S3.SS3.SSS0.Px2.p1.1.m1.1.1.2">subscript</csymbol><ci id="S3.SS3.SSS0.Px2.p1.1.m1.1.1.2.2.cmml" xref="S3.SS3.SSS0.Px2.p1.1.m1.1.1.2.2">𝐱</ci><ci id="S3.SS3.SSS0.Px2.p1.1.m1.1.1.2.3.cmml" xref="S3.SS3.SSS0.Px2.p1.1.m1.1.1.2.3">𝑞</ci></apply><apply id="S3.SS3.SSS0.Px2.p1.1.m1.1.1.3.cmml" xref="S3.SS3.SSS0.Px2.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.SSS0.Px2.p1.1.m1.1.1.3.1.cmml" xref="S3.SS3.SSS0.Px2.p1.1.m1.1.1.3">superscript</csymbol><ci id="S3.SS3.SSS0.Px2.p1.1.m1.1.1.3.2.cmml" xref="S3.SS3.SSS0.Px2.p1.1.m1.1.1.3.2">ℝ</ci><apply id="S3.SS3.SSS0.Px2.p1.1.m1.1.1.3.3.cmml" xref="S3.SS3.SSS0.Px2.p1.1.m1.1.1.3.3"><times id="S3.SS3.SSS0.Px2.p1.1.m1.1.1.3.3.1.cmml" xref="S3.SS3.SSS0.Px2.p1.1.m1.1.1.3.3.1"></times><apply id="S3.SS3.SSS0.Px2.p1.1.m1.1.1.3.3.2.cmml" xref="S3.SS3.SSS0.Px2.p1.1.m1.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.SS3.SSS0.Px2.p1.1.m1.1.1.3.3.2.1.cmml" xref="S3.SS3.SSS0.Px2.p1.1.m1.1.1.3.3.2">subscript</csymbol><ci id="S3.SS3.SSS0.Px2.p1.1.m1.1.1.3.3.2.2.cmml" xref="S3.SS3.SSS0.Px2.p1.1.m1.1.1.3.3.2.2">𝑙</ci><ci id="S3.SS3.SSS0.Px2.p1.1.m1.1.1.3.3.2.3.cmml" xref="S3.SS3.SSS0.Px2.p1.1.m1.1.1.3.3.2.3">𝑞</ci></apply><ci id="S3.SS3.SSS0.Px2.p1.1.m1.1.1.3.3.3.cmml" xref="S3.SS3.SSS0.Px2.p1.1.m1.1.1.3.3.3">𝑑</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS0.Px2.p1.1.m1.1c">\mathbf{x}_{q}\in\mathbb{R}^{l_{q}\times d}</annotation></semantics></math> from T5’s input embedding matrix.</p>
</div>
</section>
<section id="S3.SS3.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Retrieval Embedding:</h4>

<div id="S3.SS3.SSS0.Px3.p1" class="ltx_para">
<p id="S3.SS3.SSS0.Px3.p1.11" class="ltx_p">Based on the top-<math id="S3.SS3.SSS0.Px3.p1.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS3.SSS0.Px3.p1.1.m1.1a"><mi id="S3.SS3.SSS0.Px3.p1.1.m1.1.1" xref="S3.SS3.SSS0.Px3.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS0.Px3.p1.1.m1.1b"><ci id="S3.SS3.SSS0.Px3.p1.1.m1.1.1.cmml" xref="S3.SS3.SSS0.Px3.p1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS0.Px3.p1.1.m1.1c">k</annotation></semantics></math> similar examples retrieved <math id="S3.SS3.SSS0.Px3.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{K}" display="inline"><semantics id="S3.SS3.SSS0.Px3.p1.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.SSS0.Px3.p1.2.m2.1.1" xref="S3.SS3.SSS0.Px3.p1.2.m2.1.1.cmml">𝒦</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS0.Px3.p1.2.m2.1b"><ci id="S3.SS3.SSS0.Px3.p1.2.m2.1.1.cmml" xref="S3.SS3.SSS0.Px3.p1.2.m2.1.1">𝒦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS0.Px3.p1.2.m2.1c">\mathcal{K}</annotation></semantics></math>, we define an ordered list of quantifier words <math id="S3.SS3.SSS0.Px3.p1.3.m3.3" class="ltx_Math" alttext="\mathcal{Q}=[q_{1},\dots,q_{M}]" display="inline"><semantics id="S3.SS3.SSS0.Px3.p1.3.m3.3a"><mrow id="S3.SS3.SSS0.Px3.p1.3.m3.3.3" xref="S3.SS3.SSS0.Px3.p1.3.m3.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.SSS0.Px3.p1.3.m3.3.3.4" xref="S3.SS3.SSS0.Px3.p1.3.m3.3.3.4.cmml">𝒬</mi><mo id="S3.SS3.SSS0.Px3.p1.3.m3.3.3.3" xref="S3.SS3.SSS0.Px3.p1.3.m3.3.3.3.cmml">=</mo><mrow id="S3.SS3.SSS0.Px3.p1.3.m3.3.3.2.2" xref="S3.SS3.SSS0.Px3.p1.3.m3.3.3.2.3.cmml"><mo stretchy="false" id="S3.SS3.SSS0.Px3.p1.3.m3.3.3.2.2.3" xref="S3.SS3.SSS0.Px3.p1.3.m3.3.3.2.3.cmml">[</mo><msub id="S3.SS3.SSS0.Px3.p1.3.m3.2.2.1.1.1" xref="S3.SS3.SSS0.Px3.p1.3.m3.2.2.1.1.1.cmml"><mi id="S3.SS3.SSS0.Px3.p1.3.m3.2.2.1.1.1.2" xref="S3.SS3.SSS0.Px3.p1.3.m3.2.2.1.1.1.2.cmml">q</mi><mn id="S3.SS3.SSS0.Px3.p1.3.m3.2.2.1.1.1.3" xref="S3.SS3.SSS0.Px3.p1.3.m3.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S3.SS3.SSS0.Px3.p1.3.m3.3.3.2.2.4" xref="S3.SS3.SSS0.Px3.p1.3.m3.3.3.2.3.cmml">,</mo><mi mathvariant="normal" id="S3.SS3.SSS0.Px3.p1.3.m3.1.1" xref="S3.SS3.SSS0.Px3.p1.3.m3.1.1.cmml">…</mi><mo id="S3.SS3.SSS0.Px3.p1.3.m3.3.3.2.2.5" xref="S3.SS3.SSS0.Px3.p1.3.m3.3.3.2.3.cmml">,</mo><msub id="S3.SS3.SSS0.Px3.p1.3.m3.3.3.2.2.2" xref="S3.SS3.SSS0.Px3.p1.3.m3.3.3.2.2.2.cmml"><mi id="S3.SS3.SSS0.Px3.p1.3.m3.3.3.2.2.2.2" xref="S3.SS3.SSS0.Px3.p1.3.m3.3.3.2.2.2.2.cmml">q</mi><mi id="S3.SS3.SSS0.Px3.p1.3.m3.3.3.2.2.2.3" xref="S3.SS3.SSS0.Px3.p1.3.m3.3.3.2.2.2.3.cmml">M</mi></msub><mo stretchy="false" id="S3.SS3.SSS0.Px3.p1.3.m3.3.3.2.2.6" xref="S3.SS3.SSS0.Px3.p1.3.m3.3.3.2.3.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS0.Px3.p1.3.m3.3b"><apply id="S3.SS3.SSS0.Px3.p1.3.m3.3.3.cmml" xref="S3.SS3.SSS0.Px3.p1.3.m3.3.3"><eq id="S3.SS3.SSS0.Px3.p1.3.m3.3.3.3.cmml" xref="S3.SS3.SSS0.Px3.p1.3.m3.3.3.3"></eq><ci id="S3.SS3.SSS0.Px3.p1.3.m3.3.3.4.cmml" xref="S3.SS3.SSS0.Px3.p1.3.m3.3.3.4">𝒬</ci><list id="S3.SS3.SSS0.Px3.p1.3.m3.3.3.2.3.cmml" xref="S3.SS3.SSS0.Px3.p1.3.m3.3.3.2.2"><apply id="S3.SS3.SSS0.Px3.p1.3.m3.2.2.1.1.1.cmml" xref="S3.SS3.SSS0.Px3.p1.3.m3.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS0.Px3.p1.3.m3.2.2.1.1.1.1.cmml" xref="S3.SS3.SSS0.Px3.p1.3.m3.2.2.1.1.1">subscript</csymbol><ci id="S3.SS3.SSS0.Px3.p1.3.m3.2.2.1.1.1.2.cmml" xref="S3.SS3.SSS0.Px3.p1.3.m3.2.2.1.1.1.2">𝑞</ci><cn type="integer" id="S3.SS3.SSS0.Px3.p1.3.m3.2.2.1.1.1.3.cmml" xref="S3.SS3.SSS0.Px3.p1.3.m3.2.2.1.1.1.3">1</cn></apply><ci id="S3.SS3.SSS0.Px3.p1.3.m3.1.1.cmml" xref="S3.SS3.SSS0.Px3.p1.3.m3.1.1">…</ci><apply id="S3.SS3.SSS0.Px3.p1.3.m3.3.3.2.2.2.cmml" xref="S3.SS3.SSS0.Px3.p1.3.m3.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS3.SSS0.Px3.p1.3.m3.3.3.2.2.2.1.cmml" xref="S3.SS3.SSS0.Px3.p1.3.m3.3.3.2.2.2">subscript</csymbol><ci id="S3.SS3.SSS0.Px3.p1.3.m3.3.3.2.2.2.2.cmml" xref="S3.SS3.SSS0.Px3.p1.3.m3.3.3.2.2.2.2">𝑞</ci><ci id="S3.SS3.SSS0.Px3.p1.3.m3.3.3.2.2.2.3.cmml" xref="S3.SS3.SSS0.Px3.p1.3.m3.3.3.2.2.2.3">𝑀</ci></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS0.Px3.p1.3.m3.3c">\mathcal{Q}=[q_{1},\dots,q_{M}]</annotation></semantics></math> (e.g., <math id="S3.SS3.SSS0.Px3.p1.4.m4.1" class="ltx_Math" alttext="[\text{very unlikely, ..., very likely, certainly}]" display="inline"><semantics id="S3.SS3.SSS0.Px3.p1.4.m4.1a"><mrow id="S3.SS3.SSS0.Px3.p1.4.m4.1.2.2" xref="S3.SS3.SSS0.Px3.p1.4.m4.1.2.1.cmml"><mo stretchy="false" id="S3.SS3.SSS0.Px3.p1.4.m4.1.2.2.1" xref="S3.SS3.SSS0.Px3.p1.4.m4.1.2.1.1.cmml">[</mo><mtext id="S3.SS3.SSS0.Px3.p1.4.m4.1.1" xref="S3.SS3.SSS0.Px3.p1.4.m4.1.1a.cmml">very unlikely, …, very likely, certainly</mtext><mo stretchy="false" id="S3.SS3.SSS0.Px3.p1.4.m4.1.2.2.2" xref="S3.SS3.SSS0.Px3.p1.4.m4.1.2.1.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS0.Px3.p1.4.m4.1b"><apply id="S3.SS3.SSS0.Px3.p1.4.m4.1.2.1.cmml" xref="S3.SS3.SSS0.Px3.p1.4.m4.1.2.2"><csymbol cd="latexml" id="S3.SS3.SSS0.Px3.p1.4.m4.1.2.1.1.cmml" xref="S3.SS3.SSS0.Px3.p1.4.m4.1.2.2.1">delimited-[]</csymbol><ci id="S3.SS3.SSS0.Px3.p1.4.m4.1.1a.cmml" xref="S3.SS3.SSS0.Px3.p1.4.m4.1.1"><mtext id="S3.SS3.SSS0.Px3.p1.4.m4.1.1.cmml" xref="S3.SS3.SSS0.Px3.p1.4.m4.1.1">very unlikely, …, very likely, certainly</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS0.Px3.p1.4.m4.1c">[\text{very unlikely, ..., very likely, certainly}]</annotation></semantics></math>) and a text template <math id="S3.SS3.SSS0.Px3.p1.5.m5.1" class="ltx_Math" alttext="T_{\text{prompt}}" display="inline"><semantics id="S3.SS3.SSS0.Px3.p1.5.m5.1a"><msub id="S3.SS3.SSS0.Px3.p1.5.m5.1.1" xref="S3.SS3.SSS0.Px3.p1.5.m5.1.1.cmml"><mi id="S3.SS3.SSS0.Px3.p1.5.m5.1.1.2" xref="S3.SS3.SSS0.Px3.p1.5.m5.1.1.2.cmml">T</mi><mtext id="S3.SS3.SSS0.Px3.p1.5.m5.1.1.3" xref="S3.SS3.SSS0.Px3.p1.5.m5.1.1.3a.cmml">prompt</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS0.Px3.p1.5.m5.1b"><apply id="S3.SS3.SSS0.Px3.p1.5.m5.1.1.cmml" xref="S3.SS3.SSS0.Px3.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS0.Px3.p1.5.m5.1.1.1.cmml" xref="S3.SS3.SSS0.Px3.p1.5.m5.1.1">subscript</csymbol><ci id="S3.SS3.SSS0.Px3.p1.5.m5.1.1.2.cmml" xref="S3.SS3.SSS0.Px3.p1.5.m5.1.1.2">𝑇</ci><ci id="S3.SS3.SSS0.Px3.p1.5.m5.1.1.3a.cmml" xref="S3.SS3.SSS0.Px3.p1.5.m5.1.1.3"><mtext mathsize="70%" id="S3.SS3.SSS0.Px3.p1.5.m5.1.1.3.cmml" xref="S3.SS3.SSS0.Px3.p1.5.m5.1.1.3">prompt</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS0.Px3.p1.5.m5.1c">T_{\text{prompt}}</annotation></semantics></math>. We define a confidence score that counts the frequency of the retrieved answers in <math id="S3.SS3.SSS0.Px3.p1.6.m6.1" class="ltx_Math" alttext="\mathcal{K}" display="inline"><semantics id="S3.SS3.SSS0.Px3.p1.6.m6.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.SSS0.Px3.p1.6.m6.1.1" xref="S3.SS3.SSS0.Px3.p1.6.m6.1.1.cmml">𝒦</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS0.Px3.p1.6.m6.1b"><ci id="S3.SS3.SSS0.Px3.p1.6.m6.1.1.cmml" xref="S3.SS3.SSS0.Px3.p1.6.m6.1.1">𝒦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS0.Px3.p1.6.m6.1c">\mathcal{K}</annotation></semantics></math>, and then select the most frequent answer <math id="S3.SS3.SSS0.Px3.p1.7.m7.1" class="ltx_Math" alttext="y_{r}^{*}" display="inline"><semantics id="S3.SS3.SSS0.Px3.p1.7.m7.1a"><msubsup id="S3.SS3.SSS0.Px3.p1.7.m7.1.1" xref="S3.SS3.SSS0.Px3.p1.7.m7.1.1.cmml"><mi id="S3.SS3.SSS0.Px3.p1.7.m7.1.1.2.2" xref="S3.SS3.SSS0.Px3.p1.7.m7.1.1.2.2.cmml">y</mi><mi id="S3.SS3.SSS0.Px3.p1.7.m7.1.1.2.3" xref="S3.SS3.SSS0.Px3.p1.7.m7.1.1.2.3.cmml">r</mi><mo id="S3.SS3.SSS0.Px3.p1.7.m7.1.1.3" xref="S3.SS3.SSS0.Px3.p1.7.m7.1.1.3.cmml">∗</mo></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS0.Px3.p1.7.m7.1b"><apply id="S3.SS3.SSS0.Px3.p1.7.m7.1.1.cmml" xref="S3.SS3.SSS0.Px3.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS0.Px3.p1.7.m7.1.1.1.cmml" xref="S3.SS3.SSS0.Px3.p1.7.m7.1.1">superscript</csymbol><apply id="S3.SS3.SSS0.Px3.p1.7.m7.1.1.2.cmml" xref="S3.SS3.SSS0.Px3.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS0.Px3.p1.7.m7.1.1.2.1.cmml" xref="S3.SS3.SSS0.Px3.p1.7.m7.1.1">subscript</csymbol><ci id="S3.SS3.SSS0.Px3.p1.7.m7.1.1.2.2.cmml" xref="S3.SS3.SSS0.Px3.p1.7.m7.1.1.2.2">𝑦</ci><ci id="S3.SS3.SSS0.Px3.p1.7.m7.1.1.2.3.cmml" xref="S3.SS3.SSS0.Px3.p1.7.m7.1.1.2.3">𝑟</ci></apply><times id="S3.SS3.SSS0.Px3.p1.7.m7.1.1.3.cmml" xref="S3.SS3.SSS0.Px3.p1.7.m7.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS0.Px3.p1.7.m7.1c">y_{r}^{*}</annotation></semantics></math> from <math id="S3.SS3.SSS0.Px3.p1.8.m8.1" class="ltx_Math" alttext="\mathcal{K}" display="inline"><semantics id="S3.SS3.SSS0.Px3.p1.8.m8.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.SSS0.Px3.p1.8.m8.1.1" xref="S3.SS3.SSS0.Px3.p1.8.m8.1.1.cmml">𝒦</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS0.Px3.p1.8.m8.1b"><ci id="S3.SS3.SSS0.Px3.p1.8.m8.1.1.cmml" xref="S3.SS3.SSS0.Px3.p1.8.m8.1.1">𝒦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS0.Px3.p1.8.m8.1c">\mathcal{K}</annotation></semantics></math> in Eq. (<a href="#S3.E3" title="Equation 3 ‣ Retrieval Embedding: ‣ 3.3 Prompt Construction ‣ 3 Methods ‣ Multimodal Prompt Retrieval for Generative Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>). We then apply a threshold function to select an appropriate quantifier <math id="S3.SS3.SSS0.Px3.p1.9.m9.1" class="ltx_Math" alttext="q_{r}^{*}" display="inline"><semantics id="S3.SS3.SSS0.Px3.p1.9.m9.1a"><msubsup id="S3.SS3.SSS0.Px3.p1.9.m9.1.1" xref="S3.SS3.SSS0.Px3.p1.9.m9.1.1.cmml"><mi id="S3.SS3.SSS0.Px3.p1.9.m9.1.1.2.2" xref="S3.SS3.SSS0.Px3.p1.9.m9.1.1.2.2.cmml">q</mi><mi id="S3.SS3.SSS0.Px3.p1.9.m9.1.1.2.3" xref="S3.SS3.SSS0.Px3.p1.9.m9.1.1.2.3.cmml">r</mi><mo id="S3.SS3.SSS0.Px3.p1.9.m9.1.1.3" xref="S3.SS3.SSS0.Px3.p1.9.m9.1.1.3.cmml">∗</mo></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS0.Px3.p1.9.m9.1b"><apply id="S3.SS3.SSS0.Px3.p1.9.m9.1.1.cmml" xref="S3.SS3.SSS0.Px3.p1.9.m9.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS0.Px3.p1.9.m9.1.1.1.cmml" xref="S3.SS3.SSS0.Px3.p1.9.m9.1.1">superscript</csymbol><apply id="S3.SS3.SSS0.Px3.p1.9.m9.1.1.2.cmml" xref="S3.SS3.SSS0.Px3.p1.9.m9.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS0.Px3.p1.9.m9.1.1.2.1.cmml" xref="S3.SS3.SSS0.Px3.p1.9.m9.1.1">subscript</csymbol><ci id="S3.SS3.SSS0.Px3.p1.9.m9.1.1.2.2.cmml" xref="S3.SS3.SSS0.Px3.p1.9.m9.1.1.2.2">𝑞</ci><ci id="S3.SS3.SSS0.Px3.p1.9.m9.1.1.2.3.cmml" xref="S3.SS3.SSS0.Px3.p1.9.m9.1.1.2.3">𝑟</ci></apply><times id="S3.SS3.SSS0.Px3.p1.9.m9.1.1.3.cmml" xref="S3.SS3.SSS0.Px3.p1.9.m9.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS0.Px3.p1.9.m9.1c">q_{r}^{*}</annotation></semantics></math> from <math id="S3.SS3.SSS0.Px3.p1.10.m10.1" class="ltx_Math" alttext="\mathcal{Q}" display="inline"><semantics id="S3.SS3.SSS0.Px3.p1.10.m10.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.SSS0.Px3.p1.10.m10.1.1" xref="S3.SS3.SSS0.Px3.p1.10.m10.1.1.cmml">𝒬</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS0.Px3.p1.10.m10.1b"><ci id="S3.SS3.SSS0.Px3.p1.10.m10.1.1.cmml" xref="S3.SS3.SSS0.Px3.p1.10.m10.1.1">𝒬</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS0.Px3.p1.10.m10.1c">\mathcal{Q}</annotation></semantics></math> based on the confidence score of <math id="S3.SS3.SSS0.Px3.p1.11.m11.1" class="ltx_Math" alttext="y_{r}^{*}" display="inline"><semantics id="S3.SS3.SSS0.Px3.p1.11.m11.1a"><msubsup id="S3.SS3.SSS0.Px3.p1.11.m11.1.1" xref="S3.SS3.SSS0.Px3.p1.11.m11.1.1.cmml"><mi id="S3.SS3.SSS0.Px3.p1.11.m11.1.1.2.2" xref="S3.SS3.SSS0.Px3.p1.11.m11.1.1.2.2.cmml">y</mi><mi id="S3.SS3.SSS0.Px3.p1.11.m11.1.1.2.3" xref="S3.SS3.SSS0.Px3.p1.11.m11.1.1.2.3.cmml">r</mi><mo id="S3.SS3.SSS0.Px3.p1.11.m11.1.1.3" xref="S3.SS3.SSS0.Px3.p1.11.m11.1.1.3.cmml">∗</mo></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS0.Px3.p1.11.m11.1b"><apply id="S3.SS3.SSS0.Px3.p1.11.m11.1.1.cmml" xref="S3.SS3.SSS0.Px3.p1.11.m11.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS0.Px3.p1.11.m11.1.1.1.cmml" xref="S3.SS3.SSS0.Px3.p1.11.m11.1.1">superscript</csymbol><apply id="S3.SS3.SSS0.Px3.p1.11.m11.1.1.2.cmml" xref="S3.SS3.SSS0.Px3.p1.11.m11.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS0.Px3.p1.11.m11.1.1.2.1.cmml" xref="S3.SS3.SSS0.Px3.p1.11.m11.1.1">subscript</csymbol><ci id="S3.SS3.SSS0.Px3.p1.11.m11.1.1.2.2.cmml" xref="S3.SS3.SSS0.Px3.p1.11.m11.1.1.2.2">𝑦</ci><ci id="S3.SS3.SSS0.Px3.p1.11.m11.1.1.2.3.cmml" xref="S3.SS3.SSS0.Px3.p1.11.m11.1.1.2.3">𝑟</ci></apply><times id="S3.SS3.SSS0.Px3.p1.11.m11.1.1.3.cmml" xref="S3.SS3.SSS0.Px3.p1.11.m11.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS0.Px3.p1.11.m11.1c">y_{r}^{*}</annotation></semantics></math> by Eq. (<a href="#S3.E4" title="Equation 4 ‣ Retrieval Embedding: ‣ 3.3 Prompt Construction ‣ 3 Methods ‣ Multimodal Prompt Retrieval for Generative Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>).</p>
<table id="A4.EGx2" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S3.E3"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S3.E3.m2.6" class="ltx_Math" alttext="\displaystyle\mathbf{p}_{r}^{*},y_{r}^{*}=\arg\max_{(\mathbf{p},y)~{}\in\mathcal{K}}\text{Freq}(y,\mathcal{K})" display="inline"><semantics id="S3.E3.m2.6a"><mrow id="S3.E3.m2.6.6" xref="S3.E3.m2.6.6.cmml"><mrow id="S3.E3.m2.6.6.2.2" xref="S3.E3.m2.6.6.2.3.cmml"><msubsup id="S3.E3.m2.5.5.1.1.1" xref="S3.E3.m2.5.5.1.1.1.cmml"><mi id="S3.E3.m2.5.5.1.1.1.2.2" xref="S3.E3.m2.5.5.1.1.1.2.2.cmml">𝐩</mi><mi id="S3.E3.m2.5.5.1.1.1.2.3" xref="S3.E3.m2.5.5.1.1.1.2.3.cmml">r</mi><mo id="S3.E3.m2.5.5.1.1.1.3" xref="S3.E3.m2.5.5.1.1.1.3.cmml">∗</mo></msubsup><mo id="S3.E3.m2.6.6.2.2.3" xref="S3.E3.m2.6.6.2.3.cmml">,</mo><msubsup id="S3.E3.m2.6.6.2.2.2" xref="S3.E3.m2.6.6.2.2.2.cmml"><mi id="S3.E3.m2.6.6.2.2.2.2.2" xref="S3.E3.m2.6.6.2.2.2.2.2.cmml">y</mi><mi id="S3.E3.m2.6.6.2.2.2.2.3" xref="S3.E3.m2.6.6.2.2.2.2.3.cmml">r</mi><mo id="S3.E3.m2.6.6.2.2.2.3" xref="S3.E3.m2.6.6.2.2.2.3.cmml">∗</mo></msubsup></mrow><mo id="S3.E3.m2.6.6.3" xref="S3.E3.m2.6.6.3.cmml">=</mo><mrow id="S3.E3.m2.6.6.4" xref="S3.E3.m2.6.6.4.cmml"><mrow id="S3.E3.m2.6.6.4.2" xref="S3.E3.m2.6.6.4.2.cmml"><mi id="S3.E3.m2.6.6.4.2.1" xref="S3.E3.m2.6.6.4.2.1.cmml">arg</mi><mo lspace="0.167em" id="S3.E3.m2.6.6.4.2a" xref="S3.E3.m2.6.6.4.2.cmml">⁡</mo><mrow id="S3.E3.m2.6.6.4.2.2" xref="S3.E3.m2.6.6.4.2.2.cmml"><munder id="S3.E3.m2.6.6.4.2.2.1" xref="S3.E3.m2.6.6.4.2.2.1.cmml"><mi id="S3.E3.m2.6.6.4.2.2.1.2" xref="S3.E3.m2.6.6.4.2.2.1.2.cmml">max</mi><mrow id="S3.E3.m2.2.2.2" xref="S3.E3.m2.2.2.2.cmml"><mrow id="S3.E3.m2.2.2.2.4.2" xref="S3.E3.m2.2.2.2.4.1.cmml"><mo stretchy="false" id="S3.E3.m2.2.2.2.4.2.1" xref="S3.E3.m2.2.2.2.4.1.cmml">(</mo><mi id="S3.E3.m2.1.1.1.1" xref="S3.E3.m2.1.1.1.1.cmml">𝐩</mi><mo id="S3.E3.m2.2.2.2.4.2.2" xref="S3.E3.m2.2.2.2.4.1.cmml">,</mo><mi id="S3.E3.m2.2.2.2.2" xref="S3.E3.m2.2.2.2.2.cmml">y</mi><mo rspace="0.230em" stretchy="false" id="S3.E3.m2.2.2.2.4.2.3" xref="S3.E3.m2.2.2.2.4.1.cmml">)</mo></mrow><mo id="S3.E3.m2.2.2.2.3" xref="S3.E3.m2.2.2.2.3.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S3.E3.m2.2.2.2.5" xref="S3.E3.m2.2.2.2.5.cmml">𝒦</mi></mrow></munder><mo lspace="0.167em" id="S3.E3.m2.6.6.4.2.2a" xref="S3.E3.m2.6.6.4.2.2.cmml">⁡</mo><mtext id="S3.E3.m2.6.6.4.2.2.2" xref="S3.E3.m2.6.6.4.2.2.2a.cmml">Freq</mtext></mrow></mrow><mo lspace="0em" rspace="0em" id="S3.E3.m2.6.6.4.1" xref="S3.E3.m2.6.6.4.1.cmml">​</mo><mrow id="S3.E3.m2.6.6.4.3.2" xref="S3.E3.m2.6.6.4.3.1.cmml"><mo stretchy="false" id="S3.E3.m2.6.6.4.3.2.1" xref="S3.E3.m2.6.6.4.3.1.cmml">(</mo><mi id="S3.E3.m2.3.3" xref="S3.E3.m2.3.3.cmml">y</mi><mo id="S3.E3.m2.6.6.4.3.2.2" xref="S3.E3.m2.6.6.4.3.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S3.E3.m2.4.4" xref="S3.E3.m2.4.4.cmml">𝒦</mi><mo stretchy="false" id="S3.E3.m2.6.6.4.3.2.3" xref="S3.E3.m2.6.6.4.3.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m2.6b"><apply id="S3.E3.m2.6.6.cmml" xref="S3.E3.m2.6.6"><eq id="S3.E3.m2.6.6.3.cmml" xref="S3.E3.m2.6.6.3"></eq><list id="S3.E3.m2.6.6.2.3.cmml" xref="S3.E3.m2.6.6.2.2"><apply id="S3.E3.m2.5.5.1.1.1.cmml" xref="S3.E3.m2.5.5.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m2.5.5.1.1.1.1.cmml" xref="S3.E3.m2.5.5.1.1.1">superscript</csymbol><apply id="S3.E3.m2.5.5.1.1.1.2.cmml" xref="S3.E3.m2.5.5.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m2.5.5.1.1.1.2.1.cmml" xref="S3.E3.m2.5.5.1.1.1">subscript</csymbol><ci id="S3.E3.m2.5.5.1.1.1.2.2.cmml" xref="S3.E3.m2.5.5.1.1.1.2.2">𝐩</ci><ci id="S3.E3.m2.5.5.1.1.1.2.3.cmml" xref="S3.E3.m2.5.5.1.1.1.2.3">𝑟</ci></apply><times id="S3.E3.m2.5.5.1.1.1.3.cmml" xref="S3.E3.m2.5.5.1.1.1.3"></times></apply><apply id="S3.E3.m2.6.6.2.2.2.cmml" xref="S3.E3.m2.6.6.2.2.2"><csymbol cd="ambiguous" id="S3.E3.m2.6.6.2.2.2.1.cmml" xref="S3.E3.m2.6.6.2.2.2">superscript</csymbol><apply id="S3.E3.m2.6.6.2.2.2.2.cmml" xref="S3.E3.m2.6.6.2.2.2"><csymbol cd="ambiguous" id="S3.E3.m2.6.6.2.2.2.2.1.cmml" xref="S3.E3.m2.6.6.2.2.2">subscript</csymbol><ci id="S3.E3.m2.6.6.2.2.2.2.2.cmml" xref="S3.E3.m2.6.6.2.2.2.2.2">𝑦</ci><ci id="S3.E3.m2.6.6.2.2.2.2.3.cmml" xref="S3.E3.m2.6.6.2.2.2.2.3">𝑟</ci></apply><times id="S3.E3.m2.6.6.2.2.2.3.cmml" xref="S3.E3.m2.6.6.2.2.2.3"></times></apply></list><apply id="S3.E3.m2.6.6.4.cmml" xref="S3.E3.m2.6.6.4"><times id="S3.E3.m2.6.6.4.1.cmml" xref="S3.E3.m2.6.6.4.1"></times><apply id="S3.E3.m2.6.6.4.2.cmml" xref="S3.E3.m2.6.6.4.2"><arg id="S3.E3.m2.6.6.4.2.1.cmml" xref="S3.E3.m2.6.6.4.2.1"></arg><apply id="S3.E3.m2.6.6.4.2.2.cmml" xref="S3.E3.m2.6.6.4.2.2"><apply id="S3.E3.m2.6.6.4.2.2.1.cmml" xref="S3.E3.m2.6.6.4.2.2.1"><csymbol cd="ambiguous" id="S3.E3.m2.6.6.4.2.2.1.1.cmml" xref="S3.E3.m2.6.6.4.2.2.1">subscript</csymbol><max id="S3.E3.m2.6.6.4.2.2.1.2.cmml" xref="S3.E3.m2.6.6.4.2.2.1.2"></max><apply id="S3.E3.m2.2.2.2.cmml" xref="S3.E3.m2.2.2.2"><in id="S3.E3.m2.2.2.2.3.cmml" xref="S3.E3.m2.2.2.2.3"></in><interval closure="open" id="S3.E3.m2.2.2.2.4.1.cmml" xref="S3.E3.m2.2.2.2.4.2"><ci id="S3.E3.m2.1.1.1.1.cmml" xref="S3.E3.m2.1.1.1.1">𝐩</ci><ci id="S3.E3.m2.2.2.2.2.cmml" xref="S3.E3.m2.2.2.2.2">𝑦</ci></interval><ci id="S3.E3.m2.2.2.2.5.cmml" xref="S3.E3.m2.2.2.2.5">𝒦</ci></apply></apply><ci id="S3.E3.m2.6.6.4.2.2.2a.cmml" xref="S3.E3.m2.6.6.4.2.2.2"><mtext id="S3.E3.m2.6.6.4.2.2.2.cmml" xref="S3.E3.m2.6.6.4.2.2.2">Freq</mtext></ci></apply></apply><interval closure="open" id="S3.E3.m2.6.6.4.3.1.cmml" xref="S3.E3.m2.6.6.4.3.2"><ci id="S3.E3.m2.3.3.cmml" xref="S3.E3.m2.3.3">𝑦</ci><ci id="S3.E3.m2.4.4.cmml" xref="S3.E3.m2.4.4">𝒦</ci></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m2.6c">\displaystyle\mathbf{p}_{r}^{*},y_{r}^{*}=\arg\max_{(\mathbf{p},y)~{}\in\mathcal{K}}\text{Freq}(y,\mathcal{K})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
<tbody id="S3.E4"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S3.E4.m2.4" class="ltx_Math" alttext="\displaystyle q_{r}^{*}=q_{i},~{}\text{if}~{}\frac{i-1}{M}\leq\frac{\text{Freq}(y_{r}^{*},\mathcal{K})}{k}&lt;\frac{i}{M}" display="inline"><semantics id="S3.E4.m2.4a"><mrow id="S3.E4.m2.4.4.2" xref="S3.E4.m2.4.4.3.cmml"><mrow id="S3.E4.m2.3.3.1.1" xref="S3.E4.m2.3.3.1.1.cmml"><msubsup id="S3.E4.m2.3.3.1.1.2" xref="S3.E4.m2.3.3.1.1.2.cmml"><mi id="S3.E4.m2.3.3.1.1.2.2.2" xref="S3.E4.m2.3.3.1.1.2.2.2.cmml">q</mi><mi id="S3.E4.m2.3.3.1.1.2.2.3" xref="S3.E4.m2.3.3.1.1.2.2.3.cmml">r</mi><mo id="S3.E4.m2.3.3.1.1.2.3" xref="S3.E4.m2.3.3.1.1.2.3.cmml">∗</mo></msubsup><mo id="S3.E4.m2.3.3.1.1.1" xref="S3.E4.m2.3.3.1.1.1.cmml">=</mo><msub id="S3.E4.m2.3.3.1.1.3" xref="S3.E4.m2.3.3.1.1.3.cmml"><mi id="S3.E4.m2.3.3.1.1.3.2" xref="S3.E4.m2.3.3.1.1.3.2.cmml">q</mi><mi id="S3.E4.m2.3.3.1.1.3.3" xref="S3.E4.m2.3.3.1.1.3.3.cmml">i</mi></msub></mrow><mo rspace="0.497em" id="S3.E4.m2.4.4.2.3" xref="S3.E4.m2.4.4.3a.cmml">,</mo><mrow id="S3.E4.m2.4.4.2.2" xref="S3.E4.m2.4.4.2.2.cmml"><mrow id="S3.E4.m2.4.4.2.2.2" xref="S3.E4.m2.4.4.2.2.2.cmml"><mtext id="S3.E4.m2.4.4.2.2.2.2" xref="S3.E4.m2.4.4.2.2.2.2a.cmml">if</mtext><mo lspace="0.330em" rspace="0em" id="S3.E4.m2.4.4.2.2.2.1" xref="S3.E4.m2.4.4.2.2.2.1.cmml">​</mo><mstyle displaystyle="true" id="S3.E4.m2.4.4.2.2.2.3" xref="S3.E4.m2.4.4.2.2.2.3.cmml"><mfrac id="S3.E4.m2.4.4.2.2.2.3a" xref="S3.E4.m2.4.4.2.2.2.3.cmml"><mrow id="S3.E4.m2.4.4.2.2.2.3.2" xref="S3.E4.m2.4.4.2.2.2.3.2.cmml"><mi id="S3.E4.m2.4.4.2.2.2.3.2.2" xref="S3.E4.m2.4.4.2.2.2.3.2.2.cmml">i</mi><mo id="S3.E4.m2.4.4.2.2.2.3.2.1" xref="S3.E4.m2.4.4.2.2.2.3.2.1.cmml">−</mo><mn id="S3.E4.m2.4.4.2.2.2.3.2.3" xref="S3.E4.m2.4.4.2.2.2.3.2.3.cmml">1</mn></mrow><mi id="S3.E4.m2.4.4.2.2.2.3.3" xref="S3.E4.m2.4.4.2.2.2.3.3.cmml">M</mi></mfrac></mstyle></mrow><mo id="S3.E4.m2.4.4.2.2.3" xref="S3.E4.m2.4.4.2.2.3.cmml">≤</mo><mstyle displaystyle="true" id="S3.E4.m2.2.2" xref="S3.E4.m2.2.2.cmml"><mfrac id="S3.E4.m2.2.2a" xref="S3.E4.m2.2.2.cmml"><mrow id="S3.E4.m2.2.2.2" xref="S3.E4.m2.2.2.2.cmml"><mtext id="S3.E4.m2.2.2.2.4" xref="S3.E4.m2.2.2.2.4a.cmml">Freq</mtext><mo lspace="0em" rspace="0em" id="S3.E4.m2.2.2.2.3" xref="S3.E4.m2.2.2.2.3.cmml">​</mo><mrow id="S3.E4.m2.2.2.2.2.1" xref="S3.E4.m2.2.2.2.2.2.cmml"><mo stretchy="false" id="S3.E4.m2.2.2.2.2.1.2" xref="S3.E4.m2.2.2.2.2.2.cmml">(</mo><msubsup id="S3.E4.m2.2.2.2.2.1.1" xref="S3.E4.m2.2.2.2.2.1.1.cmml"><mi id="S3.E4.m2.2.2.2.2.1.1.2.2" xref="S3.E4.m2.2.2.2.2.1.1.2.2.cmml">y</mi><mi id="S3.E4.m2.2.2.2.2.1.1.2.3" xref="S3.E4.m2.2.2.2.2.1.1.2.3.cmml">r</mi><mo id="S3.E4.m2.2.2.2.2.1.1.3" xref="S3.E4.m2.2.2.2.2.1.1.3.cmml">∗</mo></msubsup><mo id="S3.E4.m2.2.2.2.2.1.3" xref="S3.E4.m2.2.2.2.2.2.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S3.E4.m2.1.1.1.1" xref="S3.E4.m2.1.1.1.1.cmml">𝒦</mi><mo stretchy="false" id="S3.E4.m2.2.2.2.2.1.4" xref="S3.E4.m2.2.2.2.2.2.cmml">)</mo></mrow></mrow><mi id="S3.E4.m2.2.2.4" xref="S3.E4.m2.2.2.4.cmml">k</mi></mfrac></mstyle><mo id="S3.E4.m2.4.4.2.2.4" xref="S3.E4.m2.4.4.2.2.4.cmml">&lt;</mo><mstyle displaystyle="true" id="S3.E4.m2.4.4.2.2.5" xref="S3.E4.m2.4.4.2.2.5.cmml"><mfrac id="S3.E4.m2.4.4.2.2.5a" xref="S3.E4.m2.4.4.2.2.5.cmml"><mi id="S3.E4.m2.4.4.2.2.5.2" xref="S3.E4.m2.4.4.2.2.5.2.cmml">i</mi><mi id="S3.E4.m2.4.4.2.2.5.3" xref="S3.E4.m2.4.4.2.2.5.3.cmml">M</mi></mfrac></mstyle></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m2.4b"><apply id="S3.E4.m2.4.4.3.cmml" xref="S3.E4.m2.4.4.2"><csymbol cd="ambiguous" id="S3.E4.m2.4.4.3a.cmml" xref="S3.E4.m2.4.4.2.3">formulae-sequence</csymbol><apply id="S3.E4.m2.3.3.1.1.cmml" xref="S3.E4.m2.3.3.1.1"><eq id="S3.E4.m2.3.3.1.1.1.cmml" xref="S3.E4.m2.3.3.1.1.1"></eq><apply id="S3.E4.m2.3.3.1.1.2.cmml" xref="S3.E4.m2.3.3.1.1.2"><csymbol cd="ambiguous" id="S3.E4.m2.3.3.1.1.2.1.cmml" xref="S3.E4.m2.3.3.1.1.2">superscript</csymbol><apply id="S3.E4.m2.3.3.1.1.2.2.cmml" xref="S3.E4.m2.3.3.1.1.2"><csymbol cd="ambiguous" id="S3.E4.m2.3.3.1.1.2.2.1.cmml" xref="S3.E4.m2.3.3.1.1.2">subscript</csymbol><ci id="S3.E4.m2.3.3.1.1.2.2.2.cmml" xref="S3.E4.m2.3.3.1.1.2.2.2">𝑞</ci><ci id="S3.E4.m2.3.3.1.1.2.2.3.cmml" xref="S3.E4.m2.3.3.1.1.2.2.3">𝑟</ci></apply><times id="S3.E4.m2.3.3.1.1.2.3.cmml" xref="S3.E4.m2.3.3.1.1.2.3"></times></apply><apply id="S3.E4.m2.3.3.1.1.3.cmml" xref="S3.E4.m2.3.3.1.1.3"><csymbol cd="ambiguous" id="S3.E4.m2.3.3.1.1.3.1.cmml" xref="S3.E4.m2.3.3.1.1.3">subscript</csymbol><ci id="S3.E4.m2.3.3.1.1.3.2.cmml" xref="S3.E4.m2.3.3.1.1.3.2">𝑞</ci><ci id="S3.E4.m2.3.3.1.1.3.3.cmml" xref="S3.E4.m2.3.3.1.1.3.3">𝑖</ci></apply></apply><apply id="S3.E4.m2.4.4.2.2.cmml" xref="S3.E4.m2.4.4.2.2"><and id="S3.E4.m2.4.4.2.2a.cmml" xref="S3.E4.m2.4.4.2.2"></and><apply id="S3.E4.m2.4.4.2.2b.cmml" xref="S3.E4.m2.4.4.2.2"><leq id="S3.E4.m2.4.4.2.2.3.cmml" xref="S3.E4.m2.4.4.2.2.3"></leq><apply id="S3.E4.m2.4.4.2.2.2.cmml" xref="S3.E4.m2.4.4.2.2.2"><times id="S3.E4.m2.4.4.2.2.2.1.cmml" xref="S3.E4.m2.4.4.2.2.2.1"></times><ci id="S3.E4.m2.4.4.2.2.2.2a.cmml" xref="S3.E4.m2.4.4.2.2.2.2"><mtext id="S3.E4.m2.4.4.2.2.2.2.cmml" xref="S3.E4.m2.4.4.2.2.2.2">if</mtext></ci><apply id="S3.E4.m2.4.4.2.2.2.3.cmml" xref="S3.E4.m2.4.4.2.2.2.3"><divide id="S3.E4.m2.4.4.2.2.2.3.1.cmml" xref="S3.E4.m2.4.4.2.2.2.3"></divide><apply id="S3.E4.m2.4.4.2.2.2.3.2.cmml" xref="S3.E4.m2.4.4.2.2.2.3.2"><minus id="S3.E4.m2.4.4.2.2.2.3.2.1.cmml" xref="S3.E4.m2.4.4.2.2.2.3.2.1"></minus><ci id="S3.E4.m2.4.4.2.2.2.3.2.2.cmml" xref="S3.E4.m2.4.4.2.2.2.3.2.2">𝑖</ci><cn type="integer" id="S3.E4.m2.4.4.2.2.2.3.2.3.cmml" xref="S3.E4.m2.4.4.2.2.2.3.2.3">1</cn></apply><ci id="S3.E4.m2.4.4.2.2.2.3.3.cmml" xref="S3.E4.m2.4.4.2.2.2.3.3">𝑀</ci></apply></apply><apply id="S3.E4.m2.2.2.cmml" xref="S3.E4.m2.2.2"><divide id="S3.E4.m2.2.2.3.cmml" xref="S3.E4.m2.2.2"></divide><apply id="S3.E4.m2.2.2.2.cmml" xref="S3.E4.m2.2.2.2"><times id="S3.E4.m2.2.2.2.3.cmml" xref="S3.E4.m2.2.2.2.3"></times><ci id="S3.E4.m2.2.2.2.4a.cmml" xref="S3.E4.m2.2.2.2.4"><mtext id="S3.E4.m2.2.2.2.4.cmml" xref="S3.E4.m2.2.2.2.4">Freq</mtext></ci><interval closure="open" id="S3.E4.m2.2.2.2.2.2.cmml" xref="S3.E4.m2.2.2.2.2.1"><apply id="S3.E4.m2.2.2.2.2.1.1.cmml" xref="S3.E4.m2.2.2.2.2.1.1"><csymbol cd="ambiguous" id="S3.E4.m2.2.2.2.2.1.1.1.cmml" xref="S3.E4.m2.2.2.2.2.1.1">superscript</csymbol><apply id="S3.E4.m2.2.2.2.2.1.1.2.cmml" xref="S3.E4.m2.2.2.2.2.1.1"><csymbol cd="ambiguous" id="S3.E4.m2.2.2.2.2.1.1.2.1.cmml" xref="S3.E4.m2.2.2.2.2.1.1">subscript</csymbol><ci id="S3.E4.m2.2.2.2.2.1.1.2.2.cmml" xref="S3.E4.m2.2.2.2.2.1.1.2.2">𝑦</ci><ci id="S3.E4.m2.2.2.2.2.1.1.2.3.cmml" xref="S3.E4.m2.2.2.2.2.1.1.2.3">𝑟</ci></apply><times id="S3.E4.m2.2.2.2.2.1.1.3.cmml" xref="S3.E4.m2.2.2.2.2.1.1.3"></times></apply><ci id="S3.E4.m2.1.1.1.1.cmml" xref="S3.E4.m2.1.1.1.1">𝒦</ci></interval></apply><ci id="S3.E4.m2.2.2.4.cmml" xref="S3.E4.m2.2.2.4">𝑘</ci></apply></apply><apply id="S3.E4.m2.4.4.2.2c.cmml" xref="S3.E4.m2.4.4.2.2"><lt id="S3.E4.m2.4.4.2.2.4.cmml" xref="S3.E4.m2.4.4.2.2.4"></lt><share href="#S3.E4.m2.2.2.cmml" id="S3.E4.m2.4.4.2.2d.cmml" xref="S3.E4.m2.4.4.2.2"></share><apply id="S3.E4.m2.4.4.2.2.5.cmml" xref="S3.E4.m2.4.4.2.2.5"><divide id="S3.E4.m2.4.4.2.2.5.1.cmml" xref="S3.E4.m2.4.4.2.2.5"></divide><ci id="S3.E4.m2.4.4.2.2.5.2.cmml" xref="S3.E4.m2.4.4.2.2.5.2">𝑖</ci><ci id="S3.E4.m2.4.4.2.2.5.3.cmml" xref="S3.E4.m2.4.4.2.2.5.3">𝑀</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m2.4c">\displaystyle q_{r}^{*}=q_{i},~{}\text{if}~{}\frac{i-1}{M}\leq\frac{\text{Freq}(y_{r}^{*},\mathcal{K})}{k}&lt;\frac{i}{M}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p id="S3.SS3.SSS0.Px3.p1.15" class="ltx_p">We then construct the retrieval prompt by filling in the template <math id="S3.SS3.SSS0.Px3.p1.12.m1.1" class="ltx_Math" alttext="T_{\text{prompt}}" display="inline"><semantics id="S3.SS3.SSS0.Px3.p1.12.m1.1a"><msub id="S3.SS3.SSS0.Px3.p1.12.m1.1.1" xref="S3.SS3.SSS0.Px3.p1.12.m1.1.1.cmml"><mi id="S3.SS3.SSS0.Px3.p1.12.m1.1.1.2" xref="S3.SS3.SSS0.Px3.p1.12.m1.1.1.2.cmml">T</mi><mtext id="S3.SS3.SSS0.Px3.p1.12.m1.1.1.3" xref="S3.SS3.SSS0.Px3.p1.12.m1.1.1.3a.cmml">prompt</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS0.Px3.p1.12.m1.1b"><apply id="S3.SS3.SSS0.Px3.p1.12.m1.1.1.cmml" xref="S3.SS3.SSS0.Px3.p1.12.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS0.Px3.p1.12.m1.1.1.1.cmml" xref="S3.SS3.SSS0.Px3.p1.12.m1.1.1">subscript</csymbol><ci id="S3.SS3.SSS0.Px3.p1.12.m1.1.1.2.cmml" xref="S3.SS3.SSS0.Px3.p1.12.m1.1.1.2">𝑇</ci><ci id="S3.SS3.SSS0.Px3.p1.12.m1.1.1.3a.cmml" xref="S3.SS3.SSS0.Px3.p1.12.m1.1.1.3"><mtext mathsize="70%" id="S3.SS3.SSS0.Px3.p1.12.m1.1.1.3.cmml" xref="S3.SS3.SSS0.Px3.p1.12.m1.1.1.3">prompt</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS0.Px3.p1.12.m1.1c">T_{\text{prompt}}</annotation></semantics></math> with the quantifier <math id="S3.SS3.SSS0.Px3.p1.13.m2.1" class="ltx_Math" alttext="q_{r}^{*}" display="inline"><semantics id="S3.SS3.SSS0.Px3.p1.13.m2.1a"><msubsup id="S3.SS3.SSS0.Px3.p1.13.m2.1.1" xref="S3.SS3.SSS0.Px3.p1.13.m2.1.1.cmml"><mi id="S3.SS3.SSS0.Px3.p1.13.m2.1.1.2.2" xref="S3.SS3.SSS0.Px3.p1.13.m2.1.1.2.2.cmml">q</mi><mi id="S3.SS3.SSS0.Px3.p1.13.m2.1.1.2.3" xref="S3.SS3.SSS0.Px3.p1.13.m2.1.1.2.3.cmml">r</mi><mo id="S3.SS3.SSS0.Px3.p1.13.m2.1.1.3" xref="S3.SS3.SSS0.Px3.p1.13.m2.1.1.3.cmml">∗</mo></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS0.Px3.p1.13.m2.1b"><apply id="S3.SS3.SSS0.Px3.p1.13.m2.1.1.cmml" xref="S3.SS3.SSS0.Px3.p1.13.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS0.Px3.p1.13.m2.1.1.1.cmml" xref="S3.SS3.SSS0.Px3.p1.13.m2.1.1">superscript</csymbol><apply id="S3.SS3.SSS0.Px3.p1.13.m2.1.1.2.cmml" xref="S3.SS3.SSS0.Px3.p1.13.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS0.Px3.p1.13.m2.1.1.2.1.cmml" xref="S3.SS3.SSS0.Px3.p1.13.m2.1.1">subscript</csymbol><ci id="S3.SS3.SSS0.Px3.p1.13.m2.1.1.2.2.cmml" xref="S3.SS3.SSS0.Px3.p1.13.m2.1.1.2.2">𝑞</ci><ci id="S3.SS3.SSS0.Px3.p1.13.m2.1.1.2.3.cmml" xref="S3.SS3.SSS0.Px3.p1.13.m2.1.1.2.3">𝑟</ci></apply><times id="S3.SS3.SSS0.Px3.p1.13.m2.1.1.3.cmml" xref="S3.SS3.SSS0.Px3.p1.13.m2.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS0.Px3.p1.13.m2.1c">q_{r}^{*}</annotation></semantics></math> and the retrieved answer <math id="S3.SS3.SSS0.Px3.p1.14.m3.1" class="ltx_Math" alttext="y_{r}^{*}" display="inline"><semantics id="S3.SS3.SSS0.Px3.p1.14.m3.1a"><msubsup id="S3.SS3.SSS0.Px3.p1.14.m3.1.1" xref="S3.SS3.SSS0.Px3.p1.14.m3.1.1.cmml"><mi id="S3.SS3.SSS0.Px3.p1.14.m3.1.1.2.2" xref="S3.SS3.SSS0.Px3.p1.14.m3.1.1.2.2.cmml">y</mi><mi id="S3.SS3.SSS0.Px3.p1.14.m3.1.1.2.3" xref="S3.SS3.SSS0.Px3.p1.14.m3.1.1.2.3.cmml">r</mi><mo id="S3.SS3.SSS0.Px3.p1.14.m3.1.1.3" xref="S3.SS3.SSS0.Px3.p1.14.m3.1.1.3.cmml">∗</mo></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS0.Px3.p1.14.m3.1b"><apply id="S3.SS3.SSS0.Px3.p1.14.m3.1.1.cmml" xref="S3.SS3.SSS0.Px3.p1.14.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS0.Px3.p1.14.m3.1.1.1.cmml" xref="S3.SS3.SSS0.Px3.p1.14.m3.1.1">superscript</csymbol><apply id="S3.SS3.SSS0.Px3.p1.14.m3.1.1.2.cmml" xref="S3.SS3.SSS0.Px3.p1.14.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS0.Px3.p1.14.m3.1.1.2.1.cmml" xref="S3.SS3.SSS0.Px3.p1.14.m3.1.1">subscript</csymbol><ci id="S3.SS3.SSS0.Px3.p1.14.m3.1.1.2.2.cmml" xref="S3.SS3.SSS0.Px3.p1.14.m3.1.1.2.2">𝑦</ci><ci id="S3.SS3.SSS0.Px3.p1.14.m3.1.1.2.3.cmml" xref="S3.SS3.SSS0.Px3.p1.14.m3.1.1.2.3">𝑟</ci></apply><times id="S3.SS3.SSS0.Px3.p1.14.m3.1.1.3.cmml" xref="S3.SS3.SSS0.Px3.p1.14.m3.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS0.Px3.p1.14.m3.1c">y_{r}^{*}</annotation></semantics></math>. We detail example templates and prompt variants we explored in Appendix <a href="#A1" title="Appendix A Templates ‣ Multimodal Prompt Retrieval for Generative Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A</span></a>. The same pre-trained T5 model used for the question prompt is used to tokenize the retrieval prompt and obtain the retrieval embeddings <math id="S3.SS3.SSS0.Px3.p1.15.m4.1" class="ltx_Math" alttext="\mathbf{x}_{r}\in\mathbb{R}^{l_{r}\times d}" display="inline"><semantics id="S3.SS3.SSS0.Px3.p1.15.m4.1a"><mrow id="S3.SS3.SSS0.Px3.p1.15.m4.1.1" xref="S3.SS3.SSS0.Px3.p1.15.m4.1.1.cmml"><msub id="S3.SS3.SSS0.Px3.p1.15.m4.1.1.2" xref="S3.SS3.SSS0.Px3.p1.15.m4.1.1.2.cmml"><mi id="S3.SS3.SSS0.Px3.p1.15.m4.1.1.2.2" xref="S3.SS3.SSS0.Px3.p1.15.m4.1.1.2.2.cmml">𝐱</mi><mi id="S3.SS3.SSS0.Px3.p1.15.m4.1.1.2.3" xref="S3.SS3.SSS0.Px3.p1.15.m4.1.1.2.3.cmml">r</mi></msub><mo id="S3.SS3.SSS0.Px3.p1.15.m4.1.1.1" xref="S3.SS3.SSS0.Px3.p1.15.m4.1.1.1.cmml">∈</mo><msup id="S3.SS3.SSS0.Px3.p1.15.m4.1.1.3" xref="S3.SS3.SSS0.Px3.p1.15.m4.1.1.3.cmml"><mi id="S3.SS3.SSS0.Px3.p1.15.m4.1.1.3.2" xref="S3.SS3.SSS0.Px3.p1.15.m4.1.1.3.2.cmml">ℝ</mi><mrow id="S3.SS3.SSS0.Px3.p1.15.m4.1.1.3.3" xref="S3.SS3.SSS0.Px3.p1.15.m4.1.1.3.3.cmml"><msub id="S3.SS3.SSS0.Px3.p1.15.m4.1.1.3.3.2" xref="S3.SS3.SSS0.Px3.p1.15.m4.1.1.3.3.2.cmml"><mi id="S3.SS3.SSS0.Px3.p1.15.m4.1.1.3.3.2.2" xref="S3.SS3.SSS0.Px3.p1.15.m4.1.1.3.3.2.2.cmml">l</mi><mi id="S3.SS3.SSS0.Px3.p1.15.m4.1.1.3.3.2.3" xref="S3.SS3.SSS0.Px3.p1.15.m4.1.1.3.3.2.3.cmml">r</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.SSS0.Px3.p1.15.m4.1.1.3.3.1" xref="S3.SS3.SSS0.Px3.p1.15.m4.1.1.3.3.1.cmml">×</mo><mi id="S3.SS3.SSS0.Px3.p1.15.m4.1.1.3.3.3" xref="S3.SS3.SSS0.Px3.p1.15.m4.1.1.3.3.3.cmml">d</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS0.Px3.p1.15.m4.1b"><apply id="S3.SS3.SSS0.Px3.p1.15.m4.1.1.cmml" xref="S3.SS3.SSS0.Px3.p1.15.m4.1.1"><in id="S3.SS3.SSS0.Px3.p1.15.m4.1.1.1.cmml" xref="S3.SS3.SSS0.Px3.p1.15.m4.1.1.1"></in><apply id="S3.SS3.SSS0.Px3.p1.15.m4.1.1.2.cmml" xref="S3.SS3.SSS0.Px3.p1.15.m4.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.SSS0.Px3.p1.15.m4.1.1.2.1.cmml" xref="S3.SS3.SSS0.Px3.p1.15.m4.1.1.2">subscript</csymbol><ci id="S3.SS3.SSS0.Px3.p1.15.m4.1.1.2.2.cmml" xref="S3.SS3.SSS0.Px3.p1.15.m4.1.1.2.2">𝐱</ci><ci id="S3.SS3.SSS0.Px3.p1.15.m4.1.1.2.3.cmml" xref="S3.SS3.SSS0.Px3.p1.15.m4.1.1.2.3">𝑟</ci></apply><apply id="S3.SS3.SSS0.Px3.p1.15.m4.1.1.3.cmml" xref="S3.SS3.SSS0.Px3.p1.15.m4.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.SSS0.Px3.p1.15.m4.1.1.3.1.cmml" xref="S3.SS3.SSS0.Px3.p1.15.m4.1.1.3">superscript</csymbol><ci id="S3.SS3.SSS0.Px3.p1.15.m4.1.1.3.2.cmml" xref="S3.SS3.SSS0.Px3.p1.15.m4.1.1.3.2">ℝ</ci><apply id="S3.SS3.SSS0.Px3.p1.15.m4.1.1.3.3.cmml" xref="S3.SS3.SSS0.Px3.p1.15.m4.1.1.3.3"><times id="S3.SS3.SSS0.Px3.p1.15.m4.1.1.3.3.1.cmml" xref="S3.SS3.SSS0.Px3.p1.15.m4.1.1.3.3.1"></times><apply id="S3.SS3.SSS0.Px3.p1.15.m4.1.1.3.3.2.cmml" xref="S3.SS3.SSS0.Px3.p1.15.m4.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.SS3.SSS0.Px3.p1.15.m4.1.1.3.3.2.1.cmml" xref="S3.SS3.SSS0.Px3.p1.15.m4.1.1.3.3.2">subscript</csymbol><ci id="S3.SS3.SSS0.Px3.p1.15.m4.1.1.3.3.2.2.cmml" xref="S3.SS3.SSS0.Px3.p1.15.m4.1.1.3.3.2.2">𝑙</ci><ci id="S3.SS3.SSS0.Px3.p1.15.m4.1.1.3.3.2.3.cmml" xref="S3.SS3.SSS0.Px3.p1.15.m4.1.1.3.3.2.3">𝑟</ci></apply><ci id="S3.SS3.SSS0.Px3.p1.15.m4.1.1.3.3.3.cmml" xref="S3.SS3.SSS0.Px3.p1.15.m4.1.1.3.3.3">𝑑</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS0.Px3.p1.15.m4.1c">\mathbf{x}_{r}\in\mathbb{R}^{l_{r}\times d}</annotation></semantics></math>.</p>
</div>
</section>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Generative Visual Question Answering</h3>

<section id="S3.SS4.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Encoder:</h4>

<div id="S3.SS4.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS4.SSS0.Px1.p1.2" class="ltx_p">Following prompt construction, we obtain a combination of embeddings <math id="S3.SS4.SSS0.Px1.p1.1.m1.3" class="ltx_Math" alttext="[\mathbf{v}_{p};\mathbf{x}_{q};\mathbf{x}_{r}]" display="inline"><semantics id="S3.SS4.SSS0.Px1.p1.1.m1.3a"><mrow id="S3.SS4.SSS0.Px1.p1.1.m1.3.3.3" xref="S3.SS4.SSS0.Px1.p1.1.m1.3.3.4.cmml"><mo stretchy="false" id="S3.SS4.SSS0.Px1.p1.1.m1.3.3.3.4" xref="S3.SS4.SSS0.Px1.p1.1.m1.3.3.4.cmml">[</mo><msub id="S3.SS4.SSS0.Px1.p1.1.m1.1.1.1.1" xref="S3.SS4.SSS0.Px1.p1.1.m1.1.1.1.1.cmml"><mi id="S3.SS4.SSS0.Px1.p1.1.m1.1.1.1.1.2" xref="S3.SS4.SSS0.Px1.p1.1.m1.1.1.1.1.2.cmml">𝐯</mi><mi id="S3.SS4.SSS0.Px1.p1.1.m1.1.1.1.1.3" xref="S3.SS4.SSS0.Px1.p1.1.m1.1.1.1.1.3.cmml">p</mi></msub><mo id="S3.SS4.SSS0.Px1.p1.1.m1.3.3.3.5" xref="S3.SS4.SSS0.Px1.p1.1.m1.3.3.4.cmml">;</mo><msub id="S3.SS4.SSS0.Px1.p1.1.m1.2.2.2.2" xref="S3.SS4.SSS0.Px1.p1.1.m1.2.2.2.2.cmml"><mi id="S3.SS4.SSS0.Px1.p1.1.m1.2.2.2.2.2" xref="S3.SS4.SSS0.Px1.p1.1.m1.2.2.2.2.2.cmml">𝐱</mi><mi id="S3.SS4.SSS0.Px1.p1.1.m1.2.2.2.2.3" xref="S3.SS4.SSS0.Px1.p1.1.m1.2.2.2.2.3.cmml">q</mi></msub><mo id="S3.SS4.SSS0.Px1.p1.1.m1.3.3.3.6" xref="S3.SS4.SSS0.Px1.p1.1.m1.3.3.4.cmml">;</mo><msub id="S3.SS4.SSS0.Px1.p1.1.m1.3.3.3.3" xref="S3.SS4.SSS0.Px1.p1.1.m1.3.3.3.3.cmml"><mi id="S3.SS4.SSS0.Px1.p1.1.m1.3.3.3.3.2" xref="S3.SS4.SSS0.Px1.p1.1.m1.3.3.3.3.2.cmml">𝐱</mi><mi id="S3.SS4.SSS0.Px1.p1.1.m1.3.3.3.3.3" xref="S3.SS4.SSS0.Px1.p1.1.m1.3.3.3.3.3.cmml">r</mi></msub><mo stretchy="false" id="S3.SS4.SSS0.Px1.p1.1.m1.3.3.3.7" xref="S3.SS4.SSS0.Px1.p1.1.m1.3.3.4.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS0.Px1.p1.1.m1.3b"><list id="S3.SS4.SSS0.Px1.p1.1.m1.3.3.4.cmml" xref="S3.SS4.SSS0.Px1.p1.1.m1.3.3.3"><apply id="S3.SS4.SSS0.Px1.p1.1.m1.1.1.1.1.cmml" xref="S3.SS4.SSS0.Px1.p1.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS4.SSS0.Px1.p1.1.m1.1.1.1.1.1.cmml" xref="S3.SS4.SSS0.Px1.p1.1.m1.1.1.1.1">subscript</csymbol><ci id="S3.SS4.SSS0.Px1.p1.1.m1.1.1.1.1.2.cmml" xref="S3.SS4.SSS0.Px1.p1.1.m1.1.1.1.1.2">𝐯</ci><ci id="S3.SS4.SSS0.Px1.p1.1.m1.1.1.1.1.3.cmml" xref="S3.SS4.SSS0.Px1.p1.1.m1.1.1.1.1.3">𝑝</ci></apply><apply id="S3.SS4.SSS0.Px1.p1.1.m1.2.2.2.2.cmml" xref="S3.SS4.SSS0.Px1.p1.1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS4.SSS0.Px1.p1.1.m1.2.2.2.2.1.cmml" xref="S3.SS4.SSS0.Px1.p1.1.m1.2.2.2.2">subscript</csymbol><ci id="S3.SS4.SSS0.Px1.p1.1.m1.2.2.2.2.2.cmml" xref="S3.SS4.SSS0.Px1.p1.1.m1.2.2.2.2.2">𝐱</ci><ci id="S3.SS4.SSS0.Px1.p1.1.m1.2.2.2.2.3.cmml" xref="S3.SS4.SSS0.Px1.p1.1.m1.2.2.2.2.3">𝑞</ci></apply><apply id="S3.SS4.SSS0.Px1.p1.1.m1.3.3.3.3.cmml" xref="S3.SS4.SSS0.Px1.p1.1.m1.3.3.3.3"><csymbol cd="ambiguous" id="S3.SS4.SSS0.Px1.p1.1.m1.3.3.3.3.1.cmml" xref="S3.SS4.SSS0.Px1.p1.1.m1.3.3.3.3">subscript</csymbol><ci id="S3.SS4.SSS0.Px1.p1.1.m1.3.3.3.3.2.cmml" xref="S3.SS4.SSS0.Px1.p1.1.m1.3.3.3.3.2">𝐱</ci><ci id="S3.SS4.SSS0.Px1.p1.1.m1.3.3.3.3.3.cmml" xref="S3.SS4.SSS0.Px1.p1.1.m1.3.3.3.3.3">𝑟</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS0.Px1.p1.1.m1.3c">[\mathbf{v}_{p};\mathbf{x}_{q};\mathbf{x}_{r}]</annotation></semantics></math> which is further fed as inputs to the transformer encoder layers of a pre-trained T5 model, and obtain contextualized representations of the combined sequence from the top encoder layer, where we denote as <math id="S3.SS4.SSS0.Px1.p1.2.m2.1" class="ltx_Math" alttext="\mathbf{X}=\text{Encoder}([\mathbf{v}_{p};\mathbf{x}_{q};\mathbf{x}_{r}])" display="inline"><semantics id="S3.SS4.SSS0.Px1.p1.2.m2.1a"><mrow id="S3.SS4.SSS0.Px1.p1.2.m2.1.1" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.cmml"><mi id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.3" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.3.cmml">𝐗</mi><mo id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.2" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.2.cmml">=</mo><mrow id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.cmml"><mtext id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.3" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.3a.cmml">Encoder</mtext><mo lspace="0em" rspace="0em" id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.2" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.2.cmml">​</mo><mrow id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.1.1" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.cmml"><mo stretchy="false" id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.1.1.2" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.cmml">(</mo><mrow id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.3" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.4.cmml"><mo stretchy="false" id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.3.4" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.4.cmml">[</mo><msub id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.1" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.1.cmml"><mi id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.1.2" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.1.2.cmml">𝐯</mi><mi id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.1.3" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.1.3.cmml">p</mi></msub><mo id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.3.5" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.4.cmml">;</mo><msub id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.2.2" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.2.2.cmml"><mi id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.2.2.2" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.2.2.2.cmml">𝐱</mi><mi id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.2.2.3" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.2.2.3.cmml">q</mi></msub><mo id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.3.6" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.4.cmml">;</mo><msub id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.3.3" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.3.3.cmml"><mi id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.3.3.2" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.3.3.2.cmml">𝐱</mi><mi id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.3.3.3" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.3.3.3.cmml">r</mi></msub><mo stretchy="false" id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.3.7" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.4.cmml">]</mo></mrow><mo stretchy="false" id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.1.1.3" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS0.Px1.p1.2.m2.1b"><apply id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1"><eq id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.2.cmml" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.2"></eq><ci id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.3.cmml" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.3">𝐗</ci><apply id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.cmml" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1"><times id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.2.cmml" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.2"></times><ci id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.3a.cmml" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.3"><mtext id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.3.cmml" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.3">Encoder</mtext></ci><list id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.4.cmml" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.3"><apply id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.1.cmml" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.1.2.cmml" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.1.2">𝐯</ci><ci id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.1.3.cmml" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.1.1.3">𝑝</ci></apply><apply id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.2.2.cmml" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.2.2.1.cmml" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.2.2">subscript</csymbol><ci id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.2.2.2.cmml" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.2.2.2">𝐱</ci><ci id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.2.2.3.cmml" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.2.2.3">𝑞</ci></apply><apply id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.3.3.cmml" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.3.3.1.cmml" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.3.3">subscript</csymbol><ci id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.3.3.2.cmml" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.3.3.2">𝐱</ci><ci id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.3.3.3.cmml" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.1.1.1.3.3.3">𝑟</ci></apply></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS0.Px1.p1.2.m2.1c">\mathbf{X}=\text{Encoder}([\mathbf{v}_{p};\mathbf{x}_{q};\mathbf{x}_{r}])</annotation></semantics></math>. In this work, we use a moderately sized model with around 60 million parameters, T5-small, and leave models with more parameters for future exploration.</p>
</div>
</section>
<section id="S3.SS4.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Decoder:</h4>

<div id="S3.SS4.SSS0.Px2.p1" class="ltx_para">
<p id="S3.SS4.SSS0.Px2.p1.5" class="ltx_p">While most prior works use a discriminative architecture for medical VQA, we experiment with a decoder to predict free-form text. A transformer decoder from T5 is used to predict words in the vocabulary autoregressively. As each answer label <math id="S3.SS4.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="y" display="inline"><semantics id="S3.SS4.SSS0.Px2.p1.1.m1.1a"><mi id="S3.SS4.SSS0.Px2.p1.1.m1.1.1" xref="S3.SS4.SSS0.Px2.p1.1.m1.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS0.Px2.p1.1.m1.1b"><ci id="S3.SS4.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S3.SS4.SSS0.Px2.p1.1.m1.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS0.Px2.p1.1.m1.1c">y</annotation></semantics></math> has a corresponding text string <math id="S3.SS4.SSS0.Px2.p1.2.m2.1" class="ltx_Math" alttext="z" display="inline"><semantics id="S3.SS4.SSS0.Px2.p1.2.m2.1a"><mi id="S3.SS4.SSS0.Px2.p1.2.m2.1.1" xref="S3.SS4.SSS0.Px2.p1.2.m2.1.1.cmml">z</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS0.Px2.p1.2.m2.1b"><ci id="S3.SS4.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S3.SS4.SSS0.Px2.p1.2.m2.1.1">𝑧</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS0.Px2.p1.2.m2.1c">z</annotation></semantics></math> of varying length, we formulate the likelihood of an answer string <math id="S3.SS4.SSS0.Px2.p1.3.m3.1" class="ltx_Math" alttext="z" display="inline"><semantics id="S3.SS4.SSS0.Px2.p1.3.m3.1a"><mi id="S3.SS4.SSS0.Px2.p1.3.m3.1.1" xref="S3.SS4.SSS0.Px2.p1.3.m3.1.1.cmml">z</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS0.Px2.p1.3.m3.1b"><ci id="S3.SS4.SSS0.Px2.p1.3.m3.1.1.cmml" xref="S3.SS4.SSS0.Px2.p1.3.m3.1.1">𝑧</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS0.Px2.p1.3.m3.1c">z</annotation></semantics></math> given an image <math id="S3.SS4.SSS0.Px2.p1.4.m4.1" class="ltx_Math" alttext="\mathbf{v}" display="inline"><semantics id="S3.SS4.SSS0.Px2.p1.4.m4.1a"><mi id="S3.SS4.SSS0.Px2.p1.4.m4.1.1" xref="S3.SS4.SSS0.Px2.p1.4.m4.1.1.cmml">𝐯</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS0.Px2.p1.4.m4.1b"><ci id="S3.SS4.SSS0.Px2.p1.4.m4.1.1.cmml" xref="S3.SS4.SSS0.Px2.p1.4.m4.1.1">𝐯</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS0.Px2.p1.4.m4.1c">\mathbf{v}</annotation></semantics></math> and a question <math id="S3.SS4.SSS0.Px2.p1.5.m5.1" class="ltx_Math" alttext="\mathbf{x}" display="inline"><semantics id="S3.SS4.SSS0.Px2.p1.5.m5.1a"><mi id="S3.SS4.SSS0.Px2.p1.5.m5.1.1" xref="S3.SS4.SSS0.Px2.p1.5.m5.1.1.cmml">𝐱</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS0.Px2.p1.5.m5.1b"><ci id="S3.SS4.SSS0.Px2.p1.5.m5.1.1.cmml" xref="S3.SS4.SSS0.Px2.p1.5.m5.1.1">𝐱</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS0.Px2.p1.5.m5.1c">\mathbf{x}</annotation></semantics></math> by the following conditional probability:</p>
<table id="A4.EGx3" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S3.E5"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E5.m1.3" class="ltx_Math" alttext="\displaystyle P_{\text{gen}}(z|\mathbf{X})=\prod_{j=0}^{|z|}P_{\phi}(z_{j}|\mathbf{X},z_{&lt;j})." display="inline"><semantics id="S3.E5.m1.3a"><mrow id="S3.E5.m1.3.3.1" xref="S3.E5.m1.3.3.1.1.cmml"><mrow id="S3.E5.m1.3.3.1.1" xref="S3.E5.m1.3.3.1.1.cmml"><mrow id="S3.E5.m1.3.3.1.1.1" xref="S3.E5.m1.3.3.1.1.1.cmml"><msub id="S3.E5.m1.3.3.1.1.1.3" xref="S3.E5.m1.3.3.1.1.1.3.cmml"><mi id="S3.E5.m1.3.3.1.1.1.3.2" xref="S3.E5.m1.3.3.1.1.1.3.2.cmml">P</mi><mtext id="S3.E5.m1.3.3.1.1.1.3.3" xref="S3.E5.m1.3.3.1.1.1.3.3a.cmml">gen</mtext></msub><mo lspace="0em" rspace="0em" id="S3.E5.m1.3.3.1.1.1.2" xref="S3.E5.m1.3.3.1.1.1.2.cmml">​</mo><mrow id="S3.E5.m1.3.3.1.1.1.1.1" xref="S3.E5.m1.3.3.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E5.m1.3.3.1.1.1.1.1.2" xref="S3.E5.m1.3.3.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E5.m1.3.3.1.1.1.1.1.1" xref="S3.E5.m1.3.3.1.1.1.1.1.1.cmml"><mi id="S3.E5.m1.3.3.1.1.1.1.1.1.2" xref="S3.E5.m1.3.3.1.1.1.1.1.1.2.cmml">z</mi><mo fence="false" id="S3.E5.m1.3.3.1.1.1.1.1.1.1" xref="S3.E5.m1.3.3.1.1.1.1.1.1.1.cmml">|</mo><mi id="S3.E5.m1.3.3.1.1.1.1.1.1.3" xref="S3.E5.m1.3.3.1.1.1.1.1.1.3.cmml">𝐗</mi></mrow><mo stretchy="false" id="S3.E5.m1.3.3.1.1.1.1.1.3" xref="S3.E5.m1.3.3.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E5.m1.3.3.1.1.3" xref="S3.E5.m1.3.3.1.1.3.cmml">=</mo><mrow id="S3.E5.m1.3.3.1.1.2" xref="S3.E5.m1.3.3.1.1.2.cmml"><mstyle displaystyle="true" id="S3.E5.m1.3.3.1.1.2.2" xref="S3.E5.m1.3.3.1.1.2.2.cmml"><munderover id="S3.E5.m1.3.3.1.1.2.2a" xref="S3.E5.m1.3.3.1.1.2.2.cmml"><mo movablelimits="false" id="S3.E5.m1.3.3.1.1.2.2.2.2" xref="S3.E5.m1.3.3.1.1.2.2.2.2.cmml">∏</mo><mrow id="S3.E5.m1.3.3.1.1.2.2.2.3" xref="S3.E5.m1.3.3.1.1.2.2.2.3.cmml"><mi id="S3.E5.m1.3.3.1.1.2.2.2.3.2" xref="S3.E5.m1.3.3.1.1.2.2.2.3.2.cmml">j</mi><mo id="S3.E5.m1.3.3.1.1.2.2.2.3.1" xref="S3.E5.m1.3.3.1.1.2.2.2.3.1.cmml">=</mo><mn id="S3.E5.m1.3.3.1.1.2.2.2.3.3" xref="S3.E5.m1.3.3.1.1.2.2.2.3.3.cmml">0</mn></mrow><mrow id="S3.E5.m1.1.1.1.3" xref="S3.E5.m1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E5.m1.1.1.1.3.1" xref="S3.E5.m1.1.1.1.2.1.cmml">|</mo><mi id="S3.E5.m1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.cmml">z</mi><mo stretchy="false" id="S3.E5.m1.1.1.1.3.2" xref="S3.E5.m1.1.1.1.2.1.cmml">|</mo></mrow></munderover></mstyle><mrow id="S3.E5.m1.3.3.1.1.2.1" xref="S3.E5.m1.3.3.1.1.2.1.cmml"><msub id="S3.E5.m1.3.3.1.1.2.1.3" xref="S3.E5.m1.3.3.1.1.2.1.3.cmml"><mi id="S3.E5.m1.3.3.1.1.2.1.3.2" xref="S3.E5.m1.3.3.1.1.2.1.3.2.cmml">P</mi><mi id="S3.E5.m1.3.3.1.1.2.1.3.3" xref="S3.E5.m1.3.3.1.1.2.1.3.3.cmml">ϕ</mi></msub><mo lspace="0em" rspace="0em" id="S3.E5.m1.3.3.1.1.2.1.2" xref="S3.E5.m1.3.3.1.1.2.1.2.cmml">​</mo><mrow id="S3.E5.m1.3.3.1.1.2.1.1.1" xref="S3.E5.m1.3.3.1.1.2.1.1.1.1.cmml"><mo stretchy="false" id="S3.E5.m1.3.3.1.1.2.1.1.1.2" xref="S3.E5.m1.3.3.1.1.2.1.1.1.1.cmml">(</mo><mrow id="S3.E5.m1.3.3.1.1.2.1.1.1.1" xref="S3.E5.m1.3.3.1.1.2.1.1.1.1.cmml"><msub id="S3.E5.m1.3.3.1.1.2.1.1.1.1.3" xref="S3.E5.m1.3.3.1.1.2.1.1.1.1.3.cmml"><mi id="S3.E5.m1.3.3.1.1.2.1.1.1.1.3.2" xref="S3.E5.m1.3.3.1.1.2.1.1.1.1.3.2.cmml">z</mi><mi id="S3.E5.m1.3.3.1.1.2.1.1.1.1.3.3" xref="S3.E5.m1.3.3.1.1.2.1.1.1.1.3.3.cmml">j</mi></msub><mo fence="false" id="S3.E5.m1.3.3.1.1.2.1.1.1.1.2" xref="S3.E5.m1.3.3.1.1.2.1.1.1.1.2.cmml">|</mo><mrow id="S3.E5.m1.3.3.1.1.2.1.1.1.1.1.1" xref="S3.E5.m1.3.3.1.1.2.1.1.1.1.1.2.cmml"><mi id="S3.E5.m1.2.2" xref="S3.E5.m1.2.2.cmml">𝐗</mi><mo id="S3.E5.m1.3.3.1.1.2.1.1.1.1.1.1.2" xref="S3.E5.m1.3.3.1.1.2.1.1.1.1.1.2.cmml">,</mo><msub id="S3.E5.m1.3.3.1.1.2.1.1.1.1.1.1.1" xref="S3.E5.m1.3.3.1.1.2.1.1.1.1.1.1.1.cmml"><mi id="S3.E5.m1.3.3.1.1.2.1.1.1.1.1.1.1.2" xref="S3.E5.m1.3.3.1.1.2.1.1.1.1.1.1.1.2.cmml">z</mi><mrow id="S3.E5.m1.3.3.1.1.2.1.1.1.1.1.1.1.3" xref="S3.E5.m1.3.3.1.1.2.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E5.m1.3.3.1.1.2.1.1.1.1.1.1.1.3.2" xref="S3.E5.m1.3.3.1.1.2.1.1.1.1.1.1.1.3.2.cmml"></mi><mo id="S3.E5.m1.3.3.1.1.2.1.1.1.1.1.1.1.3.1" xref="S3.E5.m1.3.3.1.1.2.1.1.1.1.1.1.1.3.1.cmml">&lt;</mo><mi id="S3.E5.m1.3.3.1.1.2.1.1.1.1.1.1.1.3.3" xref="S3.E5.m1.3.3.1.1.2.1.1.1.1.1.1.1.3.3.cmml">j</mi></mrow></msub></mrow></mrow><mo stretchy="false" id="S3.E5.m1.3.3.1.1.2.1.1.1.3" xref="S3.E5.m1.3.3.1.1.2.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><mo lspace="0em" id="S3.E5.m1.3.3.1.2" xref="S3.E5.m1.3.3.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E5.m1.3b"><apply id="S3.E5.m1.3.3.1.1.cmml" xref="S3.E5.m1.3.3.1"><eq id="S3.E5.m1.3.3.1.1.3.cmml" xref="S3.E5.m1.3.3.1.1.3"></eq><apply id="S3.E5.m1.3.3.1.1.1.cmml" xref="S3.E5.m1.3.3.1.1.1"><times id="S3.E5.m1.3.3.1.1.1.2.cmml" xref="S3.E5.m1.3.3.1.1.1.2"></times><apply id="S3.E5.m1.3.3.1.1.1.3.cmml" xref="S3.E5.m1.3.3.1.1.1.3"><csymbol cd="ambiguous" id="S3.E5.m1.3.3.1.1.1.3.1.cmml" xref="S3.E5.m1.3.3.1.1.1.3">subscript</csymbol><ci id="S3.E5.m1.3.3.1.1.1.3.2.cmml" xref="S3.E5.m1.3.3.1.1.1.3.2">𝑃</ci><ci id="S3.E5.m1.3.3.1.1.1.3.3a.cmml" xref="S3.E5.m1.3.3.1.1.1.3.3"><mtext mathsize="70%" id="S3.E5.m1.3.3.1.1.1.3.3.cmml" xref="S3.E5.m1.3.3.1.1.1.3.3">gen</mtext></ci></apply><apply id="S3.E5.m1.3.3.1.1.1.1.1.1.cmml" xref="S3.E5.m1.3.3.1.1.1.1.1"><csymbol cd="latexml" id="S3.E5.m1.3.3.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.3.3.1.1.1.1.1.1.1">conditional</csymbol><ci id="S3.E5.m1.3.3.1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.3.3.1.1.1.1.1.1.2">𝑧</ci><ci id="S3.E5.m1.3.3.1.1.1.1.1.1.3.cmml" xref="S3.E5.m1.3.3.1.1.1.1.1.1.3">𝐗</ci></apply></apply><apply id="S3.E5.m1.3.3.1.1.2.cmml" xref="S3.E5.m1.3.3.1.1.2"><apply id="S3.E5.m1.3.3.1.1.2.2.cmml" xref="S3.E5.m1.3.3.1.1.2.2"><csymbol cd="ambiguous" id="S3.E5.m1.3.3.1.1.2.2.1.cmml" xref="S3.E5.m1.3.3.1.1.2.2">superscript</csymbol><apply id="S3.E5.m1.3.3.1.1.2.2.2.cmml" xref="S3.E5.m1.3.3.1.1.2.2"><csymbol cd="ambiguous" id="S3.E5.m1.3.3.1.1.2.2.2.1.cmml" xref="S3.E5.m1.3.3.1.1.2.2">subscript</csymbol><csymbol cd="latexml" id="S3.E5.m1.3.3.1.1.2.2.2.2.cmml" xref="S3.E5.m1.3.3.1.1.2.2.2.2">product</csymbol><apply id="S3.E5.m1.3.3.1.1.2.2.2.3.cmml" xref="S3.E5.m1.3.3.1.1.2.2.2.3"><eq id="S3.E5.m1.3.3.1.1.2.2.2.3.1.cmml" xref="S3.E5.m1.3.3.1.1.2.2.2.3.1"></eq><ci id="S3.E5.m1.3.3.1.1.2.2.2.3.2.cmml" xref="S3.E5.m1.3.3.1.1.2.2.2.3.2">𝑗</ci><cn type="integer" id="S3.E5.m1.3.3.1.1.2.2.2.3.3.cmml" xref="S3.E5.m1.3.3.1.1.2.2.2.3.3">0</cn></apply></apply><apply id="S3.E5.m1.1.1.1.2.cmml" xref="S3.E5.m1.1.1.1.3"><abs id="S3.E5.m1.1.1.1.2.1.cmml" xref="S3.E5.m1.1.1.1.3.1"></abs><ci id="S3.E5.m1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1">𝑧</ci></apply></apply><apply id="S3.E5.m1.3.3.1.1.2.1.cmml" xref="S3.E5.m1.3.3.1.1.2.1"><times id="S3.E5.m1.3.3.1.1.2.1.2.cmml" xref="S3.E5.m1.3.3.1.1.2.1.2"></times><apply id="S3.E5.m1.3.3.1.1.2.1.3.cmml" xref="S3.E5.m1.3.3.1.1.2.1.3"><csymbol cd="ambiguous" id="S3.E5.m1.3.3.1.1.2.1.3.1.cmml" xref="S3.E5.m1.3.3.1.1.2.1.3">subscript</csymbol><ci id="S3.E5.m1.3.3.1.1.2.1.3.2.cmml" xref="S3.E5.m1.3.3.1.1.2.1.3.2">𝑃</ci><ci id="S3.E5.m1.3.3.1.1.2.1.3.3.cmml" xref="S3.E5.m1.3.3.1.1.2.1.3.3">italic-ϕ</ci></apply><apply id="S3.E5.m1.3.3.1.1.2.1.1.1.1.cmml" xref="S3.E5.m1.3.3.1.1.2.1.1.1"><csymbol cd="latexml" id="S3.E5.m1.3.3.1.1.2.1.1.1.1.2.cmml" xref="S3.E5.m1.3.3.1.1.2.1.1.1.1.2">conditional</csymbol><apply id="S3.E5.m1.3.3.1.1.2.1.1.1.1.3.cmml" xref="S3.E5.m1.3.3.1.1.2.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E5.m1.3.3.1.1.2.1.1.1.1.3.1.cmml" xref="S3.E5.m1.3.3.1.1.2.1.1.1.1.3">subscript</csymbol><ci id="S3.E5.m1.3.3.1.1.2.1.1.1.1.3.2.cmml" xref="S3.E5.m1.3.3.1.1.2.1.1.1.1.3.2">𝑧</ci><ci id="S3.E5.m1.3.3.1.1.2.1.1.1.1.3.3.cmml" xref="S3.E5.m1.3.3.1.1.2.1.1.1.1.3.3">𝑗</ci></apply><list id="S3.E5.m1.3.3.1.1.2.1.1.1.1.1.2.cmml" xref="S3.E5.m1.3.3.1.1.2.1.1.1.1.1.1"><ci id="S3.E5.m1.2.2.cmml" xref="S3.E5.m1.2.2">𝐗</ci><apply id="S3.E5.m1.3.3.1.1.2.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.3.3.1.1.2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E5.m1.3.3.1.1.2.1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.3.3.1.1.2.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E5.m1.3.3.1.1.2.1.1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.3.3.1.1.2.1.1.1.1.1.1.1.2">𝑧</ci><apply id="S3.E5.m1.3.3.1.1.2.1.1.1.1.1.1.1.3.cmml" xref="S3.E5.m1.3.3.1.1.2.1.1.1.1.1.1.1.3"><lt id="S3.E5.m1.3.3.1.1.2.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E5.m1.3.3.1.1.2.1.1.1.1.1.1.1.3.1"></lt><csymbol cd="latexml" id="S3.E5.m1.3.3.1.1.2.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E5.m1.3.3.1.1.2.1.1.1.1.1.1.1.3.2">absent</csymbol><ci id="S3.E5.m1.3.3.1.1.2.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E5.m1.3.3.1.1.2.1.1.1.1.1.1.1.3.3">𝑗</ci></apply></apply></list></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5.m1.3c">\displaystyle P_{\text{gen}}(z|\mathbf{X})=\prod_{j=0}^{|z|}P_{\phi}(z_{j}|\mathbf{X},z_{&lt;j}).</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<p id="S3.SS4.SSS0.Px2.p1.7" class="ltx_p">We finally optimize the generative model using a cross-entropy loss between the conditional probability <math id="S3.SS4.SSS0.Px2.p1.6.m1.1" class="ltx_Math" alttext="P_{\text{gen}}(z|\mathbf{X})" display="inline"><semantics id="S3.SS4.SSS0.Px2.p1.6.m1.1a"><mrow id="S3.SS4.SSS0.Px2.p1.6.m1.1.1" xref="S3.SS4.SSS0.Px2.p1.6.m1.1.1.cmml"><msub id="S3.SS4.SSS0.Px2.p1.6.m1.1.1.3" xref="S3.SS4.SSS0.Px2.p1.6.m1.1.1.3.cmml"><mi id="S3.SS4.SSS0.Px2.p1.6.m1.1.1.3.2" xref="S3.SS4.SSS0.Px2.p1.6.m1.1.1.3.2.cmml">P</mi><mtext id="S3.SS4.SSS0.Px2.p1.6.m1.1.1.3.3" xref="S3.SS4.SSS0.Px2.p1.6.m1.1.1.3.3a.cmml">gen</mtext></msub><mo lspace="0em" rspace="0em" id="S3.SS4.SSS0.Px2.p1.6.m1.1.1.2" xref="S3.SS4.SSS0.Px2.p1.6.m1.1.1.2.cmml">​</mo><mrow id="S3.SS4.SSS0.Px2.p1.6.m1.1.1.1.1" xref="S3.SS4.SSS0.Px2.p1.6.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS4.SSS0.Px2.p1.6.m1.1.1.1.1.2" xref="S3.SS4.SSS0.Px2.p1.6.m1.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS4.SSS0.Px2.p1.6.m1.1.1.1.1.1" xref="S3.SS4.SSS0.Px2.p1.6.m1.1.1.1.1.1.cmml"><mi id="S3.SS4.SSS0.Px2.p1.6.m1.1.1.1.1.1.2" xref="S3.SS4.SSS0.Px2.p1.6.m1.1.1.1.1.1.2.cmml">z</mi><mo fence="false" id="S3.SS4.SSS0.Px2.p1.6.m1.1.1.1.1.1.1" xref="S3.SS4.SSS0.Px2.p1.6.m1.1.1.1.1.1.1.cmml">|</mo><mi id="S3.SS4.SSS0.Px2.p1.6.m1.1.1.1.1.1.3" xref="S3.SS4.SSS0.Px2.p1.6.m1.1.1.1.1.1.3.cmml">𝐗</mi></mrow><mo stretchy="false" id="S3.SS4.SSS0.Px2.p1.6.m1.1.1.1.1.3" xref="S3.SS4.SSS0.Px2.p1.6.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS0.Px2.p1.6.m1.1b"><apply id="S3.SS4.SSS0.Px2.p1.6.m1.1.1.cmml" xref="S3.SS4.SSS0.Px2.p1.6.m1.1.1"><times id="S3.SS4.SSS0.Px2.p1.6.m1.1.1.2.cmml" xref="S3.SS4.SSS0.Px2.p1.6.m1.1.1.2"></times><apply id="S3.SS4.SSS0.Px2.p1.6.m1.1.1.3.cmml" xref="S3.SS4.SSS0.Px2.p1.6.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS4.SSS0.Px2.p1.6.m1.1.1.3.1.cmml" xref="S3.SS4.SSS0.Px2.p1.6.m1.1.1.3">subscript</csymbol><ci id="S3.SS4.SSS0.Px2.p1.6.m1.1.1.3.2.cmml" xref="S3.SS4.SSS0.Px2.p1.6.m1.1.1.3.2">𝑃</ci><ci id="S3.SS4.SSS0.Px2.p1.6.m1.1.1.3.3a.cmml" xref="S3.SS4.SSS0.Px2.p1.6.m1.1.1.3.3"><mtext mathsize="70%" id="S3.SS4.SSS0.Px2.p1.6.m1.1.1.3.3.cmml" xref="S3.SS4.SSS0.Px2.p1.6.m1.1.1.3.3">gen</mtext></ci></apply><apply id="S3.SS4.SSS0.Px2.p1.6.m1.1.1.1.1.1.cmml" xref="S3.SS4.SSS0.Px2.p1.6.m1.1.1.1.1"><csymbol cd="latexml" id="S3.SS4.SSS0.Px2.p1.6.m1.1.1.1.1.1.1.cmml" xref="S3.SS4.SSS0.Px2.p1.6.m1.1.1.1.1.1.1">conditional</csymbol><ci id="S3.SS4.SSS0.Px2.p1.6.m1.1.1.1.1.1.2.cmml" xref="S3.SS4.SSS0.Px2.p1.6.m1.1.1.1.1.1.2">𝑧</ci><ci id="S3.SS4.SSS0.Px2.p1.6.m1.1.1.1.1.1.3.cmml" xref="S3.SS4.SSS0.Px2.p1.6.m1.1.1.1.1.1.3">𝐗</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS0.Px2.p1.6.m1.1c">P_{\text{gen}}(z|\mathbf{X})</annotation></semantics></math> and the ground-truth answer string <math id="S3.SS4.SSS0.Px2.p1.7.m2.1" class="ltx_Math" alttext="z" display="inline"><semantics id="S3.SS4.SSS0.Px2.p1.7.m2.1a"><mi id="S3.SS4.SSS0.Px2.p1.7.m2.1.1" xref="S3.SS4.SSS0.Px2.p1.7.m2.1.1.cmml">z</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS0.Px2.p1.7.m2.1b"><ci id="S3.SS4.SSS0.Px2.p1.7.m2.1.1.cmml" xref="S3.SS4.SSS0.Px2.p1.7.m2.1.1">𝑧</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS0.Px2.p1.7.m2.1c">z</annotation></semantics></math> on the training dataset.
This formulation allows for more flexible answers, which can easily change depending on the task, but may produce answers that are essentially the same with minor differences (e.g., extra whitespace, synonyms, etc.). To resolve these minor discrepancies, we utilize a simple string-matching heuristic that matches the longest continuous subsequence<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a target="_blank" href="https://docs.python.org/3/library/difflib.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://docs.python.org/3/library/difflib.html</a></span></span></span> between the generated answer and the closest possible label in the answer label set. Thus, our final generative model predicts answers as follows:</p>
<table id="A4.EGx4" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S3.E6"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E6.m1.1" class="ltx_Math" alttext="\displaystyle z^{*}" display="inline"><semantics id="S3.E6.m1.1a"><msup id="S3.E6.m1.1.1" xref="S3.E6.m1.1.1.cmml"><mi id="S3.E6.m1.1.1.2" xref="S3.E6.m1.1.1.2.cmml">z</mi><mo id="S3.E6.m1.1.1.3" xref="S3.E6.m1.1.1.3.cmml">∗</mo></msup><annotation-xml encoding="MathML-Content" id="S3.E6.m1.1b"><apply id="S3.E6.m1.1.1.cmml" xref="S3.E6.m1.1.1"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.cmml" xref="S3.E6.m1.1.1">superscript</csymbol><ci id="S3.E6.m1.1.1.2.cmml" xref="S3.E6.m1.1.1.2">𝑧</ci><times id="S3.E6.m1.1.1.3.cmml" xref="S3.E6.m1.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E6.m1.1c">\displaystyle z^{*}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S3.E6.m2.1" class="ltx_Math" alttext="\displaystyle=\arg\max_{z}P_{gen}(z|\mathbf{X})" display="inline"><semantics id="S3.E6.m2.1a"><mrow id="S3.E6.m2.1.1" xref="S3.E6.m2.1.1.cmml"><mi id="S3.E6.m2.1.1.3" xref="S3.E6.m2.1.1.3.cmml"></mi><mo id="S3.E6.m2.1.1.2" xref="S3.E6.m2.1.1.2.cmml">=</mo><mrow id="S3.E6.m2.1.1.1" xref="S3.E6.m2.1.1.1.cmml"><mrow id="S3.E6.m2.1.1.1.3" xref="S3.E6.m2.1.1.1.3.cmml"><mi id="S3.E6.m2.1.1.1.3.1" xref="S3.E6.m2.1.1.1.3.1.cmml">arg</mi><mo lspace="0.167em" id="S3.E6.m2.1.1.1.3a" xref="S3.E6.m2.1.1.1.3.cmml">⁡</mo><mrow id="S3.E6.m2.1.1.1.3.2" xref="S3.E6.m2.1.1.1.3.2.cmml"><munder id="S3.E6.m2.1.1.1.3.2.1" xref="S3.E6.m2.1.1.1.3.2.1.cmml"><mi id="S3.E6.m2.1.1.1.3.2.1.2" xref="S3.E6.m2.1.1.1.3.2.1.2.cmml">max</mi><mi id="S3.E6.m2.1.1.1.3.2.1.3" xref="S3.E6.m2.1.1.1.3.2.1.3.cmml">z</mi></munder><mo lspace="0.167em" id="S3.E6.m2.1.1.1.3.2a" xref="S3.E6.m2.1.1.1.3.2.cmml">⁡</mo><msub id="S3.E6.m2.1.1.1.3.2.2" xref="S3.E6.m2.1.1.1.3.2.2.cmml"><mi id="S3.E6.m2.1.1.1.3.2.2.2" xref="S3.E6.m2.1.1.1.3.2.2.2.cmml">P</mi><mrow id="S3.E6.m2.1.1.1.3.2.2.3" xref="S3.E6.m2.1.1.1.3.2.2.3.cmml"><mi id="S3.E6.m2.1.1.1.3.2.2.3.2" xref="S3.E6.m2.1.1.1.3.2.2.3.2.cmml">g</mi><mo lspace="0em" rspace="0em" id="S3.E6.m2.1.1.1.3.2.2.3.1" xref="S3.E6.m2.1.1.1.3.2.2.3.1.cmml">​</mo><mi id="S3.E6.m2.1.1.1.3.2.2.3.3" xref="S3.E6.m2.1.1.1.3.2.2.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E6.m2.1.1.1.3.2.2.3.1a" xref="S3.E6.m2.1.1.1.3.2.2.3.1.cmml">​</mo><mi id="S3.E6.m2.1.1.1.3.2.2.3.4" xref="S3.E6.m2.1.1.1.3.2.2.3.4.cmml">n</mi></mrow></msub></mrow></mrow><mo lspace="0em" rspace="0em" id="S3.E6.m2.1.1.1.2" xref="S3.E6.m2.1.1.1.2.cmml">​</mo><mrow id="S3.E6.m2.1.1.1.1.1" xref="S3.E6.m2.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E6.m2.1.1.1.1.1.2" xref="S3.E6.m2.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E6.m2.1.1.1.1.1.1" xref="S3.E6.m2.1.1.1.1.1.1.cmml"><mi id="S3.E6.m2.1.1.1.1.1.1.2" xref="S3.E6.m2.1.1.1.1.1.1.2.cmml">z</mi><mo fence="false" id="S3.E6.m2.1.1.1.1.1.1.1" xref="S3.E6.m2.1.1.1.1.1.1.1.cmml">|</mo><mi id="S3.E6.m2.1.1.1.1.1.1.3" xref="S3.E6.m2.1.1.1.1.1.1.3.cmml">𝐗</mi></mrow><mo stretchy="false" id="S3.E6.m2.1.1.1.1.1.3" xref="S3.E6.m2.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E6.m2.1b"><apply id="S3.E6.m2.1.1.cmml" xref="S3.E6.m2.1.1"><eq id="S3.E6.m2.1.1.2.cmml" xref="S3.E6.m2.1.1.2"></eq><csymbol cd="latexml" id="S3.E6.m2.1.1.3.cmml" xref="S3.E6.m2.1.1.3">absent</csymbol><apply id="S3.E6.m2.1.1.1.cmml" xref="S3.E6.m2.1.1.1"><times id="S3.E6.m2.1.1.1.2.cmml" xref="S3.E6.m2.1.1.1.2"></times><apply id="S3.E6.m2.1.1.1.3.cmml" xref="S3.E6.m2.1.1.1.3"><arg id="S3.E6.m2.1.1.1.3.1.cmml" xref="S3.E6.m2.1.1.1.3.1"></arg><apply id="S3.E6.m2.1.1.1.3.2.cmml" xref="S3.E6.m2.1.1.1.3.2"><apply id="S3.E6.m2.1.1.1.3.2.1.cmml" xref="S3.E6.m2.1.1.1.3.2.1"><csymbol cd="ambiguous" id="S3.E6.m2.1.1.1.3.2.1.1.cmml" xref="S3.E6.m2.1.1.1.3.2.1">subscript</csymbol><max id="S3.E6.m2.1.1.1.3.2.1.2.cmml" xref="S3.E6.m2.1.1.1.3.2.1.2"></max><ci id="S3.E6.m2.1.1.1.3.2.1.3.cmml" xref="S3.E6.m2.1.1.1.3.2.1.3">𝑧</ci></apply><apply id="S3.E6.m2.1.1.1.3.2.2.cmml" xref="S3.E6.m2.1.1.1.3.2.2"><csymbol cd="ambiguous" id="S3.E6.m2.1.1.1.3.2.2.1.cmml" xref="S3.E6.m2.1.1.1.3.2.2">subscript</csymbol><ci id="S3.E6.m2.1.1.1.3.2.2.2.cmml" xref="S3.E6.m2.1.1.1.3.2.2.2">𝑃</ci><apply id="S3.E6.m2.1.1.1.3.2.2.3.cmml" xref="S3.E6.m2.1.1.1.3.2.2.3"><times id="S3.E6.m2.1.1.1.3.2.2.3.1.cmml" xref="S3.E6.m2.1.1.1.3.2.2.3.1"></times><ci id="S3.E6.m2.1.1.1.3.2.2.3.2.cmml" xref="S3.E6.m2.1.1.1.3.2.2.3.2">𝑔</ci><ci id="S3.E6.m2.1.1.1.3.2.2.3.3.cmml" xref="S3.E6.m2.1.1.1.3.2.2.3.3">𝑒</ci><ci id="S3.E6.m2.1.1.1.3.2.2.3.4.cmml" xref="S3.E6.m2.1.1.1.3.2.2.3.4">𝑛</ci></apply></apply></apply></apply><apply id="S3.E6.m2.1.1.1.1.1.1.cmml" xref="S3.E6.m2.1.1.1.1.1"><csymbol cd="latexml" id="S3.E6.m2.1.1.1.1.1.1.1.cmml" xref="S3.E6.m2.1.1.1.1.1.1.1">conditional</csymbol><ci id="S3.E6.m2.1.1.1.1.1.1.2.cmml" xref="S3.E6.m2.1.1.1.1.1.1.2">𝑧</ci><ci id="S3.E6.m2.1.1.1.1.1.1.3.cmml" xref="S3.E6.m2.1.1.1.1.1.1.3">𝐗</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E6.m2.1c">\displaystyle=\arg\max_{z}P_{gen}(z|\mathbf{X})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
<tbody id="S3.E7"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E7.m1.1" class="ltx_Math" alttext="\displaystyle y^{*}" display="inline"><semantics id="S3.E7.m1.1a"><msup id="S3.E7.m1.1.1" xref="S3.E7.m1.1.1.cmml"><mi id="S3.E7.m1.1.1.2" xref="S3.E7.m1.1.1.2.cmml">y</mi><mo id="S3.E7.m1.1.1.3" xref="S3.E7.m1.1.1.3.cmml">∗</mo></msup><annotation-xml encoding="MathML-Content" id="S3.E7.m1.1b"><apply id="S3.E7.m1.1.1.cmml" xref="S3.E7.m1.1.1"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.1.cmml" xref="S3.E7.m1.1.1">superscript</csymbol><ci id="S3.E7.m1.1.1.2.cmml" xref="S3.E7.m1.1.1.2">𝑦</ci><times id="S3.E7.m1.1.1.3.cmml" xref="S3.E7.m1.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E7.m1.1c">\displaystyle y^{*}</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S3.E7.m2.2" class="ltx_Math" alttext="\displaystyle=\text{LongestCommonString}(z^{*},\mathcal{Y})." display="inline"><semantics id="S3.E7.m2.2a"><mrow id="S3.E7.m2.2.2.1" xref="S3.E7.m2.2.2.1.1.cmml"><mrow id="S3.E7.m2.2.2.1.1" xref="S3.E7.m2.2.2.1.1.cmml"><mi id="S3.E7.m2.2.2.1.1.3" xref="S3.E7.m2.2.2.1.1.3.cmml"></mi><mo id="S3.E7.m2.2.2.1.1.2" xref="S3.E7.m2.2.2.1.1.2.cmml">=</mo><mrow id="S3.E7.m2.2.2.1.1.1" xref="S3.E7.m2.2.2.1.1.1.cmml"><mtext id="S3.E7.m2.2.2.1.1.1.3" xref="S3.E7.m2.2.2.1.1.1.3a.cmml">LongestCommonString</mtext><mo lspace="0em" rspace="0em" id="S3.E7.m2.2.2.1.1.1.2" xref="S3.E7.m2.2.2.1.1.1.2.cmml">​</mo><mrow id="S3.E7.m2.2.2.1.1.1.1.1" xref="S3.E7.m2.2.2.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E7.m2.2.2.1.1.1.1.1.2" xref="S3.E7.m2.2.2.1.1.1.1.2.cmml">(</mo><msup id="S3.E7.m2.2.2.1.1.1.1.1.1" xref="S3.E7.m2.2.2.1.1.1.1.1.1.cmml"><mi id="S3.E7.m2.2.2.1.1.1.1.1.1.2" xref="S3.E7.m2.2.2.1.1.1.1.1.1.2.cmml">z</mi><mo id="S3.E7.m2.2.2.1.1.1.1.1.1.3" xref="S3.E7.m2.2.2.1.1.1.1.1.1.3.cmml">∗</mo></msup><mo id="S3.E7.m2.2.2.1.1.1.1.1.3" xref="S3.E7.m2.2.2.1.1.1.1.2.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S3.E7.m2.1.1" xref="S3.E7.m2.1.1.cmml">𝒴</mi><mo stretchy="false" id="S3.E7.m2.2.2.1.1.1.1.1.4" xref="S3.E7.m2.2.2.1.1.1.1.2.cmml">)</mo></mrow></mrow></mrow><mo lspace="0em" id="S3.E7.m2.2.2.1.2" xref="S3.E7.m2.2.2.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E7.m2.2b"><apply id="S3.E7.m2.2.2.1.1.cmml" xref="S3.E7.m2.2.2.1"><eq id="S3.E7.m2.2.2.1.1.2.cmml" xref="S3.E7.m2.2.2.1.1.2"></eq><csymbol cd="latexml" id="S3.E7.m2.2.2.1.1.3.cmml" xref="S3.E7.m2.2.2.1.1.3">absent</csymbol><apply id="S3.E7.m2.2.2.1.1.1.cmml" xref="S3.E7.m2.2.2.1.1.1"><times id="S3.E7.m2.2.2.1.1.1.2.cmml" xref="S3.E7.m2.2.2.1.1.1.2"></times><ci id="S3.E7.m2.2.2.1.1.1.3a.cmml" xref="S3.E7.m2.2.2.1.1.1.3"><mtext id="S3.E7.m2.2.2.1.1.1.3.cmml" xref="S3.E7.m2.2.2.1.1.1.3">LongestCommonString</mtext></ci><interval closure="open" id="S3.E7.m2.2.2.1.1.1.1.2.cmml" xref="S3.E7.m2.2.2.1.1.1.1.1"><apply id="S3.E7.m2.2.2.1.1.1.1.1.1.cmml" xref="S3.E7.m2.2.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E7.m2.2.2.1.1.1.1.1.1.1.cmml" xref="S3.E7.m2.2.2.1.1.1.1.1.1">superscript</csymbol><ci id="S3.E7.m2.2.2.1.1.1.1.1.1.2.cmml" xref="S3.E7.m2.2.2.1.1.1.1.1.1.2">𝑧</ci><times id="S3.E7.m2.2.2.1.1.1.1.1.1.3.cmml" xref="S3.E7.m2.2.2.1.1.1.1.1.1.3"></times></apply><ci id="S3.E7.m2.1.1.cmml" xref="S3.E7.m2.1.1">𝒴</ci></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E7.m2.2c">\displaystyle=\text{LongestCommonString}(z^{*},\mathcal{Y}).</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(7)</span></td>
</tr></tbody>
</table>
<p id="S3.SS4.SSS0.Px2.p1.9" class="ltx_p">Compared to the exact match between the generated answer string <math id="S3.SS4.SSS0.Px2.p1.8.m1.1" class="ltx_Math" alttext="z^{*}" display="inline"><semantics id="S3.SS4.SSS0.Px2.p1.8.m1.1a"><msup id="S3.SS4.SSS0.Px2.p1.8.m1.1.1" xref="S3.SS4.SSS0.Px2.p1.8.m1.1.1.cmml"><mi id="S3.SS4.SSS0.Px2.p1.8.m1.1.1.2" xref="S3.SS4.SSS0.Px2.p1.8.m1.1.1.2.cmml">z</mi><mo id="S3.SS4.SSS0.Px2.p1.8.m1.1.1.3" xref="S3.SS4.SSS0.Px2.p1.8.m1.1.1.3.cmml">∗</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS0.Px2.p1.8.m1.1b"><apply id="S3.SS4.SSS0.Px2.p1.8.m1.1.1.cmml" xref="S3.SS4.SSS0.Px2.p1.8.m1.1.1"><csymbol cd="ambiguous" id="S3.SS4.SSS0.Px2.p1.8.m1.1.1.1.cmml" xref="S3.SS4.SSS0.Px2.p1.8.m1.1.1">superscript</csymbol><ci id="S3.SS4.SSS0.Px2.p1.8.m1.1.1.2.cmml" xref="S3.SS4.SSS0.Px2.p1.8.m1.1.1.2">𝑧</ci><times id="S3.SS4.SSS0.Px2.p1.8.m1.1.1.3.cmml" xref="S3.SS4.SSS0.Px2.p1.8.m1.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS0.Px2.p1.8.m1.1c">z^{*}</annotation></semantics></math> and the ground-truth string <math id="S3.SS4.SSS0.Px2.p1.9.m2.1" class="ltx_Math" alttext="z" display="inline"><semantics id="S3.SS4.SSS0.Px2.p1.9.m2.1a"><mi id="S3.SS4.SSS0.Px2.p1.9.m2.1.1" xref="S3.SS4.SSS0.Px2.p1.9.m2.1.1.cmml">z</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS0.Px2.p1.9.m2.1b"><ci id="S3.SS4.SSS0.Px2.p1.9.m2.1.1.cmml" xref="S3.SS4.SSS0.Px2.p1.9.m2.1.1">𝑧</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS0.Px2.p1.9.m2.1c">z</annotation></semantics></math>, we observe a 3-4% improvement in accuracy when using this heuristic on the VQA-RAD dataset and a 1% gain on the SLAKE dataset.</p>
</div>
</section>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experimental Setup</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.2" class="ltx_p">We perform our analysis on the VQA-RAD and SLAKE datasets, which are anonymous and preprocessed following prior works <cite class="ltx_cite ltx_citemacro_cite">Eslami et al. (<a href="#bib.bib6" title="" class="ltx_ref">2021</a>); Zhan et al. (<a href="#bib.bib43" title="" class="ltx_ref">2020</a>)</cite>. We use an AdamW optimizer with an initial learning rate <math id="S4.p1.1.m1.1" class="ltx_Math" alttext="1e^{-4}" display="inline"><semantics id="S4.p1.1.m1.1a"><mrow id="S4.p1.1.m1.1.1" xref="S4.p1.1.m1.1.1.cmml"><mn id="S4.p1.1.m1.1.1.2" xref="S4.p1.1.m1.1.1.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="S4.p1.1.m1.1.1.1" xref="S4.p1.1.m1.1.1.1.cmml">​</mo><msup id="S4.p1.1.m1.1.1.3" xref="S4.p1.1.m1.1.1.3.cmml"><mi id="S4.p1.1.m1.1.1.3.2" xref="S4.p1.1.m1.1.1.3.2.cmml">e</mi><mrow id="S4.p1.1.m1.1.1.3.3" xref="S4.p1.1.m1.1.1.3.3.cmml"><mo id="S4.p1.1.m1.1.1.3.3a" xref="S4.p1.1.m1.1.1.3.3.cmml">−</mo><mn id="S4.p1.1.m1.1.1.3.3.2" xref="S4.p1.1.m1.1.1.3.3.2.cmml">4</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.p1.1.m1.1b"><apply id="S4.p1.1.m1.1.1.cmml" xref="S4.p1.1.m1.1.1"><times id="S4.p1.1.m1.1.1.1.cmml" xref="S4.p1.1.m1.1.1.1"></times><cn type="integer" id="S4.p1.1.m1.1.1.2.cmml" xref="S4.p1.1.m1.1.1.2">1</cn><apply id="S4.p1.1.m1.1.1.3.cmml" xref="S4.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S4.p1.1.m1.1.1.3.1.cmml" xref="S4.p1.1.m1.1.1.3">superscript</csymbol><ci id="S4.p1.1.m1.1.1.3.2.cmml" xref="S4.p1.1.m1.1.1.3.2">𝑒</ci><apply id="S4.p1.1.m1.1.1.3.3.cmml" xref="S4.p1.1.m1.1.1.3.3"><minus id="S4.p1.1.m1.1.1.3.3.1.cmml" xref="S4.p1.1.m1.1.1.3.3"></minus><cn type="integer" id="S4.p1.1.m1.1.1.3.3.2.cmml" xref="S4.p1.1.m1.1.1.3.3.2">4</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.1.m1.1c">1e^{-4}</annotation></semantics></math> for T5 finetuning. We use a <span id="S4.p1.2.1" class="ltx_text ltx_markedasmath ltx_font_typewriter">ViT-B/32</span> architecture for our CLIP models, and T5-small for answer generation. The plateau learning rate scheduler is used to decay the learning rate by a factor of 10 if the validation loss does not decrease for 10 consecutive epochs.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p">All model training used a batch size of 16 and took 2-3 hours on average on a RTX 3090 GPU. All results were seeded with the best run of <cite class="ltx_cite ltx_citemacro_citet">Eslami et al. (<a href="#bib.bib6" title="" class="ltx_ref">2021</a>); Zhan et al. (<a href="#bib.bib43" title="" class="ltx_ref">2020</a>)</cite> for reproducibility.<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>The performance was similar across 5 different seeds for our best model, with a standard deviation of about 1.5%.</span></span></span></p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Datasets</h3>

<section id="S4.SS1.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">SLAKE</h4>

<div id="S4.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px1.p1.1" class="ltx_p">The SLAKE dataset comprises 642 images and over 14,000 VQA pairs in English and Chinese. We only use the English portion to match the language of the T5 pretraining corpus. We use the provided train, validation and test splits, corresponding to 4918, 1053, and 1061 QA pairs. SLAKE consists of 10 different question types.<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>Details in Table <a href="#A3.T7" title="Table 7 ‣ Appendix C Dataset Information ‣ Multimodal Prompt Retrieval for Generative Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> and <a href="#A3.T8" title="Table 8 ‣ Appendix C Dataset Information ‣ Multimodal Prompt Retrieval for Generative Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> in the appendix.</span></span></span></p>
</div>
</section>
<section id="S4.SS1.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">VQA-RAD</h4>

<div id="S4.SS1.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px2.p1.1" class="ltx_p">VQA-RAD is a high-quality dataset consisting of 315 patient scans and 3515 questions. We use the train and eval splits provided with the original data, following prior works <cite class="ltx_cite ltx_citemacro_cite">Tanwani et al. (<a href="#bib.bib39" title="" class="ltx_ref">2022</a>); Eslami et al. (<a href="#bib.bib6" title="" class="ltx_ref">2021</a>); Nguyen et al. (<a href="#bib.bib30" title="" class="ltx_ref">2019</a>)</cite>. VQA-RAD consists of 11 different question types.</p>
</div>
</section>
<section id="S4.SS1.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Radiology Objects in Context (ROCO)</h4>

<div id="S4.SS1.SSS0.Px3.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px3.p1.1" class="ltx_p">The ROCO dataset <cite class="ltx_cite ltx_citemacro_cite">Pelka et al. (<a href="#bib.bib32" title="" class="ltx_ref">2018</a>)</cite> has over 81,000 radiology image-caption pairs, making it a popular medical dataset for pretraining vision-language models <cite class="ltx_cite ltx_citemacro_cite">Pelka et al. (<a href="#bib.bib32" title="" class="ltx_ref">2018</a>)</cite>. Each image-caption pair also contains keywords and semantic types used by existing works for masked language modeling on salient spans <cite class="ltx_cite ltx_citemacro_cite">Khare et al. (<a href="#bib.bib14" title="" class="ltx_ref">2021</a>)</cite>.</p>
</div>
</section>
<section id="S4.SS1.SSS0.Px4" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Synthetic VQA Data</h4>

<div id="S4.SS1.SSS0.Px4.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px4.p1.1" class="ltx_p">Using the image-caption data from the ROCO dataset, we construct a large-scale synthetic VQA dataset consisting of over 50,000 question-answer pairs. Using our procedure (§<a href="#S3.SS1.SSS0.Px2" title="Retrieval Set Augmentation on Image-Caption Data: ‣ 3.1 Multimodal Prompt Encoding ‣ 3 Methods ‣ Multimodal Prompt Retrieval for Generative Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a>), we create question and keyword templates focusing on organ, modality, and plane questions.</p>
</div>
</section>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Training Settings</h3>

<section id="S4.SS2.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Dataset Adaptation (DA):</h4>

<div id="S4.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS2.SSS0.Px1.p1.1" class="ltx_p">To evaluate the generalization of VQA models across datasets, we examine a setting where we train a model on a source-labeled dataset and use it to answer questions from a different target dataset with access to a target dataset. We further compare models using the target labeled examples for (a) in-context prediction without updating source-trained models or (b) continued fine-tuning.</p>
</div>
</section>
<section id="S4.SS2.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">In-domain Evaluation (IDE):</h4>

<div id="S4.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS2.SSS0.Px2.p1.1" class="ltx_p">In this setting, we adopt a standard split of each dataset into train/validation/test sets. We then train models on the train set, select the best checkpoints by the validation set, and evaluate models on the test set.</p>
</div>
</section>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Baselines</h3>

<section id="S4.SS3.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Mixture of Enhanced Visual Features (MEVF)</h4>

<div id="S4.SS3.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS3.SSS0.Px1.p1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citet">Nguyen et al. (<a href="#bib.bib30" title="" class="ltx_ref">2019</a>)</cite> utilize model agnostic meta-learning (MAML) in conjunction with a convolutional denoising autoencoder (CDAE) to learn medical image latent feature representations.</p>
</div>
</section>
<section id="S4.SS3.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Question Answering with Conditional Reasoning (QCR)</h4>

<div id="S4.SS3.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS3.SSS0.Px2.p1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citet">Zhan et al. (<a href="#bib.bib43" title="" class="ltx_ref">2020</a>)</cite> introduce novel task-conditioned, open, and closed reasoning modules to distinguish between answer types and improve open question accuracy.</p>
</div>
</section>
<section id="S4.SS3.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">PubMedCLIP</h4>

<div id="S4.SS3.SSS0.Px3.p1" class="ltx_para">
<p id="S4.SS3.SSS0.Px3.p1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citet">Eslami et al. (<a href="#bib.bib6" title="" class="ltx_ref">2021</a>)</cite> utilize the ROCO dataset to finetune a general CLIP model on medical image-caption pairs. They modify existing architectures with the finetuned vision encoder to achieve improved results.</p>
</div>
</section>
<section id="S4.SS3.SSS0.Px4" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">MMBERT</h4>

<div id="S4.SS3.SSS0.Px4.p1" class="ltx_para">
<p id="S4.SS3.SSS0.Px4.p1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citet">Khare et al. (<a href="#bib.bib14" title="" class="ltx_ref">2021</a>)</cite> introduces a BERT-based method that utilizes pretraining on the ROCO dataset with a masked language modeling objective. The model predicts answers by performing an average pooling on the last layer features followed by a linear classification layer.</p>
</div>
</section>
<section id="S4.SS3.SSS0.Px5" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">MPR<math id="S4.SS3.SSS0.Px5.1.m1.1" class="ltx_Math" alttext="{}_{\text{disc}}" display="inline"><semantics id="S4.SS3.SSS0.Px5.1.m1.1b"><msub id="S4.SS3.SSS0.Px5.1.m1.1.1" xref="S4.SS3.SSS0.Px5.1.m1.1.1.cmml"><mi id="S4.SS3.SSS0.Px5.1.m1.1.1b" xref="S4.SS3.SSS0.Px5.1.m1.1.1.cmml"></mi><mtext id="S4.SS3.SSS0.Px5.1.m1.1.1.1" xref="S4.SS3.SSS0.Px5.1.m1.1.1.1a.cmml">disc</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px5.1.m1.1c"><apply id="S4.SS3.SSS0.Px5.1.m1.1.1.cmml" xref="S4.SS3.SSS0.Px5.1.m1.1.1"><ci id="S4.SS3.SSS0.Px5.1.m1.1.1.1a.cmml" xref="S4.SS3.SSS0.Px5.1.m1.1.1.1"><mtext mathsize="70%" id="S4.SS3.SSS0.Px5.1.m1.1.1.1.cmml" xref="S4.SS3.SSS0.Px5.1.m1.1.1.1">disc</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px5.1.m1.1d">{}_{\text{disc}}</annotation></semantics></math> (Ours):</h4>

<div id="S4.SS3.SSS0.Px5.p1" class="ltx_para">
<p id="S4.SS3.SSS0.Px5.p1.3" class="ltx_p">MPR<math id="S4.SS3.SSS0.Px5.p1.1.m1.1" class="ltx_Math" alttext="{}_{\text{disc}}" display="inline"><semantics id="S4.SS3.SSS0.Px5.p1.1.m1.1a"><msub id="S4.SS3.SSS0.Px5.p1.1.m1.1.1" xref="S4.SS3.SSS0.Px5.p1.1.m1.1.1.cmml"><mi id="S4.SS3.SSS0.Px5.p1.1.m1.1.1a" xref="S4.SS3.SSS0.Px5.p1.1.m1.1.1.cmml"></mi><mtext id="S4.SS3.SSS0.Px5.p1.1.m1.1.1.1" xref="S4.SS3.SSS0.Px5.p1.1.m1.1.1.1a.cmml">disc</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px5.p1.1.m1.1b"><apply id="S4.SS3.SSS0.Px5.p1.1.m1.1.1.cmml" xref="S4.SS3.SSS0.Px5.p1.1.m1.1.1"><ci id="S4.SS3.SSS0.Px5.p1.1.m1.1.1.1a.cmml" xref="S4.SS3.SSS0.Px5.p1.1.m1.1.1.1"><mtext mathsize="70%" id="S4.SS3.SSS0.Px5.p1.1.m1.1.1.1.cmml" xref="S4.SS3.SSS0.Px5.p1.1.m1.1.1.1">disc</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px5.p1.1.m1.1c">{}_{\text{disc}}</annotation></semantics></math> refers to our discriminative variant by replacing a generative decoder with a prediction head to predict a finite set of answers. MPR<math id="S4.SS3.SSS0.Px5.p1.2.m2.1" class="ltx_Math" alttext="{}_{\text{disc\_BAN}}\ " display="inline"><semantics id="S4.SS3.SSS0.Px5.p1.2.m2.1a"><msub id="S4.SS3.SSS0.Px5.p1.2.m2.1.1" xref="S4.SS3.SSS0.Px5.p1.2.m2.1.1.cmml"><mi id="S4.SS3.SSS0.Px5.p1.2.m2.1.1a" xref="S4.SS3.SSS0.Px5.p1.2.m2.1.1.cmml"></mi><mtext id="S4.SS3.SSS0.Px5.p1.2.m2.1.1.1" xref="S4.SS3.SSS0.Px5.p1.2.m2.1.1.1a.cmml">disc_BAN</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px5.p1.2.m2.1b"><apply id="S4.SS3.SSS0.Px5.p1.2.m2.1.1.cmml" xref="S4.SS3.SSS0.Px5.p1.2.m2.1.1"><ci id="S4.SS3.SSS0.Px5.p1.2.m2.1.1.1a.cmml" xref="S4.SS3.SSS0.Px5.p1.2.m2.1.1.1"><mtext mathsize="70%" id="S4.SS3.SSS0.Px5.p1.2.m2.1.1.1.cmml" xref="S4.SS3.SSS0.Px5.p1.2.m2.1.1.1">disc_BAN</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px5.p1.2.m2.1c">{}_{\text{disc\_BAN}}\ </annotation></semantics></math>uses a prediction head similar to MPR<math id="S4.SS3.SSS0.Px5.p1.3.m3.1" class="ltx_Math" alttext="{}_{\text{disc}}" display="inline"><semantics id="S4.SS3.SSS0.Px5.p1.3.m3.1a"><msub id="S4.SS3.SSS0.Px5.p1.3.m3.1.1" xref="S4.SS3.SSS0.Px5.p1.3.m3.1.1.cmml"><mi id="S4.SS3.SSS0.Px5.p1.3.m3.1.1a" xref="S4.SS3.SSS0.Px5.p1.3.m3.1.1.cmml"></mi><mtext id="S4.SS3.SSS0.Px5.p1.3.m3.1.1.1" xref="S4.SS3.SSS0.Px5.p1.3.m3.1.1.1a.cmml">disc</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px5.p1.3.m3.1b"><apply id="S4.SS3.SSS0.Px5.p1.3.m3.1.1.cmml" xref="S4.SS3.SSS0.Px5.p1.3.m3.1.1"><ci id="S4.SS3.SSS0.Px5.p1.3.m3.1.1.1a.cmml" xref="S4.SS3.SSS0.Px5.p1.3.m3.1.1.1"><mtext mathsize="70%" id="S4.SS3.SSS0.Px5.p1.3.m3.1.1.1.cmml" xref="S4.SS3.SSS0.Px5.p1.3.m3.1.1.1">disc</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px5.p1.3.m3.1c">{}_{\text{disc}}</annotation></semantics></math>, but fuses the image and text features with a bilinear attention network <cite class="ltx_cite ltx_citemacro_cite">Kim et al. (<a href="#bib.bib16" title="" class="ltx_ref">2018</a>)</cite>.</p>
</div>
</section>
<section id="S4.SS3.SSS0.Px6" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">MPR<math id="S4.SS3.SSS0.Px6.1.m1.1" class="ltx_Math" alttext="{}_{\text{gen}}\ " display="inline"><semantics id="S4.SS3.SSS0.Px6.1.m1.1b"><msub id="S4.SS3.SSS0.Px6.1.m1.1.1" xref="S4.SS3.SSS0.Px6.1.m1.1.1.cmml"><mi id="S4.SS3.SSS0.Px6.1.m1.1.1b" xref="S4.SS3.SSS0.Px6.1.m1.1.1.cmml"></mi><mtext id="S4.SS3.SSS0.Px6.1.m1.1.1.1" xref="S4.SS3.SSS0.Px6.1.m1.1.1.1a.cmml">gen</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px6.1.m1.1c"><apply id="S4.SS3.SSS0.Px6.1.m1.1.1.cmml" xref="S4.SS3.SSS0.Px6.1.m1.1.1"><ci id="S4.SS3.SSS0.Px6.1.m1.1.1.1a.cmml" xref="S4.SS3.SSS0.Px6.1.m1.1.1.1"><mtext mathsize="70%" id="S4.SS3.SSS0.Px6.1.m1.1.1.1.cmml" xref="S4.SS3.SSS0.Px6.1.m1.1.1.1">gen</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px6.1.m1.1d">{}_{\text{gen}}\ </annotation></semantics></math>(Ours):</h4>

<div id="S4.SS3.SSS0.Px6.p1" class="ltx_para">
<p id="S4.SS3.SSS0.Px6.p1.3" class="ltx_p">MPR<math id="S4.SS3.SSS0.Px6.p1.1.m1.1" class="ltx_Math" alttext="{}_{\text{gen}}\ " display="inline"><semantics id="S4.SS3.SSS0.Px6.p1.1.m1.1a"><msub id="S4.SS3.SSS0.Px6.p1.1.m1.1.1" xref="S4.SS3.SSS0.Px6.p1.1.m1.1.1.cmml"><mi id="S4.SS3.SSS0.Px6.p1.1.m1.1.1a" xref="S4.SS3.SSS0.Px6.p1.1.m1.1.1.cmml"></mi><mtext id="S4.SS3.SSS0.Px6.p1.1.m1.1.1.1" xref="S4.SS3.SSS0.Px6.p1.1.m1.1.1.1a.cmml">gen</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px6.p1.1.m1.1b"><apply id="S4.SS3.SSS0.Px6.p1.1.m1.1.1.cmml" xref="S4.SS3.SSS0.Px6.p1.1.m1.1.1"><ci id="S4.SS3.SSS0.Px6.p1.1.m1.1.1.1a.cmml" xref="S4.SS3.SSS0.Px6.p1.1.m1.1.1.1"><mtext mathsize="70%" id="S4.SS3.SSS0.Px6.p1.1.m1.1.1.1.cmml" xref="S4.SS3.SSS0.Px6.p1.1.m1.1.1.1">gen</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px6.p1.1.m1.1c">{}_{\text{gen}}\ </annotation></semantics></math>refers to our generative architecture which outputs flexible answers. MPR<math id="S4.SS3.SSS0.Px6.p1.2.m2.1" class="ltx_Math" alttext="{}_{\text{gen\_PM}}\ " display="inline"><semantics id="S4.SS3.SSS0.Px6.p1.2.m2.1a"><msub id="S4.SS3.SSS0.Px6.p1.2.m2.1.1" xref="S4.SS3.SSS0.Px6.p1.2.m2.1.1.cmml"><mi id="S4.SS3.SSS0.Px6.p1.2.m2.1.1a" xref="S4.SS3.SSS0.Px6.p1.2.m2.1.1.cmml"></mi><mtext id="S4.SS3.SSS0.Px6.p1.2.m2.1.1.1" xref="S4.SS3.SSS0.Px6.p1.2.m2.1.1.1a.cmml">gen_PM</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px6.p1.2.m2.1b"><apply id="S4.SS3.SSS0.Px6.p1.2.m2.1.1.cmml" xref="S4.SS3.SSS0.Px6.p1.2.m2.1.1"><ci id="S4.SS3.SSS0.Px6.p1.2.m2.1.1.1a.cmml" xref="S4.SS3.SSS0.Px6.p1.2.m2.1.1.1"><mtext mathsize="70%" id="S4.SS3.SSS0.Px6.p1.2.m2.1.1.1.cmml" xref="S4.SS3.SSS0.Px6.p1.2.m2.1.1.1">gen_PM</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px6.p1.2.m2.1c">{}_{\text{gen\_PM}}\ </annotation></semantics></math>has the same architecture as MPR<math id="S4.SS3.SSS0.Px6.p1.3.m3.1" class="ltx_Math" alttext="{}_{\text{gen}}\ " display="inline"><semantics id="S4.SS3.SSS0.Px6.p1.3.m3.1a"><msub id="S4.SS3.SSS0.Px6.p1.3.m3.1.1" xref="S4.SS3.SSS0.Px6.p1.3.m3.1.1.cmml"><mi id="S4.SS3.SSS0.Px6.p1.3.m3.1.1a" xref="S4.SS3.SSS0.Px6.p1.3.m3.1.1.cmml"></mi><mtext id="S4.SS3.SSS0.Px6.p1.3.m3.1.1.1" xref="S4.SS3.SSS0.Px6.p1.3.m3.1.1.1a.cmml">gen</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px6.p1.3.m3.1b"><apply id="S4.SS3.SSS0.Px6.p1.3.m3.1.1.cmml" xref="S4.SS3.SSS0.Px6.p1.3.m3.1.1"><ci id="S4.SS3.SSS0.Px6.p1.3.m3.1.1.1a.cmml" xref="S4.SS3.SSS0.Px6.p1.3.m3.1.1.1"><mtext mathsize="70%" id="S4.SS3.SSS0.Px6.p1.3.m3.1.1.1.cmml" xref="S4.SS3.SSS0.Px6.p1.3.m3.1.1.1">gen</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px6.p1.3.m3.1c">{}_{\text{gen}}\ </annotation></semantics></math>, but is initialized with a pre-trained checkpoint from PubMedCLIP <cite class="ltx_cite ltx_citemacro_cite">Eslami et al. (<a href="#bib.bib6" title="" class="ltx_ref">2021</a>)</cite>.<span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><a target="_blank" href="https://github.com/sarahESL/PubMedCLIP" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/sarahESL/PubMedCLIP</a></span></span></span></p>
</div>
<figure id="S4.T1" class="ltx_table">
<div id="S4.T1.6" class="ltx_inline-block ltx_transformed_outer" style="width:433.6pt;height:104.1pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-10.2pt,2.4pt) scale(0.955015176280977,0.955015176280977) ;">
<table id="S4.T1.6.6" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T1.2.2.2" class="ltx_tr">
<th id="S4.T1.2.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt ltx_border_t" rowspan="2"><span id="S4.T1.2.2.2.3.1" class="ltx_text">Context</span></th>
<th id="S4.T1.2.2.2.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt ltx_border_t" rowspan="2"><span id="S4.T1.2.2.2.4.1" class="ltx_text">Method</span></th>
<th id="S4.T1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt ltx_border_t" colspan="3">SLAKE <math id="S4.T1.1.1.1.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.T1.1.1.1.1.m1.1a"><mo stretchy="false" id="S4.T1.1.1.1.1.m1.1.1" xref="S4.T1.1.1.1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.T1.1.1.1.1.m1.1b"><ci id="S4.T1.1.1.1.1.m1.1.1.cmml" xref="S4.T1.1.1.1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.1.1.1.1.m1.1c">\rightarrow</annotation></semantics></math> <span id="S4.T1.1.1.1.1.1" class="ltx_text">VQA-RAD</span>
</th>
<th id="S4.T1.2.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt ltx_border_t" colspan="3">VQA-RAD <math id="S4.T1.2.2.2.2.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S4.T1.2.2.2.2.m1.1a"><mo stretchy="false" id="S4.T1.2.2.2.2.m1.1.1" xref="S4.T1.2.2.2.2.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.T1.2.2.2.2.m1.1b"><ci id="S4.T1.2.2.2.2.m1.1.1.cmml" xref="S4.T1.2.2.2.2.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.2.2.2.2.m1.1c">\rightarrow</annotation></semantics></math> <span id="S4.T1.2.2.2.2.1" class="ltx_text">SLAKE</span>
</th>
</tr>
<tr id="S4.T1.6.6.7.1" class="ltx_tr">
<th id="S4.T1.6.6.7.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column">Open</th>
<th id="S4.T1.6.6.7.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column">Closed</th>
<th id="S4.T1.6.6.7.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r">Overall</th>
<th id="S4.T1.6.6.7.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column">Open</th>
<th id="S4.T1.6.6.7.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column">Closed</th>
<th id="S4.T1.6.6.7.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column">Overall</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T1.3.3.3" class="ltx_tr">
<th id="S4.T1.3.3.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" rowspan="2"><span id="S4.T1.3.3.3.2.1" class="ltx_text">Image and Question</span></th>
<th id="S4.T1.3.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">MPR<math id="S4.T1.3.3.3.1.m1.1" class="ltx_Math" alttext="{}_{\text{gen\_PM}}\ " display="inline"><semantics id="S4.T1.3.3.3.1.m1.1a"><msub id="S4.T1.3.3.3.1.m1.1.1" xref="S4.T1.3.3.3.1.m1.1.1.cmml"><mi id="S4.T1.3.3.3.1.m1.1.1a" xref="S4.T1.3.3.3.1.m1.1.1.cmml"></mi><mtext id="S4.T1.3.3.3.1.m1.1.1.1" xref="S4.T1.3.3.3.1.m1.1.1.1a.cmml">gen_PM</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.T1.3.3.3.1.m1.1b"><apply id="S4.T1.3.3.3.1.m1.1.1.cmml" xref="S4.T1.3.3.3.1.m1.1.1"><ci id="S4.T1.3.3.3.1.m1.1.1.1a.cmml" xref="S4.T1.3.3.3.1.m1.1.1.1"><mtext mathsize="70%" id="S4.T1.3.3.3.1.m1.1.1.1.cmml" xref="S4.T1.3.3.3.1.m1.1.1.1">gen_PM</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.3.3.3.1.m1.1c">{}_{\text{gen\_PM}}\ </annotation></semantics></math>
</th>
<td id="S4.T1.3.3.3.3" class="ltx_td ltx_align_center ltx_border_t">6.0</td>
<td id="S4.T1.3.3.3.4" class="ltx_td ltx_align_center ltx_border_t">53.4</td>
<td id="S4.T1.3.3.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">34.6</td>
<td id="S4.T1.3.3.3.6" class="ltx_td ltx_align_center ltx_border_t">18.3</td>
<td id="S4.T1.3.3.3.7" class="ltx_td ltx_align_center ltx_border_t">52.2</td>
<td id="S4.T1.3.3.3.8" class="ltx_td ltx_align_center ltx_border_t">31.6</td>
</tr>
<tr id="S4.T1.4.4.4" class="ltx_tr">
<th id="S4.T1.4.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">MPR<math id="S4.T1.4.4.4.1.m1.1" class="ltx_Math" alttext="{}_{\text{gen}}\ " display="inline"><semantics id="S4.T1.4.4.4.1.m1.1a"><msub id="S4.T1.4.4.4.1.m1.1.1" xref="S4.T1.4.4.4.1.m1.1.1.cmml"><mi id="S4.T1.4.4.4.1.m1.1.1a" xref="S4.T1.4.4.4.1.m1.1.1.cmml"></mi><mtext id="S4.T1.4.4.4.1.m1.1.1.1" xref="S4.T1.4.4.4.1.m1.1.1.1a.cmml">gen</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.T1.4.4.4.1.m1.1b"><apply id="S4.T1.4.4.4.1.m1.1.1.cmml" xref="S4.T1.4.4.4.1.m1.1.1"><ci id="S4.T1.4.4.4.1.m1.1.1.1a.cmml" xref="S4.T1.4.4.4.1.m1.1.1.1"><mtext mathsize="70%" id="S4.T1.4.4.4.1.m1.1.1.1.cmml" xref="S4.T1.4.4.4.1.m1.1.1.1">gen</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.4.4.4.1.m1.1c">{}_{\text{gen}}\ </annotation></semantics></math>
</th>
<td id="S4.T1.4.4.4.2" class="ltx_td ltx_align_center">4.9</td>
<td id="S4.T1.4.4.4.3" class="ltx_td ltx_align_center">52.0</td>
<td id="S4.T1.4.4.4.4" class="ltx_td ltx_align_center ltx_border_r">33.3</td>
<td id="S4.T1.4.4.4.5" class="ltx_td ltx_align_center">16.9</td>
<td id="S4.T1.4.4.4.6" class="ltx_td ltx_align_center">46.4</td>
<td id="S4.T1.4.4.4.7" class="ltx_td ltx_align_center">28.5</td>
</tr>
<tr id="S4.T1.5.5.5" class="ltx_tr">
<th id="S4.T1.5.5.5.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_t" rowspan="2"><span id="S4.T1.5.5.5.2.1" class="ltx_text">Image, Question, and Retrieval</span></th>
<th id="S4.T1.5.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">MPR<math id="S4.T1.5.5.5.1.m1.1" class="ltx_Math" alttext="{}_{\text{gen\_PM}}\ " display="inline"><semantics id="S4.T1.5.5.5.1.m1.1a"><msub id="S4.T1.5.5.5.1.m1.1.1" xref="S4.T1.5.5.5.1.m1.1.1.cmml"><mi id="S4.T1.5.5.5.1.m1.1.1a" xref="S4.T1.5.5.5.1.m1.1.1.cmml"></mi><mtext id="S4.T1.5.5.5.1.m1.1.1.1" xref="S4.T1.5.5.5.1.m1.1.1.1a.cmml">gen_PM</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.T1.5.5.5.1.m1.1b"><apply id="S4.T1.5.5.5.1.m1.1.1.cmml" xref="S4.T1.5.5.5.1.m1.1.1"><ci id="S4.T1.5.5.5.1.m1.1.1.1a.cmml" xref="S4.T1.5.5.5.1.m1.1.1.1"><mtext mathsize="70%" id="S4.T1.5.5.5.1.m1.1.1.1.cmml" xref="S4.T1.5.5.5.1.m1.1.1.1">gen_PM</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.5.5.5.1.m1.1c">{}_{\text{gen\_PM}}\ </annotation></semantics></math>
</th>
<td id="S4.T1.5.5.5.3" class="ltx_td ltx_align_center ltx_border_t">42.9</td>
<td id="S4.T1.5.5.5.4" class="ltx_td ltx_align_center ltx_border_t">76.2</td>
<td id="S4.T1.5.5.5.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">63.0</td>
<td id="S4.T1.5.5.5.6" class="ltx_td ltx_align_center ltx_border_t">45.1</td>
<td id="S4.T1.5.5.5.7" class="ltx_td ltx_align_center ltx_border_t">67.3</td>
<td id="S4.T1.5.5.5.8" class="ltx_td ltx_align_center ltx_border_t">53.8</td>
</tr>
<tr id="S4.T1.6.6.6" class="ltx_tr">
<th id="S4.T1.6.6.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r">MPR<math id="S4.T1.6.6.6.1.m1.1" class="ltx_Math" alttext="{}_{\text{gen}}\ " display="inline"><semantics id="S4.T1.6.6.6.1.m1.1a"><msub id="S4.T1.6.6.6.1.m1.1.1" xref="S4.T1.6.6.6.1.m1.1.1.cmml"><mi id="S4.T1.6.6.6.1.m1.1.1a" xref="S4.T1.6.6.6.1.m1.1.1.cmml"></mi><mtext id="S4.T1.6.6.6.1.m1.1.1.1" xref="S4.T1.6.6.6.1.m1.1.1.1a.cmml">gen</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.T1.6.6.6.1.m1.1b"><apply id="S4.T1.6.6.6.1.m1.1.1.cmml" xref="S4.T1.6.6.6.1.m1.1.1"><ci id="S4.T1.6.6.6.1.m1.1.1.1a.cmml" xref="S4.T1.6.6.6.1.m1.1.1.1"><mtext mathsize="70%" id="S4.T1.6.6.6.1.m1.1.1.1.cmml" xref="S4.T1.6.6.6.1.m1.1.1.1">gen</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.6.6.6.1.m1.1c">{}_{\text{gen}}\ </annotation></semantics></math>
</th>
<td id="S4.T1.6.6.6.2" class="ltx_td ltx_align_center ltx_border_bb">41.8</td>
<td id="S4.T1.6.6.6.3" class="ltx_td ltx_align_center ltx_border_bb">74.4</td>
<td id="S4.T1.6.6.6.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">61.4</td>
<td id="S4.T1.6.6.6.5" class="ltx_td ltx_align_center ltx_border_bb">38.4</td>
<td id="S4.T1.6.6.6.6" class="ltx_td ltx_align_center ltx_border_bb">57.7</td>
<td id="S4.T1.6.6.6.7" class="ltx_td ltx_align_center ltx_border_bb">46.0</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>Performances of our generative prompting method in a domain adaptation setting with different levels of context. When provided with retrieval context, the models query for <math id="S4.T1.8.m1.1" class="ltx_Math" alttext="k=1" display="inline"><semantics id="S4.T1.8.m1.1b"><mrow id="S4.T1.8.m1.1.1" xref="S4.T1.8.m1.1.1.cmml"><mi id="S4.T1.8.m1.1.1.2" xref="S4.T1.8.m1.1.1.2.cmml">k</mi><mo id="S4.T1.8.m1.1.1.1" xref="S4.T1.8.m1.1.1.1.cmml">=</mo><mn id="S4.T1.8.m1.1.1.3" xref="S4.T1.8.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.8.m1.1c"><apply id="S4.T1.8.m1.1.1.cmml" xref="S4.T1.8.m1.1.1"><eq id="S4.T1.8.m1.1.1.1.cmml" xref="S4.T1.8.m1.1.1.1"></eq><ci id="S4.T1.8.m1.1.1.2.cmml" xref="S4.T1.8.m1.1.1.2">𝑘</ci><cn type="integer" id="S4.T1.8.m1.1.1.3.cmml" xref="S4.T1.8.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.8.m1.1d">k=1</annotation></semantics></math> relevant image-question pairs. </figcaption>
</figure>
<figure id="S4.F2" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2306.17675/assets/x2.png" id="S4.F2.g1" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="230" height="179" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2306.17675/assets/x3.png" id="S4.F2.g2" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="230" height="179" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Domain adapation accuracy for the top 5 most common question types in the SLAKE and VQA-RAD datasets. Percentages on the x-axis indicate each question type’s proportion of the dataset. MPR<math id="S4.F2.4.m1.1" class="ltx_Math" alttext="{}_{\text{gen}}\ " display="inline"><semantics id="S4.F2.4.m1.1b"><msub id="S4.F2.4.m1.1.1" xref="S4.F2.4.m1.1.1.cmml"><mi id="S4.F2.4.m1.1.1b" xref="S4.F2.4.m1.1.1.cmml"></mi><mtext id="S4.F2.4.m1.1.1.1" xref="S4.F2.4.m1.1.1.1a.cmml">gen</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.F2.4.m1.1c"><apply id="S4.F2.4.m1.1.1.cmml" xref="S4.F2.4.m1.1.1"><ci id="S4.F2.4.m1.1.1.1a.cmml" xref="S4.F2.4.m1.1.1.1"><mtext mathsize="70%" id="S4.F2.4.m1.1.1.1.cmml" xref="S4.F2.4.m1.1.1.1">gen</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F2.4.m1.1d">{}_{\text{gen}}\ </annotation></semantics></math>and MPR<math id="S4.F2.5.m2.1" class="ltx_Math" alttext="{}_{\text{gen\_PM}}\ " display="inline"><semantics id="S4.F2.5.m2.1b"><msub id="S4.F2.5.m2.1.1" xref="S4.F2.5.m2.1.1.cmml"><mi id="S4.F2.5.m2.1.1b" xref="S4.F2.5.m2.1.1.cmml"></mi><mtext id="S4.F2.5.m2.1.1.1" xref="S4.F2.5.m2.1.1.1a.cmml">gen_PM</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.F2.5.m2.1c"><apply id="S4.F2.5.m2.1.1.cmml" xref="S4.F2.5.m2.1.1"><ci id="S4.F2.5.m2.1.1.1a.cmml" xref="S4.F2.5.m2.1.1.1"><mtext mathsize="70%" id="S4.F2.5.m2.1.1.1.cmml" xref="S4.F2.5.m2.1.1.1">gen_PM</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F2.5.m2.1d">{}_{\text{gen\_PM}}\ </annotation></semantics></math>use retrieval and query for <math id="S4.F2.6.m3.1" class="ltx_Math" alttext="k=1" display="inline"><semantics id="S4.F2.6.m3.1b"><mrow id="S4.F2.6.m3.1.1" xref="S4.F2.6.m3.1.1.cmml"><mi id="S4.F2.6.m3.1.1.2" xref="S4.F2.6.m3.1.1.2.cmml">k</mi><mo id="S4.F2.6.m3.1.1.1" xref="S4.F2.6.m3.1.1.1.cmml">=</mo><mn id="S4.F2.6.m3.1.1.3" xref="S4.F2.6.m3.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.F2.6.m3.1c"><apply id="S4.F2.6.m3.1.1.cmml" xref="S4.F2.6.m3.1.1"><eq id="S4.F2.6.m3.1.1.1.cmml" xref="S4.F2.6.m3.1.1.1"></eq><ci id="S4.F2.6.m3.1.1.2.cmml" xref="S4.F2.6.m3.1.1.2">𝑘</ci><cn type="integer" id="S4.F2.6.m3.1.1.3.cmml" xref="S4.F2.6.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F2.6.m3.1d">k=1</annotation></semantics></math> relevant image-question pairs. Retrieval-based models outperform our zero-shot baseline, and initializing MPR with a PubMedCLIP checkpoint helps. </figcaption>
</figure>
</section>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Results and Analysis</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">This section describes the results of our main experiments (§<a href="#S5.SS1" title="5.1 In-context Prediction for Adaptation ‣ 5 Results and Analysis ‣ Multimodal Prompt Retrieval for Generative Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.1</span></a>) and fine-grained analysis thereafter.</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>In-context Prediction for Adaptation</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.3" class="ltx_p">First, we evaluate our proposed method’s generalization capability of in-context predictions. We define a <math id="S5.SS1.p1.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S5.SS1.p1.1.m1.1a"><mi id="S5.SS1.p1.1.m1.1.1" xref="S5.SS1.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.1.m1.1b"><ci id="S5.SS1.p1.1.m1.1.1.cmml" xref="S5.SS1.p1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.1.m1.1c">k</annotation></semantics></math>-shot setting where our model retrieves Top-<math id="S5.SS1.p1.2.m2.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S5.SS1.p1.2.m2.1a"><mi id="S5.SS1.p1.2.m2.1.1" xref="S5.SS1.p1.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.2.m2.1b"><ci id="S5.SS1.p1.2.m2.1.1.cmml" xref="S5.SS1.p1.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.2.m2.1c">k</annotation></semantics></math> similar image-question pairs from the retrieval set. We compare the performance of the <math id="S5.SS1.p1.3.m3.1" class="ltx_Math" alttext="k=1" display="inline"><semantics id="S5.SS1.p1.3.m3.1a"><mrow id="S5.SS1.p1.3.m3.1.1" xref="S5.SS1.p1.3.m3.1.1.cmml"><mi id="S5.SS1.p1.3.m3.1.1.2" xref="S5.SS1.p1.3.m3.1.1.2.cmml">k</mi><mo id="S5.SS1.p1.3.m3.1.1.1" xref="S5.SS1.p1.3.m3.1.1.1.cmml">=</mo><mn id="S5.SS1.p1.3.m3.1.1.3" xref="S5.SS1.p1.3.m3.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.3.m3.1b"><apply id="S5.SS1.p1.3.m3.1.1.cmml" xref="S5.SS1.p1.3.m3.1.1"><eq id="S5.SS1.p1.3.m3.1.1.1.cmml" xref="S5.SS1.p1.3.m3.1.1.1"></eq><ci id="S5.SS1.p1.3.m3.1.1.2.cmml" xref="S5.SS1.p1.3.m3.1.1.2">𝑘</ci><cn type="integer" id="S5.SS1.p1.3.m3.1.1.3.cmml" xref="S5.SS1.p1.3.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.3.m3.1c">k=1</annotation></semantics></math> setting with zero-shot MPR (i.e., MPR w/o retrieval) on two medical domain adaptation tasks.</p>
</div>
<section id="S5.SS1.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Overall Accuracy:</h4>

<div id="S5.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="S5.SS1.SSS0.Px1.p1.1" class="ltx_p">Table <a href="#S4.T1" title='Table 1 ‣ MPR_"gen"(Ours): ‣ 4.3 Baselines ‣ 4 Experimental Setup ‣ Multimodal Prompt Retrieval for Generative Visual Question Answering' class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> compares the performances of our generative models under domain shift. Most notably, allowing the models to access a retrieval set universally improves performance, especially on questions with open answers. We also demonstrate that initializing our model with a PubMedCLIP pre-trained checkpoint results in higher accuracy than a general CLIP checkpoint. As the other discrinimative baselines can only predict a fixed set of answers, they cannot perform adaptation over different answer sets. We only compare them for our in-domain analysis (§<a href="#S5.SS5" title="5.5 In-domain Evaluation ‣ 5 Results and Analysis ‣ Multimodal Prompt Retrieval for Generative Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.5</span></a>).</p>
</div>
</section>
<section id="S5.SS1.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Fine-grained Accuracy over QA Types:</h4>

<div id="S5.SS1.SSS0.Px2.p1" class="ltx_para">
<p id="S5.SS1.SSS0.Px2.p1.1" class="ltx_p">Figure <a href="#S4.F2" title='Figure 2 ‣ MPR_"gen"(Ours): ‣ 4.3 Baselines ‣ 4 Experimental Setup ‣ Multimodal Prompt Retrieval for Generative Visual Question Answering' class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> summarizes our model performances across individual QA types in a domain adaptation setting. We find that zero-shot MPR struggles with question types that require logical reasoning, such as Knowledge Graph (KG) or Position questions, while in-context retrieval increases model performance significantly in these question types. Using a PubMedCLIP vision encoder further increases accuracy for these challenging question types.</p>
</div>
</section>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Retrieval Sets for In-context Prediction</h3>

<figure id="S5.T2" class="ltx_table">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_1"><span id="S5.T2.10" class="ltx_ERROR ltx_figure_panel undefined">\renewrobustcmd</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div id="S5.T2.3" class="ltx_inline-block ltx_figure_panel ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:208.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(48.5pt,-23.3pt) scale(1.28787194534707,1.28787194534707) ;">
<table id="S5.T2.3.3" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T2.1.1.1" class="ltx_tr">
<th id="S5.T2.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt ltx_border_tt">Source <math id="S5.T2.1.1.1.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S5.T2.1.1.1.1.m1.1a"><mo stretchy="false" id="S5.T2.1.1.1.1.m1.1.1" xref="S5.T2.1.1.1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S5.T2.1.1.1.1.m1.1b"><ci id="S5.T2.1.1.1.1.m1.1.1.cmml" xref="S5.T2.1.1.1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.1.1.1.1.m1.1c">\rightarrow</annotation></semantics></math> Target</th>
<th id="S5.T2.1.1.1.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_tt ltx_border_tt">Retrieval Set</th>
<th id="S5.T2.1.1.1.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_tt ltx_border_tt">Open</th>
<th id="S5.T2.1.1.1.4" class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_tt ltx_border_tt">Closed</th>
<th id="S5.T2.1.1.1.5" class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_tt ltx_border_tt">Overall</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T2.2.2.2" class="ltx_tr">
<td id="S5.T2.2.2.2.1" class="ltx_td ltx_align_center ltx_border_t" rowspan="4"><span id="S5.T2.2.2.2.1.1" class="ltx_text">SLAKE <math id="S5.T2.2.2.2.1.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S5.T2.2.2.2.1.1.m1.1a"><mo stretchy="false" id="S5.T2.2.2.2.1.1.m1.1.1" xref="S5.T2.2.2.2.1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S5.T2.2.2.2.1.1.m1.1b"><ci id="S5.T2.2.2.2.1.1.m1.1.1.cmml" xref="S5.T2.2.2.2.1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.2.2.2.1.1.m1.1c">\rightarrow</annotation></semantics></math> VQA-RAD</span></td>
<td id="S5.T2.2.2.2.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t">None (Zero-shot)</td>
<td id="S5.T2.2.2.2.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t">6.0</td>
<td id="S5.T2.2.2.2.4" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t">53.4</td>
<td id="S5.T2.2.2.2.5" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t">34.6</td>
</tr>
<tr id="S5.T2.3.3.4.1" class="ltx_tr">
<td id="S5.T2.3.3.4.1.1" class="ltx_td ltx_nopad_l ltx_align_center">Synthetic</td>
<td id="S5.T2.3.3.4.1.2" class="ltx_td ltx_nopad_l ltx_align_center">11.5</td>
<td id="S5.T2.3.3.4.1.3" class="ltx_td ltx_nopad_l ltx_align_center">49.8</td>
<td id="S5.T2.3.3.4.1.4" class="ltx_td ltx_nopad_l ltx_align_center">34.6</td>
</tr>
<tr id="S5.T2.3.3.5.2" class="ltx_tr">
<td id="S5.T2.3.3.5.2.1" class="ltx_td ltx_nopad_l ltx_align_center">VQA-RAD</td>
<td id="S5.T2.3.3.5.2.2" class="ltx_td ltx_nopad_l ltx_align_center">42.9</td>
<td id="S5.T2.3.3.5.2.3" class="ltx_td ltx_nopad_l ltx_align_center">76.2</td>
<td id="S5.T2.3.3.5.2.4" class="ltx_td ltx_nopad_l ltx_align_center">63.0</td>
</tr>
<tr id="S5.T2.3.3.6.3" class="ltx_tr">
<td id="S5.T2.3.3.6.3.1" class="ltx_td ltx_nopad_l ltx_align_center">VQA-RAD + Synthetic</td>
<td id="S5.T2.3.3.6.3.2" class="ltx_td ltx_nopad_l ltx_align_center">44.5</td>
<td id="S5.T2.3.3.6.3.3" class="ltx_td ltx_nopad_l ltx_align_center">76.5</td>
<td id="S5.T2.3.3.6.3.4" class="ltx_td ltx_nopad_l ltx_align_center">63.8</td>
</tr>
<tr id="S5.T2.3.3.3" class="ltx_tr">
<td id="S5.T2.3.3.3.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" rowspan="4"><span id="S5.T2.3.3.3.1.1" class="ltx_text">VQA-RAD <math id="S5.T2.3.3.3.1.1.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S5.T2.3.3.3.1.1.m1.1a"><mo stretchy="false" id="S5.T2.3.3.3.1.1.m1.1.1" xref="S5.T2.3.3.3.1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S5.T2.3.3.3.1.1.m1.1b"><ci id="S5.T2.3.3.3.1.1.m1.1.1.cmml" xref="S5.T2.3.3.3.1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.3.3.3.1.1.m1.1c">\rightarrow</annotation></semantics></math> SLAKE</span></td>
<td id="S5.T2.3.3.3.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t">None (Zero-shot)</td>
<td id="S5.T2.3.3.3.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t">16.9</td>
<td id="S5.T2.3.3.3.4" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t">46.4</td>
<td id="S5.T2.3.3.3.5" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t">28.5</td>
</tr>
<tr id="S5.T2.3.3.7.4" class="ltx_tr">
<td id="S5.T2.3.3.7.4.1" class="ltx_td ltx_nopad_l ltx_align_center">Synthetic</td>
<td id="S5.T2.3.3.7.4.2" class="ltx_td ltx_nopad_l ltx_align_center">18.3</td>
<td id="S5.T2.3.3.7.4.3" class="ltx_td ltx_nopad_l ltx_align_center">50.2</td>
<td id="S5.T2.3.3.7.4.4" class="ltx_td ltx_nopad_l ltx_align_center">30.8</td>
</tr>
<tr id="S5.T2.3.3.8.5" class="ltx_tr">
<td id="S5.T2.3.3.8.5.1" class="ltx_td ltx_nopad_l ltx_align_center">SLAKE</td>
<td id="S5.T2.3.3.8.5.2" class="ltx_td ltx_nopad_l ltx_align_center">45.1</td>
<td id="S5.T2.3.3.8.5.3" class="ltx_td ltx_nopad_l ltx_align_center">67.3</td>
<td id="S5.T2.3.3.8.5.4" class="ltx_td ltx_nopad_l ltx_align_center">53.8</td>
</tr>
<tr id="S5.T2.3.3.9.6" class="ltx_tr">
<td id="S5.T2.3.3.9.6.1" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb">SLAKE + Synthetic</td>
<td id="S5.T2.3.3.9.6.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb">45.1</td>
<td id="S5.T2.3.3.9.6.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb">67.3</td>
<td id="S5.T2.3.3.9.6.4" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb">53.8</td>
</tr>
</tbody>
</table>
</span></div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Results of zero-/few-shot in-context prediction for domain adaptation with varying degrees of retrieval dataset access. We use MPR<math id="S5.T2.7.m1.1" class="ltx_Math" alttext="{}_{\text{gen\_PM}}\ " display="inline"><semantics id="S5.T2.7.m1.1b"><msub id="S5.T2.7.m1.1.1" xref="S5.T2.7.m1.1.1.cmml"><mi id="S5.T2.7.m1.1.1b" xref="S5.T2.7.m1.1.1.cmml"></mi><mtext id="S5.T2.7.m1.1.1.1" xref="S5.T2.7.m1.1.1.1a.cmml">gen_PM</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.T2.7.m1.1c"><apply id="S5.T2.7.m1.1.1.cmml" xref="S5.T2.7.m1.1.1"><ci id="S5.T2.7.m1.1.1.1a.cmml" xref="S5.T2.7.m1.1.1.1"><mtext mathsize="70%" id="S5.T2.7.m1.1.1.1.cmml" xref="S5.T2.7.m1.1.1.1">gen_PM</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.7.m1.1d">{}_{\text{gen\_PM}}\ </annotation></semantics></math>with <math id="S5.T2.8.m2.1" class="ltx_Math" alttext="k=1" display="inline"><semantics id="S5.T2.8.m2.1b"><mrow id="S5.T2.8.m2.1.1" xref="S5.T2.8.m2.1.1.cmml"><mi id="S5.T2.8.m2.1.1.2" xref="S5.T2.8.m2.1.1.2.cmml">k</mi><mo id="S5.T2.8.m2.1.1.1" xref="S5.T2.8.m2.1.1.1.cmml">=</mo><mn id="S5.T2.8.m2.1.1.3" xref="S5.T2.8.m2.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.8.m2.1c"><apply id="S5.T2.8.m2.1.1.cmml" xref="S5.T2.8.m2.1.1"><eq id="S5.T2.8.m2.1.1.1.cmml" xref="S5.T2.8.m2.1.1.1"></eq><ci id="S5.T2.8.m2.1.1.2.cmml" xref="S5.T2.8.m2.1.1.2">𝑘</ci><cn type="integer" id="S5.T2.8.m2.1.1.3.cmml" xref="S5.T2.8.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.8.m2.1d">k=1</annotation></semantics></math> for all settings except <math id="S5.T2.9.m3.1" class="ltx_Math" alttext="k=50" display="inline"><semantics id="S5.T2.9.m3.1b"><mrow id="S5.T2.9.m3.1.1" xref="S5.T2.9.m3.1.1.cmml"><mi id="S5.T2.9.m3.1.1.2" xref="S5.T2.9.m3.1.1.2.cmml">k</mi><mo id="S5.T2.9.m3.1.1.1" xref="S5.T2.9.m3.1.1.1.cmml">=</mo><mn id="S5.T2.9.m3.1.1.3" xref="S5.T2.9.m3.1.1.3.cmml">50</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.9.m3.1c"><apply id="S5.T2.9.m3.1.1.cmml" xref="S5.T2.9.m3.1.1"><eq id="S5.T2.9.m3.1.1.1.cmml" xref="S5.T2.9.m3.1.1.1"></eq><ci id="S5.T2.9.m3.1.1.2.cmml" xref="S5.T2.9.m3.1.1.2">𝑘</ci><cn type="integer" id="S5.T2.9.m3.1.1.3.cmml" xref="S5.T2.9.m3.1.1.3">50</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.9.m3.1d">k=50</annotation></semantics></math> for the noisy synthetic dataset.</figcaption>
</figure>
<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">We also examine the effect of using different datasets for retrieval. Table <a href="#S5.T2" title="Table 2 ‣ 5.2 Retrieval Sets for In-context Prediction ‣ 5 Results and Analysis ‣ Multimodal Prompt Retrieval for Generative Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> illustrates the zero-shot/few-shot accuracies when applying a source model to a target dataset with different retrieval datasets. Increasing the retrieval dataset’s quality improves the model’s adaptation capability to new questions. Without any retrieval, open question accuracy is as low as 6%. Providing access to a noisy synthetic retrieval dataset improves open question performance. Using a higher quality in-domain retrieval set further enhances performance in all categories, achieving over 30% improvement in open question accuracy compared to the zero-shot baselines. Combining in-domain retrieval data with noisy synthetic data further boosts accuracy in all three accuracy categories on VQA-RAD. However, we observed no further improvement when combining the synthetic and SLAKE datasets. With a manual investigation, we find that questions in SLAKE have much simpler synthetic variants than those in VQA-RAD. Therefore, SLAKE already provides the most similar examples during retrieval, and additional synthetic data provides minimal gains.</p>
</div>
<figure id="S5.F3" class="ltx_figure"><img src="/html/2306.17675/assets/x4.png" id="S5.F3.g1" class="ltx_graphics ltx_img_landscape" width="133" height="69" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>A generative model MPR<math id="S5.F3.2.m1.1" class="ltx_Math" alttext="{}_{\text{gen\_PM}}\ " display="inline"><semantics id="S5.F3.2.m1.1b"><msub id="S5.F3.2.m1.1.1" xref="S5.F3.2.m1.1.1.cmml"><mi id="S5.F3.2.m1.1.1b" xref="S5.F3.2.m1.1.1.cmml"></mi><mtext id="S5.F3.2.m1.1.1.1" xref="S5.F3.2.m1.1.1.1a.cmml">gen_PM</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.F3.2.m1.1c"><apply id="S5.F3.2.m1.1.1.cmml" xref="S5.F3.2.m1.1.1"><ci id="S5.F3.2.m1.1.1.1a.cmml" xref="S5.F3.2.m1.1.1.1"><mtext mathsize="70%" id="S5.F3.2.m1.1.1.1.cmml" xref="S5.F3.2.m1.1.1.1">gen_PM</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F3.2.m1.1d">{}_{\text{gen\_PM}}\ </annotation></semantics></math>trained on the SLAKE dataset is evaluated on the VQA-RAD dataset over different numbers of few-shot retrievals. </figcaption>
</figure>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>How Many Shots are Needed?</h3>

<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.4" class="ltx_p">For adaptation at test time, we investigate the effect of varying the number of retrieved image-question pairs from the target dataset for constructing the retrieval prompts in Figure <a href="#S5.F3" title="Figure 3 ‣ 5.2 Retrieval Sets for In-context Prediction ‣ 5 Results and Analysis ‣ Multimodal Prompt Retrieval for Generative Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. Regardless of the number of pairs retrieved, the overall target accuracy of MPR<math id="S5.SS3.p1.1.m1.1" class="ltx_Math" alttext="{}_{\text{gen}}\ " display="inline"><semantics id="S5.SS3.p1.1.m1.1a"><msub id="S5.SS3.p1.1.m1.1.1" xref="S5.SS3.p1.1.m1.1.1.cmml"><mi id="S5.SS3.p1.1.m1.1.1a" xref="S5.SS3.p1.1.m1.1.1.cmml"></mi><mtext id="S5.SS3.p1.1.m1.1.1.1" xref="S5.SS3.p1.1.m1.1.1.1a.cmml">gen</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.1.m1.1b"><apply id="S5.SS3.p1.1.m1.1.1.cmml" xref="S5.SS3.p1.1.m1.1.1"><ci id="S5.SS3.p1.1.m1.1.1.1a.cmml" xref="S5.SS3.p1.1.m1.1.1.1"><mtext mathsize="70%" id="S5.SS3.p1.1.m1.1.1.1.cmml" xref="S5.SS3.p1.1.m1.1.1.1">gen</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.1.m1.1c">{}_{\text{gen}}\ </annotation></semantics></math>is always above the none-retrieval baseline (i.e., zero-shot). We hypothesize that accuracy peaks when <math id="S5.SS3.p1.2.m2.1" class="ltx_Math" alttext="k=1" display="inline"><semantics id="S5.SS3.p1.2.m2.1a"><mrow id="S5.SS3.p1.2.m2.1.1" xref="S5.SS3.p1.2.m2.1.1.cmml"><mi id="S5.SS3.p1.2.m2.1.1.2" xref="S5.SS3.p1.2.m2.1.1.2.cmml">k</mi><mo id="S5.SS3.p1.2.m2.1.1.1" xref="S5.SS3.p1.2.m2.1.1.1.cmml">=</mo><mn id="S5.SS3.p1.2.m2.1.1.3" xref="S5.SS3.p1.2.m2.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.2.m2.1b"><apply id="S5.SS3.p1.2.m2.1.1.cmml" xref="S5.SS3.p1.2.m2.1.1"><eq id="S5.SS3.p1.2.m2.1.1.1.cmml" xref="S5.SS3.p1.2.m2.1.1.1"></eq><ci id="S5.SS3.p1.2.m2.1.1.2.cmml" xref="S5.SS3.p1.2.m2.1.1.2">𝑘</ci><cn type="integer" id="S5.SS3.p1.2.m2.1.1.3.cmml" xref="S5.SS3.p1.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.2.m2.1c">k=1</annotation></semantics></math> and stabilizes as <math id="S5.SS3.p1.3.m3.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S5.SS3.p1.3.m3.1a"><mi id="S5.SS3.p1.3.m3.1.1" xref="S5.SS3.p1.3.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.3.m3.1b"><ci id="S5.SS3.p1.3.m3.1.1.cmml" xref="S5.SS3.p1.3.m3.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.3.m3.1c">k</annotation></semantics></math> increases due to the small dataset size. MPR<math id="S5.SS3.p1.4.m4.1" class="ltx_Math" alttext="{}_{\text{gen}}\ " display="inline"><semantics id="S5.SS3.p1.4.m4.1a"><msub id="S5.SS3.p1.4.m4.1.1" xref="S5.SS3.p1.4.m4.1.1.cmml"><mi id="S5.SS3.p1.4.m4.1.1a" xref="S5.SS3.p1.4.m4.1.1.cmml"></mi><mtext id="S5.SS3.p1.4.m4.1.1.1" xref="S5.SS3.p1.4.m4.1.1.1a.cmml">gen</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.4.m4.1b"><apply id="S5.SS3.p1.4.m4.1.1.cmml" xref="S5.SS3.p1.4.m4.1.1"><ci id="S5.SS3.p1.4.m4.1.1.1a.cmml" xref="S5.SS3.p1.4.m4.1.1.1"><mtext mathsize="70%" id="S5.SS3.p1.4.m4.1.1.1.cmml" xref="S5.SS3.p1.4.m4.1.1.1">gen</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.4.m4.1c">{}_{\text{gen}}\ </annotation></semantics></math>outperforms a purely nearest neighbor-based approach when testing on the VQA-RAD dataset. However, on a syntactically simpler dataset (i.e., SLAKE), we also find that a nearest neighbor-based classifier can achieve higher accuracy than our model.</p>
</div>
</section>
<section id="S5.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4 </span>In-context Prediction vs Finetuning</h3>

<div id="S5.SS4.p1" class="ltx_para">
<p id="S5.SS4.p1.1" class="ltx_p">While further finetuning neural models on the target dataset often successfully learns to adapt to the new distribution, this technique often results in catastrophic forgetting <cite class="ltx_cite ltx_citemacro_cite">Thompson et al. (<a href="#bib.bib40" title="" class="ltx_ref">2019</a>)</cite>. Figure <a href="#S5.F4" title="Figure 4 ‣ 5.4 In-context Prediction vs Finetuning ‣ 5 Results and Analysis ‣ Multimodal Prompt Retrieval for Generative Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows our experiments with further finetuning a source-trained model on a target dataset. First, we initialize three models with a MPR<math id="S5.SS4.p1.1.m1.1" class="ltx_Math" alttext="{}_{\text{gen\_PM}}\ " display="inline"><semantics id="S5.SS4.p1.1.m1.1a"><msub id="S5.SS4.p1.1.m1.1.1" xref="S5.SS4.p1.1.m1.1.1.cmml"><mi id="S5.SS4.p1.1.m1.1.1a" xref="S5.SS4.p1.1.m1.1.1.cmml"></mi><mtext id="S5.SS4.p1.1.m1.1.1.1" xref="S5.SS4.p1.1.m1.1.1.1a.cmml">gen_PM</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.SS4.p1.1.m1.1b"><apply id="S5.SS4.p1.1.m1.1.1.cmml" xref="S5.SS4.p1.1.m1.1.1"><ci id="S5.SS4.p1.1.m1.1.1.1a.cmml" xref="S5.SS4.p1.1.m1.1.1.1"><mtext mathsize="70%" id="S5.SS4.p1.1.m1.1.1.1.cmml" xref="S5.SS4.p1.1.m1.1.1.1">gen_PM</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p1.1.m1.1c">{}_{\text{gen\_PM}}\ </annotation></semantics></math>checkpoint trained on SLAKE and adapt them to VQA-RAD. The first model is frozen, only using in-context prediction with retrieved target data (green). Another model is further finetuned on the target data without in-context prediction (red). The last model uses fine-tuning first and then does in-context predictions with retrieval (blue).</p>
</div>
<div id="S5.SS4.p2" class="ltx_para">
<p id="S5.SS4.p2.1" class="ltx_p">Several findings can be observed. First, we find that in-context prediction with MPR<math id="S5.SS4.p2.1.m1.1" class="ltx_Math" alttext="{}_{\text{gen\_PM}}\ " display="inline"><semantics id="S5.SS4.p2.1.m1.1a"><msub id="S5.SS4.p2.1.m1.1.1" xref="S5.SS4.p2.1.m1.1.1.cmml"><mi id="S5.SS4.p2.1.m1.1.1a" xref="S5.SS4.p2.1.m1.1.1.cmml"></mi><mtext id="S5.SS4.p2.1.m1.1.1.1" xref="S5.SS4.p2.1.m1.1.1.1a.cmml">gen_PM</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.SS4.p2.1.m1.1b"><apply id="S5.SS4.p2.1.m1.1.1.cmml" xref="S5.SS4.p2.1.m1.1.1"><ci id="S5.SS4.p2.1.m1.1.1.1a.cmml" xref="S5.SS4.p2.1.m1.1.1.1"><mtext mathsize="70%" id="S5.SS4.p2.1.m1.1.1.1.cmml" xref="S5.SS4.p2.1.m1.1.1.1">gen_PM</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p2.1.m1.1c">{}_{\text{gen\_PM}}\ </annotation></semantics></math>can mitigate the forgetting issue and improve cross-dataset adaptation. Second, when target data is scarce, in-context prediction outperforms further finetuning. Although the finetuned model achieved higher test accuracy when using all the target data, it suffered significant performance loss in its original domain. Lastly, combining in-context prediction with further finetuning eliminates most of this forgetting with minimal target domain performance loss.</p>
</div>
<figure id="S5.F4" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2306.17675/assets/x5.png" id="S5.F4.g1" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="207" height="115" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2306.17675/assets/x6.png" id="S5.F4.g2" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="207" height="115" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>We vary the finetuning dataset size and observe the accuracy of finetuning compared to in-context prediction. All models start from a MPR<math id="S5.F4.2.m1.1" class="ltx_Math" alttext="{}_{\text{gen\_PM}}\ " display="inline"><semantics id="S5.F4.2.m1.1b"><msub id="S5.F4.2.m1.1.1" xref="S5.F4.2.m1.1.1.cmml"><mi id="S5.F4.2.m1.1.1b" xref="S5.F4.2.m1.1.1.cmml"></mi><mtext id="S5.F4.2.m1.1.1.1" xref="S5.F4.2.m1.1.1.1a.cmml">gen_PM</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.F4.2.m1.1c"><apply id="S5.F4.2.m1.1.1.cmml" xref="S5.F4.2.m1.1.1"><ci id="S5.F4.2.m1.1.1.1a.cmml" xref="S5.F4.2.m1.1.1.1"><mtext mathsize="70%" id="S5.F4.2.m1.1.1.1.cmml" xref="S5.F4.2.m1.1.1.1">gen_PM</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F4.2.m1.1d">{}_{\text{gen\_PM}}\ </annotation></semantics></math>checkpoint and are either further finetuned (red + blue) or kept the same (green). </figcaption>
</figure>
<figure id="S5.T3" class="ltx_table">
<div id="S5.T3.10" class="ltx_inline-block ltx_transformed_outer" style="width:433.6pt;height:181.8pt;vertical-align:-0.6pt;"><span class="ltx_transformed_inner" style="transform:translate(-127.8pt,53.4pt) scale(0.629168200138123,0.629168200138123) ;">
<table id="S5.T3.10.10" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S5.T3.10.10.11.1" class="ltx_tr">
<td id="S5.T3.10.10.11.1.1" class="ltx_td ltx_align_center ltx_border_tt ltx_border_t" rowspan="2"><span id="S5.T3.10.10.11.1.1.1" class="ltx_text">Context</span></td>
<td id="S5.T3.10.10.11.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_t" rowspan="2"><span id="S5.T3.10.10.11.1.2.1" class="ltx_text">Method</span></td>
<td id="S5.T3.10.10.11.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_t" colspan="3">SLAKE</td>
<td id="S5.T3.10.10.11.1.4" class="ltx_td ltx_align_center ltx_border_tt ltx_border_t" colspan="3">VQA-RAD</td>
</tr>
<tr id="S5.T3.10.10.12.2" class="ltx_tr">
<td id="S5.T3.10.10.12.2.1" class="ltx_td ltx_align_center">Open</td>
<td id="S5.T3.10.10.12.2.2" class="ltx_td ltx_align_center">Closed</td>
<td id="S5.T3.10.10.12.2.3" class="ltx_td ltx_align_center ltx_border_r">Overall</td>
<td id="S5.T3.10.10.12.2.4" class="ltx_td ltx_align_center">Open</td>
<td id="S5.T3.10.10.12.2.5" class="ltx_td ltx_align_center">Closed</td>
<td id="S5.T3.10.10.12.2.6" class="ltx_td ltx_align_center">Overall</td>
</tr>
<tr id="S5.T3.1.1.1" class="ltx_tr">
<td id="S5.T3.1.1.1.2" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S5.T3.1.1.1.2.1" class="ltx_text">Question Only</span></td>
<td id="S5.T3.1.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">MPR<math id="S5.T3.1.1.1.1.m1.1" class="ltx_Math" alttext="{}_{\text{gen}}\ " display="inline"><semantics id="S5.T3.1.1.1.1.m1.1a"><msub id="S5.T3.1.1.1.1.m1.1.1" xref="S5.T3.1.1.1.1.m1.1.1.cmml"><mi id="S5.T3.1.1.1.1.m1.1.1a" xref="S5.T3.1.1.1.1.m1.1.1.cmml"></mi><mtext id="S5.T3.1.1.1.1.m1.1.1.1" xref="S5.T3.1.1.1.1.m1.1.1.1a.cmml">gen</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.T3.1.1.1.1.m1.1b"><apply id="S5.T3.1.1.1.1.m1.1.1.cmml" xref="S5.T3.1.1.1.1.m1.1.1"><ci id="S5.T3.1.1.1.1.m1.1.1.1a.cmml" xref="S5.T3.1.1.1.1.m1.1.1.1"><mtext mathsize="70%" id="S5.T3.1.1.1.1.m1.1.1.1.cmml" xref="S5.T3.1.1.1.1.m1.1.1.1">gen</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.1.1.1.1.m1.1c">{}_{\text{gen}}\ </annotation></semantics></math>
</td>
<td id="S5.T3.1.1.1.3" class="ltx_td ltx_align_center ltx_border_t">45.6</td>
<td id="S5.T3.1.1.1.4" class="ltx_td ltx_align_center ltx_border_t">68.3</td>
<td id="S5.T3.1.1.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">54.9</td>
<td id="S5.T3.1.1.1.6" class="ltx_td ltx_align_center ltx_border_t">22.5</td>
<td id="S5.T3.1.1.1.7" class="ltx_td ltx_align_center ltx_border_t">63.5</td>
<td id="S5.T3.1.1.1.8" class="ltx_td ltx_align_center ltx_border_t">50.3</td>
</tr>
<tr id="S5.T3.2.2.2" class="ltx_tr">
<td id="S5.T3.2.2.2.1" class="ltx_td ltx_align_center ltx_border_r">MPR<math id="S5.T3.2.2.2.1.m1.1" class="ltx_Math" alttext="{}_{\text{disc}}" display="inline"><semantics id="S5.T3.2.2.2.1.m1.1a"><msub id="S5.T3.2.2.2.1.m1.1.1" xref="S5.T3.2.2.2.1.m1.1.1.cmml"><mi id="S5.T3.2.2.2.1.m1.1.1a" xref="S5.T3.2.2.2.1.m1.1.1.cmml"></mi><mtext id="S5.T3.2.2.2.1.m1.1.1.1" xref="S5.T3.2.2.2.1.m1.1.1.1a.cmml">disc</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.T3.2.2.2.1.m1.1b"><apply id="S5.T3.2.2.2.1.m1.1.1.cmml" xref="S5.T3.2.2.2.1.m1.1.1"><ci id="S5.T3.2.2.2.1.m1.1.1.1a.cmml" xref="S5.T3.2.2.2.1.m1.1.1.1"><mtext mathsize="70%" id="S5.T3.2.2.2.1.m1.1.1.1.cmml" xref="S5.T3.2.2.2.1.m1.1.1.1">disc</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.2.2.2.1.m1.1c">{}_{\text{disc}}</annotation></semantics></math>
</td>
<td id="S5.T3.2.2.2.2" class="ltx_td ltx_align_center">48.5</td>
<td id="S5.T3.2.2.2.3" class="ltx_td ltx_align_center">66.6</td>
<td id="S5.T3.2.2.2.4" class="ltx_td ltx_align_center ltx_border_r">55.6</td>
<td id="S5.T3.2.2.2.5" class="ltx_td ltx_align_center">38.5</td>
<td id="S5.T3.2.2.2.6" class="ltx_td ltx_align_center">72.6</td>
<td id="S5.T3.2.2.2.7" class="ltx_td ltx_align_center">59.0</td>
</tr>
<tr id="S5.T3.3.3.3" class="ltx_tr">
<td id="S5.T3.3.3.3.2" class="ltx_td ltx_align_center ltx_border_t" rowspan="8"><span id="S5.T3.3.3.3.2.1" class="ltx_text">Image and Question</span></td>
<td id="S5.T3.3.3.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">MPR<math id="S5.T3.3.3.3.1.m1.1" class="ltx_Math" alttext="{}_{\text{gen}}\ " display="inline"><semantics id="S5.T3.3.3.3.1.m1.1a"><msub id="S5.T3.3.3.3.1.m1.1.1" xref="S5.T3.3.3.3.1.m1.1.1.cmml"><mi id="S5.T3.3.3.3.1.m1.1.1a" xref="S5.T3.3.3.3.1.m1.1.1.cmml"></mi><mtext id="S5.T3.3.3.3.1.m1.1.1.1" xref="S5.T3.3.3.3.1.m1.1.1.1a.cmml">gen</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.T3.3.3.3.1.m1.1b"><apply id="S5.T3.3.3.3.1.m1.1.1.cmml" xref="S5.T3.3.3.3.1.m1.1.1"><ci id="S5.T3.3.3.3.1.m1.1.1.1a.cmml" xref="S5.T3.3.3.3.1.m1.1.1.1"><mtext mathsize="70%" id="S5.T3.3.3.3.1.m1.1.1.1.cmml" xref="S5.T3.3.3.3.1.m1.1.1.1">gen</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.3.3.3.1.m1.1c">{}_{\text{gen}}\ </annotation></semantics></math>
</td>
<td id="S5.T3.3.3.3.3" class="ltx_td ltx_align_center ltx_border_t">71.5</td>
<td id="S5.T3.3.3.3.4" class="ltx_td ltx_align_center ltx_border_t">76.7</td>
<td id="S5.T3.3.3.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">73.5</td>
<td id="S5.T3.3.3.3.6" class="ltx_td ltx_align_center ltx_border_t">57.7</td>
<td id="S5.T3.3.3.3.7" class="ltx_td ltx_align_center ltx_border_t">77.6</td>
<td id="S5.T3.3.3.3.8" class="ltx_td ltx_align_center ltx_border_t">69.7</td>
</tr>
<tr id="S5.T3.4.4.4" class="ltx_tr">
<td id="S5.T3.4.4.4.1" class="ltx_td ltx_align_center ltx_border_r">MPR<math id="S5.T3.4.4.4.1.m1.1" class="ltx_Math" alttext="{}_{\text{gen\_PM}}\ " display="inline"><semantics id="S5.T3.4.4.4.1.m1.1a"><msub id="S5.T3.4.4.4.1.m1.1.1" xref="S5.T3.4.4.4.1.m1.1.1.cmml"><mi id="S5.T3.4.4.4.1.m1.1.1a" xref="S5.T3.4.4.4.1.m1.1.1.cmml"></mi><mtext id="S5.T3.4.4.4.1.m1.1.1.1" xref="S5.T3.4.4.4.1.m1.1.1.1a.cmml">gen_PM</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.T3.4.4.4.1.m1.1b"><apply id="S5.T3.4.4.4.1.m1.1.1.cmml" xref="S5.T3.4.4.4.1.m1.1.1"><ci id="S5.T3.4.4.4.1.m1.1.1.1a.cmml" xref="S5.T3.4.4.4.1.m1.1.1.1"><mtext mathsize="70%" id="S5.T3.4.4.4.1.m1.1.1.1.cmml" xref="S5.T3.4.4.4.1.m1.1.1.1">gen_PM</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.4.4.4.1.m1.1c">{}_{\text{gen\_PM}}\ </annotation></semantics></math>
</td>
<td id="S5.T3.4.4.4.2" class="ltx_td ltx_align_center">74.1</td>
<td id="S5.T3.4.4.4.3" class="ltx_td ltx_align_center">82.2</td>
<td id="S5.T3.4.4.4.4" class="ltx_td ltx_align_center ltx_border_r">77.3</td>
<td id="S5.T3.4.4.4.5" class="ltx_td ltx_align_center">62.6</td>
<td id="S5.T3.4.4.4.6" class="ltx_td ltx_align_center">78.3</td>
<td id="S5.T3.4.4.4.7" class="ltx_td ltx_align_center">72.1</td>
</tr>
<tr id="S5.T3.5.5.5" class="ltx_tr">
<td id="S5.T3.5.5.5.1" class="ltx_td ltx_align_center ltx_border_r">MPR<math id="S5.T3.5.5.5.1.m1.1" class="ltx_Math" alttext="{}_{\text{disc}}" display="inline"><semantics id="S5.T3.5.5.5.1.m1.1a"><msub id="S5.T3.5.5.5.1.m1.1.1" xref="S5.T3.5.5.5.1.m1.1.1.cmml"><mi id="S5.T3.5.5.5.1.m1.1.1a" xref="S5.T3.5.5.5.1.m1.1.1.cmml"></mi><mtext id="S5.T3.5.5.5.1.m1.1.1.1" xref="S5.T3.5.5.5.1.m1.1.1.1a.cmml">disc</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.T3.5.5.5.1.m1.1b"><apply id="S5.T3.5.5.5.1.m1.1.1.cmml" xref="S5.T3.5.5.5.1.m1.1.1"><ci id="S5.T3.5.5.5.1.m1.1.1.1a.cmml" xref="S5.T3.5.5.5.1.m1.1.1.1"><mtext mathsize="70%" id="S5.T3.5.5.5.1.m1.1.1.1.cmml" xref="S5.T3.5.5.5.1.m1.1.1.1">disc</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.5.5.5.1.m1.1c">{}_{\text{disc}}</annotation></semantics></math>
</td>
<td id="S5.T3.5.5.5.2" class="ltx_td ltx_align_center">78.3</td>
<td id="S5.T3.5.5.5.3" class="ltx_td ltx_align_center"><span id="S5.T3.5.5.5.3.1" class="ltx_text ltx_font_bold">84.9</span></td>
<td id="S5.T3.5.5.5.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T3.5.5.5.4.1" class="ltx_text ltx_font_bold">80.9</span></td>
<td id="S5.T3.5.5.5.5" class="ltx_td ltx_align_center">57.7</td>
<td id="S5.T3.5.5.5.6" class="ltx_td ltx_align_center">76.2</td>
<td id="S5.T3.5.5.5.7" class="ltx_td ltx_align_center">68.8</td>
</tr>
<tr id="S5.T3.6.6.6" class="ltx_tr">
<td id="S5.T3.6.6.6.1" class="ltx_td ltx_align_center ltx_border_r">MPR<math id="S5.T3.6.6.6.1.m1.1" class="ltx_Math" alttext="{}_{\text{disc\_BAN}}\ " display="inline"><semantics id="S5.T3.6.6.6.1.m1.1a"><msub id="S5.T3.6.6.6.1.m1.1.1" xref="S5.T3.6.6.6.1.m1.1.1.cmml"><mi id="S5.T3.6.6.6.1.m1.1.1a" xref="S5.T3.6.6.6.1.m1.1.1.cmml"></mi><mtext id="S5.T3.6.6.6.1.m1.1.1.1" xref="S5.T3.6.6.6.1.m1.1.1.1a.cmml">disc_BAN</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.T3.6.6.6.1.m1.1b"><apply id="S5.T3.6.6.6.1.m1.1.1.cmml" xref="S5.T3.6.6.6.1.m1.1.1"><ci id="S5.T3.6.6.6.1.m1.1.1.1a.cmml" xref="S5.T3.6.6.6.1.m1.1.1.1"><mtext mathsize="70%" id="S5.T3.6.6.6.1.m1.1.1.1.cmml" xref="S5.T3.6.6.6.1.m1.1.1.1">disc_BAN</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.6.6.6.1.m1.1c">{}_{\text{disc\_BAN}}\ </annotation></semantics></math>
</td>
<td id="S5.T3.6.6.6.2" class="ltx_td ltx_align_center">76.0</td>
<td id="S5.T3.6.6.6.3" class="ltx_td ltx_align_center">79.8</td>
<td id="S5.T3.6.6.6.4" class="ltx_td ltx_align_center ltx_border_r">77.5</td>
<td id="S5.T3.6.6.6.5" class="ltx_td ltx_align_center">60.4</td>
<td id="S5.T3.6.6.6.6" class="ltx_td ltx_align_center"><span id="S5.T3.6.6.6.6.1" class="ltx_text ltx_font_bold">81.6</span></td>
<td id="S5.T3.6.6.6.7" class="ltx_td ltx_align_center"><span id="S5.T3.6.6.6.7.1" class="ltx_text ltx_font_bold">73.2</span></td>
</tr>
<tr id="S5.T3.10.10.13.3" class="ltx_tr">
<td id="S5.T3.10.10.13.3.1" class="ltx_td ltx_align_center ltx_border_r">PubMedCLIP <cite class="ltx_cite ltx_citemacro_cite">Eslami et al. (<a href="#bib.bib6" title="" class="ltx_ref">2021</a>)</cite>
</td>
<td id="S5.T3.10.10.13.3.2" class="ltx_td ltx_align_center"><span id="S5.T3.10.10.13.3.2.1" class="ltx_text ltx_font_bold">78.4</span></td>
<td id="S5.T3.10.10.13.3.3" class="ltx_td ltx_align_center">82.5</td>
<td id="S5.T3.10.10.13.3.4" class="ltx_td ltx_align_center ltx_border_r">80.1</td>
<td id="S5.T3.10.10.13.3.5" class="ltx_td ltx_align_center">60.1</td>
<td id="S5.T3.10.10.13.3.6" class="ltx_td ltx_align_center">80.0</td>
<td id="S5.T3.10.10.13.3.7" class="ltx_td ltx_align_center">72.1</td>
</tr>
<tr id="S5.T3.10.10.14.4" class="ltx_tr">
<td id="S5.T3.10.10.14.4.1" class="ltx_td ltx_align_center ltx_border_r">MMBert <cite class="ltx_cite ltx_citemacro_cite">Khare et al. (<a href="#bib.bib14" title="" class="ltx_ref">2021</a>)</cite>
</td>
<td id="S5.T3.10.10.14.4.2" class="ltx_td ltx_align_center">-</td>
<td id="S5.T3.10.10.14.4.3" class="ltx_td ltx_align_center">-</td>
<td id="S5.T3.10.10.14.4.4" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S5.T3.10.10.14.4.5" class="ltx_td ltx_align_center"><span id="S5.T3.10.10.14.4.5.1" class="ltx_text ltx_font_bold">63.1</span></td>
<td id="S5.T3.10.10.14.4.6" class="ltx_td ltx_align_center">77.9</td>
<td id="S5.T3.10.10.14.4.7" class="ltx_td ltx_align_center">72.0</td>
</tr>
<tr id="S5.T3.10.10.15.5" class="ltx_tr">
<td id="S5.T3.10.10.15.5.1" class="ltx_td ltx_align_center ltx_border_r">QCR <cite class="ltx_cite ltx_citemacro_cite">Zhan et al. (<a href="#bib.bib43" title="" class="ltx_ref">2020</a>)</cite>
</td>
<td id="S5.T3.10.10.15.5.2" class="ltx_td ltx_align_center">-</td>
<td id="S5.T3.10.10.15.5.3" class="ltx_td ltx_align_center">-</td>
<td id="S5.T3.10.10.15.5.4" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S5.T3.10.10.15.5.5" class="ltx_td ltx_align_center">60.0</td>
<td id="S5.T3.10.10.15.5.6" class="ltx_td ltx_align_center">79.3</td>
<td id="S5.T3.10.10.15.5.7" class="ltx_td ltx_align_center">71.6</td>
</tr>
<tr id="S5.T3.10.10.16.6" class="ltx_tr">
<td id="S5.T3.10.10.16.6.1" class="ltx_td ltx_align_center ltx_border_r">MEVF <cite class="ltx_cite ltx_citemacro_cite">Nguyen et al. (<a href="#bib.bib30" title="" class="ltx_ref">2019</a>)</cite>
</td>
<td id="S5.T3.10.10.16.6.2" class="ltx_td ltx_align_center">-</td>
<td id="S5.T3.10.10.16.6.3" class="ltx_td ltx_align_center">-</td>
<td id="S5.T3.10.10.16.6.4" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S5.T3.10.10.16.6.5" class="ltx_td ltx_align_center">43.9</td>
<td id="S5.T3.10.10.16.6.6" class="ltx_td ltx_align_center">75.1</td>
<td id="S5.T3.10.10.16.6.7" class="ltx_td ltx_align_center">62.7</td>
</tr>
<tr id="S5.T3.7.7.7" class="ltx_tr">
<td id="S5.T3.7.7.7.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" rowspan="4"><span id="S5.T3.7.7.7.2.1" class="ltx_text">Image, Question, and Retrieval</span></td>
<td id="S5.T3.7.7.7.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">MPR<math id="S5.T3.7.7.7.1.m1.1" class="ltx_Math" alttext="{}_{\text{gen}}\ " display="inline"><semantics id="S5.T3.7.7.7.1.m1.1a"><msub id="S5.T3.7.7.7.1.m1.1.1" xref="S5.T3.7.7.7.1.m1.1.1.cmml"><mi id="S5.T3.7.7.7.1.m1.1.1a" xref="S5.T3.7.7.7.1.m1.1.1.cmml"></mi><mtext id="S5.T3.7.7.7.1.m1.1.1.1" xref="S5.T3.7.7.7.1.m1.1.1.1a.cmml">gen</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.T3.7.7.7.1.m1.1b"><apply id="S5.T3.7.7.7.1.m1.1.1.cmml" xref="S5.T3.7.7.7.1.m1.1.1"><ci id="S5.T3.7.7.7.1.m1.1.1.1a.cmml" xref="S5.T3.7.7.7.1.m1.1.1.1"><mtext mathsize="70%" id="S5.T3.7.7.7.1.m1.1.1.1.cmml" xref="S5.T3.7.7.7.1.m1.1.1.1">gen</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.7.7.7.1.m1.1c">{}_{\text{gen}}\ </annotation></semantics></math>
</td>
<td id="S5.T3.7.7.7.3" class="ltx_td ltx_align_center ltx_border_t">73.0</td>
<td id="S5.T3.7.7.7.4" class="ltx_td ltx_align_center ltx_border_t">79.8</td>
<td id="S5.T3.7.7.7.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">75.7</td>
<td id="S5.T3.7.7.7.6" class="ltx_td ltx_align_center ltx_border_t">57.7</td>
<td id="S5.T3.7.7.7.7" class="ltx_td ltx_align_center ltx_border_t">77.3</td>
<td id="S5.T3.7.7.7.8" class="ltx_td ltx_align_center ltx_border_t">69.5</td>
</tr>
<tr id="S5.T3.8.8.8" class="ltx_tr">
<td id="S5.T3.8.8.8.1" class="ltx_td ltx_align_center ltx_border_r">MPR<math id="S5.T3.8.8.8.1.m1.1" class="ltx_Math" alttext="{}_{\text{gen\_PM}}\ " display="inline"><semantics id="S5.T3.8.8.8.1.m1.1a"><msub id="S5.T3.8.8.8.1.m1.1.1" xref="S5.T3.8.8.8.1.m1.1.1.cmml"><mi id="S5.T3.8.8.8.1.m1.1.1a" xref="S5.T3.8.8.8.1.m1.1.1.cmml"></mi><mtext id="S5.T3.8.8.8.1.m1.1.1.1" xref="S5.T3.8.8.8.1.m1.1.1.1a.cmml">gen_PM</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.T3.8.8.8.1.m1.1b"><apply id="S5.T3.8.8.8.1.m1.1.1.cmml" xref="S5.T3.8.8.8.1.m1.1.1"><ci id="S5.T3.8.8.8.1.m1.1.1.1a.cmml" xref="S5.T3.8.8.8.1.m1.1.1.1"><mtext mathsize="70%" id="S5.T3.8.8.8.1.m1.1.1.1.cmml" xref="S5.T3.8.8.8.1.m1.1.1.1">gen_PM</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.8.8.8.1.m1.1c">{}_{\text{gen\_PM}}\ </annotation></semantics></math>
</td>
<td id="S5.T3.8.8.8.2" class="ltx_td ltx_align_center">73.5</td>
<td id="S5.T3.8.8.8.3" class="ltx_td ltx_align_center">80.5</td>
<td id="S5.T3.8.8.8.4" class="ltx_td ltx_align_center ltx_border_r">76.2</td>
<td id="S5.T3.8.8.8.5" class="ltx_td ltx_align_center">60.4</td>
<td id="S5.T3.8.8.8.6" class="ltx_td ltx_align_center">80.9</td>
<td id="S5.T3.8.8.8.7" class="ltx_td ltx_align_center">72.8</td>
</tr>
<tr id="S5.T3.9.9.9" class="ltx_tr">
<td id="S5.T3.9.9.9.1" class="ltx_td ltx_align_center ltx_border_r">MPR<math id="S5.T3.9.9.9.1.m1.1" class="ltx_Math" alttext="{}_{\text{disc}}" display="inline"><semantics id="S5.T3.9.9.9.1.m1.1a"><msub id="S5.T3.9.9.9.1.m1.1.1" xref="S5.T3.9.9.9.1.m1.1.1.cmml"><mi id="S5.T3.9.9.9.1.m1.1.1a" xref="S5.T3.9.9.9.1.m1.1.1.cmml"></mi><mtext id="S5.T3.9.9.9.1.m1.1.1.1" xref="S5.T3.9.9.9.1.m1.1.1.1a.cmml">disc</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.T3.9.9.9.1.m1.1b"><apply id="S5.T3.9.9.9.1.m1.1.1.cmml" xref="S5.T3.9.9.9.1.m1.1.1"><ci id="S5.T3.9.9.9.1.m1.1.1.1a.cmml" xref="S5.T3.9.9.9.1.m1.1.1.1"><mtext mathsize="70%" id="S5.T3.9.9.9.1.m1.1.1.1.cmml" xref="S5.T3.9.9.9.1.m1.1.1.1">disc</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.9.9.9.1.m1.1c">{}_{\text{disc}}</annotation></semantics></math>
</td>
<td id="S5.T3.9.9.9.2" class="ltx_td ltx_align_center">75.0</td>
<td id="S5.T3.9.9.9.3" class="ltx_td ltx_align_center">81.0</td>
<td id="S5.T3.9.9.9.4" class="ltx_td ltx_align_center ltx_border_r">77.4</td>
<td id="S5.T3.9.9.9.5" class="ltx_td ltx_align_center">51.6</td>
<td id="S5.T3.9.9.9.6" class="ltx_td ltx_align_center">78.0</td>
<td id="S5.T3.9.9.9.7" class="ltx_td ltx_align_center">67.5</td>
</tr>
<tr id="S5.T3.10.10.10" class="ltx_tr">
<td id="S5.T3.10.10.10.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">MPR<math id="S5.T3.10.10.10.1.m1.1" class="ltx_Math" alttext="{}_{\text{disc\_BAN}}\ " display="inline"><semantics id="S5.T3.10.10.10.1.m1.1a"><msub id="S5.T3.10.10.10.1.m1.1.1" xref="S5.T3.10.10.10.1.m1.1.1.cmml"><mi id="S5.T3.10.10.10.1.m1.1.1a" xref="S5.T3.10.10.10.1.m1.1.1.cmml"></mi><mtext id="S5.T3.10.10.10.1.m1.1.1.1" xref="S5.T3.10.10.10.1.m1.1.1.1a.cmml">disc_BAN</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.T3.10.10.10.1.m1.1b"><apply id="S5.T3.10.10.10.1.m1.1.1.cmml" xref="S5.T3.10.10.10.1.m1.1.1"><ci id="S5.T3.10.10.10.1.m1.1.1.1a.cmml" xref="S5.T3.10.10.10.1.m1.1.1.1"><mtext mathsize="70%" id="S5.T3.10.10.10.1.m1.1.1.1.cmml" xref="S5.T3.10.10.10.1.m1.1.1.1">disc_BAN</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.10.10.10.1.m1.1c">{}_{\text{disc\_BAN}}\ </annotation></semantics></math>
</td>
<td id="S5.T3.10.10.10.2" class="ltx_td ltx_align_center ltx_border_bb">77.5</td>
<td id="S5.T3.10.10.10.3" class="ltx_td ltx_align_center ltx_border_bb">82.2</td>
<td id="S5.T3.10.10.10.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">79.4</td>
<td id="S5.T3.10.10.10.5" class="ltx_td ltx_align_center ltx_border_bb">62.6</td>
<td id="S5.T3.10.10.10.6" class="ltx_td ltx_align_center ltx_border_bb">80.1</td>
<td id="S5.T3.10.10.10.7" class="ltx_td ltx_align_center ltx_border_bb">73.2</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span>Performances of our prompting method with different levels of context provided to the model. In most cases, our model is competitive with state-of-the-art methods even in the generative based cases. Retrieval context is provided by querying for the 15 most relevant image-question pairs. Bold values indicate the maximum in each column.</figcaption>
</figure>
</section>
<section id="S5.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.5 </span>In-domain Evaluation</h3>

<section id="S5.SS5.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Overall Accuracy</h4>

<div id="S5.SS5.SSS0.Px1.p1" class="ltx_para">
<p id="S5.SS5.SSS0.Px1.p1.1" class="ltx_p">We also compare our proposed model with existing models for the in-domain setting on SLAKE and VQA-RAD. We highlight the overall, open, and closed test accuracy for each dataset. We also evaluate our method with three contexts to analyze the effect of each component of our prompting method in Table <a href="#S5.T3" title="Table 3 ‣ 5.4 In-context Prediction vs Finetuning ‣ 5 Results and Analysis ‣ Multimodal Prompt Retrieval for Generative Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<div id="S5.SS5.SSS0.Px1.p2" class="ltx_para">
<p id="S5.SS5.SSS0.Px1.p2.1" class="ltx_p">As expected, the model variants perform worse when we only provide questions as inputs. Under the same setting where both the question and image features are provided, our generative model is competitive with the state-of-the-art discriminative models. Besides, we also find that using an in-domain dataset for retrieval does not provide performance gains, indicating that models can easily fit a small in-domain dataset, and retrieving prompts from the same training set does not provide extra useful information.</p>
</div>
</section>
<section id="S5.SS5.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Finegrained Accuracy</h4>

<div id="S5.SS5.SSS0.Px2.p1" class="ltx_para">
<p id="S5.SS5.SSS0.Px2.p1.1" class="ltx_p">Figure <a href="#A3.F5" title="Figure 5 ‣ Appendix C Dataset Information ‣ Multimodal Prompt Retrieval for Generative Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> in Appendix also shows the in-domain performance of our model variants across different question types for both datasets. The results indicate that all models generally struggle with questions requiring more complex reasoning, such as Position, Abnormality, and Knowledge Graph (KG) questions.</p>
</div>
</section>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Related Work</h2>

<section id="S6.SS0.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Retrieval-Based VQA</h4>

<div id="S6.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S6.SS0.SSS0.Px1.p1.1" class="ltx_p">Retrieval-based methods typically combine parametric models with non-parametric external memory for prediction. This idea first surfaces in KNN-LMs <cite class="ltx_cite ltx_citemacro_cite">Khandelwal et al. (<a href="#bib.bib13" title="" class="ltx_ref">2020</a>)</cite>, which utilizes a static retrieval data store to help language models adapt rapidly to new domains without further training. <cite class="ltx_cite ltx_citemacro_citet">Guu et al. (<a href="#bib.bib10" title="" class="ltx_ref">2020</a>)</cite> extends this idea by introducing a parametric retriever that learns to attend to relevant documents during training. Recently, <cite class="ltx_cite ltx_citemacro_citet">Gao et al. (<a href="#bib.bib7" title="" class="ltx_ref">2022</a>)</cite> summarizes visual information into natural language to use as a query for dense passage retrieval. The retrieved passages allow for the VQA model to outperform existing works, especially on questions which require outside knowledge. <cite class="ltx_cite ltx_citemacro_citet">Lin and Byrne (<a href="#bib.bib22" title="" class="ltx_ref">2022</a>)</cite> consider training the retriever in an end-to-end manner similar to <cite class="ltx_cite ltx_citemacro_citet">Lewis et al. (<a href="#bib.bib20" title="" class="ltx_ref">2020</a>)</cite> and find that this results in higher answer quality and lower computational training cost.</p>
</div>
<div id="S6.SS0.SSS0.Px1.p2" class="ltx_para">
<p id="S6.SS0.SSS0.Px1.p2.1" class="ltx_p">Different from these methods, we propose to construct multimodal prompts from retrieval to perform zeroshot dataset adaptation. While dataset adaptation of VQA models has been investigated in <cite class="ltx_cite ltx_citemacro_citet">Agrawal et al. (<a href="#bib.bib1" title="" class="ltx_ref">2023</a>)</cite>, we focus on the effect of retrieval on generalization capability.</p>
</div>
</section>
<section id="S6.SS0.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Generative QA</h4>

<div id="S6.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S6.SS0.SSS0.Px2.p1.1" class="ltx_p">Generative QA models focus on predicting answers autoregressively based on the input question. In this setting, the model may either generate the response based solely on model parameters (closed book) <cite class="ltx_cite ltx_citemacro_cite">Khashabi et al. (<a href="#bib.bib15" title="" class="ltx_ref">2021</a>); Roberts et al. (<a href="#bib.bib35" title="" class="ltx_ref">2020</a>)</cite> or rely on additional retrieved contexts (open book) <cite class="ltx_cite ltx_citemacro_cite">Karpukhin et al. (<a href="#bib.bib12" title="" class="ltx_ref">2020</a>); Lewis et al. (<a href="#bib.bib20" title="" class="ltx_ref">2020</a>)</cite>. Our prompt construction method is inspired by the retrieval augmented generator (RAG) model <cite class="ltx_cite ltx_citemacro_cite">Lewis et al. (<a href="#bib.bib20" title="" class="ltx_ref">2020</a>)</cite>, which retrieves relevant documents to answer questions. Instead of retrieving documents exclusively, we identify suitable image-question pairs to perform VQA.</p>
</div>
</section>
<section id="S6.SS0.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">VQA</h4>

<div id="S6.SS0.SSS0.Px3.p1" class="ltx_para">
<p id="S6.SS0.SSS0.Px3.p1.1" class="ltx_p">First introduced by <cite class="ltx_cite ltx_citemacro_citet">Antol et al. (<a href="#bib.bib3" title="" class="ltx_ref">2015</a>)</cite>, most VQA systems learn a joint embedding space for images and text to answer questions <cite class="ltx_cite ltx_citemacro_cite">Malinowski et al. (<a href="#bib.bib26" title="" class="ltx_ref">2015</a>); Gao et al. (<a href="#bib.bib8" title="" class="ltx_ref">2015</a>)</cite>. These approaches combine image and text features through either bilinear pooling or attention-based mechanisms <cite class="ltx_cite ltx_citemacro_cite">Yang et al. (<a href="#bib.bib42" title="" class="ltx_ref">2016</a>); Lu et al. (<a href="#bib.bib25" title="" class="ltx_ref">2016</a>); Anderson et al. (<a href="#bib.bib2" title="" class="ltx_ref">2018</a>); Guo et al. (<a href="#bib.bib9" title="" class="ltx_ref">2021</a>)</cite>. To help models understand the relationships between objects in an image, graph convolutional neural networks were introduced for VQA <cite class="ltx_cite ltx_citemacro_cite">Norcliffe-Brown et al. (<a href="#bib.bib31" title="" class="ltx_ref">2018</a>); Li et al. (<a href="#bib.bib21" title="" class="ltx_ref">2019</a>)</cite>. Current methods often combine supplemental knowledge with fusion-based approaches to achieve state-of-the-art performance <cite class="ltx_cite ltx_citemacro_cite">Shevchenko et al. (<a href="#bib.bib37" title="" class="ltx_ref">2021</a>); Marino et al. (<a href="#bib.bib27" title="" class="ltx_ref">2021</a>); Wu et al. (<a href="#bib.bib41" title="" class="ltx_ref">2022</a>); Chen et al. (<a href="#bib.bib4" title="" class="ltx_ref">2022</a>)</cite>. We take a similar approach by using supplementary knowledge to construct context-aware prompts.</p>
</div>
</section>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusion</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">In this work, we propose a flexible prompt-based method for VQA in the medical domain. While our approach is designed for low-resource domains, the generative architecture of our model, in combination with a retrieval component, enables generalization to other fields. Our results are on par with state-of-the-art accuracies on the SLAKE and VQA-RAD datasets and show promising zero-shot and few-shot transfer results across different medical datasets. We hope these results can offer a baseline to compare with future work on knowledge-intensive and reasoning tasks.</p>
</div>
</section>
<section id="S8" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8 </span>Limitations</h2>

<div id="S8.p1" class="ltx_para">
<p id="S8.p1.1" class="ltx_p">When evaluating our model in a cross-dataset adaptation setting, our experiments indicate the importance of using a retrieval dataset. It is challenging to procure high-quality and volume retrieval datasets, especially in low-resource domains such as the medical field. Fortunately, the VQA-RAD and SLAKE datasets we evaluate on contain professionally annotated medical images. We also overcome the lack of data by creating a synthetic dataset from the medical ROCO image-captioning dataset.</p>
</div>
<div id="S8.p2" class="ltx_para">
<p id="S8.p2.1" class="ltx_p">Additionally, our model struggles with questions requiring multi-step reasoning, such as knowledge graph, abnormality, and position questions. Although performances in these question types are not far below the overall accuracy, future work may consider supplementary knowledge-based retrieval to assist in these challenging question types.</p>
</div>
</section>
<section id="S9" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">9 </span>Ethics Statement</h2>

<div id="S9.p1" class="ltx_para">
<p id="S9.p1.1" class="ltx_p">Although medical VQA provides exciting opportunities for future AI-assisted clinical diagnostic tools, there are several ethical challenges associated with these approaches.</p>
</div>
<section id="S9.SS0.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Patient Safety and Model Transparency</h4>

<div id="S9.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S9.SS0.SSS0.Px1.p1.1" class="ltx_p">Since the model decision process for deep learning models is difficult to understand, these models should only be used as an auxiliary tool. This obscure decision process is crucial to clarify in the medical domain, in which a poor diagnosis or choice of treatment can significantly affect patient lives. For example, medical experts found that cancer treatment recommendation software often gave unsafe or incorrect treatment advice in a recent study <cite class="ltx_cite ltx_citemacro_cite">Ross and Swetlitz (<a href="#bib.bib36" title="" class="ltx_ref">2018</a>)</cite>.</p>
</div>
</section>
<section id="S9.SS0.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Dataset Biases</h4>

<div id="S9.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S9.SS0.SSS0.Px2.p1.1" class="ltx_p">The fairness of medical AI systems depends on the distribution of people in its training dataset. To ensure that AI algorithms display fairness to all races, genders, and ethnic groups, practitioners should verify that the training dataset contains an equal representation of all groups. Before deploying our architecture or other deep learning-based models to a clinical setting, practitioners should ensure that their patient’s background is adequately represented in the training data.</p>
</div>
</section>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Agrawal et al. (2023)</span>
<span class="ltx_bibblock">
Aishwarya Agrawal, Ivana Kajić, Emanuele Bugliarello, Elnaz Davoodi, Anita
Gergely, Phil Blunsom, and Aida Nematzadeh. 2023.

</span>
<span class="ltx_bibblock">Rethinking evaluation practices in visual question answering: A case
study on out-of-distribution generalization.

</span>
<span class="ltx_bibblock">In <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2023 European Chapter of the Association
for Computational Linguistics (Findings)</em>.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Anderson et al. (2018)</span>
<span class="ltx_bibblock">
Peter Anderson, Xiaodong He, Chris Buehler, Damien Teney, Mark Johnson, Stephen
Gould, and Lei Zhang. 2018.

</span>
<span class="ltx_bibblock">Bottom-up and top-down attention for image captioning and visual
question answering.

</span>
<span class="ltx_bibblock">In <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE conference on computer vision and
pattern recognition</em>, pages 6077–6086.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Antol et al. (2015)</span>
<span class="ltx_bibblock">
Stanislaw Antol, Aishwarya Agrawal, Jiasen Lu, Margaret Mitchell, Dhruv Batra,
C Lawrence Zitnick, and Devi Parikh. 2015.

</span>
<span class="ltx_bibblock">Vqa: Visual question answering.

</span>
<span class="ltx_bibblock">In <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE international conference on computer
vision</em>, pages 2425–2433.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2022)</span>
<span class="ltx_bibblock">
Wenhu Chen, Hexiang Hu, Xi Chen, Pat Verga, and William W Cohen. 2022.

</span>
<span class="ltx_bibblock">Murag: Multimodal retrieval-augmented generator for open question
answering over images and text.

</span>
<span class="ltx_bibblock">In <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2022 Conference on Empirical Methods in
Natural Language Processing</em>.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dosovitskiy et al. (2021)</span>
<span class="ltx_bibblock">
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
Heigold, Sylvain Gelly, et al. 2021.

</span>
<span class="ltx_bibblock">An image is worth 16x16 words: Transformers for image recognition at
scale.

</span>
<span class="ltx_bibblock">In <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations</em>.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Eslami et al. (2021)</span>
<span class="ltx_bibblock">
Sedigheh Eslami, Gerard de Melo, and Christoph Meinel. 2021.

</span>
<span class="ltx_bibblock">Does clip benefit visual question answering in the medical domain as
much as it does in the general domain?

</span>
<span class="ltx_bibblock"><em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2112.13906</em>.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et al. (2022)</span>
<span class="ltx_bibblock">
Feng Gao, Qing Ping, Govind Thattai, Aishwarya Reganti, Ying Nian Wu, and Prem
Natarajan. 2022.

</span>
<span class="ltx_bibblock">Transform-retrieve-generate: Natural language-centric
outside-knowledge visual question answering.

</span>
<span class="ltx_bibblock">In <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition</em>, pages 5067–5077.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et al. (2015)</span>
<span class="ltx_bibblock">
Haoyuan Gao, Junhua Mao, Jie Zhou, Zhiheng Huang, Lei Wang, and Wei Xu. 2015.

</span>
<span class="ltx_bibblock">Are you talking to a machine? dataset and methods for multilingual
image question.

</span>
<span class="ltx_bibblock"><em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, 28.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guo et al. (2021)</span>
<span class="ltx_bibblock">
Dalu Guo, Chang Xu, and Dacheng Tao. 2021.

</span>
<span class="ltx_bibblock">Bilinear graph networks for visual question answering.

</span>
<span class="ltx_bibblock"><em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Neural Networks and Learning Systems</em>.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guu et al. (2020)</span>
<span class="ltx_bibblock">
Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, and Mingwei Chang. 2020.

</span>
<span class="ltx_bibblock">Retrieval augmented language model pre-training.

</span>
<span class="ltx_bibblock">In <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>, pages
3929–3938. PMLR.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hasan et al. (2018)</span>
<span class="ltx_bibblock">
Sadid A Hasan, Yuan Ling, Oladimeji Farri, Joey Liu, Henning Müller, and
Matthew P Lungren. 2018.

</span>
<span class="ltx_bibblock">Overview of imageclef 2018 medical domain visual question answering
task.

</span>
<span class="ltx_bibblock">In <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Conference and Labs of the Evaluation Forum (Working
Notes)</em>.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Karpukhin et al. (2020)</span>
<span class="ltx_bibblock">
Vladimir Karpukhin, Barlas Oğuz, Sewon Min, Patrick Lewis, Ledell Wu,
Sergey Edunov, Danqi Chen, and Wen-tau Yih. 2020.

</span>
<span class="ltx_bibblock">Dense passage retrieval for open-domain question answering.

</span>
<span class="ltx_bibblock">In <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020 Conference on Empirical Methods in
Natural Language Processing</em>.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Khandelwal et al. (2020)</span>
<span class="ltx_bibblock">
Urvashi Khandelwal, Omer Levy, Dan Jurafsky, Luke Zettlemoyer, and Mike Lewis.
2020.

</span>
<span class="ltx_bibblock">Generalization through memorization: Nearest neighbor language
models.

</span>
<span class="ltx_bibblock">In <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations</em>.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Khare et al. (2021)</span>
<span class="ltx_bibblock">
Yash Khare, Viraj Bagal, Minesh Mathew, Adithi Devi, U Deva Priyakumar, and
CV Jawahar. 2021.

</span>
<span class="ltx_bibblock">Mmbert: multimodal bert pretraining for improved medical vqa.

</span>
<span class="ltx_bibblock">In <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">2021 IEEE 18th International Symposium on Biomedical Imaging
(ISBI)</em>, pages 1033–1036. IEEE.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Khashabi et al. (2021)</span>
<span class="ltx_bibblock">
Daniel Khashabi, Sewon Min, Tushar Khot, Ashish Sabharwal, Oyvind Tafjord,
Peter Clark, and Hannaneh Hajishirzi. 2021.

</span>
<span class="ltx_bibblock">Unifiedqa: Crossing format boundaries with a single qa system.

</span>
<span class="ltx_bibblock">In <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021 Conference on Empirical Methods in
Natural Language Processing (Findings)</em>.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim et al. (2018)</span>
<span class="ltx_bibblock">
Jin-Hwa Kim, Jaehyun Jun, and Byoung-Tak Zhang. 2018.

</span>
<span class="ltx_bibblock">Bilinear attention networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, 31.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kovaleva et al. (2020)</span>
<span class="ltx_bibblock">
Olga Kovaleva, Chaitanya Shivade, Satyananda Kashyap, Karina Kanjaria, Joy Wu,
Deddeh Ballah, Adam Coy, Alexandros Karargyris, Yufan Guo, David Beymer
Beymer, Anna Rumshisky, and Vandana Mukherjee Mukherjee. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2020.bionlp-1.6" title="" class="ltx_ref ltx_href">Towards visual
dialog for radiology</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 19th SIGBioMed Workshop on Biomedical
Language Processing</em>, pages 60–69, Online. Association for Computational
Linguistics.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lau et al. (2018)</span>
<span class="ltx_bibblock">
Jason J Lau, Soumya Gayen, Asma Ben Abacha, and Dina Demner-Fushman. 2018.

</span>
<span class="ltx_bibblock">A dataset of clinically generated visual questions and answers about
radiology images.

</span>
<span class="ltx_bibblock"><em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">Scientific data</em>, 5(1):1–10.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lester et al. (2021)</span>
<span class="ltx_bibblock">
Brian Lester, Rami Al-Rfou, and Noah Constant. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2021.emnlp-main.243" title="" class="ltx_ref ltx_href">The power of
scale for parameter-efficient prompt tuning</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021 Conference on Empirical Methods in
Natural Language Processing</em>, pages 3045–3059, Online and Punta Cana,
Dominican Republic. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lewis et al. (2020)</span>
<span class="ltx_bibblock">
Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir
Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim
Rocktäschel, et al. 2020.

</span>
<span class="ltx_bibblock">Retrieval-augmented generation for knowledge-intensive nlp tasks.

</span>
<span class="ltx_bibblock"><em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>,
33:9459–9474.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2019)</span>
<span class="ltx_bibblock">
Linjie Li, Zhe Gan, Yu Cheng, and Jingjing Liu. 2019.

</span>
<span class="ltx_bibblock">Relation-aware graph attention network for visual question answering.

</span>
<span class="ltx_bibblock">In <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF international conference on
computer vision</em>, pages 10313–10322.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin and Byrne (2022)</span>
<span class="ltx_bibblock">
Weizhe Lin and Bill Byrne. 2022.

</span>
<span class="ltx_bibblock">Retrieval augmented visual question answering with outside knowledge.

</span>
<span class="ltx_bibblock">In <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2022 Conference on Empirical Methods in
Natural Language Processing</em>.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et al. (2021)</span>
<span class="ltx_bibblock">
Zhihong Lin, Donghao Zhang, Qingyi Tao, Danli Shi, Gholamreza Haffari, Qi Wu,
Mingguang He, and Zongyuan Ge. 2021.

</span>
<span class="ltx_bibblock">Medical visual question answering: A survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2111.10056.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2021)</span>
<span class="ltx_bibblock">
Bo Liu, Li-Ming Zhan, Li Xu, Lin Ma, Yan Yang, and Xiao-Ming Wu. 2021.

</span>
<span class="ltx_bibblock">Slake: a semantically-labeled knowledge-enhanced dataset for medical
visual question answering.

</span>
<span class="ltx_bibblock">In <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">2021 IEEE 18th International Symposium on Biomedical Imaging
(ISBI)</em>, pages 1650–1654. IEEE.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lu et al. (2016)</span>
<span class="ltx_bibblock">
Jiasen Lu, Jianwei Yang, Dhruv Batra, and Devi Parikh. 2016.

</span>
<span class="ltx_bibblock">Hierarchical question-image co-attention for visual question
answering.

</span>
<span class="ltx_bibblock"><em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, 29.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Malinowski et al. (2015)</span>
<span class="ltx_bibblock">
Mateusz Malinowski, Marcus Rohrbach, and Mario Fritz. 2015.

</span>
<span class="ltx_bibblock">Ask your neurons: A neural-based approach to answering questions
about images.

</span>
<span class="ltx_bibblock">In <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE international conference on computer
vision</em>, pages 1–9.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Marino et al. (2021)</span>
<span class="ltx_bibblock">
Kenneth Marino, Xinlei Chen, Devi Parikh, Abhinav Gupta, and Marcus Rohrbach.
2021.

</span>
<span class="ltx_bibblock">Krisp: Integrating implicit and symbolic knowledge for open-domain
knowledge-based vqa.

</span>
<span class="ltx_bibblock">In <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition</em>, pages 14111–14121.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Moon et al. (2022)</span>
<span class="ltx_bibblock">
Jong Hak Moon, Hyungyung Lee, Woncheol Shin, Young-Hak Kim, and Edward Choi.
2022.

</span>
<span class="ltx_bibblock">Multi-modal understanding and generation for medical images and text
via vision-language pre-training.

</span>
<span class="ltx_bibblock"><em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">IEEE Journal of Biomedical and Health Informatics</em>.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Narasimhan and Schwing (2018)</span>
<span class="ltx_bibblock">
Medhini Narasimhan and Alexander G Schwing. 2018.

</span>
<span class="ltx_bibblock">Straight to the facts: Learning knowledge base retrieval for factual
visual question answering.

</span>
<span class="ltx_bibblock">In <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">Proceedings of the European conference on computer vision
(ECCV)</em>, pages 451–468.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nguyen et al. (2019)</span>
<span class="ltx_bibblock">
Binh D Nguyen, Thanh-Toan Do, Binh X Nguyen, Tuong Do, Erman Tjiputra, and
Quang D Tran. 2019.

</span>
<span class="ltx_bibblock">Overcoming data limitation in medical visual question answering.

</span>
<span class="ltx_bibblock">In <em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">International Conference on Medical Image Computing and
Computer-Assisted Intervention</em>, pages 522–530. Springer.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Norcliffe-Brown et al. (2018)</span>
<span class="ltx_bibblock">
Will Norcliffe-Brown, Stathis Vafeias, and Sarah Parisot. 2018.

</span>
<span class="ltx_bibblock">Learning conditioned graph structures for interpretable visual
question answering.

</span>
<span class="ltx_bibblock"><em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, 31.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pelka et al. (2018)</span>
<span class="ltx_bibblock">
Obioma Pelka, Sven Koitka, Johannes Rückert, Felix Nensa, and Christoph M
Friedrich. 2018.

</span>
<span class="ltx_bibblock">Radiology objects in context (roco): a multimodal image dataset.

</span>
<span class="ltx_bibblock">In <em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">Intravascular Imaging and Computer Assisted Stenting and
Large-Scale Annotation of Biomedical Data and Expert Label Synthesis</em>, pages
180–189. Springer.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et al. (2021)</span>
<span class="ltx_bibblock">
Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh,
Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark,
Gretchen Krueger, and Ilya Sutskever. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://proceedings.mlr.press/v139/radford21a.html" title="" class="ltx_ref ltx_href">Learning
transferable visual models from natural language supervision</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 38th International Conference on Machine
Learning</em>, volume 139 of <em id="bib.bib33.2.2" class="ltx_emph ltx_font_italic">Proceedings of Machine Learning Research</em>,
pages 8748–8763. PMLR.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Raffel et al. (2020)</span>
<span class="ltx_bibblock">
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael
Matena, Yanqi Zhou, Wei Li, Peter J Liu, et al. 2020.

</span>
<span class="ltx_bibblock">Exploring the limits of transfer learning with a unified text-to-text
transformer.

</span>
<span class="ltx_bibblock"><em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">Journal of Machine Learning Research</em>, 21(140):1–67.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Roberts et al. (2020)</span>
<span class="ltx_bibblock">
Adam Roberts, Colin Raffel, and Noam Shazeer. 2020.

</span>
<span class="ltx_bibblock">How much knowledge can you pack into the parameters of a language
model?

</span>
<span class="ltx_bibblock">In <em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020 Conference on Empirical Methods in
Natural Language Processing</em>.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ross and Swetlitz (2018)</span>
<span class="ltx_bibblock">
Casey Ross and Ike Swetlitz. 2018.

</span>
<span class="ltx_bibblock">Ibm’s watson supercomputer recommended ‘unsafe and
incorrect’cancer treatments, internal documents show.

</span>
<span class="ltx_bibblock"><em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">Stat</em>, 25.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shevchenko et al. (2021)</span>
<span class="ltx_bibblock">
Violetta Shevchenko, Damien Teney, Anthony Dick, and Anton van den Hengel.
2021.

</span>
<span class="ltx_bibblock">Reasoning over vision and language: Exploring the benefits of
supplemental knowledge.

</span>
<span class="ltx_bibblock"><em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2101.06013</em>.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shrivastava and Li (2014)</span>
<span class="ltx_bibblock">
Anshumali Shrivastava and Ping Li. 2014.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://proceedings.neurips.cc/paper/2014/file/310ce61c90f3a46e340ee8257bc70e93-Paper.pdf" title="" class="ltx_ref ltx_href">Asymmetric lsh (alsh) for sublinear time maximum inner product search
(mips)</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>,
volume 27. Curran Associates, Inc.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tanwani et al. (2022)</span>
<span class="ltx_bibblock">
Ajay K Tanwani, Joelle Barral, and Daniel Freedman. 2022.

</span>
<span class="ltx_bibblock">Repsnet: Combining vision with language for automated medical
reports.

</span>
<span class="ltx_bibblock">In <em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">International Conference on Medical Image Computing and
Computer-Assisted Intervention</em>, pages 714–724. Springer.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Thompson et al. (2019)</span>
<span class="ltx_bibblock">
Brian Thompson, Jeremy Gwinnup, Huda Khayrallah, Kevin Duh, and Philipp Koehn.
2019.

</span>
<span class="ltx_bibblock">Overcoming catastrophic forgetting during domain adaptation of neural
machine translation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies, Volume 1 (Long and Short Papers)</em>, pages 2062–2068.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al. (2022)</span>
<span class="ltx_bibblock">
Jialin Wu, Jiasen Lu, Ashish Sabharwal, and Roozbeh Mottaghi. 2022.

</span>
<span class="ltx_bibblock">Multi-modal answer validation for knowledge-based vqa.

</span>
<span class="ltx_bibblock">In <em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI Conference on Artificial
Intelligence</em>, volume 36, pages 2712–2721.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al. (2016)</span>
<span class="ltx_bibblock">
Zichao Yang, Xiaodong He, Jianfeng Gao, Li Deng, and Alex Smola. 2016.

</span>
<span class="ltx_bibblock">Stacked attention networks for image question answering.

</span>
<span class="ltx_bibblock">In <em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE conference on computer vision and
pattern recognition</em>, pages 21–29.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhan et al. (2020)</span>
<span class="ltx_bibblock">
Li-Ming Zhan, Bo Liu, Lu Fan, Jiaxin Chen, and Xiao-Ming Wu. 2020.

</span>
<span class="ltx_bibblock">Medical visual question answering via conditional reasoning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 28th ACM International Conference on
Multimedia</em>, pages 2345–2354.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al. (2019)</span>
<span class="ltx_bibblock">
Yangyang Zhou, Xin Kang, and Fuji Ren. 2019.

</span>
<span class="ltx_bibblock">Tua1 at imageclef 2019 vqa-med: a classification and generation model
based on transfer learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">Conference and Labs of the Evaluation Forum (Working
Notes)</em>.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="Ax1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">Appendix</h2>

<figure id="Ax1.T4" class="ltx_table">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_1"><span id="Ax1.T4.2" class="ltx_ERROR ltx_figure_panel undefined">\renewrobustcmd</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div id="Ax1.T4.1" class="ltx_inline-block ltx_figure_panel ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:97pt;vertical-align:-0.6pt;"><span class="ltx_transformed_inner" style="transform:translate(-147.7pt,32.8pt) scale(0.594813662705975,0.594813662705975) ;">
<table id="Ax1.T4.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="Ax1.T4.1.1.1" class="ltx_tr">
<th id="Ax1.T4.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt ltx_border_t">Q Type</th>
<th id="Ax1.T4.1.1.1.3" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_column ltx_border_tt ltx_border_t">A Type</th>
<th id="Ax1.T4.1.1.1.1" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_column ltx_border_tt ltx_border_t">Question Templates &amp; Answer Templates (<math id="Ax1.T4.1.1.1.1.m1.1" class="ltx_Math" alttext="{\mathcal{T}}_{t}" display="inline"><semantics id="Ax1.T4.1.1.1.1.m1.1a"><msub id="Ax1.T4.1.1.1.1.m1.1.1" xref="Ax1.T4.1.1.1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="Ax1.T4.1.1.1.1.m1.1.1.2" xref="Ax1.T4.1.1.1.1.m1.1.1.2.cmml">𝒯</mi><mi id="Ax1.T4.1.1.1.1.m1.1.1.3" xref="Ax1.T4.1.1.1.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="Ax1.T4.1.1.1.1.m1.1b"><apply id="Ax1.T4.1.1.1.1.m1.1.1.cmml" xref="Ax1.T4.1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="Ax1.T4.1.1.1.1.m1.1.1.1.cmml" xref="Ax1.T4.1.1.1.1.m1.1.1">subscript</csymbol><ci id="Ax1.T4.1.1.1.1.m1.1.1.2.cmml" xref="Ax1.T4.1.1.1.1.m1.1.1.2">𝒯</ci><ci id="Ax1.T4.1.1.1.1.m1.1.1.3.cmml" xref="Ax1.T4.1.1.1.1.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ax1.T4.1.1.1.1.m1.1c">{\mathcal{T}}_{t}</annotation></semantics></math>)</th>
<th id="Ax1.T4.1.1.1.4" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_column ltx_border_tt ltx_border_t">Answer Templates</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="Ax1.T4.1.1.2.1" class="ltx_tr">
<td id="Ax1.T4.1.1.2.1.1" class="ltx_td ltx_align_left ltx_border_t">Organ</td>
<td id="Ax1.T4.1.1.2.1.2" class="ltx_td ltx_nopad_l ltx_align_left ltx_border_t">Open</td>
<td id="Ax1.T4.1.1.2.1.3" class="ltx_td ltx_nopad_l ltx_align_left ltx_border_t">Q: What part of the body is being imaged? What is the organ shown in this image? …</td>
<td id="Ax1.T4.1.1.2.1.4" class="ltx_td ltx_nopad_l ltx_align_left ltx_border_t">A:{Brain, Chest, …}</td>
</tr>
<tr id="Ax1.T4.1.1.3.2" class="ltx_tr">
<td id="Ax1.T4.1.1.3.2.1" class="ltx_td ltx_align_left">Organ</td>
<td id="Ax1.T4.1.1.3.2.2" class="ltx_td ltx_nopad_l ltx_align_left">Closed</td>
<td id="Ax1.T4.1.1.3.2.3" class="ltx_td ltx_nopad_l ltx_align_left">Q: Does the picture contain {}? Is this a study of the {}? …</td>
<td id="Ax1.T4.1.1.3.2.4" class="ltx_td ltx_nopad_l ltx_align_left">A:{Yes,No}</td>
</tr>
<tr id="Ax1.T4.1.1.4.3" class="ltx_tr">
<td id="Ax1.T4.1.1.4.3.1" class="ltx_td ltx_align_left">Organ System</td>
<td id="Ax1.T4.1.1.4.3.2" class="ltx_td ltx_nopad_l ltx_align_left">Open</td>
<td id="Ax1.T4.1.1.4.3.3" class="ltx_td ltx_nopad_l ltx_align_left">Q: What organ system is pictured? What system is this pathology in? …</td>
<td id="Ax1.T4.1.1.4.3.4" class="ltx_td ltx_nopad_l ltx_align_left">A:{Respiratory System, Cardiovascular System, …}</td>
</tr>
<tr id="Ax1.T4.1.1.5.4" class="ltx_tr">
<td id="Ax1.T4.1.1.5.4.1" class="ltx_td ltx_align_left">Organ System</td>
<td id="Ax1.T4.1.1.5.4.2" class="ltx_td ltx_nopad_l ltx_align_left">Closed</td>
<td id="Ax1.T4.1.1.5.4.3" class="ltx_td ltx_nopad_l ltx_align_left">Q: Is this an image of the {}? Is the {} shown? …</td>
<td id="Ax1.T4.1.1.5.4.4" class="ltx_td ltx_nopad_l ltx_align_left">A:{Yes,No}</td>
</tr>
<tr id="Ax1.T4.1.1.6.5" class="ltx_tr">
<td id="Ax1.T4.1.1.6.5.1" class="ltx_td ltx_align_left">Modality</td>
<td id="Ax1.T4.1.1.6.5.2" class="ltx_td ltx_nopad_l ltx_align_left">Open</td>
<td id="Ax1.T4.1.1.6.5.3" class="ltx_td ltx_nopad_l ltx_align_left">Q: What kind of scan is this? How was this image taken? …</td>
<td id="Ax1.T4.1.1.6.5.4" class="ltx_td ltx_nopad_l ltx_align_left">A:{MRI, X-ray, …}</td>
</tr>
<tr id="Ax1.T4.1.1.7.6" class="ltx_tr">
<td id="Ax1.T4.1.1.7.6.1" class="ltx_td ltx_align_left">Modality</td>
<td id="Ax1.T4.1.1.7.6.2" class="ltx_td ltx_nopad_l ltx_align_left">Closed</td>
<td id="Ax1.T4.1.1.7.6.3" class="ltx_td ltx_nopad_l ltx_align_left">Q: Is this a {}? Is the image a {}? …</td>
<td id="Ax1.T4.1.1.7.6.4" class="ltx_td ltx_nopad_l ltx_align_left">A:{Yes,No}</td>
</tr>
<tr id="Ax1.T4.1.1.8.7" class="ltx_tr">
<td id="Ax1.T4.1.1.8.7.1" class="ltx_td ltx_align_left">Plane</td>
<td id="Ax1.T4.1.1.8.7.2" class="ltx_td ltx_nopad_l ltx_align_left">Open</td>
<td id="Ax1.T4.1.1.8.7.3" class="ltx_td ltx_nopad_l ltx_align_left">Q: What image plane is this? How is the image oriented? …</td>
<td id="Ax1.T4.1.1.8.7.4" class="ltx_td ltx_nopad_l ltx_align_left">A:{Axial, Coronal, …}</td>
</tr>
<tr id="Ax1.T4.1.1.9.8" class="ltx_tr">
<td id="Ax1.T4.1.1.9.8.1" class="ltx_td ltx_align_left ltx_border_bb">Plane</td>
<td id="Ax1.T4.1.1.9.8.2" class="ltx_td ltx_nopad_l ltx_align_left ltx_border_bb">Closed</td>
<td id="Ax1.T4.1.1.9.8.3" class="ltx_td ltx_nopad_l ltx_align_left ltx_border_bb">Q: Is this a {} plane? Is the image a {} section? …</td>
<td id="Ax1.T4.1.1.9.8.4" class="ltx_td ltx_nopad_l ltx_align_left ltx_border_bb">A:{Yes,No}</td>
</tr>
</tbody>
</table>
</span></div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>Example templates for different question categories and question types.</figcaption>
</figure>
<figure id="Ax1.T5" class="ltx_table">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_1"><span id="Ax1.T5.3" class="ltx_ERROR ltx_figure_panel undefined">\renewrobustcmd</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div id="Ax1.T5.2" class="ltx_inline-block ltx_figure_panel ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:58.4pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-54.0pt,7.2pt) scale(0.800659241670349,0.800659241670349) ;">
<table id="Ax1.T5.2.2" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="Ax1.T5.2.2.2" class="ltx_tr">
<th id="Ax1.T5.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt ltx_border_t">Q&amp;A Types (<math id="Ax1.T5.1.1.1.1.m1.1" class="ltx_Math" alttext="t\in\mathcal{Q}_{\text{type}}\times\mathcal{A}_{\text{type}}" display="inline"><semantics id="Ax1.T5.1.1.1.1.m1.1a"><mrow id="Ax1.T5.1.1.1.1.m1.1.1" xref="Ax1.T5.1.1.1.1.m1.1.1.cmml"><mi id="Ax1.T5.1.1.1.1.m1.1.1.2" xref="Ax1.T5.1.1.1.1.m1.1.1.2.cmml">t</mi><mo id="Ax1.T5.1.1.1.1.m1.1.1.1" xref="Ax1.T5.1.1.1.1.m1.1.1.1.cmml">∈</mo><mrow id="Ax1.T5.1.1.1.1.m1.1.1.3" xref="Ax1.T5.1.1.1.1.m1.1.1.3.cmml"><msub id="Ax1.T5.1.1.1.1.m1.1.1.3.2" xref="Ax1.T5.1.1.1.1.m1.1.1.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="Ax1.T5.1.1.1.1.m1.1.1.3.2.2" xref="Ax1.T5.1.1.1.1.m1.1.1.3.2.2.cmml">𝒬</mi><mtext id="Ax1.T5.1.1.1.1.m1.1.1.3.2.3" xref="Ax1.T5.1.1.1.1.m1.1.1.3.2.3a.cmml">type</mtext></msub><mo lspace="0.222em" rspace="0.222em" id="Ax1.T5.1.1.1.1.m1.1.1.3.1" xref="Ax1.T5.1.1.1.1.m1.1.1.3.1.cmml">×</mo><msub id="Ax1.T5.1.1.1.1.m1.1.1.3.3" xref="Ax1.T5.1.1.1.1.m1.1.1.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="Ax1.T5.1.1.1.1.m1.1.1.3.3.2" xref="Ax1.T5.1.1.1.1.m1.1.1.3.3.2.cmml">𝒜</mi><mtext id="Ax1.T5.1.1.1.1.m1.1.1.3.3.3" xref="Ax1.T5.1.1.1.1.m1.1.1.3.3.3a.cmml">type</mtext></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ax1.T5.1.1.1.1.m1.1b"><apply id="Ax1.T5.1.1.1.1.m1.1.1.cmml" xref="Ax1.T5.1.1.1.1.m1.1.1"><in id="Ax1.T5.1.1.1.1.m1.1.1.1.cmml" xref="Ax1.T5.1.1.1.1.m1.1.1.1"></in><ci id="Ax1.T5.1.1.1.1.m1.1.1.2.cmml" xref="Ax1.T5.1.1.1.1.m1.1.1.2">𝑡</ci><apply id="Ax1.T5.1.1.1.1.m1.1.1.3.cmml" xref="Ax1.T5.1.1.1.1.m1.1.1.3"><times id="Ax1.T5.1.1.1.1.m1.1.1.3.1.cmml" xref="Ax1.T5.1.1.1.1.m1.1.1.3.1"></times><apply id="Ax1.T5.1.1.1.1.m1.1.1.3.2.cmml" xref="Ax1.T5.1.1.1.1.m1.1.1.3.2"><csymbol cd="ambiguous" id="Ax1.T5.1.1.1.1.m1.1.1.3.2.1.cmml" xref="Ax1.T5.1.1.1.1.m1.1.1.3.2">subscript</csymbol><ci id="Ax1.T5.1.1.1.1.m1.1.1.3.2.2.cmml" xref="Ax1.T5.1.1.1.1.m1.1.1.3.2.2">𝒬</ci><ci id="Ax1.T5.1.1.1.1.m1.1.1.3.2.3a.cmml" xref="Ax1.T5.1.1.1.1.m1.1.1.3.2.3"><mtext mathsize="70%" id="Ax1.T5.1.1.1.1.m1.1.1.3.2.3.cmml" xref="Ax1.T5.1.1.1.1.m1.1.1.3.2.3">type</mtext></ci></apply><apply id="Ax1.T5.1.1.1.1.m1.1.1.3.3.cmml" xref="Ax1.T5.1.1.1.1.m1.1.1.3.3"><csymbol cd="ambiguous" id="Ax1.T5.1.1.1.1.m1.1.1.3.3.1.cmml" xref="Ax1.T5.1.1.1.1.m1.1.1.3.3">subscript</csymbol><ci id="Ax1.T5.1.1.1.1.m1.1.1.3.3.2.cmml" xref="Ax1.T5.1.1.1.1.m1.1.1.3.3.2">𝒜</ci><ci id="Ax1.T5.1.1.1.1.m1.1.1.3.3.3a.cmml" xref="Ax1.T5.1.1.1.1.m1.1.1.3.3.3"><mtext mathsize="70%" id="Ax1.T5.1.1.1.1.m1.1.1.3.3.3.cmml" xref="Ax1.T5.1.1.1.1.m1.1.1.3.3.3">type</mtext></ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ax1.T5.1.1.1.1.m1.1c">t\in\mathcal{Q}_{\text{type}}\times\mathcal{A}_{\text{type}}</annotation></semantics></math>)</th>
<th id="Ax1.T5.2.2.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt ltx_border_t">Keywords (<math id="Ax1.T5.2.2.2.2.m1.1" class="ltx_Math" alttext="\mathcal{W}_{t}" display="inline"><semantics id="Ax1.T5.2.2.2.2.m1.1a"><msub id="Ax1.T5.2.2.2.2.m1.1.1" xref="Ax1.T5.2.2.2.2.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="Ax1.T5.2.2.2.2.m1.1.1.2" xref="Ax1.T5.2.2.2.2.m1.1.1.2.cmml">𝒲</mi><mi id="Ax1.T5.2.2.2.2.m1.1.1.3" xref="Ax1.T5.2.2.2.2.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="Ax1.T5.2.2.2.2.m1.1b"><apply id="Ax1.T5.2.2.2.2.m1.1.1.cmml" xref="Ax1.T5.2.2.2.2.m1.1.1"><csymbol cd="ambiguous" id="Ax1.T5.2.2.2.2.m1.1.1.1.cmml" xref="Ax1.T5.2.2.2.2.m1.1.1">subscript</csymbol><ci id="Ax1.T5.2.2.2.2.m1.1.1.2.cmml" xref="Ax1.T5.2.2.2.2.m1.1.1.2">𝒲</ci><ci id="Ax1.T5.2.2.2.2.m1.1.1.3.cmml" xref="Ax1.T5.2.2.2.2.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ax1.T5.2.2.2.2.m1.1c">\mathcal{W}_{t}</annotation></semantics></math>)</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="Ax1.T5.2.2.3.1" class="ltx_tr">
<td id="Ax1.T5.2.2.3.1.1" class="ltx_td ltx_align_left ltx_border_t">Organ &amp; Open</td>
<td id="Ax1.T5.2.2.3.1.2" class="ltx_td ltx_align_left ltx_border_t">Heart, Lungs, Lung, Liver, Breasts, Chest, Cardiovascular System, Respiratory System …</td>
</tr>
<tr id="Ax1.T5.2.2.4.2" class="ltx_tr">
<td id="Ax1.T5.2.2.4.2.1" class="ltx_td ltx_align_left">Plane &amp; Open</td>
<td id="Ax1.T5.2.2.4.2.2" class="ltx_td ltx_align_left">Axial, Coronal, Supratentorial, Posteroanterior …</td>
</tr>
<tr id="Ax1.T5.2.2.5.3" class="ltx_tr">
<td id="Ax1.T5.2.2.5.3.1" class="ltx_td ltx_align_left ltx_border_bb">Modality &amp; Open</td>
<td id="Ax1.T5.2.2.5.3.2" class="ltx_td ltx_align_left ltx_border_bb">MRI, T1, T2, CT, X-ray, Ultrasound, Flair …</td>
</tr>
</tbody>
</table>
</span></div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>Example keywords for different question types.</figcaption>
</figure>
</section>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Templates</h2>

<div id="A1.p1" class="ltx_para">
<p id="A1.p1.2" class="ltx_p">We use the question and keyword templates in Tables <a href="#Ax1.T4" title="Table 4 ‣ Appendix ‣ Multimodal Prompt Retrieval for Generative Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> and <a href="#Ax1.T5" title="Table 5 ‣ Appendix ‣ Multimodal Prompt Retrieval for Generative Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> to construct a synthetic retrieval set. For open questions, the question template is static. However, the answer to open questions may be any of the keywords <math id="A1.p1.1.m1.1" class="ltx_Math" alttext="w\in\mathcal{W}_{t}" display="inline"><semantics id="A1.p1.1.m1.1a"><mrow id="A1.p1.1.m1.1.1" xref="A1.p1.1.m1.1.1.cmml"><mi id="A1.p1.1.m1.1.1.2" xref="A1.p1.1.m1.1.1.2.cmml">w</mi><mo id="A1.p1.1.m1.1.1.1" xref="A1.p1.1.m1.1.1.1.cmml">∈</mo><msub id="A1.p1.1.m1.1.1.3" xref="A1.p1.1.m1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="A1.p1.1.m1.1.1.3.2" xref="A1.p1.1.m1.1.1.3.2.cmml">𝒲</mi><mi id="A1.p1.1.m1.1.1.3.3" xref="A1.p1.1.m1.1.1.3.3.cmml">t</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="A1.p1.1.m1.1b"><apply id="A1.p1.1.m1.1.1.cmml" xref="A1.p1.1.m1.1.1"><in id="A1.p1.1.m1.1.1.1.cmml" xref="A1.p1.1.m1.1.1.1"></in><ci id="A1.p1.1.m1.1.1.2.cmml" xref="A1.p1.1.m1.1.1.2">𝑤</ci><apply id="A1.p1.1.m1.1.1.3.cmml" xref="A1.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="A1.p1.1.m1.1.1.3.1.cmml" xref="A1.p1.1.m1.1.1.3">subscript</csymbol><ci id="A1.p1.1.m1.1.1.3.2.cmml" xref="A1.p1.1.m1.1.1.3.2">𝒲</ci><ci id="A1.p1.1.m1.1.1.3.3.cmml" xref="A1.p1.1.m1.1.1.3.3">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.1.m1.1c">w\in\mathcal{W}_{t}</annotation></semantics></math>. Closed question templates have a slot that is filled in by one of the keywords <math id="A1.p1.2.m2.1" class="ltx_Math" alttext="w\in\mathcal{W}_{t}" display="inline"><semantics id="A1.p1.2.m2.1a"><mrow id="A1.p1.2.m2.1.1" xref="A1.p1.2.m2.1.1.cmml"><mi id="A1.p1.2.m2.1.1.2" xref="A1.p1.2.m2.1.1.2.cmml">w</mi><mo id="A1.p1.2.m2.1.1.1" xref="A1.p1.2.m2.1.1.1.cmml">∈</mo><msub id="A1.p1.2.m2.1.1.3" xref="A1.p1.2.m2.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="A1.p1.2.m2.1.1.3.2" xref="A1.p1.2.m2.1.1.3.2.cmml">𝒲</mi><mi id="A1.p1.2.m2.1.1.3.3" xref="A1.p1.2.m2.1.1.3.3.cmml">t</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="A1.p1.2.m2.1b"><apply id="A1.p1.2.m2.1.1.cmml" xref="A1.p1.2.m2.1.1"><in id="A1.p1.2.m2.1.1.1.cmml" xref="A1.p1.2.m2.1.1.1"></in><ci id="A1.p1.2.m2.1.1.2.cmml" xref="A1.p1.2.m2.1.1.2">𝑤</ci><apply id="A1.p1.2.m2.1.1.3.cmml" xref="A1.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="A1.p1.2.m2.1.1.3.1.cmml" xref="A1.p1.2.m2.1.1.3">subscript</csymbol><ci id="A1.p1.2.m2.1.1.3.2.cmml" xref="A1.p1.2.m2.1.1.3.2">𝒲</ci><ci id="A1.p1.2.m2.1.1.3.3.cmml" xref="A1.p1.2.m2.1.1.3.3">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.2.m2.1c">w\in\mathcal{W}_{t}</annotation></semantics></math>, and the answer to these questions is either yes or no:</p>
</div>
<figure id="A1.T6" class="ltx_table">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_1"><span id="A1.T6.5" class="ltx_ERROR ltx_figure_panel undefined">\renewrobustcmd</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div id="A1.T6.2" class="ltx_inline-block ltx_figure_panel ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:57.1pt;vertical-align:-0.6pt;"><span class="ltx_transformed_inner" style="transform:translate(-128.7pt,16.8pt) scale(0.627574626089438,0.627574626089438) ;">
<table id="A1.T6.2.2" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A1.T6.2.2.2" class="ltx_tr">
<th id="A1.T6.2.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt ltx_border_t">Prompt Construction Order</th>
<th id="A1.T6.1.1.1.1" class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_tt ltx_border_t">Prompt Template (<math id="A1.T6.1.1.1.1.m1.1" class="ltx_Math" alttext="T_{\text{prompt}}" display="inline"><semantics id="A1.T6.1.1.1.1.m1.1a"><msub id="A1.T6.1.1.1.1.m1.1.1" xref="A1.T6.1.1.1.1.m1.1.1.cmml"><mi id="A1.T6.1.1.1.1.m1.1.1.2" xref="A1.T6.1.1.1.1.m1.1.1.2.cmml">T</mi><mtext id="A1.T6.1.1.1.1.m1.1.1.3" xref="A1.T6.1.1.1.1.m1.1.1.3a.cmml">prompt</mtext></msub><annotation-xml encoding="MathML-Content" id="A1.T6.1.1.1.1.m1.1b"><apply id="A1.T6.1.1.1.1.m1.1.1.cmml" xref="A1.T6.1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="A1.T6.1.1.1.1.m1.1.1.1.cmml" xref="A1.T6.1.1.1.1.m1.1.1">subscript</csymbol><ci id="A1.T6.1.1.1.1.m1.1.1.2.cmml" xref="A1.T6.1.1.1.1.m1.1.1.2">𝑇</ci><ci id="A1.T6.1.1.1.1.m1.1.1.3a.cmml" xref="A1.T6.1.1.1.1.m1.1.1.3"><mtext mathsize="70%" id="A1.T6.1.1.1.1.m1.1.1.3.cmml" xref="A1.T6.1.1.1.1.m1.1.1.3">prompt</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T6.1.1.1.1.m1.1c">T_{\text{prompt}}</annotation></semantics></math>)</th>
<th id="A1.T6.2.2.2.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_tt ltx_border_t">Possible Quantifiers (<math id="A1.T6.2.2.2.2.m1.1" class="ltx_Math" alttext="\mathcal{Q}" display="inline"><semantics id="A1.T6.2.2.2.2.m1.1a"><mi class="ltx_font_mathcaligraphic" id="A1.T6.2.2.2.2.m1.1.1" xref="A1.T6.2.2.2.2.m1.1.1.cmml">𝒬</mi><annotation-xml encoding="MathML-Content" id="A1.T6.2.2.2.2.m1.1b"><ci id="A1.T6.2.2.2.2.m1.1.1.cmml" xref="A1.T6.2.2.2.2.m1.1.1">𝒬</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T6.2.2.2.2.m1.1c">\mathcal{Q}</annotation></semantics></math>)</th>
<th id="A1.T6.2.2.2.4" class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_tt ltx_border_t">Open</th>
<th id="A1.T6.2.2.2.5" class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_tt ltx_border_t">Closed</th>
<th id="A1.T6.2.2.2.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt ltx_border_t">Overall</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A1.T6.2.2.3.1" class="ltx_tr">
<td id="A1.T6.2.2.3.1.1" class="ltx_td ltx_align_center ltx_border_t">Question, Retrieval, Image</td>
<td id="A1.T6.2.2.3.1.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t">I believe the answer is {quantifier} {answer}</td>
<td id="A1.T6.2.2.3.1.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t">very unlikely, unlikely, maybe, likely, very likely, certainly</td>
<td id="A1.T6.2.2.3.1.4" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t">39.6</td>
<td id="A1.T6.2.2.3.1.5" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t">65.0</td>
<td id="A1.T6.2.2.3.1.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t">54.9</td>
</tr>
<tr id="A1.T6.2.2.4.2" class="ltx_tr">
<td id="A1.T6.2.2.4.2.1" class="ltx_td ltx_align_center">Image, Retrieval, Question</td>
<td id="A1.T6.2.2.4.2.2" class="ltx_td ltx_nopad_l ltx_align_center">I believe the answer is {quantifier} {answer}</td>
<td id="A1.T6.2.2.4.2.3" class="ltx_td ltx_nopad_l ltx_align_center">very unlikely, unlikely, maybe, likely, very likely, certainly</td>
<td id="A1.T6.2.2.4.2.4" class="ltx_td ltx_nopad_l ltx_align_center">39.0</td>
<td id="A1.T6.2.2.4.2.5" class="ltx_td ltx_nopad_l ltx_align_center">65.3</td>
<td id="A1.T6.2.2.4.2.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center">54.9</td>
</tr>
<tr id="A1.T6.2.2.5.3" class="ltx_tr">
<td id="A1.T6.2.2.5.3.1" class="ltx_td ltx_align_center">Image, Question, Retrieval</td>
<td id="A1.T6.2.2.5.3.2" class="ltx_td ltx_nopad_l ltx_align_center">{answer} is {quantifier} the answer</td>
<td id="A1.T6.2.2.5.3.3" class="ltx_td ltx_nopad_l ltx_align_center">very unlikely, unlikely, maybe, likely, very likely, certainly</td>
<td id="A1.T6.2.2.5.3.4" class="ltx_td ltx_nopad_l ltx_align_center">37.9</td>
<td id="A1.T6.2.2.5.3.5" class="ltx_td ltx_nopad_l ltx_align_center">68.6</td>
<td id="A1.T6.2.2.5.3.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center">56.4</td>
</tr>
<tr id="A1.T6.2.2.6.4" class="ltx_tr">
<td id="A1.T6.2.2.6.4.1" class="ltx_td ltx_align_center ltx_border_bb">Image, Question, Retrieval</td>
<td id="A1.T6.2.2.6.4.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb">I believe the answer is {quantifier} {answer}</td>
<td id="A1.T6.2.2.6.4.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb">very unlikely, unlikely, maybe, likely, very likely, certainly</td>
<td id="A1.T6.2.2.6.4.4" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb">39.6</td>
<td id="A1.T6.2.2.6.4.5" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb">65.3</td>
<td id="A1.T6.2.2.6.4.6" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb">55.1</td>
</tr>
</tbody>
</table>
</span></div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6: </span>Using different variants of our prompt results in similar performances. This table shows the open, closed, and overall accuracy of MPR<math id="A1.T6.4.m1.1" class="ltx_Math" alttext="{}_{\text{gen\_PM}}\ " display="inline"><semantics id="A1.T6.4.m1.1b"><msub id="A1.T6.4.m1.1.1" xref="A1.T6.4.m1.1.1.cmml"><mi id="A1.T6.4.m1.1.1b" xref="A1.T6.4.m1.1.1.cmml"></mi><mtext id="A1.T6.4.m1.1.1.1" xref="A1.T6.4.m1.1.1.1a.cmml">gen_PM</mtext></msub><annotation-xml encoding="MathML-Content" id="A1.T6.4.m1.1c"><apply id="A1.T6.4.m1.1.1.cmml" xref="A1.T6.4.m1.1.1"><ci id="A1.T6.4.m1.1.1.1a.cmml" xref="A1.T6.4.m1.1.1.1"><mtext mathsize="70%" id="A1.T6.4.m1.1.1.1.cmml" xref="A1.T6.4.m1.1.1.1">gen_PM</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T6.4.m1.1d">{}_{\text{gen\_PM}}\ </annotation></semantics></math>in a domain adaptation setting from SLAKE to VQA-RAD, retrieving k=1 nearest question-image pairs.</figcaption>
</figure>
</section>
<section id="A2" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Prompt Variations</h2>

<div id="A2.p1" class="ltx_para">
<p id="A2.p1.1" class="ltx_p">During the prompt construction process, we experiment with different prompt ordering and wording of retrieval prompts. We illustrate different template wording in the Prompt Template column of Table <a href="#A1.T6" title="Table 6 ‣ Appendix A Templates ‣ Multimodal Prompt Retrieval for Generative Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>. Each prompt contains a quantifier that is filled in with an expression ranging from “very unlikely" to “certainly" based on the confidence score of <math id="A2.p1.1.m1.1" class="ltx_Math" alttext="y^{*}" display="inline"><semantics id="A2.p1.1.m1.1a"><msup id="A2.p1.1.m1.1.1" xref="A2.p1.1.m1.1.1.cmml"><mi id="A2.p1.1.m1.1.1.2" xref="A2.p1.1.m1.1.1.2.cmml">y</mi><mo id="A2.p1.1.m1.1.1.3" xref="A2.p1.1.m1.1.1.3.cmml">∗</mo></msup><annotation-xml encoding="MathML-Content" id="A2.p1.1.m1.1b"><apply id="A2.p1.1.m1.1.1.cmml" xref="A2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A2.p1.1.m1.1.1.1.cmml" xref="A2.p1.1.m1.1.1">superscript</csymbol><ci id="A2.p1.1.m1.1.1.2.cmml" xref="A2.p1.1.m1.1.1.2">𝑦</ci><times id="A2.p1.1.m1.1.1.3.cmml" xref="A2.p1.1.m1.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.p1.1.m1.1c">y^{*}</annotation></semantics></math>, described in Section <a href="#S3.SS2" title="3.2 Multimodal Embedding Retrieval ‣ 3 Methods ‣ Multimodal Prompt Retrieval for Generative Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a>. We found that performance does not significantly change when changing these aspects of the prompt, and we ultimately decided to use settings in the last row of the table.</p>
</div>
</section>
<section id="A3" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Dataset Information</h2>

<div id="A3.p1" class="ltx_para">
<p id="A3.p1.1" class="ltx_p">Tables <a href="#A3.T7" title="Table 7 ‣ Appendix C Dataset Information ‣ Multimodal Prompt Retrieval for Generative Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> and <a href="#A3.T8" title="Table 8 ‣ Appendix C Dataset Information ‣ Multimodal Prompt Retrieval for Generative Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> report descriptive statistics about the datasets used in our experiments. Although the synthetic data contains more question-answer pairs than SLAKE and VQA-RAD, it has noisier labels and more limited question types. SLAKE and VQA-RAD have larger question-answer diversity and share several question types, such as Organ, Position, and Abnormality questions.</p>
</div>
<figure id="A3.T7" class="ltx_table">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_1"><span id="A3.T7.1" class="ltx_ERROR ltx_figure_panel undefined">\renewrobustcmd</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div id="A3.T7.2" class="ltx_inline-block ltx_figure_panel ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:84.8pt;vertical-align:-0.9pt;"><span class="ltx_transformed_inner" style="transform:translate(-15.7pt,3.0pt) scale(0.932347358686205,0.932347358686205) ;">
<table id="A3.T7.2.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A3.T7.2.1.1.1" class="ltx_tr">
<th id="A3.T7.2.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt ltx_border_t">Dataset</th>
<th id="A3.T7.2.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt ltx_border_t">Train Split</th>
<th id="A3.T7.2.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt ltx_border_t">Validation Split</th>
<th id="A3.T7.2.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt ltx_border_t">Test Split</th>
<th id="A3.T7.2.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt ltx_border_t">Number of Question Types</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A3.T7.2.1.2.1" class="ltx_tr">
<td id="A3.T7.2.1.2.1.1" class="ltx_td ltx_align_center ltx_border_t">SLAKE</td>
<td id="A3.T7.2.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t">4918</td>
<td id="A3.T7.2.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t">1053</td>
<td id="A3.T7.2.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t">1061</td>
<td id="A3.T7.2.1.2.1.5" class="ltx_td ltx_align_center ltx_border_t">10</td>
</tr>
<tr id="A3.T7.2.1.3.2" class="ltx_tr">
<td id="A3.T7.2.1.3.2.1" class="ltx_td ltx_align_center">VQA-RAD</td>
<td id="A3.T7.2.1.3.2.2" class="ltx_td ltx_align_center">3064</td>
<td id="A3.T7.2.1.3.2.3" class="ltx_td ltx_align_center">-</td>
<td id="A3.T7.2.1.3.2.4" class="ltx_td ltx_align_center">451</td>
<td id="A3.T7.2.1.3.2.5" class="ltx_td ltx_align_center">11</td>
</tr>
<tr id="A3.T7.2.1.4.3" class="ltx_tr">
<td id="A3.T7.2.1.4.3.1" class="ltx_td ltx_align_center">ROCO (image-caption only)</td>
<td id="A3.T7.2.1.4.3.2" class="ltx_td ltx_align_center">65460</td>
<td id="A3.T7.2.1.4.3.3" class="ltx_td ltx_align_center">8183</td>
<td id="A3.T7.2.1.4.3.4" class="ltx_td ltx_align_center">8182</td>
<td id="A3.T7.2.1.4.3.5" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="A3.T7.2.1.5.4" class="ltx_tr">
<td id="A3.T7.2.1.5.4.1" class="ltx_td ltx_align_center ltx_border_bb">Synthetic</td>
<td id="A3.T7.2.1.5.4.2" class="ltx_td ltx_align_center ltx_border_bb">56526</td>
<td id="A3.T7.2.1.5.4.3" class="ltx_td ltx_align_center ltx_border_bb">-</td>
<td id="A3.T7.2.1.5.4.4" class="ltx_td ltx_align_center ltx_border_bb">-</td>
<td id="A3.T7.2.1.5.4.5" class="ltx_td ltx_align_center ltx_border_bb">3</td>
</tr>
</tbody>
</table>
</span></div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 7: </span>Statistics about the datasets in our experiments. The synthetic data contains three different question types because other types require domain-specific knowledge (e.g. abnormality, knowledge graph, etc).</figcaption>
</figure>
<figure id="A3.T8" class="ltx_table">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_1"><span id="A3.T8.1" class="ltx_ERROR ltx_figure_panel undefined">\renewrobustcmd</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div id="A3.T8.2" class="ltx_inline-block ltx_figure_panel ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:170.3pt;vertical-align:-0.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-82.3pt,32.2pt) scale(0.724897085435032,0.724897085435032) ;">
<table id="A3.T8.2.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A3.T8.2.1.1.1" class="ltx_tr">
<th id="A3.T8.2.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" colspan="2">SLAKE</th>
<th id="A3.T8.2.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" colspan="2">VQA-RAD</th>
<th id="A3.T8.2.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt" colspan="2">Synthetic</th>
</tr>
<tr id="A3.T8.2.1.2.2" class="ltx_tr">
<th id="A3.T8.2.1.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row">Question Type</th>
<th id="A3.T8.2.1.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r">Percentage of Test Data</th>
<th id="A3.T8.2.1.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row">Question Type</th>
<th id="A3.T8.2.1.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r">Percentage of Test Data</th>
<th id="A3.T8.2.1.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row">Question Type</th>
<th id="A3.T8.2.1.2.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column">Percentage of Data</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A3.T8.2.1.3.1" class="ltx_tr">
<th id="A3.T8.2.1.3.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">Shape</th>
<td id="A3.T8.2.1.3.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.66</td>
<th id="A3.T8.2.1.3.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">Color</th>
<td id="A3.T8.2.1.3.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.87</td>
<th id="A3.T8.2.1.3.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">Modality</th>
<td id="A3.T8.2.1.3.1.6" class="ltx_td ltx_align_center ltx_border_t">30.61</td>
</tr>
<tr id="A3.T8.2.1.4.2" class="ltx_tr">
<th id="A3.T8.2.1.4.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">Color</th>
<td id="A3.T8.2.1.4.2.2" class="ltx_td ltx_align_center ltx_border_r">3.20</td>
<th id="A3.T8.2.1.4.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_row">Quantity/Counting</th>
<td id="A3.T8.2.1.4.2.4" class="ltx_td ltx_align_center ltx_border_r">1.31</td>
<th id="A3.T8.2.1.4.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_row">Plane</th>
<td id="A3.T8.2.1.4.2.6" class="ltx_td ltx_align_center">30.65</td>
</tr>
<tr id="A3.T8.2.1.5.3" class="ltx_tr">
<th id="A3.T8.2.1.5.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">Quantity</th>
<td id="A3.T8.2.1.5.3.2" class="ltx_td ltx_align_center ltx_border_r">4.90</td>
<th id="A3.T8.2.1.5.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_row">Organ</th>
<td id="A3.T8.2.1.5.3.4" class="ltx_td ltx_align_center ltx_border_r">2.18</td>
<th id="A3.T8.2.1.5.3.5" class="ltx_td ltx_align_center ltx_th ltx_th_row">Organ</th>
<td id="A3.T8.2.1.5.3.6" class="ltx_td ltx_align_center">38.74</td>
</tr>
<tr id="A3.T8.2.1.6.4" class="ltx_tr">
<th id="A3.T8.2.1.6.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">Plane</th>
<td id="A3.T8.2.1.6.4.2" class="ltx_td ltx_align_center ltx_border_r">5.47</td>
<th id="A3.T8.2.1.6.4.3" class="ltx_td ltx_align_center ltx_th ltx_th_row">Attribute</th>
<td id="A3.T8.2.1.6.4.4" class="ltx_td ltx_align_center ltx_border_r">4.36</td>
<th id="A3.T8.2.1.6.4.5" class="ltx_td ltx_align_center ltx_th ltx_th_row">-</th>
<td id="A3.T8.2.1.6.4.6" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="A3.T8.2.1.7.5" class="ltx_tr">
<th id="A3.T8.2.1.7.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">Size</th>
<td id="A3.T8.2.1.7.5.2" class="ltx_td ltx_align_center ltx_border_r">6.13</td>
<th id="A3.T8.2.1.7.5.3" class="ltx_td ltx_align_center ltx_th ltx_th_row">Other</th>
<td id="A3.T8.2.1.7.5.4" class="ltx_td ltx_align_center ltx_border_r">5.66</td>
<th id="A3.T8.2.1.7.5.5" class="ltx_td ltx_align_center ltx_th ltx_th_row">-</th>
<td id="A3.T8.2.1.7.5.6" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="A3.T8.2.1.8.6" class="ltx_tr">
<th id="A3.T8.2.1.8.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">Modality</th>
<td id="A3.T8.2.1.8.6.2" class="ltx_td ltx_align_center ltx_border_r">10.18</td>
<th id="A3.T8.2.1.8.6.3" class="ltx_td ltx_align_center ltx_th ltx_th_row">Plane</th>
<td id="A3.T8.2.1.8.6.4" class="ltx_td ltx_align_center ltx_border_r">5.66</td>
<th id="A3.T8.2.1.8.6.5" class="ltx_td ltx_align_center ltx_th ltx_th_row">-</th>
<td id="A3.T8.2.1.8.6.6" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="A3.T8.2.1.9.7" class="ltx_tr">
<th id="A3.T8.2.1.9.7.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">Knowledge Graph</th>
<td id="A3.T8.2.1.9.7.2" class="ltx_td ltx_align_center ltx_border_r">13.95</td>
<th id="A3.T8.2.1.9.7.3" class="ltx_td ltx_align_center ltx_th ltx_th_row">Modality</th>
<td id="A3.T8.2.1.9.7.4" class="ltx_td ltx_align_center ltx_border_r">7.19</td>
<th id="A3.T8.2.1.9.7.5" class="ltx_td ltx_align_center ltx_th ltx_th_row">-</th>
<td id="A3.T8.2.1.9.7.6" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="A3.T8.2.1.10.8" class="ltx_tr">
<th id="A3.T8.2.1.10.8.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">Abnormality</th>
<td id="A3.T8.2.1.10.8.2" class="ltx_td ltx_align_center ltx_border_r">14.14</td>
<th id="A3.T8.2.1.10.8.3" class="ltx_td ltx_align_center ltx_th ltx_th_row">Size</th>
<td id="A3.T8.2.1.10.8.4" class="ltx_td ltx_align_center ltx_border_r">10.02</td>
<th id="A3.T8.2.1.10.8.5" class="ltx_td ltx_align_center ltx_th ltx_th_row">-</th>
<td id="A3.T8.2.1.10.8.6" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="A3.T8.2.1.11.9" class="ltx_tr">
<th id="A3.T8.2.1.11.9.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">Position</th>
<td id="A3.T8.2.1.11.9.2" class="ltx_td ltx_align_center ltx_border_r">17.53</td>
<th id="A3.T8.2.1.11.9.3" class="ltx_td ltx_align_center ltx_th ltx_th_row">Abnormality</th>
<td id="A3.T8.2.1.11.9.4" class="ltx_td ltx_align_center ltx_border_r">12.20</td>
<th id="A3.T8.2.1.11.9.5" class="ltx_td ltx_align_center ltx_th ltx_th_row">-</th>
<td id="A3.T8.2.1.11.9.6" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="A3.T8.2.1.12.10" class="ltx_tr">
<th id="A3.T8.2.1.12.10.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">Organ</th>
<td id="A3.T8.2.1.12.10.2" class="ltx_td ltx_align_center ltx_border_r">23.85</td>
<th id="A3.T8.2.1.12.10.3" class="ltx_td ltx_align_center ltx_th ltx_th_row">Position</th>
<td id="A3.T8.2.1.12.10.4" class="ltx_td ltx_align_center ltx_border_r">13.29</td>
<th id="A3.T8.2.1.12.10.5" class="ltx_td ltx_align_center ltx_th ltx_th_row">-</th>
<td id="A3.T8.2.1.12.10.6" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="A3.T8.2.1.13.11" class="ltx_tr">
<th id="A3.T8.2.1.13.11.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_b">-</th>
<td id="A3.T8.2.1.13.11.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_r">-</td>
<th id="A3.T8.2.1.13.11.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_b">Presence</th>
<td id="A3.T8.2.1.13.11.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_r">37.25</td>
<th id="A3.T8.2.1.13.11.5" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_b">-</th>
<td id="A3.T8.2.1.13.11.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_b">-</td>
</tr>
</tbody>
</table>
</span></div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 8: </span>Composition of the datasets in our experiments. We use the English portion of the SLAKE dataset.</figcaption>
</figure>
<div id="A3.p2" class="ltx_para">
<p id="A3.p2.1" class="ltx_p">Figure <a href="#A3.F5" title="Figure 5 ‣ Appendix C Dataset Information ‣ Multimodal Prompt Retrieval for Generative Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> displays our model’s in-domain accuracies on SLAKE and VQA-RAD. The models perform best on Color, Attribute, and Size questions in VQA-RAD. The discriminative variants have better accuracy overall, but can not be directly applied to other datasets. We observed lower accuracy on Modality and Organ questions in VQA-RAD, which we attribute to the diversity of question and answer phrasing in these VQA-RAD question types.</p>
</div>
<figure id="A3.F5" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2306.17675/assets/x7.png" id="A3.F5.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="415" height="161" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2306.17675/assets/x8.png" id="A3.F5.g2" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="415" height="161" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Accuracy for each question type for the SLAKE and VQA-RAD test datasets. Percentages on the x-axis indicate each question type’s proportion of the dataset.</figcaption>
</figure>
</section>
<section id="A4" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Attention Visualization</h2>

<div id="A4.p1" class="ltx_para">
<p id="A4.p1.1" class="ltx_p">Transformer-based models utilize attention to calculate dependencies between inputs which may be important for prediction. Since our MPR model uses a pretrained T5 encoder to combine features from several sources, a visualization of its attention scores may indicate which parts of the image contribute to its answers. Figure <a href="#A4.F6" title="Figure 6 ‣ Appendix D Attention Visualization ‣ Multimodal Prompt Retrieval for Generative Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> illustrates the encoder self-attention in different attention heads and layers of our model when asked a challenging position question. The results suggest that some attention modules may attend to the entire input image (Layer 1, Head 4), whereas others may look for local dependencies by attending to adjacent tokens (Layer 2, Head 7).</p>
</div>
<div id="A4.p2" class="ltx_para">
<p id="A4.p2.1" class="ltx_p">In addition to encoder self-attention, cross attention in encoder-decoder transformer architectures may also illustrate which tokens from the input prompt contribute the most when generating answer tokens. Since the prompt to our model consists of image tokens, we visualize which image regions have the highest attention scores in <a href="#A4.F8" title="Figure 8 ‣ Appendix D Attention Visualization ‣ Multimodal Prompt Retrieval for Generative Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>.</p>
</div>
<div id="A4.p3" class="ltx_para">
<p id="A4.p3.1" class="ltx_p">Existing work has shown the effectiveness of using retrieval from a data store to rapidly adapt language models to new domains <cite class="ltx_cite ltx_citemacro_cite">Khandelwal et al. (<a href="#bib.bib13" title="" class="ltx_ref">2020</a>)</cite>. KNN LMs uses a blending parameter <math id="A4.p3.1.m1.2" class="ltx_Math" alttext="\lambda\in[0,1]" display="inline"><semantics id="A4.p3.1.m1.2a"><mrow id="A4.p3.1.m1.2.3" xref="A4.p3.1.m1.2.3.cmml"><mi id="A4.p3.1.m1.2.3.2" xref="A4.p3.1.m1.2.3.2.cmml">λ</mi><mo id="A4.p3.1.m1.2.3.1" xref="A4.p3.1.m1.2.3.1.cmml">∈</mo><mrow id="A4.p3.1.m1.2.3.3.2" xref="A4.p3.1.m1.2.3.3.1.cmml"><mo stretchy="false" id="A4.p3.1.m1.2.3.3.2.1" xref="A4.p3.1.m1.2.3.3.1.cmml">[</mo><mn id="A4.p3.1.m1.1.1" xref="A4.p3.1.m1.1.1.cmml">0</mn><mo id="A4.p3.1.m1.2.3.3.2.2" xref="A4.p3.1.m1.2.3.3.1.cmml">,</mo><mn id="A4.p3.1.m1.2.2" xref="A4.p3.1.m1.2.2.cmml">1</mn><mo stretchy="false" id="A4.p3.1.m1.2.3.3.2.3" xref="A4.p3.1.m1.2.3.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A4.p3.1.m1.2b"><apply id="A4.p3.1.m1.2.3.cmml" xref="A4.p3.1.m1.2.3"><in id="A4.p3.1.m1.2.3.1.cmml" xref="A4.p3.1.m1.2.3.1"></in><ci id="A4.p3.1.m1.2.3.2.cmml" xref="A4.p3.1.m1.2.3.2">𝜆</ci><interval closure="closed" id="A4.p3.1.m1.2.3.3.1.cmml" xref="A4.p3.1.m1.2.3.3.2"><cn type="integer" id="A4.p3.1.m1.1.1.cmml" xref="A4.p3.1.m1.1.1">0</cn><cn type="integer" id="A4.p3.1.m1.2.2.cmml" xref="A4.p3.1.m1.2.2">1</cn></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.p3.1.m1.2c">\lambda\in[0,1]</annotation></semantics></math> to control the influence of retrieved information towards prediction:</p>
<table id="A4.EGx5" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="A4.E8"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="A4.E8.m1.3" class="ltx_Math" alttext="\displaystyle\lambda\text{pkNN}(y|x)+(1-\lambda)\text{pLM}(y|x)" display="inline"><semantics id="A4.E8.m1.3a"><mrow id="A4.E8.m1.3.3" xref="A4.E8.m1.3.3.cmml"><mrow id="A4.E8.m1.1.1.1" xref="A4.E8.m1.1.1.1.cmml"><mi id="A4.E8.m1.1.1.1.3" xref="A4.E8.m1.1.1.1.3.cmml">λ</mi><mo lspace="0em" rspace="0em" id="A4.E8.m1.1.1.1.2" xref="A4.E8.m1.1.1.1.2.cmml">​</mo><mtext id="A4.E8.m1.1.1.1.4" xref="A4.E8.m1.1.1.1.4a.cmml">pkNN</mtext><mo lspace="0em" rspace="0em" id="A4.E8.m1.1.1.1.2a" xref="A4.E8.m1.1.1.1.2.cmml">​</mo><mrow id="A4.E8.m1.1.1.1.1.1" xref="A4.E8.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="A4.E8.m1.1.1.1.1.1.2" xref="A4.E8.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="A4.E8.m1.1.1.1.1.1.1" xref="A4.E8.m1.1.1.1.1.1.1.cmml"><mi id="A4.E8.m1.1.1.1.1.1.1.2" xref="A4.E8.m1.1.1.1.1.1.1.2.cmml">y</mi><mo fence="false" id="A4.E8.m1.1.1.1.1.1.1.1" xref="A4.E8.m1.1.1.1.1.1.1.1.cmml">|</mo><mi id="A4.E8.m1.1.1.1.1.1.1.3" xref="A4.E8.m1.1.1.1.1.1.1.3.cmml">x</mi></mrow><mo stretchy="false" id="A4.E8.m1.1.1.1.1.1.3" xref="A4.E8.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="A4.E8.m1.3.3.4" xref="A4.E8.m1.3.3.4.cmml">+</mo><mrow id="A4.E8.m1.3.3.3" xref="A4.E8.m1.3.3.3.cmml"><mrow id="A4.E8.m1.2.2.2.1.1" xref="A4.E8.m1.2.2.2.1.1.1.cmml"><mo stretchy="false" id="A4.E8.m1.2.2.2.1.1.2" xref="A4.E8.m1.2.2.2.1.1.1.cmml">(</mo><mrow id="A4.E8.m1.2.2.2.1.1.1" xref="A4.E8.m1.2.2.2.1.1.1.cmml"><mn id="A4.E8.m1.2.2.2.1.1.1.2" xref="A4.E8.m1.2.2.2.1.1.1.2.cmml">1</mn><mo id="A4.E8.m1.2.2.2.1.1.1.1" xref="A4.E8.m1.2.2.2.1.1.1.1.cmml">−</mo><mi id="A4.E8.m1.2.2.2.1.1.1.3" xref="A4.E8.m1.2.2.2.1.1.1.3.cmml">λ</mi></mrow><mo stretchy="false" id="A4.E8.m1.2.2.2.1.1.3" xref="A4.E8.m1.2.2.2.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="A4.E8.m1.3.3.3.3" xref="A4.E8.m1.3.3.3.3.cmml">​</mo><mtext id="A4.E8.m1.3.3.3.4" xref="A4.E8.m1.3.3.3.4a.cmml">pLM</mtext><mo lspace="0em" rspace="0em" id="A4.E8.m1.3.3.3.3a" xref="A4.E8.m1.3.3.3.3.cmml">​</mo><mrow id="A4.E8.m1.3.3.3.2.1" xref="A4.E8.m1.3.3.3.2.1.1.cmml"><mo stretchy="false" id="A4.E8.m1.3.3.3.2.1.2" xref="A4.E8.m1.3.3.3.2.1.1.cmml">(</mo><mrow id="A4.E8.m1.3.3.3.2.1.1" xref="A4.E8.m1.3.3.3.2.1.1.cmml"><mi id="A4.E8.m1.3.3.3.2.1.1.2" xref="A4.E8.m1.3.3.3.2.1.1.2.cmml">y</mi><mo fence="false" id="A4.E8.m1.3.3.3.2.1.1.1" xref="A4.E8.m1.3.3.3.2.1.1.1.cmml">|</mo><mi id="A4.E8.m1.3.3.3.2.1.1.3" xref="A4.E8.m1.3.3.3.2.1.1.3.cmml">x</mi></mrow><mo stretchy="false" id="A4.E8.m1.3.3.3.2.1.3" xref="A4.E8.m1.3.3.3.2.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="A4.E8.m1.3b"><apply id="A4.E8.m1.3.3.cmml" xref="A4.E8.m1.3.3"><plus id="A4.E8.m1.3.3.4.cmml" xref="A4.E8.m1.3.3.4"></plus><apply id="A4.E8.m1.1.1.1.cmml" xref="A4.E8.m1.1.1.1"><times id="A4.E8.m1.1.1.1.2.cmml" xref="A4.E8.m1.1.1.1.2"></times><ci id="A4.E8.m1.1.1.1.3.cmml" xref="A4.E8.m1.1.1.1.3">𝜆</ci><ci id="A4.E8.m1.1.1.1.4a.cmml" xref="A4.E8.m1.1.1.1.4"><mtext id="A4.E8.m1.1.1.1.4.cmml" xref="A4.E8.m1.1.1.1.4">pkNN</mtext></ci><apply id="A4.E8.m1.1.1.1.1.1.1.cmml" xref="A4.E8.m1.1.1.1.1.1"><csymbol cd="latexml" id="A4.E8.m1.1.1.1.1.1.1.1.cmml" xref="A4.E8.m1.1.1.1.1.1.1.1">conditional</csymbol><ci id="A4.E8.m1.1.1.1.1.1.1.2.cmml" xref="A4.E8.m1.1.1.1.1.1.1.2">𝑦</ci><ci id="A4.E8.m1.1.1.1.1.1.1.3.cmml" xref="A4.E8.m1.1.1.1.1.1.1.3">𝑥</ci></apply></apply><apply id="A4.E8.m1.3.3.3.cmml" xref="A4.E8.m1.3.3.3"><times id="A4.E8.m1.3.3.3.3.cmml" xref="A4.E8.m1.3.3.3.3"></times><apply id="A4.E8.m1.2.2.2.1.1.1.cmml" xref="A4.E8.m1.2.2.2.1.1"><minus id="A4.E8.m1.2.2.2.1.1.1.1.cmml" xref="A4.E8.m1.2.2.2.1.1.1.1"></minus><cn type="integer" id="A4.E8.m1.2.2.2.1.1.1.2.cmml" xref="A4.E8.m1.2.2.2.1.1.1.2">1</cn><ci id="A4.E8.m1.2.2.2.1.1.1.3.cmml" xref="A4.E8.m1.2.2.2.1.1.1.3">𝜆</ci></apply><ci id="A4.E8.m1.3.3.3.4a.cmml" xref="A4.E8.m1.3.3.3.4"><mtext id="A4.E8.m1.3.3.3.4.cmml" xref="A4.E8.m1.3.3.3.4">pLM</mtext></ci><apply id="A4.E8.m1.3.3.3.2.1.1.cmml" xref="A4.E8.m1.3.3.3.2.1"><csymbol cd="latexml" id="A4.E8.m1.3.3.3.2.1.1.1.cmml" xref="A4.E8.m1.3.3.3.2.1.1.1">conditional</csymbol><ci id="A4.E8.m1.3.3.3.2.1.1.2.cmml" xref="A4.E8.m1.3.3.3.2.1.1.2">𝑦</ci><ci id="A4.E8.m1.3.3.3.2.1.1.3.cmml" xref="A4.E8.m1.3.3.3.2.1.1.3">𝑥</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.E8.m1.3c">\displaystyle\lambda\text{pkNN}(y|x)+(1-\lambda)\text{pLM}(y|x)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(8)</span></td>
</tr></tbody>
</table>
</div>
<div id="A4.p4" class="ltx_para">
<p id="A4.p4.5" class="ltx_p">This method assumes the availability of a language model <math id="A4.p4.1.m1.1" class="ltx_Math" alttext="\text{pLM}(y|x)" display="inline"><semantics id="A4.p4.1.m1.1a"><mrow id="A4.p4.1.m1.1.1" xref="A4.p4.1.m1.1.1.cmml"><mtext id="A4.p4.1.m1.1.1.3" xref="A4.p4.1.m1.1.1.3a.cmml">pLM</mtext><mo lspace="0em" rspace="0em" id="A4.p4.1.m1.1.1.2" xref="A4.p4.1.m1.1.1.2.cmml">​</mo><mrow id="A4.p4.1.m1.1.1.1.1" xref="A4.p4.1.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="A4.p4.1.m1.1.1.1.1.2" xref="A4.p4.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="A4.p4.1.m1.1.1.1.1.1" xref="A4.p4.1.m1.1.1.1.1.1.cmml"><mi id="A4.p4.1.m1.1.1.1.1.1.2" xref="A4.p4.1.m1.1.1.1.1.1.2.cmml">y</mi><mo fence="false" id="A4.p4.1.m1.1.1.1.1.1.1" xref="A4.p4.1.m1.1.1.1.1.1.1.cmml">|</mo><mi id="A4.p4.1.m1.1.1.1.1.1.3" xref="A4.p4.1.m1.1.1.1.1.1.3.cmml">x</mi></mrow><mo stretchy="false" id="A4.p4.1.m1.1.1.1.1.3" xref="A4.p4.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A4.p4.1.m1.1b"><apply id="A4.p4.1.m1.1.1.cmml" xref="A4.p4.1.m1.1.1"><times id="A4.p4.1.m1.1.1.2.cmml" xref="A4.p4.1.m1.1.1.2"></times><ci id="A4.p4.1.m1.1.1.3a.cmml" xref="A4.p4.1.m1.1.1.3"><mtext id="A4.p4.1.m1.1.1.3.cmml" xref="A4.p4.1.m1.1.1.3">pLM</mtext></ci><apply id="A4.p4.1.m1.1.1.1.1.1.cmml" xref="A4.p4.1.m1.1.1.1.1"><csymbol cd="latexml" id="A4.p4.1.m1.1.1.1.1.1.1.cmml" xref="A4.p4.1.m1.1.1.1.1.1.1">conditional</csymbol><ci id="A4.p4.1.m1.1.1.1.1.1.2.cmml" xref="A4.p4.1.m1.1.1.1.1.1.2">𝑦</ci><ci id="A4.p4.1.m1.1.1.1.1.1.3.cmml" xref="A4.p4.1.m1.1.1.1.1.1.3">𝑥</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.p4.1.m1.1c">\text{pLM}(y|x)</annotation></semantics></math> and a retrieval model <math id="A4.p4.2.m2.1" class="ltx_Math" alttext="\text{pkNN}(y|x)" display="inline"><semantics id="A4.p4.2.m2.1a"><mrow id="A4.p4.2.m2.1.1" xref="A4.p4.2.m2.1.1.cmml"><mtext id="A4.p4.2.m2.1.1.3" xref="A4.p4.2.m2.1.1.3a.cmml">pkNN</mtext><mo lspace="0em" rspace="0em" id="A4.p4.2.m2.1.1.2" xref="A4.p4.2.m2.1.1.2.cmml">​</mo><mrow id="A4.p4.2.m2.1.1.1.1" xref="A4.p4.2.m2.1.1.1.1.1.cmml"><mo stretchy="false" id="A4.p4.2.m2.1.1.1.1.2" xref="A4.p4.2.m2.1.1.1.1.1.cmml">(</mo><mrow id="A4.p4.2.m2.1.1.1.1.1" xref="A4.p4.2.m2.1.1.1.1.1.cmml"><mi id="A4.p4.2.m2.1.1.1.1.1.2" xref="A4.p4.2.m2.1.1.1.1.1.2.cmml">y</mi><mo fence="false" id="A4.p4.2.m2.1.1.1.1.1.1" xref="A4.p4.2.m2.1.1.1.1.1.1.cmml">|</mo><mi id="A4.p4.2.m2.1.1.1.1.1.3" xref="A4.p4.2.m2.1.1.1.1.1.3.cmml">x</mi></mrow><mo stretchy="false" id="A4.p4.2.m2.1.1.1.1.3" xref="A4.p4.2.m2.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A4.p4.2.m2.1b"><apply id="A4.p4.2.m2.1.1.cmml" xref="A4.p4.2.m2.1.1"><times id="A4.p4.2.m2.1.1.2.cmml" xref="A4.p4.2.m2.1.1.2"></times><ci id="A4.p4.2.m2.1.1.3a.cmml" xref="A4.p4.2.m2.1.1.3"><mtext id="A4.p4.2.m2.1.1.3.cmml" xref="A4.p4.2.m2.1.1.3">pkNN</mtext></ci><apply id="A4.p4.2.m2.1.1.1.1.1.cmml" xref="A4.p4.2.m2.1.1.1.1"><csymbol cd="latexml" id="A4.p4.2.m2.1.1.1.1.1.1.cmml" xref="A4.p4.2.m2.1.1.1.1.1.1">conditional</csymbol><ci id="A4.p4.2.m2.1.1.1.1.1.2.cmml" xref="A4.p4.2.m2.1.1.1.1.1.2">𝑦</ci><ci id="A4.p4.2.m2.1.1.1.1.1.3.cmml" xref="A4.p4.2.m2.1.1.1.1.1.3">𝑥</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.p4.2.m2.1c">\text{pkNN}(y|x)</annotation></semantics></math>which can predict the next vocabulary token <math id="A4.p4.3.m3.1" class="ltx_Math" alttext="y" display="inline"><semantics id="A4.p4.3.m3.1a"><mi id="A4.p4.3.m3.1.1" xref="A4.p4.3.m3.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="A4.p4.3.m3.1b"><ci id="A4.p4.3.m3.1.1.cmml" xref="A4.p4.3.m3.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.p4.3.m3.1c">y</annotation></semantics></math> given context <math id="A4.p4.4.m4.1" class="ltx_Math" alttext="x" display="inline"><semantics id="A4.p4.4.m4.1a"><mi id="A4.p4.4.m4.1.1" xref="A4.p4.4.m4.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="A4.p4.4.m4.1b"><ci id="A4.p4.4.m4.1.1.cmml" xref="A4.p4.4.m4.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.p4.4.m4.1c">x</annotation></semantics></math>. However, given our retrieval set which consists of variable length answers and image data, it is difficult to estimate <math id="A4.p4.5.m5.1" class="ltx_Math" alttext="\text{pkNN}(y|x)" display="inline"><semantics id="A4.p4.5.m5.1a"><mrow id="A4.p4.5.m5.1.1" xref="A4.p4.5.m5.1.1.cmml"><mtext id="A4.p4.5.m5.1.1.3" xref="A4.p4.5.m5.1.1.3a.cmml">pkNN</mtext><mo lspace="0em" rspace="0em" id="A4.p4.5.m5.1.1.2" xref="A4.p4.5.m5.1.1.2.cmml">​</mo><mrow id="A4.p4.5.m5.1.1.1.1" xref="A4.p4.5.m5.1.1.1.1.1.cmml"><mo stretchy="false" id="A4.p4.5.m5.1.1.1.1.2" xref="A4.p4.5.m5.1.1.1.1.1.cmml">(</mo><mrow id="A4.p4.5.m5.1.1.1.1.1" xref="A4.p4.5.m5.1.1.1.1.1.cmml"><mi id="A4.p4.5.m5.1.1.1.1.1.2" xref="A4.p4.5.m5.1.1.1.1.1.2.cmml">y</mi><mo fence="false" id="A4.p4.5.m5.1.1.1.1.1.1" xref="A4.p4.5.m5.1.1.1.1.1.1.cmml">|</mo><mi id="A4.p4.5.m5.1.1.1.1.1.3" xref="A4.p4.5.m5.1.1.1.1.1.3.cmml">x</mi></mrow><mo stretchy="false" id="A4.p4.5.m5.1.1.1.1.3" xref="A4.p4.5.m5.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A4.p4.5.m5.1b"><apply id="A4.p4.5.m5.1.1.cmml" xref="A4.p4.5.m5.1.1"><times id="A4.p4.5.m5.1.1.2.cmml" xref="A4.p4.5.m5.1.1.2"></times><ci id="A4.p4.5.m5.1.1.3a.cmml" xref="A4.p4.5.m5.1.1.3"><mtext id="A4.p4.5.m5.1.1.3.cmml" xref="A4.p4.5.m5.1.1.3">pkNN</mtext></ci><apply id="A4.p4.5.m5.1.1.1.1.1.cmml" xref="A4.p4.5.m5.1.1.1.1"><csymbol cd="latexml" id="A4.p4.5.m5.1.1.1.1.1.1.cmml" xref="A4.p4.5.m5.1.1.1.1.1.1">conditional</csymbol><ci id="A4.p4.5.m5.1.1.1.1.1.2.cmml" xref="A4.p4.5.m5.1.1.1.1.1.2">𝑦</ci><ci id="A4.p4.5.m5.1.1.1.1.1.3.cmml" xref="A4.p4.5.m5.1.1.1.1.1.3">𝑥</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.p4.5.m5.1c">\text{pkNN}(y|x)</annotation></semantics></math> directly from our data store. Consequently, we augment our model input with retrieval prompts to allow for the implicit learning of retrieval reliance in an end-to-end manner. Figure <a href="#A4.F7" title="Figure 7 ‣ Appendix D Attention Visualization ‣ Multimodal Prompt Retrieval for Generative Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> shows the average cross attention scores to the retrieval portion of the prompt when evaluating on test data. The results demonstrate that when the model prediction matches the retrieved answer, the attention scores to the corresponding prompt section are significantly higher. Based on this observation, we believe the model has learned how to weigh the retrieved information through end-to-end training.</p>
</div>
<figure id="A4.F6" class="ltx_figure"><img src="/html/2306.17675/assets/x9.png" id="A4.F6.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="461" height="652" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Selected encoder self-attention visualizations across different encoder layers and attention heads. ITK represents an image-token from the input image. </figcaption>
</figure>
<figure id="A4.F7" class="ltx_figure"><img src="/html/2306.17675/assets/x10.png" id="A4.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="346" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Average attention score to the retrieval prompt for each attention module in our T5 encoder. When the model predicts the retrieved answer, attention scores to the retrieved information is significantly higher. </figcaption>
</figure>
<figure id="A4.F8" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2306.17675/assets/x11.png" id="A4.F8.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="461" height="153" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2306.17675/assets/x12.png" id="A4.F8.g2" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="461" height="102" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span><span id="A4.F8.3.1" class="ltx_text ltx_font_italic">Top</span>: The original image and question input to the model, followed by the average attention scores for each image patch, with darker patches corresponding to lower scores. <span id="A4.F8.4.2" class="ltx_text ltx_font_italic">Bottom</span>: When predicting each word in the answer span, which input image regions are attended to.</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2306.17674" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2306.17675" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2306.17675">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2306.17675" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2306.17676" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Wed Feb 28 21:54:46 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
