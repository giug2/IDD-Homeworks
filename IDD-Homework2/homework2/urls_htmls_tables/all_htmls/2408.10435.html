<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Enhanced document retrieval with topic embeddings</title>
<!--Generated on Mon Aug 19 21:58:18 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="
Information retrieval,  document retrieval,  text embeddings
" lang="en" name="keywords"/>
<base href="/html/2408.10435v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2408.10435v1#S1" title="In Enhanced document retrieval with topic embeddings"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">I </span><span class="ltx_text ltx_font_smallcaps">Introduction</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.10435v1#S1.SS1" title="In I Introduction ‣ Enhanced document retrieval with topic embeddings"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">I-A</span> </span><span class="ltx_text ltx_font_italic">Retrieval-Augmented Generation</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.10435v1#S1.SS2" title="In I Introduction ‣ Enhanced document retrieval with topic embeddings"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">I-B</span> </span><span class="ltx_text ltx_font_italic">Proposal</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2408.10435v1#S2" title="In Enhanced document retrieval with topic embeddings"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">II </span><span class="ltx_text ltx_font_smallcaps">Related Work</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2408.10435v1#S3" title="In Enhanced document retrieval with topic embeddings"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">III </span><span class="ltx_text ltx_font_smallcaps">Methods</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.10435v1#S3.SS1" title="In III Methods ‣ Enhanced document retrieval with topic embeddings"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-A</span> </span><span class="ltx_text ltx_font_italic">Topic-enhanced document embeddings</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.10435v1#S3.SS2" title="In III Methods ‣ Enhanced document retrieval with topic embeddings"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-B</span> </span><span class="ltx_text ltx_font_italic">Two-stage document retrieval</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2408.10435v1#S4" title="In Enhanced document retrieval with topic embeddings"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">IV </span><span class="ltx_text ltx_font_smallcaps">Results</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.10435v1#S4.SS1" title="In IV Results ‣ Enhanced document retrieval with topic embeddings"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-A</span> </span><span class="ltx_text ltx_font_italic">Experiments</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.10435v1#S4.SS2" title="In IV Results ‣ Enhanced document retrieval with topic embeddings"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-B</span> </span><span class="ltx_text ltx_font_italic">Challenges and limitations</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2408.10435v1#S5" title="In Enhanced document retrieval with topic embeddings"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">V </span><span class="ltx_text ltx_font_smallcaps">Conclusion</span></span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Enhanced document retrieval with topic embeddings</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Kavsar Huseynova
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_font_italic" id="id1.1.id1">Information Technology Department</span>
<br class="ltx_break"/><span class="ltx_text ltx_font_italic" id="id2.2.id2">Baku Higher Oil School
<br class="ltx_break"/></span>Baku, Azerbaijan 
<br class="ltx_break"/>kavsar.huseynova.std@bhos.edu.az
<br class="ltx_break"/>0009-0007-0362-9591
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jafar Isbarov
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_font_italic" id="id3.1.id1">Department of Computer Science</span>
<br class="ltx_break"/><span class="ltx_text ltx_font_italic" id="id4.2.id2">George Washington University
<br class="ltx_break"/></span>Washington, D.C., the U.S. 
<br class="ltx_break"/>jafar.isbarov@gwmail.gwu.edu
<br class="ltx_break"/>0000-0001-8404-2192 
</span></span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id5.id1">Document retrieval systems have experienced a revitalized interest with the advent of retrieval-augmented generation (RAG). RAG architecture offers a lower hallucination rate than LLM-only applications. However, the accuracy of the retrieval mechanism is known to be a bottleneck in the efficiency of these applications. A particular case of subpar retrieval performance is observed in situations where multiple documents from several different but related topics are in the corpus. We have devised a new vectorization method that takes into account the topic information of the document. The paper introduces this new method for text vectorization and evaluates it in the context of RAG. Furthermore, we discuss the challenge of evaluating RAG systems, which pertains to the case at hand.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
Information retrieval, document retrieval, text embeddings

</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span class="ltx_text ltx_font_smallcaps" id="S1.1.1">Introduction</span>
</h2>
<section class="ltx_subsection" id="S1.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S1.SS1.4.1.1">I-A</span> </span><span class="ltx_text ltx_font_italic" id="S1.SS1.5.2">Retrieval-Augmented Generation</span>
</h3>
<div class="ltx_para" id="S1.SS1.p1">
<p class="ltx_p" id="S1.SS1.p1.1">Retrieval-augmented generation (RAG) systems allow us to create chatbots on large text corpora, such as law corpus, textbooks, and software documentation.
RAG was introduced by <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.10435v1#bib.bib1" title="">1</a>]</cite>. It has seen a sudden rise in popularity due to the availability of improved large language models (LLMs), especially since the release of LLaMA models <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.10435v1#bib.bib2" title="">2</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S1.SS1.p2">
<p class="ltx_p" id="S1.SS1.p2.1">RAG system works as follows: (1) Text corpus is split into chunks and each chunk is vectorized. (2) User query is vectorized. (3) A similarity search is performed to find the chunk closest to the vectorized query. (4) The retrieved chunk is fed to the LLM along with the user query. (5) LLM uses this input to generate a free-form response.</p>
</div>
<div class="ltx_para" id="S1.SS1.p3">
<p class="ltx_p" id="S1.SS1.p3.1">One of the main bottlenecks in the performance of RAG systems is the retrieval step. The accuracy of the similarity search depends on multiple factors, including the choice of the similarity search algorithm, embedding method, and size of the indexed corpus. Corpus size becomes especially problematic if we are dealing with very similar documents.</p>
</div>
</section>
<section class="ltx_subsection" id="S1.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S1.SS2.4.1.1">I-B</span> </span><span class="ltx_text ltx_font_italic" id="S1.SS2.5.2">Proposal</span>
</h3>
<div class="ltx_para" id="S1.SS2.p1">
<p class="ltx_p" id="S1.SS2.p1.1">In most cases, we are not dealing with raw text data. Instead, the text comes with ample metadata that can be used to boost the performance of the similarity search. Our proposal is to use the available topic information of each chunk (i.e. document) and add it to the retrieval process. We have successfully implemented two such methods in industrial settings, and this paper attempts to generalize and evaluate these methods. The first method relies on creating a new document embedding by combining the original document embedding with the topic embeddings generated from the entire topic. The second method consists of two steps (1) find the topic, and (2) find the document within the topic.</p>
</div>
<div class="ltx_para" id="S1.SS2.p2">
<p class="ltx_p" id="S1.SS2.p2.1">Our contributions in this paper are as follows:</p>
<ol class="ltx_enumerate" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">Propose two new methods for using topic metadata during the document retrieval process.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">Evaluate the suggested methods with calculating the distance measures on embedded documents.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">Propose a detailed problem statement for the next stages of this work.</p>
</div>
</li>
</ol>
</div>
<div class="ltx_para" id="S1.SS2.p3">
<p class="ltx_p" id="S1.SS2.p3.1">The paper is structured as follows: The next section contains a review of relevant literature on these topics. The third section provides a detailed explanation of the proposed methods. The fourth section consists of two parts. First part outlines our experiments, their explanations, and results. A comprehensive discussion of our results, the main shortcomings of our work, as well as suggestions for future research take place in the second part. We conclude with the paper in the fifth section.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span class="ltx_text ltx_font_smallcaps" id="S2.1.1">Related Work</span>
</h2>
<figure class="ltx_figure" id="S2.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="365" id="S2.F1.g1" src="extracted/5799188/topic.jpeg" width="897"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Process for generating topic embeddings from original documents.</figcaption>
</figure>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">RAG was introduced by <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.10435v1#bib.bib1" title="">1</a>]</cite> in 2020. Their work underpins more advanced RAG systems that we see today. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.10435v1#bib.bib3" title="">3</a>]</cite> uses this idea to create a code summarization tool. Multimodal RAG systems are also seeing increasing popularity. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.10435v1#bib.bib4" title="">4</a>]</cite> implements a competitive image and caption generation system with RAG architecture.</p>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">Vectorization is an integral part of RAG systems. Traditional vectorization techniques include bag-of-words <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.10435v1#bib.bib5" title="">5</a>]</cite>, which simply uses word frequency and term frequency-inverse document frequency <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.10435v1#bib.bib6" title="">6</a>]</cite>, which additionally takes into account how unique the word is to a particular document.</p>
</div>
<div class="ltx_para" id="S2.p3">
<p class="ltx_p" id="S2.p3.1">Relatively modern approaches include Word2Vec, GloVe, and fastText. Word2Vec <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.10435v1#bib.bib7" title="">7</a>]</cite> can use either continuous bag-of-words or continuous skipgram models. GloVe <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.10435v1#bib.bib8" title="">8</a>]</cite> is a log-bilinear regression model that was trained on a word-word cooccurrence matrix. fastText <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.10435v1#bib.bib9" title="">9</a>]</cite> is a skip-gram model that treats words as a combination of character n-grams.</p>
</div>
<div class="ltx_para" id="S2.p4">
<p class="ltx_p" id="S2.p4.1">The latest family of text vectorization methods relies on transformer-based language models. BERT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.10435v1#bib.bib10" title="">10</a>]</cite> is a textbook example of this. These models usually use a masked attention mechanism to learn the context of tokens in a text. This information can later be used in various tasks, such as named entity recognition and sentiment analysis. The main advantage of this approach is that embeddings are contextual, i.e. they change depending on their place in the text. This is not the case with the aforementioned methods.</p>
</div>
<div class="ltx_para" id="S2.p5">
<p class="ltx_p" id="S2.p5.1"><cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.10435v1#bib.bib11" title="">11</a>]</cite> exploits inherent hierarchical structure in the data during the embedding process. Our work is similar but distinct: We use explicit hierarchy, not implicit. As far as we know, no work has attempted this. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.10435v1#bib.bib12" title="">12</a>]</cite> attempts a similar approach to enhance the performance of image classification models on ImageNet.</p>
</div>
<div class="ltx_para" id="S2.p6">
<p class="ltx_p" id="S2.p6.1">All of the mentioned works are either language-agnostic, or English-specific. Our dataset is in Azerbaijani, therefore works for the Azerbaijani language are of special interest to us.</p>
</div>
<div class="ltx_para" id="S2.p7">
<p class="ltx_p" id="S2.p7.1">Among the open-source embedding models, some claim to have an understanding of the Azerbaijani language. Google has released a multilingual version of the famous BERT model. We are aware of several unpublished attempts to use this model (directly or by fine-tuning) for various NLP tasks in Azerbaijani, all of them with limited success. Due to this, we avoided using the model as an embedder. Another multilingual model that has some understanding of Azerbaijani is mGPT. This is an unofficial version of the GPT-2 model released by <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.10435v1#bib.bib13" title="">13</a>]</cite> that was trained in a text corpus consisting of multiple languages. Its text generation capabilities in Azerbaijani are not satisfactory. This is why we did not use it in the generation part of our RAG systems.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span class="ltx_text ltx_font_smallcaps" id="S3.1.1">Methods</span>
</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">We propose two new methods that use topic information during document retrieval: topic-enhanced document embeddings, and two-stage document retrieval.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS1.4.1.1">III-A</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS1.5.2">Topic-enhanced document embeddings</span>
</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">Here, we create topic embeddings and then use these embeddings to update the original document embeddings in one of two ways.</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p2.1.1">Step 1: Create document embeddings.</span></p>
</div>
<div class="ltx_para" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.1">This is part of the traditional RAG pipeline. We simply chunk the document and embed these chunks separately.</p>
</div>
<div class="ltx_para" id="S3.SS1.p4">
<p class="ltx_p" id="S3.SS1.p4.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p4.1.1">Step 2: Separate documents into topics.</span></p>
</div>
<div class="ltx_para" id="S3.SS1.p5">
<p class="ltx_p" id="S3.SS1.p5.1">We assume the topic information is provided either implicitly or explicitly. In any case, we need to have explicit topic labels by the end of this stage.</p>
</div>
<div class="ltx_para" id="S3.SS1.p6">
<p class="ltx_p" id="S3.SS1.p6.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p6.1.1">Step 3: Creating topic embeddings.</span></p>
</div>
<div class="ltx_para" id="S3.SS1.p7">
<p class="ltx_p" id="S3.SS1.p7.1">Topic embeddings are supposed to be a vector of the same size as document embeddings. If we are using a neural network like BERT to embed the text, we usually cannot feed the entire topic into the model. We can bypass this by taking an element-wise average of all document embeddings for that topic. If we are using a statistical method like TF-IDF, we can run it on the entire text regardless of the text length. However, we expect both the original document embeddings and the topic embeddings to use the same embedding method. Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.10435v1#S2.F1" title="Figure 1 ‣ II Related Work ‣ Enhanced document retrieval with topic embeddings"><span class="ltx_text ltx_ref_tag">1</span></a> visualizes the process of obtaining topic embeddings from documents.</p>
</div>
<div class="ltx_para" id="S3.SS1.p8">
<p class="ltx_p" id="S3.SS1.p8.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p8.1.1">Step 4: Update the document embeddings</span></p>
</div>
<div class="ltx_para" id="S3.SS1.p9">
<p class="ltx_p" id="S3.SS1.p9.1">We propose two alternate versions here:</p>
</div>
<div class="ltx_para" id="S3.SS1.p10">
<ol class="ltx_enumerate" id="S3.I1">
<li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S3.I1.i1.p1">
<p class="ltx_p" id="S3.I1.i1.p1.1"><span class="ltx_text ltx_font_italic" id="S3.I1.i1.p1.1.1">Average method</span>: Take an average of document embeddings and topic embeddings.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S3.I1.i2.p1">
<p class="ltx_p" id="S3.I1.i2.p1.1"><span class="ltx_text ltx_font_italic" id="S3.I1.i2.p1.1.1">Append method</span>: Concatenate document embeddings and topic embeddings.</p>
</div>
</li>
</ol>
<p class="ltx_p" id="S3.SS1.p10.1">The second method creates a new problem because now the embedding dimension of a query does not match the dimensions of our embedded documents. To solve this problem, we can duplicate the length of our query embeddings.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS2.4.1.1">III-B</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS2.5.2">Two-stage document retrieval</span>
</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">This is a much simpler approach. We create topic embeddings just like the first method, but we perform retrieval in two stages:</p>
<ol class="ltx_enumerate" id="S3.I2">
<li class="ltx_item" id="S3.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S3.I2.i1.p1">
<p class="ltx_p" id="S3.I2.i1.p1.1">Retrieve a topic based on the topic-embeddings.</p>
</div>
</li>
<li class="ltx_item" id="S3.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S3.I2.i2.p1">
<p class="ltx_p" id="S3.I2.i2.p1.1">Retrieve a document within that topic.</p>
</div>
</li>
</ol>
<p class="ltx_p" id="S3.SS2.p1.2">However, two-stage retrieval system comes with own challenges. One of which is increased inference time.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span class="ltx_text ltx_font_smallcaps" id="S4.1.1">Results</span>
</h2>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS1.4.1.1">IV-A</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS1.5.2">Experiments</span>
</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">To evaluate these approaches, we have curated a dataset from Azerbaijani laws. We have selected 14 major laws and split them into chunks of 2000 characters. You can find these laws in Table <a class="ltx_ref" href="https://arxiv.org/html/2408.10435v1#S4.T1" title="TABLE I ‣ IV-A Experiments ‣ IV Results ‣ Enhanced document retrieval with topic embeddings"><span class="ltx_text ltx_ref_tag">I</span></a>. OpenAI’s ”text-embedding-3-small” embedding model has been used to embed the chunks. Each law is treated as a distinct topic. We then used both the average method and the append method to update the document embeddings.</p>
</div>
<figure class="ltx_table" id="S4.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE I: </span>Azerbaijani laws in our dataset.</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S4.T1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.1.1.1">Topic</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.1.2.1">Chunk Count</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T1.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S4.T1.1.2.1.1">Criminal Code</th>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T1.1.2.1.2">716</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S4.T1.1.3.2.1">Code of Criminal Procedure</th>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T1.1.3.2.2">1035</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S4.T1.1.4.3.1">Customs Code</th>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T1.1.4.3.2">280</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S4.T1.1.5.4.1">Constitution</th>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T1.1.5.4.2">100</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S4.T1.1.6.5.1">Forest Code</th>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T1.1.6.5.2">60</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.7.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S4.T1.1.7.6.1">Civil Procedure Code</th>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T1.1.7.6.2">551</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.8.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S4.T1.1.8.7.1">Civil Code</th>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T1.1.8.7.2">1283</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.9.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S4.T1.1.9.8.1">Migration Code</th>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T1.1.9.8.2">181</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.10.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S4.T1.1.10.9.1">Water Code</th>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T1.1.10.9.2">76</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.11.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S4.T1.1.11.10.1">Land Code</th>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T1.1.11.10.2">150</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.12.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S4.T1.1.12.11.1">Tax Code</th>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T1.1.12.11.2">1122</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.13.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S4.T1.1.13.12.1">Code on Administrative Violations</th>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T1.1.13.12.2">781</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.14.13">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="S4.T1.1.14.13.1">Labor Code</th>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T1.1.14.13.2">414</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.15.14">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="S4.T1.1.15.14.1">Education Law</th>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S4.T1.1.15.14.2">129</td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1">By treating topics (i.e., laws) as cluster labels, we have evaluated the ”clustering results” of three methods:</p>
<ul class="ltx_itemize" id="S4.I1">
<li class="ltx_item" id="S4.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i1.p1">
<p class="ltx_p" id="S4.I1.i1.p1.1">original embeddings</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i2.p1">
<p class="ltx_p" id="S4.I1.i2.p1.1">averaged embeddings</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i3.p1">
<p class="ltx_p" id="S4.I1.i3.p1.1">appended embeddings</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S4.SS1.p3">
<p class="ltx_p" id="S4.SS1.p3.1">To visualize the embeddings of different methods, the tSNE algorithm has been used to reduce the number of dimensions to 2 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.10435v1#bib.bib14" title="">14</a>]</cite>. You can see the results in Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.10435v1#S4.F2.sf1" title="In Figure 2 ‣ IV-A Experiments ‣ IV Results ‣ Enhanced document retrieval with topic embeddings"><span class="ltx_text ltx_ref_tag">2a</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2408.10435v1#S4.F2.sf2" title="In Figure 2 ‣ IV-A Experiments ‣ IV Results ‣ Enhanced document retrieval with topic embeddings"><span class="ltx_text ltx_ref_tag">2b</span></a>.</p>
</div>
<div class="ltx_para" id="S4.SS1.p4">
<p class="ltx_p" id="S4.SS1.p4.1">To accurately evaluate our proposed methods, it is essential to use a dedicated RAG evaluation dataset. Although we initially attempted to construct this dataset synthetically, we recognized the limitations of this approach and concluded that a natural evaluation dataset is necessary. We have explored this issue in detail in the section B.</p>
</div>
<div class="ltx_para" id="S4.SS1.p5">
<p class="ltx_p" id="S4.SS1.p5.1">Another approach to calculate the performance of these ”clustering models” is using the cluster validity indices. These indices provide insights into how well the embeddings separate different topics, which is crucial for ensuring that similar documents are grouped effectively—a key factor in improving retrieval performance.</p>
</div>
<div class="ltx_para" id="S4.SS1.p6">
<p class="ltx_p" id="S4.SS1.p6.1">We have used three different indices:</p>
<ul class="ltx_itemize" id="S4.I2">
<li class="ltx_item" id="S4.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i1.p1">
<p class="ltx_p" id="S4.I2.i1.p1.1">Silhouette Coefficient</p>
</div>
</li>
<li class="ltx_item" id="S4.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i2.p1">
<p class="ltx_p" id="S4.I2.i2.p1.1">Davies–Bouldin index</p>
</div>
</li>
<li class="ltx_item" id="S4.I2.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i3.p1">
<p class="ltx_p" id="S4.I2.i3.p1.1">Calinski–Harabasz index</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S4.SS1.p7">
<p class="ltx_p" id="S4.SS1.p7.1">The Silhouette Coefficient, ranging from -1 to +1, measures clustering effectiveness, with higher values indicating better clustering. In contrast, the Davies-Bouldin Index (DBI) assesses cluster separation and compactness, where lower values signify better quality. The Calinski-Harabasz (CH) Index evaluates how well-separated and dense clusters are, with higher values indicating better clusters, typically identified by a peak in the index. Together, these metrics provide a comprehensive assessment of clustering performance.</p>
</div>
<div class="ltx_para" id="S4.SS1.p8">
<p class="ltx_p" id="S4.SS1.p8.1">The results are available in Table <a class="ltx_ref" href="https://arxiv.org/html/2408.10435v1#S4.T2" title="TABLE II ‣ IV-A Experiments ‣ IV Results ‣ Enhanced document retrieval with topic embeddings"><span class="ltx_text ltx_ref_tag">II</span></a>. As you can see, adding topic embeddings to the original embeddings results in better separation of different topics. The average method performs better than the append method, although we suspect that it may be data-specific. As future work, these experiments can be performed on larger and more variable datasets to assess the methods’ performance against each other.</p>
</div>
<div class="ltx_para" id="S4.SS1.p9">
<p class="ltx_p" id="S4.SS1.p9.1">We were unable to evaluate the ’Two-stage document retrieval’ method due to limitations in the evaluation dataset, which will be discussed further.</p>
</div>
<figure class="ltx_figure" id="S4.F2">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F2.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="501" id="S4.F2.sf1.g1" src="extracted/5799188/normal_2000.jpeg" width="598"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F2.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="505" id="S4.F2.sf2.g1" src="extracted/5799188/avg.jpeg" width="598"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F2.sf3"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="598" id="S4.F2.sf3.g1" src="extracted/5799188/append_2000.jpeg" width="598"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(c) </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>2D visualization of topics with (a) original embeddings, (b) averaged embeddings, (c) appended embeddings.</figcaption>
</figure>
<figure class="ltx_table" id="S4.T2">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE II: </span>Performance of original and topic-based clustering. DBI: Davies–Bouldin index, CHI: Calinski–Harabasz index.</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T2.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T2.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t" id="S4.T2.1.1.1.1">Metric</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T2.1.1.1.2">Original</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T2.1.1.1.3">Average</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T2.1.1.1.4">Append</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T2.1.2.1">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S4.T2.1.2.1.1">Silhouette</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T2.1.2.1.2">0.01</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T2.1.2.1.3"><span class="ltx_text ltx_font_bold" id="S4.T2.1.2.1.3.1">0.11</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T2.1.2.1.4">0.06</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.3.2">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S4.T2.1.3.2.1">DBI</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T2.1.3.2.2">4.60</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T2.1.3.2.3"><span class="ltx_text ltx_font_bold" id="S4.T2.1.3.2.3.1">2.30</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T2.1.3.2.4">3.25</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.4.3">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="S4.T2.1.4.3.1">CHI</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S4.T2.1.4.3.2">63.42</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S4.T2.1.4.3.3"><span class="ltx_text ltx_font_bold" id="S4.T2.1.4.3.3.1">253.67</span></td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S4.T2.1.4.3.4">126.84</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS2.4.1.1">IV-B</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS2.5.2">Challenges and limitations</span>
</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">The main challenge we are facing is the lack of an end-to-end evaluation dataset. This dataset needs to have the following features:</p>
<ul class="ltx_itemize" id="S4.I3">
<li class="ltx_item" id="S4.I3.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I3.i1.p1">
<p class="ltx_p" id="S4.I3.i1.p1.1">A text corpus with topic labels</p>
</div>
</li>
<li class="ltx_item" id="S4.I3.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I3.i2.p1">
<p class="ltx_p" id="S4.I3.i2.p1.1">Natural queries that can be answered based on a part of this corpus.</p>
</div>
</li>
</ul>
<p class="ltx_p" id="S4.SS2.p1.2">Using this dataset, one can first embed the queries with traditional and our proposed methods, then run the similarity search on each of them to match the queries with respective documents, and hence get an evaluation score to make a fair comparison between traditional RAG system and our approach.</p>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1">This first feature is easy to attain. We have already performed some analysis on such datasets. We have attempted to gain the second feature by synthetic query generation, but it did not achieve any better result than normal RAG system, because generated queries are highly specific to the chunk provided. For example, we used the following query:</p>
<blockquote class="ltx_quote ltx_displayquote" id="S4.SS2.p2.2">
<p class="ltx_p" id="S4.SS2.p2.2.1"><span class="ltx_text ltx_inline-quote" id="S4.SS2.p2.2.1.1"><span class="ltx_text ltx_font_italic" id="S4.SS2.p2.2.1.1.1">
”</span><span class="ltx_text ltx_font_bold" id="S4.SS2.p2.2.1.1.2">Given the following context, generate a question that would be asked by a curious citizen:</span><span class="ltx_text ltx_font_italic" id="S4.SS2.p2.2.1.1.3">
Context:
Article 25. Right to equality
I. Everyone shall be equal before the law and the courts.
II. Men and women possess equal rights and freedoms.
III. The State shall guarantee the equality of rights and freedoms to everyone, irrespective of race, ethnicity, religion, language, sex, origin, property status, occupation, beliefs or affiliation with political parties, trade union organisations or other public associations. Restrictions of rights and freedoms on the grounds of race, ethnicity, religion, language, sex, origin, beliefs, or political or social affiliation are prohibited.
IV. No one may be harmed, granted advantages or privileges, or refused to be granted advantages and privileges on the grounds laid down in Paragraph III of the present Article.
V. Everyone shall be guaranteed equal rights in any proceeding before state authorities and bearers of public authority that decide upon his/her rights and duties.
VI. Persons with impaired health are entitled to all rights and carry all duties enshrined in this Constitution, except in cases when enjoyment of rights and performance of duties is impeded by their limited abilities.”
</span></span></p>
</blockquote>
</div>
<div class="ltx_para" id="S4.SS2.p3">
<p class="ltx_p" id="S4.SS2.p3.1">This resulted in the following response:</p>
<blockquote class="ltx_quote ltx_displayquote" id="S4.SS2.p3.2">
<p class="ltx_p" id="S4.SS2.p3.2.1"><span class="ltx_text ltx_inline-quote" id="S4.SS2.p3.2.1.1"><span class="ltx_text ltx_font_italic" id="S4.SS2.p3.2.1.1.1">
”What measures are in place to ensure enforcement of Article 25, particularly regarding equality before the law and in courts, as well as the guarantee of equal rights and freedoms regardless of various personal characteristics?”
</span></span></p>
</blockquote>
</div>
<div class="ltx_para" id="S4.SS2.p4">
<p class="ltx_p" id="S4.SS2.p4.1">As you can see, if we generate a large dataset automatically using these prompts, we will end up with questions that exactly match the provided context (i.e., chunk). Because the content of the queries are highly related with the document chunks, our proposed methods achieve similar performance as the traditional RAG system.</p>
</div>
<div class="ltx_para" id="S4.SS2.p5">
<p class="ltx_p" id="S4.SS2.p5.1">Although the synthetic query generation attempts did not work, we have tried it on the English version of our dataset. As far as we are concerned, no LLM can generate natural text in Azerbaijani at a level that would be sufficient for this task. Due to these restrictions, we are researching the possibility of creating a natural dataset. We can use logs of one of our chatbots in production for this, or we can create an annotator team to build the dataset.</p>
</div>
<div class="ltx_para" id="S4.SS2.p6">
<p class="ltx_p" id="S4.SS2.p6.1">Another inherent limitation of our approach is that it depends on the existence of topic metadata. It would be interesting to devise a method to infer the topic information from the raw data itself, although we do not believe that there is a generalizable approach to this problem.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span class="ltx_text ltx_font_smallcaps" id="S5.1.1">Conclusion</span>
</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">This paper introduces an enhanced vectorization technique for document retrieval. As RAG applications become increasingly popular, it is important to handle the challenge of having a large number of documents within the same database. We proposed two new methods that utilize the provided topic information in the text corpus. We have shown that by implementing our two novel approaches, the distance between different documents can be broadened through the introduction of topic embeddings, potentially resulting in more accurate similarity searches. Despite our progress in RAG application, there is a need to refine evaluation techniques. To ensure accurate and representative performance assessments of our research, an end-to-end evaluation dataset should be curated. As future work, evaluating our method in multiple languages would better demonstrate its generality.</p>
</div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_font_smallcaps ltx_title_section">Acknowledgements</h2>
<div class="ltx_para" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">The authors declare that this manuscript is original, has not been published before, and is not currently being considered for publication elsewhere.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
P. Lewis, E. Perez, A. Piktus, F. Petroni, V. Karpukhin, N. Goyal, H. Küttler, M. Lewis, W.-t. Yih, T. Rocktäschel, S. Riedel, and D. Kiela, “Retrieval-augmented generation for knowledge-intensive nlp tasks,” in <em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">Proceedings of the 34th International Conference on Neural Information Processing Systems</em>, ser. NIPS’20.   Red Hook, NY, USA: Curran Associates Inc., 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux, T. Lacroix, B. Rozière, N. Goyal, E. Hambro, F. Azhar, A. Rodriguez, A. Joulin, E. Grave, and G. Lample, “Llama: Open and efficient foundation language models,” 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
S. Liu, Y. Chen, X. Xie, J. Siow, and Y. Liu, “Retrieval-augmented generation for code summarization via hybrid gnn,” 2020. [Online]. Available: https://api.semanticscholar.org/CorpusID:234487049

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
M. Yasunaga, A. Aghajanyan, W. Shi, R. James, J. Leskovec, P. Liang, M. Lewis, L. Zettlemoyer, and W.-t. Yih, “Retrieval-augmented multimodal language modeling,” ser. ICML’23.   JMLR.org, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
W. A. Qader, M. M. Ameen, and B. I. Ahmed, “An overview of bag of words;importance, implementation, applications, and challenges,” in <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">2019 International Engineering Conference (IEC)</em>, 2019, pp. 200–204.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
S. Qaiser and R. Ali, “Text mining: Use of tf-idf to examine the relevance of words to documents,” <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">International Journal of Computer Applications</em>, 2018. [Online]. Available: https://api.semanticscholar.org/CorpusID:53702508

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
T. Mikolov, K. Chen, G. S. Corrado, and J. Dean, “Efficient estimation of word representations in vector space,” in <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">International Conference on Learning Representations</em>, 2013. [Online]. Available: https://api.semanticscholar.org/CorpusID:5959482

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
J. Pennington, R. Socher, and C. Manning, “GloVe: Global vectors for word representation,” in <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>, A. Moschitti, B. Pang, and W. Daelemans, Eds.   Doha, Qatar: Association for Computational Linguistics, Oct. 2014, pp. 1532–1543. [Online]. Available: https://aclanthology.org/D14-1162

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
P. Bojanowski, E. Grave, A. Joulin, and T. Mikolov, “Enriching word vectors with subword information,” <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">Transactions of the Association for Computational Linguistics</em>, vol. 5, pp. 135–146, 2016. [Online]. Available: https://api.semanticscholar.org/CorpusID:207556454

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, “Bert: Pre-training of deep bidirectional transformers for language understanding,” in <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">North American Chapter of the Association for Computational Linguistics</em>, 2019. [Online]. Available: https://api.semanticscholar.org/CorpusID:52967399

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
M. Nickel and D. Kiela, “Poincaré embeddings for learning hierarchical representations,” in <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">Advances in Neural Information Processing Systems</em>, I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, Eds., vol. 30.   Curran Associates, Inc., 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
B. Barz and J. Denzler, “Hierarchy-based image embeddings for semantic image retrieval,” in <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">2019 IEEE Winter Conference on Applications of Computer Vision (WACV)</em>, 2019, pp. 638–647.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
O. Shliazhko, A. Fenogenova, M. Tikhonova, V. Mikhailov, A. Kozlova, and T. Shavrina, “mgpt: Few-shot learners go multilingual,” 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
T. T. Cai and R. Ma, “Theoretical foundations of t-sne for visualizing high-dimensional clustered data,” <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">J. Mach. Learn. Res.</em>, vol. 23, no. 1, jan 2022.

</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Mon Aug 19 21:58:18 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
