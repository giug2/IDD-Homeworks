<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2103.11226] Demystifying the Effects of Non-Independence in Federated Learning</title><meta property="og:description" content="Federated Learning (FL) enables statistical models to be built on user-generated data without compromising data security and user privacy. For this reason, FL is well suited for on-device learning from mobile devices w…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Demystifying the Effects of Non-Independence in Federated Learning">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Demystifying the Effects of Non-Independence in Federated Learning">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2103.11226">

<!--Generated on Sat Mar 16 20:02:48 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Demystifying the Effects of Non-Independence in Federated Learning</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Stefan Arnold
<br class="ltx_break">Friedrich-Alexander-University
<br class="ltx_break">Erlangen-Nuremberg
<br class="ltx_break">Institute of Information Systems
<br class="ltx_break">90403 Nuremberg, Germany
<br class="ltx_break"><span id="id2.1.id1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">stefan.st.arnold@fau.de</span>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Dilara Yesilbas
<br class="ltx_break">Friedrich-Alexander-University
<br class="ltx_break">Erlangen-Nuremberg
<br class="ltx_break">Institute of Information Systems
<br class="ltx_break">90403 Nuremberg, Germany
<br class="ltx_break"><span id="id3.1.id1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">dilara.yesilbas@fau.de</span>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.1" class="ltx_p">Federated Learning (FL) enables statistical models to be built on user-generated data without compromising data security and user privacy. For this reason, FL is well suited for on-device learning from mobile devices where data is abundant and highly privatized. Constrained by the temporal availability of mobile devices, only a subset of devices is accessible to participate in the iterative protocol consisting of training and aggregation. In this study, we take a step toward better understanding the effect of non-independent data distributions arising from block-cyclic sampling. By conducting extensive experiments on visual classification, we measure the effects of block-cyclic sampling (both standalone and in combination with non-balanced block distributions). Specifically, we measure the alterations induced by block-cyclic sampling from the perspective of accuracy, fairness, and convergence rate. Experimental results indicate robustness to cycling over a two-block structure, e.g., due to time zones. In contrast, drawing data samples dependently from a multi-block structure significantly degrades the performance and rate of convergence by up to <math id="id1.1.m1.1" class="ltx_Math" alttext="26" display="inline"><semantics id="id1.1.m1.1a"><mn id="id1.1.m1.1.1" xref="id1.1.m1.1.1.cmml">26</mn><annotation-xml encoding="MathML-Content" id="id1.1.m1.1b"><cn type="integer" id="id1.1.m1.1.1.cmml" xref="id1.1.m1.1.1">26</cn></annotation-xml><annotation encoding="application/x-tex" id="id1.1.m1.1c">26</annotation></semantics></math>%. Moreover, we find that this performance degeneration is further aggravated by unbalanced block distributions to a point that can no longer be adequately compensated by higher communication and more frequent synchronization.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p"><span id="S1.p1.1.1" class="ltx_text ltx_font_italic">Federated Learning</span> (FL) was introduced by McMahan <em id="S1.p1.1.2" class="ltx_emph ltx_font_italic">et al</em>.<span id="S1.p1.1.3" class="ltx_text"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite> with an initial emphasis on applications for mobile devices, <em id="S1.p1.1.4" class="ltx_emph ltx_font_italic">e.g</em>.<span id="S1.p1.1.5" class="ltx_text"></span>, keyboard prediction <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib31" title="" class="ltx_ref">31</a>, <a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>. Following the recent interest in using FL for other applications <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>, it has emerged as the leading paradigm to address the omnipresent conflict between utility and privacy of user-generated data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">FL poses challenges that differ fundamentally from distributed optimization <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>. In particular, FL is exposed to statistical heterogeneity. When referring to statistical heterogeneity, it means that user-generated data residing on mobile devices usually follows a non-representative distribution of the total population. This statistical heterogeneity is violating the fundamental assumptions of independent and identical distributions (i.i.d.). Data non-compliance with i.i.d. (non-i.i.d.) has been observed to induce a divergence to the model weights which may significantly degrade the performance and convergence of FL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite>. The problem of non-i.i.d. data is further complicated by the fact that the data in practical FL environments are massively and unbalanced distributed across devices.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">In this study, we respond to the recent call of Kairouz <em id="S1.p3.1.1" class="ltx_emph ltx_font_italic">et al</em>.<span id="S1.p3.1.2" class="ltx_text"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> to extend the current understanding of the non-i.i.d. and unbalanced properties of FL. Most studies in terms of statistical heterogeneity have been devoted to challenges of non-identical data distributions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite> or non-balanced data distributions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib39" title="" class="ltx_ref">39</a>, <a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>. Although non-independence is a common phenomenon in FL, mainly due to temporal unavailability of mobile devices <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>, almost no research is concerned with non-independent data distributions. For this reason, we focus on quantifying and understanding the implications brought by block-cyclic sampling with and without additional block imbalance. We particularly emphasize on accuracy parity <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite> among clients <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">The remainder of this study is organized as follows: In Section <a href="#S2" title="2 Background ‣ Demystifying the Effects of Non-Independence in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, we elaborate on the theoretical background of statistical heterogeneity and briefly review related work. In Section <a href="#S3" title="3 Methodology ‣ Demystifying the Effects of Non-Independence in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, we explain the experimental setup that has been used to simulate and analyze block-cyclic sampling. This includes data preparation and the manipulation of the vanilla FL selection protocol. In Section <a href="#S4" title="4 Experiments ‣ Demystifying the Effects of Non-Independence in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, we present the results obtained given both a fixed and fine-tuned optimization budget. Our empirical results help to illustrate and validate the performance of FL in applications consisting of heterogeneous blocks. In Section <a href="#S5" title="5 Conclusion ‣ Demystifying the Effects of Non-Independence in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, we conclude our research by advocating carefully tuned hyperparameters and call for the development of novel algorithmic subroutines to address the problem of data dependence.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Background</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">Coordinated by a central parameter server, FL builds a statistical model using an iterative multi-step protocol. Each iteration constitutes a round of communication between the central server and the devices at the edge, also known as <span id="S2.p1.1.1" class="ltx_text ltx_font_italic">clients</span>. At the beginning of the protocol, a statistical model with a fixed model structure is compiled using a generic initialization <math id="S2.p1.1.m1.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="S2.p1.1.m1.1a"><mi id="S2.p1.1.m1.1.1" xref="S2.p1.1.m1.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="S2.p1.1.m1.1b"><ci id="S2.p1.1.m1.1.1.cmml" xref="S2.p1.1.m1.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.1.m1.1c">\theta</annotation></semantics></math>. In each round, a random subset of clients is selected for improving the global model. To improve the global model, the server broadcasts a copy of the global model to a randomly selected portion of available clients. Every client then trains its copy by performing multiple local updates based on their local data. To perform local updates, stochastic gradient descent (SGD) is typically applied. Upon completing a fixed number of local updates, clients report the changes made to the copy of the global model back to the central server. This report takes the form of a <span id="S2.p1.1.2" class="ltx_text ltx_font_italic">d</span>-dimensional vector of model weights. After aggregating the local updates from the selected subset of clients, the central server calculates a weighted average of the received model weights to obtain an optimized global model. The vanilla averaging procedure in FL is termed <span id="S2.p1.1.3" class="ltx_text ltx_font_typewriter">FedAvg</span>. Implementation details of <span id="S2.p1.1.4" class="ltx_text ltx_font_typewriter">FedAvg</span> are shown in Algorithm <a href="#alg1" title="Algorithm 1 ‣ 2 Background ‣ Demystifying the Effects of Non-Independence in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. The aggregation concludes one round of communication. By dispatching the updated global model to another random subset of clients, the process repeats itself until a fixed communication budget is depleted or convergence is achieved.</p>
</div>
<figure id="alg1" class="ltx_float ltx_float_algorithm ltx_framed ltx_framed_top">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span id="alg1.12.1.1" class="ltx_text ltx_font_bold">Algorithm 1</span> </span> Federated Averaging. The <math id="alg1.6.m1.1" class="ltx_Math" alttext="K" display="inline"><semantics id="alg1.6.m1.1b"><mi id="alg1.6.m1.1.1" xref="alg1.6.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="alg1.6.m1.1c"><ci id="alg1.6.m1.1.1.cmml" xref="alg1.6.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.6.m1.1d">K</annotation></semantics></math> clients are indexed by <math id="alg1.7.m2.1" class="ltx_Math" alttext="k" display="inline"><semantics id="alg1.7.m2.1b"><mi id="alg1.7.m2.1.1" xref="alg1.7.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="alg1.7.m2.1c"><ci id="alg1.7.m2.1.1.cmml" xref="alg1.7.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.7.m2.1d">k</annotation></semantics></math>; <math id="alg1.8.m3.1" class="ltx_Math" alttext="B" display="inline"><semantics id="alg1.8.m3.1b"><mi id="alg1.8.m3.1.1" xref="alg1.8.m3.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="alg1.8.m3.1c"><ci id="alg1.8.m3.1.1.cmml" xref="alg1.8.m3.1.1">𝐵</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.8.m3.1d">B</annotation></semantics></math> is the local mini-batch size, <math id="alg1.9.m4.1" class="ltx_Math" alttext="E" display="inline"><semantics id="alg1.9.m4.1b"><mi id="alg1.9.m4.1.1" xref="alg1.9.m4.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="alg1.9.m4.1c"><ci id="alg1.9.m4.1.1.cmml" xref="alg1.9.m4.1.1">𝐸</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.9.m4.1d">E</annotation></semantics></math> is the number of local epochs, and <math id="alg1.10.m5.1" class="ltx_Math" alttext="\eta" display="inline"><semantics id="alg1.10.m5.1b"><mi id="alg1.10.m5.1.1" xref="alg1.10.m5.1.1.cmml">η</mi><annotation-xml encoding="MathML-Content" id="alg1.10.m5.1c"><ci id="alg1.10.m5.1.1.cmml" xref="alg1.10.m5.1.1">𝜂</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.10.m5.1d">\eta</annotation></semantics></math> is the learning rate.</figcaption>
<div id="alg1.13" class="ltx_listing ltx_listing">
<div id="alg1.l1" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l1.1.1.1" class="ltx_text" style="font-size:80%;">1:</span></span><math id="alg1.l1.m1.1" class="ltx_Math" alttext="\text{global model }w_{0}" display="inline"><semantics id="alg1.l1.m1.1a"><mrow id="alg1.l1.m1.1.1" xref="alg1.l1.m1.1.1.cmml"><mtext id="alg1.l1.m1.1.1.2" xref="alg1.l1.m1.1.1.2a.cmml">global model </mtext><mo lspace="0em" rspace="0em" id="alg1.l1.m1.1.1.1" xref="alg1.l1.m1.1.1.1.cmml">​</mo><msub id="alg1.l1.m1.1.1.3" xref="alg1.l1.m1.1.1.3.cmml"><mi id="alg1.l1.m1.1.1.3.2" xref="alg1.l1.m1.1.1.3.2.cmml">w</mi><mn id="alg1.l1.m1.1.1.3.3" xref="alg1.l1.m1.1.1.3.3.cmml">0</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="alg1.l1.m1.1b"><apply id="alg1.l1.m1.1.1.cmml" xref="alg1.l1.m1.1.1"><times id="alg1.l1.m1.1.1.1.cmml" xref="alg1.l1.m1.1.1.1"></times><ci id="alg1.l1.m1.1.1.2a.cmml" xref="alg1.l1.m1.1.1.2"><mtext id="alg1.l1.m1.1.1.2.cmml" xref="alg1.l1.m1.1.1.2">global model </mtext></ci><apply id="alg1.l1.m1.1.1.3.cmml" xref="alg1.l1.m1.1.1.3"><csymbol cd="ambiguous" id="alg1.l1.m1.1.1.3.1.cmml" xref="alg1.l1.m1.1.1.3">subscript</csymbol><ci id="alg1.l1.m1.1.1.3.2.cmml" xref="alg1.l1.m1.1.1.3.2">𝑤</ci><cn type="integer" id="alg1.l1.m1.1.1.3.3.cmml" xref="alg1.l1.m1.1.1.3.3">0</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m1.1c">\text{global model }w_{0}</annotation></semantics></math>

</div>
<div id="alg1.l2" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l2.1.1.1" class="ltx_text" style="font-size:80%;">2:</span></span><span id="alg1.l2.2" class="ltx_text ltx_font_bold">procedure</span> <span id="alg1.l2.3" class="ltx_text ltx_font_smallcaps">ServerUpdate</span>

</div>
<div id="alg1.l3" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l3.1.1.1" class="ltx_text" style="font-size:80%;">3:</span></span>     <span id="alg1.l3.2" class="ltx_text ltx_font_bold">for</span> <math id="alg1.l3.m1.1" class="ltx_Math" alttext="\text{each round }t\in[T]" display="inline"><semantics id="alg1.l3.m1.1a"><mrow id="alg1.l3.m1.1.2" xref="alg1.l3.m1.1.2.cmml"><mrow id="alg1.l3.m1.1.2.2" xref="alg1.l3.m1.1.2.2.cmml"><mtext id="alg1.l3.m1.1.2.2.2" xref="alg1.l3.m1.1.2.2.2a.cmml">each round </mtext><mo lspace="0em" rspace="0em" id="alg1.l3.m1.1.2.2.1" xref="alg1.l3.m1.1.2.2.1.cmml">​</mo><mi id="alg1.l3.m1.1.2.2.3" xref="alg1.l3.m1.1.2.2.3.cmml">t</mi></mrow><mo id="alg1.l3.m1.1.2.1" xref="alg1.l3.m1.1.2.1.cmml">∈</mo><mrow id="alg1.l3.m1.1.2.3.2" xref="alg1.l3.m1.1.2.3.1.cmml"><mo stretchy="false" id="alg1.l3.m1.1.2.3.2.1" xref="alg1.l3.m1.1.2.3.1.1.cmml">[</mo><mi id="alg1.l3.m1.1.1" xref="alg1.l3.m1.1.1.cmml">T</mi><mo stretchy="false" id="alg1.l3.m1.1.2.3.2.2" xref="alg1.l3.m1.1.2.3.1.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l3.m1.1b"><apply id="alg1.l3.m1.1.2.cmml" xref="alg1.l3.m1.1.2"><in id="alg1.l3.m1.1.2.1.cmml" xref="alg1.l3.m1.1.2.1"></in><apply id="alg1.l3.m1.1.2.2.cmml" xref="alg1.l3.m1.1.2.2"><times id="alg1.l3.m1.1.2.2.1.cmml" xref="alg1.l3.m1.1.2.2.1"></times><ci id="alg1.l3.m1.1.2.2.2a.cmml" xref="alg1.l3.m1.1.2.2.2"><mtext id="alg1.l3.m1.1.2.2.2.cmml" xref="alg1.l3.m1.1.2.2.2">each round </mtext></ci><ci id="alg1.l3.m1.1.2.2.3.cmml" xref="alg1.l3.m1.1.2.2.3">𝑡</ci></apply><apply id="alg1.l3.m1.1.2.3.1.cmml" xref="alg1.l3.m1.1.2.3.2"><csymbol cd="latexml" id="alg1.l3.m1.1.2.3.1.1.cmml" xref="alg1.l3.m1.1.2.3.2.1">delimited-[]</csymbol><ci id="alg1.l3.m1.1.1.cmml" xref="alg1.l3.m1.1.1">𝑇</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l3.m1.1c">\text{each round }t\in[T]</annotation></semantics></math> <span id="alg1.l3.3" class="ltx_text ltx_font_bold">do</span>

</div>
<div id="alg1.l4" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l4.1.1.1" class="ltx_text" style="font-size:80%;">4:</span></span>         <math id="alg1.l4.m1.3" class="ltx_Math" alttext="m\leftarrow\max(C\times K,1)" display="inline"><semantics id="alg1.l4.m1.3a"><mrow id="alg1.l4.m1.3.3" xref="alg1.l4.m1.3.3.cmml"><mi id="alg1.l4.m1.3.3.3" xref="alg1.l4.m1.3.3.3.cmml">m</mi><mo stretchy="false" id="alg1.l4.m1.3.3.2" xref="alg1.l4.m1.3.3.2.cmml">←</mo><mrow id="alg1.l4.m1.3.3.1.1" xref="alg1.l4.m1.3.3.1.2.cmml"><mi id="alg1.l4.m1.1.1" xref="alg1.l4.m1.1.1.cmml">max</mi><mo id="alg1.l4.m1.3.3.1.1a" xref="alg1.l4.m1.3.3.1.2.cmml">⁡</mo><mrow id="alg1.l4.m1.3.3.1.1.1" xref="alg1.l4.m1.3.3.1.2.cmml"><mo stretchy="false" id="alg1.l4.m1.3.3.1.1.1.2" xref="alg1.l4.m1.3.3.1.2.cmml">(</mo><mrow id="alg1.l4.m1.3.3.1.1.1.1" xref="alg1.l4.m1.3.3.1.1.1.1.cmml"><mi id="alg1.l4.m1.3.3.1.1.1.1.2" xref="alg1.l4.m1.3.3.1.1.1.1.2.cmml">C</mi><mo lspace="0.222em" rspace="0.222em" id="alg1.l4.m1.3.3.1.1.1.1.1" xref="alg1.l4.m1.3.3.1.1.1.1.1.cmml">×</mo><mi id="alg1.l4.m1.3.3.1.1.1.1.3" xref="alg1.l4.m1.3.3.1.1.1.1.3.cmml">K</mi></mrow><mo id="alg1.l4.m1.3.3.1.1.1.3" xref="alg1.l4.m1.3.3.1.2.cmml">,</mo><mn id="alg1.l4.m1.2.2" xref="alg1.l4.m1.2.2.cmml">1</mn><mo stretchy="false" id="alg1.l4.m1.3.3.1.1.1.4" xref="alg1.l4.m1.3.3.1.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l4.m1.3b"><apply id="alg1.l4.m1.3.3.cmml" xref="alg1.l4.m1.3.3"><ci id="alg1.l4.m1.3.3.2.cmml" xref="alg1.l4.m1.3.3.2">←</ci><ci id="alg1.l4.m1.3.3.3.cmml" xref="alg1.l4.m1.3.3.3">𝑚</ci><apply id="alg1.l4.m1.3.3.1.2.cmml" xref="alg1.l4.m1.3.3.1.1"><max id="alg1.l4.m1.1.1.cmml" xref="alg1.l4.m1.1.1"></max><apply id="alg1.l4.m1.3.3.1.1.1.1.cmml" xref="alg1.l4.m1.3.3.1.1.1.1"><times id="alg1.l4.m1.3.3.1.1.1.1.1.cmml" xref="alg1.l4.m1.3.3.1.1.1.1.1"></times><ci id="alg1.l4.m1.3.3.1.1.1.1.2.cmml" xref="alg1.l4.m1.3.3.1.1.1.1.2">𝐶</ci><ci id="alg1.l4.m1.3.3.1.1.1.1.3.cmml" xref="alg1.l4.m1.3.3.1.1.1.1.3">𝐾</ci></apply><cn type="integer" id="alg1.l4.m1.2.2.cmml" xref="alg1.l4.m1.2.2">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l4.m1.3c">m\leftarrow\max(C\times K,1)</annotation></semantics></math>

</div>
<div id="alg1.l5" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l5.1.1.1" class="ltx_text" style="font-size:80%;">5:</span></span>         <math id="alg1.l5.m1.1" class="ltx_Math" alttext="S_{t}\leftarrow\text{random subset of }m\text{ with }p_{k}=\frac{1}{K}" display="inline"><semantics id="alg1.l5.m1.1a"><mrow id="alg1.l5.m1.1.1" xref="alg1.l5.m1.1.1.cmml"><msub id="alg1.l5.m1.1.1.2" xref="alg1.l5.m1.1.1.2.cmml"><mi id="alg1.l5.m1.1.1.2.2" xref="alg1.l5.m1.1.1.2.2.cmml">S</mi><mi id="alg1.l5.m1.1.1.2.3" xref="alg1.l5.m1.1.1.2.3.cmml">t</mi></msub><mo stretchy="false" id="alg1.l5.m1.1.1.3" xref="alg1.l5.m1.1.1.3.cmml">←</mo><mrow id="alg1.l5.m1.1.1.4" xref="alg1.l5.m1.1.1.4.cmml"><mtext id="alg1.l5.m1.1.1.4.2" xref="alg1.l5.m1.1.1.4.2a.cmml">random subset of </mtext><mo lspace="0em" rspace="0em" id="alg1.l5.m1.1.1.4.1" xref="alg1.l5.m1.1.1.4.1.cmml">​</mo><mi id="alg1.l5.m1.1.1.4.3" xref="alg1.l5.m1.1.1.4.3.cmml">m</mi><mo lspace="0em" rspace="0em" id="alg1.l5.m1.1.1.4.1a" xref="alg1.l5.m1.1.1.4.1.cmml">​</mo><mtext id="alg1.l5.m1.1.1.4.4" xref="alg1.l5.m1.1.1.4.4a.cmml"> with </mtext><mo lspace="0em" rspace="0em" id="alg1.l5.m1.1.1.4.1b" xref="alg1.l5.m1.1.1.4.1.cmml">​</mo><msub id="alg1.l5.m1.1.1.4.5" xref="alg1.l5.m1.1.1.4.5.cmml"><mi id="alg1.l5.m1.1.1.4.5.2" xref="alg1.l5.m1.1.1.4.5.2.cmml">p</mi><mi id="alg1.l5.m1.1.1.4.5.3" xref="alg1.l5.m1.1.1.4.5.3.cmml">k</mi></msub></mrow><mo id="alg1.l5.m1.1.1.5" xref="alg1.l5.m1.1.1.5.cmml">=</mo><mfrac id="alg1.l5.m1.1.1.6" xref="alg1.l5.m1.1.1.6.cmml"><mn id="alg1.l5.m1.1.1.6.2" xref="alg1.l5.m1.1.1.6.2.cmml">1</mn><mi id="alg1.l5.m1.1.1.6.3" xref="alg1.l5.m1.1.1.6.3.cmml">K</mi></mfrac></mrow><annotation-xml encoding="MathML-Content" id="alg1.l5.m1.1b"><apply id="alg1.l5.m1.1.1.cmml" xref="alg1.l5.m1.1.1"><and id="alg1.l5.m1.1.1a.cmml" xref="alg1.l5.m1.1.1"></and><apply id="alg1.l5.m1.1.1b.cmml" xref="alg1.l5.m1.1.1"><ci id="alg1.l5.m1.1.1.3.cmml" xref="alg1.l5.m1.1.1.3">←</ci><apply id="alg1.l5.m1.1.1.2.cmml" xref="alg1.l5.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.l5.m1.1.1.2.1.cmml" xref="alg1.l5.m1.1.1.2">subscript</csymbol><ci id="alg1.l5.m1.1.1.2.2.cmml" xref="alg1.l5.m1.1.1.2.2">𝑆</ci><ci id="alg1.l5.m1.1.1.2.3.cmml" xref="alg1.l5.m1.1.1.2.3">𝑡</ci></apply><apply id="alg1.l5.m1.1.1.4.cmml" xref="alg1.l5.m1.1.1.4"><times id="alg1.l5.m1.1.1.4.1.cmml" xref="alg1.l5.m1.1.1.4.1"></times><ci id="alg1.l5.m1.1.1.4.2a.cmml" xref="alg1.l5.m1.1.1.4.2"><mtext id="alg1.l5.m1.1.1.4.2.cmml" xref="alg1.l5.m1.1.1.4.2">random subset of </mtext></ci><ci id="alg1.l5.m1.1.1.4.3.cmml" xref="alg1.l5.m1.1.1.4.3">𝑚</ci><ci id="alg1.l5.m1.1.1.4.4a.cmml" xref="alg1.l5.m1.1.1.4.4"><mtext id="alg1.l5.m1.1.1.4.4.cmml" xref="alg1.l5.m1.1.1.4.4"> with </mtext></ci><apply id="alg1.l5.m1.1.1.4.5.cmml" xref="alg1.l5.m1.1.1.4.5"><csymbol cd="ambiguous" id="alg1.l5.m1.1.1.4.5.1.cmml" xref="alg1.l5.m1.1.1.4.5">subscript</csymbol><ci id="alg1.l5.m1.1.1.4.5.2.cmml" xref="alg1.l5.m1.1.1.4.5.2">𝑝</ci><ci id="alg1.l5.m1.1.1.4.5.3.cmml" xref="alg1.l5.m1.1.1.4.5.3">𝑘</ci></apply></apply></apply><apply id="alg1.l5.m1.1.1c.cmml" xref="alg1.l5.m1.1.1"><eq id="alg1.l5.m1.1.1.5.cmml" xref="alg1.l5.m1.1.1.5"></eq><share href="#alg1.l5.m1.1.1.4.cmml" id="alg1.l5.m1.1.1d.cmml" xref="alg1.l5.m1.1.1"></share><apply id="alg1.l5.m1.1.1.6.cmml" xref="alg1.l5.m1.1.1.6"><divide id="alg1.l5.m1.1.1.6.1.cmml" xref="alg1.l5.m1.1.1.6"></divide><cn type="integer" id="alg1.l5.m1.1.1.6.2.cmml" xref="alg1.l5.m1.1.1.6.2">1</cn><ci id="alg1.l5.m1.1.1.6.3.cmml" xref="alg1.l5.m1.1.1.6.3">𝐾</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l5.m1.1c">S_{t}\leftarrow\text{random subset of }m\text{ with }p_{k}=\frac{1}{K}</annotation></semantics></math>

</div>
<div id="alg1.l6" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l6.1.1.1" class="ltx_text" style="font-size:80%;">6:</span></span>         <span id="alg1.l6.2" class="ltx_text ltx_font_bold">for</span> <math id="alg1.l6.m1.1" class="ltx_Math" alttext="\text{each client }k\in S_{t}" display="inline"><semantics id="alg1.l6.m1.1a"><mrow id="alg1.l6.m1.1.1" xref="alg1.l6.m1.1.1.cmml"><mrow id="alg1.l6.m1.1.1.2" xref="alg1.l6.m1.1.1.2.cmml"><mtext id="alg1.l6.m1.1.1.2.2" xref="alg1.l6.m1.1.1.2.2a.cmml">each client </mtext><mo lspace="0em" rspace="0em" id="alg1.l6.m1.1.1.2.1" xref="alg1.l6.m1.1.1.2.1.cmml">​</mo><mi id="alg1.l6.m1.1.1.2.3" xref="alg1.l6.m1.1.1.2.3.cmml">k</mi></mrow><mo id="alg1.l6.m1.1.1.1" xref="alg1.l6.m1.1.1.1.cmml">∈</mo><msub id="alg1.l6.m1.1.1.3" xref="alg1.l6.m1.1.1.3.cmml"><mi id="alg1.l6.m1.1.1.3.2" xref="alg1.l6.m1.1.1.3.2.cmml">S</mi><mi id="alg1.l6.m1.1.1.3.3" xref="alg1.l6.m1.1.1.3.3.cmml">t</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="alg1.l6.m1.1b"><apply id="alg1.l6.m1.1.1.cmml" xref="alg1.l6.m1.1.1"><in id="alg1.l6.m1.1.1.1.cmml" xref="alg1.l6.m1.1.1.1"></in><apply id="alg1.l6.m1.1.1.2.cmml" xref="alg1.l6.m1.1.1.2"><times id="alg1.l6.m1.1.1.2.1.cmml" xref="alg1.l6.m1.1.1.2.1"></times><ci id="alg1.l6.m1.1.1.2.2a.cmml" xref="alg1.l6.m1.1.1.2.2"><mtext id="alg1.l6.m1.1.1.2.2.cmml" xref="alg1.l6.m1.1.1.2.2">each client </mtext></ci><ci id="alg1.l6.m1.1.1.2.3.cmml" xref="alg1.l6.m1.1.1.2.3">𝑘</ci></apply><apply id="alg1.l6.m1.1.1.3.cmml" xref="alg1.l6.m1.1.1.3"><csymbol cd="ambiguous" id="alg1.l6.m1.1.1.3.1.cmml" xref="alg1.l6.m1.1.1.3">subscript</csymbol><ci id="alg1.l6.m1.1.1.3.2.cmml" xref="alg1.l6.m1.1.1.3.2">𝑆</ci><ci id="alg1.l6.m1.1.1.3.3.cmml" xref="alg1.l6.m1.1.1.3.3">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l6.m1.1c">\text{each client }k\in S_{t}</annotation></semantics></math> <span id="alg1.l6.3" class="ltx_text ltx_font_bold">do</span>

</div>
<div id="alg1.l7" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l7.1.1.1" class="ltx_text" style="font-size:80%;">7:</span></span>              <math id="alg1.l7.m1.2" class="ltx_Math" alttext="w^{k}_{t}+1\leftarrow\text{ ClientUpdate}(k,w_{t})" display="inline"><semantics id="alg1.l7.m1.2a"><mrow id="alg1.l7.m1.2.2" xref="alg1.l7.m1.2.2.cmml"><mrow id="alg1.l7.m1.2.2.3" xref="alg1.l7.m1.2.2.3.cmml"><msubsup id="alg1.l7.m1.2.2.3.2" xref="alg1.l7.m1.2.2.3.2.cmml"><mi id="alg1.l7.m1.2.2.3.2.2.2" xref="alg1.l7.m1.2.2.3.2.2.2.cmml">w</mi><mi id="alg1.l7.m1.2.2.3.2.3" xref="alg1.l7.m1.2.2.3.2.3.cmml">t</mi><mi id="alg1.l7.m1.2.2.3.2.2.3" xref="alg1.l7.m1.2.2.3.2.2.3.cmml">k</mi></msubsup><mo id="alg1.l7.m1.2.2.3.1" xref="alg1.l7.m1.2.2.3.1.cmml">+</mo><mn id="alg1.l7.m1.2.2.3.3" xref="alg1.l7.m1.2.2.3.3.cmml">1</mn></mrow><mo stretchy="false" id="alg1.l7.m1.2.2.2" xref="alg1.l7.m1.2.2.2.cmml">←</mo><mrow id="alg1.l7.m1.2.2.1" xref="alg1.l7.m1.2.2.1.cmml"><mtext id="alg1.l7.m1.2.2.1.3" xref="alg1.l7.m1.2.2.1.3a.cmml"> ClientUpdate</mtext><mo lspace="0em" rspace="0em" id="alg1.l7.m1.2.2.1.2" xref="alg1.l7.m1.2.2.1.2.cmml">​</mo><mrow id="alg1.l7.m1.2.2.1.1.1" xref="alg1.l7.m1.2.2.1.1.2.cmml"><mo stretchy="false" id="alg1.l7.m1.2.2.1.1.1.2" xref="alg1.l7.m1.2.2.1.1.2.cmml">(</mo><mi id="alg1.l7.m1.1.1" xref="alg1.l7.m1.1.1.cmml">k</mi><mo id="alg1.l7.m1.2.2.1.1.1.3" xref="alg1.l7.m1.2.2.1.1.2.cmml">,</mo><msub id="alg1.l7.m1.2.2.1.1.1.1" xref="alg1.l7.m1.2.2.1.1.1.1.cmml"><mi id="alg1.l7.m1.2.2.1.1.1.1.2" xref="alg1.l7.m1.2.2.1.1.1.1.2.cmml">w</mi><mi id="alg1.l7.m1.2.2.1.1.1.1.3" xref="alg1.l7.m1.2.2.1.1.1.1.3.cmml">t</mi></msub><mo stretchy="false" id="alg1.l7.m1.2.2.1.1.1.4" xref="alg1.l7.m1.2.2.1.1.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l7.m1.2b"><apply id="alg1.l7.m1.2.2.cmml" xref="alg1.l7.m1.2.2"><ci id="alg1.l7.m1.2.2.2.cmml" xref="alg1.l7.m1.2.2.2">←</ci><apply id="alg1.l7.m1.2.2.3.cmml" xref="alg1.l7.m1.2.2.3"><plus id="alg1.l7.m1.2.2.3.1.cmml" xref="alg1.l7.m1.2.2.3.1"></plus><apply id="alg1.l7.m1.2.2.3.2.cmml" xref="alg1.l7.m1.2.2.3.2"><csymbol cd="ambiguous" id="alg1.l7.m1.2.2.3.2.1.cmml" xref="alg1.l7.m1.2.2.3.2">subscript</csymbol><apply id="alg1.l7.m1.2.2.3.2.2.cmml" xref="alg1.l7.m1.2.2.3.2"><csymbol cd="ambiguous" id="alg1.l7.m1.2.2.3.2.2.1.cmml" xref="alg1.l7.m1.2.2.3.2">superscript</csymbol><ci id="alg1.l7.m1.2.2.3.2.2.2.cmml" xref="alg1.l7.m1.2.2.3.2.2.2">𝑤</ci><ci id="alg1.l7.m1.2.2.3.2.2.3.cmml" xref="alg1.l7.m1.2.2.3.2.2.3">𝑘</ci></apply><ci id="alg1.l7.m1.2.2.3.2.3.cmml" xref="alg1.l7.m1.2.2.3.2.3">𝑡</ci></apply><cn type="integer" id="alg1.l7.m1.2.2.3.3.cmml" xref="alg1.l7.m1.2.2.3.3">1</cn></apply><apply id="alg1.l7.m1.2.2.1.cmml" xref="alg1.l7.m1.2.2.1"><times id="alg1.l7.m1.2.2.1.2.cmml" xref="alg1.l7.m1.2.2.1.2"></times><ci id="alg1.l7.m1.2.2.1.3a.cmml" xref="alg1.l7.m1.2.2.1.3"><mtext id="alg1.l7.m1.2.2.1.3.cmml" xref="alg1.l7.m1.2.2.1.3"> ClientUpdate</mtext></ci><interval closure="open" id="alg1.l7.m1.2.2.1.1.2.cmml" xref="alg1.l7.m1.2.2.1.1.1"><ci id="alg1.l7.m1.1.1.cmml" xref="alg1.l7.m1.1.1">𝑘</ci><apply id="alg1.l7.m1.2.2.1.1.1.1.cmml" xref="alg1.l7.m1.2.2.1.1.1.1"><csymbol cd="ambiguous" id="alg1.l7.m1.2.2.1.1.1.1.1.cmml" xref="alg1.l7.m1.2.2.1.1.1.1">subscript</csymbol><ci id="alg1.l7.m1.2.2.1.1.1.1.2.cmml" xref="alg1.l7.m1.2.2.1.1.1.1.2">𝑤</ci><ci id="alg1.l7.m1.2.2.1.1.1.1.3.cmml" xref="alg1.l7.m1.2.2.1.1.1.1.3">𝑡</ci></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l7.m1.2c">w^{k}_{t}+1\leftarrow\text{ ClientUpdate}(k,w_{t})</annotation></semantics></math>

</div>
<div id="alg1.l8" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l8.1.1.1" class="ltx_text" style="font-size:80%;">8:</span></span>         <span id="alg1.l8.2" class="ltx_text ltx_font_bold">end</span> <span id="alg1.l8.3" class="ltx_text ltx_font_bold">for</span>
</div>
<div id="alg1.l9" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l9.1.1.1" class="ltx_text" style="font-size:80%;">9:</span></span>         <math id="alg1.l9.m1.1" class="ltx_Math" alttext="w_{t}\leftarrow\sum_{k=1}^{K}\frac{n_{k}}{n\times w^{k}_{t+1}}" display="inline"><semantics id="alg1.l9.m1.1a"><mrow id="alg1.l9.m1.1.1" xref="alg1.l9.m1.1.1.cmml"><msub id="alg1.l9.m1.1.1.2" xref="alg1.l9.m1.1.1.2.cmml"><mi id="alg1.l9.m1.1.1.2.2" xref="alg1.l9.m1.1.1.2.2.cmml">w</mi><mi id="alg1.l9.m1.1.1.2.3" xref="alg1.l9.m1.1.1.2.3.cmml">t</mi></msub><mo rspace="0.111em" stretchy="false" id="alg1.l9.m1.1.1.1" xref="alg1.l9.m1.1.1.1.cmml">←</mo><mrow id="alg1.l9.m1.1.1.3" xref="alg1.l9.m1.1.1.3.cmml"><msubsup id="alg1.l9.m1.1.1.3.1" xref="alg1.l9.m1.1.1.3.1.cmml"><mo id="alg1.l9.m1.1.1.3.1.2.2" xref="alg1.l9.m1.1.1.3.1.2.2.cmml">∑</mo><mrow id="alg1.l9.m1.1.1.3.1.2.3" xref="alg1.l9.m1.1.1.3.1.2.3.cmml"><mi id="alg1.l9.m1.1.1.3.1.2.3.2" xref="alg1.l9.m1.1.1.3.1.2.3.2.cmml">k</mi><mo id="alg1.l9.m1.1.1.3.1.2.3.1" xref="alg1.l9.m1.1.1.3.1.2.3.1.cmml">=</mo><mn id="alg1.l9.m1.1.1.3.1.2.3.3" xref="alg1.l9.m1.1.1.3.1.2.3.3.cmml">1</mn></mrow><mi id="alg1.l9.m1.1.1.3.1.3" xref="alg1.l9.m1.1.1.3.1.3.cmml">K</mi></msubsup><mfrac id="alg1.l9.m1.1.1.3.2" xref="alg1.l9.m1.1.1.3.2.cmml"><msub id="alg1.l9.m1.1.1.3.2.2" xref="alg1.l9.m1.1.1.3.2.2.cmml"><mi id="alg1.l9.m1.1.1.3.2.2.2" xref="alg1.l9.m1.1.1.3.2.2.2.cmml">n</mi><mi id="alg1.l9.m1.1.1.3.2.2.3" xref="alg1.l9.m1.1.1.3.2.2.3.cmml">k</mi></msub><mrow id="alg1.l9.m1.1.1.3.2.3" xref="alg1.l9.m1.1.1.3.2.3.cmml"><mi id="alg1.l9.m1.1.1.3.2.3.2" xref="alg1.l9.m1.1.1.3.2.3.2.cmml">n</mi><mo lspace="0.222em" rspace="0.222em" id="alg1.l9.m1.1.1.3.2.3.1" xref="alg1.l9.m1.1.1.3.2.3.1.cmml">×</mo><msubsup id="alg1.l9.m1.1.1.3.2.3.3" xref="alg1.l9.m1.1.1.3.2.3.3.cmml"><mi id="alg1.l9.m1.1.1.3.2.3.3.2.2" xref="alg1.l9.m1.1.1.3.2.3.3.2.2.cmml">w</mi><mrow id="alg1.l9.m1.1.1.3.2.3.3.3" xref="alg1.l9.m1.1.1.3.2.3.3.3.cmml"><mi id="alg1.l9.m1.1.1.3.2.3.3.3.2" xref="alg1.l9.m1.1.1.3.2.3.3.3.2.cmml">t</mi><mo id="alg1.l9.m1.1.1.3.2.3.3.3.1" xref="alg1.l9.m1.1.1.3.2.3.3.3.1.cmml">+</mo><mn id="alg1.l9.m1.1.1.3.2.3.3.3.3" xref="alg1.l9.m1.1.1.3.2.3.3.3.3.cmml">1</mn></mrow><mi id="alg1.l9.m1.1.1.3.2.3.3.2.3" xref="alg1.l9.m1.1.1.3.2.3.3.2.3.cmml">k</mi></msubsup></mrow></mfrac></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l9.m1.1b"><apply id="alg1.l9.m1.1.1.cmml" xref="alg1.l9.m1.1.1"><ci id="alg1.l9.m1.1.1.1.cmml" xref="alg1.l9.m1.1.1.1">←</ci><apply id="alg1.l9.m1.1.1.2.cmml" xref="alg1.l9.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.l9.m1.1.1.2.1.cmml" xref="alg1.l9.m1.1.1.2">subscript</csymbol><ci id="alg1.l9.m1.1.1.2.2.cmml" xref="alg1.l9.m1.1.1.2.2">𝑤</ci><ci id="alg1.l9.m1.1.1.2.3.cmml" xref="alg1.l9.m1.1.1.2.3">𝑡</ci></apply><apply id="alg1.l9.m1.1.1.3.cmml" xref="alg1.l9.m1.1.1.3"><apply id="alg1.l9.m1.1.1.3.1.cmml" xref="alg1.l9.m1.1.1.3.1"><csymbol cd="ambiguous" id="alg1.l9.m1.1.1.3.1.1.cmml" xref="alg1.l9.m1.1.1.3.1">superscript</csymbol><apply id="alg1.l9.m1.1.1.3.1.2.cmml" xref="alg1.l9.m1.1.1.3.1"><csymbol cd="ambiguous" id="alg1.l9.m1.1.1.3.1.2.1.cmml" xref="alg1.l9.m1.1.1.3.1">subscript</csymbol><sum id="alg1.l9.m1.1.1.3.1.2.2.cmml" xref="alg1.l9.m1.1.1.3.1.2.2"></sum><apply id="alg1.l9.m1.1.1.3.1.2.3.cmml" xref="alg1.l9.m1.1.1.3.1.2.3"><eq id="alg1.l9.m1.1.1.3.1.2.3.1.cmml" xref="alg1.l9.m1.1.1.3.1.2.3.1"></eq><ci id="alg1.l9.m1.1.1.3.1.2.3.2.cmml" xref="alg1.l9.m1.1.1.3.1.2.3.2">𝑘</ci><cn type="integer" id="alg1.l9.m1.1.1.3.1.2.3.3.cmml" xref="alg1.l9.m1.1.1.3.1.2.3.3">1</cn></apply></apply><ci id="alg1.l9.m1.1.1.3.1.3.cmml" xref="alg1.l9.m1.1.1.3.1.3">𝐾</ci></apply><apply id="alg1.l9.m1.1.1.3.2.cmml" xref="alg1.l9.m1.1.1.3.2"><divide id="alg1.l9.m1.1.1.3.2.1.cmml" xref="alg1.l9.m1.1.1.3.2"></divide><apply id="alg1.l9.m1.1.1.3.2.2.cmml" xref="alg1.l9.m1.1.1.3.2.2"><csymbol cd="ambiguous" id="alg1.l9.m1.1.1.3.2.2.1.cmml" xref="alg1.l9.m1.1.1.3.2.2">subscript</csymbol><ci id="alg1.l9.m1.1.1.3.2.2.2.cmml" xref="alg1.l9.m1.1.1.3.2.2.2">𝑛</ci><ci id="alg1.l9.m1.1.1.3.2.2.3.cmml" xref="alg1.l9.m1.1.1.3.2.2.3">𝑘</ci></apply><apply id="alg1.l9.m1.1.1.3.2.3.cmml" xref="alg1.l9.m1.1.1.3.2.3"><times id="alg1.l9.m1.1.1.3.2.3.1.cmml" xref="alg1.l9.m1.1.1.3.2.3.1"></times><ci id="alg1.l9.m1.1.1.3.2.3.2.cmml" xref="alg1.l9.m1.1.1.3.2.3.2">𝑛</ci><apply id="alg1.l9.m1.1.1.3.2.3.3.cmml" xref="alg1.l9.m1.1.1.3.2.3.3"><csymbol cd="ambiguous" id="alg1.l9.m1.1.1.3.2.3.3.1.cmml" xref="alg1.l9.m1.1.1.3.2.3.3">subscript</csymbol><apply id="alg1.l9.m1.1.1.3.2.3.3.2.cmml" xref="alg1.l9.m1.1.1.3.2.3.3"><csymbol cd="ambiguous" id="alg1.l9.m1.1.1.3.2.3.3.2.1.cmml" xref="alg1.l9.m1.1.1.3.2.3.3">superscript</csymbol><ci id="alg1.l9.m1.1.1.3.2.3.3.2.2.cmml" xref="alg1.l9.m1.1.1.3.2.3.3.2.2">𝑤</ci><ci id="alg1.l9.m1.1.1.3.2.3.3.2.3.cmml" xref="alg1.l9.m1.1.1.3.2.3.3.2.3">𝑘</ci></apply><apply id="alg1.l9.m1.1.1.3.2.3.3.3.cmml" xref="alg1.l9.m1.1.1.3.2.3.3.3"><plus id="alg1.l9.m1.1.1.3.2.3.3.3.1.cmml" xref="alg1.l9.m1.1.1.3.2.3.3.3.1"></plus><ci id="alg1.l9.m1.1.1.3.2.3.3.3.2.cmml" xref="alg1.l9.m1.1.1.3.2.3.3.3.2">𝑡</ci><cn type="integer" id="alg1.l9.m1.1.1.3.2.3.3.3.3.cmml" xref="alg1.l9.m1.1.1.3.2.3.3.3.3">1</cn></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l9.m1.1c">w_{t}\leftarrow\sum_{k=1}^{K}\frac{n_{k}}{n\times w^{k}_{t+1}}</annotation></semantics></math>

</div>
<div id="alg1.l10" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l10.1.1.1" class="ltx_text" style="font-size:80%;">10:</span></span>     <span id="alg1.l10.2" class="ltx_text ltx_font_bold">end</span> <span id="alg1.l10.3" class="ltx_text ltx_font_bold">for</span>
</div>
<div id="alg1.l11" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l11.1.1.1" class="ltx_text" style="font-size:80%;">11:</span></span><span id="alg1.l11.2" class="ltx_text ltx_font_bold">end</span> <span id="alg1.l11.3" class="ltx_text ltx_font_bold">procedure</span>
</div>
<div id="alg1.l12" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l12.1.1.1" class="ltx_text" style="font-size:80%;">12:</span></span><span id="alg1.l12.2" class="ltx_text ltx_font_bold">function</span> <span id="alg1.l12.3" class="ltx_text ltx_font_smallcaps">ClientUpdate</span>(k,w)

</div>
<div id="alg1.l13" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l13.1.1.1" class="ltx_text" style="font-size:80%;">13:</span></span>     <math id="alg1.l13.m1.1" class="ltx_Math" alttext="B\leftarrow\text{split local data into batches of size }b" display="inline"><semantics id="alg1.l13.m1.1a"><mrow id="alg1.l13.m1.1.1" xref="alg1.l13.m1.1.1.cmml"><mi id="alg1.l13.m1.1.1.2" xref="alg1.l13.m1.1.1.2.cmml">B</mi><mo stretchy="false" id="alg1.l13.m1.1.1.1" xref="alg1.l13.m1.1.1.1.cmml">←</mo><mrow id="alg1.l13.m1.1.1.3" xref="alg1.l13.m1.1.1.3.cmml"><mtext id="alg1.l13.m1.1.1.3.2" xref="alg1.l13.m1.1.1.3.2a.cmml">split local data into batches of size </mtext><mo lspace="0em" rspace="0em" id="alg1.l13.m1.1.1.3.1" xref="alg1.l13.m1.1.1.3.1.cmml">​</mo><mi id="alg1.l13.m1.1.1.3.3" xref="alg1.l13.m1.1.1.3.3.cmml">b</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l13.m1.1b"><apply id="alg1.l13.m1.1.1.cmml" xref="alg1.l13.m1.1.1"><ci id="alg1.l13.m1.1.1.1.cmml" xref="alg1.l13.m1.1.1.1">←</ci><ci id="alg1.l13.m1.1.1.2.cmml" xref="alg1.l13.m1.1.1.2">𝐵</ci><apply id="alg1.l13.m1.1.1.3.cmml" xref="alg1.l13.m1.1.1.3"><times id="alg1.l13.m1.1.1.3.1.cmml" xref="alg1.l13.m1.1.1.3.1"></times><ci id="alg1.l13.m1.1.1.3.2a.cmml" xref="alg1.l13.m1.1.1.3.2"><mtext id="alg1.l13.m1.1.1.3.2.cmml" xref="alg1.l13.m1.1.1.3.2">split local data into batches of size </mtext></ci><ci id="alg1.l13.m1.1.1.3.3.cmml" xref="alg1.l13.m1.1.1.3.3">𝑏</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l13.m1.1c">B\leftarrow\text{split local data into batches of size }b</annotation></semantics></math>

</div>
<div id="alg1.l14" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l14.1.1.1" class="ltx_text" style="font-size:80%;">14:</span></span>     <span id="alg1.l14.2" class="ltx_text ltx_font_bold">for</span> <math id="alg1.l14.m1.3" class="ltx_Math" alttext="\text{each local epoch }i=0,\ldots,E-1" display="inline"><semantics id="alg1.l14.m1.3a"><mrow id="alg1.l14.m1.3.3" xref="alg1.l14.m1.3.3.cmml"><mrow id="alg1.l14.m1.3.3.3" xref="alg1.l14.m1.3.3.3.cmml"><mtext id="alg1.l14.m1.3.3.3.2" xref="alg1.l14.m1.3.3.3.2a.cmml">each local epoch </mtext><mo lspace="0em" rspace="0em" id="alg1.l14.m1.3.3.3.1" xref="alg1.l14.m1.3.3.3.1.cmml">​</mo><mi id="alg1.l14.m1.3.3.3.3" xref="alg1.l14.m1.3.3.3.3.cmml">i</mi></mrow><mo id="alg1.l14.m1.3.3.2" xref="alg1.l14.m1.3.3.2.cmml">=</mo><mrow id="alg1.l14.m1.3.3.1.1" xref="alg1.l14.m1.3.3.1.2.cmml"><mn id="alg1.l14.m1.1.1" xref="alg1.l14.m1.1.1.cmml">0</mn><mo id="alg1.l14.m1.3.3.1.1.2" xref="alg1.l14.m1.3.3.1.2.cmml">,</mo><mi mathvariant="normal" id="alg1.l14.m1.2.2" xref="alg1.l14.m1.2.2.cmml">…</mi><mo id="alg1.l14.m1.3.3.1.1.3" xref="alg1.l14.m1.3.3.1.2.cmml">,</mo><mrow id="alg1.l14.m1.3.3.1.1.1" xref="alg1.l14.m1.3.3.1.1.1.cmml"><mi id="alg1.l14.m1.3.3.1.1.1.2" xref="alg1.l14.m1.3.3.1.1.1.2.cmml">E</mi><mo id="alg1.l14.m1.3.3.1.1.1.1" xref="alg1.l14.m1.3.3.1.1.1.1.cmml">−</mo><mn id="alg1.l14.m1.3.3.1.1.1.3" xref="alg1.l14.m1.3.3.1.1.1.3.cmml">1</mn></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l14.m1.3b"><apply id="alg1.l14.m1.3.3.cmml" xref="alg1.l14.m1.3.3"><eq id="alg1.l14.m1.3.3.2.cmml" xref="alg1.l14.m1.3.3.2"></eq><apply id="alg1.l14.m1.3.3.3.cmml" xref="alg1.l14.m1.3.3.3"><times id="alg1.l14.m1.3.3.3.1.cmml" xref="alg1.l14.m1.3.3.3.1"></times><ci id="alg1.l14.m1.3.3.3.2a.cmml" xref="alg1.l14.m1.3.3.3.2"><mtext id="alg1.l14.m1.3.3.3.2.cmml" xref="alg1.l14.m1.3.3.3.2">each local epoch </mtext></ci><ci id="alg1.l14.m1.3.3.3.3.cmml" xref="alg1.l14.m1.3.3.3.3">𝑖</ci></apply><list id="alg1.l14.m1.3.3.1.2.cmml" xref="alg1.l14.m1.3.3.1.1"><cn type="integer" id="alg1.l14.m1.1.1.cmml" xref="alg1.l14.m1.1.1">0</cn><ci id="alg1.l14.m1.2.2.cmml" xref="alg1.l14.m1.2.2">…</ci><apply id="alg1.l14.m1.3.3.1.1.1.cmml" xref="alg1.l14.m1.3.3.1.1.1"><minus id="alg1.l14.m1.3.3.1.1.1.1.cmml" xref="alg1.l14.m1.3.3.1.1.1.1"></minus><ci id="alg1.l14.m1.3.3.1.1.1.2.cmml" xref="alg1.l14.m1.3.3.1.1.1.2">𝐸</ci><cn type="integer" id="alg1.l14.m1.3.3.1.1.1.3.cmml" xref="alg1.l14.m1.3.3.1.1.1.3">1</cn></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l14.m1.3c">\text{each local epoch }i=0,\ldots,E-1</annotation></semantics></math> <span id="alg1.l14.3" class="ltx_text ltx_font_bold">do</span>

</div>
<div id="alg1.l15" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l15.1.1.1" class="ltx_text" style="font-size:80%;">15:</span></span>         <span id="alg1.l15.2" class="ltx_text ltx_font_bold">for</span> <math id="alg1.l15.m1.1" class="ltx_Math" alttext="\text{batch }b\in B" display="inline"><semantics id="alg1.l15.m1.1a"><mrow id="alg1.l15.m1.1.1" xref="alg1.l15.m1.1.1.cmml"><mrow id="alg1.l15.m1.1.1.2" xref="alg1.l15.m1.1.1.2.cmml"><mtext id="alg1.l15.m1.1.1.2.2" xref="alg1.l15.m1.1.1.2.2a.cmml">batch </mtext><mo lspace="0em" rspace="0em" id="alg1.l15.m1.1.1.2.1" xref="alg1.l15.m1.1.1.2.1.cmml">​</mo><mi id="alg1.l15.m1.1.1.2.3" xref="alg1.l15.m1.1.1.2.3.cmml">b</mi></mrow><mo id="alg1.l15.m1.1.1.1" xref="alg1.l15.m1.1.1.1.cmml">∈</mo><mi id="alg1.l15.m1.1.1.3" xref="alg1.l15.m1.1.1.3.cmml">B</mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.l15.m1.1b"><apply id="alg1.l15.m1.1.1.cmml" xref="alg1.l15.m1.1.1"><in id="alg1.l15.m1.1.1.1.cmml" xref="alg1.l15.m1.1.1.1"></in><apply id="alg1.l15.m1.1.1.2.cmml" xref="alg1.l15.m1.1.1.2"><times id="alg1.l15.m1.1.1.2.1.cmml" xref="alg1.l15.m1.1.1.2.1"></times><ci id="alg1.l15.m1.1.1.2.2a.cmml" xref="alg1.l15.m1.1.1.2.2"><mtext id="alg1.l15.m1.1.1.2.2.cmml" xref="alg1.l15.m1.1.1.2.2">batch </mtext></ci><ci id="alg1.l15.m1.1.1.2.3.cmml" xref="alg1.l15.m1.1.1.2.3">𝑏</ci></apply><ci id="alg1.l15.m1.1.1.3.cmml" xref="alg1.l15.m1.1.1.3">𝐵</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l15.m1.1c">\text{batch }b\in B</annotation></semantics></math> <span id="alg1.l15.3" class="ltx_text ltx_font_bold">do</span>

</div>
<div id="alg1.l16" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l16.1.1.1" class="ltx_text" style="font-size:80%;">16:</span></span>              <math id="alg1.l16.m1.2" class="ltx_Math" alttext="w\leftarrow w+\eta\times\nabla l(w;b)" display="inline"><semantics id="alg1.l16.m1.2a"><mrow id="alg1.l16.m1.2.3" xref="alg1.l16.m1.2.3.cmml"><mi id="alg1.l16.m1.2.3.2" xref="alg1.l16.m1.2.3.2.cmml">w</mi><mo stretchy="false" id="alg1.l16.m1.2.3.1" xref="alg1.l16.m1.2.3.1.cmml">←</mo><mrow id="alg1.l16.m1.2.3.3" xref="alg1.l16.m1.2.3.3.cmml"><mi id="alg1.l16.m1.2.3.3.2" xref="alg1.l16.m1.2.3.3.2.cmml">w</mi><mo id="alg1.l16.m1.2.3.3.1" xref="alg1.l16.m1.2.3.3.1.cmml">+</mo><mrow id="alg1.l16.m1.2.3.3.3" xref="alg1.l16.m1.2.3.3.3.cmml"><mrow id="alg1.l16.m1.2.3.3.3.2" xref="alg1.l16.m1.2.3.3.3.2.cmml"><mi id="alg1.l16.m1.2.3.3.3.2.2" xref="alg1.l16.m1.2.3.3.3.2.2.cmml">η</mi><mo lspace="0.222em" rspace="0.222em" id="alg1.l16.m1.2.3.3.3.2.1" xref="alg1.l16.m1.2.3.3.3.2.1.cmml">×</mo><mrow id="alg1.l16.m1.2.3.3.3.2.3" xref="alg1.l16.m1.2.3.3.3.2.3.cmml"><mo rspace="0.167em" id="alg1.l16.m1.2.3.3.3.2.3.1" xref="alg1.l16.m1.2.3.3.3.2.3.1.cmml">∇</mo><mi id="alg1.l16.m1.2.3.3.3.2.3.2" xref="alg1.l16.m1.2.3.3.3.2.3.2.cmml">l</mi></mrow></mrow><mo lspace="0em" rspace="0em" id="alg1.l16.m1.2.3.3.3.1" xref="alg1.l16.m1.2.3.3.3.1.cmml">​</mo><mrow id="alg1.l16.m1.2.3.3.3.3.2" xref="alg1.l16.m1.2.3.3.3.3.1.cmml"><mo stretchy="false" id="alg1.l16.m1.2.3.3.3.3.2.1" xref="alg1.l16.m1.2.3.3.3.3.1.cmml">(</mo><mi id="alg1.l16.m1.1.1" xref="alg1.l16.m1.1.1.cmml">w</mi><mo id="alg1.l16.m1.2.3.3.3.3.2.2" xref="alg1.l16.m1.2.3.3.3.3.1.cmml">;</mo><mi id="alg1.l16.m1.2.2" xref="alg1.l16.m1.2.2.cmml">b</mi><mo stretchy="false" id="alg1.l16.m1.2.3.3.3.3.2.3" xref="alg1.l16.m1.2.3.3.3.3.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l16.m1.2b"><apply id="alg1.l16.m1.2.3.cmml" xref="alg1.l16.m1.2.3"><ci id="alg1.l16.m1.2.3.1.cmml" xref="alg1.l16.m1.2.3.1">←</ci><ci id="alg1.l16.m1.2.3.2.cmml" xref="alg1.l16.m1.2.3.2">𝑤</ci><apply id="alg1.l16.m1.2.3.3.cmml" xref="alg1.l16.m1.2.3.3"><plus id="alg1.l16.m1.2.3.3.1.cmml" xref="alg1.l16.m1.2.3.3.1"></plus><ci id="alg1.l16.m1.2.3.3.2.cmml" xref="alg1.l16.m1.2.3.3.2">𝑤</ci><apply id="alg1.l16.m1.2.3.3.3.cmml" xref="alg1.l16.m1.2.3.3.3"><times id="alg1.l16.m1.2.3.3.3.1.cmml" xref="alg1.l16.m1.2.3.3.3.1"></times><apply id="alg1.l16.m1.2.3.3.3.2.cmml" xref="alg1.l16.m1.2.3.3.3.2"><times id="alg1.l16.m1.2.3.3.3.2.1.cmml" xref="alg1.l16.m1.2.3.3.3.2.1"></times><ci id="alg1.l16.m1.2.3.3.3.2.2.cmml" xref="alg1.l16.m1.2.3.3.3.2.2">𝜂</ci><apply id="alg1.l16.m1.2.3.3.3.2.3.cmml" xref="alg1.l16.m1.2.3.3.3.2.3"><ci id="alg1.l16.m1.2.3.3.3.2.3.1.cmml" xref="alg1.l16.m1.2.3.3.3.2.3.1">∇</ci><ci id="alg1.l16.m1.2.3.3.3.2.3.2.cmml" xref="alg1.l16.m1.2.3.3.3.2.3.2">𝑙</ci></apply></apply><list id="alg1.l16.m1.2.3.3.3.3.1.cmml" xref="alg1.l16.m1.2.3.3.3.3.2"><ci id="alg1.l16.m1.1.1.cmml" xref="alg1.l16.m1.1.1">𝑤</ci><ci id="alg1.l16.m1.2.2.cmml" xref="alg1.l16.m1.2.2">𝑏</ci></list></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l16.m1.2c">w\leftarrow w+\eta\times\nabla l(w;b)</annotation></semantics></math>

</div>
<div id="alg1.l17" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l17.1.1.1" class="ltx_text" style="font-size:80%;">17:</span></span>         <span id="alg1.l17.2" class="ltx_text ltx_font_bold">end</span> <span id="alg1.l17.3" class="ltx_text ltx_font_bold">for</span>
</div>
<div id="alg1.l18" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l18.1.1.1" class="ltx_text" style="font-size:80%;">18:</span></span>     <span id="alg1.l18.2" class="ltx_text ltx_font_bold">end</span> <span id="alg1.l18.3" class="ltx_text ltx_font_bold">for</span>
</div>
<div id="alg1.l19" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l19.1.1.1" class="ltx_text" style="font-size:80%;">19:</span></span>     <span id="alg1.l19.2" class="ltx_text ltx_font_bold">return</span> <math id="alg1.l19.m1.1" class="ltx_Math" alttext="w" display="inline"><semantics id="alg1.l19.m1.1a"><mi id="alg1.l19.m1.1.1" xref="alg1.l19.m1.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="alg1.l19.m1.1b"><ci id="alg1.l19.m1.1.1.cmml" xref="alg1.l19.m1.1.1">𝑤</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l19.m1.1c">w</annotation></semantics></math>

</div>
<div id="alg1.l20" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l20.1.1.1" class="ltx_text" style="font-size:80%;">20:</span></span><span id="alg1.l20.2" class="ltx_text ltx_font_bold">end</span> <span id="alg1.l20.3" class="ltx_text ltx_font_bold">function</span>
</div>
</div>
</figure>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">While i.i.d. data is formally defined, non-i.i.d. data properties are manifested by different forms. To ensure a consistent understanding of non-i.i.d. data regimes, we provide a taxonomy of non-i.i.d. data in reference to Hsieh <em id="S2.p2.1.1" class="ltx_emph ltx_font_italic">et al</em>.<span id="S2.p2.1.2" class="ltx_text"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> and Kairouz <em id="S2.p2.1.3" class="ltx_emph ltx_font_italic">et al</em>.<span id="S2.p2.1.4" class="ltx_text"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>. The taxonomy adopts notions of dataset shift <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>. However, instead of focusing on differences between training and test data distribution, their taxonomy considers differences in the data distribution between clients.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.5" class="ltx_p">Building a statistical model in a supervised manner using FL involves two stages of sampling: (i) selecting a client <math id="S2.p3.1.m1.1" class="ltx_Math" alttext="i\sim Q" display="inline"><semantics id="S2.p3.1.m1.1a"><mrow id="S2.p3.1.m1.1.1" xref="S2.p3.1.m1.1.1.cmml"><mi id="S2.p3.1.m1.1.1.2" xref="S2.p3.1.m1.1.1.2.cmml">i</mi><mo id="S2.p3.1.m1.1.1.1" xref="S2.p3.1.m1.1.1.1.cmml">∼</mo><mi id="S2.p3.1.m1.1.1.3" xref="S2.p3.1.m1.1.1.3.cmml">Q</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.p3.1.m1.1b"><apply id="S2.p3.1.m1.1.1.cmml" xref="S2.p3.1.m1.1.1"><csymbol cd="latexml" id="S2.p3.1.m1.1.1.1.cmml" xref="S2.p3.1.m1.1.1.1">similar-to</csymbol><ci id="S2.p3.1.m1.1.1.2.cmml" xref="S2.p3.1.m1.1.1.2">𝑖</ci><ci id="S2.p3.1.m1.1.1.3.cmml" xref="S2.p3.1.m1.1.1.3">𝑄</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p3.1.m1.1c">i\sim Q</annotation></semantics></math>, where <math id="S2.p3.2.m2.1" class="ltx_Math" alttext="Q" display="inline"><semantics id="S2.p3.2.m2.1a"><mi id="S2.p3.2.m2.1.1" xref="S2.p3.2.m2.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S2.p3.2.m2.1b"><ci id="S2.p3.2.m2.1.1.cmml" xref="S2.p3.2.m2.1.1">𝑄</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p3.2.m2.1c">Q</annotation></semantics></math> denotes the distribution over available clients, and (ii) drawing a sample-label pair from the local data distribution, i.e., <math id="S2.p3.3.m3.4" class="ltx_Math" alttext="(x,y)\sim P_{i}(x,y)" display="inline"><semantics id="S2.p3.3.m3.4a"><mrow id="S2.p3.3.m3.4.5" xref="S2.p3.3.m3.4.5.cmml"><mrow id="S2.p3.3.m3.4.5.2.2" xref="S2.p3.3.m3.4.5.2.1.cmml"><mo stretchy="false" id="S2.p3.3.m3.4.5.2.2.1" xref="S2.p3.3.m3.4.5.2.1.cmml">(</mo><mi id="S2.p3.3.m3.1.1" xref="S2.p3.3.m3.1.1.cmml">x</mi><mo id="S2.p3.3.m3.4.5.2.2.2" xref="S2.p3.3.m3.4.5.2.1.cmml">,</mo><mi id="S2.p3.3.m3.2.2" xref="S2.p3.3.m3.2.2.cmml">y</mi><mo stretchy="false" id="S2.p3.3.m3.4.5.2.2.3" xref="S2.p3.3.m3.4.5.2.1.cmml">)</mo></mrow><mo id="S2.p3.3.m3.4.5.1" xref="S2.p3.3.m3.4.5.1.cmml">∼</mo><mrow id="S2.p3.3.m3.4.5.3" xref="S2.p3.3.m3.4.5.3.cmml"><msub id="S2.p3.3.m3.4.5.3.2" xref="S2.p3.3.m3.4.5.3.2.cmml"><mi id="S2.p3.3.m3.4.5.3.2.2" xref="S2.p3.3.m3.4.5.3.2.2.cmml">P</mi><mi id="S2.p3.3.m3.4.5.3.2.3" xref="S2.p3.3.m3.4.5.3.2.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S2.p3.3.m3.4.5.3.1" xref="S2.p3.3.m3.4.5.3.1.cmml">​</mo><mrow id="S2.p3.3.m3.4.5.3.3.2" xref="S2.p3.3.m3.4.5.3.3.1.cmml"><mo stretchy="false" id="S2.p3.3.m3.4.5.3.3.2.1" xref="S2.p3.3.m3.4.5.3.3.1.cmml">(</mo><mi id="S2.p3.3.m3.3.3" xref="S2.p3.3.m3.3.3.cmml">x</mi><mo id="S2.p3.3.m3.4.5.3.3.2.2" xref="S2.p3.3.m3.4.5.3.3.1.cmml">,</mo><mi id="S2.p3.3.m3.4.4" xref="S2.p3.3.m3.4.4.cmml">y</mi><mo stretchy="false" id="S2.p3.3.m3.4.5.3.3.2.3" xref="S2.p3.3.m3.4.5.3.3.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p3.3.m3.4b"><apply id="S2.p3.3.m3.4.5.cmml" xref="S2.p3.3.m3.4.5"><csymbol cd="latexml" id="S2.p3.3.m3.4.5.1.cmml" xref="S2.p3.3.m3.4.5.1">similar-to</csymbol><interval closure="open" id="S2.p3.3.m3.4.5.2.1.cmml" xref="S2.p3.3.m3.4.5.2.2"><ci id="S2.p3.3.m3.1.1.cmml" xref="S2.p3.3.m3.1.1">𝑥</ci><ci id="S2.p3.3.m3.2.2.cmml" xref="S2.p3.3.m3.2.2">𝑦</ci></interval><apply id="S2.p3.3.m3.4.5.3.cmml" xref="S2.p3.3.m3.4.5.3"><times id="S2.p3.3.m3.4.5.3.1.cmml" xref="S2.p3.3.m3.4.5.3.1"></times><apply id="S2.p3.3.m3.4.5.3.2.cmml" xref="S2.p3.3.m3.4.5.3.2"><csymbol cd="ambiguous" id="S2.p3.3.m3.4.5.3.2.1.cmml" xref="S2.p3.3.m3.4.5.3.2">subscript</csymbol><ci id="S2.p3.3.m3.4.5.3.2.2.cmml" xref="S2.p3.3.m3.4.5.3.2.2">𝑃</ci><ci id="S2.p3.3.m3.4.5.3.2.3.cmml" xref="S2.p3.3.m3.4.5.3.2.3">𝑖</ci></apply><interval closure="open" id="S2.p3.3.m3.4.5.3.3.1.cmml" xref="S2.p3.3.m3.4.5.3.3.2"><ci id="S2.p3.3.m3.3.3.cmml" xref="S2.p3.3.m3.3.3">𝑥</ci><ci id="S2.p3.3.m3.4.4.cmml" xref="S2.p3.3.m3.4.4">𝑦</ci></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p3.3.m3.4c">(x,y)\sim P_{i}(x,y)</annotation></semantics></math>, where <math id="S2.p3.4.m4.1" class="ltx_Math" alttext="P_{i}" display="inline"><semantics id="S2.p3.4.m4.1a"><msub id="S2.p3.4.m4.1.1" xref="S2.p3.4.m4.1.1.cmml"><mi id="S2.p3.4.m4.1.1.2" xref="S2.p3.4.m4.1.1.2.cmml">P</mi><mi id="S2.p3.4.m4.1.1.3" xref="S2.p3.4.m4.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.p3.4.m4.1b"><apply id="S2.p3.4.m4.1.1.cmml" xref="S2.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S2.p3.4.m4.1.1.1.cmml" xref="S2.p3.4.m4.1.1">subscript</csymbol><ci id="S2.p3.4.m4.1.1.2.cmml" xref="S2.p3.4.m4.1.1.2">𝑃</ci><ci id="S2.p3.4.m4.1.1.3.cmml" xref="S2.p3.4.m4.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p3.4.m4.1c">P_{i}</annotation></semantics></math> denotes the data distribution of the selected client <math id="S2.p3.5.m5.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S2.p3.5.m5.1a"><mi id="S2.p3.5.m5.1.1" xref="S2.p3.5.m5.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S2.p3.5.m5.1b"><ci id="S2.p3.5.m5.1.1.cmml" xref="S2.p3.5.m5.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p3.5.m5.1c">i</annotation></semantics></math>.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.2" class="ltx_p">In FL, dependency mostly arises from the fact that each client corresponds to a user with specific interests, geographic location, and time zone. Therefore, the principle of independence is violated whenever the distribution <math id="S2.p4.1.m1.1" class="ltx_Math" alttext="Q" display="inline"><semantics id="S2.p4.1.m1.1a"><mi id="S2.p4.1.m1.1.1" xref="S2.p4.1.m1.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S2.p4.1.m1.1b"><ci id="S2.p4.1.m1.1.1.cmml" xref="S2.p4.1.m1.1.1">𝑄</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p4.1.m1.1c">Q</annotation></semantics></math> changes over the course of training. Due to the design of FL on mobile devices, only devices that are idle, charging, and connected to an unmetered wireless connection are available for selection. Noted that client availability follows temporal and/or behavioral patterns, therefore this condition is typically satisfied during nighttime hours. As a consequence, the distribution <math id="S2.p4.2.m2.1" class="ltx_Math" alttext="Q" display="inline"><semantics id="S2.p4.2.m2.1a"><mi id="S2.p4.2.m2.1.1" xref="S2.p4.2.m2.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S2.p4.2.m2.1b"><ci id="S2.p4.2.m2.1.1.cmml" xref="S2.p4.2.m2.1.1">𝑄</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p4.2.m2.1c">Q</annotation></semantics></math> changes cyclically.</p>
</div>
<div id="S2.p5" class="ltx_para">
<p id="S2.p5.8" class="ltx_p">In contrast to the violation of independence, common ways in which the principle of identicalness is violated are manifold. In FL, we distinguish between covariate shift, prior probability shift and concept shift. Covariate shift, also referred to as feature distribution skew, indicates the scenario in which the marginal distributions <math id="S2.p5.1.m1.1" class="ltx_Math" alttext="P_{i}(x)" display="inline"><semantics id="S2.p5.1.m1.1a"><mrow id="S2.p5.1.m1.1.2" xref="S2.p5.1.m1.1.2.cmml"><msub id="S2.p5.1.m1.1.2.2" xref="S2.p5.1.m1.1.2.2.cmml"><mi id="S2.p5.1.m1.1.2.2.2" xref="S2.p5.1.m1.1.2.2.2.cmml">P</mi><mi id="S2.p5.1.m1.1.2.2.3" xref="S2.p5.1.m1.1.2.2.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S2.p5.1.m1.1.2.1" xref="S2.p5.1.m1.1.2.1.cmml">​</mo><mrow id="S2.p5.1.m1.1.2.3.2" xref="S2.p5.1.m1.1.2.cmml"><mo stretchy="false" id="S2.p5.1.m1.1.2.3.2.1" xref="S2.p5.1.m1.1.2.cmml">(</mo><mi id="S2.p5.1.m1.1.1" xref="S2.p5.1.m1.1.1.cmml">x</mi><mo stretchy="false" id="S2.p5.1.m1.1.2.3.2.2" xref="S2.p5.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p5.1.m1.1b"><apply id="S2.p5.1.m1.1.2.cmml" xref="S2.p5.1.m1.1.2"><times id="S2.p5.1.m1.1.2.1.cmml" xref="S2.p5.1.m1.1.2.1"></times><apply id="S2.p5.1.m1.1.2.2.cmml" xref="S2.p5.1.m1.1.2.2"><csymbol cd="ambiguous" id="S2.p5.1.m1.1.2.2.1.cmml" xref="S2.p5.1.m1.1.2.2">subscript</csymbol><ci id="S2.p5.1.m1.1.2.2.2.cmml" xref="S2.p5.1.m1.1.2.2.2">𝑃</ci><ci id="S2.p5.1.m1.1.2.2.3.cmml" xref="S2.p5.1.m1.1.2.2.3">𝑖</ci></apply><ci id="S2.p5.1.m1.1.1.cmml" xref="S2.p5.1.m1.1.1">𝑥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.1.m1.1c">P_{i}(x)</annotation></semantics></math> varies across clients even if <math id="S2.p5.2.m2.1" class="ltx_Math" alttext="P(y|x)" display="inline"><semantics id="S2.p5.2.m2.1a"><mrow id="S2.p5.2.m2.1.1" xref="S2.p5.2.m2.1.1.cmml"><mi id="S2.p5.2.m2.1.1.3" xref="S2.p5.2.m2.1.1.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="S2.p5.2.m2.1.1.2" xref="S2.p5.2.m2.1.1.2.cmml">​</mo><mrow id="S2.p5.2.m2.1.1.1.1" xref="S2.p5.2.m2.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.p5.2.m2.1.1.1.1.2" xref="S2.p5.2.m2.1.1.1.1.1.cmml">(</mo><mrow id="S2.p5.2.m2.1.1.1.1.1" xref="S2.p5.2.m2.1.1.1.1.1.cmml"><mi id="S2.p5.2.m2.1.1.1.1.1.2" xref="S2.p5.2.m2.1.1.1.1.1.2.cmml">y</mi><mo fence="false" id="S2.p5.2.m2.1.1.1.1.1.1" xref="S2.p5.2.m2.1.1.1.1.1.1.cmml">|</mo><mi id="S2.p5.2.m2.1.1.1.1.1.3" xref="S2.p5.2.m2.1.1.1.1.1.3.cmml">x</mi></mrow><mo stretchy="false" id="S2.p5.2.m2.1.1.1.1.3" xref="S2.p5.2.m2.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p5.2.m2.1b"><apply id="S2.p5.2.m2.1.1.cmml" xref="S2.p5.2.m2.1.1"><times id="S2.p5.2.m2.1.1.2.cmml" xref="S2.p5.2.m2.1.1.2"></times><ci id="S2.p5.2.m2.1.1.3.cmml" xref="S2.p5.2.m2.1.1.3">𝑃</ci><apply id="S2.p5.2.m2.1.1.1.1.1.cmml" xref="S2.p5.2.m2.1.1.1.1"><csymbol cd="latexml" id="S2.p5.2.m2.1.1.1.1.1.1.cmml" xref="S2.p5.2.m2.1.1.1.1.1.1">conditional</csymbol><ci id="S2.p5.2.m2.1.1.1.1.1.2.cmml" xref="S2.p5.2.m2.1.1.1.1.1.2">𝑦</ci><ci id="S2.p5.2.m2.1.1.1.1.1.3.cmml" xref="S2.p5.2.m2.1.1.1.1.1.3">𝑥</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.2.m2.1c">P(y|x)</annotation></semantics></math> is shared. This is the case, for example, with handwriting recognition, where clients write the same words with different accentuations, such as stroke widths. Prior probability shift, also referred to as label distribution skew, indicates the scenario in which the marginal distributions <math id="S2.p5.3.m3.1" class="ltx_Math" alttext="P_{i}(y)" display="inline"><semantics id="S2.p5.3.m3.1a"><mrow id="S2.p5.3.m3.1.2" xref="S2.p5.3.m3.1.2.cmml"><msub id="S2.p5.3.m3.1.2.2" xref="S2.p5.3.m3.1.2.2.cmml"><mi id="S2.p5.3.m3.1.2.2.2" xref="S2.p5.3.m3.1.2.2.2.cmml">P</mi><mi id="S2.p5.3.m3.1.2.2.3" xref="S2.p5.3.m3.1.2.2.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S2.p5.3.m3.1.2.1" xref="S2.p5.3.m3.1.2.1.cmml">​</mo><mrow id="S2.p5.3.m3.1.2.3.2" xref="S2.p5.3.m3.1.2.cmml"><mo stretchy="false" id="S2.p5.3.m3.1.2.3.2.1" xref="S2.p5.3.m3.1.2.cmml">(</mo><mi id="S2.p5.3.m3.1.1" xref="S2.p5.3.m3.1.1.cmml">y</mi><mo stretchy="false" id="S2.p5.3.m3.1.2.3.2.2" xref="S2.p5.3.m3.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p5.3.m3.1b"><apply id="S2.p5.3.m3.1.2.cmml" xref="S2.p5.3.m3.1.2"><times id="S2.p5.3.m3.1.2.1.cmml" xref="S2.p5.3.m3.1.2.1"></times><apply id="S2.p5.3.m3.1.2.2.cmml" xref="S2.p5.3.m3.1.2.2"><csymbol cd="ambiguous" id="S2.p5.3.m3.1.2.2.1.cmml" xref="S2.p5.3.m3.1.2.2">subscript</csymbol><ci id="S2.p5.3.m3.1.2.2.2.cmml" xref="S2.p5.3.m3.1.2.2.2">𝑃</ci><ci id="S2.p5.3.m3.1.2.2.3.cmml" xref="S2.p5.3.m3.1.2.2.3">𝑖</ci></apply><ci id="S2.p5.3.m3.1.1.cmml" xref="S2.p5.3.m3.1.1">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.3.m3.1c">P_{i}(y)</annotation></semantics></math> varies across clients even if <math id="S2.p5.4.m4.1" class="ltx_Math" alttext="P(x|y)" display="inline"><semantics id="S2.p5.4.m4.1a"><mrow id="S2.p5.4.m4.1.1" xref="S2.p5.4.m4.1.1.cmml"><mi id="S2.p5.4.m4.1.1.3" xref="S2.p5.4.m4.1.1.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="S2.p5.4.m4.1.1.2" xref="S2.p5.4.m4.1.1.2.cmml">​</mo><mrow id="S2.p5.4.m4.1.1.1.1" xref="S2.p5.4.m4.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.p5.4.m4.1.1.1.1.2" xref="S2.p5.4.m4.1.1.1.1.1.cmml">(</mo><mrow id="S2.p5.4.m4.1.1.1.1.1" xref="S2.p5.4.m4.1.1.1.1.1.cmml"><mi id="S2.p5.4.m4.1.1.1.1.1.2" xref="S2.p5.4.m4.1.1.1.1.1.2.cmml">x</mi><mo fence="false" id="S2.p5.4.m4.1.1.1.1.1.1" xref="S2.p5.4.m4.1.1.1.1.1.1.cmml">|</mo><mi id="S2.p5.4.m4.1.1.1.1.1.3" xref="S2.p5.4.m4.1.1.1.1.1.3.cmml">y</mi></mrow><mo stretchy="false" id="S2.p5.4.m4.1.1.1.1.3" xref="S2.p5.4.m4.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p5.4.m4.1b"><apply id="S2.p5.4.m4.1.1.cmml" xref="S2.p5.4.m4.1.1"><times id="S2.p5.4.m4.1.1.2.cmml" xref="S2.p5.4.m4.1.1.2"></times><ci id="S2.p5.4.m4.1.1.3.cmml" xref="S2.p5.4.m4.1.1.3">𝑃</ci><apply id="S2.p5.4.m4.1.1.1.1.1.cmml" xref="S2.p5.4.m4.1.1.1.1"><csymbol cd="latexml" id="S2.p5.4.m4.1.1.1.1.1.1.cmml" xref="S2.p5.4.m4.1.1.1.1.1.1">conditional</csymbol><ci id="S2.p5.4.m4.1.1.1.1.1.2.cmml" xref="S2.p5.4.m4.1.1.1.1.1.2">𝑥</ci><ci id="S2.p5.4.m4.1.1.1.1.1.3.cmml" xref="S2.p5.4.m4.1.1.1.1.1.3">𝑦</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.4.m4.1c">P(x|y)</annotation></semantics></math> is shared. For example, clients located in different geographic regions may contain images of regional animals. Due to differences in the demographics of clients, skewed distribution of labels is most common for user-generated data. Thus, majority of research in FL is devoted to dealing with skewed labels. Concept shift may also be a reason for data to deviate from being identically distributed. It occurs in two distinct settings. First, the conditional distributions <math id="S2.p5.5.m5.1" class="ltx_Math" alttext="P_{i}(x|y)" display="inline"><semantics id="S2.p5.5.m5.1a"><mrow id="S2.p5.5.m5.1.1" xref="S2.p5.5.m5.1.1.cmml"><msub id="S2.p5.5.m5.1.1.3" xref="S2.p5.5.m5.1.1.3.cmml"><mi id="S2.p5.5.m5.1.1.3.2" xref="S2.p5.5.m5.1.1.3.2.cmml">P</mi><mi id="S2.p5.5.m5.1.1.3.3" xref="S2.p5.5.m5.1.1.3.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S2.p5.5.m5.1.1.2" xref="S2.p5.5.m5.1.1.2.cmml">​</mo><mrow id="S2.p5.5.m5.1.1.1.1" xref="S2.p5.5.m5.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.p5.5.m5.1.1.1.1.2" xref="S2.p5.5.m5.1.1.1.1.1.cmml">(</mo><mrow id="S2.p5.5.m5.1.1.1.1.1" xref="S2.p5.5.m5.1.1.1.1.1.cmml"><mi id="S2.p5.5.m5.1.1.1.1.1.2" xref="S2.p5.5.m5.1.1.1.1.1.2.cmml">x</mi><mo fence="false" id="S2.p5.5.m5.1.1.1.1.1.1" xref="S2.p5.5.m5.1.1.1.1.1.1.cmml">|</mo><mi id="S2.p5.5.m5.1.1.1.1.1.3" xref="S2.p5.5.m5.1.1.1.1.1.3.cmml">y</mi></mrow><mo stretchy="false" id="S2.p5.5.m5.1.1.1.1.3" xref="S2.p5.5.m5.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p5.5.m5.1b"><apply id="S2.p5.5.m5.1.1.cmml" xref="S2.p5.5.m5.1.1"><times id="S2.p5.5.m5.1.1.2.cmml" xref="S2.p5.5.m5.1.1.2"></times><apply id="S2.p5.5.m5.1.1.3.cmml" xref="S2.p5.5.m5.1.1.3"><csymbol cd="ambiguous" id="S2.p5.5.m5.1.1.3.1.cmml" xref="S2.p5.5.m5.1.1.3">subscript</csymbol><ci id="S2.p5.5.m5.1.1.3.2.cmml" xref="S2.p5.5.m5.1.1.3.2">𝑃</ci><ci id="S2.p5.5.m5.1.1.3.3.cmml" xref="S2.p5.5.m5.1.1.3.3">𝑖</ci></apply><apply id="S2.p5.5.m5.1.1.1.1.1.cmml" xref="S2.p5.5.m5.1.1.1.1"><csymbol cd="latexml" id="S2.p5.5.m5.1.1.1.1.1.1.cmml" xref="S2.p5.5.m5.1.1.1.1.1.1">conditional</csymbol><ci id="S2.p5.5.m5.1.1.1.1.1.2.cmml" xref="S2.p5.5.m5.1.1.1.1.1.2">𝑥</ci><ci id="S2.p5.5.m5.1.1.1.1.1.3.cmml" xref="S2.p5.5.m5.1.1.1.1.1.3">𝑦</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.5.m5.1c">P_{i}(x|y)</annotation></semantics></math> may vary across clients even if <math id="S2.p5.6.m6.1" class="ltx_Math" alttext="P(y)" display="inline"><semantics id="S2.p5.6.m6.1a"><mrow id="S2.p5.6.m6.1.2" xref="S2.p5.6.m6.1.2.cmml"><mi id="S2.p5.6.m6.1.2.2" xref="S2.p5.6.m6.1.2.2.cmml">P</mi><mo lspace="0em" rspace="0em" id="S2.p5.6.m6.1.2.1" xref="S2.p5.6.m6.1.2.1.cmml">​</mo><mrow id="S2.p5.6.m6.1.2.3.2" xref="S2.p5.6.m6.1.2.cmml"><mo stretchy="false" id="S2.p5.6.m6.1.2.3.2.1" xref="S2.p5.6.m6.1.2.cmml">(</mo><mi id="S2.p5.6.m6.1.1" xref="S2.p5.6.m6.1.1.cmml">y</mi><mo stretchy="false" id="S2.p5.6.m6.1.2.3.2.2" xref="S2.p5.6.m6.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p5.6.m6.1b"><apply id="S2.p5.6.m6.1.2.cmml" xref="S2.p5.6.m6.1.2"><times id="S2.p5.6.m6.1.2.1.cmml" xref="S2.p5.6.m6.1.2.1"></times><ci id="S2.p5.6.m6.1.2.2.cmml" xref="S2.p5.6.m6.1.2.2">𝑃</ci><ci id="S2.p5.6.m6.1.1.cmml" xref="S2.p5.6.m6.1.1">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.6.m6.1c">P(y)</annotation></semantics></math> is shared. In this case, the same label can have very dissimilar features for different clients. For example, images of clothing may vary widely across geographic regions, due to culture, weather conditions, standards of living or whether the images were captured during the day or at night. Second, the conditional distributions <math id="S2.p5.7.m7.1" class="ltx_Math" alttext="P_{i}(y|x)" display="inline"><semantics id="S2.p5.7.m7.1a"><mrow id="S2.p5.7.m7.1.1" xref="S2.p5.7.m7.1.1.cmml"><msub id="S2.p5.7.m7.1.1.3" xref="S2.p5.7.m7.1.1.3.cmml"><mi id="S2.p5.7.m7.1.1.3.2" xref="S2.p5.7.m7.1.1.3.2.cmml">P</mi><mi id="S2.p5.7.m7.1.1.3.3" xref="S2.p5.7.m7.1.1.3.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S2.p5.7.m7.1.1.2" xref="S2.p5.7.m7.1.1.2.cmml">​</mo><mrow id="S2.p5.7.m7.1.1.1.1" xref="S2.p5.7.m7.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.p5.7.m7.1.1.1.1.2" xref="S2.p5.7.m7.1.1.1.1.1.cmml">(</mo><mrow id="S2.p5.7.m7.1.1.1.1.1" xref="S2.p5.7.m7.1.1.1.1.1.cmml"><mi id="S2.p5.7.m7.1.1.1.1.1.2" xref="S2.p5.7.m7.1.1.1.1.1.2.cmml">y</mi><mo fence="false" id="S2.p5.7.m7.1.1.1.1.1.1" xref="S2.p5.7.m7.1.1.1.1.1.1.cmml">|</mo><mi id="S2.p5.7.m7.1.1.1.1.1.3" xref="S2.p5.7.m7.1.1.1.1.1.3.cmml">x</mi></mrow><mo stretchy="false" id="S2.p5.7.m7.1.1.1.1.3" xref="S2.p5.7.m7.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p5.7.m7.1b"><apply id="S2.p5.7.m7.1.1.cmml" xref="S2.p5.7.m7.1.1"><times id="S2.p5.7.m7.1.1.2.cmml" xref="S2.p5.7.m7.1.1.2"></times><apply id="S2.p5.7.m7.1.1.3.cmml" xref="S2.p5.7.m7.1.1.3"><csymbol cd="ambiguous" id="S2.p5.7.m7.1.1.3.1.cmml" xref="S2.p5.7.m7.1.1.3">subscript</csymbol><ci id="S2.p5.7.m7.1.1.3.2.cmml" xref="S2.p5.7.m7.1.1.3.2">𝑃</ci><ci id="S2.p5.7.m7.1.1.3.3.cmml" xref="S2.p5.7.m7.1.1.3.3">𝑖</ci></apply><apply id="S2.p5.7.m7.1.1.1.1.1.cmml" xref="S2.p5.7.m7.1.1.1.1"><csymbol cd="latexml" id="S2.p5.7.m7.1.1.1.1.1.1.cmml" xref="S2.p5.7.m7.1.1.1.1.1.1">conditional</csymbol><ci id="S2.p5.7.m7.1.1.1.1.1.2.cmml" xref="S2.p5.7.m7.1.1.1.1.1.2">𝑦</ci><ci id="S2.p5.7.m7.1.1.1.1.1.3.cmml" xref="S2.p5.7.m7.1.1.1.1.1.3">𝑥</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.7.m7.1c">P_{i}(y|x)</annotation></semantics></math> may vary across clients even if <math id="S2.p5.8.m8.1" class="ltx_Math" alttext="P(x)" display="inline"><semantics id="S2.p5.8.m8.1a"><mrow id="S2.p5.8.m8.1.2" xref="S2.p5.8.m8.1.2.cmml"><mi id="S2.p5.8.m8.1.2.2" xref="S2.p5.8.m8.1.2.2.cmml">P</mi><mo lspace="0em" rspace="0em" id="S2.p5.8.m8.1.2.1" xref="S2.p5.8.m8.1.2.1.cmml">​</mo><mrow id="S2.p5.8.m8.1.2.3.2" xref="S2.p5.8.m8.1.2.cmml"><mo stretchy="false" id="S2.p5.8.m8.1.2.3.2.1" xref="S2.p5.8.m8.1.2.cmml">(</mo><mi id="S2.p5.8.m8.1.1" xref="S2.p5.8.m8.1.1.cmml">x</mi><mo stretchy="false" id="S2.p5.8.m8.1.2.3.2.2" xref="S2.p5.8.m8.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p5.8.m8.1b"><apply id="S2.p5.8.m8.1.2.cmml" xref="S2.p5.8.m8.1.2"><times id="S2.p5.8.m8.1.2.1.cmml" xref="S2.p5.8.m8.1.2.1"></times><ci id="S2.p5.8.m8.1.2.2.cmml" xref="S2.p5.8.m8.1.2.2">𝑃</ci><ci id="S2.p5.8.m8.1.1.cmml" xref="S2.p5.8.m8.1.1">𝑥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.8.m8.1c">P(x)</annotation></semantics></math> is shared. In this case, the same features can be interpreted as different labels due to personal preferences. For example, next word prediction may vary across regions and depending on the client’s personal language. Similar, labels that reflect the sentiment of sentences have personal and regional variation. Apart from skewed distributions, clients may generate and hold vastly different amounts of data. This case resembles a form of data imbalance.</p>
</div>
<div id="S2.p6" class="ltx_para">
<p id="S2.p6.1" class="ltx_p">McMahan <em id="S2.p6.1.1" class="ltx_emph ltx_font_italic">et al</em>.<span id="S2.p6.1.2" class="ltx_text"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite> demonstrated by means of experiments that FL is able to converge under non-identical data distributions. Lacking a theoretical proof of convergence, Li <em id="S2.p6.1.3" class="ltx_emph ltx_font_italic">et al</em>.<span id="S2.p6.1.4" class="ltx_text"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> complemented theoretical convergence guarantees. Li <em id="S2.p6.1.5" class="ltx_emph ltx_font_italic">et al</em>.<span id="S2.p6.1.6" class="ltx_text"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite> and Khaled <em id="S2.p6.1.7" class="ltx_emph ltx_font_italic">et al</em>.<span id="S2.p6.1.8" class="ltx_text"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> further tightened the theoretical guarantees for the convergence of distributed optimization on statistically heterogeneous data.</p>
</div>
<div id="S2.p7" class="ltx_para">
<p id="S2.p7.1" class="ltx_p">Assuming that data are drawn independently from differing distributions, the impact of non-identically distributed data has been highlighted by several studies <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite>. Zhao <em id="S2.p7.1.1" class="ltx_emph ltx_font_italic">et al</em>.<span id="S2.p7.1.2" class="ltx_text"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite> attribute the detrimental effect to weight divergence, which refers to an observed drift in local models due to on-device training based on non-representative data. As the number of local training iterations increases, the drifts become more pronounced yielding a higher generalization gap. Recently, this line of work was extended upon by Chen <em id="S2.p7.1.3" class="ltx_emph ltx_font_italic">et al</em>.<span id="S2.p7.1.4" class="ltx_text"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>. The authors attribute the performance degeneration to a divergence in the activation in addition to the divergence in weights. The activation in neural networks is related to the last dense layer to yield logits, <em id="S2.p7.1.5" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S2.p7.1.6" class="ltx_text"></span>, unnormalized probabilities.</p>
</div>
<div id="S2.p8" class="ltx_para">
<p id="S2.p8.1" class="ltx_p">To address the issue of non-identicalness, several algorithmic extensions have been proposed <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>, <a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>. Zhao <em id="S2.p8.1.1" class="ltx_emph ltx_font_italic">et al</em>.<span id="S2.p8.1.2" class="ltx_text"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite> propose sharing a small portion of the data between the participating clients. While this approach helped mitigating the detrimental effect of non-identicalness, it is contradictory with the fundamental privacy-sensitive learning objective of FL. Li <em id="S2.p8.1.3" class="ltx_emph ltx_font_italic">et al</em>.<span id="S2.p8.1.4" class="ltx_text"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> introduce a proximal term to constrain the distance between local models and the global model. Showing that non-identical data leads to degradation of accuracy and a slowdown in the rate of convergence, Sattler <em id="S2.p8.1.5" class="ltx_emph ltx_font_italic">et al</em>.<span id="S2.p8.1.6" class="ltx_text"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite> advocate sparsification to permit more frequent global aggregation instead of local training iterations. Karimireddy <em id="S2.p8.1.7" class="ltx_emph ltx_font_italic">et al</em>.<span id="S2.p8.1.8" class="ltx_text"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> suggest utilizing a form of stochastic variance reduction to control the local drifts caused by non-identical data distribution. Recently, Duan <em id="S2.p8.1.9" class="ltx_emph ltx_font_italic">et al</em>.<span id="S2.p8.1.10" class="ltx_text"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> propose clustering the clients into multiple groups based on their cosine similarity of their local updates. By grouping clients into shared groups, a singular model is cascaded through intra-group and inter-group aggregation. Instead of increasing the resilience of a singular model to non-identical data, another line of research considers exploiting the statistical heterogeneity in non-identical data to construct pluralistic models through personalization. To attain personalization across groups of clients, several techniques from domain adaptation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> can be employed, such as local fine-tuning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>, mixture of experts <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite>, meta-learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>, or multi-task learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>. We refer to Kulkarni <em id="S2.p8.1.11" class="ltx_emph ltx_font_italic">et al</em>.<span id="S2.p8.1.12" class="ltx_text"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> for a comprehensive survey on personalization techniques in FL.</p>
</div>
<div id="S2.p9" class="ltx_para">
<p id="S2.p9.1" class="ltx_p">Compared to the plethora of research on non-identical data distributions, research on addressing the violations of independence stemming from changes in client availability is almost non-existent. For the purpose of language models, Eichner <em id="S2.p9.1.1" class="ltx_emph ltx_font_italic">et al</em>.<span id="S2.p9.1.2" class="ltx_text"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> studied the performance and convergence rate of FL when multiple blocks of clients with differing characteristics are sampled according to a regular cyclic pattern (<em id="S2.p9.1.3" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S2.p9.1.4" class="ltx_text"></span>, based on time zones). The authors show that block-cyclic sampling can significantly deteriorate the rate of convergence in FL. To mitigate the slowdown induced by the block-cyclic sampling, the authors suggest using pluralistic models. These models are built based on a semi-cyclic method that performs a one-time model averaging over the blocks of clients. In contrast to Eichner <em id="S2.p9.1.5" class="ltx_emph ltx_font_italic">et al</em>.<span id="S2.p9.1.6" class="ltx_text"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>, our paper takes a different angle by focusing on visual classification instead of natural language processing. We also investigate the effect of cycling over multi-block structures while considering both balanced and unbalanced block distributions.</p>
</div>
<div id="S2.p10" class="ltx_para">
<p id="S2.p10.1" class="ltx_p">Induced by violations of balancedness, several algorithmic subroutines to FL have been proposed <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib32" title="" class="ltx_ref">32</a>, <a href="#bib.bib39" title="" class="ltx_ref">39</a>, <a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>. To mitigate the effect of skewed data distributions, Duan <em id="S2.p10.1.1" class="ltx_emph ltx_font_italic">et al</em>.<span id="S2.p10.1.2" class="ltx_text"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> build a self-balancing framework that alleviates imbalance by applying a <math id="S2.p10.1.m1.1" class="ltx_Math" alttext="z" display="inline"><semantics id="S2.p10.1.m1.1a"><mi id="S2.p10.1.m1.1.1" xref="S2.p10.1.m1.1.1.cmml">z</mi><annotation-xml encoding="MathML-Content" id="S2.p10.1.m1.1b"><ci id="S2.p10.1.m1.1.1.cmml" xref="S2.p10.1.m1.1.1">𝑧</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p10.1.m1.1c">z</annotation></semantics></math>-score-based data augmentation along with a multi-client rescheduling scheme. Yang <em id="S2.p10.1.3" class="ltx_emph ltx_font_italic">et al</em>.<span id="S2.p10.1.4" class="ltx_text"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite> developed an estimation scheme of the class distribution that is used to adjust the scheduling according to the class distribution. Wang <em id="S2.p10.1.5" class="ltx_emph ltx_font_italic">et al</em>.<span id="S2.p10.1.6" class="ltx_text"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite> and Sarkar <em id="S2.p10.1.7" class="ltx_emph ltx_font_italic">et al</em>.<span id="S2.p10.1.8" class="ltx_text"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite> modify the objective function by adapting focal loss <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>.</p>
</div>
<div id="S2.p11" class="ltx_para">
<p id="S2.p11.1" class="ltx_p">Reviewing related studies on statistical heterogeneity yield that non-i.i.d. data regimes are typically examined in isolation with an apparent prevalence on non-identical data distributions. Highlighted by the recent findings of Eichner <em id="S2.p11.1.1" class="ltx_emph ltx_font_italic">et al</em>.<span id="S2.p11.1.2" class="ltx_text"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>, we complement on the scarce body of research on non-independence. More specifically, we make the following contributions: (i) we measure the implications of non-independent data arising from block-cyclic sampling, (ii) we a provide generalization to multi-block structures, (iii) we measure the moderation effect of block imbalance, and (iv) we analyze the sensitivity to the choice of the learning rate. By conducting extensive experiments on the interactions of non-independence and non-balancedness, we advocate for a paradigm shift towards other regimes of non-i.i.d. data and their combinations.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Methodology</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Unlike the definitional perspective of the previous section, we now adopt an applied perspective to present the experimental setup. At the level of block structures, the experiments consist of three dimensions: (i) non-independence, (ii) non-identicalness, and (iii) non-balancedness. With rigorous experimental methodologies, we explore the effect of these dimensions on the vanilla <span id="S3.p1.1.1" class="ltx_text ltx_font_typewriter">FedAvg</span> algorithm from the perspectives of accuracy, fairness, and convergence.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.3" class="ltx_p">The MNIST dataset provides the basis for all pathological experiments. We use MNIST for reference as it is commonly used in FL literature. In total, the MNIST dataset contains <math id="S3.p2.1.m1.2" class="ltx_Math" alttext="60,000" display="inline"><semantics id="S3.p2.1.m1.2a"><mrow id="S3.p2.1.m1.2.3.2" xref="S3.p2.1.m1.2.3.1.cmml"><mn id="S3.p2.1.m1.1.1" xref="S3.p2.1.m1.1.1.cmml">60</mn><mo id="S3.p2.1.m1.2.3.2.1" xref="S3.p2.1.m1.2.3.1.cmml">,</mo><mn id="S3.p2.1.m1.2.2" xref="S3.p2.1.m1.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.1.m1.2b"><list id="S3.p2.1.m1.2.3.1.cmml" xref="S3.p2.1.m1.2.3.2"><cn type="integer" id="S3.p2.1.m1.1.1.cmml" xref="S3.p2.1.m1.1.1">60</cn><cn type="integer" id="S3.p2.1.m1.2.2.cmml" xref="S3.p2.1.m1.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.1.m1.2c">60,000</annotation></semantics></math> labeled images from <math id="S3.p2.2.m2.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S3.p2.2.m2.1a"><mn id="S3.p2.2.m2.1.1" xref="S3.p2.2.m2.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S3.p2.2.m2.1b"><cn type="integer" id="S3.p2.2.m2.1.1.cmml" xref="S3.p2.2.m2.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.2.m2.1c">10</annotation></semantics></math> classes whereby additional <math id="S3.p2.3.m3.2" class="ltx_Math" alttext="10,000" display="inline"><semantics id="S3.p2.3.m3.2a"><mrow id="S3.p2.3.m3.2.3.2" xref="S3.p2.3.m3.2.3.1.cmml"><mn id="S3.p2.3.m3.1.1" xref="S3.p2.3.m3.1.1.cmml">10</mn><mo id="S3.p2.3.m3.2.3.2.1" xref="S3.p2.3.m3.2.3.1.cmml">,</mo><mn id="S3.p2.3.m3.2.2" xref="S3.p2.3.m3.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.3.m3.2b"><list id="S3.p2.3.m3.2.3.1.cmml" xref="S3.p2.3.m3.2.3.2"><cn type="integer" id="S3.p2.3.m3.1.1.cmml" xref="S3.p2.3.m3.1.1">10</cn><cn type="integer" id="S3.p2.3.m3.2.2.cmml" xref="S3.p2.3.m3.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.3.m3.2c">10,000</annotation></semantics></math> images are reserved has holdout for validation. For the i.i.d. setting, we subsample a population of homogeneous clients with an almost equal number of samples per class. This represents an unrealistic setting since practical FL would typically involve clients with data generated from heterogeneous interests and behaviors. To synthetize this homogeneous population, we randomly assign a uniform distribution over all classes to each client without replacement. Therefore, each client holds a similar amount of data samples from all classes.</p>
</div>
<div id="S3.p3" class="ltx_para">
<p id="S3.p3.1" class="ltx_p">In contrast to the i.i.d. setting, we use the term non-i.i.d. data to refer to samples that have been purposely redistributed to a client. To synthesize a population with non-i.i.d. data, we follow the approach of sorting and partitioning data into shards as put forward by McMahan <em id="S3.p3.1.1" class="ltx_emph ltx_font_italic">et al</em>.<span id="S3.p3.1.2" class="ltx_text"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>. This approach is widely used to analyze and benchmark FL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib33" title="" class="ltx_ref">33</a>, <a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite>. The step-by-step process is to sort the data by labels, divide the data label-wise into equally sized shards, and then randomly assign a fixed number <math id="S3.p3.1.m1.1" class="ltx_Math" alttext="s\geq 1" display="inline"><semantics id="S3.p3.1.m1.1a"><mrow id="S3.p3.1.m1.1.1" xref="S3.p3.1.m1.1.1.cmml"><mi id="S3.p3.1.m1.1.1.2" xref="S3.p3.1.m1.1.1.2.cmml">s</mi><mo id="S3.p3.1.m1.1.1.1" xref="S3.p3.1.m1.1.1.1.cmml">≥</mo><mn id="S3.p3.1.m1.1.1.3" xref="S3.p3.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.p3.1.m1.1b"><apply id="S3.p3.1.m1.1.1.cmml" xref="S3.p3.1.m1.1.1"><geq id="S3.p3.1.m1.1.1.1.cmml" xref="S3.p3.1.m1.1.1.1"></geq><ci id="S3.p3.1.m1.1.1.2.cmml" xref="S3.p3.1.m1.1.1.2">𝑠</ci><cn type="integer" id="S3.p3.1.m1.1.1.3.cmml" xref="S3.p3.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.1.m1.1c">s\geq 1</annotation></semantics></math> of shards to each client. Although this represents a pathological extreme case of non-identicalness, practical FL is likely to involve more complex distributions than partitions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>.</p>
</div>
<div id="S3.p4" class="ltx_para">
<p id="S3.p4.7" class="ltx_p">We modify this sort-and-partition manner to account for <math id="S3.p4.1.m1.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S3.p4.1.m1.1a"><mi id="S3.p4.1.m1.1.1" xref="S3.p4.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.p4.1.m1.1b"><ci id="S3.p4.1.m1.1.1.cmml" xref="S3.p4.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.1.m1.1c">n</annotation></semantics></math>-block structures. Instead of assigning a number of shards from all labels to each client at random, we group the sorted labels according to a configured number of equally sized blocks <math id="S3.p4.2.m2.2" class="ltx_Math" alttext="G=\{2,5\}" display="inline"><semantics id="S3.p4.2.m2.2a"><mrow id="S3.p4.2.m2.2.3" xref="S3.p4.2.m2.2.3.cmml"><mi id="S3.p4.2.m2.2.3.2" xref="S3.p4.2.m2.2.3.2.cmml">G</mi><mo id="S3.p4.2.m2.2.3.1" xref="S3.p4.2.m2.2.3.1.cmml">=</mo><mrow id="S3.p4.2.m2.2.3.3.2" xref="S3.p4.2.m2.2.3.3.1.cmml"><mo stretchy="false" id="S3.p4.2.m2.2.3.3.2.1" xref="S3.p4.2.m2.2.3.3.1.cmml">{</mo><mn id="S3.p4.2.m2.1.1" xref="S3.p4.2.m2.1.1.cmml">2</mn><mo id="S3.p4.2.m2.2.3.3.2.2" xref="S3.p4.2.m2.2.3.3.1.cmml">,</mo><mn id="S3.p4.2.m2.2.2" xref="S3.p4.2.m2.2.2.cmml">5</mn><mo stretchy="false" id="S3.p4.2.m2.2.3.3.2.3" xref="S3.p4.2.m2.2.3.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p4.2.m2.2b"><apply id="S3.p4.2.m2.2.3.cmml" xref="S3.p4.2.m2.2.3"><eq id="S3.p4.2.m2.2.3.1.cmml" xref="S3.p4.2.m2.2.3.1"></eq><ci id="S3.p4.2.m2.2.3.2.cmml" xref="S3.p4.2.m2.2.3.2">𝐺</ci><set id="S3.p4.2.m2.2.3.3.1.cmml" xref="S3.p4.2.m2.2.3.3.2"><cn type="integer" id="S3.p4.2.m2.1.1.cmml" xref="S3.p4.2.m2.1.1">2</cn><cn type="integer" id="S3.p4.2.m2.2.2.cmml" xref="S3.p4.2.m2.2.2">5</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.2.m2.2c">G=\{2,5\}</annotation></semantics></math>. FL assumes <math id="S3.p4.3.m3.1" class="ltx_Math" alttext="G=1" display="inline"><semantics id="S3.p4.3.m3.1a"><mrow id="S3.p4.3.m3.1.1" xref="S3.p4.3.m3.1.1.cmml"><mi id="S3.p4.3.m3.1.1.2" xref="S3.p4.3.m3.1.1.2.cmml">G</mi><mo id="S3.p4.3.m3.1.1.1" xref="S3.p4.3.m3.1.1.1.cmml">=</mo><mn id="S3.p4.3.m3.1.1.3" xref="S3.p4.3.m3.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.p4.3.m3.1b"><apply id="S3.p4.3.m3.1.1.cmml" xref="S3.p4.3.m3.1.1"><eq id="S3.p4.3.m3.1.1.1.cmml" xref="S3.p4.3.m3.1.1.1"></eq><ci id="S3.p4.3.m3.1.1.2.cmml" xref="S3.p4.3.m3.1.1.2">𝐺</ci><cn type="integer" id="S3.p4.3.m3.1.1.3.cmml" xref="S3.p4.3.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.3.m3.1c">G=1</annotation></semantics></math> by design, which means that the samples are drawn independently from a single homogeneous group consisting of all clients. Considering that samples from a block are processed each <math id="S3.p4.4.m4.1" class="ltx_Math" alttext="G^{\text{th}}" display="inline"><semantics id="S3.p4.4.m4.1a"><msup id="S3.p4.4.m4.1.1" xref="S3.p4.4.m4.1.1.cmml"><mi id="S3.p4.4.m4.1.1.2" xref="S3.p4.4.m4.1.1.2.cmml">G</mi><mtext id="S3.p4.4.m4.1.1.3" xref="S3.p4.4.m4.1.1.3a.cmml">th</mtext></msup><annotation-xml encoding="MathML-Content" id="S3.p4.4.m4.1b"><apply id="S3.p4.4.m4.1.1.cmml" xref="S3.p4.4.m4.1.1"><csymbol cd="ambiguous" id="S3.p4.4.m4.1.1.1.cmml" xref="S3.p4.4.m4.1.1">superscript</csymbol><ci id="S3.p4.4.m4.1.1.2.cmml" xref="S3.p4.4.m4.1.1.2">𝐺</ci><ci id="S3.p4.4.m4.1.1.3a.cmml" xref="S3.p4.4.m4.1.1.3"><mtext mathsize="70%" id="S3.p4.4.m4.1.1.3.cmml" xref="S3.p4.4.m4.1.1.3">th</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.4.m4.1c">G^{\text{th}}</annotation></semantics></math> round, higher <math id="S3.p4.5.m5.1" class="ltx_Math" alttext="G" display="inline"><semantics id="S3.p4.5.m5.1a"><mi id="S3.p4.5.m5.1.1" xref="S3.p4.5.m5.1.1.cmml">G</mi><annotation-xml encoding="MathML-Content" id="S3.p4.5.m5.1b"><ci id="S3.p4.5.m5.1.1.cmml" xref="S3.p4.5.m5.1.1">𝐺</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.5.m5.1c">G</annotation></semantics></math> naturally yields to more dependence. Thus, any <math id="S3.p4.6.m6.1" class="ltx_Math" alttext="G&gt;1" display="inline"><semantics id="S3.p4.6.m6.1a"><mrow id="S3.p4.6.m6.1.1" xref="S3.p4.6.m6.1.1.cmml"><mi id="S3.p4.6.m6.1.1.2" xref="S3.p4.6.m6.1.1.2.cmml">G</mi><mo id="S3.p4.6.m6.1.1.1" xref="S3.p4.6.m6.1.1.1.cmml">&gt;</mo><mn id="S3.p4.6.m6.1.1.3" xref="S3.p4.6.m6.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.p4.6.m6.1b"><apply id="S3.p4.6.m6.1.1.cmml" xref="S3.p4.6.m6.1.1"><gt id="S3.p4.6.m6.1.1.1.cmml" xref="S3.p4.6.m6.1.1.1"></gt><ci id="S3.p4.6.m6.1.1.2.cmml" xref="S3.p4.6.m6.1.1.2">𝐺</ci><cn type="integer" id="S3.p4.6.m6.1.1.3.cmml" xref="S3.p4.6.m6.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.6.m6.1c">G&gt;1</annotation></semantics></math> represents non-independence. Each client is then assigned to a block and subsamples shards associated with this block. We fixed the number of shards to <math id="S3.p4.7.m7.1" class="ltx_Math" alttext="s=2" display="inline"><semantics id="S3.p4.7.m7.1a"><mrow id="S3.p4.7.m7.1.1" xref="S3.p4.7.m7.1.1.cmml"><mi id="S3.p4.7.m7.1.1.2" xref="S3.p4.7.m7.1.1.2.cmml">s</mi><mo id="S3.p4.7.m7.1.1.1" xref="S3.p4.7.m7.1.1.1.cmml">=</mo><mn id="S3.p4.7.m7.1.1.3" xref="S3.p4.7.m7.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.p4.7.m7.1b"><apply id="S3.p4.7.m7.1.1.cmml" xref="S3.p4.7.m7.1.1"><eq id="S3.p4.7.m7.1.1.1.cmml" xref="S3.p4.7.m7.1.1.1"></eq><ci id="S3.p4.7.m7.1.1.2.cmml" xref="S3.p4.7.m7.1.1.2">𝑠</ci><cn type="integer" id="S3.p4.7.m7.1.1.3.cmml" xref="S3.p4.7.m7.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.7.m7.1c">s=2</annotation></semantics></math>. With this modification we generate blocks consisting of non-overlapping classes. Figure <a href="#S3.F1" title="Figure 1 ‣ 3 Methodology ‣ Demystifying the Effects of Non-Independence in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows an example for an instantiation of this process with fifteen clients partitioned into a five-block structure. Note that classes (coded by color) are not shared between the blocks.</p>
</div>
<div id="S3.p5" class="ltx_para">
<p id="S3.p5.2" class="ltx_p">To account for a block-level non-balancedness, instead of assigning an equal number of samples per block, we distribute shards with replacement in a way that the number of samples across blocks follows a power law distribution. Note that this has a similar effect to distributing the number of clients per block following the power law. For the power law distribution, we experiment with a discrete range of scaling factors <math id="S3.p5.1.m1.4" class="ltx_Math" alttext="\alpha\in\{1.0,1.5,2.0,5.0\}" display="inline"><semantics id="S3.p5.1.m1.4a"><mrow id="S3.p5.1.m1.4.5" xref="S3.p5.1.m1.4.5.cmml"><mi id="S3.p5.1.m1.4.5.2" xref="S3.p5.1.m1.4.5.2.cmml">α</mi><mo id="S3.p5.1.m1.4.5.1" xref="S3.p5.1.m1.4.5.1.cmml">∈</mo><mrow id="S3.p5.1.m1.4.5.3.2" xref="S3.p5.1.m1.4.5.3.1.cmml"><mo stretchy="false" id="S3.p5.1.m1.4.5.3.2.1" xref="S3.p5.1.m1.4.5.3.1.cmml">{</mo><mn id="S3.p5.1.m1.1.1" xref="S3.p5.1.m1.1.1.cmml">1.0</mn><mo id="S3.p5.1.m1.4.5.3.2.2" xref="S3.p5.1.m1.4.5.3.1.cmml">,</mo><mn id="S3.p5.1.m1.2.2" xref="S3.p5.1.m1.2.2.cmml">1.5</mn><mo id="S3.p5.1.m1.4.5.3.2.3" xref="S3.p5.1.m1.4.5.3.1.cmml">,</mo><mn id="S3.p5.1.m1.3.3" xref="S3.p5.1.m1.3.3.cmml">2.0</mn><mo id="S3.p5.1.m1.4.5.3.2.4" xref="S3.p5.1.m1.4.5.3.1.cmml">,</mo><mn id="S3.p5.1.m1.4.4" xref="S3.p5.1.m1.4.4.cmml">5.0</mn><mo stretchy="false" id="S3.p5.1.m1.4.5.3.2.5" xref="S3.p5.1.m1.4.5.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p5.1.m1.4b"><apply id="S3.p5.1.m1.4.5.cmml" xref="S3.p5.1.m1.4.5"><in id="S3.p5.1.m1.4.5.1.cmml" xref="S3.p5.1.m1.4.5.1"></in><ci id="S3.p5.1.m1.4.5.2.cmml" xref="S3.p5.1.m1.4.5.2">𝛼</ci><set id="S3.p5.1.m1.4.5.3.1.cmml" xref="S3.p5.1.m1.4.5.3.2"><cn type="float" id="S3.p5.1.m1.1.1.cmml" xref="S3.p5.1.m1.1.1">1.0</cn><cn type="float" id="S3.p5.1.m1.2.2.cmml" xref="S3.p5.1.m1.2.2">1.5</cn><cn type="float" id="S3.p5.1.m1.3.3.cmml" xref="S3.p5.1.m1.3.3">2.0</cn><cn type="float" id="S3.p5.1.m1.4.4.cmml" xref="S3.p5.1.m1.4.4">5.0</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p5.1.m1.4c">\alpha\in\{1.0,1.5,2.0,5.0\}</annotation></semantics></math>. For example, a two-block structure corresponds to minority-majority ratio of approximately <math id="S3.p5.2.m2.8" class="ltx_Math" alttext="\{1:1,1:2,1:3,1:11\}" display="inline"><semantics id="S3.p5.2.m2.8a"><mrow id="S3.p5.2.m2.8.8.1" xref="S3.p5.2.m2.8.8.2.cmml"><mo stretchy="false" id="S3.p5.2.m2.8.8.1.2" xref="S3.p5.2.m2.8.8.2.1.cmml">{</mo><mn id="S3.p5.2.m2.7.7" xref="S3.p5.2.m2.7.7.cmml">1</mn><mo lspace="0.278em" rspace="0.278em" id="S3.p5.2.m2.8.8.1.3" xref="S3.p5.2.m2.8.8.2.1.cmml">:</mo><mrow id="S3.p5.2.m2.8.8.1.1" xref="S3.p5.2.m2.8.8.1.1.cmml"><mrow id="S3.p5.2.m2.8.8.1.1.2.2" xref="S3.p5.2.m2.8.8.1.1.2.1.cmml"><mn id="S3.p5.2.m2.1.1" xref="S3.p5.2.m2.1.1.cmml">1</mn><mo id="S3.p5.2.m2.8.8.1.1.2.2.1" xref="S3.p5.2.m2.8.8.1.1.2.1.cmml">,</mo><mn id="S3.p5.2.m2.2.2" xref="S3.p5.2.m2.2.2.cmml">1</mn></mrow><mo lspace="0.278em" rspace="0.278em" id="S3.p5.2.m2.8.8.1.1.3" xref="S3.p5.2.m2.8.8.1.1.3.cmml">:</mo><mrow id="S3.p5.2.m2.8.8.1.1.4.2" xref="S3.p5.2.m2.8.8.1.1.4.1.cmml"><mn id="S3.p5.2.m2.3.3" xref="S3.p5.2.m2.3.3.cmml">2</mn><mo id="S3.p5.2.m2.8.8.1.1.4.2.1" xref="S3.p5.2.m2.8.8.1.1.4.1.cmml">,</mo><mn id="S3.p5.2.m2.4.4" xref="S3.p5.2.m2.4.4.cmml">1</mn></mrow><mo lspace="0.278em" rspace="0.278em" id="S3.p5.2.m2.8.8.1.1.5" xref="S3.p5.2.m2.8.8.1.1.5.cmml">:</mo><mrow id="S3.p5.2.m2.8.8.1.1.6.2" xref="S3.p5.2.m2.8.8.1.1.6.1.cmml"><mn id="S3.p5.2.m2.5.5" xref="S3.p5.2.m2.5.5.cmml">3</mn><mo id="S3.p5.2.m2.8.8.1.1.6.2.1" xref="S3.p5.2.m2.8.8.1.1.6.1.cmml">,</mo><mn id="S3.p5.2.m2.6.6" xref="S3.p5.2.m2.6.6.cmml">1</mn></mrow><mo lspace="0.278em" rspace="0.278em" id="S3.p5.2.m2.8.8.1.1.7" xref="S3.p5.2.m2.8.8.1.1.7.cmml">:</mo><mn id="S3.p5.2.m2.8.8.1.1.8" xref="S3.p5.2.m2.8.8.1.1.8.cmml">11</mn></mrow><mo stretchy="false" id="S3.p5.2.m2.8.8.1.4" xref="S3.p5.2.m2.8.8.2.1.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.p5.2.m2.8b"><apply id="S3.p5.2.m2.8.8.2.cmml" xref="S3.p5.2.m2.8.8.1"><csymbol cd="latexml" id="S3.p5.2.m2.8.8.2.1.cmml" xref="S3.p5.2.m2.8.8.1.2">conditional-set</csymbol><cn type="integer" id="S3.p5.2.m2.7.7.cmml" xref="S3.p5.2.m2.7.7">1</cn><apply id="S3.p5.2.m2.8.8.1.1.cmml" xref="S3.p5.2.m2.8.8.1.1"><and id="S3.p5.2.m2.8.8.1.1a.cmml" xref="S3.p5.2.m2.8.8.1.1"></and><apply id="S3.p5.2.m2.8.8.1.1b.cmml" xref="S3.p5.2.m2.8.8.1.1"><ci id="S3.p5.2.m2.8.8.1.1.3.cmml" xref="S3.p5.2.m2.8.8.1.1.3">:</ci><list id="S3.p5.2.m2.8.8.1.1.2.1.cmml" xref="S3.p5.2.m2.8.8.1.1.2.2"><cn type="integer" id="S3.p5.2.m2.1.1.cmml" xref="S3.p5.2.m2.1.1">1</cn><cn type="integer" id="S3.p5.2.m2.2.2.cmml" xref="S3.p5.2.m2.2.2">1</cn></list><list id="S3.p5.2.m2.8.8.1.1.4.1.cmml" xref="S3.p5.2.m2.8.8.1.1.4.2"><cn type="integer" id="S3.p5.2.m2.3.3.cmml" xref="S3.p5.2.m2.3.3">2</cn><cn type="integer" id="S3.p5.2.m2.4.4.cmml" xref="S3.p5.2.m2.4.4">1</cn></list></apply><apply id="S3.p5.2.m2.8.8.1.1c.cmml" xref="S3.p5.2.m2.8.8.1.1"><ci id="S3.p5.2.m2.8.8.1.1.5.cmml" xref="S3.p5.2.m2.8.8.1.1.5">:</ci><share href="#S3.p5.2.m2.8.8.1.1.4.cmml" id="S3.p5.2.m2.8.8.1.1d.cmml" xref="S3.p5.2.m2.8.8.1.1"></share><list id="S3.p5.2.m2.8.8.1.1.6.1.cmml" xref="S3.p5.2.m2.8.8.1.1.6.2"><cn type="integer" id="S3.p5.2.m2.5.5.cmml" xref="S3.p5.2.m2.5.5">3</cn><cn type="integer" id="S3.p5.2.m2.6.6.cmml" xref="S3.p5.2.m2.6.6">1</cn></list></apply><apply id="S3.p5.2.m2.8.8.1.1e.cmml" xref="S3.p5.2.m2.8.8.1.1"><ci id="S3.p5.2.m2.8.8.1.1.7.cmml" xref="S3.p5.2.m2.8.8.1.1.7">:</ci><share href="#S3.p5.2.m2.8.8.1.1.6.cmml" id="S3.p5.2.m2.8.8.1.1f.cmml" xref="S3.p5.2.m2.8.8.1.1"></share><cn type="integer" id="S3.p5.2.m2.8.8.1.1.8.cmml" xref="S3.p5.2.m2.8.8.1.1.8">11</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p5.2.m2.8c">\{1:1,1:2,1:3,1:11\}</annotation></semantics></math>.</p>
</div>
<div id="S3.p6" class="ltx_para">
<p id="S3.p6.3" class="ltx_p">We separate a part of each client’s data as a holdout set. To generate the local holdout sets, we subsample examples from the MNIST validation set using the same distribution that has been used to construct the local training data. Thus, the holdout set inherits the local distribution and therefore each client’s test data is different. In each round, we measure and report the accuracy of the global model on the union of the holdout set and the local accuracy of each client on its own local holdout data. In this way, we account for the recent debate on fairness in FL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib23" title="" class="ltx_ref">23</a>, <a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>. To assess the fairness change induced by cyclic sampling, we adopt the definition of fairness formulated by Li <em id="S3.p6.3.1" class="ltx_emph ltx_font_italic">et al</em>.<span id="S3.p6.3.2" class="ltx_text"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>. A consensus model <math id="S3.p6.1.m1.1" class="ltx_Math" alttext="w" display="inline"><semantics id="S3.p6.1.m1.1a"><mi id="S3.p6.1.m1.1.1" xref="S3.p6.1.m1.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="S3.p6.1.m1.1b"><ci id="S3.p6.1.m1.1.1.cmml" xref="S3.p6.1.m1.1.1">𝑤</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p6.1.m1.1c">w</annotation></semantics></math> is considered fair when its generalization performance <math id="S3.p6.2.m2.3" class="ltx_Math" alttext="\{A_{1},…,A_{m}\}" display="inline"><semantics id="S3.p6.2.m2.3a"><mrow id="S3.p6.2.m2.3.3.2" xref="S3.p6.2.m2.3.3.3.cmml"><mo stretchy="false" id="S3.p6.2.m2.3.3.2.3" xref="S3.p6.2.m2.3.3.3.cmml">{</mo><msub id="S3.p6.2.m2.2.2.1.1" xref="S3.p6.2.m2.2.2.1.1.cmml"><mi id="S3.p6.2.m2.2.2.1.1.2" xref="S3.p6.2.m2.2.2.1.1.2.cmml">A</mi><mn id="S3.p6.2.m2.2.2.1.1.3" xref="S3.p6.2.m2.2.2.1.1.3.cmml">1</mn></msub><mo id="S3.p6.2.m2.3.3.2.4" xref="S3.p6.2.m2.3.3.3.cmml">,</mo><mi mathvariant="normal" id="S3.p6.2.m2.1.1" xref="S3.p6.2.m2.1.1.cmml">…</mi><mo id="S3.p6.2.m2.3.3.2.5" xref="S3.p6.2.m2.3.3.3.cmml">,</mo><msub id="S3.p6.2.m2.3.3.2.2" xref="S3.p6.2.m2.3.3.2.2.cmml"><mi id="S3.p6.2.m2.3.3.2.2.2" xref="S3.p6.2.m2.3.3.2.2.2.cmml">A</mi><mi id="S3.p6.2.m2.3.3.2.2.3" xref="S3.p6.2.m2.3.3.2.2.3.cmml">m</mi></msub><mo stretchy="false" id="S3.p6.2.m2.3.3.2.6" xref="S3.p6.2.m2.3.3.3.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.p6.2.m2.3b"><set id="S3.p6.2.m2.3.3.3.cmml" xref="S3.p6.2.m2.3.3.2"><apply id="S3.p6.2.m2.2.2.1.1.cmml" xref="S3.p6.2.m2.2.2.1.1"><csymbol cd="ambiguous" id="S3.p6.2.m2.2.2.1.1.1.cmml" xref="S3.p6.2.m2.2.2.1.1">subscript</csymbol><ci id="S3.p6.2.m2.2.2.1.1.2.cmml" xref="S3.p6.2.m2.2.2.1.1.2">𝐴</ci><cn type="integer" id="S3.p6.2.m2.2.2.1.1.3.cmml" xref="S3.p6.2.m2.2.2.1.1.3">1</cn></apply><ci id="S3.p6.2.m2.1.1.cmml" xref="S3.p6.2.m2.1.1">…</ci><apply id="S3.p6.2.m2.3.3.2.2.cmml" xref="S3.p6.2.m2.3.3.2.2"><csymbol cd="ambiguous" id="S3.p6.2.m2.3.3.2.2.1.cmml" xref="S3.p6.2.m2.3.3.2.2">subscript</csymbol><ci id="S3.p6.2.m2.3.3.2.2.2.cmml" xref="S3.p6.2.m2.3.3.2.2.2">𝐴</ci><ci id="S3.p6.2.m2.3.3.2.2.3.cmml" xref="S3.p6.2.m2.3.3.2.2.3">𝑚</ci></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S3.p6.2.m2.3c">\{A_{1},…,A_{m}\}</annotation></semantics></math> is <span id="S3.p6.3.3" class="ltx_text ltx_font_italic">uniform</span> across <math id="S3.p6.3.m3.1" class="ltx_Math" alttext="m" display="inline"><semantics id="S3.p6.3.m3.1a"><mi id="S3.p6.3.m3.1.1" xref="S3.p6.3.m3.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S3.p6.3.m3.1b"><ci id="S3.p6.3.m3.1.1.cmml" xref="S3.p6.3.m3.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p6.3.m3.1c">m</annotation></semantics></math> clients.</p>
</div>
<figure id="S3.F1" class="ltx_figure"><img src="/html/2103.11226/assets/x1.png" id="S3.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="172" height="101" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Exemplary representation of a five-block structure with <math id="S3.F1.3.m1.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S3.F1.3.m1.1b"><mn id="S3.F1.3.m1.1.1" xref="S3.F1.3.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S3.F1.3.m1.1c"><cn type="integer" id="S3.F1.3.m1.1.1.cmml" xref="S3.F1.3.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.F1.3.m1.1d">2</annotation></semantics></math> classes per block across <math id="S3.F1.4.m2.1" class="ltx_Math" alttext="15" display="inline"><semantics id="S3.F1.4.m2.1b"><mn id="S3.F1.4.m2.1.1" xref="S3.F1.4.m2.1.1.cmml">15</mn><annotation-xml encoding="MathML-Content" id="S3.F1.4.m2.1c"><cn type="integer" id="S3.F1.4.m2.1.1.cmml" xref="S3.F1.4.m2.1.1">15</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.F1.4.m2.1d">15</annotation></semantics></math> clients. Classes are colored by label. Note that classes are not shared between the blocks.</figcaption>
</figure>
<div id="S3.p7" class="ltx_para">
<p id="S3.p7.7" class="ltx_p">In line with Eichner <em id="S3.p7.7.1" class="ltx_emph ltx_font_italic">et al</em>.<span id="S3.p7.7.2" class="ltx_text"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>, we model and operationalize the block-structure by modifying the random selection of a subset of clients into block-cyclic selection. During the course of training, we cycle over blocks in a fixed and repeating order and select a configured fraction of clients belonging to the current block at random. For example, given two cyclically ordered blocks [A,B], we select a subset of clients <math id="S3.p7.1.m1.1" class="ltx_Math" alttext="S_{t}=K\times C\leq\lceil G\rceil" display="inline"><semantics id="S3.p7.1.m1.1a"><mrow id="S3.p7.1.m1.1.2" xref="S3.p7.1.m1.1.2.cmml"><msub id="S3.p7.1.m1.1.2.2" xref="S3.p7.1.m1.1.2.2.cmml"><mi id="S3.p7.1.m1.1.2.2.2" xref="S3.p7.1.m1.1.2.2.2.cmml">S</mi><mi id="S3.p7.1.m1.1.2.2.3" xref="S3.p7.1.m1.1.2.2.3.cmml">t</mi></msub><mo id="S3.p7.1.m1.1.2.3" xref="S3.p7.1.m1.1.2.3.cmml">=</mo><mrow id="S3.p7.1.m1.1.2.4" xref="S3.p7.1.m1.1.2.4.cmml"><mi id="S3.p7.1.m1.1.2.4.2" xref="S3.p7.1.m1.1.2.4.2.cmml">K</mi><mo lspace="0.222em" rspace="0.222em" id="S3.p7.1.m1.1.2.4.1" xref="S3.p7.1.m1.1.2.4.1.cmml">×</mo><mi id="S3.p7.1.m1.1.2.4.3" xref="S3.p7.1.m1.1.2.4.3.cmml">C</mi></mrow><mo id="S3.p7.1.m1.1.2.5" xref="S3.p7.1.m1.1.2.5.cmml">≤</mo><mrow id="S3.p7.1.m1.1.2.6.2" xref="S3.p7.1.m1.1.2.6.1.cmml"><mo stretchy="false" id="S3.p7.1.m1.1.2.6.2.1" xref="S3.p7.1.m1.1.2.6.1.1.cmml">⌈</mo><mi id="S3.p7.1.m1.1.1" xref="S3.p7.1.m1.1.1.cmml">G</mi><mo stretchy="false" id="S3.p7.1.m1.1.2.6.2.2" xref="S3.p7.1.m1.1.2.6.1.1.cmml">⌉</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p7.1.m1.1b"><apply id="S3.p7.1.m1.1.2.cmml" xref="S3.p7.1.m1.1.2"><and id="S3.p7.1.m1.1.2a.cmml" xref="S3.p7.1.m1.1.2"></and><apply id="S3.p7.1.m1.1.2b.cmml" xref="S3.p7.1.m1.1.2"><eq id="S3.p7.1.m1.1.2.3.cmml" xref="S3.p7.1.m1.1.2.3"></eq><apply id="S3.p7.1.m1.1.2.2.cmml" xref="S3.p7.1.m1.1.2.2"><csymbol cd="ambiguous" id="S3.p7.1.m1.1.2.2.1.cmml" xref="S3.p7.1.m1.1.2.2">subscript</csymbol><ci id="S3.p7.1.m1.1.2.2.2.cmml" xref="S3.p7.1.m1.1.2.2.2">𝑆</ci><ci id="S3.p7.1.m1.1.2.2.3.cmml" xref="S3.p7.1.m1.1.2.2.3">𝑡</ci></apply><apply id="S3.p7.1.m1.1.2.4.cmml" xref="S3.p7.1.m1.1.2.4"><times id="S3.p7.1.m1.1.2.4.1.cmml" xref="S3.p7.1.m1.1.2.4.1"></times><ci id="S3.p7.1.m1.1.2.4.2.cmml" xref="S3.p7.1.m1.1.2.4.2">𝐾</ci><ci id="S3.p7.1.m1.1.2.4.3.cmml" xref="S3.p7.1.m1.1.2.4.3">𝐶</ci></apply></apply><apply id="S3.p7.1.m1.1.2c.cmml" xref="S3.p7.1.m1.1.2"><leq id="S3.p7.1.m1.1.2.5.cmml" xref="S3.p7.1.m1.1.2.5"></leq><share href="#S3.p7.1.m1.1.2.4.cmml" id="S3.p7.1.m1.1.2d.cmml" xref="S3.p7.1.m1.1.2"></share><apply id="S3.p7.1.m1.1.2.6.1.cmml" xref="S3.p7.1.m1.1.2.6.2"><ceiling id="S3.p7.1.m1.1.2.6.1.1.cmml" xref="S3.p7.1.m1.1.2.6.2.1"></ceiling><ci id="S3.p7.1.m1.1.1.cmml" xref="S3.p7.1.m1.1.1">𝐺</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p7.1.m1.1c">S_{t}=K\times C\leq\lceil G\rceil</annotation></semantics></math> from block <math id="S3.p7.2.m2.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S3.p7.2.m2.1a"><mi id="S3.p7.2.m2.1.1" xref="S3.p7.2.m2.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S3.p7.2.m2.1b"><ci id="S3.p7.2.m2.1.1.cmml" xref="S3.p7.2.m2.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p7.2.m2.1c">A</annotation></semantics></math> (<math id="S3.p7.3.m3.1" class="ltx_Math" alttext="A\longrightarrow B\rightarrow A\longrightarrow\dotsb" display="inline"><semantics id="S3.p7.3.m3.1a"><mrow id="S3.p7.3.m3.1.1" xref="S3.p7.3.m3.1.1.cmml"><mi id="S3.p7.3.m3.1.1.2" xref="S3.p7.3.m3.1.1.2.cmml">A</mi><mo stretchy="false" id="S3.p7.3.m3.1.1.3" xref="S3.p7.3.m3.1.1.3.cmml">⟶</mo><mi id="S3.p7.3.m3.1.1.4" xref="S3.p7.3.m3.1.1.4.cmml">B</mi><mo stretchy="false" id="S3.p7.3.m3.1.1.5" xref="S3.p7.3.m3.1.1.5.cmml">→</mo><mi id="S3.p7.3.m3.1.1.6" xref="S3.p7.3.m3.1.1.6.cmml">A</mi><mo stretchy="false" id="S3.p7.3.m3.1.1.7" xref="S3.p7.3.m3.1.1.7.cmml">⟶</mo><mi mathvariant="normal" id="S3.p7.3.m3.1.1.8" xref="S3.p7.3.m3.1.1.8.cmml">⋯</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.p7.3.m3.1b"><apply id="S3.p7.3.m3.1.1.cmml" xref="S3.p7.3.m3.1.1"><and id="S3.p7.3.m3.1.1a.cmml" xref="S3.p7.3.m3.1.1"></and><apply id="S3.p7.3.m3.1.1b.cmml" xref="S3.p7.3.m3.1.1"><ci id="S3.p7.3.m3.1.1.3.cmml" xref="S3.p7.3.m3.1.1.3">⟶</ci><ci id="S3.p7.3.m3.1.1.2.cmml" xref="S3.p7.3.m3.1.1.2">𝐴</ci><ci id="S3.p7.3.m3.1.1.4.cmml" xref="S3.p7.3.m3.1.1.4">𝐵</ci></apply><apply id="S3.p7.3.m3.1.1c.cmml" xref="S3.p7.3.m3.1.1"><ci id="S3.p7.3.m3.1.1.5.cmml" xref="S3.p7.3.m3.1.1.5">→</ci><share href="#S3.p7.3.m3.1.1.4.cmml" id="S3.p7.3.m3.1.1d.cmml" xref="S3.p7.3.m3.1.1"></share><ci id="S3.p7.3.m3.1.1.6.cmml" xref="S3.p7.3.m3.1.1.6">𝐴</ci></apply><apply id="S3.p7.3.m3.1.1e.cmml" xref="S3.p7.3.m3.1.1"><ci id="S3.p7.3.m3.1.1.7.cmml" xref="S3.p7.3.m3.1.1.7">⟶</ci><share href="#S3.p7.3.m3.1.1.6.cmml" id="S3.p7.3.m3.1.1f.cmml" xref="S3.p7.3.m3.1.1"></share><ci id="S3.p7.3.m3.1.1.8.cmml" xref="S3.p7.3.m3.1.1.8">⋯</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p7.3.m3.1c">A\longrightarrow B\rightarrow A\longrightarrow\dotsb</annotation></semantics></math> in consecutive rounds), where <math id="S3.p7.4.m4.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.p7.4.m4.1a"><mi id="S3.p7.4.m4.1.1" xref="S3.p7.4.m4.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.p7.4.m4.1b"><ci id="S3.p7.4.m4.1.1.cmml" xref="S3.p7.4.m4.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p7.4.m4.1c">K</annotation></semantics></math> denotes the number of clients, <math id="S3.p7.5.m5.2" class="ltx_Math" alttext="C\in[0,1]" display="inline"><semantics id="S3.p7.5.m5.2a"><mrow id="S3.p7.5.m5.2.3" xref="S3.p7.5.m5.2.3.cmml"><mi id="S3.p7.5.m5.2.3.2" xref="S3.p7.5.m5.2.3.2.cmml">C</mi><mo id="S3.p7.5.m5.2.3.1" xref="S3.p7.5.m5.2.3.1.cmml">∈</mo><mrow id="S3.p7.5.m5.2.3.3.2" xref="S3.p7.5.m5.2.3.3.1.cmml"><mo stretchy="false" id="S3.p7.5.m5.2.3.3.2.1" xref="S3.p7.5.m5.2.3.3.1.cmml">[</mo><mn id="S3.p7.5.m5.1.1" xref="S3.p7.5.m5.1.1.cmml">0</mn><mo id="S3.p7.5.m5.2.3.3.2.2" xref="S3.p7.5.m5.2.3.3.1.cmml">,</mo><mn id="S3.p7.5.m5.2.2" xref="S3.p7.5.m5.2.2.cmml">1</mn><mo stretchy="false" id="S3.p7.5.m5.2.3.3.2.3" xref="S3.p7.5.m5.2.3.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p7.5.m5.2b"><apply id="S3.p7.5.m5.2.3.cmml" xref="S3.p7.5.m5.2.3"><in id="S3.p7.5.m5.2.3.1.cmml" xref="S3.p7.5.m5.2.3.1"></in><ci id="S3.p7.5.m5.2.3.2.cmml" xref="S3.p7.5.m5.2.3.2">𝐶</ci><interval closure="closed" id="S3.p7.5.m5.2.3.3.1.cmml" xref="S3.p7.5.m5.2.3.3.2"><cn type="integer" id="S3.p7.5.m5.1.1.cmml" xref="S3.p7.5.m5.1.1">0</cn><cn type="integer" id="S3.p7.5.m5.2.2.cmml" xref="S3.p7.5.m5.2.2">1</cn></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p7.5.m5.2c">C\in[0,1]</annotation></semantics></math> denotes the reporting fraction, and <math id="S3.p7.6.m6.1" class="ltx_Math" alttext="\lceil G\rceil" display="inline"><semantics id="S3.p7.6.m6.1a"><mrow id="S3.p7.6.m6.1.2.2" xref="S3.p7.6.m6.1.2.1.cmml"><mo stretchy="false" id="S3.p7.6.m6.1.2.2.1" xref="S3.p7.6.m6.1.2.1.1.cmml">⌈</mo><mi id="S3.p7.6.m6.1.1" xref="S3.p7.6.m6.1.1.cmml">G</mi><mo stretchy="false" id="S3.p7.6.m6.1.2.2.2" xref="S3.p7.6.m6.1.2.1.1.cmml">⌉</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.p7.6.m6.1b"><apply id="S3.p7.6.m6.1.2.1.cmml" xref="S3.p7.6.m6.1.2.2"><ceiling id="S3.p7.6.m6.1.2.1.1.cmml" xref="S3.p7.6.m6.1.2.2.1"></ceiling><ci id="S3.p7.6.m6.1.1.cmml" xref="S3.p7.6.m6.1.1">𝐺</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p7.6.m6.1c">\lceil G\rceil</annotation></semantics></math> denotes the block size. Using <math id="S3.p7.7.m7.1" class="ltx_Math" alttext="\lceil G\rceil" display="inline"><semantics id="S3.p7.7.m7.1a"><mrow id="S3.p7.7.m7.1.2.2" xref="S3.p7.7.m7.1.2.1.cmml"><mo stretchy="false" id="S3.p7.7.m7.1.2.2.1" xref="S3.p7.7.m7.1.2.1.1.cmml">⌈</mo><mi id="S3.p7.7.m7.1.1" xref="S3.p7.7.m7.1.1.cmml">G</mi><mo stretchy="false" id="S3.p7.7.m7.1.2.2.2" xref="S3.p7.7.m7.1.2.1.1.cmml">⌉</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.p7.7.m7.1b"><apply id="S3.p7.7.m7.1.2.1.cmml" xref="S3.p7.7.m7.1.2.2"><ceiling id="S3.p7.7.m7.1.2.1.1.cmml" xref="S3.p7.7.m7.1.2.2.1"></ceiling><ci id="S3.p7.7.m7.1.1.cmml" xref="S3.p7.7.m7.1.1">𝐺</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p7.7.m7.1c">\lceil G\rceil</annotation></semantics></math> limits the number of clients selected for training to the the number of clients per block</p>
</div>
<div id="S3.p8" class="ltx_para">
<p id="S3.p8.10" class="ltx_p">For the <span id="S3.p8.10.1" class="ltx_text ltx_font_typewriter">FedAvg</span> algorithm, we use the same notations as McMahan <em id="S3.p8.10.2" class="ltx_emph ltx_font_italic">et al</em>.<span id="S3.p8.10.3" class="ltx_text"></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>. We simulate all experiments with a fixed setup regarding the batch size <math id="S3.p8.1.m1.1" class="ltx_Math" alttext="B=64" display="inline"><semantics id="S3.p8.1.m1.1a"><mrow id="S3.p8.1.m1.1.1" xref="S3.p8.1.m1.1.1.cmml"><mi id="S3.p8.1.m1.1.1.2" xref="S3.p8.1.m1.1.1.2.cmml">B</mi><mo id="S3.p8.1.m1.1.1.1" xref="S3.p8.1.m1.1.1.1.cmml">=</mo><mn id="S3.p8.1.m1.1.1.3" xref="S3.p8.1.m1.1.1.3.cmml">64</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.p8.1.m1.1b"><apply id="S3.p8.1.m1.1.1.cmml" xref="S3.p8.1.m1.1.1"><eq id="S3.p8.1.m1.1.1.1.cmml" xref="S3.p8.1.m1.1.1.1"></eq><ci id="S3.p8.1.m1.1.1.2.cmml" xref="S3.p8.1.m1.1.1.2">𝐵</ci><cn type="integer" id="S3.p8.1.m1.1.1.3.cmml" xref="S3.p8.1.m1.1.1.3">64</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p8.1.m1.1c">B=64</annotation></semantics></math>, local epoch <math id="S3.p8.2.m2.1" class="ltx_Math" alttext="E=3" display="inline"><semantics id="S3.p8.2.m2.1a"><mrow id="S3.p8.2.m2.1.1" xref="S3.p8.2.m2.1.1.cmml"><mi id="S3.p8.2.m2.1.1.2" xref="S3.p8.2.m2.1.1.2.cmml">E</mi><mo id="S3.p8.2.m2.1.1.1" xref="S3.p8.2.m2.1.1.1.cmml">=</mo><mn id="S3.p8.2.m2.1.1.3" xref="S3.p8.2.m2.1.1.3.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.p8.2.m2.1b"><apply id="S3.p8.2.m2.1.1.cmml" xref="S3.p8.2.m2.1.1"><eq id="S3.p8.2.m2.1.1.1.cmml" xref="S3.p8.2.m2.1.1.1"></eq><ci id="S3.p8.2.m2.1.1.2.cmml" xref="S3.p8.2.m2.1.1.2">𝐸</ci><cn type="integer" id="S3.p8.2.m2.1.1.3.cmml" xref="S3.p8.2.m2.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p8.2.m2.1c">E=3</annotation></semantics></math>, and number of clients <math id="S3.p8.3.m3.1" class="ltx_Math" alttext="K=100" display="inline"><semantics id="S3.p8.3.m3.1a"><mrow id="S3.p8.3.m3.1.1" xref="S3.p8.3.m3.1.1.cmml"><mi id="S3.p8.3.m3.1.1.2" xref="S3.p8.3.m3.1.1.2.cmml">K</mi><mo id="S3.p8.3.m3.1.1.1" xref="S3.p8.3.m3.1.1.1.cmml">=</mo><mn id="S3.p8.3.m3.1.1.3" xref="S3.p8.3.m3.1.1.3.cmml">100</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.p8.3.m3.1b"><apply id="S3.p8.3.m3.1.1.cmml" xref="S3.p8.3.m3.1.1"><eq id="S3.p8.3.m3.1.1.1.cmml" xref="S3.p8.3.m3.1.1.1"></eq><ci id="S3.p8.3.m3.1.1.2.cmml" xref="S3.p8.3.m3.1.1.2">𝐾</ci><cn type="integer" id="S3.p8.3.m3.1.1.3.cmml" xref="S3.p8.3.m3.1.1.3">100</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p8.3.m3.1c">K=100</annotation></semantics></math> indexed by <math id="S3.p8.4.m4.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.p8.4.m4.1a"><mi id="S3.p8.4.m4.1.1" xref="S3.p8.4.m4.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.p8.4.m4.1b"><ci id="S3.p8.4.m4.1.1.cmml" xref="S3.p8.4.m4.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p8.4.m4.1c">k</annotation></semantics></math>. We consider full and partial participation by allowing a variable fraction <math id="S3.p8.5.m5.4" class="ltx_Math" alttext="C\in\{0.05,0.10,0.20,1.00\}" display="inline"><semantics id="S3.p8.5.m5.4a"><mrow id="S3.p8.5.m5.4.5" xref="S3.p8.5.m5.4.5.cmml"><mi id="S3.p8.5.m5.4.5.2" xref="S3.p8.5.m5.4.5.2.cmml">C</mi><mo id="S3.p8.5.m5.4.5.1" xref="S3.p8.5.m5.4.5.1.cmml">∈</mo><mrow id="S3.p8.5.m5.4.5.3.2" xref="S3.p8.5.m5.4.5.3.1.cmml"><mo stretchy="false" id="S3.p8.5.m5.4.5.3.2.1" xref="S3.p8.5.m5.4.5.3.1.cmml">{</mo><mn id="S3.p8.5.m5.1.1" xref="S3.p8.5.m5.1.1.cmml">0.05</mn><mo id="S3.p8.5.m5.4.5.3.2.2" xref="S3.p8.5.m5.4.5.3.1.cmml">,</mo><mn id="S3.p8.5.m5.2.2" xref="S3.p8.5.m5.2.2.cmml">0.10</mn><mo id="S3.p8.5.m5.4.5.3.2.3" xref="S3.p8.5.m5.4.5.3.1.cmml">,</mo><mn id="S3.p8.5.m5.3.3" xref="S3.p8.5.m5.3.3.cmml">0.20</mn><mo id="S3.p8.5.m5.4.5.3.2.4" xref="S3.p8.5.m5.4.5.3.1.cmml">,</mo><mn id="S3.p8.5.m5.4.4" xref="S3.p8.5.m5.4.4.cmml">1.00</mn><mo stretchy="false" id="S3.p8.5.m5.4.5.3.2.5" xref="S3.p8.5.m5.4.5.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p8.5.m5.4b"><apply id="S3.p8.5.m5.4.5.cmml" xref="S3.p8.5.m5.4.5"><in id="S3.p8.5.m5.4.5.1.cmml" xref="S3.p8.5.m5.4.5.1"></in><ci id="S3.p8.5.m5.4.5.2.cmml" xref="S3.p8.5.m5.4.5.2">𝐶</ci><set id="S3.p8.5.m5.4.5.3.1.cmml" xref="S3.p8.5.m5.4.5.3.2"><cn type="float" id="S3.p8.5.m5.1.1.cmml" xref="S3.p8.5.m5.1.1">0.05</cn><cn type="float" id="S3.p8.5.m5.2.2.cmml" xref="S3.p8.5.m5.2.2">0.10</cn><cn type="float" id="S3.p8.5.m5.3.3.cmml" xref="S3.p8.5.m5.3.3">0.20</cn><cn type="float" id="S3.p8.5.m5.4.4.cmml" xref="S3.p8.5.m5.4.4">1.00</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p8.5.m5.4c">C\in\{0.05,0.10,0.20,1.00\}</annotation></semantics></math> (corresponding to <math id="S3.p8.6.m6.4" class="ltx_Math" alttext="\{5,10,20,100\}" display="inline"><semantics id="S3.p8.6.m6.4a"><mrow id="S3.p8.6.m6.4.5.2" xref="S3.p8.6.m6.4.5.1.cmml"><mo stretchy="false" id="S3.p8.6.m6.4.5.2.1" xref="S3.p8.6.m6.4.5.1.cmml">{</mo><mn id="S3.p8.6.m6.1.1" xref="S3.p8.6.m6.1.1.cmml">5</mn><mo id="S3.p8.6.m6.4.5.2.2" xref="S3.p8.6.m6.4.5.1.cmml">,</mo><mn id="S3.p8.6.m6.2.2" xref="S3.p8.6.m6.2.2.cmml">10</mn><mo id="S3.p8.6.m6.4.5.2.3" xref="S3.p8.6.m6.4.5.1.cmml">,</mo><mn id="S3.p8.6.m6.3.3" xref="S3.p8.6.m6.3.3.cmml">20</mn><mo id="S3.p8.6.m6.4.5.2.4" xref="S3.p8.6.m6.4.5.1.cmml">,</mo><mn id="S3.p8.6.m6.4.4" xref="S3.p8.6.m6.4.4.cmml">100</mn><mo stretchy="false" id="S3.p8.6.m6.4.5.2.5" xref="S3.p8.6.m6.4.5.1.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.p8.6.m6.4b"><set id="S3.p8.6.m6.4.5.1.cmml" xref="S3.p8.6.m6.4.5.2"><cn type="integer" id="S3.p8.6.m6.1.1.cmml" xref="S3.p8.6.m6.1.1">5</cn><cn type="integer" id="S3.p8.6.m6.2.2.cmml" xref="S3.p8.6.m6.2.2">10</cn><cn type="integer" id="S3.p8.6.m6.3.3.cmml" xref="S3.p8.6.m6.3.3">20</cn><cn type="integer" id="S3.p8.6.m6.4.4.cmml" xref="S3.p8.6.m6.4.4">100</cn></set></annotation-xml><annotation encoding="application/x-tex" id="S3.p8.6.m6.4c">\{5,10,20,100\}</annotation></semantics></math> clients participating in every communication round, respectively). To be consistent with <span id="S3.p8.10.4" class="ltx_text ltx_font_typewriter">FedAvg</span>, the fraction is based on the total number of clients. In case the reporting fraction <math id="S3.p8.7.m7.1" class="ltx_Math" alttext="K\times C" display="inline"><semantics id="S3.p8.7.m7.1a"><mrow id="S3.p8.7.m7.1.1" xref="S3.p8.7.m7.1.1.cmml"><mi id="S3.p8.7.m7.1.1.2" xref="S3.p8.7.m7.1.1.2.cmml">K</mi><mo lspace="0.222em" rspace="0.222em" id="S3.p8.7.m7.1.1.1" xref="S3.p8.7.m7.1.1.1.cmml">×</mo><mi id="S3.p8.7.m7.1.1.3" xref="S3.p8.7.m7.1.1.3.cmml">C</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.p8.7.m7.1b"><apply id="S3.p8.7.m7.1.1.cmml" xref="S3.p8.7.m7.1.1"><times id="S3.p8.7.m7.1.1.1.cmml" xref="S3.p8.7.m7.1.1.1"></times><ci id="S3.p8.7.m7.1.1.2.cmml" xref="S3.p8.7.m7.1.1.2">𝐾</ci><ci id="S3.p8.7.m7.1.1.3.cmml" xref="S3.p8.7.m7.1.1.3">𝐶</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p8.7.m7.1c">K\times C</annotation></semantics></math> exceeds the number of clients artificially assigned to a block, all clients from this block are chosen to participate. Thus, full participation translates into reporting fraction of <math id="S3.p8.8.m8.1" class="ltx_Math" alttext="\frac{K}{G}" display="inline"><semantics id="S3.p8.8.m8.1a"><mfrac id="S3.p8.8.m8.1.1" xref="S3.p8.8.m8.1.1.cmml"><mi id="S3.p8.8.m8.1.1.2" xref="S3.p8.8.m8.1.1.2.cmml">K</mi><mi id="S3.p8.8.m8.1.1.3" xref="S3.p8.8.m8.1.1.3.cmml">G</mi></mfrac><annotation-xml encoding="MathML-Content" id="S3.p8.8.m8.1b"><apply id="S3.p8.8.m8.1.1.cmml" xref="S3.p8.8.m8.1.1"><divide id="S3.p8.8.m8.1.1.1.cmml" xref="S3.p8.8.m8.1.1"></divide><ci id="S3.p8.8.m8.1.1.2.cmml" xref="S3.p8.8.m8.1.1.2">𝐾</ci><ci id="S3.p8.8.m8.1.1.3.cmml" xref="S3.p8.8.m8.1.1.3">𝐺</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p8.8.m8.1c">\frac{K}{G}</annotation></semantics></math> for all block-cyclic settings. <span id="S3.p8.10.5" class="ltx_text ltx_font_typewriter">FedAvg</span> is run for a fixed optimization budget of <math id="S3.p8.9.m9.1" class="ltx_Math" alttext="T=100" display="inline"><semantics id="S3.p8.9.m9.1a"><mrow id="S3.p8.9.m9.1.1" xref="S3.p8.9.m9.1.1.cmml"><mi id="S3.p8.9.m9.1.1.2" xref="S3.p8.9.m9.1.1.2.cmml">T</mi><mo id="S3.p8.9.m9.1.1.1" xref="S3.p8.9.m9.1.1.1.cmml">=</mo><mn id="S3.p8.9.m9.1.1.3" xref="S3.p8.9.m9.1.1.3.cmml">100</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.p8.9.m9.1b"><apply id="S3.p8.9.m9.1.1.cmml" xref="S3.p8.9.m9.1.1"><eq id="S3.p8.9.m9.1.1.1.cmml" xref="S3.p8.9.m9.1.1.1"></eq><ci id="S3.p8.9.m9.1.1.2.cmml" xref="S3.p8.9.m9.1.1.2">𝑇</ci><cn type="integer" id="S3.p8.9.m9.1.1.3.cmml" xref="S3.p8.9.m9.1.1.3">100</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p8.9.m9.1c">T=100</annotation></semantics></math> communication rounds. No early stopping <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> is applied. To obtain a statistically sufficient sample size that diminishes random variances, we substantiated our experiments by <math id="S3.p8.10.m10.1" class="ltx_Math" alttext="n=3" display="inline"><semantics id="S3.p8.10.m10.1a"><mrow id="S3.p8.10.m10.1.1" xref="S3.p8.10.m10.1.1.cmml"><mi id="S3.p8.10.m10.1.1.2" xref="S3.p8.10.m10.1.1.2.cmml">n</mi><mo id="S3.p8.10.m10.1.1.1" xref="S3.p8.10.m10.1.1.1.cmml">=</mo><mn id="S3.p8.10.m10.1.1.3" xref="S3.p8.10.m10.1.1.3.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.p8.10.m10.1b"><apply id="S3.p8.10.m10.1.1.cmml" xref="S3.p8.10.m10.1.1"><eq id="S3.p8.10.m10.1.1.1.cmml" xref="S3.p8.10.m10.1.1.1"></eq><ci id="S3.p8.10.m10.1.1.2.cmml" xref="S3.p8.10.m10.1.1.2">𝑛</ci><cn type="integer" id="S3.p8.10.m10.1.1.3.cmml" xref="S3.p8.10.m10.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p8.10.m10.1c">n=3</annotation></semantics></math> independent replications.</p>
</div>
<div id="S3.p9" class="ltx_para">
<p id="S3.p9.9" class="ltx_p">For our experiments, we exploit a simple convolutional neural network (CNN) architecture. The CNN model propagates data through two convolutional layers with filter size 3×3 and two dense layers. The first convolutional layer has <math id="S3.p9.1.m1.1" class="ltx_Math" alttext="32" display="inline"><semantics id="S3.p9.1.m1.1a"><mn id="S3.p9.1.m1.1.1" xref="S3.p9.1.m1.1.1.cmml">32</mn><annotation-xml encoding="MathML-Content" id="S3.p9.1.m1.1b"><cn type="integer" id="S3.p9.1.m1.1.1.cmml" xref="S3.p9.1.m1.1.1">32</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.p9.1.m1.1c">32</annotation></semantics></math> channels, followed by maximum pooling with filter size <math id="S3.p9.2.m2.1" class="ltx_Math" alttext="2\times 2" display="inline"><semantics id="S3.p9.2.m2.1a"><mrow id="S3.p9.2.m2.1.1" xref="S3.p9.2.m2.1.1.cmml"><mn id="S3.p9.2.m2.1.1.2" xref="S3.p9.2.m2.1.1.2.cmml">2</mn><mo lspace="0.222em" rspace="0.222em" id="S3.p9.2.m2.1.1.1" xref="S3.p9.2.m2.1.1.1.cmml">×</mo><mn id="S3.p9.2.m2.1.1.3" xref="S3.p9.2.m2.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.p9.2.m2.1b"><apply id="S3.p9.2.m2.1.1.cmml" xref="S3.p9.2.m2.1.1"><times id="S3.p9.2.m2.1.1.1.cmml" xref="S3.p9.2.m2.1.1.1"></times><cn type="integer" id="S3.p9.2.m2.1.1.2.cmml" xref="S3.p9.2.m2.1.1.2">2</cn><cn type="integer" id="S3.p9.2.m2.1.1.3.cmml" xref="S3.p9.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p9.2.m2.1c">2\times 2</annotation></semantics></math> and dropout with probability <math id="S3.p9.3.m3.1" class="ltx_Math" alttext="p=0.5" display="inline"><semantics id="S3.p9.3.m3.1a"><mrow id="S3.p9.3.m3.1.1" xref="S3.p9.3.m3.1.1.cmml"><mi id="S3.p9.3.m3.1.1.2" xref="S3.p9.3.m3.1.1.2.cmml">p</mi><mo id="S3.p9.3.m3.1.1.1" xref="S3.p9.3.m3.1.1.1.cmml">=</mo><mn id="S3.p9.3.m3.1.1.3" xref="S3.p9.3.m3.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.p9.3.m3.1b"><apply id="S3.p9.3.m3.1.1.cmml" xref="S3.p9.3.m3.1.1"><eq id="S3.p9.3.m3.1.1.1.cmml" xref="S3.p9.3.m3.1.1.1"></eq><ci id="S3.p9.3.m3.1.1.2.cmml" xref="S3.p9.3.m3.1.1.2">𝑝</ci><cn type="float" id="S3.p9.3.m3.1.1.3.cmml" xref="S3.p9.3.m3.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p9.3.m3.1c">p=0.5</annotation></semantics></math>. The second convolutional layer has <math id="S3.p9.4.m4.1" class="ltx_Math" alttext="64" display="inline"><semantics id="S3.p9.4.m4.1a"><mn id="S3.p9.4.m4.1.1" xref="S3.p9.4.m4.1.1.cmml">64</mn><annotation-xml encoding="MathML-Content" id="S3.p9.4.m4.1b"><cn type="integer" id="S3.p9.4.m4.1.1.cmml" xref="S3.p9.4.m4.1.1">64</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.p9.4.m4.1c">64</annotation></semantics></math> channels. Dropout is applied with <math id="S3.p9.5.m5.1" class="ltx_Math" alttext="p=0.25" display="inline"><semantics id="S3.p9.5.m5.1a"><mrow id="S3.p9.5.m5.1.1" xref="S3.p9.5.m5.1.1.cmml"><mi id="S3.p9.5.m5.1.1.2" xref="S3.p9.5.m5.1.1.2.cmml">p</mi><mo id="S3.p9.5.m5.1.1.1" xref="S3.p9.5.m5.1.1.1.cmml">=</mo><mn id="S3.p9.5.m5.1.1.3" xref="S3.p9.5.m5.1.1.3.cmml">0.25</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.p9.5.m5.1b"><apply id="S3.p9.5.m5.1.1.cmml" xref="S3.p9.5.m5.1.1"><eq id="S3.p9.5.m5.1.1.1.cmml" xref="S3.p9.5.m5.1.1.1"></eq><ci id="S3.p9.5.m5.1.1.2.cmml" xref="S3.p9.5.m5.1.1.2">𝑝</ci><cn type="float" id="S3.p9.5.m5.1.1.3.cmml" xref="S3.p9.5.m5.1.1.3">0.25</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p9.5.m5.1c">p=0.25</annotation></semantics></math>. The dense layers contain <math id="S3.p9.6.m6.1" class="ltx_Math" alttext="128" display="inline"><semantics id="S3.p9.6.m6.1a"><mn id="S3.p9.6.m6.1.1" xref="S3.p9.6.m6.1.1.cmml">128</mn><annotation-xml encoding="MathML-Content" id="S3.p9.6.m6.1b"><cn type="integer" id="S3.p9.6.m6.1.1.cmml" xref="S3.p9.6.m6.1.1">128</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.p9.6.m6.1c">128</annotation></semantics></math> units. Except for the output layer, which uses a softmax to yield a probability distribution, all layers use rectified linear unit activation. In total the CNN model consists of <math id="S3.p9.7.m7.3" class="ltx_Math" alttext="1,199,882" display="inline"><semantics id="S3.p9.7.m7.3a"><mrow id="S3.p9.7.m7.3.4.2" xref="S3.p9.7.m7.3.4.1.cmml"><mn id="S3.p9.7.m7.1.1" xref="S3.p9.7.m7.1.1.cmml">1</mn><mo id="S3.p9.7.m7.3.4.2.1" xref="S3.p9.7.m7.3.4.1.cmml">,</mo><mn id="S3.p9.7.m7.2.2" xref="S3.p9.7.m7.2.2.cmml">199</mn><mo id="S3.p9.7.m7.3.4.2.2" xref="S3.p9.7.m7.3.4.1.cmml">,</mo><mn id="S3.p9.7.m7.3.3" xref="S3.p9.7.m7.3.3.cmml">882</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.p9.7.m7.3b"><list id="S3.p9.7.m7.3.4.1.cmml" xref="S3.p9.7.m7.3.4.2"><cn type="integer" id="S3.p9.7.m7.1.1.cmml" xref="S3.p9.7.m7.1.1">1</cn><cn type="integer" id="S3.p9.7.m7.2.2.cmml" xref="S3.p9.7.m7.2.2">199</cn><cn type="integer" id="S3.p9.7.m7.3.3.cmml" xref="S3.p9.7.m7.3.3">882</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.p9.7.m7.3c">1,199,882</annotation></semantics></math> trainable parameters. While this model is not state-of-the-art, it is sufficient to show relative performance for the purposes of our investigation. Note that the model is the same for each client. The model is initialized and transmitted to all clients. To optimize the model, we apply SGD with a fixed learning rate of <math id="S3.p9.8.m8.1" class="ltx_Math" alttext="\eta=0.01" display="inline"><semantics id="S3.p9.8.m8.1a"><mrow id="S3.p9.8.m8.1.1" xref="S3.p9.8.m8.1.1.cmml"><mi id="S3.p9.8.m8.1.1.2" xref="S3.p9.8.m8.1.1.2.cmml">η</mi><mo id="S3.p9.8.m8.1.1.1" xref="S3.p9.8.m8.1.1.1.cmml">=</mo><mn id="S3.p9.8.m8.1.1.3" xref="S3.p9.8.m8.1.1.3.cmml">0.01</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.p9.8.m8.1b"><apply id="S3.p9.8.m8.1.1.cmml" xref="S3.p9.8.m8.1.1"><eq id="S3.p9.8.m8.1.1.1.cmml" xref="S3.p9.8.m8.1.1.1"></eq><ci id="S3.p9.8.m8.1.1.2.cmml" xref="S3.p9.8.m8.1.1.2">𝜂</ci><cn type="float" id="S3.p9.8.m8.1.1.3.cmml" xref="S3.p9.8.m8.1.1.3">0.01</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p9.8.m8.1c">\eta=0.01</annotation></semantics></math> and momentum of <math id="S3.p9.9.m9.1" class="ltx_Math" alttext="\beta=0.50" display="inline"><semantics id="S3.p9.9.m9.1a"><mrow id="S3.p9.9.m9.1.1" xref="S3.p9.9.m9.1.1.cmml"><mi id="S3.p9.9.m9.1.1.2" xref="S3.p9.9.m9.1.1.2.cmml">β</mi><mo id="S3.p9.9.m9.1.1.1" xref="S3.p9.9.m9.1.1.1.cmml">=</mo><mn id="S3.p9.9.m9.1.1.3" xref="S3.p9.9.m9.1.1.3.cmml">0.50</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.p9.9.m9.1b"><apply id="S3.p9.9.m9.1.1.cmml" xref="S3.p9.9.m9.1.1"><eq id="S3.p9.9.m9.1.1.1.cmml" xref="S3.p9.9.m9.1.1.1"></eq><ci id="S3.p9.9.m9.1.1.2.cmml" xref="S3.p9.9.m9.1.1.2">𝛽</ci><cn type="float" id="S3.p9.9.m9.1.1.3.cmml" xref="S3.p9.9.m9.1.1.3">0.50</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p9.9.m9.1c">\beta=0.50</annotation></semantics></math> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>. We take the search for an optimal learning rate in the sensitivity analysis. For simplicity, we did not apply weight decay or any learning rate decay schedule.</p>
</div>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.5" class="ltx_p">For comparison, we consider a performance upper bound by creating a hypothetical i.i.d. case where images are distributed uniformly across <math id="S4.p1.1.m1.1" class="ltx_Math" alttext="K=100" display="inline"><semantics id="S4.p1.1.m1.1a"><mrow id="S4.p1.1.m1.1.1" xref="S4.p1.1.m1.1.1.cmml"><mi id="S4.p1.1.m1.1.1.2" xref="S4.p1.1.m1.1.1.2.cmml">K</mi><mo id="S4.p1.1.m1.1.1.1" xref="S4.p1.1.m1.1.1.1.cmml">=</mo><mn id="S4.p1.1.m1.1.1.3" xref="S4.p1.1.m1.1.1.3.cmml">100</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.p1.1.m1.1b"><apply id="S4.p1.1.m1.1.1.cmml" xref="S4.p1.1.m1.1.1"><eq id="S4.p1.1.m1.1.1.1.cmml" xref="S4.p1.1.m1.1.1.1"></eq><ci id="S4.p1.1.m1.1.1.2.cmml" xref="S4.p1.1.m1.1.1.2">𝐾</ci><cn type="integer" id="S4.p1.1.m1.1.1.3.cmml" xref="S4.p1.1.m1.1.1.3">100</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.1.m1.1c">K=100</annotation></semantics></math> clients, and training is performed each round <math id="S4.p1.2.m2.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S4.p1.2.m2.1a"><mi id="S4.p1.2.m2.1.1" xref="S4.p1.2.m2.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S4.p1.2.m2.1b"><ci id="S4.p1.2.m2.1.1.cmml" xref="S4.p1.2.m2.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.2.m2.1c">t</annotation></semantics></math> by a subset of <math id="S4.p1.3.m3.1" class="ltx_Math" alttext="|S_{t}|=20" display="inline"><semantics id="S4.p1.3.m3.1a"><mrow id="S4.p1.3.m3.1.1" xref="S4.p1.3.m3.1.1.cmml"><mrow id="S4.p1.3.m3.1.1.1.1" xref="S4.p1.3.m3.1.1.1.2.cmml"><mo stretchy="false" id="S4.p1.3.m3.1.1.1.1.2" xref="S4.p1.3.m3.1.1.1.2.1.cmml">|</mo><msub id="S4.p1.3.m3.1.1.1.1.1" xref="S4.p1.3.m3.1.1.1.1.1.cmml"><mi id="S4.p1.3.m3.1.1.1.1.1.2" xref="S4.p1.3.m3.1.1.1.1.1.2.cmml">S</mi><mi id="S4.p1.3.m3.1.1.1.1.1.3" xref="S4.p1.3.m3.1.1.1.1.1.3.cmml">t</mi></msub><mo stretchy="false" id="S4.p1.3.m3.1.1.1.1.3" xref="S4.p1.3.m3.1.1.1.2.1.cmml">|</mo></mrow><mo id="S4.p1.3.m3.1.1.2" xref="S4.p1.3.m3.1.1.2.cmml">=</mo><mn id="S4.p1.3.m3.1.1.3" xref="S4.p1.3.m3.1.1.3.cmml">20</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.p1.3.m3.1b"><apply id="S4.p1.3.m3.1.1.cmml" xref="S4.p1.3.m3.1.1"><eq id="S4.p1.3.m3.1.1.2.cmml" xref="S4.p1.3.m3.1.1.2"></eq><apply id="S4.p1.3.m3.1.1.1.2.cmml" xref="S4.p1.3.m3.1.1.1.1"><abs id="S4.p1.3.m3.1.1.1.2.1.cmml" xref="S4.p1.3.m3.1.1.1.1.2"></abs><apply id="S4.p1.3.m3.1.1.1.1.1.cmml" xref="S4.p1.3.m3.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.p1.3.m3.1.1.1.1.1.1.cmml" xref="S4.p1.3.m3.1.1.1.1.1">subscript</csymbol><ci id="S4.p1.3.m3.1.1.1.1.1.2.cmml" xref="S4.p1.3.m3.1.1.1.1.1.2">𝑆</ci><ci id="S4.p1.3.m3.1.1.1.1.1.3.cmml" xref="S4.p1.3.m3.1.1.1.1.1.3">𝑡</ci></apply></apply><cn type="integer" id="S4.p1.3.m3.1.1.3.cmml" xref="S4.p1.3.m3.1.1.3">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.3.m3.1c">|S_{t}|=20</annotation></semantics></math> clients drawn uniformly at random. With this setup, we measure a test accuracy of <math id="S4.p1.4.m4.1" class="ltx_Math" alttext="0.9901" display="inline"><semantics id="S4.p1.4.m4.1a"><mn id="S4.p1.4.m4.1.1" xref="S4.p1.4.m4.1.1.cmml">0.9901</mn><annotation-xml encoding="MathML-Content" id="S4.p1.4.m4.1b"><cn type="float" id="S4.p1.4.m4.1.1.cmml" xref="S4.p1.4.m4.1.1">0.9901</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.4.m4.1c">0.9901</annotation></semantics></math>. We also consider a more practical upper bound for the performance by sorting and distributing the images non-identically across clients. With the training remaining unchanged, we achieve a practical upper bound for the test accuracy of <math id="S4.p1.5.m5.1" class="ltx_Math" alttext="0.9878" display="inline"><semantics id="S4.p1.5.m5.1a"><mn id="S4.p1.5.m5.1.1" xref="S4.p1.5.m5.1.1.cmml">0.9878</mn><annotation-xml encoding="MathML-Content" id="S4.p1.5.m5.1b"><cn type="float" id="S4.p1.5.m5.1.1.cmml" xref="S4.p1.5.m5.1.1">0.9878</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.5.m5.1c">0.9878</annotation></semantics></math>. This shows that FL is capable to deal with non-identical data.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p">Given the above data preparation, we proceed to benchmark the <span id="S4.p2.1.1" class="ltx_text ltx_font_typewriter">FedAvg</span> algorithm using block-cyclic sampling. We present our results on a discrete range of blocks ordered from balanced to unbalanced.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Performance Analysis</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.9" class="ltx_p">We commence by presenting the performance impact of non-independence on non-identical data <span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Note that non-independence has no effect if data are identically distributed across all clients. This is because each client, regardless of the block, resembles a representative of the entire population.</span></span></span> given a fixed optimization budget. In Figure <a href="#S4.F2" title="Figure 2 ‣ 4.1 Performance Analysis ‣ 4 Experiments ‣ Demystifying the Effects of Non-Independence in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, we depict the classification accuracy of the consensus model as a function of the power law scaling (larger implies more unbalanced group distributions) and client fraction, each grouped by number of blocks (larger implies more dependence). Significant changes in accuracy occur between blocks. Increasing the dependency by sampling from a multi-block structure <math id="S4.SS1.p1.1.m1.1" class="ltx_Math" alttext="G\gg 2" display="inline"><semantics id="S4.SS1.p1.1.m1.1a"><mrow id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml"><mi id="S4.SS1.p1.1.m1.1.1.2" xref="S4.SS1.p1.1.m1.1.1.2.cmml">G</mi><mo id="S4.SS1.p1.1.m1.1.1.1" xref="S4.SS1.p1.1.m1.1.1.1.cmml">≫</mo><mn id="S4.SS1.p1.1.m1.1.1.3" xref="S4.SS1.p1.1.m1.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><apply id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1"><csymbol cd="latexml" id="S4.SS1.p1.1.m1.1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1.1">much-greater-than</csymbol><ci id="S4.SS1.p1.1.m1.1.1.2.cmml" xref="S4.SS1.p1.1.m1.1.1.2">𝐺</ci><cn type="integer" id="S4.SS1.p1.1.m1.1.1.3.cmml" xref="S4.SS1.p1.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">G\gg 2</annotation></semantics></math> significantly degrades the performance by up to <math id="S4.SS1.p1.2.m2.1" class="ltx_Math" alttext="0.253" display="inline"><semantics id="S4.SS1.p1.2.m2.1a"><mn id="S4.SS1.p1.2.m2.1.1" xref="S4.SS1.p1.2.m2.1.1.cmml">0.253</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.2.m2.1b"><cn type="float" id="S4.SS1.p1.2.m2.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1">0.253</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.2.m2.1c">0.253</annotation></semantics></math> percentage points, on average. For <math id="S4.SS1.p1.3.m3.1" class="ltx_Math" alttext="G=2" display="inline"><semantics id="S4.SS1.p1.3.m3.1a"><mrow id="S4.SS1.p1.3.m3.1.1" xref="S4.SS1.p1.3.m3.1.1.cmml"><mi id="S4.SS1.p1.3.m3.1.1.2" xref="S4.SS1.p1.3.m3.1.1.2.cmml">G</mi><mo id="S4.SS1.p1.3.m3.1.1.1" xref="S4.SS1.p1.3.m3.1.1.1.cmml">=</mo><mn id="S4.SS1.p1.3.m3.1.1.3" xref="S4.SS1.p1.3.m3.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.3.m3.1b"><apply id="S4.SS1.p1.3.m3.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1"><eq id="S4.SS1.p1.3.m3.1.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1.1"></eq><ci id="S4.SS1.p1.3.m3.1.1.2.cmml" xref="S4.SS1.p1.3.m3.1.1.2">𝐺</ci><cn type="integer" id="S4.SS1.p1.3.m3.1.1.3.cmml" xref="S4.SS1.p1.3.m3.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.3.m3.1c">G=2</annotation></semantics></math>, <span id="S4.SS1.p1.9.1" class="ltx_text ltx_font_typewriter">FedAvg</span> yields a test accuracy of <math id="S4.SS1.p1.4.m4.1" class="ltx_Math" alttext="0.9546" display="inline"><semantics id="S4.SS1.p1.4.m4.1a"><mn id="S4.SS1.p1.4.m4.1.1" xref="S4.SS1.p1.4.m4.1.1.cmml">0.9546</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.4.m4.1b"><cn type="float" id="S4.SS1.p1.4.m4.1.1.cmml" xref="S4.SS1.p1.4.m4.1.1">0.9546</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.4.m4.1c">0.9546</annotation></semantics></math> on average, which is slightly below the practical upper bound. For <math id="S4.SS1.p1.5.m5.1" class="ltx_Math" alttext="G=5" display="inline"><semantics id="S4.SS1.p1.5.m5.1a"><mrow id="S4.SS1.p1.5.m5.1.1" xref="S4.SS1.p1.5.m5.1.1.cmml"><mi id="S4.SS1.p1.5.m5.1.1.2" xref="S4.SS1.p1.5.m5.1.1.2.cmml">G</mi><mo id="S4.SS1.p1.5.m5.1.1.1" xref="S4.SS1.p1.5.m5.1.1.1.cmml">=</mo><mn id="S4.SS1.p1.5.m5.1.1.3" xref="S4.SS1.p1.5.m5.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.5.m5.1b"><apply id="S4.SS1.p1.5.m5.1.1.cmml" xref="S4.SS1.p1.5.m5.1.1"><eq id="S4.SS1.p1.5.m5.1.1.1.cmml" xref="S4.SS1.p1.5.m5.1.1.1"></eq><ci id="S4.SS1.p1.5.m5.1.1.2.cmml" xref="S4.SS1.p1.5.m5.1.1.2">𝐺</ci><cn type="integer" id="S4.SS1.p1.5.m5.1.1.3.cmml" xref="S4.SS1.p1.5.m5.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.5.m5.1c">G=5</annotation></semantics></math>, by contrast, <span id="S4.SS1.p1.9.2" class="ltx_text ltx_font_typewriter">FedAvg</span> achieves a test accuracy of <math id="S4.SS1.p1.6.m6.1" class="ltx_Math" alttext="0.7016" display="inline"><semantics id="S4.SS1.p1.6.m6.1a"><mn id="S4.SS1.p1.6.m6.1.1" xref="S4.SS1.p1.6.m6.1.1.cmml">0.7016</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.6.m6.1b"><cn type="float" id="S4.SS1.p1.6.m6.1.1.cmml" xref="S4.SS1.p1.6.m6.1.1">0.7016</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.6.m6.1c">0.7016</annotation></semantics></math> on average for a range from <math id="S4.SS1.p1.7.m7.1" class="ltx_Math" alttext="0.6426" display="inline"><semantics id="S4.SS1.p1.7.m7.1a"><mn id="S4.SS1.p1.7.m7.1.1" xref="S4.SS1.p1.7.m7.1.1.cmml">0.6426</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.7.m7.1b"><cn type="float" id="S4.SS1.p1.7.m7.1.1.cmml" xref="S4.SS1.p1.7.m7.1.1">0.6426</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.7.m7.1c">0.6426</annotation></semantics></math> to <math id="S4.SS1.p1.8.m8.1" class="ltx_Math" alttext="0.7865" display="inline"><semantics id="S4.SS1.p1.8.m8.1a"><mn id="S4.SS1.p1.8.m8.1.1" xref="S4.SS1.p1.8.m8.1.1.cmml">0.7865</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.8.m8.1b"><cn type="float" id="S4.SS1.p1.8.m8.1.1.cmml" xref="S4.SS1.p1.8.m8.1.1">0.7865</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.8.m8.1c">0.7865</annotation></semantics></math>. We conclude that the volatility of <span id="S4.SS1.p1.9.3" class="ltx_text ltx_font_typewriter">FedAvg</span> increases disproportionately with the number of blocks <math id="S4.SS1.p1.9.m9.1" class="ltx_Math" alttext="G" display="inline"><semantics id="S4.SS1.p1.9.m9.1a"><mi id="S4.SS1.p1.9.m9.1.1" xref="S4.SS1.p1.9.m9.1.1.cmml">G</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.9.m9.1b"><ci id="S4.SS1.p1.9.m9.1.1.cmml" xref="S4.SS1.p1.9.m9.1.1">𝐺</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.9.m9.1c">G</annotation></semantics></math> for multi-block structures.</p>
</div>
<figure id="S4.F2" class="ltx_figure"><img src="/html/2103.11226/assets/x2.png" id="S4.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="170" height="114" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span><span id="S4.F2.14.1" class="ltx_text ltx_font_typewriter">FedAvg</span> test accuracy for different degrees of non-independence and non-balancedness. Each cell is optimized with a communication budget of <math id="S4.F2.7.m1.1" class="ltx_Math" alttext="T=100" display="inline"><semantics id="S4.F2.7.m1.1b"><mrow id="S4.F2.7.m1.1.1" xref="S4.F2.7.m1.1.1.cmml"><mi id="S4.F2.7.m1.1.1.2" xref="S4.F2.7.m1.1.1.2.cmml">T</mi><mo id="S4.F2.7.m1.1.1.1" xref="S4.F2.7.m1.1.1.1.cmml">=</mo><mn id="S4.F2.7.m1.1.1.3" xref="S4.F2.7.m1.1.1.3.cmml">100</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.F2.7.m1.1c"><apply id="S4.F2.7.m1.1.1.cmml" xref="S4.F2.7.m1.1.1"><eq id="S4.F2.7.m1.1.1.1.cmml" xref="S4.F2.7.m1.1.1.1"></eq><ci id="S4.F2.7.m1.1.1.2.cmml" xref="S4.F2.7.m1.1.1.2">𝑇</ci><cn type="integer" id="S4.F2.7.m1.1.1.3.cmml" xref="S4.F2.7.m1.1.1.3">100</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F2.7.m1.1d">T=100</annotation></semantics></math> rounds synchronized every <math id="S4.F2.8.m2.1" class="ltx_Math" alttext="E=3" display="inline"><semantics id="S4.F2.8.m2.1b"><mrow id="S4.F2.8.m2.1.1" xref="S4.F2.8.m2.1.1.cmml"><mi id="S4.F2.8.m2.1.1.2" xref="S4.F2.8.m2.1.1.2.cmml">E</mi><mo id="S4.F2.8.m2.1.1.1" xref="S4.F2.8.m2.1.1.1.cmml">=</mo><mn id="S4.F2.8.m2.1.1.3" xref="S4.F2.8.m2.1.1.3.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.F2.8.m2.1c"><apply id="S4.F2.8.m2.1.1.cmml" xref="S4.F2.8.m2.1.1"><eq id="S4.F2.8.m2.1.1.1.cmml" xref="S4.F2.8.m2.1.1.1"></eq><ci id="S4.F2.8.m2.1.1.2.cmml" xref="S4.F2.8.m2.1.1.2">𝐸</ci><cn type="integer" id="S4.F2.8.m2.1.1.3.cmml" xref="S4.F2.8.m2.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F2.8.m2.1d">E=3</annotation></semantics></math> epochs. Each cell is averaged over <math id="S4.F2.9.m3.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S4.F2.9.m3.1b"><mn id="S4.F2.9.m3.1.1" xref="S4.F2.9.m3.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S4.F2.9.m3.1c"><cn type="integer" id="S4.F2.9.m3.1.1.cmml" xref="S4.F2.9.m3.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.F2.9.m3.1d">3</annotation></semantics></math> seeded runs on different populations using the same <math id="S4.F2.10.m4.1" class="ltx_Math" alttext="G" display="inline"><semantics id="S4.F2.10.m4.1b"><mi id="S4.F2.10.m4.1.1" xref="S4.F2.10.m4.1.1.cmml">G</mi><annotation-xml encoding="MathML-Content" id="S4.F2.10.m4.1c"><ci id="S4.F2.10.m4.1.1.cmml" xref="S4.F2.10.m4.1.1">𝐺</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F2.10.m4.1d">G</annotation></semantics></math>, <math id="S4.F2.11.m5.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S4.F2.11.m5.1b"><mi id="S4.F2.11.m5.1.1" xref="S4.F2.11.m5.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S4.F2.11.m5.1c"><ci id="S4.F2.11.m5.1.1.cmml" xref="S4.F2.11.m5.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F2.11.m5.1d">C</annotation></semantics></math>, and <math id="S4.F2.12.m6.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S4.F2.12.m6.1b"><mi id="S4.F2.12.m6.1.1" xref="S4.F2.12.m6.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S4.F2.12.m6.1c"><ci id="S4.F2.12.m6.1.1.cmml" xref="S4.F2.12.m6.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F2.12.m6.1d">\alpha</annotation></semantics></math>. </figcaption>
</figure>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.3" class="ltx_p">To investigate the moderating effect of the reporting fraction and ratio of imbalance within blocks, we calculate the per-block row-wise means (representing the effect of participation rates) and column-wise means (representing the effect of imbalance). While a wide range of fractions yield statistically indistinguishable test accuracies, we find that partial participation almost always leads to results than full participation. Recall that the client fraction in block-cyclic sampling is bound by <math id="S4.SS1.p2.1.m1.1" class="ltx_Math" alttext="\frac{K}{G}" display="inline"><semantics id="S4.SS1.p2.1.m1.1a"><mfrac id="S4.SS1.p2.1.m1.1.1" xref="S4.SS1.p2.1.m1.1.1.cmml"><mi id="S4.SS1.p2.1.m1.1.1.2" xref="S4.SS1.p2.1.m1.1.1.2.cmml">K</mi><mi id="S4.SS1.p2.1.m1.1.1.3" xref="S4.SS1.p2.1.m1.1.1.3.cmml">G</mi></mfrac><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.1b"><apply id="S4.SS1.p2.1.m1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1"><divide id="S4.SS1.p2.1.m1.1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1"></divide><ci id="S4.SS1.p2.1.m1.1.1.2.cmml" xref="S4.SS1.p2.1.m1.1.1.2">𝐾</ci><ci id="S4.SS1.p2.1.m1.1.1.3.cmml" xref="S4.SS1.p2.1.m1.1.1.3">𝐺</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.1.m1.1c">\frac{K}{G}</annotation></semantics></math>. Given this upper bound, the results of full participation in the five-block structure are not further considered. Findings regarding the moderating effect of imbalance in addition to dependence are inconclusive. While there is no significant difference between the test accuracy scores of balanced and unbalanced data for the two-block structure, we observe a more pronounced drop in test accuracy for the multi-block structure. For <math id="S4.SS1.p2.2.m2.1" class="ltx_Math" alttext="G=5" display="inline"><semantics id="S4.SS1.p2.2.m2.1a"><mrow id="S4.SS1.p2.2.m2.1.1" xref="S4.SS1.p2.2.m2.1.1.cmml"><mi id="S4.SS1.p2.2.m2.1.1.2" xref="S4.SS1.p2.2.m2.1.1.2.cmml">G</mi><mo id="S4.SS1.p2.2.m2.1.1.1" xref="S4.SS1.p2.2.m2.1.1.1.cmml">=</mo><mn id="S4.SS1.p2.2.m2.1.1.3" xref="S4.SS1.p2.2.m2.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.2.m2.1b"><apply id="S4.SS1.p2.2.m2.1.1.cmml" xref="S4.SS1.p2.2.m2.1.1"><eq id="S4.SS1.p2.2.m2.1.1.1.cmml" xref="S4.SS1.p2.2.m2.1.1.1"></eq><ci id="S4.SS1.p2.2.m2.1.1.2.cmml" xref="S4.SS1.p2.2.m2.1.1.2">𝐺</ci><cn type="integer" id="S4.SS1.p2.2.m2.1.1.3.cmml" xref="S4.SS1.p2.2.m2.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.2.m2.1c">G=5</annotation></semantics></math>, the accuracy degrades by up to <math id="S4.SS1.p2.3.m3.1" class="ltx_Math" alttext="0.098" display="inline"><semantics id="S4.SS1.p2.3.m3.1a"><mn id="S4.SS1.p2.3.m3.1.1" xref="S4.SS1.p2.3.m3.1.1.cmml">0.098</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.3.m3.1b"><cn type="float" id="S4.SS1.p2.3.m3.1.1.cmml" xref="S4.SS1.p2.3.m3.1.1">0.098</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.3.m3.1c">0.098</annotation></semantics></math> percentage points. Despite the marginal effect in the case of the two-block compared to the five-block structure, we conclude that the implications of block-cyclic sampling are aggravated by unbalanced block distributions. This is concerning because unbalanced blocks may represent a realistic scenario when learning cyclically from differently engaged or sized geographic regions. For example, as the largest and most populous continent, rich sources of data are found in Asia. Due to cultural differences, however, the data found on mobile devices may differ greatly from those in America or Europe.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.1" class="ltx_p">In Figure <a href="#S4.F3" title="Figure 3 ‣ 4.1 Performance Analysis ‣ 4 Experiments ‣ Demystifying the Effects of Non-Independence in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, we show the confusion matrix for the predictions of the consensus model separated by two-block and five-block structure. We find that the two-block structure only shows a slight inclination towards the block of the final round, while cycling over a multi-block structure is prone to catastrophic forgetting <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>. We explain this behavior by the fact that <span id="S4.SS1.p3.1.1" class="ltx_text ltx_font_typewriter">FedAvg</span> treats each block as a separate task, forgetting the previous task. Although not explicitly depicted in Figure <a href="#S4.F3" title="Figure 3 ‣ 4.1 Performance Analysis ‣ 4 Experiments ‣ Demystifying the Effects of Non-Independence in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, we find that the proneness to block-structures is increased by higher block imbalance (not illustrated).</p>
</div>
<figure id="S4.F3" class="ltx_figure"><img src="/html/2103.11226/assets/x3.png" id="S4.F3.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="165" height="267" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Classification predictions of <span id="S4.F3.7.1" class="ltx_text ltx_font_typewriter">FedAvg</span> regarding the block-structure. Two-block structure, where the last block that performs training holds the classes <math id="S4.F3.3.m1.5" class="ltx_Math" alttext="\{5,6,7,8,9\}" display="inline"><semantics id="S4.F3.3.m1.5b"><mrow id="S4.F3.3.m1.5.6.2" xref="S4.F3.3.m1.5.6.1.cmml"><mo stretchy="false" id="S4.F3.3.m1.5.6.2.1" xref="S4.F3.3.m1.5.6.1.cmml">{</mo><mn id="S4.F3.3.m1.1.1" xref="S4.F3.3.m1.1.1.cmml">5</mn><mo id="S4.F3.3.m1.5.6.2.2" xref="S4.F3.3.m1.5.6.1.cmml">,</mo><mn id="S4.F3.3.m1.2.2" xref="S4.F3.3.m1.2.2.cmml">6</mn><mo id="S4.F3.3.m1.5.6.2.3" xref="S4.F3.3.m1.5.6.1.cmml">,</mo><mn id="S4.F3.3.m1.3.3" xref="S4.F3.3.m1.3.3.cmml">7</mn><mo id="S4.F3.3.m1.5.6.2.4" xref="S4.F3.3.m1.5.6.1.cmml">,</mo><mn id="S4.F3.3.m1.4.4" xref="S4.F3.3.m1.4.4.cmml">8</mn><mo id="S4.F3.3.m1.5.6.2.5" xref="S4.F3.3.m1.5.6.1.cmml">,</mo><mn id="S4.F3.3.m1.5.5" xref="S4.F3.3.m1.5.5.cmml">9</mn><mo stretchy="false" id="S4.F3.3.m1.5.6.2.6" xref="S4.F3.3.m1.5.6.1.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.F3.3.m1.5c"><set id="S4.F3.3.m1.5.6.1.cmml" xref="S4.F3.3.m1.5.6.2"><cn type="integer" id="S4.F3.3.m1.1.1.cmml" xref="S4.F3.3.m1.1.1">5</cn><cn type="integer" id="S4.F3.3.m1.2.2.cmml" xref="S4.F3.3.m1.2.2">6</cn><cn type="integer" id="S4.F3.3.m1.3.3.cmml" xref="S4.F3.3.m1.3.3">7</cn><cn type="integer" id="S4.F3.3.m1.4.4.cmml" xref="S4.F3.3.m1.4.4">8</cn><cn type="integer" id="S4.F3.3.m1.5.5.cmml" xref="S4.F3.3.m1.5.5">9</cn></set></annotation-xml><annotation encoding="application/x-tex" id="S4.F3.3.m1.5d">\{5,6,7,8,9\}</annotation></semantics></math>. Five-block structure, where the last block that performs training holds the classes <math id="S4.F3.4.m2.2" class="ltx_Math" alttext="\{8,9\}" display="inline"><semantics id="S4.F3.4.m2.2b"><mrow id="S4.F3.4.m2.2.3.2" xref="S4.F3.4.m2.2.3.1.cmml"><mo stretchy="false" id="S4.F3.4.m2.2.3.2.1" xref="S4.F3.4.m2.2.3.1.cmml">{</mo><mn id="S4.F3.4.m2.1.1" xref="S4.F3.4.m2.1.1.cmml">8</mn><mo id="S4.F3.4.m2.2.3.2.2" xref="S4.F3.4.m2.2.3.1.cmml">,</mo><mn id="S4.F3.4.m2.2.2" xref="S4.F3.4.m2.2.2.cmml">9</mn><mo stretchy="false" id="S4.F3.4.m2.2.3.2.3" xref="S4.F3.4.m2.2.3.1.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.F3.4.m2.2c"><set id="S4.F3.4.m2.2.3.1.cmml" xref="S4.F3.4.m2.2.3.2"><cn type="integer" id="S4.F3.4.m2.1.1.cmml" xref="S4.F3.4.m2.1.1">8</cn><cn type="integer" id="S4.F3.4.m2.2.2.cmml" xref="S4.F3.4.m2.2.2">9</cn></set></annotation-xml><annotation encoding="application/x-tex" id="S4.F3.4.m2.2d">\{8,9\}</annotation></semantics></math>. Caused by catastrophic forgetting, <span id="S4.F3.8.2" class="ltx_text ltx_font_typewriter">FedAvg</span> treats each block like a separate task and abruptly overwrites the previously learned information once information (in the form of data) is received from the subsequent block. This is particularly noticeable in the multi-block structure.</figcaption>
</figure>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Convergence Analysis</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">Following the performance analysis, we present the detailed convergence timeline graphs for balanced group distributions in Figure <a href="#S4.F4" title="Figure 4 ‣ 4.2 Convergence Analysis ‣ 4 Experiments ‣ Demystifying the Effects of Non-Independence in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. Convergence rates are plotted in increments of <math id="S4.SS2.p1.1.m1.1" class="ltx_Math" alttext="5" display="inline"><semantics id="S4.SS2.p1.1.m1.1a"><mn id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><cn type="integer" id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">5</annotation></semantics></math> rounds. We observe that the training in FL is robust to cyclic sampling up to two-block structures. In addition to reduced end-of-training test accuracy, we observe more volatile training error in the case of the multi-block structure. This oscillation makes it to achieve convergence.</p>
</div>
<figure id="S4.F4" class="ltx_figure"><img src="/html/2103.11226/assets/x4.png" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="148" height="107" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span><span id="S4.F4.6.1" class="ltx_text ltx_font_typewriter">FedAvg</span> training error with block-cyclic sampling. <math id="S4.F4.3.m1.1" class="ltx_Math" alttext="G=1" display="inline"><semantics id="S4.F4.3.m1.1b"><mrow id="S4.F4.3.m1.1.1" xref="S4.F4.3.m1.1.1.cmml"><mi id="S4.F4.3.m1.1.1.2" xref="S4.F4.3.m1.1.1.2.cmml">G</mi><mo id="S4.F4.3.m1.1.1.1" xref="S4.F4.3.m1.1.1.1.cmml">=</mo><mn id="S4.F4.3.m1.1.1.3" xref="S4.F4.3.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.F4.3.m1.1c"><apply id="S4.F4.3.m1.1.1.cmml" xref="S4.F4.3.m1.1.1"><eq id="S4.F4.3.m1.1.1.1.cmml" xref="S4.F4.3.m1.1.1.1"></eq><ci id="S4.F4.3.m1.1.1.2.cmml" xref="S4.F4.3.m1.1.1.2">𝐺</ci><cn type="integer" id="S4.F4.3.m1.1.1.3.cmml" xref="S4.F4.3.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.3.m1.1d">G=1</annotation></semantics></math> represents the convergence rate for the practical upper bound for non-cyclic non-i.i.d. training. We zoom into the interval <math id="S4.F4.4.m2.2" class="ltx_Math" alttext="[20,70]" display="inline"><semantics id="S4.F4.4.m2.2b"><mrow id="S4.F4.4.m2.2.3.2" xref="S4.F4.4.m2.2.3.1.cmml"><mo stretchy="false" id="S4.F4.4.m2.2.3.2.1" xref="S4.F4.4.m2.2.3.1.cmml">[</mo><mn id="S4.F4.4.m2.1.1" xref="S4.F4.4.m2.1.1.cmml">20</mn><mo id="S4.F4.4.m2.2.3.2.2" xref="S4.F4.4.m2.2.3.1.cmml">,</mo><mn id="S4.F4.4.m2.2.2" xref="S4.F4.4.m2.2.2.cmml">70</mn><mo stretchy="false" id="S4.F4.4.m2.2.3.2.3" xref="S4.F4.4.m2.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.F4.4.m2.2c"><interval closure="closed" id="S4.F4.4.m2.2.3.1.cmml" xref="S4.F4.4.m2.2.3.2"><cn type="integer" id="S4.F4.4.m2.1.1.cmml" xref="S4.F4.4.m2.1.1">20</cn><cn type="integer" id="S4.F4.4.m2.2.2.cmml" xref="S4.F4.4.m2.2.2">70</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.4.m2.2d">[20,70]</annotation></semantics></math> to show the oscillation of the error rate. While the two-block structure hardly oscillates, the oscillation in the training error of the multi-block structure slows down the convergence considerably.</figcaption>
</figure>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">Due to space limitations, we focus our analysis of block imbalance on the five-block structure. From Figure <a href="#S4.F5" title="Figure 5 ‣ 4.2 Convergence Analysis ‣ 4 Experiments ‣ Demystifying the Effects of Non-Independence in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, we find that the convergence slowdown is even more evident when the blocks are of skewed size. The vertical lines represent the lowest and highest loss achieved by clients selected at each training round. Although the average per-round training loss is low, the vertical lines clearly indicate that the training loss varies significantly. The variation is more pronounced when learning from unbalanced blocks. From the error amplitudes occurring every <math id="S4.SS2.p2.1.m1.1" class="ltx_Math" alttext="5{\text{th}}" display="inline"><semantics id="S4.SS2.p2.1.m1.1a"><mrow id="S4.SS2.p2.1.m1.1.1" xref="S4.SS2.p2.1.m1.1.1.cmml"><mn id="S4.SS2.p2.1.m1.1.1.2" xref="S4.SS2.p2.1.m1.1.1.2.cmml">5</mn><mo lspace="0em" rspace="0em" id="S4.SS2.p2.1.m1.1.1.1" xref="S4.SS2.p2.1.m1.1.1.1.cmml">​</mo><mtext id="S4.SS2.p2.1.m1.1.1.3" xref="S4.SS2.p2.1.m1.1.1.3a.cmml">th</mtext></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.1.m1.1b"><apply id="S4.SS2.p2.1.m1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1"><times id="S4.SS2.p2.1.m1.1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1.1"></times><cn type="integer" id="S4.SS2.p2.1.m1.1.1.2.cmml" xref="S4.SS2.p2.1.m1.1.1.2">5</cn><ci id="S4.SS2.p2.1.m1.1.1.3a.cmml" xref="S4.SS2.p2.1.m1.1.1.3"><mtext id="S4.SS2.p2.1.m1.1.1.3.cmml" xref="S4.SS2.p2.1.m1.1.1.3">th</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.1.m1.1c">5{\text{th}}</annotation></semantics></math> epoch we can clearly distinguish the training intervals of the minority block.</p>
</div>
<figure id="S4.F5" class="ltx_figure"><img src="/html/2103.11226/assets/x5.png" id="S4.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="170" height="114" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span><span id="S4.F5.8.1" class="ltx_text ltx_font_typewriter">FedAvg</span> training error with multi-block cyclic sampling with respect to block imbalance <math id="S4.F5.4.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S4.F5.4.m1.1b"><mi id="S4.F5.4.m1.1.1" xref="S4.F5.4.m1.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S4.F5.4.m1.1c"><ci id="S4.F5.4.m1.1.1.cmml" xref="S4.F5.4.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F5.4.m1.1d">\alpha</annotation></semantics></math>. A value of <math id="S4.F5.5.m2.1" class="ltx_Math" alttext="\alpha=1" display="inline"><semantics id="S4.F5.5.m2.1b"><mrow id="S4.F5.5.m2.1.1" xref="S4.F5.5.m2.1.1.cmml"><mi id="S4.F5.5.m2.1.1.2" xref="S4.F5.5.m2.1.1.2.cmml">α</mi><mo id="S4.F5.5.m2.1.1.1" xref="S4.F5.5.m2.1.1.1.cmml">=</mo><mn id="S4.F5.5.m2.1.1.3" xref="S4.F5.5.m2.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.F5.5.m2.1c"><apply id="S4.F5.5.m2.1.1.cmml" xref="S4.F5.5.m2.1.1"><eq id="S4.F5.5.m2.1.1.1.cmml" xref="S4.F5.5.m2.1.1.1"></eq><ci id="S4.F5.5.m2.1.1.2.cmml" xref="S4.F5.5.m2.1.1.2">𝛼</ci><cn type="integer" id="S4.F5.5.m2.1.1.3.cmml" xref="S4.F5.5.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F5.5.m2.1d">\alpha=1</annotation></semantics></math> indicates balanced blocks. A value of <math id="S4.F5.6.m3.1" class="ltx_Math" alttext="\alpha=5" display="inline"><semantics id="S4.F5.6.m3.1b"><mrow id="S4.F5.6.m3.1.1" xref="S4.F5.6.m3.1.1.cmml"><mi id="S4.F5.6.m3.1.1.2" xref="S4.F5.6.m3.1.1.2.cmml">α</mi><mo id="S4.F5.6.m3.1.1.1" xref="S4.F5.6.m3.1.1.1.cmml">=</mo><mn id="S4.F5.6.m3.1.1.3" xref="S4.F5.6.m3.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.F5.6.m3.1c"><apply id="S4.F5.6.m3.1.1.cmml" xref="S4.F5.6.m3.1.1"><eq id="S4.F5.6.m3.1.1.1.cmml" xref="S4.F5.6.m3.1.1.1"></eq><ci id="S4.F5.6.m3.1.1.2.cmml" xref="S4.F5.6.m3.1.1.2">𝛼</ci><cn type="integer" id="S4.F5.6.m3.1.1.3.cmml" xref="S4.F5.6.m3.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F5.6.m3.1d">\alpha=5</annotation></semantics></math> indicates unbalanced blocks. Vertical lines illustrate the highest and lowest training error achieved within the subset of selected clients per round. Note that top and bottom diagram are drawn at different scales.</figcaption>
</figure>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.9" class="ltx_p">To quantify the slowdown introduced by cycling over heterogeneous multi-block structures, we train the consensus model until convergence. With more rounds of communication and more frequent synchronization, we could compensate for the multi-block cycling. We begin with balanced distributions <math id="S4.SS2.p3.1.m1.1" class="ltx_Math" alttext="\alpha=1" display="inline"><semantics id="S4.SS2.p3.1.m1.1a"><mrow id="S4.SS2.p3.1.m1.1.1" xref="S4.SS2.p3.1.m1.1.1.cmml"><mi id="S4.SS2.p3.1.m1.1.1.2" xref="S4.SS2.p3.1.m1.1.1.2.cmml">α</mi><mo id="S4.SS2.p3.1.m1.1.1.1" xref="S4.SS2.p3.1.m1.1.1.1.cmml">=</mo><mn id="S4.SS2.p3.1.m1.1.1.3" xref="S4.SS2.p3.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.1.m1.1b"><apply id="S4.SS2.p3.1.m1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1"><eq id="S4.SS2.p3.1.m1.1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1.1"></eq><ci id="S4.SS2.p3.1.m1.1.1.2.cmml" xref="S4.SS2.p3.1.m1.1.1.2">𝛼</ci><cn type="integer" id="S4.SS2.p3.1.m1.1.1.3.cmml" xref="S4.SS2.p3.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.1.m1.1c">\alpha=1</annotation></semantics></math>. By doubling the number of communication rounds, <em id="S4.SS2.p3.9.1" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S4.SS2.p3.9.2" class="ltx_text"></span>, <math id="S4.SS2.p3.2.m2.2" class="ltx_Math" alttext="T=200,E=3" display="inline"><semantics id="S4.SS2.p3.2.m2.2a"><mrow id="S4.SS2.p3.2.m2.2.2.2" xref="S4.SS2.p3.2.m2.2.2.3.cmml"><mrow id="S4.SS2.p3.2.m2.1.1.1.1" xref="S4.SS2.p3.2.m2.1.1.1.1.cmml"><mi id="S4.SS2.p3.2.m2.1.1.1.1.2" xref="S4.SS2.p3.2.m2.1.1.1.1.2.cmml">T</mi><mo id="S4.SS2.p3.2.m2.1.1.1.1.1" xref="S4.SS2.p3.2.m2.1.1.1.1.1.cmml">=</mo><mn id="S4.SS2.p3.2.m2.1.1.1.1.3" xref="S4.SS2.p3.2.m2.1.1.1.1.3.cmml">200</mn></mrow><mo id="S4.SS2.p3.2.m2.2.2.2.3" xref="S4.SS2.p3.2.m2.2.2.3a.cmml">,</mo><mrow id="S4.SS2.p3.2.m2.2.2.2.2" xref="S4.SS2.p3.2.m2.2.2.2.2.cmml"><mi id="S4.SS2.p3.2.m2.2.2.2.2.2" xref="S4.SS2.p3.2.m2.2.2.2.2.2.cmml">E</mi><mo id="S4.SS2.p3.2.m2.2.2.2.2.1" xref="S4.SS2.p3.2.m2.2.2.2.2.1.cmml">=</mo><mn id="S4.SS2.p3.2.m2.2.2.2.2.3" xref="S4.SS2.p3.2.m2.2.2.2.2.3.cmml">3</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.2.m2.2b"><apply id="S4.SS2.p3.2.m2.2.2.3.cmml" xref="S4.SS2.p3.2.m2.2.2.2"><csymbol cd="ambiguous" id="S4.SS2.p3.2.m2.2.2.3a.cmml" xref="S4.SS2.p3.2.m2.2.2.2.3">formulae-sequence</csymbol><apply id="S4.SS2.p3.2.m2.1.1.1.1.cmml" xref="S4.SS2.p3.2.m2.1.1.1.1"><eq id="S4.SS2.p3.2.m2.1.1.1.1.1.cmml" xref="S4.SS2.p3.2.m2.1.1.1.1.1"></eq><ci id="S4.SS2.p3.2.m2.1.1.1.1.2.cmml" xref="S4.SS2.p3.2.m2.1.1.1.1.2">𝑇</ci><cn type="integer" id="S4.SS2.p3.2.m2.1.1.1.1.3.cmml" xref="S4.SS2.p3.2.m2.1.1.1.1.3">200</cn></apply><apply id="S4.SS2.p3.2.m2.2.2.2.2.cmml" xref="S4.SS2.p3.2.m2.2.2.2.2"><eq id="S4.SS2.p3.2.m2.2.2.2.2.1.cmml" xref="S4.SS2.p3.2.m2.2.2.2.2.1"></eq><ci id="S4.SS2.p3.2.m2.2.2.2.2.2.cmml" xref="S4.SS2.p3.2.m2.2.2.2.2.2">𝐸</ci><cn type="integer" id="S4.SS2.p3.2.m2.2.2.2.2.3.cmml" xref="S4.SS2.p3.2.m2.2.2.2.2.3">3</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.2.m2.2c">T=200,E=3</annotation></semantics></math>, we measure a consensus accuracy of <math id="S4.SS2.p3.3.m3.1" class="ltx_Math" alttext="0.8878" display="inline"><semantics id="S4.SS2.p3.3.m3.1a"><mn id="S4.SS2.p3.3.m3.1.1" xref="S4.SS2.p3.3.m3.1.1.cmml">0.8878</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.3.m3.1b"><cn type="float" id="S4.SS2.p3.3.m3.1.1.cmml" xref="S4.SS2.p3.3.m3.1.1">0.8878</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.3.m3.1c">0.8878</annotation></semantics></math>. This represents a performance gain of about <math id="S4.SS2.p3.4.m4.1" class="ltx_Math" alttext="20" display="inline"><semantics id="S4.SS2.p3.4.m4.1a"><mn id="S4.SS2.p3.4.m4.1.1" xref="S4.SS2.p3.4.m4.1.1.cmml">20</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.4.m4.1b"><cn type="integer" id="S4.SS2.p3.4.m4.1.1.cmml" xref="S4.SS2.p3.4.m4.1.1">20</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.4.m4.1c">20</annotation></semantics></math>%. By synchronizing weights more frequently in addition to doubling the number of communication rounds, <em id="S4.SS2.p3.9.3" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S4.SS2.p3.9.4" class="ltx_text"></span>, <math id="S4.SS2.p3.5.m5.2" class="ltx_Math" alttext="T=200,E=1" display="inline"><semantics id="S4.SS2.p3.5.m5.2a"><mrow id="S4.SS2.p3.5.m5.2.2.2" xref="S4.SS2.p3.5.m5.2.2.3.cmml"><mrow id="S4.SS2.p3.5.m5.1.1.1.1" xref="S4.SS2.p3.5.m5.1.1.1.1.cmml"><mi id="S4.SS2.p3.5.m5.1.1.1.1.2" xref="S4.SS2.p3.5.m5.1.1.1.1.2.cmml">T</mi><mo id="S4.SS2.p3.5.m5.1.1.1.1.1" xref="S4.SS2.p3.5.m5.1.1.1.1.1.cmml">=</mo><mn id="S4.SS2.p3.5.m5.1.1.1.1.3" xref="S4.SS2.p3.5.m5.1.1.1.1.3.cmml">200</mn></mrow><mo id="S4.SS2.p3.5.m5.2.2.2.3" xref="S4.SS2.p3.5.m5.2.2.3a.cmml">,</mo><mrow id="S4.SS2.p3.5.m5.2.2.2.2" xref="S4.SS2.p3.5.m5.2.2.2.2.cmml"><mi id="S4.SS2.p3.5.m5.2.2.2.2.2" xref="S4.SS2.p3.5.m5.2.2.2.2.2.cmml">E</mi><mo id="S4.SS2.p3.5.m5.2.2.2.2.1" xref="S4.SS2.p3.5.m5.2.2.2.2.1.cmml">=</mo><mn id="S4.SS2.p3.5.m5.2.2.2.2.3" xref="S4.SS2.p3.5.m5.2.2.2.2.3.cmml">1</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.5.m5.2b"><apply id="S4.SS2.p3.5.m5.2.2.3.cmml" xref="S4.SS2.p3.5.m5.2.2.2"><csymbol cd="ambiguous" id="S4.SS2.p3.5.m5.2.2.3a.cmml" xref="S4.SS2.p3.5.m5.2.2.2.3">formulae-sequence</csymbol><apply id="S4.SS2.p3.5.m5.1.1.1.1.cmml" xref="S4.SS2.p3.5.m5.1.1.1.1"><eq id="S4.SS2.p3.5.m5.1.1.1.1.1.cmml" xref="S4.SS2.p3.5.m5.1.1.1.1.1"></eq><ci id="S4.SS2.p3.5.m5.1.1.1.1.2.cmml" xref="S4.SS2.p3.5.m5.1.1.1.1.2">𝑇</ci><cn type="integer" id="S4.SS2.p3.5.m5.1.1.1.1.3.cmml" xref="S4.SS2.p3.5.m5.1.1.1.1.3">200</cn></apply><apply id="S4.SS2.p3.5.m5.2.2.2.2.cmml" xref="S4.SS2.p3.5.m5.2.2.2.2"><eq id="S4.SS2.p3.5.m5.2.2.2.2.1.cmml" xref="S4.SS2.p3.5.m5.2.2.2.2.1"></eq><ci id="S4.SS2.p3.5.m5.2.2.2.2.2.cmml" xref="S4.SS2.p3.5.m5.2.2.2.2.2">𝐸</ci><cn type="integer" id="S4.SS2.p3.5.m5.2.2.2.2.3.cmml" xref="S4.SS2.p3.5.m5.2.2.2.2.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.5.m5.2c">T=200,E=1</annotation></semantics></math>, we measure a consensus accuracy of <math id="S4.SS2.p3.6.m6.1" class="ltx_Math" alttext="0.9392" display="inline"><semantics id="S4.SS2.p3.6.m6.1a"><mn id="S4.SS2.p3.6.m6.1.1" xref="S4.SS2.p3.6.m6.1.1.cmml">0.9392</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.6.m6.1b"><cn type="float" id="S4.SS2.p3.6.m6.1.1.cmml" xref="S4.SS2.p3.6.m6.1.1">0.9392</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.6.m6.1c">0.9392</annotation></semantics></math> which resembles approximately the value of cyclic sampling from two blocks. Considering this rather simple visual classification task, the results show that the performance decrease induced by high degrees of independence can hardly be compensated by additional optimization budget. This is even more concerning for unbalanced block distributions. For <math id="S4.SS2.p3.7.m7.1" class="ltx_Math" alttext="\alpha=5" display="inline"><semantics id="S4.SS2.p3.7.m7.1a"><mrow id="S4.SS2.p3.7.m7.1.1" xref="S4.SS2.p3.7.m7.1.1.cmml"><mi id="S4.SS2.p3.7.m7.1.1.2" xref="S4.SS2.p3.7.m7.1.1.2.cmml">α</mi><mo id="S4.SS2.p3.7.m7.1.1.1" xref="S4.SS2.p3.7.m7.1.1.1.cmml">=</mo><mn id="S4.SS2.p3.7.m7.1.1.3" xref="S4.SS2.p3.7.m7.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.7.m7.1b"><apply id="S4.SS2.p3.7.m7.1.1.cmml" xref="S4.SS2.p3.7.m7.1.1"><eq id="S4.SS2.p3.7.m7.1.1.1.cmml" xref="S4.SS2.p3.7.m7.1.1.1"></eq><ci id="S4.SS2.p3.7.m7.1.1.2.cmml" xref="S4.SS2.p3.7.m7.1.1.2">𝛼</ci><cn type="integer" id="S4.SS2.p3.7.m7.1.1.3.cmml" xref="S4.SS2.p3.7.m7.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.7.m7.1c">\alpha=5</annotation></semantics></math>, doubling the number of communication rounds, <em id="S4.SS2.p3.9.5" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S4.SS2.p3.9.6" class="ltx_text"></span>, <math id="S4.SS2.p3.8.m8.2" class="ltx_Math" alttext="T=200,E=3" display="inline"><semantics id="S4.SS2.p3.8.m8.2a"><mrow id="S4.SS2.p3.8.m8.2.2.2" xref="S4.SS2.p3.8.m8.2.2.3.cmml"><mrow id="S4.SS2.p3.8.m8.1.1.1.1" xref="S4.SS2.p3.8.m8.1.1.1.1.cmml"><mi id="S4.SS2.p3.8.m8.1.1.1.1.2" xref="S4.SS2.p3.8.m8.1.1.1.1.2.cmml">T</mi><mo id="S4.SS2.p3.8.m8.1.1.1.1.1" xref="S4.SS2.p3.8.m8.1.1.1.1.1.cmml">=</mo><mn id="S4.SS2.p3.8.m8.1.1.1.1.3" xref="S4.SS2.p3.8.m8.1.1.1.1.3.cmml">200</mn></mrow><mo id="S4.SS2.p3.8.m8.2.2.2.3" xref="S4.SS2.p3.8.m8.2.2.3a.cmml">,</mo><mrow id="S4.SS2.p3.8.m8.2.2.2.2" xref="S4.SS2.p3.8.m8.2.2.2.2.cmml"><mi id="S4.SS2.p3.8.m8.2.2.2.2.2" xref="S4.SS2.p3.8.m8.2.2.2.2.2.cmml">E</mi><mo id="S4.SS2.p3.8.m8.2.2.2.2.1" xref="S4.SS2.p3.8.m8.2.2.2.2.1.cmml">=</mo><mn id="S4.SS2.p3.8.m8.2.2.2.2.3" xref="S4.SS2.p3.8.m8.2.2.2.2.3.cmml">3</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.8.m8.2b"><apply id="S4.SS2.p3.8.m8.2.2.3.cmml" xref="S4.SS2.p3.8.m8.2.2.2"><csymbol cd="ambiguous" id="S4.SS2.p3.8.m8.2.2.3a.cmml" xref="S4.SS2.p3.8.m8.2.2.2.3">formulae-sequence</csymbol><apply id="S4.SS2.p3.8.m8.1.1.1.1.cmml" xref="S4.SS2.p3.8.m8.1.1.1.1"><eq id="S4.SS2.p3.8.m8.1.1.1.1.1.cmml" xref="S4.SS2.p3.8.m8.1.1.1.1.1"></eq><ci id="S4.SS2.p3.8.m8.1.1.1.1.2.cmml" xref="S4.SS2.p3.8.m8.1.1.1.1.2">𝑇</ci><cn type="integer" id="S4.SS2.p3.8.m8.1.1.1.1.3.cmml" xref="S4.SS2.p3.8.m8.1.1.1.1.3">200</cn></apply><apply id="S4.SS2.p3.8.m8.2.2.2.2.cmml" xref="S4.SS2.p3.8.m8.2.2.2.2"><eq id="S4.SS2.p3.8.m8.2.2.2.2.1.cmml" xref="S4.SS2.p3.8.m8.2.2.2.2.1"></eq><ci id="S4.SS2.p3.8.m8.2.2.2.2.2.cmml" xref="S4.SS2.p3.8.m8.2.2.2.2.2">𝐸</ci><cn type="integer" id="S4.SS2.p3.8.m8.2.2.2.2.3.cmml" xref="S4.SS2.p3.8.m8.2.2.2.2.3">3</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.8.m8.2c">T=200,E=3</annotation></semantics></math>, improves the test accuracy only slightly by about <math id="S4.SS2.p3.9.m9.1" class="ltx_Math" alttext="18" display="inline"><semantics id="S4.SS2.p3.9.m9.1a"><mn id="S4.SS2.p3.9.m9.1.1" xref="S4.SS2.p3.9.m9.1.1.cmml">18</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.9.m9.1b"><cn type="integer" id="S4.SS2.p3.9.m9.1.1.cmml" xref="S4.SS2.p3.9.m9.1.1">18</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.9.m9.1c">18</annotation></semantics></math>%. A further tripling of the synchronization resulted in no further improvement.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Fairness Analysis</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.3" class="ltx_p">Abandoning the fixed optimization budget in terms of communication-efficiency, we unset the total number of rounds and train until convergence. By training until convergence we achieve a test accuracy of the consensus model above <math id="S4.SS3.p1.1.m1.1" class="ltx_Math" alttext="0.9616" display="inline"><semantics id="S4.SS3.p1.1.m1.1a"><mn id="S4.SS3.p1.1.m1.1.1" xref="S4.SS3.p1.1.m1.1.1.cmml">0.9616</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.1.m1.1b"><cn type="float" id="S4.SS3.p1.1.m1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1">0.9616</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.1.m1.1c">0.9616</annotation></semantics></math> for all experiments. To draw conclusions about the effect of block-cycling sampling on fairness, we plot the ordered local accuracies on a quantile-quantile diagram in Figure <a href="#S4.F6" title="Figure 6 ‣ 4.3 Fairness Analysis ‣ 4 Experiments ‣ Demystifying the Effects of Non-Independence in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>. The dashed line represents the fairness-optimal accuracy distribution. With the exception of a few slightly underperforming clients, we find the the balanced two-block structure results in a fair distribution. With increasing block imbalance <math id="S4.SS3.p1.2.m2.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S4.SS3.p1.2.m2.1a"><mi id="S4.SS3.p1.2.m2.1.1" xref="S4.SS3.p1.2.m2.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.2.m2.1b"><ci id="S4.SS3.p1.2.m2.1.1.cmml" xref="S4.SS3.p1.2.m2.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.2.m2.1c">\alpha</annotation></semantics></math>, we find clients from the majority block performing better with an almost constant accuracy. An in-depth analysis reveals that their performance increase does not come at the expense of clients from the minority block. We thus conclude that the performance increase can be attributed to the sampling with replacement entailing an oversampling effect. We cannot assume that multi-block structures will also lead to a fair accuracy distribution. When cycling over multi-block structures the accuracy concentrates towards the distribution tails. Having the tails heavily overpopulated while the middle is underpopulated means that a large portion of the clients will benefit less from the collaborative training. This accuracy gap is even wider for unbalanced block distributions with <math id="S4.SS3.p1.3.m3.1" class="ltx_Math" alttext="\alpha&gt;1" display="inline"><semantics id="S4.SS3.p1.3.m3.1a"><mrow id="S4.SS3.p1.3.m3.1.1" xref="S4.SS3.p1.3.m3.1.1.cmml"><mi id="S4.SS3.p1.3.m3.1.1.2" xref="S4.SS3.p1.3.m3.1.1.2.cmml">α</mi><mo id="S4.SS3.p1.3.m3.1.1.1" xref="S4.SS3.p1.3.m3.1.1.1.cmml">&gt;</mo><mn id="S4.SS3.p1.3.m3.1.1.3" xref="S4.SS3.p1.3.m3.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.3.m3.1b"><apply id="S4.SS3.p1.3.m3.1.1.cmml" xref="S4.SS3.p1.3.m3.1.1"><gt id="S4.SS3.p1.3.m3.1.1.1.cmml" xref="S4.SS3.p1.3.m3.1.1.1"></gt><ci id="S4.SS3.p1.3.m3.1.1.2.cmml" xref="S4.SS3.p1.3.m3.1.1.2">𝛼</ci><cn type="integer" id="S4.SS3.p1.3.m3.1.1.3.cmml" xref="S4.SS3.p1.3.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.3.m3.1c">\alpha&gt;1</annotation></semantics></math>. In fact, the accuracy distribution of unbalanced multi-blocks deviates the most from an uniform trend.</p>
</div>
<figure id="S4.F6" class="ltx_figure"><img src="/html/2103.11226/assets/x6.png" id="S4.F6.g1" class="ltx_graphics ltx_centering ltx_img_square" width="170" height="197" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span><span id="S4.F6.2.1" class="ltx_text ltx_font_typewriter">FedAvg</span> test accuracy distribution with respect to different variants of block-cyclic sampling. Figures are sorted in ascending order of complexity. The dashed line represents a theoretical uniform distribution. It resembles the fairness-optimal accuracy distribution from a client-level perspective.</figcaption>
</figure>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Sensitivity Analysis</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.3" class="ltx_p">The learning rate is widely considered one of the most important hyperparameters, <em id="S4.SS4.p1.3.1" class="ltx_emph ltx_font_italic">e.g</em>.<span id="S4.SS4.p1.3.2" class="ltx_text"></span>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>. For this reason, we perform a sensitivity analysis over a grid of client learning rates in logarithmic scale, <em id="S4.SS4.p1.3.3" class="ltx_emph ltx_font_italic">i.e</em>.<span id="S4.SS4.p1.3.4" class="ltx_text"></span>, <math id="S4.SS4.p1.1.m1.3" class="ltx_Math" alttext="\eta\in\{0.001,0.01,0.1\}" display="inline"><semantics id="S4.SS4.p1.1.m1.3a"><mrow id="S4.SS4.p1.1.m1.3.4" xref="S4.SS4.p1.1.m1.3.4.cmml"><mi id="S4.SS4.p1.1.m1.3.4.2" xref="S4.SS4.p1.1.m1.3.4.2.cmml">η</mi><mo id="S4.SS4.p1.1.m1.3.4.1" xref="S4.SS4.p1.1.m1.3.4.1.cmml">∈</mo><mrow id="S4.SS4.p1.1.m1.3.4.3.2" xref="S4.SS4.p1.1.m1.3.4.3.1.cmml"><mo stretchy="false" id="S4.SS4.p1.1.m1.3.4.3.2.1" xref="S4.SS4.p1.1.m1.3.4.3.1.cmml">{</mo><mn id="S4.SS4.p1.1.m1.1.1" xref="S4.SS4.p1.1.m1.1.1.cmml">0.001</mn><mo id="S4.SS4.p1.1.m1.3.4.3.2.2" xref="S4.SS4.p1.1.m1.3.4.3.1.cmml">,</mo><mn id="S4.SS4.p1.1.m1.2.2" xref="S4.SS4.p1.1.m1.2.2.cmml">0.01</mn><mo id="S4.SS4.p1.1.m1.3.4.3.2.3" xref="S4.SS4.p1.1.m1.3.4.3.1.cmml">,</mo><mn id="S4.SS4.p1.1.m1.3.3" xref="S4.SS4.p1.1.m1.3.3.cmml">0.1</mn><mo stretchy="false" id="S4.SS4.p1.1.m1.3.4.3.2.4" xref="S4.SS4.p1.1.m1.3.4.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.1.m1.3b"><apply id="S4.SS4.p1.1.m1.3.4.cmml" xref="S4.SS4.p1.1.m1.3.4"><in id="S4.SS4.p1.1.m1.3.4.1.cmml" xref="S4.SS4.p1.1.m1.3.4.1"></in><ci id="S4.SS4.p1.1.m1.3.4.2.cmml" xref="S4.SS4.p1.1.m1.3.4.2">𝜂</ci><set id="S4.SS4.p1.1.m1.3.4.3.1.cmml" xref="S4.SS4.p1.1.m1.3.4.3.2"><cn type="float" id="S4.SS4.p1.1.m1.1.1.cmml" xref="S4.SS4.p1.1.m1.1.1">0.001</cn><cn type="float" id="S4.SS4.p1.1.m1.2.2.cmml" xref="S4.SS4.p1.1.m1.2.2">0.01</cn><cn type="float" id="S4.SS4.p1.1.m1.3.3.cmml" xref="S4.SS4.p1.1.m1.3.3">0.1</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.1.m1.3c">\eta\in\{0.001,0.01,0.1\}</annotation></semantics></math>. For the sensitivity analysis, we again reset the communication budget to <math id="S4.SS4.p1.2.m2.1" class="ltx_Math" alttext="E=3" display="inline"><semantics id="S4.SS4.p1.2.m2.1a"><mrow id="S4.SS4.p1.2.m2.1.1" xref="S4.SS4.p1.2.m2.1.1.cmml"><mi id="S4.SS4.p1.2.m2.1.1.2" xref="S4.SS4.p1.2.m2.1.1.2.cmml">E</mi><mo id="S4.SS4.p1.2.m2.1.1.1" xref="S4.SS4.p1.2.m2.1.1.1.cmml">=</mo><mn id="S4.SS4.p1.2.m2.1.1.3" xref="S4.SS4.p1.2.m2.1.1.3.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.2.m2.1b"><apply id="S4.SS4.p1.2.m2.1.1.cmml" xref="S4.SS4.p1.2.m2.1.1"><eq id="S4.SS4.p1.2.m2.1.1.1.cmml" xref="S4.SS4.p1.2.m2.1.1.1"></eq><ci id="S4.SS4.p1.2.m2.1.1.2.cmml" xref="S4.SS4.p1.2.m2.1.1.2">𝐸</ci><cn type="integer" id="S4.SS4.p1.2.m2.1.1.3.cmml" xref="S4.SS4.p1.2.m2.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.2.m2.1c">E=3</annotation></semantics></math> and <math id="S4.SS4.p1.3.m3.1" class="ltx_Math" alttext="T=100" display="inline"><semantics id="S4.SS4.p1.3.m3.1a"><mrow id="S4.SS4.p1.3.m3.1.1" xref="S4.SS4.p1.3.m3.1.1.cmml"><mi id="S4.SS4.p1.3.m3.1.1.2" xref="S4.SS4.p1.3.m3.1.1.2.cmml">T</mi><mo id="S4.SS4.p1.3.m3.1.1.1" xref="S4.SS4.p1.3.m3.1.1.1.cmml">=</mo><mn id="S4.SS4.p1.3.m3.1.1.3" xref="S4.SS4.p1.3.m3.1.1.3.cmml">100</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.3.m3.1b"><apply id="S4.SS4.p1.3.m3.1.1.cmml" xref="S4.SS4.p1.3.m3.1.1"><eq id="S4.SS4.p1.3.m3.1.1.1.cmml" xref="S4.SS4.p1.3.m3.1.1.1"></eq><ci id="S4.SS4.p1.3.m3.1.1.2.cmml" xref="S4.SS4.p1.3.m3.1.1.2">𝑇</ci><cn type="integer" id="S4.SS4.p1.3.m3.1.1.3.cmml" xref="S4.SS4.p1.3.m3.1.1.3">100</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.3.m3.1c">T=100</annotation></semantics></math> (as in our primary analysis).</p>
</div>
<figure id="S4.F7" class="ltx_figure"><img src="/html/2103.11226/assets/x7.png" id="S4.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="170" height="114" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span><span id="S4.F7.2.1" class="ltx_text ltx_font_typewriter">FedAvg</span> test accuracy in terms of learning rate grouped by the ratio of dependence. The magnitude of the learning rates is encoded by the line thickness. More solid lines represent higher rates. Stronger dotted lines represent lower rates.</figcaption>
</figure>
<div id="S4.SS4.p2" class="ltx_para">
<p id="S4.SS4.p2.2" class="ltx_p">From Figure <a href="#S4.F7" title="Figure 7 ‣ 4.4 Sensitivity Analysis ‣ 4 Experiments ‣ Demystifying the Effects of Non-Independence in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>, we observe that the lines representing the test accuracy are closer together for the two-block structure compared to the five-block structure. We thus conclude that the learning rate is highly sensitive to the ratio of dependence. We also identify diminishing returns when fine-tuning the learning rates. For a small <math id="S4.SS4.p2.1.m1.1" class="ltx_Math" alttext="G" display="inline"><semantics id="S4.SS4.p2.1.m1.1a"><mi id="S4.SS4.p2.1.m1.1.1" xref="S4.SS4.p2.1.m1.1.1.cmml">G</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.1.m1.1b"><ci id="S4.SS4.p2.1.m1.1.1.cmml" xref="S4.SS4.p2.1.m1.1.1">𝐺</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.1.m1.1c">G</annotation></semantics></math>, a range of learning rates (about one order of magnitude) can produce good accuracy on the holdout set. For a large <math id="S4.SS4.p2.2.m2.1" class="ltx_Math" alttext="G" display="inline"><semantics id="S4.SS4.p2.2.m2.1a"><mi id="S4.SS4.p2.2.m2.1.1" xref="S4.SS4.p2.2.m2.1.1.cmml">G</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.2.m2.1b"><ci id="S4.SS4.p2.2.m2.1.1.cmml" xref="S4.SS4.p2.2.m2.1.1">𝐺</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.2.m2.1c">G</annotation></semantics></math>, careful fine-tuning of the learning rate is required to reach good accuracy. In fact, suboptimal learning rates may halve the accuracy for high ratios of dependence. We argue that learning rates that are set too high intensify catastrophic forgetting, resulting in a high misclassification rate towards the last trained block. However, once an optimal learning rate is found, it is relatively unaffected by the ratio of imbalance between blocks.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In response to the growing demand on the part of legislative authorities to consider user privacy, FL is increasingly employed in practice. Practical FL is exposed to statistical heterogeneity. In this study, we analyzed the effect of block-cyclic sampling embodied in FL as a result of temporal and behavioral patterns of end-users. We conduct extensive experiments on block-cyclic sampling of images for visual classification. We empirically find that the performance degrades gracefully when training with two-block structures, <em id="S5.p1.1.1" class="ltx_emph ltx_font_italic">e.g</em>.<span id="S5.p1.1.2" class="ltx_text"></span>, blocks corresponding to ”day” and ”night”. Once block-cyclic sampling approaches a multi-block structure, significant communication overhead is required to compensate for the severe drop in classification performance. We also find that multiblock structures lead to non-uniform accuracy distributions that systematically discriminate a subset of clients. We also find that multiblock structures lead to non-uniform accuracy distributions that systematically discriminate a subset of clients.A number of avenues for future research are appealing. To further understand the impact of block-cyclic sampling in visual classification, reproducing the experiments on real-world data is required. In addition, finding methods to address the problem of data non-independence in FL while maintaining privacy and fairness is of primary concern.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock"><span id="bib.bib1.1.1" class="ltx_text" style="font-size:90%;">
Manoj Ghuhan Arivazhagan, Vinay Aggarwal, Aaditya Kumar Singh, and Sunav
Choudhary.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.2.1" class="ltx_text" style="font-size:90%;">Federated learning with personalization layers.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1912.00818</span><span id="bib.bib1.4.2" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text" style="font-size:90%;">
Shai Ben-David, John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, and
Jennifer Wortman Vaughan.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.2.1" class="ltx_text" style="font-size:90%;">A theory of learning from different domains.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Machine learning</span><span id="bib.bib2.4.2" class="ltx_text" style="font-size:90%;">, 79(1):151–175, 2010.
</span>
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text" style="font-size:90%;">
Fei Chen, Mi Luo, Zhenhua Dong, Zhenguo Li, and Xiuqiang He.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.2.1" class="ltx_text" style="font-size:90%;">Federated meta-learning with fast convergence and efficient
communication.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1802.07876</span><span id="bib.bib3.4.2" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock"><span id="bib.bib4.1.1" class="ltx_text" style="font-size:90%;">
Wei Chen, Kartikeya Bhardwaj, and Radu Marculescu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.2.1" class="ltx_text" style="font-size:90%;">Fedmax: Mitigating activation divergence for accurate and
communication-efficient federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2004.03657</span><span id="bib.bib4.4.2" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text" style="font-size:90%;">
Luca Corinzia and Joachim M Buhmann.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.2.1" class="ltx_text" style="font-size:90%;">Variational federated multi-task learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1906.06268</span><span id="bib.bib5.4.2" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text" style="font-size:90%;">
Moming Duan, Duo Liu, Xianzhang Chen, Renping Liu, Yujuan Tan, and Liang Liang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.2.1" class="ltx_text" style="font-size:90%;">Self-balancing federated learning with global imbalanced data in
mobile systems.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Parallel and Distributed Systems</span><span id="bib.bib6.4.2" class="ltx_text" style="font-size:90%;">,
32(1):59–71, 2020.
</span>
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text" style="font-size:90%;">
Moming Duan, Duo Liu, Xinyuan Ji, Renping Liu, Liang Liang, Xianzhang Chen, and
Yujuan Tan.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.2.1" class="ltx_text" style="font-size:90%;">Fedgroup: Ternary cosine similarity-based clustered federated
learning framework toward high accuracy in heterogeneity data.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2010.06870</span><span id="bib.bib7.4.2" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text" style="font-size:90%;">
Hubert Eichner, Tomer Koren, Brendan McMahan, Nathan Srebro, and Kunal Talwar.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.2.1" class="ltx_text" style="font-size:90%;">Semi-cyclic stochastic gradient descent.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib8.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">International Conference on Machine Learning</span><span id="bib.bib8.5.3" class="ltx_text" style="font-size:90%;">, pages
1764–1773. PMLR, 2019.
</span>
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text" style="font-size:90%;">
Alireza Fallah, Aryan Mokhtari, and Asuman Ozdaglar.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.2.1" class="ltx_text" style="font-size:90%;">Personalized federated learning: A meta-learning approach.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2002.07948</span><span id="bib.bib9.4.2" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text" style="font-size:90%;">
Filip Hanzely and Peter Richtárik.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.2.1" class="ltx_text" style="font-size:90%;">Federated learning of a mixture of global and local models.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2002.05516</span><span id="bib.bib10.4.2" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text" style="font-size:90%;">
Andrew Hard, Kanishka Rao, Rajiv Mathews, Swaroop Ramaswamy, Françoise
Beaufays, Sean Augenstein, Hubert Eichner, Chloé Kiddon, and Daniel
Ramage.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.2.1" class="ltx_text" style="font-size:90%;">Federated learning for mobile keyboard prediction.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1811.03604</span><span id="bib.bib11.4.2" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock"><span id="bib.bib12.1.1" class="ltx_text" style="font-size:90%;">
Kevin Hsieh, Amar Phanishayee, Onur Mutlu, and Phillip Gibbons.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.2.1" class="ltx_text" style="font-size:90%;">The non-iid data quagmire of decentralized machine learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib12.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">International Conference on Machine Learning</span><span id="bib.bib12.5.3" class="ltx_text" style="font-size:90%;">, pages
4387–4398. PMLR, 2020.
</span>
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text" style="font-size:90%;">
Tzu-Ming Harry Hsu, Hang Qi, and Matthew Brown.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.2.1" class="ltx_text" style="font-size:90%;">Measuring the effects of non-identical data distribution for
federated visual classification.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1909.06335</span><span id="bib.bib13.4.2" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock"><span id="bib.bib14.1.1" class="ltx_text" style="font-size:90%;">
Yaochen Hu, Di Niu, Jianming Yang, and Shengping Zhou.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.2.1" class="ltx_text" style="font-size:90%;">Stochastic distributed optimization for machine learning from
decentralized features.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1812.06415</span><span id="bib.bib14.4.2" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock"><span id="bib.bib15.1.1" class="ltx_text" style="font-size:90%;">
Wei Huang, Tianrui Li, Dexian Wang, Shengdong Du, and Junbo Zhang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.2.1" class="ltx_text" style="font-size:90%;">Fairness and accuracy in federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2012.10069</span><span id="bib.bib15.4.2" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text" style="font-size:90%;">
Peter Kairouz, H Brendan McMahan, Brendan Avent, Aurélien Bellet, Mehdi
Bennis, Arjun Nitin Bhagoji, Keith Bonawitz, Zachary Charles, Graham Cormode,
Rachel Cummings, et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.2.1" class="ltx_text" style="font-size:90%;">Advances and open problems in federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1912.04977</span><span id="bib.bib16.4.2" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock"><span id="bib.bib17.1.1" class="ltx_text" style="font-size:90%;">
Sai Praneeth Karimireddy, Satyen Kale, Mehryar Mohri, Sashank Reddi, Sebastian
Stich, and Ananda Theertha Suresh.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.2.1" class="ltx_text" style="font-size:90%;">Scaffold: Stochastic controlled averaging for federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib17.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">International Conference on Machine Learning</span><span id="bib.bib17.5.3" class="ltx_text" style="font-size:90%;">, pages
5132–5143. PMLR, 2020.
</span>
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock"><span id="bib.bib18.1.1" class="ltx_text" style="font-size:90%;">
Ahmed Khaled, Konstantin Mishchenko, and Peter Richtárik.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.2.1" class="ltx_text" style="font-size:90%;">Tighter theory for local sgd on identical and heterogeneous data.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib18.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">International Conference on Artificial Intelligence and
Statistics</span><span id="bib.bib18.5.3" class="ltx_text" style="font-size:90%;">, pages 4519–4529. PMLR, 2020.
</span>
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock"><span id="bib.bib19.1.1" class="ltx_text" style="font-size:90%;">
James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume
Desjardins, Andrei A Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka
Grabska-Barwinska, et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.2.1" class="ltx_text" style="font-size:90%;">Overcoming catastrophic forgetting in neural networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the national academy of sciences</span><span id="bib.bib19.4.2" class="ltx_text" style="font-size:90%;">,
114(13):3521–3526, 2017.
</span>
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock"><span id="bib.bib20.1.1" class="ltx_text" style="font-size:90%;">
Viraj Kulkarni, Milind Kulkarni, and Aniruddha Pant.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.2.1" class="ltx_text" style="font-size:90%;">Survey of personalization techniques for federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib20.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2020 Fourth World Conference on Smart Trends in Systems,
Security and Sustainability (WorldS4)</span><span id="bib.bib20.5.3" class="ltx_text" style="font-size:90%;">, pages 794–797. IEEE, 2020.
</span>
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock"><span id="bib.bib21.1.1" class="ltx_text" style="font-size:90%;">
Li Li, Yuxi Fan, Mike Tse, and Kuo-Yi Lin.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.2.1" class="ltx_text" style="font-size:90%;">A review of applications in federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Computers &amp; Industrial Engineering</span><span id="bib.bib21.4.2" class="ltx_text" style="font-size:90%;">, page 106854, 2020.
</span>
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock"><span id="bib.bib22.1.1" class="ltx_text" style="font-size:90%;">
Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and
Virginia Smith.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.2.1" class="ltx_text" style="font-size:90%;">Federated optimization in heterogeneous networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1812.06127</span><span id="bib.bib22.4.2" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock"><span id="bib.bib23.1.1" class="ltx_text" style="font-size:90%;">
Tian Li, Maziar Sanjabi, Ahmad Beirami, and Virginia Smith.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.2.1" class="ltx_text" style="font-size:90%;">Fair resource allocation in federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1905.10497</span><span id="bib.bib23.4.2" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock"><span id="bib.bib24.1.1" class="ltx_text" style="font-size:90%;">
Xiang Li, Kaixuan Huang, Wenhao Yang, Shusen Wang, and Zhihua Zhang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.2.1" class="ltx_text" style="font-size:90%;">On the convergence of fedavg on non-iid data.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1907.02189</span><span id="bib.bib24.4.2" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock"><span id="bib.bib25.1.1" class="ltx_text" style="font-size:90%;">
Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and Piotr Dollár.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.2.1" class="ltx_text" style="font-size:90%;">Focal loss for dense object detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib25.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE international conference on computer
vision</span><span id="bib.bib25.5.3" class="ltx_text" style="font-size:90%;">, pages 2980–2988, 2017.
</span>
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock"><span id="bib.bib26.1.1" class="ltx_text" style="font-size:90%;">
Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y
Arcas.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.2.1" class="ltx_text" style="font-size:90%;">Communication-efficient learning of deep networks from decentralized
data.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib26.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Artificial Intelligence and Statistics</span><span id="bib.bib26.5.3" class="ltx_text" style="font-size:90%;">, pages 1273–1282.
PMLR, 2017.
</span>
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock"><span id="bib.bib27.1.1" class="ltx_text" style="font-size:90%;">
Mehryar Mohri, Gary Sivek, and Ananda Theertha Suresh.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.2.1" class="ltx_text" style="font-size:90%;">Agnostic federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib27.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">International Conference on Machine Learning</span><span id="bib.bib27.5.3" class="ltx_text" style="font-size:90%;">, pages
4615–4625. PMLR, 2019.
</span>
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock"><span id="bib.bib28.1.1" class="ltx_text" style="font-size:90%;">
Jose G Moreno-Torres, Troy Raeder, Rocío Alaiz-Rodríguez, Nitesh V
Chawla, and Francisco Herrera.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.2.1" class="ltx_text" style="font-size:90%;">A unifying view on dataset shift in classification.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Pattern recognition</span><span id="bib.bib28.4.2" class="ltx_text" style="font-size:90%;">, 45(1):521–530, 2012.
</span>
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock"><span id="bib.bib29.1.1" class="ltx_text" style="font-size:90%;">
Adrian Nilsson, Simon Smith, Gregor Ulm, Emil Gustavsson, and Mats Jirstrand.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.2.1" class="ltx_text" style="font-size:90%;">A performance evaluation of federated learning algorithms.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib29.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the Second Workshop on Distributed
Infrastructures for Deep Learning</span><span id="bib.bib29.5.3" class="ltx_text" style="font-size:90%;">, pages 1–8, 2018.
</span>
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock"><span id="bib.bib30.1.1" class="ltx_text" style="font-size:90%;">
Lutz Prechelt.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.2.1" class="ltx_text" style="font-size:90%;">Early stopping-but when?
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib30.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Neural Networks: Tricks of the trade</span><span id="bib.bib30.5.3" class="ltx_text" style="font-size:90%;">, pages 55–69.
Springer, 1998.
</span>
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock"><span id="bib.bib31.1.1" class="ltx_text" style="font-size:90%;">
Swaroop Ramaswamy, Rajiv Mathews, Kanishka Rao, and Françoise Beaufays.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.2.1" class="ltx_text" style="font-size:90%;">Federated learning for emoji prediction in a mobile keyboard.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1906.04329</span><span id="bib.bib31.4.2" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock"><span id="bib.bib32.1.1" class="ltx_text" style="font-size:90%;">
Dipankar Sarkar, Ankur Narang, and Sumit Rai.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.2.1" class="ltx_text" style="font-size:90%;">Fed-focal loss for imbalanced data classification in federated
learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2011.06283</span><span id="bib.bib32.4.2" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock"><span id="bib.bib33.1.1" class="ltx_text" style="font-size:90%;">
Felix Sattler, Simon Wiedemann, Klaus-Robert Müller, and Wojciech Samek.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.2.1" class="ltx_text" style="font-size:90%;">Robust and communication-efficient federated learning from non-iid
data.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE transactions on neural networks and learning systems</span><span id="bib.bib33.4.2" class="ltx_text" style="font-size:90%;">,
31(9):3400–3413, 2019.
</span>
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock"><span id="bib.bib34.1.1" class="ltx_text" style="font-size:90%;">
Neta Shoham, Tomer Avidor, Aviv Keren, Nadav Israel, Daniel Benditkis, Liron
Mor-Yosef, and Itai Zeitak.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.2.1" class="ltx_text" style="font-size:90%;">Overcoming forgetting in federated learning on non-iid data.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1910.07796</span><span id="bib.bib34.4.2" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock"><span id="bib.bib35.1.1" class="ltx_text" style="font-size:90%;">
Samuel L Smith, Pieter-Jan Kindermans, Chris Ying, and Quoc V Le.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.2.1" class="ltx_text" style="font-size:90%;">Don’t decay the learning rate, increase the batch size.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1711.00489</span><span id="bib.bib35.4.2" class="ltx_text" style="font-size:90%;">, 2017.
</span>
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock"><span id="bib.bib36.1.1" class="ltx_text" style="font-size:90%;">
Virginia Smith, Chao-Kai Chiang, Maziar Sanjabi, and Ameet Talwalkar.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.2.1" class="ltx_text" style="font-size:90%;">Federated multi-task learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1705.10467</span><span id="bib.bib36.4.2" class="ltx_text" style="font-size:90%;">, 2017.
</span>
</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock"><span id="bib.bib37.1.1" class="ltx_text" style="font-size:90%;">
Ilya Sutskever, James Martens, George Dahl, and Geoffrey Hinton.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.2.1" class="ltx_text" style="font-size:90%;">On the importance of initialization and momentum in deep learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib37.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">International conference on machine learning</span><span id="bib.bib37.5.3" class="ltx_text" style="font-size:90%;">, pages
1139–1147. PMLR, 2013.
</span>
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock"><span id="bib.bib38.1.1" class="ltx_text" style="font-size:90%;">
Kangkang Wang, Rajiv Mathews, Chloé Kiddon, Hubert Eichner, Françoise
Beaufays, and Daniel Ramage.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.2.1" class="ltx_text" style="font-size:90%;">Federated evaluation of on-device personalization.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1910.10252</span><span id="bib.bib38.4.2" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock"><span id="bib.bib39.1.1" class="ltx_text" style="font-size:90%;">
Lixu Wang, Shichao Xu, Xiao Wang, and Qi Zhu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.2.1" class="ltx_text" style="font-size:90%;">Towards class imbalance in federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2008.06217</span><span id="bib.bib39.4.2" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock"><span id="bib.bib40.1.1" class="ltx_text" style="font-size:90%;">
Miao Yang, Akitanoshou Wong, Hongbin Zhu, Haifeng Wang, and Hua Qian.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.2.1" class="ltx_text" style="font-size:90%;">Federated learning with class imbalance reduction.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2011.11266</span><span id="bib.bib40.4.2" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock"><span id="bib.bib41.1.1" class="ltx_text" style="font-size:90%;">
Timothy Yang, Galen Andrew, Hubert Eichner, Haicheng Sun, Wei Li, Nicholas
Kong, Daniel Ramage, and Françoise Beaufays.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.2.1" class="ltx_text" style="font-size:90%;">Applied federated learning: Improving google keyboard query
suggestions.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1812.02903</span><span id="bib.bib41.4.2" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock"><span id="bib.bib42.1.1" class="ltx_text" style="font-size:90%;">
Muhammad Bilal Zafar, Isabel Valera, Manuel Gomez Rodriguez, and Krishna P
Gummadi.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.2.1" class="ltx_text" style="font-size:90%;">Fairness beyond disparate treatment &amp; disparate impact: Learning
classification without disparate mistreatment.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib42.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the 26th international conference on world
wide web</span><span id="bib.bib42.5.3" class="ltx_text" style="font-size:90%;">, pages 1171–1180, 2017.
</span>
</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock"><span id="bib.bib43.1.1" class="ltx_text" style="font-size:90%;">
Edvin Listo Zec, Olof Mogren, John Martinsson, Leon René Sütfeld, and
Daniel Gillblad.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.2.1" class="ltx_text" style="font-size:90%;">Federated learning using a mixture of experts.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2010.02056</span><span id="bib.bib43.4.2" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock"><span id="bib.bib44.1.1" class="ltx_text" style="font-size:90%;">
Yue Zhao, Meng Li, Liangzhen Lai, Naveen Suda, Damon Civin, and Vikas Chandra.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib44.2.1" class="ltx_text" style="font-size:90%;">Federated learning with non-iid data.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib44.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1806.00582</span><span id="bib.bib44.4.2" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2103.11224" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2103.11226" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2103.11226">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2103.11226" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2103.11227" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sat Mar 16 20:02:48 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
