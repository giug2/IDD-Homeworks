<article class="ltx_document">
 <h1 class="ltx_title ltx_title_document">
  PPTC-R benchmark: Towards Evaluating the Robustness of Large Language Models for PowerPoint Task Completion
 </h1>
 <div class="ltx_authors">
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Zekai Zhang
    <sup class="ltx_sup" id="id8.8.id1">
     <span class="ltx_text ltx_font_italic" id="id8.8.id1.1">
      1
     </span>
    </sup>
    <span class="ltx_note ltx_role_footnote" id="footnotex1">
     <sup class="ltx_note_mark">
      1
     </sup>
     <span class="ltx_note_outer">
      <span class="ltx_note_content">
       <sup class="ltx_note_mark">
        1
       </sup>
       <span class="ltx_tag ltx_tag_note">
        1
       </span>
       Equal contribution
      </span>
     </span>
    </span>
    ,  Yiduo Guo
    <sup class="ltx_sup" id="id9.9.id2">
     <span class="ltx_text ltx_font_italic" id="id9.9.id2.1">
      1
     </span>
    </sup>
    <span class="ltx_note ltx_role_footnote" id="footnotex2">
     <sup class="ltx_note_mark">
      1
     </sup>
     <span class="ltx_note_outer">
      <span class="ltx_note_content">
       <sup class="ltx_note_mark">
        1
       </sup>
       <span class="ltx_tag ltx_tag_note">
        1
       </span>
       Equal contribution
      </span>
     </span>
    </span>
    ,  Yaobo Liang
    <sup class="ltx_sup" id="id10.10.id3">
     <span class="ltx_text ltx_font_italic" id="id10.10.id3.1">
      2
     </span>
    </sup>
    ,  Dongyan Zhao
    <sup class="ltx_sup" id="id11.11.id4">
     <span class="ltx_text ltx_font_italic" id="id11.11.id4.1">
      1
     </span>
    </sup>
    ,  Nan Duan
    <sup class="ltx_sup" id="id12.12.id5">
     <span class="ltx_text ltx_font_italic" id="id12.12.id5.1">
      2
     </span>
    </sup>
    <br class="ltx_break"/>
    <sup class="ltx_sup" id="id13.13.id6">
     1
    </sup>
    Peking University
    <br class="ltx_break"/>
    <sup class="ltx_sup" id="id14.14.id7">
     2
    </sup>
    Microsoft Research Asia
    <br class="ltx_break"/>
    <span class="ltx_text ltx_font_typewriter" id="id15.15.id8">
     {justinzzk,yiduo}@stu.pku.edu.cn,{yaobo.liang,nanduan}@microsoft.com
     <br class="ltx_break"/>
     zhaody@pku.edu.cn
     <br class="ltx_break"/>
    </span>
   </span>
  </span>
 </div>
 <div class="ltx_abstract">
  <h6 class="ltx_title ltx_title_abstract">
   Abstract
  </h6>
  <p class="ltx_p" id="id16.id1">
   The growing dependence on Large Language Models (LLMs) for finishing user instructions necessitates a comprehensive understanding of their robustness to complex task completion in real-world situations. To address this critical need, we propose the PowerPoint Task Completion-Robustness (PPTC-R) benchmark to measure LLMs’ robustness to the user PPT task instruction and software version (Powerpoint). Specifically, we construct adversarial user instructions by attacking user instructions at sentence, semantic, and multi-language levels.
To assess the robustness of Language Models to software versions, we vary the number of provided APIs to simulate both the newest version and earlier version settings. Subsequently, we test 3 closed-source and 4 open-source LLMs using a benchmark that incorporates these robustness settings, aiming to evaluate how deviations impact LLMs’ API calls for task completion. We find that GPT-4 exhibits the highest performance and strong robustness in our benchmark, particularly in the version update and the multilingual settings. However, we find that all LLMs lose their robustness when confronted with multiple challenges (e.g., multi-turn) simultaneously, leading to significant performance drops. We further analyze the robustness behavior and error reasons of LLMs in our benchmark, which provide valuable insights for researchers to understand the LLM’s robustness in task completion and develop more robust LLMs and agents. We release the code and data at
   <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/ZekaiGalaxy/PPTCR" target="_blank" title="">
    https://github.com/ZekaiGalaxy/PPTCR
   </a>
   .
  </p>
 </div>
 <div class="ltx_para ltx_noindent" id="p1">
  <div class="ltx_block ltx_align_bottom" id="p1.7">
   <p class="ltx_p" id="p1.7.8">
    <span class="ltx_text ltx_font_bold" id="p1.7.8.1">
     PPTC-R benchmark: Towards Evaluating the Robustness of Large Language Models for PowerPoint Task Completion
    </span>
   </p>
   <br class="ltx_break ltx_centering"/>
   <p class="ltx_p ltx_align_center" id="p1.7.7" style="width:433.6pt;">
    <span class="ltx_text ltx_inline-block" id="p1.7.7.7" style="width:0.0pt;">
     <span class="ltx_tabular ltx_align_top" id="p1.7.7.7.7">
      <span class="ltx_tbody">
       <span class="ltx_tr" id="p1.5.5.5.5.5">
        <span class="ltx_td ltx_align_center" id="p1.5.5.5.5.5.5">
         <span class="ltx_text ltx_font_bold" id="p1.5.5.5.5.5.5.5">
          Zekai Zhang
          <sup class="ltx_sup" id="p1.5.5.5.5.5.5.5.1">
           <span class="ltx_text ltx_font_medium ltx_font_italic" id="p1.5.5.5.5.5.5.5.1.1">
            1
           </span>
          </sup>
          <span class="ltx_note ltx_role_footnote" id="footnotex3">
           <sup class="ltx_note_mark">
            1
           </sup>
           <span class="ltx_note_outer">
            <span class="ltx_note_content">
             <sup class="ltx_note_mark">
              1
             </sup>
             <span class="ltx_tag ltx_tag_note">
              <span class="ltx_text ltx_font_medium" id="footnotex3.1.1.1">
               1
              </span>
             </span>
             Equal contribution
            </span>
           </span>
          </span>
          ,  Yiduo Guo
          <sup class="ltx_sup" id="p1.5.5.5.5.5.5.5.2">
           <span class="ltx_text ltx_font_medium ltx_font_italic" id="p1.5.5.5.5.5.5.5.2.1">
            1
           </span>
          </sup>
          <span class="ltx_note ltx_role_footnote" id="footnotex4">
           <sup class="ltx_note_mark">
            1
           </sup>
           <span class="ltx_note_outer">
            <span class="ltx_note_content">
             <sup class="ltx_note_mark">
              1
             </sup>
             <span class="ltx_tag ltx_tag_note">
              <span class="ltx_text ltx_font_medium" id="footnotex4.1.1.1">
               1
              </span>
             </span>
             Equal contribution
            </span>
           </span>
          </span>
          ,  Yaobo Liang
          <sup class="ltx_sup" id="p1.5.5.5.5.5.5.5.3">
           <span class="ltx_text ltx_font_medium ltx_font_italic" id="p1.5.5.5.5.5.5.5.3.1">
            2
           </span>
          </sup>
          ,  Dongyan Zhao
          <sup class="ltx_sup" id="p1.5.5.5.5.5.5.5.4">
           <span class="ltx_text ltx_font_medium ltx_font_italic" id="p1.5.5.5.5.5.5.5.4.1">
            1
           </span>
          </sup>
          ,  Nan Duan
          <sup class="ltx_sup" id="p1.5.5.5.5.5.5.5.5">
           <span class="ltx_text ltx_font_medium ltx_font_italic" id="p1.5.5.5.5.5.5.5.5.1">
            2
           </span>
          </sup>
         </span>
        </span>
       </span>
       <span class="ltx_tr" id="p1.6.6.6.6.6">
        <span class="ltx_td ltx_align_center" id="p1.6.6.6.6.6.1">
         <sup class="ltx_sup" id="p1.6.6.6.6.6.1.1">
          1
         </sup>
         Peking University
        </span>
       </span>
       <span class="ltx_tr" id="p1.7.7.7.7.7">
        <span class="ltx_td ltx_align_center" id="p1.7.7.7.7.7.1">
         <sup class="ltx_sup" id="p1.7.7.7.7.7.1.1">
          2
         </sup>
         Microsoft Research Asia
        </span>
       </span>
       <span class="ltx_tr" id="p1.7.7.7.7.8.1">
        <span class="ltx_td ltx_align_center" id="p1.7.7.7.7.8.1.1">
         <span class="ltx_text ltx_font_typewriter" id="p1.7.7.7.7.8.1.1.1">
          {justinzzk,yiduo}@stu.pku.edu.cn,{yaobo.liang,nanduan}@microsoft.com
         </span>
        </span>
       </span>
       <span class="ltx_tr" id="p1.7.7.7.7.9.2">
        <span class="ltx_td ltx_align_center" id="p1.7.7.7.7.9.2.1">
         <span class="ltx_text ltx_font_typewriter" id="p1.7.7.7.7.9.2.1.1">
          zhaody@pku.edu.cn
         </span>
        </span>
       </span>
      </span>
     </span>
    </span>
   </p>
   <br class="ltx_break ltx_centering"/>
  </div>
 </div>
 <section class="ltx_section" id="S1">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    1
   </span>
   Introduction
  </h2>
  <figure class="ltx_figure" id="S1.F1">
   <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="278" id="S1.F1.g1" src="/html/2403.03788/assets/Radar.png" width="299"/>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     Figure 1:
    </span>
    We illustrate the turn-base multilingual results of closed-source LLMs.
   </figcaption>
  </figure>
  <figure class="ltx_figure" id="S1.F2">
   <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="311" id="S1.F2.g1" src="/html/2403.03788/assets/demonstrations.jpeg" width="598"/>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     Figure 2:
    </span>
    We illustrate two examples for constructing our robustness benchmark. The perturbations correctly distract the LLM from completing the user instruction (the left) and mislead the LLM into generating the wrong API sequence (the right), which underscores the importance of evaluating and analyzing LLMs’ task completion robustness.
   </figcaption>
  </figure>
  <div class="ltx_para" id="S1.p1">
   <p class="ltx_p" id="S1.p1.1">
    Large Language Models (e.g. GPT-4
    <cite class="ltx_cite ltx_citemacro_cite">
     OpenAI (
     <a class="ltx_ref" href="#bib.bib27" title="">
      2023
     </a>
     )
    </cite>
    ) show strong strong performance on various basic natural language tasks and human examinations
    <cite class="ltx_cite ltx_citemacro_cite">
     Qin et al. (
     <a class="ltx_ref" href="#bib.bib29" title="">
      2023a
     </a>
     ); Jiao et al. (
     <a class="ltx_ref" href="#bib.bib12" title="">
      2023
     </a>
     ); Zhong et al. (
     <a class="ltx_ref" href="#bib.bib46" title="">
      2023
     </a>
     ); Wang et al. (
     <a class="ltx_ref" href="#bib.bib40" title="">
      2023d
     </a>
     ); Liang et al. (
     <a class="ltx_ref" href="#bib.bib18" title="">
      2023
     </a>
     )
    </cite>
    , and arises the hope to help humans to complete tasks in complex environments, such as purchasing items in WebShop
    <cite class="ltx_cite ltx_citemacro_cite">
     Yao et al. (
     <a class="ltx_ref" href="#bib.bib44" title="">
      2022
     </a>
     )
    </cite>
    , creating and editing PPT slide in PPTC
    <cite class="ltx_cite ltx_citemacro_cite">
     Guo et al. (
     <a class="ltx_ref" href="#bib.bib9" title="">
      2023
     </a>
     )
    </cite>
    , and nagativing computer in MiniWob++
    <cite class="ltx_cite ltx_citemacro_cite">
     Liu et al. (
     <a class="ltx_ref" href="#bib.bib19" title="">
      2018
     </a>
     )
    </cite>
    . Also, recent works
    <cite class="ltx_cite ltx_citemacro_cite">
     Zhu et al. (
     <a class="ltx_ref" href="#bib.bib47" title="">
      2023
     </a>
     ); Liu et al. (
     <a class="ltx_ref" href="#bib.bib24" title="">
      2023d
     </a>
     ); Wang et al. (
     <a class="ltx_ref" href="#bib.bib39" title="">
      2023c
     </a>
     )
    </cite>
    such as PromptBench
    <cite class="ltx_cite ltx_citemacro_cite">
     Zhu et al. (
     <a class="ltx_ref" href="#bib.bib47" title="">
      2023
     </a>
     )
    </cite>
    study the LLM’s robustness to task prompts for basic natural language tasks. However, there remains an absence of a benchmark for evaluating the LLM’s robustness in complex task completion, which is a key factor for the LLM’s task completion performance in real-world user scenarios. To address this need, We introduce
    <span class="ltx_text ltx_font_bold" id="S1.p1.1.1">
     P
    </span>
    ower
    <span class="ltx_text ltx_font_bold" id="S1.p1.1.2">
     P
    </span>
    oint
    <span class="ltx_text ltx_font_bold" id="S1.p1.1.3">
     T
    </span>
    ask
    <span class="ltx_text ltx_font_bold" id="S1.p1.1.4">
     C
    </span>
    ompletion-
    <span class="ltx_text ltx_font_bold" id="S1.p1.1.5">
     R
    </span>
    obustness (PPTC-R), a benchmark for measuring and analyzing LLMs’ robustness to the user instruction and software version in PowerPoint task completion setting. Our benchmark has two distinct features: (1) Previous robustness evaluations are based on traditional natural language tasks, where the model only needs to generate options or text strings. In contrast, we focus on evaluating how adversarial perturbation influences LLMs’ API calls for complex PPT task completion. (2) Previous studies construct their benchmarks mainly by attacking the task prompt or input in text. We consider how the shift of the software version influences the LLM’s performance, which is a new perspective.
   </p>
  </div>
  <div class="ltx_para" id="S1.p2">
   <p class="ltx_p" id="S1.p2.1">
    To measure LLMs’ robustness to the user instruction, we need to construct the adversarial user instruction. We
consider instruction perturbations including 1) (language-level) translating the original English instructions into 14 non-English languages (See Figure
    <a class="ltx_ref" href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ PPTC-R benchmark: Towards Evaluating the Robustness of Large Language Models for PowerPoint Task Completion">
     <span class="ltx_text ltx_ref_tag">
      1
     </span>
    </a>
    ), 2) (sentence-level) adding GPT-4 generated chitchat sentences into the original instructions as noisy sentences, and 3) (semantic-level) prompting GPT-4 to express
original instructions with the same semantic meaning in 4 different ways (See examples in Figure
    <a class="ltx_ref" href="#S1.F2" title="Figure 2 ‣ 1 Introduction ‣ PPTC-R benchmark: Towards Evaluating the Robustness of Large Language Models for PowerPoint Task Completion">
     <span class="ltx_text ltx_ref_tag">
      2
     </span>
    </a>
    ). These perturbations commonly occur to normal users or developers in their daily use of PPT (with agent). Our LLM-based sentence and semantic perturbation approaches can quickly obtain lots of new high-quality adversarial data without being seen before. On the other hand, the software versions can affect the PPT task completion process by providing different numbers of functions (APIs) for the user. Thus we test the LLM’s robustness to the software version by adjusting the number of provided APIs: (1) introducing many new APIs into the existing API list to simulate the version update situation where new APIs may impact the LLM’s API selection and (2) removing many APIs in the existing API list to simulate the situation in which APIs in the current software version may not be capable of completely addressing some user instruction and the LLM needs to seek for assistance. We conduct these perturbations ( 3 for user instructions and 2 for APIs) on the original PPTC benchmark separately to construct our PPTC-R benchmarks (a total of 5 settings).
   </p>
  </div>
  <div class="ltx_para" id="S1.p3">
   <p class="ltx_p" id="S1.p3.1">
    We test 3 closed-source LLMs (e.g., GPT-4 and ChatGPT) and 4 representative open-source LLMs (e.g., LLaMa-2 and WizardLM) in our benchmarks. We find that GPT-4 achieves the highest performance and strong robustness in our 5 settings (see Sec.
    <a class="ltx_ref" href="#S4.SS3" title="4.3 Main results ‣ 4 Experiments ‣ PPTC-R benchmark: Towards Evaluating the Robustness of Large Language Models for PowerPoint Task Completion">
     <span class="ltx_text ltx_ref_tag">
      4.3
     </span>
    </a>
    ). For example, GPT-4 can maintain its high turn-based performance with the introduction of 97 new APIs. In contrast, other LLMs experience a larger performance drop (e.g., ChatGPT) or maintain their performance at a pretty low level (e.g., LLaMa-2). We also find a unique robustness degradation phenomenon for all LLMs: The LLMs’ robustness decreases obviously when we increase the difficulty of the same task or move to a more complex environment. We further analyze and find three main error reasons for LLMs: being distracted by chitchat (See the bottom of Figure
    <a class="ltx_ref" href="#S1.F2" title="Figure 2 ‣ 1 Introduction ‣ PPTC-R benchmark: Towards Evaluating the Robustness of Large Language Models for PowerPoint Task Completion">
     <span class="ltx_text ltx_ref_tag">
      2
     </span>
    </a>
    ), calling unavailable APIs, and misunderstanding instructions with new expressions (refer to Sec.
    <a class="ltx_ref" href="#S5.SS1" title="5.1 Error analysis for LLMs ‣ 5 Analysis ‣ PPTC-R benchmark: Towards Evaluating the Robustness of Large Language Models for PowerPoint Task Completion">
     <span class="ltx_text ltx_ref_tag">
      5.1
     </span>
    </a>
    ). We also investigate the LLM’s behavior with different numbers of new APIs (See Sec
    <a class="ltx_ref" href="#S5.SS3" title="5.3 How does the number of new APIs influence the LLM’s performance? ‣ 5 Analysis ‣ PPTC-R benchmark: Towards Evaluating the Robustness of Large Language Models for PowerPoint Task Completion">
     <span class="ltx_text ltx_ref_tag">
      5.3
     </span>
    </a>
    ).
   </p>
  </div>
  <div class="ltx_para" id="S1.p4">
   <p class="ltx_p" id="S1.p4.1">
    In summary, the contributions of our paper are:
   </p>
  </div>
  <div class="ltx_para" id="S1.p5">
   <p class="ltx_p" id="S1.p5.1">
    (1) We propose the PowerPoint Task Completion Robustness benchmark, which is the first one to measure LLM’s task completion robustness for calling APIs to complete user instructions. Furthermore, our LLM-based perturbation approaches can be easily deployed to generate adversarial data for future datasets.
   </p>
  </div>
  <div class="ltx_para" id="S1.p6">
   <p class="ltx_p" id="S1.p6.1">
    (2) We test 7 LLMs in our benchmark and find that GPT-4 achieves the best performance with strong robustness. However, all LLMs’ robustness degrades when we increase the task difficulty, showing the challenge of our benchmark.
   </p>
  </div>
  <div class="ltx_para" id="S1.p7">
   <p class="ltx_p" id="S1.p7.1">
    (3) We further analyze the error reasons and robustness behavior of LLMs in our benchmark, which provides valuable insights for researchers to understand LLMs’ robustness in task completion settings and to design more robust agent.
   </p>
  </div>
 </section>
 <section class="ltx_section" id="S2">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    2
   </span>
   Related Works
  </h2>
  <div class="ltx_para" id="S2.p1">
   <p class="ltx_p" id="S2.p1.1">
    <span class="ltx_text ltx_font_bold" id="S2.p1.1.1">
     Large Language Models (LLMs)
    </span>
    such as GPT-4
    <cite class="ltx_cite ltx_citemacro_cite">
     Bubeck et al. (
     <a class="ltx_ref" href="#bib.bib3" title="">
      2023
     </a>
     ); OpenAI (
     <a class="ltx_ref" href="#bib.bib27" title="">
      2023
     </a>
     )
    </cite>
    , and PaLM-2
    <cite class="ltx_cite ltx_citemacro_cite">
     Anil et al. (
     <a class="ltx_ref" href="#bib.bib1" title="">
      2023
     </a>
     )
    </cite>
    exhibit excellent performance for various traditional natural language tasks
    <cite class="ltx_cite ltx_citemacro_cite">
     Kim et al. (
     <a class="ltx_ref" href="#bib.bib15" title="">
      2023
     </a>
     ); Jiao et al. (
     <a class="ltx_ref" href="#bib.bib12" title="">
      2023
     </a>
     ); Zhong et al. (
     <a class="ltx_ref" href="#bib.bib46" title="">
      2023
     </a>
     ); Wang et al. (
     <a class="ltx_ref" href="#bib.bib40" title="">
      2023d
     </a>
     )
    </cite>
    and can do complex logic reasoning
    <cite class="ltx_cite ltx_citemacro_cite">
     Feng et al. (
     <a class="ltx_ref" href="#bib.bib7" title="">
      2023
     </a>
     ); Liu et al. (
     <a class="ltx_ref" href="#bib.bib20" title="">
      2023a
     </a>
     )
    </cite>
    , pass human-level examination
    <cite class="ltx_cite ltx_citemacro_cite">
     Zhong et al. (
     <a class="ltx_ref" href="#bib.bib46" title="">
      2023
     </a>
     ); Gilson et al. (
     <a class="ltx_ref" href="#bib.bib8" title="">
      2023
     </a>
     ); Katz et al. (
     <a class="ltx_ref" href="#bib.bib14" title="">
      2023
     </a>
     )
    </cite>
    , and write code
    <cite class="ltx_cite ltx_citemacro_cite">
     Li et al. (
     <a class="ltx_ref" href="#bib.bib17" title="">
      2022
     </a>
     ); Liu et al. (
     <a class="ltx_ref" href="#bib.bib21" title="">
      2023b
     </a>
     )
    </cite>
    after instruction fine-tuning. Open-source LLMs like LLaMa-2
    <cite class="ltx_cite ltx_citemacro_cite">
     Touvron et al. (
     <a class="ltx_ref" href="#bib.bib35" title="">
      2023
     </a>
     )
    </cite>
    , Mistral 7b
    <cite class="ltx_cite ltx_citemacro_cite">
     Jiang et al. (
     <a class="ltx_ref" href="#bib.bib11" title="">
      2023
     </a>
     )
    </cite>
    , and Baichuan-2
    <cite class="ltx_cite ltx_citemacro_cite">
     Yang et al. (
     <a class="ltx_ref" href="#bib.bib43" title="">
      2023
     </a>
     )
    </cite>
    and their fine-tuned versions also show promising performance on public benchmarks. Recent survey
    <cite class="ltx_cite ltx_citemacro_cite">
     Chen et al. (
     <a class="ltx_ref" href="#bib.bib4" title="">
      2023
     </a>
     )
    </cite>
    finds that they usually still have a performance gap when compared to their closed-source counterparts like GPT-4.
   </p>
  </div>
  <div class="ltx_para" id="S2.p2">
   <p class="ltx_p" id="S2.p2.1">
    <span class="ltx_text ltx_font_bold" id="S2.p2.1.1">
     Task completion benchmarks for LLM-based Agents
    </span>
    . LLMs and multi-modal models (e.g., GPT-4Vision) raise the hope of designing LLM-based agents to help humans finish complex tasks in complex environments. To test agents,
Saycan
    <cite class="ltx_cite ltx_citemacro_cite">
     Brohan et al. (
     <a class="ltx_ref" href="#bib.bib2" title="">
      2023
     </a>
     )
    </cite>
    , Behavior
    <cite class="ltx_cite ltx_citemacro_cite">
     Srivastava et al. (
     <a class="ltx_ref" href="#bib.bib33" title="">
      2022
     </a>
     ); Li et al. (
     <a class="ltx_ref" href="#bib.bib16" title="">
      2023
     </a>
     )
    </cite>
    and VirtualHome
    <cite class="ltx_cite ltx_citemacro_cite">
     Puig et al. (
     <a class="ltx_ref" href="#bib.bib28" title="">
      2018
     </a>
     )
    </cite>
    benchmarks ask the agent to negative a series of physical actions to finish the user instruction in simulated physical environments. WebShop
    <cite class="ltx_cite ltx_citemacro_cite">
     Yao et al. (
     <a class="ltx_ref" href="#bib.bib44" title="">
      2022
     </a>
     )
    </cite>
    , AgentBench
    <cite class="ltx_cite ltx_citemacro_cite">
     Liu et al. (
     <a class="ltx_ref" href="#bib.bib22" title="">
      2023c
     </a>
     )
    </cite>
    and Android in the wild
    <cite class="ltx_cite ltx_citemacro_cite">
     Rawles et al. (
     <a class="ltx_ref" href="#bib.bib31" title="">
      2023
     </a>
     )
    </cite>
    require the agent conduct actions (e.g., click and search) in website environment to meet the user requirement. ToolBench
    <cite class="ltx_cite ltx_citemacro_cite">
     Xu et al. (
     <a class="ltx_ref" href="#bib.bib42" title="">
      2023b
     </a>
     ); Qin et al. (
     <a class="ltx_ref" href="#bib.bib30" title="">
      2023b
     </a>
     )
    </cite>
    needs the agent to select proper APIs from thousands of candidate APIs.
   </p>
  </div>
  <div class="ltx_para" id="S2.p3">
   <p class="ltx_p" id="S2.p3.1">
    <span class="ltx_text ltx_font_bold" id="S2.p3.1.1">
     Robustness in natural language processing
    </span>
    Traditional natural language robustness evaluation focuses on constructing the adversarial dataset of basic natural language tasks, such as the adversarial natural inference task
    <cite class="ltx_cite ltx_citemacro_cite">
     Nie et al. (
     <a class="ltx_ref" href="#bib.bib26" title="">
      2019
     </a>
     )
    </cite>
    via human attacks, adversarial BLUE tasks
    <cite class="ltx_cite ltx_citemacro_cite">
     Wang et al. (
     <a class="ltx_ref" href="#bib.bib37" title="">
      2021
     </a>
     )
    </cite>
    via word-level, sentence-level, and human attacks, and adversarial dialogue tasks
    <cite class="ltx_cite ltx_citemacro_cite">
     Yu and Rieser (
     <a class="ltx_ref" href="#bib.bib45" title="">
      2023
     </a>
     )
    </cite>
    via question and dialogue history Attack. Then they analyze models’ (e.g., RoBERT
    <cite class="ltx_cite ltx_citemacro_cite">
     Liu et al. (
     <a class="ltx_ref" href="#bib.bib23" title="">
      2019
     </a>
     )
    </cite>
    ) behavior on these datasets. Recent robustness evaluations for LLMs try to measure their robustness to LLM’s version
    <cite class="ltx_cite ltx_citemacro_cite">
     Liu et al. (
     <a class="ltx_ref" href="#bib.bib24" title="">
      2023d
     </a>
     )
    </cite>
    , search engine version
    <cite class="ltx_cite ltx_citemacro_cite">
     Kasai et al. (
     <a class="ltx_ref" href="#bib.bib13" title="">
      2024
     </a>
     )
    </cite>
    , basic task’s prompt
    <cite class="ltx_cite ltx_citemacro_cite">
     Zhu et al. (
     <a class="ltx_ref" href="#bib.bib47" title="">
      2023
     </a>
     ); Sun et al. (
     <a class="ltx_ref" href="#bib.bib34" title="">
      2023
     </a>
     ); Hu et al. (
     <a class="ltx_ref" href="#bib.bib10" title="">
      2024
     </a>
     )
    </cite>
    and specific adversarial samples
    <cite class="ltx_cite ltx_citemacro_cite">
     Wang et al. (
     <a class="ltx_ref" href="#bib.bib39" title="">
      2023c
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib36" title="">
      a
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib38" title="">
      b
     </a>
     )
    </cite>
    .
   </p>
  </div>
 </section>
 <section class="ltx_section" id="S3">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    3
   </span>
   PPTC-R Benchmark
  </h2>
  <div class="ltx_para" id="S3.p1">
   <p class="ltx_p" id="S3.p1.1">
    In this section, we introduce our PowerPoint Task Completion-Robustness (PPTC-R) benchmark, including its dataset components, design principles, and the collection and validation process.
   </p>
  </div>
  <section class="ltx_subsection" id="S3.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     3.1
    </span>
    Introduction of the PowerPoint Task Completion benchmark
   </h3>
   <div class="ltx_para" id="S3.SS1.p1">
    <p class="ltx_p" id="S3.SS1.p1.1">
     We construct our robustness benchmark based on the open-source Powerpoint Task Completion benchmark and use its dataset, PPT tasks, and evaluation system. Here is a brief introduction to it.
    </p>
   </div>
   <div class="ltx_para" id="S3.SS1.p2">
    <p class="ltx_p" id="S3.SS1.p2.1">
     <span class="ltx_text ltx_font_bold" id="S3.SS1.p2.1.1">
      Dataset
     </span>
     : PPTC simulates a multi-turn dialogue between the user and the LLM, comprising 279 multi-turn sessions. Each turn within a session has a user instruction, a feasible API sequence for the instruction, and the labeled PPT file representing the correct result. To help the LLM finish the PPT task, it also provides an API reference file that contains all feasible APIs along with their description for reference. Furthermore, there’s a PPT reader function that transforms the PPT file into a text-format PPT file content, as well as an API executor that executes the LLM’s generated API sequence to produce the PPT prediction file.
    </p>
   </div>
   <div class="ltx_para" id="S3.SS1.p3">
    <p class="ltx_p" id="S3.SS1.p3.1">
     <span class="ltx_text ltx_font_bold" id="S3.SS1.p3.1.1">
      PPT Task description
     </span>
     PPTC considers both creating new slides and editing existing PPT template tasks. Each task has its own set of sessions. To finish one turn’s instruction in a session, we follow PPTC and prompt the LLM with the current instruction, previous instructions (dialogue history), the PPT file content, and the reference API file to generate an API sequence as the solution. Then the executor executes the API sequence to produce the prediction file.
    </p>
   </div>
   <div class="ltx_para" id="S3.SS1.p4">
    <p class="ltx_p" id="S3.SS1.p4.1">
     <span class="ltx_text ltx_font_bold" id="S3.SS1.p4.1.1">
      Evaluation system
     </span>
     We use the PPTX-evaluation system within PPTC to evaluate the correctness of the LLM prediction file. The system assesses if the objects and their position relations in the prediction file match those in the label PPT file.
    </p>
   </div>
   <figure class="ltx_figure" id="S3.F3">
    <svg class="ltx_picture ltx_centering" height="193.66" id="S3.F3.pic1" overflow="visible" version="1.1" width="600">
     <g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,193.66) matrix(1 0 0 -1 0 0)">
      <g fill="#008C73" fill-opacity="1.0">
       <path d="M 0 5.91 L 0 143.42 C 0 146.68 2.64 149.33 5.91 149.33 L 594.09 149.33 C 597.36 149.33 600 146.68 600 143.42 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none">
       </path>
      </g>
      <g fill="#FFFFFF" fill-opacity="1.0">
       <path d="M 1.97 5.91 L 1.97 125.22 L 598.03 125.22 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none">
       </path>
      </g>
      <g color="#008C73" fill="#008C73" stroke="#008C73" stroke-dasharray="2.84528pt,2.84528pt" stroke-dashoffset="1.42264pt" stroke-opacity="1.0">
       <path d="M 300 125.22 L 300 1.97" style="fill:none">
       </path>
      </g>
      <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 131.12)">
       <foreignobject color="#000000" height="12.3" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">
        <span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="S3.F3.pic1.2.2.2.1.1" style="width:402.3pt;">
         <span class="ltx_p" id="S3.F3.pic1.2.2.2.1.1.1">
          <span class="ltx_text ltx_font_bold" id="S3.F3.pic1.2.2.2.1.1.1.1">
           Sentence-level perturbation         Semantic-level perturbation
          </span>
         </span>
        </span>
       </foreignobject>
      </g>
      <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 103.72)">
       <foreignobject color="#000000" height="99.63" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">
        <span class="ltx_inline-logical-block ltx_minipage ltx_align_top" id="S3.F3.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1" style="width:402.3pt;">
         <span class="ltx_para ltx_noindent" id="S3.F3.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1">
          <span class="ltx_p" id="S3.F3.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1">
           <span class="ltx_text" id="S3.F3.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.1">
            <span class="ltx_inline-block ltx_minipage ltx_align_top" id="S3.F3.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.1.1" style="width:186.9pt;">
             <span class="ltx_p" id="S3.F3.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.1.1.1">
              <span class="ltx_text ltx_font_bold" id="S3.F3.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.1.1.1.1">
               Prompt for generating irrelevant chitchat sentences:
               <br class="ltx_break"/>
              </span>
              Add 1
              <math alttext="\sim" class="ltx_Math" display="inline" id="S3.F3.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.1.1.1.m1.1">
               <semantics id="S3.F3.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.1.1.1.m1.1a">
                <mo id="S3.F3.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.1.1.1.m1.1.1" xref="S3.F3.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.1.1.1.m1.1.1.cmml">
                 ∼
                </mo>
                <annotation-xml encoding="MathML-Content" id="S3.F3.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.1.1.1.m1.1b">
                 <csymbol cd="latexml" id="S3.F3.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.1.1.1.m1.1.1.cmml" xref="S3.F3.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.1.1.1.m1.1.1">
                  similar-to
                 </csymbol>
                </annotation-xml>
                <annotation encoding="application/x-tex" id="S3.F3.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.1.1.1.m1.1c">
                 \sim
                </annotation>
               </semantics>
              </math>
              3 irrelevant chitchat non-instruction sentences into the following instruction. Don’t add a new question. Instruction:&lt;original instruction&gt;.
             </span>
            </span>
           </span>
           <span class="ltx_text" id="S3.F3.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.2">
            <span class="ltx_inline-block ltx_minipage ltx_align_top" id="S3.F3.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.2.1" style="width:186.9pt;">
             <span class="ltx_p" id="S3.F3.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.2.1.1">
              <span class="ltx_text ltx_font_bold" id="S3.F3.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.2.1.1.1">
               Prompt for paraphrasing instructions:
              </span>
             </span>
             <span class="ltx_p" id="S3.F3.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.2.1.2">
              Rephrase the following instruction into &lt;number&gt; different ways: &lt;original instruction&gt;.
             </span>
            </span>
           </span>
          </span>
         </span>
        </span>
       </foreignobject>
      </g>
     </g>
    </svg>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      Figure 3:
     </span>
     The prompts we used to create the sentence and semantic level perturbations. ’&lt;number&gt;’ is the number of paraphrased Instructions.
    </figcaption>
   </figure>
  </section>
  <section class="ltx_subsection" id="S3.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     3.2
    </span>
    Design principles
   </h3>
   <div class="ltx_para" id="S3.SS2.p1">
    <p class="ltx_p" id="S3.SS2.p1.1">
     The construction of adversarial user instructions aims to simulate possible
perturbations that naturally occur in real task-completion situations. Thus we follow three principles to construct our robustness benchmark: (1)
     <span class="ltx_text ltx_font_bold" id="S3.SS2.p1.1.1">
      Realistic
     </span>
     : We only consider the common and daily
perturbations in the real world. For example, testing LLMs in reversed user instructions may be interesting, but this situation is impossible. So we do not consider it. (2)
     <span class="ltx_text ltx_font_bold" id="S3.SS2.p1.1.2">
      Preserve semantic integrity
     </span>
     . We don’t consider the perturbation that would change the original semantic of the instruction (e.g., deleting some sentences of the instruction randomly). We also should not add new instructions to PPTC (3)
     <span class="ltx_text ltx_font_bold" id="S3.SS2.p1.1.3">
      Diverse
     </span>
     We should try our best to create various perturbations, making the smart LLM can not solve them by finding some simple rules.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S3.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     3.3
    </span>
    Dataset collection and validation
   </h3>
   <div class="ltx_para" id="S3.SS3.p1">
    <p class="ltx_p" id="S3.SS3.p1.1">
     We construct our adversarial instructions for three levels: sentence, semantic, and language levels. We do not consider character and word level perturbations as
     <cite class="ltx_cite ltx_citemacro_cite">
      Zhu et al. (
      <a class="ltx_ref" href="#bib.bib47" title="">
       2023
      </a>
      )
     </cite>
     has shown the LLM’s strong robustness to these simple manipulations.
    </p>
    <ul class="ltx_itemize" id="S3.I1">
     <li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S3.I1.i1.p1">
       <p class="ltx_p" id="S3.I1.i1.p1.1">
        <span class="ltx_text ltx_font_bold" id="S3.I1.i1.p1.1.1">
         Sentence-level perturbation:
        </span>
        We add irrelevant chitchat sentences to the original user instruction in an attempt to confuse the LLM’s understanding. Specifically, for each instruction, we first prompt GPT-4 to generate 1
        <math alttext="\sim" class="ltx_Math" display="inline" id="S3.I1.i1.p1.1.m1.1">
         <semantics id="S3.I1.i1.p1.1.m1.1a">
          <mo id="S3.I1.i1.p1.1.m1.1.1" xref="S3.I1.i1.p1.1.m1.1.1.cmml">
           ∼
          </mo>
          <annotation-xml encoding="MathML-Content" id="S3.I1.i1.p1.1.m1.1b">
           <csymbol cd="latexml" id="S3.I1.i1.p1.1.m1.1.1.cmml" xref="S3.I1.i1.p1.1.m1.1.1">
            similar-to
           </csymbol>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S3.I1.i1.p1.1.m1.1c">
           \sim
          </annotation>
         </semantics>
        </math>
        3 chitchat sentences, such as ‘Hey there! I hope you’re having a great day. It’s pretty amazing how colors can make a presentation more engaging, right?’, then we incorporate these sentences around the original user instruction (see the left part of Figure
        <a class="ltx_ref" href="#S3.F3" title="Figure 3 ‣ 3.1 Introduction of the PowerPoint Task Completion benchmark ‣ 3 PPTC-R Benchmark ‣ PPTC-R benchmark: Towards Evaluating the Robustness of Large Language Models for PowerPoint Task Completion">
         <span class="ltx_text ltx_ref_tag">
          3
         </span>
        </a>
        ). The LLM needs to complete the user instruction while ignoring chitchat sentences. The semantics of these instructions are not changed. We further compare our perturbation approach with traditional sentence perturbation in Sec.
        <a class="ltx_ref" href="#S5.SS2" title="5.2 Chitchat sentences Vs ’True or False’ ‣ 5 Analysis ‣ PPTC-R benchmark: Towards Evaluating the Robustness of Large Language Models for PowerPoint Task Completion">
         <span class="ltx_text ltx_ref_tag">
          5.2
         </span>
        </a>
        .
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S3.I1.i2.p1">
       <p class="ltx_p" id="S3.I1.i2.p1.1">
        <span class="ltx_text ltx_font_bold" id="S3.I1.i2.p1.1.1">
         Semantic-level perturbation:
        </span>
        For each original instruction, we prompt GPT-4 to paraphrase it in four different expressions (see the right part of Figure
        <a class="ltx_ref" href="#S3.F3" title="Figure 3 ‣ 3.1 Introduction of the PowerPoint Task Completion benchmark ‣ 3 PPTC-R Benchmark ‣ PPTC-R benchmark: Towards Evaluating the Robustness of Large Language Models for PowerPoint Task Completion">
         <span class="ltx_text ltx_ref_tag">
          3
         </span>
        </a>
        ) and then we use the paraphrased instructions to test
the LLM’s performance. Finally, we report the average performance of the LLM in completing the instruction across four different expressions. We maintain the semantics of these instructions with various expressions.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S3.I1.i3" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S3.I1.i3.p1">
       <p class="ltx_p" id="S3.I1.i3.p1.2">
        <span class="ltx_text ltx_font_bold" id="S3.I1.i3.p1.2.1">
         Language-level perturbation:
        </span>
        To test the LLM’s ability to finish the user instruction written in non-English languages, we follow the dataset XNLI
        <cite class="ltx_cite ltx_citemacro_cite">
         Conneau et al. (
         <a class="ltx_ref" href="#bib.bib6" title="">
          2018
         </a>
         )
        </cite>
        and choose French, Spanish, German, Greek, Bulgarian, Russian, Turkish, Arabic, Vietnamese, Thai, Chinese, Hindi, Swahili and Urdu as the 14 non-English target languages. Then we use the Google Translation API to translate all user instructions from English into these target languages. We also translate the text input content in the feasible API sequence (e.g., translate Insert
        <math alttext="\_" class="ltx_Math" display="inline" id="S3.I1.i3.p1.1.m1.1">
         <semantics id="S3.I1.i3.p1.1.m1.1a">
          <mi id="S3.I1.i3.p1.1.m1.1.1" mathvariant="normal" xref="S3.I1.i3.p1.1.m1.1.1.cmml">
           _
          </mi>
          <annotation-xml encoding="MathML-Content" id="S3.I1.i3.p1.1.m1.1b">
           <ci id="S3.I1.i3.p1.1.m1.1.1.cmml" xref="S3.I1.i3.p1.1.m1.1.1">
            _
           </ci>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S3.I1.i3.p1.1.m1.1c">
           \_
          </annotation>
         </semantics>
        </math>
        text (’Hello!’) (English) to Insert
        <math alttext="\_" class="ltx_Math" display="inline" id="S3.I1.i3.p1.2.m2.1">
         <semantics id="S3.I1.i3.p1.2.m2.1a">
          <mi id="S3.I1.i3.p1.2.m2.1.1" mathvariant="normal" xref="S3.I1.i3.p1.2.m2.1.1.cmml">
           _
          </mi>
          <annotation-xml encoding="MathML-Content" id="S3.I1.i3.p1.2.m2.1b">
           <ci id="S3.I1.i3.p1.2.m2.1.1.cmml" xref="S3.I1.i3.p1.2.m2.1.1">
            _
           </ci>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="S3.I1.i3.p1.2.m2.1c">
           \_
          </annotation>
         </semantics>
        </math>
        text(’Hallo!’) (German)). Then we execute the translated feasible API sequence to obtain the label file in the target language setting. The translation operation maintains the original semantics of these instructions while expressing them in various languages.
       </p>
      </div>
     </li>
    </ul>
   </div>
   <div class="ltx_para" id="S3.SS3.p2">
    <p class="ltx_p" id="S3.SS3.p2.1">
     The change in software version usually influences the functions it can provide, and the functions can be simplified as the APIs. Thus we consider two API number perturbations to measure the LLM’s robustness to the software version:
    </p>
   </div>
   <div class="ltx_para" id="S3.SS3.p3">
    <ul class="ltx_itemize" id="S3.I2">
     <li class="ltx_item" id="S3.I2.i1" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S3.I2.i1.p1">
       <p class="ltx_p" id="S3.I2.i1.p1.1">
        <span class="ltx_text ltx_font_bold" id="S3.I2.i1.p1.1.1">
         API update perturbation:
        </span>
        To simulate the version update scenario, we
introduce 97 new APIs along with their descriptions
into the existing API file while keeping all previous APIs unchanged
        <span class="ltx_note ltx_role_footnote" id="footnote1">
         <sup class="ltx_note_mark">
          *
         </sup>
         <span class="ltx_note_outer">
          <span class="ltx_note_content">
           <sup class="ltx_note_mark">
            *
           </sup>
           <span class="ltx_tag ltx_tag_note">
            *
           </span>
           We put the new APIs in the supplementary
          </span>
         </span>
        </span>
        . These new APIs are selected from the Powerpoint keyboard and are not necessary for finishing original user instructions. But it may impact the LLM’s API selection. We set the
execution result of these new APIs in the API executor as
inserting a meaningless string ’@@@’. So calling them would lead to the wrong prediction.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="S3.I2.i2" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="S3.I2.i2.p1">
       <p class="ltx_p" id="S3.I2.i2.p1.1">
        <span class="ltx_text ltx_font_bold" id="S3.I2.i2.p1.1.1">
         API lack perturbation:
        </span>
        To simulate the earlier software environment where some advanced functions are not provided, we only provide 24 (original 49-&gt; now 24) basic PowerPoint APIs and the "Seek for assistance" API to the LLM. That means some parts of the user instruction may remain unfinished with the provided APIs. When the LLM finds that one part of the instruction can not be solved, it needs to call the "Seek for assistance" API to bypass this part. When it finds one part of the instruction can be solved, it needs to call the corresponding correct APIs. In nature, our objective is to measure LLMs’ ability to identify whether they can complete one part of the instruction and call the correct APIs for the given situation. We set the
execution result of the API "Seek for assistance" in the API executor as
empty. For the label file in this perturbation, we first filter
the APIs that are in the feasible API sequence but not in the 24 basic APIs. Then we execute the filtered API sequence to obtain the
label file. We list these APIs in Appendix
        <a class="ltx_ref" href="#A1" title="Appendix A Basic APIs in the API lack setting ‣ PPTC-R benchmark: Towards Evaluating the Robustness of Large Language Models for PowerPoint Task Completion">
         <span class="ltx_text ltx_ref_tag">
          A
         </span>
        </a>
        .
       </p>
      </div>
     </li>
    </ul>
   </div>
   <div class="ltx_para" id="S3.SS3.p4">
    <p class="ltx_p" id="S3.SS3.p4.1">
     We separately conduct these five perturbations on the original PPTC benchmark to construct five different robustness settings. Our robustness benchmark consists of these five robustness settings.
Note that our sentence and semantic perturbation approach can online generate rich adversarial data for robustness tests. Then the LLM can not improve the robustness performance cheatingly by pre-training on these adversarial data.
    </p>
   </div>
   <div class="ltx_para" id="S3.SS3.p5">
    <p class="ltx_p" id="S3.SS3.p5.1">
     <span class="ltx_text ltx_font_bold" id="S3.SS3.p5.1.1">
      Validation
     </span>
     To guarantee the quality of our robustness benchmark, three of the authors check if each adversarial instruction follows the design principles. If the paraphrased instruction or the translated instruction changes the original meaning and thus violates the second principle, we discard the instruction and regenerate or use Bing to translate the original instruction until the paraphrased/translated instruction maintains semantic integrity. If the chitchat sentence contains new PPT task instruction and thus violates the second principle, we discard it and re-generate chitchat sentences. Also, if the paraphrased instruction is too similar to other paraphrased instructions, we re-paraphrase it.
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S4">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    4
   </span>
   Experiments
  </h2>
  <figure class="ltx_table" id="S4.T1">
   <div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T1.1" style="width:458.1pt;height:113.1pt;vertical-align:-0.6pt;">
    <span class="ltx_transformed_inner" style="transform:translate(-137.4pt,33.8pt) scale(0.625,0.625) ;">
     <table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T1.1.1">
      <tbody class="ltx_tbody">
       <tr class="ltx_tr" id="S4.T1.1.1.1.1">
        <th class="ltx_td ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T1.1.1.1.1.1">
        </th>
        <td class="ltx_td ltx_align_center ltx_border_t" colspan="6" id="S4.T1.1.1.1.1.2">
         Creating new slides
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" colspan="6" id="S4.T1.1.1.1.1.3">
         Editing PPT template
        </td>
       </tr>
       <tr class="ltx_tr" id="S4.T1.1.1.2.2">
        <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T1.1.1.2.2.1">
         Models
        </th>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3" id="S4.T1.1.1.2.2.2">
         Turn-based
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3" id="S4.T1.1.1.2.2.3">
         Session-based
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3" id="S4.T1.1.1.2.2.4">
         Turn-based
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" colspan="3" id="S4.T1.1.1.2.2.5">
         Session-based
        </td>
       </tr>
       <tr class="ltx_tr" id="S4.T1.1.1.3.3">
        <th class="ltx_td ltx_th ltx_th_row ltx_border_r" id="S4.T1.1.1.3.3.1">
        </th>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.3.3.2">
         Original
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.3.3.3">
         Sentence
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.1.3.3.4">
         Semantic
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.3.3.5">
         Original
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.3.3.6">
         Sentence
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.1.3.3.7">
         Semantic
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.3.3.8">
         Original
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.3.3.9">
         Sentence
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.1.3.3.10">
         Semantic
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.3.3.11">
         Original
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.3.3.12">
         Sentence
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.3.3.13">
         Semantic
        </td>
       </tr>
       <tr class="ltx_tr" id="S4.T1.1.1.4.4">
        <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T1.1.1.4.4.1">
         Davinci-003
        </th>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.4.4.2">
         72.6
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.4.4.3">
         64.8 (-7.8)
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.1.4.4.4">
         67.4 (-5.2)
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.4.4.5">
         12.7
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.4.4.6">
         11.7 (-1.0)
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.1.4.4.7">
         9.5 (-3.2)
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.4.4.8">
         24.4
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.4.4.9">
         26.3 (+1.9)
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.1.4.4.10">
         25.8 (+1.4)
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.4.4.11">
         4.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.4.4.12">
         0.0 (-4.0)
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.4.4.13">
         0.5 (-3.5)
        </td>
       </tr>
       <tr class="ltx_tr" id="S4.T1.1.1.5.5">
        <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T1.1.1.5.5.1">
         ChatGPT
        </th>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.5.5.2">
         70.6
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.5.5.3">
         61.3 (-9.3)
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.1.5.5.4">
         65.0 (-5.6)
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.5.5.5">
         12.7
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.5.5.6">
         9.7 (-3.0)
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.1.5.5.7">
         8.7 (-4.0)
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.5.5.8">
         26.3
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.5.5.9">
         28.8 (+2.5)
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.1.5.5.10">
         27.0 (+0.3)
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.5.5.11">
         2.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.5.5.12">
         2.0 (+0.0)
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.5.5.13">
         2.0 (+0.0)
        </td>
       </tr>
       <tr class="ltx_tr" id="S4.T1.1.1.6.6">
        <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T1.1.1.6.6.1">
         GPT-4
        </th>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.6.6.2">
         75.1
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.6.6.3">
         72.3 (-2.8)
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.1.6.6.4">
         72.0 (-3.1)
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.6.6.5">
         22.7
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.6.6.6">
         12.3 (-10.4)
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.1.6.6.7">
         14.2 (-8.5)
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.6.6.8">
         38.1
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.6.6.9">
         36.9 (-1.2)
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.1.6.6.10">
         35.8 (-6.3)
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.6.6.11">
         6.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.6.6.12">
         4.0 (-2.0)
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.6.6.13">
         4.0 (-2.0)
        </td>
       </tr>
       <tr class="ltx_tr" id="S4.T1.1.1.7.7">
        <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T1.1.1.7.7.1">
         LLaMa-2
        </th>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.7.7.2">
         16.4
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.7.7.3">
         16.3 (-0.1)
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.1.7.7.4">
         16.1 (-0.3)
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.7.7.5">
         3.4
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.7.7.6">
         1.7 (-1.7)
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.1.7.7.7">
         1.0 (-2.4)
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.7.7.8">
         8.8
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.7.7.9">
         8.8 (+0.0)
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.1.7.7.10">
         7.6 (-1.2)
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.7.7.11">
         0.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.7.7.12">
         2.0 (+2.0)
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.7.7.13">
         0.0 (+0.0)
        </td>
       </tr>
       <tr class="ltx_tr" id="S4.T1.1.1.8.8">
        <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T1.1.1.8.8.1">
         WizardLM
        </th>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.8.8.2">
         23.9
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.8.8.3">
         23.8 (-0.1)
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.1.8.8.4">
         23.8 (-0.1)
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.8.8.5">
         4.3
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.8.8.6">
         1.0 (-3.3)
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.1.8.8.7">
         0.0 (-4.3)
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.8.8.8">
         10.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.8.8.9">
         10.0 (+0.0)
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.1.8.8.10">
         10.0 (+0.0)
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.8.8.11">
         0.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.8.8.12">
         0.0 (+0.0)
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.8.8.13">
         0.0 (+0.0)
        </td>
       </tr>
       <tr class="ltx_tr" id="S4.T1.1.1.9.9">
        <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T1.1.1.9.9.1">
         Baichuan
        </th>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.9.9.2">
         15.5
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.9.9.3">
         15.5 (+0.0)
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.1.9.9.4">
         15.0 (-0.5)
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.9.9.5">
         0.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.9.9.6">
         1.4 (+1.4)
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.1.9.9.7">
         1.7 (+1.7)
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.9.9.8">
         4.3
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.9.9.9">
         4.3 (+0.0)
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.1.9.9.10">
         2.5 (-1.8)
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.9.9.11">
         0.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.9.9.12">
         0.0 (+0.0)
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.9.9.13">
         0.0 (+0.0)
        </td>
       </tr>
       <tr class="ltx_tr" id="S4.T1.1.1.10.10">
        <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t" id="S4.T1.1.1.10.10.1">
         CodeLLaMa
        </th>
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T1.1.1.10.10.2">
         36.8
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T1.1.1.10.10.3">
         36.2 (-0.6)
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.T1.1.1.10.10.4">
         36.8 (-0.0)
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T1.1.1.10.10.5">
         0.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T1.1.1.10.10.6">
         0.0 (+0.0)
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.T1.1.1.10.10.7">
         0.0 (+0.0)
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T1.1.1.10.10.8">
         18.7
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T1.1.1.10.10.9">
         18.8 (+0.1)
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.T1.1.1.10.10.10">
         18.7 (+0.0)
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T1.1.1.10.10.11">
         2.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T1.1.1.10.10.12">
         2.0 (+0.0)
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T1.1.1.10.10.13">
         0.0 (-2.0)
        </td>
       </tr>
      </tbody>
     </table>
    </span>
   </div>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_table">
     Table 1:
    </span>
    We report the robustness results of LLMs in the sentence-level and semantic-level settings in this table. ’Original’ is the original accuracy copied from the PPTC benchmark. ’Sentence’ and ’Semantic’ are the LLM’s accuracy in the sentence-level and semantic-level settings, respectively. The value in ’()’ is the range of change from the original performance to the robustness performance.
   </figcaption>
  </figure>
  <section class="ltx_subsection" id="S4.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     4.1
    </span>
    Large Language Models Selected for Evaluation
   </h3>
   <div class="ltx_para" id="S4.SS1.p1">
    <p class="ltx_p" id="S4.SS1.p1.1">
     We follow PPTC
     <cite class="ltx_cite ltx_citemacro_cite">
      Guo et al. (
      <a class="ltx_ref" href="#bib.bib9" title="">
       2023
      </a>
      )
     </cite>
     and select 3 closed-source LLMs:
     <span class="ltx_text ltx_font_italic" id="S4.SS1.p1.1.1">
      GPT-4
     </span>
     <cite class="ltx_cite ltx_citemacro_cite">
      OpenAI (
      <a class="ltx_ref" href="#bib.bib27" title="">
       2023
      </a>
      )
     </cite>
     ,
     <span class="ltx_text ltx_font_italic" id="S4.SS1.p1.1.2">
      ChatGPT
     </span>
     ,
     <span class="ltx_text ltx_font_italic" id="S4.SS1.p1.1.3">
      Text-Davinci-003
     </span>
     and 4 strong open-source LLMs:
     <span class="ltx_text ltx_font_italic" id="S4.SS1.p1.1.4">
      LLaMa-2-Chat
     </span>
     <cite class="ltx_cite ltx_citemacro_cite">
      Touvron et al. (
      <a class="ltx_ref" href="#bib.bib35" title="">
       2023
      </a>
      )
     </cite>
     ,
     <span class="ltx_text ltx_font_italic" id="S4.SS1.p1.1.5">
      Code-LLaMa-instruct
     </span>
     <cite class="ltx_cite ltx_citemacro_cite">
      Chiang et al. (
      <a class="ltx_ref" href="#bib.bib5" title="">
       2023
      </a>
      )
     </cite>
     ,
     <span class="ltx_text ltx_font_italic" id="S4.SS1.p1.1.6">
      WizardLM v1.2
     </span>
     <cite class="ltx_cite ltx_citemacro_cite">
      Xu et al. (
      <a class="ltx_ref" href="#bib.bib41" title="">
       2023a
      </a>
      )
     </cite>
     , and
     <span class="ltx_text ltx_font_italic" id="S4.SS1.p1.1.7">
      Baichuan-2-Chat
     </span>
     <cite class="ltx_cite ltx_citemacro_cite">
      Yang et al. (
      <a class="ltx_ref" href="#bib.bib43" title="">
       2023
      </a>
      )
     </cite>
     as our LLMs for evaluation. We select them as they have shown strong performance on the original PPTC benchmark or they are typical LLMs (e.g., LLaMa-2 series). For open-source LLMs, we use their chat/instruct version with 13 billion parameters.
    </p>
   </div>
   <figure class="ltx_figure" id="S4.F4">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="223" id="S4.F4.g1" src="/html/2403.03788/assets/multilingual.png" width="598"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      Figure 4:
     </span>
     We illustrate the turn-based results of closed-source LLMs in the creating new slides task, where the instructions are translated into 14 non-English languages. The bar for each language represents the LLM’s accuracy in the corresponding language setting. The dotted line is the LLM’s accuracy when tested in the English setting.
    </figcaption>
   </figure>
   <section class="ltx_subsubsection" id="S4.SS1.SSS1">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      4.1.1
     </span>
     Evaluation approaches and metrics
    </h4>
    <div class="ltx_para" id="S4.SS1.SSS1.p1">
     <p class="ltx_p" id="S4.SS1.SSS1.p1.1">
      We follow PPTC
      <cite class="ltx_cite ltx_citemacro_cite">
       Guo et al. (
       <a class="ltx_ref" href="#bib.bib9" title="">
        2023
       </a>
       )
      </cite>
      and use the two evaluation approaches: (1) Turn-based evaluation aims to measure the LLM’s ability to finish a single turn where we assume that previous turns of this turn have been correctly finished. (2) Session-based evaluation tests the LLM’s ability to finish the entire session containing multiple turns. Here we don’t assume the LLM has correctly finished previous turns when it is asked to finish one turn of a session.
     </p>
    </div>
    <div class="ltx_para" id="S4.SS1.SSS1.p2">
     <p class="ltx_p" id="S4.SS1.SSS1.p2.1">
      <span class="ltx_text ltx_font_bold" id="S4.SS1.SSS1.p2.1.1">
       Metrics
      </span>
      In turn-based evaluation, we report the
      <span class="ltx_text" id="S4.SS1.SSS1.p2.1.2">
       turn-based accuracy
      </span>
      as the ratio of the number of successfully finished turns to the total number of turns.
In session-based evaluation, we report the
      <span class="ltx_text" id="S4.SS1.SSS1.p2.1.3">
       session-based accuracy
      </span>
      as the ratio of the number of successfully finished sessions to the total number of sessions.
     </p>
    </div>
   </section>
  </section>
  <section class="ltx_subsection" id="S4.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     4.2
    </span>
    Implementation Details
   </h3>
   <div class="ltx_para" id="S4.SS2.p1">
    <p class="ltx_p" id="S4.SS2.p1.1">
     For fair comparison and reproducibility, we follow PPTC and use the respective language models’ API provided by Azure OpenAI Service for closed-source LLMs. For open-source LLMs, we download them from the official websites. More details are in Appendix
     <a class="ltx_ref" href="#A2" title="Appendix B Experimental details ‣ PPTC-R benchmark: Towards Evaluating the Robustness of Large Language Models for PowerPoint Task Completion">
      <span class="ltx_text ltx_ref_tag">
       B
      </span>
     </a>
     .
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S4.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     4.3
    </span>
    Main results
   </h3>
   <div class="ltx_para" id="S4.SS3.p1">
    <p class="ltx_p" id="S4.SS3.p1.1">
     In this section, we report the accuracy results of LLMs on our benchmark in Tables
     <a class="ltx_ref" href="#S4.T1" title="Table 1 ‣ 4 Experiments ‣ PPTC-R benchmark: Towards Evaluating the Robustness of Large Language Models for PowerPoint Task Completion">
      <span class="ltx_text ltx_ref_tag">
       1
      </span>
     </a>
     &amp;
     <a class="ltx_ref" href="#S4.T2" title="Table 2 ‣ 4.3 Main results ‣ 4 Experiments ‣ PPTC-R benchmark: Towards Evaluating the Robustness of Large Language Models for PowerPoint Task Completion">
      <span class="ltx_text ltx_ref_tag">
       2
      </span>
     </a>
     and Figures
     <a class="ltx_ref" href="#S4.F4" title="Figure 4 ‣ 4.1 Large Language Models Selected for Evaluation ‣ 4 Experiments ‣ PPTC-R benchmark: Towards Evaluating the Robustness of Large Language Models for PowerPoint Task Completion">
      <span class="ltx_text ltx_ref_tag">
       4
      </span>
     </a>
     &amp;
     <a class="ltx_ref" href="#A4.F9" title="Figure 9 ‣ Appendix D Closed-source LLM’s Multilingual Results in the Editing Template Task ‣ PPTC-R benchmark: Towards Evaluating the Robustness of Large Language Models for PowerPoint Task Completion">
      <span class="ltx_text ltx_ref_tag">
       9
      </span>
     </a>
     &amp;
     <a class="ltx_ref" href="#A4.F10" title="Figure 10 ‣ Appendix D Closed-source LLM’s Multilingual Results in the Editing Template Task ‣ PPTC-R benchmark: Towards Evaluating the Robustness of Large Language Models for PowerPoint Task Completion">
      <span class="ltx_text ltx_ref_tag">
       10
      </span>
     </a>
     . The results of the cost measurement are in Appendix
     <a class="ltx_ref" href="#A3.T8" title="Table 8 ‣ Appendix C Detailed Results of LLMs on PPTC-R benchmark ‣ PPTC-R benchmark: Towards Evaluating the Robustness of Large Language Models for PowerPoint Task Completion">
      <span class="ltx_text ltx_ref_tag">
       8
      </span>
     </a>
     . Then we analyze the results from the aspects of LLMs and perturbation types.
    </p>
   </div>
   <figure class="ltx_table" id="S4.T2">
    <div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T2.1" style="width:455.2pt;height:112.2pt;vertical-align:-0.6pt;">
     <span class="ltx_transformed_inner" style="transform:translate(-139.5pt,34.2pt) scale(0.62,0.62) ;">
      <table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T2.1.1">
       <tbody class="ltx_tbody">
        <tr class="ltx_tr" id="S4.T2.1.1.1.1">
         <th class="ltx_td ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.1.1.1.1.1">
         </th>
         <td class="ltx_td ltx_align_center ltx_border_t" colspan="6" id="S4.T2.1.1.1.1.2">
          Creating new slides
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" colspan="6" id="S4.T2.1.1.1.1.3">
          Editing PPT template
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T2.1.1.2.2">
         <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T2.1.1.2.2.1">
          Models
         </th>
         <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3" id="S4.T2.1.1.2.2.2">
          Turn-based
         </td>
         <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3" id="S4.T2.1.1.2.2.3">
          Session-based
         </td>
         <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3" id="S4.T2.1.1.2.2.4">
          Turn-based
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" colspan="3" id="S4.T2.1.1.2.2.5">
          Session-based
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T2.1.1.3.3">
         <th class="ltx_td ltx_th ltx_th_row ltx_border_r" id="S4.T2.1.1.3.3.1">
         </th>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.3.3.2">
          Original
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.3.3.3">
          Lack
         </td>
         <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.1.1.3.3.4">
          Update
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.3.3.5">
          Original
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.3.3.6">
          Lack
         </td>
         <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.1.1.3.3.7">
          Update
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.3.3.8">
          Original
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.3.3.9">
          Lack
         </td>
         <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.1.1.3.3.10">
          Update
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.3.3.11">
          Original
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.3.3.12">
          Lack
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.3.3.13">
          Update
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T2.1.1.4.4">
         <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.1.1.4.4.1">
          Davinci-003
         </th>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.4.4.2">
          72.6
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.4.4.3">
          55.1 (-17.5)
         </td>
         <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.1.1.4.4.4">
          44.5 (-28.1)
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.4.4.5">
          12.7
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.4.4.6">
          5.2 (-7.5)
         </td>
         <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.1.1.4.4.7">
          1.3 (-11.4)
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.4.4.8">
          24.4
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.4.4.9">
          33.7 (+9.3)
         </td>
         <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.1.1.4.4.10">
          17.5 (-6.9)
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.4.4.11">
          4.0
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.4.4.12">
          0.0 (-4.0)
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.4.4.13">
          0.0 (-4.0)
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T2.1.1.5.5">
         <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.1.1.5.5.1">
          ChatGPT
         </th>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.5.5.2">
          70.6
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.5.5.3">
          55.4 (-15.2)
         </td>
         <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.1.1.5.5.4">
          55.4 (-15.2)
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.5.5.5">
          12.7
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.5.5.6">
          3.9 (-8.8)
         </td>
         <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.1.1.5.5.7">
          5.3 (-7.4)
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.5.5.8">
          26.3
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.5.5.9">
          27.5 (+1.2)
         </td>
         <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.1.1.5.5.10">
          15.0 (-11.3)
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.5.5.11">
          2.0
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.5.5.12">
          0.0 (-2.0)
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.5.5.13">
          0.0 (-2.0)
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T2.1.1.6.6">
         <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.1.1.6.6.1">
          GPT-4
         </th>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.6.6.2">
          75.1
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.6.6.3">
          62.5 (-12.6)
         </td>
         <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.1.1.6.6.4">
          75.7 (+0.6)
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.6.6.5">
          22.7
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.6.6.6">
          5.2 (-17.5)
         </td>
         <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.1.1.6.6.7">
          18.8 (-3.9)
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.6.6.8">
          38.1
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.6.6.9">
          39.4 (+1.3)
         </td>
         <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.1.1.6.6.10">
          35.6 (-2.5)
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.6.6.11">
          6.0
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.6.6.12">
          0.0 (-6.0)
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.6.6.13">
          2.0 (-4.0)
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T2.1.1.7.7">
         <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.1.1.7.7.1">
          LLaMa-2
         </th>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.7.7.2">
          16.4
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.7.7.3">
          16.5 (+0.1)
         </td>
         <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.1.1.7.7.4">
          7.8 (-8.6)
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.7.7.5">
          3.4
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.7.7.6">
          0.0 (-3.4)
         </td>
         <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.1.1.7.7.7">
          3.4 (-0.0)
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.7.7.8">
          8.8
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.7.7.9">
          12.0 (+4.0)
         </td>
         <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.1.1.7.7.10">
          7.5 (-1.3)
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.7.7.11">
          0.0
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.7.7.12">
          0.0 (+0.0)
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.7.7.13">
          2.0 (+2.0)
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T2.1.1.8.8">
         <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.1.1.8.8.1">
          WizardLM
         </th>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.8.8.2">
          23.9
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.8.8.3">
          18.9 (-5.0)
         </td>
         <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.1.1.8.8.4">
          11.3 (-12.6)
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.8.8.5">
          4.3
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.8.8.6">
          0.0 (-4.3)
         </td>
         <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.1.1.8.8.7">
          0.0 (-4.3)
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.8.8.8">
          10.0
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.8.8.9">
          14.4 (+4.4)
         </td>
         <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.1.1.8.8.10">
          6.9 (-3.1)
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.8.8.11">
          0.0
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.8.8.12">
          0.0 (+0.0)
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.8.8.13">
          0.0 (+0.0)
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T2.1.1.9.9">
         <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.1.1.9.9.1">
          Baichuan
         </th>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.9.9.2">
          15.5
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.9.9.3">
          18.7 (+3.2)
         </td>
         <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.1.1.9.9.4">
          13.2 (-2.3)
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.9.9.5">
          0.0
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.9.9.6">
          0.0 (+0.0)
         </td>
         <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.1.1.9.9.7">
          1.0 (+1.0)
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.9.9.8">
          4.3
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.9.9.9">
          10.6 (+6.3)
         </td>
         <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.1.1.9.9.10">
          2.5 (+1.8)
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.9.9.11">
          0.0
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.9.9.12">
          6.0 (+6.0)
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.9.9.13">
          0.0 (+0.0)
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T2.1.1.10.10">
         <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t" id="S4.T2.1.1.10.10.1">
          CodeLLaMa
         </th>
         <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T2.1.1.10.10.2">
          36.8
         </td>
         <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T2.1.1.10.10.3">
          26.3 (-10.5)
         </td>
         <td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.T2.1.1.10.10.4">
          22.4 (-14.4)
         </td>
         <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T2.1.1.10.10.5">
          0.0
         </td>
         <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T2.1.1.10.10.6">
          0.0 (+0.0)
         </td>
         <td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.T2.1.1.10.10.7">
          1.0 (+2.0)
         </td>
         <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T2.1.1.10.10.8">
          18.7
         </td>
         <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T2.1.1.10.10.9">
          13.6 (-5.1)
         </td>
         <td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.T2.1.1.10.10.10">
          12.6 (-6.1)
         </td>
         <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T2.1.1.10.10.11">
          2.0
         </td>
         <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T2.1.1.10.10.12">
          2.0 (+0.0)
         </td>
         <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T2.1.1.10.10.13">
          2.0 (+0.0)
         </td>
        </tr>
       </tbody>
      </table>
     </span>
    </div>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_table">
      Table 2:
     </span>
     We report the robustness results of LLMs in the API-lack and API-update settings in this table. ’Original’ is the original accuracy copied from the PPTC benchmark. ’Lack’ and ’Update’ are the LLM’s accuracy in the API-lack and API-update settings, respectively.
    </figcaption>
   </figure>
   <figure class="ltx_table" id="S4.T3">
    <div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T3.1" style="width:192.8pt;height:67.5pt;vertical-align:-0.0pt;">
     <span class="ltx_transformed_inner" style="transform:translate(-57.9pt,20.3pt) scale(0.625,0.625) ;">
      <table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T3.1.1">
       <thead class="ltx_thead">
        <tr class="ltx_tr" id="S4.T3.1.1.1.1">
         <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" id="S4.T3.1.1.1.1.1">
          Models
         </th>
         <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" colspan="2" id="S4.T3.1.1.1.1.2">
          Creating new slides
         </th>
         <th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T3.1.1.1.1.3">
          Editing PPT template
         </th>
        </tr>
       </thead>
       <tbody class="ltx_tbody">
        <tr class="ltx_tr" id="S4.T3.1.1.2.1">
         <th class="ltx_td ltx_th ltx_th_row ltx_border_r" id="S4.T3.1.1.2.1.1">
         </th>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.2.1.2">
          Turn-based
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.2.1.3">
          Session-based
         </td>
         <td class="ltx_td ltx_align_center ltx_border_l ltx_border_t" id="S4.T3.1.1.2.1.4">
          Turn-based
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T3.1.1.3.2">
         <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T3.1.1.3.2.1">
          ChatGPT
         </th>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.3.2.2">
          16.3
         </td>
         <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.1.1.3.2.3">
          54.7
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.3.2.4">
          19.7
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T3.1.1.4.3">
         <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T3.1.1.4.3.1">
          GPT-4
         </th>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.4.3.2">
          9.4
         </td>
         <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.1.1.4.3.3">
          54.1
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.4.3.4">
          17.7
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T3.1.1.5.4">
         <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T3.1.1.5.4.1">
          LLaMa-2
         </th>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.5.4.2">
          13.6
         </td>
         <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.1.1.5.4.3">
          55.2
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.5.4.4">
          9.4
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T3.1.1.6.5">
         <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t" id="S4.T3.1.1.6.5.1">
          WizardLM
         </th>
         <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T3.1.1.6.5.2">
          18.5
         </td>
         <td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.T3.1.1.6.5.3">
          94.2
         </td>
         <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T3.1.1.6.5.4">
          10.3
         </td>
        </tr>
       </tbody>
      </table>
     </span>
    </div>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_table">
      Table 3:
     </span>
     This table presents Average Performance Drop Rate (APDR) results for LLMs. For the "creating new slides" task’s turn-based column, we compute LLMs’ PDR rates using their turn-based accuracy of the creating new slides task in each robustness setting. The average is reported as APDR. The same calculation is applied to the other columns. Note that we exclude the multilingual setting for open-source LLMs.
    </figcaption>
   </figure>
   <figure class="ltx_table" id="S4.T4">
    <div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T4.1" style="width:465.6pt;height:45.6pt;vertical-align:-0.6pt;">
     <span class="ltx_transformed_inner" style="transform:translate(-139.7pt,13.5pt) scale(0.625,0.625) ;">
      <table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T4.1.1">
       <tbody class="ltx_tbody">
        <tr class="ltx_tr" id="S4.T4.1.1.1.1">
         <th class="ltx_td ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T4.1.1.1.1.1">
         </th>
         <td class="ltx_td ltx_align_center ltx_border_t" colspan="6" id="S4.T4.1.1.1.1.2">
          Creating new slides
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" colspan="6" id="S4.T4.1.1.1.1.3">
          Editing PPT template
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T4.1.1.2.2">
         <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T4.1.1.2.2.1">
          Models
         </th>
         <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3" id="S4.T4.1.1.2.2.2">
          Turn-based
         </td>
         <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3" id="S4.T4.1.1.2.2.3">
          Session-based
         </td>
         <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3" id="S4.T4.1.1.2.2.4">
          Turn-based
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" colspan="3" id="S4.T4.1.1.2.2.5">
          Session-based
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T4.1.1.3.3">
         <th class="ltx_td ltx_th ltx_th_row ltx_border_r" id="S4.T4.1.1.3.3.1">
         </th>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.1.1.3.3.2">
          Original
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.1.1.3.3.3">
          ChitChat
         </td>
         <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.1.1.3.3.4">
          True or False
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.1.1.3.3.5">
          Original
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.1.1.3.3.6">
          ChitChat
         </td>
         <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.1.1.3.3.7">
          True or False
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.1.1.3.3.8">
          Original
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.1.1.3.3.9">
          ChitChat
         </td>
         <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.1.1.3.3.10">
          True or False
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.1.1.3.3.11">
          Original
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.1.1.3.3.12">
          ChitChat
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.1.1.3.3.13">
          True or False
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T4.1.1.4.4">
         <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t" id="S4.T4.1.1.4.4.1">
          GPT-4
         </th>
         <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T4.1.1.4.4.2">
          75.1
         </td>
         <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T4.1.1.4.4.3">
          72.3 (-2.8)
         </td>
         <td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.T4.1.1.4.4.4">
          73.2 (-1.9)
         </td>
         <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T4.1.1.4.4.5">
          22.7
         </td>
         <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T4.1.1.4.4.6">
          12.3 (-10.4)
         </td>
         <td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.T4.1.1.4.4.7">
          14.8 (-7.9)
         </td>
         <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T4.1.1.4.4.8">
          38.1
         </td>
         <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T4.1.1.4.4.9">
          36.9 (-1.2)
         </td>
         <td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.T4.1.1.4.4.10">
          37.5 (-0.6)
         </td>
         <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T4.1.1.4.4.11">
          6.0
         </td>
         <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T4.1.1.4.4.12">
          4.0 (-2.0)
         </td>
         <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T4.1.1.4.4.13">
          6.0 (+0.0)
         </td>
        </tr>
       </tbody>
      </table>
     </span>
    </div>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_table">
      Table 4:
     </span>
     We report the robustness results of GPT-4 in the sentence-level setting by adding chitchat sentences (’Chitchat’) and randomly generated strings (’Random’), respectively.
    </figcaption>
   </figure>
   <div class="ltx_para" id="S4.SS3.p2">
    <p class="ltx_p" id="S4.SS3.p2.1">
     <span class="ltx_text ltx_font_bold" id="S4.SS3.p2.1.1">
      Sentence-level and semantic-level robustness:
     </span>
     We report LLMs’ robustness performance for Sentence-level and semantic-level settings in Table
     <a class="ltx_ref" href="#S4.T1" title="Table 1 ‣ 4 Experiments ‣ PPTC-R benchmark: Towards Evaluating the Robustness of Large Language Models for PowerPoint Task Completion">
      <span class="ltx_text ltx_ref_tag">
       1
      </span>
     </a>
     .
From the results, we highlight the following key findings: (1) For both two tasks, GPT-4 shows the strongest performance under the sentence-level and semantic-level perturbations and it usually drops its performance less than other closed-source LLMs. (2) Open-source LLMs achieve low performance but also drop less performance than their closed-source counterparts. CodeLLaMa achieves the strongest robustness and performance among open-source LLMs. (3) Overcoming the sentence-level perturbation is harder than the semantic-level perturbation as LLMs usually drop much performance in the former setting for both the turn-based and session-based evaluation.
    </p>
   </div>
   <div class="ltx_para" id="S4.SS3.p3">
    <p class="ltx_p" id="S4.SS3.p3.1">
     <span class="ltx_text ltx_font_bold" id="S4.SS3.p3.1.1">
      Language-level robustness:
     </span>
     We illustrate the turn-based results of closed-source LLMs
     <span class="ltx_note ltx_role_footnote" id="footnote2">
      <sup class="ltx_note_mark">
       †
      </sup>
      <span class="ltx_note_outer">
       <span class="ltx_note_content">
        <sup class="ltx_note_mark">
         †
        </sup>
        <span class="ltx_tag ltx_tag_note">
         †
        </span>
        Current open-source LLMs claim that they are mainly pre-trained in English corpus (e.g., only 1% non-English corpus for Llama-2) and do not support multi-lingual settings.
       </span>
      </span>
     </span>
     in the language-level robustness setting in Figure
     <a class="ltx_ref" href="#S4.F4" title="Figure 4 ‣ 4.1 Large Language Models Selected for Evaluation ‣ 4 Experiments ‣ PPTC-R benchmark: Towards Evaluating the Robustness of Large Language Models for PowerPoint Task Completion">
      <span class="ltx_text ltx_ref_tag">
       4
      </span>
     </a>
     . Due to space limitation, we put other results of the multilingual setting in Appendix
     <a class="ltx_ref" href="#A4" title="Appendix D Closed-source LLM’s Multilingual Results in the Editing Template Task ‣ PPTC-R benchmark: Towards Evaluating the Robustness of Large Language Models for PowerPoint Task Completion">
      <span class="ltx_text ltx_ref_tag">
       D
      </span>
     </a>
     . From these results, we find that (1) GPT-4 outperforms other LLMs obviously in the turn-based evaluation (see Figure
     <a class="ltx_ref" href="#S4.F4" title="Figure 4 ‣ 4.1 Large Language Models Selected for Evaluation ‣ 4 Experiments ‣ PPTC-R benchmark: Towards Evaluating the Robustness of Large Language Models for PowerPoint Task Completion">
      <span class="ltx_text ltx_ref_tag">
       4
      </span>
     </a>
     and
     <a class="ltx_ref" href="#A4.F10" title="Figure 10 ‣ Appendix D Closed-source LLM’s Multilingual Results in the Editing Template Task ‣ PPTC-R benchmark: Towards Evaluating the Robustness of Large Language Models for PowerPoint Task Completion">
      <span class="ltx_text ltx_ref_tag">
       10
      </span>
     </a>
     ) and also drops less than the other two LLMs, which shows GPT-4’s strong multilingual understanding ability. (2) Even GPT-4 also performs poorly in low-resource languages like Swahili. ChatGPT and Davinci further perform poorly in Urdu and Arabic. That means improving LLM’s performance in low-resource languages is still a long-term challenge.
    </p>
   </div>
   <div class="ltx_para" id="S4.SS3.p4">
    <p class="ltx_p" id="S4.SS3.p4.1">
     <span class="ltx_text ltx_font_bold" id="S4.SS3.p4.1.1">
      API lack and API update robustness:
     </span>
     We report the results of the API lack and update settings in Table
     <a class="ltx_ref" href="#S4.T2" title="Table 2 ‣ 4.3 Main results ‣ 4 Experiments ‣ PPTC-R benchmark: Towards Evaluating the Robustness of Large Language Models for PowerPoint Task Completion">
      <span class="ltx_text ltx_ref_tag">
       2
      </span>
     </a>
     . From the results, we find that:(1) GPT-4 shows good robustness to the API-update perturbation as it only drops the performance slightly by 2
     <math alttext="\sim" class="ltx_Math" display="inline" id="S4.SS3.p4.1.m1.1">
      <semantics id="S4.SS3.p4.1.m1.1a">
       <mo id="S4.SS3.p4.1.m1.1.1" xref="S4.SS3.p4.1.m1.1.1.cmml">
        ∼
       </mo>
       <annotation-xml encoding="MathML-Content" id="S4.SS3.p4.1.m1.1b">
        <csymbol cd="latexml" id="S4.SS3.p4.1.m1.1.1.cmml" xref="S4.SS3.p4.1.m1.1.1">
         similar-to
        </csymbol>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS3.p4.1.m1.1c">
        \sim
       </annotation>
      </semantics>
     </math>
     4 percent. In contrast, other closed-LLMs drop their performance markedly as the perturbation of introducing more new APIs. That shows the unique position of GPT-4 in API calls. (2) For the creating slides task, LLMs drop more performance in the API-lack setting than they in the API-update setting. That means it is harder for current LLMs to know what they can not do based on the provided API list. We analyze the wrong examples and find that is because LLMs call unavailable APIs rather than seek assistance. (3) Surprisingly, we observe that the turn-based performance of almost all LLMs in the editing task improves under the API-lack perturbation. We discover that this is attributed to the editing task design in PPTC, which emphasizes instructing LLMs to process lengthy PPT templates with high-frequency basic APIs. Consequently, the API-lack setting occasionally reduces the task difficulty by deleting low-frequency APIs.
    </p>
   </div>
   <div class="ltx_para" id="S4.SS3.p5">
    <p class="ltx_p" id="S4.SS3.p5.1">
     <span class="ltx_text ltx_font_bold" id="S4.SS3.p5.1.1">
      LLMs’ robustness varies with the difficulty of the task and the complexity of the environment
     </span>
     To measure the variation of LLMs’ robustness, we use the Average Performance Drop Rate (APDR) metric proposed in
     <cite class="ltx_cite ltx_citemacro_cite">
      Zhu et al. (
      <a class="ltx_ref" href="#bib.bib47" title="">
       2023
      </a>
      )
     </cite>
     <span class="ltx_note ltx_role_footnote" id="footnote3">
      <sup class="ltx_note_mark">
       ‡
      </sup>
      <span class="ltx_note_outer">
       <span class="ltx_note_content">
        <sup class="ltx_note_mark">
         ‡
        </sup>
        <span class="ltx_tag ltx_tag_note">
         ‡
        </span>
        We don’t use this rate to compare different LLMs as open-source LLMs can achieve low APDR rates with a pretty low performance. Then the comparison is useless.
       </span>
      </span>
     </span>
     , which quantifies the average relative performance decline of LLMs when subjected to perturbation attacks
     <span class="ltx_note ltx_role_footnote" id="footnote4">
      <sup class="ltx_note_mark">
       §
      </sup>
      <span class="ltx_note_outer">
       <span class="ltx_note_content">
        <sup class="ltx_note_mark">
         §
        </sup>
        <span class="ltx_tag ltx_tag_note">
         §
        </span>
        It is calculated by dividing the range of performance variation with the original performance.
       </span>
      </span>
     </span>
     . We report the APDR rate of LLMs in Table
     <a class="ltx_ref" href="#S4.T3" title="Table 3 ‣ 4.3 Main results ‣ 4 Experiments ‣ PPTC-R benchmark: Towards Evaluating the Robustness of Large Language Models for PowerPoint Task Completion">
      <span class="ltx_text ltx_ref_tag">
       3
      </span>
     </a>
     . We find a decrease in the robustness of LLMs when we increase the difficulty of the same task (e.g., turn-based evaluation-&gt;session-based evaluation) or move to complex environments (e.g., creating 1
     <math alttext="\sim" class="ltx_Math" display="inline" id="S4.SS3.p5.1.m1.1">
      <semantics id="S4.SS3.p5.1.m1.1a">
       <mo id="S4.SS3.p5.1.m1.1.1" xref="S4.SS3.p5.1.m1.1.1.cmml">
        ∼
       </mo>
       <annotation-xml encoding="MathML-Content" id="S4.SS3.p5.1.m1.1b">
        <csymbol cd="latexml" id="S4.SS3.p5.1.m1.1.1.cmml" xref="S4.SS3.p5.1.m1.1.1">
         similar-to
        </csymbol>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S4.SS3.p5.1.m1.1c">
        \sim
       </annotation>
      </semantics>
     </math>
     2 slides-&gt;editing the long template with tens of slides), even for GPT-4. For instance, in the task of creating new slides, GPT-4’s APDR rate increases from 9.4 to 54.1 (where a higher value indicates poorer robustness) when transitioning from turn-based to session-based task evaluation. The table further indicates that completing multi-turns (session-based evaluation) is harder than editing the template as LLMs exhibit higher APDR rates in the former, and occasionally, open-source LLMs’ APDR rate experiences a slight drop in the latter.
    </p>
   </div>
   <figure class="ltx_figure" id="S4.F5">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="229" id="S4.F5.g1" src="/html/2403.03788/assets/API_number.png" width="598"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      Figure 5:
     </span>
     We report the results of three LLMs with different numbers of new APIs in sub-figures (a), (b), and (c). The session-based accuracy of all LLMs’ editing template task performance is pretty low (&lt;4).
    </figcaption>
   </figure>
  </section>
 </section>
 <section class="ltx_section" id="S5">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    5
   </span>
   Analysis
  </h2>
  <section class="ltx_subsection" id="S5.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     5.1
    </span>
    Error analysis for LLMs
   </h3>
   <div class="ltx_para" id="S5.SS1.p1">
    <p class="ltx_p" id="S5.SS1.p1.1">
     To conduct error analysis in PPTC-R, for each robustness setting, we randomly collect 25 examples that are wrong in PPTC-R but are correct in the original PPTC. We do the collection process separately for ChatGPT and GPT-4. Based on these collected examples, we identify the following error reasons: (1) Being Distracted by chitchat sentences. When processing the user instruction in the sentence-level robustness setting, LLMs start to chat with the user and forget to generate API sequences, with a rate of 61% in all errors. (2) Calling unavailable APIs or new APIs. In the API lack and multilingual settings, we find that GPT-4 and ChatGPT tend to create new APIs like ’select
     <math alttext="\_" class="ltx_Math" display="inline" id="S5.SS1.p1.1.m1.1">
      <semantics id="S5.SS1.p1.1.m1.1a">
       <mi id="S5.SS1.p1.1.m1.1.1" mathvariant="normal" xref="S5.SS1.p1.1.m1.1.1.cmml">
        _
       </mi>
       <annotation-xml encoding="MathML-Content" id="S5.SS1.p1.1.m1.1b">
        <ci id="S5.SS1.p1.1.m1.1.1.cmml" xref="S5.SS1.p1.1.m1.1.1">
         _
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S5.SS1.p1.1.m1.1c">
        \_
       </annotation>
      </semantics>
     </math>
     column’. Though these APIs may appear reliable, they are non-executable. In the API update setting, ChatGPT invokes new APIs provided by our setting. Although these APIs are executable, they are not necessary. (3) Misunderstanding the instruction. In the sentence and semantic-level robustness settings, GPT-4 and ChatGPT might misunderstand instructions, leading to the call of wrong APIs. We provide detailed examples in Appendix
     <a class="ltx_ref" href="#A5" title="Appendix E Detailed Wrong Examples Made by LLMs ‣ PPTC-R benchmark: Towards Evaluating the Robustness of Large Language Models for PowerPoint Task Completion">
      <span class="ltx_text ltx_ref_tag">
       E
      </span>
     </a>
     .
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S5.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     5.2
    </span>
    Chitchat sentences Vs ’True or False’
   </h3>
   <div class="ltx_para" id="S5.SS2.p1">
    <p class="ltx_p" id="S5.SS2.p1.1">
     Traditional sentence-level perturbations are typically performed by inserting ’True or False’ (StressTest
     <cite class="ltx_cite ltx_citemacro_cite">
      Naik et al. (
      <a class="ltx_ref" href="#bib.bib25" title="">
       2018
      </a>
      )
     </cite>
     ) or a randomly generated string like ’KjPJJ2a7RB’ (Checklist
     <cite class="ltx_cite ltx_citemacro_cite">
      Ribeiro et al. (
      <a class="ltx_ref" href="#bib.bib32" title="">
       2020
      </a>
      )
     </cite>
     ) into the original input. In contrast, our sentence-level perturbation is more challenging as it introduces various chitchat sentences. Empirically, we test GPT-4 in a robustness setting where we prepend ’True or False’ to each instruction. From Table
     <a class="ltx_ref" href="#S4.T4" title="Table 4 ‣ 4.3 Main results ‣ 4 Experiments ‣ PPTC-R benchmark: Towards Evaluating the Robustness of Large Language Models for PowerPoint Task Completion">
      <span class="ltx_text ltx_ref_tag">
       4
      </span>
     </a>
     , we observe that our perturbation indeed causes GPT-4 to experience a greater performance drop, as it deviates from chitchat.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S5.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     5.3
    </span>
    <span class="ltx_text ltx_font_italic" id="S5.SS3.1.1">
     How does the number of new APIs influence the LLM’s performance?
    </span>
   </h3>
   <div class="ltx_para" id="S5.SS3.p1">
    <p class="ltx_p" id="S5.SS3.p1.1">
     We study the influence of different numbers of new APIs on LLMs’ performance in Figure
     <a class="ltx_ref" href="#S4.F5" title="Figure 5 ‣ 4.3 Main results ‣ 4 Experiments ‣ PPTC-R benchmark: Towards Evaluating the Robustness of Large Language Models for PowerPoint Task Completion">
      <span class="ltx_text ltx_ref_tag">
       5
      </span>
     </a>
     . We find that ChatGPT’s performance gradually decreases when increasing the number of APIs. The performance of open-source WizardLM first quickly drops when we add 25 new APIs to its API reference list and then maintains its performance at a pretty low level. This means current most LLMs still lack enough robustness to select the correct APIs from a larger candidate pool (version update). In contrast, GPT-4 maintains its turn-based performance at a comparatively high level, which shows its strong robustness to the API update setting. However, its session-based performance in the creating task also drops obviously as the double challenges of increasing the new API number and finishing the entire multi-turn session.
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S6">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    6
   </span>
   Conclusion
  </h2>
  <div class="ltx_para" id="S6.p1">
   <p class="ltx_p" id="S6.p1.1">
    Deploying LLMs and LLM-based agents to complete users’ task instructions has become a pressing demand. However, there still lacks a evaluation and analysis of LLMs’ robustness in complex task completions. We introduce the PowerPoint Task Completion-Robustness benchmark, designed to assess LLMs’ robustness in handling user adversarial instructions and adapting to different software versions in complex PPT task completion. The results of 7 LLMs in our benchmark show that GPT-4 is the strongest one but all LLMs’ robustness degrades when increasing the task difficulty. We further conduct a detailed analysis of error reasons and robustness behaviors for profound understanding.
   </p>
  </div>
 </section>
 <section class="ltx_section" id="S7">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    7
   </span>
   Limitations and potential risks
  </h2>
  <div class="ltx_para" id="S7.p1">
   <p class="ltx_p" id="S7.p1.1">
    Investigating the LLM’s robustness to the PPT file (environment) may be interesting. A simple way is to vary the number of shapes in the PPT file. For example, slides containing more figures may pose a greater challenge for LLMs when completing figure-related instructions. However, we do not consider this perturbation as it is hard to control in specific slides. For example, some slides may allow the addition of more figures, while others can not as they are completely fulfilled. On the other hand, our benchmark does not consider creating harder instructions by further asking experts to write and edit the instructions. But current LLMs have already dropped their performance obviously in our setting. So we leave the further creation work in the future.
   </p>
  </div>
  <div class="ltx_para" id="S7.p2">
   <p class="ltx_p" id="S7.p2.1">
    We do not see any potential physical risk in our benchmark as we just test the LLM’s robustness to do virtual PPT tasks under perturbations. We also do not see any societal risk.
   </p>
  </div>
 </section>
 <section class="ltx_bibliography" id="bib">
  <h2 class="ltx_title ltx_title_bibliography">
   References
  </h2>
  <ul class="ltx_biblist">
   <li class="ltx_bibitem" id="bib.bib1">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Anil et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Rohan Anil, Andrew M Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin, Alexandre Passos, Siamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen, et al. 2023.
    </span>
    <span class="ltx_bibblock">
     Palm 2 technical report.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">
      arXiv preprint arXiv:2305.10403
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib2">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Brohan et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Anthony Brohan, Yevgen Chebotar, Chelsea Finn, Karol Hausman, Alexander Herzog, Daniel Ho, Julian Ibarz, Alex Irpan, Eric Jang, Ryan Julian, et al. 2023.
    </span>
    <span class="ltx_bibblock">
     Do as i can, not as i say: Grounding language in robotic affordances.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">
      Conference on Robot Learning
     </em>
     , pages 287–318. PMLR.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib3">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Bubeck et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Sébastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, et al. 2023.
    </span>
    <span class="ltx_bibblock">
     Sparks of artificial general intelligence: Early experiments with gpt-4.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">
      arXiv preprint arXiv:2303.12712
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib4">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chen et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Hailin Chen, Fangkai Jiao, Xingxuan Li, Chengwei Qin, Mathieu Ravaut, Ruochen Zhao, Caiming Xiong, and Shafiq Joty. 2023.
    </span>
    <span class="ltx_bibblock">
     Chatgpt’s one-year anniversary: Are open-source large language models catching up?
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">
      arXiv preprint arXiv:2311.16989
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib5">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chiang et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph E Gonzalez, et al. 2023.
    </span>
    <span class="ltx_bibblock">
     Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">
      See https://vicuna. lmsys. org (accessed 14 April 2023)
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib6">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Conneau et al. (2018)
    </span>
    <span class="ltx_bibblock">
     Alexis Conneau, Ruty Rinott, Guillaume Lample, Adina Williams, Samuel R. Bowman, Holger Schwenk, and Veselin Stoyanov. 2018.
    </span>
    <span class="ltx_bibblock">
     Xnli: Evaluating cross-lingual sentence representations.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">
      Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing
     </em>
     . Association for Computational Linguistics.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib7">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Feng et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Jiazhan Feng, Ruochen Xu, Junheng Hao, Hiteshi Sharma, Yelong Shen, Dongyan Zhao, and Weizhu Chen. 2023.
    </span>
    <span class="ltx_bibblock">
     Language models can be logical solvers.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">
      arXiv preprint arXiv:2311.06158
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib8">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Gilson et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Aidan Gilson, Conrad W Safranek, Thomas Huang, Vimig Socrates, Ling Chi, Richard Andrew Taylor, David Chartash, et al. 2023.
    </span>
    <span class="ltx_bibblock">
     How does chatgpt perform on the united states medical licensing examination? the implications of large language models for medical education and knowledge assessment.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">
      JMIR Medical Education
     </em>
     , 9(1):e45312.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib9">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Guo et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Yiduo Guo, Zekai Zhang, Yaobo Liang, Dongyan Zhao, and Duan Nan. 2023.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://api.semanticscholar.org/CorpusID:265019477" target="_blank" title="">
      Pptc benchmark: Evaluating large language models for powerpoint task completion
     </a>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib10">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Hu et al. (2024)
    </span>
    <span class="ltx_bibblock">
     Zhibo Hu, Chen Wang, Yanfeng Shu, Liming Zhu, et al. 2024.
    </span>
    <span class="ltx_bibblock">
     Prompt perturbation in retrieval-augmented generation based large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">
      arXiv preprint arXiv:2402.07179
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib11">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Jiang et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Albert Q Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, et al. 2023.
    </span>
    <span class="ltx_bibblock">
     Mistral 7b.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">
      arXiv preprint arXiv:2310.06825
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib12">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Jiao et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Wenxiang Jiao, Wenxuan Wang, Jen-tse Huang, Xing Wang, and Zhaopeng Tu. 2023.
    </span>
    <span class="ltx_bibblock">
     Is chatgpt a good translator? a preliminary study.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">
      arXiv preprint arXiv:2301.08745
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib13">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Kasai et al. (2024)
    </span>
    <span class="ltx_bibblock">
     Jungo Kasai, Keisuke Sakaguchi, Ronan Le Bras, Akari Asai, Xinyan Yu, Dragomir Radev, Noah A Smith, Yejin Choi, Kentaro Inui, et al. 2024.
    </span>
    <span class="ltx_bibblock">
     Realtime qa: What’s the answer right now?
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">
      Advances in Neural Information Processing Systems
     </em>
     , 36.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib14">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Katz et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Daniel Martin Katz, Michael James Bommarito, Shang Gao, and Pablo Arredondo. 2023.
    </span>
    <span class="ltx_bibblock">
     Gpt-4 passes the bar exam.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">
      Available at SSRN 4389233
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib15">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Kim et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Geunwoo Kim, Pierre Baldi, and Stephen McAleer. 2023.
    </span>
    <span class="ltx_bibblock">
     Language models can solve computer tasks.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">
      arXiv preprint arXiv:2303.17491
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib16">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Li et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Chengshu Li, Ruohan Zhang, Josiah Wong, Cem Gokmen, Sanjana Srivastava, Roberto Martín-Martín, Chen Wang, Gabrael Levine, Michael Lingelbach, Jiankai Sun, et al. 2023.
    </span>
    <span class="ltx_bibblock">
     Behavior-1k: A benchmark for embodied ai with 1,000 everyday activities and realistic simulation.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">
      Conference on Robot Learning
     </em>
     , pages 80–93. PMLR.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib17">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Li et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Yujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser, Rémi Leblond, Tom Eccles, James Keeling, Felix Gimeno, Agustin Dal Lago, et al. 2022.
    </span>
    <span class="ltx_bibblock">
     Competition-level code generation with alphacode.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">
      Science
     </em>
     , 378(6624):1092–1097.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib18">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Liang et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Yaobo Liang, Chenfei Wu, Ting Song, Wenshan Wu, Yan Xia, Yu Liu, Yang Ou, Shuai Lu, Lei Ji, Shaoguang Mao, et al. 2023.
    </span>
    <span class="ltx_bibblock">
     Taskmatrix. ai: Completing tasks by connecting foundation models with millions of apis.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">
      arXiv preprint arXiv:2303.16434
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib19">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Liu et al. (2018)
    </span>
    <span class="ltx_bibblock">
     Evan Zheran Liu, Kelvin Guu, Panupong Pasupat, Tianlin Shi, and Percy Liang. 2018.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="https://arxiv.org/abs/1802.08802" target="_blank" title="">
      Reinforcement learning on web interfaces using workflow-guided exploration
     </a>
     .
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">
      International Conference on Learning Representations (ICLR)
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib20">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Liu et al. (2023a)
    </span>
    <span class="ltx_bibblock">
     Hanmeng Liu, Ruoxi Ning, Zhiyang Teng, Jian Liu, Qiji Zhou, and Yue Zhang. 2023a.
    </span>
    <span class="ltx_bibblock">
     Evaluating the logical reasoning ability of chatgpt and gpt-4.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">
      arXiv preprint arXiv:2304.03439
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib21">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Liu et al. (2023b)
    </span>
    <span class="ltx_bibblock">
     Jiawei Liu, Chunqiu Steven Xia, Yuyao Wang, and Lingming Zhang. 2023b.
    </span>
    <span class="ltx_bibblock">
     Is your code generated by chatgpt really correct? rigorous evaluation of large language models for code generation.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">
      arXiv preprint arXiv:2305.01210
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib22">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Liu et al. (2023c)
    </span>
    <span class="ltx_bibblock">
     Xiao Liu, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu Lai, Yu Gu, Hangliang Ding, Kaiwen Men, Kejuan Yang, et al. 2023c.
    </span>
    <span class="ltx_bibblock">
     Agentbench: Evaluating llms as agents.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">
      arXiv preprint arXiv:2308.03688
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib23">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Liu et al. (2019)
    </span>
    <span class="ltx_bibblock">
     Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019.
    </span>
    <span class="ltx_bibblock">
     Roberta: A robustly optimized bert pretraining approach.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">
      arXiv preprint arXiv:1907.11692
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib24">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Liu et al. (2023d)
    </span>
    <span class="ltx_bibblock">
     Yugeng Liu, Tianshuo Cong, Zhengyu Zhao, Michael Backes, Yun Shen, and Yang Zhang. 2023d.
    </span>
    <span class="ltx_bibblock">
     Robustness over time: Understanding adversarial examples’ effectiveness on longitudinal versions of large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">
      arXiv preprint arXiv:2308.07847
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib25">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Naik et al. (2018)
    </span>
    <span class="ltx_bibblock">
     Aakanksha Naik, Abhilasha Ravichander, Norman Sadeh, Carolyn Rose, and Graham Neubig. 2018.
    </span>
    <span class="ltx_bibblock">
     Stress test evaluation for natural language inference.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">
      arXiv preprint arXiv:1806.00692
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib26">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Nie et al. (2019)
    </span>
    <span class="ltx_bibblock">
     Yixin Nie, Adina Williams, Emily Dinan, Mohit Bansal, Jason Weston, and Douwe Kiela. 2019.
    </span>
    <span class="ltx_bibblock">
     Adversarial nli: A new benchmark for natural language understanding.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">
      arXiv preprint arXiv:1910.14599
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib27">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     OpenAI (2023)
    </span>
    <span class="ltx_bibblock">
     OpenAI. 2023.
    </span>
    <span class="ltx_bibblock">
     Gpt-4 technical report.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">
      arXiv preprint arXiv:2303.08774
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib28">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Puig et al. (2018)
    </span>
    <span class="ltx_bibblock">
     Xavier Puig, Kevin Ra, Marko Boben, Jiaman Li, Tingwu Wang, Sanja Fidler, and Antonio Torralba. 2018.
    </span>
    <span class="ltx_bibblock">
     Virtualhome: Simulating household activities via programs.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">
      Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition
     </em>
     , pages 8494–8502.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib29">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Qin et al. (2023a)
    </span>
    <span class="ltx_bibblock">
     Chengwei Qin, Aston Zhang, Zhuosheng Zhang, Jiaao Chen, Michihiro Yasunaga, and Diyi Yang. 2023a.
    </span>
    <span class="ltx_bibblock">
     Is chatgpt a general-purpose natural language processing task solver?
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">
      arXiv preprint arXiv:2302.06476
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib30">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Qin et al. (2023b)
    </span>
    <span class="ltx_bibblock">
     Yujia Qin, Shengding Hu, Yankai Lin, Weize Chen, Ning Ding, Ganqu Cui, Zheni Zeng, Yufei Huang, Chaojun Xiao, Chi Han, Yi Ren Fung, Yusheng Su, Huadong Wang, Cheng Qian, Runchu Tian, Kunlun Zhu, Shihao Liang, Xingyu Shen, Bokai Xu, Zhen Zhang, Yining Ye, Bowen Li, Ziwei Tang, Jing Yi, Yuzhang Zhu, Zhenning Dai, Lan Yan, Xin Cong, Yaxi Lu, Weilin Zhao, Yuxiang Huang, Junxi Yan, Xu Han, Xian Sun, Dahai Li, Jason Phang, Cheng Yang, Tongshuang Wu, Heng Ji, Zhiyuan Liu, and Maosong Sun. 2023b.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2304.08354" target="_blank" title="">
      Tool learning with foundation models
     </a>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib31">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Rawles et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Christopher Rawles, Alice Li, Daniel Rodriguez, Oriana Riva, and Timothy Lillicrap. 2023.
    </span>
    <span class="ltx_bibblock">
     Android in the wild: A large-scale dataset for android device control.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">
      arXiv preprint arXiv:2307.10088
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib32">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Ribeiro et al. (2020)
    </span>
    <span class="ltx_bibblock">
     Marco Tulio Ribeiro, Tongshuang Wu, Carlos Guestrin, and Sameer Singh. 2020.
    </span>
    <span class="ltx_bibblock">
     Beyond accuracy: Behavioral testing of nlp models with checklist.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">
      arXiv preprint arXiv:2005.04118
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib33">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Srivastava et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Sanjana Srivastava, Chengshu Li, Michael Lingelbach, Roberto Martín-Martín, Fei Xia, Kent Elliott Vainio, Zheng Lian, Cem Gokmen, Shyamal Buch, Karen Liu, et al. 2022.
    </span>
    <span class="ltx_bibblock">
     Behavior: Benchmark for everyday household activities in virtual, interactive, and ecological environments.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">
      Conference on Robot Learning
     </em>
     , pages 477–490. PMLR.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib34">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Sun et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Hao Sun, Zhexin Zhang, Jiawen Deng, Jiale Cheng, and Minlie Huang. 2023.
    </span>
    <span class="ltx_bibblock">
     Safety assessment of chinese large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">
      arXiv preprint arXiv:2304.10436
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib35">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Touvron et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. 2023.
    </span>
    <span class="ltx_bibblock">
     Llama: Open and efficient foundation language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">
      arXiv preprint arXiv:2302.13971
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib36">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al. (2023a)
    </span>
    <span class="ltx_bibblock">
     Boxin Wang, Weixin Chen, Hengzhi Pei, Chulin Xie, Mintong Kang, Chenhui Zhang, Chejian Xu, Zidi Xiong, Ritik Dutta, Rylan Schaeffer, et al. 2023a.
    </span>
    <span class="ltx_bibblock">
     Decodingtrust: A comprehensive assessment of trustworthiness in gpt models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">
      arXiv preprint arXiv:2306.11698
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib37">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al. (2021)
    </span>
    <span class="ltx_bibblock">
     Boxin Wang, Chejian Xu, Shuohang Wang, Zhe Gan, Yu Cheng, Jianfeng Gao, Ahmed Hassan Awadallah, and Bo Li. 2021.
    </span>
    <span class="ltx_bibblock">
     Adversarial glue: A multi-task benchmark for robustness evaluation of language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">
      arXiv preprint arXiv:2111.02840
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib38">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al. (2023b)
    </span>
    <span class="ltx_bibblock">
     Haoyu Wang, Guozheng Ma, Cong Yu, Ning Gui, Linrui Zhang, Zhiqi Huang, Suwei Ma, Yongzhe Chang, Sen Zhang, Li Shen, et al. 2023b.
    </span>
    <span class="ltx_bibblock">
     Are large language models really robust to word-level perturbations?
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">
      arXiv preprint arXiv:2309.11166
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib39">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al. (2023c)
    </span>
    <span class="ltx_bibblock">
     Jindong Wang, Xixu Hu, Wenxin Hou, Hao Chen, Runkai Zheng, Yidong Wang, Linyi Yang, Haojun Huang, Wei Ye, Xiubo Geng, et al. 2023c.
    </span>
    <span class="ltx_bibblock">
     On the robustness of chatgpt: An adversarial and out-of-distribution perspective.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">
      arXiv preprint arXiv:2302.12095
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib40">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al. (2023d)
    </span>
    <span class="ltx_bibblock">
     Zengzhi Wang, Qiming Xie, Zixiang Ding, Yi Feng, and Rui Xia. 2023d.
    </span>
    <span class="ltx_bibblock">
     Is chatgpt a good sentiment analyzer? a preliminary study.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">
      arXiv preprint arXiv:2304.04339
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib41">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Xu et al. (2023a)
    </span>
    <span class="ltx_bibblock">
     Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu Zhao, Jiazhan Feng, Chongyang Tao, and Daxin Jiang. 2023a.
    </span>
    <span class="ltx_bibblock">
     Wizardlm: Empowering large language models to follow complex instructions.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">
      arXiv preprint arXiv:2304.12244
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib42">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Xu et al. (2023b)
    </span>
    <span class="ltx_bibblock">
     Qiantong Xu, Fenglu Hong, Bo Li, Changran Hu, Zhengyu Chen, and Jian Zhang. 2023b.
    </span>
    <span class="ltx_bibblock">
     On the tool manipulation capability of open-source large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">
      arXiv preprint arXiv:2305.16504
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib43">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yang et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Aiyuan Yang, Bin Xiao, Bingning Wang, Borong Zhang, Chao Yin, Chenxu Lv, Da Pan, Dian Wang, Dong Yan, Fan Yang, et al. 2023.
    </span>
    <span class="ltx_bibblock">
     Baichuan 2: Open large-scale language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">
      arXiv preprint arXiv:2309.10305
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib44">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yao et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Shunyu Yao, Howard Chen, John Yang, and Karthik Narasimhan. 2022.
    </span>
    <span class="ltx_bibblock">
     Webshop: Towards scalable real-world web interaction with grounded language agents.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib44.1.1">
      Advances in Neural Information Processing Systems
     </em>
     , 35:20744–20757.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib45">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yu and Rieser (2023)
    </span>
    <span class="ltx_bibblock">
     Lu Yu and Verena Rieser. 2023.
    </span>
    <span class="ltx_bibblock">
     Adversarial textual robustness on visual dialog.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib45.1.1">
      Findings of the Association for Computational Linguistics: ACL 2023
     </em>
     , pages 3422–3438.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib46">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhong et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Wanjun Zhong, Ruixiang Cui, Yiduo Guo, Yaobo Liang, Shuai Lu, Yanlin Wang, Amin Saied, Weizhu Chen, and Nan Duan. 2023.
    </span>
    <span class="ltx_bibblock">
     Agieval: A human-centric benchmark for evaluating foundation models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib46.1.1">
      arXiv preprint arXiv:2304.06364
     </em>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib47">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhu et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Kaijie Zhu, Jindong Wang, Jiaheng Zhou, Zichen Wang, Hao Chen, Yidong Wang, Linyi Yang, Wei Ye, Neil Zhenqiang Gong, Yue Zhang, et al. 2023.
    </span>
    <span class="ltx_bibblock">
     Promptbench: Towards evaluating the robustness of large language models on adversarial prompts.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib47.1.1">
      arXiv preprint arXiv:2306.04528
     </em>
     .
    </span>
   </li>
  </ul>
 </section>
 <section class="ltx_appendix" id="A1">
  <h2 class="ltx_title ltx_title_appendix">
   <span class="ltx_tag ltx_tag_appendix">
    Appendix A
   </span>
   Basic APIs in the API lack setting
  </h2>
  <div class="ltx_para" id="A1.p1">
   <p class="ltx_p" id="A1.p1.1">
    We list the APIs used in the API lack setting in Figure
    <a class="ltx_ref" href="#A1.F6" title="Figure 6 ‣ Appendix A Basic APIs in the API lack setting ‣ PPTC-R benchmark: Towards Evaluating the Robustness of Large Language Models for PowerPoint Task Completion">
     <span class="ltx_text ltx_ref_tag">
      6
     </span>
    </a>
    <math alttext="\&amp;" class="ltx_Math" display="inline" id="A1.p1.1.m1.1">
     <semantics id="A1.p1.1.m1.1a">
      <mo id="A1.p1.1.m1.1.1" xref="A1.p1.1.m1.1.1.cmml">
       &amp;
      </mo>
      <annotation-xml encoding="MathML-Content" id="A1.p1.1.m1.1b">
       <and id="A1.p1.1.m1.1.1.cmml" xref="A1.p1.1.m1.1.1">
       </and>
      </annotation-xml>
      <annotation encoding="application/x-tex" id="A1.p1.1.m1.1c">
       \&amp;
      </annotation>
     </semantics>
    </math>
    <a class="ltx_ref" href="#A1.F7" title="Figure 7 ‣ Appendix A Basic APIs in the API lack setting ‣ PPTC-R benchmark: Towards Evaluating the Robustness of Large Language Models for PowerPoint Task Completion">
     <span class="ltx_text ltx_ref_tag">
      7
     </span>
    </a>
    . We select them as they provide basic functions in PowerPoint software with high usage frequency in the benchmark.
   </p>
  </div>
  <figure class="ltx_figure" id="A1.F6">
   <svg class="ltx_picture" height="708.42" id="A1.F6.pic1" overflow="visible" version="1.1" width="600">
    <g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,708.42) matrix(1 0 0 -1 0 0)">
     <g fill="#00A600" fill-opacity="1.0">
      <path d="M 0 5.91 L 0 702.51 C 0 705.78 2.64 708.42 5.91 708.42 L 594.09 708.42 C 597.36 708.42 600 705.78 600 702.51 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none">
      </path>
     </g>
     <g fill="#FFFFFF" fill-opacity="1.0">
      <path d="M 1.97 5.91 L 1.97 687 L 598.03 687 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none">
      </path>
     </g>
     <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 692.9)">
      <foreignobject color="#FFFFFF" height="9.61" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">
       <span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A1.F6.pic1.49.49.49.1.1" style="width:402.3pt;">
        <span class="ltx_p" id="A1.F6.pic1.49.49.49.1.1.1">
         <span class="ltx_text ltx_font_bold" id="A1.F6.pic1.49.49.49.1.1.1.1">
          API reference file
         </span>
        </span>
       </span>
      </foreignobject>
     </g>
     <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)">
      <foreignobject color="#000000" height="661.41" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">
       <span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A1.F6.pic1.48.48.48.48.48.48.48.48.48.48.48.48.48.48.48.48.48" style="width:402.3pt;">
        <span class="ltx_p" id="A1.F6.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1">
         API: create
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F6.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1">
          <semantics id="A1.F6.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1a">
           <mi id="A1.F6.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1" mathvariant="normal" xref="A1.F6.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F6.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1b">
            <ci id="A1.F6.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="A1.F6.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F6.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1c">
            \_
           </annotation>
          </semantics>
         </math>
         slide(): This API creates a new slide.
        </span>
        <span class="ltx_p" id="A1.F6.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3">
         API: set
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F6.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m1.1">
          <semantics id="A1.F6.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m1.1a">
           <mi id="A1.F6.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m1.1.1" mathvariant="normal" xref="A1.F6.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m1.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F6.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m1.1b">
            <ci id="A1.F6.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m1.1.1.cmml" xref="A1.F6.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m1.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F6.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m1.1c">
            \_
           </annotation>
          </semantics>
         </math>
         background
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F6.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m2.1">
          <semantics id="A1.F6.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m2.1a">
           <mi id="A1.F6.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m2.1.1" mathvariant="normal" xref="A1.F6.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m2.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F6.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m2.1b">
            <ci id="A1.F6.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m2.1.1.cmml" xref="A1.F6.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m2.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F6.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m2.1c">
            \_
           </annotation>
          </semantics>
         </math>
         color(color): This API sets the background color of the slide.
It takes one parameter ’color’, the color name to set as a string, such as ’red’, ’purple’.
        </span>
        <span class="ltx_p" id="A1.F6.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5">
         API: choose
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F6.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m1.1">
          <semantics id="A1.F6.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m1.1a">
           <mi id="A1.F6.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m1.1.1" mathvariant="normal" xref="A1.F6.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m1.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F6.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m1.1b">
            <ci id="A1.F6.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m1.1.1.cmml" xref="A1.F6.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m1.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F6.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m1.1c">
            \_
           </annotation>
          </semantics>
         </math>
         title(): This API selects the title on the slide.
You should first call choose
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F6.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m2.1">
          <semantics id="A1.F6.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m2.1a">
           <mi id="A1.F6.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m2.1.1" mathvariant="normal" xref="A1.F6.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m2.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F6.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m2.1b">
            <ci id="A1.F6.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m2.1.1.cmml" xref="A1.F6.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m2.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F6.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m2.1c">
            \_
           </annotation>
          </semantics>
         </math>
         title() before inserting text to or changing font attributes of the title.
        </span>
        <span class="ltx_p" id="A1.F6.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7">
         API: choose
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F6.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m1.1">
          <semantics id="A1.F6.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m1.1a">
           <mi id="A1.F6.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m1.1.1" mathvariant="normal" xref="A1.F6.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m1.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F6.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m1.1b">
            <ci id="A1.F6.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m1.1.1.cmml" xref="A1.F6.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m1.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F6.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m1.1c">
            \_
           </annotation>
          </semantics>
         </math>
         content(): This API select the content on the slide.
You should first call choose
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F6.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m2.1">
          <semantics id="A1.F6.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m2.1a">
           <mi id="A1.F6.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m2.1.1" mathvariant="normal" xref="A1.F6.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m2.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F6.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m2.1b">
            <ci id="A1.F6.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m2.1.1.cmml" xref="A1.F6.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m2.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F6.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m2.1c">
            \_
           </annotation>
          </semantics>
         </math>
         content() before inserting text to or changing font attributes of the content.
        </span>
        <span class="ltx_p" id="A1.F6.pic1.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9">
         API: choose
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F6.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.m1.1">
          <semantics id="A1.F6.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.m1.1a">
           <mi id="A1.F6.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.m1.1.1" mathvariant="normal" xref="A1.F6.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.m1.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F6.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.m1.1b">
            <ci id="A1.F6.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.m1.1.1.cmml" xref="A1.F6.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.m1.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F6.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.m1.1c">
            \_
           </annotation>
          </semantics>
         </math>
         textbox(idx): This API selects the textbox element on the slide.
It takes one parameter, the index of textbox as integer. idx is set to 0 by default, meaning the first textbox.
You should first call choose
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F6.pic1.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.m2.1">
          <semantics id="A1.F6.pic1.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.m2.1a">
           <mi id="A1.F6.pic1.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.m2.1.1" mathvariant="normal" xref="A1.F6.pic1.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.m2.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F6.pic1.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.m2.1b">
            <ci id="A1.F6.pic1.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.m2.1.1.cmml" xref="A1.F6.pic1.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.m2.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F6.pic1.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.m2.1c">
            \_
           </annotation>
          </semantics>
         </math>
         textbox() before inserting text to or changing font attributes of the textbox element.
        </span>
        <span class="ltx_p" id="A1.F6.pic1.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12">
         API: choose
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F6.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.m1.1">
          <semantics id="A1.F6.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.m1.1a">
           <mi id="A1.F6.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.m1.1.1" mathvariant="normal" xref="A1.F6.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.m1.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F6.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.m1.1b">
            <ci id="A1.F6.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.m1.1.1.cmml" xref="A1.F6.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.m1.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F6.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.m1.1c">
            \_
           </annotation>
          </semantics>
         </math>
         picture(idx): This API selects the picture element on the slide.
It takes one parameter, the index of textbox as integer. idx is set to 0 by default, meaning the first textbox.
You should first call choose
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F6.pic1.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.m2.1">
          <semantics id="A1.F6.pic1.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.m2.1a">
           <mi id="A1.F6.pic1.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.m2.1.1" mathvariant="normal" xref="A1.F6.pic1.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.m2.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F6.pic1.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.m2.1b">
            <ci id="A1.F6.pic1.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.m2.1.1.cmml" xref="A1.F6.pic1.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.m2.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F6.pic1.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.m2.1c">
            \_
           </annotation>
          </semantics>
         </math>
         picture() before changing height, width, rotation of the picture element. You should not call choose
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F6.pic1.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.m3.1">
          <semantics id="A1.F6.pic1.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.m3.1a">
           <mi id="A1.F6.pic1.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.m3.1.1" mathvariant="normal" xref="A1.F6.pic1.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.m3.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F6.pic1.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.m3.1b">
            <ci id="A1.F6.pic1.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.m3.1.1.cmml" xref="A1.F6.pic1.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.m3.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F6.pic1.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.m3.1c">
            \_
           </annotation>
          </semantics>
         </math>
         picture() before inserting picture element.
        </span>
        <span class="ltx_p" id="A1.F6.pic1.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22">
         API: choose
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F6.pic1.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.m1.1">
          <semantics id="A1.F6.pic1.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.m1.1a">
           <mi id="A1.F6.pic1.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.m1.1.1" mathvariant="normal" xref="A1.F6.pic1.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.m1.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F6.pic1.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.m1.1b">
            <ci id="A1.F6.pic1.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.m1.1.1.cmml" xref="A1.F6.pic1.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.m1.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F6.pic1.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.m1.1c">
            \_
           </annotation>
          </semantics>
         </math>
         shape(shape
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F6.pic1.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.m2.1">
          <semantics id="A1.F6.pic1.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.m2.1a">
           <mi id="A1.F6.pic1.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.m2.1.1" mathvariant="normal" xref="A1.F6.pic1.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.m2.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F6.pic1.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.m2.1b">
            <ci id="A1.F6.pic1.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.m2.1.1.cmml" xref="A1.F6.pic1.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.m2.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F6.pic1.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.m2.1c">
            \_
           </annotation>
          </semantics>
         </math>
         name): This API selects a specific shape by shape name on the slide.
It takes one parameter ’shape
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F6.pic1.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.m3.1">
          <semantics id="A1.F6.pic1.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.m3.1a">
           <mi id="A1.F6.pic1.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.m3.1.1" mathvariant="normal" xref="A1.F6.pic1.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.m3.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F6.pic1.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.m3.1b">
            <ci id="A1.F6.pic1.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.m3.1.1.cmml" xref="A1.F6.pic1.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.m3.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F6.pic1.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.m3.1c">
            \_
           </annotation>
          </semantics>
         </math>
         name’, the name of the shape to select as a string. shape
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F6.pic1.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.m4.1">
          <semantics id="A1.F6.pic1.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.m4.1a">
           <mi id="A1.F6.pic1.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.m4.1.1" mathvariant="normal" xref="A1.F6.pic1.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.m4.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F6.pic1.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.m4.1b">
            <ci id="A1.F6.pic1.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.m4.1.1.cmml" xref="A1.F6.pic1.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.m4.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F6.pic1.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.m4.1c">
            \_
           </annotation>
          </semantics>
         </math>
         name can be chosen from [’rectangle’,’right
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F6.pic1.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.m5.1">
          <semantics id="A1.F6.pic1.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.m5.1a">
           <mi id="A1.F6.pic1.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.m5.1.1" mathvariant="normal" xref="A1.F6.pic1.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.m5.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F6.pic1.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.m5.1b">
            <ci id="A1.F6.pic1.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.m5.1.1.cmml" xref="A1.F6.pic1.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.m5.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F6.pic1.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.m5.1c">
            \_
           </annotation>
          </semantics>
         </math>
         arrow’,’rounded
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F6.pic1.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.m6.1">
          <semantics id="A1.F6.pic1.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.m6.1a">
           <mi id="A1.F6.pic1.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.m6.1.1" mathvariant="normal" xref="A1.F6.pic1.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.m6.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F6.pic1.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.m6.1b">
            <ci id="A1.F6.pic1.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.m6.1.1.cmml" xref="A1.F6.pic1.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.m6.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F6.pic1.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.m6.1c">
            \_
           </annotation>
          </semantics>
         </math>
         rectangle’,’triangle’,’callout’,’cloud’,’star’,’circle’]
You should first call choose
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F6.pic1.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.m7.1">
          <semantics id="A1.F6.pic1.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.m7.1a">
           <mi id="A1.F6.pic1.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.m7.1.1" mathvariant="normal" xref="A1.F6.pic1.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.m7.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F6.pic1.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.m7.1b">
            <ci id="A1.F6.pic1.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.m7.1.1.cmml" xref="A1.F6.pic1.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.m7.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F6.pic1.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.19.m7.1c">
            \_
           </annotation>
          </semantics>
         </math>
         shape(shape
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F6.pic1.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.m8.1">
          <semantics id="A1.F6.pic1.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.m8.1a">
           <mi id="A1.F6.pic1.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.m8.1.1" mathvariant="normal" xref="A1.F6.pic1.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.m8.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F6.pic1.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.m8.1b">
            <ci id="A1.F6.pic1.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.m8.1.1.cmml" xref="A1.F6.pic1.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.m8.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F6.pic1.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.20.m8.1c">
            \_
           </annotation>
          </semantics>
         </math>
         name) before you can do operations on the shape. You should not call choose
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F6.pic1.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.m9.1">
          <semantics id="A1.F6.pic1.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.m9.1a">
           <mi id="A1.F6.pic1.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.m9.1.1" mathvariant="normal" xref="A1.F6.pic1.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.m9.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F6.pic1.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.m9.1b">
            <ci id="A1.F6.pic1.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.m9.1.1.cmml" xref="A1.F6.pic1.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.m9.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F6.pic1.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.21.m9.1c">
            \_
           </annotation>
          </semantics>
         </math>
         shape(shape
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F6.pic1.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.m10.1">
          <semantics id="A1.F6.pic1.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.m10.1a">
           <mi id="A1.F6.pic1.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.m10.1.1" mathvariant="normal" xref="A1.F6.pic1.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.m10.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F6.pic1.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.m10.1b">
            <ci id="A1.F6.pic1.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.m10.1.1.cmml" xref="A1.F6.pic1.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.m10.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F6.pic1.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.22.m10.1c">
            \_
           </annotation>
          </semantics>
         </math>
         name) before inserting shape element.
        </span>
        <span class="ltx_p" id="A1.F6.pic1.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25">
         API: choose
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F6.pic1.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.m1.1">
          <semantics id="A1.F6.pic1.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.m1.1a">
           <mi id="A1.F6.pic1.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.m1.1.1" mathvariant="normal" xref="A1.F6.pic1.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.m1.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F6.pic1.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.m1.1b">
            <ci id="A1.F6.pic1.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.m1.1.1.cmml" xref="A1.F6.pic1.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.m1.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F6.pic1.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.23.m1.1c">
            \_
           </annotation>
          </semantics>
         </math>
         table(): This API selects the table element on the slide.
You should first call choose
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F6.pic1.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.m2.1">
          <semantics id="A1.F6.pic1.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.m2.1a">
           <mi id="A1.F6.pic1.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.m2.1.1" mathvariant="normal" xref="A1.F6.pic1.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.m2.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F6.pic1.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.m2.1b">
            <ci id="A1.F6.pic1.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.m2.1.1.cmml" xref="A1.F6.pic1.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.m2.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F6.pic1.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.24.m2.1c">
            \_
           </annotation>
          </semantics>
         </math>
         table() before changing the table. You should not call choose
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F6.pic1.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.m3.1">
          <semantics id="A1.F6.pic1.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.m3.1a">
           <mi id="A1.F6.pic1.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.m3.1.1" mathvariant="normal" xref="A1.F6.pic1.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.m3.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F6.pic1.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.m3.1b">
            <ci id="A1.F6.pic1.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.m3.1.1.cmml" xref="A1.F6.pic1.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.m3.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F6.pic1.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.25.m3.1c">
            \_
           </annotation>
          </semantics>
         </math>
         table() before inserting table element.
        </span>
        <span class="ltx_p" id="A1.F6.pic1.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35">
         API: choose
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F6.pic1.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.m1.1">
          <semantics id="A1.F6.pic1.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.m1.1a">
           <mi id="A1.F6.pic1.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.m1.1.1" mathvariant="normal" xref="A1.F6.pic1.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.m1.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F6.pic1.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.m1.1b">
            <ci id="A1.F6.pic1.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.m1.1.1.cmml" xref="A1.F6.pic1.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.m1.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F6.pic1.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.26.m1.1c">
            \_
           </annotation>
          </semantics>
         </math>
         table
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F6.pic1.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.m2.1">
          <semantics id="A1.F6.pic1.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.m2.1a">
           <mi id="A1.F6.pic1.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.m2.1.1" mathvariant="normal" xref="A1.F6.pic1.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.m2.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F6.pic1.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.m2.1b">
            <ci id="A1.F6.pic1.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.m2.1.1.cmml" xref="A1.F6.pic1.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.m2.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F6.pic1.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.27.m2.1c">
            \_
           </annotation>
          </semantics>
         </math>
         cell(row
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F6.pic1.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.m3.1">
          <semantics id="A1.F6.pic1.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.m3.1a">
           <mi id="A1.F6.pic1.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.m3.1.1" mathvariant="normal" xref="A1.F6.pic1.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.m3.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F6.pic1.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.m3.1b">
            <ci id="A1.F6.pic1.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.m3.1.1.cmml" xref="A1.F6.pic1.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.m3.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F6.pic1.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.28.m3.1c">
            \_
           </annotation>
          </semantics>
         </math>
         id, column
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F6.pic1.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.m4.1">
          <semantics id="A1.F6.pic1.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.m4.1a">
           <mi id="A1.F6.pic1.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.m4.1.1" mathvariant="normal" xref="A1.F6.pic1.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.m4.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F6.pic1.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.m4.1b">
            <ci id="A1.F6.pic1.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.m4.1.1.cmml" xref="A1.F6.pic1.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.m4.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F6.pic1.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.29.m4.1c">
            \_
           </annotation>
          </semantics>
         </math>
         id): This API selects a specific cell in the table by giving row
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F6.pic1.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.m5.1">
          <semantics id="A1.F6.pic1.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.m5.1a">
           <mi id="A1.F6.pic1.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.m5.1.1" mathvariant="normal" xref="A1.F6.pic1.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.m5.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F6.pic1.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.m5.1b">
            <ci id="A1.F6.pic1.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.m5.1.1.cmml" xref="A1.F6.pic1.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.m5.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F6.pic1.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.30.m5.1c">
            \_
           </annotation>
          </semantics>
         </math>
         id and column
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F6.pic1.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.m6.1">
          <semantics id="A1.F6.pic1.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.m6.1a">
           <mi id="A1.F6.pic1.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.m6.1.1" mathvariant="normal" xref="A1.F6.pic1.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.m6.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F6.pic1.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.m6.1b">
            <ci id="A1.F6.pic1.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.m6.1.1.cmml" xref="A1.F6.pic1.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.m6.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F6.pic1.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.31.m6.1c">
            \_
           </annotation>
          </semantics>
         </math>
         id.
It takes two parameters, the row id and column id of the cell to select as integers (id starts from 0). Remember the first parameter is row id, the second parameter is column id.
You should first call choose
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F6.pic1.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.m7.1">
          <semantics id="A1.F6.pic1.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.m7.1a">
           <mi id="A1.F6.pic1.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.m7.1.1" mathvariant="normal" xref="A1.F6.pic1.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.m7.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F6.pic1.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.m7.1b">
            <ci id="A1.F6.pic1.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.m7.1.1.cmml" xref="A1.F6.pic1.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.m7.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F6.pic1.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.32.m7.1c">
            \_
           </annotation>
          </semantics>
         </math>
         table
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F6.pic1.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.m8.1">
          <semantics id="A1.F6.pic1.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.m8.1a">
           <mi id="A1.F6.pic1.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.m8.1.1" mathvariant="normal" xref="A1.F6.pic1.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.m8.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F6.pic1.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.m8.1b">
            <ci id="A1.F6.pic1.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.m8.1.1.cmml" xref="A1.F6.pic1.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.m8.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F6.pic1.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.33.m8.1c">
            \_
           </annotation>
          </semantics>
         </math>
         cell(row
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F6.pic1.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.m9.1">
          <semantics id="A1.F6.pic1.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.m9.1a">
           <mi id="A1.F6.pic1.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.m9.1.1" mathvariant="normal" xref="A1.F6.pic1.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.m9.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F6.pic1.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.m9.1b">
            <ci id="A1.F6.pic1.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.m9.1.1.cmml" xref="A1.F6.pic1.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.m9.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F6.pic1.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.34.m9.1c">
            \_
           </annotation>
          </semantics>
         </math>
         id, column
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F6.pic1.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.m10.1">
          <semantics id="A1.F6.pic1.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.m10.1a">
           <mi id="A1.F6.pic1.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.m10.1.1" mathvariant="normal" xref="A1.F6.pic1.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.m10.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F6.pic1.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.m10.1b">
            <ci id="A1.F6.pic1.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.m10.1.1.cmml" xref="A1.F6.pic1.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.m10.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F6.pic1.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.35.m10.1c">
            \_
           </annotation>
          </semantics>
         </math>
         id) before inserting text into a specific cell of the table.
        </span>
        <span class="ltx_p" id="A1.F6.pic1.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36">
         API: set
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F6.pic1.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.m1.1">
          <semantics id="A1.F6.pic1.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.m1.1a">
           <mi id="A1.F6.pic1.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.m1.1.1" mathvariant="normal" xref="A1.F6.pic1.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.m1.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F6.pic1.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.m1.1b">
            <ci id="A1.F6.pic1.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.m1.1.1.cmml" xref="A1.F6.pic1.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.m1.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F6.pic1.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.36.m1.1c">
            \_
           </annotation>
          </semantics>
         </math>
         width(width): This API sets the width of the selected object.
It takes one parameter ’width’, the width of an object in centimeters as float.
You should first choose an object before you can change the width of it.
        </span>
        <span class="ltx_p" id="A1.F6.pic1.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37">
         API: set
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F6.pic1.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.m1.1">
          <semantics id="A1.F6.pic1.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.m1.1a">
           <mi id="A1.F6.pic1.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.m1.1.1" mathvariant="normal" xref="A1.F6.pic1.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.m1.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F6.pic1.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.m1.1b">
            <ci id="A1.F6.pic1.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.m1.1.1.cmml" xref="A1.F6.pic1.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.m1.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F6.pic1.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.37.m1.1c">
            \_
           </annotation>
          </semantics>
         </math>
         height(height): This API sets the height of the selected object.
It takes one parameter ’height’, the height of an object in centimeters as float.
You should first choose an object before you can change the height of it
        </span>
        <span class="ltx_p" id="A1.F6.pic1.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38">
         API: set
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F6.pic1.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.m1.1">
          <semantics id="A1.F6.pic1.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.m1.1a">
           <mi id="A1.F6.pic1.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.m1.1.1" mathvariant="normal" xref="A1.F6.pic1.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.m1.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F6.pic1.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.m1.1b">
            <ci id="A1.F6.pic1.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.m1.1.1.cmml" xref="A1.F6.pic1.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.m1.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F6.pic1.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.38.m1.1c">
            \_
           </annotation>
          </semantics>
         </math>
         left(left): This API moves and changes the object’s position. It sets the x position of the selected object’s leftmost point.
It takes one parameter, the x position to set.
You should first choose an object before you can change the left of it
        </span>
        <span class="ltx_p" id="A1.F6.pic1.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39">
         API: set
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F6.pic1.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.m1.1">
          <semantics id="A1.F6.pic1.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.m1.1a">
           <mi id="A1.F6.pic1.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.m1.1.1" mathvariant="normal" xref="A1.F6.pic1.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.m1.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F6.pic1.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.m1.1b">
            <ci id="A1.F6.pic1.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.m1.1.1.cmml" xref="A1.F6.pic1.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.m1.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F6.pic1.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.39.m1.1c">
            \_
           </annotation>
          </semantics>
         </math>
         top(top): This API moves and changes the object’s position. It sets the y position of the selected object’s upmost point.
It takes one parameter, the y position to set.
You should first choose an object before you can change the top of it
        </span>
        <span class="ltx_p" id="A1.F6.pic1.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40">
         API: insert
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F6.pic1.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.m1.1">
          <semantics id="A1.F6.pic1.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.m1.1a">
           <mi id="A1.F6.pic1.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.m1.1.1" mathvariant="normal" xref="A1.F6.pic1.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.m1.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F6.pic1.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.m1.1b">
            <ci id="A1.F6.pic1.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.m1.1.1.cmml" xref="A1.F6.pic1.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.m1.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F6.pic1.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.40.m1.1c">
            \_
           </annotation>
          </semantics>
         </math>
         text(text): This API inserts text into a text frame (textbox, title, content, table).
        </span>
        <span class="ltx_p" id="A1.F6.pic1.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44">
         API: set
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F6.pic1.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.m1.1">
          <semantics id="A1.F6.pic1.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.m1.1a">
           <mi id="A1.F6.pic1.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.m1.1.1" mathvariant="normal" xref="A1.F6.pic1.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.m1.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F6.pic1.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.m1.1b">
            <ci id="A1.F6.pic1.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.m1.1.1.cmml" xref="A1.F6.pic1.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.m1.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F6.pic1.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.41.m1.1c">
            \_
           </annotation>
          </semantics>
         </math>
         font
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F6.pic1.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.m2.1">
          <semantics id="A1.F6.pic1.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.m2.1a">
           <mi id="A1.F6.pic1.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.m2.1.1" mathvariant="normal" xref="A1.F6.pic1.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.m2.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F6.pic1.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.m2.1b">
            <ci id="A1.F6.pic1.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.m2.1.1.cmml" xref="A1.F6.pic1.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.m2.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F6.pic1.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.42.m2.1c">
            \_
           </annotation>
          </semantics>
         </math>
         size(font
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F6.pic1.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.m3.1">
          <semantics id="A1.F6.pic1.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.m3.1a">
           <mi id="A1.F6.pic1.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.m3.1.1" mathvariant="normal" xref="A1.F6.pic1.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.m3.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F6.pic1.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.m3.1b">
            <ci id="A1.F6.pic1.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.m3.1.1.cmml" xref="A1.F6.pic1.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.m3.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F6.pic1.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.43.m3.1c">
            \_
           </annotation>
          </semantics>
         </math>
         size): This API sets the size of the font
It can take one argument ’font
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F6.pic1.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.m4.1">
          <semantics id="A1.F6.pic1.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.m4.1a">
           <mi id="A1.F6.pic1.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.m4.1.1" mathvariant="normal" xref="A1.F6.pic1.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.m4.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F6.pic1.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.m4.1b">
            <ci id="A1.F6.pic1.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.m4.1.1.cmml" xref="A1.F6.pic1.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.m4.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F6.pic1.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.44.m4.1c">
            \_
           </annotation>
          </semantics>
         </math>
         size’, the font size to set as an integer.
        </span>
        <span class="ltx_p" id="A1.F6.pic1.46.46.46.46.46.46.46.46.46.46.46.46.46.46.46.46.46.46">
         API: set
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F6.pic1.45.45.45.45.45.45.45.45.45.45.45.45.45.45.45.45.45.45.m1.1">
          <semantics id="A1.F6.pic1.45.45.45.45.45.45.45.45.45.45.45.45.45.45.45.45.45.45.m1.1a">
           <mi id="A1.F6.pic1.45.45.45.45.45.45.45.45.45.45.45.45.45.45.45.45.45.45.m1.1.1" mathvariant="normal" xref="A1.F6.pic1.45.45.45.45.45.45.45.45.45.45.45.45.45.45.45.45.45.45.m1.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F6.pic1.45.45.45.45.45.45.45.45.45.45.45.45.45.45.45.45.45.45.m1.1b">
            <ci id="A1.F6.pic1.45.45.45.45.45.45.45.45.45.45.45.45.45.45.45.45.45.45.m1.1.1.cmml" xref="A1.F6.pic1.45.45.45.45.45.45.45.45.45.45.45.45.45.45.45.45.45.45.m1.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F6.pic1.45.45.45.45.45.45.45.45.45.45.45.45.45.45.45.45.45.45.m1.1c">
            \_
           </annotation>
          </semantics>
         </math>
         font
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F6.pic1.46.46.46.46.46.46.46.46.46.46.46.46.46.46.46.46.46.46.m2.1">
          <semantics id="A1.F6.pic1.46.46.46.46.46.46.46.46.46.46.46.46.46.46.46.46.46.46.m2.1a">
           <mi id="A1.F6.pic1.46.46.46.46.46.46.46.46.46.46.46.46.46.46.46.46.46.46.m2.1.1" mathvariant="normal" xref="A1.F6.pic1.46.46.46.46.46.46.46.46.46.46.46.46.46.46.46.46.46.46.m2.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F6.pic1.46.46.46.46.46.46.46.46.46.46.46.46.46.46.46.46.46.46.m2.1b">
            <ci id="A1.F6.pic1.46.46.46.46.46.46.46.46.46.46.46.46.46.46.46.46.46.46.m2.1.1.cmml" xref="A1.F6.pic1.46.46.46.46.46.46.46.46.46.46.46.46.46.46.46.46.46.46.m2.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F6.pic1.46.46.46.46.46.46.46.46.46.46.46.46.46.46.46.46.46.46.m2.1c">
            \_
           </annotation>
          </semantics>
         </math>
         color(color): This API sets the color of the font.
It takes one parameter ’color’, the color name to set as a string, such as ’red’, ’purple’.
        </span>
        <span class="ltx_p" id="A1.F6.pic1.48.48.48.48.48.48.48.48.48.48.48.48.48.48.48.48.48.48">
         API: set
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F6.pic1.47.47.47.47.47.47.47.47.47.47.47.47.47.47.47.47.47.47.m1.1">
          <semantics id="A1.F6.pic1.47.47.47.47.47.47.47.47.47.47.47.47.47.47.47.47.47.47.m1.1a">
           <mi id="A1.F6.pic1.47.47.47.47.47.47.47.47.47.47.47.47.47.47.47.47.47.47.m1.1.1" mathvariant="normal" xref="A1.F6.pic1.47.47.47.47.47.47.47.47.47.47.47.47.47.47.47.47.47.47.m1.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F6.pic1.47.47.47.47.47.47.47.47.47.47.47.47.47.47.47.47.47.47.m1.1b">
            <ci id="A1.F6.pic1.47.47.47.47.47.47.47.47.47.47.47.47.47.47.47.47.47.47.m1.1.1.cmml" xref="A1.F6.pic1.47.47.47.47.47.47.47.47.47.47.47.47.47.47.47.47.47.47.m1.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F6.pic1.47.47.47.47.47.47.47.47.47.47.47.47.47.47.47.47.47.47.m1.1c">
            \_
           </annotation>
          </semantics>
         </math>
         font
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F6.pic1.48.48.48.48.48.48.48.48.48.48.48.48.48.48.48.48.48.48.m2.1">
          <semantics id="A1.F6.pic1.48.48.48.48.48.48.48.48.48.48.48.48.48.48.48.48.48.48.m2.1a">
           <mi id="A1.F6.pic1.48.48.48.48.48.48.48.48.48.48.48.48.48.48.48.48.48.48.m2.1.1" mathvariant="normal" xref="A1.F6.pic1.48.48.48.48.48.48.48.48.48.48.48.48.48.48.48.48.48.48.m2.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F6.pic1.48.48.48.48.48.48.48.48.48.48.48.48.48.48.48.48.48.48.m2.1b">
            <ci id="A1.F6.pic1.48.48.48.48.48.48.48.48.48.48.48.48.48.48.48.48.48.48.m2.1.1.cmml" xref="A1.F6.pic1.48.48.48.48.48.48.48.48.48.48.48.48.48.48.48.48.48.48.m2.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F6.pic1.48.48.48.48.48.48.48.48.48.48.48.48.48.48.48.48.48.48.m2.1c">
            \_
           </annotation>
          </semantics>
         </math>
         bold(): This API sets the font to be bold.
        </span>
       </span>
      </foreignobject>
     </g>
    </g>
   </svg>
   <figcaption class="ltx_caption">
    <span class="ltx_tag ltx_tag_figure">
     Figure 6:
    </span>
    The reference API file in the API-lack setting.
   </figcaption>
  </figure>
  <figure class="ltx_figure" id="A1.F7">
   <svg class="ltx_picture" height="275.17" id="A1.F7.pic1" overflow="visible" version="1.1" width="600">
    <g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,275.17) matrix(1 0 0 -1 0 0)">
     <g fill="#00A600" fill-opacity="1.0">
      <path d="M 0 5.91 L 0 269.26 C 0 272.52 2.64 275.17 5.91 275.17 L 594.09 275.17 C 597.36 275.17 600 272.52 600 269.26 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none">
      </path>
     </g>
     <g fill="#FFFFFF" fill-opacity="1.0">
      <path d="M 1.97 5.91 L 1.97 253.75 L 598.03 253.75 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none">
      </path>
     </g>
     <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 259.65)">
      <foreignobject color="#FFFFFF" height="9.61" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">
       <span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A1.F7.pic1.19.19.19.1.1" style="width:402.3pt;">
        <span class="ltx_p" id="A1.F7.pic1.19.19.19.1.1.1">
         <span class="ltx_text ltx_font_bold" id="A1.F7.pic1.19.19.19.1.1.1.1">
          API reference file
         </span>
        </span>
       </span>
      </foreignobject>
     </g>
     <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)">
      <foreignobject color="#000000" height="228.16" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">
       <span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A1.F7.pic1.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18" style="width:402.3pt;">
        <span class="ltx_p" id="A1.F7.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3">
         API: insert
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1">
          <semantics id="A1.F7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1a">
           <mi id="A1.F7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1" mathvariant="normal" xref="A1.F7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1b">
            <ci id="A1.F7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="A1.F7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1c">
            \_
           </annotation>
          </semantics>
         </math>
         picture(picture
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F7.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1">
          <semantics id="A1.F7.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1a">
           <mi id="A1.F7.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1" mathvariant="normal" xref="A1.F7.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F7.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1b">
            <ci id="A1.F7.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.cmml" xref="A1.F7.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F7.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1c">
            \_
           </annotation>
          </semantics>
         </math>
         name): This API inserts a picture onto the slide.
It takes one parameter ’picture
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F7.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1">
          <semantics id="A1.F7.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1a">
           <mi id="A1.F7.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1" mathvariant="normal" xref="A1.F7.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F7.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1b">
            <ci id="A1.F7.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1.cmml" xref="A1.F7.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F7.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1c">
            \_
           </annotation>
          </semantics>
         </math>
         name’, the name or description of picture as a string
        </span>
        <span class="ltx_p" id="A1.F7.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4">
         API: insert
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F7.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m1.1">
          <semantics id="A1.F7.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m1.1a">
           <mi id="A1.F7.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m1.1.1" mathvariant="normal" xref="A1.F7.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m1.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F7.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m1.1b">
            <ci id="A1.F7.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m1.1.1.cmml" xref="A1.F7.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m1.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F7.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m1.1c">
            \_
           </annotation>
          </semantics>
         </math>
         rectangle(): This API inserts a rectangle or square shape onto the slide.
        </span>
        <span class="ltx_p" id="A1.F7.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6">
         API: insert
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m1.1">
          <semantics id="A1.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m1.1a">
           <mi id="A1.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m1.1.1" mathvariant="normal" xref="A1.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m1.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m1.1b">
            <ci id="A1.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m1.1.1.cmml" xref="A1.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m1.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.m1.1c">
            \_
           </annotation>
          </semantics>
         </math>
         right
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F7.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m2.1">
          <semantics id="A1.F7.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m2.1a">
           <mi id="A1.F7.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m2.1.1" mathvariant="normal" xref="A1.F7.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m2.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F7.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m2.1b">
            <ci id="A1.F7.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m2.1.1.cmml" xref="A1.F7.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m2.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F7.pic1.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.6.m2.1c">
            \_
           </annotation>
          </semantics>
         </math>
         arrow(): This API inserts an arrow shape onto the slide.
        </span>
        <span class="ltx_p" id="A1.F7.pic1.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11">
         API: insert
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F7.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m1.1">
          <semantics id="A1.F7.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m1.1a">
           <mi id="A1.F7.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m1.1.1" mathvariant="normal" xref="A1.F7.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m1.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F7.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m1.1b">
            <ci id="A1.F7.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m1.1.1.cmml" xref="A1.F7.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m1.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F7.pic1.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.7.m1.1c">
            \_
           </annotation>
          </semantics>
         </math>
         table(row
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F7.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.m2.1">
          <semantics id="A1.F7.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.m2.1a">
           <mi id="A1.F7.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.m2.1.1" mathvariant="normal" xref="A1.F7.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.m2.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F7.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.m2.1b">
            <ci id="A1.F7.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.m2.1.1.cmml" xref="A1.F7.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.m2.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F7.pic1.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.m2.1c">
            \_
           </annotation>
          </semantics>
         </math>
         num, col
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F7.pic1.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.m3.1">
          <semantics id="A1.F7.pic1.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.m3.1a">
           <mi id="A1.F7.pic1.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.m3.1.1" mathvariant="normal" xref="A1.F7.pic1.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.m3.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F7.pic1.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.m3.1b">
            <ci id="A1.F7.pic1.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.m3.1.1.cmml" xref="A1.F7.pic1.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.m3.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F7.pic1.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.9.m3.1c">
            \_
           </annotation>
          </semantics>
         </math>
         num): This API inserts a table of row
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F7.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.m4.1">
          <semantics id="A1.F7.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.m4.1a">
           <mi id="A1.F7.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.m4.1.1" mathvariant="normal" xref="A1.F7.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.m4.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F7.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.m4.1b">
            <ci id="A1.F7.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.m4.1.1.cmml" xref="A1.F7.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.m4.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F7.pic1.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.10.m4.1c">
            \_
           </annotation>
          </semantics>
         </math>
         num rows and col
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F7.pic1.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.m5.1">
          <semantics id="A1.F7.pic1.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.m5.1a">
           <mi id="A1.F7.pic1.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.m5.1.1" mathvariant="normal" xref="A1.F7.pic1.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.m5.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F7.pic1.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.m5.1b">
            <ci id="A1.F7.pic1.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.m5.1.1.cmml" xref="A1.F7.pic1.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.m5.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F7.pic1.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.11.m5.1c">
            \_
           </annotation>
          </semantics>
         </math>
         num columns onto the current slide.
It takes two argument, the row number and the column number of the inserted table as integer. Remember the first parameter is row number and the second parameter is column number.
        </span>
        <span class="ltx_p" id="A1.F7.pic1.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13">
         API: insert
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F7.pic1.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.m1.1">
          <semantics id="A1.F7.pic1.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.m1.1a">
           <mi id="A1.F7.pic1.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.m1.1.1" mathvariant="normal" xref="A1.F7.pic1.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.m1.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F7.pic1.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.m1.1b">
            <ci id="A1.F7.pic1.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.m1.1.1.cmml" xref="A1.F7.pic1.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.m1.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F7.pic1.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.12.m1.1c">
            \_
           </annotation>
          </semantics>
         </math>
         line
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F7.pic1.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.m2.1">
          <semantics id="A1.F7.pic1.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.m2.1a">
           <mi id="A1.F7.pic1.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.m2.1.1" mathvariant="normal" xref="A1.F7.pic1.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.m2.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F7.pic1.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.m2.1b">
            <ci id="A1.F7.pic1.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.m2.1.1.cmml" xref="A1.F7.pic1.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.m2.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F7.pic1.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.13.m2.1c">
            \_
           </annotation>
          </semantics>
         </math>
         chart(data, series): This API inserts a line chart onto the slide.
It takes two argument, ’data’ is a list of numbers and ’series’ is a list of strings.
        </span>
        <span class="ltx_p" id="A1.F7.pic1.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15">
         API: insert
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F7.pic1.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.m1.1">
          <semantics id="A1.F7.pic1.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.m1.1a">
           <mi id="A1.F7.pic1.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.m1.1.1" mathvariant="normal" xref="A1.F7.pic1.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.m1.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F7.pic1.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.m1.1b">
            <ci id="A1.F7.pic1.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.m1.1.1.cmml" xref="A1.F7.pic1.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.m1.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F7.pic1.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.14.m1.1c">
            \_
           </annotation>
          </semantics>
         </math>
         bar
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F7.pic1.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.m2.1">
          <semantics id="A1.F7.pic1.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.m2.1a">
           <mi id="A1.F7.pic1.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.m2.1.1" mathvariant="normal" xref="A1.F7.pic1.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.m2.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F7.pic1.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.m2.1b">
            <ci id="A1.F7.pic1.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.m2.1.1.cmml" xref="A1.F7.pic1.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.m2.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F7.pic1.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.15.m2.1c">
            \_
           </annotation>
          </semantics>
         </math>
         chart(data, series): This API inserts a bar chart onto the slide.
It takes two argument, ’data’ is a list of numbers and ’series’ is a list of strings.
        </span>
        <span class="ltx_p" id="A1.F7.pic1.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17">
         API: insert
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F7.pic1.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.m1.1">
          <semantics id="A1.F7.pic1.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.m1.1a">
           <mi id="A1.F7.pic1.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.m1.1.1" mathvariant="normal" xref="A1.F7.pic1.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.m1.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F7.pic1.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.m1.1b">
            <ci id="A1.F7.pic1.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.m1.1.1.cmml" xref="A1.F7.pic1.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.m1.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F7.pic1.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.16.m1.1c">
            \_
           </annotation>
          </semantics>
         </math>
         pie
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F7.pic1.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.m2.1">
          <semantics id="A1.F7.pic1.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.m2.1a">
           <mi id="A1.F7.pic1.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.m2.1.1" mathvariant="normal" xref="A1.F7.pic1.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.m2.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F7.pic1.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.m2.1b">
            <ci id="A1.F7.pic1.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.m2.1.1.cmml" xref="A1.F7.pic1.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.m2.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F7.pic1.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.17.m2.1c">
            \_
           </annotation>
          </semantics>
         </math>
         chart(data, series): This API inserts a pie chart onto the slide.
It takes two argument, ’data’ is a list of numbers and ’series’ is a list of strings.
        </span>
        <span class="ltx_p" id="A1.F7.pic1.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18">
         API: seek
         <math alttext="\_" class="ltx_Math" display="inline" id="A1.F7.pic1.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.m1.1">
          <semantics id="A1.F7.pic1.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.m1.1a">
           <mi id="A1.F7.pic1.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.m1.1.1" mathvariant="normal" xref="A1.F7.pic1.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.m1.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A1.F7.pic1.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.m1.1b">
            <ci id="A1.F7.pic1.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.m1.1.1.cmml" xref="A1.F7.pic1.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.m1.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A1.F7.pic1.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.18.m1.1c">
            \_
           </annotation>
          </semantics>
         </math>
         assistance(): This API requests human help when the computer is unsure about the result or lacks the necessary API to fulfill the user’s instruction.
        </span>
       </span>
      </foreignobject>
     </g>
    </g>
   </svg>
   <figcaption class="ltx_caption">
    <span class="ltx_tag ltx_tag_figure">
     Figure 7:
    </span>
    The reference API file in the API-lack setting.
   </figcaption>
  </figure>
 </section>
 <section class="ltx_appendix" id="A2">
  <h2 class="ltx_title ltx_title_appendix">
   <span class="ltx_tag ltx_tag_appendix">
    Appendix B
   </span>
   Experimental details
  </h2>
  <div class="ltx_para" id="A2.p1">
   <p class="ltx_p" id="A2.p1.1">
    For closed-source LLMs, Azure OpenAI services
    <span class="ltx_note ltx_role_footnote" id="footnote5">
     <sup class="ltx_note_mark">
      ¶
     </sup>
     <span class="ltx_note_outer">
      <span class="ltx_note_content">
       <sup class="ltx_note_mark">
        ¶
       </sup>
       <span class="ltx_tag ltx_tag_note">
        ¶
       </span>
       <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://azure.microsoft.com/en-us/products/cognitive-services/openai-service" target="_blank" title="">
        https://azure.microsoft.com/en-us/products/cognitive-services/openai-service
       </a>
      </span>
     </span>
    </span>
    offer two API types: completion and chat completion. Completion API generates text from prompts, while chat completion API responds based on conversation history and new input. We use the completion API for Text-Davinci-003 and the chat completion API for ChatGPT and GPT-4. We set a temperature of zero for deterministic output and a max token limit of 2048. Frequency penalty and top p are kept at their default values of zero and 1, respectively. For open-source LLMs, we choose the chat version of Llama-2, the v1.2 version of WizardLM, and the chat version of Baichuan as our open-source LLMs. We choose the 13 billion parameters model of the three LLMs. If the token number of the input prompt is beyond the token limit, we cut the PPT content to reduce the token number of the prompt.
   </p>
  </div>
  <div class="ltx_para" id="A2.p2">
   <p class="ltx_p" id="A2.p2.1">
    The inference prompts in the turn-based evaluation and session-based evaluation have two differences: the API solutions for previous turns in dialogue history are the correct API sequences in the turn-based evaluation and the outputs of the LLM in the session-based evaluation. (2) The PPT content is parsed from the PPT file. The PPT file is obtained by executing the label API sequences in the turn-based evaluation and the previous outputs of the LLM in the session-based evaluation. That means the error made by LLMs in previous turns would influence subsequent turns in the session-based evaluation.
We copy the inference prompt we used from PPTC and illustrate it in Figure
    <a class="ltx_ref" href="#A2.F8" title="Figure 8 ‣ Appendix B Experimental details ‣ PPTC-R benchmark: Towards Evaluating the Robustness of Large Language Models for PowerPoint Task Completion">
     <span class="ltx_text ltx_ref_tag">
      8
     </span>
    </a>
    .
   </p>
  </div>
  <figure class="ltx_figure" id="A2.F8">
   <svg class="ltx_picture" height="705.19" id="A2.F8.pic1" overflow="visible" version="1.1" width="600">
    <g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,705.19) matrix(1 0 0 -1 0 0)">
     <g fill="#00A600" fill-opacity="1.0">
      <path d="M 0 5.91 L 0 699.28 C 0 702.55 2.64 705.19 5.91 705.19 L 594.09 705.19 C 597.36 705.19 600 702.55 600 699.28 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none">
      </path>
     </g>
     <g fill="#FFFFFF" fill-opacity="1.0">
      <path d="M 1.97 5.91 L 1.97 681.08 L 598.03 681.08 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none">
      </path>
     </g>
     <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 686.99)">
      <foreignobject color="#FFFFFF" height="12.3" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">
       <span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A2.F8.pic1.5.5.5.1.1" style="width:402.3pt;">
        <span class="ltx_p" id="A2.F8.pic1.5.5.5.1.1.1">
         <span class="ltx_text ltx_font_bold" id="A2.F8.pic1.5.5.5.1.1.1.1">
          Inference prompt in PPTC
         </span>
        </span>
       </span>
      </foreignobject>
     </g>
     <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)">
      <foreignobject color="#000000" height="655.49" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">
       <span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A2.F8.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4" style="width:402.3pt;">
        <span class="ltx_p" id="A2.F8.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.5">
         (
         <span class="ltx_text ltx_font_bold" id="A2.F8.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.5.1">
          Task instruction
         </span>
         ) You are an AI assistant to help the user to operate PowerPoint and edit the contents.
        </span>
        <span class="ltx_p" id="A2.F8.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.6">
         Give you the user instruction:&lt;Current user instruction&gt;, you can complete it based on the following APIs and PPT file content. Current you are at page &lt;Page id&gt;. Please finish the user instruction with the functions you have.
Don’t generate instructions beyond what the user has instructed.
Don’t guess what the user may instruct in the next step and generete API for them.
Don’t use python loop to call API. You can only call API once in one line.
If the user does not specify the page to be modified, you can directly start using the APIs without having to navigate to other pages.
        </span>
        <span class="ltx_p" id="A2.F8.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.7">
         You need to generate code which can finish the user instruction. The multiple lines of code should be surrounded by &lt;code&gt; and &lt;/code&gt; such as:
&lt;code&gt;
API();
API();
&lt;/code&gt;
        </span>
        <span class="ltx_p" id="A2.F8.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.8">
         For example, if the user instruction is "create a slide", then the answer should be:
        </span>
        <span class="ltx_p" id="A2.F8.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.9">
         &lt;code&gt;
create_slide();
&lt;/code&gt;
        </span>
        <span class="ltx_p" id="A2.F8.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.10">
         (
         <span class="ltx_text ltx_font_bold" id="A2.F8.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.10.1">
          API file
         </span>
         ) Now, you have access to a list of PowerPoint APIs with the following functions: &lt;APIs and their descriptions&gt;
        </span>
        <span class="ltx_p" id="A2.F8.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1">
         (e.g.,API(name="set
         <math alttext="\_" class="ltx_Math" display="inline" id="A2.F8.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1">
          <semantics id="A2.F8.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1a">
           <mi id="A2.F8.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1" mathvariant="normal" xref="A2.F8.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A2.F8.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1b">
            <ci id="A2.F8.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="A2.F8.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A2.F8.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1c">
            \_
           </annotation>
          </semantics>
         </math>
         width", parameters="(width)",
        </span>
        <span class="ltx_p" id="A2.F8.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.11">
         description="This API sets the width of the selected object.",
        </span>
        <span class="ltx_p" id="A2.F8.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2">
         parameter
         <math alttext="\_" class="ltx_Math" display="inline" id="A2.F8.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m1.1">
          <semantics id="A2.F8.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m1.1a">
           <mi id="A2.F8.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m1.1.1" mathvariant="normal" xref="A2.F8.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m1.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A2.F8.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m1.1b">
            <ci id="A2.F8.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m1.1.1.cmml" xref="A2.F8.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m1.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A2.F8.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m1.1c">
            \_
           </annotation>
          </semantics>
         </math>
         description="It takes one parameter ’width’, the width of an object in centimeters as float.",
        </span>
        <span class="ltx_p" id="A2.F8.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3">
         composition
         <math alttext="\_" class="ltx_Math" display="inline" id="A2.F8.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m1.1">
          <semantics id="A2.F8.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m1.1a">
           <mi id="A2.F8.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m1.1.1" mathvariant="normal" xref="A2.F8.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m1.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A2.F8.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m1.1b">
            <ci id="A2.F8.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m1.1.1.cmml" xref="A2.F8.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m1.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A2.F8.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m1.1c">
            \_
           </annotation>
          </semantics>
         </math>
         instruction="You should first choose an object before you can change the width of it.",
        </span>
        <span class="ltx_p" id="A2.F8.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4">
         api
         <math alttext="\_" class="ltx_Math" display="inline" id="A2.F8.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m1.1">
          <semantics id="A2.F8.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m1.1a">
           <mi id="A2.F8.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m1.1.1" mathvariant="normal" xref="A2.F8.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m1.1.1.cmml">
            _
           </mi>
           <annotation-xml encoding="MathML-Content" id="A2.F8.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m1.1b">
            <ci id="A2.F8.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m1.1.1.cmml" xref="A2.F8.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m1.1.1">
             _
            </ci>
           </annotation-xml>
           <annotation encoding="application/x-tex" id="A2.F8.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m1.1c">
            \_
           </annotation>
          </semantics>
         </math>
         desc="width of picture and shapes")
)
        </span>
        <span class="ltx_p" id="A2.F8.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.12">
         (
         <span class="ltx_text ltx_font_bold" id="A2.F8.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.12.1">
          PPT file content
         </span>
         ) All the PPT contents are:
        </span>
        <span class="ltx_p" id="A2.F8.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.13">
         &lt;Begin of PPT&gt;
        </span>
        <span class="ltx_p" id="A2.F8.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.14">
         <span class="ltx_text ltx_font_italic" id="A2.F8.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.14.1">
          Turn-based: &lt;Parsed PPT file content of the label PPT file of the previous turns&gt;
          <br class="ltx_break"/>
          Session-based: &lt;Parsed PPT file content of the LLM prediction file of the previous turns&gt;
          <br class="ltx_break"/>
         </span>
         &lt;End of PPT&gt;
        </span>
        <span class="ltx_p" id="A2.F8.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.15">
         (
         <span class="ltx_text ltx_font_bold" id="A2.F8.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.15.1">
          Dialogue history
         </span>
         )
        </span>
        <span class="ltx_p" id="A2.F8.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.16">
         ¬User¬:
Hello!
        </span>
        <span class="ltx_p" id="A2.F8.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.17">
         ¬AI¬:
Hi there! How can I help you?
        </span>
        <span class="ltx_p" id="A2.F8.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.18">
         ¬User¬:
&lt;the first instruction&gt;
        </span>
        <span class="ltx_p" id="A2.F8.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.19">
         ¬AI¬:
        </span>
        <span class="ltx_p" id="A2.F8.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.20">
         <span class="ltx_text ltx_font_italic" id="A2.F8.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.20.1">
          Turn-based: &lt;the correct feasible API sequence&gt;,
          <br class="ltx_break"/>
          Session-based: &lt;the LLM-generated API sequence&gt;
         </span>
        </span>
        <span class="ltx_p" id="A2.F8.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.21">
         …
        </span>
        <span class="ltx_p" id="A2.F8.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.22">
         ¬User¬:
&lt;Current user instruction&gt;. Surrounding your answer with &lt;code&gt; and &lt;/code&gt;.
        </span>
        <span class="ltx_p" id="A2.F8.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.23">
         ¬AI¬:
        </span>
       </span>
      </foreignobject>
     </g>
    </g>
   </svg>
   <figcaption class="ltx_caption">
    <span class="ltx_tag ltx_tag_figure">
     Figure 8:
    </span>
    The inference prompt we used in both turn-based and session-based evaluation settings.
   </figcaption>
  </figure>
 </section>
 <section class="ltx_appendix" id="A3">
  <h2 class="ltx_title ltx_title_appendix">
   <span class="ltx_tag ltx_tag_appendix">
    Appendix C
   </span>
   Detailed Results of LLMs on PPTC-R benchmark
  </h2>
  <div class="ltx_para" id="A3.p1">
   <p class="ltx_p" id="A3.p1.1">
    In turn-based evaluation, we report the average token number of the input of one turn and the average API number for finishing one turn as the cost measurement.
In session-based evaluation, we report the average value of the token number of all inputs in one session and the average API number required to complete one session as the cost measurement.
We return the accuracy and the cost measurement in both two evaluations in Table
    <a class="ltx_ref" href="#A3.T5" title="Table 5 ‣ Appendix C Detailed Results of LLMs on PPTC-R benchmark ‣ PPTC-R benchmark: Towards Evaluating the Robustness of Large Language Models for PowerPoint Task Completion">
     <span class="ltx_text ltx_ref_tag">
      5
     </span>
    </a>
    ,
    <a class="ltx_ref" href="#A3.T6" title="Table 6 ‣ Appendix C Detailed Results of LLMs on PPTC-R benchmark ‣ PPTC-R benchmark: Towards Evaluating the Robustness of Large Language Models for PowerPoint Task Completion">
     <span class="ltx_text ltx_ref_tag">
      6
     </span>
    </a>
    ,
    <a class="ltx_ref" href="#A3.T7" title="Table 7 ‣ Appendix C Detailed Results of LLMs on PPTC-R benchmark ‣ PPTC-R benchmark: Towards Evaluating the Robustness of Large Language Models for PowerPoint Task Completion">
     <span class="ltx_text ltx_ref_tag">
      7
     </span>
    </a>
    , and
    <a class="ltx_ref" href="#A3.T8" title="Table 8 ‣ Appendix C Detailed Results of LLMs on PPTC-R benchmark ‣ PPTC-R benchmark: Towards Evaluating the Robustness of Large Language Models for PowerPoint Task Completion">
     <span class="ltx_text ltx_ref_tag">
      8
     </span>
    </a>
    .
   </p>
  </div>
  <figure class="ltx_table" id="A3.T5">
   <div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A3.T5.1" style="width:449.7pt;height:108.6pt;vertical-align:-0.6pt;">
    <span class="ltx_transformed_inner" style="transform:translate(-149.9pt,36.0pt) scale(0.6,0.6) ;">
     <table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A3.T5.1.1">
      <tbody class="ltx_tbody">
       <tr class="ltx_tr" id="A3.T5.1.1.1.1">
        <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A3.T5.1.1.1.1.1" rowspan="3">
         <span class="ltx_text" id="A3.T5.1.1.1.1.1.1">
          Models and Methods
         </span>
        </th>
        <td class="ltx_td ltx_align_center ltx_border_t" colspan="6" id="A3.T5.1.1.1.1.2">
         Creating new slides
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" colspan="6" id="A3.T5.1.1.1.1.3">
         Editing PPT template
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T5.1.1.2.2">
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3" id="A3.T5.1.1.2.2.1">
         Turn-based
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3" id="A3.T5.1.1.2.2.2">
         Session-based
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3" id="A3.T5.1.1.2.2.3">
         Turn-based
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" colspan="3" id="A3.T5.1.1.2.2.4">
         Session-based
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T5.1.1.3.3">
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.3.3.1">
         Accuracy
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.3.3.2">
         Avg token
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T5.1.1.3.3.3">
         Avg API
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.3.3.4">
         Accuracy
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.3.3.5">
         Avg token
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T5.1.1.3.3.6">
         Avg API
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.3.3.7">
         Accuracy
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.3.3.8">
         Avg token
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T5.1.1.3.3.9">
         Avg API
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.3.3.10">
         Accuracy
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.3.3.11">
         Avg token
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.3.3.12">
         Avg API
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T5.1.1.4.4">
        <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A3.T5.1.1.4.4.1">
         Davinci-003
        </th>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.4.4.2">
         64.8
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.4.4.3">
         2872.2
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T5.1.1.4.4.4">
         3.1
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.4.4.5">
         11.7
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.4.4.6">
         20716.8
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T5.1.1.4.4.7">
         24.2
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.4.4.8">
         26.3
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.4.4.9">
         2915.8
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T5.1.1.4.4.10">
         8.3
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.4.4.11">
         0.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.4.4.12">
         9321.1
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.4.4.13">
         23.6
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T5.1.1.5.5">
        <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A3.T5.1.1.5.5.1">
         ChatGPT
        </th>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.5.5.2">
         61.3
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.5.5.3">
         3106.6
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T5.1.1.5.5.4">
         3.4
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.5.5.5">
         9.7
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.5.5.6">
         22611.1
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T5.1.1.5.5.7">
         26.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.5.5.8">
         28.8
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.5.5.9">
         4140.9
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T5.1.1.5.5.10">
         8.1
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.5.5.11">
         2.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.5.5.12">
         13240.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.5.5.13">
         26.8
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T5.1.1.6.6">
        <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A3.T5.1.1.6.6.1">
         GPT-4
        </th>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.6.6.2">
         72.3
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.6.6.3">
         3111.2
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T5.1.1.6.6.4">
         3.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.6.6.5">
         12.3
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.6.6.6">
         22438.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T5.1.1.6.6.7">
         21.6
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.6.6.8">
         36.9
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.6.6.9">
         7565.9
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T5.1.1.6.6.10">
         7.7
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.6.6.11">
         4.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.6.6.12">
         24185.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.6.6.13">
         24.0
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T5.1.1.7.7">
        <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A3.T5.1.1.7.7.1">
         LLaMa-2
        </th>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.7.7.2">
         16.3
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.7.7.3">
         2822.6
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T5.1.1.7.7.4">
         4.3
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.7.7.5">
         1.7
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.7.7.6">
         11018.5
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T5.1.1.7.7.7">
         60.3
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.7.7.8">
         8.8
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.7.7.9">
         4124.5
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T5.1.1.7.7.10">
         7.6
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.7.7.11">
         2.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.7.7.12">
         4173.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.7.7.13">
         15.4
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T5.1.1.8.8">
        <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A3.T5.1.1.8.8.1">
         WizardLM
        </th>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.8.8.2">
         23.8
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.8.8.3">
         1327.1
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T5.1.1.8.8.4">
         3.3
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.8.8.5">
         1.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.8.8.6">
         11494.4
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T5.1.1.8.8.7">
         22.8
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.8.8.8">
         10.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.8.8.9">
         1328.4
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T5.1.1.8.8.10">
         5.7
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.8.8.11">
         0.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.8.8.12">
         4303.7
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.8.8.13">
         9.5
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T5.1.1.9.9">
        <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A3.T5.1.1.9.9.1">
         Baichuan
        </th>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.9.9.2">
         15.5
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.9.9.3">
         1327.1
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T5.1.1.9.9.4">
         9.8
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.9.9.5">
         1.4
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.9.9.6">
         10548.9
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T5.1.1.9.9.7">
         56.1
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.9.9.8">
         4.3
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.9.9.9">
         1328.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T5.1.1.9.9.10">
         9.6
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.9.9.11">
         0.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.9.9.12">
         4256.4
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T5.1.1.9.9.13">
         25.0
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T5.1.1.10.10">
        <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t" id="A3.T5.1.1.10.10.1">
         CodeLLaMa
        </th>
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="A3.T5.1.1.10.10.2">
         36.2
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="A3.T5.1.1.10.10.3">
         2814.3
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="A3.T5.1.1.10.10.4">
         3.5
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="A3.T5.1.1.10.10.5">
         0.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="A3.T5.1.1.10.10.6">
         20720.9
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="A3.T5.1.1.10.10.7">
         32.1
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="A3.T5.1.1.10.10.8">
         18.8
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="A3.T5.1.1.10.10.9">
         2061.7
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="A3.T5.1.1.10.10.10">
         7.5
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="A3.T5.1.1.10.10.11">
         2.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="A3.T5.1.1.10.10.12">
         9566.9
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="A3.T5.1.1.10.10.13">
         22.58
        </td>
       </tr>
      </tbody>
     </table>
    </span>
   </div>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_table">
     Table 5:
    </span>
    We report the results of LLMs in the sentence-level robustness setting in this table.’ Davinci-003’ is the Text-Davinci-003 model.
   </figcaption>
  </figure>
  <figure class="ltx_table" id="A3.T6">
   <div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A3.T6.1" style="width:449.7pt;height:108.6pt;vertical-align:-0.6pt;">
    <span class="ltx_transformed_inner" style="transform:translate(-149.9pt,36.0pt) scale(0.6,0.6) ;">
     <table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A3.T6.1.1">
      <tbody class="ltx_tbody">
       <tr class="ltx_tr" id="A3.T6.1.1.1.1">
        <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A3.T6.1.1.1.1.1" rowspan="3">
         <span class="ltx_text" id="A3.T6.1.1.1.1.1.1">
          Models and Methods
         </span>
        </th>
        <td class="ltx_td ltx_align_center ltx_border_t" colspan="6" id="A3.T6.1.1.1.1.2">
         Creating new slides
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" colspan="6" id="A3.T6.1.1.1.1.3">
         Editing PPT template
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T6.1.1.2.2">
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3" id="A3.T6.1.1.2.2.1">
         Turn-based
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3" id="A3.T6.1.1.2.2.2">
         Session-based
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3" id="A3.T6.1.1.2.2.3">
         Turn-based
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" colspan="3" id="A3.T6.1.1.2.2.4">
         Session-based
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T6.1.1.3.3">
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T6.1.1.3.3.1">
         Accuracy
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T6.1.1.3.3.2">
         Avg token
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T6.1.1.3.3.3">
         Avg API
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T6.1.1.3.3.4">
         Accuracy
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T6.1.1.3.3.5">
         Avg token
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T6.1.1.3.3.6">
         Avg API
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T6.1.1.3.3.7">
         Accuracy
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T6.1.1.3.3.8">
         Avg token
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T6.1.1.3.3.9">
         Avg API
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T6.1.1.3.3.10">
         Accuracy
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T6.1.1.3.3.11">
         Avg token
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T6.1.1.3.3.12">
         Avg API
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T6.1.1.4.4">
        <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A3.T6.1.1.4.4.1">
         Davinci-003
        </th>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T6.1.1.4.4.2">
         67.4
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T6.1.1.4.4.3">
         2781.3
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T6.1.1.4.4.4">
         2.4
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T6.1.1.4.4.5">
         9.5
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T6.1.1.4.4.6">
         20065.9
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T6.1.1.4.4.7">
         25.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T6.1.1.4.4.8">
         25.8
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T6.1.1.4.4.9">
         2892.9
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T6.1.1.4.4.10">
         7.8
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T6.1.1.4.4.11">
         0.5
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T6.1.1.4.4.12">
         9247.9
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T6.1.1.4.4.13">
         23.3
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T6.1.1.5.5">
        <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A3.T6.1.1.5.5.1">
         ChatGPT
        </th>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T6.1.1.5.5.2">
         65.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T6.1.1.5.5.3">
         2887.1
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T6.1.1.5.5.4">
         3.3
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T6.1.1.5.5.5">
         8.7
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T6.1.1.5.5.6">
         20865.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T6.1.1.5.5.7">
         25.3
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T6.1.1.5.5.8">
         27.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T6.1.1.5.5.9">
         4127.8
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T6.1.1.5.5.10">
         8.1
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T6.1.1.5.5.11">
         2.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T6.1.1.5.5.12">
         13207.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T6.1.1.5.5.13">
         26.3
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T6.1.1.6.6">
        <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A3.T6.1.1.6.6.1">
         GPT-4
        </th>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T6.1.1.6.6.2">
         72.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T6.1.1.6.6.3">
         2887.7
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T6.1.1.6.6.4">
         3.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T6.1.1.6.6.5">
         14.2
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T6.1.1.6.6.6">
         20817.7
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T6.1.1.6.6.7">
         22.2
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T6.1.1.6.6.8">
         35.8
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T6.1.1.6.6.9">
         7538.3
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T6.1.1.6.6.10">
         7.8
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T6.1.1.6.6.11">
         4.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T6.1.1.6.6.12">
         24103.1
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T6.1.1.6.6.13">
         24.4
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T6.1.1.7.7">
        <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A3.T6.1.1.7.7.1">
         LLaMa-2
        </th>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T6.1.1.7.7.2">
         16.1
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T6.1.1.7.7.3">
         2822.6
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T6.1.1.7.7.4">
         4.3
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T6.1.1.7.7.5">
         1.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T6.1.1.7.7.6">
         9777.9
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T6.1.1.7.7.7">
         16.6
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T6.1.1.7.7.8">
         7.6
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T6.1.1.7.7.9">
         2983.8
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T6.1.1.7.7.10">
         6.4
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T6.1.1.7.7.11">
         0.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T6.1.1.7.7.12">
         9550.7
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T6.1.1.7.7.13">
         22.8
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T6.1.1.8.8">
        <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A3.T6.1.1.8.8.1">
         WizardLM
        </th>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T6.1.1.8.8.2">
         23.8
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T6.1.1.8.8.3">
         1327.1
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T6.1.1.8.8.4">
         3.4
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T6.1.1.8.8.5">
         0.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T6.1.1.8.8.6">
         11494.4
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T6.1.1.8.8.7">
         22.8
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T6.1.1.8.8.8">
         10.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T6.1.1.8.8.9">
         1328.5
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T6.1.1.8.8.10">
         5.8
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T6.1.1.8.8.11">
         0.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T6.1.1.8.8.12">
         4303.7
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T6.1.1.8.8.13">
         9.5
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T6.1.1.9.9">
        <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A3.T6.1.1.9.9.1">
         Baichuan
        </th>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T6.1.1.9.9.2">
         15.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T6.1.1.9.9.3">
         1327.1
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T6.1.1.9.9.4">
         10.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T6.1.1.9.9.5">
         0.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T6.1.1.9.9.6">
         10112.3
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T6.1.1.9.9.7">
         24.1
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T6.1.1.9.9.8">
         2.5
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T6.1.1.9.9.9">
         1328.5
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T6.1.1.9.9.10">
         12.2
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T6.1.1.9.9.11">
         0.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T6.1.1.9.9.12">
         4256.4
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T6.1.1.9.9.13">
         17.0
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T6.1.1.10.10">
        <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t" id="A3.T6.1.1.10.10.1">
         CodeLLaMa
        </th>
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="A3.T6.1.1.10.10.2">
         36.8
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="A3.T6.1.1.10.10.3">
         2819.7
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="A3.T6.1.1.10.10.4">
         3.4
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="A3.T6.1.1.10.10.5">
         0.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="A3.T6.1.1.10.10.6">
         20720.9
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="A3.T6.1.1.10.10.7">
         32.1
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="A3.T6.1.1.10.10.8">
         18.8
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="A3.T6.1.1.10.10.9">
         2983.1
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="A3.T6.1.1.10.10.10">
         7.3
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="A3.T6.1.1.10.10.11">
         0.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="A3.T6.1.1.10.10.12">
         10351.1
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="A3.T6.1.1.10.10.13">
         25.0
        </td>
       </tr>
      </tbody>
     </table>
    </span>
   </div>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_table">
     Table 6:
    </span>
    We report the results of LLMs in the semantic-level robustness setting in this table. Each result is the average performance in finishing four different paraphrased instructions.
   </figcaption>
  </figure>
  <figure class="ltx_table" id="A3.T7">
   <div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A3.T7.1" style="width:449.7pt;height:108.6pt;vertical-align:-0.6pt;">
    <span class="ltx_transformed_inner" style="transform:translate(-149.9pt,36.0pt) scale(0.6,0.6) ;">
     <table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A3.T7.1.1">
      <tbody class="ltx_tbody">
       <tr class="ltx_tr" id="A3.T7.1.1.1.1">
        <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A3.T7.1.1.1.1.1" rowspan="3">
         <span class="ltx_text" id="A3.T7.1.1.1.1.1.1">
          Models and Methods
         </span>
        </th>
        <td class="ltx_td ltx_align_center ltx_border_t" colspan="6" id="A3.T7.1.1.1.1.2">
         Creating new slides
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" colspan="6" id="A3.T7.1.1.1.1.3">
         Editing PPT template
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T7.1.1.2.2">
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3" id="A3.T7.1.1.2.2.1">
         Turn-based
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3" id="A3.T7.1.1.2.2.2">
         Session-based
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3" id="A3.T7.1.1.2.2.3">
         Turn-based
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" colspan="3" id="A3.T7.1.1.2.2.4">
         Session-based
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T7.1.1.3.3">
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T7.1.1.3.3.1">
         Accuracy
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T7.1.1.3.3.2">
         Avg token
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T7.1.1.3.3.3">
         Avg API
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T7.1.1.3.3.4">
         Accuracy
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T7.1.1.3.3.5">
         Avg token
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T7.1.1.3.3.6">
         Avg API
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T7.1.1.3.3.7">
         Accuracy
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T7.1.1.3.3.8">
         Avg token
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T7.1.1.3.3.9">
         Avg API
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T7.1.1.3.3.10">
         Accuracy
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T7.1.1.3.3.11">
         Avg token
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T7.1.1.3.3.12">
         Avg API
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T7.1.1.4.4">
        <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A3.T7.1.1.4.4.1">
         Davinci-003
        </th>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T7.1.1.4.4.2">
         55.1
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T7.1.1.4.4.3">
         2125.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T7.1.1.4.4.4">
         3.4
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T7.1.1.4.4.5">
         5.2
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T7.1.1.4.4.6">
         15527.1
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T7.1.1.4.4.7">
         25.2
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T7.1.1.4.4.8">
         33.75
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T7.1.1.4.4.9">
         2720.7
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T7.1.1.4.4.10">
         8.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T7.1.1.4.4.11">
         0.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T7.1.1.4.4.12">
         8720.3
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T7.1.1.4.4.13">
         25.0
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T7.1.1.5.5">
        <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A3.T7.1.1.5.5.1">
         ChatGPT
        </th>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T7.1.1.5.5.2">
         55.4
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T7.1.1.5.5.3">
         2138.9
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T7.1.1.5.5.4">
         3.6
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T7.1.1.5.5.5">
         3.9
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T7.1.1.5.5.6">
         15631.6
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T7.1.1.5.5.7">
         26.3
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T7.1.1.5.5.8">
         27.5
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T7.1.1.5.5.9">
         3925.5
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T7.1.1.5.5.10">
         8.8
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T7.1.1.5.5.11">
         0.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T7.1.1.5.5.12">
         12567.9
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T7.1.1.5.5.13">
         26.9
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T7.1.1.6.6">
        <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A3.T7.1.1.6.6.1">
         GPT-4
        </th>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T7.1.1.6.6.2">
         62.5
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T7.1.1.6.6.3">
         2138.9
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T7.1.1.6.6.4">
         3.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T7.1.1.6.6.5">
         5.2
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T7.1.1.6.6.6">
         15572.4
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T7.1.1.6.6.7">
         22.2
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T7.1.1.6.6.8">
         39.4
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T7.1.1.6.6.9">
         7265.1
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T7.1.1.6.6.10">
         7.6
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T7.1.1.6.6.11">
         0.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T7.1.1.6.6.12">
         23251.6
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T7.1.1.6.6.13">
         24.9
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T7.1.1.7.7">
        <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A3.T7.1.1.7.7.1">
         LLaMa-2
        </th>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T7.1.1.7.7.2">
         16.5
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T7.1.1.7.7.3">
         2070.4
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T7.1.1.7.7.4">
         5.7
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T7.1.1.7.7.5">
         0.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T7.1.1.7.7.6">
         17322.6
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T7.1.1.7.7.7">
         49.5
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T7.1.1.7.7.8">
         12.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T7.1.1.7.7.9">
         2787.8
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T7.1.1.7.7.10">
         7.8
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T7.1.1.7.7.11">
         0.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T7.1.1.7.7.12">
         8993.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T7.1.1.7.7.13">
         20.8
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T7.1.1.8.8">
        <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A3.T7.1.1.8.8.1">
         WizardLM
        </th>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T7.1.1.8.8.2">
         18.9
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T7.1.1.8.8.3">
         1308.8
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T7.1.1.8.8.4">
         3.2
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T7.1.1.8.8.5">
         0.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T7.1.1.8.8.6">
         15885.4
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T7.1.1.8.8.7">
         121.5
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T7.1.1.8.8.8">
         14.4
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T7.1.1.8.8.9">
         1306.7
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T7.1.1.8.8.10">
         5.6
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T7.1.1.8.8.11">
         0.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T7.1.1.8.8.12">
         13508.7
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T7.1.1.8.8.13">
         29.5
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T7.1.1.9.9">
        <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A3.T7.1.1.9.9.1">
         Baichuan
        </th>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T7.1.1.9.9.2">
         18.7
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T7.1.1.9.9.3">
         1310.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T7.1.1.9.9.4">
         10.1
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T7.1.1.9.9.5">
         0.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T7.1.1.9.9.6">
         11335.2
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T7.1.1.9.9.7">
         66.4
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T7.1.1.9.9.8">
         10.6
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T7.1.1.9.9.9">
         1308
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T7.1.1.9.9.10">
         8.5
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T7.1.1.9.9.11">
         6.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T7.1.1.9.9.12">
         4209.6
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T7.1.1.9.9.13">
         22.5
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T7.1.1.10.10">
        <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t" id="A3.T7.1.1.10.10.1">
         CodeLLaMa
        </th>
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="A3.T7.1.1.10.10.2">
         26.3
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="A3.T7.1.1.10.10.3">
         2061.7
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="A3.T7.1.1.10.10.4">
         4.4
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="A3.T7.1.1.10.10.5">
         0.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="A3.T7.1.1.10.10.6">
         14448.1
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="A3.T7.1.1.10.10.7">
         34.7
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="A3.T7.1.1.10.10.8">
         13.6
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="A3.T7.1.1.10.10.9">
         2791.8
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="A3.T7.1.1.10.10.10">
         7.6
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="A3.T7.1.1.10.10.11">
         2.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="A3.T7.1.1.10.10.12">
         10001.8
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="A3.T7.1.1.10.10.13">
         13.3
        </td>
       </tr>
      </tbody>
     </table>
    </span>
   </div>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_table">
     Table 7:
    </span>
    We report the results of LLMs in the API lack setting in this table. In this setting, we only maintain the 24 basic APIs. LLMs only need to finish the content that can be finished by the 24 APIs.
   </figcaption>
  </figure>
  <figure class="ltx_table" id="A3.T8">
   <div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A3.T8.1" style="width:449.7pt;height:108.6pt;vertical-align:-0.6pt;">
    <span class="ltx_transformed_inner" style="transform:translate(-149.9pt,36.0pt) scale(0.6,0.6) ;">
     <table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A3.T8.1.1">
      <tbody class="ltx_tbody">
       <tr class="ltx_tr" id="A3.T8.1.1.1.1">
        <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A3.T8.1.1.1.1.1" rowspan="3">
         <span class="ltx_text" id="A3.T8.1.1.1.1.1.1">
          Models and Methods
         </span>
        </th>
        <td class="ltx_td ltx_align_center ltx_border_t" colspan="6" id="A3.T8.1.1.1.1.2">
         Creating new slides
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" colspan="6" id="A3.T8.1.1.1.1.3">
         Editing PPT template
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T8.1.1.2.2">
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3" id="A3.T8.1.1.2.2.1">
         Turn-based
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3" id="A3.T8.1.1.2.2.2">
         Session-based
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3" id="A3.T8.1.1.2.2.3">
         Turn-based
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" colspan="3" id="A3.T8.1.1.2.2.4">
         Session-based
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T8.1.1.3.3">
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.1.1.3.3.1">
         Accuracy
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.1.1.3.3.2">
         Avg token
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T8.1.1.3.3.3">
         Avg API
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.1.1.3.3.4">
         Accuracy
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.1.1.3.3.5">
         Avg token
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T8.1.1.3.3.6">
         Avg API
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.1.1.3.3.7">
         Accuracy
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.1.1.3.3.8">
         Avg token
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T8.1.1.3.3.9">
         Avg API
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.1.1.3.3.10">
         Accuracy
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.1.1.3.3.11">
         Avg token
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.1.1.3.3.12">
         Avg API
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T8.1.1.4.4">
        <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A3.T8.1.1.4.4.1">
         Davinci-003
        </th>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.1.1.4.4.2">
         44.5
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.1.1.4.4.3">
         2938.8
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T8.1.1.4.4.4">
         2.8
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.1.1.4.4.5">
         1.3
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.1.1.4.4.6">
         21178.7
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T8.1.1.4.4.7">
         21.1
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.1.1.4.4.8">
         17.5
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.1.1.4.4.9">
         2942.6
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T8.1.1.4.4.10">
         6.6
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.1.1.4.4.11">
         0.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.1.1.4.4.12">
         9419.1
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.1.1.4.4.13">
         18.9
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T8.1.1.5.5">
        <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A3.T8.1.1.5.5.1">
         ChatGPT
        </th>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.1.1.5.5.2">
         55.4
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.1.1.5.5.3">
         4603.6
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T8.1.1.5.5.4">
         2.9
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.1.1.5.5.5">
         5.2
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.1.1.5.5.6">
         33166.4
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T8.1.1.5.5.7">
         23.2
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.1.1.5.5.8">
         15.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.1.1.5.5.9">
         4605.9
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T8.1.1.5.5.10">
         7.1
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.1.1.5.5.11">
         0.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.1.1.5.5.12">
         14724.6
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.1.1.5.5.13">
         20.3
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T8.1.1.6.6">
        <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A3.T8.1.1.6.6.1">
         GPT-4
        </th>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.1.1.6.6.2">
         75.7
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.1.1.6.6.3">
         6495.9
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T8.1.1.6.6.4">
         2.8
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.1.1.6.6.5">
         18.8
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.1.1.6.6.6">
         46747.9
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T8.1.1.6.6.7">
         20.7
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.1.1.6.6.8">
         35.6
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.1.1.6.6.9">
         8511.7
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T8.1.1.6.6.10">
         7.5
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.1.1.6.6.11">
         2.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.1.1.6.6.12">
         27211.5
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.1.1.6.6.13">
         23.4
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T8.1.1.7.7">
        <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A3.T8.1.1.7.7.1">
         LLaMa-2
        </th>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.1.1.7.7.2">
         7.8
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.1.1.7.7.3">
         2318.8
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T8.1.1.7.7.4">
         10.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.1.1.7.7.5">
         3.4
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.1.1.7.7.6">
         10073.8
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T8.1.1.7.7.7">
         17.2
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.1.1.7.7.8">
         7.5
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.1.1.7.7.9">
         2137.8
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T8.1.1.7.7.10">
         8.7
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.1.1.7.7.11">
         2.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.1.1.7.7.12">
         9910
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.1.1.7.7.13">
         13.7
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T8.1.1.8.8">
        <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A3.T8.1.1.8.8.1">
         WizardLM
        </th>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.1.1.8.8.2">
         11.3
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.1.1.8.8.3">
         1317.3
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T8.1.1.8.8.4">
         2.5
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.1.1.8.8.5">
         0.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.1.1.8.8.6">
         10285.4
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T8.1.1.8.8.7">
         11.8
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.1.1.8.8.8">
         6.9
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.1.1.8.8.9">
         1321.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T8.1.1.8.8.10">
         5.4
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.1.1.8.8.11">
         0.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.1.1.8.8.12">
         10406.5
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.1.1.8.8.13">
         33.3
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T8.1.1.9.9">
        <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A3.T8.1.1.9.9.1">
         Baichuan
        </th>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.1.1.9.9.2">
         13.2
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.1.1.9.9.3">
         1325.7
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T8.1.1.9.9.4">
         5.8
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.1.1.9.9.5">
         1.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.1.1.9.9.6">
         12018.5
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T8.1.1.9.9.7">
         60.3
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.1.1.9.9.8">
         2.5
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.1.1.9.9.9">
         1320.7
        </td>
        <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A3.T8.1.1.9.9.10">
         10.2
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.1.1.9.9.11">
         0.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.1.1.9.9.12">
         9818.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A3.T8.1.1.9.9.13">
         22.8
        </td>
       </tr>
       <tr class="ltx_tr" id="A3.T8.1.1.10.10">
        <th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t" id="A3.T8.1.1.10.10.1">
         CodeLLaMA
        </th>
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="A3.T8.1.1.10.10.2">
         22.4
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="A3.T8.1.1.10.10.3">
         3134.6
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="A3.T8.1.1.10.10.4">
         2.3
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="A3.T8.1.1.10.10.5">
         1.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="A3.T8.1.1.10.10.6">
         22536.2
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="A3.T8.1.1.10.10.7">
         17.2
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="A3.T8.1.1.10.10.8">
         12.6
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="A3.T8.1.1.10.10.9">
         3137.1
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="A3.T8.1.1.10.10.10">
         5.4
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="A3.T8.1.1.10.10.11">
         2.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="A3.T8.1.1.10.10.12">
         10001.1
        </td>
        <td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="A3.T8.1.1.10.10.13">
         13.3
        </td>
       </tr>
      </tbody>
     </table>
    </span>
   </div>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_table">
     Table 8:
    </span>
    We report the results of LLMs in the API update setting in this table. In this setting, we add 97 new APIs into the prompt to simulate the version update.
   </figcaption>
  </figure>
 </section>
 <section class="ltx_appendix" id="A4">
  <h2 class="ltx_title ltx_title_appendix">
   <span class="ltx_tag ltx_tag_appendix">
    Appendix D
   </span>
   Closed-source LLM’s Multilingual Results in the Editing Template Task
  </h2>
  <div class="ltx_para" id="A4.p1">
   <p class="ltx_p" id="A4.p1.1">
    We report the session-based performance of the creating new slides task in Figure
    <a class="ltx_ref" href="#A4.F9" title="Figure 9 ‣ Appendix D Closed-source LLM’s Multilingual Results in the Editing Template Task ‣ PPTC-R benchmark: Towards Evaluating the Robustness of Large Language Models for PowerPoint Task Completion">
     <span class="ltx_text ltx_ref_tag">
      9
     </span>
    </a>
    .
For the editing template task, we report the turn-based accuracy of 3 LLMs for it in Figure
    <a class="ltx_ref" href="#A4.F10" title="Figure 10 ‣ Appendix D Closed-source LLM’s Multilingual Results in the Editing Template Task ‣ PPTC-R benchmark: Towards Evaluating the Robustness of Large Language Models for PowerPoint Task Completion">
     <span class="ltx_text ltx_ref_tag">
      10
     </span>
    </a>
    . We find that all LLM’s session-based accuracy in this task is smaller than 4 percent. So we do not further report and analyze the session-based result.
   </p>
  </div>
  <figure class="ltx_figure" id="A4.F9">
   <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="225" id="A4.F9.g1" src="/html/2403.03788/assets/multi_task1_sess.png" width="598"/>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     Figure 9:
    </span>
    We illustrate the session-based results of closed-source LLMs in the creating new slides task, where the instructions are translated into 14 non-English languages. The bar for each language represents the LLM’s accuracy in the corresponding language setting. The dotted line is the LLM’s accuracy when tested in the English setting.
   </figcaption>
  </figure>
  <figure class="ltx_figure" id="A4.F10">
   <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="222" id="A4.F10.g1" src="/html/2403.03788/assets/multi_task2_tf.png" width="598"/>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     Figure 10:
    </span>
    We illustrate the turn-based results of closed-source LLMs in the editing template task, where the instructions are translated into 14 non-English languages. The bar for each language represents the LLM’s accuracy in the corresponding language setting. The dotted line is the LLM’s accuracy when tested in the English setting.
   </figcaption>
  </figure>
 </section>
 <section class="ltx_appendix" id="A5">
  <h2 class="ltx_title ltx_title_appendix">
   <span class="ltx_tag ltx_tag_appendix">
    Appendix E
   </span>
   Detailed Wrong Examples Made by LLMs
  </h2>
  <div class="ltx_para" id="A5.p1">
   <p class="ltx_p" id="A5.p1.1">
    We provide 4 typical wrong examples with their explanations in Figure
    <a class="ltx_ref" href="#A5.F11" title="Figure 11 ‣ Appendix E Detailed Wrong Examples Made by LLMs ‣ PPTC-R benchmark: Towards Evaluating the Robustness of Large Language Models for PowerPoint Task Completion">
     <span class="ltx_text ltx_ref_tag">
      11
     </span>
    </a>
    .
   </p>
  </div>
  <figure class="ltx_figure" id="A5.F11">
   <svg class="ltx_picture ltx_centering" height="1389.18" id="A5.F11.pic1" overflow="visible" version="1.1" width="600">
    <g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,1389.18) matrix(1 0 0 -1 0 0)">
     <g fill="#FF6C00" fill-opacity="1.0">
      <path d="M 0 5.91 L 0 741.18 C 0 744.44 2.64 747.09 5.91 747.09 L 594.09 747.09 C 597.36 747.09 600 744.44 600 741.18 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none">
      </path>
     </g>
     <g fill="#FFFFFF" fill-opacity="1.0">
      <path d="M 1.97 5.91 L 1.97 722.98 L 598.03 722.98 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none">
      </path>
     </g>
     <g color="#FF6C00" fill="#FF6C00" stroke="#FF6C00" stroke-dasharray="2.84528pt,2.84528pt" stroke-dashoffset="1.42264pt" stroke-opacity="1.0">
      <path d="M 300 722.98 L 300 1.97" style="fill:none">
      </path>
     </g>
     <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 728.88)">
      <foreignobject color="#000000" height="12.3" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">
       <span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A5.F11.pic1.2.2.2.1.1" style="width:402.3pt;">
        <span class="ltx_p" id="A5.F11.pic1.2.2.2.1.1.1">
         <span class="ltx_text ltx_font_bold" id="A5.F11.pic1.2.2.2.1.1.1.1">
          Calling unavailable APIs or new APIs     Misunderstanding the instruction
         </span>
        </span>
       </span>
      </foreignobject>
     </g>
     <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 701.48)">
      <foreignobject color="#000000" height="697.38" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">
       <span class="ltx_inline-logical-block ltx_minipage ltx_align_top" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1" style="width:402.3pt;">
        <span class="ltx_para ltx_noindent" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1">
         <span class="ltx_p" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.23">
          <span class="ltx_text" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.12.12">
           <span class="ltx_inline-block ltx_minipage ltx_align_top" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.12.12.12" style="width:186.9pt;">
            <span class="ltx_p" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.12.12.12.13">
             <span class="ltx_text ltx_font_bold" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.12.12.12.13.1">
              Example 1 (GPT-4 in the API update setting):
              <br class="ltx_break"/>
              Instruction
             </span>
             : Fill the star with blue color.
            </span>
            <span class="ltx_p" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.12.12.12.14">
             <span class="ltx_text ltx_font_bold" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.12.12.12.14.1">
              Generated API sequence
             </span>
             :
            </span>
            <span class="ltx_p" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.3.3.3.3">
             choose
             <math alttext="\_" class="ltx_Math" display="inline" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.1.1.1.m1.1">
              <semantics id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.1.1.1.m1.1a">
               <mi id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.1.1.1.m1.1.1" mathvariant="normal" xref="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.1.1.1.m1.1.1.cmml">
                _
               </mi>
               <annotation-xml encoding="MathML-Content" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.1.1.1.m1.1b">
                <ci id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.1.1.1.m1.1.1.cmml" xref="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.1.1.1.m1.1.1">
                 _
                </ci>
               </annotation-xml>
               <annotation encoding="application/x-tex" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.1.1.1.m1.1c">
                \_
               </annotation>
              </semantics>
             </math>
             shape(’star’)
set
             <math alttext="\_" class="ltx_Math" display="inline" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.2.2.2.2.m2.1">
              <semantics id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.2.2.2.2.m2.1a">
               <mi id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.2.2.2.2.m2.1.1" mathvariant="normal" xref="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.2.2.2.2.m2.1.1.cmml">
                _
               </mi>
               <annotation-xml encoding="MathML-Content" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.2.2.2.2.m2.1b">
                <ci id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.2.2.2.2.m2.1.1.cmml" xref="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.2.2.2.2.m2.1.1">
                 _
                </ci>
               </annotation-xml>
               <annotation encoding="application/x-tex" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.2.2.2.2.m2.1c">
                \_
               </annotation>
              </semantics>
             </math>
             shape
             <math alttext="\_" class="ltx_Math" display="inline" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.3.3.3.3.m3.1">
              <semantics id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.3.3.3.3.m3.1a">
               <mi id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.3.3.3.3.m3.1.1" mathvariant="normal" xref="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.3.3.3.3.m3.1.1.cmml">
                _
               </mi>
               <annotation-xml encoding="MathML-Content" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.3.3.3.3.m3.1b">
                <ci id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.3.3.3.3.m3.1.1.cmml" xref="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.3.3.3.3.m3.1.1">
                 _
                </ci>
               </annotation-xml>
               <annotation encoding="application/x-tex" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.3.3.3.3.m3.1c">
                \_
               </annotation>
              </semantics>
             </math>
             gradient(’star’, ’radial’, [’blue’, ’light blue’])
            </span>
            <span class="ltx_p" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.5.5.5.5">
             <span class="ltx_text ltx_font_bold" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.5.5.5.5.1">
              Explanation:
             </span>
             We do not provide the API set
             <math alttext="\_" class="ltx_Math" display="inline" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.4.4.4.4.m1.1">
              <semantics id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.4.4.4.4.m1.1a">
               <mi id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.4.4.4.4.m1.1.1" mathvariant="normal" xref="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.4.4.4.4.m1.1.1.cmml">
                _
               </mi>
               <annotation-xml encoding="MathML-Content" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.4.4.4.4.m1.1b">
                <ci id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.4.4.4.4.m1.1.1.cmml" xref="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.4.4.4.4.m1.1.1">
                 _
                </ci>
               </annotation-xml>
               <annotation encoding="application/x-tex" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.4.4.4.4.m1.1c">
                \_
               </annotation>
              </semantics>
             </math>
             shape
             <math alttext="\_" class="ltx_Math" display="inline" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.5.5.5.5.m2.1">
              <semantics id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.5.5.5.5.m2.1a">
               <mi id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.5.5.5.5.m2.1.1" mathvariant="normal" xref="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.5.5.5.5.m2.1.1.cmml">
                _
               </mi>
               <annotation-xml encoding="MathML-Content" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.5.5.5.5.m2.1b">
                <ci id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.5.5.5.5.m2.1.1.cmml" xref="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.5.5.5.5.m2.1.1">
                 _
                </ci>
               </annotation-xml>
               <annotation encoding="application/x-tex" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.5.5.5.5.m2.1c">
                \_
               </annotation>
              </semantics>
             </math>
             gradient in the API reference file.
            </span>
            <span class="ltx_p" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.12.12.12.15">
             <span class="ltx_text ltx_font_bold" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.12.12.12.15.1">
              Example 2 (ChatGPT in the API update setting)
             </span>
             "
            </span>
            <span class="ltx_p" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.12.12.12.16">
             <span class="ltx_text ltx_font_bold" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.12.12.12.16.1">
              Instruction
             </span>
             : Insert one clock. Make it on the right side.
            </span>
            <span class="ltx_p" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.12.12.12.17">
             <span class="ltx_text ltx_font_bold" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.12.12.12.17.1">
              Generated API sequence
             </span>
             :
            </span>
            <span class="ltx_p" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.7.7.7.7">
             insert
             <math alttext="\_" class="ltx_Math" display="inline" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.6.6.6.6.m1.1">
              <semantics id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.6.6.6.6.m1.1a">
               <mi id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.6.6.6.6.m1.1.1" mathvariant="normal" xref="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.6.6.6.6.m1.1.1.cmml">
                _
               </mi>
               <annotation-xml encoding="MathML-Content" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.6.6.6.6.m1.1b">
                <ci id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.6.6.6.6.m1.1.1.cmml" xref="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.6.6.6.6.m1.1.1">
                 _
                </ci>
               </annotation-xml>
               <annotation encoding="application/x-tex" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.6.6.6.6.m1.1c">
                \_
               </annotation>
              </semantics>
             </math>
             date
             <math alttext="\_" class="ltx_Math" display="inline" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.7.7.7.7.m2.1">
              <semantics id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.7.7.7.7.m2.1a">
               <mi id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.7.7.7.7.m2.1.1" mathvariant="normal" xref="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.7.7.7.7.m2.1.1.cmml">
                _
               </mi>
               <annotation-xml encoding="MathML-Content" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.7.7.7.7.m2.1b">
                <ci id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.7.7.7.7.m2.1.1.cmml" xref="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.7.7.7.7.m2.1.1">
                 _
                </ci>
               </annotation-xml>
               <annotation encoding="application/x-tex" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.7.7.7.7.m2.1c">
                \_
               </annotation>
              </semantics>
             </math>
             time("h:mm AM/PM", "right")
            </span>
            <span class="ltx_p" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.12.12.12.18">
             <span class="ltx_text ltx_font_bold" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.12.12.12.18.1">
              Label API sequence
             </span>
             :
            </span>
            <span class="ltx_p" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.8.8.8.8">
             insert
             <math alttext="\_" class="ltx_Math" display="inline" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.8.8.8.8.m1.1">
              <semantics id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.8.8.8.8.m1.1a">
               <mi id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.8.8.8.8.m1.1.1" mathvariant="normal" xref="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.8.8.8.8.m1.1.1.cmml">
                _
               </mi>
               <annotation-xml encoding="MathML-Content" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.8.8.8.8.m1.1b">
                <ci id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.8.8.8.8.m1.1.1.cmml" xref="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.8.8.8.8.m1.1.1">
                 _
                </ci>
               </annotation-xml>
               <annotation encoding="application/x-tex" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.8.8.8.8.m1.1c">
                \_
               </annotation>
              </semantics>
             </math>
             picture("clock")
            </span>
            <span class="ltx_p" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.10.10.10.10">
             align
             <math alttext="\_" class="ltx_Math" display="inline" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.9.9.9.9.m1.1">
              <semantics id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.9.9.9.9.m1.1a">
               <mi id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.9.9.9.9.m1.1.1" mathvariant="normal" xref="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.9.9.9.9.m1.1.1.cmml">
                _
               </mi>
               <annotation-xml encoding="MathML-Content" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.9.9.9.9.m1.1b">
                <ci id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.9.9.9.9.m1.1.1.cmml" xref="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.9.9.9.9.m1.1.1">
                 _
                </ci>
               </annotation-xml>
               <annotation encoding="application/x-tex" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.9.9.9.9.m1.1c">
                \_
               </annotation>
              </semantics>
             </math>
             slide
             <math alttext="\_" class="ltx_Math" display="inline" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.10.10.10.10.m2.1">
              <semantics id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.10.10.10.10.m2.1a">
               <mi id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.10.10.10.10.m2.1.1" mathvariant="normal" xref="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.10.10.10.10.m2.1.1.cmml">
                _
               </mi>
               <annotation-xml encoding="MathML-Content" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.10.10.10.10.m2.1b">
                <ci id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.10.10.10.10.m2.1.1.cmml" xref="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.10.10.10.10.m2.1.1">
                 _
                </ci>
               </annotation-xml>
               <annotation encoding="application/x-tex" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.10.10.10.10.m2.1c">
                \_
               </annotation>
              </semantics>
             </math>
             right()
            </span>
            <span class="ltx_p" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.12.12.12.12">
             <span class="ltx_text ltx_font_bold" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.12.12.12.12.1">
              Explanation
             </span>
             : The new API insert
             <math alttext="\_" class="ltx_Math" display="inline" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.11.11.11.11.m1.1">
              <semantics id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.11.11.11.11.m1.1a">
               <mi id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.11.11.11.11.m1.1.1" mathvariant="normal" xref="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.11.11.11.11.m1.1.1.cmml">
                _
               </mi>
               <annotation-xml encoding="MathML-Content" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.11.11.11.11.m1.1b">
                <ci id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.11.11.11.11.m1.1.1.cmml" xref="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.11.11.11.11.m1.1.1">
                 _
                </ci>
               </annotation-xml>
               <annotation encoding="application/x-tex" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.11.11.11.11.m1.1c">
                \_
               </annotation>
              </semantics>
             </math>
             date
             <math alttext="\_" class="ltx_Math" display="inline" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.12.12.12.12.m2.1">
              <semantics id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.12.12.12.12.m2.1a">
               <mi id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.12.12.12.12.m2.1.1" mathvariant="normal" xref="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.12.12.12.12.m2.1.1.cmml">
                _
               </mi>
               <annotation-xml encoding="MathML-Content" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.12.12.12.12.m2.1b">
                <ci id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.12.12.12.12.m2.1.1.cmml" xref="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.12.12.12.12.m2.1.1">
                 _
                </ci>
               </annotation-xml>
               <annotation encoding="application/x-tex" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.12.12.12.12.m2.1c">
                \_
               </annotation>
              </semantics>
             </math>
             time provided in the reference file is related to the clock (time). But it’s not the right API.
            </span>
           </span>
          </span>
          <span class="ltx_text" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.23.23">
           <span class="ltx_inline-block ltx_minipage ltx_align_top" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.23.23.11" style="width:186.9pt;">
            <span class="ltx_p" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.23.23.11.12">
             <span class="ltx_text ltx_font_bold" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.23.23.11.12.1">
              Example 1 (ChatGPT in the sentence-level robustness setting)
             </span>
            </span>
            <span class="ltx_p" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.23.23.11.13">
             <span class="ltx_text ltx_font_bold" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.23.23.11.13.1">
              Instruction
             </span>
             : You know, I’ve always admired the creativity and innovation behind successful business plans. Anyway, go ahead and create a slide and insert the title "Business Plan". By the way, have you ever noticed how soothing the color blue can be? It’s one of my favorites.
            </span>
            <span class="ltx_p" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.23.23.11.14">
             <span class="ltx_text ltx_font_bold" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.23.23.11.14.1">
              Generated API sequence
             </span>
             :
            </span>
            <span class="ltx_p" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.13.13.1.1">
             create
             <math alttext="\_" class="ltx_Math" display="inline" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.13.13.1.1.m1.1">
              <semantics id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.13.13.1.1.m1.1a">
               <mi id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.13.13.1.1.m1.1.1" mathvariant="normal" xref="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.13.13.1.1.m1.1.1.cmml">
                _
               </mi>
               <annotation-xml encoding="MathML-Content" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.13.13.1.1.m1.1b">
                <ci id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.13.13.1.1.m1.1.1.cmml" xref="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.13.13.1.1.m1.1.1">
                 _
                </ci>
               </annotation-xml>
               <annotation encoding="application/x-tex" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.13.13.1.1.m1.1c">
                \_
               </annotation>
              </semantics>
             </math>
             slide()
            </span>
            <span class="ltx_p" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.14.14.2.2">
             choose
             <math alttext="\_" class="ltx_Math" display="inline" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.14.14.2.2.m1.1">
              <semantics id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.14.14.2.2.m1.1a">
               <mi id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.14.14.2.2.m1.1.1" mathvariant="normal" xref="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.14.14.2.2.m1.1.1.cmml">
                _
               </mi>
               <annotation-xml encoding="MathML-Content" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.14.14.2.2.m1.1b">
                <ci id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.14.14.2.2.m1.1.1.cmml" xref="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.14.14.2.2.m1.1.1">
                 _
                </ci>
               </annotation-xml>
               <annotation encoding="application/x-tex" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.14.14.2.2.m1.1c">
                \_
               </annotation>
              </semantics>
             </math>
             title()
            </span>
            <span class="ltx_p" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.15.15.3.3">
             insert
             <math alttext="\_" class="ltx_Math" display="inline" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.15.15.3.3.m1.1">
              <semantics id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.15.15.3.3.m1.1a">
               <mi id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.15.15.3.3.m1.1.1" mathvariant="normal" xref="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.15.15.3.3.m1.1.1.cmml">
                _
               </mi>
               <annotation-xml encoding="MathML-Content" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.15.15.3.3.m1.1b">
                <ci id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.15.15.3.3.m1.1.1.cmml" xref="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.15.15.3.3.m1.1.1">
                 _
                </ci>
               </annotation-xml>
               <annotation encoding="application/x-tex" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.15.15.3.3.m1.1c">
                \_
               </annotation>
              </semantics>
             </math>
             text("Business Plan")
            </span>
            <span class="ltx_p" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.17.17.5.5">
             set
             <math alttext="\_" class="ltx_Math" display="inline" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.16.16.4.4.m1.1">
              <semantics id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.16.16.4.4.m1.1a">
               <mi id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.16.16.4.4.m1.1.1" mathvariant="normal" xref="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.16.16.4.4.m1.1.1.cmml">
                _
               </mi>
               <annotation-xml encoding="MathML-Content" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.16.16.4.4.m1.1b">
                <ci id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.16.16.4.4.m1.1.1.cmml" xref="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.16.16.4.4.m1.1.1">
                 _
                </ci>
               </annotation-xml>
               <annotation encoding="application/x-tex" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.16.16.4.4.m1.1c">
                \_
               </annotation>
              </semantics>
             </math>
             background
             <math alttext="\_" class="ltx_Math" display="inline" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.17.17.5.5.m2.1">
              <semantics id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.17.17.5.5.m2.1a">
               <mi id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.17.17.5.5.m2.1.1" mathvariant="normal" xref="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.17.17.5.5.m2.1.1.cmml">
                _
               </mi>
               <annotation-xml encoding="MathML-Content" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.17.17.5.5.m2.1b">
                <ci id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.17.17.5.5.m2.1.1.cmml" xref="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.17.17.5.5.m2.1.1">
                 _
                </ci>
               </annotation-xml>
               <annotation encoding="application/x-tex" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.17.17.5.5.m2.1c">
                \_
               </annotation>
              </semantics>
             </math>
             color("blue")
            </span>
            <span class="ltx_p" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.19.19.7.7">
             <span class="ltx_text ltx_font_bold" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.19.19.7.7.1">
              Explanation
             </span>
             : The LLM misunderstands the instruction and generates extra ’set
             <math alttext="\_" class="ltx_Math" display="inline" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.18.18.6.6.m1.1">
              <semantics id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.18.18.6.6.m1.1a">
               <mi id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.18.18.6.6.m1.1.1" mathvariant="normal" xref="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.18.18.6.6.m1.1.1.cmml">
                _
               </mi>
               <annotation-xml encoding="MathML-Content" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.18.18.6.6.m1.1b">
                <ci id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.18.18.6.6.m1.1.1.cmml" xref="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.18.18.6.6.m1.1.1">
                 _
                </ci>
               </annotation-xml>
               <annotation encoding="application/x-tex" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.18.18.6.6.m1.1c">
                \_
               </annotation>
              </semantics>
             </math>
             background
             <math alttext="\_" class="ltx_Math" display="inline" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.19.19.7.7.m2.1">
              <semantics id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.19.19.7.7.m2.1a">
               <mi id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.19.19.7.7.m2.1.1" mathvariant="normal" xref="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.19.19.7.7.m2.1.1.cmml">
                _
               </mi>
               <annotation-xml encoding="MathML-Content" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.19.19.7.7.m2.1b">
                <ci id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.19.19.7.7.m2.1.1.cmml" xref="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.19.19.7.7.m2.1.1">
                 _
                </ci>
               </annotation-xml>
               <annotation encoding="application/x-tex" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.19.19.7.7.m2.1c">
                \_
               </annotation>
              </semantics>
             </math>
             color("blue")’ API action, which leads to the wrong prediction.
            </span>
            <span class="ltx_p" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.23.23.11.15">
             <span class="ltx_text ltx_font_bold" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.23.23.11.15.1">
              Example 2 (GPT-4 in the sentence-level robustness setting)
             </span>
             "
            </span>
            <span class="ltx_p" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.23.23.11.16">
             <span class="ltx_text ltx_font_bold" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.23.23.11.16.1">
              Instruction
             </span>
             : I hope you’re having a great day! By the way, the height of the picture should be 2 on slide 6, and it’s incredible how technology can help us with these tasks. While you’re at it, the font size of all textboxes should be 10 on slide 11. Time flies when you’re working on presentations, doesn’t it?
            </span>
            <span class="ltx_p" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.23.23.11.17">
             <span class="ltx_text ltx_font_bold" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.23.23.11.17.1">
              Generated API sequence
             </span>
             :
            </span>
            <span class="ltx_p" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.21.21.9.9">
             move
             <math alttext="\_" class="ltx_Math" display="inline" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.20.20.8.8.m1.1">
              <semantics id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.20.20.8.8.m1.1a">
               <mi id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.20.20.8.8.m1.1.1" mathvariant="normal" xref="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.20.20.8.8.m1.1.1.cmml">
                _
               </mi>
               <annotation-xml encoding="MathML-Content" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.20.20.8.8.m1.1b">
                <ci id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.20.20.8.8.m1.1.1.cmml" xref="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.20.20.8.8.m1.1.1">
                 _
                </ci>
               </annotation-xml>
               <annotation encoding="application/x-tex" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.20.20.8.8.m1.1c">
                \_
               </annotation>
              </semantics>
             </math>
             to
             <math alttext="\_" class="ltx_Math" display="inline" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.21.21.9.9.m2.1">
              <semantics id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.21.21.9.9.m2.1a">
               <mi id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.21.21.9.9.m2.1.1" mathvariant="normal" xref="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.21.21.9.9.m2.1.1.cmml">
                _
               </mi>
               <annotation-xml encoding="MathML-Content" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.21.21.9.9.m2.1b">
                <ci id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.21.21.9.9.m2.1.1.cmml" xref="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.21.21.9.9.m2.1.1">
                 _
                </ci>
               </annotation-xml>
               <annotation encoding="application/x-tex" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.21.21.9.9.m2.1c">
                \_
               </annotation>
              </semantics>
             </math>
             slide(6)
            </span>
            <span class="ltx_p" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.22.22.10.10">
             choose
             <math alttext="\_" class="ltx_Math" display="inline" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.22.22.10.10.m1.1">
              <semantics id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.22.22.10.10.m1.1a">
               <mi id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.22.22.10.10.m1.1.1" mathvariant="normal" xref="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.22.22.10.10.m1.1.1.cmml">
                _
               </mi>
               <annotation-xml encoding="MathML-Content" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.22.22.10.10.m1.1b">
                <ci id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.22.22.10.10.m1.1.1.cmml" xref="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.22.22.10.10.m1.1.1">
                 _
                </ci>
               </annotation-xml>
               <annotation encoding="application/x-tex" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.22.22.10.10.m1.1c">
                \_
               </annotation>
              </semantics>
             </math>
             picture(0)
            </span>
            <span class="ltx_p" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.23.23.11.11">
             set
             <math alttext="\_" class="ltx_Math" display="inline" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.23.23.11.11.m1.1">
              <semantics id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.23.23.11.11.m1.1a">
               <mi id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.23.23.11.11.m1.1.1" mathvariant="normal" xref="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.23.23.11.11.m1.1.1.cmml">
                _
               </mi>
               <annotation-xml encoding="MathML-Content" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.23.23.11.11.m1.1b">
                <ci id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.23.23.11.11.m1.1.1.cmml" xref="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.23.23.11.11.m1.1.1">
                 _
                </ci>
               </annotation-xml>
               <annotation encoding="application/x-tex" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.23.23.11.11.m1.1c">
                \_
               </annotation>
              </semantics>
             </math>
             height(2)
            </span>
            <span class="ltx_p" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.23.23.11.18">
             <span class="ltx_text ltx_font_bold" id="A5.F11.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.23.23.11.18.1">
              Explanation
             </span>
             : The LLM misunderstands the instruction and forgets to set the font size of all textboxes to be 10 on slide 11.
            </span>
           </span>
          </span>
         </span>
        </span>
       </span>
      </foreignobject>
     </g>
    </g>
   </svg>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     Figure 11:
    </span>
    The detailed wrong examples with their explanations.
   </figcaption>
  </figure>
  <div class="ltx_pagination ltx_role_newpage">
  </div>
 </section>
</article>
