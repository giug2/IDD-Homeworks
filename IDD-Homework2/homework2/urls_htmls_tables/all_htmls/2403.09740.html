<!DOCTYPE html>

<html lang="en" prefix="dcterms: http://purl.org/dc/terms/">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Teaching Machines to Code: Smart Contract Translation with LLMs</title>
<!--Generated on Wed Mar 13 18:54:03 2024 by LaTeXML (version 0.8.7) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv_0.7.4.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2403.09740v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#S1" title="1 Introduction ‣ Teaching Machines to Code: Smart Contract Translation with LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#S2" title="2 SolMover ‣ Teaching Machines to Code: Smart Contract Translation with LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>SolMover</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#S2.SS1" title="2.1 Code Understanding ‣ 2 SolMover ‣ Teaching Machines to Code: Smart Contract Translation with LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Code Understanding</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#S2.SS2" title="2.2 Concept Mining ‣ 2 SolMover ‣ Teaching Machines to Code: Smart Contract Translation with LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Concept Mining</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#S2.SS2.SSS1" title="2.2.1 Architecture ‣ 2.2 Concept Mining ‣ 2 SolMover ‣ Teaching Machines to Code: Smart Contract Translation with LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2.1 </span>Architecture</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#S2.SS3" title="2.3 Concept Selection ‣ 2 SolMover ‣ Teaching Machines to Code: Smart Contract Translation with LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Concept Selection</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#S2.SS4" title="2.4 Sol-Mover Code Generator ‣ 2 SolMover ‣ Teaching Machines to Code: Smart Contract Translation with LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.4 </span>Sol-Mover Code Generator</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#S2.SS5" title="2.5 Dataset for Solidity as Input Candidate ‣ 2 SolMover ‣ Teaching Machines to Code: Smart Contract Translation with LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.5 </span>Dataset for Solidity as Input Candidate</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#S2.SS5.SSS0.Px1" title="Compilation of the raw code corpus. ‣ 2.5 Dataset for Solidity as Input Candidate ‣ 2 SolMover ‣ Teaching Machines to Code: Smart Contract Translation with LLMs"><span class="ltx_text ltx_ref_title">Compilation of the raw code corpus.</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#S3" title="3 Technical Specification ‣ Teaching Machines to Code: Smart Contract Translation with LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Technical Specification</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#S3.SS1" title="3.1 Retrieval Augmented LLM for Concept Understanding ‣ 3 Technical Specification ‣ Teaching Machines to Code: Smart Contract Translation with LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Retrieval Augmented LLM for Concept Understanding</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#S3.SS1.SSS1" title="3.1.1 Experimental Setup ‣ 3.1 Retrieval Augmented LLM for Concept Understanding ‣ 3 Technical Specification ‣ Teaching Machines to Code: Smart Contract Translation with LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.1 </span>Experimental Setup</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#S3.SS2" title="3.2 Sol-Mover Code Generation Training ‣ 3 Technical Specification ‣ Teaching Machines to Code: Smart Contract Translation with LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Sol-Mover Code Generation Training</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#S4" title="4 Experiments ‣ Teaching Machines to Code: Smart Contract Translation with LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#S4.SS1" title="4.1 Experimental Setup ‣ 4 Experiments ‣ Teaching Machines to Code: Smart Contract Translation with LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Experimental Setup</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#S4.SS1.SSS0.Px1" title="Models. ‣ 4.1 Experimental Setup ‣ 4 Experiments ‣ Teaching Machines to Code: Smart Contract Translation with LLMs"><span class="ltx_text ltx_ref_title">Models.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#S4.SS1.SSS0.Px2" title="Comparative Methods ‣ 4.1 Experimental Setup ‣ 4 Experiments ‣ Teaching Machines to Code: Smart Contract Translation with LLMs"><span class="ltx_text ltx_ref_title">Comparative Methods</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#S4.SS1.SSS0.Px3" title="Metrics and Benchmark ‣ 4.1 Experimental Setup ‣ 4 Experiments ‣ Teaching Machines to Code: Smart Contract Translation with LLMs"><span class="ltx_text ltx_ref_title">Metrics and Benchmark</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#S5" title="5 Results ‣ Teaching Machines to Code: Smart Contract Translation with LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Results</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#S5.SS1" title="5.1 Successful Smart Contract Translation ‣ 5 Results ‣ Teaching Machines to Code: Smart Contract Translation with LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Successful Smart Contract Translation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#S5.SS2" title="5.2 Reducing Bugs using Iterative Error Feedback ‣ 5 Results ‣ Teaching Machines to Code: Smart Contract Translation with LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Reducing Bugs using Iterative Error Feedback</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#S5.SS3" title="5.3 Correctness ‣ 5 Results ‣ Teaching Machines to Code: Smart Contract Translation with LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3 </span>Correctness</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#S6" title="6 Discussion &amp; Analysis ‣ Teaching Machines to Code: Smart Contract Translation with LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Discussion &amp; Analysis</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#S6.SS1" title="6.1 Concept Distillation ‣ 6 Discussion &amp; Analysis ‣ Teaching Machines to Code: Smart Contract Translation with LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.1 </span>Concept Distillation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#S6.SS2" title="6.2 Smart Contract Translation ‣ 6 Discussion &amp; Analysis ‣ Teaching Machines to Code: Smart Contract Translation with LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.2 </span>Smart Contract Translation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#S7" title="7 Related Work ‣ Teaching Machines to Code: Smart Contract Translation with LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#S8" title="8 Conclusion ‣ Teaching Machines to Code: Smart Contract Translation with LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8 </span>Conclusion</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<div aria-label="Conversion errors have been found" class="package-alerts ltx_document" role="status">
<button aria-label="Dismiss alert" onclick="closePopup()">
<span aria-hidden="true"><svg aria-hidden="true" focusable="false" height="20" role="presentation" viewbox="0 0 44 44" width="20">
<path d="M0.549989 4.44999L4.44999 0.549988L43.45 39.55L39.55 43.45L0.549989 4.44999Z"></path>
<path d="M39.55 0.549988L43.45 4.44999L4.44999 43.45L0.549988 39.55L39.55 0.549988Z"></path>
</svg></span>
</button>
<p>HTML conversions <a href="https://info.dev.arxiv.org/about/accessibility_html_error_messages.html" target="_blank">sometimes display errors</a> due to content that did not convert correctly from the source. This paper uses the following packages that are not yet supported by the HTML conversion tool. Feedback on these issues are not necessary; they are known and are being worked on.</p>
<ul arial-label="Unsupported packages used in this paper">
<li>failed: inconsolata</li>
<li>failed: arydshln</li>
<li>failed: nicematrix</li>
<li>failed: fontawesome</li>
</ul>
<p>Authors: achieve the best HTML results from your LaTeX submissions by following these <a href="https://info.arxiv.org/help/submit_latex_best_practices.html" target="_blank">best practices</a>.</p>
</div><div class="section" id="target-section"><div id="license-tr">License: CC BY-NC-ND 4.0</div><div id="watermark-tr">arXiv:2403.09740v1 [cs.SE] 13 Mar 2024</div></div>
<script>
            function closePopup() {
                document.querySelector('.package-alerts').style.display = 'none';
            }
        </script>
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Teaching Machines to Code: Smart Contract Translation with LLMs</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> <a class="ltx_ref ltx_href" href="https://orcid.org/0000-0002-6705-6506" title=""><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="8" id="id1.1.1.g1" src="x1.png" width="8"/> Rabimba Karanjai</a>
<br class="ltx_break"/>Department of Computer Science
<br class="ltx_break"/>University Of Houston
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id2.2.id1">rkaranjai@uh.edu</span>
<br class="ltx_break"/>&amp;Lei Xu 
<br class="ltx_break"/>Department of Computer Science
<br class="ltx_break"/>Kent State University 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id3.3.id2">xuleimath@gmail.com
<br class="ltx_break"/></span>&amp;Weidong Shi 
<br class="ltx_break"/>Department of Computer Science
<br class="ltx_break"/>University Of Houston 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id4.4.id3">wshi3@uh.edu
<br class="ltx_break"/></span>
</span><span class="ltx_author_notes">www.rabimba.me</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id5.id1">The advent of large language models (LLMs) has marked a significant milestone in the realm of artificial intelligence, with their capabilities often matching or surpassing human expertise in various domains. Among these achievements, their adeptness in translation tasks stands out, closely mimicking the intricate and preliminary processes undertaken by human translators to ensure the fidelity and quality of the translated content. Despite the advancements in utilizing LLMs for translating programming code across different languages, the domain of smart contract translation, particularly into languages not previously encountered by the LLM, remains largely unexplored. In our research, we present a pioneering approach, SolMover, which harnesses the synergy of two distinct LLMs within a unified framework. This framework is designed to grasp coding principles and apply this understanding to the translation of code into an unfamiliar language. Our study delves into the capacity of LLMs to mimic human learning processes, offering an in-depth evaluation of our methodology for converting smart contracts written in Solidity to Move, a language with limited resources. The framework employs one LLM to decipher coding conventions for the new language, creating a blueprint for the second LLM, which, lacking planning abilities, possesses coding expertise. The empirical evidence from our experiments suggests that SolMover substantially enhances performance compared to gpt-3.5-turbo-1106, and achieves superior results over competitors such as Palm2 and Mixtral-8x7B-Instruct. Additionally, our analysis highlights the efficacy of our bug mitigation strategy in elevating code quality across all models, even outside the SolMover framework.</p>
</div>
<div class="ltx_para ltx_noindent" id="p1">
<p class="ltx_p" id="p1.1"><em class="ltx_emph ltx_font_bold ltx_font_italic" id="p1.1.1">Keywords</em> Smart Contracts, Machine Learning, Machine Translation, Code Transpilation, LLM, Large Language Model</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para ltx_noindent" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">The groundbreaking strides in Large Language Models (LLMs) have been instrumental in shaping a future that mirrors human cognitive abilities, particularly in the understanding and generation of natural language. These models, acclaimed for their near-human intelligence, have significantly advanced the field of natural language processing, as highlighted by several seminal works <cite class="ltx_cite ltx_citemacro_cite">Liang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib1" title="">2022</a>); Bubeck et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib2" title="">2023</a>); Wu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib3" title="">2023</a>); Moghaddam and Honey (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib4" title="">2023</a>)</cite>. The prowess of LLMs in the realm of natural language translation has been especially pronounced, underscoring their capability to execute translations with remarkable accuracy and efficiency <cite class="ltx_cite ltx_citemacro_cite">Jiao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib5" title="">2023</a>); Agrawal et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib6" title="">2023</a>); Zhang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib7" title="">2023a</a>); Vilar et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib8" title="">2022</a>); Lu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib9" title="">2023</a>)</cite>. This progress resonates deeply with the aspirations of early machine translation researchers from the 1960s, prompting a reevaluation of whether LLMs can replicate human translation methodologies <cite class="ltx_cite ltx_citemacro_cite">Bar-Hillel (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib10" title="">1960</a>); Macklovitch (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib11" title="">1995</a>)</cite>. Consequently, this beckons the exploration of LLMs in the domain of code-to-code translation, leveraging their advanced translation mechanisms.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">In the context of the financial industry, the rapid expansion of decentralized ledger technologies and smart contracts has been noteworthy. The utilization of Uniswap’s smart contracts, for instance, achieved an average daily transaction volume of approximately $7.17 billion in 2021, underscoring the growing significance of smart contracts across various applications, including Confidential Computing and Decentralized Serverless Architectures <cite class="ltx_cite ltx_citemacro_cite">Benson (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib12" title="">2021</a>); Rabimba et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib13" title="">2022</a>); Karanjai et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib14" title="">2023a</a>)</cite>. This surge in adoption raises pertinent questions about the potential of LLMs to not only author smart contracts based on user directives but also ensure their security and robustness.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Our research endeavors to unravel the capabilities and limitations of LLMs in the translation of smart contract code. We investigate the feasibility of employing LLMs to translate smart contracts, focusing on their ability to emulate human translation techniques. This inquiry centers on the potential of LLMs to comprehend a smart contract written in Solidity and to produce an equivalent in another language, Move, in this case. Our approach seeks to encapsulate smart contract concepts within the model, facilitating a universal framework for code transpilation.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">To achieve this, we introduce SolMover, a system designed to bridge the gap between Solidity and Move through a multi-step knowledge distillation process. This process involves parsing Solidity files to extract functions and content, subsequently generating high-level tasks that inform the creation of sub-tasks by a fine-tuned LLM. This LLM, having been fine-tuned on textbooks and specifications related to both Solidity and Move, paves the way for a secondary, more specialized code generation model to produce the equivalent Move code. Verification and error correction mechanisms, including move-prover and multi-prompting techniques, further refine the quality of the generated code. Our study aims to elucidate the following research queries:</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p5">
<p class="ltx_p" id="S1.p5.1"><span class="ltx_text ltx_font_bold" id="S1.p5.1.1">RQ1:</span> We explore the LLMs’ ability to internalize coding concepts, particularly those of the Move language, assessing whether they can learn programmatic rules from textual descriptions and apply these in code generation.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p6">
<p class="ltx_p" id="S1.p6.1"><span class="ltx_text ltx_font_bold" id="S1.p6.1.1">RQ2:</span> We assess the generation of specific sub-tasks from a general prompt, evaluating the utility of these sub-tasks in code production.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p7">
<p class="ltx_p" id="S1.p7.1"><span class="ltx_text ltx_font_bold" id="S1.p7.1.1">RQ3:</span> Our investigation extends to the generation of compilable Move code by a model not extensively trained on Move, questioning the limits of LLMs’ adaptability.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p8">
<p class="ltx_p" id="S1.p8.1"><span class="ltx_text ltx_font_bold" id="S1.p8.1.1">RQ4:</span> We examine the efficacy of compiler feedback in debugging and enhancing code quality, and the extent to which prompting techniques aid in this process.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p9">
<p class="ltx_p" id="S1.p9.1">The Move language, developed for the Libra Blockchain, introduces unique asset types with stringent safety measures, posing a unique challenge for code translation from Solidity. This work contributes to the field by demonstrating the potential of LLMs to translate code between languages, refine code generation through compiler feedback, and apply knowledge distillation for translating to low-resource languages. To our knowledge, this is the first study to illustrate the feasibility of using LLMs for generating compilable code in a low-resource language through fine-tuning and strategic model integration.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>SolMover</h2>
<div class="ltx_para ltx_noindent" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">In the present section, we unveil the architecture of the SolMover framework.</p>
</div>
<figure class="ltx_figure" id="S2.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="578" id="S2.F1.g1" src="extracted/5469016/figs/Solidity_upgrade.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>The architecture of the <span class="ltx_text ltx_font_bold" id="S2.F1.2.1">SolMover</span> framework is delineated across five phases: (1) Task Creation involves the parsing of a Solidity file to generate the initial task prompt, utilizing comments and keywords found within the smart contract. (2) In Concept Mining, a retrieval-augmented technique is employed to extract concepts from Move programming resources to create sub-tasks derived from the initial prompt. (3) Code Generation leverages these sub-tasks, refined through concept mining, to produce code for each sub-task. These segments are subsequently compiled into a unified Move file, representing the candidate translation. (4) This code undergoes compilation; failures in this process trigger a feedback loop, where the error is reported back to SolMover for prompt modification and code regeneration. (5) Successfully compiled code is subjected to verification through the Move Prover to assess its provability. Should verification fail, the error is integrated into the prompt for corrective regeneration by SolMover.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">As illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#S2.F1" title="Figure 1 ‣ 2 SolMover ‣ Teaching Machines to Code: Smart Contract Translation with LLMs"><span class="ltx_text ltx_ref_tag">1</span></a>, the SolMover framework is composed of several interconnected modules. <span class="ltx_text ltx_font_italic" id="S2.p2.1.1">In the first module</span>, the analysis of the Solidity smart contract slated for translation is carried out, employing a method akin to that proposed by Karanjai et al. <cite class="ltx_cite ltx_citemacro_cite">Karanjai et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib15" title="">2023b</a>)</cite> for the extraction of functions and comments from the Solidity file. The module synergizes a parser and a comment extractor to mine comments from the code, utilizing a prompt template similar to the one described in <cite class="ltx_cite ltx_citemacro_cite">Karanjai et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib15" title="">2023b</a>)</cite> to formulate the initial task prompt. <span class="ltx_text ltx_font_italic" id="S2.p2.1.2">The second module</span> features the LLM tasker, which sources from Move documentation, whitepapers, and tutorials to conduct a Retrieval Augmented Search, generating sub-tasks aligned with the initial prompt. These sub-tasks are subsequently processed by a second, specifically tuned LLM (Sol-Mover), culminating in the assembly of the final Move code in <span class="ltx_text ltx_font_italic" id="S2.p2.1.3">Module 4</span>. Here, the move-cli tool attempts to compile the translated code, recording successful compilations and flagging compilation failures by feeding error messages back to Sol-Mover for iterative code regeneration, with a maximum of five attempts before declaring a translation failure. <span class="ltx_text ltx_font_italic" id="S2.p2.1.4">In the fifth module</span>, the framework endeavors to validate the compilable code’s correctness through the Move Prover <cite class="ltx_cite ltx_citemacro_cite">Zhong et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib16" title="">2020</a>)</cite>, aiming to formally prove the smart contract’s adherence to its specifications. Failures in verification prompt a feedback loop, where Sol-Mover reattempts correction by incorporating the identified errors into the prompt. After a maximum of five iterations, if the code’s correctness is established, it is designated as a safe contract; otherwise, it is considered compilable but unverified.</p>
</div>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Code Understanding</h3>
<div class="ltx_para ltx_noindent" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">As we transition our efforts from code translation to code generation, it becomes imperative to comprehend the functionalities and intentions encapsulated within the original input code. To facilitate this understanding, we have devised a parser dedicated to analyzing Solidity files. This parser is capable of extracting comments, functions, and formulating an initial candidate prompt based on the content of the Solidity file, despite the description being <span class="ltx_text" id="S2.SS1.p1.1.1" style="color:#FF0000;">incomplete</span>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1">The significance of <span class="ltx_text ltx_font_italic" id="S2.SS1.p2.1.1">comments</span> in deciphering the functionality and intended outcomes of a Solidity smart contract cannot be overstated. These comments, embedded within the code, serve as guides, illuminating the underlying logic and primary objectives of the contract. They are instrumental in grasping the developer’s original intentions and guaranteeing the precise execution of the code. The parsing of Solidity code to extract these insights is executed utilizing methodologies paralleled to those described in <cite class="ltx_cite ltx_citemacro_cite">Karanjai et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib17" title="">2023c</a>)</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS1.p3">
<p class="ltx_p" id="S2.SS1.p3.1">The <span class="ltx_text ltx_font_italic" id="S2.SS1.p3.1.1">Topic</span> of the Solidity code essentially encapsulates the contract’s functionality, typically inferred from the preliminary comments and the functions utilized within the code. This is exemplified in the code snippet presented in Listing <span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:lst:solidty</span>, which outlines a rudimentary hotel and vending machine Solidity smart contract. This contract enables the renting of hotel rooms, allowing payments for a room under the condition it is vacant. Upon payment, funds are transferred to the owner’s account. This contract metaphorically resembles a vending machine, where an input of funds, upon successful validation, results in the delivery of a product or service, akin to a gumball machine. The concept includes potential expansions such as unlocking doors or dispensing key codes post-payment, demonstrating the contract’s foundational logic and its intended purpose.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Concept Mining</h3>
<div class="ltx_para ltx_noindent" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">Drawing inspiration from the principles underlying human translation methodologies as explicated by Gile <cite class="ltx_cite ltx_citemacro_cite">Gile (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib18" title="">2009</a>)</cite>, the procedure of concept mining necessitates that the Large Language Model (LLM) initially generates output that is congruent with the pertinent concepts and knowledge essential for the task of transpilation.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1">The process of concept mining entails the fine-tuning of an LLM using textbook data specific to the Move programming language. Following the methodology outlined by Gunasekar et al <cite class="ltx_cite ltx_citemacro_cite">Gunasekar et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib19" title="">2023</a>)</cite>, the dataset is meticulously prepared and the model is subsequently fine-tuned. Furthermore, strategies for identifying relevant textual material are incorporated as per the guidelines provided by Zhang et al <cite class="ltx_cite ltx_citemacro_cite">Zhang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib20" title="">2023b</a>)</cite> and Lu et al <cite class="ltx_cite ltx_citemacro_cite">Lu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib21" title="">2022</a>)</cite>. The dataset preparation is depicted in Figure <span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:fig:conceptdist</span>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS2.p3">
<p class="ltx_p" id="S2.SS2.p3.1">In this context, various sources are employed for the extraction of concepts, including textbooks on Move <cite class="ltx_cite ltx_citemacro_cite">Int (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib22" title="">2023</a>); The (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib23" title="">2022</a>)</cite>, blogs pertaining to Move programming <cite class="ltx_cite ltx_citemacro_cite">mov (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib24" title="">2023a</a>)</cite>, and tutorials featuring code snippets <cite class="ltx_cite ltx_citemacro_cite">mov (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib25" title="">2023b</a>)</cite>, alongside code samples from the repository <cite class="ltx_cite ltx_citemacro_cite">Sui (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib26" title="">2023</a>)</cite>. Notably, the fine-tuning of the model intentionally eschews the use of any code corpus.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS2.p4">
<p class="ltx_p" id="S2.SS2.p4.1">For preparing the dataset we use scripts from <cite class="ltx_cite ltx_citemacro_cite">hfc (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib27" title="">2023</a>)</cite> modified to work for our files.</p>
</div>
<section class="ltx_subsubsection" id="S2.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.2.1 </span>Architecture</h4>
<div class="ltx_para ltx_noindent" id="S2.SS2.SSS1.p1">
<p class="ltx_p" id="S2.SS2.SSS1.p1.1">Within our architectural framework, we incorporate the methodology of Retrieval Augmented Generation as delineated by Zhang et al <cite class="ltx_cite ltx_citemacro_cite">Zhang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib20" title="">2023b</a>)</cite>, tailored to our specific needs for concept identification. This adaptation acknowledges the distinct requirements of our task compared to the original application of the method.
</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS2.SSS1.p2">
<p class="ltx_p" id="S2.SS2.SSS1.p2.3">We posit the existence of a comprehensive textbook database, replete with a diverse array of textual content and code snippets, as detailed in Section <a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#S2.SS2" title="2.2 Concept Mining ‣ 2 SolMover ‣ Teaching Machines to Code: Smart Contract Translation with LLMs"><span class="ltx_text ltx_ref_tag">2.2</span></a>. From this repository, we derive <math alttext="D" class="ltx_Math" display="inline" id="S2.SS2.SSS1.p2.1.m1.1"><semantics id="S2.SS2.SSS1.p2.1.m1.1a"><mi id="S2.SS2.SSS1.p2.1.m1.1.1" xref="S2.SS2.SSS1.p2.1.m1.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS1.p2.1.m1.1b"><ci id="S2.SS2.SSS1.p2.1.m1.1.1.cmml" xref="S2.SS2.SSS1.p2.1.m1.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS1.p2.1.m1.1c">D</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS1.p2.1.m1.1d">italic_D</annotation></semantics></math> text snippets by segmenting the documents. Given that these documents are in HTML format, segmentation is achieved through the identification of <span class="ltx_text ltx_font_bold" id="S2.SS2.SSS1.p2.3.1">H</span> tags or <span class="ltx_text ltx_font_bold" id="S2.SS2.SSS1.p2.3.2">Headings</span> in the HTML code, or alternatively, in the absence of prominent text blocks, accompanied by smaller textual segments. This strategy aims to delineate concept headings and their corresponding descriptions. Utilizing the Dense Passage Retriever (DPR) methodology <cite class="ltx_cite ltx_citemacro_cite">Karpukhin et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib28" title="">2020</a>)</cite>, we further divide these text segments into equally sized fragments, serving as the primary units for search and retrieval. This approach is predicated on the premise that such a division facilitates enhanced retrieval efficacy, as suggested by Karpukhin et al <cite class="ltx_cite ltx_citemacro_cite">Karpukhin et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib28" title="">2020</a>)</cite>, and concurrently, augments the scalability of our framework to accommodate substantial file sizes. Consequently, we amass <math alttext="M" class="ltx_Math" display="inline" id="S2.SS2.SSS1.p2.2.m2.1"><semantics id="S2.SS2.SSS1.p2.2.m2.1a"><mi id="S2.SS2.SSS1.p2.2.m2.1.1" xref="S2.SS2.SSS1.p2.2.m2.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS1.p2.2.m2.1b"><ci id="S2.SS2.SSS1.p2.2.m2.1.1.cmml" xref="S2.SS2.SSS1.p2.2.m2.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS1.p2.2.m2.1c">M</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS1.p2.2.m2.1d">italic_M</annotation></semantics></math> text fragments constituting the retrieval database <math alttext="C={c_{1},c_{2},...,c_{M}}" class="ltx_Math" display="inline" id="S2.SS2.SSS1.p2.3.m3.4"><semantics id="S2.SS2.SSS1.p2.3.m3.4a"><mrow id="S2.SS2.SSS1.p2.3.m3.4.4" xref="S2.SS2.SSS1.p2.3.m3.4.4.cmml"><mi id="S2.SS2.SSS1.p2.3.m3.4.4.5" xref="S2.SS2.SSS1.p2.3.m3.4.4.5.cmml">C</mi><mo id="S2.SS2.SSS1.p2.3.m3.4.4.4" xref="S2.SS2.SSS1.p2.3.m3.4.4.4.cmml">=</mo><mrow id="S2.SS2.SSS1.p2.3.m3.4.4.3.3" xref="S2.SS2.SSS1.p2.3.m3.4.4.3.4.cmml"><msub id="S2.SS2.SSS1.p2.3.m3.2.2.1.1.1" xref="S2.SS2.SSS1.p2.3.m3.2.2.1.1.1.cmml"><mi id="S2.SS2.SSS1.p2.3.m3.2.2.1.1.1.2" xref="S2.SS2.SSS1.p2.3.m3.2.2.1.1.1.2.cmml">c</mi><mn id="S2.SS2.SSS1.p2.3.m3.2.2.1.1.1.3" xref="S2.SS2.SSS1.p2.3.m3.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S2.SS2.SSS1.p2.3.m3.4.4.3.3.4" xref="S2.SS2.SSS1.p2.3.m3.4.4.3.4.cmml">,</mo><msub id="S2.SS2.SSS1.p2.3.m3.3.3.2.2.2" xref="S2.SS2.SSS1.p2.3.m3.3.3.2.2.2.cmml"><mi id="S2.SS2.SSS1.p2.3.m3.3.3.2.2.2.2" xref="S2.SS2.SSS1.p2.3.m3.3.3.2.2.2.2.cmml">c</mi><mn id="S2.SS2.SSS1.p2.3.m3.3.3.2.2.2.3" xref="S2.SS2.SSS1.p2.3.m3.3.3.2.2.2.3.cmml">2</mn></msub><mo id="S2.SS2.SSS1.p2.3.m3.4.4.3.3.5" xref="S2.SS2.SSS1.p2.3.m3.4.4.3.4.cmml">,</mo><mi id="S2.SS2.SSS1.p2.3.m3.1.1" mathvariant="normal" xref="S2.SS2.SSS1.p2.3.m3.1.1.cmml">…</mi><mo id="S2.SS2.SSS1.p2.3.m3.4.4.3.3.6" xref="S2.SS2.SSS1.p2.3.m3.4.4.3.4.cmml">,</mo><msub id="S2.SS2.SSS1.p2.3.m3.4.4.3.3.3" xref="S2.SS2.SSS1.p2.3.m3.4.4.3.3.3.cmml"><mi id="S2.SS2.SSS1.p2.3.m3.4.4.3.3.3.2" xref="S2.SS2.SSS1.p2.3.m3.4.4.3.3.3.2.cmml">c</mi><mi id="S2.SS2.SSS1.p2.3.m3.4.4.3.3.3.3" xref="S2.SS2.SSS1.p2.3.m3.4.4.3.3.3.3.cmml">M</mi></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS1.p2.3.m3.4b"><apply id="S2.SS2.SSS1.p2.3.m3.4.4.cmml" xref="S2.SS2.SSS1.p2.3.m3.4.4"><eq id="S2.SS2.SSS1.p2.3.m3.4.4.4.cmml" xref="S2.SS2.SSS1.p2.3.m3.4.4.4"></eq><ci id="S2.SS2.SSS1.p2.3.m3.4.4.5.cmml" xref="S2.SS2.SSS1.p2.3.m3.4.4.5">𝐶</ci><list id="S2.SS2.SSS1.p2.3.m3.4.4.3.4.cmml" xref="S2.SS2.SSS1.p2.3.m3.4.4.3.3"><apply id="S2.SS2.SSS1.p2.3.m3.2.2.1.1.1.cmml" xref="S2.SS2.SSS1.p2.3.m3.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS1.p2.3.m3.2.2.1.1.1.1.cmml" xref="S2.SS2.SSS1.p2.3.m3.2.2.1.1.1">subscript</csymbol><ci id="S2.SS2.SSS1.p2.3.m3.2.2.1.1.1.2.cmml" xref="S2.SS2.SSS1.p2.3.m3.2.2.1.1.1.2">𝑐</ci><cn id="S2.SS2.SSS1.p2.3.m3.2.2.1.1.1.3.cmml" type="integer" xref="S2.SS2.SSS1.p2.3.m3.2.2.1.1.1.3">1</cn></apply><apply id="S2.SS2.SSS1.p2.3.m3.3.3.2.2.2.cmml" xref="S2.SS2.SSS1.p2.3.m3.3.3.2.2.2"><csymbol cd="ambiguous" id="S2.SS2.SSS1.p2.3.m3.3.3.2.2.2.1.cmml" xref="S2.SS2.SSS1.p2.3.m3.3.3.2.2.2">subscript</csymbol><ci id="S2.SS2.SSS1.p2.3.m3.3.3.2.2.2.2.cmml" xref="S2.SS2.SSS1.p2.3.m3.3.3.2.2.2.2">𝑐</ci><cn id="S2.SS2.SSS1.p2.3.m3.3.3.2.2.2.3.cmml" type="integer" xref="S2.SS2.SSS1.p2.3.m3.3.3.2.2.2.3">2</cn></apply><ci id="S2.SS2.SSS1.p2.3.m3.1.1.cmml" xref="S2.SS2.SSS1.p2.3.m3.1.1">…</ci><apply id="S2.SS2.SSS1.p2.3.m3.4.4.3.3.3.cmml" xref="S2.SS2.SSS1.p2.3.m3.4.4.3.3.3"><csymbol cd="ambiguous" id="S2.SS2.SSS1.p2.3.m3.4.4.3.3.3.1.cmml" xref="S2.SS2.SSS1.p2.3.m3.4.4.3.3.3">subscript</csymbol><ci id="S2.SS2.SSS1.p2.3.m3.4.4.3.3.3.2.cmml" xref="S2.SS2.SSS1.p2.3.m3.4.4.3.3.3.2">𝑐</ci><ci id="S2.SS2.SSS1.p2.3.m3.4.4.3.3.3.3.cmml" xref="S2.SS2.SSS1.p2.3.m3.4.4.3.3.3.3">𝑀</ci></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS1.p2.3.m3.4c">C={c_{1},c_{2},...,c_{M}}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS1.p2.3.m3.4d">italic_C = italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_c start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , italic_c start_POSTSUBSCRIPT italic_M end_POSTSUBSCRIPT</annotation></semantics></math>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS2.SSS1.p3">
<p class="ltx_p" id="S2.SS2.SSS1.p3.7">Given a set of query keywords <math alttext="X={x_{1},x_{2},...,x_{k}}" class="ltx_Math" display="inline" id="S2.SS2.SSS1.p3.1.m1.4"><semantics id="S2.SS2.SSS1.p3.1.m1.4a"><mrow id="S2.SS2.SSS1.p3.1.m1.4.4" xref="S2.SS2.SSS1.p3.1.m1.4.4.cmml"><mi id="S2.SS2.SSS1.p3.1.m1.4.4.5" xref="S2.SS2.SSS1.p3.1.m1.4.4.5.cmml">X</mi><mo id="S2.SS2.SSS1.p3.1.m1.4.4.4" xref="S2.SS2.SSS1.p3.1.m1.4.4.4.cmml">=</mo><mrow id="S2.SS2.SSS1.p3.1.m1.4.4.3.3" xref="S2.SS2.SSS1.p3.1.m1.4.4.3.4.cmml"><msub id="S2.SS2.SSS1.p3.1.m1.2.2.1.1.1" xref="S2.SS2.SSS1.p3.1.m1.2.2.1.1.1.cmml"><mi id="S2.SS2.SSS1.p3.1.m1.2.2.1.1.1.2" xref="S2.SS2.SSS1.p3.1.m1.2.2.1.1.1.2.cmml">x</mi><mn id="S2.SS2.SSS1.p3.1.m1.2.2.1.1.1.3" xref="S2.SS2.SSS1.p3.1.m1.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S2.SS2.SSS1.p3.1.m1.4.4.3.3.4" xref="S2.SS2.SSS1.p3.1.m1.4.4.3.4.cmml">,</mo><msub id="S2.SS2.SSS1.p3.1.m1.3.3.2.2.2" xref="S2.SS2.SSS1.p3.1.m1.3.3.2.2.2.cmml"><mi id="S2.SS2.SSS1.p3.1.m1.3.3.2.2.2.2" xref="S2.SS2.SSS1.p3.1.m1.3.3.2.2.2.2.cmml">x</mi><mn id="S2.SS2.SSS1.p3.1.m1.3.3.2.2.2.3" xref="S2.SS2.SSS1.p3.1.m1.3.3.2.2.2.3.cmml">2</mn></msub><mo id="S2.SS2.SSS1.p3.1.m1.4.4.3.3.5" xref="S2.SS2.SSS1.p3.1.m1.4.4.3.4.cmml">,</mo><mi id="S2.SS2.SSS1.p3.1.m1.1.1" mathvariant="normal" xref="S2.SS2.SSS1.p3.1.m1.1.1.cmml">…</mi><mo id="S2.SS2.SSS1.p3.1.m1.4.4.3.3.6" xref="S2.SS2.SSS1.p3.1.m1.4.4.3.4.cmml">,</mo><msub id="S2.SS2.SSS1.p3.1.m1.4.4.3.3.3" xref="S2.SS2.SSS1.p3.1.m1.4.4.3.3.3.cmml"><mi id="S2.SS2.SSS1.p3.1.m1.4.4.3.3.3.2" xref="S2.SS2.SSS1.p3.1.m1.4.4.3.3.3.2.cmml">x</mi><mi id="S2.SS2.SSS1.p3.1.m1.4.4.3.3.3.3" xref="S2.SS2.SSS1.p3.1.m1.4.4.3.3.3.3.cmml">k</mi></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS1.p3.1.m1.4b"><apply id="S2.SS2.SSS1.p3.1.m1.4.4.cmml" xref="S2.SS2.SSS1.p3.1.m1.4.4"><eq id="S2.SS2.SSS1.p3.1.m1.4.4.4.cmml" xref="S2.SS2.SSS1.p3.1.m1.4.4.4"></eq><ci id="S2.SS2.SSS1.p3.1.m1.4.4.5.cmml" xref="S2.SS2.SSS1.p3.1.m1.4.4.5">𝑋</ci><list id="S2.SS2.SSS1.p3.1.m1.4.4.3.4.cmml" xref="S2.SS2.SSS1.p3.1.m1.4.4.3.3"><apply id="S2.SS2.SSS1.p3.1.m1.2.2.1.1.1.cmml" xref="S2.SS2.SSS1.p3.1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS1.p3.1.m1.2.2.1.1.1.1.cmml" xref="S2.SS2.SSS1.p3.1.m1.2.2.1.1.1">subscript</csymbol><ci id="S2.SS2.SSS1.p3.1.m1.2.2.1.1.1.2.cmml" xref="S2.SS2.SSS1.p3.1.m1.2.2.1.1.1.2">𝑥</ci><cn id="S2.SS2.SSS1.p3.1.m1.2.2.1.1.1.3.cmml" type="integer" xref="S2.SS2.SSS1.p3.1.m1.2.2.1.1.1.3">1</cn></apply><apply id="S2.SS2.SSS1.p3.1.m1.3.3.2.2.2.cmml" xref="S2.SS2.SSS1.p3.1.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="S2.SS2.SSS1.p3.1.m1.3.3.2.2.2.1.cmml" xref="S2.SS2.SSS1.p3.1.m1.3.3.2.2.2">subscript</csymbol><ci id="S2.SS2.SSS1.p3.1.m1.3.3.2.2.2.2.cmml" xref="S2.SS2.SSS1.p3.1.m1.3.3.2.2.2.2">𝑥</ci><cn id="S2.SS2.SSS1.p3.1.m1.3.3.2.2.2.3.cmml" type="integer" xref="S2.SS2.SSS1.p3.1.m1.3.3.2.2.2.3">2</cn></apply><ci id="S2.SS2.SSS1.p3.1.m1.1.1.cmml" xref="S2.SS2.SSS1.p3.1.m1.1.1">…</ci><apply id="S2.SS2.SSS1.p3.1.m1.4.4.3.3.3.cmml" xref="S2.SS2.SSS1.p3.1.m1.4.4.3.3.3"><csymbol cd="ambiguous" id="S2.SS2.SSS1.p3.1.m1.4.4.3.3.3.1.cmml" xref="S2.SS2.SSS1.p3.1.m1.4.4.3.3.3">subscript</csymbol><ci id="S2.SS2.SSS1.p3.1.m1.4.4.3.3.3.2.cmml" xref="S2.SS2.SSS1.p3.1.m1.4.4.3.3.3.2">𝑥</ci><ci id="S2.SS2.SSS1.p3.1.m1.4.4.3.3.3.3.cmml" xref="S2.SS2.SSS1.p3.1.m1.4.4.3.3.3.3">𝑘</ci></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS1.p3.1.m1.4c">X={x_{1},x_{2},...,x_{k}}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS1.p3.1.m1.4d">italic_X = italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , italic_x start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT</annotation></semantics></math>, a search mechanism <math alttext="\textbf{R}:(X,C)\rightarrow C" class="ltx_Math" display="inline" id="S2.SS2.SSS1.p3.2.m2.2"><semantics id="S2.SS2.SSS1.p3.2.m2.2a"><mrow id="S2.SS2.SSS1.p3.2.m2.2.3" xref="S2.SS2.SSS1.p3.2.m2.2.3.cmml"><mtext id="S2.SS2.SSS1.p3.2.m2.2.3.2" xref="S2.SS2.SSS1.p3.2.m2.2.3.2a.cmml">𝐑</mtext><mo id="S2.SS2.SSS1.p3.2.m2.2.3.1" lspace="0.278em" rspace="0.278em" xref="S2.SS2.SSS1.p3.2.m2.2.3.1.cmml">:</mo><mrow id="S2.SS2.SSS1.p3.2.m2.2.3.3" xref="S2.SS2.SSS1.p3.2.m2.2.3.3.cmml"><mrow id="S2.SS2.SSS1.p3.2.m2.2.3.3.2.2" xref="S2.SS2.SSS1.p3.2.m2.2.3.3.2.1.cmml"><mo id="S2.SS2.SSS1.p3.2.m2.2.3.3.2.2.1" stretchy="false" xref="S2.SS2.SSS1.p3.2.m2.2.3.3.2.1.cmml">(</mo><mi id="S2.SS2.SSS1.p3.2.m2.1.1" xref="S2.SS2.SSS1.p3.2.m2.1.1.cmml">X</mi><mo id="S2.SS2.SSS1.p3.2.m2.2.3.3.2.2.2" xref="S2.SS2.SSS1.p3.2.m2.2.3.3.2.1.cmml">,</mo><mi id="S2.SS2.SSS1.p3.2.m2.2.2" xref="S2.SS2.SSS1.p3.2.m2.2.2.cmml">C</mi><mo id="S2.SS2.SSS1.p3.2.m2.2.3.3.2.2.3" stretchy="false" xref="S2.SS2.SSS1.p3.2.m2.2.3.3.2.1.cmml">)</mo></mrow><mo id="S2.SS2.SSS1.p3.2.m2.2.3.3.1" stretchy="false" xref="S2.SS2.SSS1.p3.2.m2.2.3.3.1.cmml">→</mo><mi id="S2.SS2.SSS1.p3.2.m2.2.3.3.3" xref="S2.SS2.SSS1.p3.2.m2.2.3.3.3.cmml">C</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS1.p3.2.m2.2b"><apply id="S2.SS2.SSS1.p3.2.m2.2.3.cmml" xref="S2.SS2.SSS1.p3.2.m2.2.3"><ci id="S2.SS2.SSS1.p3.2.m2.2.3.1.cmml" xref="S2.SS2.SSS1.p3.2.m2.2.3.1">:</ci><ci id="S2.SS2.SSS1.p3.2.m2.2.3.2a.cmml" xref="S2.SS2.SSS1.p3.2.m2.2.3.2"><mtext id="S2.SS2.SSS1.p3.2.m2.2.3.2.cmml" xref="S2.SS2.SSS1.p3.2.m2.2.3.2">𝐑</mtext></ci><apply id="S2.SS2.SSS1.p3.2.m2.2.3.3.cmml" xref="S2.SS2.SSS1.p3.2.m2.2.3.3"><ci id="S2.SS2.SSS1.p3.2.m2.2.3.3.1.cmml" xref="S2.SS2.SSS1.p3.2.m2.2.3.3.1">→</ci><interval closure="open" id="S2.SS2.SSS1.p3.2.m2.2.3.3.2.1.cmml" xref="S2.SS2.SSS1.p3.2.m2.2.3.3.2.2"><ci id="S2.SS2.SSS1.p3.2.m2.1.1.cmml" xref="S2.SS2.SSS1.p3.2.m2.1.1">𝑋</ci><ci id="S2.SS2.SSS1.p3.2.m2.2.2.cmml" xref="S2.SS2.SSS1.p3.2.m2.2.2">𝐶</ci></interval><ci id="S2.SS2.SSS1.p3.2.m2.2.3.3.3.cmml" xref="S2.SS2.SSS1.p3.2.m2.2.3.3.3">𝐶</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS1.p3.2.m2.2c">\textbf{R}:(X,C)\rightarrow C</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS1.p3.2.m2.2d">R : ( italic_X , italic_C ) → italic_C</annotation></semantics></math> is employed to locate the most akin text fragment <math alttext="c_{s}" class="ltx_Math" display="inline" id="S2.SS2.SSS1.p3.3.m3.1"><semantics id="S2.SS2.SSS1.p3.3.m3.1a"><msub id="S2.SS2.SSS1.p3.3.m3.1.1" xref="S2.SS2.SSS1.p3.3.m3.1.1.cmml"><mi id="S2.SS2.SSS1.p3.3.m3.1.1.2" xref="S2.SS2.SSS1.p3.3.m3.1.1.2.cmml">c</mi><mi id="S2.SS2.SSS1.p3.3.m3.1.1.3" xref="S2.SS2.SSS1.p3.3.m3.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS1.p3.3.m3.1b"><apply id="S2.SS2.SSS1.p3.3.m3.1.1.cmml" xref="S2.SS2.SSS1.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS1.p3.3.m3.1.1.1.cmml" xref="S2.SS2.SSS1.p3.3.m3.1.1">subscript</csymbol><ci id="S2.SS2.SSS1.p3.3.m3.1.1.2.cmml" xref="S2.SS2.SSS1.p3.3.m3.1.1.2">𝑐</ci><ci id="S2.SS2.SSS1.p3.3.m3.1.1.3.cmml" xref="S2.SS2.SSS1.p3.3.m3.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS1.p3.3.m3.1c">c_{s}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS1.p3.3.m3.1d">italic_c start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT</annotation></semantics></math> within <math alttext="C" class="ltx_Math" display="inline" id="S2.SS2.SSS1.p3.4.m4.1"><semantics id="S2.SS2.SSS1.p3.4.m4.1a"><mi id="S2.SS2.SSS1.p3.4.m4.1.1" xref="S2.SS2.SSS1.p3.4.m4.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS1.p3.4.m4.1b"><ci id="S2.SS2.SSS1.p3.4.m4.1.1.cmml" xref="S2.SS2.SSS1.p3.4.m4.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS1.p3.4.m4.1c">C</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS1.p3.4.m4.1d">italic_C</annotation></semantics></math>. Subsequently, a generator <span class="ltx_text ltx_markedasmath ltx_font_bold" id="S2.SS2.SSS1.p3.7.1">G</span> is tasked with predicting the ensuing text tokens <math alttext="Y={x_{k+1},...,x_{k+n}}" class="ltx_Math" display="inline" id="S2.SS2.SSS1.p3.6.m6.3"><semantics id="S2.SS2.SSS1.p3.6.m6.3a"><mrow id="S2.SS2.SSS1.p3.6.m6.3.3" xref="S2.SS2.SSS1.p3.6.m6.3.3.cmml"><mi id="S2.SS2.SSS1.p3.6.m6.3.3.4" xref="S2.SS2.SSS1.p3.6.m6.3.3.4.cmml">Y</mi><mo id="S2.SS2.SSS1.p3.6.m6.3.3.3" xref="S2.SS2.SSS1.p3.6.m6.3.3.3.cmml">=</mo><mrow id="S2.SS2.SSS1.p3.6.m6.3.3.2.2" xref="S2.SS2.SSS1.p3.6.m6.3.3.2.3.cmml"><msub id="S2.SS2.SSS1.p3.6.m6.2.2.1.1.1" xref="S2.SS2.SSS1.p3.6.m6.2.2.1.1.1.cmml"><mi id="S2.SS2.SSS1.p3.6.m6.2.2.1.1.1.2" xref="S2.SS2.SSS1.p3.6.m6.2.2.1.1.1.2.cmml">x</mi><mrow id="S2.SS2.SSS1.p3.6.m6.2.2.1.1.1.3" xref="S2.SS2.SSS1.p3.6.m6.2.2.1.1.1.3.cmml"><mi id="S2.SS2.SSS1.p3.6.m6.2.2.1.1.1.3.2" xref="S2.SS2.SSS1.p3.6.m6.2.2.1.1.1.3.2.cmml">k</mi><mo id="S2.SS2.SSS1.p3.6.m6.2.2.1.1.1.3.1" xref="S2.SS2.SSS1.p3.6.m6.2.2.1.1.1.3.1.cmml">+</mo><mn id="S2.SS2.SSS1.p3.6.m6.2.2.1.1.1.3.3" xref="S2.SS2.SSS1.p3.6.m6.2.2.1.1.1.3.3.cmml">1</mn></mrow></msub><mo id="S2.SS2.SSS1.p3.6.m6.3.3.2.2.3" xref="S2.SS2.SSS1.p3.6.m6.3.3.2.3.cmml">,</mo><mi id="S2.SS2.SSS1.p3.6.m6.1.1" mathvariant="normal" xref="S2.SS2.SSS1.p3.6.m6.1.1.cmml">…</mi><mo id="S2.SS2.SSS1.p3.6.m6.3.3.2.2.4" xref="S2.SS2.SSS1.p3.6.m6.3.3.2.3.cmml">,</mo><msub id="S2.SS2.SSS1.p3.6.m6.3.3.2.2.2" xref="S2.SS2.SSS1.p3.6.m6.3.3.2.2.2.cmml"><mi id="S2.SS2.SSS1.p3.6.m6.3.3.2.2.2.2" xref="S2.SS2.SSS1.p3.6.m6.3.3.2.2.2.2.cmml">x</mi><mrow id="S2.SS2.SSS1.p3.6.m6.3.3.2.2.2.3" xref="S2.SS2.SSS1.p3.6.m6.3.3.2.2.2.3.cmml"><mi id="S2.SS2.SSS1.p3.6.m6.3.3.2.2.2.3.2" xref="S2.SS2.SSS1.p3.6.m6.3.3.2.2.2.3.2.cmml">k</mi><mo id="S2.SS2.SSS1.p3.6.m6.3.3.2.2.2.3.1" xref="S2.SS2.SSS1.p3.6.m6.3.3.2.2.2.3.1.cmml">+</mo><mi id="S2.SS2.SSS1.p3.6.m6.3.3.2.2.2.3.3" xref="S2.SS2.SSS1.p3.6.m6.3.3.2.2.2.3.3.cmml">n</mi></mrow></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS1.p3.6.m6.3b"><apply id="S2.SS2.SSS1.p3.6.m6.3.3.cmml" xref="S2.SS2.SSS1.p3.6.m6.3.3"><eq id="S2.SS2.SSS1.p3.6.m6.3.3.3.cmml" xref="S2.SS2.SSS1.p3.6.m6.3.3.3"></eq><ci id="S2.SS2.SSS1.p3.6.m6.3.3.4.cmml" xref="S2.SS2.SSS1.p3.6.m6.3.3.4">𝑌</ci><list id="S2.SS2.SSS1.p3.6.m6.3.3.2.3.cmml" xref="S2.SS2.SSS1.p3.6.m6.3.3.2.2"><apply id="S2.SS2.SSS1.p3.6.m6.2.2.1.1.1.cmml" xref="S2.SS2.SSS1.p3.6.m6.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS1.p3.6.m6.2.2.1.1.1.1.cmml" xref="S2.SS2.SSS1.p3.6.m6.2.2.1.1.1">subscript</csymbol><ci id="S2.SS2.SSS1.p3.6.m6.2.2.1.1.1.2.cmml" xref="S2.SS2.SSS1.p3.6.m6.2.2.1.1.1.2">𝑥</ci><apply id="S2.SS2.SSS1.p3.6.m6.2.2.1.1.1.3.cmml" xref="S2.SS2.SSS1.p3.6.m6.2.2.1.1.1.3"><plus id="S2.SS2.SSS1.p3.6.m6.2.2.1.1.1.3.1.cmml" xref="S2.SS2.SSS1.p3.6.m6.2.2.1.1.1.3.1"></plus><ci id="S2.SS2.SSS1.p3.6.m6.2.2.1.1.1.3.2.cmml" xref="S2.SS2.SSS1.p3.6.m6.2.2.1.1.1.3.2">𝑘</ci><cn id="S2.SS2.SSS1.p3.6.m6.2.2.1.1.1.3.3.cmml" type="integer" xref="S2.SS2.SSS1.p3.6.m6.2.2.1.1.1.3.3">1</cn></apply></apply><ci id="S2.SS2.SSS1.p3.6.m6.1.1.cmml" xref="S2.SS2.SSS1.p3.6.m6.1.1">…</ci><apply id="S2.SS2.SSS1.p3.6.m6.3.3.2.2.2.cmml" xref="S2.SS2.SSS1.p3.6.m6.3.3.2.2.2"><csymbol cd="ambiguous" id="S2.SS2.SSS1.p3.6.m6.3.3.2.2.2.1.cmml" xref="S2.SS2.SSS1.p3.6.m6.3.3.2.2.2">subscript</csymbol><ci id="S2.SS2.SSS1.p3.6.m6.3.3.2.2.2.2.cmml" xref="S2.SS2.SSS1.p3.6.m6.3.3.2.2.2.2">𝑥</ci><apply id="S2.SS2.SSS1.p3.6.m6.3.3.2.2.2.3.cmml" xref="S2.SS2.SSS1.p3.6.m6.3.3.2.2.2.3"><plus id="S2.SS2.SSS1.p3.6.m6.3.3.2.2.2.3.1.cmml" xref="S2.SS2.SSS1.p3.6.m6.3.3.2.2.2.3.1"></plus><ci id="S2.SS2.SSS1.p3.6.m6.3.3.2.2.2.3.2.cmml" xref="S2.SS2.SSS1.p3.6.m6.3.3.2.2.2.3.2">𝑘</ci><ci id="S2.SS2.SSS1.p3.6.m6.3.3.2.2.2.3.3.cmml" xref="S2.SS2.SSS1.p3.6.m6.3.3.2.2.2.3.3">𝑛</ci></apply></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS1.p3.6.m6.3c">Y={x_{k+1},...,x_{k+n}}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS1.p3.6.m6.3d">italic_Y = italic_x start_POSTSUBSCRIPT italic_k + 1 end_POSTSUBSCRIPT , … , italic_x start_POSTSUBSCRIPT italic_k + italic_n end_POSTSUBSCRIPT</annotation></semantics></math>, where <math alttext="n=1" class="ltx_Math" display="inline" id="S2.SS2.SSS1.p3.7.m7.1"><semantics id="S2.SS2.SSS1.p3.7.m7.1a"><mrow id="S2.SS2.SSS1.p3.7.m7.1.1" xref="S2.SS2.SSS1.p3.7.m7.1.1.cmml"><mi id="S2.SS2.SSS1.p3.7.m7.1.1.2" xref="S2.SS2.SSS1.p3.7.m7.1.1.2.cmml">n</mi><mo id="S2.SS2.SSS1.p3.7.m7.1.1.1" xref="S2.SS2.SSS1.p3.7.m7.1.1.1.cmml">=</mo><mn id="S2.SS2.SSS1.p3.7.m7.1.1.3" xref="S2.SS2.SSS1.p3.7.m7.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS1.p3.7.m7.1b"><apply id="S2.SS2.SSS1.p3.7.m7.1.1.cmml" xref="S2.SS2.SSS1.p3.7.m7.1.1"><eq id="S2.SS2.SSS1.p3.7.m7.1.1.1.cmml" xref="S2.SS2.SSS1.p3.7.m7.1.1.1"></eq><ci id="S2.SS2.SSS1.p3.7.m7.1.1.2.cmml" xref="S2.SS2.SSS1.p3.7.m7.1.1.2">𝑛</ci><cn id="S2.SS2.SSS1.p3.7.m7.1.1.3.cmml" type="integer" xref="S2.SS2.SSS1.p3.7.m7.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS1.p3.7.m7.1c">n=1</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS1.p3.7.m7.1d">italic_n = 1</annotation></semantics></math> denotes the granularity of token-level text prediction, guided by both the context and the retrieved text.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS2.SSS1.p4">
<p class="ltx_p" id="S2.SS2.SSS1.p4.1">This process is formally encapsulated as <math alttext="P(Y)=\prod_{i=1}^{n}P(x_{k+i}|c_{s},x_{1:k+i-1})" class="ltx_Math" display="inline" id="S2.SS2.SSS1.p4.1.m1.2"><semantics id="S2.SS2.SSS1.p4.1.m1.2a"><mrow id="S2.SS2.SSS1.p4.1.m1.2.2" xref="S2.SS2.SSS1.p4.1.m1.2.2.cmml"><mrow id="S2.SS2.SSS1.p4.1.m1.2.2.3" xref="S2.SS2.SSS1.p4.1.m1.2.2.3.cmml"><mi id="S2.SS2.SSS1.p4.1.m1.2.2.3.2" xref="S2.SS2.SSS1.p4.1.m1.2.2.3.2.cmml">P</mi><mo id="S2.SS2.SSS1.p4.1.m1.2.2.3.1" xref="S2.SS2.SSS1.p4.1.m1.2.2.3.1.cmml">⁢</mo><mrow id="S2.SS2.SSS1.p4.1.m1.2.2.3.3.2" xref="S2.SS2.SSS1.p4.1.m1.2.2.3.cmml"><mo id="S2.SS2.SSS1.p4.1.m1.2.2.3.3.2.1" stretchy="false" xref="S2.SS2.SSS1.p4.1.m1.2.2.3.cmml">(</mo><mi id="S2.SS2.SSS1.p4.1.m1.1.1" xref="S2.SS2.SSS1.p4.1.m1.1.1.cmml">Y</mi><mo id="S2.SS2.SSS1.p4.1.m1.2.2.3.3.2.2" stretchy="false" xref="S2.SS2.SSS1.p4.1.m1.2.2.3.cmml">)</mo></mrow></mrow><mo id="S2.SS2.SSS1.p4.1.m1.2.2.2" rspace="0.111em" xref="S2.SS2.SSS1.p4.1.m1.2.2.2.cmml">=</mo><mrow id="S2.SS2.SSS1.p4.1.m1.2.2.1" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.cmml"><msubsup id="S2.SS2.SSS1.p4.1.m1.2.2.1.2" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.2.cmml"><mo id="S2.SS2.SSS1.p4.1.m1.2.2.1.2.2.2" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.2.2.2.cmml">∏</mo><mrow id="S2.SS2.SSS1.p4.1.m1.2.2.1.2.2.3" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.2.2.3.cmml"><mi id="S2.SS2.SSS1.p4.1.m1.2.2.1.2.2.3.2" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.2.2.3.2.cmml">i</mi><mo id="S2.SS2.SSS1.p4.1.m1.2.2.1.2.2.3.1" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.2.2.3.1.cmml">=</mo><mn id="S2.SS2.SSS1.p4.1.m1.2.2.1.2.2.3.3" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.2.2.3.3.cmml">1</mn></mrow><mi id="S2.SS2.SSS1.p4.1.m1.2.2.1.2.3" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.2.3.cmml">n</mi></msubsup><mrow id="S2.SS2.SSS1.p4.1.m1.2.2.1.1" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.1.cmml"><mi id="S2.SS2.SSS1.p4.1.m1.2.2.1.1.3" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.1.3.cmml">P</mi><mo id="S2.SS2.SSS1.p4.1.m1.2.2.1.1.2" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.1.2.cmml">⁢</mo><mrow id="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.cmml"><mo id="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.2" stretchy="false" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.cmml">(</mo><mrow id="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.cmml"><msub id="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.4" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.4.cmml"><mi id="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.4.2" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.4.2.cmml">x</mi><mrow id="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.4.3" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.4.3.cmml"><mi id="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.4.3.2" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.4.3.2.cmml">k</mi><mo id="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.4.3.1" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.4.3.1.cmml">+</mo><mi id="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.4.3.3" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.4.3.3.cmml">i</mi></mrow></msub><mo fence="false" id="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.3" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.3.cmml">|</mo><mrow id="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.2.2" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.2.3.cmml"><msub id="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.1.1.1" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.1.1.1.cmml"><mi id="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.1.1.1.2" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.1.1.1.2.cmml">c</mi><mi id="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.1.1.1.3" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.1.1.1.3.cmml">s</mi></msub><mo id="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.2.2.3" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.2.3.cmml">,</mo><msub id="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.2.2.2" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.2.2.2.cmml"><mi id="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.2.2.2.2" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.2.2.2.2.cmml">x</mi><mrow id="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.2.2.2.3" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.2.2.2.3.cmml"><mn id="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.2.2.2.3.2" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.2.2.2.3.2.cmml">1</mn><mo id="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.2.2.2.3.1" lspace="0.278em" rspace="0.278em" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.2.2.2.3.1.cmml">:</mo><mrow id="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.2.2.2.3.3" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.2.2.2.3.3.cmml"><mrow id="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.2.2.2.3.3.2" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.2.2.2.3.3.2.cmml"><mi id="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.2.2.2.3.3.2.2" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.2.2.2.3.3.2.2.cmml">k</mi><mo id="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.2.2.2.3.3.2.1" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.2.2.2.3.3.2.1.cmml">+</mo><mi id="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.2.2.2.3.3.2.3" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.2.2.2.3.3.2.3.cmml">i</mi></mrow><mo id="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.2.2.2.3.3.1" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.2.2.2.3.3.1.cmml">−</mo><mn id="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.2.2.2.3.3.3" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.2.2.2.3.3.3.cmml">1</mn></mrow></mrow></msub></mrow></mrow><mo id="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.3" stretchy="false" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS1.p4.1.m1.2b"><apply id="S2.SS2.SSS1.p4.1.m1.2.2.cmml" xref="S2.SS2.SSS1.p4.1.m1.2.2"><eq id="S2.SS2.SSS1.p4.1.m1.2.2.2.cmml" xref="S2.SS2.SSS1.p4.1.m1.2.2.2"></eq><apply id="S2.SS2.SSS1.p4.1.m1.2.2.3.cmml" xref="S2.SS2.SSS1.p4.1.m1.2.2.3"><times id="S2.SS2.SSS1.p4.1.m1.2.2.3.1.cmml" xref="S2.SS2.SSS1.p4.1.m1.2.2.3.1"></times><ci id="S2.SS2.SSS1.p4.1.m1.2.2.3.2.cmml" xref="S2.SS2.SSS1.p4.1.m1.2.2.3.2">𝑃</ci><ci id="S2.SS2.SSS1.p4.1.m1.1.1.cmml" xref="S2.SS2.SSS1.p4.1.m1.1.1">𝑌</ci></apply><apply id="S2.SS2.SSS1.p4.1.m1.2.2.1.cmml" xref="S2.SS2.SSS1.p4.1.m1.2.2.1"><apply id="S2.SS2.SSS1.p4.1.m1.2.2.1.2.cmml" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.2"><csymbol cd="ambiguous" id="S2.SS2.SSS1.p4.1.m1.2.2.1.2.1.cmml" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.2">superscript</csymbol><apply id="S2.SS2.SSS1.p4.1.m1.2.2.1.2.2.cmml" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.2"><csymbol cd="ambiguous" id="S2.SS2.SSS1.p4.1.m1.2.2.1.2.2.1.cmml" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.2">subscript</csymbol><csymbol cd="latexml" id="S2.SS2.SSS1.p4.1.m1.2.2.1.2.2.2.cmml" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.2.2.2">product</csymbol><apply id="S2.SS2.SSS1.p4.1.m1.2.2.1.2.2.3.cmml" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.2.2.3"><eq id="S2.SS2.SSS1.p4.1.m1.2.2.1.2.2.3.1.cmml" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.2.2.3.1"></eq><ci id="S2.SS2.SSS1.p4.1.m1.2.2.1.2.2.3.2.cmml" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.2.2.3.2">𝑖</ci><cn id="S2.SS2.SSS1.p4.1.m1.2.2.1.2.2.3.3.cmml" type="integer" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.2.2.3.3">1</cn></apply></apply><ci id="S2.SS2.SSS1.p4.1.m1.2.2.1.2.3.cmml" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.2.3">𝑛</ci></apply><apply id="S2.SS2.SSS1.p4.1.m1.2.2.1.1.cmml" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.1"><times id="S2.SS2.SSS1.p4.1.m1.2.2.1.1.2.cmml" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.1.2"></times><ci id="S2.SS2.SSS1.p4.1.m1.2.2.1.1.3.cmml" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.1.3">𝑃</ci><apply id="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.cmml" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1"><csymbol cd="latexml" id="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.3.cmml" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.3">conditional</csymbol><apply id="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.4.cmml" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.4"><csymbol cd="ambiguous" id="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.4.1.cmml" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.4">subscript</csymbol><ci id="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.4.2.cmml" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.4.2">𝑥</ci><apply id="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.4.3.cmml" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.4.3"><plus id="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.4.3.1.cmml" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.4.3.1"></plus><ci id="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.4.3.2.cmml" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.4.3.2">𝑘</ci><ci id="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.4.3.3.cmml" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.4.3.3">𝑖</ci></apply></apply><list id="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.2.3.cmml" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.2.2"><apply id="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.1.1.1.cmml" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.1.1.1.1.cmml" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.1.1.1.2.cmml" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.1.1.1.2">𝑐</ci><ci id="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.1.1.1.3.cmml" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.1.1.1.3">𝑠</ci></apply><apply id="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.2.2.2.cmml" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.2.2.2.1.cmml" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.2.2.2">subscript</csymbol><ci id="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.2.2.2.2.cmml" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.2.2.2.2">𝑥</ci><apply id="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.2.2.2.3.cmml" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.2.2.2.3"><ci id="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.2.2.2.3.1.cmml" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.2.2.2.3.1">:</ci><cn id="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.2.2.2.3.2.cmml" type="integer" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.2.2.2.3.2">1</cn><apply id="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.2.2.2.3.3.cmml" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.2.2.2.3.3"><minus id="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.2.2.2.3.3.1.cmml" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.2.2.2.3.3.1"></minus><apply id="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.2.2.2.3.3.2.cmml" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.2.2.2.3.3.2"><plus id="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.2.2.2.3.3.2.1.cmml" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.2.2.2.3.3.2.1"></plus><ci id="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.2.2.2.3.3.2.2.cmml" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.2.2.2.3.3.2.2">𝑘</ci><ci id="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.2.2.2.3.3.2.3.cmml" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.2.2.2.3.3.2.3">𝑖</ci></apply><cn id="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.2.2.2.3.3.3.cmml" type="integer" xref="S2.SS2.SSS1.p4.1.m1.2.2.1.1.1.1.1.2.2.2.3.3.3">1</cn></apply></apply></apply></list></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS1.p4.1.m1.2c">P(Y)=\prod_{i=1}^{n}P(x_{k+i}|c_{s},x_{1:k+i-1})</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS1.p4.1.m1.2d">italic_P ( italic_Y ) = ∏ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT italic_P ( italic_x start_POSTSUBSCRIPT italic_k + italic_i end_POSTSUBSCRIPT | italic_c start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT 1 : italic_k + italic_i - 1 end_POSTSUBSCRIPT )</annotation></semantics></math>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS2.SSS1.p5">
<p class="ltx_p" id="S2.SS2.SSS1.p5.5">For the search functionality, we employ the BM25 algorithm <cite class="ltx_cite ltx_citemacro_cite">Robertson et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib29" title="">2009</a>)</cite>, akin to its utilization within ElasticSearch frameworks. BM25 operates as a term-based search methodology, employing a bag-of-words model to ascertain lexical similarity between the query and document fragments. The DPR framework <cite class="ltx_cite ltx_citemacro_cite">Karpukhin et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib28" title="">2020</a>)</cite> is constituted by two bidirectional transformers, <math alttext="E_{C}" class="ltx_Math" display="inline" id="S2.SS2.SSS1.p5.1.m1.1"><semantics id="S2.SS2.SSS1.p5.1.m1.1a"><msub id="S2.SS2.SSS1.p5.1.m1.1.1" xref="S2.SS2.SSS1.p5.1.m1.1.1.cmml"><mi id="S2.SS2.SSS1.p5.1.m1.1.1.2" xref="S2.SS2.SSS1.p5.1.m1.1.1.2.cmml">E</mi><mi id="S2.SS2.SSS1.p5.1.m1.1.1.3" xref="S2.SS2.SSS1.p5.1.m1.1.1.3.cmml">C</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS1.p5.1.m1.1b"><apply id="S2.SS2.SSS1.p5.1.m1.1.1.cmml" xref="S2.SS2.SSS1.p5.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS1.p5.1.m1.1.1.1.cmml" xref="S2.SS2.SSS1.p5.1.m1.1.1">subscript</csymbol><ci id="S2.SS2.SSS1.p5.1.m1.1.1.2.cmml" xref="S2.SS2.SSS1.p5.1.m1.1.1.2">𝐸</ci><ci id="S2.SS2.SSS1.p5.1.m1.1.1.3.cmml" xref="S2.SS2.SSS1.p5.1.m1.1.1.3">𝐶</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS1.p5.1.m1.1c">E_{C}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS1.p5.1.m1.1d">italic_E start_POSTSUBSCRIPT italic_C end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="E_{Q}" class="ltx_Math" display="inline" id="S2.SS2.SSS1.p5.2.m2.1"><semantics id="S2.SS2.SSS1.p5.2.m2.1a"><msub id="S2.SS2.SSS1.p5.2.m2.1.1" xref="S2.SS2.SSS1.p5.2.m2.1.1.cmml"><mi id="S2.SS2.SSS1.p5.2.m2.1.1.2" xref="S2.SS2.SSS1.p5.2.m2.1.1.2.cmml">E</mi><mi id="S2.SS2.SSS1.p5.2.m2.1.1.3" xref="S2.SS2.SSS1.p5.2.m2.1.1.3.cmml">Q</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS1.p5.2.m2.1b"><apply id="S2.SS2.SSS1.p5.2.m2.1.1.cmml" xref="S2.SS2.SSS1.p5.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS1.p5.2.m2.1.1.1.cmml" xref="S2.SS2.SSS1.p5.2.m2.1.1">subscript</csymbol><ci id="S2.SS2.SSS1.p5.2.m2.1.1.2.cmml" xref="S2.SS2.SSS1.p5.2.m2.1.1.2">𝐸</ci><ci id="S2.SS2.SSS1.p5.2.m2.1.1.3.cmml" xref="S2.SS2.SSS1.p5.2.m2.1.1.3">𝑄</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS1.p5.2.m2.1c">E_{Q}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS1.p5.2.m2.1d">italic_E start_POSTSUBSCRIPT italic_Q end_POSTSUBSCRIPT</annotation></semantics></math>, where <math alttext="E_{C}" class="ltx_Math" display="inline" id="S2.SS2.SSS1.p5.3.m3.1"><semantics id="S2.SS2.SSS1.p5.3.m3.1a"><msub id="S2.SS2.SSS1.p5.3.m3.1.1" xref="S2.SS2.SSS1.p5.3.m3.1.1.cmml"><mi id="S2.SS2.SSS1.p5.3.m3.1.1.2" xref="S2.SS2.SSS1.p5.3.m3.1.1.2.cmml">E</mi><mi id="S2.SS2.SSS1.p5.3.m3.1.1.3" xref="S2.SS2.SSS1.p5.3.m3.1.1.3.cmml">C</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS1.p5.3.m3.1b"><apply id="S2.SS2.SSS1.p5.3.m3.1.1.cmml" xref="S2.SS2.SSS1.p5.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS1.p5.3.m3.1.1.1.cmml" xref="S2.SS2.SSS1.p5.3.m3.1.1">subscript</csymbol><ci id="S2.SS2.SSS1.p5.3.m3.1.1.2.cmml" xref="S2.SS2.SSS1.p5.3.m3.1.1.2">𝐸</ci><ci id="S2.SS2.SSS1.p5.3.m3.1.1.3.cmml" xref="S2.SS2.SSS1.p5.3.m3.1.1.3">𝐶</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS1.p5.3.m3.1c">E_{C}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS1.p5.3.m3.1d">italic_E start_POSTSUBSCRIPT italic_C end_POSTSUBSCRIPT</annotation></semantics></math> is responsible for encoding and indexing each segmented text within the database <math alttext="C" class="ltx_Math" display="inline" id="S2.SS2.SSS1.p5.4.m4.1"><semantics id="S2.SS2.SSS1.p5.4.m4.1a"><mi id="S2.SS2.SSS1.p5.4.m4.1.1" xref="S2.SS2.SSS1.p5.4.m4.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS1.p5.4.m4.1b"><ci id="S2.SS2.SSS1.p5.4.m4.1.1.cmml" xref="S2.SS2.SSS1.p5.4.m4.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS1.p5.4.m4.1c">C</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS1.p5.4.m4.1d">italic_C</annotation></semantics></math>. The encoded representation of the <span class="ltx_text ltx_font_typewriter" id="S2.SS2.SSS1.p5.5.1">[CLS]</span> token is extracted as the output, facilitating the computation of similarity as <math alttext="sim(q,c)=E_{C}(c)^{T}E_{Q}(q)" class="ltx_Math" display="inline" id="S2.SS2.SSS1.p5.5.m5.4"><semantics id="S2.SS2.SSS1.p5.5.m5.4a"><mrow id="S2.SS2.SSS1.p5.5.m5.4.5" xref="S2.SS2.SSS1.p5.5.m5.4.5.cmml"><mrow id="S2.SS2.SSS1.p5.5.m5.4.5.2" xref="S2.SS2.SSS1.p5.5.m5.4.5.2.cmml"><mi id="S2.SS2.SSS1.p5.5.m5.4.5.2.2" xref="S2.SS2.SSS1.p5.5.m5.4.5.2.2.cmml">s</mi><mo id="S2.SS2.SSS1.p5.5.m5.4.5.2.1" xref="S2.SS2.SSS1.p5.5.m5.4.5.2.1.cmml">⁢</mo><mi id="S2.SS2.SSS1.p5.5.m5.4.5.2.3" xref="S2.SS2.SSS1.p5.5.m5.4.5.2.3.cmml">i</mi><mo id="S2.SS2.SSS1.p5.5.m5.4.5.2.1a" xref="S2.SS2.SSS1.p5.5.m5.4.5.2.1.cmml">⁢</mo><mi id="S2.SS2.SSS1.p5.5.m5.4.5.2.4" xref="S2.SS2.SSS1.p5.5.m5.4.5.2.4.cmml">m</mi><mo id="S2.SS2.SSS1.p5.5.m5.4.5.2.1b" xref="S2.SS2.SSS1.p5.5.m5.4.5.2.1.cmml">⁢</mo><mrow id="S2.SS2.SSS1.p5.5.m5.4.5.2.5.2" xref="S2.SS2.SSS1.p5.5.m5.4.5.2.5.1.cmml"><mo id="S2.SS2.SSS1.p5.5.m5.4.5.2.5.2.1" stretchy="false" xref="S2.SS2.SSS1.p5.5.m5.4.5.2.5.1.cmml">(</mo><mi id="S2.SS2.SSS1.p5.5.m5.1.1" xref="S2.SS2.SSS1.p5.5.m5.1.1.cmml">q</mi><mo id="S2.SS2.SSS1.p5.5.m5.4.5.2.5.2.2" xref="S2.SS2.SSS1.p5.5.m5.4.5.2.5.1.cmml">,</mo><mi id="S2.SS2.SSS1.p5.5.m5.2.2" xref="S2.SS2.SSS1.p5.5.m5.2.2.cmml">c</mi><mo id="S2.SS2.SSS1.p5.5.m5.4.5.2.5.2.3" stretchy="false" xref="S2.SS2.SSS1.p5.5.m5.4.5.2.5.1.cmml">)</mo></mrow></mrow><mo id="S2.SS2.SSS1.p5.5.m5.4.5.1" xref="S2.SS2.SSS1.p5.5.m5.4.5.1.cmml">=</mo><mrow id="S2.SS2.SSS1.p5.5.m5.4.5.3" xref="S2.SS2.SSS1.p5.5.m5.4.5.3.cmml"><msub id="S2.SS2.SSS1.p5.5.m5.4.5.3.2" xref="S2.SS2.SSS1.p5.5.m5.4.5.3.2.cmml"><mi id="S2.SS2.SSS1.p5.5.m5.4.5.3.2.2" xref="S2.SS2.SSS1.p5.5.m5.4.5.3.2.2.cmml">E</mi><mi id="S2.SS2.SSS1.p5.5.m5.4.5.3.2.3" xref="S2.SS2.SSS1.p5.5.m5.4.5.3.2.3.cmml">C</mi></msub><mo id="S2.SS2.SSS1.p5.5.m5.4.5.3.1" xref="S2.SS2.SSS1.p5.5.m5.4.5.3.1.cmml">⁢</mo><msup id="S2.SS2.SSS1.p5.5.m5.4.5.3.3" xref="S2.SS2.SSS1.p5.5.m5.4.5.3.3.cmml"><mrow id="S2.SS2.SSS1.p5.5.m5.4.5.3.3.2.2" xref="S2.SS2.SSS1.p5.5.m5.4.5.3.3.cmml"><mo id="S2.SS2.SSS1.p5.5.m5.4.5.3.3.2.2.1" stretchy="false" xref="S2.SS2.SSS1.p5.5.m5.4.5.3.3.cmml">(</mo><mi id="S2.SS2.SSS1.p5.5.m5.3.3" xref="S2.SS2.SSS1.p5.5.m5.3.3.cmml">c</mi><mo id="S2.SS2.SSS1.p5.5.m5.4.5.3.3.2.2.2" stretchy="false" xref="S2.SS2.SSS1.p5.5.m5.4.5.3.3.cmml">)</mo></mrow><mi id="S2.SS2.SSS1.p5.5.m5.4.5.3.3.3" xref="S2.SS2.SSS1.p5.5.m5.4.5.3.3.3.cmml">T</mi></msup><mo id="S2.SS2.SSS1.p5.5.m5.4.5.3.1a" xref="S2.SS2.SSS1.p5.5.m5.4.5.3.1.cmml">⁢</mo><msub id="S2.SS2.SSS1.p5.5.m5.4.5.3.4" xref="S2.SS2.SSS1.p5.5.m5.4.5.3.4.cmml"><mi id="S2.SS2.SSS1.p5.5.m5.4.5.3.4.2" xref="S2.SS2.SSS1.p5.5.m5.4.5.3.4.2.cmml">E</mi><mi id="S2.SS2.SSS1.p5.5.m5.4.5.3.4.3" xref="S2.SS2.SSS1.p5.5.m5.4.5.3.4.3.cmml">Q</mi></msub><mo id="S2.SS2.SSS1.p5.5.m5.4.5.3.1b" xref="S2.SS2.SSS1.p5.5.m5.4.5.3.1.cmml">⁢</mo><mrow id="S2.SS2.SSS1.p5.5.m5.4.5.3.5.2" xref="S2.SS2.SSS1.p5.5.m5.4.5.3.cmml"><mo id="S2.SS2.SSS1.p5.5.m5.4.5.3.5.2.1" stretchy="false" xref="S2.SS2.SSS1.p5.5.m5.4.5.3.cmml">(</mo><mi id="S2.SS2.SSS1.p5.5.m5.4.4" xref="S2.SS2.SSS1.p5.5.m5.4.4.cmml">q</mi><mo id="S2.SS2.SSS1.p5.5.m5.4.5.3.5.2.2" stretchy="false" xref="S2.SS2.SSS1.p5.5.m5.4.5.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS1.p5.5.m5.4b"><apply id="S2.SS2.SSS1.p5.5.m5.4.5.cmml" xref="S2.SS2.SSS1.p5.5.m5.4.5"><eq id="S2.SS2.SSS1.p5.5.m5.4.5.1.cmml" xref="S2.SS2.SSS1.p5.5.m5.4.5.1"></eq><apply id="S2.SS2.SSS1.p5.5.m5.4.5.2.cmml" xref="S2.SS2.SSS1.p5.5.m5.4.5.2"><times id="S2.SS2.SSS1.p5.5.m5.4.5.2.1.cmml" xref="S2.SS2.SSS1.p5.5.m5.4.5.2.1"></times><ci id="S2.SS2.SSS1.p5.5.m5.4.5.2.2.cmml" xref="S2.SS2.SSS1.p5.5.m5.4.5.2.2">𝑠</ci><ci id="S2.SS2.SSS1.p5.5.m5.4.5.2.3.cmml" xref="S2.SS2.SSS1.p5.5.m5.4.5.2.3">𝑖</ci><ci id="S2.SS2.SSS1.p5.5.m5.4.5.2.4.cmml" xref="S2.SS2.SSS1.p5.5.m5.4.5.2.4">𝑚</ci><interval closure="open" id="S2.SS2.SSS1.p5.5.m5.4.5.2.5.1.cmml" xref="S2.SS2.SSS1.p5.5.m5.4.5.2.5.2"><ci id="S2.SS2.SSS1.p5.5.m5.1.1.cmml" xref="S2.SS2.SSS1.p5.5.m5.1.1">𝑞</ci><ci id="S2.SS2.SSS1.p5.5.m5.2.2.cmml" xref="S2.SS2.SSS1.p5.5.m5.2.2">𝑐</ci></interval></apply><apply id="S2.SS2.SSS1.p5.5.m5.4.5.3.cmml" xref="S2.SS2.SSS1.p5.5.m5.4.5.3"><times id="S2.SS2.SSS1.p5.5.m5.4.5.3.1.cmml" xref="S2.SS2.SSS1.p5.5.m5.4.5.3.1"></times><apply id="S2.SS2.SSS1.p5.5.m5.4.5.3.2.cmml" xref="S2.SS2.SSS1.p5.5.m5.4.5.3.2"><csymbol cd="ambiguous" id="S2.SS2.SSS1.p5.5.m5.4.5.3.2.1.cmml" xref="S2.SS2.SSS1.p5.5.m5.4.5.3.2">subscript</csymbol><ci id="S2.SS2.SSS1.p5.5.m5.4.5.3.2.2.cmml" xref="S2.SS2.SSS1.p5.5.m5.4.5.3.2.2">𝐸</ci><ci id="S2.SS2.SSS1.p5.5.m5.4.5.3.2.3.cmml" xref="S2.SS2.SSS1.p5.5.m5.4.5.3.2.3">𝐶</ci></apply><apply id="S2.SS2.SSS1.p5.5.m5.4.5.3.3.cmml" xref="S2.SS2.SSS1.p5.5.m5.4.5.3.3"><csymbol cd="ambiguous" id="S2.SS2.SSS1.p5.5.m5.4.5.3.3.1.cmml" xref="S2.SS2.SSS1.p5.5.m5.4.5.3.3">superscript</csymbol><ci id="S2.SS2.SSS1.p5.5.m5.3.3.cmml" xref="S2.SS2.SSS1.p5.5.m5.3.3">𝑐</ci><ci id="S2.SS2.SSS1.p5.5.m5.4.5.3.3.3.cmml" xref="S2.SS2.SSS1.p5.5.m5.4.5.3.3.3">𝑇</ci></apply><apply id="S2.SS2.SSS1.p5.5.m5.4.5.3.4.cmml" xref="S2.SS2.SSS1.p5.5.m5.4.5.3.4"><csymbol cd="ambiguous" id="S2.SS2.SSS1.p5.5.m5.4.5.3.4.1.cmml" xref="S2.SS2.SSS1.p5.5.m5.4.5.3.4">subscript</csymbol><ci id="S2.SS2.SSS1.p5.5.m5.4.5.3.4.2.cmml" xref="S2.SS2.SSS1.p5.5.m5.4.5.3.4.2">𝐸</ci><ci id="S2.SS2.SSS1.p5.5.m5.4.5.3.4.3.cmml" xref="S2.SS2.SSS1.p5.5.m5.4.5.3.4.3">𝑄</ci></apply><ci id="S2.SS2.SSS1.p5.5.m5.4.4.cmml" xref="S2.SS2.SSS1.p5.5.m5.4.4">𝑞</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS1.p5.5.m5.4c">sim(q,c)=E_{C}(c)^{T}E_{Q}(q)</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS1.p5.5.m5.4d">italic_s italic_i italic_m ( italic_q , italic_c ) = italic_E start_POSTSUBSCRIPT italic_C end_POSTSUBSCRIPT ( italic_c ) start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT italic_E start_POSTSUBSCRIPT italic_Q end_POSTSUBSCRIPT ( italic_q )</annotation></semantics></math>. In the training phase, we adopt the batch negative strategy for loss computation, as illustrated by van den Oord et al <cite class="ltx_cite ltx_citemacro_cite">Oord et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib30" title="">2018</a>)</cite>. Contrary to the approach of Lu et al <cite class="ltx_cite ltx_citemacro_cite">Lu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib21" title="">2022</a>)</cite> which overlooks hard negatives, our methodology aligns with that of Karpukhin et al <cite class="ltx_cite ltx_citemacro_cite">Karpukhin et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib28" title="">2020</a>)</cite>, embracing a comprehensive perspective on negative sampling.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS2.SSS1.p6">
<table class="ltx_equationgroup ltx_eqn_table" id="S2.E1">
<tbody>
<tr class="ltx_equation ltx_eqn_row ltx_align_baseline" id="S2.E1X">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle L(q,c^{+},c^{-}_{1},c^{-}_{2},...,c^{-}m)\ =" class="ltx_Math" display="inline" id="S2.E1X.2.1.1.m1.6"><semantics id="S2.E1X.2.1.1.m1.6a"><mrow id="S2.E1X.2.1.1.m1.6.6" xref="S2.E1X.2.1.1.m1.6.6.cmml"><mrow id="S2.E1X.2.1.1.m1.6.6.4" xref="S2.E1X.2.1.1.m1.6.6.4.cmml"><mi id="S2.E1X.2.1.1.m1.6.6.4.6" xref="S2.E1X.2.1.1.m1.6.6.4.6.cmml">L</mi><mo id="S2.E1X.2.1.1.m1.6.6.4.5" xref="S2.E1X.2.1.1.m1.6.6.4.5.cmml">⁢</mo><mrow id="S2.E1X.2.1.1.m1.6.6.4.4.4" xref="S2.E1X.2.1.1.m1.6.6.4.4.5.cmml"><mo id="S2.E1X.2.1.1.m1.6.6.4.4.4.5" stretchy="false" xref="S2.E1X.2.1.1.m1.6.6.4.4.5.cmml">(</mo><mi id="S2.E1X.2.1.1.m1.1.1" xref="S2.E1X.2.1.1.m1.1.1.cmml">q</mi><mo id="S2.E1X.2.1.1.m1.6.6.4.4.4.6" xref="S2.E1X.2.1.1.m1.6.6.4.4.5.cmml">,</mo><msup id="S2.E1X.2.1.1.m1.3.3.1.1.1.1" xref="S2.E1X.2.1.1.m1.3.3.1.1.1.1.cmml"><mi id="S2.E1X.2.1.1.m1.3.3.1.1.1.1.2" xref="S2.E1X.2.1.1.m1.3.3.1.1.1.1.2.cmml">c</mi><mo id="S2.E1X.2.1.1.m1.3.3.1.1.1.1.3" xref="S2.E1X.2.1.1.m1.3.3.1.1.1.1.3.cmml">+</mo></msup><mo id="S2.E1X.2.1.1.m1.6.6.4.4.4.7" xref="S2.E1X.2.1.1.m1.6.6.4.4.5.cmml">,</mo><msubsup id="S2.E1X.2.1.1.m1.4.4.2.2.2.2" xref="S2.E1X.2.1.1.m1.4.4.2.2.2.2.cmml"><mi id="S2.E1X.2.1.1.m1.4.4.2.2.2.2.2.2" xref="S2.E1X.2.1.1.m1.4.4.2.2.2.2.2.2.cmml">c</mi><mn id="S2.E1X.2.1.1.m1.4.4.2.2.2.2.3" xref="S2.E1X.2.1.1.m1.4.4.2.2.2.2.3.cmml">1</mn><mo id="S2.E1X.2.1.1.m1.4.4.2.2.2.2.2.3" xref="S2.E1X.2.1.1.m1.4.4.2.2.2.2.2.3.cmml">−</mo></msubsup><mo id="S2.E1X.2.1.1.m1.6.6.4.4.4.8" xref="S2.E1X.2.1.1.m1.6.6.4.4.5.cmml">,</mo><msubsup id="S2.E1X.2.1.1.m1.5.5.3.3.3.3" xref="S2.E1X.2.1.1.m1.5.5.3.3.3.3.cmml"><mi id="S2.E1X.2.1.1.m1.5.5.3.3.3.3.2.2" xref="S2.E1X.2.1.1.m1.5.5.3.3.3.3.2.2.cmml">c</mi><mn id="S2.E1X.2.1.1.m1.5.5.3.3.3.3.3" xref="S2.E1X.2.1.1.m1.5.5.3.3.3.3.3.cmml">2</mn><mo id="S2.E1X.2.1.1.m1.5.5.3.3.3.3.2.3" xref="S2.E1X.2.1.1.m1.5.5.3.3.3.3.2.3.cmml">−</mo></msubsup><mo id="S2.E1X.2.1.1.m1.6.6.4.4.4.9" xref="S2.E1X.2.1.1.m1.6.6.4.4.5.cmml">,</mo><mi id="S2.E1X.2.1.1.m1.2.2" mathvariant="normal" xref="S2.E1X.2.1.1.m1.2.2.cmml">…</mi><mo id="S2.E1X.2.1.1.m1.6.6.4.4.4.10" xref="S2.E1X.2.1.1.m1.6.6.4.4.5.cmml">,</mo><mrow id="S2.E1X.2.1.1.m1.6.6.4.4.4.4" xref="S2.E1X.2.1.1.m1.6.6.4.4.4.4.cmml"><msup id="S2.E1X.2.1.1.m1.6.6.4.4.4.4.2" xref="S2.E1X.2.1.1.m1.6.6.4.4.4.4.2.cmml"><mi id="S2.E1X.2.1.1.m1.6.6.4.4.4.4.2.2" xref="S2.E1X.2.1.1.m1.6.6.4.4.4.4.2.2.cmml">c</mi><mo id="S2.E1X.2.1.1.m1.6.6.4.4.4.4.2.3" xref="S2.E1X.2.1.1.m1.6.6.4.4.4.4.2.3.cmml">−</mo></msup><mo id="S2.E1X.2.1.1.m1.6.6.4.4.4.4.1" xref="S2.E1X.2.1.1.m1.6.6.4.4.4.4.1.cmml">⁢</mo><mi id="S2.E1X.2.1.1.m1.6.6.4.4.4.4.3" xref="S2.E1X.2.1.1.m1.6.6.4.4.4.4.3.cmml">m</mi></mrow><mo id="S2.E1X.2.1.1.m1.6.6.4.4.4.11" rspace="0.500em" stretchy="false" xref="S2.E1X.2.1.1.m1.6.6.4.4.5.cmml">)</mo></mrow></mrow><mo id="S2.E1X.2.1.1.m1.6.6.5" xref="S2.E1X.2.1.1.m1.6.6.5.cmml">=</mo><mi id="S2.E1X.2.1.1.m1.6.6.6" xref="S2.E1X.2.1.1.m1.6.6.6.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="S2.E1X.2.1.1.m1.6b"><apply id="S2.E1X.2.1.1.m1.6.6.cmml" xref="S2.E1X.2.1.1.m1.6.6"><eq id="S2.E1X.2.1.1.m1.6.6.5.cmml" xref="S2.E1X.2.1.1.m1.6.6.5"></eq><apply id="S2.E1X.2.1.1.m1.6.6.4.cmml" xref="S2.E1X.2.1.1.m1.6.6.4"><times id="S2.E1X.2.1.1.m1.6.6.4.5.cmml" xref="S2.E1X.2.1.1.m1.6.6.4.5"></times><ci id="S2.E1X.2.1.1.m1.6.6.4.6.cmml" xref="S2.E1X.2.1.1.m1.6.6.4.6">𝐿</ci><vector id="S2.E1X.2.1.1.m1.6.6.4.4.5.cmml" xref="S2.E1X.2.1.1.m1.6.6.4.4.4"><ci id="S2.E1X.2.1.1.m1.1.1.cmml" xref="S2.E1X.2.1.1.m1.1.1">𝑞</ci><apply id="S2.E1X.2.1.1.m1.3.3.1.1.1.1.cmml" xref="S2.E1X.2.1.1.m1.3.3.1.1.1.1"><csymbol cd="ambiguous" id="S2.E1X.2.1.1.m1.3.3.1.1.1.1.1.cmml" xref="S2.E1X.2.1.1.m1.3.3.1.1.1.1">superscript</csymbol><ci id="S2.E1X.2.1.1.m1.3.3.1.1.1.1.2.cmml" xref="S2.E1X.2.1.1.m1.3.3.1.1.1.1.2">𝑐</ci><plus id="S2.E1X.2.1.1.m1.3.3.1.1.1.1.3.cmml" xref="S2.E1X.2.1.1.m1.3.3.1.1.1.1.3"></plus></apply><apply id="S2.E1X.2.1.1.m1.4.4.2.2.2.2.cmml" xref="S2.E1X.2.1.1.m1.4.4.2.2.2.2"><csymbol cd="ambiguous" id="S2.E1X.2.1.1.m1.4.4.2.2.2.2.1.cmml" xref="S2.E1X.2.1.1.m1.4.4.2.2.2.2">subscript</csymbol><apply id="S2.E1X.2.1.1.m1.4.4.2.2.2.2.2.cmml" xref="S2.E1X.2.1.1.m1.4.4.2.2.2.2"><csymbol cd="ambiguous" id="S2.E1X.2.1.1.m1.4.4.2.2.2.2.2.1.cmml" xref="S2.E1X.2.1.1.m1.4.4.2.2.2.2">superscript</csymbol><ci id="S2.E1X.2.1.1.m1.4.4.2.2.2.2.2.2.cmml" xref="S2.E1X.2.1.1.m1.4.4.2.2.2.2.2.2">𝑐</ci><minus id="S2.E1X.2.1.1.m1.4.4.2.2.2.2.2.3.cmml" xref="S2.E1X.2.1.1.m1.4.4.2.2.2.2.2.3"></minus></apply><cn id="S2.E1X.2.1.1.m1.4.4.2.2.2.2.3.cmml" type="integer" xref="S2.E1X.2.1.1.m1.4.4.2.2.2.2.3">1</cn></apply><apply id="S2.E1X.2.1.1.m1.5.5.3.3.3.3.cmml" xref="S2.E1X.2.1.1.m1.5.5.3.3.3.3"><csymbol cd="ambiguous" id="S2.E1X.2.1.1.m1.5.5.3.3.3.3.1.cmml" xref="S2.E1X.2.1.1.m1.5.5.3.3.3.3">subscript</csymbol><apply id="S2.E1X.2.1.1.m1.5.5.3.3.3.3.2.cmml" xref="S2.E1X.2.1.1.m1.5.5.3.3.3.3"><csymbol cd="ambiguous" id="S2.E1X.2.1.1.m1.5.5.3.3.3.3.2.1.cmml" xref="S2.E1X.2.1.1.m1.5.5.3.3.3.3">superscript</csymbol><ci id="S2.E1X.2.1.1.m1.5.5.3.3.3.3.2.2.cmml" xref="S2.E1X.2.1.1.m1.5.5.3.3.3.3.2.2">𝑐</ci><minus id="S2.E1X.2.1.1.m1.5.5.3.3.3.3.2.3.cmml" xref="S2.E1X.2.1.1.m1.5.5.3.3.3.3.2.3"></minus></apply><cn id="S2.E1X.2.1.1.m1.5.5.3.3.3.3.3.cmml" type="integer" xref="S2.E1X.2.1.1.m1.5.5.3.3.3.3.3">2</cn></apply><ci id="S2.E1X.2.1.1.m1.2.2.cmml" xref="S2.E1X.2.1.1.m1.2.2">…</ci><apply id="S2.E1X.2.1.1.m1.6.6.4.4.4.4.cmml" xref="S2.E1X.2.1.1.m1.6.6.4.4.4.4"><times id="S2.E1X.2.1.1.m1.6.6.4.4.4.4.1.cmml" xref="S2.E1X.2.1.1.m1.6.6.4.4.4.4.1"></times><apply id="S2.E1X.2.1.1.m1.6.6.4.4.4.4.2.cmml" xref="S2.E1X.2.1.1.m1.6.6.4.4.4.4.2"><csymbol cd="ambiguous" id="S2.E1X.2.1.1.m1.6.6.4.4.4.4.2.1.cmml" xref="S2.E1X.2.1.1.m1.6.6.4.4.4.4.2">superscript</csymbol><ci id="S2.E1X.2.1.1.m1.6.6.4.4.4.4.2.2.cmml" xref="S2.E1X.2.1.1.m1.6.6.4.4.4.4.2.2">𝑐</ci><minus id="S2.E1X.2.1.1.m1.6.6.4.4.4.4.2.3.cmml" xref="S2.E1X.2.1.1.m1.6.6.4.4.4.4.2.3"></minus></apply><ci id="S2.E1X.2.1.1.m1.6.6.4.4.4.4.3.cmml" xref="S2.E1X.2.1.1.m1.6.6.4.4.4.4.3">𝑚</ci></apply></vector></apply><csymbol cd="latexml" id="S2.E1X.2.1.1.m1.6.6.6.cmml" xref="S2.E1X.2.1.1.m1.6.6.6">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1X.2.1.1.m1.6c">\displaystyle L(q,c^{+},c^{-}_{1},c^{-}_{2},...,c^{-}m)\ =</annotation><annotation encoding="application/x-llamapun" id="S2.E1X.2.1.1.m1.6d">italic_L ( italic_q , italic_c start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT , italic_c start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_c start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , italic_c start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT italic_m ) =</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle-log\frac{e^{sim(q,c^{+})}}{e^{sim(q,c^{+})}+\sum^{m}{i=1}e^{sim(%
q,c^{-}_{i})}}" class="ltx_Math" display="inline" id="S2.E1X.4.1.1.m1.6"><semantics id="S2.E1X.4.1.1.m1.6a"><mrow id="S2.E1X.4.1.1.m1.6.7" xref="S2.E1X.4.1.1.m1.6.7.cmml"><mo id="S2.E1X.4.1.1.m1.6.7a" xref="S2.E1X.4.1.1.m1.6.7.cmml">−</mo><mrow id="S2.E1X.4.1.1.m1.6.7.2" xref="S2.E1X.4.1.1.m1.6.7.2.cmml"><mi id="S2.E1X.4.1.1.m1.6.7.2.2" xref="S2.E1X.4.1.1.m1.6.7.2.2.cmml">l</mi><mo id="S2.E1X.4.1.1.m1.6.7.2.1" xref="S2.E1X.4.1.1.m1.6.7.2.1.cmml">⁢</mo><mi id="S2.E1X.4.1.1.m1.6.7.2.3" xref="S2.E1X.4.1.1.m1.6.7.2.3.cmml">o</mi><mo id="S2.E1X.4.1.1.m1.6.7.2.1a" xref="S2.E1X.4.1.1.m1.6.7.2.1.cmml">⁢</mo><mi id="S2.E1X.4.1.1.m1.6.7.2.4" xref="S2.E1X.4.1.1.m1.6.7.2.4.cmml">g</mi><mo id="S2.E1X.4.1.1.m1.6.7.2.1b" xref="S2.E1X.4.1.1.m1.6.7.2.1.cmml">⁢</mo><mstyle displaystyle="true" id="S2.E1X.4.1.1.m1.6.6" xref="S2.E1X.4.1.1.m1.6.6.cmml"><mfrac id="S2.E1X.4.1.1.m1.6.6a" xref="S2.E1X.4.1.1.m1.6.6.cmml"><msup id="S2.E1X.4.1.1.m1.2.2.2" xref="S2.E1X.4.1.1.m1.2.2.2.cmml"><mi id="S2.E1X.4.1.1.m1.2.2.2.4" xref="S2.E1X.4.1.1.m1.2.2.2.4.cmml">e</mi><mrow id="S2.E1X.4.1.1.m1.2.2.2.2.2" xref="S2.E1X.4.1.1.m1.2.2.2.2.2.cmml"><mi id="S2.E1X.4.1.1.m1.2.2.2.2.2.4" xref="S2.E1X.4.1.1.m1.2.2.2.2.2.4.cmml">s</mi><mo id="S2.E1X.4.1.1.m1.2.2.2.2.2.3" xref="S2.E1X.4.1.1.m1.2.2.2.2.2.3.cmml">⁢</mo><mi id="S2.E1X.4.1.1.m1.2.2.2.2.2.5" xref="S2.E1X.4.1.1.m1.2.2.2.2.2.5.cmml">i</mi><mo id="S2.E1X.4.1.1.m1.2.2.2.2.2.3a" xref="S2.E1X.4.1.1.m1.2.2.2.2.2.3.cmml">⁢</mo><mi id="S2.E1X.4.1.1.m1.2.2.2.2.2.6" xref="S2.E1X.4.1.1.m1.2.2.2.2.2.6.cmml">m</mi><mo id="S2.E1X.4.1.1.m1.2.2.2.2.2.3b" xref="S2.E1X.4.1.1.m1.2.2.2.2.2.3.cmml">⁢</mo><mrow id="S2.E1X.4.1.1.m1.2.2.2.2.2.2.1" xref="S2.E1X.4.1.1.m1.2.2.2.2.2.2.2.cmml"><mo id="S2.E1X.4.1.1.m1.2.2.2.2.2.2.1.2" stretchy="false" xref="S2.E1X.4.1.1.m1.2.2.2.2.2.2.2.cmml">(</mo><mi id="S2.E1X.4.1.1.m1.1.1.1.1.1.1" xref="S2.E1X.4.1.1.m1.1.1.1.1.1.1.cmml">q</mi><mo id="S2.E1X.4.1.1.m1.2.2.2.2.2.2.1.3" xref="S2.E1X.4.1.1.m1.2.2.2.2.2.2.2.cmml">,</mo><msup id="S2.E1X.4.1.1.m1.2.2.2.2.2.2.1.1" xref="S2.E1X.4.1.1.m1.2.2.2.2.2.2.1.1.cmml"><mi id="S2.E1X.4.1.1.m1.2.2.2.2.2.2.1.1.2" xref="S2.E1X.4.1.1.m1.2.2.2.2.2.2.1.1.2.cmml">c</mi><mo id="S2.E1X.4.1.1.m1.2.2.2.2.2.2.1.1.3" xref="S2.E1X.4.1.1.m1.2.2.2.2.2.2.1.1.3.cmml">+</mo></msup><mo id="S2.E1X.4.1.1.m1.2.2.2.2.2.2.1.4" stretchy="false" xref="S2.E1X.4.1.1.m1.2.2.2.2.2.2.2.cmml">)</mo></mrow></mrow></msup><mrow id="S2.E1X.4.1.1.m1.6.6.6" xref="S2.E1X.4.1.1.m1.6.6.6.cmml"><mrow id="S2.E1X.4.1.1.m1.6.6.6.6" xref="S2.E1X.4.1.1.m1.6.6.6.6.cmml"><msup id="S2.E1X.4.1.1.m1.6.6.6.6.2" xref="S2.E1X.4.1.1.m1.6.6.6.6.2.cmml"><mi id="S2.E1X.4.1.1.m1.6.6.6.6.2.2" xref="S2.E1X.4.1.1.m1.6.6.6.6.2.2.cmml">e</mi><mrow id="S2.E1X.4.1.1.m1.4.4.4.2.2" xref="S2.E1X.4.1.1.m1.4.4.4.2.2.cmml"><mi id="S2.E1X.4.1.1.m1.4.4.4.2.2.4" xref="S2.E1X.4.1.1.m1.4.4.4.2.2.4.cmml">s</mi><mo id="S2.E1X.4.1.1.m1.4.4.4.2.2.3" xref="S2.E1X.4.1.1.m1.4.4.4.2.2.3.cmml">⁢</mo><mi id="S2.E1X.4.1.1.m1.4.4.4.2.2.5" xref="S2.E1X.4.1.1.m1.4.4.4.2.2.5.cmml">i</mi><mo id="S2.E1X.4.1.1.m1.4.4.4.2.2.3a" xref="S2.E1X.4.1.1.m1.4.4.4.2.2.3.cmml">⁢</mo><mi id="S2.E1X.4.1.1.m1.4.4.4.2.2.6" xref="S2.E1X.4.1.1.m1.4.4.4.2.2.6.cmml">m</mi><mo id="S2.E1X.4.1.1.m1.4.4.4.2.2.3b" xref="S2.E1X.4.1.1.m1.4.4.4.2.2.3.cmml">⁢</mo><mrow id="S2.E1X.4.1.1.m1.4.4.4.2.2.2.1" xref="S2.E1X.4.1.1.m1.4.4.4.2.2.2.2.cmml"><mo id="S2.E1X.4.1.1.m1.4.4.4.2.2.2.1.2" stretchy="false" xref="S2.E1X.4.1.1.m1.4.4.4.2.2.2.2.cmml">(</mo><mi id="S2.E1X.4.1.1.m1.3.3.3.1.1.1" xref="S2.E1X.4.1.1.m1.3.3.3.1.1.1.cmml">q</mi><mo id="S2.E1X.4.1.1.m1.4.4.4.2.2.2.1.3" xref="S2.E1X.4.1.1.m1.4.4.4.2.2.2.2.cmml">,</mo><msup id="S2.E1X.4.1.1.m1.4.4.4.2.2.2.1.1" xref="S2.E1X.4.1.1.m1.4.4.4.2.2.2.1.1.cmml"><mi id="S2.E1X.4.1.1.m1.4.4.4.2.2.2.1.1.2" xref="S2.E1X.4.1.1.m1.4.4.4.2.2.2.1.1.2.cmml">c</mi><mo id="S2.E1X.4.1.1.m1.4.4.4.2.2.2.1.1.3" xref="S2.E1X.4.1.1.m1.4.4.4.2.2.2.1.1.3.cmml">+</mo></msup><mo id="S2.E1X.4.1.1.m1.4.4.4.2.2.2.1.4" stretchy="false" xref="S2.E1X.4.1.1.m1.4.4.4.2.2.2.2.cmml">)</mo></mrow></mrow></msup><mo id="S2.E1X.4.1.1.m1.6.6.6.6.1" rspace="0.055em" xref="S2.E1X.4.1.1.m1.6.6.6.6.1.cmml">+</mo><mrow id="S2.E1X.4.1.1.m1.6.6.6.6.3" xref="S2.E1X.4.1.1.m1.6.6.6.6.3.cmml"><msup id="S2.E1X.4.1.1.m1.6.6.6.6.3.1" xref="S2.E1X.4.1.1.m1.6.6.6.6.3.1.cmml"><mo id="S2.E1X.4.1.1.m1.6.6.6.6.3.1.2" xref="S2.E1X.4.1.1.m1.6.6.6.6.3.1.2.cmml">∑</mo><mi id="S2.E1X.4.1.1.m1.6.6.6.6.3.1.3" xref="S2.E1X.4.1.1.m1.6.6.6.6.3.1.3.cmml">m</mi></msup><mi id="S2.E1X.4.1.1.m1.6.6.6.6.3.2" xref="S2.E1X.4.1.1.m1.6.6.6.6.3.2.cmml">i</mi></mrow></mrow><mo id="S2.E1X.4.1.1.m1.6.6.6.5" xref="S2.E1X.4.1.1.m1.6.6.6.5.cmml">=</mo><mrow id="S2.E1X.4.1.1.m1.6.6.6.7" xref="S2.E1X.4.1.1.m1.6.6.6.7.cmml"><mn id="S2.E1X.4.1.1.m1.6.6.6.7.2" xref="S2.E1X.4.1.1.m1.6.6.6.7.2.cmml">1</mn><mo id="S2.E1X.4.1.1.m1.6.6.6.7.1" xref="S2.E1X.4.1.1.m1.6.6.6.7.1.cmml">⁢</mo><msup id="S2.E1X.4.1.1.m1.6.6.6.7.3" xref="S2.E1X.4.1.1.m1.6.6.6.7.3.cmml"><mi id="S2.E1X.4.1.1.m1.6.6.6.7.3.2" xref="S2.E1X.4.1.1.m1.6.6.6.7.3.2.cmml">e</mi><mrow id="S2.E1X.4.1.1.m1.6.6.6.4.2" xref="S2.E1X.4.1.1.m1.6.6.6.4.2.cmml"><mi id="S2.E1X.4.1.1.m1.6.6.6.4.2.4" xref="S2.E1X.4.1.1.m1.6.6.6.4.2.4.cmml">s</mi><mo id="S2.E1X.4.1.1.m1.6.6.6.4.2.3" xref="S2.E1X.4.1.1.m1.6.6.6.4.2.3.cmml">⁢</mo><mi id="S2.E1X.4.1.1.m1.6.6.6.4.2.5" xref="S2.E1X.4.1.1.m1.6.6.6.4.2.5.cmml">i</mi><mo id="S2.E1X.4.1.1.m1.6.6.6.4.2.3a" xref="S2.E1X.4.1.1.m1.6.6.6.4.2.3.cmml">⁢</mo><mi id="S2.E1X.4.1.1.m1.6.6.6.4.2.6" xref="S2.E1X.4.1.1.m1.6.6.6.4.2.6.cmml">m</mi><mo id="S2.E1X.4.1.1.m1.6.6.6.4.2.3b" xref="S2.E1X.4.1.1.m1.6.6.6.4.2.3.cmml">⁢</mo><mrow id="S2.E1X.4.1.1.m1.6.6.6.4.2.2.1" xref="S2.E1X.4.1.1.m1.6.6.6.4.2.2.2.cmml"><mo id="S2.E1X.4.1.1.m1.6.6.6.4.2.2.1.2" stretchy="false" xref="S2.E1X.4.1.1.m1.6.6.6.4.2.2.2.cmml">(</mo><mi id="S2.E1X.4.1.1.m1.5.5.5.3.1.1" xref="S2.E1X.4.1.1.m1.5.5.5.3.1.1.cmml">q</mi><mo id="S2.E1X.4.1.1.m1.6.6.6.4.2.2.1.3" xref="S2.E1X.4.1.1.m1.6.6.6.4.2.2.2.cmml">,</mo><msubsup id="S2.E1X.4.1.1.m1.6.6.6.4.2.2.1.1" xref="S2.E1X.4.1.1.m1.6.6.6.4.2.2.1.1.cmml"><mi id="S2.E1X.4.1.1.m1.6.6.6.4.2.2.1.1.2.2" xref="S2.E1X.4.1.1.m1.6.6.6.4.2.2.1.1.2.2.cmml">c</mi><mi id="S2.E1X.4.1.1.m1.6.6.6.4.2.2.1.1.3" xref="S2.E1X.4.1.1.m1.6.6.6.4.2.2.1.1.3.cmml">i</mi><mo id="S2.E1X.4.1.1.m1.6.6.6.4.2.2.1.1.2.3" xref="S2.E1X.4.1.1.m1.6.6.6.4.2.2.1.1.2.3.cmml">−</mo></msubsup><mo id="S2.E1X.4.1.1.m1.6.6.6.4.2.2.1.4" stretchy="false" xref="S2.E1X.4.1.1.m1.6.6.6.4.2.2.2.cmml">)</mo></mrow></mrow></msup></mrow></mrow></mfrac></mstyle></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E1X.4.1.1.m1.6b"><apply id="S2.E1X.4.1.1.m1.6.7.cmml" xref="S2.E1X.4.1.1.m1.6.7"><minus id="S2.E1X.4.1.1.m1.6.7.1.cmml" xref="S2.E1X.4.1.1.m1.6.7"></minus><apply id="S2.E1X.4.1.1.m1.6.7.2.cmml" xref="S2.E1X.4.1.1.m1.6.7.2"><times id="S2.E1X.4.1.1.m1.6.7.2.1.cmml" xref="S2.E1X.4.1.1.m1.6.7.2.1"></times><ci id="S2.E1X.4.1.1.m1.6.7.2.2.cmml" xref="S2.E1X.4.1.1.m1.6.7.2.2">𝑙</ci><ci id="S2.E1X.4.1.1.m1.6.7.2.3.cmml" xref="S2.E1X.4.1.1.m1.6.7.2.3">𝑜</ci><ci id="S2.E1X.4.1.1.m1.6.7.2.4.cmml" xref="S2.E1X.4.1.1.m1.6.7.2.4">𝑔</ci><apply id="S2.E1X.4.1.1.m1.6.6.cmml" xref="S2.E1X.4.1.1.m1.6.6"><divide id="S2.E1X.4.1.1.m1.6.6.7.cmml" xref="S2.E1X.4.1.1.m1.6.6"></divide><apply id="S2.E1X.4.1.1.m1.2.2.2.cmml" xref="S2.E1X.4.1.1.m1.2.2.2"><csymbol cd="ambiguous" id="S2.E1X.4.1.1.m1.2.2.2.3.cmml" xref="S2.E1X.4.1.1.m1.2.2.2">superscript</csymbol><ci id="S2.E1X.4.1.1.m1.2.2.2.4.cmml" xref="S2.E1X.4.1.1.m1.2.2.2.4">𝑒</ci><apply id="S2.E1X.4.1.1.m1.2.2.2.2.2.cmml" xref="S2.E1X.4.1.1.m1.2.2.2.2.2"><times id="S2.E1X.4.1.1.m1.2.2.2.2.2.3.cmml" xref="S2.E1X.4.1.1.m1.2.2.2.2.2.3"></times><ci id="S2.E1X.4.1.1.m1.2.2.2.2.2.4.cmml" xref="S2.E1X.4.1.1.m1.2.2.2.2.2.4">𝑠</ci><ci id="S2.E1X.4.1.1.m1.2.2.2.2.2.5.cmml" xref="S2.E1X.4.1.1.m1.2.2.2.2.2.5">𝑖</ci><ci id="S2.E1X.4.1.1.m1.2.2.2.2.2.6.cmml" xref="S2.E1X.4.1.1.m1.2.2.2.2.2.6">𝑚</ci><interval closure="open" id="S2.E1X.4.1.1.m1.2.2.2.2.2.2.2.cmml" xref="S2.E1X.4.1.1.m1.2.2.2.2.2.2.1"><ci id="S2.E1X.4.1.1.m1.1.1.1.1.1.1.cmml" xref="S2.E1X.4.1.1.m1.1.1.1.1.1.1">𝑞</ci><apply id="S2.E1X.4.1.1.m1.2.2.2.2.2.2.1.1.cmml" xref="S2.E1X.4.1.1.m1.2.2.2.2.2.2.1.1"><csymbol cd="ambiguous" id="S2.E1X.4.1.1.m1.2.2.2.2.2.2.1.1.1.cmml" xref="S2.E1X.4.1.1.m1.2.2.2.2.2.2.1.1">superscript</csymbol><ci id="S2.E1X.4.1.1.m1.2.2.2.2.2.2.1.1.2.cmml" xref="S2.E1X.4.1.1.m1.2.2.2.2.2.2.1.1.2">𝑐</ci><plus id="S2.E1X.4.1.1.m1.2.2.2.2.2.2.1.1.3.cmml" xref="S2.E1X.4.1.1.m1.2.2.2.2.2.2.1.1.3"></plus></apply></interval></apply></apply><apply id="S2.E1X.4.1.1.m1.6.6.6.cmml" xref="S2.E1X.4.1.1.m1.6.6.6"><eq id="S2.E1X.4.1.1.m1.6.6.6.5.cmml" xref="S2.E1X.4.1.1.m1.6.6.6.5"></eq><apply id="S2.E1X.4.1.1.m1.6.6.6.6.cmml" xref="S2.E1X.4.1.1.m1.6.6.6.6"><plus id="S2.E1X.4.1.1.m1.6.6.6.6.1.cmml" xref="S2.E1X.4.1.1.m1.6.6.6.6.1"></plus><apply id="S2.E1X.4.1.1.m1.6.6.6.6.2.cmml" xref="S2.E1X.4.1.1.m1.6.6.6.6.2"><csymbol cd="ambiguous" id="S2.E1X.4.1.1.m1.6.6.6.6.2.1.cmml" xref="S2.E1X.4.1.1.m1.6.6.6.6.2">superscript</csymbol><ci id="S2.E1X.4.1.1.m1.6.6.6.6.2.2.cmml" xref="S2.E1X.4.1.1.m1.6.6.6.6.2.2">𝑒</ci><apply id="S2.E1X.4.1.1.m1.4.4.4.2.2.cmml" xref="S2.E1X.4.1.1.m1.4.4.4.2.2"><times id="S2.E1X.4.1.1.m1.4.4.4.2.2.3.cmml" xref="S2.E1X.4.1.1.m1.4.4.4.2.2.3"></times><ci id="S2.E1X.4.1.1.m1.4.4.4.2.2.4.cmml" xref="S2.E1X.4.1.1.m1.4.4.4.2.2.4">𝑠</ci><ci id="S2.E1X.4.1.1.m1.4.4.4.2.2.5.cmml" xref="S2.E1X.4.1.1.m1.4.4.4.2.2.5">𝑖</ci><ci id="S2.E1X.4.1.1.m1.4.4.4.2.2.6.cmml" xref="S2.E1X.4.1.1.m1.4.4.4.2.2.6">𝑚</ci><interval closure="open" id="S2.E1X.4.1.1.m1.4.4.4.2.2.2.2.cmml" xref="S2.E1X.4.1.1.m1.4.4.4.2.2.2.1"><ci id="S2.E1X.4.1.1.m1.3.3.3.1.1.1.cmml" xref="S2.E1X.4.1.1.m1.3.3.3.1.1.1">𝑞</ci><apply id="S2.E1X.4.1.1.m1.4.4.4.2.2.2.1.1.cmml" xref="S2.E1X.4.1.1.m1.4.4.4.2.2.2.1.1"><csymbol cd="ambiguous" id="S2.E1X.4.1.1.m1.4.4.4.2.2.2.1.1.1.cmml" xref="S2.E1X.4.1.1.m1.4.4.4.2.2.2.1.1">superscript</csymbol><ci id="S2.E1X.4.1.1.m1.4.4.4.2.2.2.1.1.2.cmml" xref="S2.E1X.4.1.1.m1.4.4.4.2.2.2.1.1.2">𝑐</ci><plus id="S2.E1X.4.1.1.m1.4.4.4.2.2.2.1.1.3.cmml" xref="S2.E1X.4.1.1.m1.4.4.4.2.2.2.1.1.3"></plus></apply></interval></apply></apply><apply id="S2.E1X.4.1.1.m1.6.6.6.6.3.cmml" xref="S2.E1X.4.1.1.m1.6.6.6.6.3"><apply id="S2.E1X.4.1.1.m1.6.6.6.6.3.1.cmml" xref="S2.E1X.4.1.1.m1.6.6.6.6.3.1"><csymbol cd="ambiguous" id="S2.E1X.4.1.1.m1.6.6.6.6.3.1.1.cmml" xref="S2.E1X.4.1.1.m1.6.6.6.6.3.1">superscript</csymbol><sum id="S2.E1X.4.1.1.m1.6.6.6.6.3.1.2.cmml" xref="S2.E1X.4.1.1.m1.6.6.6.6.3.1.2"></sum><ci id="S2.E1X.4.1.1.m1.6.6.6.6.3.1.3.cmml" xref="S2.E1X.4.1.1.m1.6.6.6.6.3.1.3">𝑚</ci></apply><ci id="S2.E1X.4.1.1.m1.6.6.6.6.3.2.cmml" xref="S2.E1X.4.1.1.m1.6.6.6.6.3.2">𝑖</ci></apply></apply><apply id="S2.E1X.4.1.1.m1.6.6.6.7.cmml" xref="S2.E1X.4.1.1.m1.6.6.6.7"><times id="S2.E1X.4.1.1.m1.6.6.6.7.1.cmml" xref="S2.E1X.4.1.1.m1.6.6.6.7.1"></times><cn id="S2.E1X.4.1.1.m1.6.6.6.7.2.cmml" type="integer" xref="S2.E1X.4.1.1.m1.6.6.6.7.2">1</cn><apply id="S2.E1X.4.1.1.m1.6.6.6.7.3.cmml" xref="S2.E1X.4.1.1.m1.6.6.6.7.3"><csymbol cd="ambiguous" id="S2.E1X.4.1.1.m1.6.6.6.7.3.1.cmml" xref="S2.E1X.4.1.1.m1.6.6.6.7.3">superscript</csymbol><ci id="S2.E1X.4.1.1.m1.6.6.6.7.3.2.cmml" xref="S2.E1X.4.1.1.m1.6.6.6.7.3.2">𝑒</ci><apply id="S2.E1X.4.1.1.m1.6.6.6.4.2.cmml" xref="S2.E1X.4.1.1.m1.6.6.6.4.2"><times id="S2.E1X.4.1.1.m1.6.6.6.4.2.3.cmml" xref="S2.E1X.4.1.1.m1.6.6.6.4.2.3"></times><ci id="S2.E1X.4.1.1.m1.6.6.6.4.2.4.cmml" xref="S2.E1X.4.1.1.m1.6.6.6.4.2.4">𝑠</ci><ci id="S2.E1X.4.1.1.m1.6.6.6.4.2.5.cmml" xref="S2.E1X.4.1.1.m1.6.6.6.4.2.5">𝑖</ci><ci id="S2.E1X.4.1.1.m1.6.6.6.4.2.6.cmml" xref="S2.E1X.4.1.1.m1.6.6.6.4.2.6">𝑚</ci><interval closure="open" id="S2.E1X.4.1.1.m1.6.6.6.4.2.2.2.cmml" xref="S2.E1X.4.1.1.m1.6.6.6.4.2.2.1"><ci id="S2.E1X.4.1.1.m1.5.5.5.3.1.1.cmml" xref="S2.E1X.4.1.1.m1.5.5.5.3.1.1">𝑞</ci><apply id="S2.E1X.4.1.1.m1.6.6.6.4.2.2.1.1.cmml" xref="S2.E1X.4.1.1.m1.6.6.6.4.2.2.1.1"><csymbol cd="ambiguous" id="S2.E1X.4.1.1.m1.6.6.6.4.2.2.1.1.1.cmml" xref="S2.E1X.4.1.1.m1.6.6.6.4.2.2.1.1">subscript</csymbol><apply id="S2.E1X.4.1.1.m1.6.6.6.4.2.2.1.1.2.cmml" xref="S2.E1X.4.1.1.m1.6.6.6.4.2.2.1.1"><csymbol cd="ambiguous" id="S2.E1X.4.1.1.m1.6.6.6.4.2.2.1.1.2.1.cmml" xref="S2.E1X.4.1.1.m1.6.6.6.4.2.2.1.1">superscript</csymbol><ci id="S2.E1X.4.1.1.m1.6.6.6.4.2.2.1.1.2.2.cmml" xref="S2.E1X.4.1.1.m1.6.6.6.4.2.2.1.1.2.2">𝑐</ci><minus id="S2.E1X.4.1.1.m1.6.6.6.4.2.2.1.1.2.3.cmml" xref="S2.E1X.4.1.1.m1.6.6.6.4.2.2.1.1.2.3"></minus></apply><ci id="S2.E1X.4.1.1.m1.6.6.6.4.2.2.1.1.3.cmml" xref="S2.E1X.4.1.1.m1.6.6.6.4.2.2.1.1.3">𝑖</ci></apply></interval></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1X.4.1.1.m1.6c">\displaystyle-log\frac{e^{sim(q,c^{+})}}{e^{sim(q,c^{+})}+\sum^{m}{i=1}e^{sim(%
q,c^{-}_{i})}}</annotation><annotation encoding="application/x-llamapun" id="S2.E1X.4.1.1.m1.6d">- italic_l italic_o italic_g divide start_ARG italic_e start_POSTSUPERSCRIPT italic_s italic_i italic_m ( italic_q , italic_c start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT ) end_POSTSUPERSCRIPT end_ARG start_ARG italic_e start_POSTSUPERSCRIPT italic_s italic_i italic_m ( italic_q , italic_c start_POSTSUPERSCRIPT + end_POSTSUPERSCRIPT ) end_POSTSUPERSCRIPT + ∑ start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT italic_i = 1 italic_e start_POSTSUPERSCRIPT italic_s italic_i italic_m ( italic_q , italic_c start_POSTSUPERSCRIPT - end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) end_POSTSUPERSCRIPT end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(1)</span></td>
</tr>
</tbody>
</table>
</div>
<figure class="ltx_figure" id="S2.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="299" id="S2.F2.g1" src="x2.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>The process of concept selection.</figcaption>
</figure>
</section>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Concept Selection</h3>
<div class="ltx_para ltx_noindent" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1">The process of Concept Selection signifies the culmination of our sub-task generation phase. While keywords, topics, and demonstrations of relevant text are instrumental in generating sub-tasks for our translation endeavor, it is crucial to acknowledge that not all generated outcomes may serve a practical purpose. Specifically, the LLM might engender sub-tasks predicated on either trivial or extraneous content, potentially leading the Sol-Mover LLM to produce either superfluous code snippets or, in less favorable instances, incorrect code. To mitigate such outcomes, we refine our sub-task generation to encompass only those concepts accompanied by suitable code snippets. These code snippets, in turn, are incorporated into the Sol-Mover as integral components of the sub-task prompts, thereby enhancing the LLM’s capability to generate pertinent sub-tasks, as illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#S2.F2" title="Figure 2 ‣ 2.2.1 Architecture ‣ 2.2 Concept Mining ‣ 2 SolMover ‣ Teaching Machines to Code: Smart Contract Translation with LLMs"><span class="ltx_text ltx_ref_tag">2</span></a>.
</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.4 </span>Sol-Mover Code Generator</h3>
<div class="ltx_para ltx_noindent" id="S2.SS4.p1">
<p class="ltx_p" id="S2.SS4.p1.1">Sol-Mover emerges as our dedicated Move code generator, which processes the sub-tasks delineated by the preceding LLM, as depicted in Figure <a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#S2.F2" title="Figure 2 ‣ 2.2.1 Architecture ‣ 2.2 Concept Mining ‣ 2 SolMover ‣ Teaching Machines to Code: Smart Contract Translation with LLMs"><span class="ltx_text ltx_ref_tag">2</span></a>, to produce Move code. The foundation of Sol-Mover is an instruction-trained model, derived from Alpaca <cite class="ltx_cite ltx_citemacro_cite">Taori et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib31" title="">2023</a>)</cite>, an open-source LLM refined through fine-tuning on the LLaMA <cite class="ltx_cite ltx_citemacro_cite">Touvron et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib32" title="">2023</a>)</cite> architecture. This model incorporates 52k instances of Self-Instruct data alongside user-contributed dialogues from ShareGPT <cite class="ltx_cite ltx_citemacro_cite">ShareGPT (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib33" title="">2023</a>)</cite>. Utilizing langchain, a prompting infrastructure is devised, assimilating each sub-task in conjunction with any associated code snippets to facilitate code generation via the fine-tuned model. Subsequent to the generation phase, the responses are amalgamated into a unified file, adhering to the task sequence, thereby reconstructing the translated code pertaining to the original task. This consolidated code is then subjected to compilation via move-cli. Compilation errors, if any, are meticulously logged and integrated as experiential data within the langchain agent, which is subsequently relayed back to Sol-Mover for corrective measures. This iterative process is executed up to five times. Upon successful passage through the compilation phase, the code translation is deemed successful. However, the verification of its correctness remains, prompting the involvement of Move Prover, an automated formal verification tool for Move code. Any discrepancies identified by the Prover are directed back to Sol-Mover, initiating up to five iterations of corrective adjustments. The intricacies surrounding the training of both Sol-Mover and the sub-task creation LLM are expounded in Section <a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#S3" title="3 Technical Specification ‣ Teaching Machines to Code: Smart Contract Translation with LLMs"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.5 </span>Dataset for Solidity as Input Candidate</h3>
<div class="ltx_para ltx_noindent" id="S2.SS5.p1">
<p class="ltx_p" id="S2.SS5.p1.1">In our research, we encountered a significant challenge due to the inability to employ pre-existing datasets like HumanEval <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_ref ltx_missing_citation ltx_ref_self">chen2021codex</span></cite>, which predominantly cater to Python programming. This limitation necessitated the generation of a new dataset tailored to our specific requirements. To ensure the accuracy of code validation, our methodology involved a rigorous selection process for source files, prioritizing those available on GitHub under open-source licenses that offer permissive usage terms.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS5.p2">
<p class="ltx_p" id="S2.SS5.p2.1">To systematically compile Solidity code from various projects, we developed a scraper utilizing GitHub’s APIs. The criteria for corpus collection were meticulously defined to enhance the quality and relevance of the dataset:</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS5.p3">
<ul class="ltx_itemize" id="S2.I1">
<li class="ltx_item" id="S2.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i1.p1">
<p class="ltx_p" id="S2.I1.i1.p1.1">We targeted projects that had garnered a minimum of 50 GitHub stars, a benchmark indicative of a project’s interest, popularity, and its appeal to a human audience.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i2.p1">
<p class="ltx_p" id="S2.I1.i2.p1.1">The explicit tagging of a project with "Solidity" as a programming language was a prerequisite, ensuring the relevance of the collected code.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S2.I1.i3.p1">
<p class="ltx_p" id="S2.I1.i3.p1.1">A substantial volume of comments within the projects was deemed crucial. This was to facilitate the generation of scalable prompts and to lay the groundwork for an effective experimental pipeline.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS5.p4">
<p class="ltx_p" id="S2.SS5.p4.1">Subsequent to this targeted collection, an additional layer of processing was applied to sift through the gathered materials, excluding any files not authored in Solidity.</p>
</div>
<section class="ltx_paragraph" id="S2.SS5.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Compilation of the raw code corpus.</h5>
<div class="ltx_para ltx_noindent" id="S2.SS5.SSS0.Px1.p1">
<p class="ltx_p" id="S2.SS5.SSS0.Px1.p1.1">Our approach leveraged GitHub, a rich repository of publicly accessible source code, to mirror repositories prominently featuring the Solidity language tag and possessing at least 50 stars. This procedure enabled the extraction of Solidity files, which were then aggregated to form the base dataset intended for training purposes.</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Technical Specification</h2>
<div class="ltx_para ltx_noindent" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">In our research, we delineate the training regimen and model selection strategies for our models, focused on Concept understanding and sub-task generation, as well as the fine-tuning of Alpaca for code generation tasks.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Retrieval Augmented LLM for Concept Understanding</h3>
<div class="ltx_para ltx_noindent" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">In the pursuit of facilitating code-to-code translation for languages with very limited resources such as Move, our framework addresses a crucial challenge: premise selection <cite class="ltx_cite ltx_citemacro_cite">Urban (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib34" title="">2004</a>)</cite>. Whereas existing frameworks based on Large Language Models (LLMs) for knowledge distillation <cite class="ltx_cite ltx_citemacro_cite">Zhang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib20" title="">2023b</a>)</cite> and code completion <cite class="ltx_cite ltx_citemacro_cite">Robertson et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib29" title="">2009</a>)</cite> predominantly generate subsequent steps predicated on the immediate preceding input, the creation of coherent plans and sub-tasks is significantly reliant on premises. These include rules and code examples extracted from related descriptions, which are essential for understanding and translating code accurately.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1">The integration of all possible contexts within the limited input window of an LLM is infeasible, and attempts to bypass this limitation via LangChain’s agent-based memory have not yielded substantially improved outcomes. Traditional methods are constrained to memorize associations between the current task state and the subsequent relevant task, contingent on the original task. This approach is effective when the training data encompasses similar problems; however, for low-resource languages like Move, this methodology encounters limitations. Moreover, since Move is syntactically akin to Rust, pre-trained models on Rust may inadvertently introduce incorrect premise candidates. This issue is exacerbated in scenarios requiring the generation of code for tasks that were not encountered in the training dataset.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.1">To address these challenges, our framework enhances LLM memorization with a strategy for explicit context selection, thereby facilitating improved concept identification. This is achieved by extracting contexts directly from texts where they are defined and utilized, thereby enabling the identification of pertinent contexts through the augmentation of LLMs with retrieval capabilities.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p4">
<p class="ltx_p" id="S3.SS1.p4.1">Furthermore, it is imperative to constrain context retrieval to a manageable number of contexts to ensure its efficacy. As outlined in Section <a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#S2.SS2.SSS1" title="2.2.1 Architecture ‣ 2.2 Concept Mining ‣ 2 SolMover ‣ Teaching Machines to Code: Smart Contract Translation with LLMs"><span class="ltx_text ltx_ref_tag">2.2.1</span></a>, our retrieval mechanism is based on the Dense Passage Retriever (DPR) but incorporates two significant modifications tailored to our specific requirements. Firstly, the scope of context available for retrieval is deliberately restricted by initially extracting comments and functions, which serve as keywords in the initial prompt. This reduction simplifies the retrieval task by approximately 75%. Secondly, unlike the conventional DPR that benefits from the inclusion of hard negatives (irrelevant contexts that are challenging to differentiate) in its training, our approach employs in-file hard negatives. This method utilizes negative contexts derived from within the prompt itself, enhancing the model’s ability to discern relevant from irrelevant contexts effectively.</p>
</div>
<section class="ltx_subsubsection" id="S3.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.1 </span>Experimental Setup</h4>
<div class="ltx_para ltx_noindent" id="S3.SS1.SSS1.p1">
<p class="ltx_p" id="S3.SS1.SSS1.p1.1">The training is in two stages. In the first stage, we train the retriever and use it to retrieve 100 context states for all contexts for each task. Second, we train the sub-task generator, taking as input the retrieved context. We evaluate the task generator by combining it with the best-first search to generate valid sub-tasks. Training takes 7 days on a single NVIDIA A100 GPU. </p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Sol-Mover Code Generation Training</h3>
<div class="ltx_para ltx_noindent" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">For the development of our code generator, we employed the Alpaca model and subjected it to a fine-tuning process utilizing code examples derived from the instruction training dataset, as elaborated upon in Section <a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#S2.SS4" title="2.4 Sol-Mover Code Generator ‣ 2 SolMover ‣ Teaching Machines to Code: Smart Contract Translation with LLMs"><span class="ltx_text ltx_ref_tag">2.4</span></a>. The corpus for fine-tuning was notably small, comprising a select compilation of code samples. This curated selection included examples of Fungible Tokens <cite class="ltx_cite ltx_citemacro_cite">fun (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib35" title="">2023</a>); bas (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib36" title="">2023</a>); die (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib37" title="">2023</a>); tok (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib38" title="">2023</a>); gas (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib39" title="">2023</a>)</cite>, Non-Fungible Tokens (NFTs)<cite class="ltx_cite ltx_citemacro_cite">nft (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib40" title="">2023</a>); mer (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib41" title="">2023</a>)</cite>, and Decentralized Finance (DeFi) applications<cite class="ltx_cite ltx_citemacro_cite">def (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib42" title="">2023</a>); coi (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib43" title="">2023</a>); sta (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib44" title="">2023</a>)</cite>, which served as a foundation for the dataset’s creation.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1">The primary objective of this fine-tuning process was to imbue the Alpaca model with the capability to form associations with Move code constructs. By integrating these specific code examples into the training regimen, the model was tailored to recognize and generate Move code, facilitating the creation of more accurate and contextually relevant code outputs. This approach ensured that Alpaca could leverage its understanding of the underlying concepts and patterns within Move programming, thereby enhancing its efficiency and effectiveness as a code generator within our framework.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Experimental Setup</h3>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Models.</h5>
<div class="ltx_para ltx_noindent" id="S4.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px1.p1.1">In our exploration, we evaluated four Large Language Models (LLMs), including both open and closed-source models at the forefront of current technology.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.SSS0.Px1.p2">
<p class="ltx_p" id="S4.SS1.SSS0.Px1.p2.1">gpt-3.5-turbo-1106: This model represents OpenAI’s implementation of the Reinforcement Learning from Human Feedback (RLHF) technique <cite class="ltx_cite ltx_citemacro_cite">Ouyang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib45" title="">2022</a>)</cite>, showcasing remarkable capabilities. Access to this closed-source language model is facilitated through OpenAI’s official API.
Alpaca: Developed from the LLaMA model <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_ref ltx_missing_citation ltx_ref_self">touvron2023llama1</span></cite>, Alpaca is an open-source model refined to follow instructions. It has been enhanced with a dataset comprising 52,000 Self-Instruct examples <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_ref ltx_missing_citation ltx_ref_self">selfinstruct</span></cite>, showcasing its adaptability to diverse tasks.
Mixtral: The Mixtral-8x7B-Instruct variant, based on the Mixtral-8x7B architecture <cite class="ltx_cite ltx_citemacro_cite">mix (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib46" title="">2023</a>)</cite>, stands out for its instruction-following prowess and creative output capabilities. Available for public use, this model is adept at generating text across different formats, language translation, answering questions, and creating varied forms of creative content.
Palm2: Google’s PaLM 2 model is distinguished by its advanced language understanding and reasoning capabilities. Excelling in complex tasks involving code, mathematics, and multilingual translation, PaLM 2 leverages its substantial size and innovative techniques to achieve superior performance.
For our experimentation with Alpaca, specifically the 7B model variant, inference was executed on a single NVIDIA V100 32GB GPU.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">Comparative Methods</h5>
<div class="ltx_para ltx_noindent" id="S4.SS1.SSS0.Px2.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px2.p1.1">In the context of our code generation endeavor, we confined our methodology to the single-candidate approach. This decision was informed by our framework’s reliance on a sequential response mechanism, necessitating the focus on only the initial candidate response.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.SSS0.Px2.p2">
<p class="ltx_p" id="S4.SS1.SSS0.Px2.p2.1">Within single candidate method, we consider:</p>
<ul class="ltx_itemize" id="S4.I1">
<li class="ltx_item" id="S4.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i1.p1">
<p class="ltx_p" id="S4.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i1.p1.1.1">Baseline</span>: Zero-shot smart contract translation with temperature set to 0 (default for remainder of experiments in this paper).</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S4.I1.i2.p1">
<p class="ltx_p" id="S4.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i2.p1.1.1">5-Shot</span>  <cite class="ltx_cite ltx_citemacro_cite">Hendy et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib47" title="">2023</a>)</cite>: Prompting the model with five exemplars of superior quality, specifically selected from the sub-task domain and prepended to the test input, has been demonstrated to yield optimal overall performance, as per  <cite class="ltx_cite ltx_citemacro_cite">Hendy et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib47" title="">2023</a>)</cite>. Further augmenting the number of examples, however, does not appear to produce any appreciable enhancement in outcomes.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px3">
<h5 class="ltx_title ltx_title_paragraph">Metrics and Benchmark</h5>
<div class="ltx_para ltx_noindent" id="S4.SS1.SSS0.Px3.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px3.p1.1">In our exploration of code translation challenges for the notably resource-scarce language Move, we encountered the absence of pre-existing benchmarks suitable for code generation or testing evaluations. This limitation is compounded by the distinctive nature of Move smart contracts, which complicates the creation of a segregated evaluation dataset for training and testing purposes. Additionally, the specific requirements of a Code Translation Task, as opposed to straightforward code generation, render it impractical to rely solely on public code repositories like GitHub for the procurement of precise code examples for comparative analysis.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.SSS0.Px3.p2">
<p class="ltx_p" id="S4.SS1.SSS0.Px3.p2.1">Given these constraints, we have adopted a set of evaluation criteria tailored to the unique context of our study:</p>
<ul class="ltx_itemize" id="S4.I2">
<li class="ltx_item" id="S4.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i1.p1">
<p class="ltx_p" id="S4.I2.i1.p1.1">Code Compilability of the translated smart contract</p>
</div>
</li>
<li class="ltx_item" id="S4.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I2.i2.p1">
<p class="ltx_p" id="S4.I2.i2.p1.1">Code Correctness of the translated smart contract</p>
</div>
</li>
<li class="ltx_item" id="S4.I2.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S4.I2.i3.p1">
<p class="ltx_p" id="S4.I2.i3.p1.1">Bug mitigation of first candidate translation
</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.SSS0.Px3.p3">
<p class="ltx_p" id="S4.SS1.SSS0.Px3.p3.1">Based on this we evaluate the effectiveness of our approach.</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Results</h2>
<div class="ltx_para ltx_noindent" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">We have run the experiments on all four LLMs defined in Section <a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#S4" title="4 Experiments ‣ Teaching Machines to Code: Smart Contract Translation with LLMs"><span class="ltx_text ltx_ref_tag">4</span></a>. However, both Palm2 and Mixtral did not produce any tangible output for any of our candidate translations as we can see from Table <a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#S5.T1" title="Table 1 ‣ 5 Results ‣ Teaching Machines to Code: Smart Contract Translation with LLMs"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<figure class="ltx_table" id="S5.T1">
<div class="ltx_inline-block ltx_transformed_outer" id="S5.T1.1" style="width:433.6pt;height:102.4pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-11.9pt,2.8pt) scale(0.947859034248274,0.947859034248274) ;">
<table class="ltx_tabular ltx_align_middle" id="S5.T1.1.1">
<tr class="ltx_tr" id="S5.T1.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_tt" id="S5.T1.1.1.1.1">LLMs</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="S5.T1.1.1.1.2">Compilable Code?</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="S5.T1.1.1.1.3">Performance</td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.1.2">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S5.T1.1.1.2.1">gpt-3.5-turbo-1106</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T1.1.1.2.2">Y</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T1.1.1.2.3">Mixed</td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.1.3">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S5.T1.1.1.3.1">Solmover (Two LLM Combined)</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T1.1.1.3.2">Y</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T1.1.1.3.3">Mixed</td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.1.4">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S5.T1.1.1.4.1">Mixtral-8x7B-Instruct</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T1.1.1.4.2">N</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T1.1.1.4.3">Mixes different languages and generate unusable code</td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.1.5">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S5.T1.1.1.5.1">LLama2</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T1.1.1.5.2">N</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T1.1.1.5.3">Mixes different languages and generate unusable code</td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.1.6">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_l ltx_border_r ltx_border_t" id="S5.T1.1.1.6.1">Palm2</td>
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t" id="S5.T1.1.1.6.2">N</td>
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t" id="S5.T1.1.1.6.3">For Move only generates code snippets and plan</td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>Code Translation Capability of Four LLMs.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S5.p2">
<p class="ltx_p" id="S5.p2.1">Henceforth we will only report the results found in our SolMover framework and gpt-3.5-turbo-1106.
</p>
</div>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Successful Smart Contract Translation</h3>
<div class="ltx_para ltx_noindent" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">We ran a total of 734 Solidity contracts from our collected dataset in Section <a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#S2.SS5" title="2.5 Dataset for Solidity as Input Candidate ‣ 2 SolMover ‣ Teaching Machines to Code: Smart Contract Translation with LLMs"><span class="ltx_text ltx_ref_tag">2.5</span></a> through both gpt-3.5-turbo-1106 and SolMover. Each model was allocated an identical quantity of tasks totaling 734. The performance is evaluated based on successful compilation (SC), improvements post-error feedback, and further enhancements after Move Prover feedback. The results are detailed in Table <a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#S5.T2" title="Table 2 ‣ 5.1 Successful Smart Contract Translation ‣ 5 Results ‣ Teaching Machines to Code: Smart Contract Translation with LLMs"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<figure class="ltx_table" id="S5.T2">
<div class="ltx_inline-block ltx_transformed_outer" id="S5.T2.1" style="width:433.6pt;height:38.3pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-89.3pt,7.9pt) scale(0.708367359671873,0.708367359671873) ;">
<table class="ltx_tabular ltx_align_middle" id="S5.T2.1.1">
<tr class="ltx_tr" id="S5.T2.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_tt" id="S5.T2.1.1.1.1">LLM</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="S5.T2.1.1.1.2">Total Translation Task</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="S5.T2.1.1.1.3">Successful Compilation(SC)</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="S5.T2.1.1.1.4">SC After Error Feedback</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="S5.T2.1.1.1.5">SC after Move Prover Feedback</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.2">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S5.T2.1.1.2.1"><span class="ltx_text" id="S5.T2.1.1.2.1.1" style="color:#353740;">gpt-3.5-turbo-1106</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T2.1.1.2.2">734</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T2.1.1.2.3">204</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T2.1.1.2.4">229</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T2.1.1.2.5">229</td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.3">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_l ltx_border_r ltx_border_t" id="S5.T2.1.1.3.1">Solmover (Two LLM Combined)</td>
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t" id="S5.T2.1.1.3.2">734</td>
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t" id="S5.T2.1.1.3.3">313</td>
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t" id="S5.T2.1.1.3.4">397</td>
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t" id="S5.T2.1.1.3.5">401</td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span>Successful Translations.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S5.SS1.p2">
<p class="ltx_p" id="S5.SS1.p2.1">As we can see from Figure <a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#S5.F3" title="Figure 3 ‣ 5.1 Successful Smart Contract Translation ‣ 5 Results ‣ Teaching Machines to Code: Smart Contract Translation with LLMs"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS1.p3">
<ul class="ltx_itemize" id="S5.I1">
<li class="ltx_item" id="S5.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I1.i1.p1">
<p class="ltx_p" id="S5.I1.i1.p1.1">Initial SC rates were 204 for <span class="ltx_text ltx_font_typewriter" id="S5.I1.i1.p1.1.1">gpt-3.5-turbo-1106</span> and 313 for <span class="ltx_text ltx_font_typewriter" id="S5.I1.i1.p1.1.2">Solmover</span>.</p>
</div>
</li>
<li class="ltx_item" id="S5.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I1.i2.p1">
<p class="ltx_p" id="S5.I1.i2.p1.1">Post error feedback, SC rates improved to 229 for <span class="ltx_text ltx_font_typewriter" id="S5.I1.i2.p1.1.1">gpt-3.5-turbo-1106</span> and significantly to 397 for <span class="ltx_text ltx_font_typewriter" id="S5.I1.i2.p1.1.2">Solmover</span>.</p>
</div>
</li>
<li class="ltx_item" id="S5.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S5.I1.i3.p1">
<p class="ltx_p" id="S5.I1.i3.p1.1">Subsequent to Move Prover feedback, <span class="ltx_text ltx_font_typewriter" id="S5.I1.i3.p1.1.1">gpt-3.5-turbo-1106</span> remained static at 229 SCs, whereas <span class="ltx_text ltx_font_typewriter" id="S5.I1.i3.p1.1.2">Solmover</span> exhibited a marginal increase to 401 SCs.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS1.p4">
<p class="ltx_p" id="S5.SS1.p4.1">In this comparative analysis, the combined language model <span class="ltx_text ltx_font_typewriter" id="S5.SS1.p4.1.1">Solmover</span> exhibited superior performance over <span class="ltx_text ltx_font_typewriter" id="S5.SS1.p4.1.2">gpt-3.5-turbo-1106</span> in a translation task involving 734 items. <span class="ltx_text ltx_font_typewriter" id="S5.SS1.p4.1.3">Solmover</span> outperformed in successful compilations initially, after error feedback, and after Move Prover feedback, with the latter showing no improvement at the final stage. This indicates that the integration of two language models in <span class="ltx_text ltx_font_typewriter" id="S5.SS1.p4.1.4">Solmover</span> significantly enhances its ability to learn from feedback and improve its output, making it more adept at handling complex code translation tasks.</p>
</div>
<figure class="ltx_figure" id="S5.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="360" id="S5.F3.g1" src="extracted/5469016/figs/Figure-1_chart.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Successful Translations.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Reducing Bugs using Iterative Error Feedback</h3>
<div class="ltx_para ltx_noindent" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">As we described in Section <a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#S2.SS4" title="2.4 Sol-Mover Code Generator ‣ 2 SolMover ‣ Teaching Machines to Code: Smart Contract Translation with LLMs"><span class="ltx_text ltx_ref_tag">2.4</span></a> we try to mitigate bugs introduced by the LLMs for code generation by iterative prompting with error code as a guide. This compiler error-based prompting iterative loop runs at a maximum of five times before marking the translation case as unsuccessful. We run this experiment on both of the LLMs to decouple the concept mining part from the bug mitigation part, and to see if just iterative prompting alone can help achieve better performance on state-of-the-art commercial LLMs too. We report the result in the Table <a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#S5.T3" title="Table 3 ‣ 5.2 Reducing Bugs using Iterative Error Feedback ‣ 5 Results ‣ Teaching Machines to Code: Smart Contract Translation with LLMs"><span class="ltx_text ltx_ref_tag">3</span></a>. The focus here is on incomplete translations (IC) before and after error feedback is applied.</p>
</div>
<figure class="ltx_table" id="S5.T3">
<div class="ltx_inline-block ltx_transformed_outer" id="S5.T3.1" style="width:433.6pt;height:49.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-19.8pt,2.3pt) scale(0.916473418880725,0.916473418880725) ;">
<table class="ltx_tabular ltx_align_middle" id="S5.T3.1.1">
<tr class="ltx_tr" id="S5.T3.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_tt" id="S5.T3.1.1.1.1">LLM</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="S5.T3.1.1.1.2">Total Translation Task</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="S5.T3.1.1.1.3">Incomplete Translation (IC)</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="S5.T3.1.1.1.4">IC After Error Feedback</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.2">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S5.T3.1.1.2.1"><span class="ltx_text" id="S5.T3.1.1.2.1.1" style="color:#353740;">gpt-3.5-turbo-1106</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T3.1.1.2.2">734</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T3.1.1.2.3">187</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T3.1.1.2.4">110</td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.1.3">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_l ltx_border_r ltx_border_t" id="S5.T3.1.1.3.1">Solmover (Two LLM Combined)</td>
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t" id="S5.T3.1.1.3.2">734</td>
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t" id="S5.T3.1.1.3.3">201</td>
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t" id="S5.T3.1.1.3.4">134</td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span>Bug Mitigation.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S5.SS2.p2">
<p class="ltx_p" id="S5.SS2.p2.1">Here we first log the incomplete translations without any kind of compiler feedback. Then we log how both compiler feedback and move provers feedback affect the LLM’s bug mitigation capabilities.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS2.p3">
<p class="ltx_p" id="S5.SS2.p3.1">As we can see from Figure <a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#S5.F4" title="Figure 4 ‣ 5.2 Reducing Bugs using Iterative Error Feedback ‣ 5 Results ‣ Teaching Machines to Code: Smart Contract Translation with LLMs"><span class="ltx_text ltx_ref_tag">4</span></a> the results indicate that both models benefited from error feedback, with <span class="ltx_text ltx_font_typewriter" id="S5.SS2.p3.1.1">gpt-3.5-turbo-1106</span> showing a more substantial reduction in Incomplete Completions. Producing more compilable code after the feedback loop. Despite <span class="ltx_text ltx_font_typewriter" id="S5.SS2.p3.1.2">Solmover</span> starting with more Incomplete Completions(ICs), it did not reduce its ICs as effectively as <span class="ltx_text ltx_font_typewriter" id="S5.SS2.p3.1.3">gpt-3.5-turbo-1106</span> post-feedback.</p>
</div>
<figure class="ltx_figure" id="S5.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="360" id="S5.F4.g1" src="extracted/5469016/figs/Fig2_chart.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Bug Mitigation.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S5.SS2.p4">
<p class="ltx_p" id="S5.SS2.p4.1">In the comparison of incomplete translations for two language models, <span class="ltx_text ltx_font_typewriter" id="S5.SS2.p4.1.1">gpt-3.5-turbo-1106</span> and <span class="ltx_text ltx_font_typewriter" id="S5.SS2.p4.1.2">Solmover (Two LLM Combined)</span>, both began with a similar number of tasks. <span class="ltx_text ltx_font_typewriter" id="S5.SS2.p4.1.3">gpt-3.5-turbo-1106</span> initially reported fewer incomplete translations and also showed greater improvement after receiving error feedback. This suggests that while <span class="ltx_text ltx_font_typewriter" id="S5.SS2.p4.1.4">Solmover</span> had a higher starting point of incomplete tasks, it was less responsive to feedback in reducing these errors compared to <span class="ltx_text ltx_font_typewriter" id="S5.SS2.p4.1.5">gpt-3.5-turbo-1106</span>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS2.p5">
<ul class="ltx_itemize" id="S5.I2">
<li class="ltx_item" id="S5.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I2.i1.p1">
<p class="ltx_p" id="S5.I2.i1.p1.1">Pre-feedback, <span class="ltx_text ltx_font_typewriter" id="S5.I2.i1.p1.1.1">gpt-3.5-turbo-1106</span> had 187 ICs, while <span class="ltx_text ltx_font_typewriter" id="S5.I2.i1.p1.1.2">Solmover</span> had slightly more with 201 ICs.</p>
</div>
</li>
<li class="ltx_item" id="S5.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S5.I2.i2.p1">
<p class="ltx_p" id="S5.I2.i2.p1.1">Post-error feedback, ICs reduced to 110 for <span class="ltx_text ltx_font_typewriter" id="S5.I2.i2.p1.1.1">gpt-3.5-turbo-1106</span> and to 134 for <span class="ltx_text ltx_font_typewriter" id="S5.I2.i2.p1.1.2">Solmover</span>.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Correctness</h3>
<div class="ltx_para ltx_noindent" id="S5.SS3.p1">
<p class="ltx_p" id="S5.SS3.p1.1">The evaluation of code correctness in our study leverages the capabilities of the Move Prover, a theorem prover specifically designed for the Move programming language. The criterion for determining the safety of a contract hinges on whether the Move Prover can successfully verify the contract without encountering any errors. Contracts that are verifiable by the Move Prover are classified as safe. Conversely, if the Move Prover identifies errors, rendering it unable to prove the contract’s correctness, such contracts are categorized under the status of correctness not proved.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS3.p2">
<p class="ltx_p" id="S5.SS3.p2.1">To further refine our understanding of code correctness and its implications across different compilers, we employ a similar iterative methodology as used in the compilation error feedback loop. This approach enables us to assess the impact of iterative feedback on the performance of various compilers in terms of enhancing the correctness of the translated code.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS3.p3">
<p class="ltx_p" id="S5.SS3.p3.1">The outcomes of this comprehensive evaluation process, focusing on the correctness of translated Move contracts and their verification status as assessed by the Move Prover, are meticulously compiled and presented in Table <a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#S5.F5" title="Figure 5 ‣ 5.3 Correctness ‣ 5 Results ‣ Teaching Machines to Code: Smart Contract Translation with LLMs"><span class="ltx_text ltx_ref_tag">5</span></a>. This systematic analysis aims to shed light on the effectiveness of our code translation framework in producing functionally accurate and provably safe smart contracts within the Move ecosystem.
</p>
</div>
<figure class="ltx_table" id="S5.T4">
<div class="ltx_inline-block ltx_transformed_outer" id="S5.T4.1" style="width:433.6pt;height:45.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-39.2pt,4.1pt) scale(0.846912538565626,0.846912538565626) ;">
<table class="ltx_tabular ltx_align_middle" id="S5.T4.1.1">
<tr class="ltx_tr" id="S5.T4.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_tt" id="S5.T4.1.1.1.1">LLM</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="S5.T4.1.1.1.2">Successful Compilation(SC)</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="S5.T4.1.1.1.3">SC After Error Feedback</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="S5.T4.1.1.1.4">SC after Move Prover Feedback</td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.1.2">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" id="S5.T4.1.1.2.1"><span class="ltx_text" id="S5.T4.1.1.2.1.1" style="color:#353740;">gpt-3.5-turbo-1106</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T4.1.1.2.2">204</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T4.1.1.2.3">229</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S5.T4.1.1.2.4">229</td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.1.3">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_l ltx_border_r ltx_border_t" id="S5.T4.1.1.3.1">Solmover (Two LLM Combined)</td>
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t" id="S5.T4.1.1.3.2">313</td>
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t" id="S5.T4.1.1.3.3">397</td>
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t" id="S5.T4.1.1.3.4">401</td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4: </span>Contract Correctness.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S5.SS3.p4">
<p class="ltx_p" id="S5.SS3.p4.1">As we can see from Figure <a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#S5.F5" title="Figure 5 ‣ 5.3 Correctness ‣ 5 Results ‣ Teaching Machines to Code: Smart Contract Translation with LLMs"><span class="ltx_text ltx_ref_tag">5</span></a> that <span class="ltx_text ltx_font_typewriter" id="S5.SS3.p4.1.1">Solmover</span> not only had a higher success rate in initial compilations but also showed greater improvement upon receiving feedback. Moreover, it continued to improve even after the Move Prover feedback, in contrast to the <span class="ltx_text ltx_font_typewriter" id="S5.SS3.p4.1.2">gpt-3.5-turbo-1106</span>, which plateaued.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS3.p5">
<ul class="ltx_itemize" id="S5.I3">
<li class="ltx_item" id="S5.I3.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S5.I3.i1.p1">
<p class="ltx_p" id="S5.I3.i1.p1.1">The <span class="ltx_text ltx_font_typewriter" id="S5.I3.i1.p1.1.1">gpt-3.5-turbo-1106</span> had a baseline SC of 204, which increased to 229 after error feedback and remained unchanged after Move Prover feedback.</p>
</div>
</li>
<li class="ltx_item" id="S5.I3.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S5.I3.i2.p1">
<p class="ltx_p" id="S5.I3.i2.p1.1">The <span class="ltx_text ltx_font_typewriter" id="S5.I3.i2.p1.1.1">Solmover</span> model, on the other hand, started with a higher SC of 313, which then improved to 397 after error feedback and slightly increased to 401 after Move Prover feedback.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS3.p6">
<p class="ltx_p" id="S5.SS3.p6.1">The comparative assessment of <span class="ltx_text ltx_font_typewriter" id="S5.SS3.p6.1.1">gpt-3.5-turbo-1106</span> and <span class="ltx_text ltx_font_typewriter" id="S5.SS3.p6.1.2">Solmover (Two LLM Combined)</span> reveals that the latter outperforms the former in all stages of code compilation. Initially, <span class="ltx_text ltx_font_typewriter" id="S5.SS3.p6.1.3">Solmover</span> starts with a higher number of successful compilations. It continues to improve significantly upon receiving error feedback and demonstrates a modest increase even after Move Prover feedback, suggesting a robust ability to learn and adapt. In contrast, <span class="ltx_text ltx_font_typewriter" id="S5.SS3.p6.1.4">gpt-3.5-turbo-1106</span> exhibits improvement after error feedback but shows no further enhancement post Move Prover feedback, indicating a potential limit to its adaptability.</p>
</div>
<figure class="ltx_figure" id="S5.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="360" id="S5.F5.g1" src="extracted/5469016/figs/Picture1.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Contract Correctness.</figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Discussion &amp; Analysis</h2>
<div class="ltx_para ltx_noindent" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">In this section, we conduct analyses to understand the SolMover framework. We try to answer the research question (RQ) we started with and analyze the results reported.</p>
</div>
<section class="ltx_subsection" id="S6.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1 </span>Concept Distillation</h3>
<div class="ltx_para ltx_noindent" id="S6.SS1.p1">
<p class="ltx_p" id="S6.SS1.p1.1">A distinctive feature of our framework is the implementation of concept distillation via retrieval-augmented search methods. As illustrated in Figure <span class="ltx_ref ltx_missing_label ltx_ref_self">LABEL:fig:conceptdist</span>, our search methodology is adept at generating sub-tasks. A closer examination of the results presented in Figure 6, which addresses Contract Correctness, and Figure 5, focusing on Bug Mitigation, reveals the application of an iterative method to both the SolMover and the gpt-3.5-turbo-1106 model. Notably, the enhancement in performance and the reduction in the generation of non-compilable code are predominantly observed within our framework. This observation prompted a deeper investigation into our code translation strategy, particularly the generation of code using sub-tasks and the formulation of these sub-tasks through Concept Distillation.</p>
</div>
<div class="ltx_para ltx_noindent" id="S6.SS1.p2">
<svg class="ltx_picture" height="123.03" id="S6.SS1.p2.pic1" overflow="visible" version="1.1" width="600"><g color="#000000" fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,123.03) matrix(1 0 0 -1 0 0)"><g fill="#404040" fill-opacity="1.000000"><path d="M 0 5.91 L 0 117.13 C 0 120.39 2.64 123.03 5.91 123.03 L 594.09 123.03 C 597.36 123.03 600 120.39 600 117.13 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.000000"><path d="M 1.97 5.91 L 1.97 117.13 C 1.97 119.3 3.73 121.07 5.91 121.07 L 594.09 121.07 C 596.27 121.07 598.03 119.3 598.03 117.13 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.000000" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject height="95.48" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69"><span class="ltx_inline-para ltx_minipage ltx_align_bottom" id="S6.SS1.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2" style="width:402.3pt;">
<span class="ltx_para ltx_noindent" id="S6.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1">
<span class="ltx_p" id="S6.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1"><span class="ltx_text ltx_font_bold" id="S6.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.1">RQ1 &amp; RQ2</span> <span class="ltx_text ltx_font_italic" id="S6.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.2">Are LLMs capable of learning coding concepts, and can these concepts facilitate the generation of detailed subtasks from a generalized prompt?</span></span>
</span>
<span class="ltx_para" id="S6.SS1.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.p2">
<span class="ltx_p" id="S6.SS1.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.p2.1">Empirical evidence indicates a notable improvement in successful code translations when the model is prompted by sub-tasks derived from concepts. This leads to the conclusion that LLMs are capable of encoding associations that resemble concepts. However, we prefer to refer to these associations not as "concepts" in the traditional sense, but as "context associations."</span>
</span></span></foreignobject></g></g></svg>
</div>
</section>
<section class="ltx_subsection" id="S6.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2 </span>Smart Contract Translation</h3>
<div class="ltx_para ltx_noindent" id="S6.SS2.p1">
<p class="ltx_p" id="S6.SS2.p1.1">A central aim of this study was to assess the feasibility of translating smart contract code from one language (Solidity) to another (Move), a task complicated by the scarcity of Move code available on GitHub for model training purposes. We also explored various strategies to enhance the quality of the translated code by minimizing bugs introduced by the LLM. The findings, depicted in Figure 4, affirm the potential for successful translation of smart contracts from Solidity to Move, surpassing the performance of existing methodologies.</p>
</div>
<div class="ltx_para ltx_noindent" id="S6.SS2.p2">
<svg class="ltx_picture" height="99.93" id="S6.SS2.p2.pic1" overflow="visible" version="1.1" width="600"><g color="#000000" fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,99.93) matrix(1 0 0 -1 0 0)"><g fill="#404040" fill-opacity="1.000000"><path d="M 0 5.91 L 0 94.03 C 0 97.29 2.64 99.93 5.91 99.93 L 594.09 99.93 C 597.36 99.93 600 97.29 600 94.03 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.000000"><path d="M 1.97 5.91 L 1.97 94.03 C 1.97 96.2 3.73 97.97 5.91 97.97 L 594.09 97.97 C 596.27 97.97 598.03 96.2 598.03 94.03 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.000000" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject height="72.38" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69"><span class="ltx_inline-para ltx_minipage ltx_align_bottom" id="S6.SS2.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2" style="width:402.3pt;">
<span class="ltx_para ltx_noindent" id="S6.SS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1">
<span class="ltx_p" id="S6.SS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1"><span class="ltx_text ltx_font_bold" id="S6.SS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.1">RQ3</span> <span class="ltx_text ltx_font_italic" id="S6.SS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.2">Is it possible for an LLM to generate code in a low-resource language it has not been explicitly trained on?</span>
</span>
</span>
<span class="ltx_para" id="S6.SS2.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.p2">
<span class="ltx_p" id="S6.SS2.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.p2.1">Yes. Our findings suggest that, even in the absence of specific training in a given language, an LLM is capable of translating smart contracts from a well-documented language to a low-resource one, utilizing sub-tasks and minimal fine-tuning as facilitative measures.</span>
</span></span></foreignobject></g></g></svg>
</div>
<div class="ltx_para ltx_noindent" id="S6.SS2.p3">
<p class="ltx_p" id="S6.SS2.p3.1">The incorporation of feedback from both the compiler and the prover into our iterative methodology contributes to a reduction in bugs and an enhancement in code correctness, as evidenced in Figures 6 and 5. Nevertheless, the improvement attributable to prover feedback appears to be minimal.</p>
</div>
<div class="ltx_para ltx_noindent" id="S6.SS2.p4">
<svg class="ltx_picture" height="86.98" id="S6.SS2.p4.pic1" overflow="visible" version="1.1" width="600"><g color="#000000" fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,86.98) matrix(1 0 0 -1 0 0)"><g fill="#404040" fill-opacity="1.000000"><path d="M 0 5.91 L 0 81.08 C 0 84.34 2.64 86.98 5.91 86.98 L 594.09 86.98 C 597.36 86.98 600 84.34 600 81.08 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.000000"><path d="M 1.97 5.91 L 1.97 81.08 C 1.97 83.25 3.73 85.01 5.91 85.01 L 594.09 85.01 C 596.27 85.01 598.03 83.25 598.03 81.08 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.000000" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject height="59.42" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69"><span class="ltx_inline-para ltx_minipage ltx_align_bottom" id="S6.SS2.p4.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2" style="width:402.3pt;">
<span class="ltx_para ltx_noindent" id="S6.SS2.p4.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1">
<span class="ltx_p" id="S6.SS2.p4.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1"><span class="ltx_text ltx_font_bold" id="S6.SS2.p4.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.1">RQ4</span> <span class="ltx_text ltx_font_italic" id="S6.SS2.p4.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.2">Does employing compiler feedback mitigate bugs?</span></span>
</span>
<span class="ltx_para" id="S6.SS2.p4.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.p2">
<span class="ltx_p" id="S6.SS2.p4.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.p2.1">Yes. The empirical data indicates that iterative prompting with compiler feedback effectively reduces the incidence of uncompilable code. This positive outcome is observable across both models, with a more pronounced effect within our framework.</span>
</span></span></foreignobject></g></g></svg>
</div>
</section>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Related Work</h2>
<div class="ltx_para ltx_noindent" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">The related work can be categorized broadly as just Code Transpilers and LLM based solutions.
<span class="ltx_text ltx_font_bold" id="S7.p1.1.1">Rule-based Transpilers.</span>
Rule-based transpilers serve as a conduit between different programming languages, akin to skilled interpreters. They operate on a set of predefined rules rather than conjecture, guaranteeing accurate and consistent code conversions. This method promotes collaboration and facilitates code reuse across languages, enabling straightforward transitions from Python to Java <cite class="ltx_cite ltx_citemacro_cite">py (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib48" title="">2</a>)</cite> and Java to Python <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib49" title="">Melhase et al. </a></cite>. Despite their precision and adaptability, rule-based transpilers are not without limitations. The establishment of conversion rules may necessitate a degree of programming acumen, and intricately featured language elements could require manual intervention for accurate translation.</p>
</div>
<div class="ltx_para ltx_noindent" id="S7.p2">
<p class="ltx_p" id="S7.p2.1"><span class="ltx_text ltx_font_bold" id="S7.p2.1.1">Statistical ML-based Transpilers.</span>
These transpilers harness machine learning to navigate the translation between programming languages. Diverging from rule-based strategies, statistical ML-based transpilers digest extensive corpora of parallel translations to discern patterns and correlations, aiding in the translation of novel code instances. Nguyen et al. <cite class="ltx_cite ltx_citemacro_cite">Nguyen et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib50" title="">2013</a>)</cite> and Karaivanov et al. <cite class="ltx_cite ltx_citemacro_cite">Karaivanov et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib51" title="">2014</a>)</cite> have contributed methodologies that blend phrase-based translation with an understanding of the grammatical structuring of the target language, augmented by custom rules. Aggarwal et al. <cite class="ltx_cite ltx_citemacro_cite">Aggarwal et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib52" title="">2015</a>)</cite> employed a similar strategy for transitioning from Python2 to Python3, leveraging sentence alignment techniques. Explorations into bidirectional transpilers, such as the one by Schultes <cite class="ltx_cite ltx_citemacro_cite">Schultes (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib53" title="">2021</a>)</cite> for Swift <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib54" title="">swi </a></cite> and Kotlin <cite class="ltx_cite ltx_citemacro_cite"><a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib55" title="">kot </a></cite>, and the CRustS transpiler by Ling et al. <cite class="ltx_cite ltx_citemacro_cite">Ling et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib56" title="">2022</a>)</cite>, which emphasizes reducing unsafe expressions in the resultant code, represent significant advancements in this domain.</p>
</div>
<div class="ltx_para ltx_noindent" id="S7.p3">
<p class="ltx_p" id="S7.p3.1"><span class="ltx_text ltx_font_bold" id="S7.p3.1.1">Transformer and Other ML-based Code Translation Tools.</span>
Transformer models have revolutionized the field of code translation, drawing from their success in natural language processing. The encoder-decoder structure, as introduced by Vaswani et al. <cite class="ltx_cite ltx_citemacro_cite">Vaswani et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib57" title="">2017</a>)</cite>, has profoundly influenced software engineering, inspiring the creation of specialized models for code translation. Variants such as CodeBERT <cite class="ltx_cite ltx_citemacro_cite">Feng et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib58" title="">2020</a>)</cite> and CodeGPT <cite class="ltx_cite ltx_citemacro_cite">Lu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib59" title="">2021</a>)</cite> have emerged, each with a focus either on code comprehension or the generation of coherent code in the target language. CodeT5 by Wang et al. <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib60" title="">2021</a>)</cite>, which integrates code semantics, and PLBART by Ahmad et al. <cite class="ltx_cite ltx_citemacro_cite">Ahmad et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib61" title="">2021</a>)</cite>, a unified model designed for versatility across programming and natural languages, exemplify the ongoing innovation in this space. Efforts are also directed towards integrating developer insights and experimenting with novel architectures, including tree-to-tree models for program translation as pioneered by Chen et al. <cite class="ltx_cite ltx_citemacro_cite">Chen et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib62" title="">2018</a>)</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S7.p4">
<p class="ltx_p" id="S7.p4.1"><span class="ltx_text ltx_font_bold" id="S7.p4.1.1">LLM-based Methods Using Compiler/unit testing.</span>
Unsupervised code translation techniques that capitalize on self-training and automated unit tests for verifying source-to-target code equivalence have been introduced by Roziere et al. <cite class="ltx_cite ltx_citemacro_cite">Roziere et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib63" title="">2022</a>)</cite>. Although these methods utilize unit tests for creating synthetic parallel datasets for model enhancement, such tests are not factored into the training loss calculation. Wang et al. <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib64" title="">2022</a>)</cite>’s approach, which incorporates reinforcement learning with compiler feedback for code generation, offers a unique perspective distinct from supervised learning paradigms. Further research by Pan et al. <cite class="ltx_cite ltx_citemacro_cite">Haugeland et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib65" title="">2021</a>)</cite> and Orlanski et al. <cite class="ltx_cite ltx_citemacro_cite">Orlanski et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.09740v1#bib.bib66" title="">2023</a>)</cite> delves into the impact of LLMs on code translation, particularly in the context of low-resource languages, highlighting both the potential and challenges in this evolving field.</p>
</div>
</section>
<section class="ltx_section" id="S8">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8 </span>Conclusion</h2>
<div class="ltx_para ltx_noindent" id="S8.p1">
<p class="ltx_p" id="S8.p1.1">In this study, we introduce SolMover, an innovative framework comprising two Large Language Models (LLMs) designed to leverage textbook knowledge. Specifically, one LLM is utilized to distill and generate granular subtasks for the other, which then undertakes the task of generating code based on these subtasks. Our research focuses on the code translation task, with a particular emphasis on "Move" — a target language characterized by its extremely limited resources — for the creation of smart contracts.</p>
</div>
<div class="ltx_para ltx_noindent" id="S8.p2">
<p class="ltx_p" id="S8.p2.1">The SolMover framework facilitates the translation of existing Solidity smart contracts into Move smart contracts, showcasing the feasibility of such translations even when the target language is significantly under-represented in training datasets. The contributions of our work are multifaceted:</p>
</div>
<div class="ltx_para ltx_noindent" id="S8.p3">
<ul class="ltx_itemize" id="S8.I1">
<li class="ltx_item" id="S8.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S8.I1.i1.p1">
<p class="ltx_p" id="S8.I1.i1.p1.1">We present a novel approach for encoding concepts within an LLM, illustrating how such encoded knowledge can assist in translating code into languages that the LLM was not explicitly trained on.</p>
</div>
</li>
<li class="ltx_item" id="S8.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S8.I1.i2.p1">
<p class="ltx_p" id="S8.I1.i2.p1.1">Our exploration into an iterative compiler error feedback loop demonstrates its effectiveness in identifying and rectifying bugs within the translated code, thereby enhancing the overall quality and reliability of the output.</p>
</div>
</li>
</ul>
<p class="ltx_p" id="S8.p3.1">Through these contributions, SolMover advances the field of code translation, particularly in scenarios involving low-resource target languages, by demonstrating that it is possible to bridge the gap between different programming languages for smart contract development using LLMs. This approach not only expands the potential applications of LLMs in software engineering but also opens up new avenues for research in automated code translation and bug mitigation strategies.</p>
</div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">Acknowledgement</h2>
<div class="ltx_para ltx_noindent" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">Part of this work was conducted with the generous grant support from Sui Foundation Academic Research Grant.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liang et al. [2022]</span>
<span class="ltx_bibblock">
Percy Liang, Rishi Bommasani, Tony Lee, Dimitris Tsipras, Dilara Soylu, Michihiro Yasunaga, Yian Zhang, Deepak Narayanan, Yuhuai Wu, Ananya Kumar, et al.

</span>
<span class="ltx_bibblock">Holistic evaluation of language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">ArXiv preprint</em>, abs/2211.09110, 2022.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2211.09110" title="">https://arxiv.org/abs/2211.09110</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bubeck et al. [2023]</span>
<span class="ltx_bibblock">
Sébastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, et al.

</span>
<span class="ltx_bibblock">Sparks of artificial general intelligence: Early experiments with gpt-4.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">ArXiv preprint</em>, abs/2303.12712, 2023.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2303.12712" title="">https://arxiv.org/abs/2303.12712</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al. [2023]</span>
<span class="ltx_bibblock">
Hao Wu, Wenxuan Wang, Yuxuan Wan, Wenxiang Jiao, and Michael R. Lyu.

</span>
<span class="ltx_bibblock">Chatgpt or grammarly? evaluating chatgpt on grammatical error correction benchmark.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">ArXiv preprint</em>, abs/2303.13648, 2023.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2303.13648" title="">https://arxiv.org/abs/2303.13648</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Moghaddam and Honey [2023]</span>
<span class="ltx_bibblock">
Shima Rahimi Moghaddam and Christopher J Honey.

</span>
<span class="ltx_bibblock">Boosting theory-of-mind performance in large language models via prompting.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">ArXiv preprint</em>, abs/2304.11490, 2023.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2304.11490" title="">https://arxiv.org/abs/2304.11490</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiao et al. [2023]</span>
<span class="ltx_bibblock">
Wenxiang Jiao, Wenxuan Wang, Jen tse Huang, Xing Wang, and Zhaopeng Tu.

</span>
<span class="ltx_bibblock">Is chatgpt a good translator? a preliminary study.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">ArXiv</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Agrawal et al. [2023]</span>
<span class="ltx_bibblock">
Sweta Agrawal, Chunting Zhou, Mike Lewis, Luke Zettlemoyer, and Marjan Ghazvininejad.

</span>
<span class="ltx_bibblock">In-context examples selection for machine translation.

</span>
<span class="ltx_bibblock">In Anna Rogers, Jordan Boyd-Graber, and Naoaki Okazaki, editors, <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">Findings of the Association for Computational Linguistics: ACL 2023</em>, pages 8857–8873, Toronto, Canada, 2023. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.findings-acl.564" title="">10.18653/v1/2023.findings-acl.564</a>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2023.findings-acl.564" title="">https://aclanthology.org/2023.findings-acl.564</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. [2023a]</span>
<span class="ltx_bibblock">
Biao Zhang, Barry Haddow, and Alexandra Birch.

</span>
<span class="ltx_bibblock">Prompting large language model for machine translation: A case study.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">ArXiv preprint</em>, abs/2301.07069, 2023a.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2301.07069" title="">https://arxiv.org/abs/2301.07069</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vilar et al. [2022]</span>
<span class="ltx_bibblock">
David Vilar, Markus Freitag, Colin Cherry, Jiaming Luo, Viresh Ratnakar, and George Foster.

</span>
<span class="ltx_bibblock">Prompting palm for translation: Assessing strategies and performance.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">ArXiv preprint</em>, abs/2211.09102, 2022.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2211.09102" title="">https://arxiv.org/abs/2211.09102</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lu et al. [2023]</span>
<span class="ltx_bibblock">
Hongyuan Lu, Haoyang Huang, Dongdong Zhang, Haoran Yang, Wai Lam, and Furu Wei.

</span>
<span class="ltx_bibblock">Chain-of-dictionary prompting elicits translation in large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">ArXiv preprint</em>, abs/2305.06575, 2023.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2305.06575" title="">https://arxiv.org/abs/2305.06575</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bar-Hillel [1960]</span>
<span class="ltx_bibblock">
Yehoshua Bar-Hillel.

</span>
<span class="ltx_bibblock">A demonstration of the nonfeasibility of fully automatic high quality translation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">Advances in computers</em>, 1:158–163, 1960.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Macklovitch [1995]</span>
<span class="ltx_bibblock">
Elliott Macklovitch.

</span>
<span class="ltx_bibblock">The future of mt is now and bar-hillel was (almost entirely) right.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">Proceedings of the Fourth Bar-Ilan Symposium on the Foundations of Artificial Intelligence. url: http://rali. iro. umontreal. ca/Publications/urls/bisfai95. ps</em>, 1995.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Benson [2021]</span>
<span class="ltx_bibblock">
Jeff Benson.

</span>
<span class="ltx_bibblock">Uniswap trading volume exploded by 450% to $7 billion. here’s why, 2021.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://decrypt.co/63280/uniswap-trading-volume-exploded-7-billion-heres-why" title="">https://decrypt.co/63280/uniswap-trading-volume-exploded-7-billion-heres-why</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rabimba et al. [2022]</span>
<span class="ltx_bibblock">
Karanjai Rabimba, Lei Xu, Lin Chen, Fengwei Zhang, Zhimin Gao, and Weidong Shi.

</span>
<span class="ltx_bibblock">Lessons learned from blockchain applications of trusted execution environments and implications for future research.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">Workshop on Hardware and Architectural Support for Security and Privacy</em>, HASP ’21, New York, NY, USA, 2022. Association for Computing Machinery.

</span>
<span class="ltx_bibblock">ISBN 9781450396141.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.1145/3505253.3505259" title="">10.1145/3505253.3505259</a>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3505253.3505259" title="">https://doi.org/10.1145/3505253.3505259</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Karanjai et al. [2023a]</span>
<span class="ltx_bibblock">
Rabimba Karanjai, Lei Xu, Nour Diallo, Lin Chen, and Weidong Shi.

</span>
<span class="ltx_bibblock">Defaas: Decentralized function-as-a-service for emerging dapps and web3.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">2023 IEEE International Conference on Blockchain and Cryptocurrency (ICBC)</em>, pages 1–3, 2023a.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.1109/ICBC56567.2023.10174945" title="">10.1109/ICBC56567.2023.10174945</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Karanjai et al. [2023b]</span>
<span class="ltx_bibblock">
Rabimba Karanjai, Edward Li, Lei Xu, and Weidong Shi.

</span>
<span class="ltx_bibblock">Who is smarter? an empirical study of ai-based smart contract creation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">2023 5th Conference on Blockchain Research &amp; Applications for Innovative Networks and Services (BRAINS)</em>, pages 1–8, 2023b.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.1109/BRAINS59668.2023.10316829" title="">10.1109/BRAINS59668.2023.10316829</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhong et al. [2020]</span>
<span class="ltx_bibblock">
Jingyi Emma Zhong, Kevin Cheang, Shaz Qadeer, Wolfgang Grieskamp, Sam Blackshear, Junkil Park, Yoni Zohar, Clark Barrett, and David L. Dill.

</span>
<span class="ltx_bibblock">The move prover.

</span>
<span class="ltx_bibblock">In Shuvendu K. Lahiri and Chao Wang, editors, <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">Computer Aided Verification</em>, pages 137–150, Cham, 2020. Springer International Publishing.

</span>
<span class="ltx_bibblock">ISBN 978-3-030-53288-8.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Karanjai et al. [2023c]</span>
<span class="ltx_bibblock">
Rabimba Karanjai, Edward Li, Lei Xu, and Weidong Shi.

</span>
<span class="ltx_bibblock">Who is smarter? an empirical study of ai-based smart contract creation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">2023 5th Conference on Blockchain Research &amp; Applications for Innovative Networks and Services (BRAINS)</em>, pages 1–8. IEEE, 2023c.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gile [2009]</span>
<span class="ltx_bibblock">
Daniel Gile.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">Basic concepts and models for interpreter and translator training</em>.

</span>
<span class="ltx_bibblock">Number 8 in Benjamins Translation Library. John Benjamins, Amsterdam, 2009.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gunasekar et al. [2023]</span>
<span class="ltx_bibblock">
Suriya Gunasekar, Yi Zhang, Jyoti Aneja, Caio César Teodoro Mendes, Allie Del Giorno, Sivakanth Gopi, Mojan Javaheripi, Piero Kauffmann, Gustavo de Rosa, Olli Saarikivi, et al.

</span>
<span class="ltx_bibblock">Textbooks are all you need.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">arXiv preprint arXiv:2306.11644</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. [2023b]</span>
<span class="ltx_bibblock">
Jianyi Zhang, Aashiq Muhamed, Aditya Anantharaman, Guoyin Wang, Changyou Chen, Kai Zhong, Qingjun Cui, Yi Xu, Belinda Zeng, Trishul Chilimbi, et al.

</span>
<span class="ltx_bibblock">Reaugkd: Retrieval-augmented knowledge distillation for pre-trained language models.

</span>
<span class="ltx_bibblock">2023b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lu et al. [2022]</span>
<span class="ltx_bibblock">
Shuai Lu, Nan Duan, Hojae Han, Daya Guo, Seung-won Hwang, and Alexey Svyatkovskiy.

</span>
<span class="ltx_bibblock">Reacc: A retrieval-augmented code completion framework.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">arXiv preprint arXiv:2203.07722</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Int [2023]</span>
<span class="ltx_bibblock">
Introduction - the move book, 2023.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://move-language.github.io/move/" title="">https://move-language.github.io/move/</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">The [2022]</span>
<span class="ltx_bibblock">
The move language - the move book, 2022.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://move-book.com/" title="">https://move-book.com/</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">mov [2023a]</span>
<span class="ltx_bibblock">
Introduction - move patterns: Design patterns for resource based programming, 2023a.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.move-patterns.com/" title="">https://www.move-patterns.com/</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">mov [2023b]</span>
<span class="ltx_bibblock">
move · github, 2023b.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/move-language/move/tree/main/language/documentation/tutorial" title="">https://github.com/move-language/move/tree/main/language/documentation/tutorial</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sui [2023]</span>
<span class="ltx_bibblock">
Sui basics - sui move by example, 2023.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://examples.sui.io/basics/index.html" title="">https://examples.sui.io/basics/index.html</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">hfc [2023]</span>
<span class="ltx_bibblock">
hf-codegen, 2023.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/sayakpaul/hf-codegen/blob/main/data/prepare_dataset.py" title="">https://github.com/sayakpaul/hf-codegen/blob/main/data/prepare_dataset.py</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Karpukhin et al. [2020]</span>
<span class="ltx_bibblock">
Vladimir Karpukhin, Barlas Oğuz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih.

</span>
<span class="ltx_bibblock">Dense passage retrieval for open-domain question answering.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">arXiv preprint arXiv:2004.04906</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Robertson et al. [2009]</span>
<span class="ltx_bibblock">
Stephen Robertson, Hugo Zaragoza, et al.

</span>
<span class="ltx_bibblock">The probabilistic relevance framework: Bm25 and beyond.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">Foundations and Trends® in Information Retrieval</em>, 3(4):333–389, 2009.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Oord et al. [2018]</span>
<span class="ltx_bibblock">
Aaron van den Oord, Yazhe Li, and Oriol Vinyals.

</span>
<span class="ltx_bibblock">Representation learning with contrastive predictive coding.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">arXiv preprint arXiv:1807.03748</em>, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Taori et al. [2023]</span>
<span class="ltx_bibblock">
Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, and Tatsunori B. Hashimoto.

</span>
<span class="ltx_bibblock">Stanford alpaca: An instruction-following llama model.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/tatsu-lab/stanford_alpaca" title="">https://github.com/tatsu-lab/stanford_alpaca</a>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et al. [2023]</span>
<span class="ltx_bibblock">
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al.

</span>
<span class="ltx_bibblock">Llama: Open and efficient foundation language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">arXiv preprint arXiv:2302.13971</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">ShareGPT [2023]</span>
<span class="ltx_bibblock">
ShareGPT.

</span>
<span class="ltx_bibblock">Sharegpt: Share your wildest chatgpt conversations with one click., 2023.

</span>
<span class="ltx_bibblock">Available at: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://sharegpt.com/" title="">https://sharegpt.com/</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Urban [2004]</span>
<span class="ltx_bibblock">
Josef Urban.

</span>
<span class="ltx_bibblock">Mptp–motivation, implementation, first experiments.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">Journal of Automated Reasoning</em>, 33:319–339, 2004.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">fun [2023]</span>
<span class="ltx_bibblock">
fungible tokens, 2023.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/MystenLabs/sui/tree/main/sui_programmability/examples/fungible_tokens" title="">https://github.com/MystenLabs/sui/tree/main/sui_programmability/examples/fungible_tokens</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">bas [2023]</span>
<span class="ltx_bibblock">
move/language/documentation/examples/experimental/basic-coin at main · move-language/move · github, 2023.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/move-language/move/tree/main/language/documentation/examples/experimental/basic-coin" title="">https://github.com/move-language/move/tree/main/language/documentation/examples/experimental/basic-coin</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">die [2023]</span>
<span class="ltx_bibblock">
Diem, 2023.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/0LNetworkCommunity/libra-legacy-v6/blob/main/language/diem-framework/modules/Diem.move" title="">https://github.com/0LNetworkCommunity/libra-legacy-v6/blob/main/language/diem-framework/modules/Diem.move</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">tok [2023]</span>
<span class="ltx_bibblock">
Token, 2023.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/starcoinorg/starcoin-framework/blob/main/sources/Token.move" title="">https://github.com/starcoinorg/starcoin-framework/blob/main/sources/Token.move</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">gas [2023]</span>
<span class="ltx_bibblock">
Gas, 2023.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/0LNetworkCommunity/libra-legacy-v6/blob/main/language/diem-framework/modules/0L/GAS.move" title="">https://github.com/0LNetworkCommunity/libra-legacy-v6/blob/main/language/diem-framework/modules/0L/GAS.move</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">nft [2023]</span>
<span class="ltx_bibblock">
Nft, 2023.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/MystenLabs/sui/tree/main/sui_programmability/examples/nfts" title="">https://github.com/MystenLabs/sui/tree/main/sui_programmability/examples/nfts</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">mer [2023]</span>
<span class="ltx_bibblock">
starcoin-framework/sources/merklenft.move at main · starcoinorg/starcoin-framework · github, 2023.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/starcoinorg/starcoin-framework/blob/main/sources/MerkleNFT.move" title="">https://github.com/starcoinorg/starcoin-framework/blob/main/sources/MerkleNFT.move</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">def [2023]</span>
<span class="ltx_bibblock">
Defi, 2023.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/MystenLabs/sui/tree/main/sui_programmability/examples/defi" title="">https://github.com/MystenLabs/sui/tree/main/sui_programmability/examples/defi</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">coi [2023]</span>
<span class="ltx_bibblock">
move/language/documentation/examples/experimental/coin-swap at main · move-language/move · github, 2023.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/move-language/move/tree/main/language/documentation/examples/experimental/coin-swap" title="">https://github.com/move-language/move/tree/main/language/documentation/examples/experimental/coin-swap</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">sta [2023]</span>
<span class="ltx_bibblock">
Github - elements-studio/starswap-core: The swap project on starcoin such as uniswap a sushiswap, 2023.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/Elements-Studio/starswap-core" title="">https://github.com/Elements-Studio/starswap-core</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ouyang et al. [2022]</span>
<span class="ltx_bibblock">
Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al.

</span>
<span class="ltx_bibblock">Training language models to follow instructions with human feedback.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib45.1.1">Advances in Neural Information Processing Systems</em>, 35:27730–27744, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">mix [2023]</span>
<span class="ltx_bibblock">
Can you feel the moe? mixtral available with over 100 tokens per second through together platform!, 2023.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.together.ai/blog/mixtral" title="">https://www.together.ai/blog/mixtral</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hendy et al. [2023]</span>
<span class="ltx_bibblock">
Amr Hendy, Mohamed Abdelrehim, Amr Sharaf, Vikas Raunak, Mohamed Gabr, Hitokazu Matsushita, Young Jin Kim, Mohamed Afify, and Hany Hassan Awadalla.

</span>
<span class="ltx_bibblock">How good are gpt models at machine translation? a comprehensive evaluation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib47.1.1">ArXiv preprint</em>, abs/2302.09210, 2023.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2302.09210" title="">https://arxiv.org/abs/2302.09210</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">py [2]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_typewriter" id="bib.bib48.1.1">py2java</span>: Python to Java Language Translator.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://pypi.org/project/py2java/" title="">https://pypi.org/project/py2java/</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
Troy Melhase et al.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_typewriter" id="bib.bib49.1.1">java2python</span>: Simple but Effective Tool to Translate Java Source Code into Python.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/natural/java2python" title="">https://github.com/natural/java2python</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nguyen et al. [2013]</span>
<span class="ltx_bibblock">
Anh Tuan Nguyen, Tung Thanh Nguyen, and Tien N Nguyen.

</span>
<span class="ltx_bibblock">Lexical Statistical Machine Translation for Language Migration.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib50.1.1">Proceedings of the 9th Joint Meeting on Foundations of Software Engineering</em>, pages 651–654, 2013.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Karaivanov et al. [2014]</span>
<span class="ltx_bibblock">
Svetoslav Karaivanov, Veselin Raychev, and Martin Vechev.

</span>
<span class="ltx_bibblock">Phrase-based Statistical Translation of Programming Languages.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib51.1.1">Proceedings of the 2014 ACM International Symposium on New Ideas, New Paradigms, and Reflections on Programming &amp; Software</em>, pages 173–184, 2014.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Aggarwal et al. [2015]</span>
<span class="ltx_bibblock">
Karan Aggarwal, Mohammad Salameh, and Abram Hindle.

</span>
<span class="ltx_bibblock">Using Machine Translation for Converting Python 2 to Python 3 Code.

</span>
<span class="ltx_bibblock">Technical report, PeerJ PrePrints, 2015.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schultes [2021]</span>
<span class="ltx_bibblock">
Dominik Schultes.

</span>
<span class="ltx_bibblock">SequalsK – A Bidirectional Swift-Kotlin-Transpiler.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib53.1.1">2021 IEEE/ACM 8th International Conference on Mobile Software Engineering and Systems (MobileSoft)</em>, pages 73–83. IEEE, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock">
Swift: The Powerful Programming Language that is Also Easy to Learn.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://developer.apple.com/swift/" title="">https://developer.apple.com/swift/</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
Kotlin Programming Language: Concise. Cross<span class="ltx_text" id="bib.bib55.1.1">-</span>platform. Fun.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://kotlinlang.org/" title="">https://kotlinlang.org/</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ling et al. [2022]</span>
<span class="ltx_bibblock">
Michael Ling, Yijun Yu, Haitao Wu, Yuan Wang, James R Cordy, and Ahmed E Hassan.

</span>
<span class="ltx_bibblock">In Rust We Trust: A Transpiler from Unsafe C to Safer Rust.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib56.1.1">Proceedings of the ACM/IEEE 44th International Conference on Software Engineering: Companion Proceedings</em>, pages 354–355, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vaswani et al. [2017]</span>
<span class="ltx_bibblock">
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin.

</span>
<span class="ltx_bibblock">Attention Is All You Need.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib57.1.1">Advances in Neural Information Processing Systems (NeurIPS)</em>, 30, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Feng et al. [2020]</span>
<span class="ltx_bibblock">
Zhangyin Feng, Daya Guo, Duyu Tang, Nan Duan, Xiaocheng Feng, Ming Gong, Linjun Shou, Bing Qin, Ting Liu, Daxin Jiang, and Ming Zhou.

</span>
<span class="ltx_bibblock">CodeBERT: A Pre-Trained Model for Programming and Natural Languages.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib58.1.1">Findings of the Association for Computational Linguistics: EMNLP 2020</em>, pages 1536–1547, Online, November 2020. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2020.findings-emnlp.139" title="">10.18653/v1/2020.findings-emnlp.139</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lu et al. [2021]</span>
<span class="ltx_bibblock">
Shuai Lu, Daya Guo, Shuo Ren, Junjie Huang, Alexey Svyatkovskiy, Ambrosio Blanco, Colin Clement, Dawn Drain, Daxin Jiang, Duyu Tang, et al.

</span>
<span class="ltx_bibblock">CodeXGLUE: A Machine Learning Benchmark Dataset for Code Understanding and Generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib59.1.1">arXiv preprint arXiv:2102.04664</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib60">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. [2021]</span>
<span class="ltx_bibblock">
Yue Wang, Weishi Wang, Shafiq Joty, and Steven C.H. Hoi.

</span>
<span class="ltx_bibblock">CodeT5: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding and Generation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib60.1.1">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</em>, pages 8696–8708, Online and Punta Cana, Dominican Republic, 2021. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2021.emnlp-main.685" title="">10.18653/v1/2021.emnlp-main.685</a>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2021.emnlp-main.685" title="">https://aclanthology.org/2021.emnlp-main.685</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib61">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ahmad et al. [2021]</span>
<span class="ltx_bibblock">
Wasi Ahmad, Saikat Chakraborty, Baishakhi Ray, and Kai-Wei Chang.

</span>
<span class="ltx_bibblock">Unified Pre-training for Program Understanding and Generation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib61.1.1">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</em>, pages 2655–2668, Online, June 2021. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi:<a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2021.naacl-main.211" title="">10.18653/v1/2021.naacl-main.211</a>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2021.naacl-main.211" title="">https://aclanthology.org/2021.naacl-main.211</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib62">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. [2018]</span>
<span class="ltx_bibblock">
Xinyun Chen, Chang Liu, and Dawn Song.

</span>
<span class="ltx_bibblock">Tree-to-Tree Neural Networks for Program Translation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib62.1.1">Advances in Neural Information Processing Systems (NeurIPS)</em>, 31, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib63">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Roziere et al. [2022]</span>
<span class="ltx_bibblock">
Baptiste Roziere, Jie Zhang, Francois Charton, Mark Harman, Gabriel Synnaeve, and Guillaume Lample.

</span>
<span class="ltx_bibblock">TransCoder-ST: Leveraging Automated Unit Tests for Unsupervised Code Translation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib63.1.1">International Conference on Learning Representations (ICLR)</em>, 2022.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/forum?id=cmt-6KtR4c4" title="">https://openreview.net/forum?id=cmt-6KtR4c4</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib64">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. [2022]</span>
<span class="ltx_bibblock">
Xin Wang, Yasheng Wang, Yao Wan, Fei Mi, Yitong Li, Pingyi Zhou, Jin Liu, Hao Wu, Xin Jiang, and Qun Liu.

</span>
<span class="ltx_bibblock">Compilable Neural Code Generation with Compiler Feedback.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib64.1.1">Findings of the Association for Computational Linguistics: ACL 2022</em>, pages 9–19, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib65">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Haugeland et al. [2021]</span>
<span class="ltx_bibblock">
Sindre Grønstøl Haugeland, Phu H Nguyen, Hui Song, and Franck Chauvel.

</span>
<span class="ltx_bibblock">Migrating monoliths to microservices-based customizable multi-tenant cloud-native apps.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib65.1.1">2021 47th Euromicro Conference on Software Engineering and Advanced Applications (SEAA)</em>, pages 170–177. IEEE, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib66">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Orlanski et al. [2023]</span>
<span class="ltx_bibblock">
Gabriel Orlanski, Kefan Xiao, Xavier Garcia, Jeffrey Hui, Joshua Howland, Jonathan Malmaud, Jacob Austin, Rishabh Singh, and Michele Catasta.

</span>
<span class="ltx_bibblock">Measuring the impact of programming language distribution.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib66.1.1">International Conference on Machine Learning</em>, pages 26619–26645. PMLR, 2023.

</span>
</li>
</ul>
</section><div about="" class="ltx_rdf" content="Rabimba Karanjai" property="dcterms:creator"></div>
<div about="" class="ltx_rdf" content="Smart Contracts, Machine Learning, Machine Translation, Code Transpilation, LLM, Large Language Model" property="dcterms:subject"></div>
<div about="" class="ltx_rdf" content="Smart Contract LLM Translation" property="dcterms:subject"></div>
<div about="" class="ltx_rdf" content="SMART CONTRACT TRANSLATION WITH LLMS" property="dcterms:title"></div>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Wed Mar 13 18:54:03 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span style="font-size:70%;position:relative; bottom:2.2pt;">A</span>T<span style="position:relative; bottom:-0.4ex;">E</span></span><span class="ltx_font_smallcaps">xml</span><img alt="[LOGO]" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
