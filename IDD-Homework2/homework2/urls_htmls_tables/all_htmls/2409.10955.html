<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style</title>
<!--Generated on Tue Sep 17 07:39:09 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2409.10955v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#S1" title="In Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#S2" title="In Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#S2.SS1" title="In 2 Related Work ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Context Faithfulness of LLM</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#S2.SS2" title="In 2 Related Work ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Construction of Knowledge Conflicts</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#S3" title="In Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Methodology</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#S3.SS1" title="In 3 Methodology ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Problem Definition</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#S3.SS2" title="In 3 Methodology ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Datasets</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#S3.SS3" title="In 3 Methodology ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Memory Strength</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#S3.SS3.SSS1" title="In 3.3 Memory Strength ‣ 3 Methodology ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3.1 </span>Question Paraphrases and Answer Clustering</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#S3.SS3.SSS2" title="In 3.3 Memory Strength ‣ 3 Methodology ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3.2 </span>Calculating Memory Strength</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#S3.SS4" title="In 3 Methodology ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4 </span>MA, CMA, and Evidence Generation</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#S3.SS4.SSS1" title="In 3.4 MA, CMA, and Evidence Generation ‣ 3 Methodology ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4.1 </span>MA and CMA Generation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#S3.SS4.SSS2" title="In 3.4 MA, CMA, and Evidence Generation ‣ 3 Methodology ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4.2 </span>Evidence Generation</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#S4" title="In Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#S4.SS1" title="In 4 Experiments ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Experiment Setup</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#S4.SS2" title="In 4 Experiments ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Impact of Memory Strength</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#S4.SS2.SSS1" title="In 4.2 Impact of Memory Strength ‣ 4 Experiments ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.1 </span>Memory Strength on Different Datasets</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#S4.SS2.SSS2" title="In 4.2 Impact of Memory Strength ‣ 4 Experiments ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.2 </span>Context-Faithfulness with Memory Strength</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#S4.SS3" title="In 4 Experiments ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Impact of Evidence Style</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#S5" title="In Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#A1" title="In Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Additional Study</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#A1.SS1" title="In Appendix A Additional Study ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.1 </span>Order of Options</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#A1.SS2" title="In Appendix A Additional Study ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.2 </span>Case Study</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#A2" title="In Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B </span>Methodology and Experiment Details</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#A2.SS1" title="In Appendix B Methodology and Experiment Details ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.1 </span>CMA Generation for NQ dataset</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#A2.SS2" title="In Appendix B Methodology and Experiment Details ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.2 </span>Dataset Details</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#A2.SS3" title="In Appendix B Methodology and Experiment Details ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.3 </span>Human Evaluation for Model Reliability</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#A2.SS4" title="In Appendix B Methodology and Experiment Details ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.4 </span>Impact of Memory Strength with Different Evidence Styles</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#A3" title="In Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C </span>Prompts</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style </h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yuepei Li,   Kang Zhou,   Qiao Qiao,   Bach Nguyen,   Qing Wang,   Qi Li 
<br class="ltx_break"/>Department of Computer Science, Iowa State University, Ames, Iowa, USA 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id1.1.id1">{liyp0095, kangzhou, qqiao1, ntbach, qingwang, qli}@iastate.edu</span>
<br class="ltx_break"/>
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id2.id1">Retrieval-augmented generation (RAG) improves Large Language Models (LLMs) by incorporating external information into the response generation process. However, how context-faithful LLMs are and what factors influence LLMs’ context-faithfulness remain largely unexplored. In this study, we investigate the impact of memory strength and evidence presentation on LLMs’ receptiveness to external evidence. We introduce a method to quantify the memory strength of LLMs by measuring the divergence in LLMs’ responses to different paraphrases of the same question, which is not considered by previous works. We also generate evidence in various styles to evaluate the effects of evidence in different styles. Two datasets are used for evaluation: Natural Questions (NQ) with popular questions and popQA featuring long-tail questions. Our results show that for questions with high memory strength, LLMs are more likely to rely on internal memory, particularly for larger LLMs such as GPT-4. On the other hand, presenting paraphrased evidence significantly increases LLMs’ receptiveness compared to simple repetition or adding details.</p>
</div>
<div class="ltx_para ltx_noindent" id="p1">
<div class="ltx_block ltx_align_bottom" id="p1.1">
<p class="ltx_p" id="p1.1.1"><span class="ltx_text ltx_font_bold" id="p1.1.1.1">Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style</span></p>
<br class="ltx_break ltx_centering"/>
<p class="ltx_p ltx_align_center" id="p1.1.2" style="width:433.6pt;"><span class="ltx_text ltx_inline-block" id="p1.1.2.1" style="width:0.0pt;">
<span class="ltx_tabular ltx_align_top" id="p1.1.2.1.1">
<span class="ltx_tbody">
<span class="ltx_tr" id="p1.1.2.1.1.1.1">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="p1.1.2.1.1.1.1.1.1">Yuepei Li,   Kang Zhou,   Qiao Qiao,   Bach Nguyen,   Qing Wang,   Qi Li</span></span></span>
<span class="ltx_tr" id="p1.1.2.1.1.2.2">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.2.2.1">Department of Computer Science, Iowa State University, Ames, Iowa, USA</span></span>
<span class="ltx_tr" id="p1.1.2.1.1.3.3">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.3.3.1"><span class="ltx_text ltx_font_typewriter" id="p1.1.2.1.1.3.3.1.1">{liyp0095, kangzhou, qqiao1, ntbach, qingwang, qli}@iastate.edu</span></span></span>
</span>
</span></span></p>
<br class="ltx_break ltx_centering"/>
</div>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Retrieval-Augmented Generation (RAG) <cite class="ltx_cite ltx_citemacro_cite">Fan et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib3" title="">2024</a>); Zhao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib33" title="">2023</a>)</cite> has gained increasing popularity as it improves the performance of Large Language Models (LLMs) by integrating external information during the generation process, particularly when the model’s internal knowledge is insufficient or outdated <cite class="ltx_cite ltx_citemacro_cite">Bianchini et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib1" title="">2024</a>); Procko (<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib23" title="">2024</a>); Siriwardhana et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib26" title="">2023</a>); Vakayil et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib28" title="">2024</a>); Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib29" title="">2024</a>); Jeong (<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib6" title="">2023</a>)</cite>. It raises the importance of the study of how context-faithful LLMs are, as RAG relies on effectively incorporating retrieved external information into the generated responses to ensure accuracy and contextual relevance. In this study, we explore whether LLMs are context-faithful when encountering external information, particularly when that information conflicts with the LLMs’ internal memory.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">To investigate the issue of context-faithfulness, one approach <cite class="ltx_cite ltx_citemacro_cite">Longpre et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib16" title="">2021</a>); Chen et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib2" title="">2022</a>)</cite> is to create conflicts through entity substitution. <cite class="ltx_cite ltx_citemacro_citet">Longpre et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib16" title="">2021</a>)</cite> concluded that models frequently rely on their parametric knowledge, generating responses not found in the provided evidence. In contrast, <cite class="ltx_cite ltx_citemacro_citet">Chen et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib2" title="">2022</a>)</cite> found that LLMs rely almost exclusively on evidence passages rather than internal memory when multiple evidence passages are presented. Another approach <cite class="ltx_cite ltx_citemacro_cite">Xie et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib32" title="">2024</a>); Jin et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib7" title="">2024</a>)</cite> involves generating counter-memory evidence with LLMs, and these studies have shown that LLMs are generally receptive to external evidence as long as it is coherent.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">These methods, however, overlook some important aspects of the task. On one hand, LLMs have different memory strengths for different knowledge, and their behavior towards external evidence may vary significantly depending on how strongly it resistant to that knowledge. On the other hand, the characteristics of the evidence, such as evidence length, expressions, and detailed information involved, can influence how persuasive the evidence is. The behavior of LLMs is also expected to vary with evidence of different persuasiveness. Overlooking these factors could result in conflicting conclusions.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">To address these issues, we introduce a method to quantify the memory strength of LLMs. We also generate evidence in various styles to evaluate the different effects of evidence in different styles. Inspired by <cite class="ltx_cite ltx_citemacro_citet">Zhao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib34" title="">2024</a>)</cite>, we assess memory strength by measuring the divergence in LLMs’ responses to different paraphrases of the same question. Intuitively, an LLM demonstrates high memory strength when it consistently provides the same answer across all paraphrased versions of a question. For evidence style, We classify it into direct and indirect forms: direct evidence provides a straightforward answer to the question, while indirect evidence incorporates additional details to support the answer. Through these methods, we analyze the relationship between context-faithfulness and LLM memory strength, and we explore the impact of different evidence styles on context-faithfulness. Our conclusions are as follows:</p>
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">The receptiveness of LLMs to external evidence is strongly correlated with memory strength to the question. We observed this relationship both across different datasets and different LLMs. Contrary to the findings of <cite class="ltx_cite ltx_citemacro_cite">Xie et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib32" title="">2024</a>); Jin et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib7" title="">2024</a>)</cite> that LLMs are highly receptive (less than 5%) to external evidence when it is coherent, we find that the probability of the model relying on its parametric memory is non-negligible for questions that the LLMs have a strong memory. For example, GPT-4, which has strong memory on the NQ dataset, reaches almost 50% memory answer ratio when answering questions from the NQ dataset.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">The style of the evidence plays an important role in determining the LLM’s receptiveness to external information. Our research demonstrates that presenting the LLM with multiple paraphrases of the same evidence substantially increases its receptiveness. This approach outperforms simple repetition of the evidence and is more effective than adding additional details to the evidence. These findings provide valuable insights for work in research of RAG and context faithful, highlighting the importance of prioritizing LLM receptiveness in both model training and application.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Context Faithfulness of LLM</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">To update static factual knowledge <cite class="ltx_cite ltx_citemacro_cite">Lazaridou et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib14" title="">2021</a>); Karpukhin et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib8" title="">2020</a>); Kasai et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib9" title="">2023</a>)</cite> in LLMs, the retrieval-based method has been introduced to involve external information to LLMs <cite class="ltx_cite ltx_citemacro_cite">Lazaridou et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib13" title="">2022</a>); Izacard et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib5" title="">2024</a>); Khattab et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib11" title="">2022</a>); Santhanam et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib24" title="">2022</a>); Gao and Callan (<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib4" title="">2022</a>)</cite>. However, these methods can introduce <span class="ltx_text ltx_font_bold" id="S2.SS1.p1.1.1">knowledge conflicts</span> between the introduced context and pre-existing memories from LLMs. LLMs often persist in relying on their pre-existing memories, overlooking newly provided contextual evidence <cite class="ltx_cite ltx_citemacro_cite">Longpre et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib16" title="">2021</a>)</cite>. To address this, recent studies <cite class="ltx_cite ltx_citemacro_cite">Neeman et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib18" title="">2023</a>); Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib15" title="">2023</a>)</cite> fine-tune LLMs on counterfactual contexts, where the original facts are replaced with counterfactual ones. Another work <cite class="ltx_cite ltx_citemacro_cite">Zhou et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib36" title="">2023</a>)</cite> proposes a novel approach using prompting to improve context faithfulness in LLMs without additional fine-tuning.</p>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1">A related area of research focuses on <span class="ltx_text ltx_font_bold" id="S2.SS1.p2.1.1">prediction with abstention</span>. <cite class="ltx_cite ltx_citemacro_citet">Neeman et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib18" title="">2023</a>); Zhou et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib35" title="">2024</a>)</cite> introduced the concept of answerability augmentation, where LLMs are trained to respond with "Unanswerable" when presented with irrelevant or randomly generated contexts. This ensures that the models do not make incorrect predictions in the absence of reliable evidence. Further studies <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib30" title="">2023</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib31" title="">2022</a>)</cite> have developed confidence calibration techniques, which encourage LLMs to avoid overly confident predictions in ambiguous or uncertain situations.</p>
</div>
<div class="ltx_para" id="S2.SS1.p3">
<p class="ltx_p" id="S2.SS1.p3.1">In our work, we investigate the context-faithfulness of LLMs when faced with conflicting knowledge. We define a model as context-faithful if it demonstrates strong receptiveness to new facts and evidence, adapting its responses accordingly. This capability is essential for ensuring the reliability of LLMs in the RAG system.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Construction of Knowledge Conflicts</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">In controlled experiments, knowledge conflicts are typically simulated by constructing counterfactual memories based on a model’s parametric memory. Various heuristic approaches have been proposed for this purpose, such as negation injection <cite class="ltx_cite ltx_citemacro_cite">Kassner et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib10" title="">2021</a>); Petroni et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib22" title="">2020</a>); Pan et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib21" title="">2021</a>)</cite>, which alters facts by introducing negations, and entity substitution <cite class="ltx_cite ltx_citemacro_cite">Longpre et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib16" title="">2021</a>); Chen et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib2" title="">2022</a>); Si et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib25" title="">2023</a>); Zhou et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib36" title="">2023</a>)</cite>, which replaces mentions or entities in the parametric memory with alternatives to generate <span class="ltx_text ltx_font_bold" id="S2.SS2.p1.1.1">counter-memory</span> answers. However, these techniques are constrained to word-level edits, which can lead to low coherence across the constructed counter-memory. To address this limitation, recent studies <cite class="ltx_cite ltx_citemacro_cite">Xie et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib32" title="">2024</a>); Jin et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib7" title="">2024</a>)</cite> have explored generating counter-memories using LLMs, producing more coherent and consistent counterfactual content. We adopt this approach in generating our dataset, ensuring the counter-memories maintain a higher level of coherence.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Methodology</h2>
<figure class="ltx_figure" id="S3.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="168" id="S3.F1.g1" src="extracted/5859889/fig/framework2.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Framework for Evaluating LLMs’ Evidence Context-faithfulness.
In Step 1, we calculate the memory strength of a question by calculating the consistency of answers to different paraphrases of the same question. In Step 2, we generate MA (memory answer) with closed-book setting and CMA (counter memory answer) by modifying <span class="ltx_text" id="S3.F1.3.1" style="background-color:#4DA6A6;">answer entity</span> in MA. <span class="ltx_text" id="S3.F1.4.2" style="background-color:#A64DA6;">Key information</span> should not changed. Step 3 involves generating supporting evidence for the CMA, either as direct or indirect evidence. In Step 4 (not shown), we test the LLM’s response by presenting it with the evidence to evaluate whether it adheres to the CMA or defaults to its MA. All experiments are implemented under the zero-shot setting to avoid the bias introduced by demonstrations.</figcaption>
</figure>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Problem Definition</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.5">Following prior work <cite class="ltx_cite ltx_citemacro_cite">Longpre et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib16" title="">2021</a>); Chen et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib2" title="">2022</a>); Xie et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib32" title="">2024</a>)</cite>, we adopt question answering (QA)
task as the testbed for knowledge conflict experiments.
For a given <span class="ltx_text ltx_font_bold" id="S3.SS1.p1.1.1">question <math alttext="Q" class="ltx_Math" display="inline" id="S3.SS1.p1.1.1.m1.1"><semantics id="S3.SS1.p1.1.1.m1.1a"><mi id="S3.SS1.p1.1.1.m1.1.1" xref="S3.SS1.p1.1.1.m1.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.1.m1.1b"><ci id="S3.SS1.p1.1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.1.m1.1.1">𝑄</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.1.m1.1c">Q</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.1.1.m1.1d">italic_Q</annotation></semantics></math></span>, if the answer generated by the LLM relies solely on its internal parameters, it is referred to as the <span class="ltx_text ltx_font_bold" id="S3.SS1.p1.5.2">memory answer</span> (MA). If an evidence passage <math alttext="E" class="ltx_Math" display="inline" id="S3.SS1.p1.2.m1.1"><semantics id="S3.SS1.p1.2.m1.1a"><mi id="S3.SS1.p1.2.m1.1.1" xref="S3.SS1.p1.2.m1.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m1.1b"><ci id="S3.SS1.p1.2.m1.1.1.cmml" xref="S3.SS1.p1.2.m1.1.1">𝐸</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m1.1c">E</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.2.m1.1d">italic_E</annotation></semantics></math> is provided with question <math alttext="Q" class="ltx_Math" display="inline" id="S3.SS1.p1.3.m2.1"><semantics id="S3.SS1.p1.3.m2.1a"><mi id="S3.SS1.p1.3.m2.1.1" xref="S3.SS1.p1.3.m2.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m2.1b"><ci id="S3.SS1.p1.3.m2.1.1.cmml" xref="S3.SS1.p1.3.m2.1.1">𝑄</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m2.1c">Q</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.3.m2.1d">italic_Q</annotation></semantics></math>, then ideally, LLM should generate an answer based on <math alttext="E" class="ltx_Math" display="inline" id="S3.SS1.p1.4.m3.1"><semantics id="S3.SS1.p1.4.m3.1a"><mi id="S3.SS1.p1.4.m3.1.1" xref="S3.SS1.p1.4.m3.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m3.1b"><ci id="S3.SS1.p1.4.m3.1.1.cmml" xref="S3.SS1.p1.4.m3.1.1">𝐸</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m3.1c">E</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.4.m3.1d">italic_E</annotation></semantics></math>, even if <math alttext="E" class="ltx_Math" display="inline" id="S3.SS1.p1.5.m4.1"><semantics id="S3.SS1.p1.5.m4.1a"><mi id="S3.SS1.p1.5.m4.1.1" xref="S3.SS1.p1.5.m4.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.5.m4.1b"><ci id="S3.SS1.p1.5.m4.1.1.cmml" xref="S3.SS1.p1.5.m4.1.1">𝐸</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.5.m4.1c">E</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.5.m4.1d">italic_E</annotation></semantics></math> conflicts with memory answers. We call the answers that conflict with MA as <span class="ltx_text ltx_font_bold" id="S3.SS1.p1.5.3">counter memory answer</span> (CMA).</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Datasets</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">We use two datasets for our experiments: the long-tail, entity-based QA dataset popQA, and the popular, human-written question dataset Natural Questions (NQ). Specifically:</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<ul class="ltx_itemize" id="S3.I1">
<li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I1.i1.p1">
<p class="ltx_p" id="S3.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i1.p1.1.1">popQA</span> <cite class="ltx_cite ltx_citemacro_cite">Mallen et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib17" title="">2023</a>)</cite> is an entity-centric question-answering dataset comprising 14,000 questions. The dataset is derived from knowledge triples in Wikidata, where questions are generated using question templates specific to different relationship types. popQA aims to capture a realistic, long-tail distribution of entity popularity, making it a valuable resource for studying the performance of lesser-known entities. <cite class="ltx_cite ltx_citemacro_citet">Xie et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib32" title="">2024</a>)</cite> use popQA to test the receptiveness of LLMs by eliciting high-quality parametric memory from LLMs and constructing the corresponding counter-memory. We reuse MA and CMA generated by <cite class="ltx_cite ltx_citemacro_citet">Xie et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib32" title="">2024</a>)</cite> for our experiments.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S3.I1.i2.p1">
<p class="ltx_p" id="S3.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i2.p1.1.1">Natural Questions</span> <cite class="ltx_cite ltx_citemacro_cite">Kwiatkowski et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib12" title="">2019</a>)</cite> is widely used in open-domain QA research. It consists of manually crafted questions based on selected paragraphs from Wikipedia, and the subjects in questions of the NQ dataset are generally more popular and commonly known.
<cite class="ltx_cite ltx_citemacro_citet">Longpre et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib16" title="">2021</a>)</cite> provide a test set that is used to test the context-faithfulness of LLMs by substituting entity of the NQ dataset. The entity substitute involves five categories: person (PER), date (DAT), numeric (NUM), organization (ORG), and location (LOC). The test set contains 4,685 samples, including 1,667 unique questions.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Memory Strength</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.4">Inspired by <cite class="ltx_cite ltx_citemacro_citet">Zhao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib34" title="">2024</a>)</cite>, we use the consistency of answers to different paraphrases of the same question <math alttext="Q" class="ltx_Math" display="inline" id="S3.SS3.p1.1.m1.1"><semantics id="S3.SS3.p1.1.m1.1a"><mi id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><ci id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">𝑄</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">Q</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.1.m1.1d">italic_Q</annotation></semantics></math> to measure the LLM’s memory strength <math alttext="S_{Q}" class="ltx_Math" display="inline" id="S3.SS3.p1.2.m2.1"><semantics id="S3.SS3.p1.2.m2.1a"><msub id="S3.SS3.p1.2.m2.1.1" xref="S3.SS3.p1.2.m2.1.1.cmml"><mi id="S3.SS3.p1.2.m2.1.1.2" xref="S3.SS3.p1.2.m2.1.1.2.cmml">S</mi><mi id="S3.SS3.p1.2.m2.1.1.3" xref="S3.SS3.p1.2.m2.1.1.3.cmml">Q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.2.m2.1b"><apply id="S3.SS3.p1.2.m2.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.2.m2.1.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS3.p1.2.m2.1.1.2.cmml" xref="S3.SS3.p1.2.m2.1.1.2">𝑆</ci><ci id="S3.SS3.p1.2.m2.1.1.3.cmml" xref="S3.SS3.p1.2.m2.1.1.3">𝑄</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.2.m2.1c">S_{Q}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.2.m2.1d">italic_S start_POSTSUBSCRIPT italic_Q end_POSTSUBSCRIPT</annotation></semantics></math> for the knowledge <math alttext="K_{Q}" class="ltx_Math" display="inline" id="S3.SS3.p1.3.m3.1"><semantics id="S3.SS3.p1.3.m3.1a"><msub id="S3.SS3.p1.3.m3.1.1" xref="S3.SS3.p1.3.m3.1.1.cmml"><mi id="S3.SS3.p1.3.m3.1.1.2" xref="S3.SS3.p1.3.m3.1.1.2.cmml">K</mi><mi id="S3.SS3.p1.3.m3.1.1.3" xref="S3.SS3.p1.3.m3.1.1.3.cmml">Q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.3.m3.1b"><apply id="S3.SS3.p1.3.m3.1.1.cmml" xref="S3.SS3.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.3.m3.1.1.1.cmml" xref="S3.SS3.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS3.p1.3.m3.1.1.2.cmml" xref="S3.SS3.p1.3.m3.1.1.2">𝐾</ci><ci id="S3.SS3.p1.3.m3.1.1.3.cmml" xref="S3.SS3.p1.3.m3.1.1.3">𝑄</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.3.m3.1c">K_{Q}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.3.m3.1d">italic_K start_POSTSUBSCRIPT italic_Q end_POSTSUBSCRIPT</annotation></semantics></math> associated with the question. This method is motivated by the intuition that if an LLM does not have a strong memory of a question, it often produces varying answers when presented with different paraphrases but semantically equivalent questions, as shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#A2.T8" title="Table 8 ‣ B.4 Impact of Memory Strength with Different Evidence Styles ‣ Appendix B Methodology and Experiment Details ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_tag">8</span></a> in Appendix. In contrast, it can produce consistent answers if the LLM has a strong memory of a question. The process involves two key steps: First, several paraphrased versions of the original question are generated with ChatGPT<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>https://platform.openai.com/docs/models/gpt-3-5-turbo, the specific version is 0125.</span></span></span>, and the answers to those paraphrased questions are clustered (Section <a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#S3.SS3.SSS1" title="3.3.1 Question Paraphrases and Answer Clustering ‣ 3.3 Memory Strength ‣ 3 Methodology ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_tag">3.3.1</span></a>). Then, memory strength <math alttext="S_{Q}" class="ltx_Math" display="inline" id="S3.SS3.p1.4.m4.1"><semantics id="S3.SS3.p1.4.m4.1a"><msub id="S3.SS3.p1.4.m4.1.1" xref="S3.SS3.p1.4.m4.1.1.cmml"><mi id="S3.SS3.p1.4.m4.1.1.2" xref="S3.SS3.p1.4.m4.1.1.2.cmml">S</mi><mi id="S3.SS3.p1.4.m4.1.1.3" xref="S3.SS3.p1.4.m4.1.1.3.cmml">Q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.4.m4.1b"><apply id="S3.SS3.p1.4.m4.1.1.cmml" xref="S3.SS3.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.4.m4.1.1.1.cmml" xref="S3.SS3.p1.4.m4.1.1">subscript</csymbol><ci id="S3.SS3.p1.4.m4.1.1.2.cmml" xref="S3.SS3.p1.4.m4.1.1.2">𝑆</ci><ci id="S3.SS3.p1.4.m4.1.1.3.cmml" xref="S3.SS3.p1.4.m4.1.1.3">𝑄</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.4.m4.1c">S_{Q}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.4.m4.1d">italic_S start_POSTSUBSCRIPT italic_Q end_POSTSUBSCRIPT</annotation></semantics></math> is calculated using answer consistency (Section <a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#S3.SS3.SSS2" title="3.3.2 Calculating Memory Strength ‣ 3.3 Memory Strength ‣ 3 Methodology ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_tag">3.3.2</span></a>).</p>
</div>
<section class="ltx_subsubsection" id="S3.SS3.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.1 </span>Question Paraphrases and Answer Clustering</h4>
<div class="ltx_para" id="S3.SS3.SSS1.p1">
<p class="ltx_p" id="S3.SS3.SSS1.p1.3">The prompt used for paraphrasing the question is provided in Tabel <a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#A3.T9" title="Table 9 ‣ Appendix C Prompts ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_tag">9</span></a> (index 1) in the Appendix.
For each question <math alttext="Q" class="ltx_Math" display="inline" id="S3.SS3.SSS1.p1.1.m1.1"><semantics id="S3.SS3.SSS1.p1.1.m1.1a"><mi id="S3.SS3.SSS1.p1.1.m1.1.1" xref="S3.SS3.SSS1.p1.1.m1.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p1.1.m1.1b"><ci id="S3.SS3.SSS1.p1.1.m1.1.1.cmml" xref="S3.SS3.SSS1.p1.1.m1.1.1">𝑄</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p1.1.m1.1c">Q</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.SSS1.p1.1.m1.1d">italic_Q</annotation></semantics></math>, we generate <math alttext="n" class="ltx_Math" display="inline" id="S3.SS3.SSS1.p1.2.m2.1"><semantics id="S3.SS3.SSS1.p1.2.m2.1a"><mi id="S3.SS3.SSS1.p1.2.m2.1.1" xref="S3.SS3.SSS1.p1.2.m2.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p1.2.m2.1b"><ci id="S3.SS3.SSS1.p1.2.m2.1.1.cmml" xref="S3.SS3.SSS1.p1.2.m2.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p1.2.m2.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.SSS1.p1.2.m2.1d">italic_n</annotation></semantics></math> paraphrases <math alttext="\{P_{1},\cdots,P_{n}\}_{Q}" class="ltx_Math" display="inline" id="S3.SS3.SSS1.p1.3.m3.3"><semantics id="S3.SS3.SSS1.p1.3.m3.3a"><msub id="S3.SS3.SSS1.p1.3.m3.3.3" xref="S3.SS3.SSS1.p1.3.m3.3.3.cmml"><mrow id="S3.SS3.SSS1.p1.3.m3.3.3.2.2" xref="S3.SS3.SSS1.p1.3.m3.3.3.2.3.cmml"><mo id="S3.SS3.SSS1.p1.3.m3.3.3.2.2.3" stretchy="false" xref="S3.SS3.SSS1.p1.3.m3.3.3.2.3.cmml">{</mo><msub id="S3.SS3.SSS1.p1.3.m3.2.2.1.1.1" xref="S3.SS3.SSS1.p1.3.m3.2.2.1.1.1.cmml"><mi id="S3.SS3.SSS1.p1.3.m3.2.2.1.1.1.2" xref="S3.SS3.SSS1.p1.3.m3.2.2.1.1.1.2.cmml">P</mi><mn id="S3.SS3.SSS1.p1.3.m3.2.2.1.1.1.3" xref="S3.SS3.SSS1.p1.3.m3.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S3.SS3.SSS1.p1.3.m3.3.3.2.2.4" xref="S3.SS3.SSS1.p1.3.m3.3.3.2.3.cmml">,</mo><mi id="S3.SS3.SSS1.p1.3.m3.1.1" mathvariant="normal" xref="S3.SS3.SSS1.p1.3.m3.1.1.cmml">⋯</mi><mo id="S3.SS3.SSS1.p1.3.m3.3.3.2.2.5" xref="S3.SS3.SSS1.p1.3.m3.3.3.2.3.cmml">,</mo><msub id="S3.SS3.SSS1.p1.3.m3.3.3.2.2.2" xref="S3.SS3.SSS1.p1.3.m3.3.3.2.2.2.cmml"><mi id="S3.SS3.SSS1.p1.3.m3.3.3.2.2.2.2" xref="S3.SS3.SSS1.p1.3.m3.3.3.2.2.2.2.cmml">P</mi><mi id="S3.SS3.SSS1.p1.3.m3.3.3.2.2.2.3" xref="S3.SS3.SSS1.p1.3.m3.3.3.2.2.2.3.cmml">n</mi></msub><mo id="S3.SS3.SSS1.p1.3.m3.3.3.2.2.6" stretchy="false" xref="S3.SS3.SSS1.p1.3.m3.3.3.2.3.cmml">}</mo></mrow><mi id="S3.SS3.SSS1.p1.3.m3.3.3.4" xref="S3.SS3.SSS1.p1.3.m3.3.3.4.cmml">Q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p1.3.m3.3b"><apply id="S3.SS3.SSS1.p1.3.m3.3.3.cmml" xref="S3.SS3.SSS1.p1.3.m3.3.3"><csymbol cd="ambiguous" id="S3.SS3.SSS1.p1.3.m3.3.3.3.cmml" xref="S3.SS3.SSS1.p1.3.m3.3.3">subscript</csymbol><set id="S3.SS3.SSS1.p1.3.m3.3.3.2.3.cmml" xref="S3.SS3.SSS1.p1.3.m3.3.3.2.2"><apply id="S3.SS3.SSS1.p1.3.m3.2.2.1.1.1.cmml" xref="S3.SS3.SSS1.p1.3.m3.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS1.p1.3.m3.2.2.1.1.1.1.cmml" xref="S3.SS3.SSS1.p1.3.m3.2.2.1.1.1">subscript</csymbol><ci id="S3.SS3.SSS1.p1.3.m3.2.2.1.1.1.2.cmml" xref="S3.SS3.SSS1.p1.3.m3.2.2.1.1.1.2">𝑃</ci><cn id="S3.SS3.SSS1.p1.3.m3.2.2.1.1.1.3.cmml" type="integer" xref="S3.SS3.SSS1.p1.3.m3.2.2.1.1.1.3">1</cn></apply><ci id="S3.SS3.SSS1.p1.3.m3.1.1.cmml" xref="S3.SS3.SSS1.p1.3.m3.1.1">⋯</ci><apply id="S3.SS3.SSS1.p1.3.m3.3.3.2.2.2.cmml" xref="S3.SS3.SSS1.p1.3.m3.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS3.SSS1.p1.3.m3.3.3.2.2.2.1.cmml" xref="S3.SS3.SSS1.p1.3.m3.3.3.2.2.2">subscript</csymbol><ci id="S3.SS3.SSS1.p1.3.m3.3.3.2.2.2.2.cmml" xref="S3.SS3.SSS1.p1.3.m3.3.3.2.2.2.2">𝑃</ci><ci id="S3.SS3.SSS1.p1.3.m3.3.3.2.2.2.3.cmml" xref="S3.SS3.SSS1.p1.3.m3.3.3.2.2.2.3">𝑛</ci></apply></set><ci id="S3.SS3.SSS1.p1.3.m3.3.3.4.cmml" xref="S3.SS3.SSS1.p1.3.m3.3.3.4">𝑄</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p1.3.m3.3c">\{P_{1},\cdots,P_{n}\}_{Q}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.SSS1.p1.3.m3.3d">{ italic_P start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , ⋯ , italic_P start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_Q end_POSTSUBSCRIPT</annotation></semantics></math>. For the NQ dataset, we paraphrase the question in each data sample directly. For the popQA dataset, we paraphrase the question template for each relation type since all questions of the same relation type share the same question template. To ensure the paraphrased questions are proper to use, we check if two paraphrased questions are semantically equivalent with an LLM<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>https://huggingface.co/meta-llama/Meta-Llama-3.1-8B</span></span></span>. The prompt for this semantic equivalence detection is provided in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#A3.T9" title="Table 9 ‣ Appendix C Prompts ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_tag">9</span></a> (index 2). For any paraphrase that is deemed unequivalent, we ask the LLM to re-generate it until a satisfactory version is produced.</p>
</div>
<div class="ltx_para" id="S3.SS3.SSS1.p2">
<p class="ltx_p" id="S3.SS3.SSS1.p2.4">Next, LLMs answer the paraphrased questions <math alttext="\{P_{1},\cdots,P_{n}\}_{Q}" class="ltx_Math" display="inline" id="S3.SS3.SSS1.p2.1.m1.3"><semantics id="S3.SS3.SSS1.p2.1.m1.3a"><msub id="S3.SS3.SSS1.p2.1.m1.3.3" xref="S3.SS3.SSS1.p2.1.m1.3.3.cmml"><mrow id="S3.SS3.SSS1.p2.1.m1.3.3.2.2" xref="S3.SS3.SSS1.p2.1.m1.3.3.2.3.cmml"><mo id="S3.SS3.SSS1.p2.1.m1.3.3.2.2.3" stretchy="false" xref="S3.SS3.SSS1.p2.1.m1.3.3.2.3.cmml">{</mo><msub id="S3.SS3.SSS1.p2.1.m1.2.2.1.1.1" xref="S3.SS3.SSS1.p2.1.m1.2.2.1.1.1.cmml"><mi id="S3.SS3.SSS1.p2.1.m1.2.2.1.1.1.2" xref="S3.SS3.SSS1.p2.1.m1.2.2.1.1.1.2.cmml">P</mi><mn id="S3.SS3.SSS1.p2.1.m1.2.2.1.1.1.3" xref="S3.SS3.SSS1.p2.1.m1.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S3.SS3.SSS1.p2.1.m1.3.3.2.2.4" xref="S3.SS3.SSS1.p2.1.m1.3.3.2.3.cmml">,</mo><mi id="S3.SS3.SSS1.p2.1.m1.1.1" mathvariant="normal" xref="S3.SS3.SSS1.p2.1.m1.1.1.cmml">⋯</mi><mo id="S3.SS3.SSS1.p2.1.m1.3.3.2.2.5" xref="S3.SS3.SSS1.p2.1.m1.3.3.2.3.cmml">,</mo><msub id="S3.SS3.SSS1.p2.1.m1.3.3.2.2.2" xref="S3.SS3.SSS1.p2.1.m1.3.3.2.2.2.cmml"><mi id="S3.SS3.SSS1.p2.1.m1.3.3.2.2.2.2" xref="S3.SS3.SSS1.p2.1.m1.3.3.2.2.2.2.cmml">P</mi><mi id="S3.SS3.SSS1.p2.1.m1.3.3.2.2.2.3" xref="S3.SS3.SSS1.p2.1.m1.3.3.2.2.2.3.cmml">n</mi></msub><mo id="S3.SS3.SSS1.p2.1.m1.3.3.2.2.6" stretchy="false" xref="S3.SS3.SSS1.p2.1.m1.3.3.2.3.cmml">}</mo></mrow><mi id="S3.SS3.SSS1.p2.1.m1.3.3.4" xref="S3.SS3.SSS1.p2.1.m1.3.3.4.cmml">Q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p2.1.m1.3b"><apply id="S3.SS3.SSS1.p2.1.m1.3.3.cmml" xref="S3.SS3.SSS1.p2.1.m1.3.3"><csymbol cd="ambiguous" id="S3.SS3.SSS1.p2.1.m1.3.3.3.cmml" xref="S3.SS3.SSS1.p2.1.m1.3.3">subscript</csymbol><set id="S3.SS3.SSS1.p2.1.m1.3.3.2.3.cmml" xref="S3.SS3.SSS1.p2.1.m1.3.3.2.2"><apply id="S3.SS3.SSS1.p2.1.m1.2.2.1.1.1.cmml" xref="S3.SS3.SSS1.p2.1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS1.p2.1.m1.2.2.1.1.1.1.cmml" xref="S3.SS3.SSS1.p2.1.m1.2.2.1.1.1">subscript</csymbol><ci id="S3.SS3.SSS1.p2.1.m1.2.2.1.1.1.2.cmml" xref="S3.SS3.SSS1.p2.1.m1.2.2.1.1.1.2">𝑃</ci><cn id="S3.SS3.SSS1.p2.1.m1.2.2.1.1.1.3.cmml" type="integer" xref="S3.SS3.SSS1.p2.1.m1.2.2.1.1.1.3">1</cn></apply><ci id="S3.SS3.SSS1.p2.1.m1.1.1.cmml" xref="S3.SS3.SSS1.p2.1.m1.1.1">⋯</ci><apply id="S3.SS3.SSS1.p2.1.m1.3.3.2.2.2.cmml" xref="S3.SS3.SSS1.p2.1.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS3.SSS1.p2.1.m1.3.3.2.2.2.1.cmml" xref="S3.SS3.SSS1.p2.1.m1.3.3.2.2.2">subscript</csymbol><ci id="S3.SS3.SSS1.p2.1.m1.3.3.2.2.2.2.cmml" xref="S3.SS3.SSS1.p2.1.m1.3.3.2.2.2.2">𝑃</ci><ci id="S3.SS3.SSS1.p2.1.m1.3.3.2.2.2.3.cmml" xref="S3.SS3.SSS1.p2.1.m1.3.3.2.2.2.3">𝑛</ci></apply></set><ci id="S3.SS3.SSS1.p2.1.m1.3.3.4.cmml" xref="S3.SS3.SSS1.p2.1.m1.3.3.4">𝑄</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p2.1.m1.3c">\{P_{1},\cdots,P_{n}\}_{Q}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.SSS1.p2.1.m1.3d">{ italic_P start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , ⋯ , italic_P start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_Q end_POSTSUBSCRIPT</annotation></semantics></math> in a closed-book setting. We denote the answers as <math alttext="\{A_{1},\cdots,A_{n}\}_{Q}" class="ltx_Math" display="inline" id="S3.SS3.SSS1.p2.2.m2.3"><semantics id="S3.SS3.SSS1.p2.2.m2.3a"><msub id="S3.SS3.SSS1.p2.2.m2.3.3" xref="S3.SS3.SSS1.p2.2.m2.3.3.cmml"><mrow id="S3.SS3.SSS1.p2.2.m2.3.3.2.2" xref="S3.SS3.SSS1.p2.2.m2.3.3.2.3.cmml"><mo id="S3.SS3.SSS1.p2.2.m2.3.3.2.2.3" stretchy="false" xref="S3.SS3.SSS1.p2.2.m2.3.3.2.3.cmml">{</mo><msub id="S3.SS3.SSS1.p2.2.m2.2.2.1.1.1" xref="S3.SS3.SSS1.p2.2.m2.2.2.1.1.1.cmml"><mi id="S3.SS3.SSS1.p2.2.m2.2.2.1.1.1.2" xref="S3.SS3.SSS1.p2.2.m2.2.2.1.1.1.2.cmml">A</mi><mn id="S3.SS3.SSS1.p2.2.m2.2.2.1.1.1.3" xref="S3.SS3.SSS1.p2.2.m2.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S3.SS3.SSS1.p2.2.m2.3.3.2.2.4" xref="S3.SS3.SSS1.p2.2.m2.3.3.2.3.cmml">,</mo><mi id="S3.SS3.SSS1.p2.2.m2.1.1" mathvariant="normal" xref="S3.SS3.SSS1.p2.2.m2.1.1.cmml">⋯</mi><mo id="S3.SS3.SSS1.p2.2.m2.3.3.2.2.5" xref="S3.SS3.SSS1.p2.2.m2.3.3.2.3.cmml">,</mo><msub id="S3.SS3.SSS1.p2.2.m2.3.3.2.2.2" xref="S3.SS3.SSS1.p2.2.m2.3.3.2.2.2.cmml"><mi id="S3.SS3.SSS1.p2.2.m2.3.3.2.2.2.2" xref="S3.SS3.SSS1.p2.2.m2.3.3.2.2.2.2.cmml">A</mi><mi id="S3.SS3.SSS1.p2.2.m2.3.3.2.2.2.3" xref="S3.SS3.SSS1.p2.2.m2.3.3.2.2.2.3.cmml">n</mi></msub><mo id="S3.SS3.SSS1.p2.2.m2.3.3.2.2.6" stretchy="false" xref="S3.SS3.SSS1.p2.2.m2.3.3.2.3.cmml">}</mo></mrow><mi id="S3.SS3.SSS1.p2.2.m2.3.3.4" xref="S3.SS3.SSS1.p2.2.m2.3.3.4.cmml">Q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p2.2.m2.3b"><apply id="S3.SS3.SSS1.p2.2.m2.3.3.cmml" xref="S3.SS3.SSS1.p2.2.m2.3.3"><csymbol cd="ambiguous" id="S3.SS3.SSS1.p2.2.m2.3.3.3.cmml" xref="S3.SS3.SSS1.p2.2.m2.3.3">subscript</csymbol><set id="S3.SS3.SSS1.p2.2.m2.3.3.2.3.cmml" xref="S3.SS3.SSS1.p2.2.m2.3.3.2.2"><apply id="S3.SS3.SSS1.p2.2.m2.2.2.1.1.1.cmml" xref="S3.SS3.SSS1.p2.2.m2.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS1.p2.2.m2.2.2.1.1.1.1.cmml" xref="S3.SS3.SSS1.p2.2.m2.2.2.1.1.1">subscript</csymbol><ci id="S3.SS3.SSS1.p2.2.m2.2.2.1.1.1.2.cmml" xref="S3.SS3.SSS1.p2.2.m2.2.2.1.1.1.2">𝐴</ci><cn id="S3.SS3.SSS1.p2.2.m2.2.2.1.1.1.3.cmml" type="integer" xref="S3.SS3.SSS1.p2.2.m2.2.2.1.1.1.3">1</cn></apply><ci id="S3.SS3.SSS1.p2.2.m2.1.1.cmml" xref="S3.SS3.SSS1.p2.2.m2.1.1">⋯</ci><apply id="S3.SS3.SSS1.p2.2.m2.3.3.2.2.2.cmml" xref="S3.SS3.SSS1.p2.2.m2.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS3.SSS1.p2.2.m2.3.3.2.2.2.1.cmml" xref="S3.SS3.SSS1.p2.2.m2.3.3.2.2.2">subscript</csymbol><ci id="S3.SS3.SSS1.p2.2.m2.3.3.2.2.2.2.cmml" xref="S3.SS3.SSS1.p2.2.m2.3.3.2.2.2.2">𝐴</ci><ci id="S3.SS3.SSS1.p2.2.m2.3.3.2.2.2.3.cmml" xref="S3.SS3.SSS1.p2.2.m2.3.3.2.2.2.3">𝑛</ci></apply></set><ci id="S3.SS3.SSS1.p2.2.m2.3.3.4.cmml" xref="S3.SS3.SSS1.p2.2.m2.3.3.4">𝑄</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p2.2.m2.3c">\{A_{1},\cdots,A_{n}\}_{Q}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.SSS1.p2.2.m2.3d">{ italic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , ⋯ , italic_A start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_Q end_POSTSUBSCRIPT</annotation></semantics></math>. The answers are grouped into several clusters based on their consistency. The clustering is done by checking answers incrementally. If an answer matches any answer within an existing cluster, this answer is added to this cluster; if not, a new cluster is created with this answer. We use an LLM<sup class="ltx_sup" id="S3.SS3.SSS1.p2.4.1"><a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#footnote2" title="footnote 2 ‣ 3.3.1 Question Paraphrases and Answer Clustering ‣ 3.3 Memory Strength ‣ 3 Methodology ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_tag">2</span></a></sup> to determine whether two answers are consistent. The prompt used for this answer inconsistency detection is shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#A3.T9" title="Table 9 ‣ Appendix C Prompts ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_tag">9</span></a> (index 3). We denote the clusters for question <math alttext="Q" class="ltx_Math" display="inline" id="S3.SS3.SSS1.p2.3.m3.1"><semantics id="S3.SS3.SSS1.p2.3.m3.1a"><mi id="S3.SS3.SSS1.p2.3.m3.1.1" xref="S3.SS3.SSS1.p2.3.m3.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p2.3.m3.1b"><ci id="S3.SS3.SSS1.p2.3.m3.1.1.cmml" xref="S3.SS3.SSS1.p2.3.m3.1.1">𝑄</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p2.3.m3.1c">Q</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.SSS1.p2.3.m3.1d">italic_Q</annotation></semantics></math> as <math alttext="\{c_{1},\cdots,c_{m}\}_{Q}" class="ltx_Math" display="inline" id="S3.SS3.SSS1.p2.4.m4.3"><semantics id="S3.SS3.SSS1.p2.4.m4.3a"><msub id="S3.SS3.SSS1.p2.4.m4.3.3" xref="S3.SS3.SSS1.p2.4.m4.3.3.cmml"><mrow id="S3.SS3.SSS1.p2.4.m4.3.3.2.2" xref="S3.SS3.SSS1.p2.4.m4.3.3.2.3.cmml"><mo id="S3.SS3.SSS1.p2.4.m4.3.3.2.2.3" stretchy="false" xref="S3.SS3.SSS1.p2.4.m4.3.3.2.3.cmml">{</mo><msub id="S3.SS3.SSS1.p2.4.m4.2.2.1.1.1" xref="S3.SS3.SSS1.p2.4.m4.2.2.1.1.1.cmml"><mi id="S3.SS3.SSS1.p2.4.m4.2.2.1.1.1.2" xref="S3.SS3.SSS1.p2.4.m4.2.2.1.1.1.2.cmml">c</mi><mn id="S3.SS3.SSS1.p2.4.m4.2.2.1.1.1.3" xref="S3.SS3.SSS1.p2.4.m4.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S3.SS3.SSS1.p2.4.m4.3.3.2.2.4" xref="S3.SS3.SSS1.p2.4.m4.3.3.2.3.cmml">,</mo><mi id="S3.SS3.SSS1.p2.4.m4.1.1" mathvariant="normal" xref="S3.SS3.SSS1.p2.4.m4.1.1.cmml">⋯</mi><mo id="S3.SS3.SSS1.p2.4.m4.3.3.2.2.5" xref="S3.SS3.SSS1.p2.4.m4.3.3.2.3.cmml">,</mo><msub id="S3.SS3.SSS1.p2.4.m4.3.3.2.2.2" xref="S3.SS3.SSS1.p2.4.m4.3.3.2.2.2.cmml"><mi id="S3.SS3.SSS1.p2.4.m4.3.3.2.2.2.2" xref="S3.SS3.SSS1.p2.4.m4.3.3.2.2.2.2.cmml">c</mi><mi id="S3.SS3.SSS1.p2.4.m4.3.3.2.2.2.3" xref="S3.SS3.SSS1.p2.4.m4.3.3.2.2.2.3.cmml">m</mi></msub><mo id="S3.SS3.SSS1.p2.4.m4.3.3.2.2.6" stretchy="false" xref="S3.SS3.SSS1.p2.4.m4.3.3.2.3.cmml">}</mo></mrow><mi id="S3.SS3.SSS1.p2.4.m4.3.3.4" xref="S3.SS3.SSS1.p2.4.m4.3.3.4.cmml">Q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p2.4.m4.3b"><apply id="S3.SS3.SSS1.p2.4.m4.3.3.cmml" xref="S3.SS3.SSS1.p2.4.m4.3.3"><csymbol cd="ambiguous" id="S3.SS3.SSS1.p2.4.m4.3.3.3.cmml" xref="S3.SS3.SSS1.p2.4.m4.3.3">subscript</csymbol><set id="S3.SS3.SSS1.p2.4.m4.3.3.2.3.cmml" xref="S3.SS3.SSS1.p2.4.m4.3.3.2.2"><apply id="S3.SS3.SSS1.p2.4.m4.2.2.1.1.1.cmml" xref="S3.SS3.SSS1.p2.4.m4.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS1.p2.4.m4.2.2.1.1.1.1.cmml" xref="S3.SS3.SSS1.p2.4.m4.2.2.1.1.1">subscript</csymbol><ci id="S3.SS3.SSS1.p2.4.m4.2.2.1.1.1.2.cmml" xref="S3.SS3.SSS1.p2.4.m4.2.2.1.1.1.2">𝑐</ci><cn id="S3.SS3.SSS1.p2.4.m4.2.2.1.1.1.3.cmml" type="integer" xref="S3.SS3.SSS1.p2.4.m4.2.2.1.1.1.3">1</cn></apply><ci id="S3.SS3.SSS1.p2.4.m4.1.1.cmml" xref="S3.SS3.SSS1.p2.4.m4.1.1">⋯</ci><apply id="S3.SS3.SSS1.p2.4.m4.3.3.2.2.2.cmml" xref="S3.SS3.SSS1.p2.4.m4.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS3.SSS1.p2.4.m4.3.3.2.2.2.1.cmml" xref="S3.SS3.SSS1.p2.4.m4.3.3.2.2.2">subscript</csymbol><ci id="S3.SS3.SSS1.p2.4.m4.3.3.2.2.2.2.cmml" xref="S3.SS3.SSS1.p2.4.m4.3.3.2.2.2.2">𝑐</ci><ci id="S3.SS3.SSS1.p2.4.m4.3.3.2.2.2.3.cmml" xref="S3.SS3.SSS1.p2.4.m4.3.3.2.2.2.3">𝑚</ci></apply></set><ci id="S3.SS3.SSS1.p2.4.m4.3.3.4.cmml" xref="S3.SS3.SSS1.p2.4.m4.3.3.4">𝑄</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p2.4.m4.3c">\{c_{1},\cdots,c_{m}\}_{Q}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.SSS1.p2.4.m4.3d">{ italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , ⋯ , italic_c start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_Q end_POSTSUBSCRIPT</annotation></semantics></math>.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS3.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.2 </span>Calculating Memory Strength</h4>
<div class="ltx_para" id="S3.SS3.SSS2.p1">
<p class="ltx_p" id="S3.SS3.SSS2.p1.2">Once answer clusters <math alttext="\{c_{1},\cdots,c_{m}\}_{Q}" class="ltx_Math" display="inline" id="S3.SS3.SSS2.p1.1.m1.3"><semantics id="S3.SS3.SSS2.p1.1.m1.3a"><msub id="S3.SS3.SSS2.p1.1.m1.3.3" xref="S3.SS3.SSS2.p1.1.m1.3.3.cmml"><mrow id="S3.SS3.SSS2.p1.1.m1.3.3.2.2" xref="S3.SS3.SSS2.p1.1.m1.3.3.2.3.cmml"><mo id="S3.SS3.SSS2.p1.1.m1.3.3.2.2.3" stretchy="false" xref="S3.SS3.SSS2.p1.1.m1.3.3.2.3.cmml">{</mo><msub id="S3.SS3.SSS2.p1.1.m1.2.2.1.1.1" xref="S3.SS3.SSS2.p1.1.m1.2.2.1.1.1.cmml"><mi id="S3.SS3.SSS2.p1.1.m1.2.2.1.1.1.2" xref="S3.SS3.SSS2.p1.1.m1.2.2.1.1.1.2.cmml">c</mi><mn id="S3.SS3.SSS2.p1.1.m1.2.2.1.1.1.3" xref="S3.SS3.SSS2.p1.1.m1.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S3.SS3.SSS2.p1.1.m1.3.3.2.2.4" xref="S3.SS3.SSS2.p1.1.m1.3.3.2.3.cmml">,</mo><mi id="S3.SS3.SSS2.p1.1.m1.1.1" mathvariant="normal" xref="S3.SS3.SSS2.p1.1.m1.1.1.cmml">⋯</mi><mo id="S3.SS3.SSS2.p1.1.m1.3.3.2.2.5" xref="S3.SS3.SSS2.p1.1.m1.3.3.2.3.cmml">,</mo><msub id="S3.SS3.SSS2.p1.1.m1.3.3.2.2.2" xref="S3.SS3.SSS2.p1.1.m1.3.3.2.2.2.cmml"><mi id="S3.SS3.SSS2.p1.1.m1.3.3.2.2.2.2" xref="S3.SS3.SSS2.p1.1.m1.3.3.2.2.2.2.cmml">c</mi><mi id="S3.SS3.SSS2.p1.1.m1.3.3.2.2.2.3" xref="S3.SS3.SSS2.p1.1.m1.3.3.2.2.2.3.cmml">m</mi></msub><mo id="S3.SS3.SSS2.p1.1.m1.3.3.2.2.6" stretchy="false" xref="S3.SS3.SSS2.p1.1.m1.3.3.2.3.cmml">}</mo></mrow><mi id="S3.SS3.SSS2.p1.1.m1.3.3.4" xref="S3.SS3.SSS2.p1.1.m1.3.3.4.cmml">Q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p1.1.m1.3b"><apply id="S3.SS3.SSS2.p1.1.m1.3.3.cmml" xref="S3.SS3.SSS2.p1.1.m1.3.3"><csymbol cd="ambiguous" id="S3.SS3.SSS2.p1.1.m1.3.3.3.cmml" xref="S3.SS3.SSS2.p1.1.m1.3.3">subscript</csymbol><set id="S3.SS3.SSS2.p1.1.m1.3.3.2.3.cmml" xref="S3.SS3.SSS2.p1.1.m1.3.3.2.2"><apply id="S3.SS3.SSS2.p1.1.m1.2.2.1.1.1.cmml" xref="S3.SS3.SSS2.p1.1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS2.p1.1.m1.2.2.1.1.1.1.cmml" xref="S3.SS3.SSS2.p1.1.m1.2.2.1.1.1">subscript</csymbol><ci id="S3.SS3.SSS2.p1.1.m1.2.2.1.1.1.2.cmml" xref="S3.SS3.SSS2.p1.1.m1.2.2.1.1.1.2">𝑐</ci><cn id="S3.SS3.SSS2.p1.1.m1.2.2.1.1.1.3.cmml" type="integer" xref="S3.SS3.SSS2.p1.1.m1.2.2.1.1.1.3">1</cn></apply><ci id="S3.SS3.SSS2.p1.1.m1.1.1.cmml" xref="S3.SS3.SSS2.p1.1.m1.1.1">⋯</ci><apply id="S3.SS3.SSS2.p1.1.m1.3.3.2.2.2.cmml" xref="S3.SS3.SSS2.p1.1.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS3.SSS2.p1.1.m1.3.3.2.2.2.1.cmml" xref="S3.SS3.SSS2.p1.1.m1.3.3.2.2.2">subscript</csymbol><ci id="S3.SS3.SSS2.p1.1.m1.3.3.2.2.2.2.cmml" xref="S3.SS3.SSS2.p1.1.m1.3.3.2.2.2.2">𝑐</ci><ci id="S3.SS3.SSS2.p1.1.m1.3.3.2.2.2.3.cmml" xref="S3.SS3.SSS2.p1.1.m1.3.3.2.2.2.3">𝑚</ci></apply></set><ci id="S3.SS3.SSS2.p1.1.m1.3.3.4.cmml" xref="S3.SS3.SSS2.p1.1.m1.3.3.4">𝑄</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p1.1.m1.3c">\{c_{1},\cdots,c_{m}\}_{Q}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.SSS2.p1.1.m1.3d">{ italic_c start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , ⋯ , italic_c start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_Q end_POSTSUBSCRIPT</annotation></semantics></math> are identified, memory strength <math alttext="S(Q)" class="ltx_Math" display="inline" id="S3.SS3.SSS2.p1.2.m2.1"><semantics id="S3.SS3.SSS2.p1.2.m2.1a"><mrow id="S3.SS3.SSS2.p1.2.m2.1.2" xref="S3.SS3.SSS2.p1.2.m2.1.2.cmml"><mi id="S3.SS3.SSS2.p1.2.m2.1.2.2" xref="S3.SS3.SSS2.p1.2.m2.1.2.2.cmml">S</mi><mo id="S3.SS3.SSS2.p1.2.m2.1.2.1" xref="S3.SS3.SSS2.p1.2.m2.1.2.1.cmml">⁢</mo><mrow id="S3.SS3.SSS2.p1.2.m2.1.2.3.2" xref="S3.SS3.SSS2.p1.2.m2.1.2.cmml"><mo id="S3.SS3.SSS2.p1.2.m2.1.2.3.2.1" stretchy="false" xref="S3.SS3.SSS2.p1.2.m2.1.2.cmml">(</mo><mi id="S3.SS3.SSS2.p1.2.m2.1.1" xref="S3.SS3.SSS2.p1.2.m2.1.1.cmml">Q</mi><mo id="S3.SS3.SSS2.p1.2.m2.1.2.3.2.2" stretchy="false" xref="S3.SS3.SSS2.p1.2.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p1.2.m2.1b"><apply id="S3.SS3.SSS2.p1.2.m2.1.2.cmml" xref="S3.SS3.SSS2.p1.2.m2.1.2"><times id="S3.SS3.SSS2.p1.2.m2.1.2.1.cmml" xref="S3.SS3.SSS2.p1.2.m2.1.2.1"></times><ci id="S3.SS3.SSS2.p1.2.m2.1.2.2.cmml" xref="S3.SS3.SSS2.p1.2.m2.1.2.2">𝑆</ci><ci id="S3.SS3.SSS2.p1.2.m2.1.1.cmml" xref="S3.SS3.SSS2.p1.2.m2.1.1">𝑄</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p1.2.m2.1c">S(Q)</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.SSS2.p1.2.m2.1d">italic_S ( italic_Q )</annotation></semantics></math> can be obtained by calculating the entropy of cluster distribution. The formula is</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="S(Q)=\sum_{i=1}^{m}\frac{N(c_{i})}{n}log\frac{N(c_{i})}{n}," class="ltx_Math" display="block" id="S3.E1.m1.4"><semantics id="S3.E1.m1.4a"><mrow id="S3.E1.m1.4.4.1" xref="S3.E1.m1.4.4.1.1.cmml"><mrow id="S3.E1.m1.4.4.1.1" xref="S3.E1.m1.4.4.1.1.cmml"><mrow id="S3.E1.m1.4.4.1.1.2" xref="S3.E1.m1.4.4.1.1.2.cmml"><mi id="S3.E1.m1.4.4.1.1.2.2" xref="S3.E1.m1.4.4.1.1.2.2.cmml">S</mi><mo id="S3.E1.m1.4.4.1.1.2.1" xref="S3.E1.m1.4.4.1.1.2.1.cmml">⁢</mo><mrow id="S3.E1.m1.4.4.1.1.2.3.2" xref="S3.E1.m1.4.4.1.1.2.cmml"><mo id="S3.E1.m1.4.4.1.1.2.3.2.1" stretchy="false" xref="S3.E1.m1.4.4.1.1.2.cmml">(</mo><mi id="S3.E1.m1.3.3" xref="S3.E1.m1.3.3.cmml">Q</mi><mo id="S3.E1.m1.4.4.1.1.2.3.2.2" stretchy="false" xref="S3.E1.m1.4.4.1.1.2.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.4.4.1.1.1" rspace="0.111em" xref="S3.E1.m1.4.4.1.1.1.cmml">=</mo><mrow id="S3.E1.m1.4.4.1.1.3" xref="S3.E1.m1.4.4.1.1.3.cmml"><munderover id="S3.E1.m1.4.4.1.1.3.1" xref="S3.E1.m1.4.4.1.1.3.1.cmml"><mo id="S3.E1.m1.4.4.1.1.3.1.2.2" movablelimits="false" xref="S3.E1.m1.4.4.1.1.3.1.2.2.cmml">∑</mo><mrow id="S3.E1.m1.4.4.1.1.3.1.2.3" xref="S3.E1.m1.4.4.1.1.3.1.2.3.cmml"><mi id="S3.E1.m1.4.4.1.1.3.1.2.3.2" xref="S3.E1.m1.4.4.1.1.3.1.2.3.2.cmml">i</mi><mo id="S3.E1.m1.4.4.1.1.3.1.2.3.1" xref="S3.E1.m1.4.4.1.1.3.1.2.3.1.cmml">=</mo><mn id="S3.E1.m1.4.4.1.1.3.1.2.3.3" xref="S3.E1.m1.4.4.1.1.3.1.2.3.3.cmml">1</mn></mrow><mi id="S3.E1.m1.4.4.1.1.3.1.3" xref="S3.E1.m1.4.4.1.1.3.1.3.cmml">m</mi></munderover><mrow id="S3.E1.m1.4.4.1.1.3.2" xref="S3.E1.m1.4.4.1.1.3.2.cmml"><mfrac id="S3.E1.m1.1.1" xref="S3.E1.m1.1.1.cmml"><mrow id="S3.E1.m1.1.1.1" xref="S3.E1.m1.1.1.1.cmml"><mi id="S3.E1.m1.1.1.1.3" xref="S3.E1.m1.1.1.1.3.cmml">N</mi><mo id="S3.E1.m1.1.1.1.2" xref="S3.E1.m1.1.1.1.2.cmml">⁢</mo><mrow id="S3.E1.m1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.cmml"><mo id="S3.E1.m1.1.1.1.1.1.2" stretchy="false" xref="S3.E1.m1.1.1.1.1.1.1.cmml">(</mo><msub id="S3.E1.m1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.1.2.cmml">c</mi><mi id="S3.E1.m1.1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.E1.m1.1.1.1.1.1.3" stretchy="false" xref="S3.E1.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mi id="S3.E1.m1.1.1.3" xref="S3.E1.m1.1.1.3.cmml">n</mi></mfrac><mo id="S3.E1.m1.4.4.1.1.3.2.1" xref="S3.E1.m1.4.4.1.1.3.2.1.cmml">⁢</mo><mi id="S3.E1.m1.4.4.1.1.3.2.2" xref="S3.E1.m1.4.4.1.1.3.2.2.cmml">l</mi><mo id="S3.E1.m1.4.4.1.1.3.2.1a" xref="S3.E1.m1.4.4.1.1.3.2.1.cmml">⁢</mo><mi id="S3.E1.m1.4.4.1.1.3.2.3" xref="S3.E1.m1.4.4.1.1.3.2.3.cmml">o</mi><mo id="S3.E1.m1.4.4.1.1.3.2.1b" xref="S3.E1.m1.4.4.1.1.3.2.1.cmml">⁢</mo><mi id="S3.E1.m1.4.4.1.1.3.2.4" xref="S3.E1.m1.4.4.1.1.3.2.4.cmml">g</mi><mo id="S3.E1.m1.4.4.1.1.3.2.1c" xref="S3.E1.m1.4.4.1.1.3.2.1.cmml">⁢</mo><mfrac id="S3.E1.m1.2.2" xref="S3.E1.m1.2.2.cmml"><mrow id="S3.E1.m1.2.2.1" xref="S3.E1.m1.2.2.1.cmml"><mi id="S3.E1.m1.2.2.1.3" xref="S3.E1.m1.2.2.1.3.cmml">N</mi><mo id="S3.E1.m1.2.2.1.2" xref="S3.E1.m1.2.2.1.2.cmml">⁢</mo><mrow id="S3.E1.m1.2.2.1.1.1" xref="S3.E1.m1.2.2.1.1.1.1.cmml"><mo id="S3.E1.m1.2.2.1.1.1.2" stretchy="false" xref="S3.E1.m1.2.2.1.1.1.1.cmml">(</mo><msub id="S3.E1.m1.2.2.1.1.1.1" xref="S3.E1.m1.2.2.1.1.1.1.cmml"><mi id="S3.E1.m1.2.2.1.1.1.1.2" xref="S3.E1.m1.2.2.1.1.1.1.2.cmml">c</mi><mi id="S3.E1.m1.2.2.1.1.1.1.3" xref="S3.E1.m1.2.2.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.E1.m1.2.2.1.1.1.3" stretchy="false" xref="S3.E1.m1.2.2.1.1.1.1.cmml">)</mo></mrow></mrow><mi id="S3.E1.m1.2.2.3" xref="S3.E1.m1.2.2.3.cmml">n</mi></mfrac></mrow></mrow></mrow><mo id="S3.E1.m1.4.4.1.2" xref="S3.E1.m1.4.4.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.4b"><apply id="S3.E1.m1.4.4.1.1.cmml" xref="S3.E1.m1.4.4.1"><eq id="S3.E1.m1.4.4.1.1.1.cmml" xref="S3.E1.m1.4.4.1.1.1"></eq><apply id="S3.E1.m1.4.4.1.1.2.cmml" xref="S3.E1.m1.4.4.1.1.2"><times id="S3.E1.m1.4.4.1.1.2.1.cmml" xref="S3.E1.m1.4.4.1.1.2.1"></times><ci id="S3.E1.m1.4.4.1.1.2.2.cmml" xref="S3.E1.m1.4.4.1.1.2.2">𝑆</ci><ci id="S3.E1.m1.3.3.cmml" xref="S3.E1.m1.3.3">𝑄</ci></apply><apply id="S3.E1.m1.4.4.1.1.3.cmml" xref="S3.E1.m1.4.4.1.1.3"><apply id="S3.E1.m1.4.4.1.1.3.1.cmml" xref="S3.E1.m1.4.4.1.1.3.1"><csymbol cd="ambiguous" id="S3.E1.m1.4.4.1.1.3.1.1.cmml" xref="S3.E1.m1.4.4.1.1.3.1">superscript</csymbol><apply id="S3.E1.m1.4.4.1.1.3.1.2.cmml" xref="S3.E1.m1.4.4.1.1.3.1"><csymbol cd="ambiguous" id="S3.E1.m1.4.4.1.1.3.1.2.1.cmml" xref="S3.E1.m1.4.4.1.1.3.1">subscript</csymbol><sum id="S3.E1.m1.4.4.1.1.3.1.2.2.cmml" xref="S3.E1.m1.4.4.1.1.3.1.2.2"></sum><apply id="S3.E1.m1.4.4.1.1.3.1.2.3.cmml" xref="S3.E1.m1.4.4.1.1.3.1.2.3"><eq id="S3.E1.m1.4.4.1.1.3.1.2.3.1.cmml" xref="S3.E1.m1.4.4.1.1.3.1.2.3.1"></eq><ci id="S3.E1.m1.4.4.1.1.3.1.2.3.2.cmml" xref="S3.E1.m1.4.4.1.1.3.1.2.3.2">𝑖</ci><cn id="S3.E1.m1.4.4.1.1.3.1.2.3.3.cmml" type="integer" xref="S3.E1.m1.4.4.1.1.3.1.2.3.3">1</cn></apply></apply><ci id="S3.E1.m1.4.4.1.1.3.1.3.cmml" xref="S3.E1.m1.4.4.1.1.3.1.3">𝑚</ci></apply><apply id="S3.E1.m1.4.4.1.1.3.2.cmml" xref="S3.E1.m1.4.4.1.1.3.2"><times id="S3.E1.m1.4.4.1.1.3.2.1.cmml" xref="S3.E1.m1.4.4.1.1.3.2.1"></times><apply id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1"><divide id="S3.E1.m1.1.1.2.cmml" xref="S3.E1.m1.1.1"></divide><apply id="S3.E1.m1.1.1.1.cmml" xref="S3.E1.m1.1.1.1"><times id="S3.E1.m1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.2"></times><ci id="S3.E1.m1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.3">𝑁</ci><apply id="S3.E1.m1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.2">𝑐</ci><ci id="S3.E1.m1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.3">𝑖</ci></apply></apply><ci id="S3.E1.m1.1.1.3.cmml" xref="S3.E1.m1.1.1.3">𝑛</ci></apply><ci id="S3.E1.m1.4.4.1.1.3.2.2.cmml" xref="S3.E1.m1.4.4.1.1.3.2.2">𝑙</ci><ci id="S3.E1.m1.4.4.1.1.3.2.3.cmml" xref="S3.E1.m1.4.4.1.1.3.2.3">𝑜</ci><ci id="S3.E1.m1.4.4.1.1.3.2.4.cmml" xref="S3.E1.m1.4.4.1.1.3.2.4">𝑔</ci><apply id="S3.E1.m1.2.2.cmml" xref="S3.E1.m1.2.2"><divide id="S3.E1.m1.2.2.2.cmml" xref="S3.E1.m1.2.2"></divide><apply id="S3.E1.m1.2.2.1.cmml" xref="S3.E1.m1.2.2.1"><times id="S3.E1.m1.2.2.1.2.cmml" xref="S3.E1.m1.2.2.1.2"></times><ci id="S3.E1.m1.2.2.1.3.cmml" xref="S3.E1.m1.2.2.1.3">𝑁</ci><apply id="S3.E1.m1.2.2.1.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.1">subscript</csymbol><ci id="S3.E1.m1.2.2.1.1.1.1.2.cmml" xref="S3.E1.m1.2.2.1.1.1.1.2">𝑐</ci><ci id="S3.E1.m1.2.2.1.1.1.1.3.cmml" xref="S3.E1.m1.2.2.1.1.1.1.3">𝑖</ci></apply></apply><ci id="S3.E1.m1.2.2.3.cmml" xref="S3.E1.m1.2.2.3">𝑛</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.4c">S(Q)=\sum_{i=1}^{m}\frac{N(c_{i})}{n}log\frac{N(c_{i})}{n},</annotation><annotation encoding="application/x-llamapun" id="S3.E1.m1.4d">italic_S ( italic_Q ) = ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_m end_POSTSUPERSCRIPT divide start_ARG italic_N ( italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) end_ARG start_ARG italic_n end_ARG italic_l italic_o italic_g divide start_ARG italic_N ( italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) end_ARG start_ARG italic_n end_ARG ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS3.SSS2.p1.7">where <math alttext="N(c_{i})" class="ltx_Math" display="inline" id="S3.SS3.SSS2.p1.3.m1.1"><semantics id="S3.SS3.SSS2.p1.3.m1.1a"><mrow id="S3.SS3.SSS2.p1.3.m1.1.1" xref="S3.SS3.SSS2.p1.3.m1.1.1.cmml"><mi id="S3.SS3.SSS2.p1.3.m1.1.1.3" xref="S3.SS3.SSS2.p1.3.m1.1.1.3.cmml">N</mi><mo id="S3.SS3.SSS2.p1.3.m1.1.1.2" xref="S3.SS3.SSS2.p1.3.m1.1.1.2.cmml">⁢</mo><mrow id="S3.SS3.SSS2.p1.3.m1.1.1.1.1" xref="S3.SS3.SSS2.p1.3.m1.1.1.1.1.1.cmml"><mo id="S3.SS3.SSS2.p1.3.m1.1.1.1.1.2" stretchy="false" xref="S3.SS3.SSS2.p1.3.m1.1.1.1.1.1.cmml">(</mo><msub id="S3.SS3.SSS2.p1.3.m1.1.1.1.1.1" xref="S3.SS3.SSS2.p1.3.m1.1.1.1.1.1.cmml"><mi id="S3.SS3.SSS2.p1.3.m1.1.1.1.1.1.2" xref="S3.SS3.SSS2.p1.3.m1.1.1.1.1.1.2.cmml">c</mi><mi id="S3.SS3.SSS2.p1.3.m1.1.1.1.1.1.3" xref="S3.SS3.SSS2.p1.3.m1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.SS3.SSS2.p1.3.m1.1.1.1.1.3" stretchy="false" xref="S3.SS3.SSS2.p1.3.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p1.3.m1.1b"><apply id="S3.SS3.SSS2.p1.3.m1.1.1.cmml" xref="S3.SS3.SSS2.p1.3.m1.1.1"><times id="S3.SS3.SSS2.p1.3.m1.1.1.2.cmml" xref="S3.SS3.SSS2.p1.3.m1.1.1.2"></times><ci id="S3.SS3.SSS2.p1.3.m1.1.1.3.cmml" xref="S3.SS3.SSS2.p1.3.m1.1.1.3">𝑁</ci><apply id="S3.SS3.SSS2.p1.3.m1.1.1.1.1.1.cmml" xref="S3.SS3.SSS2.p1.3.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS2.p1.3.m1.1.1.1.1.1.1.cmml" xref="S3.SS3.SSS2.p1.3.m1.1.1.1.1">subscript</csymbol><ci id="S3.SS3.SSS2.p1.3.m1.1.1.1.1.1.2.cmml" xref="S3.SS3.SSS2.p1.3.m1.1.1.1.1.1.2">𝑐</ci><ci id="S3.SS3.SSS2.p1.3.m1.1.1.1.1.1.3.cmml" xref="S3.SS3.SSS2.p1.3.m1.1.1.1.1.1.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p1.3.m1.1c">N(c_{i})</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.SSS2.p1.3.m1.1d">italic_N ( italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math> is the number of answers in the cluster <math alttext="c_{i}" class="ltx_Math" display="inline" id="S3.SS3.SSS2.p1.4.m2.1"><semantics id="S3.SS3.SSS2.p1.4.m2.1a"><msub id="S3.SS3.SSS2.p1.4.m2.1.1" xref="S3.SS3.SSS2.p1.4.m2.1.1.cmml"><mi id="S3.SS3.SSS2.p1.4.m2.1.1.2" xref="S3.SS3.SSS2.p1.4.m2.1.1.2.cmml">c</mi><mi id="S3.SS3.SSS2.p1.4.m2.1.1.3" xref="S3.SS3.SSS2.p1.4.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p1.4.m2.1b"><apply id="S3.SS3.SSS2.p1.4.m2.1.1.cmml" xref="S3.SS3.SSS2.p1.4.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS2.p1.4.m2.1.1.1.cmml" xref="S3.SS3.SSS2.p1.4.m2.1.1">subscript</csymbol><ci id="S3.SS3.SSS2.p1.4.m2.1.1.2.cmml" xref="S3.SS3.SSS2.p1.4.m2.1.1.2">𝑐</ci><ci id="S3.SS3.SSS2.p1.4.m2.1.1.3.cmml" xref="S3.SS3.SSS2.p1.4.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p1.4.m2.1c">c_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.SSS2.p1.4.m2.1d">italic_c start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>, and <math alttext="n" class="ltx_Math" display="inline" id="S3.SS3.SSS2.p1.5.m3.1"><semantics id="S3.SS3.SSS2.p1.5.m3.1a"><mi id="S3.SS3.SSS2.p1.5.m3.1.1" xref="S3.SS3.SSS2.p1.5.m3.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p1.5.m3.1b"><ci id="S3.SS3.SSS2.p1.5.m3.1.1.cmml" xref="S3.SS3.SSS2.p1.5.m3.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p1.5.m3.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.SSS2.p1.5.m3.1d">italic_n</annotation></semantics></math> is the number of paraphrases for question <math alttext="Q" class="ltx_Math" display="inline" id="S3.SS3.SSS2.p1.6.m4.1"><semantics id="S3.SS3.SSS2.p1.6.m4.1a"><mi id="S3.SS3.SSS2.p1.6.m4.1.1" xref="S3.SS3.SSS2.p1.6.m4.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p1.6.m4.1b"><ci id="S3.SS3.SSS2.p1.6.m4.1.1.cmml" xref="S3.SS3.SSS2.p1.6.m4.1.1">𝑄</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p1.6.m4.1c">Q</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.SSS2.p1.6.m4.1d">italic_Q</annotation></semantics></math>. In the experiments, we set <math alttext="n=7" class="ltx_Math" display="inline" id="S3.SS3.SSS2.p1.7.m5.1"><semantics id="S3.SS3.SSS2.p1.7.m5.1a"><mrow id="S3.SS3.SSS2.p1.7.m5.1.1" xref="S3.SS3.SSS2.p1.7.m5.1.1.cmml"><mi id="S3.SS3.SSS2.p1.7.m5.1.1.2" xref="S3.SS3.SSS2.p1.7.m5.1.1.2.cmml">n</mi><mo id="S3.SS3.SSS2.p1.7.m5.1.1.1" xref="S3.SS3.SSS2.p1.7.m5.1.1.1.cmml">=</mo><mn id="S3.SS3.SSS2.p1.7.m5.1.1.3" xref="S3.SS3.SSS2.p1.7.m5.1.1.3.cmml">7</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p1.7.m5.1b"><apply id="S3.SS3.SSS2.p1.7.m5.1.1.cmml" xref="S3.SS3.SSS2.p1.7.m5.1.1"><eq id="S3.SS3.SSS2.p1.7.m5.1.1.1.cmml" xref="S3.SS3.SSS2.p1.7.m5.1.1.1"></eq><ci id="S3.SS3.SSS2.p1.7.m5.1.1.2.cmml" xref="S3.SS3.SSS2.p1.7.m5.1.1.2">𝑛</ci><cn id="S3.SS3.SSS2.p1.7.m5.1.1.3.cmml" type="integer" xref="S3.SS3.SSS2.p1.7.m5.1.1.3">7</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p1.7.m5.1c">n=7</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.SSS2.p1.7.m5.1d">italic_n = 7</annotation></semantics></math> for all the questions in the NQ and popQA datasets. Memory strength reflects how well the LLM remembers the required knowledge: the weaker the memory, the more random and inconsistent the answers are.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S3.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>MA, CMA, and Evidence Generation</h3>
<section class="ltx_subsubsection" id="S3.SS4.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.4.1 </span>MA and CMA Generation</h4>
<div class="ltx_para" id="S3.SS4.SSS1.p1">
<p class="ltx_p" id="S3.SS4.SSS1.p1.1">For the popQA dataset, both MA and CMA are obtained following the method described in <cite class="ltx_cite ltx_citemacro_citet">Xie et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib32" title="">2024</a>)</cite>. For the MA of the NQ dataset, we also use a closed-book approach, similar to <cite class="ltx_cite ltx_citemacro_citet">Xie et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib32" title="">2024</a>)</cite>. While, the process for generating CMA differs.
Unlike the popQA dataset, the NQ dataset does not provide relation types for the questions or offer sets of subject and object entities for substitution.
To address this issue, we propose an approach using an LLM to substitute entities in MA to generate CMA. First, we identify which “wh-” question type<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>which refers to what, when, where, who, whom, which, whose, why, and how.</span></span></span> the question belongs to using string matching. Then, based on the question type, we determine the type of entity to be replaced in the MA. Finally, we use an LLM to make the substitution. For example, in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#S3.F1" title="Figure 1 ‣ 3 Methodology ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_tag">1</span></a>, the question “how many episodes…” is of the type “how_many”, so the entity to be replaced in the MA “there are 23 episodes…” should be a <span class="ltx_text ltx_font_italic" id="S3.SS4.SSS1.p1.1.1">NUMBER</span>. We let ChatGPT perform the substitution with an alternative entity. The prompt used is shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#A3.T9" title="Table 9 ‣ Appendix C Prompts ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_tag">9</span></a> (index 5). We have the detailed description for generating CMA in Appendex <a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#A2.SS1" title="B.1 CMA Generation for NQ dataset ‣ Appendix B Methodology and Experiment Details ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_tag">B.1</span></a>.</p>
</div>
<div class="ltx_para" id="S3.SS4.SSS1.p2">
<p class="ltx_p" id="S3.SS4.SSS1.p2.2"><span class="ltx_text ltx_font_bold" id="S3.SS4.SSS1.p2.2.1">CMA filter</span>. As noted in Section <a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#S3.SS3" title="3.3 Memory Strength ‣ 3 Methodology ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_tag">3.3</span></a>, LLMs can produce multiple MAs for the same question. To ensure the CMA conflicts with MAs, we require that the CMA is different from any of the answers <math alttext="\{A_{1},\cdots,A_{n}\}" class="ltx_Math" display="inline" id="S3.SS4.SSS1.p2.1.m1.3"><semantics id="S3.SS4.SSS1.p2.1.m1.3a"><mrow id="S3.SS4.SSS1.p2.1.m1.3.3.2" xref="S3.SS4.SSS1.p2.1.m1.3.3.3.cmml"><mo id="S3.SS4.SSS1.p2.1.m1.3.3.2.3" stretchy="false" xref="S3.SS4.SSS1.p2.1.m1.3.3.3.cmml">{</mo><msub id="S3.SS4.SSS1.p2.1.m1.2.2.1.1" xref="S3.SS4.SSS1.p2.1.m1.2.2.1.1.cmml"><mi id="S3.SS4.SSS1.p2.1.m1.2.2.1.1.2" xref="S3.SS4.SSS1.p2.1.m1.2.2.1.1.2.cmml">A</mi><mn id="S3.SS4.SSS1.p2.1.m1.2.2.1.1.3" xref="S3.SS4.SSS1.p2.1.m1.2.2.1.1.3.cmml">1</mn></msub><mo id="S3.SS4.SSS1.p2.1.m1.3.3.2.4" xref="S3.SS4.SSS1.p2.1.m1.3.3.3.cmml">,</mo><mi id="S3.SS4.SSS1.p2.1.m1.1.1" mathvariant="normal" xref="S3.SS4.SSS1.p2.1.m1.1.1.cmml">⋯</mi><mo id="S3.SS4.SSS1.p2.1.m1.3.3.2.5" xref="S3.SS4.SSS1.p2.1.m1.3.3.3.cmml">,</mo><msub id="S3.SS4.SSS1.p2.1.m1.3.3.2.2" xref="S3.SS4.SSS1.p2.1.m1.3.3.2.2.cmml"><mi id="S3.SS4.SSS1.p2.1.m1.3.3.2.2.2" xref="S3.SS4.SSS1.p2.1.m1.3.3.2.2.2.cmml">A</mi><mi id="S3.SS4.SSS1.p2.1.m1.3.3.2.2.3" xref="S3.SS4.SSS1.p2.1.m1.3.3.2.2.3.cmml">n</mi></msub><mo id="S3.SS4.SSS1.p2.1.m1.3.3.2.6" stretchy="false" xref="S3.SS4.SSS1.p2.1.m1.3.3.3.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS1.p2.1.m1.3b"><set id="S3.SS4.SSS1.p2.1.m1.3.3.3.cmml" xref="S3.SS4.SSS1.p2.1.m1.3.3.2"><apply id="S3.SS4.SSS1.p2.1.m1.2.2.1.1.cmml" xref="S3.SS4.SSS1.p2.1.m1.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS4.SSS1.p2.1.m1.2.2.1.1.1.cmml" xref="S3.SS4.SSS1.p2.1.m1.2.2.1.1">subscript</csymbol><ci id="S3.SS4.SSS1.p2.1.m1.2.2.1.1.2.cmml" xref="S3.SS4.SSS1.p2.1.m1.2.2.1.1.2">𝐴</ci><cn id="S3.SS4.SSS1.p2.1.m1.2.2.1.1.3.cmml" type="integer" xref="S3.SS4.SSS1.p2.1.m1.2.2.1.1.3">1</cn></apply><ci id="S3.SS4.SSS1.p2.1.m1.1.1.cmml" xref="S3.SS4.SSS1.p2.1.m1.1.1">⋯</ci><apply id="S3.SS4.SSS1.p2.1.m1.3.3.2.2.cmml" xref="S3.SS4.SSS1.p2.1.m1.3.3.2.2"><csymbol cd="ambiguous" id="S3.SS4.SSS1.p2.1.m1.3.3.2.2.1.cmml" xref="S3.SS4.SSS1.p2.1.m1.3.3.2.2">subscript</csymbol><ci id="S3.SS4.SSS1.p2.1.m1.3.3.2.2.2.cmml" xref="S3.SS4.SSS1.p2.1.m1.3.3.2.2.2">𝐴</ci><ci id="S3.SS4.SSS1.p2.1.m1.3.3.2.2.3.cmml" xref="S3.SS4.SSS1.p2.1.m1.3.3.2.2.3">𝑛</ci></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS1.p2.1.m1.3c">\{A_{1},\cdots,A_{n}\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS1.p2.1.m1.3d">{ italic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , ⋯ , italic_A start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT }</annotation></semantics></math> generated in Section <a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#S3.SS3.SSS1" title="3.3.1 Question Paraphrases and Answer Clustering ‣ 3.3 Memory Strength ‣ 3 Methodology ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_tag">3.3.1</span></a>, so the alternative entity should not appear in MAs. For the popQA dataset, the alternative entity is known. For NQ dataset, we first identify the alternative entity in the CMA by comparing the MA and CMA, and then check if this entity appears in any of the MAs <math alttext="\{A_{1},\cdots,A_{n}\}" class="ltx_Math" display="inline" id="S3.SS4.SSS1.p2.2.m2.3"><semantics id="S3.SS4.SSS1.p2.2.m2.3a"><mrow id="S3.SS4.SSS1.p2.2.m2.3.3.2" xref="S3.SS4.SSS1.p2.2.m2.3.3.3.cmml"><mo id="S3.SS4.SSS1.p2.2.m2.3.3.2.3" stretchy="false" xref="S3.SS4.SSS1.p2.2.m2.3.3.3.cmml">{</mo><msub id="S3.SS4.SSS1.p2.2.m2.2.2.1.1" xref="S3.SS4.SSS1.p2.2.m2.2.2.1.1.cmml"><mi id="S3.SS4.SSS1.p2.2.m2.2.2.1.1.2" xref="S3.SS4.SSS1.p2.2.m2.2.2.1.1.2.cmml">A</mi><mn id="S3.SS4.SSS1.p2.2.m2.2.2.1.1.3" xref="S3.SS4.SSS1.p2.2.m2.2.2.1.1.3.cmml">1</mn></msub><mo id="S3.SS4.SSS1.p2.2.m2.3.3.2.4" xref="S3.SS4.SSS1.p2.2.m2.3.3.3.cmml">,</mo><mi id="S3.SS4.SSS1.p2.2.m2.1.1" mathvariant="normal" xref="S3.SS4.SSS1.p2.2.m2.1.1.cmml">⋯</mi><mo id="S3.SS4.SSS1.p2.2.m2.3.3.2.5" xref="S3.SS4.SSS1.p2.2.m2.3.3.3.cmml">,</mo><msub id="S3.SS4.SSS1.p2.2.m2.3.3.2.2" xref="S3.SS4.SSS1.p2.2.m2.3.3.2.2.cmml"><mi id="S3.SS4.SSS1.p2.2.m2.3.3.2.2.2" xref="S3.SS4.SSS1.p2.2.m2.3.3.2.2.2.cmml">A</mi><mi id="S3.SS4.SSS1.p2.2.m2.3.3.2.2.3" xref="S3.SS4.SSS1.p2.2.m2.3.3.2.2.3.cmml">n</mi></msub><mo id="S3.SS4.SSS1.p2.2.m2.3.3.2.6" stretchy="false" xref="S3.SS4.SSS1.p2.2.m2.3.3.3.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS1.p2.2.m2.3b"><set id="S3.SS4.SSS1.p2.2.m2.3.3.3.cmml" xref="S3.SS4.SSS1.p2.2.m2.3.3.2"><apply id="S3.SS4.SSS1.p2.2.m2.2.2.1.1.cmml" xref="S3.SS4.SSS1.p2.2.m2.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS4.SSS1.p2.2.m2.2.2.1.1.1.cmml" xref="S3.SS4.SSS1.p2.2.m2.2.2.1.1">subscript</csymbol><ci id="S3.SS4.SSS1.p2.2.m2.2.2.1.1.2.cmml" xref="S3.SS4.SSS1.p2.2.m2.2.2.1.1.2">𝐴</ci><cn id="S3.SS4.SSS1.p2.2.m2.2.2.1.1.3.cmml" type="integer" xref="S3.SS4.SSS1.p2.2.m2.2.2.1.1.3">1</cn></apply><ci id="S3.SS4.SSS1.p2.2.m2.1.1.cmml" xref="S3.SS4.SSS1.p2.2.m2.1.1">⋯</ci><apply id="S3.SS4.SSS1.p2.2.m2.3.3.2.2.cmml" xref="S3.SS4.SSS1.p2.2.m2.3.3.2.2"><csymbol cd="ambiguous" id="S3.SS4.SSS1.p2.2.m2.3.3.2.2.1.cmml" xref="S3.SS4.SSS1.p2.2.m2.3.3.2.2">subscript</csymbol><ci id="S3.SS4.SSS1.p2.2.m2.3.3.2.2.2.cmml" xref="S3.SS4.SSS1.p2.2.m2.3.3.2.2.2">𝐴</ci><ci id="S3.SS4.SSS1.p2.2.m2.3.3.2.2.3.cmml" xref="S3.SS4.SSS1.p2.2.m2.3.3.2.2.3">𝑛</ci></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS1.p2.2.m2.3c">\{A_{1},\cdots,A_{n}\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS1.p2.2.m2.3d">{ italic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , ⋯ , italic_A start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT }</annotation></semantics></math>. We filter out data samples whose CMA does not conflict with MAs.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS4.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.4.2 </span>Evidence Generation</h4>
<div class="ltx_para" id="S3.SS4.SSS2.p1">
<p class="ltx_p" id="S3.SS4.SSS2.p1.1">In this section, we explain how to generate different styles of evidence. We classify evidence into two categories: direct evidence and indirect evidence.</p>
</div>
<div class="ltx_para" id="S3.SS4.SSS2.p2">
<p class="ltx_p" id="S3.SS4.SSS2.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS4.SSS2.p2.1.1">Direct evidence</span> is a semantically equivalent statement of the CMA, providing the clearest support for the claim made by the CMA. We generate the direct evidence by paraphrasing the CMA with ChatGPT, following the prompt shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#A3.T9" title="Table 9 ‣ Appendix C Prompts ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_tag">9</span></a> (index 6). For example, in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#S3.F1" title="Figure 1 ‣ 3 Methodology ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_tag">1</span></a>, the CMA “there are 15 episodes in Chicago Fire season 4” is paraphrased to “season 4 of Chicago Fire consists of a total of 15 episodes”. These two statements are semantically equivalent.</p>
</div>
<div class="ltx_para" id="S3.SS4.SSS2.p3">
<p class="ltx_p" id="S3.SS4.SSS2.p3.1">To ensure the reliability of the evidence, the evidence must mutually entail with the CMA. This entailment is verified using an NLI model <span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>https://huggingface.co/microsoft/deberta-v2-xxlarge-mnli</span></span></span>.
Direct evidence is intuitive, simple, and coherent, making it the straightforward type of evidence for the LLM to process. If the LLM is receptive to external evidence, it should be able to easily adopt direct evidence.</p>
</div>
<div class="ltx_para" id="S3.SS4.SSS2.p4">
<p class="ltx_p" id="S3.SS4.SSS2.p4.1"><span class="ltx_text ltx_font_bold" id="S3.SS4.SSS2.p4.1.1">Indirect evidence</span> differs from direct evidence by adding extra details that provide a more thorough description of the subject related to the CMA. This additional information makes the evidence more comprehensive and might be more persuasive. For example, in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#S3.F1" title="Figure 1 ‣ 3 Methodology ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_tag">1</span></a>, the indirect evidence includes details not found in the counter answer, such as the title of the first episode and its release date, along with the fact that there are 15 episodes in total. The prompt to generate indirect evidence is shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#A3.T9" title="Table 9 ‣ Appendix C Prompts ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_tag">9</span></a> (index 7).</p>
</div>
<div class="ltx_para" id="S3.SS4.SSS2.p5">
<p class="ltx_p" id="S3.SS4.SSS2.p5.1">To ensure the reliability of indirect evidence, the indirect evidence should entail the CMA, and the additional information introduced by the evidence should not entail the MA. Otherwise, the indirect evidence can support both the MA and CMA. The NLI model<sup class="ltx_sup" id="S3.SS4.SSS2.p5.1.1"><a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#footnote4" title="footnote 4 ‣ 3.4.2 Evidence Generation ‣ 3.4 MA, CMA, and Evidence Generation ‣ 3 Methodology ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_tag">4</span></a></sup> is used to verify that indirect evidence entailed with CMA and neutral or contradictory with MA.</p>
</div>
<div class="ltx_para" id="S3.SS4.SSS2.p6">
<p class="ltx_p" id="S3.SS4.SSS2.p6.1">For both direct and indirect evidence, if the content generated by the LLM does not meet the required conditions, we prompt the LLM to regenerate it up to five times. If it still fails after five attempts, we exclude that question from the dataset.</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">In this study, we aim to investigate two key research questions. 1) Whether memory strength has an impact on the context faithfulness of LLMs. 2) If the style of evidence affects the context faithfulness of LLMs. These research questions are explored in Section <a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#S4.SS2" title="4.2 Impact of Memory Strength ‣ 4 Experiments ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_tag">4.2</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#S4.SS3" title="4.3 Impact of Evidence Style ‣ 4 Experiments ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_tag">4.3</span></a>, respectively. We also provide additional studies in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#A1" title="Appendix A Additional Study ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_tag">A</span></a>, which includes a study about the impact of option order and a case study.</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Experiment Setup</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.p1.1.1">LLM Models.</span> Our experiments were conducted using four well-known language models: ChatGPT <cite class="ltx_cite ltx_citemacro_cite">OpenAI (<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib19" title="">2023a</a>)</cite>, GPT-4 <cite class="ltx_cite ltx_citemacro_cite">OpenAI (<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib20" title="">2023b</a>)</cite>, LLaMA2.7B, and LLaMA2.70B <cite class="ltx_cite ltx_citemacro_cite">Touvron et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib27" title="">2023</a>)</cite>. These models represent a diverse range of architectures and capabilities. ChatGPT and GPT-4 are cutting-edge models developed by OpenAI, with GPT-4 being the most advanced in terms of reasoning, accuracy, and contextual understanding. LLaMA2, with its 7 billion and 70 billion parameter variants, is a strong open-source alternative that has demonstrated competitive performance across a wide variety of tasks. The inclusion of models with varying scales (from 7B to 70B) and training methodologies allows us to explore both closed-source systems (GPT-4 and ChatGPT) and open-source solutions (LLaMA2).</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.2"><span class="ltx_text ltx_font_bold" id="S4.SS1.p2.2.1">Evaluation Metrics.</span> Following previous work <cite class="ltx_cite ltx_citemacro_cite">Longpre et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib16" title="">2021</a>); Xie et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib32" title="">2024</a>); Chen et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib2" title="">2022</a>)</cite>, we transform the free-form QA to a multiple-choice QA format by providing a few options as possible answers<span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><cite class="ltx_cite ltx_citemacro_citet">Xie et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib32" title="">2024</a>)</cite> shows that answer consistency between free-form and multi-choice are 94%, 96% and 92% for ChatGPT, GPT-4 and LLaMA2.7B, respectively.</span></span></span>. This limits the generation space and helps determine the answer provided by LLMs
with certainty. Specifically, for each question from both datasets, LLMs are instructed to select one
answer from MA, CMA, and “Uncertain” (UCT). We report the ratio of MA, CMA, and UCT, and the formulas are</p>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="A3.EGx1">
<tbody id="S4.Ex1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle R_{m}" class="ltx_Math" display="inline" id="S4.Ex1.m1.1"><semantics id="S4.Ex1.m1.1a"><msub id="S4.Ex1.m1.1.1" xref="S4.Ex1.m1.1.1.cmml"><mi id="S4.Ex1.m1.1.1.2" xref="S4.Ex1.m1.1.1.2.cmml">R</mi><mi id="S4.Ex1.m1.1.1.3" xref="S4.Ex1.m1.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="S4.Ex1.m1.1b"><apply id="S4.Ex1.m1.1.1.cmml" xref="S4.Ex1.m1.1.1"><csymbol cd="ambiguous" id="S4.Ex1.m1.1.1.1.cmml" xref="S4.Ex1.m1.1.1">subscript</csymbol><ci id="S4.Ex1.m1.1.1.2.cmml" xref="S4.Ex1.m1.1.1.2">𝑅</ci><ci id="S4.Ex1.m1.1.1.3.cmml" xref="S4.Ex1.m1.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.Ex1.m1.1c">\displaystyle R_{m}</annotation><annotation encoding="application/x-llamapun" id="S4.Ex1.m1.1d">italic_R start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=\frac{f_{m}}{f_{m}+f_{c}+f_{u}}" class="ltx_Math" display="inline" id="S4.Ex1.m2.1"><semantics id="S4.Ex1.m2.1a"><mrow id="S4.Ex1.m2.1.1" xref="S4.Ex1.m2.1.1.cmml"><mi id="S4.Ex1.m2.1.1.2" xref="S4.Ex1.m2.1.1.2.cmml"></mi><mo id="S4.Ex1.m2.1.1.1" xref="S4.Ex1.m2.1.1.1.cmml">=</mo><mstyle displaystyle="true" id="S4.Ex1.m2.1.1.3" xref="S4.Ex1.m2.1.1.3.cmml"><mfrac id="S4.Ex1.m2.1.1.3a" xref="S4.Ex1.m2.1.1.3.cmml"><msub id="S4.Ex1.m2.1.1.3.2" xref="S4.Ex1.m2.1.1.3.2.cmml"><mi id="S4.Ex1.m2.1.1.3.2.2" xref="S4.Ex1.m2.1.1.3.2.2.cmml">f</mi><mi id="S4.Ex1.m2.1.1.3.2.3" xref="S4.Ex1.m2.1.1.3.2.3.cmml">m</mi></msub><mrow id="S4.Ex1.m2.1.1.3.3" xref="S4.Ex1.m2.1.1.3.3.cmml"><msub id="S4.Ex1.m2.1.1.3.3.2" xref="S4.Ex1.m2.1.1.3.3.2.cmml"><mi id="S4.Ex1.m2.1.1.3.3.2.2" xref="S4.Ex1.m2.1.1.3.3.2.2.cmml">f</mi><mi id="S4.Ex1.m2.1.1.3.3.2.3" xref="S4.Ex1.m2.1.1.3.3.2.3.cmml">m</mi></msub><mo id="S4.Ex1.m2.1.1.3.3.1" xref="S4.Ex1.m2.1.1.3.3.1.cmml">+</mo><msub id="S4.Ex1.m2.1.1.3.3.3" xref="S4.Ex1.m2.1.1.3.3.3.cmml"><mi id="S4.Ex1.m2.1.1.3.3.3.2" xref="S4.Ex1.m2.1.1.3.3.3.2.cmml">f</mi><mi id="S4.Ex1.m2.1.1.3.3.3.3" xref="S4.Ex1.m2.1.1.3.3.3.3.cmml">c</mi></msub><mo id="S4.Ex1.m2.1.1.3.3.1a" xref="S4.Ex1.m2.1.1.3.3.1.cmml">+</mo><msub id="S4.Ex1.m2.1.1.3.3.4" xref="S4.Ex1.m2.1.1.3.3.4.cmml"><mi id="S4.Ex1.m2.1.1.3.3.4.2" xref="S4.Ex1.m2.1.1.3.3.4.2.cmml">f</mi><mi id="S4.Ex1.m2.1.1.3.3.4.3" xref="S4.Ex1.m2.1.1.3.3.4.3.cmml">u</mi></msub></mrow></mfrac></mstyle></mrow><annotation-xml encoding="MathML-Content" id="S4.Ex1.m2.1b"><apply id="S4.Ex1.m2.1.1.cmml" xref="S4.Ex1.m2.1.1"><eq id="S4.Ex1.m2.1.1.1.cmml" xref="S4.Ex1.m2.1.1.1"></eq><csymbol cd="latexml" id="S4.Ex1.m2.1.1.2.cmml" xref="S4.Ex1.m2.1.1.2">absent</csymbol><apply id="S4.Ex1.m2.1.1.3.cmml" xref="S4.Ex1.m2.1.1.3"><divide id="S4.Ex1.m2.1.1.3.1.cmml" xref="S4.Ex1.m2.1.1.3"></divide><apply id="S4.Ex1.m2.1.1.3.2.cmml" xref="S4.Ex1.m2.1.1.3.2"><csymbol cd="ambiguous" id="S4.Ex1.m2.1.1.3.2.1.cmml" xref="S4.Ex1.m2.1.1.3.2">subscript</csymbol><ci id="S4.Ex1.m2.1.1.3.2.2.cmml" xref="S4.Ex1.m2.1.1.3.2.2">𝑓</ci><ci id="S4.Ex1.m2.1.1.3.2.3.cmml" xref="S4.Ex1.m2.1.1.3.2.3">𝑚</ci></apply><apply id="S4.Ex1.m2.1.1.3.3.cmml" xref="S4.Ex1.m2.1.1.3.3"><plus id="S4.Ex1.m2.1.1.3.3.1.cmml" xref="S4.Ex1.m2.1.1.3.3.1"></plus><apply id="S4.Ex1.m2.1.1.3.3.2.cmml" xref="S4.Ex1.m2.1.1.3.3.2"><csymbol cd="ambiguous" id="S4.Ex1.m2.1.1.3.3.2.1.cmml" xref="S4.Ex1.m2.1.1.3.3.2">subscript</csymbol><ci id="S4.Ex1.m2.1.1.3.3.2.2.cmml" xref="S4.Ex1.m2.1.1.3.3.2.2">𝑓</ci><ci id="S4.Ex1.m2.1.1.3.3.2.3.cmml" xref="S4.Ex1.m2.1.1.3.3.2.3">𝑚</ci></apply><apply id="S4.Ex1.m2.1.1.3.3.3.cmml" xref="S4.Ex1.m2.1.1.3.3.3"><csymbol cd="ambiguous" id="S4.Ex1.m2.1.1.3.3.3.1.cmml" xref="S4.Ex1.m2.1.1.3.3.3">subscript</csymbol><ci id="S4.Ex1.m2.1.1.3.3.3.2.cmml" xref="S4.Ex1.m2.1.1.3.3.3.2">𝑓</ci><ci id="S4.Ex1.m2.1.1.3.3.3.3.cmml" xref="S4.Ex1.m2.1.1.3.3.3.3">𝑐</ci></apply><apply id="S4.Ex1.m2.1.1.3.3.4.cmml" xref="S4.Ex1.m2.1.1.3.3.4"><csymbol cd="ambiguous" id="S4.Ex1.m2.1.1.3.3.4.1.cmml" xref="S4.Ex1.m2.1.1.3.3.4">subscript</csymbol><ci id="S4.Ex1.m2.1.1.3.3.4.2.cmml" xref="S4.Ex1.m2.1.1.3.3.4.2">𝑓</ci><ci id="S4.Ex1.m2.1.1.3.3.4.3.cmml" xref="S4.Ex1.m2.1.1.3.3.4.3">𝑢</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.Ex1.m2.1c">\displaystyle=\frac{f_{m}}{f_{m}+f_{c}+f_{u}}</annotation><annotation encoding="application/x-llamapun" id="S4.Ex1.m2.1d">= divide start_ARG italic_f start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT end_ARG start_ARG italic_f start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT + italic_f start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT + italic_f start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="S4.Ex2"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle R_{c}" class="ltx_Math" display="inline" id="S4.Ex2.m1.1"><semantics id="S4.Ex2.m1.1a"><msub id="S4.Ex2.m1.1.1" xref="S4.Ex2.m1.1.1.cmml"><mi id="S4.Ex2.m1.1.1.2" xref="S4.Ex2.m1.1.1.2.cmml">R</mi><mi id="S4.Ex2.m1.1.1.3" xref="S4.Ex2.m1.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S4.Ex2.m1.1b"><apply id="S4.Ex2.m1.1.1.cmml" xref="S4.Ex2.m1.1.1"><csymbol cd="ambiguous" id="S4.Ex2.m1.1.1.1.cmml" xref="S4.Ex2.m1.1.1">subscript</csymbol><ci id="S4.Ex2.m1.1.1.2.cmml" xref="S4.Ex2.m1.1.1.2">𝑅</ci><ci id="S4.Ex2.m1.1.1.3.cmml" xref="S4.Ex2.m1.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.Ex2.m1.1c">\displaystyle R_{c}</annotation><annotation encoding="application/x-llamapun" id="S4.Ex2.m1.1d">italic_R start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=\frac{f_{c}}{f_{m}+f_{c}+f_{u}}" class="ltx_Math" display="inline" id="S4.Ex2.m2.1"><semantics id="S4.Ex2.m2.1a"><mrow id="S4.Ex2.m2.1.1" xref="S4.Ex2.m2.1.1.cmml"><mi id="S4.Ex2.m2.1.1.2" xref="S4.Ex2.m2.1.1.2.cmml"></mi><mo id="S4.Ex2.m2.1.1.1" xref="S4.Ex2.m2.1.1.1.cmml">=</mo><mstyle displaystyle="true" id="S4.Ex2.m2.1.1.3" xref="S4.Ex2.m2.1.1.3.cmml"><mfrac id="S4.Ex2.m2.1.1.3a" xref="S4.Ex2.m2.1.1.3.cmml"><msub id="S4.Ex2.m2.1.1.3.2" xref="S4.Ex2.m2.1.1.3.2.cmml"><mi id="S4.Ex2.m2.1.1.3.2.2" xref="S4.Ex2.m2.1.1.3.2.2.cmml">f</mi><mi id="S4.Ex2.m2.1.1.3.2.3" xref="S4.Ex2.m2.1.1.3.2.3.cmml">c</mi></msub><mrow id="S4.Ex2.m2.1.1.3.3" xref="S4.Ex2.m2.1.1.3.3.cmml"><msub id="S4.Ex2.m2.1.1.3.3.2" xref="S4.Ex2.m2.1.1.3.3.2.cmml"><mi id="S4.Ex2.m2.1.1.3.3.2.2" xref="S4.Ex2.m2.1.1.3.3.2.2.cmml">f</mi><mi id="S4.Ex2.m2.1.1.3.3.2.3" xref="S4.Ex2.m2.1.1.3.3.2.3.cmml">m</mi></msub><mo id="S4.Ex2.m2.1.1.3.3.1" xref="S4.Ex2.m2.1.1.3.3.1.cmml">+</mo><msub id="S4.Ex2.m2.1.1.3.3.3" xref="S4.Ex2.m2.1.1.3.3.3.cmml"><mi id="S4.Ex2.m2.1.1.3.3.3.2" xref="S4.Ex2.m2.1.1.3.3.3.2.cmml">f</mi><mi id="S4.Ex2.m2.1.1.3.3.3.3" xref="S4.Ex2.m2.1.1.3.3.3.3.cmml">c</mi></msub><mo id="S4.Ex2.m2.1.1.3.3.1a" xref="S4.Ex2.m2.1.1.3.3.1.cmml">+</mo><msub id="S4.Ex2.m2.1.1.3.3.4" xref="S4.Ex2.m2.1.1.3.3.4.cmml"><mi id="S4.Ex2.m2.1.1.3.3.4.2" xref="S4.Ex2.m2.1.1.3.3.4.2.cmml">f</mi><mi id="S4.Ex2.m2.1.1.3.3.4.3" xref="S4.Ex2.m2.1.1.3.3.4.3.cmml">u</mi></msub></mrow></mfrac></mstyle></mrow><annotation-xml encoding="MathML-Content" id="S4.Ex2.m2.1b"><apply id="S4.Ex2.m2.1.1.cmml" xref="S4.Ex2.m2.1.1"><eq id="S4.Ex2.m2.1.1.1.cmml" xref="S4.Ex2.m2.1.1.1"></eq><csymbol cd="latexml" id="S4.Ex2.m2.1.1.2.cmml" xref="S4.Ex2.m2.1.1.2">absent</csymbol><apply id="S4.Ex2.m2.1.1.3.cmml" xref="S4.Ex2.m2.1.1.3"><divide id="S4.Ex2.m2.1.1.3.1.cmml" xref="S4.Ex2.m2.1.1.3"></divide><apply id="S4.Ex2.m2.1.1.3.2.cmml" xref="S4.Ex2.m2.1.1.3.2"><csymbol cd="ambiguous" id="S4.Ex2.m2.1.1.3.2.1.cmml" xref="S4.Ex2.m2.1.1.3.2">subscript</csymbol><ci id="S4.Ex2.m2.1.1.3.2.2.cmml" xref="S4.Ex2.m2.1.1.3.2.2">𝑓</ci><ci id="S4.Ex2.m2.1.1.3.2.3.cmml" xref="S4.Ex2.m2.1.1.3.2.3">𝑐</ci></apply><apply id="S4.Ex2.m2.1.1.3.3.cmml" xref="S4.Ex2.m2.1.1.3.3"><plus id="S4.Ex2.m2.1.1.3.3.1.cmml" xref="S4.Ex2.m2.1.1.3.3.1"></plus><apply id="S4.Ex2.m2.1.1.3.3.2.cmml" xref="S4.Ex2.m2.1.1.3.3.2"><csymbol cd="ambiguous" id="S4.Ex2.m2.1.1.3.3.2.1.cmml" xref="S4.Ex2.m2.1.1.3.3.2">subscript</csymbol><ci id="S4.Ex2.m2.1.1.3.3.2.2.cmml" xref="S4.Ex2.m2.1.1.3.3.2.2">𝑓</ci><ci id="S4.Ex2.m2.1.1.3.3.2.3.cmml" xref="S4.Ex2.m2.1.1.3.3.2.3">𝑚</ci></apply><apply id="S4.Ex2.m2.1.1.3.3.3.cmml" xref="S4.Ex2.m2.1.1.3.3.3"><csymbol cd="ambiguous" id="S4.Ex2.m2.1.1.3.3.3.1.cmml" xref="S4.Ex2.m2.1.1.3.3.3">subscript</csymbol><ci id="S4.Ex2.m2.1.1.3.3.3.2.cmml" xref="S4.Ex2.m2.1.1.3.3.3.2">𝑓</ci><ci id="S4.Ex2.m2.1.1.3.3.3.3.cmml" xref="S4.Ex2.m2.1.1.3.3.3.3">𝑐</ci></apply><apply id="S4.Ex2.m2.1.1.3.3.4.cmml" xref="S4.Ex2.m2.1.1.3.3.4"><csymbol cd="ambiguous" id="S4.Ex2.m2.1.1.3.3.4.1.cmml" xref="S4.Ex2.m2.1.1.3.3.4">subscript</csymbol><ci id="S4.Ex2.m2.1.1.3.3.4.2.cmml" xref="S4.Ex2.m2.1.1.3.3.4.2">𝑓</ci><ci id="S4.Ex2.m2.1.1.3.3.4.3.cmml" xref="S4.Ex2.m2.1.1.3.3.4.3">𝑢</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.Ex2.m2.1c">\displaystyle=\frac{f_{c}}{f_{m}+f_{c}+f_{u}}</annotation><annotation encoding="application/x-llamapun" id="S4.Ex2.m2.1d">= divide start_ARG italic_f start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT end_ARG start_ARG italic_f start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT + italic_f start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT + italic_f start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="S4.E2"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle R_{u}" class="ltx_Math" display="inline" id="S4.E2.m1.1"><semantics id="S4.E2.m1.1a"><msub id="S4.E2.m1.1.1" xref="S4.E2.m1.1.1.cmml"><mi id="S4.E2.m1.1.1.2" xref="S4.E2.m1.1.1.2.cmml">R</mi><mi id="S4.E2.m1.1.1.3" xref="S4.E2.m1.1.1.3.cmml">u</mi></msub><annotation-xml encoding="MathML-Content" id="S4.E2.m1.1b"><apply id="S4.E2.m1.1.1.cmml" xref="S4.E2.m1.1.1"><csymbol cd="ambiguous" id="S4.E2.m1.1.1.1.cmml" xref="S4.E2.m1.1.1">subscript</csymbol><ci id="S4.E2.m1.1.1.2.cmml" xref="S4.E2.m1.1.1.2">𝑅</ci><ci id="S4.E2.m1.1.1.3.cmml" xref="S4.E2.m1.1.1.3">𝑢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E2.m1.1c">\displaystyle R_{u}</annotation><annotation encoding="application/x-llamapun" id="S4.E2.m1.1d">italic_R start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=\frac{f_{u}}{f_{m}+f_{c}+f_{u}}," class="ltx_Math" display="inline" id="S4.E2.m2.1"><semantics id="S4.E2.m2.1a"><mrow id="S4.E2.m2.1.1.1" xref="S4.E2.m2.1.1.1.1.cmml"><mrow id="S4.E2.m2.1.1.1.1" xref="S4.E2.m2.1.1.1.1.cmml"><mi id="S4.E2.m2.1.1.1.1.2" xref="S4.E2.m2.1.1.1.1.2.cmml"></mi><mo id="S4.E2.m2.1.1.1.1.1" xref="S4.E2.m2.1.1.1.1.1.cmml">=</mo><mstyle displaystyle="true" id="S4.E2.m2.1.1.1.1.3" xref="S4.E2.m2.1.1.1.1.3.cmml"><mfrac id="S4.E2.m2.1.1.1.1.3a" xref="S4.E2.m2.1.1.1.1.3.cmml"><msub id="S4.E2.m2.1.1.1.1.3.2" xref="S4.E2.m2.1.1.1.1.3.2.cmml"><mi id="S4.E2.m2.1.1.1.1.3.2.2" xref="S4.E2.m2.1.1.1.1.3.2.2.cmml">f</mi><mi id="S4.E2.m2.1.1.1.1.3.2.3" xref="S4.E2.m2.1.1.1.1.3.2.3.cmml">u</mi></msub><mrow id="S4.E2.m2.1.1.1.1.3.3" xref="S4.E2.m2.1.1.1.1.3.3.cmml"><msub id="S4.E2.m2.1.1.1.1.3.3.2" xref="S4.E2.m2.1.1.1.1.3.3.2.cmml"><mi id="S4.E2.m2.1.1.1.1.3.3.2.2" xref="S4.E2.m2.1.1.1.1.3.3.2.2.cmml">f</mi><mi id="S4.E2.m2.1.1.1.1.3.3.2.3" xref="S4.E2.m2.1.1.1.1.3.3.2.3.cmml">m</mi></msub><mo id="S4.E2.m2.1.1.1.1.3.3.1" xref="S4.E2.m2.1.1.1.1.3.3.1.cmml">+</mo><msub id="S4.E2.m2.1.1.1.1.3.3.3" xref="S4.E2.m2.1.1.1.1.3.3.3.cmml"><mi id="S4.E2.m2.1.1.1.1.3.3.3.2" xref="S4.E2.m2.1.1.1.1.3.3.3.2.cmml">f</mi><mi id="S4.E2.m2.1.1.1.1.3.3.3.3" xref="S4.E2.m2.1.1.1.1.3.3.3.3.cmml">c</mi></msub><mo id="S4.E2.m2.1.1.1.1.3.3.1a" xref="S4.E2.m2.1.1.1.1.3.3.1.cmml">+</mo><msub id="S4.E2.m2.1.1.1.1.3.3.4" xref="S4.E2.m2.1.1.1.1.3.3.4.cmml"><mi id="S4.E2.m2.1.1.1.1.3.3.4.2" xref="S4.E2.m2.1.1.1.1.3.3.4.2.cmml">f</mi><mi id="S4.E2.m2.1.1.1.1.3.3.4.3" xref="S4.E2.m2.1.1.1.1.3.3.4.3.cmml">u</mi></msub></mrow></mfrac></mstyle></mrow><mo id="S4.E2.m2.1.1.1.2" xref="S4.E2.m2.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E2.m2.1b"><apply id="S4.E2.m2.1.1.1.1.cmml" xref="S4.E2.m2.1.1.1"><eq id="S4.E2.m2.1.1.1.1.1.cmml" xref="S4.E2.m2.1.1.1.1.1"></eq><csymbol cd="latexml" id="S4.E2.m2.1.1.1.1.2.cmml" xref="S4.E2.m2.1.1.1.1.2">absent</csymbol><apply id="S4.E2.m2.1.1.1.1.3.cmml" xref="S4.E2.m2.1.1.1.1.3"><divide id="S4.E2.m2.1.1.1.1.3.1.cmml" xref="S4.E2.m2.1.1.1.1.3"></divide><apply id="S4.E2.m2.1.1.1.1.3.2.cmml" xref="S4.E2.m2.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S4.E2.m2.1.1.1.1.3.2.1.cmml" xref="S4.E2.m2.1.1.1.1.3.2">subscript</csymbol><ci id="S4.E2.m2.1.1.1.1.3.2.2.cmml" xref="S4.E2.m2.1.1.1.1.3.2.2">𝑓</ci><ci id="S4.E2.m2.1.1.1.1.3.2.3.cmml" xref="S4.E2.m2.1.1.1.1.3.2.3">𝑢</ci></apply><apply id="S4.E2.m2.1.1.1.1.3.3.cmml" xref="S4.E2.m2.1.1.1.1.3.3"><plus id="S4.E2.m2.1.1.1.1.3.3.1.cmml" xref="S4.E2.m2.1.1.1.1.3.3.1"></plus><apply id="S4.E2.m2.1.1.1.1.3.3.2.cmml" xref="S4.E2.m2.1.1.1.1.3.3.2"><csymbol cd="ambiguous" id="S4.E2.m2.1.1.1.1.3.3.2.1.cmml" xref="S4.E2.m2.1.1.1.1.3.3.2">subscript</csymbol><ci id="S4.E2.m2.1.1.1.1.3.3.2.2.cmml" xref="S4.E2.m2.1.1.1.1.3.3.2.2">𝑓</ci><ci id="S4.E2.m2.1.1.1.1.3.3.2.3.cmml" xref="S4.E2.m2.1.1.1.1.3.3.2.3">𝑚</ci></apply><apply id="S4.E2.m2.1.1.1.1.3.3.3.cmml" xref="S4.E2.m2.1.1.1.1.3.3.3"><csymbol cd="ambiguous" id="S4.E2.m2.1.1.1.1.3.3.3.1.cmml" xref="S4.E2.m2.1.1.1.1.3.3.3">subscript</csymbol><ci id="S4.E2.m2.1.1.1.1.3.3.3.2.cmml" xref="S4.E2.m2.1.1.1.1.3.3.3.2">𝑓</ci><ci id="S4.E2.m2.1.1.1.1.3.3.3.3.cmml" xref="S4.E2.m2.1.1.1.1.3.3.3.3">𝑐</ci></apply><apply id="S4.E2.m2.1.1.1.1.3.3.4.cmml" xref="S4.E2.m2.1.1.1.1.3.3.4"><csymbol cd="ambiguous" id="S4.E2.m2.1.1.1.1.3.3.4.1.cmml" xref="S4.E2.m2.1.1.1.1.3.3.4">subscript</csymbol><ci id="S4.E2.m2.1.1.1.1.3.3.4.2.cmml" xref="S4.E2.m2.1.1.1.1.3.3.4.2">𝑓</ci><ci id="S4.E2.m2.1.1.1.1.3.3.4.3.cmml" xref="S4.E2.m2.1.1.1.1.3.3.4.3">𝑢</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E2.m2.1c">\displaystyle=\frac{f_{u}}{f_{m}+f_{c}+f_{u}},</annotation><annotation encoding="application/x-llamapun" id="S4.E2.m2.1d">= divide start_ARG italic_f start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT end_ARG start_ARG italic_f start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT + italic_f start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT + italic_f start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT end_ARG ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S4.SS1.p2.1">where <math alttext="f_{m},f_{c},f_{u}" class="ltx_Math" display="inline" id="S4.SS1.p2.1.m1.3"><semantics id="S4.SS1.p2.1.m1.3a"><mrow id="S4.SS1.p2.1.m1.3.3.3" xref="S4.SS1.p2.1.m1.3.3.4.cmml"><msub id="S4.SS1.p2.1.m1.1.1.1.1" xref="S4.SS1.p2.1.m1.1.1.1.1.cmml"><mi id="S4.SS1.p2.1.m1.1.1.1.1.2" xref="S4.SS1.p2.1.m1.1.1.1.1.2.cmml">f</mi><mi id="S4.SS1.p2.1.m1.1.1.1.1.3" xref="S4.SS1.p2.1.m1.1.1.1.1.3.cmml">m</mi></msub><mo id="S4.SS1.p2.1.m1.3.3.3.4" xref="S4.SS1.p2.1.m1.3.3.4.cmml">,</mo><msub id="S4.SS1.p2.1.m1.2.2.2.2" xref="S4.SS1.p2.1.m1.2.2.2.2.cmml"><mi id="S4.SS1.p2.1.m1.2.2.2.2.2" xref="S4.SS1.p2.1.m1.2.2.2.2.2.cmml">f</mi><mi id="S4.SS1.p2.1.m1.2.2.2.2.3" xref="S4.SS1.p2.1.m1.2.2.2.2.3.cmml">c</mi></msub><mo id="S4.SS1.p2.1.m1.3.3.3.5" xref="S4.SS1.p2.1.m1.3.3.4.cmml">,</mo><msub id="S4.SS1.p2.1.m1.3.3.3.3" xref="S4.SS1.p2.1.m1.3.3.3.3.cmml"><mi id="S4.SS1.p2.1.m1.3.3.3.3.2" xref="S4.SS1.p2.1.m1.3.3.3.3.2.cmml">f</mi><mi id="S4.SS1.p2.1.m1.3.3.3.3.3" xref="S4.SS1.p2.1.m1.3.3.3.3.3.cmml">u</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.3b"><list id="S4.SS1.p2.1.m1.3.3.4.cmml" xref="S4.SS1.p2.1.m1.3.3.3"><apply id="S4.SS1.p2.1.m1.1.1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.1.m1.1.1.1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1.1.1">subscript</csymbol><ci id="S4.SS1.p2.1.m1.1.1.1.1.2.cmml" xref="S4.SS1.p2.1.m1.1.1.1.1.2">𝑓</ci><ci id="S4.SS1.p2.1.m1.1.1.1.1.3.cmml" xref="S4.SS1.p2.1.m1.1.1.1.1.3">𝑚</ci></apply><apply id="S4.SS1.p2.1.m1.2.2.2.2.cmml" xref="S4.SS1.p2.1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S4.SS1.p2.1.m1.2.2.2.2.1.cmml" xref="S4.SS1.p2.1.m1.2.2.2.2">subscript</csymbol><ci id="S4.SS1.p2.1.m1.2.2.2.2.2.cmml" xref="S4.SS1.p2.1.m1.2.2.2.2.2">𝑓</ci><ci id="S4.SS1.p2.1.m1.2.2.2.2.3.cmml" xref="S4.SS1.p2.1.m1.2.2.2.2.3">𝑐</ci></apply><apply id="S4.SS1.p2.1.m1.3.3.3.3.cmml" xref="S4.SS1.p2.1.m1.3.3.3.3"><csymbol cd="ambiguous" id="S4.SS1.p2.1.m1.3.3.3.3.1.cmml" xref="S4.SS1.p2.1.m1.3.3.3.3">subscript</csymbol><ci id="S4.SS1.p2.1.m1.3.3.3.3.2.cmml" xref="S4.SS1.p2.1.m1.3.3.3.3.2">𝑓</ci><ci id="S4.SS1.p2.1.m1.3.3.3.3.3.cmml" xref="S4.SS1.p2.1.m1.3.3.3.3.3">𝑢</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.1.m1.3c">f_{m},f_{c},f_{u}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p2.1.m1.3d">italic_f start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT , italic_f start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT , italic_f start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT</annotation></semantics></math> are the count of questions with MA, CMA, and UCT answers, respectively.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Impact of Memory Strength</h3>
<section class="ltx_subsubsection" id="S4.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.1 </span>Memory Strength on Different Datasets</h4>
<figure class="ltx_figure" id="S4.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="195" id="S4.F2.g1" src="extracted/5859889/fig/memory_strength_distribution.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Memory Strength Distribution Across popQA and NQ Datasets. Each dataset is classified into 8 bins. The x-axis shows the range of memory strength for each bin. The y-axis shows the question count in each bin. The NQ dataset exhibits higher overall memory strength. Additionally, larger models (e.g., GPT-4) show stronger memory strength compared to smaller models.</figcaption>
</figure>
<figure class="ltx_figure" id="S4.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="244" id="S4.F3.g1" src="extracted/5859889/fig/ratio_on_memory_strength_removed.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Relationship between Memory Strength and Answer Ratio across popQA and NQ datasets (with Direct Evidence).
The figure presents the ratio and count of MA, CMA, and UCT across four memory strength groups: low(lo), mid-low(ml), mid-high(mh), and high(hi). The results show a clear positive correlation between memory strength and MA ratio(<math alttext="R_{m}" class="ltx_Math" display="inline" id="S4.F3.2.m1.1"><semantics id="S4.F3.2.m1.1b"><msub id="S4.F3.2.m1.1.1" xref="S4.F3.2.m1.1.1.cmml"><mi id="S4.F3.2.m1.1.1.2" xref="S4.F3.2.m1.1.1.2.cmml">R</mi><mi id="S4.F3.2.m1.1.1.3" xref="S4.F3.2.m1.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="S4.F3.2.m1.1c"><apply id="S4.F3.2.m1.1.1.cmml" xref="S4.F3.2.m1.1.1"><csymbol cd="ambiguous" id="S4.F3.2.m1.1.1.1.cmml" xref="S4.F3.2.m1.1.1">subscript</csymbol><ci id="S4.F3.2.m1.1.1.2.cmml" xref="S4.F3.2.m1.1.1.2">𝑅</ci><ci id="S4.F3.2.m1.1.1.3.cmml" xref="S4.F3.2.m1.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F3.2.m1.1d">R_{m}</annotation><annotation encoding="application/x-llamapun" id="S4.F3.2.m1.1e">italic_R start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT</annotation></semantics></math>).</figcaption>
</figure>
<div class="ltx_para" id="S4.SS2.SSS1.p1">
<p class="ltx_p" id="S4.SS2.SSS1.p1.1">We first illustrate the distributions of memory strength across the popQA and NQ datasets for LLaMA2.7B, LLaMA2.70B, ChatGPT, and GPT-4, respectively (shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#S4.F2" title="Figure 2 ‣ 4.2.1 Memory Strength on Different Datasets ‣ 4.2 Impact of Memory Strength ‣ 4 Experiments ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_tag">2</span></a>). From the analysis, two key insights can be drawn.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS1.p2">
<p class="ltx_p" id="S4.SS2.SSS1.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.SSS1.p2.1.1">LLMs demonstrate stronger memory for the NQ dataset than the popQA dataset.</span> For the NQ dataset, most questions fall within the bin of (0.25, 0]. Only a few questions fall within bins of weaker memory strength. In contrast, the popQA dataset has a greater number of questions in bins with weaker memory strength. This phenomenon is consistent across all four evaluated LLMs, indicating that the LLMs exhibit stronger memory strength for the NQ dataset compared to the PopQA dataset. A possible explanation is that the NQ dataset covers more commonly discussed subjects than those in the PopQA dataset. These subjects may have been encountered more frequently during the training of the LLMs, making it easier for the models to recall the information and resulting in stronger memory strength.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS1.p3">
<p class="ltx_p" id="S4.SS2.SSS1.p3.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.SSS1.p3.1.1">Memory Strength Increases with Model Scale.</span> There is a clear trend that larger LLMs, such as GPT-4, demonstrate significantly higher memory strength compared to smaller models, such as LLaMA2.7B. It means larger models are more likely to provide consistent answers to paraphrased questions. This observation aligns with the common intuition that larger LLMs with more parameters have more memory than smaller LLMs.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS2.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.2 </span>Context-Faithfulness with Memory Strength</h4>
<div class="ltx_para" id="S4.SS2.SSS2.p1">
<p class="ltx_p" id="S4.SS2.SSS2.p1.1">To demonstrate the relationship between context-faithfulness and memory strength, we categorize the questions in each dataset into four groups according to memory strength for each LLM. The four groups are low, mid-low, mid-high, and high, corresponding to the memory strength intervals [-2, -1], (-1, -0.5], (-0.5, -0.25] and [-0.25, 0], respectively. We use the direct evidence. The results are shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#S4.F3" title="Figure 3 ‣ 4.2.1 Memory Strength on Different Datasets ‣ 4.2 Impact of Memory Strength ‣ 4 Experiments ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_tag">3</span></a><span class="ltx_note ltx_role_footnote" id="footnote6"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span>We put results for other evidence styles in Appendix, Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#A2.F6" title="Figure 6 ‣ B.4 Impact of Memory Strength with Different Evidence Styles ‣ Appendix B Methodology and Experiment Details ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_tag">6</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#A2.F7" title="Figure 7 ‣ B.4 Impact of Memory Strength with Different Evidence Styles ‣ Appendix B Methodology and Experiment Details ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_tag">7</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#A2.F8" title="Figure 8 ‣ B.4 Impact of Memory Strength with Different Evidence Styles ‣ Appendix B Methodology and Experiment Details ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_tag">8</span></a>. The conclusion is consistent.</span></span></span>. Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#S4.F3" title="Figure 3 ‣ 4.2.1 Memory Strength on Different Datasets ‣ 4.2 Impact of Memory Strength ‣ 4 Experiments ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_tag">3</span></a> (a)(b) shows the ratios of questions with MA, CMA, and UCT answers for the NQ and popQA datasets, respectively. Note that different LLMs may have different memory strengths to the same question. Therefore, the count of questions and the specific questions within the same group can vary across different LLMs. To illustrate this, we present the count of questions in each group (low, mid-low, mid-high, and high) in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#S4.F3" title="Figure 3 ‣ 4.2.1 Memory Strength on Different Datasets ‣ 4.2 Impact of Memory Strength ‣ 4 Experiments ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_tag">3</span></a> (c)(d) for popQA and NQ datasets, respectively. We can draw the following conclusions.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS2.p2">
<p class="ltx_p" id="S4.SS2.SSS2.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.SSS2.p2.1.1">There is a clear positive correlation between memory strength and MA ratio</span>. From Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#S4.F3" title="Figure 3 ‣ 4.2.1 Memory Strength on Different Datasets ‣ 4.2 Impact of Memory Strength ‣ 4 Experiments ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_tag">3</span></a> (a)(b), it is obvious that as memory strength increases, the ratio of MA (red) increases significantly, while the proportion of CMA (blue) decreases. This trend is consistent across both datasets, but it is more obvious in the NQ dataset, especially for larger models such as GPT-4 and ChatGPT.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS2.p3">
<p class="ltx_p" id="S4.SS2.SSS2.p3.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.SSS2.p3.1.1">In general, the LLaMA models are more context-faithful than the GPT models</span>. Comparing the LLaMA models (7B and 70B) with the GPT models (ChatGPT and GPT-4) in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#S4.F3" title="Figure 3 ‣ 4.2.1 Memory Strength on Different Datasets ‣ 4.2 Impact of Memory Strength ‣ 4 Experiments ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_tag">3</span></a> (a)(b), the LLaMA models have a lower MA ratio and a higher CMA ratio. Even within groups of the same memory strength (low or high), the LLaMA models demonstrate more context-faithful performance.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Impact of Evidence Style</h3>
<figure class="ltx_table" id="S4.T1">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T1.3" style="width:411.9pt;height:60.9pt;vertical-align:-0.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-101.8pt,14.9pt) scale(0.669241847757444,0.669241847757444) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T1.3.3">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T1.3.3.4.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T1.3.3.4.1.1"></th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="4" id="S4.T1.3.3.4.1.2"><span class="ltx_text ltx_font_bold" id="S4.T1.3.3.4.1.2.1">popQA</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="4" id="S4.T1.3.3.4.1.3"><span class="ltx_text ltx_font_bold" id="S4.T1.3.3.4.1.3.1">NQ</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.3.3.5.2">
<th class="ltx_td ltx_th ltx_th_row ltx_border_r" id="S4.T1.3.3.5.2.1"></th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.3.3.5.2.2"><span class="ltx_text ltx_font_bold" id="S4.T1.3.3.5.2.2.1">LLaMA2.7B</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.3.3.5.2.3"><span class="ltx_text ltx_font_bold" id="S4.T1.3.3.5.2.3.1">LLaMA2.70B</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.3.3.5.2.4"><span class="ltx_text ltx_font_bold" id="S4.T1.3.3.5.2.4.1">ChatGPT</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.3.3.5.2.5"><span class="ltx_text ltx_font_bold" id="S4.T1.3.3.5.2.5.1">GPT-4</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.3.3.5.2.6"><span class="ltx_text ltx_font_bold" id="S4.T1.3.3.5.2.6.1">LLaMA2.7B</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.3.3.5.2.7"><span class="ltx_text ltx_font_bold" id="S4.T1.3.3.5.2.7.1">LLaMA2.70B</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.3.3.5.2.8"><span class="ltx_text ltx_font_bold" id="S4.T1.3.3.5.2.8.1">ChatGPT</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.3.5.2.9"><span class="ltx_text ltx_font_bold" id="S4.T1.3.3.5.2.9.1">GPT-4</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T1.1.1.1.1">
<math alttext="\#" class="ltx_Math" display="inline" id="S4.T1.1.1.1.1.m1.1"><semantics id="S4.T1.1.1.1.1.m1.1a"><mi id="S4.T1.1.1.1.1.m1.1.1" mathvariant="normal" xref="S4.T1.1.1.1.1.m1.1.1.cmml">#</mi><annotation-xml encoding="MathML-Content" id="S4.T1.1.1.1.1.m1.1b"><ci id="S4.T1.1.1.1.1.m1.1.1.cmml" xref="S4.T1.1.1.1.1.m1.1.1">#</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.1.1.1.1.m1.1c">\#</annotation><annotation encoding="application/x-llamapun" id="S4.T1.1.1.1.1.m1.1d">#</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.1.1.1"> of Q (Initial)</span>
</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.1.1.2">1000</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.1.1.3">1000</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.1.1.4">1000</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.1.1.5">1000</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.1.1.6">1667</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.1.1.7">1667</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.1.1.8">1667</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.1.9">1667</td>
</tr>
<tr class="ltx_tr" id="S4.T1.2.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T1.2.2.2.1">
<math alttext="\#" class="ltx_Math" display="inline" id="S4.T1.2.2.2.1.m1.1"><semantics id="S4.T1.2.2.2.1.m1.1a"><mi id="S4.T1.2.2.2.1.m1.1.1" mathvariant="normal" xref="S4.T1.2.2.2.1.m1.1.1.cmml">#</mi><annotation-xml encoding="MathML-Content" id="S4.T1.2.2.2.1.m1.1b"><ci id="S4.T1.2.2.2.1.m1.1.1.cmml" xref="S4.T1.2.2.2.1.m1.1.1">#</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.2.2.2.1.m1.1c">\#</annotation><annotation encoding="application/x-llamapun" id="S4.T1.2.2.2.1.m1.1d">#</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="S4.T1.2.2.2.1.1"> of Q with direct evidence</span>
</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.2.2.2.2">918</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.2.2.2.3">922</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.2.2.2.4">933</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.2.2.2.5">933</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.2.2.2.6">1042</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.2.2.2.7">1009</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.2.2.2.8">1079</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.2.2.2.9">1171</td>
</tr>
<tr class="ltx_tr" id="S4.T1.3.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t" id="S4.T1.3.3.3.1">
<math alttext="\#" class="ltx_Math" display="inline" id="S4.T1.3.3.3.1.m1.1"><semantics id="S4.T1.3.3.3.1.m1.1a"><mi id="S4.T1.3.3.3.1.m1.1.1" mathvariant="normal" xref="S4.T1.3.3.3.1.m1.1.1.cmml">#</mi><annotation-xml encoding="MathML-Content" id="S4.T1.3.3.3.1.m1.1b"><ci id="S4.T1.3.3.3.1.m1.1.1.cmml" xref="S4.T1.3.3.3.1.m1.1.1">#</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.3.3.3.1.m1.1c">\#</annotation><annotation encoding="application/x-llamapun" id="S4.T1.3.3.3.1.m1.1d">#</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="S4.T1.3.3.3.1.1"> of Q with indirect evidence</span>
</th>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.T1.3.3.3.2">901</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.T1.3.3.3.3">895</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.T1.3.3.3.4">911</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.T1.3.3.3.5">918</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.T1.3.3.3.6">976</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.T1.3.3.3.7">972</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.T1.3.3.3.8">1025</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T1.3.3.3.9">1108</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Number of final examples for each LLM. The difference between LLMs is due to their different outputs going through the framework.</figcaption>
</figure>
<figure class="ltx_table" id="S4.T2">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T2.12" style="width:433.6pt;height:360.1pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-65.6pt,54.3pt) scale(0.767769653650018,0.767769653650018) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T2.12.12">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T2.12.12.13.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.12.12.13.1.1" rowspan="2"><span class="ltx_text" id="S4.T2.12.12.13.1.1.1">Dataset</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.12.12.13.1.2" rowspan="2"><span class="ltx_text" id="S4.T2.12.12.13.1.2.1">Evidence Style</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.12.12.13.1.3" rowspan="2"><span class="ltx_text" id="S4.T2.12.12.13.1.3.1">S #</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="3" id="S4.T2.12.12.13.1.4">LLaMA2.7B</td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="3" id="S4.T2.12.12.13.1.5">LLaMA2.70B</td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="3" id="S4.T2.12.12.13.1.6">ChatGPT</td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="3" id="S4.T2.12.12.13.1.7">GPT-4</td>
</tr>
<tr class="ltx_tr" id="S4.T2.12.12.12">
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.1.1"><math alttext="R_{m}\downarrow" class="ltx_Math" display="inline" id="S4.T2.1.1.1.1.m1.1"><semantics id="S4.T2.1.1.1.1.m1.1a"><mrow id="S4.T2.1.1.1.1.m1.1.1" xref="S4.T2.1.1.1.1.m1.1.1.cmml"><msub id="S4.T2.1.1.1.1.m1.1.1.2" xref="S4.T2.1.1.1.1.m1.1.1.2.cmml"><mi id="S4.T2.1.1.1.1.m1.1.1.2.2" xref="S4.T2.1.1.1.1.m1.1.1.2.2.cmml">R</mi><mi id="S4.T2.1.1.1.1.m1.1.1.2.3" xref="S4.T2.1.1.1.1.m1.1.1.2.3.cmml">m</mi></msub><mo id="S4.T2.1.1.1.1.m1.1.1.1" stretchy="false" xref="S4.T2.1.1.1.1.m1.1.1.1.cmml">↓</mo><mi id="S4.T2.1.1.1.1.m1.1.1.3" xref="S4.T2.1.1.1.1.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.1.1.1.1.m1.1b"><apply id="S4.T2.1.1.1.1.m1.1.1.cmml" xref="S4.T2.1.1.1.1.m1.1.1"><ci id="S4.T2.1.1.1.1.m1.1.1.1.cmml" xref="S4.T2.1.1.1.1.m1.1.1.1">↓</ci><apply id="S4.T2.1.1.1.1.m1.1.1.2.cmml" xref="S4.T2.1.1.1.1.m1.1.1.2"><csymbol cd="ambiguous" id="S4.T2.1.1.1.1.m1.1.1.2.1.cmml" xref="S4.T2.1.1.1.1.m1.1.1.2">subscript</csymbol><ci id="S4.T2.1.1.1.1.m1.1.1.2.2.cmml" xref="S4.T2.1.1.1.1.m1.1.1.2.2">𝑅</ci><ci id="S4.T2.1.1.1.1.m1.1.1.2.3.cmml" xref="S4.T2.1.1.1.1.m1.1.1.2.3">𝑚</ci></apply><csymbol cd="latexml" id="S4.T2.1.1.1.1.m1.1.1.3.cmml" xref="S4.T2.1.1.1.1.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.1.1.1.1.m1.1c">R_{m}\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T2.1.1.1.1.m1.1d">italic_R start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT ↓</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.2.2.2.2"><math alttext="R_{c}\uparrow" class="ltx_Math" display="inline" id="S4.T2.2.2.2.2.m1.1"><semantics id="S4.T2.2.2.2.2.m1.1a"><mrow id="S4.T2.2.2.2.2.m1.1.1" xref="S4.T2.2.2.2.2.m1.1.1.cmml"><msub id="S4.T2.2.2.2.2.m1.1.1.2" xref="S4.T2.2.2.2.2.m1.1.1.2.cmml"><mi id="S4.T2.2.2.2.2.m1.1.1.2.2" xref="S4.T2.2.2.2.2.m1.1.1.2.2.cmml">R</mi><mi id="S4.T2.2.2.2.2.m1.1.1.2.3" xref="S4.T2.2.2.2.2.m1.1.1.2.3.cmml">c</mi></msub><mo id="S4.T2.2.2.2.2.m1.1.1.1" stretchy="false" xref="S4.T2.2.2.2.2.m1.1.1.1.cmml">↑</mo><mi id="S4.T2.2.2.2.2.m1.1.1.3" xref="S4.T2.2.2.2.2.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.2.2.2.2.m1.1b"><apply id="S4.T2.2.2.2.2.m1.1.1.cmml" xref="S4.T2.2.2.2.2.m1.1.1"><ci id="S4.T2.2.2.2.2.m1.1.1.1.cmml" xref="S4.T2.2.2.2.2.m1.1.1.1">↑</ci><apply id="S4.T2.2.2.2.2.m1.1.1.2.cmml" xref="S4.T2.2.2.2.2.m1.1.1.2"><csymbol cd="ambiguous" id="S4.T2.2.2.2.2.m1.1.1.2.1.cmml" xref="S4.T2.2.2.2.2.m1.1.1.2">subscript</csymbol><ci id="S4.T2.2.2.2.2.m1.1.1.2.2.cmml" xref="S4.T2.2.2.2.2.m1.1.1.2.2">𝑅</ci><ci id="S4.T2.2.2.2.2.m1.1.1.2.3.cmml" xref="S4.T2.2.2.2.2.m1.1.1.2.3">𝑐</ci></apply><csymbol cd="latexml" id="S4.T2.2.2.2.2.m1.1.1.3.cmml" xref="S4.T2.2.2.2.2.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.2.2.2.2.m1.1c">R_{c}\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T2.2.2.2.2.m1.1d">italic_R start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ↑</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.3.3.3.3"><math alttext="R_{u}" class="ltx_Math" display="inline" id="S4.T2.3.3.3.3.m1.1"><semantics id="S4.T2.3.3.3.3.m1.1a"><msub id="S4.T2.3.3.3.3.m1.1.1" xref="S4.T2.3.3.3.3.m1.1.1.cmml"><mi id="S4.T2.3.3.3.3.m1.1.1.2" xref="S4.T2.3.3.3.3.m1.1.1.2.cmml">R</mi><mi id="S4.T2.3.3.3.3.m1.1.1.3" xref="S4.T2.3.3.3.3.m1.1.1.3.cmml">u</mi></msub><annotation-xml encoding="MathML-Content" id="S4.T2.3.3.3.3.m1.1b"><apply id="S4.T2.3.3.3.3.m1.1.1.cmml" xref="S4.T2.3.3.3.3.m1.1.1"><csymbol cd="ambiguous" id="S4.T2.3.3.3.3.m1.1.1.1.cmml" xref="S4.T2.3.3.3.3.m1.1.1">subscript</csymbol><ci id="S4.T2.3.3.3.3.m1.1.1.2.cmml" xref="S4.T2.3.3.3.3.m1.1.1.2">𝑅</ci><ci id="S4.T2.3.3.3.3.m1.1.1.3.cmml" xref="S4.T2.3.3.3.3.m1.1.1.3">𝑢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.3.3.3.3.m1.1c">R_{u}</annotation><annotation encoding="application/x-llamapun" id="S4.T2.3.3.3.3.m1.1d">italic_R start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.4.4.4.4"><math alttext="R_{m}\downarrow" class="ltx_Math" display="inline" id="S4.T2.4.4.4.4.m1.1"><semantics id="S4.T2.4.4.4.4.m1.1a"><mrow id="S4.T2.4.4.4.4.m1.1.1" xref="S4.T2.4.4.4.4.m1.1.1.cmml"><msub id="S4.T2.4.4.4.4.m1.1.1.2" xref="S4.T2.4.4.4.4.m1.1.1.2.cmml"><mi id="S4.T2.4.4.4.4.m1.1.1.2.2" xref="S4.T2.4.4.4.4.m1.1.1.2.2.cmml">R</mi><mi id="S4.T2.4.4.4.4.m1.1.1.2.3" xref="S4.T2.4.4.4.4.m1.1.1.2.3.cmml">m</mi></msub><mo id="S4.T2.4.4.4.4.m1.1.1.1" stretchy="false" xref="S4.T2.4.4.4.4.m1.1.1.1.cmml">↓</mo><mi id="S4.T2.4.4.4.4.m1.1.1.3" xref="S4.T2.4.4.4.4.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.4.4.4.4.m1.1b"><apply id="S4.T2.4.4.4.4.m1.1.1.cmml" xref="S4.T2.4.4.4.4.m1.1.1"><ci id="S4.T2.4.4.4.4.m1.1.1.1.cmml" xref="S4.T2.4.4.4.4.m1.1.1.1">↓</ci><apply id="S4.T2.4.4.4.4.m1.1.1.2.cmml" xref="S4.T2.4.4.4.4.m1.1.1.2"><csymbol cd="ambiguous" id="S4.T2.4.4.4.4.m1.1.1.2.1.cmml" xref="S4.T2.4.4.4.4.m1.1.1.2">subscript</csymbol><ci id="S4.T2.4.4.4.4.m1.1.1.2.2.cmml" xref="S4.T2.4.4.4.4.m1.1.1.2.2">𝑅</ci><ci id="S4.T2.4.4.4.4.m1.1.1.2.3.cmml" xref="S4.T2.4.4.4.4.m1.1.1.2.3">𝑚</ci></apply><csymbol cd="latexml" id="S4.T2.4.4.4.4.m1.1.1.3.cmml" xref="S4.T2.4.4.4.4.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.4.4.4.4.m1.1c">R_{m}\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T2.4.4.4.4.m1.1d">italic_R start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT ↓</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.5.5.5.5"><math alttext="R_{c}\uparrow" class="ltx_Math" display="inline" id="S4.T2.5.5.5.5.m1.1"><semantics id="S4.T2.5.5.5.5.m1.1a"><mrow id="S4.T2.5.5.5.5.m1.1.1" xref="S4.T2.5.5.5.5.m1.1.1.cmml"><msub id="S4.T2.5.5.5.5.m1.1.1.2" xref="S4.T2.5.5.5.5.m1.1.1.2.cmml"><mi id="S4.T2.5.5.5.5.m1.1.1.2.2" xref="S4.T2.5.5.5.5.m1.1.1.2.2.cmml">R</mi><mi id="S4.T2.5.5.5.5.m1.1.1.2.3" xref="S4.T2.5.5.5.5.m1.1.1.2.3.cmml">c</mi></msub><mo id="S4.T2.5.5.5.5.m1.1.1.1" stretchy="false" xref="S4.T2.5.5.5.5.m1.1.1.1.cmml">↑</mo><mi id="S4.T2.5.5.5.5.m1.1.1.3" xref="S4.T2.5.5.5.5.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.5.5.5.5.m1.1b"><apply id="S4.T2.5.5.5.5.m1.1.1.cmml" xref="S4.T2.5.5.5.5.m1.1.1"><ci id="S4.T2.5.5.5.5.m1.1.1.1.cmml" xref="S4.T2.5.5.5.5.m1.1.1.1">↑</ci><apply id="S4.T2.5.5.5.5.m1.1.1.2.cmml" xref="S4.T2.5.5.5.5.m1.1.1.2"><csymbol cd="ambiguous" id="S4.T2.5.5.5.5.m1.1.1.2.1.cmml" xref="S4.T2.5.5.5.5.m1.1.1.2">subscript</csymbol><ci id="S4.T2.5.5.5.5.m1.1.1.2.2.cmml" xref="S4.T2.5.5.5.5.m1.1.1.2.2">𝑅</ci><ci id="S4.T2.5.5.5.5.m1.1.1.2.3.cmml" xref="S4.T2.5.5.5.5.m1.1.1.2.3">𝑐</ci></apply><csymbol cd="latexml" id="S4.T2.5.5.5.5.m1.1.1.3.cmml" xref="S4.T2.5.5.5.5.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.5.5.5.5.m1.1c">R_{c}\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T2.5.5.5.5.m1.1d">italic_R start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ↑</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.6.6.6.6"><math alttext="R_{u}" class="ltx_Math" display="inline" id="S4.T2.6.6.6.6.m1.1"><semantics id="S4.T2.6.6.6.6.m1.1a"><msub id="S4.T2.6.6.6.6.m1.1.1" xref="S4.T2.6.6.6.6.m1.1.1.cmml"><mi id="S4.T2.6.6.6.6.m1.1.1.2" xref="S4.T2.6.6.6.6.m1.1.1.2.cmml">R</mi><mi id="S4.T2.6.6.6.6.m1.1.1.3" xref="S4.T2.6.6.6.6.m1.1.1.3.cmml">u</mi></msub><annotation-xml encoding="MathML-Content" id="S4.T2.6.6.6.6.m1.1b"><apply id="S4.T2.6.6.6.6.m1.1.1.cmml" xref="S4.T2.6.6.6.6.m1.1.1"><csymbol cd="ambiguous" id="S4.T2.6.6.6.6.m1.1.1.1.cmml" xref="S4.T2.6.6.6.6.m1.1.1">subscript</csymbol><ci id="S4.T2.6.6.6.6.m1.1.1.2.cmml" xref="S4.T2.6.6.6.6.m1.1.1.2">𝑅</ci><ci id="S4.T2.6.6.6.6.m1.1.1.3.cmml" xref="S4.T2.6.6.6.6.m1.1.1.3">𝑢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.6.6.6.6.m1.1c">R_{u}</annotation><annotation encoding="application/x-llamapun" id="S4.T2.6.6.6.6.m1.1d">italic_R start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.7.7.7.7"><math alttext="R_{m}\downarrow" class="ltx_Math" display="inline" id="S4.T2.7.7.7.7.m1.1"><semantics id="S4.T2.7.7.7.7.m1.1a"><mrow id="S4.T2.7.7.7.7.m1.1.1" xref="S4.T2.7.7.7.7.m1.1.1.cmml"><msub id="S4.T2.7.7.7.7.m1.1.1.2" xref="S4.T2.7.7.7.7.m1.1.1.2.cmml"><mi id="S4.T2.7.7.7.7.m1.1.1.2.2" xref="S4.T2.7.7.7.7.m1.1.1.2.2.cmml">R</mi><mi id="S4.T2.7.7.7.7.m1.1.1.2.3" xref="S4.T2.7.7.7.7.m1.1.1.2.3.cmml">m</mi></msub><mo id="S4.T2.7.7.7.7.m1.1.1.1" stretchy="false" xref="S4.T2.7.7.7.7.m1.1.1.1.cmml">↓</mo><mi id="S4.T2.7.7.7.7.m1.1.1.3" xref="S4.T2.7.7.7.7.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.7.7.7.7.m1.1b"><apply id="S4.T2.7.7.7.7.m1.1.1.cmml" xref="S4.T2.7.7.7.7.m1.1.1"><ci id="S4.T2.7.7.7.7.m1.1.1.1.cmml" xref="S4.T2.7.7.7.7.m1.1.1.1">↓</ci><apply id="S4.T2.7.7.7.7.m1.1.1.2.cmml" xref="S4.T2.7.7.7.7.m1.1.1.2"><csymbol cd="ambiguous" id="S4.T2.7.7.7.7.m1.1.1.2.1.cmml" xref="S4.T2.7.7.7.7.m1.1.1.2">subscript</csymbol><ci id="S4.T2.7.7.7.7.m1.1.1.2.2.cmml" xref="S4.T2.7.7.7.7.m1.1.1.2.2">𝑅</ci><ci id="S4.T2.7.7.7.7.m1.1.1.2.3.cmml" xref="S4.T2.7.7.7.7.m1.1.1.2.3">𝑚</ci></apply><csymbol cd="latexml" id="S4.T2.7.7.7.7.m1.1.1.3.cmml" xref="S4.T2.7.7.7.7.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.7.7.7.7.m1.1c">R_{m}\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T2.7.7.7.7.m1.1d">italic_R start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT ↓</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.8.8.8.8"><math alttext="R_{c}\uparrow" class="ltx_Math" display="inline" id="S4.T2.8.8.8.8.m1.1"><semantics id="S4.T2.8.8.8.8.m1.1a"><mrow id="S4.T2.8.8.8.8.m1.1.1" xref="S4.T2.8.8.8.8.m1.1.1.cmml"><msub id="S4.T2.8.8.8.8.m1.1.1.2" xref="S4.T2.8.8.8.8.m1.1.1.2.cmml"><mi id="S4.T2.8.8.8.8.m1.1.1.2.2" xref="S4.T2.8.8.8.8.m1.1.1.2.2.cmml">R</mi><mi id="S4.T2.8.8.8.8.m1.1.1.2.3" xref="S4.T2.8.8.8.8.m1.1.1.2.3.cmml">c</mi></msub><mo id="S4.T2.8.8.8.8.m1.1.1.1" stretchy="false" xref="S4.T2.8.8.8.8.m1.1.1.1.cmml">↑</mo><mi id="S4.T2.8.8.8.8.m1.1.1.3" xref="S4.T2.8.8.8.8.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.8.8.8.8.m1.1b"><apply id="S4.T2.8.8.8.8.m1.1.1.cmml" xref="S4.T2.8.8.8.8.m1.1.1"><ci id="S4.T2.8.8.8.8.m1.1.1.1.cmml" xref="S4.T2.8.8.8.8.m1.1.1.1">↑</ci><apply id="S4.T2.8.8.8.8.m1.1.1.2.cmml" xref="S4.T2.8.8.8.8.m1.1.1.2"><csymbol cd="ambiguous" id="S4.T2.8.8.8.8.m1.1.1.2.1.cmml" xref="S4.T2.8.8.8.8.m1.1.1.2">subscript</csymbol><ci id="S4.T2.8.8.8.8.m1.1.1.2.2.cmml" xref="S4.T2.8.8.8.8.m1.1.1.2.2">𝑅</ci><ci id="S4.T2.8.8.8.8.m1.1.1.2.3.cmml" xref="S4.T2.8.8.8.8.m1.1.1.2.3">𝑐</ci></apply><csymbol cd="latexml" id="S4.T2.8.8.8.8.m1.1.1.3.cmml" xref="S4.T2.8.8.8.8.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.8.8.8.8.m1.1c">R_{c}\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T2.8.8.8.8.m1.1d">italic_R start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ↑</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.9.9.9.9"><math alttext="R_{u}" class="ltx_Math" display="inline" id="S4.T2.9.9.9.9.m1.1"><semantics id="S4.T2.9.9.9.9.m1.1a"><msub id="S4.T2.9.9.9.9.m1.1.1" xref="S4.T2.9.9.9.9.m1.1.1.cmml"><mi id="S4.T2.9.9.9.9.m1.1.1.2" xref="S4.T2.9.9.9.9.m1.1.1.2.cmml">R</mi><mi id="S4.T2.9.9.9.9.m1.1.1.3" xref="S4.T2.9.9.9.9.m1.1.1.3.cmml">u</mi></msub><annotation-xml encoding="MathML-Content" id="S4.T2.9.9.9.9.m1.1b"><apply id="S4.T2.9.9.9.9.m1.1.1.cmml" xref="S4.T2.9.9.9.9.m1.1.1"><csymbol cd="ambiguous" id="S4.T2.9.9.9.9.m1.1.1.1.cmml" xref="S4.T2.9.9.9.9.m1.1.1">subscript</csymbol><ci id="S4.T2.9.9.9.9.m1.1.1.2.cmml" xref="S4.T2.9.9.9.9.m1.1.1.2">𝑅</ci><ci id="S4.T2.9.9.9.9.m1.1.1.3.cmml" xref="S4.T2.9.9.9.9.m1.1.1.3">𝑢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.9.9.9.9.m1.1c">R_{u}</annotation><annotation encoding="application/x-llamapun" id="S4.T2.9.9.9.9.m1.1d">italic_R start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.10.10.10.10"><math alttext="R_{m}\downarrow" class="ltx_Math" display="inline" id="S4.T2.10.10.10.10.m1.1"><semantics id="S4.T2.10.10.10.10.m1.1a"><mrow id="S4.T2.10.10.10.10.m1.1.1" xref="S4.T2.10.10.10.10.m1.1.1.cmml"><msub id="S4.T2.10.10.10.10.m1.1.1.2" xref="S4.T2.10.10.10.10.m1.1.1.2.cmml"><mi id="S4.T2.10.10.10.10.m1.1.1.2.2" xref="S4.T2.10.10.10.10.m1.1.1.2.2.cmml">R</mi><mi id="S4.T2.10.10.10.10.m1.1.1.2.3" xref="S4.T2.10.10.10.10.m1.1.1.2.3.cmml">m</mi></msub><mo id="S4.T2.10.10.10.10.m1.1.1.1" stretchy="false" xref="S4.T2.10.10.10.10.m1.1.1.1.cmml">↓</mo><mi id="S4.T2.10.10.10.10.m1.1.1.3" xref="S4.T2.10.10.10.10.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.10.10.10.10.m1.1b"><apply id="S4.T2.10.10.10.10.m1.1.1.cmml" xref="S4.T2.10.10.10.10.m1.1.1"><ci id="S4.T2.10.10.10.10.m1.1.1.1.cmml" xref="S4.T2.10.10.10.10.m1.1.1.1">↓</ci><apply id="S4.T2.10.10.10.10.m1.1.1.2.cmml" xref="S4.T2.10.10.10.10.m1.1.1.2"><csymbol cd="ambiguous" id="S4.T2.10.10.10.10.m1.1.1.2.1.cmml" xref="S4.T2.10.10.10.10.m1.1.1.2">subscript</csymbol><ci id="S4.T2.10.10.10.10.m1.1.1.2.2.cmml" xref="S4.T2.10.10.10.10.m1.1.1.2.2">𝑅</ci><ci id="S4.T2.10.10.10.10.m1.1.1.2.3.cmml" xref="S4.T2.10.10.10.10.m1.1.1.2.3">𝑚</ci></apply><csymbol cd="latexml" id="S4.T2.10.10.10.10.m1.1.1.3.cmml" xref="S4.T2.10.10.10.10.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.10.10.10.10.m1.1c">R_{m}\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T2.10.10.10.10.m1.1d">italic_R start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT ↓</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.11.11.11.11"><math alttext="R_{c}\uparrow" class="ltx_Math" display="inline" id="S4.T2.11.11.11.11.m1.1"><semantics id="S4.T2.11.11.11.11.m1.1a"><mrow id="S4.T2.11.11.11.11.m1.1.1" xref="S4.T2.11.11.11.11.m1.1.1.cmml"><msub id="S4.T2.11.11.11.11.m1.1.1.2" xref="S4.T2.11.11.11.11.m1.1.1.2.cmml"><mi id="S4.T2.11.11.11.11.m1.1.1.2.2" xref="S4.T2.11.11.11.11.m1.1.1.2.2.cmml">R</mi><mi id="S4.T2.11.11.11.11.m1.1.1.2.3" xref="S4.T2.11.11.11.11.m1.1.1.2.3.cmml">c</mi></msub><mo id="S4.T2.11.11.11.11.m1.1.1.1" stretchy="false" xref="S4.T2.11.11.11.11.m1.1.1.1.cmml">↑</mo><mi id="S4.T2.11.11.11.11.m1.1.1.3" xref="S4.T2.11.11.11.11.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.11.11.11.11.m1.1b"><apply id="S4.T2.11.11.11.11.m1.1.1.cmml" xref="S4.T2.11.11.11.11.m1.1.1"><ci id="S4.T2.11.11.11.11.m1.1.1.1.cmml" xref="S4.T2.11.11.11.11.m1.1.1.1">↑</ci><apply id="S4.T2.11.11.11.11.m1.1.1.2.cmml" xref="S4.T2.11.11.11.11.m1.1.1.2"><csymbol cd="ambiguous" id="S4.T2.11.11.11.11.m1.1.1.2.1.cmml" xref="S4.T2.11.11.11.11.m1.1.1.2">subscript</csymbol><ci id="S4.T2.11.11.11.11.m1.1.1.2.2.cmml" xref="S4.T2.11.11.11.11.m1.1.1.2.2">𝑅</ci><ci id="S4.T2.11.11.11.11.m1.1.1.2.3.cmml" xref="S4.T2.11.11.11.11.m1.1.1.2.3">𝑐</ci></apply><csymbol cd="latexml" id="S4.T2.11.11.11.11.m1.1.1.3.cmml" xref="S4.T2.11.11.11.11.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.11.11.11.11.m1.1c">R_{c}\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T2.11.11.11.11.m1.1d">italic_R start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ↑</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.12.12"><math alttext="R_{u}" class="ltx_Math" display="inline" id="S4.T2.12.12.12.12.m1.1"><semantics id="S4.T2.12.12.12.12.m1.1a"><msub id="S4.T2.12.12.12.12.m1.1.1" xref="S4.T2.12.12.12.12.m1.1.1.cmml"><mi id="S4.T2.12.12.12.12.m1.1.1.2" xref="S4.T2.12.12.12.12.m1.1.1.2.cmml">R</mi><mi id="S4.T2.12.12.12.12.m1.1.1.3" xref="S4.T2.12.12.12.12.m1.1.1.3.cmml">u</mi></msub><annotation-xml encoding="MathML-Content" id="S4.T2.12.12.12.12.m1.1b"><apply id="S4.T2.12.12.12.12.m1.1.1.cmml" xref="S4.T2.12.12.12.12.m1.1.1"><csymbol cd="ambiguous" id="S4.T2.12.12.12.12.m1.1.1.1.cmml" xref="S4.T2.12.12.12.12.m1.1.1">subscript</csymbol><ci id="S4.T2.12.12.12.12.m1.1.1.2.cmml" xref="S4.T2.12.12.12.12.m1.1.1.2">𝑅</ci><ci id="S4.T2.12.12.12.12.m1.1.1.3.cmml" xref="S4.T2.12.12.12.12.m1.1.1.3">𝑢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.12.12.12.12.m1.1c">R_{u}</annotation><annotation encoding="application/x-llamapun" id="S4.T2.12.12.12.12.m1.1d">italic_R start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="S4.T2.12.12.14.2">
<th class="ltx_td ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.12.12.14.2.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="14" id="S4.T2.12.12.14.2.2" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T2.12.12.14.2.2.1" style="background-color:#E6E6E6;">Group 1: Q with direct evidence</span></th>
</tr>
<tr class="ltx_tr" id="S4.T2.12.12.15.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T2.12.12.15.3.1" rowspan="11"><span class="ltx_text" id="S4.T2.12.12.15.3.1.1">NQ</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.12.12.15.3.2" rowspan="3"><span class="ltx_text" id="S4.T2.12.12.15.3.2.1">Direct</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.12.12.15.3.3">1</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.15.3.4">7.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.15.3.5">92.8</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.12.12.15.3.6">0.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.15.3.7">3.07</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.15.3.8">96.93</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.12.12.15.3.9">0.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.15.3.10">19.46</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.15.3.11">75.16</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.12.12.15.3.12">5.38</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.15.3.13">50.04</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.15.3.14">47.99</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.15.3.15">1.96</td>
</tr>
<tr class="ltx_tr" id="S4.T2.12.12.16.4">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.12.12.16.4.1">2</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.16.4.2">5.47</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.16.4.3">94.53</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.12.12.16.4.4">0.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.16.4.5">3.07</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.16.4.6">96.93</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.12.12.16.4.7">0.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.16.4.8">19.09</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.16.4.9">76.83</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.12.12.16.4.10">4.08</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.16.4.11">20.24</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.16.4.12">77.54</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.16.4.13">2.22</td>
</tr>
<tr class="ltx_tr" id="S4.T2.12.12.17.5">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.12.12.17.5.1">3</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.17.5.2">6.81</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.17.5.3">93.19</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.12.12.17.5.4">0.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.17.5.5">2.68</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.17.5.6">97.22</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.12.12.17.5.7">0.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.17.5.8">22.06</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.17.5.9">72.75</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.12.12.17.5.10">5.19</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.17.5.11">17.34</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.17.5.12">80.87</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.17.5.13">1.79</td>
</tr>
<tr class="ltx_tr" id="S4.T2.12.12.18.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.12.12.18.6.1" rowspan="2"><span class="ltx_text" id="S4.T2.12.12.18.6.1.1">Direct + Paraphrase</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.12.12.18.6.2">2</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.18.6.3">4.13</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.18.6.4">95.87</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.12.12.18.6.5">0.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.18.6.6">1.49</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.18.6.7">98.41</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.12.12.18.6.8">0.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.18.6.9">15.29</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.18.6.10">81.28</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.12.12.18.6.11">3.43</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.18.6.12">18.96</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.18.6.13">79.67</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.18.6.14">1.37</td>
</tr>
<tr class="ltx_tr" id="S4.T2.12.12.19.7">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.12.12.19.7.1">3</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.19.7.2">3.26</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.19.7.3">96.74</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.12.12.19.7.4">0.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.19.7.5">1.19</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.19.7.6">98.61</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.12.12.19.7.7">0.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.19.7.8">9.55</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.19.7.9">86.75</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.12.12.19.7.10">3.71</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.19.7.11">11.27</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.19.7.12">87.28</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.19.7.13">1.45</td>
</tr>
<tr class="ltx_tr" id="S4.T2.12.12.20.8">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="14" id="S4.T2.12.12.20.8.1" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T2.12.12.20.8.1.1" style="background-color:#E6E6E6;">Group 2: Q with indirect evidence</span></th>
</tr>
<tr class="ltx_tr" id="S4.T2.12.12.21.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.12.12.21.9.1">Direct</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.12.12.21.9.2">1</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.21.9.3">5.53</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.21.9.4">94.47</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.12.12.21.9.5">0.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.21.9.6">2.67</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.21.9.7">97.32</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.12.12.21.9.8">0.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.21.9.9">18.73</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.21.9.10">75.71</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.12.12.21.9.11">5.56</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.21.9.12">48.83</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.21.9.13">49.19</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.21.9.14">1.99</td>
</tr>
<tr class="ltx_tr" id="S4.T2.12.12.22.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.12.12.22.10.1" rowspan="2"><span class="ltx_text" id="S4.T2.12.12.22.10.1.1">Indirect</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.12.12.22.10.2">2</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.22.10.3">3.28</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.22.10.4">95.29</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.12.12.22.10.5">1.43</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.22.10.6">1.65</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.22.10.7">98.25</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.12.12.22.10.8">0.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.22.10.9">13.66</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.22.10.10">84.1</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.12.12.22.10.11">2.24</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.22.10.12">44.59</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.22.10.13">53.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.22.10.14">1.71</td>
</tr>
<tr class="ltx_tr" id="S4.T2.12.12.23.11">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.12.12.23.11.1">3</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.23.11.2">4.82</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.23.11.3">94.06</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.12.12.23.11.4">1.13</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.23.11.5">1.85</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.23.11.6">97.84</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.12.12.23.11.7">0.31</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.23.11.8">13.27</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.23.11.9">84.19</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.12.12.23.11.10">2.54</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.23.11.11">39.89</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.23.11.12">58.57</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.23.11.13">1.53</td>
</tr>
<tr class="ltx_tr" id="S4.T2.12.12.24.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.12.12.24.12.1" rowspan="2"><span class="ltx_text" id="S4.T2.12.12.24.12.1.1">Direct + Indirect</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.12.12.24.12.2">2</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.24.12.3">5.33</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.24.12.4">94.67</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.12.12.24.12.5">0.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.24.12.6">1.34</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.24.12.7">98.25</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.12.12.24.12.8">0.41</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.24.12.9">12.68</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.24.12.10">84.78</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.12.12.24.12.11">2.54</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.24.12.12">32.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.24.12.13">66.06</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.24.12.14">1.53</td>
</tr>
<tr class="ltx_tr" id="S4.T2.12.12.25.13">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.12.12.25.13.1">3</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.25.13.2">4.41</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.25.13.3">95.59</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.12.12.25.13.4">0.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.25.13.5">1.44</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.25.13.6">98.56</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.12.12.25.13.7">0.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.25.13.8">9.46</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.25.13.9">88.1</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.12.12.25.13.10">2.44</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.25.13.11">28.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.25.13.12">69.67</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.25.13.13">1.62</td>
</tr>
<tr class="ltx_tr" id="S4.T2.12.12.26.14">
<th class="ltx_td ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.12.12.26.14.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="14" id="S4.T2.12.12.26.14.2" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T2.12.12.26.14.2.1" style="background-color:#E6E6E6;">Group 1: Q with direct evidence</span></th>
</tr>
<tr class="ltx_tr" id="S4.T2.12.12.27.15">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r" id="S4.T2.12.12.27.15.1" rowspan="11"><span class="ltx_text" id="S4.T2.12.12.27.15.1.1">popQA</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.12.12.27.15.2" rowspan="3"><span class="ltx_text" id="S4.T2.12.12.27.15.2.1">Direct</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.12.12.27.15.3">1</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.27.15.4">0.44</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.27.15.5">99.56</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.12.12.27.15.6">0.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.27.15.7">1.08</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.27.15.8">98.7</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.12.12.27.15.9">0.22</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.27.15.10">3.32</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.27.15.11">94.75</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.12.12.27.15.12">1.93</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.27.15.13">13.29</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.27.15.14">84.57</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.27.15.15">2.14</td>
</tr>
<tr class="ltx_tr" id="S4.T2.12.12.28.16">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.12.12.28.16.1">2</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.28.16.2">0.44</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.28.16.3">99.56</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.12.12.28.16.4">0.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.28.16.5">0.98</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.28.16.6">98.81</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.12.12.28.16.7">0.22</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.28.16.8">2.79</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.28.16.9">96.03</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.12.12.28.16.10">1.18</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.28.16.11">4.39</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.28.16.12">93.46</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.28.16.13">2.14</td>
</tr>
<tr class="ltx_tr" id="S4.T2.12.12.29.17">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.12.12.29.17.1">3</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.29.17.2">0.65</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.29.17.3">99.35</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.12.12.29.17.4">0.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.29.17.5">1.08</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.29.17.6">98.7</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.12.12.29.17.7">0.22</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.29.17.8">3.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.29.17.9">95.5</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.12.12.29.17.10">1.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.29.17.11">2.57</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.29.17.12">95.28</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.29.17.13">2.14</td>
</tr>
<tr class="ltx_tr" id="S4.T2.12.12.30.18">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.12.12.30.18.1" rowspan="2"><span class="ltx_text" id="S4.T2.12.12.30.18.1.1">Direct + Paraphrase</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.12.12.30.18.2">2</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.30.18.3">0.22</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.30.18.4">99.78</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.12.12.30.18.5">0.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.30.18.6">1.19</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.30.18.7">98.7</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.12.12.30.18.8">0.11</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.30.18.9">2.36</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.30.18.10">97.0</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.12.12.30.18.11">0.64</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.30.18.12">3.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.30.18.13">95.71</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.30.18.14">1.29</td>
</tr>
<tr class="ltx_tr" id="S4.T2.12.12.31.19">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.12.12.31.19.1">3</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.31.19.2">0.11</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.31.19.3">99.89</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.12.12.31.19.4">0.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.31.19.5">0.43</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.31.19.6">99.35</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.12.12.31.19.7">0.22</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.31.19.8">1.39</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.31.19.9">98.28</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.12.12.31.19.10">0.32</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.31.19.11">1.29</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.31.19.12">98.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.31.19.13">0.21</td>
</tr>
<tr class="ltx_tr" id="S4.T2.12.12.32.20">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="14" id="S4.T2.12.12.32.20.1" style="background-color:#E6E6E6;"><span class="ltx_text" id="S4.T2.12.12.32.20.1.1" style="background-color:#E6E6E6;">Group 2: Q with indirect evidence</span></th>
</tr>
<tr class="ltx_tr" id="S4.T2.12.12.33.21">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.12.12.33.21.1">Direct</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.12.12.33.21.2">1</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.33.21.3">0.44</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.33.21.4">99.56</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.12.12.33.21.5">0.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.33.21.6">0.45</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.33.21.7">99.33</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.12.12.33.21.8">0.22</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.33.21.9">3.07</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.33.21.10">95.28</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.12.12.33.21.11">1.65</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.33.21.12">12.53</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.33.21.13">85.29</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.33.21.14">2.18</td>
</tr>
<tr class="ltx_tr" id="S4.T2.12.12.34.22">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.12.12.34.22.1" rowspan="2"><span class="ltx_text" id="S4.T2.12.12.34.22.1.1">Indirect</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.12.12.34.22.2">2</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.34.22.3">0.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.34.22.4">100.0</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.12.12.34.22.5">0.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.34.22.6">0.11</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.34.22.7">99.89</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.12.12.34.22.8">0.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.34.22.9">3.18</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.34.22.10">96.38</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.12.12.34.22.11">0.44</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.34.22.12">13.51</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.34.22.13">85.73</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.34.22.14">0.76</td>
</tr>
<tr class="ltx_tr" id="S4.T2.12.12.35.23">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.12.12.35.23.1">3</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.35.23.2">0.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.35.23.3">100.0</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.12.12.35.23.4">0.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.35.23.5">0.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.35.23.6">100.0</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.12.12.35.23.7">0.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.35.23.8">1.76</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.35.23.9">97.91</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.12.12.35.23.10">0.33</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.35.23.11">9.26</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.35.23.12">90.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.35.23.13">0.55</td>
</tr>
<tr class="ltx_tr" id="S4.T2.12.12.36.24">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t" id="S4.T2.12.12.36.24.1" rowspan="2"><span class="ltx_text" id="S4.T2.12.12.36.24.1.1">Direct + Indirect</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.12.12.36.24.2">2</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.36.24.3">0.22</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.36.24.4">99.78</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.12.12.36.24.5">0.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.36.24.6">0.11</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.36.24.7">99.78</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.12.12.36.24.8">0.11</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.36.24.9">1.87</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.36.24.10">97.26</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.12.12.36.24.11">0.88</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.36.24.12">7.95</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.36.24.13">91.18</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.12.12.36.24.14">0.87</td>
</tr>
<tr class="ltx_tr" id="S4.T2.12.12.37.25">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t" id="S4.T2.12.12.37.25.1">3</th>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T2.12.12.37.25.2">0.11</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T2.12.12.37.25.3">99.89</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.T2.12.12.37.25.4">0.0</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T2.12.12.37.25.5">0.11</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T2.12.12.37.25.6">99.78</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.T2.12.12.37.25.7">0.11</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T2.12.12.37.25.8">1.43</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T2.12.12.37.25.9">98.13</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S4.T2.12.12.37.25.10">0.44</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T2.12.12.37.25.11">5.12</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T2.12.12.37.25.12">94.77</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T2.12.12.37.25.13">0.11</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Results of LLM Receptiveness to Different Evidence Styles Across NQ and popQA Datasets.
The table presents the MA ratio (<math alttext="R_{m}" class="ltx_Math" display="inline" id="S4.T2.16.m1.1"><semantics id="S4.T2.16.m1.1b"><msub id="S4.T2.16.m1.1.1" xref="S4.T2.16.m1.1.1.cmml"><mi id="S4.T2.16.m1.1.1.2" xref="S4.T2.16.m1.1.1.2.cmml">R</mi><mi id="S4.T2.16.m1.1.1.3" xref="S4.T2.16.m1.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="S4.T2.16.m1.1c"><apply id="S4.T2.16.m1.1.1.cmml" xref="S4.T2.16.m1.1.1"><csymbol cd="ambiguous" id="S4.T2.16.m1.1.1.1.cmml" xref="S4.T2.16.m1.1.1">subscript</csymbol><ci id="S4.T2.16.m1.1.1.2.cmml" xref="S4.T2.16.m1.1.1.2">𝑅</ci><ci id="S4.T2.16.m1.1.1.3.cmml" xref="S4.T2.16.m1.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.16.m1.1d">R_{m}</annotation><annotation encoding="application/x-llamapun" id="S4.T2.16.m1.1e">italic_R start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT</annotation></semantics></math>), CMA ratio (<math alttext="R_{c}" class="ltx_Math" display="inline" id="S4.T2.17.m2.1"><semantics id="S4.T2.17.m2.1b"><msub id="S4.T2.17.m2.1.1" xref="S4.T2.17.m2.1.1.cmml"><mi id="S4.T2.17.m2.1.1.2" xref="S4.T2.17.m2.1.1.2.cmml">R</mi><mi id="S4.T2.17.m2.1.1.3" xref="S4.T2.17.m2.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S4.T2.17.m2.1c"><apply id="S4.T2.17.m2.1.1.cmml" xref="S4.T2.17.m2.1.1"><csymbol cd="ambiguous" id="S4.T2.17.m2.1.1.1.cmml" xref="S4.T2.17.m2.1.1">subscript</csymbol><ci id="S4.T2.17.m2.1.1.2.cmml" xref="S4.T2.17.m2.1.1.2">𝑅</ci><ci id="S4.T2.17.m2.1.1.3.cmml" xref="S4.T2.17.m2.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.17.m2.1d">R_{c}</annotation><annotation encoding="application/x-llamapun" id="S4.T2.17.m2.1e">italic_R start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT</annotation></semantics></math>), and uncertain answer ratio (<math alttext="R_{u}" class="ltx_Math" display="inline" id="S4.T2.18.m3.1"><semantics id="S4.T2.18.m3.1b"><msub id="S4.T2.18.m3.1.1" xref="S4.T2.18.m3.1.1.cmml"><mi id="S4.T2.18.m3.1.1.2" xref="S4.T2.18.m3.1.1.2.cmml">R</mi><mi id="S4.T2.18.m3.1.1.3" xref="S4.T2.18.m3.1.1.3.cmml">u</mi></msub><annotation-xml encoding="MathML-Content" id="S4.T2.18.m3.1c"><apply id="S4.T2.18.m3.1.1.cmml" xref="S4.T2.18.m3.1.1"><csymbol cd="ambiguous" id="S4.T2.18.m3.1.1.1.cmml" xref="S4.T2.18.m3.1.1">subscript</csymbol><ci id="S4.T2.18.m3.1.1.2.cmml" xref="S4.T2.18.m3.1.1.2">𝑅</ci><ci id="S4.T2.18.m3.1.1.3.cmml" xref="S4.T2.18.m3.1.1.3">𝑢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.18.m3.1d">R_{u}</annotation><annotation encoding="application/x-llamapun" id="S4.T2.18.m3.1e">italic_R start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT</annotation></semantics></math>) for various evidence styles across four models. All the ratios are in %.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1"><span class="ltx_text ltx_font_bold" id="S4.SS3.p1.1.1">Evidence Styles.</span>
We formulate four types of evidence styles:
<span class="ltx_text ltx_font_bold" id="S4.SS3.p1.1.2">1)</span> Direct Evidence. This is the most straightforward form of evidence and serves as our baseline. To assess the impact of evidence length, we also create versions where the direct evidence is repeated twice and three times for comparison.
<span class="ltx_text ltx_font_bold" id="S4.SS3.p1.1.3">2)</span> Direct Evidence Combined with Paraphrases of CMA (Direct + Paraphrase). To examine the effect of evidence phrasing and expression, we combine the direct evidence with one paraphrase of the CMA to form a two-sentence evidence and with two paraphrases to form a three-sentence evidence.
<span class="ltx_text ltx_font_bold" id="S4.SS3.p1.1.4">3)</span> Indirect Evidence. We generate indirect evidence consisting of two sentences and three sentences, respectively<span class="ltx_note ltx_role_footnote" id="footnote7"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span>We regulate the length of the generated evidence to control the influence of evidence length. The prompts used are detailed in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#A3.T9" title="Table 9 ‣ Appendix C Prompts ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_tag">9</span></a> (index 7) in Appendix.</span></span></span>.
<span class="ltx_text ltx_font_bold" id="S4.SS3.p1.1.5">4)</span> Direct Evidence Combined with Indirect Evidence (Direct + Indirect). We combine the direct evidence with the first sentence of the two-sentence indirect evidence to form a two-sentence evidence and with both sentences to form a three-sentence evidence.</p>
</div>
<div class="ltx_para" id="S4.SS3.p2">
<p class="ltx_p" id="S4.SS3.p2.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#S4.T1" title="Table 1 ‣ 4.3 Impact of Evidence Style ‣ 4 Experiments ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_tag">1</span></a> presents the final number of instances used for evaluation. We observe a slight difference in the quantities of questions with direct and indirect evidence since it is easier for ChatGPT to generate direct evidence that meets our requirements. The specific number of instances at each step in evidence generation is detailed in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#A2.T7" title="Table 7 ‣ B.2 Dataset Details ‣ Appendix B Methodology and Experiment Details ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_tag">7</span></a> in the Appendix. Due to the quantity difference between direct evidence and indirect evidence, we divide the styles of evidence into two groups: Group 1 includes direct evidence and direct + paraphrase evidence. Group 2 includes indirect evidence and direct + indirect evidence. Each group has different Direct Evidence results serving as baselines.</p>
</div>
<div class="ltx_para" id="S4.SS3.p3">
<p class="ltx_p" id="S4.SS3.p3.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#S4.T2" title="Table 2 ‣ 4.3 Impact of Evidence Style ‣ 4 Experiments ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_tag">2</span></a> shows the results of different evidence styles. We can make the following observations and conclusions.</p>
</div>
<div class="ltx_para" id="S4.SS3.p4">
<p class="ltx_p" id="S4.SS3.p4.4"><span class="ltx_text ltx_font_bold" id="S4.SS3.p4.1.1">In Group 2, <math alttext="R_{m}" class="ltx_Math" display="inline" id="S4.SS3.p4.1.1.m1.1"><semantics id="S4.SS3.p4.1.1.m1.1a"><msub id="S4.SS3.p4.1.1.m1.1.1" xref="S4.SS3.p4.1.1.m1.1.1.cmml"><mi id="S4.SS3.p4.1.1.m1.1.1.2" xref="S4.SS3.p4.1.1.m1.1.1.2.cmml">R</mi><mi id="S4.SS3.p4.1.1.m1.1.1.3" xref="S4.SS3.p4.1.1.m1.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p4.1.1.m1.1b"><apply id="S4.SS3.p4.1.1.m1.1.1.cmml" xref="S4.SS3.p4.1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS3.p4.1.1.m1.1.1.1.cmml" xref="S4.SS3.p4.1.1.m1.1.1">subscript</csymbol><ci id="S4.SS3.p4.1.1.m1.1.1.2.cmml" xref="S4.SS3.p4.1.1.m1.1.1.2">𝑅</ci><ci id="S4.SS3.p4.1.1.m1.1.1.3.cmml" xref="S4.SS3.p4.1.1.m1.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p4.1.1.m1.1c">R_{m}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p4.1.1.m1.1d">italic_R start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT</annotation></semantics></math> of direct evidence with one sentence is slightly lower than that in Group 1</span>.
During the evidence generation, there are some questions for which ChatGPT can provide direct evidence but cannot produce indirect evidence. Removing these questions leads to a decrease in <math alttext="R_{m}" class="ltx_Math" display="inline" id="S4.SS3.p4.2.m1.1"><semantics id="S4.SS3.p4.2.m1.1a"><msub id="S4.SS3.p4.2.m1.1.1" xref="S4.SS3.p4.2.m1.1.1.cmml"><mi id="S4.SS3.p4.2.m1.1.1.2" xref="S4.SS3.p4.2.m1.1.1.2.cmml">R</mi><mi id="S4.SS3.p4.2.m1.1.1.3" xref="S4.SS3.p4.2.m1.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p4.2.m1.1b"><apply id="S4.SS3.p4.2.m1.1.1.cmml" xref="S4.SS3.p4.2.m1.1.1"><csymbol cd="ambiguous" id="S4.SS3.p4.2.m1.1.1.1.cmml" xref="S4.SS3.p4.2.m1.1.1">subscript</csymbol><ci id="S4.SS3.p4.2.m1.1.1.2.cmml" xref="S4.SS3.p4.2.m1.1.1.2">𝑅</ci><ci id="S4.SS3.p4.2.m1.1.1.3.cmml" xref="S4.SS3.p4.2.m1.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p4.2.m1.1c">R_{m}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p4.2.m1.1d">italic_R start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT</annotation></semantics></math> of direct evidence with one sentence, which implies that LLMs have a relatively high <math alttext="R_{m}" class="ltx_Math" display="inline" id="S4.SS3.p4.3.m2.1"><semantics id="S4.SS3.p4.3.m2.1a"><msub id="S4.SS3.p4.3.m2.1.1" xref="S4.SS3.p4.3.m2.1.1.cmml"><mi id="S4.SS3.p4.3.m2.1.1.2" xref="S4.SS3.p4.3.m2.1.1.2.cmml">R</mi><mi id="S4.SS3.p4.3.m2.1.1.3" xref="S4.SS3.p4.3.m2.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p4.3.m2.1b"><apply id="S4.SS3.p4.3.m2.1.1.cmml" xref="S4.SS3.p4.3.m2.1.1"><csymbol cd="ambiguous" id="S4.SS3.p4.3.m2.1.1.1.cmml" xref="S4.SS3.p4.3.m2.1.1">subscript</csymbol><ci id="S4.SS3.p4.3.m2.1.1.2.cmml" xref="S4.SS3.p4.3.m2.1.1.2">𝑅</ci><ci id="S4.SS3.p4.3.m2.1.1.3.cmml" xref="S4.SS3.p4.3.m2.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p4.3.m2.1c">R_{m}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p4.3.m2.1d">italic_R start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT</annotation></semantics></math> for the removed questions. But in general, the <math alttext="R_{m}" class="ltx_Math" display="inline" id="S4.SS3.p4.4.m3.1"><semantics id="S4.SS3.p4.4.m3.1a"><msub id="S4.SS3.p4.4.m3.1.1" xref="S4.SS3.p4.4.m3.1.1.cmml"><mi id="S4.SS3.p4.4.m3.1.1.2" xref="S4.SS3.p4.4.m3.1.1.2.cmml">R</mi><mi id="S4.SS3.p4.4.m3.1.1.3" xref="S4.SS3.p4.4.m3.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p4.4.m3.1b"><apply id="S4.SS3.p4.4.m3.1.1.cmml" xref="S4.SS3.p4.4.m3.1.1"><csymbol cd="ambiguous" id="S4.SS3.p4.4.m3.1.1.1.cmml" xref="S4.SS3.p4.4.m3.1.1">subscript</csymbol><ci id="S4.SS3.p4.4.m3.1.1.2.cmml" xref="S4.SS3.p4.4.m3.1.1.2">𝑅</ci><ci id="S4.SS3.p4.4.m3.1.1.3.cmml" xref="S4.SS3.p4.4.m3.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p4.4.m3.1c">R_{m}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p4.4.m3.1d">italic_R start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT</annotation></semantics></math> of direct evidence with one sentence in Group 1 is close to that in Group 2, so the results of Group 1 and Group 2 are still comparable.</p>
</div>
<div class="ltx_para" id="S4.SS3.p5">
<p class="ltx_p" id="S4.SS3.p5.4"><span class="ltx_text ltx_font_bold" id="S4.SS3.p5.4.1">Simple repetition of direct evidence is ineffective, except for GPT-4</span>. Comparing direct evidence with one to three sentences, we observe similar <math alttext="R_{m}" class="ltx_Math" display="inline" id="S4.SS3.p5.1.m1.1"><semantics id="S4.SS3.p5.1.m1.1a"><msub id="S4.SS3.p5.1.m1.1.1" xref="S4.SS3.p5.1.m1.1.1.cmml"><mi id="S4.SS3.p5.1.m1.1.1.2" xref="S4.SS3.p5.1.m1.1.1.2.cmml">R</mi><mi id="S4.SS3.p5.1.m1.1.1.3" xref="S4.SS3.p5.1.m1.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p5.1.m1.1b"><apply id="S4.SS3.p5.1.m1.1.1.cmml" xref="S4.SS3.p5.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS3.p5.1.m1.1.1.1.cmml" xref="S4.SS3.p5.1.m1.1.1">subscript</csymbol><ci id="S4.SS3.p5.1.m1.1.1.2.cmml" xref="S4.SS3.p5.1.m1.1.1.2">𝑅</ci><ci id="S4.SS3.p5.1.m1.1.1.3.cmml" xref="S4.SS3.p5.1.m1.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p5.1.m1.1c">R_{m}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p5.1.m1.1d">italic_R start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="R_{c}" class="ltx_Math" display="inline" id="S4.SS3.p5.2.m2.1"><semantics id="S4.SS3.p5.2.m2.1a"><msub id="S4.SS3.p5.2.m2.1.1" xref="S4.SS3.p5.2.m2.1.1.cmml"><mi id="S4.SS3.p5.2.m2.1.1.2" xref="S4.SS3.p5.2.m2.1.1.2.cmml">R</mi><mi id="S4.SS3.p5.2.m2.1.1.3" xref="S4.SS3.p5.2.m2.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p5.2.m2.1b"><apply id="S4.SS3.p5.2.m2.1.1.cmml" xref="S4.SS3.p5.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS3.p5.2.m2.1.1.1.cmml" xref="S4.SS3.p5.2.m2.1.1">subscript</csymbol><ci id="S4.SS3.p5.2.m2.1.1.2.cmml" xref="S4.SS3.p5.2.m2.1.1.2">𝑅</ci><ci id="S4.SS3.p5.2.m2.1.1.3.cmml" xref="S4.SS3.p5.2.m2.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p5.2.m2.1c">R_{c}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p5.2.m2.1d">italic_R start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT</annotation></semantics></math> for most LLMs, except for GPT-4. On direct evidence with two and three sentences, <math alttext="R_{m}" class="ltx_Math" display="inline" id="S4.SS3.p5.3.m3.1"><semantics id="S4.SS3.p5.3.m3.1a"><msub id="S4.SS3.p5.3.m3.1.1" xref="S4.SS3.p5.3.m3.1.1.cmml"><mi id="S4.SS3.p5.3.m3.1.1.2" xref="S4.SS3.p5.3.m3.1.1.2.cmml">R</mi><mi id="S4.SS3.p5.3.m3.1.1.3" xref="S4.SS3.p5.3.m3.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p5.3.m3.1b"><apply id="S4.SS3.p5.3.m3.1.1.cmml" xref="S4.SS3.p5.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS3.p5.3.m3.1.1.1.cmml" xref="S4.SS3.p5.3.m3.1.1">subscript</csymbol><ci id="S4.SS3.p5.3.m3.1.1.2.cmml" xref="S4.SS3.p5.3.m3.1.1.2">𝑅</ci><ci id="S4.SS3.p5.3.m3.1.1.3.cmml" xref="S4.SS3.p5.3.m3.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p5.3.m3.1c">R_{m}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p5.3.m3.1d">italic_R start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT</annotation></semantics></math> of GPT-4 decreases significantly, and <math alttext="R_{c}" class="ltx_Math" display="inline" id="S4.SS3.p5.4.m4.1"><semantics id="S4.SS3.p5.4.m4.1a"><msub id="S4.SS3.p5.4.m4.1.1" xref="S4.SS3.p5.4.m4.1.1.cmml"><mi id="S4.SS3.p5.4.m4.1.1.2" xref="S4.SS3.p5.4.m4.1.1.2.cmml">R</mi><mi id="S4.SS3.p5.4.m4.1.1.3" xref="S4.SS3.p5.4.m4.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p5.4.m4.1b"><apply id="S4.SS3.p5.4.m4.1.1.cmml" xref="S4.SS3.p5.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS3.p5.4.m4.1.1.1.cmml" xref="S4.SS3.p5.4.m4.1.1">subscript</csymbol><ci id="S4.SS3.p5.4.m4.1.1.2.cmml" xref="S4.SS3.p5.4.m4.1.1.2">𝑅</ci><ci id="S4.SS3.p5.4.m4.1.1.3.cmml" xref="S4.SS3.p5.4.m4.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p5.4.m4.1c">R_{c}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p5.4.m4.1d">italic_R start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT</annotation></semantics></math> increases significantly. The results imply that simple repetition of direct evidence has no improvement in the LLMs’ receptiveness to CMAs for LLaMA2.7B, LLaMA2.70B, and ChatGPT.</p>
</div>
<div class="ltx_para" id="S4.SS3.p6">
<p class="ltx_p" id="S4.SS3.p6.2"><span class="ltx_text ltx_font_bold" id="S4.SS3.p6.2.1">Paraphrasing direct evidence is highly effective across all models and datasets</span>. Comparing direct with two and three sentences and direct + paraphrase with two and three sentences, we observe <math alttext="R_{m}" class="ltx_Math" display="inline" id="S4.SS3.p6.1.m1.1"><semantics id="S4.SS3.p6.1.m1.1a"><msub id="S4.SS3.p6.1.m1.1.1" xref="S4.SS3.p6.1.m1.1.1.cmml"><mi id="S4.SS3.p6.1.m1.1.1.2" xref="S4.SS3.p6.1.m1.1.1.2.cmml">R</mi><mi id="S4.SS3.p6.1.m1.1.1.3" xref="S4.SS3.p6.1.m1.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p6.1.m1.1b"><apply id="S4.SS3.p6.1.m1.1.1.cmml" xref="S4.SS3.p6.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS3.p6.1.m1.1.1.1.cmml" xref="S4.SS3.p6.1.m1.1.1">subscript</csymbol><ci id="S4.SS3.p6.1.m1.1.1.2.cmml" xref="S4.SS3.p6.1.m1.1.1.2">𝑅</ci><ci id="S4.SS3.p6.1.m1.1.1.3.cmml" xref="S4.SS3.p6.1.m1.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p6.1.m1.1c">R_{m}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p6.1.m1.1d">italic_R start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT</annotation></semantics></math> of paraphrase evidence decrease significantly. For example, <math alttext="R_{m}" class="ltx_Math" display="inline" id="S4.SS3.p6.2.m2.1"><semantics id="S4.SS3.p6.2.m2.1a"><msub id="S4.SS3.p6.2.m2.1.1" xref="S4.SS3.p6.2.m2.1.1.cmml"><mi id="S4.SS3.p6.2.m2.1.1.2" xref="S4.SS3.p6.2.m2.1.1.2.cmml">R</mi><mi id="S4.SS3.p6.2.m2.1.1.3" xref="S4.SS3.p6.2.m2.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p6.2.m2.1b"><apply id="S4.SS3.p6.2.m2.1.1.cmml" xref="S4.SS3.p6.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS3.p6.2.m2.1.1.1.cmml" xref="S4.SS3.p6.2.m2.1.1">subscript</csymbol><ci id="S4.SS3.p6.2.m2.1.1.2.cmml" xref="S4.SS3.p6.2.m2.1.1.2">𝑅</ci><ci id="S4.SS3.p6.2.m2.1.1.3.cmml" xref="S4.SS3.p6.2.m2.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p6.2.m2.1c">R_{m}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p6.2.m2.1d">italic_R start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT</annotation></semantics></math> is reduced by more than half, comparing paraphrase with three sentences with direct with three sentences. The result implies that paraphrasing is an effective method to enhance the receptiveness of LLMs to external evidence.</p>
</div>
<div class="ltx_para" id="S4.SS3.p7">
<p class="ltx_p" id="S4.SS3.p7.1"><span class="ltx_text ltx_font_bold" id="S4.SS3.p7.1.1">Indirect evidence improves LLMs’ receptiveness to CMAs, but less effectively than paraphrasing</span>.
Comparing indirect evidence with two and three sentences with direct evidence with one sentence, <math alttext="R_{m}" class="ltx_Math" display="inline" id="S4.SS3.p7.1.m1.1"><semantics id="S4.SS3.p7.1.m1.1a"><msub id="S4.SS3.p7.1.m1.1.1" xref="S4.SS3.p7.1.m1.1.1.cmml"><mi id="S4.SS3.p7.1.m1.1.1.2" xref="S4.SS3.p7.1.m1.1.1.2.cmml">R</mi><mi id="S4.SS3.p7.1.m1.1.1.3" xref="S4.SS3.p7.1.m1.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p7.1.m1.1b"><apply id="S4.SS3.p7.1.m1.1.1.cmml" xref="S4.SS3.p7.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS3.p7.1.m1.1.1.1.cmml" xref="S4.SS3.p7.1.m1.1.1">subscript</csymbol><ci id="S4.SS3.p7.1.m1.1.1.2.cmml" xref="S4.SS3.p7.1.m1.1.1.2">𝑅</ci><ci id="S4.SS3.p7.1.m1.1.1.3.cmml" xref="S4.SS3.p7.1.m1.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p7.1.m1.1c">R_{m}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p7.1.m1.1d">italic_R start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT</annotation></semantics></math> decreased. But compared to the direct + paraphrase evidence with two or three sentences, the reduction is not significant. It implies that adding detailed information is less effective than paraphrasing direct evidence.</p>
</div>
<div class="ltx_para" id="S4.SS3.p8">
<p class="ltx_p" id="S4.SS3.p8.2"><span class="ltx_text ltx_font_bold" id="S4.SS3.p8.2.1">Combining direct evidence with indirect evidence generally enhances persuasiveness, except for LLaMA2.7B</span>. Comparing direct + indirect evidence with indirect evidence, <math alttext="R_{m}" class="ltx_Math" display="inline" id="S4.SS3.p8.1.m1.1"><semantics id="S4.SS3.p8.1.m1.1a"><msub id="S4.SS3.p8.1.m1.1.1" xref="S4.SS3.p8.1.m1.1.1.cmml"><mi id="S4.SS3.p8.1.m1.1.1.2" xref="S4.SS3.p8.1.m1.1.1.2.cmml">R</mi><mi id="S4.SS3.p8.1.m1.1.1.3" xref="S4.SS3.p8.1.m1.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p8.1.m1.1b"><apply id="S4.SS3.p8.1.m1.1.1.cmml" xref="S4.SS3.p8.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS3.p8.1.m1.1.1.1.cmml" xref="S4.SS3.p8.1.m1.1.1">subscript</csymbol><ci id="S4.SS3.p8.1.m1.1.1.2.cmml" xref="S4.SS3.p8.1.m1.1.1.2">𝑅</ci><ci id="S4.SS3.p8.1.m1.1.1.3.cmml" xref="S4.SS3.p8.1.m1.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p8.1.m1.1c">R_{m}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p8.1.m1.1d">italic_R start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT</annotation></semantics></math> decreases except for LLaMA2.7B. For example, comparing direct + indirect with three sentences and indirect evidence with three sentences, <math alttext="R_{m}" class="ltx_Math" display="inline" id="S4.SS3.p8.2.m2.1"><semantics id="S4.SS3.p8.2.m2.1a"><msub id="S4.SS3.p8.2.m2.1.1" xref="S4.SS3.p8.2.m2.1.1.cmml"><mi id="S4.SS3.p8.2.m2.1.1.2" xref="S4.SS3.p8.2.m2.1.1.2.cmml">R</mi><mi id="S4.SS3.p8.2.m2.1.1.3" xref="S4.SS3.p8.2.m2.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p8.2.m2.1b"><apply id="S4.SS3.p8.2.m2.1.1.cmml" xref="S4.SS3.p8.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS3.p8.2.m2.1.1.1.cmml" xref="S4.SS3.p8.2.m2.1.1">subscript</csymbol><ci id="S4.SS3.p8.2.m2.1.1.2.cmml" xref="S4.SS3.p8.2.m2.1.1.2">𝑅</ci><ci id="S4.SS3.p8.2.m2.1.1.3.cmml" xref="S4.SS3.p8.2.m2.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p8.2.m2.1c">R_{m}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p8.2.m2.1d">italic_R start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT</annotation></semantics></math> has an obvious decrease. The result implies that adding direct evidence to indirect evidence is effective in improving LLMs’ receptiveness to CMAs.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">We investigate how context-faithful LLMs are to external evidence across two datasets, PopQA and NQ datasets, using LLaMA2.7B, LLaMA2.70B, ChatGPT, and GPT-4. Our findings highlight the critical role of memory strength in shaping LLM behavior. There is a clear positive correlation between memory strength and memory answer ratio. Furthermore, we demonstrate that paraphrasing significantly enhances the context-faithfulness of LLMs across various models and datasets.
In conclusion, our results emphasize the influence of memory strength on the context-faithfulness of LLMs and show that paraphrasing direct evidence improves the receptiveness of LLMs to external evidence. These findings offer valuable insights for advancing research in retrieval-augmented generation and context-based LLM applications.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">Limitations</h2>
<div class="ltx_para" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">Our framework does not process all types of questions in the NQ dataset. Although it effectively handles the majority of NQ questions, it currently lacks the capability to address "what," "how," and "why" question types. The omission of these questions may introduce some bias into our results. Similar to previous studies, our study also focuses on knowledge conflict for extractive QA tasks, where the answer must appear in the evidence. Our conclusion may not be extendable to other types of QA tasks, such as abstractive QA and generative QA.</p>
</div>
<div class="ltx_para" id="Sx1.p2">
<p class="ltx_p" id="Sx1.p2.1">We employed a Natural Language Inference (NLI) model to detect and filter the generated data. Although the NLI model demonstrates high accuracy and the quality of generated data is high, it still cannot guarantee complete correctness. Further, since the NLI model is also trained using language models, which may be biased with parametric memory, it may introduce biases facing knowledge conflicts.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bianchini et al. (2024)</span>
<span class="ltx_bibblock">
Filippo Bianchini, Marco Calamo, Francesca De Luzi, Mattia Macrì, and Massimo Mecella. 2024.

</span>
<span class="ltx_bibblock">Enhancing complex linguistic tasks resolution through fine-tuning llms, rag and knowledge graphs (short paper).

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">International Conference on Advanced Information Systems Engineering</em>, pages 147–155. Springer.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2022)</span>
<span class="ltx_bibblock">
Hung-Ting Chen, Michael Zhang, and Eunsol Choi. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2022.emnlp-main.146" title="">Rich knowledge sources bring complex knowledge conflicts: Recalibrating models to reflect conflicting evidence</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing</em>, pages 2292–2307, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fan et al. (2024)</span>
<span class="ltx_bibblock">
Wenqi Fan, Yujuan Ding, Liangbo Ning, Shijie Wang, Hengyun Li, Dawei Yin, Tat-Seng Chua, and Qing Li. 2024.

</span>
<span class="ltx_bibblock">A survey on rag meeting llms: Towards retrieval-augmented large language models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</em>, pages 6491–6501.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao and Callan (2022)</span>
<span class="ltx_bibblock">
Luyu Gao and Jamie Callan. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2022.acl-long.203" title="">Unsupervised corpus aware language model pre-training for dense passage retrieval</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 2843–2853, Dublin, Ireland. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Izacard et al. (2024)</span>
<span class="ltx_bibblock">
Gautier Izacard, Patrick Lewis, Maria Lomeli, Lucas Hosseini, Fabio Petroni, Timo Schick, Jane Dwivedi-Yu, Armand Joulin, Sebastian Riedel, and Edouard Grave. 2024.

</span>
<span class="ltx_bibblock">Atlas: few-shot learning with retrieval augmented language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">J. Mach. Learn. Res.</em>, 24(1).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jeong (2023)</span>
<span class="ltx_bibblock">
Cheonsu Jeong. 2023.

</span>
<span class="ltx_bibblock">Generative ai service implementation using llm application architecture: based on rag model and langchain framework.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">Journal of Intelligence and Information Systems</em>, 29(4):129–164.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jin et al. (2024)</span>
<span class="ltx_bibblock">
Zhuoran Jin, Pengfei Cao, Yubo Chen, Kang Liu, Xiaojian Jiang, Jiexin Xu, Li Qiuxia, and Jun Zhao. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2024.lrec-main.1466" title="">Tug-of-war between knowledge: Exploring and resolving knowledge conflicts in retrieval-augmented language models</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)</em>, pages 16867–16878, Torino, Italia. ELRA and ICCL.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Karpukhin et al. (2020)</span>
<span class="ltx_bibblock">
Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2020.emnlp-main.550" title="">Dense passage retrieval for open-domain question answering</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>, pages 6769–6781, Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kasai et al. (2023)</span>
<span class="ltx_bibblock">
Jungo Kasai, Keisuke Sakaguchi, yoichi takahashi, Ronan Le Bras, Akari Asai, Xinyan Yu, Dragomir Radev, Noah A Smith, Yejin Choi, and Kentaro Inui. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://proceedings.neurips.cc/paper_files/paper/2023/file/9941624ef7f867a502732b5154d30cb7-Paper-Datasets_and_Benchmarks.pdf" title="">Realtime qa: What's the answer right now?</a>
</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">Advances in Neural Information Processing Systems</em>, volume 36, pages 49025–49043. Curran Associates, Inc.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kassner et al. (2021)</span>
<span class="ltx_bibblock">
Nora Kassner, Oyvind Tafjord, Hinrich Schütze, and Peter Clark. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2021.emnlp-main.697" title="">BeliefBank: Adding memory to a pre-trained language model for a systematic notion of belief</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</em>, pages 8849–8861, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Khattab et al. (2022)</span>
<span class="ltx_bibblock">
Omar Khattab, Keshav Santhanam, Xiang Lisa Li, David Hall, Percy Liang, Christopher Potts, and Matei Zaharia. 2022.

</span>
<span class="ltx_bibblock">Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">arXiv preprint arXiv:2212.14024</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kwiatkowski et al. (2019)</span>
<span class="ltx_bibblock">
Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Matthew Kelcey, Jacob Devlin, Kenton Lee, Kristina N. Toutanova, Llion Jones, Ming-Wei Chang, Andrew Dai, Jakob Uszkoreit, Quoc Le, and Slav Petrov. 2019.

</span>
<span class="ltx_bibblock">Natural questions: a benchmark for question answering research.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">Transactions of the Association of Computational Linguistics</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lazaridou et al. (2022)</span>
<span class="ltx_bibblock">
Angeliki Lazaridou, Elena Gribovskaya, Wojciech Stokowiec, and Nikolai Grigorev. 2022.

</span>
<span class="ltx_bibblock">Internet-augmented language models through few-shot prompting for open-domain question answering.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">arXiv preprint arXiv:2203.05115</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lazaridou et al. (2021)</span>
<span class="ltx_bibblock">
Angeliki Lazaridou, Adhi Kuncoro, Elena Gribovskaya, Devang Agrawal, Adam Liska, Tayfun Terzi, Mai Gimenez, Cyprien de Masson d’Autume, Tomas Kocisky, Sebastian Ruder, et al. 2021.

</span>
<span class="ltx_bibblock">Mind the gap: Assessing temporal generalization in neural language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">Advances in Neural Information Processing Systems</em>, 34:29348–29363.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2023)</span>
<span class="ltx_bibblock">
Daliang Li, Ankit Singh Rawat, Manzil Zaheer, Xin Wang, Michal Lukasik, Andreas Veit, Felix Yu, and Sanjiv Kumar. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.findings-acl.112" title="">Large language models with controllable working memory</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">Findings of the Association for Computational Linguistics: ACL 2023</em>, pages 1774–1793, Toronto, Canada. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Longpre et al. (2021)</span>
<span class="ltx_bibblock">
Shayne Longpre, Kartik Perisetla, Anthony Chen, Nikhil Ramesh, Chris DuBois, and Sameer Singh. 2021.

</span>
<span class="ltx_bibblock">Entity-based knowledge conflicts in question answering.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">arXiv preprint arXiv:2109.05052</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mallen et al. (2023)</span>
<span class="ltx_bibblock">
Alex Mallen, Akari Asai, Victor Zhong, Rajarshi Das, Daniel Khashabi, and Hannaneh Hajishirzi. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.acl-long.546" title="">When not to trust language models: Investigating effectiveness of parametric and non-parametric memories</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 9802–9822, Toronto, Canada. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Neeman et al. (2023)</span>
<span class="ltx_bibblock">
Ella Neeman, Roee Aharoni, Or Honovich, Leshem Choshen, Idan Szpektor, and Omri Abend. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.acl-long.559" title="">DisentQA: Disentangling parametric and contextual knowledge with counterfactual question answering</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 10056–10070, Toronto, Canada. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2023a)</span>
<span class="ltx_bibblock">
OpenAI. 2023a.

</span>
<span class="ltx_bibblock">Chatgpt: Large Language Model.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://chat.openai.com" title="">https://chat.openai.com</a>.

</span>
<span class="ltx_bibblock">September 2023 version.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2023b)</span>
<span class="ltx_bibblock">
OpenAI. 2023b.

</span>
<span class="ltx_bibblock">Gpt-4 technical report.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openai.com/research/gpt-4" title="">https://openai.com/research/gpt-4</a>.

</span>
<span class="ltx_bibblock">March 2023 version.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pan et al. (2021)</span>
<span class="ltx_bibblock">
Liangming Pan, Wenhu Chen, Min-Yen Kan, and William Yang Wang. 2021.

</span>
<span class="ltx_bibblock">Contraqa: Question answering under contradicting contexts.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Petroni et al. (2020)</span>
<span class="ltx_bibblock">
Fabio Petroni, Patrick Lewis, Aleksandra Piktus, Tim Rocktäschel, Yuxiang Wu, Alexander H. Miller, and Sebastian Riedel. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://openreview.net/forum?id=025X0zPfn" title="">How context affects language models’ factual predictions</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">Automated Knowledge Base Construction</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Procko (2024)</span>
<span class="ltx_bibblock">
Tyler Procko. 2024.

</span>
<span class="ltx_bibblock">Graph retrieval-augmented generation for large language models: A survey.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">Available at SSRN</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Santhanam et al. (2022)</span>
<span class="ltx_bibblock">
Keshav Santhanam, Omar Khattab, Jon Saad-Falcon, Christopher Potts, and Matei Zaharia. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2022.naacl-main.272" title="">ColBERTv2: Effective and efficient retrieval via lightweight late interaction</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</em>, pages 3715–3734, Seattle, United States. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Si et al. (2023)</span>
<span class="ltx_bibblock">
Chenglei Si, Zhe Gan, Zhengyuan Yang, Shuohang Wang, Jianfeng Wang, Jordan Lee Boyd-Graber, and Lijuan Wang. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://openreview.net/forum?id=98p5x51L5af" title="">Prompting GPT-3 to be reliable</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">The Eleventh International Conference on Learning Representations</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Siriwardhana et al. (2023)</span>
<span class="ltx_bibblock">
Shamane Siriwardhana, Rivindu Weerasekera, Elliott Wen, Tharindu Kaluarachchi, Rajib Rana, and Suranga Nanayakkara. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1162/tacl_a_00530" title="">Improving the domain adaptation of retrieval augmented generation (RAG) models for open domain question answering</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">Transactions of the Association for Computational Linguistics</em>, 11:1–17.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et al. (2023)</span>
<span class="ltx_bibblock">
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, and et al. Shruti Bhosale. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2307.09288" title="">Llama 2: Open foundation and fine-tuned chat models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">Preprint</em>, arXiv:2307.09288.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vakayil et al. (2024)</span>
<span class="ltx_bibblock">
Sonia Vakayil, D. Sujitha Juliet, Anitha. J, and Sunil Vakayil. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1109/ICDCS59278.2024.10561020" title="">Rag-based llm chatbot using llama-2</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">2024 7th International Conference on Devices, Circuits and Systems (ICDCS)</em>, pages 1–5.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2024)</span>
<span class="ltx_bibblock">
Chengrui Wang, Qingqing Long, Xiao Meng, Xunxin Cai, Chengjun Wu, Zhen Meng, Xuezhi Wang, and Yuanchun Zhou. 2024.

</span>
<span class="ltx_bibblock">Biorag: A rag-llm framework for biological question reasoning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">arXiv preprint arXiv:2408.01107</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2023)</span>
<span class="ltx_bibblock">
Haoyu Wang, Hongming Zhang, Yuqian Deng, Jacob Gardner, Dan Roth, and Muhao Chen. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.eacl-main.39" title="">Extracting or guessing? improving faithfulness of event temporal relation extraction</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics</em>, pages 541–553, Dubrovnik, Croatia. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2022)</span>
<span class="ltx_bibblock">
Yiwei Wang, Muhao Chen, Wenxuan Zhou, Yujun Cai, Yuxuan Liang, Dayiheng Liu, Baosong Yang, Juncheng Liu, and Bryan Hooi. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2022.naacl-main.224" title="">Should we rely on entity mentions for relation extraction? debiasing relation extraction with counterfactual analysis</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</em>, pages 3071–3081, Seattle, United States. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xie et al. (2024)</span>
<span class="ltx_bibblock">
Jian Xie, Kai Zhang, Jiangjie Chen, Renze Lou, and Yu Su. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2305.13300" title="">Adaptive chameleon or stubborn sloth: Revealing the behavior of large language models in knowledge conflicts</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">The Twelfth International Conference on Learning Representations</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al. (2023)</span>
<span class="ltx_bibblock">
Ruochen Zhao, Hailin Chen, Weishi Wang, Fangkai Jiao, Xuan Long Do, Chengwei Qin, Bosheng Ding, Xiaobao Guo, Minzhi Li, Xingxuan Li, et al. 2023.

</span>
<span class="ltx_bibblock">Retrieving multimodal information for augmented generation: A survey.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">arXiv preprint arXiv:2303.10868</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al. (2024)</span>
<span class="ltx_bibblock">
Yukun Zhao, Lingyong Yan, Weiwei Sun, Guoliang Xing, Chong Meng, Shuaiqiang Wang, Zhicong Cheng, Zhaochun Ren, and Dawei Yin. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2024.naacl-long.390" title="">Knowing what LLMs DO NOT know: A simple yet effective self-detection method</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)</em>, pages 7051–7063, Mexico City, Mexico. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al. (2024)</span>
<span class="ltx_bibblock">
Kang Zhou, Yuepei Li, Qing Wang, Qiao Qiao, and Qi Li. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2024.naacl-short.22" title="">GenDecider: Integrating “none of the candidates” judgments in zero-shot entity linking re-ranking</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 2: Short Papers)</em>, pages 239–245, Mexico City, Mexico. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al. (2023)</span>
<span class="ltx_bibblock">
Wenxuan Zhou, Sheng Zhang, Hoifung Poon, and Muhao Chen. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.findings-emnlp.968" title="">Context-faithful prompting for large language models</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">Findings of the Association for Computational Linguistics: EMNLP 2023</em>, pages 14544–14556, Singapore. Association for Computational Linguistics.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_appendix" id="Ax1">
<h2 class="ltx_title ltx_title_appendix">Appendix</h2>
</section>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Additional Study</h2>
<section class="ltx_subsection" id="A1.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1 </span>Order of Options</h3>
<figure class="ltx_figure" id="A1.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="212" id="A1.F4.g1" src="extracted/5859889/fig/option_order.png" width="568"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Impact of Option orders on Memory and Counter Ratios Across NQ and popQA Datasets. Either the memory answer ("mem first") or the counter answer ("ctr first") is introduced first to four models.</figcaption>
</figure>
<figure class="ltx_table" id="A1.T3">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A1.T3.12" style="width:433.6pt;height:190.9pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-70.6pt,30.9pt) scale(0.754411958383595,0.754411958383595) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A1.T3.12.12">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.T3.12.12.13.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T3.12.12.13.1.1" rowspan="2"><span class="ltx_text" id="A1.T3.12.12.13.1.1.1">Dataset</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T3.12.12.13.1.2" rowspan="2"><span class="ltx_text" id="A1.T3.12.12.13.1.2.1">Evidence Style</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T3.12.12.13.1.3" rowspan="2"><span class="ltx_text" id="A1.T3.12.12.13.1.3.1">S #</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="3" id="A1.T3.12.12.13.1.4">LLaMA2.7B</td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="3" id="A1.T3.12.12.13.1.5">LLaMA2.70B</td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="3" id="A1.T3.12.12.13.1.6">ChatGPT</td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="3" id="A1.T3.12.12.13.1.7">GPT-4</td>
</tr>
<tr class="ltx_tr" id="A1.T3.12.12.12">
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.1.1.1.1"><math alttext="R_{m}\downarrow" class="ltx_Math" display="inline" id="A1.T3.1.1.1.1.m1.1"><semantics id="A1.T3.1.1.1.1.m1.1a"><mrow id="A1.T3.1.1.1.1.m1.1.1" xref="A1.T3.1.1.1.1.m1.1.1.cmml"><msub id="A1.T3.1.1.1.1.m1.1.1.2" xref="A1.T3.1.1.1.1.m1.1.1.2.cmml"><mi id="A1.T3.1.1.1.1.m1.1.1.2.2" xref="A1.T3.1.1.1.1.m1.1.1.2.2.cmml">R</mi><mi id="A1.T3.1.1.1.1.m1.1.1.2.3" xref="A1.T3.1.1.1.1.m1.1.1.2.3.cmml">m</mi></msub><mo id="A1.T3.1.1.1.1.m1.1.1.1" stretchy="false" xref="A1.T3.1.1.1.1.m1.1.1.1.cmml">↓</mo><mi id="A1.T3.1.1.1.1.m1.1.1.3" xref="A1.T3.1.1.1.1.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="A1.T3.1.1.1.1.m1.1b"><apply id="A1.T3.1.1.1.1.m1.1.1.cmml" xref="A1.T3.1.1.1.1.m1.1.1"><ci id="A1.T3.1.1.1.1.m1.1.1.1.cmml" xref="A1.T3.1.1.1.1.m1.1.1.1">↓</ci><apply id="A1.T3.1.1.1.1.m1.1.1.2.cmml" xref="A1.T3.1.1.1.1.m1.1.1.2"><csymbol cd="ambiguous" id="A1.T3.1.1.1.1.m1.1.1.2.1.cmml" xref="A1.T3.1.1.1.1.m1.1.1.2">subscript</csymbol><ci id="A1.T3.1.1.1.1.m1.1.1.2.2.cmml" xref="A1.T3.1.1.1.1.m1.1.1.2.2">𝑅</ci><ci id="A1.T3.1.1.1.1.m1.1.1.2.3.cmml" xref="A1.T3.1.1.1.1.m1.1.1.2.3">𝑚</ci></apply><csymbol cd="latexml" id="A1.T3.1.1.1.1.m1.1.1.3.cmml" xref="A1.T3.1.1.1.1.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.1.1.1.1.m1.1c">R_{m}\downarrow</annotation><annotation encoding="application/x-llamapun" id="A1.T3.1.1.1.1.m1.1d">italic_R start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT ↓</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.2.2.2.2"><math alttext="R_{c}\uparrow" class="ltx_Math" display="inline" id="A1.T3.2.2.2.2.m1.1"><semantics id="A1.T3.2.2.2.2.m1.1a"><mrow id="A1.T3.2.2.2.2.m1.1.1" xref="A1.T3.2.2.2.2.m1.1.1.cmml"><msub id="A1.T3.2.2.2.2.m1.1.1.2" xref="A1.T3.2.2.2.2.m1.1.1.2.cmml"><mi id="A1.T3.2.2.2.2.m1.1.1.2.2" xref="A1.T3.2.2.2.2.m1.1.1.2.2.cmml">R</mi><mi id="A1.T3.2.2.2.2.m1.1.1.2.3" xref="A1.T3.2.2.2.2.m1.1.1.2.3.cmml">c</mi></msub><mo id="A1.T3.2.2.2.2.m1.1.1.1" stretchy="false" xref="A1.T3.2.2.2.2.m1.1.1.1.cmml">↑</mo><mi id="A1.T3.2.2.2.2.m1.1.1.3" xref="A1.T3.2.2.2.2.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="A1.T3.2.2.2.2.m1.1b"><apply id="A1.T3.2.2.2.2.m1.1.1.cmml" xref="A1.T3.2.2.2.2.m1.1.1"><ci id="A1.T3.2.2.2.2.m1.1.1.1.cmml" xref="A1.T3.2.2.2.2.m1.1.1.1">↑</ci><apply id="A1.T3.2.2.2.2.m1.1.1.2.cmml" xref="A1.T3.2.2.2.2.m1.1.1.2"><csymbol cd="ambiguous" id="A1.T3.2.2.2.2.m1.1.1.2.1.cmml" xref="A1.T3.2.2.2.2.m1.1.1.2">subscript</csymbol><ci id="A1.T3.2.2.2.2.m1.1.1.2.2.cmml" xref="A1.T3.2.2.2.2.m1.1.1.2.2">𝑅</ci><ci id="A1.T3.2.2.2.2.m1.1.1.2.3.cmml" xref="A1.T3.2.2.2.2.m1.1.1.2.3">𝑐</ci></apply><csymbol cd="latexml" id="A1.T3.2.2.2.2.m1.1.1.3.cmml" xref="A1.T3.2.2.2.2.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.2.2.2.2.m1.1c">R_{c}\uparrow</annotation><annotation encoding="application/x-llamapun" id="A1.T3.2.2.2.2.m1.1d">italic_R start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ↑</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.3.3.3.3"><math alttext="R_{u}" class="ltx_Math" display="inline" id="A1.T3.3.3.3.3.m1.1"><semantics id="A1.T3.3.3.3.3.m1.1a"><msub id="A1.T3.3.3.3.3.m1.1.1" xref="A1.T3.3.3.3.3.m1.1.1.cmml"><mi id="A1.T3.3.3.3.3.m1.1.1.2" xref="A1.T3.3.3.3.3.m1.1.1.2.cmml">R</mi><mi id="A1.T3.3.3.3.3.m1.1.1.3" xref="A1.T3.3.3.3.3.m1.1.1.3.cmml">u</mi></msub><annotation-xml encoding="MathML-Content" id="A1.T3.3.3.3.3.m1.1b"><apply id="A1.T3.3.3.3.3.m1.1.1.cmml" xref="A1.T3.3.3.3.3.m1.1.1"><csymbol cd="ambiguous" id="A1.T3.3.3.3.3.m1.1.1.1.cmml" xref="A1.T3.3.3.3.3.m1.1.1">subscript</csymbol><ci id="A1.T3.3.3.3.3.m1.1.1.2.cmml" xref="A1.T3.3.3.3.3.m1.1.1.2">𝑅</ci><ci id="A1.T3.3.3.3.3.m1.1.1.3.cmml" xref="A1.T3.3.3.3.3.m1.1.1.3">𝑢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.3.3.3.3.m1.1c">R_{u}</annotation><annotation encoding="application/x-llamapun" id="A1.T3.3.3.3.3.m1.1d">italic_R start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.4.4.4.4"><math alttext="R_{m}\downarrow" class="ltx_Math" display="inline" id="A1.T3.4.4.4.4.m1.1"><semantics id="A1.T3.4.4.4.4.m1.1a"><mrow id="A1.T3.4.4.4.4.m1.1.1" xref="A1.T3.4.4.4.4.m1.1.1.cmml"><msub id="A1.T3.4.4.4.4.m1.1.1.2" xref="A1.T3.4.4.4.4.m1.1.1.2.cmml"><mi id="A1.T3.4.4.4.4.m1.1.1.2.2" xref="A1.T3.4.4.4.4.m1.1.1.2.2.cmml">R</mi><mi id="A1.T3.4.4.4.4.m1.1.1.2.3" xref="A1.T3.4.4.4.4.m1.1.1.2.3.cmml">m</mi></msub><mo id="A1.T3.4.4.4.4.m1.1.1.1" stretchy="false" xref="A1.T3.4.4.4.4.m1.1.1.1.cmml">↓</mo><mi id="A1.T3.4.4.4.4.m1.1.1.3" xref="A1.T3.4.4.4.4.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="A1.T3.4.4.4.4.m1.1b"><apply id="A1.T3.4.4.4.4.m1.1.1.cmml" xref="A1.T3.4.4.4.4.m1.1.1"><ci id="A1.T3.4.4.4.4.m1.1.1.1.cmml" xref="A1.T3.4.4.4.4.m1.1.1.1">↓</ci><apply id="A1.T3.4.4.4.4.m1.1.1.2.cmml" xref="A1.T3.4.4.4.4.m1.1.1.2"><csymbol cd="ambiguous" id="A1.T3.4.4.4.4.m1.1.1.2.1.cmml" xref="A1.T3.4.4.4.4.m1.1.1.2">subscript</csymbol><ci id="A1.T3.4.4.4.4.m1.1.1.2.2.cmml" xref="A1.T3.4.4.4.4.m1.1.1.2.2">𝑅</ci><ci id="A1.T3.4.4.4.4.m1.1.1.2.3.cmml" xref="A1.T3.4.4.4.4.m1.1.1.2.3">𝑚</ci></apply><csymbol cd="latexml" id="A1.T3.4.4.4.4.m1.1.1.3.cmml" xref="A1.T3.4.4.4.4.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.4.4.4.4.m1.1c">R_{m}\downarrow</annotation><annotation encoding="application/x-llamapun" id="A1.T3.4.4.4.4.m1.1d">italic_R start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT ↓</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.5.5.5.5"><math alttext="R_{c}\uparrow" class="ltx_Math" display="inline" id="A1.T3.5.5.5.5.m1.1"><semantics id="A1.T3.5.5.5.5.m1.1a"><mrow id="A1.T3.5.5.5.5.m1.1.1" xref="A1.T3.5.5.5.5.m1.1.1.cmml"><msub id="A1.T3.5.5.5.5.m1.1.1.2" xref="A1.T3.5.5.5.5.m1.1.1.2.cmml"><mi id="A1.T3.5.5.5.5.m1.1.1.2.2" xref="A1.T3.5.5.5.5.m1.1.1.2.2.cmml">R</mi><mi id="A1.T3.5.5.5.5.m1.1.1.2.3" xref="A1.T3.5.5.5.5.m1.1.1.2.3.cmml">c</mi></msub><mo id="A1.T3.5.5.5.5.m1.1.1.1" stretchy="false" xref="A1.T3.5.5.5.5.m1.1.1.1.cmml">↑</mo><mi id="A1.T3.5.5.5.5.m1.1.1.3" xref="A1.T3.5.5.5.5.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="A1.T3.5.5.5.5.m1.1b"><apply id="A1.T3.5.5.5.5.m1.1.1.cmml" xref="A1.T3.5.5.5.5.m1.1.1"><ci id="A1.T3.5.5.5.5.m1.1.1.1.cmml" xref="A1.T3.5.5.5.5.m1.1.1.1">↑</ci><apply id="A1.T3.5.5.5.5.m1.1.1.2.cmml" xref="A1.T3.5.5.5.5.m1.1.1.2"><csymbol cd="ambiguous" id="A1.T3.5.5.5.5.m1.1.1.2.1.cmml" xref="A1.T3.5.5.5.5.m1.1.1.2">subscript</csymbol><ci id="A1.T3.5.5.5.5.m1.1.1.2.2.cmml" xref="A1.T3.5.5.5.5.m1.1.1.2.2">𝑅</ci><ci id="A1.T3.5.5.5.5.m1.1.1.2.3.cmml" xref="A1.T3.5.5.5.5.m1.1.1.2.3">𝑐</ci></apply><csymbol cd="latexml" id="A1.T3.5.5.5.5.m1.1.1.3.cmml" xref="A1.T3.5.5.5.5.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.5.5.5.5.m1.1c">R_{c}\uparrow</annotation><annotation encoding="application/x-llamapun" id="A1.T3.5.5.5.5.m1.1d">italic_R start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ↑</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.6.6.6.6"><math alttext="R_{u}" class="ltx_Math" display="inline" id="A1.T3.6.6.6.6.m1.1"><semantics id="A1.T3.6.6.6.6.m1.1a"><msub id="A1.T3.6.6.6.6.m1.1.1" xref="A1.T3.6.6.6.6.m1.1.1.cmml"><mi id="A1.T3.6.6.6.6.m1.1.1.2" xref="A1.T3.6.6.6.6.m1.1.1.2.cmml">R</mi><mi id="A1.T3.6.6.6.6.m1.1.1.3" xref="A1.T3.6.6.6.6.m1.1.1.3.cmml">u</mi></msub><annotation-xml encoding="MathML-Content" id="A1.T3.6.6.6.6.m1.1b"><apply id="A1.T3.6.6.6.6.m1.1.1.cmml" xref="A1.T3.6.6.6.6.m1.1.1"><csymbol cd="ambiguous" id="A1.T3.6.6.6.6.m1.1.1.1.cmml" xref="A1.T3.6.6.6.6.m1.1.1">subscript</csymbol><ci id="A1.T3.6.6.6.6.m1.1.1.2.cmml" xref="A1.T3.6.6.6.6.m1.1.1.2">𝑅</ci><ci id="A1.T3.6.6.6.6.m1.1.1.3.cmml" xref="A1.T3.6.6.6.6.m1.1.1.3">𝑢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.6.6.6.6.m1.1c">R_{u}</annotation><annotation encoding="application/x-llamapun" id="A1.T3.6.6.6.6.m1.1d">italic_R start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.7.7.7.7"><math alttext="R_{m}\downarrow" class="ltx_Math" display="inline" id="A1.T3.7.7.7.7.m1.1"><semantics id="A1.T3.7.7.7.7.m1.1a"><mrow id="A1.T3.7.7.7.7.m1.1.1" xref="A1.T3.7.7.7.7.m1.1.1.cmml"><msub id="A1.T3.7.7.7.7.m1.1.1.2" xref="A1.T3.7.7.7.7.m1.1.1.2.cmml"><mi id="A1.T3.7.7.7.7.m1.1.1.2.2" xref="A1.T3.7.7.7.7.m1.1.1.2.2.cmml">R</mi><mi id="A1.T3.7.7.7.7.m1.1.1.2.3" xref="A1.T3.7.7.7.7.m1.1.1.2.3.cmml">m</mi></msub><mo id="A1.T3.7.7.7.7.m1.1.1.1" stretchy="false" xref="A1.T3.7.7.7.7.m1.1.1.1.cmml">↓</mo><mi id="A1.T3.7.7.7.7.m1.1.1.3" xref="A1.T3.7.7.7.7.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="A1.T3.7.7.7.7.m1.1b"><apply id="A1.T3.7.7.7.7.m1.1.1.cmml" xref="A1.T3.7.7.7.7.m1.1.1"><ci id="A1.T3.7.7.7.7.m1.1.1.1.cmml" xref="A1.T3.7.7.7.7.m1.1.1.1">↓</ci><apply id="A1.T3.7.7.7.7.m1.1.1.2.cmml" xref="A1.T3.7.7.7.7.m1.1.1.2"><csymbol cd="ambiguous" id="A1.T3.7.7.7.7.m1.1.1.2.1.cmml" xref="A1.T3.7.7.7.7.m1.1.1.2">subscript</csymbol><ci id="A1.T3.7.7.7.7.m1.1.1.2.2.cmml" xref="A1.T3.7.7.7.7.m1.1.1.2.2">𝑅</ci><ci id="A1.T3.7.7.7.7.m1.1.1.2.3.cmml" xref="A1.T3.7.7.7.7.m1.1.1.2.3">𝑚</ci></apply><csymbol cd="latexml" id="A1.T3.7.7.7.7.m1.1.1.3.cmml" xref="A1.T3.7.7.7.7.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.7.7.7.7.m1.1c">R_{m}\downarrow</annotation><annotation encoding="application/x-llamapun" id="A1.T3.7.7.7.7.m1.1d">italic_R start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT ↓</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.8.8.8.8"><math alttext="R_{c}\uparrow" class="ltx_Math" display="inline" id="A1.T3.8.8.8.8.m1.1"><semantics id="A1.T3.8.8.8.8.m1.1a"><mrow id="A1.T3.8.8.8.8.m1.1.1" xref="A1.T3.8.8.8.8.m1.1.1.cmml"><msub id="A1.T3.8.8.8.8.m1.1.1.2" xref="A1.T3.8.8.8.8.m1.1.1.2.cmml"><mi id="A1.T3.8.8.8.8.m1.1.1.2.2" xref="A1.T3.8.8.8.8.m1.1.1.2.2.cmml">R</mi><mi id="A1.T3.8.8.8.8.m1.1.1.2.3" xref="A1.T3.8.8.8.8.m1.1.1.2.3.cmml">c</mi></msub><mo id="A1.T3.8.8.8.8.m1.1.1.1" stretchy="false" xref="A1.T3.8.8.8.8.m1.1.1.1.cmml">↑</mo><mi id="A1.T3.8.8.8.8.m1.1.1.3" xref="A1.T3.8.8.8.8.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="A1.T3.8.8.8.8.m1.1b"><apply id="A1.T3.8.8.8.8.m1.1.1.cmml" xref="A1.T3.8.8.8.8.m1.1.1"><ci id="A1.T3.8.8.8.8.m1.1.1.1.cmml" xref="A1.T3.8.8.8.8.m1.1.1.1">↑</ci><apply id="A1.T3.8.8.8.8.m1.1.1.2.cmml" xref="A1.T3.8.8.8.8.m1.1.1.2"><csymbol cd="ambiguous" id="A1.T3.8.8.8.8.m1.1.1.2.1.cmml" xref="A1.T3.8.8.8.8.m1.1.1.2">subscript</csymbol><ci id="A1.T3.8.8.8.8.m1.1.1.2.2.cmml" xref="A1.T3.8.8.8.8.m1.1.1.2.2">𝑅</ci><ci id="A1.T3.8.8.8.8.m1.1.1.2.3.cmml" xref="A1.T3.8.8.8.8.m1.1.1.2.3">𝑐</ci></apply><csymbol cd="latexml" id="A1.T3.8.8.8.8.m1.1.1.3.cmml" xref="A1.T3.8.8.8.8.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.8.8.8.8.m1.1c">R_{c}\uparrow</annotation><annotation encoding="application/x-llamapun" id="A1.T3.8.8.8.8.m1.1d">italic_R start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ↑</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.9.9.9.9"><math alttext="R_{u}" class="ltx_Math" display="inline" id="A1.T3.9.9.9.9.m1.1"><semantics id="A1.T3.9.9.9.9.m1.1a"><msub id="A1.T3.9.9.9.9.m1.1.1" xref="A1.T3.9.9.9.9.m1.1.1.cmml"><mi id="A1.T3.9.9.9.9.m1.1.1.2" xref="A1.T3.9.9.9.9.m1.1.1.2.cmml">R</mi><mi id="A1.T3.9.9.9.9.m1.1.1.3" xref="A1.T3.9.9.9.9.m1.1.1.3.cmml">u</mi></msub><annotation-xml encoding="MathML-Content" id="A1.T3.9.9.9.9.m1.1b"><apply id="A1.T3.9.9.9.9.m1.1.1.cmml" xref="A1.T3.9.9.9.9.m1.1.1"><csymbol cd="ambiguous" id="A1.T3.9.9.9.9.m1.1.1.1.cmml" xref="A1.T3.9.9.9.9.m1.1.1">subscript</csymbol><ci id="A1.T3.9.9.9.9.m1.1.1.2.cmml" xref="A1.T3.9.9.9.9.m1.1.1.2">𝑅</ci><ci id="A1.T3.9.9.9.9.m1.1.1.3.cmml" xref="A1.T3.9.9.9.9.m1.1.1.3">𝑢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.9.9.9.9.m1.1c">R_{u}</annotation><annotation encoding="application/x-llamapun" id="A1.T3.9.9.9.9.m1.1d">italic_R start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.10.10.10.10"><math alttext="R_{m}\downarrow" class="ltx_Math" display="inline" id="A1.T3.10.10.10.10.m1.1"><semantics id="A1.T3.10.10.10.10.m1.1a"><mrow id="A1.T3.10.10.10.10.m1.1.1" xref="A1.T3.10.10.10.10.m1.1.1.cmml"><msub id="A1.T3.10.10.10.10.m1.1.1.2" xref="A1.T3.10.10.10.10.m1.1.1.2.cmml"><mi id="A1.T3.10.10.10.10.m1.1.1.2.2" xref="A1.T3.10.10.10.10.m1.1.1.2.2.cmml">R</mi><mi id="A1.T3.10.10.10.10.m1.1.1.2.3" xref="A1.T3.10.10.10.10.m1.1.1.2.3.cmml">m</mi></msub><mo id="A1.T3.10.10.10.10.m1.1.1.1" stretchy="false" xref="A1.T3.10.10.10.10.m1.1.1.1.cmml">↓</mo><mi id="A1.T3.10.10.10.10.m1.1.1.3" xref="A1.T3.10.10.10.10.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="A1.T3.10.10.10.10.m1.1b"><apply id="A1.T3.10.10.10.10.m1.1.1.cmml" xref="A1.T3.10.10.10.10.m1.1.1"><ci id="A1.T3.10.10.10.10.m1.1.1.1.cmml" xref="A1.T3.10.10.10.10.m1.1.1.1">↓</ci><apply id="A1.T3.10.10.10.10.m1.1.1.2.cmml" xref="A1.T3.10.10.10.10.m1.1.1.2"><csymbol cd="ambiguous" id="A1.T3.10.10.10.10.m1.1.1.2.1.cmml" xref="A1.T3.10.10.10.10.m1.1.1.2">subscript</csymbol><ci id="A1.T3.10.10.10.10.m1.1.1.2.2.cmml" xref="A1.T3.10.10.10.10.m1.1.1.2.2">𝑅</ci><ci id="A1.T3.10.10.10.10.m1.1.1.2.3.cmml" xref="A1.T3.10.10.10.10.m1.1.1.2.3">𝑚</ci></apply><csymbol cd="latexml" id="A1.T3.10.10.10.10.m1.1.1.3.cmml" xref="A1.T3.10.10.10.10.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.10.10.10.10.m1.1c">R_{m}\downarrow</annotation><annotation encoding="application/x-llamapun" id="A1.T3.10.10.10.10.m1.1d">italic_R start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT ↓</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.11.11.11.11"><math alttext="R_{c}\uparrow" class="ltx_Math" display="inline" id="A1.T3.11.11.11.11.m1.1"><semantics id="A1.T3.11.11.11.11.m1.1a"><mrow id="A1.T3.11.11.11.11.m1.1.1" xref="A1.T3.11.11.11.11.m1.1.1.cmml"><msub id="A1.T3.11.11.11.11.m1.1.1.2" xref="A1.T3.11.11.11.11.m1.1.1.2.cmml"><mi id="A1.T3.11.11.11.11.m1.1.1.2.2" xref="A1.T3.11.11.11.11.m1.1.1.2.2.cmml">R</mi><mi id="A1.T3.11.11.11.11.m1.1.1.2.3" xref="A1.T3.11.11.11.11.m1.1.1.2.3.cmml">c</mi></msub><mo id="A1.T3.11.11.11.11.m1.1.1.1" stretchy="false" xref="A1.T3.11.11.11.11.m1.1.1.1.cmml">↑</mo><mi id="A1.T3.11.11.11.11.m1.1.1.3" xref="A1.T3.11.11.11.11.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="A1.T3.11.11.11.11.m1.1b"><apply id="A1.T3.11.11.11.11.m1.1.1.cmml" xref="A1.T3.11.11.11.11.m1.1.1"><ci id="A1.T3.11.11.11.11.m1.1.1.1.cmml" xref="A1.T3.11.11.11.11.m1.1.1.1">↑</ci><apply id="A1.T3.11.11.11.11.m1.1.1.2.cmml" xref="A1.T3.11.11.11.11.m1.1.1.2"><csymbol cd="ambiguous" id="A1.T3.11.11.11.11.m1.1.1.2.1.cmml" xref="A1.T3.11.11.11.11.m1.1.1.2">subscript</csymbol><ci id="A1.T3.11.11.11.11.m1.1.1.2.2.cmml" xref="A1.T3.11.11.11.11.m1.1.1.2.2">𝑅</ci><ci id="A1.T3.11.11.11.11.m1.1.1.2.3.cmml" xref="A1.T3.11.11.11.11.m1.1.1.2.3">𝑐</ci></apply><csymbol cd="latexml" id="A1.T3.11.11.11.11.m1.1.1.3.cmml" xref="A1.T3.11.11.11.11.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.11.11.11.11.m1.1c">R_{c}\uparrow</annotation><annotation encoding="application/x-llamapun" id="A1.T3.11.11.11.11.m1.1d">italic_R start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT ↑</annotation></semantics></math></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.12.12"><math alttext="R_{u}" class="ltx_Math" display="inline" id="A1.T3.12.12.12.12.m1.1"><semantics id="A1.T3.12.12.12.12.m1.1a"><msub id="A1.T3.12.12.12.12.m1.1.1" xref="A1.T3.12.12.12.12.m1.1.1.cmml"><mi id="A1.T3.12.12.12.12.m1.1.1.2" xref="A1.T3.12.12.12.12.m1.1.1.2.cmml">R</mi><mi id="A1.T3.12.12.12.12.m1.1.1.3" xref="A1.T3.12.12.12.12.m1.1.1.3.cmml">u</mi></msub><annotation-xml encoding="MathML-Content" id="A1.T3.12.12.12.12.m1.1b"><apply id="A1.T3.12.12.12.12.m1.1.1.cmml" xref="A1.T3.12.12.12.12.m1.1.1"><csymbol cd="ambiguous" id="A1.T3.12.12.12.12.m1.1.1.1.cmml" xref="A1.T3.12.12.12.12.m1.1.1">subscript</csymbol><ci id="A1.T3.12.12.12.12.m1.1.1.2.cmml" xref="A1.T3.12.12.12.12.m1.1.1.2">𝑅</ci><ci id="A1.T3.12.12.12.12.m1.1.1.3.cmml" xref="A1.T3.12.12.12.12.m1.1.1.3">𝑢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.12.12.12.12.m1.1c">R_{u}</annotation><annotation encoding="application/x-llamapun" id="A1.T3.12.12.12.12.m1.1d">italic_R start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT</annotation></semantics></math></td>
</tr>
<tr class="ltx_tr" id="A1.T3.12.12.14.2">
<th class="ltx_td ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T3.12.12.14.2.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="14" id="A1.T3.12.12.14.2.2" style="background-color:#E6E6E6;"><span class="ltx_text" id="A1.T3.12.12.14.2.2.1" style="background-color:#E6E6E6;">MA first</span></th>
</tr>
<tr class="ltx_tr" id="A1.T3.12.12.15.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="A1.T3.12.12.15.3.1" rowspan="4"><span class="ltx_text" id="A1.T3.12.12.15.3.1.1">NQ</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T3.12.12.15.3.2">Direct</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T3.12.12.15.3.3">1</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.15.3.4">7.26</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.15.3.5">92.75</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.12.12.15.3.6">0.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.15.3.7">3.11</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.15.3.8">96.89</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.12.12.15.3.9">0.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.15.3.10">18.54</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.15.3.11">76.38</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.12.12.15.3.12">5.08</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.15.3.13">48.51</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.15.3.14">49.48</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.15.3.15">2.01</td>
</tr>
<tr class="ltx_tr" id="A1.T3.12.12.16.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T3.12.12.16.4.1">Direct + Paraphrase</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T3.12.12.16.4.2">3</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.16.4.3">3.26</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.16.4.4">96.74</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.12.12.16.4.5">0.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.16.4.6">1.11</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.16.4.7">98.71</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.12.12.16.4.8">0.18</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.16.4.9">8.99</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.16.4.10">87.59</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.12.12.16.4.11">3.43</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.16.4.12">11.34</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.16.4.13">87.21</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.16.4.14">1.46</td>
</tr>
<tr class="ltx_tr" id="A1.T3.12.12.17.5">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="14" id="A1.T3.12.12.17.5.1" style="background-color:#E6E6E6;"><span class="ltx_text" id="A1.T3.12.12.17.5.1.1" style="background-color:#E6E6E6;">CMA first</span></th>
</tr>
<tr class="ltx_tr" id="A1.T3.12.12.18.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T3.12.12.18.6.1">Direct</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T3.12.12.18.6.2">1</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.18.6.3">22.26</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.18.6.4">77.73</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.12.12.18.6.5">0.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.18.6.6">19.13</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.18.6.7">80.38</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.12.12.18.6.8">0.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.18.6.9">34.48</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.18.6.10">61.82</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.12.12.18.6.11">3.71</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.18.6.12">49.19</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.18.6.13">47.99</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.18.6.14">2.82</td>
</tr>
<tr class="ltx_tr" id="A1.T3.12.12.19.7">
<th class="ltx_td ltx_th ltx_th_row ltx_border_r" id="A1.T3.12.12.19.7.1"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T3.12.12.19.7.2">Direct + Parapharse</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T3.12.12.19.7.3">3</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.19.7.4">4.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.19.7.5">95.11</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.12.12.19.7.6">0.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.19.7.7">8.72</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.19.7.8">90.39</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.12.12.19.7.9">0.89</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.19.7.10">18.63</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.19.7.11">78.96</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.12.12.19.7.12">2.41</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.19.7.13">17.76</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.19.7.14">80.02</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.19.7.15">2.22</td>
</tr>
<tr class="ltx_tr" id="A1.T3.12.12.20.8">
<th class="ltx_td ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T3.12.12.20.8.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="14" id="A1.T3.12.12.20.8.2" style="background-color:#E6E6E6;"><span class="ltx_text" id="A1.T3.12.12.20.8.2.1" style="background-color:#E6E6E6;">MA first</span></th>
</tr>
<tr class="ltx_tr" id="A1.T3.12.12.21.9">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="A1.T3.12.12.21.9.1" rowspan="4"><span class="ltx_text" id="A1.T3.12.12.21.9.1.1">popQA</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T3.12.12.21.9.2">Direct</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T3.12.12.21.9.3">1</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.21.9.4">0.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.21.9.5">99.3</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.12.12.21.9.6">0.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.21.9.7">1.31</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.21.9.8">98.49</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.12.12.21.9.9">0.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.21.9.10">3.51</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.21.9.11">94.58</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.12.12.21.9.12">1.91</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.21.9.13">12.99</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.21.9.14">84.79</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.21.9.15">2.22</td>
</tr>
<tr class="ltx_tr" id="A1.T3.12.12.22.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T3.12.12.22.10.1">Direct + Paraphrase</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T3.12.12.22.10.2">3</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.22.10.3">0.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.22.10.4">99.7</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.12.12.22.10.5">0.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.22.10.6">0.51</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.22.10.7">99.29</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.12.12.22.10.8">0.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.22.10.9">1.32</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.22.10.10">98.38</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.12.12.22.10.11">0.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.22.10.12">1.32</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.22.10.13">98.48</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.22.10.14">0.2</td>
</tr>
<tr class="ltx_tr" id="A1.T3.12.12.23.11">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="14" id="A1.T3.12.12.23.11.1" style="background-color:#E6E6E6;"><span class="ltx_text" id="A1.T3.12.12.23.11.1.1" style="background-color:#E6E6E6;">CMA first</span></th>
</tr>
<tr class="ltx_tr" id="A1.T3.12.12.24.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T3.12.12.24.12.1">Direct</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T3.12.12.24.12.2">1</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.24.12.3">59.37</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.24.12.4">40.41</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.12.12.24.12.5">0.22</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.24.12.6">5.75</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.24.12.7">93.27</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.12.12.24.12.8">0.98</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.24.12.9">6.22</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.24.12.10">91.96</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A1.T3.12.12.24.12.11">1.82</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.24.12.12">21.44</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.24.12.13">75.24</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.12.12.24.12.14">3.32</td>
</tr>
<tr class="ltx_tr" id="A1.T3.12.12.25.13">
<th class="ltx_td ltx_th ltx_th_row ltx_border_b ltx_border_r" id="A1.T3.12.12.25.13.1"></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t" id="A1.T3.12.12.25.13.2">Direct + Paraphrase</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t" id="A1.T3.12.12.25.13.3">3</th>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="A1.T3.12.12.25.13.4">16.78</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="A1.T3.12.12.25.13.5">83.22</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="A1.T3.12.12.25.13.6">0.0</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="A1.T3.12.12.25.13.7">1.74</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="A1.T3.12.12.25.13.8">98.05</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="A1.T3.12.12.25.13.9">0.22</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="A1.T3.12.12.25.13.10">1.82</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="A1.T3.12.12.25.13.11">97.75</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="A1.T3.12.12.25.13.12">0.43</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="A1.T3.12.12.25.13.13">2.79</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="A1.T3.12.12.25.13.14">96.78</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="A1.T3.12.12.25.13.15">0.43</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Results of LLM Receptiveness to Different Evidence Styles Across NQ and popQA Datasets.
The table presents the MA ratio (<math alttext="R_{m}" class="ltx_Math" display="inline" id="A1.T3.16.m1.1"><semantics id="A1.T3.16.m1.1b"><msub id="A1.T3.16.m1.1.1" xref="A1.T3.16.m1.1.1.cmml"><mi id="A1.T3.16.m1.1.1.2" xref="A1.T3.16.m1.1.1.2.cmml">R</mi><mi id="A1.T3.16.m1.1.1.3" xref="A1.T3.16.m1.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="A1.T3.16.m1.1c"><apply id="A1.T3.16.m1.1.1.cmml" xref="A1.T3.16.m1.1.1"><csymbol cd="ambiguous" id="A1.T3.16.m1.1.1.1.cmml" xref="A1.T3.16.m1.1.1">subscript</csymbol><ci id="A1.T3.16.m1.1.1.2.cmml" xref="A1.T3.16.m1.1.1.2">𝑅</ci><ci id="A1.T3.16.m1.1.1.3.cmml" xref="A1.T3.16.m1.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.16.m1.1d">R_{m}</annotation><annotation encoding="application/x-llamapun" id="A1.T3.16.m1.1e">italic_R start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT</annotation></semantics></math>), CMA ratio (<math alttext="R_{c}" class="ltx_Math" display="inline" id="A1.T3.17.m2.1"><semantics id="A1.T3.17.m2.1b"><msub id="A1.T3.17.m2.1.1" xref="A1.T3.17.m2.1.1.cmml"><mi id="A1.T3.17.m2.1.1.2" xref="A1.T3.17.m2.1.1.2.cmml">R</mi><mi id="A1.T3.17.m2.1.1.3" xref="A1.T3.17.m2.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="A1.T3.17.m2.1c"><apply id="A1.T3.17.m2.1.1.cmml" xref="A1.T3.17.m2.1.1"><csymbol cd="ambiguous" id="A1.T3.17.m2.1.1.1.cmml" xref="A1.T3.17.m2.1.1">subscript</csymbol><ci id="A1.T3.17.m2.1.1.2.cmml" xref="A1.T3.17.m2.1.1.2">𝑅</ci><ci id="A1.T3.17.m2.1.1.3.cmml" xref="A1.T3.17.m2.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.17.m2.1d">R_{c}</annotation><annotation encoding="application/x-llamapun" id="A1.T3.17.m2.1e">italic_R start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT</annotation></semantics></math>), and UCT ratio (<math alttext="R_{u}" class="ltx_Math" display="inline" id="A1.T3.18.m3.1"><semantics id="A1.T3.18.m3.1b"><msub id="A1.T3.18.m3.1.1" xref="A1.T3.18.m3.1.1.cmml"><mi id="A1.T3.18.m3.1.1.2" xref="A1.T3.18.m3.1.1.2.cmml">R</mi><mi id="A1.T3.18.m3.1.1.3" xref="A1.T3.18.m3.1.1.3.cmml">u</mi></msub><annotation-xml encoding="MathML-Content" id="A1.T3.18.m3.1c"><apply id="A1.T3.18.m3.1.1.cmml" xref="A1.T3.18.m3.1.1"><csymbol cd="ambiguous" id="A1.T3.18.m3.1.1.1.cmml" xref="A1.T3.18.m3.1.1">subscript</csymbol><ci id="A1.T3.18.m3.1.1.2.cmml" xref="A1.T3.18.m3.1.1.2">𝑅</ci><ci id="A1.T3.18.m3.1.1.3.cmml" xref="A1.T3.18.m3.1.1.3">𝑢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.18.m3.1d">R_{u}</annotation><annotation encoding="application/x-llamapun" id="A1.T3.18.m3.1e">italic_R start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT</annotation></semantics></math>) for Direct Evidence and Direct + Paraphrase Evidence with CMA first and MA first scenarios. All the ratios are in %.</figcaption>
</figure>
<div class="ltx_para" id="A1.SS1.p1">
<p class="ltx_p" id="A1.SS1.p1.1">To test the effect of the order of options on <math alttext="R_{m}" class="ltx_Math" display="inline" id="A1.SS1.p1.1.m1.1"><semantics id="A1.SS1.p1.1.m1.1a"><msub id="A1.SS1.p1.1.m1.1.1" xref="A1.SS1.p1.1.m1.1.1.cmml"><mi id="A1.SS1.p1.1.m1.1.1.2" xref="A1.SS1.p1.1.m1.1.1.2.cmml">R</mi><mi id="A1.SS1.p1.1.m1.1.1.3" xref="A1.SS1.p1.1.m1.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.1.m1.1b"><apply id="A1.SS1.p1.1.m1.1.1.cmml" xref="A1.SS1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A1.SS1.p1.1.m1.1.1.1.cmml" xref="A1.SS1.p1.1.m1.1.1">subscript</csymbol><ci id="A1.SS1.p1.1.m1.1.1.2.cmml" xref="A1.SS1.p1.1.m1.1.1.2">𝑅</ci><ci id="A1.SS1.p1.1.m1.1.1.3.cmml" xref="A1.SS1.p1.1.m1.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.1.m1.1c">R_{m}</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p1.1.m1.1d">italic_R start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT</annotation></semantics></math>, we conduct an experiment with one sentence direct evidence by changing the order of options (MA option and CMA option). We define the scenario where the CMA option is presented first in the prompt as “CMA first”, and the scenario where the MA option is presented first as “MA first”<span class="ltx_note ltx_role_footnote" id="footnote8"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span>All previous evaluations are under “MA first” conditions.</span></span></span>. Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#A1.F4" title="Figure 4 ‣ A.1 Order of Options ‣ Appendix A Additional Study ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_tag">4</span></a> shows the results.</p>
</div>
<div class="ltx_para" id="A1.SS1.p2">
<p class="ltx_p" id="A1.SS1.p2.1">Across all four models (LLaMA2.7B, LLaMA2.70B, ChatGPT, and GPT-4), we observe a consistent trend: MA ratio (<math alttext="R_{m}" class="ltx_Math" display="inline" id="A1.SS1.p2.1.m1.1"><semantics id="A1.SS1.p2.1.m1.1a"><msub id="A1.SS1.p2.1.m1.1.1" xref="A1.SS1.p2.1.m1.1.1.cmml"><mi id="A1.SS1.p2.1.m1.1.1.2" xref="A1.SS1.p2.1.m1.1.1.2.cmml">R</mi><mi id="A1.SS1.p2.1.m1.1.1.3" xref="A1.SS1.p2.1.m1.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="A1.SS1.p2.1.m1.1b"><apply id="A1.SS1.p2.1.m1.1.1.cmml" xref="A1.SS1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="A1.SS1.p2.1.m1.1.1.1.cmml" xref="A1.SS1.p2.1.m1.1.1">subscript</csymbol><ci id="A1.SS1.p2.1.m1.1.1.2.cmml" xref="A1.SS1.p2.1.m1.1.1.2">𝑅</ci><ci id="A1.SS1.p2.1.m1.1.1.3.cmml" xref="A1.SS1.p2.1.m1.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p2.1.m1.1c">R_{m}</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p2.1.m1.1d">italic_R start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT</annotation></semantics></math>) under “CMA first” is significantly higher than that under “MA first”.
Evaluations under “CMA first” demonstrate that LLMs are less context-faithful.</p>
</div>
<div class="ltx_para" id="A1.SS1.p3">
<p class="ltx_p" id="A1.SS1.p3.4">To further demonstrate the effect of the order of options on <math alttext="R_{m}" class="ltx_Math" display="inline" id="A1.SS1.p3.1.m1.1"><semantics id="A1.SS1.p3.1.m1.1a"><msub id="A1.SS1.p3.1.m1.1.1" xref="A1.SS1.p3.1.m1.1.1.cmml"><mi id="A1.SS1.p3.1.m1.1.1.2" xref="A1.SS1.p3.1.m1.1.1.2.cmml">R</mi><mi id="A1.SS1.p3.1.m1.1.1.3" xref="A1.SS1.p3.1.m1.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="A1.SS1.p3.1.m1.1b"><apply id="A1.SS1.p3.1.m1.1.1.cmml" xref="A1.SS1.p3.1.m1.1.1"><csymbol cd="ambiguous" id="A1.SS1.p3.1.m1.1.1.1.cmml" xref="A1.SS1.p3.1.m1.1.1">subscript</csymbol><ci id="A1.SS1.p3.1.m1.1.1.2.cmml" xref="A1.SS1.p3.1.m1.1.1.2">𝑅</ci><ci id="A1.SS1.p3.1.m1.1.1.3.cmml" xref="A1.SS1.p3.1.m1.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p3.1.m1.1c">R_{m}</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p3.1.m1.1d">italic_R start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT</annotation></semantics></math>, we compare the performance of experiments with “CMA first” and “MA first” under two evidence styles: direct evidence with one sentence and direct + paraphrase with three sentences. The results are presented in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#A1.T3" title="Table 3 ‣ A.1 Order of Options ‣ Appendix A Additional Study ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_tag">3</span></a>. The results show that, for different evidence styles, <math alttext="R_{m}" class="ltx_Math" display="inline" id="A1.SS1.p3.2.m2.1"><semantics id="A1.SS1.p3.2.m2.1a"><msub id="A1.SS1.p3.2.m2.1.1" xref="A1.SS1.p3.2.m2.1.1.cmml"><mi id="A1.SS1.p3.2.m2.1.1.2" xref="A1.SS1.p3.2.m2.1.1.2.cmml">R</mi><mi id="A1.SS1.p3.2.m2.1.1.3" xref="A1.SS1.p3.2.m2.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="A1.SS1.p3.2.m2.1b"><apply id="A1.SS1.p3.2.m2.1.1.cmml" xref="A1.SS1.p3.2.m2.1.1"><csymbol cd="ambiguous" id="A1.SS1.p3.2.m2.1.1.1.cmml" xref="A1.SS1.p3.2.m2.1.1">subscript</csymbol><ci id="A1.SS1.p3.2.m2.1.1.2.cmml" xref="A1.SS1.p3.2.m2.1.1.2">𝑅</ci><ci id="A1.SS1.p3.2.m2.1.1.3.cmml" xref="A1.SS1.p3.2.m2.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p3.2.m2.1c">R_{m}</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p3.2.m2.1d">italic_R start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT</annotation></semantics></math> is consistently higher in the “CMA first” compared to the “MA first”. Comparing the results under the “CMA first”, the <math alttext="R_{m}" class="ltx_Math" display="inline" id="A1.SS1.p3.3.m3.1"><semantics id="A1.SS1.p3.3.m3.1a"><msub id="A1.SS1.p3.3.m3.1.1" xref="A1.SS1.p3.3.m3.1.1.cmml"><mi id="A1.SS1.p3.3.m3.1.1.2" xref="A1.SS1.p3.3.m3.1.1.2.cmml">R</mi><mi id="A1.SS1.p3.3.m3.1.1.3" xref="A1.SS1.p3.3.m3.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="A1.SS1.p3.3.m3.1b"><apply id="A1.SS1.p3.3.m3.1.1.cmml" xref="A1.SS1.p3.3.m3.1.1"><csymbol cd="ambiguous" id="A1.SS1.p3.3.m3.1.1.1.cmml" xref="A1.SS1.p3.3.m3.1.1">subscript</csymbol><ci id="A1.SS1.p3.3.m3.1.1.2.cmml" xref="A1.SS1.p3.3.m3.1.1.2">𝑅</ci><ci id="A1.SS1.p3.3.m3.1.1.3.cmml" xref="A1.SS1.p3.3.m3.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p3.3.m3.1c">R_{m}</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p3.3.m3.1d">italic_R start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT</annotation></semantics></math> of direct + paraphrase with three sentences is significantly lower than that with direct evidence with one sentence. This demonstrates that paraphrasing direct evidence is an effective method for decreasing <math alttext="R_{m}" class="ltx_Math" display="inline" id="A1.SS1.p3.4.m4.1"><semantics id="A1.SS1.p3.4.m4.1a"><msub id="A1.SS1.p3.4.m4.1.1" xref="A1.SS1.p3.4.m4.1.1.cmml"><mi id="A1.SS1.p3.4.m4.1.1.2" xref="A1.SS1.p3.4.m4.1.1.2.cmml">R</mi><mi id="A1.SS1.p3.4.m4.1.1.3" xref="A1.SS1.p3.4.m4.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="A1.SS1.p3.4.m4.1b"><apply id="A1.SS1.p3.4.m4.1.1.cmml" xref="A1.SS1.p3.4.m4.1.1"><csymbol cd="ambiguous" id="A1.SS1.p3.4.m4.1.1.1.cmml" xref="A1.SS1.p3.4.m4.1.1">subscript</csymbol><ci id="A1.SS1.p3.4.m4.1.1.2.cmml" xref="A1.SS1.p3.4.m4.1.1.2">𝑅</ci><ci id="A1.SS1.p3.4.m4.1.1.3.cmml" xref="A1.SS1.p3.4.m4.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p3.4.m4.1c">R_{m}</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p3.4.m4.1d">italic_R start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT</annotation></semantics></math>. Our conclusion remains unchanged.</p>
</div>
</section>
<section class="ltx_subsection" id="A1.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.2 </span>Case Study</h3>
<div class="ltx_para" id="A1.SS2.p1">
<p class="ltx_p" id="A1.SS2.p1.3"><span class="ltx_text ltx_font_bold" id="A1.SS2.p1.1.1">The higher <math alttext="R_{m}" class="ltx_Math" display="inline" id="A1.SS2.p1.1.1.m1.1"><semantics id="A1.SS2.p1.1.1.m1.1a"><msub id="A1.SS2.p1.1.1.m1.1.1" xref="A1.SS2.p1.1.1.m1.1.1.cmml"><mi id="A1.SS2.p1.1.1.m1.1.1.2" xref="A1.SS2.p1.1.1.m1.1.1.2.cmml">R</mi><mi id="A1.SS2.p1.1.1.m1.1.1.3" xref="A1.SS2.p1.1.1.m1.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="A1.SS2.p1.1.1.m1.1b"><apply id="A1.SS2.p1.1.1.m1.1.1.cmml" xref="A1.SS2.p1.1.1.m1.1.1"><csymbol cd="ambiguous" id="A1.SS2.p1.1.1.m1.1.1.1.cmml" xref="A1.SS2.p1.1.1.m1.1.1">subscript</csymbol><ci id="A1.SS2.p1.1.1.m1.1.1.2.cmml" xref="A1.SS2.p1.1.1.m1.1.1.2">𝑅</ci><ci id="A1.SS2.p1.1.1.m1.1.1.3.cmml" xref="A1.SS2.p1.1.1.m1.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p1.1.1.m1.1c">R_{m}</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.p1.1.1.m1.1d">italic_R start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT</annotation></semantics></math> of LLaMA2.7B may be attributed to its weakness of reasoning ability</span>.
From Table 2, we observe that on the NQ dataset, the <math alttext="R_{m}" class="ltx_Math" display="inline" id="A1.SS2.p1.2.m1.1"><semantics id="A1.SS2.p1.2.m1.1a"><msub id="A1.SS2.p1.2.m1.1.1" xref="A1.SS2.p1.2.m1.1.1.cmml"><mi id="A1.SS2.p1.2.m1.1.1.2" xref="A1.SS2.p1.2.m1.1.1.2.cmml">R</mi><mi id="A1.SS2.p1.2.m1.1.1.3" xref="A1.SS2.p1.2.m1.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="A1.SS2.p1.2.m1.1b"><apply id="A1.SS2.p1.2.m1.1.1.cmml" xref="A1.SS2.p1.2.m1.1.1"><csymbol cd="ambiguous" id="A1.SS2.p1.2.m1.1.1.1.cmml" xref="A1.SS2.p1.2.m1.1.1">subscript</csymbol><ci id="A1.SS2.p1.2.m1.1.1.2.cmml" xref="A1.SS2.p1.2.m1.1.1.2">𝑅</ci><ci id="A1.SS2.p1.2.m1.1.1.3.cmml" xref="A1.SS2.p1.2.m1.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p1.2.m1.1c">R_{m}</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.p1.2.m1.1d">italic_R start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT</annotation></semantics></math> of LLaMA2.7B is higher than that of LLaMA2.70B. This phenomenon is counter-intuitive, as a weaker memory strength in LLMs corresponds to a lower <math alttext="R_{m}" class="ltx_Math" display="inline" id="A1.SS2.p1.3.m2.1"><semantics id="A1.SS2.p1.3.m2.1a"><msub id="A1.SS2.p1.3.m2.1.1" xref="A1.SS2.p1.3.m2.1.1.cmml"><mi id="A1.SS2.p1.3.m2.1.1.2" xref="A1.SS2.p1.3.m2.1.1.2.cmml">R</mi><mi id="A1.SS2.p1.3.m2.1.1.3" xref="A1.SS2.p1.3.m2.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="A1.SS2.p1.3.m2.1b"><apply id="A1.SS2.p1.3.m2.1.1.cmml" xref="A1.SS2.p1.3.m2.1.1"><csymbol cd="ambiguous" id="A1.SS2.p1.3.m2.1.1.1.cmml" xref="A1.SS2.p1.3.m2.1.1">subscript</csymbol><ci id="A1.SS2.p1.3.m2.1.1.2.cmml" xref="A1.SS2.p1.3.m2.1.1.2">𝑅</ci><ci id="A1.SS2.p1.3.m2.1.1.3.cmml" xref="A1.SS2.p1.3.m2.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p1.3.m2.1c">R_{m}</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.p1.3.m2.1d">italic_R start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT</annotation></semantics></math> for the other three LLMs (LLaMA2.70B, ChatGPT, and GPT-4). To investigate the cause of this issue, we prompt LLaMA2.7B to provide a rationale alongside the answer. We discover that LLaMA2.7B seems to exhibit reasoning errors. Below is an example that shows this phenomenon.</p>
<blockquote class="ltx_quote" id="A1.SS2.p1.5">
<p class="ltx_p" id="A1.SS2.p1.5.1"><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="A1.SS2.p1.5.1.1">Information<span class="ltx_text ltx_font_medium" id="A1.SS2.p1.5.1.1.1">: Michigan State University holds the record for the highest number of Big Ten football championships, with a total of 36 titles. 
<br class="ltx_break"/></span>Question<span class="ltx_text ltx_font_medium" id="A1.SS2.p1.5.1.1.2">: who has the most big ten championships in football 
<br class="ltx_break"/></span>Options<span class="ltx_text ltx_font_medium" id="A1.SS2.p1.5.1.1.3">: 
<br class="ltx_break"/>A: Ohio State University has the most Big Ten championships in football with 36 titles. 
<br class="ltx_break"/>B: Michigan State University has the most Big Ten championships in football with 36 titles. 
<br class="ltx_break"/>C: Uncertain.  
<br class="ltx_break"/></span>Answer<span class="ltx_text ltx_font_medium" id="A1.SS2.p1.5.1.1.4">: 
<br class="ltx_break"/>A: Ohio State University has the most Big Ten championships in football with 36 titles.  
<br class="ltx_break"/>According to the information provided, Michigan State University holds the record for the highest number of Big Ten football championships, with a total of 36 titles. Therefore, option A is the correct answer.
</span></span></p>
</blockquote>
<p class="ltx_p" id="A1.SS2.p1.4">In this case, option A represents MA, and option B represents CMA. While the model select MA as the final answer, its rationale indicates that it successfully received and processed the information from CMA. However, for some unknown reason, it still provides the MA as the final answer. This reasoning process is highly confusing. We suspect that the higher <math alttext="R_{m}" class="ltx_Math" display="inline" id="A1.SS2.p1.4.m1.1"><semantics id="A1.SS2.p1.4.m1.1a"><msub id="A1.SS2.p1.4.m1.1.1" xref="A1.SS2.p1.4.m1.1.1.cmml"><mi id="A1.SS2.p1.4.m1.1.1.2" xref="A1.SS2.p1.4.m1.1.1.2.cmml">R</mi><mi id="A1.SS2.p1.4.m1.1.1.3" xref="A1.SS2.p1.4.m1.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="A1.SS2.p1.4.m1.1b"><apply id="A1.SS2.p1.4.m1.1.1.cmml" xref="A1.SS2.p1.4.m1.1.1"><csymbol cd="ambiguous" id="A1.SS2.p1.4.m1.1.1.1.cmml" xref="A1.SS2.p1.4.m1.1.1">subscript</csymbol><ci id="A1.SS2.p1.4.m1.1.1.2.cmml" xref="A1.SS2.p1.4.m1.1.1.2">𝑅</ci><ci id="A1.SS2.p1.4.m1.1.1.3.cmml" xref="A1.SS2.p1.4.m1.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p1.4.m1.1c">R_{m}</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.p1.4.m1.1d">italic_R start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT</annotation></semantics></math> of LLaMA2.7B can be attributed to its weakness in reasoning ability. This finding raises an interesting question about the relationship between reasoning ability and memory strength of LLMs. We leave this for future work.</p>
</div>
</section>
</section>
<section class="ltx_appendix" id="A2">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Methodology and Experiment Details</h2>
<section class="ltx_subsection" id="A2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.1 </span>CMA Generation for NQ dataset</h3>
<figure class="ltx_figure" id="A2.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="444" id="A2.F5.g1" src="extracted/5859889/fig/type_tree.png" width="509"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Two-layer Question Typing Tree</figcaption>
</figure>
<figure class="ltx_table" id="A2.T4">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A2.T4.1" style="width:86.7pt;height:290.1pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-18.5pt,61.9pt) scale(0.700788314212504,0.700788314212504) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A2.T4.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A2.T4.1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A2.T4.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="A2.T4.1.1.1.1.1.1">Question Type</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t" id="A2.T4.1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="A2.T4.1.1.1.1.2.1">Count</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A2.T4.1.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A2.T4.1.1.2.1.1">how_many</th>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="A2.T4.1.1.2.1.2">97</td>
</tr>
<tr class="ltx_tr" id="A2.T4.1.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="A2.T4.1.1.3.2.1">how_much</th>
<td class="ltx_td ltx_align_right ltx_border_r" id="A2.T4.1.1.3.2.2">1</td>
</tr>
<tr class="ltx_tr" id="A2.T4.1.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="A2.T4.1.1.4.3.1">how_long</th>
<td class="ltx_td ltx_align_right ltx_border_r" id="A2.T4.1.1.4.3.2">3</td>
</tr>
<tr class="ltx_tr" id="A2.T4.1.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="A2.T4.1.1.5.4.1">how_old</th>
<td class="ltx_td ltx_align_right ltx_border_r" id="A2.T4.1.1.5.4.2">3</td>
</tr>
<tr class="ltx_tr" id="A2.T4.1.1.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="A2.T4.1.1.6.5.1">how</th>
<td class="ltx_td ltx_align_right ltx_border_r" id="A2.T4.1.1.6.5.2">2</td>
</tr>
<tr class="ltx_tr" id="A2.T4.1.1.7.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="A2.T4.1.1.7.6.1">who_sings</th>
<td class="ltx_td ltx_align_right ltx_border_r" id="A2.T4.1.1.7.6.2">100</td>
</tr>
<tr class="ltx_tr" id="A2.T4.1.1.8.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="A2.T4.1.1.8.7.1">who_plays</th>
<td class="ltx_td ltx_align_right ltx_border_r" id="A2.T4.1.1.8.7.2">179</td>
</tr>
<tr class="ltx_tr" id="A2.T4.1.1.9.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="A2.T4.1.1.9.8.1">who_writes</th>
<td class="ltx_td ltx_align_right ltx_border_r" id="A2.T4.1.1.9.8.2">65</td>
</tr>
<tr class="ltx_tr" id="A2.T4.1.1.10.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="A2.T4.1.1.10.9.1">who_wins</th>
<td class="ltx_td ltx_align_right ltx_border_r" id="A2.T4.1.1.10.9.2">55</td>
</tr>
<tr class="ltx_tr" id="A2.T4.1.1.11.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="A2.T4.1.1.11.10.1">who</th>
<td class="ltx_td ltx_align_right ltx_border_r" id="A2.T4.1.1.11.10.2">479</td>
</tr>
<tr class="ltx_tr" id="A2.T4.1.1.12.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="A2.T4.1.1.12.11.1">where</th>
<td class="ltx_td ltx_align_right ltx_border_r" id="A2.T4.1.1.12.11.2">138</td>
</tr>
<tr class="ltx_tr" id="A2.T4.1.1.13.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="A2.T4.1.1.13.12.1">when</th>
<td class="ltx_td ltx_align_right ltx_border_r" id="A2.T4.1.1.13.12.2">276</td>
</tr>
<tr class="ltx_tr" id="A2.T4.1.1.14.13">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="A2.T4.1.1.14.13.1">what_year</th>
<td class="ltx_td ltx_align_right ltx_border_r" id="A2.T4.1.1.14.13.2">7</td>
</tr>
<tr class="ltx_tr" id="A2.T4.1.1.15.14">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="A2.T4.1.1.15.14.1">what_name</th>
<td class="ltx_td ltx_align_right ltx_border_r" id="A2.T4.1.1.15.14.2">4</td>
</tr>
<tr class="ltx_tr" id="A2.T4.1.1.16.15">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="A2.T4.1.1.16.15.1">what</th>
<td class="ltx_td ltx_align_right ltx_border_r" id="A2.T4.1.1.16.15.2">98</td>
</tr>
<tr class="ltx_tr" id="A2.T4.1.1.17.16">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="A2.T4.1.1.17.16.1">which_country</th>
<td class="ltx_td ltx_align_right ltx_border_r" id="A2.T4.1.1.17.16.2">6</td>
</tr>
<tr class="ltx_tr" id="A2.T4.1.1.18.17">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="A2.T4.1.1.18.17.1">which_city</th>
<td class="ltx_td ltx_align_right ltx_border_r" id="A2.T4.1.1.18.17.2">2</td>
</tr>
<tr class="ltx_tr" id="A2.T4.1.1.19.18">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="A2.T4.1.1.19.18.1">which_state</th>
<td class="ltx_td ltx_align_right ltx_border_r" id="A2.T4.1.1.19.18.2">2</td>
</tr>
<tr class="ltx_tr" id="A2.T4.1.1.20.19">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="A2.T4.1.1.20.19.1">which_year</th>
<td class="ltx_td ltx_align_right ltx_border_r" id="A2.T4.1.1.20.19.2">1</td>
</tr>
<tr class="ltx_tr" id="A2.T4.1.1.21.20">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="A2.T4.1.1.21.20.1">which</th>
<td class="ltx_td ltx_align_right ltx_border_r" id="A2.T4.1.1.21.20.2">22</td>
</tr>
<tr class="ltx_tr" id="A2.T4.1.1.22.21">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r" id="A2.T4.1.1.22.21.1">other</th>
<td class="ltx_td ltx_align_right ltx_border_r" id="A2.T4.1.1.22.21.2">127</td>
</tr>
<tr class="ltx_tr" id="A2.T4.1.1.23.22">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="A2.T4.1.1.23.22.1">total</th>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" id="A2.T4.1.1.23.22.2">1667</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>Distribution of Question Types and their Counts</figcaption>
</figure>
<figure class="ltx_table" id="A2.T5">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A2.T5.1" style="width:208.1pt;height:134.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-49.0pt,31.7pt) scale(0.679872638119665,0.679872638119665) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A2.T5.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A2.T5.1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="A2.T5.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="A2.T5.1.1.1.1.1.1">Question Type</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="A2.T5.1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="A2.T5.1.1.1.1.2.1">Key Term</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A2.T5.1.1.2.1">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A2.T5.1.1.2.1.1">when, what_year, which_year, how_long</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A2.T5.1.1.2.1.2">time</td>
</tr>
<tr class="ltx_tr" id="A2.T5.1.1.3.2">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A2.T5.1.1.3.2.1">where, which_city, which_state, which_country</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A2.T5.1.1.3.2.2">location</td>
</tr>
<tr class="ltx_tr" id="A2.T5.1.1.4.3">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A2.T5.1.1.4.3.1">who, what_name</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A2.T5.1.1.4.3.2">name of person</td>
</tr>
<tr class="ltx_tr" id="A2.T5.1.1.5.4">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A2.T5.1.1.5.4.1">how_many, how_much</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A2.T5.1.1.5.4.2">number</td>
</tr>
<tr class="ltx_tr" id="A2.T5.1.1.6.5">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A2.T5.1.1.6.5.1">who_sings</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A2.T5.1.1.6.5.2">singer’s name</td>
</tr>
<tr class="ltx_tr" id="A2.T5.1.1.7.6">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A2.T5.1.1.7.6.1">who_plays</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A2.T5.1.1.7.6.2">player’s name</td>
</tr>
<tr class="ltx_tr" id="A2.T5.1.1.8.7">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A2.T5.1.1.8.7.1">who_writes</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A2.T5.1.1.8.7.2">writer’s name</td>
</tr>
<tr class="ltx_tr" id="A2.T5.1.1.9.8">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A2.T5.1.1.9.8.1">who_wins</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A2.T5.1.1.9.8.2">winner’s name</td>
</tr>
<tr class="ltx_tr" id="A2.T5.1.1.10.9">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A2.T5.1.1.10.9.1">how_far</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A2.T5.1.1.10.9.2">distance</td>
</tr>
<tr class="ltx_tr" id="A2.T5.1.1.11.10">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="A2.T5.1.1.11.10.1">how_old</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_t" id="A2.T5.1.1.11.10.2">age</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>Question Types and Their Corresponding Key Terms</figcaption>
</figure>
<figure class="ltx_table" id="A2.T6">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A2.T6.1" style="width:216.8pt;height:71.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-54.7pt,18.1pt) scale(0.664833991997583,0.664833991997583) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A2.T6.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A2.T6.1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="A2.T6.1.1.1.1.1">Type</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" id="A2.T6.1.1.1.1.2">Count</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="A2.T6.1.1.1.1.3">Question Examples</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A2.T6.1.1.2.1">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A2.T6.1.1.2.1.1">how</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T6.1.1.2.1.2">2</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A2.T6.1.1.2.1.3">how are leaders of the two parties in congress chosen</td>
</tr>
<tr class="ltx_tr" id="A2.T6.1.1.3.2">
<td class="ltx_td ltx_align_left ltx_border_r" id="A2.T6.1.1.3.2.1">what</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A2.T6.1.1.3.2.2">98</td>
<td class="ltx_td ltx_align_left" id="A2.T6.1.1.3.2.3">what is the setting of the story sorry wrong number</td>
</tr>
<tr class="ltx_tr" id="A2.T6.1.1.4.3">
<td class="ltx_td ltx_align_left ltx_border_r" id="A2.T6.1.1.4.3.1">which</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A2.T6.1.1.4.3.2">22</td>
<td class="ltx_td ltx_align_left" id="A2.T6.1.1.4.3.3">which domain of life are humans members of</td>
</tr>
<tr class="ltx_tr" id="A2.T6.1.1.5.4">
<td class="ltx_td ltx_align_left ltx_border_r" id="A2.T6.1.1.5.4.1">other</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A2.T6.1.1.5.4.2">127</td>
<td class="ltx_td ltx_align_left" id="A2.T6.1.1.5.4.3">latest season on keeping up with the kardashians</td>
</tr>
<tr class="ltx_tr" id="A2.T6.1.1.6.5">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="A2.T6.1.1.6.5.1">total</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="A2.T6.1.1.6.5.2">1667</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_t" id="A2.T6.1.1.6.5.3">-</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6: </span>Summary of Excluded Question Types in Memory Answer and Counter Answer Generation.
The table lists question types that were excluded from processing due to either the difficulty in identifying a unified entity type (“how”, “what”, “which”) or poor question quality (“other”).</figcaption>
</figure>
<div class="ltx_para" id="A2.SS1.p1">
<p class="ltx_p" id="A2.SS1.p1.1">We generate CMA from MA with three steps: 1)identity question type, 2) determine entity type in MA to change, and 3) generate CMA with LLMs.</p>
</div>
<div class="ltx_para" id="A2.SS1.p2">
<p class="ltx_p" id="A2.SS1.p2.1"><span class="ltx_text ltx_font_bold" id="A2.SS1.p2.1.1">Identity Question Type:</span> We first build a typing tree using rules to categorize questions. Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#A2.F5" title="Figure 5 ‣ B.1 CMA Generation for NQ dataset ‣ Appendix B Methodology and Experiment Details ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_tag">5</span></a> illustrates the typing tree, which consists of a two-layer structure. In the typing process, we first determine if a question begins with one of the following words: “what”, “when”, “where”, “which”, “who”, “why”, or “how”. If it does, the question is categorized accordingly; if not, it is classified as “other”. However, this approach can still group different types of questions together. To address this, we use a second layer to refine the typing by analyzing two specific words in the question. For example, the question shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#S3.F1" title="Figure 1 ‣ 3 Methodology ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_tag">1</span></a> falls into the “how_many” category.</p>
</div>
<div class="ltx_para" id="A2.SS1.p3">
<p class="ltx_p" id="A2.SS1.p3.1"><span class="ltx_text ltx_font_bold" id="A2.SS1.p3.1.1">Determine Entity Type in MA to Change:</span> After categorizing the questions, we determine the entity type in MA needs to be replaced. To achieve this, we give each type of question an entity type, and many questions can share the same entity type. For example, both “when” and “what year” ask for a time. So a time entity in MA should be substituted. The final set of entity types is summarized in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#A2.T5" title="Table 5 ‣ B.1 CMA Generation for NQ dataset ‣ Appendix B Methodology and Experiment Details ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_tag">5</span></a>. We do not process questions starting with “what”, “which” or “how” due to the lack of a unified entity type for these questions. Table <a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#A2.T6" title="Table 6 ‣ B.1 CMA Generation for NQ dataset ‣ Appendix B Methodology and Experiment Details ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_tag">6</span></a> shows the statistics of the unprocessed questions.</p>
</div>
<div class="ltx_para" id="A2.SS1.p4">
<p class="ltx_p" id="A2.SS1.p4.1"><span class="ltx_text ltx_font_bold" id="A2.SS1.p4.1.1">Generate CMA with LLMs:</span> Instead of manually editing the MA, we leverage the LLMs’ ability to generate CMA by providing it with a carefully designed prompt, which is shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#A3.T9" title="Table 9 ‣ Appendix C Prompts ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_tag">9</span></a> (index 5). This prompt instructs the LLM to replace the entity with a certain type in the MA (from Step 2) with an alternative, ensuring the generated CMA differs from the MA.</p>
</div>
<div class="ltx_para" id="A2.SS1.p5">
<p class="ltx_p" id="A2.SS1.p5.1">The generated CMA must meet two key criteria: 1) The CMA must directly contradict the MA. To ensure this, we employ a Natural Language Inference (NLI) model<span class="ltx_note ltx_role_footnote" id="footnote9"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span>https://huggingface.co/microsoft/deberta-v2-xxlarge-mnli</span></span></span> to verify the contradiction between the two answers. 2) The alternative entity in CMA must not appear in the question. We achieve this check by string matching.
If the CMA fails to meet either of these criteria, we prompt the LLM to regenerate the CMA up to 5 times. If no proper CMA is generated, we filter out this question.</p>
</div>
</section>
<section class="ltx_subsection" id="A2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.2 </span>Dataset Details</h3>
<figure class="ltx_table" id="A2.T7">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A2.T7.1" style="width:411.9pt;height:115.1pt;vertical-align:-0.6pt;"><span class="ltx_transformed_inner" style="transform:translate(-118.0pt,32.8pt) scale(0.635841494066519,0.635841494066519) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A2.T7.1.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A2.T7.1.1.1.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A2.T7.1.1.1.1.1"></th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="4" id="A2.T7.1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="A2.T7.1.1.1.1.2.1">popQA</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="4" id="A2.T7.1.1.1.1.3"><span class="ltx_text ltx_font_bold" id="A2.T7.1.1.1.1.3.1">NQ</span></td>
</tr>
<tr class="ltx_tr" id="A2.T7.1.1.2.2">
<th class="ltx_td ltx_th ltx_th_row ltx_border_r" id="A2.T7.1.1.2.2.1"></th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T7.1.1.2.2.2"><span class="ltx_text ltx_font_bold" id="A2.T7.1.1.2.2.2.1">LLaMA2.7B</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T7.1.1.2.2.3"><span class="ltx_text ltx_font_bold" id="A2.T7.1.1.2.2.3.1">LLaMA2.70B</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T7.1.1.2.2.4"><span class="ltx_text ltx_font_bold" id="A2.T7.1.1.2.2.4.1">ChatGPT</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T7.1.1.2.2.5"><span class="ltx_text ltx_font_bold" id="A2.T7.1.1.2.2.5.1">GPT-4</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T7.1.1.2.2.6"><span class="ltx_text ltx_font_bold" id="A2.T7.1.1.2.2.6.1">LLaMA2.7B</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T7.1.1.2.2.7"><span class="ltx_text ltx_font_bold" id="A2.T7.1.1.2.2.7.1">LLaMA2.70B</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T7.1.1.2.2.8"><span class="ltx_text ltx_font_bold" id="A2.T7.1.1.2.2.8.1">ChatGPT</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T7.1.1.2.2.9"><span class="ltx_text ltx_font_bold" id="A2.T7.1.1.2.2.9.1">GPT-4</span></td>
</tr>
<tr class="ltx_tr" id="A2.T7.1.1.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A2.T7.1.1.3.3.1"><span class="ltx_text ltx_font_bold" id="A2.T7.1.1.3.3.1.1">Initial (# of Q)</span></th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T7.1.1.3.3.2">1000</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T7.1.1.3.3.3">1000</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T7.1.1.3.3.4">1000</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T7.1.1.3.3.5">1000</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T7.1.1.3.3.6">1667</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T7.1.1.3.3.7">1667</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T7.1.1.3.3.8">1667</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T7.1.1.3.3.9">1667</td>
</tr>
<tr class="ltx_tr" id="A2.T7.1.1.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A2.T7.1.1.4.4.1"><span class="ltx_text ltx_font_bold" id="A2.T7.1.1.4.4.1.1">Generate MA</span></th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T7.1.1.4.4.2">1000</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T7.1.1.4.4.3">1000</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T7.1.1.4.4.4">1000</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T7.1.1.4.4.5">1000</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T7.1.1.4.4.6">1435</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T7.1.1.4.4.7">1392</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T7.1.1.4.4.8">1532</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T7.1.1.4.4.9">1539</td>
</tr>
<tr class="ltx_tr" id="A2.T7.1.1.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A2.T7.1.1.5.5.1"><span class="ltx_text ltx_font_bold" id="A2.T7.1.1.5.5.1.1">Generate CMA</span></th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T7.1.1.5.5.2">1000</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T7.1.1.5.5.3">1000</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T7.1.1.5.5.4">1000</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T7.1.1.5.5.5">1000</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T7.1.1.5.5.6">1152</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T7.1.1.5.5.7">1101</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T7.1.1.5.5.8">1189</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T7.1.1.5.5.9">1252</td>
</tr>
<tr class="ltx_tr" id="A2.T7.1.1.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A2.T7.1.1.6.6.1"><span class="ltx_text ltx_font_bold" id="A2.T7.1.1.6.6.1.1">CMA filter</span></th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T7.1.1.6.6.2">922</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T7.1.1.6.6.3">932</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T7.1.1.6.6.4">944</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T7.1.1.6.6.5">946</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T7.1.1.6.6.6">1060</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T7.1.1.6.6.7">1027</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T7.1.1.6.6.8">1110</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T7.1.1.6.6.9">1188</td>
</tr>
<tr class="ltx_tr" id="A2.T7.1.1.7.7" style="background-color:#E6E6E6;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A2.T7.1.1.7.7.1"><span class="ltx_text ltx_font_bold" id="A2.T7.1.1.7.7.1.1" style="background-color:#E6E6E6;">Direct Evidence</span></th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T7.1.1.7.7.2"><span class="ltx_text" id="A2.T7.1.1.7.7.2.1" style="background-color:#E6E6E6;">918</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T7.1.1.7.7.3"><span class="ltx_text" id="A2.T7.1.1.7.7.3.1" style="background-color:#E6E6E6;">922</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T7.1.1.7.7.4"><span class="ltx_text" id="A2.T7.1.1.7.7.4.1" style="background-color:#E6E6E6;">933</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T7.1.1.7.7.5"><span class="ltx_text" id="A2.T7.1.1.7.7.5.1" style="background-color:#E6E6E6;">933</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T7.1.1.7.7.6"><span class="ltx_text" id="A2.T7.1.1.7.7.6.1" style="background-color:#E6E6E6;">1042</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T7.1.1.7.7.7"><span class="ltx_text" id="A2.T7.1.1.7.7.7.1" style="background-color:#E6E6E6;">1009</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T7.1.1.7.7.8"><span class="ltx_text" id="A2.T7.1.1.7.7.8.1" style="background-color:#E6E6E6;">1079</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T7.1.1.7.7.9"><span class="ltx_text" id="A2.T7.1.1.7.7.9.1" style="background-color:#E6E6E6;">1171</span></td>
</tr>
<tr class="ltx_tr" id="A2.T7.1.1.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A2.T7.1.1.8.8.1"><span class="ltx_text ltx_font_bold" id="A2.T7.1.1.8.8.1.1">2 sentence indirect evidence</span></th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T7.1.1.8.8.2">903</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T7.1.1.8.8.3">910</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T7.1.1.8.8.4">921</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T7.1.1.8.8.5">923</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T7.1.1.8.8.6">990</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T7.1.1.8.8.7">985</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T7.1.1.8.8.8">1038</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T7.1.1.8.8.9">1129</td>
</tr>
<tr class="ltx_tr" id="A2.T7.1.1.9.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A2.T7.1.1.9.9.1"><span class="ltx_text ltx_font_bold" id="A2.T7.1.1.9.9.1.1">3 sentence indirect evidence</span></th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T7.1.1.9.9.2">907</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T7.1.1.9.9.3">897</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T7.1.1.9.9.4">918</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T7.1.1.9.9.5">924</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T7.1.1.9.9.6">991</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T7.1.1.9.9.7">982</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A2.T7.1.1.9.9.8">1041</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T7.1.1.9.9.9">1125</td>
</tr>
<tr class="ltx_tr" id="A2.T7.1.1.10.10" style="background-color:#E6E6E6;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t" id="A2.T7.1.1.10.10.1"><span class="ltx_text ltx_font_bold" id="A2.T7.1.1.10.10.1.1" style="background-color:#E6E6E6;">intersection of 2&amp;3 sentence evidence</span></th>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="A2.T7.1.1.10.10.2"><span class="ltx_text" id="A2.T7.1.1.10.10.2.1" style="background-color:#E6E6E6;">901</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="A2.T7.1.1.10.10.3"><span class="ltx_text" id="A2.T7.1.1.10.10.3.1" style="background-color:#E6E6E6;">895</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="A2.T7.1.1.10.10.4"><span class="ltx_text" id="A2.T7.1.1.10.10.4.1" style="background-color:#E6E6E6;">911</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="A2.T7.1.1.10.10.5"><span class="ltx_text" id="A2.T7.1.1.10.10.5.1" style="background-color:#E6E6E6;">918</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="A2.T7.1.1.10.10.6"><span class="ltx_text" id="A2.T7.1.1.10.10.6.1" style="background-color:#E6E6E6;">976</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="A2.T7.1.1.10.10.7"><span class="ltx_text" id="A2.T7.1.1.10.10.7.1" style="background-color:#E6E6E6;">972</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="A2.T7.1.1.10.10.8"><span class="ltx_text" id="A2.T7.1.1.10.10.8.1" style="background-color:#E6E6E6;">1025</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="A2.T7.1.1.10.10.9"><span class="ltx_text" id="A2.T7.1.1.10.10.9.1" style="background-color:#E6E6E6;">1108</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 7: </span>The dataset scale at each step across popQA and NQ dataset. “intersection of 2&amp;3 sentence evidence” is the count for indirect evidence.</figcaption>
</figure>
<div class="ltx_para" id="A2.SS2.p1">
<p class="ltx_p" id="A2.SS2.p1.1">For the popQA dataset, we use the dataset from <cite class="ltx_cite ltx_citemacro_citet">Xie et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib32" title="">2024</a>)</cite> by randomly selecting 1,000 questions from the data intersection of the conflicts generated by LLaMA2.7B, LLaMA2.70B, ChatGPT, and GPT-4. We use the MA and CMA from <cite class="ltx_cite ltx_citemacro_citet">Xie et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib32" title="">2024</a>)</cite> and only generate direct evidence and indirect evidence using our framework. For the NQ dataset, we use the test set from <cite class="ltx_cite ltx_citemacro_citet">Longpre et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib16" title="">2021</a>)</cite>, which consists of 1,667 unique questions. The MA, CMA, and evidence are all generated with our framework. The dataset scale at each step is presented in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#A2.T7" title="Table 7 ‣ B.2 Dataset Details ‣ Appendix B Methodology and Experiment Details ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_tag">7</span></a>.</p>
</div>
</section>
<section class="ltx_subsection" id="A2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.3 </span>Human Evaluation for Model Reliability</h3>
<div class="ltx_para" id="A2.SS3.p1">
<p class="ltx_p" id="A2.SS3.p1.1">To ensure the reliability of the NLI model, <cite class="ltx_cite ltx_citemacro_citet">Xie et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#bib.bib32" title="">2024</a>)</cite> randomly sample 200 generated examples and manually annotate whether the generated content entails the corresponding claim. The labels are supportive (entailment in
the NLI task) or not supportive (either neutral or contradiction in the NLI task). The accuracy is 99%.</p>
</div>
<div class="ltx_para" id="A2.SS3.p2">
<p class="ltx_p" id="A2.SS3.p2.1">Following this process, we evaluate how reliable the generated CMA is. We randomly sample 200 generated examples in the NQ dataset and manually annotate whether the correct entity in MA is found and replaced with a same type alternative. The accuracy is 98%, which means the generated CMA is reliable.</p>
</div>
</section>
<section class="ltx_subsection" id="A2.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.4 </span>Impact of Memory Strength with Different Evidence Styles</h3>
<div class="ltx_para" id="A2.SS4.p1">
<p class="ltx_p" id="A2.SS4.p1.1">To demonstrate the relationship between context-faithfulness and memory strength with other evidence styles, we categorize the questions in each dataset into four groups according to the memory strength intervals [-2, -1], (-1, -0.5], (-0.5, -0.25] and [-0.25, 0], The evidence styles are direct + paraphrase evidence with two sentences and indirect evidence with two sentences. Figures <a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#A2.F6" title="Figure 6 ‣ B.4 Impact of Memory Strength with Different Evidence Styles ‣ Appendix B Methodology and Experiment Details ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_tag">6</span></a>,<a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#A2.F7" title="Figure 7 ‣ B.4 Impact of Memory Strength with Different Evidence Styles ‣ Appendix B Methodology and Experiment Details ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_tag">7</span></a> show the result. The figures show that there is a clear positive correlation between memory strength and MA ratio for both evidence styles, which implies that this positive correlation between memory strength and MA ratio is general.</p>
</div>
<div class="ltx_para" id="A2.SS4.p2">
<p class="ltx_p" id="A2.SS4.p2.1">To demonstrate the relationship between context-faithfulness and memory strength with “CMA first” scenario, we show MA, CMA, and UCT ratios with direct evidence with one sentence under “CMA first” scenario in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#A2.F8" title="Figure 8 ‣ B.4 Impact of Memory Strength with Different Evidence Styles ‣ Appendix B Methodology and Experiment Details ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_tag">8</span></a>. The positive correlation between memory strength and MA ratio stays unchanged.</p>
</div>
<figure class="ltx_figure" id="A2.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="198" id="A2.F6.g1" src="extracted/5859889/fig/ratio_on_memory_strength_first_paraphrase.png" width="550"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Relationship between Memory Strength and Answer Ratio with Direct + Paraphrase Evidence with Two Sentences.</figcaption>
</figure>
<figure class="ltx_figure" id="A2.F7"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="200" id="A2.F7.g1" src="extracted/5859889/fig/ratio_on_memory_strength_two_sentence.png" width="550"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Relationship between Memory Strength and Answer Ratio with Indirect Evidence with Two Sentences.</figcaption>
</figure>
<figure class="ltx_figure" id="A2.F8"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="198" id="A2.F8.g1" src="extracted/5859889/fig/ratio_on_memory_strength_direct_counter.png" width="550"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Relationship between Memory Strength and Answer Ratio with Direct Evidence. The option order is Counter First.</figcaption>
</figure>
<figure class="ltx_table" id="A2.T8">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A2.T8.1" style="width:403.3pt;height:85.7pt;vertical-align:-0.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-88.3pt,18.6pt) scale(0.695358871802061,0.695358871802061) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A2.T8.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A2.T8.1.1.1.1">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t" id="A2.T8.1.1.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="A2.T8.1.1.1.1.1.1">
<span class="ltx_p" id="A2.T8.1.1.1.1.1.1.1" style="width:85.4pt;"><span class="ltx_text ltx_font_bold" id="A2.T8.1.1.1.1.1.1.1.1">Origin Question</span></span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t" id="A2.T8.1.1.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="A2.T8.1.1.1.1.2.1">
<span class="ltx_p" id="A2.T8.1.1.1.1.2.1.1" style="width:227.6pt;"><span class="ltx_text ltx_font_bold" id="A2.T8.1.1.1.1.2.1.1.1">Paraphrased Questions</span></span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t" id="A2.T8.1.1.1.1.3">
<span class="ltx_inline-block ltx_align_top" id="A2.T8.1.1.1.1.3.1">
<span class="ltx_p" id="A2.T8.1.1.1.1.3.1.1" style="width:227.6pt;"><span class="ltx_text ltx_font_bold" id="A2.T8.1.1.1.1.3.1.1.1">Answers</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A2.T8.1.1.2.1">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="A2.T8.1.1.2.1.1" rowspan="4">
<span class="ltx_inline-block ltx_align_top" id="A2.T8.1.1.2.1.1.1">
<span class="ltx_p" id="A2.T8.1.1.2.1.1.1.1" style="width:85.4pt;"><span class="ltx_text" id="A2.T8.1.1.2.1.1.1.1.1">Who sings the Christmas song “Mary Did You Know”?</span></span>
</span>
</th>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A2.T8.1.1.2.1.2">
<span class="ltx_inline-block ltx_align_top" id="A2.T8.1.1.2.1.2.1">
<span class="ltx_p" id="A2.T8.1.1.2.1.2.1.1" style="width:227.6pt;">Can you tell me the artist who performs the Christmas song “Mary Did You Know”?</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A2.T8.1.1.2.1.3">
<span class="ltx_inline-block ltx_align_top" id="A2.T8.1.1.2.1.3.1">
<span class="ltx_p" id="A2.T8.1.1.2.1.3.1.1" style="width:227.6pt;">Of course! The artist who performs the Christmas song “Mary Did You Know” is <span class="ltx_text" id="A2.T8.1.1.2.1.3.1.1.1" style="background-color:#B3B3FF;">Mark Lowry</span>.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A2.T8.1.1.3.2">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A2.T8.1.1.3.2.1">
<span class="ltx_inline-block ltx_align_top" id="A2.T8.1.1.3.2.1.1">
<span class="ltx_p" id="A2.T8.1.1.3.2.1.1.1" style="width:227.6pt;">Who is the singer behind the Christmas song “Mary Did You Know”?</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A2.T8.1.1.3.2.2">
<span class="ltx_inline-block ltx_align_top" id="A2.T8.1.1.3.2.2.1">
<span class="ltx_p" id="A2.T8.1.1.3.2.2.1.1" style="width:227.6pt;">The singer behind the Christmas song “Mary Did You Know” is <span class="ltx_text" id="A2.T8.1.1.3.2.2.1.1.1" style="background-color:#B3B3FF;">Mark Lowry</span>.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A2.T8.1.1.4.3">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A2.T8.1.1.4.3.1">
<span class="ltx_inline-block ltx_align_top" id="A2.T8.1.1.4.3.1.1">
<span class="ltx_p" id="A2.T8.1.1.4.3.1.1.1" style="width:227.6pt;">Which musician sings the Christmas tune “Mary Did You Know”?</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A2.T8.1.1.4.3.2">
<span class="ltx_inline-block ltx_align_top" id="A2.T8.1.1.4.3.2.1">
<span class="ltx_p" id="A2.T8.1.1.4.3.2.1.1" style="width:227.6pt;"><span class="ltx_text" id="A2.T8.1.1.4.3.2.1.1.1" style="background-color:#FFB3B3;">Brandy Clark</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A2.T8.1.1.5.4">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t" id="A2.T8.1.1.5.4.1">
<span class="ltx_inline-block ltx_align_top" id="A2.T8.1.1.5.4.1.1">
<span class="ltx_p" id="A2.T8.1.1.5.4.1.1.1" style="width:227.6pt;">Who is the vocalist that sings “Mary Did You Know” during the holiday season?</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t" id="A2.T8.1.1.5.4.2">
<span class="ltx_inline-block ltx_align_top" id="A2.T8.1.1.5.4.2.1">
<span class="ltx_p" id="A2.T8.1.1.5.4.2.1.1" style="width:227.6pt;">The vocalist who sings “Mary Did You Know” during the holiday season is <span class="ltx_text" id="A2.T8.1.1.5.4.2.1.1.1" style="background-color:#B3B3FF;">Mark Lowry</span>.</span>
</span>
</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 8: </span>Origin Question, Paraphrased Questions, and Corresponding Answers</figcaption>
</figure>
</section>
</section>
<section class="ltx_appendix" id="A3">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Prompts</h2>
<div class="ltx_para" id="A3.p1">
<p class="ltx_p" id="A3.p1.1">In Table <a class="ltx_ref" href="https://arxiv.org/html/2409.10955v1#A3.T9" title="Table 9 ‣ Appendix C Prompts ‣ Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style"><span class="ltx_text ltx_ref_tag">9</span></a>, we present a detailed list of all the prompts used throughout this study.</p>
</div>
<figure class="ltx_table" id="A3.T9">
<div class="ltx_inline-block ltx_transformed_outer" id="A3.T9.1" style="width:424.9pt;height:621.2pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-55.0pt,80.4pt) scale(0.794246363087104,0.794246363087104) ;">
<table class="ltx_tabular ltx_align_middle" id="A3.T9.1.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A3.T9.1.1.1.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A3.T9.1.1.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="A3.T9.1.1.1.1.1.1">
<span class="ltx_p" id="A3.T9.1.1.1.1.1.1.1" style="width:42.7pt;"><span class="ltx_text ltx_font_bold" id="A3.T9.1.1.1.1.1.1.1.1">Step</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A3.T9.1.1.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="A3.T9.1.1.1.1.2.1">
<span class="ltx_p" id="A3.T9.1.1.1.1.2.1.1" style="width:28.5pt;"><span class="ltx_text ltx_font_bold" id="A3.T9.1.1.1.1.2.1.1.1">index</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A3.T9.1.1.1.1.3">
<span class="ltx_inline-block ltx_align_top" id="A3.T9.1.1.1.1.3.1">
<span class="ltx_p" id="A3.T9.1.1.1.1.3.1.1" style="width:71.1pt;"><span class="ltx_text ltx_font_bold" id="A3.T9.1.1.1.1.3.1.1.1">Prompt Name</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A3.T9.1.1.1.1.4">
<span class="ltx_inline-block ltx_align_top" id="A3.T9.1.1.1.1.4.1">
<span class="ltx_p" id="A3.T9.1.1.1.1.4.1.1" style="width:341.4pt;"><span class="ltx_text ltx_font_bold" id="A3.T9.1.1.1.1.4.1.1.1">Prompts</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T9.1.1.2.2">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A3.T9.1.1.2.2.1" rowspan="11">
<span class="ltx_inline-block ltx_align_top" id="A3.T9.1.1.2.2.1.1">
<span class="ltx_p" id="A3.T9.1.1.2.2.1.1.1" style="width:42.7pt;"><span class="ltx_text" id="A3.T9.1.1.2.2.1.1.1.1">Step <span class="ltx_text" id="A3.T9.1.1.2.2.1.1.1.1.1">1:</span> Memory Strength</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A3.T9.1.1.2.2.2" rowspan="2">
<span class="ltx_inline-block ltx_align_top" id="A3.T9.1.1.2.2.2.1">
<span class="ltx_p" id="A3.T9.1.1.2.2.2.1.1" style="width:28.5pt;"><span class="ltx_text" id="A3.T9.1.1.2.2.2.1.1.1">1</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A3.T9.1.1.2.2.3" rowspan="2">
<span class="ltx_inline-block ltx_align_top" id="A3.T9.1.1.2.2.3.1">
<span class="ltx_p" id="A3.T9.1.1.2.2.3.1.1" style="width:71.1pt;"><span class="ltx_text" id="A3.T9.1.1.2.2.3.1.1.1">Question paraphrase prompt</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A3.T9.1.1.2.2.4">
<span class="ltx_inline-block ltx_align_top" id="A3.T9.1.1.2.2.4.1">
<span class="ltx_p" id="A3.T9.1.1.2.2.4.1.1" style="width:341.4pt;">Generate 7 meaningful paraphrases for the following question: [Question]. Read the question carefully.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T9.1.1.3.3">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T9.1.1.3.3.1">
<span class="ltx_inline-block ltx_align_top" id="A3.T9.1.1.3.3.1.1">
<span class="ltx_p" id="A3.T9.1.1.3.3.1.1.1" style="width:341.4pt;">Paraphrases:</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T9.1.1.4.4">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A3.T9.1.1.4.4.1" rowspan="4">
<span class="ltx_inline-block ltx_align_top" id="A3.T9.1.1.4.4.1.1">
<span class="ltx_p" id="A3.T9.1.1.4.4.1.1.1" style="width:28.5pt;"><span class="ltx_text" id="A3.T9.1.1.4.4.1.1.1.1">2</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A3.T9.1.1.4.4.2" rowspan="4">
<span class="ltx_inline-block ltx_align_top" id="A3.T9.1.1.4.4.2.1">
<span class="ltx_p" id="A3.T9.1.1.4.4.2.1.1" style="width:71.1pt;"><span class="ltx_text" id="A3.T9.1.1.4.4.2.1.1.1">Question equivalent check prompt</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A3.T9.1.1.4.4.3">
<span class="ltx_inline-block ltx_align_top" id="A3.T9.1.1.4.4.3.1">
<span class="ltx_p" id="A3.T9.1.1.4.4.3.1.1" style="width:341.4pt;">Determine whether the paraphrased question describes the same thing as the original question, and give "Contradicted" if they are not the same, otherwise give "Same" as the result.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T9.1.1.5.5">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T9.1.1.5.5.1">
<span class="ltx_inline-block ltx_align_top" id="A3.T9.1.1.5.5.1.1">
<span class="ltx_p" id="A3.T9.1.1.5.5.1.1.1" style="width:341.4pt;">Q1: [Paraphrased Q1]</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T9.1.1.6.6">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T9.1.1.6.6.1">
<span class="ltx_inline-block ltx_align_top" id="A3.T9.1.1.6.6.1.1">
<span class="ltx_p" id="A3.T9.1.1.6.6.1.1.1" style="width:341.4pt;">Q2: [Paraphrased Q2]</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T9.1.1.7.7">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T9.1.1.7.7.1">
<span class="ltx_inline-block ltx_align_top" id="A3.T9.1.1.7.7.1.1">
<span class="ltx_p" id="A3.T9.1.1.7.7.1.1.1" style="width:341.4pt;">Keep the answer short and concise.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T9.1.1.8.8">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A3.T9.1.1.8.8.1" rowspan="5">
<span class="ltx_inline-block ltx_align_top" id="A3.T9.1.1.8.8.1.1">
<span class="ltx_p" id="A3.T9.1.1.8.8.1.1.1" style="width:28.5pt;"><span class="ltx_text" id="A3.T9.1.1.8.8.1.1.1.1">3</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A3.T9.1.1.8.8.2" rowspan="5">
<span class="ltx_inline-block ltx_align_top" id="A3.T9.1.1.8.8.2.1">
<span class="ltx_p" id="A3.T9.1.1.8.8.2.1.1" style="width:71.1pt;"><span class="ltx_text" id="A3.T9.1.1.8.8.2.1.1.1">Answer consistency check prompt</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A3.T9.1.1.8.8.3">
<span class="ltx_inline-block ltx_align_top" id="A3.T9.1.1.8.8.3.1">
<span class="ltx_p" id="A3.T9.1.1.8.8.3.1.1" style="width:341.4pt;">Determine whether the answer ‘A1’ is ‘Contradicted’ or ‘Same’ with the answer ‘A2’ for the question ‘Q’. You need to check whether the two answers exactly have the same answer to the question. The answer could be person, name, place, time, number, genre, occupation, sport, entity, digit, or arithmetical results. If the two answers are the same, give “Same”, otherwise give “Contradicted” as the result.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T9.1.1.9.9">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T9.1.1.9.9.1">
<span class="ltx_inline-block ltx_align_top" id="A3.T9.1.1.9.9.1.1">
<span class="ltx_p" id="A3.T9.1.1.9.9.1.1.1" style="width:341.4pt;">Q: [question]</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T9.1.1.10.10">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T9.1.1.10.10.1">
<span class="ltx_inline-block ltx_align_top" id="A3.T9.1.1.10.10.1.1">
<span class="ltx_p" id="A3.T9.1.1.10.10.1.1.1" style="width:341.4pt;">A1: [LLM answer 1]</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T9.1.1.11.11">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T9.1.1.11.11.1">
<span class="ltx_inline-block ltx_align_top" id="A3.T9.1.1.11.11.1.1">
<span class="ltx_p" id="A3.T9.1.1.11.11.1.1.1" style="width:341.4pt;">A2: [LLM answer 2]</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T9.1.1.12.12">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T9.1.1.12.12.1">
<span class="ltx_inline-block ltx_align_top" id="A3.T9.1.1.12.12.1.1">
<span class="ltx_p" id="A3.T9.1.1.12.12.1.1.1" style="width:341.4pt;">Keep the answer short and concise.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T9.1.1.13.13">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A3.T9.1.1.13.13.1" rowspan="8">
<span class="ltx_inline-block ltx_align_top" id="A3.T9.1.1.13.13.1.1">
<span class="ltx_p" id="A3.T9.1.1.13.13.1.1.1" style="width:42.7pt;"><span class="ltx_text" id="A3.T9.1.1.13.13.1.1.1.1">Step <span class="ltx_text" id="A3.T9.1.1.13.13.1.1.1.1.1">2:</span> MA and CMA</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A3.T9.1.1.13.13.2" rowspan="4">
<span class="ltx_inline-block ltx_align_top" id="A3.T9.1.1.13.13.2.1">
<span class="ltx_p" id="A3.T9.1.1.13.13.2.1.1" style="width:28.5pt;"><span class="ltx_text" id="A3.T9.1.1.13.13.2.1.1.1">4</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A3.T9.1.1.13.13.3" rowspan="4">
<span class="ltx_inline-block ltx_align_top" id="A3.T9.1.1.13.13.3.1">
<span class="ltx_p" id="A3.T9.1.1.13.13.3.1.1" style="width:71.1pt;"><span class="ltx_text" id="A3.T9.1.1.13.13.3.1.1.1">Close book QA prompt</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A3.T9.1.1.13.13.4">
<span class="ltx_inline-block ltx_align_top" id="A3.T9.1.1.13.13.4.1">
<span class="ltx_p" id="A3.T9.1.1.13.13.4.1.1" style="width:341.4pt;">Answer the question with one sentence with object and subject only. Give a statement that is most likely to be true directly.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T9.1.1.14.14">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T9.1.1.14.14.1">
<span class="ltx_inline-block ltx_align_top" id="A3.T9.1.1.14.14.1.1">
<span class="ltx_p" id="A3.T9.1.1.14.14.1.1.1" style="width:341.4pt;">Question:</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T9.1.1.15.15">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T9.1.1.15.15.1">
<span class="ltx_inline-block ltx_align_top" id="A3.T9.1.1.15.15.1.1">
<span class="ltx_p" id="A3.T9.1.1.15.15.1.1.1" style="width:341.4pt;">[Question]</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T9.1.1.16.16">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T9.1.1.16.16.1">
<span class="ltx_inline-block ltx_align_top" id="A3.T9.1.1.16.16.1.1">
<span class="ltx_p" id="A3.T9.1.1.16.16.1.1.1" style="width:341.4pt;">Answer:</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T9.1.1.17.17">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A3.T9.1.1.17.17.1" rowspan="4">
<span class="ltx_inline-block ltx_align_top" id="A3.T9.1.1.17.17.1.1">
<span class="ltx_p" id="A3.T9.1.1.17.17.1.1.1" style="width:28.5pt;"><span class="ltx_text" id="A3.T9.1.1.17.17.1.1.1.1">5</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A3.T9.1.1.17.17.2" rowspan="4">
<span class="ltx_inline-block ltx_align_top" id="A3.T9.1.1.17.17.2.1">
<span class="ltx_p" id="A3.T9.1.1.17.17.2.1.1" style="width:71.1pt;"><span class="ltx_text" id="A3.T9.1.1.17.17.2.1.1.1">Change MA to CMA prompt</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A3.T9.1.1.17.17.3">
<span class="ltx_inline-block ltx_align_top" id="A3.T9.1.1.17.17.3.1">
<span class="ltx_p" id="A3.T9.1.1.17.17.3.1.1" style="width:341.4pt;">Context:</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T9.1.1.18.18">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T9.1.1.18.18.1">
<span class="ltx_inline-block ltx_align_top" id="A3.T9.1.1.18.18.1.1">
<span class="ltx_p" id="A3.T9.1.1.18.18.1.1.1" style="width:341.4pt;">[CMA]</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T9.1.1.19.19">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T9.1.1.19.19.1">
<span class="ltx_inline-block ltx_align_top" id="A3.T9.1.1.19.19.1.1">
<span class="ltx_p" id="A3.T9.1.1.19.19.1.1.1" style="width:341.4pt;">Change the [entity type] part of the context. When multiple parts need to be changed, only choose one part to change.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T9.1.1.20.20">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T9.1.1.20.20.1">
<span class="ltx_inline-block ltx_align_top" id="A3.T9.1.1.20.20.1.1">
<span class="ltx_p" id="A3.T9.1.1.20.20.1.1.1" style="width:341.4pt;">Answer:</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T9.1.1.21.21">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A3.T9.1.1.21.21.1" rowspan="7">
<span class="ltx_inline-block ltx_align_top" id="A3.T9.1.1.21.21.1.1">
<span class="ltx_p" id="A3.T9.1.1.21.21.1.1.1" style="width:42.7pt;"><span class="ltx_text" id="A3.T9.1.1.21.21.1.1.1.1">Step <span class="ltx_text" id="A3.T9.1.1.21.21.1.1.1.1.1">3:</span> Evidence</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A3.T9.1.1.21.21.2" rowspan="2">
<span class="ltx_inline-block ltx_align_top" id="A3.T9.1.1.21.21.2.1">
<span class="ltx_p" id="A3.T9.1.1.21.21.2.1.1" style="width:28.5pt;"><span class="ltx_text" id="A3.T9.1.1.21.21.2.1.1.1">6</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A3.T9.1.1.21.21.3" rowspan="2">
<span class="ltx_inline-block ltx_align_top" id="A3.T9.1.1.21.21.3.1">
<span class="ltx_p" id="A3.T9.1.1.21.21.3.1.1" style="width:71.1pt;"><span class="ltx_text" id="A3.T9.1.1.21.21.3.1.1.1">Direct evidence prompt</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A3.T9.1.1.21.21.4">
<span class="ltx_inline-block ltx_align_top" id="A3.T9.1.1.21.21.4.1">
<span class="ltx_p" id="A3.T9.1.1.21.21.4.1.1" style="width:341.4pt;">Please paraphrase the following sentence by changing the terms, order, and phrases, but keep the meaning the same.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T9.1.1.22.22">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T9.1.1.22.22.1">
<span class="ltx_inline-block ltx_align_top" id="A3.T9.1.1.22.22.1.1">
<span class="ltx_p" id="A3.T9.1.1.22.22.1.1.1" style="width:341.4pt;">Sentence: [CMA]</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T9.1.1.23.23">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A3.T9.1.1.23.23.1" rowspan="5">
<span class="ltx_inline-block ltx_align_top" id="A3.T9.1.1.23.23.1.1">
<span class="ltx_p" id="A3.T9.1.1.23.23.1.1.1" style="width:28.5pt;"><span class="ltx_text" id="A3.T9.1.1.23.23.1.1.1.1">7</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A3.T9.1.1.23.23.2" rowspan="5">
<span class="ltx_inline-block ltx_align_top" id="A3.T9.1.1.23.23.2.1">
<span class="ltx_p" id="A3.T9.1.1.23.23.2.1.1" style="width:71.1pt;"><span class="ltx_text" id="A3.T9.1.1.23.23.2.1.1.1">Indirect evidence prompt</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A3.T9.1.1.23.23.3">
<span class="ltx_inline-block ltx_align_top" id="A3.T9.1.1.23.23.3.1">
<span class="ltx_p" id="A3.T9.1.1.23.23.3.1.1" style="width:341.4pt;">Given a claim, please write a short piece of detailed evidence to support it. Please ignore the correctness of the claim. You can make up fake content and supporting evidence but it should be as realistic as possible.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T9.1.1.24.24">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T9.1.1.24.24.1">
<span class="ltx_inline-block ltx_align_top" id="A3.T9.1.1.24.24.1.1">
<span class="ltx_p" id="A3.T9.1.1.24.24.1.1.1" style="width:341.4pt;">Claim:</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T9.1.1.25.25">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T9.1.1.25.25.1">
<span class="ltx_inline-block ltx_align_top" id="A3.T9.1.1.25.25.1.1">
<span class="ltx_p" id="A3.T9.1.1.25.25.1.1.1" style="width:341.4pt;">[counter memory answer]</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T9.1.1.26.26">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T9.1.1.26.26.1">
<span class="ltx_inline-block ltx_align_top" id="A3.T9.1.1.26.26.1.1">
<span class="ltx_p" id="A3.T9.1.1.26.26.1.1.1" style="width:341.4pt;">Evidence:</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T9.1.1.27.27">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T9.1.1.27.27.1">
<span class="ltx_inline-block ltx_align_top" id="A3.T9.1.1.27.27.1.1">
<span class="ltx_p" id="A3.T9.1.1.27.27.1.1.1" style="width:341.4pt;">Give the answer in [2 or 3] sentences directly.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T9.1.1.28.28">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t" id="A3.T9.1.1.28.28.1" rowspan="8">
<span class="ltx_inline-block ltx_align_top" id="A3.T9.1.1.28.28.1.1">
<span class="ltx_p" id="A3.T9.1.1.28.28.1.1.1" style="width:42.7pt;"><span class="ltx_text" id="A3.T9.1.1.28.28.1.1.1.1">Step <span class="ltx_text" id="A3.T9.1.1.28.28.1.1.1.1.1">4:</span> Evaluation</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t" id="A3.T9.1.1.28.28.2" rowspan="8">
<span class="ltx_inline-block ltx_align_top" id="A3.T9.1.1.28.28.2.1">
<span class="ltx_p" id="A3.T9.1.1.28.28.2.1.1" style="width:28.5pt;"><span class="ltx_text" id="A3.T9.1.1.28.28.2.1.1.1">8</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t" id="A3.T9.1.1.28.28.3" rowspan="8">
<span class="ltx_inline-block ltx_align_top" id="A3.T9.1.1.28.28.3.1">
<span class="ltx_p" id="A3.T9.1.1.28.28.3.1.1" style="width:71.1pt;"><span class="ltx_text" id="A3.T9.1.1.28.28.3.1.1.1">Evaluate with evidence prompt</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A3.T9.1.1.28.28.4">
<span class="ltx_inline-block ltx_align_top" id="A3.T9.1.1.28.28.4.1">
<span class="ltx_p" id="A3.T9.1.1.28.28.4.1.1" style="width:341.4pt;">According to the given information, choose the best choice from
the following options.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T9.1.1.29.29">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T9.1.1.29.29.1">
<span class="ltx_inline-block ltx_align_top" id="A3.T9.1.1.29.29.1.1">
<span class="ltx_p" id="A3.T9.1.1.29.29.1.1.1" style="width:341.4pt;">Information: [evidence]</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T9.1.1.30.30">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T9.1.1.30.30.1">
<span class="ltx_inline-block ltx_align_top" id="A3.T9.1.1.30.30.1.1">
<span class="ltx_p" id="A3.T9.1.1.30.30.1.1.1" style="width:341.4pt;">Question: [question]</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T9.1.1.31.31">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T9.1.1.31.31.1">
<span class="ltx_inline-block ltx_align_top" id="A3.T9.1.1.31.31.1.1">
<span class="ltx_p" id="A3.T9.1.1.31.31.1.1.1" style="width:341.4pt;">Option:</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T9.1.1.32.32">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T9.1.1.32.32.1">
<span class="ltx_inline-block ltx_align_top" id="A3.T9.1.1.32.32.1.1">
<span class="ltx_p" id="A3.T9.1.1.32.32.1.1.1" style="width:341.4pt;">A: [option 1]</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T9.1.1.33.33">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T9.1.1.33.33.1">
<span class="ltx_inline-block ltx_align_top" id="A3.T9.1.1.33.33.1.1">
<span class="ltx_p" id="A3.T9.1.1.33.33.1.1.1" style="width:341.4pt;">B: [option 2]</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T9.1.1.34.34">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A3.T9.1.1.34.34.1">
<span class="ltx_inline-block ltx_align_top" id="A3.T9.1.1.34.34.1.1">
<span class="ltx_p" id="A3.T9.1.1.34.34.1.1.1" style="width:341.4pt;">…</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T9.1.1.35.35">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_b" id="A3.T9.1.1.35.35.1">
<span class="ltx_inline-block ltx_align_top" id="A3.T9.1.1.35.35.1.1">
<span class="ltx_p" id="A3.T9.1.1.35.35.1.1.1" style="width:341.4pt;">Answer:</span>
</span>
</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 9: </span>Prompts for LLMs in this paper. “[PLACEHOLDER]” is the corresponding input. </figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Tue Sep 17 07:39:09 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
