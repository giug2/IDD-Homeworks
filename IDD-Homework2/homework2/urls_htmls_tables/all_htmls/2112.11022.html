<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2112.11022] Synthetic Data and Simulators for Recommendation Systems: Current State and Future Directions</title><meta property="og:description" content="Synthetic data and simulators have the potential to markedly improve the performance and robustness of recommendation systems. These approaches have already had a beneficial impact in other machine-learning driven fiel…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Synthetic Data and Simulators for Recommendation Systems: Current State and Future Directions">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Synthetic Data and Simulators for Recommendation Systems: Current State and Future Directions">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2112.11022">

<!--Generated on Fri Mar  1 15:47:46 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="synthetic data,  simulators,  dataset fidelity,  privacy preservation">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">Synthetic Data and Simulators for Recommendation Systems: Current State and Future Directions </h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Adam Lesnikowski
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:adam.lesnikowski@gmail.com">adam.lesnikowski@gmail.com</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span id="id1.1.id1" class="ltx_text ltx_affiliation_institution">NVIDIA*</span><span id="id2.2.id2" class="ltx_text ltx_affiliation_city">Redmond</span><span id="id3.3.id3" class="ltx_text ltx_affiliation_state">Washington</span><span id="id4.4.id4" class="ltx_text ltx_affiliation_country">USA</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Gabriel de Souza Pereira Moreira
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:gmoreira@nvidia.com">gmoreira@nvidia.com</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span id="id5.1.id1" class="ltx_text ltx_affiliation_institution">NVIDIA</span><span id="id6.2.id2" class="ltx_text ltx_affiliation_city">São Paulo</span><span id="id7.3.id3" class="ltx_text ltx_affiliation_state">São Paulo</span><span id="id8.4.id4" class="ltx_text ltx_affiliation_country">Brazil</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Sara Rabhi
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:srabhi@nvidia.com">srabhi@nvidia.com</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span id="id9.1.id1" class="ltx_text ltx_affiliation_institution">NVIDIA</span><span id="id10.2.id2" class="ltx_text ltx_affiliation_state">Ontario</span><span id="id11.3.id3" class="ltx_text ltx_affiliation_country">Canada</span>
</span></span></span>
<span class="ltx_author_before"> and </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Karl Byleen-Higley
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:karlb@nvidia.com">karlb@nvidia.com</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span id="id12.1.id1" class="ltx_text ltx_affiliation_institution">NVIDIA</span><span id="id13.2.id2" class="ltx_text ltx_affiliation_country">USA</span>
</span></span></span>
</div>
<div class="ltx_dates">(2021)</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p id="id14.id1" class="ltx_p">Synthetic data and simulators have the potential to markedly improve the performance and robustness of recommendation systems. These approaches have already had a beneficial impact in other machine-learning driven fields. We identify and discuss a key trade-off between data fidelity and privacy in the past work on synthetic data and simulators for recommendation systems. For the important use case of predicting algorithm rankings on real data from synthetic data, we provide motivation and current successes versus limitations. Finally we outline a number of exciting future directions for recommendation systems that we believe deserve further attention and work, including mixing real and synthetic data, feedback in dataset generation, robust simulations, and privacy-preserving methods.</p>
</div>
<div class="ltx_keywords">synthetic data, simulators, dataset fidelity, privacy preservation
</div>
<span id="id1" class="ltx_note ltx_note_frontmatter ltx_role_copyright"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">copyright: </span>acmcopyright</span></span></span><span id="id2" class="ltx_note ltx_note_frontmatter ltx_role_journalyear"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">journalyear: </span>2021</span></span></span><span id="id3" class="ltx_note ltx_note_frontmatter ltx_role_conference"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">conference: </span>SimuRec 2021: Workshop on Simulation Methods for Recommender Systems at ACM RecSys ’21; October 2nd, 2021; Amsterdam, NL, online</span></span></span><span id="id4" class="ltx_note ltx_note_frontmatter ltx_role_booktitle"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">booktitle: </span>SimuRec 2021: Workshop on Simulation Methods for Recommender Systems at ACM RecSys 2021, October 2nd, 2021, Amsterdam, NL and online</span></span></span>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Synthetic data generation and simulation techniques have been popular and successful in machine learning areas such as computer vision <cite class="ltx_cite ltx_citemacro_citep">(Tremblay
et al<span class="ltx_text">.</span>, <a href="#bib.bib26" title="" class="ltx_ref">2018</a>)</cite> <cite class="ltx_cite ltx_citemacro_citep">(Sankaranarayanan et al<span class="ltx_text">.</span>, <a href="#bib.bib18" title="" class="ltx_ref">2018</a>)</cite> and robotics <cite class="ltx_cite ltx_citemacro_citep">(Tobin
et al<span class="ltx_text">.</span>, <a href="#bib.bib25" title="" class="ltx_ref">2018</a>)</cite> <cite class="ltx_cite ltx_citemacro_citep">(Prakash et al<span class="ltx_text">.</span>, <a href="#bib.bib15" title="" class="ltx_ref">2019</a>)</cite>, but have not been broadly explored for recommender systems, with <cite class="ltx_cite ltx_citemacro_citep">(Antulov-Fantulin et al<span class="ltx_text">.</span>, <a href="#bib.bib2" title="" class="ltx_ref">2014</a>; Slokom, <a href="#bib.bib22" title="" class="ltx_ref">2018</a>; Slokom
et al<span class="ltx_text">.</span>, <a href="#bib.bib23" title="" class="ltx_ref">2020a</a>)</cite> being notable exceptions.
These techniques have the potential to address problems such as the lack of publicly available large datasets for research outside of industry.
This problem is motivated by companies’ concerns about user privacy, and the possibility of revealing strategic internal KPIs, such as the level of user engagement and their recurrence in the service, or the growth of the company’s item catalog over time.
Synthetic data, when representative of real data, can enable researchers to benchmark, evaluate their methods on datasets of the scale and complexity used in commercial applications.
The question remains however, to what extent can simulated data effectively balance the trade-off between being close enough to the real data to act as an effective surrogate, while not being close enough to the real data to leak sensitive personal information.
Simulators can potentially generate an infinite amount of synthetic data at very little cost. They bring opportunities for design decisions on recommender systems and algorithms. An algorithm designer could simulate different patterns of user behaviour to evaluate and compare recommendation algorithms, or could emulate the feedback look between users and recommendations.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">The complexity of simulators proposed for recommendation systems varies from simple to complex, depending on its purpose, whether for algorithm comparison, framework development, or simulating the feedback loop between recommendations and user interactions.
We explore and motivate these uses, and highlight exciting future directions, in this work.</p>
</div>
<section id="S1.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.1. </span>Past Successes of Synthetic Data and Simulators</h3>

<div id="S1.SS1.p1" class="ltx_para">
<p id="S1.SS1.p1.1" class="ltx_p">Domains such as computer vision outside of recommendation systems have benefited markedly from applying machine learning on synthetic or simulated data <cite class="ltx_cite ltx_citemacro_citep">(Sankaranarayanan et al<span class="ltx_text">.</span>, <a href="#bib.bib18" title="" class="ltx_ref">2018</a>)</cite><cite class="ltx_cite ltx_citemacro_citep">(Prakash et al<span class="ltx_text">.</span>, <a href="#bib.bib15" title="" class="ltx_ref">2019</a>)</cite>.
Synthetic data in computer visions tasks such as object detection and segmentation has proven to be an effective strategy to increase model validation set performance<cite class="ltx_cite ltx_citemacro_citep">(Tobin
et al<span class="ltx_text">.</span>, <a href="#bib.bib25" title="" class="ltx_ref">2018</a>)</cite>, and in particular, domain randomization has been surprisingly effective<cite class="ltx_cite ltx_citemacro_citep">(Tremblay
et al<span class="ltx_text">.</span>, <a href="#bib.bib26" title="" class="ltx_ref">2018</a>)</cite>.</p>
</div>
<div id="S1.SS1.p2" class="ltx_para">
<p id="S1.SS1.p2.1" class="ltx_p">Domain randomization is a technique where simulator parameters are sampled from values which are known to be unrealistic. For example training with domain randomization in a physical simulator would include training with uncommon or extreme values for friction, gravity, and object density. This approach might <em id="S1.SS1.p2.1.1" class="ltx_emph ltx_font_italic">a priori</em> seem detrimental to final model performance by unduly focusing model performance on cases not expected to be encountered in the intended application. Nonetheless this approach of domain randomization has been shown to be effective<cite class="ltx_cite ltx_citemacro_citep">(Tobin
et al<span class="ltx_text">.</span>, <a href="#bib.bib25" title="" class="ltx_ref">2018</a>)</cite> <cite class="ltx_cite ltx_citemacro_citep">(Tremblay
et al<span class="ltx_text">.</span>, <a href="#bib.bib26" title="" class="ltx_ref">2018</a>)</cite>.
One explanation for the effectiveness of this technique is that the benefit from a large increase of training diversity outweighs any negative effects from data-distribution shifts towards physically unrealistic scenarios, while another explanation is that the training curriculum is purposefully made more difficult than the intended application, so that the intended application is an easier, more simpler sub-problem than that encountered during the totality of training. In recommendation systems, domain randomization might include setting simulator parameters for users that are known to be unrealistic, such as browsing time, budgets, or spending habits, in order to increase training diversity, so long as validation set performance is improved.
We believe this past success is a cause of optimism for the use of simulators and synthetic data in recommendation systems.</p>
</div>
</section>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Fidelity versus Privacy Trade-off</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1. </span>Fidelity</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Synthetic data should share some statistical properties of real data.
There have been a number of past approaches to capture real data fidelity in synthetic data. For instance <cite class="ltx_cite ltx_citemacro_citep">(Antulov-Fantulin et al<span class="ltx_text">.</span>, <a href="#bib.bib2" title="" class="ltx_ref">2014</a>)</cite> build synthetic clickstreams through graph walks that explicitly remain faithful to transition probabilities between items and co-occurrence probabilities of items appearing in the same clickstream. The authors measure synthetic dataset fidelity by performance on downstream tasks, such as training recommendation systems on their synthetic data and analyzing the performance of these trained models.
Past work <cite class="ltx_cite ltx_citemacro_citep">(Belletti et al<span class="ltx_text">.</span>, <a href="#bib.bib3" title="" class="ltx_ref">2019</a>)</cite> evaluate their data-generation method on MovieLens 20M by comparing the item-wise and user-wise rating sums, as well as the singular values, of their generated data matrix versus the real data matrix, in addition to baselines such as histograms of movie ratings between real and generated data.
Past work <cite class="ltx_cite ltx_citemacro_citep">(Lin
et al<span class="ltx_text">.</span>, <a href="#bib.bib12" title="" class="ltx_ref">2020</a>)</cite> evaluates dataset fidelity of generated time-series data by auto correlation metrics, distribution of generated labels and categorical event types, as well as the prediction of baseline recommendation system algorithm rankings by training and testing on synthetic data.
In general it is important that features have similar distributions, but this requirement is sensitive to the intended usage of synthetic data.
When synthetic data is used to test recommender systems framework and tools based on neural networks, the cardinality and frequency distribution of categorical features is especially important, as they are represented by embeddings in the model. High-cardinality categorical features result in very large embedding tables that may exceed the capacity of a single GPU memory. That poses engineering challenges, like distributing those huge embedding tables to multi-GPU <cite class="ltx_cite ltx_citemacro_citep">(Gupta
et al<span class="ltx_text">.</span>, <a href="#bib.bib9" title="" class="ltx_ref">2020</a>)</cite> and minimizing the inter-communication between GPUs by caching the embeddings of popular categorical values <cite class="ltx_cite ltx_citemacro_citep">(Guo
et al<span class="ltx_text">.</span>, <a href="#bib.bib8" title="" class="ltx_ref">2021</a>)</cite>, issues addressed by the HugeCTR framework<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>https://github.com/NVIDIA/HugeCTR</span></span></span> for example.
On the other hand, these requirements are much more strict for the purpose of comparing different algorithms, as they in general learn patterns from the conditional dependency among the features and the prediction target. Hence ignoring these conditional probabilities between features would be far from a realistic scenario. We discuss this requirement more in Section <a href="#S3" title="3. Predicting Algorithm Rankings ‣ Synthetic Data and Simulators for Recommendation Systems: Current State and Future Directions" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> below.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2. </span>Privacy</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">Another research direction of synthetic data generation focuses on using statistical disclosure control techniques to transform original data by hiding specific information. The scale of the resulting data remains the same, but personalized information about user’s preferences is masked to protect his privacy.
These past works can be classified into two categories: attack modelling <cite class="ltx_cite ltx_citemacro_citep">(Burke
et al<span class="ltx_text">.</span>, <a href="#bib.bib5" title="" class="ltx_ref">2004</a>; Rezaimehr and
Dadkhah, <a href="#bib.bib16" title="" class="ltx_ref">2021</a>)</cite> and differential privacy <cite class="ltx_cite ltx_citemacro_citep">(McSherry and
Mironov, <a href="#bib.bib13" title="" class="ltx_ref">2009</a>; Berlioz et al<span class="ltx_text">.</span>, <a href="#bib.bib4" title="" class="ltx_ref">2015</a>)</cite>.
Attack modelling aims to identify all types of threats, which can take at least three forms: identity disclosure, attribute disclosure and inferential disclosure. Once one or multiple of these threats are identified, synthesized data is generated to prevent attacks. The main limitation of such methods is the requirement of identifying beforehand the attacker’s capabilities and goals, a requirement which is very challenging in practice. In RecSys, previous studies have focused on the classification of recommender attack models <cite class="ltx_cite ltx_citemacro_citep">(Burke
et al<span class="ltx_text">.</span>, <a href="#bib.bib5" title="" class="ltx_ref">2004</a>)</cite> and designed simple proof-of-concept models <cite class="ltx_cite ltx_citemacro_citep">(Slokom
et al<span class="ltx_text">.</span>, <a href="#bib.bib24" title="" class="ltx_ref">2020b</a>)</cite> to evaluate if the relative performance of algorithms when trained and tested on the synthesized data matches with the relative performance of algorithms trained and tested on the original data.
By contrast differential privacy aims to prevent attackers from gaining information about their targets, even if the attacker has knowledge about the dataset. One approach towards differential privacy consists of injecting probabilistic noise in the original data while maintaining the same probability distributions. In RecSys differential privacy has been applied to matrix factorization (MF) at different levels of modelling: input perturbation of user-item matrces, private MF optimizers via gradient descent or alternating least squares solvers, and output perturbation. Previous work <cite class="ltx_cite ltx_citemacro_citep">(Berlioz et al<span class="ltx_text">.</span>, <a href="#bib.bib4" title="" class="ltx_ref">2015</a>)</cite> conducts experiments to evaluate the trade-off between the noise perturbation approaches and MF algorithm accuracy and demonstrated that input perturbation ensures the highest performance. However the authors point out that high degree of noise motivated by ensuring high-level privacy directly impacts the relative ranking of models’ performances. Most recent works are extending differential privacy methods to complex deep recommender systems such as wide and deep architectures <cite class="ltx_cite ltx_citemacro_citep">(Zhang
et al<span class="ltx_text">.</span>, <a href="#bib.bib31" title="" class="ltx_ref">2021</a>)</cite> and collaborative bandits learning <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a href="#bib.bib27" title="" class="ltx_ref">2020</a>)</cite>.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Predicting Algorithm Rankings</h2>

<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1. </span>Motivations</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">There are very few publicly available high-quality datasets, in terms of size and diversity of available features, likely due to companies concerns on having user privacy or public data that can leak internal company metrics. This scenario limits the research advances in the RecSys field, as scientists outside popular online service companies cannot assess and compare their proposed algorithms on large datasets.
Synthetic generation can be an approach for companies to release data which is similar to its large real data but does not leak this sensitive information, so that third-party researchers can evaluate their proposed algorithms.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2. </span>Successes and Limitations</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">Past works have shown that one can successfully predict what model performance ranking on datasets are, given model performance rankings on simulated and synthetic datasets. For instance <cite class="ltx_cite ltx_citemacro_citep">(Lin
et al<span class="ltx_text">.</span>, <a href="#bib.bib12" title="" class="ltx_ref">2020</a>)</cite> show a successful prediction of the relative performance rankings of various recommendation systems algorithms trained and tested on real data, obtained by training and testing on synthetic data. Here the algorithm ranking of the authors’ proposed GAN-based data-generation method on two different datasets is perfectly aligned, with a correlation ranking of 1.00, with the actual performance among five other algorithms trained and tested on real data. Similarly <cite class="ltx_cite ltx_citemacro_citep">(Slokom, <a href="#bib.bib22" title="" class="ltx_ref">2018</a>)</cite> provides successful results on the prediction of real algorithm rank orderings from synthetic algorithm rank orderings among three other recommendation system algorithms trained and tested on real data.
On the other hand, <cite class="ltx_cite ltx_citemacro_citep">(Antulov-Fantulin et al<span class="ltx_text">.</span>, <a href="#bib.bib2" title="" class="ltx_ref">2014</a>)</cite> provide inconclusive or contradictory evidence that algorithm rank orderings may be successfully predicted for click-stream algorithms, at least for the probabilistic graph walk dataset generation method that the authors propose in this past work.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>Future Directions for Simulators and Simulated Data</h2>

<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1. </span>Data Augmentation, Mixing Synthetic and Real Data for Recommendation Systems</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">Data augmentation techniques have been shown to outperform purely synthetic or purely real data in machine learning.
In computer vision, techniques like random cropping, image mirroring, and color shifting have helped models to generalize better and to achieve improved accuracy<cite class="ltx_cite ltx_citemacro_citep">(Shorten and
Khoshgoftaar, <a href="#bib.bib21" title="" class="ltx_ref">2019</a>)</cite>.
Similar strategies have been proposed for raw signals and audio spectograms, such as perturbation and noise injection <cite class="ltx_cite ltx_citemacro_citep">(Ko
et al<span class="ltx_text">.</span>, <a href="#bib.bib11" title="" class="ltx_ref">2015</a>; Park et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2019</a>)</cite>, as well as in in NLP <cite class="ltx_cite ltx_citemacro_citep">(Wei and Zou, <a href="#bib.bib29" title="" class="ltx_ref">2019</a>)</cite>.
However augmentation techniques for recommender systems have been largely unexplored, with <cite class="ltx_cite ltx_citemacro_citep">(Grbovic et al<span class="ltx_text">.</span>, <a href="#bib.bib7" title="" class="ltx_ref">2015</a>; Wang
et al<span class="ltx_text">.</span>, <a href="#bib.bib28" title="" class="ltx_ref">2019</a>; Wölbitsch et al<span class="ltx_text">.</span>, <a href="#bib.bib30" title="" class="ltx_ref">2019</a>)</cite> being some notable exceptions.
We believe mixing synthetic and real data can be a promising direction for domains or recommender systems deployments, especially early stages of data collection and small dataset size scenarios.
For research scientists outside large online services companies, it would be very helpful for synthetic data generation to augment real small data, allowing an accurate emulation of algorithm behavior on datasets larger than currently available.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2. </span>Feedback in Dataset Generation</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">In production recommendation systems, there is often a back-and-forth process between dataset generation and model training<cite class="ltx_cite ltx_citemacro_citep">(Settles, <a href="#bib.bib20" title="" class="ltx_ref">2009</a>)</cite>. In particular a model is likely to be trained on data that a previous model iteration solicited by providing some action that the model selected, like recommending a particular item to a user. This feedback cycle may be positive for performance, in selecting data that future iterations of model training find useful for increasing performance, or this feedback cycle may be pernicious, in either halting or reversing model performance<cite class="ltx_cite ltx_citemacro_citep">(Schmit and
Riquelme, <a href="#bib.bib19" title="" class="ltx_ref">2018</a>)</cite>. This latter phenomenon may occur by selecting data points which are repetitions in the existing dataset, or more broadly, by focusing on short-term utility rather than promoting dataset coverage or diversity<cite class="ltx_cite ltx_citemacro_citep">(Chaney
et al<span class="ltx_text">.</span>, <a href="#bib.bib6" title="" class="ltx_ref">2018</a>)</cite>. One concrete example of this latter phenomenon is when a recommendation system recommends a small number of highly popular items, and hence fails to build diverse datasets for future model training iterations. We believe that this back-and-forth process that occurs in commercial applications of recommendation systems, but typically does not in the academic or open-source study of recommendation systems, should be more placed at a higher priority for future recommendation systems research.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3. </span>Robust Simulations</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">Generating high-fidelity synthetic data from real data may not be fully feasible, due partly to biases introduced in the real data by the policies under which the data was collected, and partly due to our imprecise understanding of what dataset properties state-of-the-art models model.
We believe that robust simulators are a promising approach for these concerns.
For exploring what patterns models are capable of capturing, one can generate synthetic data with known, but not necessarily realistic, properties, towards understanding how the feedback loop between users and algorithms would evolve over time, and which recommendation algorithms would perform better in such scenarios.
Most public datasets do not include the information necessary to tell apart the actual preferences of the user base and the biasing effects of what the recommender presented to users, which makes unbiased evaluation of new models difficult.
By evaluating on MovieLens and other public datasets, RecSys as a field has overfit to whatever policy was used during data collection for the MovieLens and other canonical RecSys datasets.
In the robust simulators that we envision, we can make explicit assumptions about what the distribution of true preferences in the user population are, select a particular known logging policies, and generate a set of observations with known properties.
Simulation allows system administrators to model recommender system dynamics over time.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.1" class="ltx_p">Simulators can be used to test how generalizable are the proposed recommendation algorithms with respect to edge cases not frequent in real datasets.
Simulator interpretability allows us to better understand the effect of model parameters we want to test.
One can choose a distribution of true user interests and an observation sampling policy such that we end up with a dataset that has comparable statistics to MovieLens for example, then expand the simulated data to whatever large size is desired.
We do not think RecSys has yet achieved this vision for robust simulators, but simulation frameworks such as RecoGym<cite class="ltx_cite ltx_citemacro_citep">(Rohde et al<span class="ltx_text">.</span>, <a href="#bib.bib17" title="" class="ltx_ref">2018</a>)</cite> and RecSim<cite class="ltx_cite ltx_citemacro_citep">(Ie et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2019</a>)</cite> are promising approaches for this vision.</p>
</div>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4. </span>Privacy-Preserving Methods</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p">Motivated by preserving users sensitive data and global statistics related to business KPIs, large companies have not shared large-scale datasets with external communities.
Privacy-preserving methods discussed in section <a href="#S2.SS2" title="2.2. Privacy ‣ 2. Fidelity versus Privacy Trade-off ‣ Synthetic Data and Simulators for Recommendation Systems: Current State and Future Directions" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.2</span></a> constitute a promise for guaranteeing privacy while releasing large scale datasets for research development.
However it is still unclear how these noisy aggregated data impact learning effective recommender system models that maintain the relative ranking of different approaches for performance comparison and model selection.
A recent Criteo challenge organized in collaboration with the CAP21’<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>https://medium.com/criteo-engineering/criteo-cap21-privacy-preserving-ai-challenge-9cf9cd880e54</span></span></span> conference aims to benchmark models defined using private constrained training data to explore the trade-off between privacy level and prediction performance.
In particular individual data is transformed through an embedded, anonymized, and compact representation.
Then machine learning models are trained and tested on two objectives: the privacy attacks protection and the outcome prediction task.
If such privacy functions are demonstrated to lead to high performance machine learning models, large companies may generate large anonymized synthetic data using a given privacy function, and more openly share it with the RecSys community.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this paper, we motivate and state the uses of synthetic data and simulators for recommendation systems. The success of these approaches in other machine learning fields provides promise for these methods. For approaches that use real data, we identify a key trade-off between data fidelity and privacy. The important use case of predicting algorithm rankings using synthetic data is well-motivated, and has had both successes and limitations. Finally there are a number of exciting and promising future directions we believe the field should invest in, including data augmentation that mixes real and synthetic data, feedback in dataset generation in production systems, robust simulators, and privacy-preserving methods.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">        




</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Antulov-Fantulin et al<span id="bib.bib2.2.2.1" class="ltx_text">.</span> (2014)</span>
<span class="ltx_bibblock">
Nino Antulov-Fantulin,
Matko Bošnjak, Vinko Zlatić,
Miha Grčar, and Tomislav
Šmuc. 2014.

</span>
<span class="ltx_bibblock">Synthetic Sequence Generator for Recommender
Systems–Memory Biased Random Walk on a Sequence Multilayer Network. In
<em id="bib.bib2.3.1" class="ltx_emph ltx_font_italic">International Conference on Discovery Science</em>.
Springer, 25–36.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Belletti et al<span id="bib.bib3.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Francois Belletti, Karthik
Lakshmanan, Walid Krichene, Yi-Fan Chen,
and John Anderson. 2019.

</span>
<span class="ltx_bibblock">Scalable realistic recommendation datasets through
fractal expansions.

</span>
<span class="ltx_bibblock"><em id="bib.bib3.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1901.08910</em>
(2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Berlioz et al<span id="bib.bib4.2.2.1" class="ltx_text">.</span> (2015)</span>
<span class="ltx_bibblock">
Arnaud Berlioz, Arik
Friedman, Mohamed Ali Kaafar, Roksana
Boreli, and Shlomo Berkovsky.
2015.

</span>
<span class="ltx_bibblock">Applying Differential Privacy to Matrix
Factorization <em id="bib.bib4.3.1" class="ltx_emph ltx_font_italic">(RecSys ’15)</em>.
Association for Computing Machinery,
New York, NY, USA.

</span>
<span class="ltx_bibblock">

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Burke
et al<span id="bib.bib5.2.2.1" class="ltx_text">.</span> (2004)</span>
<span class="ltx_bibblock">
R. Burke, B. Mobasher,
Roman Zabicki, and Runa Bhaumik.
2004.

</span>
<span class="ltx_bibblock">Identifying Attack Models for Secure
Recommendation.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chaney
et al<span id="bib.bib6.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Allison JB Chaney,
Brandon M Stewart, and Barbara E
Engelhardt. 2018.

</span>
<span class="ltx_bibblock">How algorithmic confounding in recommendation
systems increases homogeneity and decreases utility. In
<em id="bib.bib6.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 12th ACM Conference on
Recommender Systems</em>. 224–232.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Grbovic et al<span id="bib.bib7.2.2.1" class="ltx_text">.</span> (2015)</span>
<span class="ltx_bibblock">
Mihajlo Grbovic, Vladan
Radosavljevic, Nemanja Djuric, Narayan
Bhamidipati, Jaikit Savla, Varun
Bhagwan, and Doug Sharp.
2015.

</span>
<span class="ltx_bibblock">E-commerce in your inbox: Product recommendations
at scale. In <em id="bib.bib7.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 21th ACM SIGKDD
international conference on knowledge discovery and data mining</em>.
1809–1818.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guo
et al<span id="bib.bib8.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Huifeng Guo, Wei Guo,
Yong Gao, Ruiming Tang,
Xiuqiang He, and Wenzhi Liu.
2021.

</span>
<span class="ltx_bibblock">ScaleFreeCTR: MixCache-based Distributed Training
System for CTR Models with Huge Embedding Table.

</span>
<span class="ltx_bibblock"><em id="bib.bib8.3.1" class="ltx_emph ltx_font_italic">Proceedings of SIGIR’21</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gupta
et al<span id="bib.bib9.3.3.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Udit Gupta, Carole-Jean
Wu, Xiaodong Wang, Maxim Naumov,
Brandon Reagen, David Brooks,
Bradford Cottel, Kim Hazelwood,
Mark Hempstead, Bill Jia,
et al<span id="bib.bib9.4.1" class="ltx_text">.</span> 2020.

</span>
<span class="ltx_bibblock">The architectural implications of facebook’s
dnn-based personalized recommendation. In <em id="bib.bib9.5.1" class="ltx_emph ltx_font_italic">2020
IEEE International Symposium on High Performance Computer Architecture
(HPCA)</em>. IEEE, 488–501.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ie et al<span id="bib.bib10.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Eugene Ie, Chih-wei Hsu,
Martin Mladenov, Vihan Jain,
Sanmit Narvekar, Jing Wang,
Rui Wu, and Craig Boutilier.
2019.

</span>
<span class="ltx_bibblock">Recsim: A configurable simulation platform for
recommender systems.

</span>
<span class="ltx_bibblock"><em id="bib.bib10.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1909.04847</em>
(2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ko
et al<span id="bib.bib11.2.2.1" class="ltx_text">.</span> (2015)</span>
<span class="ltx_bibblock">
Tom Ko, Vijayaditya
Peddinti, Daniel Povey, and Sanjeev
Khudanpur. 2015.

</span>
<span class="ltx_bibblock">Audio augmentation for speech recognition. In
<em id="bib.bib11.3.1" class="ltx_emph ltx_font_italic">Sixteenth annual conference of the international
speech communication association</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin
et al<span id="bib.bib12.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Zinan Lin, Alankar Jain,
Chen Wang, Giulia Fanti, and
Vyas Sekar. 2020.

</span>
<span class="ltx_bibblock">Using GANs for Sharing Networked Time Series Data:
Challenges, Initial Promise, and Open Questions. In
<em id="bib.bib12.3.1" class="ltx_emph ltx_font_italic">Proceedings of the ACM Internet Measurement
Conference</em> (Virtual Event, USA) <em id="bib.bib12.4.2" class="ltx_emph ltx_font_italic">(IMC ’20)</em>.
Association for Computing Machinery,
New York, NY, USA, 464–483.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3419394.3423643" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3419394.3423643</a>

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McSherry and
Mironov (2009)</span>
<span class="ltx_bibblock">
Frank McSherry and Ilya
Mironov. 2009.

</span>
<span class="ltx_bibblock">Differentially Private Recommender Systems:
Building Privacy into the Netflix Prize Contenders
<em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">(KDD ’09)</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Park et al<span id="bib.bib14.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Daniel S Park, William
Chan, Yu Zhang, Chung-Cheng Chiu,
Barret Zoph, Ekin D Cubuk, and
Quoc V Le. 2019.

</span>
<span class="ltx_bibblock">Specaugment: A simple data augmentation method for
automatic speech recognition.

</span>
<span class="ltx_bibblock"><em id="bib.bib14.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1904.08779</em>
(2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Prakash et al<span id="bib.bib15.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Aayush Prakash, Shaad
Boochoon, Mark Brophy, David Acuna,
Eric Cameracci, Gavriel State,
Omer Shapira, and Stan Birchfield.
2019.

</span>
<span class="ltx_bibblock">Structured domain randomization: Bridging the
reality gap by context-aware synthetic data. In
<em id="bib.bib15.3.1" class="ltx_emph ltx_font_italic">2019 International Conference on Robotics and
Automation (ICRA)</em>. IEEE, 7249–7255.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rezaimehr and
Dadkhah (2021)</span>
<span class="ltx_bibblock">
Fatemeh Rezaimehr and
Chitra Dadkhah. 2021.

</span>
<span class="ltx_bibblock">A survey of attack detection approaches in
collaborative filtering recommender systems.

</span>
<span class="ltx_bibblock"><em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">Artificial Intelligence Review</em>
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rohde et al<span id="bib.bib17.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
David Rohde, Stephen
Bonner, Travis Dunlop, Flavian Vasile,
and Alexandros Karatzoglou.
2018.

</span>
<span class="ltx_bibblock">Recogym: A reinforcement learning environment for
the problem of product recommendation in online advertising.

</span>
<span class="ltx_bibblock"><em id="bib.bib17.3.1" class="ltx_emph ltx_font_italic">Proceedings of the REVEAL workshop at the
Twelfth ACM Conference on Recommender Systems (RecSys ’18)</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sankaranarayanan et al<span id="bib.bib18.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Swami Sankaranarayanan,
Yogesh Balaji, Arpit Jain,
Ser Nam Lim, and Rama Chellappa.
2018.

</span>
<span class="ltx_bibblock">Learning from synthetic data: Addressing domain
shift for semantic segmentation. In <em id="bib.bib18.3.1" class="ltx_emph ltx_font_italic">Proceedings of
the IEEE Conference on Computer Vision and Pattern Recognition</em>.
3752–3761.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schmit and
Riquelme (2018)</span>
<span class="ltx_bibblock">
Sven Schmit and Carlos
Riquelme. 2018.

</span>
<span class="ltx_bibblock">Human interaction with recommendation systems. In
<em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">International Conference on Artificial Intelligence
and Statistics</em>. PMLR, 862–870.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Settles (2009)</span>
<span class="ltx_bibblock">
Burr Settles.
2009.

</span>
<span class="ltx_bibblock">Active learning literature survey.

</span>
<span class="ltx_bibblock">(2009).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shorten and
Khoshgoftaar (2019)</span>
<span class="ltx_bibblock">
Connor Shorten and
Taghi M Khoshgoftaar. 2019.

</span>
<span class="ltx_bibblock">A survey on image data augmentation for deep
learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Journal of Big Data</em> 6,
1 (2019), 1–48.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Slokom (2018)</span>
<span class="ltx_bibblock">
Manel Slokom.
2018.

</span>
<span class="ltx_bibblock">Comparing recommender systems using synthetic
data. In <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 12th ACM Conference on
Recommender Systems</em>. 548–552.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Slokom
et al<span id="bib.bib23.2.2.1" class="ltx_text">.</span> (2020a)</span>
<span class="ltx_bibblock">
Manel Slokom, Martha
Larson, and Alan Hanjalic.
2020a.

</span>
<span class="ltx_bibblock">Partially Synthetic Data for Recommender Systems:
Prediction Performance and Preference Hiding.

</span>
<span class="ltx_bibblock"><em id="bib.bib23.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2008.03797</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Slokom
et al<span id="bib.bib24.2.2.1" class="ltx_text">.</span> (2020b)</span>
<span class="ltx_bibblock">
Manel Slokom, Martha A.
Larson, and Alan Hanjalic.
2020b.

</span>
<span class="ltx_bibblock">Partially Synthetic Data for Recommender Systems:
Prediction Performance and Preference Hiding.

</span>
<span class="ltx_bibblock"><em id="bib.bib24.3.1" class="ltx_emph ltx_font_italic">CoRR</em> abs/2008.03797
(2020).

</span>
<span class="ltx_bibblock">arXiv:2008.03797

<a target="_blank" href="https://arxiv.org/abs/2008.03797" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2008.03797</a>

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tobin
et al<span id="bib.bib25.3.3.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Josh Tobin, Lukas
Biewald, Rocky Duan, Marcin
Andrychowicz, Ankur Handa, Vikash Kumar,
Bob McGrew, Alex Ray,
Jonas Schneider, Peter Welinder,
et al<span id="bib.bib25.4.1" class="ltx_text">.</span> 2018.

</span>
<span class="ltx_bibblock">Domain randomization and generative models for
robotic grasping. In <em id="bib.bib25.5.1" class="ltx_emph ltx_font_italic">2018 IEEE/RSJ International
Conference on Intelligent Robots and Systems (IROS)</em>. IEEE,
3482–3489.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tremblay
et al<span id="bib.bib26.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Jonathan Tremblay, Aayush
Prakash, David Acuna, Mark Brophy,
Varun Jampani, Cem Anil,
Thang To, Eric Cameracci,
Shaad Boochoon, and Stan Birchfield.
2018.

</span>
<span class="ltx_bibblock">Training deep networks with synthetic data:
Bridging the reality gap by domain randomization. In
<em id="bib.bib26.3.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE conference on computer
vision and pattern recognition workshops</em>. 969–977.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span id="bib.bib27.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Huazheng Wang, Qian Zhao,
Qingyun Wu, Shubham Chopra,
Abhinav Khaitan, and Hongning Wang.
2020.

</span>
<span class="ltx_bibblock">Global and Local Differential Privacy for
Collaborative Bandits. In <em id="bib.bib27.3.1" class="ltx_emph ltx_font_italic">Fourteenth ACM
Conference on Recommender Systems</em> <em id="bib.bib27.4.2" class="ltx_emph ltx_font_italic">(RecSys ’20)</em>.
Association for Computing Machinery,
New York, NY, USA.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3383313.3412254" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3383313.3412254</a>

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang
et al<span id="bib.bib28.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Qinyong Wang, Hongzhi
Yin, Hao Wang, Quoc Viet Hung Nguyen,
Zi Huang, and Lizhen Cui.
2019.

</span>
<span class="ltx_bibblock">Enhancing collaborative filtering with generative
augmentation. In <em id="bib.bib28.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 25th ACM
SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</em>.
548–556.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei and Zou (2019)</span>
<span class="ltx_bibblock">
Jason Wei and Kai Zou.
2019.

</span>
<span class="ltx_bibblock">Eda: Easy data augmentation techniques for boosting
performance on text classification tasks.

</span>
<span class="ltx_bibblock"><em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1901.11196</em>
(2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wölbitsch et al<span id="bib.bib30.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Matthias Wölbitsch,
Simon Walk, Michael Goller, and
Denis Helic. 2019.

</span>
<span class="ltx_bibblock">Beggars can’t be choosers: Augmenting sparse data
for embedding-based product recommendations in retail stores. In
<em id="bib.bib30.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 27th ACM Conference on User
Modeling, Adaptation and Personalization</em>. 104–112.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang
et al<span id="bib.bib31.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Huanyu Zhang, Ilya
Mironov, and Meisam Hejazinia.
2021.

</span>
<span class="ltx_bibblock">Wide Network Learning with Differential Privacy.

</span>
<span class="ltx_bibblock"><em id="bib.bib31.3.1" class="ltx_emph ltx_font_italic">CoRR</em> abs/2103.01294
(2021).

</span>
<span class="ltx_bibblock">arXiv:2103.01294

<a target="_blank" href="https://arxiv.org/abs/2103.01294" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2103.01294</a>

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2112.11021" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2112.11022" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2112.11022">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2112.11022" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2112.11023" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Mar  1 15:47:46 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
