<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2403.12895] mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding</title><meta property="og:description" content="Structure information is critical for understanding the semantics of text-rich images, such as documents, tables, and charts. Existing Multimodal Large Language Models (MLLMs) for Visual Document Understanding are equi…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2403.12895">

<!--Generated on Fri Apr  5 13:54:48 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Anwen Hu<sup id="id2.2.id1" class="ltx_sup">1</sup>, Haiyang Xu<sup id="id3.3.id2" class="ltx_sup">1</sup>, Jiabo Ye <sup id="id4.4.id3" class="ltx_sup">1</sup>, Ming Yan<sup id="id5.5.id4" class="ltx_sup">1</sup><sup id="id6.6.id5" class="ltx_sup">∗</sup> 
<br class="ltx_break"><span id="id7.7.id6" class="ltx_text ltx_font_bold">Liang Zhang<sup id="id7.7.id6.1" class="ltx_sup">2</sup>, Bo Zhang<sup id="id7.7.id6.2" class="ltx_sup">1</sup>, Chen Li<sup id="id7.7.id6.3" class="ltx_sup">1</sup>, Ji Zhang<sup id="id7.7.id6.4" class="ltx_sup">1</sup>, Qin Jin<sup id="id7.7.id6.5" class="ltx_sup">2</sup>, Fei Huang<sup id="id7.7.id6.6" class="ltx_sup">1</sup>, Jingren Zhou<sup id="id7.7.id6.7" class="ltx_sup">1</sup></span> 
<br class="ltx_break"><sup id="id8.8.id7" class="ltx_sup">1</sup>Alibaba Group 
<br class="ltx_break"><sup id="id9.9.id8" class="ltx_sup">2</sup>Renmin University of China 
<br class="ltx_break"><span id="id10.10.id9" class="ltx_text ltx_font_typewriter">{huanwen.haw,shuofeng.xhy,ym119608}@alibaba-inc.com</span>
</span><span class="ltx_author_notes">Corresponding authors</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id11.id1" class="ltx_p">Structure information is critical for understanding the semantics of text-rich images, such as documents, tables, and charts. Existing Multimodal Large Language Models (MLLMs) for Visual Document Understanding are equipped with text recognition ability but lack general structure understanding abilities for text-rich document images. In this work, we emphasize the importance of structure information in Visual Document Understanding and propose the Unified Structure Learning to boost the performance of MLLMs. Our Unified Structure Learning comprises structure-aware parsing tasks and multi-grained text localization tasks across 5 domains: document, webpage, table, chart, and natural image. To better encode structure information, we design a simple and effective vision-to-text module H-Reducer, which can not only maintain the layout information but also reduce the length of visual features by merging horizontal adjacent patches through convolution, enabling the LLM to understand high-resolution images more efficiently.
Furthermore, by constructing structure-aware text sequences and multi-grained pairs of texts and bounding boxes for publicly available text-rich images, we build a comprehensive training set DocStruct4M to support structure learning. Finally, we construct a small but high-quality reasoning tuning dataset DocReason25K to trigger the detailed explanation ability in the document domain. Our model DocOwl 1.5 achieves state-of-the-art performance on 10 visual document understanding benchmarks, improving the SOTA performance of MLLMs with a 7B LLM by more than 10 points in 5/10 benchmarks. Our codes, models, and datasets are publicly available at <a target="_blank" href="https://github.com/X-PLUG/mPLUG-DocOwl/tree/main/DocOwl1.5" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/X-PLUG/mPLUG-DocOwl/tree/main/DocOwl1.5</a>.</p>
</div>
<figure id="S0.F1" class="ltx_figure"><img src="/html/2403.12895/assets/x1.png" id="S0.F1.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="322" height="223" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Compared with similar-size generalists, our DocOwl 1.5 achieves state-of-the-art OCR-free performance on 10 Visual Document Understanding benchmarks.</figcaption>
</figure>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Leveraging the strong language understanding and generation ability of Large Language Models (LLM) <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib46" title="" class="ltx_ref">46</a>, <a href="#bib.bib48" title="" class="ltx_ref">48</a>, <a href="#bib.bib62" title="" class="ltx_ref">62</a>]</cite>, some recent works <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>, <a href="#bib.bib58" title="" class="ltx_ref">58</a>, <a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib64" title="" class="ltx_ref">64</a>, <a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite> have developed Multimodal Large Language Models (MLLMs) for general vision-and-language understanding. By aligning a pre-trained visual encoder (e.g. the ViT/L-14 <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> from CLIP <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>) and the LLM with a Vision-to-Text (V2T) module, these models present promising performance on understanding general images. However, they still face great challenges with images with rich text information, such as documents, webpages, tables, and charts <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>. This is mainly because the visual encoder and V2T module are trained on general image-text pairs and not specifically optimized to represent the textual and structural information in text-rich images.</p>
</div>
<figure id="S1.F2" class="ltx_figure"><img src="/html/2403.12895/assets/x2.png" id="S1.F2.g1" class="ltx_graphics ltx_centering ltx_img_square" width="461" height="409" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Illustrations of the importance of structure information in Visual Document Understanding on documents (a), tables (b), webpages (c), infographics (d), and charts (e-f).</figcaption>
</figure>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Textual information in images manifests with a multitude of visual structures, spanning the simplicity of plain text to the systematic grid layouts of tables and incorporating a spectrum of graphical representations such as pie, line, and bar charts. These elements may appear in isolation or be intricately interwoven within the framework of documents and webpages, reflecting a rich diversity of informational architecture across posters, invoices, infographics, scientific reports, academic and news websites, etc. As shown in <a href="#S1.F2" title="In 1 Introduction ‣ mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">2</span></a>, besides the basic textual content, structure information also plays a big role in Visual Document Understanding <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib45" title="" class="ltx_ref">45</a>, <a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>. With basic abilities to understand general images and comprehend structured texts through the LLM decoder, MLLM has the potential to achieve unified structure learning on text-rich images.
For better Visual Document Understanding with MLLMs, some works <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>, <a href="#bib.bib56" title="" class="ltx_ref">56</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> attempt to design text-reading tasks to strengthen the text recognition ability, but either ignore the structure comprehension or only cover limited domains of text-rich images, such as just webpages <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> or documents <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. In this work, we first propose to perform unified structure learning on text-rich images for MLLMs across 5 domains: document, webpage, table, chart, and natural image.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">For better structural understanding, we first design a simple and effective vision-to-text module, namely H-Reducer. Unlike the Resampler <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> or Q-former <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite> which fuses visual features with learnable queries but affects spatial information, the H-Reducer accumulates neighborhood visual features through convolution to keep the relative positional relationships.
Compared with V2T modules with only linear layers <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>, it produces much fewer visual features, which is more efficient for LLM to understand high-resolution document images. Considering texts in document images are most organized from left to right, H-Reducer merges visual features at the horizontal level. Our Unified Structure Learning comprises structure-aware parsing tasks and multi-grained text localization tasks. To learn the organization of text contents, the former mainly teaches the model to parse the texts in the image in a structure-aware style, such as using line feeds and spaces to represent the structure of documents or webpages, and using extended Markdown syntax to represent the structure of tables and charts. Multi-grained text localization tasks further enhance the ability to correlate visually situated texts and concrete positions in the image. To support unified structure learning, based on publicly available datasets, we carefully build a comprehensive training set DocStruct4M by constructing structure-aware sequences and multi-grained pairs of text and bounding boxes. The DocOwl 1.5 is trained in a two-stage framework, starting with the Unified Structure Learning and then followed by the Multi-task Tuning among downstream tasks. Finally, to trigger the reasoning ability of MLLM in Visual Document Understanding, we construct a high-quality instruction tuning dataset DocReason25K. By performing joint training on DocReason25K and downstream datasets, DocOwl 1.5-Chat well balance giving a simple answer or detailed explanations.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Our contributions in this work are four-fold:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">We first propose Unified Structure Learning on text-rich images for MLLMs and design both structure-aware parsing tasks and multi-grained text localization tasks across 5 domains. A comprehensive dataset DocStruct4M is carefully built to support Unified Structure Learning.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">We design a simple and effective vision-to-text module for structure learning and perform extensive experiments to validate its effectiveness.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">We construct a high-quality instruction tuning set to trigger the reasoning ability of MLLMs on Visual Document Understanding.</p>
</div>
</li>
<li id="S1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i4.p1" class="ltx_para">
<p id="S1.I1.i4.p1.1" class="ltx_p">DocOwl 1.5 and DocOwl 1.5-Chat achieves state-of-the-art OCR-free performance on 10 Visual Document Understanding tasks, achieving improvement of more than 10 points on 5/10 tasks among similar-sized models.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<div id="S2.p1" class="ltx_para ltx_noindent">
<p id="S2.p1.1" class="ltx_p"><span id="S2.p1.1.1" class="ltx_text ltx_font_bold">Visual Document Understanding</span>(VDU), also known as Visually-situated Language Understanding <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>, <a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite>, aims to comprehend images with rich text information. Such images range from documents <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>, <a href="#bib.bib31" title="" class="ltx_ref">31</a>, <a href="#bib.bib42" title="" class="ltx_ref">42</a>, <a href="#bib.bib41" title="" class="ltx_ref">41</a>, <a href="#bib.bib60" title="" class="ltx_ref">60</a>]</cite>, tables <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib63" title="" class="ltx_ref">63</a>]</cite>, charts <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib32" title="" class="ltx_ref">32</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib44" title="" class="ltx_ref">44</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>, natural images <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>, <a href="#bib.bib40" title="" class="ltx_ref">40</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> to webpage screenshots <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>, where diverse composition of text and visual objects contains a wealth of information. To evaluate the multimodal document understanding performance, the task formats include low-level recognition, e.g. information extraction <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>, <a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>, and high-level semantic understanding, such as visual question answering <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>, <a href="#bib.bib31" title="" class="ltx_ref">31</a>, <a href="#bib.bib34" title="" class="ltx_ref">34</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib43" title="" class="ltx_ref">43</a>, <a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>, image captioning <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite>, and natural language inference <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>. According to whether relying on an off-the-shelf OCR system to recognize texts in the image, models for Visual Document Understanding can be categorized into OCR-dependent models <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>, <a href="#bib.bib53" title="" class="ltx_ref">53</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite> and OCR-free ones <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>, <a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>. To leverage recognized texts from an OCR system, OCR-dependent models are always trained to align textual and visual inputs. For example, UDOP <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite> is pre-trained to recover masked text and layout information given image and retained text as inputs. As for OCR-free methods, training with tasks about text recognition is indispensable. Dount <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> design the text reading task to output continuous text sequences that ignore structure information.
To leverage structure information, Pix2Struct <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> designs a Screenshot Parsing Task to generate the HTML DOM tree for webpage screenshots but is hard to apply to other types of images. In this work, we first propose Unified Structure Learning for all image types and carefully build a comprehensive dataset to support layout learning.</p>
</div>
<div id="S2.p2" class="ltx_para ltx_noindent">
<p id="S2.p2.1" class="ltx_p"><span id="S2.p2.1.1" class="ltx_text ltx_font_bold">Multimodal Large Language Models</span>(MLLM) have shown strong vision understanding and open-ended conversation abilities <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>, <a href="#bib.bib58" title="" class="ltx_ref">58</a>, <a href="#bib.bib64" title="" class="ltx_ref">64</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite> for natural images. They follow the architecture paradigm of connecting a vision encoder,e.g. ViT <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>, with a Large Language Model(LLM) <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>, <a href="#bib.bib48" title="" class="ltx_ref">48</a>, <a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> by a vision-to-text module, such as simple linear layers <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite> or a Q-Former <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>/Resampler <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>/Abstractor <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>, <a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite> with learnable queries. To enable MLLMs to comprehend images with rich texts, there are major two challenges: how to encode high-resolution images and how to understand visually-situated texts. To tackle high-resolution images, most works choose to further train <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> or extraly add a high-resolution vision encoder <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>. UReader <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite> first proposes to keep the low-resolution vision encoder and use a shape-adaptive cropping module to crop raw images into multiple sub-images with low resolution. To enhance the visually-situated text understanding, some work design tasks of reading texts from top-left to bottom-right without taking into account the importance of structure <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>. CogAgent <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> and DocPedia <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> further try strengthening the layout understanding for documents, webpages, and natural images with text grounding tasks. However, the comprehension of the overall structure is ignored, and tables and charts are not covered. In this work, we follow UReader to process high-resolution images. To strengthen structure understanding, we design structure-aware praising and multi-grained text localization tasks for all types of images, covering documents, tables, charts, webpages, and natural images. We propose a vision-to-text architecture to better maintain spatial information of visual features by convolution. Finally, to support unified structure learning, we build a comprehensive training dataset DocStruct4M and greatly improve the visual document understanding performance.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>DocOwl 1.5</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">DocOwl 1.5 follows the typical architecture of Multimodal Large Language Models, which consists of a visual encoder, a vision-to-text module, and a large language model as the decoder. To better keep the textual and layout information in text-rich images of high resolution, we design an H-Reducer as the vision-to-text module to ensemble horizontal visual features. As shown in <a href="#S3.F3" title="In 3 DocOwl 1.5 ‣ mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">3</span></a>(a), to enhance the text recognition and structure understanding abilities, we first perform Unified Structure Learning with structure-aware parsing and multi-grained text localization tasks for all types of images. Then, the model is jointly tuned on multiple downstream tasks of Visual Document understanding.</p>
</div>
<figure id="S3.F3" class="ltx_figure"><img src="/html/2403.12895/assets/x3.png" id="S3.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="370" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>The two-stage training framework (a) and overall architecture (b) of DocOwl 1.5. The global image and cropped images are processed independently by the Visual Encoder and H-Reducer. <span id="S3.F3.6.1" class="ltx_text ltx_font_typewriter">&lt;rowx-coly&gt;</span> is the special textual token to indicate that the position of the cropped image in the original image is the <math id="S3.F3.3.m1.1" class="ltx_Math" alttext="x^{th}" display="inline"><semantics id="S3.F3.3.m1.1b"><msup id="S3.F3.3.m1.1.1" xref="S3.F3.3.m1.1.1.cmml"><mi id="S3.F3.3.m1.1.1.2" xref="S3.F3.3.m1.1.1.2.cmml">x</mi><mrow id="S3.F3.3.m1.1.1.3" xref="S3.F3.3.m1.1.1.3.cmml"><mi id="S3.F3.3.m1.1.1.3.2" xref="S3.F3.3.m1.1.1.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.F3.3.m1.1.1.3.1" xref="S3.F3.3.m1.1.1.3.1.cmml">​</mo><mi id="S3.F3.3.m1.1.1.3.3" xref="S3.F3.3.m1.1.1.3.3.cmml">h</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.F3.3.m1.1c"><apply id="S3.F3.3.m1.1.1.cmml" xref="S3.F3.3.m1.1.1"><csymbol cd="ambiguous" id="S3.F3.3.m1.1.1.1.cmml" xref="S3.F3.3.m1.1.1">superscript</csymbol><ci id="S3.F3.3.m1.1.1.2.cmml" xref="S3.F3.3.m1.1.1.2">𝑥</ci><apply id="S3.F3.3.m1.1.1.3.cmml" xref="S3.F3.3.m1.1.1.3"><times id="S3.F3.3.m1.1.1.3.1.cmml" xref="S3.F3.3.m1.1.1.3.1"></times><ci id="S3.F3.3.m1.1.1.3.2.cmml" xref="S3.F3.3.m1.1.1.3.2">𝑡</ci><ci id="S3.F3.3.m1.1.1.3.3.cmml" xref="S3.F3.3.m1.1.1.3.3">ℎ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.3.m1.1d">x^{th}</annotation></semantics></math> row and <math id="S3.F3.4.m2.1" class="ltx_Math" alttext="y^{th}" display="inline"><semantics id="S3.F3.4.m2.1b"><msup id="S3.F3.4.m2.1.1" xref="S3.F3.4.m2.1.1.cmml"><mi id="S3.F3.4.m2.1.1.2" xref="S3.F3.4.m2.1.1.2.cmml">y</mi><mrow id="S3.F3.4.m2.1.1.3" xref="S3.F3.4.m2.1.1.3.cmml"><mi id="S3.F3.4.m2.1.1.3.2" xref="S3.F3.4.m2.1.1.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.F3.4.m2.1.1.3.1" xref="S3.F3.4.m2.1.1.3.1.cmml">​</mo><mi id="S3.F3.4.m2.1.1.3.3" xref="S3.F3.4.m2.1.1.3.3.cmml">h</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.F3.4.m2.1c"><apply id="S3.F3.4.m2.1.1.cmml" xref="S3.F3.4.m2.1.1"><csymbol cd="ambiguous" id="S3.F3.4.m2.1.1.1.cmml" xref="S3.F3.4.m2.1.1">superscript</csymbol><ci id="S3.F3.4.m2.1.1.2.cmml" xref="S3.F3.4.m2.1.1.2">𝑦</ci><apply id="S3.F3.4.m2.1.1.3.cmml" xref="S3.F3.4.m2.1.1.3"><times id="S3.F3.4.m2.1.1.3.1.cmml" xref="S3.F3.4.m2.1.1.3.1"></times><ci id="S3.F3.4.m2.1.1.3.2.cmml" xref="S3.F3.4.m2.1.1.3.2">𝑡</ci><ci id="S3.F3.4.m2.1.1.3.3.cmml" xref="S3.F3.4.m2.1.1.3.3">ℎ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.4.m2.1d">y^{th}</annotation></semantics></math> column.</figcaption>
</figure>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Model Architecture</h3>

<div id="S3.SS1.p1" class="ltx_para ltx_noindent">
<p id="S3.SS1.p1.10" class="ltx_p"><span id="S3.SS1.p1.10.1" class="ltx_text ltx_font_bold">High-resolution Image Encoding.</span> As proved by previous works <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>, <a href="#bib.bib23" title="" class="ltx_ref">23</a>, <a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite>, the ability to encode high-resolution images is critical to ensuring that the decoder can use rich text information from document images. As shown in <a href="#S3.F3" title="In 3 DocOwl 1.5 ‣ mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">3</span></a>(b), following UReader <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite>
, we utilize a parameter-free Shape-adaptive Cropping Module to crop a shape-variable high-resolution image <math id="S3.SS1.p1.1.m1.1" class="ltx_Math" alttext="I" display="inline"><semantics id="S3.SS1.p1.1.m1.1a"><mi id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">I</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><ci id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">𝐼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">I</annotation></semantics></math> into multiple fixed-size sub-images <math id="S3.SS1.p1.2.m2.4" class="ltx_Math" alttext="(I_{1},I_{2},...,I_{C})" display="inline"><semantics id="S3.SS1.p1.2.m2.4a"><mrow id="S3.SS1.p1.2.m2.4.4.3" xref="S3.SS1.p1.2.m2.4.4.4.cmml"><mo stretchy="false" id="S3.SS1.p1.2.m2.4.4.3.4" xref="S3.SS1.p1.2.m2.4.4.4.cmml">(</mo><msub id="S3.SS1.p1.2.m2.2.2.1.1" xref="S3.SS1.p1.2.m2.2.2.1.1.cmml"><mi id="S3.SS1.p1.2.m2.2.2.1.1.2" xref="S3.SS1.p1.2.m2.2.2.1.1.2.cmml">I</mi><mn id="S3.SS1.p1.2.m2.2.2.1.1.3" xref="S3.SS1.p1.2.m2.2.2.1.1.3.cmml">1</mn></msub><mo id="S3.SS1.p1.2.m2.4.4.3.5" xref="S3.SS1.p1.2.m2.4.4.4.cmml">,</mo><msub id="S3.SS1.p1.2.m2.3.3.2.2" xref="S3.SS1.p1.2.m2.3.3.2.2.cmml"><mi id="S3.SS1.p1.2.m2.3.3.2.2.2" xref="S3.SS1.p1.2.m2.3.3.2.2.2.cmml">I</mi><mn id="S3.SS1.p1.2.m2.3.3.2.2.3" xref="S3.SS1.p1.2.m2.3.3.2.2.3.cmml">2</mn></msub><mo id="S3.SS1.p1.2.m2.4.4.3.6" xref="S3.SS1.p1.2.m2.4.4.4.cmml">,</mo><mi mathvariant="normal" id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml">…</mi><mo id="S3.SS1.p1.2.m2.4.4.3.7" xref="S3.SS1.p1.2.m2.4.4.4.cmml">,</mo><msub id="S3.SS1.p1.2.m2.4.4.3.3" xref="S3.SS1.p1.2.m2.4.4.3.3.cmml"><mi id="S3.SS1.p1.2.m2.4.4.3.3.2" xref="S3.SS1.p1.2.m2.4.4.3.3.2.cmml">I</mi><mi id="S3.SS1.p1.2.m2.4.4.3.3.3" xref="S3.SS1.p1.2.m2.4.4.3.3.3.cmml">C</mi></msub><mo stretchy="false" id="S3.SS1.p1.2.m2.4.4.3.8" xref="S3.SS1.p1.2.m2.4.4.4.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.4b"><vector id="S3.SS1.p1.2.m2.4.4.4.cmml" xref="S3.SS1.p1.2.m2.4.4.3"><apply id="S3.SS1.p1.2.m2.2.2.1.1.cmml" xref="S3.SS1.p1.2.m2.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.2.2.1.1.1.cmml" xref="S3.SS1.p1.2.m2.2.2.1.1">subscript</csymbol><ci id="S3.SS1.p1.2.m2.2.2.1.1.2.cmml" xref="S3.SS1.p1.2.m2.2.2.1.1.2">𝐼</ci><cn type="integer" id="S3.SS1.p1.2.m2.2.2.1.1.3.cmml" xref="S3.SS1.p1.2.m2.2.2.1.1.3">1</cn></apply><apply id="S3.SS1.p1.2.m2.3.3.2.2.cmml" xref="S3.SS1.p1.2.m2.3.3.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.3.3.2.2.1.cmml" xref="S3.SS1.p1.2.m2.3.3.2.2">subscript</csymbol><ci id="S3.SS1.p1.2.m2.3.3.2.2.2.cmml" xref="S3.SS1.p1.2.m2.3.3.2.2.2">𝐼</ci><cn type="integer" id="S3.SS1.p1.2.m2.3.3.2.2.3.cmml" xref="S3.SS1.p1.2.m2.3.3.2.2.3">2</cn></apply><ci id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">…</ci><apply id="S3.SS1.p1.2.m2.4.4.3.3.cmml" xref="S3.SS1.p1.2.m2.4.4.3.3"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.4.4.3.3.1.cmml" xref="S3.SS1.p1.2.m2.4.4.3.3">subscript</csymbol><ci id="S3.SS1.p1.2.m2.4.4.3.3.2.cmml" xref="S3.SS1.p1.2.m2.4.4.3.3.2">𝐼</ci><ci id="S3.SS1.p1.2.m2.4.4.3.3.3.cmml" xref="S3.SS1.p1.2.m2.4.4.3.3.3">𝐶</ci></apply></vector></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.4c">(I_{1},I_{2},...,I_{C})</annotation></semantics></math>, where <math id="S3.SS1.p1.3.m3.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S3.SS1.p1.3.m3.1a"><mi id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><ci id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">C</annotation></semantics></math> is the number of crops. To keep the overall layout information, the raw image is also resized to a low-resolution one as the global image <math id="S3.SS1.p1.4.m4.1" class="ltx_Math" alttext="I_{0}" display="inline"><semantics id="S3.SS1.p1.4.m4.1a"><msub id="S3.SS1.p1.4.m4.1.1" xref="S3.SS1.p1.4.m4.1.1.cmml"><mi id="S3.SS1.p1.4.m4.1.1.2" xref="S3.SS1.p1.4.m4.1.1.2.cmml">I</mi><mn id="S3.SS1.p1.4.m4.1.1.3" xref="S3.SS1.p1.4.m4.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.1b"><apply id="S3.SS1.p1.4.m4.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.4.m4.1.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1">subscript</csymbol><ci id="S3.SS1.p1.4.m4.1.1.2.cmml" xref="S3.SS1.p1.4.m4.1.1.2">𝐼</ci><cn type="integer" id="S3.SS1.p1.4.m4.1.1.3.cmml" xref="S3.SS1.p1.4.m4.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.1c">I_{0}</annotation></semantics></math>. Then, each image <math id="S3.SS1.p1.5.m5.1" class="ltx_Math" alttext="I_{i}" display="inline"><semantics id="S3.SS1.p1.5.m5.1a"><msub id="S3.SS1.p1.5.m5.1.1" xref="S3.SS1.p1.5.m5.1.1.cmml"><mi id="S3.SS1.p1.5.m5.1.1.2" xref="S3.SS1.p1.5.m5.1.1.2.cmml">I</mi><mi id="S3.SS1.p1.5.m5.1.1.3" xref="S3.SS1.p1.5.m5.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.5.m5.1b"><apply id="S3.SS1.p1.5.m5.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m5.1.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1">subscript</csymbol><ci id="S3.SS1.p1.5.m5.1.1.2.cmml" xref="S3.SS1.p1.5.m5.1.1.2">𝐼</ci><ci id="S3.SS1.p1.5.m5.1.1.3.cmml" xref="S3.SS1.p1.5.m5.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.5.m5.1c">I_{i}</annotation></semantics></math> in <math id="S3.SS1.p1.6.m6.4" class="ltx_Math" alttext="(I_{0},I_{1},...,I_{C})" display="inline"><semantics id="S3.SS1.p1.6.m6.4a"><mrow id="S3.SS1.p1.6.m6.4.4.3" xref="S3.SS1.p1.6.m6.4.4.4.cmml"><mo stretchy="false" id="S3.SS1.p1.6.m6.4.4.3.4" xref="S3.SS1.p1.6.m6.4.4.4.cmml">(</mo><msub id="S3.SS1.p1.6.m6.2.2.1.1" xref="S3.SS1.p1.6.m6.2.2.1.1.cmml"><mi id="S3.SS1.p1.6.m6.2.2.1.1.2" xref="S3.SS1.p1.6.m6.2.2.1.1.2.cmml">I</mi><mn id="S3.SS1.p1.6.m6.2.2.1.1.3" xref="S3.SS1.p1.6.m6.2.2.1.1.3.cmml">0</mn></msub><mo id="S3.SS1.p1.6.m6.4.4.3.5" xref="S3.SS1.p1.6.m6.4.4.4.cmml">,</mo><msub id="S3.SS1.p1.6.m6.3.3.2.2" xref="S3.SS1.p1.6.m6.3.3.2.2.cmml"><mi id="S3.SS1.p1.6.m6.3.3.2.2.2" xref="S3.SS1.p1.6.m6.3.3.2.2.2.cmml">I</mi><mn id="S3.SS1.p1.6.m6.3.3.2.2.3" xref="S3.SS1.p1.6.m6.3.3.2.2.3.cmml">1</mn></msub><mo id="S3.SS1.p1.6.m6.4.4.3.6" xref="S3.SS1.p1.6.m6.4.4.4.cmml">,</mo><mi mathvariant="normal" id="S3.SS1.p1.6.m6.1.1" xref="S3.SS1.p1.6.m6.1.1.cmml">…</mi><mo id="S3.SS1.p1.6.m6.4.4.3.7" xref="S3.SS1.p1.6.m6.4.4.4.cmml">,</mo><msub id="S3.SS1.p1.6.m6.4.4.3.3" xref="S3.SS1.p1.6.m6.4.4.3.3.cmml"><mi id="S3.SS1.p1.6.m6.4.4.3.3.2" xref="S3.SS1.p1.6.m6.4.4.3.3.2.cmml">I</mi><mi id="S3.SS1.p1.6.m6.4.4.3.3.3" xref="S3.SS1.p1.6.m6.4.4.3.3.3.cmml">C</mi></msub><mo stretchy="false" id="S3.SS1.p1.6.m6.4.4.3.8" xref="S3.SS1.p1.6.m6.4.4.4.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.6.m6.4b"><vector id="S3.SS1.p1.6.m6.4.4.4.cmml" xref="S3.SS1.p1.6.m6.4.4.3"><apply id="S3.SS1.p1.6.m6.2.2.1.1.cmml" xref="S3.SS1.p1.6.m6.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.6.m6.2.2.1.1.1.cmml" xref="S3.SS1.p1.6.m6.2.2.1.1">subscript</csymbol><ci id="S3.SS1.p1.6.m6.2.2.1.1.2.cmml" xref="S3.SS1.p1.6.m6.2.2.1.1.2">𝐼</ci><cn type="integer" id="S3.SS1.p1.6.m6.2.2.1.1.3.cmml" xref="S3.SS1.p1.6.m6.2.2.1.1.3">0</cn></apply><apply id="S3.SS1.p1.6.m6.3.3.2.2.cmml" xref="S3.SS1.p1.6.m6.3.3.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.6.m6.3.3.2.2.1.cmml" xref="S3.SS1.p1.6.m6.3.3.2.2">subscript</csymbol><ci id="S3.SS1.p1.6.m6.3.3.2.2.2.cmml" xref="S3.SS1.p1.6.m6.3.3.2.2.2">𝐼</ci><cn type="integer" id="S3.SS1.p1.6.m6.3.3.2.2.3.cmml" xref="S3.SS1.p1.6.m6.3.3.2.2.3">1</cn></apply><ci id="S3.SS1.p1.6.m6.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1">…</ci><apply id="S3.SS1.p1.6.m6.4.4.3.3.cmml" xref="S3.SS1.p1.6.m6.4.4.3.3"><csymbol cd="ambiguous" id="S3.SS1.p1.6.m6.4.4.3.3.1.cmml" xref="S3.SS1.p1.6.m6.4.4.3.3">subscript</csymbol><ci id="S3.SS1.p1.6.m6.4.4.3.3.2.cmml" xref="S3.SS1.p1.6.m6.4.4.3.3.2">𝐼</ci><ci id="S3.SS1.p1.6.m6.4.4.3.3.3.cmml" xref="S3.SS1.p1.6.m6.4.4.3.3.3">𝐶</ci></apply></vector></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.6.m6.4c">(I_{0},I_{1},...,I_{C})</annotation></semantics></math> is independently encoded to a sequence of visual features <math id="S3.SS1.p1.7.m7.3" class="ltx_Math" alttext="V_{i}=(v_{i}^{1},v_{i}^{2},...,v_{i}^{L}),0\leq i\leq C" display="inline"><semantics id="S3.SS1.p1.7.m7.3a"><mrow id="S3.SS1.p1.7.m7.3.3.2" xref="S3.SS1.p1.7.m7.3.3.3.cmml"><mrow id="S3.SS1.p1.7.m7.2.2.1.1" xref="S3.SS1.p1.7.m7.2.2.1.1.cmml"><msub id="S3.SS1.p1.7.m7.2.2.1.1.5" xref="S3.SS1.p1.7.m7.2.2.1.1.5.cmml"><mi id="S3.SS1.p1.7.m7.2.2.1.1.5.2" xref="S3.SS1.p1.7.m7.2.2.1.1.5.2.cmml">V</mi><mi id="S3.SS1.p1.7.m7.2.2.1.1.5.3" xref="S3.SS1.p1.7.m7.2.2.1.1.5.3.cmml">i</mi></msub><mo id="S3.SS1.p1.7.m7.2.2.1.1.4" xref="S3.SS1.p1.7.m7.2.2.1.1.4.cmml">=</mo><mrow id="S3.SS1.p1.7.m7.2.2.1.1.3.3" xref="S3.SS1.p1.7.m7.2.2.1.1.3.4.cmml"><mo stretchy="false" id="S3.SS1.p1.7.m7.2.2.1.1.3.3.4" xref="S3.SS1.p1.7.m7.2.2.1.1.3.4.cmml">(</mo><msubsup id="S3.SS1.p1.7.m7.2.2.1.1.1.1.1" xref="S3.SS1.p1.7.m7.2.2.1.1.1.1.1.cmml"><mi id="S3.SS1.p1.7.m7.2.2.1.1.1.1.1.2.2" xref="S3.SS1.p1.7.m7.2.2.1.1.1.1.1.2.2.cmml">v</mi><mi id="S3.SS1.p1.7.m7.2.2.1.1.1.1.1.2.3" xref="S3.SS1.p1.7.m7.2.2.1.1.1.1.1.2.3.cmml">i</mi><mn id="S3.SS1.p1.7.m7.2.2.1.1.1.1.1.3" xref="S3.SS1.p1.7.m7.2.2.1.1.1.1.1.3.cmml">1</mn></msubsup><mo id="S3.SS1.p1.7.m7.2.2.1.1.3.3.5" xref="S3.SS1.p1.7.m7.2.2.1.1.3.4.cmml">,</mo><msubsup id="S3.SS1.p1.7.m7.2.2.1.1.2.2.2" xref="S3.SS1.p1.7.m7.2.2.1.1.2.2.2.cmml"><mi id="S3.SS1.p1.7.m7.2.2.1.1.2.2.2.2.2" xref="S3.SS1.p1.7.m7.2.2.1.1.2.2.2.2.2.cmml">v</mi><mi id="S3.SS1.p1.7.m7.2.2.1.1.2.2.2.2.3" xref="S3.SS1.p1.7.m7.2.2.1.1.2.2.2.2.3.cmml">i</mi><mn id="S3.SS1.p1.7.m7.2.2.1.1.2.2.2.3" xref="S3.SS1.p1.7.m7.2.2.1.1.2.2.2.3.cmml">2</mn></msubsup><mo id="S3.SS1.p1.7.m7.2.2.1.1.3.3.6" xref="S3.SS1.p1.7.m7.2.2.1.1.3.4.cmml">,</mo><mi mathvariant="normal" id="S3.SS1.p1.7.m7.1.1" xref="S3.SS1.p1.7.m7.1.1.cmml">…</mi><mo id="S3.SS1.p1.7.m7.2.2.1.1.3.3.7" xref="S3.SS1.p1.7.m7.2.2.1.1.3.4.cmml">,</mo><msubsup id="S3.SS1.p1.7.m7.2.2.1.1.3.3.3" xref="S3.SS1.p1.7.m7.2.2.1.1.3.3.3.cmml"><mi id="S3.SS1.p1.7.m7.2.2.1.1.3.3.3.2.2" xref="S3.SS1.p1.7.m7.2.2.1.1.3.3.3.2.2.cmml">v</mi><mi id="S3.SS1.p1.7.m7.2.2.1.1.3.3.3.2.3" xref="S3.SS1.p1.7.m7.2.2.1.1.3.3.3.2.3.cmml">i</mi><mi id="S3.SS1.p1.7.m7.2.2.1.1.3.3.3.3" xref="S3.SS1.p1.7.m7.2.2.1.1.3.3.3.3.cmml">L</mi></msubsup><mo stretchy="false" id="S3.SS1.p1.7.m7.2.2.1.1.3.3.8" xref="S3.SS1.p1.7.m7.2.2.1.1.3.4.cmml">)</mo></mrow></mrow><mo id="S3.SS1.p1.7.m7.3.3.2.3" xref="S3.SS1.p1.7.m7.3.3.3a.cmml">,</mo><mrow id="S3.SS1.p1.7.m7.3.3.2.2" xref="S3.SS1.p1.7.m7.3.3.2.2.cmml"><mn id="S3.SS1.p1.7.m7.3.3.2.2.2" xref="S3.SS1.p1.7.m7.3.3.2.2.2.cmml">0</mn><mo id="S3.SS1.p1.7.m7.3.3.2.2.3" xref="S3.SS1.p1.7.m7.3.3.2.2.3.cmml">≤</mo><mi id="S3.SS1.p1.7.m7.3.3.2.2.4" xref="S3.SS1.p1.7.m7.3.3.2.2.4.cmml">i</mi><mo id="S3.SS1.p1.7.m7.3.3.2.2.5" xref="S3.SS1.p1.7.m7.3.3.2.2.5.cmml">≤</mo><mi id="S3.SS1.p1.7.m7.3.3.2.2.6" xref="S3.SS1.p1.7.m7.3.3.2.2.6.cmml">C</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.7.m7.3b"><apply id="S3.SS1.p1.7.m7.3.3.3.cmml" xref="S3.SS1.p1.7.m7.3.3.2"><csymbol cd="ambiguous" id="S3.SS1.p1.7.m7.3.3.3a.cmml" xref="S3.SS1.p1.7.m7.3.3.2.3">formulae-sequence</csymbol><apply id="S3.SS1.p1.7.m7.2.2.1.1.cmml" xref="S3.SS1.p1.7.m7.2.2.1.1"><eq id="S3.SS1.p1.7.m7.2.2.1.1.4.cmml" xref="S3.SS1.p1.7.m7.2.2.1.1.4"></eq><apply id="S3.SS1.p1.7.m7.2.2.1.1.5.cmml" xref="S3.SS1.p1.7.m7.2.2.1.1.5"><csymbol cd="ambiguous" id="S3.SS1.p1.7.m7.2.2.1.1.5.1.cmml" xref="S3.SS1.p1.7.m7.2.2.1.1.5">subscript</csymbol><ci id="S3.SS1.p1.7.m7.2.2.1.1.5.2.cmml" xref="S3.SS1.p1.7.m7.2.2.1.1.5.2">𝑉</ci><ci id="S3.SS1.p1.7.m7.2.2.1.1.5.3.cmml" xref="S3.SS1.p1.7.m7.2.2.1.1.5.3">𝑖</ci></apply><vector id="S3.SS1.p1.7.m7.2.2.1.1.3.4.cmml" xref="S3.SS1.p1.7.m7.2.2.1.1.3.3"><apply id="S3.SS1.p1.7.m7.2.2.1.1.1.1.1.cmml" xref="S3.SS1.p1.7.m7.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.7.m7.2.2.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.7.m7.2.2.1.1.1.1.1">superscript</csymbol><apply id="S3.SS1.p1.7.m7.2.2.1.1.1.1.1.2.cmml" xref="S3.SS1.p1.7.m7.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.7.m7.2.2.1.1.1.1.1.2.1.cmml" xref="S3.SS1.p1.7.m7.2.2.1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p1.7.m7.2.2.1.1.1.1.1.2.2.cmml" xref="S3.SS1.p1.7.m7.2.2.1.1.1.1.1.2.2">𝑣</ci><ci id="S3.SS1.p1.7.m7.2.2.1.1.1.1.1.2.3.cmml" xref="S3.SS1.p1.7.m7.2.2.1.1.1.1.1.2.3">𝑖</ci></apply><cn type="integer" id="S3.SS1.p1.7.m7.2.2.1.1.1.1.1.3.cmml" xref="S3.SS1.p1.7.m7.2.2.1.1.1.1.1.3">1</cn></apply><apply id="S3.SS1.p1.7.m7.2.2.1.1.2.2.2.cmml" xref="S3.SS1.p1.7.m7.2.2.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.7.m7.2.2.1.1.2.2.2.1.cmml" xref="S3.SS1.p1.7.m7.2.2.1.1.2.2.2">superscript</csymbol><apply id="S3.SS1.p1.7.m7.2.2.1.1.2.2.2.2.cmml" xref="S3.SS1.p1.7.m7.2.2.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.7.m7.2.2.1.1.2.2.2.2.1.cmml" xref="S3.SS1.p1.7.m7.2.2.1.1.2.2.2">subscript</csymbol><ci id="S3.SS1.p1.7.m7.2.2.1.1.2.2.2.2.2.cmml" xref="S3.SS1.p1.7.m7.2.2.1.1.2.2.2.2.2">𝑣</ci><ci id="S3.SS1.p1.7.m7.2.2.1.1.2.2.2.2.3.cmml" xref="S3.SS1.p1.7.m7.2.2.1.1.2.2.2.2.3">𝑖</ci></apply><cn type="integer" id="S3.SS1.p1.7.m7.2.2.1.1.2.2.2.3.cmml" xref="S3.SS1.p1.7.m7.2.2.1.1.2.2.2.3">2</cn></apply><ci id="S3.SS1.p1.7.m7.1.1.cmml" xref="S3.SS1.p1.7.m7.1.1">…</ci><apply id="S3.SS1.p1.7.m7.2.2.1.1.3.3.3.cmml" xref="S3.SS1.p1.7.m7.2.2.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.p1.7.m7.2.2.1.1.3.3.3.1.cmml" xref="S3.SS1.p1.7.m7.2.2.1.1.3.3.3">superscript</csymbol><apply id="S3.SS1.p1.7.m7.2.2.1.1.3.3.3.2.cmml" xref="S3.SS1.p1.7.m7.2.2.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.p1.7.m7.2.2.1.1.3.3.3.2.1.cmml" xref="S3.SS1.p1.7.m7.2.2.1.1.3.3.3">subscript</csymbol><ci id="S3.SS1.p1.7.m7.2.2.1.1.3.3.3.2.2.cmml" xref="S3.SS1.p1.7.m7.2.2.1.1.3.3.3.2.2">𝑣</ci><ci id="S3.SS1.p1.7.m7.2.2.1.1.3.3.3.2.3.cmml" xref="S3.SS1.p1.7.m7.2.2.1.1.3.3.3.2.3">𝑖</ci></apply><ci id="S3.SS1.p1.7.m7.2.2.1.1.3.3.3.3.cmml" xref="S3.SS1.p1.7.m7.2.2.1.1.3.3.3.3">𝐿</ci></apply></vector></apply><apply id="S3.SS1.p1.7.m7.3.3.2.2.cmml" xref="S3.SS1.p1.7.m7.3.3.2.2"><and id="S3.SS1.p1.7.m7.3.3.2.2a.cmml" xref="S3.SS1.p1.7.m7.3.3.2.2"></and><apply id="S3.SS1.p1.7.m7.3.3.2.2b.cmml" xref="S3.SS1.p1.7.m7.3.3.2.2"><leq id="S3.SS1.p1.7.m7.3.3.2.2.3.cmml" xref="S3.SS1.p1.7.m7.3.3.2.2.3"></leq><cn type="integer" id="S3.SS1.p1.7.m7.3.3.2.2.2.cmml" xref="S3.SS1.p1.7.m7.3.3.2.2.2">0</cn><ci id="S3.SS1.p1.7.m7.3.3.2.2.4.cmml" xref="S3.SS1.p1.7.m7.3.3.2.2.4">𝑖</ci></apply><apply id="S3.SS1.p1.7.m7.3.3.2.2c.cmml" xref="S3.SS1.p1.7.m7.3.3.2.2"><leq id="S3.SS1.p1.7.m7.3.3.2.2.5.cmml" xref="S3.SS1.p1.7.m7.3.3.2.2.5"></leq><share href="#S3.SS1.p1.7.m7.3.3.2.2.4.cmml" id="S3.SS1.p1.7.m7.3.3.2.2d.cmml" xref="S3.SS1.p1.7.m7.3.3.2.2"></share><ci id="S3.SS1.p1.7.m7.3.3.2.2.6.cmml" xref="S3.SS1.p1.7.m7.3.3.2.2.6">𝐶</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.7.m7.3c">V_{i}=(v_{i}^{1},v_{i}^{2},...,v_{i}^{L}),0\leq i\leq C</annotation></semantics></math> by a transformer-based Visual Encoder, where <math id="S3.SS1.p1.8.m8.2" class="ltx_Math" alttext="v_{i}^{j},1\leq j\leq L" display="inline"><semantics id="S3.SS1.p1.8.m8.2a"><mrow id="S3.SS1.p1.8.m8.2.2" xref="S3.SS1.p1.8.m8.2.2.cmml"><mrow id="S3.SS1.p1.8.m8.2.2.1.1" xref="S3.SS1.p1.8.m8.2.2.1.2.cmml"><msubsup id="S3.SS1.p1.8.m8.2.2.1.1.1" xref="S3.SS1.p1.8.m8.2.2.1.1.1.cmml"><mi id="S3.SS1.p1.8.m8.2.2.1.1.1.2.2" xref="S3.SS1.p1.8.m8.2.2.1.1.1.2.2.cmml">v</mi><mi id="S3.SS1.p1.8.m8.2.2.1.1.1.2.3" xref="S3.SS1.p1.8.m8.2.2.1.1.1.2.3.cmml">i</mi><mi id="S3.SS1.p1.8.m8.2.2.1.1.1.3" xref="S3.SS1.p1.8.m8.2.2.1.1.1.3.cmml">j</mi></msubsup><mo id="S3.SS1.p1.8.m8.2.2.1.1.2" xref="S3.SS1.p1.8.m8.2.2.1.2.cmml">,</mo><mn id="S3.SS1.p1.8.m8.1.1" xref="S3.SS1.p1.8.m8.1.1.cmml">1</mn></mrow><mo id="S3.SS1.p1.8.m8.2.2.3" xref="S3.SS1.p1.8.m8.2.2.3.cmml">≤</mo><mi id="S3.SS1.p1.8.m8.2.2.4" xref="S3.SS1.p1.8.m8.2.2.4.cmml">j</mi><mo id="S3.SS1.p1.8.m8.2.2.5" xref="S3.SS1.p1.8.m8.2.2.5.cmml">≤</mo><mi id="S3.SS1.p1.8.m8.2.2.6" xref="S3.SS1.p1.8.m8.2.2.6.cmml">L</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.8.m8.2b"><apply id="S3.SS1.p1.8.m8.2.2.cmml" xref="S3.SS1.p1.8.m8.2.2"><and id="S3.SS1.p1.8.m8.2.2a.cmml" xref="S3.SS1.p1.8.m8.2.2"></and><apply id="S3.SS1.p1.8.m8.2.2b.cmml" xref="S3.SS1.p1.8.m8.2.2"><leq id="S3.SS1.p1.8.m8.2.2.3.cmml" xref="S3.SS1.p1.8.m8.2.2.3"></leq><list id="S3.SS1.p1.8.m8.2.2.1.2.cmml" xref="S3.SS1.p1.8.m8.2.2.1.1"><apply id="S3.SS1.p1.8.m8.2.2.1.1.1.cmml" xref="S3.SS1.p1.8.m8.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.8.m8.2.2.1.1.1.1.cmml" xref="S3.SS1.p1.8.m8.2.2.1.1.1">superscript</csymbol><apply id="S3.SS1.p1.8.m8.2.2.1.1.1.2.cmml" xref="S3.SS1.p1.8.m8.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.8.m8.2.2.1.1.1.2.1.cmml" xref="S3.SS1.p1.8.m8.2.2.1.1.1">subscript</csymbol><ci id="S3.SS1.p1.8.m8.2.2.1.1.1.2.2.cmml" xref="S3.SS1.p1.8.m8.2.2.1.1.1.2.2">𝑣</ci><ci id="S3.SS1.p1.8.m8.2.2.1.1.1.2.3.cmml" xref="S3.SS1.p1.8.m8.2.2.1.1.1.2.3">𝑖</ci></apply><ci id="S3.SS1.p1.8.m8.2.2.1.1.1.3.cmml" xref="S3.SS1.p1.8.m8.2.2.1.1.1.3">𝑗</ci></apply><cn type="integer" id="S3.SS1.p1.8.m8.1.1.cmml" xref="S3.SS1.p1.8.m8.1.1">1</cn></list><ci id="S3.SS1.p1.8.m8.2.2.4.cmml" xref="S3.SS1.p1.8.m8.2.2.4">𝑗</ci></apply><apply id="S3.SS1.p1.8.m8.2.2c.cmml" xref="S3.SS1.p1.8.m8.2.2"><leq id="S3.SS1.p1.8.m8.2.2.5.cmml" xref="S3.SS1.p1.8.m8.2.2.5"></leq><share href="#S3.SS1.p1.8.m8.2.2.4.cmml" id="S3.SS1.p1.8.m8.2.2d.cmml" xref="S3.SS1.p1.8.m8.2.2"></share><ci id="S3.SS1.p1.8.m8.2.2.6.cmml" xref="S3.SS1.p1.8.m8.2.2.6">𝐿</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.8.m8.2c">v_{i}^{j},1\leq j\leq L</annotation></semantics></math> is a <math id="S3.SS1.p1.9.m9.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S3.SS1.p1.9.m9.1a"><mi id="S3.SS1.p1.9.m9.1.1" xref="S3.SS1.p1.9.m9.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.9.m9.1b"><ci id="S3.SS1.p1.9.m9.1.1.cmml" xref="S3.SS1.p1.9.m9.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.9.m9.1c">D</annotation></semantics></math>-dimension vector, <math id="S3.SS1.p1.10.m10.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S3.SS1.p1.10.m10.1a"><mi id="S3.SS1.p1.10.m10.1.1" xref="S3.SS1.p1.10.m10.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.10.m10.1b"><ci id="S3.SS1.p1.10.m10.1.1.cmml" xref="S3.SS1.p1.10.m10.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.10.m10.1c">L</annotation></semantics></math> is the length of visual features for each image.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para ltx_noindent">
<p id="S3.SS1.p2.1" class="ltx_p"><span id="S3.SS1.p2.1.1" class="ltx_text ltx_font_bold">Spatial-aware Vision-to-Text Module: H-Reducer.</span> There are two kinds of popular vision-to-text modules for Multimodal Large Language Models: a MLP <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite> or a cross-attention module with learnable queries <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>.
Both two are not quite suitable for representing high-resolution text-rich images.
The former projects complete visual features into the language embedding space. It maintains all spatial information in the document image but keeps the sequence length of raw visual features, which is too long when processing high-resolution images. For example, encoding a 1,344x1,344 image with the ViT/L-14 results in 9,216 visual tokens. The cross-attention module could greatly reduce the length of the visual sequence to the number of learnable queries, but may lose spatial information during semantic fusion.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.1" class="ltx_p">In this work, we design a more appropriate vision-to-text module for Visual Document Understanding, namely H-Reducer, which not only reduces visual sequence length but also keeps the spatial information. As shown in <a href="#S3.F3" title="In 3 DocOwl 1.5 ‣ mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">3</span></a>(b), the H-Reducer is comprised of a convolution layer to reduce sequence length and a fully-connected layer to project visual features to language embedding space. Since most textual information in document images is arranged from left to right, the horizontal text information is usually semantically coherent. Thus, the kernel size and stride size in the convolution layer are set as 1x4 to ensemble horizontal 4 visual features. The output channel is set equal to the input channel <math id="S3.SS1.p3.1.m1.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S3.SS1.p3.1.m1.1a"><mi id="S3.SS1.p3.1.m1.1.1" xref="S3.SS1.p3.1.m1.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.1.m1.1b"><ci id="S3.SS1.p3.1.m1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.1.m1.1c">D</annotation></semantics></math>. The convolution calculation is as follows:</p>
<table id="S6.EGx1" class="ltx_equationgroup ltx_eqn_gather ltx_eqn_table">

<tbody id="S3.E1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.4" class="ltx_Math" alttext="\displaystyle V_{i}=(v_{i}^{1},v_{i}^{2},...,v_{i}^{L})" display="block"><semantics id="S3.E1.m1.4a"><mrow id="S3.E1.m1.4.4" xref="S3.E1.m1.4.4.cmml"><msub id="S3.E1.m1.4.4.5" xref="S3.E1.m1.4.4.5.cmml"><mi id="S3.E1.m1.4.4.5.2" xref="S3.E1.m1.4.4.5.2.cmml">V</mi><mi id="S3.E1.m1.4.4.5.3" xref="S3.E1.m1.4.4.5.3.cmml">i</mi></msub><mo id="S3.E1.m1.4.4.4" xref="S3.E1.m1.4.4.4.cmml">=</mo><mrow id="S3.E1.m1.4.4.3.3" xref="S3.E1.m1.4.4.3.4.cmml"><mo stretchy="false" id="S3.E1.m1.4.4.3.3.4" xref="S3.E1.m1.4.4.3.4.cmml">(</mo><msubsup id="S3.E1.m1.2.2.1.1.1" xref="S3.E1.m1.2.2.1.1.1.cmml"><mi id="S3.E1.m1.2.2.1.1.1.2.2" xref="S3.E1.m1.2.2.1.1.1.2.2.cmml">v</mi><mi id="S3.E1.m1.2.2.1.1.1.2.3" xref="S3.E1.m1.2.2.1.1.1.2.3.cmml">i</mi><mn id="S3.E1.m1.2.2.1.1.1.3" xref="S3.E1.m1.2.2.1.1.1.3.cmml">1</mn></msubsup><mo id="S3.E1.m1.4.4.3.3.5" xref="S3.E1.m1.4.4.3.4.cmml">,</mo><msubsup id="S3.E1.m1.3.3.2.2.2" xref="S3.E1.m1.3.3.2.2.2.cmml"><mi id="S3.E1.m1.3.3.2.2.2.2.2" xref="S3.E1.m1.3.3.2.2.2.2.2.cmml">v</mi><mi id="S3.E1.m1.3.3.2.2.2.2.3" xref="S3.E1.m1.3.3.2.2.2.2.3.cmml">i</mi><mn id="S3.E1.m1.3.3.2.2.2.3" xref="S3.E1.m1.3.3.2.2.2.3.cmml">2</mn></msubsup><mo id="S3.E1.m1.4.4.3.3.6" xref="S3.E1.m1.4.4.3.4.cmml">,</mo><mi mathvariant="normal" id="S3.E1.m1.1.1" xref="S3.E1.m1.1.1.cmml">…</mi><mo id="S3.E1.m1.4.4.3.3.7" xref="S3.E1.m1.4.4.3.4.cmml">,</mo><msubsup id="S3.E1.m1.4.4.3.3.3" xref="S3.E1.m1.4.4.3.3.3.cmml"><mi id="S3.E1.m1.4.4.3.3.3.2.2" xref="S3.E1.m1.4.4.3.3.3.2.2.cmml">v</mi><mi id="S3.E1.m1.4.4.3.3.3.2.3" xref="S3.E1.m1.4.4.3.3.3.2.3.cmml">i</mi><mi id="S3.E1.m1.4.4.3.3.3.3" xref="S3.E1.m1.4.4.3.3.3.3.cmml">L</mi></msubsup><mo stretchy="false" id="S3.E1.m1.4.4.3.3.8" xref="S3.E1.m1.4.4.3.4.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.4b"><apply id="S3.E1.m1.4.4.cmml" xref="S3.E1.m1.4.4"><eq id="S3.E1.m1.4.4.4.cmml" xref="S3.E1.m1.4.4.4"></eq><apply id="S3.E1.m1.4.4.5.cmml" xref="S3.E1.m1.4.4.5"><csymbol cd="ambiguous" id="S3.E1.m1.4.4.5.1.cmml" xref="S3.E1.m1.4.4.5">subscript</csymbol><ci id="S3.E1.m1.4.4.5.2.cmml" xref="S3.E1.m1.4.4.5.2">𝑉</ci><ci id="S3.E1.m1.4.4.5.3.cmml" xref="S3.E1.m1.4.4.5.3">𝑖</ci></apply><vector id="S3.E1.m1.4.4.3.4.cmml" xref="S3.E1.m1.4.4.3.3"><apply id="S3.E1.m1.2.2.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.1.1.cmml" xref="S3.E1.m1.2.2.1.1.1">superscript</csymbol><apply id="S3.E1.m1.2.2.1.1.1.2.cmml" xref="S3.E1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.1.1.1.2.1.cmml" xref="S3.E1.m1.2.2.1.1.1">subscript</csymbol><ci id="S3.E1.m1.2.2.1.1.1.2.2.cmml" xref="S3.E1.m1.2.2.1.1.1.2.2">𝑣</ci><ci id="S3.E1.m1.2.2.1.1.1.2.3.cmml" xref="S3.E1.m1.2.2.1.1.1.2.3">𝑖</ci></apply><cn type="integer" id="S3.E1.m1.2.2.1.1.1.3.cmml" xref="S3.E1.m1.2.2.1.1.1.3">1</cn></apply><apply id="S3.E1.m1.3.3.2.2.2.cmml" xref="S3.E1.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.2.2.2.1.cmml" xref="S3.E1.m1.3.3.2.2.2">superscript</csymbol><apply id="S3.E1.m1.3.3.2.2.2.2.cmml" xref="S3.E1.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.2.2.2.2.1.cmml" xref="S3.E1.m1.3.3.2.2.2">subscript</csymbol><ci id="S3.E1.m1.3.3.2.2.2.2.2.cmml" xref="S3.E1.m1.3.3.2.2.2.2.2">𝑣</ci><ci id="S3.E1.m1.3.3.2.2.2.2.3.cmml" xref="S3.E1.m1.3.3.2.2.2.2.3">𝑖</ci></apply><cn type="integer" id="S3.E1.m1.3.3.2.2.2.3.cmml" xref="S3.E1.m1.3.3.2.2.2.3">2</cn></apply><ci id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1">…</ci><apply id="S3.E1.m1.4.4.3.3.3.cmml" xref="S3.E1.m1.4.4.3.3.3"><csymbol cd="ambiguous" id="S3.E1.m1.4.4.3.3.3.1.cmml" xref="S3.E1.m1.4.4.3.3.3">superscript</csymbol><apply id="S3.E1.m1.4.4.3.3.3.2.cmml" xref="S3.E1.m1.4.4.3.3.3"><csymbol cd="ambiguous" id="S3.E1.m1.4.4.3.3.3.2.1.cmml" xref="S3.E1.m1.4.4.3.3.3">subscript</csymbol><ci id="S3.E1.m1.4.4.3.3.3.2.2.cmml" xref="S3.E1.m1.4.4.3.3.3.2.2">𝑣</ci><ci id="S3.E1.m1.4.4.3.3.3.2.3.cmml" xref="S3.E1.m1.4.4.3.3.3.2.3">𝑖</ci></apply><ci id="S3.E1.m1.4.4.3.3.3.3.cmml" xref="S3.E1.m1.4.4.3.3.3.3">𝐿</ci></apply></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.4c">\displaystyle V_{i}=(v_{i}^{1},v_{i}^{2},...,v_{i}^{L})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
<tbody id="S3.E2"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E2.m1.1" class="ltx_Math" alttext="\displaystyle\overline{v}_{i}^{j}=f(v_{i}^{4j-3},v_{i}^{4j-2},v_{i}^{4j-1},v_{i}^{4j}),1\leq j\leq L/4," display="block"><semantics id="S3.E2.m1.1a"><mrow id="S3.E2.m1.1.1.1"><mrow id="S3.E2.m1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.3.cmml"><mrow id="S3.E2.m1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.cmml"><msubsup id="S3.E2.m1.1.1.1.1.1.1.6" xref="S3.E2.m1.1.1.1.1.1.1.6.cmml"><mover accent="true" id="S3.E2.m1.1.1.1.1.1.1.6.2.2" xref="S3.E2.m1.1.1.1.1.1.1.6.2.2.cmml"><mi id="S3.E2.m1.1.1.1.1.1.1.6.2.2.2" xref="S3.E2.m1.1.1.1.1.1.1.6.2.2.2.cmml">v</mi><mo id="S3.E2.m1.1.1.1.1.1.1.6.2.2.1" xref="S3.E2.m1.1.1.1.1.1.1.6.2.2.1.cmml">¯</mo></mover><mi id="S3.E2.m1.1.1.1.1.1.1.6.2.3" xref="S3.E2.m1.1.1.1.1.1.1.6.2.3.cmml">i</mi><mi id="S3.E2.m1.1.1.1.1.1.1.6.3" xref="S3.E2.m1.1.1.1.1.1.1.6.3.cmml">j</mi></msubsup><mo id="S3.E2.m1.1.1.1.1.1.1.5" xref="S3.E2.m1.1.1.1.1.1.1.5.cmml">=</mo><mrow id="S3.E2.m1.1.1.1.1.1.1.4" xref="S3.E2.m1.1.1.1.1.1.1.4.cmml"><mi id="S3.E2.m1.1.1.1.1.1.1.4.6" xref="S3.E2.m1.1.1.1.1.1.1.4.6.cmml">f</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.1.1.1.1.1.4.5" xref="S3.E2.m1.1.1.1.1.1.1.4.5.cmml">​</mo><mrow id="S3.E2.m1.1.1.1.1.1.1.4.4.4" xref="S3.E2.m1.1.1.1.1.1.1.4.4.5.cmml"><mo stretchy="false" id="S3.E2.m1.1.1.1.1.1.1.4.4.4.5" xref="S3.E2.m1.1.1.1.1.1.1.4.4.5.cmml">(</mo><msubsup id="S3.E2.m1.1.1.1.1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E2.m1.1.1.1.1.1.1.1.1.1.1.2.2" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1.1.2.2.cmml">v</mi><mi id="S3.E2.m1.1.1.1.1.1.1.1.1.1.1.2.3" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1.1.2.3.cmml">i</mi><mrow id="S3.E2.m1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1.1.3.cmml"><mrow id="S3.E2.m1.1.1.1.1.1.1.1.1.1.1.3.2" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1.1.3.2.cmml"><mn id="S3.E2.m1.1.1.1.1.1.1.1.1.1.1.3.2.2" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1.1.3.2.2.cmml">4</mn><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.1.1.1.1.1.1.1.1.1.3.2.1" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1.1.3.2.1.cmml">​</mo><mi id="S3.E2.m1.1.1.1.1.1.1.1.1.1.1.3.2.3" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1.1.3.2.3.cmml">j</mi></mrow><mo id="S3.E2.m1.1.1.1.1.1.1.1.1.1.1.3.1" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1.1.3.1.cmml">−</mo><mn id="S3.E2.m1.1.1.1.1.1.1.1.1.1.1.3.3" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1.1.3.3.cmml">3</mn></mrow></msubsup><mo id="S3.E2.m1.1.1.1.1.1.1.4.4.4.6" xref="S3.E2.m1.1.1.1.1.1.1.4.4.5.cmml">,</mo><msubsup id="S3.E2.m1.1.1.1.1.1.1.2.2.2.2" xref="S3.E2.m1.1.1.1.1.1.1.2.2.2.2.cmml"><mi id="S3.E2.m1.1.1.1.1.1.1.2.2.2.2.2.2" xref="S3.E2.m1.1.1.1.1.1.1.2.2.2.2.2.2.cmml">v</mi><mi id="S3.E2.m1.1.1.1.1.1.1.2.2.2.2.2.3" xref="S3.E2.m1.1.1.1.1.1.1.2.2.2.2.2.3.cmml">i</mi><mrow id="S3.E2.m1.1.1.1.1.1.1.2.2.2.2.3" xref="S3.E2.m1.1.1.1.1.1.1.2.2.2.2.3.cmml"><mrow id="S3.E2.m1.1.1.1.1.1.1.2.2.2.2.3.2" xref="S3.E2.m1.1.1.1.1.1.1.2.2.2.2.3.2.cmml"><mn id="S3.E2.m1.1.1.1.1.1.1.2.2.2.2.3.2.2" xref="S3.E2.m1.1.1.1.1.1.1.2.2.2.2.3.2.2.cmml">4</mn><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.1.1.1.1.1.2.2.2.2.3.2.1" xref="S3.E2.m1.1.1.1.1.1.1.2.2.2.2.3.2.1.cmml">​</mo><mi id="S3.E2.m1.1.1.1.1.1.1.2.2.2.2.3.2.3" xref="S3.E2.m1.1.1.1.1.1.1.2.2.2.2.3.2.3.cmml">j</mi></mrow><mo id="S3.E2.m1.1.1.1.1.1.1.2.2.2.2.3.1" xref="S3.E2.m1.1.1.1.1.1.1.2.2.2.2.3.1.cmml">−</mo><mn id="S3.E2.m1.1.1.1.1.1.1.2.2.2.2.3.3" xref="S3.E2.m1.1.1.1.1.1.1.2.2.2.2.3.3.cmml">2</mn></mrow></msubsup><mo id="S3.E2.m1.1.1.1.1.1.1.4.4.4.7" xref="S3.E2.m1.1.1.1.1.1.1.4.4.5.cmml">,</mo><msubsup id="S3.E2.m1.1.1.1.1.1.1.3.3.3.3" xref="S3.E2.m1.1.1.1.1.1.1.3.3.3.3.cmml"><mi id="S3.E2.m1.1.1.1.1.1.1.3.3.3.3.2.2" xref="S3.E2.m1.1.1.1.1.1.1.3.3.3.3.2.2.cmml">v</mi><mi id="S3.E2.m1.1.1.1.1.1.1.3.3.3.3.2.3" xref="S3.E2.m1.1.1.1.1.1.1.3.3.3.3.2.3.cmml">i</mi><mrow id="S3.E2.m1.1.1.1.1.1.1.3.3.3.3.3" xref="S3.E2.m1.1.1.1.1.1.1.3.3.3.3.3.cmml"><mrow id="S3.E2.m1.1.1.1.1.1.1.3.3.3.3.3.2" xref="S3.E2.m1.1.1.1.1.1.1.3.3.3.3.3.2.cmml"><mn id="S3.E2.m1.1.1.1.1.1.1.3.3.3.3.3.2.2" xref="S3.E2.m1.1.1.1.1.1.1.3.3.3.3.3.2.2.cmml">4</mn><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.1.1.1.1.1.3.3.3.3.3.2.1" xref="S3.E2.m1.1.1.1.1.1.1.3.3.3.3.3.2.1.cmml">​</mo><mi id="S3.E2.m1.1.1.1.1.1.1.3.3.3.3.3.2.3" xref="S3.E2.m1.1.1.1.1.1.1.3.3.3.3.3.2.3.cmml">j</mi></mrow><mo id="S3.E2.m1.1.1.1.1.1.1.3.3.3.3.3.1" xref="S3.E2.m1.1.1.1.1.1.1.3.3.3.3.3.1.cmml">−</mo><mn id="S3.E2.m1.1.1.1.1.1.1.3.3.3.3.3.3" xref="S3.E2.m1.1.1.1.1.1.1.3.3.3.3.3.3.cmml">1</mn></mrow></msubsup><mo id="S3.E2.m1.1.1.1.1.1.1.4.4.4.8" xref="S3.E2.m1.1.1.1.1.1.1.4.4.5.cmml">,</mo><msubsup id="S3.E2.m1.1.1.1.1.1.1.4.4.4.4" xref="S3.E2.m1.1.1.1.1.1.1.4.4.4.4.cmml"><mi id="S3.E2.m1.1.1.1.1.1.1.4.4.4.4.2.2" xref="S3.E2.m1.1.1.1.1.1.1.4.4.4.4.2.2.cmml">v</mi><mi id="S3.E2.m1.1.1.1.1.1.1.4.4.4.4.2.3" xref="S3.E2.m1.1.1.1.1.1.1.4.4.4.4.2.3.cmml">i</mi><mrow id="S3.E2.m1.1.1.1.1.1.1.4.4.4.4.3" xref="S3.E2.m1.1.1.1.1.1.1.4.4.4.4.3.cmml"><mn id="S3.E2.m1.1.1.1.1.1.1.4.4.4.4.3.2" xref="S3.E2.m1.1.1.1.1.1.1.4.4.4.4.3.2.cmml">4</mn><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.1.1.1.1.1.4.4.4.4.3.1" xref="S3.E2.m1.1.1.1.1.1.1.4.4.4.4.3.1.cmml">​</mo><mi id="S3.E2.m1.1.1.1.1.1.1.4.4.4.4.3.3" xref="S3.E2.m1.1.1.1.1.1.1.4.4.4.4.3.3.cmml">j</mi></mrow></msubsup><mo stretchy="false" id="S3.E2.m1.1.1.1.1.1.1.4.4.4.9" xref="S3.E2.m1.1.1.1.1.1.1.4.4.5.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E2.m1.1.1.1.1.2.3" xref="S3.E2.m1.1.1.1.1.3a.cmml">,</mo><mrow id="S3.E2.m1.1.1.1.1.2.2" xref="S3.E2.m1.1.1.1.1.2.2.cmml"><mn id="S3.E2.m1.1.1.1.1.2.2.2" xref="S3.E2.m1.1.1.1.1.2.2.2.cmml">1</mn><mo id="S3.E2.m1.1.1.1.1.2.2.3" xref="S3.E2.m1.1.1.1.1.2.2.3.cmml">≤</mo><mi id="S3.E2.m1.1.1.1.1.2.2.4" xref="S3.E2.m1.1.1.1.1.2.2.4.cmml">j</mi><mo id="S3.E2.m1.1.1.1.1.2.2.5" xref="S3.E2.m1.1.1.1.1.2.2.5.cmml">≤</mo><mrow id="S3.E2.m1.1.1.1.1.2.2.6" xref="S3.E2.m1.1.1.1.1.2.2.6.cmml"><mi id="S3.E2.m1.1.1.1.1.2.2.6.2" xref="S3.E2.m1.1.1.1.1.2.2.6.2.cmml">L</mi><mo id="S3.E2.m1.1.1.1.1.2.2.6.1" xref="S3.E2.m1.1.1.1.1.2.2.6.1.cmml">/</mo><mn id="S3.E2.m1.1.1.1.1.2.2.6.3" xref="S3.E2.m1.1.1.1.1.2.2.6.3.cmml">4</mn></mrow></mrow></mrow><mo id="S3.E2.m1.1.1.1.2">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.1b"><apply id="S3.E2.m1.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.3a.cmml" xref="S3.E2.m1.1.1.1.1.2.3">formulae-sequence</csymbol><apply id="S3.E2.m1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1"><eq id="S3.E2.m1.1.1.1.1.1.1.5.cmml" xref="S3.E2.m1.1.1.1.1.1.1.5"></eq><apply id="S3.E2.m1.1.1.1.1.1.1.6.cmml" xref="S3.E2.m1.1.1.1.1.1.1.6"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.1.1.6.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.6">superscript</csymbol><apply id="S3.E2.m1.1.1.1.1.1.1.6.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.6"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.1.1.6.2.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.6">subscript</csymbol><apply id="S3.E2.m1.1.1.1.1.1.1.6.2.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.6.2.2"><ci id="S3.E2.m1.1.1.1.1.1.1.6.2.2.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.6.2.2.1">¯</ci><ci id="S3.E2.m1.1.1.1.1.1.1.6.2.2.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.6.2.2.2">𝑣</ci></apply><ci id="S3.E2.m1.1.1.1.1.1.1.6.2.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.6.2.3">𝑖</ci></apply><ci id="S3.E2.m1.1.1.1.1.1.1.6.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.6.3">𝑗</ci></apply><apply id="S3.E2.m1.1.1.1.1.1.1.4.cmml" xref="S3.E2.m1.1.1.1.1.1.1.4"><times id="S3.E2.m1.1.1.1.1.1.1.4.5.cmml" xref="S3.E2.m1.1.1.1.1.1.1.4.5"></times><ci id="S3.E2.m1.1.1.1.1.1.1.4.6.cmml" xref="S3.E2.m1.1.1.1.1.1.1.4.6">𝑓</ci><vector id="S3.E2.m1.1.1.1.1.1.1.4.4.5.cmml" xref="S3.E2.m1.1.1.1.1.1.1.4.4.4"><apply id="S3.E2.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1.1">superscript</csymbol><apply id="S3.E2.m1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1.1.2.2">𝑣</ci><ci id="S3.E2.m1.1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1.1.2.3">𝑖</ci></apply><apply id="S3.E2.m1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1.1.3"><minus id="S3.E2.m1.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1.1.3.1"></minus><apply id="S3.E2.m1.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1.1.3.2"><times id="S3.E2.m1.1.1.1.1.1.1.1.1.1.1.3.2.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1.1.3.2.1"></times><cn type="integer" id="S3.E2.m1.1.1.1.1.1.1.1.1.1.1.3.2.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1.1.3.2.2">4</cn><ci id="S3.E2.m1.1.1.1.1.1.1.1.1.1.1.3.2.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1.1.3.2.3">𝑗</ci></apply><cn type="integer" id="S3.E2.m1.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1.1.3.3">3</cn></apply></apply><apply id="S3.E2.m1.1.1.1.1.1.1.2.2.2.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.1.1.2.2.2.2.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2.2.2.2">superscript</csymbol><apply id="S3.E2.m1.1.1.1.1.1.1.2.2.2.2.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.1.1.2.2.2.2.2.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2.2.2.2">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.1.1.2.2.2.2.2.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2.2.2.2.2.2">𝑣</ci><ci id="S3.E2.m1.1.1.1.1.1.1.2.2.2.2.2.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2.2.2.2.2.3">𝑖</ci></apply><apply id="S3.E2.m1.1.1.1.1.1.1.2.2.2.2.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2.2.2.2.3"><minus id="S3.E2.m1.1.1.1.1.1.1.2.2.2.2.3.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2.2.2.2.3.1"></minus><apply id="S3.E2.m1.1.1.1.1.1.1.2.2.2.2.3.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2.2.2.2.3.2"><times id="S3.E2.m1.1.1.1.1.1.1.2.2.2.2.3.2.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2.2.2.2.3.2.1"></times><cn type="integer" id="S3.E2.m1.1.1.1.1.1.1.2.2.2.2.3.2.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2.2.2.2.3.2.2">4</cn><ci id="S3.E2.m1.1.1.1.1.1.1.2.2.2.2.3.2.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2.2.2.2.3.2.3">𝑗</ci></apply><cn type="integer" id="S3.E2.m1.1.1.1.1.1.1.2.2.2.2.3.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2.2.2.2.3.3">2</cn></apply></apply><apply id="S3.E2.m1.1.1.1.1.1.1.3.3.3.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.3.3.3"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.1.1.3.3.3.3.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.3.3.3">superscript</csymbol><apply id="S3.E2.m1.1.1.1.1.1.1.3.3.3.3.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.3.3.3"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.1.1.3.3.3.3.2.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.3.3.3">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.1.1.3.3.3.3.2.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.3.3.3.2.2">𝑣</ci><ci id="S3.E2.m1.1.1.1.1.1.1.3.3.3.3.2.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.3.3.3.2.3">𝑖</ci></apply><apply id="S3.E2.m1.1.1.1.1.1.1.3.3.3.3.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.3.3.3.3"><minus id="S3.E2.m1.1.1.1.1.1.1.3.3.3.3.3.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.3.3.3.3.1"></minus><apply id="S3.E2.m1.1.1.1.1.1.1.3.3.3.3.3.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.3.3.3.3.2"><times id="S3.E2.m1.1.1.1.1.1.1.3.3.3.3.3.2.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.3.3.3.3.2.1"></times><cn type="integer" id="S3.E2.m1.1.1.1.1.1.1.3.3.3.3.3.2.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.3.3.3.3.2.2">4</cn><ci id="S3.E2.m1.1.1.1.1.1.1.3.3.3.3.3.2.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.3.3.3.3.2.3">𝑗</ci></apply><cn type="integer" id="S3.E2.m1.1.1.1.1.1.1.3.3.3.3.3.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.3.3.3.3.3">1</cn></apply></apply><apply id="S3.E2.m1.1.1.1.1.1.1.4.4.4.4.cmml" xref="S3.E2.m1.1.1.1.1.1.1.4.4.4.4"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.1.1.4.4.4.4.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.4.4.4.4">superscript</csymbol><apply id="S3.E2.m1.1.1.1.1.1.1.4.4.4.4.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.4.4.4.4"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.1.1.4.4.4.4.2.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.4.4.4.4">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.1.1.4.4.4.4.2.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.4.4.4.4.2.2">𝑣</ci><ci id="S3.E2.m1.1.1.1.1.1.1.4.4.4.4.2.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.4.4.4.4.2.3">𝑖</ci></apply><apply id="S3.E2.m1.1.1.1.1.1.1.4.4.4.4.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.4.4.4.4.3"><times id="S3.E2.m1.1.1.1.1.1.1.4.4.4.4.3.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.4.4.4.4.3.1"></times><cn type="integer" id="S3.E2.m1.1.1.1.1.1.1.4.4.4.4.3.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.4.4.4.4.3.2">4</cn><ci id="S3.E2.m1.1.1.1.1.1.1.4.4.4.4.3.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.4.4.4.4.3.3">𝑗</ci></apply></apply></vector></apply></apply><apply id="S3.E2.m1.1.1.1.1.2.2.cmml" xref="S3.E2.m1.1.1.1.1.2.2"><and id="S3.E2.m1.1.1.1.1.2.2a.cmml" xref="S3.E2.m1.1.1.1.1.2.2"></and><apply id="S3.E2.m1.1.1.1.1.2.2b.cmml" xref="S3.E2.m1.1.1.1.1.2.2"><leq id="S3.E2.m1.1.1.1.1.2.2.3.cmml" xref="S3.E2.m1.1.1.1.1.2.2.3"></leq><cn type="integer" id="S3.E2.m1.1.1.1.1.2.2.2.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2">1</cn><ci id="S3.E2.m1.1.1.1.1.2.2.4.cmml" xref="S3.E2.m1.1.1.1.1.2.2.4">𝑗</ci></apply><apply id="S3.E2.m1.1.1.1.1.2.2c.cmml" xref="S3.E2.m1.1.1.1.1.2.2"><leq id="S3.E2.m1.1.1.1.1.2.2.5.cmml" xref="S3.E2.m1.1.1.1.1.2.2.5"></leq><share href="#S3.E2.m1.1.1.1.1.2.2.4.cmml" id="S3.E2.m1.1.1.1.1.2.2d.cmml" xref="S3.E2.m1.1.1.1.1.2.2"></share><apply id="S3.E2.m1.1.1.1.1.2.2.6.cmml" xref="S3.E2.m1.1.1.1.1.2.2.6"><divide id="S3.E2.m1.1.1.1.1.2.2.6.1.cmml" xref="S3.E2.m1.1.1.1.1.2.2.6.1"></divide><ci id="S3.E2.m1.1.1.1.1.2.2.6.2.cmml" xref="S3.E2.m1.1.1.1.1.2.2.6.2">𝐿</ci><cn type="integer" id="S3.E2.m1.1.1.1.1.2.2.6.3.cmml" xref="S3.E2.m1.1.1.1.1.2.2.6.3">4</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.1c">\displaystyle\overline{v}_{i}^{j}=f(v_{i}^{4j-3},v_{i}^{4j-2},v_{i}^{4j-1},v_{i}^{4j}),1\leq j\leq L/4,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
<tbody id="S3.E3"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E3.m1.2" class="ltx_Math" alttext="\displaystyle\overline{V}_{i}=(\overline{v}_{i}^{1},\overline{v}_{i}^{2},...,\overline{v}_{i}^{L/4})," display="block"><semantics id="S3.E3.m1.2a"><mrow id="S3.E3.m1.2.2.1" xref="S3.E3.m1.2.2.1.1.cmml"><mrow id="S3.E3.m1.2.2.1.1" xref="S3.E3.m1.2.2.1.1.cmml"><msub id="S3.E3.m1.2.2.1.1.5" xref="S3.E3.m1.2.2.1.1.5.cmml"><mover accent="true" id="S3.E3.m1.2.2.1.1.5.2" xref="S3.E3.m1.2.2.1.1.5.2.cmml"><mi id="S3.E3.m1.2.2.1.1.5.2.2" xref="S3.E3.m1.2.2.1.1.5.2.2.cmml">V</mi><mo id="S3.E3.m1.2.2.1.1.5.2.1" xref="S3.E3.m1.2.2.1.1.5.2.1.cmml">¯</mo></mover><mi id="S3.E3.m1.2.2.1.1.5.3" xref="S3.E3.m1.2.2.1.1.5.3.cmml">i</mi></msub><mo id="S3.E3.m1.2.2.1.1.4" xref="S3.E3.m1.2.2.1.1.4.cmml">=</mo><mrow id="S3.E3.m1.2.2.1.1.3.3" xref="S3.E3.m1.2.2.1.1.3.4.cmml"><mo stretchy="false" id="S3.E3.m1.2.2.1.1.3.3.4" xref="S3.E3.m1.2.2.1.1.3.4.cmml">(</mo><msubsup id="S3.E3.m1.2.2.1.1.1.1.1" xref="S3.E3.m1.2.2.1.1.1.1.1.cmml"><mover accent="true" id="S3.E3.m1.2.2.1.1.1.1.1.2.2" xref="S3.E3.m1.2.2.1.1.1.1.1.2.2.cmml"><mi id="S3.E3.m1.2.2.1.1.1.1.1.2.2.2" xref="S3.E3.m1.2.2.1.1.1.1.1.2.2.2.cmml">v</mi><mo id="S3.E3.m1.2.2.1.1.1.1.1.2.2.1" xref="S3.E3.m1.2.2.1.1.1.1.1.2.2.1.cmml">¯</mo></mover><mi id="S3.E3.m1.2.2.1.1.1.1.1.2.3" xref="S3.E3.m1.2.2.1.1.1.1.1.2.3.cmml">i</mi><mn id="S3.E3.m1.2.2.1.1.1.1.1.3" xref="S3.E3.m1.2.2.1.1.1.1.1.3.cmml">1</mn></msubsup><mo id="S3.E3.m1.2.2.1.1.3.3.5" xref="S3.E3.m1.2.2.1.1.3.4.cmml">,</mo><msubsup id="S3.E3.m1.2.2.1.1.2.2.2" xref="S3.E3.m1.2.2.1.1.2.2.2.cmml"><mover accent="true" id="S3.E3.m1.2.2.1.1.2.2.2.2.2" xref="S3.E3.m1.2.2.1.1.2.2.2.2.2.cmml"><mi id="S3.E3.m1.2.2.1.1.2.2.2.2.2.2" xref="S3.E3.m1.2.2.1.1.2.2.2.2.2.2.cmml">v</mi><mo id="S3.E3.m1.2.2.1.1.2.2.2.2.2.1" xref="S3.E3.m1.2.2.1.1.2.2.2.2.2.1.cmml">¯</mo></mover><mi id="S3.E3.m1.2.2.1.1.2.2.2.2.3" xref="S3.E3.m1.2.2.1.1.2.2.2.2.3.cmml">i</mi><mn id="S3.E3.m1.2.2.1.1.2.2.2.3" xref="S3.E3.m1.2.2.1.1.2.2.2.3.cmml">2</mn></msubsup><mo id="S3.E3.m1.2.2.1.1.3.3.6" xref="S3.E3.m1.2.2.1.1.3.4.cmml">,</mo><mi mathvariant="normal" id="S3.E3.m1.1.1" xref="S3.E3.m1.1.1.cmml">…</mi><mo id="S3.E3.m1.2.2.1.1.3.3.7" xref="S3.E3.m1.2.2.1.1.3.4.cmml">,</mo><msubsup id="S3.E3.m1.2.2.1.1.3.3.3" xref="S3.E3.m1.2.2.1.1.3.3.3.cmml"><mover accent="true" id="S3.E3.m1.2.2.1.1.3.3.3.2.2" xref="S3.E3.m1.2.2.1.1.3.3.3.2.2.cmml"><mi id="S3.E3.m1.2.2.1.1.3.3.3.2.2.2" xref="S3.E3.m1.2.2.1.1.3.3.3.2.2.2.cmml">v</mi><mo id="S3.E3.m1.2.2.1.1.3.3.3.2.2.1" xref="S3.E3.m1.2.2.1.1.3.3.3.2.2.1.cmml">¯</mo></mover><mi id="S3.E3.m1.2.2.1.1.3.3.3.2.3" xref="S3.E3.m1.2.2.1.1.3.3.3.2.3.cmml">i</mi><mrow id="S3.E3.m1.2.2.1.1.3.3.3.3" xref="S3.E3.m1.2.2.1.1.3.3.3.3.cmml"><mi id="S3.E3.m1.2.2.1.1.3.3.3.3.2" xref="S3.E3.m1.2.2.1.1.3.3.3.3.2.cmml">L</mi><mo id="S3.E3.m1.2.2.1.1.3.3.3.3.1" xref="S3.E3.m1.2.2.1.1.3.3.3.3.1.cmml">/</mo><mn id="S3.E3.m1.2.2.1.1.3.3.3.3.3" xref="S3.E3.m1.2.2.1.1.3.3.3.3.3.cmml">4</mn></mrow></msubsup><mo stretchy="false" id="S3.E3.m1.2.2.1.1.3.3.8" xref="S3.E3.m1.2.2.1.1.3.4.cmml">)</mo></mrow></mrow><mo id="S3.E3.m1.2.2.1.2" xref="S3.E3.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.2b"><apply id="S3.E3.m1.2.2.1.1.cmml" xref="S3.E3.m1.2.2.1"><eq id="S3.E3.m1.2.2.1.1.4.cmml" xref="S3.E3.m1.2.2.1.1.4"></eq><apply id="S3.E3.m1.2.2.1.1.5.cmml" xref="S3.E3.m1.2.2.1.1.5"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.5.1.cmml" xref="S3.E3.m1.2.2.1.1.5">subscript</csymbol><apply id="S3.E3.m1.2.2.1.1.5.2.cmml" xref="S3.E3.m1.2.2.1.1.5.2"><ci id="S3.E3.m1.2.2.1.1.5.2.1.cmml" xref="S3.E3.m1.2.2.1.1.5.2.1">¯</ci><ci id="S3.E3.m1.2.2.1.1.5.2.2.cmml" xref="S3.E3.m1.2.2.1.1.5.2.2">𝑉</ci></apply><ci id="S3.E3.m1.2.2.1.1.5.3.cmml" xref="S3.E3.m1.2.2.1.1.5.3">𝑖</ci></apply><vector id="S3.E3.m1.2.2.1.1.3.4.cmml" xref="S3.E3.m1.2.2.1.1.3.3"><apply id="S3.E3.m1.2.2.1.1.1.1.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.1.1.1.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1">superscript</csymbol><apply id="S3.E3.m1.2.2.1.1.1.1.1.2.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.1.1.1.2.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1">subscript</csymbol><apply id="S3.E3.m1.2.2.1.1.1.1.1.2.2.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.2.2"><ci id="S3.E3.m1.2.2.1.1.1.1.1.2.2.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.2.2.1">¯</ci><ci id="S3.E3.m1.2.2.1.1.1.1.1.2.2.2.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.2.2.2">𝑣</ci></apply><ci id="S3.E3.m1.2.2.1.1.1.1.1.2.3.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.2.3">𝑖</ci></apply><cn type="integer" id="S3.E3.m1.2.2.1.1.1.1.1.3.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.3">1</cn></apply><apply id="S3.E3.m1.2.2.1.1.2.2.2.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.2.2.2.1.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2">superscript</csymbol><apply id="S3.E3.m1.2.2.1.1.2.2.2.2.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.2.2.2.2.1.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2">subscript</csymbol><apply id="S3.E3.m1.2.2.1.1.2.2.2.2.2.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.2.2"><ci id="S3.E3.m1.2.2.1.1.2.2.2.2.2.1.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.2.2.1">¯</ci><ci id="S3.E3.m1.2.2.1.1.2.2.2.2.2.2.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.2.2.2">𝑣</ci></apply><ci id="S3.E3.m1.2.2.1.1.2.2.2.2.3.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.2.3">𝑖</ci></apply><cn type="integer" id="S3.E3.m1.2.2.1.1.2.2.2.3.cmml" xref="S3.E3.m1.2.2.1.1.2.2.2.3">2</cn></apply><ci id="S3.E3.m1.1.1.cmml" xref="S3.E3.m1.1.1">…</ci><apply id="S3.E3.m1.2.2.1.1.3.3.3.cmml" xref="S3.E3.m1.2.2.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.3.3.3.1.cmml" xref="S3.E3.m1.2.2.1.1.3.3.3">superscript</csymbol><apply id="S3.E3.m1.2.2.1.1.3.3.3.2.cmml" xref="S3.E3.m1.2.2.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.3.3.3.2.1.cmml" xref="S3.E3.m1.2.2.1.1.3.3.3">subscript</csymbol><apply id="S3.E3.m1.2.2.1.1.3.3.3.2.2.cmml" xref="S3.E3.m1.2.2.1.1.3.3.3.2.2"><ci id="S3.E3.m1.2.2.1.1.3.3.3.2.2.1.cmml" xref="S3.E3.m1.2.2.1.1.3.3.3.2.2.1">¯</ci><ci id="S3.E3.m1.2.2.1.1.3.3.3.2.2.2.cmml" xref="S3.E3.m1.2.2.1.1.3.3.3.2.2.2">𝑣</ci></apply><ci id="S3.E3.m1.2.2.1.1.3.3.3.2.3.cmml" xref="S3.E3.m1.2.2.1.1.3.3.3.2.3">𝑖</ci></apply><apply id="S3.E3.m1.2.2.1.1.3.3.3.3.cmml" xref="S3.E3.m1.2.2.1.1.3.3.3.3"><divide id="S3.E3.m1.2.2.1.1.3.3.3.3.1.cmml" xref="S3.E3.m1.2.2.1.1.3.3.3.3.1"></divide><ci id="S3.E3.m1.2.2.1.1.3.3.3.3.2.cmml" xref="S3.E3.m1.2.2.1.1.3.3.3.3.2">𝐿</ci><cn type="integer" id="S3.E3.m1.2.2.1.1.3.3.3.3.3.cmml" xref="S3.E3.m1.2.2.1.1.3.3.3.3.3">4</cn></apply></apply></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.2c">\displaystyle\overline{V}_{i}=(\overline{v}_{i}^{1},\overline{v}_{i}^{2},...,\overline{v}_{i}^{L/4}),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.p3.5" class="ltx_p">where <math id="S3.SS1.p3.2.m1.1" class="ltx_Math" alttext="f" display="inline"><semantics id="S3.SS1.p3.2.m1.1a"><mi id="S3.SS1.p3.2.m1.1.1" xref="S3.SS1.p3.2.m1.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.2.m1.1b"><ci id="S3.SS1.p3.2.m1.1.1.cmml" xref="S3.SS1.p3.2.m1.1.1">𝑓</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.2.m1.1c">f</annotation></semantics></math> represents the dot product with kernel weights on multiple channels. After the convolution layer, the visual features of image <math id="S3.SS1.p3.3.m2.1" class="ltx_Math" alttext="I_{i}" display="inline"><semantics id="S3.SS1.p3.3.m2.1a"><msub id="S3.SS1.p3.3.m2.1.1" xref="S3.SS1.p3.3.m2.1.1.cmml"><mi id="S3.SS1.p3.3.m2.1.1.2" xref="S3.SS1.p3.3.m2.1.1.2.cmml">I</mi><mi id="S3.SS1.p3.3.m2.1.1.3" xref="S3.SS1.p3.3.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.3.m2.1b"><apply id="S3.SS1.p3.3.m2.1.1.cmml" xref="S3.SS1.p3.3.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.3.m2.1.1.1.cmml" xref="S3.SS1.p3.3.m2.1.1">subscript</csymbol><ci id="S3.SS1.p3.3.m2.1.1.2.cmml" xref="S3.SS1.p3.3.m2.1.1.2">𝐼</ci><ci id="S3.SS1.p3.3.m2.1.1.3.cmml" xref="S3.SS1.p3.3.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.3.m2.1c">I_{i}</annotation></semantics></math> are converted to the <math id="S3.SS1.p3.4.m3.1" class="ltx_Math" alttext="\overline{V}_{i}" display="inline"><semantics id="S3.SS1.p3.4.m3.1a"><msub id="S3.SS1.p3.4.m3.1.1" xref="S3.SS1.p3.4.m3.1.1.cmml"><mover accent="true" id="S3.SS1.p3.4.m3.1.1.2" xref="S3.SS1.p3.4.m3.1.1.2.cmml"><mi id="S3.SS1.p3.4.m3.1.1.2.2" xref="S3.SS1.p3.4.m3.1.1.2.2.cmml">V</mi><mo id="S3.SS1.p3.4.m3.1.1.2.1" xref="S3.SS1.p3.4.m3.1.1.2.1.cmml">¯</mo></mover><mi id="S3.SS1.p3.4.m3.1.1.3" xref="S3.SS1.p3.4.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.4.m3.1b"><apply id="S3.SS1.p3.4.m3.1.1.cmml" xref="S3.SS1.p3.4.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.4.m3.1.1.1.cmml" xref="S3.SS1.p3.4.m3.1.1">subscript</csymbol><apply id="S3.SS1.p3.4.m3.1.1.2.cmml" xref="S3.SS1.p3.4.m3.1.1.2"><ci id="S3.SS1.p3.4.m3.1.1.2.1.cmml" xref="S3.SS1.p3.4.m3.1.1.2.1">¯</ci><ci id="S3.SS1.p3.4.m3.1.1.2.2.cmml" xref="S3.SS1.p3.4.m3.1.1.2.2">𝑉</ci></apply><ci id="S3.SS1.p3.4.m3.1.1.3.cmml" xref="S3.SS1.p3.4.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.4.m3.1c">\overline{V}_{i}</annotation></semantics></math>, the feature length of which is <math id="S3.SS1.p3.5.m4.1" class="ltx_Math" alttext="L/4" display="inline"><semantics id="S3.SS1.p3.5.m4.1a"><mrow id="S3.SS1.p3.5.m4.1.1" xref="S3.SS1.p3.5.m4.1.1.cmml"><mi id="S3.SS1.p3.5.m4.1.1.2" xref="S3.SS1.p3.5.m4.1.1.2.cmml">L</mi><mo id="S3.SS1.p3.5.m4.1.1.1" xref="S3.SS1.p3.5.m4.1.1.1.cmml">/</mo><mn id="S3.SS1.p3.5.m4.1.1.3" xref="S3.SS1.p3.5.m4.1.1.3.cmml">4</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.5.m4.1b"><apply id="S3.SS1.p3.5.m4.1.1.cmml" xref="S3.SS1.p3.5.m4.1.1"><divide id="S3.SS1.p3.5.m4.1.1.1.cmml" xref="S3.SS1.p3.5.m4.1.1.1"></divide><ci id="S3.SS1.p3.5.m4.1.1.2.cmml" xref="S3.SS1.p3.5.m4.1.1.2">𝐿</ci><cn type="integer" id="S3.SS1.p3.5.m4.1.1.3.cmml" xref="S3.SS1.p3.5.m4.1.1.3">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.5.m4.1c">L/4</annotation></semantics></math>.</p>
</div>
<div id="S3.SS1.p4" class="ltx_para">
<p id="S3.SS1.p4.2" class="ltx_p">Then, with a fully connected layer to align visual features to the language embedding space, the <math id="S3.SS1.p4.1.m1.1" class="ltx_Math" alttext="\overline{V}_{i}" display="inline"><semantics id="S3.SS1.p4.1.m1.1a"><msub id="S3.SS1.p4.1.m1.1.1" xref="S3.SS1.p4.1.m1.1.1.cmml"><mover accent="true" id="S3.SS1.p4.1.m1.1.1.2" xref="S3.SS1.p4.1.m1.1.1.2.cmml"><mi id="S3.SS1.p4.1.m1.1.1.2.2" xref="S3.SS1.p4.1.m1.1.1.2.2.cmml">V</mi><mo id="S3.SS1.p4.1.m1.1.1.2.1" xref="S3.SS1.p4.1.m1.1.1.2.1.cmml">¯</mo></mover><mi id="S3.SS1.p4.1.m1.1.1.3" xref="S3.SS1.p4.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.1.m1.1b"><apply id="S3.SS1.p4.1.m1.1.1.cmml" xref="S3.SS1.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.1.m1.1.1.1.cmml" xref="S3.SS1.p4.1.m1.1.1">subscript</csymbol><apply id="S3.SS1.p4.1.m1.1.1.2.cmml" xref="S3.SS1.p4.1.m1.1.1.2"><ci id="S3.SS1.p4.1.m1.1.1.2.1.cmml" xref="S3.SS1.p4.1.m1.1.1.2.1">¯</ci><ci id="S3.SS1.p4.1.m1.1.1.2.2.cmml" xref="S3.SS1.p4.1.m1.1.1.2.2">𝑉</ci></apply><ci id="S3.SS1.p4.1.m1.1.1.3.cmml" xref="S3.SS1.p4.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.1.m1.1c">\overline{V}_{i}</annotation></semantics></math> are transferred to <math id="S3.SS1.p4.2.m2.4" class="ltx_Math" alttext="\hat{V}_{i}=(\hat{v}_{i}^{1},\hat{v}_{i}^{2},...,\hat{v}_{i}^{L/4})" display="inline"><semantics id="S3.SS1.p4.2.m2.4a"><mrow id="S3.SS1.p4.2.m2.4.4" xref="S3.SS1.p4.2.m2.4.4.cmml"><msub id="S3.SS1.p4.2.m2.4.4.5" xref="S3.SS1.p4.2.m2.4.4.5.cmml"><mover accent="true" id="S3.SS1.p4.2.m2.4.4.5.2" xref="S3.SS1.p4.2.m2.4.4.5.2.cmml"><mi id="S3.SS1.p4.2.m2.4.4.5.2.2" xref="S3.SS1.p4.2.m2.4.4.5.2.2.cmml">V</mi><mo id="S3.SS1.p4.2.m2.4.4.5.2.1" xref="S3.SS1.p4.2.m2.4.4.5.2.1.cmml">^</mo></mover><mi id="S3.SS1.p4.2.m2.4.4.5.3" xref="S3.SS1.p4.2.m2.4.4.5.3.cmml">i</mi></msub><mo id="S3.SS1.p4.2.m2.4.4.4" xref="S3.SS1.p4.2.m2.4.4.4.cmml">=</mo><mrow id="S3.SS1.p4.2.m2.4.4.3.3" xref="S3.SS1.p4.2.m2.4.4.3.4.cmml"><mo stretchy="false" id="S3.SS1.p4.2.m2.4.4.3.3.4" xref="S3.SS1.p4.2.m2.4.4.3.4.cmml">(</mo><msubsup id="S3.SS1.p4.2.m2.2.2.1.1.1" xref="S3.SS1.p4.2.m2.2.2.1.1.1.cmml"><mover accent="true" id="S3.SS1.p4.2.m2.2.2.1.1.1.2.2" xref="S3.SS1.p4.2.m2.2.2.1.1.1.2.2.cmml"><mi id="S3.SS1.p4.2.m2.2.2.1.1.1.2.2.2" xref="S3.SS1.p4.2.m2.2.2.1.1.1.2.2.2.cmml">v</mi><mo id="S3.SS1.p4.2.m2.2.2.1.1.1.2.2.1" xref="S3.SS1.p4.2.m2.2.2.1.1.1.2.2.1.cmml">^</mo></mover><mi id="S3.SS1.p4.2.m2.2.2.1.1.1.2.3" xref="S3.SS1.p4.2.m2.2.2.1.1.1.2.3.cmml">i</mi><mn id="S3.SS1.p4.2.m2.2.2.1.1.1.3" xref="S3.SS1.p4.2.m2.2.2.1.1.1.3.cmml">1</mn></msubsup><mo id="S3.SS1.p4.2.m2.4.4.3.3.5" xref="S3.SS1.p4.2.m2.4.4.3.4.cmml">,</mo><msubsup id="S3.SS1.p4.2.m2.3.3.2.2.2" xref="S3.SS1.p4.2.m2.3.3.2.2.2.cmml"><mover accent="true" id="S3.SS1.p4.2.m2.3.3.2.2.2.2.2" xref="S3.SS1.p4.2.m2.3.3.2.2.2.2.2.cmml"><mi id="S3.SS1.p4.2.m2.3.3.2.2.2.2.2.2" xref="S3.SS1.p4.2.m2.3.3.2.2.2.2.2.2.cmml">v</mi><mo id="S3.SS1.p4.2.m2.3.3.2.2.2.2.2.1" xref="S3.SS1.p4.2.m2.3.3.2.2.2.2.2.1.cmml">^</mo></mover><mi id="S3.SS1.p4.2.m2.3.3.2.2.2.2.3" xref="S3.SS1.p4.2.m2.3.3.2.2.2.2.3.cmml">i</mi><mn id="S3.SS1.p4.2.m2.3.3.2.2.2.3" xref="S3.SS1.p4.2.m2.3.3.2.2.2.3.cmml">2</mn></msubsup><mo id="S3.SS1.p4.2.m2.4.4.3.3.6" xref="S3.SS1.p4.2.m2.4.4.3.4.cmml">,</mo><mi mathvariant="normal" id="S3.SS1.p4.2.m2.1.1" xref="S3.SS1.p4.2.m2.1.1.cmml">…</mi><mo id="S3.SS1.p4.2.m2.4.4.3.3.7" xref="S3.SS1.p4.2.m2.4.4.3.4.cmml">,</mo><msubsup id="S3.SS1.p4.2.m2.4.4.3.3.3" xref="S3.SS1.p4.2.m2.4.4.3.3.3.cmml"><mover accent="true" id="S3.SS1.p4.2.m2.4.4.3.3.3.2.2" xref="S3.SS1.p4.2.m2.4.4.3.3.3.2.2.cmml"><mi id="S3.SS1.p4.2.m2.4.4.3.3.3.2.2.2" xref="S3.SS1.p4.2.m2.4.4.3.3.3.2.2.2.cmml">v</mi><mo id="S3.SS1.p4.2.m2.4.4.3.3.3.2.2.1" xref="S3.SS1.p4.2.m2.4.4.3.3.3.2.2.1.cmml">^</mo></mover><mi id="S3.SS1.p4.2.m2.4.4.3.3.3.2.3" xref="S3.SS1.p4.2.m2.4.4.3.3.3.2.3.cmml">i</mi><mrow id="S3.SS1.p4.2.m2.4.4.3.3.3.3" xref="S3.SS1.p4.2.m2.4.4.3.3.3.3.cmml"><mi id="S3.SS1.p4.2.m2.4.4.3.3.3.3.2" xref="S3.SS1.p4.2.m2.4.4.3.3.3.3.2.cmml">L</mi><mo id="S3.SS1.p4.2.m2.4.4.3.3.3.3.1" xref="S3.SS1.p4.2.m2.4.4.3.3.3.3.1.cmml">/</mo><mn id="S3.SS1.p4.2.m2.4.4.3.3.3.3.3" xref="S3.SS1.p4.2.m2.4.4.3.3.3.3.3.cmml">4</mn></mrow></msubsup><mo stretchy="false" id="S3.SS1.p4.2.m2.4.4.3.3.8" xref="S3.SS1.p4.2.m2.4.4.3.4.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.2.m2.4b"><apply id="S3.SS1.p4.2.m2.4.4.cmml" xref="S3.SS1.p4.2.m2.4.4"><eq id="S3.SS1.p4.2.m2.4.4.4.cmml" xref="S3.SS1.p4.2.m2.4.4.4"></eq><apply id="S3.SS1.p4.2.m2.4.4.5.cmml" xref="S3.SS1.p4.2.m2.4.4.5"><csymbol cd="ambiguous" id="S3.SS1.p4.2.m2.4.4.5.1.cmml" xref="S3.SS1.p4.2.m2.4.4.5">subscript</csymbol><apply id="S3.SS1.p4.2.m2.4.4.5.2.cmml" xref="S3.SS1.p4.2.m2.4.4.5.2"><ci id="S3.SS1.p4.2.m2.4.4.5.2.1.cmml" xref="S3.SS1.p4.2.m2.4.4.5.2.1">^</ci><ci id="S3.SS1.p4.2.m2.4.4.5.2.2.cmml" xref="S3.SS1.p4.2.m2.4.4.5.2.2">𝑉</ci></apply><ci id="S3.SS1.p4.2.m2.4.4.5.3.cmml" xref="S3.SS1.p4.2.m2.4.4.5.3">𝑖</ci></apply><vector id="S3.SS1.p4.2.m2.4.4.3.4.cmml" xref="S3.SS1.p4.2.m2.4.4.3.3"><apply id="S3.SS1.p4.2.m2.2.2.1.1.1.cmml" xref="S3.SS1.p4.2.m2.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.2.m2.2.2.1.1.1.1.cmml" xref="S3.SS1.p4.2.m2.2.2.1.1.1">superscript</csymbol><apply id="S3.SS1.p4.2.m2.2.2.1.1.1.2.cmml" xref="S3.SS1.p4.2.m2.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.2.m2.2.2.1.1.1.2.1.cmml" xref="S3.SS1.p4.2.m2.2.2.1.1.1">subscript</csymbol><apply id="S3.SS1.p4.2.m2.2.2.1.1.1.2.2.cmml" xref="S3.SS1.p4.2.m2.2.2.1.1.1.2.2"><ci id="S3.SS1.p4.2.m2.2.2.1.1.1.2.2.1.cmml" xref="S3.SS1.p4.2.m2.2.2.1.1.1.2.2.1">^</ci><ci id="S3.SS1.p4.2.m2.2.2.1.1.1.2.2.2.cmml" xref="S3.SS1.p4.2.m2.2.2.1.1.1.2.2.2">𝑣</ci></apply><ci id="S3.SS1.p4.2.m2.2.2.1.1.1.2.3.cmml" xref="S3.SS1.p4.2.m2.2.2.1.1.1.2.3">𝑖</ci></apply><cn type="integer" id="S3.SS1.p4.2.m2.2.2.1.1.1.3.cmml" xref="S3.SS1.p4.2.m2.2.2.1.1.1.3">1</cn></apply><apply id="S3.SS1.p4.2.m2.3.3.2.2.2.cmml" xref="S3.SS1.p4.2.m2.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p4.2.m2.3.3.2.2.2.1.cmml" xref="S3.SS1.p4.2.m2.3.3.2.2.2">superscript</csymbol><apply id="S3.SS1.p4.2.m2.3.3.2.2.2.2.cmml" xref="S3.SS1.p4.2.m2.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p4.2.m2.3.3.2.2.2.2.1.cmml" xref="S3.SS1.p4.2.m2.3.3.2.2.2">subscript</csymbol><apply id="S3.SS1.p4.2.m2.3.3.2.2.2.2.2.cmml" xref="S3.SS1.p4.2.m2.3.3.2.2.2.2.2"><ci id="S3.SS1.p4.2.m2.3.3.2.2.2.2.2.1.cmml" xref="S3.SS1.p4.2.m2.3.3.2.2.2.2.2.1">^</ci><ci id="S3.SS1.p4.2.m2.3.3.2.2.2.2.2.2.cmml" xref="S3.SS1.p4.2.m2.3.3.2.2.2.2.2.2">𝑣</ci></apply><ci id="S3.SS1.p4.2.m2.3.3.2.2.2.2.3.cmml" xref="S3.SS1.p4.2.m2.3.3.2.2.2.2.3">𝑖</ci></apply><cn type="integer" id="S3.SS1.p4.2.m2.3.3.2.2.2.3.cmml" xref="S3.SS1.p4.2.m2.3.3.2.2.2.3">2</cn></apply><ci id="S3.SS1.p4.2.m2.1.1.cmml" xref="S3.SS1.p4.2.m2.1.1">…</ci><apply id="S3.SS1.p4.2.m2.4.4.3.3.3.cmml" xref="S3.SS1.p4.2.m2.4.4.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.p4.2.m2.4.4.3.3.3.1.cmml" xref="S3.SS1.p4.2.m2.4.4.3.3.3">superscript</csymbol><apply id="S3.SS1.p4.2.m2.4.4.3.3.3.2.cmml" xref="S3.SS1.p4.2.m2.4.4.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.p4.2.m2.4.4.3.3.3.2.1.cmml" xref="S3.SS1.p4.2.m2.4.4.3.3.3">subscript</csymbol><apply id="S3.SS1.p4.2.m2.4.4.3.3.3.2.2.cmml" xref="S3.SS1.p4.2.m2.4.4.3.3.3.2.2"><ci id="S3.SS1.p4.2.m2.4.4.3.3.3.2.2.1.cmml" xref="S3.SS1.p4.2.m2.4.4.3.3.3.2.2.1">^</ci><ci id="S3.SS1.p4.2.m2.4.4.3.3.3.2.2.2.cmml" xref="S3.SS1.p4.2.m2.4.4.3.3.3.2.2.2">𝑣</ci></apply><ci id="S3.SS1.p4.2.m2.4.4.3.3.3.2.3.cmml" xref="S3.SS1.p4.2.m2.4.4.3.3.3.2.3">𝑖</ci></apply><apply id="S3.SS1.p4.2.m2.4.4.3.3.3.3.cmml" xref="S3.SS1.p4.2.m2.4.4.3.3.3.3"><divide id="S3.SS1.p4.2.m2.4.4.3.3.3.3.1.cmml" xref="S3.SS1.p4.2.m2.4.4.3.3.3.3.1"></divide><ci id="S3.SS1.p4.2.m2.4.4.3.3.3.3.2.cmml" xref="S3.SS1.p4.2.m2.4.4.3.3.3.3.2">𝐿</ci><cn type="integer" id="S3.SS1.p4.2.m2.4.4.3.3.3.3.3.cmml" xref="S3.SS1.p4.2.m2.4.4.3.3.3.3.3">4</cn></apply></apply></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.2.m2.4c">\hat{V}_{i}=(\hat{v}_{i}^{1},\hat{v}_{i}^{2},...,\hat{v}_{i}^{L/4})</annotation></semantics></math>.</p>
</div>
<div id="S3.SS1.p5" class="ltx_para ltx_noindent">
<p id="S3.SS1.p5.4" class="ltx_p"><span id="S3.SS1.p5.4.3" class="ltx_text ltx_font_bold">Multimodal Modeling with LLM.</span> As the decoder of MLLM, large language models should understand both the visual features of images and the textual features of language instructions. Following mPLUG-Owl2 <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite>, we apply the Modality-adaptive Module(MAM) in LLM to better distinguish visual and textual inputs. During self-attention, MAM utilizes two sets of linear projection layers to separately perform the key/value projection for visual features and textual features.
To help the LLM correlate multiple cropped sub-images, UReader <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite> designs learnable crop position embeddings to denote the row and column position in the raw image. In this work, we simply add special textual tokens <span id="S3.SS1.p5.2.2" class="ltx_text ltx_font_typewriter">‘&lt;row<math id="S3.SS1.p5.1.1.m1.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S3.SS1.p5.1.1.m1.1a"><mi id="S3.SS1.p5.1.1.m1.1.1" xref="S3.SS1.p5.1.1.m1.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.1.1.m1.1b"><ci id="S3.SS1.p5.1.1.m1.1.1.cmml" xref="S3.SS1.p5.1.1.m1.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.1.1.m1.1c">x</annotation></semantics></math>_col<math id="S3.SS1.p5.2.2.m2.1" class="ltx_Math" alttext="y" display="inline"><semantics id="S3.SS1.p5.2.2.m2.1a"><mi id="S3.SS1.p5.2.2.m2.1.1" xref="S3.SS1.p5.2.2.m2.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.2.2.m2.1b"><ci id="S3.SS1.p5.2.2.m2.1.1.cmml" xref="S3.SS1.p5.2.2.m2.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.2.2.m2.1c">y</annotation></semantics></math>&gt;’</span> before the visual features of each cropped image, where <math id="S3.SS1.p5.3.m1.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S3.SS1.p5.3.m1.1a"><mi id="S3.SS1.p5.3.m1.1.1" xref="S3.SS1.p5.3.m1.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.3.m1.1b"><ci id="S3.SS1.p5.3.m1.1.1.cmml" xref="S3.SS1.p5.3.m1.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.3.m1.1c">x</annotation></semantics></math> and <math id="S3.SS1.p5.4.m2.1" class="ltx_Math" alttext="y" display="inline"><semantics id="S3.SS1.p5.4.m2.1a"><mi id="S3.SS1.p5.4.m2.1.1" xref="S3.SS1.p5.4.m2.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.4.m2.1b"><ci id="S3.SS1.p5.4.m2.1.1.cmml" xref="S3.SS1.p5.4.m2.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.4.m2.1c">y</annotation></semantics></math> refer to the row and column index respectively. For the global image, the textual indicator token is <span id="S3.SS1.p5.4.4" class="ltx_text ltx_font_typewriter">‘&lt;global_img&gt;’</span>.
This design eliminates the need to introduce additional parameters and is more friendly to the LLM decoder. Our experiments validate that it achieves comparable effects as the crop position embedding. Overall, the decoding of the LLM is as follows:</p>
<table id="S6.EGx2" class="ltx_equationgroup ltx_eqn_gather ltx_eqn_table">

<tbody id="S3.E4"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E4.m1.3" class="ltx_Math" alttext="\displaystyle Y=\rm{LLM}([T_{0};\hat{V}_{0},T_{1};\hat{V}_{1},...,T_{C};\hat{V}_{C};X])" display="block"><semantics id="S3.E4.m1.3a"><mrow id="S3.E4.m1.3.3" xref="S3.E4.m1.3.3.cmml"><mi id="S3.E4.m1.3.3.3" xref="S3.E4.m1.3.3.3.cmml">Y</mi><mo id="S3.E4.m1.3.3.2" xref="S3.E4.m1.3.3.2.cmml">=</mo><mrow id="S3.E4.m1.3.3.1" xref="S3.E4.m1.3.3.1.cmml"><mi id="S3.E4.m1.3.3.1.3" xref="S3.E4.m1.3.3.1.3.cmml">LLM</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.3.3.1.2" xref="S3.E4.m1.3.3.1.2.cmml">​</mo><mrow id="S3.E4.m1.3.3.1.1.1" xref="S3.E4.m1.3.3.1.cmml"><mo stretchy="false" id="S3.E4.m1.3.3.1.1.1.2" xref="S3.E4.m1.3.3.1.cmml">(</mo><mrow id="S3.E4.m1.3.3.1.1.1.1.6" xref="S3.E4.m1.3.3.1.1.1.1.7.cmml"><mo stretchy="false" id="S3.E4.m1.3.3.1.1.1.1.6.7" xref="S3.E4.m1.3.3.1.1.1.1.7.cmml">[</mo><msub id="S3.E4.m1.3.3.1.1.1.1.1.1" xref="S3.E4.m1.3.3.1.1.1.1.1.1.cmml"><mi mathvariant="normal" id="S3.E4.m1.3.3.1.1.1.1.1.1.2" xref="S3.E4.m1.3.3.1.1.1.1.1.1.2.cmml">T</mi><mn id="S3.E4.m1.3.3.1.1.1.1.1.1.3" xref="S3.E4.m1.3.3.1.1.1.1.1.1.3.cmml">0</mn></msub><mo id="S3.E4.m1.3.3.1.1.1.1.6.8" xref="S3.E4.m1.3.3.1.1.1.1.7.cmml">;</mo><msub id="S3.E4.m1.3.3.1.1.1.1.2.2" xref="S3.E4.m1.3.3.1.1.1.1.2.2.cmml"><mover accent="true" id="S3.E4.m1.3.3.1.1.1.1.2.2.2" xref="S3.E4.m1.3.3.1.1.1.1.2.2.2.cmml"><mi mathvariant="normal" id="S3.E4.m1.3.3.1.1.1.1.2.2.2.2" xref="S3.E4.m1.3.3.1.1.1.1.2.2.2.2.cmml">V</mi><mo id="S3.E4.m1.3.3.1.1.1.1.2.2.2.1" xref="S3.E4.m1.3.3.1.1.1.1.2.2.2.1.cmml">^</mo></mover><mn id="S3.E4.m1.3.3.1.1.1.1.2.2.3" xref="S3.E4.m1.3.3.1.1.1.1.2.2.3.cmml">0</mn></msub><mo id="S3.E4.m1.3.3.1.1.1.1.6.9" xref="S3.E4.m1.3.3.1.1.1.1.7.cmml">,</mo><msub id="S3.E4.m1.3.3.1.1.1.1.3.3" xref="S3.E4.m1.3.3.1.1.1.1.3.3.cmml"><mi mathvariant="normal" id="S3.E4.m1.3.3.1.1.1.1.3.3.2" xref="S3.E4.m1.3.3.1.1.1.1.3.3.2.cmml">T</mi><mn id="S3.E4.m1.3.3.1.1.1.1.3.3.3" xref="S3.E4.m1.3.3.1.1.1.1.3.3.3.cmml">1</mn></msub><mo id="S3.E4.m1.3.3.1.1.1.1.6.10" xref="S3.E4.m1.3.3.1.1.1.1.7.cmml">;</mo><msub id="S3.E4.m1.3.3.1.1.1.1.4.4" xref="S3.E4.m1.3.3.1.1.1.1.4.4.cmml"><mover accent="true" id="S3.E4.m1.3.3.1.1.1.1.4.4.2" xref="S3.E4.m1.3.3.1.1.1.1.4.4.2.cmml"><mi mathvariant="normal" id="S3.E4.m1.3.3.1.1.1.1.4.4.2.2" xref="S3.E4.m1.3.3.1.1.1.1.4.4.2.2.cmml">V</mi><mo id="S3.E4.m1.3.3.1.1.1.1.4.4.2.1" xref="S3.E4.m1.3.3.1.1.1.1.4.4.2.1.cmml">^</mo></mover><mn id="S3.E4.m1.3.3.1.1.1.1.4.4.3" xref="S3.E4.m1.3.3.1.1.1.1.4.4.3.cmml">1</mn></msub><mo id="S3.E4.m1.3.3.1.1.1.1.6.11" xref="S3.E4.m1.3.3.1.1.1.1.7.cmml">,</mo><mi mathvariant="normal" id="S3.E4.m1.1.1" xref="S3.E4.m1.1.1.cmml">…</mi><mo id="S3.E4.m1.3.3.1.1.1.1.6.12" xref="S3.E4.m1.3.3.1.1.1.1.7.cmml">,</mo><msub id="S3.E4.m1.3.3.1.1.1.1.5.5" xref="S3.E4.m1.3.3.1.1.1.1.5.5.cmml"><mi mathvariant="normal" id="S3.E4.m1.3.3.1.1.1.1.5.5.2" xref="S3.E4.m1.3.3.1.1.1.1.5.5.2.cmml">T</mi><mi mathvariant="normal" id="S3.E4.m1.3.3.1.1.1.1.5.5.3" xref="S3.E4.m1.3.3.1.1.1.1.5.5.3.cmml">C</mi></msub><mo id="S3.E4.m1.3.3.1.1.1.1.6.13" xref="S3.E4.m1.3.3.1.1.1.1.7.cmml">;</mo><msub id="S3.E4.m1.3.3.1.1.1.1.6.6" xref="S3.E4.m1.3.3.1.1.1.1.6.6.cmml"><mover accent="true" id="S3.E4.m1.3.3.1.1.1.1.6.6.2" xref="S3.E4.m1.3.3.1.1.1.1.6.6.2.cmml"><mi mathvariant="normal" id="S3.E4.m1.3.3.1.1.1.1.6.6.2.2" xref="S3.E4.m1.3.3.1.1.1.1.6.6.2.2.cmml">V</mi><mo id="S3.E4.m1.3.3.1.1.1.1.6.6.2.1" xref="S3.E4.m1.3.3.1.1.1.1.6.6.2.1.cmml">^</mo></mover><mi mathvariant="normal" id="S3.E4.m1.3.3.1.1.1.1.6.6.3" xref="S3.E4.m1.3.3.1.1.1.1.6.6.3.cmml">C</mi></msub><mo id="S3.E4.m1.3.3.1.1.1.1.6.14" xref="S3.E4.m1.3.3.1.1.1.1.7.cmml">;</mo><mi mathvariant="normal" id="S3.E4.m1.2.2" xref="S3.E4.m1.2.2.cmml">X</mi><mo stretchy="false" id="S3.E4.m1.3.3.1.1.1.1.6.15" xref="S3.E4.m1.3.3.1.1.1.1.7.cmml">]</mo></mrow><mo stretchy="false" id="S3.E4.m1.3.3.1.1.1.3" xref="S3.E4.m1.3.3.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.3b"><apply id="S3.E4.m1.3.3.cmml" xref="S3.E4.m1.3.3"><eq id="S3.E4.m1.3.3.2.cmml" xref="S3.E4.m1.3.3.2"></eq><ci id="S3.E4.m1.3.3.3.cmml" xref="S3.E4.m1.3.3.3">𝑌</ci><apply id="S3.E4.m1.3.3.1.cmml" xref="S3.E4.m1.3.3.1"><times id="S3.E4.m1.3.3.1.2.cmml" xref="S3.E4.m1.3.3.1.2"></times><ci id="S3.E4.m1.3.3.1.3.cmml" xref="S3.E4.m1.3.3.1.3">LLM</ci><list id="S3.E4.m1.3.3.1.1.1.1.7.cmml" xref="S3.E4.m1.3.3.1.1.1.1.6"><apply id="S3.E4.m1.3.3.1.1.1.1.1.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E4.m1.3.3.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.2">T</ci><cn type="integer" id="S3.E4.m1.3.3.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.3.3.1.1.1.1.1.1.3">0</cn></apply><apply id="S3.E4.m1.3.3.1.1.1.1.2.2.cmml" xref="S3.E4.m1.3.3.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.1.1.1.1.2.2.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.2.2">subscript</csymbol><apply id="S3.E4.m1.3.3.1.1.1.1.2.2.2.cmml" xref="S3.E4.m1.3.3.1.1.1.1.2.2.2"><ci id="S3.E4.m1.3.3.1.1.1.1.2.2.2.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.2.2.2.1">^</ci><ci id="S3.E4.m1.3.3.1.1.1.1.2.2.2.2.cmml" xref="S3.E4.m1.3.3.1.1.1.1.2.2.2.2">V</ci></apply><cn type="integer" id="S3.E4.m1.3.3.1.1.1.1.2.2.3.cmml" xref="S3.E4.m1.3.3.1.1.1.1.2.2.3">0</cn></apply><apply id="S3.E4.m1.3.3.1.1.1.1.3.3.cmml" xref="S3.E4.m1.3.3.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.1.1.1.1.3.3.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.3.3">subscript</csymbol><ci id="S3.E4.m1.3.3.1.1.1.1.3.3.2.cmml" xref="S3.E4.m1.3.3.1.1.1.1.3.3.2">T</ci><cn type="integer" id="S3.E4.m1.3.3.1.1.1.1.3.3.3.cmml" xref="S3.E4.m1.3.3.1.1.1.1.3.3.3">1</cn></apply><apply id="S3.E4.m1.3.3.1.1.1.1.4.4.cmml" xref="S3.E4.m1.3.3.1.1.1.1.4.4"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.1.1.1.1.4.4.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.4.4">subscript</csymbol><apply id="S3.E4.m1.3.3.1.1.1.1.4.4.2.cmml" xref="S3.E4.m1.3.3.1.1.1.1.4.4.2"><ci id="S3.E4.m1.3.3.1.1.1.1.4.4.2.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.4.4.2.1">^</ci><ci id="S3.E4.m1.3.3.1.1.1.1.4.4.2.2.cmml" xref="S3.E4.m1.3.3.1.1.1.1.4.4.2.2">V</ci></apply><cn type="integer" id="S3.E4.m1.3.3.1.1.1.1.4.4.3.cmml" xref="S3.E4.m1.3.3.1.1.1.1.4.4.3">1</cn></apply><ci id="S3.E4.m1.1.1.cmml" xref="S3.E4.m1.1.1">…</ci><apply id="S3.E4.m1.3.3.1.1.1.1.5.5.cmml" xref="S3.E4.m1.3.3.1.1.1.1.5.5"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.1.1.1.1.5.5.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.5.5">subscript</csymbol><ci id="S3.E4.m1.3.3.1.1.1.1.5.5.2.cmml" xref="S3.E4.m1.3.3.1.1.1.1.5.5.2">T</ci><ci id="S3.E4.m1.3.3.1.1.1.1.5.5.3.cmml" xref="S3.E4.m1.3.3.1.1.1.1.5.5.3">C</ci></apply><apply id="S3.E4.m1.3.3.1.1.1.1.6.6.cmml" xref="S3.E4.m1.3.3.1.1.1.1.6.6"><csymbol cd="ambiguous" id="S3.E4.m1.3.3.1.1.1.1.6.6.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.6.6">subscript</csymbol><apply id="S3.E4.m1.3.3.1.1.1.1.6.6.2.cmml" xref="S3.E4.m1.3.3.1.1.1.1.6.6.2"><ci id="S3.E4.m1.3.3.1.1.1.1.6.6.2.1.cmml" xref="S3.E4.m1.3.3.1.1.1.1.6.6.2.1">^</ci><ci id="S3.E4.m1.3.3.1.1.1.1.6.6.2.2.cmml" xref="S3.E4.m1.3.3.1.1.1.1.6.6.2.2">V</ci></apply><ci id="S3.E4.m1.3.3.1.1.1.1.6.6.3.cmml" xref="S3.E4.m1.3.3.1.1.1.1.6.6.3">C</ci></apply><ci id="S3.E4.m1.2.2.cmml" xref="S3.E4.m1.2.2">X</ci></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.3c">\displaystyle Y=\rm{LLM}([T_{0};\hat{V}_{0},T_{1};\hat{V}_{1},...,T_{C};\hat{V}_{C};X])</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.p5.10" class="ltx_p">where <math id="S3.SS1.p5.5.m1.1" class="ltx_math_unparsed" alttext="[;]" display="inline"><semantics id="S3.SS1.p5.5.m1.1a"><mrow id="S3.SS1.p5.5.m1.1b"><mo stretchy="false" id="S3.SS1.p5.5.m1.1.1">[</mo><mo id="S3.SS1.p5.5.m1.1.2">;</mo><mo stretchy="false" id="S3.SS1.p5.5.m1.1.3">]</mo></mrow><annotation encoding="application/x-tex" id="S3.SS1.p5.5.m1.1c">[;]</annotation></semantics></math> means the concatenation operation, <math id="S3.SS1.p5.6.m2.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S3.SS1.p5.6.m2.1a"><mi id="S3.SS1.p5.6.m2.1.1" xref="S3.SS1.p5.6.m2.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.6.m2.1b"><ci id="S3.SS1.p5.6.m2.1.1.cmml" xref="S3.SS1.p5.6.m2.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.6.m2.1c">C</annotation></semantics></math> is the crop number of the image, <math id="S3.SS1.p5.7.m3.2" class="ltx_Math" alttext="T_{j},0\leq j\leq C" display="inline"><semantics id="S3.SS1.p5.7.m3.2a"><mrow id="S3.SS1.p5.7.m3.2.2" xref="S3.SS1.p5.7.m3.2.2.cmml"><mrow id="S3.SS1.p5.7.m3.2.2.1.1" xref="S3.SS1.p5.7.m3.2.2.1.2.cmml"><msub id="S3.SS1.p5.7.m3.2.2.1.1.1" xref="S3.SS1.p5.7.m3.2.2.1.1.1.cmml"><mi id="S3.SS1.p5.7.m3.2.2.1.1.1.2" xref="S3.SS1.p5.7.m3.2.2.1.1.1.2.cmml">T</mi><mi id="S3.SS1.p5.7.m3.2.2.1.1.1.3" xref="S3.SS1.p5.7.m3.2.2.1.1.1.3.cmml">j</mi></msub><mo id="S3.SS1.p5.7.m3.2.2.1.1.2" xref="S3.SS1.p5.7.m3.2.2.1.2.cmml">,</mo><mn id="S3.SS1.p5.7.m3.1.1" xref="S3.SS1.p5.7.m3.1.1.cmml">0</mn></mrow><mo id="S3.SS1.p5.7.m3.2.2.3" xref="S3.SS1.p5.7.m3.2.2.3.cmml">≤</mo><mi id="S3.SS1.p5.7.m3.2.2.4" xref="S3.SS1.p5.7.m3.2.2.4.cmml">j</mi><mo id="S3.SS1.p5.7.m3.2.2.5" xref="S3.SS1.p5.7.m3.2.2.5.cmml">≤</mo><mi id="S3.SS1.p5.7.m3.2.2.6" xref="S3.SS1.p5.7.m3.2.2.6.cmml">C</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.7.m3.2b"><apply id="S3.SS1.p5.7.m3.2.2.cmml" xref="S3.SS1.p5.7.m3.2.2"><and id="S3.SS1.p5.7.m3.2.2a.cmml" xref="S3.SS1.p5.7.m3.2.2"></and><apply id="S3.SS1.p5.7.m3.2.2b.cmml" xref="S3.SS1.p5.7.m3.2.2"><leq id="S3.SS1.p5.7.m3.2.2.3.cmml" xref="S3.SS1.p5.7.m3.2.2.3"></leq><list id="S3.SS1.p5.7.m3.2.2.1.2.cmml" xref="S3.SS1.p5.7.m3.2.2.1.1"><apply id="S3.SS1.p5.7.m3.2.2.1.1.1.cmml" xref="S3.SS1.p5.7.m3.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p5.7.m3.2.2.1.1.1.1.cmml" xref="S3.SS1.p5.7.m3.2.2.1.1.1">subscript</csymbol><ci id="S3.SS1.p5.7.m3.2.2.1.1.1.2.cmml" xref="S3.SS1.p5.7.m3.2.2.1.1.1.2">𝑇</ci><ci id="S3.SS1.p5.7.m3.2.2.1.1.1.3.cmml" xref="S3.SS1.p5.7.m3.2.2.1.1.1.3">𝑗</ci></apply><cn type="integer" id="S3.SS1.p5.7.m3.1.1.cmml" xref="S3.SS1.p5.7.m3.1.1">0</cn></list><ci id="S3.SS1.p5.7.m3.2.2.4.cmml" xref="S3.SS1.p5.7.m3.2.2.4">𝑗</ci></apply><apply id="S3.SS1.p5.7.m3.2.2c.cmml" xref="S3.SS1.p5.7.m3.2.2"><leq id="S3.SS1.p5.7.m3.2.2.5.cmml" xref="S3.SS1.p5.7.m3.2.2.5"></leq><share href="#S3.SS1.p5.7.m3.2.2.4.cmml" id="S3.SS1.p5.7.m3.2.2d.cmml" xref="S3.SS1.p5.7.m3.2.2"></share><ci id="S3.SS1.p5.7.m3.2.2.6.cmml" xref="S3.SS1.p5.7.m3.2.2.6">𝐶</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.7.m3.2c">T_{j},0\leq j\leq C</annotation></semantics></math> is the textual embeddings of the special textual indicator for the global image or positions of cropped images, <math id="S3.SS1.p5.8.m4.1" class="ltx_Math" alttext="\hat{V}_{j}" display="inline"><semantics id="S3.SS1.p5.8.m4.1a"><msub id="S3.SS1.p5.8.m4.1.1" xref="S3.SS1.p5.8.m4.1.1.cmml"><mover accent="true" id="S3.SS1.p5.8.m4.1.1.2" xref="S3.SS1.p5.8.m4.1.1.2.cmml"><mi id="S3.SS1.p5.8.m4.1.1.2.2" xref="S3.SS1.p5.8.m4.1.1.2.2.cmml">V</mi><mo id="S3.SS1.p5.8.m4.1.1.2.1" xref="S3.SS1.p5.8.m4.1.1.2.1.cmml">^</mo></mover><mi id="S3.SS1.p5.8.m4.1.1.3" xref="S3.SS1.p5.8.m4.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.8.m4.1b"><apply id="S3.SS1.p5.8.m4.1.1.cmml" xref="S3.SS1.p5.8.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p5.8.m4.1.1.1.cmml" xref="S3.SS1.p5.8.m4.1.1">subscript</csymbol><apply id="S3.SS1.p5.8.m4.1.1.2.cmml" xref="S3.SS1.p5.8.m4.1.1.2"><ci id="S3.SS1.p5.8.m4.1.1.2.1.cmml" xref="S3.SS1.p5.8.m4.1.1.2.1">^</ci><ci id="S3.SS1.p5.8.m4.1.1.2.2.cmml" xref="S3.SS1.p5.8.m4.1.1.2.2">𝑉</ci></apply><ci id="S3.SS1.p5.8.m4.1.1.3.cmml" xref="S3.SS1.p5.8.m4.1.1.3">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.8.m4.1c">\hat{V}_{j}</annotation></semantics></math> is the visual features of a global or cropped image, <math id="S3.SS1.p5.9.m5.1" class="ltx_Math" alttext="X" display="inline"><semantics id="S3.SS1.p5.9.m5.1a"><mi id="S3.SS1.p5.9.m5.1.1" xref="S3.SS1.p5.9.m5.1.1.cmml">X</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.9.m5.1b"><ci id="S3.SS1.p5.9.m5.1.1.cmml" xref="S3.SS1.p5.9.m5.1.1">𝑋</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.9.m5.1c">X</annotation></semantics></math> is the textual embeddings of the instruction, <math id="S3.SS1.p5.10.m6.1" class="ltx_Math" alttext="Y" display="inline"><semantics id="S3.SS1.p5.10.m6.1a"><mi id="S3.SS1.p5.10.m6.1.1" xref="S3.SS1.p5.10.m6.1.1.cmml">Y</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.10.m6.1b"><ci id="S3.SS1.p5.10.m6.1.1.cmml" xref="S3.SS1.p5.10.m6.1.1">𝑌</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.10.m6.1c">Y</annotation></semantics></math> is the predicted answer.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Unified Structure Learning</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">Most Multimodal Large Language Models <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib58" title="" class="ltx_ref">58</a>, <a href="#bib.bib50" title="" class="ltx_ref">50</a>]</cite> are trained with image-text pairs of natural images to align the visual encoder with the LLM, such as Conceptual Captions <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>, LAION <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite> and COYO <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. Initializing from such models could inherit the shallow text recognition ability, but is far from understanding complex textual and structural information in various text-rich images. In this work, to empower the comprehensive document understanding abilities of MLLM, we design a Unified Structure Learning across 5 domains, including natural images, documents, tables, charts, and webpages. It involves both structure-aware parsing tasks and multi-grained text localization tasks, as shown in <a href="#S3.F4" title="In 3.2 Unified Structure Learning ‣ 3 DocOwl 1.5 ‣ mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<figure id="S3.F4" class="ltx_figure"><img src="/html/2403.12895/assets/x4.png" id="S3.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="287" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>The illustration of Unified Structure Learning of DocOwl 1.5.</figcaption>
</figure>
<div id="S3.SS2.p2" class="ltx_para ltx_noindent">
<p id="S3.SS2.p2.1" class="ltx_p"><span id="S3.SS2.p2.1.2" class="ltx_text ltx_font_bold">Document Parsing.</span>
For representing the structure information, Pix2Struct <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> parses webpage screenshots with condensed HTML DOM trees, which are built based on the HTML source codes and are not available for other formats of documents or webpage screenshots, e.g. PDF. In documents or webpages, horizontal and vertical distances between texts form the main layout information. Therefore, to make the structure-aware parsing task applicable to most documents and webpage screenshots, we choose to add extra line feeds(<span id="S3.SS2.p2.1.1" class="ltx_text ltx_font_typewriter">‘<math id="S3.SS2.p2.1.1.m1.1" class="ltx_Math" alttext="\textbackslash n" display="inline"><semantics id="S3.SS2.p2.1.1.m1.1a"><mrow id="S3.SS2.p2.1.1.m1.1.1" xref="S3.SS2.p2.1.1.m1.1.1.cmml"><mi mathvariant="normal" id="S3.SS2.p2.1.1.m1.1.1.2" xref="S3.SS2.p2.1.1.m1.1.1.2.cmml">\</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p2.1.1.m1.1.1.1" xref="S3.SS2.p2.1.1.m1.1.1.1.cmml">​</mo><mi id="S3.SS2.p2.1.1.m1.1.1.3" xref="S3.SS2.p2.1.1.m1.1.1.3.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.1.m1.1b"><apply id="S3.SS2.p2.1.1.m1.1.1.cmml" xref="S3.SS2.p2.1.1.m1.1.1"><times id="S3.SS2.p2.1.1.m1.1.1.1.cmml" xref="S3.SS2.p2.1.1.m1.1.1.1"></times><ci id="S3.SS2.p2.1.1.m1.1.1.2.cmml" xref="S3.SS2.p2.1.1.m1.1.1.2">\</ci><ci id="S3.SS2.p2.1.1.m1.1.1.3.cmml" xref="S3.SS2.p2.1.1.m1.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.1.m1.1c">\textbackslash n</annotation></semantics></math>’</span>) and spaces into the text sequence to denote different lines and horizontal distances. The greater the horizontal distance, the more space characters.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.1" class="ltx_p">We choose CCpdf <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite>, RVL-CDIP <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>, VisualMRC <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite> and datasets encapsulated in DUE-Benchmark <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> (DocVQA <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>, InfoVQA <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>, DeepForm <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite>, KLC <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>, WTQ <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>, TabFact <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>) to support the Document Parsing task. CCpdf <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite> is a multi-lingual PDF dataset built upon webpages from Common Cramwl<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a target="_blank" href="https://commoncrawl.org" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://commoncrawl.org</a></span></span></span>, covering diverse domains of documents, such as industry, academic, and medical. In this work, we mainly focus on English Document Understanding and drop PDFs detected as other languages. RVL-CDIP contains 16 categories of industry documents, such as ‘letter’, ‘email’, and ‘scientific reports’. We further remove some categories with flipping and blurring texts, such as ‘handwritten’ and ‘form’. DUE-Benchmark is a collection of available and reformulated datasets over various document domains and layouts featuring tables, graphs, lists, and infographics. VisualMRC is a webpage screenshot dataset across 35 websites. OCR annotations in VisualMRC are aligned with local regions, thus, we follow them to utilize crops of a screenshot as input for this parsing task.
For CCpdf and DUE-Benchmark, a PDF-parsing tool pdfplumber<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a target="_blank" href="https://github.com/jsvine/pdfplumber" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/jsvine/pdfplumber</a></span></span></span> can be directly used to generate structure-aware text sequence with a PDF page as the input. For RVL-CDIP and VisualMRC, there are no PDF files, just annotations of bounding boxes of texts.
As an alternative, akin to the LATIN-Prompt <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib51" title="" class="ltx_ref">51</a>]</cite>, we insert the line feeds and spaces by calculating and comparing the horizontal and vertical distances of bounding boxes. To avoid too many space characters resulting in sparse texts, we further limit the maximum number of consecutive spaces to 4. This strategy allows us to construct structure-aware text sequences in the same style as pdfplumber.</p>
</div>
<div id="S3.SS2.p4" class="ltx_para ltx_noindent">
<p id="S3.SS2.p4.1" class="ltx_p"><span id="S3.SS2.p4.1.2" class="ltx_text ltx_font_bold">Table Parsing.</span> Different from documents or webpages, tables are structured in a more standardized way, where row and column correspondences represent key-value pairs. HTML and Markdown codes are mainly two kinds of text sequences used to represent a table. HTML codes can represent all kinds of tables, with or without cells spanning multiple rows and grids, but they contain too many paired labels (e.g. <span id="S3.SS2.p4.1.3" class="ltx_text ltx_font_typewriter">‘&lt;tr&gt;&lt;/tr&gt;’</span> and <span id="S3.SS2.p4.1.4" class="ltx_text ltx_font_typewriter">‘&lt;td&gt;&lt;/td&gt;’</span>), causing text sequences to be too long. Markdown codes can represent a table with concise text sequence, but they cannot represent cells spanning multiple rows and columns. To represent all tables with concise text sequence, we follow the main grammar of Markdown to represent table structure with <span id="S3.SS2.p4.1.5" class="ltx_text ltx_font_typewriter">‘|’</span> and line feeds(<span id="S3.SS2.p4.1.1" class="ltx_text ltx_font_typewriter">‘<math id="S3.SS2.p4.1.1.m1.1" class="ltx_Math" alttext="\textbackslash n" display="inline"><semantics id="S3.SS2.p4.1.1.m1.1a"><mrow id="S3.SS2.p4.1.1.m1.1.1" xref="S3.SS2.p4.1.1.m1.1.1.cmml"><mi mathvariant="normal" id="S3.SS2.p4.1.1.m1.1.1.2" xref="S3.SS2.p4.1.1.m1.1.1.2.cmml">\</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p4.1.1.m1.1.1.1" xref="S3.SS2.p4.1.1.m1.1.1.1.cmml">​</mo><mi id="S3.SS2.p4.1.1.m1.1.1.3" xref="S3.SS2.p4.1.1.m1.1.1.3.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.1.1.m1.1b"><apply id="S3.SS2.p4.1.1.m1.1.1.cmml" xref="S3.SS2.p4.1.1.m1.1.1"><times id="S3.SS2.p4.1.1.m1.1.1.1.cmml" xref="S3.SS2.p4.1.1.m1.1.1.1"></times><ci id="S3.SS2.p4.1.1.m1.1.1.2.cmml" xref="S3.SS2.p4.1.1.m1.1.1.2">\</ci><ci id="S3.SS2.p4.1.1.m1.1.1.3.cmml" xref="S3.SS2.p4.1.1.m1.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.1.1.m1.1c">\textbackslash n</annotation></semantics></math>’</span>). To represent cells spanning multiple rows and columns, we add special text tokens <span id="S3.SS2.p4.1.6" class="ltx_text ltx_font_typewriter">‘&lt;COLSPAN=x&gt;’</span> and <span id="S3.SS2.p4.1.7" class="ltx_text ltx_font_typewriter">‘&lt;ROWSPAN=y&gt;’</span> before the value, as shown in <a href="#S3.F4" title="In 3.2 Unified Structure Learning ‣ 3 DocOwl 1.5 ‣ mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<div id="S3.SS2.p5" class="ltx_para">
<p id="S3.SS2.p5.1" class="ltx_p">We choose TURL <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> and PubTabNet <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib63" title="" class="ltx_ref">63</a>]</cite> to do the structure-aware table parsing task, where tables are collected from Wikipedia pages and scientific articles, respectively. Without cells across rows and columns, tables in TURL can be directly represented with Markdown codes. Due to lacking table images in TURL, we transfer tables into HTML codes and render table images with variations in background color and font size. PubTabNet contains pairs of table images and HTML codes. We convert HTML codes into Markdown style and add <span id="S3.SS2.p5.1.1" class="ltx_text ltx_font_typewriter">‘&lt;ROWSPAN=x&gt;’</span> or <span id="S3.SS2.p5.1.2" class="ltx_text ltx_font_typewriter">‘&lt;COLSPAN=y&gt;’</span> before the value when attributes <span id="S3.SS2.p5.1.3" class="ltx_text ltx_font_typewriter">‘rowspan=x’</span> or <span id="S3.SS2.p5.1.4" class="ltx_text ltx_font_typewriter">‘colspan=y’</span> are set in the <span id="S3.SS2.p5.1.5" class="ltx_text ltx_font_typewriter">‘&lt;td&gt;’</span> label.</p>
</div>
<div id="S3.SS2.p6" class="ltx_para ltx_noindent">
<p id="S3.SS2.p6.1" class="ltx_p"><span id="S3.SS2.p6.1.1" class="ltx_text ltx_font_bold">Chart Parsing.</span> Unlike documents and tables, organizing texts in reading order cannot represent the structure of charts. Considering that the chart is a visualization form of the table, parsing charts to tables could best maintain the mathematical characteristics of the chart. This requires the model to understand the structure of the chart and the alignment of the x/y axis. Besides, to keep consistent with the Table Parsing task, we also use Markdown codes to represent the data tables of charts, as shown in <a href="#S3.F4" title="In 3.2 Unified Structure Learning ‣ 3 DocOwl 1.5 ‣ mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<div id="S3.SS2.p7" class="ltx_para">
<p id="S3.SS2.p7.1" class="ltx_p">We adopt PlotQA <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>, FigureQA <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>, DVQA <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>, and ChartQA <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> to support the structure-aware chart parsing task. These datasets cover charts on both synthetic <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> data and data from real-world sources <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>. Chart types include vertical bar, horizontal bar, line, dot line, and pie chart. Source data of the chart is provided in the JSON <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite> or CSV format <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>, both can be conveniently converted to Markdown codes. However, some raw values are not suitable as standard answers for parsing because there are too many significant digits to be represented on the chart. Therefore, to reduce the difficulty of estimating values and make the model focus more on structural understanding, we keep 4 significant digits for all values.</p>
</div>
<div id="S3.SS2.p8" class="ltx_para ltx_noindent">
<p id="S3.SS2.p8.1" class="ltx_p"><span id="S3.SS2.p8.1.1" class="ltx_text ltx_font_bold">Natural Image Parsing.</span> Quite different from text-dominant images mentioned above, the semantics of natural images is a combination of natural objects and scene texts. Thus, parsing natural images is necessary to organize scene texts and mention the main image content. Manually annotating captions to describe the relationship between objects and scene texts is labour- and financial-intensive. Like TAP <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite>, we concatenate the general caption with OCR texts to form the target parsing sequence.</p>
</div>
<div id="S3.SS2.p9" class="ltx_para">
<p id="S3.SS2.p9.1" class="ltx_p">We utilize OCR-CC <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite> to support the Natural Image Parsing task. OCR-CC is a subset of Conceptual Caption <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>, which contains images with scene texts detected by the Microsoft Azure OCR system.</p>
</div>
<div id="S3.SS2.p10" class="ltx_para ltx_noindent">
<p id="S3.SS2.p10.1" class="ltx_p"><span id="S3.SS2.p10.1.1" class="ltx_text ltx_font_bold">Multi-grained Text Localization.</span> As proved in previous works <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>, <a href="#bib.bib49" title="" class="ltx_ref">49</a>, <a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> on general image understanding, semantic comprehension and object grounding tasks can be well unified in a single model. For Visual Document Understanding, structure-aware parsing tasks mainly focus on organizing texts according to the overall structure, while neglecting the correspondence between specific texts and local positions. Correlating texts with the concrete position in images is another basic structure understanding ability for visual documents. To support text position learning, we design two symmetrical tasks, namely Multi-grained Text Grounding and Multi-grained Text Recognition. The former aims to predict the bounding box given the visually-situated texts, while the latter does the opposite. We set four granularities of texts for these two tasks: word, phrase, line, and block. The ‘word’ is the smallest granularity of the bounding box, referring to only 1 word. To ensure that the word is visible and the answer is unique, words that are too small (normalized area &lt; 0.001) and words that appear multiple times in the same image are excluded from candidates. The ‘line’ consists of texts that are judged to be horizontally parallel by vertical distance, and the ‘phrase’ is comprised of multiple adjacent words within the same line. The ‘block’ is a combination of multiple successive lines, ranging from 2 to half of the total lines. The text sequences of word-level and phrase-level question answering are much shorter than the other two. Therefore, in order to learn localization more efficiently, each word-level or phrase-level sample consists of up to 5 question-answer pairs for the same image. As for the representation of bounding boxes, we transfer each continuous value in the normalized bounding box into a discrete position token, ranging from 0 to 999.</p>
</div>
<div id="S3.SS2.p11" class="ltx_para">
<p id="S3.SS2.p11.1" class="ltx_p">The bounding box annotation is necessary for constructing samples for Multi-grained Text Localization tasks. Therefore, we take DocVQA, InfoVQA, WTQ, TabFact, DeepForm, KLC, ChartQA, VisualMRC, and TextVQA <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite> for this task, across domains of the document, table, chart, webpage, and natural image.</p>
</div>
<div id="S3.SS2.p12" class="ltx_para">
<p id="S3.SS2.p12.1" class="ltx_p">Overall, to support the unified structure learning for text-rich images, we build a DocStruct4M dataset by ensembling multiple training sets of publicly available datasets and constructing structure-aware text sequences or text-position pairs as the targets. The form of instructions for each task is very diverse for developing the general instruction-following ability of the model.
<a href="#S3.F5" title="In 3.2 Unified Structure Learning ‣ 3 DocOwl 1.5 ‣ mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">5</span></a> shows the detailed statistics of DocStruct4M.</p>
</div>
<figure id="S3.F5" class="ltx_figure"><img src="/html/2403.12895/assets/x5.png" id="S3.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="197" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Detailed statistics of DocStruct4M.</figcaption>
</figure>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Multi-task Fine-tuning</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">Through Unified Structure Learning, models could well understand the structure of diverse document images but cannot follow users’ instructions to do different types of tasks, such as information extraction or image captioning. So, we further perform multi-task fine-tuning to train a generalist of visual document understanding as UReader <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite>.</p>
</div>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Training Paradigm</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p">As shown in <a href="#S3.F3" title="In 3 DocOwl 1.5 ‣ mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">3</span></a>(a), DocOwl 1.5 is trained in a two-stage framework.
Considering the LLM has strong comprehension abilities for structured text <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib51" title="" class="ltx_ref">51</a>, <a href="#bib.bib61" title="" class="ltx_ref">61</a>]</cite>, we argue that the main limitation of MLLM in visual document understanding is the representation ability of the Visual Encoder and Vision-to-Text module for visually-situated text and structure information. Thus, during the Unified Structure Learning, we freeze the LLM parameters and tune the Visual Encoder and H-Reducer. The MAM is also optimized to help the LLM better distinguish visual features and texts parsed from the image. During the stage of Multi-task Fine-tuning, the model mainly learns how to follow the user’s instructions to give answers based on visually-situated text and structure understanding capabilities acquired in the first stage. Therefore, the Visual Encoder is frozen and other modules are tuned.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>DocOwl 1.5-Chat</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">Existing benchmarks mainly evaluate the document understanding ability by answering the question with simple phrases and neglect detailed explanations. In this work, to better leverage the strong language reasoning ability of Large Language Models on Visual Document Understanding, we build a small instruction-tuning set with detailed explanations on text-rich image understanding, namely DocReason25K. Based on raw questions from DocVQA <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>, InfoVQA <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>, WTQ <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>, VisualMRC <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite>, ChartQA <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> and TextVQA <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>, we collect detailed explanations with ChatGPT<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a target="_blank" href="https://openai.com/chatgpt" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openai.com/chatgpt</a></span></span></span>. Text contents are dominant information on documents, tables or webpage screenshots. Therefore, for DocVQA, InfoVQA, WTQ, and VisualMRC, we take the structure-aware text sequence of the image as the input to <span id="S4.p1.1.1" class="ltx_text ltx_font_typewriter">gpt-3.5-turbo-0301</span> and prompt it to answer the question with simple answers and detailed explanations. As for ChartQA and TextVQA, we take the image as the input and utilize the <span id="S4.p1.1.2" class="ltx_text ltx_font_typewriter">gpt-4-vision-preview</span> to answer the question with detailed explanations. In order to filter out samples where ChartGPT answers incorrectly, we further prompt <span id="S4.p1.1.3" class="ltx_text ltx_font_typewriter">gpt-3.5-turbo-0301</span> to judge whether the answer given by ChartGPT is consistent with the concise human-annotated ground-truth answer. Compared with raw questions in benchmark datasets, questions in DocReason25K are added with a prompt <span id="S4.p1.1.4" class="ltx_text ltx_font_typewriter">‘Answer the question with detailed explanation’</span>. Detailed statistics of DocReason25K are presented in <a href="#S4.T1" title="In 4 DocOwl 1.5-Chat ‣ mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">1</span></a>. DocOwl 1.5-Chat is trained by combining downstream datasets with DocReason25K and performing multi-task tuning after Unified Structure Learning.</p>
</div>
<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>The detailed statistics of DocReason25K. The ‘Avg Length’ refers to the average token length of the answer.</figcaption>
<table id="S4.T1.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T1.1.1.1" class="ltx_tr">
<th id="S4.T1.1.1.1.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt"></th>
<th id="S4.T1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T1.1.1.1.2.1" class="ltx_text" style="font-size:80%;">DocVQA</span></th>
<th id="S4.T1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T1.1.1.1.3.1" class="ltx_text" style="font-size:80%;">InfoVQA</span></th>
<th id="S4.T1.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T1.1.1.1.4.1" class="ltx_text" style="font-size:80%;">WTQ</span></th>
<th id="S4.T1.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T1.1.1.1.5.1" class="ltx_text" style="font-size:80%;">VisualMRC</span></th>
<th id="S4.T1.1.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T1.1.1.1.6.1" class="ltx_text" style="font-size:80%;">ChartQA</span></th>
<th id="S4.T1.1.1.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt"><span id="S4.T1.1.1.1.7.1" class="ltx_text" style="font-size:80%;">TextVQA</span></th>
<th id="S4.T1.1.1.1.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T1.1.1.1.8.1" class="ltx_text" style="font-size:80%;">ALL</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T1.1.2.1" class="ltx_tr">
<th id="S4.T1.1.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T1.1.2.1.1.1" class="ltx_text" style="font-size:80%;">Image</span></th>
<td id="S4.T1.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.1.2.1.2.1" class="ltx_text" style="font-size:80%;">1,491</span></td>
<td id="S4.T1.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.1.2.1.3.1" class="ltx_text" style="font-size:80%;">1,614</span></td>
<td id="S4.T1.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.1.2.1.4.1" class="ltx_text" style="font-size:80%;">850</span></td>
<td id="S4.T1.1.2.1.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.1.2.1.5.1" class="ltx_text" style="font-size:80%;">1,927</span></td>
<td id="S4.T1.1.2.1.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.1.2.1.6.1" class="ltx_text" style="font-size:80%;">1,252</span></td>
<td id="S4.T1.1.2.1.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.1.2.1.7.1" class="ltx_text" style="font-size:80%;">1,612</span></td>
<td id="S4.T1.1.2.1.8" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.1.2.1.8.1" class="ltx_text" style="font-size:80%;">8,746</span></td>
</tr>
<tr id="S4.T1.1.3.2" class="ltx_tr">
<th id="S4.T1.1.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S4.T1.1.3.2.1.1" class="ltx_text" style="font-size:80%;">Sample</span></th>
<td id="S4.T1.1.3.2.2" class="ltx_td ltx_align_center"><span id="S4.T1.1.3.2.2.1" class="ltx_text" style="font-size:80%;">5,119</span></td>
<td id="S4.T1.1.3.2.3" class="ltx_td ltx_align_center"><span id="S4.T1.1.3.2.3.1" class="ltx_text" style="font-size:80%;">5,421</span></td>
<td id="S4.T1.1.3.2.4" class="ltx_td ltx_align_center"><span id="S4.T1.1.3.2.4.1" class="ltx_text" style="font-size:80%;">5,994</span></td>
<td id="S4.T1.1.3.2.5" class="ltx_td ltx_align_center"><span id="S4.T1.1.3.2.5.1" class="ltx_text" style="font-size:80%;">5,263</span></td>
<td id="S4.T1.1.3.2.6" class="ltx_td ltx_align_center"><span id="S4.T1.1.3.2.6.1" class="ltx_text" style="font-size:80%;">1,827</span></td>
<td id="S4.T1.1.3.2.7" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.1.3.2.7.1" class="ltx_text" style="font-size:80%;">2,253</span></td>
<td id="S4.T1.1.3.2.8" class="ltx_td ltx_align_center"><span id="S4.T1.1.3.2.8.1" class="ltx_text" style="font-size:80%;">25,877</span></td>
</tr>
<tr id="S4.T1.1.4.3" class="ltx_tr">
<th id="S4.T1.1.4.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r"><span id="S4.T1.1.4.3.1.1" class="ltx_text" style="font-size:80%;">Avg Length</span></th>
<td id="S4.T1.1.4.3.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T1.1.4.3.2.1" class="ltx_text" style="font-size:80%;">79.2</span></td>
<td id="S4.T1.1.4.3.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T1.1.4.3.3.1" class="ltx_text" style="font-size:80%;">95.4</span></td>
<td id="S4.T1.1.4.3.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T1.1.4.3.4.1" class="ltx_text" style="font-size:80%;">77.7</span></td>
<td id="S4.T1.1.4.3.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T1.1.4.3.5.1" class="ltx_text" style="font-size:80%;">103.4</span></td>
<td id="S4.T1.1.4.3.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T1.1.4.3.6.1" class="ltx_text" style="font-size:80%;">106.9</span></td>
<td id="S4.T1.1.4.3.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S4.T1.1.4.3.7.1" class="ltx_text" style="font-size:80%;">88.0</span></td>
<td id="S4.T1.1.4.3.8" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T1.1.4.3.8.1" class="ltx_text" style="font-size:80%;">89.9</span></td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Experiments</h2>

<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Implementation Details</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">DocOwl 1.5 is initialized from mPLUG-Owl2 <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite>, which utilizes the ViT/L-14 <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> as the Visual Encoder and a 7B Large Langauge Model with the Modality Adaptive Module as the language decoder. According to the aspect ratio and resolution, each image is cropped into up to 9 sub-images with a fixed resolution of 448x448. Each sub-image is encoded to 1,024 features by the ViT/L-14 and then reduced to 256 features by the H-Reducer. The model is trained with 12,000 iterations on DocStruct4M, with the learning rate and batch size set as 1e-4 and 1,024. It costs about 128 A100 days. During the Multi-task finetuning, the model is trained for 6,500 iterations with the batch size set as 256 and the learning rate set as 2e-5. This further costs about 24 A100 days.</p>
</div>
<figure id="S5.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span>Different settings of OCR-free Visual Document Understanding models. ‘Open’ refers to whether all OCR learning data is open-source.</figcaption>
<div id="S5.T2.24" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:132.4pt;vertical-align:-0.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-79.6pt,24.2pt) scale(0.731482766831869,0.731482766831869) ;">
<table id="S5.T2.24.24" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T2.24.24.25.1" class="ltx_tr">
<th id="S5.T2.24.24.25.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt" rowspan="2"><span id="S5.T2.24.24.25.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Model</span></th>
<th id="S5.T2.24.24.25.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" rowspan="2"><span id="S5.T2.24.24.25.1.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Init</span></th>
<th id="S5.T2.24.24.25.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" rowspan="2"><span id="S5.T2.24.24.25.1.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Resolution</span></th>
<th id="S5.T2.24.24.25.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="5"><span id="S5.T2.24.24.25.1.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">OCR Learning</span></th>
</tr>
<tr id="S5.T2.24.24.26.2" class="ltx_tr">
<th id="S5.T2.24.24.26.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S5.T2.24.24.26.2.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Text</span></th>
<th id="S5.T2.24.24.26.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S5.T2.24.24.26.2.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Bbox</span></th>
<th id="S5.T2.24.24.26.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S5.T2.24.24.26.2.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Size</span></th>
<th id="S5.T2.24.24.26.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S5.T2.24.24.26.2.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Domain</span></th>
<th id="S5.T2.24.24.26.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S5.T2.24.24.26.2.5.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Open</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T2.3.3.3" class="ltx_tr">
<td id="S5.T2.3.3.3.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<span id="S5.T2.3.3.3.4.1" class="ltx_text" style="font-size:80%;">Donut </span><cite class="ltx_cite ltx_citemacro_citep"><span id="S5.T2.3.3.3.4.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib22" title="" class="ltx_ref">22</a><span id="S5.T2.3.3.3.4.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S5.T2.3.3.3.5" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T2.3.3.3.5.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S5.T2.3.3.3.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T2.3.3.3.6.1" class="ltx_text" style="font-size:80%;">2560x1920</span></td>
<td id="S5.T2.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t"><math id="S5.T2.1.1.1.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S5.T2.1.1.1.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S5.T2.1.1.1.1.m1.1.1" xref="S5.T2.1.1.1.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S5.T2.1.1.1.1.m1.1b"><ci id="S5.T2.1.1.1.1.m1.1.1.cmml" xref="S5.T2.1.1.1.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.1.1.1.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S5.T2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_t"><math id="S5.T2.2.2.2.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T2.2.2.2.2.m1.1a"><mo mathsize="80%" id="S5.T2.2.2.2.2.m1.1.1" xref="S5.T2.2.2.2.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T2.2.2.2.2.m1.1b"><times id="S5.T2.2.2.2.2.m1.1.1.cmml" xref="S5.T2.2.2.2.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.2.2.2.2.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T2.3.3.3.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T2.3.3.3.7.1" class="ltx_text" style="font-size:80%;">13M</span></td>
<td id="S5.T2.3.3.3.8" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T2.3.3.3.8.1" class="ltx_text" style="font-size:80%;">Synthetic, Doc</span></td>
<td id="S5.T2.3.3.3.3" class="ltx_td ltx_align_center ltx_border_t"><math id="S5.T2.3.3.3.3.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S5.T2.3.3.3.3.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S5.T2.3.3.3.3.m1.1.1" xref="S5.T2.3.3.3.3.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S5.T2.3.3.3.3.m1.1b"><ci id="S5.T2.3.3.3.3.m1.1.1.cmml" xref="S5.T2.3.3.3.3.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.3.3.3.3.m1.1c">\checkmark</annotation></semantics></math></td>
</tr>
<tr id="S5.T2.7.7.7" class="ltx_tr">
<td id="S5.T2.7.7.7.5" class="ltx_td ltx_align_left ltx_border_r">
<span id="S5.T2.7.7.7.5.1" class="ltx_text" style="font-size:80%;">Pix2Struct </span><cite class="ltx_cite ltx_citemacro_citep"><span id="S5.T2.7.7.7.5.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib23" title="" class="ltx_ref">23</a><span id="S5.T2.7.7.7.5.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S5.T2.7.7.7.6" class="ltx_td ltx_align_left"><span id="S5.T2.7.7.7.6.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S5.T2.4.4.4.1" class="ltx_td ltx_align_center ltx_border_r">
<math id="S5.T2.4.4.4.1.m1.1" class="ltx_Math" alttext="2^{19}" display="inline"><semantics id="S5.T2.4.4.4.1.m1.1a"><msup id="S5.T2.4.4.4.1.m1.1.1" xref="S5.T2.4.4.4.1.m1.1.1.cmml"><mn mathsize="80%" id="S5.T2.4.4.4.1.m1.1.1.2" xref="S5.T2.4.4.4.1.m1.1.1.2.cmml">2</mn><mn mathsize="80%" id="S5.T2.4.4.4.1.m1.1.1.3" xref="S5.T2.4.4.4.1.m1.1.1.3.cmml">19</mn></msup><annotation-xml encoding="MathML-Content" id="S5.T2.4.4.4.1.m1.1b"><apply id="S5.T2.4.4.4.1.m1.1.1.cmml" xref="S5.T2.4.4.4.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T2.4.4.4.1.m1.1.1.1.cmml" xref="S5.T2.4.4.4.1.m1.1.1">superscript</csymbol><cn type="integer" id="S5.T2.4.4.4.1.m1.1.1.2.cmml" xref="S5.T2.4.4.4.1.m1.1.1.2">2</cn><cn type="integer" id="S5.T2.4.4.4.1.m1.1.1.3.cmml" xref="S5.T2.4.4.4.1.m1.1.1.3">19</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.4.4.4.1.m1.1c">2^{19}</annotation></semantics></math><span id="S5.T2.4.4.4.1.1" class="ltx_text" style="font-size:80%;">(shape variable)</span>
</td>
<td id="S5.T2.5.5.5.2" class="ltx_td ltx_align_center"><math id="S5.T2.5.5.5.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S5.T2.5.5.5.2.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S5.T2.5.5.5.2.m1.1.1" xref="S5.T2.5.5.5.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S5.T2.5.5.5.2.m1.1b"><ci id="S5.T2.5.5.5.2.m1.1.1.cmml" xref="S5.T2.5.5.5.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.5.5.5.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S5.T2.6.6.6.3" class="ltx_td ltx_align_center"><math id="S5.T2.6.6.6.3.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T2.6.6.6.3.m1.1a"><mo mathsize="80%" id="S5.T2.6.6.6.3.m1.1.1" xref="S5.T2.6.6.6.3.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T2.6.6.6.3.m1.1b"><times id="S5.T2.6.6.6.3.m1.1.1.cmml" xref="S5.T2.6.6.6.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.6.6.6.3.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T2.7.7.7.7" class="ltx_td ltx_align_center"><span id="S5.T2.7.7.7.7.1" class="ltx_text" style="font-size:80%;">80M</span></td>
<td id="S5.T2.7.7.7.8" class="ltx_td ltx_align_center"><span id="S5.T2.7.7.7.8.1" class="ltx_text" style="font-size:80%;">Web</span></td>
<td id="S5.T2.7.7.7.4" class="ltx_td ltx_align_center"><math id="S5.T2.7.7.7.4.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T2.7.7.7.4.m1.1a"><mo mathsize="80%" id="S5.T2.7.7.7.4.m1.1.1" xref="S5.T2.7.7.7.4.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T2.7.7.7.4.m1.1b"><times id="S5.T2.7.7.7.4.m1.1.1.cmml" xref="S5.T2.7.7.7.4.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.7.7.7.4.m1.1c">\times</annotation></semantics></math></td>
</tr>
<tr id="S5.T2.10.10.10" class="ltx_tr">
<td id="S5.T2.10.10.10.4" class="ltx_td ltx_align_left ltx_border_r">
<span id="S5.T2.10.10.10.4.1" class="ltx_text" style="font-size:80%;">QwenVL </span><cite class="ltx_cite ltx_citemacro_citep"><span id="S5.T2.10.10.10.4.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib3" title="" class="ltx_ref">3</a><span id="S5.T2.10.10.10.4.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S5.T2.10.10.10.5" class="ltx_td ltx_align_left"><span id="S5.T2.10.10.10.5.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S5.T2.10.10.10.6" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.10.10.10.6.1" class="ltx_text" style="font-size:80%;">448x448</span></td>
<td id="S5.T2.8.8.8.1" class="ltx_td ltx_align_center"><math id="S5.T2.8.8.8.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S5.T2.8.8.8.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S5.T2.8.8.8.1.m1.1.1" xref="S5.T2.8.8.8.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S5.T2.8.8.8.1.m1.1b"><ci id="S5.T2.8.8.8.1.m1.1.1.cmml" xref="S5.T2.8.8.8.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.8.8.8.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S5.T2.9.9.9.2" class="ltx_td ltx_align_center"><math id="S5.T2.9.9.9.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T2.9.9.9.2.m1.1a"><mo mathsize="80%" id="S5.T2.9.9.9.2.m1.1.1" xref="S5.T2.9.9.9.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T2.9.9.9.2.m1.1b"><times id="S5.T2.9.9.9.2.m1.1.1.cmml" xref="S5.T2.9.9.9.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.9.9.9.2.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T2.10.10.10.7" class="ltx_td ltx_align_center"><span id="S5.T2.10.10.10.7.1" class="ltx_text" style="font-size:80%;">24.8M</span></td>
<td id="S5.T2.10.10.10.8" class="ltx_td ltx_align_center"><span id="S5.T2.10.10.10.8.1" class="ltx_text" style="font-size:80%;">Synthetic, Doc, Web</span></td>
<td id="S5.T2.10.10.10.3" class="ltx_td ltx_align_center"><math id="S5.T2.10.10.10.3.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T2.10.10.10.3.m1.1a"><mo mathsize="80%" id="S5.T2.10.10.10.3.m1.1.1" xref="S5.T2.10.10.10.3.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T2.10.10.10.3.m1.1b"><times id="S5.T2.10.10.10.3.m1.1.1.cmml" xref="S5.T2.10.10.10.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.10.10.10.3.m1.1c">\times</annotation></semantics></math></td>
</tr>
<tr id="S5.T2.12.12.12" class="ltx_tr">
<td id="S5.T2.12.12.12.3" class="ltx_td ltx_align_left ltx_border_r">
<span id="S5.T2.12.12.12.3.1" class="ltx_text" style="font-size:80%;">Monkey </span><cite class="ltx_cite ltx_citemacro_citep"><span id="S5.T2.12.12.12.3.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib25" title="" class="ltx_ref">25</a><span id="S5.T2.12.12.12.3.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S5.T2.12.12.12.4" class="ltx_td ltx_align_left">
<span id="S5.T2.12.12.12.4.1" class="ltx_text" style="font-size:80%;">QwenVL </span><cite class="ltx_cite ltx_citemacro_citep"><span id="S5.T2.12.12.12.4.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib3" title="" class="ltx_ref">3</a><span id="S5.T2.12.12.12.4.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S5.T2.12.12.12.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.12.12.12.5.1" class="ltx_text" style="font-size:80%;">896x896</span></td>
<td id="S5.T2.11.11.11.1" class="ltx_td ltx_align_center"><math id="S5.T2.11.11.11.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T2.11.11.11.1.m1.1a"><mo mathsize="80%" id="S5.T2.11.11.11.1.m1.1.1" xref="S5.T2.11.11.11.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T2.11.11.11.1.m1.1b"><times id="S5.T2.11.11.11.1.m1.1.1.cmml" xref="S5.T2.11.11.11.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.11.11.11.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T2.12.12.12.2" class="ltx_td ltx_align_center"><math id="S5.T2.12.12.12.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T2.12.12.12.2.m1.1a"><mo mathsize="80%" id="S5.T2.12.12.12.2.m1.1.1" xref="S5.T2.12.12.12.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T2.12.12.12.2.m1.1b"><times id="S5.T2.12.12.12.2.m1.1.1.cmml" xref="S5.T2.12.12.12.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.12.12.12.2.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T2.12.12.12.6" class="ltx_td ltx_align_center"><span id="S5.T2.12.12.12.6.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S5.T2.12.12.12.7" class="ltx_td ltx_align_center"><span id="S5.T2.12.12.12.7.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S5.T2.12.12.12.8" class="ltx_td ltx_align_center"><span id="S5.T2.12.12.12.8.1" class="ltx_text" style="font-size:80%;">-</span></td>
</tr>
<tr id="S5.T2.15.15.15" class="ltx_tr">
<td id="S5.T2.15.15.15.4" class="ltx_td ltx_align_left ltx_border_r">
<span id="S5.T2.15.15.15.4.1" class="ltx_text" style="font-size:80%;">UReader </span><cite class="ltx_cite ltx_citemacro_citep"><span id="S5.T2.15.15.15.4.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib56" title="" class="ltx_ref">56</a><span id="S5.T2.15.15.15.4.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S5.T2.15.15.15.5" class="ltx_td ltx_align_left">
<span id="S5.T2.15.15.15.5.1" class="ltx_text" style="font-size:80%;">Owl </span><cite class="ltx_cite ltx_citemacro_citep"><span id="S5.T2.15.15.15.5.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib57" title="" class="ltx_ref">57</a><span id="S5.T2.15.15.15.5.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S5.T2.15.15.15.6" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.15.15.15.6.1" class="ltx_text" style="font-size:80%;">224x224(x20 crops)</span></td>
<td id="S5.T2.13.13.13.1" class="ltx_td ltx_align_center"><math id="S5.T2.13.13.13.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S5.T2.13.13.13.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S5.T2.13.13.13.1.m1.1.1" xref="S5.T2.13.13.13.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S5.T2.13.13.13.1.m1.1b"><ci id="S5.T2.13.13.13.1.m1.1.1.cmml" xref="S5.T2.13.13.13.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.13.13.13.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S5.T2.14.14.14.2" class="ltx_td ltx_align_center"><math id="S5.T2.14.14.14.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T2.14.14.14.2.m1.1a"><mo mathsize="80%" id="S5.T2.14.14.14.2.m1.1.1" xref="S5.T2.14.14.14.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T2.14.14.14.2.m1.1b"><times id="S5.T2.14.14.14.2.m1.1.1.cmml" xref="S5.T2.14.14.14.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.14.14.14.2.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T2.15.15.15.7" class="ltx_td ltx_align_center"><span id="S5.T2.15.15.15.7.1" class="ltx_text" style="font-size:80%;">0.1M</span></td>
<td id="S5.T2.15.15.15.8" class="ltx_td ltx_align_center"><span id="S5.T2.15.15.15.8.1" class="ltx_text" style="font-size:80%;">Doc, Table, Chart, Web, Natural</span></td>
<td id="S5.T2.15.15.15.3" class="ltx_td ltx_align_center"><math id="S5.T2.15.15.15.3.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S5.T2.15.15.15.3.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S5.T2.15.15.15.3.m1.1.1" xref="S5.T2.15.15.15.3.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S5.T2.15.15.15.3.m1.1b"><ci id="S5.T2.15.15.15.3.m1.1.1.cmml" xref="S5.T2.15.15.15.3.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.15.15.15.3.m1.1c">\checkmark</annotation></semantics></math></td>
</tr>
<tr id="S5.T2.18.18.18" class="ltx_tr">
<td id="S5.T2.18.18.18.4" class="ltx_td ltx_align_left ltx_border_r">
<span id="S5.T2.18.18.18.4.1" class="ltx_text" style="font-size:80%;">DocPedia </span><cite class="ltx_cite ltx_citemacro_citep"><span id="S5.T2.18.18.18.4.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib13" title="" class="ltx_ref">13</a><span id="S5.T2.18.18.18.4.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S5.T2.18.18.18.5" class="ltx_td ltx_align_left"><span id="S5.T2.18.18.18.5.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S5.T2.18.18.18.6" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.18.18.18.6.1" class="ltx_text" style="font-size:80%;">2560×2560</span></td>
<td id="S5.T2.16.16.16.1" class="ltx_td ltx_align_center"><math id="S5.T2.16.16.16.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S5.T2.16.16.16.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S5.T2.16.16.16.1.m1.1.1" xref="S5.T2.16.16.16.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S5.T2.16.16.16.1.m1.1b"><ci id="S5.T2.16.16.16.1.m1.1.1.cmml" xref="S5.T2.16.16.16.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.16.16.16.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S5.T2.17.17.17.2" class="ltx_td ltx_align_center"><math id="S5.T2.17.17.17.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S5.T2.17.17.17.2.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S5.T2.17.17.17.2.m1.1.1" xref="S5.T2.17.17.17.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S5.T2.17.17.17.2.m1.1b"><ci id="S5.T2.17.17.17.2.m1.1.1.cmml" xref="S5.T2.17.17.17.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.17.17.17.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S5.T2.18.18.18.7" class="ltx_td ltx_align_center"><span id="S5.T2.18.18.18.7.1" class="ltx_text" style="font-size:80%;">0.9M</span></td>
<td id="S5.T2.18.18.18.8" class="ltx_td ltx_align_center"><span id="S5.T2.18.18.18.8.1" class="ltx_text" style="font-size:80%;">Doc</span></td>
<td id="S5.T2.18.18.18.3" class="ltx_td ltx_align_center"><math id="S5.T2.18.18.18.3.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T2.18.18.18.3.m1.1a"><mo mathsize="80%" id="S5.T2.18.18.18.3.m1.1.1" xref="S5.T2.18.18.18.3.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T2.18.18.18.3.m1.1b"><times id="S5.T2.18.18.18.3.m1.1.1.cmml" xref="S5.T2.18.18.18.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.18.18.18.3.m1.1c">\times</annotation></semantics></math></td>
</tr>
<tr id="S5.T2.21.21.21" class="ltx_tr">
<td id="S5.T2.21.21.21.4" class="ltx_td ltx_align_left ltx_border_r">
<span id="S5.T2.21.21.21.4.1" class="ltx_text" style="font-size:80%;">CogAgent </span><cite class="ltx_cite ltx_citemacro_citep"><span id="S5.T2.21.21.21.4.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib15" title="" class="ltx_ref">15</a><span id="S5.T2.21.21.21.4.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S5.T2.21.21.21.5" class="ltx_td ltx_align_left">
<span id="S5.T2.21.21.21.5.1" class="ltx_text" style="font-size:80%;">CogVLM </span><cite class="ltx_cite ltx_citemacro_citep"><span id="S5.T2.21.21.21.5.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib50" title="" class="ltx_ref">50</a><span id="S5.T2.21.21.21.5.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S5.T2.21.21.21.6" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T2.21.21.21.6.1" class="ltx_text" style="font-size:80%;">1120×1120</span></td>
<td id="S5.T2.19.19.19.1" class="ltx_td ltx_align_center"><math id="S5.T2.19.19.19.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S5.T2.19.19.19.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S5.T2.19.19.19.1.m1.1.1" xref="S5.T2.19.19.19.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S5.T2.19.19.19.1.m1.1b"><ci id="S5.T2.19.19.19.1.m1.1.1.cmml" xref="S5.T2.19.19.19.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.19.19.19.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S5.T2.20.20.20.2" class="ltx_td ltx_align_center"><math id="S5.T2.20.20.20.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S5.T2.20.20.20.2.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S5.T2.20.20.20.2.m1.1.1" xref="S5.T2.20.20.20.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S5.T2.20.20.20.2.m1.1b"><ci id="S5.T2.20.20.20.2.m1.1.1.cmml" xref="S5.T2.20.20.20.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.20.20.20.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S5.T2.21.21.21.7" class="ltx_td ltx_align_center"><span id="S5.T2.21.21.21.7.1" class="ltx_text" style="font-size:80%;">107M</span></td>
<td id="S5.T2.21.21.21.8" class="ltx_td ltx_align_center"><span id="S5.T2.21.21.21.8.1" class="ltx_text" style="font-size:80%;">Synthetic, Nature, Doc, Web</span></td>
<td id="S5.T2.21.21.21.3" class="ltx_td ltx_align_center"><math id="S5.T2.21.21.21.3.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T2.21.21.21.3.m1.1a"><mo mathsize="80%" id="S5.T2.21.21.21.3.m1.1.1" xref="S5.T2.21.21.21.3.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T2.21.21.21.3.m1.1b"><times id="S5.T2.21.21.21.3.m1.1.1.cmml" xref="S5.T2.21.21.21.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.21.21.21.3.m1.1c">\times</annotation></semantics></math></td>
</tr>
<tr id="S5.T2.24.24.24" class="ltx_tr">
<td id="S5.T2.24.24.24.4" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t"><span id="S5.T2.24.24.24.4.1" class="ltx_text" style="font-size:80%;">DocOwl 1.5</span></td>
<td id="S5.T2.24.24.24.5" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t">
<span id="S5.T2.24.24.24.5.1" class="ltx_text" style="font-size:80%;">Owl2 </span><cite class="ltx_cite ltx_citemacro_citep"><span id="S5.T2.24.24.24.5.2.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib58" title="" class="ltx_ref">58</a><span id="S5.T2.24.24.24.5.3.2" class="ltx_text" style="font-size:80%;">]</span></cite>
</td>
<td id="S5.T2.24.24.24.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t"><span id="S5.T2.24.24.24.6.1" class="ltx_text" style="font-size:80%;">448x448(x9 crops)</span></td>
<td id="S5.T2.22.22.22.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><math id="S5.T2.22.22.22.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S5.T2.22.22.22.1.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S5.T2.22.22.22.1.m1.1.1" xref="S5.T2.22.22.22.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S5.T2.22.22.22.1.m1.1b"><ci id="S5.T2.22.22.22.1.m1.1.1.cmml" xref="S5.T2.22.22.22.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.22.22.22.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S5.T2.23.23.23.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><math id="S5.T2.23.23.23.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S5.T2.23.23.23.2.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S5.T2.23.23.23.2.m1.1.1" xref="S5.T2.23.23.23.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S5.T2.23.23.23.2.m1.1b"><ci id="S5.T2.23.23.23.2.m1.1.1.cmml" xref="S5.T2.23.23.23.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.23.23.23.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S5.T2.24.24.24.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S5.T2.24.24.24.7.1" class="ltx_text" style="font-size:80%;">4M</span></td>
<td id="S5.T2.24.24.24.8" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S5.T2.24.24.24.8.1" class="ltx_text" style="font-size:80%;">Doc, Table, Chart, Web, Natural</span></td>
<td id="S5.T2.24.24.24.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><math id="S5.T2.24.24.24.3.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S5.T2.24.24.24.3.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S5.T2.24.24.24.3.m1.1.1" xref="S5.T2.24.24.24.3.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S5.T2.24.24.24.3.m1.1b"><ci id="S5.T2.24.24.24.3.m1.1.1.cmml" xref="S5.T2.24.24.24.3.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.24.24.24.3.m1.1c">\checkmark</annotation></semantics></math></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure id="S5.T3" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span>Comparison with OCR-free methods on various types of text-rich image understanding tasks. The superscript ‘<math id="S5.T3.3.m1.1" class="ltx_Math" alttext="*" display="inline"><semantics id="S5.T3.3.m1.1b"><mo id="S5.T3.3.m1.1.1" xref="S5.T3.3.m1.1.1.cmml">∗</mo><annotation-xml encoding="MathML-Content" id="S5.T3.3.m1.1c"><times id="S5.T3.3.m1.1.1.cmml" xref="S5.T3.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.3.m1.1d">*</annotation></semantics></math>’ refers to models separately fine-tuned on each downstream task, rather than generalists. The <math id="S5.T3.4.m2.1" class="ltx_Math" alttext="\underline{underline}" display="inline"><semantics id="S5.T3.4.m2.1b"><munder accentunder="true" id="S5.T3.4.m2.1.1" xref="S5.T3.4.m2.1.1.cmml"><mrow id="S5.T3.4.m2.1.1.2" xref="S5.T3.4.m2.1.1.2.cmml"><mi id="S5.T3.4.m2.1.1.2.2" xref="S5.T3.4.m2.1.1.2.2.cmml">u</mi><mo lspace="0em" rspace="0em" id="S5.T3.4.m2.1.1.2.1" xref="S5.T3.4.m2.1.1.2.1.cmml">​</mo><mi id="S5.T3.4.m2.1.1.2.3" xref="S5.T3.4.m2.1.1.2.3.cmml">n</mi><mo lspace="0em" rspace="0em" id="S5.T3.4.m2.1.1.2.1b" xref="S5.T3.4.m2.1.1.2.1.cmml">​</mo><mi id="S5.T3.4.m2.1.1.2.4" xref="S5.T3.4.m2.1.1.2.4.cmml">d</mi><mo lspace="0em" rspace="0em" id="S5.T3.4.m2.1.1.2.1c" xref="S5.T3.4.m2.1.1.2.1.cmml">​</mo><mi id="S5.T3.4.m2.1.1.2.5" xref="S5.T3.4.m2.1.1.2.5.cmml">e</mi><mo lspace="0em" rspace="0em" id="S5.T3.4.m2.1.1.2.1d" xref="S5.T3.4.m2.1.1.2.1.cmml">​</mo><mi id="S5.T3.4.m2.1.1.2.6" xref="S5.T3.4.m2.1.1.2.6.cmml">r</mi><mo lspace="0em" rspace="0em" id="S5.T3.4.m2.1.1.2.1e" xref="S5.T3.4.m2.1.1.2.1.cmml">​</mo><mi id="S5.T3.4.m2.1.1.2.7" xref="S5.T3.4.m2.1.1.2.7.cmml">l</mi><mo lspace="0em" rspace="0em" id="S5.T3.4.m2.1.1.2.1f" xref="S5.T3.4.m2.1.1.2.1.cmml">​</mo><mi id="S5.T3.4.m2.1.1.2.8" xref="S5.T3.4.m2.1.1.2.8.cmml">i</mi><mo lspace="0em" rspace="0em" id="S5.T3.4.m2.1.1.2.1g" xref="S5.T3.4.m2.1.1.2.1.cmml">​</mo><mi id="S5.T3.4.m2.1.1.2.9" xref="S5.T3.4.m2.1.1.2.9.cmml">n</mi><mo lspace="0em" rspace="0em" id="S5.T3.4.m2.1.1.2.1h" xref="S5.T3.4.m2.1.1.2.1.cmml">​</mo><mi id="S5.T3.4.m2.1.1.2.10" xref="S5.T3.4.m2.1.1.2.10.cmml">e</mi></mrow><mo id="S5.T3.4.m2.1.1.1" xref="S5.T3.4.m2.1.1.1.cmml">¯</mo></munder><annotation-xml encoding="MathML-Content" id="S5.T3.4.m2.1c"><apply id="S5.T3.4.m2.1.1.cmml" xref="S5.T3.4.m2.1.1"><ci id="S5.T3.4.m2.1.1.1.cmml" xref="S5.T3.4.m2.1.1.1">¯</ci><apply id="S5.T3.4.m2.1.1.2.cmml" xref="S5.T3.4.m2.1.1.2"><times id="S5.T3.4.m2.1.1.2.1.cmml" xref="S5.T3.4.m2.1.1.2.1"></times><ci id="S5.T3.4.m2.1.1.2.2.cmml" xref="S5.T3.4.m2.1.1.2.2">𝑢</ci><ci id="S5.T3.4.m2.1.1.2.3.cmml" xref="S5.T3.4.m2.1.1.2.3">𝑛</ci><ci id="S5.T3.4.m2.1.1.2.4.cmml" xref="S5.T3.4.m2.1.1.2.4">𝑑</ci><ci id="S5.T3.4.m2.1.1.2.5.cmml" xref="S5.T3.4.m2.1.1.2.5">𝑒</ci><ci id="S5.T3.4.m2.1.1.2.6.cmml" xref="S5.T3.4.m2.1.1.2.6">𝑟</ci><ci id="S5.T3.4.m2.1.1.2.7.cmml" xref="S5.T3.4.m2.1.1.2.7">𝑙</ci><ci id="S5.T3.4.m2.1.1.2.8.cmml" xref="S5.T3.4.m2.1.1.2.8">𝑖</ci><ci id="S5.T3.4.m2.1.1.2.9.cmml" xref="S5.T3.4.m2.1.1.2.9">𝑛</ci><ci id="S5.T3.4.m2.1.1.2.10.cmml" xref="S5.T3.4.m2.1.1.2.10">𝑒</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.4.m2.1d">\underline{underline}</annotation></semantics></math> means the best performance among models with &lt;10B parameters.</figcaption>
<div id="S5.T3.8" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:262.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(8.9pt,-5.4pt) scale(1.04296666419178,1.04296666419178) ;">
<table id="S5.T3.8.4" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S5.T3.8.4.5.1" class="ltx_tr">
<td id="S5.T3.8.4.5.1.1" class="ltx_td ltx_align_left ltx_border_tt" rowspan="2"><span id="S5.T3.8.4.5.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Model</span></td>
<td id="S5.T3.8.4.5.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" rowspan="2"><span id="S5.T3.8.4.5.1.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Size</span></td>
<td id="S5.T3.8.4.5.1.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.T3.8.4.5.1.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Doc</span></td>
<td id="S5.T3.8.4.5.1.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.T3.8.4.5.1.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Info</span></td>
<td id="S5.T3.8.4.5.1.5" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.T3.8.4.5.1.5.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Deep</span></td>
<td id="S5.T3.8.4.5.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" rowspan="2"><span id="S5.T3.8.4.5.1.6.1" class="ltx_text ltx_font_bold" style="font-size:80%;">KLC</span></td>
<td id="S5.T3.8.4.5.1.7" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2"><span id="S5.T3.8.4.5.1.7.1" class="ltx_text ltx_font_bold" style="font-size:80%;">WTQ</span></td>
<td id="S5.T3.8.4.5.1.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="S5.T3.8.4.5.1.8.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Tab</span></td>
<td id="S5.T3.8.4.5.1.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="S5.T3.8.4.5.1.9.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Chart</span></td>
<td id="S5.T3.8.4.5.1.10" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.T3.8.4.5.1.10.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Text</span></td>
<td id="S5.T3.8.4.5.1.11" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="S5.T3.8.4.5.1.11.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Text</span></td>
<td id="S5.T3.8.4.5.1.12" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.T3.8.4.5.1.12.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Visual</span></td>
</tr>
<tr id="S5.T3.8.4.6.2" class="ltx_tr">
<td id="S5.T3.8.4.6.2.1" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.6.2.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">VQA</span></td>
<td id="S5.T3.8.4.6.2.2" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.6.2.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">VQA</span></td>
<td id="S5.T3.8.4.6.2.3" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.6.2.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Form</span></td>
<td id="S5.T3.8.4.6.2.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T3.8.4.6.2.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Fact</span></td>
<td id="S5.T3.8.4.6.2.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T3.8.4.6.2.5.1" class="ltx_text ltx_font_bold" style="font-size:80%;">QA</span></td>
<td id="S5.T3.8.4.6.2.6" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.6.2.6.1" class="ltx_text ltx_font_bold" style="font-size:80%;">VQA</span></td>
<td id="S5.T3.8.4.6.2.7" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T3.8.4.6.2.7.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Caps</span></td>
<td id="S5.T3.8.4.6.2.8" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.6.2.8.1" class="ltx_text ltx_font_bold" style="font-size:80%;">MRC</span></td>
</tr>
<tr id="S5.T3.5.1.1" class="ltx_tr">
<td id="S5.T3.5.1.1.1" class="ltx_td ltx_align_left ltx_border_t">
<span id="S5.T3.5.1.1.1.1" class="ltx_text" style="font-size:80%;">Dessurt</span><sup id="S5.T3.5.1.1.1.2" class="ltx_sup"><span id="S5.T3.5.1.1.1.2.1" class="ltx_text ltx_font_italic" style="font-size:80%;">∗</span></sup>
</td>
<td id="S5.T3.5.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T3.5.1.1.2.1" class="ltx_text" style="font-size:80%;">&lt;1B</span></td>
<td id="S5.T3.5.1.1.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T3.5.1.1.3.1" class="ltx_text" style="font-size:80%;">63.2</span></td>
<td id="S5.T3.5.1.1.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T3.5.1.1.4.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S5.T3.5.1.1.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T3.5.1.1.5.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S5.T3.5.1.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T3.5.1.1.6.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S5.T3.5.1.1.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T3.5.1.1.7.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S5.T3.5.1.1.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T3.5.1.1.8.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S5.T3.5.1.1.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T3.5.1.1.9.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S5.T3.5.1.1.10" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T3.5.1.1.10.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S5.T3.5.1.1.11" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T3.5.1.1.11.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S5.T3.5.1.1.12" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T3.5.1.1.12.1" class="ltx_text" style="font-size:80%;">-</span></td>
</tr>
<tr id="S5.T3.6.2.2" class="ltx_tr">
<td id="S5.T3.6.2.2.1" class="ltx_td ltx_align_left">
<span id="S5.T3.6.2.2.1.1" class="ltx_text" style="font-size:80%;">Donut</span><sup id="S5.T3.6.2.2.1.2" class="ltx_sup"><span id="S5.T3.6.2.2.1.2.1" class="ltx_text ltx_font_italic" style="font-size:80%;">∗</span></sup>
</td>
<td id="S5.T3.6.2.2.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T3.6.2.2.2.1" class="ltx_text" style="font-size:80%;">&lt;1B</span></td>
<td id="S5.T3.6.2.2.3" class="ltx_td ltx_align_center"><span id="S5.T3.6.2.2.3.1" class="ltx_text" style="font-size:80%;">67.5</span></td>
<td id="S5.T3.6.2.2.4" class="ltx_td ltx_align_center"><span id="S5.T3.6.2.2.4.1" class="ltx_text" style="font-size:80%;">11.6</span></td>
<td id="S5.T3.6.2.2.5" class="ltx_td ltx_align_center"><span id="S5.T3.6.2.2.5.1" class="ltx_text" style="font-size:80%;">61.6</span></td>
<td id="S5.T3.6.2.2.6" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T3.6.2.2.6.1" class="ltx_text" style="font-size:80%;">30.0</span></td>
<td id="S5.T3.6.2.2.7" class="ltx_td ltx_align_center"><span id="S5.T3.6.2.2.7.1" class="ltx_text" style="font-size:80%;">18.8</span></td>
<td id="S5.T3.6.2.2.8" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T3.6.2.2.8.1" class="ltx_text" style="font-size:80%;">54.6</span></td>
<td id="S5.T3.6.2.2.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T3.6.2.2.9.1" class="ltx_text" style="font-size:80%;">41.8</span></td>
<td id="S5.T3.6.2.2.10" class="ltx_td ltx_align_center"><span id="S5.T3.6.2.2.10.1" class="ltx_text" style="font-size:80%;">43.5</span></td>
<td id="S5.T3.6.2.2.11" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T3.6.2.2.11.1" class="ltx_text" style="font-size:80%;">74.4</span></td>
<td id="S5.T3.6.2.2.12" class="ltx_td ltx_align_center"><span id="S5.T3.6.2.2.12.1" class="ltx_text" style="font-size:80%;">93.91</span></td>
</tr>
<tr id="S5.T3.7.3.3" class="ltx_tr">
<td id="S5.T3.7.3.3.1" class="ltx_td ltx_align_left">
<span id="S5.T3.7.3.3.1.1" class="ltx_text" style="font-size:80%;">Pix2Struct</span><math id="S5.T3.7.3.3.1.m1.1" class="ltx_Math" alttext="{}_{base}^{*}" display="inline"><semantics id="S5.T3.7.3.3.1.m1.1a"><mmultiscripts id="S5.T3.7.3.3.1.m1.1.1" xref="S5.T3.7.3.3.1.m1.1.1.cmml"><mi id="S5.T3.7.3.3.1.m1.1.1.2.2" xref="S5.T3.7.3.3.1.m1.1.1.2.2.cmml"></mi><mprescripts id="S5.T3.7.3.3.1.m1.1.1a" xref="S5.T3.7.3.3.1.m1.1.1.cmml"></mprescripts><mrow id="S5.T3.7.3.3.1.m1.1.1b" xref="S5.T3.7.3.3.1.m1.1.1.cmml"></mrow><mo mathsize="80%" id="S5.T3.7.3.3.1.m1.1.1.3" xref="S5.T3.7.3.3.1.m1.1.1.3.cmml">∗</mo><mrow id="S5.T3.7.3.3.1.m1.1.1.2.3" xref="S5.T3.7.3.3.1.m1.1.1.2.3.cmml"><mi mathsize="80%" id="S5.T3.7.3.3.1.m1.1.1.2.3.2" xref="S5.T3.7.3.3.1.m1.1.1.2.3.2.cmml">b</mi><mo lspace="0em" rspace="0em" id="S5.T3.7.3.3.1.m1.1.1.2.3.1" xref="S5.T3.7.3.3.1.m1.1.1.2.3.1.cmml">​</mo><mi mathsize="80%" id="S5.T3.7.3.3.1.m1.1.1.2.3.3" xref="S5.T3.7.3.3.1.m1.1.1.2.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S5.T3.7.3.3.1.m1.1.1.2.3.1a" xref="S5.T3.7.3.3.1.m1.1.1.2.3.1.cmml">​</mo><mi mathsize="80%" id="S5.T3.7.3.3.1.m1.1.1.2.3.4" xref="S5.T3.7.3.3.1.m1.1.1.2.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S5.T3.7.3.3.1.m1.1.1.2.3.1b" xref="S5.T3.7.3.3.1.m1.1.1.2.3.1.cmml">​</mo><mi mathsize="80%" id="S5.T3.7.3.3.1.m1.1.1.2.3.5" xref="S5.T3.7.3.3.1.m1.1.1.2.3.5.cmml">e</mi></mrow><mrow id="S5.T3.7.3.3.1.m1.1.1c" xref="S5.T3.7.3.3.1.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="S5.T3.7.3.3.1.m1.1b"><apply id="S5.T3.7.3.3.1.m1.1.1.cmml" xref="S5.T3.7.3.3.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T3.7.3.3.1.m1.1.1.1.cmml" xref="S5.T3.7.3.3.1.m1.1.1">superscript</csymbol><apply id="S5.T3.7.3.3.1.m1.1.1.2.cmml" xref="S5.T3.7.3.3.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T3.7.3.3.1.m1.1.1.2.1.cmml" xref="S5.T3.7.3.3.1.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="S5.T3.7.3.3.1.m1.1.1.2.2.cmml" xref="S5.T3.7.3.3.1.m1.1.1.2.2">absent</csymbol><apply id="S5.T3.7.3.3.1.m1.1.1.2.3.cmml" xref="S5.T3.7.3.3.1.m1.1.1.2.3"><times id="S5.T3.7.3.3.1.m1.1.1.2.3.1.cmml" xref="S5.T3.7.3.3.1.m1.1.1.2.3.1"></times><ci id="S5.T3.7.3.3.1.m1.1.1.2.3.2.cmml" xref="S5.T3.7.3.3.1.m1.1.1.2.3.2">𝑏</ci><ci id="S5.T3.7.3.3.1.m1.1.1.2.3.3.cmml" xref="S5.T3.7.3.3.1.m1.1.1.2.3.3">𝑎</ci><ci id="S5.T3.7.3.3.1.m1.1.1.2.3.4.cmml" xref="S5.T3.7.3.3.1.m1.1.1.2.3.4">𝑠</ci><ci id="S5.T3.7.3.3.1.m1.1.1.2.3.5.cmml" xref="S5.T3.7.3.3.1.m1.1.1.2.3.5">𝑒</ci></apply></apply><times id="S5.T3.7.3.3.1.m1.1.1.3.cmml" xref="S5.T3.7.3.3.1.m1.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.7.3.3.1.m1.1c">{}_{base}^{*}</annotation></semantics></math>
</td>
<td id="S5.T3.7.3.3.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T3.7.3.3.2.1" class="ltx_text" style="font-size:80%;">&lt;1B</span></td>
<td id="S5.T3.7.3.3.3" class="ltx_td ltx_align_center"><span id="S5.T3.7.3.3.3.1" class="ltx_text" style="font-size:80%;">72.1</span></td>
<td id="S5.T3.7.3.3.4" class="ltx_td ltx_align_center"><span id="S5.T3.7.3.3.4.1" class="ltx_text" style="font-size:80%;">38.2</span></td>
<td id="S5.T3.7.3.3.5" class="ltx_td ltx_align_center"><span id="S5.T3.7.3.3.5.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S5.T3.7.3.3.6" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T3.7.3.3.6.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S5.T3.7.3.3.7" class="ltx_td ltx_align_center"><span id="S5.T3.7.3.3.7.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S5.T3.7.3.3.8" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T3.7.3.3.8.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S5.T3.7.3.3.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T3.7.3.3.9.1" class="ltx_text" style="font-size:80%;">56.0</span></td>
<td id="S5.T3.7.3.3.10" class="ltx_td ltx_align_center"><span id="S5.T3.7.3.3.10.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S5.T3.7.3.3.11" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T3.7.3.3.11.1" class="ltx_text" style="font-size:80%;">88.0</span></td>
<td id="S5.T3.7.3.3.12" class="ltx_td ltx_align_center"><span id="S5.T3.7.3.3.12.1" class="ltx_text" style="font-size:80%;">-</span></td>
</tr>
<tr id="S5.T3.8.4.4" class="ltx_tr">
<td id="S5.T3.8.4.4.1" class="ltx_td ltx_align_left">
<span id="S5.T3.8.4.4.1.1" class="ltx_text" style="font-size:80%;">Pix2Struct</span><math id="S5.T3.8.4.4.1.m1.1" class="ltx_Math" alttext="{}_{large}^{*}" display="inline"><semantics id="S5.T3.8.4.4.1.m1.1a"><mmultiscripts id="S5.T3.8.4.4.1.m1.1.1" xref="S5.T3.8.4.4.1.m1.1.1.cmml"><mi id="S5.T3.8.4.4.1.m1.1.1.2.2" xref="S5.T3.8.4.4.1.m1.1.1.2.2.cmml"></mi><mprescripts id="S5.T3.8.4.4.1.m1.1.1a" xref="S5.T3.8.4.4.1.m1.1.1.cmml"></mprescripts><mrow id="S5.T3.8.4.4.1.m1.1.1b" xref="S5.T3.8.4.4.1.m1.1.1.cmml"></mrow><mo mathsize="80%" id="S5.T3.8.4.4.1.m1.1.1.3" xref="S5.T3.8.4.4.1.m1.1.1.3.cmml">∗</mo><mrow id="S5.T3.8.4.4.1.m1.1.1.2.3" xref="S5.T3.8.4.4.1.m1.1.1.2.3.cmml"><mi mathsize="80%" id="S5.T3.8.4.4.1.m1.1.1.2.3.2" xref="S5.T3.8.4.4.1.m1.1.1.2.3.2.cmml">l</mi><mo lspace="0em" rspace="0em" id="S5.T3.8.4.4.1.m1.1.1.2.3.1" xref="S5.T3.8.4.4.1.m1.1.1.2.3.1.cmml">​</mo><mi mathsize="80%" id="S5.T3.8.4.4.1.m1.1.1.2.3.3" xref="S5.T3.8.4.4.1.m1.1.1.2.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S5.T3.8.4.4.1.m1.1.1.2.3.1a" xref="S5.T3.8.4.4.1.m1.1.1.2.3.1.cmml">​</mo><mi mathsize="80%" id="S5.T3.8.4.4.1.m1.1.1.2.3.4" xref="S5.T3.8.4.4.1.m1.1.1.2.3.4.cmml">r</mi><mo lspace="0em" rspace="0em" id="S5.T3.8.4.4.1.m1.1.1.2.3.1b" xref="S5.T3.8.4.4.1.m1.1.1.2.3.1.cmml">​</mo><mi mathsize="80%" id="S5.T3.8.4.4.1.m1.1.1.2.3.5" xref="S5.T3.8.4.4.1.m1.1.1.2.3.5.cmml">g</mi><mo lspace="0em" rspace="0em" id="S5.T3.8.4.4.1.m1.1.1.2.3.1c" xref="S5.T3.8.4.4.1.m1.1.1.2.3.1.cmml">​</mo><mi mathsize="80%" id="S5.T3.8.4.4.1.m1.1.1.2.3.6" xref="S5.T3.8.4.4.1.m1.1.1.2.3.6.cmml">e</mi></mrow><mrow id="S5.T3.8.4.4.1.m1.1.1c" xref="S5.T3.8.4.4.1.m1.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="S5.T3.8.4.4.1.m1.1b"><apply id="S5.T3.8.4.4.1.m1.1.1.cmml" xref="S5.T3.8.4.4.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T3.8.4.4.1.m1.1.1.1.cmml" xref="S5.T3.8.4.4.1.m1.1.1">superscript</csymbol><apply id="S5.T3.8.4.4.1.m1.1.1.2.cmml" xref="S5.T3.8.4.4.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T3.8.4.4.1.m1.1.1.2.1.cmml" xref="S5.T3.8.4.4.1.m1.1.1">subscript</csymbol><csymbol cd="latexml" id="S5.T3.8.4.4.1.m1.1.1.2.2.cmml" xref="S5.T3.8.4.4.1.m1.1.1.2.2">absent</csymbol><apply id="S5.T3.8.4.4.1.m1.1.1.2.3.cmml" xref="S5.T3.8.4.4.1.m1.1.1.2.3"><times id="S5.T3.8.4.4.1.m1.1.1.2.3.1.cmml" xref="S5.T3.8.4.4.1.m1.1.1.2.3.1"></times><ci id="S5.T3.8.4.4.1.m1.1.1.2.3.2.cmml" xref="S5.T3.8.4.4.1.m1.1.1.2.3.2">𝑙</ci><ci id="S5.T3.8.4.4.1.m1.1.1.2.3.3.cmml" xref="S5.T3.8.4.4.1.m1.1.1.2.3.3">𝑎</ci><ci id="S5.T3.8.4.4.1.m1.1.1.2.3.4.cmml" xref="S5.T3.8.4.4.1.m1.1.1.2.3.4">𝑟</ci><ci id="S5.T3.8.4.4.1.m1.1.1.2.3.5.cmml" xref="S5.T3.8.4.4.1.m1.1.1.2.3.5">𝑔</ci><ci id="S5.T3.8.4.4.1.m1.1.1.2.3.6.cmml" xref="S5.T3.8.4.4.1.m1.1.1.2.3.6">𝑒</ci></apply></apply><times id="S5.T3.8.4.4.1.m1.1.1.3.cmml" xref="S5.T3.8.4.4.1.m1.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.8.4.4.1.m1.1c">{}_{large}^{*}</annotation></semantics></math>
</td>
<td id="S5.T3.8.4.4.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T3.8.4.4.2.1" class="ltx_text" style="font-size:80%;">1.3B</span></td>
<td id="S5.T3.8.4.4.3" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.4.3.1" class="ltx_text" style="font-size:80%;">76.6</span></td>
<td id="S5.T3.8.4.4.4" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.4.4.1" class="ltx_text" style="font-size:80%;">40.0</span></td>
<td id="S5.T3.8.4.4.5" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.4.5.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S5.T3.8.4.4.6" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T3.8.4.4.6.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S5.T3.8.4.4.7" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.4.7.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S5.T3.8.4.4.8" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T3.8.4.4.8.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S5.T3.8.4.4.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T3.8.4.4.9.1" class="ltx_text" style="font-size:80%;">58.6</span></td>
<td id="S5.T3.8.4.4.10" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.4.10.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S5.T3.8.4.4.11" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T3.8.4.4.11.1" class="ltx_text" style="font-size:80%;">95.5</span></td>
<td id="S5.T3.8.4.4.12" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.4.12.1" class="ltx_text" style="font-size:80%;">-</span></td>
</tr>
<tr id="S5.T3.8.4.7.3" class="ltx_tr">
<td id="S5.T3.8.4.7.3.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T3.8.4.7.3.1.1" class="ltx_text" style="font-size:80%;">DocPeida</span></td>
<td id="S5.T3.8.4.7.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T3.8.4.7.3.2.1" class="ltx_text" style="font-size:80%;">7.0B</span></td>
<td id="S5.T3.8.4.7.3.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T3.8.4.7.3.3.1" class="ltx_text" style="font-size:80%;">47.1</span></td>
<td id="S5.T3.8.4.7.3.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T3.8.4.7.3.4.1" class="ltx_text" style="font-size:80%;">15.2</span></td>
<td id="S5.T3.8.4.7.3.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T3.8.4.7.3.5.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S5.T3.8.4.7.3.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T3.8.4.7.3.6.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S5.T3.8.4.7.3.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T3.8.4.7.3.7.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S5.T3.8.4.7.3.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T3.8.4.7.3.8.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S5.T3.8.4.7.3.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T3.8.4.7.3.9.1" class="ltx_text" style="font-size:80%;">46.9</span></td>
<td id="S5.T3.8.4.7.3.10" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T3.8.4.7.3.10.1" class="ltx_text" style="font-size:80%;">60.2</span></td>
<td id="S5.T3.8.4.7.3.11" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T3.8.4.7.3.11.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S5.T3.8.4.7.3.12" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T3.8.4.7.3.12.1" class="ltx_text" style="font-size:80%;">-</span></td>
</tr>
<tr id="S5.T3.8.4.8.4" class="ltx_tr">
<td id="S5.T3.8.4.8.4.1" class="ltx_td ltx_align_left"><span id="S5.T3.8.4.8.4.1.1" class="ltx_text" style="font-size:80%;">DocOwl</span></td>
<td id="S5.T3.8.4.8.4.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T3.8.4.8.4.2.1" class="ltx_text" style="font-size:80%;">7.1B</span></td>
<td id="S5.T3.8.4.8.4.3" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.8.4.3.1" class="ltx_text" style="font-size:80%;">62.2</span></td>
<td id="S5.T3.8.4.8.4.4" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.8.4.4.1" class="ltx_text" style="font-size:80%;">38.2</span></td>
<td id="S5.T3.8.4.8.4.5" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.8.4.5.1" class="ltx_text" style="font-size:80%;">42.6</span></td>
<td id="S5.T3.8.4.8.4.6" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T3.8.4.8.4.6.1" class="ltx_text" style="font-size:80%;">30.3</span></td>
<td id="S5.T3.8.4.8.4.7" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.8.4.7.1" class="ltx_text" style="font-size:80%;">26.9</span></td>
<td id="S5.T3.8.4.8.4.8" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T3.8.4.8.4.8.1" class="ltx_text" style="font-size:80%;">60.2</span></td>
<td id="S5.T3.8.4.8.4.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T3.8.4.8.4.9.1" class="ltx_text" style="font-size:80%;">57.4</span></td>
<td id="S5.T3.8.4.8.4.10" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.8.4.10.1" class="ltx_text" style="font-size:80%;">52.6</span></td>
<td id="S5.T3.8.4.8.4.11" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T3.8.4.8.4.11.1" class="ltx_text" style="font-size:80%;">111.9</span></td>
<td id="S5.T3.8.4.8.4.12" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.8.4.12.1" class="ltx_text" style="font-size:80%;">188.8</span></td>
</tr>
<tr id="S5.T3.8.4.9.5" class="ltx_tr">
<td id="S5.T3.8.4.9.5.1" class="ltx_td ltx_align_left"><span id="S5.T3.8.4.9.5.1.1" class="ltx_text" style="font-size:80%;">QwenVL</span></td>
<td id="S5.T3.8.4.9.5.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T3.8.4.9.5.2.1" class="ltx_text" style="font-size:80%;">9.6B</span></td>
<td id="S5.T3.8.4.9.5.3" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.9.5.3.1" class="ltx_text" style="font-size:80%;">65.1</span></td>
<td id="S5.T3.8.4.9.5.4" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.9.5.4.1" class="ltx_text" style="font-size:80%;">35.4</span></td>
<td id="S5.T3.8.4.9.5.5" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.9.5.5.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S5.T3.8.4.9.5.6" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T3.8.4.9.5.6.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S5.T3.8.4.9.5.7" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.9.5.7.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S5.T3.8.4.9.5.8" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T3.8.4.9.5.8.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S5.T3.8.4.9.5.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T3.8.4.9.5.9.1" class="ltx_text" style="font-size:80%;">65.7</span></td>
<td id="S5.T3.8.4.9.5.10" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.9.5.10.1" class="ltx_text" style="font-size:80%;">63.8</span></td>
<td id="S5.T3.8.4.9.5.11" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T3.8.4.9.5.11.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S5.T3.8.4.9.5.12" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.9.5.12.1" class="ltx_text" style="font-size:80%;">-</span></td>
</tr>
<tr id="S5.T3.8.4.10.6" class="ltx_tr">
<td id="S5.T3.8.4.10.6.1" class="ltx_td ltx_align_left"><span id="S5.T3.8.4.10.6.1.1" class="ltx_text" style="font-size:80%;">UReader</span></td>
<td id="S5.T3.8.4.10.6.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T3.8.4.10.6.2.1" class="ltx_text" style="font-size:80%;">7.1B</span></td>
<td id="S5.T3.8.4.10.6.3" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.10.6.3.1" class="ltx_text" style="font-size:80%;">65.4</span></td>
<td id="S5.T3.8.4.10.6.4" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.10.6.4.1" class="ltx_text" style="font-size:80%;">42.2</span></td>
<td id="S5.T3.8.4.10.6.5" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.10.6.5.1" class="ltx_text" style="font-size:80%;">49.5</span></td>
<td id="S5.T3.8.4.10.6.6" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T3.8.4.10.6.6.1" class="ltx_text" style="font-size:80%;">32.8</span></td>
<td id="S5.T3.8.4.10.6.7" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.10.6.7.1" class="ltx_text" style="font-size:80%;">29.4</span></td>
<td id="S5.T3.8.4.10.6.8" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T3.8.4.10.6.8.1" class="ltx_text" style="font-size:80%;">67.6</span></td>
<td id="S5.T3.8.4.10.6.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T3.8.4.10.6.9.1" class="ltx_text" style="font-size:80%;">59.3</span></td>
<td id="S5.T3.8.4.10.6.10" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.10.6.10.1" class="ltx_text" style="font-size:80%;">57.6</span></td>
<td id="S5.T3.8.4.10.6.11" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T3.8.4.10.6.11.1" class="ltx_text" style="font-size:80%;">118.4</span></td>
<td id="S5.T3.8.4.10.6.12" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.10.6.12.1" class="ltx_text" style="font-size:80%;">221.7</span></td>
</tr>
<tr id="S5.T3.8.4.11.7" class="ltx_tr">
<td id="S5.T3.8.4.11.7.1" class="ltx_td ltx_align_left"><span id="S5.T3.8.4.11.7.1.1" class="ltx_text" style="font-size:80%;">Monkey</span></td>
<td id="S5.T3.8.4.11.7.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T3.8.4.11.7.2.1" class="ltx_text" style="font-size:80%;">9.8B</span></td>
<td id="S5.T3.8.4.11.7.3" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.11.7.3.1" class="ltx_text" style="font-size:80%;">66.5</span></td>
<td id="S5.T3.8.4.11.7.4" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.11.7.4.1" class="ltx_text" style="font-size:80%;">36.1</span></td>
<td id="S5.T3.8.4.11.7.5" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.11.7.5.1" class="ltx_text" style="font-size:80%;">40.6</span></td>
<td id="S5.T3.8.4.11.7.6" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T3.8.4.11.7.6.1" class="ltx_text" style="font-size:80%;">32.8</span></td>
<td id="S5.T3.8.4.11.7.7" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.11.7.7.1" class="ltx_text" style="font-size:80%;">25.3</span></td>
<td id="S5.T3.8.4.11.7.8" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T3.8.4.11.7.8.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S5.T3.8.4.11.7.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T3.8.4.11.7.9.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S5.T3.8.4.11.7.10" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.11.7.10.1" class="ltx_text" style="font-size:80%;">67.6</span></td>
<td id="S5.T3.8.4.11.7.11" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T3.8.4.11.7.11.1" class="ltx_text" style="font-size:80%;">93.2</span></td>
<td id="S5.T3.8.4.11.7.12" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.11.7.12.1" class="ltx_text" style="font-size:80%;">-</span></td>
</tr>
<tr id="S5.T3.8.4.12.8" class="ltx_tr">
<td id="S5.T3.8.4.12.8.1" class="ltx_td ltx_align_left"><span id="S5.T3.8.4.12.8.1.1" class="ltx_text" style="font-size:80%;">CogAgent</span></td>
<td id="S5.T3.8.4.12.8.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T3.8.4.12.8.2.1" class="ltx_text" style="font-size:80%;">17.3B</span></td>
<td id="S5.T3.8.4.12.8.3" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.12.8.3.1" class="ltx_text" style="font-size:80%;">81.6</span></td>
<td id="S5.T3.8.4.12.8.4" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.12.8.4.1" class="ltx_text" style="font-size:80%;">44.5</span></td>
<td id="S5.T3.8.4.12.8.5" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.12.8.5.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S5.T3.8.4.12.8.6" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T3.8.4.12.8.6.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S5.T3.8.4.12.8.7" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.12.8.7.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S5.T3.8.4.12.8.8" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T3.8.4.12.8.8.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S5.T3.8.4.12.8.9" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T3.8.4.12.8.9.1" class="ltx_text" style="font-size:80%;">68.4</span></td>
<td id="S5.T3.8.4.12.8.10" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.12.8.10.1" class="ltx_text ltx_font_bold" style="font-size:80%;">76.1</span></td>
<td id="S5.T3.8.4.12.8.11" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T3.8.4.12.8.11.1" class="ltx_text" style="font-size:80%;">-</span></td>
<td id="S5.T3.8.4.12.8.12" class="ltx_td ltx_align_center"><span id="S5.T3.8.4.12.8.12.1" class="ltx_text" style="font-size:80%;">-</span></td>
</tr>
<tr id="S5.T3.8.4.13.9" class="ltx_tr">
<td id="S5.T3.8.4.13.9.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T3.8.4.13.9.1.1" class="ltx_text" style="font-size:80%;">DocOwl-1.5</span></td>
<td id="S5.T3.8.4.13.9.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T3.8.4.13.9.2.1" class="ltx_text" style="font-size:80%;">8.1B</span></td>
<td id="S5.T3.8.4.13.9.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T3.8.4.13.9.3.1" class="ltx_text" style="font-size:80%;">81.6</span></td>
<td id="S5.T3.8.4.13.9.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T3.8.4.13.9.4.1" class="ltx_text" style="font-size:80%;">50.4</span></td>
<td id="S5.T3.8.4.13.9.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T3.8.4.13.9.5.1" class="ltx_text" style="font-size:80%;">68.8</span></td>
<td id="S5.T3.8.4.13.9.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T3.8.4.13.9.6.1" class="ltx_text" style="font-size:80%;">37.9</span></td>
<td id="S5.T3.8.4.13.9.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T3.8.4.13.9.7.1" class="ltx_text" style="font-size:80%;">39.8</span></td>
<td id="S5.T3.8.4.13.9.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T3.8.4.13.9.8.1" class="ltx_text ltx_font_bold" style="font-size:80%;">80.4</span></td>
<td id="S5.T3.8.4.13.9.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T3.8.4.13.9.9.1" class="ltx_text ltx_font_bold" style="font-size:80%;">70.5</span></td>
<td id="S5.T3.8.4.13.9.10" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T3.8.4.13.9.10.1" class="ltx_text ltx_framed ltx_framed_underline" style="font-size:80%;">68.8</span></td>
<td id="S5.T3.8.4.13.9.11" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T3.8.4.13.9.11.1" class="ltx_text ltx_font_bold" style="font-size:80%;">132.0</span></td>
<td id="S5.T3.8.4.13.9.12" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T3.8.4.13.9.12.1" class="ltx_text" style="font-size:80%;">239.5</span></td>
</tr>
<tr id="S5.T3.8.4.14.10" class="ltx_tr">
<td id="S5.T3.8.4.14.10.1" class="ltx_td ltx_align_left ltx_border_bb"><span id="S5.T3.8.4.14.10.1.1" class="ltx_text" style="font-size:80%;">DocOwl-1.5-Chat</span></td>
<td id="S5.T3.8.4.14.10.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S5.T3.8.4.14.10.2.1" class="ltx_text" style="font-size:80%;">8.1B</span></td>
<td id="S5.T3.8.4.14.10.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T3.8.4.14.10.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">82.2</span></td>
<td id="S5.T3.8.4.14.10.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T3.8.4.14.10.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">50.7</span></td>
<td id="S5.T3.8.4.14.10.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T3.8.4.14.10.5.1" class="ltx_text ltx_font_bold" style="font-size:80%;">68.8</span></td>
<td id="S5.T3.8.4.14.10.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S5.T3.8.4.14.10.6.1" class="ltx_text ltx_font_bold" style="font-size:80%;">38.7</span></td>
<td id="S5.T3.8.4.14.10.7" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T3.8.4.14.10.7.1" class="ltx_text ltx_font_bold" style="font-size:80%;">40.6</span></td>
<td id="S5.T3.8.4.14.10.8" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S5.T3.8.4.14.10.8.1" class="ltx_text" style="font-size:80%;">80.2</span></td>
<td id="S5.T3.8.4.14.10.9" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S5.T3.8.4.14.10.9.1" class="ltx_text" style="font-size:80%;">70.2</span></td>
<td id="S5.T3.8.4.14.10.10" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T3.8.4.14.10.10.1" class="ltx_text" style="font-size:80%;">68.6</span></td>
<td id="S5.T3.8.4.14.10.11" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S5.T3.8.4.14.10.11.1" class="ltx_text" style="font-size:80%;">131.6</span></td>
<td id="S5.T3.8.4.14.10.12" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T3.8.4.14.10.12.1" class="ltx_text ltx_font_bold" style="font-size:80%;">246.4</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Main Results</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">We evaluate the Visual Document Understanding performance on 10 text-rich image benchmarks, covering documents (DocVQA <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>, InfoVQA <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>, DeepForm <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite>, KLC <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>), tables (WTQ <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>, TabFact <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>), charts (ChartQA <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>), natural images (TextVQA <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>, TextCaps <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>), and webpage screenshots (VisualMRC <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite>). We compare DocOwl 1.5 with state-of-the-art OCR-free models, including both Multimodal Large Language Models adapted for recognizing texts and much smaller models trained only for document understanding. The detailed comparison of model settings can be found in <a href="#S5.T2" title="In 5.1 Implementation Details ‣ 5 Experiments ‣ mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">2</span></a>. As shown in <a href="#S5.T3" title="In 5.1 Implementation Details ‣ 5 Experiments ‣ mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">3</span></a>, previous MLLMs with more than 7B parameters underperform domain-specific models with less than 1B parameters, showing that the document understanding is still a shortcoming for existing MLLMs. Our DocOwl 1.5 outperforms both domain-specific models and MLLMs with similar sizes on all 10 benchmarks. This validates that DocOwl 1.5 is much stronger on visual document understanding across 5 domains, covering visual question answering, information retrieval, natural language inference, and image captioning tasks. Besides, with much fewer unnatural data (3M vs 9M) and parameters (8.1B vs 17.3B), DocOwl 1.5 outperforms CogAgent <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> on InfoVQA and ChartQA, and achieves comparable performance on DocVQA. This suggests that our unified structure learning with DocStruct4M is more efficient in learning printed text recognition and how to analyze documents. However, our model still underperforms CogAgent on TextVQA, which requires the ability of scene text recognition and general knowledge about natural objects.
The primary reason is that scene texts are more diverse in shapes than printed texts and CogAgent is trained on 98M samples of scene text recognition from LAION-2B <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite> and COYO-700M <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>, much more than the natural images (1M) in DocStruct4M.
In this work, we mainly focus on improving the unified structure comprehension of visual documents and leave further scaling up data on natural scenes as future work. Finally, DocOwl 1.5-Chat can also be evaluated on these concise-answer benchmarks by removing the prompt of detailed explanation. It achieves comparable or slightly better performance than DocOwl 1.5, showing that a small amount of detailed explanatory data may better help the model understand the semantics of text-rich images.</p>
</div>
<figure id="S5.T4" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4: </span>Ablation study of model setting. ‘Crop’ refers to the maximum number of cropped images. ‘CropPos’ means using learnable embeddings (‘Emb’) or textual tokens (‘Text’) to represent the position of cropped images. ‘Parsing’ and ‘MTL’ refer to structure-aware parsing tasks and the Multi-grained Text Location task, respectively. ‘Owl(224)’ and ‘Owl2(448)’ refer to mPLUG-Owl <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite> with 224 resolution and mPLUG-Owl2 <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite> with 448 resolution, respectively.</figcaption>
<div id="S5.T4.35" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:255.3pt;vertical-align:-0.9pt;"><span class="ltx_transformed_inner" style="transform:translate(-13.3pt,7.8pt) scale(0.942195201175975,0.942195201175975) ;">
<table id="S5.T4.35.35" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S5.T4.35.35.36.1" class="ltx_tr">
<td id="S5.T4.35.35.36.1.1" class="ltx_td ltx_border_r ltx_border_tt"></td>
<td id="S5.T4.35.35.36.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="4"><span id="S5.T4.35.35.36.1.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Model Architecture</span></td>
<td id="S5.T4.35.35.36.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="S5.T4.35.35.36.1.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Structure</span></td>
<td id="S5.T4.35.35.36.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2"><span id="S5.T4.35.35.36.1.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Multi-task Tuning</span></td>
<td id="S5.T4.35.35.36.1.5" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2"><span id="S5.T4.35.35.36.1.5.1" class="ltx_text ltx_font_bold" style="font-size:80%;">DocVQA</span></td>
<td id="S5.T4.35.35.36.1.6" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2"><span id="S5.T4.35.35.36.1.6.1" class="ltx_text ltx_font_bold" style="font-size:80%;">TabFact</span></td>
<td id="S5.T4.35.35.36.1.7" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2"><span id="S5.T4.35.35.36.1.7.1" class="ltx_text ltx_font_bold" style="font-size:80%;">ChartQA</span></td>
</tr>
<tr id="S5.T4.35.35.37.2" class="ltx_tr">
<td id="S5.T4.35.35.37.2.1" class="ltx_td ltx_border_r"></td>
<td id="S5.T4.35.35.37.2.2" class="ltx_td ltx_align_center"><span id="S5.T4.35.35.37.2.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Init</span></td>
<td id="S5.T4.35.35.37.2.3" class="ltx_td ltx_align_center"><span id="S5.T4.35.35.37.2.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">V2T</span></td>
<td id="S5.T4.35.35.37.2.4" class="ltx_td ltx_align_center"><span id="S5.T4.35.35.37.2.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Crop</span></td>
<td id="S5.T4.35.35.37.2.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T4.35.35.37.2.5.1" class="ltx_text ltx_font_bold" style="font-size:80%;">CropPos</span></td>
<td id="S5.T4.35.35.37.2.6" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T4.35.35.37.2.6.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Learning</span></td>
<td id="S5.T4.35.35.37.2.7" class="ltx_td ltx_align_center"><span id="S5.T4.35.35.37.2.7.1" class="ltx_text ltx_font_bold" style="font-size:80%;">ViT</span></td>
<td id="S5.T4.35.35.37.2.8" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T4.35.35.37.2.8.1" class="ltx_text ltx_font_bold" style="font-size:80%;">LLM</span></td>
</tr>
<tr id="S5.T4.3.3.3" class="ltx_tr">
<td id="S5.T4.3.3.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T4.3.3.3.4.1" class="ltx_text" style="font-size:80%;">r1</span></td>
<td id="S5.T4.3.3.3.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T4.3.3.3.5.1" class="ltx_text" style="font-size:80%;">Owl(224)</span></td>
<td id="S5.T4.3.3.3.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T4.3.3.3.6.1" class="ltx_text" style="font-size:80%;">Abstractor</span></td>
<td id="S5.T4.3.3.3.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T4.3.3.3.7.1" class="ltx_text" style="font-size:80%;">20</span></td>
<td id="S5.T4.3.3.3.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T4.3.3.3.8.1" class="ltx_text" style="font-size:80%;">Emb</span></td>
<td id="S5.T4.1.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S5.T4.1.1.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T4.1.1.1.1.m1.1a"><mo mathsize="80%" id="S5.T4.1.1.1.1.m1.1.1" xref="S5.T4.1.1.1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T4.1.1.1.1.m1.1b"><times id="S5.T4.1.1.1.1.m1.1.1.cmml" xref="S5.T4.1.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.1.1.1.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T4.2.2.2.2" class="ltx_td ltx_align_center ltx_border_t"><math id="S5.T4.2.2.2.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T4.2.2.2.2.m1.1a"><mo mathsize="80%" id="S5.T4.2.2.2.2.m1.1.1" xref="S5.T4.2.2.2.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T4.2.2.2.2.m1.1b"><times id="S5.T4.2.2.2.2.m1.1.1.cmml" xref="S5.T4.2.2.2.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.2.2.2.2.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T4.3.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S5.T4.3.3.3.3.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T4.3.3.3.3.m1.1a"><mo mathsize="80%" id="S5.T4.3.3.3.3.m1.1.1" xref="S5.T4.3.3.3.3.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T4.3.3.3.3.m1.1b"><times id="S5.T4.3.3.3.3.m1.1.1.cmml" xref="S5.T4.3.3.3.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.3.3.3.3.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T4.3.3.3.9" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T4.3.3.3.9.1" class="ltx_text" style="font-size:80%;">65.4</span></td>
<td id="S5.T4.3.3.3.10" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T4.3.3.3.10.1" class="ltx_text" style="font-size:80%;">67.6</span></td>
<td id="S5.T4.3.3.3.11" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T4.3.3.3.11.1" class="ltx_text" style="font-size:80%;">59.3</span></td>
</tr>
<tr id="S5.T4.6.6.6" class="ltx_tr">
<td id="S5.T4.6.6.6.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T4.6.6.6.4.1" class="ltx_text" style="font-size:80%;">r2</span></td>
<td id="S5.T4.6.6.6.5" class="ltx_td ltx_align_center"><span id="S5.T4.6.6.6.5.1" class="ltx_text" style="font-size:80%;">Owl2(448)</span></td>
<td id="S5.T4.6.6.6.6" class="ltx_td ltx_align_center"><span id="S5.T4.6.6.6.6.1" class="ltx_text" style="font-size:80%;">Abstractor</span></td>
<td id="S5.T4.6.6.6.7" class="ltx_td ltx_align_center"><span id="S5.T4.6.6.6.7.1" class="ltx_text" style="font-size:80%;">20</span></td>
<td id="S5.T4.6.6.6.8" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T4.6.6.6.8.1" class="ltx_text" style="font-size:80%;">Emb</span></td>
<td id="S5.T4.4.4.4.1" class="ltx_td ltx_align_center ltx_border_r"><math id="S5.T4.4.4.4.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T4.4.4.4.1.m1.1a"><mo mathsize="80%" id="S5.T4.4.4.4.1.m1.1.1" xref="S5.T4.4.4.4.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T4.4.4.4.1.m1.1b"><times id="S5.T4.4.4.4.1.m1.1.1.cmml" xref="S5.T4.4.4.4.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.4.4.4.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T4.5.5.5.2" class="ltx_td ltx_align_center"><math id="S5.T4.5.5.5.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T4.5.5.5.2.m1.1a"><mo mathsize="80%" id="S5.T4.5.5.5.2.m1.1.1" xref="S5.T4.5.5.5.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T4.5.5.5.2.m1.1b"><times id="S5.T4.5.5.5.2.m1.1.1.cmml" xref="S5.T4.5.5.5.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.5.5.5.2.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T4.6.6.6.3" class="ltx_td ltx_align_center ltx_border_r"><math id="S5.T4.6.6.6.3.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T4.6.6.6.3.m1.1a"><mo mathsize="80%" id="S5.T4.6.6.6.3.m1.1.1" xref="S5.T4.6.6.6.3.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T4.6.6.6.3.m1.1b"><times id="S5.T4.6.6.6.3.m1.1.1.cmml" xref="S5.T4.6.6.6.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.6.6.6.3.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T4.6.6.6.9" class="ltx_td ltx_align_center"><span id="S5.T4.6.6.6.9.1" class="ltx_text" style="font-size:80%;">66.3</span></td>
<td id="S5.T4.6.6.6.10" class="ltx_td ltx_align_center"><span id="S5.T4.6.6.6.10.1" class="ltx_text" style="font-size:80%;">69.8</span></td>
<td id="S5.T4.6.6.6.11" class="ltx_td ltx_align_center"><span id="S5.T4.6.6.6.11.1" class="ltx_text" style="font-size:80%;">60.6</span></td>
</tr>
<tr id="S5.T4.9.9.9" class="ltx_tr">
<td id="S5.T4.9.9.9.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T4.9.9.9.4.1" class="ltx_text" style="font-size:80%;">r3</span></td>
<td id="S5.T4.9.9.9.5" class="ltx_td ltx_align_center"><span id="S5.T4.9.9.9.5.1" class="ltx_text" style="font-size:80%;">Owl2(448)</span></td>
<td id="S5.T4.9.9.9.6" class="ltx_td ltx_align_center"><span id="S5.T4.9.9.9.6.1" class="ltx_text" style="font-size:80%;">Abstractor</span></td>
<td id="S5.T4.9.9.9.7" class="ltx_td ltx_align_center"><span id="S5.T4.9.9.9.7.1" class="ltx_text" style="font-size:80%;">20</span></td>
<td id="S5.T4.9.9.9.8" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T4.9.9.9.8.1" class="ltx_text" style="font-size:80%;">Emb</span></td>
<td id="S5.T4.7.7.7.1" class="ltx_td ltx_align_center ltx_border_r"><math id="S5.T4.7.7.7.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T4.7.7.7.1.m1.1a"><mo mathsize="80%" id="S5.T4.7.7.7.1.m1.1.1" xref="S5.T4.7.7.7.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T4.7.7.7.1.m1.1b"><times id="S5.T4.7.7.7.1.m1.1.1.cmml" xref="S5.T4.7.7.7.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.7.7.7.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T4.8.8.8.2" class="ltx_td ltx_align_center"><math id="S5.T4.8.8.8.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S5.T4.8.8.8.2.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S5.T4.8.8.8.2.m1.1.1" xref="S5.T4.8.8.8.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S5.T4.8.8.8.2.m1.1b"><ci id="S5.T4.8.8.8.2.m1.1.1.cmml" xref="S5.T4.8.8.8.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.8.8.8.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S5.T4.9.9.9.3" class="ltx_td ltx_align_center ltx_border_r"><math id="S5.T4.9.9.9.3.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T4.9.9.9.3.m1.1a"><mo mathsize="80%" id="S5.T4.9.9.9.3.m1.1.1" xref="S5.T4.9.9.9.3.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T4.9.9.9.3.m1.1b"><times id="S5.T4.9.9.9.3.m1.1.1.cmml" xref="S5.T4.9.9.9.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.9.9.9.3.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T4.9.9.9.9" class="ltx_td ltx_align_center" style="background-color:#E6E6E6;"><span id="S5.T4.9.9.9.9.1" class="ltx_text" style="font-size:80%;background-color:#E6E6E6;">71.4</span></td>
<td id="S5.T4.9.9.9.10" class="ltx_td ltx_align_center" style="background-color:#E6E6E6;"><span id="S5.T4.9.9.9.10.1" class="ltx_text" style="font-size:80%;background-color:#E6E6E6;">70.3</span></td>
<td id="S5.T4.9.9.9.11" class="ltx_td ltx_align_center" style="background-color:#E6E6E6;"><span id="S5.T4.9.9.9.11.1" class="ltx_text" style="font-size:80%;background-color:#E6E6E6;">64.2</span></td>
</tr>
<tr id="S5.T4.12.12.12" class="ltx_tr">
<td id="S5.T4.12.12.12.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T4.12.12.12.4.1" class="ltx_text" style="font-size:80%;">r4</span></td>
<td id="S5.T4.12.12.12.5" class="ltx_td ltx_align_center"><span id="S5.T4.12.12.12.5.1" class="ltx_text" style="font-size:80%;">Owl2(448)</span></td>
<td id="S5.T4.12.12.12.6" class="ltx_td ltx_align_center"><span id="S5.T4.12.12.12.6.1" class="ltx_text" style="font-size:80%;">Abstractor</span></td>
<td id="S5.T4.12.12.12.7" class="ltx_td ltx_align_center"><span id="S5.T4.12.12.12.7.1" class="ltx_text" style="font-size:80%;">9</span></td>
<td id="S5.T4.12.12.12.8" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T4.12.12.12.8.1" class="ltx_text" style="font-size:80%;">Emb</span></td>
<td id="S5.T4.10.10.10.1" class="ltx_td ltx_align_center ltx_border_r"><math id="S5.T4.10.10.10.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T4.10.10.10.1.m1.1a"><mo mathsize="80%" id="S5.T4.10.10.10.1.m1.1.1" xref="S5.T4.10.10.10.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T4.10.10.10.1.m1.1b"><times id="S5.T4.10.10.10.1.m1.1.1.cmml" xref="S5.T4.10.10.10.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.10.10.10.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T4.11.11.11.2" class="ltx_td ltx_align_center"><math id="S5.T4.11.11.11.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S5.T4.11.11.11.2.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S5.T4.11.11.11.2.m1.1.1" xref="S5.T4.11.11.11.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S5.T4.11.11.11.2.m1.1b"><ci id="S5.T4.11.11.11.2.m1.1.1.cmml" xref="S5.T4.11.11.11.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.11.11.11.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S5.T4.12.12.12.3" class="ltx_td ltx_align_center ltx_border_r"><math id="S5.T4.12.12.12.3.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T4.12.12.12.3.m1.1a"><mo mathsize="80%" id="S5.T4.12.12.12.3.m1.1.1" xref="S5.T4.12.12.12.3.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T4.12.12.12.3.m1.1b"><times id="S5.T4.12.12.12.3.m1.1.1.cmml" xref="S5.T4.12.12.12.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.12.12.12.3.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T4.12.12.12.9" class="ltx_td ltx_align_center"><span id="S5.T4.12.12.12.9.1" class="ltx_text" style="font-size:80%;">68.0</span></td>
<td id="S5.T4.12.12.12.10" class="ltx_td ltx_align_center"><span id="S5.T4.12.12.12.10.1" class="ltx_text" style="font-size:80%;">70.0</span></td>
<td id="S5.T4.12.12.12.11" class="ltx_td ltx_align_center"><span id="S5.T4.12.12.12.11.1" class="ltx_text" style="font-size:80%;">64.2</span></td>
</tr>
<tr id="S5.T4.15.15.15" class="ltx_tr">
<td id="S5.T4.15.15.15.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T4.15.15.15.4.1" class="ltx_text" style="font-size:80%;">r5</span></td>
<td id="S5.T4.15.15.15.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T4.15.15.15.5.1" class="ltx_text" style="font-size:80%;">Owl2(448)</span></td>
<td id="S5.T4.15.15.15.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T4.15.15.15.6.1" class="ltx_text" style="font-size:80%;">H-Reducer(1x4)</span></td>
<td id="S5.T4.15.15.15.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T4.15.15.15.7.1" class="ltx_text" style="font-size:80%;">9</span></td>
<td id="S5.T4.15.15.15.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T4.15.15.15.8.1" class="ltx_text" style="font-size:80%;">Emb</span></td>
<td id="S5.T4.13.13.13.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S5.T4.13.13.13.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T4.13.13.13.1.m1.1a"><mo mathsize="80%" id="S5.T4.13.13.13.1.m1.1.1" xref="S5.T4.13.13.13.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T4.13.13.13.1.m1.1b"><times id="S5.T4.13.13.13.1.m1.1.1.cmml" xref="S5.T4.13.13.13.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.13.13.13.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T4.14.14.14.2" class="ltx_td ltx_align_center ltx_border_t"><math id="S5.T4.14.14.14.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S5.T4.14.14.14.2.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S5.T4.14.14.14.2.m1.1.1" xref="S5.T4.14.14.14.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S5.T4.14.14.14.2.m1.1b"><ci id="S5.T4.14.14.14.2.m1.1.1.cmml" xref="S5.T4.14.14.14.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.14.14.14.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S5.T4.15.15.15.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S5.T4.15.15.15.3.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T4.15.15.15.3.m1.1a"><mo mathsize="80%" id="S5.T4.15.15.15.3.m1.1.1" xref="S5.T4.15.15.15.3.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T4.15.15.15.3.m1.1b"><times id="S5.T4.15.15.15.3.m1.1.1.cmml" xref="S5.T4.15.15.15.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.15.15.15.3.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T4.15.15.15.9" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#E6E6E6;"><span id="S5.T4.15.15.15.9.1" class="ltx_text" style="font-size:80%;background-color:#E6E6E6;">72.8</span></td>
<td id="S5.T4.15.15.15.10" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#E6E6E6;"><span id="S5.T4.15.15.15.10.1" class="ltx_text" style="font-size:80%;background-color:#E6E6E6;">72.9</span></td>
<td id="S5.T4.15.15.15.11" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#E6E6E6;"><span id="S5.T4.15.15.15.11.1" class="ltx_text" style="font-size:80%;background-color:#E6E6E6;">65.0</span></td>
</tr>
<tr id="S5.T4.18.18.18" class="ltx_tr">
<td id="S5.T4.18.18.18.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T4.18.18.18.4.1" class="ltx_text" style="font-size:80%;">r6</span></td>
<td id="S5.T4.18.18.18.5" class="ltx_td ltx_align_center"><span id="S5.T4.18.18.18.5.1" class="ltx_text" style="font-size:80%;">Owl2(448)</span></td>
<td id="S5.T4.18.18.18.6" class="ltx_td ltx_align_center"><span id="S5.T4.18.18.18.6.1" class="ltx_text" style="font-size:80%;">H-Reducer(2x2)</span></td>
<td id="S5.T4.18.18.18.7" class="ltx_td ltx_align_center"><span id="S5.T4.18.18.18.7.1" class="ltx_text" style="font-size:80%;">9</span></td>
<td id="S5.T4.18.18.18.8" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T4.18.18.18.8.1" class="ltx_text" style="font-size:80%;">Emb</span></td>
<td id="S5.T4.16.16.16.1" class="ltx_td ltx_align_center ltx_border_r"><math id="S5.T4.16.16.16.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T4.16.16.16.1.m1.1a"><mo mathsize="80%" id="S5.T4.16.16.16.1.m1.1.1" xref="S5.T4.16.16.16.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T4.16.16.16.1.m1.1b"><times id="S5.T4.16.16.16.1.m1.1.1.cmml" xref="S5.T4.16.16.16.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.16.16.16.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T4.17.17.17.2" class="ltx_td ltx_align_center"><math id="S5.T4.17.17.17.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S5.T4.17.17.17.2.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S5.T4.17.17.17.2.m1.1.1" xref="S5.T4.17.17.17.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S5.T4.17.17.17.2.m1.1b"><ci id="S5.T4.17.17.17.2.m1.1.1.cmml" xref="S5.T4.17.17.17.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.17.17.17.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S5.T4.18.18.18.3" class="ltx_td ltx_align_center ltx_border_r"><math id="S5.T4.18.18.18.3.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T4.18.18.18.3.m1.1a"><mo mathsize="80%" id="S5.T4.18.18.18.3.m1.1.1" xref="S5.T4.18.18.18.3.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T4.18.18.18.3.m1.1b"><times id="S5.T4.18.18.18.3.m1.1.1.cmml" xref="S5.T4.18.18.18.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.18.18.18.3.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T4.18.18.18.9" class="ltx_td ltx_align_center"><span id="S5.T4.18.18.18.9.1" class="ltx_text" style="font-size:80%;">71.8</span></td>
<td id="S5.T4.18.18.18.10" class="ltx_td ltx_align_center"><span id="S5.T4.18.18.18.10.1" class="ltx_text" style="font-size:80%;">72.1</span></td>
<td id="S5.T4.18.18.18.11" class="ltx_td ltx_align_center"><span id="S5.T4.18.18.18.11.1" class="ltx_text" style="font-size:80%;">65.2</span></td>
</tr>
<tr id="S5.T4.21.21.21" class="ltx_tr">
<td id="S5.T4.21.21.21.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T4.21.21.21.4.1" class="ltx_text" style="font-size:80%;">r7</span></td>
<td id="S5.T4.21.21.21.5" class="ltx_td ltx_align_center"><span id="S5.T4.21.21.21.5.1" class="ltx_text" style="font-size:80%;">Owl2(448)</span></td>
<td id="S5.T4.21.21.21.6" class="ltx_td ltx_align_center"><span id="S5.T4.21.21.21.6.1" class="ltx_text" style="font-size:80%;">H-Reducer(2x4)</span></td>
<td id="S5.T4.21.21.21.7" class="ltx_td ltx_align_center"><span id="S5.T4.21.21.21.7.1" class="ltx_text" style="font-size:80%;">9</span></td>
<td id="S5.T4.21.21.21.8" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T4.21.21.21.8.1" class="ltx_text" style="font-size:80%;">Emb</span></td>
<td id="S5.T4.19.19.19.1" class="ltx_td ltx_align_center ltx_border_r"><math id="S5.T4.19.19.19.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T4.19.19.19.1.m1.1a"><mo mathsize="80%" id="S5.T4.19.19.19.1.m1.1.1" xref="S5.T4.19.19.19.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T4.19.19.19.1.m1.1b"><times id="S5.T4.19.19.19.1.m1.1.1.cmml" xref="S5.T4.19.19.19.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.19.19.19.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T4.20.20.20.2" class="ltx_td ltx_align_center"><math id="S5.T4.20.20.20.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S5.T4.20.20.20.2.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S5.T4.20.20.20.2.m1.1.1" xref="S5.T4.20.20.20.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S5.T4.20.20.20.2.m1.1b"><ci id="S5.T4.20.20.20.2.m1.1.1.cmml" xref="S5.T4.20.20.20.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.20.20.20.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S5.T4.21.21.21.3" class="ltx_td ltx_align_center ltx_border_r"><math id="S5.T4.21.21.21.3.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T4.21.21.21.3.m1.1a"><mo mathsize="80%" id="S5.T4.21.21.21.3.m1.1.1" xref="S5.T4.21.21.21.3.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T4.21.21.21.3.m1.1b"><times id="S5.T4.21.21.21.3.m1.1.1.cmml" xref="S5.T4.21.21.21.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.21.21.21.3.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T4.21.21.21.9" class="ltx_td ltx_align_center"><span id="S5.T4.21.21.21.9.1" class="ltx_text" style="font-size:80%;">71.4</span></td>
<td id="S5.T4.21.21.21.10" class="ltx_td ltx_align_center"><span id="S5.T4.21.21.21.10.1" class="ltx_text" style="font-size:80%;">71.1</span></td>
<td id="S5.T4.21.21.21.11" class="ltx_td ltx_align_center"><span id="S5.T4.21.21.21.11.1" class="ltx_text" style="font-size:80%;">66.0</span></td>
</tr>
<tr id="S5.T4.24.24.24" class="ltx_tr">
<td id="S5.T4.24.24.24.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T4.24.24.24.4.1" class="ltx_text" style="font-size:80%;">r8</span></td>
<td id="S5.T4.24.24.24.5" class="ltx_td ltx_align_center"><span id="S5.T4.24.24.24.5.1" class="ltx_text" style="font-size:80%;">Owl2(448)</span></td>
<td id="S5.T4.24.24.24.6" class="ltx_td ltx_align_center"><span id="S5.T4.24.24.24.6.1" class="ltx_text" style="font-size:80%;">H-Reducer(1x8)</span></td>
<td id="S5.T4.24.24.24.7" class="ltx_td ltx_align_center"><span id="S5.T4.24.24.24.7.1" class="ltx_text" style="font-size:80%;">9</span></td>
<td id="S5.T4.24.24.24.8" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T4.24.24.24.8.1" class="ltx_text" style="font-size:80%;">Emb</span></td>
<td id="S5.T4.22.22.22.1" class="ltx_td ltx_align_center ltx_border_r"><math id="S5.T4.22.22.22.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T4.22.22.22.1.m1.1a"><mo mathsize="80%" id="S5.T4.22.22.22.1.m1.1.1" xref="S5.T4.22.22.22.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T4.22.22.22.1.m1.1b"><times id="S5.T4.22.22.22.1.m1.1.1.cmml" xref="S5.T4.22.22.22.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.22.22.22.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T4.23.23.23.2" class="ltx_td ltx_align_center"><math id="S5.T4.23.23.23.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S5.T4.23.23.23.2.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S5.T4.23.23.23.2.m1.1.1" xref="S5.T4.23.23.23.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S5.T4.23.23.23.2.m1.1b"><ci id="S5.T4.23.23.23.2.m1.1.1.cmml" xref="S5.T4.23.23.23.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.23.23.23.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S5.T4.24.24.24.3" class="ltx_td ltx_align_center ltx_border_r"><math id="S5.T4.24.24.24.3.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T4.24.24.24.3.m1.1a"><mo mathsize="80%" id="S5.T4.24.24.24.3.m1.1.1" xref="S5.T4.24.24.24.3.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T4.24.24.24.3.m1.1b"><times id="S5.T4.24.24.24.3.m1.1.1.cmml" xref="S5.T4.24.24.24.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.24.24.24.3.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T4.24.24.24.9" class="ltx_td ltx_align_center"><span id="S5.T4.24.24.24.9.1" class="ltx_text" style="font-size:80%;">69.9</span></td>
<td id="S5.T4.24.24.24.10" class="ltx_td ltx_align_center"><span id="S5.T4.24.24.24.10.1" class="ltx_text" style="font-size:80%;">71.2</span></td>
<td id="S5.T4.24.24.24.11" class="ltx_td ltx_align_center"><span id="S5.T4.24.24.24.11.1" class="ltx_text" style="font-size:80%;">64.4</span></td>
</tr>
<tr id="S5.T4.27.27.27" class="ltx_tr">
<td id="S5.T4.27.27.27.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T4.27.27.27.4.1" class="ltx_text" style="font-size:80%;">r9</span></td>
<td id="S5.T4.27.27.27.5" class="ltx_td ltx_align_center"><span id="S5.T4.27.27.27.5.1" class="ltx_text" style="font-size:80%;">Owl2(448)</span></td>
<td id="S5.T4.27.27.27.6" class="ltx_td ltx_align_center"><span id="S5.T4.27.27.27.6.1" class="ltx_text" style="font-size:80%;">H-Reducer(2x8)</span></td>
<td id="S5.T4.27.27.27.7" class="ltx_td ltx_align_center"><span id="S5.T4.27.27.27.7.1" class="ltx_text" style="font-size:80%;">9</span></td>
<td id="S5.T4.27.27.27.8" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T4.27.27.27.8.1" class="ltx_text" style="font-size:80%;">Emb</span></td>
<td id="S5.T4.25.25.25.1" class="ltx_td ltx_align_center ltx_border_r"><math id="S5.T4.25.25.25.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T4.25.25.25.1.m1.1a"><mo mathsize="80%" id="S5.T4.25.25.25.1.m1.1.1" xref="S5.T4.25.25.25.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T4.25.25.25.1.m1.1b"><times id="S5.T4.25.25.25.1.m1.1.1.cmml" xref="S5.T4.25.25.25.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.25.25.25.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T4.26.26.26.2" class="ltx_td ltx_align_center"><math id="S5.T4.26.26.26.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S5.T4.26.26.26.2.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S5.T4.26.26.26.2.m1.1.1" xref="S5.T4.26.26.26.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S5.T4.26.26.26.2.m1.1b"><ci id="S5.T4.26.26.26.2.m1.1.1.cmml" xref="S5.T4.26.26.26.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.26.26.26.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S5.T4.27.27.27.3" class="ltx_td ltx_align_center ltx_border_r"><math id="S5.T4.27.27.27.3.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T4.27.27.27.3.m1.1a"><mo mathsize="80%" id="S5.T4.27.27.27.3.m1.1.1" xref="S5.T4.27.27.27.3.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T4.27.27.27.3.m1.1b"><times id="S5.T4.27.27.27.3.m1.1.1.cmml" xref="S5.T4.27.27.27.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.27.27.27.3.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T4.27.27.27.9" class="ltx_td ltx_align_center"><span id="S5.T4.27.27.27.9.1" class="ltx_text" style="font-size:80%;">69.2</span></td>
<td id="S5.T4.27.27.27.10" class="ltx_td ltx_align_center"><span id="S5.T4.27.27.27.10.1" class="ltx_text" style="font-size:80%;">70.2</span></td>
<td id="S5.T4.27.27.27.11" class="ltx_td ltx_align_center"><span id="S5.T4.27.27.27.11.1" class="ltx_text" style="font-size:80%;">65.6</span></td>
</tr>
<tr id="S5.T4.29.29.29" class="ltx_tr">
<td id="S5.T4.29.29.29.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T4.29.29.29.3.1" class="ltx_text" style="font-size:80%;">r10</span></td>
<td id="S5.T4.29.29.29.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T4.29.29.29.4.1" class="ltx_text" style="font-size:80%;">Owl2(448)</span></td>
<td id="S5.T4.29.29.29.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T4.29.29.29.5.1" class="ltx_text" style="font-size:80%;">H-Reducer(1x4)</span></td>
<td id="S5.T4.29.29.29.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T4.29.29.29.6.1" class="ltx_text" style="font-size:80%;">9</span></td>
<td id="S5.T4.29.29.29.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T4.29.29.29.7.1" class="ltx_text" style="font-size:80%;">Emb</span></td>
<td id="S5.T4.29.29.29.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T4.29.29.29.8.1" class="ltx_text" style="font-size:80%;">Parsing</span></td>
<td id="S5.T4.28.28.28.1" class="ltx_td ltx_align_center ltx_border_t"><math id="S5.T4.28.28.28.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T4.28.28.28.1.m1.1a"><mo mathsize="80%" id="S5.T4.28.28.28.1.m1.1.1" xref="S5.T4.28.28.28.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T4.28.28.28.1.m1.1b"><times id="S5.T4.28.28.28.1.m1.1.1.cmml" xref="S5.T4.28.28.28.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.28.28.28.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T4.29.29.29.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math id="S5.T4.29.29.29.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T4.29.29.29.2.m1.1a"><mo mathsize="80%" id="S5.T4.29.29.29.2.m1.1.1" xref="S5.T4.29.29.29.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T4.29.29.29.2.m1.1b"><times id="S5.T4.29.29.29.2.m1.1.1.cmml" xref="S5.T4.29.29.29.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.29.29.29.2.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T4.29.29.29.9" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T4.29.29.29.9.1" class="ltx_text" style="font-size:80%;">77.7</span></td>
<td id="S5.T4.29.29.29.10" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T4.29.29.29.10.1" class="ltx_text" style="font-size:80%;">76.5</span></td>
<td id="S5.T4.29.29.29.11" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T4.29.29.29.11.1" class="ltx_text" style="font-size:80%;">67.5</span></td>
</tr>
<tr id="S5.T4.31.31.31" class="ltx_tr">
<td id="S5.T4.31.31.31.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T4.31.31.31.3.1" class="ltx_text" style="font-size:80%;">r11</span></td>
<td id="S5.T4.31.31.31.4" class="ltx_td ltx_align_center"><span id="S5.T4.31.31.31.4.1" class="ltx_text" style="font-size:80%;">Owl2(448)</span></td>
<td id="S5.T4.31.31.31.5" class="ltx_td ltx_align_center"><span id="S5.T4.31.31.31.5.1" class="ltx_text" style="font-size:80%;">H-Reducer(1x4)</span></td>
<td id="S5.T4.31.31.31.6" class="ltx_td ltx_align_center"><span id="S5.T4.31.31.31.6.1" class="ltx_text" style="font-size:80%;">9</span></td>
<td id="S5.T4.31.31.31.7" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T4.31.31.31.7.1" class="ltx_text" style="font-size:80%;">Emb</span></td>
<td id="S5.T4.31.31.31.8" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T4.31.31.31.8.1" class="ltx_text" style="font-size:80%;">Parsing</span></td>
<td id="S5.T4.30.30.30.1" class="ltx_td ltx_align_center"><math id="S5.T4.30.30.30.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T4.30.30.30.1.m1.1a"><mo mathsize="80%" id="S5.T4.30.30.30.1.m1.1.1" xref="S5.T4.30.30.30.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T4.30.30.30.1.m1.1b"><times id="S5.T4.30.30.30.1.m1.1.1.cmml" xref="S5.T4.30.30.30.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.30.30.30.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T4.31.31.31.2" class="ltx_td ltx_align_center ltx_border_r"><math id="S5.T4.31.31.31.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S5.T4.31.31.31.2.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S5.T4.31.31.31.2.m1.1.1" xref="S5.T4.31.31.31.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S5.T4.31.31.31.2.m1.1b"><ci id="S5.T4.31.31.31.2.m1.1.1.cmml" xref="S5.T4.31.31.31.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.31.31.31.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S5.T4.31.31.31.9" class="ltx_td ltx_align_center"><span id="S5.T4.31.31.31.9.1" class="ltx_text" style="font-size:80%;">78.9</span></td>
<td id="S5.T4.31.31.31.10" class="ltx_td ltx_align_center"><span id="S5.T4.31.31.31.10.1" class="ltx_text" style="font-size:80%;">78.1</span></td>
<td id="S5.T4.31.31.31.11" class="ltx_td ltx_align_center"><span id="S5.T4.31.31.31.11.1" class="ltx_text" style="font-size:80%;">68.1</span></td>
</tr>
<tr id="S5.T4.33.33.33" class="ltx_tr">
<td id="S5.T4.33.33.33.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T4.33.33.33.3.1" class="ltx_text" style="font-size:80%;">r12</span></td>
<td id="S5.T4.33.33.33.4" class="ltx_td ltx_align_center"><span id="S5.T4.33.33.33.4.1" class="ltx_text" style="font-size:80%;">Owl2(448)</span></td>
<td id="S5.T4.33.33.33.5" class="ltx_td ltx_align_center"><span id="S5.T4.33.33.33.5.1" class="ltx_text" style="font-size:80%;">H-Reducer(1x4)</span></td>
<td id="S5.T4.33.33.33.6" class="ltx_td ltx_align_center"><span id="S5.T4.33.33.33.6.1" class="ltx_text" style="font-size:80%;">9</span></td>
<td id="S5.T4.33.33.33.7" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T4.33.33.33.7.1" class="ltx_text" style="font-size:80%;">Text</span></td>
<td id="S5.T4.33.33.33.8" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T4.33.33.33.8.1" class="ltx_text" style="font-size:80%;">Parsing</span></td>
<td id="S5.T4.32.32.32.1" class="ltx_td ltx_align_center"><math id="S5.T4.32.32.32.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T4.32.32.32.1.m1.1a"><mo mathsize="80%" id="S5.T4.32.32.32.1.m1.1.1" xref="S5.T4.32.32.32.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T4.32.32.32.1.m1.1b"><times id="S5.T4.32.32.32.1.m1.1.1.cmml" xref="S5.T4.32.32.32.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.32.32.32.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T4.33.33.33.2" class="ltx_td ltx_align_center ltx_border_r"><math id="S5.T4.33.33.33.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S5.T4.33.33.33.2.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S5.T4.33.33.33.2.m1.1.1" xref="S5.T4.33.33.33.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S5.T4.33.33.33.2.m1.1b"><ci id="S5.T4.33.33.33.2.m1.1.1.cmml" xref="S5.T4.33.33.33.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.33.33.33.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S5.T4.33.33.33.9" class="ltx_td ltx_align_center"><span id="S5.T4.33.33.33.9.1" class="ltx_text" style="font-size:80%;">79.8</span></td>
<td id="S5.T4.33.33.33.10" class="ltx_td ltx_align_center"><span id="S5.T4.33.33.33.10.1" class="ltx_text" style="font-size:80%;">77.7</span></td>
<td id="S5.T4.33.33.33.11" class="ltx_td ltx_align_center"><span id="S5.T4.33.33.33.11.1" class="ltx_text" style="font-size:80%;">69.1</span></td>
</tr>
<tr id="S5.T4.35.35.35" class="ltx_tr">
<td id="S5.T4.35.35.35.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S5.T4.35.35.35.3.1" class="ltx_text" style="font-size:80%;">r13</span></td>
<td id="S5.T4.35.35.35.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T4.35.35.35.4.1" class="ltx_text" style="font-size:80%;">Owl2(448)</span></td>
<td id="S5.T4.35.35.35.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T4.35.35.35.5.1" class="ltx_text" style="font-size:80%;">H-Reducer(1x4)</span></td>
<td id="S5.T4.35.35.35.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T4.35.35.35.6.1" class="ltx_text" style="font-size:80%;">9</span></td>
<td id="S5.T4.35.35.35.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S5.T4.35.35.35.7.1" class="ltx_text" style="font-size:80%;">Text</span></td>
<td id="S5.T4.35.35.35.8" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S5.T4.35.35.35.8.1" class="ltx_text" style="font-size:80%;">Parsing+MTL</span></td>
<td id="S5.T4.34.34.34.1" class="ltx_td ltx_align_center ltx_border_bb"><math id="S5.T4.34.34.34.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T4.34.34.34.1.m1.1a"><mo mathsize="80%" id="S5.T4.34.34.34.1.m1.1.1" xref="S5.T4.34.34.34.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.T4.34.34.34.1.m1.1b"><times id="S5.T4.34.34.34.1.m1.1.1.cmml" xref="S5.T4.34.34.34.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.34.34.34.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S5.T4.35.35.35.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><math id="S5.T4.35.35.35.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S5.T4.35.35.35.2.m1.1a"><mi mathsize="80%" mathvariant="normal" id="S5.T4.35.35.35.2.m1.1.1" xref="S5.T4.35.35.35.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S5.T4.35.35.35.2.m1.1b"><ci id="S5.T4.35.35.35.2.m1.1.1.cmml" xref="S5.T4.35.35.35.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.35.35.35.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S5.T4.35.35.35.9" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#E6E6E6;"><span id="S5.T4.35.35.35.9.1" class="ltx_text" style="font-size:80%;background-color:#E6E6E6;">81.6</span></td>
<td id="S5.T4.35.35.35.10" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#E6E6E6;"><span id="S5.T4.35.35.35.10.1" class="ltx_text" style="font-size:80%;background-color:#E6E6E6;">80.4</span></td>
<td id="S5.T4.35.35.35.11" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#E6E6E6;"><span id="S5.T4.35.35.35.11.1" class="ltx_text" style="font-size:80%;background-color:#E6E6E6;">70.5</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Ablation Study</h3>

<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.1" class="ltx_p">As shown in <a href="#S5.T4" title="In 5.2 Main Results ‣ 5 Experiments ‣ mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">4</span></a>, we further perform a comprehensive ablation study to validate the effectiveness of our H-Reducer and Unified Structure Learning.</p>
</div>
<div id="S5.SS3.p2" class="ltx_para">
<p id="S5.SS3.p2.1" class="ltx_p">Firstly, initializing from a stronger general MLLMs brings better performance on text-rich images (r2 vs r1), showing general vision-and-language knowledge benefits visual document understanding. Tuning the visual encoder during multi-task fine-tuning significantly improves the document understanding performance (r3 vs r2). This suggests that the visual representation of document images may be the main shortcoming of MLLMs and inspires us to design Unified Structure Learning to enhance the representation ability of the visual encoder for visually situated texts and structure.</p>
</div>
<div id="S5.SS3.p3" class="ltx_para ltx_noindent">
<p id="S5.SS3.p3.1" class="ltx_p"><span id="S5.SS3.p3.1.1" class="ltx_text ltx_font_bold">Effectiveness of H-Reducer.</span> When using the Shape-adaptive Cropping Module, the image resolution supported by the MLLM is the product of the cropping number and basic resolution of each crop. With the Abstractor as the vision-to-text module, reducing the cropping number causes an obvious performance decrease (r4 vs r3) on documents. However, with a smaller cropping number, the H-Reducer achieves better performance than the Abstractor (r5 vs r3), showing that <math id="S5.SS3.p3.1.m1.1" class="ltx_Math" alttext="448^{2}\times 9\approx 2^{21}" display="inline"><semantics id="S5.SS3.p3.1.m1.1a"><mrow id="S5.SS3.p3.1.m1.1.1" xref="S5.SS3.p3.1.m1.1.1.cmml"><mrow id="S5.SS3.p3.1.m1.1.1.2" xref="S5.SS3.p3.1.m1.1.1.2.cmml"><msup id="S5.SS3.p3.1.m1.1.1.2.2" xref="S5.SS3.p3.1.m1.1.1.2.2.cmml"><mn id="S5.SS3.p3.1.m1.1.1.2.2.2" xref="S5.SS3.p3.1.m1.1.1.2.2.2.cmml">448</mn><mn id="S5.SS3.p3.1.m1.1.1.2.2.3" xref="S5.SS3.p3.1.m1.1.1.2.2.3.cmml">2</mn></msup><mo lspace="0.222em" rspace="0.222em" id="S5.SS3.p3.1.m1.1.1.2.1" xref="S5.SS3.p3.1.m1.1.1.2.1.cmml">×</mo><mn id="S5.SS3.p3.1.m1.1.1.2.3" xref="S5.SS3.p3.1.m1.1.1.2.3.cmml">9</mn></mrow><mo id="S5.SS3.p3.1.m1.1.1.1" xref="S5.SS3.p3.1.m1.1.1.1.cmml">≈</mo><msup id="S5.SS3.p3.1.m1.1.1.3" xref="S5.SS3.p3.1.m1.1.1.3.cmml"><mn id="S5.SS3.p3.1.m1.1.1.3.2" xref="S5.SS3.p3.1.m1.1.1.3.2.cmml">2</mn><mn id="S5.SS3.p3.1.m1.1.1.3.3" xref="S5.SS3.p3.1.m1.1.1.3.3.cmml">21</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p3.1.m1.1b"><apply id="S5.SS3.p3.1.m1.1.1.cmml" xref="S5.SS3.p3.1.m1.1.1"><approx id="S5.SS3.p3.1.m1.1.1.1.cmml" xref="S5.SS3.p3.1.m1.1.1.1"></approx><apply id="S5.SS3.p3.1.m1.1.1.2.cmml" xref="S5.SS3.p3.1.m1.1.1.2"><times id="S5.SS3.p3.1.m1.1.1.2.1.cmml" xref="S5.SS3.p3.1.m1.1.1.2.1"></times><apply id="S5.SS3.p3.1.m1.1.1.2.2.cmml" xref="S5.SS3.p3.1.m1.1.1.2.2"><csymbol cd="ambiguous" id="S5.SS3.p3.1.m1.1.1.2.2.1.cmml" xref="S5.SS3.p3.1.m1.1.1.2.2">superscript</csymbol><cn type="integer" id="S5.SS3.p3.1.m1.1.1.2.2.2.cmml" xref="S5.SS3.p3.1.m1.1.1.2.2.2">448</cn><cn type="integer" id="S5.SS3.p3.1.m1.1.1.2.2.3.cmml" xref="S5.SS3.p3.1.m1.1.1.2.2.3">2</cn></apply><cn type="integer" id="S5.SS3.p3.1.m1.1.1.2.3.cmml" xref="S5.SS3.p3.1.m1.1.1.2.3">9</cn></apply><apply id="S5.SS3.p3.1.m1.1.1.3.cmml" xref="S5.SS3.p3.1.m1.1.1.3"><csymbol cd="ambiguous" id="S5.SS3.p3.1.m1.1.1.3.1.cmml" xref="S5.SS3.p3.1.m1.1.1.3">superscript</csymbol><cn type="integer" id="S5.SS3.p3.1.m1.1.1.3.2.cmml" xref="S5.SS3.p3.1.m1.1.1.3.2">2</cn><cn type="integer" id="S5.SS3.p3.1.m1.1.1.3.3.cmml" xref="S5.SS3.p3.1.m1.1.1.3.3">21</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p3.1.m1.1c">448^{2}\times 9\approx 2^{21}</annotation></semantics></math> is an acceptable resolution for existing benchmarks and the H-Reducer is stronger on maintaining rich text information during vision-and-language feature alignment. Besides, we further compare different settings of the merging shape in the convolution layer. With the same number of merged tokens, the model with the 1x4 merging shape achieves better performance than the one with the 2x2 merging shape on document and table datasets but slightly worse performance on chart understanding (r6 vs r5). This is consistent with the common sense that documents and tables mainly organize texts in the left-to-right order while the semantic structures of charts are much more flexible. A square merging shape is more suited to encode visual features in the form of bars, lines, or pies while the 1x4 merging shape is more appropriate for general document understanding. As shown in r7-r9, further extending the 1x4 merging shape horizontally and vertically decreases the length of visual features but at the cost of performance degradation. Considering the overall performance on all text-rich images, we finally choose the 1x4 as the merging shape in H-Reducer.</p>
</div>
<div id="S5.SS3.p4" class="ltx_para ltx_noindent">
<p id="S5.SS3.p4.1" class="ltx_p"><span id="S5.SS3.p4.1.1" class="ltx_text ltx_font_bold">Effectiveness of Unified Structure Learning.</span> After determining the vision-to-text module, we perform two-stage training with Unified Structure Learning. With only the structure-aware parsing tasks, there is significant improvement across different domains (r10 vs r5). This validates that fine-tuning the visual encoder and H-Reducer with structure-aware parsing tasks greatly helps MLLMs understand text-rich images. Further tuning the parameters of LLM brings slight improvement (r11 vs r10), suggesting that general language knowledge is not the main obstacle to visual document understanding. By replacing the learnable crop position embeddings with special textual tokens, the model achieves better performance (r12 vs r11), showing that the LLM can well understand the relative positions of multiple cropped images with just simple textual indicators. Finally, by introducing Multi-grained Text Localization tasks, DocOwl 1.5 achieves the best performance, validating that correlating visually situated texts with concrete positions helps comprehend documents more accurately.</p>
</div>
<figure id="S5.T5" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 5: </span>The comparison of two-stage training and one-stage joint training with increasing samples from DocStruct4M. For a fair comparison, the LLM is frozen for both two-stage and one-stage training. The bath size of one-stage training is always set as 256, the same as the Multi-task Tuning in two-stage training. </figcaption>
<table id="S5.T5.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T5.1.1.1" class="ltx_tr">
<th id="S5.T5.1.1.1.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt"></th>
<th id="S5.T5.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" colspan="5"><span id="S5.T5.1.1.1.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">One-Stage</span></th>
<th id="S5.T5.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S5.T5.1.1.1.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Two-Stage</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T5.1.2.1" class="ltx_tr">
<th id="S5.T5.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S5.T5.1.2.1.1.1" class="ltx_text" style="font-size:80%;">DocStruct4M samples</span></th>
<td id="S5.T5.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T5.1.2.1.2.1" class="ltx_text" style="font-size:80%;">0.0M</span></td>
<td id="S5.T5.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T5.1.2.1.3.1" class="ltx_text" style="font-size:80%;">0.5M</span></td>
<td id="S5.T5.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T5.1.2.1.4.1" class="ltx_text" style="font-size:80%;">1.0M</span></td>
<td id="S5.T5.1.2.1.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T5.1.2.1.5.1" class="ltx_text" style="font-size:80%;">2.0M</span></td>
<td id="S5.T5.1.2.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T5.1.2.1.6.1" class="ltx_text" style="font-size:80%;">4.0M</span></td>
<td id="S5.T5.1.2.1.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T5.1.2.1.7.1" class="ltx_text" style="font-size:80%;">4.0M</span></td>
</tr>
<tr id="S5.T5.1.3.2" class="ltx_tr">
<th id="S5.T5.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r"><span id="S5.T5.1.3.2.1.1" class="ltx_text" style="font-size:80%;">Benchmark samples</span></th>
<td id="S5.T5.1.3.2.2" class="ltx_td ltx_align_center"><span id="S5.T5.1.3.2.2.1" class="ltx_text" style="font-size:80%;">0.6M</span></td>
<td id="S5.T5.1.3.2.3" class="ltx_td ltx_align_center"><span id="S5.T5.1.3.2.3.1" class="ltx_text" style="font-size:80%;">0.6M</span></td>
<td id="S5.T5.1.3.2.4" class="ltx_td ltx_align_center"><span id="S5.T5.1.3.2.4.1" class="ltx_text" style="font-size:80%;">0.6M</span></td>
<td id="S5.T5.1.3.2.5" class="ltx_td ltx_align_center"><span id="S5.T5.1.3.2.5.1" class="ltx_text" style="font-size:80%;">0.6M</span></td>
<td id="S5.T5.1.3.2.6" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T5.1.3.2.6.1" class="ltx_text" style="font-size:80%;">0.6M</span></td>
<td id="S5.T5.1.3.2.7" class="ltx_td ltx_align_center"><span id="S5.T5.1.3.2.7.1" class="ltx_text" style="font-size:80%;">0.6M</span></td>
</tr>
<tr id="S5.T5.1.4.3" class="ltx_tr">
<th id="S5.T5.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r"><span id="S5.T5.1.4.3.1.1" class="ltx_text" style="font-size:80%;">Epoch/iteration</span></th>
<td id="S5.T5.1.4.3.2" class="ltx_td ltx_align_center"><span id="S5.T5.1.4.3.2.1" class="ltx_text" style="font-size:80%;">7/18k</span></td>
<td id="S5.T5.1.4.3.3" class="ltx_td ltx_align_center"><span id="S5.T5.1.4.3.3.1" class="ltx_text" style="font-size:80%;">6/25k</span></td>
<td id="S5.T5.1.4.3.4" class="ltx_td ltx_align_center"><span id="S5.T5.1.4.3.4.1" class="ltx_text" style="font-size:80%;">6/37k</span></td>
<td id="S5.T5.1.4.3.5" class="ltx_td ltx_align_center"><span id="S5.T5.1.4.3.5.1" class="ltx_text" style="font-size:80%;">4/40k</span></td>
<td id="S5.T5.1.4.3.6" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T5.1.4.3.6.1" class="ltx_text" style="font-size:80%;">3/54k</span></td>
<td id="S5.T5.1.4.3.7" class="ltx_td ltx_align_center"><span id="S5.T5.1.4.3.7.1" class="ltx_text" style="font-size:80%;">3/12k + 3/6.5k</span></td>
</tr>
<tr id="S5.T5.1.5.4" class="ltx_tr">
<th id="S5.T5.1.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r"><span id="S5.T5.1.5.4.1.1" class="ltx_text" style="font-size:80%;">Cost (A100 days)</span></th>
<td id="S5.T5.1.5.4.2" class="ltx_td ltx_align_center"><span id="S5.T5.1.5.4.2.1" class="ltx_text" style="font-size:80%;">60.0</span></td>
<td id="S5.T5.1.5.4.3" class="ltx_td ltx_align_center"><span id="S5.T5.1.5.4.3.1" class="ltx_text" style="font-size:80%;">83.3</span></td>
<td id="S5.T5.1.5.4.4" class="ltx_td ltx_align_center"><span id="S5.T5.1.5.4.4.1" class="ltx_text" style="font-size:80%;">123.3</span></td>
<td id="S5.T5.1.5.4.5" class="ltx_td ltx_align_center"><span id="S5.T5.1.5.4.5.1" class="ltx_text" style="font-size:80%;">133.3</span></td>
<td id="S5.T5.1.5.4.6" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#E6E6E6;"><span id="S5.T5.1.5.4.6.1" class="ltx_text" style="font-size:80%;background-color:#E6E6E6;">180.0</span></td>
<td id="S5.T5.1.5.4.7" class="ltx_td ltx_align_center" style="background-color:#E6E6E6;"><span id="S5.T5.1.5.4.7.1" class="ltx_text" style="font-size:80%;background-color:#E6E6E6;">144.8</span></td>
</tr>
<tr id="S5.T5.1.6.5" class="ltx_tr">
<th id="S5.T5.1.6.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t"><span id="S5.T5.1.6.5.1.1" class="ltx_text" style="font-size:80%;">DocVQA</span></th>
<td id="S5.T5.1.6.5.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S5.T5.1.6.5.2.1" class="ltx_text" style="font-size:80%;">72.8</span></td>
<td id="S5.T5.1.6.5.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S5.T5.1.6.5.3.1" class="ltx_text" style="font-size:80%;">75.5</span></td>
<td id="S5.T5.1.6.5.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S5.T5.1.6.5.4.1" class="ltx_text" style="font-size:80%;">78.6</span></td>
<td id="S5.T5.1.6.5.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S5.T5.1.6.5.5.1" class="ltx_text" style="font-size:80%;">78.8</span></td>
<td id="S5.T5.1.6.5.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" style="background-color:#E6E6E6;"><span id="S5.T5.1.6.5.6.1" class="ltx_text" style="font-size:80%;background-color:#E6E6E6;">78.9</span></td>
<td id="S5.T5.1.6.5.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="background-color:#E6E6E6;"><span id="S5.T5.1.6.5.7.1" class="ltx_text" style="font-size:80%;background-color:#E6E6E6;">79.9</span></td>
</tr>
</tbody>
</table>
</figure>
<div id="S5.SS3.p5" class="ltx_para ltx_noindent">
<p id="S5.SS3.p5.1" class="ltx_p"><span id="S5.SS3.p5.1.1" class="ltx_text ltx_font_bold">Effectiveness of the Two-stage Training.</span> As shown in <a href="#S5.T5" title="In 5.3 Ablation Study ‣ 5 Experiments ‣ mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">5</span></a>, instead of two-stage training, we also try one-stage joint training of the structure learning and downstream tasks and gradually increase the samples from DocStruct4M. The epoch is gradually reduced because we didn’t observe performance improvements with more iterations. For joint training, the model improves significantly on DocVQA as the samples of Unified Structure Learning increase when it is below 1M. However, as the Unified Structure Learning samples are further increased, the improvement of the model becomes subtle and its performance is not as good as the one using two-stage training. This shows that the two-stage training could better enhance basic text recognition and structure parsing abilities and is more beneficial and efficient for downstream document understanding.</p>
</div>
<figure id="S5.T6" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 6: </span>The detailed statistic of DocLocal4K.</figcaption>
<table id="S5.T6.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T6.1.1.1" class="ltx_tr">
<th id="S5.T6.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" rowspan="2"><span id="S5.T6.1.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Task</span></th>
<th id="S5.T6.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" colspan="4"><span id="S5.T6.1.1.1.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Text Granularity</span></th>
<th id="S5.T6.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="5"><span id="S5.T6.1.1.1.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Image Domain</span></th>
</tr>
<tr id="S5.T6.1.2.2" class="ltx_tr">
<th id="S5.T6.1.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S5.T6.1.2.2.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Word</span></th>
<th id="S5.T6.1.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S5.T6.1.2.2.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Phrase</span></th>
<th id="S5.T6.1.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S5.T6.1.2.2.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Line</span></th>
<th id="S5.T6.1.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r"><span id="S5.T6.1.2.2.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Block</span></th>
<th id="S5.T6.1.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S5.T6.1.2.2.5.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Doc</span></th>
<th id="S5.T6.1.2.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S5.T6.1.2.2.6.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Table</span></th>
<th id="S5.T6.1.2.2.7" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S5.T6.1.2.2.7.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Chart</span></th>
<th id="S5.T6.1.2.2.8" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S5.T6.1.2.2.8.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Web</span></th>
<th id="S5.T6.1.2.2.9" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S5.T6.1.2.2.9.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Natural</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T6.1.3.1" class="ltx_tr">
<td id="S5.T6.1.3.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T6.1.3.1.1.1" class="ltx_text" style="font-size:80%;">Text Recognition</span></td>
<td id="S5.T6.1.3.1.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T6.1.3.1.2.1" class="ltx_text" style="font-size:80%;">622</span></td>
<td id="S5.T6.1.3.1.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T6.1.3.1.3.1" class="ltx_text" style="font-size:80%;">499</span></td>
<td id="S5.T6.1.3.1.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T6.1.3.1.4.1" class="ltx_text" style="font-size:80%;">522</span></td>
<td id="S5.T6.1.3.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T6.1.3.1.5.1" class="ltx_text" style="font-size:80%;">482</span></td>
<td id="S5.T6.1.3.1.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T6.1.3.1.6.1" class="ltx_text" style="font-size:80%;">1,004</span></td>
<td id="S5.T6.1.3.1.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T6.1.3.1.7.1" class="ltx_text" style="font-size:80%;">491</span></td>
<td id="S5.T6.1.3.1.8" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T6.1.3.1.8.1" class="ltx_text" style="font-size:80%;">229</span></td>
<td id="S5.T6.1.3.1.9" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T6.1.3.1.9.1" class="ltx_text" style="font-size:80%;">267</span></td>
<td id="S5.T6.1.3.1.10" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T6.1.3.1.10.1" class="ltx_text" style="font-size:80%;">134</span></td>
</tr>
<tr id="S5.T6.1.4.2" class="ltx_tr">
<td id="S5.T6.1.4.2.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S5.T6.1.4.2.1.1" class="ltx_text" style="font-size:80%;">Text Grounding</span></td>
<td id="S5.T6.1.4.2.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T6.1.4.2.2.1" class="ltx_text" style="font-size:80%;">595</span></td>
<td id="S5.T6.1.4.2.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T6.1.4.2.3.1" class="ltx_text" style="font-size:80%;">542</span></td>
<td id="S5.T6.1.4.2.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T6.1.4.2.4.1" class="ltx_text" style="font-size:80%;">503</span></td>
<td id="S5.T6.1.4.2.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S5.T6.1.4.2.5.1" class="ltx_text" style="font-size:80%;">485</span></td>
<td id="S5.T6.1.4.2.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T6.1.4.2.6.1" class="ltx_text" style="font-size:80%;">1,011</span></td>
<td id="S5.T6.1.4.2.7" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T6.1.4.2.7.1" class="ltx_text" style="font-size:80%;">524</span></td>
<td id="S5.T6.1.4.2.8" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T6.1.4.2.8.1" class="ltx_text" style="font-size:80%;">240</span></td>
<td id="S5.T6.1.4.2.9" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T6.1.4.2.9.1" class="ltx_text" style="font-size:80%;">242</span></td>
<td id="S5.T6.1.4.2.10" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T6.1.4.2.10.1" class="ltx_text" style="font-size:80%;">108</span></td>
</tr>
</tbody>
</table>
</figure>
<figure id="S5.T7" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 7: </span>Multi-grained text localization performance of models with different vision-to-text modules.</figcaption>
<div id="S5.T7.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:110.1pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(4.2pt,-1.1pt) scale(1.01980031913483,1.01980031913483) ;">
<table id="S5.T7.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T7.1.1.1.1" class="ltx_tr">
<th id="S5.T7.1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt" rowspan="2"><span id="S5.T7.1.1.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Module</span></th>
<th id="S5.T7.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" rowspan="2"><span id="S5.T7.1.1.1.1.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Iter</span></th>
<th id="S5.T7.1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" colspan="5"><span id="S5.T7.1.1.1.1.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Text Grounding</span></th>
<th id="S5.T7.1.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="5"><span id="S5.T7.1.1.1.1.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Text Recognition</span></th>
</tr>
<tr id="S5.T7.1.1.2.2" class="ltx_tr">
<th id="S5.T7.1.1.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S5.T7.1.1.2.2.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Word</span></th>
<th id="S5.T7.1.1.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S5.T7.1.1.2.2.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Phrase</span></th>
<th id="S5.T7.1.1.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S5.T7.1.1.2.2.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Line</span></th>
<th id="S5.T7.1.1.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S5.T7.1.1.2.2.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Block</span></th>
<th id="S5.T7.1.1.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r"><span id="S5.T7.1.1.2.2.5.1" class="ltx_text ltx_font_bold" style="font-size:80%;">ALL</span></th>
<th id="S5.T7.1.1.2.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S5.T7.1.1.2.2.6.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Word</span></th>
<th id="S5.T7.1.1.2.2.7" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S5.T7.1.1.2.2.7.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Phrase</span></th>
<th id="S5.T7.1.1.2.2.8" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S5.T7.1.1.2.2.8.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Line</span></th>
<th id="S5.T7.1.1.2.2.9" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S5.T7.1.1.2.2.9.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Block</span></th>
<th id="S5.T7.1.1.2.2.10" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S5.T7.1.1.2.2.10.1" class="ltx_text ltx_font_bold" style="font-size:80%;">ALL</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T7.1.1.3.1" class="ltx_tr">
<th id="S5.T7.1.1.3.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t"><span id="S5.T7.1.1.3.1.1.1" class="ltx_text" style="font-size:80%;">Abstractor</span></th>
<th id="S5.T7.1.1.3.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S5.T7.1.1.3.1.2.1" class="ltx_text" style="font-size:80%;">1,800</span></th>
<td id="S5.T7.1.1.3.1.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T7.1.1.3.1.3.1" class="ltx_text" style="font-size:80%;">10.92</span></td>
<td id="S5.T7.1.1.3.1.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T7.1.1.3.1.4.1" class="ltx_text" style="font-size:80%;">25.83</span></td>
<td id="S5.T7.1.1.3.1.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T7.1.1.3.1.5.1" class="ltx_text" style="font-size:80%;">34.59</span></td>
<td id="S5.T7.1.1.3.1.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T7.1.1.3.1.6.1" class="ltx_text" style="font-size:80%;">87.01</span></td>
<td id="S5.T7.1.1.3.1.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S5.T7.1.1.3.1.7.1" class="ltx_text" style="font-size:80%;">37.69</span></td>
<td id="S5.T7.1.1.3.1.8" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T7.1.1.3.1.8.1" class="ltx_text" style="font-size:80%;">30.68</span></td>
<td id="S5.T7.1.1.3.1.9" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T7.1.1.3.1.9.1" class="ltx_text" style="font-size:80%;">28.58</span></td>
<td id="S5.T7.1.1.3.1.10" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T7.1.1.3.1.10.1" class="ltx_text" style="font-size:80%;">40.12</span></td>
<td id="S5.T7.1.1.3.1.11" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T7.1.1.3.1.11.1" class="ltx_text" style="font-size:80%;">32.73</span></td>
<td id="S5.T7.1.1.3.1.12" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T7.1.1.3.1.12.1" class="ltx_text" style="font-size:80%;">33.03</span></td>
</tr>
<tr id="S5.T7.1.1.4.2" class="ltx_tr">
<th id="S5.T7.1.1.4.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row"><span id="S5.T7.1.1.4.2.1.1" class="ltx_text" style="font-size:80%;">H-Reducer(2x2)</span></th>
<th id="S5.T7.1.1.4.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S5.T7.1.1.4.2.2.1" class="ltx_text" style="font-size:80%;">1,800</span></th>
<td id="S5.T7.1.1.4.2.3" class="ltx_td ltx_align_center"><span id="S5.T7.1.1.4.2.3.1" class="ltx_text" style="font-size:80%;">14.19</span></td>
<td id="S5.T7.1.1.4.2.4" class="ltx_td ltx_align_center"><span id="S5.T7.1.1.4.2.4.1" class="ltx_text" style="font-size:80%;">34.87</span></td>
<td id="S5.T7.1.1.4.2.5" class="ltx_td ltx_align_center"><span id="S5.T7.1.1.4.2.5.1" class="ltx_text" style="font-size:80%;">43.94</span></td>
<td id="S5.T7.1.1.4.2.6" class="ltx_td ltx_align_center"><span id="S5.T7.1.1.4.2.6.1" class="ltx_text" style="font-size:80%;">89.07</span></td>
<td id="S5.T7.1.1.4.2.7" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T7.1.1.4.2.7.1" class="ltx_text" style="font-size:80%;">43.94</span></td>
<td id="S5.T7.1.1.4.2.8" class="ltx_td ltx_align_center"><span id="S5.T7.1.1.4.2.8.1" class="ltx_text" style="font-size:80%;">37.20</span></td>
<td id="S5.T7.1.1.4.2.9" class="ltx_td ltx_align_center"><span id="S5.T7.1.1.4.2.9.1" class="ltx_text" style="font-size:80%;">38.33</span></td>
<td id="S5.T7.1.1.4.2.10" class="ltx_td ltx_align_center"><span id="S5.T7.1.1.4.2.10.1" class="ltx_text" style="font-size:80%;">48.68</span></td>
<td id="S5.T7.1.1.4.2.11" class="ltx_td ltx_align_center"><span id="S5.T7.1.1.4.2.11.1" class="ltx_text" style="font-size:80%;">41.99</span></td>
<td id="S5.T7.1.1.4.2.12" class="ltx_td ltx_align_center"><span id="S5.T7.1.1.4.2.12.1" class="ltx_text" style="font-size:80%;">41.55</span></td>
</tr>
<tr id="S5.T7.1.1.5.3" class="ltx_tr">
<th id="S5.T7.1.1.5.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row"><span id="S5.T7.1.1.5.3.1.1" class="ltx_text" style="font-size:80%;">H-Reducer(1x4)</span></th>
<th id="S5.T7.1.1.5.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S5.T7.1.1.5.3.2.1" class="ltx_text" style="font-size:80%;">1,800</span></th>
<td id="S5.T7.1.1.5.3.3" class="ltx_td ltx_align_center"><span id="S5.T7.1.1.5.3.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">17.82</span></td>
<td id="S5.T7.1.1.5.3.4" class="ltx_td ltx_align_center"><span id="S5.T7.1.1.5.3.4.1" class="ltx_text ltx_font_bold" style="font-size:80%;">39.30</span></td>
<td id="S5.T7.1.1.5.3.5" class="ltx_td ltx_align_center"><span id="S5.T7.1.1.5.3.5.1" class="ltx_text ltx_font_bold" style="font-size:80%;">53.28</span></td>
<td id="S5.T7.1.1.5.3.6" class="ltx_td ltx_align_center"><span id="S5.T7.1.1.5.3.6.1" class="ltx_text ltx_font_bold" style="font-size:80%;">90.52</span></td>
<td id="S5.T7.1.1.5.3.7" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T7.1.1.5.3.7.1" class="ltx_text ltx_font_bold" style="font-size:80%;">48.28</span></td>
<td id="S5.T7.1.1.5.3.8" class="ltx_td ltx_align_center"><span id="S5.T7.1.1.5.3.8.1" class="ltx_text ltx_font_bold" style="font-size:80%;">39.60</span></td>
<td id="S5.T7.1.1.5.3.9" class="ltx_td ltx_align_center"><span id="S5.T7.1.1.5.3.9.1" class="ltx_text ltx_font_bold" style="font-size:80%;">41.84</span></td>
<td id="S5.T7.1.1.5.3.10" class="ltx_td ltx_align_center"><span id="S5.T7.1.1.5.3.10.1" class="ltx_text ltx_font_bold" style="font-size:80%;">55.37</span></td>
<td id="S5.T7.1.1.5.3.11" class="ltx_td ltx_align_center"><span id="S5.T7.1.1.5.3.11.1" class="ltx_text ltx_font_bold" style="font-size:80%;">49.84</span></td>
<td id="S5.T7.1.1.5.3.12" class="ltx_td ltx_align_center"><span id="S5.T7.1.1.5.3.12.1" class="ltx_text ltx_font_bold" style="font-size:80%;">46.66</span></td>
</tr>
<tr id="S5.T7.1.1.6.4" class="ltx_tr">
<th id="S5.T7.1.1.6.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_t"><span id="S5.T7.1.1.6.4.1.1" class="ltx_text" style="font-size:80%;">H-Reducer(1x4)</span></th>
<th id="S5.T7.1.1.6.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t"><span id="S5.T7.1.1.6.4.2.1" class="ltx_text" style="font-size:80%;">12,000</span></th>
<td id="S5.T7.1.1.6.4.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S5.T7.1.1.6.4.3.1" class="ltx_text" style="font-size:80%;">70.42</span></td>
<td id="S5.T7.1.1.6.4.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S5.T7.1.1.6.4.4.1" class="ltx_text" style="font-size:80%;">76.38</span></td>
<td id="S5.T7.1.1.6.4.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S5.T7.1.1.6.4.5.1" class="ltx_text" style="font-size:80%;">85.88</span></td>
<td id="S5.T7.1.1.6.4.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S5.T7.1.1.6.4.6.1" class="ltx_text" style="font-size:80%;">91.34</span></td>
<td id="S5.T7.1.1.6.4.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t"><span id="S5.T7.1.1.6.4.7.1" class="ltx_text" style="font-size:80%;">80.38</span></td>
<td id="S5.T7.1.1.6.4.8" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S5.T7.1.1.6.4.8.1" class="ltx_text" style="font-size:80%;">70.10</span></td>
<td id="S5.T7.1.1.6.4.9" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S5.T7.1.1.6.4.9.1" class="ltx_text" style="font-size:80%;">67.86</span></td>
<td id="S5.T7.1.1.6.4.10" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S5.T7.1.1.6.4.10.1" class="ltx_text" style="font-size:80%;">73.88</span></td>
<td id="S5.T7.1.1.6.4.11" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S5.T7.1.1.6.4.11.1" class="ltx_text" style="font-size:80%;">70.70</span></td>
<td id="S5.T7.1.1.6.4.12" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S5.T7.1.1.6.4.12.1" class="ltx_text" style="font-size:80%;">70.63</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section id="S5.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4 </span>Text Localization Evaluation</h3>

<div id="S5.SS4.p1" class="ltx_para">
<p id="S5.SS4.p1.1" class="ltx_p">Besides proving the effectiveness of H-Reducer through downstream text-rich image understanding performance in <a href="#S5.T4" title="In 5.2 Main Results ‣ 5 Experiments ‣ mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">4</span></a>, we further directly compare the text localization performance after the Unified Structure Learning to validate its superiority in preserving spatial features. We build a text localization evaluation set DocLocal4K with 4,250 samples balanced on 4 granularities and covering both text recognition and text grounding tasks. The detailed statistics of DocLocal4K are shown in <a href="#S5.T6" title="In 5.3 Ablation Study ‣ 5 Experiments ‣ mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">6</span></a>. Considering that document images are much more diverse and complex than other images, there are more samples in this domain than others. The IOU@0.5 is used to evaluate the text grounding performance. As for text recognition, the word, phrase, line, and block granularity is evaluated with BLEU1, BLEU2, BLEU3, and BLEU4 <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>, respectively. As shown in <a href="#S5.T7" title="In 5.3 Ablation Study ‣ 5 Experiments ‣ mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">7</span></a>, when trained with the same iterations, the H-Reducer achieves much better performance on both Text Recognition and Text Grounding tasks, showing that H-Reducer with the 1x4 merging shape helps the LLM better understand concrete positions in images.</p>
</div>
<figure id="S5.F6" class="ltx_figure"><img src="/html/2403.12895/assets/x6.png" id="S5.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="177" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Qualitative results of DocOwl 1.5 and UReader on different domains of images.</figcaption>
</figure>
</section>
<section id="S5.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.5 </span>Qualitative Results</h3>

<div id="S5.SS5.p1" class="ltx_para ltx_noindent">
<p id="S5.SS5.p1.1" class="ltx_p"><span id="S5.SS5.p1.1.1" class="ltx_text ltx_font_bold">Question Answering with Simple Phrases.</span> Besides quantitative results, we further present some qualitative results of visual document understanding on different domains of images. As shown in <a href="#S5.F6" title="In 5.4 Text Localization Evaluation ‣ 5 Experiments ‣ mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">6</span></a>(a) and (b), both models answer the question with texts in the image. DocOwl 1.5 can better understand the structure of two documents and give correct answers. In <a href="#S5.F6" title="In 5.4 Text Localization Evaluation ‣ 5 Experiments ‣ mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">6</span></a>(c), due to the learning of parsing chart with Markdown codes, DocOwl 1.5 can better understand the chart and successfully correlate the x/y axis. <a href="#S5.F6" title="In 5.4 Text Localization Evaluation ‣ 5 Experiments ‣ mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">6</span></a>(d) shows that although inconsistent with the ground truth, DocOwl 1.5 gives another correct answer with the help of stronger structure understanding on tables.</p>
</div>
<div id="S5.SS5.p2" class="ltx_para ltx_noindent">
<p id="S5.SS5.p2.1" class="ltx_p"><span id="S5.SS5.p2.1.1" class="ltx_text ltx_font_bold">Question Answering with Detailed Explanations.</span> <a href="#S5.F7" title="In 5.5 Qualitative Results ‣ 5 Experiments ‣ mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">7</span></a> and <a href="#S6.F8" title="In 6 Conclusion ‣ mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">8</span></a> present qualitative results of detailed explanations. Through a small amount of reasoning training, DocOwl 1.5-Chat can well inherit the reasoning ability of LLM and provide detailed explanations about the answer. However, as presented in <a href="#S6.F8" title="In 6 Conclusion ‣ mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">8</span></a>(c), like most general Multimoal large Language Models <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>, <a href="#bib.bib58" title="" class="ltx_ref">58</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>, DocOwl 1.5-Chat may also suffer from the hallucination problem in Visual Document Understanding. In this work, we mainly focus on enhancing the unified structure understanding ability of MLLMs and leave how to resolve the hallucination problem in OCR-free document understanding as future work.</p>
</div>
<div id="S5.SS5.p3" class="ltx_para ltx_noindent">
<p id="S5.SS5.p3.1" class="ltx_p"><span id="S5.SS5.p3.1.1" class="ltx_text ltx_font_bold">Structure-aware Parsing.</span> As shown in <a href="#S6.F9" title="In 6 Conclusion ‣ mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">9</span></a>, DocOwl 1.5 could parse a document image by using line feeds and spaces to represent the structure of text contents. Besides parsing the whole document, as shown in <a href="#S6.F10" title="In 6 Conclusion ‣ mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">10</span></a>, it could also parse texts from the middle of the image according to human instruction. <a href="#S6.F11" title="In 6 Conclusion ‣ mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">11</span></a> presents qualitative results of structure-aware table parsing through extended Markdown syntax on tables with cells spanning multiple columns or not. Furthermore, <a href="#S6.F12" title="In 6 Conclusion ‣ mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">12</span></a> shows some cases of parsing different types of charts into Markdown codes, including vertical bar, horizontal bar, pie, and line charts. When all data points are presented in the chart, DocOwl 1.5 can accurately align statistic objects with corresponding numbers. It makes some mistakes in <a href="#S6.F12" title="In 6 Conclusion ‣ mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">12</span></a>(d) because estimating the concrete numbers is quite challenging when no data points are provided. Finally, as shown in <a href="#S6.F13" title="In 6 Conclusion ‣ mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">13</span></a>, DocOwl 1.5 can both describe the content of natural images and read scene texts.</p>
</div>
<div id="S5.SS5.p4" class="ltx_para ltx_noindent">
<p id="S5.SS5.p4.1" class="ltx_p"><span id="S5.SS5.p4.1.1" class="ltx_text ltx_font_bold">Multi-grained Text Localization.</span> <a href="#S6.F14" title="In 6 Conclusion ‣ mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">14</span></a> and <a href="#S6.F15" title="In 6 Conclusion ‣ mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">15</span></a> show qualitative results of text grounding and text recognition at granularities of word, phrase, line and block. The image domains range from documents, webpages, charts, and tables to natural images.</p>
</div>
<figure id="S5.F7" class="ltx_figure"><img src="/html/2403.12895/assets/x7.png" id="S5.F7.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="461" height="624" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Qualitative results of question answering with detailed explanations.
Some regions are enlarged for better visualization.</figcaption>
</figure>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">To enhance the Visual Document Understanding performance of Multimodal Large Language Models, we first propose Unified Structure Learning across 5 domains of text-rich images, including both structure-aware parsing tasks and multi-grained text localization tasks. To better maintain structure and spatial information during vision-and-language feature alignment, we design a simple and effective vision-to-text module, named H-Reducer. It mainly utilizes a convolution layer to aggregate horizontally neighboring visual features. To support the Unified Structure Learning, we build a training dataset DocStruct4M by collecting publicly available images and carefully constructing structure-aware text sequences and multi-grained pairs of texts and bounding boxes. With Unified Structure Learning, our model DocOwl 1.5 achieves state-of-the-art OCR-free performance on 10 visual document understanding benchmarks.</p>
</div>
<figure id="S6.F8" class="ltx_figure"><img src="/html/2403.12895/assets/x8.png" id="S6.F8.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="461" height="624" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Qualitative results of question answering with detailed explanations. Hallucination in answers are marked in <span id="S6.F8.2.1" class="ltx_text" style="color:#FF0000;">red</span>.</figcaption>
</figure>
<figure id="S6.F9" class="ltx_figure"><img src="/html/2403.12895/assets/x9.png" id="S6.F9.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="259" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>A qualitative result of structure-aware document parsing.</figcaption>
</figure>
<figure id="S6.F10" class="ltx_figure"><img src="/html/2403.12895/assets/x10.png" id="S6.F10.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="269" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 10: </span>A qualitative result of structure-aware document parsing from the middle of the image. The red dotted box is only used to mark the location of the answers for better visualization and is not included in the input image.</figcaption>
</figure>
<figure id="S6.F11" class="ltx_figure"><img src="/html/2403.12895/assets/x11.png" id="S6.F11.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="415" height="633" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 11: </span>Qualitative results of structure-aware table parsing on the table with cells spanning multiple columns (a) and structure-aware table parsing from the middle of the image (b). The red dotted box is only used to mark the location of the answers for better visualization and is not included in the input image.</figcaption>
</figure>
<figure id="S6.F12" class="ltx_figure"><img src="/html/2403.12895/assets/x12.png" id="S6.F12.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="461" height="640" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 12: </span>Qualitative results of structure-aware chart parsing on the charts of the vertical bar (a), horizontal bar (b), pie (c), and line (d). Incorrect words in the answer are marked in <span id="S6.F12.2.1" class="ltx_text" style="color:#FF0000;">red</span>.</figcaption>
</figure>
<figure id="S6.F13" class="ltx_figure"><img src="/html/2403.12895/assets/x13.png" id="S6.F13.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="461" height="656" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 13: </span>Qualitative results of natural image parsing. For better visualization, some regions are enlarged and labeled with corresponding scene texts. Incorrect words in the answer are marked in <span id="S6.F13.2.1" class="ltx_text" style="color:#FF0000;">red</span>.</figcaption>
</figure>
<figure id="S6.F14" class="ltx_figure"><img src="/html/2403.12895/assets/x14.png" id="S6.F14.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="461" height="704" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 14: </span>Qualitative results of Multi-grained Text Grounding. Some regions are enlarged for better visualization. Bounding boxes predicted by DocOwl 1.5 are drawn in images as solid red boxes.</figcaption>
</figure>
<figure id="S6.F15" class="ltx_figure"><img src="/html/2403.12895/assets/x15.png" id="S6.F15.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="461" height="704" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 15: </span>Qualitative results of Multi-grained Text Recognition. Some regions are enlarged for better visualization. Input bounding boxes are drawn in images as solid blue boxes. Incorrect words in answers are marked in <span id="S6.F15.2.1" class="ltx_text" style="color:#FF0000;">red</span>.</figcaption>
</figure>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Alayrac et al. [2022]</span>
<span class="ltx_bibblock">
Jean-Baptiste Alayrac, Jeff Donahue, Pauline Luc, Antoine Miech, Iain Barr, Yana Hasson, Karel Lenc, Arthur Mensch, Katie Millican, Malcolm Reynolds, Roman Ring, Eliza Rutherford, Serkan Cabi, Tengda Han, Zhitao Gong, Sina Samangooei, Marianne Monteiro, Jacob Menick, Sebastian Borgeaud, Andy Brock, Aida Nematzadeh, Sahand Sharifzadeh, Mikolaj Binkowski, Ricardo Barreira, Oriol Vinyals, Andrew Zisserman, and Karen Simonyan.

</span>
<span class="ltx_bibblock">Flamingo: a visual language model for few-shot learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2204.14198, 2022.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bai et al. [2023a]</span>
<span class="ltx_bibblock">
Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong Deng, Yang Fan, Wenbin Ge, Yu Han, Fei Huang, Binyuan Hui, Luo Ji, Mei Li, Junyang Lin, Runji Lin, Dayiheng Liu, Gao Liu, Chengqiang Lu, Keming Lu, Jianxin Ma, Rui Men, Xingzhang Ren, Xuancheng Ren, Chuanqi Tan, Sinan Tan, Jianhong Tu, Peng Wang, Shijie Wang, Wei Wang, Shengguang Wu, Benfeng Xu, Jin Xu, An Yang, Hao Yang, Jian Yang, Shusheng Yang, Yang Yao, Bowen Yu, Hongyi Yuan, Zheng Yuan, Jianwei Zhang, Xingxuan Zhang, Yichang Zhang, Zhenru Zhang, Chang Zhou, Jingren Zhou, Xiaohuan Zhou, and Tianhang Zhu.

</span>
<span class="ltx_bibblock">Qwen technical report.

</span>
<span class="ltx_bibblock"><em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2309.16609</em>, 2023a.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bai et al. [2023b]</span>
<span class="ltx_bibblock">
Jinze Bai, Shuai Bai, Shusheng Yang, Shijie Wang, Sinan Tan, Peng Wang, Junyang Lin, Chang Zhou, and Jingren Zhou.

</span>
<span class="ltx_bibblock">Qwen-vl: A versatile vision-language model for understanding, localization, text reading, and beyond.

</span>
<span class="ltx_bibblock"><em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2308.12966</em>, 2023b.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Borchmann et al. [2021]</span>
<span class="ltx_bibblock">
Lukasz Borchmann, Michal Pietruszka, Tomasz Stanislawek, Dawid Jurkiewicz, Michal Turski, Karolina Szyndler, and Filip Gralinski.

</span>
<span class="ltx_bibblock">DUE: end-to-end document understanding benchmark.

</span>
<span class="ltx_bibblock">In <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">NeurIPS Datasets and Benchmarks</em>, 2021.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et al. [2020]</span>
<span class="ltx_bibblock">
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al.

</span>
<span class="ltx_bibblock">Language models are few-shot learners.

</span>
<span class="ltx_bibblock"><em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, 33:1877–1901, 2020.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Byeon et al. [2022]</span>
<span class="ltx_bibblock">
Minwoo Byeon, Beomhee Park, Haecheon Kim, Sungjun Lee, Woonhyuk Baek, and Saehoon Kim.

</span>
<span class="ltx_bibblock">Coyo-700m: Image-text pair dataset.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/kakaobrain/coyo-dataset" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/kakaobrain/coyo-dataset</a>, 2022.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Changpinyo et al. [2021]</span>
<span class="ltx_bibblock">
Soravit Changpinyo, Piyush Sharma, Nan Ding, and Radu Soricut.

</span>
<span class="ltx_bibblock">Conceptual 12m: Pushing web-scale image-text pre-training to recognize long-tail visual concepts.

</span>
<span class="ltx_bibblock">In <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">CVPR</em>, pages 3558–3568. Computer Vision Foundation / IEEE, 2021.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. [2020]</span>
<span class="ltx_bibblock">
Wenhu Chen, Hongmin Wang, Jianshu Chen, Yunkai Zhang, Hong Wang, Shiyang Li, Xiyou Zhou, and William Yang Wang.

</span>
<span class="ltx_bibblock">Tabfact : A large-scale dataset for table-based fact verification.

</span>
<span class="ltx_bibblock">In <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations (ICLR)</em>, Addis Ababa, Ethiopia, April 2020.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. [2021]</span>
<span class="ltx_bibblock">
Xingyu Chen, Zihan Zhao, Lu Chen, JiaBao Ji, Danyang Zhang, Ao Luo, Yuxuan Xiong, and Kai Yu.

</span>
<span class="ltx_bibblock">Websrc: A dataset for web-based structural reading comprehension.

</span>
<span class="ltx_bibblock">In <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</em>, pages 4173–4185, 2021.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dai et al. [2023]</span>
<span class="ltx_bibblock">
Wenliang Dai, Junnan Li, Dongxu Li, Anthony Meng Huat Tiong, Junqi Zhao, Weisheng Wang, Boyang Li, Pascale Fung, and Steven C. H. Hoi.

</span>
<span class="ltx_bibblock">Instructblip: Towards general-purpose vision-language models with instruction tuning.

</span>
<span class="ltx_bibblock"><em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2305.06500, 2023.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Deng et al. [2022]</span>
<span class="ltx_bibblock">
Xiang Deng, Huan Sun, Alyssa Lees, You Wu, and Cong Yu.

</span>
<span class="ltx_bibblock">TURL: table understanding through representation learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">SIGMOD Rec.</em>, 51(1):33–40, 2022.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dosovitskiy et al. [2021]</span>
<span class="ltx_bibblock">
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby.

</span>
<span class="ltx_bibblock">An image is worth 16x16 words: Transformers for image recognition at scale.

</span>
<span class="ltx_bibblock">In <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">ICLR</em>. OpenReview.net, 2021.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Feng et al. [2023]</span>
<span class="ltx_bibblock">
Hao Feng, Qi Liu, Hao Liu, Wengang Zhou, Houqiang Li, and Can Huang.

</span>
<span class="ltx_bibblock">Docpedia: Unleashing the power of large multimodal model in the frequency domain for versatile document understanding.

</span>
<span class="ltx_bibblock"><em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2311.11810, 2023.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Harley et al. [2015]</span>
<span class="ltx_bibblock">
Adam W. Harley, Alex Ufkes, and Konstantinos G. Derpanis.

</span>
<span class="ltx_bibblock">Evaluation of deep convolutional nets for document image classification and retrieval.

</span>
<span class="ltx_bibblock">In <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">ICDAR</em>, pages 991–995. IEEE Computer Society, 2015.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hong et al. [2023]</span>
<span class="ltx_bibblock">
Wenyi Hong, Weihan Wang, Qingsong Lv, Jiazheng Xu, Wenmeng Yu, Junhui Ji, Yan Wang, Zihan Wang, Yuxuan Zhang, Juanzi Li, Bin Xu, Yuxiao Dong, Ming Ding, and Jie Tang.

</span>
<span class="ltx_bibblock">Cogagent: A visual language model for GUI agents.

</span>
<span class="ltx_bibblock"><em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2312.08914, 2023.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et al. [2021]</span>
<span class="ltx_bibblock">
Anwen Hu, Shizhe Chen, and Qin Jin.

</span>
<span class="ltx_bibblock">Question-controlled text-aware image captioning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">ACM Multimedia</em>, pages 3097–3105. ACM, 2021.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et al. [2023]</span>
<span class="ltx_bibblock">
Anwen Hu, Yaya Shi, Haiyang Xu, Jiabo Ye, Qinghao Ye, Ming Yan, Chenliang Li, Qi Qian, Ji Zhang, and Fei Huang.

</span>
<span class="ltx_bibblock">mplug-paperowl: Scientific diagram analysis with the multimodal large language model.

</span>
<span class="ltx_bibblock"><em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2311.18248</em>, 2023.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et al. [2022]</span>
<span class="ltx_bibblock">
Yupan Huang, Tengchao Lv, Lei Cui, Yutong Lu, and Furu Wei.

</span>
<span class="ltx_bibblock">Layoutlmv3: Pre-training for document AI with unified text and image masking.

</span>
<span class="ltx_bibblock">In <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">ACM Multimedia</em>, pages 4083–4091. ACM, 2022.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kafle et al. [2018]</span>
<span class="ltx_bibblock">
Kushal Kafle, Brian L. Price, Scott Cohen, and Christopher Kanan.

</span>
<span class="ltx_bibblock">DVQA: understanding data visualizations via question answering.

</span>
<span class="ltx_bibblock">In <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">CVPR</em>, pages 5648–5656. Computer Vision Foundation / IEEE Computer Society, 2018.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kahou et al. [2018]</span>
<span class="ltx_bibblock">
Samira Ebrahimi Kahou, Vincent Michalski, Adam Atkinson, Ákos Kádár, Adam Trischler, and Yoshua Bengio.

</span>
<span class="ltx_bibblock">Figureqa: An annotated figure dataset for visual reasoning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">ICLR (Workshop)</em>. OpenReview.net, 2018.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kantharaj et al. [2022]</span>
<span class="ltx_bibblock">
Shankar Kantharaj, Rixie Tiffany Ko Leong, Xiang Lin, Ahmed Masry, Megh Thakkar, Enamul Hoque, and Shafiq R. Joty.

</span>
<span class="ltx_bibblock">Chart-to-text: A large-scale benchmark for chart summarization.

</span>
<span class="ltx_bibblock">In <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">ACL (1)</em>, pages 4005–4023. Association for Computational Linguistics, 2022.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim et al. [2022]</span>
<span class="ltx_bibblock">
Geewook Kim, Teakgyu Hong, Moonbin Yim, JeongYeon Nam, Jinyoung Park, Jinyeong Yim, Wonseok Hwang, Sangdoo Yun, Dongyoon Han, and Seunghyun Park.

</span>
<span class="ltx_bibblock">Ocr-free document understanding transformer.

</span>
<span class="ltx_bibblock">In <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">ECCV (28)</em>, volume 13688 of <em id="bib.bib22.2.2" class="ltx_emph ltx_font_italic">Lecture Notes in Computer Science</em>, pages 498–517. Springer, 2022.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee et al. [2023]</span>
<span class="ltx_bibblock">
Kenton Lee, Mandar Joshi, Iulia Raluca Turc, Hexiang Hu, Fangyu Liu, Julian Martin Eisenschlos, Urvashi Khandelwal, Peter Shaw, Ming-Wei Chang, and Kristina Toutanova.

</span>
<span class="ltx_bibblock">Pix2struct: Screenshot parsing as pretraining for visual language understanding.

</span>
<span class="ltx_bibblock">In <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">ICML</em>, volume 202 of <em id="bib.bib23.2.2" class="ltx_emph ltx_font_italic">Proceedings of Machine Learning Research</em>, pages 18893–18912. PMLR, 2023.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. [2023a]</span>
<span class="ltx_bibblock">
Junnan Li, Dongxu Li, Silvio Savarese, and Steven C. H. Hoi.

</span>
<span class="ltx_bibblock">BLIP-2: bootstrapping language-image pre-training with frozen image encoders and large language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2301.12597, 2023a.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. [2023b]</span>
<span class="ltx_bibblock">
Zhang Li, Biao Yang, Qiang Liu, Zhiyin Ma, Shuo Zhang, Jingxu Yang, Yabo Sun, Yuliang Liu, and Xiang Bai.

</span>
<span class="ltx_bibblock">Monkey: Image resolution and text label are important things for large multi-modal models.

</span>
<span class="ltx_bibblock"><em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2311.06607, 2023b.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. [2023a]</span>
<span class="ltx_bibblock">
Haotian Liu, Chunyuan Li, Yuheng Li, and Yong Jae Lee.

</span>
<span class="ltx_bibblock">Improved baselines with visual instruction tuning.

</span>
<span class="ltx_bibblock"><em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2310.03744, 2023a.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. [2023b]</span>
<span class="ltx_bibblock">
Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong Jae Lee.

</span>
<span class="ltx_bibblock">Visual instruction tuning.

</span>
<span class="ltx_bibblock"><em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2304.08485, 2023b.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. [2023c]</span>
<span class="ltx_bibblock">
Yuliang Liu, Zhang Li, Hongliang Li, Wenwen Yu, Mingxin Huang, Dezhi Peng, Mingyu Liu, Mingrui Chen, Chunyuan Li, Lianwen Jin, et al.

</span>
<span class="ltx_bibblock">On the hidden mystery of ocr in large multimodal models.

</span>
<span class="ltx_bibblock"><em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.07895</em>, 2023c.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Masry et al. [2022]</span>
<span class="ltx_bibblock">
Ahmed Masry, Do Xuan Long, Jia Qing Tan, Shafiq R. Joty, and Enamul Hoque.

</span>
<span class="ltx_bibblock">Chartqa: A benchmark for question answering about charts with visual and logical reasoning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">ACL (Findings)</em>, pages 2263–2279. Association for Computational Linguistics, 2022.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mathew et al. [2021]</span>
<span class="ltx_bibblock">
Minesh Mathew, Dimosthenis Karatzas, and C. V. Jawahar.

</span>
<span class="ltx_bibblock">Docvqa: A dataset for VQA on document images.

</span>
<span class="ltx_bibblock">In <em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">WACV</em>, pages 2199–2208. IEEE, 2021.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mathew et al. [2022]</span>
<span class="ltx_bibblock">
Minesh Mathew, Viraj Bagal, Rubèn Tito, Dimosthenis Karatzas, Ernest Valveny, and C. V. Jawahar.

</span>
<span class="ltx_bibblock">Infographicvqa.

</span>
<span class="ltx_bibblock">In <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">WACV</em>, pages 2582–2591. IEEE, 2022.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Methani et al. [2020]</span>
<span class="ltx_bibblock">
Nitesh Methani, Pritha Ganguly, Mitesh M. Khapra, and Pratyush Kumar.

</span>
<span class="ltx_bibblock">Plotqa: Reasoning over scientific plots.

</span>
<span class="ltx_bibblock">In <em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">WACV</em>, pages 1516–1525. IEEE, 2020.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Papineni et al. [2002]</span>
<span class="ltx_bibblock">
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.

</span>
<span class="ltx_bibblock">Bleu: a method for automatic evaluation of machine translation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 40th annual meeting of the Association for Computational Linguistics</em>, pages 311–318, 2002.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pasupat and Liang [2015]</span>
<span class="ltx_bibblock">
Panupong Pasupat and Percy Liang.

</span>
<span class="ltx_bibblock">Compositional semantic parsing on semi-structured tables.

</span>
<span class="ltx_bibblock">In <em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">ACL (1)</em>, pages 1470–1480. The Association for Computer Linguistics, 2015.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Peng et al. [2023]</span>
<span class="ltx_bibblock">
Zhiliang Peng, Wenhui Wang, Li Dong, Yaru Hao, Shaohan Huang, Shuming Ma, and Furu Wei.

</span>
<span class="ltx_bibblock">Kosmos-2: Grounding multimodal large language models to the world.

</span>
<span class="ltx_bibblock"><em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2306.14824, 2023.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et al. [2021]</span>
<span class="ltx_bibblock">
Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, and Ilya Sutskever.

</span>
<span class="ltx_bibblock">Learning transferable visual models from natural language supervision.

</span>
<span class="ltx_bibblock">In <em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">ICML</em>, volume 139 of <em id="bib.bib36.2.2" class="ltx_emph ltx_font_italic">Proceedings of Machine Learning Research</em>, pages 8748–8763. PMLR, 2021.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schuhmann et al. [2022]</span>
<span class="ltx_bibblock">
Christoph Schuhmann, Romain Beaumont, Richard Vencu, Cade Gordon, Ross Wightman, Mehdi Cherti, Theo Coombes, Aarush Katta, Clayton Mullis, Mitchell Wortsman, Patrick Schramowski, Srivatsa Kundurthy, Katherine Crowson, Ludwig Schmidt, Robert Kaczmarczyk, and Jenia Jitsev.

</span>
<span class="ltx_bibblock">LAION-5B: an open large-scale dataset for training next generation image-text models.

</span>
<span class="ltx_bibblock">In <em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">NeurIPS</em>, 2022.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sharma et al. [2018]</span>
<span class="ltx_bibblock">
Piyush Sharma, Nan Ding, Sebastian Goodman, and Radu Soricut.

</span>
<span class="ltx_bibblock">Conceptual captions: A cleaned, hypernymed, image alt-text dataset for automatic image captioning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">ACL (1)</em>, pages 2556–2565. Association for Computational Linguistics, 2018.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sidorov et al. [2020]</span>
<span class="ltx_bibblock">
Oleksii Sidorov, Ronghang Hu, Marcus Rohrbach, and Amanpreet Singh.

</span>
<span class="ltx_bibblock">Textcaps: A dataset for image captioning with reading comprehension.

</span>
<span class="ltx_bibblock">In <em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">ECCV (2)</em>, volume 12347 of <em id="bib.bib39.2.2" class="ltx_emph ltx_font_italic">Lecture Notes in Computer Science</em>, pages 742–758. Springer, 2020.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Singh et al. [2019]</span>
<span class="ltx_bibblock">
Amanpreet Singh, Vivek Natarajan, Meet Shah, Yu Jiang, Xinlei Chen, Dhruv Batra, Devi Parikh, and Marcus Rohrbach.

</span>
<span class="ltx_bibblock">Towards VQA models that can read.

</span>
<span class="ltx_bibblock">In <em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">CVPR</em>, pages 8317–8326. Computer Vision Foundation / IEEE, 2019.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Stanislawek et al. [2021]</span>
<span class="ltx_bibblock">
Tomasz Stanislawek, Filip Gralinski, Anna Wróblewska, Dawid Lipinski, Agnieszka Kaliska, Paulina Rosalska, Bartosz Topolski, and Przemyslaw Biecek.

</span>
<span class="ltx_bibblock">Kleister: Key information extraction datasets involving long documents with complex layouts.

</span>
<span class="ltx_bibblock">In <em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">ICDAR (1)</em>, volume 12821 of <em id="bib.bib41.2.2" class="ltx_emph ltx_font_italic">Lecture Notes in Computer Science</em>, pages 564–579. Springer, 2021.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Svetlichnaya [2020]</span>
<span class="ltx_bibblock">
S Svetlichnaya.

</span>
<span class="ltx_bibblock">Deepform: Understand structured documents at scale, 2020.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tanaka et al. [2021]</span>
<span class="ltx_bibblock">
Ryota Tanaka, Kyosuke Nishida, and Sen Yoshida.

</span>
<span class="ltx_bibblock">Visualmrc: Machine reading comprehension on document images.

</span>
<span class="ltx_bibblock">In <em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">AAAI</em>, pages 13878–13888. AAAI Press, 2021.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tang et al. [2023a]</span>
<span class="ltx_bibblock">
Benny J. Tang, Angie Boggust, and Arvind Satyanarayan.

</span>
<span class="ltx_bibblock">Vistext: A benchmark for semantically rich chart captioning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">ACL (1)</em>, pages 7268–7298. Association for Computational Linguistics, 2023a.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tang et al. [2023b]</span>
<span class="ltx_bibblock">
Zineng Tang, Ziyi Yang, Guoxin Wang, Yuwei Fang, Yang Liu, Chenguang Zhu, Michael Zeng, Cha Zhang, and Mohit Bansal.

</span>
<span class="ltx_bibblock">Unifying vision, text, and layout for universal document processing.

</span>
<span class="ltx_bibblock">In <em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, pages 19254–19264, 2023b.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et al. [2023]</span>
<span class="ltx_bibblock">
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al.

</span>
<span class="ltx_bibblock">Llama: Open and efficient foundation language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2302.13971</em>, 2023.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Turski et al. [2023]</span>
<span class="ltx_bibblock">
Michal Turski, Tomasz Stanislawek, Karol Kaczmarek, Pawel Dyda, and Filip Gralinski.

</span>
<span class="ltx_bibblock">Ccpdf: Building a high quality corpus for visually rich documents from web crawl data.

</span>
<span class="ltx_bibblock">In <em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">ICDAR (3)</em>, volume 14189 of <em id="bib.bib47.2.2" class="ltx_emph ltx_font_italic">Lecture Notes in Computer Science</em>, pages 348–365. Springer, 2023.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vicuna [2023]</span>
<span class="ltx_bibblock">
Vicuna.

</span>
<span class="ltx_bibblock">Vicuna: An open chatbot impressing gpt-4.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/lm-sys/FastChat" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/lm-sys/FastChat</a>, 2023.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. [2022]</span>
<span class="ltx_bibblock">
Peng Wang, An Yang, Rui Men, Junyang Lin, Shuai Bai, Zhikang Li, Jianxin Ma, Chang Zhou, Jingren Zhou, and Hongxia Yang.

</span>
<span class="ltx_bibblock">OFA: unifying architectures, tasks, and modalities through a simple sequence-to-sequence learning framework.

</span>
<span class="ltx_bibblock">In <em id="bib.bib49.1.1" class="ltx_emph ltx_font_italic">ICML</em>, volume 162 of <em id="bib.bib49.2.2" class="ltx_emph ltx_font_italic">Proceedings of Machine Learning Research</em>, pages 23318–23340. PMLR, 2022.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. [2023a]</span>
<span class="ltx_bibblock">
Weihan Wang, Qingsong Lv, Wenmeng Yu, Wenyi Hong, Ji Qi, Yan Wang, Junhui Ji, Zhuoyi Yang, Lei Zhao, Xixuan Song, Jiazheng Xu, Bin Xu, Juanzi Li, Yuxiao Dong, Ming Ding, and Jie Tang.

</span>
<span class="ltx_bibblock">Cogvlm: Visual expert for pretrained language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib50.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2311.03079, 2023a.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. [2023b]</span>
<span class="ltx_bibblock">
Wenjin Wang, Yunhao Li, Yixin Ou, and Yin Zhang.

</span>
<span class="ltx_bibblock">Layout and task aware instruction prompt for zero-shot document image question answering.

</span>
<span class="ltx_bibblock"><em id="bib.bib51.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2306.00526, 2023b.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al. [2021a]</span>
<span class="ltx_bibblock">
Haiyang Xu, Ming Yan, Chenliang Li, Bin Bi, Songfang Huang, Wenming Xiao, and Fei Huang.

</span>
<span class="ltx_bibblock">E2E-VLP: end-to-end vision-language pre-training enhanced by visual learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib52.1.1" class="ltx_emph ltx_font_italic">ACL/IJCNLP (1)</em>, pages 503–513. Association for Computational Linguistics, 2021a.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al. [2021b]</span>
<span class="ltx_bibblock">
Yang Xu, Yiheng Xu, Tengchao Lv, Lei Cui, Furu Wei, Guoxin Wang, Yijuan Lu, Dinei A. F. Florêncio, Cha Zhang, Wanxiang Che, Min Zhang, and Lidong Zhou.

</span>
<span class="ltx_bibblock">Layoutlmv2: Multi-modal pre-training for visually-rich document understanding.

</span>
<span class="ltx_bibblock">In <em id="bib.bib53.1.1" class="ltx_emph ltx_font_italic">ACL/IJCNLP (1)</em>, pages 2579–2591. Association for Computational Linguistics, 2021b.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al. [2021]</span>
<span class="ltx_bibblock">
Zhengyuan Yang, Yijuan Lu, Jianfeng Wang, Xi Yin, Dinei Florêncio, Lijuan Wang, Cha Zhang, Lei Zhang, and Jiebo Luo.

</span>
<span class="ltx_bibblock">TAP: text-aware pre-training for text-vqa and text-caption.

</span>
<span class="ltx_bibblock">In <em id="bib.bib54.1.1" class="ltx_emph ltx_font_italic">CVPR</em>, pages 8751–8761. Computer Vision Foundation / IEEE, 2021.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ye et al. [2023a]</span>
<span class="ltx_bibblock">
Jiabo Ye, Anwen Hu, Haiyang Xu, Qinghao Ye, Ming Yan, Yuhao Dan, Chenlin Zhao, Guohai Xu, Chenliang Li, Junfeng Tian, Qian Qi, Ji Zhang, and Fei Huang.

</span>
<span class="ltx_bibblock">mplug-docowl: Modularized multimodal large language model for document understanding.

</span>
<span class="ltx_bibblock"><em id="bib.bib55.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2307.02499, 2023a.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ye et al. [2023b]</span>
<span class="ltx_bibblock">
Jiabo Ye, Anwen Hu, Haiyang Xu, Qinghao Ye, Ming Yan, Guohai Xu, Chenliang Li, Junfeng Tian, Qi Qian, Ji Zhang, Qin Jin, Liang He, Xin Lin, and Fei Huang.

</span>
<span class="ltx_bibblock">Ureader: Universal ocr-free visually-situated language understanding with multimodal large language model.

</span>
<span class="ltx_bibblock">In <em id="bib.bib56.1.1" class="ltx_emph ltx_font_italic">EMNLP (Findings)</em>, pages 2841–2858. Association for Computational Linguistics, 2023b.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ye et al. [2023c]</span>
<span class="ltx_bibblock">
Qinghao Ye, Haiyang Xu, Guohai Xu, Jiabo Ye, Ming Yan, Yiyang Zhou, Junyang Wang, Anwen Hu, Pengcheng Shi, Yaya Shi, Chenliang Li, Yuanhong Xu, Hehong Chen, Junfeng Tian, Qian Qi, Ji Zhang, and Fei Huang.

</span>
<span class="ltx_bibblock">mplug-owl: Modularization empowers large language models with multimodality.

</span>
<span class="ltx_bibblock"><em id="bib.bib57.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2304.14178, 2023c.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ye et al. [2023d]</span>
<span class="ltx_bibblock">
Qinghao Ye, Haiyang Xu, Jiabo Ye, Ming Yan, Anwen Hu, Haowei Liu, Qi Qian, Ji Zhang, Fei Huang, and Jingren Zhou.

</span>
<span class="ltx_bibblock">mplug-owl2: Revolutionizing multi-modal large language model with modality collaboration.

</span>
<span class="ltx_bibblock"><em id="bib.bib58.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2311.04257, 2023d.

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. [2024]</span>
<span class="ltx_bibblock">
Duzhen Zhang, Yahan Yu, Chenxing Li, Jiahua Dong, Dan Su, Chenhui Chu, and Dong Yu.

</span>
<span class="ltx_bibblock">Mm-llms: Recent advances in multimodal large language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib59.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2401.13601</em>, 2024.

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. [2023a]</span>
<span class="ltx_bibblock">
Liang Zhang, Anwen Hu, Jing Zhang, Shuo Hu, and Qin Jin.

</span>
<span class="ltx_bibblock">MPMQA: multimodal question answering on product manuals.

</span>
<span class="ltx_bibblock"><em id="bib.bib60.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2304.09660, 2023a.

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. [2023b]</span>
<span class="ltx_bibblock">
Tianshu Zhang, Xiang Yue, Yifei Li, and Huan Sun.

</span>
<span class="ltx_bibblock">Tablellama: Towards open large generalist models for tables.

</span>
<span class="ltx_bibblock"><em id="bib.bib61.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2311.09206, 2023b.

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al. [2023]</span>
<span class="ltx_bibblock">
Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, Yifan Du, Chen Yang, Yushuo Chen, Zhipeng Chen, Jinhao Jiang, Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang Liu, Peiyu Liu, Jian-Yun Nie, and Ji-Rong Wen.

</span>
<span class="ltx_bibblock">A survey of large language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib62.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2303.18223, 2023.

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhong et al. [2020]</span>
<span class="ltx_bibblock">
Xu Zhong, Elaheh ShafieiBavani, and Antonio Jimeno-Yepes.

</span>
<span class="ltx_bibblock">Image-based table recognition: Data, model, and evaluation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib63.1.1" class="ltx_emph ltx_font_italic">ECCV (21)</em>, volume 12366 of <em id="bib.bib63.2.2" class="ltx_emph ltx_font_italic">Lecture Notes in Computer Science</em>, pages 564–580. Springer, 2020.

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu et al. [2023]</span>
<span class="ltx_bibblock">
Deyao Zhu, Jun Chen, Xiaoqian Shen, Xiang Li, and Mohamed Elhoseiny.

</span>
<span class="ltx_bibblock">Minigpt-4: Enhancing vision-language understanding with advanced large language models, 2023.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2403.12894" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2403.12895" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2403.12895">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2403.12895" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2403.12896" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Apr  5 13:54:48 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
