<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2012.04580] Synthetic Data: Opening the data floodgates to enable faster, more directed development of machine learning methods</title><meta property="og:description" content="Many ground-breaking advancements in machine learning can be attributed to the availability of a large volume of rich data. Unfortunately, many large-scale datasets are highly sensitive, such as healthcare data, and ar‚Ä¶">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Synthetic Data: Opening the data floodgates to enable faster, more directed development of machine learning methods">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Synthetic Data: Opening the data floodgates to enable faster, more directed development of machine learning methods">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2012.04580">

<!--Generated on Thu Mar  7 02:18:31 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">
Synthetic Data: Opening the data floodgates to enable faster, more directed development of machine learning methods</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span id="id1.1.id1" class="ltx_ERROR undefined">\name</span>James Jordon <span id="id2.2.id2" class="ltx_ERROR undefined">\email</span>james.jordon@wolfson.ox.ac.uk 
<br class="ltx_break"><span id="id3.3.id3" class="ltx_ERROR undefined">\addr</span>Department of Engineering Science
<br class="ltx_break">University of Oxford,
Oxford, United Kingdom
<span id="id4.4.id4" class="ltx_ERROR undefined">\AND</span><span id="id5.5.id5" class="ltx_ERROR undefined">\name</span>Alan Wilson <span id="id6.6.id6" class="ltx_ERROR undefined">\email</span>awilson@turing.ac.uk 
<br class="ltx_break"><span id="id7.7.id7" class="ltx_ERROR undefined">\addr</span>The Alan Turing Institute, London, United Kingdom
<span id="id8.8.id8" class="ltx_ERROR undefined">\AND</span><span id="id9.9.id9" class="ltx_ERROR undefined">\name</span>Mihaela van der Schaar <span id="id10.10.id10" class="ltx_ERROR undefined">\email</span>mv472@cam.ac.uk 
<br class="ltx_break"><span id="id11.11.id11" class="ltx_ERROR undefined">\addr</span>University of Cambridge, Cambridge, UK
<br class="ltx_break">University of California, Los Angeles, USA 
<br class="ltx_break">The Alan Turing Institute, London, UK
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id12.id1" class="ltx_p">Many ground-breaking advancements in machine learning can be attributed to the availability of a large volume of rich data. Unfortunately, many large-scale datasets are highly sensitive, such as healthcare data, and are not widely available to the machine learning community. Generating synthetic data with privacy guarantees provides one such solution, allowing meaningful research to be carried out ‚Äúat scale‚Äù - by allowing the entirety of the machine learning community to potentially accelerate progress within a given field. In this article, we provide a high-level view of synthetic data: what it means, how we might evaluate it and how we might use it.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">In recent times, many ground-breaking advancements have been made in machine learning, such as the well-known use of deep reinforcement learning to play Atari games <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> and the widespread success of deep learning in general <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>, both of which can be largely attributed to the sheer volume of rich data that is available.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">More and more large datasets are becoming available in a wide variety of communities. In the U.S. medical community, for example, the fraction of providers using electronic health records (EHR) increased from 9.4% in 2008 to 83.8% in 2015 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. Within the criminal justice system and military, machine learning has the potential to revolutionise crime prevention and detection but the sensitivity of the data involved means that only a small fraction of machine learning researchers will work on developing meaningful and directed methods for these problems. The availability of large datasets presents enormous opportunities for collaboration between data-holders and the machine learning community. Currently, however, the (in)ability to share many of these large datasets is creating a bottleneck on the rate at which cutting edge machine learning methods can be developed and deployed in the real world.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">The most common way to mitigate the risk of sharing sensitive data is to de-identify the data - but it is by now well-known that records that have been de-identified can be easily re-identified by linking them to other identifiable datasets <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib24" title="" class="ltx_ref">24</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>. As a result of the lack of robustness of existing de-identification methods, new data-sharing policies and regulations have been introduced (such as with GDPR in Europe). Increased control over sensitive data results in greater difficulties for the machine learning research community in accessing said data. As a result, cutting edge methodologies and techniques often take longer to develop and are often not as specialised as they could be for a specific dataset and/or task.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.4" class="ltx_p">In light of the flaws with de-identification, we might turn to a popular strategy for enforcing privacy known as <math id="S1.p4.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S1.p4.1.m1.1a"><mi id="S1.p4.1.m1.1.1" xref="S1.p4.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S1.p4.1.m1.1b"><ci id="S1.p4.1.m1.1.1.cmml" xref="S1.p4.1.m1.1.1">ùëò</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.1.m1.1c">k</annotation></semantics></math>-anonymisation, in which a dataset is created by "binning" features in such a way that the features for any given sample are also shared by at least <math id="S1.p4.2.m2.1" class="ltx_Math" alttext="k-1" display="inline"><semantics id="S1.p4.2.m2.1a"><mrow id="S1.p4.2.m2.1.1" xref="S1.p4.2.m2.1.1.cmml"><mi id="S1.p4.2.m2.1.1.2" xref="S1.p4.2.m2.1.1.2.cmml">k</mi><mo id="S1.p4.2.m2.1.1.1" xref="S1.p4.2.m2.1.1.1.cmml">‚àí</mo><mn id="S1.p4.2.m2.1.1.3" xref="S1.p4.2.m2.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S1.p4.2.m2.1b"><apply id="S1.p4.2.m2.1.1.cmml" xref="S1.p4.2.m2.1.1"><minus id="S1.p4.2.m2.1.1.1.cmml" xref="S1.p4.2.m2.1.1.1"></minus><ci id="S1.p4.2.m2.1.1.2.cmml" xref="S1.p4.2.m2.1.1.2">ùëò</ci><cn type="integer" id="S1.p4.2.m2.1.1.3.cmml" xref="S1.p4.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.2.m2.1c">k-1</annotation></semantics></math> other samples. This ensures that any individual is "hidden" among <math id="S1.p4.3.m3.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S1.p4.3.m3.1a"><mi id="S1.p4.3.m3.1.1" xref="S1.p4.3.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S1.p4.3.m3.1b"><ci id="S1.p4.3.m3.1.1.cmml" xref="S1.p4.3.m3.1.1">ùëò</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.3.m3.1c">k</annotation></semantics></math> individuals and thus cannot be identified. Unfortunately, this approach can have serious drawbacks from a utility perspective - if a dataset contains fewer than <math id="S1.p4.4.m4.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S1.p4.4.m4.1a"><mi id="S1.p4.4.m4.1.1" xref="S1.p4.4.m4.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S1.p4.4.m4.1b"><ci id="S1.p4.4.m4.1.1.cmml" xref="S1.p4.4.m4.1.1">ùëò</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.4.m4.1c">k</annotation></semantics></math> outliers in a particular region of the feature space then these outliers will necessarily need to be binned with samples from other parts of the feature space, thus losing a significant amount of information about each sample due to the "wide" bins necessary to achieve this. Even when there are no outliers, the binning process still results in a dataset that contains less information than the original and is typically agnostic to any downstream tasks that might be performed - the information that is thrown away may prove crucial to a given task.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">In order for machine learning to realise its enormous potential in solving real world problems, it is key that machine learning researchers are both posed with real questions that need answering, but also data for which those questions can be asked and meaningfully answered. When real data is unavailable or prohibitively slow to gain access to, "synthetic" data offers a promising alternative that can allow researchers to perform meaningful research while waiting for access. In fact, synthetic data can be used by data holders as a means of screening potential machine learning collaborators, selecting only the collaborators who perform best on the synthetic data to give access to the real data.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">Unfortunately, generating <span id="S1.p6.1.1" class="ltx_text ltx_font_italic">meaningful</span> synthetic data is not an easy task and there are several challenges in developing methods for doing so; even defining what it means to be synthetic is non-trivial. In the realm of data release, additional care needs to be taken when attempting to deploy methods that may not perform well - once the (synthetic) data has been released, there is no taking it back, and a lack of understanding of the synthetic data can lead to serious privacy concerns.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>What is synthetic data?</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">Defining the term synthetic data is itself a difficult task. In the machine learning community, synthetic data often refers to data generated from a set of easy-to-specify distributions that is used to validate a machine learning model. It is most prevalently used in situations where real data does not suffice to validate a model because ground truth knowledge in real data is not attainable (such as in causal inference <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite> and feature selection <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>). Such datasets are created with the sole purpose of comparing machine learning methods on <span id="S2.p1.1.1" class="ltx_text ltx_font_italic">reproducible</span> datasets and are <span id="S2.p1.1.2" class="ltx_text ltx_font_italic">not</span> created to imitate a real dataset. While this type of synthetic data allows for easily reproducible results, the results on the synthetic data do not necessarily reflect the performance of the methods in any real dataset, and so the conclusions that can be drawn from such experiments are limited.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">For the sake of data sharing, synthetic data should be generated <span id="S2.p2.1.1" class="ltx_text ltx_font_italic">using a real dataset</span> to shape the synthetic data. However, now that the "synthetic" data is allowed to depend on the real data, it becomes less clear exactly what is meant by the term synthetic, and how exactly the synthetic data can use the real data while still remaining synthetic. It is crucial that those looking to create synthetic versions of their data understand how a given synthetic data generating model defines synthetic - a naive belief that the term synthetic is equivalent to private can result in serious privacy violations. The popular generative modelling frameworks Generative Adversarial Networks (GANs <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>) and Variational Auto-encoders (VAEs <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>) use real data during training to train a model capable of generating (or "synthesising") "fake" data points. But what makes these data points "fake"? A quick look at the seminal GAN paper <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> might make it look like a GAN is all we need to generate a synthetic version of a real dataset. However, closer inspection would reveal that nothing is actually being done to prevent the GAN from simply learning to "regurgitate" the real data. In fact, GANs are notorious for suffering from a phenomena referred to as <span id="S2.p2.1.2" class="ltx_text ltx_font_italic">mode collapse</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>, which causes GANs to repeatedly generate data points that are very similar to the most popular training points.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">It is for precisely this reason that one needs to be careful when using the phrases "fake data" or "synthetic data". Once we allow for the data generating mechanism to depend on real data, the term synthetic on its own is not enough; it must be accompanied by some sort of constraint that makes clear the limits for how the synthetic data can use the real data. These constraints should be formulated by asking <span id="S2.p3.1.1" class="ltx_text ltx_font_italic">what is it about the real data that makes it unsuitable for release?</span> This will typically be answered in terms of certain privacy concerns that releasing the real data would have. Formulating these privacy concerns in a rigorous manner is important to allow for methods to <span id="S2.p3.1.2" class="ltx_text ltx_font_italic">provably</span> satisfy them.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Privacy</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Privacy is an ongoing area of research in the machine learning and statistics communities and has garnered much attention in recent times with the rapid advancement of technologies that allow for easy data collection on large scales. There is no single definition of privacy that will work in all situations. It should also be noted that attaining certain types of privacy on certain datasets may render the resulting synthetic data useless and so either the notion of privacy will need to be revised or the goal of generating synthetic data abandoned. A simple example of this would be the notion that private synthetic data should not allow us to learn any more about an individual than if we had not had the data. Any dataset that allows us to build a good predictive model for a particular feature based on the other features will violate this - if we know the remaining features for a particular person, we can use the predictive model to predict the final feature. More importantly, this can be done <span id="S3.p1.1.1" class="ltx_text ltx_font_italic">even if the person was not in the original dataset</span>. There are two failures: (1) the privacy notion is not immune to <span id="S3.p1.1.2" class="ltx_text ltx_font_italic">post-processing</span> and (2) the notion relies on knowing what information is already known about every individual. While the data itself may not reveal anything about a particular individual (it may not even contain the individual), it can be processed (e.g. by being used to train a predictive model) in such a way that by using existing information (such as an auxiliary dataset), more can be learned about an individual.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p">It is possible to mitigate the risk of (1) by limiting how exactly the synthetic data can be used or accessed (for example by allowing access to it only through a safe environment in which only certain functions can be performed), however, in doing so, we revert back to the problems we had with real data, in that gaining access can be a cumbersome process. As such, we believe that synthetic data is most useful when it allows for <span id="S3.p2.1.1" class="ltx_text ltx_font_italic">public</span> sharing, without constraint on how the data will be used. It is therefore imperative that we understand not only what it means for the data to be private but also what it means for the data to <span id="S3.p2.1.2" class="ltx_text ltx_font_italic">remain</span> private after being processed by an adversarial attacker. It is, however, incredibly difficult to demonstrate adversarial robustness empirically; any attempt to do so is naturally limited by the researcher‚Äôs own capabilities. Instead, the goal should be to obtain <span id="S3.p2.1.3" class="ltx_text ltx_font_italic">provable</span> guarantees, which make clear assumptions (or preferably no assumptions) about an adversaries capabilities.</p>
</div>
<div id="S3.p3" class="ltx_para">
<p id="S3.p3.1" class="ltx_p">Unfortunately, (2) is equally difficult to mitigate. Modelling the knowledge of an adversary is difficult and also risky, since failing to correctly model the full extent of an adversaries possible knowledge can naturally lead to privacy concerns. It is much safer to assume the adversary knows as much as the worst case scenario would be and work from there, though such an approach calls for the strongest privacy guarantees and thus, potentially, the lowest utility from the synthetic data. Moreover, as more and more data (even synthetic data) is released, an adversaries knowledge can easily change. As there is no way to take back data that we release publicly, it is better to be conservative in this regard (such as assuming the adversary is worst-case).</p>
</div>
<div id="S3.p4" class="ltx_para">
<p id="S3.p4.1" class="ltx_p">It is our belief that a good, <span id="S3.p4.1.1" class="ltx_text ltx_font_italic">robust</span> notion of privacy should make very few assumptions about the limitations of a potential adversary. One such notion of privacy is <span id="S3.p4.1.2" class="ltx_text ltx_font_italic">Differential Privacy</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>. Differential Privacy is a notion of privacy that is immune to post-processing, that is, if something is differentially private, then no matter what is done to the differentially private object (such as a dataset), it will remain differentially private. It also makes no assumptions about any auxiliary data that may (publicly) exist about a given individual. Perhaps, though, the most attractive thing about differential privacy is that it can be defined rigorously, in fairly simple mathematical terms. This means that, for example with synthetic data, a synthetic dataset can be <span id="S3.p4.1.3" class="ltx_text ltx_font_italic">proven</span> to be differentially private (or not) and it does not need to be assessed empirically.</p>
</div>
<div id="S3.p5" class="ltx_para">
<p id="S3.p5.2" class="ltx_p">Of course, there are drawbacks to differential privacy, for example, it requires specification of a parameter, <math id="S3.p5.1.m1.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S3.p5.1.m1.1a"><mi id="S3.p5.1.m1.1.1" xref="S3.p5.1.m1.1.1.cmml">œµ</mi><annotation-xml encoding="MathML-Content" id="S3.p5.1.m1.1b"><ci id="S3.p5.1.m1.1.1.cmml" xref="S3.p5.1.m1.1.1">italic-œµ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p5.1.m1.1c">\epsilon</annotation></semantics></math>, that controls "how" private something should be, and determining a good value for <math id="S3.p5.2.m2.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S3.p5.2.m2.1a"><mi id="S3.p5.2.m2.1.1" xref="S3.p5.2.m2.1.1.cmml">œµ</mi><annotation-xml encoding="MathML-Content" id="S3.p5.2.m2.1b"><ci id="S3.p5.2.m2.1.1.cmml" xref="S3.p5.2.m2.1.1">italic-œµ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p5.2.m2.1c">\epsilon</annotation></semantics></math> is not an easy task (because it is not easy to interpret semantically). In some situations, the assumptions (or rather lack of assumptions) can be much stronger than needed, since it relies on determining the worst-case situation and as such data utility often suffers more than is necessary for the task at hand.</p>
</div>
<div id="S3.p6" class="ltx_para">
<p id="S3.p6.1" class="ltx_p">Unfortunately, few alternatives to differential privacy actually exist. It has proven to be incredibly difficult to formulate common semantic notions of privacy in a rigorous mathematical way. This typically implies that such notions are not actually achievable in a real sense (such as the notion described at the beginning of this section) or that enforcing such notions would result in zero utility synthetic data.</p>
</div>
<div id="S3.p7" class="ltx_para">
<p id="S3.p7.3" class="ltx_p">One such theoretical alternative is membership privacy, introduced in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>. Membership privacy is a more abstract notion of privacy than differential privacy, that relies on defining a set of distributions, <math id="S3.p7.1.m1.1" class="ltx_Math" alttext="\mathbb{D}" display="inline"><semantics id="S3.p7.1.m1.1a"><mi id="S3.p7.1.m1.1.1" xref="S3.p7.1.m1.1.1.cmml">ùîª</mi><annotation-xml encoding="MathML-Content" id="S3.p7.1.m1.1b"><ci id="S3.p7.1.m1.1.1.cmml" xref="S3.p7.1.m1.1.1">ùîª</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p7.1.m1.1c">\mathbb{D}</annotation></semantics></math>, that captures the adversary‚Äôs possible states of prior knowledge, and a leakage parameter <math id="S3.p7.2.m2.1" class="ltx_Math" alttext="\gamma" display="inline"><semantics id="S3.p7.2.m2.1a"><mi id="S3.p7.2.m2.1.1" xref="S3.p7.2.m2.1.1.cmml">Œ≥</mi><annotation-xml encoding="MathML-Content" id="S3.p7.2.m2.1b"><ci id="S3.p7.2.m2.1.1.cmml" xref="S3.p7.2.m2.1.1">ùõæ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p7.2.m2.1c">\gamma</annotation></semantics></math> that determines by how much an adversary‚Äôs knowledge is allowed to change based on the output of an algorithm. Differential privacy can be recovered from this definition by defining an appropriate <math id="S3.p7.3.m3.1" class="ltx_Math" alttext="\mathbb{D}" display="inline"><semantics id="S3.p7.3.m3.1a"><mi id="S3.p7.3.m3.1.1" xref="S3.p7.3.m3.1.1.cmml">ùîª</mi><annotation-xml encoding="MathML-Content" id="S3.p7.3.m3.1b"><ci id="S3.p7.3.m3.1.1.cmml" xref="S3.p7.3.m3.1.1">ùîª</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p7.3.m3.1c">\mathbb{D}</annotation></semantics></math>.</p>
</div>
<div id="S3.p8" class="ltx_para">
<p id="S3.p8.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> propose an empirical notion of private synthetic data which relies on determining how close a synthetic data point is (in Euclidean space) to any real data points.</p>
</div>
<div id="S3.p9" class="ltx_para">
<p id="S3.p9.1" class="ltx_p">Investigating existing definitions of privacy and their real-world implications is a crucial step in understanding them and also in convincing communities at large that such definitions are appropriate for the problems they face. While notions such as differential privacy and membership privacy are both theoretical guarantees that need not be tested empirically, the semantics behind their definitions are somewhat unclear and empirical evaluations against real attackers would benefit our understanding greatly. Our recent synthetic data competition <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> pit cutting edge privacy research against real-world attackers to work towards greater clarity over existing privacy methods.</p>
</div>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>How can synthetic data be used and evaluated?</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">While promising from a privacy perspective, it is important to understand the limitations of when and how synthetic data should be used. The question of how to evaluate synthetic data is also closely tied to how it will be used. In the most general case, one might hope for the synthetic data to be a perfect substitute for the real data in anything for which the real data could be used. For this to be true, the distribution of the synthetic data should match the distribution of the real data. Evaluating this empirically, though, is difficult. A lot of time and attention is being given to developing methods for evaluating the similarity of empirical distributions and it is very much an ongoing area of research <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p">The risk with using synthetic data for training as a direct replacement for real data is that at run time, the models will be faced with real data. If the distribution of the synthetic data deviates from that of the real data, then distributional mismatch will occur, resulting in phenomena such as <span id="S4.p2.1.1" class="ltx_text ltx_font_italic">covariate shift</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>, leading to sub-optimal model performance. Depending on the severity of the mismatch (which is difficult to quantify due to the lack of good empirical evaluation tools), this could have serious implications.</p>
</div>
<div id="S4.p3" class="ltx_para">
<p id="S4.p3.1" class="ltx_p">For this reason, it is best to create synthetic data with a particular use in mind. It might be that we wish to develop an algorithm for learning a predictive model on a given dataset, or that we wish to perform unsupervised clustering, for example. The quality of the synthetic dataset can then be measured with respect to standard metrics used for these tasks by training a model (or a set of models) on synthetic data and testing it (them) on real data (a paradigm referred to as Train on Synthetic, Test on Real (TSTR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>)), the performance on the test set can then be reported using standard metrics (such as AUROC) and even compared to the performance achieved when the same model is trained on real data. By comparing the performance difference between training on synthetic and training on real data we can assess how well the synthetic data captures the characteristics of the real data that are important for carrying out the given task.</p>
</div>
<div id="S4.p4" class="ltx_para">
<p id="S4.p4.1" class="ltx_p">Unfortunately, TSTR is sensitive to the models chosen for the task; it may be that logistic regression performs similarly on synthetic and real data but that the performance of random forests drops significantly when the synthetic data is used. Aggregating the TSTR values across different models is not as simple as averaging since this can hide the fact that the synthetic data is not appropriate for the training of certain models.</p>
</div>
<div id="S4.p5" class="ltx_para">
<p id="S4.p5.1" class="ltx_p">If the synthetic data is intended to be used as a tool for enabling meaningful machine learning research (which we strongly believe is the best use of synthetic data), then it is important that when a comparison of methods is made on the synthetic data, the answer reflects what the answer would be if the same comparison was made on the real data. This comparison may be of two (or more) very different models, or may be of two slight variations of the same model, but in both cases, if the hope is that synthetic data can allow researchers to develop the best methods for us on the real data, then the development process - which will involve many comparisons of this nature - needs to be meaningful on the synthetic data. To this end, we proposed a new metric in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> which we term the Synthetic Ranking Agreement (SRA).</p>
</div>
<div id="S4.p6" class="ltx_para">
<p id="S4.p6.1" class="ltx_p">Like TSTR, SRA requires a task to be specified for the data (though like TSTR we could calculate the SRA independently for several different tasks). We train a selection of models on the synthetic data and then test them <span id="S4.p6.1.1" class="ltx_text ltx_font_italic">on the synthetic data</span>, imitating what a researcher would (have to) do given only the synthetic data. We also train and test the models in the real data. The metric is then defined to be the agreement between the <span id="S4.p6.1.2" class="ltx_text ltx_font_italic">ranking</span> of the models. While this metric certainly has its limitations (it is limited by the set of models used to calculate it), we believe that metrics such as this are a step in the right direction for enabling the creation of synthetic datasets that will enable more directed machine learning research.</p>
</div>
<div id="S4.p7" class="ltx_para">
<p id="S4.p7.1" class="ltx_p">A final, very promising use for synthetic data is in running competitions. Privacy definitions such as differential privacy lend themselves naturally (by varying the privacy parameter, <math id="S4.p7.1.m1.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S4.p7.1.m1.1a"><mi id="S4.p7.1.m1.1.1" xref="S4.p7.1.m1.1.1.cmml">œµ</mi><annotation-xml encoding="MathML-Content" id="S4.p7.1.m1.1b"><ci id="S4.p7.1.m1.1.1.cmml" xref="S4.p7.1.m1.1.1">italic-œµ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p7.1.m1.1c">\epsilon</annotation></semantics></math>) to creating a sequence of synthetic datasets with increasingly less and less privacy. At each stage of the competition, researchers can be given a synthetic dataset to develop a method for the given task. The data holder can then evaluate each of the methods on the real data and select the best methods to "advance" to the next round, at which point a new dataset will be released to those still in the competition, this time with a lower privacy guarantee. This sort of "gated" approach can also be used to alleviate the difficulties of granting access to real data. As trust grows within a data-holder and researcher partnership, data with weaker and weaker privacy guarantees can be given to the researcher.</p>
</div>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Existing Methods</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">DPGAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> proposes a framework for modifying the popular GAN framework to be differentially private, relying on the Post-Processing Theorem <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> to change the problem of learning a differentially private generator to learning a differentially private discriminator. Their work uses a technique introduced by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> that provides a differentially private mechanism for training deep networks. The key idea is that noise is added to the gradient of the discriminator during training to create differential privacy guarantees. These ideas are also used similarly in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">PATEGAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> is similar in spirit; during training of the discriminator differentially private training data is created using the method proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>. The proposed model modifies the PATE framework <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>, <a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite> for use in a generative model setting (specifically for use with GANs). The key to the GAN framework is that the discriminator is a <span id="S5.p2.1.1" class="ltx_text ltx_font_italic">differentiable</span> module trained to classify samples as either real or generated. The PATE framework provides a differentially private mechanism for classification by training multiple teacher models on disjoint partitions of the data. To classify a new sample each teacher‚Äôs output is evaluated on the sample and then all outputs are noisily aggregated. This noisy aggregation, though, results in a classifier that is <span id="S5.p2.1.2" class="ltx_text ltx_font_italic">not</span> differentiable with respect to the parameters of the generator. In order to overcome this problem the student model from <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> is used, that involves taking some <span id="S5.p2.1.3" class="ltx_text ltx_font_italic">public</span> unlabelled data, labelling it using the standard PATE mechanism and then training the student using the resulting labelled data. Because access to any public data is often an unreasonable assumption in synthetic data generation, we adapt this training paradigm in a way that does not require public data by training the student using only outputs from the (differentially private) generator.</p>
</div>
<div id="S5.p3" class="ltx_para">
<p id="S5.p3.1" class="ltx_p">While both DPGAN and PATEGAN are promising ideas from a differential privacy perspective, their utility trade-off is significant if one wants to enforce a meaningful level of differential privacy. Moreover, both methods are only evaluated on static data and while both ideas generalise to time-series data, it is not clear how the performance will be affected.</p>
</div>
<div id="S5.p4" class="ltx_para">
<p id="S5.p4.1" class="ltx_p">The Simulacrum is a synthetic dataset recently created to replicate the Cancer Analysis System datasets <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>. To generate this data, the correlation between each pair of variables was calculated, and for each variable, the two variables most correlated with it were selected. A directed graph is then constructed by taking the nodes to be the variables, and the edges to be the selected pairs of (highly) correlated variables. Directions correspond to going from the node with more edges to the node with fewer edges. From this graph, the data is then generated by learning a series of conditional distributions, starting with the root node (whose distribution is not conditional on anything), and then sequentially learning the distributions as we descend the tree, with each variable‚Äôs conditional distribution being conditioned on its parent nodes. Some clustering and grouping is applied to the conditional distributions to ensure that all conditional distributions correspond to at least 50 records (thus providing 50-anonymity). While the privacy guarantees that are claimed are indeed provided (50-anonymity), the quality of the data is not in any way guaranteed and the decision to use the two most correlated variables and even the same number of variables for each variable is entirely heuristic.</p>
</div>
<div id="S5.p5" class="ltx_para">
<p id="S5.p5.1" class="ltx_p">Other existing works generate synthetic data using summary statistics of the original data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> or based on specific domain-knowledge <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>; however, those methods are limited to low-dimensional feature spaces, specific fields and do not provide any theoretical privacy guarantees. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> generates synthetic patient records using a GAN framework. However, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> focuses only on generating discrete variables, whereas DP-GAN and PATE-GAN are both capable of generating mixed-type (continuous, discrete, and binary) variables. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> also does not provide any theoretical privacy guarantees and instead uses ad-hoc notions of privacy which are only validated empirically.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Technical Challenges</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">There are several technical challenges that must be overcome in order to develop good synthetic data generation models, which can be broadly separated into 3 main categories:</p>
<ul id="S6.I1" class="ltx_itemize">
<li id="S6.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><math id="S6.I1.i1.1.1.m1.1" class="ltx_Math" alttext="\blacksquare" display="inline"><semantics id="S6.I1.i1.1.1.m1.1b"><mi mathsize="50%" mathvariant="normal" id="S6.I1.i1.1.1.m1.1.1" xref="S6.I1.i1.1.1.m1.1.1.cmml">‚ñ†</mi><annotation-xml encoding="MathML-Content" id="S6.I1.i1.1.1.m1.1c"><ci id="S6.I1.i1.1.1.m1.1.1.cmml" xref="S6.I1.i1.1.1.m1.1.1">‚ñ†</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.I1.i1.1.1.m1.1d">\blacksquare</annotation></semantics></math></span> 
<div id="S6.I1.i1.p1" class="ltx_para">
<p id="S6.I1.i1.p1.1" class="ltx_p">Data generation</p>
<ul id="S6.I1.i1.I1" class="ltx_itemize">
<li id="S6.I1.i1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="S6.I1.i1.I1.i1.1.1.1" class="ltx_text ltx_font_bold">‚Äì</span></span> 
<div id="S6.I1.i1.I1.i1.p1" class="ltx_para">
<p id="S6.I1.i1.I1.i1.p1.1" class="ltx_p">Generating data for a variety of data types</p>
</div>
</li>
<li id="S6.I1.i1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="S6.I1.i1.I1.i2.1.1.1" class="ltx_text ltx_font_bold">‚Äì</span></span> 
<div id="S6.I1.i1.I1.i2.p1" class="ltx_para">
<p id="S6.I1.i1.I1.i2.p1.1" class="ltx_p">GANs have significant limitations which need to be addressed</p>
</div>
</li>
<li id="S6.I1.i1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="S6.I1.i1.I1.i3.1.1.1" class="ltx_text ltx_font_bold">‚Äì</span></span> 
<div id="S6.I1.i1.I1.i3.p1" class="ltx_para">
<p id="S6.I1.i1.I1.i3.p1.1" class="ltx_p">Generating mixed-type data in a non-parametric way is difficult</p>
</div>
</li>
</ul>
</div>
</li>
<li id="S6.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><math id="S6.I1.i2.1.1.m1.1" class="ltx_Math" alttext="\blacksquare" display="inline"><semantics id="S6.I1.i2.1.1.m1.1b"><mi mathsize="50%" mathvariant="normal" id="S6.I1.i2.1.1.m1.1.1" xref="S6.I1.i2.1.1.m1.1.1.cmml">‚ñ†</mi><annotation-xml encoding="MathML-Content" id="S6.I1.i2.1.1.m1.1c"><ci id="S6.I1.i2.1.1.m1.1.1.cmml" xref="S6.I1.i2.1.1.m1.1.1">‚ñ†</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.I1.i2.1.1.m1.1d">\blacksquare</annotation></semantics></math></span> 
<div id="S6.I1.i2.p1" class="ltx_para">
<p id="S6.I1.i2.p1.1" class="ltx_p">Privacy</p>
<ul id="S6.I1.i2.I1" class="ltx_itemize">
<li id="S6.I1.i2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="S6.I1.i2.I1.i1.1.1.1" class="ltx_text ltx_font_bold">‚Äì</span></span> 
<div id="S6.I1.i2.I1.i1.p1" class="ltx_para">
<p id="S6.I1.i2.I1.i1.p1.1" class="ltx_p">Mathematical notions need to align with social understanding</p>
</div>
</li>
<li id="S6.I1.i2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="S6.I1.i2.I1.i2.1.1.1" class="ltx_text ltx_font_bold">‚Äì</span></span> 
<div id="S6.I1.i2.I1.i2.p1" class="ltx_para">
<p id="S6.I1.i2.I1.i2.p1.1" class="ltx_p">Complex data generation methods will require careful application of privacy mechanisms and in some cases will require new machinery</p>
</div>
</li>
</ul>
</div>
</li>
<li id="S6.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><math id="S6.I1.i3.1.1.m1.1" class="ltx_Math" alttext="\blacksquare" display="inline"><semantics id="S6.I1.i3.1.1.m1.1b"><mi mathsize="50%" mathvariant="normal" id="S6.I1.i3.1.1.m1.1.1" xref="S6.I1.i3.1.1.m1.1.1.cmml">‚ñ†</mi><annotation-xml encoding="MathML-Content" id="S6.I1.i3.1.1.m1.1c"><ci id="S6.I1.i3.1.1.m1.1.1.cmml" xref="S6.I1.i3.1.1.m1.1.1">‚ñ†</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.I1.i3.1.1.m1.1d">\blacksquare</annotation></semantics></math></span> 
<div id="S6.I1.i3.p1" class="ltx_para">
<p id="S6.I1.i3.p1.1" class="ltx_p">Evaluation</p>
<ul id="S6.I1.i3.I1" class="ltx_itemize">
<li id="S6.I1.i3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="S6.I1.i3.I1.i1.1.1.1" class="ltx_text ltx_font_bold">‚Äì</span></span> 
<div id="S6.I1.i3.I1.i1.p1" class="ltx_para">
<p id="S6.I1.i3.I1.i1.p1.1" class="ltx_p">Empirically comparing distributions is difficult</p>
</div>
</li>
<li id="S6.I1.i3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="S6.I1.i3.I1.i2.1.1.1" class="ltx_text ltx_font_bold">‚Äì</span></span> 
<div id="S6.I1.i3.I1.i2.p1" class="ltx_para">
<p id="S6.I1.i3.I1.i2.p1.1" class="ltx_p">Existing techniques for evaluating rely on knowing what the synthetic data might be used for</p>
</div>
</li>
<li id="S6.I1.i3.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="S6.I1.i3.I1.i3.1.1.1" class="ltx_text ltx_font_bold">‚Äì</span></span> 
<div id="S6.I1.i3.I1.i3.p1" class="ltx_para">
<p id="S6.I1.i3.I1.i3.p1.1" class="ltx_p">Defining appropriate metrics on complex data structures (e.g. mixed type data) will be necessary</p>
</div>
</li>
</ul>
</div>
</li>
</ul>
</div>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>The Road Ahead</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">While the methods discussed in the previous sections provide promising first steps towards generating private synthetic data, there are still significant limitations and much room for improvement. The differentially private methods, DPGAN and PATEGAN, both rely on different differential privacy enforcing mechanisms, neither of which were designed specifically for synthetic data generation but are for use more generally. Further research can and should be done to refine or replace these mechanisms to be tailored specifically to the problem of data generation.</p>
</div>
<div id="S7.p2" class="ltx_para">
<p id="S7.p2.1" class="ltx_p">Moreover, the underlying generative model used in both cases was a GAN, which, while they have proven very successful in the realm of image generation, may not be most appropriate in all settings. Further research should be done to not only improve (or replace GANs) but to understand their limits and potential privacy concerns when used in "vanilla" form (i.e. without additional mechanisms to ensure privacy).</p>
</div>
<div id="S7.p3" class="ltx_para">
<p id="S7.p3.1" class="ltx_p">As discussed in Section <a href="#S3" title="3 Privacy ‚Ä£ Synthetic Data: Opening the data floodgates to enable faster, more directed development of machine learning methods" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, there are several existing definitions of privacy. Some are theoretically grounded such as Differential Privacy, Membership Privacy and k-anonymity (among others) whereas others are defined empirically such as the definition found in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>. There is a lot of work to be done purely within the realm of privacy, both in understanding the social implications of existing definitions and in developing new frameworks which may align better with social expectations and legal definitions (such as those laid out in GDPR). In fact, anyone working on synthetic data should work closely and discuss with policy experts to really understand what is needed of synthetic data, which will vary between data holders.</p>
</div>
<div id="S7.p4" class="ltx_para">
<p id="S7.p4.1" class="ltx_p">Finally, though provable privacy is attractive, we must strive to make it understandable and interpretable. To do so may require empirical evaluations such as our synthetic data competition <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> to shed light on exactly what different notions of privacy might mean in practice. Ultimately, our duty is to those whose data we are collecting, and it is paramount that they understand <span id="S7.p4.1.1" class="ltx_text ltx_font_italic">why</span> what we are doing to protect their data actually protects their data, so that they trust us with their data, and thus machine learning may continue its rapid advancement.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock"><span id="bib.bib1.1.1" class="ltx_text" style="font-size:90%;">
</span><span id="bib.bib1.2.2" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">Abadi, M., Chu, A., Goodfellow, I., McMahan, H.¬†B., Mironov, I., Talwar,
K., and Zhang, L.</span><span id="bib.bib1.3.3" class="ltx_text" style="font-size:90%;">
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.4.1" class="ltx_text" style="font-size:90%;">Deep learning with differential privacy.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.5.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib1.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the 2016 ACM SIGSAC Conference on Computer and
Communications Security</span><span id="bib.bib1.7.3" class="ltx_text" style="font-size:90%;"> (2016), ACM, pp.¬†308‚Äì318.
</span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text" style="font-size:90%;">
</span><span id="bib.bib2.2.2" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">Beaulieu-Jones, B.¬†K., Wu, Z.¬†S., Williams, C., and Greene, C.¬†S.</span><span id="bib.bib2.3.3" class="ltx_text" style="font-size:90%;">
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.4.1" class="ltx_text" style="font-size:90%;">Privacy-preserving generative deep neural networks support clinical
data sharing.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.5.1" class="ltx_text ltx_font_italic" style="font-size:90%;">BioRxiv</span><span id="bib.bib2.6.2" class="ltx_text" style="font-size:90%;"> (2017), 159756.
</span>
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text" style="font-size:90%;">
</span><span id="bib.bib3.2.2" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">Bi≈Ñkowski, M., Sutherland, D.¬†J., Arbel, M., and Gretton, A.</span><span id="bib.bib3.3.3" class="ltx_text" style="font-size:90%;">
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.4.1" class="ltx_text" style="font-size:90%;">Demystifying MMD GANs.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.5.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib3.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">International Conference on Learning Representations</span><span id="bib.bib3.7.3" class="ltx_text" style="font-size:90%;">
(2018).
</span>
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock"><span id="bib.bib4.1.1" class="ltx_text" style="font-size:90%;">
</span><span id="bib.bib4.2.2" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">Buczak, A.¬†L., Babin, S., and Moniz, L.</span><span id="bib.bib4.3.3" class="ltx_text" style="font-size:90%;">
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.4.1" class="ltx_text" style="font-size:90%;">Data-driven approach for creating synthetic electronic medical
records.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.5.1" class="ltx_text ltx_font_italic" style="font-size:90%;">BMC medical informatics and decision making 10</span><span id="bib.bib4.6.2" class="ltx_text" style="font-size:90%;">, 1 (2010), 59.
</span>
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text" style="font-size:90%;">
</span><span id="bib.bib5.2.2" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">Che, T., Li, Y., Jacob, A.¬†P., Bengio, Y., and Li, W.</span><span id="bib.bib5.3.3" class="ltx_text" style="font-size:90%;">
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.4.1" class="ltx_text" style="font-size:90%;">Mode regularized generative adversarial networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.5.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1612.02136</span><span id="bib.bib5.6.2" class="ltx_text" style="font-size:90%;"> (2016).
</span>
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text" style="font-size:90%;">
</span><span id="bib.bib6.2.2" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">Chen, J., Song, L., Wainwright, M.¬†J., and Jordan, M.¬†I.</span><span id="bib.bib6.3.3" class="ltx_text" style="font-size:90%;">
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.4.1" class="ltx_text" style="font-size:90%;">Learning to explain: An information-theoretic perspective on model
interpretation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.5.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1802.07814</span><span id="bib.bib6.6.2" class="ltx_text" style="font-size:90%;"> (2018).
</span>
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text" style="font-size:90%;">
</span><span id="bib.bib7.2.2" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">Choi, E., Biswal, S., Malin, B., Duke, J., Stewart, W.¬†F., and Sun, J.</span><span id="bib.bib7.3.3" class="ltx_text" style="font-size:90%;">
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.4.1" class="ltx_text" style="font-size:90%;">Generating multi-label discrete electronic health records using
generative adversarial networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.5.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1703.06490</span><span id="bib.bib7.6.2" class="ltx_text" style="font-size:90%;"> (2017).
</span>
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text" style="font-size:90%;">
</span><span id="bib.bib8.2.2" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">Dwork, C., Roth, A., et¬†al.</span><span id="bib.bib8.3.3" class="ltx_text" style="font-size:90%;">
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.4.1" class="ltx_text" style="font-size:90%;">The algorithmic foundations of differential privacy.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.5.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Foundations and Trends¬Æ in Theoretical Computer
Science 9</span><span id="bib.bib8.6.2" class="ltx_text" style="font-size:90%;">, 3‚Äì4 (2014), 211‚Äì407.
</span>
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text" style="font-size:90%;">
</span><span id="bib.bib9.2.2" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">El¬†Emam, K., Buckeridge, D., Tamblyn, R., Neisa, A., Jonker, E., and
Verma, A.</span><span id="bib.bib9.3.3" class="ltx_text" style="font-size:90%;">
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.4.1" class="ltx_text" style="font-size:90%;">The re-identification risk of canadians from longitudinal
demographics.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.5.1" class="ltx_text ltx_font_italic" style="font-size:90%;">BMC medical informatics and decision making 11</span><span id="bib.bib9.6.2" class="ltx_text" style="font-size:90%;">, 1 (2011), 46.
</span>
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text" style="font-size:90%;">
</span><span id="bib.bib10.2.2" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">Erlich, Y., and Narayanan, A.</span><span id="bib.bib10.3.3" class="ltx_text" style="font-size:90%;">
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.4.1" class="ltx_text" style="font-size:90%;">Routes for breaching and protecting genetic privacy.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.5.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Nature Reviews Genetics 15</span><span id="bib.bib10.6.2" class="ltx_text" style="font-size:90%;">, 6 (2014), 409‚Äì421.
</span>
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text" style="font-size:90%;">
</span><span id="bib.bib11.2.2" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">Esteban, C., Hyland, S.¬†L., and R√§tsch, G.</span><span id="bib.bib11.3.3" class="ltx_text" style="font-size:90%;">
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.4.1" class="ltx_text" style="font-size:90%;">Real-valued (medical) time series generation with recurrent
conditional gans.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.5.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1706.02633</span><span id="bib.bib11.6.2" class="ltx_text" style="font-size:90%;"> (2017).
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock"><span id="bib.bib12.1.1" class="ltx_text" style="font-size:90%;">
</span><span id="bib.bib12.2.2" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D.,
Ozair, S., Courville, A., and Bengio, Y.</span><span id="bib.bib12.3.3" class="ltx_text" style="font-size:90%;">
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.4.1" class="ltx_text" style="font-size:90%;">Generative adversarial nets.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.5.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib12.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Advances in neural information processing systems</span><span id="bib.bib12.7.3" class="ltx_text" style="font-size:90%;"> (2014),
pp.¬†2672‚Äì2680.
</span>
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text" style="font-size:90%;">
</span><span id="bib.bib13.2.2" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">Henry, J., Pylypchuk, Y., Searcy, T., and Patel, V.</span><span id="bib.bib13.3.3" class="ltx_text" style="font-size:90%;">
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.4.1" class="ltx_text" style="font-size:90%;">Adoption of electronic health record systems among us non-federal
acute care hospitals: 2008‚Äì2015. may 2016.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.5.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Accessed via:&lt; https://dashboard. healthit.
gov/evaluations/data-briefs/non-federal-acute-care-hospital-ehr-adoption-2008-2015.
php&gt;. Accessed on June 21</span><span id="bib.bib13.6.2" class="ltx_text" style="font-size:90%;"> (2017).
</span>
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock"><span id="bib.bib14.1.1" class="ltx_text" style="font-size:90%;">
</span><span id="bib.bib14.2.2" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">Insight, H.¬†D.</span><span id="bib.bib14.3.3" class="ltx_text" style="font-size:90%;">
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.4.1" class="ltx_text" style="font-size:90%;">The Simulacrum.
</span>
</span>
<span class="ltx_bibblock"><a target="_blank" href="https://healthdatainsight.org.uk/project/the-simulacrum/" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://healthdatainsight.org.uk/project/the-simulacrum/</a><span id="bib.bib14.5.1" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.6.1" class="ltx_text" style="font-size:90%;">Accessed: 2019-04-18.
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock"><span id="bib.bib15.1.1" class="ltx_text" style="font-size:90%;">
</span><span id="bib.bib15.2.2" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">Jordon, J., Jarrett, D., Yoon, J., Barnes, T., Elbers, P., Thoral, P.,
Ercole, A., Zhang, C., Belgrave, D., and van¬†der Schaar, M.</span><span id="bib.bib15.3.3" class="ltx_text" style="font-size:90%;">
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.4.1" class="ltx_text" style="font-size:90%;">Hide-and-seek privacy challenge.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.5.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2007.12087</span><span id="bib.bib15.6.2" class="ltx_text" style="font-size:90%;"> (2020).
</span>
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text" style="font-size:90%;">
</span><span id="bib.bib16.2.2" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">Jordon, J., Yoon, J., and van¬†der Schaar, M.</span><span id="bib.bib16.3.3" class="ltx_text" style="font-size:90%;">
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.4.1" class="ltx_text" style="font-size:90%;">KnockoffGAN: Generating knockoffs for feature selection using
generative adversarial networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.5.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib16.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">International Conference on Learning Representations</span><span id="bib.bib16.7.3" class="ltx_text" style="font-size:90%;">
(2019).
</span>
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock"><span id="bib.bib17.1.1" class="ltx_text" style="font-size:90%;">
</span><span id="bib.bib17.2.2" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">Jordon, J., Yoon, J., and van¬†der Schaar, M.</span><span id="bib.bib17.3.3" class="ltx_text" style="font-size:90%;">
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.4.1" class="ltx_text" style="font-size:90%;">PATE-GAN: Generating synthetic data with differential privacy
guarantees.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.5.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib17.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">International Conference on Learning Representations</span><span id="bib.bib17.7.3" class="ltx_text" style="font-size:90%;">
(2019).
</span>
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock"><span id="bib.bib18.1.1" class="ltx_text" style="font-size:90%;">
</span><span id="bib.bib18.2.2" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">Kingma, D.¬†P., and Welling, M.</span><span id="bib.bib18.3.3" class="ltx_text" style="font-size:90%;">
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.4.1" class="ltx_text" style="font-size:90%;">Auto-encoding variational bayes.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.5.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1312.6114</span><span id="bib.bib18.6.2" class="ltx_text" style="font-size:90%;"> (2013).
</span>
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock"><span id="bib.bib19.1.1" class="ltx_text" style="font-size:90%;">
</span><span id="bib.bib19.2.2" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">LeCun, Y., Bengio, Y., and Hinton, G.</span><span id="bib.bib19.3.3" class="ltx_text" style="font-size:90%;">
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.4.1" class="ltx_text" style="font-size:90%;">Deep learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.5.1" class="ltx_text ltx_font_italic" style="font-size:90%;">nature 521</span><span id="bib.bib19.6.2" class="ltx_text" style="font-size:90%;">, 7553 (2015), 436.
</span>
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock"><span id="bib.bib20.1.1" class="ltx_text" style="font-size:90%;">
</span><span id="bib.bib20.2.2" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">Li, N., Qardaji, W., Su, D., Wu, Y., and Yang, W.</span><span id="bib.bib20.3.3" class="ltx_text" style="font-size:90%;">
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.4.1" class="ltx_text" style="font-size:90%;">Membership privacy: a unifying framework for privacy definitions.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.5.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib20.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the 2013 ACM SIGSAC conference on Computer &amp;
communications security</span><span id="bib.bib20.7.3" class="ltx_text" style="font-size:90%;"> (2013), ACM, pp.¬†889‚Äì900.
</span>
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock"><span id="bib.bib21.1.1" class="ltx_text" style="font-size:90%;">
</span><span id="bib.bib21.2.2" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">Malin, B., and Sweeney, L.</span><span id="bib.bib21.3.3" class="ltx_text" style="font-size:90%;">
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.4.1" class="ltx_text" style="font-size:90%;">How (not) to protect genomic data privacy in a distributed network:
using trail re-identification to evaluate and design anonymity protection
systems.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.5.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Journal of biomedical informatics 37</span><span id="bib.bib21.6.2" class="ltx_text" style="font-size:90%;">, 3 (2004), 179‚Äì192.
</span>
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock"><span id="bib.bib22.1.1" class="ltx_text" style="font-size:90%;">
</span><span id="bib.bib22.2.2" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">McLachlan, S., Dube, K., and Gallagher, T.</span><span id="bib.bib22.3.3" class="ltx_text" style="font-size:90%;">
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.4.1" class="ltx_text" style="font-size:90%;">Using the caremap with health incidents statistics for generating the
realistic synthetic electronic healthcare record.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.5.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib22.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Healthcare Informatics (ICHI), 2016 IEEE International
Conference on</span><span id="bib.bib22.7.3" class="ltx_text" style="font-size:90%;"> (2016), IEEE, pp.¬†439‚Äì448.
</span>
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock"><span id="bib.bib23.1.1" class="ltx_text" style="font-size:90%;">
</span><span id="bib.bib23.2.2" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A.¬†A., Veness, J., Bellemare,
M.¬†G., Graves, A., Riedmiller, M., Fidjeland, A.¬†K., Ostrovski, G., et¬†al.</span><span id="bib.bib23.3.3" class="ltx_text" style="font-size:90%;">
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.4.1" class="ltx_text" style="font-size:90%;">Human-level control through deep reinforcement learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.5.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Nature 518</span><span id="bib.bib23.6.2" class="ltx_text" style="font-size:90%;">, 7540 (2015), 529.
</span>
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock"><span id="bib.bib24.1.1" class="ltx_text" style="font-size:90%;">
</span><span id="bib.bib24.2.2" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">Narayanan, A., and Shmatikov, V.</span><span id="bib.bib24.3.3" class="ltx_text" style="font-size:90%;">
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.4.1" class="ltx_text" style="font-size:90%;">Robust de-anonymization of large sparse datasets.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.5.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib24.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Security and Privacy, 2008. SP 2008. IEEE Symposium on</span><span id="bib.bib24.7.3" class="ltx_text" style="font-size:90%;">
(2008), IEEE, pp.¬†111‚Äì125.
</span>
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock"><span id="bib.bib25.1.1" class="ltx_text" style="font-size:90%;">
</span><span id="bib.bib25.2.2" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">Papernot, N., Abadi, M., Erlingsson, U., Goodfellow, I., and Talwar, K.</span><span id="bib.bib25.3.3" class="ltx_text" style="font-size:90%;">
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.4.1" class="ltx_text" style="font-size:90%;">Semi-supervised knowledge transfer for deep learning from private
training data.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.5.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1610.05755</span><span id="bib.bib25.6.2" class="ltx_text" style="font-size:90%;"> (2016).
</span>
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock"><span id="bib.bib26.1.1" class="ltx_text" style="font-size:90%;">
</span><span id="bib.bib26.2.2" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">Papernot, N., Song, S., Mironov, I., Raghunathan, A., Talwar, K., and
Erlingsson, √ö.</span><span id="bib.bib26.3.3" class="ltx_text" style="font-size:90%;">
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.4.1" class="ltx_text" style="font-size:90%;">Scalable private learning with pate.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.5.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1802.08908</span><span id="bib.bib26.6.2" class="ltx_text" style="font-size:90%;"> (2018).
</span>
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock"><span id="bib.bib27.1.1" class="ltx_text" style="font-size:90%;">
</span><span id="bib.bib27.2.2" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">Quionero-Candela, J., Sugiyama, M., Schwaighofer, A., and Lawrence, N.¬†D.</span><span id="bib.bib27.3.3" class="ltx_text" style="font-size:90%;">
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.4.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Dataset Shift in Machine Learning</span><span id="bib.bib27.5.2" class="ltx_text" style="font-size:90%;">.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.6.1" class="ltx_text" style="font-size:90%;">The MIT Press, 2009.
</span>
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock"><span id="bib.bib28.1.1" class="ltx_text" style="font-size:90%;">
</span><span id="bib.bib28.2.2" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">Sweeney, L.</span><span id="bib.bib28.3.3" class="ltx_text" style="font-size:90%;">
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.4.1" class="ltx_text" style="font-size:90%;">Weaving technology and policy together to maintain confidentiality.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.5.1" class="ltx_text ltx_font_italic" style="font-size:90%;">The Journal of Law, Medicine &amp; Ethics 25</span><span id="bib.bib28.6.2" class="ltx_text" style="font-size:90%;">, 2-3 (1997), 98‚Äì110.
</span>
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock"><span id="bib.bib29.1.1" class="ltx_text" style="font-size:90%;">
</span><span id="bib.bib29.2.2" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">Xie, L., Lin, K., Wang, S., Wang, F., and Zhou, J.</span><span id="bib.bib29.3.3" class="ltx_text" style="font-size:90%;">
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.4.1" class="ltx_text" style="font-size:90%;">Differentially private generative adversarial network.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.5.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1802.06739</span><span id="bib.bib29.6.2" class="ltx_text" style="font-size:90%;"> (2018).
</span>
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock"><span id="bib.bib30.1.1" class="ltx_text" style="font-size:90%;">
</span><span id="bib.bib30.2.2" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">Yoon, J., Drumright, L., and van¬†der Schaar, M.</span><span id="bib.bib30.3.3" class="ltx_text" style="font-size:90%;">
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.4.1" class="ltx_text" style="font-size:90%;">Anonymization through data synthesis using generative adversarial
networks (ADS-GAN): A harmonizing advancement for AI in medicine.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.5.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Submitted</span><span id="bib.bib30.6.2" class="ltx_text" style="font-size:90%;"> (2019).
</span>
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock"><span id="bib.bib31.1.1" class="ltx_text" style="font-size:90%;">
</span><span id="bib.bib31.2.2" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">Yoon, J., Jordon, J., and van¬†der Schaar, M.</span><span id="bib.bib31.3.3" class="ltx_text" style="font-size:90%;">
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.4.1" class="ltx_text" style="font-size:90%;">GANITE: Estimation of individualized treatment effects using
generative adversarial nets.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.5.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib31.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">International Conference on Learning Representations</span><span id="bib.bib31.7.3" class="ltx_text" style="font-size:90%;">
(2018).
</span>
</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock"><span id="bib.bib32.1.1" class="ltx_text" style="font-size:90%;">
</span><span id="bib.bib32.2.2" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">Yoon, J., Jordon, J., and van¬†der Schaar, M.</span><span id="bib.bib32.3.3" class="ltx_text" style="font-size:90%;">
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.4.1" class="ltx_text" style="font-size:90%;">ASAC: Active sensing using actor-critic models.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.5.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Submitted</span><span id="bib.bib32.6.2" class="ltx_text" style="font-size:90%;"> (2019).
</span>
</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock"><span id="bib.bib33.1.1" class="ltx_text" style="font-size:90%;">
</span><span id="bib.bib33.2.2" class="ltx_text ltx_font_smallcaps" style="font-size:90%;">Yoon, J., Jordon, J., and van¬†der Schaar, M.</span><span id="bib.bib33.3.3" class="ltx_text" style="font-size:90%;">
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.4.1" class="ltx_text" style="font-size:90%;">INVASE: Instance-wise variable selection using neural networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.5.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib33.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">International Conference on Learning Representations</span><span id="bib.bib33.7.3" class="ltx_text" style="font-size:90%;">
(2019).
</span>
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<div id="p1" class="ltx_para">
<p id="p1.1" class="ltx_p"></p>
</div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2012.04579" class="ar5iv-nav-button ar5iv-nav-button-prev">‚óÑ</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2012.04580" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2012.04580">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2012.04580" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2012.04581" class="ar5iv-nav-button ar5iv-nav-button-next">‚ñ∫</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Mar  7 02:18:31 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "√ó";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
