<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[1803.07724] Attention on Attention: Architectures for Visual Question Answering (VQA)</title><meta property="og:description" content="Visual Question Answering (VQA) is an increasingly popular topic in deep learning research, requiring coordination of natural language processing and computer vision modules into a single architecture. We build upon thâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Attention on Attention: Architectures for Visual Question Answering (VQA)">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Attention on Attention: Architectures for Visual Question Answering (VQA)">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/1803.07724">

<!--Generated on Sun Mar  3 10:58:22 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Attention on Attention: Architectures for Visual Question Answering (VQA)</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Jasdeep Singh 
<br class="ltx_break">Stanford University
<br class="ltx_break"><span id="id1.1.id1" class="ltx_text ltx_font_typewriter">jasdeep@stanford.edu</span> 
<br class="ltx_break"><span id="id2.2.id2" class="ltx_ERROR undefined">\And</span>Vincent Ying 
<br class="ltx_break">Stanford University
<br class="ltx_break"><span id="id3.3.id3" class="ltx_text ltx_font_typewriter">vhying@stanford.edu</span> 
<br class="ltx_break"><span id="id4.4.id4" class="ltx_ERROR undefined">\And</span>Alex Nutkiewicz 
<br class="ltx_break">Stanford University
<br class="ltx_break"><span id="id5.5.id5" class="ltx_text ltx_font_typewriter">alexer@stanford.edu</span> 
<br class="ltx_break">
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id6.id1" class="ltx_p">Visual Question Answering (VQA) is an increasingly popular topic in deep learning research, requiring coordination of natural language processing and computer vision modules into a single architecture. We build upon the model which placed first in the VQA Challenge by developing thirteen new attention mechanisms and introducing a simplified classifier. We performed 300 GPU hours of extensive hyperparameter and architecture searches and were able to achieve an evaluation score of 64.78%, outperforming the existing state-of-the-art single modelâ€™s validation score of 63.15%. The code is available at <a target="_blank" href="https://github.com/SinghJasdeep/Attention-on-Attention-for-VQA" title="" class="ltx_ref ltx_href"><span id="id6.id1.1.1" class="ltx_text ltx_font_slanted">github.com/SinghJasdeep/Attention-on-Attention-for-VQA</span>.</a></p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para ltx_noindent">
<p id="S1.p1.1" class="ltx_p">Visual Question Answering (VQA) is an increasingly popular topic in deep learning research as it requires coordination of several artificial intelligence-related disciplines, including Computer Vision and Natural Language Processing. Due to its growing popularity, last year (2017) a version 2 of the VQA Challenge was initiated. Due to VQAâ€™s relative complexity and need for fine grained visual and textual processing, many intricate and highly tuned architectures led performance. We chose to build upon the relatively simple model proposed by last yearâ€™s winners <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx6" title="" class="ltx_ref">TAHvdH17</a>]</cite> to investigate the role of attention and ways to improve performance.</p>
</div>
<div id="S1.p2" class="ltx_para ltx_noindent">
<p id="S1.p2.1" class="ltx_p">At a high level, VQA models require two forms of information: text and images. The inputs to a VQA model are images and free-form, open-ended natural language questions about the image, and the modelâ€™s goal is to produce a natural language answer about the input <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx1" title="" class="ltx_ref">AAL<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>15</a>]</cite>. We use pre-trained GloVe vectors and a GRU over tokenized questions to produce question embeddings, and a Faster R-CNN to generate objects centric features from the images. This information is then passed through an attention module to create a joint embedding of the image-question and the joint embedding is then passed through a classifier to produce the final answer.</p>
</div>
<div id="S1.p3" class="ltx_para ltx_noindent">
<p id="S1.p3.1" class="ltx_p">Our project aims to investigate previous methods of implementing VQA and to better understand the characteristics of more successful network architectures for this task. We build upon previous iterations of winning VQA Challenge models by developing thirteen attention mechanisms and introducing a simplified classifier to the model. We evaluate our model against other VQA implementations via an evaluation metric used in the VQA Challenge and are able to beat the 2017 VQA Challenge winners best single model scores.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<div id="S2.p1" class="ltx_para ltx_noindent">
<p id="S2.p1.1" class="ltx_p">VQA has been a rapidly growing research topic since the introduction of the seminal paper by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx1" title="" class="ltx_ref">AAL<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>15</a>]</cite>, largely because of its interdisciplinary nature. VQA problems require the model to understand a text-based question, identify elements of an image, and evaluate how these two inputs relate to one another. Much of the progress in VQA parallels developments made in other problems, such as image captioning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx8" title="" class="ltx_ref">XBK<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>15</a>]</cite>
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx7" title="" class="ltx_ref">VTBE16</a>]</cite> and textual question answering
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx4" title="" class="ltx_ref">KIS<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>15</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx9" title="" class="ltx_ref">XMS16</a>]</cite>.</p>
</div>
<div id="S2.p2" class="ltx_para ltx_noindent">
<p id="S2.p2.1" class="ltx_p">The primary method to approach VQA tasks is based on three subcomponents: creating representations for the image and question; passing these inputs through a neural network to create a co-dependent embedding; and then generating the correct natural language response. Past work by <span id="S2.p2.1.1" class="ltx_text ltx_font_bold">Xiong et al.</span> has investigated several improvements to the input modules of dynamic memory networks (DMN), which were originally developed for textual question answering, in order to show that a basic DMN architecture could be utilized for visual question answering. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx9" title="" class="ltx_ref">XMS16</a>]</cite> However, since then model architectures for visual and textual question answering have been specializing to their domains. With the models for visual question answering preferring more and more sophisticated single pass attention mechanisms. In a related paper â€Show, Attend and Tell: Neural image caption generation with visual attention,â€ <span id="S2.p2.1.2" class="ltx_text ltx_font_bold">Xu et al.</span> introduced an attention based model that learned to describe the content of images using two different attention modules: stochastic â€hardâ€ attention and deterministic â€softâ€ attention. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx8" title="" class="ltx_ref">XBK<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>15</a>]</cite></p>
</div>
<div id="S2.p3" class="ltx_para ltx_noindent">
<p id="S2.p3.1" class="ltx_p">The current state-of-the-art model in VQA was developed by <span id="S2.p3.1.1" class="ltx_text ltx_font_bold">Teney et al.</span> for the 2017 VQA Challenge, in which they show how very simple, interpretable models can achieve strong performance. Their experiments show the significance of carefully designing image features, attention mechanisms (bottom-up and top-down), gated activations, and output embeddings on model performance.
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx6" title="" class="ltx_ref">TAHvdH17</a>]</cite></p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Datasets</h2>

<div id="S3.p1" class="ltx_para ltx_noindent">
<p id="S3.p1.1" class="ltx_p">While many large-scale datasets have been developed for the application of VQA, we decided to utilize the VQA v2.0 dataset, which contains over 200,000 images, over 1 million questions and over 11 million answers and at least three questions per image preventing the model from inferring the question without considering the input image <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx3" title="" class="ltx_ref">GKSS<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>17</a>]</cite>. With this data, we do the following preprocessing:</p>
<ul id="S3.I1" class="ltx_itemize">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.p1.1" class="ltx_p">Training questions and answers are tokenized and then trimmed/padded to a maximum length of 14 words. These tokens are then represented using 300-dimentional pre-trained Wikipedia+Gigaword GloVe word embeddings <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx5" title="" class="ltx_ref">PSM14</a>]</cite>.</p>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S3.I1.i2.p1" class="ltx_para ltx_noindent">
<p id="S3.I1.i2.p1.1" class="ltx_p">Thirty six features per image are created via passing the VQA v2.0 images through a Faster R-CNN, with bottom-up attention, as proposed by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx2" title="" class="ltx_ref">AHB<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">+</span></sup>17</a>]</cite>. The Faster R-CNN detects object centric elements in the input image. This CNN is pre-trained and is held fixed during the training of the VQA model. All images are pre-converted to Faster R-CNN features for efficiency purposes.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Methodology</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">Our proposed model (Figure 1) derives inspiration from the winning architecture developed by <span id="S4.p1.1.1" class="ltx_text ltx_font_bold">Teney et al.</span> for the 2017 VQA Challenge. The model implements a joint RNN/CNN for question and image embeddings, respectively. It then uses top-down attention, guided by the question embedding, on the image embeddings. The model inputs are preprocessed GloVe embeddings and Faster R-CNN feature vectors as discussed in Section 3.</p>
</div>
<figure id="S4.F1" class="ltx_figure"><img src="/html/1803.07724/assets/VQA_Architecture.png" id="S4.F1.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="548" height="346" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Visual representation of VQA model architecture and attention modules. The specifics of each attention module are described in the text but A3x2 performed the best out of all the modules architectures investigated.</figcaption>
</figure>
<div id="S4.p2" class="ltx_para ltx_noindent">
<p id="S4.p2.3" class="ltx_p">As stated in Section 3, the question inputs are tokenized and represented using GloVe word embeddings. They are then passed through a GRU to create the final question embedding. The image feature vectors along with this question embedding of size number-of-hidden-units (1280) are then passed into the dual one-way top-down attention module (A3x2). This module computes the the relevance of each of the 36 image vectors (corresponding to 36 different objects determined by the faster R-CNN) to the current question embedding using the following equations.</p>
<table id="S4.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E1.m1.3" class="ltx_Math" alttext="a_{i}=\ wf_{c}(f_{a}(\hat{i})\circ f_{b}(\hat{q}))+b" display="block"><semantics id="S4.E1.m1.3a"><mrow id="S4.E1.m1.3.3" xref="S4.E1.m1.3.3.cmml"><msub id="S4.E1.m1.3.3.3" xref="S4.E1.m1.3.3.3.cmml"><mi id="S4.E1.m1.3.3.3.2" xref="S4.E1.m1.3.3.3.2.cmml">a</mi><mi id="S4.E1.m1.3.3.3.3" xref="S4.E1.m1.3.3.3.3.cmml">i</mi></msub><mo rspace="0.778em" id="S4.E1.m1.3.3.2" xref="S4.E1.m1.3.3.2.cmml">=</mo><mrow id="S4.E1.m1.3.3.1" xref="S4.E1.m1.3.3.1.cmml"><mrow id="S4.E1.m1.3.3.1.1" xref="S4.E1.m1.3.3.1.1.cmml"><mi id="S4.E1.m1.3.3.1.1.3" xref="S4.E1.m1.3.3.1.1.3.cmml">w</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.3.3.1.1.2" xref="S4.E1.m1.3.3.1.1.2.cmml">â€‹</mo><msub id="S4.E1.m1.3.3.1.1.4" xref="S4.E1.m1.3.3.1.1.4.cmml"><mi id="S4.E1.m1.3.3.1.1.4.2" xref="S4.E1.m1.3.3.1.1.4.2.cmml">f</mi><mi id="S4.E1.m1.3.3.1.1.4.3" xref="S4.E1.m1.3.3.1.1.4.3.cmml">c</mi></msub><mo lspace="0em" rspace="0em" id="S4.E1.m1.3.3.1.1.2a" xref="S4.E1.m1.3.3.1.1.2.cmml">â€‹</mo><mrow id="S4.E1.m1.3.3.1.1.1.1" xref="S4.E1.m1.3.3.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.E1.m1.3.3.1.1.1.1.2" xref="S4.E1.m1.3.3.1.1.1.1.1.cmml">(</mo><mrow id="S4.E1.m1.3.3.1.1.1.1.1" xref="S4.E1.m1.3.3.1.1.1.1.1.cmml"><mrow id="S4.E1.m1.3.3.1.1.1.1.1.2" xref="S4.E1.m1.3.3.1.1.1.1.1.2.cmml"><mrow id="S4.E1.m1.3.3.1.1.1.1.1.2.2" xref="S4.E1.m1.3.3.1.1.1.1.1.2.2.cmml"><msub id="S4.E1.m1.3.3.1.1.1.1.1.2.2.2" xref="S4.E1.m1.3.3.1.1.1.1.1.2.2.2.cmml"><mi id="S4.E1.m1.3.3.1.1.1.1.1.2.2.2.2" xref="S4.E1.m1.3.3.1.1.1.1.1.2.2.2.2.cmml">f</mi><mi id="S4.E1.m1.3.3.1.1.1.1.1.2.2.2.3" xref="S4.E1.m1.3.3.1.1.1.1.1.2.2.2.3.cmml">a</mi></msub><mo lspace="0em" rspace="0em" id="S4.E1.m1.3.3.1.1.1.1.1.2.2.1" xref="S4.E1.m1.3.3.1.1.1.1.1.2.2.1.cmml">â€‹</mo><mrow id="S4.E1.m1.3.3.1.1.1.1.1.2.2.3.2" xref="S4.E1.m1.1.1.cmml"><mo stretchy="false" id="S4.E1.m1.3.3.1.1.1.1.1.2.2.3.2.1" xref="S4.E1.m1.1.1.cmml">(</mo><mover accent="true" id="S4.E1.m1.1.1" xref="S4.E1.m1.1.1.cmml"><mi id="S4.E1.m1.1.1.2" xref="S4.E1.m1.1.1.2.cmml">i</mi><mo id="S4.E1.m1.1.1.1" xref="S4.E1.m1.1.1.1.cmml">^</mo></mover><mo rspace="0.055em" stretchy="false" id="S4.E1.m1.3.3.1.1.1.1.1.2.2.3.2.2" xref="S4.E1.m1.1.1.cmml">)</mo></mrow></mrow><mo rspace="0.222em" id="S4.E1.m1.3.3.1.1.1.1.1.2.1" xref="S4.E1.m1.3.3.1.1.1.1.1.2.1.cmml">âˆ˜</mo><msub id="S4.E1.m1.3.3.1.1.1.1.1.2.3" xref="S4.E1.m1.3.3.1.1.1.1.1.2.3.cmml"><mi id="S4.E1.m1.3.3.1.1.1.1.1.2.3.2" xref="S4.E1.m1.3.3.1.1.1.1.1.2.3.2.cmml">f</mi><mi id="S4.E1.m1.3.3.1.1.1.1.1.2.3.3" xref="S4.E1.m1.3.3.1.1.1.1.1.2.3.3.cmml">b</mi></msub></mrow><mo lspace="0em" rspace="0em" id="S4.E1.m1.3.3.1.1.1.1.1.1" xref="S4.E1.m1.3.3.1.1.1.1.1.1.cmml">â€‹</mo><mrow id="S4.E1.m1.3.3.1.1.1.1.1.3.2" xref="S4.E1.m1.2.2.cmml"><mo stretchy="false" id="S4.E1.m1.3.3.1.1.1.1.1.3.2.1" xref="S4.E1.m1.2.2.cmml">(</mo><mover accent="true" id="S4.E1.m1.2.2" xref="S4.E1.m1.2.2.cmml"><mi id="S4.E1.m1.2.2.2" xref="S4.E1.m1.2.2.2.cmml">q</mi><mo id="S4.E1.m1.2.2.1" xref="S4.E1.m1.2.2.1.cmml">^</mo></mover><mo stretchy="false" id="S4.E1.m1.3.3.1.1.1.1.1.3.2.2" xref="S4.E1.m1.2.2.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S4.E1.m1.3.3.1.1.1.1.3" xref="S4.E1.m1.3.3.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S4.E1.m1.3.3.1.2" xref="S4.E1.m1.3.3.1.2.cmml">+</mo><mi id="S4.E1.m1.3.3.1.3" xref="S4.E1.m1.3.3.1.3.cmml">b</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E1.m1.3b"><apply id="S4.E1.m1.3.3.cmml" xref="S4.E1.m1.3.3"><eq id="S4.E1.m1.3.3.2.cmml" xref="S4.E1.m1.3.3.2"></eq><apply id="S4.E1.m1.3.3.3.cmml" xref="S4.E1.m1.3.3.3"><csymbol cd="ambiguous" id="S4.E1.m1.3.3.3.1.cmml" xref="S4.E1.m1.3.3.3">subscript</csymbol><ci id="S4.E1.m1.3.3.3.2.cmml" xref="S4.E1.m1.3.3.3.2">ğ‘</ci><ci id="S4.E1.m1.3.3.3.3.cmml" xref="S4.E1.m1.3.3.3.3">ğ‘–</ci></apply><apply id="S4.E1.m1.3.3.1.cmml" xref="S4.E1.m1.3.3.1"><plus id="S4.E1.m1.3.3.1.2.cmml" xref="S4.E1.m1.3.3.1.2"></plus><apply id="S4.E1.m1.3.3.1.1.cmml" xref="S4.E1.m1.3.3.1.1"><times id="S4.E1.m1.3.3.1.1.2.cmml" xref="S4.E1.m1.3.3.1.1.2"></times><ci id="S4.E1.m1.3.3.1.1.3.cmml" xref="S4.E1.m1.3.3.1.1.3">ğ‘¤</ci><apply id="S4.E1.m1.3.3.1.1.4.cmml" xref="S4.E1.m1.3.3.1.1.4"><csymbol cd="ambiguous" id="S4.E1.m1.3.3.1.1.4.1.cmml" xref="S4.E1.m1.3.3.1.1.4">subscript</csymbol><ci id="S4.E1.m1.3.3.1.1.4.2.cmml" xref="S4.E1.m1.3.3.1.1.4.2">ğ‘“</ci><ci id="S4.E1.m1.3.3.1.1.4.3.cmml" xref="S4.E1.m1.3.3.1.1.4.3">ğ‘</ci></apply><apply id="S4.E1.m1.3.3.1.1.1.1.1.cmml" xref="S4.E1.m1.3.3.1.1.1.1"><times id="S4.E1.m1.3.3.1.1.1.1.1.1.cmml" xref="S4.E1.m1.3.3.1.1.1.1.1.1"></times><apply id="S4.E1.m1.3.3.1.1.1.1.1.2.cmml" xref="S4.E1.m1.3.3.1.1.1.1.1.2"><compose id="S4.E1.m1.3.3.1.1.1.1.1.2.1.cmml" xref="S4.E1.m1.3.3.1.1.1.1.1.2.1"></compose><apply id="S4.E1.m1.3.3.1.1.1.1.1.2.2.cmml" xref="S4.E1.m1.3.3.1.1.1.1.1.2.2"><times id="S4.E1.m1.3.3.1.1.1.1.1.2.2.1.cmml" xref="S4.E1.m1.3.3.1.1.1.1.1.2.2.1"></times><apply id="S4.E1.m1.3.3.1.1.1.1.1.2.2.2.cmml" xref="S4.E1.m1.3.3.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S4.E1.m1.3.3.1.1.1.1.1.2.2.2.1.cmml" xref="S4.E1.m1.3.3.1.1.1.1.1.2.2.2">subscript</csymbol><ci id="S4.E1.m1.3.3.1.1.1.1.1.2.2.2.2.cmml" xref="S4.E1.m1.3.3.1.1.1.1.1.2.2.2.2">ğ‘“</ci><ci id="S4.E1.m1.3.3.1.1.1.1.1.2.2.2.3.cmml" xref="S4.E1.m1.3.3.1.1.1.1.1.2.2.2.3">ğ‘</ci></apply><apply id="S4.E1.m1.1.1.cmml" xref="S4.E1.m1.3.3.1.1.1.1.1.2.2.3.2"><ci id="S4.E1.m1.1.1.1.cmml" xref="S4.E1.m1.1.1.1">^</ci><ci id="S4.E1.m1.1.1.2.cmml" xref="S4.E1.m1.1.1.2">ğ‘–</ci></apply></apply><apply id="S4.E1.m1.3.3.1.1.1.1.1.2.3.cmml" xref="S4.E1.m1.3.3.1.1.1.1.1.2.3"><csymbol cd="ambiguous" id="S4.E1.m1.3.3.1.1.1.1.1.2.3.1.cmml" xref="S4.E1.m1.3.3.1.1.1.1.1.2.3">subscript</csymbol><ci id="S4.E1.m1.3.3.1.1.1.1.1.2.3.2.cmml" xref="S4.E1.m1.3.3.1.1.1.1.1.2.3.2">ğ‘“</ci><ci id="S4.E1.m1.3.3.1.1.1.1.1.2.3.3.cmml" xref="S4.E1.m1.3.3.1.1.1.1.1.2.3.3">ğ‘</ci></apply></apply><apply id="S4.E1.m1.2.2.cmml" xref="S4.E1.m1.3.3.1.1.1.1.1.3.2"><ci id="S4.E1.m1.2.2.1.cmml" xref="S4.E1.m1.2.2.1">^</ci><ci id="S4.E1.m1.2.2.2.cmml" xref="S4.E1.m1.2.2.2">ğ‘</ci></apply></apply></apply><ci id="S4.E1.m1.3.3.1.3.cmml" xref="S4.E1.m1.3.3.1.3">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E1.m1.3c">a_{i}=\ wf_{c}(f_{a}(\hat{i})\circ f_{b}(\hat{q}))+b</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<table id="S4.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E2.m1.3" class="ltx_Math" alttext="a_{i}^{\prime}=\ w^{\prime}f_{c^{\prime}}(f_{a^{\prime}}(\hat{i})\circ f_{b^{\prime}}(\hat{q}))+b^{\prime}" display="block"><semantics id="S4.E2.m1.3a"><mrow id="S4.E2.m1.3.3" xref="S4.E2.m1.3.3.cmml"><msubsup id="S4.E2.m1.3.3.3" xref="S4.E2.m1.3.3.3.cmml"><mi id="S4.E2.m1.3.3.3.2.2" xref="S4.E2.m1.3.3.3.2.2.cmml">a</mi><mi id="S4.E2.m1.3.3.3.2.3" xref="S4.E2.m1.3.3.3.2.3.cmml">i</mi><mo id="S4.E2.m1.3.3.3.3" xref="S4.E2.m1.3.3.3.3.cmml">â€²</mo></msubsup><mo rspace="0.778em" id="S4.E2.m1.3.3.2" xref="S4.E2.m1.3.3.2.cmml">=</mo><mrow id="S4.E2.m1.3.3.1" xref="S4.E2.m1.3.3.1.cmml"><mrow id="S4.E2.m1.3.3.1.1" xref="S4.E2.m1.3.3.1.1.cmml"><msup id="S4.E2.m1.3.3.1.1.3" xref="S4.E2.m1.3.3.1.1.3.cmml"><mi id="S4.E2.m1.3.3.1.1.3.2" xref="S4.E2.m1.3.3.1.1.3.2.cmml">w</mi><mo id="S4.E2.m1.3.3.1.1.3.3" xref="S4.E2.m1.3.3.1.1.3.3.cmml">â€²</mo></msup><mo lspace="0em" rspace="0em" id="S4.E2.m1.3.3.1.1.2" xref="S4.E2.m1.3.3.1.1.2.cmml">â€‹</mo><msub id="S4.E2.m1.3.3.1.1.4" xref="S4.E2.m1.3.3.1.1.4.cmml"><mi id="S4.E2.m1.3.3.1.1.4.2" xref="S4.E2.m1.3.3.1.1.4.2.cmml">f</mi><msup id="S4.E2.m1.3.3.1.1.4.3" xref="S4.E2.m1.3.3.1.1.4.3.cmml"><mi id="S4.E2.m1.3.3.1.1.4.3.2" xref="S4.E2.m1.3.3.1.1.4.3.2.cmml">c</mi><mo id="S4.E2.m1.3.3.1.1.4.3.3" xref="S4.E2.m1.3.3.1.1.4.3.3.cmml">â€²</mo></msup></msub><mo lspace="0em" rspace="0em" id="S4.E2.m1.3.3.1.1.2a" xref="S4.E2.m1.3.3.1.1.2.cmml">â€‹</mo><mrow id="S4.E2.m1.3.3.1.1.1.1" xref="S4.E2.m1.3.3.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.E2.m1.3.3.1.1.1.1.2" xref="S4.E2.m1.3.3.1.1.1.1.1.cmml">(</mo><mrow id="S4.E2.m1.3.3.1.1.1.1.1" xref="S4.E2.m1.3.3.1.1.1.1.1.cmml"><mrow id="S4.E2.m1.3.3.1.1.1.1.1.2" xref="S4.E2.m1.3.3.1.1.1.1.1.2.cmml"><mrow id="S4.E2.m1.3.3.1.1.1.1.1.2.2" xref="S4.E2.m1.3.3.1.1.1.1.1.2.2.cmml"><msub id="S4.E2.m1.3.3.1.1.1.1.1.2.2.2" xref="S4.E2.m1.3.3.1.1.1.1.1.2.2.2.cmml"><mi id="S4.E2.m1.3.3.1.1.1.1.1.2.2.2.2" xref="S4.E2.m1.3.3.1.1.1.1.1.2.2.2.2.cmml">f</mi><msup id="S4.E2.m1.3.3.1.1.1.1.1.2.2.2.3" xref="S4.E2.m1.3.3.1.1.1.1.1.2.2.2.3.cmml"><mi id="S4.E2.m1.3.3.1.1.1.1.1.2.2.2.3.2" xref="S4.E2.m1.3.3.1.1.1.1.1.2.2.2.3.2.cmml">a</mi><mo id="S4.E2.m1.3.3.1.1.1.1.1.2.2.2.3.3" xref="S4.E2.m1.3.3.1.1.1.1.1.2.2.2.3.3.cmml">â€²</mo></msup></msub><mo lspace="0em" rspace="0em" id="S4.E2.m1.3.3.1.1.1.1.1.2.2.1" xref="S4.E2.m1.3.3.1.1.1.1.1.2.2.1.cmml">â€‹</mo><mrow id="S4.E2.m1.3.3.1.1.1.1.1.2.2.3.2" xref="S4.E2.m1.1.1.cmml"><mo stretchy="false" id="S4.E2.m1.3.3.1.1.1.1.1.2.2.3.2.1" xref="S4.E2.m1.1.1.cmml">(</mo><mover accent="true" id="S4.E2.m1.1.1" xref="S4.E2.m1.1.1.cmml"><mi id="S4.E2.m1.1.1.2" xref="S4.E2.m1.1.1.2.cmml">i</mi><mo id="S4.E2.m1.1.1.1" xref="S4.E2.m1.1.1.1.cmml">^</mo></mover><mo rspace="0.055em" stretchy="false" id="S4.E2.m1.3.3.1.1.1.1.1.2.2.3.2.2" xref="S4.E2.m1.1.1.cmml">)</mo></mrow></mrow><mo rspace="0.222em" id="S4.E2.m1.3.3.1.1.1.1.1.2.1" xref="S4.E2.m1.3.3.1.1.1.1.1.2.1.cmml">âˆ˜</mo><msub id="S4.E2.m1.3.3.1.1.1.1.1.2.3" xref="S4.E2.m1.3.3.1.1.1.1.1.2.3.cmml"><mi id="S4.E2.m1.3.3.1.1.1.1.1.2.3.2" xref="S4.E2.m1.3.3.1.1.1.1.1.2.3.2.cmml">f</mi><msup id="S4.E2.m1.3.3.1.1.1.1.1.2.3.3" xref="S4.E2.m1.3.3.1.1.1.1.1.2.3.3.cmml"><mi id="S4.E2.m1.3.3.1.1.1.1.1.2.3.3.2" xref="S4.E2.m1.3.3.1.1.1.1.1.2.3.3.2.cmml">b</mi><mo id="S4.E2.m1.3.3.1.1.1.1.1.2.3.3.3" xref="S4.E2.m1.3.3.1.1.1.1.1.2.3.3.3.cmml">â€²</mo></msup></msub></mrow><mo lspace="0em" rspace="0em" id="S4.E2.m1.3.3.1.1.1.1.1.1" xref="S4.E2.m1.3.3.1.1.1.1.1.1.cmml">â€‹</mo><mrow id="S4.E2.m1.3.3.1.1.1.1.1.3.2" xref="S4.E2.m1.2.2.cmml"><mo stretchy="false" id="S4.E2.m1.3.3.1.1.1.1.1.3.2.1" xref="S4.E2.m1.2.2.cmml">(</mo><mover accent="true" id="S4.E2.m1.2.2" xref="S4.E2.m1.2.2.cmml"><mi id="S4.E2.m1.2.2.2" xref="S4.E2.m1.2.2.2.cmml">q</mi><mo id="S4.E2.m1.2.2.1" xref="S4.E2.m1.2.2.1.cmml">^</mo></mover><mo stretchy="false" id="S4.E2.m1.3.3.1.1.1.1.1.3.2.2" xref="S4.E2.m1.2.2.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S4.E2.m1.3.3.1.1.1.1.3" xref="S4.E2.m1.3.3.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S4.E2.m1.3.3.1.2" xref="S4.E2.m1.3.3.1.2.cmml">+</mo><msup id="S4.E2.m1.3.3.1.3" xref="S4.E2.m1.3.3.1.3.cmml"><mi id="S4.E2.m1.3.3.1.3.2" xref="S4.E2.m1.3.3.1.3.2.cmml">b</mi><mo id="S4.E2.m1.3.3.1.3.3" xref="S4.E2.m1.3.3.1.3.3.cmml">â€²</mo></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E2.m1.3b"><apply id="S4.E2.m1.3.3.cmml" xref="S4.E2.m1.3.3"><eq id="S4.E2.m1.3.3.2.cmml" xref="S4.E2.m1.3.3.2"></eq><apply id="S4.E2.m1.3.3.3.cmml" xref="S4.E2.m1.3.3.3"><csymbol cd="ambiguous" id="S4.E2.m1.3.3.3.1.cmml" xref="S4.E2.m1.3.3.3">superscript</csymbol><apply id="S4.E2.m1.3.3.3.2.cmml" xref="S4.E2.m1.3.3.3"><csymbol cd="ambiguous" id="S4.E2.m1.3.3.3.2.1.cmml" xref="S4.E2.m1.3.3.3">subscript</csymbol><ci id="S4.E2.m1.3.3.3.2.2.cmml" xref="S4.E2.m1.3.3.3.2.2">ğ‘</ci><ci id="S4.E2.m1.3.3.3.2.3.cmml" xref="S4.E2.m1.3.3.3.2.3">ğ‘–</ci></apply><ci id="S4.E2.m1.3.3.3.3.cmml" xref="S4.E2.m1.3.3.3.3">â€²</ci></apply><apply id="S4.E2.m1.3.3.1.cmml" xref="S4.E2.m1.3.3.1"><plus id="S4.E2.m1.3.3.1.2.cmml" xref="S4.E2.m1.3.3.1.2"></plus><apply id="S4.E2.m1.3.3.1.1.cmml" xref="S4.E2.m1.3.3.1.1"><times id="S4.E2.m1.3.3.1.1.2.cmml" xref="S4.E2.m1.3.3.1.1.2"></times><apply id="S4.E2.m1.3.3.1.1.3.cmml" xref="S4.E2.m1.3.3.1.1.3"><csymbol cd="ambiguous" id="S4.E2.m1.3.3.1.1.3.1.cmml" xref="S4.E2.m1.3.3.1.1.3">superscript</csymbol><ci id="S4.E2.m1.3.3.1.1.3.2.cmml" xref="S4.E2.m1.3.3.1.1.3.2">ğ‘¤</ci><ci id="S4.E2.m1.3.3.1.1.3.3.cmml" xref="S4.E2.m1.3.3.1.1.3.3">â€²</ci></apply><apply id="S4.E2.m1.3.3.1.1.4.cmml" xref="S4.E2.m1.3.3.1.1.4"><csymbol cd="ambiguous" id="S4.E2.m1.3.3.1.1.4.1.cmml" xref="S4.E2.m1.3.3.1.1.4">subscript</csymbol><ci id="S4.E2.m1.3.3.1.1.4.2.cmml" xref="S4.E2.m1.3.3.1.1.4.2">ğ‘“</ci><apply id="S4.E2.m1.3.3.1.1.4.3.cmml" xref="S4.E2.m1.3.3.1.1.4.3"><csymbol cd="ambiguous" id="S4.E2.m1.3.3.1.1.4.3.1.cmml" xref="S4.E2.m1.3.3.1.1.4.3">superscript</csymbol><ci id="S4.E2.m1.3.3.1.1.4.3.2.cmml" xref="S4.E2.m1.3.3.1.1.4.3.2">ğ‘</ci><ci id="S4.E2.m1.3.3.1.1.4.3.3.cmml" xref="S4.E2.m1.3.3.1.1.4.3.3">â€²</ci></apply></apply><apply id="S4.E2.m1.3.3.1.1.1.1.1.cmml" xref="S4.E2.m1.3.3.1.1.1.1"><times id="S4.E2.m1.3.3.1.1.1.1.1.1.cmml" xref="S4.E2.m1.3.3.1.1.1.1.1.1"></times><apply id="S4.E2.m1.3.3.1.1.1.1.1.2.cmml" xref="S4.E2.m1.3.3.1.1.1.1.1.2"><compose id="S4.E2.m1.3.3.1.1.1.1.1.2.1.cmml" xref="S4.E2.m1.3.3.1.1.1.1.1.2.1"></compose><apply id="S4.E2.m1.3.3.1.1.1.1.1.2.2.cmml" xref="S4.E2.m1.3.3.1.1.1.1.1.2.2"><times id="S4.E2.m1.3.3.1.1.1.1.1.2.2.1.cmml" xref="S4.E2.m1.3.3.1.1.1.1.1.2.2.1"></times><apply id="S4.E2.m1.3.3.1.1.1.1.1.2.2.2.cmml" xref="S4.E2.m1.3.3.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S4.E2.m1.3.3.1.1.1.1.1.2.2.2.1.cmml" xref="S4.E2.m1.3.3.1.1.1.1.1.2.2.2">subscript</csymbol><ci id="S4.E2.m1.3.3.1.1.1.1.1.2.2.2.2.cmml" xref="S4.E2.m1.3.3.1.1.1.1.1.2.2.2.2">ğ‘“</ci><apply id="S4.E2.m1.3.3.1.1.1.1.1.2.2.2.3.cmml" xref="S4.E2.m1.3.3.1.1.1.1.1.2.2.2.3"><csymbol cd="ambiguous" id="S4.E2.m1.3.3.1.1.1.1.1.2.2.2.3.1.cmml" xref="S4.E2.m1.3.3.1.1.1.1.1.2.2.2.3">superscript</csymbol><ci id="S4.E2.m1.3.3.1.1.1.1.1.2.2.2.3.2.cmml" xref="S4.E2.m1.3.3.1.1.1.1.1.2.2.2.3.2">ğ‘</ci><ci id="S4.E2.m1.3.3.1.1.1.1.1.2.2.2.3.3.cmml" xref="S4.E2.m1.3.3.1.1.1.1.1.2.2.2.3.3">â€²</ci></apply></apply><apply id="S4.E2.m1.1.1.cmml" xref="S4.E2.m1.3.3.1.1.1.1.1.2.2.3.2"><ci id="S4.E2.m1.1.1.1.cmml" xref="S4.E2.m1.1.1.1">^</ci><ci id="S4.E2.m1.1.1.2.cmml" xref="S4.E2.m1.1.1.2">ğ‘–</ci></apply></apply><apply id="S4.E2.m1.3.3.1.1.1.1.1.2.3.cmml" xref="S4.E2.m1.3.3.1.1.1.1.1.2.3"><csymbol cd="ambiguous" id="S4.E2.m1.3.3.1.1.1.1.1.2.3.1.cmml" xref="S4.E2.m1.3.3.1.1.1.1.1.2.3">subscript</csymbol><ci id="S4.E2.m1.3.3.1.1.1.1.1.2.3.2.cmml" xref="S4.E2.m1.3.3.1.1.1.1.1.2.3.2">ğ‘“</ci><apply id="S4.E2.m1.3.3.1.1.1.1.1.2.3.3.cmml" xref="S4.E2.m1.3.3.1.1.1.1.1.2.3.3"><csymbol cd="ambiguous" id="S4.E2.m1.3.3.1.1.1.1.1.2.3.3.1.cmml" xref="S4.E2.m1.3.3.1.1.1.1.1.2.3.3">superscript</csymbol><ci id="S4.E2.m1.3.3.1.1.1.1.1.2.3.3.2.cmml" xref="S4.E2.m1.3.3.1.1.1.1.1.2.3.3.2">ğ‘</ci><ci id="S4.E2.m1.3.3.1.1.1.1.1.2.3.3.3.cmml" xref="S4.E2.m1.3.3.1.1.1.1.1.2.3.3.3">â€²</ci></apply></apply></apply><apply id="S4.E2.m1.2.2.cmml" xref="S4.E2.m1.3.3.1.1.1.1.1.3.2"><ci id="S4.E2.m1.2.2.1.cmml" xref="S4.E2.m1.2.2.1">^</ci><ci id="S4.E2.m1.2.2.2.cmml" xref="S4.E2.m1.2.2.2">ğ‘</ci></apply></apply></apply><apply id="S4.E2.m1.3.3.1.3.cmml" xref="S4.E2.m1.3.3.1.3"><csymbol cd="ambiguous" id="S4.E2.m1.3.3.1.3.1.cmml" xref="S4.E2.m1.3.3.1.3">superscript</csymbol><ci id="S4.E2.m1.3.3.1.3.2.cmml" xref="S4.E2.m1.3.3.1.3.2">ğ‘</ci><ci id="S4.E2.m1.3.3.1.3.3.cmml" xref="S4.E2.m1.3.3.1.3.3">â€²</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E2.m1.3c">a_{i}^{\prime}=\ w^{\prime}f_{c^{\prime}}(f_{a^{\prime}}(\hat{i})\circ f_{b^{\prime}}(\hat{q}))+b^{\prime}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S4.p2.2" class="ltx_p">Where <math id="S4.p2.1.m1.1" class="ltx_Math" alttext="f_{x}" display="inline"><semantics id="S4.p2.1.m1.1a"><msub id="S4.p2.1.m1.1.1" xref="S4.p2.1.m1.1.1.cmml"><mi id="S4.p2.1.m1.1.1.2" xref="S4.p2.1.m1.1.1.2.cmml">f</mi><mi id="S4.p2.1.m1.1.1.3" xref="S4.p2.1.m1.1.1.3.cmml">x</mi></msub><annotation-xml encoding="MathML-Content" id="S4.p2.1.m1.1b"><apply id="S4.p2.1.m1.1.1.cmml" xref="S4.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.p2.1.m1.1.1.1.cmml" xref="S4.p2.1.m1.1.1">subscript</csymbol><ci id="S4.p2.1.m1.1.1.2.cmml" xref="S4.p2.1.m1.1.1.2">ğ‘“</ci><ci id="S4.p2.1.m1.1.1.3.cmml" xref="S4.p2.1.m1.1.1.3">ğ‘¥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.1.m1.1c">f_{x}</annotation></semantics></math> is a fully connected layer with a non-linearity, <math id="S4.p2.2.m2.1" class="ltx_Math" alttext="w" display="inline"><semantics id="S4.p2.2.m2.1a"><mi id="S4.p2.2.m2.1.1" xref="S4.p2.2.m2.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="S4.p2.2.m2.1b"><ci id="S4.p2.2.m2.1.1.cmml" xref="S4.p2.2.m2.1.1">ğ‘¤</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.2.m2.1c">w</annotation></semantics></math> is a weight matrix for a linear layer with output dimension of 1, and b is a scalar.</p>
</div>
<div id="S4.p3" class="ltx_para ltx_noindent">
<p id="S4.p3.1" class="ltx_p">The attention weights are then normalized using a softmax function.</p>
<table id="S4.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E3.m1.2" class="ltx_Math" alttext="\alpha=softmax(\textbf{a})+softmax(\textbf{a}^{\prime})" display="block"><semantics id="S4.E3.m1.2a"><mrow id="S4.E3.m1.2.2" xref="S4.E3.m1.2.2.cmml"><mi id="S4.E3.m1.2.2.3" xref="S4.E3.m1.2.2.3.cmml">Î±</mi><mo id="S4.E3.m1.2.2.2" xref="S4.E3.m1.2.2.2.cmml">=</mo><mrow id="S4.E3.m1.2.2.1" xref="S4.E3.m1.2.2.1.cmml"><mrow id="S4.E3.m1.2.2.1.3" xref="S4.E3.m1.2.2.1.3.cmml"><mi id="S4.E3.m1.2.2.1.3.2" xref="S4.E3.m1.2.2.1.3.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S4.E3.m1.2.2.1.3.1" xref="S4.E3.m1.2.2.1.3.1.cmml">â€‹</mo><mi id="S4.E3.m1.2.2.1.3.3" xref="S4.E3.m1.2.2.1.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.E3.m1.2.2.1.3.1a" xref="S4.E3.m1.2.2.1.3.1.cmml">â€‹</mo><mi id="S4.E3.m1.2.2.1.3.4" xref="S4.E3.m1.2.2.1.3.4.cmml">f</mi><mo lspace="0em" rspace="0em" id="S4.E3.m1.2.2.1.3.1b" xref="S4.E3.m1.2.2.1.3.1.cmml">â€‹</mo><mi id="S4.E3.m1.2.2.1.3.5" xref="S4.E3.m1.2.2.1.3.5.cmml">t</mi><mo lspace="0em" rspace="0em" id="S4.E3.m1.2.2.1.3.1c" xref="S4.E3.m1.2.2.1.3.1.cmml">â€‹</mo><mi id="S4.E3.m1.2.2.1.3.6" xref="S4.E3.m1.2.2.1.3.6.cmml">m</mi><mo lspace="0em" rspace="0em" id="S4.E3.m1.2.2.1.3.1d" xref="S4.E3.m1.2.2.1.3.1.cmml">â€‹</mo><mi id="S4.E3.m1.2.2.1.3.7" xref="S4.E3.m1.2.2.1.3.7.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.E3.m1.2.2.1.3.1e" xref="S4.E3.m1.2.2.1.3.1.cmml">â€‹</mo><mi id="S4.E3.m1.2.2.1.3.8" xref="S4.E3.m1.2.2.1.3.8.cmml">x</mi><mo lspace="0em" rspace="0em" id="S4.E3.m1.2.2.1.3.1f" xref="S4.E3.m1.2.2.1.3.1.cmml">â€‹</mo><mrow id="S4.E3.m1.2.2.1.3.9.2" xref="S4.E3.m1.1.1a.cmml"><mo stretchy="false" id="S4.E3.m1.2.2.1.3.9.2.1" xref="S4.E3.m1.1.1a.cmml">(</mo><mtext class="ltx_mathvariant_bold" id="S4.E3.m1.1.1" xref="S4.E3.m1.1.1.cmml">a</mtext><mo stretchy="false" id="S4.E3.m1.2.2.1.3.9.2.2" xref="S4.E3.m1.1.1a.cmml">)</mo></mrow></mrow><mo id="S4.E3.m1.2.2.1.2" xref="S4.E3.m1.2.2.1.2.cmml">+</mo><mrow id="S4.E3.m1.2.2.1.1" xref="S4.E3.m1.2.2.1.1.cmml"><mi id="S4.E3.m1.2.2.1.1.3" xref="S4.E3.m1.2.2.1.1.3.cmml">s</mi><mo lspace="0em" rspace="0em" id="S4.E3.m1.2.2.1.1.2" xref="S4.E3.m1.2.2.1.1.2.cmml">â€‹</mo><mi id="S4.E3.m1.2.2.1.1.4" xref="S4.E3.m1.2.2.1.1.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.E3.m1.2.2.1.1.2a" xref="S4.E3.m1.2.2.1.1.2.cmml">â€‹</mo><mi id="S4.E3.m1.2.2.1.1.5" xref="S4.E3.m1.2.2.1.1.5.cmml">f</mi><mo lspace="0em" rspace="0em" id="S4.E3.m1.2.2.1.1.2b" xref="S4.E3.m1.2.2.1.1.2.cmml">â€‹</mo><mi id="S4.E3.m1.2.2.1.1.6" xref="S4.E3.m1.2.2.1.1.6.cmml">t</mi><mo lspace="0em" rspace="0em" id="S4.E3.m1.2.2.1.1.2c" xref="S4.E3.m1.2.2.1.1.2.cmml">â€‹</mo><mi id="S4.E3.m1.2.2.1.1.7" xref="S4.E3.m1.2.2.1.1.7.cmml">m</mi><mo lspace="0em" rspace="0em" id="S4.E3.m1.2.2.1.1.2d" xref="S4.E3.m1.2.2.1.1.2.cmml">â€‹</mo><mi id="S4.E3.m1.2.2.1.1.8" xref="S4.E3.m1.2.2.1.1.8.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.E3.m1.2.2.1.1.2e" xref="S4.E3.m1.2.2.1.1.2.cmml">â€‹</mo><mi id="S4.E3.m1.2.2.1.1.9" xref="S4.E3.m1.2.2.1.1.9.cmml">x</mi><mo lspace="0em" rspace="0em" id="S4.E3.m1.2.2.1.1.2f" xref="S4.E3.m1.2.2.1.1.2.cmml">â€‹</mo><mrow id="S4.E3.m1.2.2.1.1.1.1" xref="S4.E3.m1.2.2.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.E3.m1.2.2.1.1.1.1.2" xref="S4.E3.m1.2.2.1.1.1.1.1.cmml">(</mo><msup id="S4.E3.m1.2.2.1.1.1.1.1" xref="S4.E3.m1.2.2.1.1.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S4.E3.m1.2.2.1.1.1.1.1.2" xref="S4.E3.m1.2.2.1.1.1.1.1.2a.cmml">a</mtext><mo id="S4.E3.m1.2.2.1.1.1.1.1.3" xref="S4.E3.m1.2.2.1.1.1.1.1.3.cmml">â€²</mo></msup><mo stretchy="false" id="S4.E3.m1.2.2.1.1.1.1.3" xref="S4.E3.m1.2.2.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E3.m1.2b"><apply id="S4.E3.m1.2.2.cmml" xref="S4.E3.m1.2.2"><eq id="S4.E3.m1.2.2.2.cmml" xref="S4.E3.m1.2.2.2"></eq><ci id="S4.E3.m1.2.2.3.cmml" xref="S4.E3.m1.2.2.3">ğ›¼</ci><apply id="S4.E3.m1.2.2.1.cmml" xref="S4.E3.m1.2.2.1"><plus id="S4.E3.m1.2.2.1.2.cmml" xref="S4.E3.m1.2.2.1.2"></plus><apply id="S4.E3.m1.2.2.1.3.cmml" xref="S4.E3.m1.2.2.1.3"><times id="S4.E3.m1.2.2.1.3.1.cmml" xref="S4.E3.m1.2.2.1.3.1"></times><ci id="S4.E3.m1.2.2.1.3.2.cmml" xref="S4.E3.m1.2.2.1.3.2">ğ‘ </ci><ci id="S4.E3.m1.2.2.1.3.3.cmml" xref="S4.E3.m1.2.2.1.3.3">ğ‘œ</ci><ci id="S4.E3.m1.2.2.1.3.4.cmml" xref="S4.E3.m1.2.2.1.3.4">ğ‘“</ci><ci id="S4.E3.m1.2.2.1.3.5.cmml" xref="S4.E3.m1.2.2.1.3.5">ğ‘¡</ci><ci id="S4.E3.m1.2.2.1.3.6.cmml" xref="S4.E3.m1.2.2.1.3.6">ğ‘š</ci><ci id="S4.E3.m1.2.2.1.3.7.cmml" xref="S4.E3.m1.2.2.1.3.7">ğ‘</ci><ci id="S4.E3.m1.2.2.1.3.8.cmml" xref="S4.E3.m1.2.2.1.3.8">ğ‘¥</ci><ci id="S4.E3.m1.1.1a.cmml" xref="S4.E3.m1.2.2.1.3.9.2"><mtext class="ltx_mathvariant_bold" id="S4.E3.m1.1.1.cmml" xref="S4.E3.m1.1.1">a</mtext></ci></apply><apply id="S4.E3.m1.2.2.1.1.cmml" xref="S4.E3.m1.2.2.1.1"><times id="S4.E3.m1.2.2.1.1.2.cmml" xref="S4.E3.m1.2.2.1.1.2"></times><ci id="S4.E3.m1.2.2.1.1.3.cmml" xref="S4.E3.m1.2.2.1.1.3">ğ‘ </ci><ci id="S4.E3.m1.2.2.1.1.4.cmml" xref="S4.E3.m1.2.2.1.1.4">ğ‘œ</ci><ci id="S4.E3.m1.2.2.1.1.5.cmml" xref="S4.E3.m1.2.2.1.1.5">ğ‘“</ci><ci id="S4.E3.m1.2.2.1.1.6.cmml" xref="S4.E3.m1.2.2.1.1.6">ğ‘¡</ci><ci id="S4.E3.m1.2.2.1.1.7.cmml" xref="S4.E3.m1.2.2.1.1.7">ğ‘š</ci><ci id="S4.E3.m1.2.2.1.1.8.cmml" xref="S4.E3.m1.2.2.1.1.8">ğ‘</ci><ci id="S4.E3.m1.2.2.1.1.9.cmml" xref="S4.E3.m1.2.2.1.1.9">ğ‘¥</ci><apply id="S4.E3.m1.2.2.1.1.1.1.1.cmml" xref="S4.E3.m1.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S4.E3.m1.2.2.1.1.1.1.1.1.cmml" xref="S4.E3.m1.2.2.1.1.1.1">superscript</csymbol><ci id="S4.E3.m1.2.2.1.1.1.1.1.2a.cmml" xref="S4.E3.m1.2.2.1.1.1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S4.E3.m1.2.2.1.1.1.1.1.2.cmml" xref="S4.E3.m1.2.2.1.1.1.1.1.2">a</mtext></ci><ci id="S4.E3.m1.2.2.1.1.1.1.1.3.cmml" xref="S4.E3.m1.2.2.1.1.1.1.1.3">â€²</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E3.m1.2c">\alpha=softmax(\textbf{a})+softmax(\textbf{a}^{\prime})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="S4.p3.2" class="ltx_p">The final image embedding is then created by taking a weighted sum of the original 36 image vectors using the attention scalars as weights.</p>
<table id="S4.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E4.m1.2" class="ltx_Math" alttext="\hat{v}=\sum_{i=1}^{K}(\alpha_{i}\textbf{$v_{i}$})" display="block"><semantics id="S4.E4.m1.2a"><mrow id="S4.E4.m1.2.2" xref="S4.E4.m1.2.2.cmml"><mover accent="true" id="S4.E4.m1.2.2.3" xref="S4.E4.m1.2.2.3.cmml"><mi id="S4.E4.m1.2.2.3.2" xref="S4.E4.m1.2.2.3.2.cmml">v</mi><mo id="S4.E4.m1.2.2.3.1" xref="S4.E4.m1.2.2.3.1.cmml">^</mo></mover><mo rspace="0.111em" id="S4.E4.m1.2.2.2" xref="S4.E4.m1.2.2.2.cmml">=</mo><mrow id="S4.E4.m1.2.2.1" xref="S4.E4.m1.2.2.1.cmml"><munderover id="S4.E4.m1.2.2.1.2" xref="S4.E4.m1.2.2.1.2.cmml"><mo movablelimits="false" rspace="0em" id="S4.E4.m1.2.2.1.2.2.2" xref="S4.E4.m1.2.2.1.2.2.2.cmml">âˆ‘</mo><mrow id="S4.E4.m1.2.2.1.2.2.3" xref="S4.E4.m1.2.2.1.2.2.3.cmml"><mi id="S4.E4.m1.2.2.1.2.2.3.2" xref="S4.E4.m1.2.2.1.2.2.3.2.cmml">i</mi><mo id="S4.E4.m1.2.2.1.2.2.3.1" xref="S4.E4.m1.2.2.1.2.2.3.1.cmml">=</mo><mn id="S4.E4.m1.2.2.1.2.2.3.3" xref="S4.E4.m1.2.2.1.2.2.3.3.cmml">1</mn></mrow><mi id="S4.E4.m1.2.2.1.2.3" xref="S4.E4.m1.2.2.1.2.3.cmml">K</mi></munderover><mrow id="S4.E4.m1.2.2.1.1.1" xref="S4.E4.m1.2.2.1.1.1.1.cmml"><mo stretchy="false" id="S4.E4.m1.2.2.1.1.1.2" xref="S4.E4.m1.2.2.1.1.1.1.cmml">(</mo><mrow id="S4.E4.m1.2.2.1.1.1.1" xref="S4.E4.m1.2.2.1.1.1.1.cmml"><msub id="S4.E4.m1.2.2.1.1.1.1.2" xref="S4.E4.m1.2.2.1.1.1.1.2.cmml"><mi id="S4.E4.m1.2.2.1.1.1.1.2.2" xref="S4.E4.m1.2.2.1.1.1.1.2.2.cmml">Î±</mi><mi id="S4.E4.m1.2.2.1.1.1.1.2.3" xref="S4.E4.m1.2.2.1.1.1.1.2.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S4.E4.m1.2.2.1.1.1.1.1" xref="S4.E4.m1.2.2.1.1.1.1.1.cmml">â€‹</mo><msub id="S4.E4.m1.1.1.1" xref="S4.E4.m1.1.1.1.cmml"><mi id="S4.E4.m1.1.1.1.3" xref="S4.E4.m1.1.1.1.3.cmml">v</mi><mi id="S4.E4.m1.1.1.1.4" xref="S4.E4.m1.1.1.1.4.cmml">i</mi></msub></mrow><mo stretchy="false" id="S4.E4.m1.2.2.1.1.1.3" xref="S4.E4.m1.2.2.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E4.m1.2b"><apply id="S4.E4.m1.2.2.cmml" xref="S4.E4.m1.2.2"><eq id="S4.E4.m1.2.2.2.cmml" xref="S4.E4.m1.2.2.2"></eq><apply id="S4.E4.m1.2.2.3.cmml" xref="S4.E4.m1.2.2.3"><ci id="S4.E4.m1.2.2.3.1.cmml" xref="S4.E4.m1.2.2.3.1">^</ci><ci id="S4.E4.m1.2.2.3.2.cmml" xref="S4.E4.m1.2.2.3.2">ğ‘£</ci></apply><apply id="S4.E4.m1.2.2.1.cmml" xref="S4.E4.m1.2.2.1"><apply id="S4.E4.m1.2.2.1.2.cmml" xref="S4.E4.m1.2.2.1.2"><csymbol cd="ambiguous" id="S4.E4.m1.2.2.1.2.1.cmml" xref="S4.E4.m1.2.2.1.2">superscript</csymbol><apply id="S4.E4.m1.2.2.1.2.2.cmml" xref="S4.E4.m1.2.2.1.2"><csymbol cd="ambiguous" id="S4.E4.m1.2.2.1.2.2.1.cmml" xref="S4.E4.m1.2.2.1.2">subscript</csymbol><sum id="S4.E4.m1.2.2.1.2.2.2.cmml" xref="S4.E4.m1.2.2.1.2.2.2"></sum><apply id="S4.E4.m1.2.2.1.2.2.3.cmml" xref="S4.E4.m1.2.2.1.2.2.3"><eq id="S4.E4.m1.2.2.1.2.2.3.1.cmml" xref="S4.E4.m1.2.2.1.2.2.3.1"></eq><ci id="S4.E4.m1.2.2.1.2.2.3.2.cmml" xref="S4.E4.m1.2.2.1.2.2.3.2">ğ‘–</ci><cn type="integer" id="S4.E4.m1.2.2.1.2.2.3.3.cmml" xref="S4.E4.m1.2.2.1.2.2.3.3">1</cn></apply></apply><ci id="S4.E4.m1.2.2.1.2.3.cmml" xref="S4.E4.m1.2.2.1.2.3">ğ¾</ci></apply><apply id="S4.E4.m1.2.2.1.1.1.1.cmml" xref="S4.E4.m1.2.2.1.1.1"><times id="S4.E4.m1.2.2.1.1.1.1.1.cmml" xref="S4.E4.m1.2.2.1.1.1.1.1"></times><apply id="S4.E4.m1.2.2.1.1.1.1.2.cmml" xref="S4.E4.m1.2.2.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E4.m1.2.2.1.1.1.1.2.1.cmml" xref="S4.E4.m1.2.2.1.1.1.1.2">subscript</csymbol><ci id="S4.E4.m1.2.2.1.1.1.1.2.2.cmml" xref="S4.E4.m1.2.2.1.1.1.1.2.2">ğ›¼</ci><ci id="S4.E4.m1.2.2.1.1.1.1.2.3.cmml" xref="S4.E4.m1.2.2.1.1.1.1.2.3">ğ‘–</ci></apply><apply id="S4.E4.m1.1.1.1.cmml" xref="S4.E4.m1.1.1.1"><csymbol cd="ambiguous" id="S4.E4.m1.1.1.1.2.cmml" xref="S4.E4.m1.1.1.1">subscript</csymbol><ci id="S4.E4.m1.1.1.1.3.cmml" xref="S4.E4.m1.1.1.1.3">ğ‘£</ci><ci id="S4.E4.m1.1.1.1.4.cmml" xref="S4.E4.m1.1.1.1.4">ğ‘–</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E4.m1.2c">\hat{v}=\sum_{i=1}^{K}(\alpha_{i}\textbf{$v_{i}$})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p id="S4.p3.3" class="ltx_p">The final image vector and the question embedding are then passed through separate one layer transformation modules, that rearrange and convert the input vectors to the same dimensions. The resulting vectors from the one layer transformation modules are then element-wise multiplied together to create the final joint embedding. This joint embedding is then given to a simple 2 layer classification module that outputs a probability via a sigmoid layer for each of the possible answers in our answer vocabulary. The word corresponding to the maximum of these output probabilities is then taken to be the predicted answer, from which the accuracy can then be calculated using the equation from <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx6" title="" class="ltx_ref">TAHvdH17</a>]</cite>:</p>
<table id="S4.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E5.m1.2" class="ltx_Math" alttext="accuracy=\frac{1}{m_{v}}\ \sum^{Val}(one\ hot(argmax(\hat{y}))\cdot y)." display="block"><semantics id="S4.E5.m1.2a"><mrow id="S4.E5.m1.2.2.1" xref="S4.E5.m1.2.2.1.1.cmml"><mrow id="S4.E5.m1.2.2.1.1" xref="S4.E5.m1.2.2.1.1.cmml"><mrow id="S4.E5.m1.2.2.1.1.3" xref="S4.E5.m1.2.2.1.1.3.cmml"><mi id="S4.E5.m1.2.2.1.1.3.2" xref="S4.E5.m1.2.2.1.1.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.E5.m1.2.2.1.1.3.1" xref="S4.E5.m1.2.2.1.1.3.1.cmml">â€‹</mo><mi id="S4.E5.m1.2.2.1.1.3.3" xref="S4.E5.m1.2.2.1.1.3.3.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.E5.m1.2.2.1.1.3.1a" xref="S4.E5.m1.2.2.1.1.3.1.cmml">â€‹</mo><mi id="S4.E5.m1.2.2.1.1.3.4" xref="S4.E5.m1.2.2.1.1.3.4.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.E5.m1.2.2.1.1.3.1b" xref="S4.E5.m1.2.2.1.1.3.1.cmml">â€‹</mo><mi id="S4.E5.m1.2.2.1.1.3.5" xref="S4.E5.m1.2.2.1.1.3.5.cmml">u</mi><mo lspace="0em" rspace="0em" id="S4.E5.m1.2.2.1.1.3.1c" xref="S4.E5.m1.2.2.1.1.3.1.cmml">â€‹</mo><mi id="S4.E5.m1.2.2.1.1.3.6" xref="S4.E5.m1.2.2.1.1.3.6.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.E5.m1.2.2.1.1.3.1d" xref="S4.E5.m1.2.2.1.1.3.1.cmml">â€‹</mo><mi id="S4.E5.m1.2.2.1.1.3.7" xref="S4.E5.m1.2.2.1.1.3.7.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.E5.m1.2.2.1.1.3.1e" xref="S4.E5.m1.2.2.1.1.3.1.cmml">â€‹</mo><mi id="S4.E5.m1.2.2.1.1.3.8" xref="S4.E5.m1.2.2.1.1.3.8.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.E5.m1.2.2.1.1.3.1f" xref="S4.E5.m1.2.2.1.1.3.1.cmml">â€‹</mo><mi id="S4.E5.m1.2.2.1.1.3.9" xref="S4.E5.m1.2.2.1.1.3.9.cmml">y</mi></mrow><mo id="S4.E5.m1.2.2.1.1.2" xref="S4.E5.m1.2.2.1.1.2.cmml">=</mo><mrow id="S4.E5.m1.2.2.1.1.1" xref="S4.E5.m1.2.2.1.1.1.cmml"><mfrac id="S4.E5.m1.2.2.1.1.1.3" xref="S4.E5.m1.2.2.1.1.1.3.cmml"><mn id="S4.E5.m1.2.2.1.1.1.3.2" xref="S4.E5.m1.2.2.1.1.1.3.2.cmml">1</mn><msub id="S4.E5.m1.2.2.1.1.1.3.3" xref="S4.E5.m1.2.2.1.1.1.3.3.cmml"><mi id="S4.E5.m1.2.2.1.1.1.3.3.2" xref="S4.E5.m1.2.2.1.1.1.3.3.2.cmml">m</mi><mi id="S4.E5.m1.2.2.1.1.1.3.3.3" xref="S4.E5.m1.2.2.1.1.1.3.3.3.cmml">v</mi></msub></mfrac><mo lspace="0.667em" rspace="0em" id="S4.E5.m1.2.2.1.1.1.2" xref="S4.E5.m1.2.2.1.1.1.2.cmml">â€‹</mo><mrow id="S4.E5.m1.2.2.1.1.1.1" xref="S4.E5.m1.2.2.1.1.1.1.cmml"><mover id="S4.E5.m1.2.2.1.1.1.1.2" xref="S4.E5.m1.2.2.1.1.1.1.2.cmml"><mo movablelimits="false" rspace="0em" id="S4.E5.m1.2.2.1.1.1.1.2.2" xref="S4.E5.m1.2.2.1.1.1.1.2.2.cmml">âˆ‘</mo><mrow id="S4.E5.m1.2.2.1.1.1.1.2.3" xref="S4.E5.m1.2.2.1.1.1.1.2.3.cmml"><mi id="S4.E5.m1.2.2.1.1.1.1.2.3.2" xref="S4.E5.m1.2.2.1.1.1.1.2.3.2.cmml">V</mi><mo lspace="0em" rspace="0em" id="S4.E5.m1.2.2.1.1.1.1.2.3.1" xref="S4.E5.m1.2.2.1.1.1.1.2.3.1.cmml">â€‹</mo><mi id="S4.E5.m1.2.2.1.1.1.1.2.3.3" xref="S4.E5.m1.2.2.1.1.1.1.2.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.E5.m1.2.2.1.1.1.1.2.3.1a" xref="S4.E5.m1.2.2.1.1.1.1.2.3.1.cmml">â€‹</mo><mi id="S4.E5.m1.2.2.1.1.1.1.2.3.4" xref="S4.E5.m1.2.2.1.1.1.1.2.3.4.cmml">l</mi></mrow></mover><mrow id="S4.E5.m1.2.2.1.1.1.1.1.1" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.E5.m1.2.2.1.1.1.1.1.1.2" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.E5.m1.2.2.1.1.1.1.1.1.1" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.cmml"><mrow id="S4.E5.m1.2.2.1.1.1.1.1.1.1.1" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.cmml"><mi id="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.3" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.2" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.2.cmml">â€‹</mo><mi id="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.4" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.2a" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.2.cmml">â€‹</mo><mi id="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.5" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.5.cmml">e</mi><mo lspace="0.500em" rspace="0em" id="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.2b" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.2.cmml">â€‹</mo><mi id="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.6" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.6.cmml">h</mi><mo lspace="0em" rspace="0em" id="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.2c" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.2.cmml">â€‹</mo><mi id="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.7" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.7.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.2d" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.2.cmml">â€‹</mo><mi id="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.8" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.8.cmml">t</mi><mo lspace="0em" rspace="0em" id="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.2e" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.2" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.cmml">â€‹</mo><mi id="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1a" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.cmml">â€‹</mo><mi id="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.4" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.4.cmml">g</mi><mo lspace="0em" rspace="0em" id="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1b" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.cmml">â€‹</mo><mi id="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.5" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.5.cmml">m</mi><mo lspace="0em" rspace="0em" id="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1c" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.cmml">â€‹</mo><mi id="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.6" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.6.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1d" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.cmml">â€‹</mo><mi id="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.7" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.7.cmml">x</mi><mo lspace="0em" rspace="0em" id="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1e" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.cmml">â€‹</mo><mrow id="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.8.2" xref="S4.E5.m1.1.1.cmml"><mo stretchy="false" id="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.8.2.1" xref="S4.E5.m1.1.1.cmml">(</mo><mover accent="true" id="S4.E5.m1.1.1" xref="S4.E5.m1.1.1.cmml"><mi id="S4.E5.m1.1.1.2" xref="S4.E5.m1.1.1.2.cmml">y</mi><mo id="S4.E5.m1.1.1.1" xref="S4.E5.m1.1.1.1.cmml">^</mo></mover><mo stretchy="false" id="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.8.2.2" xref="S4.E5.m1.1.1.cmml">)</mo></mrow></mrow><mo rspace="0.055em" stretchy="false" id="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.3" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo rspace="0.222em" id="S4.E5.m1.2.2.1.1.1.1.1.1.1.2" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.2.cmml">â‹…</mo><mi id="S4.E5.m1.2.2.1.1.1.1.1.1.1.3" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.3.cmml">y</mi></mrow><mo stretchy="false" id="S4.E5.m1.2.2.1.1.1.1.1.1.3" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><mo lspace="0em" id="S4.E5.m1.2.2.1.2" xref="S4.E5.m1.2.2.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E5.m1.2b"><apply id="S4.E5.m1.2.2.1.1.cmml" xref="S4.E5.m1.2.2.1"><eq id="S4.E5.m1.2.2.1.1.2.cmml" xref="S4.E5.m1.2.2.1.1.2"></eq><apply id="S4.E5.m1.2.2.1.1.3.cmml" xref="S4.E5.m1.2.2.1.1.3"><times id="S4.E5.m1.2.2.1.1.3.1.cmml" xref="S4.E5.m1.2.2.1.1.3.1"></times><ci id="S4.E5.m1.2.2.1.1.3.2.cmml" xref="S4.E5.m1.2.2.1.1.3.2">ğ‘</ci><ci id="S4.E5.m1.2.2.1.1.3.3.cmml" xref="S4.E5.m1.2.2.1.1.3.3">ğ‘</ci><ci id="S4.E5.m1.2.2.1.1.3.4.cmml" xref="S4.E5.m1.2.2.1.1.3.4">ğ‘</ci><ci id="S4.E5.m1.2.2.1.1.3.5.cmml" xref="S4.E5.m1.2.2.1.1.3.5">ğ‘¢</ci><ci id="S4.E5.m1.2.2.1.1.3.6.cmml" xref="S4.E5.m1.2.2.1.1.3.6">ğ‘Ÿ</ci><ci id="S4.E5.m1.2.2.1.1.3.7.cmml" xref="S4.E5.m1.2.2.1.1.3.7">ğ‘</ci><ci id="S4.E5.m1.2.2.1.1.3.8.cmml" xref="S4.E5.m1.2.2.1.1.3.8">ğ‘</ci><ci id="S4.E5.m1.2.2.1.1.3.9.cmml" xref="S4.E5.m1.2.2.1.1.3.9">ğ‘¦</ci></apply><apply id="S4.E5.m1.2.2.1.1.1.cmml" xref="S4.E5.m1.2.2.1.1.1"><times id="S4.E5.m1.2.2.1.1.1.2.cmml" xref="S4.E5.m1.2.2.1.1.1.2"></times><apply id="S4.E5.m1.2.2.1.1.1.3.cmml" xref="S4.E5.m1.2.2.1.1.1.3"><divide id="S4.E5.m1.2.2.1.1.1.3.1.cmml" xref="S4.E5.m1.2.2.1.1.1.3"></divide><cn type="integer" id="S4.E5.m1.2.2.1.1.1.3.2.cmml" xref="S4.E5.m1.2.2.1.1.1.3.2">1</cn><apply id="S4.E5.m1.2.2.1.1.1.3.3.cmml" xref="S4.E5.m1.2.2.1.1.1.3.3"><csymbol cd="ambiguous" id="S4.E5.m1.2.2.1.1.1.3.3.1.cmml" xref="S4.E5.m1.2.2.1.1.1.3.3">subscript</csymbol><ci id="S4.E5.m1.2.2.1.1.1.3.3.2.cmml" xref="S4.E5.m1.2.2.1.1.1.3.3.2">ğ‘š</ci><ci id="S4.E5.m1.2.2.1.1.1.3.3.3.cmml" xref="S4.E5.m1.2.2.1.1.1.3.3.3">ğ‘£</ci></apply></apply><apply id="S4.E5.m1.2.2.1.1.1.1.cmml" xref="S4.E5.m1.2.2.1.1.1.1"><apply id="S4.E5.m1.2.2.1.1.1.1.2.cmml" xref="S4.E5.m1.2.2.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E5.m1.2.2.1.1.1.1.2.1.cmml" xref="S4.E5.m1.2.2.1.1.1.1.2">superscript</csymbol><sum id="S4.E5.m1.2.2.1.1.1.1.2.2.cmml" xref="S4.E5.m1.2.2.1.1.1.1.2.2"></sum><apply id="S4.E5.m1.2.2.1.1.1.1.2.3.cmml" xref="S4.E5.m1.2.2.1.1.1.1.2.3"><times id="S4.E5.m1.2.2.1.1.1.1.2.3.1.cmml" xref="S4.E5.m1.2.2.1.1.1.1.2.3.1"></times><ci id="S4.E5.m1.2.2.1.1.1.1.2.3.2.cmml" xref="S4.E5.m1.2.2.1.1.1.1.2.3.2">ğ‘‰</ci><ci id="S4.E5.m1.2.2.1.1.1.1.2.3.3.cmml" xref="S4.E5.m1.2.2.1.1.1.1.2.3.3">ğ‘</ci><ci id="S4.E5.m1.2.2.1.1.1.1.2.3.4.cmml" xref="S4.E5.m1.2.2.1.1.1.1.2.3.4">ğ‘™</ci></apply></apply><apply id="S4.E5.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S4.E5.m1.2.2.1.1.1.1.1.1"><ci id="S4.E5.m1.2.2.1.1.1.1.1.1.1.2.cmml" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.2">â‹…</ci><apply id="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.cmml" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.1"><times id="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.2"></times><ci id="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.3.cmml" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.3">ğ‘œ</ci><ci id="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.4.cmml" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.4">ğ‘›</ci><ci id="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.5.cmml" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.5">ğ‘’</ci><ci id="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.6.cmml" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.6">â„</ci><ci id="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.7.cmml" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.7">ğ‘œ</ci><ci id="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.8.cmml" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.8">ğ‘¡</ci><apply id="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1"><times id="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1"></times><ci id="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2">ğ‘</ci><ci id="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3">ğ‘Ÿ</ci><ci id="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.4.cmml" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.4">ğ‘”</ci><ci id="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.5.cmml" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.5">ğ‘š</ci><ci id="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.6.cmml" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.6">ğ‘</ci><ci id="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.7.cmml" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.7">ğ‘¥</ci><apply id="S4.E5.m1.1.1.cmml" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.8.2"><ci id="S4.E5.m1.1.1.1.cmml" xref="S4.E5.m1.1.1.1">^</ci><ci id="S4.E5.m1.1.1.2.cmml" xref="S4.E5.m1.1.1.2">ğ‘¦</ci></apply></apply></apply><ci id="S4.E5.m1.2.2.1.1.1.1.1.1.1.3.cmml" xref="S4.E5.m1.2.2.1.1.1.1.1.1.1.3">ğ‘¦</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E5.m1.2c">accuracy=\frac{1}{m_{v}}\ \sum^{Val}(one\ hot(argmax(\hat{y}))\cdot y).</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<p id="S4.p3.4" class="ltx_p">Alternatively these output probabilities could also be passed to a binary cross entropy loss layer during training.</p>
<table id="S4.E6" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E6.m1.4" class="ltx_Math" alttext="\mathcal{L}=\frac{1}{m_{t}}\sum_{i=1}^{m_{t}}-(y\log(\hat{y})-(1-y)\log(1-\hat{y}))" display="block"><semantics id="S4.E6.m1.4a"><mrow id="S4.E6.m1.4.4" xref="S4.E6.m1.4.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E6.m1.4.4.3" xref="S4.E6.m1.4.4.3.cmml">â„’</mi><mo id="S4.E6.m1.4.4.2" xref="S4.E6.m1.4.4.2.cmml">=</mo><mrow id="S4.E6.m1.4.4.1" xref="S4.E6.m1.4.4.1.cmml"><mrow id="S4.E6.m1.4.4.1.3" xref="S4.E6.m1.4.4.1.3.cmml"><mfrac id="S4.E6.m1.4.4.1.3.2" xref="S4.E6.m1.4.4.1.3.2.cmml"><mn id="S4.E6.m1.4.4.1.3.2.2" xref="S4.E6.m1.4.4.1.3.2.2.cmml">1</mn><msub id="S4.E6.m1.4.4.1.3.2.3" xref="S4.E6.m1.4.4.1.3.2.3.cmml"><mi id="S4.E6.m1.4.4.1.3.2.3.2" xref="S4.E6.m1.4.4.1.3.2.3.2.cmml">m</mi><mi id="S4.E6.m1.4.4.1.3.2.3.3" xref="S4.E6.m1.4.4.1.3.2.3.3.cmml">t</mi></msub></mfrac><mo lspace="0em" rspace="0em" id="S4.E6.m1.4.4.1.3.1" xref="S4.E6.m1.4.4.1.3.1.cmml">â€‹</mo><munderover id="S4.E6.m1.4.4.1.3.3" xref="S4.E6.m1.4.4.1.3.3.cmml"><mo movablelimits="false" rspace="0em" id="S4.E6.m1.4.4.1.3.3.2.2" xref="S4.E6.m1.4.4.1.3.3.2.2.cmml">âˆ‘</mo><mrow id="S4.E6.m1.4.4.1.3.3.2.3" xref="S4.E6.m1.4.4.1.3.3.2.3.cmml"><mi id="S4.E6.m1.4.4.1.3.3.2.3.2" xref="S4.E6.m1.4.4.1.3.3.2.3.2.cmml">i</mi><mo id="S4.E6.m1.4.4.1.3.3.2.3.1" xref="S4.E6.m1.4.4.1.3.3.2.3.1.cmml">=</mo><mn id="S4.E6.m1.4.4.1.3.3.2.3.3" xref="S4.E6.m1.4.4.1.3.3.2.3.3.cmml">1</mn></mrow><msub id="S4.E6.m1.4.4.1.3.3.3" xref="S4.E6.m1.4.4.1.3.3.3.cmml"><mi id="S4.E6.m1.4.4.1.3.3.3.2" xref="S4.E6.m1.4.4.1.3.3.3.2.cmml">m</mi><mi id="S4.E6.m1.4.4.1.3.3.3.3" xref="S4.E6.m1.4.4.1.3.3.3.3.cmml">t</mi></msub></munderover></mrow><mo lspace="0em" id="S4.E6.m1.4.4.1.2" xref="S4.E6.m1.4.4.1.2.cmml">âˆ’</mo><mrow id="S4.E6.m1.4.4.1.1.1" xref="S4.E6.m1.4.4.1.1.1.1.cmml"><mo stretchy="false" id="S4.E6.m1.4.4.1.1.1.2" xref="S4.E6.m1.4.4.1.1.1.1.cmml">(</mo><mrow id="S4.E6.m1.4.4.1.1.1.1" xref="S4.E6.m1.4.4.1.1.1.1.cmml"><mrow id="S4.E6.m1.4.4.1.1.1.1.4" xref="S4.E6.m1.4.4.1.1.1.1.4.cmml"><mi id="S4.E6.m1.4.4.1.1.1.1.4.2" xref="S4.E6.m1.4.4.1.1.1.1.4.2.cmml">y</mi><mo lspace="0.167em" rspace="0em" id="S4.E6.m1.4.4.1.1.1.1.4.1" xref="S4.E6.m1.4.4.1.1.1.1.4.1.cmml">â€‹</mo><mrow id="S4.E6.m1.4.4.1.1.1.1.4.3.2" xref="S4.E6.m1.4.4.1.1.1.1.4.3.1.cmml"><mi id="S4.E6.m1.1.1" xref="S4.E6.m1.1.1.cmml">log</mi><mo id="S4.E6.m1.4.4.1.1.1.1.4.3.2a" xref="S4.E6.m1.4.4.1.1.1.1.4.3.1.cmml">â¡</mo><mrow id="S4.E6.m1.4.4.1.1.1.1.4.3.2.1" xref="S4.E6.m1.4.4.1.1.1.1.4.3.1.cmml"><mo stretchy="false" id="S4.E6.m1.4.4.1.1.1.1.4.3.2.1.1" xref="S4.E6.m1.4.4.1.1.1.1.4.3.1.cmml">(</mo><mover accent="true" id="S4.E6.m1.2.2" xref="S4.E6.m1.2.2.cmml"><mi id="S4.E6.m1.2.2.2" xref="S4.E6.m1.2.2.2.cmml">y</mi><mo id="S4.E6.m1.2.2.1" xref="S4.E6.m1.2.2.1.cmml">^</mo></mover><mo stretchy="false" id="S4.E6.m1.4.4.1.1.1.1.4.3.2.1.2" xref="S4.E6.m1.4.4.1.1.1.1.4.3.1.cmml">)</mo></mrow></mrow></mrow><mo id="S4.E6.m1.4.4.1.1.1.1.3" xref="S4.E6.m1.4.4.1.1.1.1.3.cmml">âˆ’</mo><mrow id="S4.E6.m1.4.4.1.1.1.1.2" xref="S4.E6.m1.4.4.1.1.1.1.2.cmml"><mrow id="S4.E6.m1.4.4.1.1.1.1.1.1.1" xref="S4.E6.m1.4.4.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.E6.m1.4.4.1.1.1.1.1.1.1.2" xref="S4.E6.m1.4.4.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.E6.m1.4.4.1.1.1.1.1.1.1.1" xref="S4.E6.m1.4.4.1.1.1.1.1.1.1.1.cmml"><mn id="S4.E6.m1.4.4.1.1.1.1.1.1.1.1.2" xref="S4.E6.m1.4.4.1.1.1.1.1.1.1.1.2.cmml">1</mn><mo id="S4.E6.m1.4.4.1.1.1.1.1.1.1.1.1" xref="S4.E6.m1.4.4.1.1.1.1.1.1.1.1.1.cmml">âˆ’</mo><mi id="S4.E6.m1.4.4.1.1.1.1.1.1.1.1.3" xref="S4.E6.m1.4.4.1.1.1.1.1.1.1.1.3.cmml">y</mi></mrow><mo stretchy="false" id="S4.E6.m1.4.4.1.1.1.1.1.1.1.3" xref="S4.E6.m1.4.4.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo lspace="0.167em" rspace="0em" id="S4.E6.m1.4.4.1.1.1.1.2.3" xref="S4.E6.m1.4.4.1.1.1.1.2.3.cmml">â€‹</mo><mrow id="S4.E6.m1.4.4.1.1.1.1.2.2.1" xref="S4.E6.m1.4.4.1.1.1.1.2.2.2.cmml"><mi id="S4.E6.m1.3.3" xref="S4.E6.m1.3.3.cmml">log</mi><mo id="S4.E6.m1.4.4.1.1.1.1.2.2.1a" xref="S4.E6.m1.4.4.1.1.1.1.2.2.2.cmml">â¡</mo><mrow id="S4.E6.m1.4.4.1.1.1.1.2.2.1.1" xref="S4.E6.m1.4.4.1.1.1.1.2.2.2.cmml"><mo stretchy="false" id="S4.E6.m1.4.4.1.1.1.1.2.2.1.1.2" xref="S4.E6.m1.4.4.1.1.1.1.2.2.2.cmml">(</mo><mrow id="S4.E6.m1.4.4.1.1.1.1.2.2.1.1.1" xref="S4.E6.m1.4.4.1.1.1.1.2.2.1.1.1.cmml"><mn id="S4.E6.m1.4.4.1.1.1.1.2.2.1.1.1.2" xref="S4.E6.m1.4.4.1.1.1.1.2.2.1.1.1.2.cmml">1</mn><mo id="S4.E6.m1.4.4.1.1.1.1.2.2.1.1.1.1" xref="S4.E6.m1.4.4.1.1.1.1.2.2.1.1.1.1.cmml">âˆ’</mo><mover accent="true" id="S4.E6.m1.4.4.1.1.1.1.2.2.1.1.1.3" xref="S4.E6.m1.4.4.1.1.1.1.2.2.1.1.1.3.cmml"><mi id="S4.E6.m1.4.4.1.1.1.1.2.2.1.1.1.3.2" xref="S4.E6.m1.4.4.1.1.1.1.2.2.1.1.1.3.2.cmml">y</mi><mo id="S4.E6.m1.4.4.1.1.1.1.2.2.1.1.1.3.1" xref="S4.E6.m1.4.4.1.1.1.1.2.2.1.1.1.3.1.cmml">^</mo></mover></mrow><mo stretchy="false" id="S4.E6.m1.4.4.1.1.1.1.2.2.1.1.3" xref="S4.E6.m1.4.4.1.1.1.1.2.2.2.cmml">)</mo></mrow></mrow></mrow></mrow><mo stretchy="false" id="S4.E6.m1.4.4.1.1.1.3" xref="S4.E6.m1.4.4.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E6.m1.4b"><apply id="S4.E6.m1.4.4.cmml" xref="S4.E6.m1.4.4"><eq id="S4.E6.m1.4.4.2.cmml" xref="S4.E6.m1.4.4.2"></eq><ci id="S4.E6.m1.4.4.3.cmml" xref="S4.E6.m1.4.4.3">â„’</ci><apply id="S4.E6.m1.4.4.1.cmml" xref="S4.E6.m1.4.4.1"><minus id="S4.E6.m1.4.4.1.2.cmml" xref="S4.E6.m1.4.4.1.2"></minus><apply id="S4.E6.m1.4.4.1.3.cmml" xref="S4.E6.m1.4.4.1.3"><times id="S4.E6.m1.4.4.1.3.1.cmml" xref="S4.E6.m1.4.4.1.3.1"></times><apply id="S4.E6.m1.4.4.1.3.2.cmml" xref="S4.E6.m1.4.4.1.3.2"><divide id="S4.E6.m1.4.4.1.3.2.1.cmml" xref="S4.E6.m1.4.4.1.3.2"></divide><cn type="integer" id="S4.E6.m1.4.4.1.3.2.2.cmml" xref="S4.E6.m1.4.4.1.3.2.2">1</cn><apply id="S4.E6.m1.4.4.1.3.2.3.cmml" xref="S4.E6.m1.4.4.1.3.2.3"><csymbol cd="ambiguous" id="S4.E6.m1.4.4.1.3.2.3.1.cmml" xref="S4.E6.m1.4.4.1.3.2.3">subscript</csymbol><ci id="S4.E6.m1.4.4.1.3.2.3.2.cmml" xref="S4.E6.m1.4.4.1.3.2.3.2">ğ‘š</ci><ci id="S4.E6.m1.4.4.1.3.2.3.3.cmml" xref="S4.E6.m1.4.4.1.3.2.3.3">ğ‘¡</ci></apply></apply><apply id="S4.E6.m1.4.4.1.3.3.cmml" xref="S4.E6.m1.4.4.1.3.3"><csymbol cd="ambiguous" id="S4.E6.m1.4.4.1.3.3.1.cmml" xref="S4.E6.m1.4.4.1.3.3">superscript</csymbol><apply id="S4.E6.m1.4.4.1.3.3.2.cmml" xref="S4.E6.m1.4.4.1.3.3"><csymbol cd="ambiguous" id="S4.E6.m1.4.4.1.3.3.2.1.cmml" xref="S4.E6.m1.4.4.1.3.3">subscript</csymbol><sum id="S4.E6.m1.4.4.1.3.3.2.2.cmml" xref="S4.E6.m1.4.4.1.3.3.2.2"></sum><apply id="S4.E6.m1.4.4.1.3.3.2.3.cmml" xref="S4.E6.m1.4.4.1.3.3.2.3"><eq id="S4.E6.m1.4.4.1.3.3.2.3.1.cmml" xref="S4.E6.m1.4.4.1.3.3.2.3.1"></eq><ci id="S4.E6.m1.4.4.1.3.3.2.3.2.cmml" xref="S4.E6.m1.4.4.1.3.3.2.3.2">ğ‘–</ci><cn type="integer" id="S4.E6.m1.4.4.1.3.3.2.3.3.cmml" xref="S4.E6.m1.4.4.1.3.3.2.3.3">1</cn></apply></apply><apply id="S4.E6.m1.4.4.1.3.3.3.cmml" xref="S4.E6.m1.4.4.1.3.3.3"><csymbol cd="ambiguous" id="S4.E6.m1.4.4.1.3.3.3.1.cmml" xref="S4.E6.m1.4.4.1.3.3.3">subscript</csymbol><ci id="S4.E6.m1.4.4.1.3.3.3.2.cmml" xref="S4.E6.m1.4.4.1.3.3.3.2">ğ‘š</ci><ci id="S4.E6.m1.4.4.1.3.3.3.3.cmml" xref="S4.E6.m1.4.4.1.3.3.3.3">ğ‘¡</ci></apply></apply></apply><apply id="S4.E6.m1.4.4.1.1.1.1.cmml" xref="S4.E6.m1.4.4.1.1.1"><minus id="S4.E6.m1.4.4.1.1.1.1.3.cmml" xref="S4.E6.m1.4.4.1.1.1.1.3"></minus><apply id="S4.E6.m1.4.4.1.1.1.1.4.cmml" xref="S4.E6.m1.4.4.1.1.1.1.4"><times id="S4.E6.m1.4.4.1.1.1.1.4.1.cmml" xref="S4.E6.m1.4.4.1.1.1.1.4.1"></times><ci id="S4.E6.m1.4.4.1.1.1.1.4.2.cmml" xref="S4.E6.m1.4.4.1.1.1.1.4.2">ğ‘¦</ci><apply id="S4.E6.m1.4.4.1.1.1.1.4.3.1.cmml" xref="S4.E6.m1.4.4.1.1.1.1.4.3.2"><log id="S4.E6.m1.1.1.cmml" xref="S4.E6.m1.1.1"></log><apply id="S4.E6.m1.2.2.cmml" xref="S4.E6.m1.2.2"><ci id="S4.E6.m1.2.2.1.cmml" xref="S4.E6.m1.2.2.1">^</ci><ci id="S4.E6.m1.2.2.2.cmml" xref="S4.E6.m1.2.2.2">ğ‘¦</ci></apply></apply></apply><apply id="S4.E6.m1.4.4.1.1.1.1.2.cmml" xref="S4.E6.m1.4.4.1.1.1.1.2"><times id="S4.E6.m1.4.4.1.1.1.1.2.3.cmml" xref="S4.E6.m1.4.4.1.1.1.1.2.3"></times><apply id="S4.E6.m1.4.4.1.1.1.1.1.1.1.1.cmml" xref="S4.E6.m1.4.4.1.1.1.1.1.1.1"><minus id="S4.E6.m1.4.4.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E6.m1.4.4.1.1.1.1.1.1.1.1.1"></minus><cn type="integer" id="S4.E6.m1.4.4.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E6.m1.4.4.1.1.1.1.1.1.1.1.2">1</cn><ci id="S4.E6.m1.4.4.1.1.1.1.1.1.1.1.3.cmml" xref="S4.E6.m1.4.4.1.1.1.1.1.1.1.1.3">ğ‘¦</ci></apply><apply id="S4.E6.m1.4.4.1.1.1.1.2.2.2.cmml" xref="S4.E6.m1.4.4.1.1.1.1.2.2.1"><log id="S4.E6.m1.3.3.cmml" xref="S4.E6.m1.3.3"></log><apply id="S4.E6.m1.4.4.1.1.1.1.2.2.1.1.1.cmml" xref="S4.E6.m1.4.4.1.1.1.1.2.2.1.1.1"><minus id="S4.E6.m1.4.4.1.1.1.1.2.2.1.1.1.1.cmml" xref="S4.E6.m1.4.4.1.1.1.1.2.2.1.1.1.1"></minus><cn type="integer" id="S4.E6.m1.4.4.1.1.1.1.2.2.1.1.1.2.cmml" xref="S4.E6.m1.4.4.1.1.1.1.2.2.1.1.1.2">1</cn><apply id="S4.E6.m1.4.4.1.1.1.1.2.2.1.1.1.3.cmml" xref="S4.E6.m1.4.4.1.1.1.1.2.2.1.1.1.3"><ci id="S4.E6.m1.4.4.1.1.1.1.2.2.1.1.1.3.1.cmml" xref="S4.E6.m1.4.4.1.1.1.1.2.2.1.1.1.3.1">^</ci><ci id="S4.E6.m1.4.4.1.1.1.1.2.2.1.1.1.3.2.cmml" xref="S4.E6.m1.4.4.1.1.1.1.2.2.1.1.1.3.2">ğ‘¦</ci></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E6.m1.4c">\mathcal{L}=\frac{1}{m_{t}}\sum_{i=1}^{m_{t}}-(y\log(\hat{y})-(1-y)\log(1-\hat{y}))</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
<p id="S4.p3.5" class="ltx_p">For justification of our architecture choices refer to Section 5.</p>
</div>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Experimentation</h2>

<div id="S5.p1" class="ltx_para ltx_noindent">
<p id="S5.p1.1" class="ltx_p">Our initial experimentation was performed using hyperparameters identical to the ones used by <span id="S5.p1.1.1" class="ltx_text ltx_font_bold">Teney et al.</span> However, instead of using the Adadelta optimizer we chose Adamax, and we replaced gated tanh layers with one-layer networks of twice the size because we found these modifications were able to produce a more robust model over a larger range of hyperparameters.</p>
</div>
<div id="S5.p2" class="ltx_para ltx_noindent">
<p id="S5.p2.1" class="ltx_p">In our literature review of VQA models, we found one of the biggest determinants for increased model accuracy were new and improved attention mechanisms. To investigate this pattern, we implemented five new attention modules (A0, A1, A2, A3, APD), as shown in Figure 1. We evaluated these five modules, in addition to the original attention (AP) proposed by <span id="S5.p2.1.1" class="ltx_text ltx_font_bold">Teney et al.</span> and identified the AP, A2, and A3 modules to be the most promising. The model architectures were evaluated based on their performance on the validation set (Equation 5).</p>
</div>
<figure id="S5.F2" class="ltx_figure"><img src="/html/1803.07724/assets/Parameter_Tree.png" id="S5.F2.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="548" height="231" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Graphical representation of attention module architecture evaluation. Six primary attention modules were evaluated, and further investigation was conducted on the three optimally performing modules (A2, A3, AP). The best performing attention module, A3x2, was then used for further hyperparameter tuning.</figcaption>
</figure>
<div id="S5.p3" class="ltx_para ltx_noindent">
<p id="S5.p3.1" class="ltx_p">However, we noticed that many of the attention mechanisms used in literature, including all six that we tested, had a softmax final layer. We hypothesized that this may lead to a signal bottleneck in our model and prevent the model from being able to answer questions about images that required equal attention to several regions of the image. To investigate this, we decided to add multiple attention modules to our model and also added a sigmoid final layer to our best performing attention module at the time (A3) to create A3S (Figure 1).</p>
</div>
<div id="S5.p4" class="ltx_para ltx_noindent">
<p id="S5.p4.1" class="ltx_p">After evaluating these parallel stacked attention modules and their sigmoid variants, we found the A3x2 to perform optimally and decided to pursue all further hyperparameter search using this attention module in our model.</p>
</div>
<div id="S5.p5" class="ltx_para ltx_noindent">
<p id="S5.p5.1" class="ltx_p">Hyperparameters were tuned one at a time and the general flow is presented in Figure 3. We first took our baseline model and investigated the effects of using weight normalization. We found that weight normalization (at the purple layers in Figure 2) improved performance, so we decided to keep it for further hyperparameter tuning. Next, we investigated activation functions and found the leaky ReLU to give optimal performance. At each subsequent hyperparameter step, we found the optimal value and did all following searches using that updated value. The approach may be thought of as a greedy hyperparameter search. This approach was taken over a randomized hyperparameter search due to the large space of hyperparameters searched with relatively few resources.</p>
</div>
<figure id="S5.F3" class="ltx_figure"><img src="/html/1803.07724/assets/Hyperparams.png" id="S5.F3.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="548" height="111" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Hyperparameters and selected values used for experimentation. Boxes highlighted in blue had the highest performance and were selected for the final model.</figcaption>
</figure>
<div id="S5.p6" class="ltx_para ltx_noindent">
<p id="S5.p6.1" class="ltx_p">At each step, we determined the optimal hyperparameters based on validation set accuracy. However as can be seen from Figure 4 our models over-fit the training set given enough epochs. When compared to other papers, we found this to be expected because there is a large disparity between the distribution of questions in the validation and training set. This is understandable because VQA is such an open ended task, with an infinite number of possible image-question-answer triplets.</p>
</div>
<figure id="S5.F4" class="ltx_figure"><img src="/html/1803.07724/assets/FinalModel.png" id="S5.F4.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="274" height="206" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Final model training and validation performance, after hyperparameter search.</figcaption>
</figure>
<div id="S5.p7" class="ltx_para ltx_noindent">
<p id="S5.p7.1" class="ltx_p">Furthermore, the validation set consisted of 60,000 of the total 200,000 images while the training set consisted of a nearly similar amount of 80,000 images. Although our model may have been over-fitting the training set, it is very unlikely that dropout and activation function tuning led to over-fitting of the validation data set.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Results and Discussion</h2>

<div id="S6.p1" class="ltx_para ltx_noindent">
<p id="S6.p1.1" class="ltx_p">After determining the optimal model through experimentation and tuning, we were able to achieve an evaluation score of <span id="S6.p1.1.1" class="ltx_text ltx_font_bold">64.78%</span>, out performing the existing state-of-the-art single modelâ€™s validation score of 63.15% (Table 1).</p>
</div>
<figure id="S6.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>Performance of Our Model vs. State-of-the-Art</figcaption>
<table id="S6.T1.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S6.T1.1.1.1" class="ltx_tr">
<th id="S6.T1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row"><span id="S6.T1.1.1.1.1.1" class="ltx_text ltx_font_bold">MODEL</span></th>
<th id="S6.T1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S6.T1.1.1.1.2.1" class="ltx_text ltx_font_bold">VAL PERFORMANCE SCORE</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S6.T1.1.2.1" class="ltx_tr">
<th id="S6.T1.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Our Model</th>
<td id="S6.T1.1.2.1.2" class="ltx_td ltx_align_left ltx_border_t">Score <span id="S6.T1.1.2.1.2.1" class="ltx_text ltx_font_bold">64.78</span> %</td>
</tr>
<tr id="S6.T1.1.3.2" class="ltx_tr">
<th id="S6.T1.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Teney et al. Model</th>
<td id="S6.T1.1.3.2.2" class="ltx_td ltx_align_left">Score 63.15 %</td>
</tr>
</tbody>
</table>
</figure>
<figure id="S6.F5" class="ltx_figure"><img src="/html/1803.07724/assets/Attention.png" id="S6.F5.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="548" height="150" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Each attention module is able to pick up on different features of an input image.</figcaption>
</figure>
<div id="S6.p2" class="ltx_para ltx_noindent">
<p id="S6.p2.1" class="ltx_p">We believe one of the most significant reasons our score was able to beat the state-of-the art results was because of the more sophisticated attention mechanism. The final model used attention mechanism A3x2, which takes two A3 attention mechanisms and stacks them in parallel with the ability to focus on multiple aspects of an image. Figure 5 contains three heatmaps to show how adding a second attention mechanism allows the model to learn different aspects of an input image. As you can see form Image 1, for simple attention tasks both of our attention mechanisms are able to find the appropriate locations in the image. However, in Image 2 you can see when the task requires the need to focus highly on multiple locations in an image our model has an edge over previously presented models, which in theory leads to its increased accuracy. However for more complicated tasks such as image 3, the dual attention mechanism seems to get confused, providing no obvious advantages.</p>
</div>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Limitations, Future Work, and Conclusion</h2>

<div id="S7.p1" class="ltx_para ltx_noindent">
<p id="S7.p1.1" class="ltx_p">While our computational and time resources were limited as a result of class deadlines and budget, we were able to begin an extensive architecture and hyperparameter search. Our future work would look at the synergistic effects of some of these hyperparameters, as well as experiment with how a bi-directional attention mechanism would impact performance. Further we would like to ensemble our models so that an accurate comparison could be made with he state of the art models on the test data. However Teney et al. like many others ensembled 30 models to get state of the art performance which was unfeasible for us with our resources.</p>
</div>
<div id="S7.p2" class="ltx_para ltx_noindent">
<p id="S7.p2.1" class="ltx_p">Visual Question Answering is a unique challenge in modern Artificial Intelligence research as it combines learnings from both Computer Vision and Natural Language Processing. This paper presented our findings on what can be done to improve performance in VQA tasks and further expands upon preexisting work by improving the modelâ€™s image features, creating new attention mechanisms, and adding a simple classifier. We were able to surpass existing state-of-the art results, and we hope the insights learned from the completion of this project will inform further progress in this task.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bibx1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[AAL<sup id="bib.bibx1.4.4.1" class="ltx_sup"><span id="bib.bibx1.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>15]</span>
<span class="ltx_bibblock">
Stanislaw Antol, Aishwarya Agrawal, Jiasen Lu, Margaret Mitchell, Dhruv Batra,
CÂ LawrenceÂ Zitnick, and Devi Parikh.

</span>
<span class="ltx_bibblock">Vqa: Visual question answering.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx1.7.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE International Conference on Computer
Vision</span>, pages 2425â€“2433, 2015.

</span>
</li>
<li id="bib.bibx2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[AHB<sup id="bib.bibx2.4.4.1" class="ltx_sup"><span id="bib.bibx2.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>17]</span>
<span class="ltx_bibblock">
Peter Anderson, Xiaodong He, Chris Buehler, Damien Teney, Mark Johnson, Stephen
Gould, and Lei Zhang.

</span>
<span class="ltx_bibblock">Bottom-up and top-down attention for image captioning and vqa.

</span>
<span class="ltx_bibblock"><span id="bib.bibx2.7.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1707.07998</span>, 2017.

</span>
</li>
<li id="bib.bibx3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[GKSS<sup id="bib.bibx3.4.4.1" class="ltx_sup"><span id="bib.bibx3.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>17]</span>
<span class="ltx_bibblock">
Yash Goyal, Tejas Khot, Douglas Summers-Stay, Dhruv Batra, and Devi Parikh.

</span>
<span class="ltx_bibblock">Making the v in vqa matter: Elevating the role of image understanding
in visual question answering.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx3.7.1" class="ltx_text ltx_font_italic">CVPR</span>, volumeÂ 1, pageÂ 9, 2017.

</span>
</li>
<li id="bib.bibx4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[KIS<sup id="bib.bibx4.4.4.1" class="ltx_sup"><span id="bib.bibx4.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>15]</span>
<span class="ltx_bibblock">
Ankit Kumar, Ozan Irsoy, Jonathan Su, James Bradbury, Robert English, Brian
Pierce, Peter Ondruska, Ishaan Gulrajani, and Richard Socher.

</span>
<span class="ltx_bibblock">Ask me anything: Dynamic memory networks for natural language
processing.

</span>
<span class="ltx_bibblock"><span id="bib.bibx4.7.1" class="ltx_text ltx_font_italic">CoRR</span>, abs/1506.07285, 2015.

</span>
</li>
<li id="bib.bibx5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[PSM14]</span>
<span class="ltx_bibblock">
Jeffrey Pennington, Richard Socher, and Christopher Manning.

</span>
<span class="ltx_bibblock">Glove: Global vectors for word representation.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx5.1.1" class="ltx_text ltx_font_italic">Proceedings of the 2014 conference on empirical methods in
natural language processing (EMNLP)</span>, pages 1532â€“1543, 2014.

</span>
</li>
<li id="bib.bibx6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[TAHvdH17]</span>
<span class="ltx_bibblock">
Damien Teney, Peter Anderson, Xiaodong He, and Anton vanÂ den Hengel.

</span>
<span class="ltx_bibblock">Tips and tricks for visual question answering: Learnings from the
2017 challenge.

</span>
<span class="ltx_bibblock"><span id="bib.bibx6.1.1" class="ltx_text ltx_font_italic">CoRR</span>, abs/1708.02711, 2017.

</span>
</li>
<li id="bib.bibx7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[VTBE16]</span>
<span class="ltx_bibblock">
Oriol Vinyals, Alexander Toshev, Samy Bengio, and Dumitru Erhan.

</span>
<span class="ltx_bibblock">Show and tell: Lessons learned from the 2015 MSCOCO image
captioning challenge.

</span>
<span class="ltx_bibblock"><span id="bib.bibx7.1.1" class="ltx_text ltx_font_italic">CoRR</span>, abs/1609.06647, 2016.

</span>
</li>
<li id="bib.bibx8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[XBK<sup id="bib.bibx8.4.4.1" class="ltx_sup"><span id="bib.bibx8.4.4.1.1" class="ltx_text ltx_font_italic">+</span></sup>15]</span>
<span class="ltx_bibblock">
Kelvin Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho, AaronÂ C. Courville, Ruslan
Salakhutdinov, RichardÂ S. Zemel, and Yoshua Bengio.

</span>
<span class="ltx_bibblock">Show, attend and tell: Neural image caption generation with visual
attention.

</span>
<span class="ltx_bibblock"><span id="bib.bibx8.7.1" class="ltx_text ltx_font_italic">CoRR</span>, abs/1502.03044, 2015.

</span>
</li>
<li id="bib.bibx9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[XMS16]</span>
<span class="ltx_bibblock">
Caiming Xiong, Stephen Merity, and Richard Socher.

</span>
<span class="ltx_bibblock">Dynamic memory networks for visual and textual question answering.

</span>
<span class="ltx_bibblock"><span id="bib.bibx9.1.1" class="ltx_text ltx_font_italic">CoRR</span>, abs/1603.01417, 2016.

</span>
</li>
</ul>
</section>
<div id="p1" class="ltx_para ltx_noindent">
<p id="p1.1" class="ltx_p">Our code builds upon and uses all the preprocessing presented by https://github.com/hengyuan-hu/bottom-up-attention-vqa</p>
</div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/1803.07723" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/1803.07724" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+1803.07724">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/1803.07724" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/1803.07725" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sun Mar  3 10:58:22 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
