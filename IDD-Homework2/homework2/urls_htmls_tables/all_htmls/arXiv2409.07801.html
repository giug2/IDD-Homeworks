<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>SURGIVID: Annotation-Efficient Surgical Video Object Discovery</title>
<!--Generated on Thu Sep 12 06:55:33 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="S" lang="en" name="keywords"/>
<base href="/html/2409.07801v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#S1" title="In SURGIVID: Annotation-Efficient Surgical Video Object Discovery"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#S2" title="In SURGIVID: Annotation-Efficient Surgical Video Object Discovery"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Methodology</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#S2.SS1" title="In 2 Methodology â€£ SURGIVID: Annotation-Efficient Surgical Video Object Discovery"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Object Discovery</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#S2.SS2" title="In 2 Methodology â€£ SURGIVID: Annotation-Efficient Surgical Video Object Discovery"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>DINO Weak Supervision</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#S2.SS3" title="In 2 Methodology â€£ SURGIVID: Annotation-Efficient Surgical Video Object Discovery"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Self-Training</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#S3" title="In SURGIVID: Annotation-Efficient Surgical Video Object Discovery"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Evaluation</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#S3.SS1" title="In 3 Evaluation â€£ SURGIVID: Annotation-Efficient Surgical Video Object Discovery"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Dataset</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#S3.SS2" title="In 3 Evaluation â€£ SURGIVID: Annotation-Efficient Surgical Video Object Discovery"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Metrics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#S3.SS3" title="In 3 Evaluation â€£ SURGIVID: Annotation-Efficient Surgical Video Object Discovery"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Implementation Details</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#S3.SS3.SSS1" title="In 3.3 Implementation Details â€£ 3 Evaluation â€£ SURGIVID: Annotation-Efficient Surgical Video Object Discovery"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3.1 </span>Self-training and Weak Supervision</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#S3.SS3.SSS2" title="In 3.3 Implementation Details â€£ 3 Evaluation â€£ SURGIVID: Annotation-Efficient Surgical Video Object Discovery"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3.2 </span>Fine-tuning</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#S3.SS4" title="In 3 Evaluation â€£ SURGIVID: Annotation-Efficient Surgical Video Object Discovery"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4 </span>Results and Discussion</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#S3.SS4.SSS1" title="In 3.4 Results and Discussion â€£ 3 Evaluation â€£ SURGIVID: Annotation-Efficient Surgical Video Object Discovery"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4.1 </span>Mask2Former</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#S3.SS4.SSS2" title="In 3.4 Results and Discussion â€£ 3 Evaluation â€£ SURGIVID: Annotation-Efficient Surgical Video Object Discovery"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4.2 </span>MaskCut</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#S3.SS4.SSS3" title="In 3.4 Results and Discussion â€£ 3 Evaluation â€£ SURGIVID: Annotation-Efficient Surgical Video Object Discovery"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4.3 </span>Self-training with Mask2Former</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#S3.SS4.SSS4" title="In 3.4 Results and Discussion â€£ 3 Evaluation â€£ SURGIVID: Annotation-Efficient Surgical Video Object Discovery"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4.4 </span>Fine-tuning with Mask2Former</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#S4" title="In SURGIVID: Annotation-Efficient Surgical Video Object Discovery"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Conclusion</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line"><span class="ltx_note ltx_role_institutetext" id="id1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">institutetext: </span>Carl Zeiss AG, Germany </span></span></span><span class="ltx_note ltx_role_institutetext" id="id2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_note_type">institutetext: </span>Computer Aided Medical Procedures, Technical University of Munich, Germany </span></span></span><span class="ltx_note ltx_role_institutetext" id="id3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_note_type">institutetext: </span>Whiting School of Engineering, Johns Hopkins University, United States</span></span></span>
<h1 class="ltx_title ltx_title_document">SURGIVID: Annotation-Efficient Surgical Video Object Discovery</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Caghan Koksal  
</span><span class="ltx_author_notes">11 2 2</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Ghazal Ghazaei
</span><span class="ltx_author_notes">11</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Nassir Navab
</span><span class="ltx_author_notes">2233</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id1.1">Surgical scenes convey crucial information about the quality of surgery. Pixel-wise localization of tools and anatomical structures is the first task towards deeper surgical analysis for microscopic or endoscopic surgical views. This is typically done via fully-supervised methods which are annotation greedy and in several cases, demanding medical expertise.
Considering the profusion of surgical videos obtained through standardized surgical workflows, we propose an annotation-efficient framework for the semantic segmentation of surgical scenes.
We employ image-based self-supervised object discovery to identify the most salient tools and anatomical structures in surgical videos. These proposals are further refined within a minimally supervised fine-tuning step. Our unsupervised setup reinforced with only 36 annotation labels indicates comparable localization performance with fully-supervised segmentation models. Further, leveraging surgical phase labels as weak labels can better guide model attention towards surgical tools, leading to <math alttext="\sim 2\%" class="ltx_Math" display="inline" id="id1.1.m1.1"><semantics id="id1.1.m1.1a"><mrow id="id1.1.m1.1.1" xref="id1.1.m1.1.1.cmml"><mi id="id1.1.m1.1.1.2" xref="id1.1.m1.1.1.2.cmml"></mi><mo id="id1.1.m1.1.1.1" xref="id1.1.m1.1.1.1.cmml">âˆ¼</mo><mrow id="id1.1.m1.1.1.3" xref="id1.1.m1.1.1.3.cmml"><mn id="id1.1.m1.1.1.3.2" xref="id1.1.m1.1.1.3.2.cmml">2</mn><mo id="id1.1.m1.1.1.3.1" xref="id1.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="id1.1.m1.1b"><apply id="id1.1.m1.1.1.cmml" xref="id1.1.m1.1.1"><csymbol cd="latexml" id="id1.1.m1.1.1.1.cmml" xref="id1.1.m1.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="id1.1.m1.1.1.2.cmml" xref="id1.1.m1.1.1.2">absent</csymbol><apply id="id1.1.m1.1.1.3.cmml" xref="id1.1.m1.1.1.3"><csymbol cd="latexml" id="id1.1.m1.1.1.3.1.cmml" xref="id1.1.m1.1.1.3.1">percent</csymbol><cn id="id1.1.m1.1.1.3.2.cmml" type="integer" xref="id1.1.m1.1.1.3.2">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="id1.1.m1.1c">\sim 2\%</annotation><annotation encoding="application/x-llamapun" id="id1.1.m1.1d">âˆ¼ 2 %</annotation></semantics></math> improvement in tool localization.
Extensive ablation studies on the CaDIS dataset validate the effectiveness of our proposed solution in discovering relevant surgical objects with minimal or no supervision.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Keywords: </h6>S
</div>
<div class="ltx_para" id="p1">
<p class="ltx_p" id="p1.1">emantic Segmentation, Object Discovery, Minimal Supervision,</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Surgical videos encode a rich amount of information about surgical scenes, understanding of which can provide deeper insights into the quality of the surgeryÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#bib.bib1" title="">1</a>]</cite> as well as surgical workflowÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#bib.bib2" title="">2</a>]</cite>. A spatio-temporal semantic understanding of the surgical scene can be leveraged for computer-assisted interventionsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#bib.bib20" title="">20</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#bib.bib15" title="">15</a>]</cite> as well as offline surgery analysis for surgical skill improvementÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#bib.bib23" title="">23</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#bib.bib9" title="">9</a>]</cite>, patient care optimizationÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#bib.bib13" title="">13</a>]</cite> and education. Considering the benefits and availability of abundant surgical videos for microscopic and endoscopic surgeriesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#bib.bib10" title="">10</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#bib.bib19" title="">19</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#bib.bib25" title="">25</a>]</cite>, surgical procedures are still far from vast exploitation of surgical videos into their workflows. Besides the computational burden of video processing, video annotation is a major hindering factor for bringing surgical scene understanding solutions into practice. While pixel-wise annotation of surgical videos could be time-consuming and burdensome, requirement of medical expertise and additional temporal dimension can lead to increasing cost and difficulty of annotation. Although investigated broadly by both computer visionÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#bib.bib6" title="">6</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#bib.bib5" title="">5</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#bib.bib17" title="">17</a>]</cite> and medicalÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#bib.bib8" title="">8</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#bib.bib16" title="">16</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#bib.bib24" title="">24</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#bib.bib4" title="">4</a>]</cite> communities, the task of semantic segmentation is still among the most challenging tasks of image and video understanding. More recent advancements endeavor to tackle this problem by leveraging features of self-supervised foundation models such as DINO <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#bib.bib3" title="">3</a>]</cite>
LOSTÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#bib.bib18" title="">18</a>]</cite> and TokencutÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#bib.bib22" title="">22</a>]</cite> leveraged DINO features towards self-supervised detection and segmentation models respectively. In LOST, authors proposed to use key feature vector of the last attention layer of DINO and calculate the patch similarities. TokencutÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#bib.bib22" title="">22</a>]</cite> formulated object discovery as graph partitioning problem. The efficacy of this method is confined to predicting only the most salient object, thereby being incapable of predicting multiple objects. Mostly, some annotated labels are still needed to ensure a reliable semantic segmentation especially in the case of medical domain, which can benefit less from foundation models. Taking advantage of the foundation modelsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#bib.bib3" title="">3</a>]</cite>, recent developments in object discovery indicate huge progress in unsupervised object localizationÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#bib.bib22" title="">22</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#bib.bib21" title="">21</a>]</cite>. In this work, we introduce a minimal-annotation workflow for pixel-wise semantic segmentation in cataract surgery which can promote new possibilities for conducting annotations in the medical domain. Our contributions can be summarized as follows:</p>
</div>
<div class="ltx_para" id="S1.p2">
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">We successfully leverage the state-of-the-art in object discovery to localize the most influential components of the cataract surgery scene.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">We further exploit a self-training step using a Mask2Former model. This step refines unsupervisedly generated masks and identifies new masks corresponding to missing objects. Injecting minimal annotations into these identified masks leads to comparable pixel-wise localization accuracy to a fully-supervised method.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">We demonstrate that leveraging weak labels can effectively guide the modelâ€™s attention towards the objects of interest within the scene.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S1.I1.i4.p1">
<p class="ltx_p" id="S1.I1.i4.p1.1">We highlight the efficacy of our annotation-efficient framework through comprehensive ablation studies on pixel-wise semantic segmentation of cataract videos, thereby emphasizing its impact.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Methodology</h2>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Object Discovery</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">Our backbone model features DINOÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#bib.bib3" title="">3</a>]</cite>, a self-supervised model leveraging self-distillation, contrastive learning and Vision Transformers (ViT) Â <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#bib.bib7" title="">7</a>]</cite>. DINO attention maps tend to be highly accurate indicating impressive potential in learning both local and global scene features which can be further exploited in downstream tasks such as semantic segmentation.</p>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.3">In this work, we leveraged CutLERÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#bib.bib21" title="">21</a>]</cite> workflow to optimize the amount of annotations for semantic segmentation of surgical scenes within cataract surgery. Taking advantage of robust and informative attention of DINO, we generate class-agnostic pseudo segmentation masks using MaskCutÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#bib.bib21" title="">21</a>]</cite>. Each image is partitioned into equally-sized patches and fed into a pre-trained self-supervised DINO model to extract rich patch features represented by key vectors of the last attention layer. The cosine similarity between patches is then calculated to create an affinity matrix.</p>
<table class="ltx_equation ltx_eqn_table" id="S2.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="W_{i,j}=\frac{K_{i}K_{j}}{{|K_{i}|}_{2}{|K_{j}|}_{2}}" class="ltx_Math" display="block" id="S2.E1.m1.4"><semantics id="S2.E1.m1.4a"><mrow id="S2.E1.m1.4.5" xref="S2.E1.m1.4.5.cmml"><msub id="S2.E1.m1.4.5.2" xref="S2.E1.m1.4.5.2.cmml"><mi id="S2.E1.m1.4.5.2.2" xref="S2.E1.m1.4.5.2.2.cmml">W</mi><mrow id="S2.E1.m1.2.2.2.4" xref="S2.E1.m1.2.2.2.3.cmml"><mi id="S2.E1.m1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.cmml">i</mi><mo id="S2.E1.m1.2.2.2.4.1" xref="S2.E1.m1.2.2.2.3.cmml">,</mo><mi id="S2.E1.m1.2.2.2.2" xref="S2.E1.m1.2.2.2.2.cmml">j</mi></mrow></msub><mo id="S2.E1.m1.4.5.1" xref="S2.E1.m1.4.5.1.cmml">=</mo><mfrac id="S2.E1.m1.4.4" xref="S2.E1.m1.4.4.cmml"><mrow id="S2.E1.m1.4.4.4" xref="S2.E1.m1.4.4.4.cmml"><msub id="S2.E1.m1.4.4.4.2" xref="S2.E1.m1.4.4.4.2.cmml"><mi id="S2.E1.m1.4.4.4.2.2" xref="S2.E1.m1.4.4.4.2.2.cmml">K</mi><mi id="S2.E1.m1.4.4.4.2.3" xref="S2.E1.m1.4.4.4.2.3.cmml">i</mi></msub><mo id="S2.E1.m1.4.4.4.1" xref="S2.E1.m1.4.4.4.1.cmml">â¢</mo><msub id="S2.E1.m1.4.4.4.3" xref="S2.E1.m1.4.4.4.3.cmml"><mi id="S2.E1.m1.4.4.4.3.2" xref="S2.E1.m1.4.4.4.3.2.cmml">K</mi><mi id="S2.E1.m1.4.4.4.3.3" xref="S2.E1.m1.4.4.4.3.3.cmml">j</mi></msub></mrow><mrow id="S2.E1.m1.4.4.2" xref="S2.E1.m1.4.4.2.cmml"><msub id="S2.E1.m1.3.3.1.1" xref="S2.E1.m1.3.3.1.1.cmml"><mrow id="S2.E1.m1.3.3.1.1.1.1" xref="S2.E1.m1.3.3.1.1.1.2.cmml"><mo id="S2.E1.m1.3.3.1.1.1.1.2" stretchy="false" xref="S2.E1.m1.3.3.1.1.1.2.1.cmml">|</mo><msub id="S2.E1.m1.3.3.1.1.1.1.1" xref="S2.E1.m1.3.3.1.1.1.1.1.cmml"><mi id="S2.E1.m1.3.3.1.1.1.1.1.2" xref="S2.E1.m1.3.3.1.1.1.1.1.2.cmml">K</mi><mi id="S2.E1.m1.3.3.1.1.1.1.1.3" xref="S2.E1.m1.3.3.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S2.E1.m1.3.3.1.1.1.1.3" stretchy="false" xref="S2.E1.m1.3.3.1.1.1.2.1.cmml">|</mo></mrow><mn id="S2.E1.m1.3.3.1.1.3" xref="S2.E1.m1.3.3.1.1.3.cmml">2</mn></msub><mo id="S2.E1.m1.4.4.2.3" xref="S2.E1.m1.4.4.2.3.cmml">â¢</mo><msub id="S2.E1.m1.4.4.2.2" xref="S2.E1.m1.4.4.2.2.cmml"><mrow id="S2.E1.m1.4.4.2.2.1.1" xref="S2.E1.m1.4.4.2.2.1.2.cmml"><mo id="S2.E1.m1.4.4.2.2.1.1.2" stretchy="false" xref="S2.E1.m1.4.4.2.2.1.2.1.cmml">|</mo><msub id="S2.E1.m1.4.4.2.2.1.1.1" xref="S2.E1.m1.4.4.2.2.1.1.1.cmml"><mi id="S2.E1.m1.4.4.2.2.1.1.1.2" xref="S2.E1.m1.4.4.2.2.1.1.1.2.cmml">K</mi><mi id="S2.E1.m1.4.4.2.2.1.1.1.3" xref="S2.E1.m1.4.4.2.2.1.1.1.3.cmml">j</mi></msub><mo id="S2.E1.m1.4.4.2.2.1.1.3" stretchy="false" xref="S2.E1.m1.4.4.2.2.1.2.1.cmml">|</mo></mrow><mn id="S2.E1.m1.4.4.2.2.3" xref="S2.E1.m1.4.4.2.2.3.cmml">2</mn></msub></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.4b"><apply id="S2.E1.m1.4.5.cmml" xref="S2.E1.m1.4.5"><eq id="S2.E1.m1.4.5.1.cmml" xref="S2.E1.m1.4.5.1"></eq><apply id="S2.E1.m1.4.5.2.cmml" xref="S2.E1.m1.4.5.2"><csymbol cd="ambiguous" id="S2.E1.m1.4.5.2.1.cmml" xref="S2.E1.m1.4.5.2">subscript</csymbol><ci id="S2.E1.m1.4.5.2.2.cmml" xref="S2.E1.m1.4.5.2.2">ğ‘Š</ci><list id="S2.E1.m1.2.2.2.3.cmml" xref="S2.E1.m1.2.2.2.4"><ci id="S2.E1.m1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1">ğ‘–</ci><ci id="S2.E1.m1.2.2.2.2.cmml" xref="S2.E1.m1.2.2.2.2">ğ‘—</ci></list></apply><apply id="S2.E1.m1.4.4.cmml" xref="S2.E1.m1.4.4"><divide id="S2.E1.m1.4.4.3.cmml" xref="S2.E1.m1.4.4"></divide><apply id="S2.E1.m1.4.4.4.cmml" xref="S2.E1.m1.4.4.4"><times id="S2.E1.m1.4.4.4.1.cmml" xref="S2.E1.m1.4.4.4.1"></times><apply id="S2.E1.m1.4.4.4.2.cmml" xref="S2.E1.m1.4.4.4.2"><csymbol cd="ambiguous" id="S2.E1.m1.4.4.4.2.1.cmml" xref="S2.E1.m1.4.4.4.2">subscript</csymbol><ci id="S2.E1.m1.4.4.4.2.2.cmml" xref="S2.E1.m1.4.4.4.2.2">ğ¾</ci><ci id="S2.E1.m1.4.4.4.2.3.cmml" xref="S2.E1.m1.4.4.4.2.3">ğ‘–</ci></apply><apply id="S2.E1.m1.4.4.4.3.cmml" xref="S2.E1.m1.4.4.4.3"><csymbol cd="ambiguous" id="S2.E1.m1.4.4.4.3.1.cmml" xref="S2.E1.m1.4.4.4.3">subscript</csymbol><ci id="S2.E1.m1.4.4.4.3.2.cmml" xref="S2.E1.m1.4.4.4.3.2">ğ¾</ci><ci id="S2.E1.m1.4.4.4.3.3.cmml" xref="S2.E1.m1.4.4.4.3.3">ğ‘—</ci></apply></apply><apply id="S2.E1.m1.4.4.2.cmml" xref="S2.E1.m1.4.4.2"><times id="S2.E1.m1.4.4.2.3.cmml" xref="S2.E1.m1.4.4.2.3"></times><apply id="S2.E1.m1.3.3.1.1.cmml" xref="S2.E1.m1.3.3.1.1"><csymbol cd="ambiguous" id="S2.E1.m1.3.3.1.1.2.cmml" xref="S2.E1.m1.3.3.1.1">subscript</csymbol><apply id="S2.E1.m1.3.3.1.1.1.2.cmml" xref="S2.E1.m1.3.3.1.1.1.1"><abs id="S2.E1.m1.3.3.1.1.1.2.1.cmml" xref="S2.E1.m1.3.3.1.1.1.1.2"></abs><apply id="S2.E1.m1.3.3.1.1.1.1.1.cmml" xref="S2.E1.m1.3.3.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E1.m1.3.3.1.1.1.1.1.1.cmml" xref="S2.E1.m1.3.3.1.1.1.1.1">subscript</csymbol><ci id="S2.E1.m1.3.3.1.1.1.1.1.2.cmml" xref="S2.E1.m1.3.3.1.1.1.1.1.2">ğ¾</ci><ci id="S2.E1.m1.3.3.1.1.1.1.1.3.cmml" xref="S2.E1.m1.3.3.1.1.1.1.1.3">ğ‘–</ci></apply></apply><cn id="S2.E1.m1.3.3.1.1.3.cmml" type="integer" xref="S2.E1.m1.3.3.1.1.3">2</cn></apply><apply id="S2.E1.m1.4.4.2.2.cmml" xref="S2.E1.m1.4.4.2.2"><csymbol cd="ambiguous" id="S2.E1.m1.4.4.2.2.2.cmml" xref="S2.E1.m1.4.4.2.2">subscript</csymbol><apply id="S2.E1.m1.4.4.2.2.1.2.cmml" xref="S2.E1.m1.4.4.2.2.1.1"><abs id="S2.E1.m1.4.4.2.2.1.2.1.cmml" xref="S2.E1.m1.4.4.2.2.1.1.2"></abs><apply id="S2.E1.m1.4.4.2.2.1.1.1.cmml" xref="S2.E1.m1.4.4.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.E1.m1.4.4.2.2.1.1.1.1.cmml" xref="S2.E1.m1.4.4.2.2.1.1.1">subscript</csymbol><ci id="S2.E1.m1.4.4.2.2.1.1.1.2.cmml" xref="S2.E1.m1.4.4.2.2.1.1.1.2">ğ¾</ci><ci id="S2.E1.m1.4.4.2.2.1.1.1.3.cmml" xref="S2.E1.m1.4.4.2.2.1.1.1.3">ğ‘—</ci></apply></apply><cn id="S2.E1.m1.4.4.2.2.3.cmml" type="integer" xref="S2.E1.m1.4.4.2.2.3">2</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.4c">W_{i,j}=\frac{K_{i}K_{j}}{{|K_{i}|}_{2}{|K_{j}|}_{2}}</annotation><annotation encoding="application/x-llamapun" id="S2.E1.m1.4d">italic_W start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT = divide start_ARG italic_K start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_K start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT end_ARG start_ARG | italic_K start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT | italic_K start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT | start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S2.SS1.p2.2">where <math alttext="K_{i}" class="ltx_Math" display="inline" id="S2.SS1.p2.1.m1.1"><semantics id="S2.SS1.p2.1.m1.1a"><msub id="S2.SS1.p2.1.m1.1.1" xref="S2.SS1.p2.1.m1.1.1.cmml"><mi id="S2.SS1.p2.1.m1.1.1.2" xref="S2.SS1.p2.1.m1.1.1.2.cmml">K</mi><mi id="S2.SS1.p2.1.m1.1.1.3" xref="S2.SS1.p2.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.1.m1.1b"><apply id="S2.SS1.p2.1.m1.1.1.cmml" xref="S2.SS1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.1.m1.1.1.1.cmml" xref="S2.SS1.p2.1.m1.1.1">subscript</csymbol><ci id="S2.SS1.p2.1.m1.1.1.2.cmml" xref="S2.SS1.p2.1.m1.1.1.2">ğ¾</ci><ci id="S2.SS1.p2.1.m1.1.1.3.cmml" xref="S2.SS1.p2.1.m1.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.1.m1.1c">K_{i}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p2.1.m1.1d">italic_K start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="K_{j}" class="ltx_Math" display="inline" id="S2.SS1.p2.2.m2.1"><semantics id="S2.SS1.p2.2.m2.1a"><msub id="S2.SS1.p2.2.m2.1.1" xref="S2.SS1.p2.2.m2.1.1.cmml"><mi id="S2.SS1.p2.2.m2.1.1.2" xref="S2.SS1.p2.2.m2.1.1.2.cmml">K</mi><mi id="S2.SS1.p2.2.m2.1.1.3" xref="S2.SS1.p2.2.m2.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.2.m2.1b"><apply id="S2.SS1.p2.2.m2.1.1.cmml" xref="S2.SS1.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.2.m2.1.1.1.cmml" xref="S2.SS1.p2.2.m2.1.1">subscript</csymbol><ci id="S2.SS1.p2.2.m2.1.1.2.cmml" xref="S2.SS1.p2.2.m2.1.1.2">ğ¾</ci><ci id="S2.SS1.p2.2.m2.1.1.3.cmml" xref="S2.SS1.p2.2.m2.1.1.3">ğ‘—</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.2.m2.1c">K_{j}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p2.2.m2.1d">italic_K start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math> are the key features of patch i and j, respectively.</p>
</div>
<div class="ltx_para" id="S2.SS1.p3">
<p class="ltx_p" id="S2.SS1.p3.1">Segmentation mask generation can be formulated as a graph partitioning task. Nodes of the graphs are the image patches and affinity matrix is used as an adjacency matrix. Then, the graph bi-partition is created by solving the N-cut problem.
Bi-partitions are then converted to a foreground binary mask by selecting the bipartition that includes the most salient patch. After finding the first foreground object, the affinity matrix is re-masked to solve the N-cut problem on the masked affinity matrix. The above steps are iteratively followed until the number of maximum expected instances are reached.
As a second step, the generated unsupervised masks are used as pseudo-masks to train instance segmentation models.</p>
</div>
<figure class="ltx_figure" id="S2.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="150" id="S2.F1.g1" src="extracted/5849807/figures/attention.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>An illustration of DINOÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#bib.bib3" title="">3</a>]</cite> attention maps for 12 different heads. a) Pretrained with ImageNet: Main anatomical structure and tools can be seen in the attention maps. b) Pretrained with ImageNet and fine-tuned on phase labels: attention maps are more focused on the surgical tools since tools include strong cues to detect the surgical phase of the surgery.</figcaption>
</figure>
<figure class="ltx_figure" id="S2.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="247" id="S2.F2.g1" src="extracted/5849807/figures/method.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Overview of suggested workflow for unsupervised surgical scene segmentation: a. A pretrained DINO (optionally fine-tuned on phase labels in a multi-task learning setting) is used to extract rich scene features. Features are then leveraged within MaskCutÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#bib.bib21" title="">21</a>]</cite> to generate initial course masks of salient objects within the scene. The produced masks are further refined within a self-training step using Mask2formerÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#bib.bib6" title="">6</a>]</cite>. b. The Mask2Former pre-trained with pseudo-labels can then be fine-tuned with <math alttext="X\%" class="ltx_Math" display="inline" id="S2.F2.2.m1.1"><semantics id="S2.F2.2.m1.1b"><mrow id="S2.F2.2.m1.1.1" xref="S2.F2.2.m1.1.1.cmml"><mi id="S2.F2.2.m1.1.1.2" xref="S2.F2.2.m1.1.1.2.cmml">X</mi><mo id="S2.F2.2.m1.1.1.1" xref="S2.F2.2.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.F2.2.m1.1c"><apply id="S2.F2.2.m1.1.1.cmml" xref="S2.F2.2.m1.1.1"><csymbol cd="latexml" id="S2.F2.2.m1.1.1.1.cmml" xref="S2.F2.2.m1.1.1.1">percent</csymbol><ci id="S2.F2.2.m1.1.1.2.cmml" xref="S2.F2.2.m1.1.1.2">ğ‘‹</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.2.m1.1d">X\%</annotation><annotation encoding="application/x-llamapun" id="S2.F2.2.m1.1e">italic_X %</annotation></semantics></math> annotated masks.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>DINO Weak Supervision</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.4">To investigate the possibility of manipulating and further guiding the generated masks from MaskCut, we examined the usage of weak supervision from phase labels of the cataract surgery videos. We hypothesized that phase labels can deviate model attention to specific objects within the scene crucial for deciding on a phase, e.g. surgical tools. As such, we fine-tuned DINO in a multi-task learning scheme with surgical phase labels of the CATARACTS datasetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#bib.bib1" title="">1</a>]</cite>. We used <math alttext="[CLS]" class="ltx_Math" display="inline" id="S2.SS2.p1.1.m1.1"><semantics id="S2.SS2.p1.1.m1.1a"><mrow id="S2.SS2.p1.1.m1.1.1.1" xref="S2.SS2.p1.1.m1.1.1.2.cmml"><mo id="S2.SS2.p1.1.m1.1.1.1.2" stretchy="false" xref="S2.SS2.p1.1.m1.1.1.2.1.cmml">[</mo><mrow id="S2.SS2.p1.1.m1.1.1.1.1" xref="S2.SS2.p1.1.m1.1.1.1.1.cmml"><mi id="S2.SS2.p1.1.m1.1.1.1.1.2" xref="S2.SS2.p1.1.m1.1.1.1.1.2.cmml">C</mi><mo id="S2.SS2.p1.1.m1.1.1.1.1.1" xref="S2.SS2.p1.1.m1.1.1.1.1.1.cmml">â¢</mo><mi id="S2.SS2.p1.1.m1.1.1.1.1.3" xref="S2.SS2.p1.1.m1.1.1.1.1.3.cmml">L</mi><mo id="S2.SS2.p1.1.m1.1.1.1.1.1a" xref="S2.SS2.p1.1.m1.1.1.1.1.1.cmml">â¢</mo><mi id="S2.SS2.p1.1.m1.1.1.1.1.4" xref="S2.SS2.p1.1.m1.1.1.1.1.4.cmml">S</mi></mrow><mo id="S2.SS2.p1.1.m1.1.1.1.3" stretchy="false" xref="S2.SS2.p1.1.m1.1.1.2.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.1.m1.1b"><apply id="S2.SS2.p1.1.m1.1.1.2.cmml" xref="S2.SS2.p1.1.m1.1.1.1"><csymbol cd="latexml" id="S2.SS2.p1.1.m1.1.1.2.1.cmml" xref="S2.SS2.p1.1.m1.1.1.1.2">delimited-[]</csymbol><apply id="S2.SS2.p1.1.m1.1.1.1.1.cmml" xref="S2.SS2.p1.1.m1.1.1.1.1"><times id="S2.SS2.p1.1.m1.1.1.1.1.1.cmml" xref="S2.SS2.p1.1.m1.1.1.1.1.1"></times><ci id="S2.SS2.p1.1.m1.1.1.1.1.2.cmml" xref="S2.SS2.p1.1.m1.1.1.1.1.2">ğ¶</ci><ci id="S2.SS2.p1.1.m1.1.1.1.1.3.cmml" xref="S2.SS2.p1.1.m1.1.1.1.1.3">ğ¿</ci><ci id="S2.SS2.p1.1.m1.1.1.1.1.4.cmml" xref="S2.SS2.p1.1.m1.1.1.1.1.4">ğ‘†</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.1.m1.1c">[CLS]</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p1.1.m1.1d">[ italic_C italic_L italic_S ]</annotation></semantics></math> tokenâ€™s feature and added linear layer on top to finetune DINO. Attention maps of surgical phase-guided DINO are illustrated in Figure Â <a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#S2.F1" title="Figure 1 â€£ 2.1 Object Discovery â€£ 2 Methodology â€£ SURGIVID: Annotation-Efficient Surgical Video Object Discovery"><span class="ltx_text ltx_ref_tag">1</span></a> highlighting surgical instruments more elaborately.
The training loss consists of surgical phase classification loss and DINO loss: <math alttext="\mathcal{L}_{multi\_task}=\lambda_{cls}\mathcal{L}_{cls}+\lambda_{dino}%
\mathcal{L}_{dino}" class="ltx_Math" display="inline" id="S2.SS2.p1.2.m2.1"><semantics id="S2.SS2.p1.2.m2.1a"><mrow id="S2.SS2.p1.2.m2.1.1" xref="S2.SS2.p1.2.m2.1.1.cmml"><msub id="S2.SS2.p1.2.m2.1.1.2" xref="S2.SS2.p1.2.m2.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p1.2.m2.1.1.2.2" xref="S2.SS2.p1.2.m2.1.1.2.2.cmml">â„’</mi><mrow id="S2.SS2.p1.2.m2.1.1.2.3" xref="S2.SS2.p1.2.m2.1.1.2.3.cmml"><mi id="S2.SS2.p1.2.m2.1.1.2.3.2" xref="S2.SS2.p1.2.m2.1.1.2.3.2.cmml">m</mi><mo id="S2.SS2.p1.2.m2.1.1.2.3.1" xref="S2.SS2.p1.2.m2.1.1.2.3.1.cmml">â¢</mo><mi id="S2.SS2.p1.2.m2.1.1.2.3.3" xref="S2.SS2.p1.2.m2.1.1.2.3.3.cmml">u</mi><mo id="S2.SS2.p1.2.m2.1.1.2.3.1a" xref="S2.SS2.p1.2.m2.1.1.2.3.1.cmml">â¢</mo><mi id="S2.SS2.p1.2.m2.1.1.2.3.4" xref="S2.SS2.p1.2.m2.1.1.2.3.4.cmml">l</mi><mo id="S2.SS2.p1.2.m2.1.1.2.3.1b" xref="S2.SS2.p1.2.m2.1.1.2.3.1.cmml">â¢</mo><mi id="S2.SS2.p1.2.m2.1.1.2.3.5" xref="S2.SS2.p1.2.m2.1.1.2.3.5.cmml">t</mi><mo id="S2.SS2.p1.2.m2.1.1.2.3.1c" xref="S2.SS2.p1.2.m2.1.1.2.3.1.cmml">â¢</mo><mi id="S2.SS2.p1.2.m2.1.1.2.3.6" xref="S2.SS2.p1.2.m2.1.1.2.3.6.cmml">i</mi><mo id="S2.SS2.p1.2.m2.1.1.2.3.1d" xref="S2.SS2.p1.2.m2.1.1.2.3.1.cmml">â¢</mo><mi id="S2.SS2.p1.2.m2.1.1.2.3.7" mathvariant="normal" xref="S2.SS2.p1.2.m2.1.1.2.3.7.cmml">_</mi><mo id="S2.SS2.p1.2.m2.1.1.2.3.1e" xref="S2.SS2.p1.2.m2.1.1.2.3.1.cmml">â¢</mo><mi id="S2.SS2.p1.2.m2.1.1.2.3.8" xref="S2.SS2.p1.2.m2.1.1.2.3.8.cmml">t</mi><mo id="S2.SS2.p1.2.m2.1.1.2.3.1f" xref="S2.SS2.p1.2.m2.1.1.2.3.1.cmml">â¢</mo><mi id="S2.SS2.p1.2.m2.1.1.2.3.9" xref="S2.SS2.p1.2.m2.1.1.2.3.9.cmml">a</mi><mo id="S2.SS2.p1.2.m2.1.1.2.3.1g" xref="S2.SS2.p1.2.m2.1.1.2.3.1.cmml">â¢</mo><mi id="S2.SS2.p1.2.m2.1.1.2.3.10" xref="S2.SS2.p1.2.m2.1.1.2.3.10.cmml">s</mi><mo id="S2.SS2.p1.2.m2.1.1.2.3.1h" xref="S2.SS2.p1.2.m2.1.1.2.3.1.cmml">â¢</mo><mi id="S2.SS2.p1.2.m2.1.1.2.3.11" xref="S2.SS2.p1.2.m2.1.1.2.3.11.cmml">k</mi></mrow></msub><mo id="S2.SS2.p1.2.m2.1.1.1" xref="S2.SS2.p1.2.m2.1.1.1.cmml">=</mo><mrow id="S2.SS2.p1.2.m2.1.1.3" xref="S2.SS2.p1.2.m2.1.1.3.cmml"><mrow id="S2.SS2.p1.2.m2.1.1.3.2" xref="S2.SS2.p1.2.m2.1.1.3.2.cmml"><msub id="S2.SS2.p1.2.m2.1.1.3.2.2" xref="S2.SS2.p1.2.m2.1.1.3.2.2.cmml"><mi id="S2.SS2.p1.2.m2.1.1.3.2.2.2" xref="S2.SS2.p1.2.m2.1.1.3.2.2.2.cmml">Î»</mi><mrow id="S2.SS2.p1.2.m2.1.1.3.2.2.3" xref="S2.SS2.p1.2.m2.1.1.3.2.2.3.cmml"><mi id="S2.SS2.p1.2.m2.1.1.3.2.2.3.2" xref="S2.SS2.p1.2.m2.1.1.3.2.2.3.2.cmml">c</mi><mo id="S2.SS2.p1.2.m2.1.1.3.2.2.3.1" xref="S2.SS2.p1.2.m2.1.1.3.2.2.3.1.cmml">â¢</mo><mi id="S2.SS2.p1.2.m2.1.1.3.2.2.3.3" xref="S2.SS2.p1.2.m2.1.1.3.2.2.3.3.cmml">l</mi><mo id="S2.SS2.p1.2.m2.1.1.3.2.2.3.1a" xref="S2.SS2.p1.2.m2.1.1.3.2.2.3.1.cmml">â¢</mo><mi id="S2.SS2.p1.2.m2.1.1.3.2.2.3.4" xref="S2.SS2.p1.2.m2.1.1.3.2.2.3.4.cmml">s</mi></mrow></msub><mo id="S2.SS2.p1.2.m2.1.1.3.2.1" xref="S2.SS2.p1.2.m2.1.1.3.2.1.cmml">â¢</mo><msub id="S2.SS2.p1.2.m2.1.1.3.2.3" xref="S2.SS2.p1.2.m2.1.1.3.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p1.2.m2.1.1.3.2.3.2" xref="S2.SS2.p1.2.m2.1.1.3.2.3.2.cmml">â„’</mi><mrow id="S2.SS2.p1.2.m2.1.1.3.2.3.3" xref="S2.SS2.p1.2.m2.1.1.3.2.3.3.cmml"><mi id="S2.SS2.p1.2.m2.1.1.3.2.3.3.2" xref="S2.SS2.p1.2.m2.1.1.3.2.3.3.2.cmml">c</mi><mo id="S2.SS2.p1.2.m2.1.1.3.2.3.3.1" xref="S2.SS2.p1.2.m2.1.1.3.2.3.3.1.cmml">â¢</mo><mi id="S2.SS2.p1.2.m2.1.1.3.2.3.3.3" xref="S2.SS2.p1.2.m2.1.1.3.2.3.3.3.cmml">l</mi><mo id="S2.SS2.p1.2.m2.1.1.3.2.3.3.1a" xref="S2.SS2.p1.2.m2.1.1.3.2.3.3.1.cmml">â¢</mo><mi id="S2.SS2.p1.2.m2.1.1.3.2.3.3.4" xref="S2.SS2.p1.2.m2.1.1.3.2.3.3.4.cmml">s</mi></mrow></msub></mrow><mo id="S2.SS2.p1.2.m2.1.1.3.1" xref="S2.SS2.p1.2.m2.1.1.3.1.cmml">+</mo><mrow id="S2.SS2.p1.2.m2.1.1.3.3" xref="S2.SS2.p1.2.m2.1.1.3.3.cmml"><msub id="S2.SS2.p1.2.m2.1.1.3.3.2" xref="S2.SS2.p1.2.m2.1.1.3.3.2.cmml"><mi id="S2.SS2.p1.2.m2.1.1.3.3.2.2" xref="S2.SS2.p1.2.m2.1.1.3.3.2.2.cmml">Î»</mi><mrow id="S2.SS2.p1.2.m2.1.1.3.3.2.3" xref="S2.SS2.p1.2.m2.1.1.3.3.2.3.cmml"><mi id="S2.SS2.p1.2.m2.1.1.3.3.2.3.2" xref="S2.SS2.p1.2.m2.1.1.3.3.2.3.2.cmml">d</mi><mo id="S2.SS2.p1.2.m2.1.1.3.3.2.3.1" xref="S2.SS2.p1.2.m2.1.1.3.3.2.3.1.cmml">â¢</mo><mi id="S2.SS2.p1.2.m2.1.1.3.3.2.3.3" xref="S2.SS2.p1.2.m2.1.1.3.3.2.3.3.cmml">i</mi><mo id="S2.SS2.p1.2.m2.1.1.3.3.2.3.1a" xref="S2.SS2.p1.2.m2.1.1.3.3.2.3.1.cmml">â¢</mo><mi id="S2.SS2.p1.2.m2.1.1.3.3.2.3.4" xref="S2.SS2.p1.2.m2.1.1.3.3.2.3.4.cmml">n</mi><mo id="S2.SS2.p1.2.m2.1.1.3.3.2.3.1b" xref="S2.SS2.p1.2.m2.1.1.3.3.2.3.1.cmml">â¢</mo><mi id="S2.SS2.p1.2.m2.1.1.3.3.2.3.5" xref="S2.SS2.p1.2.m2.1.1.3.3.2.3.5.cmml">o</mi></mrow></msub><mo id="S2.SS2.p1.2.m2.1.1.3.3.1" xref="S2.SS2.p1.2.m2.1.1.3.3.1.cmml">â¢</mo><msub id="S2.SS2.p1.2.m2.1.1.3.3.3" xref="S2.SS2.p1.2.m2.1.1.3.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p1.2.m2.1.1.3.3.3.2" xref="S2.SS2.p1.2.m2.1.1.3.3.3.2.cmml">â„’</mi><mrow id="S2.SS2.p1.2.m2.1.1.3.3.3.3" xref="S2.SS2.p1.2.m2.1.1.3.3.3.3.cmml"><mi id="S2.SS2.p1.2.m2.1.1.3.3.3.3.2" xref="S2.SS2.p1.2.m2.1.1.3.3.3.3.2.cmml">d</mi><mo id="S2.SS2.p1.2.m2.1.1.3.3.3.3.1" xref="S2.SS2.p1.2.m2.1.1.3.3.3.3.1.cmml">â¢</mo><mi id="S2.SS2.p1.2.m2.1.1.3.3.3.3.3" xref="S2.SS2.p1.2.m2.1.1.3.3.3.3.3.cmml">i</mi><mo id="S2.SS2.p1.2.m2.1.1.3.3.3.3.1a" xref="S2.SS2.p1.2.m2.1.1.3.3.3.3.1.cmml">â¢</mo><mi id="S2.SS2.p1.2.m2.1.1.3.3.3.3.4" xref="S2.SS2.p1.2.m2.1.1.3.3.3.3.4.cmml">n</mi><mo id="S2.SS2.p1.2.m2.1.1.3.3.3.3.1b" xref="S2.SS2.p1.2.m2.1.1.3.3.3.3.1.cmml">â¢</mo><mi id="S2.SS2.p1.2.m2.1.1.3.3.3.3.5" xref="S2.SS2.p1.2.m2.1.1.3.3.3.3.5.cmml">o</mi></mrow></msub></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.2.m2.1b"><apply id="S2.SS2.p1.2.m2.1.1.cmml" xref="S2.SS2.p1.2.m2.1.1"><eq id="S2.SS2.p1.2.m2.1.1.1.cmml" xref="S2.SS2.p1.2.m2.1.1.1"></eq><apply id="S2.SS2.p1.2.m2.1.1.2.cmml" xref="S2.SS2.p1.2.m2.1.1.2"><csymbol cd="ambiguous" id="S2.SS2.p1.2.m2.1.1.2.1.cmml" xref="S2.SS2.p1.2.m2.1.1.2">subscript</csymbol><ci id="S2.SS2.p1.2.m2.1.1.2.2.cmml" xref="S2.SS2.p1.2.m2.1.1.2.2">â„’</ci><apply id="S2.SS2.p1.2.m2.1.1.2.3.cmml" xref="S2.SS2.p1.2.m2.1.1.2.3"><times id="S2.SS2.p1.2.m2.1.1.2.3.1.cmml" xref="S2.SS2.p1.2.m2.1.1.2.3.1"></times><ci id="S2.SS2.p1.2.m2.1.1.2.3.2.cmml" xref="S2.SS2.p1.2.m2.1.1.2.3.2">ğ‘š</ci><ci id="S2.SS2.p1.2.m2.1.1.2.3.3.cmml" xref="S2.SS2.p1.2.m2.1.1.2.3.3">ğ‘¢</ci><ci id="S2.SS2.p1.2.m2.1.1.2.3.4.cmml" xref="S2.SS2.p1.2.m2.1.1.2.3.4">ğ‘™</ci><ci id="S2.SS2.p1.2.m2.1.1.2.3.5.cmml" xref="S2.SS2.p1.2.m2.1.1.2.3.5">ğ‘¡</ci><ci id="S2.SS2.p1.2.m2.1.1.2.3.6.cmml" xref="S2.SS2.p1.2.m2.1.1.2.3.6">ğ‘–</ci><ci id="S2.SS2.p1.2.m2.1.1.2.3.7.cmml" xref="S2.SS2.p1.2.m2.1.1.2.3.7">_</ci><ci id="S2.SS2.p1.2.m2.1.1.2.3.8.cmml" xref="S2.SS2.p1.2.m2.1.1.2.3.8">ğ‘¡</ci><ci id="S2.SS2.p1.2.m2.1.1.2.3.9.cmml" xref="S2.SS2.p1.2.m2.1.1.2.3.9">ğ‘</ci><ci id="S2.SS2.p1.2.m2.1.1.2.3.10.cmml" xref="S2.SS2.p1.2.m2.1.1.2.3.10">ğ‘ </ci><ci id="S2.SS2.p1.2.m2.1.1.2.3.11.cmml" xref="S2.SS2.p1.2.m2.1.1.2.3.11">ğ‘˜</ci></apply></apply><apply id="S2.SS2.p1.2.m2.1.1.3.cmml" xref="S2.SS2.p1.2.m2.1.1.3"><plus id="S2.SS2.p1.2.m2.1.1.3.1.cmml" xref="S2.SS2.p1.2.m2.1.1.3.1"></plus><apply id="S2.SS2.p1.2.m2.1.1.3.2.cmml" xref="S2.SS2.p1.2.m2.1.1.3.2"><times id="S2.SS2.p1.2.m2.1.1.3.2.1.cmml" xref="S2.SS2.p1.2.m2.1.1.3.2.1"></times><apply id="S2.SS2.p1.2.m2.1.1.3.2.2.cmml" xref="S2.SS2.p1.2.m2.1.1.3.2.2"><csymbol cd="ambiguous" id="S2.SS2.p1.2.m2.1.1.3.2.2.1.cmml" xref="S2.SS2.p1.2.m2.1.1.3.2.2">subscript</csymbol><ci id="S2.SS2.p1.2.m2.1.1.3.2.2.2.cmml" xref="S2.SS2.p1.2.m2.1.1.3.2.2.2">ğœ†</ci><apply id="S2.SS2.p1.2.m2.1.1.3.2.2.3.cmml" xref="S2.SS2.p1.2.m2.1.1.3.2.2.3"><times id="S2.SS2.p1.2.m2.1.1.3.2.2.3.1.cmml" xref="S2.SS2.p1.2.m2.1.1.3.2.2.3.1"></times><ci id="S2.SS2.p1.2.m2.1.1.3.2.2.3.2.cmml" xref="S2.SS2.p1.2.m2.1.1.3.2.2.3.2">ğ‘</ci><ci id="S2.SS2.p1.2.m2.1.1.3.2.2.3.3.cmml" xref="S2.SS2.p1.2.m2.1.1.3.2.2.3.3">ğ‘™</ci><ci id="S2.SS2.p1.2.m2.1.1.3.2.2.3.4.cmml" xref="S2.SS2.p1.2.m2.1.1.3.2.2.3.4">ğ‘ </ci></apply></apply><apply id="S2.SS2.p1.2.m2.1.1.3.2.3.cmml" xref="S2.SS2.p1.2.m2.1.1.3.2.3"><csymbol cd="ambiguous" id="S2.SS2.p1.2.m2.1.1.3.2.3.1.cmml" xref="S2.SS2.p1.2.m2.1.1.3.2.3">subscript</csymbol><ci id="S2.SS2.p1.2.m2.1.1.3.2.3.2.cmml" xref="S2.SS2.p1.2.m2.1.1.3.2.3.2">â„’</ci><apply id="S2.SS2.p1.2.m2.1.1.3.2.3.3.cmml" xref="S2.SS2.p1.2.m2.1.1.3.2.3.3"><times id="S2.SS2.p1.2.m2.1.1.3.2.3.3.1.cmml" xref="S2.SS2.p1.2.m2.1.1.3.2.3.3.1"></times><ci id="S2.SS2.p1.2.m2.1.1.3.2.3.3.2.cmml" xref="S2.SS2.p1.2.m2.1.1.3.2.3.3.2">ğ‘</ci><ci id="S2.SS2.p1.2.m2.1.1.3.2.3.3.3.cmml" xref="S2.SS2.p1.2.m2.1.1.3.2.3.3.3">ğ‘™</ci><ci id="S2.SS2.p1.2.m2.1.1.3.2.3.3.4.cmml" xref="S2.SS2.p1.2.m2.1.1.3.2.3.3.4">ğ‘ </ci></apply></apply></apply><apply id="S2.SS2.p1.2.m2.1.1.3.3.cmml" xref="S2.SS2.p1.2.m2.1.1.3.3"><times id="S2.SS2.p1.2.m2.1.1.3.3.1.cmml" xref="S2.SS2.p1.2.m2.1.1.3.3.1"></times><apply id="S2.SS2.p1.2.m2.1.1.3.3.2.cmml" xref="S2.SS2.p1.2.m2.1.1.3.3.2"><csymbol cd="ambiguous" id="S2.SS2.p1.2.m2.1.1.3.3.2.1.cmml" xref="S2.SS2.p1.2.m2.1.1.3.3.2">subscript</csymbol><ci id="S2.SS2.p1.2.m2.1.1.3.3.2.2.cmml" xref="S2.SS2.p1.2.m2.1.1.3.3.2.2">ğœ†</ci><apply id="S2.SS2.p1.2.m2.1.1.3.3.2.3.cmml" xref="S2.SS2.p1.2.m2.1.1.3.3.2.3"><times id="S2.SS2.p1.2.m2.1.1.3.3.2.3.1.cmml" xref="S2.SS2.p1.2.m2.1.1.3.3.2.3.1"></times><ci id="S2.SS2.p1.2.m2.1.1.3.3.2.3.2.cmml" xref="S2.SS2.p1.2.m2.1.1.3.3.2.3.2">ğ‘‘</ci><ci id="S2.SS2.p1.2.m2.1.1.3.3.2.3.3.cmml" xref="S2.SS2.p1.2.m2.1.1.3.3.2.3.3">ğ‘–</ci><ci id="S2.SS2.p1.2.m2.1.1.3.3.2.3.4.cmml" xref="S2.SS2.p1.2.m2.1.1.3.3.2.3.4">ğ‘›</ci><ci id="S2.SS2.p1.2.m2.1.1.3.3.2.3.5.cmml" xref="S2.SS2.p1.2.m2.1.1.3.3.2.3.5">ğ‘œ</ci></apply></apply><apply id="S2.SS2.p1.2.m2.1.1.3.3.3.cmml" xref="S2.SS2.p1.2.m2.1.1.3.3.3"><csymbol cd="ambiguous" id="S2.SS2.p1.2.m2.1.1.3.3.3.1.cmml" xref="S2.SS2.p1.2.m2.1.1.3.3.3">subscript</csymbol><ci id="S2.SS2.p1.2.m2.1.1.3.3.3.2.cmml" xref="S2.SS2.p1.2.m2.1.1.3.3.3.2">â„’</ci><apply id="S2.SS2.p1.2.m2.1.1.3.3.3.3.cmml" xref="S2.SS2.p1.2.m2.1.1.3.3.3.3"><times id="S2.SS2.p1.2.m2.1.1.3.3.3.3.1.cmml" xref="S2.SS2.p1.2.m2.1.1.3.3.3.3.1"></times><ci id="S2.SS2.p1.2.m2.1.1.3.3.3.3.2.cmml" xref="S2.SS2.p1.2.m2.1.1.3.3.3.3.2">ğ‘‘</ci><ci id="S2.SS2.p1.2.m2.1.1.3.3.3.3.3.cmml" xref="S2.SS2.p1.2.m2.1.1.3.3.3.3.3">ğ‘–</ci><ci id="S2.SS2.p1.2.m2.1.1.3.3.3.3.4.cmml" xref="S2.SS2.p1.2.m2.1.1.3.3.3.3.4">ğ‘›</ci><ci id="S2.SS2.p1.2.m2.1.1.3.3.3.3.5.cmml" xref="S2.SS2.p1.2.m2.1.1.3.3.3.3.5">ğ‘œ</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.2.m2.1c">\mathcal{L}_{multi\_task}=\lambda_{cls}\mathcal{L}_{cls}+\lambda_{dino}%
\mathcal{L}_{dino}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p1.2.m2.1d">caligraphic_L start_POSTSUBSCRIPT italic_m italic_u italic_l italic_t italic_i _ italic_t italic_a italic_s italic_k end_POSTSUBSCRIPT = italic_Î» start_POSTSUBSCRIPT italic_c italic_l italic_s end_POSTSUBSCRIPT caligraphic_L start_POSTSUBSCRIPT italic_c italic_l italic_s end_POSTSUBSCRIPT + italic_Î» start_POSTSUBSCRIPT italic_d italic_i italic_n italic_o end_POSTSUBSCRIPT caligraphic_L start_POSTSUBSCRIPT italic_d italic_i italic_n italic_o end_POSTSUBSCRIPT</annotation></semantics></math> where <math alttext="\mathcal{L}_{cls}" class="ltx_Math" display="inline" id="S2.SS2.p1.3.m3.1"><semantics id="S2.SS2.p1.3.m3.1a"><msub id="S2.SS2.p1.3.m3.1.1" xref="S2.SS2.p1.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p1.3.m3.1.1.2" xref="S2.SS2.p1.3.m3.1.1.2.cmml">â„’</mi><mrow id="S2.SS2.p1.3.m3.1.1.3" xref="S2.SS2.p1.3.m3.1.1.3.cmml"><mi id="S2.SS2.p1.3.m3.1.1.3.2" xref="S2.SS2.p1.3.m3.1.1.3.2.cmml">c</mi><mo id="S2.SS2.p1.3.m3.1.1.3.1" xref="S2.SS2.p1.3.m3.1.1.3.1.cmml">â¢</mo><mi id="S2.SS2.p1.3.m3.1.1.3.3" xref="S2.SS2.p1.3.m3.1.1.3.3.cmml">l</mi><mo id="S2.SS2.p1.3.m3.1.1.3.1a" xref="S2.SS2.p1.3.m3.1.1.3.1.cmml">â¢</mo><mi id="S2.SS2.p1.3.m3.1.1.3.4" xref="S2.SS2.p1.3.m3.1.1.3.4.cmml">s</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.3.m3.1b"><apply id="S2.SS2.p1.3.m3.1.1.cmml" xref="S2.SS2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.3.m3.1.1.1.cmml" xref="S2.SS2.p1.3.m3.1.1">subscript</csymbol><ci id="S2.SS2.p1.3.m3.1.1.2.cmml" xref="S2.SS2.p1.3.m3.1.1.2">â„’</ci><apply id="S2.SS2.p1.3.m3.1.1.3.cmml" xref="S2.SS2.p1.3.m3.1.1.3"><times id="S2.SS2.p1.3.m3.1.1.3.1.cmml" xref="S2.SS2.p1.3.m3.1.1.3.1"></times><ci id="S2.SS2.p1.3.m3.1.1.3.2.cmml" xref="S2.SS2.p1.3.m3.1.1.3.2">ğ‘</ci><ci id="S2.SS2.p1.3.m3.1.1.3.3.cmml" xref="S2.SS2.p1.3.m3.1.1.3.3">ğ‘™</ci><ci id="S2.SS2.p1.3.m3.1.1.3.4.cmml" xref="S2.SS2.p1.3.m3.1.1.3.4">ğ‘ </ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.3.m3.1c">\mathcal{L}_{cls}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p1.3.m3.1d">caligraphic_L start_POSTSUBSCRIPT italic_c italic_l italic_s end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="\mathcal{L}_{dino}" class="ltx_Math" display="inline" id="S2.SS2.p1.4.m4.1"><semantics id="S2.SS2.p1.4.m4.1a"><msub id="S2.SS2.p1.4.m4.1.1" xref="S2.SS2.p1.4.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.p1.4.m4.1.1.2" xref="S2.SS2.p1.4.m4.1.1.2.cmml">â„’</mi><mrow id="S2.SS2.p1.4.m4.1.1.3" xref="S2.SS2.p1.4.m4.1.1.3.cmml"><mi id="S2.SS2.p1.4.m4.1.1.3.2" xref="S2.SS2.p1.4.m4.1.1.3.2.cmml">d</mi><mo id="S2.SS2.p1.4.m4.1.1.3.1" xref="S2.SS2.p1.4.m4.1.1.3.1.cmml">â¢</mo><mi id="S2.SS2.p1.4.m4.1.1.3.3" xref="S2.SS2.p1.4.m4.1.1.3.3.cmml">i</mi><mo id="S2.SS2.p1.4.m4.1.1.3.1a" xref="S2.SS2.p1.4.m4.1.1.3.1.cmml">â¢</mo><mi id="S2.SS2.p1.4.m4.1.1.3.4" xref="S2.SS2.p1.4.m4.1.1.3.4.cmml">n</mi><mo id="S2.SS2.p1.4.m4.1.1.3.1b" xref="S2.SS2.p1.4.m4.1.1.3.1.cmml">â¢</mo><mi id="S2.SS2.p1.4.m4.1.1.3.5" xref="S2.SS2.p1.4.m4.1.1.3.5.cmml">o</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.4.m4.1b"><apply id="S2.SS2.p1.4.m4.1.1.cmml" xref="S2.SS2.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.4.m4.1.1.1.cmml" xref="S2.SS2.p1.4.m4.1.1">subscript</csymbol><ci id="S2.SS2.p1.4.m4.1.1.2.cmml" xref="S2.SS2.p1.4.m4.1.1.2">â„’</ci><apply id="S2.SS2.p1.4.m4.1.1.3.cmml" xref="S2.SS2.p1.4.m4.1.1.3"><times id="S2.SS2.p1.4.m4.1.1.3.1.cmml" xref="S2.SS2.p1.4.m4.1.1.3.1"></times><ci id="S2.SS2.p1.4.m4.1.1.3.2.cmml" xref="S2.SS2.p1.4.m4.1.1.3.2">ğ‘‘</ci><ci id="S2.SS2.p1.4.m4.1.1.3.3.cmml" xref="S2.SS2.p1.4.m4.1.1.3.3">ğ‘–</ci><ci id="S2.SS2.p1.4.m4.1.1.3.4.cmml" xref="S2.SS2.p1.4.m4.1.1.3.4">ğ‘›</ci><ci id="S2.SS2.p1.4.m4.1.1.3.5.cmml" xref="S2.SS2.p1.4.m4.1.1.3.5">ğ‘œ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.4.m4.1c">\mathcal{L}_{dino}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p1.4.m4.1d">caligraphic_L start_POSTSUBSCRIPT italic_d italic_i italic_n italic_o end_POSTSUBSCRIPT</annotation></semantics></math> correspond to Cross Entropy and DINO losses Â <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#bib.bib3" title="">3</a>]</cite> respectively and coefficients are selected as 0.5.
Finetuned DINO is used to generate features for MaskCut.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Self-Training</h3>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.10">Mask2former offers a universal image segmentation framework which takes advantage of masked attention(EquationÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#S2.E2" title="In 2.3 Self-Training â€£ 2 Methodology â€£ SURGIVID: Annotation-Efficient Surgical Video Object Discovery"><span class="ltx_text ltx_ref_tag">2</span></a>) enforcing local attention within the transformer decoder. This leads to faster convergence and better performance compared with cross-attention.</p>
<table class="ltx_equation ltx_eqn_table" id="S2.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="X_{l}=\text{softmax}(\mathbb{M}_{l-1}+Q_{l}K_{l}^{T})V_{l}+X_{(l-1)}" class="ltx_Math" display="block" id="S2.E2.m1.2"><semantics id="S2.E2.m1.2a"><mrow id="S2.E2.m1.2.2" xref="S2.E2.m1.2.2.cmml"><msub id="S2.E2.m1.2.2.3" xref="S2.E2.m1.2.2.3.cmml"><mi id="S2.E2.m1.2.2.3.2" xref="S2.E2.m1.2.2.3.2.cmml">X</mi><mi id="S2.E2.m1.2.2.3.3" xref="S2.E2.m1.2.2.3.3.cmml">l</mi></msub><mo id="S2.E2.m1.2.2.2" xref="S2.E2.m1.2.2.2.cmml">=</mo><mrow id="S2.E2.m1.2.2.1" xref="S2.E2.m1.2.2.1.cmml"><mrow id="S2.E2.m1.2.2.1.1" xref="S2.E2.m1.2.2.1.1.cmml"><mtext id="S2.E2.m1.2.2.1.1.3" xref="S2.E2.m1.2.2.1.1.3a.cmml">softmax</mtext><mo id="S2.E2.m1.2.2.1.1.2" xref="S2.E2.m1.2.2.1.1.2.cmml">â¢</mo><mrow id="S2.E2.m1.2.2.1.1.1.1" xref="S2.E2.m1.2.2.1.1.1.1.1.cmml"><mo id="S2.E2.m1.2.2.1.1.1.1.2" stretchy="false" xref="S2.E2.m1.2.2.1.1.1.1.1.cmml">(</mo><mrow id="S2.E2.m1.2.2.1.1.1.1.1" xref="S2.E2.m1.2.2.1.1.1.1.1.cmml"><msub id="S2.E2.m1.2.2.1.1.1.1.1.2" xref="S2.E2.m1.2.2.1.1.1.1.1.2.cmml"><mi id="S2.E2.m1.2.2.1.1.1.1.1.2.2" xref="S2.E2.m1.2.2.1.1.1.1.1.2.2.cmml">ğ•„</mi><mrow id="S2.E2.m1.2.2.1.1.1.1.1.2.3" xref="S2.E2.m1.2.2.1.1.1.1.1.2.3.cmml"><mi id="S2.E2.m1.2.2.1.1.1.1.1.2.3.2" xref="S2.E2.m1.2.2.1.1.1.1.1.2.3.2.cmml">l</mi><mo id="S2.E2.m1.2.2.1.1.1.1.1.2.3.1" xref="S2.E2.m1.2.2.1.1.1.1.1.2.3.1.cmml">âˆ’</mo><mn id="S2.E2.m1.2.2.1.1.1.1.1.2.3.3" xref="S2.E2.m1.2.2.1.1.1.1.1.2.3.3.cmml">1</mn></mrow></msub><mo id="S2.E2.m1.2.2.1.1.1.1.1.1" xref="S2.E2.m1.2.2.1.1.1.1.1.1.cmml">+</mo><mrow id="S2.E2.m1.2.2.1.1.1.1.1.3" xref="S2.E2.m1.2.2.1.1.1.1.1.3.cmml"><msub id="S2.E2.m1.2.2.1.1.1.1.1.3.2" xref="S2.E2.m1.2.2.1.1.1.1.1.3.2.cmml"><mi id="S2.E2.m1.2.2.1.1.1.1.1.3.2.2" xref="S2.E2.m1.2.2.1.1.1.1.1.3.2.2.cmml">Q</mi><mi id="S2.E2.m1.2.2.1.1.1.1.1.3.2.3" xref="S2.E2.m1.2.2.1.1.1.1.1.3.2.3.cmml">l</mi></msub><mo id="S2.E2.m1.2.2.1.1.1.1.1.3.1" xref="S2.E2.m1.2.2.1.1.1.1.1.3.1.cmml">â¢</mo><msubsup id="S2.E2.m1.2.2.1.1.1.1.1.3.3" xref="S2.E2.m1.2.2.1.1.1.1.1.3.3.cmml"><mi id="S2.E2.m1.2.2.1.1.1.1.1.3.3.2.2" xref="S2.E2.m1.2.2.1.1.1.1.1.3.3.2.2.cmml">K</mi><mi id="S2.E2.m1.2.2.1.1.1.1.1.3.3.2.3" xref="S2.E2.m1.2.2.1.1.1.1.1.3.3.2.3.cmml">l</mi><mi id="S2.E2.m1.2.2.1.1.1.1.1.3.3.3" xref="S2.E2.m1.2.2.1.1.1.1.1.3.3.3.cmml">T</mi></msubsup></mrow></mrow><mo id="S2.E2.m1.2.2.1.1.1.1.3" stretchy="false" xref="S2.E2.m1.2.2.1.1.1.1.1.cmml">)</mo></mrow><mo id="S2.E2.m1.2.2.1.1.2a" xref="S2.E2.m1.2.2.1.1.2.cmml">â¢</mo><msub id="S2.E2.m1.2.2.1.1.4" xref="S2.E2.m1.2.2.1.1.4.cmml"><mi id="S2.E2.m1.2.2.1.1.4.2" xref="S2.E2.m1.2.2.1.1.4.2.cmml">V</mi><mi id="S2.E2.m1.2.2.1.1.4.3" xref="S2.E2.m1.2.2.1.1.4.3.cmml">l</mi></msub></mrow><mo id="S2.E2.m1.2.2.1.2" xref="S2.E2.m1.2.2.1.2.cmml">+</mo><msub id="S2.E2.m1.2.2.1.3" xref="S2.E2.m1.2.2.1.3.cmml"><mi id="S2.E2.m1.2.2.1.3.2" xref="S2.E2.m1.2.2.1.3.2.cmml">X</mi><mrow id="S2.E2.m1.1.1.1.1" xref="S2.E2.m1.1.1.1.1.1.cmml"><mo id="S2.E2.m1.1.1.1.1.2" stretchy="false" xref="S2.E2.m1.1.1.1.1.1.cmml">(</mo><mrow id="S2.E2.m1.1.1.1.1.1" xref="S2.E2.m1.1.1.1.1.1.cmml"><mi id="S2.E2.m1.1.1.1.1.1.2" xref="S2.E2.m1.1.1.1.1.1.2.cmml">l</mi><mo id="S2.E2.m1.1.1.1.1.1.1" xref="S2.E2.m1.1.1.1.1.1.1.cmml">âˆ’</mo><mn id="S2.E2.m1.1.1.1.1.1.3" xref="S2.E2.m1.1.1.1.1.1.3.cmml">1</mn></mrow><mo id="S2.E2.m1.1.1.1.1.3" stretchy="false" xref="S2.E2.m1.1.1.1.1.1.cmml">)</mo></mrow></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E2.m1.2b"><apply id="S2.E2.m1.2.2.cmml" xref="S2.E2.m1.2.2"><eq id="S2.E2.m1.2.2.2.cmml" xref="S2.E2.m1.2.2.2"></eq><apply id="S2.E2.m1.2.2.3.cmml" xref="S2.E2.m1.2.2.3"><csymbol cd="ambiguous" id="S2.E2.m1.2.2.3.1.cmml" xref="S2.E2.m1.2.2.3">subscript</csymbol><ci id="S2.E2.m1.2.2.3.2.cmml" xref="S2.E2.m1.2.2.3.2">ğ‘‹</ci><ci id="S2.E2.m1.2.2.3.3.cmml" xref="S2.E2.m1.2.2.3.3">ğ‘™</ci></apply><apply id="S2.E2.m1.2.2.1.cmml" xref="S2.E2.m1.2.2.1"><plus id="S2.E2.m1.2.2.1.2.cmml" xref="S2.E2.m1.2.2.1.2"></plus><apply id="S2.E2.m1.2.2.1.1.cmml" xref="S2.E2.m1.2.2.1.1"><times id="S2.E2.m1.2.2.1.1.2.cmml" xref="S2.E2.m1.2.2.1.1.2"></times><ci id="S2.E2.m1.2.2.1.1.3a.cmml" xref="S2.E2.m1.2.2.1.1.3"><mtext id="S2.E2.m1.2.2.1.1.3.cmml" xref="S2.E2.m1.2.2.1.1.3">softmax</mtext></ci><apply id="S2.E2.m1.2.2.1.1.1.1.1.cmml" xref="S2.E2.m1.2.2.1.1.1.1"><plus id="S2.E2.m1.2.2.1.1.1.1.1.1.cmml" xref="S2.E2.m1.2.2.1.1.1.1.1.1"></plus><apply id="S2.E2.m1.2.2.1.1.1.1.1.2.cmml" xref="S2.E2.m1.2.2.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E2.m1.2.2.1.1.1.1.1.2.1.cmml" xref="S2.E2.m1.2.2.1.1.1.1.1.2">subscript</csymbol><ci id="S2.E2.m1.2.2.1.1.1.1.1.2.2.cmml" xref="S2.E2.m1.2.2.1.1.1.1.1.2.2">ğ•„</ci><apply id="S2.E2.m1.2.2.1.1.1.1.1.2.3.cmml" xref="S2.E2.m1.2.2.1.1.1.1.1.2.3"><minus id="S2.E2.m1.2.2.1.1.1.1.1.2.3.1.cmml" xref="S2.E2.m1.2.2.1.1.1.1.1.2.3.1"></minus><ci id="S2.E2.m1.2.2.1.1.1.1.1.2.3.2.cmml" xref="S2.E2.m1.2.2.1.1.1.1.1.2.3.2">ğ‘™</ci><cn id="S2.E2.m1.2.2.1.1.1.1.1.2.3.3.cmml" type="integer" xref="S2.E2.m1.2.2.1.1.1.1.1.2.3.3">1</cn></apply></apply><apply id="S2.E2.m1.2.2.1.1.1.1.1.3.cmml" xref="S2.E2.m1.2.2.1.1.1.1.1.3"><times id="S2.E2.m1.2.2.1.1.1.1.1.3.1.cmml" xref="S2.E2.m1.2.2.1.1.1.1.1.3.1"></times><apply id="S2.E2.m1.2.2.1.1.1.1.1.3.2.cmml" xref="S2.E2.m1.2.2.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S2.E2.m1.2.2.1.1.1.1.1.3.2.1.cmml" xref="S2.E2.m1.2.2.1.1.1.1.1.3.2">subscript</csymbol><ci id="S2.E2.m1.2.2.1.1.1.1.1.3.2.2.cmml" xref="S2.E2.m1.2.2.1.1.1.1.1.3.2.2">ğ‘„</ci><ci id="S2.E2.m1.2.2.1.1.1.1.1.3.2.3.cmml" xref="S2.E2.m1.2.2.1.1.1.1.1.3.2.3">ğ‘™</ci></apply><apply id="S2.E2.m1.2.2.1.1.1.1.1.3.3.cmml" xref="S2.E2.m1.2.2.1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S2.E2.m1.2.2.1.1.1.1.1.3.3.1.cmml" xref="S2.E2.m1.2.2.1.1.1.1.1.3.3">superscript</csymbol><apply id="S2.E2.m1.2.2.1.1.1.1.1.3.3.2.cmml" xref="S2.E2.m1.2.2.1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S2.E2.m1.2.2.1.1.1.1.1.3.3.2.1.cmml" xref="S2.E2.m1.2.2.1.1.1.1.1.3.3">subscript</csymbol><ci id="S2.E2.m1.2.2.1.1.1.1.1.3.3.2.2.cmml" xref="S2.E2.m1.2.2.1.1.1.1.1.3.3.2.2">ğ¾</ci><ci id="S2.E2.m1.2.2.1.1.1.1.1.3.3.2.3.cmml" xref="S2.E2.m1.2.2.1.1.1.1.1.3.3.2.3">ğ‘™</ci></apply><ci id="S2.E2.m1.2.2.1.1.1.1.1.3.3.3.cmml" xref="S2.E2.m1.2.2.1.1.1.1.1.3.3.3">ğ‘‡</ci></apply></apply></apply><apply id="S2.E2.m1.2.2.1.1.4.cmml" xref="S2.E2.m1.2.2.1.1.4"><csymbol cd="ambiguous" id="S2.E2.m1.2.2.1.1.4.1.cmml" xref="S2.E2.m1.2.2.1.1.4">subscript</csymbol><ci id="S2.E2.m1.2.2.1.1.4.2.cmml" xref="S2.E2.m1.2.2.1.1.4.2">ğ‘‰</ci><ci id="S2.E2.m1.2.2.1.1.4.3.cmml" xref="S2.E2.m1.2.2.1.1.4.3">ğ‘™</ci></apply></apply><apply id="S2.E2.m1.2.2.1.3.cmml" xref="S2.E2.m1.2.2.1.3"><csymbol cd="ambiguous" id="S2.E2.m1.2.2.1.3.1.cmml" xref="S2.E2.m1.2.2.1.3">subscript</csymbol><ci id="S2.E2.m1.2.2.1.3.2.cmml" xref="S2.E2.m1.2.2.1.3.2">ğ‘‹</ci><apply id="S2.E2.m1.1.1.1.1.1.cmml" xref="S2.E2.m1.1.1.1.1"><minus id="S2.E2.m1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.1.1.1.1.1.1"></minus><ci id="S2.E2.m1.1.1.1.1.1.2.cmml" xref="S2.E2.m1.1.1.1.1.1.2">ğ‘™</ci><cn id="S2.E2.m1.1.1.1.1.1.3.cmml" type="integer" xref="S2.E2.m1.1.1.1.1.1.3">1</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E2.m1.2c">X_{l}=\text{softmax}(\mathbb{M}_{l-1}+Q_{l}K_{l}^{T})V_{l}+X_{(l-1)}</annotation><annotation encoding="application/x-llamapun" id="S2.E2.m1.2d">italic_X start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT = softmax ( blackboard_M start_POSTSUBSCRIPT italic_l - 1 end_POSTSUBSCRIPT + italic_Q start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT italic_K start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT ) italic_V start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT + italic_X start_POSTSUBSCRIPT ( italic_l - 1 ) end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S2.SS3.p1.9">where <math alttext="{X_{l}}\in\textbf{R}^{N\times C}" class="ltx_Math" display="inline" id="S2.SS3.p1.1.m1.1"><semantics id="S2.SS3.p1.1.m1.1a"><mrow id="S2.SS3.p1.1.m1.1.1" xref="S2.SS3.p1.1.m1.1.1.cmml"><msub id="S2.SS3.p1.1.m1.1.1.2" xref="S2.SS3.p1.1.m1.1.1.2.cmml"><mi id="S2.SS3.p1.1.m1.1.1.2.2" xref="S2.SS3.p1.1.m1.1.1.2.2.cmml">X</mi><mi id="S2.SS3.p1.1.m1.1.1.2.3" xref="S2.SS3.p1.1.m1.1.1.2.3.cmml">l</mi></msub><mo id="S2.SS3.p1.1.m1.1.1.1" xref="S2.SS3.p1.1.m1.1.1.1.cmml">âˆˆ</mo><msup id="S2.SS3.p1.1.m1.1.1.3" xref="S2.SS3.p1.1.m1.1.1.3.cmml"><mtext class="ltx_mathvariant_bold" id="S2.SS3.p1.1.m1.1.1.3.2" xref="S2.SS3.p1.1.m1.1.1.3.2a.cmml">R</mtext><mrow id="S2.SS3.p1.1.m1.1.1.3.3" xref="S2.SS3.p1.1.m1.1.1.3.3.cmml"><mi id="S2.SS3.p1.1.m1.1.1.3.3.2" xref="S2.SS3.p1.1.m1.1.1.3.3.2.cmml">N</mi><mo id="S2.SS3.p1.1.m1.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S2.SS3.p1.1.m1.1.1.3.3.1.cmml">Ã—</mo><mi id="S2.SS3.p1.1.m1.1.1.3.3.3" xref="S2.SS3.p1.1.m1.1.1.3.3.3.cmml">C</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.1.m1.1b"><apply id="S2.SS3.p1.1.m1.1.1.cmml" xref="S2.SS3.p1.1.m1.1.1"><in id="S2.SS3.p1.1.m1.1.1.1.cmml" xref="S2.SS3.p1.1.m1.1.1.1"></in><apply id="S2.SS3.p1.1.m1.1.1.2.cmml" xref="S2.SS3.p1.1.m1.1.1.2"><csymbol cd="ambiguous" id="S2.SS3.p1.1.m1.1.1.2.1.cmml" xref="S2.SS3.p1.1.m1.1.1.2">subscript</csymbol><ci id="S2.SS3.p1.1.m1.1.1.2.2.cmml" xref="S2.SS3.p1.1.m1.1.1.2.2">ğ‘‹</ci><ci id="S2.SS3.p1.1.m1.1.1.2.3.cmml" xref="S2.SS3.p1.1.m1.1.1.2.3">ğ‘™</ci></apply><apply id="S2.SS3.p1.1.m1.1.1.3.cmml" xref="S2.SS3.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S2.SS3.p1.1.m1.1.1.3.1.cmml" xref="S2.SS3.p1.1.m1.1.1.3">superscript</csymbol><ci id="S2.SS3.p1.1.m1.1.1.3.2a.cmml" xref="S2.SS3.p1.1.m1.1.1.3.2"><mtext class="ltx_mathvariant_bold" id="S2.SS3.p1.1.m1.1.1.3.2.cmml" xref="S2.SS3.p1.1.m1.1.1.3.2">R</mtext></ci><apply id="S2.SS3.p1.1.m1.1.1.3.3.cmml" xref="S2.SS3.p1.1.m1.1.1.3.3"><times id="S2.SS3.p1.1.m1.1.1.3.3.1.cmml" xref="S2.SS3.p1.1.m1.1.1.3.3.1"></times><ci id="S2.SS3.p1.1.m1.1.1.3.3.2.cmml" xref="S2.SS3.p1.1.m1.1.1.3.3.2">ğ‘</ci><ci id="S2.SS3.p1.1.m1.1.1.3.3.3.cmml" xref="S2.SS3.p1.1.m1.1.1.3.3.3">ğ¶</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.1.m1.1c">{X_{l}}\in\textbf{R}^{N\times C}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p1.1.m1.1d">italic_X start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT âˆˆ R start_POSTSUPERSCRIPT italic_N Ã— italic_C end_POSTSUPERSCRIPT</annotation></semantics></math> corresponds to <math alttext="N" class="ltx_Math" display="inline" id="S2.SS3.p1.2.m2.1"><semantics id="S2.SS3.p1.2.m2.1a"><mi id="S2.SS3.p1.2.m2.1.1" xref="S2.SS3.p1.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.2.m2.1b"><ci id="S2.SS3.p1.2.m2.1.1.cmml" xref="S2.SS3.p1.2.m2.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.2.m2.1c">N</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p1.2.m2.1d">italic_N</annotation></semantics></math> query features of layer <math alttext="l" class="ltx_Math" display="inline" id="S2.SS3.p1.3.m3.1"><semantics id="S2.SS3.p1.3.m3.1a"><mi id="S2.SS3.p1.3.m3.1.1" xref="S2.SS3.p1.3.m3.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.3.m3.1b"><ci id="S2.SS3.p1.3.m3.1.1.cmml" xref="S2.SS3.p1.3.m3.1.1">ğ‘™</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.3.m3.1c">l</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p1.3.m3.1d">italic_l</annotation></semantics></math> of dimension <math alttext="C" class="ltx_Math" display="inline" id="S2.SS3.p1.4.m4.1"><semantics id="S2.SS3.p1.4.m4.1a"><mi id="S2.SS3.p1.4.m4.1.1" xref="S2.SS3.p1.4.m4.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.4.m4.1b"><ci id="S2.SS3.p1.4.m4.1.1.cmml" xref="S2.SS3.p1.4.m4.1.1">ğ¶</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.4.m4.1c">C</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p1.4.m4.1d">italic_C</annotation></semantics></math> and <math alttext="Q_{l}=f_{Q}(X_{l-1})\in\mathbb{R}^{N\times C}" class="ltx_Math" display="inline" id="S2.SS3.p1.5.m5.1"><semantics id="S2.SS3.p1.5.m5.1a"><mrow id="S2.SS3.p1.5.m5.1.1" xref="S2.SS3.p1.5.m5.1.1.cmml"><msub id="S2.SS3.p1.5.m5.1.1.3" xref="S2.SS3.p1.5.m5.1.1.3.cmml"><mi id="S2.SS3.p1.5.m5.1.1.3.2" xref="S2.SS3.p1.5.m5.1.1.3.2.cmml">Q</mi><mi id="S2.SS3.p1.5.m5.1.1.3.3" xref="S2.SS3.p1.5.m5.1.1.3.3.cmml">l</mi></msub><mo id="S2.SS3.p1.5.m5.1.1.4" xref="S2.SS3.p1.5.m5.1.1.4.cmml">=</mo><mrow id="S2.SS3.p1.5.m5.1.1.1" xref="S2.SS3.p1.5.m5.1.1.1.cmml"><msub id="S2.SS3.p1.5.m5.1.1.1.3" xref="S2.SS3.p1.5.m5.1.1.1.3.cmml"><mi id="S2.SS3.p1.5.m5.1.1.1.3.2" xref="S2.SS3.p1.5.m5.1.1.1.3.2.cmml">f</mi><mi id="S2.SS3.p1.5.m5.1.1.1.3.3" xref="S2.SS3.p1.5.m5.1.1.1.3.3.cmml">Q</mi></msub><mo id="S2.SS3.p1.5.m5.1.1.1.2" xref="S2.SS3.p1.5.m5.1.1.1.2.cmml">â¢</mo><mrow id="S2.SS3.p1.5.m5.1.1.1.1.1" xref="S2.SS3.p1.5.m5.1.1.1.1.1.1.cmml"><mo id="S2.SS3.p1.5.m5.1.1.1.1.1.2" stretchy="false" xref="S2.SS3.p1.5.m5.1.1.1.1.1.1.cmml">(</mo><msub id="S2.SS3.p1.5.m5.1.1.1.1.1.1" xref="S2.SS3.p1.5.m5.1.1.1.1.1.1.cmml"><mi id="S2.SS3.p1.5.m5.1.1.1.1.1.1.2" xref="S2.SS3.p1.5.m5.1.1.1.1.1.1.2.cmml">X</mi><mrow id="S2.SS3.p1.5.m5.1.1.1.1.1.1.3" xref="S2.SS3.p1.5.m5.1.1.1.1.1.1.3.cmml"><mi id="S2.SS3.p1.5.m5.1.1.1.1.1.1.3.2" xref="S2.SS3.p1.5.m5.1.1.1.1.1.1.3.2.cmml">l</mi><mo id="S2.SS3.p1.5.m5.1.1.1.1.1.1.3.1" xref="S2.SS3.p1.5.m5.1.1.1.1.1.1.3.1.cmml">âˆ’</mo><mn id="S2.SS3.p1.5.m5.1.1.1.1.1.1.3.3" xref="S2.SS3.p1.5.m5.1.1.1.1.1.1.3.3.cmml">1</mn></mrow></msub><mo id="S2.SS3.p1.5.m5.1.1.1.1.1.3" stretchy="false" xref="S2.SS3.p1.5.m5.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.SS3.p1.5.m5.1.1.5" xref="S2.SS3.p1.5.m5.1.1.5.cmml">âˆˆ</mo><msup id="S2.SS3.p1.5.m5.1.1.6" xref="S2.SS3.p1.5.m5.1.1.6.cmml"><mi id="S2.SS3.p1.5.m5.1.1.6.2" xref="S2.SS3.p1.5.m5.1.1.6.2.cmml">â„</mi><mrow id="S2.SS3.p1.5.m5.1.1.6.3" xref="S2.SS3.p1.5.m5.1.1.6.3.cmml"><mi id="S2.SS3.p1.5.m5.1.1.6.3.2" xref="S2.SS3.p1.5.m5.1.1.6.3.2.cmml">N</mi><mo id="S2.SS3.p1.5.m5.1.1.6.3.1" lspace="0.222em" rspace="0.222em" xref="S2.SS3.p1.5.m5.1.1.6.3.1.cmml">Ã—</mo><mi id="S2.SS3.p1.5.m5.1.1.6.3.3" xref="S2.SS3.p1.5.m5.1.1.6.3.3.cmml">C</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.5.m5.1b"><apply id="S2.SS3.p1.5.m5.1.1.cmml" xref="S2.SS3.p1.5.m5.1.1"><and id="S2.SS3.p1.5.m5.1.1a.cmml" xref="S2.SS3.p1.5.m5.1.1"></and><apply id="S2.SS3.p1.5.m5.1.1b.cmml" xref="S2.SS3.p1.5.m5.1.1"><eq id="S2.SS3.p1.5.m5.1.1.4.cmml" xref="S2.SS3.p1.5.m5.1.1.4"></eq><apply id="S2.SS3.p1.5.m5.1.1.3.cmml" xref="S2.SS3.p1.5.m5.1.1.3"><csymbol cd="ambiguous" id="S2.SS3.p1.5.m5.1.1.3.1.cmml" xref="S2.SS3.p1.5.m5.1.1.3">subscript</csymbol><ci id="S2.SS3.p1.5.m5.1.1.3.2.cmml" xref="S2.SS3.p1.5.m5.1.1.3.2">ğ‘„</ci><ci id="S2.SS3.p1.5.m5.1.1.3.3.cmml" xref="S2.SS3.p1.5.m5.1.1.3.3">ğ‘™</ci></apply><apply id="S2.SS3.p1.5.m5.1.1.1.cmml" xref="S2.SS3.p1.5.m5.1.1.1"><times id="S2.SS3.p1.5.m5.1.1.1.2.cmml" xref="S2.SS3.p1.5.m5.1.1.1.2"></times><apply id="S2.SS3.p1.5.m5.1.1.1.3.cmml" xref="S2.SS3.p1.5.m5.1.1.1.3"><csymbol cd="ambiguous" id="S2.SS3.p1.5.m5.1.1.1.3.1.cmml" xref="S2.SS3.p1.5.m5.1.1.1.3">subscript</csymbol><ci id="S2.SS3.p1.5.m5.1.1.1.3.2.cmml" xref="S2.SS3.p1.5.m5.1.1.1.3.2">ğ‘“</ci><ci id="S2.SS3.p1.5.m5.1.1.1.3.3.cmml" xref="S2.SS3.p1.5.m5.1.1.1.3.3">ğ‘„</ci></apply><apply id="S2.SS3.p1.5.m5.1.1.1.1.1.1.cmml" xref="S2.SS3.p1.5.m5.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS3.p1.5.m5.1.1.1.1.1.1.1.cmml" xref="S2.SS3.p1.5.m5.1.1.1.1.1">subscript</csymbol><ci id="S2.SS3.p1.5.m5.1.1.1.1.1.1.2.cmml" xref="S2.SS3.p1.5.m5.1.1.1.1.1.1.2">ğ‘‹</ci><apply id="S2.SS3.p1.5.m5.1.1.1.1.1.1.3.cmml" xref="S2.SS3.p1.5.m5.1.1.1.1.1.1.3"><minus id="S2.SS3.p1.5.m5.1.1.1.1.1.1.3.1.cmml" xref="S2.SS3.p1.5.m5.1.1.1.1.1.1.3.1"></minus><ci id="S2.SS3.p1.5.m5.1.1.1.1.1.1.3.2.cmml" xref="S2.SS3.p1.5.m5.1.1.1.1.1.1.3.2">ğ‘™</ci><cn id="S2.SS3.p1.5.m5.1.1.1.1.1.1.3.3.cmml" type="integer" xref="S2.SS3.p1.5.m5.1.1.1.1.1.1.3.3">1</cn></apply></apply></apply></apply><apply id="S2.SS3.p1.5.m5.1.1c.cmml" xref="S2.SS3.p1.5.m5.1.1"><in id="S2.SS3.p1.5.m5.1.1.5.cmml" xref="S2.SS3.p1.5.m5.1.1.5"></in><share href="https://arxiv.org/html/2409.07801v1#S2.SS3.p1.5.m5.1.1.1.cmml" id="S2.SS3.p1.5.m5.1.1d.cmml" xref="S2.SS3.p1.5.m5.1.1"></share><apply id="S2.SS3.p1.5.m5.1.1.6.cmml" xref="S2.SS3.p1.5.m5.1.1.6"><csymbol cd="ambiguous" id="S2.SS3.p1.5.m5.1.1.6.1.cmml" xref="S2.SS3.p1.5.m5.1.1.6">superscript</csymbol><ci id="S2.SS3.p1.5.m5.1.1.6.2.cmml" xref="S2.SS3.p1.5.m5.1.1.6.2">â„</ci><apply id="S2.SS3.p1.5.m5.1.1.6.3.cmml" xref="S2.SS3.p1.5.m5.1.1.6.3"><times id="S2.SS3.p1.5.m5.1.1.6.3.1.cmml" xref="S2.SS3.p1.5.m5.1.1.6.3.1"></times><ci id="S2.SS3.p1.5.m5.1.1.6.3.2.cmml" xref="S2.SS3.p1.5.m5.1.1.6.3.2">ğ‘</ci><ci id="S2.SS3.p1.5.m5.1.1.6.3.3.cmml" xref="S2.SS3.p1.5.m5.1.1.6.3.3">ğ¶</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.5.m5.1c">Q_{l}=f_{Q}(X_{l-1})\in\mathbb{R}^{N\times C}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p1.5.m5.1d">italic_Q start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT = italic_f start_POSTSUBSCRIPT italic_Q end_POSTSUBSCRIPT ( italic_X start_POSTSUBSCRIPT italic_l - 1 end_POSTSUBSCRIPT ) âˆˆ blackboard_R start_POSTSUPERSCRIPT italic_N Ã— italic_C end_POSTSUPERSCRIPT</annotation></semantics></math>. <math alttext="K_{l}" class="ltx_Math" display="inline" id="S2.SS3.p1.6.m6.1"><semantics id="S2.SS3.p1.6.m6.1a"><msub id="S2.SS3.p1.6.m6.1.1" xref="S2.SS3.p1.6.m6.1.1.cmml"><mi id="S2.SS3.p1.6.m6.1.1.2" xref="S2.SS3.p1.6.m6.1.1.2.cmml">K</mi><mi id="S2.SS3.p1.6.m6.1.1.3" xref="S2.SS3.p1.6.m6.1.1.3.cmml">l</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.6.m6.1b"><apply id="S2.SS3.p1.6.m6.1.1.cmml" xref="S2.SS3.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S2.SS3.p1.6.m6.1.1.1.cmml" xref="S2.SS3.p1.6.m6.1.1">subscript</csymbol><ci id="S2.SS3.p1.6.m6.1.1.2.cmml" xref="S2.SS3.p1.6.m6.1.1.2">ğ¾</ci><ci id="S2.SS3.p1.6.m6.1.1.3.cmml" xref="S2.SS3.p1.6.m6.1.1.3">ğ‘™</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.6.m6.1c">K_{l}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p1.6.m6.1d">italic_K start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="V_{l}\in\mathbb{R}^{H_{l}W_{l}\times C}" class="ltx_Math" display="inline" id="S2.SS3.p1.7.m7.1"><semantics id="S2.SS3.p1.7.m7.1a"><mrow id="S2.SS3.p1.7.m7.1.1" xref="S2.SS3.p1.7.m7.1.1.cmml"><msub id="S2.SS3.p1.7.m7.1.1.2" xref="S2.SS3.p1.7.m7.1.1.2.cmml"><mi id="S2.SS3.p1.7.m7.1.1.2.2" xref="S2.SS3.p1.7.m7.1.1.2.2.cmml">V</mi><mi id="S2.SS3.p1.7.m7.1.1.2.3" xref="S2.SS3.p1.7.m7.1.1.2.3.cmml">l</mi></msub><mo id="S2.SS3.p1.7.m7.1.1.1" xref="S2.SS3.p1.7.m7.1.1.1.cmml">âˆˆ</mo><msup id="S2.SS3.p1.7.m7.1.1.3" xref="S2.SS3.p1.7.m7.1.1.3.cmml"><mi id="S2.SS3.p1.7.m7.1.1.3.2" xref="S2.SS3.p1.7.m7.1.1.3.2.cmml">â„</mi><mrow id="S2.SS3.p1.7.m7.1.1.3.3" xref="S2.SS3.p1.7.m7.1.1.3.3.cmml"><mrow id="S2.SS3.p1.7.m7.1.1.3.3.2" xref="S2.SS3.p1.7.m7.1.1.3.3.2.cmml"><msub id="S2.SS3.p1.7.m7.1.1.3.3.2.2" xref="S2.SS3.p1.7.m7.1.1.3.3.2.2.cmml"><mi id="S2.SS3.p1.7.m7.1.1.3.3.2.2.2" xref="S2.SS3.p1.7.m7.1.1.3.3.2.2.2.cmml">H</mi><mi id="S2.SS3.p1.7.m7.1.1.3.3.2.2.3" xref="S2.SS3.p1.7.m7.1.1.3.3.2.2.3.cmml">l</mi></msub><mo id="S2.SS3.p1.7.m7.1.1.3.3.2.1" xref="S2.SS3.p1.7.m7.1.1.3.3.2.1.cmml">â¢</mo><msub id="S2.SS3.p1.7.m7.1.1.3.3.2.3" xref="S2.SS3.p1.7.m7.1.1.3.3.2.3.cmml"><mi id="S2.SS3.p1.7.m7.1.1.3.3.2.3.2" xref="S2.SS3.p1.7.m7.1.1.3.3.2.3.2.cmml">W</mi><mi id="S2.SS3.p1.7.m7.1.1.3.3.2.3.3" xref="S2.SS3.p1.7.m7.1.1.3.3.2.3.3.cmml">l</mi></msub></mrow><mo id="S2.SS3.p1.7.m7.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S2.SS3.p1.7.m7.1.1.3.3.1.cmml">Ã—</mo><mi id="S2.SS3.p1.7.m7.1.1.3.3.3" xref="S2.SS3.p1.7.m7.1.1.3.3.3.cmml">C</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.7.m7.1b"><apply id="S2.SS3.p1.7.m7.1.1.cmml" xref="S2.SS3.p1.7.m7.1.1"><in id="S2.SS3.p1.7.m7.1.1.1.cmml" xref="S2.SS3.p1.7.m7.1.1.1"></in><apply id="S2.SS3.p1.7.m7.1.1.2.cmml" xref="S2.SS3.p1.7.m7.1.1.2"><csymbol cd="ambiguous" id="S2.SS3.p1.7.m7.1.1.2.1.cmml" xref="S2.SS3.p1.7.m7.1.1.2">subscript</csymbol><ci id="S2.SS3.p1.7.m7.1.1.2.2.cmml" xref="S2.SS3.p1.7.m7.1.1.2.2">ğ‘‰</ci><ci id="S2.SS3.p1.7.m7.1.1.2.3.cmml" xref="S2.SS3.p1.7.m7.1.1.2.3">ğ‘™</ci></apply><apply id="S2.SS3.p1.7.m7.1.1.3.cmml" xref="S2.SS3.p1.7.m7.1.1.3"><csymbol cd="ambiguous" id="S2.SS3.p1.7.m7.1.1.3.1.cmml" xref="S2.SS3.p1.7.m7.1.1.3">superscript</csymbol><ci id="S2.SS3.p1.7.m7.1.1.3.2.cmml" xref="S2.SS3.p1.7.m7.1.1.3.2">â„</ci><apply id="S2.SS3.p1.7.m7.1.1.3.3.cmml" xref="S2.SS3.p1.7.m7.1.1.3.3"><times id="S2.SS3.p1.7.m7.1.1.3.3.1.cmml" xref="S2.SS3.p1.7.m7.1.1.3.3.1"></times><apply id="S2.SS3.p1.7.m7.1.1.3.3.2.cmml" xref="S2.SS3.p1.7.m7.1.1.3.3.2"><times id="S2.SS3.p1.7.m7.1.1.3.3.2.1.cmml" xref="S2.SS3.p1.7.m7.1.1.3.3.2.1"></times><apply id="S2.SS3.p1.7.m7.1.1.3.3.2.2.cmml" xref="S2.SS3.p1.7.m7.1.1.3.3.2.2"><csymbol cd="ambiguous" id="S2.SS3.p1.7.m7.1.1.3.3.2.2.1.cmml" xref="S2.SS3.p1.7.m7.1.1.3.3.2.2">subscript</csymbol><ci id="S2.SS3.p1.7.m7.1.1.3.3.2.2.2.cmml" xref="S2.SS3.p1.7.m7.1.1.3.3.2.2.2">ğ»</ci><ci id="S2.SS3.p1.7.m7.1.1.3.3.2.2.3.cmml" xref="S2.SS3.p1.7.m7.1.1.3.3.2.2.3">ğ‘™</ci></apply><apply id="S2.SS3.p1.7.m7.1.1.3.3.2.3.cmml" xref="S2.SS3.p1.7.m7.1.1.3.3.2.3"><csymbol cd="ambiguous" id="S2.SS3.p1.7.m7.1.1.3.3.2.3.1.cmml" xref="S2.SS3.p1.7.m7.1.1.3.3.2.3">subscript</csymbol><ci id="S2.SS3.p1.7.m7.1.1.3.3.2.3.2.cmml" xref="S2.SS3.p1.7.m7.1.1.3.3.2.3.2">ğ‘Š</ci><ci id="S2.SS3.p1.7.m7.1.1.3.3.2.3.3.cmml" xref="S2.SS3.p1.7.m7.1.1.3.3.2.3.3">ğ‘™</ci></apply></apply><ci id="S2.SS3.p1.7.m7.1.1.3.3.3.cmml" xref="S2.SS3.p1.7.m7.1.1.3.3.3">ğ¶</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.7.m7.1c">V_{l}\in\mathbb{R}^{H_{l}W_{l}\times C}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p1.7.m7.1d">italic_V start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT âˆˆ blackboard_R start_POSTSUPERSCRIPT italic_H start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT italic_W start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT Ã— italic_C end_POSTSUPERSCRIPT</annotation></semantics></math> are key and value features for the image feature of resolution <math alttext="H_{l}\times W_{l}" class="ltx_Math" display="inline" id="S2.SS3.p1.8.m8.1"><semantics id="S2.SS3.p1.8.m8.1a"><mrow id="S2.SS3.p1.8.m8.1.1" xref="S2.SS3.p1.8.m8.1.1.cmml"><msub id="S2.SS3.p1.8.m8.1.1.2" xref="S2.SS3.p1.8.m8.1.1.2.cmml"><mi id="S2.SS3.p1.8.m8.1.1.2.2" xref="S2.SS3.p1.8.m8.1.1.2.2.cmml">H</mi><mi id="S2.SS3.p1.8.m8.1.1.2.3" xref="S2.SS3.p1.8.m8.1.1.2.3.cmml">l</mi></msub><mo id="S2.SS3.p1.8.m8.1.1.1" lspace="0.222em" rspace="0.222em" xref="S2.SS3.p1.8.m8.1.1.1.cmml">Ã—</mo><msub id="S2.SS3.p1.8.m8.1.1.3" xref="S2.SS3.p1.8.m8.1.1.3.cmml"><mi id="S2.SS3.p1.8.m8.1.1.3.2" xref="S2.SS3.p1.8.m8.1.1.3.2.cmml">W</mi><mi id="S2.SS3.p1.8.m8.1.1.3.3" xref="S2.SS3.p1.8.m8.1.1.3.3.cmml">l</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.8.m8.1b"><apply id="S2.SS3.p1.8.m8.1.1.cmml" xref="S2.SS3.p1.8.m8.1.1"><times id="S2.SS3.p1.8.m8.1.1.1.cmml" xref="S2.SS3.p1.8.m8.1.1.1"></times><apply id="S2.SS3.p1.8.m8.1.1.2.cmml" xref="S2.SS3.p1.8.m8.1.1.2"><csymbol cd="ambiguous" id="S2.SS3.p1.8.m8.1.1.2.1.cmml" xref="S2.SS3.p1.8.m8.1.1.2">subscript</csymbol><ci id="S2.SS3.p1.8.m8.1.1.2.2.cmml" xref="S2.SS3.p1.8.m8.1.1.2.2">ğ»</ci><ci id="S2.SS3.p1.8.m8.1.1.2.3.cmml" xref="S2.SS3.p1.8.m8.1.1.2.3">ğ‘™</ci></apply><apply id="S2.SS3.p1.8.m8.1.1.3.cmml" xref="S2.SS3.p1.8.m8.1.1.3"><csymbol cd="ambiguous" id="S2.SS3.p1.8.m8.1.1.3.1.cmml" xref="S2.SS3.p1.8.m8.1.1.3">subscript</csymbol><ci id="S2.SS3.p1.8.m8.1.1.3.2.cmml" xref="S2.SS3.p1.8.m8.1.1.3.2">ğ‘Š</ci><ci id="S2.SS3.p1.8.m8.1.1.3.3.cmml" xref="S2.SS3.p1.8.m8.1.1.3.3">ğ‘™</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.8.m8.1c">H_{l}\times W_{l}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p1.8.m8.1d">italic_H start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT Ã— italic_W start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT</annotation></semantics></math>. <math alttext="\mathbb{M}_{l-1}\in\{0,1\}^{N\times H_{l}W_{l}}" class="ltx_Math" display="inline" id="S2.SS3.p1.9.m9.2"><semantics id="S2.SS3.p1.9.m9.2a"><mrow id="S2.SS3.p1.9.m9.2.3" xref="S2.SS3.p1.9.m9.2.3.cmml"><msub id="S2.SS3.p1.9.m9.2.3.2" xref="S2.SS3.p1.9.m9.2.3.2.cmml"><mi id="S2.SS3.p1.9.m9.2.3.2.2" xref="S2.SS3.p1.9.m9.2.3.2.2.cmml">ğ•„</mi><mrow id="S2.SS3.p1.9.m9.2.3.2.3" xref="S2.SS3.p1.9.m9.2.3.2.3.cmml"><mi id="S2.SS3.p1.9.m9.2.3.2.3.2" xref="S2.SS3.p1.9.m9.2.3.2.3.2.cmml">l</mi><mo id="S2.SS3.p1.9.m9.2.3.2.3.1" xref="S2.SS3.p1.9.m9.2.3.2.3.1.cmml">âˆ’</mo><mn id="S2.SS3.p1.9.m9.2.3.2.3.3" xref="S2.SS3.p1.9.m9.2.3.2.3.3.cmml">1</mn></mrow></msub><mo id="S2.SS3.p1.9.m9.2.3.1" xref="S2.SS3.p1.9.m9.2.3.1.cmml">âˆˆ</mo><msup id="S2.SS3.p1.9.m9.2.3.3" xref="S2.SS3.p1.9.m9.2.3.3.cmml"><mrow id="S2.SS3.p1.9.m9.2.3.3.2.2" xref="S2.SS3.p1.9.m9.2.3.3.2.1.cmml"><mo id="S2.SS3.p1.9.m9.2.3.3.2.2.1" stretchy="false" xref="S2.SS3.p1.9.m9.2.3.3.2.1.cmml">{</mo><mn id="S2.SS3.p1.9.m9.1.1" xref="S2.SS3.p1.9.m9.1.1.cmml">0</mn><mo id="S2.SS3.p1.9.m9.2.3.3.2.2.2" xref="S2.SS3.p1.9.m9.2.3.3.2.1.cmml">,</mo><mn id="S2.SS3.p1.9.m9.2.2" xref="S2.SS3.p1.9.m9.2.2.cmml">1</mn><mo id="S2.SS3.p1.9.m9.2.3.3.2.2.3" stretchy="false" xref="S2.SS3.p1.9.m9.2.3.3.2.1.cmml">}</mo></mrow><mrow id="S2.SS3.p1.9.m9.2.3.3.3" xref="S2.SS3.p1.9.m9.2.3.3.3.cmml"><mrow id="S2.SS3.p1.9.m9.2.3.3.3.2" xref="S2.SS3.p1.9.m9.2.3.3.3.2.cmml"><mi id="S2.SS3.p1.9.m9.2.3.3.3.2.2" xref="S2.SS3.p1.9.m9.2.3.3.3.2.2.cmml">N</mi><mo id="S2.SS3.p1.9.m9.2.3.3.3.2.1" lspace="0.222em" rspace="0.222em" xref="S2.SS3.p1.9.m9.2.3.3.3.2.1.cmml">Ã—</mo><msub id="S2.SS3.p1.9.m9.2.3.3.3.2.3" xref="S2.SS3.p1.9.m9.2.3.3.3.2.3.cmml"><mi id="S2.SS3.p1.9.m9.2.3.3.3.2.3.2" xref="S2.SS3.p1.9.m9.2.3.3.3.2.3.2.cmml">H</mi><mi id="S2.SS3.p1.9.m9.2.3.3.3.2.3.3" xref="S2.SS3.p1.9.m9.2.3.3.3.2.3.3.cmml">l</mi></msub></mrow><mo id="S2.SS3.p1.9.m9.2.3.3.3.1" xref="S2.SS3.p1.9.m9.2.3.3.3.1.cmml">â¢</mo><msub id="S2.SS3.p1.9.m9.2.3.3.3.3" xref="S2.SS3.p1.9.m9.2.3.3.3.3.cmml"><mi id="S2.SS3.p1.9.m9.2.3.3.3.3.2" xref="S2.SS3.p1.9.m9.2.3.3.3.3.2.cmml">W</mi><mi id="S2.SS3.p1.9.m9.2.3.3.3.3.3" xref="S2.SS3.p1.9.m9.2.3.3.3.3.3.cmml">l</mi></msub></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.9.m9.2b"><apply id="S2.SS3.p1.9.m9.2.3.cmml" xref="S2.SS3.p1.9.m9.2.3"><in id="S2.SS3.p1.9.m9.2.3.1.cmml" xref="S2.SS3.p1.9.m9.2.3.1"></in><apply id="S2.SS3.p1.9.m9.2.3.2.cmml" xref="S2.SS3.p1.9.m9.2.3.2"><csymbol cd="ambiguous" id="S2.SS3.p1.9.m9.2.3.2.1.cmml" xref="S2.SS3.p1.9.m9.2.3.2">subscript</csymbol><ci id="S2.SS3.p1.9.m9.2.3.2.2.cmml" xref="S2.SS3.p1.9.m9.2.3.2.2">ğ•„</ci><apply id="S2.SS3.p1.9.m9.2.3.2.3.cmml" xref="S2.SS3.p1.9.m9.2.3.2.3"><minus id="S2.SS3.p1.9.m9.2.3.2.3.1.cmml" xref="S2.SS3.p1.9.m9.2.3.2.3.1"></minus><ci id="S2.SS3.p1.9.m9.2.3.2.3.2.cmml" xref="S2.SS3.p1.9.m9.2.3.2.3.2">ğ‘™</ci><cn id="S2.SS3.p1.9.m9.2.3.2.3.3.cmml" type="integer" xref="S2.SS3.p1.9.m9.2.3.2.3.3">1</cn></apply></apply><apply id="S2.SS3.p1.9.m9.2.3.3.cmml" xref="S2.SS3.p1.9.m9.2.3.3"><csymbol cd="ambiguous" id="S2.SS3.p1.9.m9.2.3.3.1.cmml" xref="S2.SS3.p1.9.m9.2.3.3">superscript</csymbol><set id="S2.SS3.p1.9.m9.2.3.3.2.1.cmml" xref="S2.SS3.p1.9.m9.2.3.3.2.2"><cn id="S2.SS3.p1.9.m9.1.1.cmml" type="integer" xref="S2.SS3.p1.9.m9.1.1">0</cn><cn id="S2.SS3.p1.9.m9.2.2.cmml" type="integer" xref="S2.SS3.p1.9.m9.2.2">1</cn></set><apply id="S2.SS3.p1.9.m9.2.3.3.3.cmml" xref="S2.SS3.p1.9.m9.2.3.3.3"><times id="S2.SS3.p1.9.m9.2.3.3.3.1.cmml" xref="S2.SS3.p1.9.m9.2.3.3.3.1"></times><apply id="S2.SS3.p1.9.m9.2.3.3.3.2.cmml" xref="S2.SS3.p1.9.m9.2.3.3.3.2"><times id="S2.SS3.p1.9.m9.2.3.3.3.2.1.cmml" xref="S2.SS3.p1.9.m9.2.3.3.3.2.1"></times><ci id="S2.SS3.p1.9.m9.2.3.3.3.2.2.cmml" xref="S2.SS3.p1.9.m9.2.3.3.3.2.2">ğ‘</ci><apply id="S2.SS3.p1.9.m9.2.3.3.3.2.3.cmml" xref="S2.SS3.p1.9.m9.2.3.3.3.2.3"><csymbol cd="ambiguous" id="S2.SS3.p1.9.m9.2.3.3.3.2.3.1.cmml" xref="S2.SS3.p1.9.m9.2.3.3.3.2.3">subscript</csymbol><ci id="S2.SS3.p1.9.m9.2.3.3.3.2.3.2.cmml" xref="S2.SS3.p1.9.m9.2.3.3.3.2.3.2">ğ»</ci><ci id="S2.SS3.p1.9.m9.2.3.3.3.2.3.3.cmml" xref="S2.SS3.p1.9.m9.2.3.3.3.2.3.3">ğ‘™</ci></apply></apply><apply id="S2.SS3.p1.9.m9.2.3.3.3.3.cmml" xref="S2.SS3.p1.9.m9.2.3.3.3.3"><csymbol cd="ambiguous" id="S2.SS3.p1.9.m9.2.3.3.3.3.1.cmml" xref="S2.SS3.p1.9.m9.2.3.3.3.3">subscript</csymbol><ci id="S2.SS3.p1.9.m9.2.3.3.3.3.2.cmml" xref="S2.SS3.p1.9.m9.2.3.3.3.3.2">ğ‘Š</ci><ci id="S2.SS3.p1.9.m9.2.3.3.3.3.3.cmml" xref="S2.SS3.p1.9.m9.2.3.3.3.3.3">ğ‘™</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.9.m9.2c">\mathbb{M}_{l-1}\in\{0,1\}^{N\times H_{l}W_{l}}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p1.9.m9.2d">blackboard_M start_POSTSUBSCRIPT italic_l - 1 end_POSTSUBSCRIPT âˆˆ { 0 , 1 } start_POSTSUPERSCRIPT italic_N Ã— italic_H start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT italic_W start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT end_POSTSUPERSCRIPT</annotation></semantics></math> is the attention mask.
In addition, Mask2former benefits from high-resolution features provided by its pixel decoder, which receives feature maps from a backbone ConvNet model and at a time feeds one scale of the features to the transformer decoder. Moreover, Mask2former query features are learned via a learnable positional embedding from zero initialization.
We use the realization and tiny <em class="ltx_emph ltx_font_italic" id="S2.SS3.p1.9.1">Swin</em>Â <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#bib.bib11" title="">11</a>]</cite> backbone provided by <em class="ltx_emph ltx_font_italic" id="S2.SS3.p1.9.2">hugging face</em>Â <span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a class="ltx_ref ltx_url" href="https://huggingface.co/docs/transformers/model_doc/mask2former" title="">https://huggingface.co/docs/transformers/modelË™doc/mask2former</a></span></span></span>.</p>
</div>
<div class="ltx_para" id="S2.SS3.p2">
<p class="ltx_p" id="S2.SS3.p2.4">The training loss comprises of a mask loss as well as class loss <math alttext="\mathcal{L}=\mathcal{L}_{mask}+\lambda_{cls}\mathcal{L}_{cls}" class="ltx_Math" display="inline" id="S2.SS3.p2.1.m1.1"><semantics id="S2.SS3.p2.1.m1.1a"><mrow id="S2.SS3.p2.1.m1.1.1" xref="S2.SS3.p2.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS3.p2.1.m1.1.1.2" xref="S2.SS3.p2.1.m1.1.1.2.cmml">â„’</mi><mo id="S2.SS3.p2.1.m1.1.1.1" xref="S2.SS3.p2.1.m1.1.1.1.cmml">=</mo><mrow id="S2.SS3.p2.1.m1.1.1.3" xref="S2.SS3.p2.1.m1.1.1.3.cmml"><msub id="S2.SS3.p2.1.m1.1.1.3.2" xref="S2.SS3.p2.1.m1.1.1.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS3.p2.1.m1.1.1.3.2.2" xref="S2.SS3.p2.1.m1.1.1.3.2.2.cmml">â„’</mi><mrow id="S2.SS3.p2.1.m1.1.1.3.2.3" xref="S2.SS3.p2.1.m1.1.1.3.2.3.cmml"><mi id="S2.SS3.p2.1.m1.1.1.3.2.3.2" xref="S2.SS3.p2.1.m1.1.1.3.2.3.2.cmml">m</mi><mo id="S2.SS3.p2.1.m1.1.1.3.2.3.1" xref="S2.SS3.p2.1.m1.1.1.3.2.3.1.cmml">â¢</mo><mi id="S2.SS3.p2.1.m1.1.1.3.2.3.3" xref="S2.SS3.p2.1.m1.1.1.3.2.3.3.cmml">a</mi><mo id="S2.SS3.p2.1.m1.1.1.3.2.3.1a" xref="S2.SS3.p2.1.m1.1.1.3.2.3.1.cmml">â¢</mo><mi id="S2.SS3.p2.1.m1.1.1.3.2.3.4" xref="S2.SS3.p2.1.m1.1.1.3.2.3.4.cmml">s</mi><mo id="S2.SS3.p2.1.m1.1.1.3.2.3.1b" xref="S2.SS3.p2.1.m1.1.1.3.2.3.1.cmml">â¢</mo><mi id="S2.SS3.p2.1.m1.1.1.3.2.3.5" xref="S2.SS3.p2.1.m1.1.1.3.2.3.5.cmml">k</mi></mrow></msub><mo id="S2.SS3.p2.1.m1.1.1.3.1" xref="S2.SS3.p2.1.m1.1.1.3.1.cmml">+</mo><mrow id="S2.SS3.p2.1.m1.1.1.3.3" xref="S2.SS3.p2.1.m1.1.1.3.3.cmml"><msub id="S2.SS3.p2.1.m1.1.1.3.3.2" xref="S2.SS3.p2.1.m1.1.1.3.3.2.cmml"><mi id="S2.SS3.p2.1.m1.1.1.3.3.2.2" xref="S2.SS3.p2.1.m1.1.1.3.3.2.2.cmml">Î»</mi><mrow id="S2.SS3.p2.1.m1.1.1.3.3.2.3" xref="S2.SS3.p2.1.m1.1.1.3.3.2.3.cmml"><mi id="S2.SS3.p2.1.m1.1.1.3.3.2.3.2" xref="S2.SS3.p2.1.m1.1.1.3.3.2.3.2.cmml">c</mi><mo id="S2.SS3.p2.1.m1.1.1.3.3.2.3.1" xref="S2.SS3.p2.1.m1.1.1.3.3.2.3.1.cmml">â¢</mo><mi id="S2.SS3.p2.1.m1.1.1.3.3.2.3.3" xref="S2.SS3.p2.1.m1.1.1.3.3.2.3.3.cmml">l</mi><mo id="S2.SS3.p2.1.m1.1.1.3.3.2.3.1a" xref="S2.SS3.p2.1.m1.1.1.3.3.2.3.1.cmml">â¢</mo><mi id="S2.SS3.p2.1.m1.1.1.3.3.2.3.4" xref="S2.SS3.p2.1.m1.1.1.3.3.2.3.4.cmml">s</mi></mrow></msub><mo id="S2.SS3.p2.1.m1.1.1.3.3.1" xref="S2.SS3.p2.1.m1.1.1.3.3.1.cmml">â¢</mo><msub id="S2.SS3.p2.1.m1.1.1.3.3.3" xref="S2.SS3.p2.1.m1.1.1.3.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS3.p2.1.m1.1.1.3.3.3.2" xref="S2.SS3.p2.1.m1.1.1.3.3.3.2.cmml">â„’</mi><mrow id="S2.SS3.p2.1.m1.1.1.3.3.3.3" xref="S2.SS3.p2.1.m1.1.1.3.3.3.3.cmml"><mi id="S2.SS3.p2.1.m1.1.1.3.3.3.3.2" xref="S2.SS3.p2.1.m1.1.1.3.3.3.3.2.cmml">c</mi><mo id="S2.SS3.p2.1.m1.1.1.3.3.3.3.1" xref="S2.SS3.p2.1.m1.1.1.3.3.3.3.1.cmml">â¢</mo><mi id="S2.SS3.p2.1.m1.1.1.3.3.3.3.3" xref="S2.SS3.p2.1.m1.1.1.3.3.3.3.3.cmml">l</mi><mo id="S2.SS3.p2.1.m1.1.1.3.3.3.3.1a" xref="S2.SS3.p2.1.m1.1.1.3.3.3.3.1.cmml">â¢</mo><mi id="S2.SS3.p2.1.m1.1.1.3.3.3.3.4" xref="S2.SS3.p2.1.m1.1.1.3.3.3.3.4.cmml">s</mi></mrow></msub></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.1.m1.1b"><apply id="S2.SS3.p2.1.m1.1.1.cmml" xref="S2.SS3.p2.1.m1.1.1"><eq id="S2.SS3.p2.1.m1.1.1.1.cmml" xref="S2.SS3.p2.1.m1.1.1.1"></eq><ci id="S2.SS3.p2.1.m1.1.1.2.cmml" xref="S2.SS3.p2.1.m1.1.1.2">â„’</ci><apply id="S2.SS3.p2.1.m1.1.1.3.cmml" xref="S2.SS3.p2.1.m1.1.1.3"><plus id="S2.SS3.p2.1.m1.1.1.3.1.cmml" xref="S2.SS3.p2.1.m1.1.1.3.1"></plus><apply id="S2.SS3.p2.1.m1.1.1.3.2.cmml" xref="S2.SS3.p2.1.m1.1.1.3.2"><csymbol cd="ambiguous" id="S2.SS3.p2.1.m1.1.1.3.2.1.cmml" xref="S2.SS3.p2.1.m1.1.1.3.2">subscript</csymbol><ci id="S2.SS3.p2.1.m1.1.1.3.2.2.cmml" xref="S2.SS3.p2.1.m1.1.1.3.2.2">â„’</ci><apply id="S2.SS3.p2.1.m1.1.1.3.2.3.cmml" xref="S2.SS3.p2.1.m1.1.1.3.2.3"><times id="S2.SS3.p2.1.m1.1.1.3.2.3.1.cmml" xref="S2.SS3.p2.1.m1.1.1.3.2.3.1"></times><ci id="S2.SS3.p2.1.m1.1.1.3.2.3.2.cmml" xref="S2.SS3.p2.1.m1.1.1.3.2.3.2">ğ‘š</ci><ci id="S2.SS3.p2.1.m1.1.1.3.2.3.3.cmml" xref="S2.SS3.p2.1.m1.1.1.3.2.3.3">ğ‘</ci><ci id="S2.SS3.p2.1.m1.1.1.3.2.3.4.cmml" xref="S2.SS3.p2.1.m1.1.1.3.2.3.4">ğ‘ </ci><ci id="S2.SS3.p2.1.m1.1.1.3.2.3.5.cmml" xref="S2.SS3.p2.1.m1.1.1.3.2.3.5">ğ‘˜</ci></apply></apply><apply id="S2.SS3.p2.1.m1.1.1.3.3.cmml" xref="S2.SS3.p2.1.m1.1.1.3.3"><times id="S2.SS3.p2.1.m1.1.1.3.3.1.cmml" xref="S2.SS3.p2.1.m1.1.1.3.3.1"></times><apply id="S2.SS3.p2.1.m1.1.1.3.3.2.cmml" xref="S2.SS3.p2.1.m1.1.1.3.3.2"><csymbol cd="ambiguous" id="S2.SS3.p2.1.m1.1.1.3.3.2.1.cmml" xref="S2.SS3.p2.1.m1.1.1.3.3.2">subscript</csymbol><ci id="S2.SS3.p2.1.m1.1.1.3.3.2.2.cmml" xref="S2.SS3.p2.1.m1.1.1.3.3.2.2">ğœ†</ci><apply id="S2.SS3.p2.1.m1.1.1.3.3.2.3.cmml" xref="S2.SS3.p2.1.m1.1.1.3.3.2.3"><times id="S2.SS3.p2.1.m1.1.1.3.3.2.3.1.cmml" xref="S2.SS3.p2.1.m1.1.1.3.3.2.3.1"></times><ci id="S2.SS3.p2.1.m1.1.1.3.3.2.3.2.cmml" xref="S2.SS3.p2.1.m1.1.1.3.3.2.3.2">ğ‘</ci><ci id="S2.SS3.p2.1.m1.1.1.3.3.2.3.3.cmml" xref="S2.SS3.p2.1.m1.1.1.3.3.2.3.3">ğ‘™</ci><ci id="S2.SS3.p2.1.m1.1.1.3.3.2.3.4.cmml" xref="S2.SS3.p2.1.m1.1.1.3.3.2.3.4">ğ‘ </ci></apply></apply><apply id="S2.SS3.p2.1.m1.1.1.3.3.3.cmml" xref="S2.SS3.p2.1.m1.1.1.3.3.3"><csymbol cd="ambiguous" id="S2.SS3.p2.1.m1.1.1.3.3.3.1.cmml" xref="S2.SS3.p2.1.m1.1.1.3.3.3">subscript</csymbol><ci id="S2.SS3.p2.1.m1.1.1.3.3.3.2.cmml" xref="S2.SS3.p2.1.m1.1.1.3.3.3.2">â„’</ci><apply id="S2.SS3.p2.1.m1.1.1.3.3.3.3.cmml" xref="S2.SS3.p2.1.m1.1.1.3.3.3.3"><times id="S2.SS3.p2.1.m1.1.1.3.3.3.3.1.cmml" xref="S2.SS3.p2.1.m1.1.1.3.3.3.3.1"></times><ci id="S2.SS3.p2.1.m1.1.1.3.3.3.3.2.cmml" xref="S2.SS3.p2.1.m1.1.1.3.3.3.3.2">ğ‘</ci><ci id="S2.SS3.p2.1.m1.1.1.3.3.3.3.3.cmml" xref="S2.SS3.p2.1.m1.1.1.3.3.3.3.3">ğ‘™</ci><ci id="S2.SS3.p2.1.m1.1.1.3.3.3.3.4.cmml" xref="S2.SS3.p2.1.m1.1.1.3.3.3.3.4">ğ‘ </ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.1.m1.1c">\mathcal{L}=\mathcal{L}_{mask}+\lambda_{cls}\mathcal{L}_{cls}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p2.1.m1.1d">caligraphic_L = caligraphic_L start_POSTSUBSCRIPT italic_m italic_a italic_s italic_k end_POSTSUBSCRIPT + italic_Î» start_POSTSUBSCRIPT italic_c italic_l italic_s end_POSTSUBSCRIPT caligraphic_L start_POSTSUBSCRIPT italic_c italic_l italic_s end_POSTSUBSCRIPT</annotation></semantics></math> where <math alttext="\mathcal{L}_{cls}=\lambda_{ce}\mathcal{L}_{ce}+\lambda_{dice}\mathcal{L}_{dice}" class="ltx_Math" display="inline" id="S2.SS3.p2.2.m2.1"><semantics id="S2.SS3.p2.2.m2.1a"><mrow id="S2.SS3.p2.2.m2.1.1" xref="S2.SS3.p2.2.m2.1.1.cmml"><msub id="S2.SS3.p2.2.m2.1.1.2" xref="S2.SS3.p2.2.m2.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS3.p2.2.m2.1.1.2.2" xref="S2.SS3.p2.2.m2.1.1.2.2.cmml">â„’</mi><mrow id="S2.SS3.p2.2.m2.1.1.2.3" xref="S2.SS3.p2.2.m2.1.1.2.3.cmml"><mi id="S2.SS3.p2.2.m2.1.1.2.3.2" xref="S2.SS3.p2.2.m2.1.1.2.3.2.cmml">c</mi><mo id="S2.SS3.p2.2.m2.1.1.2.3.1" xref="S2.SS3.p2.2.m2.1.1.2.3.1.cmml">â¢</mo><mi id="S2.SS3.p2.2.m2.1.1.2.3.3" xref="S2.SS3.p2.2.m2.1.1.2.3.3.cmml">l</mi><mo id="S2.SS3.p2.2.m2.1.1.2.3.1a" xref="S2.SS3.p2.2.m2.1.1.2.3.1.cmml">â¢</mo><mi id="S2.SS3.p2.2.m2.1.1.2.3.4" xref="S2.SS3.p2.2.m2.1.1.2.3.4.cmml">s</mi></mrow></msub><mo id="S2.SS3.p2.2.m2.1.1.1" xref="S2.SS3.p2.2.m2.1.1.1.cmml">=</mo><mrow id="S2.SS3.p2.2.m2.1.1.3" xref="S2.SS3.p2.2.m2.1.1.3.cmml"><mrow id="S2.SS3.p2.2.m2.1.1.3.2" xref="S2.SS3.p2.2.m2.1.1.3.2.cmml"><msub id="S2.SS3.p2.2.m2.1.1.3.2.2" xref="S2.SS3.p2.2.m2.1.1.3.2.2.cmml"><mi id="S2.SS3.p2.2.m2.1.1.3.2.2.2" xref="S2.SS3.p2.2.m2.1.1.3.2.2.2.cmml">Î»</mi><mrow id="S2.SS3.p2.2.m2.1.1.3.2.2.3" xref="S2.SS3.p2.2.m2.1.1.3.2.2.3.cmml"><mi id="S2.SS3.p2.2.m2.1.1.3.2.2.3.2" xref="S2.SS3.p2.2.m2.1.1.3.2.2.3.2.cmml">c</mi><mo id="S2.SS3.p2.2.m2.1.1.3.2.2.3.1" xref="S2.SS3.p2.2.m2.1.1.3.2.2.3.1.cmml">â¢</mo><mi id="S2.SS3.p2.2.m2.1.1.3.2.2.3.3" xref="S2.SS3.p2.2.m2.1.1.3.2.2.3.3.cmml">e</mi></mrow></msub><mo id="S2.SS3.p2.2.m2.1.1.3.2.1" xref="S2.SS3.p2.2.m2.1.1.3.2.1.cmml">â¢</mo><msub id="S2.SS3.p2.2.m2.1.1.3.2.3" xref="S2.SS3.p2.2.m2.1.1.3.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS3.p2.2.m2.1.1.3.2.3.2" xref="S2.SS3.p2.2.m2.1.1.3.2.3.2.cmml">â„’</mi><mrow id="S2.SS3.p2.2.m2.1.1.3.2.3.3" xref="S2.SS3.p2.2.m2.1.1.3.2.3.3.cmml"><mi id="S2.SS3.p2.2.m2.1.1.3.2.3.3.2" xref="S2.SS3.p2.2.m2.1.1.3.2.3.3.2.cmml">c</mi><mo id="S2.SS3.p2.2.m2.1.1.3.2.3.3.1" xref="S2.SS3.p2.2.m2.1.1.3.2.3.3.1.cmml">â¢</mo><mi id="S2.SS3.p2.2.m2.1.1.3.2.3.3.3" xref="S2.SS3.p2.2.m2.1.1.3.2.3.3.3.cmml">e</mi></mrow></msub></mrow><mo id="S2.SS3.p2.2.m2.1.1.3.1" xref="S2.SS3.p2.2.m2.1.1.3.1.cmml">+</mo><mrow id="S2.SS3.p2.2.m2.1.1.3.3" xref="S2.SS3.p2.2.m2.1.1.3.3.cmml"><msub id="S2.SS3.p2.2.m2.1.1.3.3.2" xref="S2.SS3.p2.2.m2.1.1.3.3.2.cmml"><mi id="S2.SS3.p2.2.m2.1.1.3.3.2.2" xref="S2.SS3.p2.2.m2.1.1.3.3.2.2.cmml">Î»</mi><mrow id="S2.SS3.p2.2.m2.1.1.3.3.2.3" xref="S2.SS3.p2.2.m2.1.1.3.3.2.3.cmml"><mi id="S2.SS3.p2.2.m2.1.1.3.3.2.3.2" xref="S2.SS3.p2.2.m2.1.1.3.3.2.3.2.cmml">d</mi><mo id="S2.SS3.p2.2.m2.1.1.3.3.2.3.1" xref="S2.SS3.p2.2.m2.1.1.3.3.2.3.1.cmml">â¢</mo><mi id="S2.SS3.p2.2.m2.1.1.3.3.2.3.3" xref="S2.SS3.p2.2.m2.1.1.3.3.2.3.3.cmml">i</mi><mo id="S2.SS3.p2.2.m2.1.1.3.3.2.3.1a" xref="S2.SS3.p2.2.m2.1.1.3.3.2.3.1.cmml">â¢</mo><mi id="S2.SS3.p2.2.m2.1.1.3.3.2.3.4" xref="S2.SS3.p2.2.m2.1.1.3.3.2.3.4.cmml">c</mi><mo id="S2.SS3.p2.2.m2.1.1.3.3.2.3.1b" xref="S2.SS3.p2.2.m2.1.1.3.3.2.3.1.cmml">â¢</mo><mi id="S2.SS3.p2.2.m2.1.1.3.3.2.3.5" xref="S2.SS3.p2.2.m2.1.1.3.3.2.3.5.cmml">e</mi></mrow></msub><mo id="S2.SS3.p2.2.m2.1.1.3.3.1" xref="S2.SS3.p2.2.m2.1.1.3.3.1.cmml">â¢</mo><msub id="S2.SS3.p2.2.m2.1.1.3.3.3" xref="S2.SS3.p2.2.m2.1.1.3.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS3.p2.2.m2.1.1.3.3.3.2" xref="S2.SS3.p2.2.m2.1.1.3.3.3.2.cmml">â„’</mi><mrow id="S2.SS3.p2.2.m2.1.1.3.3.3.3" xref="S2.SS3.p2.2.m2.1.1.3.3.3.3.cmml"><mi id="S2.SS3.p2.2.m2.1.1.3.3.3.3.2" xref="S2.SS3.p2.2.m2.1.1.3.3.3.3.2.cmml">d</mi><mo id="S2.SS3.p2.2.m2.1.1.3.3.3.3.1" xref="S2.SS3.p2.2.m2.1.1.3.3.3.3.1.cmml">â¢</mo><mi id="S2.SS3.p2.2.m2.1.1.3.3.3.3.3" xref="S2.SS3.p2.2.m2.1.1.3.3.3.3.3.cmml">i</mi><mo id="S2.SS3.p2.2.m2.1.1.3.3.3.3.1a" xref="S2.SS3.p2.2.m2.1.1.3.3.3.3.1.cmml">â¢</mo><mi id="S2.SS3.p2.2.m2.1.1.3.3.3.3.4" xref="S2.SS3.p2.2.m2.1.1.3.3.3.3.4.cmml">c</mi><mo id="S2.SS3.p2.2.m2.1.1.3.3.3.3.1b" xref="S2.SS3.p2.2.m2.1.1.3.3.3.3.1.cmml">â¢</mo><mi id="S2.SS3.p2.2.m2.1.1.3.3.3.3.5" xref="S2.SS3.p2.2.m2.1.1.3.3.3.3.5.cmml">e</mi></mrow></msub></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.2.m2.1b"><apply id="S2.SS3.p2.2.m2.1.1.cmml" xref="S2.SS3.p2.2.m2.1.1"><eq id="S2.SS3.p2.2.m2.1.1.1.cmml" xref="S2.SS3.p2.2.m2.1.1.1"></eq><apply id="S2.SS3.p2.2.m2.1.1.2.cmml" xref="S2.SS3.p2.2.m2.1.1.2"><csymbol cd="ambiguous" id="S2.SS3.p2.2.m2.1.1.2.1.cmml" xref="S2.SS3.p2.2.m2.1.1.2">subscript</csymbol><ci id="S2.SS3.p2.2.m2.1.1.2.2.cmml" xref="S2.SS3.p2.2.m2.1.1.2.2">â„’</ci><apply id="S2.SS3.p2.2.m2.1.1.2.3.cmml" xref="S2.SS3.p2.2.m2.1.1.2.3"><times id="S2.SS3.p2.2.m2.1.1.2.3.1.cmml" xref="S2.SS3.p2.2.m2.1.1.2.3.1"></times><ci id="S2.SS3.p2.2.m2.1.1.2.3.2.cmml" xref="S2.SS3.p2.2.m2.1.1.2.3.2">ğ‘</ci><ci id="S2.SS3.p2.2.m2.1.1.2.3.3.cmml" xref="S2.SS3.p2.2.m2.1.1.2.3.3">ğ‘™</ci><ci id="S2.SS3.p2.2.m2.1.1.2.3.4.cmml" xref="S2.SS3.p2.2.m2.1.1.2.3.4">ğ‘ </ci></apply></apply><apply id="S2.SS3.p2.2.m2.1.1.3.cmml" xref="S2.SS3.p2.2.m2.1.1.3"><plus id="S2.SS3.p2.2.m2.1.1.3.1.cmml" xref="S2.SS3.p2.2.m2.1.1.3.1"></plus><apply id="S2.SS3.p2.2.m2.1.1.3.2.cmml" xref="S2.SS3.p2.2.m2.1.1.3.2"><times id="S2.SS3.p2.2.m2.1.1.3.2.1.cmml" xref="S2.SS3.p2.2.m2.1.1.3.2.1"></times><apply id="S2.SS3.p2.2.m2.1.1.3.2.2.cmml" xref="S2.SS3.p2.2.m2.1.1.3.2.2"><csymbol cd="ambiguous" id="S2.SS3.p2.2.m2.1.1.3.2.2.1.cmml" xref="S2.SS3.p2.2.m2.1.1.3.2.2">subscript</csymbol><ci id="S2.SS3.p2.2.m2.1.1.3.2.2.2.cmml" xref="S2.SS3.p2.2.m2.1.1.3.2.2.2">ğœ†</ci><apply id="S2.SS3.p2.2.m2.1.1.3.2.2.3.cmml" xref="S2.SS3.p2.2.m2.1.1.3.2.2.3"><times id="S2.SS3.p2.2.m2.1.1.3.2.2.3.1.cmml" xref="S2.SS3.p2.2.m2.1.1.3.2.2.3.1"></times><ci id="S2.SS3.p2.2.m2.1.1.3.2.2.3.2.cmml" xref="S2.SS3.p2.2.m2.1.1.3.2.2.3.2">ğ‘</ci><ci id="S2.SS3.p2.2.m2.1.1.3.2.2.3.3.cmml" xref="S2.SS3.p2.2.m2.1.1.3.2.2.3.3">ğ‘’</ci></apply></apply><apply id="S2.SS3.p2.2.m2.1.1.3.2.3.cmml" xref="S2.SS3.p2.2.m2.1.1.3.2.3"><csymbol cd="ambiguous" id="S2.SS3.p2.2.m2.1.1.3.2.3.1.cmml" xref="S2.SS3.p2.2.m2.1.1.3.2.3">subscript</csymbol><ci id="S2.SS3.p2.2.m2.1.1.3.2.3.2.cmml" xref="S2.SS3.p2.2.m2.1.1.3.2.3.2">â„’</ci><apply id="S2.SS3.p2.2.m2.1.1.3.2.3.3.cmml" xref="S2.SS3.p2.2.m2.1.1.3.2.3.3"><times id="S2.SS3.p2.2.m2.1.1.3.2.3.3.1.cmml" xref="S2.SS3.p2.2.m2.1.1.3.2.3.3.1"></times><ci id="S2.SS3.p2.2.m2.1.1.3.2.3.3.2.cmml" xref="S2.SS3.p2.2.m2.1.1.3.2.3.3.2">ğ‘</ci><ci id="S2.SS3.p2.2.m2.1.1.3.2.3.3.3.cmml" xref="S2.SS3.p2.2.m2.1.1.3.2.3.3.3">ğ‘’</ci></apply></apply></apply><apply id="S2.SS3.p2.2.m2.1.1.3.3.cmml" xref="S2.SS3.p2.2.m2.1.1.3.3"><times id="S2.SS3.p2.2.m2.1.1.3.3.1.cmml" xref="S2.SS3.p2.2.m2.1.1.3.3.1"></times><apply id="S2.SS3.p2.2.m2.1.1.3.3.2.cmml" xref="S2.SS3.p2.2.m2.1.1.3.3.2"><csymbol cd="ambiguous" id="S2.SS3.p2.2.m2.1.1.3.3.2.1.cmml" xref="S2.SS3.p2.2.m2.1.1.3.3.2">subscript</csymbol><ci id="S2.SS3.p2.2.m2.1.1.3.3.2.2.cmml" xref="S2.SS3.p2.2.m2.1.1.3.3.2.2">ğœ†</ci><apply id="S2.SS3.p2.2.m2.1.1.3.3.2.3.cmml" xref="S2.SS3.p2.2.m2.1.1.3.3.2.3"><times id="S2.SS3.p2.2.m2.1.1.3.3.2.3.1.cmml" xref="S2.SS3.p2.2.m2.1.1.3.3.2.3.1"></times><ci id="S2.SS3.p2.2.m2.1.1.3.3.2.3.2.cmml" xref="S2.SS3.p2.2.m2.1.1.3.3.2.3.2">ğ‘‘</ci><ci id="S2.SS3.p2.2.m2.1.1.3.3.2.3.3.cmml" xref="S2.SS3.p2.2.m2.1.1.3.3.2.3.3">ğ‘–</ci><ci id="S2.SS3.p2.2.m2.1.1.3.3.2.3.4.cmml" xref="S2.SS3.p2.2.m2.1.1.3.3.2.3.4">ğ‘</ci><ci id="S2.SS3.p2.2.m2.1.1.3.3.2.3.5.cmml" xref="S2.SS3.p2.2.m2.1.1.3.3.2.3.5">ğ‘’</ci></apply></apply><apply id="S2.SS3.p2.2.m2.1.1.3.3.3.cmml" xref="S2.SS3.p2.2.m2.1.1.3.3.3"><csymbol cd="ambiguous" id="S2.SS3.p2.2.m2.1.1.3.3.3.1.cmml" xref="S2.SS3.p2.2.m2.1.1.3.3.3">subscript</csymbol><ci id="S2.SS3.p2.2.m2.1.1.3.3.3.2.cmml" xref="S2.SS3.p2.2.m2.1.1.3.3.3.2">â„’</ci><apply id="S2.SS3.p2.2.m2.1.1.3.3.3.3.cmml" xref="S2.SS3.p2.2.m2.1.1.3.3.3.3"><times id="S2.SS3.p2.2.m2.1.1.3.3.3.3.1.cmml" xref="S2.SS3.p2.2.m2.1.1.3.3.3.3.1"></times><ci id="S2.SS3.p2.2.m2.1.1.3.3.3.3.2.cmml" xref="S2.SS3.p2.2.m2.1.1.3.3.3.3.2">ğ‘‘</ci><ci id="S2.SS3.p2.2.m2.1.1.3.3.3.3.3.cmml" xref="S2.SS3.p2.2.m2.1.1.3.3.3.3.3">ğ‘–</ci><ci id="S2.SS3.p2.2.m2.1.1.3.3.3.3.4.cmml" xref="S2.SS3.p2.2.m2.1.1.3.3.3.3.4">ğ‘</ci><ci id="S2.SS3.p2.2.m2.1.1.3.3.3.3.5.cmml" xref="S2.SS3.p2.2.m2.1.1.3.3.3.3.5">ğ‘’</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.2.m2.1c">\mathcal{L}_{cls}=\lambda_{ce}\mathcal{L}_{ce}+\lambda_{dice}\mathcal{L}_{dice}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p2.2.m2.1d">caligraphic_L start_POSTSUBSCRIPT italic_c italic_l italic_s end_POSTSUBSCRIPT = italic_Î» start_POSTSUBSCRIPT italic_c italic_e end_POSTSUBSCRIPT caligraphic_L start_POSTSUBSCRIPT italic_c italic_e end_POSTSUBSCRIPT + italic_Î» start_POSTSUBSCRIPT italic_d italic_i italic_c italic_e end_POSTSUBSCRIPT caligraphic_L start_POSTSUBSCRIPT italic_d italic_i italic_c italic_e end_POSTSUBSCRIPT</annotation></semantics></math>. <math alttext="\mathcal{L}_{ce}" class="ltx_Math" display="inline" id="S2.SS3.p2.3.m3.1"><semantics id="S2.SS3.p2.3.m3.1a"><msub id="S2.SS3.p2.3.m3.1.1" xref="S2.SS3.p2.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS3.p2.3.m3.1.1.2" xref="S2.SS3.p2.3.m3.1.1.2.cmml">â„’</mi><mrow id="S2.SS3.p2.3.m3.1.1.3" xref="S2.SS3.p2.3.m3.1.1.3.cmml"><mi id="S2.SS3.p2.3.m3.1.1.3.2" xref="S2.SS3.p2.3.m3.1.1.3.2.cmml">c</mi><mo id="S2.SS3.p2.3.m3.1.1.3.1" xref="S2.SS3.p2.3.m3.1.1.3.1.cmml">â¢</mo><mi id="S2.SS3.p2.3.m3.1.1.3.3" xref="S2.SS3.p2.3.m3.1.1.3.3.cmml">e</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.3.m3.1b"><apply id="S2.SS3.p2.3.m3.1.1.cmml" xref="S2.SS3.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS3.p2.3.m3.1.1.1.cmml" xref="S2.SS3.p2.3.m3.1.1">subscript</csymbol><ci id="S2.SS3.p2.3.m3.1.1.2.cmml" xref="S2.SS3.p2.3.m3.1.1.2">â„’</ci><apply id="S2.SS3.p2.3.m3.1.1.3.cmml" xref="S2.SS3.p2.3.m3.1.1.3"><times id="S2.SS3.p2.3.m3.1.1.3.1.cmml" xref="S2.SS3.p2.3.m3.1.1.3.1"></times><ci id="S2.SS3.p2.3.m3.1.1.3.2.cmml" xref="S2.SS3.p2.3.m3.1.1.3.2">ğ‘</ci><ci id="S2.SS3.p2.3.m3.1.1.3.3.cmml" xref="S2.SS3.p2.3.m3.1.1.3.3">ğ‘’</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.3.m3.1c">\mathcal{L}_{ce}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p2.3.m3.1d">caligraphic_L start_POSTSUBSCRIPT italic_c italic_e end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="\mathcal{L}_{dice}" class="ltx_Math" display="inline" id="S2.SS3.p2.4.m4.1"><semantics id="S2.SS3.p2.4.m4.1a"><msub id="S2.SS3.p2.4.m4.1.1" xref="S2.SS3.p2.4.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS3.p2.4.m4.1.1.2" xref="S2.SS3.p2.4.m4.1.1.2.cmml">â„’</mi><mrow id="S2.SS3.p2.4.m4.1.1.3" xref="S2.SS3.p2.4.m4.1.1.3.cmml"><mi id="S2.SS3.p2.4.m4.1.1.3.2" xref="S2.SS3.p2.4.m4.1.1.3.2.cmml">d</mi><mo id="S2.SS3.p2.4.m4.1.1.3.1" xref="S2.SS3.p2.4.m4.1.1.3.1.cmml">â¢</mo><mi id="S2.SS3.p2.4.m4.1.1.3.3" xref="S2.SS3.p2.4.m4.1.1.3.3.cmml">i</mi><mo id="S2.SS3.p2.4.m4.1.1.3.1a" xref="S2.SS3.p2.4.m4.1.1.3.1.cmml">â¢</mo><mi id="S2.SS3.p2.4.m4.1.1.3.4" xref="S2.SS3.p2.4.m4.1.1.3.4.cmml">c</mi><mo id="S2.SS3.p2.4.m4.1.1.3.1b" xref="S2.SS3.p2.4.m4.1.1.3.1.cmml">â¢</mo><mi id="S2.SS3.p2.4.m4.1.1.3.5" xref="S2.SS3.p2.4.m4.1.1.3.5.cmml">e</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.4.m4.1b"><apply id="S2.SS3.p2.4.m4.1.1.cmml" xref="S2.SS3.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S2.SS3.p2.4.m4.1.1.1.cmml" xref="S2.SS3.p2.4.m4.1.1">subscript</csymbol><ci id="S2.SS3.p2.4.m4.1.1.2.cmml" xref="S2.SS3.p2.4.m4.1.1.2">â„’</ci><apply id="S2.SS3.p2.4.m4.1.1.3.cmml" xref="S2.SS3.p2.4.m4.1.1.3"><times id="S2.SS3.p2.4.m4.1.1.3.1.cmml" xref="S2.SS3.p2.4.m4.1.1.3.1"></times><ci id="S2.SS3.p2.4.m4.1.1.3.2.cmml" xref="S2.SS3.p2.4.m4.1.1.3.2">ğ‘‘</ci><ci id="S2.SS3.p2.4.m4.1.1.3.3.cmml" xref="S2.SS3.p2.4.m4.1.1.3.3">ğ‘–</ci><ci id="S2.SS3.p2.4.m4.1.1.3.4.cmml" xref="S2.SS3.p2.4.m4.1.1.3.4">ğ‘</ci><ci id="S2.SS3.p2.4.m4.1.1.3.5.cmml" xref="S2.SS3.p2.4.m4.1.1.3.5">ğ‘’</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.4.m4.1c">\mathcal{L}_{dice}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p2.4.m4.1d">caligraphic_L start_POSTSUBSCRIPT italic_d italic_i italic_c italic_e end_POSTSUBSCRIPT</annotation></semantics></math> corresponding to Cross Entropy and dice lossÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#bib.bib14" title="">14</a>]</cite> respectively.</p>
</div>
<div class="ltx_para" id="S2.SS3.p3">
<p class="ltx_p" id="S2.SS3.p3.1">We leveraged the MaskCutÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#bib.bib21" title="">21</a>]</cite> method and generated pseudo segmentation masks on the training split of the CaDIS dataset<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#bib.bib8" title="">8</a>]</cite>. DINO-B8 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#bib.bib3" title="">3</a>]</cite> is used to extract features from the scenes of cataract surgeries. The pseudo masks from MaskCutÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#bib.bib21" title="">21</a>]</cite> are then exploited to train Mask2Former in a class-agnostic setting as a pre-training step. We named this pretraining step as self-training and further training on a labeled subset of the CaDIS as fine-tuning steps. In self-training, we trained Mask2Former for 10 epochs and chose the model with the lowest validation error. Then, we fine-tuned the self-trained Mask2Former on various amounts of annotation labels from the CaDIS dataset.

</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Evaluation</h2>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Dataset</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">CaDISÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#bib.bib8" title="">8</a>]</cite> is a subset of CATARACTSÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#bib.bib1" title="">1</a>]</cite> video dataset, which comprises a collection of sampled frames from various videos. In total, CaDIS contains 4,670 images that have been annotated pixel by pixel. These annotations are based on 36 semantic classes, which encompass 29 different surgical instruments, 4 anatomy classes, and 3 classes for other external objects. CaDIS defines three semantic segmentation tasks, each with increasing levels of detail. For our purposes, we focus on TaskII, which strikes a balance in granularity and offers labels for each class. TaskII consists of 17 classes, with 9 of them corresponding to surgical instruments.During fine-tuning stage, only training set is subsampled to 1%, 10%, 50% and they subsets contain 36, 355, 1775 samples respectively. Original val and test splits are kept for each experiments.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Metrics</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">We evaluate the semantic segmentation models based on the mean intersection over union (mIoU) and pixel-wise accuracy enabling both spatial and semantic evaluation of the results. The localization performance of unsupervised models is calculated by matching predicted masks with ground truth masks using Intersection over Union (IoU). The best match is calculated by optimizing the Hungarian algorithm. To measure the mIoU<sub class="ltx_sub" id="S3.SS2.p1.1.1"><span class="ltx_text ltx_font_italic" id="S3.SS2.p1.1.1.1">loc</span></sub> the ground truth class labels are ignored to be able to assess only the localization performance. This metric is specifically more interesting in the unsupervised stage, where instances do not belong to any class IDs.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Implementation Details</h3>
<section class="ltx_subsubsection" id="S3.SS3.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.1 </span>Self-training and Weak Supervision</h4>
<div class="ltx_para" id="S3.SS3.SSS1.p1">
<p class="ltx_p" id="S3.SS3.SSS1.p1.1">In the self-training phase, we used Mask2Former with Swin-tiny and trained it on the pseudo-masks generated by MaskCut.After hyperparameter search, we decided to use 5 pseudo masks with MaskCut per image. Mask2Former is trained only for 10 epochs to not overfit on pseudo masks considering the noisy MaskCut output. The batch size was set to 16 and horizontal flipping augmentation was used during self-training. DINO is finetuned using the default hyperparameters.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS3.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.2 </span>Fine-tuning</h4>
<div class="ltx_para" id="S3.SS3.SSS2.p1">
<p class="ltx_p" id="S3.SS3.SSS2.p1.1">After pre-training, Mask2Former is fine-tuned on the CaDIS training set. To evaluate the annotation efficiency of the proposed solution, we performed data ablation experiments on a limited subset of annotated data. Our experiments include 4 subsets of the dataset progressively increasing the annotation amount. We randomly sample 1%, 10%, 50% of the CaDIS training set. In the 10%, 50%, 100% cases, the model is trained for 50 epochs, and best model is selected on the validation set. In the 1% case, the model is trained for 200 epochs. AdamW<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#bib.bib12" title="">12</a>]</cite> with an initial learning rate 1e-4 is used in all experiments. We used a single RTX 3090 with 24 GB memory for all experiments.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S3.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Results and Discussion</h3>
<section class="ltx_subsubsection" id="S3.SS4.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.4.1 </span>Mask2Former</h4>
<div class="ltx_para" id="S3.SS4.SSS1.p1">
<p class="ltx_p" id="S3.SS4.SSS1.p1.1">The Mask2Former with a Swin backbone was trained on the training set of CaDIS dataset to provide a baseline for the results. As results suggest, Mask2Former performs slightly better than OCRNetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#bib.bib16" title="">16</a>]</cite> which is the state of the art on CaDIS dataset. OCRNet creates a soft segmentation map by dividing the contextual pixels into a set of soft object regions each assigned to a class. We continued experiments using Mask2Former thanks to its prior performance in tool segmentation, which could be more challenging to localize and convey more crucial information for surgical scene understanding.</p>
</div>
<figure class="ltx_table" id="S3.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Results for pixel-wise semantic segmentation on TaskÂ II of CaDISÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#bib.bib8" title="">8</a>]</cite> test set</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S3.T1.1" style="width:433.6pt;height:94.3pt;vertical-align:-0.9pt;"><span class="ltx_transformed_inner" style="transform:translate(-34.0pt,7.3pt) scale(0.864506510770434,0.864506510770434) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S3.T1.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T1.1.1.1.1">
<th class="ltx_td ltx_th ltx_th_column ltx_th_row" id="S3.T1.1.1.1.1.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r" id="S3.T1.1.1.1.1.2">Res</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r" id="S3.T1.1.1.1.1.3">mIoU(Anatomy)</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r" id="S3.T1.1.1.1.1.4">mIoU (Instr.)</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S3.T1.1.1.1.1.5">mIoU (All Classes)</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T1.1.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="S3.T1.1.1.2.1.1">HRNetV2Â <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#bib.bib8" title="">8</a>]</cite>
</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S3.T1.1.1.2.1.2">270x480</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S3.T1.1.1.2.1.3">-</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S3.T1.1.1.2.1.4">-</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T1.1.1.2.1.5">76.1</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.1.1.3.2.1">OCRNetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#bib.bib16" title="">16</a>]</cite>
</th>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.3.2.2">540x960</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.3.2.3">85.92</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.3.2.4"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.3.2.4.1">73.49</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.3.2.5">79.09</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S3.T1.1.1.4.3.1">Mask2FormerÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#bib.bib6" title="">6</a>]</cite>
</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.4.3.2">270x480</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.4.3.3"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.4.3.3.1">86.36</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T1.1.1.4.3.4">65.91</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.4.3.5">79.91</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.1.1.5.4.1">Mask2FormerÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#bib.bib6" title="">6</a>]</cite>
</th>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.5.4.2">540x960</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.5.4.3">86.07</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T1.1.1.5.4.4">68.53</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.5.4.5">80.51</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S3.T1.1.1.6.5.1">Ours</th>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S3.T1.1.1.6.5.2">270x480</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S3.T1.1.1.6.5.3"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.6.5.3.1">86.36</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S3.T1.1.1.6.5.4">69.55</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.1.1.6.5.5"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.6.5.5.1">80.69</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_para" id="S3.SS4.SSS1.p2">
<p class="ltx_p" id="S3.SS4.SSS1.p2.1">Comparison of our method to SOTA is summarized in TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#S3.T1" title="Table 1 â€£ 3.4.1 Mask2Former â€£ 3.4 Results and Discussion â€£ 3 Evaluation â€£ SURGIVID: Annotation-Efficient Surgical Video Object Discovery"><span class="ltx_text ltx_ref_tag">1</span></a>. Supervised Mask2Former overperforms the SOTA method. Moreover, our workflow improves the mIOU and achieves the SOTA mIOU result on CaDIS Task 2.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS4.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.4.2 </span>MaskCut</h4>
<div class="ltx_para" id="S3.SS4.SSS2.p1">
<p class="ltx_p" id="S3.SS4.SSS2.p1.1">FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#S3.F3" title="Figure 3 â€£ 3.4.3 Self-training with Mask2Former â€£ 3.4 Results and Discussion â€£ 3 Evaluation â€£ SURGIVID: Annotation-Efficient Surgical Video Object Discovery"><span class="ltx_text ltx_ref_tag">3</span></a> manifests initial course masks predicted by MaskCut for various scenes with different levels of complexity, e.g. multiple tools (FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#S3.F3" title="Figure 3 â€£ 3.4.3 Self-training with Mask2Former â€£ 3.4 Results and Discussion â€£ 3 Evaluation â€£ SURGIVID: Annotation-Efficient Surgical Video Object Discovery"><span class="ltx_text ltx_ref_tag">3</span></a>.a,d), transparent (FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#S3.F3" title="Figure 3 â€£ 3.4.3 Self-training with Mask2Former â€£ 3.4 Results and Discussion â€£ 3 Evaluation â€£ SURGIVID: Annotation-Efficient Surgical Video Object Discovery"><span class="ltx_text ltx_ref_tag">3</span></a>.c) and narrow tools (FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#S3.F3" title="Figure 3 â€£ 3.4.3 Self-training with Mask2Former â€£ 3.4 Results and Discussion â€£ 3 Evaluation â€£ SURGIVID: Annotation-Efficient Surgical Video Object Discovery"><span class="ltx_text ltx_ref_tag">3</span></a>.b). It can be seen that in most cases, MaskCut discovers at least one prominent object with correct localization. A difficulty for MaskCut seems to be narrow tools and differentiation among multiple instances especially when there is no clear distinction between the boundaries of components.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS4.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.4.3 </span>Self-training with Mask2Former</h4>
<div class="ltx_para" id="S3.SS4.SSS3.p1">
<p class="ltx_p" id="S3.SS4.SSS3.p1.1">We compare the masks generated by self-training to validate whether the course masks are further refined during training with pseudo-masks. As FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#S3.F3" title="Figure 3 â€£ 3.4.3 Self-training with Mask2Former â€£ 3.4 Results and Discussion â€£ 3 Evaluation â€£ SURGIVID: Annotation-Efficient Surgical Video Object Discovery"><span class="ltx_text ltx_ref_tag">3</span></a> illustrates, the challenging instances for MaskCut are now differentiated (FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#S3.F3" title="Figure 3 â€£ 3.4.3 Self-training with Mask2Former â€£ 3.4 Results and Discussion â€£ 3 Evaluation â€£ SURGIVID: Annotation-Efficient Surgical Video Object Discovery"><span class="ltx_text ltx_ref_tag">3</span></a>.d). Although in FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#S3.F3" title="Figure 3 â€£ 3.4.3 Self-training with Mask2Former â€£ 3.4 Results and Discussion â€£ 3 Evaluation â€£ SURGIVID: Annotation-Efficient Surgical Video Object Discovery"><span class="ltx_text ltx_ref_tag">3</span></a>.a the tool instances are not refined, the Cornea instance is added. Also in the case of FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#S3.F3" title="Figure 3 â€£ 3.4.3 Self-training with Mask2Former â€£ 3.4 Results and Discussion â€£ 3 Evaluation â€£ SURGIVID: Annotation-Efficient Surgical Video Object Discovery"><span class="ltx_text ltx_ref_tag">3</span></a>.c it can be observed that the MaskCut discovers the transparent lens injector while the mask refinement reduces the instance mask and separates the Cornea.</p>
</div>
<figure class="ltx_figure" id="S3.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="189" id="S3.F3.g1" src="extracted/5849807/figures/unsupervised.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Qualitative results of the unsupervised steps of suggested framework, namely the MaskCut and self-training. Self-training increases the segmentation quality and helps to find tools that are not detected with MaskCut. </figcaption>
</figure>
</section>
<section class="ltx_subsubsection" id="S3.SS4.SSS4">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.4.4 </span>Fine-tuning with Mask2Former</h4>
<div class="ltx_para" id="S3.SS4.SSS4.p1">
<p class="ltx_p" id="S3.SS4.SSS4.p1.2">Finally, an ablation study was designed to study the impact of annotation on the performance of a self-trained model, the results of which are summarized in TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#S3.T2" title="Table 2 â€£ 3.4.4 Fine-tuning with Mask2Former â€£ 3.4 Results and Discussion â€£ 3 Evaluation â€£ SURGIVID: Annotation-Efficient Surgical Video Object Discovery"><span class="ltx_text ltx_ref_tag">2</span></a>. Our results highlight the effectiveness of the proposed unsupervised step especially for the model with 1% annotation only indicating an accuracy and mIoU<sub class="ltx_sub" id="S3.SS4.SSS4.p1.2.1"><span class="ltx_text ltx_font_italic" id="S3.SS4.SSS4.p1.2.1.1">loc</span></sub> comparable with that of a fully-supervised model with abundant samples of annotation. The 1% annotation model falls short in the mIoU score, stemming from the lack of exposure to a balanced set of semantic classes. That is, the model may miss primary tools such as primary knife, lens injector, etc. as it may not encountered these tools at all during training. However, 1% of data is sufficient to segment anatomical structures as the anatomy classes barely vary along the surgery. As the quantity of training samples increases, the boundaries become smoother, noise is reduced, and the efficacy of class prediction improves.
Finally, as the TableÂ <a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#S3.T2" title="Table 2 â€£ 3.4.4 Fine-tuning with Mask2Former â€£ 3.4 Results and Discussion â€£ 3 Evaluation â€£ SURGIVID: Annotation-Efficient Surgical Video Object Discovery"><span class="ltx_text ltx_ref_tag">2</span></a> suggests, injection of weak supervision via phase labels during DINO fine-tuning indicates better overall IoU and more specifically <math alttext="\sim 2\%" class="ltx_Math" display="inline" id="S3.SS4.SSS4.p1.2.m2.1"><semantics id="S3.SS4.SSS4.p1.2.m2.1a"><mrow id="S3.SS4.SSS4.p1.2.m2.1.1" xref="S3.SS4.SSS4.p1.2.m2.1.1.cmml"><mi id="S3.SS4.SSS4.p1.2.m2.1.1.2" xref="S3.SS4.SSS4.p1.2.m2.1.1.2.cmml"></mi><mo id="S3.SS4.SSS4.p1.2.m2.1.1.1" xref="S3.SS4.SSS4.p1.2.m2.1.1.1.cmml">âˆ¼</mo><mrow id="S3.SS4.SSS4.p1.2.m2.1.1.3" xref="S3.SS4.SSS4.p1.2.m2.1.1.3.cmml"><mn id="S3.SS4.SSS4.p1.2.m2.1.1.3.2" xref="S3.SS4.SSS4.p1.2.m2.1.1.3.2.cmml">2</mn><mo id="S3.SS4.SSS4.p1.2.m2.1.1.3.1" xref="S3.SS4.SSS4.p1.2.m2.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS4.p1.2.m2.1b"><apply id="S3.SS4.SSS4.p1.2.m2.1.1.cmml" xref="S3.SS4.SSS4.p1.2.m2.1.1"><csymbol cd="latexml" id="S3.SS4.SSS4.p1.2.m2.1.1.1.cmml" xref="S3.SS4.SSS4.p1.2.m2.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S3.SS4.SSS4.p1.2.m2.1.1.2.cmml" xref="S3.SS4.SSS4.p1.2.m2.1.1.2">absent</csymbol><apply id="S3.SS4.SSS4.p1.2.m2.1.1.3.cmml" xref="S3.SS4.SSS4.p1.2.m2.1.1.3"><csymbol cd="latexml" id="S3.SS4.SSS4.p1.2.m2.1.1.3.1.cmml" xref="S3.SS4.SSS4.p1.2.m2.1.1.3.1">percent</csymbol><cn id="S3.SS4.SSS4.p1.2.m2.1.1.3.2.cmml" type="integer" xref="S3.SS4.SSS4.p1.2.m2.1.1.3.2">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS4.p1.2.m2.1c">\sim 2\%</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS4.p1.2.m2.1d">âˆ¼ 2 %</annotation></semantics></math> improvement of tool localization. That is, by incorporating phase segmentation as an additional supervisory task in the multi-task DINO, our proposed method focuses model attention towards surgical instruments. This is due to the fact that the type and movement of surgical tools contribute to improved differentiation of surgical phases. These observations can be used further for guided localization of objects of interest using weak supervision.</p>
</div>
<figure class="ltx_figure" id="S3.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="201" id="S3.F4.g1" src="extracted/5849807/figures/results.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Qualitative results on TaskÂ II indicating the impact of annotation via feeding gradually increasing portions of labels to the self-trained model. </figcaption>
</figure>
<figure class="ltx_table" id="S3.T2">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Semantic segmentation results of used models on TaskII of CaDISÂ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.07801v1#bib.bib8" title="">8</a>]</cite> test set. *: refers to surgical phase guided DINO model.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S3.T2.3" style="width:433.6pt;height:138.1pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-39.0pt,12.3pt) scale(0.847640249557914,0.847640249557914) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S3.T2.3.3">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T2.3.3.4.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt" colspan="2" id="S3.T2.3.3.4.1.1">Supervision</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="3" id="S3.T2.3.3.4.1.2">Model</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="6" id="S3.T2.3.3.4.1.3">Metrics</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T2.3.3.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_tt" id="S3.T2.3.3.3.4">DINO</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_rr ltx_border_tt" id="S3.T2.3.3.3.5">Subset</th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T2.3.3.3.6">Maskcut</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T2.3.3.3.7">M2F</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T2.3.3.3.8">PAC</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T2.3.3.3.9">mIoU</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T2.1.1.1.1">mIoU<sub class="ltx_sub" id="S3.T2.1.1.1.1.1"><span class="ltx_text ltx_font_italic" id="S3.T2.1.1.1.1.1.1">ana</span></sub>
</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T2.2.2.2.2">mIoU<sub class="ltx_sub" id="S3.T2.2.2.2.2.1"><span class="ltx_text ltx_font_italic" id="S3.T2.2.2.2.2.1.1">ins</span></sub>
</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T2.3.3.3.3">mIoU<sub class="ltx_sub" id="S3.T2.3.3.3.3.1"><span class="ltx_text ltx_font_italic" id="S3.T2.3.3.3.3.1.1">loc</span></sub>
</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T2.3.3.3.10">AP@50</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T2.3.3.3.11">AP@75</td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.3.5.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S3.T2.3.3.5.1.1">ImageNet</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_rr" id="S3.T2.3.3.5.1.2">0%</th>
<td class="ltx_td ltx_align_center" id="S3.T2.3.3.5.1.3">âœ“</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.3.5.1.4">âœ“</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.3.5.1.5">-</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.3.5.1.6">-</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.3.5.1.7">-</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.3.5.1.8">-</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.3.5.1.9">21.35</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.3.5.1.10">-</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.3.5.1.11">-</td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.3.6.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S3.T2.3.3.6.2.1">ImageNet</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_rr ltx_border_t" id="S3.T2.3.3.6.2.2">1%</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.3.6.2.3">âœ“</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.3.6.2.4">âœ“</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.3.6.2.5">92.73</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.3.6.2.6">71.83</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.3.6.2.7">84.12</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.3.6.2.8">43.33</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.3.6.2.9">76.29</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.3.6.2.10">56.90</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.3.6.2.11">38.65</td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.3.7.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S3.T2.3.3.7.3.1">ImageNet</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_rr" id="S3.T2.3.3.7.3.2">10%</th>
<td class="ltx_td ltx_align_center" id="S3.T2.3.3.7.3.3">âœ“</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.3.7.3.4">âœ“</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.3.7.3.5">93.90</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.3.7.3.6">75.88</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.3.7.3.7">85.80</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.3.7.3.8">52.32</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.3.7.3.9">80.69</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.3.7.3.10">72.09</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.3.7.3.11">53.53</td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.3.8.4">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S3.T2.3.3.8.4.1">ImageNet</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_rr" id="S3.T2.3.3.8.4.2">50%</th>
<td class="ltx_td ltx_align_center" id="S3.T2.3.3.8.4.3">âœ“</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.3.8.4.4">âœ“</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.3.8.4.5">94.57</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.3.8.4.6">80.32</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.3.8.4.7"><span class="ltx_text ltx_font_bold" id="S3.T2.3.3.8.4.7.1">86.52</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.3.8.4.8">67.36</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.3.8.4.9">82.54</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.3.8.4.10">81.62</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.3.8.4.11">61.45</td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.3.9.5">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S3.T2.3.3.9.5.1">ImageNet</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_rr" id="S3.T2.3.3.9.5.2">100%</th>
<td class="ltx_td ltx_align_center" id="S3.T2.3.3.9.5.3">âœ“</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.3.9.5.4">âœ“</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.3.9.5.5"><span class="ltx_text ltx_font_bold" id="S3.T2.3.3.9.5.5.1">94.62</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.3.9.5.6">80.54</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.3.9.5.7">86.11</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.3.9.5.8">67.80</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.3.9.5.9">82.58</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.3.9.5.10">80.61</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.3.9.5.11">62.50</td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.3.10.6">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S3.T2.3.3.10.6.1">ImageNet+Phase *</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_rr" id="S3.T2.3.3.10.6.2">100%</th>
<td class="ltx_td ltx_align_center" id="S3.T2.3.3.10.6.3">âœ“</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.3.10.6.4">âœ“</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.3.10.6.5">93.85</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.3.10.6.6"><span class="ltx_text ltx_font_bold" id="S3.T2.3.3.10.6.6.1">80.69</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.3.10.6.7">86.36</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.3.10.6.8"><span class="ltx_text ltx_font_bold" id="S3.T2.3.3.10.6.8.1">69.55</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.3.10.6.9"><span class="ltx_text ltx_font_bold" id="S3.T2.3.3.10.6.9.1">82.82</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.3.10.6.10"><span class="ltx_text ltx_font_bold" id="S3.T2.3.3.10.6.10.1">83.11</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.3.10.6.11"><span class="ltx_text ltx_font_bold" id="S3.T2.3.3.10.6.11.1">63.44</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.3.11.7">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="S3.T2.3.3.11.7.1">M2F Baseline</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_rr ltx_border_t" id="S3.T2.3.3.11.7.2">100%</th>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S3.T2.3.3.11.7.3">-</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S3.T2.3.3.11.7.4">âœ“</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S3.T2.3.3.11.7.5">94.51</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S3.T2.3.3.11.7.6">79.91</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S3.T2.3.3.11.7.7">86.36</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S3.T2.3.3.11.7.8">65.91</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S3.T2.3.3.11.7.9">81.56</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S3.T2.3.3.11.7.10">81.37</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S3.T2.3.3.11.7.11">59.96</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Conclusion</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">In this work, we introduce SURGIVID. This annotation-efficient workflow tackles the annotation-burdensome task of semantic segmentation for surgical videos by
bringing together the capabilities of the state-of-art self-supervised object discovery method, CutLER, and segmentation model, Mask2Former. Through extensive evaluations, we demonstrate that training a class-agnostic segmentation model on generated pseudo-masks improves the quality of the masks with no labels. By reducing the labels up to 90%, we demonstrate on-par performance with a fully-supervised setup on primary tools and anatomies within a surgical scene of CaDIS dataset. Furthermore, by leveraging weak supervision from cataract surgery phase labels, more accurate localization of instruments can be achieved.
Our proposed workflow has the potential to facilitate the utilization of large volumes of unlabeled surgical videos by the medical community. As future work, it would be valuable to explore the application of our method to a broader range of surgical procedures, in order to assess its generalizability and effectiveness in diverse clinical contexts.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
AlÂ Hajj, H., Lamard, M., Conze, P.H., Roychowdhury, S., Hu, X., MarÅ¡alkaitÄ—, G., Zisimopoulos, O., Dedmari, M.A., Zhao, F., Prellberg, J., etÂ al.: Cataracts: Challenge on automatic tool annotation for cataract surgery. Medical image analysis <span class="ltx_text ltx_font_bold" id="bib.bib1.1.1">52</span>, 24â€“41 (2019)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Blum, T., FeuÃŸner, H., Navab, N.: Modeling and segmentation of surgical workflow from laparoscopic video. In: Medical Image Computing and Computer-Assisted Interventionâ€“MICCAI 2010: 13th International Conference, Beijing, China, September 20-24, 2010, Proceedings, Part III 13. pp. 400â€“407. Springer (2010)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Caron, M., Touvron, H., Misra, I., JÃ©gou, H., Mairal, J., Bojanowski, P., Joulin, A.: Emerging properties in self-supervised vision transformers. In: Proceedings of the IEEE/CVF international conference on computer vision. pp. 9650â€“9660 (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Chen, L.C., Papandreou, G., Kokkinos, I., Murphy, K., Yuille, A.L.: Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs. IEEE transactions on pattern analysis and machine intelligence <span class="ltx_text ltx_font_bold" id="bib.bib4.1.1">40</span>(4), 834â€“848 (2017)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Chen, L.C., Zhu, Y., Papandreou, G., Schroff, F., Adam, H.: Encoder-decoder with atrous separable convolution for semantic image segmentation. In: Proceedings of the European conference on computer vision (ECCV). pp. 801â€“818 (2018)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Cheng, B., Misra, I., Schwing, A.G., Kirillov, A., Girdhar, R.: Masked-attention mask transformer for universal image segmentation. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 1290â€“1299 (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., Dehghani, M., Minderer, M., Heigold, G., Gelly, S., etÂ al.: An image is worth 16x16 words: Transformers for image recognition at scale. arXiv preprint arXiv:2010.11929 (2020)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Grammatikopoulou, M., Flouty, E., Kadkhodamohammadi, A., Quellec, G., Chow, A., Nehme, J., Luengo, I., Stoyanov, D.: Cadis: Cataract dataset for image segmentation. arXiv preprint arXiv:1906.11586 (2019)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Hira, S., Singh, D., Kim, T.S., Gupta, S., Hager, G., Sikder, S., Vedula, S.S.: Video-based assessment of intraoperative surgical skill. International Journal of Computer Assisted Radiology and Surgery <span class="ltx_text ltx_font_bold" id="bib.bib9.1.1">17</span>(10), 1801â€“1811 (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Lalys, F., Jannin, P.: Surgical process modelling: a review. International journal of computer assisted radiology and surgery <span class="ltx_text ltx_font_bold" id="bib.bib10.1.1">9</span>, 495â€“511 (2014)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Liu, Z., Lin, Y., Cao, Y., Hu, H., Wei, Y., Zhang, Z., Lin, S., Guo, B.: Swin transformer: Hierarchical vision transformer using shifted windows. In: Proceedings of the IEEE/CVF international conference on computer vision. pp. 10012â€“10022 (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Loshchilov, I., Hutter, F.: Decoupled weight decay regularization. arXiv preprint arXiv:1711.05101 (2017)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Mascagni, P., Vardazaryan, A., Alapatt, D., Urade, T., Emre, T., Fiorillo, C., Pessaux, P., Mutter, D., Marescaux, J., Costamagna, G., etÂ al.: Artificial intelligence for surgical safety: automatic assessment of the critical view of safety in laparoscopic cholecystectomy using deep learning. Annals of surgery <span class="ltx_text ltx_font_bold" id="bib.bib13.1.1">275</span>(5), 955â€“961 (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Milletari, F., Navab, N., Ahmadi, S.A.: V-net: Fully convolutional neural networks for volumetric medical image segmentation. In: 2016 fourth international conference on 3D vision (3DV). pp. 565â€“571. Ieee (2016)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Nwoye, C.I., Mutter, D., Marescaux, J., Padoy, N.: Weakly supervised convolutional lstm approach for tool tracking in laparoscopic videos. International journal of computer assisted radiology and surgery <span class="ltx_text ltx_font_bold" id="bib.bib15.1.1">14</span>, 1059â€“1067 (2019)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Pissas, T., Ravasio, C.S., DaÂ Cruz, L., Bergeles, C.: Effective semantic segmentation in cataract surgery: What matters most? In: Medical Image Computing and Computer Assisted Interventionâ€“MICCAI 2021: 24th International Conference, Strasbourg, France, September 27â€“October 1, 2021, Proceedings, Part IV 24. pp. 509â€“518. Springer (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Ronneberger, O., Fischer, P., Brox, T.: U-net: Convolutional networks for biomedical image segmentation. In: Medical Image Computing and Computer-Assisted Interventionâ€“MICCAI 2015: 18th International Conference, Munich, Germany, October 5-9, 2015, Proceedings, Part III 18. pp. 234â€“241. Springer (2015)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
SimÃ©oni, O., Puy, G., Vo, H.V., Roburin, S., Gidaris, S., Bursuc, A., PÃ©rez, P., Marlet, R., Ponce, J.: Localizing objects with self-supervised transformers and no labels. arXiv preprint arXiv:2109.14279 (2021)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Valderrama, N., RuizÂ Puentes, P., HernÃ¡ndez, I., Ayobi, N., Verlyck, M., Santander, J., Caicedo, J., FernÃ¡ndez, N., ArbelÃ¡ez, P.: Towards holistic surgical scene understanding. In: Medical Image Computing and Computer Assisted Interventionâ€“MICCAI 2022: 25th International Conference, Singapore, September 18â€“22, 2022, Proceedings, Part VII. pp. 442â€“452. Springer (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Vercauteren, T., Unberath, M., Padoy, N., Navab, N.: Cai4cai: the rise of contextual artificial intelligence in computer-assisted interventions. Proceedings of the IEEE <span class="ltx_text ltx_font_bold" id="bib.bib20.1.1">108</span>(1), 198â€“214 (2019)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Wang, X., Girdhar, R., Yu, S.X., Misra, I.: Cut and learn for unsupervised object detection and instance segmentation. arXiv preprint arXiv:2301.11320 (2023)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Wang, Y., Shen, X., Yuan, Y., Du, Y., Li, M., Hu, S.X., Crowley, J.L., Vaufreydaz, D.: Tokencut: Segmenting objects in images and videos with self-supervised transformer and normalized cut. arXiv preprint arXiv:2209.00383 (2022)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Wang, Z., Fey, A.M.: Satr-dl: improving surgical skill assessment and task recognition in robot-assisted surgery with deep neural networks. In: 2018 40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC). pp. 1793â€“1796. IEEE (2018)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Yuan, Y., Chen, X., Wang, J.: Object-contextual representations for semantic segmentation. In: Computer Visionâ€“ECCV 2020: 16th European Conference, Glasgow, UK, August 23â€“28, 2020, Proceedings, Part VI 16. pp. 173â€“190. Springer (2020)

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Zisimopoulos, O., Flouty, E., Luengo, I., Giataganas, P., Nehme, J., Chow, A., Stoyanov, D.: Deepphase: surgical phase recognition in cataracts videos. In: Medical Image Computing and Computer Assisted Interventionâ€“MICCAI 2018: 21st International Conference, Granada, Spain, September 16-20, 2018, Proceedings, Part IV 11. pp. 265â€“272. Springer (2018)

</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Thu Sep 12 06:55:33 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
