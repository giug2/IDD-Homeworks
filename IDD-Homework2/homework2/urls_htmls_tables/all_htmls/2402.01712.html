<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2402.01712] Socially Aware Synthetic Data Generation for Suicidal Ideation Detection Using Large Language Models</title><meta property="og:description" content="Suicidal ideation detection is a vital research area that holds great potential for improving mental health support systems. However, the sensitivity surrounding suicide-related data poses challenges in accessing large…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Socially Aware Synthetic Data Generation for Suicidal Ideation Detection Using Large Language Models">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Socially Aware Synthetic Data Generation for Suicidal Ideation Detection Using Large Language Models">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2402.01712">

<!--Generated on Tue Mar  5 15:48:02 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="
Artificial Intelligence,  Deep Learning,  Large Language Models,  Suicide Detection,  Synthetic Data Generation,  Transformer Based Models
">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div id="p1" class="ltx_para">
<span id="p1.1" class="ltx_ERROR undefined">\history</span>
<p id="p1.2" class="ltx_p"><a target="_blank" href="https:/doi.org/10.1109/ACCESS.2024.3358206" title="" class="ltx_ref">10.1109/ACCESS.2024.3358206</a></p>
</div>
<div id="p2" class="ltx_para">
<span id="p2.1" class="ltx_ERROR undefined">\corresp</span>
<p id="p2.2" class="ltx_p">Corresponding author: Hamideh Ghanadian (e-mail: Hghan053@ uOttawa.ca)</p>
</div>
<h1 class="ltx_title ltx_title_document">Socially Aware Synthetic Data Generation for Suicidal Ideation Detection Using Large Language Models</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">HAMIDEH GHANADIAN1
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
ISAR NEJADGHOLI2
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
HUSSEIN AL OSMAN3
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_address">University of Ottawa, Ottawa, Canada (e-mail: Hghan053@uottawa.ca)
</span>
<span class="ltx_contact ltx_role_address">National Research Council Canada, Ottawa, Canada (e-mail: Isar.nejadgholi@nrc-cnrc.gc.ca)
</span>
<span class="ltx_contact ltx_role_address">University of Ottawa, Ottawa, Canada (e-mail: Hussein.alosman@uottawa.ca)
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id4.id1" class="ltx_p">Suicidal ideation detection is a vital research area that holds great potential for improving mental health support systems. However, the sensitivity surrounding suicide-related data poses challenges in accessing large-scale, annotated datasets necessary for training effective machine learning models. To address this limitation, we introduce an innovative strategy that leverages the capabilities of generative AI models, such as ChatGPT, Flan-T5, and Llama, to create synthetic data for suicidal ideation detection. Our data generation approach is grounded in social factors extracted from psychology literature and aims to ensure coverage of essential information related to suicidal ideation.
In our study, we benchmarked against state-of-the-art NLP classification models, specifically, those centered around the BERT family structures. When trained on the real-world dataset, UMD, these conventional models tend to yield F1-scores ranging from 0.75 to 0.87. Our synthetic data-driven method, informed by social factors, offers consistent F1-scores of 0.82 for both models, suggesting that the richness of topics in synthetic data can bridge the performance gap across different model complexities. Most impressively, when we combined a mere 30% of the UMD dataset with our synthetic data, we witnessed a substantial increase in performance, achieving an F1-score of 0.88 on the UMD test set. Such results underscore the cost-effectiveness and potential of our approach in confronting major challenges in the field, such as data scarcity and the quest for diversity in data representation.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
Artificial Intelligence, Deep Learning, Large Language Models, Suicide Detection, Synthetic Data Generation, Transformer Based Models

</div>
<div id="p3" class="ltx_para">
<span id="p3.1" class="ltx_ERROR undefined">\titlepgskip</span>
<p id="p3.2" class="ltx_p">=-15pt</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">According to the World Health Organization<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a target="_blank" href="https://www.who.int/news-room/fact-sheets/detail/suicide" title="" class="ltx_ref ltx_href">The World Health Organization (WHO)</a></span></span></span> more than 700,000 people die due to suicide every year. Suicide remains a global health crisis, accounting for a significant proportion of mortality rates across various age groups. Suicidal ideation, often a precursor to actual suicide attempts, involves the presence of persistent thoughts, contemplation, or planning related to self-harm or death. Early identification of suicide ideation and intervention to protect individuals at risk of suicide are crucial steps in reducing suicide rates and providing appropriate mental health support. Early detection of suicidal ideation is a complex task, as it requires the integration of various factors, including psychological, social, and environmental variables<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">In recent years, the proliferation of digital platforms and social media has provided an unprecedented opportunity to capture and analyze large-scale data related to mental health <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>. Machine learning and Natural Language Processing (NLP) techniques have shown promise in detecting linguistic patterns and indicators of suicidal ideation in diverse text-based data sources, such as social media posts, online forums, and electronic health records<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>,<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>,<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>,<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">However, the use of machine learning technologies requires high volumes of data. Data collection and annotation processes are time-consuming and impose significant financial costs <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>. Specifically, obtaining a substantial amount of labeled data related to suicide can be challenging and limited due to several factors inherent to the nature of suicide research. The sensitive and stigmatized nature of suicide often presents barriers to data collection. Individuals and organizations may be rightfully reluctant to share personal or confidential information related to suicide, fearing potential negative consequences.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Synthetic data generation offers a viable solution to mitigate the data availability limitation by creating artificially generated data that closely resembles real-world data. Synthetic data generation can be instrumental in machine learning applications as it addresses many challenges of real data collection and annotation. Here we review a list of common challenges in data collection that can be managed through synthetic data generation.</p>
</div>
<div id="S1.p5" class="ltx_para ltx_noindent">
<p id="S1.p5.1" class="ltx_p"><span id="S1.p5.1.1" class="ltx_text ltx_font_bold">Data Scarcity:</span> In many NLP tasks, such as mental health-related applications, there may be limited availability of relevant data due to privacy concerns or the complexity and cost associated with manual annotation. Synthetic data generation allows researchers and practitioners to overcome data scarcity issues and augment the limited amount of publically available data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>.</p>
</div>
<div id="S1.p6" class="ltx_para ltx_noindent">
<p id="S1.p6.1" class="ltx_p"><span id="S1.p6.1.1" class="ltx_text ltx_font_bold">Data Diversity:</span> NLP models trained on limited data may suffer from poor generalization and performance when exposed to diverse and previously unseen examples. Moreover, in real data, certain topics can be undermined or overlooked due to being less discussed. This can happen for several reasons. For example, certain topics may be stigmatized and considered too sensitive or taboo, making people hesitant to openly discuss them. This could include subjects related to mental health, addiction, discrimination, or social issues that carry societal stigmas. Additionally, topics relevant to marginalized or minority communities may receive less discussion due to systemic biases, unequal representation, or limited platforms for their voices to be heard. Also, some topics may be highly specialized or complex, requiring specific expertise or background knowledge to engage in meaningful discussions.
Encouraging diverse perspectives and actively seeking out less-discussed topics can contribute to a more comprehensive and nuanced understanding of real-world issues. Synthetic data generation can help enrich the training data by introducing a wider variety of linguistic patterns, sentence structures, vocabulary and topics. This, in turn, improves the model’s ability to handle variations in natural language and increases its robustness <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>.</p>
</div>
<div id="S1.p7" class="ltx_para ltx_noindent">
<p id="S1.p7.1" class="ltx_p"><span id="S1.p7.1.1" class="ltx_text ltx_font_bold">Privacy Preservation:</span> Suicide detection tasks often involve sensitive information. Generating synthetic data allows researchers to create representative samples that preserve the privacy of individuals while maintaining the statistical properties and distribution of the original data. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite></p>
</div>
<div id="S1.p8" class="ltx_para ltx_noindent">
<p id="S1.p8.1" class="ltx_p"><span id="S1.p8.1.1" class="ltx_text ltx_font_bold">Annotation Cost:</span> Suicide detection is a complex task, and high-quality annotation can only be performed by experts and trained annotators, which can be costly <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>. Synthetic data generation addresses the data annotation issue by targeted data generation so that each generated example is pre-labeld with a specific category. Although these labels might be noisy to some extent, they might be preferable in some settings as they come at no additional cost.</p>
</div>
<div id="S1.p9" class="ltx_para">
<p id="S1.p9.1" class="ltx_p">To investigate the feasibility and effectiveness of synthetic data generation in the task of suicide ideation generation, we use Generative Large Language Models (GLLMs) for data synthesis and use the generated data to train/test text classifiers. To train classifiers, we fine-tune pretrained BERT-like Large Language Models (LLMs) as state-of-the-art text classifiers.</p>
</div>
<div id="S1.p10" class="ltx_para">
<p id="S1.p10.1" class="ltx_p">To enhance the quality of the generated data, we benefit from domain knowledge from psychology. Previous research highlights the importance of incorporating social factors in the design process of NLP systems <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. Specifically, when generating data with LLMs, external sources of domain knowledge can be leveraged to guide the data generation process <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>. For the task of suicidal ideation detection, such knowledge can be drawn from a vast body of research in psychology devoted to gaining an understanding of the social factors associated with suicidal ideation and behavior.
In this work, we review the psychology literature to extract the social factors tightly tied to suicidal ideation and
use this knowledge for more effective prompt engineering when generating data with GLLMs. Guiding the data generation with these factors enables the creation of diverse and representative examples of suicidal ideation.</p>
</div>
<div id="S1.p11" class="ltx_para ltx_noindent">
<p id="S1.p11.1" class="ltx_p">The main contributions of this study are as follows:</p>
</div>
<div id="S1.p12" class="ltx_para">
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">We extracted the relevant social factors associated with suicidal ideation through a comprehensive review of existing literature, research papers and clinical studies to identify key themes related to suicidal ideation. These themes encompass a wide range of factors, including risk factors, common triggers and mental health indicators. Leveraging a socially aware data synthesis approach, we pave the way for more accurate and reliable suicidal ideation detection systems.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">Our study examines three GLLMs’ performance in producing synthetic datasets with Zero-Shot and Few-Shot learning techniques. Utilizing the ChatGPT, Flan-T5, and Llama 2 models and leveraging the extracted social factors from the psychology literature, we generated nine datasets with diverse characteristics.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">We trained classifiers by fine-tuning two pre-trained language models, ALBERT and DistilBERT, using the generated datasets. We tested these models on two test sets, the University of Maryland Suicidality dataset (UMD) and a human-annotated synthetic dataset presented in this paper. Our findings indicate that the GLLMs have significant potential for generating a suicide-related dataset comparable with real available datasets such as UMD. More significantly, the integration of social knowledge may significantly enhance the quality of the generated datasets and lead to more robust classifiers.</p>
</div>
</li>
<li id="S1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i4.p1" class="ltx_para">
<p id="S1.I1.i4.p1.1" class="ltx_p">We augmented our best-performing synthetic dataset using subsets of the UMD dataset to evaluate the efficacy of data augmentation in suicidal detection applications.
Our results show that models trained with synthetic data augmented with a small set of real-world data can outperform models trained by large annotated real-world datasets.</p>
</div>
</li>
</ul>
</div>
<div id="S1.p13" class="ltx_para">
<p id="S1.p13.1" class="ltx_p">This paper is organized as follows: In Section <a href="#S2" title="II Background and Related Work ‣ Socially Aware Synthetic Data Generation for Suicidal Ideation Detection Using Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a>, we review the literature and related background. In Section <a href="#S3" title="III Methodology ‣ Socially Aware Synthetic Data Generation for Suicidal Ideation Detection Using Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a>, we explain our methodology for generating and evaluating the proposed synthetic data generation, specifics of the classifiers and datasets we use in this work. Section <a href="#S4" title="IV Results ‣ Socially Aware Synthetic Data Generation for Suicidal Ideation Detection Using Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV</span></a> presents our results, and Section <a href="#S5" title="V Discussions ‣ Socially Aware Synthetic Data Generation for Suicidal Ideation Detection Using Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">V</span></a> discusses these results in detail. Additionally, the conclusion and possible future works are discussed in Section <a href="#S6" title="VI Conclusion and Future works ‣ Socially Aware Synthetic Data Generation for Suicidal Ideation Detection Using Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">VI</span></a>. We complete the article by including an ethical statement in Section <a href="#S7" title="VII Ethical Considerations ‣ Socially Aware Synthetic Data Generation for Suicidal Ideation Detection Using Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">VII</span></a>, which delves into the ethical aspects and considerations associated with our work.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Background and Related Work</span>
</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">In this section, we review the related work in suicidal ideation detection in psychology as well as NLP research that addresses the task of suicide detection. We also review the previous works that focused on generating synthetic data for a variety of NLP tasks.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS1.5.1.1" class="ltx_text">II-A</span> </span><span id="S2.SS1.6.2" class="ltx_text ltx_font_italic"> Suicidal Ideation and Related Social Factors </span>
</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Suicidal ideation has been a subject of extensive research within the field of psychology. Understanding the underlying elements and risk factors related to suicidal thoughts and behaviors is crucial for developing effective prevention and intervention strategies.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">One important area of investigation is the identification of risk factors associated with suicidal ideation. Numerous studies have examined the impact of psychological factors such as depression, anxiety, hopelessness, and feelings of worthlessness on the development of suicidal thoughts<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>.
These Studies investigate the strong association between suicidal thoughts and conditions like depression <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>, bipolar disorder <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>, borderline personality disorder <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>, and substance abuse <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>. By examining the interplay between these conditions, researchers aim to develop targeted interventions to address the unique challenges faced by individuals struggling with suicidal ideation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>, <a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>.
Additionally, environmental factors such as a history of trauma, social isolation, and access to lethal means have been identified as potential risk factors <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>, <a href="#bib.bib25" title="" class="ltx_ref">25</a>, <a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>.</p>
</div>
<div id="S2.SS1.p3" class="ltx_para">
<p id="S2.SS1.p3.1" class="ltx_p">Psychology offers valuable insights into the diverse processes and factors that contribute to suicide risk. Psychological theories and frameworks such as the interpersonal theory of suicide <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>, the cognitive model of suicidal behavior<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>, and the social-ecological model<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> provide a theoretical foundation for understanding the complex interplay between individual vulnerabilities and environmental factors.</p>
</div>
<div id="S2.SS1.p4" class="ltx_para">
<p id="S2.SS1.p4.1" class="ltx_p">The extensive research conducted on suicidal ideation and associated topics in psychology has significantly contributed to the understanding of the complex factors involved. By unraveling the causes, risk factors, and protective factors associated with suicidal thoughts, researchers aim to develop effective prevention strategies, enhance mental health interventions, and ultimately reduce the global burden of suicide. In Section <a href="#S3.SS1" title="III-A Suicide Related Topics in Psychology ‣ III Methodology ‣ Socially Aware Synthetic Data Generation for Suicidal Ideation Detection Using Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-A</span></span></a>, we enumerate the social factors that are discussed in the literature as relevant topics to suicidal ideation.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS2.5.1.1" class="ltx_text">II-B</span> </span><span id="S2.SS2.6.2" class="ltx_text ltx_font_italic"> Suicidal Ideation Detection Using NLP</span>
</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">In recent years, there has been a growing interest in using NLP techniques for suicide prevention <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>, <a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>.
Researchers have developed suicide detection systems to analyze and interpret social media data, including text data. By detecting linguistic markers of distress and other risk factors, these systems can help identify individuals with a risk of suicidality and provide early interventions to prevent such incidents <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p">Several studies indicated the impact of social network reciprocal connectivity on users’ suicidal ideation. Hsiung et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite> analyzed the changes in user behavior following a suicide case that occurred within a social media group. Jashinsky et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite> highlighted the geographic correlation between suicide mortality rates and the occurrence of risk factors in tweets. Colombo et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> focused on analyzing tweets that contained suicidal ideation, with a particular emphasis on the users’ behavior within social network interactions that resulted in strong and reciprocal connectivity, leading to strengthened bonds between users.
NLP techniques, therefore, offer a promising avenue for suicide prevention efforts, enabling more proactive and effective interventions to support those in need.</p>
</div>
<div id="S2.SS2.p3" class="ltx_para ltx_noindent">
<p id="S2.SS2.p3.1" class="ltx_p"><span id="S2.SS2.p3.1.1" class="ltx_text ltx_font_bold">Generative Language models:</span> Ghanadian et al.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite> utilized ChatGPT for assessing suicidality from social media posts. They performed Zero-Shot and Few-Shot experiments and extensive performance comparison between ChatGPT and two fine-tuned transformer-based models. They also investigated the impact of different temperature parameters on ChatGPT’s response generation. The findings of this paper suggest that ChatGPT achieves notable accuracy in the suicidal risk assessment task; however, transformer-based pre-trained models fine-tuned on human-annotated datasets exhibit superior performance. Furthermore, the analysis provides insights into adjusting ChatGPT’s hyperparameters to enhance its effectiveness in assisting mental health professionals with this critical task.</p>
</div>
<div id="S2.SS2.p4" class="ltx_para">
<p id="S2.SS2.p4.1" class="ltx_p">Yang et al.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite> conducted a comprehensive evaluation of ChatGPT’s mental health analysis and emotional reasoning ability across five tasks. They also investigated the impact of different emotion-based prompting strategies. Additionally, they explored the use of generative models to generate explanations for the decisions made by ChatGPT, aiming for interpretable mental health analysis. The experimental results revealed that ChatGPT performed better than traditional neural network-based methods such as Convolutional Neural Network (CNN) and Gated Recurrent Unit (GRU) in mental health analysis but still lagged behind advanced task-specific methods.</p>
</div>
<div id="S2.SS2.p5" class="ltx_para ltx_noindent">
<p id="S2.SS2.p5.1" class="ltx_p"><span id="S2.SS2.p5.1.1" class="ltx_text ltx_font_bold">Available Dataset:</span> Several datasets have been collected from social media platforms to serve as a resource for creating suicidal ideation detection systems. These datasets encompass a wide range of information collected from various social media sources, including <span id="S2.SS2.p5.1.2" class="ltx_text ltx_font_italic">Twitter</span>, <span id="S2.SS2.p5.1.3" class="ltx_text ltx_font_italic">Reddit</span> and other user-generated content. Sinha et al.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite> created a manually annotated dataset from <span id="S2.SS2.p5.1.4" class="ltx_text ltx_font_italic">Twitter</span> using a lexicon of suicidal phrases and a lexicon along with the social engagement data associated with real-time and historical tweets. The resulting dataset consists of 34,306 tweets with two labels, <span id="S2.SS2.p5.1.5" class="ltx_text ltx_font_italic">Suicidal</span> and <span id="S2.SS2.p5.1.6" class="ltx_text ltx_font_italic">Non-Suicidal</span>. Gaur et al.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite> collected and annotated a 5-label Suicide Risk Severity Assessment dataset from Reddit, which includes <span id="S2.SS2.p5.1.7" class="ltx_text ltx_font_italic">Suicidal Ideation (ID)</span>, <span id="S2.SS2.p5.1.8" class="ltx_text ltx_font_italic">Suicidal Behavior (BR)</span>, <span id="S2.SS2.p5.1.9" class="ltx_text ltx_font_italic">Actual Attempt (AT)</span>, <span id="S2.SS2.p5.1.10" class="ltx_text ltx_font_italic">Suicide Indicator (IN)</span> and <span id="S2.SS2.p5.1.11" class="ltx_text ltx_font_italic">Supportive (SU)</span> categories. This dataset is extracted from <span id="S2.SS2.p5.1.12" class="ltx_text ltx_font_italic">SucideWatch<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note"><span id="footnote2.1.1.1" class="ltx_text ltx_font_upright">2</span></span><a target="_blank" href="https://www.reddit.com/r/SuicideWatch/" title="" class="ltx_ref ltx_href ltx_font_upright">SuicideWatch subreddit</a></span></span></span></span> subreddit and has been annotated by four practicing clinical psychiatrists, ensuring the accuracy and reliability of the annotations. The dataset comprises a total of 500 posts, which have been carefully selected to represent a diverse range of content related to suicidal ideation.</p>
</div>
<div id="S2.SS2.p6" class="ltx_para">
<p id="S2.SS2.p6.1" class="ltx_p">Another widely referenced dataset in the field of suicidal ideation detection is the University of Maryland Reddit Suicidality Dataset(UMD) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>, <a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>. The UMD dataset is a collection of Reddit posts and comments created by individuals who expressed suicidal thoughts or behaviors. The dataset contains over 100,000 posts and comments collected from various subreddits, including those related to mental health and suicide prevention, such as <span id="S2.SS2.p6.1.1" class="ltx_text ltx_font_italic">Depression<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note"><span id="footnote3.1.1.1" class="ltx_text ltx_font_upright">3</span></span><a target="_blank" href="https://www.reddit.com/r/depression/" title="" class="ltx_ref ltx_href ltx_font_upright">Depression subreddit</a></span></span></span></span> and <span id="S2.SS2.p6.1.2" class="ltx_text ltx_font_italic">SucideWatch</span> subreddits. The data was collected over a period of several years and includes the content of the posts and comments, as well as the location and timing of the posts.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS3.5.1.1" class="ltx_text">II-C</span> </span><span id="S2.SS3.6.2" class="ltx_text ltx_font_italic">Synthetic Data collection</span>
</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">To overcome the limitations of real-world data availability, NLP researchers have explored the use of synthetic datasets for several applications.
For example, He et al.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite> utilized language models to generate synthetic unlabeled text. They introduced the Generate, Annotate, and Learn (GAL) framework that leverages synthetic text for knowledge distillation, self-training, and few-shot learning purposes. To generate the data, they fine-tune pre-trained language models on relevant datasets with limited examples. The synthetic text is then annotated with soft pseudo labels using the best available classifier for knowledge distillation and self-training. This paper achieves state-of-the-art results for knowledge distillation with 6-layer transformers on the GLUE leaderboard<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite>.</p>
</div>
<div id="S2.SS3.p2" class="ltx_para">
<p id="S2.SS3.p2.1" class="ltx_p">Bonifacia et al.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite> presents an effective approach to leverage LLMs in retrieval tasks, resulting in significant improvements across various datasets. Instead of directly utilizing LLMs during the retrieval process, they harness the LLMs’ capabilities to generate labeled data using a few-shot learning approach. Subsequently, they fine-tune smaller retrieval models on this synthetic dataset and employ them to re-rank the search results obtained from a primary retrieval system. They provide a novel method to adapt LLMs for Information Retrieval (IR) tasks that were previously deemed infeasible due to their demanding computational requirements. By shifting the computational burden from the retrieval stage to the generation of synthetic data for training, they make it feasible to exploit the power of LLMs without compromising efficiency. In an unsupervised setting, their approach significantly outperforms recently proposed methods, highlighting its superiority in terms of retrieval performance and scalability.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Methodology</span>
</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">In this section, we elaborate on our proposed methodology. Figure <a href="#S3.F1" title="Figure 1 ‣ III Methodology ‣ Socially Aware Synthetic Data Generation for Suicidal Ideation Detection Using Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows the workflow we use to generate synthetic datasets and our testing process. As shown in this figure, our method has three steps:</p>
</div>
<div id="S3.p2" class="ltx_para">
<ul id="S3.I1" class="ltx_itemize">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.p1.1" class="ltx_p"><span id="S3.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">STEP 1- Domain knowledge Extraction:</span> Extract relevant social factors from the psychology literature for an informed prompting of GLLMs in data synthesis.</p>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i2.p1.1" class="ltx_p"><span id="S3.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">STEP 2- Synthetic Data Generation:</span> Use three GLLMs to generate socially aware synthetic data, that is, data that covers a wide range of suicide-related topics.</p>
</div>
</li>
<li id="S3.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i3.p1" class="ltx_para">
<p id="S3.I1.i3.p1.1" class="ltx_p"><span id="S3.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">STEP 3- Evaluate the effectiveness of Synthetic data:</span> Train state-of-the-art classifiers with real-world, synthetic, and augmented datasets and test those classifiers on real-world as well as synthetic test sets.</p>
</div>
</li>
</ul>
</div>
<figure id="S3.F1" class="ltx_figure"><img src="/html/2402.01712/assets/x1.png" id="S3.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="664" height="375" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Workflow of the proposed methodology</figcaption>
</figure>
<div id="S3.p3" class="ltx_para">
<p id="S3.p3.1" class="ltx_p">In the following, we explain the three steps described above. The complete implementation of our project, including Zero-Shot Learning and Few-Shot Learning of GLLMs, as well as the fine-tuned classifiers, is available on GitHub <span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a target="_blank" href="https://github.com/Hamideh-ghanadian/Synthetic_Data_Generation_using_Generative_LLMs" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/Hamideh-ghanadian/Synthetic_Data_Generation_using_Generative_LLMs</a></span></span></span>.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS1.5.1.1" class="ltx_text">III-A</span> </span><span id="S3.SS1.6.2" class="ltx_text ltx_font_italic">Suicide Related Topics in Psychology </span>
</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">We conducted a comprehensive search across various academic databases, including PsycINFO, PubMed, and Google Scholar, with keywords and combinations such as “suicide”, “suicidal ideation” and “psychology” to identify relevant articles, research papers, and review papers.
Thematic analysis was employed to identify the most recurring and significant topics across the included studies. Repeated topics that demonstrate relevance to suicide in psychology were considered the most related topics.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">Based on our analysis of the literature, the following social and psychological factors were consistently reported in relation to suicidal ideation in psychology. These topics are not listed in a specific order of importance but represent the consistently reported themes in the literature reviewed:</p>
</div>
<div id="S3.SS1.p3" class="ltx_para ltx_noindent">
<p id="S3.SS1.p3.1" class="ltx_p"><span id="S3.SS1.p3.1.1" class="ltx_text ltx_font_bold">Depression:</span>
Depression emerged as a frequently reported topic, highlighting its strong association with suicidal ideation. Numerous studies have explored the relationship between depressive symptoms, including sadness, loss of interest, feelings of worthlessness, and the increased risk of suicidal thoughts.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>, <a href="#bib.bib46" title="" class="ltx_ref">46</a>, <a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite></p>
</div>
<div id="S3.SS1.p4" class="ltx_para ltx_noindent">
<p id="S3.SS1.p4.1" class="ltx_p"><span id="S3.SS1.p4.1.1" class="ltx_text ltx_font_bold">Anxiety:</span>
Anxiety disorders were also commonly associated with suicidal ideation. Research has emphasized the link between excessive worry, fear, and agitation and the presence of suicidal thoughts and behaviors<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite>.</p>
</div>
<div id="S3.SS1.p5" class="ltx_para ltx_noindent">
<p id="S3.SS1.p5.1" class="ltx_p"><span id="S3.SS1.p5.1.1" class="ltx_text ltx_font_bold">Unemployment:</span>
The experience of unemployment has been consistently identified as a topic closely related to suicidal ideation. Studies have examined the psychological distress and negative impact on self-esteem and social support that can arise from unemployment, contributing to suicidal ideation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite>.</p>
</div>
<div id="S3.SS1.p6" class="ltx_para ltx_noindent">
<p id="S3.SS1.p6.1" class="ltx_p"><span id="S3.SS1.p6.1.1" class="ltx_text ltx_font_bold">Hopelessness:</span>
Hopelessness, characterized by a lack of optimism and a perceived absence of future prospects, has been consistently linked to suicidal ideation. Studies have demonstrated the significant role of hopelessness as a predictor of suicidal thoughts <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>, <a href="#bib.bib46" title="" class="ltx_ref">46</a>, <a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite>.</p>
</div>
<div id="S3.SS1.p7" class="ltx_para ltx_noindent">
<p id="S3.SS1.p7.1" class="ltx_p"><span id="S3.SS1.p7.1.1" class="ltx_text ltx_font_bold">Anger:</span>
The expression and experience of anger have been reported as influential factors in suicidal ideation. Unresolved anger, hostility, and intense emotional distress have been associated with an increased risk of suicidal thoughts<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite>.</p>
</div>
<div id="S3.SS1.p8" class="ltx_para ltx_noindent">
<p id="S3.SS1.p8.1" class="ltx_p"><span id="S3.SS1.p8.1.1" class="ltx_text ltx_font_bold">Perfectionism:</span>
Perfectionism, marked by excessively high standards and self-criticism, has been identified as a psychological factor related to suicidal ideation. Research has explored the relationship between perfectionistic tendencies and the development of suicidal thoughts and behaviors <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite>.</p>
</div>
<div id="S3.SS1.p9" class="ltx_para ltx_noindent">
<p id="S3.SS1.p9.1" class="ltx_p"><span id="S3.SS1.p9.1.1" class="ltx_text ltx_font_bold">Family Issues:</span>
Family-related issues, such as conflict, dysfunctional dynamics, and poor communication, have consistently emerged as topics associated with suicidal ideation. These factors can contribute to a sense of isolation, distress, and feelings of being a burden, increasing the risk of suicidal thoughts<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>, <a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite>.</p>
</div>
<div id="S3.SS1.p10" class="ltx_para ltx_noindent">
<p id="S3.SS1.p10.1" class="ltx_p"><span id="S3.SS1.p10.1.1" class="ltx_text ltx_font_bold">Relationship Problems:</span>
Difficulties in intimate relationships, including conflicts, breakups, and marital dissatisfaction, have been reported as significant topics in relation to suicidal ideation. Relationship problems can contribute to emotional distress and feelings of hopelessness, leading to thoughts of suicide <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite>.</p>
</div>
<div id="S3.SS1.p11" class="ltx_para ltx_noindent">
<p id="S3.SS1.p11.1" class="ltx_p"><span id="S3.SS1.p11.1.1" class="ltx_text ltx_font_bold">Financial Crisis:</span>
Financial difficulties and crises have been consistently linked to suicidal ideation. Economic stressors, such as debt, unemployment, and financial insecurity, can contribute to psychological distress and an increased risk of suicidal thoughts <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite>.</p>
</div>
<div id="S3.SS1.p12" class="ltx_para ltx_noindent">
<p id="S3.SS1.p12.1" class="ltx_p"><span id="S3.SS1.p12.1.1" class="ltx_text ltx_font_bold">Education:</span>
Issues related to educational pressures, academic stress, and performance expectations have been reported as topics associated with suicidal ideation. Research has highlighted the impact of academic-related stressors on mental well-being and the risk of suicidal thoughts among students <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref">50</a>]</cite>.</p>
</div>
<div id="S3.SS1.p13" class="ltx_para ltx_noindent">
<p id="S3.SS1.p13.1" class="ltx_p"><span id="S3.SS1.p13.1.1" class="ltx_text ltx_font_bold">Bullying:</span>
Bullying, including physical, verbal, or cyber-bullying, has consistently emerged as a significant topic related to suicidal ideation. The experience of bullying can lead to social isolation, low self-esteem, and emotional distress, contributing to the development of suicidal thoughts <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite>.</p>
</div>
<div id="S3.SS1.p14" class="ltx_para ltx_noindent">
<p id="S3.SS1.p14.1" class="ltx_p"><span id="S3.SS1.p14.1.1" class="ltx_text ltx_font_bold">Death of Loved Ones:</span>
The loss of close family members or friends through death has been reported as a topic associated with suicidal ideation. Grief, feelings of loneliness, and a sense of being unable to cope with the loss can increase the risk of suicidal thoughts <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref">51</a>]</cite>.</p>
</div>
<div id="S3.SS1.p15" class="ltx_para ltx_noindent">
<p id="S3.SS1.p15.1" class="ltx_p"><span id="S3.SS1.p15.1.1" class="ltx_text ltx_font_bold">Immigration:</span>
Issues related to immigration, discrimination, and racism have been identified as topics linked to suicidal ideation. Experiences of marginalization, social exclusion, and acculturative stress can contribute to psychological distress and suicidal thoughts among individuals facing these challenges <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>, <a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite>.</p>
</div>
<div id="S3.SS1.p16" class="ltx_para ltx_noindent">
<p id="S3.SS1.p16.1" class="ltx_p"><span id="S3.SS1.p16.1.1" class="ltx_text ltx_font_bold">Racism:</span>
Studies have consistently highlighted the significant impact of racial discrimination on suicidal ideation. Experiencing racism and racial prejudice can increase the risk of suicidal thoughts.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite></p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS2.5.1.1" class="ltx_text">III-B</span> </span><span id="S3.SS2.6.2" class="ltx_text ltx_font_italic">Synthetic Data Generation</span>
</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">We utilized three generative language models to generate a synthetic dataset related to suicidal ideation. GLLM’s foundation is constructed with transformers. Transformers are a class of deep learning models, first introduced by Vaswani et al.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite> in 2017.
Researchers build state-of-the-art NLP models using transformer-based architectures because they can be quickly trained on large datasets, and studies have shown that they are better at modeling long-term dependencies in natural language text <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite>. GLLMs, including ChatGPT, FlanT5, and Llama are designed with the primary purpose of generating coherent and contextually relevant text. They excel at tasks such as text generation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>, completion <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite>, and dialogue generation<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite>. These models are typically based on decoder transformer architectures and focus on the generative aspect of language which involves the auto-regressive generation, where the models predict the next word based on the preceding context. Generative models are trained on a vast corpus of text, however, their main strength lies in their ability to generate text that flows naturally and contextually appropriate.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">We aim to build a diverse dataset in order to train a generalizable and robust model in suicidal ideation detection. In total, nine different datasets are generated with different specifications and models.</p>
</div>
<section id="S3.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS2.SSS1.5.1.1" class="ltx_text">III-B</span>1 </span>ChatGPT</h4>

<div id="S3.SS2.SSS1.p1" class="ltx_para">
<p id="S3.SS2.SSS1.p1.1" class="ltx_p">The language model utilized by ChatGPT is <span id="S3.SS2.SSS1.p1.1.1" class="ltx_text ltx_font_italic">gpt-3.5-turbo<span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note"><span id="footnote5.1.1.1" class="ltx_text ltx_font_upright">5</span></span><a target="_blank" href="https://platform.openai.com/docs/models/gpt-3-5" title="" class="ltx_ref ltx_url ltx_font_typewriter ltx_font_upright">https://platform.openai.com/docs/models/gpt-3-5</a></span></span></span></span>, which is one of the most advanced language models developed by OpenAI.
ChatGPT accept a sequence of messages as an input and produce a message generated by the model as an output. Although the chat format is primarily intended for conversations spanning multiple turns, it is also equally useful for single-turn tasks that do not involve any conversations. We used the <span id="S3.SS2.SSS1.p1.1.2" class="ltx_text ltx_font_italic">OpenAI Python library<span id="footnote6" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note"><span id="footnote6.1.1.1" class="ltx_text ltx_font_upright">6</span></span><a target="_blank" href="https://github.com/openai/openai-python" title="" class="ltx_ref ltx_url ltx_font_typewriter ltx_font_upright">https://github.com/openai/openai-python</a></span></span></span></span> to access the <span id="S3.SS2.SSS1.p1.1.3" class="ltx_text ltx_font_italic">ChatCompletion</span> functionality of the <span id="S3.SS2.SSS1.p1.1.4" class="ltx_text ltx_font_italic">gpt-3.5-turbo</span> model through its API.</p>
</div>
<div id="S3.SS2.SSS1.p2" class="ltx_para">
<p id="S3.SS2.SSS1.p2.1" class="ltx_p">In this project, we evaluate the capability of ChatGPT in Zero-Shot Learning and Few-Shot Learning settings to generate a diverse suicidality dataset. However, we are primarily focused on Zero-Shot Learning methods as ChatGPT has exhibited superior performance in this setting compared to Few-Shot Learning for a suicidal ideation detection task. Ghanadian et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite> conducted an extensive comparison of the Zero-Shot and Few-Shot approaches using ChatGPT. According to their findings, fine-tuning a model on Few-Shot setting might yield poorer performance compared to Zero-Shot in various scenarios. In Few-Shot, with few examples available for fine-tuning, the risk of overfitting increases. The model might learn specific nuances or noise within the limited few-shot data, leading to poor generalization on unseen examples. Moreover, Few-shot learning relies on a small subset of labeled examples, which might not adequately represent the entire diversity of the dataset. The model might fail to capture the complexity and variability present in the broader dataset during fine-tuning.</p>
</div>
<div id="S3.SS2.SSS1.p3" class="ltx_para">
<p id="S3.SS2.SSS1.p3.1" class="ltx_p">The temperature hyperparameter in ChatGPT is a crucial parameter that influences the generated output. A higher temperature value, such as 1.0, increases the randomness and produces more varied responses. Conversely, a lower temperature value, such as 0.1, reduces randomness and generates more focused and deterministic responses. Ghanadian et al.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite> investigated the effect of the temperature parameter on the generated output of ChatGPT for suicide risk assessment. Furthermore, the authors introduced a parameter known as the ”Inconclusiveness Rate,” which indicates the proportion of test cases that do not produce a definitive or conclusive result. According to their paper, this parameter decreases as the temperature parameter is increased. As such, for this project, we have configured the temperature parameter of ChatGPT to be 1.</p>
</div>
<div id="S3.SS2.SSS1.p4" class="ltx_para">
<p id="S3.SS2.SSS1.p4.1" class="ltx_p">We generated five datasets using ChatGPT. Four of these datasets are informed by 14 main suicide-related topics in psychology, while one dataset is generated without providing any specific topics. For incorporating suicide-related topics in data generation, we utilized prompt engineering techniques. Prompt engineering involves carefully crafting and designing the prompts provided to the model to elicit desired responses. By employing prompt engineering strategies, we aimed to enhance the quality and relevance of the generated dataset. This methodology allowed us to tailor the dataset generation process to align with our specific objectives and requirements. For prompt engineering, we drew inspiration from a short course on ChatGPT Prompt Engineering<span id="footnote7" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span><a target="_blank" href="https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/" title="" class="ltx_ref ltx_href">ChatGPT Prompt Engineering for Developers</a></span></span></span>.</p>
</div>
<div id="S3.SS2.SSS1.p5" class="ltx_para">
<p id="S3.SS2.SSS1.p5.1" class="ltx_p">In both Zero-Shot and Few-Shot Learning, we initiated the prompt construction process with a simple initial prompt and iteratively refined it through multiple rounds of trial and error. This iterative approach allowed us to gradually evolve the prompt, making necessary adjustments based on the observed outcomes. The following example shows a prompt we used to generate a binary dataset (<span id="S3.SS2.SSS1.p5.1.1" class="ltx_text ltx_font_italic">Suicide/non-suicide</span>), guided by the topics introduced in Section <a href="#S3.SS1" title="III-A Suicide Related Topics in Psychology ‣ III Methodology ‣ Socially Aware Synthetic Data Generation for Suicidal Ideation Detection Using Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-A</span></span></a>, in Zero-shot Learning setting.</p>
</div>
<div id="S3.SS2.SSS1.p6" class="ltx_para">
<div id="S3.SS2.SSS1.p6.1" class="ltx_listing ltx_lst_language_Python ltx_lstlisting ltx_listing">
<div class="ltx_listing_data"><a href="data:text/plain;base64,Q3JpdGVyaWE9IiIiIFRoZXNlIGFyZSB0aGUgY3JpdGVyaWEgb2YgZGlmZmVyZW50IHN1aWNpZGUgcmlzayBsZXZlbDoKICAgIFJpc2sgTGV2ZWw9Tm9uIFN1aWNpZGFsOiBJIGRvIG5vdCBzZWUgZXZpZGVuY2UgdGhhdCB0aGlzIHBlcnNvbiBpcyBhdCByaXNrIGZvciBzdWljaWRlCiAgICBSaXNrIExldmVsPVN1aWNpZGFsOiBJIGJlbGlldmUgdGhpcyBwZXJzb24gaXMgYXQgaGlnaCByaXNrIG9mIGF0dGVtcHRpbmcgc3VpY2lkZSBpbiB0aGUgbmVhciBmdXR1cmUuICIiIgoKcHJvbXB0ID0gZiIiIgpZb3VyIHRhc2sgaXMgdG8gZ2VuZXJhdGUgYSBzdWljaWRhbCB0ZXh0IGZvciBlYWNoIG9mIHRoZSBmb2xsb3dpbmcgInRvcGljcyIgd2l0aCBkaWZmZXJlbnQgUmlzayBsZXZlbHMuCgogICAgMS1EZXByZXNzaW9uCiAgICAyLUFueGlldHkKICAgIDMtSG9wZWxlc3NuZXNzCiAgICA0LUFuZ2VyCiAgICA1LVBlcmZlY3Rpb25pc20KICAgIDYtRmFtaWx5IGlzc3VlcwogICAgNy1SZWxhdGlvbnNoaXAgcHJvYmxlbXMKICAgIDgtVW5lbXBsb3ltZW50CiAgICA5LUZpbmFuY2lhbCBDcmlzaXMKICAgIDEwLUVkdWNhdGlvbgogICAgMTEtQmVpbmcgQnVsbGllZAogICAgMTItRGVhdGggb2YgY2xvc2VkIG9uZQogICAgMTMtSW1taWdyYXRpb24KICAgIDE0LVJhY2lzbQoKUHJvdmlkZSB0aGUgYW5zd2VycyBpbiBKU09OIGZvcm1hdCB3aXRoIHRoZSBmb2xsb3dpbmcgY29sdW1uczogdGV4dCwgdG9waWMsIHJpc2sgbGV2ZWwuCgpSaXNrIGxldmVsIGNyaXRlcmlhOiBgYGB7Q3JpdGVyaWF9YGBgCgoiIiI=" download="">⬇</a></div>
<div id="lstnumberx1" class="ltx_listingline">
<span id="lstnumberx1.1" class="ltx_text ltx_lst_identifier" style="font-size:90%;">Criteria</span><span id="lstnumberx1.2" class="ltx_text" style="font-size:90%;">=</span><span id="lstnumberx1.3" class="ltx_text ltx_lst_string" style="font-size:90%;">””</span><span id="lstnumberx1.4" class="ltx_text ltx_lst_string" style="font-size:90%;">”<span id="lstnumberx1.4.1" class="ltx_text ltx_lst_space">␣</span>These<span id="lstnumberx1.4.2" class="ltx_text ltx_lst_space">␣</span>are<span id="lstnumberx1.4.3" class="ltx_text ltx_lst_space">␣</span>the<span id="lstnumberx1.4.4" class="ltx_text ltx_lst_space">␣</span>criteria<span id="lstnumberx1.4.5" class="ltx_text ltx_lst_space">␣</span>of<span id="lstnumberx1.4.6" class="ltx_text ltx_lst_space">␣</span>different<span id="lstnumberx1.4.7" class="ltx_text ltx_lst_space">␣</span>suicide<span id="lstnumberx1.4.8" class="ltx_text ltx_lst_space">␣</span>risk<span id="lstnumberx1.4.9" class="ltx_text ltx_lst_space">␣</span>level:</span>
</div>
<div id="lstnumberx2" class="ltx_listingline">
<span id="lstnumberx2.1" class="ltx_text ltx_lst_space" style="font-size:90%;">␣␣␣␣</span><span id="lstnumberx2.2" class="ltx_text" style="font-size:90%;">Risk</span><span id="lstnumberx2.3" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx2.4" class="ltx_text" style="font-size:90%;">Level=Non</span><span id="lstnumberx2.5" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx2.6" class="ltx_text" style="font-size:90%;">Suicidal:</span><span id="lstnumberx2.7" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx2.8" class="ltx_text" style="font-size:90%;">I</span><span id="lstnumberx2.9" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx2.10" class="ltx_text" style="font-size:90%;">do</span><span id="lstnumberx2.11" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx2.12" class="ltx_text" style="font-size:90%;">not</span><span id="lstnumberx2.13" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx2.14" class="ltx_text" style="font-size:90%;">see</span><span id="lstnumberx2.15" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx2.16" class="ltx_text" style="font-size:90%;">evidence</span><span id="lstnumberx2.17" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx2.18" class="ltx_text" style="font-size:90%;">that</span><span id="lstnumberx2.19" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx2.20" class="ltx_text" style="font-size:90%;">this</span><span id="lstnumberx2.21" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx2.22" class="ltx_text" style="font-size:90%;">person</span><span id="lstnumberx2.23" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx2.24" class="ltx_text" style="font-size:90%;">is</span><span id="lstnumberx2.25" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx2.26" class="ltx_text" style="font-size:90%;">at</span><span id="lstnumberx2.27" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx2.28" class="ltx_text" style="font-size:90%;">risk</span><span id="lstnumberx2.29" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx2.30" class="ltx_text" style="font-size:90%;">for</span><span id="lstnumberx2.31" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx2.32" class="ltx_text" style="font-size:90%;">suicide</span>
</div>
<div id="lstnumberx3" class="ltx_listingline">
<span id="lstnumberx3.1" class="ltx_text ltx_lst_space" style="font-size:90%;">␣␣␣␣</span><span id="lstnumberx3.2" class="ltx_text" style="font-size:90%;">Risk</span><span id="lstnumberx3.3" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx3.4" class="ltx_text" style="font-size:90%;">Level=Suicidal:</span><span id="lstnumberx3.5" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx3.6" class="ltx_text" style="font-size:90%;">I</span><span id="lstnumberx3.7" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx3.8" class="ltx_text" style="font-size:90%;">believe</span><span id="lstnumberx3.9" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx3.10" class="ltx_text" style="font-size:90%;">this</span><span id="lstnumberx3.11" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx3.12" class="ltx_text" style="font-size:90%;">person</span><span id="lstnumberx3.13" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx3.14" class="ltx_text" style="font-size:90%;">is</span><span id="lstnumberx3.15" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx3.16" class="ltx_text" style="font-size:90%;">at</span><span id="lstnumberx3.17" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx3.18" class="ltx_text" style="font-size:90%;">high</span><span id="lstnumberx3.19" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx3.20" class="ltx_text" style="font-size:90%;">risk</span><span id="lstnumberx3.21" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx3.22" class="ltx_text" style="font-size:90%;">of</span><span id="lstnumberx3.23" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx3.24" class="ltx_text" style="font-size:90%;">attempting</span><span id="lstnumberx3.25" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx3.26" class="ltx_text" style="font-size:90%;">suicide</span><span id="lstnumberx3.27" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx3.28" class="ltx_text" style="font-size:90%;">in</span><span id="lstnumberx3.29" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx3.30" class="ltx_text" style="font-size:90%;">the</span><span id="lstnumberx3.31" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx3.32" class="ltx_text" style="font-size:90%;">near</span><span id="lstnumberx3.33" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx3.34" class="ltx_text" style="font-size:90%;">future.</span><span id="lstnumberx3.35" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx3.36" class="ltx_text" style="font-size:90%;">”</span><span id="lstnumberx3.37" class="ltx_text ltx_lst_string" style="font-size:90%;">””</span>
</div>
<div id="lstnumberx4" class="ltx_listingline">
</div>
<div id="lstnumberx5" class="ltx_listingline">
<span id="lstnumberx5.1" class="ltx_text ltx_lst_identifier" style="font-size:90%;">prompt</span><span id="lstnumberx5.2" class="ltx_text ltx_lst_space" style="font-size:90%;"> </span><span id="lstnumberx5.3" class="ltx_text" style="font-size:90%;">=</span><span id="lstnumberx5.4" class="ltx_text ltx_lst_space" style="font-size:90%;"> </span><span id="lstnumberx5.5" class="ltx_text ltx_lst_identifier" style="font-size:90%;">f</span><span id="lstnumberx5.6" class="ltx_text ltx_lst_string" style="font-size:90%;">””</span><span id="lstnumberx5.7" class="ltx_text ltx_lst_string" style="font-size:90%;">”</span>
</div>
<div id="lstnumberx6" class="ltx_listingline">
<span id="lstnumberx6.1" class="ltx_text" style="font-size:90%;">Your</span><span id="lstnumberx6.2" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx6.3" class="ltx_text" style="font-size:90%;">task</span><span id="lstnumberx6.4" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx6.5" class="ltx_text" style="font-size:90%;">is</span><span id="lstnumberx6.6" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx6.7" class="ltx_text" style="font-size:90%;">to</span><span id="lstnumberx6.8" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx6.9" class="ltx_text" style="font-size:90%;">generate</span><span id="lstnumberx6.10" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx6.11" class="ltx_text" style="font-size:90%;">a</span><span id="lstnumberx6.12" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx6.13" class="ltx_text" style="font-size:90%;">suicidal</span><span id="lstnumberx6.14" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx6.15" class="ltx_text" style="font-size:90%;">text</span><span id="lstnumberx6.16" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx6.17" class="ltx_text" style="font-size:90%;">for</span><span id="lstnumberx6.18" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx6.19" class="ltx_text" style="font-size:90%;">each</span><span id="lstnumberx6.20" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx6.21" class="ltx_text" style="font-size:90%;">of</span><span id="lstnumberx6.22" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx6.23" class="ltx_text" style="font-size:90%;">the</span><span id="lstnumberx6.24" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx6.25" class="ltx_text" style="font-size:90%;">following</span><span id="lstnumberx6.26" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx6.27" class="ltx_text" style="font-size:90%;">”</span><span id="lstnumberx6.28" class="ltx_text ltx_lst_identifier" style="font-size:90%;">topics</span><span id="lstnumberx6.29" class="ltx_text ltx_lst_string" style="font-size:90%;">”<span id="lstnumberx6.29.1" class="ltx_text ltx_lst_space">␣</span>with<span id="lstnumberx6.29.2" class="ltx_text ltx_lst_space">␣</span>different<span id="lstnumberx6.29.3" class="ltx_text ltx_lst_space">␣</span>Risk<span id="lstnumberx6.29.4" class="ltx_text ltx_lst_space">␣</span>levels.</span>
</div>
<div id="lstnumberx7" class="ltx_listingline">
</div>
<div id="lstnumberx8" class="ltx_listingline">
<span id="lstnumberx8.1" class="ltx_text ltx_lst_space" style="font-size:90%;">␣␣␣␣</span><span id="lstnumberx8.2" class="ltx_text" style="font-size:90%;">1-Depression</span>
</div>
<div id="lstnumberx9" class="ltx_listingline">
<span id="lstnumberx9.1" class="ltx_text ltx_lst_space" style="font-size:90%;">␣␣␣␣</span><span id="lstnumberx9.2" class="ltx_text" style="font-size:90%;">2-Anxiety</span>
</div>
<div id="lstnumberx10" class="ltx_listingline">
<span id="lstnumberx10.1" class="ltx_text ltx_lst_space" style="font-size:90%;">␣␣␣␣</span><span id="lstnumberx10.2" class="ltx_text" style="font-size:90%;">3-Hopelessness</span>
</div>
<div id="lstnumberx11" class="ltx_listingline">
<span id="lstnumberx11.1" class="ltx_text ltx_lst_space" style="font-size:90%;">␣␣␣␣</span><span id="lstnumberx11.2" class="ltx_text" style="font-size:90%;">4-Anger</span>
</div>
<div id="lstnumberx12" class="ltx_listingline">
<span id="lstnumberx12.1" class="ltx_text ltx_lst_space" style="font-size:90%;">␣␣␣␣</span><span id="lstnumberx12.2" class="ltx_text" style="font-size:90%;">5-Perfectionism</span>
</div>
<div id="lstnumberx13" class="ltx_listingline">
<span id="lstnumberx13.1" class="ltx_text ltx_lst_space" style="font-size:90%;">␣␣␣␣</span><span id="lstnumberx13.2" class="ltx_text" style="font-size:90%;">6-Family</span><span id="lstnumberx13.3" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx13.4" class="ltx_text" style="font-size:90%;">issues</span>
</div>
<div id="lstnumberx14" class="ltx_listingline">
<span id="lstnumberx14.1" class="ltx_text ltx_lst_space" style="font-size:90%;">␣␣␣␣</span><span id="lstnumberx14.2" class="ltx_text" style="font-size:90%;">7-Relationship</span><span id="lstnumberx14.3" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx14.4" class="ltx_text" style="font-size:90%;">problems</span>
</div>
<div id="lstnumberx15" class="ltx_listingline">
<span id="lstnumberx15.1" class="ltx_text ltx_lst_space" style="font-size:90%;">␣␣␣␣</span><span id="lstnumberx15.2" class="ltx_text" style="font-size:90%;">8-Unemployment</span>
</div>
<div id="lstnumberx16" class="ltx_listingline">
<span id="lstnumberx16.1" class="ltx_text ltx_lst_space" style="font-size:90%;">␣␣␣␣</span><span id="lstnumberx16.2" class="ltx_text" style="font-size:90%;">9-Financial</span><span id="lstnumberx16.3" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx16.4" class="ltx_text" style="font-size:90%;">Crisis</span>
</div>
<div id="lstnumberx17" class="ltx_listingline">
<span id="lstnumberx17.1" class="ltx_text ltx_lst_space" style="font-size:90%;">␣␣␣␣</span><span id="lstnumberx17.2" class="ltx_text" style="font-size:90%;">10-Education</span>
</div>
<div id="lstnumberx18" class="ltx_listingline">
<span id="lstnumberx18.1" class="ltx_text ltx_lst_space" style="font-size:90%;">␣␣␣␣</span><span id="lstnumberx18.2" class="ltx_text" style="font-size:90%;">11-Being</span><span id="lstnumberx18.3" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx18.4" class="ltx_text" style="font-size:90%;">Bullied</span>
</div>
<div id="lstnumberx19" class="ltx_listingline">
<span id="lstnumberx19.1" class="ltx_text ltx_lst_space" style="font-size:90%;">␣␣␣␣</span><span id="lstnumberx19.2" class="ltx_text" style="font-size:90%;">12-Death</span><span id="lstnumberx19.3" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx19.4" class="ltx_text" style="font-size:90%;">of</span><span id="lstnumberx19.5" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx19.6" class="ltx_text" style="font-size:90%;">closed</span><span id="lstnumberx19.7" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx19.8" class="ltx_text" style="font-size:90%;">one</span>
</div>
<div id="lstnumberx20" class="ltx_listingline">
<span id="lstnumberx20.1" class="ltx_text ltx_lst_space" style="font-size:90%;">␣␣␣␣</span><span id="lstnumberx20.2" class="ltx_text" style="font-size:90%;">13-Immigration</span>
</div>
<div id="lstnumberx21" class="ltx_listingline">
<span id="lstnumberx21.1" class="ltx_text ltx_lst_space" style="font-size:90%;">␣␣␣␣</span><span id="lstnumberx21.2" class="ltx_text" style="font-size:90%;">14-Racism</span>
</div>
<div id="lstnumberx22" class="ltx_listingline">
</div>
<div id="lstnumberx23" class="ltx_listingline">
<span id="lstnumberx23.1" class="ltx_text" style="font-size:90%;">Provide</span><span id="lstnumberx23.2" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx23.3" class="ltx_text" style="font-size:90%;">the</span><span id="lstnumberx23.4" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx23.5" class="ltx_text" style="font-size:90%;">answers</span><span id="lstnumberx23.6" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx23.7" class="ltx_text" style="font-size:90%;">in</span><span id="lstnumberx23.8" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx23.9" class="ltx_text" style="font-size:90%;">JSON</span><span id="lstnumberx23.10" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx23.11" class="ltx_text" style="font-size:90%;">format</span><span id="lstnumberx23.12" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx23.13" class="ltx_text" style="font-size:90%;">with</span><span id="lstnumberx23.14" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx23.15" class="ltx_text" style="font-size:90%;">the</span><span id="lstnumberx23.16" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx23.17" class="ltx_text" style="font-size:90%;">following</span><span id="lstnumberx23.18" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx23.19" class="ltx_text" style="font-size:90%;">columns:</span><span id="lstnumberx23.20" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx23.21" class="ltx_text" style="font-size:90%;">text,</span><span id="lstnumberx23.22" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx23.23" class="ltx_text" style="font-size:90%;">topic,</span><span id="lstnumberx23.24" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx23.25" class="ltx_text" style="font-size:90%;">risk</span><span id="lstnumberx23.26" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx23.27" class="ltx_text" style="font-size:90%;">level.</span>
</div>
<div id="lstnumberx24" class="ltx_listingline">
</div>
<div id="lstnumberx25" class="ltx_listingline">
<span id="lstnumberx25.1" class="ltx_text" style="font-size:90%;">Risk</span><span id="lstnumberx25.2" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx25.3" class="ltx_text" style="font-size:90%;">level</span><span id="lstnumberx25.4" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx25.5" class="ltx_text" style="font-size:90%;">criteria:</span><span id="lstnumberx25.6" class="ltx_text ltx_lst_space" style="font-size:90%;">␣</span><span id="lstnumberx25.7" class="ltx_text" style="font-size:90%;">“‘{Criteria}“‘</span>
</div>
<div id="lstnumberx26" class="ltx_listingline">
</div>
<div id="lstnumberx27" class="ltx_listingline">
<span id="lstnumberx27.1" class="ltx_text" style="font-size:90%;">”</span><span id="lstnumberx27.2" class="ltx_text ltx_lst_string" style="font-size:90%;">””</span>
</div>
</div>
</div>
<div id="S3.SS2.SSS1.p7" class="ltx_para">
<p id="S3.SS2.SSS1.p7.1" class="ltx_p">In Few-Shot Learning, the prompt is structured to include two examples for each category (8 in total) from the training set of UMD Dataset, followed by a text generation question. This approach enables the model to learn from a limited set of labeled examples before generating a dataset. Moreover, by combining the Few-Shot Learning methodology with the inclusion of psychology topics in the prompt, we aim to enhance the model’s ability to generate meaningful and contextually relevant responses when dealing with suicide-related discussions.</p>
</div>
</section>
<section id="S3.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS2.SSS2.5.1.1" class="ltx_text">III-B</span>2 </span>Flan-T5</h4>

<div id="S3.SS2.SSS2.p1" class="ltx_para">
<p id="S3.SS2.SSS2.p1.1" class="ltx_p">FLAN-T5 models are instruction fine-tuned across a diverse set of tasks, aiming to enhance their zero-shot performance on various tasks. During instruction tuning, pretrained models undergo fine-tuning using drafts of instructions that guide them on how to perform a specific task. These instructions can include real-time feedback to assist the model in learning from its mistakes and improving at a faster rate. By providing explicit guidance and incorporating feedback mechanisms, the instruction-tuning process enables the model to refine its performance and enhance its ability to accurately execute the given task. This iterative approach of incorporating instructions and feedback facilitates the model’s learning process, allowing it to adapt and improve its performance based on the provided guidance.</p>
</div>
<div id="S3.SS2.SSS2.p2" class="ltx_para">
<p id="S3.SS2.SSS2.p2.1" class="ltx_p">In this project, we utilized <span id="S3.SS2.SSS2.p2.1.1" class="ltx_text ltx_font_italic">Flan-T5-XXL<span id="footnote8" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note"><span id="footnote8.1.1.1" class="ltx_text ltx_font_upright">8</span></span><a target="_blank" href="https://huggingface.co/google/flan-t5-xxl" title="" class="ltx_ref ltx_url ltx_font_typewriter ltx_font_upright">https://huggingface.co/google/flan-t5-xxl</a></span></span></span></span> presented by Google Research <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib60" title="" class="ltx_ref">60</a>]</cite> in a Zero-Shot setting. Two datasets are generated using Flan-T5, one with topics and another without topics. Moreover, similar to ChatGPT, the temperature value is set to 1, and the same prompt structure is utilized.</p>
</div>
</section>
<section id="S3.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS2.SSS3.5.1.1" class="ltx_text">III-B</span>3 </span>Llama 2</h4>

<div id="S3.SS2.SSS3.p1" class="ltx_para">
<p id="S3.SS2.SSS3.p1.1" class="ltx_p">LLaMA (Large Language Model Meta AI) is an auto-regressive language model constructed based on transformer architecture. Similar to other generative models, LLaMA operates by taking a sequence of words as its input and making predictions about the subsequent word, iteratively producing text in a recursive manner.
It is a collection of state-of-the-art foundational language models, with parameter counts ranging from 7 billion to 65 billion. The foundation models were trained on large unlabeled datasets, making them ideal for fine-tuning on a variety of tasks. The newest version of this model, Llama 2, expanded its pre-training corpus size, allowing the model to learn from a more extensive and diverse set of publicly available data. Additionally, the context length of Llama 2 has been doubled, enabling the model to consider a more extensive context when generating responses, leading to improved output quality and accuracy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref">61</a>]</cite>. In this paper, we used Llama 2-13B, presented by Meta in the Zero-Shot setting. In total, we generated two datasets with Llama2, one with topics and another without topics. These datasets were created using the temperature of 1 and maintained the same prompt structure as ChatGPT.</p>
</div>
</section>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS3.5.1.1" class="ltx_text">III-C</span> </span><span id="S3.SS3.6.2" class="ltx_text ltx_font_italic">Evaluation of Synthetic Dataset</span>
</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">To evaluate the utility and effectiveness of synthetic datasets, we fine-tuned pre-trained transformer-based language models, ALBERT and DistilBERT, to train classifiers with each set of the generated synthetic data. We compared the trained classifiers with classifiers with similar structures fine-tuned with real-world data as the benchmark model.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.1" class="ltx_p">ALBERT and DistilBERT are two pre-trained language models from the BERT family of LMs. The BERT model was initially proposed by Delvin et al.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref">62</a>]</cite> as a bidirectional language model pretrained on a large corpus comprising the Toronto Book Corpus and Wikipedia. The model is named bidirectional because it can simultaneously gather the context of a word from either direction. Unlike the generative models such as ChatGPT, FlanT5 or Llama, which include a decoder structure, the BERT family of language models are encoder models and can be fine-tuned for specific tasks such as classification tasks.</p>
</div>
<div id="S3.SS3.p3" class="ltx_para">
<p id="S3.SS3.p3.1" class="ltx_p">The ALBERT model was proposed by Lan et al.<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib63" title="" class="ltx_ref">63</a>]</cite> to reduce memory consumption and increase the training speed compared to BERT. In other words, ALBERT is a more lightweight version of BERT that maintains its high level of accuracy, making it a powerful tool for various NLP applications.
The DistilBERT model was proposed by Sanh et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite>. The authors reported it has 40% fewer parameters than BERT and runs 60% faster while preserving over 95% of BERT’s performances as measured on the GLUE language understanding benchmark. Both models are designed as lightweight alternatives to BERT, with ALBERT emphasizing parameter efficiency and DistilBERT focusing on knowledge transfer through distillation. Overall, ALBERT, with a smaller number of parameters, shows more efficient performance compared to DistilBERT.</p>
</div>
<div id="S3.SS3.p4" class="ltx_para">
<p id="S3.SS3.p4.1" class="ltx_p">To fine-tune these models, we utilized the Huggingface library <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite>. The Huggingface is an open-source library and data science platform that provides tools to build, train and deploy ML models. We compare our classification results with baseline ALBERT<span id="footnote9" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span><a target="_blank" href="https://huggingface.co/albert-base-v2" title="" class="ltx_ref ltx_href">ALBERT</a></span></span></span> and DistilBERT<span id="footnote10" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup><span class="ltx_tag ltx_tag_note">10</span><a target="_blank" href="https://huggingface.co/distilbert-base-uncased" title="" class="ltx_ref ltx_href">DistilBERT</a></span></span></span> models fine-tuned on the UMD dataset by Ghanadian et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>. We used the Trainer<span id="footnote11" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">11</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">11</sup><span class="ltx_tag ltx_tag_note">11</span><a target="_blank" href="https://huggingface.co/docs/transformers/main_classes/trainer" title="" class="ltx_ref ltx_href">Trainer</a></span></span></span> class from Huggingface transformers<span id="footnote12" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">12</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">12</sup><span class="ltx_tag ltx_tag_note">12</span><a target="_blank" href="https://huggingface.co/docs/transformers/index" title="" class="ltx_ref ltx_href">Huggingface Transformers</a></span></span></span> for feature-complete training in PyTorch.</p>
</div>
<div id="S3.SS3.p5" class="ltx_para">
<p id="S3.SS3.p5.1" class="ltx_p">The hyperparameters were selected based on the default values commonly used in similar studies. The final hyperparameters used in our experiments were Learning Rate= <math id="S3.SS3.p5.1.m1.1" class="ltx_Math" alttext="2e^{-5}" display="inline"><semantics id="S3.SS3.p5.1.m1.1a"><mrow id="S3.SS3.p5.1.m1.1.1" xref="S3.SS3.p5.1.m1.1.1.cmml"><mn id="S3.SS3.p5.1.m1.1.1.2" xref="S3.SS3.p5.1.m1.1.1.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S3.SS3.p5.1.m1.1.1.1" xref="S3.SS3.p5.1.m1.1.1.1.cmml">​</mo><msup id="S3.SS3.p5.1.m1.1.1.3" xref="S3.SS3.p5.1.m1.1.1.3.cmml"><mi id="S3.SS3.p5.1.m1.1.1.3.2" xref="S3.SS3.p5.1.m1.1.1.3.2.cmml">e</mi><mrow id="S3.SS3.p5.1.m1.1.1.3.3" xref="S3.SS3.p5.1.m1.1.1.3.3.cmml"><mo id="S3.SS3.p5.1.m1.1.1.3.3a" xref="S3.SS3.p5.1.m1.1.1.3.3.cmml">−</mo><mn id="S3.SS3.p5.1.m1.1.1.3.3.2" xref="S3.SS3.p5.1.m1.1.1.3.3.2.cmml">5</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.1.m1.1b"><apply id="S3.SS3.p5.1.m1.1.1.cmml" xref="S3.SS3.p5.1.m1.1.1"><times id="S3.SS3.p5.1.m1.1.1.1.cmml" xref="S3.SS3.p5.1.m1.1.1.1"></times><cn type="integer" id="S3.SS3.p5.1.m1.1.1.2.cmml" xref="S3.SS3.p5.1.m1.1.1.2">2</cn><apply id="S3.SS3.p5.1.m1.1.1.3.cmml" xref="S3.SS3.p5.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p5.1.m1.1.1.3.1.cmml" xref="S3.SS3.p5.1.m1.1.1.3">superscript</csymbol><ci id="S3.SS3.p5.1.m1.1.1.3.2.cmml" xref="S3.SS3.p5.1.m1.1.1.3.2">𝑒</ci><apply id="S3.SS3.p5.1.m1.1.1.3.3.cmml" xref="S3.SS3.p5.1.m1.1.1.3.3"><minus id="S3.SS3.p5.1.m1.1.1.3.3.1.cmml" xref="S3.SS3.p5.1.m1.1.1.3.3"></minus><cn type="integer" id="S3.SS3.p5.1.m1.1.1.3.3.2.cmml" xref="S3.SS3.p5.1.m1.1.1.3.3.2">5</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.1.m1.1c">2e^{-5}</annotation></semantics></math>, Batch Size = 4, Dropout Rate = 0.1, and Maximum Sequence Length = 512. By comparing the performance of these models on synthetic datasets against the baseline, we can assess the efficiency of using the synthetic datasets and gauge the improvements achieved through our fine-tuning process.</p>
</div>
<div id="S3.SS3.p6" class="ltx_para">
<p id="S3.SS3.p6.1" class="ltx_p">To conduct a comprehensive assessment of the fine-tuned classifiers’ performance, we generated two distinct sets of testing subsets. Furthermore, we created an augmented dataset to showcase the application of synthetic data in the suicidal ideation detection domain.</p>
</div>
<section id="S3.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS3.SSS1.5.1.1" class="ltx_text">III-C</span>1 </span>Testing subsets</h4>

<div id="S3.SS3.SSS1.p1" class="ltx_para">
<p id="S3.SS3.SSS1.p1.1" class="ltx_p">We selected two test sets for evaluation purposes:
The first test dataset is the test subset of the UMD datasets utilized in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>, which is annotated as a 4-class dataset. We employed a 10-20-70 split for validation, test, and training sets, respectively. Out of the entire dataset, 10% was allocated for validation purposes, ensuring the model’s hyperparameters and configurations were appropriately set. 20% of the data was set aside as a test set to evaluate the model’s performance on unseen data and ensure its generalizability. The remaining 70% formed the training set, where the bulk of the data was utilized to train the model and learn the underlying patterns. This distribution was chosen to provide substantial data for training while reserving enough distinct data for validation and robust performance testing. The detailed description of the Multi-class UMD dataset is presented in Table <a href="#S3.T1" title="TABLE I ‣ III-C1 Testing subsets ‣ III-C Evaluation of Synthetic Dataset ‣ III Methodology ‣ Socially Aware Synthetic Data Generation for Suicidal Ideation Detection Using Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a>.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE I: </span>The description of the training and testing subset of UMD Dataset used in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite> for multi-class task</figcaption>
<div id="S3.T1.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:71.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-91.9pt,15.1pt) scale(0.702345136166287,0.702345136166287) ;">
<table id="S3.T1.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S3.T1.1.1.1.1" class="ltx_tr">
<th id="S3.T1.1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S3.T1.1.1.1.1.1.1" class="ltx_text" style="font-size:207%;">Multi-class Dataset</span></th>
<td id="S3.T1.1.1.1.1.2" class="ltx_td ltx_align_center"><span id="S3.T1.1.1.1.1.2.1" class="ltx_text" style="font-size:207%;">No Risk</span></td>
<td id="S3.T1.1.1.1.1.3" class="ltx_td ltx_align_center"><span id="S3.T1.1.1.1.1.3.1" class="ltx_text" style="font-size:207%;">Low Risk</span></td>
<td id="S3.T1.1.1.1.1.4" class="ltx_td ltx_align_center"><span id="S3.T1.1.1.1.1.4.1" class="ltx_text" style="font-size:207%;">Moderate Risk</span></td>
<td id="S3.T1.1.1.1.1.5" class="ltx_td ltx_align_center"><span id="S3.T1.1.1.1.1.5.1" class="ltx_text" style="font-size:207%;">High Risk</span></td>
</tr>
<tr id="S3.T1.1.1.2.2" class="ltx_tr">
<th id="S3.T1.1.1.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S3.T1.1.1.2.2.1.1" class="ltx_text" style="font-size:207%;">Training Subset</span></th>
<td id="S3.T1.1.1.2.2.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.1.1.2.2.2.1" class="ltx_text" style="font-size:207%;">27.45 %</span></td>
<td id="S3.T1.1.1.2.2.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.1.1.2.2.3.1" class="ltx_text" style="font-size:207%;">16.39 %</span></td>
<td id="S3.T1.1.1.2.2.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.1.1.2.2.4.1" class="ltx_text" style="font-size:207%;">31.90 %</span></td>
<td id="S3.T1.1.1.2.2.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.1.1.2.2.5.1" class="ltx_text" style="font-size:207%;">24.24 %</span></td>
</tr>
<tr id="S3.T1.1.1.3.3" class="ltx_tr">
<th id="S3.T1.1.1.3.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S3.T1.1.1.3.3.1.1" class="ltx_text" style="font-size:207%;">Number of Users</span></th>
<td id="S3.T1.1.1.3.3.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.1.1.3.3.2.1" class="ltx_text" style="font-size:207%;">154</span></td>
<td id="S3.T1.1.1.3.3.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.1.1.3.3.3.1" class="ltx_text" style="font-size:207%;">92</span></td>
<td id="S3.T1.1.1.3.3.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.1.1.3.3.4.1" class="ltx_text" style="font-size:207%;">179</span></td>
<td id="S3.T1.1.1.3.3.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T1.1.1.3.3.5.1" class="ltx_text" style="font-size:207%;">136</span></td>
</tr>
<tr id="S3.T1.1.1.4.4" class="ltx_tr">
<th id="S3.T1.1.1.4.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_tt"><span id="S3.T1.1.1.4.4.1.1" class="ltx_text" style="font-size:207%;">Testing Subset</span></th>
<td id="S3.T1.1.1.4.4.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T1.1.1.4.4.2.1" class="ltx_text" style="font-size:207%;">24.41 %</span></td>
<td id="S3.T1.1.1.4.4.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T1.1.1.4.4.3.1" class="ltx_text" style="font-size:207%;">11.62 %</span></td>
<td id="S3.T1.1.1.4.4.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T1.1.1.4.4.4.1" class="ltx_text" style="font-size:207%;">26.74 %</span></td>
<td id="S3.T1.1.1.4.4.5" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T1.1.1.4.4.5.1" class="ltx_text" style="font-size:207%;">37.20 %</span></td>
</tr>
<tr id="S3.T1.1.1.5.5" class="ltx_tr">
<th id="S3.T1.1.1.5.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t"><span id="S3.T1.1.1.5.5.1.1" class="ltx_text" style="font-size:207%;">Number of Users</span></th>
<td id="S3.T1.1.1.5.5.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S3.T1.1.1.5.5.2.1" class="ltx_text" style="font-size:207%;">42</span></td>
<td id="S3.T1.1.1.5.5.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S3.T1.1.1.5.5.3.1" class="ltx_text" style="font-size:207%;">20</span></td>
<td id="S3.T1.1.1.5.5.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S3.T1.1.1.5.5.4.1" class="ltx_text" style="font-size:207%;">46</span></td>
<td id="S3.T1.1.1.5.5.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S3.T1.1.1.5.5.5.1" class="ltx_text" style="font-size:207%;">64</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div id="S3.SS3.SSS1.p2" class="ltx_para">
<p id="S3.SS3.SSS1.p2.1" class="ltx_p">Furthermore, to employ binary classification, we binarize the UMD Dataset. Based on the definition of each class, “<span id="S3.SS3.SSS1.p2.1.1" class="ltx_text ltx_font_italic">No Risk</span>” and “<span id="S3.SS3.SSS1.p2.1.2" class="ltx_text ltx_font_italic">Low Risk</span>” classes are considered as Non-Suicidal and “<span id="S3.SS3.SSS1.p2.1.3" class="ltx_text ltx_font_italic">Moderate Risk</span>” and“<span id="S3.SS3.SSS1.p2.1.4" class="ltx_text ltx_font_italic">High Risk</span>” as Suicidal. Table <a href="#S3.T2" title="TABLE II ‣ III-C1 Testing subsets ‣ III-C Evaluation of Synthetic Dataset ‣ III Methodology ‣ Socially Aware Synthetic Data Generation for Suicidal Ideation Detection Using Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a> presents the description of binarized UMD dataset.</p>
</div>
<figure id="S3.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:50%;"><span class="ltx_tag ltx_tag_table">TABLE II: </span>The description of the training and testing subset of UMD Dataset for binary task</figcaption>
<div id="S3.T2.3" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:173.4pt;height:126.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(25.2pt,-18.4pt) scale(1.40980695780407,1.40980695780407) ;">
<table id="S3.T2.3.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S3.T2.3.1.1.1" class="ltx_tr">
<th id="S3.T2.3.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S3.T2.3.1.1.1.1.1" class="ltx_text" style="font-size:50%;">Binary Dataset</span></th>
<td id="S3.T2.3.1.1.1.2" class="ltx_td ltx_align_center"><span id="S3.T2.3.1.1.1.2.1" class="ltx_text" style="font-size:50%;">Non Suicidal</span></td>
<td id="S3.T2.3.1.1.1.3" class="ltx_td ltx_align_center"><span id="S3.T2.3.1.1.1.3.1" class="ltx_text" style="font-size:50%;">Suicidal</span></td>
</tr>
<tr id="S3.T2.3.1.2.2" class="ltx_tr">
<th id="S3.T2.3.1.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S3.T2.3.1.2.2.1.1" class="ltx_text" style="font-size:50%;">Training Subset</span></th>
<td id="S3.T2.3.1.2.2.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.3.1.2.2.2.1" class="ltx_text" style="font-size:50%;">43.84%</span></td>
<td id="S3.T2.3.1.2.2.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.3.1.2.2.3.1" class="ltx_text" style="font-size:50%;">56.14%</span></td>
</tr>
<tr id="S3.T2.3.1.3.3" class="ltx_tr">
<th id="S3.T2.3.1.3.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S3.T2.3.1.3.3.1.1" class="ltx_text" style="font-size:50%;">Number of Users</span></th>
<td id="S3.T2.3.1.3.3.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.3.1.3.3.2.1" class="ltx_text" style="font-size:50%;">246</span></td>
<td id="S3.T2.3.1.3.3.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.3.1.3.3.3.1" class="ltx_text" style="font-size:50%;">315</span></td>
</tr>
<tr id="S3.T2.3.1.4.4" class="ltx_tr">
<th id="S3.T2.3.1.4.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_tt"><span id="S3.T2.3.1.4.4.1.1" class="ltx_text" style="font-size:50%;">Testing Subset</span></th>
<td id="S3.T2.3.1.4.4.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T2.3.1.4.4.2.1" class="ltx_text" style="font-size:50%;">36.3</span></td>
<td id="S3.T2.3.1.4.4.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T2.3.1.4.4.3.1" class="ltx_text" style="font-size:50%;">63.94</span></td>
</tr>
<tr id="S3.T2.3.1.5.5" class="ltx_tr">
<th id="S3.T2.3.1.5.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t"><span id="S3.T2.3.1.5.5.1.1" class="ltx_text" style="font-size:50%;">Number of Users</span></th>
<td id="S3.T2.3.1.5.5.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S3.T2.3.1.5.5.2.1" class="ltx_text" style="font-size:50%;">62</span></td>
<td id="S3.T2.3.1.5.5.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S3.T2.3.1.5.5.3.1" class="ltx_text" style="font-size:50%;">110</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div id="S3.SS3.SSS1.p3" class="ltx_para">
<p id="S3.SS3.SSS1.p3.1" class="ltx_p">The second testing set is composed of 10% of each synthetic dataset generated in our project. This test set is annotated independently by two human annotators. A notable 89% of the labels, initially generated by the generative models, were agreed upon by the human annotators. However, for the remaining 11% of the data, the labels were altered based on the decision of the annotators. In cases where both annotators agreed on a label, that label was retained. Conversely, when disagreements arose, the annotators engaged in discussions to ultimately reach a consensus on the appropriate label. The details of the generated synthetic dataset are presented in Table  <a href="#S4.T3" title="TABLE III ‣ IV-A Synthetic Data Generation ‣ IV Results ‣ Socially Aware Synthetic Data Generation for Suicidal Ideation Detection Using Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a> as the eleventh dataset.</p>
</div>
</section>
<section id="S3.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS3.SSS2.5.1.1" class="ltx_text">III-C</span>2 </span>Augmented Dataset</h4>

<div id="S3.SS3.SSS2.p1" class="ltx_para">
<p id="S3.SS3.SSS2.p1.1" class="ltx_p">Data augmentation involves enriching a dataset by introducing variations to its existing instances or generating entirely new instances. This process is designed to enhance the diversity and quality of the dataset, which, in turn, can lead to improved model performance and generalization. Hence, in this study, we augment the best performing synthetic dataset generated by LLMs with different subset sizes of UMD dataset. Starting with 10% of the UMD training subset, this subset is combined with the selected synthetic dataset. The augmented dataset, which is a mix of synthetic and real instances, is used to fine-tune the pretrained models. We continue this process by increasing the number of real data instances, such as 20% and 30%, until achieving comparable results to those obtained from the model trained on the full UMD dataset.</p>
</div>
</section>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Results</span>
</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In this section, first, we present the characteristics of each synthetic dataset. Second, we report a comprehensive comparison of the models fine-tuned with them.
Third, we report the data augmentation results. For evaluation, we report two widely-used metrics in this task, accuracy and F-score, to provide a complete and informative evaluation of the performance of the classification models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib66" title="" class="ltx_ref">66</a>]</cite>.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS1.5.1.1" class="ltx_text">IV-A</span> </span><span id="S4.SS1.6.2" class="ltx_text ltx_font_italic">Synthetic Data Generation</span>
</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">A total of nine datasets are generated. An extensive description of these datasets, as well as a mixed set and a test subset, is presented in Table <a href="#S4.T3" title="TABLE III ‣ IV-A Synthetic Data Generation ‣ IV Results ‣ Socially Aware Synthetic Data Generation for Suicidal Ideation Detection Using Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a>. As shown in Table <a href="#S4.T3" title="TABLE III ‣ IV-A Synthetic Data Generation ‣ IV Results ‣ Socially Aware Synthetic Data Generation for Suicidal Ideation Detection Using Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a>, we created binary datasets and four-class datasets, each with the option of including or not including the topics.
The binary datasets contain two classes, which allows us to evaluate the model’s ability to distinguish between suicidal ideation and non-suicidal instances. On the other hand, the four-class datasets involve multiple categories, enabling us to explore more nuanced predictions of suicidal ideation levels, including “<span id="S4.SS1.p1.1.1" class="ltx_text ltx_font_italic">No Risk</span>”, “<span id="S4.SS1.p1.1.2" class="ltx_text ltx_font_italic">Low Risk</span>”, “<span id="S4.SS1.p1.1.3" class="ltx_text ltx_font_italic">Moderate Risk</span>” and “<span id="S4.SS1.p1.1.4" class="ltx_text ltx_font_italic">High Risk</span>” classes. Moreover, the option to include or not include the topics in these datasets allows us to investigate the impact of information provided by topics on the model’s performance.</p>
</div>
<figure id="S4.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE III: </span>Detailed description of generated synthetic datasets</figcaption>
<div id="S4.T3.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:780.5pt;height:365pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(159.3pt,-74.5pt) scale(1.69003852576862,1.69003852576862) ;">
<table id="S4.T3.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T3.1.1.1.1" class="ltx_tr">
<th id="S4.T3.1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Dataset #</th>
<th id="S4.T3.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Model</th>
<th id="S4.T3.1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Learning Method</th>
<th id="S4.T3.1.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Topic-Oriented</th>
<th id="S4.T3.1.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"># of Class</th>
<th id="S4.T3.1.1.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"># of Instances</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T3.1.1.2.1" class="ltx_tr">
<td id="S4.T3.1.1.2.1.1" class="ltx_td ltx_align_center ltx_border_t">1</td>
<td id="S4.T3.1.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t">Chat GPT</td>
<td id="S4.T3.1.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t">Zero-Shot</td>
<td id="S4.T3.1.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t">Yes</td>
<td id="S4.T3.1.1.2.1.5" class="ltx_td ltx_align_center ltx_border_t">2</td>
<td id="S4.T3.1.1.2.1.6" class="ltx_td ltx_align_center ltx_border_t">549</td>
</tr>
<tr id="S4.T3.1.1.3.2" class="ltx_tr">
<td id="S4.T3.1.1.3.2.1" class="ltx_td ltx_align_center">2</td>
<td id="S4.T3.1.1.3.2.2" class="ltx_td ltx_align_center">Chat GPT</td>
<td id="S4.T3.1.1.3.2.3" class="ltx_td ltx_align_center">Zero-Shot</td>
<td id="S4.T3.1.1.3.2.4" class="ltx_td ltx_align_center">No</td>
<td id="S4.T3.1.1.3.2.5" class="ltx_td ltx_align_center">2</td>
<td id="S4.T3.1.1.3.2.6" class="ltx_td ltx_align_center">646</td>
</tr>
<tr id="S4.T3.1.1.4.3" class="ltx_tr">
<td id="S4.T3.1.1.4.3.1" class="ltx_td ltx_align_center">3</td>
<td id="S4.T3.1.1.4.3.2" class="ltx_td ltx_align_center">Chat GPT</td>
<td id="S4.T3.1.1.4.3.3" class="ltx_td ltx_align_center">Few-Shot</td>
<td id="S4.T3.1.1.4.3.4" class="ltx_td ltx_align_center">Yes</td>
<td id="S4.T3.1.1.4.3.5" class="ltx_td ltx_align_center">2</td>
<td id="S4.T3.1.1.4.3.6" class="ltx_td ltx_align_center">545</td>
</tr>
<tr id="S4.T3.1.1.5.4" class="ltx_tr">
<td id="S4.T3.1.1.5.4.1" class="ltx_td ltx_align_center">4</td>
<td id="S4.T3.1.1.5.4.2" class="ltx_td ltx_align_center">Chat GPT</td>
<td id="S4.T3.1.1.5.4.3" class="ltx_td ltx_align_center">Zero-Shot</td>
<td id="S4.T3.1.1.5.4.4" class="ltx_td ltx_align_center">Yes</td>
<td id="S4.T3.1.1.5.4.5" class="ltx_td ltx_align_center">4</td>
<td id="S4.T3.1.1.5.4.6" class="ltx_td ltx_align_center">492</td>
</tr>
<tr id="S4.T3.1.1.6.5" class="ltx_tr">
<td id="S4.T3.1.1.6.5.1" class="ltx_td ltx_align_center">5</td>
<td id="S4.T3.1.1.6.5.2" class="ltx_td ltx_align_center">Chat GPT</td>
<td id="S4.T3.1.1.6.5.3" class="ltx_td ltx_align_center">Few-Shot</td>
<td id="S4.T3.1.1.6.5.4" class="ltx_td ltx_align_center">Yes</td>
<td id="S4.T3.1.1.6.5.5" class="ltx_td ltx_align_center">4</td>
<td id="S4.T3.1.1.6.5.6" class="ltx_td ltx_align_center">594</td>
</tr>
<tr id="S4.T3.1.1.7.6" class="ltx_tr">
<td id="S4.T3.1.1.7.6.1" class="ltx_td ltx_align_center">6</td>
<td id="S4.T3.1.1.7.6.2" class="ltx_td ltx_align_center">Flan-T5</td>
<td id="S4.T3.1.1.7.6.3" class="ltx_td ltx_align_center">Zero-Shot</td>
<td id="S4.T3.1.1.7.6.4" class="ltx_td ltx_align_center">Yes</td>
<td id="S4.T3.1.1.7.6.5" class="ltx_td ltx_align_center">2</td>
<td id="S4.T3.1.1.7.6.6" class="ltx_td ltx_align_center">561</td>
</tr>
<tr id="S4.T3.1.1.8.7" class="ltx_tr">
<td id="S4.T3.1.1.8.7.1" class="ltx_td ltx_align_center">7</td>
<td id="S4.T3.1.1.8.7.2" class="ltx_td ltx_align_center">Flan-T5</td>
<td id="S4.T3.1.1.8.7.3" class="ltx_td ltx_align_center">Zero-Shot</td>
<td id="S4.T3.1.1.8.7.4" class="ltx_td ltx_align_center">No</td>
<td id="S4.T3.1.1.8.7.5" class="ltx_td ltx_align_center">2</td>
<td id="S4.T3.1.1.8.7.6" class="ltx_td ltx_align_center">502</td>
</tr>
<tr id="S4.T3.1.1.9.8" class="ltx_tr">
<td id="S4.T3.1.1.9.8.1" class="ltx_td ltx_align_center">8</td>
<td id="S4.T3.1.1.9.8.2" class="ltx_td ltx_align_center">Llama 2</td>
<td id="S4.T3.1.1.9.8.3" class="ltx_td ltx_align_center">Zero-Shot</td>
<td id="S4.T3.1.1.9.8.4" class="ltx_td ltx_align_center">Yes</td>
<td id="S4.T3.1.1.9.8.5" class="ltx_td ltx_align_center">2</td>
<td id="S4.T3.1.1.9.8.6" class="ltx_td ltx_align_center">395</td>
</tr>
<tr id="S4.T3.1.1.10.9" class="ltx_tr">
<td id="S4.T3.1.1.10.9.1" class="ltx_td ltx_align_center">9</td>
<td id="S4.T3.1.1.10.9.2" class="ltx_td ltx_align_center">Llama 2</td>
<td id="S4.T3.1.1.10.9.3" class="ltx_td ltx_align_center">Zero-Shot</td>
<td id="S4.T3.1.1.10.9.4" class="ltx_td ltx_align_center">No</td>
<td id="S4.T3.1.1.10.9.5" class="ltx_td ltx_align_center">2</td>
<td id="S4.T3.1.1.10.9.6" class="ltx_td ltx_align_center">613</td>
</tr>
<tr id="S4.T3.1.1.11.10" class="ltx_tr">
<td id="S4.T3.1.1.11.10.1" class="ltx_td ltx_align_center">10</td>
<td id="S4.T3.1.1.11.10.2" class="ltx_td ltx_align_center">Mix Dataset</td>
<td id="S4.T3.1.1.11.10.3" class="ltx_td ltx_align_center">Zero-Shot</td>
<td id="S4.T3.1.1.11.10.4" class="ltx_td ltx_align_center">Yes</td>
<td id="S4.T3.1.1.11.10.5" class="ltx_td ltx_align_center">2</td>
<td id="S4.T3.1.1.11.10.6" class="ltx_td ltx_align_center">1352</td>
</tr>
<tr id="S4.T3.1.1.12.11" class="ltx_tr">
<td id="S4.T3.1.1.12.11.1" class="ltx_td ltx_align_center ltx_border_b">11</td>
<td id="S4.T3.1.1.12.11.2" class="ltx_td ltx_align_center ltx_border_b">Synthetic Testing Set</td>
<td id="S4.T3.1.1.12.11.3" class="ltx_td ltx_align_center ltx_border_b">Zero-Shot</td>
<td id="S4.T3.1.1.12.11.4" class="ltx_td ltx_align_center ltx_border_b">N/A</td>
<td id="S4.T3.1.1.12.11.5" class="ltx_td ltx_align_center ltx_border_b">2</td>
<td id="S4.T3.1.1.12.11.6" class="ltx_td ltx_align_center ltx_border_b">318</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p">By comparing the results from datasets with and without topics, we can gain insights into how incorporating topic-related data enhances or influences the model’s effectiveness in suicidal ideation detection.
Furthermore, as explained in Section <a href="#S3.SS3.SSS1" title="III-C1 Testing subsets ‣ III-C Evaluation of Synthetic Dataset ‣ III Methodology ‣ Socially Aware Synthetic Data Generation for Suicidal Ideation Detection Using Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-C</span>1</span></a>, we created a synthetic testing dataset comprising 10% of each dataset which is annotated by human experts.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS2.5.1.1" class="ltx_text">IV-B</span> </span><span id="S4.SS2.6.2" class="ltx_text ltx_font_italic">Fine-Tuned Classifiers</span>
</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">Two models, ALBERT and DistilBERT are fine-tuned with the generated synthetic datasets. Table <a href="#S4.T4" title="TABLE IV ‣ IV-B Fine-Tuned Classifiers ‣ IV Results ‣ Socially Aware Synthetic Data Generation for Suicidal Ideation Detection Using Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV</span></a> presents the results of the performance evaluation of models fine-tuned with multi-class synthetic datasets generated by ChatGPT in Zero-Shot and Few-Shot settings, tested on the multi-class UMD test set. Considering the poor performance of the multi-class synthetic dataset, we have chosen to disregard the multi-class aspect and proceed solely with the binary approach.</p>
</div>
<figure id="S4.T4" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE IV: </span>Performance evaluation of ALBERT and DistilBERT models on Multi-class datasets generated by ChatGPT </figcaption>
<div id="S4.T4.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:390.3pt;height:81.9pt;vertical-align:-0.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-101.3pt,21.1pt) scale(0.658181905679404,0.658181905679404) ;">
<table id="S4.T4.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T4.1.1.1.1" class="ltx_tr">
<th id="S4.T4.1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r"><span id="S4.T4.1.1.1.1.1.1" class="ltx_text" style="font-size:207%;">Models</span></th>
<th id="S4.T4.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r"><span id="S4.T4.1.1.1.1.2.1" class="ltx_text" style="font-size:207%;">Metrics</span></th>
<th id="S4.T4.1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column">
<table id="S4.T4.1.1.1.1.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T4.1.1.1.1.3.1.1" class="ltx_tr">
<td id="S4.T4.1.1.1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T4.1.1.1.1.3.1.1.1.1" class="ltx_text" style="font-size:207%;">Non-Synthetic</span></td>
</tr>
<tr id="S4.T4.1.1.1.1.3.1.2" class="ltx_tr">
<td id="S4.T4.1.1.1.1.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T4.1.1.1.1.3.1.2.1.1" class="ltx_text" style="font-size:207%;">UMD Dataset</span></td>
</tr>
</table>
</th>
<th id="S4.T4.1.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column">
<table id="S4.T4.1.1.1.1.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T4.1.1.1.1.4.1.1" class="ltx_tr">
<td id="S4.T4.1.1.1.1.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T4.1.1.1.1.4.1.1.1.1" class="ltx_text" style="font-size:207%;">ChatGPT</span></td>
</tr>
<tr id="S4.T4.1.1.1.1.4.1.2" class="ltx_tr">
<td id="S4.T4.1.1.1.1.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T4.1.1.1.1.4.1.2.1.1" class="ltx_text" style="font-size:207%;">Zero-Shot</span></td>
</tr>
</table>
</th>
<th id="S4.T4.1.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column">
<table id="S4.T4.1.1.1.1.5.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T4.1.1.1.1.5.1.1" class="ltx_tr">
<td id="S4.T4.1.1.1.1.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T4.1.1.1.1.5.1.1.1.1" class="ltx_text" style="font-size:207%;">ChatGPT</span></td>
</tr>
<tr id="S4.T4.1.1.1.1.5.1.2" class="ltx_tr">
<td id="S4.T4.1.1.1.1.5.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T4.1.1.1.1.5.1.2.1.1" class="ltx_text" style="font-size:207%;">Few-Shot</span></td>
</tr>
</table>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T4.1.1.2.1" class="ltx_tr">
<th id="S4.T4.1.1.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" rowspan="2"><span id="S4.T4.1.1.2.1.1.1" class="ltx_text" style="font-size:207%;">ALBERT</span></th>
<th id="S4.T4.1.1.2.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T4.1.1.2.1.2.1" class="ltx_text" style="font-size:207%;">Accuracy</span></th>
<td id="S4.T4.1.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.1.1.2.1.3.1" class="ltx_text" style="font-size:207%;">0.865</span></td>
<td id="S4.T4.1.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.1.1.2.1.4.1" class="ltx_text" style="font-size:207%;">0.41</span></td>
<td id="S4.T4.1.1.2.1.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.1.1.2.1.5.1" class="ltx_text" style="font-size:207%;">0.36</span></td>
</tr>
<tr id="S4.T4.1.1.3.2" class="ltx_tr">
<th id="S4.T4.1.1.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S4.T4.1.1.3.2.1.1" class="ltx_text" style="font-size:207%;">F1-Score</span></th>
<td id="S4.T4.1.1.3.2.2" class="ltx_td ltx_align_center"><span id="S4.T4.1.1.3.2.2.1" class="ltx_text" style="font-size:207%;">0.87</span></td>
<td id="S4.T4.1.1.3.2.3" class="ltx_td ltx_align_center"><span id="S4.T4.1.1.3.2.3.1" class="ltx_text" style="font-size:207%;">0.43</span></td>
<td id="S4.T4.1.1.3.2.4" class="ltx_td ltx_align_center"><span id="S4.T4.1.1.3.2.4.1" class="ltx_text" style="font-size:207%;">0.27</span></td>
</tr>
<tr id="S4.T4.1.1.4.3" class="ltx_tr">
<th id="S4.T4.1.1.4.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t" rowspan="2"><span id="S4.T4.1.1.4.3.1.1" class="ltx_text" style="font-size:207%;">DistilBERT</span></th>
<th id="S4.T4.1.1.4.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T4.1.1.4.3.2.1" class="ltx_text" style="font-size:207%;">Accuracy</span></th>
<td id="S4.T4.1.1.4.3.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.1.1.4.3.3.1" class="ltx_text" style="font-size:207%;">0.77</span></td>
<td id="S4.T4.1.1.4.3.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.1.1.4.3.4.1" class="ltx_text" style="font-size:207%;">0.06</span></td>
<td id="S4.T4.1.1.4.3.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.1.1.4.3.5.1" class="ltx_text" style="font-size:207%;">0.06</span></td>
</tr>
<tr id="S4.T4.1.1.5.4" class="ltx_tr">
<th id="S4.T4.1.1.5.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r"><span id="S4.T4.1.1.5.4.1.1" class="ltx_text" style="font-size:207%;">F1-Score</span></th>
<td id="S4.T4.1.1.5.4.2" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T4.1.1.5.4.2.1" class="ltx_text" style="font-size:207%;">0.75</span></td>
<td id="S4.T4.1.1.5.4.3" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T4.1.1.5.4.3.1" class="ltx_text" style="font-size:207%;">0.1</span></td>
<td id="S4.T4.1.1.5.4.4" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T4.1.1.5.4.4.1" class="ltx_text" style="font-size:207%;">0.12</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">Moreover, Table <a href="#S4.T5" title="TABLE V ‣ IV-B Fine-Tuned Classifiers ‣ IV Results ‣ Socially Aware Synthetic Data Generation for Suicidal Ideation Detection Using Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">V</span></a> provides the performance of the models trained on the binary synthetic datasets generated by ChatGPT, Flan-T5 and Llama models and tested on the binary UMD testing subset. We compare the results for the synthetic datasets with those of the UMD training set. Table <a href="#S4.T5" title="TABLE V ‣ IV-B Fine-Tuned Classifiers ‣ IV Results ‣ Socially Aware Synthetic Data Generation for Suicidal Ideation Detection Using Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">V</span></a> shows that incorporating topic in generating the datasets significantly improves the performance of the models. For instance, for Llama 2, the topic-oriented dataset increased the F1-score and accuracy of the ALBERT model by 10% and 14% points, respectively. We also created a mixed dataset, including all topic-oriented datasets, to further evaluate the effects of topics on the performance of the models. With both ALBERT and DistilBERT, an F1-score of 0.82 is achieved by the mixed dataset, which is significantly higher than the DistilBERT model trained on the UMD dataset and comparable with the performance of the ALBERT model fine-tuned on the UMD dataset with an F1-score of 0.87.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.1" class="ltx_p">Table <a href="#S4.T6" title="TABLE VI ‣ IV-B Fine-Tuned Classifiers ‣ IV Results ‣ Socially Aware Synthetic Data Generation for Suicidal Ideation Detection Using Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">VI</span></a> presents the results of models included in Table <a href="#S4.T5" title="TABLE V ‣ IV-B Fine-Tuned Classifiers ‣ IV Results ‣ Socially Aware Synthetic Data Generation for Suicidal Ideation Detection Using Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">V</span></a> but tested on synthetic testing datasets. Similar to the results of Table <a href="#S4.T5" title="TABLE V ‣ IV-B Fine-Tuned Classifiers ‣ IV Results ‣ Socially Aware Synthetic Data Generation for Suicidal Ideation Detection Using Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">V</span></a>, all of the topic-oriented datasets show significant improvement compared to the datasets without any topics. ChatGPT-generated training data, with an F1-score of 0.82, exhibits the best performance, while the performances of Flan-T5 and Llama2-generated datasets are acceptable. Moreover, the mixed dataset shows a 0.81 F1-score, which is an 11% improvement compared to the model trained with the UMD dataset.</p>
</div>
<figure id="S4.T5" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE V: </span>Performance evaluation of the ALBERT and DistilBERT models fine-tuned with binary datasets and tested on UMD testing subset</figcaption>
<div id="S4.T5.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:867.2pt;height:148.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(50.8pt,-8.7pt) scale(1.13282265189268,1.13282265189268) ;">
<table id="S4.T5.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T5.1.1.1.1" class="ltx_tr">
<th id="S4.T5.1.1.1.1.1" class="ltx_td ltx_th ltx_th_column"></th>
<th id="S4.T5.1.1.1.1.2" class="ltx_td ltx_th ltx_th_column ltx_border_r"></th>
<th id="S4.T5.1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r">Non-Synthetic</th>
<th id="S4.T5.1.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column" colspan="3">ChatGPT</th>
<th id="S4.T5.1.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r" colspan="2">Flan-T5</th>
<th id="S4.T5.1.1.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r" colspan="2">Llama 2</th>
<th id="S4.T5.1.1.1.1.7" class="ltx_td ltx_align_left ltx_th ltx_th_column">Mix Dataset</th>
</tr>
<tr id="S4.T5.1.1.2.2" class="ltx_tr">
<th id="S4.T5.1.1.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r">Models</th>
<th id="S4.T5.1.1.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r">Metrics</th>
<th id="S4.T5.1.1.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">UMD Dataset</th>
<th id="S4.T5.1.1.2.2.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">
<table id="S4.T5.1.1.2.2.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T5.1.1.2.2.4.1.1" class="ltx_tr">
<td id="S4.T5.1.1.2.2.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">With Topic</td>
</tr>
<tr id="S4.T5.1.1.2.2.4.1.2" class="ltx_tr">
<td id="S4.T5.1.1.2.2.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Few-Shot</td>
</tr>
</table>
</th>
<th id="S4.T5.1.1.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">
<table id="S4.T5.1.1.2.2.5.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T5.1.1.2.2.5.1.1" class="ltx_tr">
<td id="S4.T5.1.1.2.2.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Without Topic</td>
</tr>
<tr id="S4.T5.1.1.2.2.5.1.2" class="ltx_tr">
<td id="S4.T5.1.1.2.2.5.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">Zero-Shot</td>
</tr>
</table>
</th>
<th id="S4.T5.1.1.2.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">
<table id="S4.T5.1.1.2.2.6.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T5.1.1.2.2.6.1.1" class="ltx_tr">
<td id="S4.T5.1.1.2.2.6.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">With Topic</td>
</tr>
<tr id="S4.T5.1.1.2.2.6.1.2" class="ltx_tr">
<td id="S4.T5.1.1.2.2.6.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">Zero-Shot</td>
</tr>
</table>
</th>
<th id="S4.T5.1.1.2.2.7" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">Without Topic</th>
<th id="S4.T5.1.1.2.2.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">With Topic</th>
<th id="S4.T5.1.1.2.2.9" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">Without Topic</th>
<th id="S4.T5.1.1.2.2.10" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">With Topic</th>
<th id="S4.T5.1.1.2.2.11" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">With Topic</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T5.1.1.3.1" class="ltx_tr">
<td id="S4.T5.1.1.3.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="2"><span id="S4.T5.1.1.3.1.1.1" class="ltx_text">ALBERT</span></td>
<td id="S4.T5.1.1.3.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Accuracy</td>
<td id="S4.T5.1.1.3.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.87</td>
<td id="S4.T5.1.1.3.1.4" class="ltx_td ltx_align_center ltx_border_t">0.67</td>
<td id="S4.T5.1.1.3.1.5" class="ltx_td ltx_align_center ltx_border_t">0.70</td>
<td id="S4.T5.1.1.3.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.71</td>
<td id="S4.T5.1.1.3.1.7" class="ltx_td ltx_align_center ltx_border_t">0.48</td>
<td id="S4.T5.1.1.3.1.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.62</td>
<td id="S4.T5.1.1.3.1.9" class="ltx_td ltx_align_center ltx_border_t">0.33</td>
<td id="S4.T5.1.1.3.1.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.75</td>
<td id="S4.T5.1.1.3.1.11" class="ltx_td ltx_align_center ltx_border_t">0.77</td>
</tr>
<tr id="S4.T5.1.1.4.2" class="ltx_tr">
<td id="S4.T5.1.1.4.2.1" class="ltx_td ltx_align_center ltx_border_r">F1-Score</td>
<td id="S4.T5.1.1.4.2.2" class="ltx_td ltx_align_center ltx_border_r">0.87</td>
<td id="S4.T5.1.1.4.2.3" class="ltx_td ltx_align_center">0.66</td>
<td id="S4.T5.1.1.4.2.4" class="ltx_td ltx_align_center">0.79</td>
<td id="S4.T5.1.1.4.2.5" class="ltx_td ltx_align_center ltx_border_r">0.79</td>
<td id="S4.T5.1.1.4.2.6" class="ltx_td ltx_align_center">0.54</td>
<td id="S4.T5.1.1.4.2.7" class="ltx_td ltx_align_center ltx_border_r">0.64</td>
<td id="S4.T5.1.1.4.2.8" class="ltx_td ltx_align_center">0.49</td>
<td id="S4.T5.1.1.4.2.9" class="ltx_td ltx_align_center ltx_border_r">0.78</td>
<td id="S4.T5.1.1.4.2.10" class="ltx_td ltx_align_center">0.82</td>
</tr>
<tr id="S4.T5.1.1.5.3" class="ltx_tr">
<td id="S4.T5.1.1.5.3.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" rowspan="2"><span id="S4.T5.1.1.5.3.1.1" class="ltx_text">DistilBERT</span></td>
<td id="S4.T5.1.1.5.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Accuracy</td>
<td id="S4.T5.1.1.5.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.77</td>
<td id="S4.T5.1.1.5.3.4" class="ltx_td ltx_align_center ltx_border_t">0.61</td>
<td id="S4.T5.1.1.5.3.5" class="ltx_td ltx_align_center ltx_border_t">0.63</td>
<td id="S4.T5.1.1.5.3.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.64</td>
<td id="S4.T5.1.1.5.3.7" class="ltx_td ltx_align_center ltx_border_t">0.59</td>
<td id="S4.T5.1.1.5.3.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.77</td>
<td id="S4.T5.1.1.5.3.9" class="ltx_td ltx_align_center ltx_border_t">0.32</td>
<td id="S4.T5.1.1.5.3.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.75</td>
<td id="S4.T5.1.1.5.3.11" class="ltx_td ltx_align_center ltx_border_t">0.76</td>
</tr>
<tr id="S4.T5.1.1.6.4" class="ltx_tr">
<td id="S4.T5.1.1.6.4.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">F1-Score</td>
<td id="S4.T5.1.1.6.4.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">0.75</td>
<td id="S4.T5.1.1.6.4.3" class="ltx_td ltx_align_center ltx_border_b">0.59</td>
<td id="S4.T5.1.1.6.4.4" class="ltx_td ltx_align_center ltx_border_b">0.69</td>
<td id="S4.T5.1.1.6.4.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">0.71</td>
<td id="S4.T5.1.1.6.4.6" class="ltx_td ltx_align_center ltx_border_b">0.61</td>
<td id="S4.T5.1.1.6.4.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">0.84</td>
<td id="S4.T5.1.1.6.4.8" class="ltx_td ltx_align_center ltx_border_b">0.15</td>
<td id="S4.T5.1.1.6.4.9" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">0.77</td>
<td id="S4.T5.1.1.6.4.10" class="ltx_td ltx_align_center ltx_border_b">0.82</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure id="S4.T6" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE VI: </span>Performance evaluation of the ALBERT and DistilBERT models fine-tuned with binary datasets and tested on synthetic testing subset</figcaption>
<div id="S4.T6.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:867.2pt;height:148.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(50.8pt,-8.7pt) scale(1.13282265189268,1.13282265189268) ;">
<table id="S4.T6.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T6.1.1.1.1" class="ltx_tr">
<th id="S4.T6.1.1.1.1.1" class="ltx_td ltx_th ltx_th_column"></th>
<th id="S4.T6.1.1.1.1.2" class="ltx_td ltx_th ltx_th_column ltx_border_r"></th>
<th id="S4.T6.1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r">Non-Synthetic</th>
<th id="S4.T6.1.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column" colspan="3">ChatGPT</th>
<th id="S4.T6.1.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r" colspan="2">Flan-T5</th>
<th id="S4.T6.1.1.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r" colspan="2">Llama 2</th>
<th id="S4.T6.1.1.1.1.7" class="ltx_td ltx_align_left ltx_th ltx_th_column">Mix Dataset</th>
</tr>
<tr id="S4.T6.1.1.2.2" class="ltx_tr">
<th id="S4.T6.1.1.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r">Models</th>
<th id="S4.T6.1.1.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r">Metrics</th>
<th id="S4.T6.1.1.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">UMD Dataset</th>
<th id="S4.T6.1.1.2.2.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">
<table id="S4.T6.1.1.2.2.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T6.1.1.2.2.4.1.1" class="ltx_tr">
<td id="S4.T6.1.1.2.2.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">With Topic</td>
</tr>
<tr id="S4.T6.1.1.2.2.4.1.2" class="ltx_tr">
<td id="S4.T6.1.1.2.2.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Few-Shot</td>
</tr>
</table>
</th>
<th id="S4.T6.1.1.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">
<table id="S4.T6.1.1.2.2.5.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T6.1.1.2.2.5.1.1" class="ltx_tr">
<td id="S4.T6.1.1.2.2.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Without Topic</td>
</tr>
<tr id="S4.T6.1.1.2.2.5.1.2" class="ltx_tr">
<td id="S4.T6.1.1.2.2.5.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">Zero-Shot</td>
</tr>
</table>
</th>
<th id="S4.T6.1.1.2.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">
<table id="S4.T6.1.1.2.2.6.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T6.1.1.2.2.6.1.1" class="ltx_tr">
<td id="S4.T6.1.1.2.2.6.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">With Topic</td>
</tr>
<tr id="S4.T6.1.1.2.2.6.1.2" class="ltx_tr">
<td id="S4.T6.1.1.2.2.6.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">Zero-Shot</td>
</tr>
</table>
</th>
<th id="S4.T6.1.1.2.2.7" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">Without Topic</th>
<th id="S4.T6.1.1.2.2.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">With Topic</th>
<th id="S4.T6.1.1.2.2.9" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">Without Topic</th>
<th id="S4.T6.1.1.2.2.10" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">With Topic</th>
<th id="S4.T6.1.1.2.2.11" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">With Topic</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T6.1.1.3.1" class="ltx_tr">
<td id="S4.T6.1.1.3.1.1" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S4.T6.1.1.3.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Accuracy</td>
<td id="S4.T6.1.1.3.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.67</td>
<td id="S4.T6.1.1.3.1.4" class="ltx_td ltx_align_center ltx_border_t">0.71</td>
<td id="S4.T6.1.1.3.1.5" class="ltx_td ltx_align_center ltx_border_t">0.81</td>
<td id="S4.T6.1.1.3.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.81</td>
<td id="S4.T6.1.1.3.1.7" class="ltx_td ltx_align_center ltx_border_t">0.34</td>
<td id="S4.T6.1.1.3.1.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.63</td>
<td id="S4.T6.1.1.3.1.9" class="ltx_td ltx_align_center ltx_border_t">0.48</td>
<td id="S4.T6.1.1.3.1.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.70</td>
<td id="S4.T6.1.1.3.1.11" class="ltx_td ltx_align_center ltx_border_t">0.83</td>
</tr>
<tr id="S4.T6.1.1.4.2" class="ltx_tr">
<td id="S4.T6.1.1.4.2.1" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T6.1.1.4.2.1.1" class="ltx_text">ALBERT</span></td>
<td id="S4.T6.1.1.4.2.2" class="ltx_td ltx_align_center ltx_border_r">F1-Score</td>
<td id="S4.T6.1.1.4.2.3" class="ltx_td ltx_align_center ltx_border_r">0.70</td>
<td id="S4.T6.1.1.4.2.4" class="ltx_td ltx_align_center">0.69</td>
<td id="S4.T6.1.1.4.2.5" class="ltx_td ltx_align_center">0.78</td>
<td id="S4.T6.1.1.4.2.6" class="ltx_td ltx_align_center ltx_border_r">0.82</td>
<td id="S4.T6.1.1.4.2.7" class="ltx_td ltx_align_center">0.41</td>
<td id="S4.T6.1.1.4.2.8" class="ltx_td ltx_align_center ltx_border_r">0.69</td>
<td id="S4.T6.1.1.4.2.9" class="ltx_td ltx_align_center">0.24</td>
<td id="S4.T6.1.1.4.2.10" class="ltx_td ltx_align_center ltx_border_r">0.73</td>
<td id="S4.T6.1.1.4.2.11" class="ltx_td ltx_align_center">0.81</td>
</tr>
<tr id="S4.T6.1.1.5.3" class="ltx_tr">
<td id="S4.T6.1.1.5.3.1" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S4.T6.1.1.5.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Accuracy</td>
<td id="S4.T6.1.1.5.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.40</td>
<td id="S4.T6.1.1.5.3.4" class="ltx_td ltx_align_center ltx_border_t">0.65</td>
<td id="S4.T6.1.1.5.3.5" class="ltx_td ltx_align_center ltx_border_t">0.83</td>
<td id="S4.T6.1.1.5.3.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.85</td>
<td id="S4.T6.1.1.5.3.7" class="ltx_td ltx_align_center ltx_border_t">0.63</td>
<td id="S4.T6.1.1.5.3.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.86</td>
<td id="S4.T6.1.1.5.3.9" class="ltx_td ltx_align_center ltx_border_t">0.49</td>
<td id="S4.T6.1.1.5.3.10" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.63</td>
<td id="S4.T6.1.1.5.3.11" class="ltx_td ltx_align_center ltx_border_t">0.78</td>
</tr>
<tr id="S4.T6.1.1.6.4" class="ltx_tr">
<td id="S4.T6.1.1.6.4.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S4.T6.1.1.6.4.1.1" class="ltx_text">DistilBERT</span></td>
<td id="S4.T6.1.1.6.4.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">F1-Score</td>
<td id="S4.T6.1.1.6.4.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">0.61</td>
<td id="S4.T6.1.1.6.4.4" class="ltx_td ltx_align_center ltx_border_b">0.61</td>
<td id="S4.T6.1.1.6.4.5" class="ltx_td ltx_align_center ltx_border_b">0.81</td>
<td id="S4.T6.1.1.6.4.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">0.81</td>
<td id="S4.T6.1.1.6.4.7" class="ltx_td ltx_align_center ltx_border_b">0.69</td>
<td id="S4.T6.1.1.6.4.8" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">0.84</td>
<td id="S4.T6.1.1.6.4.9" class="ltx_td ltx_align_center ltx_border_b">0.12</td>
<td id="S4.T6.1.1.6.4.10" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">0.69</td>
<td id="S4.T6.1.1.6.4.11" class="ltx_td ltx_align_center ltx_border_b">0.73</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS3.5.1.1" class="ltx_text">IV-C</span> </span><span id="S4.SS3.6.2" class="ltx_text ltx_font_italic">Data Augmentation</span>
</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">Based on the results presented in Table <a href="#S4.T5" title="TABLE V ‣ IV-B Fine-Tuned Classifiers ‣ IV Results ‣ Socially Aware Synthetic Data Generation for Suicidal Ideation Detection Using Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">V</span></a> and Table <a href="#S4.T6" title="TABLE VI ‣ IV-B Fine-Tuned Classifiers ‣ IV Results ‣ Socially Aware Synthetic Data Generation for Suicidal Ideation Detection Using Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">VI</span></a>, the datasets generated by ChatGPT in the Zero-Shot setting show the best results compared to the other datasets. As explained in section <a href="#S3.SS3.SSS2" title="III-C2 Augmented Dataset ‣ III-C Evaluation of Synthetic Dataset ‣ III Methodology ‣ Socially Aware Synthetic Data Generation for Suicidal Ideation Detection Using Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-C</span>2</span></a>, the augmented dataset now contains a mix of synthetic and real data instances. The augmented dataset is used to fine-tune the pretrained models and then evaluated on two separate testing sets.
In each iteration, three folds, each comprising 10% of non-overlapping random samples from the UMD dataset, are added to the synthetic data. Subsequently, the average<span id="footnote13" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">13</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">13</sup><span class="ltx_tag ltx_tag_note">13</span>we also calculated the standard deviation of the metrics which were always ¡0.02.</span></span></span> of the accuracy and F1-score are calculated and reported in Table <a href="#S4.T7" title="TABLE VII ‣ IV-C Data Augmentation ‣ IV Results ‣ Socially Aware Synthetic Data Generation for Suicidal Ideation Detection Using Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">VII</span></a>.
If the model’s performance with the augmented dataset is less than the model trained with the UMD dataset, additional real-world data is gradually incorporated. For instance, the percentage of real data can be increased to 20% in the next iteration, and the training and evaluation process is repeated.</p>
</div>
<figure id="S4.T7" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE VII: </span>Performance evaluation of the ALBERT model fine-tuned with the augmented dataset (synthetic data + a subset of the UMD train set) and tested on UMD and synthetic testing subsets</figcaption>
<div id="S4.T7.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:63.4pt;vertical-align:-8.6pt;"><span class="ltx_transformed_inner" style="transform:translate(-442.6pt,56.0pt) scale(0.328814722556402,0.328814722556402) ;">
<table id="S4.T7.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T7.1.1.1.1" class="ltx_tr">
<th id="S4.T7.1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r"><span id="S4.T7.1.1.1.1.1.1" class="ltx_text" style="font-size:298%;">Test Set</span></th>
<th id="S4.T7.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r"><span id="S4.T7.1.1.1.1.2.1" class="ltx_text" style="font-size:298%;">Metric</span></th>
<th id="S4.T7.1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r">
<table id="S4.T7.1.1.1.1.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T7.1.1.1.1.3.1.1" class="ltx_tr">
<td id="S4.T7.1.1.1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T7.1.1.1.1.3.1.1.1.1" class="ltx_text" style="font-size:298%;">UMD</span></td>
</tr>
<tr id="S4.T7.1.1.1.1.3.1.2" class="ltx_tr">
<td id="S4.T7.1.1.1.1.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T7.1.1.1.1.3.1.2.1.1" class="ltx_text" style="font-size:298%;">Dataset</span></td>
</tr>
</table>
</th>
<th id="S4.T7.1.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column">
<table id="S4.T7.1.1.1.1.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T7.1.1.1.1.4.1.1" class="ltx_tr">
<td id="S4.T7.1.1.1.1.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T7.1.1.1.1.4.1.1.1.1" class="ltx_text" style="font-size:298%;">10%</span></td>
</tr>
<tr id="S4.T7.1.1.1.1.4.1.2" class="ltx_tr">
<td id="S4.T7.1.1.1.1.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">
<span id="S4.T7.1.1.1.1.4.1.2.1.1" class="ltx_text" style="font-size:298%;">(Avg. of 3 Folds)</span><sup id="S4.T7.1.1.1.1.4.1.2.1.2" class="ltx_sup"><span id="S4.T7.1.1.1.1.4.1.2.1.2.1" class="ltx_text" style="font-size:298%;">*</span></sup>
</td>
</tr>
</table>
</th>
<th id="S4.T7.1.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column">
<table id="S4.T7.1.1.1.1.5.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T7.1.1.1.1.5.1.1" class="ltx_tr">
<td id="S4.T7.1.1.1.1.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T7.1.1.1.1.5.1.1.1.1" class="ltx_text" style="font-size:298%;">20%</span></td>
</tr>
<tr id="S4.T7.1.1.1.1.5.1.2" class="ltx_tr">
<td id="S4.T7.1.1.1.1.5.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">
<span id="S4.T7.1.1.1.1.5.1.2.1.1" class="ltx_text" style="font-size:298%;">(Avg. of 3 Folds)</span><sup id="S4.T7.1.1.1.1.5.1.2.1.2" class="ltx_sup"><span id="S4.T7.1.1.1.1.5.1.2.1.2.1" class="ltx_text" style="font-size:298%;">*</span></sup>
</td>
</tr>
</table>
</th>
<th id="S4.T7.1.1.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column">
<span id="S4.T7.1.1.1.1.6.1" class="ltx_text" style="font-size:298%;">f</span>
<table id="S4.T7.1.1.1.1.6.2" class="ltx_tabular ltx_align_middle">
<tr id="S4.T7.1.1.1.1.6.2.1" class="ltx_tr">
<td id="S4.T7.1.1.1.1.6.2.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T7.1.1.1.1.6.2.1.1.1" class="ltx_text" style="font-size:298%;">30%</span></td>
</tr>
<tr id="S4.T7.1.1.1.1.6.2.2" class="ltx_tr">
<td id="S4.T7.1.1.1.1.6.2.2.1" class="ltx_td ltx_nopad_r ltx_align_center">
<span id="S4.T7.1.1.1.1.6.2.2.1.1" class="ltx_text" style="font-size:298%;">(Avg. of 3 Folds)</span><sup id="S4.T7.1.1.1.1.6.2.2.1.2" class="ltx_sup"><span id="S4.T7.1.1.1.1.6.2.2.1.2.1" class="ltx_text" style="font-size:298%;">*</span></sup>
</td>
</tr>
</table>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T7.1.1.2.1" class="ltx_tr">
<th id="S4.T7.1.1.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" rowspan="2"><span id="S4.T7.1.1.2.1.1.1" class="ltx_text" style="font-size:298%;">UMD Testing Set</span></th>
<th id="S4.T7.1.1.2.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T7.1.1.2.1.2.1" class="ltx_text" style="font-size:298%;">Accuracy</span></th>
<th id="S4.T7.1.1.2.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T7.1.1.2.1.3.1" class="ltx_text" style="font-size:298%;">0.87</span></th>
<td id="S4.T7.1.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T7.1.1.2.1.4.1" class="ltx_text" style="font-size:298%;">0.75</span></td>
<td id="S4.T7.1.1.2.1.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T7.1.1.2.1.5.1" class="ltx_text" style="font-size:298%;">0.81</span></td>
<td id="S4.T7.1.1.2.1.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T7.1.1.2.1.6.1" class="ltx_text" style="font-size:298%;">0.83</span></td>
</tr>
<tr id="S4.T7.1.1.3.2" class="ltx_tr">
<th id="S4.T7.1.1.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S4.T7.1.1.3.2.1.1" class="ltx_text" style="font-size:298%;">F1-Score</span></th>
<th id="S4.T7.1.1.3.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S4.T7.1.1.3.2.2.1" class="ltx_text" style="font-size:298%;">0.87</span></th>
<td id="S4.T7.1.1.3.2.3" class="ltx_td ltx_align_center"><span id="S4.T7.1.1.3.2.3.1" class="ltx_text" style="font-size:298%;">0.79</span></td>
<td id="S4.T7.1.1.3.2.4" class="ltx_td ltx_align_center"><span id="S4.T7.1.1.3.2.4.1" class="ltx_text" style="font-size:298%;">0.84</span></td>
<td id="S4.T7.1.1.3.2.5" class="ltx_td ltx_align_center"><span id="S4.T7.1.1.3.2.5.1" class="ltx_text" style="font-size:298%;">0.88</span></td>
</tr>
<tr id="S4.T7.1.1.4.3" class="ltx_tr">
<th id="S4.T7.1.1.4.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t" rowspan="2"><span id="S4.T7.1.1.4.3.1.1" class="ltx_text" style="font-size:298%;">Synthetic Testing Set</span></th>
<th id="S4.T7.1.1.4.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T7.1.1.4.3.2.1" class="ltx_text" style="font-size:298%;">Accuracy</span></th>
<th id="S4.T7.1.1.4.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T7.1.1.4.3.3.1" class="ltx_text" style="font-size:298%;">0.67</span></th>
<td id="S4.T7.1.1.4.3.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T7.1.1.4.3.4.1" class="ltx_text" style="font-size:298%;">0.87</span></td>
<td id="S4.T7.1.1.4.3.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T7.1.1.4.3.5.1" class="ltx_text" style="font-size:298%;">0.87</span></td>
<td id="S4.T7.1.1.4.3.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T7.1.1.4.3.6.1" class="ltx_text" style="font-size:298%;">0.90</span></td>
</tr>
<tr id="S4.T7.1.1.5.4" class="ltx_tr">
<th id="S4.T7.1.1.5.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r"><span id="S4.T7.1.1.5.4.1.1" class="ltx_text" style="font-size:298%;">F1-Score</span></th>
<th id="S4.T7.1.1.5.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r"><span id="S4.T7.1.1.5.4.2.1" class="ltx_text" style="font-size:298%;">0.70</span></th>
<td id="S4.T7.1.1.5.4.3" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T7.1.1.5.4.3.1" class="ltx_text" style="font-size:298%;">0.83</span></td>
<td id="S4.T7.1.1.5.4.4" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T7.1.1.5.4.4.1" class="ltx_text" style="font-size:298%;">0.86</span></td>
<td id="S4.T7.1.1.5.4.5" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T7.1.1.5.4.5.1" class="ltx_text" style="font-size:298%;">0.88</span></td>
</tr>
</tbody>
</table>
<ul id="S4.I1" class="ltx_itemize">
<li id="S4.I1.ix1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">*</span> 
<div id="S4.I1.ix1.p1" class="ltx_para">
<p id="S4.I1.ix1.p1.1" class="ltx_p"><span id="S4.I1.ix1.p1.1.1" class="ltx_text" style="font-size:298%;">Standard Deviation</span><math id="S4.I1.ix1.p1.1.m1.1" class="ltx_Math" alttext="&lt;" display="inline"><semantics id="S4.I1.ix1.p1.1.m1.1a"><mo mathsize="298%" id="S4.I1.ix1.p1.1.m1.1.1" xref="S4.I1.ix1.p1.1.m1.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="S4.I1.ix1.p1.1.m1.1b"><lt id="S4.I1.ix1.p1.1.m1.1.1.cmml" xref="S4.I1.ix1.p1.1.m1.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.ix1.p1.1.m1.1c">&lt;</annotation></semantics></math><span id="S4.I1.ix1.p1.1.2" class="ltx_text" style="font-size:298%;"> 2%</span></p>
</div>
</li>
</ul>
</span></div>
</figure>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.1" class="ltx_p">Throughout the iterations, the model’s performance is closely monitored and compared to the baseline model trained solely on the UMD dataset. The aim is to identify the point at which the augmented dataset starts producing results comparable to or even surpassing those of the baseline model. The process continues until an optimal percentage of real data is found, where the model achieves similar results as the baseline. This ratio indicates the ideal balance between synthetic and real data for achieving high model performance and generalization. Table <a href="#S4.T7" title="TABLE VII ‣ IV-C Data Augmentation ‣ IV Results ‣ Socially Aware Synthetic Data Generation for Suicidal Ideation Detection Using Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">VII</span></a> shows the results of each augmentation process until we achieved the F1-score of 0.87 on the UMD testing subset at 30% augmentation rate and F1-score of 0.85 on the synthetic testing subset at 10% augmentation rate.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Discussions</span>
</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">This study focuses on the generation of synthetic datasets using generative models and subsequently assessing the performance of models fine-tuned with these datasets. Our synthetic data generation framework addresses two limitations of real-world data collection and annotation. First, we address the data scarcity and annotation cost by generating micropost-like suicidal/non-suicidal text. Second, we address the lack of diversity in real-world data by forcing the generative models to create a balanced number of examples related to each of the psychological and social factors impacting suicidality. Integrating insights from psychology into the NLP pipeline in this context can illuminate previously unexplored facets of suicide and mental health detection in social media.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">We created several datasets, including binary and multi-class, in Zero-Shot and Few-Shot settings, topic-oriented and non-topic-oriented, with three different generative LLMs. Early in our experiments (Table  <a href="#S4.T4" title="TABLE IV ‣ IV-B Fine-Tuned Classifiers ‣ IV Results ‣ Socially Aware Synthetic Data Generation for Suicidal Ideation Detection Using Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV</span></a>), we observed that ChatGPT is not able to produce high-quality multi-class datasets in either the Zero-Shot or the Few-Shot settings.
Generating multi-class datasets using LLMs such as ChatGPT is more complex and challenging task due to the inherent complexities involved in distinguishing between multiple and fine-grained, classes. Even with the availability of a high-quality dataset, one should anticipate lower accuracies in multi-class scenarios. This is largely attributed to the ambiguous boundaries that exist between these classes, creating a complex landscape that proves difficult for any classifier to navigate successfully.
Moreover, the creation of such datasets necessitates not only a detailed prompt but also specific instructions that outline the multi-class scenarios. This process demands a nuanced understanding and a level of specificity that often poses a considerable challenge to ChatGPT. Longer<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib67" title="" class="ltx_ref">67</a>]</cite>.</p>
</div>
<div id="S5.p3" class="ltx_para">
<p id="S5.p3.1" class="ltx_p">As a result, we opted to exclusively create binary datasets and focus our investigation on how topics impact the overall generalizability of the fine-tuned models.</p>
</div>
<div id="S5.p4" class="ltx_para">
<p id="S5.p4.1" class="ltx_p">Our results show the critical role of incorporating domain knowledge in synthetic data generation. We extracted the relevant social topics from the Psychology literature and used that to create more focused prompts for data generation. Table <a href="#S5.T8" title="TABLE VIII ‣ V Discussions ‣ Socially Aware Synthetic Data Generation for Suicidal Ideation Detection Using Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">VIII</span></a> displays a selection of binary samples generated by ChatGPT within the synthetic dataset using social topics. The table provides an illustration of specific examples generated by this GLLM.</p>
</div>
<figure id="S5.T8" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE VIII: </span>Generated synthetic samples using extracted social and psychological topics by ChatGPT</figcaption>
<div id="S5.T8.1" class="ltx_inline-block ltx_transformed_outer" style="width:433.6pt;height:581.3pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-88.9pt,119.1pt) scale(0.709300830604997,0.709300830604997) ;">
<table id="S5.T8.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T8.1.1.1.1" class="ltx_tr">
<th id="S5.T8.1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r">Topics</th>
<th id="S5.T8.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r">Labels</th>
<th id="S5.T8.1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column">Sample</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T8.1.1.2.1" class="ltx_tr">
<td id="S5.T8.1.1.2.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="2"><span id="S5.T8.1.1.2.1.1.1" class="ltx_text">Depression</span></td>
<td id="S5.T8.1.1.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1</td>
<td id="S5.T8.1.1.2.1.3" class="ltx_td ltx_align_left ltx_border_t">
<table id="S5.T8.1.1.2.1.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T8.1.1.2.1.3.1.1" class="ltx_tr">
<td id="S5.T8.1.1.2.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Growing up, I always felt like nobody wanted me. No one ever seemed to care about my thoughts, feelings,</td>
</tr>
<tr id="S5.T8.1.1.2.1.3.1.2" class="ltx_tr">
<td id="S5.T8.1.1.2.1.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">or emotions. As I got older, these feelings intensified, and I started to feel like I was a burden on everyone</td>
</tr>
<tr id="S5.T8.1.1.2.1.3.1.3" class="ltx_tr">
<td id="S5.T8.1.1.2.1.3.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">around me. I never felt like I belonged anywhere and I constantly struggled with my depression. The constant</td>
</tr>
<tr id="S5.T8.1.1.2.1.3.1.4" class="ltx_tr">
<td id="S5.T8.1.1.2.1.3.1.4.1" class="ltx_td ltx_nopad_r ltx_align_left">emptiness and loneliness eventually became too much to bear, and I began to contemplate ending my life.</td>
</tr>
</table>
</td>
</tr>
<tr id="S5.T8.1.1.3.2" class="ltx_tr">
<td id="S5.T8.1.1.3.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0</td>
<td id="S5.T8.1.1.3.2.2" class="ltx_td ltx_align_left ltx_border_t">
<table id="S5.T8.1.1.3.2.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T8.1.1.3.2.2.1.1" class="ltx_tr">
<td id="S5.T8.1.1.3.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">I’ve been struggling with mental health problems for as long as I can remember. Depression have been my</td>
</tr>
<tr id="S5.T8.1.1.3.2.2.1.2" class="ltx_tr">
<td id="S5.T8.1.1.3.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">constant companions. But I’ve never let it stop me from living my life. I’ve learned to manage my symptoms</td>
</tr>
<tr id="S5.T8.1.1.3.2.2.1.3" class="ltx_tr">
<td id="S5.T8.1.1.3.2.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">with the help of therapy and medication. Some days are harder than others, but I keep pushing forward and</td>
</tr>
<tr id="S5.T8.1.1.3.2.2.1.4" class="ltx_tr">
<td id="S5.T8.1.1.3.2.2.1.4.1" class="ltx_td ltx_nopad_r ltx_align_left">focusing on the good in my life. I’ve come to accept that mental illness is a part of me, but it doesn’t define me.</td>
</tr>
</table>
</td>
</tr>
<tr id="S5.T8.1.1.4.3" class="ltx_tr">
<td id="S5.T8.1.1.4.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="2"><span id="S5.T8.1.1.4.3.1.1" class="ltx_text">Bullying</span></td>
<td id="S5.T8.1.1.4.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1</td>
<td id="S5.T8.1.1.4.3.3" class="ltx_td ltx_align_left ltx_border_t">
<table id="S5.T8.1.1.4.3.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T8.1.1.4.3.3.1.1" class="ltx_tr">
<td id="S5.T8.1.1.4.3.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">I felt like I was constantly being attacked by my classmates. They called me names, pushed me around,</td>
</tr>
<tr id="S5.T8.1.1.4.3.3.1.2" class="ltx_tr">
<td id="S5.T8.1.1.4.3.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">and even vandalized my belongings. The worst part was feeling so alone and misunderstood. I didn’t</td>
</tr>
<tr id="S5.T8.1.1.4.3.3.1.3" class="ltx_tr">
<td id="S5.T8.1.1.4.3.3.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">want to burden my parents with my problems so I kept it all inside. The idea of ending it all seemed like</td>
</tr>
<tr id="S5.T8.1.1.4.3.3.1.4" class="ltx_tr">
<td id="S5.T8.1.1.4.3.3.1.4.1" class="ltx_td ltx_nopad_r ltx_align_left">the only way to escape the pain and torment.</td>
</tr>
</table>
</td>
</tr>
<tr id="S5.T8.1.1.5.4" class="ltx_tr">
<td id="S5.T8.1.1.5.4.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0</td>
<td id="S5.T8.1.1.5.4.2" class="ltx_td ltx_align_left ltx_border_t">
<table id="S5.T8.1.1.5.4.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T8.1.1.5.4.2.1.1" class="ltx_tr">
<td id="S5.T8.1.1.5.4.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">When I was in middle school, I was constantly bullied for being overweight. It was tough going to school</td>
</tr>
<tr id="S5.T8.1.1.5.4.2.1.2" class="ltx_tr">
<td id="S5.T8.1.1.5.4.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">every day and constantly being made fun of by my peers. I felt so alone and helpless. But I didn’t let the</td>
</tr>
<tr id="S5.T8.1.1.5.4.2.1.3" class="ltx_tr">
<td id="S5.T8.1.1.5.4.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">bullies control my life. I joined a support group and found friends who lifted me up. I also started exercising</td>
</tr>
<tr id="S5.T8.1.1.5.4.2.1.4" class="ltx_tr">
<td id="S5.T8.1.1.5.4.2.1.4.1" class="ltx_td ltx_nopad_r ltx_align_left">and eating healthier, not to please anyone else, but to feel better about myself. It wasn’t an easy journey, but</td>
</tr>
<tr id="S5.T8.1.1.5.4.2.1.5" class="ltx_tr">
<td id="S5.T8.1.1.5.4.2.1.5.1" class="ltx_td ltx_nopad_r ltx_align_left">it was worth it. I’m happy to say that today I am confident and proud of who I am.</td>
</tr>
</table>
</td>
</tr>
<tr id="S5.T8.1.1.6.5" class="ltx_tr">
<td id="S5.T8.1.1.6.5.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="2"><span id="S5.T8.1.1.6.5.1.1" class="ltx_text">Unemployment</span></td>
<td id="S5.T8.1.1.6.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1</td>
<td id="S5.T8.1.1.6.5.3" class="ltx_td ltx_align_left ltx_border_t">
<table id="S5.T8.1.1.6.5.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T8.1.1.6.5.3.1.1" class="ltx_tr">
<td id="S5.T8.1.1.6.5.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">After losing my job, I stayed unemployed for months. My savings ran out and with no source of income,</td>
</tr>
<tr id="S5.T8.1.1.6.5.3.1.2" class="ltx_tr">
<td id="S5.T8.1.1.6.5.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">my bills piled up. The constant fear of not being able to provide for myself and my family drove me to</td>
</tr>
<tr id="S5.T8.1.1.6.5.3.1.3" class="ltx_tr">
<td id="S5.T8.1.1.6.5.3.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">the brink of despair. I feel worthless and like a burden on everyone around me. The future seems bleak</td>
</tr>
<tr id="S5.T8.1.1.6.5.3.1.4" class="ltx_tr">
<td id="S5.T8.1.1.6.5.3.1.4.1" class="ltx_td ltx_nopad_r ltx_align_left">and hopeless, and I wonder if it’s worth it to keep going.</td>
</tr>
</table>
</td>
</tr>
<tr id="S5.T8.1.1.7.6" class="ltx_tr">
<td id="S5.T8.1.1.7.6.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0</td>
<td id="S5.T8.1.1.7.6.2" class="ltx_td ltx_align_left ltx_border_t">
<table id="S5.T8.1.1.7.6.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T8.1.1.7.6.2.1.1" class="ltx_tr">
<td id="S5.T8.1.1.7.6.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">After graduating from college, I struggled to find a job in my field for a few months. It was frustrating</td>
</tr>
<tr id="S5.T8.1.1.7.6.2.1.2" class="ltx_tr">
<td id="S5.T8.1.1.7.6.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">and disheartening, but I kept applying and networking. Eventually, I landed a job in a related field that</td>
</tr>
<tr id="S5.T8.1.1.7.6.2.1.3" class="ltx_tr">
<td id="S5.T8.1.1.7.6.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">I enjoy. It wasn’t my dream job, but it paid the bills and gave me experience. I’m still looking for my</td>
</tr>
<tr id="S5.T8.1.1.7.6.2.1.4" class="ltx_tr">
<td id="S5.T8.1.1.7.6.2.1.4.1" class="ltx_td ltx_nopad_r ltx_align_left">dream job, but I’m grateful for what I have and optimistic about my future prospects.</td>
</tr>
</table>
</td>
</tr>
<tr id="S5.T8.1.1.8.7" class="ltx_tr">
<td id="S5.T8.1.1.8.7.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" rowspan="2"><span id="S5.T8.1.1.8.7.1.1" class="ltx_text">Relationship problems</span></td>
<td id="S5.T8.1.1.8.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1</td>
<td id="S5.T8.1.1.8.7.3" class="ltx_td ltx_align_left ltx_border_t">
<table id="S5.T8.1.1.8.7.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T8.1.1.8.7.3.1.1" class="ltx_tr">
<td id="S5.T8.1.1.8.7.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">I thought I had found the one but it seems like I was wrong because he left me for someone else. I don’t</td>
</tr>
<tr id="S5.T8.1.1.8.7.3.1.2" class="ltx_tr">
<td id="S5.T8.1.1.8.7.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">know how to deal with this pain . I can’t sleep, I can’t eat, and I just want to disappear. Maybe everything</td>
</tr>
<tr id="S5.T8.1.1.8.7.3.1.3" class="ltx_tr">
<td id="S5.T8.1.1.8.7.3.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">would be easier if I just ended it all.</td>
</tr>
</table>
</td>
</tr>
<tr id="S5.T8.1.1.9.8" class="ltx_tr">
<td id="S5.T8.1.1.9.8.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">0</td>
<td id="S5.T8.1.1.9.8.2" class="ltx_td ltx_align_left ltx_border_b ltx_border_t">
<table id="S5.T8.1.1.9.8.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T8.1.1.9.8.2.1.1" class="ltx_tr">
<td id="S5.T8.1.1.9.8.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">My relationship with my partner hasn’t been going well lately. We have been arguing over small things,</td>
</tr>
<tr id="S5.T8.1.1.9.8.2.1.2" class="ltx_tr">
<td id="S5.T8.1.1.9.8.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">and it’s affecting our mental health. We decided to go for couples therapy, and it’s been a turning point for</td>
</tr>
<tr id="S5.T8.1.1.9.8.2.1.3" class="ltx_tr">
<td id="S5.T8.1.1.9.8.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">us. We learned to communicate better and understand each other’s perspective. Now we are in a better</td>
</tr>
<tr id="S5.T8.1.1.9.8.2.1.4" class="ltx_tr">
<td id="S5.T8.1.1.9.8.2.1.4.1" class="ltx_td ltx_nopad_r ltx_align_left">place and happier than ever before.</td>
</tr>
</table>
</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div id="S5.p5" class="ltx_para">
<p id="S5.p5.1" class="ltx_p">Table <a href="#S4.T5" title="TABLE V ‣ IV-B Fine-Tuned Classifiers ‣ IV Results ‣ Socially Aware Synthetic Data Generation for Suicidal Ideation Detection Using Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">V</span></a> presents the results of fine-tuned models on synthetic datasets and tested on the UMD dataset. Comparison between topic-oriented datasets and no topic-oriented datasets shows the significant effects of including the topics on the performance of the generated
datasets. Informing the data generation with topics in Flan-T5 and Llama2 increased the F1-Score of the ALBERT model by 10% and 29% points, respectively. Fine-tuning models on topic-oriented synthetic datasets allows them to gain diverse domain-specific knowledge and patterns.
Moreover, non-topic-oriented synthetic datasets might lack specificity, leading to noise and irrelevant content. In contrast, topic-oriented datasets are curated to focus on a specific domain, reducing the chances of generating irrelevant or out-of-context text.</p>
</div>
<div id="S5.p6" class="ltx_para">
<p id="S5.p6.1" class="ltx_p">We showed that the BERT family fine-tuned with real-world data can achieve an F1 score ranging from 0.75 to 0.87, depending on the complexity of their structure. Specifically, DistilBERT, a less efficient model from the BERT Family, achieves an F1-score of 0.75, while ALBERT, a more optimized model designed for speed and accuracy, attains an F1-score of 0.87. In contrast, both DistilBERT and ALBERT achieve a consistent F1-score of 0.82 when trained on purely synthetic data and tested on real-world data. With this, we demonstrate that the diversity of synthetic data compensates for model complexity irrespective of its architecture. This not only underscores the considerable potential of synthetic data but also suggests that it can mitigate the limitations of real-world data in capturing diverse topics. Most notably, our results emphasize an optimal strategy that involves augmenting synthetic data with real data. This innovative method achieves performances comparable to the ALBERT model, even when relying on merely 30% of the manually annotated dataset. This solidifies our proposed method as a cost-effective alternative, addressing the challenges of data scarcity and diversity more effectively than the current benchmarks. However,
Synthetic datasets often exhibit a distributional shift from real-world data. This shift arises due to the inherent differences in the data generation processes between synthetic and real domains. As a result, models trained solely on synthetic datasets may not be applicable in real-world situations, leading to a lack of robustness and adaptability. Therefor, exploring hybrid approaches that combine synthetic and real-world data for training can offer a more comprehensive solution. Leveraging both sources allows models to learn from the strengths of synthetic data while adapting to the intricacies of real-world environments.</p>
</div>
<div id="S5.p7" class="ltx_para">
<p id="S5.p7.1" class="ltx_p">As presented in Table <a href="#S4.T5" title="TABLE V ‣ IV-B Fine-Tuned Classifiers ‣ IV Results ‣ Socially Aware Synthetic Data Generation for Suicidal Ideation Detection Using Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">V</span></a> and Table <a href="#S4.T7" title="TABLE VII ‣ IV-C Data Augmentation ‣ IV Results ‣ Socially Aware Synthetic Data Generation for Suicidal Ideation Detection Using Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">VII</span></a>, our study’s central objective was to investigate the potential of synthetic and augmented data in training models to perform effectively on real-world data . Given this setup, the chance of overfitting is inherently reduced since the training (synthetic) and testing (real-world) datasets are obtained from distinct distributions.
Moreover, to better understand the performance, robustness, and limitations of the fine-tuned classifiers, we curated an additional test set by manual annotation of a subset of the synthetic data.
Additional tests ensure that the models do not overfit a particular dataset and can handle a variety of data distributions and scenarios. Table <a href="#S4.T6" title="TABLE VI ‣ IV-B Fine-Tuned Classifiers ‣ IV Results ‣ Socially Aware Synthetic Data Generation for Suicidal Ideation Detection Using Large Language Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">VI</span></a> presents the performance results of the fine-tuned models evaluated on the human-annotated synthetic dataset. Notably, the topic-oriented ChatGPT dataset stands out with an F1-score of 0.82, demonstrating its superior performance compared to the other datasets. Specifically, the model trained with the UMD dataset falls short in handling the synthetic test set, presumably because of its less diverse topics.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span id="S6.1.1" class="ltx_text ltx_font_smallcaps">Conclusion and Future works</span>
</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">The accurate identification of suicidal ideation from textual data holds paramount importance for early intervention and prevention efforts. Natural Language Processing (NLP) techniques have shown promise in this domain, but the scarcity and sensitivity of real suicide-related data pose significant challenges. Gathering and annotating real suicide-related data is a resource-intensive and ethically sensitive process. Synthetic data generation methods, such as text generation models and data augmentation techniques, offer a more cost-effective way to supplement real data. Also, our synthetic datasets offer a potential solution by providing additional social and psychological context in training instances
for models to address the limitations of the existing real data.</p>
</div>
<div id="S6.p2" class="ltx_para">
<p id="S6.p2.1" class="ltx_p">Our data augmentation results show that incorporating synthetic data into the training pipeline helps diversify the dataset and enhance model generalization. Real data is often limited in size, leading to over-fitting and reduced model performance. However, by carefully blending synthetic data with real data, we can bolster the model’s performance while maintaining a balance between practicality and sensitivity.</p>
</div>
<div id="S6.p3" class="ltx_para">
<p id="S6.p3.1" class="ltx_p">Moving forward, exploring the diversity of Language Models (LLMs) stands as an intriguing avenue for future research. Investigating and quantifying the extent of diversity within LLMs across various domains, languages, and training methodologies could offer valuable insights. Future works could delve into developing robust metrics or methodologies specifically tailored to assess and measure diversity within these models.</p>
</div>
<div id="S6.p4" class="ltx_para">
<p id="S6.p4.1" class="ltx_p">This paper has effectively highlighted the advantages of using synthetic data generation techniques in detecting suicidal ideation. However, the field still presents numerous opportunities for further research and refinement. Future initiatives could focus on the adaptation of models to various linguistic and cultural environments, acknowledging the diverse ways people express suicidal thoughts across different languages and cultures. Furthermore, a holistic approach that integrates multiple data modalities, such as images, audio, or behavioral data, alongside textual information could enhance the detection process. It’s also crucial to set up a framework that allows for the continuous evaluation and optimization of models, given the ever-changing nature of online communication patterns and user behaviors.</p>
</div>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VII </span><span id="S7.1.1" class="ltx_text ltx_font_smallcaps">Ethical Considerations</span>
</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">For this research, we obtained ethics approval from the research ethics board at the University of Ottawa. Moreover, the UMD dataset was used with authorization from its creators, and we adhered to the terms of use and ethical standards <span id="footnote14" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">14</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">14</sup><span class="ltx_tag ltx_tag_note">14</span><a target="_blank" href="http://users.umiacs.umd.edu/%C2%A0resnik/umd_reddit_suicidality_dataset.html" title="" class="ltx_ref ltx_href">The University of Maryland Reddit Suicidality Dataset</a></span></span></span> provided by them.</p>
</div>
<div id="S7.p2" class="ltx_para">
<p id="S7.p2.1" class="ltx_p">The use of LLMs for suicide-related synthetic datasets raises several ethical considerations.
Firstly, synthetic datasets should be generated in a way that avoids perpetuating or amplifying biases present in the original data. It is important to carefully examine the underlying data and the algorithms used in generating synthetic datasets to ensure fairness and mitigate potential biases.</p>
</div>
<div id="S7.p3" class="ltx_para">
<p id="S7.p3.1" class="ltx_p">Secondly, the process of generating synthetic datasets should be transparent and well-documented. It is essential to provide clear information about the methods used, assumptions made, and limitations of the synthetic data. This enables others to assess and evaluate the validity and appropriateness of using synthetic datasets.</p>
</div>
<div id="S7.p4" class="ltx_para">
<p id="S7.p4.1" class="ltx_p">Thirdly, to use synthetic datasets in sensitive applications or decision-making processes, accountability and liability should be considered. Care should be taken to understand the potential impact and consequences of decisions or actions based on synthetic data and establish mechanisms for addressing any negative outcomes or biases that may arise.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Domenico De Berardis, Giovanni Martinotti, and Massimo Di Giannantonio.

</span>
<span class="ltx_bibblock">Understanding the complex phenomenon of suicide: from research to clinical practice.

</span>
<span class="ltx_bibblock"><span id="bib.bib1.1.1" class="ltx_text ltx_font_italic">Frontiers in psychiatry</span>, 9:61, 2018.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
E Rajesh Kumar and N Venkatram.

</span>
<span class="ltx_bibblock">Predicting and analyzing suicidal risk behavior using rule-based approach in twitter data.

</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text ltx_font_italic">Soft Computing</span>, ePub:1–9, 2023.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Ali Raza, Furqan Rustam, Hafeez Ur Rehman Siddiqui, Isabel de la Torre Diez, Begoña Garcia-Zapirain, Ernesto Lee, and Imran Ashraf.

</span>
<span class="ltx_bibblock">Predicting genetic disorder and types of disorder using chain classifier approach.

</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text ltx_font_italic">Genes</span>, 14(1):71, 2022.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Asma Abdulsalam and Areej Alhothali.

</span>
<span class="ltx_bibblock">Suicidal ideation detection on social media: A review of machine learning methods.

</span>
<span class="ltx_bibblock"><span id="bib.bib4.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2201.10515</span>, 2022.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Zepeng Li, Jiawei Zhou, Zhengyi An, Wenchuan Cheng, and Bin Hu.

</span>
<span class="ltx_bibblock">Deep hierarchical ensemble model for suicide detection on imbalanced social media data.

</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text ltx_font_italic">Entropy</span>, 24(4):442, 2022.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Dheeraj Kodati and Ramakrishnudu Tene.

</span>
<span class="ltx_bibblock">Identifying suicidal emotions on social media through transformer-based deep learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text ltx_font_italic">Applied Intelligence</span>, 53(10):11885–11917, 2023.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Mian Muhammad Sadiq Fareed, Ali Raza, Na Zhao, Aqil Tariq, Faizan Younas, Gulnaz Ahmed, Saleem Ullah, Syeda Fizzah Jillani, Irfan Abbas, and Muhammad Aslam.

</span>
<span class="ltx_bibblock">Predicting divorce prospect using ensemble learning: Support vector machine, linear model, and neural network.

</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text ltx_font_italic">Computational Intelligence and Neuroscience</span>, 2022, 2022.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Qiang Wei, Amy Franklin, Trevor Cohen, and Hua Xu.

</span>
<span class="ltx_bibblock">Clinical text annotation–what factors are associated with the cost of time?

</span>
<span class="ltx_bibblock">In <span id="bib.bib8.1.1" class="ltx_text ltx_font_italic">AMIA Annual Symposium Proceedings</span>, volume 2018, page 1552. American Medical Informatics Association, 2018.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Rohit Babbar and Bernhard Schölkopf.

</span>
<span class="ltx_bibblock">Data scarcity, robustness and extreme multi-label classification.

</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text ltx_font_italic">Machine Learning</span>, 108(8-9):1329–1351, 2019.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Sergey I Nikolenko.

</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text ltx_font_italic">Synthetic data for deep learning</span>, volume 174.

</span>
<span class="ltx_bibblock">Springer, 2021.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Yingzhou Lu, Huazheng Wang, and Wenqi Wei.

</span>
<span class="ltx_bibblock">Machine learning for synthetic data generation: a review.

</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2302.04062</span>, 2023.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Hung Chau, Saeid Balaneshin, Kai Liu, and Ondrej Linda.

</span>
<span class="ltx_bibblock">Understanding the tradeoff between cost and quality of expert annotations for keyphrase extraction.

</span>
<span class="ltx_bibblock">In <span id="bib.bib12.1.1" class="ltx_text ltx_font_italic">Proceedings of the 14th Linguistic Annotation Workshop</span>, pages 74–86, 2020.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Dirk Hovy and Diyi Yang.

</span>
<span class="ltx_bibblock">The importance of modeling social factors of language: Theory and practice.

</span>
<span class="ltx_bibblock">In <span id="bib.bib13.1.1" class="ltx_text ltx_font_italic">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</span>, pages 588–602, Online, June 2021. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Ziniu Hu, Yichong Xu, Wenhao Yu, Shuohang Wang, Ziyi Yang, Chenguang Zhu, Kai-Wei Chang, and Yizhou Sun.

</span>
<span class="ltx_bibblock">Empowering language models with knowledge graph reasoning for open-domain question answering.

</span>
<span class="ltx_bibblock">In <span id="bib.bib14.1.1" class="ltx_text ltx_font_italic">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing</span>, pages 9562–9581, Abu Dhabi, United Arab Emirates, December 2022. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Joseph C Franklin, Jessica D Ribeiro, Kathryn R Fox, Kate H Bentley, Evan M Kleiman, Xieyining Huang, Katherine M Musacchio, Adam C Jaroszewski, Bernard P Chang, and Matthew K Nock.

</span>
<span class="ltx_bibblock">Risk factors for suicidal thoughts and behaviors: A meta-analysis of 50 years of research.

</span>
<span class="ltx_bibblock"><span id="bib.bib15.1.1" class="ltx_text ltx_font_italic">Psychological bulletin</span>, 143(2):187, 2017.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Kate H Bentley, Joseph C Franklin, Jessica D Ribeiro, Evan M Kleiman, Kathryn R Fox, and Matthew K Nock.

</span>
<span class="ltx_bibblock">Anxiety and its disorders as risk factors for suicidal thoughts and behaviors: A meta-analytic review.

</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text ltx_font_italic">Clinical psychology review</span>, 43:30–46, 2016.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Laura Orsolini, Roberto Latini, Maurizio Pompili, Gianluca Serafini, Umberto Volpe, Federica Vellante, Michele Fornaro, Alessandro Valchera, Carmine Tomasetti, Silvia Fraticelli, et al.

</span>
<span class="ltx_bibblock">Understanding the complex of suicide in depression: from research to clinics.

</span>
<span class="ltx_bibblock"><span id="bib.bib17.1.1" class="ltx_text ltx_font_italic">Psychiatry investigation</span>, 17(3):207, 2020.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Ned H Kalin.

</span>
<span class="ltx_bibblock">Insights into suicide and depression.

</span>
<span class="ltx_bibblock"><span id="bib.bib18.1.1" class="ltx_text ltx_font_italic">Am J Psychiatry</span>, pages 877–880, 2020.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Lucas da Silva Costa, Átila Pereira Alencar, Pedro Januário Nascimento Neto, Maria do Socorro Vieira dos Santos, Cláudio Gleidiston Lima da Silva, Sally de França Lacerda Pinheiro, Regiane Teixeira Silveira, Bianca Alves Vieira Bianco, Roberto Flávio Fontenelle Pinheiro Júnior, Marcos Antonio Pereira de Lima, et al.

</span>
<span class="ltx_bibblock">Risk factors for suicide in bipolar disorder: a systematic review.

</span>
<span class="ltx_bibblock"><span id="bib.bib19.1.1" class="ltx_text ltx_font_italic">Journal of affective disorders</span>, 170:237–254, 2015.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Joel Paris.

</span>
<span class="ltx_bibblock">Suicidality in borderline personality disorder.

</span>
<span class="ltx_bibblock"><span id="bib.bib20.1.1" class="ltx_text ltx_font_italic">Medicina</span>, 55(6):223, 2019.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Kyoung Hag Lee, Jung Sim Jun, Yi Jin Kim, Soonhee Roh, Sung Seek Moon, Ngoyi Bukonda, and Lisa Hines.

</span>
<span class="ltx_bibblock">Mental health, substance abuse, and suicide among homeless adults.

</span>
<span class="ltx_bibblock"><span id="bib.bib21.1.1" class="ltx_text ltx_font_italic">Journal of evidence-informed social work</span>, 14(4):229–242, 2017.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Chukwudi Okolie, Michael Dennis, Emily Simon Thomas, and Ann John.

</span>
<span class="ltx_bibblock">A systematic review of interventions to prevent suicidal behaviors and reduce suicidal ideation in older people.

</span>
<span class="ltx_bibblock"><span id="bib.bib22.1.1" class="ltx_text ltx_font_italic">International psychogeriatrics</span>, 29(11):1801–1824, 2017.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Evan M Kleiman, Brianna J Turner, Szymon Fedor, Eleanor E Beale, Jeff C Huffman, and Matthew K Nock.

</span>
<span class="ltx_bibblock">Examination of real-time fluctuations in suicidal ideation and its risk factors: Results from two ecological momentary assessment studies.

</span>
<span class="ltx_bibblock"><span id="bib.bib23.1.1" class="ltx_text ltx_font_italic">Journal of abnormal psychology</span>, 126(6):726, 2017.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Nicholas Leigh-Hunt, David Bagguley, Kristin Bash, Victoria Turner, Stephen Turnbull, Nicole Valtorta, and Woody Caan.

</span>
<span class="ltx_bibblock">An overview of systematic reviews on the public health consequences of social isolation and loneliness.

</span>
<span class="ltx_bibblock"><span id="bib.bib24.1.1" class="ltx_text ltx_font_italic">Public health</span>, 152:157–171, 2017.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Julianne Holt-Lunstad, Timothy B Smith, Mark Baker, Tyler Harris, and David Stephenson.

</span>
<span class="ltx_bibblock">Loneliness and social isolation as risk factors for mortality: a meta-analytic review.

</span>
<span class="ltx_bibblock"><span id="bib.bib25.1.1" class="ltx_text ltx_font_italic">Perspectives on psychological science</span>, 10(2):227–237, 2015.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
Adelyn Allchin, Vicka Chaplin, and Joshua Horwitz.

</span>
<span class="ltx_bibblock">Limiting access to lethal means: applying the social ecological model for firearm suicide prevention.

</span>
<span class="ltx_bibblock"><span id="bib.bib26.1.1" class="ltx_text ltx_font_italic">Injury prevention</span>, 25(Suppl 1):i44–i48, 2019.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Kimberly A Van Orden, Tracy K Witte, Kelly C Cukrowicz, Scott R Braithwaite, Edward A Selby, and Thomas E Joiner Jr.

</span>
<span class="ltx_bibblock">The interpersonal theory of suicide.

</span>
<span class="ltx_bibblock"><span id="bib.bib27.1.1" class="ltx_text ltx_font_italic">Psychological review</span>, 117(2):575, 2010.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Amy Wenzel and Aaron T Beck.

</span>
<span class="ltx_bibblock">A cognitive model of suicidal behavior: Theory and treatment.

</span>
<span class="ltx_bibblock"><span id="bib.bib28.1.1" class="ltx_text ltx_font_italic">Applied and preventive psychology</span>, 12(4):189–201, 2008.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
Robert J Cramer and Nestor D Kapusta.

</span>
<span class="ltx_bibblock">A social-ecological framework of theory, assessment, and prevention of suicide.

</span>
<span class="ltx_bibblock"><span id="bib.bib29.1.1" class="ltx_text ltx_font_italic">Frontiers in psychology</span>, 8:1756, 2017.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
Andrea C Fernandes, Rina Dutta, Sumithra Velupillai, Jyoti Sanyal, Robert Stewart, and David Chandran.

</span>
<span class="ltx_bibblock">Identifying suicide ideation and suicidal attempts in a psychiatric clinical research database using natural language processing.

</span>
<span class="ltx_bibblock"><span id="bib.bib30.1.1" class="ltx_text ltx_font_italic">Scientific reports</span>, 8(1):7426, 2018.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
Cosmin A Bejan, Michael Ripperger, Drew Wilimitis, Ryan Ahmed, JooEun Kang, Katelyn Robinson, Theodore J Morley, Douglas M Ruderfer, and Colin G Walsh.

</span>
<span class="ltx_bibblock">Improving ascertainment of suicidal ideation and suicide attempt with natural language processing.

</span>
<span class="ltx_bibblock"><span id="bib.bib31.1.1" class="ltx_text ltx_font_italic">Scientific reports</span>, 12(1):15146, 2022.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
M Johnson Vioules, Bilel Moulahi, Jérôme Azé, and Sandra Bringay.

</span>
<span class="ltx_bibblock">Detection of suicide-related posts in twitter data streams.

</span>
<span class="ltx_bibblock"><span id="bib.bib32.1.1" class="ltx_text ltx_font_italic">IBM Journal of Research and Development</span>, 62(1):7–1, 2018.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
Robert C Hsiung.

</span>
<span class="ltx_bibblock">A suicide in an online mental health support group: reactions of the group members, administrative responses, and recommendations.

</span>
<span class="ltx_bibblock"><span id="bib.bib33.1.1" class="ltx_text ltx_font_italic">CyberPsychology &amp; Behavior</span>, 10(4):495–500, 2007.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
Jared Jashinsky, Scott H Burton, Carl L Hanson, Josh West, Christophe Giraud-Carrier, Michael D Barnes, and Trenton Argyle.

</span>
<span class="ltx_bibblock">Tracking suicide risk factors through twitter in the us.

</span>
<span class="ltx_bibblock"><span id="bib.bib34.1.1" class="ltx_text ltx_font_italic">Crisis</span>, 2014.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
Gualtiero B Colombo, Pete Burnap, Andrei Hodorog, and Jonathan Scourfield.

</span>
<span class="ltx_bibblock">Analysing the connectivity and communication of suicidal users on twitter.

</span>
<span class="ltx_bibblock"><span id="bib.bib35.1.1" class="ltx_text ltx_font_italic">Computer communications</span>, 73:291–300, 2016.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
Hamideh Ghanadian, Isar Nejadgholi, and Hussein Al Osman.

</span>
<span class="ltx_bibblock">Chatgpt for suicide risk assessment on social media: Quantitative evaluation of model performance, potentials and limitations.

</span>
<span class="ltx_bibblock"><span id="bib.bib36.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2306.09390</span>, 2023.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
Kailai Yang, Shaoxiong Ji, Tianlin Zhang, Qianqian Xie, and Sophia Ananiadou.

</span>
<span class="ltx_bibblock">On the evaluations of chatgpt and emotion-enhanced prompting for mental health analysis.

</span>
<span class="ltx_bibblock"><span id="bib.bib37.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2304.03347</span>, 2023.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
Pradyumna Prakhar Sinha, Rohan Mishra, Ramit Sawhney, Debanjan Mahata, Rajiv Ratn Shah, and Huan Liu.

</span>
<span class="ltx_bibblock"># suicidal-a multipronged approach to identify and explore suicidal ideation in twitter.

</span>
<span class="ltx_bibblock">In <span id="bib.bib38.1.1" class="ltx_text ltx_font_italic">Proceedings of the 28th ACM international conference on information and knowledge management</span>, pages 941–950, 2019.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
Manas Gaur, Amanuel Alambo, Joy Prakash Sain, Ugur Kursuncu, Krishnaprasad Thirunarayan, Ramakanth Kavuluru, Amit Sheth, Randy Welton, and Jyotishman Pathak.

</span>
<span class="ltx_bibblock">Knowledge-aware assessment of severity of suicide risk for early intervention.

</span>
<span class="ltx_bibblock">In <span id="bib.bib39.1.1" class="ltx_text ltx_font_italic">The world wide web conference</span>, pages 514–525, 2019.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
Ayah Zirikly, Philip Resnik, Özlem Uzuner, and Kristy Hollingshead.

</span>
<span class="ltx_bibblock">CLPsych 2019 shared task: Predicting the degree of suicide risk in Reddit posts.

</span>
<span class="ltx_bibblock">In <span id="bib.bib40.1.1" class="ltx_text ltx_font_italic">Proceedings of the Sixth Workshop on Computational Linguistics and Clinical Psychology</span>, June 2019.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
Han-Chin Shing, Suraj Nair, Ayah Zirikly, Meir Friedenberg, Hal Daumé III, and Philip Resnik.

</span>
<span class="ltx_bibblock">Expert, crowdsourced, and machine assessment of suicide risk via online postings.

</span>
<span class="ltx_bibblock">In <span id="bib.bib41.1.1" class="ltx_text ltx_font_italic">Proceedings of the Fifth Workshop on Computational Linguistics and Clinical Psychology: From Keyboard to Clinic</span>, pages 25–36, 2018.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
Xuanli He, Islam Nassar, Jamie Kiros, Gholamreza Haffari, and Mohammad Norouzi.

</span>
<span class="ltx_bibblock">Generate, annotate, and learn: NLP with synthetic text.

</span>
<span class="ltx_bibblock"><span id="bib.bib42.1.1" class="ltx_text ltx_font_italic">Transactions of the Association for Computational Linguistics</span>, 10:826–842, 2022.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
Ahmad Rashid, Vasileios Lioutas, and Mehdi Rezagholizadeh.

</span>
<span class="ltx_bibblock">Mate-kd: Masked adversarial text, a companion to knowledge distillation.

</span>
<span class="ltx_bibblock"><span id="bib.bib43.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2105.05912</span>, 2021.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
Luiz Bonifacio, Hugo Abonizio, Marzieh Fadaee, and Rodrigo Nogueira.

</span>
<span class="ltx_bibblock">Inpars: Unsupervised dataset generation for information retrieval.

</span>
<span class="ltx_bibblock">In <span id="bib.bib44.1.1" class="ltx_text ltx_font_italic">Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval</span>, pages 2387–2392, 2022.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
Julie Boergers, Anthony Spirito, and Deidre Donaldson.

</span>
<span class="ltx_bibblock">Reasons for adolescent suicide attempts: Associations with psychological functioning.

</span>
<span class="ltx_bibblock"><span id="bib.bib45.1.1" class="ltx_text ltx_font_italic">Journal of the American Academy of Child &amp; Adolescent Psychiatry</span>, 37(12):1287–1293, 1998.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
E David Klonsky, Alexis M May, and Boaz Y Saffer.

</span>
<span class="ltx_bibblock">Suicide, suicide attempts, and suicidal ideation.

</span>
<span class="ltx_bibblock"><span id="bib.bib46.1.1" class="ltx_text ltx_font_italic">Annual review of clinical psychology</span>, 12:307–330, 2016.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
Rúnar Vilhjálmsson, E Sveinbjarnardottir, and G Kristjansdottir.

</span>
<span class="ltx_bibblock">Factors associated with suicide ideation in adults.

</span>
<span class="ltx_bibblock"><span id="bib.bib47.1.1" class="ltx_text ltx_font_italic">Social psychiatry and psychiatric epidemiology</span>, 33:97–103, 1998.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
Cristina Lázaro-Pérez, Pilar Munuera Gómez, José Ángel Martínez-López, and José Gómez-Galán.

</span>
<span class="ltx_bibblock">Predictive factors of suicidal ideation in spanish university students: a health, preventive, social, and cultural approach.

</span>
<span class="ltx_bibblock"><span id="bib.bib48.1.1" class="ltx_text ltx_font_italic">Journal of clinical medicine</span>, 12(3):1207, 2023.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
Jia-In Lee, Ming-Been Lee, Shih-Cheng Liao, Chia-Ming Chang, Suz-Chieh Sung, Hung-Chi Chiang, and Chuan-Wan Tai.

</span>
<span class="ltx_bibblock">Prevalence of suicidal ideation and associated risk factors in the general population.

</span>
<span class="ltx_bibblock"><span id="bib.bib49.1.1" class="ltx_text ltx_font_italic">Journal of the Formosan Medical Association</span>, 109(2):138–147, 2010.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
Amy Farabaugh, Stella Bitran, Maren Nyer, Daphne J Holt, Paola Pedrelli, Irene Shyu, Steven D Hollon, Sidney Zisook, Lee Baer, Wilma Busse, et al.

</span>
<span class="ltx_bibblock">Depression and suicidal ideation in college students.

</span>
<span class="ltx_bibblock"><span id="bib.bib50.1.1" class="ltx_text ltx_font_italic">Psychopathology</span>, 45(4):228–234, 2012.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
John R Peteet, Guy Maytal, and Haleh Rokni.

</span>
<span class="ltx_bibblock">Unimaginable loss: contingent suicidal ideation in family members of oncology patients.

</span>
<span class="ltx_bibblock"><span id="bib.bib51.1.1" class="ltx_text ltx_font_italic">Psychosomatics</span>, 51(2):166–170, 2010.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
Katarzyna Anna Ratkowska and Diego De Leo.

</span>
<span class="ltx_bibblock">Suicide in immigrants: An overview.

</span>
<span class="ltx_bibblock">2013.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
Joseph D Hovey.

</span>
<span class="ltx_bibblock">Acculturative stress, depression, and suicidal ideation in mexican immigrants.

</span>
<span class="ltx_bibblock"><span id="bib.bib53.1.1" class="ltx_text ltx_font_italic">Cultural Diversity and Ethnic Minority Psychology</span>, 6(2):134, 2000.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock">
Brian TaeHyuk Keum, Michele J Wong, and Rangeena Salim-Eissa.

</span>
<span class="ltx_bibblock">Gendered racial microaggressions, internalized racism, and suicidal ideation among emerging adult asian american women.

</span>
<span class="ltx_bibblock"><span id="bib.bib54.1.1" class="ltx_text ltx_font_italic">International journal of social psychiatry</span>, 69(2):342–350, 2023.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin.

</span>
<span class="ltx_bibblock">Attention is all you need.

</span>
<span class="ltx_bibblock"><span id="bib.bib55.1.1" class="ltx_text ltx_font_italic">Advances in neural information processing systems</span>, 30:5–8, 2017.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock">
Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, et al.

</span>
<span class="ltx_bibblock">Transformers: State-of-the-art natural language processing.

</span>
<span class="ltx_bibblock">In <span id="bib.bib56.1.1" class="ltx_text ltx_font_italic">Proceedings of the 2020 conference on empirical methods in natural language processing: system demonstrations</span>, pages 38–45, 2020.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock">
Renqian Luo, Liai Sun, Yingce Xia, Tao Qin, Sheng Zhang, Hoifung Poon, and Tie-Yan Liu.

</span>
<span class="ltx_bibblock">Biogpt: generative pre-trained transformer for biomedical text generation and mining.

</span>
<span class="ltx_bibblock"><span id="bib.bib57.1.1" class="ltx_text ltx_font_italic">Briefings in Bioinformatics</span>, 23(6):bbac409, 2022.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock">
Xin Xie, Ningyu Zhang, Zhoubo Li, Shumin Deng, Hui Chen, Feiyu Xiong, Mosha Chen, and Huajun Chen.

</span>
<span class="ltx_bibblock">From discrimination to generation: Knowledge graph completion with generative transformer.

</span>
<span class="ltx_bibblock">In <span id="bib.bib58.1.1" class="ltx_text ltx_font_italic">Companion Proceedings of the Web Conference 2022</span>, pages 162–165, 2022.

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock">
Fei Mi, Yitong Li, Yulong Zeng, Jingyan Zhou, Yasheng Wang, Chuanfei Xu, Lifeng Shang, Xin Jiang, Shiqi Zhao, and Qun Liu.

</span>
<span class="ltx_bibblock">Pangu-bot: Efficient generative dialogue pre-training from pre-trained language model.

</span>
<span class="ltx_bibblock"><span id="bib.bib59.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2203.17090</span>, 2022.

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock">
Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et al.

</span>
<span class="ltx_bibblock">Scaling instruction-finetuned language models.

</span>
<span class="ltx_bibblock"><span id="bib.bib60.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2210.11416</span>, 2022.

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock">
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al.

</span>
<span class="ltx_bibblock">Llama 2: Open foundation and fine-tuned chat models.

</span>
<span class="ltx_bibblock"><span id="bib.bib61.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2307.09288</span>, 2023.

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[62]</span>
<span class="ltx_bibblock">
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.

</span>
<span class="ltx_bibblock">Bert: Pre-training of deep bidirectional transformers for language understanding.

</span>
<span class="ltx_bibblock"><span id="bib.bib62.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1810.04805</span>, 2018.

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[63]</span>
<span class="ltx_bibblock">
Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, and Radu Soricut.

</span>
<span class="ltx_bibblock">Albert: A lite bert for self-supervised learning of language representations.

</span>
<span class="ltx_bibblock"><span id="bib.bib63.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1909.11942</span>, 2019.

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[64]</span>
<span class="ltx_bibblock">
Victor Sanh, Lysandre Debut, Julien Chaumond, and Thomas Wolf.

</span>
<span class="ltx_bibblock">Distilbert, a distilled version of bert: smaller, faster, cheaper and lighter.

</span>
<span class="ltx_bibblock"><span id="bib.bib64.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1910.01108</span>, 2019.

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[65]</span>
<span class="ltx_bibblock">
Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, et al.

</span>
<span class="ltx_bibblock">Huggingface’s transformers: State-of-the-art natural language processing.

</span>
<span class="ltx_bibblock"><span id="bib.bib65.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1910.03771</span>, 2019.

</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[66]</span>
<span class="ltx_bibblock">
Marina Sokolova and Guy Lapalme.

</span>
<span class="ltx_bibblock">A systematic analysis of performance measures for classification tasks.

</span>
<span class="ltx_bibblock"><span id="bib.bib66.1.1" class="ltx_text ltx_font_italic">Information processing &amp; management</span>, 45(4):427–437, 2009.

</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[67]</span>
<span class="ltx_bibblock">
Yejin Bang, Samuel Cahyawijaya, Nayeon Lee, Wenliang Dai, Dan Su, Bryan Wilie, Holy Lovenia, Ziwei Ji, Tiezheng Yu, Willy Chung, et al.

</span>
<span class="ltx_bibblock">A multitask, multilingual, multimodal evaluation of chatgpt on reasoning, hallucination, and interactivity.

</span>
<span class="ltx_bibblock"><span id="bib.bib67.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2302.04023</span>, 2023.

</span>
</li>
</ul>
</section>
<figure id="id1" class="ltx_float biography">
<table id="id1.1" class="ltx_tabular">
<tr id="id1.1.1" class="ltx_tr">
<td id="id1.1.1.1" class="ltx_td"><img src="/html/2402.01712/assets/Hamideh-Ghanadian.jpg" id="id1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="100" height="100" alt="[Uncaptioned image]"></td>
<td id="id1.1.1.2" class="ltx_td">
<span id="id1.1.1.2.1" class="ltx_inline-block">
<span id="id1.1.1.2.1.1" class="ltx_p"><span id="id1.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Hamideh Ghanadian</span>  is Ph.D. Candidate in Electrical Engineering and Computer Science at the University of Ottawa. She also completed her MASc degree in Electrical Engineering and Computer Science at the University of Ottawa in 2018. Her research focuses on Natural Language Processing,
Applied Machine Learning, Social Media Processing and explainability of AI systems. Her work particularly focuses on the application of natural language processing techniques on suicide and mental health detection on social media platforms and exploring the ways in which NLP can be used to better understand human psychology.</span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="id2" class="ltx_float biography">
<table id="id2.1" class="ltx_tabular">
<tr id="id2.1.1" class="ltx_tr">
<td id="id2.1.1.1" class="ltx_td"><img src="/html/2402.01712/assets/Isar-Nejadgholi.jpg" id="id2.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="100" height="125" alt="[Uncaptioned image]"></td>
<td id="id2.1.1.2" class="ltx_td">
<span id="id2.1.1.2.1" class="ltx_inline-block">
<span id="id2.1.1.2.1.1" class="ltx_p"><span id="id2.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Isar Nejadgholi</span>  is a senior research scientist at the National Research Council Canada and an adjunct professor at the University of Ottawa. She completed her PhD in Artificial Intelligence at the AmirKabir University of Technology, Iran and her postdoctoral studies at the University of Ottawa, Canada, in 2016. Her research interests include machine learning applications, particularly natural language processing, social media data analysis and medical text processing. Her work also focuses on responsible AI, specifically on evaluating and improving the transparency and fairness of natural language processing systems.</span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="id3" class="ltx_float biography">
<table id="id3.1" class="ltx_tabular">
<tr id="id3.1.1" class="ltx_tr">
<td id="id3.1.1.1" class="ltx_td"><img src="/html/2402.01712/assets/hussein.png" id="id3.1.1.1.g1" class="ltx_graphics ltx_img_square" width="100" height="101" alt="[Uncaptioned image]"></td>
<td id="id3.1.1.2" class="ltx_td">
<span id="id3.1.1.2.1" class="ltx_inline-block">
<span id="id3.1.1.2.1.1" class="ltx_p"><span id="id3.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Hussein Al Osman</span> 
is an Associate Professor at the School of Electrical Engineering and Computer Science at the University of Ottawa. He completed his Ph.D. in Electrical and Computer Engineering at the University of Ottawa in 2014. He leads the Multimedia Processing and Interaction group and is a member of the Multimedia Computing and the Distributed and Collaborative Virtual Environments Research laboratories. His research focuses on the application of artificial intelligence in affective computing and biomedical engineering. In particular, he is interested in the development of multi-modal affect recognition methods using deep artificial neural networks to estimate facial expressions and speech sentiment. He studies remote physiological signal measurement using video signals and applies this technology to biomedical and Human-Computer Interaction (HCI) applications. He conducts research in HCI, especially the development of serious games intended for physical rehabilitation and education.</span>
</span>
</td>
</tr>
</table>
</figure>
<div id="p4" class="ltx_para">
<span id="p4.1" class="ltx_ERROR undefined">\EOD</span>
</div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2402.01711" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2402.01712" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2402.01712">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2402.01712" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2402.01713" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Tue Mar  5 15:48:02 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
