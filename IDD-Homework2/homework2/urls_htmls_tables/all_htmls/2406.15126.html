<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2406.15126] On LLMs-Driven Synthetic Data Generation, Curation, and Evaluation: A Survey</title><meta property="og:description" content="Within the evolving landscape of deep learning, the dilemma of data quantity and quality has been a long-standing problem. The recent advent of Large Language Models (LLMs) offers a data-centric solution to alleviate tâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="On LLMs-Driven Synthetic Data Generation, Curation, and Evaluation: A Survey">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="On LLMs-Driven Synthetic Data Generation, Curation, and Evaluation: A Survey">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2406.15126">

<!--Generated on Fri Jul  5 17:46:49 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">On LLMs-Driven Synthetic Data Generation, Curation, 
<br class="ltx_break">and Evaluation: A Survey</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Lin Long<sup id="id10.10.id1" class="ltx_sup">1</sup>, Rui Wang<sup id="id11.11.id2" class="ltx_sup">1</sup>, Ruixuan Xiao<sup id="id12.12.id3" class="ltx_sup">1</sup> 
<br class="ltx_break"><span id="id7.7.4" class="ltx_text ltx_font_bold">Junbo Zhao<sup id="id7.7.4.1" class="ltx_sup"><span id="id7.7.4.1.1" class="ltx_text ltx_font_medium">1</span></sup>, Xiao Ding<sup id="id7.7.4.2" class="ltx_sup"><span id="id7.7.4.2.1" class="ltx_text ltx_font_medium">2</span></sup>, Gang Chen<sup id="id7.7.4.3" class="ltx_sup"><span id="id7.7.4.3.1" class="ltx_text ltx_font_medium">1</span></sup>, Haobo Wang<sup id="id7.7.4.4" class="ltx_sup"><span id="id7.7.4.4.1" class="ltx_text ltx_font_medium">1</span></sup></span> 
<br class="ltx_break"><sup id="id13.13.id4" class="ltx_sup">1</sup>Zhejiang University, China â€ƒ<sup id="id14.14.id5" class="ltx_sup">2</sup>Harbin
Institute of Technology, China 
<br class="ltx_break"><span id="id15.15.id6" class="ltx_text ltx_font_italic">Correspondence</span>: <span id="id16.16.id7" class="ltx_text ltx_font_typewriter">wanghaobo@zju.edu.cn</span>
</span><span class="ltx_author_notes"><span id="id17.17.id1" class="ltx_text ltx_font_bold">Corresponding author.</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id18.id1" class="ltx_p">Within the evolving landscape of deep learning, the dilemma of data quantity and quality has been a long-standing problem. The recent advent of Large Language Models (LLMs) offers a data-centric solution to alleviate the limitations of real-world data with synthetic data generation. However, current investigations into this field lack a unified framework and mostly stay on the surface. Therefore, this paper provides an organization of relevant studies based on a generic workflow of synthetic data generation. By doing so, we highlight the gaps within existing research and outline prospective avenues for future study. This work aims to shepherd the academic and industrial communities towards deeper, more methodical inquiries into the capabilities and applications of LLMs-driven synthetic data generation.</p>
</div>
<div id="p1" class="ltx_para ltx_noindent">
<div id="p1.9" class="ltx_block ltx_align_bottom">
<p id="p1.9.10" class="ltx_p"><span id="p1.9.10.1" class="ltx_text ltx_font_bold">On LLMs-Driven Synthetic Data Generation, Curation, 
<br class="ltx_break">and Evaluation: A Survey</span></p>
<br class="ltx_break ltx_centering">
<p id="p1.9.9" class="ltx_p ltx_align_center" style="width:433.6pt;"><span id="p1.9.9.9" class="ltx_text ltx_inline-block" style="width:0.0pt;">
<span id="p1.9.9.9.9" class="ltx_tabular ltx_align_top">
<span class="ltx_tbody">
<span id="p1.3.3.3.3.3" class="ltx_tr">
<span id="p1.3.3.3.3.3.3" class="ltx_td ltx_align_center"><span id="p1.3.3.3.3.3.3.3" class="ltx_text ltx_font_bold">Lin Long<sup id="p1.3.3.3.3.3.3.3.1" class="ltx_sup"><span id="p1.3.3.3.3.3.3.3.1.1" class="ltx_text ltx_font_medium">1</span></sup>, Rui Wang<sup id="p1.3.3.3.3.3.3.3.2" class="ltx_sup"><span id="p1.3.3.3.3.3.3.3.2.1" class="ltx_text ltx_font_medium">1</span></sup>, Ruixuan Xiao<sup id="p1.3.3.3.3.3.3.3.3" class="ltx_sup"><span id="p1.3.3.3.3.3.3.3.3.1" class="ltx_text ltx_font_medium">1</span></sup></span></span></span>
<span id="p1.7.7.7.7.7" class="ltx_tr">
<span id="p1.7.7.7.7.7.4" class="ltx_td ltx_align_center"><span id="p1.7.7.7.7.7.4.4" class="ltx_text ltx_font_bold">Junbo Zhao<sup id="p1.7.7.7.7.7.4.4.1" class="ltx_sup"><span id="p1.7.7.7.7.7.4.4.1.1" class="ltx_text ltx_font_medium">1</span></sup>, Xiao Ding<sup id="p1.7.7.7.7.7.4.4.2" class="ltx_sup"><span id="p1.7.7.7.7.7.4.4.2.1" class="ltx_text ltx_font_medium">2</span></sup>, Gang Chen<sup id="p1.7.7.7.7.7.4.4.3" class="ltx_sup"><span id="p1.7.7.7.7.7.4.4.3.1" class="ltx_text ltx_font_medium">1</span></sup>, Haobo Wang<sup id="p1.7.7.7.7.7.4.4.4" class="ltx_sup"><span id="p1.7.7.7.7.7.4.4.4.1" class="ltx_text ltx_font_medium">1</span></sup><span id="p1.7.7.7.7.7.4.4.5" class="ltx_note ltx_role_thanks"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">thanks: </span>Corresponding author.</span></span></span></span></span></span>
<span id="p1.9.9.9.9.9" class="ltx_tr">
<span id="p1.9.9.9.9.9.2" class="ltx_td ltx_align_center"><sup id="p1.9.9.9.9.9.2.1" class="ltx_sup">1</sup>Zhejiang University, China â€ƒ<sup id="p1.9.9.9.9.9.2.2" class="ltx_sup">2</sup>Harbin
Institute of Technology, China</span></span>
<span id="p1.9.9.9.9.10.1" class="ltx_tr">
<span id="p1.9.9.9.9.10.1.1" class="ltx_td ltx_align_center"><span id="p1.9.9.9.9.10.1.1.1" class="ltx_text ltx_font_italic">Correspondence</span>: <span id="p1.9.9.9.9.10.1.1.2" class="ltx_text ltx_font_typewriter">wanghaobo@zju.edu.cn</span></span></span>
</span>
</span></span></p>
<br class="ltx_break ltx_centering">
</div>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">The game-changing emergence of Large Language Models (LLMs) instigated a significant paradigm shift in the field of deep learningÂ <cite class="ltx_cite ltx_citemacro_cite">Zhang etÂ al. (<a href="#bib.bib108" title="" class="ltx_ref">2023a</a>); Guo etÂ al. (<a href="#bib.bib25" title="" class="ltx_ref">2023</a>); Bang etÂ al. (<a href="#bib.bib3" title="" class="ltx_ref">2023</a>)</cite>.
Despite these advancements, a large amount of high-quality data remains the foundation for building robust NLP modelsÂ <cite class="ltx_cite ltx_citemacro_cite">Gandhi etÂ al. (<a href="#bib.bib19" title="" class="ltx_ref">2024</a>)</cite>. To be more specific, here high-quality data typically refers to diverse data that carries rich supervision signals (generally in the form of labels) closely aligned with human intent.
However, fulfilling such data reliance with human data can be challenging or even unrealistic sometimes, due to high costs, data scarcity, privacy concerns, etc. <cite class="ltx_cite ltx_citemacro_cite">Kurakin etÂ al. (<a href="#bib.bib43" title="" class="ltx_ref">2023</a>)</cite>. Moreover, several studiesÂ <cite class="ltx_cite ltx_citemacro_cite">Hosking etÂ al. (<a href="#bib.bib34" title="" class="ltx_ref">2023</a>); Singh etÂ al. (<a href="#bib.bib76" title="" class="ltx_ref">2023</a>); Gilardi etÂ al. (<a href="#bib.bib23" title="" class="ltx_ref">2023</a>)</cite> have highlighted that human-generated data, being inherently susceptible to biases and errors, may not even be optimal for model training or evaluation. These considerations necessitate a more serious inquiry into the question: are there other more <span id="S1.p1.1.1" class="ltx_text ltx_font_italic">effective and scalable</span> methods of data collection that can overcome the current limitations?</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Given the recent advancements in LLMs, which demonstrate the capability to generate fluent text on par with human outputÂ <cite class="ltx_cite ltx_citemacro_cite">Hartvigsen etÂ al. (<a href="#bib.bib28" title="" class="ltx_ref">2022</a>); Sahu etÂ al. (<a href="#bib.bib72" title="" class="ltx_ref">2022</a>); Ye etÂ al. (<a href="#bib.bib101" title="" class="ltx_ref">2022a</a>); Tang etÂ al. (<a href="#bib.bib82" title="" class="ltx_ref">2023</a>); Gao etÂ al. (<a href="#bib.bib20" title="" class="ltx_ref">2023a</a>)</cite>, synthetic data produced by LLMs emerges as a viable alternative or supplement to human-generated data. Specifically, synthetic data is designed to mimic the characteristics and patterns of real-world dataÂ <cite class="ltx_cite ltx_citemacro_cite">Liu etÂ al. (<a href="#bib.bib55" title="" class="ltx_ref">2024</a>)</cite>. On the one hand, LLMs, through extensive pretraining, have acquired a vast repository of knowledge and demonstrate exceptional linguistic comprehensionÂ <cite class="ltx_cite ltx_citemacro_cite">Kim etÂ al. (<a href="#bib.bib40" title="" class="ltx_ref">2022</a>); Ding etÂ al. (<a href="#bib.bib14" title="" class="ltx_ref">2023a</a>)</cite>, which forms a foundation for generating faithful data. On the other hand, the profound instruction-following capabilities of LLMs allow better controllability and adaptability over the generation process, facilitating the creation of tailored datasets for specific applications with more flexible process designsÂ <cite class="ltx_cite ltx_citemacro_cite">Eldan and Li (<a href="#bib.bib16" title="" class="ltx_ref">2023</a>)</cite>. These two advantages make LLMs highly promising synthetic data generators.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2406.15126/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="257" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Illustration of the LLMs-based application ecosystem, where synthetic data serves as the flowing nutrients for fruiting (training of small LMs or fine-tuning task-specific LLMs) and rooting (training stronger LLMs or self-improvement).</figcaption>
</figure>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">As a pivotal application of LLMs, synthetic data generation holds significant importance for the development of deep learning. As shown in FigureÂ <a href="#S1.F1" title="Figure 1 â€£ 1 Introduction â€£ On LLMs-Driven Synthetic Data Generation, Curation, and Evaluation: A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>,
LLMs-driven synthetic data generationÂ <cite class="ltx_cite ltx_citemacro_cite">Li etÂ al. (<a href="#bib.bib50" title="" class="ltx_ref">2023c</a>); Wang etÂ al. (<a href="#bib.bib88" title="" class="ltx_ref">2021</a>); Seedat etÂ al. (<a href="#bib.bib73" title="" class="ltx_ref">2023</a>)</cite> enables the automation of the entire model training and evaluation process with minimal human participation required in the loopÂ <cite class="ltx_cite ltx_citemacro_cite">Huang etÂ al. (<a href="#bib.bib36" title="" class="ltx_ref">2023</a>)</cite>, which allows the advantages of deep learning models to be applied across a broader range of applications. Beyond providing a scalable supply of training and testing data, LLM-driven synthetic data generation also may pave the way for developing next-generation LLMs. Insights from TinyStoriesÂ <cite class="ltx_cite ltx_citemacro_cite">Eldan and Li (<a href="#bib.bib16" title="" class="ltx_ref">2023</a>)</cite> and the <span id="S1.p3.1.1" class="ltx_text ltx_font_italic">Phi</span> seriesÂ <cite class="ltx_cite ltx_citemacro_cite">Gunasekar etÂ al. (<a href="#bib.bib24" title="" class="ltx_ref">2023</a>); Li etÂ al. (<a href="#bib.bib49" title="" class="ltx_ref">2023b</a>)</cite> emphasize that data quality is crucial for effective model learning, while LLMs empower us to actively â€œdesignâ€ what the models learn through data manipulation, significantly enhancing the efficacy and controllability of model training.
As of June 2024, there are over <math id="S1.p3.1.m1.1" class="ltx_Math" alttext="300" display="inline"><semantics id="S1.p3.1.m1.1a"><mn id="S1.p3.1.m1.1.1" xref="S1.p3.1.m1.1.1.cmml">300</mn><annotation-xml encoding="MathML-Content" id="S1.p3.1.m1.1b"><cn type="integer" id="S1.p3.1.m1.1.1.cmml" xref="S1.p3.1.m1.1.1">300</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.p3.1.m1.1c">300</annotation></semantics></math> datasets on Hugging Face<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a href="h" title="" class="ltx_ref ltx_url ltx_font_typewriter">h</a>ttps://huggingface.co</span></span></span> that are tagged as â€œsyntheticâ€, with many mainstream LLMs leveraging high-quality synthetic data for training, including AlpacaÂ <cite class="ltx_cite ltx_citemacro_cite">Taori etÂ al. (<a href="#bib.bib83" title="" class="ltx_ref">2023</a>)</cite>, VicunaÂ <cite class="ltx_cite ltx_citemacro_cite">Zheng etÂ al. (<a href="#bib.bib114" title="" class="ltx_ref">2023</a>)</cite>, OpenHermes 2.5, and Openchat 3.5Â <cite class="ltx_cite ltx_citemacro_cite">Wang etÂ al. (<a href="#bib.bib86" title="" class="ltx_ref">2023a</a>)</cite>.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Though seemingly straightforward,
generating synthetic datasets that simultaneously have high correctness and sufficient diversity requires careful process designs and involves a lot of tricksÂ <cite class="ltx_cite ltx_citemacro_cite">Gandhi etÂ al. (<a href="#bib.bib19" title="" class="ltx_ref">2024</a>)</cite>,
making LLMs-driven synthetic data generation a non-trivial problem. While most existing works generally target data generation for various tasks (e.g., pre-trainingÂ <cite class="ltx_cite ltx_citemacro_cite">Gunasekar etÂ al. (<a href="#bib.bib24" title="" class="ltx_ref">2023</a>); Li etÂ al. (<a href="#bib.bib49" title="" class="ltx_ref">2023b</a>); Eldan and Li (<a href="#bib.bib16" title="" class="ltx_ref">2023</a>)</cite>, fine-tuningÂ <cite class="ltx_cite ltx_citemacro_cite">Mukherjee etÂ al. (<a href="#bib.bib63" title="" class="ltx_ref">2023</a>); Mitra etÂ al. (<a href="#bib.bib62" title="" class="ltx_ref">2023</a>); Xu etÂ al. (<a href="#bib.bib99" title="" class="ltx_ref">2023a</a>)</cite>, evaluationÂ <cite class="ltx_cite ltx_citemacro_cite">Feng etÂ al. (<a href="#bib.bib18" title="" class="ltx_ref">2023</a>); Wei etÂ al. (<a href="#bib.bib95" title="" class="ltx_ref">2024</a>)</cite>) across different domains (e.g., mathÂ <cite class="ltx_cite ltx_citemacro_cite">Yu etÂ al. (<a href="#bib.bib105" title="" class="ltx_ref">2023a</a>); Luo etÂ al. (<a href="#bib.bib57" title="" class="ltx_ref">2023a</a>)</cite>, codeÂ <cite class="ltx_cite ltx_citemacro_cite">Luo etÂ al. (<a href="#bib.bib58" title="" class="ltx_ref">2023b</a>); Wei etÂ al. (<a href="#bib.bib96" title="" class="ltx_ref">2023b</a>)</cite>, instructionÂ <cite class="ltx_cite ltx_citemacro_cite">Honovich etÂ al. (<a href="#bib.bib32" title="" class="ltx_ref">2023a</a>); Wang etÂ al. (<a href="#bib.bib90" title="" class="ltx_ref">2023d</a>)</cite>), they share many common ideas. To address the lack of a unified framework in the emerging field of LLM-driven synthetic data generation and develop a general workflow, this survey investigates recent studies and organizes them according to the topics of generation, curation, and evaluation, which are closely related, as shown in FigureÂ <a href="#S2.F2" title="Figure 2 â€£ 2.1 Problem Definition â€£ 2 Preliminaries â€£ On LLMs-Driven Synthetic Data Generation, Curation, and Evaluation: A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. Our primary aim is to provide a comprehensive overview of the current state of the field, identify key areas of focus, and highlight the gaps that remain to be addressed. We hope to bring insights to both the academic and industrial communities and drive further development in LLM-driven synthetic data generation.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Preliminaries</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Problem Definition</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.3" class="ltx_p">In this paper, we investigate the challenge of generating high-quality synthetic data using pre-trained LLMs, denoted as <math id="S2.SS1.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{M}" display="inline"><semantics id="S2.SS1.p1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p1.1.m1.1.1" xref="S2.SS1.p1.1.m1.1.1.cmml">â„³</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.1.m1.1b"><ci id="S2.SS1.p1.1.m1.1.1.cmml" xref="S2.SS1.p1.1.m1.1.1">â„³</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.1.m1.1c">\mathcal{M}</annotation></semantics></math>. Rather than creating new datasets from scratch, in more cases, we perform data augmentation with a small number of seed samples or unlabeled inputs, which we denote uniformly as <math id="S2.SS1.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{D}_{\text{sup}}" display="inline"><semantics id="S2.SS1.p1.2.m2.1a"><msub id="S2.SS1.p1.2.m2.1.1" xref="S2.SS1.p1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p1.2.m2.1.1.2" xref="S2.SS1.p1.2.m2.1.1.2.cmml">ğ’Ÿ</mi><mtext id="S2.SS1.p1.2.m2.1.1.3" xref="S2.SS1.p1.2.m2.1.1.3a.cmml">sup</mtext></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.2.m2.1b"><apply id="S2.SS1.p1.2.m2.1.1.cmml" xref="S2.SS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.2.m2.1.1.1.cmml" xref="S2.SS1.p1.2.m2.1.1">subscript</csymbol><ci id="S2.SS1.p1.2.m2.1.1.2.cmml" xref="S2.SS1.p1.2.m2.1.1.2">ğ’Ÿ</ci><ci id="S2.SS1.p1.2.m2.1.1.3a.cmml" xref="S2.SS1.p1.2.m2.1.1.3"><mtext mathsize="70%" id="S2.SS1.p1.2.m2.1.1.3.cmml" xref="S2.SS1.p1.2.m2.1.1.3">sup</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.2.m2.1c">\mathcal{D}_{\text{sup}}</annotation></semantics></math>. Although optional for LLMs-driven synthetic data generation, <math id="S2.SS1.p1.3.m3.1" class="ltx_Math" alttext="\mathcal{D}_{\text{sup}}" display="inline"><semantics id="S2.SS1.p1.3.m3.1a"><msub id="S2.SS1.p1.3.m3.1.1" xref="S2.SS1.p1.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p1.3.m3.1.1.2" xref="S2.SS1.p1.3.m3.1.1.2.cmml">ğ’Ÿ</mi><mtext id="S2.SS1.p1.3.m3.1.1.3" xref="S2.SS1.p1.3.m3.1.1.3a.cmml">sup</mtext></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.3.m3.1b"><apply id="S2.SS1.p1.3.m3.1.1.cmml" xref="S2.SS1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.3.m3.1.1.1.cmml" xref="S2.SS1.p1.3.m3.1.1">subscript</csymbol><ci id="S2.SS1.p1.3.m3.1.1.2.cmml" xref="S2.SS1.p1.3.m3.1.1.2">ğ’Ÿ</ci><ci id="S2.SS1.p1.3.m3.1.1.3a.cmml" xref="S2.SS1.p1.3.m3.1.1.3"><mtext mathsize="70%" id="S2.SS1.p1.3.m3.1.1.3.cmml" xref="S2.SS1.p1.3.m3.1.1.3">sup</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.3.m3.1c">\mathcal{D}_{\text{sup}}</annotation></semantics></math> can typically provide valuable supporting information when available. Consequently, the overall generation task can be formulated as:</p>
<table id="S2.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E1.m1.2" class="ltx_Math" alttext="\mathcal{D}_{\text{gen}}\leftarrow\mathcal{M}_{p}(\mathcal{T},\mathcal{D}_{\text{sup}})\text{,}" display="block"><semantics id="S2.E1.m1.2a"><mrow id="S2.E1.m1.2.2" xref="S2.E1.m1.2.2.cmml"><msub id="S2.E1.m1.2.2.3" xref="S2.E1.m1.2.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E1.m1.2.2.3.2" xref="S2.E1.m1.2.2.3.2.cmml">ğ’Ÿ</mi><mtext id="S2.E1.m1.2.2.3.3" xref="S2.E1.m1.2.2.3.3a.cmml">gen</mtext></msub><mo stretchy="false" id="S2.E1.m1.2.2.2" xref="S2.E1.m1.2.2.2.cmml">â†</mo><mrow id="S2.E1.m1.2.2.1" xref="S2.E1.m1.2.2.1.cmml"><msub id="S2.E1.m1.2.2.1.3" xref="S2.E1.m1.2.2.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E1.m1.2.2.1.3.2" xref="S2.E1.m1.2.2.1.3.2.cmml">â„³</mi><mi id="S2.E1.m1.2.2.1.3.3" xref="S2.E1.m1.2.2.1.3.3.cmml">p</mi></msub><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.2.1.2" xref="S2.E1.m1.2.2.1.2.cmml">â€‹</mo><mrow id="S2.E1.m1.2.2.1.1.1" xref="S2.E1.m1.2.2.1.1.2.cmml"><mo stretchy="false" id="S2.E1.m1.2.2.1.1.1.2" xref="S2.E1.m1.2.2.1.1.2.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S2.E1.m1.1.1" xref="S2.E1.m1.1.1.cmml">ğ’¯</mi><mo id="S2.E1.m1.2.2.1.1.1.3" xref="S2.E1.m1.2.2.1.1.2.cmml">,</mo><msub id="S2.E1.m1.2.2.1.1.1.1" xref="S2.E1.m1.2.2.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E1.m1.2.2.1.1.1.1.2" xref="S2.E1.m1.2.2.1.1.1.1.2.cmml">ğ’Ÿ</mi><mtext id="S2.E1.m1.2.2.1.1.1.1.3" xref="S2.E1.m1.2.2.1.1.1.1.3a.cmml">sup</mtext></msub><mo stretchy="false" id="S2.E1.m1.2.2.1.1.1.4" xref="S2.E1.m1.2.2.1.1.2.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.2.1.2a" xref="S2.E1.m1.2.2.1.2.cmml">â€‹</mo><mtext id="S2.E1.m1.2.2.1.4" xref="S2.E1.m1.2.2.1.4a.cmml">,</mtext></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.2b"><apply id="S2.E1.m1.2.2.cmml" xref="S2.E1.m1.2.2"><ci id="S2.E1.m1.2.2.2.cmml" xref="S2.E1.m1.2.2.2">â†</ci><apply id="S2.E1.m1.2.2.3.cmml" xref="S2.E1.m1.2.2.3"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.3.1.cmml" xref="S2.E1.m1.2.2.3">subscript</csymbol><ci id="S2.E1.m1.2.2.3.2.cmml" xref="S2.E1.m1.2.2.3.2">ğ’Ÿ</ci><ci id="S2.E1.m1.2.2.3.3a.cmml" xref="S2.E1.m1.2.2.3.3"><mtext mathsize="70%" id="S2.E1.m1.2.2.3.3.cmml" xref="S2.E1.m1.2.2.3.3">gen</mtext></ci></apply><apply id="S2.E1.m1.2.2.1.cmml" xref="S2.E1.m1.2.2.1"><times id="S2.E1.m1.2.2.1.2.cmml" xref="S2.E1.m1.2.2.1.2"></times><apply id="S2.E1.m1.2.2.1.3.cmml" xref="S2.E1.m1.2.2.1.3"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.1.3.1.cmml" xref="S2.E1.m1.2.2.1.3">subscript</csymbol><ci id="S2.E1.m1.2.2.1.3.2.cmml" xref="S2.E1.m1.2.2.1.3.2">â„³</ci><ci id="S2.E1.m1.2.2.1.3.3.cmml" xref="S2.E1.m1.2.2.1.3.3">ğ‘</ci></apply><interval closure="open" id="S2.E1.m1.2.2.1.1.2.cmml" xref="S2.E1.m1.2.2.1.1.1"><ci id="S2.E1.m1.1.1.cmml" xref="S2.E1.m1.1.1">ğ’¯</ci><apply id="S2.E1.m1.2.2.1.1.1.1.cmml" xref="S2.E1.m1.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.1.1.1.1.1.cmml" xref="S2.E1.m1.2.2.1.1.1.1">subscript</csymbol><ci id="S2.E1.m1.2.2.1.1.1.1.2.cmml" xref="S2.E1.m1.2.2.1.1.1.1.2">ğ’Ÿ</ci><ci id="S2.E1.m1.2.2.1.1.1.1.3a.cmml" xref="S2.E1.m1.2.2.1.1.1.1.3"><mtext mathsize="70%" id="S2.E1.m1.2.2.1.1.1.1.3.cmml" xref="S2.E1.m1.2.2.1.1.1.1.3">sup</mtext></ci></apply></interval><ci id="S2.E1.m1.2.2.1.4a.cmml" xref="S2.E1.m1.2.2.1.4"><mtext id="S2.E1.m1.2.2.1.4.cmml" xref="S2.E1.m1.2.2.1.4">,</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.2c">\mathcal{D}_{\text{gen}}\leftarrow\mathcal{M}_{p}(\mathcal{T},\mathcal{D}_{\text{sup}})\text{,}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S2.SS1.p1.6" class="ltx_p">where <math id="S2.SS1.p1.4.m1.1" class="ltx_Math" alttext="\mathcal{D}_{\text{gen}}" display="inline"><semantics id="S2.SS1.p1.4.m1.1a"><msub id="S2.SS1.p1.4.m1.1.1" xref="S2.SS1.p1.4.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p1.4.m1.1.1.2" xref="S2.SS1.p1.4.m1.1.1.2.cmml">ğ’Ÿ</mi><mtext id="S2.SS1.p1.4.m1.1.1.3" xref="S2.SS1.p1.4.m1.1.1.3a.cmml">gen</mtext></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.4.m1.1b"><apply id="S2.SS1.p1.4.m1.1.1.cmml" xref="S2.SS1.p1.4.m1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.4.m1.1.1.1.cmml" xref="S2.SS1.p1.4.m1.1.1">subscript</csymbol><ci id="S2.SS1.p1.4.m1.1.1.2.cmml" xref="S2.SS1.p1.4.m1.1.1.2">ğ’Ÿ</ci><ci id="S2.SS1.p1.4.m1.1.1.3a.cmml" xref="S2.SS1.p1.4.m1.1.1.3"><mtext mathsize="70%" id="S2.SS1.p1.4.m1.1.1.3.cmml" xref="S2.SS1.p1.4.m1.1.1.3">gen</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.4.m1.1c">\mathcal{D}_{\text{gen}}</annotation></semantics></math> represents the final generated dataset, and <math id="S2.SS1.p1.5.m2.1" class="ltx_Math" alttext="p" display="inline"><semantics id="S2.SS1.p1.5.m2.1a"><mi id="S2.SS1.p1.5.m2.1.1" xref="S2.SS1.p1.5.m2.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.5.m2.1b"><ci id="S2.SS1.p1.5.m2.1.1.cmml" xref="S2.SS1.p1.5.m2.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.5.m2.1c">p</annotation></semantics></math> refers to the prompt used for model inference. <math id="S2.SS1.p1.6.m3.1" class="ltx_Math" alttext="\mathcal{T}" display="inline"><semantics id="S2.SS1.p1.6.m3.1a"><mi class="ltx_font_mathcaligraphic" id="S2.SS1.p1.6.m3.1.1" xref="S2.SS1.p1.6.m3.1.1.cmml">ğ’¯</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.6.m3.1b"><ci id="S2.SS1.p1.6.m3.1.1.cmml" xref="S2.SS1.p1.6.m3.1.1">ğ’¯</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.6.m3.1c">\mathcal{T}</annotation></semantics></math> specifies the generation task, such as rewriting, question answering, annotation, etc. Notably, data annotation as a specialized paradigm of synthetic data generation, has particularly extensive applicability, including RLAIFÂ <cite class="ltx_cite ltx_citemacro_cite">Bai etÂ al. (<a href="#bib.bib2" title="" class="ltx_ref">2022</a>)</cite> and LLMs-based evaluationÂ <cite class="ltx_cite ltx_citemacro_cite">Chen etÂ al. (<a href="#bib.bib9" title="" class="ltx_ref">2023b</a>); Zheng etÂ al. (<a href="#bib.bib114" title="" class="ltx_ref">2023</a>); Kim etÂ al. (<a href="#bib.bib39" title="" class="ltx_ref">2023</a>)</cite>, which may involve specific challenges and corresponding solution techniques. Due to page limitations, further details about data annotation can be found in AppendixÂ <a href="#A1" title="Appendix A Data Annotation â€£ On LLMs-Driven Synthetic Data Generation, Curation, and Evaluation: A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A</span></a>.</p>
</div>
<figure id="S2.F2" class="ltx_figure"><img src="/html/2406.15126/assets/x2.png" id="S2.F2.g1" class="ltx_graphics ltx_centering ltx_img_square" width="461" height="511" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>A taxonomy of LLMs-driven synthetic data generation, curation, and evaluation.</figcaption>
</figure>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Requirements of <math id="S2.SS2.1.m1.1" class="ltx_Math" alttext="\mathcal{D}_{\text{gen}}" display="inline"><semantics id="S2.SS2.1.m1.1b"><msub id="S2.SS2.1.m1.1.1" xref="S2.SS2.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.1.m1.1.1.2" xref="S2.SS2.1.m1.1.1.2.cmml">ğ’Ÿ</mi><mtext id="S2.SS2.1.m1.1.1.3" xref="S2.SS2.1.m1.1.1.3a.cmml">gen</mtext></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.1.m1.1c"><apply id="S2.SS2.1.m1.1.1.cmml" xref="S2.SS2.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS2.1.m1.1.1.1.cmml" xref="S2.SS2.1.m1.1.1">subscript</csymbol><ci id="S2.SS2.1.m1.1.1.2.cmml" xref="S2.SS2.1.m1.1.1.2">ğ’Ÿ</ci><ci id="S2.SS2.1.m1.1.1.3a.cmml" xref="S2.SS2.1.m1.1.1.3"><mtext mathsize="70%" id="S2.SS2.1.m1.1.1.3.cmml" xref="S2.SS2.1.m1.1.1.3">gen</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.1.m1.1d">\mathcal{D}_{\text{gen}}</annotation></semantics></math>
</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">Briefly speaking, our goal is to generate data that closely aligns with evaluation metrics. While the standard of high-quality data may vary across different downstream tasks, there are two general requirements that are considered challenging in most existing literature:</p>
<ul id="S2.I1" class="ltx_itemize">
<li id="S2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S2.I1.i1.p1" class="ltx_para">
<p id="S2.I1.i1.p1.1" class="ltx_p"><span id="S2.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Faithfulness.</span>
To provide valid supervision, the generated data must first be logically and grammatically coherent. However, the inherent problems of hallucination fat-tailed knowledge distribution of LLMs can introduce significant noise into the generated results, manifesting as factual errors, incorrect labels, or irrelevant content. These issues become more pronounced when generating long, complex, or domain-specific data.</p>
</div>
</li>
<li id="S2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S2.I1.i2.p1" class="ltx_para">
<p id="S2.I1.i2.p1.1" class="ltx_p"><span id="S2.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Diversity.</span>
Diversity captures the variation among the generated data, reflecting differences in text length, topic, or even writing style. It is crucial for generating synthetic samples that mimic the diversified nature of real-world data, thereby preventing overfitting and bias during model training or evaluation. Nevertheless, due to the inherent biases of LLMs, uncontrolled generated content often tends to be monotonous, limiting its applicability in downstream tasks.
</p>
</div>
</li>
</ul>
<p id="S2.SS2.p1.2" class="ltx_p">These two requirements are the focal points of most current research efforts. In the subsequent workflow, we will introduce how different methods address these issues.</p>
</div>
<figure id="S2.F3" class="ltx_figure"><img src="/html/2406.15126/assets/x3.png" id="S2.F3.g1" class="ltx_graphics ltx_centering ltx_img_square" width="461" height="407" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>A toy example of effective synthetic data generation. The corresponding fields for <span id="S2.F3.4.1" class="ltx_text" style="background-color:#F9DA78;">task specification</span>, <span id="S2.F3.5.2" class="ltx_text" style="background-color:#E0EBF6;">conditions</span>, and <span id="S2.F3.6.3" class="ltx_text" style="background-color:#F5BFC4;">in-context demonstrations</span> are highlighted, while &lt; &gt; marks the switchable contents.</figcaption>
</figure>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Generic Workflow</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Existing studies on LLMs-driven synthetic data generation generally incorporate three main topics: generation, curation, and evaluation. Various approaches are employed within these aspects to collaboratively achieve optimal data generation.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Data Generation</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">In this section, we systematically summarize some common practices for synthetic data generation with LLMs, which can be roughly divided into prompt engineering and multi-step generation. An overall illustration is provided in FigureÂ <a href="#S2.F3" title='Figure 3 â€£ 2.2 Requirements of ğ’Ÿ_"gen" â€£ 2 Preliminaries â€£ On LLMs-Driven Synthetic Data Generation, Curation, and Evaluation: A Survey' class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<section id="S3.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.1 </span>Prompt Engineering</h4>

<div id="S3.SS1.SSS1.p1" class="ltx_para">
<p id="S3.SS1.SSS1.p1.1" class="ltx_p">One of the greatest advantages of LLMs for synthetic data generation is their instruction-following capability, which contributes to great controllability <cite class="ltx_cite ltx_citemacro_cite">Wang etÂ al. (<a href="#bib.bib89" title="" class="ltx_ref">2023c</a>); Radford etÂ al. (<a href="#bib.bib70" title="" class="ltx_ref">2019</a>)</cite>. Therefore, many approaches try to guide LLMs with heuristic prompts to enhance the faithfulness and diversity of the synthetic dataÂ <cite class="ltx_cite ltx_citemacro_cite">Liu etÂ al. (<a href="#bib.bib55" title="" class="ltx_ref">2024</a>)</cite>.</p>
</div>
<div id="S3.SS1.SSS1.p2" class="ltx_para">
<p id="S3.SS1.SSS1.p2.4" class="ltx_p">Empirically, an effective prompt generally contains three key elements: <span id="S3.SS1.SSS1.p2.4.1" class="ltx_text ltx_font_italic">task specification</span> <math id="S3.SS1.SSS1.p2.1.m1.1" class="ltx_Math" alttext="e_{\text{task}}" display="inline"><semantics id="S3.SS1.SSS1.p2.1.m1.1a"><msub id="S3.SS1.SSS1.p2.1.m1.1.1" xref="S3.SS1.SSS1.p2.1.m1.1.1.cmml"><mi id="S3.SS1.SSS1.p2.1.m1.1.1.2" xref="S3.SS1.SSS1.p2.1.m1.1.1.2.cmml">e</mi><mtext id="S3.SS1.SSS1.p2.1.m1.1.1.3" xref="S3.SS1.SSS1.p2.1.m1.1.1.3a.cmml">task</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p2.1.m1.1b"><apply id="S3.SS1.SSS1.p2.1.m1.1.1.cmml" xref="S3.SS1.SSS1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p2.1.m1.1.1.1.cmml" xref="S3.SS1.SSS1.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.SSS1.p2.1.m1.1.1.2.cmml" xref="S3.SS1.SSS1.p2.1.m1.1.1.2">ğ‘’</ci><ci id="S3.SS1.SSS1.p2.1.m1.1.1.3a.cmml" xref="S3.SS1.SSS1.p2.1.m1.1.1.3"><mtext mathsize="70%" id="S3.SS1.SSS1.p2.1.m1.1.1.3.cmml" xref="S3.SS1.SSS1.p2.1.m1.1.1.3">task</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p2.1.m1.1c">e_{\text{task}}</annotation></semantics></math>, <span id="S3.SS1.SSS1.p2.4.2" class="ltx_text ltx_font_italic">generation conditions</span> <math id="S3.SS1.SSS1.p2.2.m2.1" class="ltx_Math" alttext="e_{\text{condition}}" display="inline"><semantics id="S3.SS1.SSS1.p2.2.m2.1a"><msub id="S3.SS1.SSS1.p2.2.m2.1.1" xref="S3.SS1.SSS1.p2.2.m2.1.1.cmml"><mi id="S3.SS1.SSS1.p2.2.m2.1.1.2" xref="S3.SS1.SSS1.p2.2.m2.1.1.2.cmml">e</mi><mtext id="S3.SS1.SSS1.p2.2.m2.1.1.3" xref="S3.SS1.SSS1.p2.2.m2.1.1.3a.cmml">condition</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p2.2.m2.1b"><apply id="S3.SS1.SSS1.p2.2.m2.1.1.cmml" xref="S3.SS1.SSS1.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p2.2.m2.1.1.1.cmml" xref="S3.SS1.SSS1.p2.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.SSS1.p2.2.m2.1.1.2.cmml" xref="S3.SS1.SSS1.p2.2.m2.1.1.2">ğ‘’</ci><ci id="S3.SS1.SSS1.p2.2.m2.1.1.3a.cmml" xref="S3.SS1.SSS1.p2.2.m2.1.1.3"><mtext mathsize="70%" id="S3.SS1.SSS1.p2.2.m2.1.1.3.cmml" xref="S3.SS1.SSS1.p2.2.m2.1.1.3">condition</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p2.2.m2.1c">e_{\text{condition}}</annotation></semantics></math>, and <span id="S3.SS1.SSS1.p2.4.3" class="ltx_text ltx_font_italic">in-context demonstrations</span> <math id="S3.SS1.SSS1.p2.3.m3.1" class="ltx_Math" alttext="e_{\text{demo}}" display="inline"><semantics id="S3.SS1.SSS1.p2.3.m3.1a"><msub id="S3.SS1.SSS1.p2.3.m3.1.1" xref="S3.SS1.SSS1.p2.3.m3.1.1.cmml"><mi id="S3.SS1.SSS1.p2.3.m3.1.1.2" xref="S3.SS1.SSS1.p2.3.m3.1.1.2.cmml">e</mi><mtext id="S3.SS1.SSS1.p2.3.m3.1.1.3" xref="S3.SS1.SSS1.p2.3.m3.1.1.3a.cmml">demo</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p2.3.m3.1b"><apply id="S3.SS1.SSS1.p2.3.m3.1.1.cmml" xref="S3.SS1.SSS1.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p2.3.m3.1.1.1.cmml" xref="S3.SS1.SSS1.p2.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.SSS1.p2.3.m3.1.1.2.cmml" xref="S3.SS1.SSS1.p2.3.m3.1.1.2">ğ‘’</ci><ci id="S3.SS1.SSS1.p2.3.m3.1.1.3a.cmml" xref="S3.SS1.SSS1.p2.3.m3.1.1.3"><mtext mathsize="70%" id="S3.SS1.SSS1.p2.3.m3.1.1.3.cmml" xref="S3.SS1.SSS1.p2.3.m3.1.1.3">demo</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p2.3.m3.1c">e_{\text{demo}}</annotation></semantics></math>, which are then collectively wrapped with a template <math id="S3.SS1.SSS1.p2.4.m4.1" class="ltx_Math" alttext="E" display="inline"><semantics id="S3.SS1.SSS1.p2.4.m4.1a"><mi id="S3.SS1.SSS1.p2.4.m4.1.1" xref="S3.SS1.SSS1.p2.4.m4.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p2.4.m4.1b"><ci id="S3.SS1.SSS1.p2.4.m4.1.1.cmml" xref="S3.SS1.SSS1.p2.4.m4.1.1">ğ¸</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p2.4.m4.1c">E</annotation></semantics></math> into the form of natural instruction:</p>
<table id="S3.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E2.m1.5" class="ltx_Math" alttext="p(\mathcal{T},\mathcal{D})\leftarrow E(e_{\text{task}},e_{\text{condition}},e_{\text{demo}})\text{.}" display="block"><semantics id="S3.E2.m1.5a"><mrow id="S3.E2.m1.5.5" xref="S3.E2.m1.5.5.cmml"><mrow id="S3.E2.m1.5.5.5" xref="S3.E2.m1.5.5.5.cmml"><mi id="S3.E2.m1.5.5.5.2" xref="S3.E2.m1.5.5.5.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.5.5.5.1" xref="S3.E2.m1.5.5.5.1.cmml">â€‹</mo><mrow id="S3.E2.m1.5.5.5.3.2" xref="S3.E2.m1.5.5.5.3.1.cmml"><mo stretchy="false" id="S3.E2.m1.5.5.5.3.2.1" xref="S3.E2.m1.5.5.5.3.1.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.1.1" xref="S3.E2.m1.1.1.cmml">ğ’¯</mi><mo id="S3.E2.m1.5.5.5.3.2.2" xref="S3.E2.m1.5.5.5.3.1.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.2.2" xref="S3.E2.m1.2.2.cmml">ğ’Ÿ</mi><mo stretchy="false" id="S3.E2.m1.5.5.5.3.2.3" xref="S3.E2.m1.5.5.5.3.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.E2.m1.5.5.4" xref="S3.E2.m1.5.5.4.cmml">â†</mo><mrow id="S3.E2.m1.5.5.3" xref="S3.E2.m1.5.5.3.cmml"><mi id="S3.E2.m1.5.5.3.5" xref="S3.E2.m1.5.5.3.5.cmml">E</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.5.5.3.4" xref="S3.E2.m1.5.5.3.4.cmml">â€‹</mo><mrow id="S3.E2.m1.5.5.3.3.3" xref="S3.E2.m1.5.5.3.3.4.cmml"><mo stretchy="false" id="S3.E2.m1.5.5.3.3.3.4" xref="S3.E2.m1.5.5.3.3.4.cmml">(</mo><msub id="S3.E2.m1.3.3.1.1.1.1" xref="S3.E2.m1.3.3.1.1.1.1.cmml"><mi id="S3.E2.m1.3.3.1.1.1.1.2" xref="S3.E2.m1.3.3.1.1.1.1.2.cmml">e</mi><mtext id="S3.E2.m1.3.3.1.1.1.1.3" xref="S3.E2.m1.3.3.1.1.1.1.3a.cmml">task</mtext></msub><mo id="S3.E2.m1.5.5.3.3.3.5" xref="S3.E2.m1.5.5.3.3.4.cmml">,</mo><msub id="S3.E2.m1.4.4.2.2.2.2" xref="S3.E2.m1.4.4.2.2.2.2.cmml"><mi id="S3.E2.m1.4.4.2.2.2.2.2" xref="S3.E2.m1.4.4.2.2.2.2.2.cmml">e</mi><mtext id="S3.E2.m1.4.4.2.2.2.2.3" xref="S3.E2.m1.4.4.2.2.2.2.3a.cmml">condition</mtext></msub><mo id="S3.E2.m1.5.5.3.3.3.6" xref="S3.E2.m1.5.5.3.3.4.cmml">,</mo><msub id="S3.E2.m1.5.5.3.3.3.3" xref="S3.E2.m1.5.5.3.3.3.3.cmml"><mi id="S3.E2.m1.5.5.3.3.3.3.2" xref="S3.E2.m1.5.5.3.3.3.3.2.cmml">e</mi><mtext id="S3.E2.m1.5.5.3.3.3.3.3" xref="S3.E2.m1.5.5.3.3.3.3.3a.cmml">demo</mtext></msub><mo stretchy="false" id="S3.E2.m1.5.5.3.3.3.7" xref="S3.E2.m1.5.5.3.3.4.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S3.E2.m1.5.5.3.4a" xref="S3.E2.m1.5.5.3.4.cmml">â€‹</mo><mtext id="S3.E2.m1.5.5.3.6" xref="S3.E2.m1.5.5.3.6a.cmml">.</mtext></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.5b"><apply id="S3.E2.m1.5.5.cmml" xref="S3.E2.m1.5.5"><ci id="S3.E2.m1.5.5.4.cmml" xref="S3.E2.m1.5.5.4">â†</ci><apply id="S3.E2.m1.5.5.5.cmml" xref="S3.E2.m1.5.5.5"><times id="S3.E2.m1.5.5.5.1.cmml" xref="S3.E2.m1.5.5.5.1"></times><ci id="S3.E2.m1.5.5.5.2.cmml" xref="S3.E2.m1.5.5.5.2">ğ‘</ci><interval closure="open" id="S3.E2.m1.5.5.5.3.1.cmml" xref="S3.E2.m1.5.5.5.3.2"><ci id="S3.E2.m1.1.1.cmml" xref="S3.E2.m1.1.1">ğ’¯</ci><ci id="S3.E2.m1.2.2.cmml" xref="S3.E2.m1.2.2">ğ’Ÿ</ci></interval></apply><apply id="S3.E2.m1.5.5.3.cmml" xref="S3.E2.m1.5.5.3"><times id="S3.E2.m1.5.5.3.4.cmml" xref="S3.E2.m1.5.5.3.4"></times><ci id="S3.E2.m1.5.5.3.5.cmml" xref="S3.E2.m1.5.5.3.5">ğ¸</ci><vector id="S3.E2.m1.5.5.3.3.4.cmml" xref="S3.E2.m1.5.5.3.3.3"><apply id="S3.E2.m1.3.3.1.1.1.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.3.3.1.1.1.1.1.cmml" xref="S3.E2.m1.3.3.1.1.1.1">subscript</csymbol><ci id="S3.E2.m1.3.3.1.1.1.1.2.cmml" xref="S3.E2.m1.3.3.1.1.1.1.2">ğ‘’</ci><ci id="S3.E2.m1.3.3.1.1.1.1.3a.cmml" xref="S3.E2.m1.3.3.1.1.1.1.3"><mtext mathsize="70%" id="S3.E2.m1.3.3.1.1.1.1.3.cmml" xref="S3.E2.m1.3.3.1.1.1.1.3">task</mtext></ci></apply><apply id="S3.E2.m1.4.4.2.2.2.2.cmml" xref="S3.E2.m1.4.4.2.2.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.4.4.2.2.2.2.1.cmml" xref="S3.E2.m1.4.4.2.2.2.2">subscript</csymbol><ci id="S3.E2.m1.4.4.2.2.2.2.2.cmml" xref="S3.E2.m1.4.4.2.2.2.2.2">ğ‘’</ci><ci id="S3.E2.m1.4.4.2.2.2.2.3a.cmml" xref="S3.E2.m1.4.4.2.2.2.2.3"><mtext mathsize="70%" id="S3.E2.m1.4.4.2.2.2.2.3.cmml" xref="S3.E2.m1.4.4.2.2.2.2.3">condition</mtext></ci></apply><apply id="S3.E2.m1.5.5.3.3.3.3.cmml" xref="S3.E2.m1.5.5.3.3.3.3"><csymbol cd="ambiguous" id="S3.E2.m1.5.5.3.3.3.3.1.cmml" xref="S3.E2.m1.5.5.3.3.3.3">subscript</csymbol><ci id="S3.E2.m1.5.5.3.3.3.3.2.cmml" xref="S3.E2.m1.5.5.3.3.3.3.2">ğ‘’</ci><ci id="S3.E2.m1.5.5.3.3.3.3.3a.cmml" xref="S3.E2.m1.5.5.3.3.3.3.3"><mtext mathsize="70%" id="S3.E2.m1.5.5.3.3.3.3.3.cmml" xref="S3.E2.m1.5.5.3.3.3.3.3">demo</mtext></ci></apply></vector><ci id="S3.E2.m1.5.5.3.6a.cmml" xref="S3.E2.m1.5.5.3.6"><mtext id="S3.E2.m1.5.5.3.6.cmml" xref="S3.E2.m1.5.5.3.6">.</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.5c">p(\mathcal{T},\mathcal{D})\leftarrow E(e_{\text{task}},e_{\text{condition}},e_{\text{demo}})\text{.}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.SSS1.p2.7" class="ltx_p">As shown above, both the generation task <math id="S3.SS1.SSS1.p2.5.m1.1" class="ltx_Math" alttext="\mathcal{T}" display="inline"><semantics id="S3.SS1.SSS1.p2.5.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.SSS1.p2.5.m1.1.1" xref="S3.SS1.SSS1.p2.5.m1.1.1.cmml">ğ’¯</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p2.5.m1.1b"><ci id="S3.SS1.SSS1.p2.5.m1.1.1.cmml" xref="S3.SS1.SSS1.p2.5.m1.1.1">ğ’¯</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p2.5.m1.1c">\mathcal{T}</annotation></semantics></math> and the support dataset <math id="S3.SS1.SSS1.p2.6.m2.1" class="ltx_Math" alttext="\mathcal{D}" display="inline"><semantics id="S3.SS1.SSS1.p2.6.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.SSS1.p2.6.m2.1.1" xref="S3.SS1.SSS1.p2.6.m2.1.1.cmml">ğ’Ÿ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p2.6.m2.1b"><ci id="S3.SS1.SSS1.p2.6.m2.1.1.cmml" xref="S3.SS1.SSS1.p2.6.m2.1.1">ğ’Ÿ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p2.6.m2.1c">\mathcal{D}</annotation></semantics></math> will affect the design of <math id="S3.SS1.SSS1.p2.7.m3.1" class="ltx_Math" alttext="p" display="inline"><semantics id="S3.SS1.SSS1.p2.7.m3.1a"><mi id="S3.SS1.SSS1.p2.7.m3.1.1" xref="S3.SS1.SSS1.p2.7.m3.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p2.7.m3.1b"><ci id="S3.SS1.SSS1.p2.7.m3.1.1.cmml" xref="S3.SS1.SSS1.p2.7.m3.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p2.7.m3.1c">p</annotation></semantics></math>. Next, we will proceed to detail how each part of the prompt should be appropriately designed to accommodate various scenarios.</p>
</div>
<section id="S3.SS1.SSS1.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Task Specification.</h5>

<div id="S3.SS1.SSS1.Px1.p1" class="ltx_para">
<p id="S3.SS1.SSS1.Px1.p1.1" class="ltx_p">In traditional crowdsourced annotation scenarios, the recruited workers are commonly offered a codebook that specifies the necessary contexts, such as task purpose, data explanation, and other background knowledge, so that they can better understand their jobs <cite class="ltx_cite ltx_citemacro_cite">Gilardi etÂ al. (<a href="#bib.bib23" title="" class="ltx_ref">2023</a>)</cite>. Similarly, such task specification is crucial for setting the right context for LLMs-driven data generation, which can also include role-playÂ <cite class="ltx_cite ltx_citemacro_cite">Li etÂ al. (<a href="#bib.bib50" title="" class="ltx_ref">2023c</a>)</cite>, format clarification, knowledge augmentationÂ <cite class="ltx_cite ltx_citemacro_cite">Xu etÂ al. (<a href="#bib.bib100" title="" class="ltx_ref">2023b</a>); Sudalairaj etÂ al. (<a href="#bib.bib80" title="" class="ltx_ref">2024</a>)</cite>, etc. Evidence shows that a simple prologue such as â€œsuppose you are a <span id="S3.SS1.SSS1.Px1.p1.1.1" class="ltx_text ltx_font_typewriter">{xxx}</span>â€ can significantly improve the LLMsâ€™ performance by setting up a proper scenario for data generation and allowing the LLMs to better take on the roles <cite class="ltx_cite ltx_citemacro_cite">Li etÂ al. (<a href="#bib.bib50" title="" class="ltx_ref">2023c</a>)</cite>. More formally, <cite class="ltx_cite ltx_citemacro_citet">Yoo etÂ al. (<a href="#bib.bib104" title="" class="ltx_ref">2021</a>)</cite> defines the task specification with a triplet of text type, label type, and label-token verbalizer. Such a description header is particularly important when extra domain expertise is demanded to address issues like terminology complexities in both context understanding and data generation. Consequently, <cite class="ltx_cite ltx_citemacro_citet">Xu etÂ al. (<a href="#bib.bib100" title="" class="ltx_ref">2023b</a>)</cite> leverages external knowledge graphs and LLMs to obtain domain topics for context-informed prompting, which effectively enhances the faithfulness and complexity of generated data.</p>
</div>
</section>
<section id="S3.SS1.SSS1.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Conditional Prompting.</h5>

<div id="S3.SS1.SSS1.Px2.p1" class="ltx_para">
<p id="S3.SS1.SSS1.Px2.p1.1" class="ltx_p">As mentioned in SectionÂ <a href="#S2.SS2" title='2.2 Requirements of ğ’Ÿ_"gen" â€£ 2 Preliminaries â€£ On LLMs-Driven Synthetic Data Generation, Curation, and Evaluation: A Survey' class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.2</span></a>, a pivotal challenge in using LLMs for synthetic data generation is ensuring sufficient diversity, as directly prompting the LLMs to produce data for certain tasks often results in highly repetitive outputs, even with a high decoding temperatureÂ <cite class="ltx_cite ltx_citemacro_cite">Gandhi etÂ al. (<a href="#bib.bib19" title="" class="ltx_ref">2024</a>); Liu etÂ al. (<a href="#bib.bib55" title="" class="ltx_ref">2024</a>)</cite>. Addressing this problem, a widely adopted strategy is conditional prompting, which explicitly and concretely communicates to the LLMs the specific type of data desired.
The core of conditional prompting involves delineating the targeted data through the formulation of a series of condition-value pairs:</p>
<table id="S3.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E3.m1.4" class="ltx_Math" alttext="e_{\text{condition}}=\{(c_{1},v_{1}),(c_{2},v_{2}),\cdots,(c_{n},v_{n})\}\text{,}" display="block"><semantics id="S3.E3.m1.4a"><mrow id="S3.E3.m1.4.4" xref="S3.E3.m1.4.4.cmml"><msub id="S3.E3.m1.4.4.5" xref="S3.E3.m1.4.4.5.cmml"><mi id="S3.E3.m1.4.4.5.2" xref="S3.E3.m1.4.4.5.2.cmml">e</mi><mtext id="S3.E3.m1.4.4.5.3" xref="S3.E3.m1.4.4.5.3a.cmml">condition</mtext></msub><mo id="S3.E3.m1.4.4.4" xref="S3.E3.m1.4.4.4.cmml">=</mo><mrow id="S3.E3.m1.4.4.3" xref="S3.E3.m1.4.4.3.cmml"><mrow id="S3.E3.m1.4.4.3.3.3" xref="S3.E3.m1.4.4.3.3.4.cmml"><mo stretchy="false" id="S3.E3.m1.4.4.3.3.3.4" xref="S3.E3.m1.4.4.3.3.4.cmml">{</mo><mrow id="S3.E3.m1.2.2.1.1.1.1.2" xref="S3.E3.m1.2.2.1.1.1.1.3.cmml"><mo stretchy="false" id="S3.E3.m1.2.2.1.1.1.1.2.3" xref="S3.E3.m1.2.2.1.1.1.1.3.cmml">(</mo><msub id="S3.E3.m1.2.2.1.1.1.1.1.1" xref="S3.E3.m1.2.2.1.1.1.1.1.1.cmml"><mi id="S3.E3.m1.2.2.1.1.1.1.1.1.2" xref="S3.E3.m1.2.2.1.1.1.1.1.1.2.cmml">c</mi><mn id="S3.E3.m1.2.2.1.1.1.1.1.1.3" xref="S3.E3.m1.2.2.1.1.1.1.1.1.3.cmml">1</mn></msub><mo id="S3.E3.m1.2.2.1.1.1.1.2.4" xref="S3.E3.m1.2.2.1.1.1.1.3.cmml">,</mo><msub id="S3.E3.m1.2.2.1.1.1.1.2.2" xref="S3.E3.m1.2.2.1.1.1.1.2.2.cmml"><mi id="S3.E3.m1.2.2.1.1.1.1.2.2.2" xref="S3.E3.m1.2.2.1.1.1.1.2.2.2.cmml">v</mi><mn id="S3.E3.m1.2.2.1.1.1.1.2.2.3" xref="S3.E3.m1.2.2.1.1.1.1.2.2.3.cmml">1</mn></msub><mo stretchy="false" id="S3.E3.m1.2.2.1.1.1.1.2.5" xref="S3.E3.m1.2.2.1.1.1.1.3.cmml">)</mo></mrow><mo id="S3.E3.m1.4.4.3.3.3.5" xref="S3.E3.m1.4.4.3.3.4.cmml">,</mo><mrow id="S3.E3.m1.3.3.2.2.2.2.2" xref="S3.E3.m1.3.3.2.2.2.2.3.cmml"><mo stretchy="false" id="S3.E3.m1.3.3.2.2.2.2.2.3" xref="S3.E3.m1.3.3.2.2.2.2.3.cmml">(</mo><msub id="S3.E3.m1.3.3.2.2.2.2.1.1" xref="S3.E3.m1.3.3.2.2.2.2.1.1.cmml"><mi id="S3.E3.m1.3.3.2.2.2.2.1.1.2" xref="S3.E3.m1.3.3.2.2.2.2.1.1.2.cmml">c</mi><mn id="S3.E3.m1.3.3.2.2.2.2.1.1.3" xref="S3.E3.m1.3.3.2.2.2.2.1.1.3.cmml">2</mn></msub><mo id="S3.E3.m1.3.3.2.2.2.2.2.4" xref="S3.E3.m1.3.3.2.2.2.2.3.cmml">,</mo><msub id="S3.E3.m1.3.3.2.2.2.2.2.2" xref="S3.E3.m1.3.3.2.2.2.2.2.2.cmml"><mi id="S3.E3.m1.3.3.2.2.2.2.2.2.2" xref="S3.E3.m1.3.3.2.2.2.2.2.2.2.cmml">v</mi><mn id="S3.E3.m1.3.3.2.2.2.2.2.2.3" xref="S3.E3.m1.3.3.2.2.2.2.2.2.3.cmml">2</mn></msub><mo stretchy="false" id="S3.E3.m1.3.3.2.2.2.2.2.5" xref="S3.E3.m1.3.3.2.2.2.2.3.cmml">)</mo></mrow><mo id="S3.E3.m1.4.4.3.3.3.6" xref="S3.E3.m1.4.4.3.3.4.cmml">,</mo><mi mathvariant="normal" id="S3.E3.m1.1.1" xref="S3.E3.m1.1.1.cmml">â‹¯</mi><mo id="S3.E3.m1.4.4.3.3.3.7" xref="S3.E3.m1.4.4.3.3.4.cmml">,</mo><mrow id="S3.E3.m1.4.4.3.3.3.3.2" xref="S3.E3.m1.4.4.3.3.3.3.3.cmml"><mo stretchy="false" id="S3.E3.m1.4.4.3.3.3.3.2.3" xref="S3.E3.m1.4.4.3.3.3.3.3.cmml">(</mo><msub id="S3.E3.m1.4.4.3.3.3.3.1.1" xref="S3.E3.m1.4.4.3.3.3.3.1.1.cmml"><mi id="S3.E3.m1.4.4.3.3.3.3.1.1.2" xref="S3.E3.m1.4.4.3.3.3.3.1.1.2.cmml">c</mi><mi id="S3.E3.m1.4.4.3.3.3.3.1.1.3" xref="S3.E3.m1.4.4.3.3.3.3.1.1.3.cmml">n</mi></msub><mo id="S3.E3.m1.4.4.3.3.3.3.2.4" xref="S3.E3.m1.4.4.3.3.3.3.3.cmml">,</mo><msub id="S3.E3.m1.4.4.3.3.3.3.2.2" xref="S3.E3.m1.4.4.3.3.3.3.2.2.cmml"><mi id="S3.E3.m1.4.4.3.3.3.3.2.2.2" xref="S3.E3.m1.4.4.3.3.3.3.2.2.2.cmml">v</mi><mi id="S3.E3.m1.4.4.3.3.3.3.2.2.3" xref="S3.E3.m1.4.4.3.3.3.3.2.2.3.cmml">n</mi></msub><mo stretchy="false" id="S3.E3.m1.4.4.3.3.3.3.2.5" xref="S3.E3.m1.4.4.3.3.3.3.3.cmml">)</mo></mrow><mo stretchy="false" id="S3.E3.m1.4.4.3.3.3.8" xref="S3.E3.m1.4.4.3.3.4.cmml">}</mo></mrow><mo lspace="0em" rspace="0em" id="S3.E3.m1.4.4.3.4" xref="S3.E3.m1.4.4.3.4.cmml">â€‹</mo><mtext id="S3.E3.m1.4.4.3.5" xref="S3.E3.m1.4.4.3.5a.cmml">,</mtext></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.4b"><apply id="S3.E3.m1.4.4.cmml" xref="S3.E3.m1.4.4"><eq id="S3.E3.m1.4.4.4.cmml" xref="S3.E3.m1.4.4.4"></eq><apply id="S3.E3.m1.4.4.5.cmml" xref="S3.E3.m1.4.4.5"><csymbol cd="ambiguous" id="S3.E3.m1.4.4.5.1.cmml" xref="S3.E3.m1.4.4.5">subscript</csymbol><ci id="S3.E3.m1.4.4.5.2.cmml" xref="S3.E3.m1.4.4.5.2">ğ‘’</ci><ci id="S3.E3.m1.4.4.5.3a.cmml" xref="S3.E3.m1.4.4.5.3"><mtext mathsize="70%" id="S3.E3.m1.4.4.5.3.cmml" xref="S3.E3.m1.4.4.5.3">condition</mtext></ci></apply><apply id="S3.E3.m1.4.4.3.cmml" xref="S3.E3.m1.4.4.3"><times id="S3.E3.m1.4.4.3.4.cmml" xref="S3.E3.m1.4.4.3.4"></times><set id="S3.E3.m1.4.4.3.3.4.cmml" xref="S3.E3.m1.4.4.3.3.3"><interval closure="open" id="S3.E3.m1.2.2.1.1.1.1.3.cmml" xref="S3.E3.m1.2.2.1.1.1.1.2"><apply id="S3.E3.m1.2.2.1.1.1.1.1.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E3.m1.2.2.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.2">ğ‘</ci><cn type="integer" id="S3.E3.m1.2.2.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.3">1</cn></apply><apply id="S3.E3.m1.2.2.1.1.1.1.2.2.cmml" xref="S3.E3.m1.2.2.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.1.1.2.2.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1.2.2">subscript</csymbol><ci id="S3.E3.m1.2.2.1.1.1.1.2.2.2.cmml" xref="S3.E3.m1.2.2.1.1.1.1.2.2.2">ğ‘£</ci><cn type="integer" id="S3.E3.m1.2.2.1.1.1.1.2.2.3.cmml" xref="S3.E3.m1.2.2.1.1.1.1.2.2.3">1</cn></apply></interval><interval closure="open" id="S3.E3.m1.3.3.2.2.2.2.3.cmml" xref="S3.E3.m1.3.3.2.2.2.2.2"><apply id="S3.E3.m1.3.3.2.2.2.2.1.1.cmml" xref="S3.E3.m1.3.3.2.2.2.2.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.2.2.2.2.1.1.1.cmml" xref="S3.E3.m1.3.3.2.2.2.2.1.1">subscript</csymbol><ci id="S3.E3.m1.3.3.2.2.2.2.1.1.2.cmml" xref="S3.E3.m1.3.3.2.2.2.2.1.1.2">ğ‘</ci><cn type="integer" id="S3.E3.m1.3.3.2.2.2.2.1.1.3.cmml" xref="S3.E3.m1.3.3.2.2.2.2.1.1.3">2</cn></apply><apply id="S3.E3.m1.3.3.2.2.2.2.2.2.cmml" xref="S3.E3.m1.3.3.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.2.2.2.2.2.2.1.cmml" xref="S3.E3.m1.3.3.2.2.2.2.2.2">subscript</csymbol><ci id="S3.E3.m1.3.3.2.2.2.2.2.2.2.cmml" xref="S3.E3.m1.3.3.2.2.2.2.2.2.2">ğ‘£</ci><cn type="integer" id="S3.E3.m1.3.3.2.2.2.2.2.2.3.cmml" xref="S3.E3.m1.3.3.2.2.2.2.2.2.3">2</cn></apply></interval><ci id="S3.E3.m1.1.1.cmml" xref="S3.E3.m1.1.1">â‹¯</ci><interval closure="open" id="S3.E3.m1.4.4.3.3.3.3.3.cmml" xref="S3.E3.m1.4.4.3.3.3.3.2"><apply id="S3.E3.m1.4.4.3.3.3.3.1.1.cmml" xref="S3.E3.m1.4.4.3.3.3.3.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.4.4.3.3.3.3.1.1.1.cmml" xref="S3.E3.m1.4.4.3.3.3.3.1.1">subscript</csymbol><ci id="S3.E3.m1.4.4.3.3.3.3.1.1.2.cmml" xref="S3.E3.m1.4.4.3.3.3.3.1.1.2">ğ‘</ci><ci id="S3.E3.m1.4.4.3.3.3.3.1.1.3.cmml" xref="S3.E3.m1.4.4.3.3.3.3.1.1.3">ğ‘›</ci></apply><apply id="S3.E3.m1.4.4.3.3.3.3.2.2.cmml" xref="S3.E3.m1.4.4.3.3.3.3.2.2"><csymbol cd="ambiguous" id="S3.E3.m1.4.4.3.3.3.3.2.2.1.cmml" xref="S3.E3.m1.4.4.3.3.3.3.2.2">subscript</csymbol><ci id="S3.E3.m1.4.4.3.3.3.3.2.2.2.cmml" xref="S3.E3.m1.4.4.3.3.3.3.2.2.2">ğ‘£</ci><ci id="S3.E3.m1.4.4.3.3.3.3.2.2.3.cmml" xref="S3.E3.m1.4.4.3.3.3.3.2.2.3">ğ‘›</ci></apply></interval></set><ci id="S3.E3.m1.4.4.3.5a.cmml" xref="S3.E3.m1.4.4.3.5"><mtext id="S3.E3.m1.4.4.3.5.cmml" xref="S3.E3.m1.4.4.3.5">,</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.4c">e_{\text{condition}}=\{(c_{1},v_{1}),(c_{2},v_{2}),\cdots,(c_{n},v_{n})\}\text{,}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.SSS1.Px2.p1.2" class="ltx_p">which effectively characterizes the desired attributes and characteristics of the synthetic data.
With different combinations of such attributes, we can automatically achieve a degree of â€œartificially definedâ€ diversity in the generated samplesÂ <cite class="ltx_cite ltx_citemacro_cite">Gunasekar etÂ al. (<a href="#bib.bib24" title="" class="ltx_ref">2023</a>); Li etÂ al. (<a href="#bib.bib49" title="" class="ltx_ref">2023b</a>); Eldan and Li (<a href="#bib.bib16" title="" class="ltx_ref">2023</a>)</cite>.
Conditional prompting not only allows better control over the diversity and coverage of the generated dataset but also refines the content to a narrower, more focused scope that is more likely to align with our specific expectations and requirementsÂ <cite class="ltx_cite ltx_citemacro_cite">Li etÂ al. (<a href="#bib.bib50" title="" class="ltx_ref">2023c</a>)</cite>. Current research on conditional prompting primarily centers on the following two subjects:</p>
<ul id="S3.I1" class="ltx_itemize">
<li id="S3.I1.ix1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1)</span> 
<div id="S3.I1.ix1.p1" class="ltx_para">
<p id="S3.I1.ix1.p1.2" class="ltx_p"><span id="S3.I1.ix1.p1.2.1" class="ltx_text ltx_font_bold">Conditioning Scope.</span> As the backbone of <math id="S3.I1.ix1.p1.1.m1.1" class="ltx_Math" alttext="e_{\text{condition}}" display="inline"><semantics id="S3.I1.ix1.p1.1.m1.1a"><msub id="S3.I1.ix1.p1.1.m1.1.1" xref="S3.I1.ix1.p1.1.m1.1.1.cmml"><mi id="S3.I1.ix1.p1.1.m1.1.1.2" xref="S3.I1.ix1.p1.1.m1.1.1.2.cmml">e</mi><mtext id="S3.I1.ix1.p1.1.m1.1.1.3" xref="S3.I1.ix1.p1.1.m1.1.1.3a.cmml">condition</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.I1.ix1.p1.1.m1.1b"><apply id="S3.I1.ix1.p1.1.m1.1.1.cmml" xref="S3.I1.ix1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.I1.ix1.p1.1.m1.1.1.1.cmml" xref="S3.I1.ix1.p1.1.m1.1.1">subscript</csymbol><ci id="S3.I1.ix1.p1.1.m1.1.1.2.cmml" xref="S3.I1.ix1.p1.1.m1.1.1.2">ğ‘’</ci><ci id="S3.I1.ix1.p1.1.m1.1.1.3a.cmml" xref="S3.I1.ix1.p1.1.m1.1.1.3"><mtext mathsize="70%" id="S3.I1.ix1.p1.1.m1.1.1.3.cmml" xref="S3.I1.ix1.p1.1.m1.1.1.3">condition</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.ix1.p1.1.m1.1c">e_{\text{condition}}</annotation></semantics></math>, conditioning scope defined by <math id="S3.I1.ix1.p1.2.m2.3" class="ltx_Math" alttext="\{c_{1},\cdots,c_{n}\}" display="inline"><semantics id="S3.I1.ix1.p1.2.m2.3a"><mrow id="S3.I1.ix1.p1.2.m2.3.3.2" xref="S3.I1.ix1.p1.2.m2.3.3.3.cmml"><mo stretchy="false" id="S3.I1.ix1.p1.2.m2.3.3.2.3" xref="S3.I1.ix1.p1.2.m2.3.3.3.cmml">{</mo><msub id="S3.I1.ix1.p1.2.m2.2.2.1.1" xref="S3.I1.ix1.p1.2.m2.2.2.1.1.cmml"><mi id="S3.I1.ix1.p1.2.m2.2.2.1.1.2" xref="S3.I1.ix1.p1.2.m2.2.2.1.1.2.cmml">c</mi><mn id="S3.I1.ix1.p1.2.m2.2.2.1.1.3" xref="S3.I1.ix1.p1.2.m2.2.2.1.1.3.cmml">1</mn></msub><mo id="S3.I1.ix1.p1.2.m2.3.3.2.4" xref="S3.I1.ix1.p1.2.m2.3.3.3.cmml">,</mo><mi mathvariant="normal" id="S3.I1.ix1.p1.2.m2.1.1" xref="S3.I1.ix1.p1.2.m2.1.1.cmml">â‹¯</mi><mo id="S3.I1.ix1.p1.2.m2.3.3.2.5" xref="S3.I1.ix1.p1.2.m2.3.3.3.cmml">,</mo><msub id="S3.I1.ix1.p1.2.m2.3.3.2.2" xref="S3.I1.ix1.p1.2.m2.3.3.2.2.cmml"><mi id="S3.I1.ix1.p1.2.m2.3.3.2.2.2" xref="S3.I1.ix1.p1.2.m2.3.3.2.2.2.cmml">c</mi><mi id="S3.I1.ix1.p1.2.m2.3.3.2.2.3" xref="S3.I1.ix1.p1.2.m2.3.3.2.2.3.cmml">n</mi></msub><mo stretchy="false" id="S3.I1.ix1.p1.2.m2.3.3.2.6" xref="S3.I1.ix1.p1.2.m2.3.3.3.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.I1.ix1.p1.2.m2.3b"><set id="S3.I1.ix1.p1.2.m2.3.3.3.cmml" xref="S3.I1.ix1.p1.2.m2.3.3.2"><apply id="S3.I1.ix1.p1.2.m2.2.2.1.1.cmml" xref="S3.I1.ix1.p1.2.m2.2.2.1.1"><csymbol cd="ambiguous" id="S3.I1.ix1.p1.2.m2.2.2.1.1.1.cmml" xref="S3.I1.ix1.p1.2.m2.2.2.1.1">subscript</csymbol><ci id="S3.I1.ix1.p1.2.m2.2.2.1.1.2.cmml" xref="S3.I1.ix1.p1.2.m2.2.2.1.1.2">ğ‘</ci><cn type="integer" id="S3.I1.ix1.p1.2.m2.2.2.1.1.3.cmml" xref="S3.I1.ix1.p1.2.m2.2.2.1.1.3">1</cn></apply><ci id="S3.I1.ix1.p1.2.m2.1.1.cmml" xref="S3.I1.ix1.p1.2.m2.1.1">â‹¯</ci><apply id="S3.I1.ix1.p1.2.m2.3.3.2.2.cmml" xref="S3.I1.ix1.p1.2.m2.3.3.2.2"><csymbol cd="ambiguous" id="S3.I1.ix1.p1.2.m2.3.3.2.2.1.cmml" xref="S3.I1.ix1.p1.2.m2.3.3.2.2">subscript</csymbol><ci id="S3.I1.ix1.p1.2.m2.3.3.2.2.2.cmml" xref="S3.I1.ix1.p1.2.m2.3.3.2.2.2">ğ‘</ci><ci id="S3.I1.ix1.p1.2.m2.3.3.2.2.3.cmml" xref="S3.I1.ix1.p1.2.m2.3.3.2.2.3">ğ‘›</ci></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.ix1.p1.2.m2.3c">\{c_{1},\cdots,c_{n}\}</annotation></semantics></math> delineates the dimensions that we utilize to characterize our target data. Early studies <cite class="ltx_cite ltx_citemacro_cite">Gao etÂ al. (<a href="#bib.bib20" title="" class="ltx_ref">2023a</a>); Ye etÂ al. (<a href="#bib.bib101" title="" class="ltx_ref">2022a</a>, <a href="#bib.bib102" title="" class="ltx_ref">b</a>)</cite> employed a basic output-conditional prompting strategy, utilizing the specific label associated with the classification task as the conditioning variable. The rationale behind this was primarily to maintain class balance and coverage. However, such a strategy is unsuitable for data lacking explicit category labels. Subsequent work byÂ <cite class="ltx_cite ltx_citemacro_citet">Yu etÂ al. (<a href="#bib.bib106" title="" class="ltx_ref">2023b</a>)</cite> argues that conditional-prompting with finer-grained attributes (e.g., topics, length, and style <cite class="ltx_cite ltx_citemacro_cite">Xu etÂ al. (<a href="#bib.bib100" title="" class="ltx_ref">2023b</a>)</cite>), can lead to more diversified generation due to the vast number of possible attribute combinations, being also applicable to open-ended data. Additionally, <cite class="ltx_cite ltx_citemacro_citet">Eldan and Li (<a href="#bib.bib16" title="" class="ltx_ref">2023</a>)</cite> also condition each generation on the task of incorporating three randomly chosen words into the generated story. This approach was also proven to significantly enhance the diversity of the generated data, shifting the focus from the heuristic features of the output to a more structured and targeted conditioning mechanism by adding â€œcreative randomnessâ€ to the promptÂ <cite class="ltx_cite ltx_citemacro_cite">Eldan and Li (<a href="#bib.bib16" title="" class="ltx_ref">2023</a>)</cite>.</p>
</div>
</li>
<li id="S3.I1.ix2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2)</span> 
<div id="S3.I1.ix2.p1" class="ltx_para">
<p id="S3.I1.ix2.p1.1" class="ltx_p"><span id="S3.I1.ix2.p1.1.1" class="ltx_text ltx_font_bold">Conditioning Values.</span> After defining the conditioning scope, we then need to assign concrete values to each condition.
Despite the seemingly straightforward strategy of sampling from the known classes or labels <cite class="ltx_cite ltx_citemacro_cite">Ye etÂ al. (<a href="#bib.bib101" title="" class="ltx_ref">2022a</a>)</cite>, there are cases where such an instance pool is unavailable. Addressing this problem, <cite class="ltx_cite ltx_citemacro_citet">Josifoski etÂ al. (<a href="#bib.bib38" title="" class="ltx_ref">2023</a>)</cite> actively retrieves the conditioning instances from external knowledge graphs, while <cite class="ltx_cite ltx_citemacro_citet">Xu etÂ al. (<a href="#bib.bib100" title="" class="ltx_ref">2023b</a>); Ding etÂ al. (<a href="#bib.bib15" title="" class="ltx_ref">2023b</a>)</cite> leverage the LLMs to generate diversified instances for conditional prompting. Specifically, <cite class="ltx_cite ltx_citemacro_citet">Ding etÂ al. (<a href="#bib.bib15" title="" class="ltx_ref">2023b</a>)</cite> construct a concept tree to delve into different subtopics, ensuring the coverage of sampled conditioning values, which then contributes to more diverse generated data. Moreover, the prompt template <math id="S3.I1.ix2.p1.1.m1.1" class="ltx_Math" alttext="E" display="inline"><semantics id="S3.I1.ix2.p1.1.m1.1a"><mi id="S3.I1.ix2.p1.1.m1.1.1" xref="S3.I1.ix2.p1.1.m1.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="S3.I1.ix2.p1.1.m1.1b"><ci id="S3.I1.ix2.p1.1.m1.1.1.cmml" xref="S3.I1.ix2.p1.1.m1.1.1">ğ¸</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.ix2.p1.1.m1.1c">E</annotation></semantics></math> can also be considered a special type of condition. It has been demonstrated that incorporating templates with a certain level of randomness throughout the generation process can enhance the diversity of the generated contents <cite class="ltx_cite ltx_citemacro_cite">Meng etÂ al. (<a href="#bib.bib60" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S3.SS1.SSS1.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">In-Context Learning.</h5>

<div id="S3.SS1.SSS1.Px3.p1" class="ltx_para">
<p id="S3.SS1.SSS1.Px3.p1.1" class="ltx_p">Due to the inherent bias of LLMs, it remains challenging to elicit favorable responses from the LLMs with merely task specification and conditional prompting. In this case, a straightforward yet effective strategy is to provide several demonstrations, which can serve as a form of implicit human guidance. Research has shown that, owing to LLMsâ€™ remarkable in-context learning (ICL) capabilities, a few exemplars can provide them with insights into the patterns exhibited in real-world data, thereby significantly improving the faithfulness of generated data <cite class="ltx_cite ltx_citemacro_cite">Li etÂ al. (<a href="#bib.bib50" title="" class="ltx_ref">2023c</a>)</cite>. In the few-shot setting, where labeled samples are available in the support set <math id="S3.SS1.SSS1.Px3.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{D}_{\text{sup}}" display="inline"><semantics id="S3.SS1.SSS1.Px3.p1.1.m1.1a"><msub id="S3.SS1.SSS1.Px3.p1.1.m1.1.1" xref="S3.SS1.SSS1.Px3.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.SSS1.Px3.p1.1.m1.1.1.2" xref="S3.SS1.SSS1.Px3.p1.1.m1.1.1.2.cmml">ğ’Ÿ</mi><mtext id="S3.SS1.SSS1.Px3.p1.1.m1.1.1.3" xref="S3.SS1.SSS1.Px3.p1.1.m1.1.1.3a.cmml">sup</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.Px3.p1.1.m1.1b"><apply id="S3.SS1.SSS1.Px3.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS1.Px3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.Px3.p1.1.m1.1.1.1.cmml" xref="S3.SS1.SSS1.Px3.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.SSS1.Px3.p1.1.m1.1.1.2.cmml" xref="S3.SS1.SSS1.Px3.p1.1.m1.1.1.2">ğ’Ÿ</ci><ci id="S3.SS1.SSS1.Px3.p1.1.m1.1.1.3a.cmml" xref="S3.SS1.SSS1.Px3.p1.1.m1.1.1.3"><mtext mathsize="70%" id="S3.SS1.SSS1.Px3.p1.1.m1.1.1.3.cmml" xref="S3.SS1.SSS1.Px3.p1.1.m1.1.1.3">sup</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.Px3.p1.1.m1.1c">\mathcal{D}_{\text{sup}}</annotation></semantics></math>, these samples can be directly utilized as demonstrations for ICL. However, in scenarios where no ground truth data is available, approaches like Self-Instruct <cite class="ltx_cite ltx_citemacro_cite">Wang etÂ al. (<a href="#bib.bib91" title="" class="ltx_ref">2023e</a>)</cite> and Self-Prompting <cite class="ltx_cite ltx_citemacro_cite">Li etÂ al. (<a href="#bib.bib47" title="" class="ltx_ref">2022</a>)</cite> instead leverage ICL with synthetic demonstrations generated by LLMs. This allows the models to learn from their own predictions or other teacher models, even in the absence of labeled data.</p>
</div>
<div id="S3.SS1.SSS1.Px3.p2" class="ltx_para">
<p id="S3.SS1.SSS1.Px3.p2.1" class="ltx_p">However, given the constraint of prompt length and data inconsistency, the quality of in-context samples significantly affects the effectiveness of in-context learning. <cite class="ltx_cite ltx_citemacro_citet">Sudalairaj etÂ al. (<a href="#bib.bib80" title="" class="ltx_ref">2024</a>)</cite> argue that randomly selecting in-context examples from the pool of seed samples, as done in Self-InstructÂ <cite class="ltx_cite ltx_citemacro_cite">Wang etÂ al. (<a href="#bib.bib91" title="" class="ltx_ref">2023e</a>)</cite>, results in a lack of diversity and quality in the generated data. To address this issue, <cite class="ltx_cite ltx_citemacro_citet">Sudalairaj etÂ al. (<a href="#bib.bib80" title="" class="ltx_ref">2024</a>)</cite> opt for selecting examples that concentrate on specific aspects to better stimulate the long tail of knowledge inherent in LLMs. <cite class="ltx_cite ltx_citemacro_citet">Liu etÂ al. (<a href="#bib.bib54" title="" class="ltx_ref">2022b</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citet">Su etÂ al. (<a href="#bib.bib79" title="" class="ltx_ref">2023</a>)</cite> prioritize consistent samples as demonstrative examples based on their cosine similarity in the embedding space. Alternatively, <cite class="ltx_cite ltx_citemacro_citet">Ye etÂ al. (<a href="#bib.bib102" title="" class="ltx_ref">2022b</a>)</cite> selects the most informative samples using quantified influence scores to steer the generation process. To enhance the informativeness of in-context examples, <cite class="ltx_cite ltx_citemacro_citet">He etÂ al. (<a href="#bib.bib29" title="" class="ltx_ref">2023</a>)</cite> prompts LLMs to provide an explanation for each sample before integrating it into the prompt. This approach not only offers valuable additional information but also aligns well with the subsequent Chain-of-Thought generation.</p>
</div>
</section>
</section>
<section id="S3.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.2 </span>Multi-Step Generation</h4>

<div id="S3.SS1.SSS2.p1" class="ltx_para">
<p id="S3.SS1.SSS2.p1.2" class="ltx_p">In the previous paragraphs, we have introduced some common prompting strategies, which are typically designed for a specific generation task <math id="S3.SS1.SSS2.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{T}" display="inline"><semantics id="S3.SS1.SSS2.p1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.SSS2.p1.1.m1.1.1" xref="S3.SS1.SSS2.p1.1.m1.1.1.cmml">ğ’¯</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p1.1.m1.1b"><ci id="S3.SS1.SSS2.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS2.p1.1.m1.1.1">ğ’¯</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p1.1.m1.1c">\mathcal{T}</annotation></semantics></math>. However, in most cases, due to the lack of enough reasoning abilities, it is unrealistic to expect the LLMs to generate the entire desired dataset within a single reference, especially when targeting data with complex structures or semanticsÂ <cite class="ltx_cite ltx_citemacro_cite">Cui and Wang (<a href="#bib.bib12" title="" class="ltx_ref">2023</a>)</cite>.
In addressing this problem, a common strategy is multi-step generation, through which the overall generation process is manually decomposed into a chain of simpler sub-tasks <math id="S3.SS1.SSS2.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{T}_{1:k}" display="inline"><semantics id="S3.SS1.SSS2.p1.2.m2.1a"><msub id="S3.SS1.SSS2.p1.2.m2.1.1" xref="S3.SS1.SSS2.p1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.SSS2.p1.2.m2.1.1.2" xref="S3.SS1.SSS2.p1.2.m2.1.1.2.cmml">ğ’¯</mi><mrow id="S3.SS1.SSS2.p1.2.m2.1.1.3" xref="S3.SS1.SSS2.p1.2.m2.1.1.3.cmml"><mn id="S3.SS1.SSS2.p1.2.m2.1.1.3.2" xref="S3.SS1.SSS2.p1.2.m2.1.1.3.2.cmml">1</mn><mo lspace="0.278em" rspace="0.278em" id="S3.SS1.SSS2.p1.2.m2.1.1.3.1" xref="S3.SS1.SSS2.p1.2.m2.1.1.3.1.cmml">:</mo><mi id="S3.SS1.SSS2.p1.2.m2.1.1.3.3" xref="S3.SS1.SSS2.p1.2.m2.1.1.3.3.cmml">k</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p1.2.m2.1b"><apply id="S3.SS1.SSS2.p1.2.m2.1.1.cmml" xref="S3.SS1.SSS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p1.2.m2.1.1.1.cmml" xref="S3.SS1.SSS2.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.SSS2.p1.2.m2.1.1.2.cmml" xref="S3.SS1.SSS2.p1.2.m2.1.1.2">ğ’¯</ci><apply id="S3.SS1.SSS2.p1.2.m2.1.1.3.cmml" xref="S3.SS1.SSS2.p1.2.m2.1.1.3"><ci id="S3.SS1.SSS2.p1.2.m2.1.1.3.1.cmml" xref="S3.SS1.SSS2.p1.2.m2.1.1.3.1">:</ci><cn type="integer" id="S3.SS1.SSS2.p1.2.m2.1.1.3.2.cmml" xref="S3.SS1.SSS2.p1.2.m2.1.1.3.2">1</cn><ci id="S3.SS1.SSS2.p1.2.m2.1.1.3.3.cmml" xref="S3.SS1.SSS2.p1.2.m2.1.1.3.3">ğ‘˜</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p1.2.m2.1c">\mathcal{T}_{1:k}</annotation></semantics></math>, to force the LLMs to produce data in a step-by-step manner as scheduled:</p>
<table id="S3.E4" class="ltx_equationgroup ltx_eqn_table">
<tbody>
<tr id="S3.E4X" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E4X.2.1.1.m1.1" class="ltx_math_unparsed" alttext="\displaystyle\mathcal{D}_{i}\leftarrow\mathcal{M}^{i}_{p_{i}}(\mathcal{T}_{i}," display="inline"><semantics id="S3.E4X.2.1.1.m1.1a"><mrow id="S3.E4X.2.1.1.m1.1b"><msub id="S3.E4X.2.1.1.m1.1.1"><mi class="ltx_font_mathcaligraphic" id="S3.E4X.2.1.1.m1.1.1.2">ğ’Ÿ</mi><mi id="S3.E4X.2.1.1.m1.1.1.3">i</mi></msub><mo stretchy="false" id="S3.E4X.2.1.1.m1.1.2">â†</mo><msubsup id="S3.E4X.2.1.1.m1.1.3"><mi class="ltx_font_mathcaligraphic" id="S3.E4X.2.1.1.m1.1.3.2.2">â„³</mi><msub id="S3.E4X.2.1.1.m1.1.3.3"><mi id="S3.E4X.2.1.1.m1.1.3.3.2">p</mi><mi id="S3.E4X.2.1.1.m1.1.3.3.3">i</mi></msub><mi id="S3.E4X.2.1.1.m1.1.3.2.3">i</mi></msubsup><mrow id="S3.E4X.2.1.1.m1.1.4"><mo stretchy="false" id="S3.E4X.2.1.1.m1.1.4.1">(</mo><msub id="S3.E4X.2.1.1.m1.1.4.2"><mi class="ltx_font_mathcaligraphic" id="S3.E4X.2.1.1.m1.1.4.2.2">ğ’¯</mi><mi id="S3.E4X.2.1.1.m1.1.4.2.3">i</mi></msub><mo id="S3.E4X.2.1.1.m1.1.4.3">,</mo></mrow></mrow><annotation encoding="application/x-tex" id="S3.E4X.2.1.1.m1.1c">\displaystyle\mathcal{D}_{i}\leftarrow\mathcal{M}^{i}_{p_{i}}(\mathcal{T}_{i},</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S3.E4X.3.2.2.m1.1" class="ltx_math_unparsed" alttext="\displaystyle\mathcal{D}_{0:i-1}),\ i=1,2,\cdots,k\text{,}" display="inline"><semantics id="S3.E4X.3.2.2.m1.1a"><mrow id="S3.E4X.3.2.2.m1.1b"><msub id="S3.E4X.3.2.2.m1.1.1"><mi class="ltx_font_mathcaligraphic" id="S3.E4X.3.2.2.m1.1.1.2">ğ’Ÿ</mi><mrow id="S3.E4X.3.2.2.m1.1.1.3"><mn id="S3.E4X.3.2.2.m1.1.1.3.2">0</mn><mo lspace="0.278em" rspace="0.278em" id="S3.E4X.3.2.2.m1.1.1.3.1">:</mo><mrow id="S3.E4X.3.2.2.m1.1.1.3.3"><mi id="S3.E4X.3.2.2.m1.1.1.3.3.2">i</mi><mo id="S3.E4X.3.2.2.m1.1.1.3.3.1">âˆ’</mo><mn id="S3.E4X.3.2.2.m1.1.1.3.3.3">1</mn></mrow></mrow></msub><mo stretchy="false" id="S3.E4X.3.2.2.m1.1.2">)</mo><mo rspace="0.667em" id="S3.E4X.3.2.2.m1.1.3">,</mo><mi id="S3.E4X.3.2.2.m1.1.4">i</mi><mo id="S3.E4X.3.2.2.m1.1.5">=</mo><mn id="S3.E4X.3.2.2.m1.1.6">1</mn><mo id="S3.E4X.3.2.2.m1.1.7">,</mo><mn id="S3.E4X.3.2.2.m1.1.8">2</mn><mo id="S3.E4X.3.2.2.m1.1.9">,</mo><mi mathvariant="normal" id="S3.E4X.3.2.2.m1.1.10">â‹¯</mi><mo id="S3.E4X.3.2.2.m1.1.11">,</mo><mi id="S3.E4X.3.2.2.m1.1.12">k</mi><mtext id="S3.E4X.3.2.2.m1.1.13">,</mtext></mrow><annotation encoding="application/x-tex" id="S3.E4X.3.2.2.m1.1c">\displaystyle\mathcal{D}_{0:i-1}),\ i=1,2,\cdots,k\text{,}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(4)</span></td>
</tr>
</tbody>
</table>
<p id="S3.SS1.SSS2.p1.7" class="ltx_p">where <math id="S3.SS1.SSS2.p1.3.m1.1" class="ltx_Math" alttext="\mathcal{D}_{0}=\mathcal{D}_{\text{sup}}" display="inline"><semantics id="S3.SS1.SSS2.p1.3.m1.1a"><mrow id="S3.SS1.SSS2.p1.3.m1.1.1" xref="S3.SS1.SSS2.p1.3.m1.1.1.cmml"><msub id="S3.SS1.SSS2.p1.3.m1.1.1.2" xref="S3.SS1.SSS2.p1.3.m1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.SSS2.p1.3.m1.1.1.2.2" xref="S3.SS1.SSS2.p1.3.m1.1.1.2.2.cmml">ğ’Ÿ</mi><mn id="S3.SS1.SSS2.p1.3.m1.1.1.2.3" xref="S3.SS1.SSS2.p1.3.m1.1.1.2.3.cmml">0</mn></msub><mo id="S3.SS1.SSS2.p1.3.m1.1.1.1" xref="S3.SS1.SSS2.p1.3.m1.1.1.1.cmml">=</mo><msub id="S3.SS1.SSS2.p1.3.m1.1.1.3" xref="S3.SS1.SSS2.p1.3.m1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.SSS2.p1.3.m1.1.1.3.2" xref="S3.SS1.SSS2.p1.3.m1.1.1.3.2.cmml">ğ’Ÿ</mi><mtext id="S3.SS1.SSS2.p1.3.m1.1.1.3.3" xref="S3.SS1.SSS2.p1.3.m1.1.1.3.3a.cmml">sup</mtext></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p1.3.m1.1b"><apply id="S3.SS1.SSS2.p1.3.m1.1.1.cmml" xref="S3.SS1.SSS2.p1.3.m1.1.1"><eq id="S3.SS1.SSS2.p1.3.m1.1.1.1.cmml" xref="S3.SS1.SSS2.p1.3.m1.1.1.1"></eq><apply id="S3.SS1.SSS2.p1.3.m1.1.1.2.cmml" xref="S3.SS1.SSS2.p1.3.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p1.3.m1.1.1.2.1.cmml" xref="S3.SS1.SSS2.p1.3.m1.1.1.2">subscript</csymbol><ci id="S3.SS1.SSS2.p1.3.m1.1.1.2.2.cmml" xref="S3.SS1.SSS2.p1.3.m1.1.1.2.2">ğ’Ÿ</ci><cn type="integer" id="S3.SS1.SSS2.p1.3.m1.1.1.2.3.cmml" xref="S3.SS1.SSS2.p1.3.m1.1.1.2.3">0</cn></apply><apply id="S3.SS1.SSS2.p1.3.m1.1.1.3.cmml" xref="S3.SS1.SSS2.p1.3.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p1.3.m1.1.1.3.1.cmml" xref="S3.SS1.SSS2.p1.3.m1.1.1.3">subscript</csymbol><ci id="S3.SS1.SSS2.p1.3.m1.1.1.3.2.cmml" xref="S3.SS1.SSS2.p1.3.m1.1.1.3.2">ğ’Ÿ</ci><ci id="S3.SS1.SSS2.p1.3.m1.1.1.3.3a.cmml" xref="S3.SS1.SSS2.p1.3.m1.1.1.3.3"><mtext mathsize="70%" id="S3.SS1.SSS2.p1.3.m1.1.1.3.3.cmml" xref="S3.SS1.SSS2.p1.3.m1.1.1.3.3">sup</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p1.3.m1.1c">\mathcal{D}_{0}=\mathcal{D}_{\text{sup}}</annotation></semantics></math>. Each intermediate output <math id="S3.SS1.SSS2.p1.4.m2.1" class="ltx_Math" alttext="\mathcal{D}_{i}" display="inline"><semantics id="S3.SS1.SSS2.p1.4.m2.1a"><msub id="S3.SS1.SSS2.p1.4.m2.1.1" xref="S3.SS1.SSS2.p1.4.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.SSS2.p1.4.m2.1.1.2" xref="S3.SS1.SSS2.p1.4.m2.1.1.2.cmml">ğ’Ÿ</mi><mi id="S3.SS1.SSS2.p1.4.m2.1.1.3" xref="S3.SS1.SSS2.p1.4.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p1.4.m2.1b"><apply id="S3.SS1.SSS2.p1.4.m2.1.1.cmml" xref="S3.SS1.SSS2.p1.4.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p1.4.m2.1.1.1.cmml" xref="S3.SS1.SSS2.p1.4.m2.1.1">subscript</csymbol><ci id="S3.SS1.SSS2.p1.4.m2.1.1.2.cmml" xref="S3.SS1.SSS2.p1.4.m2.1.1.2">ğ’Ÿ</ci><ci id="S3.SS1.SSS2.p1.4.m2.1.1.3.cmml" xref="S3.SS1.SSS2.p1.4.m2.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p1.4.m2.1c">\mathcal{D}_{i}</annotation></semantics></math> is generated using model <math id="S3.SS1.SSS2.p1.5.m3.1" class="ltx_Math" alttext="\mathcal{M}^{i}" display="inline"><semantics id="S3.SS1.SSS2.p1.5.m3.1a"><msup id="S3.SS1.SSS2.p1.5.m3.1.1" xref="S3.SS1.SSS2.p1.5.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.SSS2.p1.5.m3.1.1.2" xref="S3.SS1.SSS2.p1.5.m3.1.1.2.cmml">â„³</mi><mi id="S3.SS1.SSS2.p1.5.m3.1.1.3" xref="S3.SS1.SSS2.p1.5.m3.1.1.3.cmml">i</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p1.5.m3.1b"><apply id="S3.SS1.SSS2.p1.5.m3.1.1.cmml" xref="S3.SS1.SSS2.p1.5.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p1.5.m3.1.1.1.cmml" xref="S3.SS1.SSS2.p1.5.m3.1.1">superscript</csymbol><ci id="S3.SS1.SSS2.p1.5.m3.1.1.2.cmml" xref="S3.SS1.SSS2.p1.5.m3.1.1.2">â„³</ci><ci id="S3.SS1.SSS2.p1.5.m3.1.1.3.cmml" xref="S3.SS1.SSS2.p1.5.m3.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p1.5.m3.1c">\mathcal{M}^{i}</annotation></semantics></math>, prompted by <math id="S3.SS1.SSS2.p1.6.m4.1" class="ltx_Math" alttext="p_{i}" display="inline"><semantics id="S3.SS1.SSS2.p1.6.m4.1a"><msub id="S3.SS1.SSS2.p1.6.m4.1.1" xref="S3.SS1.SSS2.p1.6.m4.1.1.cmml"><mi id="S3.SS1.SSS2.p1.6.m4.1.1.2" xref="S3.SS1.SSS2.p1.6.m4.1.1.2.cmml">p</mi><mi id="S3.SS1.SSS2.p1.6.m4.1.1.3" xref="S3.SS1.SSS2.p1.6.m4.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p1.6.m4.1b"><apply id="S3.SS1.SSS2.p1.6.m4.1.1.cmml" xref="S3.SS1.SSS2.p1.6.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p1.6.m4.1.1.1.cmml" xref="S3.SS1.SSS2.p1.6.m4.1.1">subscript</csymbol><ci id="S3.SS1.SSS2.p1.6.m4.1.1.2.cmml" xref="S3.SS1.SSS2.p1.6.m4.1.1.2">ğ‘</ci><ci id="S3.SS1.SSS2.p1.6.m4.1.1.3.cmml" xref="S3.SS1.SSS2.p1.6.m4.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p1.6.m4.1c">p_{i}</annotation></semantics></math>, for a sub-task <math id="S3.SS1.SSS2.p1.7.m5.1" class="ltx_Math" alttext="\mathcal{T}_{i}" display="inline"><semantics id="S3.SS1.SSS2.p1.7.m5.1a"><msub id="S3.SS1.SSS2.p1.7.m5.1.1" xref="S3.SS1.SSS2.p1.7.m5.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.SSS2.p1.7.m5.1.1.2" xref="S3.SS1.SSS2.p1.7.m5.1.1.2.cmml">ğ’¯</mi><mi id="S3.SS1.SSS2.p1.7.m5.1.1.3" xref="S3.SS1.SSS2.p1.7.m5.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p1.7.m5.1b"><apply id="S3.SS1.SSS2.p1.7.m5.1.1.cmml" xref="S3.SS1.SSS2.p1.7.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p1.7.m5.1.1.1.cmml" xref="S3.SS1.SSS2.p1.7.m5.1.1">subscript</csymbol><ci id="S3.SS1.SSS2.p1.7.m5.1.1.2.cmml" xref="S3.SS1.SSS2.p1.7.m5.1.1.2">ğ’¯</ci><ci id="S3.SS1.SSS2.p1.7.m5.1.1.3.cmml" xref="S3.SS1.SSS2.p1.7.m5.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p1.7.m5.1c">\mathcal{T}_{i}</annotation></semantics></math>. These outputs can then potentially be used in subsequent generations. By manually scheduling the generation procedure, we implicitly align the reasoning paths of LLMs with human prior knowledge.
Specifically, there are two common strategies for task decomposition: <span id="S3.SS1.SSS2.p1.7.1" class="ltx_text ltx_font_italic">sample-wise</span> and <span id="S3.SS1.SSS2.p1.7.2" class="ltx_text ltx_font_italic">dataset-wise</span> decomposition, which mainly aim at enhancing the quality of synthetic data at different scales.</p>
</div>
<section id="S3.SS1.SSS2.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Sample-Wise Decomposition.</h5>

<div id="S3.SS1.SSS2.Px1.p1" class="ltx_para">
<p id="S3.SS1.SSS2.Px1.p1.2" class="ltx_p">A typical use-case of multi-step generation is for addressing the challenges of long-text processing and logical reasoning when dealing with multi-text data such as dialogues and entity-relation triplets. In such cases, a straightforward approach is to divide the sample into smaller chunks and generate only a portion of each sample at a time <cite class="ltx_cite ltx_citemacro_cite">Li etÂ al. (<a href="#bib.bib47" title="" class="ltx_ref">2022</a>); Ye etÂ al. (<a href="#bib.bib103" title="" class="ltx_ref">2023</a>); Wang etÂ al. (<a href="#bib.bib91" title="" class="ltx_ref">2023e</a>)</cite>. In this way, <math id="S3.SS1.SSS2.Px1.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{D}_{1:k}" display="inline"><semantics id="S3.SS1.SSS2.Px1.p1.1.m1.1a"><msub id="S3.SS1.SSS2.Px1.p1.1.m1.1.1" xref="S3.SS1.SSS2.Px1.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.SSS2.Px1.p1.1.m1.1.1.2" xref="S3.SS1.SSS2.Px1.p1.1.m1.1.1.2.cmml">ğ’Ÿ</mi><mrow id="S3.SS1.SSS2.Px1.p1.1.m1.1.1.3" xref="S3.SS1.SSS2.Px1.p1.1.m1.1.1.3.cmml"><mn id="S3.SS1.SSS2.Px1.p1.1.m1.1.1.3.2" xref="S3.SS1.SSS2.Px1.p1.1.m1.1.1.3.2.cmml">1</mn><mo lspace="0.278em" rspace="0.278em" id="S3.SS1.SSS2.Px1.p1.1.m1.1.1.3.1" xref="S3.SS1.SSS2.Px1.p1.1.m1.1.1.3.1.cmml">:</mo><mi id="S3.SS1.SSS2.Px1.p1.1.m1.1.1.3.3" xref="S3.SS1.SSS2.Px1.p1.1.m1.1.1.3.3.cmml">k</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.Px1.p1.1.m1.1b"><apply id="S3.SS1.SSS2.Px1.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS2.Px1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.Px1.p1.1.m1.1.1.1.cmml" xref="S3.SS1.SSS2.Px1.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.SSS2.Px1.p1.1.m1.1.1.2.cmml" xref="S3.SS1.SSS2.Px1.p1.1.m1.1.1.2">ğ’Ÿ</ci><apply id="S3.SS1.SSS2.Px1.p1.1.m1.1.1.3.cmml" xref="S3.SS1.SSS2.Px1.p1.1.m1.1.1.3"><ci id="S3.SS1.SSS2.Px1.p1.1.m1.1.1.3.1.cmml" xref="S3.SS1.SSS2.Px1.p1.1.m1.1.1.3.1">:</ci><cn type="integer" id="S3.SS1.SSS2.Px1.p1.1.m1.1.1.3.2.cmml" xref="S3.SS1.SSS2.Px1.p1.1.m1.1.1.3.2">1</cn><ci id="S3.SS1.SSS2.Px1.p1.1.m1.1.1.3.3.cmml" xref="S3.SS1.SSS2.Px1.p1.1.m1.1.1.3.3">ğ‘˜</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.Px1.p1.1.m1.1c">\mathcal{D}_{1:k}</annotation></semantics></math> can be considered as different parts of <math id="S3.SS1.SSS2.Px1.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{D}_{\text{gen}}" display="inline"><semantics id="S3.SS1.SSS2.Px1.p1.2.m2.1a"><msub id="S3.SS1.SSS2.Px1.p1.2.m2.1.1" xref="S3.SS1.SSS2.Px1.p1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.SSS2.Px1.p1.2.m2.1.1.2" xref="S3.SS1.SSS2.Px1.p1.2.m2.1.1.2.cmml">ğ’Ÿ</mi><mtext id="S3.SS1.SSS2.Px1.p1.2.m2.1.1.3" xref="S3.SS1.SSS2.Px1.p1.2.m2.1.1.3a.cmml">gen</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.Px1.p1.2.m2.1b"><apply id="S3.SS1.SSS2.Px1.p1.2.m2.1.1.cmml" xref="S3.SS1.SSS2.Px1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.Px1.p1.2.m2.1.1.1.cmml" xref="S3.SS1.SSS2.Px1.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.SSS2.Px1.p1.2.m2.1.1.2.cmml" xref="S3.SS1.SSS2.Px1.p1.2.m2.1.1.2">ğ’Ÿ</ci><ci id="S3.SS1.SSS2.Px1.p1.2.m2.1.1.3a.cmml" xref="S3.SS1.SSS2.Px1.p1.2.m2.1.1.3"><mtext mathsize="70%" id="S3.SS1.SSS2.Px1.p1.2.m2.1.1.3.cmml" xref="S3.SS1.SSS2.Px1.p1.2.m2.1.1.3">gen</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.Px1.p1.2.m2.1c">\mathcal{D}_{\text{gen}}</annotation></semantics></math>:</p>
<table id="S3.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E5.m1.4" class="ltx_Math" alttext="\mathcal{D}_{\text{gen}}=(\mathcal{D}_{1},\mathcal{D}_{2},\cdots,\mathcal{D}_{k})\text{.}" display="block"><semantics id="S3.E5.m1.4a"><mrow id="S3.E5.m1.4.4" xref="S3.E5.m1.4.4.cmml"><msub id="S3.E5.m1.4.4.5" xref="S3.E5.m1.4.4.5.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E5.m1.4.4.5.2" xref="S3.E5.m1.4.4.5.2.cmml">ğ’Ÿ</mi><mtext id="S3.E5.m1.4.4.5.3" xref="S3.E5.m1.4.4.5.3a.cmml">gen</mtext></msub><mo id="S3.E5.m1.4.4.4" xref="S3.E5.m1.4.4.4.cmml">=</mo><mrow id="S3.E5.m1.4.4.3" xref="S3.E5.m1.4.4.3.cmml"><mrow id="S3.E5.m1.4.4.3.3.3" xref="S3.E5.m1.4.4.3.3.4.cmml"><mo stretchy="false" id="S3.E5.m1.4.4.3.3.3.4" xref="S3.E5.m1.4.4.3.3.4.cmml">(</mo><msub id="S3.E5.m1.2.2.1.1.1.1" xref="S3.E5.m1.2.2.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E5.m1.2.2.1.1.1.1.2" xref="S3.E5.m1.2.2.1.1.1.1.2.cmml">ğ’Ÿ</mi><mn id="S3.E5.m1.2.2.1.1.1.1.3" xref="S3.E5.m1.2.2.1.1.1.1.3.cmml">1</mn></msub><mo id="S3.E5.m1.4.4.3.3.3.5" xref="S3.E5.m1.4.4.3.3.4.cmml">,</mo><msub id="S3.E5.m1.3.3.2.2.2.2" xref="S3.E5.m1.3.3.2.2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E5.m1.3.3.2.2.2.2.2" xref="S3.E5.m1.3.3.2.2.2.2.2.cmml">ğ’Ÿ</mi><mn id="S3.E5.m1.3.3.2.2.2.2.3" xref="S3.E5.m1.3.3.2.2.2.2.3.cmml">2</mn></msub><mo id="S3.E5.m1.4.4.3.3.3.6" xref="S3.E5.m1.4.4.3.3.4.cmml">,</mo><mi mathvariant="normal" id="S3.E5.m1.1.1" xref="S3.E5.m1.1.1.cmml">â‹¯</mi><mo id="S3.E5.m1.4.4.3.3.3.7" xref="S3.E5.m1.4.4.3.3.4.cmml">,</mo><msub id="S3.E5.m1.4.4.3.3.3.3" xref="S3.E5.m1.4.4.3.3.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E5.m1.4.4.3.3.3.3.2" xref="S3.E5.m1.4.4.3.3.3.3.2.cmml">ğ’Ÿ</mi><mi id="S3.E5.m1.4.4.3.3.3.3.3" xref="S3.E5.m1.4.4.3.3.3.3.3.cmml">k</mi></msub><mo stretchy="false" id="S3.E5.m1.4.4.3.3.3.8" xref="S3.E5.m1.4.4.3.3.4.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S3.E5.m1.4.4.3.4" xref="S3.E5.m1.4.4.3.4.cmml">â€‹</mo><mtext id="S3.E5.m1.4.4.3.5" xref="S3.E5.m1.4.4.3.5a.cmml">.</mtext></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E5.m1.4b"><apply id="S3.E5.m1.4.4.cmml" xref="S3.E5.m1.4.4"><eq id="S3.E5.m1.4.4.4.cmml" xref="S3.E5.m1.4.4.4"></eq><apply id="S3.E5.m1.4.4.5.cmml" xref="S3.E5.m1.4.4.5"><csymbol cd="ambiguous" id="S3.E5.m1.4.4.5.1.cmml" xref="S3.E5.m1.4.4.5">subscript</csymbol><ci id="S3.E5.m1.4.4.5.2.cmml" xref="S3.E5.m1.4.4.5.2">ğ’Ÿ</ci><ci id="S3.E5.m1.4.4.5.3a.cmml" xref="S3.E5.m1.4.4.5.3"><mtext mathsize="70%" id="S3.E5.m1.4.4.5.3.cmml" xref="S3.E5.m1.4.4.5.3">gen</mtext></ci></apply><apply id="S3.E5.m1.4.4.3.cmml" xref="S3.E5.m1.4.4.3"><times id="S3.E5.m1.4.4.3.4.cmml" xref="S3.E5.m1.4.4.3.4"></times><vector id="S3.E5.m1.4.4.3.3.4.cmml" xref="S3.E5.m1.4.4.3.3.3"><apply id="S3.E5.m1.2.2.1.1.1.1.cmml" xref="S3.E5.m1.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S3.E5.m1.2.2.1.1.1.1.1.cmml" xref="S3.E5.m1.2.2.1.1.1.1">subscript</csymbol><ci id="S3.E5.m1.2.2.1.1.1.1.2.cmml" xref="S3.E5.m1.2.2.1.1.1.1.2">ğ’Ÿ</ci><cn type="integer" id="S3.E5.m1.2.2.1.1.1.1.3.cmml" xref="S3.E5.m1.2.2.1.1.1.1.3">1</cn></apply><apply id="S3.E5.m1.3.3.2.2.2.2.cmml" xref="S3.E5.m1.3.3.2.2.2.2"><csymbol cd="ambiguous" id="S3.E5.m1.3.3.2.2.2.2.1.cmml" xref="S3.E5.m1.3.3.2.2.2.2">subscript</csymbol><ci id="S3.E5.m1.3.3.2.2.2.2.2.cmml" xref="S3.E5.m1.3.3.2.2.2.2.2">ğ’Ÿ</ci><cn type="integer" id="S3.E5.m1.3.3.2.2.2.2.3.cmml" xref="S3.E5.m1.3.3.2.2.2.2.3">2</cn></apply><ci id="S3.E5.m1.1.1.cmml" xref="S3.E5.m1.1.1">â‹¯</ci><apply id="S3.E5.m1.4.4.3.3.3.3.cmml" xref="S3.E5.m1.4.4.3.3.3.3"><csymbol cd="ambiguous" id="S3.E5.m1.4.4.3.3.3.3.1.cmml" xref="S3.E5.m1.4.4.3.3.3.3">subscript</csymbol><ci id="S3.E5.m1.4.4.3.3.3.3.2.cmml" xref="S3.E5.m1.4.4.3.3.3.3.2">ğ’Ÿ</ci><ci id="S3.E5.m1.4.4.3.3.3.3.3.cmml" xref="S3.E5.m1.4.4.3.3.3.3.3">ğ‘˜</ci></apply></vector><ci id="S3.E5.m1.4.4.3.5a.cmml" xref="S3.E5.m1.4.4.3.5"><mtext id="S3.E5.m1.4.4.3.5.cmml" xref="S3.E5.m1.4.4.3.5">.</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5.m1.4c">\mathcal{D}_{\text{gen}}=(\mathcal{D}_{1},\mathcal{D}_{2},\cdots,\mathcal{D}_{k})\text{.}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.SSS2.Px1.p1.5" class="ltx_p">Notably, as shown in Eq.Â <a href="#S3.E4" title="In 3.1.2 Multi-Step Generation â€£ 3.1 Data Generation â€£ 3 Generic Workflow â€£ On LLMs-Driven Synthetic Data Generation, Curation, and Evaluation: A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, each iteration of the generation process can be conditioned on the previously generated contents. For example, <cite class="ltx_cite ltx_citemacro_citet">Ding etÂ al. (<a href="#bib.bib15" title="" class="ltx_ref">2023b</a>)</cite> prompts the LLMs to alternate between acting as the assistant and the user, replying to each other based on the context, ultimately producing a complete conversation transcript. In this way, the coherence among each internal component <math id="S3.SS1.SSS2.Px1.p1.3.m1.1" class="ltx_Math" alttext="\mathcal{D}_{i}" display="inline"><semantics id="S3.SS1.SSS2.Px1.p1.3.m1.1a"><msub id="S3.SS1.SSS2.Px1.p1.3.m1.1.1" xref="S3.SS1.SSS2.Px1.p1.3.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.SSS2.Px1.p1.3.m1.1.1.2" xref="S3.SS1.SSS2.Px1.p1.3.m1.1.1.2.cmml">ğ’Ÿ</mi><mi id="S3.SS1.SSS2.Px1.p1.3.m1.1.1.3" xref="S3.SS1.SSS2.Px1.p1.3.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.Px1.p1.3.m1.1b"><apply id="S3.SS1.SSS2.Px1.p1.3.m1.1.1.cmml" xref="S3.SS1.SSS2.Px1.p1.3.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.Px1.p1.3.m1.1.1.1.cmml" xref="S3.SS1.SSS2.Px1.p1.3.m1.1.1">subscript</csymbol><ci id="S3.SS1.SSS2.Px1.p1.3.m1.1.1.2.cmml" xref="S3.SS1.SSS2.Px1.p1.3.m1.1.1.2">ğ’Ÿ</ci><ci id="S3.SS1.SSS2.Px1.p1.3.m1.1.1.3.cmml" xref="S3.SS1.SSS2.Px1.p1.3.m1.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.Px1.p1.3.m1.1c">\mathcal{D}_{i}</annotation></semantics></math> can be pointedly reinforced with separated instructions, thus making it easier for the model to follow the requirements and generate more faithful data. It should be noted that <math id="S3.SS1.SSS2.Px1.p1.4.m2.1" class="ltx_Math" alttext="D_{1:k}" display="inline"><semantics id="S3.SS1.SSS2.Px1.p1.4.m2.1a"><msub id="S3.SS1.SSS2.Px1.p1.4.m2.1.1" xref="S3.SS1.SSS2.Px1.p1.4.m2.1.1.cmml"><mi id="S3.SS1.SSS2.Px1.p1.4.m2.1.1.2" xref="S3.SS1.SSS2.Px1.p1.4.m2.1.1.2.cmml">D</mi><mrow id="S3.SS1.SSS2.Px1.p1.4.m2.1.1.3" xref="S3.SS1.SSS2.Px1.p1.4.m2.1.1.3.cmml"><mn id="S3.SS1.SSS2.Px1.p1.4.m2.1.1.3.2" xref="S3.SS1.SSS2.Px1.p1.4.m2.1.1.3.2.cmml">1</mn><mo lspace="0.278em" rspace="0.278em" id="S3.SS1.SSS2.Px1.p1.4.m2.1.1.3.1" xref="S3.SS1.SSS2.Px1.p1.4.m2.1.1.3.1.cmml">:</mo><mi id="S3.SS1.SSS2.Px1.p1.4.m2.1.1.3.3" xref="S3.SS1.SSS2.Px1.p1.4.m2.1.1.3.3.cmml">k</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.Px1.p1.4.m2.1b"><apply id="S3.SS1.SSS2.Px1.p1.4.m2.1.1.cmml" xref="S3.SS1.SSS2.Px1.p1.4.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.Px1.p1.4.m2.1.1.1.cmml" xref="S3.SS1.SSS2.Px1.p1.4.m2.1.1">subscript</csymbol><ci id="S3.SS1.SSS2.Px1.p1.4.m2.1.1.2.cmml" xref="S3.SS1.SSS2.Px1.p1.4.m2.1.1.2">ğ·</ci><apply id="S3.SS1.SSS2.Px1.p1.4.m2.1.1.3.cmml" xref="S3.SS1.SSS2.Px1.p1.4.m2.1.1.3"><ci id="S3.SS1.SSS2.Px1.p1.4.m2.1.1.3.1.cmml" xref="S3.SS1.SSS2.Px1.p1.4.m2.1.1.3.1">:</ci><cn type="integer" id="S3.SS1.SSS2.Px1.p1.4.m2.1.1.3.2.cmml" xref="S3.SS1.SSS2.Px1.p1.4.m2.1.1.3.2">1</cn><ci id="S3.SS1.SSS2.Px1.p1.4.m2.1.1.3.3.cmml" xref="S3.SS1.SSS2.Px1.p1.4.m2.1.1.3.3">ğ‘˜</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.Px1.p1.4.m2.1c">D_{1:k}</annotation></semantics></math> may not necessarily form part of the final <math id="S3.SS1.SSS2.Px1.p1.5.m3.1" class="ltx_Math" alttext="D_{\text{gen}}" display="inline"><semantics id="S3.SS1.SSS2.Px1.p1.5.m3.1a"><msub id="S3.SS1.SSS2.Px1.p1.5.m3.1.1" xref="S3.SS1.SSS2.Px1.p1.5.m3.1.1.cmml"><mi id="S3.SS1.SSS2.Px1.p1.5.m3.1.1.2" xref="S3.SS1.SSS2.Px1.p1.5.m3.1.1.2.cmml">D</mi><mtext id="S3.SS1.SSS2.Px1.p1.5.m3.1.1.3" xref="S3.SS1.SSS2.Px1.p1.5.m3.1.1.3a.cmml">gen</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.Px1.p1.5.m3.1b"><apply id="S3.SS1.SSS2.Px1.p1.5.m3.1.1.cmml" xref="S3.SS1.SSS2.Px1.p1.5.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.Px1.p1.5.m3.1.1.1.cmml" xref="S3.SS1.SSS2.Px1.p1.5.m3.1.1">subscript</csymbol><ci id="S3.SS1.SSS2.Px1.p1.5.m3.1.1.2.cmml" xref="S3.SS1.SSS2.Px1.p1.5.m3.1.1.2">ğ·</ci><ci id="S3.SS1.SSS2.Px1.p1.5.m3.1.1.3a.cmml" xref="S3.SS1.SSS2.Px1.p1.5.m3.1.1.3"><mtext mathsize="70%" id="S3.SS1.SSS2.Px1.p1.5.m3.1.1.3.cmml" xref="S3.SS1.SSS2.Px1.p1.5.m3.1.1.3">gen</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.Px1.p1.5.m3.1c">D_{\text{gen}}</annotation></semantics></math>, instead, explicitly outputting some intermediate reasoning steps can also improve the generation of complex data <cite class="ltx_cite ltx_citemacro_cite">Bai etÂ al. (<a href="#bib.bib2" title="" class="ltx_ref">2022</a>); He etÂ al. (<a href="#bib.bib29" title="" class="ltx_ref">2023</a>)</cite>. Chain-of-Thought (CoT) prompting stands out as one of the most popular strategies for improving the faithfulness of LLM-generated contentÂ <cite class="ltx_cite ltx_citemacro_cite">Wei etÂ al. (<a href="#bib.bib94" title="" class="ltx_ref">2022</a>)</cite>. Nevertheless, current research on the exploration of such latent metadata is still insufficient, leaving sample-wise task decomposition from a reasoning perspective an open problem for future studies.</p>
</div>
</section>
<section id="S3.SS1.SSS2.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Dataset-Wise Decomposition.</h5>

<div id="S3.SS1.SSS2.Px2.p1" class="ltx_para">
<p id="S3.SS1.SSS2.Px2.p1.1" class="ltx_p">In SectionÂ <a href="#S3.SS1.SSS1.Px2" title="Conditional Prompting. â€£ 3.1.1 Prompt Engineering â€£ 3.1 Data Generation â€£ 3 Generic Workflow â€£ On LLMs-Driven Synthetic Data Generation, Curation, and Evaluation: A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1.1</span></a> we have introduced how to generate data with specified properties. However, generating a series of such data that can eventually form a dataset with good diversity and domain coverage requires long-term scheduling. To this end, dataset-wise task decomposition dynamically adjusts the conditions used at each stage of multi-step generation to ensure the overall dataset grows in the right direction:</p>
<table id="S3.E6" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E6.m1.1" class="ltx_Math" alttext="\mathcal{D}_{\text{gen}}=\bigcup_{i=1}^{k}\mathcal{D}_{i}\text{.}" display="block"><semantics id="S3.E6.m1.1a"><mrow id="S3.E6.m1.1.1" xref="S3.E6.m1.1.1.cmml"><msub id="S3.E6.m1.1.1.2" xref="S3.E6.m1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E6.m1.1.1.2.2" xref="S3.E6.m1.1.1.2.2.cmml">ğ’Ÿ</mi><mtext id="S3.E6.m1.1.1.2.3" xref="S3.E6.m1.1.1.2.3a.cmml">gen</mtext></msub><mo rspace="0.111em" id="S3.E6.m1.1.1.1" xref="S3.E6.m1.1.1.1.cmml">=</mo><mrow id="S3.E6.m1.1.1.3" xref="S3.E6.m1.1.1.3.cmml"><munderover id="S3.E6.m1.1.1.3.1" xref="S3.E6.m1.1.1.3.1.cmml"><mo movablelimits="false" id="S3.E6.m1.1.1.3.1.2.2" xref="S3.E6.m1.1.1.3.1.2.2.cmml">â‹ƒ</mo><mrow id="S3.E6.m1.1.1.3.1.2.3" xref="S3.E6.m1.1.1.3.1.2.3.cmml"><mi id="S3.E6.m1.1.1.3.1.2.3.2" xref="S3.E6.m1.1.1.3.1.2.3.2.cmml">i</mi><mo id="S3.E6.m1.1.1.3.1.2.3.1" xref="S3.E6.m1.1.1.3.1.2.3.1.cmml">=</mo><mn id="S3.E6.m1.1.1.3.1.2.3.3" xref="S3.E6.m1.1.1.3.1.2.3.3.cmml">1</mn></mrow><mi id="S3.E6.m1.1.1.3.1.3" xref="S3.E6.m1.1.1.3.1.3.cmml">k</mi></munderover><mrow id="S3.E6.m1.1.1.3.2" xref="S3.E6.m1.1.1.3.2.cmml"><msub id="S3.E6.m1.1.1.3.2.2" xref="S3.E6.m1.1.1.3.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E6.m1.1.1.3.2.2.2" xref="S3.E6.m1.1.1.3.2.2.2.cmml">ğ’Ÿ</mi><mi id="S3.E6.m1.1.1.3.2.2.3" xref="S3.E6.m1.1.1.3.2.2.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S3.E6.m1.1.1.3.2.1" xref="S3.E6.m1.1.1.3.2.1.cmml">â€‹</mo><mtext id="S3.E6.m1.1.1.3.2.3" xref="S3.E6.m1.1.1.3.2.3a.cmml">.</mtext></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E6.m1.1b"><apply id="S3.E6.m1.1.1.cmml" xref="S3.E6.m1.1.1"><eq id="S3.E6.m1.1.1.1.cmml" xref="S3.E6.m1.1.1.1"></eq><apply id="S3.E6.m1.1.1.2.cmml" xref="S3.E6.m1.1.1.2"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.2.1.cmml" xref="S3.E6.m1.1.1.2">subscript</csymbol><ci id="S3.E6.m1.1.1.2.2.cmml" xref="S3.E6.m1.1.1.2.2">ğ’Ÿ</ci><ci id="S3.E6.m1.1.1.2.3a.cmml" xref="S3.E6.m1.1.1.2.3"><mtext mathsize="70%" id="S3.E6.m1.1.1.2.3.cmml" xref="S3.E6.m1.1.1.2.3">gen</mtext></ci></apply><apply id="S3.E6.m1.1.1.3.cmml" xref="S3.E6.m1.1.1.3"><apply id="S3.E6.m1.1.1.3.1.cmml" xref="S3.E6.m1.1.1.3.1"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.3.1.1.cmml" xref="S3.E6.m1.1.1.3.1">superscript</csymbol><apply id="S3.E6.m1.1.1.3.1.2.cmml" xref="S3.E6.m1.1.1.3.1"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.3.1.2.1.cmml" xref="S3.E6.m1.1.1.3.1">subscript</csymbol><union id="S3.E6.m1.1.1.3.1.2.2.cmml" xref="S3.E6.m1.1.1.3.1.2.2"></union><apply id="S3.E6.m1.1.1.3.1.2.3.cmml" xref="S3.E6.m1.1.1.3.1.2.3"><eq id="S3.E6.m1.1.1.3.1.2.3.1.cmml" xref="S3.E6.m1.1.1.3.1.2.3.1"></eq><ci id="S3.E6.m1.1.1.3.1.2.3.2.cmml" xref="S3.E6.m1.1.1.3.1.2.3.2">ğ‘–</ci><cn type="integer" id="S3.E6.m1.1.1.3.1.2.3.3.cmml" xref="S3.E6.m1.1.1.3.1.2.3.3">1</cn></apply></apply><ci id="S3.E6.m1.1.1.3.1.3.cmml" xref="S3.E6.m1.1.1.3.1.3">ğ‘˜</ci></apply><apply id="S3.E6.m1.1.1.3.2.cmml" xref="S3.E6.m1.1.1.3.2"><times id="S3.E6.m1.1.1.3.2.1.cmml" xref="S3.E6.m1.1.1.3.2.1"></times><apply id="S3.E6.m1.1.1.3.2.2.cmml" xref="S3.E6.m1.1.1.3.2.2"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.3.2.2.1.cmml" xref="S3.E6.m1.1.1.3.2.2">subscript</csymbol><ci id="S3.E6.m1.1.1.3.2.2.2.cmml" xref="S3.E6.m1.1.1.3.2.2.2">ğ’Ÿ</ci><ci id="S3.E6.m1.1.1.3.2.2.3.cmml" xref="S3.E6.m1.1.1.3.2.2.3">ğ‘–</ci></apply><ci id="S3.E6.m1.1.1.3.2.3a.cmml" xref="S3.E6.m1.1.1.3.2.3"><mtext id="S3.E6.m1.1.1.3.2.3.cmml" xref="S3.E6.m1.1.1.3.2.3">.</mtext></ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E6.m1.1c">\mathcal{D}_{\text{gen}}=\bigcup_{i=1}^{k}\mathcal{D}_{i}\text{.}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.SSS2.Px2.p1.2" class="ltx_p">Specifically, S3 <cite class="ltx_cite ltx_citemacro_cite">Wang etÂ al. (<a href="#bib.bib87" title="" class="ltx_ref">2023b</a>)</cite> targets the most frequently mislabeled categories at each iteration, according to the performance of the downstream model trained on previously generated data.
Similarly, <cite class="ltx_cite ltx_citemacro_citet">Honovich etÂ al. (<a href="#bib.bib33" title="" class="ltx_ref">2023b</a>); Shao etÂ al. (<a href="#bib.bib74" title="" class="ltx_ref">2023</a>)</cite> utilize a generate-then-expand paradigm, to enhance the diversity of the overall dataset accordingly. Some other methods also leverage specific data structures to model the pathways of data generation. For example, Explore-Instruct <cite class="ltx_cite ltx_citemacro_cite">Wan etÂ al. (<a href="#bib.bib84" title="" class="ltx_ref">2023</a>)</cite> models the domain space as a tree structure and continually refines the generated data along with tree traversal to promote both the specialization and domain coverage of the generated data.</p>
</div>
</section>
</section>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Data Curation</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">After the preceding steps, one may excessively generate overflowing and theoretically unlimited data <math id="S3.SS2.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{D}_{\text{gen}}" display="inline"><semantics id="S3.SS2.p1.1.m1.1a"><msub id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p1.1.m1.1.1.2" xref="S3.SS2.p1.1.m1.1.1.2.cmml">ğ’Ÿ</mi><mtext id="S3.SS2.p1.1.m1.1.1.3" xref="S3.SS2.p1.1.m1.1.1.3a.cmml">gen</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><apply id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.1.m1.1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.p1.1.m1.1.1.2.cmml" xref="S3.SS2.p1.1.m1.1.1.2">ğ’Ÿ</ci><ci id="S3.SS2.p1.1.m1.1.1.3a.cmml" xref="S3.SS2.p1.1.m1.1.1.3"><mtext mathsize="70%" id="S3.SS2.p1.1.m1.1.1.3.cmml" xref="S3.SS2.p1.1.m1.1.1.3">gen</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">\mathcal{D}_{\text{gen}}</annotation></semantics></math>. However, these datasets often comprise a considerable portion of noisy, worthless, or even toxic samples, which primarily stems from two causes. Firstly, LLMs can inevitably produce corrupted samples with incorrect labels due to the hallucination problem. Secondly, ineffective prompts containing ambiguous descriptions can trick the model into generating irrelevant or redundant samples. Consequently, directly utilizing these low-quality data without proper processing may have a significant negative impact.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">To address this, plenty of data curation approaches have been studied, which mainly fall into two dominant groups of <span id="S3.SS2.p2.1.1" class="ltx_text ltx_font_italic">high-quality sample filtering</span> and <span id="S3.SS2.p2.1.2" class="ltx_text ltx_font_italic">label enhancement</span> as elaborated below.</p>
</div>
<figure id="S3.F4" class="ltx_figure"><img src="/html/2406.15126/assets/x4.png" id="S3.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="247" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Two dominant approaches of data curation.</figcaption>
</figure>
<section id="S3.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.1 </span>High-Quality Sample Filtering</h4>

<div id="S3.SS2.SSS1.p1" class="ltx_para">
<p id="S3.SS2.SSS1.p1.1" class="ltx_p">Sample filtering aims to weed out undesired low-quality samples and obtain a more helpful subset <math id="S3.SS2.SSS1.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{D}_{\text{curated}}\!\subset\!\mathcal{D}_{\text{gen}}" display="inline"><semantics id="S3.SS2.SSS1.p1.1.m1.1a"><mrow id="S3.SS2.SSS1.p1.1.m1.1.1" xref="S3.SS2.SSS1.p1.1.m1.1.1.cmml"><msub id="S3.SS2.SSS1.p1.1.m1.1.1.2" xref="S3.SS2.SSS1.p1.1.m1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.SSS1.p1.1.m1.1.1.2.2" xref="S3.SS2.SSS1.p1.1.m1.1.1.2.2.cmml">ğ’Ÿ</mi><mtext id="S3.SS2.SSS1.p1.1.m1.1.1.2.3" xref="S3.SS2.SSS1.p1.1.m1.1.1.2.3a.cmml">curated</mtext></msub><mo lspace="0.108em" rspace="0.108em" id="S3.SS2.SSS1.p1.1.m1.1.1.1" xref="S3.SS2.SSS1.p1.1.m1.1.1.1.cmml">âŠ‚</mo><msub id="S3.SS2.SSS1.p1.1.m1.1.1.3" xref="S3.SS2.SSS1.p1.1.m1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.SSS1.p1.1.m1.1.1.3.2" xref="S3.SS2.SSS1.p1.1.m1.1.1.3.2.cmml">ğ’Ÿ</mi><mtext id="S3.SS2.SSS1.p1.1.m1.1.1.3.3" xref="S3.SS2.SSS1.p1.1.m1.1.1.3.3a.cmml">gen</mtext></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p1.1.m1.1b"><apply id="S3.SS2.SSS1.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS1.p1.1.m1.1.1"><subset id="S3.SS2.SSS1.p1.1.m1.1.1.1.cmml" xref="S3.SS2.SSS1.p1.1.m1.1.1.1"></subset><apply id="S3.SS2.SSS1.p1.1.m1.1.1.2.cmml" xref="S3.SS2.SSS1.p1.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p1.1.m1.1.1.2.1.cmml" xref="S3.SS2.SSS1.p1.1.m1.1.1.2">subscript</csymbol><ci id="S3.SS2.SSS1.p1.1.m1.1.1.2.2.cmml" xref="S3.SS2.SSS1.p1.1.m1.1.1.2.2">ğ’Ÿ</ci><ci id="S3.SS2.SSS1.p1.1.m1.1.1.2.3a.cmml" xref="S3.SS2.SSS1.p1.1.m1.1.1.2.3"><mtext mathsize="70%" id="S3.SS2.SSS1.p1.1.m1.1.1.2.3.cmml" xref="S3.SS2.SSS1.p1.1.m1.1.1.2.3">curated</mtext></ci></apply><apply id="S3.SS2.SSS1.p1.1.m1.1.1.3.cmml" xref="S3.SS2.SSS1.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p1.1.m1.1.1.3.1.cmml" xref="S3.SS2.SSS1.p1.1.m1.1.1.3">subscript</csymbol><ci id="S3.SS2.SSS1.p1.1.m1.1.1.3.2.cmml" xref="S3.SS2.SSS1.p1.1.m1.1.1.3.2">ğ’Ÿ</ci><ci id="S3.SS2.SSS1.p1.1.m1.1.1.3.3a.cmml" xref="S3.SS2.SSS1.p1.1.m1.1.1.3.3"><mtext mathsize="70%" id="S3.SS2.SSS1.p1.1.m1.1.1.3.3.cmml" xref="S3.SS2.SSS1.p1.1.m1.1.1.3.3">gen</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p1.1.m1.1c">\mathcal{D}_{\text{curated}}\!\subset\!\mathcal{D}_{\text{gen}}</annotation></semantics></math>. These methods typically design <span id="S3.SS2.SSS1.p1.1.1" class="ltx_text ltx_font_italic">heuristic criteria</span> or <span id="S3.SS2.SSS1.p1.1.2" class="ltx_text ltx_font_italic">re-weighting functions</span> to rerank samples for filtering, as shown in FigureÂ <a href="#S3.F4" title="Figure 4 â€£ 3.2 Data Curation â€£ 3 Generic Workflow â€£ On LLMs-Driven Synthetic Data Generation, Curation, and Evaluation: A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<section id="S3.SS2.SSS1.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Heuristic Metrics.</h5>

<div id="S3.SS2.SSS1.Px1.p1" class="ltx_para">
<p id="S3.SS2.SSS1.Px1.p1.1" class="ltx_p">For methods based on heuristic metrics, the key step is to design appropriate criteria based on the learning dynamics, such as confidence score <cite class="ltx_cite ltx_citemacro_citep">(Seedat etÂ al., <a href="#bib.bib73" title="" class="ltx_ref">2023</a>)</cite>, influence function <cite class="ltx_cite ltx_citemacro_cite">Ye etÂ al. (<a href="#bib.bib102" title="" class="ltx_ref">2022b</a>)</cite>, and generation ability <cite class="ltx_cite ltx_citemacro_cite">Meng etÂ al. (<a href="#bib.bib60" title="" class="ltx_ref">2022</a>)</cite>. SuperGen <cite class="ltx_cite ltx_citemacro_cite">Meng etÂ al. (<a href="#bib.bib60" title="" class="ltx_ref">2022</a>)</cite> employs the estimated generation probability to identify samples most related to the desired label. <cite class="ltx_cite ltx_citemacro_citet">Seedat etÂ al. (<a href="#bib.bib73" title="" class="ltx_ref">2023</a>)</cite> discard samples with both low confidence and low uncertainty. Some other methods assume that clean samples are prone to hold similar predictions under different conditions and employ cross-condition consistency for filtering. Specifically, such consistency can be between LLM and downstream classifier <cite class="ltx_cite ltx_citemacro_cite">Yu etÂ al. (<a href="#bib.bib107" title="" class="ltx_ref">2023c</a>)</cite>, between multiple executions <cite class="ltx_cite ltx_citemacro_cite">Ye etÂ al. (<a href="#bib.bib103" title="" class="ltx_ref">2023</a>)</cite>, or between neighboring data points <cite class="ltx_cite ltx_citemacro_cite">Seedat etÂ al. (<a href="#bib.bib73" title="" class="ltx_ref">2023</a>)</cite>. <cite class="ltx_cite ltx_citemacro_citet">Chen etÂ al. (<a href="#bib.bib9" title="" class="ltx_ref">2023b</a>)</cite> leverage the powerful text understanding capabilities of LLMs to assess the quality of different samples and filter out those with low scores. Results show that AlpagasusÂ <cite class="ltx_cite ltx_citemacro_cite">Chen etÂ al. (<a href="#bib.bib9" title="" class="ltx_ref">2023b</a>)</cite>, trained on a much smaller but curated dataset, surpasses the original AlpacaÂ <cite class="ltx_cite ltx_citemacro_cite">Taori etÂ al. (<a href="#bib.bib83" title="" class="ltx_ref">2023</a>)</cite> across several benchmarks, underscoring the importance of data curation.</p>
</div>
</section>
<section id="S3.SS2.SSS1.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Sample Re-Weighting.</h5>

<div id="S3.SS2.SSS1.Px2.p1" class="ltx_para">
<p id="S3.SS2.SSS1.Px2.p1.1" class="ltx_p">On the other hand, re-weighting methods believe all data are valuable but with varying importance.
Thus, they assign larger weights to correctly annotated or influential samples during downstream utilization <cite class="ltx_cite ltx_citemacro_cite">Zhang etÂ al. (<a href="#bib.bib110" title="" class="ltx_ref">2023b</a>); Gao etÂ al. (<a href="#bib.bib20" title="" class="ltx_ref">2023a</a>); Meng etÂ al. (<a href="#bib.bib61" title="" class="ltx_ref">2023</a>)</cite>. For instance, SunGen <cite class="ltx_cite ltx_citemacro_cite">Gao etÂ al. (<a href="#bib.bib20" title="" class="ltx_ref">2023a</a>)</cite> proposes an adaptive bi-level re-weighting algorithm without human annotations. FewGen <cite class="ltx_cite ltx_citemacro_cite">Meng etÂ al. (<a href="#bib.bib61" title="" class="ltx_ref">2023</a>)</cite> designs a discriminative meta-learning objective to adjust sample weights and demarcate the nuanced differences between different labels.</p>
</div>
</section>
</section>
<section id="S3.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.2 </span>Label Enhancement</h4>

<div id="S3.SS2.SSS2.p1" class="ltx_para">
<p id="S3.SS2.SSS2.p1.1" class="ltx_p">Label enhancement methods strive to rectify the potentially erroneous annotations in generated samples. Due to confirmation bias, it is unrealistic for LLMs to identify their own mistakes. To address this, recent works either rely on <span id="S3.SS2.SSS2.p1.1.1" class="ltx_text ltx_font_italic">human intervention</span> or incorporate a student model for <span id="S3.SS2.SSS2.p1.1.2" class="ltx_text ltx_font_italic">human-free knowledge distillation</span>.</p>
</div>
<section id="S3.SS2.SSS2.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Human Intervention.</h5>

<div id="S3.SS2.SSS2.Px1.p1" class="ltx_para">
<p id="S3.SS2.SSS2.Px1.p1.1" class="ltx_p">A straightforward strategy for label refinery is to include human efforts to re-annotate the corrupted samples <cite class="ltx_cite ltx_citemacro_cite">Chung etÂ al. (<a href="#bib.bib10" title="" class="ltx_ref">2023a</a>); Wang etÂ al. (<a href="#bib.bib88" title="" class="ltx_ref">2021</a>); Pangakis etÂ al. (<a href="#bib.bib66" title="" class="ltx_ref">2023</a>)</cite>. <cite class="ltx_cite ltx_citemacro_citet">Wang etÂ al. (<a href="#bib.bib88" title="" class="ltx_ref">2021</a>)</cite> proposed to actively select samples with the lowest confidence for human re-labeling. <cite class="ltx_cite ltx_citemacro_citet">Pangakis etÂ al. (<a href="#bib.bib66" title="" class="ltx_ref">2023</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citet">Liu etÂ al. (<a href="#bib.bib52" title="" class="ltx_ref">2022a</a>)</cite> further emphasize the importance of human review and suggest comparing annotations from humans and LLMs guided by the same codebook. Despite the simplicity, these methods can lead to considerable labeling costs and can be unrealistic in practical deployment.</p>
</div>
</section>
<section id="S3.SS2.SSS2.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Auxiliary Model.</h5>

<div id="S3.SS2.SSS2.Px2.p1" class="ltx_para">
<p id="S3.SS2.SSS2.Px2.p1.1" class="ltx_p">To reduce the labeling cost, a more pragmatic human-free paradigm is developed which involves auxiliary student models for knowledge distillation and label refinery <cite class="ltx_cite ltx_citemacro_cite">Xiao etÂ al. (<a href="#bib.bib98" title="" class="ltx_ref">2023</a>); Zhao etÂ al. (<a href="#bib.bib112" title="" class="ltx_ref">2023a</a>); Saad-Falcon etÂ al. (<a href="#bib.bib71" title="" class="ltx_ref">2023</a>)</cite>. These methods rely on the weakly supervised ability of student models and hypothesize that a student distilled from the LLM teacher can produce superior labels. The seminal work FreeAL <cite class="ltx_cite ltx_citemacro_cite">Xiao etÂ al. (<a href="#bib.bib98" title="" class="ltx_ref">2023</a>)</cite> proposes a collaborative framework, where a student model is leveraged to distill the high-quality task-related knowledge from the weak annotations and in return feedback LLMs for label refinery. MCKD <cite class="ltx_cite ltx_citemacro_cite">Zhao etÂ al. (<a href="#bib.bib112" title="" class="ltx_ref">2023a</a>)</cite> designs a multistage distillation pipeline with data-split training and cross-partition labeling to avoid overfitting on noisy labels. With the expanding abilities and availability of LLMs, the incorporation of auxiliary student models will play a more crucial role as a cost-effective alternative to human intervention.</p>
</div>
<figure id="S3.F5" class="ltx_figure"><img src="/html/2406.15126/assets/x5.png" id="S3.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="348" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Direct and indirect methods of data evaluation.</figcaption>
</figure>
</section>
</section>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Data Evaluation</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">Before the employment of generated data, it is important to evaluate the quality and application effectiveness of the data, to ensure its value to downstream tasks.
The current mainstream evaluation methods can be roughly divided into two categories: <span id="S3.SS3.p1.1.1" class="ltx_text ltx_font_italic">direct</span> and <span id="S3.SS3.p1.1.2" class="ltx_text ltx_font_italic">indirect</span>, which evaluate the quality of <math id="S3.SS3.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{D}_{\text{gen}}" display="inline"><semantics id="S3.SS3.p1.1.m1.1a"><msub id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p1.1.m1.1.1.2" xref="S3.SS3.p1.1.m1.1.1.2.cmml">ğ’Ÿ</mi><mtext id="S3.SS3.p1.1.m1.1.1.3" xref="S3.SS3.p1.1.m1.1.1.3a.cmml">gen</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><apply id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.1.m1.1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p1.1.m1.1.1.2.cmml" xref="S3.SS3.p1.1.m1.1.1.2">ğ’Ÿ</ci><ci id="S3.SS3.p1.1.m1.1.1.3a.cmml" xref="S3.SS3.p1.1.m1.1.1.3"><mtext mathsize="70%" id="S3.SS3.p1.1.m1.1.1.3.cmml" xref="S3.SS3.p1.1.m1.1.1.3">gen</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">\mathcal{D}_{\text{gen}}</annotation></semantics></math> individually and through its effectiveness on downstream tasks, respectively.</p>
</div>
<section id="S3.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.1 </span>Direct Evaluation</h4>

<section id="S3.SS3.SSS1.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Data Faithfulness.</h5>

<div id="S3.SS3.SSS1.Px1.p1" class="ltx_para">
<p id="S3.SS3.SSS1.Px1.p1.1" class="ltx_p">Ideally, automatic evaluation of the LLMsâ€™ generation results can be easily realized with ground truths from existing datasets, if available <cite class="ltx_cite ltx_citemacro_cite">Zhu etÂ al. (<a href="#bib.bib115" title="" class="ltx_ref">2023</a>)</cite>. However, for open-ended data, human-based evaluation is necessitated. A straightforward idea is to provide some generated samples to human experts, who will then determine whether they are correct, according to which we can estimate the overall generation quality <cite class="ltx_cite ltx_citemacro_cite">Wang etÂ al. (<a href="#bib.bib91" title="" class="ltx_ref">2023e</a>)</cite>. Theoretically, the larger the sample size, the more accurate the estimation results will be, but the labor it costs will correspondingly get higher. To this end, a reliable auxiliary model can be leveraged for a more comprehensive yet cost-effective evaluation of the generated data in replace of human expertsÂ <cite class="ltx_cite ltx_citemacro_cite">Chung etÂ al. (<a href="#bib.bib11" title="" class="ltx_ref">2023b</a>)</cite>. Considering that most models can only process contents of limited length, appropriate information extraction can reduce the burden of the auxiliary model and contribute to a more precise prediction of whether a sample contains factual errors <cite class="ltx_cite ltx_citemacro_cite">Lee etÂ al. (<a href="#bib.bib45" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
</section>
<section id="S3.SS3.SSS1.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Data Diversity.</h5>

<div id="S3.SS3.SSS1.Px2.p1" class="ltx_para">
<p id="S3.SS3.SSS1.Px2.p1.1" class="ltx_p">The quantification of data diversity primarily employs vocabulary statistics and sample relevance calculations. Vocabulary statisticsÂ <cite class="ltx_cite ltx_citemacro_cite">Yu etÂ al. (<a href="#bib.bib106" title="" class="ltx_ref">2023b</a>)</cite>, such as vocabulary size and N-gram frequency, provide a straightforward and intuitive approach. However, they struggle to capture the semantic information of a dataset. The calculation of sample relevance compensates for this limitation effectively. The most common measures of sample correlation are based on cosine similarityÂ <cite class="ltx_cite ltx_citemacro_cite">Wang etÂ al. (<a href="#bib.bib87" title="" class="ltx_ref">2023b</a>)</cite> and sample distanceÂ <cite class="ltx_cite ltx_citemacro_cite">Chung etÂ al. (<a href="#bib.bib11" title="" class="ltx_ref">2023b</a>)</cite>, which can better capture the contextual and semantic diversity of the dataset. Furthermore, these metrics can also be leveraged to select in-context demonstrations <math id="S3.SS3.SSS1.Px2.p1.1.m1.1" class="ltx_Math" alttext="e_{\text{demo}}" display="inline"><semantics id="S3.SS3.SSS1.Px2.p1.1.m1.1a"><msub id="S3.SS3.SSS1.Px2.p1.1.m1.1.1" xref="S3.SS3.SSS1.Px2.p1.1.m1.1.1.cmml"><mi id="S3.SS3.SSS1.Px2.p1.1.m1.1.1.2" xref="S3.SS3.SSS1.Px2.p1.1.m1.1.1.2.cmml">e</mi><mtext id="S3.SS3.SSS1.Px2.p1.1.m1.1.1.3" xref="S3.SS3.SSS1.Px2.p1.1.m1.1.1.3a.cmml">demo</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.Px2.p1.1.m1.1b"><apply id="S3.SS3.SSS1.Px2.p1.1.m1.1.1.cmml" xref="S3.SS3.SSS1.Px2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS1.Px2.p1.1.m1.1.1.1.cmml" xref="S3.SS3.SSS1.Px2.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.SSS1.Px2.p1.1.m1.1.1.2.cmml" xref="S3.SS3.SSS1.Px2.p1.1.m1.1.1.2">ğ‘’</ci><ci id="S3.SS3.SSS1.Px2.p1.1.m1.1.1.3a.cmml" xref="S3.SS3.SSS1.Px2.p1.1.m1.1.1.3"><mtext mathsize="70%" id="S3.SS3.SSS1.Px2.p1.1.m1.1.1.3.cmml" xref="S3.SS3.SSS1.Px2.p1.1.m1.1.1.3">demo</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.Px2.p1.1.m1.1c">e_{\text{demo}}</annotation></semantics></math>Â <cite class="ltx_cite ltx_citemacro_cite">Wang etÂ al. (<a href="#bib.bib91" title="" class="ltx_ref">2023e</a>)</cite> that are more dissimilar with the previously generated samples, thereby leading to more diversified generation results.</p>
</div>
</section>
</section>
<section id="S3.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.2 </span>Indirect Evaluation</h4>

<section id="S3.SS3.SSS2.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Benchmark Evaluation.</h5>

<div id="S3.SS3.SSS2.Px1.p1" class="ltx_para">
<p id="S3.SS3.SSS2.Px1.p1.1" class="ltx_p">The performance of downstream models trained on the generated data can also reflect the generation quality to some extentÂ <cite class="ltx_cite ltx_citemacro_cite">Yu etÂ al. (<a href="#bib.bib106" title="" class="ltx_ref">2023b</a>); Chung etÂ al. (<a href="#bib.bib11" title="" class="ltx_ref">2023b</a>)</cite>.
Specifically, the impact of synthetic data can be evaluated from multiple dimensions except for the specialized capabilities of the downstream models. For example, TruthfulQA enables the assessment of a modelâ€™s ability to identify true claims <cite class="ltx_cite ltx_citemacro_cite">Sun etÂ al. (<a href="#bib.bib81" title="" class="ltx_ref">2023</a>)</cite>; NIV2 is employed to evaluate a modelâ€™s language comprehension and reasoning abilities across multiple tasks <cite class="ltx_cite ltx_citemacro_cite">Wang etÂ al. (<a href="#bib.bib91" title="" class="ltx_ref">2023e</a>)</cite>.</p>
</div>
</section>
<section id="S3.SS3.SSS2.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Open Evaluation.</h5>

<div id="S3.SS3.SSS2.Px2.p1" class="ltx_para">
<p id="S3.SS3.SSS2.Px2.p1.1" class="ltx_p">For open-ended benchmarks, evaluation by humans or auxiliary models is necessitated due to the absence of standardized answers. To fully leverage the preference outputs of the auxiliary models, multiple evaluation strategies have been designed, such as response rankingÂ <cite class="ltx_cite ltx_citemacro_cite">Xu etÂ al. (<a href="#bib.bib99" title="" class="ltx_ref">2023a</a>)</cite>, four-level rating systemÂ <cite class="ltx_cite ltx_citemacro_cite">Wang etÂ al. (<a href="#bib.bib91" title="" class="ltx_ref">2023e</a>)</cite> and Elo scoresÂ <cite class="ltx_cite ltx_citemacro_cite">Bai etÂ al. (<a href="#bib.bib2" title="" class="ltx_ref">2022</a>)</cite>. To further reduce evaluation costs, <cite class="ltx_cite ltx_citemacro_citet">Sun etÂ al. (<a href="#bib.bib81" title="" class="ltx_ref">2023</a>); Xu etÂ al. (<a href="#bib.bib99" title="" class="ltx_ref">2023a</a>)</cite> utilize the automatic evaluation framework based on GPT-4 proposed by Vicuna for evaluation. However, general LLMs may lack enough knowledge for domain-specific tasks, which hinders them to provide effective evaluationÂ <cite class="ltx_cite ltx_citemacro_cite">Bran etÂ al. (<a href="#bib.bib6" title="" class="ltx_ref">2023</a>)</cite>. Therefore, collecting human assessment data to fine-tune open-source models for evaluation purposes is an important practice in real-world scenariosÂ <cite class="ltx_cite ltx_citemacro_cite">He etÂ al. (<a href="#bib.bib29" title="" class="ltx_ref">2023</a>)</cite>. Other techniques likeÂ <cite class="ltx_cite ltx_citemacro_cite">Peng etÂ al. (<a href="#bib.bib68" title="" class="ltx_ref">2024</a>, <a href="#bib.bib67" title="" class="ltx_ref">2023</a>)</cite> remain to be further explored.</p>
</div>
</section>
</section>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Future Directions</h2>

<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Complex Task Decomposition</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">Current multi-step generation algorithms depend on the modelâ€™s understanding of task requirements, requiring it to perform complex logical reasoning with limited information. However, in real-world complex scenarios, this limited information may not adequately support effective decision-making.
For instance, the generation of mathematical problem-solution pairs entails multiple reasoning steps and may necessitate the utilization of calculator tools for validation.
To date, there remains a lack of systematic investigation on how to activate the reasoning and planning capabilities of LLMs for autonomous synthetic data generation.
Inspired by prevalent LLMs-based agents like HuggingGPT <cite class="ltx_cite ltx_citemacro_cite">Shen etÂ al. (<a href="#bib.bib75" title="" class="ltx_ref">2023</a>)</cite> and MetaGPT <cite class="ltx_cite ltx_citemacro_cite">Hong etÂ al. (<a href="#bib.bib31" title="" class="ltx_ref">2023</a>)</cite>, we believe it would also be quite valuable to develop a data generation <span id="S4.SS1.p1.1.1" class="ltx_text ltx_font_italic">agent</span> for industrial applications.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Knowledge Enhancement</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">Recent research has found that LLMsâ€™ knowledge is long-tailed and biased <cite class="ltx_cite ltx_citemacro_cite">Navigli etÂ al. (<a href="#bib.bib64" title="" class="ltx_ref">2023</a>); Fei etÂ al. (<a href="#bib.bib17" title="" class="ltx_ref">2023</a>)</cite>.
Lacking specific domain knowledge, LLMs tend to generate biased, monotonous, and even unfaithful data.
Though we have introduced how to mildly guide the data generation with task specification and conditional prompting in the previous sections, such methods still hold strong limitations and are not conducive to scalable implementation.
Instead, we believe that developing automated condition controls directly on mature domain knowledge bases will significantly improve the efficiency of knowledge enhancement.
For example, we can establish certain links between the LLMs and external knowledge graphs <cite class="ltx_cite ltx_citemacro_cite">Ji etÂ al. (<a href="#bib.bib37" title="" class="ltx_ref">2022</a>)</cite> or retrieve augmentation from the website <cite class="ltx_cite ltx_citemacro_cite">Gao etÂ al. (<a href="#bib.bib22" title="" class="ltx_ref">2023b</a>)</cite>, which is helpful for the definition, decomposition, and reasoning of data features throughout the entire generation process. Additionally, with enhanced domain knowledge, we may also better assess the quality of generated data or even develop automatic evaluation systems. Overall, we believe that knowledge-driven data generation will be a key focus for future studies.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Synergy between Large &amp; Small LMs</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">In SectionÂ <a href="#S3.SS2" title="3.2 Data Curation â€£ 3 Generic Workflow â€£ On LLMs-Driven Synthetic Data Generation, Curation, and Evaluation: A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a>, we introduced the use of small domain-specific models for data curation. In particular, FreeAL <cite class="ltx_cite ltx_citemacro_cite">Xiao etÂ al. (<a href="#bib.bib98" title="" class="ltx_ref">2023</a>)</cite> has shown the feasibility of low-cost data curation with integrated collaboration between large and small models.
The idea of leveraging real-time feedback provided by automated performance evaluation during the data generation process to guide the corresponding adjustments in the following generation hints at an important research direction.
However, the exploitation of small LMs at the current stage is simply based on prediction confidence. In the future, we are looking forward to seeing more diversified collaboration modes between large and small models to improve the quality of generated data, e.g., usage of various output information, new design of collaborative architectures, and so on.</p>
</div>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Human-Model Collaboration</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p">Data, as the source of model intelligence, theoretically cannot be generated completely without human intervention. Otherwise, wild synthetic data that carries noisy, toxic information can easily â€œpoisonâ€ a model, even resulting in mode collapse. Due to the inherent bias of LLMs, they can hardly be self-aware of the bias in their generated data and finally deviate from our intentions. Thus, designing a human-friendly interactive system to involves a few necessary human knowledge for annotation and verification is vital and irreplaceable. To date, there is still a lack of a generic framework to standardize and systematize the human-machine collaboration involved in the data production process.</p>
</div>
<div id="S4.SS4.p2" class="ltx_para">
<p id="S4.SS4.p2.1" class="ltx_p">We believe that an appropriate design of such a system must be based on a thorough understanding of the strengths and limitations of human intervention, and should follow the human-centered principle. To achieve sustainable and efficient human involvement, we need comprehensive consideration of various factors such as feasibility, cost, and even labor psychology. For specific examples: (i)-readability and interpretability of the information provided by the LLMs should be ensured to reduce obstacles to human understanding; (ii)-upstream knowledge enrichment or filtering should be carried out to improve the efficiency of human resource utilization and reduce consumption on tasks with low cost-effectiveness; (iii)-incorporating enjoyable interactive features can not only mitigate the negative impact of mechanical data processing tasks on humans but also attract a broader audience.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this paper, we present a systematic review of advancements in synthetic data generation propelled by Large Language Models (LLMs). We aim to offer guidance to enterprises and organizations on effectively building their domain-specific datasets using LLMs. In the meantime, we endeavor to provide insights into the challenges and opportunities within this field, while also proposing potential directions for future research.
We hope that our work can promote the rapid production of large amounts of data in various fields and push the limits of data-centric AI.
We also envision a fantastic future, where an LLMs community, endowed with human-like abilities such as bionics and communication, may be constructed to generate data for its own self-improvement.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Limitations</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">In this paper, we survey existing studies on LLMs-driven synthetic data generation, curation, and evaluation, proposing a generic workflow for real-world practice. Synthetic data generation is a broad topic that involves data and models of various modals, including vision and speech. Due to the page limit, we mainly focus on the objective of text data and LLMs-driven approaches, while leaving investigations in other fields for future work. We will also keep paying attention to the latest work and add more related approaches with more detailed analysis.</p>
</div>
</section>
<section id="Sx2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Ethics Statement</h2>

<div id="Sx2.p1" class="ltx_para">
<p id="Sx2.p1.1" class="ltx_p">We believe that our proposed workflow of LLMs-driven synthetic data generation, curation, and evaluation can benefit both researchers who are interested in data-centric AI and industrial producers who are facing data problems. However, the malicious use of such synthetic data also raises ethical concerns that should arouse our vigilance.</p>
</div>
</section>
<section id="Sx3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgements</h2>

<div id="Sx3.p1" class="ltx_para">
<p id="Sx3.p1.1" class="ltx_p">This work is supported by the Pioneer R&amp;D Program of Zhejiang (No. 2024C01035), NSFC under Grants (No. 62206247), and the Fundamental Research Funds for the Central Universities (No. 226-2024-00049).</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Almeida etÂ al. (2011)</span>
<span class="ltx_bibblock">
TiagoÂ A. Almeida, JosÃ© MarÃ­aÂ GÃ³mez Hidalgo, and Akebo Yamakami. 2011.

</span>
<span class="ltx_bibblock">Contributions to the study of SMS spam filtering: new collection and results.

</span>
<span class="ltx_bibblock">In <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2011 ACM Symposium on Document Engineering, Mountain View, CA, USA, September 19-22, 2011</em>.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bai etÂ al. (2022)</span>
<span class="ltx_bibblock">
Yuntao Bai, Saurav Kadavath, Sandipan Kundu, Amanda Askell, Jackson Kernion, Andy Jones, Anna Chen, Anna Goldie, Azalia Mirhoseini, Cameron McKinnon, Carol Chen, Catherine Olsson, Christopher Olah, Danny Hernandez, Dawn Drain, Deep Ganguli, Dustin Li, Eli Tran-Johnson, Ethan Perez, Jamie Kerr, Jared Mueller, Jeffrey Ladish, Joshua Landau, Kamal Ndousse, Kamile Lukosiute, Liane Lovitt, Michael Sellitto, Nelson Elhage, Nicholas Schiefer, NoemÃ­ Mercado, Nova DasSarma, Robert Lasenby, Robin Larson, Sam Ringer, Scott Johnston, Shauna Kravec, SheerÂ El Showk, Stanislav Fort, Tamera Lanham, Timothy Telleen-Lawton, Tom Conerly, Tom Henighan, Tristan Hume, SamuelÂ R. Bowman, Zac Hatfield-Dodds, Ben Mann, Dario Amodei, Nicholas Joseph, Sam McCandlish, Tom Brown, and Jared Kaplan. 2022.

</span>
<span class="ltx_bibblock">Constitutional AI: harmlessness from AI feedback.

</span>
<span class="ltx_bibblock"><em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2212.08073.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bang etÂ al. (2023)</span>
<span class="ltx_bibblock">
Yejin Bang, Samuel Cahyawijaya, Nayeon Lee, Wenliang Dai, Dan Su, Bryan Wilie, Holy Lovenia, Ziwei Ji, Tiezheng Yu, Willy Chung, QuyetÂ V. Do, Yan Xu, and Pascale Fung. 2023.

</span>
<span class="ltx_bibblock">A multitask, multilingual, multimodal evaluation of chatgpt on reasoning, hallucination, and interactivity.

</span>
<span class="ltx_bibblock"><em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2302.04023.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bansal and Sharma (2023)</span>
<span class="ltx_bibblock">
Parikshit Bansal and Amit Sharma. 2023.

</span>
<span class="ltx_bibblock">Large language models as annotators: Enhancing generalization of NLP models at minimal cost.

</span>
<span class="ltx_bibblock"><em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2306.15766.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bartolo etÂ al. (2020)</span>
<span class="ltx_bibblock">
Max Bartolo, Alastair Roberts, Johannes Welbl, Sebastian Riedel, and Pontus Stenetorp. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1162/tacl_a_00338" title="" class="ltx_ref ltx_href">Beat the AI: Investigating adversarial human annotation for reading comprehension</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Transactions of the Association for Computational Linguistics</em>, 8:662â€“678.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bran etÂ al. (2023)</span>
<span class="ltx_bibblock">
AndresÂ M Bran, Sam Cox, AndrewÂ D White, and Philippe Schwaller. 2023.

</span>
<span class="ltx_bibblock">Chemcrow: Augmenting large-language models with chemistry tools.

</span>
<span class="ltx_bibblock"><em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2304.05376</em>.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Casanueva etÂ al. (2020)</span>
<span class="ltx_bibblock">
IÃ±igo Casanueva, Tadas TemÄinas, Daniela Gerz, Matthew Henderson, and Ivan VuliÄ‡. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2020.nlp4convai-1.5" title="" class="ltx_ref ltx_href">Efficient intent detection with dual sentence encoders</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2nd Workshop on Natural Language Processing for Conversational AI</em>, pages 38â€“45, Online. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen etÂ al. (2023a)</span>
<span class="ltx_bibblock">
Derek Chen, Celine Lee, Yunan Lu, Domenic Rosati, and Zhou Yu. 2023a.

</span>
<span class="ltx_bibblock">Mixture of soft prompts for controllable data generation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">EMNLP</em>, pages 14815â€“14833. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen etÂ al. (2023b)</span>
<span class="ltx_bibblock">
Lichang Chen, Shiyang Li, Jun Yan, Hai Wang, Kalpa Gunaratna, Vikas Yadav, Zheng Tang, Vijay Srinivasan, Tianyi Zhou, Heng Huang, and Hongxia Jin. 2023b.

</span>
<span class="ltx_bibblock">Alpagasus: Training A better alpaca with fewer data.

</span>
<span class="ltx_bibblock"><em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2307.08701.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chung etÂ al. (2023a)</span>
<span class="ltx_bibblock">
John Chung, Ece Kamar, and Saleema Amershi. 2023a.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2023.acl-long.34" title="" class="ltx_ref ltx_href">Increasing diversity while maintaining accuracy: Text data generation with large language models and human interventions</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 575â€“593, Toronto, Canada. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chung etÂ al. (2023b)</span>
<span class="ltx_bibblock">
John JoonÂ Young Chung, Ece Kamar, and Saleema Amershi. 2023b.

</span>
<span class="ltx_bibblock">Increasing diversity while maintaining accuracy: Text data generation with large language models and human interventions.

</span>
<span class="ltx_bibblock">In <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">ACL</em>, pages 575â€“593. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cui and Wang (2023)</span>
<span class="ltx_bibblock">
Wanyun Cui and Qianle Wang. 2023.

</span>
<span class="ltx_bibblock">Ada-instruct: Adapting instruction generators for complex reasoning.

</span>
<span class="ltx_bibblock"><em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2310.04484.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Demszky etÂ al. (2020)</span>
<span class="ltx_bibblock">
Dorottya Demszky, Dana Movshovitz-Attias, Jeongwoo Ko, Alan Cowen, Gaurav Nemade, and Sujith Ravi. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2020.acl-main.372" title="" class="ltx_ref ltx_href">GoEmotions: A dataset of fine-grained emotions</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</em>, pages 4040â€“4054, Online. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ding etÂ al. (2023a)</span>
<span class="ltx_bibblock">
Bosheng Ding, Chengwei Qin, Linlin Liu, YewÂ Ken Chia, Boyang Li, Shafiq Joty, and Lidong Bing. 2023a.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2023.acl-long.626" title="" class="ltx_ref ltx_href">Is GPT-3 a good data annotator?</a>

</span>
<span class="ltx_bibblock">In <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 11173â€“11195, Toronto, Canada. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ding etÂ al. (2023b)</span>
<span class="ltx_bibblock">
Ning Ding, Yulin Chen, Bokai Xu, Yujia Qin, Shengding Hu, Zhiyuan Liu, Maosong Sun, and Bowen Zhou. 2023b.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2023.emnlp-main.183" title="" class="ltx_ref ltx_href">Enhancing chat language models by scaling high-quality instructional conversations</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</em>, pages 3029â€“3051, Singapore. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Eldan and Li (2023)</span>
<span class="ltx_bibblock">
Ronen Eldan and Yuanzhi Li. 2023.

</span>
<span class="ltx_bibblock">Tinystories: How small can language models be and still speak coherent english?

</span>
<span class="ltx_bibblock"><em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2305.07759.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fei etÂ al. (2023)</span>
<span class="ltx_bibblock">
YuÂ Fei, Yifan Hou, Zeming Chen, and Antoine Bosselut. 2023.

</span>
<span class="ltx_bibblock">Mitigating label biases for in-context learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">ACL</em>, pages 14014â€“14031. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Feng etÂ al. (2023)</span>
<span class="ltx_bibblock">
Shangbin Feng, Vidhisha Balachandran, Yuyang Bai, and Yulia Tsvetkov. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2023.emnlp-main.59" title="" class="ltx_ref ltx_href">FactKB: Generalizable factuality evaluation using language models enhanced with factual knowledge</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</em>, pages 933â€“952, Singapore. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gandhi etÂ al. (2024)</span>
<span class="ltx_bibblock">
Saumya Gandhi, Ritu Gala, Vijay Viswanathan, Tongshuang Wu, and Graham Neubig. 2024.

</span>
<span class="ltx_bibblock">Better synthetic data by retrieving and transforming existing datasets.

</span>
<span class="ltx_bibblock"><em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2404.14361.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao etÂ al. (2023a)</span>
<span class="ltx_bibblock">
Jiahui Gao, Renjie Pi, Yong Lin, Hang Xu, Jiacheng Ye, Zhiyong Wu, Weizhong Zhang, Xiaodan Liang, Zhenguo Li, and Lingpeng Kong. 2023a.

</span>
<span class="ltx_bibblock">Self-guided noise-free data generation for efficient zero-shot learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">ICLR</em>. OpenReview.net.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao etÂ al. (2019)</span>
<span class="ltx_bibblock">
Tianyu Gao, XuÂ Han, Hao Zhu, Zhiyuan Liu, Peng Li, Maosong Sun, and Jie Zhou. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/D19-1649" title="" class="ltx_ref ltx_href">FewRel 2.0: Towards more challenging few-shot relation classification</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</em>, pages 6250â€“6255, Hong Kong, China. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao etÂ al. (2023b)</span>
<span class="ltx_bibblock">
Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, YiÂ Dai, Jiawei Sun, Qianyu Guo, Meng Wang, and Haofen Wang. 2023b.

</span>
<span class="ltx_bibblock">Retrieval-augmented generation for large language models: A survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2312.10997.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gilardi etÂ al. (2023)</span>
<span class="ltx_bibblock">
Fabrizio Gilardi, Meysam Alizadeh, and MaÃ«l Kubli. 2023.

</span>
<span class="ltx_bibblock">Chatgpt outperforms crowd-workers for text-annotation tasks.

</span>
<span class="ltx_bibblock"><em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2303.15056.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gunasekar etÂ al. (2023)</span>
<span class="ltx_bibblock">
Suriya Gunasekar, YiÂ Zhang, Jyoti Aneja, Caio CÃ©sarÂ Teodoro Mendes, AllieÂ Del Giorno, Sivakanth Gopi, Mojan Javaheripi, Piero Kauffmann, Gustavo deÂ Rosa, Olli Saarikivi, Adil Salim, Shital Shah, HarkiratÂ Singh Behl, Xin Wang, SÃ©bastien Bubeck, Ronen Eldan, AdamÂ Tauman Kalai, YinÂ Tat Lee, and Yuanzhi Li. 2023.

</span>
<span class="ltx_bibblock">Textbooks are all you need.

</span>
<span class="ltx_bibblock"><em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2306.11644.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guo etÂ al. (2023)</span>
<span class="ltx_bibblock">
Biyang Guo, Xin Zhang, Ziyuan Wang, Minqi Jiang, Jinran Nie, Yuxuan Ding, Jianwei Yue, and Yupeng Wu. 2023.

</span>
<span class="ltx_bibblock">How close is chatgpt to human experts? comparison corpus, evaluation, and detection.

</span>
<span class="ltx_bibblock"><em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2301.07597.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Han and Gardent (2023)</span>
<span class="ltx_bibblock">
Kelvin Han and Claire Gardent. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2023.findings-emnlp.918" title="" class="ltx_ref ltx_href">Multilingual generation and answering of questions from texts and knowledge graphs</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational Linguistics: EMNLP 2023</em>, pages 13740â€“13756, Singapore. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Han etÂ al. (2023)</span>
<span class="ltx_bibblock">
Yucheng Han, Chi Zhang, Xin Chen, XuÂ Yang, Zhibin Wang, Gang Yu, Bin Fu, and Hanwang Zhang. 2023.

</span>
<span class="ltx_bibblock">Chartllama: A multimodal LLM for chart understanding and generation.

</span>
<span class="ltx_bibblock"><em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2311.16483.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hartvigsen etÂ al. (2022)</span>
<span class="ltx_bibblock">
Thomas Hartvigsen, Saadia Gabriel, Hamid Palangi, Maarten Sap, Dipankar Ray, and Ece Kamar. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2022.acl-long.234" title="" class="ltx_ref ltx_href">ToxiGen: A large-scale machine-generated dataset for adversarial and implicit hate speech detection</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 3309â€“3326, Dublin, Ireland. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He etÂ al. (2023)</span>
<span class="ltx_bibblock">
Xingwei He, Zhenghao Lin, Yeyun Gong, A-Long Jin, Hang Zhang, Chen Lin, Jian Jiao, SiuÂ Ming Yiu, Nan Duan, and Weizhu Chen. 2023.

</span>
<span class="ltx_bibblock">Annollm: Making large language models to be better crowdsourced annotators.

</span>
<span class="ltx_bibblock"><em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2303.16854.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hendrycks etÂ al. (2021)</span>
<span class="ltx_bibblock">
Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, and Jacob Steinhardt. 2021.

</span>
<span class="ltx_bibblock">Measuring mathematical problem solving with the MATH dataset.

</span>
<span class="ltx_bibblock">In <em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">Proc. of NeurIPS</em>.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hong etÂ al. (2023)</span>
<span class="ltx_bibblock">
Sirui Hong, Xiawu Zheng, Jonathan Chen, Yuheng Cheng, Jinlin Wang, Ceyao Zhang, Zili Wang, Steven KaÂ Shing Yau, Zijuan Lin, Liyang Zhou, Chenyu Ran, Lingfeng Xiao, and Chenglin Wu. 2023.

</span>
<span class="ltx_bibblock">Metagpt: Meta programming for multi-agent collaborative framework.

</span>
<span class="ltx_bibblock"><em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2308.00352.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Honovich etÂ al. (2023a)</span>
<span class="ltx_bibblock">
OrÂ Honovich, Thomas Scialom, Omer Levy, and Timo Schick. 2023a.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2023.acl-long.806" title="" class="ltx_ref ltx_href">Unnatural instructions: Tuning language models with (almost) no human labor</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 14409â€“14428, Toronto, Canada. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Honovich etÂ al. (2023b)</span>
<span class="ltx_bibblock">
OrÂ Honovich, Thomas Scialom, Omer Levy, and Timo Schick. 2023b.

</span>
<span class="ltx_bibblock">Unnatural instructions: Tuning language models with (almost) no human labor.

</span>
<span class="ltx_bibblock">In <em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">ACL</em>, pages 14409â€“14428. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hosking etÂ al. (2023)</span>
<span class="ltx_bibblock">
Tom Hosking, Phil Blunsom, and Max Bartolo. 2023.

</span>
<span class="ltx_bibblock">Human feedback is not gold standard.

</span>
<span class="ltx_bibblock"><em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2309.16349.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu etÂ al. (2023)</span>
<span class="ltx_bibblock">
Zhiqiang Hu, Lei Wang, Yihuai Lan, Wanyu Xu, Ee-Peng Lim, Lidong Bing, Xing Xu, Soujanya Poria, and Roy Lee. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2023.emnlp-main.319" title="" class="ltx_ref ltx_href">LLM-adapters: An adapter family for parameter-efficient fine-tuning of large language models</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</em>, pages 5254â€“5276, Singapore. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang etÂ al. (2023)</span>
<span class="ltx_bibblock">
Jiaxin Huang, Shixiang Gu, LeÂ Hou, Yuexin Wu, Xuezhi Wang, Hongkun Yu, and Jiawei Han. 2023.

</span>
<span class="ltx_bibblock">Large language models can self-improve.

</span>
<span class="ltx_bibblock">In <em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">EMNLP</em>, pages 1051â€“1068. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ji etÂ al. (2022)</span>
<span class="ltx_bibblock">
Shaoxiong Ji, Shirui Pan, Erik Cambria, Pekka Marttinen, and PhilipÂ S. Yu. 2022.

</span>
<span class="ltx_bibblock">A survey on knowledge graphs: Representation, acquisition, and applications.

</span>
<span class="ltx_bibblock"><em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">IEEE Trans. Neural Networks Learn. Syst.</em>, 33(2):494â€“514.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Josifoski etÂ al. (2023)</span>
<span class="ltx_bibblock">
Martin Josifoski, Marija Sakota, Maxime Peyrard, and Robert West. 2023.

</span>
<span class="ltx_bibblock">Exploiting asymmetry for synthetic training data generation: Synthie and the case of information extraction.

</span>
<span class="ltx_bibblock">In <em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">EMNLP</em>, pages 1555â€“1574. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim etÂ al. (2023)</span>
<span class="ltx_bibblock">
Seungone Kim, Jamin Shin, Yejin Cho, Joel Jang, Shayne Longpre, Hwaran Lee, Sangdoo Yun, Seongjin Shin, Sungdong Kim, James Thorne, and Minjoon Seo. 2023.

</span>
<span class="ltx_bibblock">Prometheus: Inducing fine-grained evaluation capability in language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2310.08491.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim etÂ al. (2022)</span>
<span class="ltx_bibblock">
SuÂ Young Kim, Hyeon-Jin Park, Kyuyong Shin, and Kyung-Min Kim. 2022.

</span>
<span class="ltx_bibblock">Ask me what you need: Product retrieval using knowledge from GPT-3.

</span>
<span class="ltx_bibblock"><em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2207.02516.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kocon etÂ al. (2023)</span>
<span class="ltx_bibblock">
Jan Kocon, Igor Cichecki, Oliwier Kaszyca, Mateusz Kochanek, Dominika Szydlo, Joanna Baran, Julita Bielaniewicz, Marcin Gruza, Arkadiusz Janz, Kamil Kanclerz, Anna Kocon, Bartlomiej Koptyra, Wiktoria Mieleszczenko-Kowszewicz, Piotr Milkowski, Marcin Oleksy, Maciej Piasecki, Lukasz Radlinski, Konrad Wojtasik, Stanislaw Wozniak, and Przemyslaw Kazienko. 2023.

</span>
<span class="ltx_bibblock">Chatgpt: Jack of all trades, master of none.

</span>
<span class="ltx_bibblock"><em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">Inf. Fusion</em>, 99:101861.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kritharoula etÂ al. (2023)</span>
<span class="ltx_bibblock">
Anastasia Kritharoula, Maria Lymperaiou, and Giorgos Stamou. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2023.emnlp-main.807" title="" class="ltx_ref ltx_href">Large language models and multimodal retrieval for visual word sense disambiguation</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</em>, pages 13053â€“13077, Singapore. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kurakin etÂ al. (2023)</span>
<span class="ltx_bibblock">
Alexey Kurakin, Natalia Ponomareva, Umar Syed, Liam MacDermed, and Andreas Terzis. 2023.

</span>
<span class="ltx_bibblock">Harnessing large-language models to generate private synthetic text.

</span>
<span class="ltx_bibblock"><em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2306.01684</em>.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Larson etÂ al. (2019)</span>
<span class="ltx_bibblock">
Stefan Larson, Anish Mahendran, JosephÂ J. Peper, Christopher Clarke, Andrew Lee, Parker Hill, JonathanÂ K. Kummerfeld, Kevin Leach, MichaelÂ A. Laurenzano, Lingjia Tang, and Jason Mars. 2019.

</span>
<span class="ltx_bibblock">An evaluation dataset for intent classification and out-of-scope prediction.

</span>
<span class="ltx_bibblock">In <em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">Proc. of EMNLP</em>.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee etÂ al. (2022)</span>
<span class="ltx_bibblock">
Nayeon Lee, Wei Ping, Peng Xu, Mostofa Patwary, PascaleÂ N Fung, Mohammad Shoeybi, and Bryan Catanzaro. 2022.

</span>
<span class="ltx_bibblock">Factuality enhanced language models for open-ended text generation.

</span>
<span class="ltx_bibblock"><em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">NeurIPS</em>.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li and Callison-Burch (2023)</span>
<span class="ltx_bibblock">
Bryan Li and Chris Callison-Burch. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2023.findings-emnlp.32" title="" class="ltx_ref ltx_href">PAXQA: Generating cross-lingual question answering examples at training scale</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational Linguistics: EMNLP 2023</em>, pages 439â€“454, Singapore. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li etÂ al. (2022)</span>
<span class="ltx_bibblock">
Junlong Li, Zhuosheng Zhang, and Hai Zhao. 2022.

</span>
<span class="ltx_bibblock">Self-prompting large language models for open-domain QA.

</span>
<span class="ltx_bibblock"><em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2212.08635.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li etÂ al. (2023a)</span>
<span class="ltx_bibblock">
Minzhi Li, Taiwei Shi, Caleb Ziems, Min-Yen Kan, Nancy Chen, Zhengyuan Liu, and Diyi Yang. 2023a.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2023.emnlp-main.92" title="" class="ltx_ref ltx_href">CoAnnotating: Uncertainty-guided work allocation between human and large language models for data annotation</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib48.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</em>, pages 1487â€“1505, Singapore. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li etÂ al. (2023b)</span>
<span class="ltx_bibblock">
Yuanzhi Li, SÃ©bastien Bubeck, Ronen Eldan, AllieÂ Del Giorno, Suriya Gunasekar, and YinÂ Tat Lee. 2023b.

</span>
<span class="ltx_bibblock">Textbooks are all you need II: phi-1.5 technical report.

</span>
<span class="ltx_bibblock"><em id="bib.bib49.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2309.05463.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li etÂ al. (2023c)</span>
<span class="ltx_bibblock">
Zhuoyan Li, Hangxiao Zhu, Zhuoran Lu, and Ming Yin. 2023c.

</span>
<span class="ltx_bibblock">Synthetic data generation with large language models for text classification: Potential and limitations.

</span>
<span class="ltx_bibblock">In <em id="bib.bib50.1.1" class="ltx_emph ltx_font_italic">EMNLP</em>, pages 10443â€“10461. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin etÂ al. (2022)</span>
<span class="ltx_bibblock">
Stephanie Lin, Jacob Hilton, and Owain Evans. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2022.acl-long.229" title="" class="ltx_ref ltx_href">TruthfulQA: Measuring how models mimic human falsehoods</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib51.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 3214â€“3252, Dublin, Ireland. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu etÂ al. (2022a)</span>
<span class="ltx_bibblock">
Alisa Liu, Swabha Swayamdipta, NoahÂ A. Smith, and Yejin Choi. 2022a.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2022.findings-emnlp.508" title="" class="ltx_ref ltx_href">WANLI: Worker and AI collaboration for natural language inference dataset creation</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib52.1.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational Linguistics: EMNLP 2022</em>, pages 6826â€“6847, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu etÂ al. (2023)</span>
<span class="ltx_bibblock">
Haotian Liu, Chunyuan Li, Yuheng Li, and YongÂ Jae Lee. 2023.

</span>
<span class="ltx_bibblock">Improved baselines with visual instruction tuning.

</span>
<span class="ltx_bibblock"><em id="bib.bib53.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2310.03744.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu etÂ al. (2022b)</span>
<span class="ltx_bibblock">
Jiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan, Lawrence Carin, and Weizhu Chen. 2022b.

</span>
<span class="ltx_bibblock">What makes good in-context examples for gpt-3?

</span>
<span class="ltx_bibblock">In <em id="bib.bib54.1.1" class="ltx_emph ltx_font_italic">DeeLIO@ACL</em>, pages 100â€“114. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu etÂ al. (2024)</span>
<span class="ltx_bibblock">
Ruibo Liu, Jerry Wei, Fangyu Liu, Chenglei Si, Yanzhe Zhang, Jinmeng Rao, Steven Zheng, Daiyi Peng, Diyi Yang, Denny Zhou, and AndrewÂ M. Dai. 2024.

</span>
<span class="ltx_bibblock">Best practices and lessons learned on synthetic data for language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib55.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2404.07503.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lu etÂ al. (2023)</span>
<span class="ltx_bibblock">
Yuzhe Lu, Sungmin Hong, Yash Shah, and Panpan Xu. 2023.

</span>
<span class="ltx_bibblock">Effectively fine-tune to improve large multimodal models for radiology report generation.

</span>
<span class="ltx_bibblock"><em id="bib.bib56.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2312.01504.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Luo etÂ al. (2023a)</span>
<span class="ltx_bibblock">
Haipeng Luo, Qingfeng Sun, Can Xu, PuÂ Zhao, Jianguang Lou, Chongyang Tao, Xiubo Geng, Qingwei Lin, Shifeng Chen, and Dongmei Zhang. 2023a.

</span>
<span class="ltx_bibblock">Wizardmath: Empowering mathematical reasoning for large language models via reinforced evol-instruct.

</span>
<span class="ltx_bibblock"><em id="bib.bib57.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2308.09583.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Luo etÂ al. (2023b)</span>
<span class="ltx_bibblock">
Ziyang Luo, Can Xu, PuÂ Zhao, Qingfeng Sun, Xiubo Geng, Wenxiang Hu, Chongyang Tao, Jing Ma, Qingwei Lin, and Daxin Jiang. 2023b.

</span>
<span class="ltx_bibblock">Wizardcoder: Empowering code large language models with evol-instruct.

</span>
<span class="ltx_bibblock"><em id="bib.bib58.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2306.08568.

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Maas etÂ al. (2011)</span>
<span class="ltx_bibblock">
AndrewÂ L. Maas, RaymondÂ E. Daly, PeterÂ T. Pham, Dan Huang, AndrewÂ Y. Ng, and Christopher Potts. 2011.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://aclanthology.org/P11-1015" title="" class="ltx_ref ltx_href">Learning word vectors for sentiment analysis</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib59.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</em>, pages 142â€“150, Portland, Oregon, USA. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Meng etÂ al. (2022)</span>
<span class="ltx_bibblock">
YuÂ Meng, Jiaxin Huang, YuÂ Zhang, and Jiawei Han. 2022.

</span>
<span class="ltx_bibblock">Generating training data with language models: Towards zero-shot language understanding.

</span>
<span class="ltx_bibblock">In <em id="bib.bib60.1.1" class="ltx_emph ltx_font_italic">NeurIPS</em>.

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Meng etÂ al. (2023)</span>
<span class="ltx_bibblock">
YuÂ Meng, Martin Michalski, Jiaxin Huang, YuÂ Zhang, Tarek Abdelzaher, and Jiawei Han. 2023.

</span>
<span class="ltx_bibblock">Tuning language models as training data generators for augmentation-enhanced few-shot learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib61.1.1" class="ltx_emph ltx_font_italic">ICML</em>, pages 24457â€“24477. PMLR.

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mitra etÂ al. (2023)</span>
<span class="ltx_bibblock">
Arindam Mitra, LucianoÂ Del Corro, Shweti Mahajan, AndrÃ©s Codas, Clarisse SimÃµes, Sahaj Agrawal, Xuxi Chen, Anastasia Razdaibiedina, Erik Jones, Kriti Aggarwal, Hamid Palangi, Guoqing Zheng, Corby Rosset, Hamed Khanpour, and Ahmed Awadallah. 2023.

</span>
<span class="ltx_bibblock">Orca 2: Teaching small language models how to reason.

</span>
<span class="ltx_bibblock"><em id="bib.bib62.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2311.11045.

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mukherjee etÂ al. (2023)</span>
<span class="ltx_bibblock">
Subhabrata Mukherjee, Arindam Mitra, Ganesh Jawahar, Sahaj Agarwal, Hamid Palangi, and Ahmed Awadallah. 2023.

</span>
<span class="ltx_bibblock">Orca: Progressive learning from complex explanation traces of GPT-4.

</span>
<span class="ltx_bibblock"><em id="bib.bib63.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2306.02707.

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Navigli etÂ al. (2023)</span>
<span class="ltx_bibblock">
Roberto Navigli, Simone Conia, and BjÃ¶rn Ross. 2023.

</span>
<span class="ltx_bibblock">Biases in large language models: Origins, inventory, and discussion.

</span>
<span class="ltx_bibblock"><em id="bib.bib64.1.1" class="ltx_emph ltx_font_italic">ACM J. Data Inf. Qual.</em>, 15(2):10:1â€“10:21.

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Oh etÂ al. (2023)</span>
<span class="ltx_bibblock">
Seokjin Oh, SuÂ Ah Lee, and Woohwan Jung. 2023.

</span>
<span class="ltx_bibblock">Data augmentation for neural machine translation using generative language model.

</span>
<span class="ltx_bibblock"><em id="bib.bib65.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2307.16833.

</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pangakis etÂ al. (2023)</span>
<span class="ltx_bibblock">
Nicholas Pangakis, Samuel Wolken, and Neil Fasching. 2023.

</span>
<span class="ltx_bibblock">Automated annotation with generative AI requires validation.

</span>
<span class="ltx_bibblock"><em id="bib.bib66.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2306.00176.

</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Peng etÂ al. (2023)</span>
<span class="ltx_bibblock">
RuÂ Peng, Qiuyang Duan, Haobo Wang, Jiachen Ma, Yanbo Jiang, Yongjun Tu, Xiu Jiang, and Junbo Zhao. 2023.

</span>
<span class="ltx_bibblock">Came: Contrastive automated model evaluation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib67.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF International Conference on Computer Vision</em>, pages 20121â€“20132.

</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Peng etÂ al. (2024)</span>
<span class="ltx_bibblock">
RuÂ Peng, Heming Zou, Haobo Wang, Yawen Zeng, Zenan Huang, and Junbo Zhao. 2024.

</span>
<span class="ltx_bibblock">Energy-based automated model evaluation.

</span>
<span class="ltx_bibblock"><em id="bib.bib68.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2401.12689</em>.

</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qin etÂ al. (2023)</span>
<span class="ltx_bibblock">
Yujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan Yan, Yaxi Lu, Yankai Lin, Xin Cong, Xiangru Tang, Bill Qian, Sihan Zhao, Runchu Tian, Ruobing Xie, Jie Zhou, Mark Gerstein, Dahai Li, Zhiyuan Liu, and Maosong Sun. 2023.

</span>
<span class="ltx_bibblock">Toolllm: Facilitating large language models to master 16000+ real-world apis.

</span>
<span class="ltx_bibblock"><em id="bib.bib69.1.1" class="ltx_emph ltx_font_italic">CoRR</em>.

</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford etÂ al. (2019)</span>
<span class="ltx_bibblock">
Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. 2019.

</span>
<span class="ltx_bibblock">Language models are unsupervised multitask learners.

</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Saad-Falcon etÂ al. (2023)</span>
<span class="ltx_bibblock">
Jon Saad-Falcon, Omar Khattab, Keshav Santhanam, Radu Florian, Martin Franz, Salim Roukos, Avirup Sil, MdÂ Sultan, and Christopher Potts. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2023.emnlp-main.693" title="" class="ltx_ref ltx_href">UDAPDR: Unsupervised domain adaptation via LLM prompting and distillation of rerankers</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib71.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</em>, pages 11265â€“11279, Singapore. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sahu etÂ al. (2022)</span>
<span class="ltx_bibblock">
Gaurav Sahu, Pau Rodriguez, Issam Laradji, Parmida Atighehchian, David Vazquez, and Dzmitry Bahdanau. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2022.nlp4convai-1.5" title="" class="ltx_ref ltx_href">Data augmentation for intent classification with off-the-shelf large language models</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib72.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 4th Workshop on NLP for Conversational AI</em>, pages 47â€“57, Dublin, Ireland. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Seedat etÂ al. (2023)</span>
<span class="ltx_bibblock">
Nabeel Seedat, Nicolas Huynh, Boris van Breugel, and Mihaela vanÂ der Schaar. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2312.12112" title="" class="ltx_ref ltx_href">Curated llm: Synergy of llms and data curation for tabular augmentation in ultra low-data regimes</a>.

</span>
</li>
<li id="bib.bib74" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shao etÂ al. (2023)</span>
<span class="ltx_bibblock">
Zhihong Shao, Yeyun Gong, Yelong Shen, Minlie Huang, Nan Duan, and Weizhu Chen. 2023.

</span>
<span class="ltx_bibblock">Synthetic prompting: Generating chain-of-thought demonstrations for large language models.

</span>
<span class="ltx_bibblock">In <em id="bib.bib74.1.1" class="ltx_emph ltx_font_italic">ICML</em>, volume 202 of <em id="bib.bib74.2.2" class="ltx_emph ltx_font_italic">Proceedings of Machine Learning Research</em>, pages 30706â€“30775. PMLR.

</span>
</li>
<li id="bib.bib75" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shen etÂ al. (2023)</span>
<span class="ltx_bibblock">
Yongliang Shen, Kaitao Song, XuÂ Tan, Dongsheng Li, Weiming Lu, and Yueting Zhuang. 2023.

</span>
<span class="ltx_bibblock">Hugginggpt: Solving AI tasks with chatgpt and its friends in huggingface.

</span>
<span class="ltx_bibblock"><em id="bib.bib75.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2303.17580.

</span>
</li>
<li id="bib.bib76" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Singh etÂ al. (2023)</span>
<span class="ltx_bibblock">
Avi Singh, JohnÂ D. Co-Reyes, Rishabh Agarwal, Ankesh Anand, Piyush Patil, Xavier Garcia, PeterÂ J. Liu, James Harrison, Jaehoon Lee, Kelvin Xu, Aaron Parisi, Abhishek Kumar, Alex Alemi, Alex Rizkowsky, Azade Nova, Ben Adlam, Bernd Bohnet, GamaleldinÂ F. Elsayed, Hanie Sedghi, Igor Mordatch, Isabelle Simpson, Izzeddin Gur, Jasper Snoek, Jeffrey Pennington, Jiri Hron, Kathleen Kenealy, Kevin Swersky, Kshiteej Mahajan, Laura Culp, Lechao Xiao, MaxwellÂ L. Bileschi, Noah Constant, Roman Novak, Rosanne Liu, Tris Warkentin, Yundi Qian, Yamini Bansal, Ethan Dyer, Behnam Neyshabur, Jascha Sohl-Dickstein, and Noah Fiedel. 2023.

</span>
<span class="ltx_bibblock">Beyond human data: Scaling self-training for problem-solving with language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib76.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2312.06585.

</span>
</li>
<li id="bib.bib77" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Smith etÂ al. (2022)</span>
<span class="ltx_bibblock">
Ryan Smith, JasonÂ A. Fries, Braden Hancock, and StephenÂ H. Bach. 2022.

</span>
<span class="ltx_bibblock">Language models in the loop: Incorporating prompting into weak supervision.

</span>
<span class="ltx_bibblock"><em id="bib.bib77.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2205.02318.

</span>
</li>
<li id="bib.bib78" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Srivastava etÂ al. (2022)</span>
<span class="ltx_bibblock">
Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu AwalÂ Md Shoeb, Abubakar Abid, Adam Fisch, AdamÂ R. Brown, Adam Santoro, Aditya Gupta, AdriÃ  Garriga-Alonso, Agnieszka Kluska, Aitor Lewkowycz, Akshat Agarwal, Alethea Power, Alex Ray, Alex Warstadt, AlexanderÂ W. Kocurek, Ali Safaya, Ali Tazarv, Alice Xiang, Alicia Parrish, Allen Nie, Aman Hussain, Amanda Askell, Amanda Dsouza, Ameet Rahane, AnantharamanÂ S. Iyer, Anders Andreassen, Andrea Santilli, Andreas StuhlmÃ¼ller, AndrewÂ M. Dai, Andrew La, AndrewÂ K. Lampinen, Andy Zou, Angela Jiang, Angelica Chen, Anh Vuong, Animesh Gupta, Anna Gottardi, Antonio Norelli, Anu Venkatesh, Arash Gholamidavoodi, Arfa Tabassum, Arul Menezes, Arun Kirubarajan, Asher Mullokandov, Ashish Sabharwal, Austin Herrick, Avia Efrat, Aykut Erdem, Ayla Karakas, and etÂ al. 2022.

</span>
<span class="ltx_bibblock">Beyond the imitation game: Quantifying and extrapolating the capabilities of language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib78.1.1" class="ltx_emph ltx_font_italic">CoRR</em>.

</span>
</li>
<li id="bib.bib79" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Su etÂ al. (2023)</span>
<span class="ltx_bibblock">
Hongjin Su, Jungo Kasai, ChenÂ Henry Wu, Weijia Shi, Tianlu Wang, Jiayi Xin, Rui Zhang, Mari Ostendorf, Luke Zettlemoyer, NoahÂ A. Smith, and Tao Yu. 2023.

</span>
<span class="ltx_bibblock">Selective annotation makes language models better few-shot learners.

</span>
<span class="ltx_bibblock">In <em id="bib.bib79.1.1" class="ltx_emph ltx_font_italic">ICLR</em>. OpenReview.net.

</span>
</li>
<li id="bib.bib80" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sudalairaj etÂ al. (2024)</span>
<span class="ltx_bibblock">
Shivchander Sudalairaj, Abhishek Bhandwaldar, Aldo Pareja, Kai Xu, DavidÂ D. Cox, and Akash Srivastava. 2024.

</span>
<span class="ltx_bibblock">LAB: large-scale alignment for chatbots.

</span>
<span class="ltx_bibblock"><em id="bib.bib80.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2403.01081.

</span>
</li>
<li id="bib.bib81" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun etÂ al. (2023)</span>
<span class="ltx_bibblock">
Zhiqing Sun, Yikang Shen, Qinhong Zhou, Hongxin Zhang, Zhenfang Chen, DavidÂ D. Cox, Yiming Yang, and Chuang Gan. 2023.

</span>
<span class="ltx_bibblock">Principle-driven self-alignment of language models from scratch with minimal human supervision.

</span>
<span class="ltx_bibblock"><em id="bib.bib81.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2305.03047.

</span>
</li>
<li id="bib.bib82" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tang etÂ al. (2023)</span>
<span class="ltx_bibblock">
Ruixiang Tang, Xiaotian Han, Xiaoqian Jiang, and Xia Hu. 2023.

</span>
<span class="ltx_bibblock">Does synthetic data generation of llms help clinical text mining?

</span>
<span class="ltx_bibblock"><em id="bib.bib82.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2303.04360.

</span>
</li>
<li id="bib.bib83" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Taori etÂ al. (2023)</span>
<span class="ltx_bibblock">
Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, and TatsunoriÂ B. Hashimoto. 2023.

</span>
<span class="ltx_bibblock">Stanford alpaca: An instruction-following llama model.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/tatsu-lab/stanford_alpaca" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/tatsu-lab/stanford_alpaca</a>.

</span>
</li>
<li id="bib.bib84" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wan etÂ al. (2023)</span>
<span class="ltx_bibblock">
Fanqi Wan, Xinting Huang, Tao Yang, Xiaojun Quan, Wei Bi, and Shuming Shi. 2023.

</span>
<span class="ltx_bibblock">Explore-instruct: Enhancing domain-specific instruction coverage through active exploration.

</span>
<span class="ltx_bibblock">In <em id="bib.bib84.1.1" class="ltx_emph ltx_font_italic">EMNLP</em>, pages 9435â€“9454. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib85" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang etÂ al. (2018)</span>
<span class="ltx_bibblock">
Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel Bowman. 2018.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/W18-5446" title="" class="ltx_ref ltx_href">GLUE: A multi-task benchmark and analysis platform for natural language understanding</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib85.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP</em>, pages 353â€“355, Brussels, Belgium. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib86" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang etÂ al. (2023a)</span>
<span class="ltx_bibblock">
Guan Wang, Sijie Cheng, Xianyuan Zhan, Xiangang Li, Sen Song, and Yang Liu. 2023a.

</span>
<span class="ltx_bibblock">Openchat: Advancing open-source language models with mixed-quality data.

</span>
<span class="ltx_bibblock"><em id="bib.bib86.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2309.11235</em>.

</span>
</li>
<li id="bib.bib87" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang etÂ al. (2023b)</span>
<span class="ltx_bibblock">
Ruida Wang, Wangchunshu Zhou, and Mrinmaya Sachan. 2023b.

</span>
<span class="ltx_bibblock">Letâ€™s synthesize step by step: Iterative dataset synthesis with large language models by extrapolating errors from small models.

</span>
<span class="ltx_bibblock">In <em id="bib.bib87.1.1" class="ltx_emph ltx_font_italic">EMNLP (Findings)</em>, pages 11817â€“11831. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib88" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang etÂ al. (2021)</span>
<span class="ltx_bibblock">
Shuohang Wang, Yang Liu, Yichong Xu, Chenguang Zhu, and Michael Zeng. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2021.findings-emnlp.354" title="" class="ltx_ref ltx_href">Want to reduce labeling cost? GPT-3 can help</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib88.1.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational Linguistics: EMNLP 2021</em>, pages 4195â€“4205, Punta Cana, Dominican Republic. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib89" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang etÂ al. (2023c)</span>
<span class="ltx_bibblock">
Yidong Wang, Zhuohao Yu, Zhengran Zeng, Linyi Yang, Cunxiang Wang, Hao Chen, Chaoya Jiang, Rui Xie, Jindong Wang, Xingxu Xie, Wei Ye, Shi-Bo Zhang, and Yue Zhang. 2023c.

</span>
<span class="ltx_bibblock">Pandalm: An automatic evaluation benchmark for llm instruction tuning optimization.

</span>
<span class="ltx_bibblock"><em id="bib.bib89.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>.

</span>
</li>
<li id="bib.bib90" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang etÂ al. (2023d)</span>
<span class="ltx_bibblock">
Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, NoahÂ A. Smith, Daniel Khashabi, and Hannaneh Hajishirzi. 2023d.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2023.acl-long.754" title="" class="ltx_ref ltx_href">Self-instruct: Aligning language models with self-generated instructions</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib90.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 13484â€“13508, Toronto, Canada. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib91" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang etÂ al. (2023e)</span>
<span class="ltx_bibblock">
Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, NoahÂ A. Smith, Daniel Khashabi, and Hannaneh Hajishirzi. 2023e.

</span>
<span class="ltx_bibblock">Self-instruct: Aligning language models with self-generated instructions.

</span>
<span class="ltx_bibblock">In <em id="bib.bib91.1.1" class="ltx_emph ltx_font_italic">ACL</em>, pages 13484â€“13508. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib92" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang etÂ al. (2022)</span>
<span class="ltx_bibblock">
Yizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh Kordi, Amirreza Mirzaei, Atharva Naik, Arjun Ashok, ArutÂ Selvan Dhanasekaran, Anjana Arunkumar, David Stap, Eshaan Pathak, Giannis Karamanolakis, Haizhi Lai, Ishan Purohit, Ishani Mondal, Jacob Anderson, Kirby Kuznia, Krima Doshi, KuntalÂ Kumar Pal, Maitreya Patel, Mehrad Moradshahi, Mihir Parmar, Mirali Purohit, Neeraj Varshney, PhaniÂ Rohitha Kaza, Pulkit Verma, RavsehajÂ Singh Puri, Rushang Karia, Savan Doshi, ShailajaÂ Keyur Sampat, Siddhartha Mishra, Sujan ReddyÂ A, Sumanta Patro, Tanay Dixit, and Xudong Shen. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2022.emnlp-main.340" title="" class="ltx_ref ltx_href">Super-NaturalInstructions: Generalization via declarative instructions on 1600+ NLP tasks</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib92.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing</em>, pages 5085â€“5109, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib93" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei etÂ al. (2023a)</span>
<span class="ltx_bibblock">
Fusheng Wei, Robert Keeling, Nathaniel Huber-Fliflet, Jianping Zhang, Adam Dabrowski, Jingchao Yang, Qiang Mao, and Han Qin. 2023a.

</span>
<span class="ltx_bibblock">Empirical study of LLM fine-tuning for text classification in legal document review.

</span>
<span class="ltx_bibblock">In <em id="bib.bib93.1.1" class="ltx_emph ltx_font_italic">IEEE Big Data</em>, pages 2786â€“2792. IEEE.

</span>
</li>
<li id="bib.bib94" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei etÂ al. (2022)</span>
<span class="ltx_bibblock">
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, EdÂ H. Chi, QuocÂ V. Le, and Denny Zhou. 2022.

</span>
<span class="ltx_bibblock">Chain-of-thought prompting elicits reasoning in large language models.

</span>
<span class="ltx_bibblock">In <em id="bib.bib94.1.1" class="ltx_emph ltx_font_italic">NeurIPS</em>.

</span>
</li>
<li id="bib.bib95" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei etÂ al. (2024)</span>
<span class="ltx_bibblock">
Jerry Wei, Chengrun Yang, Xinying Song, Yifeng Lu, Nathan Hu, Dustin Tran, Daiyi Peng, Ruibo Liu, DaÂ Huang, Cosmo Du, and QuocÂ V. Le. 2024.

</span>
<span class="ltx_bibblock">Long-form factuality in large language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib95.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2403.18802.

</span>
</li>
<li id="bib.bib96" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei etÂ al. (2023b)</span>
<span class="ltx_bibblock">
Yuxiang Wei, Zhe Wang, Jiawei Liu, Yifeng Ding, and Lingming Zhang. 2023b.

</span>
<span class="ltx_bibblock">Magicoder: Source code is all you need.

</span>
<span class="ltx_bibblock"><em id="bib.bib96.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2312.02120.

</span>
</li>
<li id="bib.bib97" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xiao and Chen (2023)</span>
<span class="ltx_bibblock">
LeÂ Xiao and Xiaolin Chen. 2023.

</span>
<span class="ltx_bibblock">Enhancing LLM with evolutionary fine tuning for news summary generation.

</span>
<span class="ltx_bibblock"><em id="bib.bib97.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2307.02839.

</span>
</li>
<li id="bib.bib98" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xiao etÂ al. (2023)</span>
<span class="ltx_bibblock">
Ruixuan Xiao, Yiwen Dong, Junbo Zhao, Runze Wu, Minmin Lin, Gang Chen, and Haobo Wang. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2023.emnlp-main.896" title="" class="ltx_ref ltx_href">FreeAL: Towards human-free active learning in the era of large language models</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib98.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</em>, pages 14520â€“14535, Singapore. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib99" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu etÂ al. (2023a)</span>
<span class="ltx_bibblock">
Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, PuÂ Zhao, Jiazhan Feng, Chongyang Tao, and Daxin Jiang. 2023a.

</span>
<span class="ltx_bibblock">Wizardlm: Empowering large language models to follow complex instructions.

</span>
<span class="ltx_bibblock"><em id="bib.bib99.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2304.12244.

</span>
</li>
<li id="bib.bib100" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu etÂ al. (2023b)</span>
<span class="ltx_bibblock">
Ran Xu, Hejie Cui, Yue Yu, Xuan Kan, Wenqi Shi, Yuchen Zhuang, Wei Jin, JoyceÂ C. Ho, and CarlÂ J. Yang. 2023b.

</span>
<span class="ltx_bibblock">Knowledge-infused prompting: Assessing and advancing clinical text data generation with large language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib100.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2311.00287.

</span>
</li>
<li id="bib.bib101" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ye etÂ al. (2022a)</span>
<span class="ltx_bibblock">
Jiacheng Ye, Jiahui Gao, Qintong Li, Hang Xu, Jiangtao Feng, Zhiyong Wu, Tao Yu, and Lingpeng Kong. 2022a.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2022.emnlp-main.801" title="" class="ltx_ref ltx_href">ZeroGen: Efficient zero-shot learning via dataset generation</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib101.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing</em>, pages 11653â€“11669, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib102" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ye etÂ al. (2022b)</span>
<span class="ltx_bibblock">
Jiacheng Ye, Jiahui Gao, Zhiyong Wu, Jiangtao Feng, Tao Yu, and Lingpeng Kong. 2022b.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2022.findings-emnlp.269" title="" class="ltx_ref ltx_href">ProGen: Progressive zero-shot dataset generation via in-context feedback</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib102.1.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational Linguistics: EMNLP 2022</em>, pages 3671â€“3683, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib103" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ye etÂ al. (2023)</span>
<span class="ltx_bibblock">
Jiacheng Ye, Chengzu Li, Lingpeng Kong, and Tao Yu. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2023.emnlp-main.523" title="" class="ltx_ref ltx_href">Generating data for symbolic language with large language models</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib103.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</em>, pages 8418â€“8443, Singapore. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib104" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yoo etÂ al. (2021)</span>
<span class="ltx_bibblock">
KangÂ Min Yoo, Dongju Park, Jaewook Kang, Sang-Woo Lee, and Woo-Myoung Park. 2021.

</span>
<span class="ltx_bibblock">Gpt3mix: Leveraging large-scale language models for text augmentation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib104.1.1" class="ltx_emph ltx_font_italic">EMNLP</em>, pages 2225â€“2239. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib105" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu etÂ al. (2023a)</span>
<span class="ltx_bibblock">
Longhui Yu, Weisen Jiang, Han Shi, Jincheng Yu, Zhengying Liu, YuÂ Zhang, JamesÂ T. Kwok, Zhenguo Li, Adrian Weller, and Weiyang Liu. 2023a.

</span>
<span class="ltx_bibblock">Metamath: Bootstrap your own mathematical questions for large language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib105.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2309.12284.

</span>
</li>
<li id="bib.bib106" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu etÂ al. (2023b)</span>
<span class="ltx_bibblock">
Yue Yu, Yuchen Zhuang, Jieyu Zhang, YuÂ Meng, Alexander Ratner, Ranjay Krishna, Jiaming Shen, and Chao Zhang. 2023b.

</span>
<span class="ltx_bibblock">Large language model as attributed training data generator: A tale of diversity and bias.

</span>
<span class="ltx_bibblock"><em id="bib.bib106.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2306.15895.

</span>
</li>
<li id="bib.bib107" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu etÂ al. (2023c)</span>
<span class="ltx_bibblock">
Yue Yu, Yuchen Zhuang, Rongzhi Zhang, YuÂ Meng, Jiaming Shen, and Chao Zhang. 2023c.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2023.findings-acl.748" title="" class="ltx_ref ltx_href">ReGen: Zero-shot text classification via training data generation with progressive dense retrieval</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib107.1.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational Linguistics: ACL 2023</em>, pages 11782â€“11805, Toronto, Canada. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib108" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang etÂ al. (2023a)</span>
<span class="ltx_bibblock">
Chaoning Zhang, Chenshuang Zhang, Sheng Zheng, YuÂ Qiao, Chenghao Li, Mengchun Zhang, SumitÂ Kumar Dam, ChuÂ Myaet Thwal, YeÂ Lin Tun, LeÂ Luang Huy, DongÂ Uk Kim, Sung-Ho Bae, Lik-Hang Lee, Yang Yang, HengÂ Tao Shen, InÂ So Kweon, and ChoongÂ Seon Hong. 2023a.

</span>
<span class="ltx_bibblock">A complete survey on generative AI (AIGC): is chatgpt from GPT-4 to GPT-5 all you need?

</span>
<span class="ltx_bibblock"><em id="bib.bib108.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2303.11717.

</span>
</li>
<li id="bib.bib109" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang etÂ al. (2022)</span>
<span class="ltx_bibblock">
Jieyu Zhang, Bohan Wang, Xiangchen Song, Yujing Wang, Yaming Yang, Jing Bai, and Alexander Ratner. 2022.

</span>
<span class="ltx_bibblock">Creating training sets via weak indirect supervision.

</span>
<span class="ltx_bibblock">In <em id="bib.bib109.1.1" class="ltx_emph ltx_font_italic">ICLR</em>. OpenReview.net.

</span>
</li>
<li id="bib.bib110" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang etÂ al. (2023b)</span>
<span class="ltx_bibblock">
Ruoyu Zhang, Yanzeng Li, Yongliang Ma, Ming Zhou, and Lei Zou. 2023b.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2023.findings-emnlp.872" title="" class="ltx_ref ltx_href">LLMaAA: Making large language models as active annotators</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib110.1.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational Linguistics: EMNLP 2023</em>, pages 13088â€“13103, Singapore. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib111" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang etÂ al. (2015)</span>
<span class="ltx_bibblock">
Xiang Zhang, JunboÂ Jake Zhao, and Yann LeCun. 2015.

</span>
<span class="ltx_bibblock">Character-level convolutional networks for text classification.

</span>
<span class="ltx_bibblock">In <em id="bib.bib111.1.1" class="ltx_emph ltx_font_italic">Proc. of NeurIPS</em>.

</span>
</li>
<li id="bib.bib112" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao etÂ al. (2023a)</span>
<span class="ltx_bibblock">
Jiachen Zhao, Wenlong Zhao, Andrew Drozdov, Benjamin Rozonoyer, Md.Â Arafat Sultan, Jay-Yoon Lee, Mohit Iyyer, and Andrew McCallum. 2023a.

</span>
<span class="ltx_bibblock">Multistage collaborative knowledge distillation from large language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib112.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2311.08640.

</span>
</li>
<li id="bib.bib113" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao etÂ al. (2023b)</span>
<span class="ltx_bibblock">
Zilong Zhao, Robert Birke, and Lydia Chen. 2023b.

</span>
<span class="ltx_bibblock">Tabula: Harnessing language models for tabular data synthesis.

</span>
<span class="ltx_bibblock"><em id="bib.bib113.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2310.12746</em>.

</span>
</li>
<li id="bib.bib114" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zheng etÂ al. (2023)</span>
<span class="ltx_bibblock">
Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, ZiÂ Lin, Zhuohan Li, Dacheng Li, Eric.Â P Xing, Hao Zhang, JosephÂ E. Gonzalez, and Ion Stoica. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2306.05685" title="" class="ltx_ref ltx_href">Judging llm-as-a-judge with mt-bench and chatbot arena</a>.

</span>
</li>
<li id="bib.bib115" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu etÂ al. (2023)</span>
<span class="ltx_bibblock">
Yiming Zhu, Peixian Zhang, Ehsan ulÂ Haq, Pan Hui, and Gareth Tyson. 2023.

</span>
<span class="ltx_bibblock">Can chatgpt reproduce human-generated labels? A study of social computing tasks.

</span>
<span class="ltx_bibblock"><em id="bib.bib115.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2304.10145.

</span>
</li>
</ul>
</section>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Data Annotation</h2>

<div id="A1.p1" class="ltx_para">
<p id="A1.p1.1" class="ltx_p">In the main text, we introduced a series of techniques for general data synthesis. Though annotation can be considered a special type of synthesis with the input of a particular sample as the synthesis condition, there are also approaches specifically suitable for data annotation. Among them, <span id="A1.p1.1.1" class="ltx_text ltx_font_italic">selective annotation</span> is one of the most important practices. Selective annotation represents an optimal tradeoff between expensive and precise human annotation and economic but relatively rough LLMs-based annotation<cite class="ltx_cite ltx_citemacro_cite">Wang etÂ al. (<a href="#bib.bib88" title="" class="ltx_ref">2021</a>); Kocon etÂ al. (<a href="#bib.bib41" title="" class="ltx_ref">2023</a>)</cite>.</p>
</div>
<div id="A1.p2" class="ltx_para">
<p id="A1.p2.2" class="ltx_p">The key to selective annotation is to define a "cost-effective" sample distribution between humans and LLMs. <cite class="ltx_cite ltx_citemacro_cite">Zhang etÂ al. (<a href="#bib.bib110" title="" class="ltx_ref">2023b</a>); Bansal and Sharma (<a href="#bib.bib4" title="" class="ltx_ref">2023</a>)</cite> covers some common selection strategies for LLMs-based annotation, including random selection, maximum entropy selection, least confidence selection and <math id="A1.p2.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="A1.p2.1.m1.1a"><mi id="A1.p2.1.m1.1.1" xref="A1.p2.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="A1.p2.1.m1.1b"><ci id="A1.p2.1.m1.1.1.cmml" xref="A1.p2.1.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.p2.1.m1.1c">k</annotation></semantics></math>means selection for thorough comparisons.
Results show that uncertainty-based methods, i.e. maximal entropy and least confidence, perform significantly better than the random baseline, with faster convergence and better performance of the downstream model trained on the annotated data. <cite class="ltx_cite ltx_citemacro_cite">Li etÂ al. (<a href="#bib.bib48" title="" class="ltx_ref">2023a</a>)</cite> also utilizes uncertainty to estimate LLMsâ€™ annotation capability to effectively allocate the annotation work among humans and LLMs.
<cite class="ltx_cite ltx_citemacro_cite">Su etÂ al. (<a href="#bib.bib79" title="" class="ltx_ref">2023</a>)</cite> instead proposes a novel unsupervised, graph-based selective annotation method named vote-<math id="A1.p2.2.m2.1" class="ltx_Math" alttext="k" display="inline"><semantics id="A1.p2.2.m2.1a"><mi id="A1.p2.2.m2.1.1" xref="A1.p2.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="A1.p2.2.m2.1b"><ci id="A1.p2.2.m2.1.1.cmml" xref="A1.p2.2.m2.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.p2.2.m2.1c">k</annotation></semantics></math>, to select diverse and representative examples to annotate.</p>
</div>
</section>
<section id="A2" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Tuning Techniques</h2>

<div id="A2.p1" class="ltx_para">
<p id="A2.p1.1" class="ltx_p">Another large body of research pertains to the <span id="A2.p1.1.1" class="ltx_text ltx_font_italic">tuning techniques</span>, such as model fine-tuning <cite class="ltx_cite ltx_citemacro_cite">Zhao etÂ al. (<a href="#bib.bib113" title="" class="ltx_ref">2023b</a>); Sun etÂ al. (<a href="#bib.bib81" title="" class="ltx_ref">2023</a>); Meng etÂ al. (<a href="#bib.bib61" title="" class="ltx_ref">2023</a>); Kurakin etÂ al. (<a href="#bib.bib43" title="" class="ltx_ref">2023</a>)</cite> and soft prompting <cite class="ltx_cite ltx_citemacro_cite">Chen etÂ al. (<a href="#bib.bib8" title="" class="ltx_ref">2023a</a>)</cite>, which have already been heavily studied in other fields and can be detailedly referred in <cite class="ltx_cite ltx_citemacro_cite">Hu etÂ al. (<a href="#bib.bib35" title="" class="ltx_ref">2023</a>); Lu etÂ al. (<a href="#bib.bib56" title="" class="ltx_ref">2023</a>); Wei etÂ al. (<a href="#bib.bib93" title="" class="ltx_ref">2023a</a>); Xiao and Chen (<a href="#bib.bib97" title="" class="ltx_ref">2023</a>)</cite>. Despite their effectiveness in improving the generation performance, most of the existing approaches are established on the accessibility of the LLMs, while their application on black-box models remains to be further explored.</p>
</div>
</section>
<section id="A3" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Applications</h2>

<div id="A3.p1" class="ltx_para">
<p id="A3.p1.1" class="ltx_p">LLM-driven synthetic data generation has served as a new alternative to traditional human-dependent data collection and demonstrated great potential in various applications, including general tasks, domain-specific tasks, and multimodal tasks.</p>
</div>
<section id="A3.SS0.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Generic Tasks.</h5>

<div id="A3.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="A3.SS0.SSS0.Px1.p1.1" class="ltx_p">With the exploding capabilities of LLMs, this generation pipeline has been adopted in a wide range of basic NLP studies, including text classification <cite class="ltx_cite ltx_citemacro_cite">Ye etÂ al. (<a href="#bib.bib102" title="" class="ltx_ref">2022b</a>); Yu etÂ al. (<a href="#bib.bib107" title="" class="ltx_ref">2023c</a>); Sahu etÂ al. (<a href="#bib.bib72" title="" class="ltx_ref">2022</a>)</cite>, named entity recognition <cite class="ltx_cite ltx_citemacro_cite">Xiao etÂ al. (<a href="#bib.bib98" title="" class="ltx_ref">2023</a>)</cite>, question answering <cite class="ltx_cite ltx_citemacro_cite">Li and Callison-Burch (<a href="#bib.bib46" title="" class="ltx_ref">2023</a>)</cite>, relationship extraction <cite class="ltx_cite ltx_citemacro_cite">He etÂ al. (<a href="#bib.bib29" title="" class="ltx_ref">2023</a>)</cite>, and natural language inference <cite class="ltx_cite ltx_citemacro_cite">Zhang etÂ al. (<a href="#bib.bib110" title="" class="ltx_ref">2023b</a>)</cite>. These studies further underpin diverse applications, such as sentiment recognition <cite class="ltx_cite ltx_citemacro_cite">Gao etÂ al. (<a href="#bib.bib20" title="" class="ltx_ref">2023a</a>); Ye etÂ al. (<a href="#bib.bib102" title="" class="ltx_ref">2022b</a>)</cite>, online translation <cite class="ltx_cite ltx_citemacro_cite">Oh etÂ al. (<a href="#bib.bib65" title="" class="ltx_ref">2023</a>)</cite>, stance detection <cite class="ltx_cite ltx_citemacro_cite">Li etÂ al. (<a href="#bib.bib48" title="" class="ltx_ref">2023a</a>)</cite> and spam identification <cite class="ltx_cite ltx_citemacro_cite">Smith etÂ al. (<a href="#bib.bib77" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
</section>
<section id="A3.SS0.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Domain-specific Tasks.</h5>

<div id="A3.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="A3.SS0.SSS0.Px2.p1.1" class="ltx_p">Some domain-specific tasks also impose significant demands on this pipeline, where human annotation can be extremely expensive and impractical, such as medical diagnosis <cite class="ltx_cite ltx_citemacro_cite">Tang etÂ al. (<a href="#bib.bib82" title="" class="ltx_ref">2023</a>)</cite>, drug discovery <cite class="ltx_cite ltx_citemacro_cite">Xiao etÂ al. (<a href="#bib.bib98" title="" class="ltx_ref">2023</a>)</cite>, clinical trial extraction <cite class="ltx_cite ltx_citemacro_cite">Xu etÂ al. (<a href="#bib.bib100" title="" class="ltx_ref">2023b</a>)</cite>, industrial advertisement <cite class="ltx_cite ltx_citemacro_cite">Zhang etÂ al. (<a href="#bib.bib109" title="" class="ltx_ref">2022</a>)</cite> and tabular data analysis <cite class="ltx_cite ltx_citemacro_cite">Seedat etÂ al. (<a href="#bib.bib73" title="" class="ltx_ref">2023</a>)</cite>.</p>
</div>
</section>
<section id="A3.SS0.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Multimodal Tasks.</h5>

<div id="A3.SS0.SSS0.Px3.p1" class="ltx_para">
<p id="A3.SS0.SSS0.Px3.p1.1" class="ltx_p">Stemming from the simplicity and low cost, this generation paradigm has also exhibited significant promise in multimodal tasks, including text-image retrieval <cite class="ltx_cite ltx_citemacro_cite">Kritharoula etÂ al. (<a href="#bib.bib42" title="" class="ltx_ref">2023</a>)</cite>, chat understanding <cite class="ltx_cite ltx_citemacro_cite">Han etÂ al. (<a href="#bib.bib27" title="" class="ltx_ref">2023</a>)</cite>, visual question answering <cite class="ltx_cite ltx_citemacro_cite">Han and Gardent (<a href="#bib.bib26" title="" class="ltx_ref">2023</a>)</cite>, and multimodal instruction tuning <cite class="ltx_cite ltx_citemacro_cite">Liu etÂ al. (<a href="#bib.bib53" title="" class="ltx_ref">2023</a>)</cite>.</p>
</div>
<div id="A3.T1" class="ltx_table ltx_transformed_outer" style="width:103.3pt;height:433.6pt;vertical-align:-0.0pt;"><div class="ltx_transformed_inner" style="width:433.6pt;transform:translate(-165.15pt,-164.65pt) rotate(-90deg) ;"><figure>
<div id="A3.T1.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:102.3pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-393.4pt,92.8pt) scale(0.355283954478148,0.355283954478148) ;">
<table id="A3.T1.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A3.T1.1.1.1.1" class="ltx_tr">
<th id="A3.T1.1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt">Type</th>
<th id="A3.T1.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt">Benchmark Dataset</th>
<th id="A3.T1.1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt">Subdataset Quantity</th>
<th id="A3.T1.1.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Partial Subdataset</th>
<th id="A3.T1.1.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Task</th>
<th id="A3.T1.1.1.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Ability</th>
<th id="A3.T1.1.1.1.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Domain/Data Source</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A3.T1.1.1.2.1" class="ltx_tr">
<th id="A3.T1.1.1.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" rowspan="9"><span id="A3.T1.1.1.2.1.1.1" class="ltx_text">Classification</span></th>
<th id="A3.T1.1.1.2.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">SMS spam <cite class="ltx_cite ltx_citemacro_cite">Almeida etÂ al. (<a href="#bib.bib1" title="" class="ltx_ref">2011</a>); Li etÂ al. (<a href="#bib.bib50" title="" class="ltx_ref">2023c</a>)</cite>
</th>
<th id="A3.T1.1.1.2.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">1</th>
<td id="A3.T1.1.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t">SMS spam</td>
<td id="A3.T1.1.1.2.1.5" class="ltx_td ltx_align_center ltx_border_t">Text Classification</td>
<td id="A3.T1.1.1.2.1.6" class="ltx_td ltx_align_center ltx_border_t">Spam Detection</td>
<td id="A3.T1.1.1.2.1.7" class="ltx_td ltx_align_center ltx_border_t">SMS</td>
</tr>
<tr id="A3.T1.1.1.3.2" class="ltx_tr">
<th id="A3.T1.1.1.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">AG News <cite class="ltx_cite ltx_citemacro_cite">Zhang etÂ al. (<a href="#bib.bib111" title="" class="ltx_ref">2015</a>); Li etÂ al. (<a href="#bib.bib50" title="" class="ltx_ref">2023c</a>)</cite>
</th>
<th id="A3.T1.1.1.3.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">1</th>
<td id="A3.T1.1.1.3.2.3" class="ltx_td ltx_align_center">AG News</td>
<td id="A3.T1.1.1.3.2.4" class="ltx_td ltx_align_center">Text Classification</td>
<td id="A3.T1.1.1.3.2.5" class="ltx_td ltx_align_center">Topic Classification</td>
<td id="A3.T1.1.1.3.2.6" class="ltx_td ltx_align_center">News</td>
</tr>
<tr id="A3.T1.1.1.4.3" class="ltx_tr">
<th id="A3.T1.1.1.4.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">IMDb <cite class="ltx_cite ltx_citemacro_cite">Maas etÂ al. (<a href="#bib.bib59" title="" class="ltx_ref">2011</a>); Li etÂ al. (<a href="#bib.bib50" title="" class="ltx_ref">2023c</a>); Wang etÂ al. (<a href="#bib.bib87" title="" class="ltx_ref">2023b</a>)</cite>
</th>
<th id="A3.T1.1.1.4.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">1</th>
<td id="A3.T1.1.1.4.3.3" class="ltx_td ltx_align_center">IMDb</td>
<td id="A3.T1.1.1.4.3.4" class="ltx_td ltx_align_center">Text Classification</td>
<td id="A3.T1.1.1.4.3.5" class="ltx_td ltx_align_center">Binary Sentiment Classification</td>
<td id="A3.T1.1.1.4.3.6" class="ltx_td ltx_align_center">Review</td>
</tr>
<tr id="A3.T1.1.1.5.4" class="ltx_tr">
<th id="A3.T1.1.1.5.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">GoEmotions <cite class="ltx_cite ltx_citemacro_cite">Demszky etÂ al. (<a href="#bib.bib13" title="" class="ltx_ref">2020</a>); Li etÂ al. (<a href="#bib.bib50" title="" class="ltx_ref">2023c</a>)</cite>
</th>
<th id="A3.T1.1.1.5.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">1</th>
<td id="A3.T1.1.1.5.4.3" class="ltx_td ltx_align_center">GoEmotions</td>
<td id="A3.T1.1.1.5.4.4" class="ltx_td ltx_align_center">Text Classification</td>
<td id="A3.T1.1.1.5.4.5" class="ltx_td ltx_align_center">Sentiment Classification</td>
<td id="A3.T1.1.1.5.4.6" class="ltx_td ltx_align_center">Reddit Comments</td>
</tr>
<tr id="A3.T1.1.1.6.5" class="ltx_tr">
<th id="A3.T1.1.1.6.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">CLINC150 <cite class="ltx_cite ltx_citemacro_cite">Larson etÂ al. (<a href="#bib.bib44" title="" class="ltx_ref">2019</a>); Sahu etÂ al. (<a href="#bib.bib72" title="" class="ltx_ref">2022</a>)</cite>
</th>
<th id="A3.T1.1.1.6.5.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">1</th>
<td id="A3.T1.1.1.6.5.3" class="ltx_td ltx_align_center">CLINC150</td>
<td id="A3.T1.1.1.6.5.4" class="ltx_td ltx_align_center">Text Classification</td>
<td id="A3.T1.1.1.6.5.5" class="ltx_td ltx_align_center">Intent Detection</td>
<td id="A3.T1.1.1.6.5.6" class="ltx_td ltx_align_center">Human Annotation</td>
</tr>
<tr id="A3.T1.1.1.7.6" class="ltx_tr">
<th id="A3.T1.1.1.7.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">BANKING77 <cite class="ltx_cite ltx_citemacro_cite">Casanueva etÂ al. (<a href="#bib.bib7" title="" class="ltx_ref">2020</a>); Sahu etÂ al. (<a href="#bib.bib72" title="" class="ltx_ref">2022</a>)</cite>
</th>
<th id="A3.T1.1.1.7.6.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">1</th>
<td id="A3.T1.1.1.7.6.3" class="ltx_td ltx_align_center">BANKING77</td>
<td id="A3.T1.1.1.7.6.4" class="ltx_td ltx_align_center">Text Classification</td>
<td id="A3.T1.1.1.7.6.5" class="ltx_td ltx_align_center">Intent Detection</td>
<td id="A3.T1.1.1.7.6.6" class="ltx_td ltx_align_center">Bank</td>
</tr>
<tr id="A3.T1.1.1.8.7" class="ltx_tr">
<th id="A3.T1.1.1.8.7.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">FewRel <cite class="ltx_cite ltx_citemacro_cite">Gao etÂ al. (<a href="#bib.bib21" title="" class="ltx_ref">2019</a>); Li etÂ al. (<a href="#bib.bib50" title="" class="ltx_ref">2023c</a>)</cite>
</th>
<th id="A3.T1.1.1.8.7.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">1</th>
<td id="A3.T1.1.1.8.7.3" class="ltx_td ltx_align_center">FewRel</td>
<td id="A3.T1.1.1.8.7.4" class="ltx_td ltx_align_center">Text Classification</td>
<td id="A3.T1.1.1.8.7.5" class="ltx_td ltx_align_center">Relation Classification</td>
<td id="A3.T1.1.1.8.7.6" class="ltx_td ltx_align_center">Wikipedia</td>
</tr>
<tr id="A3.T1.1.1.9.8" class="ltx_tr">
<th id="A3.T1.1.1.9.8.1" class="ltx_td ltx_align_center ltx_th ltx_th_row" rowspan="2"><span id="A3.T1.1.1.9.8.1.1" class="ltx_text">GLUE <cite class="ltx_cite ltx_citemacro_cite">Wang etÂ al. (<a href="#bib.bib85" title="" class="ltx_ref">2018</a>, <a href="#bib.bib87" title="" class="ltx_ref">2023b</a>)</cite></span></th>
<th id="A3.T1.1.1.9.8.2" class="ltx_td ltx_align_center ltx_th ltx_th_row" rowspan="2"><span id="A3.T1.1.1.9.8.2.1" class="ltx_text">7</span></th>
<td id="A3.T1.1.1.9.8.3" class="ltx_td ltx_align_center">QNLI</td>
<td id="A3.T1.1.1.9.8.4" class="ltx_td ltx_align_center">Natural Language Inference</td>
<td id="A3.T1.1.1.9.8.5" class="ltx_td ltx_align_center">Recognizing Textual Entailment</td>
<td id="A3.T1.1.1.9.8.6" class="ltx_td ltx_align_center">Wikipedia</td>
</tr>
<tr id="A3.T1.1.1.10.9" class="ltx_tr">
<td id="A3.T1.1.1.10.9.1" class="ltx_td ltx_align_center">RTE</td>
<td id="A3.T1.1.1.10.9.2" class="ltx_td ltx_align_center">Natural Language Inference</td>
<td id="A3.T1.1.1.10.9.3" class="ltx_td ltx_align_center">Recognizing Textual Entailment</td>
<td id="A3.T1.1.1.10.9.4" class="ltx_td ltx_align_center">News and Wikipedia</td>
</tr>
<tr id="A3.T1.1.1.11.10" class="ltx_tr">
<th id="A3.T1.1.1.11.10.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" rowspan="2"><span id="A3.T1.1.1.11.10.1.1" class="ltx_text">QA</span></th>
<th id="A3.T1.1.1.11.10.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">AdversarialQA <cite class="ltx_cite ltx_citemacro_cite">Bartolo etÂ al. (<a href="#bib.bib5" title="" class="ltx_ref">2020</a>); Wang etÂ al. (<a href="#bib.bib87" title="" class="ltx_ref">2023b</a>)</cite>
</th>
<th id="A3.T1.1.1.11.10.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">1</th>
<td id="A3.T1.1.1.11.10.4" class="ltx_td ltx_align_center ltx_border_t">AdversarialQA</td>
<td id="A3.T1.1.1.11.10.5" class="ltx_td ltx_align_center ltx_border_t">Question Answering</td>
<td id="A3.T1.1.1.11.10.6" class="ltx_td ltx_align_center ltx_border_t">Reading Comprehension</td>
<td id="A3.T1.1.1.11.10.7" class="ltx_td ltx_align_center ltx_border_t">Wikipedia</td>
</tr>
<tr id="A3.T1.1.1.12.11" class="ltx_tr">
<th id="A3.T1.1.1.12.11.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">TruthfulQA <cite class="ltx_cite ltx_citemacro_cite">Lin etÂ al. (<a href="#bib.bib51" title="" class="ltx_ref">2022</a>); Sun etÂ al. (<a href="#bib.bib81" title="" class="ltx_ref">2023</a>)</cite>
</th>
<th id="A3.T1.1.1.12.11.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">1</th>
<td id="A3.T1.1.1.12.11.3" class="ltx_td ltx_align_center">TruthfulQA</td>
<td id="A3.T1.1.1.12.11.4" class="ltx_td ltx_align_center">Question Answering</td>
<td id="A3.T1.1.1.12.11.5" class="ltx_td ltx_align_center">Honestness</td>
<td id="A3.T1.1.1.12.11.6" class="ltx_td ltx_align_center">Hard Data</td>
</tr>
<tr id="A3.T1.1.1.13.12" class="ltx_tr">
<th id="A3.T1.1.1.13.12.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" rowspan="2"><span id="A3.T1.1.1.13.12.1.1" class="ltx_text">Reasoning</span></th>
<th id="A3.T1.1.1.13.12.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">MATH <cite class="ltx_cite ltx_citemacro_cite">Hendrycks etÂ al. (<a href="#bib.bib30" title="" class="ltx_ref">2021</a>); Wan etÂ al. (<a href="#bib.bib84" title="" class="ltx_ref">2023</a>)</cite>
</th>
<th id="A3.T1.1.1.13.12.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">1</th>
<td id="A3.T1.1.1.13.12.4" class="ltx_td ltx_align_center ltx_border_t">MATH</td>
<td id="A3.T1.1.1.13.12.5" class="ltx_td ltx_align_center ltx_border_t">mathematical reasoning</td>
<td id="A3.T1.1.1.13.12.6" class="ltx_td ltx_align_center ltx_border_t">Complex Reasoning</td>
<td id="A3.T1.1.1.13.12.7" class="ltx_td ltx_align_center ltx_border_t">Math</td>
</tr>
<tr id="A3.T1.1.1.14.13" class="ltx_tr">
<th id="A3.T1.1.1.14.13.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">
<span id="A3.T1.1.1.14.13.1.1" class="ltx_text ltx_font_bold">ToolBench</span> <cite class="ltx_cite ltx_citemacro_cite">Qin etÂ al. (<a href="#bib.bib69" title="" class="ltx_ref">2023</a>)</cite>
</th>
<th id="A3.T1.1.1.14.13.2" class="ltx_td ltx_align_center ltx_th ltx_th_row"><span id="A3.T1.1.1.14.13.2.1" class="ltx_text ltx_font_bold">1</span></th>
<td id="A3.T1.1.1.14.13.3" class="ltx_td ltx_align_center"><span id="A3.T1.1.1.14.13.3.1" class="ltx_text ltx_font_bold">ToolBench</span></td>
<td id="A3.T1.1.1.14.13.4" class="ltx_td ltx_align_center"><span id="A3.T1.1.1.14.13.4.1" class="ltx_text ltx_font_bold">Trajectory Planning</span></td>
<td id="A3.T1.1.1.14.13.5" class="ltx_td ltx_align_center"><span id="A3.T1.1.1.14.13.5.1" class="ltx_text ltx_font_bold">Tool manipulation</span></td>
<td id="A3.T1.1.1.14.13.6" class="ltx_td ltx_align_center"><span id="A3.T1.1.1.14.13.6.1" class="ltx_text ltx_font_bold">Tool</span></td>
</tr>
<tr id="A3.T1.1.1.15.14" class="ltx_tr">
<th id="A3.T1.1.1.15.14.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">-</th>
<th id="A3.T1.1.1.15.14.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">NIV2 <cite class="ltx_cite ltx_citemacro_cite">Wang etÂ al. (<a href="#bib.bib92" title="" class="ltx_ref">2022</a>, <a href="#bib.bib91" title="" class="ltx_ref">2023e</a>)</cite>
</th>
<th id="A3.T1.1.1.15.14.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">1616</th>
<td id="A3.T1.1.1.15.14.4" class="ltx_td ltx_align_center ltx_border_t">-</td>
<td id="A3.T1.1.1.15.14.5" class="ltx_td ltx_align_center ltx_border_t">-</td>
<td id="A3.T1.1.1.15.14.6" class="ltx_td ltx_align_center ltx_border_t">Language Understanding &amp; Reasoning</td>
<td id="A3.T1.1.1.15.14.7" class="ltx_td ltx_align_center ltx_border_t">Benchmark Collection/Human Annotation</td>
</tr>
<tr id="A3.T1.1.1.16.15" class="ltx_tr">
<th id="A3.T1.1.1.16.15.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb">-</th>
<th id="A3.T1.1.1.16.15.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb">BIG-bench <cite class="ltx_cite ltx_citemacro_cite">Srivastava etÂ al. (<a href="#bib.bib78" title="" class="ltx_ref">2022</a>); Sun etÂ al. (<a href="#bib.bib81" title="" class="ltx_ref">2023</a>)</cite>
</th>
<th id="A3.T1.1.1.16.15.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb">204</th>
<td id="A3.T1.1.1.16.15.4" class="ltx_td ltx_align_center ltx_border_bb">-</td>
<td id="A3.T1.1.1.16.15.5" class="ltx_td ltx_align_center ltx_border_bb">-</td>
<td id="A3.T1.1.1.16.15.6" class="ltx_td ltx_align_center ltx_border_bb">Language Understanding &amp; Reasoning</td>
<td id="A3.T1.1.1.16.15.7" class="ltx_td ltx_align_center ltx_border_bb">Human Annotation</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Representative benchmark dataset for assessing models trained with generated data. The dataset generated based on LLM is highlighted in bold.</figcaption>
</figure></div></div>
</section>
</section>
<section id="A4" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Benchmark Datasets</h2>

<div id="A4.p1" class="ltx_para">
<p id="A4.p1.1" class="ltx_p">In Table <a href="#A3.T1" title="Table 1 â€£ Multimodal Tasks. â€£ Appendix C Applications â€£ On LLMs-Driven Synthetic Data Generation, Curation, and Evaluation: A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, we summarize representative benchmark datasets for evaluating models trained through data generation. Among them, ToolBench <cite class="ltx_cite ltx_citemacro_cite">Qin etÂ al. (<a href="#bib.bib69" title="" class="ltx_ref">2023</a>)</cite> is generated by LLMs and is commonly employed to evaluate the performance of LLMs in tool usage proficiency. In most classification task evaluations <cite class="ltx_cite ltx_citemacro_cite">Li etÂ al. (<a href="#bib.bib50" title="" class="ltx_ref">2023c</a>); Wang etÂ al. (<a href="#bib.bib87" title="" class="ltx_ref">2023b</a>); Sahu etÂ al. (<a href="#bib.bib72" title="" class="ltx_ref">2022</a>)</cite>, LLMs are infrequently used as test models; instead, small language models trained on generated data are often used, followed by testing on existing benchmarks.</p>
</div>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2406.15125" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2406.15126" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2406.15126">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2406.15126" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2406.15127" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Jul  5 17:46:49 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
