<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Conditioning LLMs with Emotion in Neural Machine Translation</title>
<!--Generated on Tue Aug  6 12:36:46 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2408.03150v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#S1" title="In Conditioning LLMs with Emotion in Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#S2" title="In Conditioning LLMs with Emotion in Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related works</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#S2.SS1" title="In 2 Related works ‣ Conditioning LLMs with Emotion in Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Machine Translation with Emotion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#S2.SS2" title="In 2 Related works ‣ Conditioning LLMs with Emotion in Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>LLM selection for MT</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#S3" title="In Conditioning LLMs with Emotion in Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Experiments and results</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#S3.SS1" title="In 3 Experiments and results ‣ Conditioning LLMs with Emotion in Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Fine-tuning LLMs on Libri-trans</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#S3.SS2" title="In 3 Experiments and results ‣ Conditioning LLMs with Emotion in Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Fine-tuning LLMs with Emotion</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#S4" title="In Conditioning LLMs with Emotion in Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#S5" title="In Conditioning LLMs with Emotion in Neural Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Acknowledgements</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">Conditioning LLMs with Emotion in Neural Machine Translation</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Charles Brazier 
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jean-Luc Rouas 
<br class="ltx_break"/>Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, F-33400 Talence, France 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id1.1.id1">charles.brazier@u-bordeaux.fr</span>       <span class="ltx_text ltx_font_typewriter" id="id2.2.id2">jean-luc.rouas@labri.fr</span>
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id3.id1">Large Language Models (LLMs) have shown remarkable performance in Natural Language Processing tasks, including Machine Translation (MT). In this work, we propose a novel MT pipeline that integrates emotion information extracted from a Speech Emotion Recognition (SER) model into LLMs to enhance translation quality. We first fine-tune five existing LLMs on the Libri-trans dataset and select the most performant model. Subsequently, we augment LLM prompts with different dimensional emotions and train the selected LLM under these different configurations. Our experiments reveal that integrating emotion information, especially arousal, into LLM prompts leads to notable improvements in translation quality.</p>
</div>
<div class="ltx_para ltx_noindent" id="p1">
<div class="ltx_block ltx_align_bottom" id="p1.1">
<p class="ltx_p" id="p1.1.1"><span class="ltx_text ltx_font_bold" id="p1.1.1.1">Conditioning LLMs with Emotion in Neural Machine Translation</span></p>
<br class="ltx_break ltx_centering"/>
<p class="ltx_p ltx_align_center" id="p1.1.2" style="width:433.6pt;"><span class="ltx_text ltx_inline-block" id="p1.1.2.1" style="width:0.0pt;">
<span class="ltx_tabular ltx_guessed_headers ltx_align_top" id="p1.1.2.1.1">
<span class="ltx_thead">
<span class="ltx_tr" id="p1.1.2.1.1.1.1">
<span class="ltx_td ltx_align_center ltx_th ltx_th_column" id="p1.1.2.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="p1.1.2.1.1.1.1.1.1">Charles Brazier  </span>and<span class="ltx_text ltx_font_bold" id="p1.1.2.1.1.1.1.1.2"> Jean-Luc Rouas</span></span></span>
</span>
<span class="ltx_tbody">
<span class="ltx_tr" id="p1.1.2.1.1.2.1">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.2.1.1">Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, F-33400 Talence, France</span></span>
<span class="ltx_tr" id="p1.1.2.1.1.3.2">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.3.2.1"><span class="ltx_text ltx_font_typewriter" id="p1.1.2.1.1.3.2.1.1">charles.brazier@u-bordeaux.fr</span>       <span class="ltx_text ltx_font_typewriter" id="p1.1.2.1.1.3.2.1.2">jean-luc.rouas@labri.fr</span></span></span>
</span>
</span></span></p>
<br class="ltx_break ltx_centering"/>
</div>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Large Language Models (LLMs) are transformer-based <cite class="ltx_cite ltx_citemacro_citep">(Vaswani et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#bib.bib27" title="">2017</a>)</cite> deep learning models designed to understand and generate natural language text by predicting the probability of the next token in a sequence. LLMs excel across various Natural Language Processing (NLP) tasks, such as information retrieval <cite class="ltx_cite ltx_citemacro_citep">(Zhu et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#bib.bib33" title="">2023b</a>)</cite>, instruction following <cite class="ltx_cite ltx_citemacro_citep">(Ouyang et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#bib.bib20" title="">2022</a>)</cite>, or engaging in chatbot discussions <cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#bib.bib18" title="">2022</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Among NLP tasks, LLMs have shown great capacities in Machine Translation (MT) <cite class="ltx_cite ltx_citemacro_citep">(Zhu et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#bib.bib32" title="">2023a</a>)</cite>, the task of translating a text from one language to another. Previous research has enhanced LLM performance in MT through various strategies, including optimized prompting techniques <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#bib.bib30" title="">2023</a>)</cite>, in-context learning features <cite class="ltx_cite ltx_citemacro_citep">(Brown et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#bib.bib6" title="">2020</a>)</cite> to improve translation quality over time <cite class="ltx_cite ltx_citemacro_citep">(Moslem et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#bib.bib16" title="">2023a</a>, <a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#bib.bib17" title="">b</a>)</cite>, and a two-stage fine-tuning method composed of a first fine-tuning on monolingual data to learn general linguistic knowledge followed by a second fine-tuning on parallel data <cite class="ltx_cite ltx_citemacro_citep">(Xu et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#bib.bib29" title="">2023</a>)</cite> that establishes the current state-of-the-art method in MT.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Apart from LLMs, previous works in MT have demonstrated the possibility of controlling the translation by adding extra information to the model that is not explicitly specified in the source sentence to be translated, and that can influence the translation. Existing works in that direction focused on the control of politeness <cite class="ltx_cite ltx_citemacro_citep">(Sennrich et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#bib.bib24" title="">2019</a>)</cite>, gender <cite class="ltx_cite ltx_citemacro_citep">(Vanmassenhove et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#bib.bib26" title="">2018</a>; Gaido et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#bib.bib11" title="">2023</a>)</cite>, or emotion <cite class="ltx_cite ltx_citemacro_citep">(Brazier and Rouas, <a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#bib.bib5" title="">2024</a>)</cite> of the translation and showed that this extra information helps improve translation quality.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">In this work, we propose to improve translation performances of an LLM-based model by adding emotion as extra information in the prompt of the model to condition the translation. This work relies on the fact that words can be classified into emotion categories, leading to affective word lists <cite class="ltx_cite ltx_citemacro_citep">(Pennebaker et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#bib.bib21" title="">2001</a>)</cite>. Thus, conditioning the translation with a specific emotion would use a suitable vocabulary in the translation. In <cite class="ltx_cite ltx_citemacro_citet">Brazier and Rouas (<a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#bib.bib5" title="">2024</a>)</cite>, authors showed that adding arousal information, reflecting the level of stimulation (ranging from calm to excited), extracted from the voice and added at the start of each input text sentence, helps improve translation performances. In the following, we study the behavior of several LLMs for the task of MT when emotion dimensions are added to input prompts.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">To address this problem, we first fine-tune several existing LLMs for the task of English-to-French text-to-text translation. Then, after selecting the best model as baseline for our experiments, we compute for each input sentence its emotional dimensions with the help of a state-of-the-art Speech Emotion Recognition (SER) model applied to audio recordings. Finally, we compare translation performance with and without the addition of each emotional dimension as extra information added to each input prompt. We show that emotion improves translation (BLEU and COMET), especially in the case of arousal.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related works</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">In this work, we aim at combining an LLM-based MT model with emotion information to improve translation performances. In the following, we first describe a close work that performs this combination without the use of an LLM. Then, we list several existing LLMs that can be used as a baseline for our MT task.
</p>
</div>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Machine Translation with Emotion</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">To our knowledge, the only work that combines an MT model with emotion information is described in <cite class="ltx_cite ltx_citemacro_citet">Brazier and Rouas (<a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#bib.bib5" title="">2024</a>)</cite>. In this study, the authors utilize a state-of-the-art Speech Emotion Recognition (SER) model <cite class="ltx_cite ltx_citemacro_citep">(Wagner et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#bib.bib28" title="">2023</a>)</cite> to automatically estimate dimensional emotion values, including arousal, dominance, and valence, for each audio recording associated with text sentence. These values are then transformed into unique emotion tokens, either positive or negative, which are added at the beginning of tokenized input text sentences. The authors report an increase in translation BLEU score, especially when adding arousal tokens at the start of input sentences.</p>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1">The MT model used for their experiments is a transformer-based encoder-decoder architecture, comprising 6 layers for the encoder, 6 layers for the decoder, and 4 attention heads in each self-attention layer. The model is trained on the Libri-trans dataset <cite class="ltx_cite ltx_citemacro_citep">(Kocabiyikoglu et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#bib.bib14" title="">2018</a>)</cite>, which includes triplets of English recordings, English texts, and French texts, totaling 235 hours of data (230h for train, 2h for dev, and 3.5h for test). The model performs English-to-French translation.</p>
</div>
<div class="ltx_para" id="S2.SS1.p3">
<p class="ltx_p" id="S2.SS1.p3.1">In this work, we propose to use the same translation pipeline, but instead of using a specific MT model, we replace it with a fine-tuned LLM. Since LLMs have more trainable parameters, we anticipate improved translation performances. However, our objective is to observe how LLMs behave when augmented with emotion information in the input prompt.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>LLM selection for MT</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">Recent advances in Large Language Modeling have significantly expanded the capabilities of LLMs across various tasks, such as reasoning, coding, or mathematics. Among the numerous existing LLMs <cite class="ltx_cite ltx_citemacro_citep">(Chiang et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#bib.bib7" title="">2024</a>)</cite>, the best-performing models are GPT-4 <cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#bib.bib19" title="">2023</a>)</cite>, LLaMA 3 <cite class="ltx_cite ltx_citemacro_citep">(AI@Meta, <a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#bib.bib2" title="">2024</a>)</cite>, Gemini 1.5 <cite class="ltx_cite ltx_citemacro_citep">(Team, <a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#bib.bib25" title="">2024</a>)</cite>, or Claude 3 <cite class="ltx_cite ltx_citemacro_citep">(Anthropic, <a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#bib.bib4" title="">2024</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1">For the task of MT, we restrict our LLM selection to models that are open-source, promising (high rank in the LLM arena<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="http://chat.lmsys.org/?leaderboard" title="">http://chat.lmsys.org/?leaderboard</a></span></span></span>, or already fine-tuned to the MT task), and that only contain 7 billion (7B) of parameters. We select 5 different models that are described in the following.</p>
</div>
<div class="ltx_para" id="S2.SS2.p3">
<p class="ltx_p" id="S2.SS2.p3.1">The first selected LLM is <span class="ltx_text ltx_font_italic" id="S2.SS2.p3.1.1">Mistral-7B-v0.1<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_upright" id="footnote2.1.1.1">2</span></span><a class="ltx_ref ltx_url ltx_font_typewriter ltx_font_upright" href="http://huggingface.co/mistralai/Mistral-7B-v0.1" title="">http://huggingface.co/mistralai/Mistral-7B-v0.1</a></span></span></span></span>, an open-source model <cite class="ltx_cite ltx_citemacro_citep">(Jiang et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#bib.bib13" title="">2023</a>)</cite> which ranks among the best 7B-parameter models.</p>
</div>
<div class="ltx_para" id="S2.SS2.p4">
<p class="ltx_p" id="S2.SS2.p4.1">As the second model, we select <span class="ltx_text ltx_font_italic" id="S2.SS2.p4.1.1">Mistral-7B-Instruct-v0.2<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_upright" id="footnote3.1.1.1">3</span></span><a class="ltx_ref ltx_url ltx_font_typewriter ltx_font_upright" href="http://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2" title="">http://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2</a></span></span></span></span>. The model is similar to the previous model but has been fine-tuned to follow instructions.</p>
</div>
<div class="ltx_para" id="S2.SS2.p5">
<p class="ltx_p" id="S2.SS2.p5.1">Our third selected model is <span class="ltx_text ltx_font_italic" id="S2.SS2.p5.1.1">TowerBase-7B-v0.1<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_upright" id="footnote4.1.1.1">4</span></span><a class="ltx_ref ltx_url ltx_font_typewriter ltx_font_upright" href="http://huggingface.co/Unbabel/TowerBase-7B-v0.1" title="">http://huggingface.co/Unbabel/TowerBase-7B-v0.1</a></span></span></span></span>. This model <cite class="ltx_cite ltx_citemacro_citep">(Alves et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#bib.bib3" title="">2024</a>)</cite> is based on LLaMA 2 <cite class="ltx_cite ltx_citemacro_citep">(AI@Meta, <a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#bib.bib1" title="">2023</a>)</cite> and its training has been continued on multilingual data (including English and French monolingual data, as well as bilingual data).</p>
</div>
<div class="ltx_para" id="S2.SS2.p6">
<p class="ltx_p" id="S2.SS2.p6.1">Similarly to Mistral, we select <span class="ltx_text ltx_font_italic" id="S2.SS2.p6.1.1">TowerInstruct-7B-v0.2<span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_upright" id="footnote5.1.1.1">5</span></span><a class="ltx_ref ltx_url ltx_font_typewriter ltx_font_upright" href="http://huggingface.co/Unbabel/TowerInstruct-7B-v0.2" title="">http://huggingface.co/Unbabel/TowerInstruct-7B-v0.2</a></span></span></span></span> as our fourth model. This model is a variant of the previous one that has been fine-tuned to follow instructions including translations.</p>
</div>
<div class="ltx_para" id="S2.SS2.p7">
<p class="ltx_p" id="S2.SS2.p7.1">Finally, as our fifth model, we select the SOTA MT model <span class="ltx_text ltx_font_italic" id="S2.SS2.p7.1.1">ALMA-7B-R<span class="ltx_note ltx_role_footnote" id="footnote6"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_upright" id="footnote6.1.1.1">6</span></span><a class="ltx_ref ltx_url ltx_font_typewriter ltx_font_upright" href="http://huggingface.co/haoranxu/ALMA-7B-R" title="">http://huggingface.co/haoranxu/ALMA-7B-R</a></span></span></span></span>, which is based on LLaMA 2 <cite class="ltx_cite ltx_citemacro_citep">(AI@Meta, <a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#bib.bib1" title="">2023</a>)</cite>, and fine-tuned on monolingual and parallel data. However, the data used for fine-tuning does not include French.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Experiments and results</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">In this section, we describe our experiments for the task of English-to-French text-to-text translation. We conduct two successive experiments. Firstly, we fine-tune five existing LLMs on the Libri-trans dataset <cite class="ltx_cite ltx_citemacro_cite">Kocabiyikoglu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#bib.bib14" title="">2018</a>)</cite> and consider the best model as a foundation for our second experiment. Secondly, we fine-tune the selected LLM on the same task but under different configurations. Henceforth, prompts used for translation include each emotion dimension that is automatically estimated from the SER model.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Fine-tuning LLMs on Libri-trans</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">To perform MT with LLMs, the task needs to be converted into a language modeling problem with the use of prompts. In this work, we perform zero-shot prompting and follow two different templates. The first template will be applied to <span class="ltx_text ltx_font_italic" id="S3.SS1.p1.1.1">Mistral-7B-v0.1</span> and <span class="ltx_text ltx_font_italic" id="S3.SS1.p1.1.2">TowerBase-7B-v0.1</span>:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><span class="ltx_text ltx_markedasmath ltx_font_typewriter" id="S3.E1.1">English: &lt;src txt&gt; \n French: &lt;tgt txt&gt;</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="0"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.p1.2">where <span class="ltx_text ltx_font_typewriter" id="S3.SS1.p1.2.1">&lt;src txt&gt;</span> and <span class="ltx_text ltx_font_typewriter" id="S3.SS1.p1.2.2">&lt;tgt txt&gt;</span> refer to the English source sentence and the French target sentence respectively.</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1">The second template will be applied to models that follow instructions, namely <span class="ltx_text ltx_font_italic" id="S3.SS1.p2.1.1">Mistral-7B-Instruct-v0.2</span>, <span class="ltx_text ltx_font_italic" id="S3.SS1.p2.1.2">TowerInstruct-7B-v0.2</span>, and <span class="ltx_text ltx_font_italic" id="S3.SS1.p2.1.3">ALMA-7B-R</span>:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><span class="ltx_text ltx_markedasmath ltx_font_typewriter" id="S3.E2.1">[INST] Translate from English to French: &lt;src txt&gt; [/INST] \n &lt;tgt txt&gt;</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="0"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.1">To fine-tune LLMs, we employ QLoRA <cite class="ltx_cite ltx_citemacro_citep">(Hu et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#bib.bib12" title="">2022</a>; Dettmers et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#bib.bib8" title="">2023</a>)</cite>, a Parameter Efficient Fine-Tuning method <cite class="ltx_cite ltx_citemacro_cite">Mangrulkar et al. (<a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#bib.bib15" title="">2022</a>)</cite> that allows training with significantly fewer parameters. Additionally, we apply a 4-bit quantization to reduce memory usage while maintaining 16-bit precision during computation.</p>
</div>
<div class="ltx_para" id="S3.SS1.p4">
<p class="ltx_p" id="S3.SS1.p4.1">We provide two distinct metrics to evaluate our MT models. The first metric is the BLEU score computed using sacrebleu <cite class="ltx_cite ltx_citemacro_citep">(Post, <a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#bib.bib22" title="">2018</a>)</cite>. It reflects the degree of lexical matches (number of common n-grams) between the proposed translation and its corresponding reference. The second metric is the COMET score <span class="ltx_note ltx_role_footnote" id="footnote7"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/Unbabel/wmt22-comet-da" title="">https://huggingface.co/Unbabel/wmt22-comet-da</a></span></span></span> <cite class="ltx_cite ltx_citemacro_citep">(Rei et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#bib.bib23" title="">2022</a>)</cite>. It is computed from a trained model and reflects translation quality between translation, reference, and also the source sentence. According to the metric ranking presented in <cite class="ltx_cite ltx_citemacro_citet">Freitag et al. (<a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#bib.bib10" title="">2022</a>)</cite>, we rely more on the COMET score than on the BLEU score.</p>
</div>
<div class="ltx_para" id="S3.SS1.p5">
<p class="ltx_p" id="S3.SS1.p5.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#S3.T1" title="Table 1 ‣ 3.1 Fine-tuning LLMs on Libri-trans ‣ 3 Experiments and results ‣ Conditioning LLMs with Emotion in Neural Machine Translation"><span class="ltx_text ltx_ref_tag">1</span></a> showcases the results of our first experiment. In this table, we report BLEU and COMET scores of the five selected LLMs on both the dev and test sets of the Libri-trans dataset.</p>
</div>
<figure class="ltx_table" id="S3.T1">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S3.T1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t" id="S3.T1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.1.1">Model</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="2" id="S3.T1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.2.1">BLEU</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="2" id="S3.T1.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.3.1">COMET</span></th>
</tr>
<tr class="ltx_tr" id="S3.T1.1.2.2">
<th class="ltx_td ltx_th ltx_th_row" id="S3.T1.1.2.2.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S3.T1.1.2.2.2"><span class="ltx_text ltx_font_bold" id="S3.T1.1.2.2.2.1">dev</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S3.T1.1.2.2.3"><span class="ltx_text ltx_font_bold" id="S3.T1.1.2.2.3.1">test</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S3.T1.1.2.2.4"><span class="ltx_text ltx_font_bold" id="S3.T1.1.2.2.4.1">dev</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S3.T1.1.2.2.5"><span class="ltx_text ltx_font_bold" id="S3.T1.1.2.2.5.1">test</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T1.1.3.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S3.T1.1.3.1.1">Mistral</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.3.1.2">16.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.3.1.3">16.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.3.1.4">73.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.3.1.5">72.5</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.4.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.1.4.2.1">MistralInstruct</th>
<td class="ltx_td ltx_align_center" id="S3.T1.1.4.2.2">16.0</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.4.2.3">17.9</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.4.2.4">72.1</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.4.2.5">71.9</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.5.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.1.5.3.1">TowerBase</th>
<td class="ltx_td ltx_align_center" id="S3.T1.1.5.3.2"><span class="ltx_text ltx_font_bold" id="S3.T1.1.5.3.2.1">24.0</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.5.3.3"><span class="ltx_text ltx_font_bold" id="S3.T1.1.5.3.3.1">20.6</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.5.3.4"><span class="ltx_text ltx_font_bold" id="S3.T1.1.5.3.4.1">73.8</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.5.3.5"><span class="ltx_text ltx_font_bold" id="S3.T1.1.5.3.5.1">72.9</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.6.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.1.6.4.1">TowerInstruct</th>
<td class="ltx_td ltx_align_center" id="S3.T1.1.6.4.2">6.4</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.6.4.3">6.1</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.6.4.4">35.5</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.6.4.5">35.5</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.7.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b" id="S3.T1.1.7.5.1">ALMA</th>
<td class="ltx_td ltx_align_center ltx_border_b" id="S3.T1.1.7.5.2">7.1</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S3.T1.1.7.5.3">7.5</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S3.T1.1.7.5.4">52.1</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S3.T1.1.7.5.5">52.8</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>BLEU and COMET scores of our five selected LLMs on dev and test sets of Libri-trans.</figcaption>
</figure>
<div class="ltx_para" id="S3.SS1.p6">
<p class="ltx_p" id="S3.SS1.p6.1">The table highlights three models, <span class="ltx_text ltx_font_italic" id="S3.SS1.p6.1.1">Mistral-7B-v0.1</span>, <span class="ltx_text ltx_font_italic" id="S3.SS1.p6.1.2">Mistral-7B-Instruct-v0.2</span>, and <span class="ltx_text ltx_font_italic" id="S3.SS1.p6.1.3">TowerBase-7B-v0.1</span>, that attain high BLEU and COMET scores. They obtain COMET scores ranging from 72.1 to 73.8 on the dev set and from 71.9 to 72.9 on the test set. Additionally, their BLEU scores ranged from 16.0 to 24.0 on the dev set and from 16.7 to 20.6 on the test set. While COMET scores are not meant to be interpretable (but enable the comparison between models), BLEU scores indicate, on average, a translation that is more or less clear with numerous grammatical errors. These low BLEU scores are comparable to performances of previous works on this dataset <cite class="ltx_cite ltx_citemacro_citep">(Zhao et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#bib.bib31" title="">2021</a>; Brazier and Rouas, <a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#bib.bib5" title="">2024</a>)</cite> and are mainly caused by the nature of the data (audiobooks with literary vocabulary).</p>
</div>
<div class="ltx_para" id="S3.SS1.p7">
<p class="ltx_p" id="S3.SS1.p7.1">Also, it is worth noting that two models, <span class="ltx_text ltx_font_italic" id="S3.SS1.p7.1.1">TowerInstruct-7B-v0.2</span> and <span class="ltx_text ltx_font_italic" id="S3.SS1.p7.1.2">ALMA-7B-R</span>, exhibit poor performances in MT when fine-tuned on Libri-trans. In the case of <span class="ltx_text ltx_font_italic" id="S3.SS1.p7.1.3">ALMA-7B-R</span>, this can be explained by the fact that French is not among the languages included in the data used to pre-train the model. Thus, the model fails at predicting French text.</p>
</div>
<div class="ltx_para" id="S3.SS1.p8">
<p class="ltx_p" id="S3.SS1.p8.1">As additional training information, all LLMs have obtained their optimal state in a maximum of 5 epochs. This represents a training time of 3 hours on a GPU NVIDIA A100 for each model. This fast fine-tuning time is due to QLoRA and 4-bit quantization strategies.
</p>
</div>
<div class="ltx_para" id="S3.SS1.p9">
<p class="ltx_p" id="S3.SS1.p9.1">To summarize, the best machine translation performances were achieved with the <span class="ltx_text ltx_font_italic" id="S3.SS1.p9.1.1">TowerBase-7B-v0.1</span>. This LLM serves as a baseline and foundation model for the following experiment.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Fine-tuning LLMs with Emotion</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">The second experiment aims at observing the behavior of our LLM-based <span class="ltx_text ltx_font_italic" id="S3.SS2.p1.1.1">TowerBase-7B-v0.1</span> model on the task of English-to-French Machine Translation when emotion information is added to the prompt before translation.</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1">As a first step, we estimate the emotion of each English recording present in the Libri-trans dataset. Following the same methodology as <cite class="ltx_cite ltx_citemacro_citet">Brazier and Rouas (<a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#bib.bib5" title="">2024</a>)</cite>, we compute dimensional emotion values for arousal, dominance, and valence with the help of a trained SER model <cite class="ltx_cite ltx_citemacro_citep">(Wagner et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#bib.bib28" title="">2023</a>)</cite>. Emotion values range between 0 and 1 and are correctly balanced (medians between 0.4 and 0.6, see <cite class="ltx_cite ltx_citemacro_citet">Brazier and Rouas (<a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#bib.bib5" title="">2024</a>)</cite>).</p>
</div>
<div class="ltx_para" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.1">As a second step, we create specific prompts that include the emotion information in the text. For this purpose, we propose 3 different templates. The first template adds emotion information before the source sentence:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><span class="ltx_text ltx_markedasmath ltx_font_typewriter" id="S3.E3.1">English &lt;status&gt; &lt;emotion&gt;: &lt;src txt&gt; \n French: &lt;tgt txt&gt;</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="0"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS2.p3.2">where <span class="ltx_text ltx_font_typewriter" id="S3.SS2.p3.2.1">status</span> is replaced by either <span class="ltx_text ltx_font_italic" id="S3.SS2.p3.2.2">with</span> or <span class="ltx_text ltx_font_italic" id="S3.SS2.p3.2.3">without</span> if the emotion value is higher or lower than 0.5 respectively, <span class="ltx_text ltx_font_typewriter" id="S3.SS2.p3.2.4">emotion</span> is replaced by either <span class="ltx_text ltx_font_italic" id="S3.SS2.p3.2.5">arousal</span>, <span class="ltx_text ltx_font_italic" id="S3.SS2.p3.2.6">dominance</span>, or <span class="ltx_text ltx_font_italic" id="S3.SS2.p3.2.7">valence</span>, <span class="ltx_text ltx_font_typewriter" id="S3.SS2.p3.2.8">src txt</span> represents the English source sentence, and <span class="ltx_text ltx_font_typewriter" id="S3.SS2.p3.2.9">tgt txt</span> represents the French target translation.</p>
</div>
<div class="ltx_para" id="S3.SS2.p4">
<p class="ltx_p" id="S3.SS2.p4.1">The second template adds emotion information before the target sentence:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E4">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><span class="ltx_text ltx_markedasmath ltx_font_typewriter" id="S3.E4.1">English: &lt;src txt&gt; \n French &lt;status&gt; &lt;emotion&gt;: &lt;tgt txt&gt;</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="0"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS2.p5">
<p class="ltx_p" id="S3.SS2.p5.1">The third template is inspired from <cite class="ltx_cite ltx_citemacro_citet">Brazier and Rouas (<a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#bib.bib5" title="">2024</a>)</cite>, where emotion information is added as a discrete token at the start of the source sentence:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E5">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><span class="ltx_text ltx_markedasmath ltx_font_typewriter" id="S3.E5.1">English: [&lt;emotion&gt; &lt;polarity&gt;] &lt;src txt&gt; \n French: &lt;tgt txt&gt;</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="0"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS2.p5.2">where <span class="ltx_text ltx_font_typewriter" id="S3.SS2.p5.2.1">polarity</span> is replaced by either <span class="ltx_text ltx_font_italic" id="S3.SS2.p5.2.2">positive</span> or <span class="ltx_text ltx_font_italic" id="S3.SS2.p5.2.3">negative</span> if the emotion value is higher or lower than 0.5 respectively.</p>
</div>
<div class="ltx_para" id="S3.SS2.p6">
<p class="ltx_p" id="S3.SS2.p6.1">In this experiment, the <span class="ltx_text ltx_font_italic" id="S3.SS2.p6.1.1">TowerBase-7B-v0.1</span> model is retrained from its initial state and not from the training checkpoint obtained after the previous experiment. In the following, all models obtain their best performances in less than 5 training epochs.</p>
</div>
<div class="ltx_para" id="S3.SS2.p7">
<p class="ltx_p" id="S3.SS2.p7.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#S3.T2" title="Table 2 ‣ 3.2 Fine-tuning LLMs with Emotion ‣ 3 Experiments and results ‣ Conditioning LLMs with Emotion in Neural Machine Translation"><span class="ltx_text ltx_ref_tag">2</span></a> showcases the results of our second experiment. It reports BLEU and COMET scores of the selected <span class="ltx_text ltx_font_italic" id="S3.SS2.p7.1.1">TowerBase-7B-v0.1</span> model on the dev and test sets of the Libri-trans dataset under different configurations. The first line mentions the score of the LLM obtained in the previous experiment and serves as a baseline for the second experiment. The other lines correspond to the model trained with different emotions (arousal, dominance, or valence), and with different prompts (the numbers <a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#S3.E3" title="In 3.2 Fine-tuning LLMs with Emotion ‣ 3 Experiments and results ‣ Conditioning LLMs with Emotion in Neural Machine Translation"><span class="ltx_text ltx_ref_tag">3</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#S3.E4" title="In 3.2 Fine-tuning LLMs with Emotion ‣ 3 Experiments and results ‣ Conditioning LLMs with Emotion in Neural Machine Translation"><span class="ltx_text ltx_ref_tag">4</span></a>, and <a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#S3.E5" title="In 3.2 Fine-tuning LLMs with Emotion ‣ 3 Experiments and results ‣ Conditioning LLMs with Emotion in Neural Machine Translation"><span class="ltx_text ltx_ref_tag">5</span></a> refer to their equation number).</p>
</div>
<figure class="ltx_table" id="S3.T2">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S3.T2.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T2.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t" id="S3.T2.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.1.1.1">Model</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="2" id="S3.T2.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.1.2.1">BLEU</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="2" id="S3.T2.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.1.3.1">COMET</span></th>
</tr>
<tr class="ltx_tr" id="S3.T2.1.2.2">
<th class="ltx_td ltx_th ltx_th_row" id="S3.T2.1.2.2.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S3.T2.1.2.2.2"><span class="ltx_text ltx_font_bold" id="S3.T2.1.2.2.2.1">dev</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S3.T2.1.2.2.3"><span class="ltx_text ltx_font_bold" id="S3.T2.1.2.2.3.1">test</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S3.T2.1.2.2.4"><span class="ltx_text ltx_font_bold" id="S3.T2.1.2.2.4.1">dev</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S3.T2.1.2.2.5"><span class="ltx_text ltx_font_bold" id="S3.T2.1.2.2.5.1">test</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T2.1.3.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S3.T2.1.3.1.1">TowerBase</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.3.1.2">24.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.3.1.3">20.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.3.1.4">73.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.3.1.5">72.9</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.4.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T2.1.4.2.1">     +arousal<a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#S3.E3" title="In 3.2 Fine-tuning LLMs with Emotion ‣ 3 Experiments and results ‣ Conditioning LLMs with Emotion in Neural Machine Translation"><span class="ltx_text ltx_ref_tag">3</span></a>
</th>
<td class="ltx_td ltx_align_center" id="S3.T2.1.4.2.2">22.1</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.4.2.3">21.8</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.4.2.4"><span class="ltx_text ltx_font_bold" id="S3.T2.1.4.2.4.1">74.9</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.4.2.5"><span class="ltx_text ltx_font_bold" id="S3.T2.1.4.2.5.1">74.3</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.5.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T2.1.5.3.1">     +arousal<a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#S3.E4" title="In 3.2 Fine-tuning LLMs with Emotion ‣ 3 Experiments and results ‣ Conditioning LLMs with Emotion in Neural Machine Translation"><span class="ltx_text ltx_ref_tag">4</span></a>
</th>
<td class="ltx_td ltx_align_center" id="S3.T2.1.5.3.2"><span class="ltx_text ltx_font_bold" id="S3.T2.1.5.3.2.1">25.6</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.5.3.3"><span class="ltx_text ltx_font_bold" id="S3.T2.1.5.3.3.1">24.1</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.5.3.4">74.8</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.5.3.5">73.9</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.6.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T2.1.6.4.1">     +arousal<a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#S3.E5" title="In 3.2 Fine-tuning LLMs with Emotion ‣ 3 Experiments and results ‣ Conditioning LLMs with Emotion in Neural Machine Translation"><span class="ltx_text ltx_ref_tag">5</span></a>
</th>
<td class="ltx_td ltx_align_center" id="S3.T2.1.6.4.2">19.3</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.6.4.3">19.2</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.6.4.4">74.2</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.6.4.5">73.4</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.7.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T2.1.7.5.1">     +dominance<a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#S3.E3" title="In 3.2 Fine-tuning LLMs with Emotion ‣ 3 Experiments and results ‣ Conditioning LLMs with Emotion in Neural Machine Translation"><span class="ltx_text ltx_ref_tag">3</span></a>
</th>
<td class="ltx_td ltx_align_center" id="S3.T2.1.7.5.2">19.9</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.7.5.3">19.4</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.7.5.4">74.4</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.7.5.5">73.5</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.8.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T2.1.8.6.1">     +dominance<a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#S3.E4" title="In 3.2 Fine-tuning LLMs with Emotion ‣ 3 Experiments and results ‣ Conditioning LLMs with Emotion in Neural Machine Translation"><span class="ltx_text ltx_ref_tag">4</span></a>
</th>
<td class="ltx_td ltx_align_center" id="S3.T2.1.8.6.2">18.9</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.8.6.3">20.9</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.8.6.4"><span class="ltx_text ltx_font_bold" id="S3.T2.1.8.6.4.1">74.9</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.8.6.5">74.0</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.9.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T2.1.9.7.1">     +dominance<a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#S3.E5" title="In 3.2 Fine-tuning LLMs with Emotion ‣ 3 Experiments and results ‣ Conditioning LLMs with Emotion in Neural Machine Translation"><span class="ltx_text ltx_ref_tag">5</span></a>
</th>
<td class="ltx_td ltx_align_center" id="S3.T2.1.9.7.2">16.5</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.9.7.3">20.1</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.9.7.4">73.4</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.9.7.5">73.0</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.10.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T2.1.10.8.1">     +valence<a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#S3.E3" title="In 3.2 Fine-tuning LLMs with Emotion ‣ 3 Experiments and results ‣ Conditioning LLMs with Emotion in Neural Machine Translation"><span class="ltx_text ltx_ref_tag">3</span></a>
</th>
<td class="ltx_td ltx_align_center" id="S3.T2.1.10.8.2">21.5</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.10.8.3">18.9</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.10.8.4">74.1</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.10.8.5">73.5</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.11.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T2.1.11.9.1">     +valence<a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#S3.E4" title="In 3.2 Fine-tuning LLMs with Emotion ‣ 3 Experiments and results ‣ Conditioning LLMs with Emotion in Neural Machine Translation"><span class="ltx_text ltx_ref_tag">4</span></a>
</th>
<td class="ltx_td ltx_align_center" id="S3.T2.1.11.9.2">18.3</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.11.9.3">21.2</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.11.9.4">74.6</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.11.9.5">73.9</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.12.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b" id="S3.T2.1.12.10.1">     +valence<a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#S3.E5" title="In 3.2 Fine-tuning LLMs with Emotion ‣ 3 Experiments and results ‣ Conditioning LLMs with Emotion in Neural Machine Translation"><span class="ltx_text ltx_ref_tag">5</span></a>
</th>
<td class="ltx_td ltx_align_center ltx_border_b" id="S3.T2.1.12.10.2">17.2</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S3.T2.1.12.10.3">16.0</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S3.T2.1.12.10.4">74.5</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S3.T2.1.12.10.5">73.6</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>BLEU and COMET scores of the TowerBase model on dev and test sets of Libri-trans. First line: baseline score. Other lines: score when trained with emotion in the prompt.</figcaption>
</figure>
<div class="ltx_para" id="S3.SS2.p8">
<p class="ltx_p" id="S3.SS2.p8.1">We first remark that, except in the case of <span class="ltx_text ltx_font_italic" id="S3.SS2.p8.1.1">dominance<a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#S3.E5" title="In 3.2 Fine-tuning LLMs with Emotion ‣ 3 Experiments and results ‣ Conditioning LLMs with Emotion in Neural Machine Translation"><span class="ltx_text ltx_ref_tag">5</span></a></span>, all COMET scores improved, compared to their baseline. This reflects a better translation quality when adding emotion information to the prompts. The best COMET scores are obtained when arousal information is added to the prompt using Equation <a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#S3.E3" title="In 3.2 Fine-tuning LLMs with Emotion ‣ 3 Experiments and results ‣ Conditioning LLMs with Emotion in Neural Machine Translation"><span class="ltx_text ltx_ref_tag">3</span></a>. In this configuration, COMET scores are increased by +1.1 and +1.4 for the dev and test sets of Libri-trans respectively.</p>
</div>
<div class="ltx_para" id="S3.SS2.p9">
<p class="ltx_p" id="S3.SS2.p9.1">Secondly, we observe that BLEU scores show improvements only for specific models. The best BLEU scores are obtained when arousal information is added to the prompt using Equation <a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#S3.E4" title="In 3.2 Fine-tuning LLMs with Emotion ‣ 3 Experiments and results ‣ Conditioning LLMs with Emotion in Neural Machine Translation"><span class="ltx_text ltx_ref_tag">4</span></a>. In this configuration, BLEU scores increase by +1.6 and +3.5 for the dev and test sets of Libri-trans respectively. However, due to the low ranking of BLEU <cite class="ltx_cite ltx_citemacro_citep">(Freitag et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#bib.bib10" title="">2022</a>)</cite>, we do not conduct further analysis based on this metric.</p>
</div>
<div class="ltx_para" id="S3.SS2.p10">
<p class="ltx_p" id="S3.SS2.p10.1">In summary, incorporating emotion information into the translation process appears to enhance translation quality. The highest scores are achieved when utilizing the arousal dimension with Equation <a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#S3.E3" title="In 3.2 Fine-tuning LLMs with Emotion ‣ 3 Experiments and results ‣ Conditioning LLMs with Emotion in Neural Machine Translation"><span class="ltx_text ltx_ref_tag">3</span></a> or <a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#S3.E4" title="In 3.2 Fine-tuning LLMs with Emotion ‣ 3 Experiments and results ‣ Conditioning LLMs with Emotion in Neural Machine Translation"><span class="ltx_text ltx_ref_tag">4</span></a>. This finding aligns with the results reported in <cite class="ltx_cite ltx_citemacro_citet">Brazier and Rouas (<a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#bib.bib5" title="">2024</a>)</cite>.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Conclusion</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">We proposed a new MT pipeline that combines an LLM-based model and emotion information extracted from a SER model to improve translation performances. We obtain the best performances when the arousal value is added to the LLM prompt.</p>
</div>
<div class="ltx_para" id="S4.p2">
<p class="ltx_p" id="S4.p2.1">As future work, we will apply our method to other multilingual datasets including Must-C <cite class="ltx_cite ltx_citemacro_citep">(Di Gangi et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.03150v1#bib.bib9" title="">2019</a>)</cite>. Unlike the Libri-trans dataset, which consists of literary text read by speakers, Must-C encompasses various speech types, such as TED talks, which can offer more emotional variability and therefore further enhance translation performance. We also plan to extend our method to the speech-to-text task, also known as Speech translation.</p>
</div>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Acknowledgements</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">The research presented in this paper is conducted as part of the project FVLLMONTI, which has received funding from the European Union’s Horizon 2020 Research and Innovation action under grant agreement No 101016776.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">AI@Meta (2023)</span>
<span class="ltx_bibblock">
AI@Meta. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2307.09288" title="">LLaMA 2: Open Foundation and Fine-tuned Chat Models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">Preprint</em>, arXiv:2307.09288.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">AI@Meta (2024)</span>
<span class="ltx_bibblock">
AI@Meta. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://github.com/meta-llama/llama3/blob/main/MODEL_CARD.md" title="">LLaMA 3 Model Card</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Alves et al. (2024)</span>
<span class="ltx_bibblock">
Duarte M. Alves, José Pombal, Nuno M. Guerreiro, Pedro H. Martins, João Alves, Amin Farajian, Ben Peters, Ricardo Rei, Patrick Fernandes, Sweta Agrawal, Pierre Colombo, José G.C. de Souza, and André F.T. Martins. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2402.17733" title="">Tower: An Open Multilingual Large Language Model for Translation-Related Tasks</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Preprint</em>, arXiv:2402.17733.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Anthropic (2024)</span>
<span class="ltx_bibblock">
Anthropic. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://www.anthropic.com/news/claude-3-family" title="">Claude 3: Introducing the Next Generation of Claude</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brazier and Rouas (2024)</span>
<span class="ltx_bibblock">
Charles Brazier and Jean-Luc Rouas. 2024.

</span>
<span class="ltx_bibblock">Usefulness of Emotional Prosody in Neural Machine Translation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">Proc. of the International Conference on Speech Prosody (SP)</em>, Leiden, The Netherlands.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et al. (2020)</span>
<span class="ltx_bibblock">
Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Daniel M. Ramesh, Aditya ans Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Bernet, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020.

</span>
<span class="ltx_bibblock">Language Models are Few-shot Learners.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">Proc. of the Annual Conference on Neural Information Processing Systems (NeurIPS)</em>, volume 33, pages 1877–1901, Virtual.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chiang et al. (2024)</span>
<span class="ltx_bibblock">
Wei-Lin Chiang, Lianmin Zheng, Ying Sheng, Anastasios Nikolas Angelopoulos, Tianle Li, Dacheng Li, Hao Zhang, Banghua Zhu, Michael Jordan, Joseph E. Gonzalez, and Ion Stoica. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2403.04132" title="">Chatbot Arena: An Open Platform for Evaluating LLMs by Human Preference</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">Preprint</em>, arXiv:2403.04132.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dettmers et al. (2023)</span>
<span class="ltx_bibblock">
Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, and Luke Zettlemoyer. 2023.

</span>
<span class="ltx_bibblock">Qlora: Efficient Finetuning of Quantized LLMs.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">Proc. of the Annual Conference on Neural Information Processing Systems (NeurIPS)</em>, volume 36, New Orleans, LA, USA.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Di Gangi et al. (2019)</span>
<span class="ltx_bibblock">
Mattia Antonino Di Gangi, Roldano Cattoni, Luisa Bentivogli, Matteo Negri, and Marco Turchi. 2019.

</span>
<span class="ltx_bibblock">MuST-C: a Multilingual Speech Translation Corpus.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">Proc. of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</em>, pages 2012–2017, Minneapolis, MN, USA.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Freitag et al. (2022)</span>
<span class="ltx_bibblock">
Markus Freitag, Ricardo Rei, Nitika Mathur, Chi-kiu Lo, Craig Stewart, Eleftherios Avramidis, Tom Kocmi, George Foster, Alon Lavie, and André F. T. Martins. 2022.

</span>
<span class="ltx_bibblock">Results of WMT22 Metrics Shared Task: Stop Using BLEU – Neural Metrics Are Better and More Robust.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">Proc. of the Conference on Machine Translation (WMT)</em>, pages 46–68, Abu Dhabi, United Arab Emirates.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gaido et al. (2023)</span>
<span class="ltx_bibblock">
Marco Gaido, Dennis Fucci, Matteo Negri, and Luisa Bentivogli. 2023.

</span>
<span class="ltx_bibblock">How to Build Competitive Multi-gender Speech Translation Models for Controlling Speaker Gender Translation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">Proc. of the Italian Conference on Computational Linguistics (CLiC-it)</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et al. (2022)</span>
<span class="ltx_bibblock">
Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. 2022.

</span>
<span class="ltx_bibblock">LoRA: Low-Rank Adaptation of Large Language Models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">Proc. of the International Conference on Learning Representations (ICLR)</em>, Virtual.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et al. (2023)</span>
<span class="ltx_bibblock">
Albert Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, Lélio Renard Lavaud, Marie-Anne Lachaux, Pierre Stock, Teven Le Scao, Thibaut Lavril, Thomas Wang, Timothée Lacroix, and William El Sayed. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2310.06825" title="">Mistral 7B</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">Preprint</em>, arXiv:2310.06825.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kocabiyikoglu et al. (2018)</span>
<span class="ltx_bibblock">
Ali Can Kocabiyikoglu, Laurent Besacier, and Olivier Kraif. 2018.

</span>
<span class="ltx_bibblock">Augmenting Librispeech with French Translations: A Multimodal Corpus for Direct Speech Translation Evaluation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">Proc. of the International Conference on Language Resources and Evaluation (LREC)</em>, Miyazaki, Japan.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mangrulkar et al. (2022)</span>
<span class="ltx_bibblock">
Sourab Mangrulkar, Sylvain Gugger, Lysandre Debut, Younes Belkada, Sayak Paul, and Benjamin Bossan. 2022.

</span>
<span class="ltx_bibblock">PEFT: State-of-the-art Parameter-Efficient Fine-Tuning methods.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/huggingface/peft" title="">https://github.com/huggingface/peft</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Moslem et al. (2023a)</span>
<span class="ltx_bibblock">
Yasmin Moslem, Rejwanul Haque, John D. Kelleher, and Andy Way. 2023a.

</span>
<span class="ltx_bibblock">Adaptive Machine Translation with Large Language Models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">Proc. of the Annual Conference of the European Association for Machine Translation (EAMT)</em>, pages 227–237, Tampere, Finland.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Moslem et al. (2023b)</span>
<span class="ltx_bibblock">
Yasmin Moslem, Rejwanul Haque, and Andy Way. 2023b.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2312.12740" title="">Fine-tuning Large Language Models for Adaptive Machine Translation</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">Preprint</em>, arXiv:2312.12740.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2022)</span>
<span class="ltx_bibblock">
OpenAI. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://chat.openai.com/" title="">https://chat.openai.com/</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2023)</span>
<span class="ltx_bibblock">
OpenAI. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2303.08774" title="">GPT-4 Technical Report</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">Preprint</em>, arXiv:2303.08774.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ouyang et al. (2022)</span>
<span class="ltx_bibblock">
Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul F. Christiano, Jan Leike, and Ryan Lowe. 2022.

</span>
<span class="ltx_bibblock">Training Language Models to Follow Instructions with Human Feedback.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">Proc. of the Annual Conference on Neural Information Processing Systems (NeurIPS)</em>, volume 35, pages 27730–27744, New Orleans, LA, USA.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pennebaker et al. (2001)</span>
<span class="ltx_bibblock">
J.W. Pennebaker, M.E. Francis, and R.J. Booth. 2001.

</span>
<span class="ltx_bibblock">Linguistic Inquiry and Word Count: LIWC 2001.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">Mahway: Lawrence Erlbaum Associates</em>, 71.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Post (2018)</span>
<span class="ltx_bibblock">
Matt Post. 2018.

</span>
<span class="ltx_bibblock">A Call for Clarity in Reporting BLEU Scores.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">Proc. of the Conference on Machine Translation: Research Papers (WMT)</em>, pages 186–191, Brussels, Belgium.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rei et al. (2022)</span>
<span class="ltx_bibblock">
Ricardo Rei, José G. C. de Souza, Duarte M. Alves, Chrysoula Zerva, Ana C Farinha, Taisiya Glushkova, Alon Lavie, Luisa Coheur, and André F. T. Martins. 2022.

</span>
<span class="ltx_bibblock">COMET-22: Unbabel-IST 2022 Submission for the Metrics Shared Task.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">Proc. of the Conference on Machine Translation (WMT)</em>, pages 578–585, Abu Dhabi, United Arab Emirates.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sennrich et al. (2019)</span>
<span class="ltx_bibblock">
Rico Sennrich, Barry Haddow, and Alexandra Birch. 2019.

</span>
<span class="ltx_bibblock">Controlling Politeness in Neural Machine Translation via Side Constraints.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">Proc. of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)</em>, pages 35–40, San Diego, USA.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Team (2024)</span>
<span class="ltx_bibblock">
Gemini Team. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2403.05530" title="">Gemini 1.5: Unlocking Multimodal Understanding across Millions of Tokens of Context</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">Preprint</em>, arXiv:2403.05530.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vanmassenhove et al. (2018)</span>
<span class="ltx_bibblock">
Eva Vanmassenhove, Christian Hardmeier, and Andy Way. 2018.

</span>
<span class="ltx_bibblock">Getting Gender Right in Neural Machine Translation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">Proc. of the Conference on Empirical Methods in Natural Language Processing (CEMNLP)</em>, pages 3003–3008, Brussels, Belgium.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vaswani et al. (2017)</span>
<span class="ltx_bibblock">
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017.

</span>
<span class="ltx_bibblock">Attention is All you Need.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">Proc. of the Annual Conference on Neural Information Processing Systems (NIPS)</em>, pages 5998–6008, Long Beach, USA.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wagner et al. (2023)</span>
<span class="ltx_bibblock">
Johannes Wagner, Andreas Triantafyllopoulos, Hagen Wierstorf, Maximilian Schmitt, Felix Burkhardt, Florian Eyben, and Björn W Schuller. 2023.

</span>
<span class="ltx_bibblock">Dawn of the Transformer Era in Speech Emotion Recognition: Closing the Valence Gap.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, 45:10745–10759.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al. (2023)</span>
<span class="ltx_bibblock">
Haoran Xu, Young Jin Kim, Amr Sharaf, and Hany Hassan Awadalla. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2309.11674" title="">A Paradigm Shift in Machine Translation: Boosting Translation Performance of Large Language Models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">Preprint</em>, arXiv:2309.11674.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2023)</span>
<span class="ltx_bibblock">
Biao Zhang, Barry Haddow, and Alexandra Birch. 2023.

</span>
<span class="ltx_bibblock">Prompting Large Language Model for Machine Translation: A Case Study.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">Proc. of the International Conference on Machine Learning (ICML)</em>, pages 41092–41110, Edinburgh, Scotland.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al. (2021)</span>
<span class="ltx_bibblock">
Chengqi Zhao, Mingxuan Wang, Qianqian Dong, Rong Ye, and Lei Li. 2021.

</span>
<span class="ltx_bibblock">NeurST: Neural speech translation toolkit.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">Proc. of the Joint Conference of the Annual Meeting of the Association for Computational Linguistics and the International Joint Conference on Natural Language Processing (ACL)</em>, pages 55–62, Online.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu et al. (2023a)</span>
<span class="ltx_bibblock">
Wenhao Zhu, Hongyi Liu, Qingxiu Dong, Jingjing Xu, Shujian Huang, Lingpeng Kong, Jiajun Chen, and Lei Li. 2023a.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2304.04675" title="">Multilingual Machine Translation with Large Language Models: Empirical Results and Analysis</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">Preprint</em>, arXiv:2304.04675.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu et al. (2023b)</span>
<span class="ltx_bibblock">
Yutao Zhu, Huaying Yuan, Shuting Wang, Jiongnan Liu, Wenhan Liu, Chenlong Deng, Zhicheng Dou, and Ji-Rong Wen. 2023b.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2308.07107" title="">Large Language Models for Information Retrieval: A Survey</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">Preprint</em>, arXiv:2308.07107.

</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Tue Aug  6 12:36:46 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
