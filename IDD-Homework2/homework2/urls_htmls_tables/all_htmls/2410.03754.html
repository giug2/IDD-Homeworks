<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Enhancing Retrieval in QA Systems with Derived Feature Association</title>
<!--Generated on Wed Oct  2 05:09:36 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2410.03754v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03754v1#S1" title="In Enhancing Retrieval in QA Systems with Derived Feature Association"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03754v1#S1.SS1" title="In 1 Introduction ‣ Enhancing Retrieval in QA Systems with Derived Feature Association"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.1 </span>Preliminaries</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03754v1#S1.SS2" title="In 1 Introduction ‣ Enhancing Retrieval in QA Systems with Derived Feature Association"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.2 </span>Motivation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03754v1#S1.SS3" title="In 1 Introduction ‣ Enhancing Retrieval in QA Systems with Derived Feature Association"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.3 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03754v1#S1.SS4" title="In 1 Introduction ‣ Enhancing Retrieval in QA Systems with Derived Feature Association"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.4 </span>Contribution</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03754v1#S2" title="In Enhancing Retrieval in QA Systems with Derived Feature Association"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Method</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03754v1#S2.SS1" title="In 2 Method ‣ Enhancing Retrieval in QA Systems with Derived Feature Association"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Derived Document Association</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03754v1#S2.SS2" title="In 2 Method ‣ Enhancing Retrieval in QA Systems with Derived Feature Association"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>RAIDD Flavors</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03754v1#S2.SS2.SSS0.Px1" title="In 2.2 RAIDD Flavors ‣ 2 Method ‣ Enhancing Retrieval in QA Systems with Derived Feature Association"><span class="ltx_text ltx_ref_title">RAIDD-S</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03754v1#S2.SS2.SSS0.Px2" title="In 2.2 RAIDD Flavors ‣ 2 Method ‣ Enhancing Retrieval in QA Systems with Derived Feature Association"><span class="ltx_text ltx_ref_title">RAIDD-S ICL</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03754v1#S2.SS2.SSS0.Px3" title="In 2.2 RAIDD Flavors ‣ 2 Method ‣ Enhancing Retrieval in QA Systems with Derived Feature Association"><span class="ltx_text ltx_ref_title">RAIDD-Q</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.03754v1#S2.SS2.SSS0.Px4" title="In 2.2 RAIDD Flavors ‣ 2 Method ‣ Enhancing Retrieval in QA Systems with Derived Feature Association"><span class="ltx_text ltx_ref_title">RAIDD-U</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03754v1#S2.SS3" title="In 2 Method ‣ Enhancing Retrieval in QA Systems with Derived Feature Association"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Dataset and Evaluation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03754v1#S3" title="In Enhancing Retrieval in QA Systems with Derived Feature Association"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03754v1#S3.SS1" title="In 3 Experiments ‣ Enhancing Retrieval in QA Systems with Derived Feature Association"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Implementation Details</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03754v1#S3.SS2" title="In 3 Experiments ‣ Enhancing Retrieval in QA Systems with Derived Feature Association"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.03754v1#S3.SS3" title="In 3 Experiments ‣ Enhancing Retrieval in QA Systems with Derived Feature Association"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Per-Task Analysis</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03754v1#S3.SS3.SSS1" title="In 3.3 Per-Task Analysis ‣ 3 Experiments ‣ Enhancing Retrieval in QA Systems with Derived Feature Association"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3.1 </span>Timeline Reorder</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03754v1#S3.SS3.SSS2" title="In 3.3 Per-Task Analysis ‣ 3 Experiments ‣ Enhancing Retrieval in QA Systems with Derived Feature Association"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3.2 </span>Multiple Information Retrieval</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03754v1#S3.SS3.SSS3" title="In 3.3 Per-Task Analysis ‣ 3 Experiments ‣ Enhancing Retrieval in QA Systems with Derived Feature Association"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3.3 </span>Comprehension and Reasoning</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.03754v1#S3.SS3.SSS4" title="In 3.3 Per-Task Analysis ‣ 3 Experiments ‣ Enhancing Retrieval in QA Systems with Derived Feature Association"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3.4 </span>Computation</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.03754v1#S4" title="In Enhancing Retrieval in QA Systems with Derived Feature Association"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2410.03754v1#A1" title="In Enhancing Retrieval in QA Systems with Derived Feature Association"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Question Examples</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Enhancing Retrieval in QA Systems with Derived Feature Association</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Keyush Shah  Abhishek Goyal  Isaac Wasserman 
<br class="ltx_break"/>Department of Computer and Information Science
<br class="ltx_break"/>University of Pennsylvania
<br class="ltx_break"/>Philadelphia, PA 19104 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id1.1.id1">{keyush06, abhi2358, isaacrw}@seas.upenn.edu</span>
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id2.id1">Retrieval augmented generation (RAG) has become the standard in long-context question answering (QA) systems. However, typical implementations of RAG rely on a rather naive retrieval mechanism, in which texts whose embeddings are most similar to that of the query are deemed most relevant. This has consequences in subjective QA tasks, where the most relevant text may not directly contain the answer. In this work, we propose a novel extension to RAG systems, which we call <span class="ltx_text ltx_font_bold" id="id2.id1.1">R</span>etrieval from <span class="ltx_text ltx_font_bold" id="id2.id1.2">AI</span>
<span class="ltx_text ltx_font_bold" id="id2.id1.3">D</span>erived <span class="ltx_text ltx_font_bold" id="id2.id1.4">D</span>ocuments (RAIDD). RAIDD leverages the full power of the LLM in the retrieval process by deriving inferred features, such as summaries and example questions, from the documents at ingest. We demonstrate that this approach significantly improves the performance of RAG systems on long-context QA tasks. <span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>https://github.com/isaacwasserman/LongRAG</span></span></span></p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<section class="ltx_subsection" id="S1.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.1 </span>Preliminaries</h3>
<div class="ltx_para" id="S1.SS1.p1">
<p class="ltx_p" id="S1.SS1.p1.1">First introduced by <cite class="ltx_cite ltx_citemacro_cite">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03754v1#bib.bib8" title="">8</a>)</cite>, retrieval augmented generation (RAG) allows LLMs to pull relevant information into context from a cache of documents. The system allows these models to access up-to-date information, rely less on their parameterized-memory, and leverage a large corpus of documents during generation, despite their limited context window <cite class="ltx_cite ltx_citemacro_cite">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03754v1#bib.bib17" title="">17</a>)</cite>. RAG extends LLMs with a retrieval mechanism that takes a query, selects the most relevant texts from a given corpus, and hands them to the generator to inform its answer. Early approaches, were optimized end-to-end, using a jointly learned retriever and generator that communicated through a shared embedding space <cite class="ltx_cite ltx_citemacro_cite">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03754v1#bib.bib8" title="">8</a>)</cite>. However, the requirement that such a system must be trained from scratch for each choice of generator architecture makes this approach expensive and cumbersome given the rapid pace with which new LLMs are developed. However, this paradigm was subverted by <cite class="ltx_cite ltx_citemacro_cite">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03754v1#bib.bib14" title="">14</a>)</cite>, which assumes the generator to be black-box, training a generator-agnostic retriever that simply prepends the retrieved text to the generator’s input. In practice, the retriever is often further simplified to score documents based on their cosine similarity in a pretrained embedding space (dense retrieval); also popular is the use of BM25, a simple term-frequency based similarity metric (sparse retrieval) <cite class="ltx_cite ltx_citemacro_cite">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03754v1#bib.bib17" title="">17</a>)</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="S1.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.2 </span>Motivation</h3>
<div class="ltx_para" id="S1.SS2.p1">
<p class="ltx_p" id="S1.SS2.p1.1">RAG systems, especially those which rely on embedding cosine similarity or BM25 to measure relevance, are fast and remarkably effective for answering questions whose answers are explicitly stated in the text. However, from a user’s perspective, this is only marginally more effective than a simple <code class="ltx_verbatim ltx_font_typewriter" id="S1.SS2.p1.1.1">ctrl+f</code> search. We expect more from the systems that we call “artificially intelligent”. In particular, we expect them to be able to answer questions whose answers are not explicitly stated in the text, but can be easily inferred from the text. Consider the example in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.03754v1#S1.F1" title="Figure 1 ‣ 1.2 Motivation ‣ 1 Introduction ‣ Enhancing Retrieval in QA Systems with Derived Feature Association"><span class="ltx_text ltx_ref_tag">1</span></a>, using cosine similarity between the query and text; the retriever latches onto the text which most explicitly describes commentary on the artist’s work and ignores the text which contains the answer but does not contain words like “regarded”. This is a common failure mode for RAG systems, and it demonstrates how the retriever can be a hindrance to what is otherwise a powerful model for natural language understanding.</p>
</div>
<figure class="ltx_figure" id="S1.F1">
<p class="ltx_p ltx_align_center" id="S1.F1.1"><span class="ltx_text" id="S1.F1.1.1" style="background-color:#FAFAFF;">
<span class="ltx_tabular ltx_align_middle" id="S1.F1.1.1.1">
<span class="ltx_tr" id="S1.F1.1.1.1.1">
<span class="ltx_td ltx_align_left" id="S1.F1.1.1.1.1.1" style="padding-top:5pt;padding-bottom:5pt;"><span class="ltx_text ltx_font_bold" id="S1.F1.1.1.1.1.1.1">Question</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="S1.F1.1.1.1.1.2" style="padding-top:5pt;padding-bottom:5pt;">
<span class="ltx_inline-block ltx_align_top" id="S1.F1.1.1.1.1.2.1">
<span class="ltx_p" id="S1.F1.1.1.1.1.2.1.1" style="width:284.5pt;">All of historians speak highly of Picardo’s work, is this true? Why?</span>
</span></span></span>
<span class="ltx_tr" id="S1.F1.1.1.1.2">
<span class="ltx_td ltx_align_left" id="S1.F1.1.1.1.2.1" style="padding-top:5pt;padding-bottom:5pt;"><span class="ltx_ERROR undefined" id="S1.F1.1.1.1.2.1.1">\cdashline</span>1-2[1.5pt/3pt] 
<span class="ltx_text ltx_font_bold" id="S1.F1.1.1.1.2.1.2">Target Text</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="S1.F1.1.1.1.2.2" style="padding-top:5pt;padding-bottom:5pt;">
<span class="ltx_inline-block ltx_align_top" id="S1.F1.1.1.1.2.2.1">
<span class="ltx_p" id="S1.F1.1.1.1.2.2.1.1" style="width:284.5pt;">“…
 <span class="ltx_text" id="S1.F1.1.1.1.2.2.1.1.1" style="background-color:#85FF82;">was somewhat frowned upon</span>  in the 1960s and 1970s, and over half a century later is seen by archeologists and historians as a matter of significant 
 <span class="ltx_text" id="S1.F1.1.1.1.2.2.1.1.2" style="background-color:#85FF82;">controversy and regret</span> .”</span>
</span></span></span>
<span class="ltx_tr" id="S1.F1.1.1.1.3">
<span class="ltx_td ltx_align_left" id="S1.F1.1.1.1.3.1" style="padding-top:5pt;padding-bottom:5pt;"><span class="ltx_text ltx_font_bold" id="S1.F1.1.1.1.3.1.1">Ground Truth</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="S1.F1.1.1.1.3.2" style="padding-top:5pt;padding-bottom:5pt;">
<span class="ltx_inline-block ltx_align_top" id="S1.F1.1.1.1.3.2.1">
<span class="ltx_p" id="S1.F1.1.1.1.3.2.1.1" style="width:284.5pt;">False, because some people believe that Parrado destroyed the part of historical and architectural [sic].</span>
</span></span></span>
<span class="ltx_tr" id="S1.F1.1.1.1.4">
<span class="ltx_td ltx_align_left" id="S1.F1.1.1.1.4.1" style="padding-top:5pt;padding-bottom:5pt;"><span class="ltx_ERROR undefined" id="S1.F1.1.1.1.4.1.1">\cdashline</span>1-2[1.5pt/3pt] 
<span class="ltx_text" id="S1.F1.1.1.1.4.1.2" style="font-size:70%;">RAG</span></span>
<span class="ltx_td ltx_align_top" id="S1.F1.1.1.1.4.2" style="padding-top:5pt;padding-bottom:5pt;"></span></span>
<span class="ltx_tr" id="S1.F1.1.1.1.5">
<span class="ltx_td ltx_align_left" id="S1.F1.1.1.1.5.1" style="padding-top:5pt;padding-bottom:5pt;"><span class="ltx_text ltx_font_bold" id="S1.F1.1.1.1.5.1.1">Retrieved Text</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="S1.F1.1.1.1.5.2" style="padding-top:5pt;padding-bottom:5pt;">
<span class="ltx_inline-block ltx_align_top" id="S1.F1.1.1.1.5.2.1">
<span class="ltx_p" id="S1.F1.1.1.1.5.2.1.1" style="width:284.5pt;">“…Picardo’s published architectural drawings were highly regarded. They were described as 
 <span class="ltx_text" id="S1.F1.1.1.1.5.2.1.1.1" style="background-color:#FF6969;">“magnificent”</span>  by the leading Spanish restoration architect …”</span>
</span></span></span>
<span class="ltx_tr" id="S1.F1.1.1.1.6">
<span class="ltx_td ltx_align_left" id="S1.F1.1.1.1.6.1" style="padding-top:5pt;padding-bottom:5pt;"><span class="ltx_text ltx_font_bold" id="S1.F1.1.1.1.6.1.1">Prediction</span> <span class="ltx_text" id="S1.F1.1.1.1.6.1.2" style="position:relative; bottom:0.0pt;"></span></span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="S1.F1.1.1.1.6.2" style="padding-top:5pt;padding-bottom:5pt;">
<span class="ltx_inline-block ltx_align_top" id="S1.F1.1.1.1.6.2.1">
<span class="ltx_p" id="S1.F1.1.1.1.6.2.1.1" style="width:284.5pt;">Yes, because his architectural drawings were described as 
 <span class="ltx_text" id="S1.F1.1.1.1.6.2.1.1.1" style="background-color:#FF6969;">“magnificent”</span>  …</span>
</span></span></span>
<span class="ltx_tr" id="S1.F1.1.1.1.7">
<span class="ltx_td ltx_align_left" id="S1.F1.1.1.1.7.1" style="padding-top:5pt;padding-bottom:5pt;"><span class="ltx_ERROR undefined" id="S1.F1.1.1.1.7.1.1">\cdashline</span>1-2[1.5pt/3pt] 
<span class="ltx_text" id="S1.F1.1.1.1.7.1.2" style="font-size:70%;">RAIDD-S</span></span>
<span class="ltx_td ltx_align_top" id="S1.F1.1.1.1.7.2" style="padding-top:5pt;padding-bottom:5pt;"></span></span>
<span class="ltx_tr" id="S1.F1.1.1.1.8">
<span class="ltx_td ltx_align_left" id="S1.F1.1.1.1.8.1" style="padding-top:5pt;padding-bottom:5pt;"><span class="ltx_text ltx_font_bold" id="S1.F1.1.1.1.8.1.1">Retrieved Text</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="S1.F1.1.1.1.8.2" style="padding-top:5pt;padding-bottom:5pt;">
<span class="ltx_inline-block ltx_align_top" id="S1.F1.1.1.1.8.2.1">
<span class="ltx_p" id="S1.F1.1.1.1.8.2.1.1" style="width:284.5pt;">“…
 <span class="ltx_text" id="S1.F1.1.1.1.8.2.1.1.1" style="background-color:#85FF82;">was somewhat frowned upon</span>  in the 1960s and 1970s, and over half a century later is seen by archeologists and historians as a matter of significant 
 <span class="ltx_text" id="S1.F1.1.1.1.8.2.1.1.2" style="background-color:#85FF82;">controversy and regret</span> .”</span>
</span></span></span>
<span class="ltx_tr" id="S1.F1.1.1.1.9">
<span class="ltx_td ltx_align_left" id="S1.F1.1.1.1.9.1" style="padding-top:5pt;padding-bottom:5pt;"><span class="ltx_text ltx_font_bold" id="S1.F1.1.1.1.9.1.1">Prediction</span> <span class="ltx_text" id="S1.F1.1.1.1.9.1.2" style="position:relative; bottom:0.0pt;"></span></span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="S1.F1.1.1.1.9.2" style="padding-top:5pt;padding-bottom:5pt;">
<span class="ltx_inline-block ltx_align_top" id="S1.F1.1.1.1.9.2.1">
<span class="ltx_p" id="S1.F1.1.1.1.9.2.1.1" style="width:284.5pt;">No, …Some historians and archeologists have criticized his rehabilitation and restoration projects for being 
 <span class="ltx_text" id="S1.F1.1.1.1.9.2.1.1.1" style="background-color:#85FF82;">pastiche</span>  and for the 
 <span class="ltx_text" id="S1.F1.1.1.1.9.2.1.1.2" style="background-color:#85FF82;">demolition of large parts of monumental buildings</span>  …This has led to 
 <span class="ltx_text" id="S1.F1.1.1.1.9.2.1.1.3" style="background-color:#85FF82;">significant controversy and regret</span>  over half a century later.</span>
</span></span></span>
</span>
</span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Example of a question from the LooGLE <cite class="ltx_cite ltx_citemacro_cite">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03754v1#bib.bib9" title="">9</a>)</cite> dataset answered by a traditional RAG system and RAIDD-S. The traditional system identifies the a text that describes how Picardo’s work was regarded by one figure, but it fails to identify the more subtly worded target text which contains the answer. Using summary generation, RAIDD-S is able to retrieve a more relevant passage and correctly answer the question.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S1.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.3 </span>Related Work</h3>
<div class="ltx_para" id="S1.SS3.p1">
<p class="ltx_p" id="S1.SS3.p1.1">RAG is an extremely active area of AI research with the goal of improving LLM performance and safety by augmenting the generation context with useful cached information <cite class="ltx_cite ltx_citemacro_cite">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03754v1#bib.bib17" title="">17</a>)</cite>. The modern approach to RAG is generator-agnostic <cite class="ltx_cite ltx_citemacro_cite">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03754v1#bib.bib14" title="">14</a>)</cite>. This is convenient as it allows for the use of the latest and greatest LLMs without the need for retraining; however, it places a much greater burden on the retriever to be effective and efficient.</p>
</div>
<div class="ltx_para" id="S1.SS3.p2">
<p class="ltx_p" id="S1.SS3.p2.1">In addition to the rather expensive and unportable practice of training domain-specific query encoders <cite class="ltx_cite ltx_citemacro_cite">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03754v1#bib.bib14" title="">14</a>)</cite> and rerankers <cite class="ltx_cite ltx_citemacro_cite">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03754v1#bib.bib3" title="">3</a>)</cite>, simple modifications to the retrieval mechanism can make a profound impact on the system’s performance. For example, <cite class="ltx_cite ltx_citemacro_cite">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03754v1#bib.bib1" title="">1</a>)</cite> demonstrated the benefits of shorter chunk sizes and more granular indexing, while <cite class="ltx_cite ltx_citemacro_cite">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03754v1#bib.bib11" title="">11</a>)</cite> and <cite class="ltx_cite ltx_citemacro_cite">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03754v1#bib.bib13" title="">13</a>)</cite> construct multi-resolution document stores which afford a balance of context and precision. Input transformation has also been shown to be an effective tool for improving dense retrieval. In this paradigm, we use an LLM to generate a “pseudo-document” from the query: a piece of text that looks like the document we want to retrieve but it is actually contrived <cite class="ltx_cite ltx_citemacro_cite">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03754v1#bib.bib2" title="">2</a>)</cite>, serving as a template for the target document.</p>
</div>
<div class="ltx_para" id="S1.SS3.p3">
<p class="ltx_p" id="S1.SS3.p3.1">Data augmentation is an increasingly popular solution for improving dense retrieval. <cite class="ltx_cite ltx_citemacro_cite">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03754v1#bib.bib6" title="">6</a>)</cite> uses an RAG system to retrieve audio clips using a text query. To achieve such behavior, they generate text aliases for each audio clip and index the clips according to these aliases. This approach serves as <cite class="ltx_cite ltx_citemacro_cite">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03754v1#bib.bib1" title="">1</a>)</cite> demonstrates the utility of transforming RAG documents into more digestible, concise, and explicit forms. They propose “propositional retrieval”, a method quickly adopted by the AI agent community <cite class="ltx_cite ltx_citemacro_cite">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03754v1#bib.bib5" title="">5</a>)</cite> due to its effectiveness, portability, and runtime efficiency. Their method preprocesses documents to extract individual propositions from the text and indexes them instead of chunks of the original text. This greatly improves retrieval of information which is explicitly stated, but it sacrifices nuance that may be necessary for answering more complex questions.</p>
</div>
</section>
<section class="ltx_subsection" id="S1.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.4 </span>Contribution</h3>
<div class="ltx_para" id="S1.SS4.p1">
<p class="ltx_p" id="S1.SS4.p1.1">In light of previous attempts to improve dense retrieval, we sought to develop an extension to RAG that enables retrieval of implicit content without sacrificing nuance or portability. Specifically, we make the following contributions:</p>
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">RAIDD: A novel framework for RAG which retrieves more relevant context by matching the query against LLM derived features</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">Implemented multiple variants of RAIDD to improve context retrieval in RAG systems</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">Applications of RAIDD that outperform vanilla RAG in QA accuracy by 15%<sup class="ltx_sup" id="S1.I1.i3.p1.1.1"><a class="ltx_ref" href="https://arxiv.org/html/2410.03754v1#footnote2" title="footnote 2 ‣ 4th item ‣ 1.4 Contribution ‣ 1 Introduction ‣ Enhancing Retrieval in QA Systems with Derived Feature Association"><span class="ltx_text ltx_ref_tag">2</span></a></sup></p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i4.p1">
<p class="ltx_p" id="S1.I1.i4.p1.1">Applications of RAIDD that improve retrieval of relevant context by 15%<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>task dependent</span></span></span></p>
</div>
</li>
</ul>
</div>
</section>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Method</h2>
<figure class="ltx_figure" id="S2.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="567" id="S2.F2.g1" src="x1.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>During the document ingest phase, RAIDD derives new documents from the input by prompting a GPT feature extractor to summarize and generate questions from the original documents. At inference, the retriever identifies the most relevant derived documents and places the corresponding source documents into context for question answering.</figcaption>
</figure>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Derived Document Association</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">RAIDD generalizes the retrieval paradigms first introduced by Chen et al. (2023) <cite class="ltx_cite ltx_citemacro_cite">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03754v1#bib.bib1" title="">1</a>)</cite>. In this original paradigm, LLM generated “propositional” documents completely supplant the original text, throughout the retrieval and generation processes. Our method, RAIDD, diverges from this paradigm by placing the original text in the generation context, rather than the derived documents themselves. We make this change in an effort to minimize the impact of information loss in the document derivation process, retaining the same level of detail as vanilla RAG. We call this practice of using the derived documents as handles for the original text “derived document association”. Derived document association generalizes the retrieval technique of Huang et al. (2023), in which the system retrieves audio clips based on how well their derived text aliases match the query.</p>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1">More concretely, our method involves two phases: ingest and inference. During ingest, we prompt an LLM to generate derived documents from each input document. These derived documents are either summaries of each chunk, sets of questions from each chunk, or both. We generate embeddings from these derived documents and store them in a vector database. At inference time, the retriever matches our query against all of the derived documents. For each of the top <math alttext="k" class="ltx_Math" display="inline" id="S2.SS1.p2.1.m1.1"><semantics id="S2.SS1.p2.1.m1.1a"><mi id="S2.SS1.p2.1.m1.1.1" xref="S2.SS1.p2.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.1.m1.1b"><ci id="S2.SS1.p2.1.m1.1.1.cmml" xref="S2.SS1.p2.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p2.1.m1.1d">italic_k</annotation></semantics></math> derived documents, we place the corresponding original document into our question answering context.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>RAIDD Flavors</h3>
<section class="ltx_paragraph" id="S2.SS2.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">RAIDD-S</h5>
<div class="ltx_para" id="S2.SS2.SSS0.Px1.p1">
<p class="ltx_p" id="S2.SS2.SSS0.Px1.p1.1">Consider the following scenario where the document store has two documents: (a) “Johnny mixed ‘ocean’ and ‘fire-engine’ on his palette” and (b) “Johnny made so much green as a world-renowned painter”, and the model is asked “What color paint did Johnny make?”. Modern LLMs are more than capable of understanding that “green” is a euphemism for money, and that “ocean” and “fire-engine” are shades of blue and red that make purple when combined. However, dense retrieval with OpenAI’s text-embedding-ada-002 <cite class="ltx_cite ltx_citemacro_cite">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03754v1#bib.bib4" title="">4</a>)</cite> scores document (b) 4% higher than document (a), likely because of its inclusion of words like “made”, “green”, and “paint”. While this is a contrived example, it demonstrates how dense retrieval systems place too much responsibility on a underpowered retriever, despite having access to incredibly performant natural language understanding models.</p>
</div>
<div class="ltx_para" id="S2.SS2.SSS0.Px1.p2">
<p class="ltx_p" id="S2.SS2.SSS0.Px1.p2.1">RAIDD-S seeks to improve the retrieval of implied information by retrieving text chunks based on their LLM generated summaries. By forcing our LLM to make the document more direct, concise, and explicit, we hope to improve the retriever’s ability to identify the most relevant text. We generate summaries for each chunk of text in the document store, requesting that the LLM provide concept-level summaries which paraphrase the original text. We condition this generation with the original text as well as the summary of the previous chunk to maintain coherence. RAIDD-S+ augments this by also directly retrieving raw text chunks if they rank higher than summaries.</p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS2.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">RAIDD-S ICL</h5>
<div class="ltx_para" id="S2.SS2.SSS0.Px2.p1">
<p class="ltx_p" id="S2.SS2.SSS0.Px2.p1.1">We use the LLM as an optimizer within a feedback loop mechanism aimed at enhancing the accuracy and relevance of its responses to QA task. The LLM generates answers to a set of input questions. Each generated answer is then evaluated against a ground truth answer, and the LLM assigns itself a self-score ranging from 0 to 1, indicating the confidence or quality of its response. These scores, along with the generated answers and the respective ground truth answers, form a set of data points known as solution-score pairs.
<br class="ltx_break"/>These solution-score pairs are utilized as a “meta-prompt” for the LLM. The meta-prompt also includes a task description that contextualizes the next question for which a solution is sought. This comprehensive meta-prompt serves as a refined input that guides the LLM in adjusting its internal strategies for generating solutions, effectively using its past performance (as reflected by the scores and solution accuracy) to optimize future outputs.
<br class="ltx_break"/>Through this iterative process, it optimizes its context retrieval and answer generation to increase alignment with expected results.</p>
</div>
<figure class="ltx_figure" id="S2.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="483" id="S2.F3.g1" src="x2.png" width="717"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>In-context learning using an LLM as an optimizer</figcaption>
</figure>
</section>
<section class="ltx_paragraph" id="S2.SS2.SSS0.Px3">
<h5 class="ltx_title ltx_title_paragraph">RAIDD-Q</h5>
<div class="ltx_para" id="S2.SS2.SSS0.Px3.p1">
<p class="ltx_p" id="S2.SS2.SSS0.Px3.p1.1">For RAIDD-Q, we draw inspiration from the work of <cite class="ltx_cite ltx_citemacro_cite">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03754v1#bib.bib2" title="">2</a>)</cite> and <cite class="ltx_cite ltx_citemacro_cite">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03754v1#bib.bib16" title="">16</a>)</cite>. While in their work, they generate pseudo-documents from the query in order to provide the retriever with a template for the target document, we perform the inverse process, generating pseudo-queries from the documents. We prompt the LLM to generate a set of unique reading comprehension questions from each chunk of text in the document store. To accommodate multiple chunk sizes, we generate 32 questions for every 1024 tokens of text. Since each chunk now has multiple questions associated with it, during retrieval, we retrieve the top <math alttext="k" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px3.p1.1.m1.1"><semantics id="S2.SS2.SSS0.Px3.p1.1.m1.1a"><mi id="S2.SS2.SSS0.Px3.p1.1.m1.1.1" xref="S2.SS2.SSS0.Px3.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px3.p1.1.m1.1b"><ci id="S2.SS2.SSS0.Px3.p1.1.m1.1.1.cmml" xref="S2.SS2.SSS0.Px3.p1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px3.p1.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px3.p1.1.m1.1d">italic_k</annotation></semantics></math> questions that correspond to unique chunks of the original text. We then place the original text into context for question answering. Like RAIDD-S+, RAIDD-Q+ is a variation which also retrieves raw text chunks.</p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS2.SSS0.Px4">
<h5 class="ltx_title ltx_title_paragraph">RAIDD-U</h5>
<div class="ltx_para" id="S2.SS2.SSS0.Px4.p1">
<p class="ltx_p" id="S2.SS2.SSS0.Px4.p1.1">RAIDD-U attempts to ensemble the benefits of RAIDD-S+ and RAIDD-Q+ by retrieving from an index which contains the union of the summary, question, and raw text document stores. RAIDD-U emulates a form of multiheaded attention, in which each our raw text, summary, and generated questions can be thought of as multiple keys for the same value.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Dataset and Evaluation</h3>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1">We evaluate long-context question answering performance using the long-dependency QA subset of LooGLE <cite class="ltx_cite ltx_citemacro_cite">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03754v1#bib.bib9" title="">9</a>)</cite>. To minimize cost, we use the first 100 questions of the dataset, as our validation set for choosing hyperparameters, and we use the next 100 questions to test our final configurations. We compare each of our models to a standard dense retrieval baseline using the same embedding and generator models. Question answering performance is measured using ROUGE <cite class="ltx_cite ltx_citemacro_cite">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03754v1#bib.bib10" title="">10</a>)</cite> and accuracy. The accuracy of each response is decided by GPT-4; we prompt the model to decide whether the generated answer is sufficiently similar to the ground-truth, given the question.</p>
</div>
<div class="ltx_para" id="S2.SS3.p2">
<p class="ltx_p" id="S2.SS3.p2.1">Note that generating the summarizations and questions used as the AI derived documents takes place during document ingest and is just a means to an end that is answering the questions.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Experiments</h2>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Implementation Details</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">Our experiments are implemented using the LlamaIndex <cite class="ltx_cite ltx_citemacro_cite">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03754v1#bib.bib11" title="">11</a>)</cite> RAG library. For generating derived documents, we prompt an instruction tuned Mixtral-8x7B model <cite class="ltx_cite ltx_citemacro_cite">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03754v1#bib.bib7" title="">7</a>)</cite>. We use the frontier-class Mistral Large model <cite class="ltx_cite ltx_citemacro_cite">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03754v1#bib.bib15" title="">15</a>)</cite> as our question answering model. Our retriever uses a simple cosine similarity metric between the query and document embeddings, which are encoded using OpenAI’s text-embedding-ada-002 <cite class="ltx_cite ltx_citemacro_cite">(<a class="ltx_ref" href="https://arxiv.org/html/2410.03754v1#bib.bib4" title="">4</a>)</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Results</h3>
<figure class="ltx_table" id="S3.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Performance comparison of various flavors of RAIDD on the validation set. </figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S3.T1.1">
<tr class="ltx_tr" id="S3.T1.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S3.T1.1.1.2">Method</td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S3.T1.1.1.3">Chunk Size</td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S3.T1.1.1.4">Overlap</td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S3.T1.1.1.1">Top-<math alttext="k" class="ltx_Math" display="inline" id="S3.T1.1.1.1.m1.1"><semantics id="S3.T1.1.1.1.m1.1a"><mi id="S3.T1.1.1.1.m1.1.1" xref="S3.T1.1.1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.T1.1.1.1.m1.1b"><ci id="S3.T1.1.1.1.m1.1.1.cmml" xref="S3.T1.1.1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.1.1.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.T1.1.1.1.m1.1d">italic_k</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S3.T1.1.1.5">Accuracy</td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S3.T1.1.1.6">ROUGE-1</td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S3.T1.1.1.7">ROUGE-L</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T1.1.2.1" rowspan="6"><span class="ltx_text" id="S3.T1.1.2.1.1">Baseline</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T1.1.2.2">64</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T1.1.2.3">10</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T1.1.2.4">32</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T1.1.2.5">0.43</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T1.1.2.6">0.216</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T1.1.2.7">0.174</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.3">
<td class="ltx_td ltx_align_left" id="S3.T1.1.3.1">128</td>
<td class="ltx_td ltx_align_left" id="S3.T1.1.3.2">25</td>
<td class="ltx_td ltx_align_left" id="S3.T1.1.3.3">16</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.3.4">0.46</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.3.5">0.209</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.3.6">0.167</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.4">
<td class="ltx_td ltx_align_left" id="S3.T1.1.4.1">256</td>
<td class="ltx_td ltx_align_left" id="S3.T1.1.4.2">50</td>
<td class="ltx_td ltx_align_left" id="S3.T1.1.4.3">8</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.4.4">0.48</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.4.5">0.249</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.4.6">0.206</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.5">
<td class="ltx_td ltx_align_left" id="S3.T1.1.5.1">512</td>
<td class="ltx_td ltx_align_left" id="S3.T1.1.5.2">100</td>
<td class="ltx_td ltx_align_left" id="S3.T1.1.5.3">4</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.5.4">0.48</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.5.5">0.223</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.5.6">0.189</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.6">
<td class="ltx_td ltx_align_left" id="S3.T1.1.6.1">1024</td>
<td class="ltx_td ltx_align_left" id="S3.T1.1.6.2">200</td>
<td class="ltx_td ltx_align_left" id="S3.T1.1.6.3">2</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.6.4">0.39</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.6.5">0.212</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.6.6">0.167</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.7">
<td class="ltx_td ltx_align_left" id="S3.T1.1.7.1">2048</td>
<td class="ltx_td ltx_align_left" id="S3.T1.1.7.2">400</td>
<td class="ltx_td ltx_align_left" id="S3.T1.1.7.3">1</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.7.4">0.35</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.7.5">0.191</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.7.6">0.152</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.8">
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T1.1.8.1" rowspan="6"><span class="ltx_text" id="S3.T1.1.8.1.1">RAIDD-S</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T1.1.8.2">64</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T1.1.8.3">10</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T1.1.8.4">32</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T1.1.8.5">0.48</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T1.1.8.6">0.214</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T1.1.8.7">0.171</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.9">
<td class="ltx_td ltx_align_left" id="S3.T1.1.9.1">128</td>
<td class="ltx_td ltx_align_left" id="S3.T1.1.9.2">25</td>
<td class="ltx_td ltx_align_left" id="S3.T1.1.9.3">16</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.9.4">0.41</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.9.5">0.204</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.9.6">0.167</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.10">
<td class="ltx_td ltx_align_left" id="S3.T1.1.10.1">256</td>
<td class="ltx_td ltx_align_left" id="S3.T1.1.10.2">50</td>
<td class="ltx_td ltx_align_left" id="S3.T1.1.10.3">8</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.10.4"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T1.1.10.4.1">0.49</span></td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.10.5">0.230</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.10.6">0.183</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.11">
<td class="ltx_td ltx_align_left" id="S3.T1.1.11.1">512</td>
<td class="ltx_td ltx_align_left" id="S3.T1.1.11.2">100</td>
<td class="ltx_td ltx_align_left" id="S3.T1.1.11.3">4</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.11.4">0.43</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.11.5">0.224</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.11.6">0.178</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.12">
<td class="ltx_td ltx_align_left" id="S3.T1.1.12.1">1024</td>
<td class="ltx_td ltx_align_left" id="S3.T1.1.12.2">200</td>
<td class="ltx_td ltx_align_left" id="S3.T1.1.12.3">2</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.12.4">0.31</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.12.5">0.205</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.12.6">0.178</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.13">
<td class="ltx_td ltx_align_left" id="S3.T1.1.13.1">2048</td>
<td class="ltx_td ltx_align_left" id="S3.T1.1.13.2">400</td>
<td class="ltx_td ltx_align_left" id="S3.T1.1.13.3">1</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.13.4">0.31</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.13.5">0.201</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.13.6">0.163</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.14">
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T1.1.14.1" rowspan="6"><span class="ltx_text" id="S3.T1.1.14.1.1">RAIDD-Q</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T1.1.14.2">64</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T1.1.14.3">10</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T1.1.14.4">32</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T1.1.14.5">0.46</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T1.1.14.6">0.217</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T1.1.14.7">0.173</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.15">
<td class="ltx_td ltx_align_left" id="S3.T1.1.15.1">128</td>
<td class="ltx_td ltx_align_left" id="S3.T1.1.15.2">25</td>
<td class="ltx_td ltx_align_left" id="S3.T1.1.15.3">16</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.15.4">0.46</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.15.5">0.222</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.15.6">0.180</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.16">
<td class="ltx_td ltx_align_left" id="S3.T1.1.16.1">256</td>
<td class="ltx_td ltx_align_left" id="S3.T1.1.16.2">50</td>
<td class="ltx_td ltx_align_left" id="S3.T1.1.16.3">8</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.16.4">0.44</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.16.5"><span class="ltx_text ltx_font_bold" id="S3.T1.1.16.5.1">0.269</span></td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.16.6"><span class="ltx_text ltx_font_bold" id="S3.T1.1.16.6.1">0.208</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.17">
<td class="ltx_td ltx_align_left" id="S3.T1.1.17.1">512</td>
<td class="ltx_td ltx_align_left" id="S3.T1.1.17.2">100</td>
<td class="ltx_td ltx_align_left" id="S3.T1.1.17.3">4</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.17.4">0.46</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.17.5">0.218</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.17.6">0.180</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.18">
<td class="ltx_td ltx_align_left" id="S3.T1.1.18.1">1024</td>
<td class="ltx_td ltx_align_left" id="S3.T1.1.18.2">200</td>
<td class="ltx_td ltx_align_left" id="S3.T1.1.18.3">2</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.18.4">0.44</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.18.5">0.201</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.18.6">0.167</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.19">
<td class="ltx_td ltx_align_left" id="S3.T1.1.19.1">2048</td>
<td class="ltx_td ltx_align_left" id="S3.T1.1.19.2">400</td>
<td class="ltx_td ltx_align_left" id="S3.T1.1.19.3">1</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.19.4">0.39</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.19.5">0.203</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.19.6">0.164</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.20">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S3.T1.1.20.1" rowspan="6"><span class="ltx_text" id="S3.T1.1.20.1.1">RAIDD-U</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T1.1.20.2">64</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T1.1.20.3">10</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T1.1.20.4">32</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T1.1.20.5">0.47</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T1.1.20.6">0.220</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T1.1.20.7">0.181</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.21">
<td class="ltx_td ltx_align_left" id="S3.T1.1.21.1">128</td>
<td class="ltx_td ltx_align_left" id="S3.T1.1.21.2">25</td>
<td class="ltx_td ltx_align_left" id="S3.T1.1.21.3">16</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.21.4">0.46</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.21.5">0.214</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.21.6">0.172</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.22">
<td class="ltx_td ltx_align_left" id="S3.T1.1.22.1">256</td>
<td class="ltx_td ltx_align_left" id="S3.T1.1.22.2">50</td>
<td class="ltx_td ltx_align_left" id="S3.T1.1.22.3">8</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.22.4"><span class="ltx_text ltx_font_bold" id="S3.T1.1.22.4.1">0.52</span></td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.22.5"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T1.1.22.5.1">0.254</span></td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.22.6"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T1.1.22.6.1">0.207</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.23">
<td class="ltx_td ltx_align_left" id="S3.T1.1.23.1">512</td>
<td class="ltx_td ltx_align_left" id="S3.T1.1.23.2">100</td>
<td class="ltx_td ltx_align_left" id="S3.T1.1.23.3">4</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.23.4">0.45</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.23.5">0.225</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.23.6">0.182</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.24">
<td class="ltx_td ltx_align_left" id="S3.T1.1.24.1">1024</td>
<td class="ltx_td ltx_align_left" id="S3.T1.1.24.2">200</td>
<td class="ltx_td ltx_align_left" id="S3.T1.1.24.3">2</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.24.4">0.46</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.24.5">0.209</td>
<td class="ltx_td ltx_align_right" id="S3.T1.1.24.6">0.171</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.25">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S3.T1.1.25.1">2048</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S3.T1.1.25.2">400</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S3.T1.1.25.3">1</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S3.T1.1.25.4">0.36</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S3.T1.1.25.5">0.203</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S3.T1.1.25.6">0.163</td>
</tr>
</table>
</figure>
<figure class="ltx_table" id="S3.T2">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Performance comparison on test set. Having tried different configurations on the validation set (Table <a class="ltx_ref" href="https://arxiv.org/html/2410.03754v1#S3.T1" title="Table 1 ‣ 3.2 Results ‣ 3 Experiments ‣ Enhancing Retrieval in QA Systems with Derived Feature Association"><span class="ltx_text ltx_ref_tag">1</span></a>), we settled on a chunk size of 256, overlap of 50, and <math alttext="k" class="ltx_Math" display="inline" id="S3.T2.2.m1.1"><semantics id="S3.T2.2.m1.1b"><mi id="S3.T2.2.m1.1.1" xref="S3.T2.2.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.T2.2.m1.1c"><ci id="S3.T2.2.m1.1.1.cmml" xref="S3.T2.2.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.2.m1.1d">k</annotation><annotation encoding="application/x-llamapun" id="S3.T2.2.m1.1e">italic_k</annotation></semantics></math> of 8 for the test set.</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S3.T2.3">
<tr class="ltx_tr" id="S3.T2.3.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S3.T2.3.1.1">Method</td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S3.T2.3.1.2">Accuracy</td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S3.T2.3.1.3">ROUGE-1</td>
<td class="ltx_td ltx_nopad_r ltx_align_right ltx_border_tt" id="S3.T2.3.1.4">ROUGE-L</td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T2.3.2.1">Baseline</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T2.3.2.2">0.48</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T2.3.2.3">0.19291</td>
<td class="ltx_td ltx_nopad_r ltx_align_right ltx_border_t" id="S3.T2.3.2.4">0.16160</td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.3">
<td class="ltx_td ltx_align_left" id="S3.T2.3.3.1">RAIDD-S</td>
<td class="ltx_td ltx_align_right" id="S3.T2.3.3.2"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T2.3.3.2.1">0.50</span></td>
<td class="ltx_td ltx_align_right" id="S3.T2.3.3.3"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T2.3.3.3.1">0.20814</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_right" id="S3.T2.3.3.4"><span class="ltx_text ltx_framed ltx_framed_underline" id="S3.T2.3.3.4.1">0.17116</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.4">
<td class="ltx_td ltx_align_left" id="S3.T2.3.4.1">RAIDD-S+</td>
<td class="ltx_td ltx_align_right" id="S3.T2.3.4.2">0.49</td>
<td class="ltx_td ltx_align_right" id="S3.T2.3.4.3">0.20561</td>
<td class="ltx_td ltx_nopad_r ltx_align_right" id="S3.T2.3.4.4">0.16612</td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.5">
<td class="ltx_td ltx_align_left" id="S3.T2.3.5.1">RAIDD-Q</td>
<td class="ltx_td ltx_align_right" id="S3.T2.3.5.2"><span class="ltx_text ltx_font_bold" id="S3.T2.3.5.2.1">0.52</span></td>
<td class="ltx_td ltx_align_right" id="S3.T2.3.5.3">0.19178</td>
<td class="ltx_td ltx_nopad_r ltx_align_right" id="S3.T2.3.5.4">0.16424</td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.6">
<td class="ltx_td ltx_align_left" id="S3.T2.3.6.1">RAIDD-Q+</td>
<td class="ltx_td ltx_align_right" id="S3.T2.3.6.2">0.46</td>
<td class="ltx_td ltx_align_right" id="S3.T2.3.6.3"><span class="ltx_text ltx_font_bold" id="S3.T2.3.6.3.1">0.22677</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_right" id="S3.T2.3.6.4"><span class="ltx_text ltx_font_bold" id="S3.T2.3.6.4.1">0.18130</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.7">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S3.T2.3.7.1">RAIDD-U</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S3.T2.3.7.2">0.48</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S3.T2.3.7.3">0.19130</td>
<td class="ltx_td ltx_nopad_r ltx_align_right ltx_border_bb" id="S3.T2.3.7.4">0.15976</td>
</tr>
</table>
</figure>
<figure class="ltx_table" id="S3.T3">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span>Per-Task performance comparison on the test set. CP-CCR (Correct Prediction - Correct Chunk Retrieved) and IP-CCR (Incorrect Prediction - Correct Chunk Retrieved) measures whether the retrieved chunks for both correct and incorrect predictions match the ground truth context required for answering the question. This helps to measure the performance of the methods in enhancing context retrieval. <span class="ltx_text ltx_font_bold" id="S3.T3.2.1">Bold</span> denotes better than baseline accuracy.</figcaption>
<table class="ltx_tabular ltx_align_middle" id="S3.T3.3">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T3.3.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S3.T3.3.1.1.1">
<span class="ltx_text" id="S3.T3.3.1.1.1.1"></span> <span class="ltx_text" id="S3.T3.3.1.1.1.2">
<span class="ltx_tabular ltx_align_middle" id="S3.T3.3.1.1.1.2.1">
<span class="ltx_tr" id="S3.T3.3.1.1.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T3.3.1.1.1.2.1.1.1"><span class="ltx_text" id="S3.T3.3.1.1.1.2.1.1.1.1" style="font-size:80%;">Method</span></span></span>
</span></span><span class="ltx_text" id="S3.T3.3.1.1.1.3"></span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S3.T3.3.1.1.2">
<span class="ltx_text" id="S3.T3.3.1.1.2.1"></span> <span class="ltx_text" id="S3.T3.3.1.1.2.2">
<span class="ltx_tabular ltx_align_middle" id="S3.T3.3.1.1.2.2.1">
<span class="ltx_tr" id="S3.T3.3.1.1.2.2.1.1">
<span class="ltx_td ltx_align_center" id="S3.T3.3.1.1.2.2.1.1.1"><span class="ltx_text" id="S3.T3.3.1.1.2.2.1.1.1.1" style="font-size:80%;">Metric</span></span></span>
</span></span><span class="ltx_text" id="S3.T3.3.1.1.2.3"></span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S3.T3.3.1.1.3">
<span class="ltx_text" id="S3.T3.3.1.1.3.1"></span> <span class="ltx_text" id="S3.T3.3.1.1.3.2">
<span class="ltx_tabular ltx_align_middle" id="S3.T3.3.1.1.3.2.1">
<span class="ltx_tr" id="S3.T3.3.1.1.3.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T3.3.1.1.3.2.1.1.1"><span class="ltx_text" id="S3.T3.3.1.1.3.2.1.1.1.1" style="font-size:80%;">Timeline</span></span></span>
<span class="ltx_tr" id="S3.T3.3.1.1.3.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T3.3.1.1.3.2.1.2.1"><span class="ltx_text" id="S3.T3.3.1.1.3.2.1.2.1.1" style="font-size:80%;">Reorder</span></span></span>
</span></span><span class="ltx_text" id="S3.T3.3.1.1.3.3"></span>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S3.T3.3.1.1.4">
<span class="ltx_text" id="S3.T3.3.1.1.4.1"></span> <span class="ltx_text" id="S3.T3.3.1.1.4.2">
<span class="ltx_tabular ltx_align_middle" id="S3.T3.3.1.1.4.2.1">
<span class="ltx_tr" id="S3.T3.3.1.1.4.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T3.3.1.1.4.2.1.1.1"><span class="ltx_text" id="S3.T3.3.1.1.4.2.1.1.1.1" style="font-size:80%;">Multiple</span></span></span>
<span class="ltx_tr" id="S3.T3.3.1.1.4.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T3.3.1.1.4.2.1.2.1"><span class="ltx_text" id="S3.T3.3.1.1.4.2.1.2.1.1" style="font-size:80%;">Information</span></span></span>
<span class="ltx_tr" id="S3.T3.3.1.1.4.2.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T3.3.1.1.4.2.1.3.1"><span class="ltx_text" id="S3.T3.3.1.1.4.2.1.3.1.1" style="font-size:80%;">Retrieval</span></span></span>
</span></span><span class="ltx_text" id="S3.T3.3.1.1.4.3"></span>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S3.T3.3.1.1.5">
<span class="ltx_text" id="S3.T3.3.1.1.5.1"></span> <span class="ltx_text" id="S3.T3.3.1.1.5.2">
<span class="ltx_tabular ltx_align_middle" id="S3.T3.3.1.1.5.2.1">
<span class="ltx_tr" id="S3.T3.3.1.1.5.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T3.3.1.1.5.2.1.1.1"><span class="ltx_text" id="S3.T3.3.1.1.5.2.1.1.1.1" style="font-size:80%;">Comprehension</span></span></span>
<span class="ltx_tr" id="S3.T3.3.1.1.5.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T3.3.1.1.5.2.1.2.1"><span class="ltx_text" id="S3.T3.3.1.1.5.2.1.2.1.1" style="font-size:80%;">and Reasoning</span></span></span>
</span></span><span class="ltx_text" id="S3.T3.3.1.1.5.3"></span>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S3.T3.3.1.1.6">
<span class="ltx_text" id="S3.T3.3.1.1.6.1"></span> <span class="ltx_text" id="S3.T3.3.1.1.6.2">
<span class="ltx_tabular ltx_align_middle" id="S3.T3.3.1.1.6.2.1">
<span class="ltx_tr" id="S3.T3.3.1.1.6.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T3.3.1.1.6.2.1.1.1"><span class="ltx_text" id="S3.T3.3.1.1.6.2.1.1.1.1" style="font-size:80%;">Computation</span></span></span>
</span></span><span class="ltx_text" id="S3.T3.3.1.1.6.3"></span>
</th>
<td class="ltx_td ltx_border_tt" id="S3.T3.3.1.1.7"></td>
</tr>
<tr class="ltx_tr" id="S3.T3.3.2.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T3.3.2.2.1">Baseline</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T3.3.2.2.2">Accuracy</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T3.3.2.2.3">30.77%</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T3.3.2.2.4">40.00%</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T3.3.2.2.5">57.14%</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T3.3.2.2.6">58.82%</td>
<td class="ltx_td ltx_border_t" id="S3.T3.3.2.2.7"></td>
</tr>
<tr class="ltx_tr" id="S3.T3.3.3.3">
<td class="ltx_td" id="S3.T3.3.3.3.1"></td>
<td class="ltx_td ltx_align_left" id="S3.T3.3.3.3.2">CP-CCR</td>
<td class="ltx_td ltx_align_right" id="S3.T3.3.3.3.3">75.00%</td>
<td class="ltx_td ltx_align_right" id="S3.T3.3.3.3.4">35.71%</td>
<td class="ltx_td ltx_align_right" id="S3.T3.3.3.3.5">60.00%</td>
<td class="ltx_td ltx_align_right" id="S3.T3.3.3.3.6">100.00%</td>
<td class="ltx_td" id="S3.T3.3.3.3.7"></td>
</tr>
<tr class="ltx_tr" id="S3.T3.3.4.4">
<td class="ltx_td" id="S3.T3.3.4.4.1"></td>
<td class="ltx_td ltx_align_left" id="S3.T3.3.4.4.2">IP-CCR</td>
<td class="ltx_td ltx_align_right" id="S3.T3.3.4.4.3">77.78%</td>
<td class="ltx_td ltx_align_right" id="S3.T3.3.4.4.4">42.86%</td>
<td class="ltx_td ltx_align_right" id="S3.T3.3.4.4.5">26.67%</td>
<td class="ltx_td ltx_align_right" id="S3.T3.3.4.4.6">42.86%</td>
<td class="ltx_td" id="S3.T3.3.4.4.7"></td>
</tr>
<tr class="ltx_tr" id="S3.T3.3.5.5">
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T3.3.5.5.1">RAIDD-Q</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T3.3.5.5.2">Accuracy</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T3.3.5.5.3">30.77%</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T3.3.5.5.4">31.43%</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T3.3.5.5.5"><span class="ltx_text ltx_font_bold" id="S3.T3.3.5.5.5.1">60.00%</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T3.3.5.5.6">47.06%</td>
<td class="ltx_td ltx_border_t" id="S3.T3.3.5.5.7"></td>
</tr>
<tr class="ltx_tr" id="S3.T3.3.6.6">
<td class="ltx_td" id="S3.T3.3.6.6.1"></td>
<td class="ltx_td ltx_align_left" id="S3.T3.3.6.6.2">CP-CCR</td>
<td class="ltx_td ltx_align_right" id="S3.T3.3.6.6.3">75.00%</td>
<td class="ltx_td ltx_align_right" id="S3.T3.3.6.6.4">18.18%</td>
<td class="ltx_td ltx_align_right" id="S3.T3.3.6.6.5">57.14%</td>
<td class="ltx_td ltx_align_right" id="S3.T3.3.6.6.6">87.50%</td>
<td class="ltx_td" id="S3.T3.3.6.6.7"></td>
</tr>
<tr class="ltx_tr" id="S3.T3.3.7.7">
<td class="ltx_td" id="S3.T3.3.7.7.1"></td>
<td class="ltx_td ltx_align_left" id="S3.T3.3.7.7.2">IP-CCR</td>
<td class="ltx_td ltx_align_right" id="S3.T3.3.7.7.3">33.33%</td>
<td class="ltx_td ltx_align_right" id="S3.T3.3.7.7.4">41.67%</td>
<td class="ltx_td ltx_align_right" id="S3.T3.3.7.7.5">14.29%</td>
<td class="ltx_td ltx_align_right" id="S3.T3.3.7.7.6">33.33%</td>
<td class="ltx_td" id="S3.T3.3.7.7.7"></td>
</tr>
<tr class="ltx_tr" id="S3.T3.3.8.8">
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T3.3.8.8.1">RAIDD-Q+</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T3.3.8.8.2">Accuracy</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T3.3.8.8.3"><span class="ltx_text ltx_font_bold" id="S3.T3.3.8.8.3.1">38.46%</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T3.3.8.8.4">37.14%</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T3.3.8.8.5">51.43%</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T3.3.8.8.6">52.94%</td>
<td class="ltx_td ltx_border_t" id="S3.T3.3.8.8.7"></td>
</tr>
<tr class="ltx_tr" id="S3.T3.3.9.9">
<td class="ltx_td" id="S3.T3.3.9.9.1"></td>
<td class="ltx_td ltx_align_left" id="S3.T3.3.9.9.2">CP-CCR</td>
<td class="ltx_td ltx_align_right" id="S3.T3.3.9.9.3">80.00%</td>
<td class="ltx_td ltx_align_right" id="S3.T3.3.9.9.4">46.15%</td>
<td class="ltx_td ltx_align_right" id="S3.T3.3.9.9.5">61.11%</td>
<td class="ltx_td ltx_align_right" id="S3.T3.3.9.9.6">88.89%</td>
<td class="ltx_td" id="S3.T3.3.9.9.7"></td>
</tr>
<tr class="ltx_tr" id="S3.T3.3.10.10">
<td class="ltx_td" id="S3.T3.3.10.10.1"></td>
<td class="ltx_td ltx_align_left" id="S3.T3.3.10.10.2">IP-CCR</td>
<td class="ltx_td ltx_align_right" id="S3.T3.3.10.10.3">75.00%</td>
<td class="ltx_td ltx_align_right" id="S3.T3.3.10.10.4">31.82%</td>
<td class="ltx_td ltx_align_right" id="S3.T3.3.10.10.5">17.65%</td>
<td class="ltx_td ltx_align_right" id="S3.T3.3.10.10.6">50.00%</td>
<td class="ltx_td" id="S3.T3.3.10.10.7"></td>
</tr>
<tr class="ltx_tr" id="S3.T3.3.11.11">
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T3.3.11.11.1">RAIDD-S ICL</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T3.3.11.11.2">Accuracy</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T3.3.11.11.3">23.08%</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T3.3.11.11.4">11.43%</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T3.3.11.11.5">22.86%</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T3.3.11.11.6">5.88%</td>
<td class="ltx_td ltx_border_t" id="S3.T3.3.11.11.7"></td>
</tr>
<tr class="ltx_tr" id="S3.T3.3.12.12">
<td class="ltx_td" id="S3.T3.3.12.12.1"></td>
<td class="ltx_td ltx_align_left" id="S3.T3.3.12.12.2">CP-CCR</td>
<td class="ltx_td ltx_align_right" id="S3.T3.3.12.12.3">33.33%</td>
<td class="ltx_td ltx_align_right" id="S3.T3.3.12.12.4">25.00%</td>
<td class="ltx_td ltx_align_right" id="S3.T3.3.12.12.5">75.00%</td>
<td class="ltx_td ltx_align_right" id="S3.T3.3.12.12.6">100.00%</td>
<td class="ltx_td" id="S3.T3.3.12.12.7"></td>
</tr>
<tr class="ltx_tr" id="S3.T3.3.13.13">
<td class="ltx_td" id="S3.T3.3.13.13.1"></td>
<td class="ltx_td ltx_align_left" id="S3.T3.3.13.13.2">IP-CCR</td>
<td class="ltx_td ltx_align_right" id="S3.T3.3.13.13.3">70.00%</td>
<td class="ltx_td ltx_align_right" id="S3.T3.3.13.13.4">35.48%</td>
<td class="ltx_td ltx_align_right" id="S3.T3.3.13.13.5">33.33%</td>
<td class="ltx_td ltx_align_right" id="S3.T3.3.13.13.6">75.00%</td>
<td class="ltx_td" id="S3.T3.3.13.13.7"></td>
</tr>
<tr class="ltx_tr" id="S3.T3.3.14.14">
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T3.3.14.14.1">RAIDD-S</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T3.3.14.14.2">Accuracy</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T3.3.14.14.3">23.08%</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T3.3.14.14.4"><span class="ltx_text ltx_font_bold" id="S3.T3.3.14.14.4.1">45.71%</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T3.3.14.14.5"><span class="ltx_text ltx_font_bold" id="S3.T3.3.14.14.5.1">62.86%</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T3.3.14.14.6">47.06%</td>
<td class="ltx_td ltx_border_t" id="S3.T3.3.14.14.7"></td>
</tr>
<tr class="ltx_tr" id="S3.T3.3.15.15">
<td class="ltx_td" id="S3.T3.3.15.15.1"></td>
<td class="ltx_td ltx_align_left" id="S3.T3.3.15.15.2">CP-CCR</td>
<td class="ltx_td ltx_align_right" id="S3.T3.3.15.15.3">66.67%</td>
<td class="ltx_td ltx_align_right" id="S3.T3.3.15.15.4">43.75%</td>
<td class="ltx_td ltx_align_right" id="S3.T3.3.15.15.5">54.55%</td>
<td class="ltx_td ltx_align_right" id="S3.T3.3.15.15.6">100.00%</td>
<td class="ltx_td" id="S3.T3.3.15.15.7"></td>
</tr>
<tr class="ltx_tr" id="S3.T3.3.16.16">
<td class="ltx_td" id="S3.T3.3.16.16.1"></td>
<td class="ltx_td ltx_align_left" id="S3.T3.3.16.16.2">IP-CCR</td>
<td class="ltx_td ltx_align_right" id="S3.T3.3.16.16.3">60.00%</td>
<td class="ltx_td ltx_align_right" id="S3.T3.3.16.16.4">26.32%</td>
<td class="ltx_td ltx_align_right" id="S3.T3.3.16.16.5">23.08%</td>
<td class="ltx_td ltx_align_right" id="S3.T3.3.16.16.6">55.56%</td>
<td class="ltx_td" id="S3.T3.3.16.16.7"></td>
</tr>
<tr class="ltx_tr" id="S3.T3.3.17.17">
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T3.3.17.17.1">RAIDD-S+</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T3.3.17.17.2">Accuracy</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T3.3.17.17.3"><span class="ltx_text ltx_font_bold" id="S3.T3.3.17.17.3.1">38.46%</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T3.3.17.17.4"><span class="ltx_text ltx_font_bold" id="S3.T3.3.17.17.4.1">45.71%</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T3.3.17.17.5"><span class="ltx_text ltx_font_bold" id="S3.T3.3.17.17.5.1">62.86%</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T3.3.17.17.6">58.82%</td>
<td class="ltx_td ltx_border_t" id="S3.T3.3.17.17.7"></td>
</tr>
<tr class="ltx_tr" id="S3.T3.3.18.18">
<td class="ltx_td" id="S3.T3.3.18.18.1"></td>
<td class="ltx_td ltx_align_left" id="S3.T3.3.18.18.2">CP-CCR</td>
<td class="ltx_td ltx_align_right" id="S3.T3.3.18.18.3">80.00%</td>
<td class="ltx_td ltx_align_right" id="S3.T3.3.18.18.4">43.75%</td>
<td class="ltx_td ltx_align_right" id="S3.T3.3.18.18.5">63.64%</td>
<td class="ltx_td ltx_align_right" id="S3.T3.3.18.18.6">100.00%</td>
<td class="ltx_td" id="S3.T3.3.18.18.7"></td>
</tr>
<tr class="ltx_tr" id="S3.T3.3.19.19">
<td class="ltx_td" id="S3.T3.3.19.19.1"></td>
<td class="ltx_td ltx_align_left" id="S3.T3.3.19.19.2">IP-CCR</td>
<td class="ltx_td ltx_align_right" id="S3.T3.3.19.19.3">62.50%</td>
<td class="ltx_td ltx_align_right" id="S3.T3.3.19.19.4">36.84%</td>
<td class="ltx_td ltx_align_right" id="S3.T3.3.19.19.5">23.08%</td>
<td class="ltx_td ltx_align_right" id="S3.T3.3.19.19.6">42.86%</td>
<td class="ltx_td" id="S3.T3.3.19.19.7"></td>
</tr>
<tr class="ltx_tr" id="S3.T3.3.20.20">
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T3.3.20.20.1">RAIDD-U</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T3.3.20.20.2">Accuracy</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T3.3.20.20.3"><span class="ltx_text ltx_font_bold" id="S3.T3.3.20.20.3.1">46.15%</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T3.3.20.20.4"><span class="ltx_text ltx_font_bold" id="S3.T3.3.20.20.4.1">42.86%</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T3.3.20.20.5"><span class="ltx_text ltx_font_bold" id="S3.T3.3.20.20.5.1">62.86%</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T3.3.20.20.6">52.94%</td>
<td class="ltx_td ltx_border_t" id="S3.T3.3.20.20.7"></td>
</tr>
<tr class="ltx_tr" id="S3.T3.3.21.21">
<td class="ltx_td" id="S3.T3.3.21.21.1"></td>
<td class="ltx_td ltx_align_left" id="S3.T3.3.21.21.2">CP-CCR</td>
<td class="ltx_td ltx_align_right" id="S3.T3.3.21.21.3">83.33%</td>
<td class="ltx_td ltx_align_right" id="S3.T3.3.21.21.4">40.00%</td>
<td class="ltx_td ltx_align_right" id="S3.T3.3.21.21.5">50.00%</td>
<td class="ltx_td ltx_align_right" id="S3.T3.3.21.21.6">88.89%</td>
<td class="ltx_td" id="S3.T3.3.21.21.7"></td>
</tr>
<tr class="ltx_tr" id="S3.T3.3.22.22">
<td class="ltx_td ltx_border_bb" id="S3.T3.3.22.22.1"></td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S3.T3.3.22.22.2">IP-CCR</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S3.T3.3.22.22.3">57.14%</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S3.T3.3.22.22.4">35.00%</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S3.T3.3.22.22.5">23.08%</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S3.T3.3.22.22.6">50.00%</td>
<td class="ltx_td ltx_border_bb" id="S3.T3.3.22.22.7"></td>
</tr>
</tbody>
</table>
<br class="ltx_break"/>
</figure>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Per-Task Analysis</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2410.03754v1#S3.T3" title="Table 3 ‣ 3.2 Results ‣ 3 Experiments ‣ Enhancing Retrieval in QA Systems with Derived Feature Association"><span class="ltx_text ltx_ref_tag">3</span></a> highlights the performance of various augmentation methods applied to RAG system across multiple tasks: timeline reorder, multiple information retrieval, comprehension and reasoning, and computation (see appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.03754v1#A1" title="Appendix A Question Examples ‣ Enhancing Retrieval in QA Systems with Derived Feature Association"><span class="ltx_text ltx_ref_tag">A</span></a> for examples). These results give a clearer understanding of how each augmentation strategy impacts performance in specific domains. Here’s a detailed breakdown:</p>
</div>
<section class="ltx_subsubsection" id="S3.SS3.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.1 </span>Timeline Reorder</h4>
<div class="ltx_para" id="S3.SS3.SSS1.p1">
<p class="ltx_p" id="S3.SS3.SSS1.p1.1">Our baseline method demonstrated a relatively modest performance, achieving an accuracy of 30.77%, which suggests a limited capability in the timeline reordering question type. The RAIDD-U method, however, showed a significant improvement, with 46.15% accuracy, a 15% increase compared to the baseline. This enhancement is also reflected in the correct chunk match rate, indicating that our method is effective in retrieving more relevant context to accurately answer the questions.</p>
</div>
<div class="ltx_para" id="S3.SS3.SSS1.p2">
<p class="ltx_p" id="S3.SS3.SSS1.p2.1">Additionally, the RAIDD-Q+ and RAIDD-S+ methods have outperformed the baseline in terms of both accuracy and context retrieval, affirming their efficacy in handling timeline reorder questions. It is noteworthy that the RAIDD-S method exhibited a marked decrease in performance. We hypothesize that this decline is due to the nature of the timeline reorder task, which requires precise and factual information from the text to correctly analyze and reorder events. The summarization process inherent to the RAIDD-S method potentially omits crucial details, leading to a loss of essential information and consequently, lower performance on this task type.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS3.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.2 </span>Multiple Information Retrieval</h4>
<div class="ltx_para" id="S3.SS3.SSS2.p1">
<p class="ltx_p" id="S3.SS3.SSS2.p1.1">The RAIDD-S+ method demonstrates a notable improvement in performance compared to the baseline. Similarly, the RAIDD-S and RAIDD-U methods also contribute to enhanced performance, indicating that these approaches effectively enhance the retrieval of relevant context necessary for answering the questions.</p>
</div>
<div class="ltx_para" id="S3.SS3.SSS2.p2">
<p class="ltx_p" id="S3.SS3.SSS2.p2.1">However, it is observed that the question-based feature generation methods lead to a decline in performance. This decline can be attributed to the specific requirements of this question type, which likely necessitates long-range context dependencies that span multiple text chunks. The questions generated from each individual chunk do not adequately reflect the types of questions typically associated with this question type. As a result, these methods fail to retrieve the relevant context needed to accurately answer the questions.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS3.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.3 </span>Comprehension and Reasoning</h4>
<div class="ltx_para" id="S3.SS3.SSS3.p1">
<p class="ltx_p" id="S3.SS3.SSS3.p1.1">We observe that all methods, with the exception of RAIDD-S ICL, show enhanced performance compared to the baseline. Notably, despite its lower accuracy, the RAIDD-S ICL method demonstrates superior capability in retrieving context pertinent to the questions posed. There is an evident 15% increase in the extraction of relevant chunks. This suggests that providing additional context in the prompt facilitates more effective retrieval of pertinent information. However, we hypothesize that the utilization of significantly larger prompts might lead to a dilution of information. Consequently, the LLM struggles to concentrate on the retrieved context to accurately answer the question, thereby impairing performance.Despite this, we observe a consistent performance gain using the RAIDD methodology for this particular question type.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS3.SSS4">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.4 </span>Computation</h4>
<div class="ltx_para" id="S3.SS3.SSS4.p1">
<p class="ltx_p" id="S3.SS3.SSS4.p1.1">In this evaluation, it is observed that all the methods under consideration perform suboptimally in comparison to the baseline. Intriguingly, despite the baseline’s capacity to retrieve relevant chunks with 100% accuracy, it achieves only about 58% overall accuracy. This outcome suggests that for this specific question type, the efficacy of the LLM in generating outputs is paramount. The LLM’s ability to intricately process details and synthesize responses based on the provided context is crucial.</p>
</div>
<div class="ltx_para" id="S3.SS3.SSS4.p2">
<p class="ltx_p" id="S3.SS3.SSS4.p2.1">Further analysis indicates that enhancing the vector database to improve context retrieval does not significantly impact the performance for this type of question. The fundamental challenge appears to be the LLM’s capability to effectively utilize the context to compute and generate precise answers. This underscores the necessity of focusing on improving the LLM’s generative abilities rather than merely augmenting the context retrieval mechanisms.</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Conclusion</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">The results clearly demonstrate the significant impact that augmentation strategies—such as question-focused approaches, raw text integration, and summarization techniques—have on enhancing the performance of RAG systems across diverse complex tasks. The effectiveness of these strategies varies with the nature of the task, highlighting the importance for a tailored system design that incorporates specific augmentation methods suitable to the task requirements. For example, tasks requiring deep comprehension and information synthesis are better served by summarization techniques that distill and captures key details, while those requiring precise fact retrieval benefit from improved raw text integration. This adaptability in strategy selection is crucial for optimizing RAG system performance across varying task demands.</p>
</div>
<div class="ltx_para" id="S4.p2">
<p class="ltx_p" id="S4.p2.1">Although our method successfully retrieves enhanced contextual information to address queries, the primary obstacle in generating accurate responses lies in the capabilities of the LLM employed to produce answers. Thus, even with improved context retrieval, there remains a critical need for a more advanced LLM capable of utilizing this context to generate responses that are conceptually and semantically correct.</p>
</div>
<div class="ltx_para" id="S4.p3">
<p class="ltx_p" id="S4.p3.1">RAIDD introduces a novel framework for RAG which retrieves more relevant context than vanilla RAG implementations while retaining the portability of dense retrieval. We show that across multiple QA tasks, RAIDD is able to improve retrieval and QA accuracy by up to 15%. Further research is necessary to tune the derived document generation process to retain all necessary information across domains. Additionally, we hope to develop additional types of derived documents, beyond summaries and questions, to optimize the distillation of information performed by RAIDD.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Tong Chen, Hongwei Wang, Sihao Chen, Wenhao Yu, Kaixin Ma, Xinran Zhao,
Hongming Zhang, and Dong Yu.

</span>
<span class="ltx_bibblock">Dense X Retrieval: What Retrieval Granularity Should We Use?

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib1.1.1">arXiv</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Luyu Gao, Xueguang Ma, Jimmy Lin, and Jamie Callan.

</span>
<span class="ltx_bibblock">Precise Zero-Shot Dense Retrieval without Relevance Labels.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Michael Glass, Gaetano Rossiello, Md Faisal Mahbub Chowdhury, Ankita Rajaram
Naik, Pengshan Cai, and Alfio Gliozzo.

</span>
<span class="ltx_bibblock">Re2G: Retrieve, Rerank, Generate.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Ryan Greene, Ted Sanders, Lilian Weng, and Arvind Neelakantan.

</span>
<span class="ltx_bibblock">New and improved embedding model, Dec 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Chase Harrison.

</span>
<span class="ltx_bibblock">Langchain – propositional-retrieval, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Rongjie Huang, Jiawei Huang, Dongchao Yang, Yi Ren, Luping Liu, Mingze Li,
Zhenhui Ye, Jinglin Liu, Xiang Yin, and Zhou Zhao.

</span>
<span class="ltx_bibblock">Make-An-Audio: Text-To-Audio Generation with Prompt-Enhanced
Diffusion Models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib6.1.1">arXiv</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Albert Q Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur Mensch, Blanche
Savary, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Emma Bou
Hanna, Florian Bressand, Gianna Lengyel, Guillaume Bour, Guillaume Lample,
Lélio Renard Lavaud, Lucile Saulnier, Marie-Anne Lachaux, Pierre Stock,
Sandeep Subramanian, Sophia Yang, Szymon Antoniak, Teven Le Scao, Théophile
Gervet, Thibaut Lavril, Thomas Wang, Timothée Lacroix, and William El Sayed.

</span>
<span class="ltx_bibblock">Mixtral of Experts.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib7.1.1">arXiv</span>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir
Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim
Rocktäschel, Sebastian Riedel, and Douwe Kiela.

</span>
<span class="ltx_bibblock">Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib8.1.1">arXiv</span>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Jiaqi Li, Mengmeng Wang, Zilong Zheng, and Muhan Zhang.

</span>
<span class="ltx_bibblock">Loogle: Can long-context language models understand long contexts?

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib9.1.1">arXiv preprint arXiv:2311.04939</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Chin-Yew Lin.

</span>
<span class="ltx_bibblock">ROUGE: A package for automatic evaluation of summaries.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib10.1.1">Text Summarization Branches Out</span>, pages 74–81, Barcelona,
Spain, July 2004. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Jerry Liu.

</span>
<span class="ltx_bibblock">LlamaIndex, 11 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
OpenAI, Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya,
Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman,
Shyamal Anadkat, Red Avila, Igor Babuschkin, Suchir Balaji, Valerie Balcom,
Paul Baltescu, Haiming Bao, Mohammad Bavarian, Jeff Belgum, Irwan Bello, Jake
Berdine, Gabriel Bernadett-Shapiro, Christopher Berner, Lenny Bogdonoff, Oleg
Boiko, Madelaine Boyd, Anna-Luisa Brakman, Greg Brockman, Tim Brooks, Miles
Brundage, Kevin Button, Trevor Cai, Rosie Campbell, Andrew Cann, Brittany
Carey, Chelsea Carlson, Rory Carmichael, Brooke Chan, Che Chang, Fotis
Chantzis, Derek Chen, Sully Chen, Ruby Chen, Jason Chen, Mark Chen, Ben
Chess, Chester Cho, Casey Chu, Hyung Won Chung, Dave Cummings, Jeremiah
Currier, Yunxing Dai, Cory Decareaux, Thomas Degry, Noah Deutsch, Damien
Deville, Arka Dhar, David Dohan, Steve Dowling, Sheila Dunning, Adrien
Ecoffet, Atty Eleti, Tyna Eloundou, David Farhi, Liam Fedus, Niko Felix,
Simón Posada Fishman, Juston Forte, Isabella Fulford, Leo Gao, Elie Georges,
Christian Gibson, Vik Goel, Tarun Gogineni, Gabriel Goh, Rapha Gontijo-Lopes,
Jonathan Gordon, Morgan Grafstein, Scott Gray, Ryan Greene, Joshua Gross,
Shixiang Shane Gu, Yufei Guo, Chris Hallacy, Jesse Han, Jeff Harris, Yuchen
He, Mike Heaton, Johannes Heidecke, Chris Hesse, Alan Hickey, Wade Hickey,
Peter Hoeschele, Brandon Houghton, Kenny Hsu, Shengli Hu, Xin Hu, Joost
Huizinga, Shantanu Jain, Shawn Jain, Joanne Jang, Angela Jiang, Roger Jiang,
Haozhun Jin, Denny Jin, Shino Jomoto, Billie Jonn, Heewoo Jun, Tomer Kaftan,
Łukasz Kaiser, Ali Kamali, Ingmar Kanitscheider, Nitish Shirish Keskar,
Tabarak Khan, Logan Kilpatrick, Jong Wook Kim, Christina Kim, Yongjik Kim,
Jan Hendrik Kirchner, Jamie Kiros, Matt Knight, Daniel Kokotajlo, Łukasz
Kondraciuk, Andrew Kondrich, Aris Konstantinidis, Kyle Kosic, Gretchen
Krueger, Vishal Kuo, Michael Lampe, Ikai Lan, Teddy Lee, Jan Leike, Jade
Leung, Daniel Levy, Chak Ming Li, Rachel Lim, Molly Lin, Stephanie Lin,
Mateusz Litwin, Theresa Lopez, Ryan Lowe, Patricia Lue, Anna Makanju, Kim
Malfacini, Sam Manning, Todor Markov, Yaniv Markovski, Bianca Martin, Katie
Mayer, Andrew Mayne, Bob McGrew, Scott Mayer McKinney, Christine McLeavey,
Paul McMillan, Jake McNeil, David Medina, Aalok Mehta, Jacob Menick, Luke
Metz, Andrey Mishchenko, Pamela Mishkin, Vinnie Monaco, Evan Morikawa, Daniel
Mossing, Tong Mu, Mira Murati, Oleg Murk, David Mély, Ashvin Nair, Reiichiro
Nakano, Rajeev Nayak, Arvind Neelakantan, Richard Ngo, Hyeonwoo Noh, Long
Ouyang, Cullen O’Keefe, Jakub Pachocki, Alex Paino, Joe Palermo, Ashley
Pantuliano, Giambattista Parascandolo, Joel Parish, Emy Parparita, Alex
Passos, Mikhail Pavlov, Andrew Peng, Adam Perelman, Filipe de Avila
Belbute Peres, Michael Petrov, Henrique Ponde de Oliveira Pinto, Michael,
Pokorny, Michelle Pokrass, Vitchyr H. Pong, Tolly Powell, Alethea Power,
Boris Power, Elizabeth Proehl, Raul Puri, Alec Radford, Jack Rae, Aditya
Ramesh, Cameron Raymond, Francis Real, Kendra Rimbach, Carl Ross, Bob
Rotsted, Henri Roussez, Nick Ryder, Mario Saltarelli, Ted Sanders, Shibani
Santurkar, Girish Sastry, Heather Schmidt, David Schnurr, John Schulman,
Daniel Selsam, Kyla Sheppard, Toki Sherbakov, Jessica Shieh, Sarah Shoker,
Pranav Shyam, Szymon Sidor, Eric Sigler, Maddie Simens, Jordan Sitkin,
Katarina Slama, Ian Sohl, Benjamin Sokolowsky, Yang Song, Natalie Staudacher,
Felipe Petroski Such, Natalie Summers, Ilya Sutskever, Jie Tang, Nikolas
Tezak, Madeleine B. Thompson, Phil Tillet, Amin Tootoonchian, Elizabeth
Tseng, Preston Tuggle, Nick Turley, Jerry Tworek, Juan Felipe Cerón Uribe,
Andrea Vallone, Arun Vijayvergiya, Chelsea Voss, Carroll Wainwright,
Justin Jay Wang, Alvin Wang, Ben Wang, Jonathan Ward, Jason Wei, CJ Weinmann,
Akila Welihinda, Peter Welinder, Jiayi Weng, Lilian Weng, Matt Wiethoff, Dave
Willner, Clemens Winter, Samuel Wolrich, Hannah Wong, Lauren Workman, Sherwin
Wu, Jeff Wu, Michael Wu, Kai Xiao, Tao Xu, Sarah Yoo, Kevin Yu, Qiming Yuan,
Wojciech Zaremba, Rowan Zellers, Chong Zhang, Marvin Zhang, Shengjia Zhao,
Tianhao Zheng, Juntang Zhuang, William Zhuk, and Barret Zoph.

</span>
<span class="ltx_bibblock">Gpt-4 technical report, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Parth Sarthi, Salman Abdullah, Aditi Tuli, Shubh Khanna, Anna Goldie, and
Christopher D. Manning.

</span>
<span class="ltx_bibblock">RAPTOR: Recursive Abstractive Processing for Tree-Organized
Retrieval.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Weijia Shi, Sewon Min, Michihiro Yasunaga, Minjoon Seo, Rich James, Mike Lewis,
Luke Zettlemoyer, and Wen-tau Yih.

</span>
<span class="ltx_bibblock">REPLUG: Retrieval-Augmented Black-Box Language Models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib14.1.1">arXiv</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Mistral AI Team.

</span>
<span class="ltx_bibblock">Au large | mistral ai | frontier ai in your hands, Feb 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Liang Wang, Nan Yang, and Furu Wei.

</span>
<span class="ltx_bibblock">Query2doc: Query Expansion with Large Language Models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib16.1.1">arXiv</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Penghao Zhao, Hailin Zhang, Qinhan Yu, Zhengren Wang, Yunteng Geng, Fangcheng
Fu, Ling Yang, Wentao Zhang, and Bin Cui.

</span>
<span class="ltx_bibblock">Retrieval-augmented generation for ai-generated content: A survey,
2024.

</span>
</li>
</ul>
</section>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Question Examples</h2>
<div class="ltx_para ltx_align_center" id="A1.p1">
<p class="ltx_p" id="A1.p1.1"><span class="ltx_text" id="A1.p1.1.1" style="background-color:#FAFAFF;">
<span class="ltx_tabular ltx_align_middle" id="A1.p1.1.1.1">
<span class="ltx_tr" id="A1.p1.1.1.1.1">
<span class="ltx_td ltx_align_left" id="A1.p1.1.1.1.1.1" style="padding-top:5pt;padding-bottom:5pt;"><span class="ltx_text ltx_font_bold" id="A1.p1.1.1.1.1.1.1">Timeline Reordering</span></span>
<span class="ltx_td ltx_align_top" id="A1.p1.1.1.1.1.2" style="padding-top:5pt;padding-bottom:5pt;"></span></span>
<span class="ltx_tr" id="A1.p1.1.1.1.2">
<span class="ltx_td ltx_align_left" id="A1.p1.1.1.1.2.1" style="padding-top:5pt;padding-bottom:5pt;"><span class="ltx_text ltx_font_bold" id="A1.p1.1.1.1.2.1.1">Question</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="A1.p1.1.1.1.2.2" style="padding-top:5pt;padding-bottom:5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.p1.1.1.1.2.2.1">
<span class="ltx_p" id="A1.p1.1.1.1.2.2.1.1" style="width:284.5pt;">Picardo dedicated much of his professional life to Paradores, please order these projects by open day: 1. Parador de Arcos de la Frontera, 2. Parador de Guadalupe, 3. Parador de Carmona</span>
</span></span></span>
<span class="ltx_tr" id="A1.p1.1.1.1.3">
<span class="ltx_td ltx_align_left" id="A1.p1.1.1.1.3.1" style="padding-top:5pt;padding-bottom:5pt;"><span class="ltx_text ltx_font_bold" id="A1.p1.1.1.1.3.1.1">Target Text</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="A1.p1.1.1.1.3.2" style="padding-top:5pt;padding-bottom:5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.p1.1.1.1.3.2.1">
<span class="ltx_p" id="A1.p1.1.1.1.3.2.1.1" style="width:284.5pt;">“Restoration at Guadalupe started in November 1963 and the hotel, with twenty double rooms, opened on 11 December 1965.”</span>
</span></span></span>
<span class="ltx_tr" id="A1.p1.1.1.1.4">
<span class="ltx_td" id="A1.p1.1.1.1.4.1" style="padding-top:5pt;padding-bottom:5pt;"></span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="A1.p1.1.1.1.4.2" style="padding-top:5pt;padding-bottom:5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.p1.1.1.1.4.2.1">
<span class="ltx_p" id="A1.p1.1.1.1.4.2.1.1" style="width:284.5pt;">“Parador de Arcos de la Frontera opened to guests on 7 November 1966.”</span>
</span></span></span>
<span class="ltx_tr" id="A1.p1.1.1.1.5">
<span class="ltx_td ltx_align_left" id="A1.p1.1.1.1.5.1" style="padding-top:5pt;padding-bottom:5pt;"><span class="ltx_text ltx_font_bold" id="A1.p1.1.1.1.5.1.1">Ground Truth</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="A1.p1.1.1.1.5.2" style="padding-top:5pt;padding-bottom:5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.p1.1.1.1.5.2.1">
<span class="ltx_p" id="A1.p1.1.1.1.5.2.1.1" style="width:284.5pt;">2,1,3</span>
</span></span></span>
<span class="ltx_tr" id="A1.p1.1.1.1.6">
<span class="ltx_td ltx_align_left" id="A1.p1.1.1.1.6.1" style="padding-top:5pt;padding-bottom:5pt;"><span class="ltx_ERROR undefined" id="A1.p1.1.1.1.6.1.1">\cdashline</span>1-2[1.5pt/3pt] 
<span class="ltx_text ltx_font_bold" id="A1.p1.1.1.1.6.1.2">Multiple Information Retrieval</span></span>
<span class="ltx_td ltx_align_top" id="A1.p1.1.1.1.6.2" style="padding-top:5pt;padding-bottom:5pt;"></span></span>
<span class="ltx_tr" id="A1.p1.1.1.1.7">
<span class="ltx_td ltx_align_left" id="A1.p1.1.1.1.7.1" style="padding-top:5pt;padding-bottom:5pt;"><span class="ltx_text ltx_font_bold" id="A1.p1.1.1.1.7.1.1">Question</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="A1.p1.1.1.1.7.2" style="padding-top:5pt;padding-bottom:5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.p1.1.1.1.7.2.1">
<span class="ltx_p" id="A1.p1.1.1.1.7.2.1.1" style="width:284.5pt;">How did Picardo build the Parador at the Castillo de Santa Catalina to get a good view for vistors?</span>
</span></span></span>
<span class="ltx_tr" id="A1.p1.1.1.1.8">
<span class="ltx_td ltx_align_left" id="A1.p1.1.1.1.8.1" style="padding-top:5pt;padding-bottom:5pt;"><span class="ltx_text ltx_font_bold" id="A1.p1.1.1.1.8.1.1">Target Text</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="A1.p1.1.1.1.8.2" style="padding-top:5pt;padding-bottom:5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.p1.1.1.1.8.2.1">
<span class="ltx_p" id="A1.p1.1.1.1.8.2.1.1" style="width:284.5pt;">“Using the elongated site at the top of the hill, Picardo planned a dining room, a lounge, service accommodation and guest rooms.”</span>
</span></span></span>
<span class="ltx_tr" id="A1.p1.1.1.1.9">
<span class="ltx_td" id="A1.p1.1.1.1.9.1" style="padding-top:5pt;padding-bottom:5pt;"></span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="A1.p1.1.1.1.9.2" style="padding-top:5pt;padding-bottom:5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.p1.1.1.1.9.2.1">
<span class="ltx_p" id="A1.p1.1.1.1.9.2.1.1" style="width:284.5pt;">“He styled his new building on the layout and dimensions …”</span>
</span></span></span>
<span class="ltx_tr" id="A1.p1.1.1.1.10">
<span class="ltx_td ltx_align_left" id="A1.p1.1.1.1.10.1" style="padding-top:5pt;padding-bottom:5pt;"><span class="ltx_text ltx_font_bold" id="A1.p1.1.1.1.10.1.1">Ground Truth</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="A1.p1.1.1.1.10.2" style="padding-top:5pt;padding-bottom:5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.p1.1.1.1.10.2.1">
<span class="ltx_p" id="A1.p1.1.1.1.10.2.1.1" style="width:284.5pt;">He used the elongated site at the top of the hill, styled his new building on the layout and dimensions of the old castle and on what had been discovered during his research of its surviving interior designs.</span>
</span></span></span>
<span class="ltx_tr" id="A1.p1.1.1.1.11">
<span class="ltx_td ltx_align_left" id="A1.p1.1.1.1.11.1" style="padding-top:5pt;padding-bottom:5pt;"><span class="ltx_ERROR undefined" id="A1.p1.1.1.1.11.1.1">\cdashline</span>1-2[1.5pt/3pt] 
<span class="ltx_text ltx_font_bold" id="A1.p1.1.1.1.11.1.2">Comprehension and Reasoning</span></span>
<span class="ltx_td ltx_align_top" id="A1.p1.1.1.1.11.2" style="padding-top:5pt;padding-bottom:5pt;"></span></span>
<span class="ltx_tr" id="A1.p1.1.1.1.12">
<span class="ltx_td ltx_align_left" id="A1.p1.1.1.1.12.1" style="padding-top:5pt;padding-bottom:5pt;"><span class="ltx_text ltx_font_bold" id="A1.p1.1.1.1.12.1.1">Question</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="A1.p1.1.1.1.12.2" style="padding-top:5pt;padding-bottom:5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.p1.1.1.1.12.2.1">
<span class="ltx_p" id="A1.p1.1.1.1.12.2.1.1" style="width:284.5pt;">How many religious functional zones that have historically emerged in Barcelona?</span>
</span></span></span>
<span class="ltx_tr" id="A1.p1.1.1.1.13">
<span class="ltx_td ltx_align_left" id="A1.p1.1.1.1.13.1" style="padding-top:5pt;padding-bottom:5pt;"><span class="ltx_text ltx_font_bold" id="A1.p1.1.1.1.13.1.1">Target Text</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="A1.p1.1.1.1.13.2" style="padding-top:5pt;padding-bottom:5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.p1.1.1.1.13.2.1">
<span class="ltx_p" id="A1.p1.1.1.1.13.2.1.1" style="width:284.5pt;">“Jewish Quarter (Call) :During medieval times Barcelona had a Jewish quarter…”</span>
</span></span></span>
<span class="ltx_tr" id="A1.p1.1.1.1.14">
<span class="ltx_td" id="A1.p1.1.1.1.14.1" style="padding-top:5pt;padding-bottom:5pt;"></span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="A1.p1.1.1.1.14.2" style="padding-top:5pt;padding-bottom:5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.p1.1.1.1.14.2.1">
<span class="ltx_p" id="A1.p1.1.1.1.14.2.1.1" style="width:284.5pt;">“Christian Quarters: Various population centers (vila nova) were created, generally around churches and monasteries: this was the case around the church…”</span>
</span></span></span>
<span class="ltx_tr" id="A1.p1.1.1.1.15">
<span class="ltx_td ltx_align_left" id="A1.p1.1.1.1.15.1" style="padding-top:5pt;padding-bottom:5pt;"><span class="ltx_text ltx_font_bold" id="A1.p1.1.1.1.15.1.1">Ground Truth</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="A1.p1.1.1.1.15.2" style="padding-top:5pt;padding-bottom:5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.p1.1.1.1.15.2.1">
<span class="ltx_p" id="A1.p1.1.1.1.15.2.1.1" style="width:284.5pt;">2</span>
</span></span></span>
<span class="ltx_tr" id="A1.p1.1.1.1.16">
<span class="ltx_td ltx_align_left" id="A1.p1.1.1.1.16.1" style="padding-top:5pt;padding-bottom:5pt;"><span class="ltx_ERROR undefined" id="A1.p1.1.1.1.16.1.1">\cdashline</span>1-2[1.5pt/3pt] 
<span class="ltx_text ltx_font_bold" id="A1.p1.1.1.1.16.1.2">Computation</span></span>
<span class="ltx_td ltx_align_top" id="A1.p1.1.1.1.16.2" style="padding-top:5pt;padding-bottom:5pt;"></span></span>
<span class="ltx_tr" id="A1.p1.1.1.1.17">
<span class="ltx_td ltx_align_left" id="A1.p1.1.1.1.17.1" style="padding-top:5pt;padding-bottom:5pt;"><span class="ltx_text ltx_font_bold" id="A1.p1.1.1.1.17.1.1">Question</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="A1.p1.1.1.1.17.2" style="padding-top:5pt;padding-bottom:5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.p1.1.1.1.17.2.1">
<span class="ltx_p" id="A1.p1.1.1.1.17.2.1.1" style="width:284.5pt;">How many years did Picardo work for Parador from his first of Parador projects until the bankruptcy on Parador?</span>
</span></span></span>
<span class="ltx_tr" id="A1.p1.1.1.1.18">
<span class="ltx_td ltx_align_left" id="A1.p1.1.1.1.18.1" style="padding-top:5pt;padding-bottom:5pt;"><span class="ltx_text ltx_font_bold" id="A1.p1.1.1.1.18.1.1">Target Text</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="A1.p1.1.1.1.18.2" style="padding-top:5pt;padding-bottom:5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.p1.1.1.1.18.2.1">
<span class="ltx_p" id="A1.p1.1.1.1.18.2.1.1" style="width:284.5pt;">“For his first of many Parador projects Picardo was appointed by the Ministry of Information and Tourism …”</span>
</span></span></span>
<span class="ltx_tr" id="A1.p1.1.1.1.19">
<span class="ltx_td" id="A1.p1.1.1.1.19.1" style="padding-top:5pt;padding-bottom:5pt;"></span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="A1.p1.1.1.1.19.2" style="padding-top:5pt;padding-bottom:5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.p1.1.1.1.19.2.1">
<span class="ltx_p" id="A1.p1.1.1.1.19.2.1.1" style="width:284.5pt;">“The Pedraza Hostería continued in operation until 15 December 1992 when economic pressures on the Parador chain caused its closure.”</span>
</span></span></span>
<span class="ltx_tr" id="A1.p1.1.1.1.20">
<span class="ltx_td ltx_align_left" id="A1.p1.1.1.1.20.1" style="padding-top:5pt;padding-bottom:5pt;"><span class="ltx_text ltx_font_bold" id="A1.p1.1.1.1.20.1.1">Ground Truth</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top" id="A1.p1.1.1.1.20.2" style="padding-top:5pt;padding-bottom:5pt;">
<span class="ltx_inline-block ltx_align_top" id="A1.p1.1.1.1.20.2.1">
<span class="ltx_p" id="A1.p1.1.1.1.20.2.1.1" style="width:284.5pt;">Twenty-nine years.</span>
</span></span></span>
</span>
</span></p>
</div>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Wed Oct  2 05:09:36 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
