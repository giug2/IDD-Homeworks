<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions</title>
<!--Generated on Sun Jul  7 05:46:39 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2407.05271v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#S1" title="In Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#S2" title="In Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#S3" title="In Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#S3.SS1" title="In 3 Experiments ‣ Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Data</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#S3.SS2" title="In 3 Experiments ‣ Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Gender Prediction Models</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#S3.SS3" title="In 3 Experiments ‣ Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Results</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#S4" title="In Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Discussion</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#S4.SS0.SSS0.Px1" title="In 4 Discussion ‣ Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions"><span class="ltx_text ltx_ref_title">LLMs are poor at accurately predicting gender.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#S4.SS0.SSS0.Px2" title="In 4 Discussion ‣ Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions"><span class="ltx_text ltx_ref_title">Including temporal information mostly degrades accuracy.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#S4.SS0.SSS0.Px3" title="In 4 Discussion ‣ Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions"><span class="ltx_text ltx_ref_title">LLMs have worst performance on gender-neutral names.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#S4.SS0.SSS0.Px4" title="In 4 Discussion ‣ Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions"><span class="ltx_text ltx_ref_title">LLM performance is biased towards recent year patterns.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#S4.SS0.SSS0.Px5" title="In 4 Discussion ‣ Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions"><span class="ltx_text ltx_ref_title">Suggestions for practitioners</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#S5" title="In Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#S6" title="In Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Bias Statement</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#A1" title="In Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Dataset Statistics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#A2" title="In Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B </span>Experimental Settings</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#A3" title="In Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C </span>LLMs for Gender Prediction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#A4" title="In Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">D </span>Prompt Templates for LLMs</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#A5" title="In Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">E </span>Prompt Robustness Evaluation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#A6" title="In Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">F </span>Over-time Trends of LLM Performances</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Zhiwen You<sup class="ltx_sup" id="id16.16.id1">1</sup>, HaeJin Lee<sup class="ltx_sup" id="id17.17.id2">1</sup><span class="ltx_note ltx_role_footnotemark" id="footnotex1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">1</span></span></span></span>, Shubhanshu Mishra<sup class="ltx_sup" id="id18.18.id3">2</sup>,
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="id7.7.4">Sullam Jeoung<sup class="ltx_sup" id="id7.7.4.1"><span class="ltx_text ltx_font_medium" id="id7.7.4.1.1">1</span></sup>, Apratim Mishra<sup class="ltx_sup" id="id7.7.4.2"><span class="ltx_text ltx_font_medium" id="id7.7.4.2.1">1</span></sup>, Jinseok Kim<sup class="ltx_sup" id="id7.7.4.3"><span class="ltx_text ltx_font_medium" id="id7.7.4.3.1">3</span></sup>, Jana Diesner<math alttext="{}^{1},^{4}" class="ltx_math_unparsed" display="inline" id="id7.7.4.m4.1"><semantics id="id7.7.4.m4.1a"><mmultiscripts id="id7.7.4.m4.1.1"><mo id="id7.7.4.m4.1.1.2.2">,</mo><mrow id="id7.7.4.m4.1.1a"></mrow><mn id="id7.7.4.m4.1.1.2.3">4</mn><mprescripts id="id7.7.4.m4.1.1b"></mprescripts><mrow id="id7.7.4.m4.1.1c"></mrow><mn id="id7.7.4.m4.1.1.3">1</mn></mmultiscripts><annotation encoding="application/x-tex" id="id7.7.4.m4.1b">{}^{1},^{4}</annotation><annotation encoding="application/x-llamapun" id="id7.7.4.m4.1c">start_FLOATSUPERSCRIPT 1 end_FLOATSUPERSCRIPT , start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT</annotation></semantics></math></span>
<br class="ltx_break"/><sup class="ltx_sup" id="id19.19.id4">1</sup> University of Illinois Urbana-Champaign  <sup class="ltx_sup" id="id20.20.id5">2</sup> https://shubhanshu.com 
<br class="ltx_break"/><sup class="ltx_sup" id="id21.21.id6">3</sup> University of Michigan - Ann Arbor  <sup class="ltx_sup" id="id22.22.id7">4</sup> Technical University of Munich 
<br class="ltx_break"/><sup class="ltx_sup" id="id23.23.id8">1</sup> <span class="ltx_text ltx_font_typewriter" id="id24.24.id9">{zhiweny2, haejin2, sjeoung2, apratim3}@illinois.edu</span>
<br class="ltx_break"/><sup class="ltx_sup" id="id25.25.id10">2</sup> <span class="ltx_text ltx_font_typewriter" id="id26.26.id11">mishra@shubhanshu.com</span>  <sup class="ltx_sup" id="id27.27.id12">3</sup> <span class="ltx_text ltx_font_typewriter" id="id28.28.id13">jinseokk@umich.edu</span>  <sup class="ltx_sup" id="id29.29.id14">4</sup> <span class="ltx_text ltx_font_typewriter" id="id30.30.id15">jana.diesner@tum.de</span>
</span><span class="ltx_author_notes">Equal Contribution.</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id31.id1">Name-based gender prediction has traditionally categorized individuals as either female or male based on their names, using a binary classification system. That binary approach can be problematic in the cases of gender-neutral names that do not align with any one gender, among other reasons. Relying solely on binary gender categories without recognizing gender-neutral names can reduce the inclusiveness of gender prediction tasks. We introduce an additional gender category, i.e., “neutral”, to study and address potential gender biases in Large Language Models (LLMs). We evaluate the performance of several foundational and large language models in predicting gender based on first names only. Additionally, we investigate the impact of adding birth years to enhance the accuracy of gender prediction, accounting for shifting associations between names and genders over time. Our findings indicate that most LLMs identify male and female names with high accuracy (over 80%) but struggle with gender-neutral names (under 40%), and the accuracy of gender prediction is higher for English-based first names than non-English names. The experimental results show that incorporating the birth year does not improve the overall accuracy of gender prediction, especially for names with evolving gender associations. We recommend using caution when applying LLMs for gender identification in downstream tasks, particularly when dealing with non-binary gender labels<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Our code is available at <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/zhiwenyou103/Beyond-Binary-Gender-Labels" title="">https://github.com/zhiwenyou103/Beyond-Binary-Gender-Labels</a>.</span></span></span>.</p>
</div>
<div class="ltx_para ltx_noindent" id="p1">
<div class="ltx_block ltx_align_bottom" id="p1.15">
<p class="ltx_p" id="p1.15.16"><span class="ltx_text ltx_font_bold" id="p1.15.16.1">Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions</span></p>
<br class="ltx_break ltx_centering"/>
<p class="ltx_p ltx_align_center" id="p1.15.15" style="width:433.6pt;"><span class="ltx_text ltx_inline-block" id="p1.15.15.15" style="width:0.0pt;">
<span class="ltx_tabular ltx_align_top" id="p1.15.15.15.15">
<span class="ltx_tr" id="p1.3.3.3.3.3">
<span class="ltx_td ltx_align_center" id="p1.3.3.3.3.3.3"><span class="ltx_text ltx_font_bold" id="p1.3.3.3.3.3.3.3">Zhiwen You<sup class="ltx_sup" id="p1.3.3.3.3.3.3.3.1"><span class="ltx_text ltx_font_medium" id="p1.3.3.3.3.3.3.3.1.1">1</span></sup><span class="ltx_note ltx_role_thanks" id="p1.3.3.3.3.3.3.3.2"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">thanks: </span>Equal Contribution.</span></span></span>, HaeJin Lee<sup class="ltx_sup" id="p1.3.3.3.3.3.3.3.3"><span class="ltx_text ltx_font_medium" id="p1.3.3.3.3.3.3.3.3.1">1</span></sup><span class="ltx_note ltx_role_footnotemark" id="footnotex2"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_medium" id="footnotex2.1.1.1">1</span></span></span></span></span>, Shubhanshu Mishra<sup class="ltx_sup" id="p1.3.3.3.3.3.3.3.4"><span class="ltx_text ltx_font_medium" id="p1.3.3.3.3.3.3.3.4.1">2</span></sup>,</span></span></span>
<span class="ltx_tr" id="p1.7.7.7.7.7">
<span class="ltx_td ltx_align_center" id="p1.7.7.7.7.7.4"><span class="ltx_text ltx_font_bold" id="p1.7.7.7.7.7.4.4">Sullam Jeoung<sup class="ltx_sup" id="p1.7.7.7.7.7.4.4.1"><span class="ltx_text ltx_font_medium" id="p1.7.7.7.7.7.4.4.1.1">1</span></sup>, Apratim Mishra<sup class="ltx_sup" id="p1.7.7.7.7.7.4.4.2"><span class="ltx_text ltx_font_medium" id="p1.7.7.7.7.7.4.4.2.1">1</span></sup>, Jinseok Kim<sup class="ltx_sup" id="p1.7.7.7.7.7.4.4.3"><span class="ltx_text ltx_font_medium" id="p1.7.7.7.7.7.4.4.3.1">3</span></sup>, Jana Diesner<math alttext="{}^{1},^{4}" class="ltx_math_unparsed" display="inline" id="p1.7.7.7.7.7.4.4.m4.1"><semantics id="p1.7.7.7.7.7.4.4.m4.1a"><mmultiscripts id="p1.7.7.7.7.7.4.4.m4.1.1"><mo id="p1.7.7.7.7.7.4.4.m4.1.1.2.2">,</mo><mrow id="p1.7.7.7.7.7.4.4.m4.1.1a"></mrow><mn id="p1.7.7.7.7.7.4.4.m4.1.1.2.3">4</mn><mprescripts id="p1.7.7.7.7.7.4.4.m4.1.1b"></mprescripts><mrow id="p1.7.7.7.7.7.4.4.m4.1.1c"></mrow><mn id="p1.7.7.7.7.7.4.4.m4.1.1.3">1</mn></mmultiscripts><annotation encoding="application/x-tex" id="p1.7.7.7.7.7.4.4.m4.1b">{}^{1},^{4}</annotation><annotation encoding="application/x-llamapun" id="p1.7.7.7.7.7.4.4.m4.1c">start_FLOATSUPERSCRIPT 1 end_FLOATSUPERSCRIPT , start_POSTSUPERSCRIPT 4 end_POSTSUPERSCRIPT</annotation></semantics></math></span></span></span>
<span class="ltx_tr" id="p1.9.9.9.9.9">
<span class="ltx_td ltx_align_center" id="p1.9.9.9.9.9.2"><sup class="ltx_sup" id="p1.9.9.9.9.9.2.1">1</sup> University of Illinois Urbana-Champaign  <sup class="ltx_sup" id="p1.9.9.9.9.9.2.2">2</sup> https://shubhanshu.com</span></span>
<span class="ltx_tr" id="p1.11.11.11.11.11">
<span class="ltx_td ltx_align_center" id="p1.11.11.11.11.11.2"><sup class="ltx_sup" id="p1.11.11.11.11.11.2.1">3</sup> University of Michigan - Ann Arbor  <sup class="ltx_sup" id="p1.11.11.11.11.11.2.2">4</sup> Technical University of Munich</span></span>
<span class="ltx_tr" id="p1.12.12.12.12.12">
<span class="ltx_td ltx_align_center" id="p1.12.12.12.12.12.1"><sup class="ltx_sup" id="p1.12.12.12.12.12.1.1">1</sup> <span class="ltx_text ltx_font_typewriter" id="p1.12.12.12.12.12.1.2">{zhiweny2, haejin2, sjeoung2, apratim3}@illinois.edu</span></span></span>
<span class="ltx_tr" id="p1.15.15.15.15.15">
<span class="ltx_td ltx_align_center" id="p1.15.15.15.15.15.3"><sup class="ltx_sup" id="p1.15.15.15.15.15.3.1">2</sup> <span class="ltx_text ltx_font_typewriter" id="p1.15.15.15.15.15.3.2">mishra@shubhanshu.com</span>  <sup class="ltx_sup" id="p1.15.15.15.15.15.3.3">3</sup> <span class="ltx_text ltx_font_typewriter" id="p1.15.15.15.15.15.3.4">jinseokk@umich.edu</span>  <sup class="ltx_sup" id="p1.15.15.15.15.15.3.5">4</sup> <span class="ltx_text ltx_font_typewriter" id="p1.15.15.15.15.15.3.6">jana.diesner@tum.de</span></span></span>
</span></span></p>
<br class="ltx_break ltx_centering"/>
</div>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="249" id="S1.F1.g1" src="extracted/5715083/pics/diagram.png" width="438"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Example of an LLM predicting different gender labels over time for the same first name. “Victory” was labeled Male in 1933, and the LLM predicted it correctly. However, by 2016, the name had become predominantly gender-neutral, but the LLM still incorrectly predicted it as Male.</figcaption>
</figure>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Name-based gender prediction is the task of identifying the most likely gender label for a given name. This task, while not reflective of the true gender identify of the individual, is often useful for aggregate downstream analysis and as a demographic feature for predictive models. Prior work has utilized name-based gender prediction to investigate gender bias in scientific productivity, citation practices, information extraction systems, personalized marketing, content recommendation, targeted advertising, gender-based sentiment analysis, and social network analysis <cite class="ltx_cite ltx_citemacro_cite">Diesner and Carley (<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib8" title="">2009</a>); Ross et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib32" title="">2022</a>); Jentzsch and Turan (<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib11" title="">2022</a>); Teich et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib35" title="">2022</a>); Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib18" title="">2023</a>); Larivière et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib17" title="">2013</a>); Mishra et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib25" title="">2020</a>, <a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib24" title="">2018</a>); VanHelene et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib38" title="">2024</a>)</cite>. Most prior work has utilized computational tools (e.g., Genderize.io<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://genderize.io/" title="">https://genderize.io/</a></span></span></span>, Namsor<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://namsor.app/" title="">https://namsor.app/</a></span></span></span>, Gender API<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://gender-api.com/" title="">https://gender-api.com/</a></span></span></span>, or machine learning (ML) models) or datasets (e.g., US SSN) to assign probabilities of a name (along with other features like demographics, time) likely to be a male or a female. Since name-based gender is used both as a feature in downstream systems and an indicator of demographic representation, it can lead to both measurement bias and representational bias as identified in the framework proposed by <cite class="ltx_cite ltx_citemacro_citet">Suresh and Guttag (<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib33" title="">2021</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">A prevalent challenge in contexts utilizing inferred gender is the practice of treating gender as a binary construct, strictly categorizing names as either male or female <cite class="ltx_cite ltx_citemacro_cite">Chatterjee and Werner (<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib6" title="">2021</a>); Pilkina and Lovakov (<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib29" title="">2022</a>)</cite>. This reliance on binary labels likely stems from historical and societal norms that often only recognize these two categories. Binary representations can reinforce existing gender biases and exclude non-binary and gender-diverse individuals, hindering their representation and understanding <cite class="ltx_cite ltx_citemacro_cite">Krstovski et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib15" title="">2023</a>); Dinh et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib9" title="">2023</a>); Mishra et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib24" title="">2018</a>)</cite> in algorithm design and data annotation. The presence of gender-neutral names, as defined by <cite class="ltx_cite ltx_citemacro_citet">Barry III and Harper (<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib4" title="">2014</a>)</cite>, further complicates this issue. These names, frequently assigned to both genders, contradict the binary classification system, leading to potential inaccuracies and misrepresentations in data and processes reliant on gender predictions.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">This study aims to answer the following research questions to examine one of many aspects of gender biases in LLMs concerning gender prediction, especially for gender-neutral names and gender labels that change over time (Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions"><span class="ltx_text ltx_ref_tag">1</span></a>).</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1"><span class="ltx_text ltx_font_bold" id="S1.p4.1.1">RQ1.</span> How does the performance of autoregressive LLMs versus fine-tuned foundation language models compare when predicting gender categories (i.e., female, male, and neutral) given first names?</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1"><span class="ltx_text ltx_font_bold" id="S1.p5.1.1">RQ2.</span> How does adding the birth year impact gender prediction accuracy?</p>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1"><span class="ltx_text ltx_font_bold" id="S1.p6.1.1">NOTE:</span> In the context of this research, we are only interested in studying the likelihood of a name being identified as <span class="ltx_text ltx_font_typewriter" id="S1.p6.1.2">Male</span>, <span class="ltx_text ltx_font_typewriter" id="S1.p6.1.3">Female</span>, and <span class="ltx_text ltx_font_typewriter" id="S1.p6.1.4">Neutral</span>. As highlighted in <cite class="ltx_cite ltx_citemacro_citet">Yee et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib39" title="">2021</a>)</cite>, predictive models cannot be accurate about demographic attributes, and it is best to rely on individual responses to assign sensitive demographic attributes e.g. gender, however, they can be useful at the aggregate level, which is the focus of this work.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">In the gender prediction task, models are trained to predict or classify gender labels based on various input features, such as first or last names, country information, behavioral data, or textual content from social media activity <cite class="ltx_cite ltx_citemacro_cite">Liu and Ruths (<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib19" title="">2013</a>); Tang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib34" title="">2011</a>); To et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib36" title="">2020</a>)</cite>. Consequently, the accuracy of gender prediction can impact the validity of research findings and derived implication, such as policies. In other words, inaccurate gender prediction can distort results and lead to misunderstandings of gender-related biases. Moreover, the reliance on binary gender categorizations constrains the nuanced understanding of bias and the representation of individuals. Therefore, ensuring accurate and unbiased gender prediction is essential as it can impact the fairness and effectiveness of downstream applications.</p>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">Previous studies found prevalent biases in NLP-based gender prediction using gender-predicting software tools <cite class="ltx_cite ltx_citemacro_cite">Misa (<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib23" title="">2022</a>); Alexopoulos et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib2" title="">2023</a>)</cite>, which failed to appropriately capture the fact that gender exists on a non-binary scale. While most studies of bias in gender prediction relied on binary gender labels <cite class="ltx_cite ltx_citemacro_cite">Teich et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib35" title="">2022</a>); Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib18" title="">2023</a>)</cite>, some studies have gone beyond binary labels by introducing an additional category for names that were not strictly associated with either female or male genders <cite class="ltx_cite ltx_citemacro_cite">Larivière et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib16" title="">2013</a>); Mishra et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib24" title="">2018</a>); Pinheiro et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib30" title="">2022</a>)</cite>. For instance, <cite class="ltx_cite ltx_citemacro_citet">Krstovski et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib15" title="">2023</a>)</cite> categorized names that appeared as both female and male as “gender ambiguous”. Additionally, most prior work on gender prediction used names as the only input feature <cite class="ltx_cite ltx_citemacro_cite">Jia and Zhao (<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib12" title="">2019</a>); Hu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib10" title="">2021</a>); Pham and Nguyen (<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib28" title="">2023</a>)</cite>, while others such as <cite class="ltx_cite ltx_citemacro_citet">Blevins and Mullen (<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib5" title="">2015</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citet">Misa (<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib23" title="">2022</a>)</cite> inferred the gender of first names using historical datasets with multilpe features.</p>
</div>
<div class="ltx_para" id="S2.p3">
<p class="ltx_p" id="S2.p3.1">Recent advances in deep learning (DL) have produced pre-trained language models like BERT <cite class="ltx_cite ltx_citemacro_cite">Devlin et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib7" title="">2019</a>)</cite>, CharBERT <cite class="ltx_cite ltx_citemacro_cite">Ma et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib21" title="">2020</a>)</cite>, and RoBERTa <cite class="ltx_cite ltx_citemacro_cite">Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib20" title="">2019</a>)</cite>, which have been widely used for gender prediction. For example, <cite class="ltx_cite ltx_citemacro_citet">Hu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib10" title="">2021</a>)</cite> found that using the user’s name achieved higher gender prediction accuracy than using other features (e.g., website page views and clicks) in both ML and DL models, while <cite class="ltx_cite ltx_citemacro_citet">Jia and Zhao (<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib12" title="">2019</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citet">Pham and Nguyen (<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib28" title="">2023</a>)</cite> demonstrated the effectiveness of BERT-based models for gender prediction for Japanese and Chinese names. Despite these developments, few studies focused on gender prediction using autoregressive models like ChatGPT <cite class="ltx_cite ltx_citemacro_cite">OpenAI (<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib26" title="">2024a</a>)</cite> and Llama 2 <cite class="ltx_cite ltx_citemacro_cite">Touvron et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib37" title="">2023</a>)</cite>. The increasing application of LLMs for gender prediction <cite class="ltx_cite ltx_citemacro_cite">Kotek et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib14" title="">2023</a>); Rhue et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib31" title="">2024</a>)</cite> underscores the need to evaluate the limitations of LLMs, particularly for gender-neutral names. For example, <cite class="ltx_cite ltx_citemacro_citet">Michelle et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib22" title="">2023</a>)</cite> used a prompting approach with ChatGPT to predict the gender of Olympic athletes, showing ChatGPT performed at least as well as common commercial tools (i.e., Gender-API and Namsor) and often outperforms them on a binary gender scale. In this paper, we conducted experiments beyond prior approaches by introducing the gender-neutral label and using three Social Security Administration (SSA) baby name datasets to investigate gender biases by predicting non-binary gender labels.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Experiments</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">This section discussed the datasets, pre-processing, experimental design, and how we compared various models for name-based gender prediction.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Data</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p1.1.1">Dataset Pre-processing.</span> We re-used three datasets of first names of children: one from the SSA of the US<span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.ssa.gov/oact/babynames/limits.html" title="">https://www.ssa.gov/oact/babynames/limits.html</a></span></span></span>, one from the province of Alberta, Canada<span class="ltx_note ltx_role_footnote" id="footnote6"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://ouvert.canada.ca/data/dataset" title="">https://ouvert.canada.ca/data/dataset</a></span></span></span>, and one from France<span class="ltx_note ltx_role_footnote" id="footnote7"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.insee.fr/fr/statistiques/7633685?sommaire=7635552" title="">https://www.insee.fr/fr/statistiques/7633685?sommaire=7635552</a></span></span></span>. Each dataset included first names, gender (female or male), and birth year. To identify and associate the gender label for each name, we counted how often each name appeared with its associated gender labels (i.e., female or male) and year of birth for a specific year. For example, if the name “Harry” appeared five times as female and 15 times as male in a specific year, we calculated the gender ratios for that year as 25% female and 75% male. Using these ratios, we labeled the first names with the associated gender labels according to the following rule-set: if a first name was at least 10% female and 10% male representation in a given year, we labeled the name as neutral. For first names with at least 85% female representation, we labeled the names as female gender label. Similarly, for the first names with at least 85% male, we labeled the names as male.</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1">Due to the scarcity of gender-neutral names in our relabeled datasets from the 1900s, we needed to balance the number of names by gender to ensure fair comparisons in our experiments. We achieved this by sampling an equal number of female, male, and neutral names each year in the relabeled datasets. Specifically, we randomly selected 300 names per gender for each year from 1914 to 2022 from the US SSA dataset. In the Canada SSA dataset, where gender-neutral names were rare before 2000 (less than five first names per year) but increased in recent years (after 2010), we sampled 273 names per gender for each year from 2013 to 2020. Similarly, the France SSA dataset had few gender-neutral names in the early 1900s. Therefore, we selected 32 names per gender for each year from 1908 to 2022. Additional details on the dataset statistics can be found in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#A1" title="Appendix A Dataset Statistics ‣ Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions"><span class="ltx_text ltx_ref_tag">A</span></a>. We used these balanced datasets for all the experiments in Table <a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#S3.T2" title="Table 2 ‣ 3.1 Data ‣ 3 Experiments ‣ Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<figure class="ltx_table" id="S3.T1">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S3.T1.1" style="width:244.6pt;height:126.4pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-34.5pt,17.8pt) scale(0.78,0.78) ;">
<table class="ltx_tabular ltx_align_middle" id="S3.T1.1.1">
<tr class="ltx_tr" id="S3.T1.1.1.1">
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.1.1">First Names</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.2.1">Gender 1 (year)</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T1.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.3.1">Gender 2 (year)</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T1.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.4.1">Gender 3 (year)</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.2">
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.2.1">Arlie</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.2.2">Male (1971)</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.2.3">Neutral (1980)</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.2.4">-</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.3">
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.3.1">Hasani</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.3.2">Neutral (1983)</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.3.3">Male (2000)</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.3.4">-</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.4">
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.4.1">Neer</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.4.2">Male (2014)</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.4.3">Neutral (2018)</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.4.4">-</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.5">
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.5.1">CARMEL</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.5.2">Neutral (1920)</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.5.3">Male (1951)</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.5.4">-</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.6">
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.6.1">FIDELE</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.6.2">Neutral (1918)</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.6.3">Female (1945)</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.6.4">-</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.7">
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.7.1">Morley</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.7.2">Female (2013)</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.7.3">Neutral (2015)</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.7.4">Female (2017)</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.8">
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.8.1">Victory</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.8.2">Male (1933)</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.8.3">Female (2000)</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.8.4">Neutral (2016)</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.9">
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.1.1.9.1">Carmin</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.1.1.9.2">Male (1924)</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.1.1.9.3">Neutral (1958)</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.1.1.9.4">Female (2021)</td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>
Examples of first names that were labeled as different genders over the years.
</figcaption>
</figure>
<div class="ltx_para" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p3.1.1">Dynamic gender label datasets.</span>
We observed that each balanced SSA dataset included first names labeled with different genders over the years, as shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#S3.T1" title="Table 1 ‣ 3.1 Data ‣ 3 Experiments ‣ Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions"><span class="ltx_text ltx_ref_tag">1</span></a>. For example, <span class="ltx_text ltx_font_typewriter" id="S3.SS1.p3.1.2">Victory</span> was recorded as a male name in 1933, a female name in 2000, and as a gender-neutral name in 2016 (Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions"><span class="ltx_text ltx_ref_tag">1</span></a>). To further analyze the gender prediction performance of LLMs on first names with varying gender labels over time, we created a dynamic gender label dataset for each country. We selected first names with dynamic gender labels (i.e. names for which the gender association changes over time) from the test set of each balanced SSA dataset. The dynamic gender label datasets were used in the experiments of Table <a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#S3.T3" title="Table 3 ‣ 3.1 Data ‣ 3 Experiments ‣ Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions"><span class="ltx_text ltx_ref_tag">3</span></a>. The distribution of these dynamic gender labels is detailed in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#A1" title="Appendix A Dataset Statistics ‣ Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions"><span class="ltx_text ltx_ref_tag">A</span></a>.</p>
</div>
<figure class="ltx_table" id="S3.T2">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S3.T2.1">
<tr class="ltx_tr" id="S3.T2.1.1">
<td class="ltx_td ltx_border_tt" id="S3.T2.1.1.1"></td>
<td class="ltx_td ltx_border_tt" id="S3.T2.1.1.2"></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="4" id="S3.T2.1.1.3">First Name</td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="4" id="S3.T2.1.1.4">First Name + Year</td>
<td class="ltx_td ltx_border_tt" id="S3.T2.1.1.5"></td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.2">
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.2.1">Datasets</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.2.2">Models</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.2.3">Male</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.2.4">Female</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.2.5">Neutral</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.2.6">Acc.</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.2.7">Male</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.2.8">Female</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.2.9">Neutral</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.2.10">Acc.</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.2.11">Avg.</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.3">
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.3.1" rowspan="8"><span class="ltx_text" id="S3.T2.1.3.1.1">US SSA</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.3.2">BERT</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.3.3">84.46</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.3.4"><span class="ltx_text ltx_font_bold" id="S3.T2.1.3.4.1">89.30</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.3.5"><span class="ltx_text ltx_font_bold" id="S3.T2.1.3.5.1">90.55</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.3.6"><span class="ltx_text ltx_font_bold" id="S3.T2.1.3.6.1">88.10</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.3.7"><span class="ltx_text ltx_font_bold" id="S3.T2.1.3.7.1">86.64</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.3.8"><span class="ltx_text ltx_font_bold" id="S3.T2.1.3.8.1">90.98</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.3.9">91.13</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.3.10"><span class="ltx_text ltx_font_bold" id="S3.T2.1.3.10.1">89.58</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.3.11"><span class="ltx_text ltx_font_bold" id="S3.T2.1.3.11.1">88.84</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.4">
<td class="ltx_td ltx_align_center" id="S3.T2.1.4.1">RoBERTa</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.4.2">83.76</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.4.3">87.80</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.4.4">90.00</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.4.5">87.19</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.4.6">85.05</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.4.7">88.53</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.4.8">90.95</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.4.9">88.18</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.4.10">87.69</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.5">
<td class="ltx_td ltx_align_center" id="S3.T2.1.5.1">CharRoBERTa</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.5.2"><span class="ltx_text ltx_font_bold" id="S3.T2.1.5.2.1">84.62</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.5.3">88.81</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.5.4">88.99</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.5.5">87.47</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.5.6">83.55</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.5.7">88.59</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.5.8"><span class="ltx_text ltx_font_bold" id="S3.T2.1.5.8.1">91.96</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.5.9">88.03</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.5.10">87.75</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.6">
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.6.1">GPT-3.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.6.2">91.62</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.6.3"><span class="ltx_text ltx_font_bold" id="S3.T2.1.6.3.1">96.70</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.6.4">15.99</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.6.5">68.10</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.6.6">94.68</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.6.7"><span class="ltx_text ltx_font_bold" id="S3.T2.1.6.7.1">96.30</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.6.8">14.37</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.6.9"><span class="ltx_text ltx_font_bold" id="S3.T2.1.6.9.1">68.45</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.6.10">68.28</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.7">
<td class="ltx_td ltx_align_center" id="S3.T2.1.7.1">Llama 2</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.7.2">1.93</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.7.3">6.42</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.7.4"><span class="ltx_text ltx_font_bold" id="S3.T2.1.7.4.1">99.66</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.7.5">36.00</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.7.6">16.48</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.7.7">36.97</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.7.8"><span class="ltx_text ltx_font_bold" id="S3.T2.1.7.8.1">90.37</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.7.9">47.94</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.7.10">41.97</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.8">
<td class="ltx_td ltx_align_center" id="S3.T2.1.8.1">Llama 3</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.8.2"><span class="ltx_text ltx_font_bold" id="S3.T2.1.8.2.1">94.80</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.8.3">94.83</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.8.4">13.03</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.8.5">67.55</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.8.6">95.29</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.8.7">95.26</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.8.8">6.09</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.8.9">65.55</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.8.10">66.55</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.9">
<td class="ltx_td ltx_align_center" id="S3.T2.1.9.1">Mixtral-8x7B</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.9.2">64.62</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.9.3">85.81</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.9.4">53.30</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.9.5">67.91</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.9.6">61.38</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.9.7">78.44</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.9.8">56.42</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.9.9">65.41</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.9.10">66.66</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.10">
<td class="ltx_td ltx_align_center" id="S3.T2.1.10.1">Claude 3 Haiku</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.10.2">91.50</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.10.3">93.67</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.10.4">30.00</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.10.5"><span class="ltx_text ltx_font_bold" id="S3.T2.1.10.5.1">71.72</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.10.6"><span class="ltx_text ltx_font_bold" id="S3.T2.1.10.6.1">96.30</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.10.7">93.46</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.10.8">6.97</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.10.9">65.58</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.10.10"><span class="ltx_text ltx_font_bold" id="S3.T2.1.10.10.1">68.65</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.11">
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.11.1" rowspan="8"><span class="ltx_text" id="S3.T2.1.11.1.1">Canada SSA</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.11.2">BERT</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.11.3">70.98</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.11.4">73.21</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.11.5"><span class="ltx_text ltx_font_bold" id="S3.T2.1.11.5.1">82.14</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.11.6"><span class="ltx_text ltx_font_bold" id="S3.T2.1.11.6.1">75.45</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.11.7"><span class="ltx_text ltx_font_bold" id="S3.T2.1.11.7.1">74.11</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.11.8">74.55</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.11.9">74.11</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.11.10"><span class="ltx_text ltx_font_bold" id="S3.T2.1.11.10.1">75.15</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.11.11"><span class="ltx_text ltx_font_bold" id="S3.T2.1.11.11.1">75.30</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.12">
<td class="ltx_td ltx_align_center" id="S3.T2.1.12.1">RoBERTa</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.12.2"><span class="ltx_text ltx_font_bold" id="S3.T2.1.12.2.1">72.77</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.12.3">75.00</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.12.4">73.66</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.12.5">73.81</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.12.6">67.86</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.12.7">75.00</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.12.8"><span class="ltx_text ltx_font_bold" id="S3.T2.1.12.8.1">76.34</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.12.9">73.07</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.12.10">73.44</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.13">
<td class="ltx_td ltx_align_center" id="S3.T2.1.13.1">CharRoBERTa</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.13.2">71.43</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.13.3"><span class="ltx_text ltx_font_bold" id="S3.T2.1.13.3.1">76.34</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.13.4">71.88</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.13.5">73.21</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.13.6">69.20</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.13.7"><span class="ltx_text ltx_font_bold" id="S3.T2.1.13.7.1">76.34</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.13.8">74.11</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.13.9">73.21</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.13.10">73.21</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.14">
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.14.1">GPT-3.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.14.2">82.14</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.14.3"><span class="ltx_text ltx_font_bold" id="S3.T2.1.14.3.1">86.61</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.14.4">27.68</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.14.5">65.48</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.14.6"><span class="ltx_text ltx_font_bold" id="S3.T2.1.14.6.1">83.93</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.14.7">83.93</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.14.8">28.12</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.14.9">65.33</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.14.10">65.41</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.15">
<td class="ltx_td ltx_align_center" id="S3.T2.1.15.1">Llama 2</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.15.2">1.79</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.15.3">11.16</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.15.4"><span class="ltx_text ltx_font_bold" id="S3.T2.1.15.4.1">100.00</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.15.5">37.65</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.15.6">0.45</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.15.7">9.82</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.15.8"><span class="ltx_text ltx_font_bold" id="S3.T2.1.15.8.1">100.00</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.15.9">36.76</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.15.10">37.21</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.16">
<td class="ltx_td ltx_align_center" id="S3.T2.1.16.1">Llama 3</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.16.2"><span class="ltx_text ltx_font_bold" id="S3.T2.1.16.2.1">87.05</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.16.3">84.38</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.16.4">21.43</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.16.5">64.29</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.16.6">76.79</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.16.7">86.16</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.16.8">28.57</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.16.9">63.84</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.16.10">64.07</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.17">
<td class="ltx_td ltx_align_center" id="S3.T2.1.17.1">Mixtral-8x7B</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.17.2">50.45</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.17.3">69.64</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.17.4">68.30</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.17.5">62.80</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.17.6">35.27</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.17.7">46.43</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.17.8">90.62</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.17.9">57.44</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.17.10">60.12</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.18">
<td class="ltx_td ltx_align_center" id="S3.T2.1.18.1">Claude 3 Haiku</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.18.2">78.12</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.18.3">80.80</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.18.4">57.59</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.18.5"><span class="ltx_text ltx_font_bold" id="S3.T2.1.18.5.1">72.17</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.18.6">77.68</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.18.7"><span class="ltx_text ltx_font_bold" id="S3.T2.1.18.7.1">86.16</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.18.8">32.59</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.18.9"><span class="ltx_text ltx_font_bold" id="S3.T2.1.18.9.1">65.48</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.18.10"><span class="ltx_text ltx_font_bold" id="S3.T2.1.18.10.1">68.83</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.19">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S3.T2.1.19.1" rowspan="9"><span class="ltx_text" id="S3.T2.1.19.1.1">France SSA</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.19.2">BERT</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.19.3">82.17</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.19.4"><span class="ltx_text ltx_font_bold" id="S3.T2.1.19.4.1">84.57</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.19.5"><span class="ltx_text ltx_font_bold" id="S3.T2.1.19.5.1">93.04</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.19.6">86.59</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.19.7">82.39</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.19.8">84.78</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.19.9">92.61</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.19.10">86.59</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.19.11">86.59</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.20">
<td class="ltx_td ltx_align_center" id="S3.T2.1.20.1">RoBERTa</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.20.2"><span class="ltx_text ltx_font_bold" id="S3.T2.1.20.2.1">85.22</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.20.3">84.13</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.20.4">90.87</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.20.5"><span class="ltx_text ltx_font_bold" id="S3.T2.1.20.5.1">86.74</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.20.6">81.52</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.20.7"><span class="ltx_text ltx_font_bold" id="S3.T2.1.20.7.1">86.09</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.20.8"><span class="ltx_text ltx_font_bold" id="S3.T2.1.20.8.1">93.04</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.20.9">86.88</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.20.10"><span class="ltx_text ltx_font_bold" id="S3.T2.1.20.10.1">86.81</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.21">
<td class="ltx_td ltx_align_center" id="S3.T2.1.21.1">CharRoBERTa</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.21.2">84.35</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.21.3">80.43</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.21.4">91.30</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.21.5">85.36</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.21.6"><span class="ltx_text ltx_font_bold" id="S3.T2.1.21.6.1">83.04</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.21.7">83.04</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.21.8">91.96</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.21.9">86.01</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.21.10">85.69</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.22">
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.22.1">GPT-3.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.22.2">89.35</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.22.3"><span class="ltx_text ltx_font_bold" id="S3.T2.1.22.3.1">95.65</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.22.4">8.91</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.22.5">64.64</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.22.6">92.61</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.22.7"><span class="ltx_text ltx_font_bold" id="S3.T2.1.22.7.1">96.74</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.22.8">8.26</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T2.1.22.9"><span class="ltx_text ltx_font_bold" id="S3.T2.1.22.9.1">65.87</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.22.10">65.26</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.23">
<td class="ltx_td ltx_align_center" id="S3.T2.1.23.1">Llama 2</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.23.2">1.96</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.23.3">15.22</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.23.4"><span class="ltx_text ltx_font_bold" id="S3.T2.1.23.4.1">91.52</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.23.5">36.23</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.23.6">32.39</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.23.7">55.43</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.23.8"><span class="ltx_text ltx_font_bold" id="S3.T2.1.23.8.1">71.96</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.23.9">53.26</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.23.10">44.75</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.24">
<td class="ltx_td ltx_align_center" id="S3.T2.1.24.1">Llama 3</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.24.2"><span class="ltx_text ltx_font_bold" id="S3.T2.1.24.2.1">91.52</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.24.3">94.57</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.24.4">7.17</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.24.5">64.42</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.24.6">92.39</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.24.7">95.87</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.24.8">6.52</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.24.9">64.93</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.24.10">64.68</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.25">
<td class="ltx_td ltx_align_center" id="S3.T2.1.25.1">Mixtral-8x7B</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.25.2">71.96</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.25.3">88.70</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.25.4">38.04</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.25.5"><span class="ltx_text ltx_font_bold" id="S3.T2.1.25.5.1">66.23</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.25.6">68.26</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.25.7">83.26</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.25.8">39.35</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T2.1.25.9">63.62</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.25.10">64.93</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.26">
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.1.26.1">Claude 3 Haiku</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.1.26.2">89.13</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.1.26.3">93.91</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.1.26.4">13.70</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S3.T2.1.26.5">65.58</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.1.26.6"><span class="ltx_text ltx_font_bold" id="S3.T2.1.26.6.1">96.75</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.1.26.7">94.78</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.1.26.8">4.57</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S3.T2.1.26.9">65.36</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.1.26.10"><span class="ltx_text ltx_font_bold" id="S3.T2.1.26.10.1">65.47</span></td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Experimental results for applying foundation language models and LLMs to the test sets of three balanced SSA datasets. We assessed gender prediction performance by calculating an accuracy score for each gender. Acc. represents the overall accuracy across genders. BERT, RoBERTa, and CharRoBERTa were fine-tuned using the training set of each SSA dataset. In contrast, we applied 0-shot prompting to evaluate other LLMs using the test sets.</figcaption>
</figure>
<figure class="ltx_table" id="S3.T3">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S3.T3.1">
<tr class="ltx_tr" id="S3.T3.1.1">
<td class="ltx_td ltx_border_tt" id="S3.T3.1.1.1"></td>
<td class="ltx_td ltx_border_tt" id="S3.T3.1.1.2"></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="4" id="S3.T3.1.1.3">First Name</td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="4" id="S3.T3.1.1.4">First Name + Year</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.2">
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.2.1">Datasets</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.2.2">Models</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.2.3">Male</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.2.4">Female</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.2.5">Neutral</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.2.6">Acc.</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.2.7">Male</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.2.8">Female</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.2.9">Neutral</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.2.10">Acc.</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.3">
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.3.1" rowspan="10"><span class="ltx_text" id="S3.T3.1.3.1.1">US SSA</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.3.2">GPT-3.5 (0-shot)</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.3.3">86.30</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.3.4">92.39</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.3.5">31.80</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.3.6">55.61</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.3.7">95.21</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.3.8"><span class="ltx_text ltx_font_bold" id="S3.T3.1.3.8.1">93.66</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.3.9">3.92</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.3.10">41.94</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.4">
<td class="ltx_td ltx_align_center" id="S3.T3.1.4.1">Llama 2 (0-shot)</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.4.2">14.94</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.4.3">33.60</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.4.4"><span class="ltx_text ltx_font_bold" id="S3.T3.1.4.4.1">94.23</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.4.5"><span class="ltx_text ltx_font_bold" id="S3.T3.1.4.5.1">63.94</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.4.6">47.80</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.4.7">62.12</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.4.8"><span class="ltx_text ltx_font_bold" id="S3.T3.1.4.8.1">66.70</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.4.9"><span class="ltx_text ltx_font_bold" id="S3.T3.1.4.9.1">61.04</span></td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.5">
<td class="ltx_td ltx_align_center" id="S3.T3.1.5.1">Llama 3 (0-shot)</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.5.2"><span class="ltx_text ltx_font_bold" id="S3.T3.1.5.2.1">92.53</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.5.3"><span class="ltx_text ltx_font_bold" id="S3.T3.1.5.3.1">93.19</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.5.4">11.89</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.5.5">45.80</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.5.6">96.26</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.5.7">93.50</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.5.8">2.02</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.5.9">41.09</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.6">
<td class="ltx_td ltx_align_center" id="S3.T3.1.6.1">Mixtral-8x7B (0-shot)</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.6.2">80.84</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.6.3">91.28</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.6.4">32.06</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.6.5">54.15</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.6.6">70.59</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.6.7">92.23</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.6.8">32.49</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.6.9">51.88</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.7">
<td class="ltx_td ltx_align_center" id="S3.T3.1.7.1">Claude 3 Haiku (0-shot)</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.7.2">88.89</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.7.3">91.60</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.7.4">25.85</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.7.5">52.70</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.7.6"><span class="ltx_text ltx_font_bold" id="S3.T3.1.7.6.1">96.74</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.7.7">90.97</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.7.8">10.60</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.7.9">45.80</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.8">
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.8.1">GPT-3.5 (5-shot)</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.8.2">84.96</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.8.3">91.92</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.8.4">43.64</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.8.5">62.06</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.8.6">65.33</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.8.7">67.35</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.8.8">4.05</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.8.9">30.06</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.9">
<td class="ltx_td ltx_align_center" id="S3.T3.1.9.1">Llama 2 (5-shot)</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.9.2">24.71</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.9.3">50.40</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.9.4"><span class="ltx_text ltx_font_bold" id="S3.T3.1.9.4.1">86.17</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.9.5"><span class="ltx_text ltx_font_bold" id="S3.T3.1.9.5.1">64.46</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.9.6">36.88</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.9.7">64.98</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.9.8"><span class="ltx_text ltx_font_bold" id="S3.T3.1.9.8.1">68.94</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.9.9"><span class="ltx_text ltx_font_bold" id="S3.T3.1.9.9.1">59.93</span></td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.10">
<td class="ltx_td ltx_align_center" id="S3.T3.1.10.1">Llama 3 (5-shot)</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.10.2"><span class="ltx_text ltx_font_bold" id="S3.T3.1.10.2.1">92.82</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.10.3">94.45</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.10.4">13.96</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.10.5">47.27</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.10.6"><span class="ltx_text ltx_font_bold" id="S3.T3.1.10.6.1">93.77</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.10.7"><span class="ltx_text ltx_font_bold" id="S3.T3.1.10.7.1">95.72</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.10.8">11.33</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.10.9">46.20</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.11">
<td class="ltx_td ltx_align_center" id="S3.T3.1.11.1">Mixtral-8x7B (5-shot)</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.11.2">79.79</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.11.3"><span class="ltx_text ltx_font_bold" id="S3.T3.1.11.3.1">95.09</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.11.4">16.76</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.11.5">45.60</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.11.6">74.81</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.11.7">90.65</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.11.8">39.55</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.11.9">56.83</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.12">
<td class="ltx_td ltx_align_center" id="S3.T3.1.12.1">Claude 3 Haiku (5-shot)</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.12.2">87.45</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.12.3">84.63</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.12.4">39.34</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.12.5">59.06</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.12.6">91.38</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.12.7">88.75</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.12.8">32.36</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.12.9">56.68</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.13">
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.13.1" rowspan="10"><span class="ltx_text" id="S3.T3.1.13.1.1">Canada SSA</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.13.2">GPT-3.5 (0-shot)</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.13.3">86.36</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.13.4">78.07</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.13.5">49.08</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.13.6">54.74</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.13.7"><span class="ltx_text ltx_font_bold" id="S3.T3.1.13.7.1">97.27</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.13.8">78.95</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.13.9">19.00</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.13.10">30.81</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.14">
<td class="ltx_td ltx_align_center" id="S3.T3.1.14.1">Llama 2 (0-shot)</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.14.2">21.82</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.14.3">28.07</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.14.4"><span class="ltx_text ltx_font_bold" id="S3.T3.1.14.4.1">98.62</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.14.5"><span class="ltx_text ltx_font_bold" id="S3.T3.1.14.5.1">86.01</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.14.6">4.55</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.14.7">8.77</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.14.8"><span class="ltx_text ltx_font_bold" id="S3.T3.1.14.8.1">99.82</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.14.9"><span class="ltx_text ltx_font_bold" id="S3.T3.1.14.9.1">83.87</span></td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.15">
<td class="ltx_td ltx_align_center" id="S3.T3.1.15.1">Llama 3 (0-shot)</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.15.2"><span class="ltx_text ltx_font_bold" id="S3.T3.1.15.2.1">92.73</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.15.3">78.07</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.15.4">22.32</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.15.5">33.10</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.15.6">87.27</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.15.7"><span class="ltx_text ltx_font_bold" id="S3.T3.1.15.7.1">84.21</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.15.8">13.93</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.15.9">26.22</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.16">
<td class="ltx_td ltx_align_center" id="S3.T3.1.16.1">Mixtral-8x7B (0-shot)</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.16.2">67.27</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.16.3"><span class="ltx_text ltx_font_bold" id="S3.T3.1.16.3.1">78.95</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.16.4">46.31</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.16.5">50.92</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.16.6">50.00</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.16.7">79.82</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.16.8">60.70</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.16.9">61.47</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.17">
<td class="ltx_td ltx_align_center" id="S3.T3.1.17.1">Claude 3 Haiku (0-shot)</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.17.2">88.18</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.17.3"><span class="ltx_text ltx_font_bold" id="S3.T3.1.17.3.1">78.95</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.17.4">41.88</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.17.5">49.01</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.17.6">89.09</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.17.7">77.19</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.17.8">43.36</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.17.9">50.15</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.18">
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.18.1">GPT-3.5 (5-shot)</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.18.2">84.55</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.18.3">74.56</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.18.4">56.00</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.18.5">60.02</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.18.6"><span class="ltx_text ltx_font_bold" id="S3.T3.1.18.6.1">97.27</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.18.7">80.70</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.18.8">18.82</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.18.9">30.81</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.19">
<td class="ltx_td ltx_align_center" id="S3.T3.1.19.1">Llama 2 (5-shot)</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.19.2">22.73</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.19.3">24.56</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.19.4"><span class="ltx_text ltx_font_bold" id="S3.T3.1.19.4.1">97.42</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.19.5"><span class="ltx_text ltx_font_bold" id="S3.T3.1.19.5.1">84.79</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.19.6">32.73</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.19.7">23.68</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.19.8"><span class="ltx_text ltx_font_bold" id="S3.T3.1.19.8.1">87.27</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.19.9"><span class="ltx_text ltx_font_bold" id="S3.T3.1.19.9.1">77.14</span></td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.20">
<td class="ltx_td ltx_align_center" id="S3.T3.1.20.1">Llama 3 (5-shot)</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.20.2"><span class="ltx_text ltx_font_bold" id="S3.T3.1.20.2.1">91.82</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.20.3"><span class="ltx_text ltx_font_bold" id="S3.T3.1.20.3.1">79.82</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.20.4">36.62</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.20.5">45.03</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.20.6">82.73</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.20.7"><span class="ltx_text ltx_font_bold" id="S3.T3.1.20.7.1">85.96</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.20.8">32.01</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.20.9">40.98</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.21">
<td class="ltx_td ltx_align_center" id="S3.T3.1.21.1">Mixtral-8x7B (5-shot)</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.21.2">68.18</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.21.3">77.19</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.21.4">49.17</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.21.5">53.21</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.21.6">68.18</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.21.7">74.56</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.21.8">58.30</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.21.9">60.55</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.22">
<td class="ltx_td ltx_align_center" id="S3.T3.1.22.1">Claude 3 Haiku (5-shot)</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.22.2">83.64</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.22.3">64.91</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.22.4">55.26</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.22.5">58.49</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.22.6">90.91</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.22.7">60.53</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.22.8">41.97</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.22.9">47.71</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.23">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S3.T3.1.23.1" rowspan="10"><span class="ltx_text" id="S3.T3.1.23.1.1">France SSA</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.23.2">GPT-3.5 (0-shot)</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.23.3">78.43</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.23.4"><span class="ltx_text ltx_font_bold" id="S3.T3.1.23.4.1">98.31</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.23.5">16.52</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.23.6">34.30</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.23.7"><span class="ltx_text ltx_font_bold" id="S3.T3.1.23.7.1">90.20</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.23.8"><span class="ltx_text ltx_font_bold" id="S3.T3.1.23.8.1">98.31</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.23.9">3.54</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.23.10">25.84</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.24">
<td class="ltx_td ltx_align_center" id="S3.T3.1.24.1">Llama 2 (0-shot)</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.24.2">3.92</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.24.3">35.59</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.24.4"><span class="ltx_text ltx_font_bold" id="S3.T3.1.24.4.1">89.38</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.24.5"><span class="ltx_text ltx_font_bold" id="S3.T3.1.24.5.1">72.61</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.24.6">27.45</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.24.7">79.66</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.24.8"><span class="ltx_text ltx_font_bold" id="S3.T3.1.24.8.1">74.93</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.24.9"><span class="ltx_text ltx_font_bold" id="S3.T3.1.24.9.1">70.16</span></td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.25">
<td class="ltx_td ltx_align_center" id="S3.T3.1.25.1">Llama 3 (0-shot)</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.25.2">74.51</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.25.3"><span class="ltx_text ltx_font_bold" id="S3.T3.1.25.3.1">98.31</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.25.4">4.13</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.25.5">24.50</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.25.6">90.20</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.25.7"><span class="ltx_text ltx_font_bold" id="S3.T3.1.25.7.1">98.31</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.25.8">0.00</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.25.9">23.16</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.26">
<td class="ltx_td ltx_align_center" id="S3.T3.1.26.1">Mixtral-8x7B (0-shot)</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.26.2"><span class="ltx_text ltx_font_bold" id="S3.T3.1.26.2.1">82.35</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.26.3">94.92</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.26.4">14.75</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.26.5">32.96</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.26.6">88.24</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.26.7">94.92</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.26.8">28.91</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.26.9">44.32</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.27">
<td class="ltx_td ltx_align_center" id="S3.T3.1.27.1">Claude 3 Haiku (0-shot)</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.27.2">78.43</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.27.3">94.92</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.27.4">10.62</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.27.5">29.40</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.27.6">88.24</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.27.7">94.92</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.27.8">6.78</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.27.9">27.62</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.28">
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.28.1">GPT-3.5 (5-shot)</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.28.2">78.43</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.28.3">98.31</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.28.4">20.35</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.28.5">37.19</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.28.6"><span class="ltx_text ltx_font_bold" id="S3.T3.1.28.6.1">98.04</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.28.7"><span class="ltx_text ltx_font_bold" id="S3.T3.1.28.7.1">100.00</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.28.8">5.01</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.28.9">28.06</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.29">
<td class="ltx_td ltx_align_center" id="S3.T3.1.29.1">Llama 2 (5-shot)</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.29.2">3.92</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.29.3">33.90</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.29.4"><span class="ltx_text ltx_font_bold" id="S3.T3.1.29.4.1">88.20</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.29.5"><span class="ltx_text ltx_font_bold" id="S3.T3.1.29.5.1">71.49</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.29.6">13.73</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.29.7">47.46</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.29.8"><span class="ltx_text ltx_font_bold" id="S3.T3.1.29.8.1">91.15</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.29.9"><span class="ltx_text ltx_font_bold" id="S3.T3.1.29.9.1">76.61</span></td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.30">
<td class="ltx_td ltx_align_center" id="S3.T3.1.30.1">Llama 3 (5-shot)</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.30.2">82.35</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.30.3">98.31</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.30.4">9.44</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.30.5">29.40</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.30.6">90.20</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.30.7"><span class="ltx_text ltx_font_bold" id="S3.T3.1.30.7.1">100.00</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.30.8">5.01</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.30.9">27.17</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.31">
<td class="ltx_td ltx_align_center" id="S3.T3.1.31.1">Mixtral-8x7B (5-shot)</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.31.2"><span class="ltx_text ltx_font_bold" id="S3.T3.1.31.2.1">88.24</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.31.3"><span class="ltx_text ltx_font_bold" id="S3.T3.1.31.3.1">100.00</span></td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.31.4">13.57</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.31.5">33.41</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.31.6">88.24</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.31.7">94.92</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.31.8">28.91</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.31.9">44.32</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.32">
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T3.1.32.1">Claude 3 Haiku (5-shot)</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T3.1.32.2">74.51</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T3.1.32.3">86.44</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T3.1.32.4">41.00</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S3.T3.1.32.5">50.78</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T3.1.32.6">94.12</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T3.1.32.7">96.61</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T3.1.32.8">26.25</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T3.1.32.9">43.21</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Gender prediction results of LLMs using dynamic gender label datasets under 0- and 5-shot settings. We report the gender prediction performance using accuracy for each gender. Acc. denotes the overall accuracy across genders. Appendix <a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#A4" title="Appendix D Prompt Templates for LLMs ‣ Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions"><span class="ltx_text ltx_ref_tag">D</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#A5" title="Appendix E Prompt Robustness Evaluation ‣ Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions"><span class="ltx_text ltx_ref_tag">E</span></a> provide the prompt templates and prompt robustness evaluation for LLMs.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Gender Prediction Models</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">We compared several pre-trained foundation language models with a classification head to predict the gender of first names as a multi-class classification task. Additionally, we conducted LLM-based 0-shot and 5-shot experiments to evaluate the performance of LLMs as gender classifiers.</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p2.1.1">Foundation Language Models.</span> We fine-tuned three widely used foundation language models, i.e., BERT, RoBERTa, and CharBERT, as baselines for name-based gender prediction under the same experimental settings to conduct gender prediction. Model tuning hyper-parameters are detailed in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#A2" title="Appendix B Experimental Settings ‣ Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions"><span class="ltx_text ltx_ref_tag">B</span></a>.</p>
</div>
<div class="ltx_para" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p3.1.1">Large Language Models.</span> We aimed to identify the potential gender bias of LLMs in predicting gender labels given first names (plus birth year). We used five widely used LLMs for experimentation: GPT-3.5<span class="ltx_note ltx_role_footnote" id="footnote8"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://platform.openai.com/docs/models/gpt-3-5-turbo" title="">https://platform.openai.com/docs/models/gpt-3-5-turbo</a></span></span></span> <cite class="ltx_cite ltx_citemacro_cite">OpenAI (<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib27" title="">2024b</a>)</cite>, Llama 2<span class="ltx_note ltx_role_footnote" id="footnote9"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://llama.meta.com/llama2/" title="">https://llama.meta.com/llama2/</a></span></span></span> <cite class="ltx_cite ltx_citemacro_cite">Touvron et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib37" title="">2023</a>)</cite>, Llama 3<span class="ltx_note ltx_role_footnote" id="footnote10"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup><span class="ltx_tag ltx_tag_note">10</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://llama.meta.com/llama3/" title="">https://llama.meta.com/llama3/</a></span></span></span> <cite class="ltx_cite ltx_citemacro_cite">AI@Meta (<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib1" title="">2024</a>)</cite>, Mixtral-8x7B<span class="ltx_note ltx_role_footnote" id="footnote11"><sup class="ltx_note_mark">11</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">11</sup><span class="ltx_tag ltx_tag_note">11</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://mistral.ai/news/mixtral-of-experts/" title="">https://mistral.ai/news/mixtral-of-experts/</a></span></span></span> <cite class="ltx_cite ltx_citemacro_cite">Jiang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib13" title="">2024</a>)</cite>, and Claude 3 Haiku<span class="ltx_note ltx_role_footnote" id="footnote12"><sup class="ltx_note_mark">12</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">12</sup><span class="ltx_tag ltx_tag_note">12</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.anthropic.com/news/claude-3-haiku" title="">https://www.anthropic.com/news/claude-3-haiku</a></span></span></span> <cite class="ltx_cite ltx_citemacro_cite">Anthropic (<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib3" title="">2024</a>)</cite>. For more information about these models and the settings we used see Appendix <a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#A2" title="Appendix B Experimental Settings ‣ Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions"><span class="ltx_text ltx_ref_tag">B</span></a> and Appendix <a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#A3" title="Appendix C LLMs for Gender Prediction ‣ Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions"><span class="ltx_text ltx_ref_tag">C</span></a>, respectively.</p>
</div>
<figure class="ltx_figure" id="S3.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_portrait" height="1631" id="S3.F2.g1" src="extracted/5715083/pics/us_performance_plot_v3.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Temporal-level comparison of 5 LLMs using the US SSA dynamic gender label dataset given the results of Table <a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#S3.T3" title="Table 3 ‣ 3.1 Data ‣ 3 Experiments ‣ Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions"><span class="ltx_text ltx_ref_tag">3</span></a>. We report the overall accuracy of gender prediction for each year.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Results</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1"><span class="ltx_text ltx_font_bold" id="S3.SS3.p1.1.1">RQ1: How does the performance of LLMs versus fine-tuned foundation language models compare in first-name gender prediction?</span>
Fine-tuned foundational language models predicted gender-neutral first names more accurately than LLMs under 0-shot prompting across all three datasets. As shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#S3.T2" title="Table 2 ‣ 3.1 Data ‣ 3 Experiments ‣ Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions"><span class="ltx_text ltx_ref_tag">2</span></a>, out of all models, BERT results in the highest average accuracy for the US and Canada dataset, while RoBERTa outperformed BERT on the France dataset. Claude 3 Haiku achieved the highest accuracy among the LLMs with 0-shot prompting on all three datasets. The Llama 2 model did best on identifying gender-neutral names (100% accuracy for Canada SSA, 99.66% for US SSA, and 91.52% for France SSA when using only first names as input). Llama 3 demonstrated a more balanced distribution of prediction performance across different gender categories, similar to other LLMs such as GPT-3.5, Mixtral-8x7B, and Claude 3 Haiku. However, most LLMs failed to predict gender-neutral first names in the France SSA dataset compared to the English-based datasets, with accuracies of 7.17% for Llama 3, 8.91% for GPT-3.5, and 13.7% for Claude 3 Haiku. To assess the performance of gender prediction in dynamic gender label datasets (see Table <a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#S3.T3" title="Table 3 ‣ 3.1 Data ‣ 3 Experiments ‣ Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions"><span class="ltx_text ltx_ref_tag">3</span></a>), we evaluated LLMs in 0-shot and 5-shot settings, using only first names as input. Most LLMs showed higher accuracy in gender prediction when provided with 5 labeled name-gender pairs through in-context learning compared to the 0-shot setting across all datasets.</p>
</div>
<div class="ltx_para" id="S3.SS3.p2">
<p class="ltx_p" id="S3.SS3.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS3.p2.1.1">RQ2: How does adding the birth year impact gender prediction accuracy?</span> The effectiveness of the input variation (i.e., first name + birth year) varied among different language models. Incorporating birth years as an additional input feature improved the prediction accuracy of foundational language models compared to the first-name-only setting (Table <a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#S3.T2" title="Table 2 ‣ 3.1 Data ‣ 3 Experiments ‣ Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions"><span class="ltx_text ltx_ref_tag">2</span></a>). However, most LLMs showed a decline in accuracy when birth years were added, particularly in predicting gender-neutral names. Despite this trend, Mixtral-8x7B consistently improved its prediction accuracy for gender-neutral names across all three datasets by adding birth year information. Similarly, the overall accuracy of Llama 2 increased, with improvements of 12% and 17% in the US and France SSA datasets, respectively.</p>
</div>
<div class="ltx_para" id="S3.SS3.p3">
<p class="ltx_p" id="S3.SS3.p3.1">Additionally, including birth years decreased the accuracy of predicting gender-neutral names in both 0- and 5-shot settings across all datasets (Table <a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#S3.T3" title="Table 3 ‣ 3.1 Data ‣ 3 Experiments ‣ Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions"><span class="ltx_text ltx_ref_tag">3</span></a>), except for the Mixtral-8x7B model, which increased the gender prediction accuracy by adding birth years. The accuracy of GPT-3.5 and Llama 3 in predicting gender-neutral names dropped when adding the birth year among all three datasets.</p>
</div>
<div class="ltx_para" id="S3.SS3.p4">
<p class="ltx_p" id="S3.SS3.p4.1">We observed varying trends in prediction accuracy over time across 5 LLMs (Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#S3.F2" title="Figure 2 ‣ 3.2 Gender Prediction Models ‣ 3 Experiments ‣ Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions"><span class="ltx_text ltx_ref_tag">2</span></a>). The accuracy of gender prediction using the US SSA dynamic gender label dataset has increased in recent years for most LLMs, including Llama3, Mixtral-8x7B, Claude 3 Haiku, and GPT-3.5. In particular, GPT-3.5 performed better without than with birth years, suggesting that incorporating recent birth year information in the US SSA dataset did not enhance predictive accuracy. The over-time results in Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#S3.F2" title="Figure 2 ‣ 3.2 Gender Prediction Models ‣ 3 Experiments ‣ Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions"><span class="ltx_text ltx_ref_tag">2</span></a> indicated that most LLMs were better at predicting the genders of more recent first names. The over-time comparison of the other two datasets was provided in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#A6" title="Appendix F Over-time Trends of LLM Performances ‣ Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions"><span class="ltx_text ltx_ref_tag">F</span></a>.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Discussion</h2>
<section class="ltx_paragraph" id="S4.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">LLMs are poor at accurately predicting gender.</h4>
<div class="ltx_para" id="S4.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS0.SSS0.Px1.p1.1">Gender bias occurs in LLMs when performing name-based gender predictions, which shows varying performance in predicting non-binary gender labels. Llama 2 categorizes nearly all names as neutral genders, with first names only as input. This tendency may result from Llama 2’s training approach, which used reward modeling to promote more inclusive responses, where initial model outputs are adjusted based on human feedback to maximize inclusivenes and factual accuracy <cite class="ltx_cite ltx_citemacro_cite">Touvron et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib37" title="">2023</a>)</cite>. The rewarding process allows the model to better align with modern datasets’ nuanced and inclusive expectations.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Including temporal information mostly degrades accuracy.</h4>
<div class="ltx_para" id="S4.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S4.SS0.SSS0.Px2.p1.1">When providing dynamic gender label datasets with birth year information, the gender-prediction performance of most LLMs decreased, especially for gender-neutral names. However, Mixtral-8x7B showed an increase in overall accuracy when birth years were added in 0- and 5-shot settings. We hypothesize that Mixtral-8x7B can better use temporal data as a reference for gender prediction because it is trained with more numerical information. Although Llama 2 outperformed other LLMs in predicting gender-neutral names, it exhibited biased prediction results, often classifying most names as gender-neutral. We assume Llama 2’s Reinforcement Learning with Human Feedback (RLHF) approach <cite class="ltx_cite ltx_citemacro_cite">Touvron et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib37" title="">2023</a>)</cite> guides the model to generate more inclusive responses. When Llama 2 is unsure about a name’s gender, it may default to labeling it as neutral, potentially reducing prediction accuracy for gender-neutral names.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS0.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">LLMs have worst performance on gender-neutral names.</h4>
<div class="ltx_para" id="S4.SS0.SSS0.Px3.p1">
<p class="ltx_p" id="S4.SS0.SSS0.Px3.p1.1">We also find that most tested LLMs have more difficulties in predicting gender-neutral first names than binary genders, which may stem from the training data of LLMs that primarily includes binary gender labels in the training documents <cite class="ltx_cite ltx_citemacro_cite">Touvron et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib37" title="">2023</a>)</cite>. Llama 3, in particular, performed poorly overall across all three datasets with different input variations (i.e., first names with or without birth years). As detailed in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#A1" title="Appendix A Dataset Statistics ‣ Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions"><span class="ltx_text ltx_ref_tag">A</span></a>, the datasets used for dynamically labeling genders were imbalanced, with gender-neutral names being the majority. Specifically, the total numbers of gendered names for the US, Canada, and France SSA datasets were 3,996, 1,308, and 449, respectively, with around 58.1%, 82.9%, and 75.5% being gender-neutral. Consequently, Llama 3 underperformed in overall prediction accuracy compared to other LLMs due to its poor accuracy in predicting neutral genders despite performing better in predicting binary genders.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS0.SSS0.Px4">
<h4 class="ltx_title ltx_title_paragraph">LLM performance is biased towards recent year patterns.</h4>
<div class="ltx_para" id="S4.SS0.SSS0.Px4.p1">
<p class="ltx_p" id="S4.SS0.SSS0.Px4.p1.1">Based on the over-time comparison of the US SSA dataset (Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#S3.F2" title="Figure 2 ‣ 3.2 Gender Prediction Models ‣ 3 Experiments ‣ Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions"><span class="ltx_text ltx_ref_tag">2</span></a>), we hypothesize that the improved prediction performance of LLMs for recent data can be attributed to the increased volume of training data from recent years. We assume that the training data of LLMs is unbalanced, predominantly consisting of recent data, potentially explaining the higher gender prediction accuracy of LLMs in recent years. The comparison of balanced SSA datasets and dynamic gender label datasets shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#S3.T2" title="Table 2 ‣ 3.1 Data ‣ 3 Experiments ‣ Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions"><span class="ltx_text ltx_ref_tag">2</span></a> and Table <a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#S3.T3" title="Table 3 ‣ 3.1 Data ‣ 3 Experiments ‣ Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions"><span class="ltx_text ltx_ref_tag">3</span></a> indicates that LLMs face challenges not only with predicting gender-neutral names but also with dynamically changing gender associations for the same names. This issue likely originates from the inherent limitations of the pre-training approach and data used in LLMs. These models tend to memorize training data, which lacks inferential capability, rather than adapting well to names with evolving gender labels over time. Overall, most LLMs better predict female names than male names, and the accuracy of gender prediction is higher for English-based first names in the US and Canada SSA datasets than in the France SSA.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS0.SSS0.Px5">
<h4 class="ltx_title ltx_title_paragraph">Suggestions for practitioners</h4>
<div class="ltx_para" id="S4.SS0.SSS0.Px5.p1">
<p class="ltx_p" id="S4.SS0.SSS0.Px5.p1.1">As we have highlighted in this work, LLMs have a biased and in-accurate understanding of names and hence we should be careful about using them for gender inference related tasks, even at an aggregate level. Furthermore, when dealing with temporal and especially historical data, LLM’s name-based gender understanding may be limited and hence their usage for aggregated data analysis is likely to lead to incorrect results.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">This study underscores the limited performance of LLMs as classifiers in predicting gender-neutral names compared to binary genders and the challenges posed by the inherent biases in the datasets used to train LLMs, which may lead to unbalanced gender prediction results. By introducing a “neutral” category, we have taken a step towards more inclusive gender prediction. However, our findings revealed that LLMs may struggle recognizing gender-neutral names, especially for non-English first names. Despite efforts to enhance LLMs’ predictive capabilities by including temporal data, there were no meaningful improvements in gender prediction accuracy, especially for gender-neutral names. This suggests a fundamental limitation of current LLMs and training datasets when adapting to the complexities of gender identities. In future studies, we plan to expand our work by using more inclusive gender categories (e.g., cisgender and transgender) to thoroughly assess gender bias in LLMs across various NLP downstream tasks, including sentiment analysis and coreference resolution.
</p>
</div>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Bias Statement</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">Our study investigates gender bias in LLMs and fine-tuned foundation language models when predicting the gender of names by introducing a “neutral” category alongside the traditional binary classification of male and female gender labels. Traditionally, the binary gender classification system has not accounted for gender-neutral names. This exclusion arises from imbalanced training data and fixed representations of gender (i.e., female and male), causing LLMs to be prone to classify names into binary gender labels.</p>
</div>
<div class="ltx_para" id="S6.p2">
<p class="ltx_p" id="S6.p2.1">When using LLMs in name-based gender prediction tasks, they generally consider only two gender labels, thereby restricting the scope of gender-related analysis. This binary approach perpetuates potential biases in areas associated with fixed gender representations <cite class="ltx_cite ltx_citemacro_cite">Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib18" title="">2023</a>); Teich et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib35" title="">2022</a>)</cite>, e.g., how male and female authors express sentiment <cite class="ltx_cite ltx_citemacro_cite">Jentzsch and Turan (<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib11" title="">2022</a>)</cite> or how male and female researchers face different challenges in academia <cite class="ltx_cite ltx_citemacro_cite">VanHelene et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib38" title="">2024</a>)</cite>. However, this binary labeling of gender overlooks individuals with gender-neutral names, which could encompass both female and male identities, thereby missing valuable insights from a more inclusive perspective. Our work considers more inclusive gender labeling by examining the accuracy of gender-neutral name predictions using LLMs while also providing insights into factors that may lead to biased gender prediction results (i.e., poorer prediction for neutral names compared to binary names) in these models.</p>
</div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">Limitations</h2>
<div class="ltx_para" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">Our study’s limitations are as follows:
(1) Our assessment was limited to specific countries, i.e., the US, Canada, and France, not considering a broad spectrum of countries and cultures, particularly in Asia and Africa. This limitation may affect the generalizability of our findings across different cultural and linguistic contexts.
(2) The dataset preparation involved a subjective threshold to determine gender-neutral names, defined as names where the gender frequency for both males and females is greater than 10%. This choice may impact the reliability and consistency of the presented findings.
(3) The prompt templates employed for interacting with LLMs were not optimized, which may lead to variations in results with different prompt formulations. This indicates a potential variability in LLMs’ performance that could impact the robustness of our conclusions, as LLMs are sensitive to prompt design.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">AI@Meta (2024)</span>
<span class="ltx_bibblock">
AI@Meta. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://github.com/meta-llama/llama3/blob/main/MODEL_CARD.md" title="">Llama 3 model card</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Alexopoulos et al. (2023)</span>
<span class="ltx_bibblock">
Michelle Alexopoulos, Kelly Lyons, Kaushar Mahetaji, Marcus Emmanuel Barnes, and Rogan Gutwillinger. 2023.

</span>
<span class="ltx_bibblock">Gender inference: can chatgpt outperform common commercial tools?

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">arXiv preprint arXiv:2312.00805</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Anthropic (2024)</span>
<span class="ltx_bibblock">
AI Anthropic. 2024.

</span>
<span class="ltx_bibblock">The claude 3 model family: Opus, sonnet, haiku.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Claude-3 Model Card</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Barry III and Harper (2014)</span>
<span class="ltx_bibblock">
Herbert Barry III and Aylene S Harper. 2014.

</span>
<span class="ltx_bibblock">Unisex names for babies born in pennsylvania 1990–2010.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">Names</em>, 62(1):13–22.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Blevins and Mullen (2015)</span>
<span class="ltx_bibblock">
Cameron Blevins and Lincoln Mullen. 2015.

</span>
<span class="ltx_bibblock">Jane, john… leslie? a historical method for algorithmic gender prediction.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">DHQ: Digital Humanities Quarterly</em>, 9(3).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chatterjee and Werner (2021)</span>
<span class="ltx_bibblock">
Paula Chatterjee and Rachel M Werner. 2021.

</span>
<span class="ltx_bibblock">Gender disparity in citations in high-impact journal articles.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">JAMA Network Open</em>, 4(7):e2114509–e2114509.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Devlin et al. (2019)</span>
<span class="ltx_bibblock">
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/N19-1423" title="">BERT: Pre-training of deep bidirectional transformers for language understanding</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</em>, pages 4171–4186, Minneapolis, Minnesota. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Diesner and Carley (2009)</span>
<span class="ltx_bibblock">
Jana Diesner and Kathleen M Carley. 2009.

</span>
<span class="ltx_bibblock">He says, she says. pat says, tricia says. how much reference resolution matters for entity extraction, relation extraction, and social network analysis.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">2009 IEEE Symposium on Computational Intelligence for Security and Defense Applications</em>, pages 1–8. IEEE.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dinh et al. (2023)</span>
<span class="ltx_bibblock">
Ly Dinh, Janina Sarol, Sullam Jeoung, and Jana Diesner. 2023.

</span>
<span class="ltx_bibblock">Are we projecting gender biases to ungendered things? differences in referring to female versus male named hurricanes in 33 years of news coverage.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">Computational Communication Research</em>, 5(1):141.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et al. (2021)</span>
<span class="ltx_bibblock">
Yifan Hu, Changwei Hu, Thanh Tran, Tejaswi Kasturi, Elizabeth Joseph, and Matt Gillingham. 2021.

</span>
<span class="ltx_bibblock">What’s in a name?–gender classification of names with character based machine learning models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">Data Mining and Knowledge Discovery</em>, 35(4):1537–1563.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jentzsch and Turan (2022)</span>
<span class="ltx_bibblock">
Sophie Jentzsch and Cigdem Turan. 2022.

</span>
<span class="ltx_bibblock">Gender bias in bert-measuring and analysing biases through sentiment rating in a realistic downstream classification task.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">Proceedings of the 4th Workshop on Gender Bias in Natural Language Processing (GeBNLP)</em>, pages 184–199.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jia and Zhao (2019)</span>
<span class="ltx_bibblock">
Jizheng Jia and Qiyang Zhao. 2019.

</span>
<span class="ltx_bibblock">Gender prediction based on chinese name.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">Natural Language Processing and Chinese Computing: 8th CCF International Conference, NLPCC 2019, Dunhuang, China, October 9–14, 2019, Proceedings, Part II 8</em>, pages 676–683. Springer.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et al. (2024)</span>
<span class="ltx_bibblock">
Albert Q Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur Mensch, Blanche Savary, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Emma Bou Hanna, Florian Bressand, et al. 2024.

</span>
<span class="ltx_bibblock">Mixtral of experts.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">arXiv preprint arXiv:2401.04088</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kotek et al. (2023)</span>
<span class="ltx_bibblock">
Hadas Kotek, Rikker Dockum, and David Sun. 2023.

</span>
<span class="ltx_bibblock">Gender bias and stereotypes in large language models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">Proceedings of The ACM Collective Intelligence Conference</em>, pages 12–24.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Krstovski et al. (2023)</span>
<span class="ltx_bibblock">
Kriste Krstovski, Yao Lu, and Ye Xu. 2023.

</span>
<span class="ltx_bibblock">Inferring gender from name: a large scale performance evaluation study.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">arXiv preprint arXiv:2308.12381</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Larivière et al. (2013)</span>
<span class="ltx_bibblock">
Vincent Larivière, Chaoqun Ni, Yves Gingras, Blaise Cronin, and Cassidy R Sugimoto. 2013.

</span>
<span class="ltx_bibblock">Bibliometrics: Global gender disparities in science.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">Nature</em>, 504(7479):211–213.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Larivière et al. (2013)</span>
<span class="ltx_bibblock">
Vincent Larivière, Chaoqun Ni, Yves Gingras, Blaise Cronin, and Cassidy R. Sugimoto. 2013.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1038/504211a" title="">Bibliometrics: Global gender disparities in science</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">Nature</em>, 504(7479):211–213.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2023)</span>
<span class="ltx_bibblock">
Fengyuan Liu, Petter Holme, Matteo Chiesa, Bedoor AlShebli, and Talal Rahwan. 2023.

</span>
<span class="ltx_bibblock">Gender inequality and self-publication are common among academic editors.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">Nature human behaviour</em>, 7(3):353–364.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu and Ruths (2013)</span>
<span class="ltx_bibblock">
Wendy Liu and Derek Ruths. 2013.

</span>
<span class="ltx_bibblock">What’s in a name? using first names as features for gender inference in twitter.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">2013 AAAI spring symposium series</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2019)</span>
<span class="ltx_bibblock">
Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019.

</span>
<span class="ltx_bibblock">Roberta: A robustly optimized bert pretraining approach.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">arXiv preprint arXiv:1907.11692</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ma et al. (2020)</span>
<span class="ltx_bibblock">
Wentao Ma, Yiming Cui, Chenglei Si, Ting Liu, Shijin Wang, and Guoping Hu. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2020.coling-main.4" title="">CharBERT: Character-aware pre-trained language model</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">Proceedings of the 28th International Conference on Computational Linguistics</em>, pages 39–50, Barcelona, Spain (Online). International Committee on Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Michelle et al. (2023)</span>
<span class="ltx_bibblock">
Alexopoulos Michelle, Lyons Kelly, Mahetaji Kaushar, Barnes Marcus Emmanuel, and Gutwillinger Rogan. 2023.

</span>
<span class="ltx_bibblock">Gender inference: Can chatgpt outperform common commercial tools?

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">Proceedings of the 33rd Annual International Conference on Computer Science and Software Engineering</em>, pages 161–166.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Misa (2022)</span>
<span class="ltx_bibblock">
Thomas J Misa. 2022.

</span>
<span class="ltx_bibblock">Gender bias in big data analysis.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">Information &amp; Culture</em>, 57(3):283–306.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mishra et al. (2018)</span>
<span class="ltx_bibblock">
Shubhanshu Mishra, Brent D Fegley, Jana Diesner, and Vetle I Torvik. 2018.

</span>
<span class="ltx_bibblock">Self-citation is the hallmark of productive authors, of any gender.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">PloS one</em>, 13(9):e0195773.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mishra et al. (2020)</span>
<span class="ltx_bibblock">
Shubhanshu Mishra, Sijun He, and Luca Belli. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.48550/arXiv.2008.03415" title="">Assessing demographic bias in named entity recognition</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">Proceedings of the KG-BIAS Workshop 2020 at AKBC 2020</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2024a)</span>
<span class="ltx_bibblock">
OpenAI. 2024a.

</span>
<span class="ltx_bibblock">Chatgpt.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openai.com/chatgpt/" title="">https://openai.com/chatgpt/</a>.

</span>
<span class="ltx_bibblock">Accessed: 2024-05-20.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2024b)</span>
<span class="ltx_bibblock">
OpenAI. 2024b.

</span>
<span class="ltx_bibblock">Gpt-3.5.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://platform.openai.com/docs/models/gpt-3-5-turbo" title="">https://platform.openai.com/docs/models/gpt-3-5-turbo</a>.

</span>
<span class="ltx_bibblock">Accessed: 2024-05-21.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pham and Nguyen (2023)</span>
<span class="ltx_bibblock">
Duong Tien Pham and Luan Thanh Nguyen. 2023.

</span>
<span class="ltx_bibblock">Gendec: A machine learning-based framework for gender detection from japanese names.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">arXiv preprint arXiv:2311.11001</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pilkina and Lovakov (2022)</span>
<span class="ltx_bibblock">
Marina Pilkina and Andrey Lovakov. 2022.

</span>
<span class="ltx_bibblock">Gender disparities in russian academia: A bibliometric analysis.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">Scientometrics</em>, 127(6):3577–3591.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pinheiro et al. (2022)</span>
<span class="ltx_bibblock">
Henrique Pinheiro, Matt Durning, and David Campbell. 2022.

</span>
<span class="ltx_bibblock">Do women undertake interdisciplinary research more than men, and do self-citations bias observed differences?

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">Quantitative science studies</em>, 3(2):363–392.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rhue et al. (2024)</span>
<span class="ltx_bibblock">
Lauren Rhue, Sofie Goethals, and Arun Sundararajan. 2024.

</span>
<span class="ltx_bibblock">Evaluating llms for gender disparities in notable persons.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">arXiv preprint arXiv:2403.09148</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ross et al. (2022)</span>
<span class="ltx_bibblock">
Matthew B Ross, Britta M Glennon, Raviv Murciano-Goroff, Enrico G Berkes, Bruce A Weinberg, and Julia I Lane. 2022.

</span>
<span class="ltx_bibblock">Women are credited less in science than men.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">Nature</em>, 608(7921):135–145.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Suresh and Guttag (2021)</span>
<span class="ltx_bibblock">
Harini Suresh and John Guttag. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1145/3465416.3483305" title="">A framework for understanding sources of harm throughout the machine learning life cycle</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">Proceedings of the 1st ACM Conference on Equity and Access in Algorithms, Mechanisms, and Optimization</em>, EAAMO ’21, New York, NY, USA. Association for Computing Machinery.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tang et al. (2011)</span>
<span class="ltx_bibblock">
Cong Tang, Keith Ross, Nitesh Saxena, and Ruichuan Chen. 2011.

</span>
<span class="ltx_bibblock">What’s in a name: A study of names, gender inference, and gender behavior in facebook.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">Database Systems for Adanced Applications: 16th International Conference, DASFAA 2011, International Workshops: GDB, SIM3, FlashDB, SNSMW, DaMEN, DQIS, Hong Kong, China, April 22-25, 2011. Proceedings 16</em>, pages 344–356. Springer.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Teich et al. (2022)</span>
<span class="ltx_bibblock">
Erin G Teich, Jason Z Kim, Christopher W Lynn, Samantha C Simon, Andrei A Klishin, Karol P Szymula, Pragya Srivastava, Lee C Bassett, Perry Zurn, Jordan D Dworkin, et al. 2022.

</span>
<span class="ltx_bibblock">Citation inequity and gendered citation practices in contemporary physics.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">Nature Physics</em>, 18(10):1161–1170.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">To et al. (2020)</span>
<span class="ltx_bibblock">
Huy Quoc To, Kiet Van Nguyen, Ngan Luu-Thuy Nguyen, and Anh Gia-Tuan Nguyen. 2020.

</span>
<span class="ltx_bibblock">Gender prediction based on vietnamese names with machine learning techniques.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">Proceedings of the 4th International Conference on Natural Language Processing and Information Retrieval</em>, pages 55–60.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et al. (2023)</span>
<span class="ltx_bibblock">
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. 2023.

</span>
<span class="ltx_bibblock">Llama 2: Open foundation and fine-tuned chat models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">arXiv preprint arXiv:2307.09288</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">VanHelene et al. (2024)</span>
<span class="ltx_bibblock">
Alexander D VanHelene, Ishaani Khatri, C Beau Hilton, Sanjay Mishra, Ece D Gamsiz Uzun, and Jeremy Warner. 2024.

</span>
<span class="ltx_bibblock">Inferring gender from first names: Comparing the accuracy of genderize, gender api, and the gender r package on authors of diverse nationality.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">medRxiv</em>, pages 2024–01.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yee et al. (2021)</span>
<span class="ltx_bibblock">
Kyra Yee, Uthaipon Tantipongpipat, and Shubhanshu Mishra. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1145/3479594" title="">Image cropping on twitter: Fairness metrics, their limitations, and the importance of representation, design, and agency</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">Proc. ACM Hum.-Comput. Interact.</em>, 5(CSCW2).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al. (2022)</span>
<span class="ltx_bibblock">
Yongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy Ba. 2022.

</span>
<span class="ltx_bibblock">Large language models are human-level prompt engineers.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">arXiv preprint arXiv:2211.01910</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu et al. (2023)</span>
<span class="ltx_bibblock">
Kaijie Zhu, Jindong Wang, Jiaheng Zhou, Zichen Wang, Hao Chen, Yidong Wang, Linyi Yang, Wei Ye, Neil Zhenqiang Gong, Yue Zhang, et al. 2023.

</span>
<span class="ltx_bibblock">Promptbench: Towards evaluating the robustness of large language models on adversarial prompts.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">arXiv preprint arXiv:2306.04528</em>.

</span>
</li>
</ul>
</section>
<figure class="ltx_table" id="A0.T4">
<div class="ltx_inline-block ltx_transformed_outer" id="A0.T4.1" style="width:244.3pt;height:53.3pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-42.9pt,9.4pt) scale(0.74,0.74) ;">
<table class="ltx_tabular ltx_align_middle" id="A0.T4.1.1">
<tr class="ltx_tr" id="A0.T4.1.1.1">
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T4.1.1.1.1"><span class="ltx_text ltx_font_bold" id="A0.T4.1.1.1.1.1">Datasets</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T4.1.1.1.2"><span class="ltx_text ltx_font_bold" id="A0.T4.1.1.1.2.1"># Names</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T4.1.1.1.3"><span class="ltx_text ltx_font_bold" id="A0.T4.1.1.1.3.1">Year span</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T4.1.1.1.4"><span class="ltx_text ltx_font_bold" id="A0.T4.1.1.1.4.1">Train</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T4.1.1.1.5"><span class="ltx_text ltx_font_bold" id="A0.T4.1.1.1.5.1">Val</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T4.1.1.1.6"><span class="ltx_text ltx_font_bold" id="A0.T4.1.1.1.6.1">Test</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T4.1.1.1.7"><span class="ltx_text ltx_font_bold" id="A0.T4.1.1.1.7.1">Overall</span></td>
</tr>
<tr class="ltx_tr" id="A0.T4.1.1.2">
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T4.1.1.2.1">US SSA</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T4.1.1.2.2">300</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T4.1.1.2.3">1914 - 2022</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T4.1.1.2.4">78480</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T4.1.1.2.5">9810</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T4.1.1.2.6">9810</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T4.1.1.2.7">98100</td>
</tr>
<tr class="ltx_tr" id="A0.T4.1.1.3">
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T4.1.1.3.1">Canada SSA</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T4.1.1.3.2">273</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T4.1.1.3.3">2013 - 2020</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T4.1.1.3.4">5232</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T4.1.1.3.5">648</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T4.1.1.3.6">672</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T4.1.1.3.7">6552</td>
</tr>
<tr class="ltx_tr" id="A0.T4.1.1.4">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A0.T4.1.1.4.1">France SSA</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A0.T4.1.1.4.2">32</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A0.T4.1.1.4.3">1908 - 2022</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A0.T4.1.1.4.4">8625</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A0.T4.1.1.4.5">1035</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A0.T4.1.1.4.6">1380</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A0.T4.1.1.4.7">11040</td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4: </span>
Statistics of balanced SSA datasets. # Names represent the number of names per gender per year.
</figcaption>
</figure>
<figure class="ltx_table" id="A0.T5">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A0.T5.1">
<tr class="ltx_tr" id="A0.T5.1.1">
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T5.1.1.1"><span class="ltx_text ltx_font_bold" id="A0.T5.1.1.1.1">Datasets</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T5.1.1.2"><span class="ltx_text ltx_font_bold" id="A0.T5.1.1.2.1"># Neutral</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T5.1.1.3"><span class="ltx_text ltx_font_bold" id="A0.T5.1.1.3.1"># Male</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A0.T5.1.1.4"><span class="ltx_text ltx_font_bold" id="A0.T5.1.1.4.1"># Female</span></td>
</tr>
<tr class="ltx_tr" id="A0.T5.1.2">
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T5.1.2.1">US SSA</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T5.1.2.2">2321</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T5.1.2.3">1044</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T5.1.2.4">631</td>
</tr>
<tr class="ltx_tr" id="A0.T5.1.3">
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T5.1.3.1">Canada SSA</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T5.1.3.2">1084</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T5.1.3.3">110</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A0.T5.1.3.4">114</td>
</tr>
<tr class="ltx_tr" id="A0.T5.1.4">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A0.T5.1.4.1">France SSA</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A0.T5.1.4.2">339</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A0.T5.1.4.3">59</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A0.T5.1.4.4">51</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>
Statistics of dynamic gender label datasets.
</figcaption>
</figure>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Dataset Statistics</h2>
<div class="ltx_para" id="A1.p1">
<p class="ltx_p" id="A1.p1.1">Overall training and testing dataset statistics were reported in Table <a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#A0.T4" title="Table 4 ‣ Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions"><span class="ltx_text ltx_ref_tag">4</span></a>. We split the train/val/test sets into 80%/10%/10% of the data. We found that gender-neutral names have increased in both the US and Canada SSA datasets over time and surged in more recent years (i.e., after 2000).</p>
</div>
<div class="ltx_para" id="A1.p2">
<p class="ltx_p" id="A1.p2.1">Dataset statistics of dynamic gender labels extracted from the three datasets’ test sets are reported in Table <a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#A0.T5" title="Table 5 ‣ Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions"><span class="ltx_text ltx_ref_tag">5</span></a>. Note that the Canada SSA dataset only contained 63 first names whose gender labels changed over time in the test set and 50 in the validation set, which was insufficient for evaluating LLMs’ performance in dynamic gender prediction. Therefore, we used the training set to extract the names with dynamic gender labels for the Canada SSA dataset.</p>
</div>
</section>
<section class="ltx_appendix" id="A2">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Experimental Settings</h2>
<div class="ltx_para" id="A2.p1">
<p class="ltx_p" id="A2.p1.1">In foundation language model fine-tuning, we set the maximum length of the tokenizer to 32 across all three models since the results won’t change with an increase in the maximum input length. We fine-tuned foundation language models through 7 epochs, and the batch size for either training or validation was 128. We set the warm-up ratio to 0.1 and the learning rate toas 2e-5. The foundation language models included BERT (<span class="ltx_text ltx_font_typewriter" id="A2.p1.1.1">bert-base-cased</span>), RoBERTa (<span class="ltx_text ltx_font_typewriter" id="A2.p1.1.2">roberta-base</span>), and CharRoBERTa. We chose the cased models because they are case-sensitive and can distinguish names such as “huntley” and “Huntley”.</p>
</div>
<div class="ltx_para" id="A2.p2">
<p class="ltx_p" id="A2.p2.1">For the model settings of LLMs, we applied GPT-3.5 (<span class="ltx_text ltx_font_typewriter" id="A2.p2.1.1">gpt-3.5-turbo-instruct</span>), Llama 2 (<span class="ltx_text ltx_font_typewriter" id="A2.p2.1.2">meta/llama-2-70b-chat</span>), Llama 3 (<span class="ltx_text ltx_font_typewriter" id="A2.p2.1.3">meta/meta-llama-3-70b-instruct</span>), Mixtral-8x7B (<span class="ltx_text ltx_font_typewriter" id="A2.p2.1.4">mixtral-8x7b-instruct-v0.1</span>), and Claude 3 Haiku (<span class="ltx_text ltx_font_typewriter" id="A2.p2.1.5">claude-3-haiku-20240307</span>) for name gender prediction tasks.</p>
</div>
<figure class="ltx_table" id="A2.T6">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A2.T6.1" style="width:453.0pt;height:32743.4pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-25.2pt,1819.1pt) scale(0.9,0.9) ;">
<table class="ltx_tabular ltx_align_middle" id="A2.T6.1.1">
<tr class="ltx_tr" id="A2.T6.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="A2.T6.1.1.1.1"><span class="ltx_text ltx_font_bold" id="A2.T6.1.1.1.1.1">Experimental Setting</span></td>
<td class="ltx_td ltx_align_justify ltx_border_tt" id="A2.T6.1.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="A2.T6.1.1.1.2.1">
<span class="ltx_p" id="A2.T6.1.1.1.2.1.1"><span class="ltx_text ltx_font_bold" id="A2.T6.1.1.1.2.1.1.1">RQ 1</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_border_tt" id="A2.T6.1.1.1.3">
<span class="ltx_inline-block ltx_align_top" id="A2.T6.1.1.1.3.1">
<span class="ltx_p" id="A2.T6.1.1.1.3.1.1"><span class="ltx_text ltx_font_bold" id="A2.T6.1.1.1.3.1.1.1">RQ 2</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A2.T6.1.1.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="A2.T6.1.1.2.1">0-shot</td>
<td class="ltx_td ltx_align_justify ltx_border_t" id="A2.T6.1.1.2.2">
<span class="ltx_inline-block ltx_align_top" id="A2.T6.1.1.2.2.1">
<span class="ltx_p" id="A2.T6.1.1.2.2.1.1">Predict the gender association of the given name. <span class="ltx_text ltx_font_typewriter" id="A2.T6.1.1.2.2.1.1.1">\n</span>Use the following labels for classification: <span class="ltx_text ltx_font_typewriter" id="A2.T6.1.1.2.2.1.1.2">\n</span>Male: The name is predominantly associated with males. <span class="ltx_text ltx_font_typewriter" id="A2.T6.1.1.2.2.1.1.3">\n</span>Female: The name is predominantly associated with females. <span class="ltx_text ltx_font_typewriter" id="A2.T6.1.1.2.2.1.1.4">\n</span>Neutral: The name is not predominantly associated with any single gender and is considered neutral. <span class="ltx_text ltx_font_typewriter" id="A2.T6.1.1.2.2.1.1.5">\n</span>Your outputs should be all in lowercase and can only output gender from male, female, or neutral. <span class="ltx_text ltx_font_typewriter" id="A2.T6.1.1.2.2.1.1.6">\n</span>Name: + <span class="ltx_text ltx_font_typewriter" id="A2.T6.1.1.2.2.1.1.7">{name}</span> + <span class="ltx_text ltx_font_typewriter" id="A2.T6.1.1.2.2.1.1.8">\n</span>Gender:</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_border_t" id="A2.T6.1.1.2.3">
<span class="ltx_inline-block ltx_align_top" id="A2.T6.1.1.2.3.1">
<span class="ltx_p" id="A2.T6.1.1.2.3.1.1">Predict the gender association of the given name, considering the year of birth as an additional reference. <span class="ltx_text ltx_font_typewriter" id="A2.T6.1.1.2.3.1.1.1">\n</span>The provided names appear more than once across different years of birth as they may be labeled in different genders given the change in the predominant gender of names. <span class="ltx_text ltx_font_typewriter" id="A2.T6.1.1.2.3.1.1.2">\n</span>Use the following labels for classification: <span class="ltx_text ltx_font_typewriter" id="A2.T6.1.1.2.3.1.1.3">\n</span>Male: The name is predominantly associated with males. <span class="ltx_text ltx_font_typewriter" id="A2.T6.1.1.2.3.1.1.4">\n</span>Female: The name is predominantly associated with females. <span class="ltx_text ltx_font_typewriter" id="A2.T6.1.1.2.3.1.1.5">\n</span>Neutral: The name is not predominantly associated with any single gender and is considered neutral. <span class="ltx_text ltx_font_typewriter" id="A2.T6.1.1.2.3.1.1.6">\n</span>Your outputs should be all in lowercase and can only output gender from male, female, or neutral. <span class="ltx_text ltx_font_typewriter" id="A2.T6.1.1.2.3.1.1.7">\n</span>Name: + <span class="ltx_text ltx_font_typewriter" id="A2.T6.1.1.2.3.1.1.8">{name}</span> + <span class="ltx_text ltx_font_typewriter" id="A2.T6.1.1.2.3.1.1.9">\n</span>Year of Birth: + <span class="ltx_text ltx_font_typewriter" id="A2.T6.1.1.2.3.1.1.10">{year}</span> + <span class="ltx_text ltx_font_typewriter" id="A2.T6.1.1.2.3.1.1.11">\n</span>Gender:</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A2.T6.1.1.3">
<td class="ltx_td ltx_align_left ltx_border_t" id="A2.T6.1.1.3.1">5-shot (US SSA)</td>
<td class="ltx_td ltx_align_justify ltx_border_t" id="A2.T6.1.1.3.2">
<span class="ltx_inline-block ltx_align_top" id="A2.T6.1.1.3.2.1">
<span class="ltx_p" id="A2.T6.1.1.3.2.1.1">Predict the gender association of the given name. <span class="ltx_text ltx_font_typewriter" id="A2.T6.1.1.3.2.1.1.1">\n</span>The provided names appear more than once. <span class="ltx_text ltx_font_typewriter" id="A2.T6.1.1.3.2.1.1.2">\n</span>Use the following labels for classification: <span class="ltx_text ltx_font_typewriter" id="A2.T6.1.1.3.2.1.1.3">\n</span>Male: The name is predominantly associated with males. <span class="ltx_text ltx_font_typewriter" id="A2.T6.1.1.3.2.1.1.4">\n</span>Female: The name is predominantly associated with females. <span class="ltx_text ltx_font_typewriter" id="A2.T6.1.1.3.2.1.1.5">\n</span>Neutral: The name is not predominantly associated with any single gender and is considered neutral. <span class="ltx_text ltx_font_typewriter" id="A2.T6.1.1.3.2.1.1.6">\n</span>Please note that first names can be labeled in different genders over time. <span class="ltx_text ltx_font_typewriter" id="A2.T6.1.1.3.2.1.1.7">\n</span>Here are five pairs of examples of first names and genders: <span class="ltx_text ltx_font_typewriter" id="A2.T6.1.1.3.2.1.1.8">\n</span>Pair 1: Name: Christie, Gender: Neutral; Name: Christie, Gender: Female
Pair 2: Name: Jan, Gender: Neutral; Name: Jan, Gender: Male
Pair 3: Name: Bee, Gender: Female; Name: Bee, Gender: Neutral
Pair 4: Name: Kasen, Gender: Neutral; Name: Kasen, Gender: Male
Pair 5: Name: Mel, Gender: Male; Name: Mel, Gender: Neutral
<span class="ltx_text ltx_font_typewriter" id="A2.T6.1.1.3.2.1.1.9">\n</span>Your outputs should be all in lowercase and can only output gender from male, female, or neutral. <span class="ltx_text ltx_font_typewriter" id="A2.T6.1.1.3.2.1.1.10">\n</span>Name: + <span class="ltx_text ltx_font_typewriter" id="A2.T6.1.1.3.2.1.1.11">{name}</span> + <span class="ltx_text ltx_font_typewriter" id="A2.T6.1.1.3.2.1.1.12">\n</span>Gender:</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_border_t" id="A2.T6.1.1.3.3">
<span class="ltx_inline-block ltx_align_top" id="A2.T6.1.1.3.3.1">
<span class="ltx_p" id="A2.T6.1.1.3.3.1.1">Predict the gender association of the given name, considering the year of birth as an additional reference. <span class="ltx_text ltx_font_typewriter" id="A2.T6.1.1.3.3.1.1.1">\n</span>The provided names appear more than once. <span class="ltx_text ltx_font_typewriter" id="A2.T6.1.1.3.3.1.1.2">\n</span>Use the following labels for classification: <span class="ltx_text ltx_font_typewriter" id="A2.T6.1.1.3.3.1.1.3">\n</span>Male: The name is predominantly associated with males. <span class="ltx_text ltx_font_typewriter" id="A2.T6.1.1.3.3.1.1.4">\n</span>Female: The name is predominantly associated with females. <span class="ltx_text ltx_font_typewriter" id="A2.T6.1.1.3.3.1.1.5">\n</span>Neutral: The name is not predominantly associated with any single gender and is considered neutral. <span class="ltx_text ltx_font_typewriter" id="A2.T6.1.1.3.3.1.1.6">\n</span>Please note that first names can be labeled in different genders over time. <span class="ltx_text ltx_font_typewriter" id="A2.T6.1.1.3.3.1.1.7">\n</span>Here are five pairs of examples of first names and genders: <span class="ltx_text ltx_font_typewriter" id="A2.T6.1.1.3.3.1.1.8">\n</span>Pair 1: Name: Christie, Year of Birth: 1919, Gender: Neutral; Name: Christie, Year of Birth: 1949, Gender: Female
Pair 2: Name: Jan, Year of Birth: 1966, Gender: Neutral; Name: Jan, Year of Birth: 2012, Gender: Male
Pair 3: Name: Bee, Year of Birth: 1952, Gender: Female; Name: Bee, Year of Birth: 1989, Gender: Neutral
Pair 4: Name: Kasen, Year of Birth: 2000, Gender: Neutral; Name: Kasen, Year of Birth: 2006, Gender: Male
Pair 5: Name: Mel, Year of Birth: 1947, Gender: Male; Name: Mel, Year of Birth: 2007, Gender: Neutral
<span class="ltx_text ltx_font_typewriter" id="A2.T6.1.1.3.3.1.1.9">\n</span>Your outputs should be all in lowercase and can only output gender from male, female, or neutral. <span class="ltx_text ltx_font_typewriter" id="A2.T6.1.1.3.3.1.1.10">\n</span>Name: + <span class="ltx_text ltx_font_typewriter" id="A2.T6.1.1.3.3.1.1.11">{name}</span> + <span class="ltx_text ltx_font_typewriter" id="A2.T6.1.1.3.3.1.1.12">\n</span>Year of Birth: + <span class="ltx_text ltx_font_typewriter" id="A2.T6.1.1.3.3.1.1.13">{year}</span> + <span class="ltx_text ltx_font_typewriter" id="A2.T6.1.1.3.3.1.1.14">\n</span>Gender:</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A2.T6.1.1.4">
<td class="ltx_td ltx_align_left" id="A2.T6.1.1.4.1">5-shot (Canada SSA)</td>
<td class="ltx_td ltx_align_justify" id="A2.T6.1.1.4.2">
<span class="ltx_inline-block ltx_align_top" id="A2.T6.1.1.4.2.1">
<span class="ltx_p" id="A2.T6.1.1.4.2.1.1">…Pair 1: Name: Nyjah, Gender: Neutral; Name: Nyjah, Gender: Male
Pair 2: Name: Kendell, Gender: Neutral; Name: Kendell, Gender: Male
Pair 3: Name: Arshia, Gender: Neutral; Name: Arshia, Gender: Male
Pair 4: Name: Lennix, Gender: Neutral; Name: Lennix, Gender: Female
Pair 5: Name: Kirat, Gender: Male; Name: Kirat, Gender: Neutral…</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="A2.T6.1.1.4.3">
<span class="ltx_inline-block ltx_align_top" id="A2.T6.1.1.4.3.1">
<span class="ltx_p" id="A2.T6.1.1.4.3.1.1">…Pair 1: Name: Nyjah, Year of Birth: 2014, Gender: Neutral; Name: Nyjah, Year of Birth: 2016, Gender: Male
Pair 2: Name: Kendell, Year of Birth: 2014, Gender: Neutral; Name: Kendell, Year of Birth: 2016, Gender: Male
Pair 3: Name: Arshia, Year of Birth: 2014, Gender: Neutral; Name: Arshia, Year of Birth: 2018, Gender: Male
Pair 4: Name: Lennix, Year of Birth: 2013, Gender: Neutral; Name: Lennix, Year of Birth: 2018, Gender: Female
Pair 5: Name: Kirat, Year of Birth: 2013, Gender: Male; Name: Kirat, Year of Birth: 2014, Gender: Neutral…</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A2.T6.1.1.5">
<td class="ltx_td ltx_align_left ltx_border_bb" id="A2.T6.1.1.5.1">5-shot (France SSA)</td>
<td class="ltx_td ltx_align_justify ltx_border_bb" id="A2.T6.1.1.5.2">
<span class="ltx_inline-block ltx_align_top" id="A2.T6.1.1.5.2.1">
<span class="ltx_p" id="A2.T6.1.1.5.2.1.1">…Pair 1: Name: CARMEL, Gender: Male; Name: CARMEL, Gender: Neutral
Pair 2: Name: LIE, Gender: Male; Name: LIE, Gender: Neutral Pair 3: Name: JESSY, Gender: Female; Name: JESSY, Gender: Neutral
Pair 4: Name: ANH, Gender: Neutral; Name: ANH, Gender: Male
Pair 5: Name: FIDELE, Gender: Neutral; Name: FIDELE, Gender: Female…</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_border_bb" id="A2.T6.1.1.5.3">
<span class="ltx_inline-block ltx_align_top" id="A2.T6.1.1.5.3.1">
<span class="ltx_p" id="A2.T6.1.1.5.3.1.1">…Pair 1: Name: CARMEL, Year of Birth: 1920, Gender: Male; Name: CARMEL, Year of Birth: 1951, Gender: Neutral
Pair 2: Name: LIE, Year of Birth: 1922, Gender: Male; Name: LIE, Year of Birth: 1931, Gender: Neutral
Pair 3: Name: JESSY, Year of Birth: 1960, Gender: Female; Name: JESSY, Year of Birth: 1975, Gender: Neutral
Pair 4: Name: ANH, Year of Birth: 1995, Gender: Neutral; Name: ANH, Year of Birth: 2006, Gender: Male
Pair 5: Name: FIDELE, Year of Birth: 1918, Gender: Neutral; Name: FIDELE, Year of Birth: 1945, Gender: Female…</span>
</span>
</td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6: </span>Task-oriented prompt templates of LLMs in 0-shot and 5-shot settings for RQ 1 (w/o birth year) and RQ 2 (w/ birth year). For clarity, we report only the 5-shot example pairs for Canada and France’s SSA datasets, as the prompt templates are the same as those used for the 5-shot US SSA dataset.</figcaption>
</figure>
</section>
<section class="ltx_appendix" id="A3">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>LLMs for Gender Prediction</h2>
<div class="ltx_para" id="A3.p1">
<p class="ltx_p" id="A3.p1.1">We applied the 5 LLMs for name-based gender prediction using three country-level SSA datasets.</p>
</div>
<div class="ltx_para" id="A3.p2">
<p class="ltx_p" id="A3.p2.1"><span class="ltx_text ltx_font_bold" id="A3.p2.1.1">GPT-3.5.</span> GPT-3.5 is an autoregressive generation model developed by OpenAI <cite class="ltx_cite ltx_citemacro_cite">OpenAI (<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib27" title="">2024b</a>)</cite>. The model (<span class="ltx_text ltx_font_typewriter" id="A3.p2.1.2">gpt-3.5-turbo-instruct</span>) has been tuned through an instruction-tuning technique and aims to generate human-preferred responses.</p>
</div>
<div class="ltx_para" id="A3.p3">
<p class="ltx_p" id="A3.p3.1"><span class="ltx_text ltx_font_bold" id="A3.p3.1.1">Llama 2.</span> Llama 2 is a collection of open-source chat models developed by Meta, ranging from 7 to 70B parameters <cite class="ltx_cite ltx_citemacro_cite">Touvron et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib37" title="">2023</a>)</cite>. It was trained on 2 trillion tokens of publicly available data and tuned through over one million new human-annotated examples. We applied <span class="ltx_text ltx_font_typewriter" id="A3.p3.1.2">llama-2-chat</span> for our experiments.</p>
</div>
<div class="ltx_para" id="A3.p4">
<p class="ltx_p" id="A3.p4.1"><span class="ltx_text ltx_font_bold" id="A3.p4.1.1">Llama 3.</span> Following Llama 2, Llama 3 is a series of pre-trained and instruction-tuned autoregressive models in 8 and 70B sizes <cite class="ltx_cite ltx_citemacro_cite">AI@Meta (<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib1" title="">2024</a>)</cite>. The training data of Llama 3 is over seven times larger than Llama 2, reaching over 15 trillion tokens of data and over 10M human-annotated examples.</p>
</div>
<div class="ltx_para" id="A3.p5">
<p class="ltx_p" id="A3.p5.1"><span class="ltx_text ltx_font_bold" id="A3.p5.1.1">Mixtral-8x7B.</span> Mixtral-8x7B is a pre-trained generative Sparse Mixture of Experts <cite class="ltx_cite ltx_citemacro_cite">Jiang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib13" title="">2024</a>)</cite>. The Mixtral-8x7B outperformed Llama 2 70B on most benchmarks and can handle English, French, Italian, German, and Spanish, which is helpful when predicting French name genders.</p>
</div>
<div class="ltx_para" id="A3.p6">
<p class="ltx_p" id="A3.p6.1"><span class="ltx_text ltx_font_bold" id="A3.p6.1.1">Claude 3 Haiku.</span> Claude 3 family is a series of close-source language models, including three state-of-the-art models in ascending order of capability: Claude 3 Haiku, Claude 3 Sonnet, and Claude 3 Opus <cite class="ltx_cite ltx_citemacro_cite">Anthropic (<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib3" title="">2024</a>)</cite>. Claude 3 Haiku is the fastest, most compact model for near-instant responsiveness. We used Claude 3.</p>
</div>
</section>
<section class="ltx_appendix" id="A4">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Prompt Templates for LLMs</h2>
<div class="ltx_para" id="A4.p1">
<p class="ltx_p" id="A4.p1.1">We reported the prompt templates for the experiments of LLMs in 0- and 5-shot settings for RQ 1 and RQ 2 in Table <a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#A2.T6" title="Table 6 ‣ Appendix B Experimental Settings ‣ Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions"><span class="ltx_text ltx_ref_tag">6</span></a>. For RQ 1, we used “First Name” for gender prediction. For RQ 2, we provided “First Name” and “Year of Birth” as input.</p>
</div>
<div class="ltx_para" id="A4.p2">
<p class="ltx_p" id="A4.p2.1">In the 5-shot setting, we randomly chose five name-gender pairs from the three SSA datasets, using the number 42 as the random seed. We selected names that appeared at least twice and were assigned different genders in different years.</p>
</div>
</section>
<section class="ltx_appendix" id="A5">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix E </span>Prompt Robustness Evaluation</h2>
<div class="ltx_para" id="A5.p1">
<p class="ltx_p" id="A5.p1.1">The effectiveness of prompts designed for LLM-based experiments is crucial for the performance of downstream natural language processing tasks, as highlighted by <cite class="ltx_cite ltx_citemacro_citet">Zhou et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib40" title="">2022</a>); Zhu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib41" title="">2023</a>)</cite>. Therefore, we developed two prompt templates inspired by <cite class="ltx_cite ltx_citemacro_citet">Zhu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#bib.bib41" title="">2023</a>)</cite>: task-oriented and role-oriented prompts, to evaluate the robustness of LLM gender prediction performance. The task-oriented prompt was the same as introduced in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#A4" title="Appendix D Prompt Templates for LLMs ‣ Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions"><span class="ltx_text ltx_ref_tag">D</span></a>.</p>
</div>
<div class="ltx_para ltx_noindent" id="A5.p2">
<svg class="ltx_picture" height="194.25" id="A5.p2.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,194.25) matrix(1 0 0 -1 0 0)"><g fill="#000000" fill-opacity="1.0"><path d="M 0 6.92 L 0 187.33 C 0 191.15 3.1 194.25 6.92 194.25 L 593.08 194.25 C 596.9 194.25 600 191.15 600 187.33 L 600 6.92 C 600 3.1 596.9 0 593.08 0 L 6.92 0 C 3.1 0 0 3.1 0 6.92 Z" style="stroke:none"></path></g><g fill="#FFFFFF" fill-opacity="1.0"><path d="M 1.38 6.92 L 1.38 187.33 C 1.38 190.38 3.86 192.86 6.92 192.86 L 593.08 192.86 C 596.14 192.86 598.62 190.38 598.62 187.33 L 598.62 6.92 C 598.62 3.86 596.14 1.38 593.08 1.38 L 6.92 1.38 C 3.86 1.38 1.38 3.86 1.38 6.92 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 24.05 16.18)"><foreignobject color="#000000" height="161.89" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="551.9"><span class="ltx_inline-logical-block ltx_minipage ltx_align_bottom" id="A5.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.1" style="width:398.9pt;">
<span class="ltx_para ltx_noindent" id="A5.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1">
<span class="ltx_p" id="A5.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1"><span class="ltx_text ltx_font_bold" id="A5.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.1">0-shot Role-Based Prompt for RQ 1
<br class="ltx_break"/></span>In the role of a first name gender prediction tool, classify names based on their gender association using the following gender labels:
<br class="ltx_break"/></span>
</span>
<span class="ltx_para" id="A5.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.1.p2">
<span class="ltx_p" id="A5.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.1.p2.1">Male: The name is predominantly associated with males.</span>
<span class="ltx_p" id="A5.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.1.p2.2">Female: The name is predominantly associated with females.</span>
<span class="ltx_p" id="A5.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.1.p2.3">Neutral: The name is not predominantly associated with any single gender and is considered neutral.</span>
<span class="ltx_p" id="A5.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.1.p2.4">The provided names appear more than once. Your outputs should be all in lowercase and can only output gender from male, female, or neutral.
"\n Name: " + name + "\n Gender: "</span>
</span></span></foreignobject></g></g></svg>
</div>
<div class="ltx_para ltx_noindent" id="A5.p3">
<svg class="ltx_picture" height="212.23" id="A5.p3.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,212.23) matrix(1 0 0 -1 0 0)"><g fill="#000000" fill-opacity="1.0"><path d="M 0 6.92 L 0 205.31 C 0 209.14 3.1 212.23 6.92 212.23 L 593.08 212.23 C 596.9 212.23 600 209.14 600 205.31 L 600 6.92 C 600 3.1 596.9 0 593.08 0 L 6.92 0 C 3.1 0 0 3.1 0 6.92 Z" style="stroke:none"></path></g><g fill="#FFFFFF" fill-opacity="1.0"><path d="M 1.38 6.92 L 1.38 205.31 C 1.38 208.37 3.86 210.85 6.92 210.85 L 593.08 210.85 C 596.14 210.85 598.62 208.37 598.62 205.31 L 598.62 6.92 C 598.62 3.86 596.14 1.38 593.08 1.38 L 6.92 1.38 C 3.86 1.38 1.38 3.86 1.38 6.92 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 24.05 16.18)"><foreignobject color="#000000" height="179.88" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="551.9"><span class="ltx_inline-logical-block ltx_minipage ltx_align_bottom" id="A5.p3.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1" style="width:398.9pt;">
<span class="ltx_para ltx_noindent" id="A5.p3.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1">
<span class="ltx_p" id="A5.p3.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1"><span class="ltx_text ltx_font_bold" id="A5.p3.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.1">0-shot Role-Based Prompt for RQ 2</span></span>
</span>
<span class="ltx_para ltx_noindent" id="A5.p3.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.p2">
<span class="ltx_p" id="A5.p3.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.p2.1">In the role of a first name gender prediction tool, classify names based on their gender association using the following gender labels:
<br class="ltx_break"/></span>
</span>
<span class="ltx_para" id="A5.p3.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.p3">
<span class="ltx_p" id="A5.p3.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.p3.1">Male: The name is predominantly associated with males.</span>
<span class="ltx_p" id="A5.p3.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.p3.2">Female: The name is predominantly associated with females.</span>
<span class="ltx_p" id="A5.p3.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.p3.3">Neutral: The name is not predominantly associated with any single gender and is considered neutral.</span>
<span class="ltx_p" id="A5.p3.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.p3.4">Consider the year of birth as an additional reference. The provided names appear more than once across different years of birth as they may be labeled in different genders given the change in the predominant gender of names.</span>
<span class="ltx_p" id="A5.p3.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1.p3.5">Your outputs should be all in lowercase and can only output gender from male, female, or neutral.
"\n Name: " + name + "\n Year of Birth: " + year + "\n Gender: "</span>
</span></span></foreignobject></g></g></svg>
</div>
<div class="ltx_para" id="A5.p4">
<p class="ltx_p" id="A5.p4.1">Above are examples of role-based prompts used in RQ 1 and 2 under the 0-shot setting. The 5-shot examples are the same as we applied in task-oriented prompts. We provided first names after “Name” and guided LLMs to output genders after “Gender”.</p>
</div>
<div class="ltx_para" id="A5.p5">
<p class="ltx_p" id="A5.p5.1">We evaluated the robustness of prompts using GPT-3.5 on the France SSA dynamic gender label dataset referenced in Table <a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#S3.T3" title="Table 3 ‣ 3.1 Data ‣ 3 Experiments ‣ Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions"><span class="ltx_text ltx_ref_tag">3</span></a>. As shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#A5.T7" title="Table 7 ‣ Appendix E Prompt Robustness Evaluation ‣ Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions"><span class="ltx_text ltx_ref_tag">7</span></a>, our results indicate that in the 0-shot setting, both prompts exhibited similar performance for predicting male and female genders. However, using the task-oriented prompt showed a better performance in predicting gender-neutral names than using the role-oriented prompt. Given that over 75% of names in the French dataset were gender-neutral, even minor discrepancies in the “Neutral” category can significantly impact the overall accuracy. While the role-oriented prompt yielded better predictions for binary gender predictions when only the first names were provided, its overall accuracy still fell behind the task-oriented setting in both experimental setups. Notably, incorporating birth year as an additional feature for name gender prediction reduced the differences between various prompt templates, particularly for the performance of gender-neutral names (Table <a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#A5.T7" title="Table 7 ‣ Appendix E Prompt Robustness Evaluation ‣ Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions"><span class="ltx_text ltx_ref_tag">7</span></a>).</p>
</div>
<div class="ltx_para" id="A5.p6">
<p class="ltx_p" id="A5.p6.1">We also assessed the impact of including “Country” information in the gender prediction prompt using the France dataset. The results indicated no significant difference (i.e., the variation in overall accuracy is within 2%) when incorporating the original country of the given names in both 0-shot and 5-shot settings.</p>
</div>
<figure class="ltx_table" id="A5.T7">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A5.T7.1">
<tr class="ltx_tr" id="A5.T7.1.1">
<td class="ltx_td ltx_border_tt" id="A5.T7.1.1.1"></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="4" id="A5.T7.1.1.2">First Name</td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="4" id="A5.T7.1.1.3">First Name + Year</td>
</tr>
<tr class="ltx_tr" id="A5.T7.1.2">
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T7.1.2.1">Models</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T7.1.2.2">Male</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T7.1.2.3">Female</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T7.1.2.4">Neutral</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T7.1.2.5">Acc.</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T7.1.2.6">Male</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T7.1.2.7">Female</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T7.1.2.8">Neutral</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T7.1.2.9">Acc.</td>
</tr>
<tr class="ltx_tr" id="A5.T7.1.3">
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T7.1.3.1">Task-o Oriented Prompt (0-shot)</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T7.1.3.2">78.43</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T7.1.3.3">98.31</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T7.1.3.4">16.52</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T7.1.3.5">34.30</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T7.1.3.6">90.20</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T7.1.3.7">98.31</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T7.1.3.8">3.54</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T7.1.3.9">25.84</td>
</tr>
<tr class="ltx_tr" id="A5.T7.1.4">
<td class="ltx_td ltx_align_center" id="A5.T7.1.4.1">Role-o Oriented Prompt (0-shot)</td>
<td class="ltx_td ltx_align_center" id="A5.T7.1.4.2">78.43</td>
<td class="ltx_td ltx_align_center" id="A5.T7.1.4.3">98.31</td>
<td class="ltx_td ltx_align_center" id="A5.T7.1.4.4">9.73</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="A5.T7.1.4.5">29.18</td>
<td class="ltx_td ltx_align_center" id="A5.T7.1.4.6">88.24</td>
<td class="ltx_td ltx_align_center" id="A5.T7.1.4.7">98.31</td>
<td class="ltx_td ltx_align_center" id="A5.T7.1.4.8">3.54</td>
<td class="ltx_td ltx_align_center" id="A5.T7.1.4.9">25.61</td>
</tr>
<tr class="ltx_tr" id="A5.T7.1.5">
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T7.1.5.1">Task-o Oriented Prompt (5-shot)</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T7.1.5.2">78.43</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T7.1.5.3">98.31</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T7.1.5.4">20.35</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A5.T7.1.5.5">37.19</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T7.1.5.6">98.04</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T7.1.5.7">100.00</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T7.1.5.8">5.01</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T7.1.5.9">28.06</td>
</tr>
<tr class="ltx_tr" id="A5.T7.1.6">
<td class="ltx_td ltx_align_center ltx_border_bb" id="A5.T7.1.6.1">Role-o Oriented Prompt (5-shot)</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A5.T7.1.6.2">90.20</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A5.T7.1.6.3">100.00</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A5.T7.1.6.4">17.11</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="A5.T7.1.6.5">36.30</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A5.T7.1.6.6">92.16</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A5.T7.1.6.7">100.00</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A5.T7.1.6.8">4.42</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A5.T7.1.6.9">26.95</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 7: </span>Prompt robustness evaluation of name gender prediction using GPT-3.5 under the France dynamic gender label dataset.</figcaption>
</figure>
<figure class="ltx_figure" id="A5.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_portrait" height="1631" id="A5.F3.g1" src="extracted/5715083/pics/canada_performance_plot_v3.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Temporal-level comparison of all LLMs across Canada SSA dynamic gender label dataset given the results of Table <a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#S3.T3" title="Table 3 ‣ 3.1 Data ‣ 3 Experiments ‣ Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions"><span class="ltx_text ltx_ref_tag">3</span></a>.</figcaption>
</figure>
<figure class="ltx_figure" id="A5.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_portrait" height="1631" id="A5.F4.g1" src="extracted/5715083/pics/france_performance_plot_v3.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Temporal-level comparison of all LLMs across France SSA dynamic gender label dataset given the results of Table <a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#S3.T3" title="Table 3 ‣ 3.1 Data ‣ 3 Experiments ‣ Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions"><span class="ltx_text ltx_ref_tag">3</span></a>.</figcaption>
</figure>
</section>
<section class="ltx_appendix" id="A6">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix F </span>Over-time Trends of LLM Performances</h2>
<div class="ltx_para" id="A6.p1">
<p class="ltx_p" id="A6.p1.1">In Figures <a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#A5.F3" title="Figure 3 ‣ Appendix E Prompt Robustness Evaluation ‣ Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions"><span class="ltx_text ltx_ref_tag">3</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#A5.F4" title="Figure 4 ‣ Appendix E Prompt Robustness Evaluation ‣ Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions"><span class="ltx_text ltx_ref_tag">4</span></a>, we presented the trends in gender prediction accuracy for Canada and France using dynamic gender label datasets across five different LLMs. Generally, the performance of these LLMs varied over time for both datasets. Notably, models that did not incorporate temporal information tended to perform better, yielding more stable accuracy rates over the years than models that included birth year data. Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.05271v1#A5.F3" title="Figure 3 ‣ Appendix E Prompt Robustness Evaluation ‣ Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions"><span class="ltx_text ltx_ref_tag">3</span></a> also indicated that the LLMs were less effective at predicting names from more recent years. In particular, GPT-3.5 demonstrated that omitting temporal information led to higher gender prediction performance consistently over the years than including it.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Sun Jul  7 05:46:39 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
