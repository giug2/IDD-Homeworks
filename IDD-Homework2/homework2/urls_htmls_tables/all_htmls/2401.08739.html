<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2401.08739] EgoGen: An Egocentric Synthetic Data Generator</title><meta property="og:description" content="Understanding the world in first-person view is fundamental in Augmented Reality (AR).
This immersive perspective brings dramatic visual changes and unique challenges compared to third-person views. Synthetic data has â€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="EgoGen: An Egocentric Synthetic Data Generator">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="EgoGen: An Egocentric Synthetic Data Generator">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2401.08739">

<!--Generated on Tue Feb 27 09:16:37 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_pruned_first">
<h1 class="ltx_title ltx_title_document">EgoGen: An Egocentric Synthetic Data Generator</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Gen Li<sup id="id13.11.id1" class="ltx_sup"><span id="id13.11.id1.1" class="ltx_text ltx_font_italic">1</span></sup> â€ƒKaifeng Zhao<sup id="id14.12.id2" class="ltx_sup"><span id="id14.12.id2.1" class="ltx_text ltx_font_italic">1</span></sup> â€ƒSiwei Zhang<sup id="id15.13.id3" class="ltx_sup"><span id="id15.13.id3.1" class="ltx_text ltx_font_italic">1</span></sup> â€ƒXiaozhong Lyu<sup id="id16.14.id4" class="ltx_sup"><span id="id16.14.id4.1" class="ltx_text ltx_font_italic">1</span></sup> 
<br class="ltx_break">â€ƒMihai Dusmanu<sup id="id17.15.id5" class="ltx_sup"><span id="id17.15.id5.1" class="ltx_text ltx_font_italic">2</span></sup> â€ƒYan Zhang<sup id="id18.16.id6" class="ltx_sup"><span id="id18.16.id6.1" class="ltx_text ltx_font_italic">1</span></sup> â€ƒMarc Pollefeys<sup id="id19.17.id7" class="ltx_sup"><span id="id19.17.id7.1" class="ltx_text ltx_font_italic">1,2</span></sup> â€ƒSiyu Tang<sup id="id20.18.id8" class="ltx_sup"><span id="id20.18.id8.1" class="ltx_text ltx_font_italic">1</span></sup>  
<br class="ltx_break"><sup id="id21.19.id9" class="ltx_sup">1</sup>ETH ZÃ¼rich â€ƒ<sup id="id22.20.id10" class="ltx_sup">2</sup>Microsoft
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id23.id1" class="ltx_p">Understanding the world in first-person view is fundamental in Augmented Reality (AR).
This immersive perspective brings dramatic visual changes and unique challenges compared to third-person views. Synthetic data has empowered third-person-view vision models, but its application to embodied egocentric perception tasks remains largely unexplored.
A critical challenge lies in simulating natural human movements and behaviors that effectively steer the embodied cameras to capture a faithful egocentric representation of the 3D world.
To address this challenge, we introduce <span id="id23.id1.1" class="ltx_text ltx_font_italic">EgoGen</span>, a new synthetic data generator that can produce accurate and rich ground-truth training data for egocentric perception tasks.
At the heart of <span id="id23.id1.2" class="ltx_text ltx_font_italic">EgoGen</span>Â is a novel human motion synthesis model that directly leverages egocentric visual inputs of a virtual human to sense the 3D environment. Combined with collision-avoiding motion primitives and a two-stage reinforcement learning approach, our motion synthesis model offers a closed-loop solution where the embodied perception and movement of the virtual human are seamlessly coupled.
Compared to previous works, our model eliminates the need for a pre-defined global path, and is directly applicable to dynamic environments.
Combined with our easy-to-use and scalable data generation pipeline, we demonstrate <span id="id23.id1.3" class="ltx_text ltx_font_italic">EgoGen</span>â€™s efficacy in three tasks: mapping and localization for head-mounted cameras, egocentric camera tracking, and human mesh recovery from egocentric views. <span id="id23.id1.4" class="ltx_text ltx_font_italic">EgoGen</span>Â will be fully open-sourced, offering a practical solution for creating realistic egocentric training data and aiming to serve as a useful tool for egocentric computer vision research. Refer to our <a target="_blank" href="https://ego-gen.github.io/" title="" class="ltx_ref ltx_href">project page</a>.</p>
</div>
<div id="id12" class="ltx_logical-block">
<div id="id12.p1" class="ltx_para">
<img src="/html/2401.08739/assets/x1.png" id="id11.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="528" height="193" alt="[Uncaptioned image]">
</div>
<figure id="S0.F1" class="ltx_figure ltx_align_center">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S0.F1.2.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S0.F1.3.2" class="ltx_text" style="font-size:90%;">EgoGen: a scalable synthetic data generation system for egocentric perception tasks, with rich multi-modal data and accurate annotations. We simulate camera rigs for head-mounted devices (HMDs) and render from the perspective of the camera wearer with various sensors. Top to bottom: middle and right camera sensors in the rig. Left to right: photo-realistic RGB image, RGB with simulated motion blur, depth map, surface normal, segmentation mask, and world position for fisheye cameras widely used in HMDs.</span></figcaption>
</figure>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">The analysis of visual input from front-facing egocentric cameras is crucial for applications that benefit from a first-person perspective, mirroring the natural human experienceÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">26</span></a>, <a href="#bib.bib47" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">47</span></a>, <a href="#bib.bib125" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">125</span></a>]</cite>. AR devices, for instance, can utilize this viewpoint to amplify user immersion. Such cameras can also cater to individual preferences, providing custom visual assistance for those with impaired vision <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib130" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">130</span></a>, <a href="#bib.bib21" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">21</span></a>]</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Despite its potential, egocentric perception faces challenges, primarily due to the scarcity of labeled data. Although datasets like Ego4DÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">26</span></a>]</cite>, ADTÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib65" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">65</span></a>]</cite>, Epic-KitchenÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">15</span></a>]</cite> and HoloAssistÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib110" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">110</span></a>]</cite> exist, creating such datasets with rich and accurate annotations is costly and raises privacy concernsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib125" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">125</span></a>]</cite>.
Alternatively, using graphics techniques to render synthetic multi-modal visual data has proven to be cost-effective and successful in training deep learning models, such as 3D human body estimationÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">9</span></a>]</cite> and facial landmark detectionÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib116" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">116</span></a>]</cite>.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Creating egocentric synthetic data is challenging because egocentric cameras capture the complex interplay of body movements and the environment from the camera wearerâ€™s viewpoint.
Modeling the intricate details and variations in human behavior presents a significant challenge.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">To tackle this problem, we introduce <span id="S1.p4.1.1" class="ltx_text ltx_font_italic">EgoGen</span>, an egocentric synthetic data generation approach that simulates data from embodied sensors, i.e., front-facing cameras in head-mounted devices (HMD).
While the ultimate goal is to simulate human behaviors that are indistinguishable from reality, in this work, we focus on creating virtual humans (i.e., camera wearers) that can explore and avoid obstacles in the 3D world that is not only complex and dynamic but could potentially include other <span id="S1.p4.1.2" class="ltx_text ltx_font_italic">moving</span> virtual humans.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">Specifically, we propose a novel generative human motion model.
Our key insight is that body movement and embodied perception should be seamlessly coupled.
As William Gibson aptly stated, <span id="S1.p5.1.1" class="ltx_text ltx_font_italic">â€œWe see in order to move; we move in order to see.â€</span>, our egocentric perception is crucial for identifying obstacles, navigating in an environment, and planning actions. Our body movements are not solely a response to visual stimuli; they also change our egocentric perception.
Therefore, the key idea of our motion model is to enable virtual humans to <span id="S1.p5.1.2" class="ltx_text ltx_font_italic">see</span> their environment with <span id="S1.p5.1.3" class="ltx_text ltx_font_italic">egocentric</span> visual inputs and respond accordingly by learning a policy to control a set of collision-avoiding motion primitives (CAMPs) that are composable for synthesizing long-term, diverse human motions.
Due to the unbounded and high-dimensional latent action space of our generative motion primitive model, direct policy training through rendered egocentric images is often unstable <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib133" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">133</span></a>]</cite>.
Therefore, we propose a two-stage reinforcement learning scheme using an efficient <span id="S1.p5.1.4" class="ltx_text ltx_font_italic">egocentric</span> visual proxy to couple egocentric visual cues and body movements seamlessly.
In addition, we use an â€œattentionâ€ reward to incentivize egocentric perception behaviors, i.e.,Â looking in the desired direction.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">Empirical results showcase the benefits of our egocentric perception-driven motion framework, which does not require a pre-calculated walking path in 3D scenes as inÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">33</span></a>, <a href="#bib.bib129" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">129</span></a>, <a href="#bib.bib57" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">57</span></a>]</cite>. Instead, it empowers virtual humans to perceive the environment from their own viewpoint, enabling them to navigate, circumvent obstacles, and plan movements to reach the destination.
Moreover, our model generalizes well to dynamic environments, even with training limited to static settings.
By training virtual humans independently using CAMPs, our method synthesizes emergent multi-human behaviors without relying on multi-agent reinforcement learning algorithms.
Egocentric visual cues are essential to build exploratory and generalizable motion models that unify navigational planning and movement control in complex and dynamic environments.</p>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p">Building upon CAMPs, we further create a scalable data generation pipeline for <span id="S1.p7.1.1" class="ltx_text ltx_font_italic">EgoGen</span>Â that outfits virtual humans with clothing, automates cloth animation, and integrates 3D assets from various sources.
We validate <span id="S1.p7.1.2" class="ltx_text ltx_font_italic">EgoGen</span>â€™s efficacy across three egocentric perception tasks. The high-quality synthetic data with precise ground truth annotations consistently improve the performance of state-of-the-art methods. In summary, the contributions of this work are:</p>
<ol id="S1.I1" class="ltx_enumerate">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">We introduce <span id="S1.I1.i1.p1.1.1" class="ltx_text ltx_font_italic">EgoGen</span>, a generative and scalable synthetic data generation approach specifically tailored for egocentric perception tasks.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">We introduce novel motion primitives based on egocentric visual cues,
enabling diverse and realistic human motion synthesis in 3D scenes.
These primitives empower virtual humans to handle complex scenarios, such as dynamic environments and crowd motion without relying on multi-agent reinforcement learning.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p"><span id="S1.I1.i3.p1.1.1" class="ltx_text ltx_font_italic">EgoGen</span>Â enables us to augment existing real-world egocentric datasets with synthetic images. Quantitative results demonstrate enhanced performance in state-of-the-art algorithms on mapping and localization for head-mounted cameras, egocentric camera tracking, and human mesh recovery from egocentric views.</p>
</div>
</li>
</ol>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p"><span id="S2.p1.1.1" class="ltx_text ltx_font_bold">Human-Related Simulators and Synthetic Data.</span>
Previous works primarily focus on simulating robots <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib75" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">75</span></a>, <a href="#bib.bib58" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">58</span></a>, <a href="#bib.bib100" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">100</span></a>, <a href="#bib.bib103" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">103</span></a>, <a href="#bib.bib86" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">86</span></a>]</cite> and autonomous cars <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">18</span></a>, <a href="#bib.bib23" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">23</span></a>, <a href="#bib.bib8" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">8</span></a>, <a href="#bib.bib81" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">81</span></a>]</cite>. While some incorporated animated digital humans, like in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">23</span></a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib73" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">73</span></a>]</cite>, these efforts relied on pre-recorded motion sequences. Rendering images of people to train perception models has been widely studied such asÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">47</span></a>, <a href="#bib.bib94" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">94</span></a>, <a href="#bib.bib90" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">90</span></a>, <a href="#bib.bib19" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">19</span></a>, <a href="#bib.bib74" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">74</span></a>, <a href="#bib.bib20" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">20</span></a>]</cite>.
In particular, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib105" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">105</span></a>]</cite>
offers large-scale synthetic data for egocentric camera wearer pose estimation but relies on mocap data, lacking realistic and spontaneous interactions with the digital world.
In contrast, <span id="S2.p1.1.2" class="ltx_text ltx_font_italic">EgoGen</span>Â closes the gap in egocentric synthetic data generation for head-mounted devices. Please refer to <a href="#S1a" title="S1 Related Work â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Sec.</span>Â <span class="ltx_text ltx_ref_tag">S1</span></a> for detailed comparisons.</p>
</div>
<div id="S2.p2" class="ltx_para ltx_noindent">
<p id="S2.p2.1" class="ltx_p"><span id="S2.p2.1.1" class="ltx_text ltx_font_bold">Human Motion Synthesis.</span>
Generating high-fidelity human motions and interactions with 3D scenes is widely studied in graphics <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">46</span></a>, <a href="#bib.bib12" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">12</span></a>, <a href="#bib.bib36" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">36</span></a>, <a href="#bib.bib98" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">98</span></a>, <a href="#bib.bib97" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">97</span></a>, <a href="#bib.bib35" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">35</span></a>]</cite>.
While they can generate high-quality motion, itâ€™s usually deterministic.
Synthesizing physically plausible human motions has been extensively studiedÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">14</span></a>, <a href="#bib.bib104" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">104</span></a>, <a href="#bib.bib68" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">68</span></a>, <a href="#bib.bib115" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">115</span></a>, <a href="#bib.bib34" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">34</span></a>, <a href="#bib.bib80" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">80</span></a>]</cite>. However, they struggle with generalization to different body shapes.
For example, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib80" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">80</span></a>]</cite> explicitly created 2048 humanoids to improve body shape generalizability.
Time series modelsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib69" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">69</span></a>, <a href="#bib.bib102" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">102</span></a>, <a href="#bib.bib124" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">124</span></a>]</cite> synthesize the stochastic motions of diverse people well.
However, inÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib102" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">102</span></a>, <a href="#bib.bib124" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">124</span></a>]</cite>, their generated motion sequences have limited lengths and human-scene interactions are not explicitly considered.
Autoregressive methodsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">49</span></a>, <a href="#bib.bib79" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">79</span></a>, <a href="#bib.bib127" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">127</span></a>, <a href="#bib.bib129" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">129</span></a>]</cite> can produce perpetual motions.
In particular, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib127" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">127</span></a>]</cite> can generalize to diverse body shapes and synthesize long-term human motions.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">Our egocentric perception-driven motion synthesis model is closely related to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib127" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">127</span></a>, <a href="#bib.bib129" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">129</span></a>]</cite>, but distinguishes itself w.r.t.:
(1) Enabling virtual humans to explore using egocentric visual cues, without predefined paths.
(2) Synthesizing egocentric perception behaviors beyond locomotion, e.g., looking in certain directions.
(3) Handling dynamic environments and multi-agent behavior without re-training.</p>
</div>
<div id="S2.p4" class="ltx_para ltx_noindent">
<p id="S2.p4.1" class="ltx_p"><span id="S2.p4.1.1" class="ltx_text ltx_font_bold">Mapping and Localization for AR.</span>
Localization and mapping from images is a long-standing problem known as:
PhotogrammetryÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">30</span></a>, <a href="#bib.bib2" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2</span></a>]</cite>; Structure-from-MotionÂ (SfM)Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">25</span></a>, <a href="#bib.bib70" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">70</span></a>, <a href="#bib.bib114" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">114</span></a>, <a href="#bib.bib87" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">87</span></a>, <a href="#bib.bib95" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">95</span></a>]</cite>; Simultaneous Localization and MappingÂ (SLAM)Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">16</span></a>, <a href="#bib.bib64" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">64</span></a>, <a href="#bib.bib60" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">60</span></a>, <a href="#bib.bib41" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">41</span></a>]</cite>.
Researchers have worked to make SLAM amenable for edge hand-held or head-mounted devicesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">41</span></a>, <a href="#bib.bib7" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">7</span></a>, <a href="#bib.bib24" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">24</span></a>]</cite>.
Cloud-based services like Googleâ€™s Visual Positioning SystemÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib78" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">78</span></a>]</cite>, Nianticâ€™s LightshipÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib63" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">63</span></a>]</cite>, and Microsoftâ€™s Azure Spatial AnchorsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">38</span></a>]</cite> have made visual localization and mapping more accessible.
Benchmarking efforts have arisen for small-scale AR scenariosÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib93" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">93</span></a>, <a href="#bib.bib40" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">40</span></a>]</cite>, touristic landmarksÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib88" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">88</span></a>, <a href="#bib.bib37" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">37</span></a>]</cite>, and large-scale AR-device based localizationÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib85" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">85</span></a>, <a href="#bib.bib84" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">84</span></a>]</cite> to evaluate these systems.</p>
</div>
<div id="S2.p5" class="ltx_para ltx_noindent">
<p id="S2.p5.1" class="ltx_p"><span id="S2.p5.1.1" class="ltx_text ltx_font_bold">Egocentric Human Pose Estimation.</span>
Estimating 3D bodies from RGB images is widely studied from third-person viewsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">39</span></a>, <a href="#bib.bib44" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">44</span></a>, <a href="#bib.bib43" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">43</span></a>, <a href="#bib.bib67" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">67</span></a>, <a href="#bib.bib42" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">42</span></a>, <a href="#bib.bib48" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">48</span></a>, <a href="#bib.bib10" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">10</span></a>, <a href="#bib.bib45" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">45</span></a>]</cite>, and egocentric viewsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">51</span></a>, <a href="#bib.bib123" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">123</span></a>, <a href="#bib.bib91" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">91</span></a>, <a href="#bib.bib106" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">106</span></a>, <a href="#bib.bib105" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">105</span></a>, <a href="#bib.bib29" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">29</span></a>, <a href="#bib.bib61" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">61</span></a>, <a href="#bib.bib50" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">50</span></a>, <a href="#bib.bib122" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">122</span></a>, <a href="#bib.bib126" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">126</span></a>]</cite>, mostly requiring expensive real-world data paired with ground truth annotations.
Besides RGB images, depth images offer explicit 3D information, mitigating scale and shape ambiguity, with the potential to enable broader AR/VR applications.
However, depth-based methods, especially for the egocentric view, are underexplored.
Most existing worksÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">59</span></a>, <a href="#bib.bib117" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">117</span></a>, <a href="#bib.bib53" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">53</span></a>, <a href="#bib.bib32" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">32</span></a>, <a href="#bib.bib92" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">92</span></a>, <a href="#bib.bib121" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">121</span></a>, <a href="#bib.bib109" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">109</span></a>, <a href="#bib.bib76" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">76</span></a>]</cite> predict 3D body skeletons without expressive body meshes, struggling with challenges like severe body truncations and scene occlusions typical in egocentric views.
Such limited attention mainly stems from the scarcity of data, as obtaining high-quality human mesh annotations for real-world depth images is labor-intensive.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Ego-Sensing Driven Motion Synthesis</h2>

<figure id="S3.F2" class="ltx_figure"><img src="/html/2401.08739/assets/x2.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="160" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F2.16.8.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S3.F2.14.7" class="ltx_text" style="font-size:90%;">Policy network architecture. We learn a generalizable mapping from motion seed body markers <math id="S3.F2.8.1.m1.1" class="ltx_Math" alttext="\mathbf{X}_{t}^{S}" display="inline"><semantics id="S3.F2.8.1.m1.1b"><msubsup id="S3.F2.8.1.m1.1.1" xref="S3.F2.8.1.m1.1.1.cmml"><mi id="S3.F2.8.1.m1.1.1.2.2" xref="S3.F2.8.1.m1.1.1.2.2.cmml">ğ—</mi><mi id="S3.F2.8.1.m1.1.1.2.3" xref="S3.F2.8.1.m1.1.1.2.3.cmml">t</mi><mi id="S3.F2.8.1.m1.1.1.3" xref="S3.F2.8.1.m1.1.1.3.cmml">S</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.F2.8.1.m1.1c"><apply id="S3.F2.8.1.m1.1.1.cmml" xref="S3.F2.8.1.m1.1.1"><csymbol cd="ambiguous" id="S3.F2.8.1.m1.1.1.1.cmml" xref="S3.F2.8.1.m1.1.1">superscript</csymbol><apply id="S3.F2.8.1.m1.1.1.2.cmml" xref="S3.F2.8.1.m1.1.1"><csymbol cd="ambiguous" id="S3.F2.8.1.m1.1.1.2.1.cmml" xref="S3.F2.8.1.m1.1.1">subscript</csymbol><ci id="S3.F2.8.1.m1.1.1.2.2.cmml" xref="S3.F2.8.1.m1.1.1.2.2">ğ—</ci><ci id="S3.F2.8.1.m1.1.1.2.3.cmml" xref="S3.F2.8.1.m1.1.1.2.3">ğ‘¡</ci></apply><ci id="S3.F2.8.1.m1.1.1.3.cmml" xref="S3.F2.8.1.m1.1.1.3">ğ‘†</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.8.1.m1.1d">\mathbf{X}_{t}^{S}</annotation></semantics></math>, marker directions <math id="S3.F2.9.2.m2.1" class="ltx_Math" alttext="\mathbf{X}_{t}^{S^{D}}" display="inline"><semantics id="S3.F2.9.2.m2.1b"><msubsup id="S3.F2.9.2.m2.1.1" xref="S3.F2.9.2.m2.1.1.cmml"><mi id="S3.F2.9.2.m2.1.1.2.2" xref="S3.F2.9.2.m2.1.1.2.2.cmml">ğ—</mi><mi id="S3.F2.9.2.m2.1.1.2.3" xref="S3.F2.9.2.m2.1.1.2.3.cmml">t</mi><msup id="S3.F2.9.2.m2.1.1.3" xref="S3.F2.9.2.m2.1.1.3.cmml"><mi id="S3.F2.9.2.m2.1.1.3.2" xref="S3.F2.9.2.m2.1.1.3.2.cmml">S</mi><mi id="S3.F2.9.2.m2.1.1.3.3" xref="S3.F2.9.2.m2.1.1.3.3.cmml">D</mi></msup></msubsup><annotation-xml encoding="MathML-Content" id="S3.F2.9.2.m2.1c"><apply id="S3.F2.9.2.m2.1.1.cmml" xref="S3.F2.9.2.m2.1.1"><csymbol cd="ambiguous" id="S3.F2.9.2.m2.1.1.1.cmml" xref="S3.F2.9.2.m2.1.1">superscript</csymbol><apply id="S3.F2.9.2.m2.1.1.2.cmml" xref="S3.F2.9.2.m2.1.1"><csymbol cd="ambiguous" id="S3.F2.9.2.m2.1.1.2.1.cmml" xref="S3.F2.9.2.m2.1.1">subscript</csymbol><ci id="S3.F2.9.2.m2.1.1.2.2.cmml" xref="S3.F2.9.2.m2.1.1.2.2">ğ—</ci><ci id="S3.F2.9.2.m2.1.1.2.3.cmml" xref="S3.F2.9.2.m2.1.1.2.3">ğ‘¡</ci></apply><apply id="S3.F2.9.2.m2.1.1.3.cmml" xref="S3.F2.9.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.F2.9.2.m2.1.1.3.1.cmml" xref="S3.F2.9.2.m2.1.1.3">superscript</csymbol><ci id="S3.F2.9.2.m2.1.1.3.2.cmml" xref="S3.F2.9.2.m2.1.1.3.2">ğ‘†</ci><ci id="S3.F2.9.2.m2.1.1.3.3.cmml" xref="S3.F2.9.2.m2.1.1.3.3">ğ·</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.9.2.m2.1d">\mathbf{X}_{t}^{S^{D}}</annotation></semantics></math>, egocentric sensing <math id="S3.F2.10.3.m3.1" class="ltx_Math" alttext="\mathcal{E}_{t}" display="inline"><semantics id="S3.F2.10.3.m3.1b"><msub id="S3.F2.10.3.m3.1.1" xref="S3.F2.10.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.F2.10.3.m3.1.1.2" xref="S3.F2.10.3.m3.1.1.2.cmml">â„°</mi><mi id="S3.F2.10.3.m3.1.1.3" xref="S3.F2.10.3.m3.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.F2.10.3.m3.1c"><apply id="S3.F2.10.3.m3.1.1.cmml" xref="S3.F2.10.3.m3.1.1"><csymbol cd="ambiguous" id="S3.F2.10.3.m3.1.1.1.cmml" xref="S3.F2.10.3.m3.1.1">subscript</csymbol><ci id="S3.F2.10.3.m3.1.1.2.cmml" xref="S3.F2.10.3.m3.1.1.2">â„°</ci><ci id="S3.F2.10.3.m3.1.1.3.cmml" xref="S3.F2.10.3.m3.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.10.3.m3.1d">\mathcal{E}_{t}</annotation></semantics></math>, and distance to the target <math id="S3.F2.11.4.m4.1" class="ltx_Math" alttext="d_{t}" display="inline"><semantics id="S3.F2.11.4.m4.1b"><msub id="S3.F2.11.4.m4.1.1" xref="S3.F2.11.4.m4.1.1.cmml"><mi id="S3.F2.11.4.m4.1.1.2" xref="S3.F2.11.4.m4.1.1.2.cmml">d</mi><mi id="S3.F2.11.4.m4.1.1.3" xref="S3.F2.11.4.m4.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.F2.11.4.m4.1c"><apply id="S3.F2.11.4.m4.1.1.cmml" xref="S3.F2.11.4.m4.1.1"><csymbol cd="ambiguous" id="S3.F2.11.4.m4.1.1.1.cmml" xref="S3.F2.11.4.m4.1.1">subscript</csymbol><ci id="S3.F2.11.4.m4.1.1.2.cmml" xref="S3.F2.11.4.m4.1.1.2">ğ‘‘</ci><ci id="S3.F2.11.4.m4.1.1.3.cmml" xref="S3.F2.11.4.m4.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.11.4.m4.1d">d_{t}</annotation></semantics></math> to CAMPs. The policy learns a stochastic collision avoiding action space to predict future body markers <math id="S3.F2.12.5.m5.1" class="ltx_Math" alttext="\mathbf{X}_{t}^{F}" display="inline"><semantics id="S3.F2.12.5.m5.1b"><msubsup id="S3.F2.12.5.m5.1.1" xref="S3.F2.12.5.m5.1.1.cmml"><mi id="S3.F2.12.5.m5.1.1.2.2" xref="S3.F2.12.5.m5.1.1.2.2.cmml">ğ—</mi><mi id="S3.F2.12.5.m5.1.1.2.3" xref="S3.F2.12.5.m5.1.1.2.3.cmml">t</mi><mi id="S3.F2.12.5.m5.1.1.3" xref="S3.F2.12.5.m5.1.1.3.cmml">F</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.F2.12.5.m5.1c"><apply id="S3.F2.12.5.m5.1.1.cmml" xref="S3.F2.12.5.m5.1.1"><csymbol cd="ambiguous" id="S3.F2.12.5.m5.1.1.1.cmml" xref="S3.F2.12.5.m5.1.1">superscript</csymbol><apply id="S3.F2.12.5.m5.1.1.2.cmml" xref="S3.F2.12.5.m5.1.1"><csymbol cd="ambiguous" id="S3.F2.12.5.m5.1.1.2.1.cmml" xref="S3.F2.12.5.m5.1.1">subscript</csymbol><ci id="S3.F2.12.5.m5.1.1.2.2.cmml" xref="S3.F2.12.5.m5.1.1.2.2">ğ—</ci><ci id="S3.F2.12.5.m5.1.1.2.3.cmml" xref="S3.F2.12.5.m5.1.1.2.3">ğ‘¡</ci></apply><ci id="S3.F2.12.5.m5.1.1.3.cmml" xref="S3.F2.12.5.m5.1.1.3">ğ¹</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.12.5.m5.1d">\mathbf{X}_{t}^{F}</annotation></semantics></math>. For illustration purposes, we visualize only one frame of <math id="S3.F2.13.6.m6.1" class="ltx_Math" alttext="\mathbf{X}_{t}^{S}" display="inline"><semantics id="S3.F2.13.6.m6.1b"><msubsup id="S3.F2.13.6.m6.1.1" xref="S3.F2.13.6.m6.1.1.cmml"><mi id="S3.F2.13.6.m6.1.1.2.2" xref="S3.F2.13.6.m6.1.1.2.2.cmml">ğ—</mi><mi id="S3.F2.13.6.m6.1.1.2.3" xref="S3.F2.13.6.m6.1.1.2.3.cmml">t</mi><mi id="S3.F2.13.6.m6.1.1.3" xref="S3.F2.13.6.m6.1.1.3.cmml">S</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.F2.13.6.m6.1c"><apply id="S3.F2.13.6.m6.1.1.cmml" xref="S3.F2.13.6.m6.1.1"><csymbol cd="ambiguous" id="S3.F2.13.6.m6.1.1.1.cmml" xref="S3.F2.13.6.m6.1.1">superscript</csymbol><apply id="S3.F2.13.6.m6.1.1.2.cmml" xref="S3.F2.13.6.m6.1.1"><csymbol cd="ambiguous" id="S3.F2.13.6.m6.1.1.2.1.cmml" xref="S3.F2.13.6.m6.1.1">subscript</csymbol><ci id="S3.F2.13.6.m6.1.1.2.2.cmml" xref="S3.F2.13.6.m6.1.1.2.2">ğ—</ci><ci id="S3.F2.13.6.m6.1.1.2.3.cmml" xref="S3.F2.13.6.m6.1.1.2.3">ğ‘¡</ci></apply><ci id="S3.F2.13.6.m6.1.1.3.cmml" xref="S3.F2.13.6.m6.1.1.3">ğ‘†</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.13.6.m6.1d">\mathbf{X}_{t}^{S}</annotation></semantics></math> and <math id="S3.F2.14.7.m7.1" class="ltx_Math" alttext="\mathcal{E}_{t}" display="inline"><semantics id="S3.F2.14.7.m7.1b"><msub id="S3.F2.14.7.m7.1.1" xref="S3.F2.14.7.m7.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.F2.14.7.m7.1.1.2" xref="S3.F2.14.7.m7.1.1.2.cmml">â„°</mi><mi id="S3.F2.14.7.m7.1.1.3" xref="S3.F2.14.7.m7.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.F2.14.7.m7.1c"><apply id="S3.F2.14.7.m7.1.1.cmml" xref="S3.F2.14.7.m7.1.1"><csymbol cd="ambiguous" id="S3.F2.14.7.m7.1.1.1.cmml" xref="S3.F2.14.7.m7.1.1">subscript</csymbol><ci id="S3.F2.14.7.m7.1.1.2.cmml" xref="S3.F2.14.7.m7.1.1.2">â„°</ci><ci id="S3.F2.14.7.m7.1.1.3.cmml" xref="S3.F2.14.7.m7.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.14.7.m7.1d">\mathcal{E}_{t}</annotation></semantics></math>. See Sec.Â <a href="#S3.SS1" title="3.1 Ego-Sensing Driven Motion Primitives â€£ 3 Ego-Sensing Driven Motion Synthesis â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a> and <a href="#S3.SS2" title="3.2 Training Collision-Avoiding Stochastic Policies â€£ 3 Ego-Sensing Driven Motion Synthesis â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a> for details.</span></figcaption>
</figure>
<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">To close the loop for the interdependence between egocentric synthetic image data and human motion synthesis, we use deep reinforcement learning (RL), integrating egocentric vision cues to synthesize human motions as described in Sec.Â <a href="#S3.SS1" title="3.1 Ego-Sensing Driven Motion Primitives â€£ 3 Ego-Sensing Driven Motion Synthesis â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a> and <a href="#S3.SS2" title="3.2 Training Collision-Avoiding Stochastic Policies â€£ 3 Ego-Sensing Driven Motion Synthesis â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a>. Subsequently, we extend learned policies to generate emergent multi-agent behaviors, as in Sec.Â <a href="#S3.SS3" title="3.3 Compositing Learned Motion Primitives â€£ 3 Ego-Sensing Driven Motion Synthesis â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3</span></a>.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Ego-Sensing Driven Motion Primitives</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">Generating realistic egocentric data requires diverse and lifelike human motion synthesis.
In this work, we consider arguably the most common everyday behaviors: navigating towards goals with egocentric perception while avoiding collisions with obstacles and people in dynamic 3D scenes.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para ltx_noindent">
<p id="S3.SS1.p2.6" class="ltx_p"><span id="S3.SS1.p2.6.1" class="ltx_text ltx_font_bold">Overview.</span> Following recent literature <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">49</span></a>, <a href="#bib.bib127" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">127</span></a>, <a href="#bib.bib120" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">120</span></a>, <a href="#bib.bib129" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">129</span></a>]</cite>, we employ deep RL to train control policies on learned latent spaces that characterize natural human motions.
However, unlike these previous works that only consider simple static scenes, we leverage egocentric perception and propose collision-avoiding motion primitives (CAMPs) to enable virtual humans to self-explore and navigate in a dynamic environment.
Specifically, CAMPs are trained jointly to produce collision-free motion sequences. At each timestep <math id="S3.SS1.p2.1.m1.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S3.SS1.p2.1.m1.1a"><mi id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><ci id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">t</annotation></semantics></math>, the agent observes the state <math id="S3.SS1.p2.2.m2.1" class="ltx_Math" alttext="\mathbf{s}_{t}" display="inline"><semantics id="S3.SS1.p2.2.m2.1a"><msub id="S3.SS1.p2.2.m2.1.1" xref="S3.SS1.p2.2.m2.1.1.cmml"><mi id="S3.SS1.p2.2.m2.1.1.2" xref="S3.SS1.p2.2.m2.1.1.2.cmml">ğ¬</mi><mi id="S3.SS1.p2.2.m2.1.1.3" xref="S3.SS1.p2.2.m2.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.1b"><apply id="S3.SS1.p2.2.m2.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.2.m2.1.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.p2.2.m2.1.1.2.cmml" xref="S3.SS1.p2.2.m2.1.1.2">ğ¬</ci><ci id="S3.SS1.p2.2.m2.1.1.3.cmml" xref="S3.SS1.p2.2.m2.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.1c">\mathbf{s}_{t}</annotation></semantics></math>, performs an action <math id="S3.SS1.p2.3.m3.1" class="ltx_Math" alttext="\mathbf{a}_{t}" display="inline"><semantics id="S3.SS1.p2.3.m3.1a"><msub id="S3.SS1.p2.3.m3.1.1" xref="S3.SS1.p2.3.m3.1.1.cmml"><mi id="S3.SS1.p2.3.m3.1.1.2" xref="S3.SS1.p2.3.m3.1.1.2.cmml">ğš</mi><mi id="S3.SS1.p2.3.m3.1.1.3" xref="S3.SS1.p2.3.m3.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.3.m3.1b"><apply id="S3.SS1.p2.3.m3.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m3.1.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.p2.3.m3.1.1.2.cmml" xref="S3.SS1.p2.3.m3.1.1.2">ğš</ci><ci id="S3.SS1.p2.3.m3.1.1.3.cmml" xref="S3.SS1.p2.3.m3.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.3.m3.1c">\mathbf{a}_{t}</annotation></semantics></math>, and receives a reward <math id="S3.SS1.p2.4.m4.3" class="ltx_Math" alttext="r_{t}=r(\mathbf{s}_{t},\mathbf{a}_{t},\mathbf{s}_{t+1})" display="inline"><semantics id="S3.SS1.p2.4.m4.3a"><mrow id="S3.SS1.p2.4.m4.3.3" xref="S3.SS1.p2.4.m4.3.3.cmml"><msub id="S3.SS1.p2.4.m4.3.3.5" xref="S3.SS1.p2.4.m4.3.3.5.cmml"><mi id="S3.SS1.p2.4.m4.3.3.5.2" xref="S3.SS1.p2.4.m4.3.3.5.2.cmml">r</mi><mi id="S3.SS1.p2.4.m4.3.3.5.3" xref="S3.SS1.p2.4.m4.3.3.5.3.cmml">t</mi></msub><mo id="S3.SS1.p2.4.m4.3.3.4" xref="S3.SS1.p2.4.m4.3.3.4.cmml">=</mo><mrow id="S3.SS1.p2.4.m4.3.3.3" xref="S3.SS1.p2.4.m4.3.3.3.cmml"><mi id="S3.SS1.p2.4.m4.3.3.3.5" xref="S3.SS1.p2.4.m4.3.3.3.5.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.4.m4.3.3.3.4" xref="S3.SS1.p2.4.m4.3.3.3.4.cmml">â€‹</mo><mrow id="S3.SS1.p2.4.m4.3.3.3.3.3" xref="S3.SS1.p2.4.m4.3.3.3.3.4.cmml"><mo stretchy="false" id="S3.SS1.p2.4.m4.3.3.3.3.3.4" xref="S3.SS1.p2.4.m4.3.3.3.3.4.cmml">(</mo><msub id="S3.SS1.p2.4.m4.1.1.1.1.1.1" xref="S3.SS1.p2.4.m4.1.1.1.1.1.1.cmml"><mi id="S3.SS1.p2.4.m4.1.1.1.1.1.1.2" xref="S3.SS1.p2.4.m4.1.1.1.1.1.1.2.cmml">ğ¬</mi><mi id="S3.SS1.p2.4.m4.1.1.1.1.1.1.3" xref="S3.SS1.p2.4.m4.1.1.1.1.1.1.3.cmml">t</mi></msub><mo id="S3.SS1.p2.4.m4.3.3.3.3.3.5" xref="S3.SS1.p2.4.m4.3.3.3.3.4.cmml">,</mo><msub id="S3.SS1.p2.4.m4.2.2.2.2.2.2" xref="S3.SS1.p2.4.m4.2.2.2.2.2.2.cmml"><mi id="S3.SS1.p2.4.m4.2.2.2.2.2.2.2" xref="S3.SS1.p2.4.m4.2.2.2.2.2.2.2.cmml">ğš</mi><mi id="S3.SS1.p2.4.m4.2.2.2.2.2.2.3" xref="S3.SS1.p2.4.m4.2.2.2.2.2.2.3.cmml">t</mi></msub><mo id="S3.SS1.p2.4.m4.3.3.3.3.3.6" xref="S3.SS1.p2.4.m4.3.3.3.3.4.cmml">,</mo><msub id="S3.SS1.p2.4.m4.3.3.3.3.3.3" xref="S3.SS1.p2.4.m4.3.3.3.3.3.3.cmml"><mi id="S3.SS1.p2.4.m4.3.3.3.3.3.3.2" xref="S3.SS1.p2.4.m4.3.3.3.3.3.3.2.cmml">ğ¬</mi><mrow id="S3.SS1.p2.4.m4.3.3.3.3.3.3.3" xref="S3.SS1.p2.4.m4.3.3.3.3.3.3.3.cmml"><mi id="S3.SS1.p2.4.m4.3.3.3.3.3.3.3.2" xref="S3.SS1.p2.4.m4.3.3.3.3.3.3.3.2.cmml">t</mi><mo id="S3.SS1.p2.4.m4.3.3.3.3.3.3.3.1" xref="S3.SS1.p2.4.m4.3.3.3.3.3.3.3.1.cmml">+</mo><mn id="S3.SS1.p2.4.m4.3.3.3.3.3.3.3.3" xref="S3.SS1.p2.4.m4.3.3.3.3.3.3.3.3.cmml">1</mn></mrow></msub><mo stretchy="false" id="S3.SS1.p2.4.m4.3.3.3.3.3.7" xref="S3.SS1.p2.4.m4.3.3.3.3.4.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.4.m4.3b"><apply id="S3.SS1.p2.4.m4.3.3.cmml" xref="S3.SS1.p2.4.m4.3.3"><eq id="S3.SS1.p2.4.m4.3.3.4.cmml" xref="S3.SS1.p2.4.m4.3.3.4"></eq><apply id="S3.SS1.p2.4.m4.3.3.5.cmml" xref="S3.SS1.p2.4.m4.3.3.5"><csymbol cd="ambiguous" id="S3.SS1.p2.4.m4.3.3.5.1.cmml" xref="S3.SS1.p2.4.m4.3.3.5">subscript</csymbol><ci id="S3.SS1.p2.4.m4.3.3.5.2.cmml" xref="S3.SS1.p2.4.m4.3.3.5.2">ğ‘Ÿ</ci><ci id="S3.SS1.p2.4.m4.3.3.5.3.cmml" xref="S3.SS1.p2.4.m4.3.3.5.3">ğ‘¡</ci></apply><apply id="S3.SS1.p2.4.m4.3.3.3.cmml" xref="S3.SS1.p2.4.m4.3.3.3"><times id="S3.SS1.p2.4.m4.3.3.3.4.cmml" xref="S3.SS1.p2.4.m4.3.3.3.4"></times><ci id="S3.SS1.p2.4.m4.3.3.3.5.cmml" xref="S3.SS1.p2.4.m4.3.3.3.5">ğ‘Ÿ</ci><vector id="S3.SS1.p2.4.m4.3.3.3.3.4.cmml" xref="S3.SS1.p2.4.m4.3.3.3.3.3"><apply id="S3.SS1.p2.4.m4.1.1.1.1.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.4.m4.1.1.1.1.1.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p2.4.m4.1.1.1.1.1.1.2.cmml" xref="S3.SS1.p2.4.m4.1.1.1.1.1.1.2">ğ¬</ci><ci id="S3.SS1.p2.4.m4.1.1.1.1.1.1.3.cmml" xref="S3.SS1.p2.4.m4.1.1.1.1.1.1.3">ğ‘¡</ci></apply><apply id="S3.SS1.p2.4.m4.2.2.2.2.2.2.cmml" xref="S3.SS1.p2.4.m4.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p2.4.m4.2.2.2.2.2.2.1.cmml" xref="S3.SS1.p2.4.m4.2.2.2.2.2.2">subscript</csymbol><ci id="S3.SS1.p2.4.m4.2.2.2.2.2.2.2.cmml" xref="S3.SS1.p2.4.m4.2.2.2.2.2.2.2">ğš</ci><ci id="S3.SS1.p2.4.m4.2.2.2.2.2.2.3.cmml" xref="S3.SS1.p2.4.m4.2.2.2.2.2.2.3">ğ‘¡</ci></apply><apply id="S3.SS1.p2.4.m4.3.3.3.3.3.3.cmml" xref="S3.SS1.p2.4.m4.3.3.3.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.p2.4.m4.3.3.3.3.3.3.1.cmml" xref="S3.SS1.p2.4.m4.3.3.3.3.3.3">subscript</csymbol><ci id="S3.SS1.p2.4.m4.3.3.3.3.3.3.2.cmml" xref="S3.SS1.p2.4.m4.3.3.3.3.3.3.2">ğ¬</ci><apply id="S3.SS1.p2.4.m4.3.3.3.3.3.3.3.cmml" xref="S3.SS1.p2.4.m4.3.3.3.3.3.3.3"><plus id="S3.SS1.p2.4.m4.3.3.3.3.3.3.3.1.cmml" xref="S3.SS1.p2.4.m4.3.3.3.3.3.3.3.1"></plus><ci id="S3.SS1.p2.4.m4.3.3.3.3.3.3.3.2.cmml" xref="S3.SS1.p2.4.m4.3.3.3.3.3.3.3.2">ğ‘¡</ci><cn type="integer" id="S3.SS1.p2.4.m4.3.3.3.3.3.3.3.3.cmml" xref="S3.SS1.p2.4.m4.3.3.3.3.3.3.3.3">1</cn></apply></apply></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.4.m4.3c">r_{t}=r(\mathbf{s}_{t},\mathbf{a}_{t},\mathbf{s}_{t+1})</annotation></semantics></math>, where <math id="S3.SS1.p2.5.m5.1" class="ltx_Math" alttext="\mathbf{s}_{t+1}" display="inline"><semantics id="S3.SS1.p2.5.m5.1a"><msub id="S3.SS1.p2.5.m5.1.1" xref="S3.SS1.p2.5.m5.1.1.cmml"><mi id="S3.SS1.p2.5.m5.1.1.2" xref="S3.SS1.p2.5.m5.1.1.2.cmml">ğ¬</mi><mrow id="S3.SS1.p2.5.m5.1.1.3" xref="S3.SS1.p2.5.m5.1.1.3.cmml"><mi id="S3.SS1.p2.5.m5.1.1.3.2" xref="S3.SS1.p2.5.m5.1.1.3.2.cmml">t</mi><mo id="S3.SS1.p2.5.m5.1.1.3.1" xref="S3.SS1.p2.5.m5.1.1.3.1.cmml">+</mo><mn id="S3.SS1.p2.5.m5.1.1.3.3" xref="S3.SS1.p2.5.m5.1.1.3.3.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.5.m5.1b"><apply id="S3.SS1.p2.5.m5.1.1.cmml" xref="S3.SS1.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.5.m5.1.1.1.cmml" xref="S3.SS1.p2.5.m5.1.1">subscript</csymbol><ci id="S3.SS1.p2.5.m5.1.1.2.cmml" xref="S3.SS1.p2.5.m5.1.1.2">ğ¬</ci><apply id="S3.SS1.p2.5.m5.1.1.3.cmml" xref="S3.SS1.p2.5.m5.1.1.3"><plus id="S3.SS1.p2.5.m5.1.1.3.1.cmml" xref="S3.SS1.p2.5.m5.1.1.3.1"></plus><ci id="S3.SS1.p2.5.m5.1.1.3.2.cmml" xref="S3.SS1.p2.5.m5.1.1.3.2">ğ‘¡</ci><cn type="integer" id="S3.SS1.p2.5.m5.1.1.3.3.cmml" xref="S3.SS1.p2.5.m5.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.5.m5.1c">\mathbf{s}_{t+1}</annotation></semantics></math> represents the next state of the environment due to <math id="S3.SS1.p2.6.m6.1" class="ltx_Math" alttext="\mathbf{a}_{t}" display="inline"><semantics id="S3.SS1.p2.6.m6.1a"><msub id="S3.SS1.p2.6.m6.1.1" xref="S3.SS1.p2.6.m6.1.1.cmml"><mi id="S3.SS1.p2.6.m6.1.1.2" xref="S3.SS1.p2.6.m6.1.1.2.cmml">ğš</mi><mi id="S3.SS1.p2.6.m6.1.1.3" xref="S3.SS1.p2.6.m6.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.6.m6.1b"><apply id="S3.SS1.p2.6.m6.1.1.cmml" xref="S3.SS1.p2.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.6.m6.1.1.1.cmml" xref="S3.SS1.p2.6.m6.1.1">subscript</csymbol><ci id="S3.SS1.p2.6.m6.1.1.2.cmml" xref="S3.SS1.p2.6.m6.1.1.2">ğš</ci><ci id="S3.SS1.p2.6.m6.1.1.3.cmml" xref="S3.SS1.p2.6.m6.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.6.m6.1c">\mathbf{a}_{t}</annotation></semantics></math>.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para ltx_noindent">
<p id="S3.SS1.p3.4" class="ltx_p"><span id="S3.SS1.p3.4.1" class="ltx_text ltx_font_bold">Egocentric Sensing As Depth Proxy.</span> We aim to sample actions given by a policy to synthesize realistic human motions.
Egocentric perception-driven motion synthesis should arguably use egocentric vision as input. However, depth rendering is costly and RL requires billions of samples to converge <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">3</span></a>, <a href="#bib.bib113" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">113</span></a>]</cite>. Besides, directly training RL with visual data can be unstable <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib133" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">133</span></a>]</cite>.
We thereby use a cheap-to-compute <span id="S3.SS1.p3.4.2" class="ltx_text ltx_font_italic">egocentric sensing</span> <math id="S3.SS1.p3.1.m1.1" class="ltx_Math" alttext="\mathcal{E}_{t}" display="inline"><semantics id="S3.SS1.p3.1.m1.1a"><msub id="S3.SS1.p3.1.m1.1.1" xref="S3.SS1.p3.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p3.1.m1.1.1.2" xref="S3.SS1.p3.1.m1.1.1.2.cmml">â„°</mi><mi id="S3.SS1.p3.1.m1.1.1.3" xref="S3.SS1.p3.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.1.m1.1b"><apply id="S3.SS1.p3.1.m1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.1.m1.1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p3.1.m1.1.1.2.cmml" xref="S3.SS1.p3.1.m1.1.1.2">â„°</ci><ci id="S3.SS1.p3.1.m1.1.1.3.cmml" xref="S3.SS1.p3.1.m1.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.1.m1.1c">\mathcal{E}_{t}</annotation></semantics></math> as a proxy for depth images as illustrated in Fig.Â <a href="#S3.F2" title="Figure 2 â€£ 3 Ego-Sensing Driven Motion Synthesis â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. <math id="S3.SS1.p3.2.m2.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S3.SS1.p3.2.m2.1a"><mi id="S3.SS1.p3.2.m2.1.1" xref="S3.SS1.p3.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.2.m2.1b"><ci id="S3.SS1.p3.2.m2.1.1.cmml" xref="S3.SS1.p3.2.m2.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.2.m2.1c">N</annotation></semantics></math> rays are cast evenly from the midpoint of two eyeballs, i.e., the location of the egocentric camera. The field of view <math id="S3.SS1.p3.3.m3.2" class="ltx_Math" alttext="[\theta_{min},\theta_{max}]" display="inline"><semantics id="S3.SS1.p3.3.m3.2a"><mrow id="S3.SS1.p3.3.m3.2.2.2" xref="S3.SS1.p3.3.m3.2.2.3.cmml"><mo stretchy="false" id="S3.SS1.p3.3.m3.2.2.2.3" xref="S3.SS1.p3.3.m3.2.2.3.cmml">[</mo><msub id="S3.SS1.p3.3.m3.1.1.1.1" xref="S3.SS1.p3.3.m3.1.1.1.1.cmml"><mi id="S3.SS1.p3.3.m3.1.1.1.1.2" xref="S3.SS1.p3.3.m3.1.1.1.1.2.cmml">Î¸</mi><mrow id="S3.SS1.p3.3.m3.1.1.1.1.3" xref="S3.SS1.p3.3.m3.1.1.1.1.3.cmml"><mi id="S3.SS1.p3.3.m3.1.1.1.1.3.2" xref="S3.SS1.p3.3.m3.1.1.1.1.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p3.3.m3.1.1.1.1.3.1" xref="S3.SS1.p3.3.m3.1.1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS1.p3.3.m3.1.1.1.1.3.3" xref="S3.SS1.p3.3.m3.1.1.1.1.3.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p3.3.m3.1.1.1.1.3.1a" xref="S3.SS1.p3.3.m3.1.1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS1.p3.3.m3.1.1.1.1.3.4" xref="S3.SS1.p3.3.m3.1.1.1.1.3.4.cmml">n</mi></mrow></msub><mo id="S3.SS1.p3.3.m3.2.2.2.4" xref="S3.SS1.p3.3.m3.2.2.3.cmml">,</mo><msub id="S3.SS1.p3.3.m3.2.2.2.2" xref="S3.SS1.p3.3.m3.2.2.2.2.cmml"><mi id="S3.SS1.p3.3.m3.2.2.2.2.2" xref="S3.SS1.p3.3.m3.2.2.2.2.2.cmml">Î¸</mi><mrow id="S3.SS1.p3.3.m3.2.2.2.2.3" xref="S3.SS1.p3.3.m3.2.2.2.2.3.cmml"><mi id="S3.SS1.p3.3.m3.2.2.2.2.3.2" xref="S3.SS1.p3.3.m3.2.2.2.2.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p3.3.m3.2.2.2.2.3.1" xref="S3.SS1.p3.3.m3.2.2.2.2.3.1.cmml">â€‹</mo><mi id="S3.SS1.p3.3.m3.2.2.2.2.3.3" xref="S3.SS1.p3.3.m3.2.2.2.2.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p3.3.m3.2.2.2.2.3.1a" xref="S3.SS1.p3.3.m3.2.2.2.2.3.1.cmml">â€‹</mo><mi id="S3.SS1.p3.3.m3.2.2.2.2.3.4" xref="S3.SS1.p3.3.m3.2.2.2.2.3.4.cmml">x</mi></mrow></msub><mo stretchy="false" id="S3.SS1.p3.3.m3.2.2.2.5" xref="S3.SS1.p3.3.m3.2.2.3.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.3.m3.2b"><interval closure="closed" id="S3.SS1.p3.3.m3.2.2.3.cmml" xref="S3.SS1.p3.3.m3.2.2.2"><apply id="S3.SS1.p3.3.m3.1.1.1.1.cmml" xref="S3.SS1.p3.3.m3.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.3.m3.1.1.1.1.1.cmml" xref="S3.SS1.p3.3.m3.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p3.3.m3.1.1.1.1.2.cmml" xref="S3.SS1.p3.3.m3.1.1.1.1.2">ğœƒ</ci><apply id="S3.SS1.p3.3.m3.1.1.1.1.3.cmml" xref="S3.SS1.p3.3.m3.1.1.1.1.3"><times id="S3.SS1.p3.3.m3.1.1.1.1.3.1.cmml" xref="S3.SS1.p3.3.m3.1.1.1.1.3.1"></times><ci id="S3.SS1.p3.3.m3.1.1.1.1.3.2.cmml" xref="S3.SS1.p3.3.m3.1.1.1.1.3.2">ğ‘š</ci><ci id="S3.SS1.p3.3.m3.1.1.1.1.3.3.cmml" xref="S3.SS1.p3.3.m3.1.1.1.1.3.3">ğ‘–</ci><ci id="S3.SS1.p3.3.m3.1.1.1.1.3.4.cmml" xref="S3.SS1.p3.3.m3.1.1.1.1.3.4">ğ‘›</ci></apply></apply><apply id="S3.SS1.p3.3.m3.2.2.2.2.cmml" xref="S3.SS1.p3.3.m3.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p3.3.m3.2.2.2.2.1.cmml" xref="S3.SS1.p3.3.m3.2.2.2.2">subscript</csymbol><ci id="S3.SS1.p3.3.m3.2.2.2.2.2.cmml" xref="S3.SS1.p3.3.m3.2.2.2.2.2">ğœƒ</ci><apply id="S3.SS1.p3.3.m3.2.2.2.2.3.cmml" xref="S3.SS1.p3.3.m3.2.2.2.2.3"><times id="S3.SS1.p3.3.m3.2.2.2.2.3.1.cmml" xref="S3.SS1.p3.3.m3.2.2.2.2.3.1"></times><ci id="S3.SS1.p3.3.m3.2.2.2.2.3.2.cmml" xref="S3.SS1.p3.3.m3.2.2.2.2.3.2">ğ‘š</ci><ci id="S3.SS1.p3.3.m3.2.2.2.2.3.3.cmml" xref="S3.SS1.p3.3.m3.2.2.2.2.3.3">ğ‘</ci><ci id="S3.SS1.p3.3.m3.2.2.2.2.3.4.cmml" xref="S3.SS1.p3.3.m3.2.2.2.2.3.4">ğ‘¥</ci></apply></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.3.m3.2c">[\theta_{min},\theta_{max}]</annotation></semantics></math>, centered on the 2D projection of the viewing direction <math id="S3.SS1.p3.4.m4.1" class="ltx_Math" alttext="\vv{\mathbf{v}}" display="inline"><semantics id="S3.SS1.p3.4.m4.1a"><mrow id="S3.SS1.p3.4.m4.1.1" xref="S3.SS1.p3.4.m4.1.1.cmml"><merror class="ltx_ERROR undefined undefined" id="S3.SS1.p3.4.m4.1.1.2" xref="S3.SS1.p3.4.m4.1.1.2b.cmml"><mtext id="S3.SS1.p3.4.m4.1.1.2a" xref="S3.SS1.p3.4.m4.1.1.2b.cmml">\vv</mtext></merror><mo lspace="0em" rspace="0em" id="S3.SS1.p3.4.m4.1.1.1" xref="S3.SS1.p3.4.m4.1.1.1.cmml">â€‹</mo><mi id="S3.SS1.p3.4.m4.1.1.3" xref="S3.SS1.p3.4.m4.1.1.3.cmml">ğ¯</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.4.m4.1b"><apply id="S3.SS1.p3.4.m4.1.1.cmml" xref="S3.SS1.p3.4.m4.1.1"><times id="S3.SS1.p3.4.m4.1.1.1.cmml" xref="S3.SS1.p3.4.m4.1.1.1"></times><ci id="S3.SS1.p3.4.m4.1.1.2b.cmml" xref="S3.SS1.p3.4.m4.1.1.2"><merror class="ltx_ERROR undefined undefined" id="S3.SS1.p3.4.m4.1.1.2.cmml" xref="S3.SS1.p3.4.m4.1.1.2"><mtext id="S3.SS1.p3.4.m4.1.1.2a.cmml" xref="S3.SS1.p3.4.m4.1.1.2">\vv</mtext></merror></ci><ci id="S3.SS1.p3.4.m4.1.1.3.cmml" xref="S3.SS1.p3.4.m4.1.1.3">ğ¯</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.4.m4.1c">\vv{\mathbf{v}}</annotation></semantics></math>, limits the agentâ€™s perception to the front area. Rays stop at collisions, with collision detection in 2D. See more details in <a href="#S2.SS1" title="S2.1 Egocentric Sensing Calculation â€£ S2 Ego-Sensing Driven Motion Synthesis â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Sec.</span>Â <span class="ltx_text ltx_ref_tag">S2.1</span></a>.</p>
</div>
<div id="S3.SS1.p4" class="ltx_para ltx_noindent">
<p id="S3.SS1.p4.2" class="ltx_p"><span id="S3.SS1.p4.2.1" class="ltx_text ltx_font_bold">Agent Representation.</span> The agent is a virtual human represented by an SMPL-X mesh <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib67" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">67</span></a>]</cite>. We further compact the body representation by selecting <math id="S3.SS1.p4.1.m1.1" class="ltx_Math" alttext="M=67" display="inline"><semantics id="S3.SS1.p4.1.m1.1a"><mrow id="S3.SS1.p4.1.m1.1.1" xref="S3.SS1.p4.1.m1.1.1.cmml"><mi id="S3.SS1.p4.1.m1.1.1.2" xref="S3.SS1.p4.1.m1.1.1.2.cmml">M</mi><mo id="S3.SS1.p4.1.m1.1.1.1" xref="S3.SS1.p4.1.m1.1.1.1.cmml">=</mo><mn id="S3.SS1.p4.1.m1.1.1.3" xref="S3.SS1.p4.1.m1.1.1.3.cmml">67</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.1.m1.1b"><apply id="S3.SS1.p4.1.m1.1.1.cmml" xref="S3.SS1.p4.1.m1.1.1"><eq id="S3.SS1.p4.1.m1.1.1.1.cmml" xref="S3.SS1.p4.1.m1.1.1.1"></eq><ci id="S3.SS1.p4.1.m1.1.1.2.cmml" xref="S3.SS1.p4.1.m1.1.1.2">ğ‘€</ci><cn type="integer" id="S3.SS1.p4.1.m1.1.1.3.cmml" xref="S3.SS1.p4.1.m1.1.1.3">67</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.1.m1.1c">M=67</annotation></semantics></math> body surface markers <math id="S3.SS1.p4.2.m2.1" class="ltx_Math" alttext="\mathbf{x}\in\mathbb{R}^{M\times 3}" display="inline"><semantics id="S3.SS1.p4.2.m2.1a"><mrow id="S3.SS1.p4.2.m2.1.1" xref="S3.SS1.p4.2.m2.1.1.cmml"><mi id="S3.SS1.p4.2.m2.1.1.2" xref="S3.SS1.p4.2.m2.1.1.2.cmml">ğ±</mi><mo id="S3.SS1.p4.2.m2.1.1.1" xref="S3.SS1.p4.2.m2.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS1.p4.2.m2.1.1.3" xref="S3.SS1.p4.2.m2.1.1.3.cmml"><mi id="S3.SS1.p4.2.m2.1.1.3.2" xref="S3.SS1.p4.2.m2.1.1.3.2.cmml">â„</mi><mrow id="S3.SS1.p4.2.m2.1.1.3.3" xref="S3.SS1.p4.2.m2.1.1.3.3.cmml"><mi id="S3.SS1.p4.2.m2.1.1.3.3.2" xref="S3.SS1.p4.2.m2.1.1.3.3.2.cmml">M</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p4.2.m2.1.1.3.3.1" xref="S3.SS1.p4.2.m2.1.1.3.3.1.cmml">Ã—</mo><mn id="S3.SS1.p4.2.m2.1.1.3.3.3" xref="S3.SS1.p4.2.m2.1.1.3.3.3.cmml">3</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.2.m2.1b"><apply id="S3.SS1.p4.2.m2.1.1.cmml" xref="S3.SS1.p4.2.m2.1.1"><in id="S3.SS1.p4.2.m2.1.1.1.cmml" xref="S3.SS1.p4.2.m2.1.1.1"></in><ci id="S3.SS1.p4.2.m2.1.1.2.cmml" xref="S3.SS1.p4.2.m2.1.1.2">ğ±</ci><apply id="S3.SS1.p4.2.m2.1.1.3.cmml" xref="S3.SS1.p4.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p4.2.m2.1.1.3.1.cmml" xref="S3.SS1.p4.2.m2.1.1.3">superscript</csymbol><ci id="S3.SS1.p4.2.m2.1.1.3.2.cmml" xref="S3.SS1.p4.2.m2.1.1.3.2">â„</ci><apply id="S3.SS1.p4.2.m2.1.1.3.3.cmml" xref="S3.SS1.p4.2.m2.1.1.3.3"><times id="S3.SS1.p4.2.m2.1.1.3.3.1.cmml" xref="S3.SS1.p4.2.m2.1.1.3.3.1"></times><ci id="S3.SS1.p4.2.m2.1.1.3.3.2.cmml" xref="S3.SS1.p4.2.m2.1.1.3.3.2">ğ‘€</ci><cn type="integer" id="S3.SS1.p4.2.m2.1.1.3.3.3.cmml" xref="S3.SS1.p4.2.m2.1.1.3.3.3">3</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.2.m2.1c">\mathbf{x}\in\mathbb{R}^{M\times 3}</annotation></semantics></math> on the mesh following <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib128" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">128</span></a>]</cite>.</p>
</div>
<div id="S3.SS1.p5" class="ltx_para ltx_noindent">
<p id="S3.SS1.p5.9" class="ltx_p"><span id="S3.SS1.p5.9.1" class="ltx_text ltx_font_bold">Motion Primitive Environment.</span>
We implement a <span id="S3.SS1.p5.9.2" class="ltx_text ltx_font_italic">finite-horizon</span> environment based on the generative motion primitive model fromÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib127" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">127</span></a>]</cite>.
Specifically, a motion primitive is defined as a 0.5-second motion clip containing <math id="S3.SS1.p5.1.m1.1" class="ltx_Math" alttext="T=20" display="inline"><semantics id="S3.SS1.p5.1.m1.1a"><mrow id="S3.SS1.p5.1.m1.1.1" xref="S3.SS1.p5.1.m1.1.1.cmml"><mi id="S3.SS1.p5.1.m1.1.1.2" xref="S3.SS1.p5.1.m1.1.1.2.cmml">T</mi><mo id="S3.SS1.p5.1.m1.1.1.1" xref="S3.SS1.p5.1.m1.1.1.1.cmml">=</mo><mn id="S3.SS1.p5.1.m1.1.1.3" xref="S3.SS1.p5.1.m1.1.1.3.cmml">20</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.1.m1.1b"><apply id="S3.SS1.p5.1.m1.1.1.cmml" xref="S3.SS1.p5.1.m1.1.1"><eq id="S3.SS1.p5.1.m1.1.1.1.cmml" xref="S3.SS1.p5.1.m1.1.1.1"></eq><ci id="S3.SS1.p5.1.m1.1.1.2.cmml" xref="S3.SS1.p5.1.m1.1.1.2">ğ‘‡</ci><cn type="integer" id="S3.SS1.p5.1.m1.1.1.3.cmml" xref="S3.SS1.p5.1.m1.1.1.3">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.1.m1.1c">T=20</annotation></semantics></math> frames in the canonical coordinate, and each frame contains a single agent representation.
The primitive modelÂ <math id="S3.SS1.p5.2.m2.1" class="ltx_Math" alttext="\mathcal{P}" display="inline"><semantics id="S3.SS1.p5.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p5.2.m2.1.1" xref="S3.SS1.p5.2.m2.1.1.cmml">ğ’«</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.2.m2.1b"><ci id="S3.SS1.p5.2.m2.1.1.cmml" xref="S3.SS1.p5.2.m2.1.1">ğ’«</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.2.m2.1c">\mathcal{P}</annotation></semantics></math> is based on the C-VAE frameworkÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib96" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">96</span></a>]</cite>, which takes the first <math id="S3.SS1.p5.3.m3.1" class="ltx_Math" alttext="T_{s}=2" display="inline"><semantics id="S3.SS1.p5.3.m3.1a"><mrow id="S3.SS1.p5.3.m3.1.1" xref="S3.SS1.p5.3.m3.1.1.cmml"><msub id="S3.SS1.p5.3.m3.1.1.2" xref="S3.SS1.p5.3.m3.1.1.2.cmml"><mi id="S3.SS1.p5.3.m3.1.1.2.2" xref="S3.SS1.p5.3.m3.1.1.2.2.cmml">T</mi><mi id="S3.SS1.p5.3.m3.1.1.2.3" xref="S3.SS1.p5.3.m3.1.1.2.3.cmml">s</mi></msub><mo id="S3.SS1.p5.3.m3.1.1.1" xref="S3.SS1.p5.3.m3.1.1.1.cmml">=</mo><mn id="S3.SS1.p5.3.m3.1.1.3" xref="S3.SS1.p5.3.m3.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.3.m3.1b"><apply id="S3.SS1.p5.3.m3.1.1.cmml" xref="S3.SS1.p5.3.m3.1.1"><eq id="S3.SS1.p5.3.m3.1.1.1.cmml" xref="S3.SS1.p5.3.m3.1.1.1"></eq><apply id="S3.SS1.p5.3.m3.1.1.2.cmml" xref="S3.SS1.p5.3.m3.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p5.3.m3.1.1.2.1.cmml" xref="S3.SS1.p5.3.m3.1.1.2">subscript</csymbol><ci id="S3.SS1.p5.3.m3.1.1.2.2.cmml" xref="S3.SS1.p5.3.m3.1.1.2.2">ğ‘‡</ci><ci id="S3.SS1.p5.3.m3.1.1.2.3.cmml" xref="S3.SS1.p5.3.m3.1.1.2.3">ğ‘ </ci></apply><cn type="integer" id="S3.SS1.p5.3.m3.1.1.3.cmml" xref="S3.SS1.p5.3.m3.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.3.m3.1c">T_{s}=2</annotation></semantics></math> frames as the condition, and models a conditional probability of the next <math id="S3.SS1.p5.4.m4.1" class="ltx_Math" alttext="T-T_{s}" display="inline"><semantics id="S3.SS1.p5.4.m4.1a"><mrow id="S3.SS1.p5.4.m4.1.1" xref="S3.SS1.p5.4.m4.1.1.cmml"><mi id="S3.SS1.p5.4.m4.1.1.2" xref="S3.SS1.p5.4.m4.1.1.2.cmml">T</mi><mo id="S3.SS1.p5.4.m4.1.1.1" xref="S3.SS1.p5.4.m4.1.1.1.cmml">âˆ’</mo><msub id="S3.SS1.p5.4.m4.1.1.3" xref="S3.SS1.p5.4.m4.1.1.3.cmml"><mi id="S3.SS1.p5.4.m4.1.1.3.2" xref="S3.SS1.p5.4.m4.1.1.3.2.cmml">T</mi><mi id="S3.SS1.p5.4.m4.1.1.3.3" xref="S3.SS1.p5.4.m4.1.1.3.3.cmml">s</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.4.m4.1b"><apply id="S3.SS1.p5.4.m4.1.1.cmml" xref="S3.SS1.p5.4.m4.1.1"><minus id="S3.SS1.p5.4.m4.1.1.1.cmml" xref="S3.SS1.p5.4.m4.1.1.1"></minus><ci id="S3.SS1.p5.4.m4.1.1.2.cmml" xref="S3.SS1.p5.4.m4.1.1.2">ğ‘‡</ci><apply id="S3.SS1.p5.4.m4.1.1.3.cmml" xref="S3.SS1.p5.4.m4.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p5.4.m4.1.1.3.1.cmml" xref="S3.SS1.p5.4.m4.1.1.3">subscript</csymbol><ci id="S3.SS1.p5.4.m4.1.1.3.2.cmml" xref="S3.SS1.p5.4.m4.1.1.3.2">ğ‘‡</ci><ci id="S3.SS1.p5.4.m4.1.1.3.3.cmml" xref="S3.SS1.p5.4.m4.1.1.3.3">ğ‘ </ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.4.m4.1c">T-T_{s}</annotation></semantics></math> frames.
Compared to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib127" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">127</span></a>]</cite> trained on the AMASS datasetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">52</span></a>]</cite> with many sport motion sequences,
we trainÂ <math id="S3.SS1.p5.5.m5.1" class="ltx_Math" alttext="\mathcal{P}" display="inline"><semantics id="S3.SS1.p5.5.m5.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p5.5.m5.1.1" xref="S3.SS1.p5.5.m5.1.1.cmml">ğ’«</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.5.m5.1b"><ci id="S3.SS1.p5.5.m5.1.1.cmml" xref="S3.SS1.p5.5.m5.1.1">ğ’«</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.5.m5.1c">\mathcal{P}</annotation></semantics></math> using the SAMP datasetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">33</span></a>]</cite>, which focuses on daily activities, better suited for HMD use cases.
Our <span id="S3.SS1.p5.9.3" class="ltx_text ltx_font_italic">action space</span> <math id="S3.SS1.p5.6.m6.1" class="ltx_Math" alttext="\mathcal{A}" display="inline"><semantics id="S3.SS1.p5.6.m6.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p5.6.m6.1.1" xref="S3.SS1.p5.6.m6.1.1.cmml">ğ’œ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.6.m6.1b"><ci id="S3.SS1.p5.6.m6.1.1.cmml" xref="S3.SS1.p5.6.m6.1.1">ğ’œ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.6.m6.1c">\mathcal{A}</annotation></semantics></math> is the pretrained 128D latent space of <math id="S3.SS1.p5.7.m7.1" class="ltx_Math" alttext="\mathcal{P}" display="inline"><semantics id="S3.SS1.p5.7.m7.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p5.7.m7.1.1" xref="S3.SS1.p5.7.m7.1.1.cmml">ğ’«</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.7.m7.1b"><ci id="S3.SS1.p5.7.m7.1.1.cmml" xref="S3.SS1.p5.7.m7.1.1">ğ’«</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.7.m7.1c">\mathcal{P}</annotation></semantics></math>, and the <span id="S3.SS1.p5.9.4" class="ltx_text ltx_font_bold">action</span> <math id="S3.SS1.p5.8.m8.1" class="ltx_Math" alttext="\mathbf{a}_{t}" display="inline"><semantics id="S3.SS1.p5.8.m8.1a"><msub id="S3.SS1.p5.8.m8.1.1" xref="S3.SS1.p5.8.m8.1.1.cmml"><mi id="S3.SS1.p5.8.m8.1.1.2" xref="S3.SS1.p5.8.m8.1.1.2.cmml">ğš</mi><mi id="S3.SS1.p5.8.m8.1.1.3" xref="S3.SS1.p5.8.m8.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.8.m8.1b"><apply id="S3.SS1.p5.8.m8.1.1.cmml" xref="S3.SS1.p5.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS1.p5.8.m8.1.1.1.cmml" xref="S3.SS1.p5.8.m8.1.1">subscript</csymbol><ci id="S3.SS1.p5.8.m8.1.1.2.cmml" xref="S3.SS1.p5.8.m8.1.1.2">ğš</ci><ci id="S3.SS1.p5.8.m8.1.1.3.cmml" xref="S3.SS1.p5.8.m8.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.8.m8.1c">\mathbf{a}_{t}</annotation></semantics></math> can be randomly sampled from <math id="S3.SS1.p5.9.m9.1" class="ltx_Math" alttext="\mathcal{A}" display="inline"><semantics id="S3.SS1.p5.9.m9.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p5.9.m9.1.1" xref="S3.SS1.p5.9.m9.1.1.cmml">ğ’œ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.9.m9.1b"><ci id="S3.SS1.p5.9.m9.1.1.cmml" xref="S3.SS1.p5.9.m9.1.1">ğ’œ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.9.m9.1c">\mathcal{A}</annotation></semantics></math>.</p>
</div>
<div id="S3.SS1.p6" class="ltx_para">
<p id="S3.SS1.p6.5" class="ltx_p">With the input of a random action <math id="S3.SS1.p6.1.m1.1" class="ltx_Math" alttext="\mathbf{a}_{t}\in\mathbb{R}^{128}" display="inline"><semantics id="S3.SS1.p6.1.m1.1a"><mrow id="S3.SS1.p6.1.m1.1.1" xref="S3.SS1.p6.1.m1.1.1.cmml"><msub id="S3.SS1.p6.1.m1.1.1.2" xref="S3.SS1.p6.1.m1.1.1.2.cmml"><mi id="S3.SS1.p6.1.m1.1.1.2.2" xref="S3.SS1.p6.1.m1.1.1.2.2.cmml">ğš</mi><mi id="S3.SS1.p6.1.m1.1.1.2.3" xref="S3.SS1.p6.1.m1.1.1.2.3.cmml">t</mi></msub><mo id="S3.SS1.p6.1.m1.1.1.1" xref="S3.SS1.p6.1.m1.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS1.p6.1.m1.1.1.3" xref="S3.SS1.p6.1.m1.1.1.3.cmml"><mi id="S3.SS1.p6.1.m1.1.1.3.2" xref="S3.SS1.p6.1.m1.1.1.3.2.cmml">â„</mi><mn id="S3.SS1.p6.1.m1.1.1.3.3" xref="S3.SS1.p6.1.m1.1.1.3.3.cmml">128</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p6.1.m1.1b"><apply id="S3.SS1.p6.1.m1.1.1.cmml" xref="S3.SS1.p6.1.m1.1.1"><in id="S3.SS1.p6.1.m1.1.1.1.cmml" xref="S3.SS1.p6.1.m1.1.1.1"></in><apply id="S3.SS1.p6.1.m1.1.1.2.cmml" xref="S3.SS1.p6.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p6.1.m1.1.1.2.1.cmml" xref="S3.SS1.p6.1.m1.1.1.2">subscript</csymbol><ci id="S3.SS1.p6.1.m1.1.1.2.2.cmml" xref="S3.SS1.p6.1.m1.1.1.2.2">ğš</ci><ci id="S3.SS1.p6.1.m1.1.1.2.3.cmml" xref="S3.SS1.p6.1.m1.1.1.2.3">ğ‘¡</ci></apply><apply id="S3.SS1.p6.1.m1.1.1.3.cmml" xref="S3.SS1.p6.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p6.1.m1.1.1.3.1.cmml" xref="S3.SS1.p6.1.m1.1.1.3">superscript</csymbol><ci id="S3.SS1.p6.1.m1.1.1.3.2.cmml" xref="S3.SS1.p6.1.m1.1.1.3.2">â„</ci><cn type="integer" id="S3.SS1.p6.1.m1.1.1.3.3.cmml" xref="S3.SS1.p6.1.m1.1.1.3.3">128</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p6.1.m1.1c">\mathbf{a}_{t}\in\mathbb{R}^{128}</annotation></semantics></math> and a motion <span id="S3.SS1.p6.5.1" class="ltx_text ltx_font_bold">s</span>eed <math id="S3.SS1.p6.2.m2.2" class="ltx_Math" alttext="\mathbf{X}^{S}_{t}=[\mathbf{x}_{t}^{0},\mathbf{x}_{t}^{T_{s}-1}]" display="inline"><semantics id="S3.SS1.p6.2.m2.2a"><mrow id="S3.SS1.p6.2.m2.2.2" xref="S3.SS1.p6.2.m2.2.2.cmml"><msubsup id="S3.SS1.p6.2.m2.2.2.4" xref="S3.SS1.p6.2.m2.2.2.4.cmml"><mi id="S3.SS1.p6.2.m2.2.2.4.2.2" xref="S3.SS1.p6.2.m2.2.2.4.2.2.cmml">ğ—</mi><mi id="S3.SS1.p6.2.m2.2.2.4.3" xref="S3.SS1.p6.2.m2.2.2.4.3.cmml">t</mi><mi id="S3.SS1.p6.2.m2.2.2.4.2.3" xref="S3.SS1.p6.2.m2.2.2.4.2.3.cmml">S</mi></msubsup><mo id="S3.SS1.p6.2.m2.2.2.3" xref="S3.SS1.p6.2.m2.2.2.3.cmml">=</mo><mrow id="S3.SS1.p6.2.m2.2.2.2.2" xref="S3.SS1.p6.2.m2.2.2.2.3.cmml"><mo stretchy="false" id="S3.SS1.p6.2.m2.2.2.2.2.3" xref="S3.SS1.p6.2.m2.2.2.2.3.cmml">[</mo><msubsup id="S3.SS1.p6.2.m2.1.1.1.1.1" xref="S3.SS1.p6.2.m2.1.1.1.1.1.cmml"><mi id="S3.SS1.p6.2.m2.1.1.1.1.1.2.2" xref="S3.SS1.p6.2.m2.1.1.1.1.1.2.2.cmml">ğ±</mi><mi id="S3.SS1.p6.2.m2.1.1.1.1.1.2.3" xref="S3.SS1.p6.2.m2.1.1.1.1.1.2.3.cmml">t</mi><mn id="S3.SS1.p6.2.m2.1.1.1.1.1.3" xref="S3.SS1.p6.2.m2.1.1.1.1.1.3.cmml">0</mn></msubsup><mo id="S3.SS1.p6.2.m2.2.2.2.2.4" xref="S3.SS1.p6.2.m2.2.2.2.3.cmml">,</mo><msubsup id="S3.SS1.p6.2.m2.2.2.2.2.2" xref="S3.SS1.p6.2.m2.2.2.2.2.2.cmml"><mi id="S3.SS1.p6.2.m2.2.2.2.2.2.2.2" xref="S3.SS1.p6.2.m2.2.2.2.2.2.2.2.cmml">ğ±</mi><mi id="S3.SS1.p6.2.m2.2.2.2.2.2.2.3" xref="S3.SS1.p6.2.m2.2.2.2.2.2.2.3.cmml">t</mi><mrow id="S3.SS1.p6.2.m2.2.2.2.2.2.3" xref="S3.SS1.p6.2.m2.2.2.2.2.2.3.cmml"><msub id="S3.SS1.p6.2.m2.2.2.2.2.2.3.2" xref="S3.SS1.p6.2.m2.2.2.2.2.2.3.2.cmml"><mi id="S3.SS1.p6.2.m2.2.2.2.2.2.3.2.2" xref="S3.SS1.p6.2.m2.2.2.2.2.2.3.2.2.cmml">T</mi><mi id="S3.SS1.p6.2.m2.2.2.2.2.2.3.2.3" xref="S3.SS1.p6.2.m2.2.2.2.2.2.3.2.3.cmml">s</mi></msub><mo id="S3.SS1.p6.2.m2.2.2.2.2.2.3.1" xref="S3.SS1.p6.2.m2.2.2.2.2.2.3.1.cmml">âˆ’</mo><mn id="S3.SS1.p6.2.m2.2.2.2.2.2.3.3" xref="S3.SS1.p6.2.m2.2.2.2.2.2.3.3.cmml">1</mn></mrow></msubsup><mo stretchy="false" id="S3.SS1.p6.2.m2.2.2.2.2.5" xref="S3.SS1.p6.2.m2.2.2.2.3.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p6.2.m2.2b"><apply id="S3.SS1.p6.2.m2.2.2.cmml" xref="S3.SS1.p6.2.m2.2.2"><eq id="S3.SS1.p6.2.m2.2.2.3.cmml" xref="S3.SS1.p6.2.m2.2.2.3"></eq><apply id="S3.SS1.p6.2.m2.2.2.4.cmml" xref="S3.SS1.p6.2.m2.2.2.4"><csymbol cd="ambiguous" id="S3.SS1.p6.2.m2.2.2.4.1.cmml" xref="S3.SS1.p6.2.m2.2.2.4">subscript</csymbol><apply id="S3.SS1.p6.2.m2.2.2.4.2.cmml" xref="S3.SS1.p6.2.m2.2.2.4"><csymbol cd="ambiguous" id="S3.SS1.p6.2.m2.2.2.4.2.1.cmml" xref="S3.SS1.p6.2.m2.2.2.4">superscript</csymbol><ci id="S3.SS1.p6.2.m2.2.2.4.2.2.cmml" xref="S3.SS1.p6.2.m2.2.2.4.2.2">ğ—</ci><ci id="S3.SS1.p6.2.m2.2.2.4.2.3.cmml" xref="S3.SS1.p6.2.m2.2.2.4.2.3">ğ‘†</ci></apply><ci id="S3.SS1.p6.2.m2.2.2.4.3.cmml" xref="S3.SS1.p6.2.m2.2.2.4.3">ğ‘¡</ci></apply><interval closure="closed" id="S3.SS1.p6.2.m2.2.2.2.3.cmml" xref="S3.SS1.p6.2.m2.2.2.2.2"><apply id="S3.SS1.p6.2.m2.1.1.1.1.1.cmml" xref="S3.SS1.p6.2.m2.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p6.2.m2.1.1.1.1.1.1.cmml" xref="S3.SS1.p6.2.m2.1.1.1.1.1">superscript</csymbol><apply id="S3.SS1.p6.2.m2.1.1.1.1.1.2.cmml" xref="S3.SS1.p6.2.m2.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p6.2.m2.1.1.1.1.1.2.1.cmml" xref="S3.SS1.p6.2.m2.1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p6.2.m2.1.1.1.1.1.2.2.cmml" xref="S3.SS1.p6.2.m2.1.1.1.1.1.2.2">ğ±</ci><ci id="S3.SS1.p6.2.m2.1.1.1.1.1.2.3.cmml" xref="S3.SS1.p6.2.m2.1.1.1.1.1.2.3">ğ‘¡</ci></apply><cn type="integer" id="S3.SS1.p6.2.m2.1.1.1.1.1.3.cmml" xref="S3.SS1.p6.2.m2.1.1.1.1.1.3">0</cn></apply><apply id="S3.SS1.p6.2.m2.2.2.2.2.2.cmml" xref="S3.SS1.p6.2.m2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p6.2.m2.2.2.2.2.2.1.cmml" xref="S3.SS1.p6.2.m2.2.2.2.2.2">superscript</csymbol><apply id="S3.SS1.p6.2.m2.2.2.2.2.2.2.cmml" xref="S3.SS1.p6.2.m2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p6.2.m2.2.2.2.2.2.2.1.cmml" xref="S3.SS1.p6.2.m2.2.2.2.2.2">subscript</csymbol><ci id="S3.SS1.p6.2.m2.2.2.2.2.2.2.2.cmml" xref="S3.SS1.p6.2.m2.2.2.2.2.2.2.2">ğ±</ci><ci id="S3.SS1.p6.2.m2.2.2.2.2.2.2.3.cmml" xref="S3.SS1.p6.2.m2.2.2.2.2.2.2.3">ğ‘¡</ci></apply><apply id="S3.SS1.p6.2.m2.2.2.2.2.2.3.cmml" xref="S3.SS1.p6.2.m2.2.2.2.2.2.3"><minus id="S3.SS1.p6.2.m2.2.2.2.2.2.3.1.cmml" xref="S3.SS1.p6.2.m2.2.2.2.2.2.3.1"></minus><apply id="S3.SS1.p6.2.m2.2.2.2.2.2.3.2.cmml" xref="S3.SS1.p6.2.m2.2.2.2.2.2.3.2"><csymbol cd="ambiguous" id="S3.SS1.p6.2.m2.2.2.2.2.2.3.2.1.cmml" xref="S3.SS1.p6.2.m2.2.2.2.2.2.3.2">subscript</csymbol><ci id="S3.SS1.p6.2.m2.2.2.2.2.2.3.2.2.cmml" xref="S3.SS1.p6.2.m2.2.2.2.2.2.3.2.2">ğ‘‡</ci><ci id="S3.SS1.p6.2.m2.2.2.2.2.2.3.2.3.cmml" xref="S3.SS1.p6.2.m2.2.2.2.2.2.3.2.3">ğ‘ </ci></apply><cn type="integer" id="S3.SS1.p6.2.m2.2.2.2.2.2.3.3.cmml" xref="S3.SS1.p6.2.m2.2.2.2.2.2.3.3">1</cn></apply></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p6.2.m2.2c">\mathbf{X}^{S}_{t}=[\mathbf{x}_{t}^{0},\mathbf{x}_{t}^{T_{s}-1}]</annotation></semantics></math> (history frames), <math id="S3.SS1.p6.3.m3.1" class="ltx_Math" alttext="\mathcal{P}" display="inline"><semantics id="S3.SS1.p6.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p6.3.m3.1.1" xref="S3.SS1.p6.3.m3.1.1.cmml">ğ’«</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p6.3.m3.1b"><ci id="S3.SS1.p6.3.m3.1.1.cmml" xref="S3.SS1.p6.3.m3.1.1">ğ’«</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p6.3.m3.1c">\mathcal{P}</annotation></semantics></math> predicts <span id="S3.SS1.p6.5.2" class="ltx_text ltx_font_bold">f</span>uture frames <math id="S3.SS1.p6.4.m4.3" class="ltx_Math" alttext="\mathbf{X}^{F}_{t}=[\mathbf{x}_{t}^{T_{s}},...,\mathbf{x}_{t}^{T-1}]" display="inline"><semantics id="S3.SS1.p6.4.m4.3a"><mrow id="S3.SS1.p6.4.m4.3.3" xref="S3.SS1.p6.4.m4.3.3.cmml"><msubsup id="S3.SS1.p6.4.m4.3.3.4" xref="S3.SS1.p6.4.m4.3.3.4.cmml"><mi id="S3.SS1.p6.4.m4.3.3.4.2.2" xref="S3.SS1.p6.4.m4.3.3.4.2.2.cmml">ğ—</mi><mi id="S3.SS1.p6.4.m4.3.3.4.3" xref="S3.SS1.p6.4.m4.3.3.4.3.cmml">t</mi><mi id="S3.SS1.p6.4.m4.3.3.4.2.3" xref="S3.SS1.p6.4.m4.3.3.4.2.3.cmml">F</mi></msubsup><mo id="S3.SS1.p6.4.m4.3.3.3" xref="S3.SS1.p6.4.m4.3.3.3.cmml">=</mo><mrow id="S3.SS1.p6.4.m4.3.3.2.2" xref="S3.SS1.p6.4.m4.3.3.2.3.cmml"><mo stretchy="false" id="S3.SS1.p6.4.m4.3.3.2.2.3" xref="S3.SS1.p6.4.m4.3.3.2.3.cmml">[</mo><msubsup id="S3.SS1.p6.4.m4.2.2.1.1.1" xref="S3.SS1.p6.4.m4.2.2.1.1.1.cmml"><mi id="S3.SS1.p6.4.m4.2.2.1.1.1.2.2" xref="S3.SS1.p6.4.m4.2.2.1.1.1.2.2.cmml">ğ±</mi><mi id="S3.SS1.p6.4.m4.2.2.1.1.1.2.3" xref="S3.SS1.p6.4.m4.2.2.1.1.1.2.3.cmml">t</mi><msub id="S3.SS1.p6.4.m4.2.2.1.1.1.3" xref="S3.SS1.p6.4.m4.2.2.1.1.1.3.cmml"><mi id="S3.SS1.p6.4.m4.2.2.1.1.1.3.2" xref="S3.SS1.p6.4.m4.2.2.1.1.1.3.2.cmml">T</mi><mi id="S3.SS1.p6.4.m4.2.2.1.1.1.3.3" xref="S3.SS1.p6.4.m4.2.2.1.1.1.3.3.cmml">s</mi></msub></msubsup><mo id="S3.SS1.p6.4.m4.3.3.2.2.4" xref="S3.SS1.p6.4.m4.3.3.2.3.cmml">,</mo><mi mathvariant="normal" id="S3.SS1.p6.4.m4.1.1" xref="S3.SS1.p6.4.m4.1.1.cmml">â€¦</mi><mo id="S3.SS1.p6.4.m4.3.3.2.2.5" xref="S3.SS1.p6.4.m4.3.3.2.3.cmml">,</mo><msubsup id="S3.SS1.p6.4.m4.3.3.2.2.2" xref="S3.SS1.p6.4.m4.3.3.2.2.2.cmml"><mi id="S3.SS1.p6.4.m4.3.3.2.2.2.2.2" xref="S3.SS1.p6.4.m4.3.3.2.2.2.2.2.cmml">ğ±</mi><mi id="S3.SS1.p6.4.m4.3.3.2.2.2.2.3" xref="S3.SS1.p6.4.m4.3.3.2.2.2.2.3.cmml">t</mi><mrow id="S3.SS1.p6.4.m4.3.3.2.2.2.3" xref="S3.SS1.p6.4.m4.3.3.2.2.2.3.cmml"><mi id="S3.SS1.p6.4.m4.3.3.2.2.2.3.2" xref="S3.SS1.p6.4.m4.3.3.2.2.2.3.2.cmml">T</mi><mo id="S3.SS1.p6.4.m4.3.3.2.2.2.3.1" xref="S3.SS1.p6.4.m4.3.3.2.2.2.3.1.cmml">âˆ’</mo><mn id="S3.SS1.p6.4.m4.3.3.2.2.2.3.3" xref="S3.SS1.p6.4.m4.3.3.2.2.2.3.3.cmml">1</mn></mrow></msubsup><mo stretchy="false" id="S3.SS1.p6.4.m4.3.3.2.2.6" xref="S3.SS1.p6.4.m4.3.3.2.3.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p6.4.m4.3b"><apply id="S3.SS1.p6.4.m4.3.3.cmml" xref="S3.SS1.p6.4.m4.3.3"><eq id="S3.SS1.p6.4.m4.3.3.3.cmml" xref="S3.SS1.p6.4.m4.3.3.3"></eq><apply id="S3.SS1.p6.4.m4.3.3.4.cmml" xref="S3.SS1.p6.4.m4.3.3.4"><csymbol cd="ambiguous" id="S3.SS1.p6.4.m4.3.3.4.1.cmml" xref="S3.SS1.p6.4.m4.3.3.4">subscript</csymbol><apply id="S3.SS1.p6.4.m4.3.3.4.2.cmml" xref="S3.SS1.p6.4.m4.3.3.4"><csymbol cd="ambiguous" id="S3.SS1.p6.4.m4.3.3.4.2.1.cmml" xref="S3.SS1.p6.4.m4.3.3.4">superscript</csymbol><ci id="S3.SS1.p6.4.m4.3.3.4.2.2.cmml" xref="S3.SS1.p6.4.m4.3.3.4.2.2">ğ—</ci><ci id="S3.SS1.p6.4.m4.3.3.4.2.3.cmml" xref="S3.SS1.p6.4.m4.3.3.4.2.3">ğ¹</ci></apply><ci id="S3.SS1.p6.4.m4.3.3.4.3.cmml" xref="S3.SS1.p6.4.m4.3.3.4.3">ğ‘¡</ci></apply><list id="S3.SS1.p6.4.m4.3.3.2.3.cmml" xref="S3.SS1.p6.4.m4.3.3.2.2"><apply id="S3.SS1.p6.4.m4.2.2.1.1.1.cmml" xref="S3.SS1.p6.4.m4.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p6.4.m4.2.2.1.1.1.1.cmml" xref="S3.SS1.p6.4.m4.2.2.1.1.1">superscript</csymbol><apply id="S3.SS1.p6.4.m4.2.2.1.1.1.2.cmml" xref="S3.SS1.p6.4.m4.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p6.4.m4.2.2.1.1.1.2.1.cmml" xref="S3.SS1.p6.4.m4.2.2.1.1.1">subscript</csymbol><ci id="S3.SS1.p6.4.m4.2.2.1.1.1.2.2.cmml" xref="S3.SS1.p6.4.m4.2.2.1.1.1.2.2">ğ±</ci><ci id="S3.SS1.p6.4.m4.2.2.1.1.1.2.3.cmml" xref="S3.SS1.p6.4.m4.2.2.1.1.1.2.3">ğ‘¡</ci></apply><apply id="S3.SS1.p6.4.m4.2.2.1.1.1.3.cmml" xref="S3.SS1.p6.4.m4.2.2.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p6.4.m4.2.2.1.1.1.3.1.cmml" xref="S3.SS1.p6.4.m4.2.2.1.1.1.3">subscript</csymbol><ci id="S3.SS1.p6.4.m4.2.2.1.1.1.3.2.cmml" xref="S3.SS1.p6.4.m4.2.2.1.1.1.3.2">ğ‘‡</ci><ci id="S3.SS1.p6.4.m4.2.2.1.1.1.3.3.cmml" xref="S3.SS1.p6.4.m4.2.2.1.1.1.3.3">ğ‘ </ci></apply></apply><ci id="S3.SS1.p6.4.m4.1.1.cmml" xref="S3.SS1.p6.4.m4.1.1">â€¦</ci><apply id="S3.SS1.p6.4.m4.3.3.2.2.2.cmml" xref="S3.SS1.p6.4.m4.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p6.4.m4.3.3.2.2.2.1.cmml" xref="S3.SS1.p6.4.m4.3.3.2.2.2">superscript</csymbol><apply id="S3.SS1.p6.4.m4.3.3.2.2.2.2.cmml" xref="S3.SS1.p6.4.m4.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p6.4.m4.3.3.2.2.2.2.1.cmml" xref="S3.SS1.p6.4.m4.3.3.2.2.2">subscript</csymbol><ci id="S3.SS1.p6.4.m4.3.3.2.2.2.2.2.cmml" xref="S3.SS1.p6.4.m4.3.3.2.2.2.2.2">ğ±</ci><ci id="S3.SS1.p6.4.m4.3.3.2.2.2.2.3.cmml" xref="S3.SS1.p6.4.m4.3.3.2.2.2.2.3">ğ‘¡</ci></apply><apply id="S3.SS1.p6.4.m4.3.3.2.2.2.3.cmml" xref="S3.SS1.p6.4.m4.3.3.2.2.2.3"><minus id="S3.SS1.p6.4.m4.3.3.2.2.2.3.1.cmml" xref="S3.SS1.p6.4.m4.3.3.2.2.2.3.1"></minus><ci id="S3.SS1.p6.4.m4.3.3.2.2.2.3.2.cmml" xref="S3.SS1.p6.4.m4.3.3.2.2.2.3.2">ğ‘‡</ci><cn type="integer" id="S3.SS1.p6.4.m4.3.3.2.2.2.3.3.cmml" xref="S3.SS1.p6.4.m4.3.3.2.2.2.3.3">1</cn></apply></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p6.4.m4.3c">\mathbf{X}^{F}_{t}=[\mathbf{x}_{t}^{T_{s}},...,\mathbf{x}_{t}^{T-1}]</annotation></semantics></math> of the current motion primitive <math id="S3.SS1.p6.5.m5.2" class="ltx_Math" alttext="\mathbf{X}_{t}=[\mathbf{X}^{S}_{t},\mathbf{X}^{F}_{t}]\in\mathbb{R}^{T\times M\times 3}" display="inline"><semantics id="S3.SS1.p6.5.m5.2a"><mrow id="S3.SS1.p6.5.m5.2.2" xref="S3.SS1.p6.5.m5.2.2.cmml"><msub id="S3.SS1.p6.5.m5.2.2.4" xref="S3.SS1.p6.5.m5.2.2.4.cmml"><mi id="S3.SS1.p6.5.m5.2.2.4.2" xref="S3.SS1.p6.5.m5.2.2.4.2.cmml">ğ—</mi><mi id="S3.SS1.p6.5.m5.2.2.4.3" xref="S3.SS1.p6.5.m5.2.2.4.3.cmml">t</mi></msub><mo id="S3.SS1.p6.5.m5.2.2.5" xref="S3.SS1.p6.5.m5.2.2.5.cmml">=</mo><mrow id="S3.SS1.p6.5.m5.2.2.2.2" xref="S3.SS1.p6.5.m5.2.2.2.3.cmml"><mo stretchy="false" id="S3.SS1.p6.5.m5.2.2.2.2.3" xref="S3.SS1.p6.5.m5.2.2.2.3.cmml">[</mo><msubsup id="S3.SS1.p6.5.m5.1.1.1.1.1" xref="S3.SS1.p6.5.m5.1.1.1.1.1.cmml"><mi id="S3.SS1.p6.5.m5.1.1.1.1.1.2.2" xref="S3.SS1.p6.5.m5.1.1.1.1.1.2.2.cmml">ğ—</mi><mi id="S3.SS1.p6.5.m5.1.1.1.1.1.3" xref="S3.SS1.p6.5.m5.1.1.1.1.1.3.cmml">t</mi><mi id="S3.SS1.p6.5.m5.1.1.1.1.1.2.3" xref="S3.SS1.p6.5.m5.1.1.1.1.1.2.3.cmml">S</mi></msubsup><mo id="S3.SS1.p6.5.m5.2.2.2.2.4" xref="S3.SS1.p6.5.m5.2.2.2.3.cmml">,</mo><msubsup id="S3.SS1.p6.5.m5.2.2.2.2.2" xref="S3.SS1.p6.5.m5.2.2.2.2.2.cmml"><mi id="S3.SS1.p6.5.m5.2.2.2.2.2.2.2" xref="S3.SS1.p6.5.m5.2.2.2.2.2.2.2.cmml">ğ—</mi><mi id="S3.SS1.p6.5.m5.2.2.2.2.2.3" xref="S3.SS1.p6.5.m5.2.2.2.2.2.3.cmml">t</mi><mi id="S3.SS1.p6.5.m5.2.2.2.2.2.2.3" xref="S3.SS1.p6.5.m5.2.2.2.2.2.2.3.cmml">F</mi></msubsup><mo stretchy="false" id="S3.SS1.p6.5.m5.2.2.2.2.5" xref="S3.SS1.p6.5.m5.2.2.2.3.cmml">]</mo></mrow><mo id="S3.SS1.p6.5.m5.2.2.6" xref="S3.SS1.p6.5.m5.2.2.6.cmml">âˆˆ</mo><msup id="S3.SS1.p6.5.m5.2.2.7" xref="S3.SS1.p6.5.m5.2.2.7.cmml"><mi id="S3.SS1.p6.5.m5.2.2.7.2" xref="S3.SS1.p6.5.m5.2.2.7.2.cmml">â„</mi><mrow id="S3.SS1.p6.5.m5.2.2.7.3" xref="S3.SS1.p6.5.m5.2.2.7.3.cmml"><mi id="S3.SS1.p6.5.m5.2.2.7.3.2" xref="S3.SS1.p6.5.m5.2.2.7.3.2.cmml">T</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p6.5.m5.2.2.7.3.1" xref="S3.SS1.p6.5.m5.2.2.7.3.1.cmml">Ã—</mo><mi id="S3.SS1.p6.5.m5.2.2.7.3.3" xref="S3.SS1.p6.5.m5.2.2.7.3.3.cmml">M</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p6.5.m5.2.2.7.3.1a" xref="S3.SS1.p6.5.m5.2.2.7.3.1.cmml">Ã—</mo><mn id="S3.SS1.p6.5.m5.2.2.7.3.4" xref="S3.SS1.p6.5.m5.2.2.7.3.4.cmml">3</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p6.5.m5.2b"><apply id="S3.SS1.p6.5.m5.2.2.cmml" xref="S3.SS1.p6.5.m5.2.2"><and id="S3.SS1.p6.5.m5.2.2a.cmml" xref="S3.SS1.p6.5.m5.2.2"></and><apply id="S3.SS1.p6.5.m5.2.2b.cmml" xref="S3.SS1.p6.5.m5.2.2"><eq id="S3.SS1.p6.5.m5.2.2.5.cmml" xref="S3.SS1.p6.5.m5.2.2.5"></eq><apply id="S3.SS1.p6.5.m5.2.2.4.cmml" xref="S3.SS1.p6.5.m5.2.2.4"><csymbol cd="ambiguous" id="S3.SS1.p6.5.m5.2.2.4.1.cmml" xref="S3.SS1.p6.5.m5.2.2.4">subscript</csymbol><ci id="S3.SS1.p6.5.m5.2.2.4.2.cmml" xref="S3.SS1.p6.5.m5.2.2.4.2">ğ—</ci><ci id="S3.SS1.p6.5.m5.2.2.4.3.cmml" xref="S3.SS1.p6.5.m5.2.2.4.3">ğ‘¡</ci></apply><interval closure="closed" id="S3.SS1.p6.5.m5.2.2.2.3.cmml" xref="S3.SS1.p6.5.m5.2.2.2.2"><apply id="S3.SS1.p6.5.m5.1.1.1.1.1.cmml" xref="S3.SS1.p6.5.m5.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p6.5.m5.1.1.1.1.1.1.cmml" xref="S3.SS1.p6.5.m5.1.1.1.1.1">subscript</csymbol><apply id="S3.SS1.p6.5.m5.1.1.1.1.1.2.cmml" xref="S3.SS1.p6.5.m5.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p6.5.m5.1.1.1.1.1.2.1.cmml" xref="S3.SS1.p6.5.m5.1.1.1.1.1">superscript</csymbol><ci id="S3.SS1.p6.5.m5.1.1.1.1.1.2.2.cmml" xref="S3.SS1.p6.5.m5.1.1.1.1.1.2.2">ğ—</ci><ci id="S3.SS1.p6.5.m5.1.1.1.1.1.2.3.cmml" xref="S3.SS1.p6.5.m5.1.1.1.1.1.2.3">ğ‘†</ci></apply><ci id="S3.SS1.p6.5.m5.1.1.1.1.1.3.cmml" xref="S3.SS1.p6.5.m5.1.1.1.1.1.3">ğ‘¡</ci></apply><apply id="S3.SS1.p6.5.m5.2.2.2.2.2.cmml" xref="S3.SS1.p6.5.m5.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p6.5.m5.2.2.2.2.2.1.cmml" xref="S3.SS1.p6.5.m5.2.2.2.2.2">subscript</csymbol><apply id="S3.SS1.p6.5.m5.2.2.2.2.2.2.cmml" xref="S3.SS1.p6.5.m5.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p6.5.m5.2.2.2.2.2.2.1.cmml" xref="S3.SS1.p6.5.m5.2.2.2.2.2">superscript</csymbol><ci id="S3.SS1.p6.5.m5.2.2.2.2.2.2.2.cmml" xref="S3.SS1.p6.5.m5.2.2.2.2.2.2.2">ğ—</ci><ci id="S3.SS1.p6.5.m5.2.2.2.2.2.2.3.cmml" xref="S3.SS1.p6.5.m5.2.2.2.2.2.2.3">ğ¹</ci></apply><ci id="S3.SS1.p6.5.m5.2.2.2.2.2.3.cmml" xref="S3.SS1.p6.5.m5.2.2.2.2.2.3">ğ‘¡</ci></apply></interval></apply><apply id="S3.SS1.p6.5.m5.2.2c.cmml" xref="S3.SS1.p6.5.m5.2.2"><in id="S3.SS1.p6.5.m5.2.2.6.cmml" xref="S3.SS1.p6.5.m5.2.2.6"></in><share href="#S3.SS1.p6.5.m5.2.2.2.cmml" id="S3.SS1.p6.5.m5.2.2d.cmml" xref="S3.SS1.p6.5.m5.2.2"></share><apply id="S3.SS1.p6.5.m5.2.2.7.cmml" xref="S3.SS1.p6.5.m5.2.2.7"><csymbol cd="ambiguous" id="S3.SS1.p6.5.m5.2.2.7.1.cmml" xref="S3.SS1.p6.5.m5.2.2.7">superscript</csymbol><ci id="S3.SS1.p6.5.m5.2.2.7.2.cmml" xref="S3.SS1.p6.5.m5.2.2.7.2">â„</ci><apply id="S3.SS1.p6.5.m5.2.2.7.3.cmml" xref="S3.SS1.p6.5.m5.2.2.7.3"><times id="S3.SS1.p6.5.m5.2.2.7.3.1.cmml" xref="S3.SS1.p6.5.m5.2.2.7.3.1"></times><ci id="S3.SS1.p6.5.m5.2.2.7.3.2.cmml" xref="S3.SS1.p6.5.m5.2.2.7.3.2">ğ‘‡</ci><ci id="S3.SS1.p6.5.m5.2.2.7.3.3.cmml" xref="S3.SS1.p6.5.m5.2.2.7.3.3">ğ‘€</ci><cn type="integer" id="S3.SS1.p6.5.m5.2.2.7.3.4.cmml" xref="S3.SS1.p6.5.m5.2.2.7.3.4">3</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p6.5.m5.2c">\mathbf{X}_{t}=[\mathbf{X}^{S}_{t},\mathbf{X}^{F}_{t}]\in\mathbb{R}^{T\times M\times 3}</annotation></semantics></math>, which represents a short sequence of human motion spanning 0.5Â s:</p>
<table id="S5.EGx1" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S3.Ex1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.Ex1.m1.2" class="ltx_Math" alttext="\displaystyle\mathbf{X}^{F}_{t}=\mathcal{P}(\mathbf{X}^{S}_{t},\mathbf{a}_{t})" display="inline"><semantics id="S3.Ex1.m1.2a"><mrow id="S3.Ex1.m1.2.2" xref="S3.Ex1.m1.2.2.cmml"><msubsup id="S3.Ex1.m1.2.2.4" xref="S3.Ex1.m1.2.2.4.cmml"><mi id="S3.Ex1.m1.2.2.4.2.2" xref="S3.Ex1.m1.2.2.4.2.2.cmml">ğ—</mi><mi id="S3.Ex1.m1.2.2.4.3" xref="S3.Ex1.m1.2.2.4.3.cmml">t</mi><mi id="S3.Ex1.m1.2.2.4.2.3" xref="S3.Ex1.m1.2.2.4.2.3.cmml">F</mi></msubsup><mo id="S3.Ex1.m1.2.2.3" xref="S3.Ex1.m1.2.2.3.cmml">=</mo><mrow id="S3.Ex1.m1.2.2.2" xref="S3.Ex1.m1.2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.Ex1.m1.2.2.2.4" xref="S3.Ex1.m1.2.2.2.4.cmml">ğ’«</mi><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.2.2.2.3" xref="S3.Ex1.m1.2.2.2.3.cmml">â€‹</mo><mrow id="S3.Ex1.m1.2.2.2.2.2" xref="S3.Ex1.m1.2.2.2.2.3.cmml"><mo stretchy="false" id="S3.Ex1.m1.2.2.2.2.2.3" xref="S3.Ex1.m1.2.2.2.2.3.cmml">(</mo><msubsup id="S3.Ex1.m1.1.1.1.1.1.1" xref="S3.Ex1.m1.1.1.1.1.1.1.cmml"><mi id="S3.Ex1.m1.1.1.1.1.1.1.2.2" xref="S3.Ex1.m1.1.1.1.1.1.1.2.2.cmml">ğ—</mi><mi id="S3.Ex1.m1.1.1.1.1.1.1.3" xref="S3.Ex1.m1.1.1.1.1.1.1.3.cmml">t</mi><mi id="S3.Ex1.m1.1.1.1.1.1.1.2.3" xref="S3.Ex1.m1.1.1.1.1.1.1.2.3.cmml">S</mi></msubsup><mo id="S3.Ex1.m1.2.2.2.2.2.4" xref="S3.Ex1.m1.2.2.2.2.3.cmml">,</mo><msub id="S3.Ex1.m1.2.2.2.2.2.2" xref="S3.Ex1.m1.2.2.2.2.2.2.cmml"><mi id="S3.Ex1.m1.2.2.2.2.2.2.2" xref="S3.Ex1.m1.2.2.2.2.2.2.2.cmml">ğš</mi><mi id="S3.Ex1.m1.2.2.2.2.2.2.3" xref="S3.Ex1.m1.2.2.2.2.2.2.3.cmml">t</mi></msub><mo stretchy="false" id="S3.Ex1.m1.2.2.2.2.2.5" xref="S3.Ex1.m1.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex1.m1.2b"><apply id="S3.Ex1.m1.2.2.cmml" xref="S3.Ex1.m1.2.2"><eq id="S3.Ex1.m1.2.2.3.cmml" xref="S3.Ex1.m1.2.2.3"></eq><apply id="S3.Ex1.m1.2.2.4.cmml" xref="S3.Ex1.m1.2.2.4"><csymbol cd="ambiguous" id="S3.Ex1.m1.2.2.4.1.cmml" xref="S3.Ex1.m1.2.2.4">subscript</csymbol><apply id="S3.Ex1.m1.2.2.4.2.cmml" xref="S3.Ex1.m1.2.2.4"><csymbol cd="ambiguous" id="S3.Ex1.m1.2.2.4.2.1.cmml" xref="S3.Ex1.m1.2.2.4">superscript</csymbol><ci id="S3.Ex1.m1.2.2.4.2.2.cmml" xref="S3.Ex1.m1.2.2.4.2.2">ğ—</ci><ci id="S3.Ex1.m1.2.2.4.2.3.cmml" xref="S3.Ex1.m1.2.2.4.2.3">ğ¹</ci></apply><ci id="S3.Ex1.m1.2.2.4.3.cmml" xref="S3.Ex1.m1.2.2.4.3">ğ‘¡</ci></apply><apply id="S3.Ex1.m1.2.2.2.cmml" xref="S3.Ex1.m1.2.2.2"><times id="S3.Ex1.m1.2.2.2.3.cmml" xref="S3.Ex1.m1.2.2.2.3"></times><ci id="S3.Ex1.m1.2.2.2.4.cmml" xref="S3.Ex1.m1.2.2.2.4">ğ’«</ci><interval closure="open" id="S3.Ex1.m1.2.2.2.2.3.cmml" xref="S3.Ex1.m1.2.2.2.2.2"><apply id="S3.Ex1.m1.1.1.1.1.1.1.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.Ex1.m1.1.1.1.1.1.1.1.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1">subscript</csymbol><apply id="S3.Ex1.m1.1.1.1.1.1.1.2.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.Ex1.m1.1.1.1.1.1.1.2.1.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1">superscript</csymbol><ci id="S3.Ex1.m1.1.1.1.1.1.1.2.2.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.2.2">ğ—</ci><ci id="S3.Ex1.m1.1.1.1.1.1.1.2.3.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.2.3">ğ‘†</ci></apply><ci id="S3.Ex1.m1.1.1.1.1.1.1.3.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1.3">ğ‘¡</ci></apply><apply id="S3.Ex1.m1.2.2.2.2.2.2.cmml" xref="S3.Ex1.m1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.Ex1.m1.2.2.2.2.2.2.1.cmml" xref="S3.Ex1.m1.2.2.2.2.2.2">subscript</csymbol><ci id="S3.Ex1.m1.2.2.2.2.2.2.2.cmml" xref="S3.Ex1.m1.2.2.2.2.2.2.2">ğš</ci><ci id="S3.Ex1.m1.2.2.2.2.2.2.3.cmml" xref="S3.Ex1.m1.2.2.2.2.2.2.3">ğ‘¡</ci></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex1.m1.2c">\displaystyle\mathbf{X}^{F}_{t}=\mathcal{P}(\mathbf{X}^{S}_{t},\mathbf{a}_{t})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS1.p7" class="ltx_para ltx_noindent">
<p id="S3.SS1.p7.5" class="ltx_p"><span id="S3.SS1.p7.5.1" class="ltx_text ltx_font_bold">State.</span> To preserve Markov property <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib66" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">66</span></a>]</cite>, the state is defined as <math id="S3.SS1.p7.1.m1.5" class="ltx_Math" alttext="\mathbf{s}_{t}=\{\mathbf{X}_{t}^{S},\mathbf{X}_{t}^{S^{D}},\mathcal{E}_{t},d_{t},\tau_{t}\}" display="inline"><semantics id="S3.SS1.p7.1.m1.5a"><mrow id="S3.SS1.p7.1.m1.5.5" xref="S3.SS1.p7.1.m1.5.5.cmml"><msub id="S3.SS1.p7.1.m1.5.5.7" xref="S3.SS1.p7.1.m1.5.5.7.cmml"><mi id="S3.SS1.p7.1.m1.5.5.7.2" xref="S3.SS1.p7.1.m1.5.5.7.2.cmml">ğ¬</mi><mi id="S3.SS1.p7.1.m1.5.5.7.3" xref="S3.SS1.p7.1.m1.5.5.7.3.cmml">t</mi></msub><mo id="S3.SS1.p7.1.m1.5.5.6" xref="S3.SS1.p7.1.m1.5.5.6.cmml">=</mo><mrow id="S3.SS1.p7.1.m1.5.5.5.5" xref="S3.SS1.p7.1.m1.5.5.5.6.cmml"><mo stretchy="false" id="S3.SS1.p7.1.m1.5.5.5.5.6" xref="S3.SS1.p7.1.m1.5.5.5.6.cmml">{</mo><msubsup id="S3.SS1.p7.1.m1.1.1.1.1.1" xref="S3.SS1.p7.1.m1.1.1.1.1.1.cmml"><mi id="S3.SS1.p7.1.m1.1.1.1.1.1.2.2" xref="S3.SS1.p7.1.m1.1.1.1.1.1.2.2.cmml">ğ—</mi><mi id="S3.SS1.p7.1.m1.1.1.1.1.1.2.3" xref="S3.SS1.p7.1.m1.1.1.1.1.1.2.3.cmml">t</mi><mi id="S3.SS1.p7.1.m1.1.1.1.1.1.3" xref="S3.SS1.p7.1.m1.1.1.1.1.1.3.cmml">S</mi></msubsup><mo id="S3.SS1.p7.1.m1.5.5.5.5.7" xref="S3.SS1.p7.1.m1.5.5.5.6.cmml">,</mo><msubsup id="S3.SS1.p7.1.m1.2.2.2.2.2" xref="S3.SS1.p7.1.m1.2.2.2.2.2.cmml"><mi id="S3.SS1.p7.1.m1.2.2.2.2.2.2.2" xref="S3.SS1.p7.1.m1.2.2.2.2.2.2.2.cmml">ğ—</mi><mi id="S3.SS1.p7.1.m1.2.2.2.2.2.2.3" xref="S3.SS1.p7.1.m1.2.2.2.2.2.2.3.cmml">t</mi><msup id="S3.SS1.p7.1.m1.2.2.2.2.2.3" xref="S3.SS1.p7.1.m1.2.2.2.2.2.3.cmml"><mi id="S3.SS1.p7.1.m1.2.2.2.2.2.3.2" xref="S3.SS1.p7.1.m1.2.2.2.2.2.3.2.cmml">S</mi><mi id="S3.SS1.p7.1.m1.2.2.2.2.2.3.3" xref="S3.SS1.p7.1.m1.2.2.2.2.2.3.3.cmml">D</mi></msup></msubsup><mo id="S3.SS1.p7.1.m1.5.5.5.5.8" xref="S3.SS1.p7.1.m1.5.5.5.6.cmml">,</mo><msub id="S3.SS1.p7.1.m1.3.3.3.3.3" xref="S3.SS1.p7.1.m1.3.3.3.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p7.1.m1.3.3.3.3.3.2" xref="S3.SS1.p7.1.m1.3.3.3.3.3.2.cmml">â„°</mi><mi id="S3.SS1.p7.1.m1.3.3.3.3.3.3" xref="S3.SS1.p7.1.m1.3.3.3.3.3.3.cmml">t</mi></msub><mo id="S3.SS1.p7.1.m1.5.5.5.5.9" xref="S3.SS1.p7.1.m1.5.5.5.6.cmml">,</mo><msub id="S3.SS1.p7.1.m1.4.4.4.4.4" xref="S3.SS1.p7.1.m1.4.4.4.4.4.cmml"><mi id="S3.SS1.p7.1.m1.4.4.4.4.4.2" xref="S3.SS1.p7.1.m1.4.4.4.4.4.2.cmml">d</mi><mi id="S3.SS1.p7.1.m1.4.4.4.4.4.3" xref="S3.SS1.p7.1.m1.4.4.4.4.4.3.cmml">t</mi></msub><mo id="S3.SS1.p7.1.m1.5.5.5.5.10" xref="S3.SS1.p7.1.m1.5.5.5.6.cmml">,</mo><msub id="S3.SS1.p7.1.m1.5.5.5.5.5" xref="S3.SS1.p7.1.m1.5.5.5.5.5.cmml"><mi id="S3.SS1.p7.1.m1.5.5.5.5.5.2" xref="S3.SS1.p7.1.m1.5.5.5.5.5.2.cmml">Ï„</mi><mi id="S3.SS1.p7.1.m1.5.5.5.5.5.3" xref="S3.SS1.p7.1.m1.5.5.5.5.5.3.cmml">t</mi></msub><mo stretchy="false" id="S3.SS1.p7.1.m1.5.5.5.5.11" xref="S3.SS1.p7.1.m1.5.5.5.6.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p7.1.m1.5b"><apply id="S3.SS1.p7.1.m1.5.5.cmml" xref="S3.SS1.p7.1.m1.5.5"><eq id="S3.SS1.p7.1.m1.5.5.6.cmml" xref="S3.SS1.p7.1.m1.5.5.6"></eq><apply id="S3.SS1.p7.1.m1.5.5.7.cmml" xref="S3.SS1.p7.1.m1.5.5.7"><csymbol cd="ambiguous" id="S3.SS1.p7.1.m1.5.5.7.1.cmml" xref="S3.SS1.p7.1.m1.5.5.7">subscript</csymbol><ci id="S3.SS1.p7.1.m1.5.5.7.2.cmml" xref="S3.SS1.p7.1.m1.5.5.7.2">ğ¬</ci><ci id="S3.SS1.p7.1.m1.5.5.7.3.cmml" xref="S3.SS1.p7.1.m1.5.5.7.3">ğ‘¡</ci></apply><set id="S3.SS1.p7.1.m1.5.5.5.6.cmml" xref="S3.SS1.p7.1.m1.5.5.5.5"><apply id="S3.SS1.p7.1.m1.1.1.1.1.1.cmml" xref="S3.SS1.p7.1.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p7.1.m1.1.1.1.1.1.1.cmml" xref="S3.SS1.p7.1.m1.1.1.1.1.1">superscript</csymbol><apply id="S3.SS1.p7.1.m1.1.1.1.1.1.2.cmml" xref="S3.SS1.p7.1.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p7.1.m1.1.1.1.1.1.2.1.cmml" xref="S3.SS1.p7.1.m1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p7.1.m1.1.1.1.1.1.2.2.cmml" xref="S3.SS1.p7.1.m1.1.1.1.1.1.2.2">ğ—</ci><ci id="S3.SS1.p7.1.m1.1.1.1.1.1.2.3.cmml" xref="S3.SS1.p7.1.m1.1.1.1.1.1.2.3">ğ‘¡</ci></apply><ci id="S3.SS1.p7.1.m1.1.1.1.1.1.3.cmml" xref="S3.SS1.p7.1.m1.1.1.1.1.1.3">ğ‘†</ci></apply><apply id="S3.SS1.p7.1.m1.2.2.2.2.2.cmml" xref="S3.SS1.p7.1.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p7.1.m1.2.2.2.2.2.1.cmml" xref="S3.SS1.p7.1.m1.2.2.2.2.2">superscript</csymbol><apply id="S3.SS1.p7.1.m1.2.2.2.2.2.2.cmml" xref="S3.SS1.p7.1.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p7.1.m1.2.2.2.2.2.2.1.cmml" xref="S3.SS1.p7.1.m1.2.2.2.2.2">subscript</csymbol><ci id="S3.SS1.p7.1.m1.2.2.2.2.2.2.2.cmml" xref="S3.SS1.p7.1.m1.2.2.2.2.2.2.2">ğ—</ci><ci id="S3.SS1.p7.1.m1.2.2.2.2.2.2.3.cmml" xref="S3.SS1.p7.1.m1.2.2.2.2.2.2.3">ğ‘¡</ci></apply><apply id="S3.SS1.p7.1.m1.2.2.2.2.2.3.cmml" xref="S3.SS1.p7.1.m1.2.2.2.2.2.3"><csymbol cd="ambiguous" id="S3.SS1.p7.1.m1.2.2.2.2.2.3.1.cmml" xref="S3.SS1.p7.1.m1.2.2.2.2.2.3">superscript</csymbol><ci id="S3.SS1.p7.1.m1.2.2.2.2.2.3.2.cmml" xref="S3.SS1.p7.1.m1.2.2.2.2.2.3.2">ğ‘†</ci><ci id="S3.SS1.p7.1.m1.2.2.2.2.2.3.3.cmml" xref="S3.SS1.p7.1.m1.2.2.2.2.2.3.3">ğ·</ci></apply></apply><apply id="S3.SS1.p7.1.m1.3.3.3.3.3.cmml" xref="S3.SS1.p7.1.m1.3.3.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.p7.1.m1.3.3.3.3.3.1.cmml" xref="S3.SS1.p7.1.m1.3.3.3.3.3">subscript</csymbol><ci id="S3.SS1.p7.1.m1.3.3.3.3.3.2.cmml" xref="S3.SS1.p7.1.m1.3.3.3.3.3.2">â„°</ci><ci id="S3.SS1.p7.1.m1.3.3.3.3.3.3.cmml" xref="S3.SS1.p7.1.m1.3.3.3.3.3.3">ğ‘¡</ci></apply><apply id="S3.SS1.p7.1.m1.4.4.4.4.4.cmml" xref="S3.SS1.p7.1.m1.4.4.4.4.4"><csymbol cd="ambiguous" id="S3.SS1.p7.1.m1.4.4.4.4.4.1.cmml" xref="S3.SS1.p7.1.m1.4.4.4.4.4">subscript</csymbol><ci id="S3.SS1.p7.1.m1.4.4.4.4.4.2.cmml" xref="S3.SS1.p7.1.m1.4.4.4.4.4.2">ğ‘‘</ci><ci id="S3.SS1.p7.1.m1.4.4.4.4.4.3.cmml" xref="S3.SS1.p7.1.m1.4.4.4.4.4.3">ğ‘¡</ci></apply><apply id="S3.SS1.p7.1.m1.5.5.5.5.5.cmml" xref="S3.SS1.p7.1.m1.5.5.5.5.5"><csymbol cd="ambiguous" id="S3.SS1.p7.1.m1.5.5.5.5.5.1.cmml" xref="S3.SS1.p7.1.m1.5.5.5.5.5">subscript</csymbol><ci id="S3.SS1.p7.1.m1.5.5.5.5.5.2.cmml" xref="S3.SS1.p7.1.m1.5.5.5.5.5.2">ğœ</ci><ci id="S3.SS1.p7.1.m1.5.5.5.5.5.3.cmml" xref="S3.SS1.p7.1.m1.5.5.5.5.5.3">ğ‘¡</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p7.1.m1.5c">\mathbf{s}_{t}=\{\mathbf{X}_{t}^{S},\mathbf{X}_{t}^{S^{D}},\mathcal{E}_{t},d_{t},\tau_{t}\}</annotation></semantics></math>, in which <math id="S3.SS1.p7.2.m2.1" class="ltx_Math" alttext="\mathbf{X}_{t}^{S^{D}}\in\mathbb{R}^{T_{s}\times M\times 3}" display="inline"><semantics id="S3.SS1.p7.2.m2.1a"><mrow id="S3.SS1.p7.2.m2.1.1" xref="S3.SS1.p7.2.m2.1.1.cmml"><msubsup id="S3.SS1.p7.2.m2.1.1.2" xref="S3.SS1.p7.2.m2.1.1.2.cmml"><mi id="S3.SS1.p7.2.m2.1.1.2.2.2" xref="S3.SS1.p7.2.m2.1.1.2.2.2.cmml">ğ—</mi><mi id="S3.SS1.p7.2.m2.1.1.2.2.3" xref="S3.SS1.p7.2.m2.1.1.2.2.3.cmml">t</mi><msup id="S3.SS1.p7.2.m2.1.1.2.3" xref="S3.SS1.p7.2.m2.1.1.2.3.cmml"><mi id="S3.SS1.p7.2.m2.1.1.2.3.2" xref="S3.SS1.p7.2.m2.1.1.2.3.2.cmml">S</mi><mi id="S3.SS1.p7.2.m2.1.1.2.3.3" xref="S3.SS1.p7.2.m2.1.1.2.3.3.cmml">D</mi></msup></msubsup><mo id="S3.SS1.p7.2.m2.1.1.1" xref="S3.SS1.p7.2.m2.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS1.p7.2.m2.1.1.3" xref="S3.SS1.p7.2.m2.1.1.3.cmml"><mi id="S3.SS1.p7.2.m2.1.1.3.2" xref="S3.SS1.p7.2.m2.1.1.3.2.cmml">â„</mi><mrow id="S3.SS1.p7.2.m2.1.1.3.3" xref="S3.SS1.p7.2.m2.1.1.3.3.cmml"><msub id="S3.SS1.p7.2.m2.1.1.3.3.2" xref="S3.SS1.p7.2.m2.1.1.3.3.2.cmml"><mi id="S3.SS1.p7.2.m2.1.1.3.3.2.2" xref="S3.SS1.p7.2.m2.1.1.3.3.2.2.cmml">T</mi><mi id="S3.SS1.p7.2.m2.1.1.3.3.2.3" xref="S3.SS1.p7.2.m2.1.1.3.3.2.3.cmml">s</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p7.2.m2.1.1.3.3.1" xref="S3.SS1.p7.2.m2.1.1.3.3.1.cmml">Ã—</mo><mi id="S3.SS1.p7.2.m2.1.1.3.3.3" xref="S3.SS1.p7.2.m2.1.1.3.3.3.cmml">M</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p7.2.m2.1.1.3.3.1a" xref="S3.SS1.p7.2.m2.1.1.3.3.1.cmml">Ã—</mo><mn id="S3.SS1.p7.2.m2.1.1.3.3.4" xref="S3.SS1.p7.2.m2.1.1.3.3.4.cmml">3</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p7.2.m2.1b"><apply id="S3.SS1.p7.2.m2.1.1.cmml" xref="S3.SS1.p7.2.m2.1.1"><in id="S3.SS1.p7.2.m2.1.1.1.cmml" xref="S3.SS1.p7.2.m2.1.1.1"></in><apply id="S3.SS1.p7.2.m2.1.1.2.cmml" xref="S3.SS1.p7.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p7.2.m2.1.1.2.1.cmml" xref="S3.SS1.p7.2.m2.1.1.2">superscript</csymbol><apply id="S3.SS1.p7.2.m2.1.1.2.2.cmml" xref="S3.SS1.p7.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p7.2.m2.1.1.2.2.1.cmml" xref="S3.SS1.p7.2.m2.1.1.2">subscript</csymbol><ci id="S3.SS1.p7.2.m2.1.1.2.2.2.cmml" xref="S3.SS1.p7.2.m2.1.1.2.2.2">ğ—</ci><ci id="S3.SS1.p7.2.m2.1.1.2.2.3.cmml" xref="S3.SS1.p7.2.m2.1.1.2.2.3">ğ‘¡</ci></apply><apply id="S3.SS1.p7.2.m2.1.1.2.3.cmml" xref="S3.SS1.p7.2.m2.1.1.2.3"><csymbol cd="ambiguous" id="S3.SS1.p7.2.m2.1.1.2.3.1.cmml" xref="S3.SS1.p7.2.m2.1.1.2.3">superscript</csymbol><ci id="S3.SS1.p7.2.m2.1.1.2.3.2.cmml" xref="S3.SS1.p7.2.m2.1.1.2.3.2">ğ‘†</ci><ci id="S3.SS1.p7.2.m2.1.1.2.3.3.cmml" xref="S3.SS1.p7.2.m2.1.1.2.3.3">ğ·</ci></apply></apply><apply id="S3.SS1.p7.2.m2.1.1.3.cmml" xref="S3.SS1.p7.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p7.2.m2.1.1.3.1.cmml" xref="S3.SS1.p7.2.m2.1.1.3">superscript</csymbol><ci id="S3.SS1.p7.2.m2.1.1.3.2.cmml" xref="S3.SS1.p7.2.m2.1.1.3.2">â„</ci><apply id="S3.SS1.p7.2.m2.1.1.3.3.cmml" xref="S3.SS1.p7.2.m2.1.1.3.3"><times id="S3.SS1.p7.2.m2.1.1.3.3.1.cmml" xref="S3.SS1.p7.2.m2.1.1.3.3.1"></times><apply id="S3.SS1.p7.2.m2.1.1.3.3.2.cmml" xref="S3.SS1.p7.2.m2.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.SS1.p7.2.m2.1.1.3.3.2.1.cmml" xref="S3.SS1.p7.2.m2.1.1.3.3.2">subscript</csymbol><ci id="S3.SS1.p7.2.m2.1.1.3.3.2.2.cmml" xref="S3.SS1.p7.2.m2.1.1.3.3.2.2">ğ‘‡</ci><ci id="S3.SS1.p7.2.m2.1.1.3.3.2.3.cmml" xref="S3.SS1.p7.2.m2.1.1.3.3.2.3">ğ‘ </ci></apply><ci id="S3.SS1.p7.2.m2.1.1.3.3.3.cmml" xref="S3.SS1.p7.2.m2.1.1.3.3.3">ğ‘€</ci><cn type="integer" id="S3.SS1.p7.2.m2.1.1.3.3.4.cmml" xref="S3.SS1.p7.2.m2.1.1.3.3.4">3</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p7.2.m2.1c">\mathbf{X}_{t}^{S^{D}}\in\mathbb{R}^{T_{s}\times M\times 3}</annotation></semantics></math> denotes the normalized direction of each marker seed to the target, <math id="S3.SS1.p7.3.m3.1" class="ltx_Math" alttext="\mathcal{E}_{t}\in\mathbb{R}^{T_{s}\times N}" display="inline"><semantics id="S3.SS1.p7.3.m3.1a"><mrow id="S3.SS1.p7.3.m3.1.1" xref="S3.SS1.p7.3.m3.1.1.cmml"><msub id="S3.SS1.p7.3.m3.1.1.2" xref="S3.SS1.p7.3.m3.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p7.3.m3.1.1.2.2" xref="S3.SS1.p7.3.m3.1.1.2.2.cmml">â„°</mi><mi id="S3.SS1.p7.3.m3.1.1.2.3" xref="S3.SS1.p7.3.m3.1.1.2.3.cmml">t</mi></msub><mo id="S3.SS1.p7.3.m3.1.1.1" xref="S3.SS1.p7.3.m3.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS1.p7.3.m3.1.1.3" xref="S3.SS1.p7.3.m3.1.1.3.cmml"><mi id="S3.SS1.p7.3.m3.1.1.3.2" xref="S3.SS1.p7.3.m3.1.1.3.2.cmml">â„</mi><mrow id="S3.SS1.p7.3.m3.1.1.3.3" xref="S3.SS1.p7.3.m3.1.1.3.3.cmml"><msub id="S3.SS1.p7.3.m3.1.1.3.3.2" xref="S3.SS1.p7.3.m3.1.1.3.3.2.cmml"><mi id="S3.SS1.p7.3.m3.1.1.3.3.2.2" xref="S3.SS1.p7.3.m3.1.1.3.3.2.2.cmml">T</mi><mi id="S3.SS1.p7.3.m3.1.1.3.3.2.3" xref="S3.SS1.p7.3.m3.1.1.3.3.2.3.cmml">s</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p7.3.m3.1.1.3.3.1" xref="S3.SS1.p7.3.m3.1.1.3.3.1.cmml">Ã—</mo><mi id="S3.SS1.p7.3.m3.1.1.3.3.3" xref="S3.SS1.p7.3.m3.1.1.3.3.3.cmml">N</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p7.3.m3.1b"><apply id="S3.SS1.p7.3.m3.1.1.cmml" xref="S3.SS1.p7.3.m3.1.1"><in id="S3.SS1.p7.3.m3.1.1.1.cmml" xref="S3.SS1.p7.3.m3.1.1.1"></in><apply id="S3.SS1.p7.3.m3.1.1.2.cmml" xref="S3.SS1.p7.3.m3.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p7.3.m3.1.1.2.1.cmml" xref="S3.SS1.p7.3.m3.1.1.2">subscript</csymbol><ci id="S3.SS1.p7.3.m3.1.1.2.2.cmml" xref="S3.SS1.p7.3.m3.1.1.2.2">â„°</ci><ci id="S3.SS1.p7.3.m3.1.1.2.3.cmml" xref="S3.SS1.p7.3.m3.1.1.2.3">ğ‘¡</ci></apply><apply id="S3.SS1.p7.3.m3.1.1.3.cmml" xref="S3.SS1.p7.3.m3.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p7.3.m3.1.1.3.1.cmml" xref="S3.SS1.p7.3.m3.1.1.3">superscript</csymbol><ci id="S3.SS1.p7.3.m3.1.1.3.2.cmml" xref="S3.SS1.p7.3.m3.1.1.3.2">â„</ci><apply id="S3.SS1.p7.3.m3.1.1.3.3.cmml" xref="S3.SS1.p7.3.m3.1.1.3.3"><times id="S3.SS1.p7.3.m3.1.1.3.3.1.cmml" xref="S3.SS1.p7.3.m3.1.1.3.3.1"></times><apply id="S3.SS1.p7.3.m3.1.1.3.3.2.cmml" xref="S3.SS1.p7.3.m3.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.SS1.p7.3.m3.1.1.3.3.2.1.cmml" xref="S3.SS1.p7.3.m3.1.1.3.3.2">subscript</csymbol><ci id="S3.SS1.p7.3.m3.1.1.3.3.2.2.cmml" xref="S3.SS1.p7.3.m3.1.1.3.3.2.2">ğ‘‡</ci><ci id="S3.SS1.p7.3.m3.1.1.3.3.2.3.cmml" xref="S3.SS1.p7.3.m3.1.1.3.3.2.3">ğ‘ </ci></apply><ci id="S3.SS1.p7.3.m3.1.1.3.3.3.cmml" xref="S3.SS1.p7.3.m3.1.1.3.3.3">ğ‘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p7.3.m3.1c">\mathcal{E}_{t}\in\mathbb{R}^{T_{s}\times N}</annotation></semantics></math> denotes the egocentric sensing depth proxy, <math id="S3.SS1.p7.4.m4.1" class="ltx_Math" alttext="d_{t}" display="inline"><semantics id="S3.SS1.p7.4.m4.1a"><msub id="S3.SS1.p7.4.m4.1.1" xref="S3.SS1.p7.4.m4.1.1.cmml"><mi id="S3.SS1.p7.4.m4.1.1.2" xref="S3.SS1.p7.4.m4.1.1.2.cmml">d</mi><mi id="S3.SS1.p7.4.m4.1.1.3" xref="S3.SS1.p7.4.m4.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p7.4.m4.1b"><apply id="S3.SS1.p7.4.m4.1.1.cmml" xref="S3.SS1.p7.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p7.4.m4.1.1.1.cmml" xref="S3.SS1.p7.4.m4.1.1">subscript</csymbol><ci id="S3.SS1.p7.4.m4.1.1.2.cmml" xref="S3.SS1.p7.4.m4.1.1.2">ğ‘‘</ci><ci id="S3.SS1.p7.4.m4.1.1.3.cmml" xref="S3.SS1.p7.4.m4.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p7.4.m4.1c">d_{t}</annotation></semantics></math> denotes the distance from the pelvis to the target, and <math id="S3.SS1.p7.5.m5.1" class="ltx_Math" alttext="\tau_{t}" display="inline"><semantics id="S3.SS1.p7.5.m5.1a"><msub id="S3.SS1.p7.5.m5.1.1" xref="S3.SS1.p7.5.m5.1.1.cmml"><mi id="S3.SS1.p7.5.m5.1.1.2" xref="S3.SS1.p7.5.m5.1.1.2.cmml">Ï„</mi><mi id="S3.SS1.p7.5.m5.1.1.3" xref="S3.SS1.p7.5.m5.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p7.5.m5.1b"><apply id="S3.SS1.p7.5.m5.1.1.cmml" xref="S3.SS1.p7.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.p7.5.m5.1.1.1.cmml" xref="S3.SS1.p7.5.m5.1.1">subscript</csymbol><ci id="S3.SS1.p7.5.m5.1.1.2.cmml" xref="S3.SS1.p7.5.m5.1.1.2">ğœ</ci><ci id="S3.SS1.p7.5.m5.1.1.3.cmml" xref="S3.SS1.p7.5.m5.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p7.5.m5.1c">\tau_{t}</annotation></semantics></math> denotes the remaining time. See Fig.Â <a href="#S3.F2" title="Figure 2 â€£ 3 Ego-Sensing Driven Motion Synthesis â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<div id="S3.SS1.p8" class="ltx_para ltx_noindent">
<p id="S3.SS1.p8.2" class="ltx_p"><span id="S3.SS1.p8.2.1" class="ltx_text ltx_font_bold">Reward.</span> To synthesize egocentric perception behaviors,
we use an â€œattention rewardâ€ to incentivize the virtual human to look in specific directions: <math id="S3.SS1.p8.1.m1.3" class="ltx_Math" alttext="r_{attention}=\cos\langle\vv{\mathbf{v}},\vv{\mathbf{a}}\rangle" display="inline"><semantics id="S3.SS1.p8.1.m1.3a"><mrow id="S3.SS1.p8.1.m1.3.3" xref="S3.SS1.p8.1.m1.3.3.cmml"><msub id="S3.SS1.p8.1.m1.3.3.4" xref="S3.SS1.p8.1.m1.3.3.4.cmml"><mi id="S3.SS1.p8.1.m1.3.3.4.2" xref="S3.SS1.p8.1.m1.3.3.4.2.cmml">r</mi><mrow id="S3.SS1.p8.1.m1.3.3.4.3" xref="S3.SS1.p8.1.m1.3.3.4.3.cmml"><mi id="S3.SS1.p8.1.m1.3.3.4.3.2" xref="S3.SS1.p8.1.m1.3.3.4.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p8.1.m1.3.3.4.3.1" xref="S3.SS1.p8.1.m1.3.3.4.3.1.cmml">â€‹</mo><mi id="S3.SS1.p8.1.m1.3.3.4.3.3" xref="S3.SS1.p8.1.m1.3.3.4.3.3.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p8.1.m1.3.3.4.3.1a" xref="S3.SS1.p8.1.m1.3.3.4.3.1.cmml">â€‹</mo><mi id="S3.SS1.p8.1.m1.3.3.4.3.4" xref="S3.SS1.p8.1.m1.3.3.4.3.4.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p8.1.m1.3.3.4.3.1b" xref="S3.SS1.p8.1.m1.3.3.4.3.1.cmml">â€‹</mo><mi id="S3.SS1.p8.1.m1.3.3.4.3.5" xref="S3.SS1.p8.1.m1.3.3.4.3.5.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p8.1.m1.3.3.4.3.1c" xref="S3.SS1.p8.1.m1.3.3.4.3.1.cmml">â€‹</mo><mi id="S3.SS1.p8.1.m1.3.3.4.3.6" xref="S3.SS1.p8.1.m1.3.3.4.3.6.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p8.1.m1.3.3.4.3.1d" xref="S3.SS1.p8.1.m1.3.3.4.3.1.cmml">â€‹</mo><mi id="S3.SS1.p8.1.m1.3.3.4.3.7" xref="S3.SS1.p8.1.m1.3.3.4.3.7.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p8.1.m1.3.3.4.3.1e" xref="S3.SS1.p8.1.m1.3.3.4.3.1.cmml">â€‹</mo><mi id="S3.SS1.p8.1.m1.3.3.4.3.8" xref="S3.SS1.p8.1.m1.3.3.4.3.8.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p8.1.m1.3.3.4.3.1f" xref="S3.SS1.p8.1.m1.3.3.4.3.1.cmml">â€‹</mo><mi id="S3.SS1.p8.1.m1.3.3.4.3.9" xref="S3.SS1.p8.1.m1.3.3.4.3.9.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p8.1.m1.3.3.4.3.1g" xref="S3.SS1.p8.1.m1.3.3.4.3.1.cmml">â€‹</mo><mi id="S3.SS1.p8.1.m1.3.3.4.3.10" xref="S3.SS1.p8.1.m1.3.3.4.3.10.cmml">n</mi></mrow></msub><mo id="S3.SS1.p8.1.m1.3.3.3" xref="S3.SS1.p8.1.m1.3.3.3.cmml">=</mo><mrow id="S3.SS1.p8.1.m1.3.3.2.2" xref="S3.SS1.p8.1.m1.3.3.2.3.cmml"><mi id="S3.SS1.p8.1.m1.1.1" xref="S3.SS1.p8.1.m1.1.1.cmml">cos</mi><mo id="S3.SS1.p8.1.m1.3.3.2.2a" xref="S3.SS1.p8.1.m1.3.3.2.3.cmml">â¡</mo><mrow id="S3.SS1.p8.1.m1.3.3.2.2.2" xref="S3.SS1.p8.1.m1.3.3.2.3.cmml"><mo stretchy="false" id="S3.SS1.p8.1.m1.3.3.2.2.2.3" xref="S3.SS1.p8.1.m1.3.3.2.3.cmml">âŸ¨</mo><mrow id="S3.SS1.p8.1.m1.2.2.1.1.1.1" xref="S3.SS1.p8.1.m1.2.2.1.1.1.1.cmml"><merror class="ltx_ERROR undefined undefined" id="S3.SS1.p8.1.m1.2.2.1.1.1.1.2" xref="S3.SS1.p8.1.m1.2.2.1.1.1.1.2b.cmml"><mtext id="S3.SS1.p8.1.m1.2.2.1.1.1.1.2a" xref="S3.SS1.p8.1.m1.2.2.1.1.1.1.2b.cmml">\vv</mtext></merror><mo lspace="0em" rspace="0em" id="S3.SS1.p8.1.m1.2.2.1.1.1.1.1" xref="S3.SS1.p8.1.m1.2.2.1.1.1.1.1.cmml">â€‹</mo><mi id="S3.SS1.p8.1.m1.2.2.1.1.1.1.3" xref="S3.SS1.p8.1.m1.2.2.1.1.1.1.3.cmml">ğ¯</mi></mrow><mo id="S3.SS1.p8.1.m1.3.3.2.2.2.4" xref="S3.SS1.p8.1.m1.3.3.2.3.cmml">,</mo><mrow id="S3.SS1.p8.1.m1.3.3.2.2.2.2" xref="S3.SS1.p8.1.m1.3.3.2.2.2.2.cmml"><merror class="ltx_ERROR undefined undefined" id="S3.SS1.p8.1.m1.3.3.2.2.2.2.2" xref="S3.SS1.p8.1.m1.3.3.2.2.2.2.2b.cmml"><mtext id="S3.SS1.p8.1.m1.3.3.2.2.2.2.2a" xref="S3.SS1.p8.1.m1.3.3.2.2.2.2.2b.cmml">\vv</mtext></merror><mo lspace="0em" rspace="0em" id="S3.SS1.p8.1.m1.3.3.2.2.2.2.1" xref="S3.SS1.p8.1.m1.3.3.2.2.2.2.1.cmml">â€‹</mo><mi id="S3.SS1.p8.1.m1.3.3.2.2.2.2.3" xref="S3.SS1.p8.1.m1.3.3.2.2.2.2.3.cmml">ğš</mi></mrow><mo stretchy="false" id="S3.SS1.p8.1.m1.3.3.2.2.2.5" xref="S3.SS1.p8.1.m1.3.3.2.3.cmml">âŸ©</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p8.1.m1.3b"><apply id="S3.SS1.p8.1.m1.3.3.cmml" xref="S3.SS1.p8.1.m1.3.3"><eq id="S3.SS1.p8.1.m1.3.3.3.cmml" xref="S3.SS1.p8.1.m1.3.3.3"></eq><apply id="S3.SS1.p8.1.m1.3.3.4.cmml" xref="S3.SS1.p8.1.m1.3.3.4"><csymbol cd="ambiguous" id="S3.SS1.p8.1.m1.3.3.4.1.cmml" xref="S3.SS1.p8.1.m1.3.3.4">subscript</csymbol><ci id="S3.SS1.p8.1.m1.3.3.4.2.cmml" xref="S3.SS1.p8.1.m1.3.3.4.2">ğ‘Ÿ</ci><apply id="S3.SS1.p8.1.m1.3.3.4.3.cmml" xref="S3.SS1.p8.1.m1.3.3.4.3"><times id="S3.SS1.p8.1.m1.3.3.4.3.1.cmml" xref="S3.SS1.p8.1.m1.3.3.4.3.1"></times><ci id="S3.SS1.p8.1.m1.3.3.4.3.2.cmml" xref="S3.SS1.p8.1.m1.3.3.4.3.2">ğ‘</ci><ci id="S3.SS1.p8.1.m1.3.3.4.3.3.cmml" xref="S3.SS1.p8.1.m1.3.3.4.3.3">ğ‘¡</ci><ci id="S3.SS1.p8.1.m1.3.3.4.3.4.cmml" xref="S3.SS1.p8.1.m1.3.3.4.3.4">ğ‘¡</ci><ci id="S3.SS1.p8.1.m1.3.3.4.3.5.cmml" xref="S3.SS1.p8.1.m1.3.3.4.3.5">ğ‘’</ci><ci id="S3.SS1.p8.1.m1.3.3.4.3.6.cmml" xref="S3.SS1.p8.1.m1.3.3.4.3.6">ğ‘›</ci><ci id="S3.SS1.p8.1.m1.3.3.4.3.7.cmml" xref="S3.SS1.p8.1.m1.3.3.4.3.7">ğ‘¡</ci><ci id="S3.SS1.p8.1.m1.3.3.4.3.8.cmml" xref="S3.SS1.p8.1.m1.3.3.4.3.8">ğ‘–</ci><ci id="S3.SS1.p8.1.m1.3.3.4.3.9.cmml" xref="S3.SS1.p8.1.m1.3.3.4.3.9">ğ‘œ</ci><ci id="S3.SS1.p8.1.m1.3.3.4.3.10.cmml" xref="S3.SS1.p8.1.m1.3.3.4.3.10">ğ‘›</ci></apply></apply><apply id="S3.SS1.p8.1.m1.3.3.2.3.cmml" xref="S3.SS1.p8.1.m1.3.3.2.2"><cos id="S3.SS1.p8.1.m1.1.1.cmml" xref="S3.SS1.p8.1.m1.1.1"></cos><apply id="S3.SS1.p8.1.m1.2.2.1.1.1.1.cmml" xref="S3.SS1.p8.1.m1.2.2.1.1.1.1"><times id="S3.SS1.p8.1.m1.2.2.1.1.1.1.1.cmml" xref="S3.SS1.p8.1.m1.2.2.1.1.1.1.1"></times><ci id="S3.SS1.p8.1.m1.2.2.1.1.1.1.2b.cmml" xref="S3.SS1.p8.1.m1.2.2.1.1.1.1.2"><merror class="ltx_ERROR undefined undefined" id="S3.SS1.p8.1.m1.2.2.1.1.1.1.2.cmml" xref="S3.SS1.p8.1.m1.2.2.1.1.1.1.2"><mtext id="S3.SS1.p8.1.m1.2.2.1.1.1.1.2a.cmml" xref="S3.SS1.p8.1.m1.2.2.1.1.1.1.2">\vv</mtext></merror></ci><ci id="S3.SS1.p8.1.m1.2.2.1.1.1.1.3.cmml" xref="S3.SS1.p8.1.m1.2.2.1.1.1.1.3">ğ¯</ci></apply><apply id="S3.SS1.p8.1.m1.3.3.2.2.2.2.cmml" xref="S3.SS1.p8.1.m1.3.3.2.2.2.2"><times id="S3.SS1.p8.1.m1.3.3.2.2.2.2.1.cmml" xref="S3.SS1.p8.1.m1.3.3.2.2.2.2.1"></times><ci id="S3.SS1.p8.1.m1.3.3.2.2.2.2.2b.cmml" xref="S3.SS1.p8.1.m1.3.3.2.2.2.2.2"><merror class="ltx_ERROR undefined undefined" id="S3.SS1.p8.1.m1.3.3.2.2.2.2.2.cmml" xref="S3.SS1.p8.1.m1.3.3.2.2.2.2.2"><mtext id="S3.SS1.p8.1.m1.3.3.2.2.2.2.2a.cmml" xref="S3.SS1.p8.1.m1.3.3.2.2.2.2.2">\vv</mtext></merror></ci><ci id="S3.SS1.p8.1.m1.3.3.2.2.2.2.3.cmml" xref="S3.SS1.p8.1.m1.3.3.2.2.2.2.3">ğš</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p8.1.m1.3c">r_{attention}=\cos\langle\vv{\mathbf{v}},\vv{\mathbf{a}}\rangle</annotation></semantics></math>, where <math id="S3.SS1.p8.2.m2.1" class="ltx_Math" alttext="\vv{\mathbf{a}}" display="inline"><semantics id="S3.SS1.p8.2.m2.1a"><mrow id="S3.SS1.p8.2.m2.1.1" xref="S3.SS1.p8.2.m2.1.1.cmml"><merror class="ltx_ERROR undefined undefined" id="S3.SS1.p8.2.m2.1.1.2" xref="S3.SS1.p8.2.m2.1.1.2b.cmml"><mtext id="S3.SS1.p8.2.m2.1.1.2a" xref="S3.SS1.p8.2.m2.1.1.2b.cmml">\vv</mtext></merror><mo lspace="0em" rspace="0em" id="S3.SS1.p8.2.m2.1.1.1" xref="S3.SS1.p8.2.m2.1.1.1.cmml">â€‹</mo><mi id="S3.SS1.p8.2.m2.1.1.3" xref="S3.SS1.p8.2.m2.1.1.3.cmml">ğš</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p8.2.m2.1b"><apply id="S3.SS1.p8.2.m2.1.1.cmml" xref="S3.SS1.p8.2.m2.1.1"><times id="S3.SS1.p8.2.m2.1.1.1.cmml" xref="S3.SS1.p8.2.m2.1.1.1"></times><ci id="S3.SS1.p8.2.m2.1.1.2b.cmml" xref="S3.SS1.p8.2.m2.1.1.2"><merror class="ltx_ERROR undefined undefined" id="S3.SS1.p8.2.m2.1.1.2.cmml" xref="S3.SS1.p8.2.m2.1.1.2"><mtext id="S3.SS1.p8.2.m2.1.1.2a.cmml" xref="S3.SS1.p8.2.m2.1.1.2">\vv</mtext></merror></ci><ci id="S3.SS1.p8.2.m2.1.1.3.cmml" xref="S3.SS1.p8.2.m2.1.1.3">ğš</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p8.2.m2.1c">\vv{\mathbf{a}}</annotation></semantics></math> is the attention direction from the head joint to the viewing target. The reward function is defined as:</p>
<table id="S3.Ex2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.Ex2.m1.2" class="ltx_Math" alttext="r_{t}=r_{cont.}+r_{dist}+r_{ori}+r_{attention}+r_{pene}+r_{pose}+r_{succ}," display="block"><semantics id="S3.Ex2.m1.2a"><mrow id="S3.Ex2.m1.2.2.1" xref="S3.Ex2.m1.2.2.1.1.cmml"><mrow id="S3.Ex2.m1.2.2.1.1" xref="S3.Ex2.m1.2.2.1.1.cmml"><msub id="S3.Ex2.m1.2.2.1.1.2" xref="S3.Ex2.m1.2.2.1.1.2.cmml"><mi id="S3.Ex2.m1.2.2.1.1.2.2" xref="S3.Ex2.m1.2.2.1.1.2.2.cmml">r</mi><mi id="S3.Ex2.m1.2.2.1.1.2.3" xref="S3.Ex2.m1.2.2.1.1.2.3.cmml">t</mi></msub><mo id="S3.Ex2.m1.2.2.1.1.1" xref="S3.Ex2.m1.2.2.1.1.1.cmml">=</mo><mrow id="S3.Ex2.m1.2.2.1.1.3" xref="S3.Ex2.m1.2.2.1.1.3.cmml"><msub id="S3.Ex2.m1.2.2.1.1.3.2" xref="S3.Ex2.m1.2.2.1.1.3.2.cmml"><mi id="S3.Ex2.m1.2.2.1.1.3.2.2" xref="S3.Ex2.m1.2.2.1.1.3.2.2.cmml">r</mi><mrow id="S3.Ex2.m1.1.1.1.1" xref="S3.Ex2.m1.1.1.1.2.cmml"><mrow id="S3.Ex2.m1.1.1.1.1.1" xref="S3.Ex2.m1.1.1.1.1.1.cmml"><mi id="S3.Ex2.m1.1.1.1.1.1.2" xref="S3.Ex2.m1.1.1.1.1.1.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.Ex2.m1.1.1.1.1.1.1" xref="S3.Ex2.m1.1.1.1.1.1.1.cmml">â€‹</mo><mi id="S3.Ex2.m1.1.1.1.1.1.3" xref="S3.Ex2.m1.1.1.1.1.1.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.Ex2.m1.1.1.1.1.1.1a" xref="S3.Ex2.m1.1.1.1.1.1.1.cmml">â€‹</mo><mi id="S3.Ex2.m1.1.1.1.1.1.4" xref="S3.Ex2.m1.1.1.1.1.1.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.Ex2.m1.1.1.1.1.1.1b" xref="S3.Ex2.m1.1.1.1.1.1.1.cmml">â€‹</mo><mi id="S3.Ex2.m1.1.1.1.1.1.5" xref="S3.Ex2.m1.1.1.1.1.1.5.cmml">t</mi></mrow><mo lspace="0em" id="S3.Ex2.m1.1.1.1.1.2" xref="S3.Ex2.m1.1.1.1.2.cmml">.</mo></mrow></msub><mo id="S3.Ex2.m1.2.2.1.1.3.1" xref="S3.Ex2.m1.2.2.1.1.3.1.cmml">+</mo><msub id="S3.Ex2.m1.2.2.1.1.3.3" xref="S3.Ex2.m1.2.2.1.1.3.3.cmml"><mi id="S3.Ex2.m1.2.2.1.1.3.3.2" xref="S3.Ex2.m1.2.2.1.1.3.3.2.cmml">r</mi><mrow id="S3.Ex2.m1.2.2.1.1.3.3.3" xref="S3.Ex2.m1.2.2.1.1.3.3.3.cmml"><mi id="S3.Ex2.m1.2.2.1.1.3.3.3.2" xref="S3.Ex2.m1.2.2.1.1.3.3.3.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="S3.Ex2.m1.2.2.1.1.3.3.3.1" xref="S3.Ex2.m1.2.2.1.1.3.3.3.1.cmml">â€‹</mo><mi id="S3.Ex2.m1.2.2.1.1.3.3.3.3" xref="S3.Ex2.m1.2.2.1.1.3.3.3.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.Ex2.m1.2.2.1.1.3.3.3.1a" xref="S3.Ex2.m1.2.2.1.1.3.3.3.1.cmml">â€‹</mo><mi id="S3.Ex2.m1.2.2.1.1.3.3.3.4" xref="S3.Ex2.m1.2.2.1.1.3.3.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.Ex2.m1.2.2.1.1.3.3.3.1b" xref="S3.Ex2.m1.2.2.1.1.3.3.3.1.cmml">â€‹</mo><mi id="S3.Ex2.m1.2.2.1.1.3.3.3.5" xref="S3.Ex2.m1.2.2.1.1.3.3.3.5.cmml">t</mi></mrow></msub><mo id="S3.Ex2.m1.2.2.1.1.3.1a" xref="S3.Ex2.m1.2.2.1.1.3.1.cmml">+</mo><msub id="S3.Ex2.m1.2.2.1.1.3.4" xref="S3.Ex2.m1.2.2.1.1.3.4.cmml"><mi id="S3.Ex2.m1.2.2.1.1.3.4.2" xref="S3.Ex2.m1.2.2.1.1.3.4.2.cmml">r</mi><mrow id="S3.Ex2.m1.2.2.1.1.3.4.3" xref="S3.Ex2.m1.2.2.1.1.3.4.3.cmml"><mi id="S3.Ex2.m1.2.2.1.1.3.4.3.2" xref="S3.Ex2.m1.2.2.1.1.3.4.3.2.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.Ex2.m1.2.2.1.1.3.4.3.1" xref="S3.Ex2.m1.2.2.1.1.3.4.3.1.cmml">â€‹</mo><mi id="S3.Ex2.m1.2.2.1.1.3.4.3.3" xref="S3.Ex2.m1.2.2.1.1.3.4.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.Ex2.m1.2.2.1.1.3.4.3.1a" xref="S3.Ex2.m1.2.2.1.1.3.4.3.1.cmml">â€‹</mo><mi id="S3.Ex2.m1.2.2.1.1.3.4.3.4" xref="S3.Ex2.m1.2.2.1.1.3.4.3.4.cmml">i</mi></mrow></msub><mo id="S3.Ex2.m1.2.2.1.1.3.1b" xref="S3.Ex2.m1.2.2.1.1.3.1.cmml">+</mo><msub id="S3.Ex2.m1.2.2.1.1.3.5" xref="S3.Ex2.m1.2.2.1.1.3.5.cmml"><mi id="S3.Ex2.m1.2.2.1.1.3.5.2" xref="S3.Ex2.m1.2.2.1.1.3.5.2.cmml">r</mi><mrow id="S3.Ex2.m1.2.2.1.1.3.5.3" xref="S3.Ex2.m1.2.2.1.1.3.5.3.cmml"><mi id="S3.Ex2.m1.2.2.1.1.3.5.3.2" xref="S3.Ex2.m1.2.2.1.1.3.5.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.Ex2.m1.2.2.1.1.3.5.3.1" xref="S3.Ex2.m1.2.2.1.1.3.5.3.1.cmml">â€‹</mo><mi id="S3.Ex2.m1.2.2.1.1.3.5.3.3" xref="S3.Ex2.m1.2.2.1.1.3.5.3.3.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.Ex2.m1.2.2.1.1.3.5.3.1a" xref="S3.Ex2.m1.2.2.1.1.3.5.3.1.cmml">â€‹</mo><mi id="S3.Ex2.m1.2.2.1.1.3.5.3.4" xref="S3.Ex2.m1.2.2.1.1.3.5.3.4.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.Ex2.m1.2.2.1.1.3.5.3.1b" xref="S3.Ex2.m1.2.2.1.1.3.5.3.1.cmml">â€‹</mo><mi id="S3.Ex2.m1.2.2.1.1.3.5.3.5" xref="S3.Ex2.m1.2.2.1.1.3.5.3.5.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.Ex2.m1.2.2.1.1.3.5.3.1c" xref="S3.Ex2.m1.2.2.1.1.3.5.3.1.cmml">â€‹</mo><mi id="S3.Ex2.m1.2.2.1.1.3.5.3.6" xref="S3.Ex2.m1.2.2.1.1.3.5.3.6.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.Ex2.m1.2.2.1.1.3.5.3.1d" xref="S3.Ex2.m1.2.2.1.1.3.5.3.1.cmml">â€‹</mo><mi id="S3.Ex2.m1.2.2.1.1.3.5.3.7" xref="S3.Ex2.m1.2.2.1.1.3.5.3.7.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.Ex2.m1.2.2.1.1.3.5.3.1e" xref="S3.Ex2.m1.2.2.1.1.3.5.3.1.cmml">â€‹</mo><mi id="S3.Ex2.m1.2.2.1.1.3.5.3.8" xref="S3.Ex2.m1.2.2.1.1.3.5.3.8.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.Ex2.m1.2.2.1.1.3.5.3.1f" xref="S3.Ex2.m1.2.2.1.1.3.5.3.1.cmml">â€‹</mo><mi id="S3.Ex2.m1.2.2.1.1.3.5.3.9" xref="S3.Ex2.m1.2.2.1.1.3.5.3.9.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.Ex2.m1.2.2.1.1.3.5.3.1g" xref="S3.Ex2.m1.2.2.1.1.3.5.3.1.cmml">â€‹</mo><mi id="S3.Ex2.m1.2.2.1.1.3.5.3.10" xref="S3.Ex2.m1.2.2.1.1.3.5.3.10.cmml">n</mi></mrow></msub><mo id="S3.Ex2.m1.2.2.1.1.3.1c" xref="S3.Ex2.m1.2.2.1.1.3.1.cmml">+</mo><msub id="S3.Ex2.m1.2.2.1.1.3.6" xref="S3.Ex2.m1.2.2.1.1.3.6.cmml"><mi id="S3.Ex2.m1.2.2.1.1.3.6.2" xref="S3.Ex2.m1.2.2.1.1.3.6.2.cmml">r</mi><mrow id="S3.Ex2.m1.2.2.1.1.3.6.3" xref="S3.Ex2.m1.2.2.1.1.3.6.3.cmml"><mi id="S3.Ex2.m1.2.2.1.1.3.6.3.2" xref="S3.Ex2.m1.2.2.1.1.3.6.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.Ex2.m1.2.2.1.1.3.6.3.1" xref="S3.Ex2.m1.2.2.1.1.3.6.3.1.cmml">â€‹</mo><mi id="S3.Ex2.m1.2.2.1.1.3.6.3.3" xref="S3.Ex2.m1.2.2.1.1.3.6.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.Ex2.m1.2.2.1.1.3.6.3.1a" xref="S3.Ex2.m1.2.2.1.1.3.6.3.1.cmml">â€‹</mo><mi id="S3.Ex2.m1.2.2.1.1.3.6.3.4" xref="S3.Ex2.m1.2.2.1.1.3.6.3.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.Ex2.m1.2.2.1.1.3.6.3.1b" xref="S3.Ex2.m1.2.2.1.1.3.6.3.1.cmml">â€‹</mo><mi id="S3.Ex2.m1.2.2.1.1.3.6.3.5" xref="S3.Ex2.m1.2.2.1.1.3.6.3.5.cmml">e</mi></mrow></msub><mo id="S3.Ex2.m1.2.2.1.1.3.1d" xref="S3.Ex2.m1.2.2.1.1.3.1.cmml">+</mo><msub id="S3.Ex2.m1.2.2.1.1.3.7" xref="S3.Ex2.m1.2.2.1.1.3.7.cmml"><mi id="S3.Ex2.m1.2.2.1.1.3.7.2" xref="S3.Ex2.m1.2.2.1.1.3.7.2.cmml">r</mi><mrow id="S3.Ex2.m1.2.2.1.1.3.7.3" xref="S3.Ex2.m1.2.2.1.1.3.7.3.cmml"><mi id="S3.Ex2.m1.2.2.1.1.3.7.3.2" xref="S3.Ex2.m1.2.2.1.1.3.7.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.Ex2.m1.2.2.1.1.3.7.3.1" xref="S3.Ex2.m1.2.2.1.1.3.7.3.1.cmml">â€‹</mo><mi id="S3.Ex2.m1.2.2.1.1.3.7.3.3" xref="S3.Ex2.m1.2.2.1.1.3.7.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.Ex2.m1.2.2.1.1.3.7.3.1a" xref="S3.Ex2.m1.2.2.1.1.3.7.3.1.cmml">â€‹</mo><mi id="S3.Ex2.m1.2.2.1.1.3.7.3.4" xref="S3.Ex2.m1.2.2.1.1.3.7.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.Ex2.m1.2.2.1.1.3.7.3.1b" xref="S3.Ex2.m1.2.2.1.1.3.7.3.1.cmml">â€‹</mo><mi id="S3.Ex2.m1.2.2.1.1.3.7.3.5" xref="S3.Ex2.m1.2.2.1.1.3.7.3.5.cmml">e</mi></mrow></msub><mo id="S3.Ex2.m1.2.2.1.1.3.1e" xref="S3.Ex2.m1.2.2.1.1.3.1.cmml">+</mo><msub id="S3.Ex2.m1.2.2.1.1.3.8" xref="S3.Ex2.m1.2.2.1.1.3.8.cmml"><mi id="S3.Ex2.m1.2.2.1.1.3.8.2" xref="S3.Ex2.m1.2.2.1.1.3.8.2.cmml">r</mi><mrow id="S3.Ex2.m1.2.2.1.1.3.8.3" xref="S3.Ex2.m1.2.2.1.1.3.8.3.cmml"><mi id="S3.Ex2.m1.2.2.1.1.3.8.3.2" xref="S3.Ex2.m1.2.2.1.1.3.8.3.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.Ex2.m1.2.2.1.1.3.8.3.1" xref="S3.Ex2.m1.2.2.1.1.3.8.3.1.cmml">â€‹</mo><mi id="S3.Ex2.m1.2.2.1.1.3.8.3.3" xref="S3.Ex2.m1.2.2.1.1.3.8.3.3.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.Ex2.m1.2.2.1.1.3.8.3.1a" xref="S3.Ex2.m1.2.2.1.1.3.8.3.1.cmml">â€‹</mo><mi id="S3.Ex2.m1.2.2.1.1.3.8.3.4" xref="S3.Ex2.m1.2.2.1.1.3.8.3.4.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.Ex2.m1.2.2.1.1.3.8.3.1b" xref="S3.Ex2.m1.2.2.1.1.3.8.3.1.cmml">â€‹</mo><mi id="S3.Ex2.m1.2.2.1.1.3.8.3.5" xref="S3.Ex2.m1.2.2.1.1.3.8.3.5.cmml">c</mi></mrow></msub></mrow></mrow><mo id="S3.Ex2.m1.2.2.1.2" xref="S3.Ex2.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex2.m1.2b"><apply id="S3.Ex2.m1.2.2.1.1.cmml" xref="S3.Ex2.m1.2.2.1"><eq id="S3.Ex2.m1.2.2.1.1.1.cmml" xref="S3.Ex2.m1.2.2.1.1.1"></eq><apply id="S3.Ex2.m1.2.2.1.1.2.cmml" xref="S3.Ex2.m1.2.2.1.1.2"><csymbol cd="ambiguous" id="S3.Ex2.m1.2.2.1.1.2.1.cmml" xref="S3.Ex2.m1.2.2.1.1.2">subscript</csymbol><ci id="S3.Ex2.m1.2.2.1.1.2.2.cmml" xref="S3.Ex2.m1.2.2.1.1.2.2">ğ‘Ÿ</ci><ci id="S3.Ex2.m1.2.2.1.1.2.3.cmml" xref="S3.Ex2.m1.2.2.1.1.2.3">ğ‘¡</ci></apply><apply id="S3.Ex2.m1.2.2.1.1.3.cmml" xref="S3.Ex2.m1.2.2.1.1.3"><plus id="S3.Ex2.m1.2.2.1.1.3.1.cmml" xref="S3.Ex2.m1.2.2.1.1.3.1"></plus><apply id="S3.Ex2.m1.2.2.1.1.3.2.cmml" xref="S3.Ex2.m1.2.2.1.1.3.2"><csymbol cd="ambiguous" id="S3.Ex2.m1.2.2.1.1.3.2.1.cmml" xref="S3.Ex2.m1.2.2.1.1.3.2">subscript</csymbol><ci id="S3.Ex2.m1.2.2.1.1.3.2.2.cmml" xref="S3.Ex2.m1.2.2.1.1.3.2.2">ğ‘Ÿ</ci><list id="S3.Ex2.m1.1.1.1.2.cmml" xref="S3.Ex2.m1.1.1.1.1"><apply id="S3.Ex2.m1.1.1.1.1.1.cmml" xref="S3.Ex2.m1.1.1.1.1.1"><times id="S3.Ex2.m1.1.1.1.1.1.1.cmml" xref="S3.Ex2.m1.1.1.1.1.1.1"></times><ci id="S3.Ex2.m1.1.1.1.1.1.2.cmml" xref="S3.Ex2.m1.1.1.1.1.1.2">ğ‘</ci><ci id="S3.Ex2.m1.1.1.1.1.1.3.cmml" xref="S3.Ex2.m1.1.1.1.1.1.3">ğ‘œ</ci><ci id="S3.Ex2.m1.1.1.1.1.1.4.cmml" xref="S3.Ex2.m1.1.1.1.1.1.4">ğ‘›</ci><ci id="S3.Ex2.m1.1.1.1.1.1.5.cmml" xref="S3.Ex2.m1.1.1.1.1.1.5">ğ‘¡</ci></apply></list></apply><apply id="S3.Ex2.m1.2.2.1.1.3.3.cmml" xref="S3.Ex2.m1.2.2.1.1.3.3"><csymbol cd="ambiguous" id="S3.Ex2.m1.2.2.1.1.3.3.1.cmml" xref="S3.Ex2.m1.2.2.1.1.3.3">subscript</csymbol><ci id="S3.Ex2.m1.2.2.1.1.3.3.2.cmml" xref="S3.Ex2.m1.2.2.1.1.3.3.2">ğ‘Ÿ</ci><apply id="S3.Ex2.m1.2.2.1.1.3.3.3.cmml" xref="S3.Ex2.m1.2.2.1.1.3.3.3"><times id="S3.Ex2.m1.2.2.1.1.3.3.3.1.cmml" xref="S3.Ex2.m1.2.2.1.1.3.3.3.1"></times><ci id="S3.Ex2.m1.2.2.1.1.3.3.3.2.cmml" xref="S3.Ex2.m1.2.2.1.1.3.3.3.2">ğ‘‘</ci><ci id="S3.Ex2.m1.2.2.1.1.3.3.3.3.cmml" xref="S3.Ex2.m1.2.2.1.1.3.3.3.3">ğ‘–</ci><ci id="S3.Ex2.m1.2.2.1.1.3.3.3.4.cmml" xref="S3.Ex2.m1.2.2.1.1.3.3.3.4">ğ‘ </ci><ci id="S3.Ex2.m1.2.2.1.1.3.3.3.5.cmml" xref="S3.Ex2.m1.2.2.1.1.3.3.3.5">ğ‘¡</ci></apply></apply><apply id="S3.Ex2.m1.2.2.1.1.3.4.cmml" xref="S3.Ex2.m1.2.2.1.1.3.4"><csymbol cd="ambiguous" id="S3.Ex2.m1.2.2.1.1.3.4.1.cmml" xref="S3.Ex2.m1.2.2.1.1.3.4">subscript</csymbol><ci id="S3.Ex2.m1.2.2.1.1.3.4.2.cmml" xref="S3.Ex2.m1.2.2.1.1.3.4.2">ğ‘Ÿ</ci><apply id="S3.Ex2.m1.2.2.1.1.3.4.3.cmml" xref="S3.Ex2.m1.2.2.1.1.3.4.3"><times id="S3.Ex2.m1.2.2.1.1.3.4.3.1.cmml" xref="S3.Ex2.m1.2.2.1.1.3.4.3.1"></times><ci id="S3.Ex2.m1.2.2.1.1.3.4.3.2.cmml" xref="S3.Ex2.m1.2.2.1.1.3.4.3.2">ğ‘œ</ci><ci id="S3.Ex2.m1.2.2.1.1.3.4.3.3.cmml" xref="S3.Ex2.m1.2.2.1.1.3.4.3.3">ğ‘Ÿ</ci><ci id="S3.Ex2.m1.2.2.1.1.3.4.3.4.cmml" xref="S3.Ex2.m1.2.2.1.1.3.4.3.4">ğ‘–</ci></apply></apply><apply id="S3.Ex2.m1.2.2.1.1.3.5.cmml" xref="S3.Ex2.m1.2.2.1.1.3.5"><csymbol cd="ambiguous" id="S3.Ex2.m1.2.2.1.1.3.5.1.cmml" xref="S3.Ex2.m1.2.2.1.1.3.5">subscript</csymbol><ci id="S3.Ex2.m1.2.2.1.1.3.5.2.cmml" xref="S3.Ex2.m1.2.2.1.1.3.5.2">ğ‘Ÿ</ci><apply id="S3.Ex2.m1.2.2.1.1.3.5.3.cmml" xref="S3.Ex2.m1.2.2.1.1.3.5.3"><times id="S3.Ex2.m1.2.2.1.1.3.5.3.1.cmml" xref="S3.Ex2.m1.2.2.1.1.3.5.3.1"></times><ci id="S3.Ex2.m1.2.2.1.1.3.5.3.2.cmml" xref="S3.Ex2.m1.2.2.1.1.3.5.3.2">ğ‘</ci><ci id="S3.Ex2.m1.2.2.1.1.3.5.3.3.cmml" xref="S3.Ex2.m1.2.2.1.1.3.5.3.3">ğ‘¡</ci><ci id="S3.Ex2.m1.2.2.1.1.3.5.3.4.cmml" xref="S3.Ex2.m1.2.2.1.1.3.5.3.4">ğ‘¡</ci><ci id="S3.Ex2.m1.2.2.1.1.3.5.3.5.cmml" xref="S3.Ex2.m1.2.2.1.1.3.5.3.5">ğ‘’</ci><ci id="S3.Ex2.m1.2.2.1.1.3.5.3.6.cmml" xref="S3.Ex2.m1.2.2.1.1.3.5.3.6">ğ‘›</ci><ci id="S3.Ex2.m1.2.2.1.1.3.5.3.7.cmml" xref="S3.Ex2.m1.2.2.1.1.3.5.3.7">ğ‘¡</ci><ci id="S3.Ex2.m1.2.2.1.1.3.5.3.8.cmml" xref="S3.Ex2.m1.2.2.1.1.3.5.3.8">ğ‘–</ci><ci id="S3.Ex2.m1.2.2.1.1.3.5.3.9.cmml" xref="S3.Ex2.m1.2.2.1.1.3.5.3.9">ğ‘œ</ci><ci id="S3.Ex2.m1.2.2.1.1.3.5.3.10.cmml" xref="S3.Ex2.m1.2.2.1.1.3.5.3.10">ğ‘›</ci></apply></apply><apply id="S3.Ex2.m1.2.2.1.1.3.6.cmml" xref="S3.Ex2.m1.2.2.1.1.3.6"><csymbol cd="ambiguous" id="S3.Ex2.m1.2.2.1.1.3.6.1.cmml" xref="S3.Ex2.m1.2.2.1.1.3.6">subscript</csymbol><ci id="S3.Ex2.m1.2.2.1.1.3.6.2.cmml" xref="S3.Ex2.m1.2.2.1.1.3.6.2">ğ‘Ÿ</ci><apply id="S3.Ex2.m1.2.2.1.1.3.6.3.cmml" xref="S3.Ex2.m1.2.2.1.1.3.6.3"><times id="S3.Ex2.m1.2.2.1.1.3.6.3.1.cmml" xref="S3.Ex2.m1.2.2.1.1.3.6.3.1"></times><ci id="S3.Ex2.m1.2.2.1.1.3.6.3.2.cmml" xref="S3.Ex2.m1.2.2.1.1.3.6.3.2">ğ‘</ci><ci id="S3.Ex2.m1.2.2.1.1.3.6.3.3.cmml" xref="S3.Ex2.m1.2.2.1.1.3.6.3.3">ğ‘’</ci><ci id="S3.Ex2.m1.2.2.1.1.3.6.3.4.cmml" xref="S3.Ex2.m1.2.2.1.1.3.6.3.4">ğ‘›</ci><ci id="S3.Ex2.m1.2.2.1.1.3.6.3.5.cmml" xref="S3.Ex2.m1.2.2.1.1.3.6.3.5">ğ‘’</ci></apply></apply><apply id="S3.Ex2.m1.2.2.1.1.3.7.cmml" xref="S3.Ex2.m1.2.2.1.1.3.7"><csymbol cd="ambiguous" id="S3.Ex2.m1.2.2.1.1.3.7.1.cmml" xref="S3.Ex2.m1.2.2.1.1.3.7">subscript</csymbol><ci id="S3.Ex2.m1.2.2.1.1.3.7.2.cmml" xref="S3.Ex2.m1.2.2.1.1.3.7.2">ğ‘Ÿ</ci><apply id="S3.Ex2.m1.2.2.1.1.3.7.3.cmml" xref="S3.Ex2.m1.2.2.1.1.3.7.3"><times id="S3.Ex2.m1.2.2.1.1.3.7.3.1.cmml" xref="S3.Ex2.m1.2.2.1.1.3.7.3.1"></times><ci id="S3.Ex2.m1.2.2.1.1.3.7.3.2.cmml" xref="S3.Ex2.m1.2.2.1.1.3.7.3.2">ğ‘</ci><ci id="S3.Ex2.m1.2.2.1.1.3.7.3.3.cmml" xref="S3.Ex2.m1.2.2.1.1.3.7.3.3">ğ‘œ</ci><ci id="S3.Ex2.m1.2.2.1.1.3.7.3.4.cmml" xref="S3.Ex2.m1.2.2.1.1.3.7.3.4">ğ‘ </ci><ci id="S3.Ex2.m1.2.2.1.1.3.7.3.5.cmml" xref="S3.Ex2.m1.2.2.1.1.3.7.3.5">ğ‘’</ci></apply></apply><apply id="S3.Ex2.m1.2.2.1.1.3.8.cmml" xref="S3.Ex2.m1.2.2.1.1.3.8"><csymbol cd="ambiguous" id="S3.Ex2.m1.2.2.1.1.3.8.1.cmml" xref="S3.Ex2.m1.2.2.1.1.3.8">subscript</csymbol><ci id="S3.Ex2.m1.2.2.1.1.3.8.2.cmml" xref="S3.Ex2.m1.2.2.1.1.3.8.2">ğ‘Ÿ</ci><apply id="S3.Ex2.m1.2.2.1.1.3.8.3.cmml" xref="S3.Ex2.m1.2.2.1.1.3.8.3"><times id="S3.Ex2.m1.2.2.1.1.3.8.3.1.cmml" xref="S3.Ex2.m1.2.2.1.1.3.8.3.1"></times><ci id="S3.Ex2.m1.2.2.1.1.3.8.3.2.cmml" xref="S3.Ex2.m1.2.2.1.1.3.8.3.2">ğ‘ </ci><ci id="S3.Ex2.m1.2.2.1.1.3.8.3.3.cmml" xref="S3.Ex2.m1.2.2.1.1.3.8.3.3">ğ‘¢</ci><ci id="S3.Ex2.m1.2.2.1.1.3.8.3.4.cmml" xref="S3.Ex2.m1.2.2.1.1.3.8.3.4">ğ‘</ci><ci id="S3.Ex2.m1.2.2.1.1.3.8.3.5.cmml" xref="S3.Ex2.m1.2.2.1.1.3.8.3.5">ğ‘</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex2.m1.2c">r_{t}=r_{cont.}+r_{dist}+r_{ori}+r_{attention}+r_{pene}+r_{pose}+r_{succ},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S3.SS1.p8.8" class="ltx_p">where <math id="S3.SS1.p8.3.m1.1" class="ltx_Math" alttext="r_{cont.}" display="inline"><semantics id="S3.SS1.p8.3.m1.1a"><msub id="S3.SS1.p8.3.m1.1.2" xref="S3.SS1.p8.3.m1.1.2.cmml"><mi id="S3.SS1.p8.3.m1.1.2.2" xref="S3.SS1.p8.3.m1.1.2.2.cmml">r</mi><mrow id="S3.SS1.p8.3.m1.1.1.1.1" xref="S3.SS1.p8.3.m1.1.1.1.2.cmml"><mrow id="S3.SS1.p8.3.m1.1.1.1.1.1" xref="S3.SS1.p8.3.m1.1.1.1.1.1.cmml"><mi id="S3.SS1.p8.3.m1.1.1.1.1.1.2" xref="S3.SS1.p8.3.m1.1.1.1.1.1.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p8.3.m1.1.1.1.1.1.1" xref="S3.SS1.p8.3.m1.1.1.1.1.1.1.cmml">â€‹</mo><mi id="S3.SS1.p8.3.m1.1.1.1.1.1.3" xref="S3.SS1.p8.3.m1.1.1.1.1.1.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p8.3.m1.1.1.1.1.1.1a" xref="S3.SS1.p8.3.m1.1.1.1.1.1.1.cmml">â€‹</mo><mi id="S3.SS1.p8.3.m1.1.1.1.1.1.4" xref="S3.SS1.p8.3.m1.1.1.1.1.1.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p8.3.m1.1.1.1.1.1.1b" xref="S3.SS1.p8.3.m1.1.1.1.1.1.1.cmml">â€‹</mo><mi id="S3.SS1.p8.3.m1.1.1.1.1.1.5" xref="S3.SS1.p8.3.m1.1.1.1.1.1.5.cmml">t</mi></mrow><mo lspace="0em" id="S3.SS1.p8.3.m1.1.1.1.1.2" xref="S3.SS1.p8.3.m1.1.1.1.2.cmml">.</mo></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p8.3.m1.1b"><apply id="S3.SS1.p8.3.m1.1.2.cmml" xref="S3.SS1.p8.3.m1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p8.3.m1.1.2.1.cmml" xref="S3.SS1.p8.3.m1.1.2">subscript</csymbol><ci id="S3.SS1.p8.3.m1.1.2.2.cmml" xref="S3.SS1.p8.3.m1.1.2.2">ğ‘Ÿ</ci><list id="S3.SS1.p8.3.m1.1.1.1.2.cmml" xref="S3.SS1.p8.3.m1.1.1.1.1"><apply id="S3.SS1.p8.3.m1.1.1.1.1.1.cmml" xref="S3.SS1.p8.3.m1.1.1.1.1.1"><times id="S3.SS1.p8.3.m1.1.1.1.1.1.1.cmml" xref="S3.SS1.p8.3.m1.1.1.1.1.1.1"></times><ci id="S3.SS1.p8.3.m1.1.1.1.1.1.2.cmml" xref="S3.SS1.p8.3.m1.1.1.1.1.1.2">ğ‘</ci><ci id="S3.SS1.p8.3.m1.1.1.1.1.1.3.cmml" xref="S3.SS1.p8.3.m1.1.1.1.1.1.3">ğ‘œ</ci><ci id="S3.SS1.p8.3.m1.1.1.1.1.1.4.cmml" xref="S3.SS1.p8.3.m1.1.1.1.1.1.4">ğ‘›</ci><ci id="S3.SS1.p8.3.m1.1.1.1.1.1.5.cmml" xref="S3.SS1.p8.3.m1.1.1.1.1.1.5">ğ‘¡</ci></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p8.3.m1.1c">r_{cont.}</annotation></semantics></math> enforces valid foot contact and minimizes foot skating; <math id="S3.SS1.p8.4.m2.1" class="ltx_Math" alttext="r_{dist}" display="inline"><semantics id="S3.SS1.p8.4.m2.1a"><msub id="S3.SS1.p8.4.m2.1.1" xref="S3.SS1.p8.4.m2.1.1.cmml"><mi id="S3.SS1.p8.4.m2.1.1.2" xref="S3.SS1.p8.4.m2.1.1.2.cmml">r</mi><mrow id="S3.SS1.p8.4.m2.1.1.3" xref="S3.SS1.p8.4.m2.1.1.3.cmml"><mi id="S3.SS1.p8.4.m2.1.1.3.2" xref="S3.SS1.p8.4.m2.1.1.3.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p8.4.m2.1.1.3.1" xref="S3.SS1.p8.4.m2.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS1.p8.4.m2.1.1.3.3" xref="S3.SS1.p8.4.m2.1.1.3.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p8.4.m2.1.1.3.1a" xref="S3.SS1.p8.4.m2.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS1.p8.4.m2.1.1.3.4" xref="S3.SS1.p8.4.m2.1.1.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p8.4.m2.1.1.3.1b" xref="S3.SS1.p8.4.m2.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS1.p8.4.m2.1.1.3.5" xref="S3.SS1.p8.4.m2.1.1.3.5.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p8.4.m2.1b"><apply id="S3.SS1.p8.4.m2.1.1.cmml" xref="S3.SS1.p8.4.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p8.4.m2.1.1.1.cmml" xref="S3.SS1.p8.4.m2.1.1">subscript</csymbol><ci id="S3.SS1.p8.4.m2.1.1.2.cmml" xref="S3.SS1.p8.4.m2.1.1.2">ğ‘Ÿ</ci><apply id="S3.SS1.p8.4.m2.1.1.3.cmml" xref="S3.SS1.p8.4.m2.1.1.3"><times id="S3.SS1.p8.4.m2.1.1.3.1.cmml" xref="S3.SS1.p8.4.m2.1.1.3.1"></times><ci id="S3.SS1.p8.4.m2.1.1.3.2.cmml" xref="S3.SS1.p8.4.m2.1.1.3.2">ğ‘‘</ci><ci id="S3.SS1.p8.4.m2.1.1.3.3.cmml" xref="S3.SS1.p8.4.m2.1.1.3.3">ğ‘–</ci><ci id="S3.SS1.p8.4.m2.1.1.3.4.cmml" xref="S3.SS1.p8.4.m2.1.1.3.4">ğ‘ </ci><ci id="S3.SS1.p8.4.m2.1.1.3.5.cmml" xref="S3.SS1.p8.4.m2.1.1.3.5">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p8.4.m2.1c">r_{dist}</annotation></semantics></math> encourages reaching the target; <math id="S3.SS1.p8.5.m3.1" class="ltx_Math" alttext="r_{ori}" display="inline"><semantics id="S3.SS1.p8.5.m3.1a"><msub id="S3.SS1.p8.5.m3.1.1" xref="S3.SS1.p8.5.m3.1.1.cmml"><mi id="S3.SS1.p8.5.m3.1.1.2" xref="S3.SS1.p8.5.m3.1.1.2.cmml">r</mi><mrow id="S3.SS1.p8.5.m3.1.1.3" xref="S3.SS1.p8.5.m3.1.1.3.cmml"><mi id="S3.SS1.p8.5.m3.1.1.3.2" xref="S3.SS1.p8.5.m3.1.1.3.2.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p8.5.m3.1.1.3.1" xref="S3.SS1.p8.5.m3.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS1.p8.5.m3.1.1.3.3" xref="S3.SS1.p8.5.m3.1.1.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p8.5.m3.1.1.3.1a" xref="S3.SS1.p8.5.m3.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS1.p8.5.m3.1.1.3.4" xref="S3.SS1.p8.5.m3.1.1.3.4.cmml">i</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p8.5.m3.1b"><apply id="S3.SS1.p8.5.m3.1.1.cmml" xref="S3.SS1.p8.5.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p8.5.m3.1.1.1.cmml" xref="S3.SS1.p8.5.m3.1.1">subscript</csymbol><ci id="S3.SS1.p8.5.m3.1.1.2.cmml" xref="S3.SS1.p8.5.m3.1.1.2">ğ‘Ÿ</ci><apply id="S3.SS1.p8.5.m3.1.1.3.cmml" xref="S3.SS1.p8.5.m3.1.1.3"><times id="S3.SS1.p8.5.m3.1.1.3.1.cmml" xref="S3.SS1.p8.5.m3.1.1.3.1"></times><ci id="S3.SS1.p8.5.m3.1.1.3.2.cmml" xref="S3.SS1.p8.5.m3.1.1.3.2">ğ‘œ</ci><ci id="S3.SS1.p8.5.m3.1.1.3.3.cmml" xref="S3.SS1.p8.5.m3.1.1.3.3">ğ‘Ÿ</ci><ci id="S3.SS1.p8.5.m3.1.1.3.4.cmml" xref="S3.SS1.p8.5.m3.1.1.3.4">ğ‘–</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p8.5.m3.1c">r_{ori}</annotation></semantics></math> aligns the body forward direction with the target; <math id="S3.SS1.p8.6.m4.1" class="ltx_Math" alttext="r_{pene}" display="inline"><semantics id="S3.SS1.p8.6.m4.1a"><msub id="S3.SS1.p8.6.m4.1.1" xref="S3.SS1.p8.6.m4.1.1.cmml"><mi id="S3.SS1.p8.6.m4.1.1.2" xref="S3.SS1.p8.6.m4.1.1.2.cmml">r</mi><mrow id="S3.SS1.p8.6.m4.1.1.3" xref="S3.SS1.p8.6.m4.1.1.3.cmml"><mi id="S3.SS1.p8.6.m4.1.1.3.2" xref="S3.SS1.p8.6.m4.1.1.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p8.6.m4.1.1.3.1" xref="S3.SS1.p8.6.m4.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS1.p8.6.m4.1.1.3.3" xref="S3.SS1.p8.6.m4.1.1.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p8.6.m4.1.1.3.1a" xref="S3.SS1.p8.6.m4.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS1.p8.6.m4.1.1.3.4" xref="S3.SS1.p8.6.m4.1.1.3.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p8.6.m4.1.1.3.1b" xref="S3.SS1.p8.6.m4.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS1.p8.6.m4.1.1.3.5" xref="S3.SS1.p8.6.m4.1.1.3.5.cmml">e</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p8.6.m4.1b"><apply id="S3.SS1.p8.6.m4.1.1.cmml" xref="S3.SS1.p8.6.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p8.6.m4.1.1.1.cmml" xref="S3.SS1.p8.6.m4.1.1">subscript</csymbol><ci id="S3.SS1.p8.6.m4.1.1.2.cmml" xref="S3.SS1.p8.6.m4.1.1.2">ğ‘Ÿ</ci><apply id="S3.SS1.p8.6.m4.1.1.3.cmml" xref="S3.SS1.p8.6.m4.1.1.3"><times id="S3.SS1.p8.6.m4.1.1.3.1.cmml" xref="S3.SS1.p8.6.m4.1.1.3.1"></times><ci id="S3.SS1.p8.6.m4.1.1.3.2.cmml" xref="S3.SS1.p8.6.m4.1.1.3.2">ğ‘</ci><ci id="S3.SS1.p8.6.m4.1.1.3.3.cmml" xref="S3.SS1.p8.6.m4.1.1.3.3">ğ‘’</ci><ci id="S3.SS1.p8.6.m4.1.1.3.4.cmml" xref="S3.SS1.p8.6.m4.1.1.3.4">ğ‘›</ci><ci id="S3.SS1.p8.6.m4.1.1.3.5.cmml" xref="S3.SS1.p8.6.m4.1.1.3.5">ğ‘’</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p8.6.m4.1c">r_{pene}</annotation></semantics></math> guides collision avoidance; <math id="S3.SS1.p8.7.m5.1" class="ltx_Math" alttext="r_{pose}" display="inline"><semantics id="S3.SS1.p8.7.m5.1a"><msub id="S3.SS1.p8.7.m5.1.1" xref="S3.SS1.p8.7.m5.1.1.cmml"><mi id="S3.SS1.p8.7.m5.1.1.2" xref="S3.SS1.p8.7.m5.1.1.2.cmml">r</mi><mrow id="S3.SS1.p8.7.m5.1.1.3" xref="S3.SS1.p8.7.m5.1.1.3.cmml"><mi id="S3.SS1.p8.7.m5.1.1.3.2" xref="S3.SS1.p8.7.m5.1.1.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p8.7.m5.1.1.3.1" xref="S3.SS1.p8.7.m5.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS1.p8.7.m5.1.1.3.3" xref="S3.SS1.p8.7.m5.1.1.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p8.7.m5.1.1.3.1a" xref="S3.SS1.p8.7.m5.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS1.p8.7.m5.1.1.3.4" xref="S3.SS1.p8.7.m5.1.1.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p8.7.m5.1.1.3.1b" xref="S3.SS1.p8.7.m5.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS1.p8.7.m5.1.1.3.5" xref="S3.SS1.p8.7.m5.1.1.3.5.cmml">e</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p8.7.m5.1b"><apply id="S3.SS1.p8.7.m5.1.1.cmml" xref="S3.SS1.p8.7.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.p8.7.m5.1.1.1.cmml" xref="S3.SS1.p8.7.m5.1.1">subscript</csymbol><ci id="S3.SS1.p8.7.m5.1.1.2.cmml" xref="S3.SS1.p8.7.m5.1.1.2">ğ‘Ÿ</ci><apply id="S3.SS1.p8.7.m5.1.1.3.cmml" xref="S3.SS1.p8.7.m5.1.1.3"><times id="S3.SS1.p8.7.m5.1.1.3.1.cmml" xref="S3.SS1.p8.7.m5.1.1.3.1"></times><ci id="S3.SS1.p8.7.m5.1.1.3.2.cmml" xref="S3.SS1.p8.7.m5.1.1.3.2">ğ‘</ci><ci id="S3.SS1.p8.7.m5.1.1.3.3.cmml" xref="S3.SS1.p8.7.m5.1.1.3.3">ğ‘œ</ci><ci id="S3.SS1.p8.7.m5.1.1.3.4.cmml" xref="S3.SS1.p8.7.m5.1.1.3.4">ğ‘ </ci><ci id="S3.SS1.p8.7.m5.1.1.3.5.cmml" xref="S3.SS1.p8.7.m5.1.1.3.5">ğ‘’</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p8.7.m5.1c">r_{pose}</annotation></semantics></math> reduces unrealistic human poses; and <math id="S3.SS1.p8.8.m6.1" class="ltx_Math" alttext="r_{succ}" display="inline"><semantics id="S3.SS1.p8.8.m6.1a"><msub id="S3.SS1.p8.8.m6.1.1" xref="S3.SS1.p8.8.m6.1.1.cmml"><mi id="S3.SS1.p8.8.m6.1.1.2" xref="S3.SS1.p8.8.m6.1.1.2.cmml">r</mi><mrow id="S3.SS1.p8.8.m6.1.1.3" xref="S3.SS1.p8.8.m6.1.1.3.cmml"><mi id="S3.SS1.p8.8.m6.1.1.3.2" xref="S3.SS1.p8.8.m6.1.1.3.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p8.8.m6.1.1.3.1" xref="S3.SS1.p8.8.m6.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS1.p8.8.m6.1.1.3.3" xref="S3.SS1.p8.8.m6.1.1.3.3.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p8.8.m6.1.1.3.1a" xref="S3.SS1.p8.8.m6.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS1.p8.8.m6.1.1.3.4" xref="S3.SS1.p8.8.m6.1.1.3.4.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p8.8.m6.1.1.3.1b" xref="S3.SS1.p8.8.m6.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS1.p8.8.m6.1.1.3.5" xref="S3.SS1.p8.8.m6.1.1.3.5.cmml">c</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p8.8.m6.1b"><apply id="S3.SS1.p8.8.m6.1.1.cmml" xref="S3.SS1.p8.8.m6.1.1"><csymbol cd="ambiguous" id="S3.SS1.p8.8.m6.1.1.1.cmml" xref="S3.SS1.p8.8.m6.1.1">subscript</csymbol><ci id="S3.SS1.p8.8.m6.1.1.2.cmml" xref="S3.SS1.p8.8.m6.1.1.2">ğ‘Ÿ</ci><apply id="S3.SS1.p8.8.m6.1.1.3.cmml" xref="S3.SS1.p8.8.m6.1.1.3"><times id="S3.SS1.p8.8.m6.1.1.3.1.cmml" xref="S3.SS1.p8.8.m6.1.1.3.1"></times><ci id="S3.SS1.p8.8.m6.1.1.3.2.cmml" xref="S3.SS1.p8.8.m6.1.1.3.2">ğ‘ </ci><ci id="S3.SS1.p8.8.m6.1.1.3.3.cmml" xref="S3.SS1.p8.8.m6.1.1.3.3">ğ‘¢</ci><ci id="S3.SS1.p8.8.m6.1.1.3.4.cmml" xref="S3.SS1.p8.8.m6.1.1.3.4">ğ‘</ci><ci id="S3.SS1.p8.8.m6.1.1.3.5.cmml" xref="S3.SS1.p8.8.m6.1.1.3.5">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p8.8.m6.1c">r_{succ}</annotation></semantics></math> is a sparse reward when reaching the target.</p>
</div>
<div id="S3.SS1.p9" class="ltx_para ltx_noindent">
<p id="S3.SS1.p9.1" class="ltx_p"><span id="S3.SS1.p9.1.1" class="ltx_text ltx_font_bold">Episode Termination.</span> To handle collisions beyond <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib129" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">129</span></a>]</cite>, we employ multiple <span id="S3.SS1.p9.1.2" class="ltx_text ltx_font_italic">termination</span> signals to conclude an episode if the generated motion primitive <math id="S3.SS1.p9.1.m1.1" class="ltx_Math" alttext="\mathbf{X}_{t}" display="inline"><semantics id="S3.SS1.p9.1.m1.1a"><msub id="S3.SS1.p9.1.m1.1.1" xref="S3.SS1.p9.1.m1.1.1.cmml"><mi id="S3.SS1.p9.1.m1.1.1.2" xref="S3.SS1.p9.1.m1.1.1.2.cmml">ğ—</mi><mi id="S3.SS1.p9.1.m1.1.1.3" xref="S3.SS1.p9.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p9.1.m1.1b"><apply id="S3.SS1.p9.1.m1.1.1.cmml" xref="S3.SS1.p9.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p9.1.m1.1.1.1.cmml" xref="S3.SS1.p9.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p9.1.m1.1.1.2.cmml" xref="S3.SS1.p9.1.m1.1.1.2">ğ—</ci><ci id="S3.SS1.p9.1.m1.1.1.3.cmml" xref="S3.SS1.p9.1.m1.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p9.1.m1.1c">\mathbf{X}_{t}</annotation></semantics></math> satisfies any of the following conditions:</p>
<ul id="S3.I1" class="ltx_itemize">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.p1.1" class="ltx_p">Success: The virtual human reached the target.</p>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S3.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i2.p1.1" class="ltx_p">Penetration: The virtual human collides with the obstacle.</p>
</div>
</li>
<li id="S3.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S3.I1.i3.p1" class="ltx_para">
<p id="S3.I1.i3.p1.1" class="ltx_p">Timeout: The virtual human did not reach the target within the maximum timesteps.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Training Collision-Avoiding Stochastic Policies</h3>

<div id="S3.SS2.p1" class="ltx_para ltx_noindent">
<p id="S3.SS2.p1.1" class="ltx_p"><span id="S3.SS2.p1.1.1" class="ltx_text ltx_font_bold">Algorithm.</span> We use Proximal Policy Optimization <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib89" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">89</span></a>]</cite> (PPO) to learn a generalizable mapping from various egocentric sensing and body configurations to CAMPs.
Instead of extensive manual data collection for all possible input combinations, we leverage the stochastic nature of the PPO policy. Through exploration and sampling actions, the agent traverses the scene and generates varied egocentric sensing and body configurations, diversifying the training data.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">Instead of training each CAMP independently for every single step, we use PPO to train a sequence of CAMPs jointly in multi-step collision avoidance tasks. This approach can benefit choosing a more favorable CAMP which makes the subsequent action easier.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para ltx_noindent">
<p id="S3.SS2.p3.9" class="ltx_p"><span id="S3.SS2.p3.9.1" class="ltx_text ltx_font_bold">Network.</span> The network architecture is shown in Fig <a href="#S3.F2" title="Figure 2 â€£ 3 Ego-Sensing Driven Motion Synthesis â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. The actor and critic network share a feature extraction trunk to encode the state <math id="S3.SS2.p3.1.m1.1" class="ltx_Math" alttext="\mathbf{s}_{t}" display="inline"><semantics id="S3.SS2.p3.1.m1.1a"><msub id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml"><mi id="S3.SS2.p3.1.m1.1.1.2" xref="S3.SS2.p3.1.m1.1.1.2.cmml">ğ¬</mi><mi id="S3.SS2.p3.1.m1.1.1.3" xref="S3.SS2.p3.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><apply id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.1.m1.1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.p3.1.m1.1.1.2.cmml" xref="S3.SS2.p3.1.m1.1.1.2">ğ¬</ci><ci id="S3.SS2.p3.1.m1.1.1.3.cmml" xref="S3.SS2.p3.1.m1.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">\mathbf{s}_{t}</annotation></semantics></math>: the motion seed (<math id="S3.SS2.p3.2.m2.1" class="ltx_Math" alttext="\mathbf{X}_{t}^{S}" display="inline"><semantics id="S3.SS2.p3.2.m2.1a"><msubsup id="S3.SS2.p3.2.m2.1.1" xref="S3.SS2.p3.2.m2.1.1.cmml"><mi id="S3.SS2.p3.2.m2.1.1.2.2" xref="S3.SS2.p3.2.m2.1.1.2.2.cmml">ğ—</mi><mi id="S3.SS2.p3.2.m2.1.1.2.3" xref="S3.SS2.p3.2.m2.1.1.2.3.cmml">t</mi><mi id="S3.SS2.p3.2.m2.1.1.3" xref="S3.SS2.p3.2.m2.1.1.3.cmml">S</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m2.1b"><apply id="S3.SS2.p3.2.m2.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.2.m2.1.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1">superscript</csymbol><apply id="S3.SS2.p3.2.m2.1.1.2.cmml" xref="S3.SS2.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.2.m2.1.1.2.1.cmml" xref="S3.SS2.p3.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.p3.2.m2.1.1.2.2.cmml" xref="S3.SS2.p3.2.m2.1.1.2.2">ğ—</ci><ci id="S3.SS2.p3.2.m2.1.1.2.3.cmml" xref="S3.SS2.p3.2.m2.1.1.2.3">ğ‘¡</ci></apply><ci id="S3.SS2.p3.2.m2.1.1.3.cmml" xref="S3.SS2.p3.2.m2.1.1.3">ğ‘†</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m2.1c">\mathbf{X}_{t}^{S}</annotation></semantics></math> and <math id="S3.SS2.p3.3.m3.1" class="ltx_Math" alttext="\mathbf{X}_{t}^{S^{D}}" display="inline"><semantics id="S3.SS2.p3.3.m3.1a"><msubsup id="S3.SS2.p3.3.m3.1.1" xref="S3.SS2.p3.3.m3.1.1.cmml"><mi id="S3.SS2.p3.3.m3.1.1.2.2" xref="S3.SS2.p3.3.m3.1.1.2.2.cmml">ğ—</mi><mi id="S3.SS2.p3.3.m3.1.1.2.3" xref="S3.SS2.p3.3.m3.1.1.2.3.cmml">t</mi><msup id="S3.SS2.p3.3.m3.1.1.3" xref="S3.SS2.p3.3.m3.1.1.3.cmml"><mi id="S3.SS2.p3.3.m3.1.1.3.2" xref="S3.SS2.p3.3.m3.1.1.3.2.cmml">S</mi><mi id="S3.SS2.p3.3.m3.1.1.3.3" xref="S3.SS2.p3.3.m3.1.1.3.3.cmml">D</mi></msup></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.3.m3.1b"><apply id="S3.SS2.p3.3.m3.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.3.m3.1.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1">superscript</csymbol><apply id="S3.SS2.p3.3.m3.1.1.2.cmml" xref="S3.SS2.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.3.m3.1.1.2.1.cmml" xref="S3.SS2.p3.3.m3.1.1">subscript</csymbol><ci id="S3.SS2.p3.3.m3.1.1.2.2.cmml" xref="S3.SS2.p3.3.m3.1.1.2.2">ğ—</ci><ci id="S3.SS2.p3.3.m3.1.1.2.3.cmml" xref="S3.SS2.p3.3.m3.1.1.2.3">ğ‘¡</ci></apply><apply id="S3.SS2.p3.3.m3.1.1.3.cmml" xref="S3.SS2.p3.3.m3.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p3.3.m3.1.1.3.1.cmml" xref="S3.SS2.p3.3.m3.1.1.3">superscript</csymbol><ci id="S3.SS2.p3.3.m3.1.1.3.2.cmml" xref="S3.SS2.p3.3.m3.1.1.3.2">ğ‘†</ci><ci id="S3.SS2.p3.3.m3.1.1.3.3.cmml" xref="S3.SS2.p3.3.m3.1.1.3.3">ğ·</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.3.m3.1c">\mathbf{X}_{t}^{S^{D}}</annotation></semantics></math>) and the egocentric sensing <math id="S3.SS2.p3.4.m4.1" class="ltx_Math" alttext="\mathcal{E}_{t}" display="inline"><semantics id="S3.SS2.p3.4.m4.1a"><msub id="S3.SS2.p3.4.m4.1.1" xref="S3.SS2.p3.4.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p3.4.m4.1.1.2" xref="S3.SS2.p3.4.m4.1.1.2.cmml">â„°</mi><mi id="S3.SS2.p3.4.m4.1.1.3" xref="S3.SS2.p3.4.m4.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.4.m4.1b"><apply id="S3.SS2.p3.4.m4.1.1.cmml" xref="S3.SS2.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.4.m4.1.1.1.cmml" xref="S3.SS2.p3.4.m4.1.1">subscript</csymbol><ci id="S3.SS2.p3.4.m4.1.1.2.cmml" xref="S3.SS2.p3.4.m4.1.1.2">â„°</ci><ci id="S3.SS2.p3.4.m4.1.1.3.cmml" xref="S3.SS2.p3.4.m4.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.4.m4.1c">\mathcal{E}_{t}</annotation></semantics></math> are encoded using RNNs; the rest of scalar states are encoded using positional encodingÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib108" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">108</span></a>]</cite>. The actor predicts a stochastic policy <math id="S3.SS2.p3.5.m5.1" class="ltx_Math" alttext="\mathbf{a}_{t}\sim\pi(\mathbf{z}_{t}|\mathbf{s}_{t})" display="inline"><semantics id="S3.SS2.p3.5.m5.1a"><mrow id="S3.SS2.p3.5.m5.1.1" xref="S3.SS2.p3.5.m5.1.1.cmml"><msub id="S3.SS2.p3.5.m5.1.1.3" xref="S3.SS2.p3.5.m5.1.1.3.cmml"><mi id="S3.SS2.p3.5.m5.1.1.3.2" xref="S3.SS2.p3.5.m5.1.1.3.2.cmml">ğš</mi><mi id="S3.SS2.p3.5.m5.1.1.3.3" xref="S3.SS2.p3.5.m5.1.1.3.3.cmml">t</mi></msub><mo id="S3.SS2.p3.5.m5.1.1.2" xref="S3.SS2.p3.5.m5.1.1.2.cmml">âˆ¼</mo><mrow id="S3.SS2.p3.5.m5.1.1.1" xref="S3.SS2.p3.5.m5.1.1.1.cmml"><mi id="S3.SS2.p3.5.m5.1.1.1.3" xref="S3.SS2.p3.5.m5.1.1.1.3.cmml">Ï€</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.5.m5.1.1.1.2" xref="S3.SS2.p3.5.m5.1.1.1.2.cmml">â€‹</mo><mrow id="S3.SS2.p3.5.m5.1.1.1.1.1" xref="S3.SS2.p3.5.m5.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS2.p3.5.m5.1.1.1.1.1.2" xref="S3.SS2.p3.5.m5.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.p3.5.m5.1.1.1.1.1.1" xref="S3.SS2.p3.5.m5.1.1.1.1.1.1.cmml"><msub id="S3.SS2.p3.5.m5.1.1.1.1.1.1.2" xref="S3.SS2.p3.5.m5.1.1.1.1.1.1.2.cmml"><mi id="S3.SS2.p3.5.m5.1.1.1.1.1.1.2.2" xref="S3.SS2.p3.5.m5.1.1.1.1.1.1.2.2.cmml">ğ³</mi><mi id="S3.SS2.p3.5.m5.1.1.1.1.1.1.2.3" xref="S3.SS2.p3.5.m5.1.1.1.1.1.1.2.3.cmml">t</mi></msub><mo fence="false" id="S3.SS2.p3.5.m5.1.1.1.1.1.1.1" xref="S3.SS2.p3.5.m5.1.1.1.1.1.1.1.cmml">|</mo><msub id="S3.SS2.p3.5.m5.1.1.1.1.1.1.3" xref="S3.SS2.p3.5.m5.1.1.1.1.1.1.3.cmml"><mi id="S3.SS2.p3.5.m5.1.1.1.1.1.1.3.2" xref="S3.SS2.p3.5.m5.1.1.1.1.1.1.3.2.cmml">ğ¬</mi><mi id="S3.SS2.p3.5.m5.1.1.1.1.1.1.3.3" xref="S3.SS2.p3.5.m5.1.1.1.1.1.1.3.3.cmml">t</mi></msub></mrow><mo stretchy="false" id="S3.SS2.p3.5.m5.1.1.1.1.1.3" xref="S3.SS2.p3.5.m5.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.5.m5.1b"><apply id="S3.SS2.p3.5.m5.1.1.cmml" xref="S3.SS2.p3.5.m5.1.1"><csymbol cd="latexml" id="S3.SS2.p3.5.m5.1.1.2.cmml" xref="S3.SS2.p3.5.m5.1.1.2">similar-to</csymbol><apply id="S3.SS2.p3.5.m5.1.1.3.cmml" xref="S3.SS2.p3.5.m5.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p3.5.m5.1.1.3.1.cmml" xref="S3.SS2.p3.5.m5.1.1.3">subscript</csymbol><ci id="S3.SS2.p3.5.m5.1.1.3.2.cmml" xref="S3.SS2.p3.5.m5.1.1.3.2">ğš</ci><ci id="S3.SS2.p3.5.m5.1.1.3.3.cmml" xref="S3.SS2.p3.5.m5.1.1.3.3">ğ‘¡</ci></apply><apply id="S3.SS2.p3.5.m5.1.1.1.cmml" xref="S3.SS2.p3.5.m5.1.1.1"><times id="S3.SS2.p3.5.m5.1.1.1.2.cmml" xref="S3.SS2.p3.5.m5.1.1.1.2"></times><ci id="S3.SS2.p3.5.m5.1.1.1.3.cmml" xref="S3.SS2.p3.5.m5.1.1.1.3">ğœ‹</ci><apply id="S3.SS2.p3.5.m5.1.1.1.1.1.1.cmml" xref="S3.SS2.p3.5.m5.1.1.1.1.1"><csymbol cd="latexml" id="S3.SS2.p3.5.m5.1.1.1.1.1.1.1.cmml" xref="S3.SS2.p3.5.m5.1.1.1.1.1.1.1">conditional</csymbol><apply id="S3.SS2.p3.5.m5.1.1.1.1.1.1.2.cmml" xref="S3.SS2.p3.5.m5.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p3.5.m5.1.1.1.1.1.1.2.1.cmml" xref="S3.SS2.p3.5.m5.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.SS2.p3.5.m5.1.1.1.1.1.1.2.2.cmml" xref="S3.SS2.p3.5.m5.1.1.1.1.1.1.2.2">ğ³</ci><ci id="S3.SS2.p3.5.m5.1.1.1.1.1.1.2.3.cmml" xref="S3.SS2.p3.5.m5.1.1.1.1.1.1.2.3">ğ‘¡</ci></apply><apply id="S3.SS2.p3.5.m5.1.1.1.1.1.1.3.cmml" xref="S3.SS2.p3.5.m5.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p3.5.m5.1.1.1.1.1.1.3.1.cmml" xref="S3.SS2.p3.5.m5.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.SS2.p3.5.m5.1.1.1.1.1.1.3.2.cmml" xref="S3.SS2.p3.5.m5.1.1.1.1.1.1.3.2">ğ¬</ci><ci id="S3.SS2.p3.5.m5.1.1.1.1.1.1.3.3.cmml" xref="S3.SS2.p3.5.m5.1.1.1.1.1.1.3.3">ğ‘¡</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.5.m5.1c">\mathbf{a}_{t}\sim\pi(\mathbf{z}_{t}|\mathbf{s}_{t})</annotation></semantics></math> conditioned on the current state <math id="S3.SS2.p3.6.m6.1" class="ltx_Math" alttext="\mathbf{s}_{t}" display="inline"><semantics id="S3.SS2.p3.6.m6.1a"><msub id="S3.SS2.p3.6.m6.1.1" xref="S3.SS2.p3.6.m6.1.1.cmml"><mi id="S3.SS2.p3.6.m6.1.1.2" xref="S3.SS2.p3.6.m6.1.1.2.cmml">ğ¬</mi><mi id="S3.SS2.p3.6.m6.1.1.3" xref="S3.SS2.p3.6.m6.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.6.m6.1b"><apply id="S3.SS2.p3.6.m6.1.1.cmml" xref="S3.SS2.p3.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.6.m6.1.1.1.cmml" xref="S3.SS2.p3.6.m6.1.1">subscript</csymbol><ci id="S3.SS2.p3.6.m6.1.1.2.cmml" xref="S3.SS2.p3.6.m6.1.1.2">ğ¬</ci><ci id="S3.SS2.p3.6.m6.1.1.3.cmml" xref="S3.SS2.p3.6.m6.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.6.m6.1c">\mathbf{s}_{t}</annotation></semantics></math>, where <math id="S3.SS2.p3.7.m7.2" class="ltx_Math" alttext="\mathbf{z}_{t}\sim\mathcal{N}(\mathbf{\mu},\Sigma)" display="inline"><semantics id="S3.SS2.p3.7.m7.2a"><mrow id="S3.SS2.p3.7.m7.2.3" xref="S3.SS2.p3.7.m7.2.3.cmml"><msub id="S3.SS2.p3.7.m7.2.3.2" xref="S3.SS2.p3.7.m7.2.3.2.cmml"><mi id="S3.SS2.p3.7.m7.2.3.2.2" xref="S3.SS2.p3.7.m7.2.3.2.2.cmml">ğ³</mi><mi id="S3.SS2.p3.7.m7.2.3.2.3" xref="S3.SS2.p3.7.m7.2.3.2.3.cmml">t</mi></msub><mo id="S3.SS2.p3.7.m7.2.3.1" xref="S3.SS2.p3.7.m7.2.3.1.cmml">âˆ¼</mo><mrow id="S3.SS2.p3.7.m7.2.3.3" xref="S3.SS2.p3.7.m7.2.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p3.7.m7.2.3.3.2" xref="S3.SS2.p3.7.m7.2.3.3.2.cmml">ğ’©</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.7.m7.2.3.3.1" xref="S3.SS2.p3.7.m7.2.3.3.1.cmml">â€‹</mo><mrow id="S3.SS2.p3.7.m7.2.3.3.3.2" xref="S3.SS2.p3.7.m7.2.3.3.3.1.cmml"><mo stretchy="false" id="S3.SS2.p3.7.m7.2.3.3.3.2.1" xref="S3.SS2.p3.7.m7.2.3.3.3.1.cmml">(</mo><mi id="S3.SS2.p3.7.m7.1.1" xref="S3.SS2.p3.7.m7.1.1.cmml">Î¼</mi><mo id="S3.SS2.p3.7.m7.2.3.3.3.2.2" xref="S3.SS2.p3.7.m7.2.3.3.3.1.cmml">,</mo><mi mathvariant="normal" id="S3.SS2.p3.7.m7.2.2" xref="S3.SS2.p3.7.m7.2.2.cmml">Î£</mi><mo stretchy="false" id="S3.SS2.p3.7.m7.2.3.3.3.2.3" xref="S3.SS2.p3.7.m7.2.3.3.3.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.7.m7.2b"><apply id="S3.SS2.p3.7.m7.2.3.cmml" xref="S3.SS2.p3.7.m7.2.3"><csymbol cd="latexml" id="S3.SS2.p3.7.m7.2.3.1.cmml" xref="S3.SS2.p3.7.m7.2.3.1">similar-to</csymbol><apply id="S3.SS2.p3.7.m7.2.3.2.cmml" xref="S3.SS2.p3.7.m7.2.3.2"><csymbol cd="ambiguous" id="S3.SS2.p3.7.m7.2.3.2.1.cmml" xref="S3.SS2.p3.7.m7.2.3.2">subscript</csymbol><ci id="S3.SS2.p3.7.m7.2.3.2.2.cmml" xref="S3.SS2.p3.7.m7.2.3.2.2">ğ³</ci><ci id="S3.SS2.p3.7.m7.2.3.2.3.cmml" xref="S3.SS2.p3.7.m7.2.3.2.3">ğ‘¡</ci></apply><apply id="S3.SS2.p3.7.m7.2.3.3.cmml" xref="S3.SS2.p3.7.m7.2.3.3"><times id="S3.SS2.p3.7.m7.2.3.3.1.cmml" xref="S3.SS2.p3.7.m7.2.3.3.1"></times><ci id="S3.SS2.p3.7.m7.2.3.3.2.cmml" xref="S3.SS2.p3.7.m7.2.3.3.2">ğ’©</ci><interval closure="open" id="S3.SS2.p3.7.m7.2.3.3.3.1.cmml" xref="S3.SS2.p3.7.m7.2.3.3.3.2"><ci id="S3.SS2.p3.7.m7.1.1.cmml" xref="S3.SS2.p3.7.m7.1.1">ğœ‡</ci><ci id="S3.SS2.p3.7.m7.2.2.cmml" xref="S3.SS2.p3.7.m7.2.2">Î£</ci></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.7.m7.2c">\mathbf{z}_{t}\sim\mathcal{N}(\mathbf{\mu},\Sigma)</annotation></semantics></math>. <math id="S3.SS2.p3.8.m8.1" class="ltx_Math" alttext="\mathbf{\mu}" display="inline"><semantics id="S3.SS2.p3.8.m8.1a"><mi id="S3.SS2.p3.8.m8.1.1" xref="S3.SS2.p3.8.m8.1.1.cmml">Î¼</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.8.m8.1b"><ci id="S3.SS2.p3.8.m8.1.1.cmml" xref="S3.SS2.p3.8.m8.1.1">ğœ‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.8.m8.1c">\mathbf{\mu}</annotation></semantics></math> and <math id="S3.SS2.p3.9.m9.1" class="ltx_Math" alttext="\Sigma" display="inline"><semantics id="S3.SS2.p3.9.m9.1a"><mi mathvariant="normal" id="S3.SS2.p3.9.m9.1.1" xref="S3.SS2.p3.9.m9.1.1.cmml">Î£</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.9.m9.1b"><ci id="S3.SS2.p3.9.m9.1.1.cmml" xref="S3.SS2.p3.9.m9.1.1">Î£</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.9.m9.1c">\Sigma</annotation></semantics></math> are the mean and variance of the learned action space.</p>
</div>
<div id="S3.SS2.p4" class="ltx_para ltx_noindent">
<p id="S3.SS2.p4.4" class="ltx_p"><span id="S3.SS2.p4.4.1" class="ltx_text ltx_font_bold">Objective Function.</span> The objective function includes the policy surrogate <math id="S3.SS2.p4.1.m1.1" class="ltx_Math" alttext="L^{CLIP}" display="inline"><semantics id="S3.SS2.p4.1.m1.1a"><msup id="S3.SS2.p4.1.m1.1.1" xref="S3.SS2.p4.1.m1.1.1.cmml"><mi id="S3.SS2.p4.1.m1.1.1.2" xref="S3.SS2.p4.1.m1.1.1.2.cmml">L</mi><mrow id="S3.SS2.p4.1.m1.1.1.3" xref="S3.SS2.p4.1.m1.1.1.3.cmml"><mi id="S3.SS2.p4.1.m1.1.1.3.2" xref="S3.SS2.p4.1.m1.1.1.3.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p4.1.m1.1.1.3.1" xref="S3.SS2.p4.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.p4.1.m1.1.1.3.3" xref="S3.SS2.p4.1.m1.1.1.3.3.cmml">L</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p4.1.m1.1.1.3.1a" xref="S3.SS2.p4.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.p4.1.m1.1.1.3.4" xref="S3.SS2.p4.1.m1.1.1.3.4.cmml">I</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p4.1.m1.1.1.3.1b" xref="S3.SS2.p4.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.p4.1.m1.1.1.3.5" xref="S3.SS2.p4.1.m1.1.1.3.5.cmml">P</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.1.m1.1b"><apply id="S3.SS2.p4.1.m1.1.1.cmml" xref="S3.SS2.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.1.m1.1.1.1.cmml" xref="S3.SS2.p4.1.m1.1.1">superscript</csymbol><ci id="S3.SS2.p4.1.m1.1.1.2.cmml" xref="S3.SS2.p4.1.m1.1.1.2">ğ¿</ci><apply id="S3.SS2.p4.1.m1.1.1.3.cmml" xref="S3.SS2.p4.1.m1.1.1.3"><times id="S3.SS2.p4.1.m1.1.1.3.1.cmml" xref="S3.SS2.p4.1.m1.1.1.3.1"></times><ci id="S3.SS2.p4.1.m1.1.1.3.2.cmml" xref="S3.SS2.p4.1.m1.1.1.3.2">ğ¶</ci><ci id="S3.SS2.p4.1.m1.1.1.3.3.cmml" xref="S3.SS2.p4.1.m1.1.1.3.3">ğ¿</ci><ci id="S3.SS2.p4.1.m1.1.1.3.4.cmml" xref="S3.SS2.p4.1.m1.1.1.3.4">ğ¼</ci><ci id="S3.SS2.p4.1.m1.1.1.3.5.cmml" xref="S3.SS2.p4.1.m1.1.1.3.5">ğ‘ƒ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.1.m1.1c">L^{CLIP}</annotation></semantics></math>, the value function error term <math id="S3.SS2.p4.2.m2.1" class="ltx_Math" alttext="L^{VF}" display="inline"><semantics id="S3.SS2.p4.2.m2.1a"><msup id="S3.SS2.p4.2.m2.1.1" xref="S3.SS2.p4.2.m2.1.1.cmml"><mi id="S3.SS2.p4.2.m2.1.1.2" xref="S3.SS2.p4.2.m2.1.1.2.cmml">L</mi><mrow id="S3.SS2.p4.2.m2.1.1.3" xref="S3.SS2.p4.2.m2.1.1.3.cmml"><mi id="S3.SS2.p4.2.m2.1.1.3.2" xref="S3.SS2.p4.2.m2.1.1.3.2.cmml">V</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p4.2.m2.1.1.3.1" xref="S3.SS2.p4.2.m2.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.p4.2.m2.1.1.3.3" xref="S3.SS2.p4.2.m2.1.1.3.3.cmml">F</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.2.m2.1b"><apply id="S3.SS2.p4.2.m2.1.1.cmml" xref="S3.SS2.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.2.m2.1.1.1.cmml" xref="S3.SS2.p4.2.m2.1.1">superscript</csymbol><ci id="S3.SS2.p4.2.m2.1.1.2.cmml" xref="S3.SS2.p4.2.m2.1.1.2">ğ¿</ci><apply id="S3.SS2.p4.2.m2.1.1.3.cmml" xref="S3.SS2.p4.2.m2.1.1.3"><times id="S3.SS2.p4.2.m2.1.1.3.1.cmml" xref="S3.SS2.p4.2.m2.1.1.3.1"></times><ci id="S3.SS2.p4.2.m2.1.1.3.2.cmml" xref="S3.SS2.p4.2.m2.1.1.3.2">ğ‘‰</ci><ci id="S3.SS2.p4.2.m2.1.1.3.3.cmml" xref="S3.SS2.p4.2.m2.1.1.3.3">ğ¹</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.2.m2.1c">L^{VF}</annotation></semantics></math> to evaluate the value prediction <math id="S3.SS2.p4.3.m3.1" class="ltx_Math" alttext="V_{\theta}" display="inline"><semantics id="S3.SS2.p4.3.m3.1a"><msub id="S3.SS2.p4.3.m3.1.1" xref="S3.SS2.p4.3.m3.1.1.cmml"><mi id="S3.SS2.p4.3.m3.1.1.2" xref="S3.SS2.p4.3.m3.1.1.2.cmml">V</mi><mi id="S3.SS2.p4.3.m3.1.1.3" xref="S3.SS2.p4.3.m3.1.1.3.cmml">Î¸</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.3.m3.1b"><apply id="S3.SS2.p4.3.m3.1.1.cmml" xref="S3.SS2.p4.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.3.m3.1.1.1.cmml" xref="S3.SS2.p4.3.m3.1.1">subscript</csymbol><ci id="S3.SS2.p4.3.m3.1.1.2.cmml" xref="S3.SS2.p4.3.m3.1.1.2">ğ‘‰</ci><ci id="S3.SS2.p4.3.m3.1.1.3.cmml" xref="S3.SS2.p4.3.m3.1.1.3">ğœƒ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.3.m3.1c">V_{\theta}</annotation></semantics></math>, and an entropy bonus <math id="S3.SS2.p4.4.m4.1" class="ltx_Math" alttext="L^{S}" display="inline"><semantics id="S3.SS2.p4.4.m4.1a"><msup id="S3.SS2.p4.4.m4.1.1" xref="S3.SS2.p4.4.m4.1.1.cmml"><mi id="S3.SS2.p4.4.m4.1.1.2" xref="S3.SS2.p4.4.m4.1.1.2.cmml">L</mi><mi id="S3.SS2.p4.4.m4.1.1.3" xref="S3.SS2.p4.4.m4.1.1.3.cmml">S</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.4.m4.1b"><apply id="S3.SS2.p4.4.m4.1.1.cmml" xref="S3.SS2.p4.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.4.m4.1.1.1.cmml" xref="S3.SS2.p4.4.m4.1.1">superscript</csymbol><ci id="S3.SS2.p4.4.m4.1.1.2.cmml" xref="S3.SS2.p4.4.m4.1.1.2">ğ¿</ci><ci id="S3.SS2.p4.4.m4.1.1.3.cmml" xref="S3.SS2.p4.4.m4.1.1.3">ğ‘†</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.4.m4.1c">L^{S}</annotation></semantics></math> to encourage exploration:</p>
<table id="S5.EGx2" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S3.Ex3"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.Ex3.m1.1" class="ltx_Math" alttext="\displaystyle L=L^{CLIP}+c_{1}L^{VF}+c_{2}L^{S}" display="inline"><semantics id="S3.Ex3.m1.1a"><mrow id="S3.Ex3.m1.1.1" xref="S3.Ex3.m1.1.1.cmml"><mi id="S3.Ex3.m1.1.1.2" xref="S3.Ex3.m1.1.1.2.cmml">L</mi><mo id="S3.Ex3.m1.1.1.1" xref="S3.Ex3.m1.1.1.1.cmml">=</mo><mrow id="S3.Ex3.m1.1.1.3" xref="S3.Ex3.m1.1.1.3.cmml"><msup id="S3.Ex3.m1.1.1.3.2" xref="S3.Ex3.m1.1.1.3.2.cmml"><mi id="S3.Ex3.m1.1.1.3.2.2" xref="S3.Ex3.m1.1.1.3.2.2.cmml">L</mi><mrow id="S3.Ex3.m1.1.1.3.2.3" xref="S3.Ex3.m1.1.1.3.2.3.cmml"><mi id="S3.Ex3.m1.1.1.3.2.3.2" xref="S3.Ex3.m1.1.1.3.2.3.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.Ex3.m1.1.1.3.2.3.1" xref="S3.Ex3.m1.1.1.3.2.3.1.cmml">â€‹</mo><mi id="S3.Ex3.m1.1.1.3.2.3.3" xref="S3.Ex3.m1.1.1.3.2.3.3.cmml">L</mi><mo lspace="0em" rspace="0em" id="S3.Ex3.m1.1.1.3.2.3.1a" xref="S3.Ex3.m1.1.1.3.2.3.1.cmml">â€‹</mo><mi id="S3.Ex3.m1.1.1.3.2.3.4" xref="S3.Ex3.m1.1.1.3.2.3.4.cmml">I</mi><mo lspace="0em" rspace="0em" id="S3.Ex3.m1.1.1.3.2.3.1b" xref="S3.Ex3.m1.1.1.3.2.3.1.cmml">â€‹</mo><mi id="S3.Ex3.m1.1.1.3.2.3.5" xref="S3.Ex3.m1.1.1.3.2.3.5.cmml">P</mi></mrow></msup><mo id="S3.Ex3.m1.1.1.3.1" xref="S3.Ex3.m1.1.1.3.1.cmml">+</mo><mrow id="S3.Ex3.m1.1.1.3.3" xref="S3.Ex3.m1.1.1.3.3.cmml"><msub id="S3.Ex3.m1.1.1.3.3.2" xref="S3.Ex3.m1.1.1.3.3.2.cmml"><mi id="S3.Ex3.m1.1.1.3.3.2.2" xref="S3.Ex3.m1.1.1.3.3.2.2.cmml">c</mi><mn id="S3.Ex3.m1.1.1.3.3.2.3" xref="S3.Ex3.m1.1.1.3.3.2.3.cmml">1</mn></msub><mo lspace="0em" rspace="0em" id="S3.Ex3.m1.1.1.3.3.1" xref="S3.Ex3.m1.1.1.3.3.1.cmml">â€‹</mo><msup id="S3.Ex3.m1.1.1.3.3.3" xref="S3.Ex3.m1.1.1.3.3.3.cmml"><mi id="S3.Ex3.m1.1.1.3.3.3.2" xref="S3.Ex3.m1.1.1.3.3.3.2.cmml">L</mi><mrow id="S3.Ex3.m1.1.1.3.3.3.3" xref="S3.Ex3.m1.1.1.3.3.3.3.cmml"><mi id="S3.Ex3.m1.1.1.3.3.3.3.2" xref="S3.Ex3.m1.1.1.3.3.3.3.2.cmml">V</mi><mo lspace="0em" rspace="0em" id="S3.Ex3.m1.1.1.3.3.3.3.1" xref="S3.Ex3.m1.1.1.3.3.3.3.1.cmml">â€‹</mo><mi id="S3.Ex3.m1.1.1.3.3.3.3.3" xref="S3.Ex3.m1.1.1.3.3.3.3.3.cmml">F</mi></mrow></msup></mrow><mo id="S3.Ex3.m1.1.1.3.1a" xref="S3.Ex3.m1.1.1.3.1.cmml">+</mo><mrow id="S3.Ex3.m1.1.1.3.4" xref="S3.Ex3.m1.1.1.3.4.cmml"><msub id="S3.Ex3.m1.1.1.3.4.2" xref="S3.Ex3.m1.1.1.3.4.2.cmml"><mi id="S3.Ex3.m1.1.1.3.4.2.2" xref="S3.Ex3.m1.1.1.3.4.2.2.cmml">c</mi><mn id="S3.Ex3.m1.1.1.3.4.2.3" xref="S3.Ex3.m1.1.1.3.4.2.3.cmml">2</mn></msub><mo lspace="0em" rspace="0em" id="S3.Ex3.m1.1.1.3.4.1" xref="S3.Ex3.m1.1.1.3.4.1.cmml">â€‹</mo><msup id="S3.Ex3.m1.1.1.3.4.3" xref="S3.Ex3.m1.1.1.3.4.3.cmml"><mi id="S3.Ex3.m1.1.1.3.4.3.2" xref="S3.Ex3.m1.1.1.3.4.3.2.cmml">L</mi><mi id="S3.Ex3.m1.1.1.3.4.3.3" xref="S3.Ex3.m1.1.1.3.4.3.3.cmml">S</mi></msup></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex3.m1.1b"><apply id="S3.Ex3.m1.1.1.cmml" xref="S3.Ex3.m1.1.1"><eq id="S3.Ex3.m1.1.1.1.cmml" xref="S3.Ex3.m1.1.1.1"></eq><ci id="S3.Ex3.m1.1.1.2.cmml" xref="S3.Ex3.m1.1.1.2">ğ¿</ci><apply id="S3.Ex3.m1.1.1.3.cmml" xref="S3.Ex3.m1.1.1.3"><plus id="S3.Ex3.m1.1.1.3.1.cmml" xref="S3.Ex3.m1.1.1.3.1"></plus><apply id="S3.Ex3.m1.1.1.3.2.cmml" xref="S3.Ex3.m1.1.1.3.2"><csymbol cd="ambiguous" id="S3.Ex3.m1.1.1.3.2.1.cmml" xref="S3.Ex3.m1.1.1.3.2">superscript</csymbol><ci id="S3.Ex3.m1.1.1.3.2.2.cmml" xref="S3.Ex3.m1.1.1.3.2.2">ğ¿</ci><apply id="S3.Ex3.m1.1.1.3.2.3.cmml" xref="S3.Ex3.m1.1.1.3.2.3"><times id="S3.Ex3.m1.1.1.3.2.3.1.cmml" xref="S3.Ex3.m1.1.1.3.2.3.1"></times><ci id="S3.Ex3.m1.1.1.3.2.3.2.cmml" xref="S3.Ex3.m1.1.1.3.2.3.2">ğ¶</ci><ci id="S3.Ex3.m1.1.1.3.2.3.3.cmml" xref="S3.Ex3.m1.1.1.3.2.3.3">ğ¿</ci><ci id="S3.Ex3.m1.1.1.3.2.3.4.cmml" xref="S3.Ex3.m1.1.1.3.2.3.4">ğ¼</ci><ci id="S3.Ex3.m1.1.1.3.2.3.5.cmml" xref="S3.Ex3.m1.1.1.3.2.3.5">ğ‘ƒ</ci></apply></apply><apply id="S3.Ex3.m1.1.1.3.3.cmml" xref="S3.Ex3.m1.1.1.3.3"><times id="S3.Ex3.m1.1.1.3.3.1.cmml" xref="S3.Ex3.m1.1.1.3.3.1"></times><apply id="S3.Ex3.m1.1.1.3.3.2.cmml" xref="S3.Ex3.m1.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.Ex3.m1.1.1.3.3.2.1.cmml" xref="S3.Ex3.m1.1.1.3.3.2">subscript</csymbol><ci id="S3.Ex3.m1.1.1.3.3.2.2.cmml" xref="S3.Ex3.m1.1.1.3.3.2.2">ğ‘</ci><cn type="integer" id="S3.Ex3.m1.1.1.3.3.2.3.cmml" xref="S3.Ex3.m1.1.1.3.3.2.3">1</cn></apply><apply id="S3.Ex3.m1.1.1.3.3.3.cmml" xref="S3.Ex3.m1.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.Ex3.m1.1.1.3.3.3.1.cmml" xref="S3.Ex3.m1.1.1.3.3.3">superscript</csymbol><ci id="S3.Ex3.m1.1.1.3.3.3.2.cmml" xref="S3.Ex3.m1.1.1.3.3.3.2">ğ¿</ci><apply id="S3.Ex3.m1.1.1.3.3.3.3.cmml" xref="S3.Ex3.m1.1.1.3.3.3.3"><times id="S3.Ex3.m1.1.1.3.3.3.3.1.cmml" xref="S3.Ex3.m1.1.1.3.3.3.3.1"></times><ci id="S3.Ex3.m1.1.1.3.3.3.3.2.cmml" xref="S3.Ex3.m1.1.1.3.3.3.3.2">ğ‘‰</ci><ci id="S3.Ex3.m1.1.1.3.3.3.3.3.cmml" xref="S3.Ex3.m1.1.1.3.3.3.3.3">ğ¹</ci></apply></apply></apply><apply id="S3.Ex3.m1.1.1.3.4.cmml" xref="S3.Ex3.m1.1.1.3.4"><times id="S3.Ex3.m1.1.1.3.4.1.cmml" xref="S3.Ex3.m1.1.1.3.4.1"></times><apply id="S3.Ex3.m1.1.1.3.4.2.cmml" xref="S3.Ex3.m1.1.1.3.4.2"><csymbol cd="ambiguous" id="S3.Ex3.m1.1.1.3.4.2.1.cmml" xref="S3.Ex3.m1.1.1.3.4.2">subscript</csymbol><ci id="S3.Ex3.m1.1.1.3.4.2.2.cmml" xref="S3.Ex3.m1.1.1.3.4.2.2">ğ‘</ci><cn type="integer" id="S3.Ex3.m1.1.1.3.4.2.3.cmml" xref="S3.Ex3.m1.1.1.3.4.2.3">2</cn></apply><apply id="S3.Ex3.m1.1.1.3.4.3.cmml" xref="S3.Ex3.m1.1.1.3.4.3"><csymbol cd="ambiguous" id="S3.Ex3.m1.1.1.3.4.3.1.cmml" xref="S3.Ex3.m1.1.1.3.4.3">superscript</csymbol><ci id="S3.Ex3.m1.1.1.3.4.3.2.cmml" xref="S3.Ex3.m1.1.1.3.4.3.2">ğ¿</ci><ci id="S3.Ex3.m1.1.1.3.4.3.3.cmml" xref="S3.Ex3.m1.1.1.3.4.3.3">ğ‘†</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex3.m1.1c">\displaystyle L=L^{CLIP}+c_{1}L^{VF}+c_{2}L^{S}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S3.SS2.p4.7" class="ltx_p">where <math id="S3.SS2.p4.5.m1.2" class="ltx_Math" alttext="c_{1},c_{2}" display="inline"><semantics id="S3.SS2.p4.5.m1.2a"><mrow id="S3.SS2.p4.5.m1.2.2.2" xref="S3.SS2.p4.5.m1.2.2.3.cmml"><msub id="S3.SS2.p4.5.m1.1.1.1.1" xref="S3.SS2.p4.5.m1.1.1.1.1.cmml"><mi id="S3.SS2.p4.5.m1.1.1.1.1.2" xref="S3.SS2.p4.5.m1.1.1.1.1.2.cmml">c</mi><mn id="S3.SS2.p4.5.m1.1.1.1.1.3" xref="S3.SS2.p4.5.m1.1.1.1.1.3.cmml">1</mn></msub><mo id="S3.SS2.p4.5.m1.2.2.2.3" xref="S3.SS2.p4.5.m1.2.2.3.cmml">,</mo><msub id="S3.SS2.p4.5.m1.2.2.2.2" xref="S3.SS2.p4.5.m1.2.2.2.2.cmml"><mi id="S3.SS2.p4.5.m1.2.2.2.2.2" xref="S3.SS2.p4.5.m1.2.2.2.2.2.cmml">c</mi><mn id="S3.SS2.p4.5.m1.2.2.2.2.3" xref="S3.SS2.p4.5.m1.2.2.2.2.3.cmml">2</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.5.m1.2b"><list id="S3.SS2.p4.5.m1.2.2.3.cmml" xref="S3.SS2.p4.5.m1.2.2.2"><apply id="S3.SS2.p4.5.m1.1.1.1.1.cmml" xref="S3.SS2.p4.5.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.5.m1.1.1.1.1.1.cmml" xref="S3.SS2.p4.5.m1.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p4.5.m1.1.1.1.1.2.cmml" xref="S3.SS2.p4.5.m1.1.1.1.1.2">ğ‘</ci><cn type="integer" id="S3.SS2.p4.5.m1.1.1.1.1.3.cmml" xref="S3.SS2.p4.5.m1.1.1.1.1.3">1</cn></apply><apply id="S3.SS2.p4.5.m1.2.2.2.2.cmml" xref="S3.SS2.p4.5.m1.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p4.5.m1.2.2.2.2.1.cmml" xref="S3.SS2.p4.5.m1.2.2.2.2">subscript</csymbol><ci id="S3.SS2.p4.5.m1.2.2.2.2.2.cmml" xref="S3.SS2.p4.5.m1.2.2.2.2.2">ğ‘</ci><cn type="integer" id="S3.SS2.p4.5.m1.2.2.2.2.3.cmml" xref="S3.SS2.p4.5.m1.2.2.2.2.3">2</cn></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.5.m1.2c">c_{1},c_{2}</annotation></semantics></math> are coefficients. See more details in <a href="#S2.SS3" title="S2.3 PPO â€£ S2 Ego-Sensing Driven Motion Synthesis â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Sec.</span>Â <span class="ltx_text ltx_ref_tag">S2.3</span></a>.
<span id="S3.SS2.p4.7.1" class="ltx_text ltx_font_bold">RL Pre-training and Finetuning.</span> Training in crowded scenes, e.g.Â Replica <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib99" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">99</span></a>]</cite>, requires additional steps.
Because the action space <math id="S3.SS2.p4.6.m2.1" class="ltx_Math" alttext="\mathcal{A}" display="inline"><semantics id="S3.SS2.p4.6.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p4.6.m2.1.1" xref="S3.SS2.p4.6.m2.1.1.cmml">ğ’œ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.6.m2.1b"><ci id="S3.SS2.p4.6.m2.1.1.cmml" xref="S3.SS2.p4.6.m2.1.1">ğ’œ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.6.m2.1c">\mathcal{A}</annotation></semantics></math>
is an unbounded Gaussian, RL exploration while predicting reasonable human poses can be challenging.
We first pretrain the policy with a higher <math id="S3.SS2.p4.7.m3.1" class="ltx_Math" alttext="r_{pene}" display="inline"><semantics id="S3.SS2.p4.7.m3.1a"><msub id="S3.SS2.p4.7.m3.1.1" xref="S3.SS2.p4.7.m3.1.1.cmml"><mi id="S3.SS2.p4.7.m3.1.1.2" xref="S3.SS2.p4.7.m3.1.1.2.cmml">r</mi><mrow id="S3.SS2.p4.7.m3.1.1.3" xref="S3.SS2.p4.7.m3.1.1.3.cmml"><mi id="S3.SS2.p4.7.m3.1.1.3.2" xref="S3.SS2.p4.7.m3.1.1.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p4.7.m3.1.1.3.1" xref="S3.SS2.p4.7.m3.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.p4.7.m3.1.1.3.3" xref="S3.SS2.p4.7.m3.1.1.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p4.7.m3.1.1.3.1a" xref="S3.SS2.p4.7.m3.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.p4.7.m3.1.1.3.4" xref="S3.SS2.p4.7.m3.1.1.3.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p4.7.m3.1.1.3.1b" xref="S3.SS2.p4.7.m3.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.p4.7.m3.1.1.3.5" xref="S3.SS2.p4.7.m3.1.1.3.5.cmml">e</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.7.m3.1b"><apply id="S3.SS2.p4.7.m3.1.1.cmml" xref="S3.SS2.p4.7.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.7.m3.1.1.1.cmml" xref="S3.SS2.p4.7.m3.1.1">subscript</csymbol><ci id="S3.SS2.p4.7.m3.1.1.2.cmml" xref="S3.SS2.p4.7.m3.1.1.2">ğ‘Ÿ</ci><apply id="S3.SS2.p4.7.m3.1.1.3.cmml" xref="S3.SS2.p4.7.m3.1.1.3"><times id="S3.SS2.p4.7.m3.1.1.3.1.cmml" xref="S3.SS2.p4.7.m3.1.1.3.1"></times><ci id="S3.SS2.p4.7.m3.1.1.3.2.cmml" xref="S3.SS2.p4.7.m3.1.1.3.2">ğ‘</ci><ci id="S3.SS2.p4.7.m3.1.1.3.3.cmml" xref="S3.SS2.p4.7.m3.1.1.3.3">ğ‘’</ci><ci id="S3.SS2.p4.7.m3.1.1.3.4.cmml" xref="S3.SS2.p4.7.m3.1.1.3.4">ğ‘›</ci><ci id="S3.SS2.p4.7.m3.1.1.3.5.cmml" xref="S3.SS2.p4.7.m3.1.1.3.5">ğ‘’</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.7.m3.1c">r_{pene}</annotation></semantics></math> weight without <span id="S3.SS2.p4.7.2" class="ltx_text ltx_font_italic">penetration termination</span>. After convergence, we finetune it with strict termination constraints using a signed distance field (SDF) for penetration detection. Please refer to <a href="#S2.SS2" title="S2.2 Reward, Weighting, and Training Detail â€£ S2 Ego-Sensing Driven Motion Synthesis â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Sec.</span>Â <span class="ltx_text ltx_ref_tag">S2.2</span></a> for the formulation and weighting of each reward and training detail.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Compositing Learned Motion Primitives</h3>

<figure id="alg1" class="ltx_float ltx_float_algorithm ltx_framed ltx_framed_top">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span id="alg1.2.1.1" class="ltx_text ltx_font_bold">Algorithm 1</span> </span> Crowd motion synthesis with learned CAMPs</figcaption>
<div id="alg1.3" class="ltx_listing ltx_listing">
<div id="alg1.l1" class="ltx_listingline">
<span id="alg1.l1.1" class="ltx_text ltx_font_bold">Result:</span> Multi-human locomotion w/ collision avoidance;

</div>
<div id="alg1.l2" class="ltx_listingline">
<span id="alg1.l2.1" class="ltx_text ltx_font_bold">Init:</span> crowd size <math id="alg1.l2.m1.1" class="ltx_Math" alttext="C" display="inline"><semantics id="alg1.l2.m1.1a"><mi id="alg1.l2.m1.1.1" xref="alg1.l2.m1.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="alg1.l2.m1.1b"><ci id="alg1.l2.m1.1.1.cmml" xref="alg1.l2.m1.1.1">ğ¶</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l2.m1.1c">C</annotation></semantics></math>, marker seed for each human <math id="alg1.l2.m2.1" class="ltx_Math" alttext="\mathbf{X}^{S}_{c}" display="inline"><semantics id="alg1.l2.m2.1a"><msubsup id="alg1.l2.m2.1.1" xref="alg1.l2.m2.1.1.cmml"><mi id="alg1.l2.m2.1.1.2.2" xref="alg1.l2.m2.1.1.2.2.cmml">ğ—</mi><mi id="alg1.l2.m2.1.1.3" xref="alg1.l2.m2.1.1.3.cmml">c</mi><mi id="alg1.l2.m2.1.1.2.3" xref="alg1.l2.m2.1.1.2.3.cmml">S</mi></msubsup><annotation-xml encoding="MathML-Content" id="alg1.l2.m2.1b"><apply id="alg1.l2.m2.1.1.cmml" xref="alg1.l2.m2.1.1"><csymbol cd="ambiguous" id="alg1.l2.m2.1.1.1.cmml" xref="alg1.l2.m2.1.1">subscript</csymbol><apply id="alg1.l2.m2.1.1.2.cmml" xref="alg1.l2.m2.1.1"><csymbol cd="ambiguous" id="alg1.l2.m2.1.1.2.1.cmml" xref="alg1.l2.m2.1.1">superscript</csymbol><ci id="alg1.l2.m2.1.1.2.2.cmml" xref="alg1.l2.m2.1.1.2.2">ğ—</ci><ci id="alg1.l2.m2.1.1.2.3.cmml" xref="alg1.l2.m2.1.1.2.3">ğ‘†</ci></apply><ci id="alg1.l2.m2.1.1.3.cmml" xref="alg1.l2.m2.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l2.m2.1c">\mathbf{X}^{S}_{c}</annotation></semantics></math>; 
</div>
<div id="alg1.l3" class="ltx_listingline">
<span id="alg1.l3.2" class="ltx_text ltx_font_bold">for</span>Â <math id="alg1.l3.m1.1" class="ltx_Math" alttext="step\leftarrow 1" display="inline"><semantics id="alg1.l3.m1.1a"><mrow id="alg1.l3.m1.1.1" xref="alg1.l3.m1.1.1.cmml"><mrow id="alg1.l3.m1.1.1.2" xref="alg1.l3.m1.1.1.2.cmml"><mi id="alg1.l3.m1.1.1.2.2" xref="alg1.l3.m1.1.1.2.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="alg1.l3.m1.1.1.2.1" xref="alg1.l3.m1.1.1.2.1.cmml">â€‹</mo><mi id="alg1.l3.m1.1.1.2.3" xref="alg1.l3.m1.1.1.2.3.cmml">t</mi><mo lspace="0em" rspace="0em" id="alg1.l3.m1.1.1.2.1a" xref="alg1.l3.m1.1.1.2.1.cmml">â€‹</mo><mi id="alg1.l3.m1.1.1.2.4" xref="alg1.l3.m1.1.1.2.4.cmml">e</mi><mo lspace="0em" rspace="0em" id="alg1.l3.m1.1.1.2.1b" xref="alg1.l3.m1.1.1.2.1.cmml">â€‹</mo><mi id="alg1.l3.m1.1.1.2.5" xref="alg1.l3.m1.1.1.2.5.cmml">p</mi></mrow><mo stretchy="false" id="alg1.l3.m1.1.1.1" xref="alg1.l3.m1.1.1.1.cmml">â†</mo><mn id="alg1.l3.m1.1.1.3" xref="alg1.l3.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="alg1.l3.m1.1b"><apply id="alg1.l3.m1.1.1.cmml" xref="alg1.l3.m1.1.1"><ci id="alg1.l3.m1.1.1.1.cmml" xref="alg1.l3.m1.1.1.1">â†</ci><apply id="alg1.l3.m1.1.1.2.cmml" xref="alg1.l3.m1.1.1.2"><times id="alg1.l3.m1.1.1.2.1.cmml" xref="alg1.l3.m1.1.1.2.1"></times><ci id="alg1.l3.m1.1.1.2.2.cmml" xref="alg1.l3.m1.1.1.2.2">ğ‘ </ci><ci id="alg1.l3.m1.1.1.2.3.cmml" xref="alg1.l3.m1.1.1.2.3">ğ‘¡</ci><ci id="alg1.l3.m1.1.1.2.4.cmml" xref="alg1.l3.m1.1.1.2.4">ğ‘’</ci><ci id="alg1.l3.m1.1.1.2.5.cmml" xref="alg1.l3.m1.1.1.2.5">ğ‘</ci></apply><cn type="integer" id="alg1.l3.m1.1.1.3.cmml" xref="alg1.l3.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l3.m1.1c">step\leftarrow 1</annotation></semantics></math> <span id="alg1.l3.3" class="ltx_text ltx_font_bold">to</span> <math id="alg1.l3.m2.1" class="ltx_Math" alttext="max\_steps" display="inline"><semantics id="alg1.l3.m2.1a"><mrow id="alg1.l3.m2.1.1" xref="alg1.l3.m2.1.1.cmml"><mi id="alg1.l3.m2.1.1.2" xref="alg1.l3.m2.1.1.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="alg1.l3.m2.1.1.1" xref="alg1.l3.m2.1.1.1.cmml">â€‹</mo><mi id="alg1.l3.m2.1.1.3" xref="alg1.l3.m2.1.1.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="alg1.l3.m2.1.1.1a" xref="alg1.l3.m2.1.1.1.cmml">â€‹</mo><mi id="alg1.l3.m2.1.1.4" xref="alg1.l3.m2.1.1.4.cmml">x</mi><mo lspace="0em" rspace="0em" id="alg1.l3.m2.1.1.1b" xref="alg1.l3.m2.1.1.1.cmml">â€‹</mo><mi mathvariant="normal" id="alg1.l3.m2.1.1.5" xref="alg1.l3.m2.1.1.5.cmml">_</mi><mo lspace="0em" rspace="0em" id="alg1.l3.m2.1.1.1c" xref="alg1.l3.m2.1.1.1.cmml">â€‹</mo><mi id="alg1.l3.m2.1.1.6" xref="alg1.l3.m2.1.1.6.cmml">s</mi><mo lspace="0em" rspace="0em" id="alg1.l3.m2.1.1.1d" xref="alg1.l3.m2.1.1.1.cmml">â€‹</mo><mi id="alg1.l3.m2.1.1.7" xref="alg1.l3.m2.1.1.7.cmml">t</mi><mo lspace="0em" rspace="0em" id="alg1.l3.m2.1.1.1e" xref="alg1.l3.m2.1.1.1.cmml">â€‹</mo><mi id="alg1.l3.m2.1.1.8" xref="alg1.l3.m2.1.1.8.cmml">e</mi><mo lspace="0em" rspace="0em" id="alg1.l3.m2.1.1.1f" xref="alg1.l3.m2.1.1.1.cmml">â€‹</mo><mi id="alg1.l3.m2.1.1.9" xref="alg1.l3.m2.1.1.9.cmml">p</mi><mo lspace="0em" rspace="0em" id="alg1.l3.m2.1.1.1g" xref="alg1.l3.m2.1.1.1.cmml">â€‹</mo><mi id="alg1.l3.m2.1.1.10" xref="alg1.l3.m2.1.1.10.cmml">s</mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.l3.m2.1b"><apply id="alg1.l3.m2.1.1.cmml" xref="alg1.l3.m2.1.1"><times id="alg1.l3.m2.1.1.1.cmml" xref="alg1.l3.m2.1.1.1"></times><ci id="alg1.l3.m2.1.1.2.cmml" xref="alg1.l3.m2.1.1.2">ğ‘š</ci><ci id="alg1.l3.m2.1.1.3.cmml" xref="alg1.l3.m2.1.1.3">ğ‘</ci><ci id="alg1.l3.m2.1.1.4.cmml" xref="alg1.l3.m2.1.1.4">ğ‘¥</ci><ci id="alg1.l3.m2.1.1.5.cmml" xref="alg1.l3.m2.1.1.5">_</ci><ci id="alg1.l3.m2.1.1.6.cmml" xref="alg1.l3.m2.1.1.6">ğ‘ </ci><ci id="alg1.l3.m2.1.1.7.cmml" xref="alg1.l3.m2.1.1.7">ğ‘¡</ci><ci id="alg1.l3.m2.1.1.8.cmml" xref="alg1.l3.m2.1.1.8">ğ‘’</ci><ci id="alg1.l3.m2.1.1.9.cmml" xref="alg1.l3.m2.1.1.9">ğ‘</ci><ci id="alg1.l3.m2.1.1.10.cmml" xref="alg1.l3.m2.1.1.10">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l3.m2.1c">max\_steps</annotation></semantics></math>Â <span id="alg1.l3.4" class="ltx_text ltx_font_bold">do</span> <span id="alg1.l3.1" class="ltx_text" style="float:right;"><math id="alg1.l3.1.m1.1" class="ltx_Math" alttext="\triangleright" display="inline"><semantics id="alg1.l3.1.m1.1a"><mo id="alg1.l3.1.m1.1.1" xref="alg1.l3.1.m1.1.1.cmml">â–·</mo><annotation-xml encoding="MathML-Content" id="alg1.l3.1.m1.1b"><ci id="alg1.l3.1.m1.1.1.cmml" xref="alg1.l3.1.m1.1.1">â–·</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l3.1.m1.1c">\triangleright</annotation></semantics></math> env. finite horizon
</span>
</div>
<div id="alg1.l4" class="ltx_listingline">Â Â Â Â Â <span id="alg1.l4.2" class="ltx_text ltx_font_bold">for</span>Â <math id="alg1.l4.m1.1" class="ltx_Math" alttext="c\leftarrow 1" display="inline"><semantics id="alg1.l4.m1.1a"><mrow id="alg1.l4.m1.1.1" xref="alg1.l4.m1.1.1.cmml"><mi id="alg1.l4.m1.1.1.2" xref="alg1.l4.m1.1.1.2.cmml">c</mi><mo stretchy="false" id="alg1.l4.m1.1.1.1" xref="alg1.l4.m1.1.1.1.cmml">â†</mo><mn id="alg1.l4.m1.1.1.3" xref="alg1.l4.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="alg1.l4.m1.1b"><apply id="alg1.l4.m1.1.1.cmml" xref="alg1.l4.m1.1.1"><ci id="alg1.l4.m1.1.1.1.cmml" xref="alg1.l4.m1.1.1.1">â†</ci><ci id="alg1.l4.m1.1.1.2.cmml" xref="alg1.l4.m1.1.1.2">ğ‘</ci><cn type="integer" id="alg1.l4.m1.1.1.3.cmml" xref="alg1.l4.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l4.m1.1c">c\leftarrow 1</annotation></semantics></math> <span id="alg1.l4.3" class="ltx_text ltx_font_bold">to</span> <math id="alg1.l4.m2.1" class="ltx_Math" alttext="C" display="inline"><semantics id="alg1.l4.m2.1a"><mi id="alg1.l4.m2.1.1" xref="alg1.l4.m2.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="alg1.l4.m2.1b"><ci id="alg1.l4.m2.1.1.cmml" xref="alg1.l4.m2.1.1">ğ¶</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l4.m2.1c">C</annotation></semantics></math>Â <span id="alg1.l4.4" class="ltx_text ltx_font_bold">do</span> <span id="alg1.l4.1" class="ltx_text" style="float:right;"><math id="alg1.l4.1.m1.1" class="ltx_Math" alttext="\triangleright" display="inline"><semantics id="alg1.l4.1.m1.1a"><mo id="alg1.l4.1.m1.1.1" xref="alg1.l4.1.m1.1.1.cmml">â–·</mo><annotation-xml encoding="MathML-Content" id="alg1.l4.1.m1.1b"><ci id="alg1.l4.1.m1.1.1.cmml" xref="alg1.l4.1.m1.1.1">â–·</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l4.1.m1.1c">\triangleright</annotation></semantics></math> for each human
</span>
</div>
<div id="alg1.l5" class="ltx_listingline">Â Â Â Â Â Â Â Â Â update all locations with <math id="alg1.l5.m1.1" class="ltx_Math" alttext="\{bbox(\mathbf{X}^{S}_{c})\}_{c=1:C}" display="inline"><semantics id="alg1.l5.m1.1a"><msub id="alg1.l5.m1.1.1" xref="alg1.l5.m1.1.1.cmml"><mrow id="alg1.l5.m1.1.1.1.1" xref="alg1.l5.m1.1.1.1.2.cmml"><mo stretchy="false" id="alg1.l5.m1.1.1.1.1.2" xref="alg1.l5.m1.1.1.1.2.cmml">{</mo><mrow id="alg1.l5.m1.1.1.1.1.1" xref="alg1.l5.m1.1.1.1.1.1.cmml"><mi id="alg1.l5.m1.1.1.1.1.1.3" xref="alg1.l5.m1.1.1.1.1.1.3.cmml">b</mi><mo lspace="0em" rspace="0em" id="alg1.l5.m1.1.1.1.1.1.2" xref="alg1.l5.m1.1.1.1.1.1.2.cmml">â€‹</mo><mi id="alg1.l5.m1.1.1.1.1.1.4" xref="alg1.l5.m1.1.1.1.1.1.4.cmml">b</mi><mo lspace="0em" rspace="0em" id="alg1.l5.m1.1.1.1.1.1.2a" xref="alg1.l5.m1.1.1.1.1.1.2.cmml">â€‹</mo><mi id="alg1.l5.m1.1.1.1.1.1.5" xref="alg1.l5.m1.1.1.1.1.1.5.cmml">o</mi><mo lspace="0em" rspace="0em" id="alg1.l5.m1.1.1.1.1.1.2b" xref="alg1.l5.m1.1.1.1.1.1.2.cmml">â€‹</mo><mi id="alg1.l5.m1.1.1.1.1.1.6" xref="alg1.l5.m1.1.1.1.1.1.6.cmml">x</mi><mo lspace="0em" rspace="0em" id="alg1.l5.m1.1.1.1.1.1.2c" xref="alg1.l5.m1.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="alg1.l5.m1.1.1.1.1.1.1.1" xref="alg1.l5.m1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="alg1.l5.m1.1.1.1.1.1.1.1.2" xref="alg1.l5.m1.1.1.1.1.1.1.1.1.cmml">(</mo><msubsup id="alg1.l5.m1.1.1.1.1.1.1.1.1" xref="alg1.l5.m1.1.1.1.1.1.1.1.1.cmml"><mi id="alg1.l5.m1.1.1.1.1.1.1.1.1.2.2" xref="alg1.l5.m1.1.1.1.1.1.1.1.1.2.2.cmml">ğ—</mi><mi id="alg1.l5.m1.1.1.1.1.1.1.1.1.3" xref="alg1.l5.m1.1.1.1.1.1.1.1.1.3.cmml">c</mi><mi id="alg1.l5.m1.1.1.1.1.1.1.1.1.2.3" xref="alg1.l5.m1.1.1.1.1.1.1.1.1.2.3.cmml">S</mi></msubsup><mo stretchy="false" id="alg1.l5.m1.1.1.1.1.1.1.1.3" xref="alg1.l5.m1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="alg1.l5.m1.1.1.1.1.3" xref="alg1.l5.m1.1.1.1.2.cmml">}</mo></mrow><mrow id="alg1.l5.m1.1.1.3" xref="alg1.l5.m1.1.1.3.cmml"><mrow id="alg1.l5.m1.1.1.3.2" xref="alg1.l5.m1.1.1.3.2.cmml"><mi id="alg1.l5.m1.1.1.3.2.2" xref="alg1.l5.m1.1.1.3.2.2.cmml">c</mi><mo id="alg1.l5.m1.1.1.3.2.1" xref="alg1.l5.m1.1.1.3.2.1.cmml">=</mo><mn id="alg1.l5.m1.1.1.3.2.3" xref="alg1.l5.m1.1.1.3.2.3.cmml">1</mn></mrow><mo lspace="0.278em" rspace="0.278em" id="alg1.l5.m1.1.1.3.1" xref="alg1.l5.m1.1.1.3.1.cmml">:</mo><mi id="alg1.l5.m1.1.1.3.3" xref="alg1.l5.m1.1.1.3.3.cmml">C</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="alg1.l5.m1.1b"><apply id="alg1.l5.m1.1.1.cmml" xref="alg1.l5.m1.1.1"><csymbol cd="ambiguous" id="alg1.l5.m1.1.1.2.cmml" xref="alg1.l5.m1.1.1">subscript</csymbol><set id="alg1.l5.m1.1.1.1.2.cmml" xref="alg1.l5.m1.1.1.1.1"><apply id="alg1.l5.m1.1.1.1.1.1.cmml" xref="alg1.l5.m1.1.1.1.1.1"><times id="alg1.l5.m1.1.1.1.1.1.2.cmml" xref="alg1.l5.m1.1.1.1.1.1.2"></times><ci id="alg1.l5.m1.1.1.1.1.1.3.cmml" xref="alg1.l5.m1.1.1.1.1.1.3">ğ‘</ci><ci id="alg1.l5.m1.1.1.1.1.1.4.cmml" xref="alg1.l5.m1.1.1.1.1.1.4">ğ‘</ci><ci id="alg1.l5.m1.1.1.1.1.1.5.cmml" xref="alg1.l5.m1.1.1.1.1.1.5">ğ‘œ</ci><ci id="alg1.l5.m1.1.1.1.1.1.6.cmml" xref="alg1.l5.m1.1.1.1.1.1.6">ğ‘¥</ci><apply id="alg1.l5.m1.1.1.1.1.1.1.1.1.cmml" xref="alg1.l5.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="alg1.l5.m1.1.1.1.1.1.1.1.1.1.cmml" xref="alg1.l5.m1.1.1.1.1.1.1.1">subscript</csymbol><apply id="alg1.l5.m1.1.1.1.1.1.1.1.1.2.cmml" xref="alg1.l5.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="alg1.l5.m1.1.1.1.1.1.1.1.1.2.1.cmml" xref="alg1.l5.m1.1.1.1.1.1.1.1">superscript</csymbol><ci id="alg1.l5.m1.1.1.1.1.1.1.1.1.2.2.cmml" xref="alg1.l5.m1.1.1.1.1.1.1.1.1.2.2">ğ—</ci><ci id="alg1.l5.m1.1.1.1.1.1.1.1.1.2.3.cmml" xref="alg1.l5.m1.1.1.1.1.1.1.1.1.2.3">ğ‘†</ci></apply><ci id="alg1.l5.m1.1.1.1.1.1.1.1.1.3.cmml" xref="alg1.l5.m1.1.1.1.1.1.1.1.1.3">ğ‘</ci></apply></apply></set><apply id="alg1.l5.m1.1.1.3.cmml" xref="alg1.l5.m1.1.1.3"><ci id="alg1.l5.m1.1.1.3.1.cmml" xref="alg1.l5.m1.1.1.3.1">:</ci><apply id="alg1.l5.m1.1.1.3.2.cmml" xref="alg1.l5.m1.1.1.3.2"><eq id="alg1.l5.m1.1.1.3.2.1.cmml" xref="alg1.l5.m1.1.1.3.2.1"></eq><ci id="alg1.l5.m1.1.1.3.2.2.cmml" xref="alg1.l5.m1.1.1.3.2.2">ğ‘</ci><cn type="integer" id="alg1.l5.m1.1.1.3.2.3.cmml" xref="alg1.l5.m1.1.1.3.2.3">1</cn></apply><ci id="alg1.l5.m1.1.1.3.3.cmml" xref="alg1.l5.m1.1.1.3.3">ğ¶</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l5.m1.1c">\{bbox(\mathbf{X}^{S}_{c})\}_{c=1:C}</annotation></semantics></math>

</div>
<div id="alg1.l6" class="ltx_listingline">Â Â Â Â Â Â Â Â Â compute egocentric sensing <math id="alg1.l6.m1.1" class="ltx_Math" alttext="\mathcal{E}_{c}" display="inline"><semantics id="alg1.l6.m1.1a"><msub id="alg1.l6.m1.1.1" xref="alg1.l6.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="alg1.l6.m1.1.1.2" xref="alg1.l6.m1.1.1.2.cmml">â„°</mi><mi id="alg1.l6.m1.1.1.3" xref="alg1.l6.m1.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l6.m1.1b"><apply id="alg1.l6.m1.1.1.cmml" xref="alg1.l6.m1.1.1"><csymbol cd="ambiguous" id="alg1.l6.m1.1.1.1.cmml" xref="alg1.l6.m1.1.1">subscript</csymbol><ci id="alg1.l6.m1.1.1.2.cmml" xref="alg1.l6.m1.1.1.2">â„°</ci><ci id="alg1.l6.m1.1.1.3.cmml" xref="alg1.l6.m1.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l6.m1.1c">\mathcal{E}_{c}</annotation></semantics></math>;

</div>
<div id="alg1.l7" class="ltx_listingline">Â Â Â Â Â Â Â Â Â execute one action, produce one CAMP;

</div>
<div id="alg1.l8" class="ltx_listingline">Â Â Â Â Â <span id="alg1.l8.1" class="ltx_text ltx_font_bold">end</span>Â <span id="alg1.l8.2" class="ltx_text ltx_font_bold">for</span>
</div>
<div id="alg1.l9" class="ltx_listingline">
<span id="alg1.l9.1" class="ltx_text ltx_font_bold">end</span>Â <span id="alg1.l9.2" class="ltx_text ltx_font_bold">for</span>
</div>
</div>
</figure>
<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">Although CAMPs are trained solely with static scenes, their direct application to dynamic settings is achieved by decomposing jointly trained CAMPs into individual motion primitives and re-compositing them. Our model demonstrates effective generalization, provided that the egocentric sensing is updated with the most recent obstacle location at each timestep.
Furthermore, our model is directly applicable to tasks involving complex interactions with other virtual humans. To synthesize crowd motion (Alg.Â <a href="#alg1" title="Algorithm 1 â€£ 3.3 Compositing Learned Motion Primitives â€£ 3 Ego-Sensing Driven Motion Synthesis â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>), each virtual human employs the same policy to navigate and avoid others.
To a specific virtual human, others are seen as dynamic obstacles, represented by body bounding boxes for avoidance.
Acknowledging the inherent delay in human reactions when avoiding dynamic obstacles <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">4</span></a>]</cite>, agents take a single CAMP sequentially, instead of in parallel, i.e. the first agent generates its first CAMP and waits for others to complete their first CAMP before all agents move on to prepare their second CAMP. To ensure successful collision avoidance, the agentâ€™s egocentric sensing is updated before taking a new action.
This composition of CAMPs synthesizes emergent multi-human behaviors <span id="S3.SS3.p1.1.1" class="ltx_text ltx_font_italic">without</span> multi-agent RL algorithms (see Sec.Â <a href="#S5.SS1" title="5.1 Evaluation of Learned CAMPs â€£ 5 Experiments â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.1</span></a>), enhancing the generalization and scalability.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Egocentric Synthetic Data Generation</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">Synthesizing realistic egocentric perception-driven human motions (as detailed in Sec.Â <a href="#S3" title="3 Ego-Sensing Driven Motion Synthesis â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>) forms the foundation of simulating egocentric synthetic data.
An overview of our egocentric data generation pipeline <span id="S4.p1.1.1" class="ltx_text ltx_font_italic">EgoGen</span>, is shown in Fig.Â <a href="#S4.F3" title="Figure 3 â€£ 4 Egocentric Synthetic Data Generation â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<figure id="S4.F3" class="ltx_figure"><img src="/html/2401.08739/assets/x3.png" id="S4.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="363" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F3.3.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S4.F3.4.2" class="ltx_text" style="font-size:90%;">Overview of <span id="S4.F3.4.2.1" class="ltx_text ltx_font_italic">EgoGen</span>. Through generative motion synthesis (Sec.Â <a href="#S3" title="3 Ego-Sensing Driven Motion Synthesis â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>), we further enhance egocentric data diversity by randomly sampling diverse body textures (ethnicity, gender) and 3D textured clothing through an automated clothing simulation pipeline (Sec.Â <a href="#S4.SS2" title="4.2 Body Texture and Clothing â€£ 4 Egocentric Synthetic Data Generation â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>). With high-quality scenes and different egocentric cameras, we can render photorealistic egocentric synthetic data with rich and accurate ground truth annotations (Sec.Â <a href="#S4.SS3" title="4.3 Rendering and Annotations â€£ 4 Egocentric Synthetic Data Generation â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3</span></a>).</span></figcaption>
</figure>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Embodied Camera Placement</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.2" class="ltx_p">Similar to existing AR devices, we use the head pose to define the egocentric viewing direction <math id="S4.SS1.p1.1.m1.1" class="ltx_Math" alttext="\vv{\mathbf{v}}" display="inline"><semantics id="S4.SS1.p1.1.m1.1a"><mrow id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml"><merror class="ltx_ERROR undefined undefined" id="S4.SS1.p1.1.m1.1.1.2" xref="S4.SS1.p1.1.m1.1.1.2b.cmml"><mtext id="S4.SS1.p1.1.m1.1.1.2a" xref="S4.SS1.p1.1.m1.1.1.2b.cmml">\vv</mtext></merror><mo lspace="0em" rspace="0em" id="S4.SS1.p1.1.m1.1.1.1" xref="S4.SS1.p1.1.m1.1.1.1.cmml">â€‹</mo><mi id="S4.SS1.p1.1.m1.1.1.3" xref="S4.SS1.p1.1.m1.1.1.3.cmml">ğ¯</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><apply id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1"><times id="S4.SS1.p1.1.m1.1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1.1"></times><ci id="S4.SS1.p1.1.m1.1.1.2b.cmml" xref="S4.SS1.p1.1.m1.1.1.2"><merror class="ltx_ERROR undefined undefined" id="S4.SS1.p1.1.m1.1.1.2.cmml" xref="S4.SS1.p1.1.m1.1.1.2"><mtext id="S4.SS1.p1.1.m1.1.1.2a.cmml" xref="S4.SS1.p1.1.m1.1.1.2">\vv</mtext></merror></ci><ci id="S4.SS1.p1.1.m1.1.1.3.cmml" xref="S4.SS1.p1.1.m1.1.1.3">ğ¯</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">\vv{\mathbf{v}}</annotation></semantics></math>. Our development is based on BlenderÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">13</span></a>]</cite>.
We use the SMPL-XÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib67" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">67</span></a>]</cite> mesh to position the egocentric camera between the two eyeballs. The cameraâ€™s viewing direction (<math id="S4.SS1.p1.2.m2.1" class="ltx_Math" alttext="\vv{\mathbf{v}}" display="inline"><semantics id="S4.SS1.p1.2.m2.1a"><mrow id="S4.SS1.p1.2.m2.1.1" xref="S4.SS1.p1.2.m2.1.1.cmml"><merror class="ltx_ERROR undefined undefined" id="S4.SS1.p1.2.m2.1.1.2" xref="S4.SS1.p1.2.m2.1.1.2b.cmml"><mtext id="S4.SS1.p1.2.m2.1.1.2a" xref="S4.SS1.p1.2.m2.1.1.2b.cmml">\vv</mtext></merror><mo lspace="0em" rspace="0em" id="S4.SS1.p1.2.m2.1.1.1" xref="S4.SS1.p1.2.m2.1.1.1.cmml">â€‹</mo><mi id="S4.SS1.p1.2.m2.1.1.3" xref="S4.SS1.p1.2.m2.1.1.3.cmml">ğ¯</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.2.m2.1b"><apply id="S4.SS1.p1.2.m2.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1"><times id="S4.SS1.p1.2.m2.1.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1.1"></times><ci id="S4.SS1.p1.2.m2.1.1.2b.cmml" xref="S4.SS1.p1.2.m2.1.1.2"><merror class="ltx_ERROR undefined undefined" id="S4.SS1.p1.2.m2.1.1.2.cmml" xref="S4.SS1.p1.2.m2.1.1.2"><mtext id="S4.SS1.p1.2.m2.1.1.2a.cmml" xref="S4.SS1.p1.2.m2.1.1.2">\vv</mtext></merror></ci><ci id="S4.SS1.p1.2.m2.1.1.3.cmml" xref="S4.SS1.p1.2.m2.1.1.3">ğ¯</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.2.m2.1c">\vv{\mathbf{v}}</annotation></semantics></math>) is perpendicular to the plane determined by the two eye bones in the armature.
We also support simulating multi-camera rigs as shown in Fig.Â <a href="#S0.F1" title="Figure 1 â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
When the body moves (Sec.Â <a href="#S3.SS3" title="3.3 Compositing Learned Motion Primitives â€£ 3 Ego-Sensing Driven Motion Synthesis â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3</span></a>), we can synthesize egocentric videos with continuously updated camera poses.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Body Texture and Clothing</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">To enhance <span id="S4.SS2.p1.1.1" class="ltx_text ltx_font_italic">EgoGen</span>â€™s synthetic data realism, we dress virtual humans using human textures and 3D clothing assets from BEDLAMÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">9</span></a>, <a href="#bib.bib1" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">1</span></a>]</cite>, including 50 male and 50 female skin albedo textures from seven ethnic groups.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">Unlike prior worksÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">9</span></a>, <a href="#bib.bib119" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">119</span></a>]</cite> relying on unscalable commercial software for clothing dynamics simulation, we automate it for diverse synthesized motions and body shapes, minimizing manual effort. Each garment mesh is in a consistent rest pose, i.e., A-Pose (See Fig.Â <a href="#S4.F3" title="Figure 3 â€£ 4 Egocentric Synthetic Data Generation â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> middle-left).
For each motion sequence, we first repose it to match the body pose in the first frame using linear blend skinning. This involves initializing the clothing geometry by sampling pose and shape blend shapes, along with skinning weights from the nearest multiple SMPL-X vertices in A-Pose. Then we simulate upper and lower garments separately using a state-of-the-art clothing simulation networkÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">28</span></a>]</cite>.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Rendering and Annotations</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p"><span id="S4.SS3.p1.1.1" class="ltx_text ltx_font_italic">EgoGen</span> supports simulating diverse head-mounted devices with different camera models, such as fisheye and pinhole cameras.
Given the cameraâ€™s intrinsic parameters and relative poses within the camera rig, we can simulate AR devices like Project Aria glassesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib54" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">54</span></a>]</cite> and HoloLensÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">55</span></a>]</cite>, facilitating synthetic data generation for real-world applications.
Camera extrinsic is determined by our generative human motion model. We use BlenderÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">13</span></a>]</cite> to render photorealistic egocentric image sequences with motion blur. We also render out a rich set of ground truth annotations, such as depth maps, surface normals, segmentation masks, world positions, optical flow, etc for egocentric perception tasks.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Experiments</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">We assess the motion quality, generalizability, and diversity of our motion model, highlighting its ability to generalize to unseen complex tasks and comparing it with recent baselines (Sec.Â <a href="#S5.SS1" title="5.1 Evaluation of Learned CAMPs â€£ 5 Experiments â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.1</span></a>).
We evaluate our proposed egocentric sensing as a depth proxy for enhancing agent exploration (Sec.Â <a href="#S5.SS2" title="5.2 Evaluation of Egocentric Sensing â€£ 5 Experiments â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.2</span></a>) and conduct ablation studies (Sec.Â <a href="#S5.SS3" title="5.3 Ablation Studies â€£ 5 Experiments â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.3</span></a>).</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">We further demonstrate the effectiveness of <span id="S5.p2.1.1" class="ltx_text ltx_font_italic">EgoGen</span>Â on three egocentric computer vision tasks in Sec.Â <a href="#S5.SS4" title="5.4 Mapping, Localization, and Tracking for HMD â€£ 5 Experiments â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.4</span></a>, andÂ <a href="#S5.SS5" title="5.5 Human Mesh Recovery from Egocentric views â€£ 5 Experiments â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.5</span></a>. By incorporating synthesized egocentric images, we can enhance the performance of the state-of-the-art algorithms.</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Evaluation of Learned CAMPs</h3>

<figure id="S5.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S5.T1.20.3.1" class="ltx_text" style="font-size:90%;">Table 1</span>: </span><span id="S5.T1.4.2" class="ltx_text" style="font-size:90%;">Evaluation of motion synthesis in scenes with moving obstacles, multiple humans, and path diversity. <math id="S5.T1.3.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T1.3.1.m1.1b"><mo stretchy="false" id="S5.T1.3.1.m1.1.1" xref="S5.T1.3.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S5.T1.3.1.m1.1c"><ci id="S5.T1.3.1.m1.1.1.cmml" xref="S5.T1.3.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.3.1.m1.1d">\downarrow</annotation></semantics></math>: lower is better; <math id="S5.T1.4.2.m2.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S5.T1.4.2.m2.1b"><mo stretchy="false" id="S5.T1.4.2.m2.1.1" xref="S5.T1.4.2.m2.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S5.T1.4.2.m2.1c"><ci id="S5.T1.4.2.m2.1.1.cmml" xref="S5.T1.4.2.m2.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.4.2.m2.1d">\uparrow</annotation></semantics></math>: higher is better. The best results in each scenario are in boldface. * denotes an improved version for fair comparison. (Sec.Â <a href="#S5.SS1" title="5.1 Evaluation of Learned CAMPs â€£ 5 Experiments â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.1</span></a>)</span></figcaption>
<div id="S5.T1.18" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:595.0pt;height:271pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="S5.T1.18.14" class="ltx_p"><span id="S5.T1.18.14.14" class="ltx_text">
<span id="S5.T1.18.14.14.14" class="ltx_tabular ltx_align_middle">
<span id="S5.T1.18.14.14.14.15" class="ltx_tr">
<span id="S5.T1.18.14.14.14.15.1" class="ltx_td ltx_align_center ltx_border_ll ltx_border_t">Evaluation</span>
<span id="S5.T1.18.14.14.14.15.2" class="ltx_td ltx_align_center ltx_border_t">Metrics</span>
<span id="S5.T1.18.14.14.14.15.3" class="ltx_td ltx_align_center ltx_border_t">GAMMA*Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib127" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">127</span></a>]</cite></span>
<span id="S5.T1.18.14.14.14.15.4" class="ltx_td ltx_align_center ltx_border_t">DIMOS*Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib129" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">129</span></a>]</cite></span>
<span id="S5.T1.18.14.14.14.15.5" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">Ours</span></span>
<span id="S5.T1.5.1.1.1.1" class="ltx_tr">
<span id="S5.T1.5.1.1.1.1.2" class="ltx_td ltx_align_center ltx_border_ll ltx_border_tt ltx_rowspan ltx_rowspan_4"><span id="S5.T1.5.1.1.1.1.2.1" class="ltx_text">Mov. obs.</span></span>
<span id="S5.T1.5.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_tt">SR (%) <math id="S5.T1.5.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S5.T1.5.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S5.T1.5.1.1.1.1.1.m1.1.1" xref="S5.T1.5.1.1.1.1.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S5.T1.5.1.1.1.1.1.m1.1b"><ci id="S5.T1.5.1.1.1.1.1.m1.1.1.cmml" xref="S5.T1.5.1.1.1.1.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.5.1.1.1.1.1.m1.1c">\uparrow</annotation></semantics></math></span>
<span id="S5.T1.5.1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_tt">96</span>
<span id="S5.T1.5.1.1.1.1.4" class="ltx_td ltx_align_center ltx_border_tt">83</span>
<span id="S5.T1.5.1.1.1.1.5" class="ltx_td ltx_align_center ltx_border_rr ltx_border_tt"><span id="S5.T1.5.1.1.1.1.5.1" class="ltx_text ltx_font_bold">100</span></span></span>
<span id="S5.T1.6.2.2.2.2" class="ltx_tr">
<span id="S5.T1.6.2.2.2.2.1" class="ltx_td ltx_align_center">Dist. (m) <math id="S5.T1.6.2.2.2.2.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T1.6.2.2.2.2.1.m1.1a"><mo stretchy="false" id="S5.T1.6.2.2.2.2.1.m1.1.1" xref="S5.T1.6.2.2.2.2.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S5.T1.6.2.2.2.2.1.m1.1b"><ci id="S5.T1.6.2.2.2.2.1.m1.1.1.cmml" xref="S5.T1.6.2.2.2.2.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.6.2.2.2.2.1.m1.1c">\downarrow</annotation></semantics></math></span>
<span id="S5.T1.6.2.2.2.2.2" class="ltx_td ltx_align_center">0.29</span>
<span id="S5.T1.6.2.2.2.2.3" class="ltx_td ltx_align_center">0.55</span>
<span id="S5.T1.6.2.2.2.2.4" class="ltx_td ltx_align_center ltx_border_rr"><span id="S5.T1.6.2.2.2.2.4.1" class="ltx_text ltx_font_bold">0.06</span></span></span>
<span id="S5.T1.7.3.3.3.3" class="ltx_tr">
<span id="S5.T1.7.3.3.3.3.1" class="ltx_td ltx_align_center">Cont. <math id="S5.T1.7.3.3.3.3.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S5.T1.7.3.3.3.3.1.m1.1a"><mo stretchy="false" id="S5.T1.7.3.3.3.3.1.m1.1.1" xref="S5.T1.7.3.3.3.3.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S5.T1.7.3.3.3.3.1.m1.1b"><ci id="S5.T1.7.3.3.3.3.1.m1.1.1.cmml" xref="S5.T1.7.3.3.3.3.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.7.3.3.3.3.1.m1.1c">\uparrow</annotation></semantics></math></span>
<span id="S5.T1.7.3.3.3.3.2" class="ltx_td ltx_align_center">0.95</span>
<span id="S5.T1.7.3.3.3.3.3" class="ltx_td ltx_align_center">0.96</span>
<span id="S5.T1.7.3.3.3.3.4" class="ltx_td ltx_align_center ltx_border_rr"><span id="S5.T1.7.3.3.3.3.4.1" class="ltx_text ltx_font_bold">0.97</span></span></span>
<span id="S5.T1.8.4.4.4.4" class="ltx_tr">
<span id="S5.T1.8.4.4.4.4.1" class="ltx_td ltx_align_center">Pene-S. (%) <math id="S5.T1.8.4.4.4.4.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T1.8.4.4.4.4.1.m1.1a"><mo stretchy="false" id="S5.T1.8.4.4.4.4.1.m1.1.1" xref="S5.T1.8.4.4.4.4.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S5.T1.8.4.4.4.4.1.m1.1b"><ci id="S5.T1.8.4.4.4.4.1.m1.1.1.cmml" xref="S5.T1.8.4.4.4.4.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.8.4.4.4.4.1.m1.1c">\downarrow</annotation></semantics></math></span>
<span id="S5.T1.8.4.4.4.4.2" class="ltx_td ltx_align_center">9.2</span>
<span id="S5.T1.8.4.4.4.4.3" class="ltx_td ltx_align_center">8.4</span>
<span id="S5.T1.8.4.4.4.4.4" class="ltx_td ltx_align_center ltx_border_rr"><span id="S5.T1.8.4.4.4.4.4.1" class="ltx_text ltx_font_bold">3.4</span></span></span>
<span id="S5.T1.9.5.5.5.5" class="ltx_tr">
<span id="S5.T1.9.5.5.5.5.2" class="ltx_td ltx_align_center ltx_border_ll ltx_border_t ltx_rowspan ltx_rowspan_4"><span id="S5.T1.9.5.5.5.5.2.1" class="ltx_text">2 humans</span></span>
<span id="S5.T1.9.5.5.5.5.1" class="ltx_td ltx_align_center ltx_border_t">SR (%) <math id="S5.T1.9.5.5.5.5.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S5.T1.9.5.5.5.5.1.m1.1a"><mo stretchy="false" id="S5.T1.9.5.5.5.5.1.m1.1.1" xref="S5.T1.9.5.5.5.5.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S5.T1.9.5.5.5.5.1.m1.1b"><ci id="S5.T1.9.5.5.5.5.1.m1.1.1.cmml" xref="S5.T1.9.5.5.5.5.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.9.5.5.5.5.1.m1.1c">\uparrow</annotation></semantics></math></span>
<span id="S5.T1.9.5.5.5.5.3" class="ltx_td ltx_align_center ltx_border_t">95</span>
<span id="S5.T1.9.5.5.5.5.4" class="ltx_td ltx_align_center ltx_border_t">88</span>
<span id="S5.T1.9.5.5.5.5.5" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t"><span id="S5.T1.9.5.5.5.5.5.1" class="ltx_text ltx_font_bold">100</span></span></span>
<span id="S5.T1.10.6.6.6.6" class="ltx_tr">
<span id="S5.T1.10.6.6.6.6.1" class="ltx_td ltx_align_center">Dist. (m) <math id="S5.T1.10.6.6.6.6.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T1.10.6.6.6.6.1.m1.1a"><mo stretchy="false" id="S5.T1.10.6.6.6.6.1.m1.1.1" xref="S5.T1.10.6.6.6.6.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S5.T1.10.6.6.6.6.1.m1.1b"><ci id="S5.T1.10.6.6.6.6.1.m1.1.1.cmml" xref="S5.T1.10.6.6.6.6.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.10.6.6.6.6.1.m1.1c">\downarrow</annotation></semantics></math></span>
<span id="S5.T1.10.6.6.6.6.2" class="ltx_td ltx_align_center">0.32</span>
<span id="S5.T1.10.6.6.6.6.3" class="ltx_td ltx_align_center">0.41</span>
<span id="S5.T1.10.6.6.6.6.4" class="ltx_td ltx_align_center ltx_border_rr"><span id="S5.T1.10.6.6.6.6.4.1" class="ltx_text ltx_font_bold">0.07</span></span></span>
<span id="S5.T1.11.7.7.7.7" class="ltx_tr">
<span id="S5.T1.11.7.7.7.7.1" class="ltx_td ltx_align_center">Cont. <math id="S5.T1.11.7.7.7.7.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S5.T1.11.7.7.7.7.1.m1.1a"><mo stretchy="false" id="S5.T1.11.7.7.7.7.1.m1.1.1" xref="S5.T1.11.7.7.7.7.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S5.T1.11.7.7.7.7.1.m1.1b"><ci id="S5.T1.11.7.7.7.7.1.m1.1.1.cmml" xref="S5.T1.11.7.7.7.7.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.11.7.7.7.7.1.m1.1c">\uparrow</annotation></semantics></math></span>
<span id="S5.T1.11.7.7.7.7.2" class="ltx_td ltx_align_center">0.96</span>
<span id="S5.T1.11.7.7.7.7.3" class="ltx_td ltx_align_center"><span id="S5.T1.11.7.7.7.7.3.1" class="ltx_text ltx_font_bold">0.98</span></span>
<span id="S5.T1.11.7.7.7.7.4" class="ltx_td ltx_align_center ltx_border_rr">0.97</span></span>
<span id="S5.T1.12.8.8.8.8" class="ltx_tr">
<span id="S5.T1.12.8.8.8.8.1" class="ltx_td ltx_align_center">Pene-H. <math id="S5.T1.12.8.8.8.8.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T1.12.8.8.8.8.1.m1.1a"><mo stretchy="false" id="S5.T1.12.8.8.8.8.1.m1.1.1" xref="S5.T1.12.8.8.8.8.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S5.T1.12.8.8.8.8.1.m1.1b"><ci id="S5.T1.12.8.8.8.8.1.m1.1.1.cmml" xref="S5.T1.12.8.8.8.8.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.12.8.8.8.8.1.m1.1c">\downarrow</annotation></semantics></math></span>
<span id="S5.T1.12.8.8.8.8.2" class="ltx_td ltx_align_center">27.6</span>
<span id="S5.T1.12.8.8.8.8.3" class="ltx_td ltx_align_center">10.7</span>
<span id="S5.T1.12.8.8.8.8.4" class="ltx_td ltx_align_center ltx_border_rr"><span id="S5.T1.12.8.8.8.8.4.1" class="ltx_text ltx_font_bold">0</span></span></span>
<span id="S5.T1.13.9.9.9.9" class="ltx_tr">
<span id="S5.T1.13.9.9.9.9.2" class="ltx_td ltx_align_center ltx_border_ll ltx_border_t ltx_rowspan ltx_rowspan_4"><span id="S5.T1.13.9.9.9.9.2.1" class="ltx_text">4 humans</span></span>
<span id="S5.T1.13.9.9.9.9.1" class="ltx_td ltx_align_center ltx_border_t">SR (%) <math id="S5.T1.13.9.9.9.9.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S5.T1.13.9.9.9.9.1.m1.1a"><mo stretchy="false" id="S5.T1.13.9.9.9.9.1.m1.1.1" xref="S5.T1.13.9.9.9.9.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S5.T1.13.9.9.9.9.1.m1.1b"><ci id="S5.T1.13.9.9.9.9.1.m1.1.1.cmml" xref="S5.T1.13.9.9.9.9.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.13.9.9.9.9.1.m1.1c">\uparrow</annotation></semantics></math></span>
<span id="S5.T1.13.9.9.9.9.3" class="ltx_td ltx_align_center ltx_border_t">92</span>
<span id="S5.T1.13.9.9.9.9.4" class="ltx_td ltx_align_center ltx_border_t">70</span>
<span id="S5.T1.13.9.9.9.9.5" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t"><span id="S5.T1.13.9.9.9.9.5.1" class="ltx_text ltx_font_bold">100</span></span></span>
<span id="S5.T1.14.10.10.10.10" class="ltx_tr">
<span id="S5.T1.14.10.10.10.10.1" class="ltx_td ltx_align_center">Dist. (m) <math id="S5.T1.14.10.10.10.10.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T1.14.10.10.10.10.1.m1.1a"><mo stretchy="false" id="S5.T1.14.10.10.10.10.1.m1.1.1" xref="S5.T1.14.10.10.10.10.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S5.T1.14.10.10.10.10.1.m1.1b"><ci id="S5.T1.14.10.10.10.10.1.m1.1.1.cmml" xref="S5.T1.14.10.10.10.10.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.14.10.10.10.10.1.m1.1c">\downarrow</annotation></semantics></math></span>
<span id="S5.T1.14.10.10.10.10.2" class="ltx_td ltx_align_center">0.41</span>
<span id="S5.T1.14.10.10.10.10.3" class="ltx_td ltx_align_center">0.79</span>
<span id="S5.T1.14.10.10.10.10.4" class="ltx_td ltx_align_center ltx_border_rr"><span id="S5.T1.14.10.10.10.10.4.1" class="ltx_text ltx_font_bold">0.07</span></span></span>
<span id="S5.T1.15.11.11.11.11" class="ltx_tr">
<span id="S5.T1.15.11.11.11.11.1" class="ltx_td ltx_align_center">Cont. <math id="S5.T1.15.11.11.11.11.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S5.T1.15.11.11.11.11.1.m1.1a"><mo stretchy="false" id="S5.T1.15.11.11.11.11.1.m1.1.1" xref="S5.T1.15.11.11.11.11.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S5.T1.15.11.11.11.11.1.m1.1b"><ci id="S5.T1.15.11.11.11.11.1.m1.1.1.cmml" xref="S5.T1.15.11.11.11.11.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.15.11.11.11.11.1.m1.1c">\uparrow</annotation></semantics></math></span>
<span id="S5.T1.15.11.11.11.11.2" class="ltx_td ltx_align_center">0.94</span>
<span id="S5.T1.15.11.11.11.11.3" class="ltx_td ltx_align_center">0.95</span>
<span id="S5.T1.15.11.11.11.11.4" class="ltx_td ltx_align_center ltx_border_rr"><span id="S5.T1.15.11.11.11.11.4.1" class="ltx_text ltx_font_bold">0.96</span></span></span>
<span id="S5.T1.16.12.12.12.12" class="ltx_tr">
<span id="S5.T1.16.12.12.12.12.1" class="ltx_td ltx_align_center">Pene-H. <math id="S5.T1.16.12.12.12.12.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T1.16.12.12.12.12.1.m1.1a"><mo stretchy="false" id="S5.T1.16.12.12.12.12.1.m1.1.1" xref="S5.T1.16.12.12.12.12.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S5.T1.16.12.12.12.12.1.m1.1b"><ci id="S5.T1.16.12.12.12.12.1.m1.1.1.cmml" xref="S5.T1.16.12.12.12.12.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.16.12.12.12.12.1.m1.1c">\downarrow</annotation></semantics></math></span>
<span id="S5.T1.16.12.12.12.12.2" class="ltx_td ltx_align_center">60.4</span>
<span id="S5.T1.16.12.12.12.12.3" class="ltx_td ltx_align_center">41.7</span>
<span id="S5.T1.16.12.12.12.12.4" class="ltx_td ltx_align_center ltx_border_rr"><span id="S5.T1.16.12.12.12.12.4.1" class="ltx_text ltx_font_bold">0</span></span></span>
<span id="S5.T1.17.13.13.13.13" class="ltx_tr">
<span id="S5.T1.17.13.13.13.13.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_ll ltx_border_t ltx_rowspan ltx_rowspan_2"><span id="S5.T1.17.13.13.13.13.2.1" class="ltx_text">Diversity</span></span>
<span id="S5.T1.17.13.13.13.13.1" class="ltx_td ltx_align_center ltx_border_t">SR (%) <math id="S5.T1.17.13.13.13.13.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S5.T1.17.13.13.13.13.1.m1.1a"><mo stretchy="false" id="S5.T1.17.13.13.13.13.1.m1.1.1" xref="S5.T1.17.13.13.13.13.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S5.T1.17.13.13.13.13.1.m1.1b"><ci id="S5.T1.17.13.13.13.13.1.m1.1.1.cmml" xref="S5.T1.17.13.13.13.13.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.17.13.13.13.13.1.m1.1c">\uparrow</annotation></semantics></math></span>
<span id="S5.T1.17.13.13.13.13.3" class="ltx_td ltx_align_center ltx_border_t">96</span>
<span id="S5.T1.17.13.13.13.13.4" class="ltx_td ltx_align_center ltx_border_t">84</span>
<span id="S5.T1.17.13.13.13.13.5" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t"><span id="S5.T1.17.13.13.13.13.5.1" class="ltx_text ltx_font_bold">97</span></span></span>
<span id="S5.T1.18.14.14.14.14" class="ltx_tr">
<span id="S5.T1.18.14.14.14.14.1" class="ltx_td ltx_align_center ltx_border_b">Std Dev <math id="S5.T1.18.14.14.14.14.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S5.T1.18.14.14.14.14.1.m1.1a"><mo stretchy="false" id="S5.T1.18.14.14.14.14.1.m1.1.1" xref="S5.T1.18.14.14.14.14.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S5.T1.18.14.14.14.14.1.m1.1b"><ci id="S5.T1.18.14.14.14.14.1.m1.1.1.cmml" xref="S5.T1.18.14.14.14.14.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.18.14.14.14.14.1.m1.1c">\uparrow</annotation></semantics></math></span>
<span id="S5.T1.18.14.14.14.14.2" class="ltx_td ltx_align_center ltx_border_b">0.987</span>
<span id="S5.T1.18.14.14.14.14.3" class="ltx_td ltx_align_center ltx_border_b">1.05</span>
<span id="S5.T1.18.14.14.14.14.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_rr"><span id="S5.T1.18.14.14.14.14.4.1" class="ltx_text ltx_font_bold">1.21</span></span></span>
</span></span></p>
</span></div>
</figure>
<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">We assess CAMPsâ€™ generalizability in dynamic scenes, including scenes with moving obstacles and scenes with multiple individuals.
In tests with moving obstacles, the obstacle blocks the personâ€™s path by moving between the person and the goal. In multiple human test scenes, lines from their starting and goal locations intersect in the middle, requiring solving human-human penetrations. See detail in <a href="#S4.SS1a" title="S4.1 Test Scenarios in Evaluation of CAMPs â€£ S4 Experiments â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Sec.</span>Â <span class="ltx_text ltx_ref_tag">S4.1</span></a>.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.1" class="ltx_p">In Tab.Â <a href="#S5.T1" title="Table 1 â€£ 5.1 Evaluation of Learned CAMPs â€£ 5 Experiments â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, we compare goal-reaching behaviors with two recent baselines: GAMMAÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib127" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">127</span></a>]</cite> and DIMOSÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib129" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">129</span></a>]</cite>.
Baseline methods use navigation meshes and path planning for static scenes, while CAMPs can autonomously avoid dynamic obstacles (Sec.Â <a href="#S3.SS3" title="3.3 Compositing Learned Motion Primitives â€£ 3 Ego-Sensing Driven Motion Synthesis â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3</span></a>). For fair comparison in dynamic scenes, we extend the baselines by updating navigation meshes and performing on-the-fly path planning at each time step. The tree-based search as inÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib127" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">127</span></a>]</cite> is disabled for all the methods.
<span id="S5.SS1.p2.1.1" class="ltx_text ltx_font_bold">Metrics</span>:
(1) <span id="S5.SS1.p2.1.2" class="ltx_text ltx_font_italic">SR</span>: Success rate for reaching the goal location within a 0.3m threshold.
(2) <span id="S5.SS1.p2.1.3" class="ltx_text ltx_font_italic">Dist.</span>: Average distance of the final pelvis location to the goal.
(3) <span id="S5.SS1.p2.1.4" class="ltx_text ltx_font_italic">Cont.</span>: The contact metricÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib127" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">127</span></a>]</cite> that measures foot-floor contact and foot skating.
(4) <span id="S5.SS1.p2.1.5" class="ltx_text ltx_font_italic">Pene-S.</span>: Percentage of frames with detected human-scene penetration in moving obstacle scenes.
(5) <span id="S5.SS1.p2.1.6" class="ltx_text ltx_font_italic">Pene-H.</span>: Accurate human-human penetration evaluation metric using COAPÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">56</span></a>]</cite> in multiple human scenes.
Please refer to <a href="#S4.SS2a" title="S4.2 Evaluation Metrics â€£ S4 Experiments â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Sec.</span>Â <span class="ltx_text ltx_ref_tag">S4.2</span></a> for metric details.</p>
</div>
<div id="S5.SS1.p3" class="ltx_para">
<p id="S5.SS1.p3.1" class="ltx_p">CAMPs outperform the two baselines in dynamic scenarios with moving obstacles and multiple humans, exhibiting lower human-scene and human-human penetrations and a higher goal-reaching success rate.
In multiple human scenarios, we observe that in the baselines, dynamically redoing path planning for each human independently can not effectively solve human-human penetration. In contrast, composable CAMPs can generalize well in dynamic settings without using multi-agent RL to synthesize crowd motions.</p>
</div>
<div id="S5.SS1.p4" class="ltx_para">
<p id="S5.SS1.p4.1" class="ltx_p">We assess walking path diversity using the standard deviation of pelvis locations for the same start-target pairs in scenes with a single static box obstacle.
As shown in Tab.Â <a href="#S5.T1" title="Table 1 â€£ 5.1 Evaluation of Learned CAMPs â€£ 5 Experiments â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> (Diversity), our approach does not require a pre-computed global path and allows agents to self-explore without being constrained by predefined paths, achieving higher walking path diversity and success rate. This fosters diverse synthetic data generation via more diverse synthesized motion.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Evaluation of Egocentric Sensing</h3>

<figure id="S5.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S5.T2.4.1.1" class="ltx_text" style="font-size:90%;">Table 2</span>: </span><span id="S5.T2.5.2" class="ltx_text" style="font-size:90%;">Evaluation of egocentric sensing. (Sec.Â <a href="#S5.SS2" title="5.2 Evaluation of Egocentric Sensing â€£ 5 Experiments â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.2</span></a>)</span></figcaption>
<div id="S5.T2.2" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:378.0pt;height:72pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="S5.T2.2.2" class="ltx_p"><span id="S5.T2.2.2.2" class="ltx_text">
<span id="S5.T2.2.2.2.2" class="ltx_tabular ltx_align_middle">
<span id="S5.T2.2.2.2.2.2" class="ltx_tr">
<span id="S5.T2.2.2.2.2.2.3" class="ltx_td ltx_align_center ltx_border_ll ltx_border_t" style="padding-bottom:2.15277pt;">Method (sensing range)</span>
<span id="S5.T2.1.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-bottom:2.15277pt;">SR (%) <math id="S5.T2.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S5.T2.1.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S5.T2.1.1.1.1.1.1.m1.1.1" xref="S5.T2.1.1.1.1.1.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S5.T2.1.1.1.1.1.1.m1.1b"><ci id="S5.T2.1.1.1.1.1.1.m1.1.1.cmml" xref="S5.T2.1.1.1.1.1.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.1.1.1.1.1.1.m1.1c">\uparrow</annotation></semantics></math></span>
<span id="S5.T2.2.2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" style="padding-bottom:2.15277pt;">Dist. (m) <math id="S5.T2.2.2.2.2.2.2.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T2.2.2.2.2.2.2.m1.1a"><mo stretchy="false" id="S5.T2.2.2.2.2.2.2.m1.1.1" xref="S5.T2.2.2.2.2.2.2.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S5.T2.2.2.2.2.2.2.m1.1b"><ci id="S5.T2.2.2.2.2.2.2.m1.1.1.cmml" xref="S5.T2.2.2.2.2.2.2.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.2.2.2.2.2.2.m1.1c">\downarrow</annotation></semantics></math></span></span>
<span id="S5.T2.2.2.2.2.3" class="ltx_tr">
<span id="S5.T2.2.2.2.2.3.1" class="ltx_td ltx_align_center ltx_border_ll ltx_border_tt">Local mapÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib129" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">129</span></a>]</cite> (0.8 m)</span>
<span id="S5.T2.2.2.2.2.3.2" class="ltx_td ltx_align_center ltx_border_tt">78</span>
<span id="S5.T2.2.2.2.2.3.3" class="ltx_td ltx_align_center ltx_border_rr ltx_border_tt">0.35</span></span>
<span id="S5.T2.2.2.2.2.4" class="ltx_tr">
<span id="S5.T2.2.2.2.2.4.1" class="ltx_td ltx_align_center ltx_border_ll">Local map* (7 m)</span>
<span id="S5.T2.2.2.2.2.4.2" class="ltx_td ltx_align_center">4</span>
<span id="S5.T2.2.2.2.2.4.3" class="ltx_td ltx_align_center ltx_border_rr">3.04</span></span>
<span id="S5.T2.2.2.2.2.5" class="ltx_tr">
<span id="S5.T2.2.2.2.2.5.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_ll">Egocentric sensing (ours) (7 m)</span>
<span id="S5.T2.2.2.2.2.5.2" class="ltx_td ltx_align_center ltx_border_b"><span id="S5.T2.2.2.2.2.5.2.1" class="ltx_text ltx_font_bold">95</span></span>
<span id="S5.T2.2.2.2.2.5.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_rr"><span id="S5.T2.2.2.2.2.5.3.1" class="ltx_text ltx_font_bold">0.12</span></span></span>
</span></span></p>
</span></div>
</figure>
<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.3" class="ltx_p">We assess the exploration ability of our egocentric sensing <math id="S5.SS2.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{E}_{t}" display="inline"><semantics id="S5.SS2.p1.1.m1.1a"><msub id="S5.SS2.p1.1.m1.1.1" xref="S5.SS2.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.SS2.p1.1.m1.1.1.2" xref="S5.SS2.p1.1.m1.1.1.2.cmml">â„°</mi><mi id="S5.SS2.p1.1.m1.1.1.3" xref="S5.SS2.p1.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.1.m1.1b"><apply id="S5.SS2.p1.1.m1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS2.p1.1.m1.1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1">subscript</csymbol><ci id="S5.SS2.p1.1.m1.1.1.2.cmml" xref="S5.SS2.p1.1.m1.1.1.2">â„°</ci><ci id="S5.SS2.p1.1.m1.1.1.3.cmml" xref="S5.SS2.p1.1.m1.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.1.m1.1c">\mathcal{E}_{t}</annotation></semantics></math> in ReplicaÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib99" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">99</span></a>]</cite> scenes. In Tab.Â <a href="#S5.T2" title="Table 2 â€£ 5.2 Evaluation of Egocentric Sensing â€£ 5 Experiments â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, we replace <math id="S5.SS2.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{E}_{t}" display="inline"><semantics id="S5.SS2.p1.2.m2.1a"><msub id="S5.SS2.p1.2.m2.1.1" xref="S5.SS2.p1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.SS2.p1.2.m2.1.1.2" xref="S5.SS2.p1.2.m2.1.1.2.cmml">â„°</mi><mi id="S5.SS2.p1.2.m2.1.1.3" xref="S5.SS2.p1.2.m2.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.2.m2.1b"><apply id="S5.SS2.p1.2.m2.1.1.cmml" xref="S5.SS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS2.p1.2.m2.1.1.1.cmml" xref="S5.SS2.p1.2.m2.1.1">subscript</csymbol><ci id="S5.SS2.p1.2.m2.1.1.2.cmml" xref="S5.SS2.p1.2.m2.1.1.2">â„°</ci><ci id="S5.SS2.p1.2.m2.1.1.3.cmml" xref="S5.SS2.p1.2.m2.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.2.m2.1c">\mathcal{E}_{t}</annotation></semantics></math> with a local mapÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib129" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">129</span></a>]</cite> in our state <math id="S5.SS2.p1.3.m3.1" class="ltx_Math" alttext="\mathbf{s}_{t}" display="inline"><semantics id="S5.SS2.p1.3.m3.1a"><msub id="S5.SS2.p1.3.m3.1.1" xref="S5.SS2.p1.3.m3.1.1.cmml"><mi id="S5.SS2.p1.3.m3.1.1.2" xref="S5.SS2.p1.3.m3.1.1.2.cmml">ğ¬</mi><mi id="S5.SS2.p1.3.m3.1.1.3" xref="S5.SS2.p1.3.m3.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.3.m3.1b"><apply id="S5.SS2.p1.3.m3.1.1.cmml" xref="S5.SS2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S5.SS2.p1.3.m3.1.1.1.cmml" xref="S5.SS2.p1.3.m3.1.1">subscript</csymbol><ci id="S5.SS2.p1.3.m3.1.1.2.cmml" xref="S5.SS2.p1.3.m3.1.1.2">ğ¬</ci><ci id="S5.SS2.p1.3.m3.1.1.3.cmml" xref="S5.SS2.p1.3.m3.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.3.m3.1c">\mathbf{s}_{t}</annotation></semantics></math>, following their encoding method. Relying on local information can trap agents in local optima, e.g., walls beyond their sensing range, resulting in lower SR. Our egocentric sensing acts as a depth proxy, allowing the agent to avoid local optima, explore more effectively than local mapsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib129" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">129</span></a>]</cite> or scandotsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">3</span></a>]</cite>, and achieve higher SR. In addition, our compact representation is more scalable as the sensing range increases, while quadratic local map growth can hinder the policy networkâ€™s learning.</p>
</div>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Ablation Studies</h3>

<figure id="S5.T3" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S5.T3.12.3.1" class="ltx_text" style="font-size:90%;">Table 3</span>: </span><span id="S5.T3.4.2" class="ltx_text" style="font-size:90%;">Ablation studies. <span id="S5.T3.4.2.2" class="ltx_text ltx_font_italic">Note: in our observation, <math id="S5.T3.3.1.1.m1.1" class="ltx_Math" alttext="\|" display="inline"><semantics id="S5.T3.3.1.1.m1.1b"><mo id="S5.T3.3.1.1.m1.1.1" xref="S5.T3.3.1.1.m1.1.1.cmml">âˆ¥</mo><annotation-xml encoding="MathML-Content" id="S5.T3.3.1.1.m1.1c"><ci id="S5.T3.3.1.1.m1.1.1.cmml" xref="S5.T3.3.1.1.m1.1.1">âˆ¥</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.3.1.1.m1.1d">\|</annotation></semantics></math>VP<math id="S5.T3.4.2.2.m2.1" class="ltx_math_unparsed" alttext="\|_{2}&gt;15" display="inline"><semantics id="S5.T3.4.2.2.m2.1b"><mrow id="S5.T3.4.2.2.m2.1c"><msub id="S5.T3.4.2.2.m2.1.1"><mo id="S5.T3.4.2.2.m2.1.1.2">âˆ¥</mo><mn id="S5.T3.4.2.2.m2.1.1.3">2</mn></msub><mo lspace="0.167em" id="S5.T3.4.2.2.m2.1.2">&gt;</mo><mn id="S5.T3.4.2.2.m2.1.3">15</mn></mrow><annotation encoding="application/x-tex" id="S5.T3.4.2.2.m2.1d">\|_{2}&gt;15</annotation></semantics></math> indicates abnormal human poses.</span> (Sec.Â <a href="#S5.SS3" title="5.3 Ablation Studies â€£ 5 Experiments â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.3</span></a>)</span></figcaption>
<div id="S5.T3.10" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:276.8pt;height:90pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="S5.T3.10.6" class="ltx_p"><span id="S5.T3.10.6.6" class="ltx_text">
<span id="S5.T3.10.6.6.6" class="ltx_tabular ltx_align_middle">
<span id="S5.T3.10.6.6.6.6" class="ltx_tr">
<span id="S5.T3.10.6.6.6.6.7" class="ltx_td ltx_border_ll ltx_border_t" style="padding-bottom:2.15277pt;"></span>
<span id="S5.T3.5.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-bottom:2.15277pt;">SR (%) <math id="S5.T3.5.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S5.T3.5.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S5.T3.5.1.1.1.1.1.m1.1.1" xref="S5.T3.5.1.1.1.1.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S5.T3.5.1.1.1.1.1.m1.1b"><ci id="S5.T3.5.1.1.1.1.1.m1.1.1.cmml" xref="S5.T3.5.1.1.1.1.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.5.1.1.1.1.1.m1.1c">\uparrow</annotation></semantics></math></span>
<span id="S5.T3.8.4.4.4.4.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-bottom:2.15277pt;"><math id="S5.T3.6.2.2.2.2.2.m1.1" class="ltx_Math" alttext="\|" display="inline"><semantics id="S5.T3.6.2.2.2.2.2.m1.1a"><mo id="S5.T3.6.2.2.2.2.2.m1.1.1" xref="S5.T3.6.2.2.2.2.2.m1.1.1.cmml">âˆ¥</mo><annotation-xml encoding="MathML-Content" id="S5.T3.6.2.2.2.2.2.m1.1b"><ci id="S5.T3.6.2.2.2.2.2.m1.1.1.cmml" xref="S5.T3.6.2.2.2.2.2.m1.1.1">âˆ¥</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.6.2.2.2.2.2.m1.1c">\|</annotation></semantics></math>VP<math id="S5.T3.7.3.3.3.3.3.m2.1" class="ltx_math_unparsed" alttext="\|_{2}" display="inline"><semantics id="S5.T3.7.3.3.3.3.3.m2.1a"><msub id="S5.T3.7.3.3.3.3.3.m2.1.1"><mo id="S5.T3.7.3.3.3.3.3.m2.1.1.2">âˆ¥</mo><mn id="S5.T3.7.3.3.3.3.3.m2.1.1.3">2</mn></msub><annotation encoding="application/x-tex" id="S5.T3.7.3.3.3.3.3.m2.1b">\|_{2}</annotation></semantics></math> <math id="S5.T3.8.4.4.4.4.4.m3.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T3.8.4.4.4.4.4.m3.1a"><mo stretchy="false" id="S5.T3.8.4.4.4.4.4.m3.1.1" xref="S5.T3.8.4.4.4.4.4.m3.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S5.T3.8.4.4.4.4.4.m3.1b"><ci id="S5.T3.8.4.4.4.4.4.m3.1.1.cmml" xref="S5.T3.8.4.4.4.4.4.m3.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.8.4.4.4.4.4.m3.1c">\downarrow</annotation></semantics></math></span>
<span id="S5.T3.10.6.6.6.6.6" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" style="padding-bottom:2.15277pt;"><math id="S5.T3.9.5.5.5.5.5.m1.3" class="ltx_Math" alttext="\cos(\vv{\mathbf{v}},\vv{\mathbf{a}})" display="inline"><semantics id="S5.T3.9.5.5.5.5.5.m1.3a"><mrow id="S5.T3.9.5.5.5.5.5.m1.3.3.2" xref="S5.T3.9.5.5.5.5.5.m1.3.3.3.cmml"><mi id="S5.T3.9.5.5.5.5.5.m1.1.1" xref="S5.T3.9.5.5.5.5.5.m1.1.1.cmml">cos</mi><mo id="S5.T3.9.5.5.5.5.5.m1.3.3.2a" xref="S5.T3.9.5.5.5.5.5.m1.3.3.3.cmml">â¡</mo><mrow id="S5.T3.9.5.5.5.5.5.m1.3.3.2.2" xref="S5.T3.9.5.5.5.5.5.m1.3.3.3.cmml"><mo stretchy="false" id="S5.T3.9.5.5.5.5.5.m1.3.3.2.2.3" xref="S5.T3.9.5.5.5.5.5.m1.3.3.3.cmml">(</mo><mrow id="S5.T3.9.5.5.5.5.5.m1.2.2.1.1.1" xref="S5.T3.9.5.5.5.5.5.m1.2.2.1.1.1.cmml"><merror class="ltx_ERROR undefined undefined" id="S5.T3.9.5.5.5.5.5.m1.2.2.1.1.1.2" xref="S5.T3.9.5.5.5.5.5.m1.2.2.1.1.1.2b.cmml"><mtext id="S5.T3.9.5.5.5.5.5.m1.2.2.1.1.1.2a" xref="S5.T3.9.5.5.5.5.5.m1.2.2.1.1.1.2b.cmml">\vv</mtext></merror><mo lspace="0em" rspace="0em" id="S5.T3.9.5.5.5.5.5.m1.2.2.1.1.1.1" xref="S5.T3.9.5.5.5.5.5.m1.2.2.1.1.1.1.cmml">â€‹</mo><mi id="S5.T3.9.5.5.5.5.5.m1.2.2.1.1.1.3" xref="S5.T3.9.5.5.5.5.5.m1.2.2.1.1.1.3.cmml">ğ¯</mi></mrow><mo id="S5.T3.9.5.5.5.5.5.m1.3.3.2.2.4" xref="S5.T3.9.5.5.5.5.5.m1.3.3.3.cmml">,</mo><mrow id="S5.T3.9.5.5.5.5.5.m1.3.3.2.2.2" xref="S5.T3.9.5.5.5.5.5.m1.3.3.2.2.2.cmml"><merror class="ltx_ERROR undefined undefined" id="S5.T3.9.5.5.5.5.5.m1.3.3.2.2.2.2" xref="S5.T3.9.5.5.5.5.5.m1.3.3.2.2.2.2b.cmml"><mtext id="S5.T3.9.5.5.5.5.5.m1.3.3.2.2.2.2a" xref="S5.T3.9.5.5.5.5.5.m1.3.3.2.2.2.2b.cmml">\vv</mtext></merror><mo lspace="0em" rspace="0em" id="S5.T3.9.5.5.5.5.5.m1.3.3.2.2.2.1" xref="S5.T3.9.5.5.5.5.5.m1.3.3.2.2.2.1.cmml">â€‹</mo><mi id="S5.T3.9.5.5.5.5.5.m1.3.3.2.2.2.3" xref="S5.T3.9.5.5.5.5.5.m1.3.3.2.2.2.3.cmml">ğš</mi></mrow><mo stretchy="false" id="S5.T3.9.5.5.5.5.5.m1.3.3.2.2.5" xref="S5.T3.9.5.5.5.5.5.m1.3.3.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.T3.9.5.5.5.5.5.m1.3b"><apply id="S5.T3.9.5.5.5.5.5.m1.3.3.3.cmml" xref="S5.T3.9.5.5.5.5.5.m1.3.3.2"><cos id="S5.T3.9.5.5.5.5.5.m1.1.1.cmml" xref="S5.T3.9.5.5.5.5.5.m1.1.1"></cos><apply id="S5.T3.9.5.5.5.5.5.m1.2.2.1.1.1.cmml" xref="S5.T3.9.5.5.5.5.5.m1.2.2.1.1.1"><times id="S5.T3.9.5.5.5.5.5.m1.2.2.1.1.1.1.cmml" xref="S5.T3.9.5.5.5.5.5.m1.2.2.1.1.1.1"></times><ci id="S5.T3.9.5.5.5.5.5.m1.2.2.1.1.1.2b.cmml" xref="S5.T3.9.5.5.5.5.5.m1.2.2.1.1.1.2"><merror class="ltx_ERROR undefined undefined" id="S5.T3.9.5.5.5.5.5.m1.2.2.1.1.1.2.cmml" xref="S5.T3.9.5.5.5.5.5.m1.2.2.1.1.1.2"><mtext id="S5.T3.9.5.5.5.5.5.m1.2.2.1.1.1.2a.cmml" xref="S5.T3.9.5.5.5.5.5.m1.2.2.1.1.1.2">\vv</mtext></merror></ci><ci id="S5.T3.9.5.5.5.5.5.m1.2.2.1.1.1.3.cmml" xref="S5.T3.9.5.5.5.5.5.m1.2.2.1.1.1.3">ğ¯</ci></apply><apply id="S5.T3.9.5.5.5.5.5.m1.3.3.2.2.2.cmml" xref="S5.T3.9.5.5.5.5.5.m1.3.3.2.2.2"><times id="S5.T3.9.5.5.5.5.5.m1.3.3.2.2.2.1.cmml" xref="S5.T3.9.5.5.5.5.5.m1.3.3.2.2.2.1"></times><ci id="S5.T3.9.5.5.5.5.5.m1.3.3.2.2.2.2b.cmml" xref="S5.T3.9.5.5.5.5.5.m1.3.3.2.2.2.2"><merror class="ltx_ERROR undefined undefined" id="S5.T3.9.5.5.5.5.5.m1.3.3.2.2.2.2.cmml" xref="S5.T3.9.5.5.5.5.5.m1.3.3.2.2.2.2"><mtext id="S5.T3.9.5.5.5.5.5.m1.3.3.2.2.2.2a.cmml" xref="S5.T3.9.5.5.5.5.5.m1.3.3.2.2.2.2">\vv</mtext></merror></ci><ci id="S5.T3.9.5.5.5.5.5.m1.3.3.2.2.2.3.cmml" xref="S5.T3.9.5.5.5.5.5.m1.3.3.2.2.2.3">ğš</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.9.5.5.5.5.5.m1.3c">\cos(\vv{\mathbf{v}},\vv{\mathbf{a}})</annotation></semantics></math> <math id="S5.T3.10.6.6.6.6.6.m2.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S5.T3.10.6.6.6.6.6.m2.1a"><mo stretchy="false" id="S5.T3.10.6.6.6.6.6.m2.1.1" xref="S5.T3.10.6.6.6.6.6.m2.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S5.T3.10.6.6.6.6.6.m2.1b"><ci id="S5.T3.10.6.6.6.6.6.m2.1.1.cmml" xref="S5.T3.10.6.6.6.6.6.m2.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.10.6.6.6.6.6.m2.1c">\uparrow</annotation></semantics></math></span></span>
<span id="S5.T3.10.6.6.6.7" class="ltx_tr">
<span id="S5.T3.10.6.6.6.7.1" class="ltx_td ltx_align_center ltx_border_ll ltx_border_tt">Egocentric depth</span>
<span id="S5.T3.10.6.6.6.7.2" class="ltx_td ltx_align_center ltx_border_tt">8</span>
<span id="S5.T3.10.6.6.6.7.3" class="ltx_td ltx_align_center ltx_border_tt">13.64</span>
<span id="S5.T3.10.6.6.6.7.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_tt">0.049</span></span>
<span id="S5.T3.10.6.6.6.8" class="ltx_tr">
<span id="S5.T3.10.6.6.6.8.1" class="ltx_td ltx_align_center ltx_border_ll">No pretraining</span>
<span id="S5.T3.10.6.6.6.8.2" class="ltx_td ltx_align_center">90</span>
<span id="S5.T3.10.6.6.6.8.3" class="ltx_td ltx_align_center">28.77</span>
<span id="S5.T3.10.6.6.6.8.4" class="ltx_td ltx_align_center ltx_border_rr">0.918</span></span>
<span id="S5.T3.10.6.6.6.9" class="ltx_tr">
<span id="S5.T3.10.6.6.6.9.1" class="ltx_td ltx_align_center ltx_border_ll">No attention reward</span>
<span id="S5.T3.10.6.6.6.9.2" class="ltx_td ltx_align_center">90</span>
<span id="S5.T3.10.6.6.6.9.3" class="ltx_td ltx_align_center">12.26</span>
<span id="S5.T3.10.6.6.6.9.4" class="ltx_td ltx_align_center ltx_border_rr">0.891</span></span>
<span id="S5.T3.10.6.6.6.10" class="ltx_tr">
<span id="S5.T3.10.6.6.6.10.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_ll">Our policy</span>
<span id="S5.T3.10.6.6.6.10.2" class="ltx_td ltx_align_center ltx_border_b"><span id="S5.T3.10.6.6.6.10.2.1" class="ltx_text ltx_font_bold">92</span></span>
<span id="S5.T3.10.6.6.6.10.3" class="ltx_td ltx_align_center ltx_border_b"><span id="S5.T3.10.6.6.6.10.3.1" class="ltx_text ltx_font_bold">10.57</span></span>
<span id="S5.T3.10.6.6.6.10.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_rr"><span id="S5.T3.10.6.6.6.10.4.1" class="ltx_text ltx_font_bold">0.940</span></span></span>
</span></span></p>
</span></div>
</figure>
<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.1" class="ltx_p">We compare our policy with several ablations in Tab.Â <a href="#S5.T3" title="Table 3 â€£ 5.3 Ablation Studies â€£ 5 Experiments â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>: 
<br class="ltx_break"><span id="S5.SS3.p1.1.1" class="ltx_text ltx_font_bold">Egocentric depth</span>: an ablation training an egocentric depth image-based policy without the depth sensing proxy. Egocentric depth images are encoded with a CNN; 
<br class="ltx_break"><span id="S5.SS3.p1.1.2" class="ltx_text ltx_font_bold">No pretraining</span>: an ablation training collision avoidance in crowded scenes with strict penetration termination directly; 
<br class="ltx_break"><span id="S5.SS3.p1.1.3" class="ltx_text ltx_font_bold">No attention reward</span>: an ablation for the viewing direction.</p>
</div>
<div id="S5.SS3.p2" class="ltx_para">
<p id="S5.SS3.p2.2" class="ltx_p">We assess pose naturalness with the maximum pose embedding norm encoded with VPoserÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib67" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">67</span></a>]</cite> and evaluate the attention reward with the cosine similarity between the viewing direction <math id="S5.SS3.p2.1.m1.1" class="ltx_Math" alttext="\vv{\mathbf{v}}" display="inline"><semantics id="S5.SS3.p2.1.m1.1a"><mrow id="S5.SS3.p2.1.m1.1.1" xref="S5.SS3.p2.1.m1.1.1.cmml"><merror class="ltx_ERROR undefined undefined" id="S5.SS3.p2.1.m1.1.1.2" xref="S5.SS3.p2.1.m1.1.1.2b.cmml"><mtext id="S5.SS3.p2.1.m1.1.1.2a" xref="S5.SS3.p2.1.m1.1.1.2b.cmml">\vv</mtext></merror><mo lspace="0em" rspace="0em" id="S5.SS3.p2.1.m1.1.1.1" xref="S5.SS3.p2.1.m1.1.1.1.cmml">â€‹</mo><mi id="S5.SS3.p2.1.m1.1.1.3" xref="S5.SS3.p2.1.m1.1.1.3.cmml">ğ¯</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.1.m1.1b"><apply id="S5.SS3.p2.1.m1.1.1.cmml" xref="S5.SS3.p2.1.m1.1.1"><times id="S5.SS3.p2.1.m1.1.1.1.cmml" xref="S5.SS3.p2.1.m1.1.1.1"></times><ci id="S5.SS3.p2.1.m1.1.1.2b.cmml" xref="S5.SS3.p2.1.m1.1.1.2"><merror class="ltx_ERROR undefined undefined" id="S5.SS3.p2.1.m1.1.1.2.cmml" xref="S5.SS3.p2.1.m1.1.1.2"><mtext id="S5.SS3.p2.1.m1.1.1.2a.cmml" xref="S5.SS3.p2.1.m1.1.1.2">\vv</mtext></merror></ci><ci id="S5.SS3.p2.1.m1.1.1.3.cmml" xref="S5.SS3.p2.1.m1.1.1.3">ğ¯</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.1.m1.1c">\vv{\mathbf{v}}</annotation></semantics></math> and the attention direction <math id="S5.SS3.p2.2.m2.1" class="ltx_Math" alttext="\vv{\mathbf{a}}" display="inline"><semantics id="S5.SS3.p2.2.m2.1a"><mrow id="S5.SS3.p2.2.m2.1.1" xref="S5.SS3.p2.2.m2.1.1.cmml"><merror class="ltx_ERROR undefined undefined" id="S5.SS3.p2.2.m2.1.1.2" xref="S5.SS3.p2.2.m2.1.1.2b.cmml"><mtext id="S5.SS3.p2.2.m2.1.1.2a" xref="S5.SS3.p2.2.m2.1.1.2b.cmml">\vv</mtext></merror><mo lspace="0em" rspace="0em" id="S5.SS3.p2.2.m2.1.1.1" xref="S5.SS3.p2.2.m2.1.1.1.cmml">â€‹</mo><mi id="S5.SS3.p2.2.m2.1.1.3" xref="S5.SS3.p2.2.m2.1.1.3.cmml">ğš</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.2.m2.1b"><apply id="S5.SS3.p2.2.m2.1.1.cmml" xref="S5.SS3.p2.2.m2.1.1"><times id="S5.SS3.p2.2.m2.1.1.1.cmml" xref="S5.SS3.p2.2.m2.1.1.1"></times><ci id="S5.SS3.p2.2.m2.1.1.2b.cmml" xref="S5.SS3.p2.2.m2.1.1.2"><merror class="ltx_ERROR undefined undefined" id="S5.SS3.p2.2.m2.1.1.2.cmml" xref="S5.SS3.p2.2.m2.1.1.2"><mtext id="S5.SS3.p2.2.m2.1.1.2a.cmml" xref="S5.SS3.p2.2.m2.1.1.2">\vv</mtext></merror></ci><ci id="S5.SS3.p2.2.m2.1.1.3.cmml" xref="S5.SS3.p2.2.m2.1.1.3">ğš</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.2.m2.1c">\vv{\mathbf{a}}</annotation></semantics></math> (Sec.Â <a href="#S3.SS1" title="3.1 Ego-Sensing Driven Motion Primitives â€£ 3 Ego-Sensing Driven Motion Synthesis â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a>).</p>
</div>
<div id="S5.SS3.p3" class="ltx_para">
<p id="S5.SS3.p3.1" class="ltx_p">Directly training RL with egocentric depth images is ineffective due to our high-dimensional action space, emphasizing the value of the compact egocentric sensing representation. Training agents with strict penetration constraints in crowded scenes directly can result in exploring unreasonable action subspaces, given its unbounded Gaussian nature, leading to unrealistic human poses, highlighting the effectiveness of our two-stage RL training scheme. Without the attention reward, the virtual humanâ€™s capability to attend to a specific direction decreases. All ablation studies are evaluated in Replica.
See visuals in Sup. Vid. and <a href="#S4.SS3a" title="S4.3 Ablation Studies â€£ S4 Experiments â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Sec.</span>Â <span class="ltx_text ltx_ref_tag">S4.3</span></a>.</p>
</div>
</section>
<section id="S5.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4 </span>Mapping, Localization, and Tracking for HMD</h3>

<div id="S5.SS4.p1" class="ltx_para ltx_noindent">
<p id="S5.SS4.p1.1" class="ltx_p"><span id="S5.SS4.p1.1.1" class="ltx_text ltx_font_bold">Mapping and localization.</span>

LaMARÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib84" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">84</span></a>]</cite> is the first mapping and localization benchmark dataset for AR in large-scale scenes.
Despite over a year of extensive data collection, the dataset still lacks exhaustive scene coverage, especially in large open spaces.
<span id="S5.SS4.p1.1.2" class="ltx_text ltx_font_italic">EgoGen</span>Â can let virtual humans explore large-scale scenes, render dense egocentric views, and build a more complete SfM map by extracting image feature points with SuperPointÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">17</span></a>]</cite> and matching images with SuperGlueÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib83" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">83</span></a>]</cite>.
Despite synthetic images being noisier due to scene quality, SuperGlueÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib83" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">83</span></a>]</cite> matching can filter out noisy feature points and yield reliable matches.</p>
</div>
<div id="S5.SS4.p2" class="ltx_para">
<p id="S5.SS4.p2.2" class="ltx_p">In Tab.Â <a href="#S5.T4" title="Table 4 â€£ 5.4 Mapping, Localization, and Tracking for HMD â€£ 5 Experiments â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, we evaluate <span id="S5.SS4.p2.2.1" class="ltx_text ltx_font_italic">EgoGen</span>Â by assessing the localization recall at (<math id="S5.SS4.p2.1.m1.2" class="ltx_Math" alttext="1^{\circ},10cm" display="inline"><semantics id="S5.SS4.p2.1.m1.2a"><mrow id="S5.SS4.p2.1.m1.2.2.2" xref="S5.SS4.p2.1.m1.2.2.3.cmml"><msup id="S5.SS4.p2.1.m1.1.1.1.1" xref="S5.SS4.p2.1.m1.1.1.1.1.cmml"><mn id="S5.SS4.p2.1.m1.1.1.1.1.2" xref="S5.SS4.p2.1.m1.1.1.1.1.2.cmml">1</mn><mo id="S5.SS4.p2.1.m1.1.1.1.1.3" xref="S5.SS4.p2.1.m1.1.1.1.1.3.cmml">âˆ˜</mo></msup><mo id="S5.SS4.p2.1.m1.2.2.2.3" xref="S5.SS4.p2.1.m1.2.2.3.cmml">,</mo><mrow id="S5.SS4.p2.1.m1.2.2.2.2" xref="S5.SS4.p2.1.m1.2.2.2.2.cmml"><mn id="S5.SS4.p2.1.m1.2.2.2.2.2" xref="S5.SS4.p2.1.m1.2.2.2.2.2.cmml">10</mn><mo lspace="0em" rspace="0em" id="S5.SS4.p2.1.m1.2.2.2.2.1" xref="S5.SS4.p2.1.m1.2.2.2.2.1.cmml">â€‹</mo><mi id="S5.SS4.p2.1.m1.2.2.2.2.3" xref="S5.SS4.p2.1.m1.2.2.2.2.3.cmml">c</mi><mo lspace="0em" rspace="0em" id="S5.SS4.p2.1.m1.2.2.2.2.1a" xref="S5.SS4.p2.1.m1.2.2.2.2.1.cmml">â€‹</mo><mi id="S5.SS4.p2.1.m1.2.2.2.2.4" xref="S5.SS4.p2.1.m1.2.2.2.2.4.cmml">m</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS4.p2.1.m1.2b"><list id="S5.SS4.p2.1.m1.2.2.3.cmml" xref="S5.SS4.p2.1.m1.2.2.2"><apply id="S5.SS4.p2.1.m1.1.1.1.1.cmml" xref="S5.SS4.p2.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S5.SS4.p2.1.m1.1.1.1.1.1.cmml" xref="S5.SS4.p2.1.m1.1.1.1.1">superscript</csymbol><cn type="integer" id="S5.SS4.p2.1.m1.1.1.1.1.2.cmml" xref="S5.SS4.p2.1.m1.1.1.1.1.2">1</cn><compose id="S5.SS4.p2.1.m1.1.1.1.1.3.cmml" xref="S5.SS4.p2.1.m1.1.1.1.1.3"></compose></apply><apply id="S5.SS4.p2.1.m1.2.2.2.2.cmml" xref="S5.SS4.p2.1.m1.2.2.2.2"><times id="S5.SS4.p2.1.m1.2.2.2.2.1.cmml" xref="S5.SS4.p2.1.m1.2.2.2.2.1"></times><cn type="integer" id="S5.SS4.p2.1.m1.2.2.2.2.2.cmml" xref="S5.SS4.p2.1.m1.2.2.2.2.2">10</cn><ci id="S5.SS4.p2.1.m1.2.2.2.2.3.cmml" xref="S5.SS4.p2.1.m1.2.2.2.2.3">ğ‘</ci><ci id="S5.SS4.p2.1.m1.2.2.2.2.4.cmml" xref="S5.SS4.p2.1.m1.2.2.2.2.4">ğ‘š</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p2.1.m1.2c">1^{\circ},10cm</annotation></semantics></math>) on the validation set in a lobby of <math id="S5.SS4.p2.2.m2.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S5.SS4.p2.2.m2.1a"><mo id="S5.SS4.p2.2.m2.1.1" xref="S5.SS4.p2.2.m2.1.1.cmml">âˆ¼</mo><annotation-xml encoding="MathML-Content" id="S5.SS4.p2.2.m2.1b"><csymbol cd="latexml" id="S5.SS4.p2.2.m2.1.1.cmml" xref="S5.SS4.p2.2.m2.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p2.2.m2.1c">\sim</annotation></semantics></math>120 sqm of the LaMAR CAB location. In addition, we report the number of triangulated 3D points (#P3D) and track length.
<span id="S5.SS4.p2.2.2" class="ltx_text ltx_font_italic">EgoGen</span>Â improves the 3D reconstruction by yielding more points for a slightly improved track length and also a significantly better localization performance compared to using the real data only. Ng et al.Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">62</span></a>]</cite> augments mapping images by perturbing real-world camera poses with noise, which may generate unrealistic camera poses (e.g., stuck in a wall or facing the ceiling), limiting egocentric localization effectiveness. Their method also assumes the availability of initial camera poses, which may not always be feasible.
In contrast, <span id="S5.SS4.p2.2.3" class="ltx_text ltx_font_italic">EgoGen</span>Â augments by virtual humans <span id="S5.SS4.p2.2.4" class="ltx_text ltx_font_italic">randomly</span> exploring scenes. Our approach holds promise for creating AR mapping and localization datasets for digital twin scenes without manual data collection, providing enhanced privacy preservation, e.g. no need for anonymization.
Refer to <a href="#S5.SS1a" title="S5.1 Mapping and Localization for AR â€£ S5 Egocentric Perception Tasks â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Sec.</span>Â <span class="ltx_text ltx_ref_tag">S5.1</span></a> for visualization and implementation details.</p>
</div>
<figure id="S5.T4" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S5.T4.8.2.1" class="ltx_text" style="font-size:90%;">Table 4</span>: </span><span id="S5.T4.2.1" class="ltx_text" style="font-size:90%;">Mapping and localization evaluation. We augment LaMAR with the same amount of images (248 frames) and report the localization recall at (<math id="S5.T4.2.1.m1.2" class="ltx_Math" alttext="1^{\circ},10cm" display="inline"><semantics id="S5.T4.2.1.m1.2b"><mrow id="S5.T4.2.1.m1.2.2.2" xref="S5.T4.2.1.m1.2.2.3.cmml"><msup id="S5.T4.2.1.m1.1.1.1.1" xref="S5.T4.2.1.m1.1.1.1.1.cmml"><mn id="S5.T4.2.1.m1.1.1.1.1.2" xref="S5.T4.2.1.m1.1.1.1.1.2.cmml">1</mn><mo id="S5.T4.2.1.m1.1.1.1.1.3" xref="S5.T4.2.1.m1.1.1.1.1.3.cmml">âˆ˜</mo></msup><mo id="S5.T4.2.1.m1.2.2.2.3" xref="S5.T4.2.1.m1.2.2.3.cmml">,</mo><mrow id="S5.T4.2.1.m1.2.2.2.2" xref="S5.T4.2.1.m1.2.2.2.2.cmml"><mn id="S5.T4.2.1.m1.2.2.2.2.2" xref="S5.T4.2.1.m1.2.2.2.2.2.cmml">10</mn><mo lspace="0em" rspace="0em" id="S5.T4.2.1.m1.2.2.2.2.1" xref="S5.T4.2.1.m1.2.2.2.2.1.cmml">â€‹</mo><mi id="S5.T4.2.1.m1.2.2.2.2.3" xref="S5.T4.2.1.m1.2.2.2.2.3.cmml">c</mi><mo lspace="0em" rspace="0em" id="S5.T4.2.1.m1.2.2.2.2.1b" xref="S5.T4.2.1.m1.2.2.2.2.1.cmml">â€‹</mo><mi id="S5.T4.2.1.m1.2.2.2.2.4" xref="S5.T4.2.1.m1.2.2.2.2.4.cmml">m</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.T4.2.1.m1.2c"><list id="S5.T4.2.1.m1.2.2.3.cmml" xref="S5.T4.2.1.m1.2.2.2"><apply id="S5.T4.2.1.m1.1.1.1.1.cmml" xref="S5.T4.2.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S5.T4.2.1.m1.1.1.1.1.1.cmml" xref="S5.T4.2.1.m1.1.1.1.1">superscript</csymbol><cn type="integer" id="S5.T4.2.1.m1.1.1.1.1.2.cmml" xref="S5.T4.2.1.m1.1.1.1.1.2">1</cn><compose id="S5.T4.2.1.m1.1.1.1.1.3.cmml" xref="S5.T4.2.1.m1.1.1.1.1.3"></compose></apply><apply id="S5.T4.2.1.m1.2.2.2.2.cmml" xref="S5.T4.2.1.m1.2.2.2.2"><times id="S5.T4.2.1.m1.2.2.2.2.1.cmml" xref="S5.T4.2.1.m1.2.2.2.2.1"></times><cn type="integer" id="S5.T4.2.1.m1.2.2.2.2.2.cmml" xref="S5.T4.2.1.m1.2.2.2.2.2">10</cn><ci id="S5.T4.2.1.m1.2.2.2.2.3.cmml" xref="S5.T4.2.1.m1.2.2.2.2.3">ğ‘</ci><ci id="S5.T4.2.1.m1.2.2.2.2.4.cmml" xref="S5.T4.2.1.m1.2.2.2.2.4">ğ‘š</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.2.1.m1.2d">1^{\circ},10cm</annotation></semantics></math>) on the validation set. <span id="S5.T4.2.1.1" class="ltx_text ltx_font_italic">EgoGen</span>Â achieves the highest track length and recall. (Sec.Â <a href="#S5.SS4" title="5.4 Mapping, Localization, and Tracking for HMD â€£ 5 Experiments â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.4</span></a>)</span></figcaption>
<div id="S5.T4.5" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:382.1pt;height:72pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="S5.T4.5.3" class="ltx_p"><span id="S5.T4.5.3.3" class="ltx_text">
<span id="S5.T4.5.3.3.3" class="ltx_tabular ltx_align_middle">
<span id="S5.T4.5.3.3.3.3" class="ltx_tr">
<span id="S5.T4.5.3.3.3.3.4" class="ltx_td ltx_border_ll ltx_border_t" style="padding-bottom:2.15277pt;"></span>
<span id="S5.T4.3.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-bottom:2.15277pt;">#P3D <math id="S5.T4.3.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S5.T4.3.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S5.T4.3.1.1.1.1.1.m1.1.1" xref="S5.T4.3.1.1.1.1.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S5.T4.3.1.1.1.1.1.m1.1b"><ci id="S5.T4.3.1.1.1.1.1.m1.1.1.cmml" xref="S5.T4.3.1.1.1.1.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.3.1.1.1.1.1.m1.1c">\uparrow</annotation></semantics></math></span>
<span id="S5.T4.4.2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-bottom:2.15277pt;">Track length <math id="S5.T4.4.2.2.2.2.2.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S5.T4.4.2.2.2.2.2.m1.1a"><mo stretchy="false" id="S5.T4.4.2.2.2.2.2.m1.1.1" xref="S5.T4.4.2.2.2.2.2.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S5.T4.4.2.2.2.2.2.m1.1b"><ci id="S5.T4.4.2.2.2.2.2.m1.1.1.cmml" xref="S5.T4.4.2.2.2.2.2.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.4.2.2.2.2.2.m1.1c">\uparrow</annotation></semantics></math></span>
<span id="S5.T4.5.3.3.3.3.3" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" style="padding-bottom:2.15277pt;">Recall (%) <math id="S5.T4.5.3.3.3.3.3.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S5.T4.5.3.3.3.3.3.m1.1a"><mo stretchy="false" id="S5.T4.5.3.3.3.3.3.m1.1.1" xref="S5.T4.5.3.3.3.3.3.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S5.T4.5.3.3.3.3.3.m1.1b"><ci id="S5.T4.5.3.3.3.3.3.m1.1.1.cmml" xref="S5.T4.5.3.3.3.3.3.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T4.5.3.3.3.3.3.m1.1c">\uparrow</annotation></semantics></math></span></span>
<span id="S5.T4.5.3.3.3.4" class="ltx_tr">
<span id="S5.T4.5.3.3.3.4.1" class="ltx_td ltx_align_center ltx_border_ll ltx_border_tt">LaMAR</span>
<span id="S5.T4.5.3.3.3.4.2" class="ltx_td ltx_align_center ltx_border_tt">1929739</span>
<span id="S5.T4.5.3.3.3.4.3" class="ltx_td ltx_align_center ltx_border_tt">5.1946</span>
<span id="S5.T4.5.3.3.3.4.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_tt">66.9</span></span>
<span id="S5.T4.5.3.3.3.5" class="ltx_tr">
<span id="S5.T4.5.3.3.3.5.1" class="ltx_td ltx_align_center ltx_border_ll">Ng et al.Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">62</span></a>]</cite></span>
<span id="S5.T4.5.3.3.3.5.2" class="ltx_td ltx_align_center"><span id="S5.T4.5.3.3.3.5.2.1" class="ltx_text ltx_font_bold">1937758</span></span>
<span id="S5.T4.5.3.3.3.5.3" class="ltx_td ltx_align_center">5.1940</span>
<span id="S5.T4.5.3.3.3.5.4" class="ltx_td ltx_align_center ltx_border_rr">74.9</span></span>
<span id="S5.T4.5.3.3.3.6" class="ltx_tr">
<span id="S5.T4.5.3.3.3.6.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_ll">EgoGen</span>
<span id="S5.T4.5.3.3.3.6.2" class="ltx_td ltx_align_center ltx_border_b">1936169</span>
<span id="S5.T4.5.3.3.3.6.3" class="ltx_td ltx_align_center ltx_border_b"><span id="S5.T4.5.3.3.3.6.3.1" class="ltx_text ltx_font_bold">5.2105</span></span>
<span id="S5.T4.5.3.3.3.6.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_rr"><span id="S5.T4.5.3.3.3.6.4.1" class="ltx_text ltx_font_bold">76.7</span></span></span>
</span></span></p>
</span></div>
</figure>
<figure id="S5.T5" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S5.T5.6.1.1" class="ltx_text" style="font-size:90%;">Table 5</span>: </span><span id="S5.T5.7.2" class="ltx_text" style="font-size:90%;">Egocentric camera tracking evaluation of models trained with and without synthetic data from <span id="S5.T5.7.2.1" class="ltx_text ltx_font_italic">EgoGen</span>. (Sec.Â <a href="#S5.T5" title="Table 5 â€£ 5.4 Mapping, Localization, and Tracking for HMD â€£ 5 Experiments â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>)</span></figcaption>
<div id="S5.T5.3" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:275.7pt;height:54pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="S5.T5.3.3" class="ltx_p"><span id="S5.T5.3.3.3" class="ltx_text">
<span id="S5.T5.3.3.3.3" class="ltx_tabular ltx_align_middle">
<span id="S5.T5.3.3.3.3.3" class="ltx_tr">
<span id="S5.T5.3.3.3.3.3.4" class="ltx_td ltx_border_ll ltx_border_t" style="padding-bottom:2.15277pt;"></span>
<span id="S5.T5.1.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-bottom:2.15277pt;">Pose <math id="S5.T5.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T5.1.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S5.T5.1.1.1.1.1.1.m1.1.1" xref="S5.T5.1.1.1.1.1.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S5.T5.1.1.1.1.1.1.m1.1b"><ci id="S5.T5.1.1.1.1.1.1.m1.1.1.cmml" xref="S5.T5.1.1.1.1.1.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.1.1.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math></span>
<span id="S5.T5.2.2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-bottom:2.15277pt;">Rotation <math id="S5.T5.2.2.2.2.2.2.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T5.2.2.2.2.2.2.m1.1a"><mo stretchy="false" id="S5.T5.2.2.2.2.2.2.m1.1.1" xref="S5.T5.2.2.2.2.2.2.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S5.T5.2.2.2.2.2.2.m1.1b"><ci id="S5.T5.2.2.2.2.2.2.m1.1.1.cmml" xref="S5.T5.2.2.2.2.2.2.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.2.2.2.2.2.2.m1.1c">\downarrow</annotation></semantics></math></span>
<span id="S5.T5.3.3.3.3.3.3" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" style="padding-bottom:2.15277pt;">Transl <math id="S5.T5.3.3.3.3.3.3.m1.1" class="ltx_Math" alttext="(mm)\downarrow" display="inline"><semantics id="S5.T5.3.3.3.3.3.3.m1.1a"><mrow id="S5.T5.3.3.3.3.3.3.m1.1.1" xref="S5.T5.3.3.3.3.3.3.m1.1.1.cmml"><mrow id="S5.T5.3.3.3.3.3.3.m1.1.1.1.1" xref="S5.T5.3.3.3.3.3.3.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="S5.T5.3.3.3.3.3.3.m1.1.1.1.1.2" xref="S5.T5.3.3.3.3.3.3.m1.1.1.1.1.1.cmml">(</mo><mrow id="S5.T5.3.3.3.3.3.3.m1.1.1.1.1.1" xref="S5.T5.3.3.3.3.3.3.m1.1.1.1.1.1.cmml"><mi id="S5.T5.3.3.3.3.3.3.m1.1.1.1.1.1.2" xref="S5.T5.3.3.3.3.3.3.m1.1.1.1.1.1.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S5.T5.3.3.3.3.3.3.m1.1.1.1.1.1.1" xref="S5.T5.3.3.3.3.3.3.m1.1.1.1.1.1.1.cmml">â€‹</mo><mi id="S5.T5.3.3.3.3.3.3.m1.1.1.1.1.1.3" xref="S5.T5.3.3.3.3.3.3.m1.1.1.1.1.1.3.cmml">m</mi></mrow><mo stretchy="false" id="S5.T5.3.3.3.3.3.3.m1.1.1.1.1.3" xref="S5.T5.3.3.3.3.3.3.m1.1.1.1.1.1.cmml">)</mo></mrow><mo stretchy="false" id="S5.T5.3.3.3.3.3.3.m1.1.1.2" xref="S5.T5.3.3.3.3.3.3.m1.1.1.2.cmml">â†“</mo><mi id="S5.T5.3.3.3.3.3.3.m1.1.1.3" xref="S5.T5.3.3.3.3.3.3.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="S5.T5.3.3.3.3.3.3.m1.1b"><apply id="S5.T5.3.3.3.3.3.3.m1.1.1.cmml" xref="S5.T5.3.3.3.3.3.3.m1.1.1"><ci id="S5.T5.3.3.3.3.3.3.m1.1.1.2.cmml" xref="S5.T5.3.3.3.3.3.3.m1.1.1.2">â†“</ci><apply id="S5.T5.3.3.3.3.3.3.m1.1.1.1.1.1.cmml" xref="S5.T5.3.3.3.3.3.3.m1.1.1.1.1"><times id="S5.T5.3.3.3.3.3.3.m1.1.1.1.1.1.1.cmml" xref="S5.T5.3.3.3.3.3.3.m1.1.1.1.1.1.1"></times><ci id="S5.T5.3.3.3.3.3.3.m1.1.1.1.1.1.2.cmml" xref="S5.T5.3.3.3.3.3.3.m1.1.1.1.1.1.2">ğ‘š</ci><ci id="S5.T5.3.3.3.3.3.3.m1.1.1.1.1.1.3.cmml" xref="S5.T5.3.3.3.3.3.3.m1.1.1.1.1.1.3">ğ‘š</ci></apply><csymbol cd="latexml" id="S5.T5.3.3.3.3.3.3.m1.1.1.3.cmml" xref="S5.T5.3.3.3.3.3.3.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T5.3.3.3.3.3.3.m1.1c">(mm)\downarrow</annotation></semantics></math></span></span>
<span id="S5.T5.3.3.3.3.4" class="ltx_tr">
<span id="S5.T5.3.3.3.3.4.1" class="ltx_td ltx_align_center ltx_border_ll ltx_border_tt">Scratch</span>
<span id="S5.T5.3.3.3.3.4.2" class="ltx_td ltx_align_center ltx_border_tt">1.83</span>
<span id="S5.T5.3.3.3.3.4.3" class="ltx_td ltx_align_center ltx_border_tt">0.74</span>
<span id="S5.T5.3.3.3.3.4.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_tt"><span id="S5.T5.3.3.3.3.4.4.1" class="ltx_text ltx_font_bold">1303</span></span></span>
<span id="S5.T5.3.3.3.3.5" class="ltx_tr">
<span id="S5.T5.3.3.3.3.5.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_ll">+ <span id="S5.T5.3.3.3.3.5.1.1" class="ltx_text ltx_font_italic">EgoGen</span>Â pretrain</span>
<span id="S5.T5.3.3.3.3.5.2" class="ltx_td ltx_align_center ltx_border_b"><span id="S5.T5.3.3.3.3.5.2.1" class="ltx_text ltx_font_bold">1.67</span></span>
<span id="S5.T5.3.3.3.3.5.3" class="ltx_td ltx_align_center ltx_border_b"><span id="S5.T5.3.3.3.3.5.3.1" class="ltx_text ltx_font_bold">0.62</span></span>
<span id="S5.T5.3.3.3.3.5.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_rr">1305</span></span>
</span></span></p>
</span></div>
</figure>
<div id="S5.SS4.p3" class="ltx_para ltx_noindent">
<p id="S5.SS4.p3.2" class="ltx_p"><span id="S5.SS4.p3.2.1" class="ltx_text ltx_font_bold">Egocentric camera tracking.</span>

Egocentric camera tracking for HMD aims to yield device pose trajectories in 3D scenes given egocentric video observations.
Recovering camera poses from monocular RGB videos using SLAM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib101" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">101</span></a>]</cite> is a challenging and ill-posed problem due to scale ambiguity. EgoEgo <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">47</span></a>]</cite> leverages the knowledge of human motion to address the egocentric HMD tracking problem. Specifically, EgoEgo trains a
neural network to infer the translation scaling and rotations from egocentric videos, which improves the HMD tracking performance.
However, training this model requires jointly captured data of ground truth HMD trajectories and egocentric videos, which are costly to collect.
We address this limitation by using <span id="S5.SS4.p3.2.2" class="ltx_text ltx_font_italic">EgoGen</span>Â to synthesize quantities of egocentric videos with accurate camera trajectories to pretrain the model, which proves to improve the tracking performance on real data.
We conduct experiments on the GIMO <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib131" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">131</span></a>]</cite> dataset that contains <math id="S5.SS4.p3.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S5.SS4.p3.1.m1.1a"><mo id="S5.SS4.p3.1.m1.1.1" xref="S5.SS4.p3.1.m1.1.1.cmml">âˆ¼</mo><annotation-xml encoding="MathML-Content" id="S5.SS4.p3.1.m1.1b"><csymbol cd="latexml" id="S5.SS4.p3.1.m1.1.1.cmml" xref="S5.SS4.p3.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p3.1.m1.1c">\sim</annotation></semantics></math>200 short sequences of paired motion-video data in 19 scenes.
UsingÂ <span id="S5.SS4.p3.2.3" class="ltx_text ltx_font_italic">EgoGen</span>, we synthesize <math id="S5.SS4.p3.2.m2.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S5.SS4.p3.2.m2.1a"><mo id="S5.SS4.p3.2.m2.1.1" xref="S5.SS4.p3.2.m2.1.1.cmml">âˆ¼</mo><annotation-xml encoding="MathML-Content" id="S5.SS4.p3.2.m2.1b"><csymbol cd="latexml" id="S5.SS4.p3.2.m2.1.1.cmml" xref="S5.SS4.p3.2.m2.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p3.2.m2.1c">\sim</annotation></semantics></math>4k sequences of human movements in their scenes and render corresponding egocentric videos using the same camera intrinsic as GIMO and the embodied camera placement described in Sec.Â <a href="#S4.SS1" title="4.1 Embodied Camera Placement â€£ 4 Egocentric Synthetic Data Generation â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>.
We also slightly perturb the camera placement location and orientation to simulate the diversity of how people wear HMDs in real data and avoid overfitting to one specific camera placement.
We first pretrain the model with synthetic data generated by <span id="S5.SS4.p3.2.4" class="ltx_text ltx_font_italic">EgoGen</span>, then finetune it on the real GIMO data.
Tab.Â <a href="#S5.T5" title="Table 5 â€£ 5.4 Mapping, Localization, and Tracking for HMD â€£ 5 Experiments â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> shows the egocentric camera tracking performances for models trained with and without synthetic data.
Definitions of evaluation metrics can be found in <a href="#S5.SS2a" title="S5.2 Egocentric Camera Tracking â€£ S5 Egocentric Perception Tasks â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Sec.</span>Â <span class="ltx_text ltx_ref_tag">S5.2</span></a>.
The finetuned model benefits from <span id="S5.SS4.p3.2.5" class="ltx_text ltx_font_italic">EgoGen</span>Â synthetic data and predicts more accurate camera poses compared to the model trained using real data only.</p>
</div>
</section>
<section id="S5.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.5 </span>Human Mesh Recovery from Egocentric views</h3>

<div id="S5.SS5.p1" class="ltx_para">
<p id="S5.SS5.p1.4" class="ltx_p">Human mesh recovery (HMR) is the key to human behavior understanding from the egocentric view, thus crucial for applications in robotics and AR/VR. Given an egocentric RGB or depth image of a target subject, HMR aims to reconstruct the subjectâ€™s 3D body pose and shape.
However, acquiring and annotating real-world data is expensive, demanding, and time-consuming, with egocentric data being particularly scarce.
EgoBodyÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib125" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">125</span></a>]</cite> is a recent egocentric dataset capturing two-people interactions, with egocentric depth/RGB frames annotated with SMPL-X body meshes. EgoBody provides <math id="S5.SS5.p1.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S5.SS5.p1.1.m1.1a"><mo id="S5.SS5.p1.1.m1.1.1" xref="S5.SS5.p1.1.m1.1.1.cmml">âˆ¼</mo><annotation-xml encoding="MathML-Content" id="S5.SS5.p1.1.m1.1b"><csymbol cd="latexml" id="S5.SS5.p1.1.m1.1.1.cmml" xref="S5.SS5.p1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p1.1.m1.1c">\sim</annotation></semantics></math>180k egocentric RGB frames, and merely <math id="S5.SS5.p1.2.m2.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S5.SS5.p1.2.m2.1a"><mo id="S5.SS5.p1.2.m2.1.1" xref="S5.SS5.p1.2.m2.1.1.cmml">âˆ¼</mo><annotation-xml encoding="MathML-Content" id="S5.SS5.p1.2.m2.1b"><csymbol cd="latexml" id="S5.SS5.p1.2.m2.1.1.cmml" xref="S5.SS5.p1.2.m2.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p1.2.m2.1c">\sim</annotation></semantics></math>23k depth frames due to the low frame rate of the depth sensor, with <math id="S5.SS5.p1.3.m3.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S5.SS5.p1.3.m3.1a"><mo id="S5.SS5.p1.3.m3.1.1" xref="S5.SS5.p1.3.m3.1.1.cmml">âˆ¼</mo><annotation-xml encoding="MathML-Content" id="S5.SS5.p1.3.m3.1b"><csymbol cd="latexml" id="S5.SS5.p1.3.m3.1.1.cmml" xref="S5.SS5.p1.3.m3.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p1.3.m3.1c">\sim</annotation></semantics></math>90k/<math id="S5.SS5.p1.4.m4.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S5.SS5.p1.4.m4.1a"><mo id="S5.SS5.p1.4.m4.1.1" xref="S5.SS5.p1.4.m4.1.1.cmml">âˆ¼</mo><annotation-xml encoding="MathML-Content" id="S5.SS5.p1.4.m4.1b"><csymbol cd="latexml" id="S5.SS5.p1.4.m4.1.1.cmml" xref="S5.SS5.p1.4.m4.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p1.4.m4.1c">\sim</annotation></semantics></math>10k in the RGB/depth training set. Such limited data is insufficient to train a learning-based model from scratch.
In contrast, with <span id="S5.SS5.p1.4.1" class="ltx_text ltx_font_italic">EgoGen</span>,
large-scale synthetic egocentric data can be generated in a time-efficient way.
We leverage <span id="S5.SS5.p1.4.2" class="ltx_text ltx_font_italic">EgoGen</span>Â to generate quantities of training frames (300k RGB, 105k depth) of humans moving in EgoBody 3D scenes, rendered from the egocentric view, and annotated by SMPL-X parameters of the target subject. Specifically, RGB images are rendered with lifelike human body textures and 3D clothing, with random lighting.</p>
</div>
<div id="S5.SS5.p2" class="ltx_para">
<p id="S5.SS5.p2.1" class="ltx_p">With the recent HMR regressor, ProHMRÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">45</span></a>]</cite>, we show that pre-training with our synthetic data from <span id="S5.SS5.p2.1.1" class="ltx_text ltx_font_italic">EgoGen</span>Â enhances the existing methodâ€™s capability to generalize on real-world scenarios.
Evaluated on the real-world EgoBody test set, we compare two training schemes: (1) trained from scratch on the real-world EgoBody training set (â€œ-scratchâ€), and (2) pre-trained on synthetic data from <span id="S5.SS5.p2.1.2" class="ltx_text ltx_font_italic">EgoGen</span>Â and fine-tuned on the real-world EgoBody training set (â€œ-ftâ€).</p>
</div>
<div id="S5.SS5.p3" class="ltx_para">
<p id="S5.SS5.p3.1" class="ltx_p"><span id="S5.SS5.p3.1.1" class="ltx_text ltx_font_bold">HMR from depth.</span>
As no existing methods were proposed for depth-based HMR task, we adapt ProHMRÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">45</span></a>]</cite> to the depth input by changing the channel number of the first convolution layer.
To mimic real-world sensor noise, synthetic noiseÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">31</span></a>]</cite> is added to the rendered depth.
G-MPJPE is additionally reported for depth-based HMR as depth images provide global information.
As shown in Tab.Â <a href="#S5.T6" title="Table 6 â€£ 5.5 Human Mesh Recovery from Egocentric views â€£ 5 Experiments â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>, compared to the model trained only with a limited amount of real-world data (Depth-scratch), errors are significantly reduced for the model pre-trained with our large-scale synthetic data (Depth-ft), in terms of global translation (22.9% lower G-MPJPE), local pose (20.7% lower MPJPE), and body shape (19.5% lower V2V).</p>
</div>
<div id="S5.SS5.p4" class="ltx_para">
<p id="S5.SS5.p4.1" class="ltx_p"><span id="S5.SS5.p4.1.1" class="ltx_text ltx_font_bold">HMR from RGB.</span>
For training with RGB images, we apply various data augmentation techniques similar toÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">9</span></a>]</cite>.
Tab.Â <a href="#S5.T6" title="Table 6 â€£ 5.5 Human Mesh Recovery from Egocentric views â€£ 5 Experiments â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> indicates that the RGB-based model pre-trained with large-scale synthetic data (â€œRGB-ftâ€) also outperforms the model trained only on real-world data (â€œRGB-scratchâ€), for both body pose and shape accuracy.</p>
</div>
<div id="S5.SS5.p5" class="ltx_para">
<p id="S5.SS5.p5.1" class="ltx_p">The enhanced performance highlights that <span id="S5.SS5.p5.1.1" class="ltx_text ltx_font_italic">EgoGen</span>â€™s synthetic data effectively compensates for the lack of real-world training data, boosting the performance of current methods when test on real-world data. We will release both of our synthetic EgoBody datasets. See <a href="#S5.SS3a" title="S5.3 Human Mesh Recovery from Egocentric Views â€£ S5 Egocentric Perception Tasks â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Sec.</span>Â <span class="ltx_text ltx_ref_tag">S5.3</span></a> for dataset statistics, qualitative visualizations, and training details.</p>
</div>
<figure id="S5.T6" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S5.T6.8.1.1" class="ltx_text" style="font-size:90%;">Table 6</span>: </span><span id="S5.T6.9.2" class="ltx_text" style="font-size:90%;">Evaluation of HMR on EgoBody test set. â€œ*-scratchâ€ denotes the model trained from scratch with the Egobody training set, and â€œ*-ftâ€ denotes the model pre-trained with <span id="S5.T6.9.2.1" class="ltx_text ltx_font_italic">EgoGen</span>Â synthetic data. The units for all metrics are in <span id="S5.T6.9.2.2" class="ltx_text ltx_font_italic">mm</span>. (Sec.Â <a href="#S5.SS5" title="5.5 Human Mesh Recovery from Egocentric views â€£ 5 Experiments â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.5</span></a>)</span></figcaption>
<div id="S5.T6.4" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:311.0pt;height:90pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="S5.T6.4.4" class="ltx_p"><span id="S5.T6.4.4.4" class="ltx_text">
<span id="S5.T6.4.4.4.4" class="ltx_tabular ltx_align_middle">
<span id="S5.T6.4.4.4.4.4" class="ltx_tr">
<span id="S5.T6.4.4.4.4.4.5" class="ltx_td ltx_border_ll ltx_border_t"></span>
<span id="S5.T6.1.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t">G-MPJPE <math id="S5.T6.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T6.1.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S5.T6.1.1.1.1.1.1.m1.1.1" xref="S5.T6.1.1.1.1.1.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S5.T6.1.1.1.1.1.1.m1.1b"><ci id="S5.T6.1.1.1.1.1.1.m1.1.1.cmml" xref="S5.T6.1.1.1.1.1.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.1.1.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math></span>
<span id="S5.T6.2.2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_t">MPJPE <math id="S5.T6.2.2.2.2.2.2.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T6.2.2.2.2.2.2.m1.1a"><mo stretchy="false" id="S5.T6.2.2.2.2.2.2.m1.1.1" xref="S5.T6.2.2.2.2.2.2.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S5.T6.2.2.2.2.2.2.m1.1b"><ci id="S5.T6.2.2.2.2.2.2.m1.1.1.cmml" xref="S5.T6.2.2.2.2.2.2.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.2.2.2.2.2.2.m1.1c">\downarrow</annotation></semantics></math></span>
<span id="S5.T6.3.3.3.3.3.3" class="ltx_td ltx_align_center ltx_border_t">PA-MPJPE <math id="S5.T6.3.3.3.3.3.3.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T6.3.3.3.3.3.3.m1.1a"><mo stretchy="false" id="S5.T6.3.3.3.3.3.3.m1.1.1" xref="S5.T6.3.3.3.3.3.3.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S5.T6.3.3.3.3.3.3.m1.1b"><ci id="S5.T6.3.3.3.3.3.3.m1.1.1.cmml" xref="S5.T6.3.3.3.3.3.3.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.3.3.3.3.3.3.m1.1c">\downarrow</annotation></semantics></math></span>
<span id="S5.T6.4.4.4.4.4.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">V2V <math id="S5.T6.4.4.4.4.4.4.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T6.4.4.4.4.4.4.m1.1a"><mo stretchy="false" id="S5.T6.4.4.4.4.4.4.m1.1.1" xref="S5.T6.4.4.4.4.4.4.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S5.T6.4.4.4.4.4.4.m1.1b"><ci id="S5.T6.4.4.4.4.4.4.m1.1.1.cmml" xref="S5.T6.4.4.4.4.4.4.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.4.4.4.4.4.4.m1.1c">\downarrow</annotation></semantics></math></span></span>
<span id="S5.T6.4.4.4.4.5" class="ltx_tr">
<span id="S5.T6.4.4.4.4.5.1" class="ltx_td ltx_align_center ltx_border_ll ltx_border_tt">Depth-scratch</span>
<span id="S5.T6.4.4.4.4.5.2" class="ltx_td ltx_align_center ltx_border_tt">117.7</span>
<span id="S5.T6.4.4.4.4.5.3" class="ltx_td ltx_align_center ltx_border_tt">82.2</span>
<span id="S5.T6.4.4.4.4.5.4" class="ltx_td ltx_align_center ltx_border_tt">54.1</span>
<span id="S5.T6.4.4.4.4.5.5" class="ltx_td ltx_align_center ltx_border_rr ltx_border_tt">100.6</span></span>
<span id="S5.T6.4.4.4.4.6" class="ltx_tr">
<span id="S5.T6.4.4.4.4.6.1" class="ltx_td ltx_align_center ltx_border_ll">Depth-ft</span>
<span id="S5.T6.4.4.4.4.6.2" class="ltx_td ltx_align_center"><span id="S5.T6.4.4.4.4.6.2.1" class="ltx_text ltx_font_bold">90.7</span></span>
<span id="S5.T6.4.4.4.4.6.3" class="ltx_td ltx_align_center"><span id="S5.T6.4.4.4.4.6.3.1" class="ltx_text ltx_font_bold">65.2</span></span>
<span id="S5.T6.4.4.4.4.6.4" class="ltx_td ltx_align_center"><span id="S5.T6.4.4.4.4.6.4.1" class="ltx_text ltx_font_bold">47.3</span></span>
<span id="S5.T6.4.4.4.4.6.5" class="ltx_td ltx_align_center ltx_border_rr"><span id="S5.T6.4.4.4.4.6.5.1" class="ltx_text ltx_font_bold">81.0</span></span></span>
<span id="S5.T6.4.4.4.4.7" class="ltx_tr">
<span id="S5.T6.4.4.4.4.7.1" class="ltx_td ltx_align_center ltx_border_ll ltx_border_tt">RGB-scratch</span>
<span id="S5.T6.4.4.4.4.7.2" class="ltx_td ltx_align_center ltx_border_tt">-</span>
<span id="S5.T6.4.4.4.4.7.3" class="ltx_td ltx_align_center ltx_border_tt">90.7</span>
<span id="S5.T6.4.4.4.4.7.4" class="ltx_td ltx_align_center ltx_border_tt">59.9</span>
<span id="S5.T6.4.4.4.4.7.5" class="ltx_td ltx_align_center ltx_border_rr ltx_border_tt">102.1</span></span>
<span id="S5.T6.4.4.4.4.8" class="ltx_tr">
<span id="S5.T6.4.4.4.4.8.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_ll">RGB-ft</span>
<span id="S5.T6.4.4.4.4.8.2" class="ltx_td ltx_align_center ltx_border_b">-</span>
<span id="S5.T6.4.4.4.4.8.3" class="ltx_td ltx_align_center ltx_border_b"><span id="S5.T6.4.4.4.4.8.3.1" class="ltx_text ltx_font_bold">85.3</span></span>
<span id="S5.T6.4.4.4.4.8.4" class="ltx_td ltx_align_center ltx_border_b"><span id="S5.T6.4.4.4.4.8.4.1" class="ltx_text ltx_font_bold">56.2</span></span>
<span id="S5.T6.4.4.4.4.8.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_rr"><span id="S5.T6.4.4.4.4.8.5.1" class="ltx_text ltx_font_bold">97.2</span></span></span>
</span></span></p>
</span></div>
</figure>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">We propose a novel egocentric synthetic data generation approach, <span id="S6.p1.1.1" class="ltx_text ltx_font_italic">EgoGen</span>, that uses embodied sensors, a parametric body model, and a generative egocentric perception-driven human motion synthesis method to create egocentric training data with accurate and rich ground truth annotations.
By integrating deep reinforcement learning and collision-avoiding motion primitives with egocentric depth proxy, <span id="S6.p1.1.2" class="ltx_text ltx_font_italic">EgoGen</span>Â synthesizes robust human motion and emergent multi-agent behaviors. This paves the way to an efficient and scalable data generation solution that may have a profound impact on egocentric perception tasks.</p>
</div>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Future Work and Potentials</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">Human-scene interaction in <span id="S7.p1.1.1" class="ltx_text ltx_font_italic">EgoGen</span>Â is currently coarse. We aim to extend the current method to simulate more detailed human motion driven by egocentric perception, such as hand manipulation, sitting, lying, etc, to facilitate more realistic egocentric synthetic data.
We use fixed attention goals to model human attention.
Predicting human intention through historical egocentric perception and synthesizing viewing directions based on predicted intention holds significant potential.
Synthesizing gaze direction for predicting human intent is valuable but presently hampered by data requirements; we will revisit this when resources allow.</p>
</div>
<div id="S7.p2" class="ltx_para">
<p id="S7.p2.1" class="ltx_p">Egocentric perception tasks are broad. We will explore many other egocentric vision tasks with <span id="S7.p2.1.1" class="ltx_text ltx_font_italic">EgoGen</span>Â as this area grows rapidly such as social understanding and forecasting.</p>
</div>
<div id="S7.p3" class="ltx_para">
<p id="S7.p3.1" class="ltx_p"><span id="S7.p3.1.1" class="ltx_text ltx_font_italic">EgoGen</span>Â could also benefit human-robot interaction. For example, our generative human motion model and lifelike human appearances can be integrated into Habitat 3.0Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib73" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">73</span></a>]</cite> to further close the sim2real gap for robotic agents.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib1.4.4.1" class="ltx_text" style="font-size:90%;">Mes [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib1.6.1" class="ltx_text" style="font-size:90%;">
Meshcapade GmbH, TÃ¼bingen, Germany.
</span>
</span>
<span class="ltx_bibblock"><a target="_blank" href="https://meshcapade.com," title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://meshcapade.com,</a><span id="bib.bib1.7.1" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib2.5.5.1" class="ltx_text" style="font-size:90%;">Abdel-Wahab etÂ al. [2012]</span></span>
<span class="ltx_bibblock"><span id="bib.bib2.7.1" class="ltx_text" style="font-size:90%;">
Mohammed Abdel-Wahab, Konrad Wenzel, and Dieter Fritsch.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.8.1" class="ltx_text" style="font-size:90%;">Efficient reconstruction of large unordered image datasets for high accuracy photogrammetric applications.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib2.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences, Melbourne, Australia. XXII ISPRS Congress</em><span id="bib.bib2.11.3" class="ltx_text" style="font-size:90%;">, 2012.
</span>
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib3.5.5.1" class="ltx_text" style="font-size:90%;">Agarwal etÂ al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib3.7.1" class="ltx_text" style="font-size:90%;">
Ananye Agarwal, Ashish Kumar, Jitendra Malik, and Deepak Pathak.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.8.1" class="ltx_text" style="font-size:90%;">Legged locomotion in challenging terrains using egocentric vision.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib3.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Conference on Robot Learning, CoRL 2022, 14-18 December 2022, Auckland, New Zealand</em><span id="bib.bib3.11.3" class="ltx_text" style="font-size:90%;">, pages 403â€“415. PMLR, 2022.
</span>
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib4.5.5.1" class="ltx_text" style="font-size:90%;">Aivar etÂ al. [2008]</span></span>
<span class="ltx_bibblock"><span id="bib.bib4.7.1" class="ltx_text" style="font-size:90%;">
M.Â Pilar Aivar, Eli Brenner, and Jeroen B.Â J. Smeets.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.8.1" class="ltx_text" style="font-size:90%;">Avoiding moving obstacles.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib4.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Experimental Brain Research</em><span id="bib.bib4.10.2" class="ltx_text" style="font-size:90%;">, 190(3):251â€“264, 2008.
</span>
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib5.5.5.1" class="ltx_text" style="font-size:90%;">Akada etÂ al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib5.7.1" class="ltx_text" style="font-size:90%;">
Hiroyasu Akada, Jian Wang, Soshi Shimada, Masaki Takahashi, Christian Theobalt, and Vladislav Golyanik.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.8.1" class="ltx_text" style="font-size:90%;">Unrealego: A new dataset for robust egocentric 3d human motion capture.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib5.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">European Conference on Computer Vision (ECCV)</em><span id="bib.bib5.11.3" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib6.5.5.1" class="ltx_text" style="font-size:90%;">Andrychowicz etÂ al. [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib6.7.1" class="ltx_text" style="font-size:90%;">
Marcin Andrychowicz, Anton Raichuk, Piotr Stanczyk, Manu Orsini, Sertan Girgin, RaphaÃ«l Marinier, LÃ©onard Hussenot, Matthieu Geist, Olivier Pietquin, Marcin Michalski, Sylvain Gelly, and Olivier Bachem.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.8.1" class="ltx_text" style="font-size:90%;">What matters in on-policy reinforcement learning? A large-scale empirical study.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib6.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">CoRR</em><span id="bib.bib6.10.2" class="ltx_text" style="font-size:90%;">, abs/2006.05990, 2020.
</span>
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib7.4.4.1" class="ltx_text" style="font-size:90%;">Apple [2017]</span></span>
<span class="ltx_bibblock"><span id="bib.bib7.6.1" class="ltx_text" style="font-size:90%;">
Apple.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.7.1" class="ltx_text" style="font-size:90%;">ARKit.
</span>
</span>
<span class="ltx_bibblock"><a target="_blank" href="https://developer.apple.com/arkit/" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://developer.apple.com/arkit/</a><span id="bib.bib7.8.1" class="ltx_text" style="font-size:90%;">, 2017.
</span>
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib8.5.5.1" class="ltx_text" style="font-size:90%;">Baltodano etÂ al. [2015]</span></span>
<span class="ltx_bibblock"><span id="bib.bib8.7.1" class="ltx_text" style="font-size:90%;">
Sonia Baltodano, Srinath Sibi, Nikolas Martelaro, Nikhil Gowda, and Wendy Ju.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.8.1" class="ltx_text" style="font-size:90%;">The rrads platform: a real road autonomous driving simulator.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib8.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the 7th International Conference on Automotive User Interfaces and Interactive Vehicular Applications</em><span id="bib.bib8.11.3" class="ltx_text" style="font-size:90%;">, pages 281â€“288, 2015.
</span>
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib9.5.5.1" class="ltx_text" style="font-size:90%;">Black etÂ al. [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib9.7.1" class="ltx_text" style="font-size:90%;">
MichaelÂ J. Black, Priyanka Patel, Joachim Tesch, and Jinlong Yang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.8.1" class="ltx_text" style="font-size:90%;">BEDLAM: A synthetic dataset of bodies exhibiting detailed lifelike animated motion.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib9.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings IEEE/CVF Conf. on Computer Vision and Pattern Recognition (CVPR)</em><span id="bib.bib9.11.3" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib10.5.5.1" class="ltx_text" style="font-size:90%;">Bogo etÂ al. [2016]</span></span>
<span class="ltx_bibblock"><span id="bib.bib10.7.1" class="ltx_text" style="font-size:90%;">
Federica Bogo, Angjoo Kanazawa, Christoph Lassner, Peter Gehler, Javier Romero, and MichaelÂ J. Black.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.8.1" class="ltx_text" style="font-size:90%;">Keep it SMPL: Automatic estimation of 3D human pose and shape from a single image.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib10.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">European Conference on Computer Vision</em><span id="bib.bib10.11.3" class="ltx_text" style="font-size:90%;">, pages 561â€“578, 2016.
</span>
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib11.5.5.1" class="ltx_text" style="font-size:90%;">Cai etÂ al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib11.7.1" class="ltx_text" style="font-size:90%;">
Zhongang Cai, Mingyuan Zhang, Jiawei Ren, Chen Wei, Daxuan Ren, Zhengyu Lin, Haiyu Zhao, Lei Yang, and Ziwei Liu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.8.1" class="ltx_text" style="font-size:90%;">Playing for 3d human recovery.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib11.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2110.07588</em><span id="bib.bib11.10.2" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib12.4.4.1" class="ltx_text" style="font-size:90%;">Clavet [2016]</span></span>
<span class="ltx_bibblock"><span id="bib.bib12.6.1" class="ltx_text" style="font-size:90%;">
Simon Clavet.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.7.1" class="ltx_text" style="font-size:90%;">Motion matching and the road to next-gen animation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.8.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib12.9.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proc. of GDC</em><span id="bib.bib12.10.3" class="ltx_text" style="font-size:90%;">, 2016.
</span>
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib13.4.4.1" class="ltx_text" style="font-size:90%;">Community [2018]</span></span>
<span class="ltx_bibblock"><span id="bib.bib13.6.1" class="ltx_text" style="font-size:90%;">
BlenderÂ Online Community.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib13.7.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Blender - a 3D modelling and rendering package</em><span id="bib.bib13.8.2" class="ltx_text" style="font-size:90%;">.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.9.1" class="ltx_text" style="font-size:90%;">Blender Foundation, Stichting Blender Foundation, Amsterdam, 2018.
</span>
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib14.4.4.1" class="ltx_text" style="font-size:90%;">Coumans and Bai [2016â€“2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib14.6.1" class="ltx_text" style="font-size:90%;">
Erwin Coumans and Yunfei Bai.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.7.1" class="ltx_text" style="font-size:90%;">Pybullet, a python module for physics simulation for games, robotics and machine learning.
</span>
</span>
<span class="ltx_bibblock"><a target="_blank" href="http://pybullet.org" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">http://pybullet.org</a><span id="bib.bib14.8.1" class="ltx_text" style="font-size:90%;">, 2016â€“2021.
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib15.5.5.1" class="ltx_text" style="font-size:90%;">Damen etÂ al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib15.7.1" class="ltx_text" style="font-size:90%;">
Dima Damen, Hazel Doughty, GiovanniÂ Maria Farinella, Sanja Fidler, Antonino Furnari, Evangelos Kazakos, Davide Moltisanti, Jonathan Munro, Toby Perrett, Will Price, and Michael Wray.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.8.1" class="ltx_text" style="font-size:90%;">The epic-kitchens dataset: Collection, challenges and baselines.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib15.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</em><span id="bib.bib15.10.2" class="ltx_text" style="font-size:90%;">, 43(11):4125â€“4141, 2021.
</span>
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib16.4.4.1" class="ltx_text" style="font-size:90%;">Davison [2003]</span></span>
<span class="ltx_bibblock"><span id="bib.bib16.6.1" class="ltx_text" style="font-size:90%;">
AndrewÂ J. Davison.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.7.1" class="ltx_text" style="font-size:90%;">Real-time simultaneous localisation and mapping with a single camera.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.8.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib16.9.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">ICCV</em><span id="bib.bib16.10.3" class="ltx_text" style="font-size:90%;">, 2003.
</span>
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib17.5.5.1" class="ltx_text" style="font-size:90%;">DeTone etÂ al. [2018]</span></span>
<span class="ltx_bibblock"><span id="bib.bib17.7.1" class="ltx_text" style="font-size:90%;">
Daniel DeTone, Tomasz Malisiewicz, and Andrew Rabinovich.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.8.1" class="ltx_text" style="font-size:90%;">Superpoint: Self-supervised interest point detection and description, 2018.
</span>
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib18.5.5.1" class="ltx_text" style="font-size:90%;">Dosovitskiy etÂ al. [2017]</span></span>
<span class="ltx_bibblock"><span id="bib.bib18.7.1" class="ltx_text" style="font-size:90%;">
Alexey Dosovitskiy, German Ros, Felipe Codevilla, Antonio Lopez, and Vladlen Koltun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.8.1" class="ltx_text" style="font-size:90%;">Carla: An open urban driving simulator, 2017.
</span>
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib19.5.5.1" class="ltx_text" style="font-size:90%;">ErfanianÂ Ebadi etÂ al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib19.7.1" class="ltx_text" style="font-size:90%;">
Salehe ErfanianÂ Ebadi, Saurav Dhakad, Sanjay Vishwakarma, Chunpu Wang, You-Cyuan Jhang, Maciek Chociej, Adam Crespi, Alex Thaman, and Sujoy Ganguly.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.8.1" class="ltx_text" style="font-size:90%;">Psp-hdri+: A synthetic dataset generator for pre-training of human-centric computer vision models.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib19.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">First Workshop on Pre-training: Perspectives, Pitfalls, and Paths Forward at ICML 2022</em><span id="bib.bib19.11.3" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib20.5.5.1" class="ltx_text" style="font-size:90%;">Fabbri etÂ al. [2018]</span></span>
<span class="ltx_bibblock"><span id="bib.bib20.7.1" class="ltx_text" style="font-size:90%;">
Matteo Fabbri, Fabio Lanzi, Simone Calderara, Andrea Palazzi, Roberto Vezzani, and Rita Cucchiara.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.8.1" class="ltx_text" style="font-size:90%;">Learning to detect and track visible and occluded body joints in a virtual world.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib20.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">European Conference on Computer Vision (ECCV)</em><span id="bib.bib20.11.3" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib21.5.5.1" class="ltx_text" style="font-size:90%;">Fiannaca etÂ al. [2014]</span></span>
<span class="ltx_bibblock"><span id="bib.bib21.7.1" class="ltx_text" style="font-size:90%;">
Alexander Fiannaca, Ilias Apostolopoulous, and Eelke Folmer.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.8.1" class="ltx_text" style="font-size:90%;">Headlock: A wearable navigation aid that helps blind cane users traverse large open spaces.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib21.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the 16th international ACM SIGACCESS conference on Computers &amp; accessibility</em><span id="bib.bib21.11.3" class="ltx_text" style="font-size:90%;">, pages 19â€“26, 2014.
</span>
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib22.5.5.1" class="ltx_text" style="font-size:90%;">Gao etÂ al. [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib22.7.1" class="ltx_text" style="font-size:90%;">
Xiaofeng Gao, Ran Gong, Tianmin Shu, Xu Xie, Shu Wang, and Song-Chun Zhu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.8.1" class="ltx_text" style="font-size:90%;">Vrkitchen: an interactive 3d virtual environment for task-oriented learning.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib22.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv</em><span id="bib.bib22.10.2" class="ltx_text" style="font-size:90%;">, abs/1903.05757, 2019.
</span>
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib23.5.5.1" class="ltx_text" style="font-size:90%;">Ghodsi etÂ al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib23.7.1" class="ltx_text" style="font-size:90%;">
Zahra Ghodsi, Siva KumarÂ Sastry Hari, Iuri Frosio, Timothy Tsai, Alejandro Troccoli, StephenÂ W. Keckler, Siddharth Garg, and Anima Anandkumar.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.8.1" class="ltx_text" style="font-size:90%;">Generating and characterizing scenarios for safety testing of autonomous vehicles, 2021.
</span>
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib24.4.4.1" class="ltx_text" style="font-size:90%;">Google [2018]</span></span>
<span class="ltx_bibblock"><span id="bib.bib24.6.1" class="ltx_text" style="font-size:90%;">
Google.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.7.1" class="ltx_text" style="font-size:90%;">ARCore.
</span>
</span>
<span class="ltx_bibblock"><a target="_blank" href="https://developers.google.com/ar/" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://developers.google.com/ar/</a><span id="bib.bib24.8.1" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib25.4.4.1" class="ltx_text" style="font-size:90%;">Govindu [2001]</span></span>
<span class="ltx_bibblock"><span id="bib.bib25.6.1" class="ltx_text" style="font-size:90%;">
VenuÂ Madhav Govindu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.7.1" class="ltx_text" style="font-size:90%;">Combining two-view constraints for motion estimation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.8.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib25.9.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">CVPR</em><span id="bib.bib25.10.3" class="ltx_text" style="font-size:90%;">, 2001.
</span>
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib26.5.5.1" class="ltx_text" style="font-size:90%;">Grauman etÂ al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib26.7.1" class="ltx_text" style="font-size:90%;">
Kristen Grauman, Andrew Westbury, Eugene Byrne, Zachary Chavis, Antonino Furnari, Rohit Girdhar, Jackson Hamburger, Hao Jiang, Miao Liu, Xingyu Liu, Miguel Martin, Tushar Nagarajan, Ilija Radosavovic, SanthoshÂ Kumar Ramakrishnan, Fiona Ryan, Jayant Sharma, Michael Wray, Mengmeng Xu, EricÂ Zhongcong Xu, Chen Zhao, Siddhant Bansal, Dhruv Batra, Vincent Cartillier, Sean Crane, Tien Do, Morrie Doulaty, Akshay Erapalli, Christoph Feichtenhofer, Adriano Fragomeni, Qichen Fu, Christian Fuegen, Abrham Gebreselasie, Cristina Gonzalez, James Hillis, Xuhua Huang, Yifei Huang, Wenqi Jia, Weslie Khoo, Jachym Kolar, Satwik Kottur, Anurag Kumar, Federico Landini, Chao Li, Yanghao Li, Zhenqiang Li, Karttikeya Mangalam, Raghava Modhugu, Jonathan Munro, Tullie Murrell, Takumi Nishiyasu, Will Price, PaolaÂ Ruiz Puentes, Merey Ramazanova, Leda Sari, Kiran Somasundaram, Audrey Southerland, Yusuke Sugano, Ruijie Tao, Minh Vo, Yuchen Wang, Xindi Wu, Takuma Yagi, Yunyi Zhu, Pablo Arbelaez, David Crandall, Dima Damen, GiovanniÂ Maria
Farinella, Bernard Ghanem, VamsiÂ Krishna Ithapu, C.Â V. Jawahar, Hanbyul Joo, Kris Kitani, Haizhou Li, Richard Newcombe, Aude Oliva, HyunÂ Soo Park, JamesÂ M. Rehg, Yoichi Sato, Jianbo Shi, MikeÂ Zheng Shou, Antonio Torralba, Lorenzo Torresani, Mingfei Yan, and Jitendra Malik.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.8.1" class="ltx_text" style="font-size:90%;">Ego4d: Around the World in 3,000 Hours of Egocentric Video.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib26.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE/CVF Computer Vision and Pattern Recognition (CVPR)</em><span id="bib.bib26.11.3" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib27.5.5.1" class="ltx_text" style="font-size:90%;">Greff etÂ al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib27.7.1" class="ltx_text" style="font-size:90%;">
Klaus Greff, Francois Belletti, Lucas Beyer, Carl Doersch, Yilun Du, Daniel Duckworth, DavidÂ J. Fleet, Dan Gnanapragasam, Florian Golemo, Charles Herrmann, Thomas Kipf, Abhijit Kundu, Dmitry Lagun, IssamÂ H. Laradji, Hsueh-TiÂ Derek Liu, Henning Meyer, Yishu Miao, Derek Nowrouzezahrai, A.Â Cengiz Ã–ztireli, Etienne Pot, Noha Radwan, Daniel Rebain, Sara Sabour, Mehdi S.Â M. Sajjadi, Matan Sela, Vincent Sitzmann, Austin Stone, Deqing Sun, Suhani Vora, Ziyu Wang, Tianhao Wu, KwangÂ Moo Yi, Fangcheng Zhong, and Andrea Tagliasacchi.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.8.1" class="ltx_text" style="font-size:90%;">Kubric: A scalable dataset generator.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib27.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2022, New Orleans, LA, USA, June 18-24, 2022</em><span id="bib.bib27.11.3" class="ltx_text" style="font-size:90%;">, pages 3739â€“3751. IEEE, 2022.
</span>
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib28.5.5.1" class="ltx_text" style="font-size:90%;">Grigorev etÂ al. [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib28.7.1" class="ltx_text" style="font-size:90%;">
Artur Grigorev, MichaelÂ J. Black, and Otmar Hilliges.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.8.1" class="ltx_text" style="font-size:90%;">HOOD: hierarchical graphs for generalized modelling of clothing dynamics.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib28.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2023, Vancouver, BC, Canada, June 17-24, 2023</em><span id="bib.bib28.11.3" class="ltx_text" style="font-size:90%;">, pages 16965â€“16974. IEEE, 2023.
</span>
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib29.5.5.1" class="ltx_text" style="font-size:90%;">Guzov etÂ al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib29.7.1" class="ltx_text" style="font-size:90%;">
Vladimir Guzov, Aymen Mir, Torsten Sattler, and Gerard Pons-Moll.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.8.1" class="ltx_text" style="font-size:90%;">Human poseitioning system (hps): 3d human pose estimation and self-localization in large scenes from body-mounted sensors.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib29.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em><span id="bib.bib29.11.3" class="ltx_text" style="font-size:90%;">, pages 4318â€“4329, 2021.
</span>
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib30.5.5.1" class="ltx_text" style="font-size:90%;">Haala etÂ al. [2012]</span></span>
<span class="ltx_bibblock"><span id="bib.bib30.7.1" class="ltx_text" style="font-size:90%;">
Norbert Haala, Michael Cramer, Florian Weimer, and Martin Trittler.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.8.1" class="ltx_text" style="font-size:90%;">Performance test on uav-based photogrammetric data collection.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib30.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences</em><span id="bib.bib30.10.2" class="ltx_text" style="font-size:90%;">, 2012.
</span>
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib31.5.5.1" class="ltx_text" style="font-size:90%;">Handa etÂ al. [2014]</span></span>
<span class="ltx_bibblock"><span id="bib.bib31.7.1" class="ltx_text" style="font-size:90%;">
Ankur Handa, Thomas Whelan, John McDonald, and AndrewÂ J Davison.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.8.1" class="ltx_text" style="font-size:90%;">A benchmark for rgb-d visual odometry, 3d reconstruction and slam.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib31.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">ICRA</em><span id="bib.bib31.10.2" class="ltx_text" style="font-size:90%;">, 2014.
</span>
</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib32.5.5.1" class="ltx_text" style="font-size:90%;">Haque etÂ al. [2016]</span></span>
<span class="ltx_bibblock"><span id="bib.bib32.7.1" class="ltx_text" style="font-size:90%;">
Albert Haque, Boya Peng, Zelun Luo, Alexandre Alahi, Serena Yeung, and Li Fei-Fei.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.8.1" class="ltx_text" style="font-size:90%;">Towards viewpoint invariant 3d human pose estimation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib32.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Computer Visionâ€“ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11â€“14, 2016, Proceedings, Part I 14</em><span id="bib.bib32.11.3" class="ltx_text" style="font-size:90%;">, pages 160â€“177. Springer, 2016.
</span>
</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib33.5.5.1" class="ltx_text" style="font-size:90%;">Hassan etÂ al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib33.7.1" class="ltx_text" style="font-size:90%;">
Mohamed Hassan, Duygu Ceylan, Ruben Villegas, Jun Saito, Jimei Yang, Yi Zhou, and Michael Black.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.8.1" class="ltx_text" style="font-size:90%;">Stochastic scene-aware motion prediction.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib33.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the International Conference on Computer Vision 2021</em><span id="bib.bib33.11.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib34.5.5.1" class="ltx_text" style="font-size:90%;">Hassan etÂ al. [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib34.7.1" class="ltx_text" style="font-size:90%;">
Mohamed Hassan, Yunrong Guo, Tingwu Wang, Michael Black, Sanja Fidler, and XueÂ Bin Peng.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.8.1" class="ltx_text" style="font-size:90%;">Synthesizing physical character-scene interactions.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib34.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2302.00883</em><span id="bib.bib34.10.2" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib35.5.5.1" class="ltx_text" style="font-size:90%;">Holden etÂ al. [2017]</span></span>
<span class="ltx_bibblock"><span id="bib.bib35.7.1" class="ltx_text" style="font-size:90%;">
Daniel Holden, Taku Komura, and Jun Saito.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.8.1" class="ltx_text" style="font-size:90%;">Phase-functioned neural networks for character control.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib35.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">ACM Trans. Graph.</em><span id="bib.bib35.10.2" class="ltx_text" style="font-size:90%;">, 36(4):1â€“13, 2017.
</span>
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib36.5.5.1" class="ltx_text" style="font-size:90%;">Holden etÂ al. [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib36.7.1" class="ltx_text" style="font-size:90%;">
Daniel Holden, Oussama Kanoun, Maksym Perepichka, and Tiberiu Popa.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.8.1" class="ltx_text" style="font-size:90%;">Learned motion matching.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib36.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">ACM Transactions on Graphics (TOG)</em><span id="bib.bib36.10.2" class="ltx_text" style="font-size:90%;">, 39(4):53â€“1, 2020.
</span>
</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib37.5.5.1" class="ltx_text" style="font-size:90%;">Jin etÂ al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib37.7.1" class="ltx_text" style="font-size:90%;">
Yuhe Jin, Dmytro Mishkin, Anastasiia Mishchuk, Jiri Matas, Pascal Fua, KwangÂ Moo Yi, and Eduard Trulls.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.8.1" class="ltx_text" style="font-size:90%;">Image Matching across Wide Baselines: From Paper to Practice.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib37.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">IJCV</em><span id="bib.bib37.10.2" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib38.4.4.1" class="ltx_text" style="font-size:90%;">Kamath [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib38.6.1" class="ltx_text" style="font-size:90%;">
Neena Kamath.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.7.1" class="ltx_text" style="font-size:90%;">Announcing Azure Spatial Anchors for collaborative, cross-platform mixed reality apps.
</span>
</span>
<span class="ltx_bibblock"><a target="_blank" href="https://azure.microsoft.com/en-us/blog/announcing-azure-spatial-anchors-for-collaborative-cross-platform-mixed-reality-apps/" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://azure.microsoft.com/en-us/blog/announcing-azure-spatial-anchors-for-collaborative-cross-platform-mixed-reality-apps/</a><span id="bib.bib38.8.1" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib39.5.5.1" class="ltx_text" style="font-size:90%;">Kanazawa etÂ al. [2018]</span></span>
<span class="ltx_bibblock"><span id="bib.bib39.7.1" class="ltx_text" style="font-size:90%;">
Angjoo Kanazawa, MichaelÂ J Black, DavidÂ W Jacobs, and Jitendra Malik.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.8.1" class="ltx_text" style="font-size:90%;">End-to-end recovery of human shape and pose.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib39.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</em><span id="bib.bib39.11.3" class="ltx_text" style="font-size:90%;">, pages 7122â€“7131, 2018.
</span>
</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib40.5.5.1" class="ltx_text" style="font-size:90%;">Kendall etÂ al. [2015]</span></span>
<span class="ltx_bibblock"><span id="bib.bib40.7.1" class="ltx_text" style="font-size:90%;">
Alex Kendall, Matthew Grimes, and Roberto Cipolla.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.8.1" class="ltx_text" style="font-size:90%;">PoseNet: A Convolutional Network for Real-Time 6-DoF Camera Relocalization.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib40.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">ICCV</em><span id="bib.bib40.11.3" class="ltx_text" style="font-size:90%;">, 2015.
</span>
</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib41.4.4.1" class="ltx_text" style="font-size:90%;">Klein and Murray [2007]</span></span>
<span class="ltx_bibblock"><span id="bib.bib41.6.1" class="ltx_text" style="font-size:90%;">
Georg Klein and David Murray.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.7.1" class="ltx_text" style="font-size:90%;">Parallel tracking and mapping for small ar workspaces.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.8.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib41.9.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE and ACM International Symposium on Mixed and Augmented Reality</em><span id="bib.bib41.10.3" class="ltx_text" style="font-size:90%;">, 2007.
</span>
</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib42.5.5.1" class="ltx_text" style="font-size:90%;">Kocabas etÂ al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib42.7.1" class="ltx_text" style="font-size:90%;">
Muhammed Kocabas, Chun-HaoÂ P. Huang, Otmar Hilliges, and MichaelÂ J. Black.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.8.1" class="ltx_text" style="font-size:90%;">PARE: Part attention regressor for 3D human body estimation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib42.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings International Conference on Computer Vision (ICCV)</em><span id="bib.bib42.11.3" class="ltx_text" style="font-size:90%;">, pages 11127â€“11137. IEEE, 2021.
</span>
</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib43.5.5.1" class="ltx_text" style="font-size:90%;">Kolotouros etÂ al. [2019a]</span></span>
<span class="ltx_bibblock"><span id="bib.bib43.7.1" class="ltx_text" style="font-size:90%;">
Nikos Kolotouros, Georgios Pavlakos, MichaelÂ J Black, and Kostas Daniilidis.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.8.1" class="ltx_text" style="font-size:90%;">Learning to reconstruct 3D human pose and shape via model-fitting in the loop.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib43.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE International Conference on Computer Vision</em><span id="bib.bib43.11.3" class="ltx_text" style="font-size:90%;">, pages 2252â€“2261, 2019a.
</span>
</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib44.5.5.1" class="ltx_text" style="font-size:90%;">Kolotouros etÂ al. [2019b]</span></span>
<span class="ltx_bibblock"><span id="bib.bib44.7.1" class="ltx_text" style="font-size:90%;">
Nikos Kolotouros, Georgios Pavlakos, and Kostas Daniilidis.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib44.8.1" class="ltx_text" style="font-size:90%;">Convolutional mesh regression for single-image human shape reconstruction.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib44.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib44.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">CVPR</em><span id="bib.bib44.11.3" class="ltx_text" style="font-size:90%;">, 2019b.
</span>
</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib45.5.5.1" class="ltx_text" style="font-size:90%;">Kolotouros etÂ al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib45.7.1" class="ltx_text" style="font-size:90%;">
Nikos Kolotouros, Georgios Pavlakos, Dinesh Jayaraman, and Kostas Daniilidis.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib45.8.1" class="ltx_text" style="font-size:90%;">Probabilistic modeling for human mesh recovery.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib45.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib45.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF international conference on computer vision</em><span id="bib.bib45.11.3" class="ltx_text" style="font-size:90%;">, pages 11605â€“11614, 2021.
</span>
</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib46.5.5.1" class="ltx_text" style="font-size:90%;">Kovar etÂ al. [2008]</span></span>
<span class="ltx_bibblock"><span id="bib.bib46.7.1" class="ltx_text" style="font-size:90%;">
Lucas Kovar, Michael Gleicher, and FrÃ©dÃ©ricÂ H. Pighin.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib46.8.1" class="ltx_text" style="font-size:90%;">Motion graphs.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib46.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib46.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">International Conference on Computer Graphics and Interactive Techniques, SIGGRAPH 2008, Los Angeles, California, USA, August 11-15, 2008, Classes</em><span id="bib.bib46.11.3" class="ltx_text" style="font-size:90%;">, pages 51:1â€“51:10. ACM, 2008.
</span>
</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib47.5.5.1" class="ltx_text" style="font-size:90%;">Li etÂ al. [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib47.7.1" class="ltx_text" style="font-size:90%;">
Jiaman Li, C.Â Karen Liu, and Jiajun Wu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib47.8.1" class="ltx_text" style="font-size:90%;">Ego-body pose estimation via ego-head pose estimation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib47.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib47.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2023, Vancouver, BC, Canada, June 17-24, 2023</em><span id="bib.bib47.11.3" class="ltx_text" style="font-size:90%;">, pages 17142â€“17151. IEEE, 2023.
</span>
</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib48.5.5.1" class="ltx_text" style="font-size:90%;">Li etÂ al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib48.7.1" class="ltx_text" style="font-size:90%;">
Zhihao Li, Jianzhuang Liu, Zhensong Zhang, Songcen Xu, and Youliang Yan.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib48.8.1" class="ltx_text" style="font-size:90%;">CLIFF: Carrying location information in full frames into human pose and shape estimation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib48.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib48.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Computer Visionâ€“ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23â€“27, 2022, Proceedings, Part V</em><span id="bib.bib48.11.3" class="ltx_text" style="font-size:90%;">, pages 590â€“606. Springer, 2022.
</span>
</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib49.5.5.1" class="ltx_text" style="font-size:90%;">Ling etÂ al. [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib49.7.1" class="ltx_text" style="font-size:90%;">
HungÂ Yu Ling, Fabio Zinno, George Cheng, and Michiel vanÂ de Panne.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib49.8.1" class="ltx_text" style="font-size:90%;">Character controllers using motion vaes.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib49.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">ACM Trans. Graph.</em><span id="bib.bib49.10.2" class="ltx_text" style="font-size:90%;">, 39(4), 2020.
</span>
</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib50.5.5.1" class="ltx_text" style="font-size:90%;">Liu etÂ al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib50.7.1" class="ltx_text" style="font-size:90%;">
Miao Liu, Dexin Yang, Yan Zhang, Zhaopeng Cui, JamesÂ M Rehg, and Siyu Tang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib50.8.1" class="ltx_text" style="font-size:90%;">4d human body capture from egocentric video via 3d scene grounding.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib50.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib50.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2021 International Conference on 3D Vision (3DV)</em><span id="bib.bib50.11.3" class="ltx_text" style="font-size:90%;">, pages 930â€“939. IEEE, 2021.
</span>
</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib51.5.5.1" class="ltx_text" style="font-size:90%;">Luo etÂ al. [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib51.7.1" class="ltx_text" style="font-size:90%;">
Zhengyi Luo, Ryo Hachiuma, Ye Yuan, Shun Iwase, and KrisÂ M Kitani.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib51.8.1" class="ltx_text" style="font-size:90%;">Kinematics-guided reinforcement learning for object-aware 3d ego-pose estimation.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib51.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2011.04837</em><span id="bib.bib51.10.2" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib52.5.5.1" class="ltx_text" style="font-size:90%;">Mahmood etÂ al. [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib52.7.1" class="ltx_text" style="font-size:90%;">
Naureen Mahmood, Nima Ghorbani, NikolausÂ F Troje, Gerard Pons-Moll, and MichaelÂ J Black.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib52.8.1" class="ltx_text" style="font-size:90%;">Amass: Archive of motion capture as surface shapes.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib52.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib52.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF international conference on computer vision</em><span id="bib.bib52.11.3" class="ltx_text" style="font-size:90%;">, pages 5442â€“5451, 2019.
</span>
</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib53.5.5.1" class="ltx_text" style="font-size:90%;">MartÃ­nez-GonzÃ¡lez etÂ al. [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib53.7.1" class="ltx_text" style="font-size:90%;">
Angel MartÃ­nez-GonzÃ¡lez, Michael Villamizar, Olivier CanÃ©vet, and Jean-Marc Odobez.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib53.8.1" class="ltx_text" style="font-size:90%;">Residual pose: A decoupled approach for depth-based 3d human pose estimation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib53.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib53.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</em><span id="bib.bib53.11.3" class="ltx_text" style="font-size:90%;">, pages 10313â€“10318. IEEE, 2020.
</span>
</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib54.4.4.1" class="ltx_text" style="font-size:90%;">Meta [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib54.6.1" class="ltx_text" style="font-size:90%;">
Meta.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib54.7.1" class="ltx_text" style="font-size:90%;">Project Aria Glasses.
</span>
</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.projectaria.com/" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://www.projectaria.com/</a><span id="bib.bib54.8.1" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib55.4.4.1" class="ltx_text" style="font-size:90%;">Microsoft [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib55.6.1" class="ltx_text" style="font-size:90%;">
Microsoft.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib55.7.1" class="ltx_text" style="font-size:90%;">HoloLens 2.
</span>
</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.microsoft.com/en-us/hololens" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://www.microsoft.com/en-us/hololens</a><span id="bib.bib55.8.1" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib56.5.5.1" class="ltx_text" style="font-size:90%;">Mihajlovic etÂ al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib56.7.1" class="ltx_text" style="font-size:90%;">
Marko Mihajlovic, Shunsuke Saito, Aayush Bansal, Michael Zollhoefer, and Siyu Tang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib56.8.1" class="ltx_text" style="font-size:90%;">COAP: Compositional articulated occupancy of people.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib56.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib56.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</em><span id="bib.bib56.11.3" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib57.5.5.1" class="ltx_text" style="font-size:90%;">Mir etÂ al. [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib57.7.1" class="ltx_text" style="font-size:90%;">
Aymen Mir, Xavier Puig, Angjoo Kanazawa, and Gerard Pons-Moll.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib57.8.1" class="ltx_text" style="font-size:90%;">Generating continual human motion in diverse 3d scenes.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib57.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">CoRR</em><span id="bib.bib57.10.2" class="ltx_text" style="font-size:90%;">, abs/2304.02061, 2023.
</span>
</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib58.5.5.1" class="ltx_text" style="font-size:90%;">Montemerlo etÂ al. [2003]</span></span>
<span class="ltx_bibblock"><span id="bib.bib58.7.1" class="ltx_text" style="font-size:90%;">
Michael Montemerlo, Nicholas Roy, and Sebastian Thrun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib58.8.1" class="ltx_text" style="font-size:90%;">Perspectives on standardization in mobile robot programming: the carnegie mellon navigation (CARMEN) toolkit.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib58.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib58.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2003 IEEE/RSJ International Conference on Intelligent Robots and Systems, Las Vegas, Nevada, USA, October 27 - November 1, 2003</em><span id="bib.bib58.11.3" class="ltx_text" style="font-size:90%;">, pages 2436â€“2441. IEEE, 2003.
</span>
</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib59.5.5.1" class="ltx_text" style="font-size:90%;">Moon etÂ al. [2018]</span></span>
<span class="ltx_bibblock"><span id="bib.bib59.7.1" class="ltx_text" style="font-size:90%;">
Gyeongsik Moon, JuÂ Yong Chang, and KyoungÂ Mu Lee.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib59.8.1" class="ltx_text" style="font-size:90%;">V2v-posenet: Voxel-to-voxel prediction network for accurate 3d hand and human pose estimation from a single depth map.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib59.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib59.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE conference on computer vision and pattern Recognition</em><span id="bib.bib59.11.3" class="ltx_text" style="font-size:90%;">, pages 5079â€“5088, 2018.
</span>
</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib60.5.5.1" class="ltx_text" style="font-size:90%;">Mouragnon etÂ al. [2006]</span></span>
<span class="ltx_bibblock"><span id="bib.bib60.7.1" class="ltx_text" style="font-size:90%;">
Etienne Mouragnon, Maxime Lhuillier, Michel Dhome, Fabien Dekeyser, and Patrick Sayd.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib60.8.1" class="ltx_text" style="font-size:90%;">Real time localization and 3d reconstruction.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib60.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib60.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">CVPR</em><span id="bib.bib60.11.3" class="ltx_text" style="font-size:90%;">, 2006.
</span>
</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib61.5.5.1" class="ltx_text" style="font-size:90%;">Ng etÂ al. [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib61.7.1" class="ltx_text" style="font-size:90%;">
Evonne Ng, Donglai Xiang, Hanbyul Joo, and Kristen Grauman.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib61.8.1" class="ltx_text" style="font-size:90%;">You2me: Inferring body pose in egocentric video via first and second person interactions.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib61.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib61.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em><span id="bib.bib61.11.3" class="ltx_text" style="font-size:90%;">, pages 9890â€“9900, 2020.
</span>
</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib62.5.5.1" class="ltx_text" style="font-size:90%;">Ng etÂ al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib62.7.1" class="ltx_text" style="font-size:90%;">
Tony Ng, Adrian Lopez-Rodriguez, Vassileios Balntas, and Krystian Mikolajczyk.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib62.8.1" class="ltx_text" style="font-size:90%;">Reassessing the limitations of cnn methods for camera pose regression, 2021.
</span>
</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib63.4.4.1" class="ltx_text" style="font-size:90%;">Niantic [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib63.6.1" class="ltx_text" style="font-size:90%;">
Niantic.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib63.7.1" class="ltx_text" style="font-size:90%;">Niantic Expands Developer Platform and AR Tools with Niantic Lightship.
</span>
</span>
<span class="ltx_bibblock"><a target="_blank" href="https://nianticlabs.com/news/lightship/" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://nianticlabs.com/news/lightship/</a><span id="bib.bib63.8.1" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib64.5.5.1" class="ltx_text" style="font-size:90%;">NistÃ©r etÂ al. [2004]</span></span>
<span class="ltx_bibblock"><span id="bib.bib64.7.1" class="ltx_text" style="font-size:90%;">
David NistÃ©r, Oleg Naroditsky, and James Bergen.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib64.8.1" class="ltx_text" style="font-size:90%;">Visual odometry.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib64.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib64.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">CVPR</em><span id="bib.bib64.11.3" class="ltx_text" style="font-size:90%;">, 2004.
</span>
</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib65.5.5.1" class="ltx_text" style="font-size:90%;">Pan etÂ al. [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib65.7.1" class="ltx_text" style="font-size:90%;">
Xiaqing Pan, Nicholas Charron, Yongqian Yang, Scott Peters, Thomas Whelan, Chen Kong, OmkarÂ M. Parkhi, RichardÂ A. Newcombe, and CarlÂ Yuheng Ren.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib65.8.1" class="ltx_text" style="font-size:90%;">Aria digital twin: A new benchmark dataset for egocentric 3d machine perception.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib65.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">CoRR</em><span id="bib.bib65.10.2" class="ltx_text" style="font-size:90%;">, abs/2306.06362, 2023.
</span>
</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib66.5.5.1" class="ltx_text" style="font-size:90%;">Pardo etÂ al. [2018]</span></span>
<span class="ltx_bibblock"><span id="bib.bib66.7.1" class="ltx_text" style="font-size:90%;">
Fabio Pardo, Arash Tavakoli, Vitaly Levdik, and Petar Kormushev.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib66.8.1" class="ltx_text" style="font-size:90%;">Time limits in reinforcement learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib66.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib66.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the 35th International Conference on Machine Learning</em><span id="bib.bib66.11.3" class="ltx_text" style="font-size:90%;">, pages 4045â€“4054, StockholmsmÃ¤ssan, Stockholm Sweden, 2018. PMLR.
</span>
</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib67.5.5.1" class="ltx_text" style="font-size:90%;">Pavlakos etÂ al. [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib67.7.1" class="ltx_text" style="font-size:90%;">
Georgios Pavlakos, Vasileios Choutas, Nima Ghorbani, Timo Bolkart, Ahmed A.Â A. Osman, Dimitrios Tzionas, and MichaelÂ J. Black.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib67.8.1" class="ltx_text" style="font-size:90%;">Expressive body capture: 3D hands, face, and body from a single image.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib67.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib67.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</em><span id="bib.bib67.11.3" class="ltx_text" style="font-size:90%;">, pages 10975â€“10985, 2019.
</span>
</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib68.5.5.1" class="ltx_text" style="font-size:90%;">Peng etÂ al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib68.7.1" class="ltx_text" style="font-size:90%;">
XueÂ Bin Peng, Ze Ma, Pieter Abbeel, Sergey Levine, and Angjoo Kanazawa.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib68.8.1" class="ltx_text" style="font-size:90%;">Amp: Adversarial motion priors for stylized physics-based character control.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib68.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">ACM Transactions on Graphics (TOG)</em><span id="bib.bib68.10.2" class="ltx_text" style="font-size:90%;">, 40(4):1â€“20, 2021.
</span>
</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib69.5.5.1" class="ltx_text" style="font-size:90%;">Petrovich etÂ al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib69.7.1" class="ltx_text" style="font-size:90%;">
Mathis Petrovich, MichaelÂ J. Black, and GÃ¼l Varol.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib69.8.1" class="ltx_text" style="font-size:90%;">Action-conditioned 3d human motion synthesis with transformer vae, 2021.
</span>
</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib70.5.5.1" class="ltx_text" style="font-size:90%;">Pollefeys etÂ al. [2004]</span></span>
<span class="ltx_bibblock"><span id="bib.bib70.7.1" class="ltx_text" style="font-size:90%;">
Marc Pollefeys, Luc VanÂ Gool, Maarten Vergauwen, Frank Verbiest, Kurt Cornelis, Jan Tops, and Reinhard Koch.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib70.8.1" class="ltx_text" style="font-size:90%;">Visual modeling with a hand-held camera.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib70.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">IJCV</em><span id="bib.bib70.10.2" class="ltx_text" style="font-size:90%;">, 2004.
</span>
</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib71.5.5.1" class="ltx_text" style="font-size:90%;">Puig etÂ al. [2018]</span></span>
<span class="ltx_bibblock"><span id="bib.bib71.7.1" class="ltx_text" style="font-size:90%;">
Xavier Puig, Kevin Ra, Marko Boben, Jiaman Li, Tingwu Wang, Sanja Fidler, and Antonio Torralba.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib71.8.1" class="ltx_text" style="font-size:90%;">Virtualhome: Simulating household activities via programs.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib71.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib71.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</em><span id="bib.bib71.11.3" class="ltx_text" style="font-size:90%;">, pages 8494â€“8502, 2018.
</span>
</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib72.5.5.1" class="ltx_text" style="font-size:90%;">Puig etÂ al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib72.7.1" class="ltx_text" style="font-size:90%;">
Xavier Puig, Tianmin Shu, Shuang Li, Zilin Wang, Yuan-Hong Liao, JoshuaÂ B. Tenenbaum, Sanja Fidler, and Antonio Torralba.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib72.8.1" class="ltx_text" style="font-size:90%;">Watch-and-help: A challenge for social perception and human-{ai} collaboration.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib72.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib72.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">International Conference on Learning Representations</em><span id="bib.bib72.11.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib73.5.5.1" class="ltx_text" style="font-size:90%;">Puig etÂ al. [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib73.7.1" class="ltx_text" style="font-size:90%;">
Xavier Puig, Eric Undersander, Andrew Szot, MikaelÂ Dallaire Cote, Tsung-Yen Yang, Ruslan Partsey, Ruta Desai, AlexanderÂ William Clegg, Michal Hlavac, SoÂ Yeon Min, Vladimir Vondrus, ThÃ©ophile Gervet, Vincent-Pierre Berges, JohnÂ M. Turner, Oleksandr Maksymets, Zsolt Kira, Mrinal Kalakrishnan, Jitendra Malik, DevendraÂ Singh Chaplot, Unnat Jain, Dhruv Batra, Akshara Rai, and Roozbeh Mottaghi.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib73.8.1" class="ltx_text" style="font-size:90%;">Habitat 3.0: A co-habitat for humans, avatars and robots.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib73.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">CoRR</em><span id="bib.bib73.10.2" class="ltx_text" style="font-size:90%;">, abs/2310.13724, 2023.
</span>
</span>
</li>
<li id="bib.bib74" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib74.5.5.1" class="ltx_text" style="font-size:90%;">Pumarola etÂ al. [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib74.7.1" class="ltx_text" style="font-size:90%;">
Albert Pumarola, Jordi Sanchez, Gary Choi, Alberto Sanfeliu, and Francesc Moreno-Noguer.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib74.8.1" class="ltx_text" style="font-size:90%;">3DPeople: Modeling the Geometry of Dressed Humans.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib74.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib74.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">International Conference in Computer Vision (ICCV)</em><span id="bib.bib74.11.3" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib75" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib75.5.5.1" class="ltx_text" style="font-size:90%;">Quigley etÂ al. [2009]</span></span>
<span class="ltx_bibblock"><span id="bib.bib75.7.1" class="ltx_text" style="font-size:90%;">
Morgan Quigley, Ken Conley, Brian Gerkey, Josh Faust, Tully Foote, Jeremy Leibs, Rob Wheeler, AndrewÂ Y Ng, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib75.8.1" class="ltx_text" style="font-size:90%;">Ros: an open-source robot operating system.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib75.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib75.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">ICRA workshop on open source software</em><span id="bib.bib75.11.3" class="ltx_text" style="font-size:90%;">, pageÂ 5. Kobe, Japan, 2009.
</span>
</span>
</li>
<li id="bib.bib76" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib76.5.5.1" class="ltx_text" style="font-size:90%;">Rafi etÂ al. [2015]</span></span>
<span class="ltx_bibblock"><span id="bib.bib76.7.1" class="ltx_text" style="font-size:90%;">
Umer Rafi, Juergen Gall, and Bastian Leibe.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib76.8.1" class="ltx_text" style="font-size:90%;">A semantic occlusion model for human pose estimation from a single depth image.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib76.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib76.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE conference on computer vision and pattern recognition workshops</em><span id="bib.bib76.11.3" class="ltx_text" style="font-size:90%;">, pages 67â€“74, 2015.
</span>
</span>
</li>
<li id="bib.bib77" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib77.5.5.1" class="ltx_text" style="font-size:90%;">Raistrick etÂ al. [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib77.7.1" class="ltx_text" style="font-size:90%;">
Alexander Raistrick, Lahav Lipson, Zeyu Ma, Lingjie Mei, Mingzhe Wang, Yiming Zuo, Karhan Kayan, Hongyu Wen, Beining Han, Yihan Wang, Alejandro Newell, Hei Law, Ankit Goyal, Kaiyu Yang, and Jia Deng.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib77.8.1" class="ltx_text" style="font-size:90%;">Infinite photorealistic worlds using procedural generation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib77.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib77.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em><span id="bib.bib77.11.3" class="ltx_text" style="font-size:90%;">, pages 12630â€“12641, 2023.
</span>
</span>
</li>
<li id="bib.bib78" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib78.4.4.1" class="ltx_text" style="font-size:90%;">Reinhardt [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib78.6.1" class="ltx_text" style="font-size:90%;">
Tilman Reinhardt.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib78.7.1" class="ltx_text" style="font-size:90%;">Google Visual Positioning Service.
</span>
</span>
<span class="ltx_bibblock"><a target="_blank" href="https://ai.googleblog.com/2019/02/using-global-localization-to-improve.html" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://ai.googleblog.com/2019/02/using-global-localization-to-improve.html</a><span id="bib.bib78.8.1" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib79" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib79.5.5.1" class="ltx_text" style="font-size:90%;">Rempe etÂ al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib79.7.1" class="ltx_text" style="font-size:90%;">
Davis Rempe, Tolga Birdal, Aaron Hertzmann, Jimei Yang, Srinath Sridhar, and LeonidasÂ J. Guibas.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib79.8.1" class="ltx_text" style="font-size:90%;">Humor: 3d human motion model for robust pose estimation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib79.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib79.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">International Conference on Computer Vision (ICCV)</em><span id="bib.bib79.11.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib80" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib80.5.5.1" class="ltx_text" style="font-size:90%;">Rempe etÂ al. [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib80.7.1" class="ltx_text" style="font-size:90%;">
Davis Rempe, Zhengyi Luo, XueÂ Bin Peng, Ye Yuan, Kris Kitani, Karsten Kreis, Sanja Fidler, and Or Litany.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib80.8.1" class="ltx_text" style="font-size:90%;">Trace and pace: Controllable pedestrian animation via guided trajectory diffusion, 2023.
</span>
</span>
</li>
<li id="bib.bib81" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib81.5.5.1" class="ltx_text" style="font-size:90%;">Rong etÂ al. [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib81.7.1" class="ltx_text" style="font-size:90%;">
Guodong Rong, ByungÂ Hyun Shin, Hadi Tabatabaee, Qiang Lu, Steve Lemke, MÄrtiÅ†Å¡ MoÅ¾eiko, Eric Boise, Geehoon Uhm, Mark Gerow, Shalin Mehta, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib81.8.1" class="ltx_text" style="font-size:90%;">Lgsvl simulator: A high fidelity simulator for autonomous driving.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib81.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib81.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2020 IEEE 23rd International conference on intelligent transportation systems (ITSC)</em><span id="bib.bib81.11.3" class="ltx_text" style="font-size:90%;">, pages 1â€“6. IEEE, 2020.
</span>
</span>
</li>
<li id="bib.bib82" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib82.5.5.1" class="ltx_text" style="font-size:90%;">Rosinol etÂ al. [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib82.7.1" class="ltx_text" style="font-size:90%;">
A. Rosinol, A. Gupta, M. Abate, J. Shi, and L. Carlone.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib82.8.1" class="ltx_text" style="font-size:90%;">3D dynamic scene graphs: Actionable spatial perception with places, objects, and humans.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib82.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib82.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Robotics: Science and Systems (RSS)</em><span id="bib.bib82.11.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib83" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib83.5.5.1" class="ltx_text" style="font-size:90%;">Sarlin etÂ al. [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib83.7.1" class="ltx_text" style="font-size:90%;">
Paul-Edouard Sarlin, Daniel DeTone, Tomasz Malisiewicz, and Andrew Rabinovich.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib83.8.1" class="ltx_text" style="font-size:90%;">Superglue: Learning feature matching with graph neural networks, 2020.
</span>
</span>
</li>
<li id="bib.bib84" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib84.5.5.1" class="ltx_text" style="font-size:90%;">Sarlin etÂ al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib84.7.1" class="ltx_text" style="font-size:90%;">
Paul-Edouard Sarlin, Mihai Dusmanu, JohannesÂ L. SchÃ¶nberger, Pablo Speciale, Lukas Gruber, Viktor Larsson, Ondrej Miksik, and Marc Pollefeys.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib84.8.1" class="ltx_text" style="font-size:90%;">LaMAR: Benchmarking Localization and Mapping for Augmented Reality.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib84.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib84.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">ECCV</em><span id="bib.bib84.11.3" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib85" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib85.5.5.1" class="ltx_text" style="font-size:90%;">Sattler etÂ al. [2018]</span></span>
<span class="ltx_bibblock"><span id="bib.bib85.7.1" class="ltx_text" style="font-size:90%;">
Torsten Sattler, Will Maddern, Carl Toft, Akihiko Torii, Lars Hammarstrand, Erik Stenborg, Daniel Safari, Masatoshi Okutomi, Marc Pollefeys, Josef Sivic, Fredrik Kahl, and Tomas Pajdla.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib85.8.1" class="ltx_text" style="font-size:90%;">Benchmarking 6DoF outdoor visual localization in changing conditions.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib85.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib85.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">CVPR</em><span id="bib.bib85.11.3" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib86" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib86.5.5.1" class="ltx_text" style="font-size:90%;">Savva etÂ al. [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib86.7.1" class="ltx_text" style="font-size:90%;">
Manolis Savva, Abhishek Kadian, Oleksandr Maksymets, Yili Zhao, Erik Wijmans, Bhavana Jain, Julian Straub, Jia Liu, Vladlen Koltun, Jitendra Malik, Devi Parikh, and Dhruv Batra.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib86.8.1" class="ltx_text" style="font-size:90%;">Habitat: A platform for embodied ai research, 2019.
</span>
</span>
</li>
<li id="bib.bib87" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib87.4.4.1" class="ltx_text" style="font-size:90%;">SchÃ¶nberger and Frahm [2016]</span></span>
<span class="ltx_bibblock"><span id="bib.bib87.6.1" class="ltx_text" style="font-size:90%;">
JohannesÂ Lutz SchÃ¶nberger and Jan-Michael Frahm.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib87.7.1" class="ltx_text" style="font-size:90%;">Structure-from-motion revisited.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib87.8.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib87.9.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">CVPR</em><span id="bib.bib87.10.3" class="ltx_text" style="font-size:90%;">, 2016.
</span>
</span>
</li>
<li id="bib.bib88" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib88.5.5.1" class="ltx_text" style="font-size:90%;">SchÃ¶nberger etÂ al. [2017]</span></span>
<span class="ltx_bibblock"><span id="bib.bib88.7.1" class="ltx_text" style="font-size:90%;">
JohannesÂ L. SchÃ¶nberger, Hans Hardmeier, Torsten Sattler, and Marc Pollefeys.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib88.8.1" class="ltx_text" style="font-size:90%;">Comparative evaluation of hand-crafted and learned local features.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib88.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib88.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">CVPR</em><span id="bib.bib88.11.3" class="ltx_text" style="font-size:90%;">, 2017.
</span>
</span>
</li>
<li id="bib.bib89" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib89.5.5.1" class="ltx_text" style="font-size:90%;">Schulman etÂ al. [2017]</span></span>
<span class="ltx_bibblock"><span id="bib.bib89.7.1" class="ltx_text" style="font-size:90%;">
John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib89.8.1" class="ltx_text" style="font-size:90%;">Proximal policy optimization algorithms, 2017.
</span>
</span>
</li>
<li id="bib.bib90" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib90.5.5.1" class="ltx_text" style="font-size:90%;">Sengupta etÂ al. [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib90.7.1" class="ltx_text" style="font-size:90%;">
Akash Sengupta, Ignas Budvytis, and Roberto Cipolla.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib90.8.1" class="ltx_text" style="font-size:90%;">Synthetic training for accurate 3d human pose and shape estimation in the wild.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib90.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib90.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">British Machine Vision Conference (BMVC)</em><span id="bib.bib90.11.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib91" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib91.5.5.1" class="ltx_text" style="font-size:90%;">Shiratori etÂ al. [2011]</span></span>
<span class="ltx_bibblock"><span id="bib.bib91.7.1" class="ltx_text" style="font-size:90%;">
Takaaki Shiratori, HyunÂ Soo Park, Leonid Sigal, Yaser Sheikh, and JessicaÂ K. Hodgins.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib91.8.1" class="ltx_text" style="font-size:90%;">Motion capture from body-mounted cameras.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib91.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">ACM Trans. Graph.</em><span id="bib.bib91.10.2" class="ltx_text" style="font-size:90%;">, 30(4):31, 2011.
</span>
</span>
</li>
<li id="bib.bib92" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib92.5.5.1" class="ltx_text" style="font-size:90%;">Shotton etÂ al. [2012]</span></span>
<span class="ltx_bibblock"><span id="bib.bib92.7.1" class="ltx_text" style="font-size:90%;">
Jamie Shotton, Ross Girshick, Andrew Fitzgibbon, Toby Sharp, Mat Cook, Mark Finocchio, Richard Moore, Pushmeet Kohli, Antonio Criminisi, Alex Kipman, etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib92.8.1" class="ltx_text" style="font-size:90%;">Efficient human pose estimation from single depth images.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib92.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE transactions on pattern analysis and machine intelligence</em><span id="bib.bib92.10.2" class="ltx_text" style="font-size:90%;">, 35(12):2821â€“2840, 2012.
</span>
</span>
</li>
<li id="bib.bib93" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib93.5.5.1" class="ltx_text" style="font-size:90%;">Shotton etÂ al. [2013a]</span></span>
<span class="ltx_bibblock"><span id="bib.bib93.7.1" class="ltx_text" style="font-size:90%;">
Jamie Shotton, Ben Glocker, Christopher Zach, Shahram Izadi, Antonio Criminisi, and Andrew Fitzgibbon.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib93.8.1" class="ltx_text" style="font-size:90%;">Scene Coordinate Regression Forests for Camera Relocalization in RGB-D Images.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib93.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib93.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">CVPR</em><span id="bib.bib93.11.3" class="ltx_text" style="font-size:90%;">, 2013a.
</span>
</span>
</li>
<li id="bib.bib94" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib94.5.5.1" class="ltx_text" style="font-size:90%;">Shotton etÂ al. [2013b]</span></span>
<span class="ltx_bibblock"><span id="bib.bib94.7.1" class="ltx_text" style="font-size:90%;">
Jamie Shotton, Toby Sharp, Alex Kipman, Andrew Fitzgibbon, Mark Finocchio, Andrew Blake, Mat Cook, and Richard Moore.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib94.8.1" class="ltx_text" style="font-size:90%;">Real-time human pose recognition in parts from single depth images.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib94.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Commun. ACM</em><span id="bib.bib94.10.2" class="ltx_text" style="font-size:90%;">, 56(1):116â€“124, 2013b.
</span>
</span>
</li>
<li id="bib.bib95" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib95.5.5.1" class="ltx_text" style="font-size:90%;">Snavely etÂ al. [2006]</span></span>
<span class="ltx_bibblock"><span id="bib.bib95.7.1" class="ltx_text" style="font-size:90%;">
Noah Snavely, StevenÂ M. Seitz, and Richard Szeliski.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib95.8.1" class="ltx_text" style="font-size:90%;">Photo tourism: exploring photo collections in 3d.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib95.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">ACM Trans. Graph.</em><span id="bib.bib95.10.2" class="ltx_text" style="font-size:90%;">, 25(3):835â€“846, 2006.
</span>
</span>
</li>
<li id="bib.bib96" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib96.5.5.1" class="ltx_text" style="font-size:90%;">Sohn etÂ al. [2015]</span></span>
<span class="ltx_bibblock"><span id="bib.bib96.7.1" class="ltx_text" style="font-size:90%;">
Kihyuk Sohn, Honglak Lee, and Xinchen Yan.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib96.8.1" class="ltx_text" style="font-size:90%;">Learning structured output representation using deep conditional generative models.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib96.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib96.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Advances in Neural Information Processing Systems</em><span id="bib.bib96.11.3" class="ltx_text" style="font-size:90%;">. Curran Associates, Inc., 2015.
</span>
</span>
</li>
<li id="bib.bib97" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib97.5.5.1" class="ltx_text" style="font-size:90%;">Starke etÂ al. [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib97.7.1" class="ltx_text" style="font-size:90%;">
Sebastian Starke, He Zhang, Taku Komura, and Jun Saito.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib97.8.1" class="ltx_text" style="font-size:90%;">Neural state machine for character-scene interactions.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib97.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">ACM Trans. Graph.</em><span id="bib.bib97.10.2" class="ltx_text" style="font-size:90%;">, 38(6):209â€“1, 2019.
</span>
</span>
</li>
<li id="bib.bib98" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib98.5.5.1" class="ltx_text" style="font-size:90%;">Starke etÂ al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib98.7.1" class="ltx_text" style="font-size:90%;">
Sebastian Starke, Ian Mason, and Taku Komura.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib98.8.1" class="ltx_text" style="font-size:90%;">Deepphase: Periodic autoencoders for learning motion phase manifolds.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib98.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">ACM Transactions on Graphics (TOG)</em><span id="bib.bib98.10.2" class="ltx_text" style="font-size:90%;">, 41(4):1â€“13, 2022.
</span>
</span>
</li>
<li id="bib.bib99" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib99.5.5.1" class="ltx_text" style="font-size:90%;">Straub etÂ al. [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib99.7.1" class="ltx_text" style="font-size:90%;">
Julian Straub, Thomas Whelan, Lingni Ma, Yufan Chen, Erik Wijmans, Simon Green, JakobÂ J. Engel, Raul Mur-Artal, Carl Ren, Shobhit Verma, Anton Clarkson, Mingfei Yan, Brian Budge, Yajie Yan, Xiaqing Pan, June Yon, Yuyang Zou, Kimberly Leon, Nigel Carter, Jesus Briales, Tyler Gillingham, Elias Mueggler, Luis Pesqueira, Manolis Savva, Dhruv Batra, HaukeÂ M. Strasdat, RenzoÂ De Nardi, Michael Goesele, Steven Lovegrove, and Richard Newcombe.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib99.8.1" class="ltx_text" style="font-size:90%;">The Replica dataset: A digital replica of indoor spaces.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib99.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1906.05797</em><span id="bib.bib99.10.2" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib100" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib100.5.5.1" class="ltx_text" style="font-size:90%;">Szot etÂ al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib100.7.1" class="ltx_text" style="font-size:90%;">
Andrew Szot, Alex Clegg, Eric Undersander, Erik Wijmans, Yili Zhao, John Turner, Noah Maestre, Mustafa Mukadam, Devendra Chaplot, Oleksandr Maksymets, Aaron Gokaslan, Vladimir Vondrus, Sameer Dharur, Franziska Meier, Wojciech Galuba, Angel Chang, Zsolt Kira, Vladlen Koltun, Jitendra Malik, Manolis Savva, and Dhruv Batra.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib100.8.1" class="ltx_text" style="font-size:90%;">Habitat 2.0: Training home assistants to rearrange their habitat.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib100.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib100.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Advances in Neural Information Processing Systems (NeurIPS)</em><span id="bib.bib100.11.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib101" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib101.4.4.1" class="ltx_text" style="font-size:90%;">Teed and Deng [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib101.6.1" class="ltx_text" style="font-size:90%;">
Zachary Teed and Jia Deng.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib101.7.1" class="ltx_text" style="font-size:90%;">DROID-SLAM: Deep Visual SLAM for Monocular, Stereo, and RGB-D Cameras.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib101.8.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Advances in neural information processing systems</em><span id="bib.bib101.9.2" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib102" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib102.5.5.1" class="ltx_text" style="font-size:90%;">Tevet etÂ al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib102.7.1" class="ltx_text" style="font-size:90%;">
Guy Tevet, Sigal Raab, Brian Gordon, Yonatan Shafir, Daniel Cohen-Or, and AmitÂ H Bermano.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib102.8.1" class="ltx_text" style="font-size:90%;">Human motion diffusion model.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib102.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2209.14916</em><span id="bib.bib102.10.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib103" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib103.5.5.1" class="ltx_text" style="font-size:90%;">Todorov etÂ al. [2012a]</span></span>
<span class="ltx_bibblock"><span id="bib.bib103.7.1" class="ltx_text" style="font-size:90%;">
Emanuel Todorov, Tom Erez, and Yuval Tassa.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib103.8.1" class="ltx_text" style="font-size:90%;">Mujoco: A physics engine for model-based control.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib103.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib103.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2012 IEEE/RSJ International Conference on Intelligent Robots and Systems</em><span id="bib.bib103.11.3" class="ltx_text" style="font-size:90%;">, pages 5026â€“5033, 2012a.
</span>
</span>
</li>
<li id="bib.bib104" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib104.5.5.1" class="ltx_text" style="font-size:90%;">Todorov etÂ al. [2012b]</span></span>
<span class="ltx_bibblock"><span id="bib.bib104.7.1" class="ltx_text" style="font-size:90%;">
Emanuel Todorov, Tom Erez, and Yuval Tassa.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib104.8.1" class="ltx_text" style="font-size:90%;">Mujoco: A physics engine for model-based control.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib104.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib104.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2012 IEEE/RSJ International Conference on Intelligent Robots and Systems</em><span id="bib.bib104.11.3" class="ltx_text" style="font-size:90%;">, pages 5026â€“5033. IEEE, 2012b.
</span>
</span>
</li>
<li id="bib.bib105" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib105.5.5.1" class="ltx_text" style="font-size:90%;">Tome etÂ al. [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib105.7.1" class="ltx_text" style="font-size:90%;">
Denis Tome, Patrick Peluse, Lourdes Agapito, and Hernan Badino.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib105.8.1" class="ltx_text" style="font-size:90%;">xr-egopose: Egocentric 3d human pose from an hmd camera.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib105.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib105.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE International Conference on Computer Vision</em><span id="bib.bib105.11.3" class="ltx_text" style="font-size:90%;">, pages 7728â€“7738, 2019.
</span>
</span>
</li>
<li id="bib.bib106" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib106.5.5.1" class="ltx_text" style="font-size:90%;">Tome etÂ al. [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib106.7.1" class="ltx_text" style="font-size:90%;">
Denis Tome, Thiemo Alldieck, Patrick Peluse, Gerard Pons-Moll, Lourdes Agapito, Hernan Badino, and Fernando DeÂ la Torre.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib106.8.1" class="ltx_text" style="font-size:90%;">Selfpose: 3d egocentric pose estimation from a headset mounted camera.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib106.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2011.01519</em><span id="bib.bib106.10.2" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib107" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib107.4.4.1" class="ltx_text" style="font-size:90%;">Unity Technologies [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib107.6.1" class="ltx_text" style="font-size:90%;">
Unity Technologies.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib107.7.1" class="ltx_text" style="font-size:90%;">Unity Perception package.
</span>
</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/Unity-Technologies/com.unity.perception" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://github.com/Unity-Technologies/com.unity.perception</a><span id="bib.bib107.8.1" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib108" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib108.5.5.1" class="ltx_text" style="font-size:90%;">Vaswani etÂ al. [2017]</span></span>
<span class="ltx_bibblock"><span id="bib.bib108.7.1" class="ltx_text" style="font-size:90%;">
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, AidanÂ N Gomez, Åukasz Kaiser, and Illia Polosukhin.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib108.8.1" class="ltx_text" style="font-size:90%;">Attention is all you need.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib108.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib108.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Advances in neural information processing systems</em><span id="bib.bib108.11.3" class="ltx_text" style="font-size:90%;">, pages 5998â€“6008, 2017.
</span>
</span>
</li>
<li id="bib.bib109" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib109.5.5.1" class="ltx_text" style="font-size:90%;">Wang etÂ al. [2016]</span></span>
<span class="ltx_bibblock"><span id="bib.bib109.7.1" class="ltx_text" style="font-size:90%;">
Keze Wang, Shengfu Zhai, Hui Cheng, Xiaodan Liang, and Liang Lin.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib109.8.1" class="ltx_text" style="font-size:90%;">Human pose estimation from depth images via inference embedded multi-task learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib109.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib109.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the 24th ACM international conference on Multimedia</em><span id="bib.bib109.11.3" class="ltx_text" style="font-size:90%;">, pages 1227â€“1236, 2016.
</span>
</span>
</li>
<li id="bib.bib110" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib110.5.5.1" class="ltx_text" style="font-size:90%;">Wang etÂ al. [2023a]</span></span>
<span class="ltx_bibblock"><span id="bib.bib110.7.1" class="ltx_text" style="font-size:90%;">
Xin Wang, Taein Kwon, Mahdi Rad, Bowen Pan, Ishani Chakraborty, Sean Andrist, Dan Bohus, Ashley Feniello, Bugra Tekin, FelipeÂ Vieira Frujeri, Neel Joshi, and Marc Pollefeys.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib110.8.1" class="ltx_text" style="font-size:90%;">Holoassist: an egocentric human interaction dataset for interactive ai assistants in the real world.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib110.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib110.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</em><span id="bib.bib110.11.3" class="ltx_text" style="font-size:90%;">, pages 20270â€“20281, 2023a.
</span>
</span>
</li>
<li id="bib.bib111" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib111.5.5.1" class="ltx_text" style="font-size:90%;">Wang etÂ al. [2023b]</span></span>
<span class="ltx_bibblock"><span id="bib.bib111.7.1" class="ltx_text" style="font-size:90%;">
Yufei Wang, Zhou Xian, Feng Chen, Tsun-Hsuan Wang, Yian Wang, Katerina Fragkiadaki, Zackory Erickson, David Held, and Chuang Gan.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib111.8.1" class="ltx_text" style="font-size:90%;">Robogen: Towards unleashing infinite data for automated robot learning via generative simulation, 2023b.
</span>
</span>
</li>
<li id="bib.bib112" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib112.5.5.1" class="ltx_text" style="font-size:90%;">Weng etÂ al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib112.7.1" class="ltx_text" style="font-size:90%;">
Jiayi Weng, Huayu Chen, Dong Yan, Kaichao You, Alexis Duburcq, Minghao Zhang, Yi Su, Hang Su, and Jun Zhu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib112.8.1" class="ltx_text" style="font-size:90%;">Tianshou: A highly modularized deep reinforcement learning library.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib112.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Journal of Machine Learning Research</em><span id="bib.bib112.10.2" class="ltx_text" style="font-size:90%;">, 23(267):1â€“6, 2022.
</span>
</span>
</li>
<li id="bib.bib113" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib113.5.5.1" class="ltx_text" style="font-size:90%;">Wijmans etÂ al. [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib113.7.1" class="ltx_text" style="font-size:90%;">
Erik Wijmans, Abhishek Kadian, Ari Morcos, Stefan Lee, Irfan Essa, Devi Parikh, Manolis Savva, and Dhruv Batra.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib113.8.1" class="ltx_text" style="font-size:90%;">DD-PPO: learning near-perfect pointgoal navigators from 2.5 billion frames.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib113.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib113.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020</em><span id="bib.bib113.11.3" class="ltx_text" style="font-size:90%;">. OpenReview.net, 2020.
</span>
</span>
</li>
<li id="bib.bib114" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib114.4.4.1" class="ltx_text" style="font-size:90%;">Wilson and Snavely [2014]</span></span>
<span class="ltx_bibblock"><span id="bib.bib114.6.1" class="ltx_text" style="font-size:90%;">
Kyle Wilson and Noah Snavely.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib114.7.1" class="ltx_text" style="font-size:90%;">Robust global translations with 1dsfm.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib114.8.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib114.9.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">ECCV</em><span id="bib.bib114.10.3" class="ltx_text" style="font-size:90%;">, 2014.
</span>
</span>
</li>
<li id="bib.bib115" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib115.5.5.1" class="ltx_text" style="font-size:90%;">Won etÂ al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib115.7.1" class="ltx_text" style="font-size:90%;">
Jungdam Won, Deepak Gopinath, and Jessica Hodgins.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib115.8.1" class="ltx_text" style="font-size:90%;">Physics-based character controllers using conditional vaes.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib115.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">ACM Trans. Graph.</em><span id="bib.bib115.10.2" class="ltx_text" style="font-size:90%;">, 41(4), 2022.
</span>
</span>
</li>
<li id="bib.bib116" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib116.5.5.1" class="ltx_text" style="font-size:90%;">Wood etÂ al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib116.7.1" class="ltx_text" style="font-size:90%;">
Erroll Wood, Tadas BaltruÅ¡aitis, Charlie Hewitt, Sebastian Dziadzio, ThomasÂ J Cashman, and Jamie Shotton.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib116.8.1" class="ltx_text" style="font-size:90%;">Fake it till you make it: face analysis in the wild using synthetic data alone.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib116.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib116.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF international conference on computer vision</em><span id="bib.bib116.11.3" class="ltx_text" style="font-size:90%;">, pages 3681â€“3691, 2021.
</span>
</span>
</li>
<li id="bib.bib117" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib117.5.5.1" class="ltx_text" style="font-size:90%;">Xiong etÂ al. [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib117.7.1" class="ltx_text" style="font-size:90%;">
Fu Xiong, Boshen Zhang, Yang Xiao, Zhiguo Cao, Taidong Yu, JoeyÂ Tianyi Zhou, and Junsong Yuan.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib117.8.1" class="ltx_text" style="font-size:90%;">A2j: Anchor-to-joint regression network for 3d articulated pose estimation from a single depth image.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib117.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib117.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on Computer Vision</em><span id="bib.bib117.11.3" class="ltx_text" style="font-size:90%;">, pages 793â€“802, 2019.
</span>
</span>
</li>
<li id="bib.bib118" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib118.5.5.1" class="ltx_text" style="font-size:90%;">Yang etÂ al. [2023a]</span></span>
<span class="ltx_bibblock"><span id="bib.bib118.7.1" class="ltx_text" style="font-size:90%;">
Mengjiao Yang, Yilun Du, Kamyar Ghasemipour, Jonathan Tompson, Dale Schuurmans, and Pieter Abbeel.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib118.8.1" class="ltx_text" style="font-size:90%;">Learning interactive real-world simulators.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib118.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2310.06114</em><span id="bib.bib118.10.2" class="ltx_text" style="font-size:90%;">, 2023a.
</span>
</span>
</li>
<li id="bib.bib119" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib119.5.5.1" class="ltx_text" style="font-size:90%;">Yang etÂ al. [2023b]</span></span>
<span class="ltx_bibblock"><span id="bib.bib119.7.1" class="ltx_text" style="font-size:90%;">
Zhitao Yang, Zhongang Cai, Haiyi Mei, Shuai Liu, Zhaoxi Chen, Weiye Xiao, Yukun Wei, Zhongfei Qing, Chen Wei, Bo Dai, Wayne Wu, Chen Qian, Dahua Lin, Ziwei Liu, and Lei Yang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib119.8.1" class="ltx_text" style="font-size:90%;">Synbody: Synthetic dataset with layered human models for 3d human perception and modeling, 2023b.
</span>
</span>
</li>
<li id="bib.bib120" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib120.5.5.1" class="ltx_text" style="font-size:90%;">Yao etÂ al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib120.7.1" class="ltx_text" style="font-size:90%;">
Heyuan Yao, Zhenhua Song, Baoquan Chen, and Libin Liu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib120.8.1" class="ltx_text" style="font-size:90%;">Controlvae: Model-based learning of generative controllers for physics-based characters.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib120.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">ACM Trans. Graph.</em><span id="bib.bib120.10.2" class="ltx_text" style="font-size:90%;">, 41(6), 2022.
</span>
</span>
</li>
<li id="bib.bib121" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib121.5.5.1" class="ltx_text" style="font-size:90%;">Ye etÂ al. [2011]</span></span>
<span class="ltx_bibblock"><span id="bib.bib121.7.1" class="ltx_text" style="font-size:90%;">
Mao Ye, Xianwang Wang, Ruigang Yang, Liu Ren, and Marc Pollefeys.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib121.8.1" class="ltx_text" style="font-size:90%;">Accurate 3d pose estimation from a single depth image.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib121.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib121.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2011 International Conference on Computer Vision</em><span id="bib.bib121.11.3" class="ltx_text" style="font-size:90%;">, pages 731â€“738. IEEE, 2011.
</span>
</span>
</li>
<li id="bib.bib122" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib122.5.5.1" class="ltx_text" style="font-size:90%;">Ye etÂ al. [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib122.7.1" class="ltx_text" style="font-size:90%;">
Vickie Ye, Georgios Pavlakos, Jitendra Malik, and Angjoo Kanazawa.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib122.8.1" class="ltx_text" style="font-size:90%;">Decoupling human and camera motion from videos in the wild.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib122.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2302.12827</em><span id="bib.bib122.10.2" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib123" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib123.4.4.1" class="ltx_text" style="font-size:90%;">Yuan and Kitani [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib123.6.1" class="ltx_text" style="font-size:90%;">
Ye Yuan and Kris Kitani.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib123.7.1" class="ltx_text" style="font-size:90%;">Ego-pose estimation and forecasting as real-time pd control.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib123.8.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib123.9.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on Computer Vision</em><span id="bib.bib123.10.3" class="ltx_text" style="font-size:90%;">, pages 10082â€“10092, 2019.
</span>
</span>
</li>
<li id="bib.bib124" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib124.5.5.1" class="ltx_text" style="font-size:90%;">Zhang etÂ al. [2022a]</span></span>
<span class="ltx_bibblock"><span id="bib.bib124.7.1" class="ltx_text" style="font-size:90%;">
Mingyuan Zhang, Zhongang Cai, Liang Pan, Fangzhou Hong, Xinying Guo, Lei Yang, and Ziwei Liu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib124.8.1" class="ltx_text" style="font-size:90%;">Motiondiffuse: Text-driven human motion generation with diffusion model.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib124.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2208.15001</em><span id="bib.bib124.10.2" class="ltx_text" style="font-size:90%;">, 2022a.
</span>
</span>
</li>
<li id="bib.bib125" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib125.5.5.1" class="ltx_text" style="font-size:90%;">Zhang etÂ al. [2022b]</span></span>
<span class="ltx_bibblock"><span id="bib.bib125.7.1" class="ltx_text" style="font-size:90%;">
Siwei Zhang, Qianli Ma, Yan Zhang, Zhiyin Qian, Taein Kwon, Marc Pollefeys, Federica Bogo, and Siyu Tang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib125.8.1" class="ltx_text" style="font-size:90%;">Egobody: Human body shape and motion of interacting people from head-mounted devices.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib125.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib125.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">European conference on computer vision (ECCV)</em><span id="bib.bib125.11.3" class="ltx_text" style="font-size:90%;">, 2022b.
</span>
</span>
</li>
<li id="bib.bib126" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib126.5.5.1" class="ltx_text" style="font-size:90%;">Zhang etÂ al. [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib126.7.1" class="ltx_text" style="font-size:90%;">
Siwei Zhang, Qianli Ma, Yan Zhang, Sadegh Aliakbarian, Darren Cosker, and Siyu Tang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib126.8.1" class="ltx_text" style="font-size:90%;">Probabilistic human mesh recovery in 3d scenes from egocentric views.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib126.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib126.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on Computer Vision</em><span id="bib.bib126.11.3" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib127" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib127.4.4.1" class="ltx_text" style="font-size:90%;">Zhang and Tang [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib127.6.1" class="ltx_text" style="font-size:90%;">
Yan Zhang and Siyu Tang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib127.7.1" class="ltx_text" style="font-size:90%;">The wanderings of odysseus in 3d scenes.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib127.8.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib127.9.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em><span id="bib.bib127.10.3" class="ltx_text" style="font-size:90%;">, pages 20481â€“20491, 2022.
</span>
</span>
</li>
<li id="bib.bib128" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib128.5.5.1" class="ltx_text" style="font-size:90%;">Zhang etÂ al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib128.7.1" class="ltx_text" style="font-size:90%;">
Yan Zhang, MichaelÂ J Black, and Siyu Tang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib128.8.1" class="ltx_text" style="font-size:90%;">We are more than our joints: Predicting how 3d bodies move.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib128.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib128.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em><span id="bib.bib128.11.3" class="ltx_text" style="font-size:90%;">, pages 3372â€“3382, 2021.
</span>
</span>
</li>
<li id="bib.bib129" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib129.5.5.1" class="ltx_text" style="font-size:90%;">Zhao etÂ al. [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib129.7.1" class="ltx_text" style="font-size:90%;">
Kaifeng Zhao, Yan Zhang, Shaofei Wang, Thabo Beeler, , and Siyu Tang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib129.8.1" class="ltx_text" style="font-size:90%;">Synthesizing diverse human motions in 3d indoor scenes.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib129.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib129.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">International conference on computer vision (ICCV)</em><span id="bib.bib129.11.3" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib130" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib130.5.5.1" class="ltx_text" style="font-size:90%;">Zhao etÂ al. [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib130.7.1" class="ltx_text" style="font-size:90%;">
Yuhang Zhao, Elizabeth Kupferstein, BrendaÂ Veronica Castro, Steven Feiner, and Shiri Azenkot.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib130.8.1" class="ltx_text" style="font-size:90%;">Designing ar visualizations to facilitate stair navigation for people with low vision.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib130.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib130.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the 32nd annual ACM symposium on user interface software and technology</em><span id="bib.bib130.11.3" class="ltx_text" style="font-size:90%;">, pages 387â€“402, 2019.
</span>
</span>
</li>
<li id="bib.bib131" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib131.5.5.1" class="ltx_text" style="font-size:90%;">Zheng etÂ al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib131.7.1" class="ltx_text" style="font-size:90%;">
Yang Zheng, Yanchao Yang, Kaichun Mo, Jiaman Li, Tao Yu, Yebin Liu, CÂ Karen Liu, and LeonidasÂ J Guibas.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib131.8.1" class="ltx_text" style="font-size:90%;">Gimo: Gaze-informed human motion prediction in context.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib131.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib131.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Computer Visionâ€“ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23â€“27, 2022, Proceedings, Part XIII</em><span id="bib.bib131.11.3" class="ltx_text" style="font-size:90%;">, pages 676â€“694. Springer, 2022.
</span>
</span>
</li>
<li id="bib.bib132" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib132.5.5.1" class="ltx_text" style="font-size:90%;">Zheng etÂ al. [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib132.7.1" class="ltx_text" style="font-size:90%;">
Yang Zheng, AdamÂ W. Harley, Bokui Shen, Gordon Wetzstein, and LeonidasÂ J. Guibas.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib132.8.1" class="ltx_text" style="font-size:90%;">Pointodyssey: A large-scale synthetic dataset for long-term point tracking.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib132.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib132.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">ICCV</em><span id="bib.bib132.11.3" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib133" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib133.5.5.1" class="ltx_text" style="font-size:90%;">Zhuang etÂ al. [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib133.7.1" class="ltx_text" style="font-size:90%;">
Ziwen Zhuang, Zipeng Fu, Jianren Wang, Christopher Atkeson, SÃ¶ren Schwertfeger, Chelsea Finn, and Hang Zhao.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib133.8.1" class="ltx_text" style="font-size:90%;">Robot parkour learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib133.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib133.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Conference on Robot Learning (CoRL)</em><span id="bib.bib133.11.3" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_pagination ltx_role_newpage"></div>
<div id="p2" class="ltx_para ltx_align_center">
<span id="p2.1" class="ltx_ERROR undefined">\thetitle</span>
<br class="ltx_break">
<p id="p2.2" class="ltx_p"><span id="p2.2.1" class="ltx_text" style="font-size:144%;">Supplementary Material 
<br class="ltx_break"></span></p>
</div>
<section id="S1a" class="ltx_section ltx_centering">
<h2 class="ltx_title ltx_title_section" style="font-size:144%;">
<span class="ltx_tag ltx_tag_section">S1 </span>Related Work</h2>

<div id="S1a.p1" class="ltx_para">
<p id="S1a.p1.1" class="ltx_p"><span id="S1a.p1.1.1" class="ltx_text ltx_font_italic" style="font-size:144%;">EgoGen</span><span id="S1a.p1.1.2" class="ltx_text" style="font-size:144%;">Â addresses the gap in egocentric synthetic data generation specifically tailored for head-mounted devices, situated at the intersection of three key areas: 1) General synthetic data generation; 2) Egocentric simulation for embodied agents; 3) Human-related synthetic data generation. For a more detailed understanding of the distinctions between </span><span id="S1a.p1.1.3" class="ltx_text ltx_font_italic" style="font-size:144%;">EgoGen</span><span id="S1a.p1.1.4" class="ltx_text" style="font-size:144%;">Â and existing methods, refer to Tab.Â </span><a href="#S1.T1" title="Table S1 â€£ S1 Related Work â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref" style="font-size:144%;"><span class="ltx_text ltx_ref_tag">S1</span></a><span id="S1a.p1.1.5" class="ltx_text" style="font-size:144%;">, where these three areas are clearly outlined within distinct blocks.</span></p>
</div>
<div id="S1a.p2" class="ltx_para">
<p id="S1a.p2.1" class="ltx_p"><span id="S1a.p2.1.1" class="ltx_text" style="font-size:144%;">In particular, VirtualHomeÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1a.p2.1.2.1" class="ltx_text" style="font-size:144%;">[</span><a href="#bib.bib71" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">71</span></a>, <a href="#bib.bib72" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">72</span></a><span id="S1a.p2.1.3.2" class="ltx_text" style="font-size:144%;">]</span></cite><span id="S1a.p2.1.4" class="ltx_text" style="font-size:144%;"> also provides rendered egocentric views from head-mounted cameras. However, their egocentric videos lack fluctuating patterns due to the absence of natural human motion; instead, they display robotic-like patterns as Habitat 2.0Â </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1a.p2.1.5.1" class="ltx_text" style="font-size:144%;">[</span><a href="#bib.bib100" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">100</span></a><span id="S1a.p2.1.6.2" class="ltx_text" style="font-size:144%;">]</span></cite><span id="S1a.p2.1.7" class="ltx_text" style="font-size:144%;">. We advance closer to synthesizing more realistic data for head-mounted devices. In addition, they lack a generative human motion model, whereas ours can generate more diverse human motion and trajectories. A very recent work Habitat 3.0Â </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S1a.p2.1.8.1" class="ltx_text" style="font-size:144%;">[</span><a href="#bib.bib73" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">73</span></a><span id="S1a.p2.1.9.2" class="ltx_text" style="font-size:144%;">]</span></cite><span id="S1a.p2.1.10" class="ltx_text" style="font-size:144%;"> introduced virtual humans to robotic simulation. However, their human locomotion is synthesized by cyclically replaying a walking motion clip from MoCap data along a pre-calculated path with rigid rotations to transition to the next walking direction. Both VirtualHome and Habitat 3.0 have a limited number of human agents and fall short in representing diverse human characters, with limitations in body shapes, ethnic variation, and clothing options.</span></p>
</div>
<div id="S1a.p3" class="ltx_para">
<p id="S1a.p3.1" class="ltx_p"><span id="S1a.p3.1.1" class="ltx_text" style="font-size:144%;">Our synthetic data generation achieves increased diversity by incorporating a walking path-free generative human motion model, diverse body shapes, various body textures, and varied 3D textured clothing.</span></p>
</div>
<figure id="S1.T1" class="ltx_table">
<figcaption class="ltx_caption" style="font-size:144%;"><span class="ltx_tag ltx_tag_table"><span id="S1.T1.5.1.1" class="ltx_text" style="font-size:63%;">Table S1</span>: </span><span id="S1.T1.6.2" class="ltx_text" style="font-size:63%;">Comparison of existing synthetic datasets or generators. (Sec. <a href="#S1a" title="S1 Related Work â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref"><span class="ltx_text ltx_ref_tag">S1</span></a>)</span></figcaption>
<div id="S1.T1.7" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:1334.1pt;height:436.6pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="S1.T1.7.1" class="ltx_p"><span id="S1.T1.7.1.1" class="ltx_text" style="font-size:144%;">

<span id="S1.T1.7.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.7.1.1.1.1" class="ltx_tr" style="background-color:#E6E6E6;">
<span id="S1.T1.7.1.1.1.1.1" class="ltx_td ltx_border_ll ltx_border_t"></span>
<span id="S1.T1.7.1.1.1.1.2" class="ltx_td ltx_align_center ltx_border_t">Domain</span>
<span id="S1.T1.7.1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_t">Egocentric</span>
<span id="S1.T1.7.1.1.1.1.4" class="ltx_td ltx_align_center ltx_border_t">Head-mounted</span>
<span id="S1.T1.7.1.1.1.1.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S1.T1.7.1.1.1.1.5.1" class="ltx_text"></span> <span id="S1.T1.7.1.1.1.1.5.2" class="ltx_text">
<span id="S1.T1.7.1.1.1.1.5.2.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.7.1.1.1.1.5.2.1.1" class="ltx_tr">
<span id="S1.T1.7.1.1.1.1.5.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Multi-Camera</span></span>
<span id="S1.T1.7.1.1.1.1.5.2.1.2" class="ltx_tr">
<span id="S1.T1.7.1.1.1.1.5.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S1.T1.7.1.1.1.1.5.2.1.2.1.1" class="ltx_text" style="background-color:#E6E6E6;">rigs</span></span></span>
</span></span><span id="S1.T1.7.1.1.1.1.5.3" class="ltx_text"></span></span>
<span id="S1.T1.7.1.1.1.1.6" class="ltx_td ltx_align_center ltx_border_t">Virtual Humans</span>
<span id="S1.T1.7.1.1.1.1.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S1.T1.7.1.1.1.1.7.1" class="ltx_text"></span> <span id="S1.T1.7.1.1.1.1.7.2" class="ltx_text">
<span id="S1.T1.7.1.1.1.1.7.2.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.7.1.1.1.1.7.2.1.1" class="ltx_tr">
<span id="S1.T1.7.1.1.1.1.7.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Automated</span></span>
<span id="S1.T1.7.1.1.1.1.7.2.1.2" class="ltx_tr">
<span id="S1.T1.7.1.1.1.1.7.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S1.T1.7.1.1.1.1.7.2.1.2.1.1" class="ltx_text" style="background-color:#E6E6E6;">Clothing Simulation</span></span></span>
</span></span><span id="S1.T1.7.1.1.1.1.7.3" class="ltx_text"></span></span>
<span id="S1.T1.7.1.1.1.1.8" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t"><span id="S1.T1.7.1.1.1.1.8.1" class="ltx_text"></span> <span id="S1.T1.7.1.1.1.1.8.2" class="ltx_text">
<span id="S1.T1.7.1.1.1.1.8.2.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.7.1.1.1.1.8.2.1.1" class="ltx_tr">
<span id="S1.T1.7.1.1.1.1.8.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Generative Human</span></span>
<span id="S1.T1.7.1.1.1.1.8.2.1.2" class="ltx_tr">
<span id="S1.T1.7.1.1.1.1.8.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S1.T1.7.1.1.1.1.8.2.1.2.1.1" class="ltx_text" style="background-color:#E6E6E6;">Motion Synthesis</span></span></span>
</span></span><span id="S1.T1.7.1.1.1.1.8.3" class="ltx_text"></span></span></span>
<span id="S1.T1.7.1.1.1.2" class="ltx_tr" style="background-color:#E6E6E6;">
<span id="S1.T1.7.1.1.1.2.1" class="ltx_td ltx_align_center ltx_border_ll ltx_border_tt"><span id="S1.T1.7.1.1.1.2.1.1" class="ltx_text" style="background-color:#E6E6E6;">KubricÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">27</span></a>]</cite></span></span>
<span id="S1.T1.7.1.1.1.2.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S1.T1.7.1.1.1.2.2.1" class="ltx_text" style="background-color:#E6E6E6;">Scattered Objects</span></span>
<span id="S1.T1.7.1.1.1.2.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S1.T1.7.1.1.1.2.3.1" class="ltx_text" style="background-color:#E6E6E6;">âœ—</span></span>
<span id="S1.T1.7.1.1.1.2.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S1.T1.7.1.1.1.2.4.1" class="ltx_text" style="background-color:#E6E6E6;">âœ—</span></span>
<span id="S1.T1.7.1.1.1.2.5" class="ltx_td ltx_align_center ltx_border_tt"><span id="S1.T1.7.1.1.1.2.5.1" class="ltx_text" style="background-color:#E6E6E6;">âœ—</span></span>
<span id="S1.T1.7.1.1.1.2.6" class="ltx_td ltx_align_center ltx_border_tt"><span id="S1.T1.7.1.1.1.2.6.1" class="ltx_text" style="background-color:#E6E6E6;">âœ“</span></span>
<span id="S1.T1.7.1.1.1.2.7" class="ltx_td ltx_align_center ltx_border_tt"><span id="S1.T1.7.1.1.1.2.7.1" class="ltx_text" style="background-color:#E6E6E6;">âœ—</span></span>
<span id="S1.T1.7.1.1.1.2.8" class="ltx_td ltx_align_center ltx_border_rr ltx_border_tt"><span id="S1.T1.7.1.1.1.2.8.1" class="ltx_text" style="background-color:#E6E6E6;">âœ—</span></span></span>
<span id="S1.T1.7.1.1.1.3" class="ltx_tr" style="background-color:#FFFFFF;">
<span id="S1.T1.7.1.1.1.3.1" class="ltx_td ltx_align_center ltx_border_ll"><span id="S1.T1.7.1.1.1.3.1.1" class="ltx_text" style="background-color:#FFFFFF;">PointOdysseyÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib132" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">132</span></a>]</cite></span></span>
<span id="S1.T1.7.1.1.1.3.2" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.3.2.1" class="ltx_text" style="background-color:#FFFFFF;">Point Tracking</span></span>
<span id="S1.T1.7.1.1.1.3.3" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.3.3.1" class="ltx_text" style="background-color:#FFFFFF;">âœ“</span></span>
<span id="S1.T1.7.1.1.1.3.4" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.3.4.1" class="ltx_text" style="background-color:#FFFFFF;">âœ“</span></span>
<span id="S1.T1.7.1.1.1.3.5" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.3.5.1" class="ltx_text" style="background-color:#FFFFFF;">âœ—</span></span>
<span id="S1.T1.7.1.1.1.3.6" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.3.6.1" class="ltx_text" style="background-color:#FFFFFF;">âœ“</span></span>
<span id="S1.T1.7.1.1.1.3.7" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.3.7.1" class="ltx_text" style="background-color:#FFFFFF;">âœ—</span></span>
<span id="S1.T1.7.1.1.1.3.8" class="ltx_td ltx_align_center ltx_border_rr"><span id="S1.T1.7.1.1.1.3.8.1" class="ltx_text" style="background-color:#FFFFFF;">âœ—</span></span></span>
<span id="S1.T1.7.1.1.1.4" class="ltx_tr" style="background-color:#E6E6E6;">
<span id="S1.T1.7.1.1.1.4.1" class="ltx_td ltx_align_center ltx_border_ll"><span id="S1.T1.7.1.1.1.4.1.1" class="ltx_text" style="background-color:#E6E6E6;">InfiniGenÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib77" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">77</span></a>]</cite></span></span>
<span id="S1.T1.7.1.1.1.4.2" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.4.2.1" class="ltx_text" style="background-color:#E6E6E6;">Natural</span></span>
<span id="S1.T1.7.1.1.1.4.3" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.4.3.1" class="ltx_text" style="background-color:#E6E6E6;">âœ—</span></span>
<span id="S1.T1.7.1.1.1.4.4" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.4.4.1" class="ltx_text" style="background-color:#E6E6E6;">âœ—</span></span>
<span id="S1.T1.7.1.1.1.4.5" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.4.5.1" class="ltx_text" style="background-color:#E6E6E6;">âœ—</span></span>
<span id="S1.T1.7.1.1.1.4.6" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.4.6.1" class="ltx_text" style="background-color:#E6E6E6;">âœ—</span></span>
<span id="S1.T1.7.1.1.1.4.7" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.4.7.1" class="ltx_text" style="background-color:#E6E6E6;">âœ—</span></span>
<span id="S1.T1.7.1.1.1.4.8" class="ltx_td ltx_align_center ltx_border_rr"><span id="S1.T1.7.1.1.1.4.8.1" class="ltx_text" style="background-color:#E6E6E6;">âœ—</span></span></span>
<span id="S1.T1.7.1.1.1.5" class="ltx_tr" style="background-color:#FFFFFF;">
<span id="S1.T1.7.1.1.1.5.1" class="ltx_td ltx_align_center ltx_border_ll"><span id="S1.T1.7.1.1.1.5.1.1" class="ltx_text" style="background-color:#FFFFFF;">RoboGenÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib111" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">111</span></a>]</cite></span></span>
<span id="S1.T1.7.1.1.1.5.2" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.5.2.1" class="ltx_text" style="background-color:#FFFFFF;">Robotics</span></span>
<span id="S1.T1.7.1.1.1.5.3" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.5.3.1" class="ltx_text" style="background-color:#FFFFFF;">âœ—</span></span>
<span id="S1.T1.7.1.1.1.5.4" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.5.4.1" class="ltx_text" style="background-color:#FFFFFF;">âœ—</span></span>
<span id="S1.T1.7.1.1.1.5.5" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.5.5.1" class="ltx_text" style="background-color:#FFFFFF;">âœ—</span></span>
<span id="S1.T1.7.1.1.1.5.6" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.5.6.1" class="ltx_text" style="background-color:#FFFFFF;">âœ—</span></span>
<span id="S1.T1.7.1.1.1.5.7" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.5.7.1" class="ltx_text" style="background-color:#FFFFFF;">âœ—</span></span>
<span id="S1.T1.7.1.1.1.5.8" class="ltx_td ltx_align_center ltx_border_rr"><span id="S1.T1.7.1.1.1.5.8.1" class="ltx_text" style="background-color:#FFFFFF;">âœ—</span></span></span>
<span id="S1.T1.7.1.1.1.6" class="ltx_tr" style="background-color:#E6E6E6;">
<span id="S1.T1.7.1.1.1.6.1" class="ltx_td ltx_align_center ltx_border_ll"><span id="S1.T1.7.1.1.1.6.1.1" class="ltx_text" style="background-color:#E6E6E6;">UniSimÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib118" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">118</span></a>]</cite></span></span>
<span id="S1.T1.7.1.1.1.6.2" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.6.2.1" class="ltx_text" style="background-color:#E6E6E6;">Real-world Interaction</span></span>
<span id="S1.T1.7.1.1.1.6.3" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.6.3.1" class="ltx_text" style="background-color:#E6E6E6;">âœ“</span></span>
<span id="S1.T1.7.1.1.1.6.4" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.6.4.1" class="ltx_text" style="background-color:#E6E6E6;">âœ“</span></span>
<span id="S1.T1.7.1.1.1.6.5" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.6.5.1" class="ltx_text" style="background-color:#E6E6E6;">âœ—</span></span>
<span id="S1.T1.7.1.1.1.6.6" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.6.6.1" class="ltx_text" style="background-color:#E6E6E6;">âœ—</span></span>
<span id="S1.T1.7.1.1.1.6.7" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.6.7.1" class="ltx_text" style="background-color:#E6E6E6;">âœ—</span></span>
<span id="S1.T1.7.1.1.1.6.8" class="ltx_td ltx_align_center ltx_border_rr"><span id="S1.T1.7.1.1.1.6.8.1" class="ltx_text" style="background-color:#E6E6E6;">âœ—</span></span></span>
<span id="S1.T1.7.1.1.1.7" class="ltx_tr" style="background-color:#FFFFFF;">
<span id="S1.T1.7.1.1.1.7.1" class="ltx_td ltx_align_center ltx_border_ll"><span id="S1.T1.7.1.1.1.7.1.1" class="ltx_text" style="background-color:#FFFFFF;">UnityPerceptionÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib107" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">107</span></a>, <a href="#bib.bib19" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">19</span></a>]</cite></span></span>
<span id="S1.T1.7.1.1.1.7.2" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.7.2.1" class="ltx_text"></span><span id="S1.T1.7.1.1.1.7.2.2" class="ltx_text" style="background-color:#FFFFFF;"> <span id="S1.T1.7.1.1.1.7.2.2.1" class="ltx_text">
<span id="S1.T1.7.1.1.1.7.2.2.1.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.7.1.1.1.7.2.2.1.1.1" class="ltx_tr">
<span id="S1.T1.7.1.1.1.7.2.2.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Object Detection</span></span>
<span id="S1.T1.7.1.1.1.7.2.2.1.1.2" class="ltx_tr">
<span id="S1.T1.7.1.1.1.7.2.2.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S1.T1.7.1.1.1.7.2.2.1.1.2.1.1" class="ltx_text" style="background-color:#E6E6E6;">Pose Estimation</span></span></span>
</span></span><span id="S1.T1.7.1.1.1.7.2.2.2" class="ltx_text"></span></span></span>
<span id="S1.T1.7.1.1.1.7.3" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.7.3.1" class="ltx_text" style="background-color:#FFFFFF;">âœ—</span></span>
<span id="S1.T1.7.1.1.1.7.4" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.7.4.1" class="ltx_text" style="background-color:#FFFFFF;">âœ—</span></span>
<span id="S1.T1.7.1.1.1.7.5" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.7.5.1" class="ltx_text" style="background-color:#FFFFFF;">âœ—</span></span>
<span id="S1.T1.7.1.1.1.7.6" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.7.6.1" class="ltx_text" style="background-color:#FFFFFF;">âœ“</span></span>
<span id="S1.T1.7.1.1.1.7.7" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.7.7.1" class="ltx_text" style="background-color:#FFFFFF;">rigged clothing</span></span>
<span id="S1.T1.7.1.1.1.7.8" class="ltx_td ltx_align_center ltx_border_rr"><span id="S1.T1.7.1.1.1.7.8.1" class="ltx_text" style="background-color:#FFFFFF;">âœ—</span></span></span>
<span id="S1.T1.7.1.1.1.8" class="ltx_tr" style="background-color:#E6E6E6;">
<span id="S1.T1.7.1.1.1.8.1" class="ltx_td ltx_align_center ltx_border_ll"><span id="S1.T1.7.1.1.1.8.1.1" class="ltx_text" style="background-color:#E6E6E6;">uHumans2Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib82" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">82</span></a>]</cite></span></span>
<span id="S1.T1.7.1.1.1.8.2" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.8.2.1" class="ltx_text" style="background-color:#E6E6E6;">Scene Graphs</span></span>
<span id="S1.T1.7.1.1.1.8.3" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.8.3.1" class="ltx_text" style="background-color:#E6E6E6;">âœ“</span></span>
<span id="S1.T1.7.1.1.1.8.4" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.8.4.1" class="ltx_text" style="background-color:#E6E6E6;">âœ—</span></span>
<span id="S1.T1.7.1.1.1.8.5" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.8.5.1" class="ltx_text" style="background-color:#E6E6E6;">âœ—</span></span>
<span id="S1.T1.7.1.1.1.8.6" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.8.6.1" class="ltx_text" style="background-color:#E6E6E6;">âœ“</span></span>
<span id="S1.T1.7.1.1.1.8.7" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.8.7.1" class="ltx_text" style="background-color:#E6E6E6;">âœ—</span></span>
<span id="S1.T1.7.1.1.1.8.8" class="ltx_td ltx_align_center ltx_border_rr"><span id="S1.T1.7.1.1.1.8.8.1" class="ltx_text" style="background-color:#E6E6E6;">âœ—</span></span></span>
<span id="S1.T1.7.1.1.1.9" class="ltx_tr" style="background-color:#FFFFFF;">
<span id="S1.T1.7.1.1.1.9.1" class="ltx_td ltx_align_center ltx_border_ll ltx_border_tt"><span id="S1.T1.7.1.1.1.9.1.1" class="ltx_text" style="background-color:#FFFFFF;">CarlaÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">18</span></a>]</cite></span></span>
<span id="S1.T1.7.1.1.1.9.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S1.T1.7.1.1.1.9.2.1" class="ltx_text" style="background-color:#FFFFFF;">Driving</span></span>
<span id="S1.T1.7.1.1.1.9.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S1.T1.7.1.1.1.9.3.1" class="ltx_text" style="background-color:#FFFFFF;">âœ“</span></span>
<span id="S1.T1.7.1.1.1.9.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S1.T1.7.1.1.1.9.4.1" class="ltx_text" style="background-color:#FFFFFF;">âœ—</span></span>
<span id="S1.T1.7.1.1.1.9.5" class="ltx_td ltx_align_center ltx_border_tt"><span id="S1.T1.7.1.1.1.9.5.1" class="ltx_text" style="background-color:#FFFFFF;">âœ—</span></span>
<span id="S1.T1.7.1.1.1.9.6" class="ltx_td ltx_align_center ltx_border_tt"><span id="S1.T1.7.1.1.1.9.6.1" class="ltx_text" style="background-color:#FFFFFF;">âœ“</span></span>
<span id="S1.T1.7.1.1.1.9.7" class="ltx_td ltx_align_center ltx_border_tt"><span id="S1.T1.7.1.1.1.9.7.1" class="ltx_text" style="background-color:#FFFFFF;">rigged clothing</span></span>
<span id="S1.T1.7.1.1.1.9.8" class="ltx_td ltx_align_center ltx_border_rr ltx_border_tt"><span id="S1.T1.7.1.1.1.9.8.1" class="ltx_text" style="background-color:#FFFFFF;">âœ—</span></span></span>
<span id="S1.T1.7.1.1.1.10" class="ltx_tr" style="background-color:#E6E6E6;">
<span id="S1.T1.7.1.1.1.10.1" class="ltx_td ltx_align_center ltx_border_ll"><span id="S1.T1.7.1.1.1.10.1.1" class="ltx_text" style="background-color:#E6E6E6;">VirtualHomeÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib71" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">71</span></a>, <a href="#bib.bib72" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">72</span></a>]</cite></span></span>
<span id="S1.T1.7.1.1.1.10.2" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.10.2.1" class="ltx_text" style="background-color:#E6E6E6;">Household Simulation</span></span>
<span id="S1.T1.7.1.1.1.10.3" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.10.3.1" class="ltx_text" style="background-color:#E6E6E6;">âœ“</span></span>
<span id="S1.T1.7.1.1.1.10.4" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.10.4.1" class="ltx_text" style="background-color:#E6E6E6;">âœ“</span></span>
<span id="S1.T1.7.1.1.1.10.5" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.10.5.1" class="ltx_text" style="background-color:#E6E6E6;">âœ—</span></span>
<span id="S1.T1.7.1.1.1.10.6" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.10.6.1" class="ltx_text" style="background-color:#E6E6E6;">âœ“</span></span>
<span id="S1.T1.7.1.1.1.10.7" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.10.7.1" class="ltx_text" style="background-color:#E6E6E6;">rigged clothing</span></span>
<span id="S1.T1.7.1.1.1.10.8" class="ltx_td ltx_align_center ltx_border_rr"><span id="S1.T1.7.1.1.1.10.8.1" class="ltx_text" style="background-color:#E6E6E6;">âœ—</span></span></span>
<span id="S1.T1.7.1.1.1.11" class="ltx_tr" style="background-color:#FFFFFF;">
<span id="S1.T1.7.1.1.1.11.1" class="ltx_td ltx_align_center ltx_border_ll"><span id="S1.T1.7.1.1.1.11.1.1" class="ltx_text" style="background-color:#FFFFFF;">VRKitchenÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">22</span></a>]</cite></span></span>
<span id="S1.T1.7.1.1.1.11.2" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.11.2.1" class="ltx_text" style="background-color:#FFFFFF;">Cooking Simulation</span></span>
<span id="S1.T1.7.1.1.1.11.3" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.11.3.1" class="ltx_text" style="background-color:#FFFFFF;">âœ“</span></span>
<span id="S1.T1.7.1.1.1.11.4" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.11.4.1" class="ltx_text" style="background-color:#FFFFFF;">âœ“</span></span>
<span id="S1.T1.7.1.1.1.11.5" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.11.5.1" class="ltx_text" style="background-color:#FFFFFF;">âœ—</span></span>
<span id="S1.T1.7.1.1.1.11.6" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.11.6.1" class="ltx_text" style="background-color:#FFFFFF;">âœ—</span></span>
<span id="S1.T1.7.1.1.1.11.7" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.11.7.1" class="ltx_text" style="background-color:#FFFFFF;">âœ—</span></span>
<span id="S1.T1.7.1.1.1.11.8" class="ltx_td ltx_align_center ltx_border_rr"><span id="S1.T1.7.1.1.1.11.8.1" class="ltx_text" style="background-color:#FFFFFF;">âœ—</span></span></span>
<span id="S1.T1.7.1.1.1.12" class="ltx_tr" style="background-color:#E6E6E6;">
<span id="S1.T1.7.1.1.1.12.1" class="ltx_td ltx_align_center ltx_border_ll"><span id="S1.T1.7.1.1.1.12.1.1" class="ltx_text" style="background-color:#E6E6E6;">Habitat 2.0Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib100" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">100</span></a>]</cite></span></span>
<span id="S1.T1.7.1.1.1.12.2" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.12.2.1" class="ltx_text" style="background-color:#E6E6E6;">Embodied Robots</span></span>
<span id="S1.T1.7.1.1.1.12.3" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.12.3.1" class="ltx_text" style="background-color:#E6E6E6;">âœ“</span></span>
<span id="S1.T1.7.1.1.1.12.4" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.12.4.1" class="ltx_text" style="background-color:#E6E6E6;">âœ—</span></span>
<span id="S1.T1.7.1.1.1.12.5" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.12.5.1" class="ltx_text" style="background-color:#E6E6E6;">âœ—</span></span>
<span id="S1.T1.7.1.1.1.12.6" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.12.6.1" class="ltx_text" style="background-color:#E6E6E6;">âœ—</span></span>
<span id="S1.T1.7.1.1.1.12.7" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.12.7.1" class="ltx_text" style="background-color:#E6E6E6;">âœ—</span></span>
<span id="S1.T1.7.1.1.1.12.8" class="ltx_td ltx_align_center ltx_border_rr"><span id="S1.T1.7.1.1.1.12.8.1" class="ltx_text" style="background-color:#E6E6E6;">âœ—</span></span></span>
<span id="S1.T1.7.1.1.1.13" class="ltx_tr" style="background-color:#FFFFFF;">
<span id="S1.T1.7.1.1.1.13.1" class="ltx_td ltx_align_center ltx_border_ll"><span id="S1.T1.7.1.1.1.13.1.1" class="ltx_text" style="background-color:#FFFFFF;">Habitat 3.0Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib73" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">73</span></a>]</cite></span></span>
<span id="S1.T1.7.1.1.1.13.2" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.13.2.1" class="ltx_text"></span><span id="S1.T1.7.1.1.1.13.2.2" class="ltx_text" style="background-color:#FFFFFF;"> <span id="S1.T1.7.1.1.1.13.2.2.1" class="ltx_text">
<span id="S1.T1.7.1.1.1.13.2.2.1.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.7.1.1.1.13.2.2.1.1.1" class="ltx_tr">
<span id="S1.T1.7.1.1.1.13.2.2.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Human-robot</span></span>
<span id="S1.T1.7.1.1.1.13.2.2.1.1.2" class="ltx_tr">
<span id="S1.T1.7.1.1.1.13.2.2.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S1.T1.7.1.1.1.13.2.2.1.1.2.1.1" class="ltx_text" style="background-color:#E6E6E6;">Interaction</span></span></span>
</span></span><span id="S1.T1.7.1.1.1.13.2.2.2" class="ltx_text"></span></span></span>
<span id="S1.T1.7.1.1.1.13.3" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.13.3.1" class="ltx_text" style="background-color:#FFFFFF;">âœ“</span></span>
<span id="S1.T1.7.1.1.1.13.4" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.13.4.1" class="ltx_text" style="background-color:#FFFFFF;">âœ—</span></span>
<span id="S1.T1.7.1.1.1.13.5" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.13.5.1" class="ltx_text" style="background-color:#FFFFFF;">âœ—</span></span>
<span id="S1.T1.7.1.1.1.13.6" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.13.6.1" class="ltx_text" style="background-color:#FFFFFF;">âœ“</span></span>
<span id="S1.T1.7.1.1.1.13.7" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.13.7.1" class="ltx_text" style="background-color:#FFFFFF;">âœ—</span></span>
<span id="S1.T1.7.1.1.1.13.8" class="ltx_td ltx_align_center ltx_border_rr"><span id="S1.T1.7.1.1.1.13.8.1" class="ltx_text" style="background-color:#FFFFFF;">âœ—</span></span></span>
<span id="S1.T1.7.1.1.1.14" class="ltx_tr" style="background-color:#E6E6E6;">
<span id="S1.T1.7.1.1.1.14.1" class="ltx_td ltx_align_center ltx_border_ll ltx_border_tt"><span id="S1.T1.7.1.1.1.14.1.1" class="ltx_text" style="background-color:#E6E6E6;">UnrealEgoÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">5</span></a>]</cite></span></span>
<span id="S1.T1.7.1.1.1.14.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S1.T1.7.1.1.1.14.2.1" class="ltx_text" style="background-color:#E6E6E6;">Ego-pose Estimation</span></span>
<span id="S1.T1.7.1.1.1.14.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S1.T1.7.1.1.1.14.3.1" class="ltx_text" style="background-color:#E6E6E6;">âœ“</span></span>
<span id="S1.T1.7.1.1.1.14.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S1.T1.7.1.1.1.14.4.1" class="ltx_text" style="background-color:#E6E6E6;">âœ“</span></span>
<span id="S1.T1.7.1.1.1.14.5" class="ltx_td ltx_align_center ltx_border_tt"><span id="S1.T1.7.1.1.1.14.5.1" class="ltx_text" style="background-color:#E6E6E6;">âœ“</span></span>
<span id="S1.T1.7.1.1.1.14.6" class="ltx_td ltx_align_center ltx_border_tt"><span id="S1.T1.7.1.1.1.14.6.1" class="ltx_text" style="background-color:#E6E6E6;">âœ“</span></span>
<span id="S1.T1.7.1.1.1.14.7" class="ltx_td ltx_align_center ltx_border_tt"><span id="S1.T1.7.1.1.1.14.7.1" class="ltx_text" style="background-color:#E6E6E6;">rigged clothing</span></span>
<span id="S1.T1.7.1.1.1.14.8" class="ltx_td ltx_align_center ltx_border_rr ltx_border_tt"><span id="S1.T1.7.1.1.1.14.8.1" class="ltx_text" style="background-color:#E6E6E6;">âœ—</span></span></span>
<span id="S1.T1.7.1.1.1.15" class="ltx_tr" style="background-color:#FFFFFF;">
<span id="S1.T1.7.1.1.1.15.1" class="ltx_td ltx_align_center ltx_border_ll"><span id="S1.T1.7.1.1.1.15.1.1" class="ltx_text" style="background-color:#FFFFFF;">GTA-HumanÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">11</span></a>]</cite></span></span>
<span id="S1.T1.7.1.1.1.15.2" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.15.2.1" class="ltx_text" style="background-color:#FFFFFF;">Pose Estimation</span></span>
<span id="S1.T1.7.1.1.1.15.3" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.15.3.1" class="ltx_text" style="background-color:#FFFFFF;">âœ—</span></span>
<span id="S1.T1.7.1.1.1.15.4" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.15.4.1" class="ltx_text" style="background-color:#FFFFFF;">âœ—</span></span>
<span id="S1.T1.7.1.1.1.15.5" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.15.5.1" class="ltx_text" style="background-color:#FFFFFF;">âœ—</span></span>
<span id="S1.T1.7.1.1.1.15.6" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.15.6.1" class="ltx_text" style="background-color:#FFFFFF;">âœ“</span></span>
<span id="S1.T1.7.1.1.1.15.7" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.15.7.1" class="ltx_text" style="background-color:#FFFFFF;">âœ—</span></span>
<span id="S1.T1.7.1.1.1.15.8" class="ltx_td ltx_align_center ltx_border_rr"><span id="S1.T1.7.1.1.1.15.8.1" class="ltx_text" style="background-color:#FFFFFF;">âœ—</span></span></span>
<span id="S1.T1.7.1.1.1.16" class="ltx_tr" style="background-color:#E6E6E6;">
<span id="S1.T1.7.1.1.1.16.1" class="ltx_td ltx_align_center ltx_border_ll"><span id="S1.T1.7.1.1.1.16.1.1" class="ltx_text" style="background-color:#E6E6E6;">BEDLAMÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">9</span></a>]</cite></span></span>
<span id="S1.T1.7.1.1.1.16.2" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.16.2.1" class="ltx_text" style="background-color:#E6E6E6;">Pose Estimation</span></span>
<span id="S1.T1.7.1.1.1.16.3" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.16.3.1" class="ltx_text" style="background-color:#E6E6E6;">âœ—</span></span>
<span id="S1.T1.7.1.1.1.16.4" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.16.4.1" class="ltx_text" style="background-color:#E6E6E6;">âœ—</span></span>
<span id="S1.T1.7.1.1.1.16.5" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.16.5.1" class="ltx_text" style="background-color:#E6E6E6;">âœ—</span></span>
<span id="S1.T1.7.1.1.1.16.6" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.16.6.1" class="ltx_text" style="background-color:#E6E6E6;">âœ“</span></span>
<span id="S1.T1.7.1.1.1.16.7" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.16.7.1" class="ltx_text" style="background-color:#E6E6E6;">âœ—</span></span>
<span id="S1.T1.7.1.1.1.16.8" class="ltx_td ltx_align_center ltx_border_rr"><span id="S1.T1.7.1.1.1.16.8.1" class="ltx_text" style="background-color:#E6E6E6;">âœ—</span></span></span>
<span id="S1.T1.7.1.1.1.17" class="ltx_tr" style="background-color:#FFFFFF;">
<span id="S1.T1.7.1.1.1.17.1" class="ltx_td ltx_align_center ltx_border_ll"><span id="S1.T1.7.1.1.1.17.1.1" class="ltx_text" style="background-color:#FFFFFF;">SynBodyÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib119" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">119</span></a>]</cite></span></span>
<span id="S1.T1.7.1.1.1.17.2" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.17.2.1" class="ltx_text" style="background-color:#FFFFFF;">Pose Estimation</span></span>
<span id="S1.T1.7.1.1.1.17.3" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.17.3.1" class="ltx_text" style="background-color:#FFFFFF;">âœ—</span></span>
<span id="S1.T1.7.1.1.1.17.4" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.17.4.1" class="ltx_text" style="background-color:#FFFFFF;">âœ—</span></span>
<span id="S1.T1.7.1.1.1.17.5" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.17.5.1" class="ltx_text" style="background-color:#FFFFFF;">âœ—</span></span>
<span id="S1.T1.7.1.1.1.17.6" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.17.6.1" class="ltx_text" style="background-color:#FFFFFF;">âœ“</span></span>
<span id="S1.T1.7.1.1.1.17.7" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.17.7.1" class="ltx_text" style="background-color:#FFFFFF;">âœ—</span></span>
<span id="S1.T1.7.1.1.1.17.8" class="ltx_td ltx_align_center ltx_border_rr"><span id="S1.T1.7.1.1.1.17.8.1" class="ltx_text" style="background-color:#FFFFFF;">âœ—</span></span></span>
<span id="S1.T1.7.1.1.1.18" class="ltx_tr" style="background-color:#E6E6E6;">
<span id="S1.T1.7.1.1.1.18.1" class="ltx_td ltx_align_center ltx_border_ll"><span id="S1.T1.7.1.1.1.18.1.1" class="ltx_text" style="background-color:#E6E6E6;">ADTÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib65" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">65</span></a>]</cite></span></span>
<span id="S1.T1.7.1.1.1.18.2" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.18.2.1" class="ltx_text" style="background-color:#E6E6E6;">Digital Twin</span></span>
<span id="S1.T1.7.1.1.1.18.3" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.18.3.1" class="ltx_text" style="background-color:#E6E6E6;">âœ“</span></span>
<span id="S1.T1.7.1.1.1.18.4" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.18.4.1" class="ltx_text" style="background-color:#E6E6E6;">âœ“</span></span>
<span id="S1.T1.7.1.1.1.18.5" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.18.5.1" class="ltx_text" style="background-color:#E6E6E6;">âœ“</span></span>
<span id="S1.T1.7.1.1.1.18.6" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.18.6.1" class="ltx_text" style="background-color:#E6E6E6;">âœ—</span></span>
<span id="S1.T1.7.1.1.1.18.7" class="ltx_td ltx_align_center"><span id="S1.T1.7.1.1.1.18.7.1" class="ltx_text" style="background-color:#E6E6E6;">âœ—</span></span>
<span id="S1.T1.7.1.1.1.18.8" class="ltx_td ltx_align_center ltx_border_rr"><span id="S1.T1.7.1.1.1.18.8.1" class="ltx_text" style="background-color:#E6E6E6;">âœ—</span></span></span>
<span id="S1.T1.7.1.1.1.19" class="ltx_tr" style="background-color:#FFFFFF;">
<span id="S1.T1.7.1.1.1.19.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_ll ltx_border_tt"><span id="S1.T1.7.1.1.1.19.1.1" class="ltx_text" style="background-color:#FFFFFF;">EgoGen (ours)</span></span>
<span id="S1.T1.7.1.1.1.19.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_tt"><span id="S1.T1.7.1.1.1.19.2.1" class="ltx_text"></span><span id="S1.T1.7.1.1.1.19.2.2" class="ltx_text" style="background-color:#FFFFFF;"> <span id="S1.T1.7.1.1.1.19.2.2.1" class="ltx_text">
<span id="S1.T1.7.1.1.1.19.2.2.1.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.7.1.1.1.19.2.2.1.1.1" class="ltx_tr">
<span id="S1.T1.7.1.1.1.19.2.2.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Head-mounted</span></span>
<span id="S1.T1.7.1.1.1.19.2.2.1.1.2" class="ltx_tr">
<span id="S1.T1.7.1.1.1.19.2.2.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S1.T1.7.1.1.1.19.2.2.1.1.2.1.1" class="ltx_text" style="background-color:#E6E6E6;">Devices</span></span></span>
</span></span><span id="S1.T1.7.1.1.1.19.2.2.2" class="ltx_text"></span></span></span>
<span id="S1.T1.7.1.1.1.19.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_tt"><span id="S1.T1.7.1.1.1.19.3.1" class="ltx_text" style="background-color:#FFFFFF;">âœ“</span></span>
<span id="S1.T1.7.1.1.1.19.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_tt"><span id="S1.T1.7.1.1.1.19.4.1" class="ltx_text" style="background-color:#FFFFFF;">âœ“</span></span>
<span id="S1.T1.7.1.1.1.19.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_tt"><span id="S1.T1.7.1.1.1.19.5.1" class="ltx_text" style="background-color:#FFFFFF;">âœ“</span></span>
<span id="S1.T1.7.1.1.1.19.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_tt"><span id="S1.T1.7.1.1.1.19.6.1" class="ltx_text" style="background-color:#FFFFFF;">âœ“</span></span>
<span id="S1.T1.7.1.1.1.19.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_tt"><span id="S1.T1.7.1.1.1.19.7.1" class="ltx_text" style="background-color:#FFFFFF;">âœ“</span></span>
<span id="S1.T1.7.1.1.1.19.8" class="ltx_td ltx_align_center ltx_border_b ltx_border_rr ltx_border_tt"><span id="S1.T1.7.1.1.1.19.8.1" class="ltx_text" style="background-color:#FFFFFF;">âœ“</span></span></span>
</span></span></p>
</span></div>
</figure>
</section>
<section id="S2a" class="ltx_section ltx_centering">
<h2 class="ltx_title ltx_title_section" style="font-size:144%;">
<span class="ltx_tag ltx_tag_section">S2 </span>Ego-Sensing Driven Motion Synthesis</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:144%;">
<span class="ltx_tag ltx_tag_subsection">S2.1 </span>Egocentric Sensing Calculation</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p"><span id="S2.SS1.p1.1.1" class="ltx_text" style="font-size:144%;">As a compact and cheap-to-compute representation of depth maps, egocentric sensing resembles the calculation of depth information but is simplified into 2D.</span></p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.7" class="ltx_p"><span id="S2.SS1.p2.7.1" class="ltx_text" style="font-size:144%;">As shown inÂ </span><a href="#S3.F3" title="In S3.1 Embodied Camera Placement â€£ S3 Egocentric Synthetic Data Generation â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref" style="font-size:144%;"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">S3</span></a><span id="S2.SS1.p2.7.2" class="ltx_text" style="font-size:144%;">, the location of the egocentric camera is the midpoint of two eyeballs, and the viewing direction </span><math id="S2.SS1.p2.1.m1.1" class="ltx_Math" alttext="\vv{\mathbf{v}}" display="inline"><semantics id="S2.SS1.p2.1.m1.1a"><mrow id="S2.SS1.p2.1.m1.1.1" xref="S2.SS1.p2.1.m1.1.1.cmml"><merror class="ltx_ERROR undefined undefined" id="S2.SS1.p2.1.m1.1.1.2" xref="S2.SS1.p2.1.m1.1.1.2b.cmml"><mtext id="S2.SS1.p2.1.m1.1.1.2a" xref="S2.SS1.p2.1.m1.1.1.2b.cmml">\vv</mtext></merror><mo lspace="0em" rspace="0em" id="S2.SS1.p2.1.m1.1.1.1" xref="S2.SS1.p2.1.m1.1.1.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.SS1.p2.1.m1.1.1.3" xref="S2.SS1.p2.1.m1.1.1.3.cmml">ğ¯</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.1.m1.1b"><apply id="S2.SS1.p2.1.m1.1.1.cmml" xref="S2.SS1.p2.1.m1.1.1"><times id="S2.SS1.p2.1.m1.1.1.1.cmml" xref="S2.SS1.p2.1.m1.1.1.1"></times><ci id="S2.SS1.p2.1.m1.1.1.2b.cmml" xref="S2.SS1.p2.1.m1.1.1.2"><merror class="ltx_ERROR undefined undefined" id="S2.SS1.p2.1.m1.1.1.2.cmml" xref="S2.SS1.p2.1.m1.1.1.2"><mtext id="S2.SS1.p2.1.m1.1.1.2a.cmml" xref="S2.SS1.p2.1.m1.1.1.2">\vv</mtext></merror></ci><ci id="S2.SS1.p2.1.m1.1.1.3.cmml" xref="S2.SS1.p2.1.m1.1.1.3">ğ¯</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.1.m1.1c">\vv{\mathbf{v}}</annotation></semantics></math><span id="S2.SS1.p2.7.3" class="ltx_text" style="font-size:144%;"> is visualized as the red arrow.
</span><math id="S2.SS1.p2.2.m2.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S2.SS1.p2.2.m2.1a"><mi mathsize="144%" id="S2.SS1.p2.2.m2.1.1" xref="S2.SS1.p2.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.2.m2.1b"><ci id="S2.SS1.p2.2.m2.1.1.cmml" xref="S2.SS1.p2.2.m2.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.2.m2.1c">N</annotation></semantics></math><span id="S2.SS1.p2.7.4" class="ltx_text" style="font-size:144%;"> rays are cast from the location of the egocentric camera, with the central direction of these rays determined by the 2D projection of </span><math id="S2.SS1.p2.3.m3.1" class="ltx_Math" alttext="\vv{\mathbf{v}}" display="inline"><semantics id="S2.SS1.p2.3.m3.1a"><mrow id="S2.SS1.p2.3.m3.1.1" xref="S2.SS1.p2.3.m3.1.1.cmml"><merror class="ltx_ERROR undefined undefined" id="S2.SS1.p2.3.m3.1.1.2" xref="S2.SS1.p2.3.m3.1.1.2b.cmml"><mtext id="S2.SS1.p2.3.m3.1.1.2a" xref="S2.SS1.p2.3.m3.1.1.2b.cmml">\vv</mtext></merror><mo lspace="0em" rspace="0em" id="S2.SS1.p2.3.m3.1.1.1" xref="S2.SS1.p2.3.m3.1.1.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.SS1.p2.3.m3.1.1.3" xref="S2.SS1.p2.3.m3.1.1.3.cmml">ğ¯</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.3.m3.1b"><apply id="S2.SS1.p2.3.m3.1.1.cmml" xref="S2.SS1.p2.3.m3.1.1"><times id="S2.SS1.p2.3.m3.1.1.1.cmml" xref="S2.SS1.p2.3.m3.1.1.1"></times><ci id="S2.SS1.p2.3.m3.1.1.2b.cmml" xref="S2.SS1.p2.3.m3.1.1.2"><merror class="ltx_ERROR undefined undefined" id="S2.SS1.p2.3.m3.1.1.2.cmml" xref="S2.SS1.p2.3.m3.1.1.2"><mtext id="S2.SS1.p2.3.m3.1.1.2a.cmml" xref="S2.SS1.p2.3.m3.1.1.2">\vv</mtext></merror></ci><ci id="S2.SS1.p2.3.m3.1.1.3.cmml" xref="S2.SS1.p2.3.m3.1.1.3">ğ¯</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.3.m3.1c">\vv{\mathbf{v}}</annotation></semantics></math><span id="S2.SS1.p2.7.5" class="ltx_text" style="font-size:144%;">.
The starting points of these rays are identical, while their endpoints form a semicircle in front of the virtual human, representing the field of view </span><math id="S2.SS1.p2.4.m4.2" class="ltx_Math" alttext="[\theta_{min},\theta_{max}]" display="inline"><semantics id="S2.SS1.p2.4.m4.2a"><mrow id="S2.SS1.p2.4.m4.2.2.2" xref="S2.SS1.p2.4.m4.2.2.3.cmml"><mo maxsize="144%" minsize="144%" id="S2.SS1.p2.4.m4.2.2.2.3" xref="S2.SS1.p2.4.m4.2.2.3.cmml">[</mo><msub id="S2.SS1.p2.4.m4.1.1.1.1" xref="S2.SS1.p2.4.m4.1.1.1.1.cmml"><mi mathsize="144%" id="S2.SS1.p2.4.m4.1.1.1.1.2" xref="S2.SS1.p2.4.m4.1.1.1.1.2.cmml">Î¸</mi><mrow id="S2.SS1.p2.4.m4.1.1.1.1.3" xref="S2.SS1.p2.4.m4.1.1.1.1.3.cmml"><mi mathsize="144%" id="S2.SS1.p2.4.m4.1.1.1.1.3.2" xref="S2.SS1.p2.4.m4.1.1.1.1.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p2.4.m4.1.1.1.1.3.1" xref="S2.SS1.p2.4.m4.1.1.1.1.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.SS1.p2.4.m4.1.1.1.1.3.3" xref="S2.SS1.p2.4.m4.1.1.1.1.3.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p2.4.m4.1.1.1.1.3.1a" xref="S2.SS1.p2.4.m4.1.1.1.1.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.SS1.p2.4.m4.1.1.1.1.3.4" xref="S2.SS1.p2.4.m4.1.1.1.1.3.4.cmml">n</mi></mrow></msub><mo mathsize="144%" id="S2.SS1.p2.4.m4.2.2.2.4" xref="S2.SS1.p2.4.m4.2.2.3.cmml">,</mo><msub id="S2.SS1.p2.4.m4.2.2.2.2" xref="S2.SS1.p2.4.m4.2.2.2.2.cmml"><mi mathsize="144%" id="S2.SS1.p2.4.m4.2.2.2.2.2" xref="S2.SS1.p2.4.m4.2.2.2.2.2.cmml">Î¸</mi><mrow id="S2.SS1.p2.4.m4.2.2.2.2.3" xref="S2.SS1.p2.4.m4.2.2.2.2.3.cmml"><mi mathsize="144%" id="S2.SS1.p2.4.m4.2.2.2.2.3.2" xref="S2.SS1.p2.4.m4.2.2.2.2.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p2.4.m4.2.2.2.2.3.1" xref="S2.SS1.p2.4.m4.2.2.2.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.SS1.p2.4.m4.2.2.2.2.3.3" xref="S2.SS1.p2.4.m4.2.2.2.2.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p2.4.m4.2.2.2.2.3.1a" xref="S2.SS1.p2.4.m4.2.2.2.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.SS1.p2.4.m4.2.2.2.2.3.4" xref="S2.SS1.p2.4.m4.2.2.2.2.3.4.cmml">x</mi></mrow></msub><mo maxsize="144%" minsize="144%" id="S2.SS1.p2.4.m4.2.2.2.5" xref="S2.SS1.p2.4.m4.2.2.3.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.4.m4.2b"><interval closure="closed" id="S2.SS1.p2.4.m4.2.2.3.cmml" xref="S2.SS1.p2.4.m4.2.2.2"><apply id="S2.SS1.p2.4.m4.1.1.1.1.cmml" xref="S2.SS1.p2.4.m4.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.4.m4.1.1.1.1.1.cmml" xref="S2.SS1.p2.4.m4.1.1.1.1">subscript</csymbol><ci id="S2.SS1.p2.4.m4.1.1.1.1.2.cmml" xref="S2.SS1.p2.4.m4.1.1.1.1.2">ğœƒ</ci><apply id="S2.SS1.p2.4.m4.1.1.1.1.3.cmml" xref="S2.SS1.p2.4.m4.1.1.1.1.3"><times id="S2.SS1.p2.4.m4.1.1.1.1.3.1.cmml" xref="S2.SS1.p2.4.m4.1.1.1.1.3.1"></times><ci id="S2.SS1.p2.4.m4.1.1.1.1.3.2.cmml" xref="S2.SS1.p2.4.m4.1.1.1.1.3.2">ğ‘š</ci><ci id="S2.SS1.p2.4.m4.1.1.1.1.3.3.cmml" xref="S2.SS1.p2.4.m4.1.1.1.1.3.3">ğ‘–</ci><ci id="S2.SS1.p2.4.m4.1.1.1.1.3.4.cmml" xref="S2.SS1.p2.4.m4.1.1.1.1.3.4">ğ‘›</ci></apply></apply><apply id="S2.SS1.p2.4.m4.2.2.2.2.cmml" xref="S2.SS1.p2.4.m4.2.2.2.2"><csymbol cd="ambiguous" id="S2.SS1.p2.4.m4.2.2.2.2.1.cmml" xref="S2.SS1.p2.4.m4.2.2.2.2">subscript</csymbol><ci id="S2.SS1.p2.4.m4.2.2.2.2.2.cmml" xref="S2.SS1.p2.4.m4.2.2.2.2.2">ğœƒ</ci><apply id="S2.SS1.p2.4.m4.2.2.2.2.3.cmml" xref="S2.SS1.p2.4.m4.2.2.2.2.3"><times id="S2.SS1.p2.4.m4.2.2.2.2.3.1.cmml" xref="S2.SS1.p2.4.m4.2.2.2.2.3.1"></times><ci id="S2.SS1.p2.4.m4.2.2.2.2.3.2.cmml" xref="S2.SS1.p2.4.m4.2.2.2.2.3.2">ğ‘š</ci><ci id="S2.SS1.p2.4.m4.2.2.2.2.3.3.cmml" xref="S2.SS1.p2.4.m4.2.2.2.2.3.3">ğ‘</ci><ci id="S2.SS1.p2.4.m4.2.2.2.2.3.4.cmml" xref="S2.SS1.p2.4.m4.2.2.2.2.3.4">ğ‘¥</ci></apply></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.4.m4.2c">[\theta_{min},\theta_{max}]</annotation></semantics></math><span id="S2.SS1.p2.7.6" class="ltx_text" style="font-size:144%;"> to the human. Each ray has the potential to extend infinitely.
In our implementation, </span><math id="S2.SS1.p2.5.m5.1" class="ltx_Math" alttext="N=32" display="inline"><semantics id="S2.SS1.p2.5.m5.1a"><mrow id="S2.SS1.p2.5.m5.1.1" xref="S2.SS1.p2.5.m5.1.1.cmml"><mi mathsize="144%" id="S2.SS1.p2.5.m5.1.1.2" xref="S2.SS1.p2.5.m5.1.1.2.cmml">N</mi><mo mathsize="144%" id="S2.SS1.p2.5.m5.1.1.1" xref="S2.SS1.p2.5.m5.1.1.1.cmml">=</mo><mn mathsize="144%" id="S2.SS1.p2.5.m5.1.1.3" xref="S2.SS1.p2.5.m5.1.1.3.cmml">32</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.5.m5.1b"><apply id="S2.SS1.p2.5.m5.1.1.cmml" xref="S2.SS1.p2.5.m5.1.1"><eq id="S2.SS1.p2.5.m5.1.1.1.cmml" xref="S2.SS1.p2.5.m5.1.1.1"></eq><ci id="S2.SS1.p2.5.m5.1.1.2.cmml" xref="S2.SS1.p2.5.m5.1.1.2">ğ‘</ci><cn type="integer" id="S2.SS1.p2.5.m5.1.1.3.cmml" xref="S2.SS1.p2.5.m5.1.1.3">32</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.5.m5.1c">N=32</annotation></semantics></math><span id="S2.SS1.p2.7.7" class="ltx_text" style="font-size:144%;">, </span><math id="S2.SS1.p2.6.m6.1" class="ltx_Math" alttext="\theta_{min}=-90^{\circ}" display="inline"><semantics id="S2.SS1.p2.6.m6.1a"><mrow id="S2.SS1.p2.6.m6.1.1" xref="S2.SS1.p2.6.m6.1.1.cmml"><msub id="S2.SS1.p2.6.m6.1.1.2" xref="S2.SS1.p2.6.m6.1.1.2.cmml"><mi mathsize="144%" id="S2.SS1.p2.6.m6.1.1.2.2" xref="S2.SS1.p2.6.m6.1.1.2.2.cmml">Î¸</mi><mrow id="S2.SS1.p2.6.m6.1.1.2.3" xref="S2.SS1.p2.6.m6.1.1.2.3.cmml"><mi mathsize="144%" id="S2.SS1.p2.6.m6.1.1.2.3.2" xref="S2.SS1.p2.6.m6.1.1.2.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p2.6.m6.1.1.2.3.1" xref="S2.SS1.p2.6.m6.1.1.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.SS1.p2.6.m6.1.1.2.3.3" xref="S2.SS1.p2.6.m6.1.1.2.3.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p2.6.m6.1.1.2.3.1a" xref="S2.SS1.p2.6.m6.1.1.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.SS1.p2.6.m6.1.1.2.3.4" xref="S2.SS1.p2.6.m6.1.1.2.3.4.cmml">n</mi></mrow></msub><mo mathsize="144%" id="S2.SS1.p2.6.m6.1.1.1" xref="S2.SS1.p2.6.m6.1.1.1.cmml">=</mo><mrow id="S2.SS1.p2.6.m6.1.1.3" xref="S2.SS1.p2.6.m6.1.1.3.cmml"><mo mathsize="144%" id="S2.SS1.p2.6.m6.1.1.3a" xref="S2.SS1.p2.6.m6.1.1.3.cmml">âˆ’</mo><msup id="S2.SS1.p2.6.m6.1.1.3.2" xref="S2.SS1.p2.6.m6.1.1.3.2.cmml"><mn mathsize="144%" id="S2.SS1.p2.6.m6.1.1.3.2.2" xref="S2.SS1.p2.6.m6.1.1.3.2.2.cmml">90</mn><mo mathsize="144%" id="S2.SS1.p2.6.m6.1.1.3.2.3" xref="S2.SS1.p2.6.m6.1.1.3.2.3.cmml">âˆ˜</mo></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.6.m6.1b"><apply id="S2.SS1.p2.6.m6.1.1.cmml" xref="S2.SS1.p2.6.m6.1.1"><eq id="S2.SS1.p2.6.m6.1.1.1.cmml" xref="S2.SS1.p2.6.m6.1.1.1"></eq><apply id="S2.SS1.p2.6.m6.1.1.2.cmml" xref="S2.SS1.p2.6.m6.1.1.2"><csymbol cd="ambiguous" id="S2.SS1.p2.6.m6.1.1.2.1.cmml" xref="S2.SS1.p2.6.m6.1.1.2">subscript</csymbol><ci id="S2.SS1.p2.6.m6.1.1.2.2.cmml" xref="S2.SS1.p2.6.m6.1.1.2.2">ğœƒ</ci><apply id="S2.SS1.p2.6.m6.1.1.2.3.cmml" xref="S2.SS1.p2.6.m6.1.1.2.3"><times id="S2.SS1.p2.6.m6.1.1.2.3.1.cmml" xref="S2.SS1.p2.6.m6.1.1.2.3.1"></times><ci id="S2.SS1.p2.6.m6.1.1.2.3.2.cmml" xref="S2.SS1.p2.6.m6.1.1.2.3.2">ğ‘š</ci><ci id="S2.SS1.p2.6.m6.1.1.2.3.3.cmml" xref="S2.SS1.p2.6.m6.1.1.2.3.3">ğ‘–</ci><ci id="S2.SS1.p2.6.m6.1.1.2.3.4.cmml" xref="S2.SS1.p2.6.m6.1.1.2.3.4">ğ‘›</ci></apply></apply><apply id="S2.SS1.p2.6.m6.1.1.3.cmml" xref="S2.SS1.p2.6.m6.1.1.3"><minus id="S2.SS1.p2.6.m6.1.1.3.1.cmml" xref="S2.SS1.p2.6.m6.1.1.3"></minus><apply id="S2.SS1.p2.6.m6.1.1.3.2.cmml" xref="S2.SS1.p2.6.m6.1.1.3.2"><csymbol cd="ambiguous" id="S2.SS1.p2.6.m6.1.1.3.2.1.cmml" xref="S2.SS1.p2.6.m6.1.1.3.2">superscript</csymbol><cn type="integer" id="S2.SS1.p2.6.m6.1.1.3.2.2.cmml" xref="S2.SS1.p2.6.m6.1.1.3.2.2">90</cn><compose id="S2.SS1.p2.6.m6.1.1.3.2.3.cmml" xref="S2.SS1.p2.6.m6.1.1.3.2.3"></compose></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.6.m6.1c">\theta_{min}=-90^{\circ}</annotation></semantics></math><span id="S2.SS1.p2.7.8" class="ltx_text" style="font-size:144%;">, </span><math id="S2.SS1.p2.7.m7.1" class="ltx_Math" alttext="\theta_{max}=90^{\circ}" display="inline"><semantics id="S2.SS1.p2.7.m7.1a"><mrow id="S2.SS1.p2.7.m7.1.1" xref="S2.SS1.p2.7.m7.1.1.cmml"><msub id="S2.SS1.p2.7.m7.1.1.2" xref="S2.SS1.p2.7.m7.1.1.2.cmml"><mi mathsize="144%" id="S2.SS1.p2.7.m7.1.1.2.2" xref="S2.SS1.p2.7.m7.1.1.2.2.cmml">Î¸</mi><mrow id="S2.SS1.p2.7.m7.1.1.2.3" xref="S2.SS1.p2.7.m7.1.1.2.3.cmml"><mi mathsize="144%" id="S2.SS1.p2.7.m7.1.1.2.3.2" xref="S2.SS1.p2.7.m7.1.1.2.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p2.7.m7.1.1.2.3.1" xref="S2.SS1.p2.7.m7.1.1.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.SS1.p2.7.m7.1.1.2.3.3" xref="S2.SS1.p2.7.m7.1.1.2.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p2.7.m7.1.1.2.3.1a" xref="S2.SS1.p2.7.m7.1.1.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.SS1.p2.7.m7.1.1.2.3.4" xref="S2.SS1.p2.7.m7.1.1.2.3.4.cmml">x</mi></mrow></msub><mo mathsize="144%" id="S2.SS1.p2.7.m7.1.1.1" xref="S2.SS1.p2.7.m7.1.1.1.cmml">=</mo><msup id="S2.SS1.p2.7.m7.1.1.3" xref="S2.SS1.p2.7.m7.1.1.3.cmml"><mn mathsize="144%" id="S2.SS1.p2.7.m7.1.1.3.2" xref="S2.SS1.p2.7.m7.1.1.3.2.cmml">90</mn><mo mathsize="144%" id="S2.SS1.p2.7.m7.1.1.3.3" xref="S2.SS1.p2.7.m7.1.1.3.3.cmml">âˆ˜</mo></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.7.m7.1b"><apply id="S2.SS1.p2.7.m7.1.1.cmml" xref="S2.SS1.p2.7.m7.1.1"><eq id="S2.SS1.p2.7.m7.1.1.1.cmml" xref="S2.SS1.p2.7.m7.1.1.1"></eq><apply id="S2.SS1.p2.7.m7.1.1.2.cmml" xref="S2.SS1.p2.7.m7.1.1.2"><csymbol cd="ambiguous" id="S2.SS1.p2.7.m7.1.1.2.1.cmml" xref="S2.SS1.p2.7.m7.1.1.2">subscript</csymbol><ci id="S2.SS1.p2.7.m7.1.1.2.2.cmml" xref="S2.SS1.p2.7.m7.1.1.2.2">ğœƒ</ci><apply id="S2.SS1.p2.7.m7.1.1.2.3.cmml" xref="S2.SS1.p2.7.m7.1.1.2.3"><times id="S2.SS1.p2.7.m7.1.1.2.3.1.cmml" xref="S2.SS1.p2.7.m7.1.1.2.3.1"></times><ci id="S2.SS1.p2.7.m7.1.1.2.3.2.cmml" xref="S2.SS1.p2.7.m7.1.1.2.3.2">ğ‘š</ci><ci id="S2.SS1.p2.7.m7.1.1.2.3.3.cmml" xref="S2.SS1.p2.7.m7.1.1.2.3.3">ğ‘</ci><ci id="S2.SS1.p2.7.m7.1.1.2.3.4.cmml" xref="S2.SS1.p2.7.m7.1.1.2.3.4">ğ‘¥</ci></apply></apply><apply id="S2.SS1.p2.7.m7.1.1.3.cmml" xref="S2.SS1.p2.7.m7.1.1.3"><csymbol cd="ambiguous" id="S2.SS1.p2.7.m7.1.1.3.1.cmml" xref="S2.SS1.p2.7.m7.1.1.3">superscript</csymbol><cn type="integer" id="S2.SS1.p2.7.m7.1.1.3.2.cmml" xref="S2.SS1.p2.7.m7.1.1.3.2">90</cn><compose id="S2.SS1.p2.7.m7.1.1.3.3.cmml" xref="S2.SS1.p2.7.m7.1.1.3.3"></compose></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.7.m7.1c">\theta_{max}=90^{\circ}</annotation></semantics></math><span id="S2.SS1.p2.7.9" class="ltx_text" style="font-size:144%;">.</span></p>
</div>
<div id="S2.SS1.p3" class="ltx_para">
<p id="S2.SS1.p3.1" class="ltx_p"><span id="S2.SS1.p3.1.1" class="ltx_text" style="font-size:144%;">The 2D collision detection of rays leverages the 2D layout of the 3D scene. For illustration purposes, we simplify the obstacles in 3D scenes with grey rectangles and visualize the collision detection of rays inÂ </span><a href="#S2.F1" title="In S2.1 Egocentric Sensing Calculation â€£ S2 Ego-Sensing Driven Motion Synthesis â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref" style="font-size:144%;"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">S1</span></a><span id="S2.SS1.p3.1.2" class="ltx_text" style="font-size:144%;">. The egocentric sensing encodes the simplified depth of obstacles.</span></p>
</div>
<figure id="S2.F1" class="ltx_figure"><img src="/html/2401.08739/assets/images/egosensing.png" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="335" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering" style="font-size:144%;"><span class="ltx_tag ltx_tag_figure"><span id="S2.F1.7.2.1" class="ltx_text" style="font-size:63%;">Figure S1</span>: </span><span id="S2.F1.2.1" class="ltx_text" style="font-size:63%;">The 2D projection of the egocentric camera location is represented by the purple point, while the 2D projection of the viewing direction <math id="S2.F1.2.1.m1.1" class="ltx_Math" alttext="\vv{\mathbf{v}}" display="inline"><semantics id="S2.F1.2.1.m1.1b"><mrow id="S2.F1.2.1.m1.1.1" xref="S2.F1.2.1.m1.1.1.cmml"><merror class="ltx_ERROR undefined undefined" id="S2.F1.2.1.m1.1.1.2" xref="S2.F1.2.1.m1.1.1.2b.cmml"><mtext id="S2.F1.2.1.m1.1.1.2b" xref="S2.F1.2.1.m1.1.1.2b.cmml">\vv</mtext></merror><mo lspace="0em" rspace="0em" id="S2.F1.2.1.m1.1.1.1" xref="S2.F1.2.1.m1.1.1.1.cmml">â€‹</mo><mi id="S2.F1.2.1.m1.1.1.3" xref="S2.F1.2.1.m1.1.1.3.cmml">ğ¯</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.F1.2.1.m1.1c"><apply id="S2.F1.2.1.m1.1.1.cmml" xref="S2.F1.2.1.m1.1.1"><times id="S2.F1.2.1.m1.1.1.1.cmml" xref="S2.F1.2.1.m1.1.1.1"></times><ci id="S2.F1.2.1.m1.1.1.2b.cmml" xref="S2.F1.2.1.m1.1.1.2"><merror class="ltx_ERROR undefined undefined" id="S2.F1.2.1.m1.1.1.2.cmml" xref="S2.F1.2.1.m1.1.1.2"><mtext id="S2.F1.2.1.m1.1.1.2a.cmml" xref="S2.F1.2.1.m1.1.1.2">\vv</mtext></merror></ci><ci id="S2.F1.2.1.m1.1.1.3.cmml" xref="S2.F1.2.1.m1.1.1.3">ğ¯</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F1.2.1.m1.1d">\vv{\mathbf{v}}</annotation></semantics></math> is indicated by the red arrow. The field of view changes due to the head pose.
</span></figcaption>
</figure>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:144%;">
<span class="ltx_tag ltx_tag_subsection">S2.2 </span>Reward, Weighting, and Training Detail</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p"><span id="S2.SS2.p1.1.1" class="ltx_text" style="font-size:144%;">In our motion primitive environment, we design an intuitive set of rewards to encourage the agent to perform realistic human motions (all vectors are normalized in the following equations):</span></p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.5" class="ltx_p"><span id="S2.SS2.p2.5.1" class="ltx_text ltx_font_bold" style="font-size:144%;">Attention reward</span><span id="S2.SS2.p2.5.2" class="ltx_text" style="font-size:144%;"> that encourages the human to look at the goal:</span></p>
<table id="S2.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E1.m1.3" class="ltx_Math" alttext="r_{attention}=\frac{\langle\vv{\mathbf{v}},g-h\rangle+1}{2}," display="block"><semantics id="S2.E1.m1.3a"><mrow id="S2.E1.m1.3.3.1" xref="S2.E1.m1.3.3.1.1.cmml"><mrow id="S2.E1.m1.3.3.1.1" xref="S2.E1.m1.3.3.1.1.cmml"><msub id="S2.E1.m1.3.3.1.1.2" xref="S2.E1.m1.3.3.1.1.2.cmml"><mi mathsize="144%" id="S2.E1.m1.3.3.1.1.2.2" xref="S2.E1.m1.3.3.1.1.2.2.cmml">r</mi><mrow id="S2.E1.m1.3.3.1.1.2.3" xref="S2.E1.m1.3.3.1.1.2.3.cmml"><mi mathsize="144%" id="S2.E1.m1.3.3.1.1.2.3.2" xref="S2.E1.m1.3.3.1.1.2.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.3.3.1.1.2.3.1" xref="S2.E1.m1.3.3.1.1.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E1.m1.3.3.1.1.2.3.3" xref="S2.E1.m1.3.3.1.1.2.3.3.cmml">t</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.3.3.1.1.2.3.1a" xref="S2.E1.m1.3.3.1.1.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E1.m1.3.3.1.1.2.3.4" xref="S2.E1.m1.3.3.1.1.2.3.4.cmml">t</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.3.3.1.1.2.3.1b" xref="S2.E1.m1.3.3.1.1.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E1.m1.3.3.1.1.2.3.5" xref="S2.E1.m1.3.3.1.1.2.3.5.cmml">e</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.3.3.1.1.2.3.1c" xref="S2.E1.m1.3.3.1.1.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E1.m1.3.3.1.1.2.3.6" xref="S2.E1.m1.3.3.1.1.2.3.6.cmml">n</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.3.3.1.1.2.3.1d" xref="S2.E1.m1.3.3.1.1.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E1.m1.3.3.1.1.2.3.7" xref="S2.E1.m1.3.3.1.1.2.3.7.cmml">t</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.3.3.1.1.2.3.1e" xref="S2.E1.m1.3.3.1.1.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E1.m1.3.3.1.1.2.3.8" xref="S2.E1.m1.3.3.1.1.2.3.8.cmml">i</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.3.3.1.1.2.3.1f" xref="S2.E1.m1.3.3.1.1.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E1.m1.3.3.1.1.2.3.9" xref="S2.E1.m1.3.3.1.1.2.3.9.cmml">o</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.3.3.1.1.2.3.1g" xref="S2.E1.m1.3.3.1.1.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E1.m1.3.3.1.1.2.3.10" xref="S2.E1.m1.3.3.1.1.2.3.10.cmml">n</mi></mrow></msub><mo mathsize="144%" id="S2.E1.m1.3.3.1.1.1" xref="S2.E1.m1.3.3.1.1.1.cmml">=</mo><mfrac id="S2.E1.m1.2.2" xref="S2.E1.m1.2.2.cmml"><mrow id="S2.E1.m1.2.2.2" xref="S2.E1.m1.2.2.2.cmml"><mrow id="S2.E1.m1.2.2.2.2.2" xref="S2.E1.m1.2.2.2.2.3.cmml"><mo maxsize="144%" minsize="144%" id="S2.E1.m1.2.2.2.2.2.3" xref="S2.E1.m1.2.2.2.2.3.cmml">âŸ¨</mo><mrow id="S2.E1.m1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.1.cmml"><merror class="ltx_ERROR undefined undefined" id="S2.E1.m1.1.1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.1.1.2b.cmml"><mtext id="S2.E1.m1.1.1.1.1.1.1.2a" xref="S2.E1.m1.1.1.1.1.1.1.2b.cmml">\vv</mtext></merror><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.1.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E1.m1.1.1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.1.1.3.cmml">ğ¯</mi></mrow><mo mathsize="144%" id="S2.E1.m1.2.2.2.2.2.4" xref="S2.E1.m1.2.2.2.2.3.cmml">,</mo><mrow id="S2.E1.m1.2.2.2.2.2.2" xref="S2.E1.m1.2.2.2.2.2.2.cmml"><mi mathsize="144%" id="S2.E1.m1.2.2.2.2.2.2.2" xref="S2.E1.m1.2.2.2.2.2.2.2.cmml">g</mi><mo mathsize="144%" id="S2.E1.m1.2.2.2.2.2.2.1" xref="S2.E1.m1.2.2.2.2.2.2.1.cmml">âˆ’</mo><mi mathsize="144%" id="S2.E1.m1.2.2.2.2.2.2.3" xref="S2.E1.m1.2.2.2.2.2.2.3.cmml">h</mi></mrow><mo maxsize="144%" minsize="144%" id="S2.E1.m1.2.2.2.2.2.5" xref="S2.E1.m1.2.2.2.2.3.cmml">âŸ©</mo></mrow><mo mathsize="144%" id="S2.E1.m1.2.2.2.3" xref="S2.E1.m1.2.2.2.3.cmml">+</mo><mn mathsize="144%" id="S2.E1.m1.2.2.2.4" xref="S2.E1.m1.2.2.2.4.cmml">1</mn></mrow><mn mathsize="144%" id="S2.E1.m1.2.2.4" xref="S2.E1.m1.2.2.4.cmml">2</mn></mfrac></mrow><mo mathsize="144%" id="S2.E1.m1.3.3.1.2" xref="S2.E1.m1.3.3.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.3b"><apply id="S2.E1.m1.3.3.1.1.cmml" xref="S2.E1.m1.3.3.1"><eq id="S2.E1.m1.3.3.1.1.1.cmml" xref="S2.E1.m1.3.3.1.1.1"></eq><apply id="S2.E1.m1.3.3.1.1.2.cmml" xref="S2.E1.m1.3.3.1.1.2"><csymbol cd="ambiguous" id="S2.E1.m1.3.3.1.1.2.1.cmml" xref="S2.E1.m1.3.3.1.1.2">subscript</csymbol><ci id="S2.E1.m1.3.3.1.1.2.2.cmml" xref="S2.E1.m1.3.3.1.1.2.2">ğ‘Ÿ</ci><apply id="S2.E1.m1.3.3.1.1.2.3.cmml" xref="S2.E1.m1.3.3.1.1.2.3"><times id="S2.E1.m1.3.3.1.1.2.3.1.cmml" xref="S2.E1.m1.3.3.1.1.2.3.1"></times><ci id="S2.E1.m1.3.3.1.1.2.3.2.cmml" xref="S2.E1.m1.3.3.1.1.2.3.2">ğ‘</ci><ci id="S2.E1.m1.3.3.1.1.2.3.3.cmml" xref="S2.E1.m1.3.3.1.1.2.3.3">ğ‘¡</ci><ci id="S2.E1.m1.3.3.1.1.2.3.4.cmml" xref="S2.E1.m1.3.3.1.1.2.3.4">ğ‘¡</ci><ci id="S2.E1.m1.3.3.1.1.2.3.5.cmml" xref="S2.E1.m1.3.3.1.1.2.3.5">ğ‘’</ci><ci id="S2.E1.m1.3.3.1.1.2.3.6.cmml" xref="S2.E1.m1.3.3.1.1.2.3.6">ğ‘›</ci><ci id="S2.E1.m1.3.3.1.1.2.3.7.cmml" xref="S2.E1.m1.3.3.1.1.2.3.7">ğ‘¡</ci><ci id="S2.E1.m1.3.3.1.1.2.3.8.cmml" xref="S2.E1.m1.3.3.1.1.2.3.8">ğ‘–</ci><ci id="S2.E1.m1.3.3.1.1.2.3.9.cmml" xref="S2.E1.m1.3.3.1.1.2.3.9">ğ‘œ</ci><ci id="S2.E1.m1.3.3.1.1.2.3.10.cmml" xref="S2.E1.m1.3.3.1.1.2.3.10">ğ‘›</ci></apply></apply><apply id="S2.E1.m1.2.2.cmml" xref="S2.E1.m1.2.2"><divide id="S2.E1.m1.2.2.3.cmml" xref="S2.E1.m1.2.2"></divide><apply id="S2.E1.m1.2.2.2.cmml" xref="S2.E1.m1.2.2.2"><plus id="S2.E1.m1.2.2.2.3.cmml" xref="S2.E1.m1.2.2.2.3"></plus><list id="S2.E1.m1.2.2.2.2.3.cmml" xref="S2.E1.m1.2.2.2.2.2"><apply id="S2.E1.m1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1"><times id="S2.E1.m1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1"></times><ci id="S2.E1.m1.1.1.1.1.1.1.2b.cmml" xref="S2.E1.m1.1.1.1.1.1.1.2"><merror class="ltx_ERROR undefined undefined" id="S2.E1.m1.1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.2"><mtext id="S2.E1.m1.1.1.1.1.1.1.2a.cmml" xref="S2.E1.m1.1.1.1.1.1.1.2">\vv</mtext></merror></ci><ci id="S2.E1.m1.1.1.1.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.1.1.3">ğ¯</ci></apply><apply id="S2.E1.m1.2.2.2.2.2.2.cmml" xref="S2.E1.m1.2.2.2.2.2.2"><minus id="S2.E1.m1.2.2.2.2.2.2.1.cmml" xref="S2.E1.m1.2.2.2.2.2.2.1"></minus><ci id="S2.E1.m1.2.2.2.2.2.2.2.cmml" xref="S2.E1.m1.2.2.2.2.2.2.2">ğ‘”</ci><ci id="S2.E1.m1.2.2.2.2.2.2.3.cmml" xref="S2.E1.m1.2.2.2.2.2.2.3">â„</ci></apply></list><cn type="integer" id="S2.E1.m1.2.2.2.4.cmml" xref="S2.E1.m1.2.2.2.4">1</cn></apply><cn type="integer" id="S2.E1.m1.2.2.4.cmml" xref="S2.E1.m1.2.2.4">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.3c">r_{attention}=\frac{\langle\vv{\mathbf{v}},g-h\rangle+1}{2},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S2.SS2.p2.4" class="ltx_p"><span id="S2.SS2.p2.4.1" class="ltx_text" style="font-size:144%;">where </span><math id="S2.SS2.p2.1.m1.1" class="ltx_Math" alttext="\vv{\mathbf{v}}" display="inline"><semantics id="S2.SS2.p2.1.m1.1a"><mrow id="S2.SS2.p2.1.m1.1.1" xref="S2.SS2.p2.1.m1.1.1.cmml"><merror class="ltx_ERROR undefined undefined" id="S2.SS2.p2.1.m1.1.1.2" xref="S2.SS2.p2.1.m1.1.1.2b.cmml"><mtext id="S2.SS2.p2.1.m1.1.1.2a" xref="S2.SS2.p2.1.m1.1.1.2b.cmml">\vv</mtext></merror><mo lspace="0em" rspace="0em" id="S2.SS2.p2.1.m1.1.1.1" xref="S2.SS2.p2.1.m1.1.1.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.SS2.p2.1.m1.1.1.3" xref="S2.SS2.p2.1.m1.1.1.3.cmml">ğ¯</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.1.m1.1b"><apply id="S2.SS2.p2.1.m1.1.1.cmml" xref="S2.SS2.p2.1.m1.1.1"><times id="S2.SS2.p2.1.m1.1.1.1.cmml" xref="S2.SS2.p2.1.m1.1.1.1"></times><ci id="S2.SS2.p2.1.m1.1.1.2b.cmml" xref="S2.SS2.p2.1.m1.1.1.2"><merror class="ltx_ERROR undefined undefined" id="S2.SS2.p2.1.m1.1.1.2.cmml" xref="S2.SS2.p2.1.m1.1.1.2"><mtext id="S2.SS2.p2.1.m1.1.1.2a.cmml" xref="S2.SS2.p2.1.m1.1.1.2">\vv</mtext></merror></ci><ci id="S2.SS2.p2.1.m1.1.1.3.cmml" xref="S2.SS2.p2.1.m1.1.1.3">ğ¯</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.1.m1.1c">\vv{\mathbf{v}}</annotation></semantics></math><span id="S2.SS2.p2.4.2" class="ltx_text" style="font-size:144%;"> denotes the viewing direction, </span><math id="S2.SS2.p2.2.m2.1" class="ltx_Math" alttext="g" display="inline"><semantics id="S2.SS2.p2.2.m2.1a"><mi mathsize="144%" id="S2.SS2.p2.2.m2.1.1" xref="S2.SS2.p2.2.m2.1.1.cmml">g</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.2.m2.1b"><ci id="S2.SS2.p2.2.m2.1.1.cmml" xref="S2.SS2.p2.2.m2.1.1">ğ‘”</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.2.m2.1c">g</annotation></semantics></math><span id="S2.SS2.p2.4.3" class="ltx_text" style="font-size:144%;"> and </span><math id="S2.SS2.p2.3.m3.1" class="ltx_Math" alttext="h" display="inline"><semantics id="S2.SS2.p2.3.m3.1a"><mi mathsize="144%" id="S2.SS2.p2.3.m3.1.1" xref="S2.SS2.p2.3.m3.1.1.cmml">h</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.3.m3.1b"><ci id="S2.SS2.p2.3.m3.1.1.cmml" xref="S2.SS2.p2.3.m3.1.1">â„</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.3.m3.1c">h</annotation></semantics></math><span id="S2.SS2.p2.4.4" class="ltx_text" style="font-size:144%;"> denote the goal location and current head location and </span><math id="S2.SS2.p2.4.m4.1" class="ltx_Math" alttext="\langle\cdot\rangle" display="inline"><semantics id="S2.SS2.p2.4.m4.1a"><mrow id="S2.SS2.p2.4.m4.1.2.2" xref="S2.SS2.p2.4.m4.1.2.1.cmml"><mo maxsize="144%" minsize="144%" id="S2.SS2.p2.4.m4.1.2.2.1" xref="S2.SS2.p2.4.m4.1.2.1.1.cmml">âŸ¨</mo><mo lspace="0em" mathsize="144%" rspace="0em" id="S2.SS2.p2.4.m4.1.1" xref="S2.SS2.p2.4.m4.1.1.cmml">â‹…</mo><mo maxsize="144%" minsize="144%" id="S2.SS2.p2.4.m4.1.2.2.2" xref="S2.SS2.p2.4.m4.1.2.1.1.cmml">âŸ©</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.4.m4.1b"><apply id="S2.SS2.p2.4.m4.1.2.1.cmml" xref="S2.SS2.p2.4.m4.1.2.2"><csymbol cd="latexml" id="S2.SS2.p2.4.m4.1.2.1.1.cmml" xref="S2.SS2.p2.4.m4.1.2.2.1">delimited-âŸ¨âŸ©</csymbol><ci id="S2.SS2.p2.4.m4.1.1.cmml" xref="S2.SS2.p2.4.m4.1.1">â‹…</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.4.m4.1c">\langle\cdot\rangle</annotation></semantics></math><span id="S2.SS2.p2.4.5" class="ltx_text" style="font-size:144%;"> denotes the inner product.</span></p>
</div>
<div id="S2.SS2.p3" class="ltx_para">
<p id="S2.SS2.p3.1" class="ltx_p"><span id="S2.SS2.p3.1.1" class="ltx_text ltx_font_bold" style="font-size:144%;">Foot contact reward</span><span id="S2.SS2.p3.1.2" class="ltx_text" style="font-size:144%;"> </span><math id="S2.SS2.p3.1.m1.1" class="ltx_Math" alttext="r_{cont.}" display="inline"><semantics id="S2.SS2.p3.1.m1.1a"><msub id="S2.SS2.p3.1.m1.1.2" xref="S2.SS2.p3.1.m1.1.2.cmml"><mi mathsize="144%" id="S2.SS2.p3.1.m1.1.2.2" xref="S2.SS2.p3.1.m1.1.2.2.cmml">r</mi><mrow id="S2.SS2.p3.1.m1.1.1.1.1" xref="S2.SS2.p3.1.m1.1.1.1.2.cmml"><mrow id="S2.SS2.p3.1.m1.1.1.1.1.1" xref="S2.SS2.p3.1.m1.1.1.1.1.1.cmml"><mi mathsize="144%" id="S2.SS2.p3.1.m1.1.1.1.1.1.2" xref="S2.SS2.p3.1.m1.1.1.1.1.1.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p3.1.m1.1.1.1.1.1.1" xref="S2.SS2.p3.1.m1.1.1.1.1.1.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.SS2.p3.1.m1.1.1.1.1.1.3" xref="S2.SS2.p3.1.m1.1.1.1.1.1.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p3.1.m1.1.1.1.1.1.1a" xref="S2.SS2.p3.1.m1.1.1.1.1.1.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.SS2.p3.1.m1.1.1.1.1.1.4" xref="S2.SS2.p3.1.m1.1.1.1.1.1.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p3.1.m1.1.1.1.1.1.1b" xref="S2.SS2.p3.1.m1.1.1.1.1.1.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.SS2.p3.1.m1.1.1.1.1.1.5" xref="S2.SS2.p3.1.m1.1.1.1.1.1.5.cmml">t</mi></mrow><mo lspace="0em" mathsize="144%" id="S2.SS2.p3.1.m1.1.1.1.1.2" xref="S2.SS2.p3.1.m1.1.1.1.2.cmml">.</mo></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.1.m1.1b"><apply id="S2.SS2.p3.1.m1.1.2.cmml" xref="S2.SS2.p3.1.m1.1.2"><csymbol cd="ambiguous" id="S2.SS2.p3.1.m1.1.2.1.cmml" xref="S2.SS2.p3.1.m1.1.2">subscript</csymbol><ci id="S2.SS2.p3.1.m1.1.2.2.cmml" xref="S2.SS2.p3.1.m1.1.2.2">ğ‘Ÿ</ci><list id="S2.SS2.p3.1.m1.1.1.1.2.cmml" xref="S2.SS2.p3.1.m1.1.1.1.1"><apply id="S2.SS2.p3.1.m1.1.1.1.1.1.cmml" xref="S2.SS2.p3.1.m1.1.1.1.1.1"><times id="S2.SS2.p3.1.m1.1.1.1.1.1.1.cmml" xref="S2.SS2.p3.1.m1.1.1.1.1.1.1"></times><ci id="S2.SS2.p3.1.m1.1.1.1.1.1.2.cmml" xref="S2.SS2.p3.1.m1.1.1.1.1.1.2">ğ‘</ci><ci id="S2.SS2.p3.1.m1.1.1.1.1.1.3.cmml" xref="S2.SS2.p3.1.m1.1.1.1.1.1.3">ğ‘œ</ci><ci id="S2.SS2.p3.1.m1.1.1.1.1.1.4.cmml" xref="S2.SS2.p3.1.m1.1.1.1.1.1.4">ğ‘›</ci><ci id="S2.SS2.p3.1.m1.1.1.1.1.1.5.cmml" xref="S2.SS2.p3.1.m1.1.1.1.1.1.5">ğ‘¡</ci></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.1.m1.1c">r_{cont.}</annotation></semantics></math><span id="S2.SS2.p3.1.3" class="ltx_text" style="font-size:144%;"> contains two components: Foot floor distance reward and foot skating reward.</span></p>
<table id="S2.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E2.m1.1" class="ltx_Math" alttext="r_{cont.}=r_{floor}+r_{skate}" display="block"><semantics id="S2.E2.m1.1a"><mrow id="S2.E2.m1.1.2" xref="S2.E2.m1.1.2.cmml"><msub id="S2.E2.m1.1.2.2" xref="S2.E2.m1.1.2.2.cmml"><mi mathsize="144%" id="S2.E2.m1.1.2.2.2" xref="S2.E2.m1.1.2.2.2.cmml">r</mi><mrow id="S2.E2.m1.1.1.1.1" xref="S2.E2.m1.1.1.1.2.cmml"><mrow id="S2.E2.m1.1.1.1.1.1" xref="S2.E2.m1.1.1.1.1.1.cmml"><mi mathsize="144%" id="S2.E2.m1.1.1.1.1.1.2" xref="S2.E2.m1.1.1.1.1.1.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.1.1.1.1.1.1" xref="S2.E2.m1.1.1.1.1.1.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E2.m1.1.1.1.1.1.3" xref="S2.E2.m1.1.1.1.1.1.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.1.1.1.1.1.1a" xref="S2.E2.m1.1.1.1.1.1.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E2.m1.1.1.1.1.1.4" xref="S2.E2.m1.1.1.1.1.1.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.1.1.1.1.1.1b" xref="S2.E2.m1.1.1.1.1.1.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E2.m1.1.1.1.1.1.5" xref="S2.E2.m1.1.1.1.1.1.5.cmml">t</mi></mrow><mo lspace="0em" mathsize="144%" id="S2.E2.m1.1.1.1.1.2" xref="S2.E2.m1.1.1.1.2.cmml">.</mo></mrow></msub><mo mathsize="144%" id="S2.E2.m1.1.2.1" xref="S2.E2.m1.1.2.1.cmml">=</mo><mrow id="S2.E2.m1.1.2.3" xref="S2.E2.m1.1.2.3.cmml"><msub id="S2.E2.m1.1.2.3.2" xref="S2.E2.m1.1.2.3.2.cmml"><mi mathsize="144%" id="S2.E2.m1.1.2.3.2.2" xref="S2.E2.m1.1.2.3.2.2.cmml">r</mi><mrow id="S2.E2.m1.1.2.3.2.3" xref="S2.E2.m1.1.2.3.2.3.cmml"><mi mathsize="144%" id="S2.E2.m1.1.2.3.2.3.2" xref="S2.E2.m1.1.2.3.2.3.2.cmml">f</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.1.2.3.2.3.1" xref="S2.E2.m1.1.2.3.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E2.m1.1.2.3.2.3.3" xref="S2.E2.m1.1.2.3.2.3.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.1.2.3.2.3.1a" xref="S2.E2.m1.1.2.3.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E2.m1.1.2.3.2.3.4" xref="S2.E2.m1.1.2.3.2.3.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.1.2.3.2.3.1b" xref="S2.E2.m1.1.2.3.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E2.m1.1.2.3.2.3.5" xref="S2.E2.m1.1.2.3.2.3.5.cmml">o</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.1.2.3.2.3.1c" xref="S2.E2.m1.1.2.3.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E2.m1.1.2.3.2.3.6" xref="S2.E2.m1.1.2.3.2.3.6.cmml">r</mi></mrow></msub><mo mathsize="144%" id="S2.E2.m1.1.2.3.1" xref="S2.E2.m1.1.2.3.1.cmml">+</mo><msub id="S2.E2.m1.1.2.3.3" xref="S2.E2.m1.1.2.3.3.cmml"><mi mathsize="144%" id="S2.E2.m1.1.2.3.3.2" xref="S2.E2.m1.1.2.3.3.2.cmml">r</mi><mrow id="S2.E2.m1.1.2.3.3.3" xref="S2.E2.m1.1.2.3.3.3.cmml"><mi mathsize="144%" id="S2.E2.m1.1.2.3.3.3.2" xref="S2.E2.m1.1.2.3.3.3.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.1.2.3.3.3.1" xref="S2.E2.m1.1.2.3.3.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E2.m1.1.2.3.3.3.3" xref="S2.E2.m1.1.2.3.3.3.3.cmml">k</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.1.2.3.3.3.1a" xref="S2.E2.m1.1.2.3.3.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E2.m1.1.2.3.3.3.4" xref="S2.E2.m1.1.2.3.3.3.4.cmml">a</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.1.2.3.3.3.1b" xref="S2.E2.m1.1.2.3.3.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E2.m1.1.2.3.3.3.5" xref="S2.E2.m1.1.2.3.3.3.5.cmml">t</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.1.2.3.3.3.1c" xref="S2.E2.m1.1.2.3.3.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E2.m1.1.2.3.3.3.6" xref="S2.E2.m1.1.2.3.3.3.6.cmml">e</mi></mrow></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E2.m1.1b"><apply id="S2.E2.m1.1.2.cmml" xref="S2.E2.m1.1.2"><eq id="S2.E2.m1.1.2.1.cmml" xref="S2.E2.m1.1.2.1"></eq><apply id="S2.E2.m1.1.2.2.cmml" xref="S2.E2.m1.1.2.2"><csymbol cd="ambiguous" id="S2.E2.m1.1.2.2.1.cmml" xref="S2.E2.m1.1.2.2">subscript</csymbol><ci id="S2.E2.m1.1.2.2.2.cmml" xref="S2.E2.m1.1.2.2.2">ğ‘Ÿ</ci><list id="S2.E2.m1.1.1.1.2.cmml" xref="S2.E2.m1.1.1.1.1"><apply id="S2.E2.m1.1.1.1.1.1.cmml" xref="S2.E2.m1.1.1.1.1.1"><times id="S2.E2.m1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.1.1.1.1.1.1"></times><ci id="S2.E2.m1.1.1.1.1.1.2.cmml" xref="S2.E2.m1.1.1.1.1.1.2">ğ‘</ci><ci id="S2.E2.m1.1.1.1.1.1.3.cmml" xref="S2.E2.m1.1.1.1.1.1.3">ğ‘œ</ci><ci id="S2.E2.m1.1.1.1.1.1.4.cmml" xref="S2.E2.m1.1.1.1.1.1.4">ğ‘›</ci><ci id="S2.E2.m1.1.1.1.1.1.5.cmml" xref="S2.E2.m1.1.1.1.1.1.5">ğ‘¡</ci></apply></list></apply><apply id="S2.E2.m1.1.2.3.cmml" xref="S2.E2.m1.1.2.3"><plus id="S2.E2.m1.1.2.3.1.cmml" xref="S2.E2.m1.1.2.3.1"></plus><apply id="S2.E2.m1.1.2.3.2.cmml" xref="S2.E2.m1.1.2.3.2"><csymbol cd="ambiguous" id="S2.E2.m1.1.2.3.2.1.cmml" xref="S2.E2.m1.1.2.3.2">subscript</csymbol><ci id="S2.E2.m1.1.2.3.2.2.cmml" xref="S2.E2.m1.1.2.3.2.2">ğ‘Ÿ</ci><apply id="S2.E2.m1.1.2.3.2.3.cmml" xref="S2.E2.m1.1.2.3.2.3"><times id="S2.E2.m1.1.2.3.2.3.1.cmml" xref="S2.E2.m1.1.2.3.2.3.1"></times><ci id="S2.E2.m1.1.2.3.2.3.2.cmml" xref="S2.E2.m1.1.2.3.2.3.2">ğ‘“</ci><ci id="S2.E2.m1.1.2.3.2.3.3.cmml" xref="S2.E2.m1.1.2.3.2.3.3">ğ‘™</ci><ci id="S2.E2.m1.1.2.3.2.3.4.cmml" xref="S2.E2.m1.1.2.3.2.3.4">ğ‘œ</ci><ci id="S2.E2.m1.1.2.3.2.3.5.cmml" xref="S2.E2.m1.1.2.3.2.3.5">ğ‘œ</ci><ci id="S2.E2.m1.1.2.3.2.3.6.cmml" xref="S2.E2.m1.1.2.3.2.3.6">ğ‘Ÿ</ci></apply></apply><apply id="S2.E2.m1.1.2.3.3.cmml" xref="S2.E2.m1.1.2.3.3"><csymbol cd="ambiguous" id="S2.E2.m1.1.2.3.3.1.cmml" xref="S2.E2.m1.1.2.3.3">subscript</csymbol><ci id="S2.E2.m1.1.2.3.3.2.cmml" xref="S2.E2.m1.1.2.3.3.2">ğ‘Ÿ</ci><apply id="S2.E2.m1.1.2.3.3.3.cmml" xref="S2.E2.m1.1.2.3.3.3"><times id="S2.E2.m1.1.2.3.3.3.1.cmml" xref="S2.E2.m1.1.2.3.3.3.1"></times><ci id="S2.E2.m1.1.2.3.3.3.2.cmml" xref="S2.E2.m1.1.2.3.3.3.2">ğ‘ </ci><ci id="S2.E2.m1.1.2.3.3.3.3.cmml" xref="S2.E2.m1.1.2.3.3.3.3">ğ‘˜</ci><ci id="S2.E2.m1.1.2.3.3.3.4.cmml" xref="S2.E2.m1.1.2.3.3.3.4">ğ‘</ci><ci id="S2.E2.m1.1.2.3.3.3.5.cmml" xref="S2.E2.m1.1.2.3.3.3.5">ğ‘¡</ci><ci id="S2.E2.m1.1.2.3.3.3.6.cmml" xref="S2.E2.m1.1.2.3.3.3.6">ğ‘’</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E2.m1.1c">r_{cont.}=r_{floor}+r_{skate}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<table id="S2.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E3.m1.2" class="ltx_Math" alttext="r_{floor}=e^{-(|\min_{x\in F}x_{z}|-0.02)_{+}}," display="block"><semantics id="S2.E3.m1.2a"><mrow id="S2.E3.m1.2.2.1" xref="S2.E3.m1.2.2.1.1.cmml"><mrow id="S2.E3.m1.2.2.1.1" xref="S2.E3.m1.2.2.1.1.cmml"><msub id="S2.E3.m1.2.2.1.1.2" xref="S2.E3.m1.2.2.1.1.2.cmml"><mi mathsize="144%" id="S2.E3.m1.2.2.1.1.2.2" xref="S2.E3.m1.2.2.1.1.2.2.cmml">r</mi><mrow id="S2.E3.m1.2.2.1.1.2.3" xref="S2.E3.m1.2.2.1.1.2.3.cmml"><mi mathsize="144%" id="S2.E3.m1.2.2.1.1.2.3.2" xref="S2.E3.m1.2.2.1.1.2.3.2.cmml">f</mi><mo lspace="0em" rspace="0em" id="S2.E3.m1.2.2.1.1.2.3.1" xref="S2.E3.m1.2.2.1.1.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E3.m1.2.2.1.1.2.3.3" xref="S2.E3.m1.2.2.1.1.2.3.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S2.E3.m1.2.2.1.1.2.3.1a" xref="S2.E3.m1.2.2.1.1.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E3.m1.2.2.1.1.2.3.4" xref="S2.E3.m1.2.2.1.1.2.3.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S2.E3.m1.2.2.1.1.2.3.1b" xref="S2.E3.m1.2.2.1.1.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E3.m1.2.2.1.1.2.3.5" xref="S2.E3.m1.2.2.1.1.2.3.5.cmml">o</mi><mo lspace="0em" rspace="0em" id="S2.E3.m1.2.2.1.1.2.3.1c" xref="S2.E3.m1.2.2.1.1.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E3.m1.2.2.1.1.2.3.6" xref="S2.E3.m1.2.2.1.1.2.3.6.cmml">r</mi></mrow></msub><mo mathsize="144%" id="S2.E3.m1.2.2.1.1.1" xref="S2.E3.m1.2.2.1.1.1.cmml">=</mo><msup id="S2.E3.m1.2.2.1.1.3" xref="S2.E3.m1.2.2.1.1.3.cmml"><mi mathsize="144%" id="S2.E3.m1.2.2.1.1.3.2" xref="S2.E3.m1.2.2.1.1.3.2.cmml">e</mi><mrow id="S2.E3.m1.1.1.1" xref="S2.E3.m1.1.1.1.cmml"><mo mathsize="144%" id="S2.E3.m1.1.1.1a" xref="S2.E3.m1.1.1.1.cmml">âˆ’</mo><msub id="S2.E3.m1.1.1.1.1" xref="S2.E3.m1.1.1.1.1.cmml"><mrow id="S2.E3.m1.1.1.1.1.1.1" xref="S2.E3.m1.1.1.1.1.1.1.1.cmml"><mo maxsize="144%" minsize="144%" id="S2.E3.m1.1.1.1.1.1.1.2" xref="S2.E3.m1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.E3.m1.1.1.1.1.1.1.1" xref="S2.E3.m1.1.1.1.1.1.1.1.cmml"><mrow id="S2.E3.m1.1.1.1.1.1.1.1.1.1" xref="S2.E3.m1.1.1.1.1.1.1.1.1.2.cmml"><mo maxsize="144%" minsize="144%" id="S2.E3.m1.1.1.1.1.1.1.1.1.1.2" xref="S2.E3.m1.1.1.1.1.1.1.1.1.2.1.cmml">|</mo><mrow id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.cmml"><msub id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi mathsize="144%" id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">min</mi><mrow id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3.cmml"><mi mathsize="144%" id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3.2" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml">x</mi><mo mathsize="144%" id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3.1" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml">âˆˆ</mo><mi mathsize="144%" id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3.3" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml">F</mi></mrow></msub><mo lspace="0.167em" id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1a" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.cmml">â¡</mo><msub id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.2" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.2.cmml"><mi mathsize="144%" id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.2.2" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.2.2.cmml">x</mi><mi mathsize="144%" id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.2.3" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.2.3.cmml">z</mi></msub></mrow><mo maxsize="144%" minsize="144%" id="S2.E3.m1.1.1.1.1.1.1.1.1.1.3" xref="S2.E3.m1.1.1.1.1.1.1.1.1.2.1.cmml">|</mo></mrow><mo mathsize="144%" id="S2.E3.m1.1.1.1.1.1.1.1.2" xref="S2.E3.m1.1.1.1.1.1.1.1.2.cmml">âˆ’</mo><mn mathsize="144%" id="S2.E3.m1.1.1.1.1.1.1.1.3" xref="S2.E3.m1.1.1.1.1.1.1.1.3.cmml">0.02</mn></mrow><mo maxsize="144%" minsize="144%" id="S2.E3.m1.1.1.1.1.1.1.3" xref="S2.E3.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo mathsize="144%" id="S2.E3.m1.1.1.1.1.3" xref="S2.E3.m1.1.1.1.1.3.cmml">+</mo></msub></mrow></msup></mrow><mo mathsize="144%" id="S2.E3.m1.2.2.1.2" xref="S2.E3.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E3.m1.2b"><apply id="S2.E3.m1.2.2.1.1.cmml" xref="S2.E3.m1.2.2.1"><eq id="S2.E3.m1.2.2.1.1.1.cmml" xref="S2.E3.m1.2.2.1.1.1"></eq><apply id="S2.E3.m1.2.2.1.1.2.cmml" xref="S2.E3.m1.2.2.1.1.2"><csymbol cd="ambiguous" id="S2.E3.m1.2.2.1.1.2.1.cmml" xref="S2.E3.m1.2.2.1.1.2">subscript</csymbol><ci id="S2.E3.m1.2.2.1.1.2.2.cmml" xref="S2.E3.m1.2.2.1.1.2.2">ğ‘Ÿ</ci><apply id="S2.E3.m1.2.2.1.1.2.3.cmml" xref="S2.E3.m1.2.2.1.1.2.3"><times id="S2.E3.m1.2.2.1.1.2.3.1.cmml" xref="S2.E3.m1.2.2.1.1.2.3.1"></times><ci id="S2.E3.m1.2.2.1.1.2.3.2.cmml" xref="S2.E3.m1.2.2.1.1.2.3.2">ğ‘“</ci><ci id="S2.E3.m1.2.2.1.1.2.3.3.cmml" xref="S2.E3.m1.2.2.1.1.2.3.3">ğ‘™</ci><ci id="S2.E3.m1.2.2.1.1.2.3.4.cmml" xref="S2.E3.m1.2.2.1.1.2.3.4">ğ‘œ</ci><ci id="S2.E3.m1.2.2.1.1.2.3.5.cmml" xref="S2.E3.m1.2.2.1.1.2.3.5">ğ‘œ</ci><ci id="S2.E3.m1.2.2.1.1.2.3.6.cmml" xref="S2.E3.m1.2.2.1.1.2.3.6">ğ‘Ÿ</ci></apply></apply><apply id="S2.E3.m1.2.2.1.1.3.cmml" xref="S2.E3.m1.2.2.1.1.3"><csymbol cd="ambiguous" id="S2.E3.m1.2.2.1.1.3.1.cmml" xref="S2.E3.m1.2.2.1.1.3">superscript</csymbol><ci id="S2.E3.m1.2.2.1.1.3.2.cmml" xref="S2.E3.m1.2.2.1.1.3.2">ğ‘’</ci><apply id="S2.E3.m1.1.1.1.cmml" xref="S2.E3.m1.1.1.1"><minus id="S2.E3.m1.1.1.1.2.cmml" xref="S2.E3.m1.1.1.1"></minus><apply id="S2.E3.m1.1.1.1.1.cmml" xref="S2.E3.m1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E3.m1.1.1.1.1.2.cmml" xref="S2.E3.m1.1.1.1.1">subscript</csymbol><apply id="S2.E3.m1.1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.1.1.1.1.1.1"><minus id="S2.E3.m1.1.1.1.1.1.1.1.2.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.2"></minus><apply id="S2.E3.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1"><abs id="S2.E3.m1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.2"></abs><apply id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1"><apply id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><min id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.2"></min><apply id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3"><in id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3.1"></in><ci id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3.2">ğ‘¥</ci><ci id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.1.3.3">ğ¹</ci></apply></apply><apply id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.2.2">ğ‘¥</ci><ci id="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.1.1.1.2.3">ğ‘§</ci></apply></apply></apply><cn type="float" id="S2.E3.m1.1.1.1.1.1.1.1.3.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1.3">0.02</cn></apply><plus id="S2.E3.m1.1.1.1.1.3.cmml" xref="S2.E3.m1.1.1.1.1.3"></plus></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E3.m1.2c">r_{floor}=e^{-(|\min_{x\in F}x_{z}|-0.02)_{+}},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<table id="S2.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E4.m1.2" class="ltx_Math" alttext="r_{skate}=e^{-(\min_{x\in F}\|x_{vel}\|_{2}-0.075)_{+}}," display="block"><semantics id="S2.E4.m1.2a"><mrow id="S2.E4.m1.2.2.1" xref="S2.E4.m1.2.2.1.1.cmml"><mrow id="S2.E4.m1.2.2.1.1" xref="S2.E4.m1.2.2.1.1.cmml"><msub id="S2.E4.m1.2.2.1.1.2" xref="S2.E4.m1.2.2.1.1.2.cmml"><mi mathsize="144%" id="S2.E4.m1.2.2.1.1.2.2" xref="S2.E4.m1.2.2.1.1.2.2.cmml">r</mi><mrow id="S2.E4.m1.2.2.1.1.2.3" xref="S2.E4.m1.2.2.1.1.2.3.cmml"><mi mathsize="144%" id="S2.E4.m1.2.2.1.1.2.3.2" xref="S2.E4.m1.2.2.1.1.2.3.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S2.E4.m1.2.2.1.1.2.3.1" xref="S2.E4.m1.2.2.1.1.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E4.m1.2.2.1.1.2.3.3" xref="S2.E4.m1.2.2.1.1.2.3.3.cmml">k</mi><mo lspace="0em" rspace="0em" id="S2.E4.m1.2.2.1.1.2.3.1a" xref="S2.E4.m1.2.2.1.1.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E4.m1.2.2.1.1.2.3.4" xref="S2.E4.m1.2.2.1.1.2.3.4.cmml">a</mi><mo lspace="0em" rspace="0em" id="S2.E4.m1.2.2.1.1.2.3.1b" xref="S2.E4.m1.2.2.1.1.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E4.m1.2.2.1.1.2.3.5" xref="S2.E4.m1.2.2.1.1.2.3.5.cmml">t</mi><mo lspace="0em" rspace="0em" id="S2.E4.m1.2.2.1.1.2.3.1c" xref="S2.E4.m1.2.2.1.1.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E4.m1.2.2.1.1.2.3.6" xref="S2.E4.m1.2.2.1.1.2.3.6.cmml">e</mi></mrow></msub><mo mathsize="144%" id="S2.E4.m1.2.2.1.1.1" xref="S2.E4.m1.2.2.1.1.1.cmml">=</mo><msup id="S2.E4.m1.2.2.1.1.3" xref="S2.E4.m1.2.2.1.1.3.cmml"><mi mathsize="144%" id="S2.E4.m1.2.2.1.1.3.2" xref="S2.E4.m1.2.2.1.1.3.2.cmml">e</mi><mrow id="S2.E4.m1.1.1.1" xref="S2.E4.m1.1.1.1.cmml"><mo mathsize="144%" id="S2.E4.m1.1.1.1a" xref="S2.E4.m1.1.1.1.cmml">âˆ’</mo><msub id="S2.E4.m1.1.1.1.1" xref="S2.E4.m1.1.1.1.1.cmml"><mrow id="S2.E4.m1.1.1.1.1.1.1" xref="S2.E4.m1.1.1.1.1.1.1.1.cmml"><mo maxsize="144%" minsize="144%" id="S2.E4.m1.1.1.1.1.1.1.2" xref="S2.E4.m1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.E4.m1.1.1.1.1.1.1.1" xref="S2.E4.m1.1.1.1.1.1.1.1.cmml"><mrow id="S2.E4.m1.1.1.1.1.1.1.1.1" xref="S2.E4.m1.1.1.1.1.1.1.1.1.cmml"><msub id="S2.E4.m1.1.1.1.1.1.1.1.1.2" xref="S2.E4.m1.1.1.1.1.1.1.1.1.2.cmml"><mi mathsize="144%" id="S2.E4.m1.1.1.1.1.1.1.1.1.2.2" xref="S2.E4.m1.1.1.1.1.1.1.1.1.2.2.cmml">min</mi><mrow id="S2.E4.m1.1.1.1.1.1.1.1.1.2.3" xref="S2.E4.m1.1.1.1.1.1.1.1.1.2.3.cmml"><mi mathsize="144%" id="S2.E4.m1.1.1.1.1.1.1.1.1.2.3.2" xref="S2.E4.m1.1.1.1.1.1.1.1.1.2.3.2.cmml">x</mi><mo mathsize="144%" id="S2.E4.m1.1.1.1.1.1.1.1.1.2.3.1" xref="S2.E4.m1.1.1.1.1.1.1.1.1.2.3.1.cmml">âˆˆ</mo><mi mathsize="144%" id="S2.E4.m1.1.1.1.1.1.1.1.1.2.3.3" xref="S2.E4.m1.1.1.1.1.1.1.1.1.2.3.3.cmml">F</mi></mrow></msub><mo id="S2.E4.m1.1.1.1.1.1.1.1.1a" xref="S2.E4.m1.1.1.1.1.1.1.1.1.cmml">â¡</mo><msub id="S2.E4.m1.1.1.1.1.1.1.1.1.1" xref="S2.E4.m1.1.1.1.1.1.1.1.1.1.cmml"><mrow id="S2.E4.m1.1.1.1.1.1.1.1.1.1.1.1" xref="S2.E4.m1.1.1.1.1.1.1.1.1.1.1.2.cmml"><mo maxsize="144%" minsize="144%" id="S2.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S2.E4.m1.1.1.1.1.1.1.1.1.1.1.2.1.cmml">â€–</mo><msub id="S2.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S2.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi mathsize="144%" id="S2.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S2.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">x</mi><mrow id="S2.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S2.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml"><mi mathsize="144%" id="S2.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.2" xref="S2.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml">v</mi><mo lspace="0em" rspace="0em" id="S2.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.1" xref="S2.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.3" xref="S2.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S2.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.1a" xref="S2.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.4" xref="S2.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.4.cmml">l</mi></mrow></msub><mo maxsize="144%" minsize="144%" id="S2.E4.m1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S2.E4.m1.1.1.1.1.1.1.1.1.1.1.2.1.cmml">â€–</mo></mrow><mn mathsize="144%" id="S2.E4.m1.1.1.1.1.1.1.1.1.1.3" xref="S2.E4.m1.1.1.1.1.1.1.1.1.1.3.cmml">2</mn></msub></mrow><mo mathsize="144%" id="S2.E4.m1.1.1.1.1.1.1.1.2" xref="S2.E4.m1.1.1.1.1.1.1.1.2.cmml">âˆ’</mo><mn mathsize="144%" id="S2.E4.m1.1.1.1.1.1.1.1.3" xref="S2.E4.m1.1.1.1.1.1.1.1.3.cmml">0.075</mn></mrow><mo maxsize="144%" minsize="144%" id="S2.E4.m1.1.1.1.1.1.1.3" xref="S2.E4.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo mathsize="144%" id="S2.E4.m1.1.1.1.1.3" xref="S2.E4.m1.1.1.1.1.3.cmml">+</mo></msub></mrow></msup></mrow><mo mathsize="144%" id="S2.E4.m1.2.2.1.2" xref="S2.E4.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E4.m1.2b"><apply id="S2.E4.m1.2.2.1.1.cmml" xref="S2.E4.m1.2.2.1"><eq id="S2.E4.m1.2.2.1.1.1.cmml" xref="S2.E4.m1.2.2.1.1.1"></eq><apply id="S2.E4.m1.2.2.1.1.2.cmml" xref="S2.E4.m1.2.2.1.1.2"><csymbol cd="ambiguous" id="S2.E4.m1.2.2.1.1.2.1.cmml" xref="S2.E4.m1.2.2.1.1.2">subscript</csymbol><ci id="S2.E4.m1.2.2.1.1.2.2.cmml" xref="S2.E4.m1.2.2.1.1.2.2">ğ‘Ÿ</ci><apply id="S2.E4.m1.2.2.1.1.2.3.cmml" xref="S2.E4.m1.2.2.1.1.2.3"><times id="S2.E4.m1.2.2.1.1.2.3.1.cmml" xref="S2.E4.m1.2.2.1.1.2.3.1"></times><ci id="S2.E4.m1.2.2.1.1.2.3.2.cmml" xref="S2.E4.m1.2.2.1.1.2.3.2">ğ‘ </ci><ci id="S2.E4.m1.2.2.1.1.2.3.3.cmml" xref="S2.E4.m1.2.2.1.1.2.3.3">ğ‘˜</ci><ci id="S2.E4.m1.2.2.1.1.2.3.4.cmml" xref="S2.E4.m1.2.2.1.1.2.3.4">ğ‘</ci><ci id="S2.E4.m1.2.2.1.1.2.3.5.cmml" xref="S2.E4.m1.2.2.1.1.2.3.5">ğ‘¡</ci><ci id="S2.E4.m1.2.2.1.1.2.3.6.cmml" xref="S2.E4.m1.2.2.1.1.2.3.6">ğ‘’</ci></apply></apply><apply id="S2.E4.m1.2.2.1.1.3.cmml" xref="S2.E4.m1.2.2.1.1.3"><csymbol cd="ambiguous" id="S2.E4.m1.2.2.1.1.3.1.cmml" xref="S2.E4.m1.2.2.1.1.3">superscript</csymbol><ci id="S2.E4.m1.2.2.1.1.3.2.cmml" xref="S2.E4.m1.2.2.1.1.3.2">ğ‘’</ci><apply id="S2.E4.m1.1.1.1.cmml" xref="S2.E4.m1.1.1.1"><minus id="S2.E4.m1.1.1.1.2.cmml" xref="S2.E4.m1.1.1.1"></minus><apply id="S2.E4.m1.1.1.1.1.cmml" xref="S2.E4.m1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E4.m1.1.1.1.1.2.cmml" xref="S2.E4.m1.1.1.1.1">subscript</csymbol><apply id="S2.E4.m1.1.1.1.1.1.1.1.cmml" xref="S2.E4.m1.1.1.1.1.1.1"><minus id="S2.E4.m1.1.1.1.1.1.1.1.2.cmml" xref="S2.E4.m1.1.1.1.1.1.1.1.2"></minus><apply id="S2.E4.m1.1.1.1.1.1.1.1.1.cmml" xref="S2.E4.m1.1.1.1.1.1.1.1.1"><apply id="S2.E4.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E4.m1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E4.m1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S2.E4.m1.1.1.1.1.1.1.1.1.2">subscript</csymbol><min id="S2.E4.m1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S2.E4.m1.1.1.1.1.1.1.1.1.2.2"></min><apply id="S2.E4.m1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S2.E4.m1.1.1.1.1.1.1.1.1.2.3"><in id="S2.E4.m1.1.1.1.1.1.1.1.1.2.3.1.cmml" xref="S2.E4.m1.1.1.1.1.1.1.1.1.2.3.1"></in><ci id="S2.E4.m1.1.1.1.1.1.1.1.1.2.3.2.cmml" xref="S2.E4.m1.1.1.1.1.1.1.1.1.2.3.2">ğ‘¥</ci><ci id="S2.E4.m1.1.1.1.1.1.1.1.1.2.3.3.cmml" xref="S2.E4.m1.1.1.1.1.1.1.1.1.2.3.3">ğ¹</ci></apply></apply><apply id="S2.E4.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E4.m1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E4.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E4.m1.1.1.1.1.1.1.1.1.1">subscript</csymbol><apply id="S2.E4.m1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E4.m1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S2.E4.m1.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S2.E4.m1.1.1.1.1.1.1.1.1.1.1.1.2">norm</csymbol><apply id="S2.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.2">ğ‘¥</ci><apply id="S2.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.3"><times id="S2.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S2.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.1"></times><ci id="S2.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S2.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.2">ğ‘£</ci><ci id="S2.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S2.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.3">ğ‘’</ci><ci id="S2.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.4.cmml" xref="S2.E4.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.4">ğ‘™</ci></apply></apply></apply><cn type="integer" id="S2.E4.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E4.m1.1.1.1.1.1.1.1.1.1.3">2</cn></apply></apply><cn type="float" id="S2.E4.m1.1.1.1.1.1.1.1.3.cmml" xref="S2.E4.m1.1.1.1.1.1.1.1.3">0.075</cn></apply><plus id="S2.E4.m1.1.1.1.1.3.cmml" xref="S2.E4.m1.1.1.1.1.3"></plus></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E4.m1.2c">r_{skate}=e^{-(\min_{x\in F}\|x_{vel}\|_{2}-0.075)_{+}},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
</div>
<div id="S2.SS2.p4" class="ltx_para">
<p id="S2.SS2.p4.4" class="ltx_p"><span id="S2.SS2.p4.4.1" class="ltx_text" style="font-size:144%;">where </span><math id="S2.SS2.p4.1.m1.1" class="ltx_Math" alttext="F" display="inline"><semantics id="S2.SS2.p4.1.m1.1a"><mi mathsize="144%" id="S2.SS2.p4.1.m1.1.1" xref="S2.SS2.p4.1.m1.1.1.cmml">F</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p4.1.m1.1b"><ci id="S2.SS2.p4.1.m1.1.1.cmml" xref="S2.SS2.p4.1.m1.1.1">ğ¹</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p4.1.m1.1c">F</annotation></semantics></math><span id="S2.SS2.p4.4.2" class="ltx_text" style="font-size:144%;"> denotes foot markers, </span><math id="S2.SS2.p4.2.m2.1" class="ltx_Math" alttext="x_{z}" display="inline"><semantics id="S2.SS2.p4.2.m2.1a"><msub id="S2.SS2.p4.2.m2.1.1" xref="S2.SS2.p4.2.m2.1.1.cmml"><mi mathsize="144%" id="S2.SS2.p4.2.m2.1.1.2" xref="S2.SS2.p4.2.m2.1.1.2.cmml">x</mi><mi mathsize="144%" id="S2.SS2.p4.2.m2.1.1.3" xref="S2.SS2.p4.2.m2.1.1.3.cmml">z</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p4.2.m2.1b"><apply id="S2.SS2.p4.2.m2.1.1.cmml" xref="S2.SS2.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS2.p4.2.m2.1.1.1.cmml" xref="S2.SS2.p4.2.m2.1.1">subscript</csymbol><ci id="S2.SS2.p4.2.m2.1.1.2.cmml" xref="S2.SS2.p4.2.m2.1.1.2">ğ‘¥</ci><ci id="S2.SS2.p4.2.m2.1.1.3.cmml" xref="S2.SS2.p4.2.m2.1.1.3">ğ‘§</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p4.2.m2.1c">x_{z}</annotation></semantics></math><span id="S2.SS2.p4.4.3" class="ltx_text" style="font-size:144%;"> denotes the marker height, </span><math id="S2.SS2.p4.3.m3.1" class="ltx_Math" alttext="x_{vel}" display="inline"><semantics id="S2.SS2.p4.3.m3.1a"><msub id="S2.SS2.p4.3.m3.1.1" xref="S2.SS2.p4.3.m3.1.1.cmml"><mi mathsize="144%" id="S2.SS2.p4.3.m3.1.1.2" xref="S2.SS2.p4.3.m3.1.1.2.cmml">x</mi><mrow id="S2.SS2.p4.3.m3.1.1.3" xref="S2.SS2.p4.3.m3.1.1.3.cmml"><mi mathsize="144%" id="S2.SS2.p4.3.m3.1.1.3.2" xref="S2.SS2.p4.3.m3.1.1.3.2.cmml">v</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p4.3.m3.1.1.3.1" xref="S2.SS2.p4.3.m3.1.1.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.SS2.p4.3.m3.1.1.3.3" xref="S2.SS2.p4.3.m3.1.1.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p4.3.m3.1.1.3.1a" xref="S2.SS2.p4.3.m3.1.1.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.SS2.p4.3.m3.1.1.3.4" xref="S2.SS2.p4.3.m3.1.1.3.4.cmml">l</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p4.3.m3.1b"><apply id="S2.SS2.p4.3.m3.1.1.cmml" xref="S2.SS2.p4.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS2.p4.3.m3.1.1.1.cmml" xref="S2.SS2.p4.3.m3.1.1">subscript</csymbol><ci id="S2.SS2.p4.3.m3.1.1.2.cmml" xref="S2.SS2.p4.3.m3.1.1.2">ğ‘¥</ci><apply id="S2.SS2.p4.3.m3.1.1.3.cmml" xref="S2.SS2.p4.3.m3.1.1.3"><times id="S2.SS2.p4.3.m3.1.1.3.1.cmml" xref="S2.SS2.p4.3.m3.1.1.3.1"></times><ci id="S2.SS2.p4.3.m3.1.1.3.2.cmml" xref="S2.SS2.p4.3.m3.1.1.3.2">ğ‘£</ci><ci id="S2.SS2.p4.3.m3.1.1.3.3.cmml" xref="S2.SS2.p4.3.m3.1.1.3.3">ğ‘’</ci><ci id="S2.SS2.p4.3.m3.1.1.3.4.cmml" xref="S2.SS2.p4.3.m3.1.1.3.4">ğ‘™</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p4.3.m3.1c">x_{vel}</annotation></semantics></math><span id="S2.SS2.p4.4.4" class="ltx_text" style="font-size:144%;"> denotes the marker velocity, and </span><math id="S2.SS2.p4.4.m4.1" class="ltx_Math" alttext="(\cdot)_{+}" display="inline"><semantics id="S2.SS2.p4.4.m4.1a"><msub id="S2.SS2.p4.4.m4.1.2" xref="S2.SS2.p4.4.m4.1.2.cmml"><mrow id="S2.SS2.p4.4.m4.1.2.2.2" xref="S2.SS2.p4.4.m4.1.2.cmml"><mo maxsize="144%" minsize="144%" id="S2.SS2.p4.4.m4.1.2.2.2.1" xref="S2.SS2.p4.4.m4.1.2.cmml">(</mo><mo lspace="0em" mathsize="144%" rspace="0em" id="S2.SS2.p4.4.m4.1.1" xref="S2.SS2.p4.4.m4.1.1.cmml">â‹…</mo><mo maxsize="144%" minsize="144%" id="S2.SS2.p4.4.m4.1.2.2.2.2" xref="S2.SS2.p4.4.m4.1.2.cmml">)</mo></mrow><mo mathsize="144%" id="S2.SS2.p4.4.m4.1.2.3" xref="S2.SS2.p4.4.m4.1.2.3.cmml">+</mo></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p4.4.m4.1b"><apply id="S2.SS2.p4.4.m4.1.2.cmml" xref="S2.SS2.p4.4.m4.1.2"><csymbol cd="ambiguous" id="S2.SS2.p4.4.m4.1.2.1.cmml" xref="S2.SS2.p4.4.m4.1.2">subscript</csymbol><ci id="S2.SS2.p4.4.m4.1.1.cmml" xref="S2.SS2.p4.4.m4.1.1">â‹…</ci><plus id="S2.SS2.p4.4.m4.1.2.3.cmml" xref="S2.SS2.p4.4.m4.1.2.3"></plus></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p4.4.m4.1c">(\cdot)_{+}</annotation></semantics></math><span id="S2.SS2.p4.4.5" class="ltx_text" style="font-size:144%;"> denotes clipping negative values. There are tolerance thresholds of 0.02m for foot-floor distance and 0.075m/s for skating.</span></p>
</div>
<div id="S2.SS2.p5" class="ltx_para">
<p id="S2.SS2.p5.1" class="ltx_p"><span id="S2.SS2.p5.1.1" class="ltx_text ltx_font_bold" style="font-size:144%;">Goal Distance reward</span><span id="S2.SS2.p5.1.2" class="ltx_text" style="font-size:144%;"> that encourages the agent to get closer to the goal at each step:</span></p>
<table id="S2.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E5.m1.1" class="ltx_Math" alttext="r_{dist}=d^{t-1}-d^{t}," display="block"><semantics id="S2.E5.m1.1a"><mrow id="S2.E5.m1.1.1.1" xref="S2.E5.m1.1.1.1.1.cmml"><mrow id="S2.E5.m1.1.1.1.1" xref="S2.E5.m1.1.1.1.1.cmml"><msub id="S2.E5.m1.1.1.1.1.2" xref="S2.E5.m1.1.1.1.1.2.cmml"><mi mathsize="144%" id="S2.E5.m1.1.1.1.1.2.2" xref="S2.E5.m1.1.1.1.1.2.2.cmml">r</mi><mrow id="S2.E5.m1.1.1.1.1.2.3" xref="S2.E5.m1.1.1.1.1.2.3.cmml"><mi mathsize="144%" id="S2.E5.m1.1.1.1.1.2.3.2" xref="S2.E5.m1.1.1.1.1.2.3.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="S2.E5.m1.1.1.1.1.2.3.1" xref="S2.E5.m1.1.1.1.1.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E5.m1.1.1.1.1.2.3.3" xref="S2.E5.m1.1.1.1.1.2.3.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S2.E5.m1.1.1.1.1.2.3.1a" xref="S2.E5.m1.1.1.1.1.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E5.m1.1.1.1.1.2.3.4" xref="S2.E5.m1.1.1.1.1.2.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S2.E5.m1.1.1.1.1.2.3.1b" xref="S2.E5.m1.1.1.1.1.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E5.m1.1.1.1.1.2.3.5" xref="S2.E5.m1.1.1.1.1.2.3.5.cmml">t</mi></mrow></msub><mo mathsize="144%" id="S2.E5.m1.1.1.1.1.1" xref="S2.E5.m1.1.1.1.1.1.cmml">=</mo><mrow id="S2.E5.m1.1.1.1.1.3" xref="S2.E5.m1.1.1.1.1.3.cmml"><msup id="S2.E5.m1.1.1.1.1.3.2" xref="S2.E5.m1.1.1.1.1.3.2.cmml"><mi mathsize="144%" id="S2.E5.m1.1.1.1.1.3.2.2" xref="S2.E5.m1.1.1.1.1.3.2.2.cmml">d</mi><mrow id="S2.E5.m1.1.1.1.1.3.2.3" xref="S2.E5.m1.1.1.1.1.3.2.3.cmml"><mi mathsize="144%" id="S2.E5.m1.1.1.1.1.3.2.3.2" xref="S2.E5.m1.1.1.1.1.3.2.3.2.cmml">t</mi><mo mathsize="144%" id="S2.E5.m1.1.1.1.1.3.2.3.1" xref="S2.E5.m1.1.1.1.1.3.2.3.1.cmml">âˆ’</mo><mn mathsize="144%" id="S2.E5.m1.1.1.1.1.3.2.3.3" xref="S2.E5.m1.1.1.1.1.3.2.3.3.cmml">1</mn></mrow></msup><mo mathsize="144%" id="S2.E5.m1.1.1.1.1.3.1" xref="S2.E5.m1.1.1.1.1.3.1.cmml">âˆ’</mo><msup id="S2.E5.m1.1.1.1.1.3.3" xref="S2.E5.m1.1.1.1.1.3.3.cmml"><mi mathsize="144%" id="S2.E5.m1.1.1.1.1.3.3.2" xref="S2.E5.m1.1.1.1.1.3.3.2.cmml">d</mi><mi mathsize="144%" id="S2.E5.m1.1.1.1.1.3.3.3" xref="S2.E5.m1.1.1.1.1.3.3.3.cmml">t</mi></msup></mrow></mrow><mo mathsize="144%" id="S2.E5.m1.1.1.1.2" xref="S2.E5.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E5.m1.1b"><apply id="S2.E5.m1.1.1.1.1.cmml" xref="S2.E5.m1.1.1.1"><eq id="S2.E5.m1.1.1.1.1.1.cmml" xref="S2.E5.m1.1.1.1.1.1"></eq><apply id="S2.E5.m1.1.1.1.1.2.cmml" xref="S2.E5.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E5.m1.1.1.1.1.2.1.cmml" xref="S2.E5.m1.1.1.1.1.2">subscript</csymbol><ci id="S2.E5.m1.1.1.1.1.2.2.cmml" xref="S2.E5.m1.1.1.1.1.2.2">ğ‘Ÿ</ci><apply id="S2.E5.m1.1.1.1.1.2.3.cmml" xref="S2.E5.m1.1.1.1.1.2.3"><times id="S2.E5.m1.1.1.1.1.2.3.1.cmml" xref="S2.E5.m1.1.1.1.1.2.3.1"></times><ci id="S2.E5.m1.1.1.1.1.2.3.2.cmml" xref="S2.E5.m1.1.1.1.1.2.3.2">ğ‘‘</ci><ci id="S2.E5.m1.1.1.1.1.2.3.3.cmml" xref="S2.E5.m1.1.1.1.1.2.3.3">ğ‘–</ci><ci id="S2.E5.m1.1.1.1.1.2.3.4.cmml" xref="S2.E5.m1.1.1.1.1.2.3.4">ğ‘ </ci><ci id="S2.E5.m1.1.1.1.1.2.3.5.cmml" xref="S2.E5.m1.1.1.1.1.2.3.5">ğ‘¡</ci></apply></apply><apply id="S2.E5.m1.1.1.1.1.3.cmml" xref="S2.E5.m1.1.1.1.1.3"><minus id="S2.E5.m1.1.1.1.1.3.1.cmml" xref="S2.E5.m1.1.1.1.1.3.1"></minus><apply id="S2.E5.m1.1.1.1.1.3.2.cmml" xref="S2.E5.m1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S2.E5.m1.1.1.1.1.3.2.1.cmml" xref="S2.E5.m1.1.1.1.1.3.2">superscript</csymbol><ci id="S2.E5.m1.1.1.1.1.3.2.2.cmml" xref="S2.E5.m1.1.1.1.1.3.2.2">ğ‘‘</ci><apply id="S2.E5.m1.1.1.1.1.3.2.3.cmml" xref="S2.E5.m1.1.1.1.1.3.2.3"><minus id="S2.E5.m1.1.1.1.1.3.2.3.1.cmml" xref="S2.E5.m1.1.1.1.1.3.2.3.1"></minus><ci id="S2.E5.m1.1.1.1.1.3.2.3.2.cmml" xref="S2.E5.m1.1.1.1.1.3.2.3.2">ğ‘¡</ci><cn type="integer" id="S2.E5.m1.1.1.1.1.3.2.3.3.cmml" xref="S2.E5.m1.1.1.1.1.3.2.3.3">1</cn></apply></apply><apply id="S2.E5.m1.1.1.1.1.3.3.cmml" xref="S2.E5.m1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S2.E5.m1.1.1.1.1.3.3.1.cmml" xref="S2.E5.m1.1.1.1.1.3.3">superscript</csymbol><ci id="S2.E5.m1.1.1.1.1.3.3.2.cmml" xref="S2.E5.m1.1.1.1.1.3.3.2">ğ‘‘</ci><ci id="S2.E5.m1.1.1.1.1.3.3.3.cmml" xref="S2.E5.m1.1.1.1.1.3.3.3">ğ‘¡</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E5.m1.1c">r_{dist}=d^{t-1}-d^{t},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
</div>
<div id="S2.SS2.p6" class="ltx_para">
<p id="S2.SS2.p6.2" class="ltx_p"><span id="S2.SS2.p6.2.1" class="ltx_text" style="font-size:144%;">Here </span><math id="S2.SS2.p6.1.m1.1" class="ltx_Math" alttext="d^{t}" display="inline"><semantics id="S2.SS2.p6.1.m1.1a"><msup id="S2.SS2.p6.1.m1.1.1" xref="S2.SS2.p6.1.m1.1.1.cmml"><mi mathsize="144%" id="S2.SS2.p6.1.m1.1.1.2" xref="S2.SS2.p6.1.m1.1.1.2.cmml">d</mi><mi mathsize="144%" id="S2.SS2.p6.1.m1.1.1.3" xref="S2.SS2.p6.1.m1.1.1.3.cmml">t</mi></msup><annotation-xml encoding="MathML-Content" id="S2.SS2.p6.1.m1.1b"><apply id="S2.SS2.p6.1.m1.1.1.cmml" xref="S2.SS2.p6.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS2.p6.1.m1.1.1.1.cmml" xref="S2.SS2.p6.1.m1.1.1">superscript</csymbol><ci id="S2.SS2.p6.1.m1.1.1.2.cmml" xref="S2.SS2.p6.1.m1.1.1.2">ğ‘‘</ci><ci id="S2.SS2.p6.1.m1.1.1.3.cmml" xref="S2.SS2.p6.1.m1.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p6.1.m1.1c">d^{t}</annotation></semantics></math><span id="S2.SS2.p6.2.2" class="ltx_text" style="font-size:144%;"> denotes the body-goal distance at step </span><math id="S2.SS2.p6.2.m2.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S2.SS2.p6.2.m2.1a"><mi mathsize="144%" id="S2.SS2.p6.2.m2.1.1" xref="S2.SS2.p6.2.m2.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p6.2.m2.1b"><ci id="S2.SS2.p6.2.m2.1.1.cmml" xref="S2.SS2.p6.2.m2.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p6.2.m2.1c">t</annotation></semantics></math><span id="S2.SS2.p6.2.3" class="ltx_text" style="font-size:144%;">.</span></p>
</div>
<div id="S2.SS2.p7" class="ltx_para">
<p id="S2.SS2.p7.5" class="ltx_p"><span id="S2.SS2.p7.5.1" class="ltx_text ltx_font_bold" style="font-size:144%;">Body orientation reward</span><span id="S2.SS2.p7.5.2" class="ltx_text" style="font-size:144%;"> that encourages the body forward direction to be aligned with the goal location direction:</span></p>
<table id="S2.E6" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E6.m1.3" class="ltx_Math" alttext="r_{ori}=\frac{\langle o_{b},g-p\rangle+1}{2}," display="block"><semantics id="S2.E6.m1.3a"><mrow id="S2.E6.m1.3.3.1" xref="S2.E6.m1.3.3.1.1.cmml"><mrow id="S2.E6.m1.3.3.1.1" xref="S2.E6.m1.3.3.1.1.cmml"><msub id="S2.E6.m1.3.3.1.1.2" xref="S2.E6.m1.3.3.1.1.2.cmml"><mi mathsize="144%" id="S2.E6.m1.3.3.1.1.2.2" xref="S2.E6.m1.3.3.1.1.2.2.cmml">r</mi><mrow id="S2.E6.m1.3.3.1.1.2.3" xref="S2.E6.m1.3.3.1.1.2.3.cmml"><mi mathsize="144%" id="S2.E6.m1.3.3.1.1.2.3.2" xref="S2.E6.m1.3.3.1.1.2.3.2.cmml">o</mi><mo lspace="0em" rspace="0em" id="S2.E6.m1.3.3.1.1.2.3.1" xref="S2.E6.m1.3.3.1.1.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E6.m1.3.3.1.1.2.3.3" xref="S2.E6.m1.3.3.1.1.2.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S2.E6.m1.3.3.1.1.2.3.1a" xref="S2.E6.m1.3.3.1.1.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E6.m1.3.3.1.1.2.3.4" xref="S2.E6.m1.3.3.1.1.2.3.4.cmml">i</mi></mrow></msub><mo mathsize="144%" id="S2.E6.m1.3.3.1.1.1" xref="S2.E6.m1.3.3.1.1.1.cmml">=</mo><mfrac id="S2.E6.m1.2.2" xref="S2.E6.m1.2.2.cmml"><mrow id="S2.E6.m1.2.2.2" xref="S2.E6.m1.2.2.2.cmml"><mrow id="S2.E6.m1.2.2.2.2.2" xref="S2.E6.m1.2.2.2.2.3.cmml"><mo maxsize="144%" minsize="144%" id="S2.E6.m1.2.2.2.2.2.3" xref="S2.E6.m1.2.2.2.2.3.cmml">âŸ¨</mo><msub id="S2.E6.m1.1.1.1.1.1.1" xref="S2.E6.m1.1.1.1.1.1.1.cmml"><mi mathsize="144%" id="S2.E6.m1.1.1.1.1.1.1.2" xref="S2.E6.m1.1.1.1.1.1.1.2.cmml">o</mi><mi mathsize="144%" id="S2.E6.m1.1.1.1.1.1.1.3" xref="S2.E6.m1.1.1.1.1.1.1.3.cmml">b</mi></msub><mo mathsize="144%" id="S2.E6.m1.2.2.2.2.2.4" xref="S2.E6.m1.2.2.2.2.3.cmml">,</mo><mrow id="S2.E6.m1.2.2.2.2.2.2" xref="S2.E6.m1.2.2.2.2.2.2.cmml"><mi mathsize="144%" id="S2.E6.m1.2.2.2.2.2.2.2" xref="S2.E6.m1.2.2.2.2.2.2.2.cmml">g</mi><mo mathsize="144%" id="S2.E6.m1.2.2.2.2.2.2.1" xref="S2.E6.m1.2.2.2.2.2.2.1.cmml">âˆ’</mo><mi mathsize="144%" id="S2.E6.m1.2.2.2.2.2.2.3" xref="S2.E6.m1.2.2.2.2.2.2.3.cmml">p</mi></mrow><mo maxsize="144%" minsize="144%" id="S2.E6.m1.2.2.2.2.2.5" xref="S2.E6.m1.2.2.2.2.3.cmml">âŸ©</mo></mrow><mo mathsize="144%" id="S2.E6.m1.2.2.2.3" xref="S2.E6.m1.2.2.2.3.cmml">+</mo><mn mathsize="144%" id="S2.E6.m1.2.2.2.4" xref="S2.E6.m1.2.2.2.4.cmml">1</mn></mrow><mn mathsize="144%" id="S2.E6.m1.2.2.4" xref="S2.E6.m1.2.2.4.cmml">2</mn></mfrac></mrow><mo mathsize="144%" id="S2.E6.m1.3.3.1.2" xref="S2.E6.m1.3.3.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E6.m1.3b"><apply id="S2.E6.m1.3.3.1.1.cmml" xref="S2.E6.m1.3.3.1"><eq id="S2.E6.m1.3.3.1.1.1.cmml" xref="S2.E6.m1.3.3.1.1.1"></eq><apply id="S2.E6.m1.3.3.1.1.2.cmml" xref="S2.E6.m1.3.3.1.1.2"><csymbol cd="ambiguous" id="S2.E6.m1.3.3.1.1.2.1.cmml" xref="S2.E6.m1.3.3.1.1.2">subscript</csymbol><ci id="S2.E6.m1.3.3.1.1.2.2.cmml" xref="S2.E6.m1.3.3.1.1.2.2">ğ‘Ÿ</ci><apply id="S2.E6.m1.3.3.1.1.2.3.cmml" xref="S2.E6.m1.3.3.1.1.2.3"><times id="S2.E6.m1.3.3.1.1.2.3.1.cmml" xref="S2.E6.m1.3.3.1.1.2.3.1"></times><ci id="S2.E6.m1.3.3.1.1.2.3.2.cmml" xref="S2.E6.m1.3.3.1.1.2.3.2">ğ‘œ</ci><ci id="S2.E6.m1.3.3.1.1.2.3.3.cmml" xref="S2.E6.m1.3.3.1.1.2.3.3">ğ‘Ÿ</ci><ci id="S2.E6.m1.3.3.1.1.2.3.4.cmml" xref="S2.E6.m1.3.3.1.1.2.3.4">ğ‘–</ci></apply></apply><apply id="S2.E6.m1.2.2.cmml" xref="S2.E6.m1.2.2"><divide id="S2.E6.m1.2.2.3.cmml" xref="S2.E6.m1.2.2"></divide><apply id="S2.E6.m1.2.2.2.cmml" xref="S2.E6.m1.2.2.2"><plus id="S2.E6.m1.2.2.2.3.cmml" xref="S2.E6.m1.2.2.2.3"></plus><list id="S2.E6.m1.2.2.2.2.3.cmml" xref="S2.E6.m1.2.2.2.2.2"><apply id="S2.E6.m1.1.1.1.1.1.1.cmml" xref="S2.E6.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E6.m1.1.1.1.1.1.1.1.cmml" xref="S2.E6.m1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E6.m1.1.1.1.1.1.1.2.cmml" xref="S2.E6.m1.1.1.1.1.1.1.2">ğ‘œ</ci><ci id="S2.E6.m1.1.1.1.1.1.1.3.cmml" xref="S2.E6.m1.1.1.1.1.1.1.3">ğ‘</ci></apply><apply id="S2.E6.m1.2.2.2.2.2.2.cmml" xref="S2.E6.m1.2.2.2.2.2.2"><minus id="S2.E6.m1.2.2.2.2.2.2.1.cmml" xref="S2.E6.m1.2.2.2.2.2.2.1"></minus><ci id="S2.E6.m1.2.2.2.2.2.2.2.cmml" xref="S2.E6.m1.2.2.2.2.2.2.2">ğ‘”</ci><ci id="S2.E6.m1.2.2.2.2.2.2.3.cmml" xref="S2.E6.m1.2.2.2.2.2.2.3">ğ‘</ci></apply></list><cn type="integer" id="S2.E6.m1.2.2.2.4.cmml" xref="S2.E6.m1.2.2.2.4">1</cn></apply><cn type="integer" id="S2.E6.m1.2.2.4.cmml" xref="S2.E6.m1.2.2.4">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E6.m1.3c">r_{ori}=\frac{\langle o_{b},g-p\rangle+1}{2},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
<p id="S2.SS2.p7.4" class="ltx_p"><span id="S2.SS2.p7.4.1" class="ltx_text" style="font-size:144%;">where </span><math id="S2.SS2.p7.1.m1.1" class="ltx_Math" alttext="o_{b}" display="inline"><semantics id="S2.SS2.p7.1.m1.1a"><msub id="S2.SS2.p7.1.m1.1.1" xref="S2.SS2.p7.1.m1.1.1.cmml"><mi mathsize="144%" id="S2.SS2.p7.1.m1.1.1.2" xref="S2.SS2.p7.1.m1.1.1.2.cmml">o</mi><mi mathsize="144%" id="S2.SS2.p7.1.m1.1.1.3" xref="S2.SS2.p7.1.m1.1.1.3.cmml">b</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p7.1.m1.1b"><apply id="S2.SS2.p7.1.m1.1.1.cmml" xref="S2.SS2.p7.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS2.p7.1.m1.1.1.1.cmml" xref="S2.SS2.p7.1.m1.1.1">subscript</csymbol><ci id="S2.SS2.p7.1.m1.1.1.2.cmml" xref="S2.SS2.p7.1.m1.1.1.2">ğ‘œ</ci><ci id="S2.SS2.p7.1.m1.1.1.3.cmml" xref="S2.SS2.p7.1.m1.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p7.1.m1.1c">o_{b}</annotation></semantics></math><span id="S2.SS2.p7.4.2" class="ltx_text" style="font-size:144%;"> denotes the body forward orientation, </span><math id="S2.SS2.p7.2.m2.1" class="ltx_Math" alttext="g" display="inline"><semantics id="S2.SS2.p7.2.m2.1a"><mi mathsize="144%" id="S2.SS2.p7.2.m2.1.1" xref="S2.SS2.p7.2.m2.1.1.cmml">g</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p7.2.m2.1b"><ci id="S2.SS2.p7.2.m2.1.1.cmml" xref="S2.SS2.p7.2.m2.1.1">ğ‘”</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p7.2.m2.1c">g</annotation></semantics></math><span id="S2.SS2.p7.4.3" class="ltx_text" style="font-size:144%;"> and </span><math id="S2.SS2.p7.3.m3.1" class="ltx_Math" alttext="p" display="inline"><semantics id="S2.SS2.p7.3.m3.1a"><mi mathsize="144%" id="S2.SS2.p7.3.m3.1.1" xref="S2.SS2.p7.3.m3.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p7.3.m3.1b"><ci id="S2.SS2.p7.3.m3.1.1.cmml" xref="S2.SS2.p7.3.m3.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p7.3.m3.1c">p</annotation></semantics></math><span id="S2.SS2.p7.4.4" class="ltx_text" style="font-size:144%;"> denote the goal location and current pelvis location, and </span><math id="S2.SS2.p7.4.m4.1" class="ltx_Math" alttext="\langle\cdot\rangle" display="inline"><semantics id="S2.SS2.p7.4.m4.1a"><mrow id="S2.SS2.p7.4.m4.1.2.2" xref="S2.SS2.p7.4.m4.1.2.1.cmml"><mo maxsize="144%" minsize="144%" id="S2.SS2.p7.4.m4.1.2.2.1" xref="S2.SS2.p7.4.m4.1.2.1.1.cmml">âŸ¨</mo><mo lspace="0em" mathsize="144%" rspace="0em" id="S2.SS2.p7.4.m4.1.1" xref="S2.SS2.p7.4.m4.1.1.cmml">â‹…</mo><mo maxsize="144%" minsize="144%" id="S2.SS2.p7.4.m4.1.2.2.2" xref="S2.SS2.p7.4.m4.1.2.1.1.cmml">âŸ©</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p7.4.m4.1b"><apply id="S2.SS2.p7.4.m4.1.2.1.cmml" xref="S2.SS2.p7.4.m4.1.2.2"><csymbol cd="latexml" id="S2.SS2.p7.4.m4.1.2.1.1.cmml" xref="S2.SS2.p7.4.m4.1.2.2.1">delimited-âŸ¨âŸ©</csymbol><ci id="S2.SS2.p7.4.m4.1.1.cmml" xref="S2.SS2.p7.4.m4.1.1">â‹…</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p7.4.m4.1c">\langle\cdot\rangle</annotation></semantics></math><span id="S2.SS2.p7.4.5" class="ltx_text" style="font-size:144%;"> denotes inner product. Different from the </span><span id="S2.SS2.p7.4.6" class="ltx_text ltx_font_italic" style="font-size:144%;">attention reward</span><span id="S2.SS2.p7.4.7" class="ltx_text" style="font-size:144%;"> that drives the head motion, this penalizes backward movement toward the goal.</span></p>
</div>
<div id="S2.SS2.p8" class="ltx_para">
<p id="S2.SS2.p8.1" class="ltx_p"><span id="S2.SS2.p8.1.1" class="ltx_text ltx_font_bold" style="font-size:144%;">Penetration reward</span><span id="S2.SS2.p8.1.2" class="ltx_text" style="font-size:144%;"> that penalizes the intersection of the human body and obstacles. We use different penetration rewards in different settings.</span></p>
</div>
<div id="S2.SS2.p9" class="ltx_para">
<p id="S2.SS2.p9.1" class="ltx_p"><span id="S2.SS2.p9.1.1" class="ltx_text" style="font-size:144%;">When training in sparse scenes, e.g., a single static box obstacle, penetration detection is simplified into 2D to accelerate calculation:</span></p>
<table id="S2.E7" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E7.m1.4" class="ltx_Math" alttext="r_{pene}^{sparse}=\begin{cases}0.05,&amp;|\mathcal{M}_{0}\cap\mathcal{B}_{xy}(X)|&lt;thres\\
0,&amp;otherwise\end{cases}" display="block"><semantics id="S2.E7.m1.4a"><mrow id="S2.E7.m1.4.5" xref="S2.E7.m1.4.5.cmml"><msubsup id="S2.E7.m1.4.5.2" xref="S2.E7.m1.4.5.2.cmml"><mi mathsize="144%" id="S2.E7.m1.4.5.2.2.2" xref="S2.E7.m1.4.5.2.2.2.cmml">r</mi><mrow id="S2.E7.m1.4.5.2.2.3" xref="S2.E7.m1.4.5.2.2.3.cmml"><mi mathsize="144%" id="S2.E7.m1.4.5.2.2.3.2" xref="S2.E7.m1.4.5.2.2.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.E7.m1.4.5.2.2.3.1" xref="S2.E7.m1.4.5.2.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E7.m1.4.5.2.2.3.3" xref="S2.E7.m1.4.5.2.2.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S2.E7.m1.4.5.2.2.3.1a" xref="S2.E7.m1.4.5.2.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E7.m1.4.5.2.2.3.4" xref="S2.E7.m1.4.5.2.2.3.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="S2.E7.m1.4.5.2.2.3.1b" xref="S2.E7.m1.4.5.2.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E7.m1.4.5.2.2.3.5" xref="S2.E7.m1.4.5.2.2.3.5.cmml">e</mi></mrow><mrow id="S2.E7.m1.4.5.2.3" xref="S2.E7.m1.4.5.2.3.cmml"><mi mathsize="144%" id="S2.E7.m1.4.5.2.3.2" xref="S2.E7.m1.4.5.2.3.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S2.E7.m1.4.5.2.3.1" xref="S2.E7.m1.4.5.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E7.m1.4.5.2.3.3" xref="S2.E7.m1.4.5.2.3.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.E7.m1.4.5.2.3.1a" xref="S2.E7.m1.4.5.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E7.m1.4.5.2.3.4" xref="S2.E7.m1.4.5.2.3.4.cmml">a</mi><mo lspace="0em" rspace="0em" id="S2.E7.m1.4.5.2.3.1b" xref="S2.E7.m1.4.5.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E7.m1.4.5.2.3.5" xref="S2.E7.m1.4.5.2.3.5.cmml">r</mi><mo lspace="0em" rspace="0em" id="S2.E7.m1.4.5.2.3.1c" xref="S2.E7.m1.4.5.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E7.m1.4.5.2.3.6" xref="S2.E7.m1.4.5.2.3.6.cmml">s</mi><mo lspace="0em" rspace="0em" id="S2.E7.m1.4.5.2.3.1d" xref="S2.E7.m1.4.5.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E7.m1.4.5.2.3.7" xref="S2.E7.m1.4.5.2.3.7.cmml">e</mi></mrow></msubsup><mo mathsize="144%" id="S2.E7.m1.4.5.1" xref="S2.E7.m1.4.5.1.cmml">=</mo><mrow id="S2.E7.m1.4.4" xref="S2.E7.m1.4.5.3.1.cmml"><mo id="S2.E7.m1.4.4.5" xref="S2.E7.m1.4.5.3.1.1.cmml">{</mo><mtable columnspacing="5pt" displaystyle="true" rowspacing="0pt" id="S2.E7.m1.4.4.4" xref="S2.E7.m1.4.5.3.1.cmml"><mtr id="S2.E7.m1.4.4.4a" xref="S2.E7.m1.4.5.3.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S2.E7.m1.4.4.4b" xref="S2.E7.m1.4.5.3.1.cmml"><mrow id="S2.E7.m1.1.1.1.1.1.1.3" xref="S2.E7.m1.4.5.3.1.cmml"><mn mathsize="144%" id="S2.E7.m1.1.1.1.1.1.1.1" xref="S2.E7.m1.1.1.1.1.1.1.1.cmml">0.05</mn><mo mathsize="144%" id="S2.E7.m1.1.1.1.1.1.1.3.1" xref="S2.E7.m1.4.5.3.1.cmml">,</mo></mrow></mtd><mtd class="ltx_align_left" columnalign="left" id="S2.E7.m1.4.4.4c" xref="S2.E7.m1.4.5.3.1.cmml"><mrow id="S2.E7.m1.2.2.2.2.2.1" xref="S2.E7.m1.2.2.2.2.2.1.cmml"><mrow id="S2.E7.m1.2.2.2.2.2.1.2.1" xref="S2.E7.m1.2.2.2.2.2.1.2.2.cmml"><mo maxsize="144%" minsize="144%" id="S2.E7.m1.2.2.2.2.2.1.2.1.2" xref="S2.E7.m1.2.2.2.2.2.1.2.2.1.cmml">|</mo><mrow id="S2.E7.m1.2.2.2.2.2.1.2.1.1" xref="S2.E7.m1.2.2.2.2.2.1.2.1.1.cmml"><msub id="S2.E7.m1.2.2.2.2.2.1.2.1.1.2" xref="S2.E7.m1.2.2.2.2.2.1.2.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" mathsize="144%" id="S2.E7.m1.2.2.2.2.2.1.2.1.1.2.2" xref="S2.E7.m1.2.2.2.2.2.1.2.1.1.2.2.cmml">â„³</mi><mn mathsize="144%" id="S2.E7.m1.2.2.2.2.2.1.2.1.1.2.3" xref="S2.E7.m1.2.2.2.2.2.1.2.1.1.2.3.cmml">0</mn></msub><mo mathsize="144%" id="S2.E7.m1.2.2.2.2.2.1.2.1.1.1" xref="S2.E7.m1.2.2.2.2.2.1.2.1.1.1.cmml">âˆ©</mo><mrow id="S2.E7.m1.2.2.2.2.2.1.2.1.1.3" xref="S2.E7.m1.2.2.2.2.2.1.2.1.1.3.cmml"><msub id="S2.E7.m1.2.2.2.2.2.1.2.1.1.3.2" xref="S2.E7.m1.2.2.2.2.2.1.2.1.1.3.2.cmml"><mi class="ltx_font_mathcaligraphic" mathsize="144%" id="S2.E7.m1.2.2.2.2.2.1.2.1.1.3.2.2" xref="S2.E7.m1.2.2.2.2.2.1.2.1.1.3.2.2.cmml">â„¬</mi><mrow id="S2.E7.m1.2.2.2.2.2.1.2.1.1.3.2.3" xref="S2.E7.m1.2.2.2.2.2.1.2.1.1.3.2.3.cmml"><mi mathsize="144%" id="S2.E7.m1.2.2.2.2.2.1.2.1.1.3.2.3.2" xref="S2.E7.m1.2.2.2.2.2.1.2.1.1.3.2.3.2.cmml">x</mi><mo lspace="0em" rspace="0em" id="S2.E7.m1.2.2.2.2.2.1.2.1.1.3.2.3.1" xref="S2.E7.m1.2.2.2.2.2.1.2.1.1.3.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E7.m1.2.2.2.2.2.1.2.1.1.3.2.3.3" xref="S2.E7.m1.2.2.2.2.2.1.2.1.1.3.2.3.3.cmml">y</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S2.E7.m1.2.2.2.2.2.1.2.1.1.3.1" xref="S2.E7.m1.2.2.2.2.2.1.2.1.1.3.1.cmml">â€‹</mo><mrow id="S2.E7.m1.2.2.2.2.2.1.2.1.1.3.3.2" xref="S2.E7.m1.2.2.2.2.2.1.2.1.1.3.cmml"><mo maxsize="144%" minsize="144%" id="S2.E7.m1.2.2.2.2.2.1.2.1.1.3.3.2.1" xref="S2.E7.m1.2.2.2.2.2.1.2.1.1.3.cmml">(</mo><mi mathsize="144%" id="S2.E7.m1.2.2.2.2.2.1.1" xref="S2.E7.m1.2.2.2.2.2.1.1.cmml">X</mi><mo maxsize="144%" minsize="144%" id="S2.E7.m1.2.2.2.2.2.1.2.1.1.3.3.2.2" xref="S2.E7.m1.2.2.2.2.2.1.2.1.1.3.cmml">)</mo></mrow></mrow></mrow><mo maxsize="144%" minsize="144%" id="S2.E7.m1.2.2.2.2.2.1.2.1.3" xref="S2.E7.m1.2.2.2.2.2.1.2.2.1.cmml">|</mo></mrow><mo mathsize="144%" id="S2.E7.m1.2.2.2.2.2.1.3" xref="S2.E7.m1.2.2.2.2.2.1.3.cmml">&lt;</mo><mrow id="S2.E7.m1.2.2.2.2.2.1.4" xref="S2.E7.m1.2.2.2.2.2.1.4.cmml"><mi mathsize="144%" id="S2.E7.m1.2.2.2.2.2.1.4.2" xref="S2.E7.m1.2.2.2.2.2.1.4.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S2.E7.m1.2.2.2.2.2.1.4.1" xref="S2.E7.m1.2.2.2.2.2.1.4.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E7.m1.2.2.2.2.2.1.4.3" xref="S2.E7.m1.2.2.2.2.2.1.4.3.cmml">h</mi><mo lspace="0em" rspace="0em" id="S2.E7.m1.2.2.2.2.2.1.4.1a" xref="S2.E7.m1.2.2.2.2.2.1.4.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E7.m1.2.2.2.2.2.1.4.4" xref="S2.E7.m1.2.2.2.2.2.1.4.4.cmml">r</mi><mo lspace="0em" rspace="0em" id="S2.E7.m1.2.2.2.2.2.1.4.1b" xref="S2.E7.m1.2.2.2.2.2.1.4.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E7.m1.2.2.2.2.2.1.4.5" xref="S2.E7.m1.2.2.2.2.2.1.4.5.cmml">e</mi><mo lspace="0em" rspace="0em" id="S2.E7.m1.2.2.2.2.2.1.4.1c" xref="S2.E7.m1.2.2.2.2.2.1.4.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E7.m1.2.2.2.2.2.1.4.6" xref="S2.E7.m1.2.2.2.2.2.1.4.6.cmml">s</mi></mrow></mrow></mtd></mtr><mtr id="S2.E7.m1.4.4.4d" xref="S2.E7.m1.4.5.3.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S2.E7.m1.4.4.4e" xref="S2.E7.m1.4.5.3.1.cmml"><mrow id="S2.E7.m1.3.3.3.3.1.1.3" xref="S2.E7.m1.4.5.3.1.cmml"><mn mathsize="144%" id="S2.E7.m1.3.3.3.3.1.1.1" xref="S2.E7.m1.3.3.3.3.1.1.1.cmml">0</mn><mo mathsize="144%" id="S2.E7.m1.3.3.3.3.1.1.3.1" xref="S2.E7.m1.4.5.3.1.cmml">,</mo></mrow></mtd><mtd class="ltx_align_left" columnalign="left" id="S2.E7.m1.4.4.4f" xref="S2.E7.m1.4.5.3.1.cmml"><mrow id="S2.E7.m1.4.4.4.4.2.1" xref="S2.E7.m1.4.4.4.4.2.1.cmml"><mi mathsize="144%" id="S2.E7.m1.4.4.4.4.2.1.2" xref="S2.E7.m1.4.4.4.4.2.1.2.cmml">o</mi><mo lspace="0em" rspace="0em" id="S2.E7.m1.4.4.4.4.2.1.1" xref="S2.E7.m1.4.4.4.4.2.1.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E7.m1.4.4.4.4.2.1.3" xref="S2.E7.m1.4.4.4.4.2.1.3.cmml">t</mi><mo lspace="0em" rspace="0em" id="S2.E7.m1.4.4.4.4.2.1.1a" xref="S2.E7.m1.4.4.4.4.2.1.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E7.m1.4.4.4.4.2.1.4" xref="S2.E7.m1.4.4.4.4.2.1.4.cmml">h</mi><mo lspace="0em" rspace="0em" id="S2.E7.m1.4.4.4.4.2.1.1b" xref="S2.E7.m1.4.4.4.4.2.1.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E7.m1.4.4.4.4.2.1.5" xref="S2.E7.m1.4.4.4.4.2.1.5.cmml">e</mi><mo lspace="0em" rspace="0em" id="S2.E7.m1.4.4.4.4.2.1.1c" xref="S2.E7.m1.4.4.4.4.2.1.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E7.m1.4.4.4.4.2.1.6" xref="S2.E7.m1.4.4.4.4.2.1.6.cmml">r</mi><mo lspace="0em" rspace="0em" id="S2.E7.m1.4.4.4.4.2.1.1d" xref="S2.E7.m1.4.4.4.4.2.1.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E7.m1.4.4.4.4.2.1.7" xref="S2.E7.m1.4.4.4.4.2.1.7.cmml">w</mi><mo lspace="0em" rspace="0em" id="S2.E7.m1.4.4.4.4.2.1.1e" xref="S2.E7.m1.4.4.4.4.2.1.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E7.m1.4.4.4.4.2.1.8" xref="S2.E7.m1.4.4.4.4.2.1.8.cmml">i</mi><mo lspace="0em" rspace="0em" id="S2.E7.m1.4.4.4.4.2.1.1f" xref="S2.E7.m1.4.4.4.4.2.1.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E7.m1.4.4.4.4.2.1.9" xref="S2.E7.m1.4.4.4.4.2.1.9.cmml">s</mi><mo lspace="0em" rspace="0em" id="S2.E7.m1.4.4.4.4.2.1.1g" xref="S2.E7.m1.4.4.4.4.2.1.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E7.m1.4.4.4.4.2.1.10" xref="S2.E7.m1.4.4.4.4.2.1.10.cmml">e</mi></mrow></mtd></mtr></mtable></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E7.m1.4b"><apply id="S2.E7.m1.4.5.cmml" xref="S2.E7.m1.4.5"><eq id="S2.E7.m1.4.5.1.cmml" xref="S2.E7.m1.4.5.1"></eq><apply id="S2.E7.m1.4.5.2.cmml" xref="S2.E7.m1.4.5.2"><csymbol cd="ambiguous" id="S2.E7.m1.4.5.2.1.cmml" xref="S2.E7.m1.4.5.2">superscript</csymbol><apply id="S2.E7.m1.4.5.2.2.cmml" xref="S2.E7.m1.4.5.2"><csymbol cd="ambiguous" id="S2.E7.m1.4.5.2.2.1.cmml" xref="S2.E7.m1.4.5.2">subscript</csymbol><ci id="S2.E7.m1.4.5.2.2.2.cmml" xref="S2.E7.m1.4.5.2.2.2">ğ‘Ÿ</ci><apply id="S2.E7.m1.4.5.2.2.3.cmml" xref="S2.E7.m1.4.5.2.2.3"><times id="S2.E7.m1.4.5.2.2.3.1.cmml" xref="S2.E7.m1.4.5.2.2.3.1"></times><ci id="S2.E7.m1.4.5.2.2.3.2.cmml" xref="S2.E7.m1.4.5.2.2.3.2">ğ‘</ci><ci id="S2.E7.m1.4.5.2.2.3.3.cmml" xref="S2.E7.m1.4.5.2.2.3.3">ğ‘’</ci><ci id="S2.E7.m1.4.5.2.2.3.4.cmml" xref="S2.E7.m1.4.5.2.2.3.4">ğ‘›</ci><ci id="S2.E7.m1.4.5.2.2.3.5.cmml" xref="S2.E7.m1.4.5.2.2.3.5">ğ‘’</ci></apply></apply><apply id="S2.E7.m1.4.5.2.3.cmml" xref="S2.E7.m1.4.5.2.3"><times id="S2.E7.m1.4.5.2.3.1.cmml" xref="S2.E7.m1.4.5.2.3.1"></times><ci id="S2.E7.m1.4.5.2.3.2.cmml" xref="S2.E7.m1.4.5.2.3.2">ğ‘ </ci><ci id="S2.E7.m1.4.5.2.3.3.cmml" xref="S2.E7.m1.4.5.2.3.3">ğ‘</ci><ci id="S2.E7.m1.4.5.2.3.4.cmml" xref="S2.E7.m1.4.5.2.3.4">ğ‘</ci><ci id="S2.E7.m1.4.5.2.3.5.cmml" xref="S2.E7.m1.4.5.2.3.5">ğ‘Ÿ</ci><ci id="S2.E7.m1.4.5.2.3.6.cmml" xref="S2.E7.m1.4.5.2.3.6">ğ‘ </ci><ci id="S2.E7.m1.4.5.2.3.7.cmml" xref="S2.E7.m1.4.5.2.3.7">ğ‘’</ci></apply></apply><apply id="S2.E7.m1.4.5.3.1.cmml" xref="S2.E7.m1.4.4"><csymbol cd="latexml" id="S2.E7.m1.4.5.3.1.1.cmml" xref="S2.E7.m1.4.4.5">cases</csymbol><cn type="float" id="S2.E7.m1.1.1.1.1.1.1.1.cmml" xref="S2.E7.m1.1.1.1.1.1.1.1">0.05</cn><apply id="S2.E7.m1.2.2.2.2.2.1.cmml" xref="S2.E7.m1.2.2.2.2.2.1"><lt id="S2.E7.m1.2.2.2.2.2.1.3.cmml" xref="S2.E7.m1.2.2.2.2.2.1.3"></lt><apply id="S2.E7.m1.2.2.2.2.2.1.2.2.cmml" xref="S2.E7.m1.2.2.2.2.2.1.2.1"><abs id="S2.E7.m1.2.2.2.2.2.1.2.2.1.cmml" xref="S2.E7.m1.2.2.2.2.2.1.2.1.2"></abs><apply id="S2.E7.m1.2.2.2.2.2.1.2.1.1.cmml" xref="S2.E7.m1.2.2.2.2.2.1.2.1.1"><intersect id="S2.E7.m1.2.2.2.2.2.1.2.1.1.1.cmml" xref="S2.E7.m1.2.2.2.2.2.1.2.1.1.1"></intersect><apply id="S2.E7.m1.2.2.2.2.2.1.2.1.1.2.cmml" xref="S2.E7.m1.2.2.2.2.2.1.2.1.1.2"><csymbol cd="ambiguous" id="S2.E7.m1.2.2.2.2.2.1.2.1.1.2.1.cmml" xref="S2.E7.m1.2.2.2.2.2.1.2.1.1.2">subscript</csymbol><ci id="S2.E7.m1.2.2.2.2.2.1.2.1.1.2.2.cmml" xref="S2.E7.m1.2.2.2.2.2.1.2.1.1.2.2">â„³</ci><cn type="integer" id="S2.E7.m1.2.2.2.2.2.1.2.1.1.2.3.cmml" xref="S2.E7.m1.2.2.2.2.2.1.2.1.1.2.3">0</cn></apply><apply id="S2.E7.m1.2.2.2.2.2.1.2.1.1.3.cmml" xref="S2.E7.m1.2.2.2.2.2.1.2.1.1.3"><times id="S2.E7.m1.2.2.2.2.2.1.2.1.1.3.1.cmml" xref="S2.E7.m1.2.2.2.2.2.1.2.1.1.3.1"></times><apply id="S2.E7.m1.2.2.2.2.2.1.2.1.1.3.2.cmml" xref="S2.E7.m1.2.2.2.2.2.1.2.1.1.3.2"><csymbol cd="ambiguous" id="S2.E7.m1.2.2.2.2.2.1.2.1.1.3.2.1.cmml" xref="S2.E7.m1.2.2.2.2.2.1.2.1.1.3.2">subscript</csymbol><ci id="S2.E7.m1.2.2.2.2.2.1.2.1.1.3.2.2.cmml" xref="S2.E7.m1.2.2.2.2.2.1.2.1.1.3.2.2">â„¬</ci><apply id="S2.E7.m1.2.2.2.2.2.1.2.1.1.3.2.3.cmml" xref="S2.E7.m1.2.2.2.2.2.1.2.1.1.3.2.3"><times id="S2.E7.m1.2.2.2.2.2.1.2.1.1.3.2.3.1.cmml" xref="S2.E7.m1.2.2.2.2.2.1.2.1.1.3.2.3.1"></times><ci id="S2.E7.m1.2.2.2.2.2.1.2.1.1.3.2.3.2.cmml" xref="S2.E7.m1.2.2.2.2.2.1.2.1.1.3.2.3.2">ğ‘¥</ci><ci id="S2.E7.m1.2.2.2.2.2.1.2.1.1.3.2.3.3.cmml" xref="S2.E7.m1.2.2.2.2.2.1.2.1.1.3.2.3.3">ğ‘¦</ci></apply></apply><ci id="S2.E7.m1.2.2.2.2.2.1.1.cmml" xref="S2.E7.m1.2.2.2.2.2.1.1">ğ‘‹</ci></apply></apply></apply><apply id="S2.E7.m1.2.2.2.2.2.1.4.cmml" xref="S2.E7.m1.2.2.2.2.2.1.4"><times id="S2.E7.m1.2.2.2.2.2.1.4.1.cmml" xref="S2.E7.m1.2.2.2.2.2.1.4.1"></times><ci id="S2.E7.m1.2.2.2.2.2.1.4.2.cmml" xref="S2.E7.m1.2.2.2.2.2.1.4.2">ğ‘¡</ci><ci id="S2.E7.m1.2.2.2.2.2.1.4.3.cmml" xref="S2.E7.m1.2.2.2.2.2.1.4.3">â„</ci><ci id="S2.E7.m1.2.2.2.2.2.1.4.4.cmml" xref="S2.E7.m1.2.2.2.2.2.1.4.4">ğ‘Ÿ</ci><ci id="S2.E7.m1.2.2.2.2.2.1.4.5.cmml" xref="S2.E7.m1.2.2.2.2.2.1.4.5">ğ‘’</ci><ci id="S2.E7.m1.2.2.2.2.2.1.4.6.cmml" xref="S2.E7.m1.2.2.2.2.2.1.4.6">ğ‘ </ci></apply></apply><cn type="integer" id="S2.E7.m1.3.3.3.3.1.1.1.cmml" xref="S2.E7.m1.3.3.3.3.1.1.1">0</cn><apply id="S2.E7.m1.4.4.4.4.2.1.cmml" xref="S2.E7.m1.4.4.4.4.2.1"><times id="S2.E7.m1.4.4.4.4.2.1.1.cmml" xref="S2.E7.m1.4.4.4.4.2.1.1"></times><ci id="S2.E7.m1.4.4.4.4.2.1.2.cmml" xref="S2.E7.m1.4.4.4.4.2.1.2">ğ‘œ</ci><ci id="S2.E7.m1.4.4.4.4.2.1.3.cmml" xref="S2.E7.m1.4.4.4.4.2.1.3">ğ‘¡</ci><ci id="S2.E7.m1.4.4.4.4.2.1.4.cmml" xref="S2.E7.m1.4.4.4.4.2.1.4">â„</ci><ci id="S2.E7.m1.4.4.4.4.2.1.5.cmml" xref="S2.E7.m1.4.4.4.4.2.1.5">ğ‘’</ci><ci id="S2.E7.m1.4.4.4.4.2.1.6.cmml" xref="S2.E7.m1.4.4.4.4.2.1.6">ğ‘Ÿ</ci><ci id="S2.E7.m1.4.4.4.4.2.1.7.cmml" xref="S2.E7.m1.4.4.4.4.2.1.7">ğ‘¤</ci><ci id="S2.E7.m1.4.4.4.4.2.1.8.cmml" xref="S2.E7.m1.4.4.4.4.2.1.8">ğ‘–</ci><ci id="S2.E7.m1.4.4.4.4.2.1.9.cmml" xref="S2.E7.m1.4.4.4.4.2.1.9">ğ‘ </ci><ci id="S2.E7.m1.4.4.4.4.2.1.10.cmml" xref="S2.E7.m1.4.4.4.4.2.1.10">ğ‘’</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E7.m1.4c">r_{pene}^{sparse}=\begin{cases}0.05,&amp;|\mathcal{M}_{0}\cap\mathcal{B}_{xy}(X)|&lt;thres\\
0,&amp;otherwise\end{cases}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(7)</span></td>
</tr></tbody>
</table>
</div>
<div id="S2.SS2.p10" class="ltx_para">
<p id="S2.SS2.p10.7" class="ltx_p"><span id="S2.SS2.p10.7.1" class="ltx_text" style="font-size:144%;">where </span><math id="S2.SS2.p10.1.m1.1" class="ltx_Math" alttext="\mathcal{M}_{0}" display="inline"><semantics id="S2.SS2.p10.1.m1.1a"><msub id="S2.SS2.p10.1.m1.1.1" xref="S2.SS2.p10.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" mathsize="144%" id="S2.SS2.p10.1.m1.1.1.2" xref="S2.SS2.p10.1.m1.1.1.2.cmml">â„³</mi><mn mathsize="144%" id="S2.SS2.p10.1.m1.1.1.3" xref="S2.SS2.p10.1.m1.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p10.1.m1.1b"><apply id="S2.SS2.p10.1.m1.1.1.cmml" xref="S2.SS2.p10.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS2.p10.1.m1.1.1.1.cmml" xref="S2.SS2.p10.1.m1.1.1">subscript</csymbol><ci id="S2.SS2.p10.1.m1.1.1.2.cmml" xref="S2.SS2.p10.1.m1.1.1.2">â„³</ci><cn type="integer" id="S2.SS2.p10.1.m1.1.1.3.cmml" xref="S2.SS2.p10.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p10.1.m1.1c">\mathcal{M}_{0}</annotation></semantics></math><span id="S2.SS2.p10.7.2" class="ltx_text" style="font-size:144%;"> denotes the non-walkable cells on the ground plane, </span><math id="S2.SS2.p10.2.m2.1" class="ltx_math_unparsed" alttext="\mathcal{B}_{xy}(.)" display="inline"><semantics id="S2.SS2.p10.2.m2.1a"><mrow id="S2.SS2.p10.2.m2.1b"><msub id="S2.SS2.p10.2.m2.1.1"><mi class="ltx_font_mathcaligraphic" mathsize="144%" id="S2.SS2.p10.2.m2.1.1.2">â„¬</mi><mrow id="S2.SS2.p10.2.m2.1.1.3"><mi mathsize="144%" id="S2.SS2.p10.2.m2.1.1.3.2">x</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p10.2.m2.1.1.3.1">â€‹</mo><mi mathsize="144%" id="S2.SS2.p10.2.m2.1.1.3.3">y</mi></mrow></msub><mrow id="S2.SS2.p10.2.m2.1.2"><mo maxsize="144%" minsize="144%" id="S2.SS2.p10.2.m2.1.2.1">(</mo><mo lspace="0em" mathsize="144%" rspace="0.167em" id="S2.SS2.p10.2.m2.1.2.2">.</mo><mo maxsize="144%" minsize="144%" id="S2.SS2.p10.2.m2.1.2.3">)</mo></mrow></mrow><annotation encoding="application/x-tex" id="S2.SS2.p10.2.m2.1c">\mathcal{B}_{xy}(.)</annotation></semantics></math><span id="S2.SS2.p10.7.3" class="ltx_text" style="font-size:144%;"> denotes the 2D bounding box of the body markers </span><math id="S2.SS2.p10.3.m3.1" class="ltx_Math" alttext="X" display="inline"><semantics id="S2.SS2.p10.3.m3.1a"><mi mathsize="144%" id="S2.SS2.p10.3.m3.1.1" xref="S2.SS2.p10.3.m3.1.1.cmml">X</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p10.3.m3.1b"><ci id="S2.SS2.p10.3.m3.1.1.cmml" xref="S2.SS2.p10.3.m3.1.1">ğ‘‹</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p10.3.m3.1c">X</annotation></semantics></math><span id="S2.SS2.p10.7.4" class="ltx_text" style="font-size:144%;">, </span><math id="S2.SS2.p10.4.m4.1" class="ltx_Math" alttext="\cap" display="inline"><semantics id="S2.SS2.p10.4.m4.1a"><mo mathsize="144%" id="S2.SS2.p10.4.m4.1.1" xref="S2.SS2.p10.4.m4.1.1.cmml">âˆ©</mo><annotation-xml encoding="MathML-Content" id="S2.SS2.p10.4.m4.1b"><intersect id="S2.SS2.p10.4.m4.1.1.cmml" xref="S2.SS2.p10.4.m4.1.1"></intersect></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p10.4.m4.1c">\cap</annotation></semantics></math><span id="S2.SS2.p10.7.5" class="ltx_text" style="font-size:144%;"> denotes their intersection, and </span><math id="S2.SS2.p10.5.m5.1" class="ltx_math_unparsed" alttext="|\cdot|" display="inline"><semantics id="S2.SS2.p10.5.m5.1a"><mrow id="S2.SS2.p10.5.m5.1b"><mo fence="false" maxsize="144%" minsize="144%" id="S2.SS2.p10.5.m5.1.1">|</mo><mo lspace="0em" mathsize="144%" rspace="0em" id="S2.SS2.p10.5.m5.1.2">â‹…</mo><mo fence="false" maxsize="144%" minsize="144%" id="S2.SS2.p10.5.m5.1.3">|</mo></mrow><annotation encoding="application/x-tex" id="S2.SS2.p10.5.m5.1c">|\cdot|</annotation></semantics></math><span id="S2.SS2.p10.7.6" class="ltx_text" style="font-size:144%;"> denotes the number of non-walkable cells within the bounding box of the human. </span><math id="S2.SS2.p10.6.m6.1" class="ltx_Math" alttext="thres" display="inline"><semantics id="S2.SS2.p10.6.m6.1a"><mrow id="S2.SS2.p10.6.m6.1.1" xref="S2.SS2.p10.6.m6.1.1.cmml"><mi mathsize="144%" id="S2.SS2.p10.6.m6.1.1.2" xref="S2.SS2.p10.6.m6.1.1.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p10.6.m6.1.1.1" xref="S2.SS2.p10.6.m6.1.1.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.SS2.p10.6.m6.1.1.3" xref="S2.SS2.p10.6.m6.1.1.3.cmml">h</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p10.6.m6.1.1.1a" xref="S2.SS2.p10.6.m6.1.1.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.SS2.p10.6.m6.1.1.4" xref="S2.SS2.p10.6.m6.1.1.4.cmml">r</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p10.6.m6.1.1.1b" xref="S2.SS2.p10.6.m6.1.1.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.SS2.p10.6.m6.1.1.5" xref="S2.SS2.p10.6.m6.1.1.5.cmml">e</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p10.6.m6.1.1.1c" xref="S2.SS2.p10.6.m6.1.1.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.SS2.p10.6.m6.1.1.6" xref="S2.SS2.p10.6.m6.1.1.6.cmml">s</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p10.6.m6.1b"><apply id="S2.SS2.p10.6.m6.1.1.cmml" xref="S2.SS2.p10.6.m6.1.1"><times id="S2.SS2.p10.6.m6.1.1.1.cmml" xref="S2.SS2.p10.6.m6.1.1.1"></times><ci id="S2.SS2.p10.6.m6.1.1.2.cmml" xref="S2.SS2.p10.6.m6.1.1.2">ğ‘¡</ci><ci id="S2.SS2.p10.6.m6.1.1.3.cmml" xref="S2.SS2.p10.6.m6.1.1.3">â„</ci><ci id="S2.SS2.p10.6.m6.1.1.4.cmml" xref="S2.SS2.p10.6.m6.1.1.4">ğ‘Ÿ</ci><ci id="S2.SS2.p10.6.m6.1.1.5.cmml" xref="S2.SS2.p10.6.m6.1.1.5">ğ‘’</ci><ci id="S2.SS2.p10.6.m6.1.1.6.cmml" xref="S2.SS2.p10.6.m6.1.1.6">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p10.6.m6.1c">thres</annotation></semantics></math><span id="S2.SS2.p10.7.7" class="ltx_text" style="font-size:144%;"> is set to 3 and the cell dimension is </span><math id="S2.SS2.p10.7.m7.1" class="ltx_Math" alttext="0.1m\times 0.1m" display="inline"><semantics id="S2.SS2.p10.7.m7.1a"><mrow id="S2.SS2.p10.7.m7.1.1" xref="S2.SS2.p10.7.m7.1.1.cmml"><mrow id="S2.SS2.p10.7.m7.1.1.2" xref="S2.SS2.p10.7.m7.1.1.2.cmml"><mrow id="S2.SS2.p10.7.m7.1.1.2.2" xref="S2.SS2.p10.7.m7.1.1.2.2.cmml"><mn mathsize="144%" id="S2.SS2.p10.7.m7.1.1.2.2.2" xref="S2.SS2.p10.7.m7.1.1.2.2.2.cmml">0.1</mn><mo lspace="0em" rspace="0em" id="S2.SS2.p10.7.m7.1.1.2.2.1" xref="S2.SS2.p10.7.m7.1.1.2.2.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.SS2.p10.7.m7.1.1.2.2.3" xref="S2.SS2.p10.7.m7.1.1.2.2.3.cmml">m</mi></mrow><mo lspace="0.222em" mathsize="144%" rspace="0.222em" id="S2.SS2.p10.7.m7.1.1.2.1" xref="S2.SS2.p10.7.m7.1.1.2.1.cmml">Ã—</mo><mn mathsize="144%" id="S2.SS2.p10.7.m7.1.1.2.3" xref="S2.SS2.p10.7.m7.1.1.2.3.cmml">0.1</mn></mrow><mo lspace="0em" rspace="0em" id="S2.SS2.p10.7.m7.1.1.1" xref="S2.SS2.p10.7.m7.1.1.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.SS2.p10.7.m7.1.1.3" xref="S2.SS2.p10.7.m7.1.1.3.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p10.7.m7.1b"><apply id="S2.SS2.p10.7.m7.1.1.cmml" xref="S2.SS2.p10.7.m7.1.1"><times id="S2.SS2.p10.7.m7.1.1.1.cmml" xref="S2.SS2.p10.7.m7.1.1.1"></times><apply id="S2.SS2.p10.7.m7.1.1.2.cmml" xref="S2.SS2.p10.7.m7.1.1.2"><times id="S2.SS2.p10.7.m7.1.1.2.1.cmml" xref="S2.SS2.p10.7.m7.1.1.2.1"></times><apply id="S2.SS2.p10.7.m7.1.1.2.2.cmml" xref="S2.SS2.p10.7.m7.1.1.2.2"><times id="S2.SS2.p10.7.m7.1.1.2.2.1.cmml" xref="S2.SS2.p10.7.m7.1.1.2.2.1"></times><cn type="float" id="S2.SS2.p10.7.m7.1.1.2.2.2.cmml" xref="S2.SS2.p10.7.m7.1.1.2.2.2">0.1</cn><ci id="S2.SS2.p10.7.m7.1.1.2.2.3.cmml" xref="S2.SS2.p10.7.m7.1.1.2.2.3">ğ‘š</ci></apply><cn type="float" id="S2.SS2.p10.7.m7.1.1.2.3.cmml" xref="S2.SS2.p10.7.m7.1.1.2.3">0.1</cn></apply><ci id="S2.SS2.p10.7.m7.1.1.3.cmml" xref="S2.SS2.p10.7.m7.1.1.3">ğ‘š</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p10.7.m7.1c">0.1m\times 0.1m</annotation></semantics></math><span id="S2.SS2.p10.7.8" class="ltx_text" style="font-size:144%;">.</span></p>
</div>
<div id="S2.SS2.p11" class="ltx_para">
<p id="S2.SS2.p11.1" class="ltx_p"><span id="S2.SS2.p11.1.1" class="ltx_text" style="font-size:144%;">When training in crowded scenes, we use the signed distance field (</span><math id="S2.SS2.p11.1.m1.1" class="ltx_Math" alttext="\Psi_{O}" display="inline"><semantics id="S2.SS2.p11.1.m1.1a"><msub id="S2.SS2.p11.1.m1.1.1" xref="S2.SS2.p11.1.m1.1.1.cmml"><mi mathsize="144%" mathvariant="normal" id="S2.SS2.p11.1.m1.1.1.2" xref="S2.SS2.p11.1.m1.1.1.2.cmml">Î¨</mi><mi mathsize="144%" id="S2.SS2.p11.1.m1.1.1.3" xref="S2.SS2.p11.1.m1.1.1.3.cmml">O</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p11.1.m1.1b"><apply id="S2.SS2.p11.1.m1.1.1.cmml" xref="S2.SS2.p11.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS2.p11.1.m1.1.1.1.cmml" xref="S2.SS2.p11.1.m1.1.1">subscript</csymbol><ci id="S2.SS2.p11.1.m1.1.1.2.cmml" xref="S2.SS2.p11.1.m1.1.1.2">Î¨</ci><ci id="S2.SS2.p11.1.m1.1.1.3.cmml" xref="S2.SS2.p11.1.m1.1.1.3">ğ‘‚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p11.1.m1.1c">\Psi_{O}</annotation></semantics></math><span id="S2.SS2.p11.1.2" class="ltx_text" style="font-size:144%;">) for precise penetration detection:</span></p>
<table id="S2.E8" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E8.m1.2" class="ltx_Math" alttext="r_{pene}^{crowded}=e^{-\frac{1}{T}\sum_{t=1}^{T}\sum_{i=1}^{|V|}|(\Psi_{O}(\mathbf{v}_{ti}))_{-}|}\\
" display="block"><semantics id="S2.E8.m1.2a"><mrow id="S2.E8.m1.2.3" xref="S2.E8.m1.2.3.cmml"><msubsup id="S2.E8.m1.2.3.2" xref="S2.E8.m1.2.3.2.cmml"><mi mathsize="144%" id="S2.E8.m1.2.3.2.2.2" xref="S2.E8.m1.2.3.2.2.2.cmml">r</mi><mrow id="S2.E8.m1.2.3.2.2.3" xref="S2.E8.m1.2.3.2.2.3.cmml"><mi mathsize="144%" id="S2.E8.m1.2.3.2.2.3.2" xref="S2.E8.m1.2.3.2.2.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.E8.m1.2.3.2.2.3.1" xref="S2.E8.m1.2.3.2.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E8.m1.2.3.2.2.3.3" xref="S2.E8.m1.2.3.2.2.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S2.E8.m1.2.3.2.2.3.1a" xref="S2.E8.m1.2.3.2.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E8.m1.2.3.2.2.3.4" xref="S2.E8.m1.2.3.2.2.3.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="S2.E8.m1.2.3.2.2.3.1b" xref="S2.E8.m1.2.3.2.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E8.m1.2.3.2.2.3.5" xref="S2.E8.m1.2.3.2.2.3.5.cmml">e</mi></mrow><mrow id="S2.E8.m1.2.3.2.3" xref="S2.E8.m1.2.3.2.3.cmml"><mi mathsize="144%" id="S2.E8.m1.2.3.2.3.2" xref="S2.E8.m1.2.3.2.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S2.E8.m1.2.3.2.3.1" xref="S2.E8.m1.2.3.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E8.m1.2.3.2.3.3" xref="S2.E8.m1.2.3.2.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S2.E8.m1.2.3.2.3.1a" xref="S2.E8.m1.2.3.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E8.m1.2.3.2.3.4" xref="S2.E8.m1.2.3.2.3.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S2.E8.m1.2.3.2.3.1b" xref="S2.E8.m1.2.3.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E8.m1.2.3.2.3.5" xref="S2.E8.m1.2.3.2.3.5.cmml">w</mi><mo lspace="0em" rspace="0em" id="S2.E8.m1.2.3.2.3.1c" xref="S2.E8.m1.2.3.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E8.m1.2.3.2.3.6" xref="S2.E8.m1.2.3.2.3.6.cmml">d</mi><mo lspace="0em" rspace="0em" id="S2.E8.m1.2.3.2.3.1d" xref="S2.E8.m1.2.3.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E8.m1.2.3.2.3.7" xref="S2.E8.m1.2.3.2.3.7.cmml">e</mi><mo lspace="0em" rspace="0em" id="S2.E8.m1.2.3.2.3.1e" xref="S2.E8.m1.2.3.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E8.m1.2.3.2.3.8" xref="S2.E8.m1.2.3.2.3.8.cmml">d</mi></mrow></msubsup><mo mathsize="144%" id="S2.E8.m1.2.3.1" xref="S2.E8.m1.2.3.1.cmml">=</mo><msup id="S2.E8.m1.2.3.3" xref="S2.E8.m1.2.3.3.cmml"><mi mathsize="144%" id="S2.E8.m1.2.3.3.2" xref="S2.E8.m1.2.3.3.2.cmml">e</mi><mrow id="S2.E8.m1.2.2.2" xref="S2.E8.m1.2.2.2.cmml"><mo mathsize="144%" id="S2.E8.m1.2.2.2a" xref="S2.E8.m1.2.2.2.cmml">âˆ’</mo><mrow id="S2.E8.m1.2.2.2.2" xref="S2.E8.m1.2.2.2.2.cmml"><mfrac id="S2.E8.m1.2.2.2.2.3" xref="S2.E8.m1.2.2.2.2.3.cmml"><mn mathsize="144%" id="S2.E8.m1.2.2.2.2.3.2" xref="S2.E8.m1.2.2.2.2.3.2.cmml">1</mn><mi mathsize="144%" id="S2.E8.m1.2.2.2.2.3.3" xref="S2.E8.m1.2.2.2.2.3.3.cmml">T</mi></mfrac><mo lspace="0em" rspace="0em" id="S2.E8.m1.2.2.2.2.2" xref="S2.E8.m1.2.2.2.2.2.cmml">â€‹</mo><mrow id="S2.E8.m1.2.2.2.2.1" xref="S2.E8.m1.2.2.2.2.1.cmml"><mstyle displaystyle="false" id="S2.E8.m1.2.2.2.2.1.2" xref="S2.E8.m1.2.2.2.2.1.2.cmml"><msubsup id="S2.E8.m1.2.2.2.2.1.2a" xref="S2.E8.m1.2.2.2.2.1.2.cmml"><mo maxsize="101%" minsize="101%" stretchy="true" id="S2.E8.m1.2.2.2.2.1.2.2.2" xref="S2.E8.m1.2.2.2.2.1.2.2.2.cmml">âˆ‘</mo><mrow id="S2.E8.m1.2.2.2.2.1.2.2.3" xref="S2.E8.m1.2.2.2.2.1.2.2.3.cmml"><mi mathsize="144%" id="S2.E8.m1.2.2.2.2.1.2.2.3.2" xref="S2.E8.m1.2.2.2.2.1.2.2.3.2.cmml">t</mi><mo mathsize="144%" id="S2.E8.m1.2.2.2.2.1.2.2.3.1" xref="S2.E8.m1.2.2.2.2.1.2.2.3.1.cmml">=</mo><mn mathsize="144%" id="S2.E8.m1.2.2.2.2.1.2.2.3.3" xref="S2.E8.m1.2.2.2.2.1.2.2.3.3.cmml">1</mn></mrow><mi mathsize="144%" id="S2.E8.m1.2.2.2.2.1.2.3" xref="S2.E8.m1.2.2.2.2.1.2.3.cmml">T</mi></msubsup></mstyle><mrow id="S2.E8.m1.2.2.2.2.1.1" xref="S2.E8.m1.2.2.2.2.1.1.cmml"><mstyle displaystyle="false" id="S2.E8.m1.2.2.2.2.1.1.2" xref="S2.E8.m1.2.2.2.2.1.1.2.cmml"><msubsup id="S2.E8.m1.2.2.2.2.1.1.2a" xref="S2.E8.m1.2.2.2.2.1.1.2.cmml"><mo maxsize="101%" minsize="101%" stretchy="true" id="S2.E8.m1.2.2.2.2.1.1.2.2.2" xref="S2.E8.m1.2.2.2.2.1.1.2.2.2.cmml">âˆ‘</mo><mrow id="S2.E8.m1.2.2.2.2.1.1.2.2.3" xref="S2.E8.m1.2.2.2.2.1.1.2.2.3.cmml"><mi mathsize="144%" id="S2.E8.m1.2.2.2.2.1.1.2.2.3.2" xref="S2.E8.m1.2.2.2.2.1.1.2.2.3.2.cmml">i</mi><mo mathsize="144%" id="S2.E8.m1.2.2.2.2.1.1.2.2.3.1" xref="S2.E8.m1.2.2.2.2.1.1.2.2.3.1.cmml">=</mo><mn mathsize="144%" id="S2.E8.m1.2.2.2.2.1.1.2.2.3.3" xref="S2.E8.m1.2.2.2.2.1.1.2.2.3.3.cmml">1</mn></mrow><mrow id="S2.E8.m1.1.1.1.1.1.3" xref="S2.E8.m1.1.1.1.1.1.2.cmml"><mo maxsize="144%" minsize="144%" id="S2.E8.m1.1.1.1.1.1.3.1" xref="S2.E8.m1.1.1.1.1.1.2.1.cmml">|</mo><mi mathsize="144%" id="S2.E8.m1.1.1.1.1.1.1" xref="S2.E8.m1.1.1.1.1.1.1.cmml">V</mi><mo maxsize="144%" minsize="144%" id="S2.E8.m1.1.1.1.1.1.3.2" xref="S2.E8.m1.1.1.1.1.1.2.1.cmml">|</mo></mrow></msubsup></mstyle><mrow id="S2.E8.m1.2.2.2.2.1.1.1.1" xref="S2.E8.m1.2.2.2.2.1.1.1.2.cmml"><mo maxsize="144%" minsize="144%" id="S2.E8.m1.2.2.2.2.1.1.1.1.2" xref="S2.E8.m1.2.2.2.2.1.1.1.2.1.cmml">|</mo><msub id="S2.E8.m1.2.2.2.2.1.1.1.1.1" xref="S2.E8.m1.2.2.2.2.1.1.1.1.1.cmml"><mrow id="S2.E8.m1.2.2.2.2.1.1.1.1.1.1.1" xref="S2.E8.m1.2.2.2.2.1.1.1.1.1.1.1.1.cmml"><mo maxsize="144%" minsize="144%" id="S2.E8.m1.2.2.2.2.1.1.1.1.1.1.1.2" xref="S2.E8.m1.2.2.2.2.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.E8.m1.2.2.2.2.1.1.1.1.1.1.1.1" xref="S2.E8.m1.2.2.2.2.1.1.1.1.1.1.1.1.cmml"><msub id="S2.E8.m1.2.2.2.2.1.1.1.1.1.1.1.1.3" xref="S2.E8.m1.2.2.2.2.1.1.1.1.1.1.1.1.3.cmml"><mi mathsize="144%" mathvariant="normal" id="S2.E8.m1.2.2.2.2.1.1.1.1.1.1.1.1.3.2" xref="S2.E8.m1.2.2.2.2.1.1.1.1.1.1.1.1.3.2.cmml">Î¨</mi><mi mathsize="144%" id="S2.E8.m1.2.2.2.2.1.1.1.1.1.1.1.1.3.3" xref="S2.E8.m1.2.2.2.2.1.1.1.1.1.1.1.1.3.3.cmml">O</mi></msub><mo lspace="0em" rspace="0em" id="S2.E8.m1.2.2.2.2.1.1.1.1.1.1.1.1.2" xref="S2.E8.m1.2.2.2.2.1.1.1.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S2.E8.m1.2.2.2.2.1.1.1.1.1.1.1.1.1.1" xref="S2.E8.m1.2.2.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo maxsize="144%" minsize="144%" id="S2.E8.m1.2.2.2.2.1.1.1.1.1.1.1.1.1.1.2" xref="S2.E8.m1.2.2.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S2.E8.m1.2.2.2.2.1.1.1.1.1.1.1.1.1.1.1" xref="S2.E8.m1.2.2.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi mathsize="144%" id="S2.E8.m1.2.2.2.2.1.1.1.1.1.1.1.1.1.1.1.2" xref="S2.E8.m1.2.2.2.2.1.1.1.1.1.1.1.1.1.1.1.2.cmml">ğ¯</mi><mrow id="S2.E8.m1.2.2.2.2.1.1.1.1.1.1.1.1.1.1.1.3" xref="S2.E8.m1.2.2.2.2.1.1.1.1.1.1.1.1.1.1.1.3.cmml"><mi mathsize="144%" id="S2.E8.m1.2.2.2.2.1.1.1.1.1.1.1.1.1.1.1.3.2" xref="S2.E8.m1.2.2.2.2.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S2.E8.m1.2.2.2.2.1.1.1.1.1.1.1.1.1.1.1.3.1" xref="S2.E8.m1.2.2.2.2.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E8.m1.2.2.2.2.1.1.1.1.1.1.1.1.1.1.1.3.3" xref="S2.E8.m1.2.2.2.2.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml">i</mi></mrow></msub><mo maxsize="144%" minsize="144%" id="S2.E8.m1.2.2.2.2.1.1.1.1.1.1.1.1.1.1.3" xref="S2.E8.m1.2.2.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo maxsize="144%" minsize="144%" id="S2.E8.m1.2.2.2.2.1.1.1.1.1.1.1.3" xref="S2.E8.m1.2.2.2.2.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo mathsize="144%" id="S2.E8.m1.2.2.2.2.1.1.1.1.1.3" xref="S2.E8.m1.2.2.2.2.1.1.1.1.1.3.cmml">âˆ’</mo></msub><mo maxsize="144%" minsize="144%" id="S2.E8.m1.2.2.2.2.1.1.1.1.3" xref="S2.E8.m1.2.2.2.2.1.1.1.2.1.cmml">|</mo></mrow></mrow></mrow></mrow></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.E8.m1.2b"><apply id="S2.E8.m1.2.3.cmml" xref="S2.E8.m1.2.3"><eq id="S2.E8.m1.2.3.1.cmml" xref="S2.E8.m1.2.3.1"></eq><apply id="S2.E8.m1.2.3.2.cmml" xref="S2.E8.m1.2.3.2"><csymbol cd="ambiguous" id="S2.E8.m1.2.3.2.1.cmml" xref="S2.E8.m1.2.3.2">superscript</csymbol><apply id="S2.E8.m1.2.3.2.2.cmml" xref="S2.E8.m1.2.3.2"><csymbol cd="ambiguous" id="S2.E8.m1.2.3.2.2.1.cmml" xref="S2.E8.m1.2.3.2">subscript</csymbol><ci id="S2.E8.m1.2.3.2.2.2.cmml" xref="S2.E8.m1.2.3.2.2.2">ğ‘Ÿ</ci><apply id="S2.E8.m1.2.3.2.2.3.cmml" xref="S2.E8.m1.2.3.2.2.3"><times id="S2.E8.m1.2.3.2.2.3.1.cmml" xref="S2.E8.m1.2.3.2.2.3.1"></times><ci id="S2.E8.m1.2.3.2.2.3.2.cmml" xref="S2.E8.m1.2.3.2.2.3.2">ğ‘</ci><ci id="S2.E8.m1.2.3.2.2.3.3.cmml" xref="S2.E8.m1.2.3.2.2.3.3">ğ‘’</ci><ci id="S2.E8.m1.2.3.2.2.3.4.cmml" xref="S2.E8.m1.2.3.2.2.3.4">ğ‘›</ci><ci id="S2.E8.m1.2.3.2.2.3.5.cmml" xref="S2.E8.m1.2.3.2.2.3.5">ğ‘’</ci></apply></apply><apply id="S2.E8.m1.2.3.2.3.cmml" xref="S2.E8.m1.2.3.2.3"><times id="S2.E8.m1.2.3.2.3.1.cmml" xref="S2.E8.m1.2.3.2.3.1"></times><ci id="S2.E8.m1.2.3.2.3.2.cmml" xref="S2.E8.m1.2.3.2.3.2">ğ‘</ci><ci id="S2.E8.m1.2.3.2.3.3.cmml" xref="S2.E8.m1.2.3.2.3.3">ğ‘Ÿ</ci><ci id="S2.E8.m1.2.3.2.3.4.cmml" xref="S2.E8.m1.2.3.2.3.4">ğ‘œ</ci><ci id="S2.E8.m1.2.3.2.3.5.cmml" xref="S2.E8.m1.2.3.2.3.5">ğ‘¤</ci><ci id="S2.E8.m1.2.3.2.3.6.cmml" xref="S2.E8.m1.2.3.2.3.6">ğ‘‘</ci><ci id="S2.E8.m1.2.3.2.3.7.cmml" xref="S2.E8.m1.2.3.2.3.7">ğ‘’</ci><ci id="S2.E8.m1.2.3.2.3.8.cmml" xref="S2.E8.m1.2.3.2.3.8">ğ‘‘</ci></apply></apply><apply id="S2.E8.m1.2.3.3.cmml" xref="S2.E8.m1.2.3.3"><csymbol cd="ambiguous" id="S2.E8.m1.2.3.3.1.cmml" xref="S2.E8.m1.2.3.3">superscript</csymbol><ci id="S2.E8.m1.2.3.3.2.cmml" xref="S2.E8.m1.2.3.3.2">ğ‘’</ci><apply id="S2.E8.m1.2.2.2.cmml" xref="S2.E8.m1.2.2.2"><minus id="S2.E8.m1.2.2.2.3.cmml" xref="S2.E8.m1.2.2.2"></minus><apply id="S2.E8.m1.2.2.2.2.cmml" xref="S2.E8.m1.2.2.2.2"><times id="S2.E8.m1.2.2.2.2.2.cmml" xref="S2.E8.m1.2.2.2.2.2"></times><apply id="S2.E8.m1.2.2.2.2.3.cmml" xref="S2.E8.m1.2.2.2.2.3"><divide id="S2.E8.m1.2.2.2.2.3.1.cmml" xref="S2.E8.m1.2.2.2.2.3"></divide><cn type="integer" id="S2.E8.m1.2.2.2.2.3.2.cmml" xref="S2.E8.m1.2.2.2.2.3.2">1</cn><ci id="S2.E8.m1.2.2.2.2.3.3.cmml" xref="S2.E8.m1.2.2.2.2.3.3">ğ‘‡</ci></apply><apply id="S2.E8.m1.2.2.2.2.1.cmml" xref="S2.E8.m1.2.2.2.2.1"><apply id="S2.E8.m1.2.2.2.2.1.2.cmml" xref="S2.E8.m1.2.2.2.2.1.2"><csymbol cd="ambiguous" id="S2.E8.m1.2.2.2.2.1.2.1.cmml" xref="S2.E8.m1.2.2.2.2.1.2">superscript</csymbol><apply id="S2.E8.m1.2.2.2.2.1.2.2.cmml" xref="S2.E8.m1.2.2.2.2.1.2"><csymbol cd="ambiguous" id="S2.E8.m1.2.2.2.2.1.2.2.1.cmml" xref="S2.E8.m1.2.2.2.2.1.2">subscript</csymbol><sum id="S2.E8.m1.2.2.2.2.1.2.2.2.cmml" xref="S2.E8.m1.2.2.2.2.1.2.2.2"></sum><apply id="S2.E8.m1.2.2.2.2.1.2.2.3.cmml" xref="S2.E8.m1.2.2.2.2.1.2.2.3"><eq id="S2.E8.m1.2.2.2.2.1.2.2.3.1.cmml" xref="S2.E8.m1.2.2.2.2.1.2.2.3.1"></eq><ci id="S2.E8.m1.2.2.2.2.1.2.2.3.2.cmml" xref="S2.E8.m1.2.2.2.2.1.2.2.3.2">ğ‘¡</ci><cn type="integer" id="S2.E8.m1.2.2.2.2.1.2.2.3.3.cmml" xref="S2.E8.m1.2.2.2.2.1.2.2.3.3">1</cn></apply></apply><ci id="S2.E8.m1.2.2.2.2.1.2.3.cmml" xref="S2.E8.m1.2.2.2.2.1.2.3">ğ‘‡</ci></apply><apply id="S2.E8.m1.2.2.2.2.1.1.cmml" xref="S2.E8.m1.2.2.2.2.1.1"><apply id="S2.E8.m1.2.2.2.2.1.1.2.cmml" xref="S2.E8.m1.2.2.2.2.1.1.2"><csymbol cd="ambiguous" id="S2.E8.m1.2.2.2.2.1.1.2.1.cmml" xref="S2.E8.m1.2.2.2.2.1.1.2">superscript</csymbol><apply id="S2.E8.m1.2.2.2.2.1.1.2.2.cmml" xref="S2.E8.m1.2.2.2.2.1.1.2"><csymbol cd="ambiguous" id="S2.E8.m1.2.2.2.2.1.1.2.2.1.cmml" xref="S2.E8.m1.2.2.2.2.1.1.2">subscript</csymbol><sum id="S2.E8.m1.2.2.2.2.1.1.2.2.2.cmml" xref="S2.E8.m1.2.2.2.2.1.1.2.2.2"></sum><apply id="S2.E8.m1.2.2.2.2.1.1.2.2.3.cmml" xref="S2.E8.m1.2.2.2.2.1.1.2.2.3"><eq id="S2.E8.m1.2.2.2.2.1.1.2.2.3.1.cmml" xref="S2.E8.m1.2.2.2.2.1.1.2.2.3.1"></eq><ci id="S2.E8.m1.2.2.2.2.1.1.2.2.3.2.cmml" xref="S2.E8.m1.2.2.2.2.1.1.2.2.3.2">ğ‘–</ci><cn type="integer" id="S2.E8.m1.2.2.2.2.1.1.2.2.3.3.cmml" xref="S2.E8.m1.2.2.2.2.1.1.2.2.3.3">1</cn></apply></apply><apply id="S2.E8.m1.1.1.1.1.1.2.cmml" xref="S2.E8.m1.1.1.1.1.1.3"><abs id="S2.E8.m1.1.1.1.1.1.2.1.cmml" xref="S2.E8.m1.1.1.1.1.1.3.1"></abs><ci id="S2.E8.m1.1.1.1.1.1.1.cmml" xref="S2.E8.m1.1.1.1.1.1.1">ğ‘‰</ci></apply></apply><apply id="S2.E8.m1.2.2.2.2.1.1.1.2.cmml" xref="S2.E8.m1.2.2.2.2.1.1.1.1"><abs id="S2.E8.m1.2.2.2.2.1.1.1.2.1.cmml" xref="S2.E8.m1.2.2.2.2.1.1.1.1.2"></abs><apply id="S2.E8.m1.2.2.2.2.1.1.1.1.1.cmml" xref="S2.E8.m1.2.2.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E8.m1.2.2.2.2.1.1.1.1.1.2.cmml" xref="S2.E8.m1.2.2.2.2.1.1.1.1.1">subscript</csymbol><apply id="S2.E8.m1.2.2.2.2.1.1.1.1.1.1.1.1.cmml" xref="S2.E8.m1.2.2.2.2.1.1.1.1.1.1.1"><times id="S2.E8.m1.2.2.2.2.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E8.m1.2.2.2.2.1.1.1.1.1.1.1.1.2"></times><apply id="S2.E8.m1.2.2.2.2.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E8.m1.2.2.2.2.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E8.m1.2.2.2.2.1.1.1.1.1.1.1.1.3.1.cmml" xref="S2.E8.m1.2.2.2.2.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S2.E8.m1.2.2.2.2.1.1.1.1.1.1.1.1.3.2.cmml" xref="S2.E8.m1.2.2.2.2.1.1.1.1.1.1.1.1.3.2">Î¨</ci><ci id="S2.E8.m1.2.2.2.2.1.1.1.1.1.1.1.1.3.3.cmml" xref="S2.E8.m1.2.2.2.2.1.1.1.1.1.1.1.1.3.3">ğ‘‚</ci></apply><apply id="S2.E8.m1.2.2.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E8.m1.2.2.2.2.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E8.m1.2.2.2.2.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E8.m1.2.2.2.2.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E8.m1.2.2.2.2.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E8.m1.2.2.2.2.1.1.1.1.1.1.1.1.1.1.1.2">ğ¯</ci><apply id="S2.E8.m1.2.2.2.2.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E8.m1.2.2.2.2.1.1.1.1.1.1.1.1.1.1.1.3"><times id="S2.E8.m1.2.2.2.2.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S2.E8.m1.2.2.2.2.1.1.1.1.1.1.1.1.1.1.1.3.1"></times><ci id="S2.E8.m1.2.2.2.2.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S2.E8.m1.2.2.2.2.1.1.1.1.1.1.1.1.1.1.1.3.2">ğ‘¡</ci><ci id="S2.E8.m1.2.2.2.2.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S2.E8.m1.2.2.2.2.1.1.1.1.1.1.1.1.1.1.1.3.3">ğ‘–</ci></apply></apply></apply><minus id="S2.E8.m1.2.2.2.2.1.1.1.1.1.3.cmml" xref="S2.E8.m1.2.2.2.2.1.1.1.1.1.3"></minus></apply></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E8.m1.2c">r_{pene}^{crowded}=e^{-\frac{1}{T}\sum_{t=1}^{T}\sum_{i=1}^{|V|}|(\Psi_{O}(\mathbf{v}_{ti}))_{-}|}\\
</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(8)</span></td>
</tr></tbody>
</table>
</div>
<div id="S2.SS2.p12" class="ltx_para">
<p id="S2.SS2.p12.5" class="ltx_p"><span id="S2.SS2.p12.5.1" class="ltx_text" style="font-size:144%;">where </span><math id="S2.SS2.p12.1.m1.1" class="ltx_Math" alttext="|V|" display="inline"><semantics id="S2.SS2.p12.1.m1.1a"><mrow id="S2.SS2.p12.1.m1.1.2.2" xref="S2.SS2.p12.1.m1.1.2.1.cmml"><mo maxsize="144%" minsize="144%" id="S2.SS2.p12.1.m1.1.2.2.1" xref="S2.SS2.p12.1.m1.1.2.1.1.cmml">|</mo><mi mathsize="144%" id="S2.SS2.p12.1.m1.1.1" xref="S2.SS2.p12.1.m1.1.1.cmml">V</mi><mo maxsize="144%" minsize="144%" id="S2.SS2.p12.1.m1.1.2.2.2" xref="S2.SS2.p12.1.m1.1.2.1.1.cmml">|</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p12.1.m1.1b"><apply id="S2.SS2.p12.1.m1.1.2.1.cmml" xref="S2.SS2.p12.1.m1.1.2.2"><abs id="S2.SS2.p12.1.m1.1.2.1.1.cmml" xref="S2.SS2.p12.1.m1.1.2.2.1"></abs><ci id="S2.SS2.p12.1.m1.1.1.cmml" xref="S2.SS2.p12.1.m1.1.1">ğ‘‰</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p12.1.m1.1c">|V|</annotation></semantics></math><span id="S2.SS2.p12.5.2" class="ltx_text" style="font-size:144%;"> denotes the number of SMPL-X mesh vertices, </span><math id="S2.SS2.p12.2.m2.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S2.SS2.p12.2.m2.1a"><mi mathsize="144%" id="S2.SS2.p12.2.m2.1.1" xref="S2.SS2.p12.2.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p12.2.m2.1b"><ci id="S2.SS2.p12.2.m2.1.1.cmml" xref="S2.SS2.p12.2.m2.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p12.2.m2.1c">T</annotation></semantics></math><span id="S2.SS2.p12.5.3" class="ltx_text" style="font-size:144%;"> denotes the number of frames in our motion primitive (</span><math id="S2.SS2.p12.3.m3.1" class="ltx_Math" alttext="T=20" display="inline"><semantics id="S2.SS2.p12.3.m3.1a"><mrow id="S2.SS2.p12.3.m3.1.1" xref="S2.SS2.p12.3.m3.1.1.cmml"><mi mathsize="144%" id="S2.SS2.p12.3.m3.1.1.2" xref="S2.SS2.p12.3.m3.1.1.2.cmml">T</mi><mo mathsize="144%" id="S2.SS2.p12.3.m3.1.1.1" xref="S2.SS2.p12.3.m3.1.1.1.cmml">=</mo><mn mathsize="144%" id="S2.SS2.p12.3.m3.1.1.3" xref="S2.SS2.p12.3.m3.1.1.3.cmml">20</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p12.3.m3.1b"><apply id="S2.SS2.p12.3.m3.1.1.cmml" xref="S2.SS2.p12.3.m3.1.1"><eq id="S2.SS2.p12.3.m3.1.1.1.cmml" xref="S2.SS2.p12.3.m3.1.1.1"></eq><ci id="S2.SS2.p12.3.m3.1.1.2.cmml" xref="S2.SS2.p12.3.m3.1.1.2">ğ‘‡</ci><cn type="integer" id="S2.SS2.p12.3.m3.1.1.3.cmml" xref="S2.SS2.p12.3.m3.1.1.3">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p12.3.m3.1c">T=20</annotation></semantics></math><span id="S2.SS2.p12.5.4" class="ltx_text" style="font-size:144%;">), </span><math id="S2.SS2.p12.4.m4.1" class="ltx_Math" alttext="\mathbf{v}" display="inline"><semantics id="S2.SS2.p12.4.m4.1a"><mi mathsize="144%" id="S2.SS2.p12.4.m4.1.1" xref="S2.SS2.p12.4.m4.1.1.cmml">ğ¯</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p12.4.m4.1b"><ci id="S2.SS2.p12.4.m4.1.1.cmml" xref="S2.SS2.p12.4.m4.1.1">ğ¯</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p12.4.m4.1c">\mathbf{v}</annotation></semantics></math><span id="S2.SS2.p12.5.5" class="ltx_text" style="font-size:144%;"> denotes SMPL-X mesh vertex, and </span><math id="S2.SS2.p12.5.m5.1" class="ltx_Math" alttext="(\cdot)_{-}" display="inline"><semantics id="S2.SS2.p12.5.m5.1a"><msub id="S2.SS2.p12.5.m5.1.2" xref="S2.SS2.p12.5.m5.1.2.cmml"><mrow id="S2.SS2.p12.5.m5.1.2.2.2" xref="S2.SS2.p12.5.m5.1.2.cmml"><mo maxsize="144%" minsize="144%" id="S2.SS2.p12.5.m5.1.2.2.2.1" xref="S2.SS2.p12.5.m5.1.2.cmml">(</mo><mo lspace="0em" mathsize="144%" rspace="0em" id="S2.SS2.p12.5.m5.1.1" xref="S2.SS2.p12.5.m5.1.1.cmml">â‹…</mo><mo maxsize="144%" minsize="144%" id="S2.SS2.p12.5.m5.1.2.2.2.2" xref="S2.SS2.p12.5.m5.1.2.cmml">)</mo></mrow><mo mathsize="144%" id="S2.SS2.p12.5.m5.1.2.3" xref="S2.SS2.p12.5.m5.1.2.3.cmml">âˆ’</mo></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p12.5.m5.1b"><apply id="S2.SS2.p12.5.m5.1.2.cmml" xref="S2.SS2.p12.5.m5.1.2"><csymbol cd="ambiguous" id="S2.SS2.p12.5.m5.1.2.1.cmml" xref="S2.SS2.p12.5.m5.1.2">subscript</csymbol><ci id="S2.SS2.p12.5.m5.1.1.cmml" xref="S2.SS2.p12.5.m5.1.1">â‹…</ci><minus id="S2.SS2.p12.5.m5.1.2.3.cmml" xref="S2.SS2.p12.5.m5.1.2.3"></minus></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p12.5.m5.1c">(\cdot)_{-}</annotation></semantics></math><span id="S2.SS2.p12.5.6" class="ltx_text" style="font-size:144%;"> denotes clipping positive values. The penetration reward penalizes body vertices with negative SDF values within a motion primitive.</span></p>
</div>
<div id="S2.SS2.p13" class="ltx_para">
<p id="S2.SS2.p13.10" class="ltx_p"><span id="S2.SS2.p13.10.1" class="ltx_text ltx_font_bold" style="font-size:144%;">Pose reward</span><span id="S2.SS2.p13.10.2" class="ltx_text" style="font-size:144%;"> that penalizes generating unrealistic human poses using VPoser </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.SS2.p13.10.3.1" class="ltx_text" style="font-size:144%;">[</span><a href="#bib.bib67" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">67</span></a><span id="S2.SS2.p13.10.4.2" class="ltx_text" style="font-size:144%;">]</span></cite><span id="S2.SS2.p13.10.5" class="ltx_text" style="font-size:144%;"> body pose prior:</span></p>
<table id="S2.E9" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E9.m1.4" class="ltx_Math" alttext="r_{pose}=\begin{cases}0.05,&amp;\|VP\|_{2}&lt;thres\\
0,&amp;otherwise\end{cases}" display="block"><semantics id="S2.E9.m1.4a"><mrow id="S2.E9.m1.4.5" xref="S2.E9.m1.4.5.cmml"><msub id="S2.E9.m1.4.5.2" xref="S2.E9.m1.4.5.2.cmml"><mi mathsize="144%" id="S2.E9.m1.4.5.2.2" xref="S2.E9.m1.4.5.2.2.cmml">r</mi><mrow id="S2.E9.m1.4.5.2.3" xref="S2.E9.m1.4.5.2.3.cmml"><mi mathsize="144%" id="S2.E9.m1.4.5.2.3.2" xref="S2.E9.m1.4.5.2.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.E9.m1.4.5.2.3.1" xref="S2.E9.m1.4.5.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E9.m1.4.5.2.3.3" xref="S2.E9.m1.4.5.2.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S2.E9.m1.4.5.2.3.1a" xref="S2.E9.m1.4.5.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E9.m1.4.5.2.3.4" xref="S2.E9.m1.4.5.2.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S2.E9.m1.4.5.2.3.1b" xref="S2.E9.m1.4.5.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E9.m1.4.5.2.3.5" xref="S2.E9.m1.4.5.2.3.5.cmml">e</mi></mrow></msub><mo mathsize="144%" id="S2.E9.m1.4.5.1" xref="S2.E9.m1.4.5.1.cmml">=</mo><mrow id="S2.E9.m1.4.4" xref="S2.E9.m1.4.5.3.1.cmml"><mo id="S2.E9.m1.4.4.5" xref="S2.E9.m1.4.5.3.1.1.cmml">{</mo><mtable columnspacing="5pt" displaystyle="true" rowspacing="0pt" id="S2.E9.m1.4.4.4" xref="S2.E9.m1.4.5.3.1.cmml"><mtr id="S2.E9.m1.4.4.4a" xref="S2.E9.m1.4.5.3.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S2.E9.m1.4.4.4b" xref="S2.E9.m1.4.5.3.1.cmml"><mrow id="S2.E9.m1.1.1.1.1.1.1.3" xref="S2.E9.m1.4.5.3.1.cmml"><mn mathsize="144%" id="S2.E9.m1.1.1.1.1.1.1.1" xref="S2.E9.m1.1.1.1.1.1.1.1.cmml">0.05</mn><mo mathsize="144%" id="S2.E9.m1.1.1.1.1.1.1.3.1" xref="S2.E9.m1.4.5.3.1.cmml">,</mo></mrow></mtd><mtd class="ltx_align_left" columnalign="left" id="S2.E9.m1.4.4.4c" xref="S2.E9.m1.4.5.3.1.cmml"><mrow id="S2.E9.m1.2.2.2.2.2.1" xref="S2.E9.m1.2.2.2.2.2.1.cmml"><msub id="S2.E9.m1.2.2.2.2.2.1.1" xref="S2.E9.m1.2.2.2.2.2.1.1.cmml"><mrow id="S2.E9.m1.2.2.2.2.2.1.1.1.1" xref="S2.E9.m1.2.2.2.2.2.1.1.1.2.cmml"><mo maxsize="144%" minsize="144%" id="S2.E9.m1.2.2.2.2.2.1.1.1.1.2" xref="S2.E9.m1.2.2.2.2.2.1.1.1.2.1.cmml">â€–</mo><mrow id="S2.E9.m1.2.2.2.2.2.1.1.1.1.1" xref="S2.E9.m1.2.2.2.2.2.1.1.1.1.1.cmml"><mi mathsize="144%" id="S2.E9.m1.2.2.2.2.2.1.1.1.1.1.2" xref="S2.E9.m1.2.2.2.2.2.1.1.1.1.1.2.cmml">V</mi><mo lspace="0em" rspace="0em" id="S2.E9.m1.2.2.2.2.2.1.1.1.1.1.1" xref="S2.E9.m1.2.2.2.2.2.1.1.1.1.1.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E9.m1.2.2.2.2.2.1.1.1.1.1.3" xref="S2.E9.m1.2.2.2.2.2.1.1.1.1.1.3.cmml">P</mi></mrow><mo maxsize="144%" minsize="144%" id="S2.E9.m1.2.2.2.2.2.1.1.1.1.3" xref="S2.E9.m1.2.2.2.2.2.1.1.1.2.1.cmml">â€–</mo></mrow><mn mathsize="144%" id="S2.E9.m1.2.2.2.2.2.1.1.3" xref="S2.E9.m1.2.2.2.2.2.1.1.3.cmml">2</mn></msub><mo mathsize="144%" id="S2.E9.m1.2.2.2.2.2.1.2" xref="S2.E9.m1.2.2.2.2.2.1.2.cmml">&lt;</mo><mrow id="S2.E9.m1.2.2.2.2.2.1.3" xref="S2.E9.m1.2.2.2.2.2.1.3.cmml"><mi mathsize="144%" id="S2.E9.m1.2.2.2.2.2.1.3.2" xref="S2.E9.m1.2.2.2.2.2.1.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S2.E9.m1.2.2.2.2.2.1.3.1" xref="S2.E9.m1.2.2.2.2.2.1.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E9.m1.2.2.2.2.2.1.3.3" xref="S2.E9.m1.2.2.2.2.2.1.3.3.cmml">h</mi><mo lspace="0em" rspace="0em" id="S2.E9.m1.2.2.2.2.2.1.3.1a" xref="S2.E9.m1.2.2.2.2.2.1.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E9.m1.2.2.2.2.2.1.3.4" xref="S2.E9.m1.2.2.2.2.2.1.3.4.cmml">r</mi><mo lspace="0em" rspace="0em" id="S2.E9.m1.2.2.2.2.2.1.3.1b" xref="S2.E9.m1.2.2.2.2.2.1.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E9.m1.2.2.2.2.2.1.3.5" xref="S2.E9.m1.2.2.2.2.2.1.3.5.cmml">e</mi><mo lspace="0em" rspace="0em" id="S2.E9.m1.2.2.2.2.2.1.3.1c" xref="S2.E9.m1.2.2.2.2.2.1.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E9.m1.2.2.2.2.2.1.3.6" xref="S2.E9.m1.2.2.2.2.2.1.3.6.cmml">s</mi></mrow></mrow></mtd></mtr><mtr id="S2.E9.m1.4.4.4d" xref="S2.E9.m1.4.5.3.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S2.E9.m1.4.4.4e" xref="S2.E9.m1.4.5.3.1.cmml"><mrow id="S2.E9.m1.3.3.3.3.1.1.3" xref="S2.E9.m1.4.5.3.1.cmml"><mn mathsize="144%" id="S2.E9.m1.3.3.3.3.1.1.1" xref="S2.E9.m1.3.3.3.3.1.1.1.cmml">0</mn><mo mathsize="144%" id="S2.E9.m1.3.3.3.3.1.1.3.1" xref="S2.E9.m1.4.5.3.1.cmml">,</mo></mrow></mtd><mtd class="ltx_align_left" columnalign="left" id="S2.E9.m1.4.4.4f" xref="S2.E9.m1.4.5.3.1.cmml"><mrow id="S2.E9.m1.4.4.4.4.2.1" xref="S2.E9.m1.4.4.4.4.2.1.cmml"><mi mathsize="144%" id="S2.E9.m1.4.4.4.4.2.1.2" xref="S2.E9.m1.4.4.4.4.2.1.2.cmml">o</mi><mo lspace="0em" rspace="0em" id="S2.E9.m1.4.4.4.4.2.1.1" xref="S2.E9.m1.4.4.4.4.2.1.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E9.m1.4.4.4.4.2.1.3" xref="S2.E9.m1.4.4.4.4.2.1.3.cmml">t</mi><mo lspace="0em" rspace="0em" id="S2.E9.m1.4.4.4.4.2.1.1a" xref="S2.E9.m1.4.4.4.4.2.1.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E9.m1.4.4.4.4.2.1.4" xref="S2.E9.m1.4.4.4.4.2.1.4.cmml">h</mi><mo lspace="0em" rspace="0em" id="S2.E9.m1.4.4.4.4.2.1.1b" xref="S2.E9.m1.4.4.4.4.2.1.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E9.m1.4.4.4.4.2.1.5" xref="S2.E9.m1.4.4.4.4.2.1.5.cmml">e</mi><mo lspace="0em" rspace="0em" id="S2.E9.m1.4.4.4.4.2.1.1c" xref="S2.E9.m1.4.4.4.4.2.1.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E9.m1.4.4.4.4.2.1.6" xref="S2.E9.m1.4.4.4.4.2.1.6.cmml">r</mi><mo lspace="0em" rspace="0em" id="S2.E9.m1.4.4.4.4.2.1.1d" xref="S2.E9.m1.4.4.4.4.2.1.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E9.m1.4.4.4.4.2.1.7" xref="S2.E9.m1.4.4.4.4.2.1.7.cmml">w</mi><mo lspace="0em" rspace="0em" id="S2.E9.m1.4.4.4.4.2.1.1e" xref="S2.E9.m1.4.4.4.4.2.1.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E9.m1.4.4.4.4.2.1.8" xref="S2.E9.m1.4.4.4.4.2.1.8.cmml">i</mi><mo lspace="0em" rspace="0em" id="S2.E9.m1.4.4.4.4.2.1.1f" xref="S2.E9.m1.4.4.4.4.2.1.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E9.m1.4.4.4.4.2.1.9" xref="S2.E9.m1.4.4.4.4.2.1.9.cmml">s</mi><mo lspace="0em" rspace="0em" id="S2.E9.m1.4.4.4.4.2.1.1g" xref="S2.E9.m1.4.4.4.4.2.1.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E9.m1.4.4.4.4.2.1.10" xref="S2.E9.m1.4.4.4.4.2.1.10.cmml">e</mi></mrow></mtd></mtr></mtable></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E9.m1.4b"><apply id="S2.E9.m1.4.5.cmml" xref="S2.E9.m1.4.5"><eq id="S2.E9.m1.4.5.1.cmml" xref="S2.E9.m1.4.5.1"></eq><apply id="S2.E9.m1.4.5.2.cmml" xref="S2.E9.m1.4.5.2"><csymbol cd="ambiguous" id="S2.E9.m1.4.5.2.1.cmml" xref="S2.E9.m1.4.5.2">subscript</csymbol><ci id="S2.E9.m1.4.5.2.2.cmml" xref="S2.E9.m1.4.5.2.2">ğ‘Ÿ</ci><apply id="S2.E9.m1.4.5.2.3.cmml" xref="S2.E9.m1.4.5.2.3"><times id="S2.E9.m1.4.5.2.3.1.cmml" xref="S2.E9.m1.4.5.2.3.1"></times><ci id="S2.E9.m1.4.5.2.3.2.cmml" xref="S2.E9.m1.4.5.2.3.2">ğ‘</ci><ci id="S2.E9.m1.4.5.2.3.3.cmml" xref="S2.E9.m1.4.5.2.3.3">ğ‘œ</ci><ci id="S2.E9.m1.4.5.2.3.4.cmml" xref="S2.E9.m1.4.5.2.3.4">ğ‘ </ci><ci id="S2.E9.m1.4.5.2.3.5.cmml" xref="S2.E9.m1.4.5.2.3.5">ğ‘’</ci></apply></apply><apply id="S2.E9.m1.4.5.3.1.cmml" xref="S2.E9.m1.4.4"><csymbol cd="latexml" id="S2.E9.m1.4.5.3.1.1.cmml" xref="S2.E9.m1.4.4.5">cases</csymbol><cn type="float" id="S2.E9.m1.1.1.1.1.1.1.1.cmml" xref="S2.E9.m1.1.1.1.1.1.1.1">0.05</cn><apply id="S2.E9.m1.2.2.2.2.2.1.cmml" xref="S2.E9.m1.2.2.2.2.2.1"><lt id="S2.E9.m1.2.2.2.2.2.1.2.cmml" xref="S2.E9.m1.2.2.2.2.2.1.2"></lt><apply id="S2.E9.m1.2.2.2.2.2.1.1.cmml" xref="S2.E9.m1.2.2.2.2.2.1.1"><csymbol cd="ambiguous" id="S2.E9.m1.2.2.2.2.2.1.1.2.cmml" xref="S2.E9.m1.2.2.2.2.2.1.1">subscript</csymbol><apply id="S2.E9.m1.2.2.2.2.2.1.1.1.2.cmml" xref="S2.E9.m1.2.2.2.2.2.1.1.1.1"><csymbol cd="latexml" id="S2.E9.m1.2.2.2.2.2.1.1.1.2.1.cmml" xref="S2.E9.m1.2.2.2.2.2.1.1.1.1.2">norm</csymbol><apply id="S2.E9.m1.2.2.2.2.2.1.1.1.1.1.cmml" xref="S2.E9.m1.2.2.2.2.2.1.1.1.1.1"><times id="S2.E9.m1.2.2.2.2.2.1.1.1.1.1.1.cmml" xref="S2.E9.m1.2.2.2.2.2.1.1.1.1.1.1"></times><ci id="S2.E9.m1.2.2.2.2.2.1.1.1.1.1.2.cmml" xref="S2.E9.m1.2.2.2.2.2.1.1.1.1.1.2">ğ‘‰</ci><ci id="S2.E9.m1.2.2.2.2.2.1.1.1.1.1.3.cmml" xref="S2.E9.m1.2.2.2.2.2.1.1.1.1.1.3">ğ‘ƒ</ci></apply></apply><cn type="integer" id="S2.E9.m1.2.2.2.2.2.1.1.3.cmml" xref="S2.E9.m1.2.2.2.2.2.1.1.3">2</cn></apply><apply id="S2.E9.m1.2.2.2.2.2.1.3.cmml" xref="S2.E9.m1.2.2.2.2.2.1.3"><times id="S2.E9.m1.2.2.2.2.2.1.3.1.cmml" xref="S2.E9.m1.2.2.2.2.2.1.3.1"></times><ci id="S2.E9.m1.2.2.2.2.2.1.3.2.cmml" xref="S2.E9.m1.2.2.2.2.2.1.3.2">ğ‘¡</ci><ci id="S2.E9.m1.2.2.2.2.2.1.3.3.cmml" xref="S2.E9.m1.2.2.2.2.2.1.3.3">â„</ci><ci id="S2.E9.m1.2.2.2.2.2.1.3.4.cmml" xref="S2.E9.m1.2.2.2.2.2.1.3.4">ğ‘Ÿ</ci><ci id="S2.E9.m1.2.2.2.2.2.1.3.5.cmml" xref="S2.E9.m1.2.2.2.2.2.1.3.5">ğ‘’</ci><ci id="S2.E9.m1.2.2.2.2.2.1.3.6.cmml" xref="S2.E9.m1.2.2.2.2.2.1.3.6">ğ‘ </ci></apply></apply><cn type="integer" id="S2.E9.m1.3.3.3.3.1.1.1.cmml" xref="S2.E9.m1.3.3.3.3.1.1.1">0</cn><apply id="S2.E9.m1.4.4.4.4.2.1.cmml" xref="S2.E9.m1.4.4.4.4.2.1"><times id="S2.E9.m1.4.4.4.4.2.1.1.cmml" xref="S2.E9.m1.4.4.4.4.2.1.1"></times><ci id="S2.E9.m1.4.4.4.4.2.1.2.cmml" xref="S2.E9.m1.4.4.4.4.2.1.2">ğ‘œ</ci><ci id="S2.E9.m1.4.4.4.4.2.1.3.cmml" xref="S2.E9.m1.4.4.4.4.2.1.3">ğ‘¡</ci><ci id="S2.E9.m1.4.4.4.4.2.1.4.cmml" xref="S2.E9.m1.4.4.4.4.2.1.4">â„</ci><ci id="S2.E9.m1.4.4.4.4.2.1.5.cmml" xref="S2.E9.m1.4.4.4.4.2.1.5">ğ‘’</ci><ci id="S2.E9.m1.4.4.4.4.2.1.6.cmml" xref="S2.E9.m1.4.4.4.4.2.1.6">ğ‘Ÿ</ci><ci id="S2.E9.m1.4.4.4.4.2.1.7.cmml" xref="S2.E9.m1.4.4.4.4.2.1.7">ğ‘¤</ci><ci id="S2.E9.m1.4.4.4.4.2.1.8.cmml" xref="S2.E9.m1.4.4.4.4.2.1.8">ğ‘–</ci><ci id="S2.E9.m1.4.4.4.4.2.1.9.cmml" xref="S2.E9.m1.4.4.4.4.2.1.9">ğ‘ </ci><ci id="S2.E9.m1.4.4.4.4.2.1.10.cmml" xref="S2.E9.m1.4.4.4.4.2.1.10">ğ‘’</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E9.m1.4c">r_{pose}=\begin{cases}0.05,&amp;\|VP\|_{2}&lt;thres\\
0,&amp;otherwise\end{cases}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(9)</span></td>
</tr></tbody>
</table>
<p id="S2.SS2.p13.9" class="ltx_p"><span id="S2.SS2.p13.9.1" class="ltx_text" style="font-size:144%;">where </span><math id="S2.SS2.p13.1.m1.1" class="ltx_Math" alttext="\|" display="inline"><semantics id="S2.SS2.p13.1.m1.1a"><mo mathsize="144%" id="S2.SS2.p13.1.m1.1.1" xref="S2.SS2.p13.1.m1.1.1.cmml">âˆ¥</mo><annotation-xml encoding="MathML-Content" id="S2.SS2.p13.1.m1.1b"><ci id="S2.SS2.p13.1.m1.1.1.cmml" xref="S2.SS2.p13.1.m1.1.1">âˆ¥</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p13.1.m1.1c">\|</annotation></semantics></math><span id="S2.SS2.p13.9.2" class="ltx_text" style="font-size:144%;">VP</span><math id="S2.SS2.p13.2.m2.1" class="ltx_math_unparsed" alttext="\|_{2}" display="inline"><semantics id="S2.SS2.p13.2.m2.1a"><msub id="S2.SS2.p13.2.m2.1.1"><mo mathsize="144%" id="S2.SS2.p13.2.m2.1.1.2">âˆ¥</mo><mn mathsize="144%" id="S2.SS2.p13.2.m2.1.1.3">2</mn></msub><annotation encoding="application/x-tex" id="S2.SS2.p13.2.m2.1b">\|_{2}</annotation></semantics></math><span id="S2.SS2.p13.9.3" class="ltx_text" style="font-size:144%;"> denotes the pose embedding inferred by the VPoser encoder </span><math id="S2.SS2.p13.3.m3.1" class="ltx_Math" alttext="\mu(\cdot)" display="inline"><semantics id="S2.SS2.p13.3.m3.1a"><mrow id="S2.SS2.p13.3.m3.1.2" xref="S2.SS2.p13.3.m3.1.2.cmml"><mi mathsize="144%" id="S2.SS2.p13.3.m3.1.2.2" xref="S2.SS2.p13.3.m3.1.2.2.cmml">Î¼</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p13.3.m3.1.2.1" xref="S2.SS2.p13.3.m3.1.2.1.cmml">â€‹</mo><mrow id="S2.SS2.p13.3.m3.1.2.3.2" xref="S2.SS2.p13.3.m3.1.2.cmml"><mo maxsize="144%" minsize="144%" id="S2.SS2.p13.3.m3.1.2.3.2.1" xref="S2.SS2.p13.3.m3.1.2.cmml">(</mo><mo lspace="0em" mathsize="144%" rspace="0em" id="S2.SS2.p13.3.m3.1.1" xref="S2.SS2.p13.3.m3.1.1.cmml">â‹…</mo><mo maxsize="144%" minsize="144%" id="S2.SS2.p13.3.m3.1.2.3.2.2" xref="S2.SS2.p13.3.m3.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p13.3.m3.1b"><apply id="S2.SS2.p13.3.m3.1.2.cmml" xref="S2.SS2.p13.3.m3.1.2"><times id="S2.SS2.p13.3.m3.1.2.1.cmml" xref="S2.SS2.p13.3.m3.1.2.1"></times><ci id="S2.SS2.p13.3.m3.1.2.2.cmml" xref="S2.SS2.p13.3.m3.1.2.2">ğœ‡</ci><ci id="S2.SS2.p13.3.m3.1.1.cmml" xref="S2.SS2.p13.3.m3.1.1">â‹…</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p13.3.m3.1c">\mu(\cdot)</annotation></semantics></math><span id="S2.SS2.p13.9.4" class="ltx_text" style="font-size:144%;">, where </span><math id="S2.SS2.p13.4.m4.1" class="ltx_Math" alttext="\|" display="inline"><semantics id="S2.SS2.p13.4.m4.1a"><mo mathsize="144%" id="S2.SS2.p13.4.m4.1.1" xref="S2.SS2.p13.4.m4.1.1.cmml">âˆ¥</mo><annotation-xml encoding="MathML-Content" id="S2.SS2.p13.4.m4.1b"><ci id="S2.SS2.p13.4.m4.1.1.cmml" xref="S2.SS2.p13.4.m4.1.1">âˆ¥</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p13.4.m4.1c">\|</annotation></semantics></math><span id="S2.SS2.p13.9.5" class="ltx_text" style="font-size:144%;">VP</span><math id="S2.SS2.p13.5.m5.1" class="ltx_math_unparsed" alttext="\|_{2}=|\mu(\theta)|_{2}" display="inline"><semantics id="S2.SS2.p13.5.m5.1a"><mrow id="S2.SS2.p13.5.m5.1b"><msub id="S2.SS2.p13.5.m5.1.1"><mo mathsize="144%" id="S2.SS2.p13.5.m5.1.1.2">âˆ¥</mo><mn mathsize="144%" id="S2.SS2.p13.5.m5.1.1.3">2</mn></msub><mo lspace="0.167em" mathsize="144%" rspace="0em" id="S2.SS2.p13.5.m5.1.2">=</mo><mo fence="false" maxsize="144%" minsize="144%" rspace="0.167em" id="S2.SS2.p13.5.m5.1.3">|</mo><mi mathsize="144%" id="S2.SS2.p13.5.m5.1.4">Î¼</mi><mrow id="S2.SS2.p13.5.m5.1.5"><mo maxsize="144%" minsize="144%" id="S2.SS2.p13.5.m5.1.5.1">(</mo><mi mathsize="144%" id="S2.SS2.p13.5.m5.1.5.2">Î¸</mi><mo maxsize="144%" minsize="144%" id="S2.SS2.p13.5.m5.1.5.3">)</mo></mrow><msub id="S2.SS2.p13.5.m5.1.6"><mo fence="false" maxsize="144%" minsize="144%" id="S2.SS2.p13.5.m5.1.6.2">|</mo><mn mathsize="144%" id="S2.SS2.p13.5.m5.1.6.3">2</mn></msub></mrow><annotation encoding="application/x-tex" id="S2.SS2.p13.5.m5.1c">\|_{2}=|\mu(\theta)|_{2}</annotation></semantics></math><span id="S2.SS2.p13.9.6" class="ltx_text" style="font-size:144%;">.
</span><math id="S2.SS2.p13.6.m6.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="S2.SS2.p13.6.m6.1a"><mi mathsize="144%" id="S2.SS2.p13.6.m6.1.1" xref="S2.SS2.p13.6.m6.1.1.cmml">Î¸</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p13.6.m6.1b"><ci id="S2.SS2.p13.6.m6.1.1.cmml" xref="S2.SS2.p13.6.m6.1.1">ğœƒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p13.6.m6.1c">\theta</annotation></semantics></math><span id="S2.SS2.p13.9.7" class="ltx_text" style="font-size:144%;"> denotes the SMPL-X body pose parameter representation. The VPoser pose prior learns a probabilistic pose distribution where vectors closing to zero have a high probability and correspond to realistic human poses. In our observation, </span><math id="S2.SS2.p13.7.m7.1" class="ltx_Math" alttext="\|" display="inline"><semantics id="S2.SS2.p13.7.m7.1a"><mo mathsize="144%" id="S2.SS2.p13.7.m7.1.1" xref="S2.SS2.p13.7.m7.1.1.cmml">âˆ¥</mo><annotation-xml encoding="MathML-Content" id="S2.SS2.p13.7.m7.1b"><ci id="S2.SS2.p13.7.m7.1.1.cmml" xref="S2.SS2.p13.7.m7.1.1">âˆ¥</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p13.7.m7.1c">\|</annotation></semantics></math><span id="S2.SS2.p13.9.8" class="ltx_text" style="font-size:144%;">VP</span><math id="S2.SS2.p13.8.m8.1" class="ltx_math_unparsed" alttext="\|_{2}&gt;15" display="inline"><semantics id="S2.SS2.p13.8.m8.1a"><mrow id="S2.SS2.p13.8.m8.1b"><msub id="S2.SS2.p13.8.m8.1.1"><mo mathsize="144%" id="S2.SS2.p13.8.m8.1.1.2">âˆ¥</mo><mn mathsize="144%" id="S2.SS2.p13.8.m8.1.1.3">2</mn></msub><mo lspace="0.167em" mathsize="144%" id="S2.SS2.p13.8.m8.1.2">&gt;</mo><mn mathsize="144%" id="S2.SS2.p13.8.m8.1.3">15</mn></mrow><annotation encoding="application/x-tex" id="S2.SS2.p13.8.m8.1c">\|_{2}&gt;15</annotation></semantics></math><span id="S2.SS2.p13.9.9" class="ltx_text" style="font-size:144%;"> produces unrealistic human poses. </span><math id="S2.SS2.p13.9.m9.1" class="ltx_Math" alttext="thres" display="inline"><semantics id="S2.SS2.p13.9.m9.1a"><mrow id="S2.SS2.p13.9.m9.1.1" xref="S2.SS2.p13.9.m9.1.1.cmml"><mi mathsize="144%" id="S2.SS2.p13.9.m9.1.1.2" xref="S2.SS2.p13.9.m9.1.1.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p13.9.m9.1.1.1" xref="S2.SS2.p13.9.m9.1.1.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.SS2.p13.9.m9.1.1.3" xref="S2.SS2.p13.9.m9.1.1.3.cmml">h</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p13.9.m9.1.1.1a" xref="S2.SS2.p13.9.m9.1.1.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.SS2.p13.9.m9.1.1.4" xref="S2.SS2.p13.9.m9.1.1.4.cmml">r</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p13.9.m9.1.1.1b" xref="S2.SS2.p13.9.m9.1.1.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.SS2.p13.9.m9.1.1.5" xref="S2.SS2.p13.9.m9.1.1.5.cmml">e</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p13.9.m9.1.1.1c" xref="S2.SS2.p13.9.m9.1.1.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.SS2.p13.9.m9.1.1.6" xref="S2.SS2.p13.9.m9.1.1.6.cmml">s</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p13.9.m9.1b"><apply id="S2.SS2.p13.9.m9.1.1.cmml" xref="S2.SS2.p13.9.m9.1.1"><times id="S2.SS2.p13.9.m9.1.1.1.cmml" xref="S2.SS2.p13.9.m9.1.1.1"></times><ci id="S2.SS2.p13.9.m9.1.1.2.cmml" xref="S2.SS2.p13.9.m9.1.1.2">ğ‘¡</ci><ci id="S2.SS2.p13.9.m9.1.1.3.cmml" xref="S2.SS2.p13.9.m9.1.1.3">â„</ci><ci id="S2.SS2.p13.9.m9.1.1.4.cmml" xref="S2.SS2.p13.9.m9.1.1.4">ğ‘Ÿ</ci><ci id="S2.SS2.p13.9.m9.1.1.5.cmml" xref="S2.SS2.p13.9.m9.1.1.5">ğ‘’</ci><ci id="S2.SS2.p13.9.m9.1.1.6.cmml" xref="S2.SS2.p13.9.m9.1.1.6">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p13.9.m9.1c">thres</annotation></semantics></math><span id="S2.SS2.p13.9.10" class="ltx_text" style="font-size:144%;"> is set to 11.</span></p>
</div>
<div id="S2.SS2.p14" class="ltx_para">
<p id="S2.SS2.p14.3" class="ltx_p"><span id="S2.SS2.p14.3.1" class="ltx_text ltx_font_bold" style="font-size:144%;">Success reward</span><span id="S2.SS2.p14.3.2" class="ltx_text" style="font-size:144%;"> for reaching the goal location:</span></p>
<table id="S2.E10" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E10.m1.4" class="ltx_Math" alttext="r_{succ}=\begin{cases}1,&amp;d&lt;thres\\
0,&amp;otherwise\end{cases}" display="block"><semantics id="S2.E10.m1.4a"><mrow id="S2.E10.m1.4.5" xref="S2.E10.m1.4.5.cmml"><msub id="S2.E10.m1.4.5.2" xref="S2.E10.m1.4.5.2.cmml"><mi mathsize="144%" id="S2.E10.m1.4.5.2.2" xref="S2.E10.m1.4.5.2.2.cmml">r</mi><mrow id="S2.E10.m1.4.5.2.3" xref="S2.E10.m1.4.5.2.3.cmml"><mi mathsize="144%" id="S2.E10.m1.4.5.2.3.2" xref="S2.E10.m1.4.5.2.3.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S2.E10.m1.4.5.2.3.1" xref="S2.E10.m1.4.5.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E10.m1.4.5.2.3.3" xref="S2.E10.m1.4.5.2.3.3.cmml">u</mi><mo lspace="0em" rspace="0em" id="S2.E10.m1.4.5.2.3.1a" xref="S2.E10.m1.4.5.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E10.m1.4.5.2.3.4" xref="S2.E10.m1.4.5.2.3.4.cmml">c</mi><mo lspace="0em" rspace="0em" id="S2.E10.m1.4.5.2.3.1b" xref="S2.E10.m1.4.5.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E10.m1.4.5.2.3.5" xref="S2.E10.m1.4.5.2.3.5.cmml">c</mi></mrow></msub><mo mathsize="144%" id="S2.E10.m1.4.5.1" xref="S2.E10.m1.4.5.1.cmml">=</mo><mrow id="S2.E10.m1.4.4" xref="S2.E10.m1.4.5.3.1.cmml"><mo id="S2.E10.m1.4.4.5" xref="S2.E10.m1.4.5.3.1.1.cmml">{</mo><mtable columnspacing="5pt" displaystyle="true" rowspacing="0pt" id="S2.E10.m1.4.4.4" xref="S2.E10.m1.4.5.3.1.cmml"><mtr id="S2.E10.m1.4.4.4a" xref="S2.E10.m1.4.5.3.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S2.E10.m1.4.4.4b" xref="S2.E10.m1.4.5.3.1.cmml"><mrow id="S2.E10.m1.1.1.1.1.1.1.3" xref="S2.E10.m1.4.5.3.1.cmml"><mn mathsize="144%" id="S2.E10.m1.1.1.1.1.1.1.1" xref="S2.E10.m1.1.1.1.1.1.1.1.cmml">1</mn><mo mathsize="144%" id="S2.E10.m1.1.1.1.1.1.1.3.1" xref="S2.E10.m1.4.5.3.1.cmml">,</mo></mrow></mtd><mtd class="ltx_align_left" columnalign="left" id="S2.E10.m1.4.4.4c" xref="S2.E10.m1.4.5.3.1.cmml"><mrow id="S2.E10.m1.2.2.2.2.2.1" xref="S2.E10.m1.2.2.2.2.2.1.cmml"><mi mathsize="144%" id="S2.E10.m1.2.2.2.2.2.1.2" xref="S2.E10.m1.2.2.2.2.2.1.2.cmml">d</mi><mo mathsize="144%" id="S2.E10.m1.2.2.2.2.2.1.1" xref="S2.E10.m1.2.2.2.2.2.1.1.cmml">&lt;</mo><mrow id="S2.E10.m1.2.2.2.2.2.1.3" xref="S2.E10.m1.2.2.2.2.2.1.3.cmml"><mi mathsize="144%" id="S2.E10.m1.2.2.2.2.2.1.3.2" xref="S2.E10.m1.2.2.2.2.2.1.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S2.E10.m1.2.2.2.2.2.1.3.1" xref="S2.E10.m1.2.2.2.2.2.1.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E10.m1.2.2.2.2.2.1.3.3" xref="S2.E10.m1.2.2.2.2.2.1.3.3.cmml">h</mi><mo lspace="0em" rspace="0em" id="S2.E10.m1.2.2.2.2.2.1.3.1a" xref="S2.E10.m1.2.2.2.2.2.1.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E10.m1.2.2.2.2.2.1.3.4" xref="S2.E10.m1.2.2.2.2.2.1.3.4.cmml">r</mi><mo lspace="0em" rspace="0em" id="S2.E10.m1.2.2.2.2.2.1.3.1b" xref="S2.E10.m1.2.2.2.2.2.1.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E10.m1.2.2.2.2.2.1.3.5" xref="S2.E10.m1.2.2.2.2.2.1.3.5.cmml">e</mi><mo lspace="0em" rspace="0em" id="S2.E10.m1.2.2.2.2.2.1.3.1c" xref="S2.E10.m1.2.2.2.2.2.1.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E10.m1.2.2.2.2.2.1.3.6" xref="S2.E10.m1.2.2.2.2.2.1.3.6.cmml">s</mi></mrow></mrow></mtd></mtr><mtr id="S2.E10.m1.4.4.4d" xref="S2.E10.m1.4.5.3.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S2.E10.m1.4.4.4e" xref="S2.E10.m1.4.5.3.1.cmml"><mrow id="S2.E10.m1.3.3.3.3.1.1.3" xref="S2.E10.m1.4.5.3.1.cmml"><mn mathsize="144%" id="S2.E10.m1.3.3.3.3.1.1.1" xref="S2.E10.m1.3.3.3.3.1.1.1.cmml">0</mn><mo mathsize="144%" id="S2.E10.m1.3.3.3.3.1.1.3.1" xref="S2.E10.m1.4.5.3.1.cmml">,</mo></mrow></mtd><mtd class="ltx_align_left" columnalign="left" id="S2.E10.m1.4.4.4f" xref="S2.E10.m1.4.5.3.1.cmml"><mrow id="S2.E10.m1.4.4.4.4.2.1" xref="S2.E10.m1.4.4.4.4.2.1.cmml"><mi mathsize="144%" id="S2.E10.m1.4.4.4.4.2.1.2" xref="S2.E10.m1.4.4.4.4.2.1.2.cmml">o</mi><mo lspace="0em" rspace="0em" id="S2.E10.m1.4.4.4.4.2.1.1" xref="S2.E10.m1.4.4.4.4.2.1.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E10.m1.4.4.4.4.2.1.3" xref="S2.E10.m1.4.4.4.4.2.1.3.cmml">t</mi><mo lspace="0em" rspace="0em" id="S2.E10.m1.4.4.4.4.2.1.1a" xref="S2.E10.m1.4.4.4.4.2.1.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E10.m1.4.4.4.4.2.1.4" xref="S2.E10.m1.4.4.4.4.2.1.4.cmml">h</mi><mo lspace="0em" rspace="0em" id="S2.E10.m1.4.4.4.4.2.1.1b" xref="S2.E10.m1.4.4.4.4.2.1.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E10.m1.4.4.4.4.2.1.5" xref="S2.E10.m1.4.4.4.4.2.1.5.cmml">e</mi><mo lspace="0em" rspace="0em" id="S2.E10.m1.4.4.4.4.2.1.1c" xref="S2.E10.m1.4.4.4.4.2.1.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E10.m1.4.4.4.4.2.1.6" xref="S2.E10.m1.4.4.4.4.2.1.6.cmml">r</mi><mo lspace="0em" rspace="0em" id="S2.E10.m1.4.4.4.4.2.1.1d" xref="S2.E10.m1.4.4.4.4.2.1.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E10.m1.4.4.4.4.2.1.7" xref="S2.E10.m1.4.4.4.4.2.1.7.cmml">w</mi><mo lspace="0em" rspace="0em" id="S2.E10.m1.4.4.4.4.2.1.1e" xref="S2.E10.m1.4.4.4.4.2.1.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E10.m1.4.4.4.4.2.1.8" xref="S2.E10.m1.4.4.4.4.2.1.8.cmml">i</mi><mo lspace="0em" rspace="0em" id="S2.E10.m1.4.4.4.4.2.1.1f" xref="S2.E10.m1.4.4.4.4.2.1.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E10.m1.4.4.4.4.2.1.9" xref="S2.E10.m1.4.4.4.4.2.1.9.cmml">s</mi><mo lspace="0em" rspace="0em" id="S2.E10.m1.4.4.4.4.2.1.1g" xref="S2.E10.m1.4.4.4.4.2.1.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E10.m1.4.4.4.4.2.1.10" xref="S2.E10.m1.4.4.4.4.2.1.10.cmml">e</mi></mrow></mtd></mtr></mtable></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E10.m1.4b"><apply id="S2.E10.m1.4.5.cmml" xref="S2.E10.m1.4.5"><eq id="S2.E10.m1.4.5.1.cmml" xref="S2.E10.m1.4.5.1"></eq><apply id="S2.E10.m1.4.5.2.cmml" xref="S2.E10.m1.4.5.2"><csymbol cd="ambiguous" id="S2.E10.m1.4.5.2.1.cmml" xref="S2.E10.m1.4.5.2">subscript</csymbol><ci id="S2.E10.m1.4.5.2.2.cmml" xref="S2.E10.m1.4.5.2.2">ğ‘Ÿ</ci><apply id="S2.E10.m1.4.5.2.3.cmml" xref="S2.E10.m1.4.5.2.3"><times id="S2.E10.m1.4.5.2.3.1.cmml" xref="S2.E10.m1.4.5.2.3.1"></times><ci id="S2.E10.m1.4.5.2.3.2.cmml" xref="S2.E10.m1.4.5.2.3.2">ğ‘ </ci><ci id="S2.E10.m1.4.5.2.3.3.cmml" xref="S2.E10.m1.4.5.2.3.3">ğ‘¢</ci><ci id="S2.E10.m1.4.5.2.3.4.cmml" xref="S2.E10.m1.4.5.2.3.4">ğ‘</ci><ci id="S2.E10.m1.4.5.2.3.5.cmml" xref="S2.E10.m1.4.5.2.3.5">ğ‘</ci></apply></apply><apply id="S2.E10.m1.4.5.3.1.cmml" xref="S2.E10.m1.4.4"><csymbol cd="latexml" id="S2.E10.m1.4.5.3.1.1.cmml" xref="S2.E10.m1.4.4.5">cases</csymbol><cn type="integer" id="S2.E10.m1.1.1.1.1.1.1.1.cmml" xref="S2.E10.m1.1.1.1.1.1.1.1">1</cn><apply id="S2.E10.m1.2.2.2.2.2.1.cmml" xref="S2.E10.m1.2.2.2.2.2.1"><lt id="S2.E10.m1.2.2.2.2.2.1.1.cmml" xref="S2.E10.m1.2.2.2.2.2.1.1"></lt><ci id="S2.E10.m1.2.2.2.2.2.1.2.cmml" xref="S2.E10.m1.2.2.2.2.2.1.2">ğ‘‘</ci><apply id="S2.E10.m1.2.2.2.2.2.1.3.cmml" xref="S2.E10.m1.2.2.2.2.2.1.3"><times id="S2.E10.m1.2.2.2.2.2.1.3.1.cmml" xref="S2.E10.m1.2.2.2.2.2.1.3.1"></times><ci id="S2.E10.m1.2.2.2.2.2.1.3.2.cmml" xref="S2.E10.m1.2.2.2.2.2.1.3.2">ğ‘¡</ci><ci id="S2.E10.m1.2.2.2.2.2.1.3.3.cmml" xref="S2.E10.m1.2.2.2.2.2.1.3.3">â„</ci><ci id="S2.E10.m1.2.2.2.2.2.1.3.4.cmml" xref="S2.E10.m1.2.2.2.2.2.1.3.4">ğ‘Ÿ</ci><ci id="S2.E10.m1.2.2.2.2.2.1.3.5.cmml" xref="S2.E10.m1.2.2.2.2.2.1.3.5">ğ‘’</ci><ci id="S2.E10.m1.2.2.2.2.2.1.3.6.cmml" xref="S2.E10.m1.2.2.2.2.2.1.3.6">ğ‘ </ci></apply></apply><cn type="integer" id="S2.E10.m1.3.3.3.3.1.1.1.cmml" xref="S2.E10.m1.3.3.3.3.1.1.1">0</cn><apply id="S2.E10.m1.4.4.4.4.2.1.cmml" xref="S2.E10.m1.4.4.4.4.2.1"><times id="S2.E10.m1.4.4.4.4.2.1.1.cmml" xref="S2.E10.m1.4.4.4.4.2.1.1"></times><ci id="S2.E10.m1.4.4.4.4.2.1.2.cmml" xref="S2.E10.m1.4.4.4.4.2.1.2">ğ‘œ</ci><ci id="S2.E10.m1.4.4.4.4.2.1.3.cmml" xref="S2.E10.m1.4.4.4.4.2.1.3">ğ‘¡</ci><ci id="S2.E10.m1.4.4.4.4.2.1.4.cmml" xref="S2.E10.m1.4.4.4.4.2.1.4">â„</ci><ci id="S2.E10.m1.4.4.4.4.2.1.5.cmml" xref="S2.E10.m1.4.4.4.4.2.1.5">ğ‘’</ci><ci id="S2.E10.m1.4.4.4.4.2.1.6.cmml" xref="S2.E10.m1.4.4.4.4.2.1.6">ğ‘Ÿ</ci><ci id="S2.E10.m1.4.4.4.4.2.1.7.cmml" xref="S2.E10.m1.4.4.4.4.2.1.7">ğ‘¤</ci><ci id="S2.E10.m1.4.4.4.4.2.1.8.cmml" xref="S2.E10.m1.4.4.4.4.2.1.8">ğ‘–</ci><ci id="S2.E10.m1.4.4.4.4.2.1.9.cmml" xref="S2.E10.m1.4.4.4.4.2.1.9">ğ‘ </ci><ci id="S2.E10.m1.4.4.4.4.2.1.10.cmml" xref="S2.E10.m1.4.4.4.4.2.1.10">ğ‘’</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E10.m1.4c">r_{succ}=\begin{cases}1,&amp;d&lt;thres\\
0,&amp;otherwise\end{cases}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(10)</span></td>
</tr></tbody>
</table>
<p id="S2.SS2.p14.2" class="ltx_p"><span id="S2.SS2.p14.2.1" class="ltx_text" style="font-size:144%;">where </span><math id="S2.SS2.p14.1.m1.1" class="ltx_Math" alttext="d" display="inline"><semantics id="S2.SS2.p14.1.m1.1a"><mi mathsize="144%" id="S2.SS2.p14.1.m1.1.1" xref="S2.SS2.p14.1.m1.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p14.1.m1.1b"><ci id="S2.SS2.p14.1.m1.1.1.cmml" xref="S2.SS2.p14.1.m1.1.1">ğ‘‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p14.1.m1.1c">d</annotation></semantics></math><span id="S2.SS2.p14.2.2" class="ltx_text" style="font-size:144%;"> is the body-goal distance. </span><math id="S2.SS2.p14.2.m2.1" class="ltx_Math" alttext="thres" display="inline"><semantics id="S2.SS2.p14.2.m2.1a"><mrow id="S2.SS2.p14.2.m2.1.1" xref="S2.SS2.p14.2.m2.1.1.cmml"><mi mathsize="144%" id="S2.SS2.p14.2.m2.1.1.2" xref="S2.SS2.p14.2.m2.1.1.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p14.2.m2.1.1.1" xref="S2.SS2.p14.2.m2.1.1.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.SS2.p14.2.m2.1.1.3" xref="S2.SS2.p14.2.m2.1.1.3.cmml">h</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p14.2.m2.1.1.1a" xref="S2.SS2.p14.2.m2.1.1.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.SS2.p14.2.m2.1.1.4" xref="S2.SS2.p14.2.m2.1.1.4.cmml">r</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p14.2.m2.1.1.1b" xref="S2.SS2.p14.2.m2.1.1.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.SS2.p14.2.m2.1.1.5" xref="S2.SS2.p14.2.m2.1.1.5.cmml">e</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p14.2.m2.1.1.1c" xref="S2.SS2.p14.2.m2.1.1.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.SS2.p14.2.m2.1.1.6" xref="S2.SS2.p14.2.m2.1.1.6.cmml">s</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p14.2.m2.1b"><apply id="S2.SS2.p14.2.m2.1.1.cmml" xref="S2.SS2.p14.2.m2.1.1"><times id="S2.SS2.p14.2.m2.1.1.1.cmml" xref="S2.SS2.p14.2.m2.1.1.1"></times><ci id="S2.SS2.p14.2.m2.1.1.2.cmml" xref="S2.SS2.p14.2.m2.1.1.2">ğ‘¡</ci><ci id="S2.SS2.p14.2.m2.1.1.3.cmml" xref="S2.SS2.p14.2.m2.1.1.3">â„</ci><ci id="S2.SS2.p14.2.m2.1.1.4.cmml" xref="S2.SS2.p14.2.m2.1.1.4">ğ‘Ÿ</ci><ci id="S2.SS2.p14.2.m2.1.1.5.cmml" xref="S2.SS2.p14.2.m2.1.1.5">ğ‘’</ci><ci id="S2.SS2.p14.2.m2.1.1.6.cmml" xref="S2.SS2.p14.2.m2.1.1.6">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p14.2.m2.1c">thres</annotation></semantics></math><span id="S2.SS2.p14.2.3" class="ltx_text" style="font-size:144%;"> is set to 0.1.</span></p>
</div>
<div id="S2.SS2.p15" class="ltx_para">
<p id="S2.SS2.p15.1" class="ltx_p"><span id="S2.SS2.p15.1.1" class="ltx_text" style="font-size:144%;">The weights for each reward are listed inÂ </span><a href="#S2.T2" title="In S2.2 Reward, Weighting, and Training Detail â€£ S2 Ego-Sensing Driven Motion Synthesis â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref" style="font-size:144%;"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">S2</span></a><span id="S2.SS2.p15.1.2" class="ltx_text" style="font-size:144%;">. The weighting of each reward is determined according to the reward value. For example, the goal distance reward measures the distance change in one motion primitive spanning 0.5s, which is approximately 10 times smaller than other rewards. As a result, its weight is 10 times bigger than others. We observe high foot skating weight helps to reduce foot skating. Higher success rewards encourage the agent to reach the goal. But on the other hand, the weight can not be too big. Because we did not do reward normalization, too large values may lead to big errors in value estimation and training instabilities.</span></p>
</div>
<figure id="S2.T2" class="ltx_table">
<table id="S2.T2.2" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S2.T2.2.1" class="ltx_tr">
<td id="S2.T2.2.1.1" class="ltx_td ltx_align_center ltx_border_ll ltx_border_t" style="padding-bottom:3.09999pt;"><span id="S2.T2.2.1.1.1" class="ltx_text" style="font-size:144%;">Reward</span></td>
<td id="S2.T2.2.1.2" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" style="padding-bottom:3.09999pt;"><span id="S2.T2.2.1.2.1" class="ltx_text" style="font-size:144%;">Weight</span></td>
</tr>
<tr id="S2.T2.2.2" class="ltx_tr">
<td id="S2.T2.2.2.1" class="ltx_td ltx_align_center ltx_border_ll ltx_border_tt"><span id="S2.T2.2.2.1.1" class="ltx_text" style="font-size:144%;">Foot floor distance</span></td>
<td id="S2.T2.2.2.2" class="ltx_td ltx_align_center ltx_border_rr ltx_border_tt"><span id="S2.T2.2.2.2.1" class="ltx_text" style="font-size:144%;">0.1</span></td>
</tr>
<tr id="S2.T2.2.3" class="ltx_tr">
<td id="S2.T2.2.3.1" class="ltx_td ltx_align_center ltx_border_ll"><span id="S2.T2.2.3.1.1" class="ltx_text" style="font-size:144%;">Foot skating</span></td>
<td id="S2.T2.2.3.2" class="ltx_td ltx_align_center ltx_border_rr"><span id="S2.T2.2.3.2.1" class="ltx_text" style="font-size:144%;">0.3</span></td>
</tr>
<tr id="S2.T2.2.4" class="ltx_tr">
<td id="S2.T2.2.4.1" class="ltx_td ltx_align_center ltx_border_ll"><span id="S2.T2.2.4.1.1" class="ltx_text" style="font-size:144%;">Goal distance</span></td>
<td id="S2.T2.2.4.2" class="ltx_td ltx_align_center ltx_border_rr"><span id="S2.T2.2.4.2.1" class="ltx_text" style="font-size:144%;">1</span></td>
</tr>
<tr id="S2.T2.2.5" class="ltx_tr">
<td id="S2.T2.2.5.1" class="ltx_td ltx_align_center ltx_border_ll"><span id="S2.T2.2.5.1.1" class="ltx_text" style="font-size:144%;">Body orientation</span></td>
<td id="S2.T2.2.5.2" class="ltx_td ltx_align_center ltx_border_rr"><span id="S2.T2.2.5.2.1" class="ltx_text" style="font-size:144%;">0.1</span></td>
</tr>
<tr id="S2.T2.2.6" class="ltx_tr">
<td id="S2.T2.2.6.1" class="ltx_td ltx_align_center ltx_border_ll"><span id="S2.T2.2.6.1.1" class="ltx_text" style="font-size:144%;">Attention</span></td>
<td id="S2.T2.2.6.2" class="ltx_td ltx_align_center ltx_border_rr"><span id="S2.T2.2.6.2.1" class="ltx_text" style="font-size:144%;">0.3</span></td>
</tr>
<tr id="S2.T2.2.7" class="ltx_tr">
<td id="S2.T2.2.7.1" class="ltx_td ltx_align_center ltx_border_ll"><span id="S2.T2.2.7.1.1" class="ltx_text" style="font-size:144%;">Penetration pretraining</span></td>
<td id="S2.T2.2.7.2" class="ltx_td ltx_align_center ltx_border_rr"><span id="S2.T2.2.7.2.1" class="ltx_text" style="font-size:144%;">1</span></td>
</tr>
<tr id="S2.T2.2.8" class="ltx_tr">
<td id="S2.T2.2.8.1" class="ltx_td ltx_align_center ltx_border_ll"><span id="S2.T2.2.8.1.1" class="ltx_text" style="font-size:144%;">Penetration finetuning</span></td>
<td id="S2.T2.2.8.2" class="ltx_td ltx_align_center ltx_border_rr"><span id="S2.T2.2.8.2.1" class="ltx_text" style="font-size:144%;">0.1</span></td>
</tr>
<tr id="S2.T2.2.9" class="ltx_tr">
<td id="S2.T2.2.9.1" class="ltx_td ltx_align_center ltx_border_ll"><span id="S2.T2.2.9.1.1" class="ltx_text" style="font-size:144%;">Pose</span></td>
<td id="S2.T2.2.9.2" class="ltx_td ltx_align_center ltx_border_rr"><span id="S2.T2.2.9.2.1" class="ltx_text" style="font-size:144%;">0.1</span></td>
</tr>
<tr id="S2.T2.2.10" class="ltx_tr">
<td id="S2.T2.2.10.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_ll"><span id="S2.T2.2.10.1.1" class="ltx_text" style="font-size:144%;">Success</span></td>
<td id="S2.T2.2.10.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_rr"><span id="S2.T2.2.10.2.1" class="ltx_text" style="font-size:144%;">0.5</span></td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:144%;"><span class="ltx_tag ltx_tag_table"><span id="S2.T2.5.1.1" class="ltx_text" style="font-size:63%;">Table S2</span>: </span><span id="S2.T2.6.2" class="ltx_text" style="font-size:63%;">Reward weights.</span></figcaption>
</figure>
<div id="S2.SS2.p16" class="ltx_para">
<p id="S2.SS2.p16.1" class="ltx_p"><span id="S2.SS2.p16.1.1" class="ltx_text ltx_font_bold" style="font-size:144%;">Penetration Termination.</span><span id="S2.SS2.p16.1.2" class="ltx_text" style="font-size:144%;"> We terminate an episode due to penetration using different criteria. In sparse scenes, an episode is terminated if </span><math id="S2.SS2.p16.1.m1.1" class="ltx_Math" alttext="r_{pene}^{sparse}=0" display="inline"><semantics id="S2.SS2.p16.1.m1.1a"><mrow id="S2.SS2.p16.1.m1.1.1" xref="S2.SS2.p16.1.m1.1.1.cmml"><msubsup id="S2.SS2.p16.1.m1.1.1.2" xref="S2.SS2.p16.1.m1.1.1.2.cmml"><mi mathsize="144%" id="S2.SS2.p16.1.m1.1.1.2.2.2" xref="S2.SS2.p16.1.m1.1.1.2.2.2.cmml">r</mi><mrow id="S2.SS2.p16.1.m1.1.1.2.2.3" xref="S2.SS2.p16.1.m1.1.1.2.2.3.cmml"><mi mathsize="144%" id="S2.SS2.p16.1.m1.1.1.2.2.3.2" xref="S2.SS2.p16.1.m1.1.1.2.2.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p16.1.m1.1.1.2.2.3.1" xref="S2.SS2.p16.1.m1.1.1.2.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.SS2.p16.1.m1.1.1.2.2.3.3" xref="S2.SS2.p16.1.m1.1.1.2.2.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p16.1.m1.1.1.2.2.3.1a" xref="S2.SS2.p16.1.m1.1.1.2.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.SS2.p16.1.m1.1.1.2.2.3.4" xref="S2.SS2.p16.1.m1.1.1.2.2.3.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p16.1.m1.1.1.2.2.3.1b" xref="S2.SS2.p16.1.m1.1.1.2.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.SS2.p16.1.m1.1.1.2.2.3.5" xref="S2.SS2.p16.1.m1.1.1.2.2.3.5.cmml">e</mi></mrow><mrow id="S2.SS2.p16.1.m1.1.1.2.3" xref="S2.SS2.p16.1.m1.1.1.2.3.cmml"><mi mathsize="144%" id="S2.SS2.p16.1.m1.1.1.2.3.2" xref="S2.SS2.p16.1.m1.1.1.2.3.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p16.1.m1.1.1.2.3.1" xref="S2.SS2.p16.1.m1.1.1.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.SS2.p16.1.m1.1.1.2.3.3" xref="S2.SS2.p16.1.m1.1.1.2.3.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p16.1.m1.1.1.2.3.1a" xref="S2.SS2.p16.1.m1.1.1.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.SS2.p16.1.m1.1.1.2.3.4" xref="S2.SS2.p16.1.m1.1.1.2.3.4.cmml">a</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p16.1.m1.1.1.2.3.1b" xref="S2.SS2.p16.1.m1.1.1.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.SS2.p16.1.m1.1.1.2.3.5" xref="S2.SS2.p16.1.m1.1.1.2.3.5.cmml">r</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p16.1.m1.1.1.2.3.1c" xref="S2.SS2.p16.1.m1.1.1.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.SS2.p16.1.m1.1.1.2.3.6" xref="S2.SS2.p16.1.m1.1.1.2.3.6.cmml">s</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p16.1.m1.1.1.2.3.1d" xref="S2.SS2.p16.1.m1.1.1.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.SS2.p16.1.m1.1.1.2.3.7" xref="S2.SS2.p16.1.m1.1.1.2.3.7.cmml">e</mi></mrow></msubsup><mo mathsize="144%" id="S2.SS2.p16.1.m1.1.1.1" xref="S2.SS2.p16.1.m1.1.1.1.cmml">=</mo><mn mathsize="144%" id="S2.SS2.p16.1.m1.1.1.3" xref="S2.SS2.p16.1.m1.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p16.1.m1.1b"><apply id="S2.SS2.p16.1.m1.1.1.cmml" xref="S2.SS2.p16.1.m1.1.1"><eq id="S2.SS2.p16.1.m1.1.1.1.cmml" xref="S2.SS2.p16.1.m1.1.1.1"></eq><apply id="S2.SS2.p16.1.m1.1.1.2.cmml" xref="S2.SS2.p16.1.m1.1.1.2"><csymbol cd="ambiguous" id="S2.SS2.p16.1.m1.1.1.2.1.cmml" xref="S2.SS2.p16.1.m1.1.1.2">superscript</csymbol><apply id="S2.SS2.p16.1.m1.1.1.2.2.cmml" xref="S2.SS2.p16.1.m1.1.1.2"><csymbol cd="ambiguous" id="S2.SS2.p16.1.m1.1.1.2.2.1.cmml" xref="S2.SS2.p16.1.m1.1.1.2">subscript</csymbol><ci id="S2.SS2.p16.1.m1.1.1.2.2.2.cmml" xref="S2.SS2.p16.1.m1.1.1.2.2.2">ğ‘Ÿ</ci><apply id="S2.SS2.p16.1.m1.1.1.2.2.3.cmml" xref="S2.SS2.p16.1.m1.1.1.2.2.3"><times id="S2.SS2.p16.1.m1.1.1.2.2.3.1.cmml" xref="S2.SS2.p16.1.m1.1.1.2.2.3.1"></times><ci id="S2.SS2.p16.1.m1.1.1.2.2.3.2.cmml" xref="S2.SS2.p16.1.m1.1.1.2.2.3.2">ğ‘</ci><ci id="S2.SS2.p16.1.m1.1.1.2.2.3.3.cmml" xref="S2.SS2.p16.1.m1.1.1.2.2.3.3">ğ‘’</ci><ci id="S2.SS2.p16.1.m1.1.1.2.2.3.4.cmml" xref="S2.SS2.p16.1.m1.1.1.2.2.3.4">ğ‘›</ci><ci id="S2.SS2.p16.1.m1.1.1.2.2.3.5.cmml" xref="S2.SS2.p16.1.m1.1.1.2.2.3.5">ğ‘’</ci></apply></apply><apply id="S2.SS2.p16.1.m1.1.1.2.3.cmml" xref="S2.SS2.p16.1.m1.1.1.2.3"><times id="S2.SS2.p16.1.m1.1.1.2.3.1.cmml" xref="S2.SS2.p16.1.m1.1.1.2.3.1"></times><ci id="S2.SS2.p16.1.m1.1.1.2.3.2.cmml" xref="S2.SS2.p16.1.m1.1.1.2.3.2">ğ‘ </ci><ci id="S2.SS2.p16.1.m1.1.1.2.3.3.cmml" xref="S2.SS2.p16.1.m1.1.1.2.3.3">ğ‘</ci><ci id="S2.SS2.p16.1.m1.1.1.2.3.4.cmml" xref="S2.SS2.p16.1.m1.1.1.2.3.4">ğ‘</ci><ci id="S2.SS2.p16.1.m1.1.1.2.3.5.cmml" xref="S2.SS2.p16.1.m1.1.1.2.3.5">ğ‘Ÿ</ci><ci id="S2.SS2.p16.1.m1.1.1.2.3.6.cmml" xref="S2.SS2.p16.1.m1.1.1.2.3.6">ğ‘ </ci><ci id="S2.SS2.p16.1.m1.1.1.2.3.7.cmml" xref="S2.SS2.p16.1.m1.1.1.2.3.7">ğ‘’</ci></apply></apply><cn type="integer" id="S2.SS2.p16.1.m1.1.1.3.cmml" xref="S2.SS2.p16.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p16.1.m1.1c">r_{pene}^{sparse}=0</annotation></semantics></math><span id="S2.SS2.p16.1.3" class="ltx_text" style="font-size:144%;">.</span></p>
</div>
<div id="S2.SS2.p17" class="ltx_para">
<p id="S2.SS2.p17.2" class="ltx_p"><span id="S2.SS2.p17.2.1" class="ltx_text" style="font-size:144%;">As mentioned in </span><a href="#S3.SS2" title="3.2 Training Collision-Avoiding Stochastic Policies â€£ 3 Ego-Sensing Driven Motion Synthesis â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref" style="font-size:144%;"><span class="ltx_text ltx_ref_tag">Sec.</span>Â <span class="ltx_text ltx_ref_tag">3.2</span></a><span id="S2.SS2.p17.2.2" class="ltx_text" style="font-size:144%;"> in crowded scenes, we employ a two-stage RL training scheme. In stage I, we pretrain the policy with a penetration weight of </span><math id="S2.SS2.p17.1.m1.1" class="ltx_Math" alttext="w_{r_{pene}}=1" display="inline"><semantics id="S2.SS2.p17.1.m1.1a"><mrow id="S2.SS2.p17.1.m1.1.1" xref="S2.SS2.p17.1.m1.1.1.cmml"><msub id="S2.SS2.p17.1.m1.1.1.2" xref="S2.SS2.p17.1.m1.1.1.2.cmml"><mi mathsize="144%" id="S2.SS2.p17.1.m1.1.1.2.2" xref="S2.SS2.p17.1.m1.1.1.2.2.cmml">w</mi><msub id="S2.SS2.p17.1.m1.1.1.2.3" xref="S2.SS2.p17.1.m1.1.1.2.3.cmml"><mi mathsize="144%" id="S2.SS2.p17.1.m1.1.1.2.3.2" xref="S2.SS2.p17.1.m1.1.1.2.3.2.cmml">r</mi><mrow id="S2.SS2.p17.1.m1.1.1.2.3.3" xref="S2.SS2.p17.1.m1.1.1.2.3.3.cmml"><mi mathsize="144%" id="S2.SS2.p17.1.m1.1.1.2.3.3.2" xref="S2.SS2.p17.1.m1.1.1.2.3.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p17.1.m1.1.1.2.3.3.1" xref="S2.SS2.p17.1.m1.1.1.2.3.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.SS2.p17.1.m1.1.1.2.3.3.3" xref="S2.SS2.p17.1.m1.1.1.2.3.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p17.1.m1.1.1.2.3.3.1a" xref="S2.SS2.p17.1.m1.1.1.2.3.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.SS2.p17.1.m1.1.1.2.3.3.4" xref="S2.SS2.p17.1.m1.1.1.2.3.3.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p17.1.m1.1.1.2.3.3.1b" xref="S2.SS2.p17.1.m1.1.1.2.3.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.SS2.p17.1.m1.1.1.2.3.3.5" xref="S2.SS2.p17.1.m1.1.1.2.3.3.5.cmml">e</mi></mrow></msub></msub><mo mathsize="144%" id="S2.SS2.p17.1.m1.1.1.1" xref="S2.SS2.p17.1.m1.1.1.1.cmml">=</mo><mn mathsize="144%" id="S2.SS2.p17.1.m1.1.1.3" xref="S2.SS2.p17.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p17.1.m1.1b"><apply id="S2.SS2.p17.1.m1.1.1.cmml" xref="S2.SS2.p17.1.m1.1.1"><eq id="S2.SS2.p17.1.m1.1.1.1.cmml" xref="S2.SS2.p17.1.m1.1.1.1"></eq><apply id="S2.SS2.p17.1.m1.1.1.2.cmml" xref="S2.SS2.p17.1.m1.1.1.2"><csymbol cd="ambiguous" id="S2.SS2.p17.1.m1.1.1.2.1.cmml" xref="S2.SS2.p17.1.m1.1.1.2">subscript</csymbol><ci id="S2.SS2.p17.1.m1.1.1.2.2.cmml" xref="S2.SS2.p17.1.m1.1.1.2.2">ğ‘¤</ci><apply id="S2.SS2.p17.1.m1.1.1.2.3.cmml" xref="S2.SS2.p17.1.m1.1.1.2.3"><csymbol cd="ambiguous" id="S2.SS2.p17.1.m1.1.1.2.3.1.cmml" xref="S2.SS2.p17.1.m1.1.1.2.3">subscript</csymbol><ci id="S2.SS2.p17.1.m1.1.1.2.3.2.cmml" xref="S2.SS2.p17.1.m1.1.1.2.3.2">ğ‘Ÿ</ci><apply id="S2.SS2.p17.1.m1.1.1.2.3.3.cmml" xref="S2.SS2.p17.1.m1.1.1.2.3.3"><times id="S2.SS2.p17.1.m1.1.1.2.3.3.1.cmml" xref="S2.SS2.p17.1.m1.1.1.2.3.3.1"></times><ci id="S2.SS2.p17.1.m1.1.1.2.3.3.2.cmml" xref="S2.SS2.p17.1.m1.1.1.2.3.3.2">ğ‘</ci><ci id="S2.SS2.p17.1.m1.1.1.2.3.3.3.cmml" xref="S2.SS2.p17.1.m1.1.1.2.3.3.3">ğ‘’</ci><ci id="S2.SS2.p17.1.m1.1.1.2.3.3.4.cmml" xref="S2.SS2.p17.1.m1.1.1.2.3.3.4">ğ‘›</ci><ci id="S2.SS2.p17.1.m1.1.1.2.3.3.5.cmml" xref="S2.SS2.p17.1.m1.1.1.2.3.3.5">ğ‘’</ci></apply></apply></apply><cn type="integer" id="S2.SS2.p17.1.m1.1.1.3.cmml" xref="S2.SS2.p17.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p17.1.m1.1c">w_{r_{pene}}=1</annotation></semantics></math><span id="S2.SS2.p17.2.3" class="ltx_text" style="font-size:144%;"> to more effectively encourage the virtual human to avoid obstacles and explicitly </span><span id="S2.SS2.p17.2.4" class="ltx_text ltx_font_bold" style="font-size:144%;">not</span><span id="S2.SS2.p17.2.5" class="ltx_text" style="font-size:144%;"> perform penetration termination.
After convergence, in stage II, we proceed to fine-tune the policy with a strict penetration termination using a reduced penetration weight of </span><math id="S2.SS2.p17.2.m2.1" class="ltx_Math" alttext="w_{r_{pene}}=0.1" display="inline"><semantics id="S2.SS2.p17.2.m2.1a"><mrow id="S2.SS2.p17.2.m2.1.1" xref="S2.SS2.p17.2.m2.1.1.cmml"><msub id="S2.SS2.p17.2.m2.1.1.2" xref="S2.SS2.p17.2.m2.1.1.2.cmml"><mi mathsize="144%" id="S2.SS2.p17.2.m2.1.1.2.2" xref="S2.SS2.p17.2.m2.1.1.2.2.cmml">w</mi><msub id="S2.SS2.p17.2.m2.1.1.2.3" xref="S2.SS2.p17.2.m2.1.1.2.3.cmml"><mi mathsize="144%" id="S2.SS2.p17.2.m2.1.1.2.3.2" xref="S2.SS2.p17.2.m2.1.1.2.3.2.cmml">r</mi><mrow id="S2.SS2.p17.2.m2.1.1.2.3.3" xref="S2.SS2.p17.2.m2.1.1.2.3.3.cmml"><mi mathsize="144%" id="S2.SS2.p17.2.m2.1.1.2.3.3.2" xref="S2.SS2.p17.2.m2.1.1.2.3.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p17.2.m2.1.1.2.3.3.1" xref="S2.SS2.p17.2.m2.1.1.2.3.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.SS2.p17.2.m2.1.1.2.3.3.3" xref="S2.SS2.p17.2.m2.1.1.2.3.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p17.2.m2.1.1.2.3.3.1a" xref="S2.SS2.p17.2.m2.1.1.2.3.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.SS2.p17.2.m2.1.1.2.3.3.4" xref="S2.SS2.p17.2.m2.1.1.2.3.3.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p17.2.m2.1.1.2.3.3.1b" xref="S2.SS2.p17.2.m2.1.1.2.3.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.SS2.p17.2.m2.1.1.2.3.3.5" xref="S2.SS2.p17.2.m2.1.1.2.3.3.5.cmml">e</mi></mrow></msub></msub><mo mathsize="144%" id="S2.SS2.p17.2.m2.1.1.1" xref="S2.SS2.p17.2.m2.1.1.1.cmml">=</mo><mn mathsize="144%" id="S2.SS2.p17.2.m2.1.1.3" xref="S2.SS2.p17.2.m2.1.1.3.cmml">0.1</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p17.2.m2.1b"><apply id="S2.SS2.p17.2.m2.1.1.cmml" xref="S2.SS2.p17.2.m2.1.1"><eq id="S2.SS2.p17.2.m2.1.1.1.cmml" xref="S2.SS2.p17.2.m2.1.1.1"></eq><apply id="S2.SS2.p17.2.m2.1.1.2.cmml" xref="S2.SS2.p17.2.m2.1.1.2"><csymbol cd="ambiguous" id="S2.SS2.p17.2.m2.1.1.2.1.cmml" xref="S2.SS2.p17.2.m2.1.1.2">subscript</csymbol><ci id="S2.SS2.p17.2.m2.1.1.2.2.cmml" xref="S2.SS2.p17.2.m2.1.1.2.2">ğ‘¤</ci><apply id="S2.SS2.p17.2.m2.1.1.2.3.cmml" xref="S2.SS2.p17.2.m2.1.1.2.3"><csymbol cd="ambiguous" id="S2.SS2.p17.2.m2.1.1.2.3.1.cmml" xref="S2.SS2.p17.2.m2.1.1.2.3">subscript</csymbol><ci id="S2.SS2.p17.2.m2.1.1.2.3.2.cmml" xref="S2.SS2.p17.2.m2.1.1.2.3.2">ğ‘Ÿ</ci><apply id="S2.SS2.p17.2.m2.1.1.2.3.3.cmml" xref="S2.SS2.p17.2.m2.1.1.2.3.3"><times id="S2.SS2.p17.2.m2.1.1.2.3.3.1.cmml" xref="S2.SS2.p17.2.m2.1.1.2.3.3.1"></times><ci id="S2.SS2.p17.2.m2.1.1.2.3.3.2.cmml" xref="S2.SS2.p17.2.m2.1.1.2.3.3.2">ğ‘</ci><ci id="S2.SS2.p17.2.m2.1.1.2.3.3.3.cmml" xref="S2.SS2.p17.2.m2.1.1.2.3.3.3">ğ‘’</ci><ci id="S2.SS2.p17.2.m2.1.1.2.3.3.4.cmml" xref="S2.SS2.p17.2.m2.1.1.2.3.3.4">ğ‘›</ci><ci id="S2.SS2.p17.2.m2.1.1.2.3.3.5.cmml" xref="S2.SS2.p17.2.m2.1.1.2.3.3.5">ğ‘’</ci></apply></apply></apply><cn type="float" id="S2.SS2.p17.2.m2.1.1.3.cmml" xref="S2.SS2.p17.2.m2.1.1.3">0.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p17.2.m2.1c">w_{r_{pene}}=0.1</annotation></semantics></math><span id="S2.SS2.p17.2.6" class="ltx_text" style="font-size:144%;">. Penetration detection involves considering the maximum number of body vertices in penetration within a motion primitive. An episode is terminated if:</span></p>
<table id="S2.E11" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E11.m1.2" class="ltx_Math" alttext="\max_{t}\sum_{i=1}^{|V|}|(\Psi_{O}(\mathbf{v}_{ti}))_{-}|\geq thres" display="block"><semantics id="S2.E11.m1.2a"><mrow id="S2.E11.m1.2.2" xref="S2.E11.m1.2.2.cmml"><mrow id="S2.E11.m1.2.2.1" xref="S2.E11.m1.2.2.1.cmml"><munder id="S2.E11.m1.2.2.1.3" xref="S2.E11.m1.2.2.1.3.cmml"><mi mathsize="144%" id="S2.E11.m1.2.2.1.3.2" xref="S2.E11.m1.2.2.1.3.2.cmml">max</mi><mi mathsize="144%" id="S2.E11.m1.2.2.1.3.3" xref="S2.E11.m1.2.2.1.3.3.cmml">t</mi></munder><mo lspace="0em" rspace="0em" id="S2.E11.m1.2.2.1.2" xref="S2.E11.m1.2.2.1.2.cmml">â€‹</mo><mrow id="S2.E11.m1.2.2.1.1" xref="S2.E11.m1.2.2.1.1.cmml"><munderover id="S2.E11.m1.2.2.1.1.2" xref="S2.E11.m1.2.2.1.1.2.cmml"><mo maxsize="144%" minsize="144%" movablelimits="false" rspace="0em" stretchy="true" id="S2.E11.m1.2.2.1.1.2.2.2" xref="S2.E11.m1.2.2.1.1.2.2.2.cmml">âˆ‘</mo><mrow id="S2.E11.m1.2.2.1.1.2.2.3" xref="S2.E11.m1.2.2.1.1.2.2.3.cmml"><mi mathsize="144%" id="S2.E11.m1.2.2.1.1.2.2.3.2" xref="S2.E11.m1.2.2.1.1.2.2.3.2.cmml">i</mi><mo mathsize="144%" id="S2.E11.m1.2.2.1.1.2.2.3.1" xref="S2.E11.m1.2.2.1.1.2.2.3.1.cmml">=</mo><mn mathsize="144%" id="S2.E11.m1.2.2.1.1.2.2.3.3" xref="S2.E11.m1.2.2.1.1.2.2.3.3.cmml">1</mn></mrow><mrow id="S2.E11.m1.1.1.1.3" xref="S2.E11.m1.1.1.1.2.cmml"><mo maxsize="144%" minsize="144%" id="S2.E11.m1.1.1.1.3.1" xref="S2.E11.m1.1.1.1.2.1.cmml">|</mo><mi mathsize="144%" id="S2.E11.m1.1.1.1.1" xref="S2.E11.m1.1.1.1.1.cmml">V</mi><mo maxsize="144%" minsize="144%" id="S2.E11.m1.1.1.1.3.2" xref="S2.E11.m1.1.1.1.2.1.cmml">|</mo></mrow></munderover><mrow id="S2.E11.m1.2.2.1.1.1.1" xref="S2.E11.m1.2.2.1.1.1.2.cmml"><mo maxsize="144%" minsize="144%" id="S2.E11.m1.2.2.1.1.1.1.2" xref="S2.E11.m1.2.2.1.1.1.2.1.cmml">|</mo><msub id="S2.E11.m1.2.2.1.1.1.1.1" xref="S2.E11.m1.2.2.1.1.1.1.1.cmml"><mrow id="S2.E11.m1.2.2.1.1.1.1.1.1.1" xref="S2.E11.m1.2.2.1.1.1.1.1.1.1.1.cmml"><mo maxsize="144%" minsize="144%" id="S2.E11.m1.2.2.1.1.1.1.1.1.1.2" xref="S2.E11.m1.2.2.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.E11.m1.2.2.1.1.1.1.1.1.1.1" xref="S2.E11.m1.2.2.1.1.1.1.1.1.1.1.cmml"><msub id="S2.E11.m1.2.2.1.1.1.1.1.1.1.1.3" xref="S2.E11.m1.2.2.1.1.1.1.1.1.1.1.3.cmml"><mi mathsize="144%" mathvariant="normal" id="S2.E11.m1.2.2.1.1.1.1.1.1.1.1.3.2" xref="S2.E11.m1.2.2.1.1.1.1.1.1.1.1.3.2.cmml">Î¨</mi><mi mathsize="144%" id="S2.E11.m1.2.2.1.1.1.1.1.1.1.1.3.3" xref="S2.E11.m1.2.2.1.1.1.1.1.1.1.1.3.3.cmml">O</mi></msub><mo lspace="0em" rspace="0em" id="S2.E11.m1.2.2.1.1.1.1.1.1.1.1.2" xref="S2.E11.m1.2.2.1.1.1.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S2.E11.m1.2.2.1.1.1.1.1.1.1.1.1.1" xref="S2.E11.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo maxsize="144%" minsize="144%" id="S2.E11.m1.2.2.1.1.1.1.1.1.1.1.1.1.2" xref="S2.E11.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S2.E11.m1.2.2.1.1.1.1.1.1.1.1.1.1.1" xref="S2.E11.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi mathsize="144%" id="S2.E11.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2" xref="S2.E11.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.cmml">ğ¯</mi><mrow id="S2.E11.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3" xref="S2.E11.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.cmml"><mi mathsize="144%" id="S2.E11.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.2" xref="S2.E11.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S2.E11.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.1" xref="S2.E11.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E11.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.3" xref="S2.E11.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml">i</mi></mrow></msub><mo maxsize="144%" minsize="144%" id="S2.E11.m1.2.2.1.1.1.1.1.1.1.1.1.1.3" xref="S2.E11.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo maxsize="144%" minsize="144%" id="S2.E11.m1.2.2.1.1.1.1.1.1.1.3" xref="S2.E11.m1.2.2.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo mathsize="144%" id="S2.E11.m1.2.2.1.1.1.1.1.3" xref="S2.E11.m1.2.2.1.1.1.1.1.3.cmml">âˆ’</mo></msub><mo maxsize="144%" minsize="144%" id="S2.E11.m1.2.2.1.1.1.1.3" xref="S2.E11.m1.2.2.1.1.1.2.1.cmml">|</mo></mrow></mrow></mrow><mo mathsize="144%" id="S2.E11.m1.2.2.2" xref="S2.E11.m1.2.2.2.cmml">â‰¥</mo><mrow id="S2.E11.m1.2.2.3" xref="S2.E11.m1.2.2.3.cmml"><mi mathsize="144%" id="S2.E11.m1.2.2.3.2" xref="S2.E11.m1.2.2.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S2.E11.m1.2.2.3.1" xref="S2.E11.m1.2.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E11.m1.2.2.3.3" xref="S2.E11.m1.2.2.3.3.cmml">h</mi><mo lspace="0em" rspace="0em" id="S2.E11.m1.2.2.3.1a" xref="S2.E11.m1.2.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E11.m1.2.2.3.4" xref="S2.E11.m1.2.2.3.4.cmml">r</mi><mo lspace="0em" rspace="0em" id="S2.E11.m1.2.2.3.1b" xref="S2.E11.m1.2.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E11.m1.2.2.3.5" xref="S2.E11.m1.2.2.3.5.cmml">e</mi><mo lspace="0em" rspace="0em" id="S2.E11.m1.2.2.3.1c" xref="S2.E11.m1.2.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.E11.m1.2.2.3.6" xref="S2.E11.m1.2.2.3.6.cmml">s</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E11.m1.2b"><apply id="S2.E11.m1.2.2.cmml" xref="S2.E11.m1.2.2"><geq id="S2.E11.m1.2.2.2.cmml" xref="S2.E11.m1.2.2.2"></geq><apply id="S2.E11.m1.2.2.1.cmml" xref="S2.E11.m1.2.2.1"><times id="S2.E11.m1.2.2.1.2.cmml" xref="S2.E11.m1.2.2.1.2"></times><apply id="S2.E11.m1.2.2.1.3.cmml" xref="S2.E11.m1.2.2.1.3"><csymbol cd="ambiguous" id="S2.E11.m1.2.2.1.3.1.cmml" xref="S2.E11.m1.2.2.1.3">subscript</csymbol><max id="S2.E11.m1.2.2.1.3.2.cmml" xref="S2.E11.m1.2.2.1.3.2"></max><ci id="S2.E11.m1.2.2.1.3.3.cmml" xref="S2.E11.m1.2.2.1.3.3">ğ‘¡</ci></apply><apply id="S2.E11.m1.2.2.1.1.cmml" xref="S2.E11.m1.2.2.1.1"><apply id="S2.E11.m1.2.2.1.1.2.cmml" xref="S2.E11.m1.2.2.1.1.2"><csymbol cd="ambiguous" id="S2.E11.m1.2.2.1.1.2.1.cmml" xref="S2.E11.m1.2.2.1.1.2">superscript</csymbol><apply id="S2.E11.m1.2.2.1.1.2.2.cmml" xref="S2.E11.m1.2.2.1.1.2"><csymbol cd="ambiguous" id="S2.E11.m1.2.2.1.1.2.2.1.cmml" xref="S2.E11.m1.2.2.1.1.2">subscript</csymbol><sum id="S2.E11.m1.2.2.1.1.2.2.2.cmml" xref="S2.E11.m1.2.2.1.1.2.2.2"></sum><apply id="S2.E11.m1.2.2.1.1.2.2.3.cmml" xref="S2.E11.m1.2.2.1.1.2.2.3"><eq id="S2.E11.m1.2.2.1.1.2.2.3.1.cmml" xref="S2.E11.m1.2.2.1.1.2.2.3.1"></eq><ci id="S2.E11.m1.2.2.1.1.2.2.3.2.cmml" xref="S2.E11.m1.2.2.1.1.2.2.3.2">ğ‘–</ci><cn type="integer" id="S2.E11.m1.2.2.1.1.2.2.3.3.cmml" xref="S2.E11.m1.2.2.1.1.2.2.3.3">1</cn></apply></apply><apply id="S2.E11.m1.1.1.1.2.cmml" xref="S2.E11.m1.1.1.1.3"><abs id="S2.E11.m1.1.1.1.2.1.cmml" xref="S2.E11.m1.1.1.1.3.1"></abs><ci id="S2.E11.m1.1.1.1.1.cmml" xref="S2.E11.m1.1.1.1.1">ğ‘‰</ci></apply></apply><apply id="S2.E11.m1.2.2.1.1.1.2.cmml" xref="S2.E11.m1.2.2.1.1.1.1"><abs id="S2.E11.m1.2.2.1.1.1.2.1.cmml" xref="S2.E11.m1.2.2.1.1.1.1.2"></abs><apply id="S2.E11.m1.2.2.1.1.1.1.1.cmml" xref="S2.E11.m1.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E11.m1.2.2.1.1.1.1.1.2.cmml" xref="S2.E11.m1.2.2.1.1.1.1.1">subscript</csymbol><apply id="S2.E11.m1.2.2.1.1.1.1.1.1.1.1.cmml" xref="S2.E11.m1.2.2.1.1.1.1.1.1.1"><times id="S2.E11.m1.2.2.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E11.m1.2.2.1.1.1.1.1.1.1.1.2"></times><apply id="S2.E11.m1.2.2.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E11.m1.2.2.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E11.m1.2.2.1.1.1.1.1.1.1.1.3.1.cmml" xref="S2.E11.m1.2.2.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S2.E11.m1.2.2.1.1.1.1.1.1.1.1.3.2.cmml" xref="S2.E11.m1.2.2.1.1.1.1.1.1.1.1.3.2">Î¨</ci><ci id="S2.E11.m1.2.2.1.1.1.1.1.1.1.1.3.3.cmml" xref="S2.E11.m1.2.2.1.1.1.1.1.1.1.1.3.3">ğ‘‚</ci></apply><apply id="S2.E11.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E11.m1.2.2.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E11.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E11.m1.2.2.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E11.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E11.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2">ğ¯</ci><apply id="S2.E11.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E11.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3"><times id="S2.E11.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S2.E11.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.1"></times><ci id="S2.E11.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S2.E11.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.2">ğ‘¡</ci><ci id="S2.E11.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S2.E11.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.3">ğ‘–</ci></apply></apply></apply><minus id="S2.E11.m1.2.2.1.1.1.1.1.3.cmml" xref="S2.E11.m1.2.2.1.1.1.1.1.3"></minus></apply></apply></apply></apply><apply id="S2.E11.m1.2.2.3.cmml" xref="S2.E11.m1.2.2.3"><times id="S2.E11.m1.2.2.3.1.cmml" xref="S2.E11.m1.2.2.3.1"></times><ci id="S2.E11.m1.2.2.3.2.cmml" xref="S2.E11.m1.2.2.3.2">ğ‘¡</ci><ci id="S2.E11.m1.2.2.3.3.cmml" xref="S2.E11.m1.2.2.3.3">â„</ci><ci id="S2.E11.m1.2.2.3.4.cmml" xref="S2.E11.m1.2.2.3.4">ğ‘Ÿ</ci><ci id="S2.E11.m1.2.2.3.5.cmml" xref="S2.E11.m1.2.2.3.5">ğ‘’</ci><ci id="S2.E11.m1.2.2.3.6.cmml" xref="S2.E11.m1.2.2.3.6">ğ‘ </ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E11.m1.2c">\max_{t}\sum_{i=1}^{|V|}|(\Psi_{O}(\mathbf{v}_{ti}))_{-}|\geq thres</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(11)</span></td>
</tr></tbody>
</table>
<p id="S2.SS2.p17.3" class="ltx_p"><span id="S2.SS2.p17.3.1" class="ltx_text" style="font-size:144%;">where </span><math id="S2.SS2.p17.3.m1.1" class="ltx_Math" alttext="thres" display="inline"><semantics id="S2.SS2.p17.3.m1.1a"><mrow id="S2.SS2.p17.3.m1.1.1" xref="S2.SS2.p17.3.m1.1.1.cmml"><mi mathsize="144%" id="S2.SS2.p17.3.m1.1.1.2" xref="S2.SS2.p17.3.m1.1.1.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p17.3.m1.1.1.1" xref="S2.SS2.p17.3.m1.1.1.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.SS2.p17.3.m1.1.1.3" xref="S2.SS2.p17.3.m1.1.1.3.cmml">h</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p17.3.m1.1.1.1a" xref="S2.SS2.p17.3.m1.1.1.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.SS2.p17.3.m1.1.1.4" xref="S2.SS2.p17.3.m1.1.1.4.cmml">r</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p17.3.m1.1.1.1b" xref="S2.SS2.p17.3.m1.1.1.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.SS2.p17.3.m1.1.1.5" xref="S2.SS2.p17.3.m1.1.1.5.cmml">e</mi><mo lspace="0em" rspace="0em" id="S2.SS2.p17.3.m1.1.1.1c" xref="S2.SS2.p17.3.m1.1.1.1.cmml">â€‹</mo><mi mathsize="144%" id="S2.SS2.p17.3.m1.1.1.6" xref="S2.SS2.p17.3.m1.1.1.6.cmml">s</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p17.3.m1.1b"><apply id="S2.SS2.p17.3.m1.1.1.cmml" xref="S2.SS2.p17.3.m1.1.1"><times id="S2.SS2.p17.3.m1.1.1.1.cmml" xref="S2.SS2.p17.3.m1.1.1.1"></times><ci id="S2.SS2.p17.3.m1.1.1.2.cmml" xref="S2.SS2.p17.3.m1.1.1.2">ğ‘¡</ci><ci id="S2.SS2.p17.3.m1.1.1.3.cmml" xref="S2.SS2.p17.3.m1.1.1.3">â„</ci><ci id="S2.SS2.p17.3.m1.1.1.4.cmml" xref="S2.SS2.p17.3.m1.1.1.4">ğ‘Ÿ</ci><ci id="S2.SS2.p17.3.m1.1.1.5.cmml" xref="S2.SS2.p17.3.m1.1.1.5">ğ‘’</ci><ci id="S2.SS2.p17.3.m1.1.1.6.cmml" xref="S2.SS2.p17.3.m1.1.1.6">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p17.3.m1.1c">thres</annotation></semantics></math><span id="S2.SS2.p17.3.2" class="ltx_text" style="font-size:144%;"> is set to 40.</span></p>
</div>
<div id="S2.SS2.p18" class="ltx_para">
<p id="S2.SS2.p18.1" class="ltx_p"><span id="S2.SS2.p18.1.1" class="ltx_text" style="font-size:144%;">This design has several reasons: 1) Our action space is an unbounded Gaussian, direct training with strict termination can lead the policy to explore unreasonable spaces and produce unrealistic human poses, seeÂ </span><a href="#S4.F7" title="In No pretraining. â€£ S4.3 Ablation Studies â€£ S4 Experiments â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref" style="font-size:144%;"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">S7</span></a><span id="S2.SS2.p18.1.2" class="ltx_text" style="font-size:144%;"> for illustration. 2) Reducing penetration weight during fine-tuning can amplify the significance of the goal-reaching weight, encouraging goal-reaching behaviors.</span></p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:144%;">
<span class="ltx_tag ltx_tag_subsection">S2.3 </span>PPO</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p"><span id="S2.SS3.p1.1.1" class="ltx_text" style="font-size:144%;">Our PPO implementation is based on TianshouÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.SS3.p1.1.2.1" class="ltx_text" style="font-size:144%;">[</span><a href="#bib.bib112" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">112</span></a><span id="S2.SS3.p1.1.3.2" class="ltx_text" style="font-size:144%;">]</span></cite><span id="S2.SS3.p1.1.4" class="ltx_text" style="font-size:144%;">.
We list the hyperparameters of PPO inÂ </span><a href="#S2.T3" title="In S2.3 PPO â€£ S2 Ego-Sensing Driven Motion Synthesis â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref" style="font-size:144%;"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">S3</span></a><span id="S2.SS3.p1.1.5" class="ltx_text" style="font-size:144%;">. </span><math id="S2.SS3.p1.1.m1.2" class="ltx_Math" alttext="c_{1},c_{2}" display="inline"><semantics id="S2.SS3.p1.1.m1.2a"><mrow id="S2.SS3.p1.1.m1.2.2.2" xref="S2.SS3.p1.1.m1.2.2.3.cmml"><msub id="S2.SS3.p1.1.m1.1.1.1.1" xref="S2.SS3.p1.1.m1.1.1.1.1.cmml"><mi mathsize="144%" id="S2.SS3.p1.1.m1.1.1.1.1.2" xref="S2.SS3.p1.1.m1.1.1.1.1.2.cmml">c</mi><mn mathsize="144%" id="S2.SS3.p1.1.m1.1.1.1.1.3" xref="S2.SS3.p1.1.m1.1.1.1.1.3.cmml">1</mn></msub><mo mathsize="144%" id="S2.SS3.p1.1.m1.2.2.2.3" xref="S2.SS3.p1.1.m1.2.2.3.cmml">,</mo><msub id="S2.SS3.p1.1.m1.2.2.2.2" xref="S2.SS3.p1.1.m1.2.2.2.2.cmml"><mi mathsize="144%" id="S2.SS3.p1.1.m1.2.2.2.2.2" xref="S2.SS3.p1.1.m1.2.2.2.2.2.cmml">c</mi><mn mathsize="144%" id="S2.SS3.p1.1.m1.2.2.2.2.3" xref="S2.SS3.p1.1.m1.2.2.2.2.3.cmml">2</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.1.m1.2b"><list id="S2.SS3.p1.1.m1.2.2.3.cmml" xref="S2.SS3.p1.1.m1.2.2.2"><apply id="S2.SS3.p1.1.m1.1.1.1.1.cmml" xref="S2.SS3.p1.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS3.p1.1.m1.1.1.1.1.1.cmml" xref="S2.SS3.p1.1.m1.1.1.1.1">subscript</csymbol><ci id="S2.SS3.p1.1.m1.1.1.1.1.2.cmml" xref="S2.SS3.p1.1.m1.1.1.1.1.2">ğ‘</ci><cn type="integer" id="S2.SS3.p1.1.m1.1.1.1.1.3.cmml" xref="S2.SS3.p1.1.m1.1.1.1.1.3">1</cn></apply><apply id="S2.SS3.p1.1.m1.2.2.2.2.cmml" xref="S2.SS3.p1.1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S2.SS3.p1.1.m1.2.2.2.2.1.cmml" xref="S2.SS3.p1.1.m1.2.2.2.2">subscript</csymbol><ci id="S2.SS3.p1.1.m1.2.2.2.2.2.cmml" xref="S2.SS3.p1.1.m1.2.2.2.2.2">ğ‘</ci><cn type="integer" id="S2.SS3.p1.1.m1.2.2.2.2.3.cmml" xref="S2.SS3.p1.1.m1.2.2.2.2.3">2</cn></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.1.m1.2c">c_{1},c_{2}</annotation></semantics></math><span id="S2.SS3.p1.1.6" class="ltx_text" style="font-size:144%;"> are defined in </span><a href="#S3.SS2" title="3.2 Training Collision-Avoiding Stochastic Policies â€£ 3 Ego-Sensing Driven Motion Synthesis â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref" style="font-size:144%;"><span class="ltx_text ltx_ref_tag">Sec.</span>Â <span class="ltx_text ltx_ref_tag">3.2</span></a><span id="S2.SS3.p1.1.7" class="ltx_text" style="font-size:144%;">. â€œRepeat per Collectâ€ is the training iterations with the same collected rollouts.</span></p>
</div>
<figure id="S2.T3" class="ltx_table">
<table id="S2.T3.4" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S2.T3.4.5" class="ltx_tr">
<td id="S2.T3.4.5.1" class="ltx_td ltx_align_center ltx_border_ll ltx_border_t" style="padding-bottom:3.09999pt;"><span id="S2.T3.4.5.1.1" class="ltx_text" style="font-size:144%;">Param</span></td>
<td id="S2.T3.4.5.2" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t" style="padding-bottom:3.09999pt;"><span id="S2.T3.4.5.2.1" class="ltx_text" style="font-size:144%;">Value</span></td>
</tr>
<tr id="S2.T3.4.6" class="ltx_tr">
<td id="S2.T3.4.6.1" class="ltx_td ltx_align_center ltx_border_ll ltx_border_tt"><span id="S2.T3.4.6.1.1" class="ltx_text" style="font-size:144%;">Learning Rate</span></td>
<td id="S2.T3.4.6.2" class="ltx_td ltx_align_center ltx_border_rr ltx_border_tt"><span id="S2.T3.4.6.2.1" class="ltx_text" style="font-size:144%;">3e-4</span></td>
</tr>
<tr id="S2.T3.1.1" class="ltx_tr">
<td id="S2.T3.1.1.1" class="ltx_td ltx_align_center ltx_border_ll">
<math id="S2.T3.1.1.1.m1.1" class="ltx_Math" alttext="\gamma" display="inline"><semantics id="S2.T3.1.1.1.m1.1a"><mi mathsize="144%" id="S2.T3.1.1.1.m1.1.1" xref="S2.T3.1.1.1.m1.1.1.cmml">Î³</mi><annotation-xml encoding="MathML-Content" id="S2.T3.1.1.1.m1.1b"><ci id="S2.T3.1.1.1.m1.1.1.cmml" xref="S2.T3.1.1.1.m1.1.1">ğ›¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T3.1.1.1.m1.1c">\gamma</annotation></semantics></math><span id="S2.T3.1.1.1.1" class="ltx_text" style="font-size:144%;"> Discount</span>
</td>
<td id="S2.T3.1.1.2" class="ltx_td ltx_align_center ltx_border_rr"><span id="S2.T3.1.1.2.1" class="ltx_text" style="font-size:144%;">0.99</span></td>
</tr>
<tr id="S2.T3.4.7" class="ltx_tr">
<td id="S2.T3.4.7.1" class="ltx_td ltx_align_center ltx_border_ll"><span id="S2.T3.4.7.1.1" class="ltx_text" style="font-size:144%;">PPO Clip Threshold</span></td>
<td id="S2.T3.4.7.2" class="ltx_td ltx_align_center ltx_border_rr"><span id="S2.T3.4.7.2.1" class="ltx_text" style="font-size:144%;">0.1</span></td>
</tr>
<tr id="S2.T3.4.8" class="ltx_tr">
<td id="S2.T3.4.8.1" class="ltx_td ltx_align_center ltx_border_ll"><span id="S2.T3.4.8.1.1" class="ltx_text" style="font-size:144%;">Repeat per Collect</span></td>
<td id="S2.T3.4.8.2" class="ltx_td ltx_align_center ltx_border_rr"><span id="S2.T3.4.8.2.1" class="ltx_text" style="font-size:144%;">1</span></td>
</tr>
<tr id="S2.T3.2.2" class="ltx_tr">
<td id="S2.T3.2.2.1" class="ltx_td ltx_align_center ltx_border_ll">
<span id="S2.T3.2.2.1.1" class="ltx_text" style="font-size:144%;">Value Function Coefficient (</span><math id="S2.T3.2.2.1.m1.1" class="ltx_Math" alttext="c_{1}" display="inline"><semantics id="S2.T3.2.2.1.m1.1a"><msub id="S2.T3.2.2.1.m1.1.1" xref="S2.T3.2.2.1.m1.1.1.cmml"><mi mathsize="144%" id="S2.T3.2.2.1.m1.1.1.2" xref="S2.T3.2.2.1.m1.1.1.2.cmml">c</mi><mn mathsize="144%" id="S2.T3.2.2.1.m1.1.1.3" xref="S2.T3.2.2.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S2.T3.2.2.1.m1.1b"><apply id="S2.T3.2.2.1.m1.1.1.cmml" xref="S2.T3.2.2.1.m1.1.1"><csymbol cd="ambiguous" id="S2.T3.2.2.1.m1.1.1.1.cmml" xref="S2.T3.2.2.1.m1.1.1">subscript</csymbol><ci id="S2.T3.2.2.1.m1.1.1.2.cmml" xref="S2.T3.2.2.1.m1.1.1.2">ğ‘</ci><cn type="integer" id="S2.T3.2.2.1.m1.1.1.3.cmml" xref="S2.T3.2.2.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T3.2.2.1.m1.1c">c_{1}</annotation></semantics></math><span id="S2.T3.2.2.1.2" class="ltx_text" style="font-size:144%;">)</span>
</td>
<td id="S2.T3.2.2.2" class="ltx_td ltx_align_center ltx_border_rr"><span id="S2.T3.2.2.2.1" class="ltx_text" style="font-size:144%;">1</span></td>
</tr>
<tr id="S2.T3.3.3" class="ltx_tr">
<td id="S2.T3.3.3.1" class="ltx_td ltx_align_center ltx_border_ll">
<span id="S2.T3.3.3.1.1" class="ltx_text" style="font-size:144%;">Entropy Coefficient (</span><math id="S2.T3.3.3.1.m1.1" class="ltx_Math" alttext="c_{2}" display="inline"><semantics id="S2.T3.3.3.1.m1.1a"><msub id="S2.T3.3.3.1.m1.1.1" xref="S2.T3.3.3.1.m1.1.1.cmml"><mi mathsize="144%" id="S2.T3.3.3.1.m1.1.1.2" xref="S2.T3.3.3.1.m1.1.1.2.cmml">c</mi><mn mathsize="144%" id="S2.T3.3.3.1.m1.1.1.3" xref="S2.T3.3.3.1.m1.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S2.T3.3.3.1.m1.1b"><apply id="S2.T3.3.3.1.m1.1.1.cmml" xref="S2.T3.3.3.1.m1.1.1"><csymbol cd="ambiguous" id="S2.T3.3.3.1.m1.1.1.1.cmml" xref="S2.T3.3.3.1.m1.1.1">subscript</csymbol><ci id="S2.T3.3.3.1.m1.1.1.2.cmml" xref="S2.T3.3.3.1.m1.1.1.2">ğ‘</ci><cn type="integer" id="S2.T3.3.3.1.m1.1.1.3.cmml" xref="S2.T3.3.3.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T3.3.3.1.m1.1c">c_{2}</annotation></semantics></math><span id="S2.T3.3.3.1.2" class="ltx_text" style="font-size:144%;">)</span>
</td>
<td id="S2.T3.3.3.2" class="ltx_td ltx_align_center ltx_border_rr"><span id="S2.T3.3.3.2.1" class="ltx_text" style="font-size:144%;">0.01</span></td>
</tr>
<tr id="S2.T3.4.4" class="ltx_tr">
<td id="S2.T3.4.4.1" class="ltx_td ltx_align_center ltx_border_ll">
<span id="S2.T3.4.4.1.1" class="ltx_text" style="font-size:144%;">GAE (</span><math id="S2.T3.4.4.1.m1.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S2.T3.4.4.1.m1.1a"><mi mathsize="144%" id="S2.T3.4.4.1.m1.1.1" xref="S2.T3.4.4.1.m1.1.1.cmml">Î»</mi><annotation-xml encoding="MathML-Content" id="S2.T3.4.4.1.m1.1b"><ci id="S2.T3.4.4.1.m1.1.1.cmml" xref="S2.T3.4.4.1.m1.1.1">ğœ†</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T3.4.4.1.m1.1c">\lambda</annotation></semantics></math><span id="S2.T3.4.4.1.2" class="ltx_text" style="font-size:144%;">)</span>
</td>
<td id="S2.T3.4.4.2" class="ltx_td ltx_align_center ltx_border_rr"><span id="S2.T3.4.4.2.1" class="ltx_text" style="font-size:144%;">0.95</span></td>
</tr>
<tr id="S2.T3.4.9" class="ltx_tr">
<td id="S2.T3.4.9.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_ll"><span id="S2.T3.4.9.1.1" class="ltx_text" style="font-size:144%;">Max Grad. Norm</span></td>
<td id="S2.T3.4.9.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_rr"><span id="S2.T3.4.9.2.1" class="ltx_text" style="font-size:144%;">0.1</span></td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:144%;"><span class="ltx_tag ltx_tag_table"><span id="S2.T3.8.1.1" class="ltx_text" style="font-size:63%;">Table S3</span>: </span><span id="S2.T3.9.2" class="ltx_text" style="font-size:63%;">PPO hyperparameters.</span></figcaption>
</figure>
<div id="S2.SS3.p2" class="ltx_para">
<p id="S2.SS3.p2.1" class="ltx_p"><span id="S2.SS3.p2.1.1" class="ltx_text" style="font-size:144%;">The majority of the hyperparameters were set to their default values. To note, adopting smaller values of â€œPPO Clip Thresholdâ€ and â€œRepeat per Collectâ€ will not update parameters too drastically and thus stabilize the training.
We use advantage normalization without value function clipping.</span></p>
</div>
<div id="S2.SS3.p3" class="ltx_para">
<p id="S2.SS3.p3.1" class="ltx_p"><span id="S2.SS3.p3.1.1" class="ltx_text" style="font-size:144%;">Another trick we adopted is that we performed the last policy layer weight scaling, which makes initial actions close to the standard normal distribution, which can boost the performance </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.SS3.p3.1.2.1" class="ltx_text" style="font-size:144%;">[</span><a href="#bib.bib6" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">6</span></a><span id="S2.SS3.p3.1.3.2" class="ltx_text" style="font-size:144%;">]</span></cite><span id="S2.SS3.p3.1.4" class="ltx_text" style="font-size:144%;">.</span></p>
</div>
<div id="S2.SS3.p4" class="ltx_para">
<p id="S2.SS3.p4.1" class="ltx_p"><span id="S2.SS3.p4.1.1" class="ltx_text" style="font-size:144%;">The training time is roughly 20 hours on a GeForce RTX 3090 GPU with batch size 256, 20000 steps per epoch.</span></p>
</div>
<div id="S2.SS3.p5" class="ltx_para">
<p id="S2.SS3.p5.1" class="ltx_p"><span id="S2.SS3.p5.1.1" class="ltx_text" style="font-size:144%;">The key difference between our environment with others is that our action space is not strictly bounded. The motion primitive model </span><math id="S2.SS3.p5.1.m1.1" class="ltx_Math" alttext="\mathcal{P}" display="inline"><semantics id="S2.SS3.p5.1.m1.1a"><mi class="ltx_font_mathcaligraphic" mathsize="144%" id="S2.SS3.p5.1.m1.1.1" xref="S2.SS3.p5.1.m1.1.1.cmml">ğ’«</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p5.1.m1.1b"><ci id="S2.SS3.p5.1.m1.1.1.cmml" xref="S2.SS3.p5.1.m1.1.1">ğ’«</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p5.1.m1.1c">\mathcal{P}</annotation></semantics></math><span id="S2.SS3.p5.1.2" class="ltx_text" style="font-size:144%;"> is based on VAE and is pretrained with a KLD loss w.r.t. a standard normal distribution. As a result, we do not do any action scaling or clipping during training.
Due to the nature of our action space, the learned policy can deviate too much from the standard normal distribution.
As a result, we select the best model using the best test reward and minimum KL divergence between the learned policy action space and the standard normal distribution.</span></p>
</div>
</section>
</section>
<section id="S3a" class="ltx_section ltx_centering">
<h2 class="ltx_title ltx_title_section" style="font-size:144%;">
<span class="ltx_tag ltx_tag_section">S3 </span>Egocentric Synthetic Data Generation</h2>

<section id="S3.SS1a" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:144%;">
<span class="ltx_tag ltx_tag_subsection">S3.1 </span>Embodied Camera Placement</h3>

<div id="S3.SS1a.p1" class="ltx_para">
<p id="S3.SS1a.p1.1" class="ltx_p"><span id="S3.SS1a.p1.1.1" class="ltx_text" style="font-size:144%;">We support various camera placements in </span><span id="S3.SS1a.p1.1.2" class="ltx_text ltx_font_italic" style="font-size:144%;">EgoGen</span><span id="S3.SS1a.p1.1.3" class="ltx_text" style="font-size:144%;">.</span></p>
</div>
<div id="S3.SS1a.p2" class="ltx_para">
<p id="S3.SS1a.p2.2" class="ltx_p"><span id="S3.SS1a.p2.2.1" class="ltx_text" style="font-size:144%;">For egocentric sensing-driven motion synthesis (</span><a href="#S3" title="3 Ego-Sensing Driven Motion Synthesis â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref" style="font-size:144%;"><span class="ltx_text ltx_ref_tag">Sec.</span>Â <span class="ltx_text ltx_ref_tag">3</span></a><span id="S3.SS1a.p2.2.2" class="ltx_text" style="font-size:144%;">), we place one camera at the midpoint of two eyeballs and the viewing direction </span><math id="S3.SS1a.p2.1.m1.1" class="ltx_Math" alttext="\vv{\mathbf{v}}" display="inline"><semantics id="S3.SS1a.p2.1.m1.1a"><mrow id="S3.SS1a.p2.1.m1.1.1" xref="S3.SS1a.p2.1.m1.1.1.cmml"><merror class="ltx_ERROR undefined undefined" id="S3.SS1a.p2.1.m1.1.1.2" xref="S3.SS1a.p2.1.m1.1.1.2b.cmml"><mtext id="S3.SS1a.p2.1.m1.1.1.2a" xref="S3.SS1a.p2.1.m1.1.1.2b.cmml">\vv</mtext></merror><mo lspace="0em" rspace="0em" id="S3.SS1a.p2.1.m1.1.1.1" xref="S3.SS1a.p2.1.m1.1.1.1.cmml">â€‹</mo><mi mathsize="144%" id="S3.SS1a.p2.1.m1.1.1.3" xref="S3.SS1a.p2.1.m1.1.1.3.cmml">ğ¯</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1a.p2.1.m1.1b"><apply id="S3.SS1a.p2.1.m1.1.1.cmml" xref="S3.SS1a.p2.1.m1.1.1"><times id="S3.SS1a.p2.1.m1.1.1.1.cmml" xref="S3.SS1a.p2.1.m1.1.1.1"></times><ci id="S3.SS1a.p2.1.m1.1.1.2b.cmml" xref="S3.SS1a.p2.1.m1.1.1.2"><merror class="ltx_ERROR undefined undefined" id="S3.SS1a.p2.1.m1.1.1.2.cmml" xref="S3.SS1a.p2.1.m1.1.1.2"><mtext id="S3.SS1a.p2.1.m1.1.1.2a.cmml" xref="S3.SS1a.p2.1.m1.1.1.2">\vv</mtext></merror></ci><ci id="S3.SS1a.p2.1.m1.1.1.3.cmml" xref="S3.SS1a.p2.1.m1.1.1.3">ğ¯</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1a.p2.1.m1.1c">\vv{\mathbf{v}}</annotation></semantics></math><span id="S3.SS1a.p2.2.3" class="ltx_text" style="font-size:144%;"> is shown inÂ </span><a href="#S3.F3" title="In S3.1 Embodied Camera Placement â€£ S3 Egocentric Synthetic Data Generation â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref" style="font-size:144%;"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">S3</span></a><span id="S3.SS1a.p2.2.4" class="ltx_text" style="font-size:144%;">. We use the SMPL-XÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.SS1a.p2.2.5.1" class="ltx_text" style="font-size:144%;">[</span><a href="#bib.bib67" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">67</span></a><span id="S3.SS1a.p2.2.6.2" class="ltx_text" style="font-size:144%;">]</span></cite><span id="S3.SS1a.p2.2.7" class="ltx_text" style="font-size:144%;"> armature in BlenderÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.SS1a.p2.2.8.1" class="ltx_text" style="font-size:144%;">[</span><a href="#bib.bib13" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">13</span></a><span id="S3.SS1a.p2.2.9.2" class="ltx_text" style="font-size:144%;">]</span></cite><span id="S3.SS1a.p2.2.10" class="ltx_text" style="font-size:144%;"> to calculate </span><math id="S3.SS1a.p2.2.m2.1" class="ltx_Math" alttext="\vv{\mathbf{v}}" display="inline"><semantics id="S3.SS1a.p2.2.m2.1a"><mrow id="S3.SS1a.p2.2.m2.1.1" xref="S3.SS1a.p2.2.m2.1.1.cmml"><merror class="ltx_ERROR undefined undefined" id="S3.SS1a.p2.2.m2.1.1.2" xref="S3.SS1a.p2.2.m2.1.1.2b.cmml"><mtext id="S3.SS1a.p2.2.m2.1.1.2a" xref="S3.SS1a.p2.2.m2.1.1.2b.cmml">\vv</mtext></merror><mo lspace="0em" rspace="0em" id="S3.SS1a.p2.2.m2.1.1.1" xref="S3.SS1a.p2.2.m2.1.1.1.cmml">â€‹</mo><mi mathsize="144%" id="S3.SS1a.p2.2.m2.1.1.3" xref="S3.SS1a.p2.2.m2.1.1.3.cmml">ğ¯</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1a.p2.2.m2.1b"><apply id="S3.SS1a.p2.2.m2.1.1.cmml" xref="S3.SS1a.p2.2.m2.1.1"><times id="S3.SS1a.p2.2.m2.1.1.1.cmml" xref="S3.SS1a.p2.2.m2.1.1.1"></times><ci id="S3.SS1a.p2.2.m2.1.1.2b.cmml" xref="S3.SS1a.p2.2.m2.1.1.2"><merror class="ltx_ERROR undefined undefined" id="S3.SS1a.p2.2.m2.1.1.2.cmml" xref="S3.SS1a.p2.2.m2.1.1.2"><mtext id="S3.SS1a.p2.2.m2.1.1.2a.cmml" xref="S3.SS1a.p2.2.m2.1.1.2">\vv</mtext></merror></ci><ci id="S3.SS1a.p2.2.m2.1.1.3.cmml" xref="S3.SS1a.p2.2.m2.1.1.3">ğ¯</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1a.p2.2.m2.1c">\vv{\mathbf{v}}</annotation></semantics></math><span id="S3.SS1a.p2.2.11" class="ltx_text" style="font-size:144%;">. The two eye bones are visualized inÂ </span><a href="#S3.F2a" title="In S3.1 Embodied Camera Placement â€£ S3 Egocentric Synthetic Data Generation â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref" style="font-size:144%;"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">S2</span></a><span id="S3.SS1a.p2.2.12" class="ltx_text" style="font-size:144%;">.</span></p>
</div>
<figure id="S3.F2a" class="ltx_figure"><img src="/html/2401.08739/assets/images/eyebone.jpg" id="S3.F2a.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="269" height="188" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering" style="font-size:144%;"><span class="ltx_tag ltx_tag_figure"><span id="S3.F2a.4.1.1" class="ltx_text" style="font-size:63%;">Figure S2</span>: </span><span id="S3.F2a.5.2" class="ltx_text" style="font-size:63%;">
Eye bones are located at the eyes and are highlighted with orange edges.
</span></figcaption>
</figure>
<figure id="S3.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2401.08739/assets/images/cam_fig1.png" id="S3.F3.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_portrait" width="281" height="407" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2401.08739/assets/images/cam_fig2.png" id="S3.F3.g2" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_portrait" width="284" height="407" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
</div>
<figcaption class="ltx_caption ltx_centering" style="font-size:144%;"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.19.2.1" class="ltx_text" style="font-size:63%;">Figure S3</span>: </span><span id="S3.F3.2.1" class="ltx_text" style="font-size:63%;">
Illustration of embodied camera placement. The camera axes are determined by 1) The <span id="S3.F3.2.1.1" class="ltx_text" style="color:#0000FF;">blue</span> arrow of the eye bone (from <span id="S3.F3.2.1.2" class="ltx_text ltx_font_italic">root</span> to <span id="S3.F3.2.1.3" class="ltx_text ltx_font_italic">tip</span>); 2) The <span id="S3.F3.2.1.4" class="ltx_text" style="color:#00FF00;">green</span> arrow from one eyeball to another; 3) The <span id="S3.F3.2.1.5" class="ltx_text" style="color:#FF0000;">red</span> arrow representing the viewing direction <math id="S3.F3.2.1.m1.1" class="ltx_Math" alttext="\vv{\mathbf{v}}" display="inline"><semantics id="S3.F3.2.1.m1.1b"><mrow id="S3.F3.2.1.m1.1.1" xref="S3.F3.2.1.m1.1.1.cmml"><merror class="ltx_ERROR undefined undefined" id="S3.F3.2.1.m1.1.1.2" xref="S3.F3.2.1.m1.1.1.2b.cmml"><mtext id="S3.F3.2.1.m1.1.1.2b" xref="S3.F3.2.1.m1.1.1.2b.cmml">\vv</mtext></merror><mo lspace="0em" rspace="0em" id="S3.F3.2.1.m1.1.1.1" xref="S3.F3.2.1.m1.1.1.1.cmml">â€‹</mo><mi id="S3.F3.2.1.m1.1.1.3" xref="S3.F3.2.1.m1.1.1.3.cmml">ğ¯</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.F3.2.1.m1.1c"><apply id="S3.F3.2.1.m1.1.1.cmml" xref="S3.F3.2.1.m1.1.1"><times id="S3.F3.2.1.m1.1.1.1.cmml" xref="S3.F3.2.1.m1.1.1.1"></times><ci id="S3.F3.2.1.m1.1.1.2b.cmml" xref="S3.F3.2.1.m1.1.1.2"><merror class="ltx_ERROR undefined undefined" id="S3.F3.2.1.m1.1.1.2.cmml" xref="S3.F3.2.1.m1.1.1.2"><mtext id="S3.F3.2.1.m1.1.1.2a.cmml" xref="S3.F3.2.1.m1.1.1.2">\vv</mtext></merror></ci><ci id="S3.F3.2.1.m1.1.1.3.cmml" xref="S3.F3.2.1.m1.1.1.3">ğ¯</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.2.1.m1.1d">\vv{\mathbf{v}}</annotation></semantics></math>. (<a href="#S2.SS1" title="S2.1 Egocentric Sensing Calculation â€£ S2 Ego-Sensing Driven Motion Synthesis â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Sec.</span>Â <span class="ltx_text ltx_ref_tag">S2.1</span></a>, <a href="#S3.SS1a" title="S3.1 Embodied Camera Placement â€£ S3 Egocentric Synthetic Data Generation â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Sec.</span>Â <span class="ltx_text ltx_ref_tag">S3.1</span></a>)</span></figcaption>
</figure>
<div id="S3.SS1a.p3" class="ltx_para">
<p id="S3.SS1a.p3.1" class="ltx_p"><span id="S3.SS1a.p3.1.1" class="ltx_text ltx_font_italic" style="font-size:144%;">EgoGen</span><span id="S3.SS1a.p3.1.2" class="ltx_text" style="font-size:144%;">Â also supports multi-camera rigs simulation. With the information about the relative poses of cameras within a rig, we have the flexibility to position the camera at various locations on the head.</span></p>
</div>
</section>
<section id="S3.SS2a" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:144%;">
<span class="ltx_tag ltx_tag_subsection">S3.2 </span>Automated Clothing Simulation</h3>

<div id="S3.SS2a.p1" class="ltx_para">
<p id="S3.SS2a.p1.1" class="ltx_p"><span id="S3.SS2a.p1.1.1" class="ltx_text" style="font-size:144%;">As shown inÂ </span><a href="#S1.T1" title="In S1 Related Work â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref" style="font-size:144%;"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">S1</span></a><span id="S3.SS2a.p1.1.2" class="ltx_text" style="font-size:144%;">, many prior works resort to generating synthetic data with rigged clothing, with unrealistic clothing deformations. In contrast, BEDLAMÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.SS2a.p1.1.3.1" class="ltx_text" style="font-size:144%;">[</span><a href="#bib.bib9" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">9</span></a><span id="S3.SS2a.p1.1.4.2" class="ltx_text" style="font-size:144%;">]</span></cite><span id="S3.SS2a.p1.1.5" class="ltx_text" style="font-size:144%;"> and SynbodyÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.SS2a.p1.1.6.1" class="ltx_text" style="font-size:144%;">[</span><a href="#bib.bib119" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">119</span></a><span id="S3.SS2a.p1.1.7.2" class="ltx_text" style="font-size:144%;">]</span></cite><span id="S3.SS2a.p1.1.8" class="ltx_text" style="font-size:144%;"> incorporate physics-based clothing simulation to enhance realism and allow for dressing a diverse range of body shapes in a wide array of clothing. However, their approaches are not scalable for handling arbitrary motion sequences produced by our generative human motion model.</span></p>
</div>
<div id="S3.SS2a.p2" class="ltx_para">
<p id="S3.SS2a.p2.1" class="ltx_p"><span id="S3.SS2a.p2.1.1" class="ltx_text" style="font-size:144%;">We further automate clothing dynamics simulation with the state-of-the-art clothing simulation network HOODÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.SS2a.p2.1.2.1" class="ltx_text" style="font-size:144%;">[</span><a href="#bib.bib28" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">28</span></a><span id="S3.SS2a.p2.1.3.2" class="ltx_text" style="font-size:144%;">]</span></cite><span id="S3.SS2a.p2.1.4" class="ltx_text" style="font-size:144%;">. HOOD treats each garment as a single graph and predicts graph deformations due to both gravity and collisions with the human body mesh.</span></p>
</div>
<div id="S3.SS2a.p3" class="ltx_para">
<p id="S3.SS2a.p3.3" class="ltx_p"><span id="S3.SS2a.p3.3.1" class="ltx_text" style="font-size:144%;">First, we perform preprocessing on the 3D clothing mesh fromÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S3.SS2a.p3.3.2.1" class="ltx_text" style="font-size:144%;">[</span><a href="#bib.bib9" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">9</span></a><span id="S3.SS2a.p3.3.3.2" class="ltx_text" style="font-size:144%;">]</span></cite><span id="S3.SS2a.p3.3.4" class="ltx_text" style="font-size:144%;"> to separate the upper garment and lower garment into distinct clothing meshes because HOOD can not handle disconnected graphs as input.
Second, we sample pose blend shapes, shape blend shapes, and average skinning weights from the closest </span><math id="S3.SS2a.p3.1.m1.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S3.SS2a.p3.1.m1.1a"><mi mathsize="144%" id="S3.SS2a.p3.1.m1.1.1" xref="S3.SS2a.p3.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS2a.p3.1.m1.1b"><ci id="S3.SS2a.p3.1.m1.1.1.cmml" xref="S3.SS2a.p3.1.m1.1.1">ğ‘›</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2a.p3.1.m1.1c">n</annotation></semantics></math><span id="S3.SS2a.p3.3.5" class="ltx_text" style="font-size:144%;"> SMPL-X mesh vertices in A-Pose, where </span><math id="S3.SS2a.p3.2.m2.1" class="ltx_Math" alttext="n=1" display="inline"><semantics id="S3.SS2a.p3.2.m2.1a"><mrow id="S3.SS2a.p3.2.m2.1.1" xref="S3.SS2a.p3.2.m2.1.1.cmml"><mi mathsize="144%" id="S3.SS2a.p3.2.m2.1.1.2" xref="S3.SS2a.p3.2.m2.1.1.2.cmml">n</mi><mo mathsize="144%" id="S3.SS2a.p3.2.m2.1.1.1" xref="S3.SS2a.p3.2.m2.1.1.1.cmml">=</mo><mn mathsize="144%" id="S3.SS2a.p3.2.m2.1.1.3" xref="S3.SS2a.p3.2.m2.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2a.p3.2.m2.1b"><apply id="S3.SS2a.p3.2.m2.1.1.cmml" xref="S3.SS2a.p3.2.m2.1.1"><eq id="S3.SS2a.p3.2.m2.1.1.1.cmml" xref="S3.SS2a.p3.2.m2.1.1.1"></eq><ci id="S3.SS2a.p3.2.m2.1.1.2.cmml" xref="S3.SS2a.p3.2.m2.1.1.2">ğ‘›</ci><cn type="integer" id="S3.SS2a.p3.2.m2.1.1.3.cmml" xref="S3.SS2a.p3.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2a.p3.2.m2.1c">n=1</annotation></semantics></math><span id="S3.SS2a.p3.3.6" class="ltx_text" style="font-size:144%;"> for tight garments such as pants and </span><math id="S3.SS2a.p3.3.m3.1" class="ltx_Math" alttext="n=1000" display="inline"><semantics id="S3.SS2a.p3.3.m3.1a"><mrow id="S3.SS2a.p3.3.m3.1.1" xref="S3.SS2a.p3.3.m3.1.1.cmml"><mi mathsize="144%" id="S3.SS2a.p3.3.m3.1.1.2" xref="S3.SS2a.p3.3.m3.1.1.2.cmml">n</mi><mo mathsize="144%" id="S3.SS2a.p3.3.m3.1.1.1" xref="S3.SS2a.p3.3.m3.1.1.1.cmml">=</mo><mn mathsize="144%" id="S3.SS2a.p3.3.m3.1.1.3" xref="S3.SS2a.p3.3.m3.1.1.3.cmml">1000</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2a.p3.3.m3.1b"><apply id="S3.SS2a.p3.3.m3.1.1.cmml" xref="S3.SS2a.p3.3.m3.1.1"><eq id="S3.SS2a.p3.3.m3.1.1.1.cmml" xref="S3.SS2a.p3.3.m3.1.1.1"></eq><ci id="S3.SS2a.p3.3.m3.1.1.2.cmml" xref="S3.SS2a.p3.3.m3.1.1.2">ğ‘›</ci><cn type="integer" id="S3.SS2a.p3.3.m3.1.1.3.cmml" xref="S3.SS2a.p3.3.m3.1.1.3">1000</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2a.p3.3.m3.1c">n=1000</annotation></semantics></math><span id="S3.SS2a.p3.3.7" class="ltx_text" style="font-size:144%;"> for loose garments such as dresses. We repose the clothing meshes in A-Pose to match the body pose in the first frame of a synthesized motion sequence. Then, for lower garments, the vertices in the top ring are fixed to the body to prevent dropping due to gravity. Finally, we simulate the upper and lower garments separately using HOOD.</span></p>
</div>
</section>
<section id="S3.SS3a" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:144%;">
<span class="ltx_tag ltx_tag_subsection">S3.3 </span>More Examples of Available Annotations</h3>

<div id="S3.SS3a.p1" class="ltx_para">
<p id="S3.SS3a.p1.1" class="ltx_p"><span id="S3.SS3a.p1.1.1" class="ltx_text" style="font-size:144%;">In addition to the fisheye cameras shown in the teaser, here we show more ground-truth annotations with perspective cameras, including RGBD, optical flow, bounding boxes, segmentation masks, and surface normals inÂ </span><a href="#S3.F4" title="In S3.3 More Examples of Available Annotations â€£ S3 Egocentric Synthetic Data Generation â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref" style="font-size:144%;"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">S4</span></a><span id="S3.SS3a.p1.1.2" class="ltx_text" style="font-size:144%;">.</span></p>
</div>
<figure id="S3.F4" class="ltx_figure"><img src="/html/2401.08739/assets/x4.png" id="S3.F4.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="461" height="772" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering" style="font-size:144%;"><span class="ltx_tag ltx_tag_figure"><span id="S3.F4.4.1.1" class="ltx_text" style="font-size:63%;">Figure S4</span>: </span><span id="S3.F4.5.2" class="ltx_text" style="font-size:63%;">Ground-truth annotations from perspective cameras.
</span></figcaption>
</figure>
</section>
</section>
<section id="S4a" class="ltx_section ltx_centering">
<h2 class="ltx_title ltx_title_section" style="font-size:144%;">
<span class="ltx_tag ltx_tag_section">S4 </span>Experiments</h2>

<section id="S4.SS1a" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:144%;">
<span class="ltx_tag ltx_tag_subsection">S4.1 </span>Test Scenarios in Evaluation of CAMPs</h3>

<div id="S4.SS1a.p1" class="ltx_para">
<p id="S4.SS1a.p1.1" class="ltx_p"><span id="S4.SS1a.p1.1.1" class="ltx_text" style="font-size:144%;">We provide visualizations of how we built test scenarios. Please refer to Sup. Vid. for qualitative results.</span></p>
</div>
<section id="S4.SS1.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph" style="font-size:144%;">Moving obstacle.</h4>

<div id="S4.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px1.p1.1" class="ltx_p"><span id="S4.SS1.SSS0.Px1.p1.1.1" class="ltx_text" style="font-size:144%;">Refer toÂ </span><a href="#S4.F5" title="In Moving obstacle. â€£ S4.1 Test Scenarios in Evaluation of CAMPs â€£ S4 Experiments â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref" style="font-size:144%;"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">S5</span></a><span id="S4.SS1.SSS0.Px1.p1.1.2" class="ltx_text" style="font-size:144%;"> for an illustration of the evaluation in scenes with moving obstacle. The moving obstacle will move between the human and its goal location.</span></p>
</div>
<figure id="S4.F5" class="ltx_figure"><img src="/html/2401.08739/assets/images/moving.png" id="S4.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="538" height="379" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering" style="font-size:144%;"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.4.1.1" class="ltx_text" style="font-size:63%;">Figure S5</span>: </span><span id="S4.F5.5.2" class="ltx_text" style="font-size:63%;">Moving obstacle test scenario illustration.
</span></figcaption>
</figure>
</section>
<section id="S4.SS1.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph" style="font-size:144%;">Multiple humans.</h4>

<div id="S4.SS1.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px2.p1.1" class="ltx_p"><span id="S4.SS1.SSS0.Px2.p1.1.1" class="ltx_text" style="font-size:144%;">To visually demonstrate, as depicted in </span><a href="#S4.F6" title="In Multiple humans. â€£ S4.1 Test Scenarios in Evaluation of CAMPs â€£ S4 Experiments â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref" style="font-size:144%;"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">S6</span></a><span id="S4.SS1.SSS0.Px2.p1.1.2" class="ltx_text" style="font-size:144%;">, we initiate four virtual humans from distinct points in the figure. We require they walk to the opposite location across the origin, either from A to B or from B to A. There are no other obstacles. Please refer to Sup. Vid. for qualitative results.</span></p>
</div>
<figure id="S4.F6" class="ltx_figure"><img src="/html/2401.08739/assets/images/aaaa.png" id="S4.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="538" height="404" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering" style="font-size:144%;"><span class="ltx_tag ltx_tag_figure"><span id="S4.F6.4.1.1" class="ltx_text" style="font-size:63%;">Figure S6</span>: </span><span id="S4.F6.5.2" class="ltx_text" style="font-size:63%;">Multiple humans crowd motion test scenario illustration.
</span></figcaption>
</figure>
</section>
<section id="S4.SS1.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph" style="font-size:144%;">Path diversity.</h4>

<div id="S4.SS1.SSS0.Px3.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px3.p1.1" class="ltx_p"><span id="S4.SS1.SSS0.Px3.p1.1.1" class="ltx_text" style="font-size:144%;">We assess walking path diversity with a static obstacle fixed at the midpoint between the start and target locations. Similar toÂ </span><a href="#S4.F5" title="In Moving obstacle. â€£ S4.1 Test Scenarios in Evaluation of CAMPs â€£ S4 Experiments â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref" style="font-size:144%;"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">S5</span></a><span id="S4.SS1.SSS0.Px3.p1.1.2" class="ltx_text" style="font-size:144%;">, but the obstacle is not moving anymore.</span></p>
</div>
</section>
</section>
<section id="S4.SS2a" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:144%;">
<span class="ltx_tag ltx_tag_subsection">S4.2 </span>Evaluation Metrics</h3>

<div id="S4.SS2a.p1" class="ltx_para">
<p id="S4.SS2a.p1.4" class="ltx_p"><span id="S4.SS2a.p1.4.1" class="ltx_text" style="font-size:144%;">The Foot contact metric </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS2a.p1.4.2.1" class="ltx_text" style="font-size:144%;">[</span><a href="#bib.bib127" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">127</span></a><span id="S4.SS2a.p1.4.3.2" class="ltx_text" style="font-size:144%;">]</span></cite><span id="S4.SS2a.p1.4.4" class="ltx_text" style="font-size:144%;"> reaches 1 when there is foot-floor contact and no foot skating, defined as:</span></p>
<table id="S4.E12" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E12.m1.3" class="ltx_Math" alttext="s_{contact}=e^{-(|\min x_{z}|-0.05)_{+}}\cdot e^{-(\min\|x_{vel}\|_{2}-0.075)_{+}}," display="block"><semantics id="S4.E12.m1.3a"><mrow id="S4.E12.m1.3.3.1" xref="S4.E12.m1.3.3.1.1.cmml"><mrow id="S4.E12.m1.3.3.1.1" xref="S4.E12.m1.3.3.1.1.cmml"><msub id="S4.E12.m1.3.3.1.1.2" xref="S4.E12.m1.3.3.1.1.2.cmml"><mi mathsize="144%" id="S4.E12.m1.3.3.1.1.2.2" xref="S4.E12.m1.3.3.1.1.2.2.cmml">s</mi><mrow id="S4.E12.m1.3.3.1.1.2.3" xref="S4.E12.m1.3.3.1.1.2.3.cmml"><mi mathsize="144%" id="S4.E12.m1.3.3.1.1.2.3.2" xref="S4.E12.m1.3.3.1.1.2.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.E12.m1.3.3.1.1.2.3.1" xref="S4.E12.m1.3.3.1.1.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S4.E12.m1.3.3.1.1.2.3.3" xref="S4.E12.m1.3.3.1.1.2.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S4.E12.m1.3.3.1.1.2.3.1a" xref="S4.E12.m1.3.3.1.1.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S4.E12.m1.3.3.1.1.2.3.4" xref="S4.E12.m1.3.3.1.1.2.3.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="S4.E12.m1.3.3.1.1.2.3.1b" xref="S4.E12.m1.3.3.1.1.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S4.E12.m1.3.3.1.1.2.3.5" xref="S4.E12.m1.3.3.1.1.2.3.5.cmml">t</mi><mo lspace="0em" rspace="0em" id="S4.E12.m1.3.3.1.1.2.3.1c" xref="S4.E12.m1.3.3.1.1.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S4.E12.m1.3.3.1.1.2.3.6" xref="S4.E12.m1.3.3.1.1.2.3.6.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.E12.m1.3.3.1.1.2.3.1d" xref="S4.E12.m1.3.3.1.1.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S4.E12.m1.3.3.1.1.2.3.7" xref="S4.E12.m1.3.3.1.1.2.3.7.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.E12.m1.3.3.1.1.2.3.1e" xref="S4.E12.m1.3.3.1.1.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S4.E12.m1.3.3.1.1.2.3.8" xref="S4.E12.m1.3.3.1.1.2.3.8.cmml">t</mi></mrow></msub><mo mathsize="144%" id="S4.E12.m1.3.3.1.1.1" xref="S4.E12.m1.3.3.1.1.1.cmml">=</mo><mrow id="S4.E12.m1.3.3.1.1.3" xref="S4.E12.m1.3.3.1.1.3.cmml"><msup id="S4.E12.m1.3.3.1.1.3.2" xref="S4.E12.m1.3.3.1.1.3.2.cmml"><mi mathsize="144%" id="S4.E12.m1.3.3.1.1.3.2.2" xref="S4.E12.m1.3.3.1.1.3.2.2.cmml">e</mi><mrow id="S4.E12.m1.1.1.1" xref="S4.E12.m1.1.1.1.cmml"><mo mathsize="144%" id="S4.E12.m1.1.1.1a" xref="S4.E12.m1.1.1.1.cmml">âˆ’</mo><msub id="S4.E12.m1.1.1.1.1" xref="S4.E12.m1.1.1.1.1.cmml"><mrow id="S4.E12.m1.1.1.1.1.1.1" xref="S4.E12.m1.1.1.1.1.1.1.1.cmml"><mo maxsize="144%" minsize="144%" id="S4.E12.m1.1.1.1.1.1.1.2" xref="S4.E12.m1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.E12.m1.1.1.1.1.1.1.1" xref="S4.E12.m1.1.1.1.1.1.1.1.cmml"><mrow id="S4.E12.m1.1.1.1.1.1.1.1.1.1" xref="S4.E12.m1.1.1.1.1.1.1.1.1.2.cmml"><mo maxsize="144%" minsize="144%" id="S4.E12.m1.1.1.1.1.1.1.1.1.1.2" xref="S4.E12.m1.1.1.1.1.1.1.1.1.2.1.cmml">|</mo><mrow id="S4.E12.m1.1.1.1.1.1.1.1.1.1.1" xref="S4.E12.m1.1.1.1.1.1.1.1.1.1.1.cmml"><mi mathsize="144%" id="S4.E12.m1.1.1.1.1.1.1.1.1.1.1.1" xref="S4.E12.m1.1.1.1.1.1.1.1.1.1.1.1.cmml">min</mi><mo lspace="0.167em" id="S4.E12.m1.1.1.1.1.1.1.1.1.1.1a" xref="S4.E12.m1.1.1.1.1.1.1.1.1.1.1.cmml">â¡</mo><msub id="S4.E12.m1.1.1.1.1.1.1.1.1.1.1.2" xref="S4.E12.m1.1.1.1.1.1.1.1.1.1.1.2.cmml"><mi mathsize="144%" id="S4.E12.m1.1.1.1.1.1.1.1.1.1.1.2.2" xref="S4.E12.m1.1.1.1.1.1.1.1.1.1.1.2.2.cmml">x</mi><mi mathsize="144%" id="S4.E12.m1.1.1.1.1.1.1.1.1.1.1.2.3" xref="S4.E12.m1.1.1.1.1.1.1.1.1.1.1.2.3.cmml">z</mi></msub></mrow><mo maxsize="144%" minsize="144%" id="S4.E12.m1.1.1.1.1.1.1.1.1.1.3" xref="S4.E12.m1.1.1.1.1.1.1.1.1.2.1.cmml">|</mo></mrow><mo mathsize="144%" id="S4.E12.m1.1.1.1.1.1.1.1.2" xref="S4.E12.m1.1.1.1.1.1.1.1.2.cmml">âˆ’</mo><mn mathsize="144%" id="S4.E12.m1.1.1.1.1.1.1.1.3" xref="S4.E12.m1.1.1.1.1.1.1.1.3.cmml">0.05</mn></mrow><mo maxsize="144%" minsize="144%" id="S4.E12.m1.1.1.1.1.1.1.3" xref="S4.E12.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo mathsize="144%" id="S4.E12.m1.1.1.1.1.3" xref="S4.E12.m1.1.1.1.1.3.cmml">+</mo></msub></mrow></msup><mo lspace="0.222em" mathsize="144%" rspace="0.222em" id="S4.E12.m1.3.3.1.1.3.1" xref="S4.E12.m1.3.3.1.1.3.1.cmml">â‹…</mo><msup id="S4.E12.m1.3.3.1.1.3.3" xref="S4.E12.m1.3.3.1.1.3.3.cmml"><mi mathsize="144%" id="S4.E12.m1.3.3.1.1.3.3.2" xref="S4.E12.m1.3.3.1.1.3.3.2.cmml">e</mi><mrow id="S4.E12.m1.2.2.1" xref="S4.E12.m1.2.2.1.cmml"><mo mathsize="144%" id="S4.E12.m1.2.2.1a" xref="S4.E12.m1.2.2.1.cmml">âˆ’</mo><msub id="S4.E12.m1.2.2.1.1" xref="S4.E12.m1.2.2.1.1.cmml"><mrow id="S4.E12.m1.2.2.1.1.1.1" xref="S4.E12.m1.2.2.1.1.1.1.1.cmml"><mo maxsize="144%" minsize="144%" id="S4.E12.m1.2.2.1.1.1.1.2" xref="S4.E12.m1.2.2.1.1.1.1.1.cmml">(</mo><mrow id="S4.E12.m1.2.2.1.1.1.1.1" xref="S4.E12.m1.2.2.1.1.1.1.1.cmml"><mrow id="S4.E12.m1.2.2.1.1.1.1.1.1" xref="S4.E12.m1.2.2.1.1.1.1.1.1.cmml"><mi mathsize="144%" id="S4.E12.m1.2.2.1.1.1.1.1.1.2" xref="S4.E12.m1.2.2.1.1.1.1.1.1.2.cmml">min</mi><mo id="S4.E12.m1.2.2.1.1.1.1.1.1a" xref="S4.E12.m1.2.2.1.1.1.1.1.1.cmml">â¡</mo><msub id="S4.E12.m1.2.2.1.1.1.1.1.1.1" xref="S4.E12.m1.2.2.1.1.1.1.1.1.1.cmml"><mrow id="S4.E12.m1.2.2.1.1.1.1.1.1.1.1.1" xref="S4.E12.m1.2.2.1.1.1.1.1.1.1.1.2.cmml"><mo maxsize="144%" minsize="144%" id="S4.E12.m1.2.2.1.1.1.1.1.1.1.1.1.2" xref="S4.E12.m1.2.2.1.1.1.1.1.1.1.1.2.1.cmml">â€–</mo><msub id="S4.E12.m1.2.2.1.1.1.1.1.1.1.1.1.1" xref="S4.E12.m1.2.2.1.1.1.1.1.1.1.1.1.1.cmml"><mi mathsize="144%" id="S4.E12.m1.2.2.1.1.1.1.1.1.1.1.1.1.2" xref="S4.E12.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.cmml">x</mi><mrow id="S4.E12.m1.2.2.1.1.1.1.1.1.1.1.1.1.3" xref="S4.E12.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.cmml"><mi mathsize="144%" id="S4.E12.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2" xref="S4.E12.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.cmml">v</mi><mo lspace="0em" rspace="0em" id="S4.E12.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.1" xref="S4.E12.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S4.E12.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3" xref="S4.E12.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.E12.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.1a" xref="S4.E12.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S4.E12.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.4" xref="S4.E12.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.4.cmml">l</mi></mrow></msub><mo maxsize="144%" minsize="144%" id="S4.E12.m1.2.2.1.1.1.1.1.1.1.1.1.3" xref="S4.E12.m1.2.2.1.1.1.1.1.1.1.1.2.1.cmml">â€–</mo></mrow><mn mathsize="144%" id="S4.E12.m1.2.2.1.1.1.1.1.1.1.3" xref="S4.E12.m1.2.2.1.1.1.1.1.1.1.3.cmml">2</mn></msub></mrow><mo mathsize="144%" id="S4.E12.m1.2.2.1.1.1.1.1.2" xref="S4.E12.m1.2.2.1.1.1.1.1.2.cmml">âˆ’</mo><mn mathsize="144%" id="S4.E12.m1.2.2.1.1.1.1.1.3" xref="S4.E12.m1.2.2.1.1.1.1.1.3.cmml">0.075</mn></mrow><mo maxsize="144%" minsize="144%" id="S4.E12.m1.2.2.1.1.1.1.3" xref="S4.E12.m1.2.2.1.1.1.1.1.cmml">)</mo></mrow><mo mathsize="144%" id="S4.E12.m1.2.2.1.1.3" xref="S4.E12.m1.2.2.1.1.3.cmml">+</mo></msub></mrow></msup></mrow></mrow><mo mathsize="144%" id="S4.E12.m1.3.3.1.2" xref="S4.E12.m1.3.3.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E12.m1.3b"><apply id="S4.E12.m1.3.3.1.1.cmml" xref="S4.E12.m1.3.3.1"><eq id="S4.E12.m1.3.3.1.1.1.cmml" xref="S4.E12.m1.3.3.1.1.1"></eq><apply id="S4.E12.m1.3.3.1.1.2.cmml" xref="S4.E12.m1.3.3.1.1.2"><csymbol cd="ambiguous" id="S4.E12.m1.3.3.1.1.2.1.cmml" xref="S4.E12.m1.3.3.1.1.2">subscript</csymbol><ci id="S4.E12.m1.3.3.1.1.2.2.cmml" xref="S4.E12.m1.3.3.1.1.2.2">ğ‘ </ci><apply id="S4.E12.m1.3.3.1.1.2.3.cmml" xref="S4.E12.m1.3.3.1.1.2.3"><times id="S4.E12.m1.3.3.1.1.2.3.1.cmml" xref="S4.E12.m1.3.3.1.1.2.3.1"></times><ci id="S4.E12.m1.3.3.1.1.2.3.2.cmml" xref="S4.E12.m1.3.3.1.1.2.3.2">ğ‘</ci><ci id="S4.E12.m1.3.3.1.1.2.3.3.cmml" xref="S4.E12.m1.3.3.1.1.2.3.3">ğ‘œ</ci><ci id="S4.E12.m1.3.3.1.1.2.3.4.cmml" xref="S4.E12.m1.3.3.1.1.2.3.4">ğ‘›</ci><ci id="S4.E12.m1.3.3.1.1.2.3.5.cmml" xref="S4.E12.m1.3.3.1.1.2.3.5">ğ‘¡</ci><ci id="S4.E12.m1.3.3.1.1.2.3.6.cmml" xref="S4.E12.m1.3.3.1.1.2.3.6">ğ‘</ci><ci id="S4.E12.m1.3.3.1.1.2.3.7.cmml" xref="S4.E12.m1.3.3.1.1.2.3.7">ğ‘</ci><ci id="S4.E12.m1.3.3.1.1.2.3.8.cmml" xref="S4.E12.m1.3.3.1.1.2.3.8">ğ‘¡</ci></apply></apply><apply id="S4.E12.m1.3.3.1.1.3.cmml" xref="S4.E12.m1.3.3.1.1.3"><ci id="S4.E12.m1.3.3.1.1.3.1.cmml" xref="S4.E12.m1.3.3.1.1.3.1">â‹…</ci><apply id="S4.E12.m1.3.3.1.1.3.2.cmml" xref="S4.E12.m1.3.3.1.1.3.2"><csymbol cd="ambiguous" id="S4.E12.m1.3.3.1.1.3.2.1.cmml" xref="S4.E12.m1.3.3.1.1.3.2">superscript</csymbol><ci id="S4.E12.m1.3.3.1.1.3.2.2.cmml" xref="S4.E12.m1.3.3.1.1.3.2.2">ğ‘’</ci><apply id="S4.E12.m1.1.1.1.cmml" xref="S4.E12.m1.1.1.1"><minus id="S4.E12.m1.1.1.1.2.cmml" xref="S4.E12.m1.1.1.1"></minus><apply id="S4.E12.m1.1.1.1.1.cmml" xref="S4.E12.m1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E12.m1.1.1.1.1.2.cmml" xref="S4.E12.m1.1.1.1.1">subscript</csymbol><apply id="S4.E12.m1.1.1.1.1.1.1.1.cmml" xref="S4.E12.m1.1.1.1.1.1.1"><minus id="S4.E12.m1.1.1.1.1.1.1.1.2.cmml" xref="S4.E12.m1.1.1.1.1.1.1.1.2"></minus><apply id="S4.E12.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E12.m1.1.1.1.1.1.1.1.1.1"><abs id="S4.E12.m1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S4.E12.m1.1.1.1.1.1.1.1.1.1.2"></abs><apply id="S4.E12.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E12.m1.1.1.1.1.1.1.1.1.1.1"><min id="S4.E12.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E12.m1.1.1.1.1.1.1.1.1.1.1.1"></min><apply id="S4.E12.m1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E12.m1.1.1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E12.m1.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S4.E12.m1.1.1.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S4.E12.m1.1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S4.E12.m1.1.1.1.1.1.1.1.1.1.1.2.2">ğ‘¥</ci><ci id="S4.E12.m1.1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S4.E12.m1.1.1.1.1.1.1.1.1.1.1.2.3">ğ‘§</ci></apply></apply></apply><cn type="float" id="S4.E12.m1.1.1.1.1.1.1.1.3.cmml" xref="S4.E12.m1.1.1.1.1.1.1.1.3">0.05</cn></apply><plus id="S4.E12.m1.1.1.1.1.3.cmml" xref="S4.E12.m1.1.1.1.1.3"></plus></apply></apply></apply><apply id="S4.E12.m1.3.3.1.1.3.3.cmml" xref="S4.E12.m1.3.3.1.1.3.3"><csymbol cd="ambiguous" id="S4.E12.m1.3.3.1.1.3.3.1.cmml" xref="S4.E12.m1.3.3.1.1.3.3">superscript</csymbol><ci id="S4.E12.m1.3.3.1.1.3.3.2.cmml" xref="S4.E12.m1.3.3.1.1.3.3.2">ğ‘’</ci><apply id="S4.E12.m1.2.2.1.cmml" xref="S4.E12.m1.2.2.1"><minus id="S4.E12.m1.2.2.1.2.cmml" xref="S4.E12.m1.2.2.1"></minus><apply id="S4.E12.m1.2.2.1.1.cmml" xref="S4.E12.m1.2.2.1.1"><csymbol cd="ambiguous" id="S4.E12.m1.2.2.1.1.2.cmml" xref="S4.E12.m1.2.2.1.1">subscript</csymbol><apply id="S4.E12.m1.2.2.1.1.1.1.1.cmml" xref="S4.E12.m1.2.2.1.1.1.1"><minus id="S4.E12.m1.2.2.1.1.1.1.1.2.cmml" xref="S4.E12.m1.2.2.1.1.1.1.1.2"></minus><apply id="S4.E12.m1.2.2.1.1.1.1.1.1.cmml" xref="S4.E12.m1.2.2.1.1.1.1.1.1"><min id="S4.E12.m1.2.2.1.1.1.1.1.1.2.cmml" xref="S4.E12.m1.2.2.1.1.1.1.1.1.2"></min><apply id="S4.E12.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S4.E12.m1.2.2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E12.m1.2.2.1.1.1.1.1.1.1.2.cmml" xref="S4.E12.m1.2.2.1.1.1.1.1.1.1">subscript</csymbol><apply id="S4.E12.m1.2.2.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E12.m1.2.2.1.1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S4.E12.m1.2.2.1.1.1.1.1.1.1.1.2.1.cmml" xref="S4.E12.m1.2.2.1.1.1.1.1.1.1.1.1.2">norm</csymbol><apply id="S4.E12.m1.2.2.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E12.m1.2.2.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.E12.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E12.m1.2.2.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S4.E12.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E12.m1.2.2.1.1.1.1.1.1.1.1.1.1.2">ğ‘¥</ci><apply id="S4.E12.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S4.E12.m1.2.2.1.1.1.1.1.1.1.1.1.1.3"><times id="S4.E12.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S4.E12.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.1"></times><ci id="S4.E12.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S4.E12.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2">ğ‘£</ci><ci id="S4.E12.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S4.E12.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3">ğ‘’</ci><ci id="S4.E12.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.4.cmml" xref="S4.E12.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.4">ğ‘™</ci></apply></apply></apply><cn type="integer" id="S4.E12.m1.2.2.1.1.1.1.1.1.1.3.cmml" xref="S4.E12.m1.2.2.1.1.1.1.1.1.1.3">2</cn></apply></apply><cn type="float" id="S4.E12.m1.2.2.1.1.1.1.1.3.cmml" xref="S4.E12.m1.2.2.1.1.1.1.1.3">0.075</cn></apply><plus id="S4.E12.m1.2.2.1.1.3.cmml" xref="S4.E12.m1.2.2.1.1.3"></plus></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E12.m1.3c">s_{contact}=e^{-(|\min x_{z}|-0.05)_{+}}\cdot e^{-(\min\|x_{vel}\|_{2}-0.075)_{+}},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(12)</span></td>
</tr></tbody>
</table>
<p id="S4.SS2a.p1.3" class="ltx_p"><span id="S4.SS2a.p1.3.1" class="ltx_text" style="font-size:144%;">where </span><math id="S4.SS2a.p1.1.m1.1" class="ltx_Math" alttext="x_{z}" display="inline"><semantics id="S4.SS2a.p1.1.m1.1a"><msub id="S4.SS2a.p1.1.m1.1.1" xref="S4.SS2a.p1.1.m1.1.1.cmml"><mi mathsize="144%" id="S4.SS2a.p1.1.m1.1.1.2" xref="S4.SS2a.p1.1.m1.1.1.2.cmml">x</mi><mi mathsize="144%" id="S4.SS2a.p1.1.m1.1.1.3" xref="S4.SS2a.p1.1.m1.1.1.3.cmml">z</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2a.p1.1.m1.1b"><apply id="S4.SS2a.p1.1.m1.1.1.cmml" xref="S4.SS2a.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2a.p1.1.m1.1.1.1.cmml" xref="S4.SS2a.p1.1.m1.1.1">subscript</csymbol><ci id="S4.SS2a.p1.1.m1.1.1.2.cmml" xref="S4.SS2a.p1.1.m1.1.1.2">ğ‘¥</ci><ci id="S4.SS2a.p1.1.m1.1.1.3.cmml" xref="S4.SS2a.p1.1.m1.1.1.3">ğ‘§</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2a.p1.1.m1.1c">x_{z}</annotation></semantics></math><span id="S4.SS2a.p1.3.2" class="ltx_text" style="font-size:144%;"> and </span><math id="S4.SS2a.p1.2.m2.1" class="ltx_Math" alttext="x_{vel}" display="inline"><semantics id="S4.SS2a.p1.2.m2.1a"><msub id="S4.SS2a.p1.2.m2.1.1" xref="S4.SS2a.p1.2.m2.1.1.cmml"><mi mathsize="144%" id="S4.SS2a.p1.2.m2.1.1.2" xref="S4.SS2a.p1.2.m2.1.1.2.cmml">x</mi><mrow id="S4.SS2a.p1.2.m2.1.1.3" xref="S4.SS2a.p1.2.m2.1.1.3.cmml"><mi mathsize="144%" id="S4.SS2a.p1.2.m2.1.1.3.2" xref="S4.SS2a.p1.2.m2.1.1.3.2.cmml">v</mi><mo lspace="0em" rspace="0em" id="S4.SS2a.p1.2.m2.1.1.3.1" xref="S4.SS2a.p1.2.m2.1.1.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S4.SS2a.p1.2.m2.1.1.3.3" xref="S4.SS2a.p1.2.m2.1.1.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.SS2a.p1.2.m2.1.1.3.1a" xref="S4.SS2a.p1.2.m2.1.1.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S4.SS2a.p1.2.m2.1.1.3.4" xref="S4.SS2a.p1.2.m2.1.1.3.4.cmml">l</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS2a.p1.2.m2.1b"><apply id="S4.SS2a.p1.2.m2.1.1.cmml" xref="S4.SS2a.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2a.p1.2.m2.1.1.1.cmml" xref="S4.SS2a.p1.2.m2.1.1">subscript</csymbol><ci id="S4.SS2a.p1.2.m2.1.1.2.cmml" xref="S4.SS2a.p1.2.m2.1.1.2">ğ‘¥</ci><apply id="S4.SS2a.p1.2.m2.1.1.3.cmml" xref="S4.SS2a.p1.2.m2.1.1.3"><times id="S4.SS2a.p1.2.m2.1.1.3.1.cmml" xref="S4.SS2a.p1.2.m2.1.1.3.1"></times><ci id="S4.SS2a.p1.2.m2.1.1.3.2.cmml" xref="S4.SS2a.p1.2.m2.1.1.3.2">ğ‘£</ci><ci id="S4.SS2a.p1.2.m2.1.1.3.3.cmml" xref="S4.SS2a.p1.2.m2.1.1.3.3">ğ‘’</ci><ci id="S4.SS2a.p1.2.m2.1.1.3.4.cmml" xref="S4.SS2a.p1.2.m2.1.1.3.4">ğ‘™</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2a.p1.2.m2.1c">x_{vel}</annotation></semantics></math><span id="S4.SS2a.p1.3.3" class="ltx_text" style="font-size:144%;"> denote the marker height and velocity, 0.05 and 0.075 are tolerance thresholds, and </span><math id="S4.SS2a.p1.3.m3.1" class="ltx_Math" alttext="(\cdot)_{+}" display="inline"><semantics id="S4.SS2a.p1.3.m3.1a"><msub id="S4.SS2a.p1.3.m3.1.2" xref="S4.SS2a.p1.3.m3.1.2.cmml"><mrow id="S4.SS2a.p1.3.m3.1.2.2.2" xref="S4.SS2a.p1.3.m3.1.2.cmml"><mo maxsize="144%" minsize="144%" id="S4.SS2a.p1.3.m3.1.2.2.2.1" xref="S4.SS2a.p1.3.m3.1.2.cmml">(</mo><mo lspace="0em" mathsize="144%" rspace="0em" id="S4.SS2a.p1.3.m3.1.1" xref="S4.SS2a.p1.3.m3.1.1.cmml">â‹…</mo><mo maxsize="144%" minsize="144%" id="S4.SS2a.p1.3.m3.1.2.2.2.2" xref="S4.SS2a.p1.3.m3.1.2.cmml">)</mo></mrow><mo mathsize="144%" id="S4.SS2a.p1.3.m3.1.2.3" xref="S4.SS2a.p1.3.m3.1.2.3.cmml">+</mo></msub><annotation-xml encoding="MathML-Content" id="S4.SS2a.p1.3.m3.1b"><apply id="S4.SS2a.p1.3.m3.1.2.cmml" xref="S4.SS2a.p1.3.m3.1.2"><csymbol cd="ambiguous" id="S4.SS2a.p1.3.m3.1.2.1.cmml" xref="S4.SS2a.p1.3.m3.1.2">subscript</csymbol><ci id="S4.SS2a.p1.3.m3.1.1.cmml" xref="S4.SS2a.p1.3.m3.1.1">â‹…</ci><plus id="S4.SS2a.p1.3.m3.1.2.3.cmml" xref="S4.SS2a.p1.3.m3.1.2.3"></plus></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2a.p1.3.m3.1c">(\cdot)_{+}</annotation></semantics></math><span id="S4.SS2a.p1.3.4" class="ltx_text" style="font-size:144%;"> denotes clipping with the lowerbound of 0.</span></p>
</div>
<div id="S4.SS2a.p2" class="ltx_para">
<p id="S4.SS2a.p2.1" class="ltx_p"><span id="S4.SS2a.p2.1.1" class="ltx_text" style="font-size:144%;">For moving obstacle scenes, we evaluate human-scene penetration by detecting all frames where the floor plane projections of any body parts and obstacles have intersections.
For multiple human scenes, we measure the accurate human-human penetration using the implicit human body occupancy model COAP </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.SS2a.p2.1.2.1" class="ltx_text" style="font-size:144%;">[</span><a href="#bib.bib56" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">56</span></a><span id="S4.SS2a.p2.1.3.2" class="ltx_text" style="font-size:144%;">]</span></cite><span id="S4.SS2a.p2.1.4" class="ltx_text" style="font-size:144%;">, which predicts the body occupancy given spatial location queries. Since the articulated human bodies are complex and require accurate penetration detection, we detect whether one human collides with other humans by querying its body vertices using the occupancy field of all other humans at that frame and report the occupancy values for human-human penetration.</span></p>
</div>
</section>
<section id="S4.SS3a" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:144%;">
<span class="ltx_tag ltx_tag_subsection">S4.3 </span>Ablation Studies</h3>

<section id="S4.SS3.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph" style="font-size:144%;">No pretraining.</h4>

<div id="S4.SS3.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS3.SSS0.Px1.p1.2" class="ltx_p"><span id="S4.SS3.SSS0.Px1.p1.2.1" class="ltx_text" style="font-size:144%;">Without our two-stage RL training scheme, direct penetration termination in crowded scenes will result in unrealistic predicted human poses. As shown in </span><a href="#S5.T3" title="In 5.3 Ablation Studies â€£ 5 Experiments â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref" style="font-size:144%;"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">3</span></a><span id="S4.SS3.SSS0.Px1.p1.2.2" class="ltx_text" style="font-size:144%;">, where </span><math id="S4.SS3.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="\|" display="inline"><semantics id="S4.SS3.SSS0.Px1.p1.1.m1.1a"><mo mathsize="144%" id="S4.SS3.SSS0.Px1.p1.1.m1.1.1" xref="S4.SS3.SSS0.Px1.p1.1.m1.1.1.cmml">âˆ¥</mo><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px1.p1.1.m1.1b"><ci id="S4.SS3.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S4.SS3.SSS0.Px1.p1.1.m1.1.1">âˆ¥</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px1.p1.1.m1.1c">\|</annotation></semantics></math><span id="S4.SS3.SSS0.Px1.p1.2.3" class="ltx_text" style="font-size:144%;">VP</span><math id="S4.SS3.SSS0.Px1.p1.2.m2.1" class="ltx_math_unparsed" alttext="\|=28.77&gt;15" display="inline"><semantics id="S4.SS3.SSS0.Px1.p1.2.m2.1a"><mrow id="S4.SS3.SSS0.Px1.p1.2.m2.1b"><mo mathsize="144%" rspace="0.0835em" id="S4.SS3.SSS0.Px1.p1.2.m2.1.1">âˆ¥</mo><mo lspace="0.0835em" mathsize="144%" id="S4.SS3.SSS0.Px1.p1.2.m2.1.2">=</mo><mn mathsize="144%" id="S4.SS3.SSS0.Px1.p1.2.m2.1.3">28.77</mn><mo mathsize="144%" id="S4.SS3.SSS0.Px1.p1.2.m2.1.4">&gt;</mo><mn mathsize="144%" id="S4.SS3.SSS0.Px1.p1.2.m2.1.5">15</mn></mrow><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px1.p1.2.m2.1c">\|=28.77&gt;15</annotation></semantics></math><span id="S4.SS3.SSS0.Px1.p1.2.4" class="ltx_text" style="font-size:144%;">, we provide visualizations of the corresponding unnatural poses inÂ </span><a href="#S4.F7" title="In No pretraining. â€£ S4.3 Ablation Studies â€£ S4 Experiments â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref" style="font-size:144%;"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">S7</span></a><span id="S4.SS3.SSS0.Px1.p1.2.5" class="ltx_text" style="font-size:144%;">. In contrast, our full model works well. Please refer to Sup. Vid.</span></p>
</div>
<figure id="S4.F7" class="ltx_figure"><img src="/html/2401.08739/assets/images/weird.png" id="S4.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="538" height="365" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering" style="font-size:144%;"><span class="ltx_tag ltx_tag_figure"><span id="S4.F7.4.1.1" class="ltx_text" style="font-size:63%;">Figure S7</span>: </span><span id="S4.F7.5.2" class="ltx_text" style="font-size:63%;">Ablation of our two-stage RL training. Without pretraining, the model can produce unrealistic human poses.
</span></figcaption>
</figure>
</section>
</section>
</section>
<section id="S5a" class="ltx_section ltx_centering">
<h2 class="ltx_title ltx_title_section" style="font-size:144%;">
<span class="ltx_tag ltx_tag_section">S5 </span>Egocentric Perception Tasks</h2>

<section id="S5.SS1a" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:144%;">
<span class="ltx_tag ltx_tag_subsection">S5.1 </span>Mapping and Localization for AR</h3>

<div id="S5.SS1a.p1" class="ltx_para">
<p id="S5.SS1a.p1.1" class="ltx_p"><span id="S5.SS1a.p1.1.1" class="ltx_text" style="font-size:144%;">As shown inÂ </span><a href="#S5.F8" title="In S5.1 Mapping and Localization for AR â€£ S5 Egocentric Perception Tasks â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref" style="font-size:144%;"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">S8</span></a><span id="S5.SS1a.p1.1.2" class="ltx_text" style="font-size:144%;">, we can leverage </span><span id="S5.SS1a.p1.1.3" class="ltx_text ltx_font_italic" style="font-size:144%;">EgoGen</span><span id="S5.SS1a.p1.1.4" class="ltx_text" style="font-size:144%;">Â to explore the large-scale scene, add synthetic egocentric images into the dataset, and build a more complete Structure-from-Motion (SfM) map (</span><a href="#S5.F8.sf2" title="In Figure S8 â€£ S5.1 Mapping and Localization for AR â€£ S5 Egocentric Perception Tasks â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref" style="font-size:144%;"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">8(b)</span></a><span id="S5.SS1a.p1.1.5" class="ltx_text" style="font-size:144%;">). In our implementation, we randomly set the starting and target locations of virtual humans. Compared withÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.SS1a.p1.1.6.1" class="ltx_text" style="font-size:144%;">[</span><a href="#bib.bib62" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">62</span></a><span id="S5.SS1a.p1.1.7.2" class="ltx_text" style="font-size:144%;">]</span></cite><span id="S5.SS1a.p1.1.8" class="ltx_text" style="font-size:144%;"> that perturbs real-world cameras with random noise (</span><a href="#S5.F8.sf3" title="In Figure S8 â€£ S5.1 Mapping and Localization for AR â€£ S5 Egocentric Perception Tasks â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref" style="font-size:144%;"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">8(c)</span></a><span id="S5.SS1a.p1.1.9" class="ltx_text" style="font-size:144%;">) that may result in unrealistic camera poses, </span><span id="S5.SS1a.p1.1.10" class="ltx_text ltx_font_italic" style="font-size:144%;">EgoGen</span><span id="S5.SS1a.p1.1.11" class="ltx_text" style="font-size:144%;">Â can simulate human trajectories and motion (</span><a href="#S5.F8.sf4" title="In Figure S8 â€£ S5.1 Mapping and Localization for AR â€£ S5 Egocentric Perception Tasks â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref" style="font-size:144%;"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">8(d)</span></a><span id="S5.SS1a.p1.1.12" class="ltx_text" style="font-size:144%;">).</span></p>
</div>
<div id="S5.SS1a.p2" class="ltx_para">
<p id="S5.SS1a.p2.1" class="ltx_p"><span id="S5.SS1a.p2.1.1" class="ltx_text" style="font-size:144%;">The efficacy of synthetic data for a task relies on the domain gap between synthetic and real-world images.
In the SfM pipeline in our experiment, the render-to-real gap can influence the result of the feature extraction. As shown inÂ </span><a href="#S5.F9" title="In S5.1 Mapping and Localization for AR â€£ S5 Egocentric Perception Tasks â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref" style="font-size:144%;"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">S9</span></a><span id="S5.SS1a.p2.1.2" class="ltx_text" style="font-size:144%;"> on the left, detected feature points with SuperPointÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.SS1a.p2.1.3.1" class="ltx_text" style="font-size:144%;">[</span><a href="#bib.bib17" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">17</span></a><span id="S5.SS1a.p2.1.4.2" class="ltx_text" style="font-size:144%;">]</span></cite><span id="S5.SS1a.p2.1.5" class="ltx_text" style="font-size:144%;"> are much noisier in synthetic images due to scene quality, which can make feature matching challenging. In addition, the feature matcher SuperGlue </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.SS1a.p2.1.6.1" class="ltx_text" style="font-size:144%;">[</span><a href="#bib.bib83" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">83</span></a><span id="S5.SS1a.p2.1.7.2" class="ltx_text" style="font-size:144%;">]</span></cite><span id="S5.SS1a.p2.1.8" class="ltx_text" style="font-size:144%;"> exhibits overfitting behaviors: visually similar images are preferred to be matched first, i.e., it tends to match sim-sim and real-real pairs only. As a result, simply adding synthetic images into the real-world dataset will result in no matches between synthetic and real-world images, making it impossible to improve localization recall.</span></p>
</div>
<div id="S5.SS1a.p3" class="ltx_para">
<p id="S5.SS1a.p3.1" class="ltx_p"><span id="S5.SS1a.p3.1.1" class="ltx_text" style="font-size:144%;">To ensure valid matching between synthetic and real-world mapping images, during the pair selection process using SuperGlue, we force synthetic images to match with real images only.
By implementing this approach, we can achieve a denser SfM map by establishing matches between synthetic and real-world 2D image feature points (seeÂ </span><a href="#S5.F9" title="In S5.1 Mapping and Localization for AR â€£ S5 Egocentric Perception Tasks â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref" style="font-size:144%;"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">S9</span></a><span id="S5.SS1a.p3.1.2" class="ltx_text" style="font-size:144%;">) and thereby triangulating more 3D points.</span></p>
</div>
<div id="S5.SS1a.p4" class="ltx_para">
<p id="S5.SS1a.p4.1" class="ltx_p"><span id="S5.SS1a.p4.1.1" class="ltx_text" style="font-size:144%;">To enhance the localization performance of real-world query images using the augmented SfM map, we enforce matches with both synthetic and real mapping images for all query images. This ensures that real-world query images can be paired with synthetic mapping images, leveraging a denser SfM map and enhancing localization recall.</span></p>
</div>
<figure id="S5.F8" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F8.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2401.08739/assets/images/lamar1.png" id="S5.F8.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="685" height="440" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering" style="font-size:144%;"><span class="ltx_tag ltx_tag_figure"><span id="S5.F8.sf1.4.1.1" class="ltx_text" style="font-size:63%;">(a)</span> </span><span id="S5.F8.sf1.5.2" class="ltx_text" style="font-size:63%;">Real-world cameras</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F8.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2401.08739/assets/images/lamar4.png" id="S5.F8.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="685" height="408" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering" style="font-size:144%;"><span class="ltx_tag ltx_tag_figure"><span id="S5.F8.sf2.4.1.1" class="ltx_text" style="font-size:63%;">(b)</span> </span><span id="S5.F8.sf2.5.2" class="ltx_text" style="font-size:63%;">EgoGen synthetic cameras</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F8.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2401.08739/assets/images/lamar2.png" id="S5.F8.sf3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="685" height="442" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering" style="font-size:144%;"><span class="ltx_tag ltx_tag_figure"><span id="S5.F8.sf3.4.1.1" class="ltx_text" style="font-size:63%;">(c)</span> </span><span id="S5.F8.sf3.5.2" class="ltx_text" style="font-size:63%;">Perturbing existing cameras</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F8.sf4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2401.08739/assets/images/lamar3.png" id="S5.F8.sf4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="685" height="421" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering" style="font-size:144%;"><span class="ltx_tag ltx_tag_figure"><span id="S5.F8.sf4.4.1.1" class="ltx_text" style="font-size:63%;">(d)</span> </span><span id="S5.F8.sf4.5.2" class="ltx_text" style="font-size:63%;">EgoGen same # of cams as (c)</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering" style="font-size:144%;"><span class="ltx_tag ltx_tag_figure"><span id="S5.F8.16.1.1" class="ltx_text" style="font-size:63%;">Figure S8</span>: </span><span id="S5.F8.17.2" class="ltx_text" style="font-size:63%;">EgoGen addresses the issue of sparsity by populating the dataset with synthetic images. In Fig.Â <a href="#S5.F8.sf1" title="Figure 8(a) â€£ Figure S8 â€£ S5.1 Mapping and Localization for AR â€£ S5 Egocentric Perception Tasks â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8(a)</span></a>, the sparsity of real-world mapping images is apparent, where each red object represents a camera and each colored dot represents a triangulated 3D point. After applying EgoGen, mapping images are more densely distributed, resulting in denser 3D triangulated points, as shown in Fig.Â <a href="#S5.F8.sf2" title="Figure 8(b) â€£ Figure S8 â€£ S5.1 Mapping and Localization for AR â€£ S5 Egocentric Perception Tasks â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8(b)</span></a>. In Fig.Â <a href="#S5.F8.sf3" title="Figure 8(c) â€£ Figure S8 â€£ S5.1 Mapping and Localization for AR â€£ S5 Egocentric Perception Tasks â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8(c)</span></a> and Fig.Â <a href="#S5.F8.sf4" title="Figure 8(d) â€£ Figure S8 â€£ S5.1 Mapping and Localization for AR â€£ S5 Egocentric Perception Tasks â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8(d)</span></a>, we augment <a href="#S5.F8.sf1" title="Figure 8(a) â€£ Figure S8 â€£ S5.1 Mapping and Localization for AR â€£ S5 Egocentric Perception Tasks â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8(a)</span></a> with the same amount of synthetic images using <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">62</span></a>]</cite> and EgoGen respectively. EgoGen generates synthetic data with a similar distribution as human trajectories as illustrated in <a href="#S5.F8.sf4" title="Figure 8(d) â€£ Figure S8 â€£ S5.1 Mapping and Localization for AR â€£ S5 Egocentric Perception Tasks â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8(d)</span></a>. Results are visualized using ColmapÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib87" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">87</span></a>]</cite>. Note that we only visualize a subset of cameras here.</span></figcaption>
</figure>
<figure id="S5.F9" class="ltx_figure"><img src="/html/2401.08739/assets/images/matches.png" id="S5.F9.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="399" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering" style="font-size:144%;"><span class="ltx_tag ltx_tag_figure"><span id="S5.F9.4.1.1" class="ltx_text" style="font-size:63%;">Figure S9</span>: </span><span id="S5.F9.5.2" class="ltx_text" style="font-size:63%;">Feature matching visualization for a render-to-real image pair.
</span></figcaption>
</figure>
</section>
<section id="S5.SS2a" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:144%;">
<span class="ltx_tag ltx_tag_subsection">S5.2 </span>Egocentric Camera Tracking</h3>

<div id="S5.SS2a.p1" class="ltx_para">
<p id="S5.SS2a.p1.2" class="ltx_p"><span id="S5.SS2a.p1.2.1" class="ltx_text" style="font-size:144%;">The egocentric camera tracking task is evaluated using the head rotation error, translation error, and pose error that jointly accounts for both rotation and translation.
The head rotation error calculates the Frobenius norm of the difference between the matrix representations of the predicted rotation </span><math id="S5.SS2a.p1.1.m1.1" class="ltx_Math" alttext="R_{pred}" display="inline"><semantics id="S5.SS2a.p1.1.m1.1a"><msub id="S5.SS2a.p1.1.m1.1.1" xref="S5.SS2a.p1.1.m1.1.1.cmml"><mi mathsize="144%" id="S5.SS2a.p1.1.m1.1.1.2" xref="S5.SS2a.p1.1.m1.1.1.2.cmml">R</mi><mrow id="S5.SS2a.p1.1.m1.1.1.3" xref="S5.SS2a.p1.1.m1.1.1.3.cmml"><mi mathsize="144%" id="S5.SS2a.p1.1.m1.1.1.3.2" xref="S5.SS2a.p1.1.m1.1.1.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S5.SS2a.p1.1.m1.1.1.3.1" xref="S5.SS2a.p1.1.m1.1.1.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S5.SS2a.p1.1.m1.1.1.3.3" xref="S5.SS2a.p1.1.m1.1.1.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S5.SS2a.p1.1.m1.1.1.3.1a" xref="S5.SS2a.p1.1.m1.1.1.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S5.SS2a.p1.1.m1.1.1.3.4" xref="S5.SS2a.p1.1.m1.1.1.3.4.cmml">e</mi><mo lspace="0em" rspace="0em" id="S5.SS2a.p1.1.m1.1.1.3.1b" xref="S5.SS2a.p1.1.m1.1.1.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S5.SS2a.p1.1.m1.1.1.3.5" xref="S5.SS2a.p1.1.m1.1.1.3.5.cmml">d</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S5.SS2a.p1.1.m1.1b"><apply id="S5.SS2a.p1.1.m1.1.1.cmml" xref="S5.SS2a.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS2a.p1.1.m1.1.1.1.cmml" xref="S5.SS2a.p1.1.m1.1.1">subscript</csymbol><ci id="S5.SS2a.p1.1.m1.1.1.2.cmml" xref="S5.SS2a.p1.1.m1.1.1.2">ğ‘…</ci><apply id="S5.SS2a.p1.1.m1.1.1.3.cmml" xref="S5.SS2a.p1.1.m1.1.1.3"><times id="S5.SS2a.p1.1.m1.1.1.3.1.cmml" xref="S5.SS2a.p1.1.m1.1.1.3.1"></times><ci id="S5.SS2a.p1.1.m1.1.1.3.2.cmml" xref="S5.SS2a.p1.1.m1.1.1.3.2">ğ‘</ci><ci id="S5.SS2a.p1.1.m1.1.1.3.3.cmml" xref="S5.SS2a.p1.1.m1.1.1.3.3">ğ‘Ÿ</ci><ci id="S5.SS2a.p1.1.m1.1.1.3.4.cmml" xref="S5.SS2a.p1.1.m1.1.1.3.4">ğ‘’</ci><ci id="S5.SS2a.p1.1.m1.1.1.3.5.cmml" xref="S5.SS2a.p1.1.m1.1.1.3.5">ğ‘‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2a.p1.1.m1.1c">R_{pred}</annotation></semantics></math><span id="S5.SS2a.p1.2.2" class="ltx_text" style="font-size:144%;"> and the ground truth rotation </span><math id="S5.SS2a.p1.2.m2.1" class="ltx_Math" alttext="R_{gt}" display="inline"><semantics id="S5.SS2a.p1.2.m2.1a"><msub id="S5.SS2a.p1.2.m2.1.1" xref="S5.SS2a.p1.2.m2.1.1.cmml"><mi mathsize="144%" id="S5.SS2a.p1.2.m2.1.1.2" xref="S5.SS2a.p1.2.m2.1.1.2.cmml">R</mi><mrow id="S5.SS2a.p1.2.m2.1.1.3" xref="S5.SS2a.p1.2.m2.1.1.3.cmml"><mi mathsize="144%" id="S5.SS2a.p1.2.m2.1.1.3.2" xref="S5.SS2a.p1.2.m2.1.1.3.2.cmml">g</mi><mo lspace="0em" rspace="0em" id="S5.SS2a.p1.2.m2.1.1.3.1" xref="S5.SS2a.p1.2.m2.1.1.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S5.SS2a.p1.2.m2.1.1.3.3" xref="S5.SS2a.p1.2.m2.1.1.3.3.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S5.SS2a.p1.2.m2.1b"><apply id="S5.SS2a.p1.2.m2.1.1.cmml" xref="S5.SS2a.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS2a.p1.2.m2.1.1.1.cmml" xref="S5.SS2a.p1.2.m2.1.1">subscript</csymbol><ci id="S5.SS2a.p1.2.m2.1.1.2.cmml" xref="S5.SS2a.p1.2.m2.1.1.2">ğ‘…</ci><apply id="S5.SS2a.p1.2.m2.1.1.3.cmml" xref="S5.SS2a.p1.2.m2.1.1.3"><times id="S5.SS2a.p1.2.m2.1.1.3.1.cmml" xref="S5.SS2a.p1.2.m2.1.1.3.1"></times><ci id="S5.SS2a.p1.2.m2.1.1.3.2.cmml" xref="S5.SS2a.p1.2.m2.1.1.3.2">ğ‘”</ci><ci id="S5.SS2a.p1.2.m2.1.1.3.3.cmml" xref="S5.SS2a.p1.2.m2.1.1.3.3">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2a.p1.2.m2.1c">R_{gt}</annotation></semantics></math><span id="S5.SS2a.p1.2.3" class="ltx_text" style="font-size:144%;">, which is defined as:</span></p>
<table id="S5.E13" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S5.E13.m1.1" class="ltx_Math" alttext="e_{rotation}=\|R_{pred}R_{gt}^{-1}\|_{2}," display="block"><semantics id="S5.E13.m1.1a"><mrow id="S5.E13.m1.1.1.1" xref="S5.E13.m1.1.1.1.1.cmml"><mrow id="S5.E13.m1.1.1.1.1" xref="S5.E13.m1.1.1.1.1.cmml"><msub id="S5.E13.m1.1.1.1.1.3" xref="S5.E13.m1.1.1.1.1.3.cmml"><mi mathsize="144%" id="S5.E13.m1.1.1.1.1.3.2" xref="S5.E13.m1.1.1.1.1.3.2.cmml">e</mi><mrow id="S5.E13.m1.1.1.1.1.3.3" xref="S5.E13.m1.1.1.1.1.3.3.cmml"><mi mathsize="144%" id="S5.E13.m1.1.1.1.1.3.3.2" xref="S5.E13.m1.1.1.1.1.3.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S5.E13.m1.1.1.1.1.3.3.1" xref="S5.E13.m1.1.1.1.1.3.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S5.E13.m1.1.1.1.1.3.3.3" xref="S5.E13.m1.1.1.1.1.3.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S5.E13.m1.1.1.1.1.3.3.1a" xref="S5.E13.m1.1.1.1.1.3.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S5.E13.m1.1.1.1.1.3.3.4" xref="S5.E13.m1.1.1.1.1.3.3.4.cmml">t</mi><mo lspace="0em" rspace="0em" id="S5.E13.m1.1.1.1.1.3.3.1b" xref="S5.E13.m1.1.1.1.1.3.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S5.E13.m1.1.1.1.1.3.3.5" xref="S5.E13.m1.1.1.1.1.3.3.5.cmml">a</mi><mo lspace="0em" rspace="0em" id="S5.E13.m1.1.1.1.1.3.3.1c" xref="S5.E13.m1.1.1.1.1.3.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S5.E13.m1.1.1.1.1.3.3.6" xref="S5.E13.m1.1.1.1.1.3.3.6.cmml">t</mi><mo lspace="0em" rspace="0em" id="S5.E13.m1.1.1.1.1.3.3.1d" xref="S5.E13.m1.1.1.1.1.3.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S5.E13.m1.1.1.1.1.3.3.7" xref="S5.E13.m1.1.1.1.1.3.3.7.cmml">i</mi><mo lspace="0em" rspace="0em" id="S5.E13.m1.1.1.1.1.3.3.1e" xref="S5.E13.m1.1.1.1.1.3.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S5.E13.m1.1.1.1.1.3.3.8" xref="S5.E13.m1.1.1.1.1.3.3.8.cmml">o</mi><mo lspace="0em" rspace="0em" id="S5.E13.m1.1.1.1.1.3.3.1f" xref="S5.E13.m1.1.1.1.1.3.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S5.E13.m1.1.1.1.1.3.3.9" xref="S5.E13.m1.1.1.1.1.3.3.9.cmml">n</mi></mrow></msub><mo mathsize="144%" id="S5.E13.m1.1.1.1.1.2" xref="S5.E13.m1.1.1.1.1.2.cmml">=</mo><msub id="S5.E13.m1.1.1.1.1.1" xref="S5.E13.m1.1.1.1.1.1.cmml"><mrow id="S5.E13.m1.1.1.1.1.1.1.1" xref="S5.E13.m1.1.1.1.1.1.1.2.cmml"><mo maxsize="144%" minsize="144%" id="S5.E13.m1.1.1.1.1.1.1.1.2" xref="S5.E13.m1.1.1.1.1.1.1.2.1.cmml">â€–</mo><mrow id="S5.E13.m1.1.1.1.1.1.1.1.1" xref="S5.E13.m1.1.1.1.1.1.1.1.1.cmml"><msub id="S5.E13.m1.1.1.1.1.1.1.1.1.2" xref="S5.E13.m1.1.1.1.1.1.1.1.1.2.cmml"><mi mathsize="144%" id="S5.E13.m1.1.1.1.1.1.1.1.1.2.2" xref="S5.E13.m1.1.1.1.1.1.1.1.1.2.2.cmml">R</mi><mrow id="S5.E13.m1.1.1.1.1.1.1.1.1.2.3" xref="S5.E13.m1.1.1.1.1.1.1.1.1.2.3.cmml"><mi mathsize="144%" id="S5.E13.m1.1.1.1.1.1.1.1.1.2.3.2" xref="S5.E13.m1.1.1.1.1.1.1.1.1.2.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S5.E13.m1.1.1.1.1.1.1.1.1.2.3.1" xref="S5.E13.m1.1.1.1.1.1.1.1.1.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S5.E13.m1.1.1.1.1.1.1.1.1.2.3.3" xref="S5.E13.m1.1.1.1.1.1.1.1.1.2.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S5.E13.m1.1.1.1.1.1.1.1.1.2.3.1a" xref="S5.E13.m1.1.1.1.1.1.1.1.1.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S5.E13.m1.1.1.1.1.1.1.1.1.2.3.4" xref="S5.E13.m1.1.1.1.1.1.1.1.1.2.3.4.cmml">e</mi><mo lspace="0em" rspace="0em" id="S5.E13.m1.1.1.1.1.1.1.1.1.2.3.1b" xref="S5.E13.m1.1.1.1.1.1.1.1.1.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S5.E13.m1.1.1.1.1.1.1.1.1.2.3.5" xref="S5.E13.m1.1.1.1.1.1.1.1.1.2.3.5.cmml">d</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S5.E13.m1.1.1.1.1.1.1.1.1.1" xref="S5.E13.m1.1.1.1.1.1.1.1.1.1.cmml">â€‹</mo><msubsup id="S5.E13.m1.1.1.1.1.1.1.1.1.3" xref="S5.E13.m1.1.1.1.1.1.1.1.1.3.cmml"><mi mathsize="144%" id="S5.E13.m1.1.1.1.1.1.1.1.1.3.2.2" xref="S5.E13.m1.1.1.1.1.1.1.1.1.3.2.2.cmml">R</mi><mrow id="S5.E13.m1.1.1.1.1.1.1.1.1.3.2.3" xref="S5.E13.m1.1.1.1.1.1.1.1.1.3.2.3.cmml"><mi mathsize="144%" id="S5.E13.m1.1.1.1.1.1.1.1.1.3.2.3.2" xref="S5.E13.m1.1.1.1.1.1.1.1.1.3.2.3.2.cmml">g</mi><mo lspace="0em" rspace="0em" id="S5.E13.m1.1.1.1.1.1.1.1.1.3.2.3.1" xref="S5.E13.m1.1.1.1.1.1.1.1.1.3.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S5.E13.m1.1.1.1.1.1.1.1.1.3.2.3.3" xref="S5.E13.m1.1.1.1.1.1.1.1.1.3.2.3.3.cmml">t</mi></mrow><mrow id="S5.E13.m1.1.1.1.1.1.1.1.1.3.3" xref="S5.E13.m1.1.1.1.1.1.1.1.1.3.3.cmml"><mo mathsize="144%" id="S5.E13.m1.1.1.1.1.1.1.1.1.3.3a" xref="S5.E13.m1.1.1.1.1.1.1.1.1.3.3.cmml">âˆ’</mo><mn mathsize="144%" id="S5.E13.m1.1.1.1.1.1.1.1.1.3.3.2" xref="S5.E13.m1.1.1.1.1.1.1.1.1.3.3.2.cmml">1</mn></mrow></msubsup></mrow><mo maxsize="144%" minsize="144%" id="S5.E13.m1.1.1.1.1.1.1.1.3" xref="S5.E13.m1.1.1.1.1.1.1.2.1.cmml">â€–</mo></mrow><mn mathsize="144%" id="S5.E13.m1.1.1.1.1.1.3" xref="S5.E13.m1.1.1.1.1.1.3.cmml">2</mn></msub></mrow><mo mathsize="144%" id="S5.E13.m1.1.1.1.2" xref="S5.E13.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.E13.m1.1b"><apply id="S5.E13.m1.1.1.1.1.cmml" xref="S5.E13.m1.1.1.1"><eq id="S5.E13.m1.1.1.1.1.2.cmml" xref="S5.E13.m1.1.1.1.1.2"></eq><apply id="S5.E13.m1.1.1.1.1.3.cmml" xref="S5.E13.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S5.E13.m1.1.1.1.1.3.1.cmml" xref="S5.E13.m1.1.1.1.1.3">subscript</csymbol><ci id="S5.E13.m1.1.1.1.1.3.2.cmml" xref="S5.E13.m1.1.1.1.1.3.2">ğ‘’</ci><apply id="S5.E13.m1.1.1.1.1.3.3.cmml" xref="S5.E13.m1.1.1.1.1.3.3"><times id="S5.E13.m1.1.1.1.1.3.3.1.cmml" xref="S5.E13.m1.1.1.1.1.3.3.1"></times><ci id="S5.E13.m1.1.1.1.1.3.3.2.cmml" xref="S5.E13.m1.1.1.1.1.3.3.2">ğ‘Ÿ</ci><ci id="S5.E13.m1.1.1.1.1.3.3.3.cmml" xref="S5.E13.m1.1.1.1.1.3.3.3">ğ‘œ</ci><ci id="S5.E13.m1.1.1.1.1.3.3.4.cmml" xref="S5.E13.m1.1.1.1.1.3.3.4">ğ‘¡</ci><ci id="S5.E13.m1.1.1.1.1.3.3.5.cmml" xref="S5.E13.m1.1.1.1.1.3.3.5">ğ‘</ci><ci id="S5.E13.m1.1.1.1.1.3.3.6.cmml" xref="S5.E13.m1.1.1.1.1.3.3.6">ğ‘¡</ci><ci id="S5.E13.m1.1.1.1.1.3.3.7.cmml" xref="S5.E13.m1.1.1.1.1.3.3.7">ğ‘–</ci><ci id="S5.E13.m1.1.1.1.1.3.3.8.cmml" xref="S5.E13.m1.1.1.1.1.3.3.8">ğ‘œ</ci><ci id="S5.E13.m1.1.1.1.1.3.3.9.cmml" xref="S5.E13.m1.1.1.1.1.3.3.9">ğ‘›</ci></apply></apply><apply id="S5.E13.m1.1.1.1.1.1.cmml" xref="S5.E13.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S5.E13.m1.1.1.1.1.1.2.cmml" xref="S5.E13.m1.1.1.1.1.1">subscript</csymbol><apply id="S5.E13.m1.1.1.1.1.1.1.2.cmml" xref="S5.E13.m1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S5.E13.m1.1.1.1.1.1.1.2.1.cmml" xref="S5.E13.m1.1.1.1.1.1.1.1.2">norm</csymbol><apply id="S5.E13.m1.1.1.1.1.1.1.1.1.cmml" xref="S5.E13.m1.1.1.1.1.1.1.1.1"><times id="S5.E13.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S5.E13.m1.1.1.1.1.1.1.1.1.1"></times><apply id="S5.E13.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S5.E13.m1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S5.E13.m1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S5.E13.m1.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S5.E13.m1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S5.E13.m1.1.1.1.1.1.1.1.1.2.2">ğ‘…</ci><apply id="S5.E13.m1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S5.E13.m1.1.1.1.1.1.1.1.1.2.3"><times id="S5.E13.m1.1.1.1.1.1.1.1.1.2.3.1.cmml" xref="S5.E13.m1.1.1.1.1.1.1.1.1.2.3.1"></times><ci id="S5.E13.m1.1.1.1.1.1.1.1.1.2.3.2.cmml" xref="S5.E13.m1.1.1.1.1.1.1.1.1.2.3.2">ğ‘</ci><ci id="S5.E13.m1.1.1.1.1.1.1.1.1.2.3.3.cmml" xref="S5.E13.m1.1.1.1.1.1.1.1.1.2.3.3">ğ‘Ÿ</ci><ci id="S5.E13.m1.1.1.1.1.1.1.1.1.2.3.4.cmml" xref="S5.E13.m1.1.1.1.1.1.1.1.1.2.3.4">ğ‘’</ci><ci id="S5.E13.m1.1.1.1.1.1.1.1.1.2.3.5.cmml" xref="S5.E13.m1.1.1.1.1.1.1.1.1.2.3.5">ğ‘‘</ci></apply></apply><apply id="S5.E13.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S5.E13.m1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S5.E13.m1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S5.E13.m1.1.1.1.1.1.1.1.1.3">superscript</csymbol><apply id="S5.E13.m1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S5.E13.m1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S5.E13.m1.1.1.1.1.1.1.1.1.3.2.1.cmml" xref="S5.E13.m1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S5.E13.m1.1.1.1.1.1.1.1.1.3.2.2.cmml" xref="S5.E13.m1.1.1.1.1.1.1.1.1.3.2.2">ğ‘…</ci><apply id="S5.E13.m1.1.1.1.1.1.1.1.1.3.2.3.cmml" xref="S5.E13.m1.1.1.1.1.1.1.1.1.3.2.3"><times id="S5.E13.m1.1.1.1.1.1.1.1.1.3.2.3.1.cmml" xref="S5.E13.m1.1.1.1.1.1.1.1.1.3.2.3.1"></times><ci id="S5.E13.m1.1.1.1.1.1.1.1.1.3.2.3.2.cmml" xref="S5.E13.m1.1.1.1.1.1.1.1.1.3.2.3.2">ğ‘”</ci><ci id="S5.E13.m1.1.1.1.1.1.1.1.1.3.2.3.3.cmml" xref="S5.E13.m1.1.1.1.1.1.1.1.1.3.2.3.3">ğ‘¡</ci></apply></apply><apply id="S5.E13.m1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S5.E13.m1.1.1.1.1.1.1.1.1.3.3"><minus id="S5.E13.m1.1.1.1.1.1.1.1.1.3.3.1.cmml" xref="S5.E13.m1.1.1.1.1.1.1.1.1.3.3"></minus><cn type="integer" id="S5.E13.m1.1.1.1.1.1.1.1.1.3.3.2.cmml" xref="S5.E13.m1.1.1.1.1.1.1.1.1.3.3.2">1</cn></apply></apply></apply></apply><cn type="integer" id="S5.E13.m1.1.1.1.1.1.3.cmml" xref="S5.E13.m1.1.1.1.1.1.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.E13.m1.1c">e_{rotation}=\|R_{pred}R_{gt}^{-1}\|_{2},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(13)</span></td>
</tr></tbody>
</table>
<p id="S5.SS2a.p1.3" class="ltx_p"><span id="S5.SS2a.p1.3.1" class="ltx_text" style="font-size:144%;">The head translation error is computed as the mean Euclidean distance of two sequences of head translations. The results are reported in the unit of millimeter.</span></p>
</div>
<div id="S5.SS2a.p2" class="ltx_para">
<p id="S5.SS2a.p2.1" class="ltx_p"><span id="S5.SS2a.p2.1.1" class="ltx_text" style="font-size:144%;">The head pose error calculates the Frobenius norm of the difference between the transformation matrix of the predicted head pose and ground truth head pose, which is given by:</span></p>
<table id="S5.E14" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S5.E14.m1.1" class="ltx_Math" alttext="e_{pose}=\|T_{pred}T_{gt}^{-1}\|_{2}," display="block"><semantics id="S5.E14.m1.1a"><mrow id="S5.E14.m1.1.1.1" xref="S5.E14.m1.1.1.1.1.cmml"><mrow id="S5.E14.m1.1.1.1.1" xref="S5.E14.m1.1.1.1.1.cmml"><msub id="S5.E14.m1.1.1.1.1.3" xref="S5.E14.m1.1.1.1.1.3.cmml"><mi mathsize="144%" id="S5.E14.m1.1.1.1.1.3.2" xref="S5.E14.m1.1.1.1.1.3.2.cmml">e</mi><mrow id="S5.E14.m1.1.1.1.1.3.3" xref="S5.E14.m1.1.1.1.1.3.3.cmml"><mi mathsize="144%" id="S5.E14.m1.1.1.1.1.3.3.2" xref="S5.E14.m1.1.1.1.1.3.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S5.E14.m1.1.1.1.1.3.3.1" xref="S5.E14.m1.1.1.1.1.3.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S5.E14.m1.1.1.1.1.3.3.3" xref="S5.E14.m1.1.1.1.1.3.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S5.E14.m1.1.1.1.1.3.3.1a" xref="S5.E14.m1.1.1.1.1.3.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S5.E14.m1.1.1.1.1.3.3.4" xref="S5.E14.m1.1.1.1.1.3.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S5.E14.m1.1.1.1.1.3.3.1b" xref="S5.E14.m1.1.1.1.1.3.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S5.E14.m1.1.1.1.1.3.3.5" xref="S5.E14.m1.1.1.1.1.3.3.5.cmml">e</mi></mrow></msub><mo mathsize="144%" id="S5.E14.m1.1.1.1.1.2" xref="S5.E14.m1.1.1.1.1.2.cmml">=</mo><msub id="S5.E14.m1.1.1.1.1.1" xref="S5.E14.m1.1.1.1.1.1.cmml"><mrow id="S5.E14.m1.1.1.1.1.1.1.1" xref="S5.E14.m1.1.1.1.1.1.1.2.cmml"><mo maxsize="144%" minsize="144%" id="S5.E14.m1.1.1.1.1.1.1.1.2" xref="S5.E14.m1.1.1.1.1.1.1.2.1.cmml">â€–</mo><mrow id="S5.E14.m1.1.1.1.1.1.1.1.1" xref="S5.E14.m1.1.1.1.1.1.1.1.1.cmml"><msub id="S5.E14.m1.1.1.1.1.1.1.1.1.2" xref="S5.E14.m1.1.1.1.1.1.1.1.1.2.cmml"><mi mathsize="144%" id="S5.E14.m1.1.1.1.1.1.1.1.1.2.2" xref="S5.E14.m1.1.1.1.1.1.1.1.1.2.2.cmml">T</mi><mrow id="S5.E14.m1.1.1.1.1.1.1.1.1.2.3" xref="S5.E14.m1.1.1.1.1.1.1.1.1.2.3.cmml"><mi mathsize="144%" id="S5.E14.m1.1.1.1.1.1.1.1.1.2.3.2" xref="S5.E14.m1.1.1.1.1.1.1.1.1.2.3.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S5.E14.m1.1.1.1.1.1.1.1.1.2.3.1" xref="S5.E14.m1.1.1.1.1.1.1.1.1.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S5.E14.m1.1.1.1.1.1.1.1.1.2.3.3" xref="S5.E14.m1.1.1.1.1.1.1.1.1.2.3.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S5.E14.m1.1.1.1.1.1.1.1.1.2.3.1a" xref="S5.E14.m1.1.1.1.1.1.1.1.1.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S5.E14.m1.1.1.1.1.1.1.1.1.2.3.4" xref="S5.E14.m1.1.1.1.1.1.1.1.1.2.3.4.cmml">e</mi><mo lspace="0em" rspace="0em" id="S5.E14.m1.1.1.1.1.1.1.1.1.2.3.1b" xref="S5.E14.m1.1.1.1.1.1.1.1.1.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S5.E14.m1.1.1.1.1.1.1.1.1.2.3.5" xref="S5.E14.m1.1.1.1.1.1.1.1.1.2.3.5.cmml">d</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S5.E14.m1.1.1.1.1.1.1.1.1.1" xref="S5.E14.m1.1.1.1.1.1.1.1.1.1.cmml">â€‹</mo><msubsup id="S5.E14.m1.1.1.1.1.1.1.1.1.3" xref="S5.E14.m1.1.1.1.1.1.1.1.1.3.cmml"><mi mathsize="144%" id="S5.E14.m1.1.1.1.1.1.1.1.1.3.2.2" xref="S5.E14.m1.1.1.1.1.1.1.1.1.3.2.2.cmml">T</mi><mrow id="S5.E14.m1.1.1.1.1.1.1.1.1.3.2.3" xref="S5.E14.m1.1.1.1.1.1.1.1.1.3.2.3.cmml"><mi mathsize="144%" id="S5.E14.m1.1.1.1.1.1.1.1.1.3.2.3.2" xref="S5.E14.m1.1.1.1.1.1.1.1.1.3.2.3.2.cmml">g</mi><mo lspace="0em" rspace="0em" id="S5.E14.m1.1.1.1.1.1.1.1.1.3.2.3.1" xref="S5.E14.m1.1.1.1.1.1.1.1.1.3.2.3.1.cmml">â€‹</mo><mi mathsize="144%" id="S5.E14.m1.1.1.1.1.1.1.1.1.3.2.3.3" xref="S5.E14.m1.1.1.1.1.1.1.1.1.3.2.3.3.cmml">t</mi></mrow><mrow id="S5.E14.m1.1.1.1.1.1.1.1.1.3.3" xref="S5.E14.m1.1.1.1.1.1.1.1.1.3.3.cmml"><mo mathsize="144%" id="S5.E14.m1.1.1.1.1.1.1.1.1.3.3a" xref="S5.E14.m1.1.1.1.1.1.1.1.1.3.3.cmml">âˆ’</mo><mn mathsize="144%" id="S5.E14.m1.1.1.1.1.1.1.1.1.3.3.2" xref="S5.E14.m1.1.1.1.1.1.1.1.1.3.3.2.cmml">1</mn></mrow></msubsup></mrow><mo maxsize="144%" minsize="144%" id="S5.E14.m1.1.1.1.1.1.1.1.3" xref="S5.E14.m1.1.1.1.1.1.1.2.1.cmml">â€–</mo></mrow><mn mathsize="144%" id="S5.E14.m1.1.1.1.1.1.3" xref="S5.E14.m1.1.1.1.1.1.3.cmml">2</mn></msub></mrow><mo mathsize="144%" id="S5.E14.m1.1.1.1.2" xref="S5.E14.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.E14.m1.1b"><apply id="S5.E14.m1.1.1.1.1.cmml" xref="S5.E14.m1.1.1.1"><eq id="S5.E14.m1.1.1.1.1.2.cmml" xref="S5.E14.m1.1.1.1.1.2"></eq><apply id="S5.E14.m1.1.1.1.1.3.cmml" xref="S5.E14.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S5.E14.m1.1.1.1.1.3.1.cmml" xref="S5.E14.m1.1.1.1.1.3">subscript</csymbol><ci id="S5.E14.m1.1.1.1.1.3.2.cmml" xref="S5.E14.m1.1.1.1.1.3.2">ğ‘’</ci><apply id="S5.E14.m1.1.1.1.1.3.3.cmml" xref="S5.E14.m1.1.1.1.1.3.3"><times id="S5.E14.m1.1.1.1.1.3.3.1.cmml" xref="S5.E14.m1.1.1.1.1.3.3.1"></times><ci id="S5.E14.m1.1.1.1.1.3.3.2.cmml" xref="S5.E14.m1.1.1.1.1.3.3.2">ğ‘</ci><ci id="S5.E14.m1.1.1.1.1.3.3.3.cmml" xref="S5.E14.m1.1.1.1.1.3.3.3">ğ‘œ</ci><ci id="S5.E14.m1.1.1.1.1.3.3.4.cmml" xref="S5.E14.m1.1.1.1.1.3.3.4">ğ‘ </ci><ci id="S5.E14.m1.1.1.1.1.3.3.5.cmml" xref="S5.E14.m1.1.1.1.1.3.3.5">ğ‘’</ci></apply></apply><apply id="S5.E14.m1.1.1.1.1.1.cmml" xref="S5.E14.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S5.E14.m1.1.1.1.1.1.2.cmml" xref="S5.E14.m1.1.1.1.1.1">subscript</csymbol><apply id="S5.E14.m1.1.1.1.1.1.1.2.cmml" xref="S5.E14.m1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S5.E14.m1.1.1.1.1.1.1.2.1.cmml" xref="S5.E14.m1.1.1.1.1.1.1.1.2">norm</csymbol><apply id="S5.E14.m1.1.1.1.1.1.1.1.1.cmml" xref="S5.E14.m1.1.1.1.1.1.1.1.1"><times id="S5.E14.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S5.E14.m1.1.1.1.1.1.1.1.1.1"></times><apply id="S5.E14.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S5.E14.m1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S5.E14.m1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S5.E14.m1.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S5.E14.m1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S5.E14.m1.1.1.1.1.1.1.1.1.2.2">ğ‘‡</ci><apply id="S5.E14.m1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S5.E14.m1.1.1.1.1.1.1.1.1.2.3"><times id="S5.E14.m1.1.1.1.1.1.1.1.1.2.3.1.cmml" xref="S5.E14.m1.1.1.1.1.1.1.1.1.2.3.1"></times><ci id="S5.E14.m1.1.1.1.1.1.1.1.1.2.3.2.cmml" xref="S5.E14.m1.1.1.1.1.1.1.1.1.2.3.2">ğ‘</ci><ci id="S5.E14.m1.1.1.1.1.1.1.1.1.2.3.3.cmml" xref="S5.E14.m1.1.1.1.1.1.1.1.1.2.3.3">ğ‘Ÿ</ci><ci id="S5.E14.m1.1.1.1.1.1.1.1.1.2.3.4.cmml" xref="S5.E14.m1.1.1.1.1.1.1.1.1.2.3.4">ğ‘’</ci><ci id="S5.E14.m1.1.1.1.1.1.1.1.1.2.3.5.cmml" xref="S5.E14.m1.1.1.1.1.1.1.1.1.2.3.5">ğ‘‘</ci></apply></apply><apply id="S5.E14.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S5.E14.m1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S5.E14.m1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S5.E14.m1.1.1.1.1.1.1.1.1.3">superscript</csymbol><apply id="S5.E14.m1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S5.E14.m1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S5.E14.m1.1.1.1.1.1.1.1.1.3.2.1.cmml" xref="S5.E14.m1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S5.E14.m1.1.1.1.1.1.1.1.1.3.2.2.cmml" xref="S5.E14.m1.1.1.1.1.1.1.1.1.3.2.2">ğ‘‡</ci><apply id="S5.E14.m1.1.1.1.1.1.1.1.1.3.2.3.cmml" xref="S5.E14.m1.1.1.1.1.1.1.1.1.3.2.3"><times id="S5.E14.m1.1.1.1.1.1.1.1.1.3.2.3.1.cmml" xref="S5.E14.m1.1.1.1.1.1.1.1.1.3.2.3.1"></times><ci id="S5.E14.m1.1.1.1.1.1.1.1.1.3.2.3.2.cmml" xref="S5.E14.m1.1.1.1.1.1.1.1.1.3.2.3.2">ğ‘”</ci><ci id="S5.E14.m1.1.1.1.1.1.1.1.1.3.2.3.3.cmml" xref="S5.E14.m1.1.1.1.1.1.1.1.1.3.2.3.3">ğ‘¡</ci></apply></apply><apply id="S5.E14.m1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S5.E14.m1.1.1.1.1.1.1.1.1.3.3"><minus id="S5.E14.m1.1.1.1.1.1.1.1.1.3.3.1.cmml" xref="S5.E14.m1.1.1.1.1.1.1.1.1.3.3"></minus><cn type="integer" id="S5.E14.m1.1.1.1.1.1.1.1.1.3.3.2.cmml" xref="S5.E14.m1.1.1.1.1.1.1.1.1.3.3.2">1</cn></apply></apply></apply></apply><cn type="integer" id="S5.E14.m1.1.1.1.1.1.3.cmml" xref="S5.E14.m1.1.1.1.1.1.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.E14.m1.1c">e_{pose}=\|T_{pred}T_{gt}^{-1}\|_{2},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(14)</span></td>
</tr></tbody>
</table>
</div>
</section>
<section id="S5.SS3a" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="font-size:144%;">
<span class="ltx_tag ltx_tag_subsection">S5.3 </span>Human Mesh Recovery from Egocentric Views</h3>

<div id="S5.SS3a.p1" class="ltx_para">
<p id="S5.SS3a.p1.1" class="ltx_p"><span id="S5.SS3a.p1.1.1" class="ltx_text" style="font-size:144%;">We simulate the data collection process of EgobodyÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.SS3a.p1.1.2.1" class="ltx_text" style="font-size:144%;">[</span><a href="#bib.bib125" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">125</span></a><span id="S5.SS3a.p1.1.3.2" class="ltx_text" style="font-size:144%;">]</span></cite><span id="S5.SS3a.p1.1.4" class="ltx_text" style="font-size:144%;"> and let two virtual humans walk in the scanned scene meshes from Egobody. We randomly sample </span><span id="S5.SS3a.p1.1.5" class="ltx_text ltx_font_italic" style="font-size:144%;">gender</span><span id="S5.SS3a.p1.1.6" class="ltx_text" style="font-size:144%;">, </span><span id="S5.SS3a.p1.1.7" class="ltx_text ltx_font_italic" style="font-size:144%;">body shape</span><span id="S5.SS3a.p1.1.8" class="ltx_text" style="font-size:144%;">, and </span><span id="S5.SS3a.p1.1.9" class="ltx_text ltx_font_italic" style="font-size:144%;">initial body pose</span><span id="S5.SS3a.p1.1.10" class="ltx_text" style="font-size:144%;"> and synthesize human motions with our proposed generative human motion model to increase data diversity.</span></p>
</div>
<div id="S5.SS3a.p2" class="ltx_para">
<p id="S5.SS3a.p2.1" class="ltx_p"><span id="S5.SS3a.p2.1.1" class="ltx_text" style="font-size:144%;">The egocentric camera is attached to both humans and we render the interactee from the camera wearerâ€™s egocentric view. Camera intrinsic is set similarly to the real-world camera. For depth data generation, we omit the clothing because the simulated depth sensor noise will remove detail. For RGB data generation, to further increase data diversity and close the sim-real gap, we randomly sample body texture and 3D textured clothing meshes from BEDLAMÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S5.SS3a.p2.1.2.1" class="ltx_text" style="font-size:144%;">[</span><a href="#bib.bib9" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">9</span></a><span id="S5.SS3a.p2.1.3.2" class="ltx_text" style="font-size:144%;">]</span></cite><span id="S5.SS3a.p2.1.4" class="ltx_text" style="font-size:144%;"> and perform automated clothing simulation (</span><a href="#S3.SS2a" title="S3.2 Automated Clothing Simulation â€£ S3 Egocentric Synthetic Data Generation â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref" style="font-size:144%;"><span class="ltx_text ltx_ref_tag">Sec.</span>Â <span class="ltx_text ltx_ref_tag">S3.2</span></a><span id="S5.SS3a.p2.1.5" class="ltx_text" style="font-size:144%;">) given arbitrary synthesized human motion sequences from our generative human motion model. In addition, we adopt random lighting in the rendering. In total, we synthesized 105k depth images and 300k RGB images with diverse body shapes, poses, skin textures, and clothing, along with ground-truth SMPL-X annotations. We will release both of our synthetic datasets as a complement to Egobody.</span></p>
</div>
<section id="S5.SS3.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph" style="font-size:144%;">Qualitative results.</h4>

<div id="S5.SS3.SSS0.Px1.p1" class="ltx_para">
<p id="S5.SS3.SSS0.Px1.p1.1" class="ltx_p"><span id="S5.SS3.SSS0.Px1.p1.1.1" class="ltx_text" style="font-size:144%;">We visualize our qualitative results for HMR from depth inÂ </span><a href="#S5.F10.sf1" title="In Figure S10 â€£ Qualitative results. â€£ S5.3 Human Mesh Recovery from Egocentric Views â€£ S5 Egocentric Perception Tasks â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref" style="font-size:144%;"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">10(a)</span></a><span id="S5.SS3.SSS0.Px1.p1.1.2" class="ltx_text" style="font-size:144%;"> and HMR from RGB inÂ </span><a href="#S5.F10.sf2" title="In Figure S10 â€£ Qualitative results. â€£ S5.3 Human Mesh Recovery from Egocentric Views â€£ S5 Egocentric Perception Tasks â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref" style="font-size:144%;"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">10(b)</span></a><span id="S5.SS3.SSS0.Px1.p1.1.3" class="ltx_text" style="font-size:144%;"> on real-world test data. With large-scale synthetic data from </span><span id="S5.SS3.SSS0.Px1.p1.1.4" class="ltx_text ltx_font_italic" style="font-size:144%;">EgoGen</span><span id="S5.SS3.SSS0.Px1.p1.1.5" class="ltx_text" style="font-size:144%;">, we can compensate for the lack of real-world data and improve the performance of current models. â€œ*-scratchâ€ denotes models trained only with limited real-world data. â€œ*-ftâ€ denotes models pretrained with our large-scale synthetic data and then finetuned with real-world data.</span></p>
</div>
<figure id="S5.F10" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S5.F10.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2401.08739/assets/x5.png" id="S5.F10.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="528" height="370" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering" style="font-size:144%;"><span class="ltx_tag ltx_tag_figure"><span id="S5.F10.sf1.4.1.1" class="ltx_text" style="font-size:63%;">(a)</span> </span><span id="S5.F10.sf1.5.2" class="ltx_text" style="font-size:63%;">Human Mesh Recovery from Depth Images</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S5.F10.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2401.08739/assets/x6.png" id="S5.F10.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="528" height="331" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering" style="font-size:144%;"><span class="ltx_tag ltx_tag_figure"><span id="S5.F10.sf2.4.1.1" class="ltx_text" style="font-size:63%;">(b)</span> </span><span id="S5.F10.sf2.5.2" class="ltx_text" style="font-size:63%;">Human Mesh Recovery from RGB Images</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering" style="font-size:144%;"><span class="ltx_tag ltx_tag_figure"><span id="S5.F10.4.1.1" class="ltx_text" style="font-size:63%;">Figure S10</span>: </span><span id="S5.F10.5.2" class="ltx_text" style="font-size:63%;">Qualitative results of HMR on EgoBody test set. The body mesh color of the last two columns denotes the per-vertex error between the predicted body and the ground truth.</span></figcaption>
</figure>
</section>
<section id="S5.SS3.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph" style="font-size:144%;">Synthetic Data Samples.</h4>

<div id="S5.SS3.SSS0.Px2.p1" class="ltx_para">
<p id="S5.SS3.SSS0.Px2.p1.1" class="ltx_p"><span id="S5.SS3.SSS0.Px2.p1.1.1" class="ltx_text" style="font-size:144%;">We show some examples of synthetic data from </span><span id="S5.SS3.SSS0.Px2.p1.1.2" class="ltx_text ltx_font_italic" style="font-size:144%;">EgoGen</span><span id="S5.SS3.SSS0.Px2.p1.1.3" class="ltx_text" style="font-size:144%;">Â inÂ </span><a href="#S5.F11" title="In Synthetic Data Samples. â€£ S5.3 Human Mesh Recovery from Egocentric Views â€£ S5 Egocentric Perception Tasks â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref" style="font-size:144%;"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">S11</span></a><span id="S5.SS3.SSS0.Px2.p1.1.4" class="ltx_text" style="font-size:144%;">.</span></p>
</div>
<figure id="S5.F11" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S5.F11.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2401.08739/assets/x7.png" id="S5.F11.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="528" height="378" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering" style="font-size:144%;"><span class="ltx_tag ltx_tag_figure"><span id="S5.F11.sf1.4.1.1" class="ltx_text" style="font-size:63%;">(a)</span> </span><span id="S5.F11.sf1.5.2" class="ltx_text" style="font-size:63%;">Our synthetic depth images.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S5.F11.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2401.08739/assets/x8.png" id="S5.F11.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="528" height="332" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering" style="font-size:144%;"><span class="ltx_tag ltx_tag_figure"><span id="S5.F11.sf2.4.1.1" class="ltx_text" style="font-size:63%;">(b)</span> </span><span id="S5.F11.sf2.5.2" class="ltx_text" style="font-size:63%;">Our synthetic RGB images.</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering" style="font-size:144%;"><span class="ltx_tag ltx_tag_figure"><span id="S5.F11.6.1.1" class="ltx_text" style="font-size:63%;">Figure S11</span>: </span><span id="S5.F11.7.2" class="ltx_text" style="font-size:63%;">Synthetic data samples from <span id="S5.F11.7.2.1" class="ltx_text ltx_font_italic">EgoGen</span>.</span></figcaption>
</figure>
</section>
<section id="S5.SS3.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph" style="font-size:144%;">Synthetic Dataset Statistics.</h4>

<div id="S5.SS3.SSS0.Px3.p1" class="ltx_para">
<p id="S5.SS3.SSS0.Px3.p1.2" class="ltx_p"><span id="S5.SS3.SSS0.Px3.p1.2.1" class="ltx_text" style="font-size:144%;">The generated depth dataset consists of 105000 depth images with 47107 male and 57893 female images. The generated RGB dataset consists of 301073 depth images with 147862 male and 153211 female images. Both datasets cover a large range of indoor interaction distances ranging from </span><math id="S5.SS3.SSS0.Px3.p1.1.m1.1" class="ltx_Math" alttext="0.60m" display="inline"><semantics id="S5.SS3.SSS0.Px3.p1.1.m1.1a"><mrow id="S5.SS3.SSS0.Px3.p1.1.m1.1.1" xref="S5.SS3.SSS0.Px3.p1.1.m1.1.1.cmml"><mn mathsize="144%" id="S5.SS3.SSS0.Px3.p1.1.m1.1.1.2" xref="S5.SS3.SSS0.Px3.p1.1.m1.1.1.2.cmml">0.60</mn><mo lspace="0em" rspace="0em" id="S5.SS3.SSS0.Px3.p1.1.m1.1.1.1" xref="S5.SS3.SSS0.Px3.p1.1.m1.1.1.1.cmml">â€‹</mo><mi mathsize="144%" id="S5.SS3.SSS0.Px3.p1.1.m1.1.1.3" xref="S5.SS3.SSS0.Px3.p1.1.m1.1.1.3.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS0.Px3.p1.1.m1.1b"><apply id="S5.SS3.SSS0.Px3.p1.1.m1.1.1.cmml" xref="S5.SS3.SSS0.Px3.p1.1.m1.1.1"><times id="S5.SS3.SSS0.Px3.p1.1.m1.1.1.1.cmml" xref="S5.SS3.SSS0.Px3.p1.1.m1.1.1.1"></times><cn type="float" id="S5.SS3.SSS0.Px3.p1.1.m1.1.1.2.cmml" xref="S5.SS3.SSS0.Px3.p1.1.m1.1.1.2">0.60</cn><ci id="S5.SS3.SSS0.Px3.p1.1.m1.1.1.3.cmml" xref="S5.SS3.SSS0.Px3.p1.1.m1.1.1.3">ğ‘š</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS0.Px3.p1.1.m1.1c">0.60m</annotation></semantics></math><span id="S5.SS3.SSS0.Px3.p1.2.2" class="ltx_text" style="font-size:144%;"> to </span><math id="S5.SS3.SSS0.Px3.p1.2.m2.1" class="ltx_Math" alttext="5.02m" display="inline"><semantics id="S5.SS3.SSS0.Px3.p1.2.m2.1a"><mrow id="S5.SS3.SSS0.Px3.p1.2.m2.1.1" xref="S5.SS3.SSS0.Px3.p1.2.m2.1.1.cmml"><mn mathsize="144%" id="S5.SS3.SSS0.Px3.p1.2.m2.1.1.2" xref="S5.SS3.SSS0.Px3.p1.2.m2.1.1.2.cmml">5.02</mn><mo lspace="0em" rspace="0em" id="S5.SS3.SSS0.Px3.p1.2.m2.1.1.1" xref="S5.SS3.SSS0.Px3.p1.2.m2.1.1.1.cmml">â€‹</mo><mi mathsize="144%" id="S5.SS3.SSS0.Px3.p1.2.m2.1.1.3" xref="S5.SS3.SSS0.Px3.p1.2.m2.1.1.3.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS0.Px3.p1.2.m2.1b"><apply id="S5.SS3.SSS0.Px3.p1.2.m2.1.1.cmml" xref="S5.SS3.SSS0.Px3.p1.2.m2.1.1"><times id="S5.SS3.SSS0.Px3.p1.2.m2.1.1.1.cmml" xref="S5.SS3.SSS0.Px3.p1.2.m2.1.1.1"></times><cn type="float" id="S5.SS3.SSS0.Px3.p1.2.m2.1.1.2.cmml" xref="S5.SS3.SSS0.Px3.p1.2.m2.1.1.2">5.02</cn><ci id="S5.SS3.SSS0.Px3.p1.2.m2.1.1.3.cmml" xref="S5.SS3.SSS0.Px3.p1.2.m2.1.1.3">ğ‘š</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS0.Px3.p1.2.m2.1c">5.02m</annotation></semantics></math><span id="S5.SS3.SSS0.Px3.p1.2.3" class="ltx_text" style="font-size:144%;">. </span><a href="#S5.F12.sf1" title="In Figure S12 â€£ Synthetic Dataset Statistics. â€£ S5.3 Human Mesh Recovery from Egocentric Views â€£ S5 Egocentric Perception Tasks â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref" style="font-size:144%;"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">12(a)</span></a><span id="S5.SS3.SSS0.Px3.p1.2.4" class="ltx_text" style="font-size:144%;"> shows the distribution of the interaction distance of the depth dataset andÂ </span><a href="#S5.F12.sf2" title="In Figure S12 â€£ Synthetic Dataset Statistics. â€£ S5.3 Human Mesh Recovery from Egocentric Views â€£ S5 Egocentric Perception Tasks â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref" style="font-size:144%;"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">12(b)</span></a><span id="S5.SS3.SSS0.Px3.p1.2.5" class="ltx_text" style="font-size:144%;"> shows the distribution of the RGB dataset.</span></p>
</div>
<figure id="S5.F12" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S5.F12.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2401.08739/assets/images/depth_dist.png" id="S5.F12.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="583" height="389" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering" style="font-size:144%;"><span class="ltx_tag ltx_tag_figure"><span id="S5.F12.sf1.4.1.1" class="ltx_text" style="font-size:63%;">(a)</span> </span><span id="S5.F12.sf1.5.2" class="ltx_text" style="font-size:63%;">3d Distance on depth images.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S5.F12.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2401.08739/assets/images/rgb_dist.png" id="S5.F12.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="583" height="389" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering" style="font-size:144%;"><span class="ltx_tag ltx_tag_figure"><span id="S5.F12.sf2.4.1.1" class="ltx_text" style="font-size:63%;">(b)</span> </span><span id="S5.F12.sf2.5.2" class="ltx_text" style="font-size:63%;">3d Distance on RGB images.</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering" style="font-size:144%;"><span class="ltx_tag ltx_tag_figure"><span id="S5.F12.6.1.1" class="ltx_text" style="font-size:63%;">Figure S12</span>: </span><span id="S5.F12.7.2" class="ltx_text" style="font-size:63%;">Interaction Distance of synthetic samples from <span id="S5.F12.7.2.1" class="ltx_text ltx_font_italic">EgoGen</span>.</span></figcaption>
</figure>
<div id="S5.SS3.SSS0.Px3.p2" class="ltx_para">
<p id="S5.SS3.SSS0.Px3.p2.1" class="ltx_p"><span id="S5.SS3.SSS0.Px3.p2.1.1" class="ltx_text" style="font-size:144%;">Additionally, we consider two types of â€œinvisibilityâ€ of the joints: frame-wise invisibility and joint-wise invisibility ratio. The frame-wise invisibility ratio calculates the percentage of joints that are not on the image plane among all body joints. The joint-wise invisibility ratio calculates the ratio of frames when the joint is
out of the image plane among all frames.</span></p>
</div>
<figure id="S5.F13" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S5.F13.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2401.08739/assets/x9.png" id="S5.F13.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="448" height="305" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering" style="font-size:144%;"><span class="ltx_tag ltx_tag_figure"><span id="S5.F13.sf1.4.1.1" class="ltx_text" style="font-size:63%;">(a)</span> </span><span id="S5.F13.sf1.5.2" class="ltx_text" style="font-size:63%;">Frame-wise invisibility on depth images.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S5.F13.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2401.08739/assets/x10.png" id="S5.F13.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="450" height="333" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering" style="font-size:144%;"><span class="ltx_tag ltx_tag_figure"><span id="S5.F13.sf2.4.1.1" class="ltx_text" style="font-size:63%;">(b)</span> </span><span id="S5.F13.sf2.5.2" class="ltx_text" style="font-size:63%;">Joint-wise invisibility on depth images.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S5.F13.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2401.08739/assets/x11.png" id="S5.F13.sf3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="450" height="296" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering" style="font-size:144%;"><span class="ltx_tag ltx_tag_figure"><span id="S5.F13.sf3.4.1.1" class="ltx_text" style="font-size:63%;">(c)</span> </span><span id="S5.F13.sf3.5.2" class="ltx_text" style="font-size:63%;">Frame-wise invisibility on RGB images.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S5.F13.sf4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2401.08739/assets/x12.png" id="S5.F13.sf4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="448" height="344" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering" style="font-size:144%;"><span class="ltx_tag ltx_tag_figure"><span id="S5.F13.sf4.4.1.1" class="ltx_text" style="font-size:63%;">(d)</span> </span><span id="S5.F13.sf4.5.2" class="ltx_text" style="font-size:63%;">Joint-wise invisibility on RGB images.</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering" style="font-size:144%;"><span class="ltx_tag ltx_tag_figure"><span id="S5.F13.4.1.1" class="ltx_text" style="font-size:63%;">Figure S13</span>: </span><span id="S5.F13.5.2" class="ltx_text" style="font-size:63%;">Invisibility Statistics.</span></figcaption>
</figure>
<div id="S5.SS3.SSS0.Px3.p3" class="ltx_para">
<p id="S5.SS3.SSS0.Px3.p3.3" class="ltx_p"><span id="S5.SS3.SSS0.Px3.p3.3.1" class="ltx_text" style="font-size:144%;">An analysis of the invisibility distribution of the depth dataset and the RGB depth distribution can be seen inÂ </span><a href="#S5.F13" title="In Synthetic Dataset Statistics. â€£ S5.3 Human Mesh Recovery from Egocentric Views â€£ S5 Egocentric Perception Tasks â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref" style="font-size:144%;"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">S13</span></a><span id="S5.SS3.SSS0.Px3.p3.3.2" class="ltx_text" style="font-size:144%;">. Due to the different camera intrinsic of depth and RGB sensor, the invisibility distribution is different. FromÂ </span><a href="#S5.F13.sf1" title="In Figure S13 â€£ Synthetic Dataset Statistics. â€£ S5.3 Human Mesh Recovery from Egocentric Views â€£ S5 Egocentric Perception Tasks â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref" style="font-size:144%;"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">13(a)</span></a><span id="S5.SS3.SSS0.Px3.p3.3.3" class="ltx_text" style="font-size:144%;">, we can see that over </span><math id="S5.SS3.SSS0.Px3.p3.1.m1.1" class="ltx_Math" alttext="79\%" display="inline"><semantics id="S5.SS3.SSS0.Px3.p3.1.m1.1a"><mrow id="S5.SS3.SSS0.Px3.p3.1.m1.1.1" xref="S5.SS3.SSS0.Px3.p3.1.m1.1.1.cmml"><mn mathsize="144%" id="S5.SS3.SSS0.Px3.p3.1.m1.1.1.2" xref="S5.SS3.SSS0.Px3.p3.1.m1.1.1.2.cmml">79</mn><mo mathsize="144%" id="S5.SS3.SSS0.Px3.p3.1.m1.1.1.1" xref="S5.SS3.SSS0.Px3.p3.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS0.Px3.p3.1.m1.1b"><apply id="S5.SS3.SSS0.Px3.p3.1.m1.1.1.cmml" xref="S5.SS3.SSS0.Px3.p3.1.m1.1.1"><csymbol cd="latexml" id="S5.SS3.SSS0.Px3.p3.1.m1.1.1.1.cmml" xref="S5.SS3.SSS0.Px3.p3.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S5.SS3.SSS0.Px3.p3.1.m1.1.1.2.cmml" xref="S5.SS3.SSS0.Px3.p3.1.m1.1.1.2">79</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS0.Px3.p3.1.m1.1c">79\%</annotation></semantics></math><span id="S5.SS3.SSS0.Px3.p3.3.4" class="ltx_text" style="font-size:144%;"> of the depth frame contains more than </span><math id="S5.SS3.SSS0.Px3.p3.2.m2.1" class="ltx_Math" alttext="90\%" display="inline"><semantics id="S5.SS3.SSS0.Px3.p3.2.m2.1a"><mrow id="S5.SS3.SSS0.Px3.p3.2.m2.1.1" xref="S5.SS3.SSS0.Px3.p3.2.m2.1.1.cmml"><mn mathsize="144%" id="S5.SS3.SSS0.Px3.p3.2.m2.1.1.2" xref="S5.SS3.SSS0.Px3.p3.2.m2.1.1.2.cmml">90</mn><mo mathsize="144%" id="S5.SS3.SSS0.Px3.p3.2.m2.1.1.1" xref="S5.SS3.SSS0.Px3.p3.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS0.Px3.p3.2.m2.1b"><apply id="S5.SS3.SSS0.Px3.p3.2.m2.1.1.cmml" xref="S5.SS3.SSS0.Px3.p3.2.m2.1.1"><csymbol cd="latexml" id="S5.SS3.SSS0.Px3.p3.2.m2.1.1.1.cmml" xref="S5.SS3.SSS0.Px3.p3.2.m2.1.1.1">percent</csymbol><cn type="integer" id="S5.SS3.SSS0.Px3.p3.2.m2.1.1.2.cmml" xref="S5.SS3.SSS0.Px3.p3.2.m2.1.1.2">90</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS0.Px3.p3.2.m2.1c">90\%</annotation></semantics></math><span id="S5.SS3.SSS0.Px3.p3.3.5" class="ltx_text" style="font-size:144%;"> joints. This means most depth images contain the full body. While fromÂ </span><a href="#S5.F13.sf3" title="In Figure S13 â€£ Synthetic Dataset Statistics. â€£ S5.3 Human Mesh Recovery from Egocentric Views â€£ S5 Egocentric Perception Tasks â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref" style="font-size:144%;"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">13(c)</span></a><span id="S5.SS3.SSS0.Px3.p3.3.6" class="ltx_text" style="font-size:144%;"> we can see that the RGB dataset yields higher invisibility. The detailed invisibility of the joints is shown inÂ </span><a href="#S5.F13.sf4" title="In Figure S13 â€£ Synthetic Dataset Statistics. â€£ S5.3 Human Mesh Recovery from Egocentric Views â€£ S5 Egocentric Perception Tasks â€£ EgoGen: An Egocentric Synthetic Data Generator" class="ltx_ref" style="font-size:144%;"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">13(d)</span></a><span id="S5.SS3.SSS0.Px3.p3.3.7" class="ltx_text" style="font-size:144%;">. It illustrates that even though RGB images have a higher invisibility, the most frequently missing joints are the upper or lower part of people (eyes and toes). In more than </span><math id="S5.SS3.SSS0.Px3.p3.3.m3.1" class="ltx_Math" alttext="85\%" display="inline"><semantics id="S5.SS3.SSS0.Px3.p3.3.m3.1a"><mrow id="S5.SS3.SSS0.Px3.p3.3.m3.1.1" xref="S5.SS3.SSS0.Px3.p3.3.m3.1.1.cmml"><mn mathsize="144%" id="S5.SS3.SSS0.Px3.p3.3.m3.1.1.2" xref="S5.SS3.SSS0.Px3.p3.3.m3.1.1.2.cmml">85</mn><mo mathsize="144%" id="S5.SS3.SSS0.Px3.p3.3.m3.1.1.1" xref="S5.SS3.SSS0.Px3.p3.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.SSS0.Px3.p3.3.m3.1b"><apply id="S5.SS3.SSS0.Px3.p3.3.m3.1.1.cmml" xref="S5.SS3.SSS0.Px3.p3.3.m3.1.1"><csymbol cd="latexml" id="S5.SS3.SSS0.Px3.p3.3.m3.1.1.1.cmml" xref="S5.SS3.SSS0.Px3.p3.3.m3.1.1.1">percent</csymbol><cn type="integer" id="S5.SS3.SSS0.Px3.p3.3.m3.1.1.2.cmml" xref="S5.SS3.SSS0.Px3.p3.3.m3.1.1.2">85</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.SSS0.Px3.p3.3.m3.1c">85\%</annotation></semantics></math><span id="S5.SS3.SSS0.Px3.p3.3.8" class="ltx_text" style="font-size:144%;"> of the images, the pelvis joint can be found.</span></p>
</div>
</section>
<section id="S5.SS3.SSS0.Px4" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph" style="font-size:144%;">Training Details.</h4>

<div id="S5.SS3.SSS0.Px4.p1" class="ltx_para">
<p id="S5.SS3.SSS0.Px4.p1.1" class="ltx_p"><span id="S5.SS3.SSS0.Px4.p1.1.1" class="ltx_text" style="font-size:144%;">We use data augmentation on the training dataset besides adding the motion blur. These methods include using different kinds of image compression, brightness and contrast modification, noise addition, gamma, hue and saturation modification, conversion to grayscale, and downscaling techniques. During training, we set the batch size to 64 for the training on the depth dataset and 128 for the training on the RGB dataset. We use the AdamW Optimizer in the training process.</span></p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2401.08738" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2401.08739" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2401.08739">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2401.08739" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2401.08740" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Tue Feb 27 09:16:37 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
