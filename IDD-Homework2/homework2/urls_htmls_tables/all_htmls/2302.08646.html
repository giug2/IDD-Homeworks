<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2302.08646] AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving</title><meta property="og:description" content="Object detection with on-board sensors (e.g., lidar, radar, and camera) play a crucial role in autonomous driving (AD), and these sensors complement each other in modalities. While crowdsensing may potentially exploit …">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2302.08646">

<!--Generated on Fri Mar  1 01:58:33 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="Autonomous driving,  autonomous vehicle, 
object detection,  federated learning,  crowdsensing,  multimodal learning.">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Tianyue Zheng<sup id="id9.9.id1" class="ltx_sup"><span id="id9.9.id1.1" class="ltx_text ltx_font_italic">1</span></sup> Ang Li<sup id="id10.10.id2" class="ltx_sup">2</sup> Zhe Chen<sup id="id11.11.id3" class="ltx_sup"><span id="id11.11.id3.1" class="ltx_text ltx_font_italic">3∗</span></sup> Hongbo Wang<sup id="id12.12.id4" class="ltx_sup"><span id="id12.12.id4.1" class="ltx_text ltx_font_italic">1</span></sup> Jun Luo<sup id="id13.13.id5" class="ltx_sup"><span id="id13.13.id5.1" class="ltx_text ltx_font_italic">1</span></sup>
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id8.8.3" class="ltx_text ltx_affiliation_institution">
<sup id="id8.8.3.1" class="ltx_sup">1</sup>School of Computer Science and Engineering, Nanyang Technological University (NTU) <span id="id8.8.3.2" class="ltx_text ltx_affiliation_country">Singapore</span> 
<br class="ltx_break"><sup id="id8.8.3.3" class="ltx_sup">2</sup>Department of Electrical and Computer Engineering, University of Maryland <span id="id8.8.3.4" class="ltx_text ltx_affiliation_country">USA</span> 
<br class="ltx_break"><sup id="id8.8.3.5" class="ltx_sup">3</sup>AIWiSe, China-Singapore International Joint Research Institute <span id="id8.8.3.6" class="ltx_text ltx_affiliation_country">China</span> 
<br class="ltx_break">Email: {tianyue002, junluo}@ntu.edu.sg, angli@umd.edu,
chenz@csijri.com
</span>
</span></span></span>
</div>
<div class="ltx_dates">(2023)</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p id="id14.id1" class="ltx_p">Object detection with on-board sensors (e.g., lidar, radar, and camera) play a crucial role in <span id="id14.id1.1" class="ltx_text ltx_font_italic">autonomous driving</span> (AD), and these sensors complement each other in modalities. While crowdsensing may potentially exploit these sensors (of huge quantity) to derive more comprehensive knowledge, <span id="id14.id1.2" class="ltx_text ltx_font_italic">federated learning</span> (FL) appears to be the necessary tool to reach this potential: it enables <span id="id14.id1.3" class="ltx_text ltx_font_italic">autonomous vehicle</span>s (AVs) to train machine learning models without explicitly sharing raw sensory data. However, the multimodal sensors introduce various data heterogeneity across distributed AVs (e.g., label quantity skews and varied modalities), posing critical challenges to effective FL. To this end, we present <span id="id14.id1.4" class="ltx_text ltx_font_bold">AutoFed</span> as a heterogeneity-aware FL framework to fully exploit multimodal sensory data on AVs and thus enable robust AD. Specifically, we first propose a novel model leveraging pseudo labeling to avoid mistakenly treating unlabeled objects as the background. We also propose an autoencoder-based data imputation method to fill missing data modality (of certain AVs) with the available ones. To further reconcile the heterogeneity, we finally present a client selection mechanism exploiting the similarities among client models to improve both training stability and convergence rate. Our experiments on benchmark dataset confirm that AutoFed substantially improves over status quo approaches in both precision and recall, while demonstrating strong robustness to adverse weather conditions.</p>
</div>
<div class="ltx_keywords">Autonomous driving, autonomous vehicle,
object detection, federated learning, crowdsensing, multimodal learning.
</div>
<div class="ltx_acknowledgements">* is the correspondence author. © Tianyue Zheng, Ang Li, Zhe Chen, Hongbo Wang, and Jun Luo — ACM 2023. This is the author’s version of the work. It is posted here for your personal use. Not for redistribution. The definitive Version of Record is accepted by ACM MobiCom 2023. 
</div>
<span id="id1" class="ltx_note ltx_note_frontmatter ltx_role_copyright"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">copyright: </span>acmcopyright</span></span></span><span id="id2" class="ltx_note ltx_note_frontmatter ltx_role_journalyear"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">journalyear: </span>2023</span></span></span><span id="id3" class="ltx_note ltx_note_frontmatter ltx_role_doi"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">doi: </span>XXX.XXX</span></span></span><span id="id4" class="ltx_note ltx_note_frontmatter ltx_role_conference"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">conference: </span>The 29th Annual International Conference on Mobile Computing and Networking; October 2-6, 2023; Madrid, Spain</span></span></span><span id="id5" class="ltx_note ltx_note_frontmatter ltx_role_booktitle"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">booktitle: </span>The 29th Annual International Conference on Mobile Computing and Networking (ACM MobiCom’23), October 2-6, 2023, Madrid, Spain</span></span></span><span id="id6" class="ltx_note ltx_note_frontmatter ltx_role_price"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">price: </span>15.00</span></span></span><span id="id7" class="ltx_note ltx_note_frontmatter ltx_role_isbn"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">isbn: </span>978-1-4503-XXXX-X/18/06</span></span></span><span id="id8" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Human-centered computing Ubiquitous and mobile computing</span></span></span><span id="id9" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Computing methodologies Machine learning</span></span></span>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Undergoing worldwide rapid development <cite class="ltx_cite ltx_citemacro_citep">(Tesla, <a href="#bib.bib57" title="" class="ltx_ref">2022</a>; Waymo, <a href="#bib.bib67" title="" class="ltx_ref">2022</a>; Uber Technologies Inc., <a href="#bib.bib60" title="" class="ltx_ref">2022</a>)</cite>, <span id="S1.p1.1.1" class="ltx_text ltx_font_italic">autonomous driving</span> (AD) aims to offer a wide range of benefits including better safety, less harmful emissions, increased lane capacity, and less travel time <cite class="ltx_cite ltx_citemacro_citep">(Shaheen and Bouzaghrane, <a href="#bib.bib52" title="" class="ltx_ref">2019</a>)</cite>. The core of AD is the perception capability to detect objects (e.g, vehicles, bicycles, signs, pedestrians) on the road; it enables interpretable path and action planning. Formally, the SAE (Society of Automotive Engineers) requires Level 3-5 AD to be able to monitor environments and detect
objects, even under adverse road and weather conditions <cite class="ltx_cite ltx_citemacro_citep">(Committee et al<span class="ltx_text">.</span>, <a href="#bib.bib9" title="" class="ltx_ref">2014</a>)</cite>.
To reach these goals, <span id="S1.p1.1.2" class="ltx_text ltx_font_italic">multiple on-board sensing modalities</span> (e.g., lidar, radar, and camera) collaboratively deliver complementary and real-time information of the surroundings. While lidar and camera provide high-definition measurements in short distance due to
attenuation in distance and degradation by adverse weather or lighting conditions,
radar achieves relatively longer-range monitoring robust to adverse conditions, leveraging the penetrating power of radio waves <cite class="ltx_cite ltx_citemacro_citep">(Zheng et al<span class="ltx_text">.</span>, <a href="#bib.bib78" title="" class="ltx_ref">2021</a>)</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">To fully take advantage of the rich multimodal information provided by various sensors, a plethora of previous arts <cite class="ltx_cite ltx_citemacro_citep">(Ku et al<span class="ltx_text">.</span>, <a href="#bib.bib26" title="" class="ltx_ref">2018</a>; Xu et al<span class="ltx_text">.</span>, <a href="#bib.bib71" title="" class="ltx_ref">2018</a>; Qi et al<span class="ltx_text">.</span>, <a href="#bib.bib45" title="" class="ltx_ref">2018</a>; Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib6" title="" class="ltx_ref">2017</a>; Liang et al<span class="ltx_text">.</span>, <a href="#bib.bib32" title="" class="ltx_ref">2018</a>; Qian et al<span class="ltx_text">.</span>, <a href="#bib.bib47" title="" class="ltx_ref">2021</a>; Liu and Niu, <a href="#bib.bib35" title="" class="ltx_ref">2021</a>)</cite> have employed deep learning to perform multi-modality fusion as well as pattern recognition, aiming to conduct accurate and reliable <span id="S1.p2.1.1" class="ltx_text ltx_font_italic">object detection</span> (OD).
The mainstream of OD relies on a two-stage method <cite class="ltx_cite ltx_citemacro_citep">(Ku et al<span class="ltx_text">.</span>, <a href="#bib.bib26" title="" class="ltx_ref">2018</a>; Xu et al<span class="ltx_text">.</span>, <a href="#bib.bib71" title="" class="ltx_ref">2018</a>; Qi et al<span class="ltx_text">.</span>, <a href="#bib.bib45" title="" class="ltx_ref">2018</a>; Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib6" title="" class="ltx_ref">2017</a>; Qian et al<span class="ltx_text">.</span>, <a href="#bib.bib47" title="" class="ltx_ref">2021</a>)</cite>, where proposals for regions of interest are generated first and then refined for object classification and bounding box regression.
Though OD can handle different viewing angles in general, we focus only on <span id="S1.p2.1.2" class="ltx_text ltx_font_italic">bird’s-eye view</span> <cite class="ltx_cite ltx_citemacro_citep">(Qian et al<span class="ltx_text">.</span>, <a href="#bib.bib47" title="" class="ltx_ref">2021</a>; Liu and Niu, <a href="#bib.bib35" title="" class="ltx_ref">2021</a>)</cite> for reduced complexity, as it
reconciles the view discrepancy among different sensing modalities at a reasonably low cost.
Yet even with this cost reduction, the fundamental difference between OD and basic learning tasks (e.g., classification) still lead to far more (deep learning) model parameters than normal, rendering its training hard to converge even for a single model, yet we shall further promote the need for training multiple models in a distributed manner.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Ideally, deep neural networks (DNNs) for OD should be trained on a dataset that takes into account different road, traffic, and weather conditions. However, the ever-changing driving environments render it infeasible for car manufacturers and developers to collect a dataset covering all scenarios. Whereas crowdsensing <cite class="ltx_cite ltx_citemacro_citep">(Ganti et al<span class="ltx_text">.</span>, <a href="#bib.bib13" title="" class="ltx_ref">2011</a>; Yang et al<span class="ltx_text">.</span>, <a href="#bib.bib73" title="" class="ltx_ref">2012</a>; Zhang et al<span class="ltx_text">.</span>, <a href="#bib.bib75" title="" class="ltx_ref">2014</a>, <a href="#bib.bib76" title="" class="ltx_ref">2015</a>; Han et al<span class="ltx_text">.</span>, <a href="#bib.bib18" title="" class="ltx_ref">2018</a>; Wang et al<span class="ltx_text">.</span>, <a href="#bib.bib65" title="" class="ltx_ref">2019</a>)</cite> can be exploited to overcome this difficulty by outsourcing data collection and annotation tasks to <span id="S1.p3.1.1" class="ltx_text ltx_font_italic">autonomous vehicle</span>s (AVs), conventional crowdsensing suffers from privacy concerns <cite class="ltx_cite ltx_citemacro_citep">(Vergara-Laurens et al<span class="ltx_text">.</span>, <a href="#bib.bib64" title="" class="ltx_ref">2016</a>; De Montjoye et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2013</a>)</cite> and data communication burdens. Fortunately,
integrating <span id="S1.p3.1.2" class="ltx_text ltx_font_italic">federated learning</span> (FL) <cite class="ltx_cite ltx_citemacro_citep">(Konečnỳ et al<span class="ltx_text">.</span>, <a href="#bib.bib25" title="" class="ltx_ref">2014</a>)</cite> into crowdsensing could virtually tackle these problems. As an emerging paradigm for distributed training across massive participating clients,
FL demands a central <span id="S1.p3.1.3" class="ltx_text ltx_font_italic">server</span> only to coordinate the distributed learning process, with which each <span id="S1.p3.1.4" class="ltx_text ltx_font_italic">client</span> shares only the local model parameters: such a scheme protects data privacy while reducing communication load at the same time.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p"><span id="S1.p4.1.1" class="ltx_text ltx_font_bold">Challenges.</span> Designing an FL system for OD upon AVs’ multimodal data is challenging, because all three entities (i.e., human, vehicle, and environment) involved in the system introduce a variety of data heterogeneity. First, relying on clients to label the data can lead to annotation heterogeneity: some clients may be more motivated to provide
annotations with adequate quality (e.g., bounding boxes around the detected vehicle), while others may be so busy and/or less skillful that they miss a large proportion of the annotations. Second, crowdsensing by different AVs also introduces sensing modality heterogeneity,<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Training a single model using FL under the heterogeneity of sensing modality allows vehicles with fewer sensors to learn from others via FL, and it also improves the model robustness against sensor malfunctions.</span></span></span> since the vehicles may be equipped with different types of sensors by their manufacturers. Even for AV models from the same manufacturer, it is common that certain sensor experiences malfunction, causing corresponding data modality to get lost.
Third, the ever-changing environment (e.g, weather and road) can introduce drifts in data distributions, further exacerbating the heterogeneity issue. Unfortunately, prior arts on FL either focus on homogeneous scenarios <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib39" title="" class="ltx_ref">2017</a>; Konečnỳ et al<span class="ltx_text">.</span>, <a href="#bib.bib25" title="" class="ltx_ref">2014</a>)</cite>, or deal with heterogeneity of unimodal data <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib31" title="" class="ltx_ref">2020</a>; Fallah et al<span class="ltx_text">.</span>, <a href="#bib.bib12" title="" class="ltx_ref">2020</a>; Tu et al<span class="ltx_text">.</span>, <a href="#bib.bib59" title="" class="ltx_ref">2021</a>)</cite>). None of existing works is capable of handling all the aforementioned heterogeneity induced by humans, vehicle, and environment under our targeted AD scenarios. Last but not least, the high complexity of the two-stage OD network makes its loss surface chaotic <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib30" title="" class="ltx_ref">2018</a>)</cite>, further exacerbating the negative impacts of the data heterogeneity on the performance.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2302.08646/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="171" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1. </span>The bird’s-eye view FL-OD of AutoFed.</figcaption>
</figure>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p"><span id="S1.p5.1.1" class="ltx_text ltx_font_bold">Our solutions.</span> To tackle these challenges, we carefully re-engineer the classical two-stage OD model <cite class="ltx_cite ltx_citemacro_citep">(Ren et al<span class="ltx_text">.</span>, <a href="#bib.bib50" title="" class="ltx_ref">2015</a>)</cite> to accommodate the multimodal data generated on AVs, and we exploit a major insight on the loss surface of OD under FL to guide the design of several learning mechanisms that handle the heterogeneity issue,
as briefly illustrated in Figure <a href="#S1.F1" title="Figure 1 ‣ 1. Introduction ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
Since we notice that tolerance for data anomalies is crucial to efficiently navigate on the chaotic loss surface, we focus on robust designs to achieve such tolerance.

Specifically, we design a cross-entropy-based loss function for training the neural model to handle unlabeled regions (of certain vehicles) that could be mistakenly regarded as the background during training. AutoFed also employs inter-modality autoencoders to perform data imputation of missing sensor modalities. The autoencoders learn from incomplete data modality and generate plausible values for the missing modality.
Finally, AutoFed exploits a novel client selection mechanism to handle environment heterogeneity by eliminating diverged models. All in all, these three mechanisms together may largely avoid data abnormality and hence prevent the clients’ losses from falling into local minimums on the chaotic loss surface.
Our key contributions can be summarized as follows:</p>
</div>
<div id="S1.p6" class="ltx_para">
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">To the best of our knowledge, AutoFed is the first FL system specifically designed for multi-modal OD under heterogeneous AV settings.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">We design a novel cross entropy loss for training the neural model for OD, aiming to mitigate the annotation heterogeneity across clients.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">We design an inter-modality autoencoder to perform missing data modality imputation, thus alleviating the modality heterogeneity across the clients.</p>
</div>
</li>
<li id="S1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i4.p1" class="ltx_para">
<p id="S1.I1.i4.p1.1" class="ltx_p">We design a novel client selection mechanism for choosing mutually-enhancing clients, thus further eliminating the harmful effects induced by heterogeneity.</p>
</div>
</li>
<li id="S1.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i5.p1" class="ltx_para">
<p id="S1.I1.i5.p1.1" class="ltx_p">We implement AutoFed prototype and evaluate AutoFed with extensive experiments. The promising results demonstrate that AutoFed can enable robust vehicle detection under AD scenarios.</p>
</div>
</li>
</ul>
<p id="S1.p6.1" class="ltx_p">Whereas most FL proposals consider only basic learning tasks <cite class="ltx_cite ltx_citemacro_citep">(Konečnỳ et al<span class="ltx_text">.</span>, <a href="#bib.bib25" title="" class="ltx_ref">2014</a>; Li et al<span class="ltx_text">.</span>, <a href="#bib.bib31" title="" class="ltx_ref">2020</a>, <a href="#bib.bib27" title="" class="ltx_ref">2021</a>; Tu et al<span class="ltx_text">.</span>, <a href="#bib.bib59" title="" class="ltx_ref">2021</a>)</cite>, AutoFed pioneers in FL-driven AV-OD far more sophisticated yet realistic than basic classification or regression.
In the following, § <a href="#S2" title="2. Motivation ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> motivates the design of AutoFed by revealing the damaging effects of the heterogeneity. § <a href="#S3" title="3. System Design ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> presents the system design of AutoFed. § <a href="#S4" title="4. Performance Evaluation ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> introduces the datasets, system implementation, and experiment setup, before reporting the evaluation results. Related works and technical limitations are discussed in § <a href="#S5" title="5. Related Work and Discussion ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>. Finally, § <a href="#S6" title="6. Conclusion ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> concludes the paper with future directions.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Motivation</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">We first investigate the impact of annotation heterogeneity on the performance of a DNN model for vehicle detection. Then we show that the heterogeneous modality significantly degrades the performance of the federated model on OD. Finally, we confirm the necessity to tackle the model divergence potentially caused by heterogeneous factors (e.g., diversified environments and human inputs) in federated training.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1. </span>Quantity Skew of Labeled Data</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">As an FL system, AutoFed relies on AV clients to provide labels (i.e., bounding boxes around vehicles) for two reasons: i) the server should not have access to local data due to privacy concerns; and ii) labeling data locally is more reasonable compared to performing the labeling offline on the server, because more visual cues can be leveraged for labeling locally on AVs,<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>The driver/co-pilot can provide online
labels similar to crowdsourcing in Waze <cite class="ltx_cite ltx_citemacro_citep">(Waze Mobile Limited, <a href="#bib.bib68" title="" class="ltx_ref">2022</a>)</cite>.</span></span></span> and we hence deem all such labels as reliable. However, relying on clients for data labeling can lead to skew in label quantity: some clients may be more motivated to provide annotations with adequate quality, while others may be so busy and/or less skillful that they miss a large proportion of the annotations. The situation may get worse during training, as the missing annotations on some AVs could be mistakenly marked as background by the OD network, thus backpropagating wrong gradients during local training. As a result, the small number of labels on some AVs may degrade the overall performance and cause training instability of the OD network.</p>
</div>
<figure id="S2.F2" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S2.F2.sf1" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S2.F2.sf1.1" class="ltx_block ltx_minipage ltx_align_bottom" style="width:203.8pt;">
<img src="/html/2302.08646/assets/x2.png" id="S2.F2.sf1.1.g1" class="ltx_graphics ltx_img_landscape" width="442" height="266" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>Average precision.</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S2.F2.sf2" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S2.F2.sf2.1" class="ltx_block ltx_minipage ltx_align_bottom" style="width:203.8pt;">
<img src="/html/2302.08646/assets/x3.png" id="S2.F2.sf2.1.g1" class="ltx_graphics ltx_img_landscape" width="442" height="262" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Average recall.</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2. </span>Damaging effects of missing annotations.</figcaption>
</figure>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">To demonstrate the damaging effects of missing labeling, we show the average precision and recall of a two-stage OD network for the task of vehicle detection in Figure <a href="#S2.F2" title="Figure 2 ‣ 2.1. Quantity Skew of Labeled Data ‣ 2. Motivation ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. The network utilizes a VGG variant <cite class="ltx_cite ltx_citemacro_citep">(Simonyan and Zisserman, <a href="#bib.bib54" title="" class="ltx_ref">2014</a>)</cite> as its backbone and was trained by standard backpropagation using an SGD optimizer on a dataset of 1,000 data samples with 50% data with missing annotations and 50% data with complete annotations in a standalone manner. After training, the network is tested on another 1,000-sample dataset. Clearly, the network under complete labeling outperforms that under missing labeling by around 20% in terms of both precision and recall. Moreover, it is evident that the performance of the DNN under missing labeling experiences a downward trend after the 20-th epoch, confirming the negative effects of the wrong gradient signals introduced by missing labeling.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2. </span>Heterogeneous Modality across AVs</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">Most prior work on the fusion of multimodal sensing data assumes that all modalities are available for every training data point <cite class="ltx_cite ltx_citemacro_citep">(Xu et al<span class="ltx_text">.</span>, <a href="#bib.bib71" title="" class="ltx_ref">2018</a>; Bijelic et al<span class="ltx_text">.</span>, <a href="#bib.bib4" title="" class="ltx_ref">2020</a>)</cite>. This assumption may not be valid in reality, as the sensing modalities of different AVs are often heterogeneous for two reasons. On one hand, the AVs may be equipped with different types of sensors by their manufacturers. On the other hand, even for AVs from the same manufacturer, it is common that certain sensor experiences malfunctions, causing corresponding data modality to get lost. Such heterogeneous modalities pose significant challenges to DNN-based OD.
Removing data entries with missing modalities or keeping only modalities shared among all clients can be a makeshift, but useful information conveyed in other modalities or clients can be discarded. Lacking access to global statistics also renders filling a missing modality with typical statistics (e.g., mean) impractical, leaving zero-filling <cite class="ltx_cite ltx_citemacro_citep">(Van Buuren, <a href="#bib.bib61" title="" class="ltx_ref">2018</a>)</cite> as the only possibility. Therefore, we show the average precision and recall of an OD network in Figure <a href="#S2.F3" title="Figure 3 ‣ 2.2. Heterogeneous Modality across AVs ‣ 2. Motivation ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>; the model is trained in a standalone manner under complete modalities and missing modalities with zero-filling. In the training process, data with missing radar and lidar each accounting for 25% of a 1,000-sample dataset. The results demonstrate that the precision and recall of training the models with complete modalities outperform those with partial modalities by more than 20% and 10%, respectively, confirming that zero-filling does not fully overcome the challenge. To mitigate the missing modality, it is necessary to propose a new data imputation technique.</p>
</div>
<figure id="S2.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S2.F3.sf1" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S2.F3.sf1.1" class="ltx_block ltx_minipage ltx_align_bottom" style="width:203.8pt;">
<img src="/html/2302.08646/assets/x4.png" id="S2.F3.sf1.1.g1" class="ltx_graphics ltx_img_landscape" width="442" height="266" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>Average precision.</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S2.F3.sf2" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S2.F3.sf2.1" class="ltx_block ltx_minipage ltx_align_bottom" style="width:203.8pt;">
<img src="/html/2302.08646/assets/x5.png" id="S2.F3.sf2.1.g1" class="ltx_graphics ltx_img_landscape" width="442" height="262" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Average recall.</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3. </span>Damaging effects of missing modality.</figcaption>
</figure>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3. </span>Model Divergence</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">Besides the above label and modality heterogeneity across the clients, there exist other heterogeneities such as those introduced by environments (e.g., different weather and road conditions). Such heterogeneity makes the local models on AVs to be diverged and the optimization goal can even become contradictory. We demonstrate such model divergence in Figure <a href="#S2.F4.sf1" title="In Figure 4 ‣ 2.3. Model Divergence ‣ 2. Motivation ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4a</span></a>, where we involve 40 clients each holding a 1,000-sample dataset for training. These datasets have i) annotation level ranging from 10% to 100% (with 10% step size for every 4 clients), ii) 25% chance to hold data with missing radar or lidar modality, and iii) equal chance to have data recorded under clear, foggy, rainy, and snowy weather. After training, the network is tested on another 2,000-sample dataset. We apply PCA (principal component analysis) <cite class="ltx_cite ltx_citemacro_citep">(Pearson, <a href="#bib.bib43" title="" class="ltx_ref">1901</a>)</cite> to the model weights at the 10-th epoch, and visualize the first two PCA components, one may readily observe that, while about half of local model weights form a cluster (colored in blue), there exist multiple outliers (colored in red). If we recklessly perform aggregation on these model weights, the performance of federated model will be significantly degraded by the outliers. We demonstrate the effects of diverged models in Figure <a href="#S2.F4.sf2" title="In Figure 4 ‣ 2.3. Model Divergence ‣ 2. Motivation ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4b</span></a>. The results show that aggregating the diverged models leads to a 10% drop in OD precision when compared with the aggregated model from homogeneous training data.</p>
</div>
<figure id="S2.F4" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S2.F4.sf1" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S2.F4.sf1.1" class="ltx_block ltx_minipage ltx_align_bottom" style="width:203.8pt;">
<img src="/html/2302.08646/assets/x6.png" id="S2.F4.sf1.1.g1" class="ltx_graphics ltx_img_landscape" width="442" height="265" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>PCA embedding.</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S2.F4.sf2" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S2.F4.sf2.1" class="ltx_block ltx_minipage ltx_align_bottom" style="width:203.8pt;">
<img src="/html/2302.08646/assets/x7.png" id="S2.F4.sf2.1.g1" class="ltx_graphics ltx_img_landscape" width="442" height="266" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Average precision.</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4. </span>Damaging effects of diverging models.</figcaption>
</figure>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>System Design</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Based on our discussions in § <a href="#S2" title="2. Motivation ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, we hereby present AutoFed comprising a two-level design: i) a multimodal OD network
to fully exploit the information provided by multimodal sensors equipped on the AVs,
and ii) an FL framework involving specifically designed loss, missing modality completion module, and client selection mechanism, aiming to achieve heterogeneity-aware federated multimodal OD on distributed AVs. In the following, we first define our problem concretely, and then we present the details of the multimodal OD network and FL framework.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1. </span>Problem Statement and Overview</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">The ultimate goal of AutoFed is to make use of the crowdsensed data collected from multiple AVs (i.e., clients) to increase the data diversity, thus improving upon the performance of a standalone OD network deployed on a single client. Since the sensors
on AVs can have multiple viewing perspectives, i.e., the lidar, radar, and camera have 3D, bird’s-eye view, and front view, respectively, there are no one-size-fits-all solutions. Therefore, we specifically choose to solve the <span id="S3.SS1.p1.1.1" class="ltx_text ltx_font_italic">vehicle detection</span> problem <cite class="ltx_cite ltx_citemacro_citep">(Petrovskaya and Thrun, <a href="#bib.bib44" title="" class="ltx_ref">2009</a>)</cite> (a special case of OD) from the bird’s-eye view using lidar and radar, thanks to (also confined by) the availability of dataset and vehicle annotations <cite class="ltx_cite ltx_citemacro_citep">(Barnes et al<span class="ltx_text">.</span>, <a href="#bib.bib2" title="" class="ltx_ref">2019</a>)</cite>. We avoid using camera in AutoFed for two reasons. First, the perception capability of lidar and camera largely overlap due to their similar spectrums. Second, the current settings and network architecture mostly are focused on the bird’s eye view of the vehicle’s surroundings, making the camera’s orthogonal front view largely incompatible. Note that our AutoFed framework is not limited to any specific OD tasks, because performing vehicle detection actually encompasses all critical elements in fulfilling other OD tasks.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">Since AV scenarios are by default a distributed setting, FL is a good candidate for better utilizing the data diversity from geographically distributed clients. However, combining FL with OD may exacerbate OD’s chaotic loss surface emphasized in § 1,
forcing naive aggregation algorithms to yield only comparable or even inferior performance compared to traditional standalone training <cite class="ltx_cite ltx_citemacro_citep">(Liu et al<span class="ltx_text">.</span>, <a href="#bib.bib37" title="" class="ltx_ref">2020</a>; Jallepalli et al<span class="ltx_text">.</span>, <a href="#bib.bib23" title="" class="ltx_ref">2021</a>; Yu and Liu, <a href="#bib.bib74" title="" class="ltx_ref">2019</a>)</cite>, especially under the challenges mentioned in § <a href="#S2" title="2. Motivation ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
Fortunately, our insight indicates that high tolerance to data anomalies can often allow effective training that leads to meaningful local minimums, by smoothly navigating on the chaotic loss surface; this motivates our following design considerations. Firstly, both data preprocessing and network architecture should be modularized and flexible enough to accommodate potentially abnormal multimodal inputs. Secondly, the network should be equipped with a mechanism to tolerate annotation anomalies of the input data. Thirdly, there should be a way to fill in missing modalities without making the data distributions abnormal. Finally, the aggregation mechanism must be sufficiently robust to withstand potentially diverging client models that could result in a non-optimal outcome after aggregation.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2. </span>Multimodal Vehicle Detection</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">Before introducing the AutoFed framework, we first look at how to design a multimodal OD network under an FL setting. While the design method of a conventional two-stage OD network is well-established,
how to integrate multimodal processing into the network remains an open issue. Furthermore, extending the multimodal OD network to the FL scenario put more stringent requirements on handling of the multimodal data. Intuitively speaking, different data modalities of such a network should i) conform to similar data formats, thus facilitating multimodal fusion, ii) collaborate by sharing information so as to enhance other modalities, and iii) be loosely coupled so as to support a more flexible FL pipeline that better deals with heterogeneous data and environment. In this section, we start with introducing the basics of the conventional OD network. Then we align lidar and radar data for improving data compatibility, in order to satisfy the requirement i). Finally, we present a novel feature-level fusion technique to satisfy the other two requirements with strong information sharing and loose coupling among the modalities.</p>
</div>
<section id="S3.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.1. </span>Object Detection Basics</h4>

<figure id="S3.F5" class="ltx_figure"><img src="/html/2302.08646/assets/x8.png" id="S3.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="438" height="146" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5. </span>The upgraded OD pipeline of AutoFed’s multi-model vehicle detection network.</figcaption>
</figure>
<div id="S3.SS2.SSS1.p1" class="ltx_para">
<p id="S3.SS2.SSS1.p1.4" class="ltx_p">Conventional two-stage OD follows 3 major steps <cite class="ltx_cite ltx_citemacro_citep">(Girshick, <a href="#bib.bib15" title="" class="ltx_ref">2015</a>; Ren et al<span class="ltx_text">.</span>, <a href="#bib.bib50" title="" class="ltx_ref">2015</a>)</cite>, with 2 steps in the first stage as shown by the “blue” boxes in Figure <a href="#S3.F5" title="Figure 5 ‣ 3.2.1. Object Detection Basics ‣ 3.2. Multimodal Vehicle Detection ‣ 3. System Design ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>. Generally, a feature map is first extracted using well-accepted feature extractors (e.g., VGGNet <cite class="ltx_cite ltx_citemacro_citep">(Simonyan and Zisserman, <a href="#bib.bib54" title="" class="ltx_ref">2014</a>)</cite> or ResNet <cite class="ltx_cite ltx_citemacro_citep">(He et al<span class="ltx_text">.</span>, <a href="#bib.bib20" title="" class="ltx_ref">2016</a>)</cite>), then region proposals are generated by the region proposal network (RPN). Specifically, taking the feature maps as input,
RPN generates anchor boxes with pre-defined fixed scales and aspect ratios. The built-in classifier of RPN differentiates whether each anchor box is foreground or background. The outcome allows RPN to generate the region proposals; it leverages a built-in regressor to fit the anchor boxes to their corresponding objects by adjusting their offsets. With the above completing Step-1, Step-2 involves the region proposals being filtered by non-maximum suppression (NMS): the proposals with the highest confidence are selected and excessive proposals overlapping with higher-confidence proposals above a given threshold are removed. The loss of RPN is <math id="S3.SS2.SSS1.p1.1.m1.1" class="ltx_Math" alttext="L^{\mathrm{RPN}}=L_{\mathrm{cls}}^{\mathrm{RPN}}+L_{\mathrm{loc}}^{\mathrm{RPN}}" display="inline"><semantics id="S3.SS2.SSS1.p1.1.m1.1a"><mrow id="S3.SS2.SSS1.p1.1.m1.1.1" xref="S3.SS2.SSS1.p1.1.m1.1.1.cmml"><msup id="S3.SS2.SSS1.p1.1.m1.1.1.2" xref="S3.SS2.SSS1.p1.1.m1.1.1.2.cmml"><mi id="S3.SS2.SSS1.p1.1.m1.1.1.2.2" xref="S3.SS2.SSS1.p1.1.m1.1.1.2.2.cmml">L</mi><mi id="S3.SS2.SSS1.p1.1.m1.1.1.2.3" xref="S3.SS2.SSS1.p1.1.m1.1.1.2.3.cmml">RPN</mi></msup><mo id="S3.SS2.SSS1.p1.1.m1.1.1.1" xref="S3.SS2.SSS1.p1.1.m1.1.1.1.cmml">=</mo><mrow id="S3.SS2.SSS1.p1.1.m1.1.1.3" xref="S3.SS2.SSS1.p1.1.m1.1.1.3.cmml"><msubsup id="S3.SS2.SSS1.p1.1.m1.1.1.3.2" xref="S3.SS2.SSS1.p1.1.m1.1.1.3.2.cmml"><mi id="S3.SS2.SSS1.p1.1.m1.1.1.3.2.2.2" xref="S3.SS2.SSS1.p1.1.m1.1.1.3.2.2.2.cmml">L</mi><mi id="S3.SS2.SSS1.p1.1.m1.1.1.3.2.2.3" xref="S3.SS2.SSS1.p1.1.m1.1.1.3.2.2.3.cmml">cls</mi><mi id="S3.SS2.SSS1.p1.1.m1.1.1.3.2.3" xref="S3.SS2.SSS1.p1.1.m1.1.1.3.2.3.cmml">RPN</mi></msubsup><mo id="S3.SS2.SSS1.p1.1.m1.1.1.3.1" xref="S3.SS2.SSS1.p1.1.m1.1.1.3.1.cmml">+</mo><msubsup id="S3.SS2.SSS1.p1.1.m1.1.1.3.3" xref="S3.SS2.SSS1.p1.1.m1.1.1.3.3.cmml"><mi id="S3.SS2.SSS1.p1.1.m1.1.1.3.3.2.2" xref="S3.SS2.SSS1.p1.1.m1.1.1.3.3.2.2.cmml">L</mi><mi id="S3.SS2.SSS1.p1.1.m1.1.1.3.3.2.3" xref="S3.SS2.SSS1.p1.1.m1.1.1.3.3.2.3.cmml">loc</mi><mi id="S3.SS2.SSS1.p1.1.m1.1.1.3.3.3" xref="S3.SS2.SSS1.p1.1.m1.1.1.3.3.3.cmml">RPN</mi></msubsup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p1.1.m1.1b"><apply id="S3.SS2.SSS1.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS1.p1.1.m1.1.1"><eq id="S3.SS2.SSS1.p1.1.m1.1.1.1.cmml" xref="S3.SS2.SSS1.p1.1.m1.1.1.1"></eq><apply id="S3.SS2.SSS1.p1.1.m1.1.1.2.cmml" xref="S3.SS2.SSS1.p1.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p1.1.m1.1.1.2.1.cmml" xref="S3.SS2.SSS1.p1.1.m1.1.1.2">superscript</csymbol><ci id="S3.SS2.SSS1.p1.1.m1.1.1.2.2.cmml" xref="S3.SS2.SSS1.p1.1.m1.1.1.2.2">𝐿</ci><ci id="S3.SS2.SSS1.p1.1.m1.1.1.2.3.cmml" xref="S3.SS2.SSS1.p1.1.m1.1.1.2.3">RPN</ci></apply><apply id="S3.SS2.SSS1.p1.1.m1.1.1.3.cmml" xref="S3.SS2.SSS1.p1.1.m1.1.1.3"><plus id="S3.SS2.SSS1.p1.1.m1.1.1.3.1.cmml" xref="S3.SS2.SSS1.p1.1.m1.1.1.3.1"></plus><apply id="S3.SS2.SSS1.p1.1.m1.1.1.3.2.cmml" xref="S3.SS2.SSS1.p1.1.m1.1.1.3.2"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p1.1.m1.1.1.3.2.1.cmml" xref="S3.SS2.SSS1.p1.1.m1.1.1.3.2">superscript</csymbol><apply id="S3.SS2.SSS1.p1.1.m1.1.1.3.2.2.cmml" xref="S3.SS2.SSS1.p1.1.m1.1.1.3.2"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p1.1.m1.1.1.3.2.2.1.cmml" xref="S3.SS2.SSS1.p1.1.m1.1.1.3.2">subscript</csymbol><ci id="S3.SS2.SSS1.p1.1.m1.1.1.3.2.2.2.cmml" xref="S3.SS2.SSS1.p1.1.m1.1.1.3.2.2.2">𝐿</ci><ci id="S3.SS2.SSS1.p1.1.m1.1.1.3.2.2.3.cmml" xref="S3.SS2.SSS1.p1.1.m1.1.1.3.2.2.3">cls</ci></apply><ci id="S3.SS2.SSS1.p1.1.m1.1.1.3.2.3.cmml" xref="S3.SS2.SSS1.p1.1.m1.1.1.3.2.3">RPN</ci></apply><apply id="S3.SS2.SSS1.p1.1.m1.1.1.3.3.cmml" xref="S3.SS2.SSS1.p1.1.m1.1.1.3.3"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p1.1.m1.1.1.3.3.1.cmml" xref="S3.SS2.SSS1.p1.1.m1.1.1.3.3">superscript</csymbol><apply id="S3.SS2.SSS1.p1.1.m1.1.1.3.3.2.cmml" xref="S3.SS2.SSS1.p1.1.m1.1.1.3.3"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p1.1.m1.1.1.3.3.2.1.cmml" xref="S3.SS2.SSS1.p1.1.m1.1.1.3.3">subscript</csymbol><ci id="S3.SS2.SSS1.p1.1.m1.1.1.3.3.2.2.cmml" xref="S3.SS2.SSS1.p1.1.m1.1.1.3.3.2.2">𝐿</ci><ci id="S3.SS2.SSS1.p1.1.m1.1.1.3.3.2.3.cmml" xref="S3.SS2.SSS1.p1.1.m1.1.1.3.3.2.3">loc</ci></apply><ci id="S3.SS2.SSS1.p1.1.m1.1.1.3.3.3.cmml" xref="S3.SS2.SSS1.p1.1.m1.1.1.3.3.3">RPN</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p1.1.m1.1c">L^{\mathrm{RPN}}=L_{\mathrm{cls}}^{\mathrm{RPN}}+L_{\mathrm{loc}}^{\mathrm{RPN}}</annotation></semantics></math>, where <math id="S3.SS2.SSS1.p1.2.m2.1" class="ltx_Math" alttext="L_{\mathrm{cls}}^{\mathrm{RPN}}" display="inline"><semantics id="S3.SS2.SSS1.p1.2.m2.1a"><msubsup id="S3.SS2.SSS1.p1.2.m2.1.1" xref="S3.SS2.SSS1.p1.2.m2.1.1.cmml"><mi id="S3.SS2.SSS1.p1.2.m2.1.1.2.2" xref="S3.SS2.SSS1.p1.2.m2.1.1.2.2.cmml">L</mi><mi id="S3.SS2.SSS1.p1.2.m2.1.1.2.3" xref="S3.SS2.SSS1.p1.2.m2.1.1.2.3.cmml">cls</mi><mi id="S3.SS2.SSS1.p1.2.m2.1.1.3" xref="S3.SS2.SSS1.p1.2.m2.1.1.3.cmml">RPN</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p1.2.m2.1b"><apply id="S3.SS2.SSS1.p1.2.m2.1.1.cmml" xref="S3.SS2.SSS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p1.2.m2.1.1.1.cmml" xref="S3.SS2.SSS1.p1.2.m2.1.1">superscript</csymbol><apply id="S3.SS2.SSS1.p1.2.m2.1.1.2.cmml" xref="S3.SS2.SSS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p1.2.m2.1.1.2.1.cmml" xref="S3.SS2.SSS1.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.SSS1.p1.2.m2.1.1.2.2.cmml" xref="S3.SS2.SSS1.p1.2.m2.1.1.2.2">𝐿</ci><ci id="S3.SS2.SSS1.p1.2.m2.1.1.2.3.cmml" xref="S3.SS2.SSS1.p1.2.m2.1.1.2.3">cls</ci></apply><ci id="S3.SS2.SSS1.p1.2.m2.1.1.3.cmml" xref="S3.SS2.SSS1.p1.2.m2.1.1.3">RPN</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p1.2.m2.1c">L_{\mathrm{cls}}^{\mathrm{RPN}}</annotation></semantics></math> is a binary cross entropy (BCE) loss measuring the “objectness” of the classification (i.e., how good the RPN is at labelling the anchor boxes as foreground or background), and <math id="S3.SS2.SSS1.p1.3.m3.1" class="ltx_Math" alttext="L_{\mathrm{loc}}^{\mathrm{RPN}}" display="inline"><semantics id="S3.SS2.SSS1.p1.3.m3.1a"><msubsup id="S3.SS2.SSS1.p1.3.m3.1.1" xref="S3.SS2.SSS1.p1.3.m3.1.1.cmml"><mi id="S3.SS2.SSS1.p1.3.m3.1.1.2.2" xref="S3.SS2.SSS1.p1.3.m3.1.1.2.2.cmml">L</mi><mi id="S3.SS2.SSS1.p1.3.m3.1.1.2.3" xref="S3.SS2.SSS1.p1.3.m3.1.1.2.3.cmml">loc</mi><mi id="S3.SS2.SSS1.p1.3.m3.1.1.3" xref="S3.SS2.SSS1.p1.3.m3.1.1.3.cmml">RPN</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p1.3.m3.1b"><apply id="S3.SS2.SSS1.p1.3.m3.1.1.cmml" xref="S3.SS2.SSS1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p1.3.m3.1.1.1.cmml" xref="S3.SS2.SSS1.p1.3.m3.1.1">superscript</csymbol><apply id="S3.SS2.SSS1.p1.3.m3.1.1.2.cmml" xref="S3.SS2.SSS1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p1.3.m3.1.1.2.1.cmml" xref="S3.SS2.SSS1.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS2.SSS1.p1.3.m3.1.1.2.2.cmml" xref="S3.SS2.SSS1.p1.3.m3.1.1.2.2">𝐿</ci><ci id="S3.SS2.SSS1.p1.3.m3.1.1.2.3.cmml" xref="S3.SS2.SSS1.p1.3.m3.1.1.2.3">loc</ci></apply><ci id="S3.SS2.SSS1.p1.3.m3.1.1.3.cmml" xref="S3.SS2.SSS1.p1.3.m3.1.1.3">RPN</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p1.3.m3.1c">L_{\mathrm{loc}}^{\mathrm{RPN}}</annotation></semantics></math> is an <math id="S3.SS2.SSS1.p1.4.m4.1" class="ltx_Math" alttext="L^{1}" display="inline"><semantics id="S3.SS2.SSS1.p1.4.m4.1a"><msup id="S3.SS2.SSS1.p1.4.m4.1.1" xref="S3.SS2.SSS1.p1.4.m4.1.1.cmml"><mi id="S3.SS2.SSS1.p1.4.m4.1.1.2" xref="S3.SS2.SSS1.p1.4.m4.1.1.2.cmml">L</mi><mn id="S3.SS2.SSS1.p1.4.m4.1.1.3" xref="S3.SS2.SSS1.p1.4.m4.1.1.3.cmml">1</mn></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p1.4.m4.1b"><apply id="S3.SS2.SSS1.p1.4.m4.1.1.cmml" xref="S3.SS2.SSS1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p1.4.m4.1.1.1.cmml" xref="S3.SS2.SSS1.p1.4.m4.1.1">superscript</csymbol><ci id="S3.SS2.SSS1.p1.4.m4.1.1.2.cmml" xref="S3.SS2.SSS1.p1.4.m4.1.1.2">𝐿</ci><cn type="integer" id="S3.SS2.SSS1.p1.4.m4.1.1.3.cmml" xref="S3.SS2.SSS1.p1.4.m4.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p1.4.m4.1c">L^{1}</annotation></semantics></math> loss quantifying the localization performance of the predicted regions generated by the RPN.</p>
</div>
<div id="S3.SS2.SSS1.p2" class="ltx_para">
<p id="S3.SS2.SSS1.p2.5" class="ltx_p">The second stage (also Step-3) performs a fine-tuning to jointly optimizes a classifier and bounding-box regressors. After cropping out the feature map and RoI pooling <cite class="ltx_cite ltx_citemacro_citep">(Ren et al<span class="ltx_text">.</span>, <a href="#bib.bib50" title="" class="ltx_ref">2015</a>)</cite> of the interested region according to the generated proposals, it further uses a classifier to detect whether the generated bounding box contains a specific class of object. It also fine-tunes the bounding boxes using a class-specific regressor. Essentially, this stage introduces three losses, i.e., a BCE classification loss <math id="S3.SS2.SSS1.p2.1.m1.1" class="ltx_Math" alttext="L_{\mathrm{cls}}" display="inline"><semantics id="S3.SS2.SSS1.p2.1.m1.1a"><msub id="S3.SS2.SSS1.p2.1.m1.1.1" xref="S3.SS2.SSS1.p2.1.m1.1.1.cmml"><mi id="S3.SS2.SSS1.p2.1.m1.1.1.2" xref="S3.SS2.SSS1.p2.1.m1.1.1.2.cmml">L</mi><mi id="S3.SS2.SSS1.p2.1.m1.1.1.3" xref="S3.SS2.SSS1.p2.1.m1.1.1.3.cmml">cls</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p2.1.m1.1b"><apply id="S3.SS2.SSS1.p2.1.m1.1.1.cmml" xref="S3.SS2.SSS1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p2.1.m1.1.1.1.cmml" xref="S3.SS2.SSS1.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.SSS1.p2.1.m1.1.1.2.cmml" xref="S3.SS2.SSS1.p2.1.m1.1.1.2">𝐿</ci><ci id="S3.SS2.SSS1.p2.1.m1.1.1.3.cmml" xref="S3.SS2.SSS1.p2.1.m1.1.1.3">cls</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p2.1.m1.1c">L_{\mathrm{cls}}</annotation></semantics></math> measuring the network performance in labeling a predicted box with an object, an <math id="S3.SS2.SSS1.p2.2.m2.1" class="ltx_Math" alttext="L^{1}" display="inline"><semantics id="S3.SS2.SSS1.p2.2.m2.1a"><msup id="S3.SS2.SSS1.p2.2.m2.1.1" xref="S3.SS2.SSS1.p2.2.m2.1.1.cmml"><mi id="S3.SS2.SSS1.p2.2.m2.1.1.2" xref="S3.SS2.SSS1.p2.2.m2.1.1.2.cmml">L</mi><mn id="S3.SS2.SSS1.p2.2.m2.1.1.3" xref="S3.SS2.SSS1.p2.2.m2.1.1.3.cmml">1</mn></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p2.2.m2.1b"><apply id="S3.SS2.SSS1.p2.2.m2.1.1.cmml" xref="S3.SS2.SSS1.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p2.2.m2.1.1.1.cmml" xref="S3.SS2.SSS1.p2.2.m2.1.1">superscript</csymbol><ci id="S3.SS2.SSS1.p2.2.m2.1.1.2.cmml" xref="S3.SS2.SSS1.p2.2.m2.1.1.2">𝐿</ci><cn type="integer" id="S3.SS2.SSS1.p2.2.m2.1.1.3.cmml" xref="S3.SS2.SSS1.p2.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p2.2.m2.1c">L^{1}</annotation></semantics></math> box regression loss <math id="S3.SS2.SSS1.p2.3.m3.1" class="ltx_Math" alttext="L_{\mathrm{reg}}" display="inline"><semantics id="S3.SS2.SSS1.p2.3.m3.1a"><msub id="S3.SS2.SSS1.p2.3.m3.1.1" xref="S3.SS2.SSS1.p2.3.m3.1.1.cmml"><mi id="S3.SS2.SSS1.p2.3.m3.1.1.2" xref="S3.SS2.SSS1.p2.3.m3.1.1.2.cmml">L</mi><mi id="S3.SS2.SSS1.p2.3.m3.1.1.3" xref="S3.SS2.SSS1.p2.3.m3.1.1.3.cmml">reg</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p2.3.m3.1b"><apply id="S3.SS2.SSS1.p2.3.m3.1.1.cmml" xref="S3.SS2.SSS1.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p2.3.m3.1.1.1.cmml" xref="S3.SS2.SSS1.p2.3.m3.1.1">subscript</csymbol><ci id="S3.SS2.SSS1.p2.3.m3.1.1.2.cmml" xref="S3.SS2.SSS1.p2.3.m3.1.1.2">𝐿</ci><ci id="S3.SS2.SSS1.p2.3.m3.1.1.3.cmml" xref="S3.SS2.SSS1.p2.3.m3.1.1.3">reg</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p2.3.m3.1c">L_{\mathrm{reg}}</annotation></semantics></math> quantifying how the predicted location deviates from the true location, and a BCE direction loss <math id="S3.SS2.SSS1.p2.4.m4.1" class="ltx_Math" alttext="L_{\mathrm{dir}}" display="inline"><semantics id="S3.SS2.SSS1.p2.4.m4.1a"><msub id="S3.SS2.SSS1.p2.4.m4.1.1" xref="S3.SS2.SSS1.p2.4.m4.1.1.cmml"><mi id="S3.SS2.SSS1.p2.4.m4.1.1.2" xref="S3.SS2.SSS1.p2.4.m4.1.1.2.cmml">L</mi><mi id="S3.SS2.SSS1.p2.4.m4.1.1.3" xref="S3.SS2.SSS1.p2.4.m4.1.1.3.cmml">dir</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p2.4.m4.1b"><apply id="S3.SS2.SSS1.p2.4.m4.1.1.cmml" xref="S3.SS2.SSS1.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p2.4.m4.1.1.1.cmml" xref="S3.SS2.SSS1.p2.4.m4.1.1">subscript</csymbol><ci id="S3.SS2.SSS1.p2.4.m4.1.1.2.cmml" xref="S3.SS2.SSS1.p2.4.m4.1.1.2">𝐿</ci><ci id="S3.SS2.SSS1.p2.4.m4.1.1.3.cmml" xref="S3.SS2.SSS1.p2.4.m4.1.1.3">dir</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p2.4.m4.1c">L_{\mathrm{dir}}</annotation></semantics></math> specifying whether the vehicle is pointing upward or downward to remove ambiguity, thus confining the possible angles of the rotated bounding box to be in the range of <math id="S3.SS2.SSS1.p2.5.m5.2" class="ltx_Math" alttext="[0^{\circ},180^{\circ}]" display="inline"><semantics id="S3.SS2.SSS1.p2.5.m5.2a"><mrow id="S3.SS2.SSS1.p2.5.m5.2.2.2" xref="S3.SS2.SSS1.p2.5.m5.2.2.3.cmml"><mo stretchy="false" id="S3.SS2.SSS1.p2.5.m5.2.2.2.3" xref="S3.SS2.SSS1.p2.5.m5.2.2.3.cmml">[</mo><msup id="S3.SS2.SSS1.p2.5.m5.1.1.1.1" xref="S3.SS2.SSS1.p2.5.m5.1.1.1.1.cmml"><mn id="S3.SS2.SSS1.p2.5.m5.1.1.1.1.2" xref="S3.SS2.SSS1.p2.5.m5.1.1.1.1.2.cmml">0</mn><mo id="S3.SS2.SSS1.p2.5.m5.1.1.1.1.3" xref="S3.SS2.SSS1.p2.5.m5.1.1.1.1.3.cmml">∘</mo></msup><mo id="S3.SS2.SSS1.p2.5.m5.2.2.2.4" xref="S3.SS2.SSS1.p2.5.m5.2.2.3.cmml">,</mo><msup id="S3.SS2.SSS1.p2.5.m5.2.2.2.2" xref="S3.SS2.SSS1.p2.5.m5.2.2.2.2.cmml"><mn id="S3.SS2.SSS1.p2.5.m5.2.2.2.2.2" xref="S3.SS2.SSS1.p2.5.m5.2.2.2.2.2.cmml">180</mn><mo id="S3.SS2.SSS1.p2.5.m5.2.2.2.2.3" xref="S3.SS2.SSS1.p2.5.m5.2.2.2.2.3.cmml">∘</mo></msup><mo stretchy="false" id="S3.SS2.SSS1.p2.5.m5.2.2.2.5" xref="S3.SS2.SSS1.p2.5.m5.2.2.3.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p2.5.m5.2b"><interval closure="closed" id="S3.SS2.SSS1.p2.5.m5.2.2.3.cmml" xref="S3.SS2.SSS1.p2.5.m5.2.2.2"><apply id="S3.SS2.SSS1.p2.5.m5.1.1.1.1.cmml" xref="S3.SS2.SSS1.p2.5.m5.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p2.5.m5.1.1.1.1.1.cmml" xref="S3.SS2.SSS1.p2.5.m5.1.1.1.1">superscript</csymbol><cn type="integer" id="S3.SS2.SSS1.p2.5.m5.1.1.1.1.2.cmml" xref="S3.SS2.SSS1.p2.5.m5.1.1.1.1.2">0</cn><compose id="S3.SS2.SSS1.p2.5.m5.1.1.1.1.3.cmml" xref="S3.SS2.SSS1.p2.5.m5.1.1.1.1.3"></compose></apply><apply id="S3.SS2.SSS1.p2.5.m5.2.2.2.2.cmml" xref="S3.SS2.SSS1.p2.5.m5.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p2.5.m5.2.2.2.2.1.cmml" xref="S3.SS2.SSS1.p2.5.m5.2.2.2.2">superscript</csymbol><cn type="integer" id="S3.SS2.SSS1.p2.5.m5.2.2.2.2.2.cmml" xref="S3.SS2.SSS1.p2.5.m5.2.2.2.2.2">180</cn><compose id="S3.SS2.SSS1.p2.5.m5.2.2.2.2.3.cmml" xref="S3.SS2.SSS1.p2.5.m5.2.2.2.2.3"></compose></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p2.5.m5.2c">[0^{\circ},180^{\circ}]</annotation></semantics></math>. In summary, the overall loss function for the OD network can be written as:</p>
<table id="Sx1.EGx1" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S3.E1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(1)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E1.m1.1" class="ltx_Math" alttext="\displaystyle L_{\mathrm{total}}=L^{\mathrm{RPN}}+L_{\mathrm{cls}}+L_{\mathrm{reg}}+L_{\mathrm{dir}}" display="inline"><semantics id="S3.E1.m1.1a"><mrow id="S3.E1.m1.1.1" xref="S3.E1.m1.1.1.cmml"><msub id="S3.E1.m1.1.1.2" xref="S3.E1.m1.1.1.2.cmml"><mi id="S3.E1.m1.1.1.2.2" xref="S3.E1.m1.1.1.2.2.cmml">L</mi><mi id="S3.E1.m1.1.1.2.3" xref="S3.E1.m1.1.1.2.3.cmml">total</mi></msub><mo id="S3.E1.m1.1.1.1" xref="S3.E1.m1.1.1.1.cmml">=</mo><mrow id="S3.E1.m1.1.1.3" xref="S3.E1.m1.1.1.3.cmml"><msup id="S3.E1.m1.1.1.3.2" xref="S3.E1.m1.1.1.3.2.cmml"><mi id="S3.E1.m1.1.1.3.2.2" xref="S3.E1.m1.1.1.3.2.2.cmml">L</mi><mi id="S3.E1.m1.1.1.3.2.3" xref="S3.E1.m1.1.1.3.2.3.cmml">RPN</mi></msup><mo id="S3.E1.m1.1.1.3.1" xref="S3.E1.m1.1.1.3.1.cmml">+</mo><msub id="S3.E1.m1.1.1.3.3" xref="S3.E1.m1.1.1.3.3.cmml"><mi id="S3.E1.m1.1.1.3.3.2" xref="S3.E1.m1.1.1.3.3.2.cmml">L</mi><mi id="S3.E1.m1.1.1.3.3.3" xref="S3.E1.m1.1.1.3.3.3.cmml">cls</mi></msub><mo id="S3.E1.m1.1.1.3.1a" xref="S3.E1.m1.1.1.3.1.cmml">+</mo><msub id="S3.E1.m1.1.1.3.4" xref="S3.E1.m1.1.1.3.4.cmml"><mi id="S3.E1.m1.1.1.3.4.2" xref="S3.E1.m1.1.1.3.4.2.cmml">L</mi><mi id="S3.E1.m1.1.1.3.4.3" xref="S3.E1.m1.1.1.3.4.3.cmml">reg</mi></msub><mo id="S3.E1.m1.1.1.3.1b" xref="S3.E1.m1.1.1.3.1.cmml">+</mo><msub id="S3.E1.m1.1.1.3.5" xref="S3.E1.m1.1.1.3.5.cmml"><mi id="S3.E1.m1.1.1.3.5.2" xref="S3.E1.m1.1.1.3.5.2.cmml">L</mi><mi id="S3.E1.m1.1.1.3.5.3" xref="S3.E1.m1.1.1.3.5.3.cmml">dir</mi></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.1b"><apply id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1"><eq id="S3.E1.m1.1.1.1.cmml" xref="S3.E1.m1.1.1.1"></eq><apply id="S3.E1.m1.1.1.2.cmml" xref="S3.E1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.2.1.cmml" xref="S3.E1.m1.1.1.2">subscript</csymbol><ci id="S3.E1.m1.1.1.2.2.cmml" xref="S3.E1.m1.1.1.2.2">𝐿</ci><ci id="S3.E1.m1.1.1.2.3.cmml" xref="S3.E1.m1.1.1.2.3">total</ci></apply><apply id="S3.E1.m1.1.1.3.cmml" xref="S3.E1.m1.1.1.3"><plus id="S3.E1.m1.1.1.3.1.cmml" xref="S3.E1.m1.1.1.3.1"></plus><apply id="S3.E1.m1.1.1.3.2.cmml" xref="S3.E1.m1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.3.2.1.cmml" xref="S3.E1.m1.1.1.3.2">superscript</csymbol><ci id="S3.E1.m1.1.1.3.2.2.cmml" xref="S3.E1.m1.1.1.3.2.2">𝐿</ci><ci id="S3.E1.m1.1.1.3.2.3.cmml" xref="S3.E1.m1.1.1.3.2.3">RPN</ci></apply><apply id="S3.E1.m1.1.1.3.3.cmml" xref="S3.E1.m1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.3.3.1.cmml" xref="S3.E1.m1.1.1.3.3">subscript</csymbol><ci id="S3.E1.m1.1.1.3.3.2.cmml" xref="S3.E1.m1.1.1.3.3.2">𝐿</ci><ci id="S3.E1.m1.1.1.3.3.3.cmml" xref="S3.E1.m1.1.1.3.3.3">cls</ci></apply><apply id="S3.E1.m1.1.1.3.4.cmml" xref="S3.E1.m1.1.1.3.4"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.3.4.1.cmml" xref="S3.E1.m1.1.1.3.4">subscript</csymbol><ci id="S3.E1.m1.1.1.3.4.2.cmml" xref="S3.E1.m1.1.1.3.4.2">𝐿</ci><ci id="S3.E1.m1.1.1.3.4.3.cmml" xref="S3.E1.m1.1.1.3.4.3">reg</ci></apply><apply id="S3.E1.m1.1.1.3.5.cmml" xref="S3.E1.m1.1.1.3.5"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.3.5.1.cmml" xref="S3.E1.m1.1.1.3.5">subscript</csymbol><ci id="S3.E1.m1.1.1.3.5.2.cmml" xref="S3.E1.m1.1.1.3.5.2">𝐿</ci><ci id="S3.E1.m1.1.1.3.5.3.cmml" xref="S3.E1.m1.1.1.3.5.3">dir</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.1c">\displaystyle L_{\mathrm{total}}=L^{\mathrm{RPN}}+L_{\mathrm{cls}}+L_{\mathrm{reg}}+L_{\mathrm{dir}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<figure id="S3.F6" class="ltx_figure"><img src="/html/2302.08646/assets/x9.png" id="S3.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="424" height="116" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6. </span>AutoFed architecture: Federated multimodal learning with heterogeneity-awareness.</figcaption>
</figure>
</section>
<section id="S3.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.2. </span>Modality Alignment</h4>

<div id="S3.SS2.SSS2.p1" class="ltx_para">
<p id="S3.SS2.SSS2.p1.4" class="ltx_p">The heterogeneous data generated by multiple modalities poses a challenge to conventional OD network. Specifically, the input 3-D lidar point clouds and mechanically scanned 2-D radar heatmap are incompatible and cannot be readily fused or imputed (as will be explained in § <a href="#S3.SS3.SSS2" title="3.3.2. Modality Imputation with Autoencoder for Tolerating Modality Anomalies ‣ 3.3. AutoFed Framework ‣ 3. System Design ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3.2</span></a>) on both the original data space and the feature space. To reconcile the incompatibility, we first voxelize the 3-D point cloud obtained by lidar <cite class="ltx_cite ltx_citemacro_citep">(Yang et al<span class="ltx_text">.</span>, <a href="#bib.bib72" title="" class="ltx_ref">2018</a>)</cite>. Since we are interested in performing vehicle detection from the bird’s-eye view, the horizontal 2-D slices of the resulting lidar data can be deemed as an image with 36 channels, i.e., 35 channels depicting the point occupancy in the space and 1 channel indicating the overall intensity of the lidar signals obtained on the horizontal plane. Similarly, the radar signal can be deemed as an image with a single channel since it has no 3-D information. After converting the data into “multi-channel” images, they are further registered by considering the extrinsics and resolutions of the sensors, as well as vehicle kinematics. Finally, two independent yet identical feature extractors (those of the OD network as shown on the left side of Figure <a href="#S3.F5" title="Figure 5 ‣ 3.2.1. Object Detection Basics ‣ 3.2. Multimodal Vehicle Detection ‣ 3. System Design ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>) are used to process lidar image <math id="S3.SS2.SSS2.p1.1.m1.1" class="ltx_Math" alttext="\mathbf{x}_{l}\in\mathcal{L}" display="inline"><semantics id="S3.SS2.SSS2.p1.1.m1.1a"><mrow id="S3.SS2.SSS2.p1.1.m1.1.1" xref="S3.SS2.SSS2.p1.1.m1.1.1.cmml"><msub id="S3.SS2.SSS2.p1.1.m1.1.1.2" xref="S3.SS2.SSS2.p1.1.m1.1.1.2.cmml"><mi id="S3.SS2.SSS2.p1.1.m1.1.1.2.2" xref="S3.SS2.SSS2.p1.1.m1.1.1.2.2.cmml">𝐱</mi><mi id="S3.SS2.SSS2.p1.1.m1.1.1.2.3" xref="S3.SS2.SSS2.p1.1.m1.1.1.2.3.cmml">l</mi></msub><mo id="S3.SS2.SSS2.p1.1.m1.1.1.1" xref="S3.SS2.SSS2.p1.1.m1.1.1.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S3.SS2.SSS2.p1.1.m1.1.1.3" xref="S3.SS2.SSS2.p1.1.m1.1.1.3.cmml">ℒ</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p1.1.m1.1b"><apply id="S3.SS2.SSS2.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS2.p1.1.m1.1.1"><in id="S3.SS2.SSS2.p1.1.m1.1.1.1.cmml" xref="S3.SS2.SSS2.p1.1.m1.1.1.1"></in><apply id="S3.SS2.SSS2.p1.1.m1.1.1.2.cmml" xref="S3.SS2.SSS2.p1.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p1.1.m1.1.1.2.1.cmml" xref="S3.SS2.SSS2.p1.1.m1.1.1.2">subscript</csymbol><ci id="S3.SS2.SSS2.p1.1.m1.1.1.2.2.cmml" xref="S3.SS2.SSS2.p1.1.m1.1.1.2.2">𝐱</ci><ci id="S3.SS2.SSS2.p1.1.m1.1.1.2.3.cmml" xref="S3.SS2.SSS2.p1.1.m1.1.1.2.3">𝑙</ci></apply><ci id="S3.SS2.SSS2.p1.1.m1.1.1.3.cmml" xref="S3.SS2.SSS2.p1.1.m1.1.1.3">ℒ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p1.1.m1.1c">\mathbf{x}_{l}\in\mathcal{L}</annotation></semantics></math> and radar image <math id="S3.SS2.SSS2.p1.2.m2.1" class="ltx_Math" alttext="\mathbf{x}_{r}\in\mathcal{R}" display="inline"><semantics id="S3.SS2.SSS2.p1.2.m2.1a"><mrow id="S3.SS2.SSS2.p1.2.m2.1.1" xref="S3.SS2.SSS2.p1.2.m2.1.1.cmml"><msub id="S3.SS2.SSS2.p1.2.m2.1.1.2" xref="S3.SS2.SSS2.p1.2.m2.1.1.2.cmml"><mi id="S3.SS2.SSS2.p1.2.m2.1.1.2.2" xref="S3.SS2.SSS2.p1.2.m2.1.1.2.2.cmml">𝐱</mi><mi id="S3.SS2.SSS2.p1.2.m2.1.1.2.3" xref="S3.SS2.SSS2.p1.2.m2.1.1.2.3.cmml">r</mi></msub><mo id="S3.SS2.SSS2.p1.2.m2.1.1.1" xref="S3.SS2.SSS2.p1.2.m2.1.1.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S3.SS2.SSS2.p1.2.m2.1.1.3" xref="S3.SS2.SSS2.p1.2.m2.1.1.3.cmml">ℛ</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p1.2.m2.1b"><apply id="S3.SS2.SSS2.p1.2.m2.1.1.cmml" xref="S3.SS2.SSS2.p1.2.m2.1.1"><in id="S3.SS2.SSS2.p1.2.m2.1.1.1.cmml" xref="S3.SS2.SSS2.p1.2.m2.1.1.1"></in><apply id="S3.SS2.SSS2.p1.2.m2.1.1.2.cmml" xref="S3.SS2.SSS2.p1.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p1.2.m2.1.1.2.1.cmml" xref="S3.SS2.SSS2.p1.2.m2.1.1.2">subscript</csymbol><ci id="S3.SS2.SSS2.p1.2.m2.1.1.2.2.cmml" xref="S3.SS2.SSS2.p1.2.m2.1.1.2.2">𝐱</ci><ci id="S3.SS2.SSS2.p1.2.m2.1.1.2.3.cmml" xref="S3.SS2.SSS2.p1.2.m2.1.1.2.3">𝑟</ci></apply><ci id="S3.SS2.SSS2.p1.2.m2.1.1.3.cmml" xref="S3.SS2.SSS2.p1.2.m2.1.1.3">ℛ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p1.2.m2.1c">\mathbf{x}_{r}\in\mathcal{R}</annotation></semantics></math>, where <math id="S3.SS2.SSS2.p1.3.m3.1" class="ltx_Math" alttext="\mathcal{L}" display="inline"><semantics id="S3.SS2.SSS2.p1.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.SSS2.p1.3.m3.1.1" xref="S3.SS2.SSS2.p1.3.m3.1.1.cmml">ℒ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p1.3.m3.1b"><ci id="S3.SS2.SSS2.p1.3.m3.1.1.cmml" xref="S3.SS2.SSS2.p1.3.m3.1.1">ℒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p1.3.m3.1c">\mathcal{L}</annotation></semantics></math> and <math id="S3.SS2.SSS2.p1.4.m4.1" class="ltx_Math" alttext="\mathcal{R}" display="inline"><semantics id="S3.SS2.SSS2.p1.4.m4.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.SSS2.p1.4.m4.1.1" xref="S3.SS2.SSS2.p1.4.m4.1.1.cmml">ℛ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p1.4.m4.1b"><ci id="S3.SS2.SSS2.p1.4.m4.1.1.cmml" xref="S3.SS2.SSS2.p1.4.m4.1.1">ℛ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p1.4.m4.1c">\mathcal{R}</annotation></semantics></math> are the datasets containing lidar and radar images, respectively. While the same architecture of these feature extractors guarantees that the modality alignment is preserved on the feature space,
they differ in the number of input channels to cater the respective needs of lidar and radar data.</p>
</div>
</section>
<section id="S3.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.3. </span>Feature-Level Sensor Fusion</h4>

<div id="S3.SS2.SSS3.p1" class="ltx_para">
<p id="S3.SS2.SSS3.p1.4" class="ltx_p">Two approaches exist for fusing multimodal data, i.e., data-level and feature-level fusion. AutoFed opts for feature-level fusion thanks to its better flexibility and low coupling offered by fusion at a later stage in the network. Specifically, to extend the OD network in § <a href="#S3.SS2.SSS1" title="3.2.1. Object Detection Basics ‣ 3.2. Multimodal Vehicle Detection ‣ 3. System Design ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2.1</span></a> to a multimodal setting, we further add parallel feature extractors for other modalities. Suppose the feature extractors output lidar feature map <math id="S3.SS2.SSS3.p1.1.m1.1" class="ltx_Math" alttext="\mathbf{z}_{l}" display="inline"><semantics id="S3.SS2.SSS3.p1.1.m1.1a"><msub id="S3.SS2.SSS3.p1.1.m1.1.1" xref="S3.SS2.SSS3.p1.1.m1.1.1.cmml"><mi id="S3.SS2.SSS3.p1.1.m1.1.1.2" xref="S3.SS2.SSS3.p1.1.m1.1.1.2.cmml">𝐳</mi><mi id="S3.SS2.SSS3.p1.1.m1.1.1.3" xref="S3.SS2.SSS3.p1.1.m1.1.1.3.cmml">l</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p1.1.m1.1b"><apply id="S3.SS2.SSS3.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p1.1.m1.1.1.1.cmml" xref="S3.SS2.SSS3.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.p1.1.m1.1.1.2.cmml" xref="S3.SS2.SSS3.p1.1.m1.1.1.2">𝐳</ci><ci id="S3.SS2.SSS3.p1.1.m1.1.1.3.cmml" xref="S3.SS2.SSS3.p1.1.m1.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p1.1.m1.1c">\mathbf{z}_{l}</annotation></semantics></math> and radar feature map <math id="S3.SS2.SSS3.p1.2.m2.1" class="ltx_Math" alttext="\mathbf{z}_{r}" display="inline"><semantics id="S3.SS2.SSS3.p1.2.m2.1a"><msub id="S3.SS2.SSS3.p1.2.m2.1.1" xref="S3.SS2.SSS3.p1.2.m2.1.1.cmml"><mi id="S3.SS2.SSS3.p1.2.m2.1.1.2" xref="S3.SS2.SSS3.p1.2.m2.1.1.2.cmml">𝐳</mi><mi id="S3.SS2.SSS3.p1.2.m2.1.1.3" xref="S3.SS2.SSS3.p1.2.m2.1.1.3.cmml">r</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p1.2.m2.1b"><apply id="S3.SS2.SSS3.p1.2.m2.1.1.cmml" xref="S3.SS2.SSS3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p1.2.m2.1.1.1.cmml" xref="S3.SS2.SSS3.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.p1.2.m2.1.1.2.cmml" xref="S3.SS2.SSS3.p1.2.m2.1.1.2">𝐳</ci><ci id="S3.SS2.SSS3.p1.2.m2.1.1.3.cmml" xref="S3.SS2.SSS3.p1.2.m2.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p1.2.m2.1c">\mathbf{z}_{r}</annotation></semantics></math>, one naive method to perform feature-level fusion would be to concatenate <math id="S3.SS2.SSS3.p1.3.m3.1" class="ltx_Math" alttext="\mathbf{z}_{l}" display="inline"><semantics id="S3.SS2.SSS3.p1.3.m3.1a"><msub id="S3.SS2.SSS3.p1.3.m3.1.1" xref="S3.SS2.SSS3.p1.3.m3.1.1.cmml"><mi id="S3.SS2.SSS3.p1.3.m3.1.1.2" xref="S3.SS2.SSS3.p1.3.m3.1.1.2.cmml">𝐳</mi><mi id="S3.SS2.SSS3.p1.3.m3.1.1.3" xref="S3.SS2.SSS3.p1.3.m3.1.1.3.cmml">l</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p1.3.m3.1b"><apply id="S3.SS2.SSS3.p1.3.m3.1.1.cmml" xref="S3.SS2.SSS3.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p1.3.m3.1.1.1.cmml" xref="S3.SS2.SSS3.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.p1.3.m3.1.1.2.cmml" xref="S3.SS2.SSS3.p1.3.m3.1.1.2">𝐳</ci><ci id="S3.SS2.SSS3.p1.3.m3.1.1.3.cmml" xref="S3.SS2.SSS3.p1.3.m3.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p1.3.m3.1c">\mathbf{z}_{l}</annotation></semantics></math> and <math id="S3.SS2.SSS3.p1.4.m4.1" class="ltx_Math" alttext="\mathbf{z}_{r}" display="inline"><semantics id="S3.SS2.SSS3.p1.4.m4.1a"><msub id="S3.SS2.SSS3.p1.4.m4.1.1" xref="S3.SS2.SSS3.p1.4.m4.1.1.cmml"><mi id="S3.SS2.SSS3.p1.4.m4.1.1.2" xref="S3.SS2.SSS3.p1.4.m4.1.1.2.cmml">𝐳</mi><mi id="S3.SS2.SSS3.p1.4.m4.1.1.3" xref="S3.SS2.SSS3.p1.4.m4.1.1.3.cmml">r</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p1.4.m4.1b"><apply id="S3.SS2.SSS3.p1.4.m4.1.1.cmml" xref="S3.SS2.SSS3.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p1.4.m4.1.1.1.cmml" xref="S3.SS2.SSS3.p1.4.m4.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.p1.4.m4.1.1.2.cmml" xref="S3.SS2.SSS3.p1.4.m4.1.1.2">𝐳</ci><ci id="S3.SS2.SSS3.p1.4.m4.1.1.3.cmml" xref="S3.SS2.SSS3.p1.4.m4.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p1.4.m4.1c">\mathbf{z}_{r}</annotation></semantics></math>, and feed the concatenated features to Step-2 of the OD network. However, this straightforward method fails to exploit the inter-modality relationship. A more relevant approach for exploiting the relationship is to apply the cross-attention mechanism <cite class="ltx_cite ltx_citemacro_citep">(Wei et al<span class="ltx_text">.</span>, <a href="#bib.bib69" title="" class="ltx_ref">2020</a>)</cite>. It generates an attention mask, in which information from a different modality is harnessed to enhance the latent features of the interested modality (e.g., an attention mask derived from lidar is used to enhance radar features, and vice versa). Different from the existing self-attention mechanism <cite class="ltx_cite ltx_citemacro_citep">(Vaswani et al<span class="ltx_text">.</span>, <a href="#bib.bib62" title="" class="ltx_ref">2017</a>)</cite>, our cross-attention mechanism focuses on modeling the cross-correlation among different modalities, and it adaptively learns the spatial correspondence to derive better alignment of important details from different modalities.</p>
</div>
<div id="S3.SS2.SSS3.p2" class="ltx_para">
<p id="S3.SS2.SSS3.p2.5" class="ltx_p">Essentially, our cross-attention mechanism can be described as transforming the latent representation <math id="S3.SS2.SSS3.p2.1.m1.1" class="ltx_Math" alttext="\mathbf{z}" display="inline"><semantics id="S3.SS2.SSS3.p2.1.m1.1a"><mi id="S3.SS2.SSS3.p2.1.m1.1.1" xref="S3.SS2.SSS3.p2.1.m1.1.1.cmml">𝐳</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p2.1.m1.1b"><ci id="S3.SS2.SSS3.p2.1.m1.1.1.cmml" xref="S3.SS2.SSS3.p2.1.m1.1.1">𝐳</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p2.1.m1.1c">\mathbf{z}</annotation></semantics></math> to a query <math id="S3.SS2.SSS3.p2.2.m2.1" class="ltx_Math" alttext="\mathbf{q}" display="inline"><semantics id="S3.SS2.SSS3.p2.2.m2.1a"><mi id="S3.SS2.SSS3.p2.2.m2.1.1" xref="S3.SS2.SSS3.p2.2.m2.1.1.cmml">𝐪</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p2.2.m2.1b"><ci id="S3.SS2.SSS3.p2.2.m2.1.1.cmml" xref="S3.SS2.SSS3.p2.2.m2.1.1">𝐪</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p2.2.m2.1c">\mathbf{q}</annotation></semantics></math> and a set of key-value pair <math id="S3.SS2.SSS3.p2.3.m3.1" class="ltx_Math" alttext="\mathbf{k}" display="inline"><semantics id="S3.SS2.SSS3.p2.3.m3.1a"><mi id="S3.SS2.SSS3.p2.3.m3.1.1" xref="S3.SS2.SSS3.p2.3.m3.1.1.cmml">𝐤</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p2.3.m3.1b"><ci id="S3.SS2.SSS3.p2.3.m3.1.1.cmml" xref="S3.SS2.SSS3.p2.3.m3.1.1">𝐤</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p2.3.m3.1c">\mathbf{k}</annotation></semantics></math> and <math id="S3.SS2.SSS3.p2.4.m4.1" class="ltx_Math" alttext="\mathbf{v}" display="inline"><semantics id="S3.SS2.SSS3.p2.4.m4.1a"><mi id="S3.SS2.SSS3.p2.4.m4.1.1" xref="S3.SS2.SSS3.p2.4.m4.1.1.cmml">𝐯</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p2.4.m4.1b"><ci id="S3.SS2.SSS3.p2.4.m4.1.1.cmml" xref="S3.SS2.SSS3.p2.4.m4.1.1">𝐯</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p2.4.m4.1c">\mathbf{v}</annotation></semantics></math>, and then mapping them to an output. The query, keys, and values are all linearly transformed versions of the input <math id="S3.SS2.SSS3.p2.5.m5.2" class="ltx_Math" alttext="\mathbf{z}_{s}\!:s\in\{\text{lidar},\text{radar}\}" display="inline"><semantics id="S3.SS2.SSS3.p2.5.m5.2a"><mrow id="S3.SS2.SSS3.p2.5.m5.2.3" xref="S3.SS2.SSS3.p2.5.m5.2.3.cmml"><msub id="S3.SS2.SSS3.p2.5.m5.2.3.2" xref="S3.SS2.SSS3.p2.5.m5.2.3.2.cmml"><mi id="S3.SS2.SSS3.p2.5.m5.2.3.2.2" xref="S3.SS2.SSS3.p2.5.m5.2.3.2.2.cmml">𝐳</mi><mi id="S3.SS2.SSS3.p2.5.m5.2.3.2.3" xref="S3.SS2.SSS3.p2.5.m5.2.3.2.3.cmml">s</mi></msub><mo lspace="0.108em" rspace="0.278em" id="S3.SS2.SSS3.p2.5.m5.2.3.1" xref="S3.SS2.SSS3.p2.5.m5.2.3.1.cmml">:</mo><mrow id="S3.SS2.SSS3.p2.5.m5.2.3.3" xref="S3.SS2.SSS3.p2.5.m5.2.3.3.cmml"><mi id="S3.SS2.SSS3.p2.5.m5.2.3.3.2" xref="S3.SS2.SSS3.p2.5.m5.2.3.3.2.cmml">s</mi><mo id="S3.SS2.SSS3.p2.5.m5.2.3.3.1" xref="S3.SS2.SSS3.p2.5.m5.2.3.3.1.cmml">∈</mo><mrow id="S3.SS2.SSS3.p2.5.m5.2.3.3.3.2" xref="S3.SS2.SSS3.p2.5.m5.2.3.3.3.1.cmml"><mo stretchy="false" id="S3.SS2.SSS3.p2.5.m5.2.3.3.3.2.1" xref="S3.SS2.SSS3.p2.5.m5.2.3.3.3.1.cmml">{</mo><mtext id="S3.SS2.SSS3.p2.5.m5.1.1" xref="S3.SS2.SSS3.p2.5.m5.1.1a.cmml">lidar</mtext><mo id="S3.SS2.SSS3.p2.5.m5.2.3.3.3.2.2" xref="S3.SS2.SSS3.p2.5.m5.2.3.3.3.1.cmml">,</mo><mtext id="S3.SS2.SSS3.p2.5.m5.2.2" xref="S3.SS2.SSS3.p2.5.m5.2.2a.cmml">radar</mtext><mo stretchy="false" id="S3.SS2.SSS3.p2.5.m5.2.3.3.3.2.3" xref="S3.SS2.SSS3.p2.5.m5.2.3.3.3.1.cmml">}</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p2.5.m5.2b"><apply id="S3.SS2.SSS3.p2.5.m5.2.3.cmml" xref="S3.SS2.SSS3.p2.5.m5.2.3"><ci id="S3.SS2.SSS3.p2.5.m5.2.3.1.cmml" xref="S3.SS2.SSS3.p2.5.m5.2.3.1">:</ci><apply id="S3.SS2.SSS3.p2.5.m5.2.3.2.cmml" xref="S3.SS2.SSS3.p2.5.m5.2.3.2"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p2.5.m5.2.3.2.1.cmml" xref="S3.SS2.SSS3.p2.5.m5.2.3.2">subscript</csymbol><ci id="S3.SS2.SSS3.p2.5.m5.2.3.2.2.cmml" xref="S3.SS2.SSS3.p2.5.m5.2.3.2.2">𝐳</ci><ci id="S3.SS2.SSS3.p2.5.m5.2.3.2.3.cmml" xref="S3.SS2.SSS3.p2.5.m5.2.3.2.3">𝑠</ci></apply><apply id="S3.SS2.SSS3.p2.5.m5.2.3.3.cmml" xref="S3.SS2.SSS3.p2.5.m5.2.3.3"><in id="S3.SS2.SSS3.p2.5.m5.2.3.3.1.cmml" xref="S3.SS2.SSS3.p2.5.m5.2.3.3.1"></in><ci id="S3.SS2.SSS3.p2.5.m5.2.3.3.2.cmml" xref="S3.SS2.SSS3.p2.5.m5.2.3.3.2">𝑠</ci><set id="S3.SS2.SSS3.p2.5.m5.2.3.3.3.1.cmml" xref="S3.SS2.SSS3.p2.5.m5.2.3.3.3.2"><ci id="S3.SS2.SSS3.p2.5.m5.1.1a.cmml" xref="S3.SS2.SSS3.p2.5.m5.1.1"><mtext id="S3.SS2.SSS3.p2.5.m5.1.1.cmml" xref="S3.SS2.SSS3.p2.5.m5.1.1">lidar</mtext></ci><ci id="S3.SS2.SSS3.p2.5.m5.2.2a.cmml" xref="S3.SS2.SSS3.p2.5.m5.2.2"><mtext id="S3.SS2.SSS3.p2.5.m5.2.2.cmml" xref="S3.SS2.SSS3.p2.5.m5.2.2">radar</mtext></ci></set></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p2.5.m5.2c">\mathbf{z}_{s}\!:s\in\{\text{lidar},\text{radar}\}</annotation></semantics></math>:</p>
<table id="Sx1.EGx2" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S3.E2"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(2)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E2.m1.1" class="ltx_Math" alttext="\displaystyle\mathbf{q}_{s}=\mathbf{W}_{q}\mathbf{z}_{\bar{s}}+\mathbf{b}_{q},~{}~{}~{}\mathbf{k}_{s}=\mathbf{W}_{k}\mathbf{z}_{\bar{s}}+\mathbf{b}_{k},~{}~{}~{}\mathbf{v}_{s}=\mathbf{W}_{v}\mathbf{z}_{s}+\mathbf{b}_{v}," display="inline"><semantics id="S3.E2.m1.1a"><mrow id="S3.E2.m1.1.1.1"><mrow id="S3.E2.m1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.3.cmml"><mrow id="S3.E2.m1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.cmml"><msub id="S3.E2.m1.1.1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.1.1.2.cmml"><mi id="S3.E2.m1.1.1.1.1.1.1.2.2" xref="S3.E2.m1.1.1.1.1.1.1.2.2.cmml">𝐪</mi><mi id="S3.E2.m1.1.1.1.1.1.1.2.3" xref="S3.E2.m1.1.1.1.1.1.1.2.3.cmml">s</mi></msub><mo id="S3.E2.m1.1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.1.cmml">=</mo><mrow id="S3.E2.m1.1.1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.1.1.3.cmml"><mrow id="S3.E2.m1.1.1.1.1.1.1.3.2" xref="S3.E2.m1.1.1.1.1.1.1.3.2.cmml"><msub id="S3.E2.m1.1.1.1.1.1.1.3.2.2" xref="S3.E2.m1.1.1.1.1.1.1.3.2.2.cmml"><mi id="S3.E2.m1.1.1.1.1.1.1.3.2.2.2" xref="S3.E2.m1.1.1.1.1.1.1.3.2.2.2.cmml">𝐖</mi><mi id="S3.E2.m1.1.1.1.1.1.1.3.2.2.3" xref="S3.E2.m1.1.1.1.1.1.1.3.2.2.3.cmml">q</mi></msub><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.1.1.1.1.1.3.2.1" xref="S3.E2.m1.1.1.1.1.1.1.3.2.1.cmml">​</mo><msub id="S3.E2.m1.1.1.1.1.1.1.3.2.3" xref="S3.E2.m1.1.1.1.1.1.1.3.2.3.cmml"><mi id="S3.E2.m1.1.1.1.1.1.1.3.2.3.2" xref="S3.E2.m1.1.1.1.1.1.1.3.2.3.2.cmml">𝐳</mi><mover accent="true" id="S3.E2.m1.1.1.1.1.1.1.3.2.3.3" xref="S3.E2.m1.1.1.1.1.1.1.3.2.3.3.cmml"><mi id="S3.E2.m1.1.1.1.1.1.1.3.2.3.3.2" xref="S3.E2.m1.1.1.1.1.1.1.3.2.3.3.2.cmml">s</mi><mo id="S3.E2.m1.1.1.1.1.1.1.3.2.3.3.1" xref="S3.E2.m1.1.1.1.1.1.1.3.2.3.3.1.cmml">¯</mo></mover></msub></mrow><mo id="S3.E2.m1.1.1.1.1.1.1.3.1" xref="S3.E2.m1.1.1.1.1.1.1.3.1.cmml">+</mo><msub id="S3.E2.m1.1.1.1.1.1.1.3.3" xref="S3.E2.m1.1.1.1.1.1.1.3.3.cmml"><mi id="S3.E2.m1.1.1.1.1.1.1.3.3.2" xref="S3.E2.m1.1.1.1.1.1.1.3.3.2.cmml">𝐛</mi><mi id="S3.E2.m1.1.1.1.1.1.1.3.3.3" xref="S3.E2.m1.1.1.1.1.1.1.3.3.3.cmml">q</mi></msub></mrow></mrow><mo rspace="1.157em" id="S3.E2.m1.1.1.1.1.2.3" xref="S3.E2.m1.1.1.1.1.3a.cmml">,</mo><mrow id="S3.E2.m1.1.1.1.1.2.2.2" xref="S3.E2.m1.1.1.1.1.2.2.3.cmml"><mrow id="S3.E2.m1.1.1.1.1.2.2.1.1" xref="S3.E2.m1.1.1.1.1.2.2.1.1.cmml"><msub id="S3.E2.m1.1.1.1.1.2.2.1.1.2" xref="S3.E2.m1.1.1.1.1.2.2.1.1.2.cmml"><mi id="S3.E2.m1.1.1.1.1.2.2.1.1.2.2" xref="S3.E2.m1.1.1.1.1.2.2.1.1.2.2.cmml">𝐤</mi><mi id="S3.E2.m1.1.1.1.1.2.2.1.1.2.3" xref="S3.E2.m1.1.1.1.1.2.2.1.1.2.3.cmml">s</mi></msub><mo id="S3.E2.m1.1.1.1.1.2.2.1.1.1" xref="S3.E2.m1.1.1.1.1.2.2.1.1.1.cmml">=</mo><mrow id="S3.E2.m1.1.1.1.1.2.2.1.1.3" xref="S3.E2.m1.1.1.1.1.2.2.1.1.3.cmml"><mrow id="S3.E2.m1.1.1.1.1.2.2.1.1.3.2" xref="S3.E2.m1.1.1.1.1.2.2.1.1.3.2.cmml"><msub id="S3.E2.m1.1.1.1.1.2.2.1.1.3.2.2" xref="S3.E2.m1.1.1.1.1.2.2.1.1.3.2.2.cmml"><mi id="S3.E2.m1.1.1.1.1.2.2.1.1.3.2.2.2" xref="S3.E2.m1.1.1.1.1.2.2.1.1.3.2.2.2.cmml">𝐖</mi><mi id="S3.E2.m1.1.1.1.1.2.2.1.1.3.2.2.3" xref="S3.E2.m1.1.1.1.1.2.2.1.1.3.2.2.3.cmml">k</mi></msub><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.1.1.1.2.2.1.1.3.2.1" xref="S3.E2.m1.1.1.1.1.2.2.1.1.3.2.1.cmml">​</mo><msub id="S3.E2.m1.1.1.1.1.2.2.1.1.3.2.3" xref="S3.E2.m1.1.1.1.1.2.2.1.1.3.2.3.cmml"><mi id="S3.E2.m1.1.1.1.1.2.2.1.1.3.2.3.2" xref="S3.E2.m1.1.1.1.1.2.2.1.1.3.2.3.2.cmml">𝐳</mi><mover accent="true" id="S3.E2.m1.1.1.1.1.2.2.1.1.3.2.3.3" xref="S3.E2.m1.1.1.1.1.2.2.1.1.3.2.3.3.cmml"><mi id="S3.E2.m1.1.1.1.1.2.2.1.1.3.2.3.3.2" xref="S3.E2.m1.1.1.1.1.2.2.1.1.3.2.3.3.2.cmml">s</mi><mo id="S3.E2.m1.1.1.1.1.2.2.1.1.3.2.3.3.1" xref="S3.E2.m1.1.1.1.1.2.2.1.1.3.2.3.3.1.cmml">¯</mo></mover></msub></mrow><mo id="S3.E2.m1.1.1.1.1.2.2.1.1.3.1" xref="S3.E2.m1.1.1.1.1.2.2.1.1.3.1.cmml">+</mo><msub id="S3.E2.m1.1.1.1.1.2.2.1.1.3.3" xref="S3.E2.m1.1.1.1.1.2.2.1.1.3.3.cmml"><mi id="S3.E2.m1.1.1.1.1.2.2.1.1.3.3.2" xref="S3.E2.m1.1.1.1.1.2.2.1.1.3.3.2.cmml">𝐛</mi><mi id="S3.E2.m1.1.1.1.1.2.2.1.1.3.3.3" xref="S3.E2.m1.1.1.1.1.2.2.1.1.3.3.3.cmml">k</mi></msub></mrow></mrow><mo rspace="1.157em" id="S3.E2.m1.1.1.1.1.2.2.2.3" xref="S3.E2.m1.1.1.1.1.2.2.3a.cmml">,</mo><mrow id="S3.E2.m1.1.1.1.1.2.2.2.2" xref="S3.E2.m1.1.1.1.1.2.2.2.2.cmml"><msub id="S3.E2.m1.1.1.1.1.2.2.2.2.2" xref="S3.E2.m1.1.1.1.1.2.2.2.2.2.cmml"><mi id="S3.E2.m1.1.1.1.1.2.2.2.2.2.2" xref="S3.E2.m1.1.1.1.1.2.2.2.2.2.2.cmml">𝐯</mi><mi id="S3.E2.m1.1.1.1.1.2.2.2.2.2.3" xref="S3.E2.m1.1.1.1.1.2.2.2.2.2.3.cmml">s</mi></msub><mo id="S3.E2.m1.1.1.1.1.2.2.2.2.1" xref="S3.E2.m1.1.1.1.1.2.2.2.2.1.cmml">=</mo><mrow id="S3.E2.m1.1.1.1.1.2.2.2.2.3" xref="S3.E2.m1.1.1.1.1.2.2.2.2.3.cmml"><mrow id="S3.E2.m1.1.1.1.1.2.2.2.2.3.2" xref="S3.E2.m1.1.1.1.1.2.2.2.2.3.2.cmml"><msub id="S3.E2.m1.1.1.1.1.2.2.2.2.3.2.2" xref="S3.E2.m1.1.1.1.1.2.2.2.2.3.2.2.cmml"><mi id="S3.E2.m1.1.1.1.1.2.2.2.2.3.2.2.2" xref="S3.E2.m1.1.1.1.1.2.2.2.2.3.2.2.2.cmml">𝐖</mi><mi id="S3.E2.m1.1.1.1.1.2.2.2.2.3.2.2.3" xref="S3.E2.m1.1.1.1.1.2.2.2.2.3.2.2.3.cmml">v</mi></msub><mo lspace="0em" rspace="0em" id="S3.E2.m1.1.1.1.1.2.2.2.2.3.2.1" xref="S3.E2.m1.1.1.1.1.2.2.2.2.3.2.1.cmml">​</mo><msub id="S3.E2.m1.1.1.1.1.2.2.2.2.3.2.3" xref="S3.E2.m1.1.1.1.1.2.2.2.2.3.2.3.cmml"><mi id="S3.E2.m1.1.1.1.1.2.2.2.2.3.2.3.2" xref="S3.E2.m1.1.1.1.1.2.2.2.2.3.2.3.2.cmml">𝐳</mi><mi id="S3.E2.m1.1.1.1.1.2.2.2.2.3.2.3.3" xref="S3.E2.m1.1.1.1.1.2.2.2.2.3.2.3.3.cmml">s</mi></msub></mrow><mo id="S3.E2.m1.1.1.1.1.2.2.2.2.3.1" xref="S3.E2.m1.1.1.1.1.2.2.2.2.3.1.cmml">+</mo><msub id="S3.E2.m1.1.1.1.1.2.2.2.2.3.3" xref="S3.E2.m1.1.1.1.1.2.2.2.2.3.3.cmml"><mi id="S3.E2.m1.1.1.1.1.2.2.2.2.3.3.2" xref="S3.E2.m1.1.1.1.1.2.2.2.2.3.3.2.cmml">𝐛</mi><mi id="S3.E2.m1.1.1.1.1.2.2.2.2.3.3.3" xref="S3.E2.m1.1.1.1.1.2.2.2.2.3.3.3.cmml">v</mi></msub></mrow></mrow></mrow></mrow><mo id="S3.E2.m1.1.1.1.2">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.1b"><apply id="S3.E2.m1.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.3a.cmml" xref="S3.E2.m1.1.1.1.1.2.3">formulae-sequence</csymbol><apply id="S3.E2.m1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1"><eq id="S3.E2.m1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1"></eq><apply id="S3.E2.m1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.1.1.2.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.1.1.2.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2.2">𝐪</ci><ci id="S3.E2.m1.1.1.1.1.1.1.2.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.2.3">𝑠</ci></apply><apply id="S3.E2.m1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3"><plus id="S3.E2.m1.1.1.1.1.1.1.3.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.1"></plus><apply id="S3.E2.m1.1.1.1.1.1.1.3.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.2"><times id="S3.E2.m1.1.1.1.1.1.1.3.2.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.2.1"></times><apply id="S3.E2.m1.1.1.1.1.1.1.3.2.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.1.1.3.2.2.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.2.2">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.1.1.3.2.2.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.2.2.2">𝐖</ci><ci id="S3.E2.m1.1.1.1.1.1.1.3.2.2.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.2.2.3">𝑞</ci></apply><apply id="S3.E2.m1.1.1.1.1.1.1.3.2.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.2.3"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.1.1.3.2.3.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.2.3">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.1.1.3.2.3.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.2.3.2">𝐳</ci><apply id="S3.E2.m1.1.1.1.1.1.1.3.2.3.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.2.3.3"><ci id="S3.E2.m1.1.1.1.1.1.1.3.2.3.3.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.2.3.3.1">¯</ci><ci id="S3.E2.m1.1.1.1.1.1.1.3.2.3.3.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.2.3.3.2">𝑠</ci></apply></apply></apply><apply id="S3.E2.m1.1.1.1.1.1.1.3.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.1.1.3.3.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.3">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.1.1.3.3.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.3.2">𝐛</ci><ci id="S3.E2.m1.1.1.1.1.1.1.3.3.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3.3.3">𝑞</ci></apply></apply></apply><apply id="S3.E2.m1.1.1.1.1.2.2.3.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.2.2.3a.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.3">formulae-sequence</csymbol><apply id="S3.E2.m1.1.1.1.1.2.2.1.1.cmml" xref="S3.E2.m1.1.1.1.1.2.2.1.1"><eq id="S3.E2.m1.1.1.1.1.2.2.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.2.2.1.1.1"></eq><apply id="S3.E2.m1.1.1.1.1.2.2.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1.2.2.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.2.2.1.1.2.1.cmml" xref="S3.E2.m1.1.1.1.1.2.2.1.1.2">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.2.2.1.1.2.2.cmml" xref="S3.E2.m1.1.1.1.1.2.2.1.1.2.2">𝐤</ci><ci id="S3.E2.m1.1.1.1.1.2.2.1.1.2.3.cmml" xref="S3.E2.m1.1.1.1.1.2.2.1.1.2.3">𝑠</ci></apply><apply id="S3.E2.m1.1.1.1.1.2.2.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.2.2.1.1.3"><plus id="S3.E2.m1.1.1.1.1.2.2.1.1.3.1.cmml" xref="S3.E2.m1.1.1.1.1.2.2.1.1.3.1"></plus><apply id="S3.E2.m1.1.1.1.1.2.2.1.1.3.2.cmml" xref="S3.E2.m1.1.1.1.1.2.2.1.1.3.2"><times id="S3.E2.m1.1.1.1.1.2.2.1.1.3.2.1.cmml" xref="S3.E2.m1.1.1.1.1.2.2.1.1.3.2.1"></times><apply id="S3.E2.m1.1.1.1.1.2.2.1.1.3.2.2.cmml" xref="S3.E2.m1.1.1.1.1.2.2.1.1.3.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.2.2.1.1.3.2.2.1.cmml" xref="S3.E2.m1.1.1.1.1.2.2.1.1.3.2.2">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.2.2.1.1.3.2.2.2.cmml" xref="S3.E2.m1.1.1.1.1.2.2.1.1.3.2.2.2">𝐖</ci><ci id="S3.E2.m1.1.1.1.1.2.2.1.1.3.2.2.3.cmml" xref="S3.E2.m1.1.1.1.1.2.2.1.1.3.2.2.3">𝑘</ci></apply><apply id="S3.E2.m1.1.1.1.1.2.2.1.1.3.2.3.cmml" xref="S3.E2.m1.1.1.1.1.2.2.1.1.3.2.3"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.2.2.1.1.3.2.3.1.cmml" xref="S3.E2.m1.1.1.1.1.2.2.1.1.3.2.3">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.2.2.1.1.3.2.3.2.cmml" xref="S3.E2.m1.1.1.1.1.2.2.1.1.3.2.3.2">𝐳</ci><apply id="S3.E2.m1.1.1.1.1.2.2.1.1.3.2.3.3.cmml" xref="S3.E2.m1.1.1.1.1.2.2.1.1.3.2.3.3"><ci id="S3.E2.m1.1.1.1.1.2.2.1.1.3.2.3.3.1.cmml" xref="S3.E2.m1.1.1.1.1.2.2.1.1.3.2.3.3.1">¯</ci><ci id="S3.E2.m1.1.1.1.1.2.2.1.1.3.2.3.3.2.cmml" xref="S3.E2.m1.1.1.1.1.2.2.1.1.3.2.3.3.2">𝑠</ci></apply></apply></apply><apply id="S3.E2.m1.1.1.1.1.2.2.1.1.3.3.cmml" xref="S3.E2.m1.1.1.1.1.2.2.1.1.3.3"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.2.2.1.1.3.3.1.cmml" xref="S3.E2.m1.1.1.1.1.2.2.1.1.3.3">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.2.2.1.1.3.3.2.cmml" xref="S3.E2.m1.1.1.1.1.2.2.1.1.3.3.2">𝐛</ci><ci id="S3.E2.m1.1.1.1.1.2.2.1.1.3.3.3.cmml" xref="S3.E2.m1.1.1.1.1.2.2.1.1.3.3.3">𝑘</ci></apply></apply></apply><apply id="S3.E2.m1.1.1.1.1.2.2.2.2.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2"><eq id="S3.E2.m1.1.1.1.1.2.2.2.2.1.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2.1"></eq><apply id="S3.E2.m1.1.1.1.1.2.2.2.2.2.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.2.2.2.2.2.1.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2.2">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.2.2.2.2.2.2.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2.2.2">𝐯</ci><ci id="S3.E2.m1.1.1.1.1.2.2.2.2.2.3.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2.2.3">𝑠</ci></apply><apply id="S3.E2.m1.1.1.1.1.2.2.2.2.3.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2.3"><plus id="S3.E2.m1.1.1.1.1.2.2.2.2.3.1.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2.3.1"></plus><apply id="S3.E2.m1.1.1.1.1.2.2.2.2.3.2.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2.3.2"><times id="S3.E2.m1.1.1.1.1.2.2.2.2.3.2.1.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2.3.2.1"></times><apply id="S3.E2.m1.1.1.1.1.2.2.2.2.3.2.2.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2.3.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.2.2.2.2.3.2.2.1.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2.3.2.2">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.2.2.2.2.3.2.2.2.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2.3.2.2.2">𝐖</ci><ci id="S3.E2.m1.1.1.1.1.2.2.2.2.3.2.2.3.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2.3.2.2.3">𝑣</ci></apply><apply id="S3.E2.m1.1.1.1.1.2.2.2.2.3.2.3.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2.3.2.3"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.2.2.2.2.3.2.3.1.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2.3.2.3">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.2.2.2.2.3.2.3.2.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2.3.2.3.2">𝐳</ci><ci id="S3.E2.m1.1.1.1.1.2.2.2.2.3.2.3.3.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2.3.2.3.3">𝑠</ci></apply></apply><apply id="S3.E2.m1.1.1.1.1.2.2.2.2.3.3.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2.3.3"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.2.2.2.2.3.3.1.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2.3.3">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.2.2.2.2.3.3.2.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2.3.3.2">𝐛</ci><ci id="S3.E2.m1.1.1.1.1.2.2.2.2.3.3.3.cmml" xref="S3.E2.m1.1.1.1.1.2.2.2.2.3.3.3">𝑣</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.1c">\displaystyle\mathbf{q}_{s}=\mathbf{W}_{q}\mathbf{z}_{\bar{s}}+\mathbf{b}_{q},~{}~{}~{}\mathbf{k}_{s}=\mathbf{W}_{k}\mathbf{z}_{\bar{s}}+\mathbf{b}_{k},~{}~{}~{}\mathbf{v}_{s}=\mathbf{W}_{v}\mathbf{z}_{s}+\mathbf{b}_{v},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S3.SS2.SSS3.p2.26" class="ltx_p">where <math id="S3.SS2.SSS3.p2.6.m1.1" class="ltx_Math" alttext="\bar{s}" display="inline"><semantics id="S3.SS2.SSS3.p2.6.m1.1a"><mover accent="true" id="S3.SS2.SSS3.p2.6.m1.1.1" xref="S3.SS2.SSS3.p2.6.m1.1.1.cmml"><mi id="S3.SS2.SSS3.p2.6.m1.1.1.2" xref="S3.SS2.SSS3.p2.6.m1.1.1.2.cmml">s</mi><mo id="S3.SS2.SSS3.p2.6.m1.1.1.1" xref="S3.SS2.SSS3.p2.6.m1.1.1.1.cmml">¯</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p2.6.m1.1b"><apply id="S3.SS2.SSS3.p2.6.m1.1.1.cmml" xref="S3.SS2.SSS3.p2.6.m1.1.1"><ci id="S3.SS2.SSS3.p2.6.m1.1.1.1.cmml" xref="S3.SS2.SSS3.p2.6.m1.1.1.1">¯</ci><ci id="S3.SS2.SSS3.p2.6.m1.1.1.2.cmml" xref="S3.SS2.SSS3.p2.6.m1.1.1.2">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p2.6.m1.1c">\bar{s}</annotation></semantics></math> is the complementary sensing modality of <math id="S3.SS2.SSS3.p2.7.m2.1" class="ltx_Math" alttext="s" display="inline"><semantics id="S3.SS2.SSS3.p2.7.m2.1a"><mi id="S3.SS2.SSS3.p2.7.m2.1.1" xref="S3.SS2.SSS3.p2.7.m2.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p2.7.m2.1b"><ci id="S3.SS2.SSS3.p2.7.m2.1.1.cmml" xref="S3.SS2.SSS3.p2.7.m2.1.1">𝑠</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p2.7.m2.1c">s</annotation></semantics></math> (e.g., if <math id="S3.SS2.SSS3.p2.8.m3.1" class="ltx_Math" alttext="s" display="inline"><semantics id="S3.SS2.SSS3.p2.8.m3.1a"><mi id="S3.SS2.SSS3.p2.8.m3.1.1" xref="S3.SS2.SSS3.p2.8.m3.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p2.8.m3.1b"><ci id="S3.SS2.SSS3.p2.8.m3.1.1.cmml" xref="S3.SS2.SSS3.p2.8.m3.1.1">𝑠</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p2.8.m3.1c">s</annotation></semantics></math> is radar, then <math id="S3.SS2.SSS3.p2.9.m4.1" class="ltx_Math" alttext="\bar{s}" display="inline"><semantics id="S3.SS2.SSS3.p2.9.m4.1a"><mover accent="true" id="S3.SS2.SSS3.p2.9.m4.1.1" xref="S3.SS2.SSS3.p2.9.m4.1.1.cmml"><mi id="S3.SS2.SSS3.p2.9.m4.1.1.2" xref="S3.SS2.SSS3.p2.9.m4.1.1.2.cmml">s</mi><mo id="S3.SS2.SSS3.p2.9.m4.1.1.1" xref="S3.SS2.SSS3.p2.9.m4.1.1.1.cmml">¯</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p2.9.m4.1b"><apply id="S3.SS2.SSS3.p2.9.m4.1.1.cmml" xref="S3.SS2.SSS3.p2.9.m4.1.1"><ci id="S3.SS2.SSS3.p2.9.m4.1.1.1.cmml" xref="S3.SS2.SSS3.p2.9.m4.1.1.1">¯</ci><ci id="S3.SS2.SSS3.p2.9.m4.1.1.2.cmml" xref="S3.SS2.SSS3.p2.9.m4.1.1.2">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p2.9.m4.1c">\bar{s}</annotation></semantics></math> is lidar, and vice versa), <math id="S3.SS2.SSS3.p2.10.m5.1" class="ltx_Math" alttext="\mathbf{W}_{q}" display="inline"><semantics id="S3.SS2.SSS3.p2.10.m5.1a"><msub id="S3.SS2.SSS3.p2.10.m5.1.1" xref="S3.SS2.SSS3.p2.10.m5.1.1.cmml"><mi id="S3.SS2.SSS3.p2.10.m5.1.1.2" xref="S3.SS2.SSS3.p2.10.m5.1.1.2.cmml">𝐖</mi><mi id="S3.SS2.SSS3.p2.10.m5.1.1.3" xref="S3.SS2.SSS3.p2.10.m5.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p2.10.m5.1b"><apply id="S3.SS2.SSS3.p2.10.m5.1.1.cmml" xref="S3.SS2.SSS3.p2.10.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p2.10.m5.1.1.1.cmml" xref="S3.SS2.SSS3.p2.10.m5.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.p2.10.m5.1.1.2.cmml" xref="S3.SS2.SSS3.p2.10.m5.1.1.2">𝐖</ci><ci id="S3.SS2.SSS3.p2.10.m5.1.1.3.cmml" xref="S3.SS2.SSS3.p2.10.m5.1.1.3">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p2.10.m5.1c">\mathbf{W}_{q}</annotation></semantics></math>, <math id="S3.SS2.SSS3.p2.11.m6.1" class="ltx_Math" alttext="\mathbf{W}_{k}" display="inline"><semantics id="S3.SS2.SSS3.p2.11.m6.1a"><msub id="S3.SS2.SSS3.p2.11.m6.1.1" xref="S3.SS2.SSS3.p2.11.m6.1.1.cmml"><mi id="S3.SS2.SSS3.p2.11.m6.1.1.2" xref="S3.SS2.SSS3.p2.11.m6.1.1.2.cmml">𝐖</mi><mi id="S3.SS2.SSS3.p2.11.m6.1.1.3" xref="S3.SS2.SSS3.p2.11.m6.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p2.11.m6.1b"><apply id="S3.SS2.SSS3.p2.11.m6.1.1.cmml" xref="S3.SS2.SSS3.p2.11.m6.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p2.11.m6.1.1.1.cmml" xref="S3.SS2.SSS3.p2.11.m6.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.p2.11.m6.1.1.2.cmml" xref="S3.SS2.SSS3.p2.11.m6.1.1.2">𝐖</ci><ci id="S3.SS2.SSS3.p2.11.m6.1.1.3.cmml" xref="S3.SS2.SSS3.p2.11.m6.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p2.11.m6.1c">\mathbf{W}_{k}</annotation></semantics></math>, <math id="S3.SS2.SSS3.p2.12.m7.1" class="ltx_Math" alttext="\mathbf{W}_{v}" display="inline"><semantics id="S3.SS2.SSS3.p2.12.m7.1a"><msub id="S3.SS2.SSS3.p2.12.m7.1.1" xref="S3.SS2.SSS3.p2.12.m7.1.1.cmml"><mi id="S3.SS2.SSS3.p2.12.m7.1.1.2" xref="S3.SS2.SSS3.p2.12.m7.1.1.2.cmml">𝐖</mi><mi id="S3.SS2.SSS3.p2.12.m7.1.1.3" xref="S3.SS2.SSS3.p2.12.m7.1.1.3.cmml">v</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p2.12.m7.1b"><apply id="S3.SS2.SSS3.p2.12.m7.1.1.cmml" xref="S3.SS2.SSS3.p2.12.m7.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p2.12.m7.1.1.1.cmml" xref="S3.SS2.SSS3.p2.12.m7.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.p2.12.m7.1.1.2.cmml" xref="S3.SS2.SSS3.p2.12.m7.1.1.2">𝐖</ci><ci id="S3.SS2.SSS3.p2.12.m7.1.1.3.cmml" xref="S3.SS2.SSS3.p2.12.m7.1.1.3">𝑣</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p2.12.m7.1c">\mathbf{W}_{v}</annotation></semantics></math> and <math id="S3.SS2.SSS3.p2.13.m8.1" class="ltx_Math" alttext="\mathbf{b}_{q}" display="inline"><semantics id="S3.SS2.SSS3.p2.13.m8.1a"><msub id="S3.SS2.SSS3.p2.13.m8.1.1" xref="S3.SS2.SSS3.p2.13.m8.1.1.cmml"><mi id="S3.SS2.SSS3.p2.13.m8.1.1.2" xref="S3.SS2.SSS3.p2.13.m8.1.1.2.cmml">𝐛</mi><mi id="S3.SS2.SSS3.p2.13.m8.1.1.3" xref="S3.SS2.SSS3.p2.13.m8.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p2.13.m8.1b"><apply id="S3.SS2.SSS3.p2.13.m8.1.1.cmml" xref="S3.SS2.SSS3.p2.13.m8.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p2.13.m8.1.1.1.cmml" xref="S3.SS2.SSS3.p2.13.m8.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.p2.13.m8.1.1.2.cmml" xref="S3.SS2.SSS3.p2.13.m8.1.1.2">𝐛</ci><ci id="S3.SS2.SSS3.p2.13.m8.1.1.3.cmml" xref="S3.SS2.SSS3.p2.13.m8.1.1.3">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p2.13.m8.1c">\mathbf{b}_{q}</annotation></semantics></math>, <math id="S3.SS2.SSS3.p2.14.m9.1" class="ltx_Math" alttext="\mathbf{b}_{k}" display="inline"><semantics id="S3.SS2.SSS3.p2.14.m9.1a"><msub id="S3.SS2.SSS3.p2.14.m9.1.1" xref="S3.SS2.SSS3.p2.14.m9.1.1.cmml"><mi id="S3.SS2.SSS3.p2.14.m9.1.1.2" xref="S3.SS2.SSS3.p2.14.m9.1.1.2.cmml">𝐛</mi><mi id="S3.SS2.SSS3.p2.14.m9.1.1.3" xref="S3.SS2.SSS3.p2.14.m9.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p2.14.m9.1b"><apply id="S3.SS2.SSS3.p2.14.m9.1.1.cmml" xref="S3.SS2.SSS3.p2.14.m9.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p2.14.m9.1.1.1.cmml" xref="S3.SS2.SSS3.p2.14.m9.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.p2.14.m9.1.1.2.cmml" xref="S3.SS2.SSS3.p2.14.m9.1.1.2">𝐛</ci><ci id="S3.SS2.SSS3.p2.14.m9.1.1.3.cmml" xref="S3.SS2.SSS3.p2.14.m9.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p2.14.m9.1c">\mathbf{b}_{k}</annotation></semantics></math>, <math id="S3.SS2.SSS3.p2.15.m10.1" class="ltx_Math" alttext="\mathbf{b}_{v}" display="inline"><semantics id="S3.SS2.SSS3.p2.15.m10.1a"><msub id="S3.SS2.SSS3.p2.15.m10.1.1" xref="S3.SS2.SSS3.p2.15.m10.1.1.cmml"><mi id="S3.SS2.SSS3.p2.15.m10.1.1.2" xref="S3.SS2.SSS3.p2.15.m10.1.1.2.cmml">𝐛</mi><mi id="S3.SS2.SSS3.p2.15.m10.1.1.3" xref="S3.SS2.SSS3.p2.15.m10.1.1.3.cmml">v</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p2.15.m10.1b"><apply id="S3.SS2.SSS3.p2.15.m10.1.1.cmml" xref="S3.SS2.SSS3.p2.15.m10.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p2.15.m10.1.1.1.cmml" xref="S3.SS2.SSS3.p2.15.m10.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.p2.15.m10.1.1.2.cmml" xref="S3.SS2.SSS3.p2.15.m10.1.1.2">𝐛</ci><ci id="S3.SS2.SSS3.p2.15.m10.1.1.3.cmml" xref="S3.SS2.SSS3.p2.15.m10.1.1.3">𝑣</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p2.15.m10.1c">\mathbf{b}_{v}</annotation></semantics></math> are trainable matrices and vectors that help transforming the input to its corresponding query <math id="S3.SS2.SSS3.p2.16.m11.1" class="ltx_Math" alttext="\mathbf{q}_{s}" display="inline"><semantics id="S3.SS2.SSS3.p2.16.m11.1a"><msub id="S3.SS2.SSS3.p2.16.m11.1.1" xref="S3.SS2.SSS3.p2.16.m11.1.1.cmml"><mi id="S3.SS2.SSS3.p2.16.m11.1.1.2" xref="S3.SS2.SSS3.p2.16.m11.1.1.2.cmml">𝐪</mi><mi id="S3.SS2.SSS3.p2.16.m11.1.1.3" xref="S3.SS2.SSS3.p2.16.m11.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p2.16.m11.1b"><apply id="S3.SS2.SSS3.p2.16.m11.1.1.cmml" xref="S3.SS2.SSS3.p2.16.m11.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p2.16.m11.1.1.1.cmml" xref="S3.SS2.SSS3.p2.16.m11.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.p2.16.m11.1.1.2.cmml" xref="S3.SS2.SSS3.p2.16.m11.1.1.2">𝐪</ci><ci id="S3.SS2.SSS3.p2.16.m11.1.1.3.cmml" xref="S3.SS2.SSS3.p2.16.m11.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p2.16.m11.1c">\mathbf{q}_{s}</annotation></semantics></math>, key <math id="S3.SS2.SSS3.p2.17.m12.1" class="ltx_Math" alttext="\mathbf{k}_{s}" display="inline"><semantics id="S3.SS2.SSS3.p2.17.m12.1a"><msub id="S3.SS2.SSS3.p2.17.m12.1.1" xref="S3.SS2.SSS3.p2.17.m12.1.1.cmml"><mi id="S3.SS2.SSS3.p2.17.m12.1.1.2" xref="S3.SS2.SSS3.p2.17.m12.1.1.2.cmml">𝐤</mi><mi id="S3.SS2.SSS3.p2.17.m12.1.1.3" xref="S3.SS2.SSS3.p2.17.m12.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p2.17.m12.1b"><apply id="S3.SS2.SSS3.p2.17.m12.1.1.cmml" xref="S3.SS2.SSS3.p2.17.m12.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p2.17.m12.1.1.1.cmml" xref="S3.SS2.SSS3.p2.17.m12.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.p2.17.m12.1.1.2.cmml" xref="S3.SS2.SSS3.p2.17.m12.1.1.2">𝐤</ci><ci id="S3.SS2.SSS3.p2.17.m12.1.1.3.cmml" xref="S3.SS2.SSS3.p2.17.m12.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p2.17.m12.1c">\mathbf{k}_{s}</annotation></semantics></math>, and value <math id="S3.SS2.SSS3.p2.18.m13.1" class="ltx_Math" alttext="\mathbf{v}_{s}" display="inline"><semantics id="S3.SS2.SSS3.p2.18.m13.1a"><msub id="S3.SS2.SSS3.p2.18.m13.1.1" xref="S3.SS2.SSS3.p2.18.m13.1.1.cmml"><mi id="S3.SS2.SSS3.p2.18.m13.1.1.2" xref="S3.SS2.SSS3.p2.18.m13.1.1.2.cmml">𝐯</mi><mi id="S3.SS2.SSS3.p2.18.m13.1.1.3" xref="S3.SS2.SSS3.p2.18.m13.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p2.18.m13.1b"><apply id="S3.SS2.SSS3.p2.18.m13.1.1.cmml" xref="S3.SS2.SSS3.p2.18.m13.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p2.18.m13.1.1.1.cmml" xref="S3.SS2.SSS3.p2.18.m13.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.p2.18.m13.1.1.2.cmml" xref="S3.SS2.SSS3.p2.18.m13.1.1.2">𝐯</ci><ci id="S3.SS2.SSS3.p2.18.m13.1.1.3.cmml" xref="S3.SS2.SSS3.p2.18.m13.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p2.18.m13.1c">\mathbf{v}_{s}</annotation></semantics></math>, whose dimensions are denoted by <math id="S3.SS2.SSS3.p2.19.m14.1" class="ltx_Math" alttext="d_{q}" display="inline"><semantics id="S3.SS2.SSS3.p2.19.m14.1a"><msub id="S3.SS2.SSS3.p2.19.m14.1.1" xref="S3.SS2.SSS3.p2.19.m14.1.1.cmml"><mi id="S3.SS2.SSS3.p2.19.m14.1.1.2" xref="S3.SS2.SSS3.p2.19.m14.1.1.2.cmml">d</mi><mi id="S3.SS2.SSS3.p2.19.m14.1.1.3" xref="S3.SS2.SSS3.p2.19.m14.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p2.19.m14.1b"><apply id="S3.SS2.SSS3.p2.19.m14.1.1.cmml" xref="S3.SS2.SSS3.p2.19.m14.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p2.19.m14.1.1.1.cmml" xref="S3.SS2.SSS3.p2.19.m14.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.p2.19.m14.1.1.2.cmml" xref="S3.SS2.SSS3.p2.19.m14.1.1.2">𝑑</ci><ci id="S3.SS2.SSS3.p2.19.m14.1.1.3.cmml" xref="S3.SS2.SSS3.p2.19.m14.1.1.3">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p2.19.m14.1c">d_{q}</annotation></semantics></math>, <math id="S3.SS2.SSS3.p2.20.m15.1" class="ltx_Math" alttext="d_{k}" display="inline"><semantics id="S3.SS2.SSS3.p2.20.m15.1a"><msub id="S3.SS2.SSS3.p2.20.m15.1.1" xref="S3.SS2.SSS3.p2.20.m15.1.1.cmml"><mi id="S3.SS2.SSS3.p2.20.m15.1.1.2" xref="S3.SS2.SSS3.p2.20.m15.1.1.2.cmml">d</mi><mi id="S3.SS2.SSS3.p2.20.m15.1.1.3" xref="S3.SS2.SSS3.p2.20.m15.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p2.20.m15.1b"><apply id="S3.SS2.SSS3.p2.20.m15.1.1.cmml" xref="S3.SS2.SSS3.p2.20.m15.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p2.20.m15.1.1.1.cmml" xref="S3.SS2.SSS3.p2.20.m15.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.p2.20.m15.1.1.2.cmml" xref="S3.SS2.SSS3.p2.20.m15.1.1.2">𝑑</ci><ci id="S3.SS2.SSS3.p2.20.m15.1.1.3.cmml" xref="S3.SS2.SSS3.p2.20.m15.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p2.20.m15.1c">d_{k}</annotation></semantics></math>, <math id="S3.SS2.SSS3.p2.21.m16.1" class="ltx_Math" alttext="d_{v}" display="inline"><semantics id="S3.SS2.SSS3.p2.21.m16.1a"><msub id="S3.SS2.SSS3.p2.21.m16.1.1" xref="S3.SS2.SSS3.p2.21.m16.1.1.cmml"><mi id="S3.SS2.SSS3.p2.21.m16.1.1.2" xref="S3.SS2.SSS3.p2.21.m16.1.1.2.cmml">d</mi><mi id="S3.SS2.SSS3.p2.21.m16.1.1.3" xref="S3.SS2.SSS3.p2.21.m16.1.1.3.cmml">v</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p2.21.m16.1b"><apply id="S3.SS2.SSS3.p2.21.m16.1.1.cmml" xref="S3.SS2.SSS3.p2.21.m16.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p2.21.m16.1.1.1.cmml" xref="S3.SS2.SSS3.p2.21.m16.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.p2.21.m16.1.1.2.cmml" xref="S3.SS2.SSS3.p2.21.m16.1.1.2">𝑑</ci><ci id="S3.SS2.SSS3.p2.21.m16.1.1.3.cmml" xref="S3.SS2.SSS3.p2.21.m16.1.1.3">𝑣</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p2.21.m16.1c">d_{v}</annotation></semantics></math>, respectively. The output context <math id="S3.SS2.SSS3.p2.22.m17.1" class="ltx_Math" alttext="\mathbf{z^{\prime}}_{s}" display="inline"><semantics id="S3.SS2.SSS3.p2.22.m17.1a"><mmultiscripts id="S3.SS2.SSS3.p2.22.m17.1.1" xref="S3.SS2.SSS3.p2.22.m17.1.1.cmml"><mi id="S3.SS2.SSS3.p2.22.m17.1.1.2.2" xref="S3.SS2.SSS3.p2.22.m17.1.1.2.2.cmml">𝐳</mi><mrow id="S3.SS2.SSS3.p2.22.m17.1.1a" xref="S3.SS2.SSS3.p2.22.m17.1.1.cmml"></mrow><mo id="S3.SS2.SSS3.p2.22.m17.1.1.2.3" xref="S3.SS2.SSS3.p2.22.m17.1.1.2.3.cmml">′</mo><mi id="S3.SS2.SSS3.p2.22.m17.1.1.3" xref="S3.SS2.SSS3.p2.22.m17.1.1.3.cmml">s</mi><mrow id="S3.SS2.SSS3.p2.22.m17.1.1b" xref="S3.SS2.SSS3.p2.22.m17.1.1.cmml"></mrow></mmultiscripts><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p2.22.m17.1b"><apply id="S3.SS2.SSS3.p2.22.m17.1.1.cmml" xref="S3.SS2.SSS3.p2.22.m17.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p2.22.m17.1.1.1.cmml" xref="S3.SS2.SSS3.p2.22.m17.1.1">subscript</csymbol><apply id="S3.SS2.SSS3.p2.22.m17.1.1.2.cmml" xref="S3.SS2.SSS3.p2.22.m17.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p2.22.m17.1.1.2.1.cmml" xref="S3.SS2.SSS3.p2.22.m17.1.1">superscript</csymbol><ci id="S3.SS2.SSS3.p2.22.m17.1.1.2.2.cmml" xref="S3.SS2.SSS3.p2.22.m17.1.1.2.2">𝐳</ci><ci id="S3.SS2.SSS3.p2.22.m17.1.1.2.3.cmml" xref="S3.SS2.SSS3.p2.22.m17.1.1.2.3">′</ci></apply><ci id="S3.SS2.SSS3.p2.22.m17.1.1.3.cmml" xref="S3.SS2.SSS3.p2.22.m17.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p2.22.m17.1c">\mathbf{z^{\prime}}_{s}</annotation></semantics></math> is obtained as a weighted sum of the values in <math id="S3.SS2.SSS3.p2.23.m18.1" class="ltx_Math" alttext="\mathbf{v}_{s}" display="inline"><semantics id="S3.SS2.SSS3.p2.23.m18.1a"><msub id="S3.SS2.SSS3.p2.23.m18.1.1" xref="S3.SS2.SSS3.p2.23.m18.1.1.cmml"><mi id="S3.SS2.SSS3.p2.23.m18.1.1.2" xref="S3.SS2.SSS3.p2.23.m18.1.1.2.cmml">𝐯</mi><mi id="S3.SS2.SSS3.p2.23.m18.1.1.3" xref="S3.SS2.SSS3.p2.23.m18.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p2.23.m18.1b"><apply id="S3.SS2.SSS3.p2.23.m18.1.1.cmml" xref="S3.SS2.SSS3.p2.23.m18.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p2.23.m18.1.1.1.cmml" xref="S3.SS2.SSS3.p2.23.m18.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.p2.23.m18.1.1.2.cmml" xref="S3.SS2.SSS3.p2.23.m18.1.1.2">𝐯</ci><ci id="S3.SS2.SSS3.p2.23.m18.1.1.3.cmml" xref="S3.SS2.SSS3.p2.23.m18.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p2.23.m18.1c">\mathbf{v}_{s}</annotation></semantics></math>, where the weight of each value is a normalized product of the query <math id="S3.SS2.SSS3.p2.24.m19.1" class="ltx_Math" alttext="\mathbf{q}_{s}" display="inline"><semantics id="S3.SS2.SSS3.p2.24.m19.1a"><msub id="S3.SS2.SSS3.p2.24.m19.1.1" xref="S3.SS2.SSS3.p2.24.m19.1.1.cmml"><mi id="S3.SS2.SSS3.p2.24.m19.1.1.2" xref="S3.SS2.SSS3.p2.24.m19.1.1.2.cmml">𝐪</mi><mi id="S3.SS2.SSS3.p2.24.m19.1.1.3" xref="S3.SS2.SSS3.p2.24.m19.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p2.24.m19.1b"><apply id="S3.SS2.SSS3.p2.24.m19.1.1.cmml" xref="S3.SS2.SSS3.p2.24.m19.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p2.24.m19.1.1.1.cmml" xref="S3.SS2.SSS3.p2.24.m19.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.p2.24.m19.1.1.2.cmml" xref="S3.SS2.SSS3.p2.24.m19.1.1.2">𝐪</ci><ci id="S3.SS2.SSS3.p2.24.m19.1.1.3.cmml" xref="S3.SS2.SSS3.p2.24.m19.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p2.24.m19.1c">\mathbf{q}_{s}</annotation></semantics></math> and its corresponding key <math id="S3.SS2.SSS3.p2.25.m20.1" class="ltx_Math" alttext="\mathbf{k}_{s}" display="inline"><semantics id="S3.SS2.SSS3.p2.25.m20.1a"><msub id="S3.SS2.SSS3.p2.25.m20.1.1" xref="S3.SS2.SSS3.p2.25.m20.1.1.cmml"><mi id="S3.SS2.SSS3.p2.25.m20.1.1.2" xref="S3.SS2.SSS3.p2.25.m20.1.1.2.cmml">𝐤</mi><mi id="S3.SS2.SSS3.p2.25.m20.1.1.3" xref="S3.SS2.SSS3.p2.25.m20.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p2.25.m20.1b"><apply id="S3.SS2.SSS3.p2.25.m20.1.1.cmml" xref="S3.SS2.SSS3.p2.25.m20.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p2.25.m20.1.1.1.cmml" xref="S3.SS2.SSS3.p2.25.m20.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.p2.25.m20.1.1.2.cmml" xref="S3.SS2.SSS3.p2.25.m20.1.1.2">𝐤</ci><ci id="S3.SS2.SSS3.p2.25.m20.1.1.3.cmml" xref="S3.SS2.SSS3.p2.25.m20.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p2.25.m20.1c">\mathbf{k}_{s}</annotation></semantics></math>:
<math id="S3.SS2.SSS3.p2.26.m21.2" class="ltx_Math" alttext="\mathbf{z^{\prime}}_{s}=\operatorname{softmax}\left(\frac{1}{\sqrt{d_{k}}}\mathbf{q}_{s}\mathbf{k}_{s}^{T}\right)\mathbf{v}_{s}." display="inline"><semantics id="S3.SS2.SSS3.p2.26.m21.2a"><mrow id="S3.SS2.SSS3.p2.26.m21.2.2.1" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.cmml"><mrow id="S3.SS2.SSS3.p2.26.m21.2.2.1.1" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.cmml"><mmultiscripts id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.3" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.3.cmml"><mi id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.3.2.2" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.3.2.2.cmml">𝐳</mi><mrow id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.3a" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.3.cmml"></mrow><mo id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.3.2.3" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.3.2.3.cmml">′</mo><mi id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.3.3" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.3.3.cmml">s</mi><mrow id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.3b" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.3.cmml"></mrow></mmultiscripts><mo id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.2" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.2.cmml">=</mo><mrow id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.cmml"><mrow id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.2.cmml"><mi id="S3.SS2.SSS3.p2.26.m21.1.1" xref="S3.SS2.SSS3.p2.26.m21.1.1.cmml">softmax</mi><mo id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1a" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.2.cmml">⁡</mo><mrow id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.2.cmml"><mo id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.2" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.2.cmml">(</mo><mrow id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.cmml"><mfrac id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.2" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.2.cmml"><mn id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.2.2" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.2.2.cmml">1</mn><msqrt id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.2.3" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.2.3.cmml"><msub id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.2.3.2" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.2.3.2.cmml"><mi id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.2.3.2.2" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.2.3.2.2.cmml">d</mi><mi id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.2.3.2.3" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.2.3.2.3.cmml">k</mi></msub></msqrt></mfrac><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.1" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.1.cmml">​</mo><msub id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.3" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.3.cmml"><mi id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.3.2" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.3.2.cmml">𝐪</mi><mi id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.3.3" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.3.3.cmml">s</mi></msub><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.1a" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.1.cmml">​</mo><msubsup id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.4" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.4.cmml"><mi id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.4.2.2" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.4.2.2.cmml">𝐤</mi><mi id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.4.2.3" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.4.2.3.cmml">s</mi><mi id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.4.3" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.4.3.cmml">T</mi></msubsup></mrow><mo id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.3" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.2" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.2.cmml">​</mo><msub id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.3" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.3.cmml"><mi id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.3.2" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.3.2.cmml">𝐯</mi><mi id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.3.3" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.3.3.cmml">s</mi></msub></mrow></mrow><mo lspace="0em" id="S3.SS2.SSS3.p2.26.m21.2.2.1.2" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p2.26.m21.2b"><apply id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.cmml" xref="S3.SS2.SSS3.p2.26.m21.2.2.1"><eq id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.2.cmml" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.2"></eq><apply id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.3.cmml" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.3.1.cmml" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.3">subscript</csymbol><apply id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.3.2.cmml" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.3.2.1.cmml" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.3">superscript</csymbol><ci id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.3.2.2.cmml" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.3.2.2">𝐳</ci><ci id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.3.2.3.cmml" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.3.2.3">′</ci></apply><ci id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.3.3.cmml" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.3.3">𝑠</ci></apply><apply id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.cmml" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1"><times id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.2.cmml" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.2"></times><apply id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.2.cmml" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1"><ci id="S3.SS2.SSS3.p2.26.m21.1.1.cmml" xref="S3.SS2.SSS3.p2.26.m21.1.1">softmax</ci><apply id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.cmml" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1"><times id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.1.cmml" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.1"></times><apply id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.2.cmml" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.2"><divide id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.2.1.cmml" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.2"></divide><cn type="integer" id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.2.2.cmml" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.2.2">1</cn><apply id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.2.3.cmml" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.2.3"><root id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.2.3a.cmml" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.2.3"></root><apply id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.2.3.2.cmml" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.2.3.2"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.2.3.2.1.cmml" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.2.3.2">subscript</csymbol><ci id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.2.3.2.2.cmml" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.2.3.2.2">𝑑</ci><ci id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.2.3.2.3.cmml" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.2.3.2.3">𝑘</ci></apply></apply></apply><apply id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.3.cmml" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.3.1.cmml" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.3.2.cmml" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.3.2">𝐪</ci><ci id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.3.3.cmml" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.3.3">𝑠</ci></apply><apply id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.4.cmml" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.4"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.4.1.cmml" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.4">superscript</csymbol><apply id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.4.2.cmml" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.4"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.4.2.1.cmml" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.4">subscript</csymbol><ci id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.4.2.2.cmml" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.4.2.2">𝐤</ci><ci id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.4.2.3.cmml" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.4.2.3">𝑠</ci></apply><ci id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.4.3.cmml" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.1.1.1.1.4.3">𝑇</ci></apply></apply></apply><apply id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.3.cmml" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.3.1.cmml" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.3">subscript</csymbol><ci id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.3.2.cmml" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.3.2">𝐯</ci><ci id="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.3.3.cmml" xref="S3.SS2.SSS3.p2.26.m21.2.2.1.1.1.3.3">𝑠</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p2.26.m21.2c">\mathbf{z^{\prime}}_{s}=\operatorname{softmax}\left(\frac{1}{\sqrt{d_{k}}}\mathbf{q}_{s}\mathbf{k}_{s}^{T}\right)\mathbf{v}_{s}.</annotation></semantics></math></p>
</div>
</section>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3. </span>AutoFed Framework</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">We intend to design an FL framework that extends our multimodal vehicle detection network in § <a href="#S3.SS2" title="3.2. Multimodal Vehicle Detection ‣ 3. System Design ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a> to a training scenario where the data are collected by geographically distributed AVs. As illustrated in Figure <a href="#S3.F6" title="Figure 6 ‣ 3.2.1. Object Detection Basics ‣ 3.2. Multimodal Vehicle Detection ‣ 3. System Design ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>, AutoFed improves the multimodal vehicle detection network in three aspects: i) modifying the loss of RPN to deal with client annotation heterogeneity, ii) employing an autoencoder to perform data imputation of missing sensing modalities, and iii) applying a client selection strategy based on <math id="S3.SS3.p1.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS3.p1.1.m1.1a"><mi id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><ci id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">k</annotation></semantics></math>-d tree <cite class="ltx_cite ltx_citemacro_citep">(Bentley, <a href="#bib.bib3" title="" class="ltx_ref">1975</a>)</cite> to overcome the diverged models brought by the environment and aforementioned heterogeneity.</p>
</div>
<section id="S3.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.1. </span>Modified Loss Function for Tolerating Annotation Anomalies</h4>

<div id="S3.SS3.SSS1.p1" class="ltx_para">
<p id="S3.SS3.SSS1.p1.3" class="ltx_p">As stated in § <a href="#S2.SS1" title="2.1. Quantity Skew of Labeled Data ‣ 2. Motivation ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.1</span></a>, the heterogeneity of labeled data may send wrong gradient signals during AutoFed training, since the bounding boxes that should be classified as foreground otherwise can be wrongly labeled as background when their correct annotations are missing. The motivation for our modified loss is that, despite the lack of correct annotations, the AutoFed model can identify vehicles wrongly labeled as backgrounds according to its own well-established classifier, thus avoiding sending erroneous gradient signals during backpropagation and better guiding the convergence
on the OD loss surface mentioned in § <a href="#S3.SS1" title="3.1. Problem Statement and Overview ‣ 3. System Design ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a>. Specifically, if the feature map of an anchor region is found to be similar to a vehicle, the classifier naturally assigns a high probability <math id="S3.SS3.SSS1.p1.1.m1.1" class="ltx_Math" alttext="p" display="inline"><semantics id="S3.SS3.SSS1.p1.1.m1.1a"><mi id="S3.SS3.SSS1.p1.1.m1.1.1" xref="S3.SS3.SSS1.p1.1.m1.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p1.1.m1.1b"><ci id="S3.SS3.SSS1.p1.1.m1.1.1.cmml" xref="S3.SS3.SSS1.p1.1.m1.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p1.1.m1.1c">p</annotation></semantics></math> of predicting it as a vehicle. This comes under a reasonable assumption that, since the global model is trained sufficiently with on average high-quality annotations, it can be more trustworthy than the annotations from a few incompetent clients. Recall the BCE loss of RPN in § <a href="#S3.SS2.SSS1" title="3.2.1. Object Detection Basics ‣ 3.2. Multimodal Vehicle Detection ‣ 3. System Design ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2.1</span></a> as: <math id="S3.SS3.SSS1.p1.2.m2.5" class="ltx_Math" alttext="L_{\mathrm{cls}}^{\mathrm{RPN}}=-p^{*}\log\left(p\right)-\left(1-p^{*}\right)\log\left(1-p\right)" display="inline"><semantics id="S3.SS3.SSS1.p1.2.m2.5a"><mrow id="S3.SS3.SSS1.p1.2.m2.5.5" xref="S3.SS3.SSS1.p1.2.m2.5.5.cmml"><msubsup id="S3.SS3.SSS1.p1.2.m2.5.5.4" xref="S3.SS3.SSS1.p1.2.m2.5.5.4.cmml"><mi id="S3.SS3.SSS1.p1.2.m2.5.5.4.2.2" xref="S3.SS3.SSS1.p1.2.m2.5.5.4.2.2.cmml">L</mi><mi id="S3.SS3.SSS1.p1.2.m2.5.5.4.2.3" xref="S3.SS3.SSS1.p1.2.m2.5.5.4.2.3.cmml">cls</mi><mi id="S3.SS3.SSS1.p1.2.m2.5.5.4.3" xref="S3.SS3.SSS1.p1.2.m2.5.5.4.3.cmml">RPN</mi></msubsup><mo id="S3.SS3.SSS1.p1.2.m2.5.5.3" xref="S3.SS3.SSS1.p1.2.m2.5.5.3.cmml">=</mo><mrow id="S3.SS3.SSS1.p1.2.m2.5.5.2" xref="S3.SS3.SSS1.p1.2.m2.5.5.2.cmml"><mrow id="S3.SS3.SSS1.p1.2.m2.5.5.2.4" xref="S3.SS3.SSS1.p1.2.m2.5.5.2.4.cmml"><mo id="S3.SS3.SSS1.p1.2.m2.5.5.2.4a" xref="S3.SS3.SSS1.p1.2.m2.5.5.2.4.cmml">−</mo><mrow id="S3.SS3.SSS1.p1.2.m2.5.5.2.4.2" xref="S3.SS3.SSS1.p1.2.m2.5.5.2.4.2.cmml"><msup id="S3.SS3.SSS1.p1.2.m2.5.5.2.4.2.2" xref="S3.SS3.SSS1.p1.2.m2.5.5.2.4.2.2.cmml"><mi id="S3.SS3.SSS1.p1.2.m2.5.5.2.4.2.2.2" xref="S3.SS3.SSS1.p1.2.m2.5.5.2.4.2.2.2.cmml">p</mi><mo id="S3.SS3.SSS1.p1.2.m2.5.5.2.4.2.2.3" xref="S3.SS3.SSS1.p1.2.m2.5.5.2.4.2.2.3.cmml">∗</mo></msup><mo lspace="0.167em" rspace="0em" id="S3.SS3.SSS1.p1.2.m2.5.5.2.4.2.1" xref="S3.SS3.SSS1.p1.2.m2.5.5.2.4.2.1.cmml">​</mo><mrow id="S3.SS3.SSS1.p1.2.m2.5.5.2.4.2.3.2" xref="S3.SS3.SSS1.p1.2.m2.5.5.2.4.2.3.1.cmml"><mi id="S3.SS3.SSS1.p1.2.m2.1.1" xref="S3.SS3.SSS1.p1.2.m2.1.1.cmml">log</mi><mo id="S3.SS3.SSS1.p1.2.m2.5.5.2.4.2.3.2a" xref="S3.SS3.SSS1.p1.2.m2.5.5.2.4.2.3.1.cmml">⁡</mo><mrow id="S3.SS3.SSS1.p1.2.m2.5.5.2.4.2.3.2.1" xref="S3.SS3.SSS1.p1.2.m2.5.5.2.4.2.3.1.cmml"><mo id="S3.SS3.SSS1.p1.2.m2.5.5.2.4.2.3.2.1.1" xref="S3.SS3.SSS1.p1.2.m2.5.5.2.4.2.3.1.cmml">(</mo><mi id="S3.SS3.SSS1.p1.2.m2.2.2" xref="S3.SS3.SSS1.p1.2.m2.2.2.cmml">p</mi><mo id="S3.SS3.SSS1.p1.2.m2.5.5.2.4.2.3.2.1.2" xref="S3.SS3.SSS1.p1.2.m2.5.5.2.4.2.3.1.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S3.SS3.SSS1.p1.2.m2.5.5.2.3" xref="S3.SS3.SSS1.p1.2.m2.5.5.2.3.cmml">−</mo><mrow id="S3.SS3.SSS1.p1.2.m2.5.5.2.2" xref="S3.SS3.SSS1.p1.2.m2.5.5.2.2.cmml"><mrow id="S3.SS3.SSS1.p1.2.m2.4.4.1.1.1.1" xref="S3.SS3.SSS1.p1.2.m2.4.4.1.1.1.1.1.cmml"><mo id="S3.SS3.SSS1.p1.2.m2.4.4.1.1.1.1.2" xref="S3.SS3.SSS1.p1.2.m2.4.4.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS3.SSS1.p1.2.m2.4.4.1.1.1.1.1" xref="S3.SS3.SSS1.p1.2.m2.4.4.1.1.1.1.1.cmml"><mn id="S3.SS3.SSS1.p1.2.m2.4.4.1.1.1.1.1.2" xref="S3.SS3.SSS1.p1.2.m2.4.4.1.1.1.1.1.2.cmml">1</mn><mo id="S3.SS3.SSS1.p1.2.m2.4.4.1.1.1.1.1.1" xref="S3.SS3.SSS1.p1.2.m2.4.4.1.1.1.1.1.1.cmml">−</mo><msup id="S3.SS3.SSS1.p1.2.m2.4.4.1.1.1.1.1.3" xref="S3.SS3.SSS1.p1.2.m2.4.4.1.1.1.1.1.3.cmml"><mi id="S3.SS3.SSS1.p1.2.m2.4.4.1.1.1.1.1.3.2" xref="S3.SS3.SSS1.p1.2.m2.4.4.1.1.1.1.1.3.2.cmml">p</mi><mo id="S3.SS3.SSS1.p1.2.m2.4.4.1.1.1.1.1.3.3" xref="S3.SS3.SSS1.p1.2.m2.4.4.1.1.1.1.1.3.3.cmml">∗</mo></msup></mrow><mo id="S3.SS3.SSS1.p1.2.m2.4.4.1.1.1.1.3" xref="S3.SS3.SSS1.p1.2.m2.4.4.1.1.1.1.1.cmml">)</mo></mrow><mo lspace="0.167em" rspace="0em" id="S3.SS3.SSS1.p1.2.m2.5.5.2.2.3" xref="S3.SS3.SSS1.p1.2.m2.5.5.2.2.3.cmml">​</mo><mrow id="S3.SS3.SSS1.p1.2.m2.5.5.2.2.2.1" xref="S3.SS3.SSS1.p1.2.m2.5.5.2.2.2.2.cmml"><mi id="S3.SS3.SSS1.p1.2.m2.3.3" xref="S3.SS3.SSS1.p1.2.m2.3.3.cmml">log</mi><mo id="S3.SS3.SSS1.p1.2.m2.5.5.2.2.2.1a" xref="S3.SS3.SSS1.p1.2.m2.5.5.2.2.2.2.cmml">⁡</mo><mrow id="S3.SS3.SSS1.p1.2.m2.5.5.2.2.2.1.1" xref="S3.SS3.SSS1.p1.2.m2.5.5.2.2.2.2.cmml"><mo id="S3.SS3.SSS1.p1.2.m2.5.5.2.2.2.1.1.2" xref="S3.SS3.SSS1.p1.2.m2.5.5.2.2.2.2.cmml">(</mo><mrow id="S3.SS3.SSS1.p1.2.m2.5.5.2.2.2.1.1.1" xref="S3.SS3.SSS1.p1.2.m2.5.5.2.2.2.1.1.1.cmml"><mn id="S3.SS3.SSS1.p1.2.m2.5.5.2.2.2.1.1.1.2" xref="S3.SS3.SSS1.p1.2.m2.5.5.2.2.2.1.1.1.2.cmml">1</mn><mo id="S3.SS3.SSS1.p1.2.m2.5.5.2.2.2.1.1.1.1" xref="S3.SS3.SSS1.p1.2.m2.5.5.2.2.2.1.1.1.1.cmml">−</mo><mi id="S3.SS3.SSS1.p1.2.m2.5.5.2.2.2.1.1.1.3" xref="S3.SS3.SSS1.p1.2.m2.5.5.2.2.2.1.1.1.3.cmml">p</mi></mrow><mo id="S3.SS3.SSS1.p1.2.m2.5.5.2.2.2.1.1.3" xref="S3.SS3.SSS1.p1.2.m2.5.5.2.2.2.2.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p1.2.m2.5b"><apply id="S3.SS3.SSS1.p1.2.m2.5.5.cmml" xref="S3.SS3.SSS1.p1.2.m2.5.5"><eq id="S3.SS3.SSS1.p1.2.m2.5.5.3.cmml" xref="S3.SS3.SSS1.p1.2.m2.5.5.3"></eq><apply id="S3.SS3.SSS1.p1.2.m2.5.5.4.cmml" xref="S3.SS3.SSS1.p1.2.m2.5.5.4"><csymbol cd="ambiguous" id="S3.SS3.SSS1.p1.2.m2.5.5.4.1.cmml" xref="S3.SS3.SSS1.p1.2.m2.5.5.4">superscript</csymbol><apply id="S3.SS3.SSS1.p1.2.m2.5.5.4.2.cmml" xref="S3.SS3.SSS1.p1.2.m2.5.5.4"><csymbol cd="ambiguous" id="S3.SS3.SSS1.p1.2.m2.5.5.4.2.1.cmml" xref="S3.SS3.SSS1.p1.2.m2.5.5.4">subscript</csymbol><ci id="S3.SS3.SSS1.p1.2.m2.5.5.4.2.2.cmml" xref="S3.SS3.SSS1.p1.2.m2.5.5.4.2.2">𝐿</ci><ci id="S3.SS3.SSS1.p1.2.m2.5.5.4.2.3.cmml" xref="S3.SS3.SSS1.p1.2.m2.5.5.4.2.3">cls</ci></apply><ci id="S3.SS3.SSS1.p1.2.m2.5.5.4.3.cmml" xref="S3.SS3.SSS1.p1.2.m2.5.5.4.3">RPN</ci></apply><apply id="S3.SS3.SSS1.p1.2.m2.5.5.2.cmml" xref="S3.SS3.SSS1.p1.2.m2.5.5.2"><minus id="S3.SS3.SSS1.p1.2.m2.5.5.2.3.cmml" xref="S3.SS3.SSS1.p1.2.m2.5.5.2.3"></minus><apply id="S3.SS3.SSS1.p1.2.m2.5.5.2.4.cmml" xref="S3.SS3.SSS1.p1.2.m2.5.5.2.4"><minus id="S3.SS3.SSS1.p1.2.m2.5.5.2.4.1.cmml" xref="S3.SS3.SSS1.p1.2.m2.5.5.2.4"></minus><apply id="S3.SS3.SSS1.p1.2.m2.5.5.2.4.2.cmml" xref="S3.SS3.SSS1.p1.2.m2.5.5.2.4.2"><times id="S3.SS3.SSS1.p1.2.m2.5.5.2.4.2.1.cmml" xref="S3.SS3.SSS1.p1.2.m2.5.5.2.4.2.1"></times><apply id="S3.SS3.SSS1.p1.2.m2.5.5.2.4.2.2.cmml" xref="S3.SS3.SSS1.p1.2.m2.5.5.2.4.2.2"><csymbol cd="ambiguous" id="S3.SS3.SSS1.p1.2.m2.5.5.2.4.2.2.1.cmml" xref="S3.SS3.SSS1.p1.2.m2.5.5.2.4.2.2">superscript</csymbol><ci id="S3.SS3.SSS1.p1.2.m2.5.5.2.4.2.2.2.cmml" xref="S3.SS3.SSS1.p1.2.m2.5.5.2.4.2.2.2">𝑝</ci><times id="S3.SS3.SSS1.p1.2.m2.5.5.2.4.2.2.3.cmml" xref="S3.SS3.SSS1.p1.2.m2.5.5.2.4.2.2.3"></times></apply><apply id="S3.SS3.SSS1.p1.2.m2.5.5.2.4.2.3.1.cmml" xref="S3.SS3.SSS1.p1.2.m2.5.5.2.4.2.3.2"><log id="S3.SS3.SSS1.p1.2.m2.1.1.cmml" xref="S3.SS3.SSS1.p1.2.m2.1.1"></log><ci id="S3.SS3.SSS1.p1.2.m2.2.2.cmml" xref="S3.SS3.SSS1.p1.2.m2.2.2">𝑝</ci></apply></apply></apply><apply id="S3.SS3.SSS1.p1.2.m2.5.5.2.2.cmml" xref="S3.SS3.SSS1.p1.2.m2.5.5.2.2"><times id="S3.SS3.SSS1.p1.2.m2.5.5.2.2.3.cmml" xref="S3.SS3.SSS1.p1.2.m2.5.5.2.2.3"></times><apply id="S3.SS3.SSS1.p1.2.m2.4.4.1.1.1.1.1.cmml" xref="S3.SS3.SSS1.p1.2.m2.4.4.1.1.1.1"><minus id="S3.SS3.SSS1.p1.2.m2.4.4.1.1.1.1.1.1.cmml" xref="S3.SS3.SSS1.p1.2.m2.4.4.1.1.1.1.1.1"></minus><cn type="integer" id="S3.SS3.SSS1.p1.2.m2.4.4.1.1.1.1.1.2.cmml" xref="S3.SS3.SSS1.p1.2.m2.4.4.1.1.1.1.1.2">1</cn><apply id="S3.SS3.SSS1.p1.2.m2.4.4.1.1.1.1.1.3.cmml" xref="S3.SS3.SSS1.p1.2.m2.4.4.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.SSS1.p1.2.m2.4.4.1.1.1.1.1.3.1.cmml" xref="S3.SS3.SSS1.p1.2.m2.4.4.1.1.1.1.1.3">superscript</csymbol><ci id="S3.SS3.SSS1.p1.2.m2.4.4.1.1.1.1.1.3.2.cmml" xref="S3.SS3.SSS1.p1.2.m2.4.4.1.1.1.1.1.3.2">𝑝</ci><times id="S3.SS3.SSS1.p1.2.m2.4.4.1.1.1.1.1.3.3.cmml" xref="S3.SS3.SSS1.p1.2.m2.4.4.1.1.1.1.1.3.3"></times></apply></apply><apply id="S3.SS3.SSS1.p1.2.m2.5.5.2.2.2.2.cmml" xref="S3.SS3.SSS1.p1.2.m2.5.5.2.2.2.1"><log id="S3.SS3.SSS1.p1.2.m2.3.3.cmml" xref="S3.SS3.SSS1.p1.2.m2.3.3"></log><apply id="S3.SS3.SSS1.p1.2.m2.5.5.2.2.2.1.1.1.cmml" xref="S3.SS3.SSS1.p1.2.m2.5.5.2.2.2.1.1.1"><minus id="S3.SS3.SSS1.p1.2.m2.5.5.2.2.2.1.1.1.1.cmml" xref="S3.SS3.SSS1.p1.2.m2.5.5.2.2.2.1.1.1.1"></minus><cn type="integer" id="S3.SS3.SSS1.p1.2.m2.5.5.2.2.2.1.1.1.2.cmml" xref="S3.SS3.SSS1.p1.2.m2.5.5.2.2.2.1.1.1.2">1</cn><ci id="S3.SS3.SSS1.p1.2.m2.5.5.2.2.2.1.1.1.3.cmml" xref="S3.SS3.SSS1.p1.2.m2.5.5.2.2.2.1.1.1.3">𝑝</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p1.2.m2.5c">L_{\mathrm{cls}}^{\mathrm{RPN}}=-p^{*}\log\left(p\right)-\left(1-p^{*}\right)\log\left(1-p\right)</annotation></semantics></math>, where <math id="S3.SS3.SSS1.p1.3.m3.1" class="ltx_Math" alttext="p^{*}" display="inline"><semantics id="S3.SS3.SSS1.p1.3.m3.1a"><msup id="S3.SS3.SSS1.p1.3.m3.1.1" xref="S3.SS3.SSS1.p1.3.m3.1.1.cmml"><mi id="S3.SS3.SSS1.p1.3.m3.1.1.2" xref="S3.SS3.SSS1.p1.3.m3.1.1.2.cmml">p</mi><mo id="S3.SS3.SSS1.p1.3.m3.1.1.3" xref="S3.SS3.SSS1.p1.3.m3.1.1.3.cmml">∗</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p1.3.m3.1b"><apply id="S3.SS3.SSS1.p1.3.m3.1.1.cmml" xref="S3.SS3.SSS1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS1.p1.3.m3.1.1.1.cmml" xref="S3.SS3.SSS1.p1.3.m3.1.1">superscript</csymbol><ci id="S3.SS3.SSS1.p1.3.m3.1.1.2.cmml" xref="S3.SS3.SSS1.p1.3.m3.1.1.2">𝑝</ci><times id="S3.SS3.SSS1.p1.3.m3.1.1.3.cmml" xref="S3.SS3.SSS1.p1.3.m3.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p1.3.m3.1c">p^{*}</annotation></semantics></math> is the training label taking on values of 0 or 1, respectively indicating the bounded region being background or vehicle.
Consequently, the modified cross-entropy (MCE) loss becomes:</p>
<table id="Sx1.EGx3" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S3.E3"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(3)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E3.m1.1" class="ltx_math_unparsed" alttext="\displaystyle\left\{\begin{matrix}0,&amp;p&gt;p_{\mathrm{th}}~{}\text{and}~{}p^{*}=0,\\
-p^{*}\log p-(1-p^{*})\log(1-p),&amp;\text{otherwise},\end{matrix}\right." display="inline"><semantics id="S3.E3.m1.1a"><mrow id="S3.E3.m1.1b"><mo id="S3.E3.m1.1.2">{</mo><mtable columnspacing="5pt" rowspacing="0pt" id="S3.E3.m1.1.1.1.1"><mtr id="S3.E3.m1.1.1.1.1a"><mtd id="S3.E3.m1.1.1.1.1b"><mrow id="S3.E3.m1.1.1.1.1.1.1.1.1.3"><mn id="S3.E3.m1.1.1.1.1.1.1.1.1.1">0</mn><mo id="S3.E3.m1.1.1.1.1.1.1.1.1.3.1">,</mo></mrow></mtd><mtd id="S3.E3.m1.1.1.1.1c"><mrow id="S3.E3.m1.1.1.1.1.2.2.2.1.1"><mrow id="S3.E3.m1.1.1.1.1.2.2.2.1.1.1"><mi id="S3.E3.m1.1.1.1.1.2.2.2.1.1.1.2">p</mi><mo id="S3.E3.m1.1.1.1.1.2.2.2.1.1.1.3">&gt;</mo><mrow id="S3.E3.m1.1.1.1.1.2.2.2.1.1.1.4"><msub id="S3.E3.m1.1.1.1.1.2.2.2.1.1.1.4.2"><mi id="S3.E3.m1.1.1.1.1.2.2.2.1.1.1.4.2.2">p</mi><mi id="S3.E3.m1.1.1.1.1.2.2.2.1.1.1.4.2.3">th</mi></msub><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.1.2.2.2.1.1.1.4.1">​</mo><mtext id="S3.E3.m1.1.1.1.1.2.2.2.1.1.1.4.3">and</mtext><mo lspace="0.330em" rspace="0em" id="S3.E3.m1.1.1.1.1.2.2.2.1.1.1.4.1a">​</mo><msup id="S3.E3.m1.1.1.1.1.2.2.2.1.1.1.4.4"><mi id="S3.E3.m1.1.1.1.1.2.2.2.1.1.1.4.4.2">p</mi><mo id="S3.E3.m1.1.1.1.1.2.2.2.1.1.1.4.4.3">∗</mo></msup></mrow><mo id="S3.E3.m1.1.1.1.1.2.2.2.1.1.1.5">=</mo><mn id="S3.E3.m1.1.1.1.1.2.2.2.1.1.1.6">0</mn></mrow><mo id="S3.E3.m1.1.1.1.1.2.2.2.1.1.2">,</mo></mrow></mtd></mtr><mtr id="S3.E3.m1.1.1.1.1d"><mtd id="S3.E3.m1.1.1.1.1e"><mrow id="S3.E3.m1.1.1.1.1.4.4.2.2.2"><mrow id="S3.E3.m1.1.1.1.1.4.4.2.2.2.1"><mrow id="S3.E3.m1.1.1.1.1.4.4.2.2.2.1.4"><mo id="S3.E3.m1.1.1.1.1.4.4.2.2.2.1.4a">−</mo><mrow id="S3.E3.m1.1.1.1.1.4.4.2.2.2.1.4.2"><msup id="S3.E3.m1.1.1.1.1.4.4.2.2.2.1.4.2.2"><mi id="S3.E3.m1.1.1.1.1.4.4.2.2.2.1.4.2.2.2">p</mi><mo id="S3.E3.m1.1.1.1.1.4.4.2.2.2.1.4.2.2.3">∗</mo></msup><mo lspace="0.167em" rspace="0em" id="S3.E3.m1.1.1.1.1.4.4.2.2.2.1.4.2.1">​</mo><mrow id="S3.E3.m1.1.1.1.1.4.4.2.2.2.1.4.2.3"><mi id="S3.E3.m1.1.1.1.1.4.4.2.2.2.1.4.2.3.1">log</mi><mo lspace="0.167em" id="S3.E3.m1.1.1.1.1.4.4.2.2.2.1.4.2.3a">⁡</mo><mi id="S3.E3.m1.1.1.1.1.4.4.2.2.2.1.4.2.3.2">p</mi></mrow></mrow></mrow><mo id="S3.E3.m1.1.1.1.1.4.4.2.2.2.1.3">−</mo><mrow id="S3.E3.m1.1.1.1.1.4.4.2.2.2.1.2"><mrow id="S3.E3.m1.1.1.1.1.4.4.2.2.2.1.1.1.1"><mo stretchy="false" id="S3.E3.m1.1.1.1.1.4.4.2.2.2.1.1.1.1.2">(</mo><mrow id="S3.E3.m1.1.1.1.1.4.4.2.2.2.1.1.1.1.1"><mn id="S3.E3.m1.1.1.1.1.4.4.2.2.2.1.1.1.1.1.2">1</mn><mo id="S3.E3.m1.1.1.1.1.4.4.2.2.2.1.1.1.1.1.1">−</mo><msup id="S3.E3.m1.1.1.1.1.4.4.2.2.2.1.1.1.1.1.3"><mi id="S3.E3.m1.1.1.1.1.4.4.2.2.2.1.1.1.1.1.3.2">p</mi><mo id="S3.E3.m1.1.1.1.1.4.4.2.2.2.1.1.1.1.1.3.3">∗</mo></msup></mrow><mo stretchy="false" id="S3.E3.m1.1.1.1.1.4.4.2.2.2.1.1.1.1.3">)</mo></mrow><mo lspace="0.167em" rspace="0em" id="S3.E3.m1.1.1.1.1.4.4.2.2.2.1.2.3">​</mo><mrow id="S3.E3.m1.1.1.1.1.4.4.2.2.2.1.2.2.1"><mi id="S3.E3.m1.1.1.1.1.3.3.1.1.1">log</mi><mo id="S3.E3.m1.1.1.1.1.4.4.2.2.2.1.2.2.1a">⁡</mo><mrow id="S3.E3.m1.1.1.1.1.4.4.2.2.2.1.2.2.1.1"><mo stretchy="false" id="S3.E3.m1.1.1.1.1.4.4.2.2.2.1.2.2.1.1.2">(</mo><mrow id="S3.E3.m1.1.1.1.1.4.4.2.2.2.1.2.2.1.1.1"><mn id="S3.E3.m1.1.1.1.1.4.4.2.2.2.1.2.2.1.1.1.2">1</mn><mo id="S3.E3.m1.1.1.1.1.4.4.2.2.2.1.2.2.1.1.1.1">−</mo><mi id="S3.E3.m1.1.1.1.1.4.4.2.2.2.1.2.2.1.1.1.3">p</mi></mrow><mo stretchy="false" id="S3.E3.m1.1.1.1.1.4.4.2.2.2.1.2.2.1.1.3">)</mo></mrow></mrow></mrow></mrow><mo id="S3.E3.m1.1.1.1.1.4.4.2.2.2.2">,</mo></mrow></mtd><mtd id="S3.E3.m1.1.1.1.1f"><mrow id="S3.E3.m1.1.1.1.1.5.5.3.1.3"><mtext id="S3.E3.m1.1.1.1.1.5.5.3.1.1">otherwise</mtext><mo id="S3.E3.m1.1.1.1.1.5.5.3.1.3.1">,</mo></mrow></mtd></mtr></mtable></mrow><annotation encoding="application/x-tex" id="S3.E3.m1.1c">\displaystyle\left\{\begin{matrix}0,&amp;p&gt;p_{\mathrm{th}}~{}\text{and}~{}p^{*}=0,\\
-p^{*}\log p-(1-p^{*})\log(1-p),&amp;\text{otherwise},\end{matrix}\right.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S3.SS3.SSS1.p1.5" class="ltx_p">where <math id="S3.SS3.SSS1.p1.4.m1.1" class="ltx_Math" alttext="p_{\mathrm{th}}" display="inline"><semantics id="S3.SS3.SSS1.p1.4.m1.1a"><msub id="S3.SS3.SSS1.p1.4.m1.1.1" xref="S3.SS3.SSS1.p1.4.m1.1.1.cmml"><mi id="S3.SS3.SSS1.p1.4.m1.1.1.2" xref="S3.SS3.SSS1.p1.4.m1.1.1.2.cmml">p</mi><mi id="S3.SS3.SSS1.p1.4.m1.1.1.3" xref="S3.SS3.SSS1.p1.4.m1.1.1.3.cmml">th</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p1.4.m1.1b"><apply id="S3.SS3.SSS1.p1.4.m1.1.1.cmml" xref="S3.SS3.SSS1.p1.4.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS1.p1.4.m1.1.1.1.cmml" xref="S3.SS3.SSS1.p1.4.m1.1.1">subscript</csymbol><ci id="S3.SS3.SSS1.p1.4.m1.1.1.2.cmml" xref="S3.SS3.SSS1.p1.4.m1.1.1.2">𝑝</ci><ci id="S3.SS3.SSS1.p1.4.m1.1.1.3.cmml" xref="S3.SS3.SSS1.p1.4.m1.1.1.3">th</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p1.4.m1.1c">p_{\mathrm{th}}</annotation></semantics></math> is a threshold value after which we believe that the classifier is more trustworthy than the annotations. The value of <math id="S3.SS3.SSS1.p1.5.m2.1" class="ltx_Math" alttext="p_{\mathrm{th}}" display="inline"><semantics id="S3.SS3.SSS1.p1.5.m2.1a"><msub id="S3.SS3.SSS1.p1.5.m2.1.1" xref="S3.SS3.SSS1.p1.5.m2.1.1.cmml"><mi id="S3.SS3.SSS1.p1.5.m2.1.1.2" xref="S3.SS3.SSS1.p1.5.m2.1.1.2.cmml">p</mi><mi id="S3.SS3.SSS1.p1.5.m2.1.1.3" xref="S3.SS3.SSS1.p1.5.m2.1.1.3.cmml">th</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p1.5.m2.1b"><apply id="S3.SS3.SSS1.p1.5.m2.1.1.cmml" xref="S3.SS3.SSS1.p1.5.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS1.p1.5.m2.1.1.1.cmml" xref="S3.SS3.SSS1.p1.5.m2.1.1">subscript</csymbol><ci id="S3.SS3.SSS1.p1.5.m2.1.1.2.cmml" xref="S3.SS3.SSS1.p1.5.m2.1.1.2">𝑝</ci><ci id="S3.SS3.SSS1.p1.5.m2.1.1.3.cmml" xref="S3.SS3.SSS1.p1.5.m2.1.1.3">th</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p1.5.m2.1c">p_{\mathrm{th}}</annotation></semantics></math> is determined by hyperparameter search in § <a href="#S4.SS7.SSS1" title="4.7.1. Loss Threshold ‣ 4.7. Hyper-parameter Evaluation ‣ 4. Performance Evaluation ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.7.1</span></a>.</p>
</div>
<figure id="S3.F7" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F7.sf1" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S3.F7.sf1.1" class="ltx_block ltx_minipage ltx_align_bottom" style="width:203.8pt;">
<img src="/html/2302.08646/assets/x10.png" id="S3.F7.sf1.1.g1" class="ltx_graphics ltx_img_landscape" width="442" height="266" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>Average precision.</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F7.sf2" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S3.F7.sf2.1" class="ltx_block ltx_minipage ltx_align_bottom" style="width:203.8pt;">
<img src="/html/2302.08646/assets/x11.png" id="S3.F7.sf2.1.g1" class="ltx_graphics ltx_img_landscape" width="442" height="258" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Average recall.</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7. </span>Comparison between CE and MCE loss.</figcaption>
</figure>
<div id="S3.SS3.SSS1.p2" class="ltx_para">
<p id="S3.SS3.SSS1.p2.1" class="ltx_p">To demonstrate the efficacy of the MCE loss, we train a multimodal vehicle detection network using the settings in § <a href="#S2.SS1" title="2.1. Quantity Skew of Labeled Data ‣ 2. Motivation ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.1</span></a>. The training results of regular CE loss and our MCE are shown in Figure <a href="#S3.F7" title="Figure 7 ‣ 3.3.1. Modified Loss Function for Tolerating Annotation Anomalies ‣ 3.3. AutoFed Framework ‣ 3. System Design ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>; they evidently confirm the superiority of MCE loss,
though the average precision and average recall of both CE and BCE losses fluctuate around their means after sufficient training (approximately 15 epochs). First of all, The average precision of vehicle detection is respectively 0.57 and 0.4 when CE and MCE loss are used. Similarly, there is a gap greater than 0.1 in the average recalls when the two losses are used. Moreover, it is clear that, though training with CE loss achieves higher precision and recall in the few initial epochs, it is quickly overtaken by the MCE loss, which keeps an upward trend and converges faster. Last but not least, one may also observe that there is a slight downward trend of performance when the CE loss is used after the 15-th epochs. The performance gaps and different performance trends clearly demonstrate that our MCE loss can make full use of vehicle annotations while avoiding backpropagating erroneous gradients caused by missing annotations.</p>
</div>
</section>
<section id="S3.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.2. </span>Modality Imputation with Autoencoder for Tolerating Modality Anomalies</h4>

<div id="S3.SS3.SSS2.p1" class="ltx_para">
<p id="S3.SS3.SSS2.p1.2" class="ltx_p">We have shown in § <a href="#S2.SS2" title="2.2. Heterogeneous Modality across AVs ‣ 2. Motivation ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.2</span></a> that conventional data imputation methods (e.g., filling the missing modalities with 0’s) incurs information loss, and may even introduce biases into the network. To leverage the valuable information in the heterogeneous sensing modalities, we propose to fill in the missing data by leveraging the relations among different modalities. Since different modalities are aligned and loosely coupled (as explained § <a href="#S3.SS2.SSS2" title="3.2.2. Modality Alignment ‣ 3.2. Multimodal Vehicle Detection ‣ 3. System Design ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2.2</span></a> and § <a href="#S3.SS2.SSS3" title="3.2.3. Feature-Level Sensor Fusion ‣ 3.2. Multimodal Vehicle Detection ‣ 3. System Design ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2.3</span></a>), we employ a convolutional autoencoder with residual connections (which connects a layer to further layers by skipping some layers in between, thus facilitating information flow) to directly perform modality imputation. The encoder of the autoencoder consists of 4 convolutional layers, and correspondingly, the decoder of the autoencoder consists of 4 transposed convolutional layers. Consequently, the lightweight architecture of our autoencoder only incurs negligible overhead representing an increase of only 4.38% (3.129 ​GFLOPS vs. 2.988 ​GFLOPS) from the AutoFed variant without autoencoder. It should be noted that the autoencoder is pre-trained and does not participate in the training process of AutoFed. During the pretraining stage, the autoencoder aims to learn a latent representation, and reconstruct the missing modality. For example, when the radar modality <math id="S3.SS3.SSS2.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{R}" display="inline"><semantics id="S3.SS3.SSS2.p1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.SSS2.p1.1.m1.1.1" xref="S3.SS3.SSS2.p1.1.m1.1.1.cmml">ℛ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p1.1.m1.1b"><ci id="S3.SS3.SSS2.p1.1.m1.1.1.cmml" xref="S3.SS3.SSS2.p1.1.m1.1.1">ℛ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p1.1.m1.1c">\mathcal{R}</annotation></semantics></math> is missing, the autoencoder encodes the lidar modality <math id="S3.SS3.SSS2.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{L}" display="inline"><semantics id="S3.SS3.SSS2.p1.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.SSS2.p1.2.m2.1.1" xref="S3.SS3.SSS2.p1.2.m2.1.1.cmml">ℒ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p1.2.m2.1b"><ci id="S3.SS3.SSS2.p1.2.m2.1.1.cmml" xref="S3.SS3.SSS2.p1.2.m2.1.1">ℒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p1.2.m2.1c">\mathcal{L}</annotation></semantics></math> and translates the latent information therein to fill in the missing radar modality.</p>
</div>
<figure id="S3.F8" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F8.sf1" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S3.F8.sf1.1" class="ltx_block ltx_minipage ltx_align_bottom" style="width:203.8pt;">
<img src="/html/2302.08646/assets/x12.png" id="S3.F8.sf1.1.g1" class="ltx_graphics ltx_img_landscape" width="442" height="266" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>Average precision.</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F8.sf2" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S3.F8.sf2.1" class="ltx_block ltx_minipage ltx_align_bottom" style="width:203.8pt;">
<img src="/html/2302.08646/assets/x13.png" id="S3.F8.sf2.1.g1" class="ltx_graphics ltx_img_landscape" width="442" height="255" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Average recall.</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8. </span>Modality imputation with an autoencoder.</figcaption>
</figure>
<div id="S3.SS3.SSS2.p2" class="ltx_para">
<p id="S3.SS3.SSS2.p2.1" class="ltx_p">To show the efficacy of the above method, we train the multimodal vehicle detection network following the settings in § <a href="#S2.SS2" title="2.2. Heterogeneous Modality across AVs ‣ 2. Motivation ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.2</span></a>, and compare the average precision and recall of autoencoder imputation with zero-filling in Figure <a href="#S3.F8.sf1" title="In Figure 8 ‣ 3.3.2. Modality Imputation with Autoencoder for Tolerating Modality Anomalies ‣ 3.3. AutoFed Framework ‣ 3. System Design ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8a</span></a> and <a href="#S3.F8.sf2" title="In Figure 8 ‣ 3.3.2. Modality Imputation with Autoencoder for Tolerating Modality Anomalies ‣ 3.3. AutoFed Framework ‣ 3. System Design ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8b</span></a>, respectively. One may readily observe that zero-filling only achieves an average precision of approximately 0.4, lower than an average precision of about 0.5 achieved by our autoencoder imputation. Similarly, autoencoder imputation also surpasses zero-filling in terms of average recall by a discernible margin. Figure <a href="#S3.F8" title="Figure 8 ‣ 3.3.2. Modality Imputation with Autoencoder for Tolerating Modality Anomalies ‣ 3.3. AutoFed Framework ‣ 3. System Design ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> also indicates
that autoencoder imputation only takes about 5 epochs to converge, much faster than the convergence speeds (i.e., 10 and 15 epochs) by zero-filling. The higher average precision and recall, as well as the faster convergence training speed have clearly demonstrated that our designed autoencoder makes full use of the heterogeneous data by taking into account the correlations among different modalities.</p>
</div>
</section>
<section id="S3.SS3.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.3. </span>Client Selection for Tolerating Model Weight Anomalies</h4>

<div id="S3.SS3.SSS3.p1" class="ltx_para">
<p id="S3.SS3.SSS3.p1.1" class="ltx_p">Environment heterogeneities, including different weather and road conditions (as indicated in § <a href="#S2.SS3" title="2.3. Model Divergence ‣ 2. Motivation ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.3</span></a>), as well as other human-induced heterogeneities (e.g., inaccurate annotations), are not easily solvable using the techniques described in Sections <a href="#S3.SS3.SSS1" title="3.3.1. Modified Loss Function for Tolerating Annotation Anomalies ‣ 3.3. AutoFed Framework ‣ 3. System Design ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3.1</span></a> and <a href="#S3.SS3.SSS2" title="3.3.2. Modality Imputation with Autoencoder for Tolerating Modality Anomalies ‣ 3.3. AutoFed Framework ‣ 3. System Design ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3.2</span></a>, yet they can cause serious model divergence among the clients.
Training with diverging clients holding extremely biased datasets may contradict models from other clients, thus increasing the overall losses. To make things worse, the chaotic loss surface mentioned in § <a href="#S1" title="1. Introduction ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> and § <a href="#S3.SS1" title="3.1. Problem Statement and Overview ‣ 3. System Design ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a> can disorient the gradient descent algorithm used for training the OD model, and further diverge the model weights. These observations urge us to devise a novel client selection strategy immune to divergence, rather than blindly using FedAvg to aggregate model weights from all clients equally. By selectively removing outlier clients, the client selection strategy should help the loss navigating on the surface more efficiently.</p>
</div>
<div id="S3.SS3.SSS3.p2" class="ltx_para">
<p id="S3.SS3.SSS3.p2.20" class="ltx_p">Suppose there are <math id="S3.SS3.SSS3.p2.1.m1.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S3.SS3.SSS3.p2.1.m1.1a"><mi id="S3.SS3.SSS3.p2.1.m1.1.1" xref="S3.SS3.SSS3.p2.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS3.p2.1.m1.1b"><ci id="S3.SS3.SSS3.p2.1.m1.1.1.cmml" xref="S3.SS3.SSS3.p2.1.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS3.p2.1.m1.1c">N</annotation></semantics></math> clients <math id="S3.SS3.SSS3.p2.2.m2.5" class="ltx_Math" alttext="\{C_{1},\cdots,C_{n},\cdots,C_{N}\}" display="inline"><semantics id="S3.SS3.SSS3.p2.2.m2.5a"><mrow id="S3.SS3.SSS3.p2.2.m2.5.5.3" xref="S3.SS3.SSS3.p2.2.m2.5.5.4.cmml"><mo stretchy="false" id="S3.SS3.SSS3.p2.2.m2.5.5.3.4" xref="S3.SS3.SSS3.p2.2.m2.5.5.4.cmml">{</mo><msub id="S3.SS3.SSS3.p2.2.m2.3.3.1.1" xref="S3.SS3.SSS3.p2.2.m2.3.3.1.1.cmml"><mi id="S3.SS3.SSS3.p2.2.m2.3.3.1.1.2" xref="S3.SS3.SSS3.p2.2.m2.3.3.1.1.2.cmml">C</mi><mn id="S3.SS3.SSS3.p2.2.m2.3.3.1.1.3" xref="S3.SS3.SSS3.p2.2.m2.3.3.1.1.3.cmml">1</mn></msub><mo id="S3.SS3.SSS3.p2.2.m2.5.5.3.5" xref="S3.SS3.SSS3.p2.2.m2.5.5.4.cmml">,</mo><mi mathvariant="normal" id="S3.SS3.SSS3.p2.2.m2.1.1" xref="S3.SS3.SSS3.p2.2.m2.1.1.cmml">⋯</mi><mo id="S3.SS3.SSS3.p2.2.m2.5.5.3.6" xref="S3.SS3.SSS3.p2.2.m2.5.5.4.cmml">,</mo><msub id="S3.SS3.SSS3.p2.2.m2.4.4.2.2" xref="S3.SS3.SSS3.p2.2.m2.4.4.2.2.cmml"><mi id="S3.SS3.SSS3.p2.2.m2.4.4.2.2.2" xref="S3.SS3.SSS3.p2.2.m2.4.4.2.2.2.cmml">C</mi><mi id="S3.SS3.SSS3.p2.2.m2.4.4.2.2.3" xref="S3.SS3.SSS3.p2.2.m2.4.4.2.2.3.cmml">n</mi></msub><mo id="S3.SS3.SSS3.p2.2.m2.5.5.3.7" xref="S3.SS3.SSS3.p2.2.m2.5.5.4.cmml">,</mo><mi mathvariant="normal" id="S3.SS3.SSS3.p2.2.m2.2.2" xref="S3.SS3.SSS3.p2.2.m2.2.2.cmml">⋯</mi><mo id="S3.SS3.SSS3.p2.2.m2.5.5.3.8" xref="S3.SS3.SSS3.p2.2.m2.5.5.4.cmml">,</mo><msub id="S3.SS3.SSS3.p2.2.m2.5.5.3.3" xref="S3.SS3.SSS3.p2.2.m2.5.5.3.3.cmml"><mi id="S3.SS3.SSS3.p2.2.m2.5.5.3.3.2" xref="S3.SS3.SSS3.p2.2.m2.5.5.3.3.2.cmml">C</mi><mi id="S3.SS3.SSS3.p2.2.m2.5.5.3.3.3" xref="S3.SS3.SSS3.p2.2.m2.5.5.3.3.3.cmml">N</mi></msub><mo stretchy="false" id="S3.SS3.SSS3.p2.2.m2.5.5.3.9" xref="S3.SS3.SSS3.p2.2.m2.5.5.4.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS3.p2.2.m2.5b"><set id="S3.SS3.SSS3.p2.2.m2.5.5.4.cmml" xref="S3.SS3.SSS3.p2.2.m2.5.5.3"><apply id="S3.SS3.SSS3.p2.2.m2.3.3.1.1.cmml" xref="S3.SS3.SSS3.p2.2.m2.3.3.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS3.p2.2.m2.3.3.1.1.1.cmml" xref="S3.SS3.SSS3.p2.2.m2.3.3.1.1">subscript</csymbol><ci id="S3.SS3.SSS3.p2.2.m2.3.3.1.1.2.cmml" xref="S3.SS3.SSS3.p2.2.m2.3.3.1.1.2">𝐶</ci><cn type="integer" id="S3.SS3.SSS3.p2.2.m2.3.3.1.1.3.cmml" xref="S3.SS3.SSS3.p2.2.m2.3.3.1.1.3">1</cn></apply><ci id="S3.SS3.SSS3.p2.2.m2.1.1.cmml" xref="S3.SS3.SSS3.p2.2.m2.1.1">⋯</ci><apply id="S3.SS3.SSS3.p2.2.m2.4.4.2.2.cmml" xref="S3.SS3.SSS3.p2.2.m2.4.4.2.2"><csymbol cd="ambiguous" id="S3.SS3.SSS3.p2.2.m2.4.4.2.2.1.cmml" xref="S3.SS3.SSS3.p2.2.m2.4.4.2.2">subscript</csymbol><ci id="S3.SS3.SSS3.p2.2.m2.4.4.2.2.2.cmml" xref="S3.SS3.SSS3.p2.2.m2.4.4.2.2.2">𝐶</ci><ci id="S3.SS3.SSS3.p2.2.m2.4.4.2.2.3.cmml" xref="S3.SS3.SSS3.p2.2.m2.4.4.2.2.3">𝑛</ci></apply><ci id="S3.SS3.SSS3.p2.2.m2.2.2.cmml" xref="S3.SS3.SSS3.p2.2.m2.2.2">⋯</ci><apply id="S3.SS3.SSS3.p2.2.m2.5.5.3.3.cmml" xref="S3.SS3.SSS3.p2.2.m2.5.5.3.3"><csymbol cd="ambiguous" id="S3.SS3.SSS3.p2.2.m2.5.5.3.3.1.cmml" xref="S3.SS3.SSS3.p2.2.m2.5.5.3.3">subscript</csymbol><ci id="S3.SS3.SSS3.p2.2.m2.5.5.3.3.2.cmml" xref="S3.SS3.SSS3.p2.2.m2.5.5.3.3.2">𝐶</ci><ci id="S3.SS3.SSS3.p2.2.m2.5.5.3.3.3.cmml" xref="S3.SS3.SSS3.p2.2.m2.5.5.3.3.3">𝑁</ci></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS3.p2.2.m2.5c">\{C_{1},\cdots,C_{n},\cdots,C_{N}\}</annotation></semantics></math> in total, which forms a set <math id="S3.SS3.SSS3.p2.3.m3.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S3.SS3.SSS3.p2.3.m3.1a"><mi id="S3.SS3.SSS3.p2.3.m3.1.1" xref="S3.SS3.SSS3.p2.3.m3.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS3.p2.3.m3.1b"><ci id="S3.SS3.SSS3.p2.3.m3.1.1.cmml" xref="S3.SS3.SSS3.p2.3.m3.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS3.p2.3.m3.1c">S</annotation></semantics></math>. To mitigate the issue of diverged models, we would like to dynamically select a subset <math id="S3.SS3.SSS3.p2.4.m4.5" class="ltx_Math" alttext="S^{\prime}=\{C_{1},\cdots,C_{m},\cdots,C_{M}\}" display="inline"><semantics id="S3.SS3.SSS3.p2.4.m4.5a"><mrow id="S3.SS3.SSS3.p2.4.m4.5.5" xref="S3.SS3.SSS3.p2.4.m4.5.5.cmml"><msup id="S3.SS3.SSS3.p2.4.m4.5.5.5" xref="S3.SS3.SSS3.p2.4.m4.5.5.5.cmml"><mi id="S3.SS3.SSS3.p2.4.m4.5.5.5.2" xref="S3.SS3.SSS3.p2.4.m4.5.5.5.2.cmml">S</mi><mo id="S3.SS3.SSS3.p2.4.m4.5.5.5.3" xref="S3.SS3.SSS3.p2.4.m4.5.5.5.3.cmml">′</mo></msup><mo id="S3.SS3.SSS3.p2.4.m4.5.5.4" xref="S3.SS3.SSS3.p2.4.m4.5.5.4.cmml">=</mo><mrow id="S3.SS3.SSS3.p2.4.m4.5.5.3.3" xref="S3.SS3.SSS3.p2.4.m4.5.5.3.4.cmml"><mo stretchy="false" id="S3.SS3.SSS3.p2.4.m4.5.5.3.3.4" xref="S3.SS3.SSS3.p2.4.m4.5.5.3.4.cmml">{</mo><msub id="S3.SS3.SSS3.p2.4.m4.3.3.1.1.1" xref="S3.SS3.SSS3.p2.4.m4.3.3.1.1.1.cmml"><mi id="S3.SS3.SSS3.p2.4.m4.3.3.1.1.1.2" xref="S3.SS3.SSS3.p2.4.m4.3.3.1.1.1.2.cmml">C</mi><mn id="S3.SS3.SSS3.p2.4.m4.3.3.1.1.1.3" xref="S3.SS3.SSS3.p2.4.m4.3.3.1.1.1.3.cmml">1</mn></msub><mo id="S3.SS3.SSS3.p2.4.m4.5.5.3.3.5" xref="S3.SS3.SSS3.p2.4.m4.5.5.3.4.cmml">,</mo><mi mathvariant="normal" id="S3.SS3.SSS3.p2.4.m4.1.1" xref="S3.SS3.SSS3.p2.4.m4.1.1.cmml">⋯</mi><mo id="S3.SS3.SSS3.p2.4.m4.5.5.3.3.6" xref="S3.SS3.SSS3.p2.4.m4.5.5.3.4.cmml">,</mo><msub id="S3.SS3.SSS3.p2.4.m4.4.4.2.2.2" xref="S3.SS3.SSS3.p2.4.m4.4.4.2.2.2.cmml"><mi id="S3.SS3.SSS3.p2.4.m4.4.4.2.2.2.2" xref="S3.SS3.SSS3.p2.4.m4.4.4.2.2.2.2.cmml">C</mi><mi id="S3.SS3.SSS3.p2.4.m4.4.4.2.2.2.3" xref="S3.SS3.SSS3.p2.4.m4.4.4.2.2.2.3.cmml">m</mi></msub><mo id="S3.SS3.SSS3.p2.4.m4.5.5.3.3.7" xref="S3.SS3.SSS3.p2.4.m4.5.5.3.4.cmml">,</mo><mi mathvariant="normal" id="S3.SS3.SSS3.p2.4.m4.2.2" xref="S3.SS3.SSS3.p2.4.m4.2.2.cmml">⋯</mi><mo id="S3.SS3.SSS3.p2.4.m4.5.5.3.3.8" xref="S3.SS3.SSS3.p2.4.m4.5.5.3.4.cmml">,</mo><msub id="S3.SS3.SSS3.p2.4.m4.5.5.3.3.3" xref="S3.SS3.SSS3.p2.4.m4.5.5.3.3.3.cmml"><mi id="S3.SS3.SSS3.p2.4.m4.5.5.3.3.3.2" xref="S3.SS3.SSS3.p2.4.m4.5.5.3.3.3.2.cmml">C</mi><mi id="S3.SS3.SSS3.p2.4.m4.5.5.3.3.3.3" xref="S3.SS3.SSS3.p2.4.m4.5.5.3.3.3.3.cmml">M</mi></msub><mo stretchy="false" id="S3.SS3.SSS3.p2.4.m4.5.5.3.3.9" xref="S3.SS3.SSS3.p2.4.m4.5.5.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS3.p2.4.m4.5b"><apply id="S3.SS3.SSS3.p2.4.m4.5.5.cmml" xref="S3.SS3.SSS3.p2.4.m4.5.5"><eq id="S3.SS3.SSS3.p2.4.m4.5.5.4.cmml" xref="S3.SS3.SSS3.p2.4.m4.5.5.4"></eq><apply id="S3.SS3.SSS3.p2.4.m4.5.5.5.cmml" xref="S3.SS3.SSS3.p2.4.m4.5.5.5"><csymbol cd="ambiguous" id="S3.SS3.SSS3.p2.4.m4.5.5.5.1.cmml" xref="S3.SS3.SSS3.p2.4.m4.5.5.5">superscript</csymbol><ci id="S3.SS3.SSS3.p2.4.m4.5.5.5.2.cmml" xref="S3.SS3.SSS3.p2.4.m4.5.5.5.2">𝑆</ci><ci id="S3.SS3.SSS3.p2.4.m4.5.5.5.3.cmml" xref="S3.SS3.SSS3.p2.4.m4.5.5.5.3">′</ci></apply><set id="S3.SS3.SSS3.p2.4.m4.5.5.3.4.cmml" xref="S3.SS3.SSS3.p2.4.m4.5.5.3.3"><apply id="S3.SS3.SSS3.p2.4.m4.3.3.1.1.1.cmml" xref="S3.SS3.SSS3.p2.4.m4.3.3.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS3.p2.4.m4.3.3.1.1.1.1.cmml" xref="S3.SS3.SSS3.p2.4.m4.3.3.1.1.1">subscript</csymbol><ci id="S3.SS3.SSS3.p2.4.m4.3.3.1.1.1.2.cmml" xref="S3.SS3.SSS3.p2.4.m4.3.3.1.1.1.2">𝐶</ci><cn type="integer" id="S3.SS3.SSS3.p2.4.m4.3.3.1.1.1.3.cmml" xref="S3.SS3.SSS3.p2.4.m4.3.3.1.1.1.3">1</cn></apply><ci id="S3.SS3.SSS3.p2.4.m4.1.1.cmml" xref="S3.SS3.SSS3.p2.4.m4.1.1">⋯</ci><apply id="S3.SS3.SSS3.p2.4.m4.4.4.2.2.2.cmml" xref="S3.SS3.SSS3.p2.4.m4.4.4.2.2.2"><csymbol cd="ambiguous" id="S3.SS3.SSS3.p2.4.m4.4.4.2.2.2.1.cmml" xref="S3.SS3.SSS3.p2.4.m4.4.4.2.2.2">subscript</csymbol><ci id="S3.SS3.SSS3.p2.4.m4.4.4.2.2.2.2.cmml" xref="S3.SS3.SSS3.p2.4.m4.4.4.2.2.2.2">𝐶</ci><ci id="S3.SS3.SSS3.p2.4.m4.4.4.2.2.2.3.cmml" xref="S3.SS3.SSS3.p2.4.m4.4.4.2.2.2.3">𝑚</ci></apply><ci id="S3.SS3.SSS3.p2.4.m4.2.2.cmml" xref="S3.SS3.SSS3.p2.4.m4.2.2">⋯</ci><apply id="S3.SS3.SSS3.p2.4.m4.5.5.3.3.3.cmml" xref="S3.SS3.SSS3.p2.4.m4.5.5.3.3.3"><csymbol cd="ambiguous" id="S3.SS3.SSS3.p2.4.m4.5.5.3.3.3.1.cmml" xref="S3.SS3.SSS3.p2.4.m4.5.5.3.3.3">subscript</csymbol><ci id="S3.SS3.SSS3.p2.4.m4.5.5.3.3.3.2.cmml" xref="S3.SS3.SSS3.p2.4.m4.5.5.3.3.3.2">𝐶</ci><ci id="S3.SS3.SSS3.p2.4.m4.5.5.3.3.3.3.cmml" xref="S3.SS3.SSS3.p2.4.m4.5.5.3.3.3.3">𝑀</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS3.p2.4.m4.5c">S^{\prime}=\{C_{1},\cdots,C_{m},\cdots,C_{M}\}</annotation></semantics></math> of <math id="S3.SS3.SSS3.p2.5.m5.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S3.SS3.SSS3.p2.5.m5.1a"><mi id="S3.SS3.SSS3.p2.5.m5.1.1" xref="S3.SS3.SSS3.p2.5.m5.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS3.p2.5.m5.1b"><ci id="S3.SS3.SSS3.p2.5.m5.1.1.cmml" xref="S3.SS3.SSS3.p2.5.m5.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS3.p2.5.m5.1c">M</annotation></semantics></math> clients (<math id="S3.SS3.SSS3.p2.6.m6.1" class="ltx_Math" alttext="M&lt;N" display="inline"><semantics id="S3.SS3.SSS3.p2.6.m6.1a"><mrow id="S3.SS3.SSS3.p2.6.m6.1.1" xref="S3.SS3.SSS3.p2.6.m6.1.1.cmml"><mi id="S3.SS3.SSS3.p2.6.m6.1.1.2" xref="S3.SS3.SSS3.p2.6.m6.1.1.2.cmml">M</mi><mo id="S3.SS3.SSS3.p2.6.m6.1.1.1" xref="S3.SS3.SSS3.p2.6.m6.1.1.1.cmml">&lt;</mo><mi id="S3.SS3.SSS3.p2.6.m6.1.1.3" xref="S3.SS3.SSS3.p2.6.m6.1.1.3.cmml">N</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS3.p2.6.m6.1b"><apply id="S3.SS3.SSS3.p2.6.m6.1.1.cmml" xref="S3.SS3.SSS3.p2.6.m6.1.1"><lt id="S3.SS3.SSS3.p2.6.m6.1.1.1.cmml" xref="S3.SS3.SSS3.p2.6.m6.1.1.1"></lt><ci id="S3.SS3.SSS3.p2.6.m6.1.1.2.cmml" xref="S3.SS3.SSS3.p2.6.m6.1.1.2">𝑀</ci><ci id="S3.SS3.SSS3.p2.6.m6.1.1.3.cmml" xref="S3.SS3.SSS3.p2.6.m6.1.1.3">𝑁</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS3.p2.6.m6.1c">M&lt;N</annotation></semantics></math>) after each FL communication round to minimize the sum of inter-client distances of model weights. To achieve this, we propose that, after receiving the local models from the clients, the central server constructs a <math id="S3.SS3.SSS3.p2.7.m7.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS3.SSS3.p2.7.m7.1a"><mi id="S3.SS3.SSS3.p2.7.m7.1.1" xref="S3.SS3.SSS3.p2.7.m7.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS3.p2.7.m7.1b"><ci id="S3.SS3.SSS3.p2.7.m7.1.1.cmml" xref="S3.SS3.SSS3.p2.7.m7.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS3.p2.7.m7.1c">k</annotation></semantics></math>-d tree using the received model weights. The <math id="S3.SS3.SSS3.p2.8.m8.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS3.SSS3.p2.8.m8.1a"><mi id="S3.SS3.SSS3.p2.8.m8.1.1" xref="S3.SS3.SSS3.p2.8.m8.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS3.p2.8.m8.1b"><ci id="S3.SS3.SSS3.p2.8.m8.1.1.cmml" xref="S3.SS3.SSS3.p2.8.m8.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS3.p2.8.m8.1c">k</annotation></semantics></math>-d tree is a bisecting structure where each branch point is the median in some dimension, and this bisecting structure helps improve the efficiency of finding the nearest client (local) models with minimum distances. Subsequently, the central server traverses every client in the set <math id="S3.SS3.SSS3.p2.9.m9.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S3.SS3.SSS3.p2.9.m9.1a"><mi id="S3.SS3.SSS3.p2.9.m9.1.1" xref="S3.SS3.SSS3.p2.9.m9.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS3.p2.9.m9.1b"><ci id="S3.SS3.SSS3.p2.9.m9.1.1.cmml" xref="S3.SS3.SSS3.p2.9.m9.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS3.p2.9.m9.1c">S</annotation></semantics></math>, and queries its <math id="S3.SS3.SSS3.p2.10.m10.1" class="ltx_Math" alttext="M-1" display="inline"><semantics id="S3.SS3.SSS3.p2.10.m10.1a"><mrow id="S3.SS3.SSS3.p2.10.m10.1.1" xref="S3.SS3.SSS3.p2.10.m10.1.1.cmml"><mi id="S3.SS3.SSS3.p2.10.m10.1.1.2" xref="S3.SS3.SSS3.p2.10.m10.1.1.2.cmml">M</mi><mo id="S3.SS3.SSS3.p2.10.m10.1.1.1" xref="S3.SS3.SSS3.p2.10.m10.1.1.1.cmml">−</mo><mn id="S3.SS3.SSS3.p2.10.m10.1.1.3" xref="S3.SS3.SSS3.p2.10.m10.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS3.p2.10.m10.1b"><apply id="S3.SS3.SSS3.p2.10.m10.1.1.cmml" xref="S3.SS3.SSS3.p2.10.m10.1.1"><minus id="S3.SS3.SSS3.p2.10.m10.1.1.1.cmml" xref="S3.SS3.SSS3.p2.10.m10.1.1.1"></minus><ci id="S3.SS3.SSS3.p2.10.m10.1.1.2.cmml" xref="S3.SS3.SSS3.p2.10.m10.1.1.2">𝑀</ci><cn type="integer" id="S3.SS3.SSS3.p2.10.m10.1.1.3.cmml" xref="S3.SS3.SSS3.p2.10.m10.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS3.p2.10.m10.1c">M-1</annotation></semantics></math> nearest neighbors efficiently using the <math id="S3.SS3.SSS3.p2.11.m11.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS3.SSS3.p2.11.m11.1a"><mi id="S3.SS3.SSS3.p2.11.m11.1.1" xref="S3.SS3.SSS3.p2.11.m11.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS3.p2.11.m11.1b"><ci id="S3.SS3.SSS3.p2.11.m11.1.1.cmml" xref="S3.SS3.SSS3.p2.11.m11.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS3.p2.11.m11.1c">k</annotation></semantics></math>-d tree data structure. The client with the minimum distance sum to its <math id="S3.SS3.SSS3.p2.12.m12.1" class="ltx_Math" alttext="M-1" display="inline"><semantics id="S3.SS3.SSS3.p2.12.m12.1a"><mrow id="S3.SS3.SSS3.p2.12.m12.1.1" xref="S3.SS3.SSS3.p2.12.m12.1.1.cmml"><mi id="S3.SS3.SSS3.p2.12.m12.1.1.2" xref="S3.SS3.SSS3.p2.12.m12.1.1.2.cmml">M</mi><mo id="S3.SS3.SSS3.p2.12.m12.1.1.1" xref="S3.SS3.SSS3.p2.12.m12.1.1.1.cmml">−</mo><mn id="S3.SS3.SSS3.p2.12.m12.1.1.3" xref="S3.SS3.SSS3.p2.12.m12.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS3.p2.12.m12.1b"><apply id="S3.SS3.SSS3.p2.12.m12.1.1.cmml" xref="S3.SS3.SSS3.p2.12.m12.1.1"><minus id="S3.SS3.SSS3.p2.12.m12.1.1.1.cmml" xref="S3.SS3.SSS3.p2.12.m12.1.1.1"></minus><ci id="S3.SS3.SSS3.p2.12.m12.1.1.2.cmml" xref="S3.SS3.SSS3.p2.12.m12.1.1.2">𝑀</ci><cn type="integer" id="S3.SS3.SSS3.p2.12.m12.1.1.3.cmml" xref="S3.SS3.SSS3.p2.12.m12.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS3.p2.12.m12.1c">M-1</annotation></semantics></math> neighbors, together with its <math id="S3.SS3.SSS3.p2.13.m13.1" class="ltx_Math" alttext="M-1" display="inline"><semantics id="S3.SS3.SSS3.p2.13.m13.1a"><mrow id="S3.SS3.SSS3.p2.13.m13.1.1" xref="S3.SS3.SSS3.p2.13.m13.1.1.cmml"><mi id="S3.SS3.SSS3.p2.13.m13.1.1.2" xref="S3.SS3.SSS3.p2.13.m13.1.1.2.cmml">M</mi><mo id="S3.SS3.SSS3.p2.13.m13.1.1.1" xref="S3.SS3.SSS3.p2.13.m13.1.1.1.cmml">−</mo><mn id="S3.SS3.SSS3.p2.13.m13.1.1.3" xref="S3.SS3.SSS3.p2.13.m13.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS3.p2.13.m13.1b"><apply id="S3.SS3.SSS3.p2.13.m13.1.1.cmml" xref="S3.SS3.SSS3.p2.13.m13.1.1"><minus id="S3.SS3.SSS3.p2.13.m13.1.1.1.cmml" xref="S3.SS3.SSS3.p2.13.m13.1.1.1"></minus><ci id="S3.SS3.SSS3.p2.13.m13.1.1.2.cmml" xref="S3.SS3.SSS3.p2.13.m13.1.1.2">𝑀</ci><cn type="integer" id="S3.SS3.SSS3.p2.13.m13.1.1.3.cmml" xref="S3.SS3.SSS3.p2.13.m13.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS3.p2.13.m13.1c">M-1</annotation></semantics></math> neighbors, form the subset of selected clients <math id="S3.SS3.SSS3.p2.14.m14.1" class="ltx_Math" alttext="S^{\prime}" display="inline"><semantics id="S3.SS3.SSS3.p2.14.m14.1a"><msup id="S3.SS3.SSS3.p2.14.m14.1.1" xref="S3.SS3.SSS3.p2.14.m14.1.1.cmml"><mi id="S3.SS3.SSS3.p2.14.m14.1.1.2" xref="S3.SS3.SSS3.p2.14.m14.1.1.2.cmml">S</mi><mo id="S3.SS3.SSS3.p2.14.m14.1.1.3" xref="S3.SS3.SSS3.p2.14.m14.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS3.p2.14.m14.1b"><apply id="S3.SS3.SSS3.p2.14.m14.1.1.cmml" xref="S3.SS3.SSS3.p2.14.m14.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS3.p2.14.m14.1.1.1.cmml" xref="S3.SS3.SSS3.p2.14.m14.1.1">superscript</csymbol><ci id="S3.SS3.SSS3.p2.14.m14.1.1.2.cmml" xref="S3.SS3.SSS3.p2.14.m14.1.1.2">𝑆</ci><ci id="S3.SS3.SSS3.p2.14.m14.1.1.3.cmml" xref="S3.SS3.SSS3.p2.14.m14.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS3.p2.14.m14.1c">S^{\prime}</annotation></semantics></math>. Since the time complexity of one query is <math id="S3.SS3.SSS3.p2.15.m15.1" class="ltx_Math" alttext="O(\log{N})" display="inline"><semantics id="S3.SS3.SSS3.p2.15.m15.1a"><mrow id="S3.SS3.SSS3.p2.15.m15.1.1" xref="S3.SS3.SSS3.p2.15.m15.1.1.cmml"><mi id="S3.SS3.SSS3.p2.15.m15.1.1.3" xref="S3.SS3.SSS3.p2.15.m15.1.1.3.cmml">O</mi><mo lspace="0em" rspace="0em" id="S3.SS3.SSS3.p2.15.m15.1.1.2" xref="S3.SS3.SSS3.p2.15.m15.1.1.2.cmml">​</mo><mrow id="S3.SS3.SSS3.p2.15.m15.1.1.1.1" xref="S3.SS3.SSS3.p2.15.m15.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS3.SSS3.p2.15.m15.1.1.1.1.2" xref="S3.SS3.SSS3.p2.15.m15.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS3.SSS3.p2.15.m15.1.1.1.1.1" xref="S3.SS3.SSS3.p2.15.m15.1.1.1.1.1.cmml"><mi id="S3.SS3.SSS3.p2.15.m15.1.1.1.1.1.1" xref="S3.SS3.SSS3.p2.15.m15.1.1.1.1.1.1.cmml">log</mi><mo lspace="0.167em" id="S3.SS3.SSS3.p2.15.m15.1.1.1.1.1a" xref="S3.SS3.SSS3.p2.15.m15.1.1.1.1.1.cmml">⁡</mo><mi id="S3.SS3.SSS3.p2.15.m15.1.1.1.1.1.2" xref="S3.SS3.SSS3.p2.15.m15.1.1.1.1.1.2.cmml">N</mi></mrow><mo stretchy="false" id="S3.SS3.SSS3.p2.15.m15.1.1.1.1.3" xref="S3.SS3.SSS3.p2.15.m15.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS3.p2.15.m15.1b"><apply id="S3.SS3.SSS3.p2.15.m15.1.1.cmml" xref="S3.SS3.SSS3.p2.15.m15.1.1"><times id="S3.SS3.SSS3.p2.15.m15.1.1.2.cmml" xref="S3.SS3.SSS3.p2.15.m15.1.1.2"></times><ci id="S3.SS3.SSS3.p2.15.m15.1.1.3.cmml" xref="S3.SS3.SSS3.p2.15.m15.1.1.3">𝑂</ci><apply id="S3.SS3.SSS3.p2.15.m15.1.1.1.1.1.cmml" xref="S3.SS3.SSS3.p2.15.m15.1.1.1.1"><log id="S3.SS3.SSS3.p2.15.m15.1.1.1.1.1.1.cmml" xref="S3.SS3.SSS3.p2.15.m15.1.1.1.1.1.1"></log><ci id="S3.SS3.SSS3.p2.15.m15.1.1.1.1.1.2.cmml" xref="S3.SS3.SSS3.p2.15.m15.1.1.1.1.1.2">𝑁</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS3.p2.15.m15.1c">O(\log{N})</annotation></semantics></math>, traversing the whole set <math id="S3.SS3.SSS3.p2.16.m16.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S3.SS3.SSS3.p2.16.m16.1a"><mi id="S3.SS3.SSS3.p2.16.m16.1.1" xref="S3.SS3.SSS3.p2.16.m16.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS3.p2.16.m16.1b"><ci id="S3.SS3.SSS3.p2.16.m16.1.1.cmml" xref="S3.SS3.SSS3.p2.16.m16.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS3.p2.16.m16.1c">S</annotation></semantics></math> demands a complexity of <math id="S3.SS3.SSS3.p2.17.m17.1" class="ltx_Math" alttext="O(N\log{N})" display="inline"><semantics id="S3.SS3.SSS3.p2.17.m17.1a"><mrow id="S3.SS3.SSS3.p2.17.m17.1.1" xref="S3.SS3.SSS3.p2.17.m17.1.1.cmml"><mi id="S3.SS3.SSS3.p2.17.m17.1.1.3" xref="S3.SS3.SSS3.p2.17.m17.1.1.3.cmml">O</mi><mo lspace="0em" rspace="0em" id="S3.SS3.SSS3.p2.17.m17.1.1.2" xref="S3.SS3.SSS3.p2.17.m17.1.1.2.cmml">​</mo><mrow id="S3.SS3.SSS3.p2.17.m17.1.1.1.1" xref="S3.SS3.SSS3.p2.17.m17.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS3.SSS3.p2.17.m17.1.1.1.1.2" xref="S3.SS3.SSS3.p2.17.m17.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS3.SSS3.p2.17.m17.1.1.1.1.1" xref="S3.SS3.SSS3.p2.17.m17.1.1.1.1.1.cmml"><mi id="S3.SS3.SSS3.p2.17.m17.1.1.1.1.1.2" xref="S3.SS3.SSS3.p2.17.m17.1.1.1.1.1.2.cmml">N</mi><mo lspace="0.167em" rspace="0em" id="S3.SS3.SSS3.p2.17.m17.1.1.1.1.1.1" xref="S3.SS3.SSS3.p2.17.m17.1.1.1.1.1.1.cmml">​</mo><mrow id="S3.SS3.SSS3.p2.17.m17.1.1.1.1.1.3" xref="S3.SS3.SSS3.p2.17.m17.1.1.1.1.1.3.cmml"><mi id="S3.SS3.SSS3.p2.17.m17.1.1.1.1.1.3.1" xref="S3.SS3.SSS3.p2.17.m17.1.1.1.1.1.3.1.cmml">log</mi><mo lspace="0.167em" id="S3.SS3.SSS3.p2.17.m17.1.1.1.1.1.3a" xref="S3.SS3.SSS3.p2.17.m17.1.1.1.1.1.3.cmml">⁡</mo><mi id="S3.SS3.SSS3.p2.17.m17.1.1.1.1.1.3.2" xref="S3.SS3.SSS3.p2.17.m17.1.1.1.1.1.3.2.cmml">N</mi></mrow></mrow><mo stretchy="false" id="S3.SS3.SSS3.p2.17.m17.1.1.1.1.3" xref="S3.SS3.SSS3.p2.17.m17.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS3.p2.17.m17.1b"><apply id="S3.SS3.SSS3.p2.17.m17.1.1.cmml" xref="S3.SS3.SSS3.p2.17.m17.1.1"><times id="S3.SS3.SSS3.p2.17.m17.1.1.2.cmml" xref="S3.SS3.SSS3.p2.17.m17.1.1.2"></times><ci id="S3.SS3.SSS3.p2.17.m17.1.1.3.cmml" xref="S3.SS3.SSS3.p2.17.m17.1.1.3">𝑂</ci><apply id="S3.SS3.SSS3.p2.17.m17.1.1.1.1.1.cmml" xref="S3.SS3.SSS3.p2.17.m17.1.1.1.1"><times id="S3.SS3.SSS3.p2.17.m17.1.1.1.1.1.1.cmml" xref="S3.SS3.SSS3.p2.17.m17.1.1.1.1.1.1"></times><ci id="S3.SS3.SSS3.p2.17.m17.1.1.1.1.1.2.cmml" xref="S3.SS3.SSS3.p2.17.m17.1.1.1.1.1.2">𝑁</ci><apply id="S3.SS3.SSS3.p2.17.m17.1.1.1.1.1.3.cmml" xref="S3.SS3.SSS3.p2.17.m17.1.1.1.1.1.3"><log id="S3.SS3.SSS3.p2.17.m17.1.1.1.1.1.3.1.cmml" xref="S3.SS3.SSS3.p2.17.m17.1.1.1.1.1.3.1"></log><ci id="S3.SS3.SSS3.p2.17.m17.1.1.1.1.1.3.2.cmml" xref="S3.SS3.SSS3.p2.17.m17.1.1.1.1.1.3.2">𝑁</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS3.p2.17.m17.1c">O(N\log{N})</annotation></semantics></math>, which saves up a lot of time when compared with <math id="S3.SS3.SSS3.p2.18.m18.1" class="ltx_Math" alttext="O(N^{2})" display="inline"><semantics id="S3.SS3.SSS3.p2.18.m18.1a"><mrow id="S3.SS3.SSS3.p2.18.m18.1.1" xref="S3.SS3.SSS3.p2.18.m18.1.1.cmml"><mi id="S3.SS3.SSS3.p2.18.m18.1.1.3" xref="S3.SS3.SSS3.p2.18.m18.1.1.3.cmml">O</mi><mo lspace="0em" rspace="0em" id="S3.SS3.SSS3.p2.18.m18.1.1.2" xref="S3.SS3.SSS3.p2.18.m18.1.1.2.cmml">​</mo><mrow id="S3.SS3.SSS3.p2.18.m18.1.1.1.1" xref="S3.SS3.SSS3.p2.18.m18.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS3.SSS3.p2.18.m18.1.1.1.1.2" xref="S3.SS3.SSS3.p2.18.m18.1.1.1.1.1.cmml">(</mo><msup id="S3.SS3.SSS3.p2.18.m18.1.1.1.1.1" xref="S3.SS3.SSS3.p2.18.m18.1.1.1.1.1.cmml"><mi id="S3.SS3.SSS3.p2.18.m18.1.1.1.1.1.2" xref="S3.SS3.SSS3.p2.18.m18.1.1.1.1.1.2.cmml">N</mi><mn id="S3.SS3.SSS3.p2.18.m18.1.1.1.1.1.3" xref="S3.SS3.SSS3.p2.18.m18.1.1.1.1.1.3.cmml">2</mn></msup><mo stretchy="false" id="S3.SS3.SSS3.p2.18.m18.1.1.1.1.3" xref="S3.SS3.SSS3.p2.18.m18.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS3.p2.18.m18.1b"><apply id="S3.SS3.SSS3.p2.18.m18.1.1.cmml" xref="S3.SS3.SSS3.p2.18.m18.1.1"><times id="S3.SS3.SSS3.p2.18.m18.1.1.2.cmml" xref="S3.SS3.SSS3.p2.18.m18.1.1.2"></times><ci id="S3.SS3.SSS3.p2.18.m18.1.1.3.cmml" xref="S3.SS3.SSS3.p2.18.m18.1.1.3">𝑂</ci><apply id="S3.SS3.SSS3.p2.18.m18.1.1.1.1.1.cmml" xref="S3.SS3.SSS3.p2.18.m18.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS3.p2.18.m18.1.1.1.1.1.1.cmml" xref="S3.SS3.SSS3.p2.18.m18.1.1.1.1">superscript</csymbol><ci id="S3.SS3.SSS3.p2.18.m18.1.1.1.1.1.2.cmml" xref="S3.SS3.SSS3.p2.18.m18.1.1.1.1.1.2">𝑁</ci><cn type="integer" id="S3.SS3.SSS3.p2.18.m18.1.1.1.1.1.3.cmml" xref="S3.SS3.SSS3.p2.18.m18.1.1.1.1.1.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS3.p2.18.m18.1c">O(N^{2})</annotation></semantics></math> complexity of brute-force search, especially when there are many clients involved. At last, the central server aggregates the model weights from the selected clients in subset <math id="S3.SS3.SSS3.p2.19.m19.1" class="ltx_Math" alttext="S^{\prime}" display="inline"><semantics id="S3.SS3.SSS3.p2.19.m19.1a"><msup id="S3.SS3.SSS3.p2.19.m19.1.1" xref="S3.SS3.SSS3.p2.19.m19.1.1.cmml"><mi id="S3.SS3.SSS3.p2.19.m19.1.1.2" xref="S3.SS3.SSS3.p2.19.m19.1.1.2.cmml">S</mi><mo id="S3.SS3.SSS3.p2.19.m19.1.1.3" xref="S3.SS3.SSS3.p2.19.m19.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS3.p2.19.m19.1b"><apply id="S3.SS3.SSS3.p2.19.m19.1.1.cmml" xref="S3.SS3.SSS3.p2.19.m19.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS3.p2.19.m19.1.1.1.cmml" xref="S3.SS3.SSS3.p2.19.m19.1.1">superscript</csymbol><ci id="S3.SS3.SSS3.p2.19.m19.1.1.2.cmml" xref="S3.SS3.SSS3.p2.19.m19.1.1.2">𝑆</ci><ci id="S3.SS3.SSS3.p2.19.m19.1.1.3.cmml" xref="S3.SS3.SSS3.p2.19.m19.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS3.p2.19.m19.1c">S^{\prime}</annotation></semantics></math>, and distributes the updated global model to all clients in <math id="S3.SS3.SSS3.p2.20.m20.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S3.SS3.SSS3.p2.20.m20.1a"><mi id="S3.SS3.SSS3.p2.20.m20.1.1" xref="S3.SS3.SSS3.p2.20.m20.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS3.p2.20.m20.1b"><ci id="S3.SS3.SSS3.p2.20.m20.1.1.cmml" xref="S3.SS3.SSS3.p2.20.m20.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS3.p2.20.m20.1c">S</annotation></semantics></math> for training in the next communication round.</p>
</div>
<figure id="S3.F9" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F9.sf1" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S3.F9.sf1.1" class="ltx_block ltx_minipage ltx_align_bottom" style="width:203.8pt;">
<img src="/html/2302.08646/assets/x14.png" id="S3.F9.sf1.1.g1" class="ltx_graphics ltx_img_landscape" width="442" height="265" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>PCA embedding.</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F9.sf2" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S3.F9.sf2.1" class="ltx_block ltx_minipage ltx_align_bottom" style="width:203.8pt;">
<img src="/html/2302.08646/assets/x15.png" id="S3.F9.sf2.1.g1" class="ltx_graphics ltx_img_landscape" width="442" height="266" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Average precision.</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9. </span>Client selection mitigates diverged models.</figcaption>
</figure>
<div id="S3.SS3.SSS3.p3" class="ltx_para">
<p id="S3.SS3.SSS3.p3.1" class="ltx_p">To illustrate the effect of our client selection strategy, we train the multi-modal vehicle detection network following the settings in § <a href="#S2.SS3" title="2.3. Model Divergence ‣ 2. Motivation ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.3</span></a>. After each communication round, we let the central server selects 40% of the clients (i.e., <math id="S3.SS3.SSS3.p3.1.m1.1" class="ltx_Math" alttext="M=0.4N" display="inline"><semantics id="S3.SS3.SSS3.p3.1.m1.1a"><mrow id="S3.SS3.SSS3.p3.1.m1.1.1" xref="S3.SS3.SSS3.p3.1.m1.1.1.cmml"><mi id="S3.SS3.SSS3.p3.1.m1.1.1.2" xref="S3.SS3.SSS3.p3.1.m1.1.1.2.cmml">M</mi><mo id="S3.SS3.SSS3.p3.1.m1.1.1.1" xref="S3.SS3.SSS3.p3.1.m1.1.1.1.cmml">=</mo><mrow id="S3.SS3.SSS3.p3.1.m1.1.1.3" xref="S3.SS3.SSS3.p3.1.m1.1.1.3.cmml"><mn id="S3.SS3.SSS3.p3.1.m1.1.1.3.2" xref="S3.SS3.SSS3.p3.1.m1.1.1.3.2.cmml">0.4</mn><mo lspace="0em" rspace="0em" id="S3.SS3.SSS3.p3.1.m1.1.1.3.1" xref="S3.SS3.SSS3.p3.1.m1.1.1.3.1.cmml">​</mo><mi id="S3.SS3.SSS3.p3.1.m1.1.1.3.3" xref="S3.SS3.SSS3.p3.1.m1.1.1.3.3.cmml">N</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS3.p3.1.m1.1b"><apply id="S3.SS3.SSS3.p3.1.m1.1.1.cmml" xref="S3.SS3.SSS3.p3.1.m1.1.1"><eq id="S3.SS3.SSS3.p3.1.m1.1.1.1.cmml" xref="S3.SS3.SSS3.p3.1.m1.1.1.1"></eq><ci id="S3.SS3.SSS3.p3.1.m1.1.1.2.cmml" xref="S3.SS3.SSS3.p3.1.m1.1.1.2">𝑀</ci><apply id="S3.SS3.SSS3.p3.1.m1.1.1.3.cmml" xref="S3.SS3.SSS3.p3.1.m1.1.1.3"><times id="S3.SS3.SSS3.p3.1.m1.1.1.3.1.cmml" xref="S3.SS3.SSS3.p3.1.m1.1.1.3.1"></times><cn type="float" id="S3.SS3.SSS3.p3.1.m1.1.1.3.2.cmml" xref="S3.SS3.SSS3.p3.1.m1.1.1.3.2">0.4</cn><ci id="S3.SS3.SSS3.p3.1.m1.1.1.3.3.cmml" xref="S3.SS3.SSS3.p3.1.m1.1.1.3.3">𝑁</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS3.p3.1.m1.1c">M=0.4N</annotation></semantics></math>) to form a subset of clients with minimum inter-client local model weight distance, as demonstrated in Figure <a href="#S3.F9.sf1" title="In Figure 9 ‣ 3.3.3. Client Selection for Tolerating Model Weight Anomalies ‣ 3.3. AutoFed Framework ‣ 3. System Design ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9a</span></a>. The average vehicle detection precision is shown in Figure <a href="#S3.F9.sf2" title="In Figure 9 ‣ 3.3.3. Client Selection for Tolerating Model Weight Anomalies ‣ 3.3. AutoFed Framework ‣ 3. System Design ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9b</span></a>. One may readily observe that the precision of vehicle detection reaches up to 0.6 when client selection is enabled, and it fluctuates around 0.5 when model weights from all clients are aggregated using the FedAvg algorithm. Moreover, Figure <a href="#S3.F9" title="Figure 9 ‣ 3.3.3. Client Selection for Tolerating Model Weight Anomalies ‣ 3.3. AutoFed Framework ‣ 3. System Design ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a> also demonstrates that client selection makes the training converge faster
with less than 20 epochs, while the training without client selection barely starts to converge till the 25-th epoch. These phenomena indicate that client selection helps better utilize data from beneficial clients. Upon further inspection, we find that after convergence, the fluctuation of the precision curve with client selection is much smaller than that without client selection, which indicates that the mechanism indeed selects mutually-enhancing clients while excluding erroneous gradient signals from outliers. Additionally, it can be observed that the average precision with client selection becomes stable after only 70 epochs. This confirms that the model has effectively learned from all clients (including the corner cases), so additional training will not yield any further improvement in performance.</p>
</div>
<figure id="algorithm1" class="ltx_float ltx_algorithm">
<div id="algorithm1.39" class="ltx_listing ltx_lst_numbers_left ltx_listing">
<div id="algorithm1.39.40" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">1</span>







</div>
<div id="algorithm1.2.2" class="ltx_listingline">
<span id="algorithm1.2.2.1" class="ltx_text ltx_font_bold">Require :</span> <math id="algorithm1.1.1.m1.1" class="ltx_Math" alttext="N" display="inline"><semantics id="algorithm1.1.1.m1.1a"><mi id="algorithm1.1.1.m1.1.1" xref="algorithm1.1.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="algorithm1.1.1.m1.1b"><ci id="algorithm1.1.1.m1.1.1.cmml" xref="algorithm1.1.1.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.1.1.m1.1c">N</annotation></semantics></math> is the total number of clients, <math id="algorithm1.2.2.m2.1" class="ltx_Math" alttext="c" display="inline"><semantics id="algorithm1.2.2.m2.1a"><mi id="algorithm1.2.2.m2.1.1" xref="algorithm1.2.2.m2.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="algorithm1.2.2.m2.1b"><ci id="algorithm1.2.2.m2.1.1.cmml" xref="algorithm1.2.2.m2.1.1">𝑐</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.2.2.m2.1c">c</annotation></semantics></math> is the percentage of clients to choose.
</div>
<div id="algorithm1.5.5" class="ltx_listingline">
<span id="algorithm1.5.5.1" class="ltx_text"><span id="algorithm1.5.5.1.1" class="ltx_text ltx_font_bold">Data:</span> </span><math id="algorithm1.3.3.m1.5" class="ltx_Math" alttext="\{(\mathcal{L}_{1},\mathcal{R}_{1}),\cdots,(\mathcal{L}_{n},\mathcal{R}_{n}),\cdots,(\mathcal{L}_{N},\mathcal{R}_{N})\}" display="inline"><semantics id="algorithm1.3.3.m1.5a"><mrow id="algorithm1.3.3.m1.5.5.3" xref="algorithm1.3.3.m1.5.5.4.cmml"><mo stretchy="false" id="algorithm1.3.3.m1.5.5.3.4" xref="algorithm1.3.3.m1.5.5.4.cmml">{</mo><mrow id="algorithm1.3.3.m1.3.3.1.1.2" xref="algorithm1.3.3.m1.3.3.1.1.3.cmml"><mo stretchy="false" id="algorithm1.3.3.m1.3.3.1.1.2.3" xref="algorithm1.3.3.m1.3.3.1.1.3.cmml">(</mo><msub id="algorithm1.3.3.m1.3.3.1.1.1.1" xref="algorithm1.3.3.m1.3.3.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="algorithm1.3.3.m1.3.3.1.1.1.1.2" xref="algorithm1.3.3.m1.3.3.1.1.1.1.2.cmml">ℒ</mi><mn id="algorithm1.3.3.m1.3.3.1.1.1.1.3" xref="algorithm1.3.3.m1.3.3.1.1.1.1.3.cmml">1</mn></msub><mo id="algorithm1.3.3.m1.3.3.1.1.2.4" xref="algorithm1.3.3.m1.3.3.1.1.3.cmml">,</mo><msub id="algorithm1.3.3.m1.3.3.1.1.2.2" xref="algorithm1.3.3.m1.3.3.1.1.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="algorithm1.3.3.m1.3.3.1.1.2.2.2" xref="algorithm1.3.3.m1.3.3.1.1.2.2.2.cmml">ℛ</mi><mn id="algorithm1.3.3.m1.3.3.1.1.2.2.3" xref="algorithm1.3.3.m1.3.3.1.1.2.2.3.cmml">1</mn></msub><mo stretchy="false" id="algorithm1.3.3.m1.3.3.1.1.2.5" xref="algorithm1.3.3.m1.3.3.1.1.3.cmml">)</mo></mrow><mo id="algorithm1.3.3.m1.5.5.3.5" xref="algorithm1.3.3.m1.5.5.4.cmml">,</mo><mi mathvariant="normal" id="algorithm1.3.3.m1.1.1" xref="algorithm1.3.3.m1.1.1.cmml">⋯</mi><mo id="algorithm1.3.3.m1.5.5.3.6" xref="algorithm1.3.3.m1.5.5.4.cmml">,</mo><mrow id="algorithm1.3.3.m1.4.4.2.2.2" xref="algorithm1.3.3.m1.4.4.2.2.3.cmml"><mo stretchy="false" id="algorithm1.3.3.m1.4.4.2.2.2.3" xref="algorithm1.3.3.m1.4.4.2.2.3.cmml">(</mo><msub id="algorithm1.3.3.m1.4.4.2.2.1.1" xref="algorithm1.3.3.m1.4.4.2.2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="algorithm1.3.3.m1.4.4.2.2.1.1.2" xref="algorithm1.3.3.m1.4.4.2.2.1.1.2.cmml">ℒ</mi><mi id="algorithm1.3.3.m1.4.4.2.2.1.1.3" xref="algorithm1.3.3.m1.4.4.2.2.1.1.3.cmml">n</mi></msub><mo id="algorithm1.3.3.m1.4.4.2.2.2.4" xref="algorithm1.3.3.m1.4.4.2.2.3.cmml">,</mo><msub id="algorithm1.3.3.m1.4.4.2.2.2.2" xref="algorithm1.3.3.m1.4.4.2.2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="algorithm1.3.3.m1.4.4.2.2.2.2.2" xref="algorithm1.3.3.m1.4.4.2.2.2.2.2.cmml">ℛ</mi><mi id="algorithm1.3.3.m1.4.4.2.2.2.2.3" xref="algorithm1.3.3.m1.4.4.2.2.2.2.3.cmml">n</mi></msub><mo stretchy="false" id="algorithm1.3.3.m1.4.4.2.2.2.5" xref="algorithm1.3.3.m1.4.4.2.2.3.cmml">)</mo></mrow><mo id="algorithm1.3.3.m1.5.5.3.7" xref="algorithm1.3.3.m1.5.5.4.cmml">,</mo><mi mathvariant="normal" id="algorithm1.3.3.m1.2.2" xref="algorithm1.3.3.m1.2.2.cmml">⋯</mi><mo id="algorithm1.3.3.m1.5.5.3.8" xref="algorithm1.3.3.m1.5.5.4.cmml">,</mo><mrow id="algorithm1.3.3.m1.5.5.3.3.2" xref="algorithm1.3.3.m1.5.5.3.3.3.cmml"><mo stretchy="false" id="algorithm1.3.3.m1.5.5.3.3.2.3" xref="algorithm1.3.3.m1.5.5.3.3.3.cmml">(</mo><msub id="algorithm1.3.3.m1.5.5.3.3.1.1" xref="algorithm1.3.3.m1.5.5.3.3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="algorithm1.3.3.m1.5.5.3.3.1.1.2" xref="algorithm1.3.3.m1.5.5.3.3.1.1.2.cmml">ℒ</mi><mi id="algorithm1.3.3.m1.5.5.3.3.1.1.3" xref="algorithm1.3.3.m1.5.5.3.3.1.1.3.cmml">N</mi></msub><mo id="algorithm1.3.3.m1.5.5.3.3.2.4" xref="algorithm1.3.3.m1.5.5.3.3.3.cmml">,</mo><msub id="algorithm1.3.3.m1.5.5.3.3.2.2" xref="algorithm1.3.3.m1.5.5.3.3.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="algorithm1.3.3.m1.5.5.3.3.2.2.2" xref="algorithm1.3.3.m1.5.5.3.3.2.2.2.cmml">ℛ</mi><mi id="algorithm1.3.3.m1.5.5.3.3.2.2.3" xref="algorithm1.3.3.m1.5.5.3.3.2.2.3.cmml">N</mi></msub><mo stretchy="false" id="algorithm1.3.3.m1.5.5.3.3.2.5" xref="algorithm1.3.3.m1.5.5.3.3.3.cmml">)</mo></mrow><mo stretchy="false" id="algorithm1.3.3.m1.5.5.3.9" xref="algorithm1.3.3.m1.5.5.4.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.3.3.m1.5b"><set id="algorithm1.3.3.m1.5.5.4.cmml" xref="algorithm1.3.3.m1.5.5.3"><interval closure="open" id="algorithm1.3.3.m1.3.3.1.1.3.cmml" xref="algorithm1.3.3.m1.3.3.1.1.2"><apply id="algorithm1.3.3.m1.3.3.1.1.1.1.cmml" xref="algorithm1.3.3.m1.3.3.1.1.1.1"><csymbol cd="ambiguous" id="algorithm1.3.3.m1.3.3.1.1.1.1.1.cmml" xref="algorithm1.3.3.m1.3.3.1.1.1.1">subscript</csymbol><ci id="algorithm1.3.3.m1.3.3.1.1.1.1.2.cmml" xref="algorithm1.3.3.m1.3.3.1.1.1.1.2">ℒ</ci><cn type="integer" id="algorithm1.3.3.m1.3.3.1.1.1.1.3.cmml" xref="algorithm1.3.3.m1.3.3.1.1.1.1.3">1</cn></apply><apply id="algorithm1.3.3.m1.3.3.1.1.2.2.cmml" xref="algorithm1.3.3.m1.3.3.1.1.2.2"><csymbol cd="ambiguous" id="algorithm1.3.3.m1.3.3.1.1.2.2.1.cmml" xref="algorithm1.3.3.m1.3.3.1.1.2.2">subscript</csymbol><ci id="algorithm1.3.3.m1.3.3.1.1.2.2.2.cmml" xref="algorithm1.3.3.m1.3.3.1.1.2.2.2">ℛ</ci><cn type="integer" id="algorithm1.3.3.m1.3.3.1.1.2.2.3.cmml" xref="algorithm1.3.3.m1.3.3.1.1.2.2.3">1</cn></apply></interval><ci id="algorithm1.3.3.m1.1.1.cmml" xref="algorithm1.3.3.m1.1.1">⋯</ci><interval closure="open" id="algorithm1.3.3.m1.4.4.2.2.3.cmml" xref="algorithm1.3.3.m1.4.4.2.2.2"><apply id="algorithm1.3.3.m1.4.4.2.2.1.1.cmml" xref="algorithm1.3.3.m1.4.4.2.2.1.1"><csymbol cd="ambiguous" id="algorithm1.3.3.m1.4.4.2.2.1.1.1.cmml" xref="algorithm1.3.3.m1.4.4.2.2.1.1">subscript</csymbol><ci id="algorithm1.3.3.m1.4.4.2.2.1.1.2.cmml" xref="algorithm1.3.3.m1.4.4.2.2.1.1.2">ℒ</ci><ci id="algorithm1.3.3.m1.4.4.2.2.1.1.3.cmml" xref="algorithm1.3.3.m1.4.4.2.2.1.1.3">𝑛</ci></apply><apply id="algorithm1.3.3.m1.4.4.2.2.2.2.cmml" xref="algorithm1.3.3.m1.4.4.2.2.2.2"><csymbol cd="ambiguous" id="algorithm1.3.3.m1.4.4.2.2.2.2.1.cmml" xref="algorithm1.3.3.m1.4.4.2.2.2.2">subscript</csymbol><ci id="algorithm1.3.3.m1.4.4.2.2.2.2.2.cmml" xref="algorithm1.3.3.m1.4.4.2.2.2.2.2">ℛ</ci><ci id="algorithm1.3.3.m1.4.4.2.2.2.2.3.cmml" xref="algorithm1.3.3.m1.4.4.2.2.2.2.3">𝑛</ci></apply></interval><ci id="algorithm1.3.3.m1.2.2.cmml" xref="algorithm1.3.3.m1.2.2">⋯</ci><interval closure="open" id="algorithm1.3.3.m1.5.5.3.3.3.cmml" xref="algorithm1.3.3.m1.5.5.3.3.2"><apply id="algorithm1.3.3.m1.5.5.3.3.1.1.cmml" xref="algorithm1.3.3.m1.5.5.3.3.1.1"><csymbol cd="ambiguous" id="algorithm1.3.3.m1.5.5.3.3.1.1.1.cmml" xref="algorithm1.3.3.m1.5.5.3.3.1.1">subscript</csymbol><ci id="algorithm1.3.3.m1.5.5.3.3.1.1.2.cmml" xref="algorithm1.3.3.m1.5.5.3.3.1.1.2">ℒ</ci><ci id="algorithm1.3.3.m1.5.5.3.3.1.1.3.cmml" xref="algorithm1.3.3.m1.5.5.3.3.1.1.3">𝑁</ci></apply><apply id="algorithm1.3.3.m1.5.5.3.3.2.2.cmml" xref="algorithm1.3.3.m1.5.5.3.3.2.2"><csymbol cd="ambiguous" id="algorithm1.3.3.m1.5.5.3.3.2.2.1.cmml" xref="algorithm1.3.3.m1.5.5.3.3.2.2">subscript</csymbol><ci id="algorithm1.3.3.m1.5.5.3.3.2.2.2.cmml" xref="algorithm1.3.3.m1.5.5.3.3.2.2.2">ℛ</ci><ci id="algorithm1.3.3.m1.5.5.3.3.2.2.3.cmml" xref="algorithm1.3.3.m1.5.5.3.3.2.2.3">𝑁</ci></apply></interval></set></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.3.3.m1.5c">\{(\mathcal{L}_{1},\mathcal{R}_{1}),\cdots,(\mathcal{L}_{n},\mathcal{R}_{n}),\cdots,(\mathcal{L}_{N},\mathcal{R}_{N})\}</annotation></semantics></math> where <math id="algorithm1.4.4.m2.2" class="ltx_Math" alttext="(\mathcal{L}_{n},\mathcal{R}_{n})" display="inline"><semantics id="algorithm1.4.4.m2.2a"><mrow id="algorithm1.4.4.m2.2.2.2" xref="algorithm1.4.4.m2.2.2.3.cmml"><mo stretchy="false" id="algorithm1.4.4.m2.2.2.2.3" xref="algorithm1.4.4.m2.2.2.3.cmml">(</mo><msub id="algorithm1.4.4.m2.1.1.1.1" xref="algorithm1.4.4.m2.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="algorithm1.4.4.m2.1.1.1.1.2" xref="algorithm1.4.4.m2.1.1.1.1.2.cmml">ℒ</mi><mi id="algorithm1.4.4.m2.1.1.1.1.3" xref="algorithm1.4.4.m2.1.1.1.1.3.cmml">n</mi></msub><mo id="algorithm1.4.4.m2.2.2.2.4" xref="algorithm1.4.4.m2.2.2.3.cmml">,</mo><msub id="algorithm1.4.4.m2.2.2.2.2" xref="algorithm1.4.4.m2.2.2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="algorithm1.4.4.m2.2.2.2.2.2" xref="algorithm1.4.4.m2.2.2.2.2.2.cmml">ℛ</mi><mi id="algorithm1.4.4.m2.2.2.2.2.3" xref="algorithm1.4.4.m2.2.2.2.2.3.cmml">n</mi></msub><mo stretchy="false" id="algorithm1.4.4.m2.2.2.2.5" xref="algorithm1.4.4.m2.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.4.4.m2.2b"><interval closure="open" id="algorithm1.4.4.m2.2.2.3.cmml" xref="algorithm1.4.4.m2.2.2.2"><apply id="algorithm1.4.4.m2.1.1.1.1.cmml" xref="algorithm1.4.4.m2.1.1.1.1"><csymbol cd="ambiguous" id="algorithm1.4.4.m2.1.1.1.1.1.cmml" xref="algorithm1.4.4.m2.1.1.1.1">subscript</csymbol><ci id="algorithm1.4.4.m2.1.1.1.1.2.cmml" xref="algorithm1.4.4.m2.1.1.1.1.2">ℒ</ci><ci id="algorithm1.4.4.m2.1.1.1.1.3.cmml" xref="algorithm1.4.4.m2.1.1.1.1.3">𝑛</ci></apply><apply id="algorithm1.4.4.m2.2.2.2.2.cmml" xref="algorithm1.4.4.m2.2.2.2.2"><csymbol cd="ambiguous" id="algorithm1.4.4.m2.2.2.2.2.1.cmml" xref="algorithm1.4.4.m2.2.2.2.2">subscript</csymbol><ci id="algorithm1.4.4.m2.2.2.2.2.2.cmml" xref="algorithm1.4.4.m2.2.2.2.2.2">ℛ</ci><ci id="algorithm1.4.4.m2.2.2.2.2.3.cmml" xref="algorithm1.4.4.m2.2.2.2.2.3">𝑛</ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.4.4.m2.2c">(\mathcal{L}_{n},\mathcal{R}_{n})</annotation></semantics></math> is the local collected lidar and radar data on the <math id="algorithm1.5.5.m3.1" class="ltx_Math" alttext="n" display="inline"><semantics id="algorithm1.5.5.m3.1a"><mi id="algorithm1.5.5.m3.1.1" xref="algorithm1.5.5.m3.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="algorithm1.5.5.m3.1b"><ci id="algorithm1.5.5.m3.1.1.cmml" xref="algorithm1.5.5.m3.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.5.5.m3.1c">n</annotation></semantics></math>-th AV.
</div>
<div id="algorithm1.39.41" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">2</span>

</div>
<div id="algorithm1.39.42" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">3</span><em id="algorithm1.39.42.1" class="ltx_emph ltx_font_typewriter">Server Executes</em><span id="algorithm1.39.42.2" class="ltx_text ltx_font_bold">:</span>
</div>
<div id="algorithm1.7.7" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">4</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
initialize the global model <math id="algorithm1.6.6.m1.1" class="ltx_Math" alttext="w^{g}_{0}" display="inline"><semantics id="algorithm1.6.6.m1.1a"><msubsup id="algorithm1.6.6.m1.1.1" xref="algorithm1.6.6.m1.1.1.cmml"><mi id="algorithm1.6.6.m1.1.1.2.2" xref="algorithm1.6.6.m1.1.1.2.2.cmml">w</mi><mn id="algorithm1.6.6.m1.1.1.3" xref="algorithm1.6.6.m1.1.1.3.cmml">0</mn><mi id="algorithm1.6.6.m1.1.1.2.3" xref="algorithm1.6.6.m1.1.1.2.3.cmml">g</mi></msubsup><annotation-xml encoding="MathML-Content" id="algorithm1.6.6.m1.1b"><apply id="algorithm1.6.6.m1.1.1.cmml" xref="algorithm1.6.6.m1.1.1"><csymbol cd="ambiguous" id="algorithm1.6.6.m1.1.1.1.cmml" xref="algorithm1.6.6.m1.1.1">subscript</csymbol><apply id="algorithm1.6.6.m1.1.1.2.cmml" xref="algorithm1.6.6.m1.1.1"><csymbol cd="ambiguous" id="algorithm1.6.6.m1.1.1.2.1.cmml" xref="algorithm1.6.6.m1.1.1">superscript</csymbol><ci id="algorithm1.6.6.m1.1.1.2.2.cmml" xref="algorithm1.6.6.m1.1.1.2.2">𝑤</ci><ci id="algorithm1.6.6.m1.1.1.2.3.cmml" xref="algorithm1.6.6.m1.1.1.2.3">𝑔</ci></apply><cn type="integer" id="algorithm1.6.6.m1.1.1.3.cmml" xref="algorithm1.6.6.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.6.6.m1.1c">w^{g}_{0}</annotation></semantics></math> at <math id="algorithm1.7.7.m2.1" class="ltx_Math" alttext="t=0" display="inline"><semantics id="algorithm1.7.7.m2.1a"><mrow id="algorithm1.7.7.m2.1.1" xref="algorithm1.7.7.m2.1.1.cmml"><mi id="algorithm1.7.7.m2.1.1.2" xref="algorithm1.7.7.m2.1.1.2.cmml">t</mi><mo id="algorithm1.7.7.m2.1.1.1" xref="algorithm1.7.7.m2.1.1.1.cmml">=</mo><mn id="algorithm1.7.7.m2.1.1.3" xref="algorithm1.7.7.m2.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.7.7.m2.1b"><apply id="algorithm1.7.7.m2.1.1.cmml" xref="algorithm1.7.7.m2.1.1"><eq id="algorithm1.7.7.m2.1.1.1.cmml" xref="algorithm1.7.7.m2.1.1.1"></eq><ci id="algorithm1.7.7.m2.1.1.2.cmml" xref="algorithm1.7.7.m2.1.1.2">𝑡</ci><cn type="integer" id="algorithm1.7.7.m2.1.1.3.cmml" xref="algorithm1.7.7.m2.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.7.7.m2.1c">t=0</annotation></semantics></math>;
</div>
<div id="algorithm1.8.8" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">5</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
<math id="algorithm1.8.8.m1.3" class="ltx_Math" alttext="S\leftarrow\{C_{1},\cdots,C_{N}\}" display="inline"><semantics id="algorithm1.8.8.m1.3a"><mrow id="algorithm1.8.8.m1.3.3" xref="algorithm1.8.8.m1.3.3.cmml"><mi id="algorithm1.8.8.m1.3.3.4" xref="algorithm1.8.8.m1.3.3.4.cmml">S</mi><mo stretchy="false" id="algorithm1.8.8.m1.3.3.3" xref="algorithm1.8.8.m1.3.3.3.cmml">←</mo><mrow id="algorithm1.8.8.m1.3.3.2.2" xref="algorithm1.8.8.m1.3.3.2.3.cmml"><mo stretchy="false" id="algorithm1.8.8.m1.3.3.2.2.3" xref="algorithm1.8.8.m1.3.3.2.3.cmml">{</mo><msub id="algorithm1.8.8.m1.2.2.1.1.1" xref="algorithm1.8.8.m1.2.2.1.1.1.cmml"><mi id="algorithm1.8.8.m1.2.2.1.1.1.2" xref="algorithm1.8.8.m1.2.2.1.1.1.2.cmml">C</mi><mn id="algorithm1.8.8.m1.2.2.1.1.1.3" xref="algorithm1.8.8.m1.2.2.1.1.1.3.cmml">1</mn></msub><mo id="algorithm1.8.8.m1.3.3.2.2.4" xref="algorithm1.8.8.m1.3.3.2.3.cmml">,</mo><mi mathvariant="normal" id="algorithm1.8.8.m1.1.1" xref="algorithm1.8.8.m1.1.1.cmml">⋯</mi><mo id="algorithm1.8.8.m1.3.3.2.2.5" xref="algorithm1.8.8.m1.3.3.2.3.cmml">,</mo><msub id="algorithm1.8.8.m1.3.3.2.2.2" xref="algorithm1.8.8.m1.3.3.2.2.2.cmml"><mi id="algorithm1.8.8.m1.3.3.2.2.2.2" xref="algorithm1.8.8.m1.3.3.2.2.2.2.cmml">C</mi><mi id="algorithm1.8.8.m1.3.3.2.2.2.3" xref="algorithm1.8.8.m1.3.3.2.2.2.3.cmml">N</mi></msub><mo stretchy="false" id="algorithm1.8.8.m1.3.3.2.2.6" xref="algorithm1.8.8.m1.3.3.2.3.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.8.8.m1.3b"><apply id="algorithm1.8.8.m1.3.3.cmml" xref="algorithm1.8.8.m1.3.3"><ci id="algorithm1.8.8.m1.3.3.3.cmml" xref="algorithm1.8.8.m1.3.3.3">←</ci><ci id="algorithm1.8.8.m1.3.3.4.cmml" xref="algorithm1.8.8.m1.3.3.4">𝑆</ci><set id="algorithm1.8.8.m1.3.3.2.3.cmml" xref="algorithm1.8.8.m1.3.3.2.2"><apply id="algorithm1.8.8.m1.2.2.1.1.1.cmml" xref="algorithm1.8.8.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="algorithm1.8.8.m1.2.2.1.1.1.1.cmml" xref="algorithm1.8.8.m1.2.2.1.1.1">subscript</csymbol><ci id="algorithm1.8.8.m1.2.2.1.1.1.2.cmml" xref="algorithm1.8.8.m1.2.2.1.1.1.2">𝐶</ci><cn type="integer" id="algorithm1.8.8.m1.2.2.1.1.1.3.cmml" xref="algorithm1.8.8.m1.2.2.1.1.1.3">1</cn></apply><ci id="algorithm1.8.8.m1.1.1.cmml" xref="algorithm1.8.8.m1.1.1">⋯</ci><apply id="algorithm1.8.8.m1.3.3.2.2.2.cmml" xref="algorithm1.8.8.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="algorithm1.8.8.m1.3.3.2.2.2.1.cmml" xref="algorithm1.8.8.m1.3.3.2.2.2">subscript</csymbol><ci id="algorithm1.8.8.m1.3.3.2.2.2.2.cmml" xref="algorithm1.8.8.m1.3.3.2.2.2.2">𝐶</ci><ci id="algorithm1.8.8.m1.3.3.2.2.2.3.cmml" xref="algorithm1.8.8.m1.3.3.2.2.2.3">𝑁</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.8.8.m1.3c">S\leftarrow\{C_{1},\cdots,C_{N}\}</annotation></semantics></math>;
</div>
<div id="algorithm1.9.9" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">6</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
<span id="algorithm1.9.9.2" class="ltx_text ltx_font_bold">for</span> <em id="algorithm1.9.9.1" class="ltx_emph ltx_font_italic">communication round <math id="algorithm1.9.9.1.m1.1" class="ltx_Math" alttext="t" display="inline"><semantics id="algorithm1.9.9.1.m1.1a"><mi id="algorithm1.9.9.1.m1.1.1" xref="algorithm1.9.9.1.m1.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="algorithm1.9.9.1.m1.1b"><ci id="algorithm1.9.9.1.m1.1.1.cmml" xref="algorithm1.9.9.1.m1.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.9.9.1.m1.1c">t</annotation></semantics></math></em> <span id="algorithm1.9.9.3" class="ltx_text ltx_font_bold">do</span>
</div>
<div id="algorithm1.10.10" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">7</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
<span id="algorithm1.10.10.2" class="ltx_text ltx_font_bold">for</span> <em id="algorithm1.10.10.1" class="ltx_emph ltx_font_italic"><math id="algorithm1.10.10.1.m1.1" class="ltx_Math" alttext="C_{n}\in S" display="inline"><semantics id="algorithm1.10.10.1.m1.1a"><mrow id="algorithm1.10.10.1.m1.1.1" xref="algorithm1.10.10.1.m1.1.1.cmml"><msub id="algorithm1.10.10.1.m1.1.1.2" xref="algorithm1.10.10.1.m1.1.1.2.cmml"><mi id="algorithm1.10.10.1.m1.1.1.2.2" xref="algorithm1.10.10.1.m1.1.1.2.2.cmml">C</mi><mi id="algorithm1.10.10.1.m1.1.1.2.3" xref="algorithm1.10.10.1.m1.1.1.2.3.cmml">n</mi></msub><mo id="algorithm1.10.10.1.m1.1.1.1" xref="algorithm1.10.10.1.m1.1.1.1.cmml">∈</mo><mi id="algorithm1.10.10.1.m1.1.1.3" xref="algorithm1.10.10.1.m1.1.1.3.cmml">S</mi></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.10.10.1.m1.1b"><apply id="algorithm1.10.10.1.m1.1.1.cmml" xref="algorithm1.10.10.1.m1.1.1"><in id="algorithm1.10.10.1.m1.1.1.1.cmml" xref="algorithm1.10.10.1.m1.1.1.1"></in><apply id="algorithm1.10.10.1.m1.1.1.2.cmml" xref="algorithm1.10.10.1.m1.1.1.2"><csymbol cd="ambiguous" id="algorithm1.10.10.1.m1.1.1.2.1.cmml" xref="algorithm1.10.10.1.m1.1.1.2">subscript</csymbol><ci id="algorithm1.10.10.1.m1.1.1.2.2.cmml" xref="algorithm1.10.10.1.m1.1.1.2.2">𝐶</ci><ci id="algorithm1.10.10.1.m1.1.1.2.3.cmml" xref="algorithm1.10.10.1.m1.1.1.2.3">𝑛</ci></apply><ci id="algorithm1.10.10.1.m1.1.1.3.cmml" xref="algorithm1.10.10.1.m1.1.1.3">𝑆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.10.10.1.m1.1c">C_{n}\in S</annotation></semantics></math> in parallel </em> <span id="algorithm1.10.10.3" class="ltx_text ltx_font_bold">do</span>
</div>
<div id="algorithm1.11.11" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">8</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
<math id="algorithm1.11.11.m1.3" class="ltx_Math" alttext="w_{t+1,n}\leftarrow\textnormal{{Client Update}}(n)" display="inline"><semantics id="algorithm1.11.11.m1.3a"><mrow id="algorithm1.11.11.m1.3.4" xref="algorithm1.11.11.m1.3.4.cmml"><msub id="algorithm1.11.11.m1.3.4.2" xref="algorithm1.11.11.m1.3.4.2.cmml"><mi id="algorithm1.11.11.m1.3.4.2.2" xref="algorithm1.11.11.m1.3.4.2.2.cmml">w</mi><mrow id="algorithm1.11.11.m1.2.2.2.2" xref="algorithm1.11.11.m1.2.2.2.3.cmml"><mrow id="algorithm1.11.11.m1.2.2.2.2.1" xref="algorithm1.11.11.m1.2.2.2.2.1.cmml"><mi id="algorithm1.11.11.m1.2.2.2.2.1.2" xref="algorithm1.11.11.m1.2.2.2.2.1.2.cmml">t</mi><mo id="algorithm1.11.11.m1.2.2.2.2.1.1" xref="algorithm1.11.11.m1.2.2.2.2.1.1.cmml">+</mo><mn id="algorithm1.11.11.m1.2.2.2.2.1.3" xref="algorithm1.11.11.m1.2.2.2.2.1.3.cmml">1</mn></mrow><mo id="algorithm1.11.11.m1.2.2.2.2.2" xref="algorithm1.11.11.m1.2.2.2.3.cmml">,</mo><mi id="algorithm1.11.11.m1.1.1.1.1" xref="algorithm1.11.11.m1.1.1.1.1.cmml">n</mi></mrow></msub><mo stretchy="false" id="algorithm1.11.11.m1.3.4.1" xref="algorithm1.11.11.m1.3.4.1.cmml">←</mo><mrow id="algorithm1.11.11.m1.3.4.3" xref="algorithm1.11.11.m1.3.4.3.cmml"><mtext class="ltx_mathvariant_monospace" id="algorithm1.11.11.m1.3.4.3.2" xref="algorithm1.11.11.m1.3.4.3.2a.cmml">Client Update</mtext><mo lspace="0em" rspace="0em" id="algorithm1.11.11.m1.3.4.3.1" xref="algorithm1.11.11.m1.3.4.3.1.cmml">​</mo><mrow id="algorithm1.11.11.m1.3.4.3.3.2" xref="algorithm1.11.11.m1.3.4.3.cmml"><mo stretchy="false" id="algorithm1.11.11.m1.3.4.3.3.2.1" xref="algorithm1.11.11.m1.3.4.3.cmml">(</mo><mi id="algorithm1.11.11.m1.3.3" xref="algorithm1.11.11.m1.3.3.cmml">n</mi><mo stretchy="false" id="algorithm1.11.11.m1.3.4.3.3.2.2" xref="algorithm1.11.11.m1.3.4.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.11.11.m1.3b"><apply id="algorithm1.11.11.m1.3.4.cmml" xref="algorithm1.11.11.m1.3.4"><ci id="algorithm1.11.11.m1.3.4.1.cmml" xref="algorithm1.11.11.m1.3.4.1">←</ci><apply id="algorithm1.11.11.m1.3.4.2.cmml" xref="algorithm1.11.11.m1.3.4.2"><csymbol cd="ambiguous" id="algorithm1.11.11.m1.3.4.2.1.cmml" xref="algorithm1.11.11.m1.3.4.2">subscript</csymbol><ci id="algorithm1.11.11.m1.3.4.2.2.cmml" xref="algorithm1.11.11.m1.3.4.2.2">𝑤</ci><list id="algorithm1.11.11.m1.2.2.2.3.cmml" xref="algorithm1.11.11.m1.2.2.2.2"><apply id="algorithm1.11.11.m1.2.2.2.2.1.cmml" xref="algorithm1.11.11.m1.2.2.2.2.1"><plus id="algorithm1.11.11.m1.2.2.2.2.1.1.cmml" xref="algorithm1.11.11.m1.2.2.2.2.1.1"></plus><ci id="algorithm1.11.11.m1.2.2.2.2.1.2.cmml" xref="algorithm1.11.11.m1.2.2.2.2.1.2">𝑡</ci><cn type="integer" id="algorithm1.11.11.m1.2.2.2.2.1.3.cmml" xref="algorithm1.11.11.m1.2.2.2.2.1.3">1</cn></apply><ci id="algorithm1.11.11.m1.1.1.1.1.cmml" xref="algorithm1.11.11.m1.1.1.1.1">𝑛</ci></list></apply><apply id="algorithm1.11.11.m1.3.4.3.cmml" xref="algorithm1.11.11.m1.3.4.3"><times id="algorithm1.11.11.m1.3.4.3.1.cmml" xref="algorithm1.11.11.m1.3.4.3.1"></times><ci id="algorithm1.11.11.m1.3.4.3.2a.cmml" xref="algorithm1.11.11.m1.3.4.3.2"><mtext class="ltx_mathvariant_monospace" id="algorithm1.11.11.m1.3.4.3.2.cmml" xref="algorithm1.11.11.m1.3.4.3.2">Client Update</mtext></ci><ci id="algorithm1.11.11.m1.3.3.cmml" xref="algorithm1.11.11.m1.3.3">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.11.11.m1.3c">w_{t+1,n}\leftarrow\textnormal{{Client Update}}(n)</annotation></semantics></math>;
</div>
<div id="algorithm1.12.12" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">9</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
<math id="algorithm1.12.12.m1.2" class="ltx_Math" alttext="W_{t}\leftarrow W_{t}\cup w_{t+1,n}" display="inline"><semantics id="algorithm1.12.12.m1.2a"><mrow id="algorithm1.12.12.m1.2.3" xref="algorithm1.12.12.m1.2.3.cmml"><msub id="algorithm1.12.12.m1.2.3.2" xref="algorithm1.12.12.m1.2.3.2.cmml"><mi id="algorithm1.12.12.m1.2.3.2.2" xref="algorithm1.12.12.m1.2.3.2.2.cmml">W</mi><mi id="algorithm1.12.12.m1.2.3.2.3" xref="algorithm1.12.12.m1.2.3.2.3.cmml">t</mi></msub><mo stretchy="false" id="algorithm1.12.12.m1.2.3.1" xref="algorithm1.12.12.m1.2.3.1.cmml">←</mo><mrow id="algorithm1.12.12.m1.2.3.3" xref="algorithm1.12.12.m1.2.3.3.cmml"><msub id="algorithm1.12.12.m1.2.3.3.2" xref="algorithm1.12.12.m1.2.3.3.2.cmml"><mi id="algorithm1.12.12.m1.2.3.3.2.2" xref="algorithm1.12.12.m1.2.3.3.2.2.cmml">W</mi><mi id="algorithm1.12.12.m1.2.3.3.2.3" xref="algorithm1.12.12.m1.2.3.3.2.3.cmml">t</mi></msub><mo id="algorithm1.12.12.m1.2.3.3.1" xref="algorithm1.12.12.m1.2.3.3.1.cmml">∪</mo><msub id="algorithm1.12.12.m1.2.3.3.3" xref="algorithm1.12.12.m1.2.3.3.3.cmml"><mi id="algorithm1.12.12.m1.2.3.3.3.2" xref="algorithm1.12.12.m1.2.3.3.3.2.cmml">w</mi><mrow id="algorithm1.12.12.m1.2.2.2.2" xref="algorithm1.12.12.m1.2.2.2.3.cmml"><mrow id="algorithm1.12.12.m1.2.2.2.2.1" xref="algorithm1.12.12.m1.2.2.2.2.1.cmml"><mi id="algorithm1.12.12.m1.2.2.2.2.1.2" xref="algorithm1.12.12.m1.2.2.2.2.1.2.cmml">t</mi><mo id="algorithm1.12.12.m1.2.2.2.2.1.1" xref="algorithm1.12.12.m1.2.2.2.2.1.1.cmml">+</mo><mn id="algorithm1.12.12.m1.2.2.2.2.1.3" xref="algorithm1.12.12.m1.2.2.2.2.1.3.cmml">1</mn></mrow><mo id="algorithm1.12.12.m1.2.2.2.2.2" xref="algorithm1.12.12.m1.2.2.2.3.cmml">,</mo><mi id="algorithm1.12.12.m1.1.1.1.1" xref="algorithm1.12.12.m1.1.1.1.1.cmml">n</mi></mrow></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.12.12.m1.2b"><apply id="algorithm1.12.12.m1.2.3.cmml" xref="algorithm1.12.12.m1.2.3"><ci id="algorithm1.12.12.m1.2.3.1.cmml" xref="algorithm1.12.12.m1.2.3.1">←</ci><apply id="algorithm1.12.12.m1.2.3.2.cmml" xref="algorithm1.12.12.m1.2.3.2"><csymbol cd="ambiguous" id="algorithm1.12.12.m1.2.3.2.1.cmml" xref="algorithm1.12.12.m1.2.3.2">subscript</csymbol><ci id="algorithm1.12.12.m1.2.3.2.2.cmml" xref="algorithm1.12.12.m1.2.3.2.2">𝑊</ci><ci id="algorithm1.12.12.m1.2.3.2.3.cmml" xref="algorithm1.12.12.m1.2.3.2.3">𝑡</ci></apply><apply id="algorithm1.12.12.m1.2.3.3.cmml" xref="algorithm1.12.12.m1.2.3.3"><union id="algorithm1.12.12.m1.2.3.3.1.cmml" xref="algorithm1.12.12.m1.2.3.3.1"></union><apply id="algorithm1.12.12.m1.2.3.3.2.cmml" xref="algorithm1.12.12.m1.2.3.3.2"><csymbol cd="ambiguous" id="algorithm1.12.12.m1.2.3.3.2.1.cmml" xref="algorithm1.12.12.m1.2.3.3.2">subscript</csymbol><ci id="algorithm1.12.12.m1.2.3.3.2.2.cmml" xref="algorithm1.12.12.m1.2.3.3.2.2">𝑊</ci><ci id="algorithm1.12.12.m1.2.3.3.2.3.cmml" xref="algorithm1.12.12.m1.2.3.3.2.3">𝑡</ci></apply><apply id="algorithm1.12.12.m1.2.3.3.3.cmml" xref="algorithm1.12.12.m1.2.3.3.3"><csymbol cd="ambiguous" id="algorithm1.12.12.m1.2.3.3.3.1.cmml" xref="algorithm1.12.12.m1.2.3.3.3">subscript</csymbol><ci id="algorithm1.12.12.m1.2.3.3.3.2.cmml" xref="algorithm1.12.12.m1.2.3.3.3.2">𝑤</ci><list id="algorithm1.12.12.m1.2.2.2.3.cmml" xref="algorithm1.12.12.m1.2.2.2.2"><apply id="algorithm1.12.12.m1.2.2.2.2.1.cmml" xref="algorithm1.12.12.m1.2.2.2.2.1"><plus id="algorithm1.12.12.m1.2.2.2.2.1.1.cmml" xref="algorithm1.12.12.m1.2.2.2.2.1.1"></plus><ci id="algorithm1.12.12.m1.2.2.2.2.1.2.cmml" xref="algorithm1.12.12.m1.2.2.2.2.1.2">𝑡</ci><cn type="integer" id="algorithm1.12.12.m1.2.2.2.2.1.3.cmml" xref="algorithm1.12.12.m1.2.2.2.2.1.3">1</cn></apply><ci id="algorithm1.12.12.m1.1.1.1.1.cmml" xref="algorithm1.12.12.m1.1.1.1.1">𝑛</ci></list></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.12.12.m1.2c">W_{t}\leftarrow W_{t}\cup w_{t+1,n}</annotation></semantics></math>;
</div>
<div id="algorithm1.39.43" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">10</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   

</div>
<div id="algorithm1.13.13" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">11</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   <math id="algorithm1.13.13.m1.1" class="ltx_Math" alttext="M\leftarrow c\times N" display="inline"><semantics id="algorithm1.13.13.m1.1a"><mrow id="algorithm1.13.13.m1.1.1" xref="algorithm1.13.13.m1.1.1.cmml"><mi id="algorithm1.13.13.m1.1.1.2" xref="algorithm1.13.13.m1.1.1.2.cmml">M</mi><mo stretchy="false" id="algorithm1.13.13.m1.1.1.1" xref="algorithm1.13.13.m1.1.1.1.cmml">←</mo><mrow id="algorithm1.13.13.m1.1.1.3" xref="algorithm1.13.13.m1.1.1.3.cmml"><mi id="algorithm1.13.13.m1.1.1.3.2" xref="algorithm1.13.13.m1.1.1.3.2.cmml">c</mi><mo lspace="0.222em" rspace="0.222em" id="algorithm1.13.13.m1.1.1.3.1" xref="algorithm1.13.13.m1.1.1.3.1.cmml">×</mo><mi id="algorithm1.13.13.m1.1.1.3.3" xref="algorithm1.13.13.m1.1.1.3.3.cmml">N</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.13.13.m1.1b"><apply id="algorithm1.13.13.m1.1.1.cmml" xref="algorithm1.13.13.m1.1.1"><ci id="algorithm1.13.13.m1.1.1.1.cmml" xref="algorithm1.13.13.m1.1.1.1">←</ci><ci id="algorithm1.13.13.m1.1.1.2.cmml" xref="algorithm1.13.13.m1.1.1.2">𝑀</ci><apply id="algorithm1.13.13.m1.1.1.3.cmml" xref="algorithm1.13.13.m1.1.1.3"><times id="algorithm1.13.13.m1.1.1.3.1.cmml" xref="algorithm1.13.13.m1.1.1.3.1"></times><ci id="algorithm1.13.13.m1.1.1.3.2.cmml" xref="algorithm1.13.13.m1.1.1.3.2">𝑐</ci><ci id="algorithm1.13.13.m1.1.1.3.3.cmml" xref="algorithm1.13.13.m1.1.1.3.3">𝑁</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.13.13.m1.1c">M\leftarrow c\times N</annotation></semantics></math>;
</div>
<div id="algorithm1.14.14" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">12</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
<math id="algorithm1.14.14.m1.2" class="ltx_Math" alttext="W_{t}^{\prime}\leftarrow\textnormal{{Client Selection}}(W_{t},M)" display="inline"><semantics id="algorithm1.14.14.m1.2a"><mrow id="algorithm1.14.14.m1.2.2" xref="algorithm1.14.14.m1.2.2.cmml"><msubsup id="algorithm1.14.14.m1.2.2.3" xref="algorithm1.14.14.m1.2.2.3.cmml"><mi id="algorithm1.14.14.m1.2.2.3.2.2" xref="algorithm1.14.14.m1.2.2.3.2.2.cmml">W</mi><mi id="algorithm1.14.14.m1.2.2.3.2.3" xref="algorithm1.14.14.m1.2.2.3.2.3.cmml">t</mi><mo id="algorithm1.14.14.m1.2.2.3.3" xref="algorithm1.14.14.m1.2.2.3.3.cmml">′</mo></msubsup><mo stretchy="false" id="algorithm1.14.14.m1.2.2.2" xref="algorithm1.14.14.m1.2.2.2.cmml">←</mo><mrow id="algorithm1.14.14.m1.2.2.1" xref="algorithm1.14.14.m1.2.2.1.cmml"><mtext class="ltx_mathvariant_monospace" id="algorithm1.14.14.m1.2.2.1.3" xref="algorithm1.14.14.m1.2.2.1.3a.cmml">Client Selection</mtext><mo lspace="0em" rspace="0em" id="algorithm1.14.14.m1.2.2.1.2" xref="algorithm1.14.14.m1.2.2.1.2.cmml">​</mo><mrow id="algorithm1.14.14.m1.2.2.1.1.1" xref="algorithm1.14.14.m1.2.2.1.1.2.cmml"><mo stretchy="false" id="algorithm1.14.14.m1.2.2.1.1.1.2" xref="algorithm1.14.14.m1.2.2.1.1.2.cmml">(</mo><msub id="algorithm1.14.14.m1.2.2.1.1.1.1" xref="algorithm1.14.14.m1.2.2.1.1.1.1.cmml"><mi id="algorithm1.14.14.m1.2.2.1.1.1.1.2" xref="algorithm1.14.14.m1.2.2.1.1.1.1.2.cmml">W</mi><mi id="algorithm1.14.14.m1.2.2.1.1.1.1.3" xref="algorithm1.14.14.m1.2.2.1.1.1.1.3.cmml">t</mi></msub><mo id="algorithm1.14.14.m1.2.2.1.1.1.3" xref="algorithm1.14.14.m1.2.2.1.1.2.cmml">,</mo><mi id="algorithm1.14.14.m1.1.1" xref="algorithm1.14.14.m1.1.1.cmml">M</mi><mo stretchy="false" id="algorithm1.14.14.m1.2.2.1.1.1.4" xref="algorithm1.14.14.m1.2.2.1.1.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.14.14.m1.2b"><apply id="algorithm1.14.14.m1.2.2.cmml" xref="algorithm1.14.14.m1.2.2"><ci id="algorithm1.14.14.m1.2.2.2.cmml" xref="algorithm1.14.14.m1.2.2.2">←</ci><apply id="algorithm1.14.14.m1.2.2.3.cmml" xref="algorithm1.14.14.m1.2.2.3"><csymbol cd="ambiguous" id="algorithm1.14.14.m1.2.2.3.1.cmml" xref="algorithm1.14.14.m1.2.2.3">superscript</csymbol><apply id="algorithm1.14.14.m1.2.2.3.2.cmml" xref="algorithm1.14.14.m1.2.2.3"><csymbol cd="ambiguous" id="algorithm1.14.14.m1.2.2.3.2.1.cmml" xref="algorithm1.14.14.m1.2.2.3">subscript</csymbol><ci id="algorithm1.14.14.m1.2.2.3.2.2.cmml" xref="algorithm1.14.14.m1.2.2.3.2.2">𝑊</ci><ci id="algorithm1.14.14.m1.2.2.3.2.3.cmml" xref="algorithm1.14.14.m1.2.2.3.2.3">𝑡</ci></apply><ci id="algorithm1.14.14.m1.2.2.3.3.cmml" xref="algorithm1.14.14.m1.2.2.3.3">′</ci></apply><apply id="algorithm1.14.14.m1.2.2.1.cmml" xref="algorithm1.14.14.m1.2.2.1"><times id="algorithm1.14.14.m1.2.2.1.2.cmml" xref="algorithm1.14.14.m1.2.2.1.2"></times><ci id="algorithm1.14.14.m1.2.2.1.3a.cmml" xref="algorithm1.14.14.m1.2.2.1.3"><mtext class="ltx_mathvariant_monospace" id="algorithm1.14.14.m1.2.2.1.3.cmml" xref="algorithm1.14.14.m1.2.2.1.3">Client Selection</mtext></ci><interval closure="open" id="algorithm1.14.14.m1.2.2.1.1.2.cmml" xref="algorithm1.14.14.m1.2.2.1.1.1"><apply id="algorithm1.14.14.m1.2.2.1.1.1.1.cmml" xref="algorithm1.14.14.m1.2.2.1.1.1.1"><csymbol cd="ambiguous" id="algorithm1.14.14.m1.2.2.1.1.1.1.1.cmml" xref="algorithm1.14.14.m1.2.2.1.1.1.1">subscript</csymbol><ci id="algorithm1.14.14.m1.2.2.1.1.1.1.2.cmml" xref="algorithm1.14.14.m1.2.2.1.1.1.1.2">𝑊</ci><ci id="algorithm1.14.14.m1.2.2.1.1.1.1.3.cmml" xref="algorithm1.14.14.m1.2.2.1.1.1.1.3">𝑡</ci></apply><ci id="algorithm1.14.14.m1.1.1.cmml" xref="algorithm1.14.14.m1.1.1">𝑀</ci></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.14.14.m1.2c">W_{t}^{\prime}\leftarrow\textnormal{{Client Selection}}(W_{t},M)</annotation></semantics></math>;
</div>
<div id="algorithm1.15.15" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">13</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
<math id="algorithm1.15.15.m1.1" class="ltx_Math" alttext="w^{g}_{t+1}\leftarrow\textnormal{{Model Aggregate}}(W_{t}^{\prime})" display="inline"><semantics id="algorithm1.15.15.m1.1a"><mrow id="algorithm1.15.15.m1.1.1" xref="algorithm1.15.15.m1.1.1.cmml"><msubsup id="algorithm1.15.15.m1.1.1.3" xref="algorithm1.15.15.m1.1.1.3.cmml"><mi id="algorithm1.15.15.m1.1.1.3.2.2" xref="algorithm1.15.15.m1.1.1.3.2.2.cmml">w</mi><mrow id="algorithm1.15.15.m1.1.1.3.3" xref="algorithm1.15.15.m1.1.1.3.3.cmml"><mi id="algorithm1.15.15.m1.1.1.3.3.2" xref="algorithm1.15.15.m1.1.1.3.3.2.cmml">t</mi><mo id="algorithm1.15.15.m1.1.1.3.3.1" xref="algorithm1.15.15.m1.1.1.3.3.1.cmml">+</mo><mn id="algorithm1.15.15.m1.1.1.3.3.3" xref="algorithm1.15.15.m1.1.1.3.3.3.cmml">1</mn></mrow><mi id="algorithm1.15.15.m1.1.1.3.2.3" xref="algorithm1.15.15.m1.1.1.3.2.3.cmml">g</mi></msubsup><mo stretchy="false" id="algorithm1.15.15.m1.1.1.2" xref="algorithm1.15.15.m1.1.1.2.cmml">←</mo><mrow id="algorithm1.15.15.m1.1.1.1" xref="algorithm1.15.15.m1.1.1.1.cmml"><mtext class="ltx_mathvariant_monospace" id="algorithm1.15.15.m1.1.1.1.3" xref="algorithm1.15.15.m1.1.1.1.3a.cmml">Model Aggregate</mtext><mo lspace="0em" rspace="0em" id="algorithm1.15.15.m1.1.1.1.2" xref="algorithm1.15.15.m1.1.1.1.2.cmml">​</mo><mrow id="algorithm1.15.15.m1.1.1.1.1.1" xref="algorithm1.15.15.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="algorithm1.15.15.m1.1.1.1.1.1.2" xref="algorithm1.15.15.m1.1.1.1.1.1.1.cmml">(</mo><msubsup id="algorithm1.15.15.m1.1.1.1.1.1.1" xref="algorithm1.15.15.m1.1.1.1.1.1.1.cmml"><mi id="algorithm1.15.15.m1.1.1.1.1.1.1.2.2" xref="algorithm1.15.15.m1.1.1.1.1.1.1.2.2.cmml">W</mi><mi id="algorithm1.15.15.m1.1.1.1.1.1.1.2.3" xref="algorithm1.15.15.m1.1.1.1.1.1.1.2.3.cmml">t</mi><mo id="algorithm1.15.15.m1.1.1.1.1.1.1.3" xref="algorithm1.15.15.m1.1.1.1.1.1.1.3.cmml">′</mo></msubsup><mo stretchy="false" id="algorithm1.15.15.m1.1.1.1.1.1.3" xref="algorithm1.15.15.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.15.15.m1.1b"><apply id="algorithm1.15.15.m1.1.1.cmml" xref="algorithm1.15.15.m1.1.1"><ci id="algorithm1.15.15.m1.1.1.2.cmml" xref="algorithm1.15.15.m1.1.1.2">←</ci><apply id="algorithm1.15.15.m1.1.1.3.cmml" xref="algorithm1.15.15.m1.1.1.3"><csymbol cd="ambiguous" id="algorithm1.15.15.m1.1.1.3.1.cmml" xref="algorithm1.15.15.m1.1.1.3">subscript</csymbol><apply id="algorithm1.15.15.m1.1.1.3.2.cmml" xref="algorithm1.15.15.m1.1.1.3"><csymbol cd="ambiguous" id="algorithm1.15.15.m1.1.1.3.2.1.cmml" xref="algorithm1.15.15.m1.1.1.3">superscript</csymbol><ci id="algorithm1.15.15.m1.1.1.3.2.2.cmml" xref="algorithm1.15.15.m1.1.1.3.2.2">𝑤</ci><ci id="algorithm1.15.15.m1.1.1.3.2.3.cmml" xref="algorithm1.15.15.m1.1.1.3.2.3">𝑔</ci></apply><apply id="algorithm1.15.15.m1.1.1.3.3.cmml" xref="algorithm1.15.15.m1.1.1.3.3"><plus id="algorithm1.15.15.m1.1.1.3.3.1.cmml" xref="algorithm1.15.15.m1.1.1.3.3.1"></plus><ci id="algorithm1.15.15.m1.1.1.3.3.2.cmml" xref="algorithm1.15.15.m1.1.1.3.3.2">𝑡</ci><cn type="integer" id="algorithm1.15.15.m1.1.1.3.3.3.cmml" xref="algorithm1.15.15.m1.1.1.3.3.3">1</cn></apply></apply><apply id="algorithm1.15.15.m1.1.1.1.cmml" xref="algorithm1.15.15.m1.1.1.1"><times id="algorithm1.15.15.m1.1.1.1.2.cmml" xref="algorithm1.15.15.m1.1.1.1.2"></times><ci id="algorithm1.15.15.m1.1.1.1.3a.cmml" xref="algorithm1.15.15.m1.1.1.1.3"><mtext class="ltx_mathvariant_monospace" id="algorithm1.15.15.m1.1.1.1.3.cmml" xref="algorithm1.15.15.m1.1.1.1.3">Model Aggregate</mtext></ci><apply id="algorithm1.15.15.m1.1.1.1.1.1.1.cmml" xref="algorithm1.15.15.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="algorithm1.15.15.m1.1.1.1.1.1.1.1.cmml" xref="algorithm1.15.15.m1.1.1.1.1.1">superscript</csymbol><apply id="algorithm1.15.15.m1.1.1.1.1.1.1.2.cmml" xref="algorithm1.15.15.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="algorithm1.15.15.m1.1.1.1.1.1.1.2.1.cmml" xref="algorithm1.15.15.m1.1.1.1.1.1">subscript</csymbol><ci id="algorithm1.15.15.m1.1.1.1.1.1.1.2.2.cmml" xref="algorithm1.15.15.m1.1.1.1.1.1.1.2.2">𝑊</ci><ci id="algorithm1.15.15.m1.1.1.1.1.1.1.2.3.cmml" xref="algorithm1.15.15.m1.1.1.1.1.1.1.2.3">𝑡</ci></apply><ci id="algorithm1.15.15.m1.1.1.1.1.1.1.3.cmml" xref="algorithm1.15.15.m1.1.1.1.1.1.1.3">′</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.15.15.m1.1c">w^{g}_{t+1}\leftarrow\textnormal{{Model Aggregate}}(W_{t}^{\prime})</annotation></semantics></math>

</div>
<div id="algorithm1.16.16" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">14</span><em id="algorithm1.16.16.1" class="ltx_emph ltx_font_typewriter">Client Update(<em id="algorithm1.16.16.1.1.1" class="ltx_emph ltx_font_serif ltx_font_italic"><math id="algorithm1.16.16.1.1.1.m1.1" class="ltx_Math" alttext="n" display="inline"><semantics id="algorithm1.16.16.1.1.1.m1.1a"><mi id="algorithm1.16.16.1.1.1.m1.1.1" xref="algorithm1.16.16.1.1.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="algorithm1.16.16.1.1.1.m1.1b"><ci id="algorithm1.16.16.1.1.1.m1.1.1.cmml" xref="algorithm1.16.16.1.1.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.16.16.1.1.1.m1.1c">n</annotation></semantics></math></em>)</em><span id="algorithm1.16.16.2" class="ltx_text ltx_font_bold">:</span>
</div>
<div id="algorithm1.18.18" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">15</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
<math id="algorithm1.17.17.m1.1" class="ltx_Math" alttext="w_{n}\leftarrow w_{t}^{g}" display="inline"><semantics id="algorithm1.17.17.m1.1a"><mrow id="algorithm1.17.17.m1.1.1" xref="algorithm1.17.17.m1.1.1.cmml"><msub id="algorithm1.17.17.m1.1.1.2" xref="algorithm1.17.17.m1.1.1.2.cmml"><mi id="algorithm1.17.17.m1.1.1.2.2" xref="algorithm1.17.17.m1.1.1.2.2.cmml">w</mi><mi id="algorithm1.17.17.m1.1.1.2.3" xref="algorithm1.17.17.m1.1.1.2.3.cmml">n</mi></msub><mo stretchy="false" id="algorithm1.17.17.m1.1.1.1" xref="algorithm1.17.17.m1.1.1.1.cmml">←</mo><msubsup id="algorithm1.17.17.m1.1.1.3" xref="algorithm1.17.17.m1.1.1.3.cmml"><mi id="algorithm1.17.17.m1.1.1.3.2.2" xref="algorithm1.17.17.m1.1.1.3.2.2.cmml">w</mi><mi id="algorithm1.17.17.m1.1.1.3.2.3" xref="algorithm1.17.17.m1.1.1.3.2.3.cmml">t</mi><mi id="algorithm1.17.17.m1.1.1.3.3" xref="algorithm1.17.17.m1.1.1.3.3.cmml">g</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.17.17.m1.1b"><apply id="algorithm1.17.17.m1.1.1.cmml" xref="algorithm1.17.17.m1.1.1"><ci id="algorithm1.17.17.m1.1.1.1.cmml" xref="algorithm1.17.17.m1.1.1.1">←</ci><apply id="algorithm1.17.17.m1.1.1.2.cmml" xref="algorithm1.17.17.m1.1.1.2"><csymbol cd="ambiguous" id="algorithm1.17.17.m1.1.1.2.1.cmml" xref="algorithm1.17.17.m1.1.1.2">subscript</csymbol><ci id="algorithm1.17.17.m1.1.1.2.2.cmml" xref="algorithm1.17.17.m1.1.1.2.2">𝑤</ci><ci id="algorithm1.17.17.m1.1.1.2.3.cmml" xref="algorithm1.17.17.m1.1.1.2.3">𝑛</ci></apply><apply id="algorithm1.17.17.m1.1.1.3.cmml" xref="algorithm1.17.17.m1.1.1.3"><csymbol cd="ambiguous" id="algorithm1.17.17.m1.1.1.3.1.cmml" xref="algorithm1.17.17.m1.1.1.3">superscript</csymbol><apply id="algorithm1.17.17.m1.1.1.3.2.cmml" xref="algorithm1.17.17.m1.1.1.3"><csymbol cd="ambiguous" id="algorithm1.17.17.m1.1.1.3.2.1.cmml" xref="algorithm1.17.17.m1.1.1.3">subscript</csymbol><ci id="algorithm1.17.17.m1.1.1.3.2.2.cmml" xref="algorithm1.17.17.m1.1.1.3.2.2">𝑤</ci><ci id="algorithm1.17.17.m1.1.1.3.2.3.cmml" xref="algorithm1.17.17.m1.1.1.3.2.3">𝑡</ci></apply><ci id="algorithm1.17.17.m1.1.1.3.3.cmml" xref="algorithm1.17.17.m1.1.1.3.3">𝑔</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.17.17.m1.1c">w_{n}\leftarrow w_{t}^{g}</annotation></semantics></math> (<math id="algorithm1.18.18.m2.1" class="ltx_Math" alttext="w_{t}^{g}" display="inline"><semantics id="algorithm1.18.18.m2.1a"><msubsup id="algorithm1.18.18.m2.1.1" xref="algorithm1.18.18.m2.1.1.cmml"><mi id="algorithm1.18.18.m2.1.1.2.2" xref="algorithm1.18.18.m2.1.1.2.2.cmml">w</mi><mi id="algorithm1.18.18.m2.1.1.2.3" xref="algorithm1.18.18.m2.1.1.2.3.cmml">t</mi><mi id="algorithm1.18.18.m2.1.1.3" xref="algorithm1.18.18.m2.1.1.3.cmml">g</mi></msubsup><annotation-xml encoding="MathML-Content" id="algorithm1.18.18.m2.1b"><apply id="algorithm1.18.18.m2.1.1.cmml" xref="algorithm1.18.18.m2.1.1"><csymbol cd="ambiguous" id="algorithm1.18.18.m2.1.1.1.cmml" xref="algorithm1.18.18.m2.1.1">superscript</csymbol><apply id="algorithm1.18.18.m2.1.1.2.cmml" xref="algorithm1.18.18.m2.1.1"><csymbol cd="ambiguous" id="algorithm1.18.18.m2.1.1.2.1.cmml" xref="algorithm1.18.18.m2.1.1">subscript</csymbol><ci id="algorithm1.18.18.m2.1.1.2.2.cmml" xref="algorithm1.18.18.m2.1.1.2.2">𝑤</ci><ci id="algorithm1.18.18.m2.1.1.2.3.cmml" xref="algorithm1.18.18.m2.1.1.2.3">𝑡</ci></apply><ci id="algorithm1.18.18.m2.1.1.3.cmml" xref="algorithm1.18.18.m2.1.1.3">𝑔</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.18.18.m2.1c">w_{t}^{g}</annotation></semantics></math> is downloaded global model) ;
</div>
<div id="algorithm1.19.19" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">16</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
<span id="algorithm1.19.19.2" class="ltx_text ltx_font_bold">if</span> <em id="algorithm1.19.19.1" class="ltx_emph ltx_font_italic"><math id="algorithm1.19.19.1.m1.1" class="ltx_Math" alttext="\mathcal{R}_{n}=\varnothing" display="inline"><semantics id="algorithm1.19.19.1.m1.1a"><mrow id="algorithm1.19.19.1.m1.1.1" xref="algorithm1.19.19.1.m1.1.1.cmml"><msub id="algorithm1.19.19.1.m1.1.1.2" xref="algorithm1.19.19.1.m1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="algorithm1.19.19.1.m1.1.1.2.2" xref="algorithm1.19.19.1.m1.1.1.2.2.cmml">ℛ</mi><mi id="algorithm1.19.19.1.m1.1.1.2.3" xref="algorithm1.19.19.1.m1.1.1.2.3.cmml">n</mi></msub><mo id="algorithm1.19.19.1.m1.1.1.1" xref="algorithm1.19.19.1.m1.1.1.1.cmml">=</mo><mi mathvariant="normal" id="algorithm1.19.19.1.m1.1.1.3" xref="algorithm1.19.19.1.m1.1.1.3.cmml">∅</mi></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.19.19.1.m1.1b"><apply id="algorithm1.19.19.1.m1.1.1.cmml" xref="algorithm1.19.19.1.m1.1.1"><eq id="algorithm1.19.19.1.m1.1.1.1.cmml" xref="algorithm1.19.19.1.m1.1.1.1"></eq><apply id="algorithm1.19.19.1.m1.1.1.2.cmml" xref="algorithm1.19.19.1.m1.1.1.2"><csymbol cd="ambiguous" id="algorithm1.19.19.1.m1.1.1.2.1.cmml" xref="algorithm1.19.19.1.m1.1.1.2">subscript</csymbol><ci id="algorithm1.19.19.1.m1.1.1.2.2.cmml" xref="algorithm1.19.19.1.m1.1.1.2.2">ℛ</ci><ci id="algorithm1.19.19.1.m1.1.1.2.3.cmml" xref="algorithm1.19.19.1.m1.1.1.2.3">𝑛</ci></apply><emptyset id="algorithm1.19.19.1.m1.1.1.3.cmml" xref="algorithm1.19.19.1.m1.1.1.3"></emptyset></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.19.19.1.m1.1c">\mathcal{R}_{n}=\varnothing</annotation></semantics></math></em> <span id="algorithm1.19.19.3" class="ltx_text ltx_font_bold">then</span>
</div>
<div id="algorithm1.21.21" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">17</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
<math id="algorithm1.20.20.m1.1" class="ltx_Math" alttext="\mathcal{R}_{n}\leftarrow" display="inline"><semantics id="algorithm1.20.20.m1.1a"><mrow id="algorithm1.20.20.m1.1.1" xref="algorithm1.20.20.m1.1.1.cmml"><msub id="algorithm1.20.20.m1.1.1.2" xref="algorithm1.20.20.m1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="algorithm1.20.20.m1.1.1.2.2" xref="algorithm1.20.20.m1.1.1.2.2.cmml">ℛ</mi><mi id="algorithm1.20.20.m1.1.1.2.3" xref="algorithm1.20.20.m1.1.1.2.3.cmml">n</mi></msub><mo stretchy="false" id="algorithm1.20.20.m1.1.1.1" xref="algorithm1.20.20.m1.1.1.1.cmml">←</mo><mi id="algorithm1.20.20.m1.1.1.3" xref="algorithm1.20.20.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.20.20.m1.1b"><apply id="algorithm1.20.20.m1.1.1.cmml" xref="algorithm1.20.20.m1.1.1"><ci id="algorithm1.20.20.m1.1.1.1.cmml" xref="algorithm1.20.20.m1.1.1.1">←</ci><apply id="algorithm1.20.20.m1.1.1.2.cmml" xref="algorithm1.20.20.m1.1.1.2"><csymbol cd="ambiguous" id="algorithm1.20.20.m1.1.1.2.1.cmml" xref="algorithm1.20.20.m1.1.1.2">subscript</csymbol><ci id="algorithm1.20.20.m1.1.1.2.2.cmml" xref="algorithm1.20.20.m1.1.1.2.2">ℛ</ci><ci id="algorithm1.20.20.m1.1.1.2.3.cmml" xref="algorithm1.20.20.m1.1.1.2.3">𝑛</ci></apply><csymbol cd="latexml" id="algorithm1.20.20.m1.1.1.3.cmml" xref="algorithm1.20.20.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.20.20.m1.1c">\mathcal{R}_{n}\leftarrow</annotation></semantics></math> <span id="algorithm1.21.21.1" class="ltx_text ltx_font_typewriter">Radar Imputation</span> (<math id="algorithm1.21.21.m2.1" class="ltx_Math" alttext="\mathcal{L}_{n}" display="inline"><semantics id="algorithm1.21.21.m2.1a"><msub id="algorithm1.21.21.m2.1.1" xref="algorithm1.21.21.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="algorithm1.21.21.m2.1.1.2" xref="algorithm1.21.21.m2.1.1.2.cmml">ℒ</mi><mi id="algorithm1.21.21.m2.1.1.3" xref="algorithm1.21.21.m2.1.1.3.cmml">n</mi></msub><annotation-xml encoding="MathML-Content" id="algorithm1.21.21.m2.1b"><apply id="algorithm1.21.21.m2.1.1.cmml" xref="algorithm1.21.21.m2.1.1"><csymbol cd="ambiguous" id="algorithm1.21.21.m2.1.1.1.cmml" xref="algorithm1.21.21.m2.1.1">subscript</csymbol><ci id="algorithm1.21.21.m2.1.1.2.cmml" xref="algorithm1.21.21.m2.1.1.2">ℒ</ci><ci id="algorithm1.21.21.m2.1.1.3.cmml" xref="algorithm1.21.21.m2.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.21.21.m2.1c">\mathcal{L}_{n}</annotation></semantics></math>);
</div>
<div id="algorithm1.39.44" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">18</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   

</div>
<div id="algorithm1.22.22" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">19</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
<span id="algorithm1.22.22.2" class="ltx_text ltx_font_bold">else if</span> <em id="algorithm1.22.22.1" class="ltx_emph ltx_font_italic"><math id="algorithm1.22.22.1.m1.1" class="ltx_Math" alttext="\mathcal{L}_{n}=\varnothing" display="inline"><semantics id="algorithm1.22.22.1.m1.1a"><mrow id="algorithm1.22.22.1.m1.1.1" xref="algorithm1.22.22.1.m1.1.1.cmml"><msub id="algorithm1.22.22.1.m1.1.1.2" xref="algorithm1.22.22.1.m1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="algorithm1.22.22.1.m1.1.1.2.2" xref="algorithm1.22.22.1.m1.1.1.2.2.cmml">ℒ</mi><mi id="algorithm1.22.22.1.m1.1.1.2.3" xref="algorithm1.22.22.1.m1.1.1.2.3.cmml">n</mi></msub><mo id="algorithm1.22.22.1.m1.1.1.1" xref="algorithm1.22.22.1.m1.1.1.1.cmml">=</mo><mi mathvariant="normal" id="algorithm1.22.22.1.m1.1.1.3" xref="algorithm1.22.22.1.m1.1.1.3.cmml">∅</mi></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.22.22.1.m1.1b"><apply id="algorithm1.22.22.1.m1.1.1.cmml" xref="algorithm1.22.22.1.m1.1.1"><eq id="algorithm1.22.22.1.m1.1.1.1.cmml" xref="algorithm1.22.22.1.m1.1.1.1"></eq><apply id="algorithm1.22.22.1.m1.1.1.2.cmml" xref="algorithm1.22.22.1.m1.1.1.2"><csymbol cd="ambiguous" id="algorithm1.22.22.1.m1.1.1.2.1.cmml" xref="algorithm1.22.22.1.m1.1.1.2">subscript</csymbol><ci id="algorithm1.22.22.1.m1.1.1.2.2.cmml" xref="algorithm1.22.22.1.m1.1.1.2.2">ℒ</ci><ci id="algorithm1.22.22.1.m1.1.1.2.3.cmml" xref="algorithm1.22.22.1.m1.1.1.2.3">𝑛</ci></apply><emptyset id="algorithm1.22.22.1.m1.1.1.3.cmml" xref="algorithm1.22.22.1.m1.1.1.3"></emptyset></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.22.22.1.m1.1c">\mathcal{L}_{n}=\varnothing</annotation></semantics></math></em> <span id="algorithm1.22.22.3" class="ltx_text ltx_font_bold">then</span>
</div>
<div id="algorithm1.24.24" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">20</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
<math id="algorithm1.23.23.m1.1" class="ltx_Math" alttext="\mathcal{L}_{n}\leftarrow" display="inline"><semantics id="algorithm1.23.23.m1.1a"><mrow id="algorithm1.23.23.m1.1.1" xref="algorithm1.23.23.m1.1.1.cmml"><msub id="algorithm1.23.23.m1.1.1.2" xref="algorithm1.23.23.m1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="algorithm1.23.23.m1.1.1.2.2" xref="algorithm1.23.23.m1.1.1.2.2.cmml">ℒ</mi><mi id="algorithm1.23.23.m1.1.1.2.3" xref="algorithm1.23.23.m1.1.1.2.3.cmml">n</mi></msub><mo stretchy="false" id="algorithm1.23.23.m1.1.1.1" xref="algorithm1.23.23.m1.1.1.1.cmml">←</mo><mi id="algorithm1.23.23.m1.1.1.3" xref="algorithm1.23.23.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.23.23.m1.1b"><apply id="algorithm1.23.23.m1.1.1.cmml" xref="algorithm1.23.23.m1.1.1"><ci id="algorithm1.23.23.m1.1.1.1.cmml" xref="algorithm1.23.23.m1.1.1.1">←</ci><apply id="algorithm1.23.23.m1.1.1.2.cmml" xref="algorithm1.23.23.m1.1.1.2"><csymbol cd="ambiguous" id="algorithm1.23.23.m1.1.1.2.1.cmml" xref="algorithm1.23.23.m1.1.1.2">subscript</csymbol><ci id="algorithm1.23.23.m1.1.1.2.2.cmml" xref="algorithm1.23.23.m1.1.1.2.2">ℒ</ci><ci id="algorithm1.23.23.m1.1.1.2.3.cmml" xref="algorithm1.23.23.m1.1.1.2.3">𝑛</ci></apply><csymbol cd="latexml" id="algorithm1.23.23.m1.1.1.3.cmml" xref="algorithm1.23.23.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.23.23.m1.1c">\mathcal{L}_{n}\leftarrow</annotation></semantics></math> <span id="algorithm1.24.24.1" class="ltx_text ltx_font_typewriter">Lidar Imputation</span> (<math id="algorithm1.24.24.m2.1" class="ltx_Math" alttext="\mathcal{R}_{n}" display="inline"><semantics id="algorithm1.24.24.m2.1a"><msub id="algorithm1.24.24.m2.1.1" xref="algorithm1.24.24.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="algorithm1.24.24.m2.1.1.2" xref="algorithm1.24.24.m2.1.1.2.cmml">ℛ</mi><mi id="algorithm1.24.24.m2.1.1.3" xref="algorithm1.24.24.m2.1.1.3.cmml">n</mi></msub><annotation-xml encoding="MathML-Content" id="algorithm1.24.24.m2.1b"><apply id="algorithm1.24.24.m2.1.1.cmml" xref="algorithm1.24.24.m2.1.1"><csymbol cd="ambiguous" id="algorithm1.24.24.m2.1.1.1.cmml" xref="algorithm1.24.24.m2.1.1">subscript</csymbol><ci id="algorithm1.24.24.m2.1.1.2.cmml" xref="algorithm1.24.24.m2.1.1.2">ℛ</ci><ci id="algorithm1.24.24.m2.1.1.3.cmml" xref="algorithm1.24.24.m2.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.24.24.m2.1c">\mathcal{R}_{n}</annotation></semantics></math>);
</div>
<div id="algorithm1.39.45" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">21</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   

</div>
<div id="algorithm1.25.25" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">22</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
<span id="algorithm1.25.25.2" class="ltx_text ltx_font_bold">for</span> <em id="algorithm1.25.25.1" class="ltx_emph ltx_font_italic">each local epoch <math id="algorithm1.25.25.1.m1.1" class="ltx_Math" alttext="e" display="inline"><semantics id="algorithm1.25.25.1.m1.1a"><mi id="algorithm1.25.25.1.m1.1.1" xref="algorithm1.25.25.1.m1.1.1.cmml">e</mi><annotation-xml encoding="MathML-Content" id="algorithm1.25.25.1.m1.1b"><ci id="algorithm1.25.25.1.m1.1.1.cmml" xref="algorithm1.25.25.1.m1.1.1">𝑒</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.25.25.1.m1.1c">e</annotation></semantics></math></em> <span id="algorithm1.25.25.3" class="ltx_text ltx_font_bold">do</span>
</div>
<div id="algorithm1.26.26" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">23</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
<span id="algorithm1.26.26.2" class="ltx_text ltx_font_bold">for</span> <em id="algorithm1.26.26.1" class="ltx_emph ltx_font_italic">each batch <math id="algorithm1.26.26.1.m1.1" class="ltx_Math" alttext="b" display="inline"><semantics id="algorithm1.26.26.1.m1.1a"><mi id="algorithm1.26.26.1.m1.1.1" xref="algorithm1.26.26.1.m1.1.1.cmml">b</mi><annotation-xml encoding="MathML-Content" id="algorithm1.26.26.1.m1.1b"><ci id="algorithm1.26.26.1.m1.1.1.cmml" xref="algorithm1.26.26.1.m1.1.1">𝑏</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.26.26.1.m1.1c">b</annotation></semantics></math></em> <span id="algorithm1.26.26.3" class="ltx_text ltx_font_bold">do</span>
</div>
<div id="algorithm1.28.28" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">24</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
<math id="algorithm1.27.27.m1.1" class="ltx_Math" alttext="w_{n}\leftarrow" display="inline"><semantics id="algorithm1.27.27.m1.1a"><mrow id="algorithm1.27.27.m1.1.1" xref="algorithm1.27.27.m1.1.1.cmml"><msub id="algorithm1.27.27.m1.1.1.2" xref="algorithm1.27.27.m1.1.1.2.cmml"><mi id="algorithm1.27.27.m1.1.1.2.2" xref="algorithm1.27.27.m1.1.1.2.2.cmml">w</mi><mi id="algorithm1.27.27.m1.1.1.2.3" xref="algorithm1.27.27.m1.1.1.2.3.cmml">n</mi></msub><mo stretchy="false" id="algorithm1.27.27.m1.1.1.1" xref="algorithm1.27.27.m1.1.1.1.cmml">←</mo><mi id="algorithm1.27.27.m1.1.1.3" xref="algorithm1.27.27.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.27.27.m1.1b"><apply id="algorithm1.27.27.m1.1.1.cmml" xref="algorithm1.27.27.m1.1.1"><ci id="algorithm1.27.27.m1.1.1.1.cmml" xref="algorithm1.27.27.m1.1.1.1">←</ci><apply id="algorithm1.27.27.m1.1.1.2.cmml" xref="algorithm1.27.27.m1.1.1.2"><csymbol cd="ambiguous" id="algorithm1.27.27.m1.1.1.2.1.cmml" xref="algorithm1.27.27.m1.1.1.2">subscript</csymbol><ci id="algorithm1.27.27.m1.1.1.2.2.cmml" xref="algorithm1.27.27.m1.1.1.2.2">𝑤</ci><ci id="algorithm1.27.27.m1.1.1.2.3.cmml" xref="algorithm1.27.27.m1.1.1.2.3">𝑛</ci></apply><csymbol cd="latexml" id="algorithm1.27.27.m1.1.1.3.cmml" xref="algorithm1.27.27.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.27.27.m1.1c">w_{n}\leftarrow</annotation></semantics></math> <span id="algorithm1.28.28.1" class="ltx_text ltx_font_typewriter">SGD</span>(<math id="algorithm1.28.28.m2.2" class="ltx_Math" alttext="w_{n},b" display="inline"><semantics id="algorithm1.28.28.m2.2a"><mrow id="algorithm1.28.28.m2.2.2.1" xref="algorithm1.28.28.m2.2.2.2.cmml"><msub id="algorithm1.28.28.m2.2.2.1.1" xref="algorithm1.28.28.m2.2.2.1.1.cmml"><mi id="algorithm1.28.28.m2.2.2.1.1.2" xref="algorithm1.28.28.m2.2.2.1.1.2.cmml">w</mi><mi id="algorithm1.28.28.m2.2.2.1.1.3" xref="algorithm1.28.28.m2.2.2.1.1.3.cmml">n</mi></msub><mo id="algorithm1.28.28.m2.2.2.1.2" xref="algorithm1.28.28.m2.2.2.2.cmml">,</mo><mi id="algorithm1.28.28.m2.1.1" xref="algorithm1.28.28.m2.1.1.cmml">b</mi></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.28.28.m2.2b"><list id="algorithm1.28.28.m2.2.2.2.cmml" xref="algorithm1.28.28.m2.2.2.1"><apply id="algorithm1.28.28.m2.2.2.1.1.cmml" xref="algorithm1.28.28.m2.2.2.1.1"><csymbol cd="ambiguous" id="algorithm1.28.28.m2.2.2.1.1.1.cmml" xref="algorithm1.28.28.m2.2.2.1.1">subscript</csymbol><ci id="algorithm1.28.28.m2.2.2.1.1.2.cmml" xref="algorithm1.28.28.m2.2.2.1.1.2">𝑤</ci><ci id="algorithm1.28.28.m2.2.2.1.1.3.cmml" xref="algorithm1.28.28.m2.2.2.1.1.3">𝑛</ci></apply><ci id="algorithm1.28.28.m2.1.1.cmml" xref="algorithm1.28.28.m2.1.1">𝑏</ci></list></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.28.28.m2.2c">w_{n},b</annotation></semantics></math>) ;
</div>
<div id="algorithm1.39.46" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">25</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   

</div>
<div id="algorithm1.29.29" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">26</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   <span id="algorithm1.29.29.1" class="ltx_text ltx_font_bold">return</span> <math id="algorithm1.29.29.m1.1" class="ltx_Math" alttext="w_{n}" display="inline"><semantics id="algorithm1.29.29.m1.1a"><msub id="algorithm1.29.29.m1.1.1" xref="algorithm1.29.29.m1.1.1.cmml"><mi id="algorithm1.29.29.m1.1.1.2" xref="algorithm1.29.29.m1.1.1.2.cmml">w</mi><mi id="algorithm1.29.29.m1.1.1.3" xref="algorithm1.29.29.m1.1.1.3.cmml">n</mi></msub><annotation-xml encoding="MathML-Content" id="algorithm1.29.29.m1.1b"><apply id="algorithm1.29.29.m1.1.1.cmml" xref="algorithm1.29.29.m1.1.1"><csymbol cd="ambiguous" id="algorithm1.29.29.m1.1.1.1.cmml" xref="algorithm1.29.29.m1.1.1">subscript</csymbol><ci id="algorithm1.29.29.m1.1.1.2.cmml" xref="algorithm1.29.29.m1.1.1.2">𝑤</ci><ci id="algorithm1.29.29.m1.1.1.3.cmml" xref="algorithm1.29.29.m1.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.29.29.m1.1c">w_{n}</annotation></semantics></math>;
</div>
<div id="algorithm1.39.47" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">27</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   

</div>
<div id="algorithm1.30.30" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">28</span><em id="algorithm1.30.30.1" class="ltx_emph ltx_font_typewriter">Client Selection(<em id="algorithm1.30.30.1.1.1" class="ltx_emph ltx_font_serif ltx_font_italic"><math id="algorithm1.30.30.1.1.1.m1.1" class="ltx_Math" alttext="W_{t}" display="inline"><semantics id="algorithm1.30.30.1.1.1.m1.1a"><msub id="algorithm1.30.30.1.1.1.m1.1.1" xref="algorithm1.30.30.1.1.1.m1.1.1.cmml"><mi id="algorithm1.30.30.1.1.1.m1.1.1.2" xref="algorithm1.30.30.1.1.1.m1.1.1.2.cmml">W</mi><mi id="algorithm1.30.30.1.1.1.m1.1.1.3" xref="algorithm1.30.30.1.1.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="algorithm1.30.30.1.1.1.m1.1b"><apply id="algorithm1.30.30.1.1.1.m1.1.1.cmml" xref="algorithm1.30.30.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="algorithm1.30.30.1.1.1.m1.1.1.1.cmml" xref="algorithm1.30.30.1.1.1.m1.1.1">subscript</csymbol><ci id="algorithm1.30.30.1.1.1.m1.1.1.2.cmml" xref="algorithm1.30.30.1.1.1.m1.1.1.2">𝑊</ci><ci id="algorithm1.30.30.1.1.1.m1.1.1.3.cmml" xref="algorithm1.30.30.1.1.1.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.30.30.1.1.1.m1.1c">W_{t}</annotation></semantics></math>, M</em>)</em><span id="algorithm1.30.30.2" class="ltx_text ltx_font_bold">:</span>
</div>
<div id="algorithm1.31.31" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">29</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
<math id="algorithm1.31.31.m1.1" class="ltx_Math" alttext="T_{t}\leftarrow\textnormal{{Construct k-d Tree}}(W_{t})" display="inline"><semantics id="algorithm1.31.31.m1.1a"><mrow id="algorithm1.31.31.m1.1.1" xref="algorithm1.31.31.m1.1.1.cmml"><msub id="algorithm1.31.31.m1.1.1.3" xref="algorithm1.31.31.m1.1.1.3.cmml"><mi id="algorithm1.31.31.m1.1.1.3.2" xref="algorithm1.31.31.m1.1.1.3.2.cmml">T</mi><mi id="algorithm1.31.31.m1.1.1.3.3" xref="algorithm1.31.31.m1.1.1.3.3.cmml">t</mi></msub><mo stretchy="false" id="algorithm1.31.31.m1.1.1.2" xref="algorithm1.31.31.m1.1.1.2.cmml">←</mo><mrow id="algorithm1.31.31.m1.1.1.1" xref="algorithm1.31.31.m1.1.1.1.cmml"><mtext class="ltx_mathvariant_monospace" id="algorithm1.31.31.m1.1.1.1.3" xref="algorithm1.31.31.m1.1.1.1.3a.cmml">Construct k-d Tree</mtext><mo lspace="0em" rspace="0em" id="algorithm1.31.31.m1.1.1.1.2" xref="algorithm1.31.31.m1.1.1.1.2.cmml">​</mo><mrow id="algorithm1.31.31.m1.1.1.1.1.1" xref="algorithm1.31.31.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="algorithm1.31.31.m1.1.1.1.1.1.2" xref="algorithm1.31.31.m1.1.1.1.1.1.1.cmml">(</mo><msub id="algorithm1.31.31.m1.1.1.1.1.1.1" xref="algorithm1.31.31.m1.1.1.1.1.1.1.cmml"><mi id="algorithm1.31.31.m1.1.1.1.1.1.1.2" xref="algorithm1.31.31.m1.1.1.1.1.1.1.2.cmml">W</mi><mi id="algorithm1.31.31.m1.1.1.1.1.1.1.3" xref="algorithm1.31.31.m1.1.1.1.1.1.1.3.cmml">t</mi></msub><mo stretchy="false" id="algorithm1.31.31.m1.1.1.1.1.1.3" xref="algorithm1.31.31.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.31.31.m1.1b"><apply id="algorithm1.31.31.m1.1.1.cmml" xref="algorithm1.31.31.m1.1.1"><ci id="algorithm1.31.31.m1.1.1.2.cmml" xref="algorithm1.31.31.m1.1.1.2">←</ci><apply id="algorithm1.31.31.m1.1.1.3.cmml" xref="algorithm1.31.31.m1.1.1.3"><csymbol cd="ambiguous" id="algorithm1.31.31.m1.1.1.3.1.cmml" xref="algorithm1.31.31.m1.1.1.3">subscript</csymbol><ci id="algorithm1.31.31.m1.1.1.3.2.cmml" xref="algorithm1.31.31.m1.1.1.3.2">𝑇</ci><ci id="algorithm1.31.31.m1.1.1.3.3.cmml" xref="algorithm1.31.31.m1.1.1.3.3">𝑡</ci></apply><apply id="algorithm1.31.31.m1.1.1.1.cmml" xref="algorithm1.31.31.m1.1.1.1"><times id="algorithm1.31.31.m1.1.1.1.2.cmml" xref="algorithm1.31.31.m1.1.1.1.2"></times><ci id="algorithm1.31.31.m1.1.1.1.3a.cmml" xref="algorithm1.31.31.m1.1.1.1.3"><mtext class="ltx_mathvariant_monospace" id="algorithm1.31.31.m1.1.1.1.3.cmml" xref="algorithm1.31.31.m1.1.1.1.3">Construct k-d Tree</mtext></ci><apply id="algorithm1.31.31.m1.1.1.1.1.1.1.cmml" xref="algorithm1.31.31.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="algorithm1.31.31.m1.1.1.1.1.1.1.1.cmml" xref="algorithm1.31.31.m1.1.1.1.1.1">subscript</csymbol><ci id="algorithm1.31.31.m1.1.1.1.1.1.1.2.cmml" xref="algorithm1.31.31.m1.1.1.1.1.1.1.2">𝑊</ci><ci id="algorithm1.31.31.m1.1.1.1.1.1.1.3.cmml" xref="algorithm1.31.31.m1.1.1.1.1.1.1.3">𝑡</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.31.31.m1.1c">T_{t}\leftarrow\textnormal{{Construct k-d Tree}}(W_{t})</annotation></semantics></math>;
</div>
<div id="algorithm1.32.32" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">30</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
<span id="algorithm1.32.32.2" class="ltx_text ltx_font_bold">for</span> <em id="algorithm1.32.32.1" class="ltx_emph ltx_font_italic"><math id="algorithm1.32.32.1.m1.1" class="ltx_Math" alttext="C_{i}\in S" display="inline"><semantics id="algorithm1.32.32.1.m1.1a"><mrow id="algorithm1.32.32.1.m1.1.1" xref="algorithm1.32.32.1.m1.1.1.cmml"><msub id="algorithm1.32.32.1.m1.1.1.2" xref="algorithm1.32.32.1.m1.1.1.2.cmml"><mi id="algorithm1.32.32.1.m1.1.1.2.2" xref="algorithm1.32.32.1.m1.1.1.2.2.cmml">C</mi><mi id="algorithm1.32.32.1.m1.1.1.2.3" xref="algorithm1.32.32.1.m1.1.1.2.3.cmml">i</mi></msub><mo id="algorithm1.32.32.1.m1.1.1.1" xref="algorithm1.32.32.1.m1.1.1.1.cmml">∈</mo><mi id="algorithm1.32.32.1.m1.1.1.3" xref="algorithm1.32.32.1.m1.1.1.3.cmml">S</mi></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.32.32.1.m1.1b"><apply id="algorithm1.32.32.1.m1.1.1.cmml" xref="algorithm1.32.32.1.m1.1.1"><in id="algorithm1.32.32.1.m1.1.1.1.cmml" xref="algorithm1.32.32.1.m1.1.1.1"></in><apply id="algorithm1.32.32.1.m1.1.1.2.cmml" xref="algorithm1.32.32.1.m1.1.1.2"><csymbol cd="ambiguous" id="algorithm1.32.32.1.m1.1.1.2.1.cmml" xref="algorithm1.32.32.1.m1.1.1.2">subscript</csymbol><ci id="algorithm1.32.32.1.m1.1.1.2.2.cmml" xref="algorithm1.32.32.1.m1.1.1.2.2">𝐶</ci><ci id="algorithm1.32.32.1.m1.1.1.2.3.cmml" xref="algorithm1.32.32.1.m1.1.1.2.3">𝑖</ci></apply><ci id="algorithm1.32.32.1.m1.1.1.3.cmml" xref="algorithm1.32.32.1.m1.1.1.3">𝑆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.32.32.1.m1.1c">C_{i}\in S</annotation></semantics></math></em> <span id="algorithm1.32.32.3" class="ltx_text ltx_font_bold">do</span>
</div>
<div id="algorithm1.33.33" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">31</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
<math id="algorithm1.33.33.m1.3" class="ltx_Math" alttext="S_{i}\leftarrow\textnormal{{Query k-d Tree}}(T_{t},C_{i},M)" display="inline"><semantics id="algorithm1.33.33.m1.3a"><mrow id="algorithm1.33.33.m1.3.3" xref="algorithm1.33.33.m1.3.3.cmml"><msub id="algorithm1.33.33.m1.3.3.4" xref="algorithm1.33.33.m1.3.3.4.cmml"><mi id="algorithm1.33.33.m1.3.3.4.2" xref="algorithm1.33.33.m1.3.3.4.2.cmml">S</mi><mi id="algorithm1.33.33.m1.3.3.4.3" xref="algorithm1.33.33.m1.3.3.4.3.cmml">i</mi></msub><mo stretchy="false" id="algorithm1.33.33.m1.3.3.3" xref="algorithm1.33.33.m1.3.3.3.cmml">←</mo><mrow id="algorithm1.33.33.m1.3.3.2" xref="algorithm1.33.33.m1.3.3.2.cmml"><mtext class="ltx_mathvariant_monospace" id="algorithm1.33.33.m1.3.3.2.4" xref="algorithm1.33.33.m1.3.3.2.4a.cmml">Query k-d Tree</mtext><mo lspace="0em" rspace="0em" id="algorithm1.33.33.m1.3.3.2.3" xref="algorithm1.33.33.m1.3.3.2.3.cmml">​</mo><mrow id="algorithm1.33.33.m1.3.3.2.2.2" xref="algorithm1.33.33.m1.3.3.2.2.3.cmml"><mo stretchy="false" id="algorithm1.33.33.m1.3.3.2.2.2.3" xref="algorithm1.33.33.m1.3.3.2.2.3.cmml">(</mo><msub id="algorithm1.33.33.m1.2.2.1.1.1.1" xref="algorithm1.33.33.m1.2.2.1.1.1.1.cmml"><mi id="algorithm1.33.33.m1.2.2.1.1.1.1.2" xref="algorithm1.33.33.m1.2.2.1.1.1.1.2.cmml">T</mi><mi id="algorithm1.33.33.m1.2.2.1.1.1.1.3" xref="algorithm1.33.33.m1.2.2.1.1.1.1.3.cmml">t</mi></msub><mo id="algorithm1.33.33.m1.3.3.2.2.2.4" xref="algorithm1.33.33.m1.3.3.2.2.3.cmml">,</mo><msub id="algorithm1.33.33.m1.3.3.2.2.2.2" xref="algorithm1.33.33.m1.3.3.2.2.2.2.cmml"><mi id="algorithm1.33.33.m1.3.3.2.2.2.2.2" xref="algorithm1.33.33.m1.3.3.2.2.2.2.2.cmml">C</mi><mi id="algorithm1.33.33.m1.3.3.2.2.2.2.3" xref="algorithm1.33.33.m1.3.3.2.2.2.2.3.cmml">i</mi></msub><mo id="algorithm1.33.33.m1.3.3.2.2.2.5" xref="algorithm1.33.33.m1.3.3.2.2.3.cmml">,</mo><mi id="algorithm1.33.33.m1.1.1" xref="algorithm1.33.33.m1.1.1.cmml">M</mi><mo stretchy="false" id="algorithm1.33.33.m1.3.3.2.2.2.6" xref="algorithm1.33.33.m1.3.3.2.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.33.33.m1.3b"><apply id="algorithm1.33.33.m1.3.3.cmml" xref="algorithm1.33.33.m1.3.3"><ci id="algorithm1.33.33.m1.3.3.3.cmml" xref="algorithm1.33.33.m1.3.3.3">←</ci><apply id="algorithm1.33.33.m1.3.3.4.cmml" xref="algorithm1.33.33.m1.3.3.4"><csymbol cd="ambiguous" id="algorithm1.33.33.m1.3.3.4.1.cmml" xref="algorithm1.33.33.m1.3.3.4">subscript</csymbol><ci id="algorithm1.33.33.m1.3.3.4.2.cmml" xref="algorithm1.33.33.m1.3.3.4.2">𝑆</ci><ci id="algorithm1.33.33.m1.3.3.4.3.cmml" xref="algorithm1.33.33.m1.3.3.4.3">𝑖</ci></apply><apply id="algorithm1.33.33.m1.3.3.2.cmml" xref="algorithm1.33.33.m1.3.3.2"><times id="algorithm1.33.33.m1.3.3.2.3.cmml" xref="algorithm1.33.33.m1.3.3.2.3"></times><ci id="algorithm1.33.33.m1.3.3.2.4a.cmml" xref="algorithm1.33.33.m1.3.3.2.4"><mtext class="ltx_mathvariant_monospace" id="algorithm1.33.33.m1.3.3.2.4.cmml" xref="algorithm1.33.33.m1.3.3.2.4">Query k-d Tree</mtext></ci><vector id="algorithm1.33.33.m1.3.3.2.2.3.cmml" xref="algorithm1.33.33.m1.3.3.2.2.2"><apply id="algorithm1.33.33.m1.2.2.1.1.1.1.cmml" xref="algorithm1.33.33.m1.2.2.1.1.1.1"><csymbol cd="ambiguous" id="algorithm1.33.33.m1.2.2.1.1.1.1.1.cmml" xref="algorithm1.33.33.m1.2.2.1.1.1.1">subscript</csymbol><ci id="algorithm1.33.33.m1.2.2.1.1.1.1.2.cmml" xref="algorithm1.33.33.m1.2.2.1.1.1.1.2">𝑇</ci><ci id="algorithm1.33.33.m1.2.2.1.1.1.1.3.cmml" xref="algorithm1.33.33.m1.2.2.1.1.1.1.3">𝑡</ci></apply><apply id="algorithm1.33.33.m1.3.3.2.2.2.2.cmml" xref="algorithm1.33.33.m1.3.3.2.2.2.2"><csymbol cd="ambiguous" id="algorithm1.33.33.m1.3.3.2.2.2.2.1.cmml" xref="algorithm1.33.33.m1.3.3.2.2.2.2">subscript</csymbol><ci id="algorithm1.33.33.m1.3.3.2.2.2.2.2.cmml" xref="algorithm1.33.33.m1.3.3.2.2.2.2.2">𝐶</ci><ci id="algorithm1.33.33.m1.3.3.2.2.2.2.3.cmml" xref="algorithm1.33.33.m1.3.3.2.2.2.2.3">𝑖</ci></apply><ci id="algorithm1.33.33.m1.1.1.cmml" xref="algorithm1.33.33.m1.1.1">𝑀</ci></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.33.33.m1.3c">S_{i}\leftarrow\textnormal{{Query k-d Tree}}(T_{t},C_{i},M)</annotation></semantics></math>;
</div>
<div id="algorithm1.35.35" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">32</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
<math id="algorithm1.34.34.m1.2" class="ltx_Math" alttext="d_{i}\leftarrow\Sigma_{m=1}^{M}\textnormal{{Dist}}(C_{i},C_{m})" display="inline"><semantics id="algorithm1.34.34.m1.2a"><mrow id="algorithm1.34.34.m1.2.2" xref="algorithm1.34.34.m1.2.2.cmml"><msub id="algorithm1.34.34.m1.2.2.4" xref="algorithm1.34.34.m1.2.2.4.cmml"><mi id="algorithm1.34.34.m1.2.2.4.2" xref="algorithm1.34.34.m1.2.2.4.2.cmml">d</mi><mi id="algorithm1.34.34.m1.2.2.4.3" xref="algorithm1.34.34.m1.2.2.4.3.cmml">i</mi></msub><mo stretchy="false" id="algorithm1.34.34.m1.2.2.3" xref="algorithm1.34.34.m1.2.2.3.cmml">←</mo><mrow id="algorithm1.34.34.m1.2.2.2" xref="algorithm1.34.34.m1.2.2.2.cmml"><msubsup id="algorithm1.34.34.m1.2.2.2.4" xref="algorithm1.34.34.m1.2.2.2.4.cmml"><mi mathvariant="normal" id="algorithm1.34.34.m1.2.2.2.4.2.2" xref="algorithm1.34.34.m1.2.2.2.4.2.2.cmml">Σ</mi><mrow id="algorithm1.34.34.m1.2.2.2.4.2.3" xref="algorithm1.34.34.m1.2.2.2.4.2.3.cmml"><mi id="algorithm1.34.34.m1.2.2.2.4.2.3.2" xref="algorithm1.34.34.m1.2.2.2.4.2.3.2.cmml">m</mi><mo id="algorithm1.34.34.m1.2.2.2.4.2.3.1" xref="algorithm1.34.34.m1.2.2.2.4.2.3.1.cmml">=</mo><mn id="algorithm1.34.34.m1.2.2.2.4.2.3.3" xref="algorithm1.34.34.m1.2.2.2.4.2.3.3.cmml">1</mn></mrow><mi id="algorithm1.34.34.m1.2.2.2.4.3" xref="algorithm1.34.34.m1.2.2.2.4.3.cmml">M</mi></msubsup><mo lspace="0em" rspace="0em" id="algorithm1.34.34.m1.2.2.2.3" xref="algorithm1.34.34.m1.2.2.2.3.cmml">​</mo><mtext class="ltx_mathvariant_monospace" id="algorithm1.34.34.m1.2.2.2.5" xref="algorithm1.34.34.m1.2.2.2.5a.cmml">Dist</mtext><mo lspace="0em" rspace="0em" id="algorithm1.34.34.m1.2.2.2.3a" xref="algorithm1.34.34.m1.2.2.2.3.cmml">​</mo><mrow id="algorithm1.34.34.m1.2.2.2.2.2" xref="algorithm1.34.34.m1.2.2.2.2.3.cmml"><mo stretchy="false" id="algorithm1.34.34.m1.2.2.2.2.2.3" xref="algorithm1.34.34.m1.2.2.2.2.3.cmml">(</mo><msub id="algorithm1.34.34.m1.1.1.1.1.1.1" xref="algorithm1.34.34.m1.1.1.1.1.1.1.cmml"><mi id="algorithm1.34.34.m1.1.1.1.1.1.1.2" xref="algorithm1.34.34.m1.1.1.1.1.1.1.2.cmml">C</mi><mi id="algorithm1.34.34.m1.1.1.1.1.1.1.3" xref="algorithm1.34.34.m1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="algorithm1.34.34.m1.2.2.2.2.2.4" xref="algorithm1.34.34.m1.2.2.2.2.3.cmml">,</mo><msub id="algorithm1.34.34.m1.2.2.2.2.2.2" xref="algorithm1.34.34.m1.2.2.2.2.2.2.cmml"><mi id="algorithm1.34.34.m1.2.2.2.2.2.2.2" xref="algorithm1.34.34.m1.2.2.2.2.2.2.2.cmml">C</mi><mi id="algorithm1.34.34.m1.2.2.2.2.2.2.3" xref="algorithm1.34.34.m1.2.2.2.2.2.2.3.cmml">m</mi></msub><mo stretchy="false" id="algorithm1.34.34.m1.2.2.2.2.2.5" xref="algorithm1.34.34.m1.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.34.34.m1.2b"><apply id="algorithm1.34.34.m1.2.2.cmml" xref="algorithm1.34.34.m1.2.2"><ci id="algorithm1.34.34.m1.2.2.3.cmml" xref="algorithm1.34.34.m1.2.2.3">←</ci><apply id="algorithm1.34.34.m1.2.2.4.cmml" xref="algorithm1.34.34.m1.2.2.4"><csymbol cd="ambiguous" id="algorithm1.34.34.m1.2.2.4.1.cmml" xref="algorithm1.34.34.m1.2.2.4">subscript</csymbol><ci id="algorithm1.34.34.m1.2.2.4.2.cmml" xref="algorithm1.34.34.m1.2.2.4.2">𝑑</ci><ci id="algorithm1.34.34.m1.2.2.4.3.cmml" xref="algorithm1.34.34.m1.2.2.4.3">𝑖</ci></apply><apply id="algorithm1.34.34.m1.2.2.2.cmml" xref="algorithm1.34.34.m1.2.2.2"><times id="algorithm1.34.34.m1.2.2.2.3.cmml" xref="algorithm1.34.34.m1.2.2.2.3"></times><apply id="algorithm1.34.34.m1.2.2.2.4.cmml" xref="algorithm1.34.34.m1.2.2.2.4"><csymbol cd="ambiguous" id="algorithm1.34.34.m1.2.2.2.4.1.cmml" xref="algorithm1.34.34.m1.2.2.2.4">superscript</csymbol><apply id="algorithm1.34.34.m1.2.2.2.4.2.cmml" xref="algorithm1.34.34.m1.2.2.2.4"><csymbol cd="ambiguous" id="algorithm1.34.34.m1.2.2.2.4.2.1.cmml" xref="algorithm1.34.34.m1.2.2.2.4">subscript</csymbol><ci id="algorithm1.34.34.m1.2.2.2.4.2.2.cmml" xref="algorithm1.34.34.m1.2.2.2.4.2.2">Σ</ci><apply id="algorithm1.34.34.m1.2.2.2.4.2.3.cmml" xref="algorithm1.34.34.m1.2.2.2.4.2.3"><eq id="algorithm1.34.34.m1.2.2.2.4.2.3.1.cmml" xref="algorithm1.34.34.m1.2.2.2.4.2.3.1"></eq><ci id="algorithm1.34.34.m1.2.2.2.4.2.3.2.cmml" xref="algorithm1.34.34.m1.2.2.2.4.2.3.2">𝑚</ci><cn type="integer" id="algorithm1.34.34.m1.2.2.2.4.2.3.3.cmml" xref="algorithm1.34.34.m1.2.2.2.4.2.3.3">1</cn></apply></apply><ci id="algorithm1.34.34.m1.2.2.2.4.3.cmml" xref="algorithm1.34.34.m1.2.2.2.4.3">𝑀</ci></apply><ci id="algorithm1.34.34.m1.2.2.2.5a.cmml" xref="algorithm1.34.34.m1.2.2.2.5"><mtext class="ltx_mathvariant_monospace" id="algorithm1.34.34.m1.2.2.2.5.cmml" xref="algorithm1.34.34.m1.2.2.2.5">Dist</mtext></ci><interval closure="open" id="algorithm1.34.34.m1.2.2.2.2.3.cmml" xref="algorithm1.34.34.m1.2.2.2.2.2"><apply id="algorithm1.34.34.m1.1.1.1.1.1.1.cmml" xref="algorithm1.34.34.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="algorithm1.34.34.m1.1.1.1.1.1.1.1.cmml" xref="algorithm1.34.34.m1.1.1.1.1.1.1">subscript</csymbol><ci id="algorithm1.34.34.m1.1.1.1.1.1.1.2.cmml" xref="algorithm1.34.34.m1.1.1.1.1.1.1.2">𝐶</ci><ci id="algorithm1.34.34.m1.1.1.1.1.1.1.3.cmml" xref="algorithm1.34.34.m1.1.1.1.1.1.1.3">𝑖</ci></apply><apply id="algorithm1.34.34.m1.2.2.2.2.2.2.cmml" xref="algorithm1.34.34.m1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="algorithm1.34.34.m1.2.2.2.2.2.2.1.cmml" xref="algorithm1.34.34.m1.2.2.2.2.2.2">subscript</csymbol><ci id="algorithm1.34.34.m1.2.2.2.2.2.2.2.cmml" xref="algorithm1.34.34.m1.2.2.2.2.2.2.2">𝐶</ci><ci id="algorithm1.34.34.m1.2.2.2.2.2.2.3.cmml" xref="algorithm1.34.34.m1.2.2.2.2.2.2.3">𝑚</ci></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.34.34.m1.2c">d_{i}\leftarrow\Sigma_{m=1}^{M}\textnormal{{Dist}}(C_{i},C_{m})</annotation></semantics></math> <span id="algorithm1.35.35.1" class="ltx_text ltx_font_bold">for</span> <math id="algorithm1.35.35.m2.1" class="ltx_Math" alttext="C_{m}\in S_{i}" display="inline"><semantics id="algorithm1.35.35.m2.1a"><mrow id="algorithm1.35.35.m2.1.1" xref="algorithm1.35.35.m2.1.1.cmml"><msub id="algorithm1.35.35.m2.1.1.2" xref="algorithm1.35.35.m2.1.1.2.cmml"><mi id="algorithm1.35.35.m2.1.1.2.2" xref="algorithm1.35.35.m2.1.1.2.2.cmml">C</mi><mi id="algorithm1.35.35.m2.1.1.2.3" xref="algorithm1.35.35.m2.1.1.2.3.cmml">m</mi></msub><mo id="algorithm1.35.35.m2.1.1.1" xref="algorithm1.35.35.m2.1.1.1.cmml">∈</mo><msub id="algorithm1.35.35.m2.1.1.3" xref="algorithm1.35.35.m2.1.1.3.cmml"><mi id="algorithm1.35.35.m2.1.1.3.2" xref="algorithm1.35.35.m2.1.1.3.2.cmml">S</mi><mi id="algorithm1.35.35.m2.1.1.3.3" xref="algorithm1.35.35.m2.1.1.3.3.cmml">i</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.35.35.m2.1b"><apply id="algorithm1.35.35.m2.1.1.cmml" xref="algorithm1.35.35.m2.1.1"><in id="algorithm1.35.35.m2.1.1.1.cmml" xref="algorithm1.35.35.m2.1.1.1"></in><apply id="algorithm1.35.35.m2.1.1.2.cmml" xref="algorithm1.35.35.m2.1.1.2"><csymbol cd="ambiguous" id="algorithm1.35.35.m2.1.1.2.1.cmml" xref="algorithm1.35.35.m2.1.1.2">subscript</csymbol><ci id="algorithm1.35.35.m2.1.1.2.2.cmml" xref="algorithm1.35.35.m2.1.1.2.2">𝐶</ci><ci id="algorithm1.35.35.m2.1.1.2.3.cmml" xref="algorithm1.35.35.m2.1.1.2.3">𝑚</ci></apply><apply id="algorithm1.35.35.m2.1.1.3.cmml" xref="algorithm1.35.35.m2.1.1.3"><csymbol cd="ambiguous" id="algorithm1.35.35.m2.1.1.3.1.cmml" xref="algorithm1.35.35.m2.1.1.3">subscript</csymbol><ci id="algorithm1.35.35.m2.1.1.3.2.cmml" xref="algorithm1.35.35.m2.1.1.3.2">𝑆</ci><ci id="algorithm1.35.35.m2.1.1.3.3.cmml" xref="algorithm1.35.35.m2.1.1.3.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.35.35.m2.1c">C_{m}\in S_{i}</annotation></semantics></math>;
</div>
<div id="algorithm1.39.48" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">33</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   

</div>
<div id="algorithm1.36.36" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">34</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   <math id="algorithm1.36.36.m1.2" class="ltx_Math" alttext="I_{min}=\operatorname*{arg\,min}_{i}(d_{i})" display="inline"><semantics id="algorithm1.36.36.m1.2a"><mrow id="algorithm1.36.36.m1.2.2" xref="algorithm1.36.36.m1.2.2.cmml"><msub id="algorithm1.36.36.m1.2.2.4" xref="algorithm1.36.36.m1.2.2.4.cmml"><mi id="algorithm1.36.36.m1.2.2.4.2" xref="algorithm1.36.36.m1.2.2.4.2.cmml">I</mi><mrow id="algorithm1.36.36.m1.2.2.4.3" xref="algorithm1.36.36.m1.2.2.4.3.cmml"><mi id="algorithm1.36.36.m1.2.2.4.3.2" xref="algorithm1.36.36.m1.2.2.4.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="algorithm1.36.36.m1.2.2.4.3.1" xref="algorithm1.36.36.m1.2.2.4.3.1.cmml">​</mo><mi id="algorithm1.36.36.m1.2.2.4.3.3" xref="algorithm1.36.36.m1.2.2.4.3.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="algorithm1.36.36.m1.2.2.4.3.1a" xref="algorithm1.36.36.m1.2.2.4.3.1.cmml">​</mo><mi id="algorithm1.36.36.m1.2.2.4.3.4" xref="algorithm1.36.36.m1.2.2.4.3.4.cmml">n</mi></mrow></msub><mo id="algorithm1.36.36.m1.2.2.3" xref="algorithm1.36.36.m1.2.2.3.cmml">=</mo><mrow id="algorithm1.36.36.m1.2.2.2.2" xref="algorithm1.36.36.m1.2.2.2.3.cmml"><msub id="algorithm1.36.36.m1.1.1.1.1.1" xref="algorithm1.36.36.m1.1.1.1.1.1.cmml"><mrow id="algorithm1.36.36.m1.1.1.1.1.1.2" xref="algorithm1.36.36.m1.1.1.1.1.1.2.cmml"><mi id="algorithm1.36.36.m1.1.1.1.1.1.2.2" xref="algorithm1.36.36.m1.1.1.1.1.1.2.2.cmml">arg</mi><mo lspace="0.170em" rspace="0em" id="algorithm1.36.36.m1.1.1.1.1.1.2.1" xref="algorithm1.36.36.m1.1.1.1.1.1.2.1.cmml">​</mo><mi id="algorithm1.36.36.m1.1.1.1.1.1.2.3" xref="algorithm1.36.36.m1.1.1.1.1.1.2.3.cmml">min</mi></mrow><mi id="algorithm1.36.36.m1.1.1.1.1.1.3" xref="algorithm1.36.36.m1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="algorithm1.36.36.m1.2.2.2.2a" xref="algorithm1.36.36.m1.2.2.2.3.cmml">⁡</mo><mrow id="algorithm1.36.36.m1.2.2.2.2.2" xref="algorithm1.36.36.m1.2.2.2.3.cmml"><mo stretchy="false" id="algorithm1.36.36.m1.2.2.2.2.2.2" xref="algorithm1.36.36.m1.2.2.2.3.cmml">(</mo><msub id="algorithm1.36.36.m1.2.2.2.2.2.1" xref="algorithm1.36.36.m1.2.2.2.2.2.1.cmml"><mi id="algorithm1.36.36.m1.2.2.2.2.2.1.2" xref="algorithm1.36.36.m1.2.2.2.2.2.1.2.cmml">d</mi><mi id="algorithm1.36.36.m1.2.2.2.2.2.1.3" xref="algorithm1.36.36.m1.2.2.2.2.2.1.3.cmml">i</mi></msub><mo stretchy="false" id="algorithm1.36.36.m1.2.2.2.2.2.3" xref="algorithm1.36.36.m1.2.2.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.36.36.m1.2b"><apply id="algorithm1.36.36.m1.2.2.cmml" xref="algorithm1.36.36.m1.2.2"><eq id="algorithm1.36.36.m1.2.2.3.cmml" xref="algorithm1.36.36.m1.2.2.3"></eq><apply id="algorithm1.36.36.m1.2.2.4.cmml" xref="algorithm1.36.36.m1.2.2.4"><csymbol cd="ambiguous" id="algorithm1.36.36.m1.2.2.4.1.cmml" xref="algorithm1.36.36.m1.2.2.4">subscript</csymbol><ci id="algorithm1.36.36.m1.2.2.4.2.cmml" xref="algorithm1.36.36.m1.2.2.4.2">𝐼</ci><apply id="algorithm1.36.36.m1.2.2.4.3.cmml" xref="algorithm1.36.36.m1.2.2.4.3"><times id="algorithm1.36.36.m1.2.2.4.3.1.cmml" xref="algorithm1.36.36.m1.2.2.4.3.1"></times><ci id="algorithm1.36.36.m1.2.2.4.3.2.cmml" xref="algorithm1.36.36.m1.2.2.4.3.2">𝑚</ci><ci id="algorithm1.36.36.m1.2.2.4.3.3.cmml" xref="algorithm1.36.36.m1.2.2.4.3.3">𝑖</ci><ci id="algorithm1.36.36.m1.2.2.4.3.4.cmml" xref="algorithm1.36.36.m1.2.2.4.3.4">𝑛</ci></apply></apply><apply id="algorithm1.36.36.m1.2.2.2.3.cmml" xref="algorithm1.36.36.m1.2.2.2.2"><apply id="algorithm1.36.36.m1.1.1.1.1.1.cmml" xref="algorithm1.36.36.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="algorithm1.36.36.m1.1.1.1.1.1.1.cmml" xref="algorithm1.36.36.m1.1.1.1.1.1">subscript</csymbol><apply id="algorithm1.36.36.m1.1.1.1.1.1.2.cmml" xref="algorithm1.36.36.m1.1.1.1.1.1.2"><times id="algorithm1.36.36.m1.1.1.1.1.1.2.1.cmml" xref="algorithm1.36.36.m1.1.1.1.1.1.2.1"></times><ci id="algorithm1.36.36.m1.1.1.1.1.1.2.2.cmml" xref="algorithm1.36.36.m1.1.1.1.1.1.2.2">arg</ci><ci id="algorithm1.36.36.m1.1.1.1.1.1.2.3.cmml" xref="algorithm1.36.36.m1.1.1.1.1.1.2.3">min</ci></apply><ci id="algorithm1.36.36.m1.1.1.1.1.1.3.cmml" xref="algorithm1.36.36.m1.1.1.1.1.1.3">𝑖</ci></apply><apply id="algorithm1.36.36.m1.2.2.2.2.2.1.cmml" xref="algorithm1.36.36.m1.2.2.2.2.2.1"><csymbol cd="ambiguous" id="algorithm1.36.36.m1.2.2.2.2.2.1.1.cmml" xref="algorithm1.36.36.m1.2.2.2.2.2.1">subscript</csymbol><ci id="algorithm1.36.36.m1.2.2.2.2.2.1.2.cmml" xref="algorithm1.36.36.m1.2.2.2.2.2.1.2">𝑑</ci><ci id="algorithm1.36.36.m1.2.2.2.2.2.1.3.cmml" xref="algorithm1.36.36.m1.2.2.2.2.2.1.3">𝑖</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.36.36.m1.2c">I_{min}=\operatorname*{arg\,min}_{i}(d_{i})</annotation></semantics></math>;
</div>
<div id="algorithm1.37.37" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">35</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
<span id="algorithm1.37.37.2" class="ltx_text ltx_font_bold">for</span> <em id="algorithm1.37.37.1" class="ltx_emph ltx_font_italic"><math id="algorithm1.37.37.1.m1.1" class="ltx_Math" alttext="C_{m}\in S_{I_{min}}" display="inline"><semantics id="algorithm1.37.37.1.m1.1a"><mrow id="algorithm1.37.37.1.m1.1.1" xref="algorithm1.37.37.1.m1.1.1.cmml"><msub id="algorithm1.37.37.1.m1.1.1.2" xref="algorithm1.37.37.1.m1.1.1.2.cmml"><mi id="algorithm1.37.37.1.m1.1.1.2.2" xref="algorithm1.37.37.1.m1.1.1.2.2.cmml">C</mi><mi id="algorithm1.37.37.1.m1.1.1.2.3" xref="algorithm1.37.37.1.m1.1.1.2.3.cmml">m</mi></msub><mo id="algorithm1.37.37.1.m1.1.1.1" xref="algorithm1.37.37.1.m1.1.1.1.cmml">∈</mo><msub id="algorithm1.37.37.1.m1.1.1.3" xref="algorithm1.37.37.1.m1.1.1.3.cmml"><mi id="algorithm1.37.37.1.m1.1.1.3.2" xref="algorithm1.37.37.1.m1.1.1.3.2.cmml">S</mi><msub id="algorithm1.37.37.1.m1.1.1.3.3" xref="algorithm1.37.37.1.m1.1.1.3.3.cmml"><mi id="algorithm1.37.37.1.m1.1.1.3.3.2" xref="algorithm1.37.37.1.m1.1.1.3.3.2.cmml">I</mi><mrow id="algorithm1.37.37.1.m1.1.1.3.3.3" xref="algorithm1.37.37.1.m1.1.1.3.3.3.cmml"><mi id="algorithm1.37.37.1.m1.1.1.3.3.3.2" xref="algorithm1.37.37.1.m1.1.1.3.3.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="algorithm1.37.37.1.m1.1.1.3.3.3.1" xref="algorithm1.37.37.1.m1.1.1.3.3.3.1.cmml">​</mo><mi id="algorithm1.37.37.1.m1.1.1.3.3.3.3" xref="algorithm1.37.37.1.m1.1.1.3.3.3.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="algorithm1.37.37.1.m1.1.1.3.3.3.1a" xref="algorithm1.37.37.1.m1.1.1.3.3.3.1.cmml">​</mo><mi id="algorithm1.37.37.1.m1.1.1.3.3.3.4" xref="algorithm1.37.37.1.m1.1.1.3.3.3.4.cmml">n</mi></mrow></msub></msub></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.37.37.1.m1.1b"><apply id="algorithm1.37.37.1.m1.1.1.cmml" xref="algorithm1.37.37.1.m1.1.1"><in id="algorithm1.37.37.1.m1.1.1.1.cmml" xref="algorithm1.37.37.1.m1.1.1.1"></in><apply id="algorithm1.37.37.1.m1.1.1.2.cmml" xref="algorithm1.37.37.1.m1.1.1.2"><csymbol cd="ambiguous" id="algorithm1.37.37.1.m1.1.1.2.1.cmml" xref="algorithm1.37.37.1.m1.1.1.2">subscript</csymbol><ci id="algorithm1.37.37.1.m1.1.1.2.2.cmml" xref="algorithm1.37.37.1.m1.1.1.2.2">𝐶</ci><ci id="algorithm1.37.37.1.m1.1.1.2.3.cmml" xref="algorithm1.37.37.1.m1.1.1.2.3">𝑚</ci></apply><apply id="algorithm1.37.37.1.m1.1.1.3.cmml" xref="algorithm1.37.37.1.m1.1.1.3"><csymbol cd="ambiguous" id="algorithm1.37.37.1.m1.1.1.3.1.cmml" xref="algorithm1.37.37.1.m1.1.1.3">subscript</csymbol><ci id="algorithm1.37.37.1.m1.1.1.3.2.cmml" xref="algorithm1.37.37.1.m1.1.1.3.2">𝑆</ci><apply id="algorithm1.37.37.1.m1.1.1.3.3.cmml" xref="algorithm1.37.37.1.m1.1.1.3.3"><csymbol cd="ambiguous" id="algorithm1.37.37.1.m1.1.1.3.3.1.cmml" xref="algorithm1.37.37.1.m1.1.1.3.3">subscript</csymbol><ci id="algorithm1.37.37.1.m1.1.1.3.3.2.cmml" xref="algorithm1.37.37.1.m1.1.1.3.3.2">𝐼</ci><apply id="algorithm1.37.37.1.m1.1.1.3.3.3.cmml" xref="algorithm1.37.37.1.m1.1.1.3.3.3"><times id="algorithm1.37.37.1.m1.1.1.3.3.3.1.cmml" xref="algorithm1.37.37.1.m1.1.1.3.3.3.1"></times><ci id="algorithm1.37.37.1.m1.1.1.3.3.3.2.cmml" xref="algorithm1.37.37.1.m1.1.1.3.3.3.2">𝑚</ci><ci id="algorithm1.37.37.1.m1.1.1.3.3.3.3.cmml" xref="algorithm1.37.37.1.m1.1.1.3.3.3.3">𝑖</ci><ci id="algorithm1.37.37.1.m1.1.1.3.3.3.4.cmml" xref="algorithm1.37.37.1.m1.1.1.3.3.3.4">𝑛</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.37.37.1.m1.1c">C_{m}\in S_{I_{min}}</annotation></semantics></math> in parallel </em> <span id="algorithm1.37.37.3" class="ltx_text ltx_font_bold">do</span>
</div>
<div id="algorithm1.38.38" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">36</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
<math id="algorithm1.38.38.m1.6" class="ltx_Math" alttext="W_{t,I_{min}}^{\prime}\leftarrow W_{t,I_{min}}^{\prime}\cup w_{t,m}" display="inline"><semantics id="algorithm1.38.38.m1.6a"><mrow id="algorithm1.38.38.m1.6.7" xref="algorithm1.38.38.m1.6.7.cmml"><msubsup id="algorithm1.38.38.m1.6.7.2" xref="algorithm1.38.38.m1.6.7.2.cmml"><mi id="algorithm1.38.38.m1.6.7.2.2.2" xref="algorithm1.38.38.m1.6.7.2.2.2.cmml">W</mi><mrow id="algorithm1.38.38.m1.2.2.2.2" xref="algorithm1.38.38.m1.2.2.2.3.cmml"><mi id="algorithm1.38.38.m1.1.1.1.1" xref="algorithm1.38.38.m1.1.1.1.1.cmml">t</mi><mo id="algorithm1.38.38.m1.2.2.2.2.2" xref="algorithm1.38.38.m1.2.2.2.3.cmml">,</mo><msub id="algorithm1.38.38.m1.2.2.2.2.1" xref="algorithm1.38.38.m1.2.2.2.2.1.cmml"><mi id="algorithm1.38.38.m1.2.2.2.2.1.2" xref="algorithm1.38.38.m1.2.2.2.2.1.2.cmml">I</mi><mrow id="algorithm1.38.38.m1.2.2.2.2.1.3" xref="algorithm1.38.38.m1.2.2.2.2.1.3.cmml"><mi id="algorithm1.38.38.m1.2.2.2.2.1.3.2" xref="algorithm1.38.38.m1.2.2.2.2.1.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="algorithm1.38.38.m1.2.2.2.2.1.3.1" xref="algorithm1.38.38.m1.2.2.2.2.1.3.1.cmml">​</mo><mi id="algorithm1.38.38.m1.2.2.2.2.1.3.3" xref="algorithm1.38.38.m1.2.2.2.2.1.3.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="algorithm1.38.38.m1.2.2.2.2.1.3.1a" xref="algorithm1.38.38.m1.2.2.2.2.1.3.1.cmml">​</mo><mi id="algorithm1.38.38.m1.2.2.2.2.1.3.4" xref="algorithm1.38.38.m1.2.2.2.2.1.3.4.cmml">n</mi></mrow></msub></mrow><mo id="algorithm1.38.38.m1.6.7.2.3" xref="algorithm1.38.38.m1.6.7.2.3.cmml">′</mo></msubsup><mo stretchy="false" id="algorithm1.38.38.m1.6.7.1" xref="algorithm1.38.38.m1.6.7.1.cmml">←</mo><mrow id="algorithm1.38.38.m1.6.7.3" xref="algorithm1.38.38.m1.6.7.3.cmml"><msubsup id="algorithm1.38.38.m1.6.7.3.2" xref="algorithm1.38.38.m1.6.7.3.2.cmml"><mi id="algorithm1.38.38.m1.6.7.3.2.2.2" xref="algorithm1.38.38.m1.6.7.3.2.2.2.cmml">W</mi><mrow id="algorithm1.38.38.m1.4.4.2.2" xref="algorithm1.38.38.m1.4.4.2.3.cmml"><mi id="algorithm1.38.38.m1.3.3.1.1" xref="algorithm1.38.38.m1.3.3.1.1.cmml">t</mi><mo id="algorithm1.38.38.m1.4.4.2.2.2" xref="algorithm1.38.38.m1.4.4.2.3.cmml">,</mo><msub id="algorithm1.38.38.m1.4.4.2.2.1" xref="algorithm1.38.38.m1.4.4.2.2.1.cmml"><mi id="algorithm1.38.38.m1.4.4.2.2.1.2" xref="algorithm1.38.38.m1.4.4.2.2.1.2.cmml">I</mi><mrow id="algorithm1.38.38.m1.4.4.2.2.1.3" xref="algorithm1.38.38.m1.4.4.2.2.1.3.cmml"><mi id="algorithm1.38.38.m1.4.4.2.2.1.3.2" xref="algorithm1.38.38.m1.4.4.2.2.1.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="algorithm1.38.38.m1.4.4.2.2.1.3.1" xref="algorithm1.38.38.m1.4.4.2.2.1.3.1.cmml">​</mo><mi id="algorithm1.38.38.m1.4.4.2.2.1.3.3" xref="algorithm1.38.38.m1.4.4.2.2.1.3.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="algorithm1.38.38.m1.4.4.2.2.1.3.1a" xref="algorithm1.38.38.m1.4.4.2.2.1.3.1.cmml">​</mo><mi id="algorithm1.38.38.m1.4.4.2.2.1.3.4" xref="algorithm1.38.38.m1.4.4.2.2.1.3.4.cmml">n</mi></mrow></msub></mrow><mo id="algorithm1.38.38.m1.6.7.3.2.3" xref="algorithm1.38.38.m1.6.7.3.2.3.cmml">′</mo></msubsup><mo id="algorithm1.38.38.m1.6.7.3.1" xref="algorithm1.38.38.m1.6.7.3.1.cmml">∪</mo><msub id="algorithm1.38.38.m1.6.7.3.3" xref="algorithm1.38.38.m1.6.7.3.3.cmml"><mi id="algorithm1.38.38.m1.6.7.3.3.2" xref="algorithm1.38.38.m1.6.7.3.3.2.cmml">w</mi><mrow id="algorithm1.38.38.m1.6.6.2.4" xref="algorithm1.38.38.m1.6.6.2.3.cmml"><mi id="algorithm1.38.38.m1.5.5.1.1" xref="algorithm1.38.38.m1.5.5.1.1.cmml">t</mi><mo id="algorithm1.38.38.m1.6.6.2.4.1" xref="algorithm1.38.38.m1.6.6.2.3.cmml">,</mo><mi id="algorithm1.38.38.m1.6.6.2.2" xref="algorithm1.38.38.m1.6.6.2.2.cmml">m</mi></mrow></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.38.38.m1.6b"><apply id="algorithm1.38.38.m1.6.7.cmml" xref="algorithm1.38.38.m1.6.7"><ci id="algorithm1.38.38.m1.6.7.1.cmml" xref="algorithm1.38.38.m1.6.7.1">←</ci><apply id="algorithm1.38.38.m1.6.7.2.cmml" xref="algorithm1.38.38.m1.6.7.2"><csymbol cd="ambiguous" id="algorithm1.38.38.m1.6.7.2.1.cmml" xref="algorithm1.38.38.m1.6.7.2">superscript</csymbol><apply id="algorithm1.38.38.m1.6.7.2.2.cmml" xref="algorithm1.38.38.m1.6.7.2"><csymbol cd="ambiguous" id="algorithm1.38.38.m1.6.7.2.2.1.cmml" xref="algorithm1.38.38.m1.6.7.2">subscript</csymbol><ci id="algorithm1.38.38.m1.6.7.2.2.2.cmml" xref="algorithm1.38.38.m1.6.7.2.2.2">𝑊</ci><list id="algorithm1.38.38.m1.2.2.2.3.cmml" xref="algorithm1.38.38.m1.2.2.2.2"><ci id="algorithm1.38.38.m1.1.1.1.1.cmml" xref="algorithm1.38.38.m1.1.1.1.1">𝑡</ci><apply id="algorithm1.38.38.m1.2.2.2.2.1.cmml" xref="algorithm1.38.38.m1.2.2.2.2.1"><csymbol cd="ambiguous" id="algorithm1.38.38.m1.2.2.2.2.1.1.cmml" xref="algorithm1.38.38.m1.2.2.2.2.1">subscript</csymbol><ci id="algorithm1.38.38.m1.2.2.2.2.1.2.cmml" xref="algorithm1.38.38.m1.2.2.2.2.1.2">𝐼</ci><apply id="algorithm1.38.38.m1.2.2.2.2.1.3.cmml" xref="algorithm1.38.38.m1.2.2.2.2.1.3"><times id="algorithm1.38.38.m1.2.2.2.2.1.3.1.cmml" xref="algorithm1.38.38.m1.2.2.2.2.1.3.1"></times><ci id="algorithm1.38.38.m1.2.2.2.2.1.3.2.cmml" xref="algorithm1.38.38.m1.2.2.2.2.1.3.2">𝑚</ci><ci id="algorithm1.38.38.m1.2.2.2.2.1.3.3.cmml" xref="algorithm1.38.38.m1.2.2.2.2.1.3.3">𝑖</ci><ci id="algorithm1.38.38.m1.2.2.2.2.1.3.4.cmml" xref="algorithm1.38.38.m1.2.2.2.2.1.3.4">𝑛</ci></apply></apply></list></apply><ci id="algorithm1.38.38.m1.6.7.2.3.cmml" xref="algorithm1.38.38.m1.6.7.2.3">′</ci></apply><apply id="algorithm1.38.38.m1.6.7.3.cmml" xref="algorithm1.38.38.m1.6.7.3"><union id="algorithm1.38.38.m1.6.7.3.1.cmml" xref="algorithm1.38.38.m1.6.7.3.1"></union><apply id="algorithm1.38.38.m1.6.7.3.2.cmml" xref="algorithm1.38.38.m1.6.7.3.2"><csymbol cd="ambiguous" id="algorithm1.38.38.m1.6.7.3.2.1.cmml" xref="algorithm1.38.38.m1.6.7.3.2">superscript</csymbol><apply id="algorithm1.38.38.m1.6.7.3.2.2.cmml" xref="algorithm1.38.38.m1.6.7.3.2"><csymbol cd="ambiguous" id="algorithm1.38.38.m1.6.7.3.2.2.1.cmml" xref="algorithm1.38.38.m1.6.7.3.2">subscript</csymbol><ci id="algorithm1.38.38.m1.6.7.3.2.2.2.cmml" xref="algorithm1.38.38.m1.6.7.3.2.2.2">𝑊</ci><list id="algorithm1.38.38.m1.4.4.2.3.cmml" xref="algorithm1.38.38.m1.4.4.2.2"><ci id="algorithm1.38.38.m1.3.3.1.1.cmml" xref="algorithm1.38.38.m1.3.3.1.1">𝑡</ci><apply id="algorithm1.38.38.m1.4.4.2.2.1.cmml" xref="algorithm1.38.38.m1.4.4.2.2.1"><csymbol cd="ambiguous" id="algorithm1.38.38.m1.4.4.2.2.1.1.cmml" xref="algorithm1.38.38.m1.4.4.2.2.1">subscript</csymbol><ci id="algorithm1.38.38.m1.4.4.2.2.1.2.cmml" xref="algorithm1.38.38.m1.4.4.2.2.1.2">𝐼</ci><apply id="algorithm1.38.38.m1.4.4.2.2.1.3.cmml" xref="algorithm1.38.38.m1.4.4.2.2.1.3"><times id="algorithm1.38.38.m1.4.4.2.2.1.3.1.cmml" xref="algorithm1.38.38.m1.4.4.2.2.1.3.1"></times><ci id="algorithm1.38.38.m1.4.4.2.2.1.3.2.cmml" xref="algorithm1.38.38.m1.4.4.2.2.1.3.2">𝑚</ci><ci id="algorithm1.38.38.m1.4.4.2.2.1.3.3.cmml" xref="algorithm1.38.38.m1.4.4.2.2.1.3.3">𝑖</ci><ci id="algorithm1.38.38.m1.4.4.2.2.1.3.4.cmml" xref="algorithm1.38.38.m1.4.4.2.2.1.3.4">𝑛</ci></apply></apply></list></apply><ci id="algorithm1.38.38.m1.6.7.3.2.3.cmml" xref="algorithm1.38.38.m1.6.7.3.2.3">′</ci></apply><apply id="algorithm1.38.38.m1.6.7.3.3.cmml" xref="algorithm1.38.38.m1.6.7.3.3"><csymbol cd="ambiguous" id="algorithm1.38.38.m1.6.7.3.3.1.cmml" xref="algorithm1.38.38.m1.6.7.3.3">subscript</csymbol><ci id="algorithm1.38.38.m1.6.7.3.3.2.cmml" xref="algorithm1.38.38.m1.6.7.3.3.2">𝑤</ci><list id="algorithm1.38.38.m1.6.6.2.3.cmml" xref="algorithm1.38.38.m1.6.6.2.4"><ci id="algorithm1.38.38.m1.5.5.1.1.cmml" xref="algorithm1.38.38.m1.5.5.1.1">𝑡</ci><ci id="algorithm1.38.38.m1.6.6.2.2.cmml" xref="algorithm1.38.38.m1.6.6.2.2">𝑚</ci></list></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.38.38.m1.6c">W_{t,I_{min}}^{\prime}\leftarrow W_{t,I_{min}}^{\prime}\cup w_{t,m}</annotation></semantics></math>;
</div>
<div id="algorithm1.39.49" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">37</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   

</div>
<div id="algorithm1.39.39" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">38</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   <span id="algorithm1.39.39.1" class="ltx_text ltx_font_bold">return</span> <math id="algorithm1.39.39.m1.2" class="ltx_Math" alttext="W_{t,I_{min}}^{\prime}" display="inline"><semantics id="algorithm1.39.39.m1.2a"><msubsup id="algorithm1.39.39.m1.2.3" xref="algorithm1.39.39.m1.2.3.cmml"><mi id="algorithm1.39.39.m1.2.3.2.2" xref="algorithm1.39.39.m1.2.3.2.2.cmml">W</mi><mrow id="algorithm1.39.39.m1.2.2.2.2" xref="algorithm1.39.39.m1.2.2.2.3.cmml"><mi id="algorithm1.39.39.m1.1.1.1.1" xref="algorithm1.39.39.m1.1.1.1.1.cmml">t</mi><mo id="algorithm1.39.39.m1.2.2.2.2.2" xref="algorithm1.39.39.m1.2.2.2.3.cmml">,</mo><msub id="algorithm1.39.39.m1.2.2.2.2.1" xref="algorithm1.39.39.m1.2.2.2.2.1.cmml"><mi id="algorithm1.39.39.m1.2.2.2.2.1.2" xref="algorithm1.39.39.m1.2.2.2.2.1.2.cmml">I</mi><mrow id="algorithm1.39.39.m1.2.2.2.2.1.3" xref="algorithm1.39.39.m1.2.2.2.2.1.3.cmml"><mi id="algorithm1.39.39.m1.2.2.2.2.1.3.2" xref="algorithm1.39.39.m1.2.2.2.2.1.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="algorithm1.39.39.m1.2.2.2.2.1.3.1" xref="algorithm1.39.39.m1.2.2.2.2.1.3.1.cmml">​</mo><mi id="algorithm1.39.39.m1.2.2.2.2.1.3.3" xref="algorithm1.39.39.m1.2.2.2.2.1.3.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="algorithm1.39.39.m1.2.2.2.2.1.3.1a" xref="algorithm1.39.39.m1.2.2.2.2.1.3.1.cmml">​</mo><mi id="algorithm1.39.39.m1.2.2.2.2.1.3.4" xref="algorithm1.39.39.m1.2.2.2.2.1.3.4.cmml">n</mi></mrow></msub></mrow><mo id="algorithm1.39.39.m1.2.3.3" xref="algorithm1.39.39.m1.2.3.3.cmml">′</mo></msubsup><annotation-xml encoding="MathML-Content" id="algorithm1.39.39.m1.2b"><apply id="algorithm1.39.39.m1.2.3.cmml" xref="algorithm1.39.39.m1.2.3"><csymbol cd="ambiguous" id="algorithm1.39.39.m1.2.3.1.cmml" xref="algorithm1.39.39.m1.2.3">superscript</csymbol><apply id="algorithm1.39.39.m1.2.3.2.cmml" xref="algorithm1.39.39.m1.2.3"><csymbol cd="ambiguous" id="algorithm1.39.39.m1.2.3.2.1.cmml" xref="algorithm1.39.39.m1.2.3">subscript</csymbol><ci id="algorithm1.39.39.m1.2.3.2.2.cmml" xref="algorithm1.39.39.m1.2.3.2.2">𝑊</ci><list id="algorithm1.39.39.m1.2.2.2.3.cmml" xref="algorithm1.39.39.m1.2.2.2.2"><ci id="algorithm1.39.39.m1.1.1.1.1.cmml" xref="algorithm1.39.39.m1.1.1.1.1">𝑡</ci><apply id="algorithm1.39.39.m1.2.2.2.2.1.cmml" xref="algorithm1.39.39.m1.2.2.2.2.1"><csymbol cd="ambiguous" id="algorithm1.39.39.m1.2.2.2.2.1.1.cmml" xref="algorithm1.39.39.m1.2.2.2.2.1">subscript</csymbol><ci id="algorithm1.39.39.m1.2.2.2.2.1.2.cmml" xref="algorithm1.39.39.m1.2.2.2.2.1.2">𝐼</ci><apply id="algorithm1.39.39.m1.2.2.2.2.1.3.cmml" xref="algorithm1.39.39.m1.2.2.2.2.1.3"><times id="algorithm1.39.39.m1.2.2.2.2.1.3.1.cmml" xref="algorithm1.39.39.m1.2.2.2.2.1.3.1"></times><ci id="algorithm1.39.39.m1.2.2.2.2.1.3.2.cmml" xref="algorithm1.39.39.m1.2.2.2.2.1.3.2">𝑚</ci><ci id="algorithm1.39.39.m1.2.2.2.2.1.3.3.cmml" xref="algorithm1.39.39.m1.2.2.2.2.1.3.3">𝑖</ci><ci id="algorithm1.39.39.m1.2.2.2.2.1.3.4.cmml" xref="algorithm1.39.39.m1.2.2.2.2.1.3.4">𝑛</ci></apply></apply></list></apply><ci id="algorithm1.39.39.m1.2.3.3.cmml" xref="algorithm1.39.39.m1.2.3.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.39.39.m1.2c">W_{t,I_{min}}^{\prime}</annotation></semantics></math>;
</div>
<div id="algorithm1.39.50" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">39</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   

</div>
<div id="algorithm1.39.51" class="ltx_listingline">
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span id="algorithm1.41.1.1" class="ltx_text ltx_font_bold">Algorithm 1</span> </span>AutoFed training.</figcaption>
</figure>
</section>
<section id="S3.SS3.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.4. </span>Putting It All Together</h4>

<div id="S3.SS3.SSS4.p1" class="ltx_para">
<p id="S3.SS3.SSS4.p1.1" class="ltx_p">We carefully summarize the training strategy of the AutoFed framework in <span id="S3.SS3.SSS4.p1.1.1" class="ltx_text ltx_font_bold">Algorithm <a href="#algorithm1" title="In 3.3.3. Client Selection for Tolerating Model Weight Anomalies ‣ 3.3. AutoFed Framework ‣ 3. System Design ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a></span>. In the algorithm, <span id="S3.SS3.SSS4.p1.1.2" class="ltx_text ltx_font_sansserif">Client Update</span> is the local training process for each client, <span id="S3.SS3.SSS4.p1.1.3" class="ltx_text ltx_font_sansserif">Radar Imputation</span> and <span id="S3.SS3.SSS4.p1.1.4" class="ltx_text ltx_font_sansserif">Lidar Imputation</span> are the imputation function introduced in § <a href="#S3.SS3.SSS2" title="3.3.2. Modality Imputation with Autoencoder for Tolerating Modality Anomalies ‣ 3.3. AutoFed Framework ‣ 3. System Design ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3.2</span></a>, <span id="S3.SS3.SSS4.p1.1.5" class="ltx_text ltx_font_sansserif">SGD</span> is the standard stochastic gradient descent algorithm with our MCE loss, <span id="S3.SS3.SSS4.p1.1.6" class="ltx_text ltx_font_sansserif">Client Selection</span> has been introduced in § <a href="#S3.SS3.SSS3" title="3.3.3. Client Selection for Tolerating Model Weight Anomalies ‣ 3.3. AutoFed Framework ‣ 3. System Design ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3.3</span></a>, which includes <span id="S3.SS3.SSS4.p1.1.7" class="ltx_text ltx_font_sansserif">Construct k-d tree</span> and <span id="S3.SS3.SSS4.p1.1.8" class="ltx_text ltx_font_sansserif">Query k-d Tree</span> as the respective processes of constructing and querying <math id="S3.SS3.SSS4.p1.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS3.SSS4.p1.1.m1.1a"><mi id="S3.SS3.SSS4.p1.1.m1.1.1" xref="S3.SS3.SSS4.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS4.p1.1.m1.1b"><ci id="S3.SS3.SSS4.p1.1.m1.1.1.cmml" xref="S3.SS3.SSS4.p1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS4.p1.1.m1.1c">k</annotation></semantics></math>-d tree, as explained in § <a href="#S3.SS3.SSS3" title="3.3.3. Client Selection for Tolerating Model Weight Anomalies ‣ 3.3. AutoFed Framework ‣ 3. System Design ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3.3</span></a>, and <span id="S3.SS3.SSS4.p1.1.9" class="ltx_text ltx_font_sansserif">Model Aggregate</span> as the standard process of averaging the selected local models. By putting together AutoFed’s modules, we create a cohesive ensemble to substantially enhance the tolerance to data anomalies. Although some techniques can be relevant even to a single model context, they work together in the FL setting to help AutoFed navigate on the chaotic loss surface in a more robust and efficient manner.</p>
</div>
</section>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>Performance Evaluation</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">To evaluate the performance of AutoFed, we apply AutoFed to build a vehicle detection application using the benchmark dataset <cite class="ltx_cite ltx_citemacro_citep">(Barnes et al<span class="ltx_text">.</span>, <a href="#bib.bib2" title="" class="ltx_ref">2019</a>)</cite>.
In particular, we evaluate the performance of AutoFed from four aspects: i) comparisons with five baseline methods to demonstrate the superiority of AutoFed; ii) cross-domain tests to show that AutoFed is robust against real-life scenarios with heterogeneous data; iii) ablation study to show the necessity of key parameter designs, and iv) investigating the impact of FL-related hyper-parameter on the model performance.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1. </span>Dataset</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.4" class="ltx_p">We mainly use the Oxford Radar RobotCar dataset <cite class="ltx_cite ltx_citemacro_citep">(Barnes et al<span class="ltx_text">.</span>, <a href="#bib.bib2" title="" class="ltx_ref">2019</a>)</cite> in our experiment. The dataset is collected by a vehicle driving around Oxford, and it includes both lidar and radar data. The lidar data is obtained by merging the point clouds collected by two Velodyne HDL-32E <cite class="ltx_cite ltx_citemacro_citep">(Velodyne Lidar, Inc., <a href="#bib.bib63" title="" class="ltx_ref">2022</a>)</cite> lidars mounted on the left and right of the vehicle’s top. Each lidar sensor provides a range of 100 ​m, a range resolution of 2 ​cm, a horizontal field of view (FoV) of 360<sup id="S4.SS1.p1.4.1" class="ltx_sup">∘</sup>, and a vertical FoV of 41.3<sup id="S4.SS1.p1.4.2" class="ltx_sup"><span id="S4.SS1.p1.4.2.1" class="ltx_text ltx_font_italic">∘</span></sup>. The radar data is collected by a millimeter-wave Frequency-Modulated Continuous-Wave (FMCW) NavTech CTS350-X radar <cite class="ltx_cite ltx_citemacro_citep">(Navtech Radar, <a href="#bib.bib40" title="" class="ltx_ref">2022</a>)</cite> mounted between the two lidar sensors and at the center of the vehicle aligned to the vehicle axes. The radar achieves 2-D horizontal scan by rotation, operating with a center frequency of 76.5 ​GHz, a bandwidth of 1.5 ​GHz, a sampling rate of 4 ​Hz (hence a range resolution of 4.38 ​cm), a rotational angle resolution of 0.9<sup id="S4.SS1.p1.4.3" class="ltx_sup"><span id="S4.SS1.p1.4.3.1" class="ltx_text ltx_font_italic">∘</span></sup>, a beamwidth of 1.8<sup id="S4.SS1.p1.4.4" class="ltx_sup"><span id="S4.SS1.p1.4.4.1" class="ltx_text ltx_font_italic">∘</span></sup>, and a range up to 163 ​m; it complements lidar by providing robustness to weather conditions that may cause trouble to lidar. We further convert the data residing in the polar coordinates to Cartesian coordinates and then calibrate radar and lidar extrinsic parameters (i.e., translation and rotation with respect to the world) by performing pose optimization to minimize the differences between lidar and radar observations. Since there is no original ground truths for vehicle detections, we create rotated boxes by inspecting the point cloud data using Scalabel <cite class="ltx_cite ltx_citemacro_citep">(Scalabel, <a href="#bib.bib51" title="" class="ltx_ref">2022</a>)</cite>, which is a scalable open-source web annotation tool for various types of annotations on both images and videos.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.2" class="ltx_p">We also involve another dataset nuScenes <cite class="ltx_cite ltx_citemacro_citep">(Caesar et al<span class="ltx_text">.</span>, <a href="#bib.bib5" title="" class="ltx_ref">2020</a>)</cite> in our experiment to demonstrate AutoFed’s generalizability across datasets. The dataset contains 1 lidar and 5 radars: the lidar has 360<sup id="S4.SS1.p2.2.1" class="ltx_sup">∘</sup> horizontal FoV, 40<sup id="S4.SS1.p2.2.2" class="ltx_sup"><span id="S4.SS1.p2.2.2.1" class="ltx_text ltx_font_italic">∘</span></sup> vertical FoV, and 2 ​cm range resolution, while the 5 radars have 77 ​GHz center frequency and 0.1 ​km/h velocity accuracy. Unlike the radars in the Oxford dataset that perform fine-grained mechanical scans, the radars in the nuScenes dataset are fixed in positions and do not have scan capability. As a result, they only generate low-quality pointclouds. Since AutoFed cannot demonstrate its full potential with the inferior radar modality, we limit the evaluation on the nuScenes dataset to only § <a href="#S4.SS4" title="4.4. Superiority of AutoFed ‣ 4. Performance Evaluation ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.4</span></a>. For both datasets, we take out a total of 50,000 samples, and use 80% and 20% of the total data to create training and test datasets, respectively.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2. </span>System Implementation</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">We implemented the vehicle detection application using AutoFed on multiple NVIDIA Jetson TX2 <cite class="ltx_cite ltx_citemacro_citep">(NVIDIA, <a href="#bib.bib41" title="" class="ltx_ref">2022</a>)</cite> devices. The central server is equipped with an Intel Xeon Gold 6226 CPU <cite class="ltx_cite ltx_citemacro_citep">(Intel Corporation, <a href="#bib.bib22" title="" class="ltx_ref">2022</a>)</cite> and 128 ​GB RAM. For both AutoFed and the baselines, we implement an FL protocol that allows 20 participating clients to randomly take 2,000 non-overlapping samples from the 40,000-sample training set. Each participating client performs 5 local training epochs for each communication round. As for the software, Python 3.7 and PyTorch 1.9.1 <cite class="ltx_cite ltx_citemacro_citep">(Paszke et al<span class="ltx_text">.</span>, <a href="#bib.bib42" title="" class="ltx_ref">2019</a>)</cite> are used for implementing the application. Our vehicle detection model is built upon Detectron2 <cite class="ltx_cite ltx_citemacro_citep">(Wu, Yuxin and Kirillov, Alexander and Massa, Francisco and Lo,
Wan-Yen and Girshick, Ross, <a href="#bib.bib70" title="" class="ltx_ref">2022</a>)</cite>, which is a Python library that provides state-of-the-art OD models. In particular, the settings for the multimodal vehicle detection model are as follows:</p>
<ul id="S4.I1" class="ltx_itemize">
<li id="S4.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i1.p1" class="ltx_para">
<p id="S4.I1.i1.p1.1" class="ltx_p">The autoencoder is trained with 20,000 samples from the Oxford dataset, distinct (in terms of traffic, weather, and locations) from those used for training the rest of AutoFed.</p>
</div>
</li>
<li id="S4.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i2.p1" class="ltx_para">
<p id="S4.I1.i2.p1.4" class="ltx_p">The angles of the rotated anchors used by the RPN are set to -90<sup id="S4.I1.i2.p1.4.1" class="ltx_sup"><span id="S4.I1.i2.p1.4.1.1" class="ltx_text ltx_font_italic">∘</span></sup>, -45<sup id="S4.I1.i2.p1.4.2" class="ltx_sup"><span id="S4.I1.i2.p1.4.2.1" class="ltx_text ltx_font_italic">∘</span></sup>, 0<sup id="S4.I1.i2.p1.4.3" class="ltx_sup"><span id="S4.I1.i2.p1.4.3.1" class="ltx_text ltx_font_italic">∘</span></sup>, and 45<sup id="S4.I1.i2.p1.4.4" class="ltx_sup"><span id="S4.I1.i2.p1.4.4.1" class="ltx_text ltx_font_italic">∘</span></sup>.</p>
</div>
</li>
<li id="S4.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i3.p1" class="ltx_para">
<p id="S4.I1.i3.p1.1" class="ltx_p">Both lidar and radar feature extractors are composed of four consecutive convolutional layers with a kernel size of 3 and padding of 1.</p>
</div>
</li>
<li id="S4.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i4.p1" class="ltx_para">
<p id="S4.I1.i4.p1.1" class="ltx_p">The aspect ratio of the anchors is set to 2.5 to conform to the length-width ratio of regular vehicles <cite class="ltx_cite ltx_citemacro_citep">(Toyota Motor Sales, U.S.A., Inc., <a href="#bib.bib58" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
</li>
<li id="S4.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i5.p1" class="ltx_para">
<p id="S4.I1.i5.p1.1" class="ltx_p">The IoU threshold (defined later) of NMS for removing excessive proposals during testing is set to 0.2.</p>
</div>
</li>
</ul>
<p id="S4.SS2.p1.2" class="ltx_p">In the local training process, we employ the SGD optimizer by setting the initial learning rate as 0.01 and the decay factor as 0.01.</p>
</div>
<figure id="S4.F10" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S4.F10.sf1" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S4.F10.sf1.1" class="ltx_block ltx_minipage ltx_align_bottom" style="width:104.1pt;">
<img src="/html/2302.08646/assets/x16.png" id="S4.F10.sf1.1.g1" class="ltx_graphics ltx_img_landscape" width="442" height="344" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>AP@IoU=0.5.</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S4.F10.sf2" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S4.F10.sf2.1" class="ltx_block ltx_minipage ltx_align_bottom" style="width:104.1pt;">
<img src="/html/2302.08646/assets/x17.png" id="S4.F10.sf2.1.g1" class="ltx_graphics ltx_img_landscape" width="442" height="337" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>AP@IoU=0.65.</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S4.F10.sf3" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S4.F10.sf3.1" class="ltx_block ltx_minipage ltx_align_bottom" style="width:104.1pt;">
<img src="/html/2302.08646/assets/x18.png" id="S4.F10.sf3.1.g1" class="ltx_graphics ltx_img_landscape" width="442" height="337" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(c) </span>AP@IoU=0.8.</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S4.F10.sf4" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S4.F10.sf4.1" class="ltx_block ltx_minipage ltx_align_bottom" style="width:104.1pt;">
<img src="/html/2302.08646/assets/x19.png" id="S4.F10.sf4.1.g1" class="ltx_graphics ltx_img_landscape" width="442" height="344" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(d) </span>AP@IoU=0.5:0.9.</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S4.F10.sf5" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S4.F10.sf5.1" class="ltx_block ltx_minipage ltx_align_bottom" style="width:104.1pt;">
<img src="/html/2302.08646/assets/x20.png" id="S4.F10.sf5.1.g1" class="ltx_graphics ltx_img_landscape" width="442" height="337" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(e) </span>AR, maxDets = 1.</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S4.F10.sf6" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S4.F10.sf6.1" class="ltx_block ltx_minipage ltx_align_bottom" style="width:104.1pt;">
<img src="/html/2302.08646/assets/x21.png" id="S4.F10.sf6.1.g1" class="ltx_graphics ltx_img_landscape" width="442" height="344" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(f) </span>AR, maxDets = 10.</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S4.F10.sf7" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S4.F10.sf7.1" class="ltx_block ltx_minipage ltx_align_bottom" style="width:104.1pt;">
<img src="/html/2302.08646/assets/x22.png" id="S4.F10.sf7.1.g1" class="ltx_graphics ltx_img_landscape" width="442" height="344" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(g) </span>AR, maxDets = 100.</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S4.F10.sf8" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S4.F10.sf8.1" class="ltx_block ltx_minipage ltx_align_bottom" style="width:104.1pt;">
<img src="/html/2302.08646/assets/x23.png" id="S4.F10.sf8.1.g1" class="ltx_graphics ltx_img_square" width="442" height="365" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(h) </span>Convergence time.</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 10. </span>Comparing AutoFed with several baseline methods, in terms of FL convergence and communication overhead.</figcaption>
</figure>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3. </span>Experiment Setup</h3>

<section id="S4.SS3.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Baselines</h5>

<div id="S4.SS3.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS3.SSS0.Px1.p1.1" class="ltx_p">To comprehensively evaluate the performance of AutoFed, we compare AutoFed against five baselines:</p>
<ul id="S4.I2" class="ltx_itemize">
<li id="S4.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i1.p1" class="ltx_para">
<p id="S4.I2.i1.p1.1" class="ltx_p"><span id="S4.I2.i1.p1.1.1" class="ltx_text ltx_font_bold">Standalone</span> trains a vehicle detection model using heterogeneous data (e.g., heterogeneous annotations, sensing modalities, and environments) locally without collaborations among clients.</p>
</div>
</li>
<li id="S4.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i2.p1" class="ltx_para">
<p id="S4.I2.i2.p1.1" class="ltx_p"><span id="S4.I2.i2.p1.1.1" class="ltx_text ltx_font_bold">Standalone+</span> trains a vehicle detection model locally using the same setting as Standalone, but the data are sampled in a homogeneous way.</p>
</div>
</li>
<li id="S4.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i3.p1" class="ltx_para">
<p id="S4.I2.i3.p1.1" class="ltx_p"><span id="S4.I2.i3.p1.1.1" class="ltx_text ltx_font_bold">FedAvg</span> is the first and perhaps the most widely adopted FL method <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib39" title="" class="ltx_ref">2017</a>)</cite>. During training, all clients communicate updated local parameters to the central server and download the aggregated (i.e., averaged) global model for local training in the next round.</p>
</div>
</li>
<li id="S4.I2.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i4.p1" class="ltx_para">
<p id="S4.I2.i4.p1.1" class="ltx_p"><span id="S4.I2.i4.p1.1.1" class="ltx_text ltx_font_bold">FedCor</span> is a correlation-based client selection strategy for heterogeneous FL <cite class="ltx_cite ltx_citemacro_citep">(Tang et al<span class="ltx_text">.</span>, <a href="#bib.bib56" title="" class="ltx_ref">2022</a>)</cite>. It formulates the goal of accelerating FL convergence as an optimization problems that maximizes the posterior expectation of loss decrease utilizing the Gaussian process.</p>
</div>
</li>
<li id="S4.I2.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i5.p1" class="ltx_para">
<p id="S4.I2.i5.p1.1" class="ltx_p"><span id="S4.I2.i5.p1.1.1" class="ltx_text ltx_font_bold">FedProx</span> adds a proximal term to the loss function of local training to reduce the distance between the local model and the global model <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a href="#bib.bib31" title="" class="ltx_ref">2020</a>)</cite>, hence addressing both system and statistical heterogeneity.</p>
</div>
</li>
</ul>
<p id="S4.SS3.SSS0.Px1.p1.2" class="ltx_p">In addition, we adopt the same multimodal vehicle detection model configuration for each baseline method as AutoFed. We also apply the same training settings and data configurations as AutoFed to the baseline methods, the results are reported after the same number of communication rounds. It should be noted that we use Standalone and Standalone+ as baselines to provide context for how better FL methods perform: it confirms that they do improve upon standalone training, because each client only has limited data in reality.</p>
</div>
</section>
<section id="S4.SS3.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Evaluation Metrics.</h5>

<div id="S4.SS3.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS3.SSS0.Px2.p1.2" class="ltx_p">Before introducing the evaluation metrics, we first define an important concept called IoU (intersection over union), which evaluates the overlap between two bounding boxes. Suppose the ground truth and predicted bounding boxes are <math id="S4.SS3.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="B_{gt}" display="inline"><semantics id="S4.SS3.SSS0.Px2.p1.1.m1.1a"><msub id="S4.SS3.SSS0.Px2.p1.1.m1.1.1" xref="S4.SS3.SSS0.Px2.p1.1.m1.1.1.cmml"><mi id="S4.SS3.SSS0.Px2.p1.1.m1.1.1.2" xref="S4.SS3.SSS0.Px2.p1.1.m1.1.1.2.cmml">B</mi><mrow id="S4.SS3.SSS0.Px2.p1.1.m1.1.1.3" xref="S4.SS3.SSS0.Px2.p1.1.m1.1.1.3.cmml"><mi id="S4.SS3.SSS0.Px2.p1.1.m1.1.1.3.2" xref="S4.SS3.SSS0.Px2.p1.1.m1.1.1.3.2.cmml">g</mi><mo lspace="0em" rspace="0em" id="S4.SS3.SSS0.Px2.p1.1.m1.1.1.3.1" xref="S4.SS3.SSS0.Px2.p1.1.m1.1.1.3.1.cmml">​</mo><mi id="S4.SS3.SSS0.Px2.p1.1.m1.1.1.3.3" xref="S4.SS3.SSS0.Px2.p1.1.m1.1.1.3.3.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px2.p1.1.m1.1b"><apply id="S4.SS3.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S4.SS3.SSS0.Px2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS3.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="S4.SS3.SSS0.Px2.p1.1.m1.1.1">subscript</csymbol><ci id="S4.SS3.SSS0.Px2.p1.1.m1.1.1.2.cmml" xref="S4.SS3.SSS0.Px2.p1.1.m1.1.1.2">𝐵</ci><apply id="S4.SS3.SSS0.Px2.p1.1.m1.1.1.3.cmml" xref="S4.SS3.SSS0.Px2.p1.1.m1.1.1.3"><times id="S4.SS3.SSS0.Px2.p1.1.m1.1.1.3.1.cmml" xref="S4.SS3.SSS0.Px2.p1.1.m1.1.1.3.1"></times><ci id="S4.SS3.SSS0.Px2.p1.1.m1.1.1.3.2.cmml" xref="S4.SS3.SSS0.Px2.p1.1.m1.1.1.3.2">𝑔</ci><ci id="S4.SS3.SSS0.Px2.p1.1.m1.1.1.3.3.cmml" xref="S4.SS3.SSS0.Px2.p1.1.m1.1.1.3.3">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px2.p1.1.m1.1c">B_{gt}</annotation></semantics></math> and <math id="S4.SS3.SSS0.Px2.p1.2.m2.1" class="ltx_Math" alttext="B_{p}" display="inline"><semantics id="S4.SS3.SSS0.Px2.p1.2.m2.1a"><msub id="S4.SS3.SSS0.Px2.p1.2.m2.1.1" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1.cmml"><mi id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.2" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1.2.cmml">B</mi><mi id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.3" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px2.p1.2.m2.1b"><apply id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.1.cmml" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1">subscript</csymbol><ci id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.2.cmml" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1.2">𝐵</ci><ci id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.3.cmml" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px2.p1.2.m2.1c">B_{p}</annotation></semantics></math>, respectively, then IoU is given by the overlapping area between the predicted bounding box and the ground truth bounding box divided by the area of union between them:</p>
<table id="Sx1.EGx4" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S4.E4"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(4)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S4.E4.m1.2" class="ltx_Math" alttext="\displaystyle\mathrm{IoU}=\frac{\mathrm{Area}(B_{p}\cap B_{gt})}{\mathrm{Area}(B_{p}\cup B_{gt})}" display="inline"><semantics id="S4.E4.m1.2a"><mrow id="S4.E4.m1.2.3" xref="S4.E4.m1.2.3.cmml"><mi id="S4.E4.m1.2.3.2" xref="S4.E4.m1.2.3.2.cmml">IoU</mi><mo id="S4.E4.m1.2.3.1" xref="S4.E4.m1.2.3.1.cmml">=</mo><mstyle displaystyle="true" id="S4.E4.m1.2.2" xref="S4.E4.m1.2.2.cmml"><mfrac id="S4.E4.m1.2.2a" xref="S4.E4.m1.2.2.cmml"><mrow id="S4.E4.m1.1.1.1" xref="S4.E4.m1.1.1.1.cmml"><mi id="S4.E4.m1.1.1.1.3" xref="S4.E4.m1.1.1.1.3.cmml">Area</mi><mo lspace="0em" rspace="0em" id="S4.E4.m1.1.1.1.2" xref="S4.E4.m1.1.1.1.2.cmml">​</mo><mrow id="S4.E4.m1.1.1.1.1.1" xref="S4.E4.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.E4.m1.1.1.1.1.1.2" xref="S4.E4.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.E4.m1.1.1.1.1.1.1" xref="S4.E4.m1.1.1.1.1.1.1.cmml"><msub id="S4.E4.m1.1.1.1.1.1.1.2" xref="S4.E4.m1.1.1.1.1.1.1.2.cmml"><mi id="S4.E4.m1.1.1.1.1.1.1.2.2" xref="S4.E4.m1.1.1.1.1.1.1.2.2.cmml">B</mi><mi id="S4.E4.m1.1.1.1.1.1.1.2.3" xref="S4.E4.m1.1.1.1.1.1.1.2.3.cmml">p</mi></msub><mo id="S4.E4.m1.1.1.1.1.1.1.1" xref="S4.E4.m1.1.1.1.1.1.1.1.cmml">∩</mo><msub id="S4.E4.m1.1.1.1.1.1.1.3" xref="S4.E4.m1.1.1.1.1.1.1.3.cmml"><mi id="S4.E4.m1.1.1.1.1.1.1.3.2" xref="S4.E4.m1.1.1.1.1.1.1.3.2.cmml">B</mi><mrow id="S4.E4.m1.1.1.1.1.1.1.3.3" xref="S4.E4.m1.1.1.1.1.1.1.3.3.cmml"><mi id="S4.E4.m1.1.1.1.1.1.1.3.3.2" xref="S4.E4.m1.1.1.1.1.1.1.3.3.2.cmml">g</mi><mo lspace="0em" rspace="0em" id="S4.E4.m1.1.1.1.1.1.1.3.3.1" xref="S4.E4.m1.1.1.1.1.1.1.3.3.1.cmml">​</mo><mi id="S4.E4.m1.1.1.1.1.1.1.3.3.3" xref="S4.E4.m1.1.1.1.1.1.1.3.3.3.cmml">t</mi></mrow></msub></mrow><mo stretchy="false" id="S4.E4.m1.1.1.1.1.1.3" xref="S4.E4.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mrow id="S4.E4.m1.2.2.2" xref="S4.E4.m1.2.2.2.cmml"><mi id="S4.E4.m1.2.2.2.3" xref="S4.E4.m1.2.2.2.3.cmml">Area</mi><mo lspace="0em" rspace="0em" id="S4.E4.m1.2.2.2.2" xref="S4.E4.m1.2.2.2.2.cmml">​</mo><mrow id="S4.E4.m1.2.2.2.1.1" xref="S4.E4.m1.2.2.2.1.1.1.cmml"><mo stretchy="false" id="S4.E4.m1.2.2.2.1.1.2" xref="S4.E4.m1.2.2.2.1.1.1.cmml">(</mo><mrow id="S4.E4.m1.2.2.2.1.1.1" xref="S4.E4.m1.2.2.2.1.1.1.cmml"><msub id="S4.E4.m1.2.2.2.1.1.1.2" xref="S4.E4.m1.2.2.2.1.1.1.2.cmml"><mi id="S4.E4.m1.2.2.2.1.1.1.2.2" xref="S4.E4.m1.2.2.2.1.1.1.2.2.cmml">B</mi><mi id="S4.E4.m1.2.2.2.1.1.1.2.3" xref="S4.E4.m1.2.2.2.1.1.1.2.3.cmml">p</mi></msub><mo id="S4.E4.m1.2.2.2.1.1.1.1" xref="S4.E4.m1.2.2.2.1.1.1.1.cmml">∪</mo><msub id="S4.E4.m1.2.2.2.1.1.1.3" xref="S4.E4.m1.2.2.2.1.1.1.3.cmml"><mi id="S4.E4.m1.2.2.2.1.1.1.3.2" xref="S4.E4.m1.2.2.2.1.1.1.3.2.cmml">B</mi><mrow id="S4.E4.m1.2.2.2.1.1.1.3.3" xref="S4.E4.m1.2.2.2.1.1.1.3.3.cmml"><mi id="S4.E4.m1.2.2.2.1.1.1.3.3.2" xref="S4.E4.m1.2.2.2.1.1.1.3.3.2.cmml">g</mi><mo lspace="0em" rspace="0em" id="S4.E4.m1.2.2.2.1.1.1.3.3.1" xref="S4.E4.m1.2.2.2.1.1.1.3.3.1.cmml">​</mo><mi id="S4.E4.m1.2.2.2.1.1.1.3.3.3" xref="S4.E4.m1.2.2.2.1.1.1.3.3.3.cmml">t</mi></mrow></msub></mrow><mo stretchy="false" id="S4.E4.m1.2.2.2.1.1.3" xref="S4.E4.m1.2.2.2.1.1.1.cmml">)</mo></mrow></mrow></mfrac></mstyle></mrow><annotation-xml encoding="MathML-Content" id="S4.E4.m1.2b"><apply id="S4.E4.m1.2.3.cmml" xref="S4.E4.m1.2.3"><eq id="S4.E4.m1.2.3.1.cmml" xref="S4.E4.m1.2.3.1"></eq><ci id="S4.E4.m1.2.3.2.cmml" xref="S4.E4.m1.2.3.2">IoU</ci><apply id="S4.E4.m1.2.2.cmml" xref="S4.E4.m1.2.2"><divide id="S4.E4.m1.2.2.3.cmml" xref="S4.E4.m1.2.2"></divide><apply id="S4.E4.m1.1.1.1.cmml" xref="S4.E4.m1.1.1.1"><times id="S4.E4.m1.1.1.1.2.cmml" xref="S4.E4.m1.1.1.1.2"></times><ci id="S4.E4.m1.1.1.1.3.cmml" xref="S4.E4.m1.1.1.1.3">Area</ci><apply id="S4.E4.m1.1.1.1.1.1.1.cmml" xref="S4.E4.m1.1.1.1.1.1"><intersect id="S4.E4.m1.1.1.1.1.1.1.1.cmml" xref="S4.E4.m1.1.1.1.1.1.1.1"></intersect><apply id="S4.E4.m1.1.1.1.1.1.1.2.cmml" xref="S4.E4.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E4.m1.1.1.1.1.1.1.2.1.cmml" xref="S4.E4.m1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S4.E4.m1.1.1.1.1.1.1.2.2.cmml" xref="S4.E4.m1.1.1.1.1.1.1.2.2">𝐵</ci><ci id="S4.E4.m1.1.1.1.1.1.1.2.3.cmml" xref="S4.E4.m1.1.1.1.1.1.1.2.3">𝑝</ci></apply><apply id="S4.E4.m1.1.1.1.1.1.1.3.cmml" xref="S4.E4.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.E4.m1.1.1.1.1.1.1.3.1.cmml" xref="S4.E4.m1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S4.E4.m1.1.1.1.1.1.1.3.2.cmml" xref="S4.E4.m1.1.1.1.1.1.1.3.2">𝐵</ci><apply id="S4.E4.m1.1.1.1.1.1.1.3.3.cmml" xref="S4.E4.m1.1.1.1.1.1.1.3.3"><times id="S4.E4.m1.1.1.1.1.1.1.3.3.1.cmml" xref="S4.E4.m1.1.1.1.1.1.1.3.3.1"></times><ci id="S4.E4.m1.1.1.1.1.1.1.3.3.2.cmml" xref="S4.E4.m1.1.1.1.1.1.1.3.3.2">𝑔</ci><ci id="S4.E4.m1.1.1.1.1.1.1.3.3.3.cmml" xref="S4.E4.m1.1.1.1.1.1.1.3.3.3">𝑡</ci></apply></apply></apply></apply><apply id="S4.E4.m1.2.2.2.cmml" xref="S4.E4.m1.2.2.2"><times id="S4.E4.m1.2.2.2.2.cmml" xref="S4.E4.m1.2.2.2.2"></times><ci id="S4.E4.m1.2.2.2.3.cmml" xref="S4.E4.m1.2.2.2.3">Area</ci><apply id="S4.E4.m1.2.2.2.1.1.1.cmml" xref="S4.E4.m1.2.2.2.1.1"><union id="S4.E4.m1.2.2.2.1.1.1.1.cmml" xref="S4.E4.m1.2.2.2.1.1.1.1"></union><apply id="S4.E4.m1.2.2.2.1.1.1.2.cmml" xref="S4.E4.m1.2.2.2.1.1.1.2"><csymbol cd="ambiguous" id="S4.E4.m1.2.2.2.1.1.1.2.1.cmml" xref="S4.E4.m1.2.2.2.1.1.1.2">subscript</csymbol><ci id="S4.E4.m1.2.2.2.1.1.1.2.2.cmml" xref="S4.E4.m1.2.2.2.1.1.1.2.2">𝐵</ci><ci id="S4.E4.m1.2.2.2.1.1.1.2.3.cmml" xref="S4.E4.m1.2.2.2.1.1.1.2.3">𝑝</ci></apply><apply id="S4.E4.m1.2.2.2.1.1.1.3.cmml" xref="S4.E4.m1.2.2.2.1.1.1.3"><csymbol cd="ambiguous" id="S4.E4.m1.2.2.2.1.1.1.3.1.cmml" xref="S4.E4.m1.2.2.2.1.1.1.3">subscript</csymbol><ci id="S4.E4.m1.2.2.2.1.1.1.3.2.cmml" xref="S4.E4.m1.2.2.2.1.1.1.3.2">𝐵</ci><apply id="S4.E4.m1.2.2.2.1.1.1.3.3.cmml" xref="S4.E4.m1.2.2.2.1.1.1.3.3"><times id="S4.E4.m1.2.2.2.1.1.1.3.3.1.cmml" xref="S4.E4.m1.2.2.2.1.1.1.3.3.1"></times><ci id="S4.E4.m1.2.2.2.1.1.1.3.3.2.cmml" xref="S4.E4.m1.2.2.2.1.1.1.3.3.2">𝑔</ci><ci id="S4.E4.m1.2.2.2.1.1.1.3.3.3.cmml" xref="S4.E4.m1.2.2.2.1.1.1.3.3.3">𝑡</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E4.m1.2c">\displaystyle\mathrm{IoU}=\frac{\mathrm{Area}(B_{p}\cap B_{gt})}{\mathrm{Area}(B_{p}\cup B_{gt})}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S4.SS3.SSS0.Px2.p1.5" class="ltx_p">We define <math id="S4.SS3.SSS0.Px2.p1.3.m1.1" class="ltx_Math" alttext="\mathit{TP}" display="inline"><semantics id="S4.SS3.SSS0.Px2.p1.3.m1.1a"><mi id="S4.SS3.SSS0.Px2.p1.3.m1.1.1" xref="S4.SS3.SSS0.Px2.p1.3.m1.1.1.cmml">𝑇𝑃</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px2.p1.3.m1.1b"><ci id="S4.SS3.SSS0.Px2.p1.3.m1.1.1.cmml" xref="S4.SS3.SSS0.Px2.p1.3.m1.1.1">𝑇𝑃</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px2.p1.3.m1.1c">\mathit{TP}</annotation></semantics></math> as the number of correct detections (i.e., detections with an IoU greater than the predefined threshold), <math id="S4.SS3.SSS0.Px2.p1.4.m2.1" class="ltx_Math" alttext="\mathit{FP}" display="inline"><semantics id="S4.SS3.SSS0.Px2.p1.4.m2.1a"><mi id="S4.SS3.SSS0.Px2.p1.4.m2.1.1" xref="S4.SS3.SSS0.Px2.p1.4.m2.1.1.cmml">𝐹𝑃</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px2.p1.4.m2.1b"><ci id="S4.SS3.SSS0.Px2.p1.4.m2.1.1.cmml" xref="S4.SS3.SSS0.Px2.p1.4.m2.1.1">𝐹𝑃</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px2.p1.4.m2.1c">\mathit{FP}</annotation></semantics></math> as wrong detections (i.e., detections with an IoU smaller than the threshold), and <math id="S4.SS3.SSS0.Px2.p1.5.m3.1" class="ltx_Math" alttext="\mathit{FN}" display="inline"><semantics id="S4.SS3.SSS0.Px2.p1.5.m3.1a"><mi id="S4.SS3.SSS0.Px2.p1.5.m3.1.1" xref="S4.SS3.SSS0.Px2.p1.5.m3.1.1.cmml">𝐹𝑁</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px2.p1.5.m3.1b"><ci id="S4.SS3.SSS0.Px2.p1.5.m3.1.1.cmml" xref="S4.SS3.SSS0.Px2.p1.5.m3.1.1">𝐹𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px2.p1.5.m3.1c">\mathit{FN}</annotation></semantics></math> as the number of ground truths that are not identified. Based on these definitions, we define precision and recall as:</p>
<table id="Sx1.EGx5" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S4.E5"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(5)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S4.E5.m1.1" class="ltx_Math" alttext="\displaystyle\mathrm{Precision}=\frac{\mathit{TP}}{\mathit{TP}+\mathit{FP}},\quad\mathrm{Recall}=\frac{\mathit{TP}}{\mathit{TP}+\mathit{FN}}." display="inline"><semantics id="S4.E5.m1.1a"><mrow id="S4.E5.m1.1.1.1"><mrow id="S4.E5.m1.1.1.1.1.2" xref="S4.E5.m1.1.1.1.1.3.cmml"><mrow id="S4.E5.m1.1.1.1.1.1.1" xref="S4.E5.m1.1.1.1.1.1.1.cmml"><mi id="S4.E5.m1.1.1.1.1.1.1.2" xref="S4.E5.m1.1.1.1.1.1.1.2.cmml">Precision</mi><mo id="S4.E5.m1.1.1.1.1.1.1.1" xref="S4.E5.m1.1.1.1.1.1.1.1.cmml">=</mo><mstyle displaystyle="true" id="S4.E5.m1.1.1.1.1.1.1.3" xref="S4.E5.m1.1.1.1.1.1.1.3.cmml"><mfrac id="S4.E5.m1.1.1.1.1.1.1.3a" xref="S4.E5.m1.1.1.1.1.1.1.3.cmml"><mi id="S4.E5.m1.1.1.1.1.1.1.3.2" xref="S4.E5.m1.1.1.1.1.1.1.3.2.cmml">𝑇𝑃</mi><mrow id="S4.E5.m1.1.1.1.1.1.1.3.3" xref="S4.E5.m1.1.1.1.1.1.1.3.3.cmml"><mi id="S4.E5.m1.1.1.1.1.1.1.3.3.2" xref="S4.E5.m1.1.1.1.1.1.1.3.3.2.cmml">𝑇𝑃</mi><mo id="S4.E5.m1.1.1.1.1.1.1.3.3.1" xref="S4.E5.m1.1.1.1.1.1.1.3.3.1.cmml">+</mo><mi id="S4.E5.m1.1.1.1.1.1.1.3.3.3" xref="S4.E5.m1.1.1.1.1.1.1.3.3.3.cmml">𝐹𝑃</mi></mrow></mfrac></mstyle></mrow><mo rspace="1.167em" id="S4.E5.m1.1.1.1.1.2.3" xref="S4.E5.m1.1.1.1.1.3a.cmml">,</mo><mrow id="S4.E5.m1.1.1.1.1.2.2" xref="S4.E5.m1.1.1.1.1.2.2.cmml"><mi id="S4.E5.m1.1.1.1.1.2.2.2" xref="S4.E5.m1.1.1.1.1.2.2.2.cmml">Recall</mi><mo id="S4.E5.m1.1.1.1.1.2.2.1" xref="S4.E5.m1.1.1.1.1.2.2.1.cmml">=</mo><mstyle displaystyle="true" id="S4.E5.m1.1.1.1.1.2.2.3" xref="S4.E5.m1.1.1.1.1.2.2.3.cmml"><mfrac id="S4.E5.m1.1.1.1.1.2.2.3a" xref="S4.E5.m1.1.1.1.1.2.2.3.cmml"><mi id="S4.E5.m1.1.1.1.1.2.2.3.2" xref="S4.E5.m1.1.1.1.1.2.2.3.2.cmml">𝑇𝑃</mi><mrow id="S4.E5.m1.1.1.1.1.2.2.3.3" xref="S4.E5.m1.1.1.1.1.2.2.3.3.cmml"><mi id="S4.E5.m1.1.1.1.1.2.2.3.3.2" xref="S4.E5.m1.1.1.1.1.2.2.3.3.2.cmml">𝑇𝑃</mi><mo id="S4.E5.m1.1.1.1.1.2.2.3.3.1" xref="S4.E5.m1.1.1.1.1.2.2.3.3.1.cmml">+</mo><mi id="S4.E5.m1.1.1.1.1.2.2.3.3.3" xref="S4.E5.m1.1.1.1.1.2.2.3.3.3.cmml">𝐹𝑁</mi></mrow></mfrac></mstyle></mrow></mrow><mo lspace="0em" id="S4.E5.m1.1.1.1.2">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E5.m1.1b"><apply id="S4.E5.m1.1.1.1.1.3.cmml" xref="S4.E5.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E5.m1.1.1.1.1.3a.cmml" xref="S4.E5.m1.1.1.1.1.2.3">formulae-sequence</csymbol><apply id="S4.E5.m1.1.1.1.1.1.1.cmml" xref="S4.E5.m1.1.1.1.1.1.1"><eq id="S4.E5.m1.1.1.1.1.1.1.1.cmml" xref="S4.E5.m1.1.1.1.1.1.1.1"></eq><ci id="S4.E5.m1.1.1.1.1.1.1.2.cmml" xref="S4.E5.m1.1.1.1.1.1.1.2">Precision</ci><apply id="S4.E5.m1.1.1.1.1.1.1.3.cmml" xref="S4.E5.m1.1.1.1.1.1.1.3"><divide id="S4.E5.m1.1.1.1.1.1.1.3.1.cmml" xref="S4.E5.m1.1.1.1.1.1.1.3"></divide><ci id="S4.E5.m1.1.1.1.1.1.1.3.2.cmml" xref="S4.E5.m1.1.1.1.1.1.1.3.2">𝑇𝑃</ci><apply id="S4.E5.m1.1.1.1.1.1.1.3.3.cmml" xref="S4.E5.m1.1.1.1.1.1.1.3.3"><plus id="S4.E5.m1.1.1.1.1.1.1.3.3.1.cmml" xref="S4.E5.m1.1.1.1.1.1.1.3.3.1"></plus><ci id="S4.E5.m1.1.1.1.1.1.1.3.3.2.cmml" xref="S4.E5.m1.1.1.1.1.1.1.3.3.2">𝑇𝑃</ci><ci id="S4.E5.m1.1.1.1.1.1.1.3.3.3.cmml" xref="S4.E5.m1.1.1.1.1.1.1.3.3.3">𝐹𝑃</ci></apply></apply></apply><apply id="S4.E5.m1.1.1.1.1.2.2.cmml" xref="S4.E5.m1.1.1.1.1.2.2"><eq id="S4.E5.m1.1.1.1.1.2.2.1.cmml" xref="S4.E5.m1.1.1.1.1.2.2.1"></eq><ci id="S4.E5.m1.1.1.1.1.2.2.2.cmml" xref="S4.E5.m1.1.1.1.1.2.2.2">Recall</ci><apply id="S4.E5.m1.1.1.1.1.2.2.3.cmml" xref="S4.E5.m1.1.1.1.1.2.2.3"><divide id="S4.E5.m1.1.1.1.1.2.2.3.1.cmml" xref="S4.E5.m1.1.1.1.1.2.2.3"></divide><ci id="S4.E5.m1.1.1.1.1.2.2.3.2.cmml" xref="S4.E5.m1.1.1.1.1.2.2.3.2">𝑇𝑃</ci><apply id="S4.E5.m1.1.1.1.1.2.2.3.3.cmml" xref="S4.E5.m1.1.1.1.1.2.2.3.3"><plus id="S4.E5.m1.1.1.1.1.2.2.3.3.1.cmml" xref="S4.E5.m1.1.1.1.1.2.2.3.3.1"></plus><ci id="S4.E5.m1.1.1.1.1.2.2.3.3.2.cmml" xref="S4.E5.m1.1.1.1.1.2.2.3.3.2">𝑇𝑃</ci><ci id="S4.E5.m1.1.1.1.1.2.2.3.3.3.cmml" xref="S4.E5.m1.1.1.1.1.2.2.3.3.3">𝐹𝑁</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E5.m1.1c">\displaystyle\mathrm{Precision}=\frac{\mathit{TP}}{\mathit{TP}+\mathit{FP}},\quad\mathrm{Recall}=\frac{\mathit{TP}}{\mathit{TP}+\mathit{FN}}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S4.SS3.SSS0.Px2.p1.6" class="ltx_p">Since there is often a tradeoff between precision and recall, we also define an average precision (AP) value across all precision values from 0 to 1, thus summarizing the precision-recall curve. Moreover, we calculate the average recall (AR) value at IoU thresholds from 0.5 to 1, thus summarizing the distribution of recall values across a range of IoU thresholds <cite class="ltx_cite ltx_citemacro_citep">(Lin et al<span class="ltx_text">.</span>, <a href="#bib.bib34" title="" class="ltx_ref">2014</a>)</cite>. AP and AR are our key evaluation metrics hereafter.</p>
</div>
</section>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4. </span>Superiority of AutoFed</h3>

<figure id="S4.F11" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S4.F11.sf1" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S4.F11.sf1.1" class="ltx_block ltx_minipage ltx_align_bottom" style="width:58.5pt;">
<img src="/html/2302.08646/assets/pic/groundtruth.jpg" id="S4.F11.sf1.1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="592" height="592" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>Ground truth.</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S4.F11.sf2" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S4.F11.sf2.1" class="ltx_block ltx_minipage ltx_align_bottom" style="width:58.5pt;">
<img src="/html/2302.08646/assets/pic/FedAuto.jpg" id="S4.F11.sf2.1.g1" class="ltx_graphics ltx_img_square" width="592" height="592" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>AutoFed.</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S4.F11.sf3" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S4.F11.sf3.1" class="ltx_block ltx_minipage ltx_align_bottom" style="width:58.5pt;">
<img src="/html/2302.08646/assets/pic/mono.jpg" id="S4.F11.sf3.1.g1" class="ltx_graphics ltx_img_square" width="592" height="592" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(c) </span>Standalone.</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S4.F11.sf4" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S4.F11.sf4.1" class="ltx_block ltx_minipage ltx_align_bottom" style="width:58.5pt;">
<img src="/html/2302.08646/assets/pic/mono_plus.jpg" id="S4.F11.sf4.1.g1" class="ltx_graphics ltx_img_square" width="592" height="592" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(d) </span>Standalone+.</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S4.F11.sf5" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S4.F11.sf5.1" class="ltx_block ltx_minipage ltx_align_bottom" style="width:58.5pt;">
<img src="/html/2302.08646/assets/pic/FedAvg.jpg" id="S4.F11.sf5.1.g1" class="ltx_graphics ltx_img_square" width="592" height="592" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(e) </span>FedAvg.</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S4.F11.sf6" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S4.F11.sf6.1" class="ltx_block ltx_minipage ltx_align_bottom" style="width:58.5pt;">
<img src="/html/2302.08646/assets/pic/FedCor.jpg" id="S4.F11.sf6.1.g1" class="ltx_graphics ltx_img_square" width="592" height="592" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(f) </span>FedCor.</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S4.F11.sf7" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S4.F11.sf7.1" class="ltx_block ltx_minipage ltx_align_bottom" style="width:58.5pt;">
<img src="/html/2302.08646/assets/pic/PoC.jpg" id="S4.F11.sf7.1.g1" class="ltx_graphics ltx_img_square" width="592" height="592" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(g) </span>FedProx.</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 11. </span>Example detection results of AutoFed and other baseline methods.</figcaption>
</figure>
<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p">We compare AutoFed with the baselines in terms of the evaluation metrics defined in § <a href="#S4.SS3" title="4.3. Experiment Setup ‣ 4. Performance Evaluation ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3</span></a>. Specifically, we report AP when the IoU is 0.5, 0.65, and 0.8, respectively, and the mean AP when the IoU ranges from 0.5 to 0.9. As for AR, we focus on the cases when the number of maximum detections is 1, 10, and 100, respectively. We report the evaluation results in Figure <a href="#S4.F10" title="Figure 10 ‣ 4.2. System Implementation ‣ 4. Performance Evaluation ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a>. Figure <a href="#S4.F10.sf1" title="In Figure 10 ‣ 4.2. System Implementation ‣ 4. Performance Evaluation ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10a</span></a> shows that, when the IoU is set as 0.5, the AP of AutoFed is 0.71 while the number of FedAvg and FedProx are 0.68 and 0.58, respectively. Moreover, the APs of Standalone, Standalone+, and FedCor oscillate dramatically and barely converge. Similarly, as shown in Figures <a href="#S4.F10.sf2" title="In Figure 10 ‣ 4.2. System Implementation ‣ 4. Performance Evaluation ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10b</span></a>, <a href="#S4.F10.sf3" title="In Figure 10 ‣ 4.2. System Implementation ‣ 4. Performance Evaluation ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10c</span></a>, and <a href="#S4.F10.sf4" title="In Figure 10 ‣ 4.2. System Implementation ‣ 4. Performance Evaluation ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10d</span></a>, the performance of AutoFed significantly outperforms the baselines. It might be curious that the AP curve of AutoFed in Figure <a href="#S4.F10.sf3" title="In Figure 10 ‣ 4.2. System Implementation ‣ 4. Performance Evaluation ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10c</span></a> appears to be fluctuating, but this can be readily attributed to the fact that setting IoU as 0.8 is a stringent criterion for the vehicle detection task and causes the performance to become unstable.</p>
</div>
<div id="S4.SS4.p2" class="ltx_para">
<p id="S4.SS4.p2.1" class="ltx_p">With regard to AR shown by Figures  <a href="#S4.F10.sf5" title="In Figure 10 ‣ 4.2. System Implementation ‣ 4. Performance Evaluation ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10e</span></a>, <a href="#S4.F10.sf6" title="In Figure 10 ‣ 4.2. System Implementation ‣ 4. Performance Evaluation ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10f</span></a>, and <a href="#S4.F10.sf7" title="In Figure 10 ‣ 4.2. System Implementation ‣ 4. Performance Evaluation ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10g</span></a>, AutoFed exhibits significantly better performance compared with the baselines, in terms of
both AP and AR. Moreover, we also find that, when compared with the baselines, AutoFed reaches the maximum AP and AR with less number of communication rounds, as also confirmed by the results presented in Figure <a href="#S4.F10" title="Figure 10 ‣ 4.2. System Implementation ‣ 4. Performance Evaluation ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a>. Specifically, while AutoFed converges in 10 communication rounds,
all baseline methods converge after 20 communication rounds. Furthermore, the AP and AR curves of AutoFed rarely fluctuate, and the
training of AutoFed is much more stable than the baselines, indicating that the multimodal network trained by AutoFed is much more robust.</p>
</div>
<div id="S4.SS4.p3" class="ltx_para">
<p id="S4.SS4.p3.1" class="ltx_p">We also showcase some examples of vehicle detection in Figure <a href="#S4.F11" title="Figure 11 ‣ 4.4. Superiority of AutoFed ‣ 4. Performance Evaluation ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a>. In the examples, we use the 2-D lidar intensity map as background for reference, and draw the ground truth and predicted bounding boxes upon it. Figure <a href="#S4.F11.sf2" title="In Figure 11 ‣ 4.4. Superiority of AutoFed ‣ 4. Performance Evaluation ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11b</span></a> shows that AutoFed generates high-precision vehicle detection results very close to the ground truth in Figure <a href="#S4.F11.sf1" title="In Figure 11 ‣ 4.4. Superiority of AutoFed ‣ 4. Performance Evaluation ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11a</span></a>. In contrast, the Standalone, Standalone+, and FedAvg methods make incorrect predictions outside the road, FedCor’s misses most of the vehicles, and FedProx misses some vehicles and generates inaccurate bounding boxes overlapped with each other. The results evidently confirm that AutoFed outperforms the baselines with more accurate predictions.</p>
</div>
<div id="S4.SS4.p4" class="ltx_para">
<p id="S4.SS4.p4.1" class="ltx_p">Furthermore, we compare the communication cost of AutoFed training (the same as other FL baselines) with centralized training, i.e., all the clients transfer the collected data to a central server for training the model. The results show that, while centralized training transfers 660000 ​KB of sensor data during each communication round per client, AutoFed only transfers 62246 ​KB of model weights. In other words, AutoFed reduces up to more than 10<math id="S4.SS4.p4.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.SS4.p4.1.m1.1a"><mo id="S4.SS4.p4.1.m1.1.1" xref="S4.SS4.p4.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.SS4.p4.1.m1.1b"><times id="S4.SS4.p4.1.m1.1.1.cmml" xref="S4.SS4.p4.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p4.1.m1.1c">\times</annotation></semantics></math> communication cost per client than the centralized training, firmly validating its communication-efficient design.</p>
</div>
<div id="S4.SS4.p5" class="ltx_para">
<p id="S4.SS4.p5.1" class="ltx_p">We finally compare the performance of AutoFed with the baselines on the nuScenes dataset <cite class="ltx_cite ltx_citemacro_citep">(Caesar et al<span class="ltx_text">.</span>, <a href="#bib.bib5" title="" class="ltx_ref">2020</a>)</cite> to demonstrate its generalizability across different datasets. We train AutoFed for 100 communication rounds on the dataset. As shown in Figure <a href="#S4.F12" title="Figure 12 ‣ 4.4. Superiority of AutoFed ‣ 4. Performance Evaluation ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">12</span></a>, AutoFed outperforms all of the baselines on the nuScenes dataset by a large margin, firmly demonstrating that the evaluation results can be generalized to other datasets as well. It is worth noting that the overall AP and AR results of AutoFed on this dataset (0.687 and 0.672) are slightly lower than those shown in Figures <a href="#S4.F10.sf1" title="In Figure 10 ‣ 4.2. System Implementation ‣ 4. Performance Evaluation ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10a</span></a> and <a href="#S4.F10.sf7" title="In Figure 10 ‣ 4.2. System Implementation ‣ 4. Performance Evaluation ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10g</span></a> on the Oxford Radar RobotCar dataset, which can be attributed to a variety of factors, such as the complexity of the scenes and objects, sensor mounting positions, and most importantly, the sparsity and lower quality of the radar point cloud provided by the nuScenes dataset.</p>
</div>
<figure id="S4.F12" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F12.sf1" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S4.F12.sf1.1" class="ltx_block ltx_minipage ltx_align_bottom" style="width:212.5pt;">
<img src="/html/2302.08646/assets/x24.png" id="S4.F12.sf1.1.g1" class="ltx_graphics ltx_img_landscape" width="442" height="292" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>Average precision.</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F12.sf2" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S4.F12.sf2.1" class="ltx_block ltx_minipage ltx_align_bottom" style="width:212.5pt;">
<img src="/html/2302.08646/assets/x25.png" id="S4.F12.sf2.1.g1" class="ltx_graphics ltx_img_landscape" width="442" height="310" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Average recall.</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 12. </span>Evaluation on the nuScenes dataset.</figcaption>
</figure>
</section>
<section id="S4.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5. </span>Cross-domain Robustness</h3>

<div id="S4.SS5.p1" class="ltx_para">
<p id="S4.SS5.p1.1" class="ltx_p">We evaluate the robustness of AutoFedin cross-domain settings by investigating how the trained model performs in varied sensing modalities and different weather conditions. Since the AVs’ routes in the experiment encompass different roads and areas, the results in § <a href="#S4.SS4" title="4.4. Superiority of AutoFed ‣ 4. Performance Evaluation ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.4</span></a> have already proven the cross-road and cross-area capabilities of AutoFed, therefore we omit their discussions here.</p>
</div>
<section id="S4.SS5.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.5.1. </span>Various Sensing Modalities</h4>

<div id="S4.SS5.SSS1.p1" class="ltx_para">
<p id="S4.SS5.SSS1.p1.1" class="ltx_p">Since AutoFed involves both lidar and radar sensors, there are three possible sensor combinations, i.e., i) lidar + radar (Li + Ra), ii) without radar (w/o Ra), and iii) without lidar (w/o Li). We evaluate the performance of AutoFed  under these three settings, and report the results in Figure <a href="#S4.F13" title="Figure 13 ‣ 4.5.1. Various Sensing Modalities ‣ 4.5. Cross-domain Robustness ‣ 4. Performance Evaluation ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">13</span></a>. The results show that, when the IoU is set to be above 0.5, the median APs achieved by AutoFed are 0.71, 0.57, and 0.12 under the aforementioned three settings. Correspondingly, the median ARs achieved by AutoFed are 0.70, 0.59, and 0.12.
The autoencoder employed by AutoFed helps the model to maximize the efficacy of information embedded in either radar or lidar data, and AutoFed exhibits the smallest performance drop compared with the baselines whose performance is drastically impacted by missing modalities. However, since the performance drop of missing modalities stems from the loss of information, even the adoption of an autoencoder cannot totally fill up the performance gap. We have also noticed that the AP and AR of AutoFed are significantly lower in the radar-only mode compared to the other sensor combinations. Upon further investigation, we suspect that this may be because the importance of radar is overshadowed by lidar that provides most of the information used by AutoFed. Specifically, the majority of the vehicles in the dataset are close to the ego vehicle, probably due to the narrow width of the road, and as a result, lidar can detect almost all of these vehicles because they are within its range. This leads to the lower performance of the radar-only mode, as radar is
often meant to supplement the lidar sensor for long-range detection.</p>
</div>
<figure id="S4.F13" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F13.sf1" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S4.F13.sf1.1" class="ltx_block ltx_minipage ltx_align_bottom" style="width:433.6pt;">
<img src="/html/2302.08646/assets/x26.png" id="S4.F13.sf1.1.g1" class="ltx_graphics ltx_img_landscape" width="442" height="139" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>Average precision.</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F13.sf2" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S4.F13.sf2.1" class="ltx_block ltx_minipage ltx_align_bottom" style="width:433.6pt;">
<img src="/html/2302.08646/assets/x27.png" id="S4.F13.sf2.1.g1" class="ltx_graphics ltx_img_landscape" width="442" height="139" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Average recall.</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F13.sf3" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S4.F13.sf3.1" class="ltx_block ltx_minipage ltx_align_bottom" style="width:143.1pt;">
<img src="/html/2302.08646/assets/pic/groundtruth_weather.jpg" id="S4.F13.sf3.1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="574" height="574" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(c) </span>Lidar + radar.</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F13.sf4" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S4.F13.sf4.1" class="ltx_block ltx_minipage ltx_align_bottom" style="width:143.1pt;">
<img src="/html/2302.08646/assets/pic/noradar.jpg" id="S4.F13.sf4.1.g1" class="ltx_graphics ltx_img_square" width="574" height="574" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(d) </span>Missing radar.</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F13.sf5" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S4.F13.sf5.1" class="ltx_block ltx_minipage ltx_align_bottom" style="width:143.1pt;">
<img src="/html/2302.08646/assets/pic/nolidar.jpg" id="S4.F13.sf5.1.g1" class="ltx_graphics ltx_img_square" width="574" height="574" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(e) </span>Missing lidar.</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 13. </span>Different missing modalities.</figcaption>
</figure>
<div id="S4.SS5.SSS1.p2" class="ltx_para">
<p id="S4.SS5.SSS1.p2.1" class="ltx_p">We also show one example of vehicle detection with three sensor combinations in Figure <a href="#S4.F13" title="Figure 13 ‣ 4.5.1. Various Sensing Modalities ‣ 4.5. Cross-domain Robustness ‣ 4. Performance Evaluation ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">13</span></a>. As Figure <a href="#S4.F13.sf3" title="In Figure 13 ‣ 4.5.1. Various Sensing Modalities ‣ 4.5. Cross-domain Robustness ‣ 4. Performance Evaluation ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">13c</span></a> illustrates, when both lidar and radar are available, AutoFed is able to recognize most of the vehicles on the road. As a comparison, Figure <a href="#S4.F13.sf4" title="In Figure 13 ‣ 4.5.1. Various Sensing Modalities ‣ 4.5. Cross-domain Robustness ‣ 4. Performance Evaluation ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">13d</span></a> shows that missing radar data affects the detection of vehicles in the further distance, but the nearby vehicles can still be identified. This phenomenon is consistent with the characteristics of the radar sensor, i.e., the radar has an extended range due to better penetration capability while lidar can only obtain a much shorter range due to attenuation caused by in-air particles <cite class="ltx_cite ltx_citemacro_citep">(Zhao et al<span class="ltx_text">.</span>, <a href="#bib.bib77" title="" class="ltx_ref">2020</a>)</cite>. In addition, we also visualize the case of missing lidar in Figure <a href="#S4.F13.sf5" title="In Figure 13 ‣ 4.5.1. Various Sensing Modalities ‣ 4.5. Cross-domain Robustness ‣ 4. Performance Evaluation ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">13e</span></a>, where the vehicles in distance can be well detected by the radar. The results clearly demonstrate the complementary sensing capability of radar and lidar.</p>
</div>
<figure id="S4.F14" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F14.sf1" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S4.F14.sf1.1" class="ltx_block ltx_minipage ltx_align_bottom" style="width:424.9pt;">
<img src="/html/2302.08646/assets/x28.png" id="S4.F14.sf1.1.g1" class="ltx_graphics ltx_img_landscape" width="442" height="149" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>Average precision.</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F14.sf2" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S4.F14.sf2.1" class="ltx_block ltx_minipage ltx_align_bottom" style="width:424.9pt;">
<img src="/html/2302.08646/assets/x29.png" id="S4.F14.sf2.1.g1" class="ltx_graphics ltx_img_landscape" width="442" height="149" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Average recall.</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F14.sf3" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S4.F14.sf3.1" class="ltx_block ltx_minipage ltx_align_bottom" style="width:143.1pt;">
<img src="/html/2302.08646/assets/pic/weather_fog.jpg" id="S4.F14.sf3.1.g1" class="ltx_graphics ltx_img_square" width="574" height="574" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(c) </span>Foggy.</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F14.sf4" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S4.F14.sf4.1" class="ltx_block ltx_minipage ltx_align_bottom" style="width:143.1pt;">
<img src="/html/2302.08646/assets/pic/weather_rain.jpg" id="S4.F14.sf4.1.g1" class="ltx_graphics ltx_img_square" width="574" height="574" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(d) </span>Rainy.</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F14.sf5" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S4.F14.sf5.1" class="ltx_block ltx_minipage ltx_align_bottom" style="width:143.1pt;">
<img src="/html/2302.08646/assets/pic/weather_snow.jpg" id="S4.F14.sf5.1.g1" class="ltx_graphics ltx_img_square" width="574" height="574" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(e) </span>Snowy.</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 14. </span>Different weathers.</figcaption>
</figure>
</section>
<section id="S4.SS5.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.5.2. </span>Robustness against Adverse Weather Conditions</h4>

<div id="S4.SS5.SSS2.p1" class="ltx_para">
<p id="S4.SS5.SSS2.p1.1" class="ltx_p">Adverse weather is a realistic but challenging scenario for vehicle detection, which has a negative impact on the sensing capabilities <cite class="ltx_cite ltx_citemacro_citep">(Kilic et al<span class="ltx_text">.</span>, <a href="#bib.bib24" title="" class="ltx_ref">2021</a>)</cite>.
Therefore, we evaluate the performance of AutoFed under different adverse weathers (e.g., foggy, rainy, and snowy). Due to the lack of available datasets collected under adverse weather, we employ the physical models in DEF <cite class="ltx_cite ltx_citemacro_citep">(Bijelic et al<span class="ltx_text">.</span>, <a href="#bib.bib4" title="" class="ltx_ref">2020</a>)</cite> and LISA <cite class="ltx_cite ltx_citemacro_citep">(Kilic et al<span class="ltx_text">.</span>, <a href="#bib.bib24" title="" class="ltx_ref">2021</a>)</cite> to simulate fog, rain, and snow respectively. Specifically, we set the fog density to 0.05m<sup id="S4.SS5.SSS2.p1.1.1" class="ltx_sup"><span id="S4.SS5.SSS2.p1.1.1.1" class="ltx_text ltx_font_italic">-1</span></sup> in the DEF model and the rate of rain and snow to 30 ​mm/h in the LISA model.
Comparing the backgrounds in Figures <a href="#S4.F14.sf3" title="In Figure 14 ‣ 4.5.1. Various Sensing Modalities ‣ 4.5. Cross-domain Robustness ‣ 4. Performance Evaluation ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">14c</span></a>, <a href="#S4.F14.sf5" title="In Figure 14 ‣ 4.5.1. Various Sensing Modalities ‣ 4.5. Cross-domain Robustness ‣ 4. Performance Evaluation ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">14e</span></a>, and <a href="#S4.F14.sf4" title="In Figure 14 ‣ 4.5.1. Various Sensing Modalities ‣ 4.5. Cross-domain Robustness ‣ 4. Performance Evaluation ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">14d</span></a>, while foggy weather attenuates lidar signals and shrinks the field of view, rainy and snowy weathers mainly affect the lidar signals by inducing scattered reflections near the sensor. In particular, the three adverse weather conditions degrade the median AP of AutoFed from 0.71 to 0.65, 0.63, and 0.63, respectively, and degrade the median AR from 0.71 to 0.64, 0.63, and 0.63, respectively. The performance discrepancies among these adverse weathers can be attributed to their different reflectance of lidar signals. Despite the performance degradation, AutoFed exhibits the best generalization when compared with the baselines. The consistently high performance of AutoFed under all adverse weather conditions confirms that the client selection mechanism has allowed the DNN model to effectively incorporate information from unusual circumstances after sufficient training.</p>
</div>
</section>
</section>
<section id="S4.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.6. </span>Ablation Study</h3>

<div id="S4.SS6.p1" class="ltx_para">
<p id="S4.SS6.p1.1" class="ltx_p">We evaluate the impact of each module of AutoFed on the model performance. We use AutoFed to train the model for 150 communication rounds, and record the AP in Table <a href="#S4.T1" title="Table 1 ‣ 4.6. Ablation Study ‣ 4. Performance Evaluation ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. Take the AP when IoU is above 0.5 as an example, AutoFed achieves an AP of 0.731, while AutoFed without MCE loss, modality imputation with autoencoder, and client selection obtain the AP of 0.707, 0.692, and 0.542, respectively. One may think that the MCE loss and modality imputation only improves the result by small margins, while the client selection is much more effective in significantly improving performance. However, it is worth noting that both MCE loss and modality imputation are indispensable parts: although the lack of the two can be compensated by client selection (which excludes erroneous gradients) to a certain extent, there still are many heterogeneous scenarios that cannot be addressed by client selection alone, such as those demonstrated in Figures <a href="#S2.F2" title="Figure 2 ‣ 2.1. Quantity Skew of Labeled Data ‣ 2. Motivation ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> and <a href="#S2.F3" title="Figure 3 ‣ 2.2. Heterogeneous Modality across AVs ‣ 2. Motivation ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. The integration of MCE loss and modality imputation, together with client selection, can act as “belt and braces” to guarantee the robustness of AutoFed in diversified heterogeneous scenarios.</p>
</div>
<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 1. </span>Effects of key AutoFed parts.</figcaption>
<table id="S4.T1.3" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T1.3.1.1" class="ltx_tr">
<th id="S4.T1.3.1.1.1" class="ltx_td ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t"></th>
<th id="S4.T1.3.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" colspan="4"><span id="S4.T1.3.1.1.2.1" class="ltx_text" style="font-size:90%;">AP</span></th>
</tr>
<tr id="S4.T1.3.2.2" class="ltx_tr">
<th id="S4.T1.3.2.2.1" class="ltx_td ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t"></th>
<th id="S4.T1.3.2.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T1.3.2.2.2.1" class="ltx_text" style="font-size:90%;">IoU=0.5:0.9</span></th>
<th id="S4.T1.3.2.2.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T1.3.2.2.3.1" class="ltx_text" style="font-size:90%;">IoU=0.5</span></th>
<th id="S4.T1.3.2.2.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T1.3.2.2.4.1" class="ltx_text" style="font-size:90%;">IoU=0.65</span></th>
<th id="S4.T1.3.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T1.3.2.2.5.1" class="ltx_text" style="font-size:90%;">IoU=0.8</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T1.3.3.1" class="ltx_tr">
<td id="S4.T1.3.3.1.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T1.3.3.1.1.1" class="ltx_text" style="font-size:90%;">AutoFed</span></td>
<td id="S4.T1.3.3.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.3.3.1.2.1" class="ltx_text" style="font-size:90%;">0.461</span></td>
<td id="S4.T1.3.3.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.3.3.1.3.1" class="ltx_text" style="font-size:90%;">0.731</span></td>
<td id="S4.T1.3.3.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.3.3.1.4.1" class="ltx_text" style="font-size:90%;">0.698</span></td>
<td id="S4.T1.3.3.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.3.3.1.5.1" class="ltx_text" style="font-size:90%;">0.371</span></td>
</tr>
<tr id="S4.T1.3.4.2" class="ltx_tr">
<td id="S4.T1.3.4.2.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T1.3.4.2.1.1" class="ltx_text" style="font-size:90%;">w/o MCE</span></td>
<td id="S4.T1.3.4.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.3.4.2.2.1" class="ltx_text" style="font-size:90%;">0.405</span></td>
<td id="S4.T1.3.4.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.3.4.2.3.1" class="ltx_text" style="font-size:90%;">0.707</span></td>
<td id="S4.T1.3.4.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.3.4.2.4.1" class="ltx_text" style="font-size:90%;">0.660</span></td>
<td id="S4.T1.3.4.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.3.4.2.5.1" class="ltx_text" style="font-size:90%;">0.212</span></td>
</tr>
<tr id="S4.T1.3.5.3" class="ltx_tr">
<td id="S4.T1.3.5.3.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T1.3.5.3.1.1" class="ltx_text" style="font-size:90%;">w/o AE</span></td>
<td id="S4.T1.3.5.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.3.5.3.2.1" class="ltx_text" style="font-size:90%;">0.396</span></td>
<td id="S4.T1.3.5.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.3.5.3.3.1" class="ltx_text" style="font-size:90%;">0.692</span></td>
<td id="S4.T1.3.5.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.3.5.3.4.1" class="ltx_text" style="font-size:90%;">0.657</span></td>
<td id="S4.T1.3.5.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.3.5.3.5.1" class="ltx_text" style="font-size:90%;">0.189</span></td>
</tr>
<tr id="S4.T1.3.6.4" class="ltx_tr">
<td id="S4.T1.3.6.4.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T1.3.6.4.1.1" class="ltx_text" style="font-size:90%;">w/o CS</span></td>
<td id="S4.T1.3.6.4.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T1.3.6.4.2.1" class="ltx_text" style="font-size:90%;">0.342</span></td>
<td id="S4.T1.3.6.4.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T1.3.6.4.3.1" class="ltx_text" style="font-size:90%;">0.542</span></td>
<td id="S4.T1.3.6.4.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T1.3.6.4.4.1" class="ltx_text" style="font-size:90%;">0.523</span></td>
<td id="S4.T1.3.6.4.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T1.3.6.4.5.1" class="ltx_text" style="font-size:90%;">0.272</span></td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S4.SS7" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.7. </span>Hyper-parameter Evaluation</h3>

<section id="S4.SS7.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.7.1. </span>Loss Threshold</h4>

<div id="S4.SS7.SSS1.p1" class="ltx_para">
<p id="S4.SS7.SSS1.p1.7" class="ltx_p">As stated in § <a href="#S3.SS3.SSS1" title="3.3.1. Modified Loss Function for Tolerating Annotation Anomalies ‣ 3.3. AutoFed Framework ‣ 3. System Design ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3.1</span></a>, <math id="S4.SS7.SSS1.p1.1.m1.1" class="ltx_Math" alttext="p_{\mathrm{th}}" display="inline"><semantics id="S4.SS7.SSS1.p1.1.m1.1a"><msub id="S4.SS7.SSS1.p1.1.m1.1.1" xref="S4.SS7.SSS1.p1.1.m1.1.1.cmml"><mi id="S4.SS7.SSS1.p1.1.m1.1.1.2" xref="S4.SS7.SSS1.p1.1.m1.1.1.2.cmml">p</mi><mi id="S4.SS7.SSS1.p1.1.m1.1.1.3" xref="S4.SS7.SSS1.p1.1.m1.1.1.3.cmml">th</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS7.SSS1.p1.1.m1.1b"><apply id="S4.SS7.SSS1.p1.1.m1.1.1.cmml" xref="S4.SS7.SSS1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS7.SSS1.p1.1.m1.1.1.1.cmml" xref="S4.SS7.SSS1.p1.1.m1.1.1">subscript</csymbol><ci id="S4.SS7.SSS1.p1.1.m1.1.1.2.cmml" xref="S4.SS7.SSS1.p1.1.m1.1.1.2">𝑝</ci><ci id="S4.SS7.SSS1.p1.1.m1.1.1.3.cmml" xref="S4.SS7.SSS1.p1.1.m1.1.1.3">th</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS7.SSS1.p1.1.m1.1c">p_{\mathrm{th}}</annotation></semantics></math> is a threshold above which we believe that the classifier is more trustworthy than the manual annotations. On one hand, when <math id="S4.SS7.SSS1.p1.2.m2.1" class="ltx_Math" alttext="p_{\mathrm{th}}" display="inline"><semantics id="S4.SS7.SSS1.p1.2.m2.1a"><msub id="S4.SS7.SSS1.p1.2.m2.1.1" xref="S4.SS7.SSS1.p1.2.m2.1.1.cmml"><mi id="S4.SS7.SSS1.p1.2.m2.1.1.2" xref="S4.SS7.SSS1.p1.2.m2.1.1.2.cmml">p</mi><mi id="S4.SS7.SSS1.p1.2.m2.1.1.3" xref="S4.SS7.SSS1.p1.2.m2.1.1.3.cmml">th</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS7.SSS1.p1.2.m2.1b"><apply id="S4.SS7.SSS1.p1.2.m2.1.1.cmml" xref="S4.SS7.SSS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS7.SSS1.p1.2.m2.1.1.1.cmml" xref="S4.SS7.SSS1.p1.2.m2.1.1">subscript</csymbol><ci id="S4.SS7.SSS1.p1.2.m2.1.1.2.cmml" xref="S4.SS7.SSS1.p1.2.m2.1.1.2">𝑝</ci><ci id="S4.SS7.SSS1.p1.2.m2.1.1.3.cmml" xref="S4.SS7.SSS1.p1.2.m2.1.1.3">th</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS7.SSS1.p1.2.m2.1c">p_{\mathrm{th}}</annotation></semantics></math> is too small, the MCE loss and traditional CE loss are equivalent, and we cannot exclude incorrect gradients induced by missing annotation boxes. On the other hand, many real backgrounds can be mistakenly excluded if <math id="S4.SS7.SSS1.p1.3.m3.1" class="ltx_Math" alttext="p_{\mathrm{th}}" display="inline"><semantics id="S4.SS7.SSS1.p1.3.m3.1a"><msub id="S4.SS7.SSS1.p1.3.m3.1.1" xref="S4.SS7.SSS1.p1.3.m3.1.1.cmml"><mi id="S4.SS7.SSS1.p1.3.m3.1.1.2" xref="S4.SS7.SSS1.p1.3.m3.1.1.2.cmml">p</mi><mi id="S4.SS7.SSS1.p1.3.m3.1.1.3" xref="S4.SS7.SSS1.p1.3.m3.1.1.3.cmml">th</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS7.SSS1.p1.3.m3.1b"><apply id="S4.SS7.SSS1.p1.3.m3.1.1.cmml" xref="S4.SS7.SSS1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS7.SSS1.p1.3.m3.1.1.1.cmml" xref="S4.SS7.SSS1.p1.3.m3.1.1">subscript</csymbol><ci id="S4.SS7.SSS1.p1.3.m3.1.1.2.cmml" xref="S4.SS7.SSS1.p1.3.m3.1.1.2">𝑝</ci><ci id="S4.SS7.SSS1.p1.3.m3.1.1.3.cmml" xref="S4.SS7.SSS1.p1.3.m3.1.1.3">th</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS7.SSS1.p1.3.m3.1c">p_{\mathrm{th}}</annotation></semantics></math> is set too large. Therefore, we evaluate the impact of <math id="S4.SS7.SSS1.p1.4.m4.1" class="ltx_Math" alttext="p_{\mathrm{th}}" display="inline"><semantics id="S4.SS7.SSS1.p1.4.m4.1a"><msub id="S4.SS7.SSS1.p1.4.m4.1.1" xref="S4.SS7.SSS1.p1.4.m4.1.1.cmml"><mi id="S4.SS7.SSS1.p1.4.m4.1.1.2" xref="S4.SS7.SSS1.p1.4.m4.1.1.2.cmml">p</mi><mi id="S4.SS7.SSS1.p1.4.m4.1.1.3" xref="S4.SS7.SSS1.p1.4.m4.1.1.3.cmml">th</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS7.SSS1.p1.4.m4.1b"><apply id="S4.SS7.SSS1.p1.4.m4.1.1.cmml" xref="S4.SS7.SSS1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS7.SSS1.p1.4.m4.1.1.1.cmml" xref="S4.SS7.SSS1.p1.4.m4.1.1">subscript</csymbol><ci id="S4.SS7.SSS1.p1.4.m4.1.1.2.cmml" xref="S4.SS7.SSS1.p1.4.m4.1.1.2">𝑝</ci><ci id="S4.SS7.SSS1.p1.4.m4.1.1.3.cmml" xref="S4.SS7.SSS1.p1.4.m4.1.1.3">th</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS7.SSS1.p1.4.m4.1c">p_{\mathrm{th}}</annotation></semantics></math> on the AutoFed performance. As Figure <a href="#S4.F15.sf1" title="In Figure 15 ‣ 4.7.1. Loss Threshold ‣ 4.7. Hyper-parameter Evaluation ‣ 4. Performance Evaluation ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">15a</span></a> shows, the AP of vehicle detection increases from 0.7 to 0.73 as <math id="S4.SS7.SSS1.p1.5.m5.1" class="ltx_Math" alttext="p_{\mathrm{th}}" display="inline"><semantics id="S4.SS7.SSS1.p1.5.m5.1a"><msub id="S4.SS7.SSS1.p1.5.m5.1.1" xref="S4.SS7.SSS1.p1.5.m5.1.1.cmml"><mi id="S4.SS7.SSS1.p1.5.m5.1.1.2" xref="S4.SS7.SSS1.p1.5.m5.1.1.2.cmml">p</mi><mi id="S4.SS7.SSS1.p1.5.m5.1.1.3" xref="S4.SS7.SSS1.p1.5.m5.1.1.3.cmml">th</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS7.SSS1.p1.5.m5.1b"><apply id="S4.SS7.SSS1.p1.5.m5.1.1.cmml" xref="S4.SS7.SSS1.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S4.SS7.SSS1.p1.5.m5.1.1.1.cmml" xref="S4.SS7.SSS1.p1.5.m5.1.1">subscript</csymbol><ci id="S4.SS7.SSS1.p1.5.m5.1.1.2.cmml" xref="S4.SS7.SSS1.p1.5.m5.1.1.2">𝑝</ci><ci id="S4.SS7.SSS1.p1.5.m5.1.1.3.cmml" xref="S4.SS7.SSS1.p1.5.m5.1.1.3">th</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS7.SSS1.p1.5.m5.1c">p_{\mathrm{th}}</annotation></semantics></math> increases to 0.1. However, the AP rapidly decreases to around 0 at <math id="S4.SS7.SSS1.p1.6.m6.1" class="ltx_Math" alttext="p_{\mathrm{th}}=0.3" display="inline"><semantics id="S4.SS7.SSS1.p1.6.m6.1a"><mrow id="S4.SS7.SSS1.p1.6.m6.1.1" xref="S4.SS7.SSS1.p1.6.m6.1.1.cmml"><msub id="S4.SS7.SSS1.p1.6.m6.1.1.2" xref="S4.SS7.SSS1.p1.6.m6.1.1.2.cmml"><mi id="S4.SS7.SSS1.p1.6.m6.1.1.2.2" xref="S4.SS7.SSS1.p1.6.m6.1.1.2.2.cmml">p</mi><mi id="S4.SS7.SSS1.p1.6.m6.1.1.2.3" xref="S4.SS7.SSS1.p1.6.m6.1.1.2.3.cmml">th</mi></msub><mo id="S4.SS7.SSS1.p1.6.m6.1.1.1" xref="S4.SS7.SSS1.p1.6.m6.1.1.1.cmml">=</mo><mn id="S4.SS7.SSS1.p1.6.m6.1.1.3" xref="S4.SS7.SSS1.p1.6.m6.1.1.3.cmml">0.3</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS7.SSS1.p1.6.m6.1b"><apply id="S4.SS7.SSS1.p1.6.m6.1.1.cmml" xref="S4.SS7.SSS1.p1.6.m6.1.1"><eq id="S4.SS7.SSS1.p1.6.m6.1.1.1.cmml" xref="S4.SS7.SSS1.p1.6.m6.1.1.1"></eq><apply id="S4.SS7.SSS1.p1.6.m6.1.1.2.cmml" xref="S4.SS7.SSS1.p1.6.m6.1.1.2"><csymbol cd="ambiguous" id="S4.SS7.SSS1.p1.6.m6.1.1.2.1.cmml" xref="S4.SS7.SSS1.p1.6.m6.1.1.2">subscript</csymbol><ci id="S4.SS7.SSS1.p1.6.m6.1.1.2.2.cmml" xref="S4.SS7.SSS1.p1.6.m6.1.1.2.2">𝑝</ci><ci id="S4.SS7.SSS1.p1.6.m6.1.1.2.3.cmml" xref="S4.SS7.SSS1.p1.6.m6.1.1.2.3">th</ci></apply><cn type="float" id="S4.SS7.SSS1.p1.6.m6.1.1.3.cmml" xref="S4.SS7.SSS1.p1.6.m6.1.1.3">0.3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS7.SSS1.p1.6.m6.1c">p_{\mathrm{th}}=0.3</annotation></semantics></math>. Likewise, a similar trend can be observed in Figure <a href="#S4.F15.sf2" title="In Figure 15 ‣ 4.7.1. Loss Threshold ‣ 4.7. Hyper-parameter Evaluation ‣ 4. Performance Evaluation ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">15b</span></a> for AR of the vehicle detection. Overall, Figure <a href="#S4.F15" title="Figure 15 ‣ 4.7.1. Loss Threshold ‣ 4.7. Hyper-parameter Evaluation ‣ 4. Performance Evaluation ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">15</span></a> offers a guidance for choosing <math id="S4.SS7.SSS1.p1.7.m7.1" class="ltx_Math" alttext="p_{\mathrm{th}}" display="inline"><semantics id="S4.SS7.SSS1.p1.7.m7.1a"><msub id="S4.SS7.SSS1.p1.7.m7.1.1" xref="S4.SS7.SSS1.p1.7.m7.1.1.cmml"><mi id="S4.SS7.SSS1.p1.7.m7.1.1.2" xref="S4.SS7.SSS1.p1.7.m7.1.1.2.cmml">p</mi><mi id="S4.SS7.SSS1.p1.7.m7.1.1.3" xref="S4.SS7.SSS1.p1.7.m7.1.1.3.cmml">th</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS7.SSS1.p1.7.m7.1b"><apply id="S4.SS7.SSS1.p1.7.m7.1.1.cmml" xref="S4.SS7.SSS1.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S4.SS7.SSS1.p1.7.m7.1.1.1.cmml" xref="S4.SS7.SSS1.p1.7.m7.1.1">subscript</csymbol><ci id="S4.SS7.SSS1.p1.7.m7.1.1.2.cmml" xref="S4.SS7.SSS1.p1.7.m7.1.1.2">𝑝</ci><ci id="S4.SS7.SSS1.p1.7.m7.1.1.3.cmml" xref="S4.SS7.SSS1.p1.7.m7.1.1.3">th</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS7.SSS1.p1.7.m7.1c">p_{\mathrm{th}}</annotation></semantics></math>.</p>
</div>
<figure id="S4.F15" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F15.sf1" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S4.F15.sf1.1" class="ltx_block ltx_minipage ltx_align_bottom" style="width:203.8pt;">
<img src="/html/2302.08646/assets/x30.png" id="S4.F15.sf1.1.g1" class="ltx_graphics ltx_img_landscape" width="442" height="271" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>Average precision.</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F15.sf2" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S4.F15.sf2.1" class="ltx_block ltx_minipage ltx_align_bottom" style="width:203.8pt;">
<img src="/html/2302.08646/assets/x31.png" id="S4.F15.sf2.1.g1" class="ltx_graphics ltx_img_landscape" width="442" height="260" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Average recall.</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 15. </span>Impact of the MCE threshold.</figcaption>
</figure>
</section>
<section id="S4.SS7.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.7.2. </span>The Number of Selected Clients</h4>

<div id="S4.SS7.SSS2.p1" class="ltx_para">
<p id="S4.SS7.SSS2.p1.1" class="ltx_p">Another hyperparameter that significantly impacts the performance of AutoFed is the number of clients selected for model aggregation. On one hand, a small percentage of selected clients could not fully utilize the diverse data collected by different clients and introduce bias into the federated model. On the other hand, if a very large proportion of the clients are selected, we cannot effectively mitigate the detrimental effect caused by diverged local models. Therefore, the number of selected clients balances the tradeoff between utilizing data and excluding diverged models. As Figure <a href="#S4.F16.sf1" title="In Figure 16 ‣ 4.7.2. The Number of Selected Clients ‣ 4.7. Hyper-parameter Evaluation ‣ 4. Performance Evaluation ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">16a</span></a> shows, the AP of AutoFed first increases with a greater percentage of selected clients, but starts to drop after the percentage reaches 0.4. The reason is that as the excessive clients are selected for aggregation, the divergence among them will degrade the performance of the federated model. Furthermore, in Figure <a href="#S4.F16.sf2" title="In Figure 16 ‣ 4.7.2. The Number of Selected Clients ‣ 4.7. Hyper-parameter Evaluation ‣ 4. Performance Evaluation ‣ AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving" class="ltx_ref"><span class="ltx_text ltx_ref_tag">16b</span></a>, it can be seen that AR of AutoFed follows a similar trend as AP, and reaches its peak when the percentage of selected clients is 0.4.</p>
</div>
<figure id="S4.F16" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F16.sf1" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S4.F16.sf1.1" class="ltx_block ltx_minipage ltx_align_bottom" style="width:203.8pt;">
<img src="/html/2302.08646/assets/x32.png" id="S4.F16.sf1.1.g1" class="ltx_graphics ltx_img_landscape" width="442" height="272" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>Average precision.</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F16.sf2" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S4.F16.sf2.1" class="ltx_block ltx_minipage ltx_align_bottom" style="width:203.8pt;">
<img src="/html/2302.08646/assets/x33.png" id="S4.F16.sf2.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="442" height="261" alt="Refer to caption">
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Average recall.</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 16. </span>Impact of selected clients percentage.</figcaption>
</figure>
</section>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Related Work and Discussion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">Recent years have witnessed rapid developments in DNN-based OD methods <cite class="ltx_cite ltx_citemacro_citep">(Redmon et al<span class="ltx_text">.</span>, <a href="#bib.bib48" title="" class="ltx_ref">2016</a>; Liu et al<span class="ltx_text">.</span>, <a href="#bib.bib36" title="" class="ltx_ref">2016</a>; Lin et al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2017</a>; Girshick et al<span class="ltx_text">.</span>, <a href="#bib.bib16" title="" class="ltx_ref">2014</a>; Girshick, <a href="#bib.bib15" title="" class="ltx_ref">2015</a>; Ren et al<span class="ltx_text">.</span>, <a href="#bib.bib50" title="" class="ltx_ref">2015</a>)</cite>. These approaches have been applied to AD <cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib6" title="" class="ltx_ref">2017</a>; Yang et al<span class="ltx_text">.</span>, <a href="#bib.bib72" title="" class="ltx_ref">2018</a>; Li, <a href="#bib.bib28" title="" class="ltx_ref">2017</a>; Li et al<span class="ltx_text">.</span>, <a href="#bib.bib29" title="" class="ltx_ref">2016</a>)</cite>. Since most AVs are equipped with multiple sensors (e.g., lidar, radar, and camera), they become technology foundations for the OD systems to fully exploit the multimodal data by sensor fusion. Among various sensor fusion schemes, the combination of lidar and another sensor (e.g., radar or camera) <cite class="ltx_cite ltx_citemacro_citep">(Ku et al<span class="ltx_text">.</span>, <a href="#bib.bib26" title="" class="ltx_ref">2018</a>; Xu et al<span class="ltx_text">.</span>, <a href="#bib.bib71" title="" class="ltx_ref">2018</a>; Qi et al<span class="ltx_text">.</span>, <a href="#bib.bib45" title="" class="ltx_ref">2018</a>; Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib6" title="" class="ltx_ref">2017</a>; Liang et al<span class="ltx_text">.</span>, <a href="#bib.bib32" title="" class="ltx_ref">2018</a>; Qian et al<span class="ltx_text">.</span>, <a href="#bib.bib47" title="" class="ltx_ref">2021</a>)</cite> is a widely-adopted option due to the complements between each other <cite class="ltx_cite ltx_citemacro_citep">(Geiger et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2012</a>; Barnes et al<span class="ltx_text">.</span>, <a href="#bib.bib2" title="" class="ltx_ref">2019</a>)</cite>. One challenge in fusing lidar with other sensors is the unique data structure of lidar, i.e., 3-D point cloud, which is a point set and not compatible with the 2-D matrix in conventional computer vision tasks. One way to overcome this challenge is to employ specially designed DNNs, such as PointNet <cite class="ltx_cite ltx_citemacro_citep">(Qi et al<span class="ltx_text">.</span>, <a href="#bib.bib46" title="" class="ltx_ref">2017</a>)</cite>, to directly extract features from point clouds and fuse with other sensing data in the feature space <cite class="ltx_cite ltx_citemacro_citep">(Xu et al<span class="ltx_text">.</span>, <a href="#bib.bib71" title="" class="ltx_ref">2018</a>)</cite>. Another approach is voxelization via transforming the point cloud to 3-D data formats like images, with the height dimension being deemed as image channels. Therefore, the transformed point clouds can be handled by conventional OD-DNNs and fused with other modalities as demonstrated in <cite class="ltx_cite ltx_citemacro_citep">(Yang et al<span class="ltx_text">.</span>, <a href="#bib.bib72" title="" class="ltx_ref">2018</a>; Simon et al<span class="ltx_text">.</span>, <a href="#bib.bib53" title="" class="ltx_ref">2019</a>; Zhou and Tuzel, <a href="#bib.bib80" title="" class="ltx_ref">2018</a>; Luo et al<span class="ltx_text">.</span>, <a href="#bib.bib38" title="" class="ltx_ref">2018</a>)</cite>.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">FL <cite class="ltx_cite ltx_citemacro_citep">(Konečnỳ et al<span class="ltx_text">.</span>, <a href="#bib.bib25" title="" class="ltx_ref">2014</a>)</cite> is a distributed machine learning paradigm that transfers only model weights
instead of explicitly sharing raw data with the central server. AutoFed employs FL to enable data crowdsensing without breaching privacy and incurring unaffordable communication cost on AVs. Despite recent FL applications in classification and regression tasks <cite class="ltx_cite ltx_citemacro_citep">(Konečnỳ et al<span class="ltx_text">.</span>, <a href="#bib.bib25" title="" class="ltx_ref">2014</a>; Li et al<span class="ltx_text">.</span>, <a href="#bib.bib31" title="" class="ltx_ref">2020</a>, <a href="#bib.bib27" title="" class="ltx_ref">2021</a>; Tu et al<span class="ltx_text">.</span>, <a href="#bib.bib59" title="" class="ltx_ref">2021</a>; Rehman et al<span class="ltx_text">.</span>, <a href="#bib.bib49" title="" class="ltx_ref">2022</a>; So et al<span class="ltx_text">.</span>, <a href="#bib.bib55" title="" class="ltx_ref">2022</a>)</cite>, applying FL to more sophisticated computer vision tasks such as OD (especially vehicle detection) is far from being exploited. In <cite class="ltx_cite ltx_citemacro_citep">(Jallepalli et al<span class="ltx_text">.</span>, <a href="#bib.bib23" title="" class="ltx_ref">2021</a>)</cite>, the authors investigate the possibility of applying FL to AD applications, and conduct preliminary experiments to verify privacy protection and convergence speed. FedVision <cite class="ltx_cite ltx_citemacro_citep">(Liu et al<span class="ltx_text">.</span>, <a href="#bib.bib37" title="" class="ltx_ref">2020</a>)</cite> proposes an online visual OD platform powered by FL,
but it focuses more on building and deploying a cloud-based platform, without concerning much on FL-related designs.
Fjord <cite class="ltx_cite ltx_citemacro_citep">(Horvath et al<span class="ltx_text">.</span>, <a href="#bib.bib21" title="" class="ltx_ref">2021</a>)</cite> claims to target the data heterogeneity in FL, yet it seems to have missed certain complicated aspects,
such as annotation and modality heterogeneity tackled in AutoFed.</p>
</div>
<div id="S5.p3" class="ltx_para">
<p id="S5.p3.1" class="ltx_p">While different from existing OD proposals by pioneering federated OD on AVs, AutoFed is also the first to take into account the effects of all kinds of multimodal heterogeneity for FL-OD on AVs.
However, AutoFed still bears one limitation: it stresses on the FL aspect of crowdsensing, pessimistically assuming a finite number of clients unable to provide complete annotations. In other words, we have not considered positive aspects innate to crowdsensing <cite class="ltx_cite ltx_citemacro_citep">(Cherian et al<span class="ltx_text">.</span>, <a href="#bib.bib8" title="" class="ltx_ref">2016</a>; Wang et al<span class="ltx_text">.</span>, <a href="#bib.bib66" title="" class="ltx_ref">2017</a>)</cite>, such the impact of client incentive <cite class="ltx_cite ltx_citemacro_citep">(Han et al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2016b</a>, <a href="#bib.bib17" title="" class="ltx_ref">a</a>)</cite>. In a future study, we will extend the design goals of AutoFed to include designing proper incentives, in order to expand its user base and attract more AV owners to perform collective learning on distributed AV data and thus guarantee AutoFed service quality.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6. </span>Conclusion</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">Taking an important step towards full driving automation, we have proposed AutoFed in this paper for federated multimodal vehicle detection. Employing a novel loss function, data imputation technique, and client selection strategy, the AutoFed framework gracefully handles the multimodal data crowdsensed by multiple AV clients, and mines information in the highly heterogeneous data to its maximum, thus releasing its full potential in the vehicle detection task. With extensive experiments under highly heterogeneous scenarios and comparisons with other baselines, we have demonstrated the promising performance of AutoFed in vehicle detection for autonomous driving. We plan to extend AutoFed framework to encompass more sensing modalities,
in order to promote its real-life usage and wider acceptance.</p>
</div>
<div id="S6.p2" class="ltx_para">
<p id="S6.p2.1" class="ltx_p">Currently, AutoFed targets on FL-driven vehicle detection, but we are planning to apply FL to other out-vehicle sensing tasks, such as pedestrian detection, lane tracking, and environment semantic segmentation. Moreover, modern vehicles are also equipped with in-vehicle sensing modalities to improve user experience, and we believe FL can help improve the performance of deep analytics upon these modalities too.
Therefore, we are actively exploring the potential of using FL for full vehicle intelligence, particularly for in-vehicle user monitoring (e.g., <cite class="ltx_cite ltx_citemacro_citep">(Ding et al<span class="ltx_text">.</span>, <a href="#bib.bib11" title="" class="ltx_ref">2020</a>; Zheng et al<span class="ltx_text">.</span>, <a href="#bib.bib79" title="" class="ltx_ref">2021</a>; Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib7" title="" class="ltx_ref">2021</a>)</cite>);
this should put us on the right track towards a future with full intelligent transportation.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgement</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">We are grateful to anonymous reviewers for their constructive suggestions. This research was support in part by National Research Foundation (NRF) Future Communications Research &amp; Development Programme (FCP) grant FCP-NTU-RG-2022-015 and MOE Tier 1 Grant RG16/22. We further thank ERI@N and NTU-IGP for supporting the PhD scholarship of Tianyue Zheng.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">        




</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Barnes et al<span id="bib.bib2.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Dan Barnes, Matthew Gadd,
Paul Murcutt, Paul Newman, and
Ingmar Posner. 2019.

</span>
<span class="ltx_bibblock">The Oxford Radar RobotCar Dataset: A Radar
Extension to the Oxford RobotCar Dataset.

</span>
<span class="ltx_bibblock"><em id="bib.bib2.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv: 1909.01300</em>
(2019).

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://arxiv.org/pdf/1909.01300" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/pdf/1909.01300</a>

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bentley (1975)</span>
<span class="ltx_bibblock">
Jon Louis Bentley.
1975.

</span>
<span class="ltx_bibblock">Multidimensional Binary Search Trees used for
Associative Searching.

</span>
<span class="ltx_bibblock"><em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">Commun. ACM</em> 18,
9 (1975), 509–517.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bijelic et al<span id="bib.bib4.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Mario Bijelic, Tobias
Gruber, Fahim Mannan, Florian Kraus,
Werner Ritter, Klaus Dietmayer, and
Felix Heide. 2020.

</span>
<span class="ltx_bibblock">Seeing through Fog without Seeing Fog: Deep
Multimodal Sensor Fusion in Unseen Adverse Weather. In
<em id="bib.bib4.3.1" class="ltx_emph ltx_font_italic">Proc, of the 33rd IEEE/CVF CVPR</em>.
11682–11692.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Caesar et al<span id="bib.bib5.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Holger Caesar, Varun
Bankiti, Alex H Lang, Sourabh Vora,
Venice Erin Liong, Qiang Xu,
Anush Krishnan, Yu Pan,
Giancarlo Baldan, and Oscar Beijbom.
2020.

</span>
<span class="ltx_bibblock">nuScenes: A Multimodal Dataset for Autonomous
Driving. In <em id="bib.bib5.3.1" class="ltx_emph ltx_font_italic">Proc. of the 33rd IEEE/CVF CVPR</em>.
11621–11631.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al<span id="bib.bib6.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Xiaozhi Chen, Huimin Ma,
Ji Wan, Bo Li, and
Tian Xia. 2017.

</span>
<span class="ltx_bibblock">Multi-view 3D Object Detection Network for
Autonomous Driving. In <em id="bib.bib6.3.1" class="ltx_emph ltx_font_italic">Proc. of the 30st IEEE/CVF
CVPR</em>. 1907–1915.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al<span id="bib.bib7.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Zhe Chen, Tianyue Zheng,
and Jun Luo. 2021.

</span>
<span class="ltx_bibblock">MoVi-Fi: Motion-robust Vital Signs Waveform
Recovery via Deep Interpreted RF Sensing. In
<em id="bib.bib7.3.1" class="ltx_emph ltx_font_italic">Proc. of the 27th ACM MobiCom</em>.
392–405.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cherian et al<span id="bib.bib8.2.2.1" class="ltx_text">.</span> (2016)</span>
<span class="ltx_bibblock">
Jim Cherian, Jun Luo,
Hongliang Guo, Shen-Shyang Ho, and
Richard Wisbrun. 2016.

</span>
<span class="ltx_bibblock">ParkGauge: Gauging the Occupancy of Parking Garages
with Crowdsensed Parking Characteristics.

</span>
<span class="ltx_bibblock">, 92-101 pages.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Committee et al<span id="bib.bib9.2.2.1" class="ltx_text">.</span> (2014)</span>
<span class="ltx_bibblock">
SAE On-Road Automated Vehicle Standards
Committee et al<span id="bib.bib9.3.1" class="ltx_text">.</span> 2014.

</span>
<span class="ltx_bibblock">Taxonomy and Definitions for Terms Related to
On-road Motor Vehicle Automated Driving Systems.

</span>
<span class="ltx_bibblock"><em id="bib.bib9.4.1" class="ltx_emph ltx_font_italic">SAE Standard J</em> 3016
(2014), 1–16.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">De Montjoye et al<span id="bib.bib10.2.2.1" class="ltx_text">.</span> (2013)</span>
<span class="ltx_bibblock">
Yves-Alexandre De Montjoye,
César A Hidalgo, Michel Verleysen,
and Vincent D. Blondel. 2013.

</span>
<span class="ltx_bibblock">Unique in the Crowd: The Privacy Bounds of Human
Mobility.

</span>
<span class="ltx_bibblock"><em id="bib.bib10.3.1" class="ltx_emph ltx_font_italic">Scientific Reports</em> 3,
1 (2013), 1376:1–5.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ding et al<span id="bib.bib11.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Shuya Ding, Zhe Chen,
Tianyue Zheng, and Jun Luo.
2020.

</span>
<span class="ltx_bibblock">RF-Net: A Unified Meta-Learning Framework for
RF-enabled One-Shot Human Activity Recognition. In
<em id="bib.bib11.3.1" class="ltx_emph ltx_font_italic">Proc. of the 18th ACM SenSys</em>.
517–530.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fallah et al<span id="bib.bib12.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Alireza Fallah, Aryan
Mokhtari, and Asuman Ozdaglar.
2020.

</span>
<span class="ltx_bibblock">Personalized Federated Learning with Theoretical
Guarantees: A Model-Agnostic Meta-Learning Approach. In
<em id="bib.bib12.3.1" class="ltx_emph ltx_font_italic">Proc. of The 34th NeurIPS</em>.
1–12.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ganti et al<span id="bib.bib13.2.2.1" class="ltx_text">.</span> (2011)</span>
<span class="ltx_bibblock">
Raghu K. Ganti, Fan Ye,
and Hui Lei. 2011.

</span>
<span class="ltx_bibblock">Mobile Crowdsensing: Current State and Future
Challenges.

</span>
<span class="ltx_bibblock"><em id="bib.bib13.3.1" class="ltx_emph ltx_font_italic">IEEE Communications Magazine</em>
49, 11 (2011),
32–39.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Geiger et al<span id="bib.bib14.2.2.1" class="ltx_text">.</span> (2012)</span>
<span class="ltx_bibblock">
Andreas Geiger, Philip
Lenz, and Raquel Urtasun.
2012.

</span>
<span class="ltx_bibblock">Are We Ready for Autonomous Driving? The KITTI
Vision Benchmark Suite. In <em id="bib.bib14.3.1" class="ltx_emph ltx_font_italic">Proc. of the 25th
IEEE/CVF CVPR</em>. IEEE, 3354–3361.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Girshick (2015)</span>
<span class="ltx_bibblock">
Ross Girshick.
2015.

</span>
<span class="ltx_bibblock">Fast R-CNN. In <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">Proc.
of the 29th IEEE ICCV</em>. 1440–1448.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Girshick et al<span id="bib.bib16.2.2.1" class="ltx_text">.</span> (2014)</span>
<span class="ltx_bibblock">
Ross Girshick, Jeff
Donahue, Trevor Darrell, and Jitendra
Malik. 2014.

</span>
<span class="ltx_bibblock">Rich Feature Hierarchies for Accurate Object
Detection and Semantic Segmentation. In <em id="bib.bib16.3.1" class="ltx_emph ltx_font_italic">Proc. of
the 27th IEEE/CVF CVPR</em>. 580–587.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Han et al<span id="bib.bib17.2.2.1" class="ltx_text">.</span> (2016a)</span>
<span class="ltx_bibblock">
Kai Han, He Huang, and
Jun Luo. 2016a.

</span>
<span class="ltx_bibblock">Posted Pricing for Robust Crowdsensing. In
<em id="bib.bib17.3.1" class="ltx_emph ltx_font_italic">Proc. of the 17th ACM MobiHoc</em>.
261–270.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Han et al<span id="bib.bib18.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Kai Han, He Huang, and
Jun Luo. 2018.

</span>
<span class="ltx_bibblock">Quality-Aware Pricing for Mobile Crowdsensing.

</span>
<span class="ltx_bibblock"><em id="bib.bib18.3.1" class="ltx_emph ltx_font_italic">IEEE/ACM Transactions on Networking</em>
26, 4 (2018),
1728–1741.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Han et al<span id="bib.bib19.2.2.1" class="ltx_text">.</span> (2016b)</span>
<span class="ltx_bibblock">
Kai Han, Chi Zhang,
Jun Luo, Menglan Hu, and
Bharadwaj Veeravalli. 2016b.

</span>
<span class="ltx_bibblock">Truthful Scheduling Mechanisms for Powering Mobile
Crowdsensing.

</span>
<span class="ltx_bibblock"><em id="bib.bib19.3.1" class="ltx_emph ltx_font_italic">IEEE Trans. Comput.</em> 65,
1 (2016), 294–307.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et al<span id="bib.bib20.2.2.1" class="ltx_text">.</span> (2016)</span>
<span class="ltx_bibblock">
Kaiming He, Xiangyu
Zhang, Shaoqing Ren, and Jian Sun.
2016.

</span>
<span class="ltx_bibblock">Deep Residual Learning for Image Recognition. In
<em id="bib.bib20.3.1" class="ltx_emph ltx_font_italic">Proc. of the 29th IEEE/CVF CVPR</em>.
770–778.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Horvath et al<span id="bib.bib21.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Samuel Horvath, Stefanos
Laskaridis, Mario Almeida, Ilias
Leontiadis, Stylianos Venieris, and
Nicholas Lane. 2021.

</span>
<span class="ltx_bibblock">Fjord: Fair and Accurate Federated Learning under
Heterogeneous Targets with Ordered Dropout.

</span>
<span class="ltx_bibblock"><em id="bib.bib21.3.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing
Systems</em> 34 (2021),
12876–12889.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Intel Corporation (2022)</span>
<span class="ltx_bibblock">
Intel Corporation.
2022.

</span>
<span class="ltx_bibblock">Intel Xeon Gold 6226 Processor.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.intel.com/content/www/xa/en/products/sku/193957/intel-xeon-gold-6226-processor-19-25m-cache-2-70-ghz/specifications.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.intel.com/content/www/xa/en/products/sku/193957/intel-xeon-gold-6226-processor-19-25m-cache-2-70-ghz/specifications.html</a>.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">Accessed: 2022-07-28.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jallepalli et al<span id="bib.bib23.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Deepthi Jallepalli,
Navya Chennagiri Ravikumar,
Poojitha Vurtur Badarinath, Shravya
Uchil, and Mahima Agumbe Suresh.
2021.

</span>
<span class="ltx_bibblock">Federated Learning for Object Detection in
Autonomous Vehicles. In <em id="bib.bib23.3.1" class="ltx_emph ltx_font_italic">2021 IEEE Seventh
International Conference on Big Data Computing Service and Applications
(BigDataService)</em>. 107–114.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kilic et al<span id="bib.bib24.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Velat Kilic, Deepti
Hegde, Vishwanath Sindagi, A Brinton
Cooper, Mark A Foster, and Vishal M
Patel. 2021.

</span>
<span class="ltx_bibblock">Lidar Light Scattering Augmentation (LISA):
Physics-based Simulation of Adverse Weather Conditions for 3D Object
Detection.

</span>
<span class="ltx_bibblock"><em id="bib.bib24.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2107.07004</em>
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Konečnỳ et al<span id="bib.bib25.2.2.1" class="ltx_text">.</span> (2014)</span>
<span class="ltx_bibblock">
Jakub Konečnỳ,
H Brendan McMahan, Felix X Yu,
Peter Richtárik, Ananda Theertha
Suresh, and Dave Bacon.
2014.

</span>
<span class="ltx_bibblock">Federated Learning: Strategies for Improving
Communication Efficiency. In <em id="bib.bib25.3.1" class="ltx_emph ltx_font_italic">NIPS Workshop on
Private Multi-Party Machine Learning</em>. 1–10.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ku et al<span id="bib.bib26.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Jason Ku, Melissa
Mozifian, Jungwook Lee, Ali Harakeh,
and Steven L. Waslander.
2018.

</span>
<span class="ltx_bibblock">Joint 3D Proposal Generation and Object Detection
from View Aggregation. In <em id="bib.bib26.3.1" class="ltx_emph ltx_font_italic">Proc. of IEEE/RSJ
IROS</em>. 1–8.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib27.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Ang Li, Jingwei Sun,
Xiao Zeng, Mi Zhang, Hai
Li, and Yiran Chen. 2021.

</span>
<span class="ltx_bibblock">FedMask: Joint Computation and
Communication-efficient Personalized Federated Learning via Heterogeneous
Masking. In <em id="bib.bib27.3.1" class="ltx_emph ltx_font_italic">Proc. of the 19th ACM SenSys</em>.
42–55.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li (2017)</span>
<span class="ltx_bibblock">
Bo Li. 2017.

</span>
<span class="ltx_bibblock">3D Fully Convolutional Network for Vehicle
Detection in Point Cloud. In <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">Proc. of IEEE/RSJ
IROS</em>. 1513–1518.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib29.2.2.1" class="ltx_text">.</span> (2016)</span>
<span class="ltx_bibblock">
Bo Li, Tianlei Zhang,
and Tian Xia. 2016.

</span>
<span class="ltx_bibblock">Vehicle Detection from 3D Lidar using Fully
Convolutional Network.

</span>
<span class="ltx_bibblock"><em id="bib.bib29.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1608.07916</em>
(2016).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib30.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Hao Li, Zheng Xu,
Gavin Taylor, Christoph Studer, and
Tom Goldstein. 2018.

</span>
<span class="ltx_bibblock">Visualizing the Loss Landscape of Neural Nets.

</span>
<span class="ltx_bibblock"><em id="bib.bib30.3.1" class="ltx_emph ltx_font_italic">Proc. of NeurIPS</em> 31
(2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib31.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Tian Li, Anit Kumar Sahu,
Manzil Zaheer, Maziar Sanjabi,
Ameet Talwalkar, and Virginia Smith.
2020.

</span>
<span class="ltx_bibblock">Federated Optimization in Heterogeneous
Networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib31.3.1" class="ltx_emph ltx_font_italic">Proc. of MLSys</em> 2
(2020), 429–450.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liang et al<span id="bib.bib32.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Ming Liang, Bin Yang,
Shenlong Wang, and Raquel Urtasun.
2018.

</span>
<span class="ltx_bibblock">Deep Continuous Fusion for Multi-sensor 3D Object
Detection. In <em id="bib.bib32.3.1" class="ltx_emph ltx_font_italic">Proc. of the 12th ECCV</em>.
641–656.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et al<span id="bib.bib33.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Tsung-Yi Lin, Priya
Goyal, Ross Girshick, Kaiming He, and
Piotr Dollár. 2017.

</span>
<span class="ltx_bibblock">Focal Loss for Dense Object Detection. In
<em id="bib.bib33.3.1" class="ltx_emph ltx_font_italic">Proc. of the 31st IEEE ICCV</em>.
2980–2988.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et al<span id="bib.bib34.2.2.1" class="ltx_text">.</span> (2014)</span>
<span class="ltx_bibblock">
Tsung-Yi Lin, Michael
Maire, Serge Belongie, James Hays,
Pietro Perona, Deva Ramanan,
Piotr Dollár, and C Lawrence
Zitnick. 2014.

</span>
<span class="ltx_bibblock">Microsoft COCO: Common Objects in Context. In
<em id="bib.bib34.3.1" class="ltx_emph ltx_font_italic">Proc. of the 8th ECCV</em>. 740–755.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu and Niu (2021)</span>
<span class="ltx_bibblock">
Meng Liu and Jianwei
Niu. 2021.

</span>
<span class="ltx_bibblock">BEV-Net: A Bird’s Eye View Object Detection
Network for LiDAR Point Cloud. In <em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">Proc. of
IEEE/RSJ IROS</em>. 5973–5980.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al<span id="bib.bib36.2.2.1" class="ltx_text">.</span> (2016)</span>
<span class="ltx_bibblock">
Wei Liu, Dragomir
Anguelov, Dumitru Erhan, Christian
Szegedy, Scott Reed, Cheng-Yang Fu,
and Alexander C. Berg. 2016.

</span>
<span class="ltx_bibblock">SSD: Single Shot Multibox Detector. In
<em id="bib.bib36.3.1" class="ltx_emph ltx_font_italic">Proc. of the 10th ECCV</em>. 21–37.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al<span id="bib.bib37.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Yang Liu, Anbu Huang,
Yun Luo, He Huang,
Youzhi Liu, Yuanyuan Chen,
Lican Feng, Tianjian Chen,
Han Yu, and Qiang Yang.
2020.

</span>
<span class="ltx_bibblock">Fedvision: An Online Visual Object Detection
Platform Powered by Federated Learning. In <em id="bib.bib37.3.1" class="ltx_emph ltx_font_italic">Proc.
of the 34th AAAI</em>, Vol. 34. 13172–13179.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Luo et al<span id="bib.bib38.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Wenjie Luo, Bin Yang,
and Raquel Urtasun. 2018.

</span>
<span class="ltx_bibblock">Fast and Furious: Real Time End-to-end 3D
Detection, Tracking and Motion Forecasting with a Single Convolutional Net.
In <em id="bib.bib38.3.1" class="ltx_emph ltx_font_italic">Proc. of the 31st IEEE/CVF CVPR</em>.
3569–3577.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McMahan et al<span id="bib.bib39.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Brendan McMahan, Eider
Moore, Daniel Ramage, Seth Hampson,
and Blaise Aguera y. Arcas.
2017.

</span>
<span class="ltx_bibblock">Communication-efficient Learning of Deep Networks
from Decentralized Data. In <em id="bib.bib39.3.1" class="ltx_emph ltx_font_italic">Proc. of the 20th
PMLR AISTATS</em>. 1273–1282.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Navtech Radar (2022)</span>
<span class="ltx_bibblock">
Navtech Radar.
2022.

</span>
<span class="ltx_bibblock">ClearWay Intelligent Transport Systems Solution.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://navtechradar.com/solutions/clearway/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://navtechradar.com/solutions/clearway/</a>.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">Accessed: 2022-07-28.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">NVIDIA (2022)</span>
<span class="ltx_bibblock">
NVIDIA. 2022.

</span>
<span class="ltx_bibblock">Jetson TX2 Module.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://developer.nvidia.com/embedded/jetson-tx2" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://developer.nvidia.com/embedded/jetson-tx2</a>.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">Accessed: 2022-07-28.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Paszke et al<span id="bib.bib42.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Adam Paszke, Sam Gross,
Francisco Massa, Adam Lerer,
James Bradbury, Gregory Chanan,
Trevor Killeen, Zeming Lin,
Natalia Gimelshein, Luca Antiga,
et al<span id="bib.bib42.3.1" class="ltx_text">.</span> 2019.

</span>
<span class="ltx_bibblock">PyTorch: An Imperative Style, High-Performance
Deep Learning Library.

</span>
<span class="ltx_bibblock"><em id="bib.bib42.4.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1912.01703</em>
(2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pearson (1901)</span>
<span class="ltx_bibblock">
Karl Pearson.
1901.

</span>
<span class="ltx_bibblock">On Lines and Planes of Closest Fit to Systems of
Points in Space.

</span>
<span class="ltx_bibblock"><em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">The London, Edinburgh, and Dublin
Philosophical Magazine and Journal of Science</em> 2,
11 (1901), 559–572.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Petrovskaya and Thrun (2009)</span>
<span class="ltx_bibblock">
Anna Petrovskaya and
Sebastian Thrun. 2009.

</span>
<span class="ltx_bibblock">Model based Vehicle Detection and Tracking for
Autonomous Urban Driving.

</span>
<span class="ltx_bibblock"><em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">Autonomous Robots</em> 26,
2 (2009), 123–139.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qi et al<span id="bib.bib45.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Charles R Qi, Wei Liu,
Chenxia Wu, Hao Su, and
Leonidas J. Guibas. 2018.

</span>
<span class="ltx_bibblock">Frustum Pointnets for 3D Object Detection from
RGB-D Data. In <em id="bib.bib45.3.1" class="ltx_emph ltx_font_italic">Proc. of the 31st IEEE/CVF CVPR</em>.
918–927.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qi et al<span id="bib.bib46.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Charles R. Qi, Hao Su,
Kaichun Mo, and Leonidas J. Guibas.
2017.

</span>
<span class="ltx_bibblock">PointNet: Deep Learning on Point Sets for 3D
Classification and Segmentation. In <em id="bib.bib46.3.1" class="ltx_emph ltx_font_italic">Proc. of the
30th IEEE/CVF CVPR</em>. 652–660.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qian et al<span id="bib.bib47.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Kun Qian, Shilin Zhu,
Xinyu Zhang, and Li Erran Li.
2021.

</span>
<span class="ltx_bibblock">Robust Multimodal Vehicle Detection in Foggy
Weather using Complementary Lidar and Radar Signals. In
<em id="bib.bib47.3.1" class="ltx_emph ltx_font_italic">Proc. of the 34th IEEE/CVF CVPR</em>.
444–453.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Redmon et al<span id="bib.bib48.2.2.1" class="ltx_text">.</span> (2016)</span>
<span class="ltx_bibblock">
Joseph Redmon, Santosh
Divvala, Ross Girshick, and Ali
Farhadi. 2016.

</span>
<span class="ltx_bibblock">You Only Look Once: Unified, Real-time Object
Detection. In <em id="bib.bib48.3.1" class="ltx_emph ltx_font_italic">Proc. of the 29th IEEE/CVF CVPR</em>.
779–788.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rehman et al<span id="bib.bib49.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Yasar Abbas Ur Rehman, Yan
Gao, Jiajun Shen, Pedro Porto Buarque de
Gusmao, and Nicholas Lane.
2022.

</span>
<span class="ltx_bibblock">Federated Self-supervised Learning for Video
Understanding.

</span>
<span class="ltx_bibblock"><em id="bib.bib49.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2207.01975</em>
(2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ren et al<span id="bib.bib50.2.2.1" class="ltx_text">.</span> (2015)</span>
<span class="ltx_bibblock">
Shaoqing Ren, Kaiming He,
Ross Girshick, and Jian Sun.
2015.

</span>
<span class="ltx_bibblock">Faster R-CNN: Towards Real-Time Object Detection
with Region Proposal Networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib50.3.1" class="ltx_emph ltx_font_italic">Proc. of The 29th NIPS</em>
28 (2015).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Scalabel (2022)</span>
<span class="ltx_bibblock">
Scalabel.
2022.

</span>
<span class="ltx_bibblock">Scalabel A Scalable Open-source Web Annotation
Tool.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.scalabel.ai/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.scalabel.ai/</a>.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">Accessed: 2022-07-28.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shaheen and Bouzaghrane (2019)</span>
<span class="ltx_bibblock">
Susan Shaheen and
Mohamed Amine Bouzaghrane.
2019.

</span>
<span class="ltx_bibblock">Mobility and Energy Impacts of Shared Automated
Vehicles: A Review of Recent Literature.

</span>
<span class="ltx_bibblock"><em id="bib.bib52.1.1" class="ltx_emph ltx_font_italic">Current Sustainable/Renewable Energy
Reports</em> 6, 4 (2019),
193–200.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Simon et al<span id="bib.bib53.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Martin Simon, Karl
Amende, Andrea Kraus, Jens Honer,
Timo Samann, Hauke Kaulbersch,
Stefan Milz, and Horst Michael Gross.
2019.

</span>
<span class="ltx_bibblock">Complexer-YOLO: Real-Time 3D Object Detection and
Tracking on Semantic Point Clouds. In <em id="bib.bib53.3.1" class="ltx_emph ltx_font_italic">Proc. of
the 32nd IEEE/CVF CVPR Workshops</em>. 1–10.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Simonyan and Zisserman (2014)</span>
<span class="ltx_bibblock">
Karen Simonyan and
Andrew Zisserman. 2014.

</span>
<span class="ltx_bibblock">Very Deep Convolutional Networks for Large-Scale
Image Recognition.

</span>
<span class="ltx_bibblock"><em id="bib.bib54.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1409.1556</em>
(2014).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">So et al<span id="bib.bib55.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Jinhyun So, Kevin Hsieh,
Behnaz Arzani, Shadi Noghabi,
Salman Avestimehr, and Ranveer
Chandra. 2022.

</span>
<span class="ltx_bibblock">Fedspace: An Efficient Federated Learning
Framework at Satellites and Ground Stations.

</span>
<span class="ltx_bibblock"><em id="bib.bib55.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2202.01267</em>
(2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tang et al<span id="bib.bib56.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Minxue Tang, Xuefei Ning,
Yitu Wang, Jingwei Sun,
Yu Wang, Hai Li, and
Yiran Chen. 2022.

</span>
<span class="ltx_bibblock">FedCor: Correlation-Based Active Client Selection
Strategy for Heterogeneous Federated Learning. In
<em id="bib.bib56.3.1" class="ltx_emph ltx_font_italic">Proc. of the 35th IEEE/CVF CVPR</em>.
10102–10111.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tesla (2022)</span>
<span class="ltx_bibblock">
Tesla. 2022.

</span>
<span class="ltx_bibblock">Autopilot: Future of Driving.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.tesla.com/en_SG/autopilot" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.tesla.com/en_SG/autopilot</a>.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">Accessed: 2022-07-25.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Toyota Motor Sales, U.S.A., Inc. (2022)</span>
<span class="ltx_bibblock">
Toyota Motor Sales, U.S.A., Inc.
2022.

</span>
<span class="ltx_bibblock">2022 Corolla Discover Corolla. Uncover Fun.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.toyota.com/corolla/2022/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.toyota.com/corolla/2022/</a>.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">Accessed: 2022-07-28.

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tu et al<span id="bib.bib59.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Linlin Tu, Xiaomin
Ouyang, Jiayu Zhou, Yuze He, and
Guoliang Xing. 2021.

</span>
<span class="ltx_bibblock">FedDL: Federated Learning via Dynamic Layer
Sharing for Human Activity Recognition. In <em id="bib.bib59.3.1" class="ltx_emph ltx_font_italic">Proc.
of the 19th ACM SenSys</em>. 15–28.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Uber Technologies Inc. (2022)</span>
<span class="ltx_bibblock">
Uber Technologies Inc.
2022.

</span>
<span class="ltx_bibblock">Self-Driving Perception &amp; Prediction.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.uber.com/us/en/atg/research-and-development/perception-and-prediction/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.uber.com/us/en/atg/research-and-development/perception-and-prediction/</a>.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">Accessed: 2022-07-25.

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Van Buuren (2018)</span>
<span class="ltx_bibblock">
Stef Van Buuren.
2018.

</span>
<span class="ltx_bibblock"><em id="bib.bib61.1.1" class="ltx_emph ltx_font_italic">Flexible Imputation of Missing Data</em>.

</span>
<span class="ltx_bibblock">CRC press.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vaswani et al<span id="bib.bib62.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Ashish Vaswani, Noam
Shazeer, Niki Parmar, Jakob Uszkoreit,
Llion Jones, Aidan N. Gomez,
Łukasz Kaiser, and Illia
Polosukhin. 2017.

</span>
<span class="ltx_bibblock">Attention is All You Need.

</span>
<span class="ltx_bibblock"><em id="bib.bib62.3.1" class="ltx_emph ltx_font_italic">Proc. of the 31st NIPS</em>
30 (2017), 1–11.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Velodyne Lidar, Inc. (2022)</span>
<span class="ltx_bibblock">
Velodyne Lidar, Inc.
2022.

</span>
<span class="ltx_bibblock">HDL-32E High Resolution Real-Time 3D Lidar Sensor.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://velodynelidar.com/products/hdl-32e/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://velodynelidar.com/products/hdl-32e/</a>.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">Accessed: 2022-07-28.

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vergara-Laurens et al<span id="bib.bib64.2.2.1" class="ltx_text">.</span> (2016)</span>
<span class="ltx_bibblock">
Idalides J. Vergara-Laurens,
Luis G. Jaimes, and Miguel A.
Labrador. 2016.

</span>
<span class="ltx_bibblock">Privacy-preserving Mechanisms for Crowdsensing:
Survey and Research Challenges.

</span>
<span class="ltx_bibblock"><em id="bib.bib64.3.1" class="ltx_emph ltx_font_italic">IEEE Internet of Things Journal</em>
4, 4 (2016),
855–869.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span id="bib.bib65.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Jin Wang, Jun Luo,
Sinno Jialin Pan, and Aixin Sun.
2019.

</span>
<span class="ltx_bibblock">Learning-Based Outdoor Localization Exploiting
Crowd-Labeled WiFi Hotspots.

</span>
<span class="ltx_bibblock"><em id="bib.bib65.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Mobile Computing</em>
18, 4 (2019),
896–909.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span id="bib.bib66.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Jin Wang, Nicholas Tan,
Jun Luo, and Sinno Jialin Pan.
2017.

</span>
<span class="ltx_bibblock">WOLoc: WiFi-only outdoor localization using
crowdsensed hotspot labels. In <em id="bib.bib66.3.1" class="ltx_emph ltx_font_italic">Proc. of the 36th
IEEE INFOCOM</em>. 1–9.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Waymo (2022)</span>
<span class="ltx_bibblock">
Waymo. 2022.

</span>
<span class="ltx_bibblock">We’re building the World’s Most Experienced
Driver.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://waymo.com/?ncr" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://waymo.com/?ncr</a>.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">Accessed: 2022-07-25.

</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Waze Mobile Limited (2022)</span>
<span class="ltx_bibblock">
Waze Mobile Limited.
2022.

</span>
<span class="ltx_bibblock">Waze: Navigation &amp; Live Traffic.

</span>
<span class="ltx_bibblock"><a href="(https://www.waze.com/" title="" class="ltx_ref ltx_url ltx_font_typewriter">(https://www.waze.com/</a>.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">Accessed: 2022-07-28.

</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et al<span id="bib.bib69.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Xi Wei, Tianzhu Zhang,
Yan Li, Yongdong Zhang, and
Feng Wu. 2020.

</span>
<span class="ltx_bibblock">Multi-modality Cross Attention Network for Image
and Sentence Matching. In <em id="bib.bib69.3.1" class="ltx_emph ltx_font_italic">Proc. of the 33rd
IEEE/CVF CVPR</em>. 10941–10950.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu, Yuxin and Kirillov, Alexander and Massa, Francisco and Lo,
Wan-Yen and Girshick, Ross (2022)</span>
<span class="ltx_bibblock">
Wu, Yuxin and Kirillov, Alexander and
Massa, Francisco and Lo, Wan-Yen and Girshick, Ross.
2022.

</span>
<span class="ltx_bibblock">Detectron2.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/facebookresearch/detectron2" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/facebookresearch/detectron2</a>.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">Accessed: 2022-07-25.

</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al<span id="bib.bib71.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Danfei Xu, Dragomir
Anguelov, and Ashesh Jain.
2018.

</span>
<span class="ltx_bibblock">PointFusion: Deep Sensor Fusion for 3D Bounding
Box Estimation. In <em id="bib.bib71.3.1" class="ltx_emph ltx_font_italic">Proc. of the 31st IEEE/CVF
CVPR</em>. 244–253.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al<span id="bib.bib72.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Bin Yang, Wenjie Luo,
and Raquel Urtasun. 2018.

</span>
<span class="ltx_bibblock">PIXOR: Real-time 3D Object Detection from Point
Clouds. In <em id="bib.bib72.3.1" class="ltx_emph ltx_font_italic">Proc. of the 31st IEEE/CVF CVPR</em>.
7652–7660.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al<span id="bib.bib73.2.2.1" class="ltx_text">.</span> (2012)</span>
<span class="ltx_bibblock">
Dejun Yang, Guoliang Xue,
Xi Fang, and Jian Tang.
2012.

</span>
<span class="ltx_bibblock">Crowdsourcing to Smartphones: Incentive Mechanism
Design for Mobile Phone Sensing. In <em id="bib.bib73.3.1" class="ltx_emph ltx_font_italic">Proc. of the
18th ACM MobiCom</em>. 173–184.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib74" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu and Liu (2019)</span>
<span class="ltx_bibblock">
Peihua Yu and Yunfeng
Liu. 2019.

</span>
<span class="ltx_bibblock">Federated Object Detection: Optimizing Object
Detection Model with Federated Learning. In
<em id="bib.bib74.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 3rd International Conference on
Vision, Image and Signal Processing</em>. 1–6.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib75" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span id="bib.bib75.2.2.1" class="ltx_text">.</span> (2014)</span>
<span class="ltx_bibblock">
Chi Zhang, Jun Luo, and
Jianxin Wu. 2014.

</span>
<span class="ltx_bibblock">A Dual-Sensor Enabled Indoor Localization System
with Crowdsensing Spot Survey. In <em id="bib.bib75.3.1" class="ltx_emph ltx_font_italic">Proc. of the
10th IEEE/ACM DCOSS</em>. 75–82.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib76" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span id="bib.bib76.2.2.1" class="ltx_text">.</span> (2015)</span>
<span class="ltx_bibblock">
Chi Zhang, Kalyan P.
Subbu, Jun Luo, and Jianxin Wu.
2015.

</span>
<span class="ltx_bibblock">GROPING: Geomagnetism and cROwdsensing Powered
Indoor NaviGation.

</span>
<span class="ltx_bibblock"><em id="bib.bib76.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Mobile Computing</em>
14, 2 (2015),
387–400.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib77" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al<span id="bib.bib77.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Jian Zhao, Yaxin Li,
Bing Zhu, Weiwen Deng, and
Bohua Sun. 2020.

</span>
<span class="ltx_bibblock">Method and Applications of LiDAR Modeling for
Virtual Testing of Intelligent Vehicles.

</span>
<span class="ltx_bibblock"><em id="bib.bib77.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Intelligent
Transportation Systems</em> 22, 5
(2020), 2990–3000.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib78" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zheng et al<span id="bib.bib78.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Tianyue Zheng, Zhe Chen,
Jun Luo, Lin Ke, Chaoyang Zhao, and
Yaowen Yang. 2020.

</span>
<span class="ltx_bibblock">SiWa: See into Walls via Deep UWB radar.
In <em id="bib.bib78.3.1" class="ltx_emph ltx_font_italic">Proc. of the 27th ACM MobiCom</em>. 323–336.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib79" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zheng et al<span id="bib.bib79.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Tianyue Zheng, Zhe Chen,
Chao Cai, Jun Luo, and
Xu Zhang. 2020.

</span>
<span class="ltx_bibblock">V<sup id="bib.bib79.3.1" class="ltx_sup">2</sup>iFi: in-Vehicle Vital Sign
Monitoring via Compact RF Sensing. In <em id="bib.bib79.4.2" class="ltx_emph ltx_font_italic">Proc. of
the 20th ACM UbiComp</em>. 70:1–27.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib80" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou and Tuzel (2018)</span>
<span class="ltx_bibblock">
Yin Zhou and Oncel
Tuzel. 2018.

</span>
<span class="ltx_bibblock">VoxelNet: End-to-End Learning for Point Cloud
based 3D Object Detection. In <em id="bib.bib80.1.1" class="ltx_emph ltx_font_italic">Proc. of the 31st
IEEE/CVF CVPR</em>. 4490–4499.

</span>
<span class="ltx_bibblock">
</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2302.08645" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2302.08646" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2302.08646">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2302.08646" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2302.08647" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Mar  1 01:58:33 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
