<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2409.05034] TF-Mamba: A Time-Frequency Network for Sound Source Localization</title><meta property="og:description" content="Sound source localization (SSL) determines the position of sound sources using multi-channel audio data. It is commonly used to improve speech enhancement and separation. Extracting spatial features is crucial for SSL,â€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="TF-Mamba: A Time-Frequency Network for Sound Source Localization">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="TF-Mamba: A Time-Frequency Network for Sound Source Localization">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2409.05034">

<!--Generated on Sun Oct  6 00:55:42 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="
DOA Estimation,  Sound Source Localization,  Mamba,  State-space Model
">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">TF-Mamba: A Time-Frequency Network
<br class="ltx_break">for Sound Source Localization</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yang Xiao and Rohan Kumar Das
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id1.1.id1" class="ltx_text ltx_font_italic">Fortemedia Singapore, Singapore</span>
<br class="ltx_break">Email: {xiaoyang, rohankd}@fortemedia.com
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id2.id1" class="ltx_p">Sound source localization (SSL) determines the position of sound sources using multi-channel audio data. It is commonly used to improve speech enhancement and separation. Extracting spatial features is crucial for SSL, especially in challenging acoustic environments. Previous studies performed well based on long short-term memory models. Recently, a novel scalable SSM referred to as Mamba demonstrated notable performance across various sequence-based modalities, including audio and speech. This study introduces the Mamba for SSL tasks. We consider the Mamba-based model to analyze spatial features from speech signals by fusing both time and frequency features, and we develop an SSL system called TF-Mamba. This system integrates time and frequency fusion, with Bidirectional Mamba managing both time-wise and frequency-wise processing. We conduct the experiments on the simulated dataset and the LOCATA dataset. Experiments show that TF-Mamba significantly outperforms other advanced methods on simulated and real-world data.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
DOA Estimation, Sound Source Localization, Mamba, State-space Model

</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Sound source localization (SSL) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> aims to automatically identify the origins of sound by analyzing signals captured through a microphone array. The core functionality of SSL systems is to calculate the angles at which sounds reach the microphones. This spatial information is essential for many speech-based applications, including speech separation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>, speech recognition <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>, and speech enhancement <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. Accurate sound localization can assist these applications to improve their performance. As a result, developing more advanced SSL techniques has become a key focus in research, aiming for greater robustness and adaptability in real-world.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Traditional SSL methods estimate spatial features linked to direct-path signal propagation to map features to source locations. Common spatial features include time delay, inter-channel phase/level difference (IPD/ILD)Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>, and relative transfer function (RTF)Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>. For example, the steered response power (SRP) based methods, particularly SRP-PHATÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>, which is obtained from the SRP by applying phase transform whitening, have been foundational due to their simplicity and versatility. These spatial features are easy to estimate in ideal conditions but become challenging in real-world scenarios with noise, reverberation, and multiple moving sources. Because the noise and overlapping speech cause distortions, while reverberation masks or colors the signal. Additionally, moving sources create time-varying spatial cues, also leading to a significant decline in localization accuracy.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">In recent years, deep learning methods for localization have gained more attentionÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> than traditional methods. These methods approach the task as either feature/location regression or location classification. Common architectures for moving SSL include convolutional neural networks (CNNs)Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> and recurrent neural networks (RNNs)Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>. CNNs extract local spatial features, while RNNs capture long-term temporal context. Deep learning models can take input at the signal level (e.g., time-domain signals, spectrograms) or feature level (e.g., inter-channel phase difference, generalized cross-correlation (GCC)Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>, spatial spectrum). Motivated by speech enhancement, the FN-SSLÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> framework builds on previous work, recognizes that the direct-path inter-channel phase difference can be estimated in both narrow-band (frequencies) and full-band (time-frames). It uses dedicated LSTM layers to process each band and show advanced performance.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">While LSTM-based models like FN-SSL have shown promising results, a new neural state space model (SSM)-based architecture called Mamba <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> has emerged and achieves superior performance to state-of-the-art models across various tasks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>. In speech processing, there have been attempts to replace transformers and RNNs with Mamba for tasks like speech separation and speech enhancement <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>, <a href="#bib.bib24" title="" class="ltx_ref">24</a>, <a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>. Mamba demonstrates a stronger ability to model extremely long-range dependencies compared to LSTM and is notable for its efficient use of computational resources.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">In this work, we <span id="S1.p5.1.1" class="ltx_text ltx_font_italic">introduce Mamba to SSL</span> by proposing a novel architecture referred to as TF-Mamba. It is built on the robust FN-SSL framework, which uses LSTM for time and frequency feature fusion. By replacing the LSTM blocks in FN-SSL with bidirectional Mamba (BiMamba) blocks, TF-Mamba aims to improve audio sequence context modeling while maintaining linear complexity with sequence length. We consider both simulated and LOCATA datasets for our studies to evaluate the effectiveness of proposed TF-Mamba for real-world scenarios. To the best of our knowledge, this is the first attempt to use a state-space-based model for SSL.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2409.05034/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="180" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Architecture of the proposed TF-Mamba network. Each TF-Mamba block includes a temporal Mamba (T-Mamba) and frequency Mamba (F-Mamba) layer, with skip connections to prevent information loss. Bidirectional Mamba (BiMamba) layers capture both past and future information. â€œSâ€ denotes the SiLU activation and â€œLinearâ€ indicates linear projection.</figcaption>
</figure>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Related Works</span>
</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS1.4.1.1" class="ltx_text">II-A</span> </span><span id="S2.SS1.5.2" class="ltx_text ltx_font_italic">Mamba for Speech</span>
</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Mamba has demonstrated transformer-level performance across various sequence-based modalities, including audio and speech, which are naturally sequential in waveform or spectrogram forms. Early works applied Mamba to single tasks such as speech enhancementÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>, speech separationÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>, <a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>, and audio detection and classificationÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>. Additionally, some studies explored self-supervised audio transformers trained with masked spectrogram modelingÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>. The most comprehensive studies to date examine Mambaâ€™s applications in speech enhancement, recognition, synthesis, understanding, and summarization. However, effective model design using SSMs for deep SSL remains unexplored.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS2.4.1.1" class="ltx_text">II-B</span> </span><span id="S2.SS2.5.2" class="ltx_text ltx_font_italic">Deep Sound Source Localization</span>
</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">In recent years, significant progress has been made in SSL using neural networks. Cross3DÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> uses the SRP-PHAT spatial spectrum as input and employs a causal 3D CNN network for tracking moving sound sources. Similarly, SE-ResNetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite> utilizes a squeeze-and-excitation residual network as an encoder and a gated recurrent unit (GRU) network as a decoder. While SELDnetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite> takes frequency-normalized inter-channel phase difference (IPD) concatenated with the magnitude spectrum as input, SALSA-LiteÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>, similar to SELDnet, uses frequency-normalized IPD with the magnitude spectrum as input and a ResNet-GRU network. With advanced performance, the FN-SSLÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> also uses direct path IPD as input and leverages dedicated full-band and narrow-band LSTM layers to exploit inter-band dependencies and inter-channel information.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Proposed TF-Mamba</span>
</h2>

<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS1.4.1.1" class="ltx_text">III-A</span> </span><span id="S3.SS1.5.2" class="ltx_text ltx_font_italic">Mamba</span>
</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">The structured SSMsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> efficiently handles long-dependent sequences with low computation and memory needs, serving as a substitute for transformers or RNNs. Mamba <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite> enhances SSM by introducing an input-dependent selection mechanism for efficient information filtering and a hardware-aware algorithm that scales linearly with sequence length, enabling faster computation. Mambaâ€™s architecture, combining SSM blocks with linear layers, is simpler but achieves state-of-the-art performance across various long-sequence tasks, offering significant computational efficiency during both training and inference.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.7" class="ltx_p">The core of Mamba is a linear selective SSM. In the equation below, the variables <math id="S3.SS1.p2.1.m1.1" class="ltx_Math" alttext="h_{t}" display="inline"><semantics id="S3.SS1.p2.1.m1.1a"><msub id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml"><mi id="S3.SS1.p2.1.m1.1.1.2" xref="S3.SS1.p2.1.m1.1.1.2.cmml">h</mi><mi id="S3.SS1.p2.1.m1.1.1.3" xref="S3.SS1.p2.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><apply id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.1.m1.1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p2.1.m1.1.1.2.cmml" xref="S3.SS1.p2.1.m1.1.1.2">â„</ci><ci id="S3.SS1.p2.1.m1.1.1.3.cmml" xref="S3.SS1.p2.1.m1.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">h_{t}</annotation></semantics></math>, <math id="S3.SS1.p2.2.m2.1" class="ltx_Math" alttext="x_{t}" display="inline"><semantics id="S3.SS1.p2.2.m2.1a"><msub id="S3.SS1.p2.2.m2.1.1" xref="S3.SS1.p2.2.m2.1.1.cmml"><mi id="S3.SS1.p2.2.m2.1.1.2" xref="S3.SS1.p2.2.m2.1.1.2.cmml">x</mi><mi id="S3.SS1.p2.2.m2.1.1.3" xref="S3.SS1.p2.2.m2.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.1b"><apply id="S3.SS1.p2.2.m2.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.2.m2.1.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.p2.2.m2.1.1.2.cmml" xref="S3.SS1.p2.2.m2.1.1.2">ğ‘¥</ci><ci id="S3.SS1.p2.2.m2.1.1.3.cmml" xref="S3.SS1.p2.2.m2.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.1c">x_{t}</annotation></semantics></math>, and <math id="S3.SS1.p2.3.m3.1" class="ltx_Math" alttext="y_{t}" display="inline"><semantics id="S3.SS1.p2.3.m3.1a"><msub id="S3.SS1.p2.3.m3.1.1" xref="S3.SS1.p2.3.m3.1.1.cmml"><mi id="S3.SS1.p2.3.m3.1.1.2" xref="S3.SS1.p2.3.m3.1.1.2.cmml">y</mi><mi id="S3.SS1.p2.3.m3.1.1.3" xref="S3.SS1.p2.3.m3.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.3.m3.1b"><apply id="S3.SS1.p2.3.m3.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m3.1.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.p2.3.m3.1.1.2.cmml" xref="S3.SS1.p2.3.m3.1.1.2">ğ‘¦</ci><ci id="S3.SS1.p2.3.m3.1.1.3.cmml" xref="S3.SS1.p2.3.m3.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.3.m3.1c">y_{t}</annotation></semantics></math> represent the hidden state, input, and output at time <math id="S3.SS1.p2.4.m4.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S3.SS1.p2.4.m4.1a"><mi id="S3.SS1.p2.4.m4.1.1" xref="S3.SS1.p2.4.m4.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.4.m4.1b"><ci id="S3.SS1.p2.4.m4.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.4.m4.1c">t</annotation></semantics></math>, respectively. The matrices <math id="S3.SS1.p2.5.m5.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S3.SS1.p2.5.m5.1a"><mi id="S3.SS1.p2.5.m5.1.1" xref="S3.SS1.p2.5.m5.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.5.m5.1b"><ci id="S3.SS1.p2.5.m5.1.1.cmml" xref="S3.SS1.p2.5.m5.1.1">ğ´</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.5.m5.1c">A</annotation></semantics></math>, <math id="S3.SS1.p2.6.m6.1" class="ltx_Math" alttext="B" display="inline"><semantics id="S3.SS1.p2.6.m6.1a"><mi id="S3.SS1.p2.6.m6.1.1" xref="S3.SS1.p2.6.m6.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.6.m6.1b"><ci id="S3.SS1.p2.6.m6.1.1.cmml" xref="S3.SS1.p2.6.m6.1.1">ğµ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.6.m6.1c">B</annotation></semantics></math>, and <math id="S3.SS1.p2.7.m7.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S3.SS1.p2.7.m7.1a"><mi id="S3.SS1.p2.7.m7.1.1" xref="S3.SS1.p2.7.m7.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.7.m7.1b"><ci id="S3.SS1.p2.7.m7.1.1.cmml" xref="S3.SS1.p2.7.m7.1.1">ğ¶</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.7.m7.1c">C</annotation></semantics></math> are learnable parameters corresponding to the state transition, input, and output processes.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.2" class="ltx_Math" alttext="h_{t}=Ah_{t-1}+Bx_{t},\quad y_{t}=Ch_{t}" display="block"><semantics id="S3.E1.m1.2a"><mrow id="S3.E1.m1.2.2.2" xref="S3.E1.m1.2.2.3.cmml"><mrow id="S3.E1.m1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml"><msub id="S3.E1.m1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.2.cmml"><mi id="S3.E1.m1.1.1.1.1.2.2" xref="S3.E1.m1.1.1.1.1.2.2.cmml">h</mi><mi id="S3.E1.m1.1.1.1.1.2.3" xref="S3.E1.m1.1.1.1.1.2.3.cmml">t</mi></msub><mo id="S3.E1.m1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.cmml">=</mo><mrow id="S3.E1.m1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.3.cmml"><mrow id="S3.E1.m1.1.1.1.1.3.2" xref="S3.E1.m1.1.1.1.1.3.2.cmml"><mi id="S3.E1.m1.1.1.1.1.3.2.2" xref="S3.E1.m1.1.1.1.1.3.2.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.1.1.3.2.1" xref="S3.E1.m1.1.1.1.1.3.2.1.cmml">â€‹</mo><msub id="S3.E1.m1.1.1.1.1.3.2.3" xref="S3.E1.m1.1.1.1.1.3.2.3.cmml"><mi id="S3.E1.m1.1.1.1.1.3.2.3.2" xref="S3.E1.m1.1.1.1.1.3.2.3.2.cmml">h</mi><mrow id="S3.E1.m1.1.1.1.1.3.2.3.3" xref="S3.E1.m1.1.1.1.1.3.2.3.3.cmml"><mi id="S3.E1.m1.1.1.1.1.3.2.3.3.2" xref="S3.E1.m1.1.1.1.1.3.2.3.3.2.cmml">t</mi><mo id="S3.E1.m1.1.1.1.1.3.2.3.3.1" xref="S3.E1.m1.1.1.1.1.3.2.3.3.1.cmml">âˆ’</mo><mn id="S3.E1.m1.1.1.1.1.3.2.3.3.3" xref="S3.E1.m1.1.1.1.1.3.2.3.3.3.cmml">1</mn></mrow></msub></mrow><mo id="S3.E1.m1.1.1.1.1.3.1" xref="S3.E1.m1.1.1.1.1.3.1.cmml">+</mo><mrow id="S3.E1.m1.1.1.1.1.3.3" xref="S3.E1.m1.1.1.1.1.3.3.cmml"><mi id="S3.E1.m1.1.1.1.1.3.3.2" xref="S3.E1.m1.1.1.1.1.3.3.2.cmml">B</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.1.1.3.3.1" xref="S3.E1.m1.1.1.1.1.3.3.1.cmml">â€‹</mo><msub id="S3.E1.m1.1.1.1.1.3.3.3" xref="S3.E1.m1.1.1.1.1.3.3.3.cmml"><mi id="S3.E1.m1.1.1.1.1.3.3.3.2" xref="S3.E1.m1.1.1.1.1.3.3.3.2.cmml">x</mi><mi id="S3.E1.m1.1.1.1.1.3.3.3.3" xref="S3.E1.m1.1.1.1.1.3.3.3.3.cmml">t</mi></msub></mrow></mrow></mrow><mo rspace="1.167em" id="S3.E1.m1.2.2.2.3" xref="S3.E1.m1.2.2.3a.cmml">,</mo><mrow id="S3.E1.m1.2.2.2.2" xref="S3.E1.m1.2.2.2.2.cmml"><msub id="S3.E1.m1.2.2.2.2.2" xref="S3.E1.m1.2.2.2.2.2.cmml"><mi id="S3.E1.m1.2.2.2.2.2.2" xref="S3.E1.m1.2.2.2.2.2.2.cmml">y</mi><mi id="S3.E1.m1.2.2.2.2.2.3" xref="S3.E1.m1.2.2.2.2.2.3.cmml">t</mi></msub><mo id="S3.E1.m1.2.2.2.2.1" xref="S3.E1.m1.2.2.2.2.1.cmml">=</mo><mrow id="S3.E1.m1.2.2.2.2.3" xref="S3.E1.m1.2.2.2.2.3.cmml"><mi id="S3.E1.m1.2.2.2.2.3.2" xref="S3.E1.m1.2.2.2.2.3.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.2.2.2.2.3.1" xref="S3.E1.m1.2.2.2.2.3.1.cmml">â€‹</mo><msub id="S3.E1.m1.2.2.2.2.3.3" xref="S3.E1.m1.2.2.2.2.3.3.cmml"><mi id="S3.E1.m1.2.2.2.2.3.3.2" xref="S3.E1.m1.2.2.2.2.3.3.2.cmml">h</mi><mi id="S3.E1.m1.2.2.2.2.3.3.3" xref="S3.E1.m1.2.2.2.2.3.3.3.cmml">t</mi></msub></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.2b"><apply id="S3.E1.m1.2.2.3.cmml" xref="S3.E1.m1.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.3a.cmml" xref="S3.E1.m1.2.2.2.3">formulae-sequence</csymbol><apply id="S3.E1.m1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1"><eq id="S3.E1.m1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1"></eq><apply id="S3.E1.m1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.2.1.cmml" xref="S3.E1.m1.1.1.1.1.2">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.2.2.cmml" xref="S3.E1.m1.1.1.1.1.2.2">â„</ci><ci id="S3.E1.m1.1.1.1.1.2.3.cmml" xref="S3.E1.m1.1.1.1.1.2.3">ğ‘¡</ci></apply><apply id="S3.E1.m1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.3"><plus id="S3.E1.m1.1.1.1.1.3.1.cmml" xref="S3.E1.m1.1.1.1.1.3.1"></plus><apply id="S3.E1.m1.1.1.1.1.3.2.cmml" xref="S3.E1.m1.1.1.1.1.3.2"><times id="S3.E1.m1.1.1.1.1.3.2.1.cmml" xref="S3.E1.m1.1.1.1.1.3.2.1"></times><ci id="S3.E1.m1.1.1.1.1.3.2.2.cmml" xref="S3.E1.m1.1.1.1.1.3.2.2">ğ´</ci><apply id="S3.E1.m1.1.1.1.1.3.2.3.cmml" xref="S3.E1.m1.1.1.1.1.3.2.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.3.2.3.1.cmml" xref="S3.E1.m1.1.1.1.1.3.2.3">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.3.2.3.2.cmml" xref="S3.E1.m1.1.1.1.1.3.2.3.2">â„</ci><apply id="S3.E1.m1.1.1.1.1.3.2.3.3.cmml" xref="S3.E1.m1.1.1.1.1.3.2.3.3"><minus id="S3.E1.m1.1.1.1.1.3.2.3.3.1.cmml" xref="S3.E1.m1.1.1.1.1.3.2.3.3.1"></minus><ci id="S3.E1.m1.1.1.1.1.3.2.3.3.2.cmml" xref="S3.E1.m1.1.1.1.1.3.2.3.3.2">ğ‘¡</ci><cn type="integer" id="S3.E1.m1.1.1.1.1.3.2.3.3.3.cmml" xref="S3.E1.m1.1.1.1.1.3.2.3.3.3">1</cn></apply></apply></apply><apply id="S3.E1.m1.1.1.1.1.3.3.cmml" xref="S3.E1.m1.1.1.1.1.3.3"><times id="S3.E1.m1.1.1.1.1.3.3.1.cmml" xref="S3.E1.m1.1.1.1.1.3.3.1"></times><ci id="S3.E1.m1.1.1.1.1.3.3.2.cmml" xref="S3.E1.m1.1.1.1.1.3.3.2">ğµ</ci><apply id="S3.E1.m1.1.1.1.1.3.3.3.cmml" xref="S3.E1.m1.1.1.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.3.3.3.1.cmml" xref="S3.E1.m1.1.1.1.1.3.3.3">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.3.3.3.2.cmml" xref="S3.E1.m1.1.1.1.1.3.3.3.2">ğ‘¥</ci><ci id="S3.E1.m1.1.1.1.1.3.3.3.3.cmml" xref="S3.E1.m1.1.1.1.1.3.3.3.3">ğ‘¡</ci></apply></apply></apply></apply><apply id="S3.E1.m1.2.2.2.2.cmml" xref="S3.E1.m1.2.2.2.2"><eq id="S3.E1.m1.2.2.2.2.1.cmml" xref="S3.E1.m1.2.2.2.2.1"></eq><apply id="S3.E1.m1.2.2.2.2.2.cmml" xref="S3.E1.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.2.2.2.1.cmml" xref="S3.E1.m1.2.2.2.2.2">subscript</csymbol><ci id="S3.E1.m1.2.2.2.2.2.2.cmml" xref="S3.E1.m1.2.2.2.2.2.2">ğ‘¦</ci><ci id="S3.E1.m1.2.2.2.2.2.3.cmml" xref="S3.E1.m1.2.2.2.2.2.3">ğ‘¡</ci></apply><apply id="S3.E1.m1.2.2.2.2.3.cmml" xref="S3.E1.m1.2.2.2.2.3"><times id="S3.E1.m1.2.2.2.2.3.1.cmml" xref="S3.E1.m1.2.2.2.2.3.1"></times><ci id="S3.E1.m1.2.2.2.2.3.2.cmml" xref="S3.E1.m1.2.2.2.2.3.2">ğ¶</ci><apply id="S3.E1.m1.2.2.2.2.3.3.cmml" xref="S3.E1.m1.2.2.2.2.3.3"><csymbol cd="ambiguous" id="S3.E1.m1.2.2.2.2.3.3.1.cmml" xref="S3.E1.m1.2.2.2.2.3.3">subscript</csymbol><ci id="S3.E1.m1.2.2.2.2.3.3.2.cmml" xref="S3.E1.m1.2.2.2.2.3.3.2">â„</ci><ci id="S3.E1.m1.2.2.2.2.3.3.3.cmml" xref="S3.E1.m1.2.2.2.2.3.3.3">ğ‘¡</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.2c">h_{t}=Ah_{t-1}+Bx_{t},\quad y_{t}=Ch_{t}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS1.p4" class="ltx_para">
<p id="S3.SS1.p4.4" class="ltx_p">Due to its linear nature, the entire output sequence <math id="S3.SS1.p4.1.m1.1" class="ltx_Math" alttext="y" display="inline"><semantics id="S3.SS1.p4.1.m1.1a"><mi id="S3.SS1.p4.1.m1.1.1" xref="S3.SS1.p4.1.m1.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.1.m1.1b"><ci id="S3.SS1.p4.1.m1.1.1.cmml" xref="S3.SS1.p4.1.m1.1.1">ğ‘¦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.1.m1.1c">y</annotation></semantics></math> of length <math id="S3.SS1.p4.2.m2.1" class="ltx_Math" alttext="\mathcal{L}" display="inline"><semantics id="S3.SS1.p4.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p4.2.m2.1.1" xref="S3.SS1.p4.2.m2.1.1.cmml">â„’</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.2.m2.1b"><ci id="S3.SS1.p4.2.m2.1.1.cmml" xref="S3.SS1.p4.2.m2.1.1">â„’</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.2.m2.1c">\mathcal{L}</annotation></semantics></math> can be expressed as a convolution between the input sequence <math id="S3.SS1.p4.3.m3.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S3.SS1.p4.3.m3.1a"><mi id="S3.SS1.p4.3.m3.1.1" xref="S3.SS1.p4.3.m3.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.3.m3.1b"><ci id="S3.SS1.p4.3.m3.1.1.cmml" xref="S3.SS1.p4.3.m3.1.1">ğ‘¥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.3.m3.1c">x</annotation></semantics></math> of the same length and a kernel <math id="S3.SS1.p4.4.m4.1" class="ltx_Math" alttext="\mathcal{K}" display="inline"><semantics id="S3.SS1.p4.4.m4.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p4.4.m4.1.1" xref="S3.SS1.p4.4.m4.1.1.cmml">ğ’¦</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.4.m4.1b"><ci id="S3.SS1.p4.4.m4.1.1.cmml" xref="S3.SS1.p4.4.m4.1.1">ğ’¦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.4.m4.1c">\mathcal{K}</annotation></semantics></math>.</p>
<table id="S3.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E2.m1.3" class="ltx_Math" alttext="\quad y=x\ast\mathcal{K},{\text{~{}where~{}}}\mathcal{K}=(CB,AB,\ldots,CA^{\mathcal{L}-1}B)" display="block"><semantics id="S3.E2.m1.3a"><mrow id="S3.E2.m1.3.3.2" xref="S3.E2.m1.3.3.3.cmml"><mrow id="S3.E2.m1.2.2.1.1" xref="S3.E2.m1.2.2.1.1.cmml"><mi id="S3.E2.m1.2.2.1.1.2" xref="S3.E2.m1.2.2.1.1.2.cmml">y</mi><mo id="S3.E2.m1.2.2.1.1.1" xref="S3.E2.m1.2.2.1.1.1.cmml">=</mo><mrow id="S3.E2.m1.2.2.1.1.3" xref="S3.E2.m1.2.2.1.1.3.cmml"><mi id="S3.E2.m1.2.2.1.1.3.2" xref="S3.E2.m1.2.2.1.1.3.2.cmml">x</mi><mo lspace="0.222em" rspace="0.222em" id="S3.E2.m1.2.2.1.1.3.1" xref="S3.E2.m1.2.2.1.1.3.1.cmml">âˆ—</mo><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.2.2.1.1.3.3" xref="S3.E2.m1.2.2.1.1.3.3.cmml">ğ’¦</mi></mrow></mrow><mo id="S3.E2.m1.3.3.2.3" xref="S3.E2.m1.3.3.3a.cmml">,</mo><mrow id="S3.E2.m1.3.3.2.2" xref="S3.E2.m1.3.3.2.2.cmml"><mrow id="S3.E2.m1.3.3.2.2.5" xref="S3.E2.m1.3.3.2.2.5.cmml"><mtext id="S3.E2.m1.3.3.2.2.5.2" xref="S3.E2.m1.3.3.2.2.5.2a.cmml">Â whereÂ </mtext><mo lspace="0em" rspace="0em" id="S3.E2.m1.3.3.2.2.5.1" xref="S3.E2.m1.3.3.2.2.5.1.cmml">â€‹</mo><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.3.3.2.2.5.3" xref="S3.E2.m1.3.3.2.2.5.3.cmml">ğ’¦</mi></mrow><mo id="S3.E2.m1.3.3.2.2.4" xref="S3.E2.m1.3.3.2.2.4.cmml">=</mo><mrow id="S3.E2.m1.3.3.2.2.3.3" xref="S3.E2.m1.3.3.2.2.3.4.cmml"><mo stretchy="false" id="S3.E2.m1.3.3.2.2.3.3.4" xref="S3.E2.m1.3.3.2.2.3.4.cmml">(</mo><mrow id="S3.E2.m1.3.3.2.2.1.1.1" xref="S3.E2.m1.3.3.2.2.1.1.1.cmml"><mi id="S3.E2.m1.3.3.2.2.1.1.1.2" xref="S3.E2.m1.3.3.2.2.1.1.1.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.3.3.2.2.1.1.1.1" xref="S3.E2.m1.3.3.2.2.1.1.1.1.cmml">â€‹</mo><mi id="S3.E2.m1.3.3.2.2.1.1.1.3" xref="S3.E2.m1.3.3.2.2.1.1.1.3.cmml">B</mi></mrow><mo id="S3.E2.m1.3.3.2.2.3.3.5" xref="S3.E2.m1.3.3.2.2.3.4.cmml">,</mo><mrow id="S3.E2.m1.3.3.2.2.2.2.2" xref="S3.E2.m1.3.3.2.2.2.2.2.cmml"><mi id="S3.E2.m1.3.3.2.2.2.2.2.2" xref="S3.E2.m1.3.3.2.2.2.2.2.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.3.3.2.2.2.2.2.1" xref="S3.E2.m1.3.3.2.2.2.2.2.1.cmml">â€‹</mo><mi id="S3.E2.m1.3.3.2.2.2.2.2.3" xref="S3.E2.m1.3.3.2.2.2.2.2.3.cmml">B</mi></mrow><mo id="S3.E2.m1.3.3.2.2.3.3.6" xref="S3.E2.m1.3.3.2.2.3.4.cmml">,</mo><mi mathvariant="normal" id="S3.E2.m1.1.1" xref="S3.E2.m1.1.1.cmml">â€¦</mi><mo id="S3.E2.m1.3.3.2.2.3.3.7" xref="S3.E2.m1.3.3.2.2.3.4.cmml">,</mo><mrow id="S3.E2.m1.3.3.2.2.3.3.3" xref="S3.E2.m1.3.3.2.2.3.3.3.cmml"><mi id="S3.E2.m1.3.3.2.2.3.3.3.2" xref="S3.E2.m1.3.3.2.2.3.3.3.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.3.3.2.2.3.3.3.1" xref="S3.E2.m1.3.3.2.2.3.3.3.1.cmml">â€‹</mo><msup id="S3.E2.m1.3.3.2.2.3.3.3.3" xref="S3.E2.m1.3.3.2.2.3.3.3.3.cmml"><mi id="S3.E2.m1.3.3.2.2.3.3.3.3.2" xref="S3.E2.m1.3.3.2.2.3.3.3.3.2.cmml">A</mi><mrow id="S3.E2.m1.3.3.2.2.3.3.3.3.3" xref="S3.E2.m1.3.3.2.2.3.3.3.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.3.3.2.2.3.3.3.3.3.2" xref="S3.E2.m1.3.3.2.2.3.3.3.3.3.2.cmml">â„’</mi><mo id="S3.E2.m1.3.3.2.2.3.3.3.3.3.1" xref="S3.E2.m1.3.3.2.2.3.3.3.3.3.1.cmml">âˆ’</mo><mn id="S3.E2.m1.3.3.2.2.3.3.3.3.3.3" xref="S3.E2.m1.3.3.2.2.3.3.3.3.3.3.cmml">1</mn></mrow></msup><mo lspace="0em" rspace="0em" id="S3.E2.m1.3.3.2.2.3.3.3.1a" xref="S3.E2.m1.3.3.2.2.3.3.3.1.cmml">â€‹</mo><mi id="S3.E2.m1.3.3.2.2.3.3.3.4" xref="S3.E2.m1.3.3.2.2.3.3.3.4.cmml">B</mi></mrow><mo stretchy="false" id="S3.E2.m1.3.3.2.2.3.3.8" xref="S3.E2.m1.3.3.2.2.3.4.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.3b"><apply id="S3.E2.m1.3.3.3.cmml" xref="S3.E2.m1.3.3.2"><csymbol cd="ambiguous" id="S3.E2.m1.3.3.3a.cmml" xref="S3.E2.m1.3.3.2.3">formulae-sequence</csymbol><apply id="S3.E2.m1.2.2.1.1.cmml" xref="S3.E2.m1.2.2.1.1"><eq id="S3.E2.m1.2.2.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1"></eq><ci id="S3.E2.m1.2.2.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.2">ğ‘¦</ci><apply id="S3.E2.m1.2.2.1.1.3.cmml" xref="S3.E2.m1.2.2.1.1.3"><ci id="S3.E2.m1.2.2.1.1.3.1.cmml" xref="S3.E2.m1.2.2.1.1.3.1">âˆ—</ci><ci id="S3.E2.m1.2.2.1.1.3.2.cmml" xref="S3.E2.m1.2.2.1.1.3.2">ğ‘¥</ci><ci id="S3.E2.m1.2.2.1.1.3.3.cmml" xref="S3.E2.m1.2.2.1.1.3.3">ğ’¦</ci></apply></apply><apply id="S3.E2.m1.3.3.2.2.cmml" xref="S3.E2.m1.3.3.2.2"><eq id="S3.E2.m1.3.3.2.2.4.cmml" xref="S3.E2.m1.3.3.2.2.4"></eq><apply id="S3.E2.m1.3.3.2.2.5.cmml" xref="S3.E2.m1.3.3.2.2.5"><times id="S3.E2.m1.3.3.2.2.5.1.cmml" xref="S3.E2.m1.3.3.2.2.5.1"></times><ci id="S3.E2.m1.3.3.2.2.5.2a.cmml" xref="S3.E2.m1.3.3.2.2.5.2"><mtext id="S3.E2.m1.3.3.2.2.5.2.cmml" xref="S3.E2.m1.3.3.2.2.5.2">Â whereÂ </mtext></ci><ci id="S3.E2.m1.3.3.2.2.5.3.cmml" xref="S3.E2.m1.3.3.2.2.5.3">ğ’¦</ci></apply><vector id="S3.E2.m1.3.3.2.2.3.4.cmml" xref="S3.E2.m1.3.3.2.2.3.3"><apply id="S3.E2.m1.3.3.2.2.1.1.1.cmml" xref="S3.E2.m1.3.3.2.2.1.1.1"><times id="S3.E2.m1.3.3.2.2.1.1.1.1.cmml" xref="S3.E2.m1.3.3.2.2.1.1.1.1"></times><ci id="S3.E2.m1.3.3.2.2.1.1.1.2.cmml" xref="S3.E2.m1.3.3.2.2.1.1.1.2">ğ¶</ci><ci id="S3.E2.m1.3.3.2.2.1.1.1.3.cmml" xref="S3.E2.m1.3.3.2.2.1.1.1.3">ğµ</ci></apply><apply id="S3.E2.m1.3.3.2.2.2.2.2.cmml" xref="S3.E2.m1.3.3.2.2.2.2.2"><times id="S3.E2.m1.3.3.2.2.2.2.2.1.cmml" xref="S3.E2.m1.3.3.2.2.2.2.2.1"></times><ci id="S3.E2.m1.3.3.2.2.2.2.2.2.cmml" xref="S3.E2.m1.3.3.2.2.2.2.2.2">ğ´</ci><ci id="S3.E2.m1.3.3.2.2.2.2.2.3.cmml" xref="S3.E2.m1.3.3.2.2.2.2.2.3">ğµ</ci></apply><ci id="S3.E2.m1.1.1.cmml" xref="S3.E2.m1.1.1">â€¦</ci><apply id="S3.E2.m1.3.3.2.2.3.3.3.cmml" xref="S3.E2.m1.3.3.2.2.3.3.3"><times id="S3.E2.m1.3.3.2.2.3.3.3.1.cmml" xref="S3.E2.m1.3.3.2.2.3.3.3.1"></times><ci id="S3.E2.m1.3.3.2.2.3.3.3.2.cmml" xref="S3.E2.m1.3.3.2.2.3.3.3.2">ğ¶</ci><apply id="S3.E2.m1.3.3.2.2.3.3.3.3.cmml" xref="S3.E2.m1.3.3.2.2.3.3.3.3"><csymbol cd="ambiguous" id="S3.E2.m1.3.3.2.2.3.3.3.3.1.cmml" xref="S3.E2.m1.3.3.2.2.3.3.3.3">superscript</csymbol><ci id="S3.E2.m1.3.3.2.2.3.3.3.3.2.cmml" xref="S3.E2.m1.3.3.2.2.3.3.3.3.2">ğ´</ci><apply id="S3.E2.m1.3.3.2.2.3.3.3.3.3.cmml" xref="S3.E2.m1.3.3.2.2.3.3.3.3.3"><minus id="S3.E2.m1.3.3.2.2.3.3.3.3.3.1.cmml" xref="S3.E2.m1.3.3.2.2.3.3.3.3.3.1"></minus><ci id="S3.E2.m1.3.3.2.2.3.3.3.3.3.2.cmml" xref="S3.E2.m1.3.3.2.2.3.3.3.3.3.2">â„’</ci><cn type="integer" id="S3.E2.m1.3.3.2.2.3.3.3.3.3.3.cmml" xref="S3.E2.m1.3.3.2.2.3.3.3.3.3.3">1</cn></apply></apply><ci id="S3.E2.m1.3.3.2.2.3.3.3.4.cmml" xref="S3.E2.m1.3.3.2.2.3.3.3.4">ğµ</ci></apply></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.3c">\quad y=x\ast\mathcal{K},{\text{~{}where~{}}}\mathcal{K}=(CB,AB,\ldots,CA^{\mathcal{L}-1}B)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.p4.8" class="ltx_p">Since the matrices <math id="S3.SS1.p4.5.m1.1" class="ltx_Math" alttext="A_{t}" display="inline"><semantics id="S3.SS1.p4.5.m1.1a"><msub id="S3.SS1.p4.5.m1.1.1" xref="S3.SS1.p4.5.m1.1.1.cmml"><mi id="S3.SS1.p4.5.m1.1.1.2" xref="S3.SS1.p4.5.m1.1.1.2.cmml">A</mi><mi id="S3.SS1.p4.5.m1.1.1.3" xref="S3.SS1.p4.5.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.5.m1.1b"><apply id="S3.SS1.p4.5.m1.1.1.cmml" xref="S3.SS1.p4.5.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.5.m1.1.1.1.cmml" xref="S3.SS1.p4.5.m1.1.1">subscript</csymbol><ci id="S3.SS1.p4.5.m1.1.1.2.cmml" xref="S3.SS1.p4.5.m1.1.1.2">ğ´</ci><ci id="S3.SS1.p4.5.m1.1.1.3.cmml" xref="S3.SS1.p4.5.m1.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.5.m1.1c">A_{t}</annotation></semantics></math>, <math id="S3.SS1.p4.6.m2.1" class="ltx_Math" alttext="B_{t}" display="inline"><semantics id="S3.SS1.p4.6.m2.1a"><msub id="S3.SS1.p4.6.m2.1.1" xref="S3.SS1.p4.6.m2.1.1.cmml"><mi id="S3.SS1.p4.6.m2.1.1.2" xref="S3.SS1.p4.6.m2.1.1.2.cmml">B</mi><mi id="S3.SS1.p4.6.m2.1.1.3" xref="S3.SS1.p4.6.m2.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.6.m2.1b"><apply id="S3.SS1.p4.6.m2.1.1.cmml" xref="S3.SS1.p4.6.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.6.m2.1.1.1.cmml" xref="S3.SS1.p4.6.m2.1.1">subscript</csymbol><ci id="S3.SS1.p4.6.m2.1.1.2.cmml" xref="S3.SS1.p4.6.m2.1.1.2">ğµ</ci><ci id="S3.SS1.p4.6.m2.1.1.3.cmml" xref="S3.SS1.p4.6.m2.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.6.m2.1c">B_{t}</annotation></semantics></math>, and <math id="S3.SS1.p4.7.m3.1" class="ltx_Math" alttext="C_{t}" display="inline"><semantics id="S3.SS1.p4.7.m3.1a"><msub id="S3.SS1.p4.7.m3.1.1" xref="S3.SS1.p4.7.m3.1.1.cmml"><mi id="S3.SS1.p4.7.m3.1.1.2" xref="S3.SS1.p4.7.m3.1.1.2.cmml">C</mi><mi id="S3.SS1.p4.7.m3.1.1.3" xref="S3.SS1.p4.7.m3.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.7.m3.1b"><apply id="S3.SS1.p4.7.m3.1.1.cmml" xref="S3.SS1.p4.7.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.7.m3.1.1.1.cmml" xref="S3.SS1.p4.7.m3.1.1">subscript</csymbol><ci id="S3.SS1.p4.7.m3.1.1.2.cmml" xref="S3.SS1.p4.7.m3.1.1.2">ğ¶</ci><ci id="S3.SS1.p4.7.m3.1.1.3.cmml" xref="S3.SS1.p4.7.m3.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.7.m3.1c">C_{t}</annotation></semantics></math> depend on the input <math id="S3.SS1.p4.8.m4.1" class="ltx_Math" alttext="x_{t}" display="inline"><semantics id="S3.SS1.p4.8.m4.1a"><msub id="S3.SS1.p4.8.m4.1.1" xref="S3.SS1.p4.8.m4.1.1.cmml"><mi id="S3.SS1.p4.8.m4.1.1.2" xref="S3.SS1.p4.8.m4.1.1.2.cmml">x</mi><mi id="S3.SS1.p4.8.m4.1.1.3" xref="S3.SS1.p4.8.m4.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.8.m4.1b"><apply id="S3.SS1.p4.8.m4.1.1.cmml" xref="S3.SS1.p4.8.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.8.m4.1.1.1.cmml" xref="S3.SS1.p4.8.m4.1.1">subscript</csymbol><ci id="S3.SS1.p4.8.m4.1.1.2.cmml" xref="S3.SS1.p4.8.m4.1.1.2">ğ‘¥</ci><ci id="S3.SS1.p4.8.m4.1.1.3.cmml" xref="S3.SS1.p4.8.m4.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.8.m4.1c">x_{t}</annotation></semantics></math> (i.e., they are selective), this convolution cannot be computed directly but is instead solved using a parallel scan algorithm. A unidirectional Mamba is an SSM positioned between gated linear layers. For most speech-related tasks, bidirectional modeling is preferred because it captures information from both past and future sequences. Therefore, we use the bidirectional Mamba (BiMamba) proposed inÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>, where two SSMs and causal convolutions run in parallel: one processes the original sequence, and the other processes the reversed sequence. The outputs from both SSMs are averaged to incorporate information from both directions.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS2.4.1.1" class="ltx_text">III-B</span> </span><span id="S3.SS2.5.2" class="ltx_text ltx_font_italic">Network Architecture</span>
</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">The structure of the proposed TF-Mamba network is illustrated in Fig.Â <a href="#S1.F1" title="Figure 1 â€£ I Introduction â€£ TF-Mamba: A Time-Frequency Network for Sound Source Localization" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. The input to the network consists of the real and imaginary parts of the STFT coefficients, resulting in an input channel count that is twice the number of microphones. The model has three modules as follows:</p>
</div>
<section id="S3.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS2.SSS1.4.1.1" class="ltx_text">III-B</span>1 </span>Feature Encoder</h4>

<div id="S3.SS2.SSS1.p1" class="ltx_para">
<p id="S3.SS2.SSS1.p1.1" class="ltx_p">The inputs are first processed by a feature encoder, which consists of a dilated DenseNetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> core flanked by two convolutional layers to enhance its spectral properties. The output from the feature encoder is then transformed through the Time-Frequency Mamba block.</p>
</div>
</section>
<section id="S3.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS2.SSS2.4.1.1" class="ltx_text">III-B</span>2 </span>Time-Frequency Mamba</h4>

<div id="S3.SS2.SSS2.p1" class="ltx_para">
<p id="S3.SS2.SSS2.p1.1" class="ltx_p">The Time-Frequency Mamba (TF-Mamba) block consists of one temporal Mamba layer and one frequency Mamba layer. Fig.Â <a href="#S1.F1" title="Figure 1 â€£ I Introduction â€£ TF-Mamba: A Time-Frequency Network for Sound Source Localization" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> illustrates a network with a TF-Mamba block, with additional blocks easily added by repeating the block multiple (<math id="S3.SS2.SSS2.p1.1.m1.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S3.SS2.SSS2.p1.1.m1.1a"><mi id="S3.SS2.SSS2.p1.1.m1.1.1" xref="S3.SS2.SSS2.p1.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p1.1.m1.1b"><ci id="S3.SS2.SSS2.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS2.p1.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p1.1.m1.1c">N</annotation></semantics></math>) times.</p>
</div>
<div id="S3.SS2.SSS2.p2" class="ltx_para">
<p id="S3.SS2.SSS2.p2.1" class="ltx_p"><span id="S3.SS2.SSS2.p2.1.1" class="ltx_text ltx_font_bold">The temporal Mamba layers</span> process time frames independently, with all frames sharing the same network parameters. The input is a sequence along the frequency axis of a single time frame, allowing the temporal Mamba layers to learn inter-frequency dependencies related to spatial and localization cues. These layers do not capture temporal information, which is instead handled by the subsequent frequency Mamba layers.</p>
</div>
<div id="S3.SS2.SSS2.p3" class="ltx_para">
<p id="S3.SS2.SSS2.p3.1" class="ltx_p"><span id="S3.SS2.SSS2.p3.1.1" class="ltx_text ltx_font_bold">The frequency Mamba layers</span> process frequencies independently, with all frequencies also sharing parameters. Differing from the temporal Mamba, the input is a sequence along the time axis of a single frequency, where the frequency Mamba layers estimate direct-path localization features. Estimating these features frequency-wise has been extensively studied in conventional methods such as inÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>. The proposed frequency Mamba layers focus on exploiting this inter-channel information. Additionally, since it is time-varying for moving sound sources, the frequency Mamba layers also learn the temporal evolution of the direct-path localization features.</p>
</div>
<div id="S3.SS2.SSS2.p4" class="ltx_para">
<p id="S3.SS2.SSS2.p4.1" class="ltx_p">Mamba is useful because it efficiently models long-range dependencies while maintaining computational efficiency. The ability of Mamba to handle both temporal and frequency-specific features in a structured manner makes it ideal for capturing complex relationships in audio data, such as the time-varying nature of localization cues, which are crucial for accurate SSL. However, the temporal Mamba and frequency Mamba layers are designed to focus on their respective types of information. Therefore the pieces of information from the frequency Mamba layer can be lost after passing through a temporal Mamba layer, and vice versa. To prevent this information loss, we add skip connections. As shown in Fig.Â <a href="#S1.F1" title="Figure 1 â€£ I Introduction â€£ TF-Mamba: A Time-Frequency Network for Sound Source Localization" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, the output of each temporal Mamba layer is added to the input of the following temporal Mamba layer. Similarly, the output of each frequency Mamba layer is added to the input of the next frequency Mamba layer. Further, each Mamba layer inside BiMamba also has the skip connection.</p>
</div>
</section>
<section id="S3.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS2.SSS3.4.1.1" class="ltx_text">III-B</span>3 </span>Output Decoder</h4>

<div id="S3.SS2.SSS3.p1" class="ltx_para">
<p id="S3.SS2.SSS3.p1.1" class="ltx_p">The output from the TF-Mamba blocks is then passed through an average pooling module to reduce the frame rate and is subsequently fed into a fully connected layer with <math id="S3.SS2.SSS3.p1.1.m1.1" class="ltx_Math" alttext="\tanh" display="inline"><semantics id="S3.SS2.SSS3.p1.1.m1.1a"><mi id="S3.SS2.SSS3.p1.1.m1.1.1" xref="S3.SS2.SSS3.p1.1.m1.1.1.cmml">tanh</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p1.1.m1.1b"><tanh id="S3.SS2.SSS3.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS3.p1.1.m1.1.1"></tanh></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p1.1.m1.1c">\tanh</annotation></semantics></math> activation, which converts the output to the desired dimension. We employ a spatial spectrum prediction module for DOA estimation as inÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>. This system learns complex relationships from the audio data to predict the potential origin of sound at every degree within a half-circle of the linear microphone array. The resulting spatial spectrum is an 181-point map. We train our model by minimizing the mean squared error (MSE) loss between the modelâ€™s output spatial spectrum and the ground truth.</p>
</div>
</section>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Experiment Setting</span>
</h2>

<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS1.4.1.1" class="ltx_text">IV-A</span> </span><span id="S4.SS1.5.2" class="ltx_text ltx_font_italic">Datasets</span>
</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">We evaluated the proposed method on both simulated and real-world datasets, using two microphones to localize the direction of arrival (DOA) within a 180-degree azimuth range.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.2" class="ltx_p"><span id="S4.SS1.p2.2.1" class="ltx_text ltx_font_bold">Simulated dataset:</span> Microphone signals are obtained by convolving room impulse responses (RIRs) with speech source signalsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>. The speech signals are randomly selected from the training, development, and test sets of the LibriSpeech corpusÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>, and then used for model training, validation, and testing, respectively. RIRs are generated using the gpuRIRÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>. We followed the settings fromÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> to obtain the simulated dataset with moving sources. The room reverberation time (RT60) is randomly set between 0.2 and 0.6 seconds, and the room size ranges from <math id="S4.SS1.p2.1.m1.1" class="ltx_Math" alttext="4\times 2\times 2" display="inline"><semantics id="S4.SS1.p2.1.m1.1a"><mrow id="S4.SS1.p2.1.m1.1.1" xref="S4.SS1.p2.1.m1.1.1.cmml"><mn id="S4.SS1.p2.1.m1.1.1.2" xref="S4.SS1.p2.1.m1.1.1.2.cmml">4</mn><mo lspace="0.222em" rspace="0.222em" id="S4.SS1.p2.1.m1.1.1.1" xref="S4.SS1.p2.1.m1.1.1.1.cmml">Ã—</mo><mn id="S4.SS1.p2.1.m1.1.1.3" xref="S4.SS1.p2.1.m1.1.1.3.cmml">2</mn><mo lspace="0.222em" rspace="0.222em" id="S4.SS1.p2.1.m1.1.1.1a" xref="S4.SS1.p2.1.m1.1.1.1.cmml">Ã—</mo><mn id="S4.SS1.p2.1.m1.1.1.4" xref="S4.SS1.p2.1.m1.1.1.4.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.1b"><apply id="S4.SS1.p2.1.m1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1"><times id="S4.SS1.p2.1.m1.1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1.1"></times><cn type="integer" id="S4.SS1.p2.1.m1.1.1.2.cmml" xref="S4.SS1.p2.1.m1.1.1.2">4</cn><cn type="integer" id="S4.SS1.p2.1.m1.1.1.3.cmml" xref="S4.SS1.p2.1.m1.1.1.3">2</cn><cn type="integer" id="S4.SS1.p2.1.m1.1.1.4.cmml" xref="S4.SS1.p2.1.m1.1.1.4">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.1.m1.1c">4\times 2\times 2</annotation></semantics></math> m to <math id="S4.SS1.p2.2.m2.1" class="ltx_Math" alttext="10\times 8\times 5" display="inline"><semantics id="S4.SS1.p2.2.m2.1a"><mrow id="S4.SS1.p2.2.m2.1.1" xref="S4.SS1.p2.2.m2.1.1.cmml"><mn id="S4.SS1.p2.2.m2.1.1.2" xref="S4.SS1.p2.2.m2.1.1.2.cmml">10</mn><mo lspace="0.222em" rspace="0.222em" id="S4.SS1.p2.2.m2.1.1.1" xref="S4.SS1.p2.2.m2.1.1.1.cmml">Ã—</mo><mn id="S4.SS1.p2.2.m2.1.1.3" xref="S4.SS1.p2.2.m2.1.1.3.cmml">8</mn><mo lspace="0.222em" rspace="0.222em" id="S4.SS1.p2.2.m2.1.1.1a" xref="S4.SS1.p2.2.m2.1.1.1.cmml">Ã—</mo><mn id="S4.SS1.p2.2.m2.1.1.4" xref="S4.SS1.p2.2.m2.1.1.4.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.2.m2.1b"><apply id="S4.SS1.p2.2.m2.1.1.cmml" xref="S4.SS1.p2.2.m2.1.1"><times id="S4.SS1.p2.2.m2.1.1.1.cmml" xref="S4.SS1.p2.2.m2.1.1.1"></times><cn type="integer" id="S4.SS1.p2.2.m2.1.1.2.cmml" xref="S4.SS1.p2.2.m2.1.1.2">10</cn><cn type="integer" id="S4.SS1.p2.2.m2.1.1.3.cmml" xref="S4.SS1.p2.2.m2.1.1.3">8</cn><cn type="integer" id="S4.SS1.p2.2.m2.1.1.4.cmml" xref="S4.SS1.p2.2.m2.1.1.4">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.2.m2.1c">10\times 8\times 5</annotation></semantics></math> m. The moving trajectories of speech sources are generated according to Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>, with each source maintaining a fixed height. Two microphones, placed 8 cm apart, are randomly positioned in the room on the same horizontal plane as the sound source. This dataset includes 1,511 audio files, which amount to approximately 4.96 hours of speech data. Based on the RIRs, we generate the mixture data for each original single-channel speech data for every 5 degrees from 0 to 180 degrees, which expands the audio files by 37 times. We then use white, babble, and factory noises from the NOISEX-92Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite> dataset as noise sources and create a diffuse sound field described inÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>. The generated diffuse noise signals are added to the clean signals with a signal-to-noise ratio (SNR) between -10 and 10 dB for noise robustness.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.1" class="ltx_p"><span id="S4.SS1.p3.1.1" class="ltx_text ltx_font_bold">Real-world dataset:</span> We also tested our proposed method on tasks 3 and 5 of the LOCATA datasetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite> following the setting inÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>. The room size was <math id="S4.SS1.p3.1.m1.1" class="ltx_Math" alttext="7.1\times 9.8\times 3" display="inline"><semantics id="S4.SS1.p3.1.m1.1a"><mrow id="S4.SS1.p3.1.m1.1.1" xref="S4.SS1.p3.1.m1.1.1.cmml"><mn id="S4.SS1.p3.1.m1.1.1.2" xref="S4.SS1.p3.1.m1.1.1.2.cmml">7.1</mn><mo lspace="0.222em" rspace="0.222em" id="S4.SS1.p3.1.m1.1.1.1" xref="S4.SS1.p3.1.m1.1.1.1.cmml">Ã—</mo><mn id="S4.SS1.p3.1.m1.1.1.3" xref="S4.SS1.p3.1.m1.1.1.3.cmml">9.8</mn><mo lspace="0.222em" rspace="0.222em" id="S4.SS1.p3.1.m1.1.1.1a" xref="S4.SS1.p3.1.m1.1.1.1.cmml">Ã—</mo><mn id="S4.SS1.p3.1.m1.1.1.4" xref="S4.SS1.p3.1.m1.1.1.4.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p3.1.m1.1b"><apply id="S4.SS1.p3.1.m1.1.1.cmml" xref="S4.SS1.p3.1.m1.1.1"><times id="S4.SS1.p3.1.m1.1.1.1.cmml" xref="S4.SS1.p3.1.m1.1.1.1"></times><cn type="float" id="S4.SS1.p3.1.m1.1.1.2.cmml" xref="S4.SS1.p3.1.m1.1.1.2">7.1</cn><cn type="float" id="S4.SS1.p3.1.m1.1.1.3.cmml" xref="S4.SS1.p3.1.m1.1.1.3">9.8</cn><cn type="integer" id="S4.SS1.p3.1.m1.1.1.4.cmml" xref="S4.SS1.p3.1.m1.1.1.4">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p3.1.m1.1c">7.1\times 9.8\times 3</annotation></semantics></math> m, with a reverberation time of 0.55 s. We used microphones 6 and 9 from the DICIT arrayÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite>, which have the same configuration as the simulated microphone array. The models trained on the simulated dataset were directly tested on the LOCATA dataset.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS2.4.1.1" class="ltx_text">IV-B</span> </span><span id="S4.SS2.5.2" class="ltx_text ltx_font_italic">Implementation details and metrics</span>
</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">For training each task with our proposed TF-Mamba model, we use 100 epochs with a 20-epoch early stopping criterion. We utilize the AdamW optimizer with a learning rate of 0.001. Additionally, we employ StepLR, to adjust the learning rate during training. For STFT computations, the frame size is set to 32 milliseconds, and the hop size to 10 milliseconds. The frequency range for the STFT is between 100 Hz and 8000 Hz, with an n_fft value of 512, which determines the length of the windowed signal after zero-padding.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.2" class="ltx_p">We use two primary metrics: mean absolute error (MAE) and accuracy (ACC). MAE quantifies the average magnitude of prediction errors, disregarding their direction. ACC, on the other hand, measures the percentage of predictions that are exactly correct or within a specified tolerance. We assess accuracy at two tolerance levels: within a <math id="S4.SS2.p2.1.m1.1" class="ltx_Math" alttext="10^{\circ}" display="inline"><semantics id="S4.SS2.p2.1.m1.1a"><msup id="S4.SS2.p2.1.m1.1.1" xref="S4.SS2.p2.1.m1.1.1.cmml"><mn id="S4.SS2.p2.1.m1.1.1.2" xref="S4.SS2.p2.1.m1.1.1.2.cmml">10</mn><mo id="S4.SS2.p2.1.m1.1.1.3" xref="S4.SS2.p2.1.m1.1.1.3.cmml">âˆ˜</mo></msup><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.1.m1.1b"><apply id="S4.SS2.p2.1.m1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p2.1.m1.1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1">superscript</csymbol><cn type="integer" id="S4.SS2.p2.1.m1.1.1.2.cmml" xref="S4.SS2.p2.1.m1.1.1.2">10</cn><compose id="S4.SS2.p2.1.m1.1.1.3.cmml" xref="S4.SS2.p2.1.m1.1.1.3"></compose></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.1.m1.1c">10^{\circ}</annotation></semantics></math> and <math id="S4.SS2.p2.2.m2.1" class="ltx_Math" alttext="15^{\circ}" display="inline"><semantics id="S4.SS2.p2.2.m2.1a"><msup id="S4.SS2.p2.2.m2.1.1" xref="S4.SS2.p2.2.m2.1.1.cmml"><mn id="S4.SS2.p2.2.m2.1.1.2" xref="S4.SS2.p2.2.m2.1.1.2.cmml">15</mn><mo id="S4.SS2.p2.2.m2.1.1.3" xref="S4.SS2.p2.2.m2.1.1.3.cmml">âˆ˜</mo></msup><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.2.m2.1b"><apply id="S4.SS2.p2.2.m2.1.1.cmml" xref="S4.SS2.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.p2.2.m2.1.1.1.cmml" xref="S4.SS2.p2.2.m2.1.1">superscript</csymbol><cn type="integer" id="S4.SS2.p2.2.m2.1.1.2.cmml" xref="S4.SS2.p2.2.m2.1.1.2">15</cn><compose id="S4.SS2.p2.2.m2.1.1.3.cmml" xref="S4.SS2.p2.2.m2.1.1.3"></compose></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.2.m2.1c">15^{\circ}</annotation></semantics></math> error margin. These tolerance levels provide insight into the modelâ€™s precision as well as its practical effectiveness.</p>
</div>
<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE I: </span>Ablation studies of TF-Mamba on simulated data. â€œExpandâ€ denotes the expand factor for the Mamba layer.</figcaption>
<div id="S4.T1.6" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:115.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(13.5pt,-3.6pt) scale(1.06661179793569,1.06661179793569) ;">
<table id="S4.T1.6.6" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T1.3.3.3" class="ltx_tr">
<th id="S4.T1.3.3.3.4" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><span id="S4.T1.3.3.3.4.1" class="ltx_text ltx_font_bold">Components</span></th>
<td id="S4.T1.3.3.3.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.3.3.3.5.1" class="ltx_text ltx_font_bold">Params[M]</span></td>
<td id="S4.T1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.1.1.1.1.1" class="ltx_text ltx_font_bold">ACC(<math id="S4.T1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="15^{\circ}" display="inline"><semantics id="S4.T1.1.1.1.1.1.m1.1a"><msup id="S4.T1.1.1.1.1.1.m1.1.1" xref="S4.T1.1.1.1.1.1.m1.1.1.cmml"><mn id="S4.T1.1.1.1.1.1.m1.1.1.2" xref="S4.T1.1.1.1.1.1.m1.1.1.2.cmml">15</mn><mo id="S4.T1.1.1.1.1.1.m1.1.1.3" xref="S4.T1.1.1.1.1.1.m1.1.1.3.cmml">âˆ˜</mo></msup><annotation-xml encoding="MathML-Content" id="S4.T1.1.1.1.1.1.m1.1b"><apply id="S4.T1.1.1.1.1.1.m1.1.1.cmml" xref="S4.T1.1.1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.1.1.1.1.1.m1.1.1.1.cmml" xref="S4.T1.1.1.1.1.1.m1.1.1">superscript</csymbol><cn type="integer" id="S4.T1.1.1.1.1.1.m1.1.1.2.cmml" xref="S4.T1.1.1.1.1.1.m1.1.1.2">15</cn><compose id="S4.T1.1.1.1.1.1.m1.1.1.3.cmml" xref="S4.T1.1.1.1.1.1.m1.1.1.3"></compose></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.1.1.1.1.1.m1.1c">15^{\circ}</annotation></semantics></math>) [%]</span></td>
<td id="S4.T1.2.2.2.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.2.2.2.2.1" class="ltx_text ltx_font_bold">ACC(<math id="S4.T1.2.2.2.2.1.m1.1" class="ltx_Math" alttext="10^{\circ}" display="inline"><semantics id="S4.T1.2.2.2.2.1.m1.1a"><msup id="S4.T1.2.2.2.2.1.m1.1.1" xref="S4.T1.2.2.2.2.1.m1.1.1.cmml"><mn id="S4.T1.2.2.2.2.1.m1.1.1.2" xref="S4.T1.2.2.2.2.1.m1.1.1.2.cmml">10</mn><mo id="S4.T1.2.2.2.2.1.m1.1.1.3" xref="S4.T1.2.2.2.2.1.m1.1.1.3.cmml">âˆ˜</mo></msup><annotation-xml encoding="MathML-Content" id="S4.T1.2.2.2.2.1.m1.1b"><apply id="S4.T1.2.2.2.2.1.m1.1.1.cmml" xref="S4.T1.2.2.2.2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.2.2.2.2.1.m1.1.1.1.cmml" xref="S4.T1.2.2.2.2.1.m1.1.1">superscript</csymbol><cn type="integer" id="S4.T1.2.2.2.2.1.m1.1.1.2.cmml" xref="S4.T1.2.2.2.2.1.m1.1.1.2">10</cn><compose id="S4.T1.2.2.2.2.1.m1.1.1.3.cmml" xref="S4.T1.2.2.2.2.1.m1.1.1.3"></compose></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.2.2.2.2.1.m1.1c">10^{\circ}</annotation></semantics></math>) [%]</span></td>
<td id="S4.T1.3.3.3.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.3.3.3.3.1" class="ltx_text ltx_font_bold">MAE [<sup id="S4.T1.3.3.3.3.1.1" class="ltx_sup"><span id="S4.T1.3.3.3.3.1.1.1" class="ltx_text ltx_font_medium">âˆ˜</span></sup>]</span></td>
</tr>
<tr id="S4.T1.4.4.4" class="ltx_tr">
<th id="S4.T1.4.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Block <math id="S4.T1.4.4.4.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T1.4.4.4.1.m1.1a"><mo id="S4.T1.4.4.4.1.m1.1.1" xref="S4.T1.4.4.4.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S4.T1.4.4.4.1.m1.1b"><times id="S4.T1.4.4.4.1.m1.1.1.cmml" xref="S4.T1.4.4.4.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.4.4.4.1.m1.1c">\times</annotation></semantics></math> 3 (Expand = [2,2,2])</th>
<td id="S4.T1.4.4.4.2" class="ltx_td ltx_align_center ltx_border_t">0.9</td>
<td id="S4.T1.4.4.4.3" class="ltx_td ltx_align_center ltx_border_t">96.5</td>
<td id="S4.T1.4.4.4.4" class="ltx_td ltx_align_center ltx_border_t">92.6</td>
<td id="S4.T1.4.4.4.5" class="ltx_td ltx_align_center ltx_border_t">2.89</td>
</tr>
<tr id="S4.T1.5.5.5" class="ltx_tr">
<th id="S4.T1.5.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Block <math id="S4.T1.5.5.5.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T1.5.5.5.1.m1.1a"><mo id="S4.T1.5.5.5.1.m1.1.1" xref="S4.T1.5.5.5.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S4.T1.5.5.5.1.m1.1b"><times id="S4.T1.5.5.5.1.m1.1.1.cmml" xref="S4.T1.5.5.5.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.5.5.5.1.m1.1c">\times</annotation></semantics></math> 4 (Expand = [2,2,4,4])</th>
<td id="S4.T1.5.5.5.2" class="ltx_td ltx_align_center ltx_border_t">1.3</td>
<td id="S4.T1.5.5.5.3" class="ltx_td ltx_align_center ltx_border_t">98.4</td>
<td id="S4.T1.5.5.5.4" class="ltx_td ltx_align_center ltx_border_t">94.9</td>
<td id="S4.T1.5.5.5.5" class="ltx_td ltx_align_center ltx_border_t">2.87</td>
</tr>
<tr id="S4.T1.6.6.6" class="ltx_tr">
<th id="S4.T1.6.6.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Block <math id="S4.T1.6.6.6.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T1.6.6.6.1.m1.1a"><mo id="S4.T1.6.6.6.1.m1.1.1" xref="S4.T1.6.6.6.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S4.T1.6.6.6.1.m1.1b"><times id="S4.T1.6.6.6.1.m1.1.1.cmml" xref="S4.T1.6.6.6.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.6.6.6.1.m1.1c">\times</annotation></semantics></math> 5 (Expand = [2,2,4,4,8])</th>
<td id="S4.T1.6.6.6.2" class="ltx_td ltx_align_center ltx_border_t">1.8</td>
<td id="S4.T1.6.6.6.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.6.6.6.3.1" class="ltx_text ltx_font_bold">98.9</span></td>
<td id="S4.T1.6.6.6.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.6.6.6.4.1" class="ltx_text ltx_font_bold">96.9</span></td>
<td id="S4.T1.6.6.6.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.6.6.6.5.1" class="ltx_text ltx_font_bold">2.52</span></td>
</tr>
<tr id="S4.T1.6.6.7.1" class="ltx_tr">
<th id="S4.T1.6.6.7.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">w/o BiMamba</th>
<td id="S4.T1.6.6.7.1.2" class="ltx_td ltx_align_center">1.4</td>
<td id="S4.T1.6.6.7.1.3" class="ltx_td ltx_align_center">97.1</td>
<td id="S4.T1.6.6.7.1.4" class="ltx_td ltx_align_center">93.6</td>
<td id="S4.T1.6.6.7.1.5" class="ltx_td ltx_align_center">2.84</td>
</tr>
<tr id="S4.T1.6.6.8.2" class="ltx_tr">
<th id="S4.T1.6.6.8.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b">w/o Skip</th>
<td id="S4.T1.6.6.8.2.2" class="ltx_td ltx_align_center ltx_border_b">1.8</td>
<td id="S4.T1.6.6.8.2.3" class="ltx_td ltx_align_center ltx_border_b">97.9</td>
<td id="S4.T1.6.6.8.2.4" class="ltx_td ltx_align_center ltx_border_b">95.4</td>
<td id="S4.T1.6.6.8.2.5" class="ltx_td ltx_align_center ltx_border_b">2.65</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS3.4.1.1" class="ltx_text">IV-C</span> </span><span id="S4.SS3.5.2" class="ltx_text ltx_font_italic">Reference baselines</span>
</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">We compared the following five moving SSL methods: Cross3DÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>, SELDnetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>, SE-ResnetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>, SALSA-LiteÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>, and FN-SSLÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>. It is noted that the SELDnet, SALSA-Lite, and SE-ResNet are models designed for joint sound event detection and localization; hence, we only utilize their localization branches for comparison. All these methods are reproduced and trained on the same dataset as our proposed method. We adjust the time pooling kernel size in each method to achieve the same output frame rate across all models for consistency.</p>
</div>
<figure id="S4.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE II: </span>Performance comparison in ACC and MAE on simulated data.</figcaption>
<div id="S4.T2.6" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:142.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-2.2pt,0.7pt) scale(0.989948395931982,0.989948395931982) ;">
<table id="S4.T2.6.6" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T2.6.6.7.1" class="ltx_tr">
<th id="S4.T2.6.6.7.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" rowspan="2"><span id="S4.T2.6.6.7.1.1.1" class="ltx_text ltx_font_bold">Methods</span></th>
<th id="S4.T2.6.6.7.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T2.6.6.7.1.2.1" class="ltx_text ltx_font_bold">Params</span></th>
<th id="S4.T2.6.6.7.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="3"><span id="S4.T2.6.6.7.1.3.1" class="ltx_text ltx_font_bold">Clean</span></th>
<th id="S4.T2.6.6.7.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="3"><span id="S4.T2.6.6.7.1.4.1" class="ltx_text ltx_font_bold">-10 dB</span></th>
</tr>
<tr id="S4.T2.6.6.6" class="ltx_tr">
<th id="S4.T2.6.6.6.7" class="ltx_td ltx_align_center ltx_th ltx_th_column">[M]</th>
<th id="S4.T2.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T2.1.1.1.1.1" class="ltx_text ltx_font_bold">ACC(<math id="S4.T2.1.1.1.1.1.m1.1" class="ltx_Math" alttext="15^{\circ}" display="inline"><semantics id="S4.T2.1.1.1.1.1.m1.1a"><msup id="S4.T2.1.1.1.1.1.m1.1.1" xref="S4.T2.1.1.1.1.1.m1.1.1.cmml"><mn id="S4.T2.1.1.1.1.1.m1.1.1.2" xref="S4.T2.1.1.1.1.1.m1.1.1.2.cmml">15</mn><mo id="S4.T2.1.1.1.1.1.m1.1.1.3" xref="S4.T2.1.1.1.1.1.m1.1.1.3.cmml">âˆ˜</mo></msup><annotation-xml encoding="MathML-Content" id="S4.T2.1.1.1.1.1.m1.1b"><apply id="S4.T2.1.1.1.1.1.m1.1.1.cmml" xref="S4.T2.1.1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T2.1.1.1.1.1.m1.1.1.1.cmml" xref="S4.T2.1.1.1.1.1.m1.1.1">superscript</csymbol><cn type="integer" id="S4.T2.1.1.1.1.1.m1.1.1.2.cmml" xref="S4.T2.1.1.1.1.1.m1.1.1.2">15</cn><compose id="S4.T2.1.1.1.1.1.m1.1.1.3.cmml" xref="S4.T2.1.1.1.1.1.m1.1.1.3"></compose></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.1.1.1.1.1.m1.1c">15^{\circ}</annotation></semantics></math>)</span></th>
<th id="S4.T2.2.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T2.2.2.2.2.1" class="ltx_text ltx_font_bold">ACC(<math id="S4.T2.2.2.2.2.1.m1.1" class="ltx_Math" alttext="10^{\circ}" display="inline"><semantics id="S4.T2.2.2.2.2.1.m1.1a"><msup id="S4.T2.2.2.2.2.1.m1.1.1" xref="S4.T2.2.2.2.2.1.m1.1.1.cmml"><mn id="S4.T2.2.2.2.2.1.m1.1.1.2" xref="S4.T2.2.2.2.2.1.m1.1.1.2.cmml">10</mn><mo id="S4.T2.2.2.2.2.1.m1.1.1.3" xref="S4.T2.2.2.2.2.1.m1.1.1.3.cmml">âˆ˜</mo></msup><annotation-xml encoding="MathML-Content" id="S4.T2.2.2.2.2.1.m1.1b"><apply id="S4.T2.2.2.2.2.1.m1.1.1.cmml" xref="S4.T2.2.2.2.2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T2.2.2.2.2.1.m1.1.1.1.cmml" xref="S4.T2.2.2.2.2.1.m1.1.1">superscript</csymbol><cn type="integer" id="S4.T2.2.2.2.2.1.m1.1.1.2.cmml" xref="S4.T2.2.2.2.2.1.m1.1.1.2">10</cn><compose id="S4.T2.2.2.2.2.1.m1.1.1.3.cmml" xref="S4.T2.2.2.2.2.1.m1.1.1.3"></compose></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.2.2.2.2.1.m1.1c">10^{\circ}</annotation></semantics></math>)</span></th>
<th id="S4.T2.3.3.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T2.3.3.3.3.1" class="ltx_text ltx_font_bold">MAE[<sup id="S4.T2.3.3.3.3.1.1" class="ltx_sup"><span id="S4.T2.3.3.3.3.1.1.1" class="ltx_text ltx_font_medium">âˆ˜</span></sup>]</span></th>
<th id="S4.T2.4.4.4.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T2.4.4.4.4.1" class="ltx_text ltx_font_bold">ACC(<math id="S4.T2.4.4.4.4.1.m1.1" class="ltx_Math" alttext="15^{\circ}" display="inline"><semantics id="S4.T2.4.4.4.4.1.m1.1a"><msup id="S4.T2.4.4.4.4.1.m1.1.1" xref="S4.T2.4.4.4.4.1.m1.1.1.cmml"><mn id="S4.T2.4.4.4.4.1.m1.1.1.2" xref="S4.T2.4.4.4.4.1.m1.1.1.2.cmml">15</mn><mo id="S4.T2.4.4.4.4.1.m1.1.1.3" xref="S4.T2.4.4.4.4.1.m1.1.1.3.cmml">âˆ˜</mo></msup><annotation-xml encoding="MathML-Content" id="S4.T2.4.4.4.4.1.m1.1b"><apply id="S4.T2.4.4.4.4.1.m1.1.1.cmml" xref="S4.T2.4.4.4.4.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T2.4.4.4.4.1.m1.1.1.1.cmml" xref="S4.T2.4.4.4.4.1.m1.1.1">superscript</csymbol><cn type="integer" id="S4.T2.4.4.4.4.1.m1.1.1.2.cmml" xref="S4.T2.4.4.4.4.1.m1.1.1.2">15</cn><compose id="S4.T2.4.4.4.4.1.m1.1.1.3.cmml" xref="S4.T2.4.4.4.4.1.m1.1.1.3"></compose></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.4.4.4.4.1.m1.1c">15^{\circ}</annotation></semantics></math>)</span></th>
<th id="S4.T2.5.5.5.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T2.5.5.5.5.1" class="ltx_text ltx_font_bold">ACC(<math id="S4.T2.5.5.5.5.1.m1.1" class="ltx_Math" alttext="10^{\circ}" display="inline"><semantics id="S4.T2.5.5.5.5.1.m1.1a"><msup id="S4.T2.5.5.5.5.1.m1.1.1" xref="S4.T2.5.5.5.5.1.m1.1.1.cmml"><mn id="S4.T2.5.5.5.5.1.m1.1.1.2" xref="S4.T2.5.5.5.5.1.m1.1.1.2.cmml">10</mn><mo id="S4.T2.5.5.5.5.1.m1.1.1.3" xref="S4.T2.5.5.5.5.1.m1.1.1.3.cmml">âˆ˜</mo></msup><annotation-xml encoding="MathML-Content" id="S4.T2.5.5.5.5.1.m1.1b"><apply id="S4.T2.5.5.5.5.1.m1.1.1.cmml" xref="S4.T2.5.5.5.5.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T2.5.5.5.5.1.m1.1.1.1.cmml" xref="S4.T2.5.5.5.5.1.m1.1.1">superscript</csymbol><cn type="integer" id="S4.T2.5.5.5.5.1.m1.1.1.2.cmml" xref="S4.T2.5.5.5.5.1.m1.1.1.2">10</cn><compose id="S4.T2.5.5.5.5.1.m1.1.1.3.cmml" xref="S4.T2.5.5.5.5.1.m1.1.1.3"></compose></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.5.5.5.5.1.m1.1c">10^{\circ}</annotation></semantics></math>)</span></th>
<th id="S4.T2.6.6.6.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T2.6.6.6.6.1" class="ltx_text ltx_font_bold">MAE[<sup id="S4.T2.6.6.6.6.1.1" class="ltx_sup"><span id="S4.T2.6.6.6.6.1.1.1" class="ltx_text ltx_font_medium">âˆ˜</span></sup>]</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T2.6.6.8.1" class="ltx_tr">
<td id="S4.T2.6.6.8.1.1" class="ltx_td ltx_align_center ltx_border_t">SELDnet</td>
<td id="S4.T2.6.6.8.1.2" class="ltx_td ltx_align_center ltx_border_t">0.8</td>
<td id="S4.T2.6.6.8.1.3" class="ltx_td ltx_align_center ltx_border_t">96.6</td>
<td id="S4.T2.6.6.8.1.4" class="ltx_td ltx_align_center ltx_border_t">93.8</td>
<td id="S4.T2.6.6.8.1.5" class="ltx_td ltx_align_center ltx_border_t">3.5</td>
<td id="S4.T2.6.6.8.1.6" class="ltx_td ltx_align_center ltx_border_t">52.8</td>
<td id="S4.T2.6.6.8.1.7" class="ltx_td ltx_align_center ltx_border_t">50.2</td>
<td id="S4.T2.6.6.8.1.8" class="ltx_td ltx_align_center ltx_border_t">16.7</td>
</tr>
<tr id="S4.T2.6.6.9.2" class="ltx_tr">
<td id="S4.T2.6.6.9.2.1" class="ltx_td ltx_align_center">FN-SSL</td>
<td id="S4.T2.6.6.9.2.2" class="ltx_td ltx_align_center">2.1</td>
<td id="S4.T2.6.6.9.2.3" class="ltx_td ltx_align_center">98.3</td>
<td id="S4.T2.6.6.9.2.4" class="ltx_td ltx_align_center">95.9</td>
<td id="S4.T2.6.6.9.2.5" class="ltx_td ltx_align_center">2.8</td>
<td id="S4.T2.6.6.9.2.6" class="ltx_td ltx_align_center">71.6</td>
<td id="S4.T2.6.6.9.2.7" class="ltx_td ltx_align_center">68.4</td>
<td id="S4.T2.6.6.9.2.8" class="ltx_td ltx_align_center">8.9</td>
</tr>
<tr id="S4.T2.6.6.10.3" class="ltx_tr">
<td id="S4.T2.6.6.10.3.1" class="ltx_td ltx_align_center">Cross3D</td>
<td id="S4.T2.6.6.10.3.2" class="ltx_td ltx_align_center">5.6</td>
<td id="S4.T2.6.6.10.3.3" class="ltx_td ltx_align_center">84.8</td>
<td id="S4.T2.6.6.10.3.4" class="ltx_td ltx_align_center">81.3</td>
<td id="S4.T2.6.6.10.3.5" class="ltx_td ltx_align_center">6.5</td>
<td id="S4.T2.6.6.10.3.6" class="ltx_td ltx_align_center">38.8</td>
<td id="S4.T2.6.6.10.3.7" class="ltx_td ltx_align_center">35.4</td>
<td id="S4.T2.6.6.10.3.8" class="ltx_td ltx_align_center">26.3</td>
</tr>
<tr id="S4.T2.6.6.11.4" class="ltx_tr">
<td id="S4.T2.6.6.11.4.1" class="ltx_td ltx_align_center">SE-ResNet</td>
<td id="S4.T2.6.6.11.4.2" class="ltx_td ltx_align_center">10.2</td>
<td id="S4.T2.6.6.11.4.3" class="ltx_td ltx_align_center">96.7</td>
<td id="S4.T2.6.6.11.4.4" class="ltx_td ltx_align_center">95.1</td>
<td id="S4.T2.6.6.11.4.5" class="ltx_td ltx_align_center">3.2</td>
<td id="S4.T2.6.6.11.4.6" class="ltx_td ltx_align_center">67.7</td>
<td id="S4.T2.6.6.11.4.7" class="ltx_td ltx_align_center">64.6</td>
<td id="S4.T2.6.6.11.4.8" class="ltx_td ltx_align_center">10.8</td>
</tr>
<tr id="S4.T2.6.6.12.5" class="ltx_tr">
<td id="S4.T2.6.6.12.5.1" class="ltx_td ltx_align_center">SALSA-Lite</td>
<td id="S4.T2.6.6.12.5.2" class="ltx_td ltx_align_center">14.0</td>
<td id="S4.T2.6.6.12.5.3" class="ltx_td ltx_align_center">96.8</td>
<td id="S4.T2.6.6.12.5.4" class="ltx_td ltx_align_center">95.6</td>
<td id="S4.T2.6.6.12.5.5" class="ltx_td ltx_align_center">2.9</td>
<td id="S4.T2.6.6.12.5.6" class="ltx_td ltx_align_center">69.1</td>
<td id="S4.T2.6.6.12.5.7" class="ltx_td ltx_align_center">65.7</td>
<td id="S4.T2.6.6.12.5.8" class="ltx_td ltx_align_center">10.3</td>
</tr>
<tr id="S4.T2.6.6.13.6" class="ltx_tr">
<td id="S4.T2.6.6.13.6.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">TF-Mamba</td>
<td id="S4.T2.6.6.13.6.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">1.8</td>
<td id="S4.T2.6.6.13.6.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S4.T2.6.6.13.6.3.1" class="ltx_text ltx_font_bold">98.9</span></td>
<td id="S4.T2.6.6.13.6.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S4.T2.6.6.13.6.4.1" class="ltx_text ltx_font_bold">96.9</span></td>
<td id="S4.T2.6.6.13.6.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S4.T2.6.6.13.6.5.1" class="ltx_text ltx_font_bold">2.5</span></td>
<td id="S4.T2.6.6.13.6.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S4.T2.6.6.13.6.6.1" class="ltx_text ltx_font_bold">74.6</span></td>
<td id="S4.T2.6.6.13.6.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S4.T2.6.6.13.6.7.1" class="ltx_text ltx_font_bold">72.5</span></td>
<td id="S4.T2.6.6.13.6.8" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S4.T2.6.6.13.6.8.1" class="ltx_text ltx_font_bold">8.2</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure id="S4.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE III: </span>Performance comparison in ACC and MAE on LOCATA dataset.</figcaption>
<div id="S4.T3.3" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:390.3pt;height:167.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(48.4pt,-20.8pt) scale(1.32973407007297,1.32973407007297) ;">
<table id="S4.T3.3.3" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T3.3.3.3" class="ltx_tr">
<th id="S4.T3.3.3.3.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T3.3.3.3.4.1" class="ltx_text ltx_font_bold">Methods</span></th>
<th id="S4.T3.3.3.3.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T3.3.3.3.5.1" class="ltx_text ltx_font_bold">Params[M]</span></th>
<th id="S4.T3.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T3.1.1.1.1.1" class="ltx_text ltx_font_bold">ACC(<math id="S4.T3.1.1.1.1.1.m1.1" class="ltx_Math" alttext="15^{\circ}" display="inline"><semantics id="S4.T3.1.1.1.1.1.m1.1a"><msup id="S4.T3.1.1.1.1.1.m1.1.1" xref="S4.T3.1.1.1.1.1.m1.1.1.cmml"><mn id="S4.T3.1.1.1.1.1.m1.1.1.2" xref="S4.T3.1.1.1.1.1.m1.1.1.2.cmml">15</mn><mo id="S4.T3.1.1.1.1.1.m1.1.1.3" xref="S4.T3.1.1.1.1.1.m1.1.1.3.cmml">âˆ˜</mo></msup><annotation-xml encoding="MathML-Content" id="S4.T3.1.1.1.1.1.m1.1b"><apply id="S4.T3.1.1.1.1.1.m1.1.1.cmml" xref="S4.T3.1.1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T3.1.1.1.1.1.m1.1.1.1.cmml" xref="S4.T3.1.1.1.1.1.m1.1.1">superscript</csymbol><cn type="integer" id="S4.T3.1.1.1.1.1.m1.1.1.2.cmml" xref="S4.T3.1.1.1.1.1.m1.1.1.2">15</cn><compose id="S4.T3.1.1.1.1.1.m1.1.1.3.cmml" xref="S4.T3.1.1.1.1.1.m1.1.1.3"></compose></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.1.1.1.1.1.m1.1c">15^{\circ}</annotation></semantics></math>)</span></th>
<th id="S4.T3.2.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T3.2.2.2.2.1" class="ltx_text ltx_font_bold">ACC(<math id="S4.T3.2.2.2.2.1.m1.1" class="ltx_Math" alttext="10^{\circ}" display="inline"><semantics id="S4.T3.2.2.2.2.1.m1.1a"><msup id="S4.T3.2.2.2.2.1.m1.1.1" xref="S4.T3.2.2.2.2.1.m1.1.1.cmml"><mn id="S4.T3.2.2.2.2.1.m1.1.1.2" xref="S4.T3.2.2.2.2.1.m1.1.1.2.cmml">10</mn><mo id="S4.T3.2.2.2.2.1.m1.1.1.3" xref="S4.T3.2.2.2.2.1.m1.1.1.3.cmml">âˆ˜</mo></msup><annotation-xml encoding="MathML-Content" id="S4.T3.2.2.2.2.1.m1.1b"><apply id="S4.T3.2.2.2.2.1.m1.1.1.cmml" xref="S4.T3.2.2.2.2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T3.2.2.2.2.1.m1.1.1.1.cmml" xref="S4.T3.2.2.2.2.1.m1.1.1">superscript</csymbol><cn type="integer" id="S4.T3.2.2.2.2.1.m1.1.1.2.cmml" xref="S4.T3.2.2.2.2.1.m1.1.1.2">10</cn><compose id="S4.T3.2.2.2.2.1.m1.1.1.3.cmml" xref="S4.T3.2.2.2.2.1.m1.1.1.3"></compose></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.2.2.2.2.1.m1.1c">10^{\circ}</annotation></semantics></math>)</span></th>
<th id="S4.T3.3.3.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T3.3.3.3.3.1" class="ltx_text ltx_font_bold">MAE [<sup id="S4.T3.3.3.3.3.1.1" class="ltx_sup"><span id="S4.T3.3.3.3.3.1.1.1" class="ltx_text ltx_font_medium">âˆ˜</span></sup>]</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T3.3.3.4.1" class="ltx_tr">
<td id="S4.T3.3.3.4.1.1" class="ltx_td ltx_align_center ltx_border_t">SELDnet</td>
<td id="S4.T3.3.3.4.1.2" class="ltx_td ltx_align_center ltx_border_t">0.8</td>
<td id="S4.T3.3.3.4.1.3" class="ltx_td ltx_align_center ltx_border_t">94.1</td>
<td id="S4.T3.3.3.4.1.4" class="ltx_td ltx_align_center ltx_border_t">91.2</td>
<td id="S4.T3.3.3.4.1.5" class="ltx_td ltx_align_center ltx_border_t">5.3</td>
</tr>
<tr id="S4.T3.3.3.5.2" class="ltx_tr">
<td id="S4.T3.3.3.5.2.1" class="ltx_td ltx_align_center">FN-SSL</td>
<td id="S4.T3.3.3.5.2.2" class="ltx_td ltx_align_center">2.1</td>
<td id="S4.T3.3.3.5.2.3" class="ltx_td ltx_align_center">96.7</td>
<td id="S4.T3.3.3.5.2.4" class="ltx_td ltx_align_center">93.3</td>
<td id="S4.T3.3.3.5.2.5" class="ltx_td ltx_align_center">3.6</td>
</tr>
<tr id="S4.T3.3.3.6.3" class="ltx_tr">
<td id="S4.T3.3.3.6.3.1" class="ltx_td ltx_align_center">Cross3D</td>
<td id="S4.T3.3.3.6.3.2" class="ltx_td ltx_align_center">5.6</td>
<td id="S4.T3.3.3.6.3.3" class="ltx_td ltx_align_center">94.8</td>
<td id="S4.T3.3.3.6.3.4" class="ltx_td ltx_align_center">91.4</td>
<td id="S4.T3.3.3.6.3.5" class="ltx_td ltx_align_center">5.1</td>
</tr>
<tr id="S4.T3.3.3.7.4" class="ltx_tr">
<td id="S4.T3.3.3.7.4.1" class="ltx_td ltx_align_center">SE-ResNet</td>
<td id="S4.T3.3.3.7.4.2" class="ltx_td ltx_align_center">10.2</td>
<td id="S4.T3.3.3.7.4.3" class="ltx_td ltx_align_center">94.0</td>
<td id="S4.T3.3.3.7.4.4" class="ltx_td ltx_align_center">90.7</td>
<td id="S4.T3.3.3.7.4.5" class="ltx_td ltx_align_center">6.5</td>
</tr>
<tr id="S4.T3.3.3.8.5" class="ltx_tr">
<td id="S4.T3.3.3.8.5.1" class="ltx_td ltx_align_center">SALSA-Lite</td>
<td id="S4.T3.3.3.8.5.2" class="ltx_td ltx_align_center">14.0</td>
<td id="S4.T3.3.3.8.5.3" class="ltx_td ltx_align_center">95.0</td>
<td id="S4.T3.3.3.8.5.4" class="ltx_td ltx_align_center">92.5</td>
<td id="S4.T3.3.3.8.5.5" class="ltx_td ltx_align_center">4.6</td>
</tr>
<tr id="S4.T3.3.3.9.6" class="ltx_tr">
<td id="S4.T3.3.3.9.6.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">TF-Mamba</td>
<td id="S4.T3.3.3.9.6.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_t">1.8</td>
<td id="S4.T3.3.3.9.6.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S4.T3.3.3.9.6.3.1" class="ltx_text ltx_font_bold">97.2</span></td>
<td id="S4.T3.3.3.9.6.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S4.T3.3.3.9.6.4.1" class="ltx_text ltx_font_bold">94.3</span></td>
<td id="S4.T3.3.3.9.6.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S4.T3.3.3.9.6.5.1" class="ltx_text ltx_font_bold">3.2</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Results and Analysis</span>
</h2>

<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS1.4.1.1" class="ltx_text">V-A</span> </span><span id="S5.SS1.5.2" class="ltx_text ltx_font_italic">Ablation: Finding the best configuration for TF-Mamba</span>
</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.7" class="ltx_p">The ablation study results for TF-Mamba, shown in TableÂ <a href="#S4.T1" title="TABLE I â€£ IV-B Implementation details and metrics â€£ IV Experiment Setting â€£ TF-Mamba: A Time-Frequency Network for Sound Source Localization" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a>, highlight the importance of different components in the network. â€œBlock <math id="S5.SS1.p1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.SS1.p1.1.m1.1a"><mo id="S5.SS1.p1.1.m1.1.1" xref="S5.SS1.p1.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.1.m1.1b"><times id="S5.SS1.p1.1.m1.1.1.cmml" xref="S5.SS1.p1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.1.m1.1c">\times</annotation></semantics></math> <math id="S5.SS1.p1.2.m2.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S5.SS1.p1.2.m2.1a"><mi id="S5.SS1.p1.2.m2.1.1" xref="S5.SS1.p1.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.2.m2.1b"><ci id="S5.SS1.p1.2.m2.1.1.cmml" xref="S5.SS1.p1.2.m2.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.2.m2.1c">N</annotation></semantics></math>â€ refers to stacking <math id="S5.SS1.p1.3.m3.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S5.SS1.p1.3.m3.1a"><mi id="S5.SS1.p1.3.m3.1.1" xref="S5.SS1.p1.3.m3.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.3.m3.1b"><ci id="S5.SS1.p1.3.m3.1.1.cmml" xref="S5.SS1.p1.3.m3.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.3.m3.1c">N</annotation></semantics></math> number of TF-Mamba blocks. As the number of blocks increases from 3 to 5, accuracy (<math id="S5.SS1.p1.4.m4.1" class="ltx_Math" alttext="10^{\circ}" display="inline"><semantics id="S5.SS1.p1.4.m4.1a"><msup id="S5.SS1.p1.4.m4.1.1" xref="S5.SS1.p1.4.m4.1.1.cmml"><mn id="S5.SS1.p1.4.m4.1.1.2" xref="S5.SS1.p1.4.m4.1.1.2.cmml">10</mn><mo id="S5.SS1.p1.4.m4.1.1.3" xref="S5.SS1.p1.4.m4.1.1.3.cmml">âˆ˜</mo></msup><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.4.m4.1b"><apply id="S5.SS1.p1.4.m4.1.1.cmml" xref="S5.SS1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S5.SS1.p1.4.m4.1.1.1.cmml" xref="S5.SS1.p1.4.m4.1.1">superscript</csymbol><cn type="integer" id="S5.SS1.p1.4.m4.1.1.2.cmml" xref="S5.SS1.p1.4.m4.1.1.2">10</cn><compose id="S5.SS1.p1.4.m4.1.1.3.cmml" xref="S5.SS1.p1.4.m4.1.1.3"></compose></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.4.m4.1c">10^{\circ}</annotation></semantics></math> error
tolerances) improves from 92.6% to 96.9%, showing that deeper networks help the model understand more complex localization information. The â€œw/o BiMambaâ€ variant, which replaces the bidirectional mamba with unidirectional, reduces accuracy to 93.6% (<math id="S5.SS1.p1.5.m5.1" class="ltx_Math" alttext="10^{\circ}" display="inline"><semantics id="S5.SS1.p1.5.m5.1a"><msup id="S5.SS1.p1.5.m5.1.1" xref="S5.SS1.p1.5.m5.1.1.cmml"><mn id="S5.SS1.p1.5.m5.1.1.2" xref="S5.SS1.p1.5.m5.1.1.2.cmml">10</mn><mo id="S5.SS1.p1.5.m5.1.1.3" xref="S5.SS1.p1.5.m5.1.1.3.cmml">âˆ˜</mo></msup><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.5.m5.1b"><apply id="S5.SS1.p1.5.m5.1.1.cmml" xref="S5.SS1.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S5.SS1.p1.5.m5.1.1.1.cmml" xref="S5.SS1.p1.5.m5.1.1">superscript</csymbol><cn type="integer" id="S5.SS1.p1.5.m5.1.1.2.cmml" xref="S5.SS1.p1.5.m5.1.1.2">10</cn><compose id="S5.SS1.p1.5.m5.1.1.3.cmml" xref="S5.SS1.p1.5.m5.1.1.3"></compose></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.5.m5.1c">10^{\circ}</annotation></semantics></math>) and 97.1% (<math id="S5.SS1.p1.6.m6.1" class="ltx_Math" alttext="15^{\circ}" display="inline"><semantics id="S5.SS1.p1.6.m6.1a"><msup id="S5.SS1.p1.6.m6.1.1" xref="S5.SS1.p1.6.m6.1.1.cmml"><mn id="S5.SS1.p1.6.m6.1.1.2" xref="S5.SS1.p1.6.m6.1.1.2.cmml">15</mn><mo id="S5.SS1.p1.6.m6.1.1.3" xref="S5.SS1.p1.6.m6.1.1.3.cmml">âˆ˜</mo></msup><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.6.m6.1b"><apply id="S5.SS1.p1.6.m6.1.1.cmml" xref="S5.SS1.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S5.SS1.p1.6.m6.1.1.1.cmml" xref="S5.SS1.p1.6.m6.1.1">superscript</csymbol><cn type="integer" id="S5.SS1.p1.6.m6.1.1.2.cmml" xref="S5.SS1.p1.6.m6.1.1.2">15</cn><compose id="S5.SS1.p1.6.m6.1.1.3.cmml" xref="S5.SS1.p1.6.m6.1.1.3"></compose></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.6.m6.1c">15^{\circ}</annotation></semantics></math>). This shows that processing both past and future information is important for achieving good performance. The â€œw/o Skipâ€ variant, which excludes skip connections, also leads to a small drop in accuracy and a higher error. This confirms that skip connections are helpful in keeping information flowing through the network. We use Block <math id="S5.SS1.p1.7.m7.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.SS1.p1.7.m7.1a"><mo id="S5.SS1.p1.7.m7.1.1" xref="S5.SS1.p1.7.m7.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.7.m7.1b"><times id="S5.SS1.p1.7.m7.1.1.cmml" xref="S5.SS1.p1.7.m7.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.7.m7.1c">\times</annotation></semantics></math> 5 version with BiMamba and skip connections in the following comparison experiments.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS2.4.1.1" class="ltx_text">V-B</span> </span><span id="S5.SS2.5.2" class="ltx_text ltx_font_italic">Results on simulated data</span>
</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.2" class="ltx_p">We report the results in two acoustic conditions of testing in TableÂ <a href="#S4.T2" title="TABLE II â€£ IV-C Reference baselines â€£ IV Experiment Setting â€£ TF-Mamba: A Time-Frequency Network for Sound Source Localization" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a> which are â€œCleanâ€ and â€œSNR=-10 dBâ€. The results demonstrate that TF-Mamba outperforms other methods in clean and noisy environments, highlighting its robustness in handling noise and reverberation. With the highest accuracy in <math id="S5.SS2.p1.1.m1.1" class="ltx_Math" alttext="10^{\circ}" display="inline"><semantics id="S5.SS2.p1.1.m1.1a"><msup id="S5.SS2.p1.1.m1.1.1" xref="S5.SS2.p1.1.m1.1.1.cmml"><mn id="S5.SS2.p1.1.m1.1.1.2" xref="S5.SS2.p1.1.m1.1.1.2.cmml">10</mn><mo id="S5.SS2.p1.1.m1.1.1.3" xref="S5.SS2.p1.1.m1.1.1.3.cmml">âˆ˜</mo></msup><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.1.m1.1b"><apply id="S5.SS2.p1.1.m1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS2.p1.1.m1.1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1">superscript</csymbol><cn type="integer" id="S5.SS2.p1.1.m1.1.1.2.cmml" xref="S5.SS2.p1.1.m1.1.1.2">10</cn><compose id="S5.SS2.p1.1.m1.1.1.3.cmml" xref="S5.SS2.p1.1.m1.1.1.3"></compose></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.1.m1.1c">10^{\circ}</annotation></semantics></math> (96.9%), <math id="S5.SS2.p1.2.m2.1" class="ltx_Math" alttext="15^{\circ}" display="inline"><semantics id="S5.SS2.p1.2.m2.1a"><msup id="S5.SS2.p1.2.m2.1.1" xref="S5.SS2.p1.2.m2.1.1.cmml"><mn id="S5.SS2.p1.2.m2.1.1.2" xref="S5.SS2.p1.2.m2.1.1.2.cmml">15</mn><mo id="S5.SS2.p1.2.m2.1.1.3" xref="S5.SS2.p1.2.m2.1.1.3.cmml">âˆ˜</mo></msup><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.2.m2.1b"><apply id="S5.SS2.p1.2.m2.1.1.cmml" xref="S5.SS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS2.p1.2.m2.1.1.1.cmml" xref="S5.SS2.p1.2.m2.1.1">superscript</csymbol><cn type="integer" id="S5.SS2.p1.2.m2.1.1.2.cmml" xref="S5.SS2.p1.2.m2.1.1.2">15</cn><compose id="S5.SS2.p1.2.m2.1.1.3.cmml" xref="S5.SS2.p1.2.m2.1.1.3"></compose></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.2.m2.1c">15^{\circ}</annotation></semantics></math> (98.9%) and lowest MAE (2.5) in clean conditions, TF-Mamba outperforms FN-SSL. Although FN-SSL also analyzes direct-path features, TF-Mamba captures time and frequency dependencies more effectively, leading to better accuracy and robustness in challenging environments. In contrast, methods like SALSA-Lite, which processes noisy IPD with magnitude spectrum, and Cross3D, which uses the SRP-PHAT spatial spectrum, show significant performance drops under noise, underscoring the advantage of TF-Mamba.</p>
</div>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS3.4.1.1" class="ltx_text">V-C</span> </span><span id="S5.SS3.5.2" class="ltx_text ltx_font_italic">Results on real-world data</span>
</h3>

<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.1" class="ltx_p">The results on the LOCATA dataset are presented in TableÂ <a href="#S4.T3" title="TABLE III â€£ IV-C Reference baselines â€£ IV Experiment Setting â€£ TF-Mamba: A Time-Frequency Network for Sound Source Localization" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a>, where the models trained on simulated data are directly tested. We observe that TF-Mamba achieves the best performance, with the highest accuracy at both 15Â° (97.2%) and 10Â° (94.3%) error tolerances, and the lowest MAE (3.2). This datasetâ€™s relatively good acoustic conditions, which are almost noise-free and have an RT60 of 0.55s, allow all models to perform well. However, TF-Mambaâ€™s superior accuracy and lower error indicate its ability to better capture fine localization details compared to the other methods. Notably, methods like SE-ResNet and SALSA-Lite, which are more complex in terms of parameters, show higher MAE, while simpler models like SELDnet struggle with accuracy and MAE. TF-Mambaâ€™s approach also avoids the over-smoothing problem seen in other models during sudden sound source turns, maintaining strong localization performance in real-world conditions.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span id="S6.1.1" class="ltx_text ltx_font_smallcaps">Conclusion</span>
</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">In this paper, we introduced TF-Mamba, a novel architecture for SSL that leverages the Mamba SSM to fuse time and frequency features effectively. By replacing traditional LSTM blocks with bidirectional Mamba, TF-Mamba enhances the modeling of audio sequence contexts while maintaining computational efficiency. Our experimental results, conducted on both simulated and real-world datasets, demonstrate that TF-Mamba significantly outperforms existing state-of-the-art methods. These findings highlight the potential of SSM like Mamba in advancing SSL tasks, marking the first application of such models in this field.</p>
</div>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VII </span><span id="S7.1.1" class="ltx_text ltx_font_smallcaps">Acknowledgement</span>
</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">The authors would like to thank Yabo Wang et. al. (The authors of FN-SSLÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>) for their valuable suggestions during this work on reproducing the FN-SSL model and other baseline models.</p>
<div class="ltx_pagination ltx_role_newpage"></div>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
P.-A. Grumiaux, S.Â KitiÄ‡, L.Â Girin, and A.Â GuÃ©rin, â€œA survey of sound source localization with deep learning methods,â€ <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">The Journal of the Acoustical Society of America</em>, vol. 152, no.Â 1, pp. 107â€“151, 07 2022.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
P.Â Chiariotti, M.Â Martarelli, and P.Â Castellini, â€œAcoustic beamforming for noise source localizationâ€“Reviews, methodology and applications,â€ <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Mechanical Systems and Signal Processing</em>, vol. 120, pp. 422â€“448, 2019.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Z.Â Zhang, Y.Â Xu, M.Â Yu, S.-X. Zhang, L.Â Chen, and D.Â Yu, â€œADL-MVDR: All deep learning MVDR beamformer for target speech separation,â€ in <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, 2021, pp. 6089â€“6093.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Y.Â Xiao and R.Â K. Das, â€œDual Knowledge Distillation for Efficient Sound Event Detection,â€ in <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>.Â Â Â IEEE, 2024.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
H.-Y. Lee, J.-W. Cho, M.Â Kim, and H.-M. Park, â€œDNN-based feature enhancement using DOA-constrained ICA for robust speech recognition,â€ <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">IEEE Signal Processing Letters</em>, vol.Â 23, no.Â 8, pp. 1091â€“1095, 2016.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
A.Â Xenaki, J.Â BÃ¼nsowÂ Boldt, and M.Â GrÃ¦sbÃ¸llÂ Christensen, â€œSound source localization and speech enhancement with sparse bayesian learning beamforming,â€ <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">The Journal of the Acoustical Society of America</em>, vol. 143, no.Â 6, pp. 3912â€“3921, 2018.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
M.Â Raspaud, H.Â Viste, and G.Â Evangelista, â€œBinaural source localization by joint estimation of ILD and ITD,â€ <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Audio, Speech, and Language Processing</em>, vol.Â 18, no.Â 1, pp. 68â€“77, 2009.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
W.Â Zhang and B.Â D. Rao, â€œA two microphone-based approach for source localization of multiple speech sources,â€ <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Audio, Speech, and Language Processing</em>, vol.Â 18, no.Â 8, pp. 1913â€“1928, 2010.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
R.Â Schmidt, â€œMultiple emitter location and signal parameter estimation,â€ <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Antennas and Propagation</em>, vol.Â 34, no.Â 3, pp. 276â€“280, 1986.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
T.Â N.Â T. Nguyen, D.Â L. Jones, K.Â N. Watcharasupat, H.Â Phan, and W.-S. Gan, â€œSALSA-Lite: A fast and effective feature for polyphonic sound event localization and detection with microphone arrays,â€ in <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, 2022.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
A.Â Politis, K.Â Shimada, P.Â Sudarsanam, S.Â Adavanne, D.Â Krause, Y.Â Koyama, N.Â Takahashi, S.Â Takahashi, Y.Â Mitsufuji, and T.Â Virtanen, â€œSTARSS22: A dataset of spatial recordings of real scenes with spatiotemporal annotations of sound events,â€ in <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Proc. the Detection and Classification of Acoustic Scenes and Events Workshop (DCASE)</em>, 2022, pp. 125â€“129.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Y.Â Xiao and R.Â K. Das, â€œConfigurable DOA Estimation using Incremental Learning,â€ <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">arXiv preprint:2407.03661</em>, 2024.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
D.Â Suvorov, R.Â Zhukov, and G.Â Dong, â€œDeep residual network for sound source localization in the time domain,â€ <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Journal of Engineering and Applied Sciences</em>, vol.Â 13, no.Â 13, pp. 5096â€“5104, 2018.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
B.Â Yang, H.Â Liu, and X.Â Li, â€œSRP-DNN: Learning direct-path phase difference for multiple moving sound source localization,â€ in <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, 2022, pp. 721â€“725.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
N.Â Ma, T.Â May, and G.Â J. Brown, â€œExploiting deep neural networks and head movements for robust binaural localization of multiple sources in reverberant environments,â€ <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Audio, Speech, and Language Processing</em>, vol.Â 25, no.Â 12, pp. 2444â€“2453, 2017.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
S.Â Adavanne, A.Â Politis, and T.Â Virtanen, â€œDirection of arrival estimation for multiple sound sources using convolutional recurrent neural network,â€ in <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">Proc. IEEE 26th European Signal Processing Conference (EUSIPCO)</em>, 2018, pp. 1462â€“1466.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
C.Â Knapp and G.Â Carter, â€œThe generalized correlation method for estimation of time delay,â€ <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Acoustics, Speech, and Signal Processing</em>, vol.Â 24, no.Â 4, pp. 320â€“327, 1976.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Y.Â Wang, B.Â Yang, and X.Â Li, â€œFN-SSL: Full-band and narrow-band fusion for sound source localization,â€ in <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">Proc. Interspeech</em>, 2023, pp. 3779â€“3783.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
A.Â Gu, K.Â Goel, and C.Â Re, â€œEfficiently modeling long sequences with structured state spaces,â€ in <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">Proc. International Conference on Learning Representations (ICLR)</em>, 2021.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
A.Â Gu, K.Â Goel, A.Â Gupta, and C.Â Re, â€œOn the parameterization and initialization of diagonal state space models,â€ in <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">Proc. Advances in Neural Information Processing Systems (NIPS)</em>, vol.Â 35, 2022, pp. 35â€‰971â€“35â€‰983.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
L.Â Zhu, B.Â Liao, Q.Â Zhang, X.Â Wang, W.Â Liu, and X.Â Wang, â€œVision mamba: Efficient visual representation learning with bidirectional state space model,â€ <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">arXiv preprint:2401.09417</em>, 2024.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
O.Â Lieber, B.Â Lenz, H.Â Bata, G.Â Cohen, J.Â Osin, I.Â Dalmedigos, E.Â Safahi, S.Â Meirom, Y.Â Belinkov, S.Â Shalev-Shwartz, <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">etÂ al.</em>, â€œJamba: A hybrid transformer-mamba language model,â€ <em id="bib.bib22.2.2" class="ltx_emph ltx_font_italic">arXiv preprint:2403.19887</em>, 2024.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
K.Â Li and G.Â Chen, â€œSpmamba: State-space model is all you need in speech separation,â€ <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">arXiv preprint:2404.02063</em>, 2024.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
X.Â Jiang, C.Â Han, and N.Â Mesgarani, â€œDual-path mamba: Short and long-term bidirectional selective structured state space models for speech separation,â€ <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">arXiv preprint:2403.18257</em>, 2024.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
R.Â Chao, W.-H. Cheng, M.Â LaÂ Quatra, S.Â M. Siniscalchi, C.-H.Â H. Yang, S.-W. Fu, and Y.Â Tsao, â€œAn investigation of incorporating mamba for speech enhancement,â€ <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">arXiv preprint:2405.06573</em>, 2024.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
C.Â Quan and X.Â Li, â€œMultichannel long-term streaming neural speech enhancement for static and moving speakers,â€ <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">IEEE Signal Processing Letters</em>, pp. 1â€“5, 2024.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
M.Â H. Erol, A.Â Senocak, J.Â Feng, and J.Â S. Chung, â€œAudio Mamba: Bidirectional State Space Model for Audio Representation Learning,â€ <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">arXiv preprint:2406.03344</em>, 2024.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Y.Â Chen, J.Â Yi, J.Â Xue, C.Â Wang, X.Â Zhang, S.Â Dong, S.Â Zeng, J.Â Tao, L.Â Zhao, and C.Â Fan, â€œRawBMamba: End-to-end bidirectional state space model for audio deepfake detection,â€ in <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">Proc. Interspeech</em>, 2024.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
S.Â Shams, S.Â S. Dindar, X.Â Jiang, and N.Â Mesgarani, â€œSSAMBA: Self-Supervised Audio Representation Learning with Mamba State Space Model,â€ <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">arXiv preprint:2405.11831</em>, 2024.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
D.Â Diaz-Guerra, A.Â Miguel, and J.Â R. Beltran, â€œRobust sound source tracking using SRP-PHAT and 3D convolutional neural networks,â€ <em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Audio, Speech, and Language Processing</em>, vol.Â 29, pp. 300â€“311, 2020.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
J.Â S. Kim, H.Â J. Park, W.Â Shin, and S.Â W. Han, â€œA robust framework for sound event localization and detection on real recordings,â€ <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">Tech. Rep.</em>, 2022.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
S.Â Adavanne, A.Â Politis, J.Â Nikunen, and T.Â Virtanen, â€œSound event localization and detection of overlapping sources using convolutional recurrent neural networks,â€ <em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">IEEE Journal of Selected Topics in Signal Processing</em>, vol.Â 13, no.Â 1, pp. 34â€“48, 2018.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
T.Â N.Â T. Nguyen, D.Â L. Jones, K.Â N. Watcharasupat, H.Â Phan, and W.-S. Gan, â€œSALSA-Lite: A fast and effective feature for polyphonic sound event localization and detection with microphone arrays,â€ in <em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>.Â Â Â IEEE, 2022, pp. 716â€“720.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
A.Â Gu and T.Â Dao, â€œMamba: Linear-time sequence modeling with selective state spaces,â€ <em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">arXiv preprint:2312.00752</em>, 2023.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
G.Â Huang, Z.Â Liu, L.Â Van DerÂ Maaten, and K.Â Q. Weinberger, â€œDensely connected convolutional networks,â€ in <em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2017, pp. 4700â€“4708.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
W.Â He, P.Â Motlicek, and J.-M. Odobez, â€œNeural network adaptation and data augmentation for multi-speaker direction-of-arrival estimation,â€ <em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Audio, Speech, and Language Processing</em>, vol.Â 29, pp. 1303â€“1317, 2021.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
V.Â Panayotov, G.Â Chen, D.Â Povey, and S.Â Khudanpur, â€œLibrispeech: an asr corpus based on public domain audio books,â€ in <em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, 2015, pp. 5206â€“5210.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
D.Â Diaz-Guerra, A.Â Miguel, and J.Â R. Beltran, â€œgpuRIR: A python library for room impulse response simulation with GPU acceleration,â€ <em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">Multimedia Tools and Applications</em>, vol.Â 80, no.Â 4, pp. 5653â€“5671, 2021.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
A.Â Varga and H.Â J. Steeneken, â€œAssessment for automatic speech recognition: II. NOISEX-92: A database and an experiment to study the effect of additive noise on speech recognition systems,â€ <em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">Speech communication</em>, vol.Â 12, no.Â 3, pp. 247â€“251, 1993.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
E.Â A. Habets, I.Â Cohen, and S.Â Gannot, â€œGenerating nonstationary multisensor signals under a spatial coherence constraint,â€ <em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">The Journal of the Acoustical Society of America</em>, vol. 124, no.Â 5, pp. 2911â€“2917, 2008.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
H.Â W. LÃ¶llmann, C.Â Evers, A.Â Schmidt, H.Â Mellmann, H.Â Barfuss, P.Â A. Naylor, and W.Â Kellermann, â€œThe LOCATA challenge data corpus for acoustic source localization and tracking,â€ in <em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">Proc. IEEE 10th Sensor Array and Multichannel Signal Processing Workshop (SAM)</em>.Â Â Â IEEE, 2018, pp. 410â€“414.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
A.Â Brutti, L.Â Cristoforetti, W.Â Kellermann, L.Â Marquardt, and M.Â Omologo, â€œWOZ acoustic data collection for interactive TV,â€ <em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">Language Resources and Evaluation</em>, vol.Â 44, pp. 205â€“219, 2010.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2409.05033" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2409.05034" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2409.05034">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2409.05034" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2409.05035" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sun Oct  6 00:55:42 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
