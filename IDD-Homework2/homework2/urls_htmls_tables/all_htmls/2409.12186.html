<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Qwen2.5-Coder Technical Report</title>
<!--Generated on Wed Sep 18 17:57:22 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2409.12186v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S1" title="In Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S2" title="In Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Model Architecture</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S2.SS0.SSS0.Px1" title="In 2 Model Architecture ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title">Architecture</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S2.SS0.SSS0.Px2" title="In 2 Model Architecture ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title">Tokenization</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S3" title="In Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Pre-training</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S3.SS1" title="In 3 Pre-training ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Pretraining Data</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S3.SS1.SSS1" title="In 3.1 Pretraining Data ‣ 3 Pre-training ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.1 </span>Data Composition</span></a>
<ol class="ltx_toclist ltx_toclist_subsubsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S3.SS1.SSS1.Px1" title="In 3.1.1 Data Composition ‣ 3.1 Pretraining Data ‣ 3 Pre-training ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title">Source Code</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S3.SS1.SSS1.Px2" title="In 3.1.1 Data Composition ‣ 3.1 Pretraining Data ‣ 3 Pre-training ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title">Text-Code Grounding Data</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S3.SS1.SSS1.Px3" title="In 3.1.1 Data Composition ‣ 3.1 Pretraining Data ‣ 3 Pre-training ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title">Synthetic Data</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S3.SS1.SSS1.Px4" title="In 3.1.1 Data Composition ‣ 3.1 Pretraining Data ‣ 3 Pre-training ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title">Math Data</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S3.SS1.SSS1.Px5" title="In 3.1.1 Data Composition ‣ 3.1 Pretraining Data ‣ 3 Pre-training ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title">Text Data</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S3.SS1.SSS2" title="In 3.1 Pretraining Data ‣ 3 Pre-training ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.2 </span>Data Mixture</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S3.SS2" title="In 3 Pre-training ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Training Policy</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S3.SS2.SSS1" title="In 3.2 Training Policy ‣ 3 Pre-training ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.1 </span>File-Level Pretraining</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S3.SS2.SSS2" title="In 3.2 Training Policy ‣ 3 Pre-training ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.2 </span>Repo-Level Pretraining</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S4" title="In Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Post-training</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S4.SS1" title="In 4 Post-training ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>A Recipe for Instruction Data</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S4.SS1.SSS0.Px1" title="In 4.1 A Recipe for Instruction Data ‣ 4 Post-training ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title">Multilingual Programming Code Identification</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S4.SS1.SSS0.Px2" title="In 4.1 A Recipe for Instruction Data ‣ 4 Post-training ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title">Instruction Synthesis from GitHub</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S4.SS1.SSS0.Px3" title="In 4.1 A Recipe for Instruction Data ‣ 4 Post-training ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title">Multilingual Code Instruction Data</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S4.SS1.SSS0.Px4" title="In 4.1 A Recipe for Instruction Data ‣ 4 Post-training ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title">Checklist-based Scoring for Instruction Data</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S4.SS1.SSS0.Px5" title="In 4.1 A Recipe for Instruction Data ‣ 4 Post-training ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title">A multilingual sandbox for code verification</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S4.SS2" title="In 4 Post-training ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Training Policy</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S4.SS2.SSS0.Px1" title="In 4.2 Training Policy ‣ 4 Post-training ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title">Coarse-to-fine Fine-tuning</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S4.SS2.SSS0.Px2" title="In 4.2 Training Policy ‣ 4 Post-training ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title">Mixed Tuning</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S5" title="In Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Decontamination</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S6" title="In Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Evaluation on Base Models</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S6.SS1" title="In 6 Evaluation on Base Models ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.1 </span>Code Generation</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S6.SS1.SSS0.Px1" title="In 6.1 Code Generation ‣ 6 Evaluation on Base Models ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title">HumanEval and MBPP</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S6.SS1.SSS0.Px2" title="In 6.1 Code Generation ‣ 6 Evaluation on Base Models ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title">BigCodeBench-Complete</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S6.SS1.SSS0.Px3" title="In 6.1 Code Generation ‣ 6 Evaluation on Base Models ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title">Multi-Programming Language</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S6.SS2" title="In 6 Evaluation on Base Models ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.2 </span>Code Completion</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S6.SS2.SSS0.Px1" title="In 6.2 Code Completion ‣ 6 Evaluation on Base Models ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title">HumanEval Infilling</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S6.SS3" title="In 6 Evaluation on Base Models ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.3 </span>Code Reasoning</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S6.SS4" title="In 6 Evaluation on Base Models ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.4 </span>Math Reasoning</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S6.SS5" title="In 6 Evaluation on Base Models ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.5 </span>General Natural Language</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S6.SS6" title="In 6 Evaluation on Base Models ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.6 </span>Long-Context Evaluation</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S6.SS6.SSS0.Px1" title="In 6.6 Long-Context Evaluation ‣ 6 Evaluation on Base Models ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title">Needle in the Code</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S7" title="In Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Evaluation on Instruct Models</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S7.SS1" title="In 7 Evaluation on Instruct Models ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.1 </span>Code Generation</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S7.SS1.SSS0.Px1" title="In 7.1 Code Generation ‣ 7 Evaluation on Instruct Models ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title">HumanEval and MBPP</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S7.SS1.SSS0.Px2" title="In 7.1 Code Generation ‣ 7 Evaluation on Instruct Models ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title">BigCodeBench-Instruct</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S7.SS1.SSS0.Px3" title="In 7.1 Code Generation ‣ 7 Evaluation on Instruct Models ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title">LiveCodeBench</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S7.SS1.SSS0.Px4" title="In 7.1 Code Generation ‣ 7 Evaluation on Instruct Models ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title">Multi-Programming Language</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S7.SS1.SSS0.Px5" title="In 7.1 Code Generation ‣ 7 Evaluation on Instruct Models ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title">MultiPL-E</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S7.SS1.SSS0.Px6" title="In 7.1 Code Generation ‣ 7 Evaluation on Instruct Models ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title">McEval</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S7.SS2" title="In 7 Evaluation on Instruct Models ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.2 </span>Code Reasoning</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S7.SS3" title="In 7 Evaluation on Instruct Models ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.3 </span>Code Editing</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S7.SS4" title="In 7 Evaluation on Instruct Models ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.4 </span>Text-to-SQL</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S7.SS5" title="In 7 Evaluation on Instruct Models ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.5 </span>Math Reasoning and General Natural Language</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S8" title="In Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8 </span>Conclusion</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div class="ltx_para" id="p1">
<span class="ltx_ERROR undefined" id="p1.1">\pdfcolInitStack</span>
<p class="ltx_p" id="p1.2">tcb@breakable










































































</p>
</div>
<h1 class="ltx_title ltx_title_document">Qwen2.5-Coder Technical Report</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">

Binyuan Hui*   
Jian Yang*   
Zeyu Cui*   
Jiaxi Yang*   

<br class="ltx_break"/>
Dayiheng Liu   
Lei Zhang   
Tianyu Liu   
Jiajun Zhang   
Bowen Yu   
Kai Dang   
An Yang   

<br class="ltx_break"/>
Rui Men   
Fei Huang   
Xingzhang Ren   
Xuancheng Ren   
Jingren Zhou   
Junyang Lin<sup class="ltx_sup" id="5.2.1"><span class="ltx_text ltx_font_italic" id="5.2.1.1">†</span></sup>
<br class="ltx_break"/>
<span class="ltx_text ltx_font_bold" id="6.3.2">Qwen Team   Alibaba Group</span>
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<span class="ltx_note ltx_role_footnotetext" id="footnotex1"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">footnotetext: </span><sup class="ltx_sup" id="footnotex1.1">∗</sup>Equal core contribution, <sup class="ltx_sup" id="footnotex1.2"><span class="ltx_text ltx_font_italic" id="footnotex1.2.1">†</span></sup>Corresponding author</span></span></span>
<p class="ltx_p" id="7.1">In this report, we introduce the Qwen2.5-Coder series, a significant upgrade from its predecessor, CodeQwen1.5. This series includes two models: Qwen2.5-Coder-1.5B and Qwen2.5-Coder-7B. As a code-specific model, Qwen2.5-Coder is built upon the Qwen2.5 architecture and continues pretrained on a vast corpus of over 5.5 trillion tokens. Through meticulous data cleaning, scalable synthetic data generation, and balanced data mixing, Qwen2.5-Coder demonstrates impressive code generation capabilities while retaining general versatility.
The model has been evaluated on a wide range of code-related tasks, achieving state-of-the-art (SOTA) performance across more than 10 benchmarks, including code generation, completion, reasoning, and repair, consistently outperforming larger models of the same model size.
We believe that the release of the Qwen2.5-Coder series will not only push the boundaries of research in code intelligence but also, through its permissive licensing, encourage broader adoption by developers in real-world applications.</p>
</div>
<div class="ltx_para" id="id3">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="id3.2">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="id2.1.1">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="id2.1.1.1"><span class="ltx_text" id="id2.1.1.1.1" style="position:relative; bottom:-1.5pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="20" id="id2.1.1.1.1.g1" src="x1.png" width="22"/></span></th>
<td class="ltx_td ltx_align_left" id="id2.1.1.2"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://hf.co/Qwen/Qwen2.5-Coder-7B-Instruct" title="">https://hf.co/Qwen/Qwen2.5-Coder-7B-Instruct</a></td>
</tr>
<tr class="ltx_tr" id="id3.2.2">
<th class="ltx_td ltx_align_right ltx_th ltx_th_row" id="id3.2.2.1"><span class="ltx_text" id="id3.2.2.1.1" style="position:relative; bottom:-1.5pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="20" id="id3.2.2.1.1.g1" src="x2.png" width="20"/></span></th>
<td class="ltx_td ltx_align_left" id="id3.2.2.2"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/QwenLM/Qwen2.5-Coder" title="">https://github.com/QwenLM/Qwen2.5-Coder</a></td>
</tr>
</tbody>
</table>
</div>
<figure class="ltx_figure" id="id4"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="600" id="id4.g1" src="x3.png" width="623"/>
</figure>
<nav class="ltx_TOC ltx_list_toc ltx_toc_toc"><h6 class="ltx_title ltx_title_contents">Contents</h6>
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S1" title="In Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S2" title="In Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Model Architecture</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S3" title="In Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Pre-training</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S3.SS1" title="In 3 Pre-training ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Pretraining Data</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S3.SS1.SSS1" title="In 3.1 Pretraining Data ‣ 3 Pre-training ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.1 </span>Data Composition</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S3.SS1.SSS2" title="In 3.1 Pretraining Data ‣ 3 Pre-training ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.2 </span>Data Mixture</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S3.SS2" title="In 3 Pre-training ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Training Policy</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S3.SS2.SSS1" title="In 3.2 Training Policy ‣ 3 Pre-training ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.1 </span>File-Level Pretraining</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S3.SS2.SSS2" title="In 3.2 Training Policy ‣ 3 Pre-training ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.2 </span>Repo-Level Pretraining</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S4" title="In Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Post-training</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S4.SS1" title="In 4 Post-training ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>A Recipe for Instruction Data</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S4.SS2" title="In 4 Post-training ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Training Policy</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S5" title="In Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Decontamination</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S6" title="In Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Evaluation on Base Models</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S6.SS1" title="In 6 Evaluation on Base Models ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.1 </span>Code Generation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S6.SS2" title="In 6 Evaluation on Base Models ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.2 </span>Code Completion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S6.SS3" title="In 6 Evaluation on Base Models ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.3 </span>Code Reasoning</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S6.SS4" title="In 6 Evaluation on Base Models ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.4 </span>Math Reasoning</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S6.SS5" title="In 6 Evaluation on Base Models ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.5 </span>General Natural Language</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S6.SS6" title="In 6 Evaluation on Base Models ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.6 </span>Long-Context Evaluation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S7" title="In Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Evaluation on Instruct Models</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S7.SS1" title="In 7 Evaluation on Instruct Models ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.1 </span>Code Generation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S7.SS2" title="In 7 Evaluation on Instruct Models ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.2 </span>Code Reasoning</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S7.SS3" title="In 7 Evaluation on Instruct Models ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.3 </span>Code Editing</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S7.SS4" title="In 7 Evaluation on Instruct Models ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.4 </span>Text-to-SQL</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S7.SS5" title="In 7 Evaluation on Instruct Models ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.5 </span>Math Reasoning and General Natural Language</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S8" title="In Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8 </span>Conclusion</span></a></li>
</ol></nav>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para ltx_noindent" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">With the rapid development of large language models (LLMs) <cite class="ltx_cite ltx_citemacro_citep">(Brown, <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#bib.bib8" title="">2020</a>; Achiam et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#bib.bib1" title="">2023</a>; Touvron et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#bib.bib35" title="">2023</a>; Dubey et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#bib.bib16" title="">2024</a>; Jiang et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#bib.bib23" title="">2023</a>; Bai et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#bib.bib6" title="">2023b</a>; Yang et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#bib.bib36" title="">2024</a>; Anthropic, <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#bib.bib3" title="">2024</a>; OpenAI, <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#bib.bib29" title="">2024</a>)</cite>, code-specific language models have garnered significant attention in the community. Built upon pretrained LLMs, code LLMs such as the StarCoder series <cite class="ltx_cite ltx_citemacro_citep">(Li et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#bib.bib25" title="">2023</a>; Lozhkov et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#bib.bib28" title="">2024</a>)</cite>, CodeLlama series <cite class="ltx_cite ltx_citemacro_citep">(Roziere et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#bib.bib31" title="">2023</a>)</cite>, DeepSeek-Coder series <cite class="ltx_cite ltx_citemacro_citep">(Guo et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#bib.bib19" title="">2024</a>)</cite>, CodeQwen1.5 <cite class="ltx_cite ltx_citemacro_citep">(Bai et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#bib.bib5" title="">2023a</a>)</cite>, and CodeStral <cite class="ltx_cite ltx_citemacro_citep">(team, <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#bib.bib34" title="">2024</a>)</cite>, have demonstrated superior performance in coding evaluations <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#bib.bib12" title="">2021</a>; Austin et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#bib.bib4" title="">2021</a>; Cassano et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#bib.bib9" title="">2022</a>; Jain et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#bib.bib22" title="">2024</a>)</cite>.
However, in comparison with the recently state-of-the-art proprietary LLMs, Claude-3.5-Sonnet <cite class="ltx_cite ltx_citemacro_citep">(Anthropic, <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#bib.bib3" title="">2024</a>)</cite> and GPT-4o <cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#bib.bib29" title="">2024</a>)</cite>, the code LLMs are still falling behind, either open-source or proprietary models.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Building upon our previous work, CodeQwen1.5, we are excited to introduce <span class="ltx_text ltx_font_bold" id="S1.p2.1.1">Qwen2.5-Coder</span>, a new series of language models designed to achieve top-tier performance in coding tasks at various model sizes.
Qwen2.5-Coder models are derived from the Qwen2.5 LLMs, inheriting their advanced architecture and tokenizer. These models are pretrained on extensive datasets and further fine-tuned on carefully curated instruction datasets specifically designed for coding tasks. The series includes models with 1.5B and 7B parameters, along with their instruction-tuned variants.
We are committed to fostering research and innovation in the field of code LLMs, coding agents, and coding assistant applications. Therefore, we are open-sourcing the Qwen2.5-Coder models to the community to support and accelerate advancements in these areas.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Significant efforts have been dedicated to constructing a large-scale, coding-specific pretraining dataset comprising over 5.5 trillion tokens. This dataset is sourced from a broad range of public code repositories, such as those on GitHub, as well as large-scale web-crawled data containing code-related texts. We have implemented sophisticated procedures to recall and clean potential code data and filter out low-quality content using weak model based classifiers and scorers. Our approach encompasses both file-level and repository-level pretraining to ensure comprehensive coverage.
To optimize performance and balance coding expertise with general language understanding, we have carefully curated a data mixture that includes code, mathematics, and general texts.
To transform models into coding assistants for downstream applications, we have developed a well-designed instruction-tuning dataset. This dataset includes a wide range of coding-related problems and solutions, sourced from real-world applications and synthetic data generated by code-focused LLMs, covering a broad spectrum of coding tasks.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">This report introduces the Qwen2.5-Coder series, an upgraded version of CodeQwen1.5, featuring two models: Qwen2.5-Coder-1.5B and Qwen2.5-Coder-7B. Built on the Qwen2.5 architecture and pretrained on over 5.5 trillion tokens, these code-specific models demonstrate exceptional code generation capabilities while maintaining general versatility. Through rigorous data processing and training techniques, Qwen2.5-Coder achieves state-of-the-art performance across more than 10 code-related benchmarks, outperforming larger models in various tasks. The release of these models aims to advance code intelligence research and promote widespread adoption in real-world applications, facilitated by permissive licensing.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Model Architecture</h2>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Architecture</h5>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px1.p1.1">The architecture of Qwen2.5-Coder is the same as Qwen2.5. Table <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S2.T1" title="Table 1 ‣ Tokenization ‣ 2 Model Architecture ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_tag">1</span></a> shows the architecture of Qwen2.5-Coder for two different model sizes: 1.5B and 7B parameters. Both sizes share the same architecture in terms of layers, having 28 layers and a head size of 128. However, they differ in several key aspects. The 1.5B model has a hidden size of 1,536, while the 7B model has a much larger hidden size of 3,584. The 1.5B model uses 12 query heads and 2 key-value heads, whereas the 7B model uses 28 query heads and 4 key-value heads, reflecting its larger capacity. The intermediate size also scales with model size, being 8,960 for the 1.5B model and 18,944 for the 7B model. Additionally, the 1.5B model employs embedding tying, while the 7B model does not. Both models share the same vocabulary size of 151,646 tokens and have been trained on 5.5 trillion tokens.</p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">Tokenization</h5>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px2.p1.1">Qwen2.5-Coder inherits the vocabulary from Qwen2.5 but introduces several special tokens to help the model better understand code.
Table <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S2.T2" title="Table 2 ‣ Tokenization ‣ 2 Model Architecture ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_tag">2</span></a> presents an overview of the special tokens added during training to better capture different forms of code data. These tokens serve specific purposes in the code-processing pipeline. For instance, <code class="ltx_verbatim ltx_font_typewriter" id="S2.SS0.SSS0.Px2.p1.1.1">&lt;|endoftext|&gt;</code> marks the end of a text or sequence, while the <code class="ltx_verbatim ltx_font_typewriter" id="S2.SS0.SSS0.Px2.p1.1.2">&lt;|fim_prefix|&gt;</code>, <code class="ltx_verbatim ltx_font_typewriter" id="S2.SS0.SSS0.Px2.p1.1.3">&lt;|fim_middle|&gt;</code>, and <code class="ltx_verbatim ltx_font_typewriter" id="S2.SS0.SSS0.Px2.p1.1.4">&lt;|fim_suffix|&gt;</code> tokens are used to implement the Fill-in-the-Middle (FIM) <cite class="ltx_cite ltx_citemacro_citep">(Bavarian et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#bib.bib7" title="">2022</a>)</cite> technique, where a model predicts the missing parts of a code block. Additionally, <code class="ltx_verbatim ltx_font_typewriter" id="S2.SS0.SSS0.Px2.p1.1.5">&lt;|fim_pad|&gt;</code> is used for padding during FIM operations. Other tokens include <code class="ltx_verbatim ltx_font_typewriter" id="S2.SS0.SSS0.Px2.p1.1.6">&lt;|repo_name|&gt;</code>, which identifies repository names, and <code class="ltx_verbatim ltx_font_typewriter" id="S2.SS0.SSS0.Px2.p1.1.7">&lt;|file_sep|&gt;</code>, used as a file separator to better manage repository-level information. These tokens are essential in helping the model learn from diverse code structures and enable it to handle longer and more complex contexts during both file-level and repo-level pretraining.</p>
</div>
<figure class="ltx_table" id="S2.T1">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S2.T1.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S2.T1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="S2.T1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S2.T1.1.1.1.1.1">Configuration</span></th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S2.T1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S2.T1.1.1.1.2.1">Qwen2.5-Coder 1.5B</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S2.T1.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S2.T1.1.1.1.3.1">Qwen2.5-Coder 7B</span></td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S2.T1.1.2.2.1">Hidden Size</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.1.2.2.2">1,536</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.1.2.2.3">3,584</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S2.T1.1.3.3.1"># Layers</th>
<td class="ltx_td ltx_align_center" id="S2.T1.1.3.3.2">28</td>
<td class="ltx_td ltx_align_center" id="S2.T1.1.3.3.3">28</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S2.T1.1.4.4.1"># Query Heads</th>
<td class="ltx_td ltx_align_center" id="S2.T1.1.4.4.2">12</td>
<td class="ltx_td ltx_align_center" id="S2.T1.1.4.4.3">28</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S2.T1.1.5.5.1"># KV Heads</th>
<td class="ltx_td ltx_align_center" id="S2.T1.1.5.5.2">2</td>
<td class="ltx_td ltx_align_center" id="S2.T1.1.5.5.3">4</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S2.T1.1.6.6.1">Head Size</th>
<td class="ltx_td ltx_align_center" id="S2.T1.1.6.6.2">128</td>
<td class="ltx_td ltx_align_center" id="S2.T1.1.6.6.3">128</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S2.T1.1.7.7.1">Intermediate Size</th>
<td class="ltx_td ltx_align_center" id="S2.T1.1.7.7.2">8,960</td>
<td class="ltx_td ltx_align_center" id="S2.T1.1.7.7.3">18,944</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S2.T1.1.8.8.1">Embedding Tying</th>
<td class="ltx_td ltx_align_center" id="S2.T1.1.8.8.2">True</td>
<td class="ltx_td ltx_align_center" id="S2.T1.1.8.8.3">False</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.9.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S2.T1.1.9.9.1">Vocabulary Size</th>
<td class="ltx_td ltx_align_center" id="S2.T1.1.9.9.2">151,646</td>
<td class="ltx_td ltx_align_center" id="S2.T1.1.9.9.3">151,646</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.10.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S2.T1.1.10.10.1"># Trained Tokens</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S2.T1.1.10.10.2">5.5T</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S2.T1.1.10.10.3">5.5T</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Architecture of Qwen2.5-Coder.</figcaption>
</figure>
<figure class="ltx_table" id="S2.T2">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S2.T2.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S2.T2.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S2.T2.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S2.T2.1.1.1.1.1">Token</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S2.T2.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S2.T2.1.1.1.2.1">Token ID</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S2.T2.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S2.T2.1.1.1.3.1">Description</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S2.T2.1.2.1">
<td class="ltx_td ltx_align_left ltx_border_t" id="S2.T2.1.2.1.1"><code class="ltx_verbatim ltx_font_typewriter" id="S2.T2.1.2.1.1.1">&lt;|endoftext|&gt;</code></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S2.T2.1.2.1.2">151643</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S2.T2.1.2.1.3">end of text/sequence</td>
</tr>
<tr class="ltx_tr" id="S2.T2.1.3.2">
<td class="ltx_td ltx_align_left" id="S2.T2.1.3.2.1"><code class="ltx_verbatim ltx_font_typewriter" id="S2.T2.1.3.2.1.1">&lt;|fim_prefix|&gt;</code></td>
<td class="ltx_td ltx_align_left" id="S2.T2.1.3.2.2">151659</td>
<td class="ltx_td ltx_align_left" id="S2.T2.1.3.2.3">FIM prefix</td>
</tr>
<tr class="ltx_tr" id="S2.T2.1.4.3">
<td class="ltx_td ltx_align_left" id="S2.T2.1.4.3.1"><code class="ltx_verbatim ltx_font_typewriter" id="S2.T2.1.4.3.1.1">&lt;|fim_middle|&gt;</code></td>
<td class="ltx_td ltx_align_left" id="S2.T2.1.4.3.2">151660</td>
<td class="ltx_td ltx_align_left" id="S2.T2.1.4.3.3">FIM middle</td>
</tr>
<tr class="ltx_tr" id="S2.T2.1.5.4">
<td class="ltx_td ltx_align_left" id="S2.T2.1.5.4.1"><code class="ltx_verbatim ltx_font_typewriter" id="S2.T2.1.5.4.1.1">&lt;|fim_suffix|&gt;</code></td>
<td class="ltx_td ltx_align_left" id="S2.T2.1.5.4.2">151661</td>
<td class="ltx_td ltx_align_left" id="S2.T2.1.5.4.3">FIM suffix</td>
</tr>
<tr class="ltx_tr" id="S2.T2.1.6.5">
<td class="ltx_td ltx_align_left" id="S2.T2.1.6.5.1"><code class="ltx_verbatim ltx_font_typewriter" id="S2.T2.1.6.5.1.1">&lt;|fim_pad|&gt;</code></td>
<td class="ltx_td ltx_align_left" id="S2.T2.1.6.5.2">151662</td>
<td class="ltx_td ltx_align_left" id="S2.T2.1.6.5.3">FIM pad</td>
</tr>
<tr class="ltx_tr" id="S2.T2.1.7.6">
<td class="ltx_td ltx_align_left" id="S2.T2.1.7.6.1"><code class="ltx_verbatim ltx_font_typewriter" id="S2.T2.1.7.6.1.1">&lt;|repo_name|&gt;</code></td>
<td class="ltx_td ltx_align_left" id="S2.T2.1.7.6.2">151663</td>
<td class="ltx_td ltx_align_left" id="S2.T2.1.7.6.3">repository name</td>
</tr>
<tr class="ltx_tr" id="S2.T2.1.8.7">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S2.T2.1.8.7.1"><code class="ltx_verbatim ltx_font_typewriter" id="S2.T2.1.8.7.1.1">&lt;|file_sep|&gt;</code></td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S2.T2.1.8.7.2">151664</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S2.T2.1.8.7.3">file separator</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Overview of the special tokens.</figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Pre-training</h2>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Pretraining Data</h3>
<div class="ltx_para ltx_noindent" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">Large-scale, high-quality, and diverse data forms the foundation of pre-trained models. To this end, we constructed a dataset named Qwen2.5-Coder-Data. This dataset comprises five key data types: Source Code Data, Text-Code Grounding Data, Synthetic Data, Math Data, and Text Data. In this section, we provide a brief overview of the sources and cleaning methods applied to these datasets.</p>
</div>
<section class="ltx_subsubsection" id="S3.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.1 </span>Data Composition</h4>
<section class="ltx_paragraph" id="S3.SS1.SSS1.Px1">
<h5 class="ltx_title ltx_title_paragraph">Source Code</h5>
<div class="ltx_para ltx_noindent" id="S3.SS1.SSS1.Px1.p1">
<p class="ltx_p" id="S3.SS1.SSS1.Px1.p1.1">We collected public repositories from GitHub created before February 2024, spanning 92 programming languages. Similar to StarCoder2 <cite class="ltx_cite ltx_citemacro_citep">(Lozhkov et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#bib.bib28" title="">2024</a>)</cite> and DS-Coder <cite class="ltx_cite ltx_citemacro_citep">(Guo et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#bib.bib19" title="">2024</a>)</cite>, we applied a series of rule-based filtering methods. In addition to raw code, we also collected data from Pull Requests, Commits, Jupyter Notebooks, and Kaggle datasets, all of which were subjected to similar rule-based cleaning techniques.</p>
</div>
<figure class="ltx_figure" id="S3.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="360" id="S3.F1.g1" src="x4.png" width="415"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Number of data tokens across different cc-stages, and the validation effectiveness of training Qwen2.5-Coder using corresponding data.</figcaption>
</figure>
</section>
<section class="ltx_paragraph" id="S3.SS1.SSS1.Px2">
<h5 class="ltx_title ltx_title_paragraph">Text-Code Grounding Data</h5>
<div class="ltx_para ltx_noindent" id="S3.SS1.SSS1.Px2.p1">
<p class="ltx_p" id="S3.SS1.SSS1.Px2.p1.1">We curated a large-scale and high-quality text-code mixed dataset from Common Crawl, which includes code-related documentation, tutorials, blogs, and more. Instead of the conventional URL-based multi-stage recall method, we developed a coarse-to-fine hierarchical filtering approach for raw data. This method offers two key advantages:</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.SSS1.Px2.p2">
<ol class="ltx_enumerate" id="S3.I1">
<li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S3.I1.i1.p1">
<p class="ltx_p" id="S3.I1.i1.p1.1">It enables precise control over each filter’s responsibility, ensuring comprehensive handling of each dimension.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para ltx_noindent" id="S3.I1.i2.p1">
<p class="ltx_p" id="S3.I1.i2.p1.1">It naturally assigns quality scores to the dataset, with data retained in the final stage being of higher quality, providing valuable insights for quality-driven data mixing.</p>
</div>
</li>
</ol>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.SSS1.Px2.p3">
<p class="ltx_p" id="S3.SS1.SSS1.Px2.p3.1">We designed a cleaning pipeline for the Text-Code Grounding Data, where each filter level is built using smaller models, such as fastText. Although we experimented with larger models, they did not yield significant benefits. A likely explanation is that smaller models focus more on surface-level features, avoiding unnecessary semantic complexity.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.SSS1.Px2.p4">
<p class="ltx_p" id="S3.SS1.SSS1.Px2.p4.1">In Qwen2.5-Coder, we applied this process iteratively. As shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S3.F1" title="Figure 1 ‣ Source Code ‣ 3.1.1 Data Composition ‣ 3.1 Pretraining Data ‣ 3 Pre-training ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_tag">1</span></a>, each iteration resulted in improvement. Through 4-stage filtering, the average scores on HumanEval and MBPP increased from 41.6% to 46.8% compared to the baseline, demonstrating the value of high-quality Text-Code Grounding Data for code generation.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS1.SSS1.Px3">
<h5 class="ltx_title ltx_title_paragraph">Synthetic Data</h5>
<div class="ltx_para ltx_noindent" id="S3.SS1.SSS1.Px3.p1">
<p class="ltx_p" id="S3.SS1.SSS1.Px3.p1.1">Synthetic data offers a promising way to address the anticipated scarcity of training data. We used CodeQwen1.5, the predecessor of Qwen2.5-Coder, to generate large-scale synthetic datasets. To mitigate the risk of hallucinations during this process, we introduced an executor for validation, ensuring that only executable code was retained.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS1.SSS1.Px4">
<h5 class="ltx_title ltx_title_paragraph">Math Data</h5>
<div class="ltx_para ltx_noindent" id="S3.SS1.SSS1.Px4.p1">
<p class="ltx_p" id="S3.SS1.SSS1.Px4.p1.1">To enhance the mathematical capabilities of Qwen2.5-Coder, we integrated the pre-training corpus from Qwen2.5-Math into the Qwen2.5-Coder dataset. Importantly, the inclusion of mathematical data did not negatively impact the model’s performance on code tasks. For further details on the collection and cleaning process, please refer to the Qwen2.5-Math technical report.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS1.SSS1.Px5">
<h5 class="ltx_title ltx_title_paragraph">Text Data</h5>
<div class="ltx_para ltx_noindent" id="S3.SS1.SSS1.Px5.p1">
<p class="ltx_p" id="S3.SS1.SSS1.Px5.p1.1">Similar to the Math Data, we included high-quality general natural language data from the pre-training corpus of the Qwen2.5 model to preserve Qwen2.5-Coder’s general capabilities. This data had already passed stringent quality checks during the cleaning phase of Qwen2.5’s dataset, so no further processing was applied. However, all code segments were removed from the general Text data to avoid overlap with our code data, ensuring the independence of different data sources.</p>
</div>
</section>
</section>
<section class="ltx_subsubsection" id="S3.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.2 </span>Data Mixture</h4>
<div class="ltx_para ltx_noindent" id="S3.SS1.SSS2.p1">
<p class="ltx_p" id="S3.SS1.SSS2.p1.1">Balancing Code, Math, and Text data is crucial for building a robust foundational model. Although the research community has explored this balance before, there is limited evidence regarding its scalability to large datasets. To address this, we conducted empirical experiments with different ratios of Code, Math, and Text data, designing multiple experiments to identify an optimal combination rapidly. Specifically, as shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S3.T3" title="Table 3 ‣ 3.1.2 Data Mixture ‣ 3.1 Pretraining Data ‣ 3 Pre-training ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_tag">3</span></a>, we compared three different Code: Text ratios — 100:0:0, 85:10:5, and 70:20:10.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.SSS2.p2">
<p class="ltx_p" id="S3.SS1.SSS2.p2.1">Interestingly, we found that the 7:2:1 ratio outperformed the others, even surpassing the performance of groups with a higher proportion of code. A possible explanation is that Math and Text data may positively contribute to code performance, but only when their concentration reaches a specific threshold. In future work, we plan to explore more efficient ratio mechanisms and investigate the underlying causes of this phenomenon. Ultimately, we selected a final mixture of 70% Code, 20% Text, and 10% Math. The final training dataset comprises 5.2 trillion tokens.</p>
</div>
<figure class="ltx_table" id="S3.T3">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S3.T3.1" style="width:397.5pt;height:77.5pt;vertical-align:-0.9pt;"><span class="ltx_transformed_inner" style="transform:translate(-34.8pt,6.7pt) scale(0.850967101468388,0.850967101468388) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S3.T3.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T3.1.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" colspan="3" id="S3.T3.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S3.T3.1.1.1.1.1.1">Token Ratio</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" colspan="2" id="S3.T3.1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S3.T3.1.1.1.1.2.1">Coding</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" colspan="2" id="S3.T3.1.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S3.T3.1.1.1.1.3.1">Math</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" colspan="3" id="S3.T3.1.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S3.T3.1.1.1.1.4.1">General</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T3.1.1.1.1.5" rowspan="2"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S3.T3.1.1.1.1.5.1">Average</span></th>
</tr>
<tr class="ltx_tr" id="S3.T3.1.1.2.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S3.T3.1.1.2.2.1">Code</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S3.T3.1.1.2.2.2">Text</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r" id="S3.T3.1.1.2.2.3">Math</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S3.T3.1.1.2.2.4">Common</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r" id="S3.T3.1.1.2.2.5">BCB</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S3.T3.1.1.2.2.6">MATH</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r" id="S3.T3.1.1.2.2.7">GSM8K</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S3.T3.1.1.2.2.8">MMLU</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S3.T3.1.1.2.2.9">CEval</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r" id="S3.T3.1.1.2.2.10">HellaSwag</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T3.1.1.3.1">
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.1.3.1.1">100</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.1.3.1.2">0</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.1.3.1.3">0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.1.3.1.4"><span class="ltx_text ltx_font_bold" id="S3.T3.1.1.3.1.4.1">49.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.1.3.1.5"><span class="ltx_text ltx_font_bold" id="S3.T3.1.1.3.1.5.1">40.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.1.3.1.6">10.3</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.1.3.1.7">23.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.1.3.1.8">42.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.1.3.1.9">35.9</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.1.1.3.1.10">58.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.1.3.1.11">31.3</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.1.4.2">
<td class="ltx_td ltx_align_center" id="S3.T3.1.1.4.2.1">85</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.1.4.2.2">15</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.1.4.2.3">5</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.1.4.2.4">43.3</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.1.4.2.5">36.2</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.1.4.2.6">26.1</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.1.4.2.7">52.5</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.1.4.2.8">56.8</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.1.4.2.9">57.1</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S3.T3.1.1.4.2.10">70.0</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.1.4.2.11">48.9</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.1.5.3">
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T3.1.1.5.3.1">70</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T3.1.1.5.3.2">20</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S3.T3.1.1.5.3.3">10</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T3.1.1.5.3.4">48.3</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S3.T3.1.1.5.3.5">38.3</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T3.1.1.5.3.6"><span class="ltx_text ltx_font_bold" id="S3.T3.1.1.5.3.6.1">33.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S3.T3.1.1.5.3.7"><span class="ltx_text ltx_font_bold" id="S3.T3.1.1.5.3.7.1">64.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T3.1.1.5.3.8"><span class="ltx_text ltx_font_bold" id="S3.T3.1.1.5.3.8.1">62.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T3.1.1.5.3.9"><span class="ltx_text ltx_font_bold" id="S3.T3.1.1.5.3.9.1">64.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S3.T3.1.1.5.3.10"><span class="ltx_text ltx_font_bold" id="S3.T3.1.1.5.3.10.1">73.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T3.1.1.5.3.11"><span class="ltx_text ltx_font_bold" id="S3.T3.1.1.5.3.11.1">55.0</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>The performance of Qwen2.5-Coder training on different data mixture policy. </figcaption>
</figure>
</section>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Training Policy</h3>
<figure class="ltx_figure" id="S3.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="99" id="S3.F2.g1" src="x5.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>The three-stage training pipeline for Qwen2.5-Coder.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">As shown in <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S3.F2" title="Figure 2 ‣ 3.2 Training Policy ‣ 3 Pre-training ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_tag">2</span></a>, we employed a three-stage training approach to train Qwen2.5-Coder, including file-level pretraining, repo-level pretraining, and instruction tuning.</p>
</div>
<section class="ltx_subsubsection" id="S3.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.1 </span>File-Level Pretraining</h4>
<div class="ltx_para ltx_noindent" id="S3.SS2.SSS1.p1">
<p class="ltx_p" id="S3.SS2.SSS1.p1.1">File-level pretraining focuses on learning from individual code files. In this stage, the maximum training sequence length is set to 8,192 tokens, covering 5.2T of high-quality data. The training objectives include next token prediction and fill-in-the-middle (FIM) <cite class="ltx_cite ltx_citemacro_citep">(Bavarian et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#bib.bib7" title="">2022</a>)</cite>. The specific FIM format is shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S3.F3" title="Figure 3 ‣ 3.2.1 File-Level Pretraining ‣ 3.2 Training Policy ‣ 3 Pre-training ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<figure class="ltx_figure" id="S3.F3"><code class="ltx_verbatim" id="S3.F3.1"> <svg class="ltx_picture" height="253.41" id="S3.F3.1.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,253.41) matrix(1 0 0 -1 0 0)"><g fill="#000000" fill-opacity="1.0"><path d="M 0 3.15 L 0 250.26 C 0 252 1.41 253.41 3.15 253.41 L 596.85 253.41 C 598.59 253.41 600 252 600 250.26 L 600 3.15 C 600 1.41 598.59 0 596.85 0 L 3.15 0 C 1.41 0 0 1.41 0 3.15 Z" style="stroke:none"></path></g><g fill="#FFFFFF" fill-opacity="1.0"><path d="M 1.18 3.15 L 1.18 233.56 L 598.82 233.56 L 598.82 3.15 C 598.82 2.06 597.94 1.18 596.85 1.18 L 3.15 1.18 C 2.06 1.18 1.18 2.06 1.18 3.15 Z" style="stroke:none"></path></g><g fill="#000000" fill-opacity="1.0"><path d="M 1.18 234.74 L 1.18 250.26 C 1.18 251.34 2.06 252.22 3.15 252.22 L 596.85 252.22 C 597.94 252.22 598.82 251.34 598.82 250.26 L 598.82 234.74 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 9.06 238.68)"><foreignobject color="#FFFFFF" height="9.61" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="581.89">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="S3.F3.1.pic1.2.2.2.1.1" style="width:420.5pt;">
<span class="ltx_p" id="S3.F3.1.pic1.2.2.2.1.1.1"><span class="ltx_text ltx_font_bold" id="S3.F3.1.pic1.2.2.2.1.1.1.1">File-Level FIM format.</span></span>
</span></foreignobject></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 9.06 5.12)"><foreignobject color="#000000" height="224.51" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="581.89"><span class="ltx_inline-logical-block ltx_minipage ltx_align_bottom" id="S3.F3.1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1" style="width:420.5pt;">
<span class="ltx_float ltx_lstlisting" id="S3.F3.1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.tab1">
<span class="ltx_listing ltx_lstlisting ltx_listing" id="S3.F3.1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.tab1.1">
</span>
</span></span></foreignobject></g></g></svg>
</code>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>File-Level FIM format.</figcaption>
</figure>
</section>
<section class="ltx_subsubsection" id="S3.SS2.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.2 </span>Repo-Level Pretraining</h4>
<div class="ltx_para ltx_noindent" id="S3.SS2.SSS2.p1">
<p class="ltx_p" id="S3.SS2.SSS2.p1.1">After file-level pretraining, we turn to repo-level pretraining, aimed at enhancing the model’s long-context capabilities. In this stage, the context length is extended from 8,192 tokens to 32,768 tokens, and RoPE’s base frequency is adjusted from 10,000 to 1,000,000. To further leverage the model’s extrapolation potential, we applied the YARN mechanism <cite class="ltx_cite ltx_citemacro_citep">(Peng et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#bib.bib30" title="">2023</a>)</cite>, enabling the model to handle sequences up to 131,072 (132K) tokens.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.SSS2.p2">
<p class="ltx_p" id="S3.SS2.SSS2.p2.1">In this stage, we used a large amount of high-quality, long-code data (<math alttext="\approx" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p2.1.m1.1"><semantics id="S3.SS2.SSS2.p2.1.m1.1a"><mo id="S3.SS2.SSS2.p2.1.m1.1.1" xref="S3.SS2.SSS2.p2.1.m1.1.1.cmml">≈</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p2.1.m1.1b"><approx id="S3.SS2.SSS2.p2.1.m1.1.1.cmml" xref="S3.SS2.SSS2.p2.1.m1.1.1"></approx></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p2.1.m1.1c">\approx</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p2.1.m1.1d">≈</annotation></semantics></math> 300B) and extended file-level FIM to the repo-level FIM followed by methods described in <cite class="ltx_cite ltx_citemacro_citet">Lozhkov et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#bib.bib28" title="">2024</a>)</cite>, with the specific format shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S3.F4" title="Figure 4 ‣ 3.2.2 Repo-Level Pretraining ‣ 3.2 Training Policy ‣ 3 Pre-training ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<figure class="ltx_figure" id="S3.F4"><code class="ltx_verbatim" id="S3.F4.1"> <svg class="ltx_picture" height="256.1" id="S3.F4.1.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,256.1) matrix(1 0 0 -1 0 0)"><g fill="#000000" fill-opacity="1.0"><path d="M 0 3.15 L 0 252.95 C 0 254.69 1.41 256.1 3.15 256.1 L 596.85 256.1 C 598.59 256.1 600 254.69 600 252.95 L 600 3.15 C 600 1.41 598.59 0 596.85 0 L 3.15 0 C 1.41 0 0 1.41 0 3.15 Z" style="stroke:none"></path></g><g fill="#FFFFFF" fill-opacity="1.0"><path d="M 1.18 3.15 L 1.18 233.56 L 598.82 233.56 L 598.82 3.15 C 598.82 2.06 597.94 1.18 596.85 1.18 L 3.15 1.18 C 2.06 1.18 1.18 2.06 1.18 3.15 Z" style="stroke:none"></path></g><g fill="#000000" fill-opacity="1.0"><path d="M 1.18 234.74 L 1.18 252.95 C 1.18 254.03 2.06 254.91 3.15 254.91 L 596.85 254.91 C 597.94 254.91 598.82 254.03 598.82 252.95 L 598.82 234.74 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 9.06 238.68)"><foreignobject color="#FFFFFF" height="12.3" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="581.89">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="S3.F4.1.pic1.2.2.2.1.1" style="width:420.5pt;">
<span class="ltx_p" id="S3.F4.1.pic1.2.2.2.1.1.1"><span class="ltx_text ltx_font_bold" id="S3.F4.1.pic1.2.2.2.1.1.1.1">Repo-Level FIM format.</span></span>
</span></foreignobject></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 9.06 5.12)"><foreignobject color="#000000" height="224.51" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="581.89"><span class="ltx_inline-logical-block ltx_minipage ltx_align_bottom" id="S3.F4.1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1" style="width:420.5pt;">
<span class="ltx_float ltx_lstlisting" id="S3.F4.1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.tab1">
<span class="ltx_listing ltx_lstlisting ltx_listing" id="S3.F4.1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.tab1.1">
</span>
</span></span></foreignobject></g></g></svg>
</code>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Repo-Level FIM format.</figcaption>
</figure>
</section>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Post-training</h2>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>A Recipe for Instruction Data</h3>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Multilingual Programming Code Identification</h5>
<div class="ltx_para ltx_noindent" id="S4.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px1.p1.1">We fine-tune a CodeBERT to perform the language identification model to categorize documents into nearly 100 programming languages. We keep the instruction data of the mainstream programming languages and randomly discard a portion of the instruction data of the long-tail languages. If a given sample contains very little code data or even no code snippets, the sample will possibly be classified into “No Programming Language” tag. We remove most of the samples without code snippets to keep the code generation capability of our instruction model.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">Instruction Synthesis from GitHub</h5>
<div class="ltx_para ltx_noindent" id="S4.SS1.SSS0.Px2.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px2.p1.1">For the unsupervised data (code snippets) massively existing in many websites (e.g. GitHub), we try to construct the supervised instruction dataset. Specifically, we use the LLM to generate the instruction from the code snippets within 1024 tokens and then we use the code LLM to generate the response <cite class="ltx_cite ltx_citemacro_cite">Sun et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#bib.bib33" title="">2024</a>)</cite>. Finally, we use the LLM scorer to filter the low-quality ones to obtain the final pair. Given the code snippets of different programming languages, we construct an instruction dataset from the code snippets. To increase the diversity of the instruction dataset. Conversely, we first generate the answers from the code. Then we use the LLM scorer to filter the low-quality to obtain the final triplet. Similarly, given the code snippets of different programming languages, we can construct an instruction dataset with the universal code from the code snippets. To fully unleash the potential of our proposed method, we also include the open-source instruction dataset in the seed instruction dataset. Finally, we combine three parts instruction dataset for supervised fine-tuning.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px3">
<h5 class="ltx_title ltx_title_paragraph">Multilingual Code Instruction Data</h5>
<div class="ltx_para ltx_noindent" id="S4.SS1.SSS0.Px3.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px3.p1.1">To bridge the gap among different programming languages, we propose a multilingual multi-agent collaborative framework to synthesize the multilingual instruction corpora. We introduce language-specific agents, where a set of specialized agents are created and each dedicated to a particular programming language. These agents are initialized with language-specific instruction data derived from the limited existing multilingual instruction corpora. The multilingual data generation process can be split into:
(1) Language-Specific Intelligent Agents: We create a set of specialized agents, each dedicated to a particular programming language. These agents are initialized with language-specific instruction data derived from curated code snippets.
(2) Collaborative Discussion Protocol: Multiple language-specific agents engage in a structured dialogue to formulate new instructions and solutions. This process can result in either enhancing existing language capabilities or generating instructions for a novel programming language.
(3) Adaptive Memory System: Each agent maintains a dynamic memory bank that stores its generation history to avoid generating the similar samples.
(4) Cross-Lingual Discussion: We implement a novel knowledge distillation technique that allows agents to share insights and patterns across language boundaries, fostering a more comprehensive understanding of programming concepts.
(5) Synergy Evaluation Metric: We develop a new metric to quantify the degree of knowledge sharing and synergy between different programming languages within the model.
(6) Adaptive Instruction Generation: The framework includes a mechanism to dynamically generate new instructions based on identified knowledge gaps across languages.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px4">
<h5 class="ltx_title ltx_title_paragraph">Checklist-based Scoring for Instruction Data</h5>
<div class="ltx_para ltx_noindent" id="S4.SS1.SSS0.Px4.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px4.p1.3">To completely evaluate the quality of the created instruction pair, we introduce several scoring points for each sample:
(1) Question&amp;Answer Consistency: Whether Q&amp;A are
consistent and correct for fine-tuning. (2) Question&amp;Answer Relevance: Whether Q&amp;A are related to the computer field. (3) Question&amp;Answer Difficulty: Whether Q&amp;A are sufficiently challenging. (4) Code Exist: Whether the code is provied in question or answer.
(5) Code Correctness: Evaluate whether the provided code is free from syntax errors and logical flaws. (6) Consider factors like proper variable naming, code indentation, and adherence to best practices. (7) Code Clarity: Assess how clear and understandable the code is. Evaluate if it uses meaningful variable names, proper comments, and follows a consistent coding style. (8) Code Comments: Evaluate the presence of
comments and their usefulness in explaining the code’s
functionality. (9) Easy to Learn: determine its educational value for a
student whose goal is to learn basic coding concepts. After gaining all scores <math alttext="(s_{1},\dots,s_{n})" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px4.p1.1.m1.3"><semantics id="S4.SS1.SSS0.Px4.p1.1.m1.3a"><mrow id="S4.SS1.SSS0.Px4.p1.1.m1.3.3.2" xref="S4.SS1.SSS0.Px4.p1.1.m1.3.3.3.cmml"><mo id="S4.SS1.SSS0.Px4.p1.1.m1.3.3.2.3" stretchy="false" xref="S4.SS1.SSS0.Px4.p1.1.m1.3.3.3.cmml">(</mo><msub id="S4.SS1.SSS0.Px4.p1.1.m1.2.2.1.1" xref="S4.SS1.SSS0.Px4.p1.1.m1.2.2.1.1.cmml"><mi id="S4.SS1.SSS0.Px4.p1.1.m1.2.2.1.1.2" xref="S4.SS1.SSS0.Px4.p1.1.m1.2.2.1.1.2.cmml">s</mi><mn id="S4.SS1.SSS0.Px4.p1.1.m1.2.2.1.1.3" xref="S4.SS1.SSS0.Px4.p1.1.m1.2.2.1.1.3.cmml">1</mn></msub><mo id="S4.SS1.SSS0.Px4.p1.1.m1.3.3.2.4" xref="S4.SS1.SSS0.Px4.p1.1.m1.3.3.3.cmml">,</mo><mi id="S4.SS1.SSS0.Px4.p1.1.m1.1.1" mathvariant="normal" xref="S4.SS1.SSS0.Px4.p1.1.m1.1.1.cmml">…</mi><mo id="S4.SS1.SSS0.Px4.p1.1.m1.3.3.2.5" xref="S4.SS1.SSS0.Px4.p1.1.m1.3.3.3.cmml">,</mo><msub id="S4.SS1.SSS0.Px4.p1.1.m1.3.3.2.2" xref="S4.SS1.SSS0.Px4.p1.1.m1.3.3.2.2.cmml"><mi id="S4.SS1.SSS0.Px4.p1.1.m1.3.3.2.2.2" xref="S4.SS1.SSS0.Px4.p1.1.m1.3.3.2.2.2.cmml">s</mi><mi id="S4.SS1.SSS0.Px4.p1.1.m1.3.3.2.2.3" xref="S4.SS1.SSS0.Px4.p1.1.m1.3.3.2.2.3.cmml">n</mi></msub><mo id="S4.SS1.SSS0.Px4.p1.1.m1.3.3.2.6" stretchy="false" xref="S4.SS1.SSS0.Px4.p1.1.m1.3.3.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px4.p1.1.m1.3b"><vector id="S4.SS1.SSS0.Px4.p1.1.m1.3.3.3.cmml" xref="S4.SS1.SSS0.Px4.p1.1.m1.3.3.2"><apply id="S4.SS1.SSS0.Px4.p1.1.m1.2.2.1.1.cmml" xref="S4.SS1.SSS0.Px4.p1.1.m1.2.2.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS0.Px4.p1.1.m1.2.2.1.1.1.cmml" xref="S4.SS1.SSS0.Px4.p1.1.m1.2.2.1.1">subscript</csymbol><ci id="S4.SS1.SSS0.Px4.p1.1.m1.2.2.1.1.2.cmml" xref="S4.SS1.SSS0.Px4.p1.1.m1.2.2.1.1.2">𝑠</ci><cn id="S4.SS1.SSS0.Px4.p1.1.m1.2.2.1.1.3.cmml" type="integer" xref="S4.SS1.SSS0.Px4.p1.1.m1.2.2.1.1.3">1</cn></apply><ci id="S4.SS1.SSS0.Px4.p1.1.m1.1.1.cmml" xref="S4.SS1.SSS0.Px4.p1.1.m1.1.1">…</ci><apply id="S4.SS1.SSS0.Px4.p1.1.m1.3.3.2.2.cmml" xref="S4.SS1.SSS0.Px4.p1.1.m1.3.3.2.2"><csymbol cd="ambiguous" id="S4.SS1.SSS0.Px4.p1.1.m1.3.3.2.2.1.cmml" xref="S4.SS1.SSS0.Px4.p1.1.m1.3.3.2.2">subscript</csymbol><ci id="S4.SS1.SSS0.Px4.p1.1.m1.3.3.2.2.2.cmml" xref="S4.SS1.SSS0.Px4.p1.1.m1.3.3.2.2.2">𝑠</ci><ci id="S4.SS1.SSS0.Px4.p1.1.m1.3.3.2.2.3.cmml" xref="S4.SS1.SSS0.Px4.p1.1.m1.3.3.2.2.3">𝑛</ci></apply></vector></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px4.p1.1.m1.3c">(s_{1},\dots,s_{n})</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS0.Px4.p1.1.m1.3d">( italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_s start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT )</annotation></semantics></math>, we can get the final score with <math alttext="s=w_{1}s_{1}+\dots+w_{n}s_{n}" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px4.p1.2.m2.1"><semantics id="S4.SS1.SSS0.Px4.p1.2.m2.1a"><mrow id="S4.SS1.SSS0.Px4.p1.2.m2.1.1" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1.cmml"><mi id="S4.SS1.SSS0.Px4.p1.2.m2.1.1.2" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1.2.cmml">s</mi><mo id="S4.SS1.SSS0.Px4.p1.2.m2.1.1.1" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1.1.cmml">=</mo><mrow id="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.cmml"><mrow id="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.2" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.2.cmml"><msub id="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.2.2" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.2.2.cmml"><mi id="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.2.2.2" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.2.2.2.cmml">w</mi><mn id="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.2.2.3" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.2.2.3.cmml">1</mn></msub><mo id="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.2.1" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.2.1.cmml">⁢</mo><msub id="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.2.3" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.2.3.cmml"><mi id="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.2.3.2" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.2.3.2.cmml">s</mi><mn id="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.2.3.3" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.2.3.3.cmml">1</mn></msub></mrow><mo id="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.1" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.1.cmml">+</mo><mi id="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.3" mathvariant="normal" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.3.cmml">⋯</mi><mo id="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.1a" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.1.cmml">+</mo><mrow id="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.4" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.4.cmml"><msub id="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.4.2" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.4.2.cmml"><mi id="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.4.2.2" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.4.2.2.cmml">w</mi><mi id="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.4.2.3" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.4.2.3.cmml">n</mi></msub><mo id="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.4.1" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.4.1.cmml">⁢</mo><msub id="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.4.3" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.4.3.cmml"><mi id="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.4.3.2" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.4.3.2.cmml">s</mi><mi id="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.4.3.3" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.4.3.3.cmml">n</mi></msub></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px4.p1.2.m2.1b"><apply id="S4.SS1.SSS0.Px4.p1.2.m2.1.1.cmml" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1"><eq id="S4.SS1.SSS0.Px4.p1.2.m2.1.1.1.cmml" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1.1"></eq><ci id="S4.SS1.SSS0.Px4.p1.2.m2.1.1.2.cmml" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1.2">𝑠</ci><apply id="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.cmml" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3"><plus id="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.1.cmml" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.1"></plus><apply id="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.2.cmml" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.2"><times id="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.2.1.cmml" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.2.1"></times><apply id="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.2.2.cmml" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.2.2"><csymbol cd="ambiguous" id="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.2.2.1.cmml" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.2.2">subscript</csymbol><ci id="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.2.2.2.cmml" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.2.2.2">𝑤</ci><cn id="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.2.2.3.cmml" type="integer" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.2.2.3">1</cn></apply><apply id="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.2.3.cmml" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.2.3"><csymbol cd="ambiguous" id="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.2.3.1.cmml" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.2.3">subscript</csymbol><ci id="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.2.3.2.cmml" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.2.3.2">𝑠</ci><cn id="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.2.3.3.cmml" type="integer" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.2.3.3">1</cn></apply></apply><ci id="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.3.cmml" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.3">⋯</ci><apply id="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.4.cmml" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.4"><times id="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.4.1.cmml" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.4.1"></times><apply id="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.4.2.cmml" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.4.2"><csymbol cd="ambiguous" id="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.4.2.1.cmml" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.4.2">subscript</csymbol><ci id="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.4.2.2.cmml" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.4.2.2">𝑤</ci><ci id="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.4.2.3.cmml" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.4.2.3">𝑛</ci></apply><apply id="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.4.3.cmml" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.4.3"><csymbol cd="ambiguous" id="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.4.3.1.cmml" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.4.3">subscript</csymbol><ci id="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.4.3.2.cmml" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.4.3.2">𝑠</ci><ci id="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.4.3.3.cmml" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.4.3.3">𝑛</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px4.p1.2.m2.1c">s=w_{1}s_{1}+\dots+w_{n}s_{n}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS0.Px4.p1.2.m2.1d">italic_s = italic_w start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + ⋯ + italic_w start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT italic_s start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT</annotation></semantics></math>, where <math alttext="(w_{1},\dots,w_{n})" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px4.p1.3.m3.3"><semantics id="S4.SS1.SSS0.Px4.p1.3.m3.3a"><mrow id="S4.SS1.SSS0.Px4.p1.3.m3.3.3.2" xref="S4.SS1.SSS0.Px4.p1.3.m3.3.3.3.cmml"><mo id="S4.SS1.SSS0.Px4.p1.3.m3.3.3.2.3" stretchy="false" xref="S4.SS1.SSS0.Px4.p1.3.m3.3.3.3.cmml">(</mo><msub id="S4.SS1.SSS0.Px4.p1.3.m3.2.2.1.1" xref="S4.SS1.SSS0.Px4.p1.3.m3.2.2.1.1.cmml"><mi id="S4.SS1.SSS0.Px4.p1.3.m3.2.2.1.1.2" xref="S4.SS1.SSS0.Px4.p1.3.m3.2.2.1.1.2.cmml">w</mi><mn id="S4.SS1.SSS0.Px4.p1.3.m3.2.2.1.1.3" xref="S4.SS1.SSS0.Px4.p1.3.m3.2.2.1.1.3.cmml">1</mn></msub><mo id="S4.SS1.SSS0.Px4.p1.3.m3.3.3.2.4" xref="S4.SS1.SSS0.Px4.p1.3.m3.3.3.3.cmml">,</mo><mi id="S4.SS1.SSS0.Px4.p1.3.m3.1.1" mathvariant="normal" xref="S4.SS1.SSS0.Px4.p1.3.m3.1.1.cmml">…</mi><mo id="S4.SS1.SSS0.Px4.p1.3.m3.3.3.2.5" xref="S4.SS1.SSS0.Px4.p1.3.m3.3.3.3.cmml">,</mo><msub id="S4.SS1.SSS0.Px4.p1.3.m3.3.3.2.2" xref="S4.SS1.SSS0.Px4.p1.3.m3.3.3.2.2.cmml"><mi id="S4.SS1.SSS0.Px4.p1.3.m3.3.3.2.2.2" xref="S4.SS1.SSS0.Px4.p1.3.m3.3.3.2.2.2.cmml">w</mi><mi id="S4.SS1.SSS0.Px4.p1.3.m3.3.3.2.2.3" xref="S4.SS1.SSS0.Px4.p1.3.m3.3.3.2.2.3.cmml">n</mi></msub><mo id="S4.SS1.SSS0.Px4.p1.3.m3.3.3.2.6" stretchy="false" xref="S4.SS1.SSS0.Px4.p1.3.m3.3.3.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px4.p1.3.m3.3b"><vector id="S4.SS1.SSS0.Px4.p1.3.m3.3.3.3.cmml" xref="S4.SS1.SSS0.Px4.p1.3.m3.3.3.2"><apply id="S4.SS1.SSS0.Px4.p1.3.m3.2.2.1.1.cmml" xref="S4.SS1.SSS0.Px4.p1.3.m3.2.2.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS0.Px4.p1.3.m3.2.2.1.1.1.cmml" xref="S4.SS1.SSS0.Px4.p1.3.m3.2.2.1.1">subscript</csymbol><ci id="S4.SS1.SSS0.Px4.p1.3.m3.2.2.1.1.2.cmml" xref="S4.SS1.SSS0.Px4.p1.3.m3.2.2.1.1.2">𝑤</ci><cn id="S4.SS1.SSS0.Px4.p1.3.m3.2.2.1.1.3.cmml" type="integer" xref="S4.SS1.SSS0.Px4.p1.3.m3.2.2.1.1.3">1</cn></apply><ci id="S4.SS1.SSS0.Px4.p1.3.m3.1.1.cmml" xref="S4.SS1.SSS0.Px4.p1.3.m3.1.1">…</ci><apply id="S4.SS1.SSS0.Px4.p1.3.m3.3.3.2.2.cmml" xref="S4.SS1.SSS0.Px4.p1.3.m3.3.3.2.2"><csymbol cd="ambiguous" id="S4.SS1.SSS0.Px4.p1.3.m3.3.3.2.2.1.cmml" xref="S4.SS1.SSS0.Px4.p1.3.m3.3.3.2.2">subscript</csymbol><ci id="S4.SS1.SSS0.Px4.p1.3.m3.3.3.2.2.2.cmml" xref="S4.SS1.SSS0.Px4.p1.3.m3.3.3.2.2.2">𝑤</ci><ci id="S4.SS1.SSS0.Px4.p1.3.m3.3.3.2.2.3.cmml" xref="S4.SS1.SSS0.Px4.p1.3.m3.3.3.2.2.3">𝑛</ci></apply></vector></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px4.p1.3.m3.3c">(w_{1},\dots,w_{n})</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS0.Px4.p1.3.m3.3d">( italic_w start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_w start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT )</annotation></semantics></math> are a series of pre-defined weights.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px5">
<h5 class="ltx_title ltx_title_paragraph">A multilingual sandbox for code verification</h5>
<div class="ltx_para ltx_noindent" id="S4.SS1.SSS0.Px5.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px5.p1.1">To further verify the correctness of the code syntax, we use the code static checking for all extracted code snippets of programming languages (e.g. Python, Java, and C++). We parse the code snippet into the abstract syntax tree and filter out the code snippet, where the parsed nodes in code snippet have parsing errors. We create a multilingual sandbox to support the code static checking for the main programming language.
Further, the multilingual sandbox is a comprehensive platform designed to validate code snippets across multiple programming languages. It automates the process of generating relevant unit tests based on language-specific samples and evaluates whether the provided code snippets can successfully pass these tests. Especially, only the self-contained (e.g. algorithm problems) code snippet will be fed into the multilingual sandbox. The multilingual verification sandbox is mainly comprised of five parts:</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.SSS0.Px5.p2">
<ol class="ltx_enumerate" id="S4.I1">
<li class="ltx_item" id="S4.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para ltx_noindent" id="S4.I1.i1.p1">
<p class="ltx_p" id="S4.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i1.p1.1.1">Language Support Module:</span></p>
<ul class="ltx_itemize" id="S4.I1.i1.I1">
<li class="ltx_item" id="S4.I1.i1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i1.I1.i1.p1">
<p class="ltx_p" id="S4.I1.i1.I1.i1.p1.1">Implements support for multiple languages (e.g., Python, Java, C++, JavaScript)</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i1.I1.i2.p1">
<p class="ltx_p" id="S4.I1.i1.I1.i2.p1.1">Maintains language-specific parsing and execution environments</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S4.I1.i1.I1.i3.p1">
<p class="ltx_p" id="S4.I1.i1.I1.i3.p1.1">Handles syntax and semantic analysis for each supported language</p>
</div>
</li>
</ul>
</div>
</li>
<li class="ltx_item" id="S4.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para ltx_noindent" id="S4.I1.i2.p1">
<p class="ltx_p" id="S4.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i2.p1.1.1">Sample Code Repository:</span></p>
<ul class="ltx_itemize" id="S4.I1.i2.I1">
<li class="ltx_item" id="S4.I1.i2.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i2.I1.i1.p1">
<p class="ltx_p" id="S4.I1.i2.I1.i1.p1.1">Stores a diverse collection of code samples for each supported language</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i2.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i2.I1.i2.p1">
<p class="ltx_p" id="S4.I1.i2.I1.i2.p1.1">Organizes samples by language, difficulty level, and programming concepts</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i2.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S4.I1.i2.I1.i3.p1">
<p class="ltx_p" id="S4.I1.i2.I1.i3.p1.1">Regularly updated and curated by language experts</p>
</div>
</li>
</ul>
</div>
</li>
<li class="ltx_item" id="S4.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para ltx_noindent" id="S4.I1.i3.p1">
<p class="ltx_p" id="S4.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i3.p1.1.1">Unit Test Generator:</span></p>
<ul class="ltx_itemize" id="S4.I1.i3.I1">
<li class="ltx_item" id="S4.I1.i3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i3.I1.i1.p1">
<p class="ltx_p" id="S4.I1.i3.I1.i1.p1.1">Analyzes sample code to identify key functionalities and edge cases</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i3.I1.i2.p1">
<p class="ltx_p" id="S4.I1.i3.I1.i2.p1.1">Automatically generates unit tests based on the expected behavior</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i3.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S4.I1.i3.I1.i3.p1">
<p class="ltx_p" id="S4.I1.i3.I1.i3.p1.1">Produces test cases covering various input scenarios and expected outputs</p>
</div>
</li>
</ul>
</div>
</li>
<li class="ltx_item" id="S4.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span>
<div class="ltx_para ltx_noindent" id="S4.I1.i4.p1">
<p class="ltx_p" id="S4.I1.i4.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i4.p1.1.1">Code Execution Engine:</span></p>
<ul class="ltx_itemize" id="S4.I1.i4.I1">
<li class="ltx_item" id="S4.I1.i4.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i4.I1.i1.p1">
<p class="ltx_p" id="S4.I1.i4.I1.i1.p1.1">Provides isolated environments for executing code snippets securely</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i4.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i4.I1.i2.p1">
<p class="ltx_p" id="S4.I1.i4.I1.i2.p1.1">Supports parallel execution of multiple test cases</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i4.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S4.I1.i4.I1.i3.p1">
<p class="ltx_p" id="S4.I1.i4.I1.i3.p1.1">Handles resource allocation and timeout mechanisms</p>
</div>
</li>
</ul>
</div>
</li>
<li class="ltx_item" id="S4.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">5.</span>
<div class="ltx_para ltx_noindent" id="S4.I1.i5.p1">
<p class="ltx_p" id="S4.I1.i5.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i5.p1.1.1">Result Analyzer:</span></p>
<ul class="ltx_itemize" id="S4.I1.i5.I1">
<li class="ltx_item" id="S4.I1.i5.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i5.I1.i1.p1">
<p class="ltx_p" id="S4.I1.i5.I1.i1.p1.1">Compares the output of code snippets against expected results from unit tests</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i5.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i5.I1.i2.p1">
<p class="ltx_p" id="S4.I1.i5.I1.i2.p1.1">Generates detailed reports on test case successes and failures</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i5.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S4.I1.i5.I1.i3.p1">
<p class="ltx_p" id="S4.I1.i5.I1.i3.p1.1">Provides suggestions for improvements based on failed test cases</p>
</div>
</li>
</ul>
</div>
</li>
</ol>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Training Policy </h3>
<section class="ltx_paragraph" id="S4.SS2.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Coarse-to-fine Fine-tuning</h5>
<div class="ltx_para ltx_noindent" id="S4.SS2.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS2.SSS0.Px1.p1.1">We first synthesized tens of millions of low-quality but diverse instruction samples to fine-tune the base model. In the second stage, we adopt millions of high-quality instruction samples to improve the performance of the instruction model with rejection sampling and supervised fine-tuning. For the same query, we use the LLM to generate multiple candidates and then use the LLM to score the best one for supervised fine-tuning.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS2.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">Mixed Tuning</h5>
<div class="ltx_para ltx_noindent" id="S4.SS2.SSS0.Px2.p1">
<p class="ltx_p" id="S4.SS2.SSS0.Px2.p1.1">Since most instruction data have a short length, we construct the instruction pair with the FIM format to keep the long context capability of the base model. Inspired by programming language syntax rules and user habits in practical scenarios, we leverage the <span class="ltx_text ltx_font_typewriter" id="S4.SS2.SSS0.Px2.p1.1.1">tree-sitter-languages<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_serif" id="footnote1.1.1.1">1</span></span><a class="ltx_ref ltx_url" href="https://pypi.org/project/tree-sitter-languages/" title="">https://pypi.org/project/tree-sitter-languages/</a></span></span></span></span> to parse the code snippets and extract the basic logic blocks as the middle code to infill. For example, the abstract syntax tree (AST) represents the structure of Python code in a tree format, where each node in the tree represents a construct occurring in the source code. The tree’s hierarchical nature reflects the syntactic nesting of constructs in the code and includes various elements such as expressions, statements, and functions. By traversing and manipulating the AST, we can randomly extract the nodes of multiple levels and use the code context of the same file to uncover the masked node. Finally, we optimize the instruction model with a majority of standard SFT data and a small part of FIM instruction samples.</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Decontamination</h2>
<div class="ltx_para ltx_noindent" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">To ensure that Qwen2.5-Coder does not produce inflated results due to test set leakage, we performed decontamination on all data, including both pre-training and post-training datasets. We removed key datasets such as HumanEval, MBPP, GSM8K, and MATH. The filtering was done using a 10-gram overlap method, where any training data with a 10-gram string-level overlap with the test data was removed.</p>
</div>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Evaluation on Base Models</h2>
<div class="ltx_para ltx_noindent" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">For the base model, we conducted a comprehensive and fair evaluation in six key aspects, including code generation, code completion, code reasoning, mathematical reasoning, general natural language understanding and long-context modeling. To ensure the reproducibility of all results, we made all evaluation codes publicly available<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/QwenLM/Qwen2.5-Coder" title="">https://github.com/QwenLM/Qwen2.5-Coder</a></span></span></span>. For comparing models, we chose the most popular and powerful open source language models, including the StarCoder2 and DeepSeek-Coder series. Below is the list of artifacts used in the evaluation for this section.</p>
</div>
<figure class="ltx_table" id="S6.T4">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S6.T4.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S6.T4.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S6.T4.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S6.T4.1.1.1.1.1">Artifact</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S6.T4.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S6.T4.1.1.1.2.1">Public link</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S6.T4.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S6.T4.1.2.1.1">Qwen2.5-Coder-1.5B</th>
<td class="ltx_td ltx_align_left ltx_border_t" id="S6.T4.1.2.1.2"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://hf.co/qwen/Qwen/Qwen2.5-Coder-1.5B" title="">https://hf.co/qwen/Qwen/Qwen2.5-Coder-1.5B</a></td>
</tr>
<tr class="ltx_tr" id="S6.T4.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S6.T4.1.3.2.1">Qwen2.5-Coder-7B</th>
<td class="ltx_td ltx_align_left" id="S6.T4.1.3.2.2"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://hf.co/qwen/Qwen/Qwen2.5-Coder-7B" title="">https://hf.co/qwen/Qwen/Qwen2.5-Coder-7B</a></td>
</tr>
<tr class="ltx_tr" id="S6.T4.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S6.T4.1.4.3.1">CodeQwen1.5-7B-Base</th>
<td class="ltx_td ltx_align_left ltx_border_t" id="S6.T4.1.4.3.2"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/Qwen/CodeQwen1.5-7B" title="">https://huggingface.co/Qwen/CodeQwen1.5-7B</a></td>
</tr>
<tr class="ltx_tr" id="S6.T4.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S6.T4.1.5.4.1">StarCoder2-3B</th>
<td class="ltx_td ltx_align_left" id="S6.T4.1.5.4.2"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://hf.co/bigcode/starcoder2-3b" title="">https://hf.co/bigcode/starcoder2-3b</a></td>
</tr>
<tr class="ltx_tr" id="S6.T4.1.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S6.T4.1.6.5.1">StarCoder2-7B</th>
<td class="ltx_td ltx_align_left" id="S6.T4.1.6.5.2"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://hf.co/bigcode/starcoder2-7b" title="">https://hf.co/bigcode/starcoder2-7b</a></td>
</tr>
<tr class="ltx_tr" id="S6.T4.1.7.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S6.T4.1.7.6.1">StarCoder2-15B</th>
<td class="ltx_td ltx_align_left" id="S6.T4.1.7.6.2"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://hf.co/bigcode/starcoder2-15b" title="">https://hf.co/bigcode/starcoder2-15b</a></td>
</tr>
<tr class="ltx_tr" id="S6.T4.1.8.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S6.T4.1.8.7.1">DS-Coder-1.3B-Base</th>
<td class="ltx_td ltx_align_left" id="S6.T4.1.8.7.2"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://hf.co/deepseek-ai/deepseek-coder-1.3b-base" title="">https://hf.co/deepseek-ai/deepseek-coder-1.3b-base</a></td>
</tr>
<tr class="ltx_tr" id="S6.T4.1.9.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S6.T4.1.9.8.1">DS-Coder-6.7B-Base</th>
<td class="ltx_td ltx_align_left" id="S6.T4.1.9.8.2"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://hf.co/deepseek-ai/deepseek-coder-6.7b-base" title="">https://hf.co/deepseek-ai/deepseek-coder-6.7b-base</a></td>
</tr>
<tr class="ltx_tr" id="S6.T4.1.10.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S6.T4.1.10.9.1">DS-Coder-33B-Base</th>
<td class="ltx_td ltx_align_left" id="S6.T4.1.10.9.2"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://hf.co/deepseek-ai/deepseek-coder-33b-base" title="">https://hf.co/deepseek-ai/deepseek-coder-33b-base</a></td>
</tr>
<tr class="ltx_tr" id="S6.T4.1.11.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S6.T4.1.11.10.1">DS-Coder-V2-Lite-Base</th>
<td class="ltx_td ltx_align_left" id="S6.T4.1.11.10.2"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://hf.co/deepseek-ai/DeepSeek-Coder-V2-Lite-Base" title="">https://hf.co/deepseek-ai/DeepSeek-Coder-V2-Lite-Base</a></td>
</tr>
<tr class="ltx_tr" id="S6.T4.1.12.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S6.T4.1.12.11.1">DS-Coder-V2-Base</th>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S6.T4.1.12.11.2"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://hf.co/deepseek-ai/DeepSeek-Coder-V2-Base" title="">https://hf.co/deepseek-ai/DeepSeek-Coder-V2-Base</a></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>All artifacts released and used in this section.</figcaption>
</figure>
<section class="ltx_subsection" id="S6.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1 </span>Code Generation</h3>
<figure class="ltx_table" id="S6.T5">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S6.T5.1" style="width:397.5pt;height:252.5pt;vertical-align:-0.9pt;"><span class="ltx_transformed_inner" style="transform:translate(-14.5pt,9.2pt) scale(0.931967851200986,0.931967851200986) ;">
<table class="ltx_tabular ltx_align_middle" id="S6.T5.1.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S6.T5.1.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S6.T5.1.1.1.1.1" rowspan="2"><span class="ltx_text ltx_font_bold" id="S6.T5.1.1.1.1.1.1">Model</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S6.T5.1.1.1.1.2" rowspan="2"><span class="ltx_text ltx_font_bold" id="S6.T5.1.1.1.1.2.1">Size</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2" id="S6.T5.1.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S6.T5.1.1.1.1.3.1">HumanEval</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="3" id="S6.T5.1.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S6.T5.1.1.1.1.4.1">MBPP</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S6.T5.1.1.1.1.5"><span class="ltx_text ltx_font_bold" id="S6.T5.1.1.1.1.5.1">BigCodeBench</span></td>
</tr>
<tr class="ltx_tr" id="S6.T5.1.1.2.2">
<td class="ltx_td ltx_align_center" id="S6.T5.1.1.2.2.1"><span class="ltx_text ltx_font_italic" id="S6.T5.1.1.2.2.1.1">HE</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.1.1.2.2.2"><span class="ltx_text ltx_font_italic" id="S6.T5.1.1.2.2.2.1">HE+</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.1.1.2.2.3"><span class="ltx_text ltx_font_italic" id="S6.T5.1.1.2.2.3.1">MBPP</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.1.1.2.2.4"><span class="ltx_text ltx_font_italic" id="S6.T5.1.1.2.2.4.1">MBPP+</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.1.1.2.2.5"><span class="ltx_text ltx_font_italic" id="S6.T5.1.1.2.2.5.1">3-shot</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.1.1.2.2.6"><span class="ltx_text ltx_font_italic" id="S6.T5.1.1.2.2.6.1">Full</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.1.1.2.2.7"><span class="ltx_text ltx_font_italic" id="S6.T5.1.1.2.2.7.1">Hard</span></td>
</tr>
<tr class="ltx_tr" id="S6.T5.1.1.3.3">
<td class="ltx_td ltx_align_center ltx_border_t" colspan="9" id="S6.T5.1.1.3.3.1"><span class="ltx_text ltx_font_bold" id="S6.T5.1.1.3.3.1.1">1B+ Models</span></td>
</tr>
<tr class="ltx_tr" id="S6.T5.1.1.4.4">
<td class="ltx_td ltx_align_left ltx_border_t" id="S6.T5.1.1.4.4.1">StarCoder2-3B</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S6.T5.1.1.4.4.2">3B</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T5.1.1.4.4.3">31.7</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S6.T5.1.1.4.4.4">27.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T5.1.1.4.4.5">60.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T5.1.1.4.4.6">49.1</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S6.T5.1.1.4.4.7">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T5.1.1.4.4.8">21.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T5.1.1.4.4.9">4.7</td>
</tr>
<tr class="ltx_tr" id="S6.T5.1.1.5.5">
<td class="ltx_td ltx_align_left" id="S6.T5.1.1.5.5.1">DS-Coder-1.3B</td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S6.T5.1.1.5.5.2">1.3B</td>
<td class="ltx_td ltx_align_center" id="S6.T5.1.1.5.5.3">34.8</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.1.1.5.5.4">26.8</td>
<td class="ltx_td ltx_align_center" id="S6.T5.1.1.5.5.5">55.6</td>
<td class="ltx_td ltx_align_center" id="S6.T5.1.1.5.5.6">46.9</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.1.1.5.5.7">46.2</td>
<td class="ltx_td ltx_align_center" id="S6.T5.1.1.5.5.8">26.1</td>
<td class="ltx_td ltx_align_center" id="S6.T5.1.1.5.5.9">3.4</td>
</tr>
<tr class="ltx_tr" id="S6.T5.1.1.6.6" style="background-color:#E6E6E6;">
<td class="ltx_td ltx_align_left" id="S6.T5.1.1.6.6.1"><span class="ltx_text ltx_font_bold" id="S6.T5.1.1.6.6.1.1" style="background-color:#E6E6E6;">Qwen2.5-Coder-1.5B</span></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S6.T5.1.1.6.6.2"><span class="ltx_text" id="S6.T5.1.1.6.6.2.1" style="background-color:#E6E6E6;">1.5B</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.1.1.6.6.3"><span class="ltx_text ltx_font_bold" id="S6.T5.1.1.6.6.3.1" style="background-color:#E6E6E6;">43.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.1.1.6.6.4"><span class="ltx_text ltx_font_bold" id="S6.T5.1.1.6.6.4.1" style="background-color:#E6E6E6;">36.6</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.1.1.6.6.5"><span class="ltx_text ltx_font_bold" id="S6.T5.1.1.6.6.5.1" style="background-color:#E6E6E6;">69.2</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.1.1.6.6.6"><span class="ltx_text ltx_font_bold" id="S6.T5.1.1.6.6.6.1" style="background-color:#E6E6E6;">58.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.1.1.6.6.7"><span class="ltx_text ltx_font_bold" id="S6.T5.1.1.6.6.7.1" style="background-color:#E6E6E6;">59.2</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.1.1.6.6.8"><span class="ltx_text ltx_font_bold" id="S6.T5.1.1.6.6.8.1" style="background-color:#E6E6E6;">34.6</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.1.1.6.6.9"><span class="ltx_text ltx_font_bold" id="S6.T5.1.1.6.6.9.1" style="background-color:#E6E6E6;">9.5</span></td>
</tr>
<tr class="ltx_tr" id="S6.T5.1.1.7.7">
<td class="ltx_td ltx_align_center ltx_border_t" colspan="9" id="S6.T5.1.1.7.7.1"><span class="ltx_text ltx_font_bold" id="S6.T5.1.1.7.7.1.1">6B+ Models</span></td>
</tr>
<tr class="ltx_tr" id="S6.T5.1.1.8.8">
<td class="ltx_td ltx_align_left ltx_border_t" id="S6.T5.1.1.8.8.1">StarCoder2-7B</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S6.T5.1.1.8.8.2">7B</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T5.1.1.8.8.3">35.4</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S6.T5.1.1.8.8.4">29.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T5.1.1.8.8.5">54.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T5.1.1.8.8.6">45.6</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S6.T5.1.1.8.8.7">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T5.1.1.8.8.8">27.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T5.1.1.8.8.9">8.8</td>
</tr>
<tr class="ltx_tr" id="S6.T5.1.1.9.9">
<td class="ltx_td ltx_align_left" id="S6.T5.1.1.9.9.1">StarCoder2-15B</td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S6.T5.1.1.9.9.2">15B</td>
<td class="ltx_td ltx_align_center" id="S6.T5.1.1.9.9.3">46.3</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.1.1.9.9.4">37.8</td>
<td class="ltx_td ltx_align_center" id="S6.T5.1.1.9.9.5">66.2</td>
<td class="ltx_td ltx_align_center" id="S6.T5.1.1.9.9.6">53.1</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.1.1.9.9.7">-</td>
<td class="ltx_td ltx_align_center" id="S6.T5.1.1.9.9.8">38.4</td>
<td class="ltx_td ltx_align_center" id="S6.T5.1.1.9.9.9">12.2</td>
</tr>
<tr class="ltx_tr" id="S6.T5.1.1.10.10">
<td class="ltx_td ltx_align_left" id="S6.T5.1.1.10.10.1">DS-Coder-6.7B-Base</td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S6.T5.1.1.10.10.2">6.7B</td>
<td class="ltx_td ltx_align_center" id="S6.T5.1.1.10.10.3">47.6</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.1.1.10.10.4">39.6</td>
<td class="ltx_td ltx_align_center" id="S6.T5.1.1.10.10.5">70.2</td>
<td class="ltx_td ltx_align_center" id="S6.T5.1.1.10.10.6">56.6</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.1.1.10.10.7">60.6</td>
<td class="ltx_td ltx_align_center" id="S6.T5.1.1.10.10.8">41.1</td>
<td class="ltx_td ltx_align_center" id="S6.T5.1.1.10.10.9">11.5</td>
</tr>
<tr class="ltx_tr" id="S6.T5.1.1.11.11">
<td class="ltx_td ltx_align_left" id="S6.T5.1.1.11.11.1">DS-Coder-V2-Lite-Base</td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S6.T5.1.1.11.11.2">2.4/16B</td>
<td class="ltx_td ltx_align_center" id="S6.T5.1.1.11.11.3">40.9</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.1.1.11.11.4">34.1</td>
<td class="ltx_td ltx_align_center" id="S6.T5.1.1.11.11.5">71.9</td>
<td class="ltx_td ltx_align_center" id="S6.T5.1.1.11.11.6">59.4</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.1.1.11.11.7">-</td>
<td class="ltx_td ltx_align_center" id="S6.T5.1.1.11.11.8">30.6</td>
<td class="ltx_td ltx_align_center" id="S6.T5.1.1.11.11.9">8.1</td>
</tr>
<tr class="ltx_tr" id="S6.T5.1.1.12.12">
<td class="ltx_td ltx_align_left" id="S6.T5.1.1.12.12.1">CodeQwen1.5-7B-Base</td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S6.T5.1.1.12.12.2">7B</td>
<td class="ltx_td ltx_align_center" id="S6.T5.1.1.12.12.3">51.8</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.1.1.12.12.4">45.7</td>
<td class="ltx_td ltx_align_center" id="S6.T5.1.1.12.12.5">72.2</td>
<td class="ltx_td ltx_align_center" id="S6.T5.1.1.12.12.6">60.2</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.1.1.12.12.7">61.8</td>
<td class="ltx_td ltx_align_center" id="S6.T5.1.1.12.12.8">45.6</td>
<td class="ltx_td ltx_align_center" id="S6.T5.1.1.12.12.9">15.6</td>
</tr>
<tr class="ltx_tr" id="S6.T5.1.1.13.13" style="background-color:#E6E6E6;">
<td class="ltx_td ltx_align_left" id="S6.T5.1.1.13.13.1"><span class="ltx_text ltx_font_bold" id="S6.T5.1.1.13.13.1.1" style="background-color:#E6E6E6;">Qwen2.5-Coder-7B-Base</span></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S6.T5.1.1.13.13.2"><span class="ltx_text" id="S6.T5.1.1.13.13.2.1" style="background-color:#E6E6E6;">7B</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.1.1.13.13.3"><span class="ltx_text ltx_font_bold" id="S6.T5.1.1.13.13.3.1" style="background-color:#E6E6E6;">61.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.1.1.13.13.4"><span class="ltx_text ltx_font_bold" id="S6.T5.1.1.13.13.4.1" style="background-color:#E6E6E6;">53.0</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.1.1.13.13.5"><span class="ltx_text ltx_font_bold" id="S6.T5.1.1.13.13.5.1" style="background-color:#E6E6E6;">76.9</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.1.1.13.13.6"><span class="ltx_text ltx_font_bold" id="S6.T5.1.1.13.13.6.1" style="background-color:#E6E6E6;">62.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T5.1.1.13.13.7"><span class="ltx_text ltx_font_bold" id="S6.T5.1.1.13.13.7.1" style="background-color:#E6E6E6;">68.8</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.1.1.13.13.8"><span class="ltx_text ltx_font_bold" id="S6.T5.1.1.13.13.8.1" style="background-color:#E6E6E6;">45.8</span></td>
<td class="ltx_td ltx_align_center" id="S6.T5.1.1.13.13.9"><span class="ltx_text ltx_font_bold" id="S6.T5.1.1.13.13.9.1" style="background-color:#E6E6E6;">16.2</span></td>
</tr>
<tr class="ltx_tr" id="S6.T5.1.1.14.14">
<td class="ltx_td ltx_align_center ltx_border_t" colspan="9" id="S6.T5.1.1.14.14.1"><span class="ltx_text ltx_font_bold" id="S6.T5.1.1.14.14.1.1">20B+ Models</span></td>
</tr>
<tr class="ltx_tr" id="S6.T5.1.1.15.15">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S6.T5.1.1.15.15.1"><span class="ltx_text" id="S6.T5.1.1.15.15.1.1" style="color:#999999;">DS-Coder-33B-Base</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb ltx_border_r ltx_border_t" id="S6.T5.1.1.15.15.2"><span class="ltx_text" id="S6.T5.1.1.15.15.2.1" style="color:#999999;">33B</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S6.T5.1.1.15.15.3"><span class="ltx_text" id="S6.T5.1.1.15.15.3.1" style="color:#999999;">54.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S6.T5.1.1.15.15.4"><span class="ltx_text" id="S6.T5.1.1.15.15.4.1" style="color:#999999;">47.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S6.T5.1.1.15.15.5"><span class="ltx_text" id="S6.T5.1.1.15.15.5.1" style="color:#999999;">74.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S6.T5.1.1.15.15.6"><span class="ltx_text" id="S6.T5.1.1.15.15.6.1" style="color:#999999;">60.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S6.T5.1.1.15.15.7"><span class="ltx_text" id="S6.T5.1.1.15.15.7.1" style="color:#999999;">66.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S6.T5.1.1.15.15.8"><span class="ltx_text" id="S6.T5.1.1.15.15.8.1" style="color:#999999;">49.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S6.T5.1.1.15.15.9"><span class="ltx_text" id="S6.T5.1.1.15.15.9.1" style="color:#999999;">20.3</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>Performance of various models on HumanEval, MBPP and the “complete” task of BigCodeBench. </figcaption>
</figure>
<figure class="ltx_table" id="S6.T6">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S6.T6.1" style="width:397.5pt;height:208.4pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-42.5pt,22.2pt) scale(0.823896512612274,0.823896512612274) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S6.T6.1.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S6.T6.1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="S6.T6.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S6.T6.1.1.1.1.1.1">Model</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_tt" id="S6.T6.1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S6.T6.1.1.1.1.2.1">Size</span></th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S6.T6.1.1.1.1.3">Python</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S6.T6.1.1.1.1.4">C++</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S6.T6.1.1.1.1.5">Java</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S6.T6.1.1.1.1.6">PHP</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S6.T6.1.1.1.1.7">TS</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S6.T6.1.1.1.1.8">C#</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S6.T6.1.1.1.1.9">Bash</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S6.T6.1.1.1.1.10">JS</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S6.T6.1.1.1.1.11"><span class="ltx_text ltx_font_bold" id="S6.T6.1.1.1.1.11.1">Average</span></td>
</tr>
<tr class="ltx_tr" id="S6.T6.1.1.2.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="11" id="S6.T6.1.1.2.2.1"><span class="ltx_text ltx_font_bold" id="S6.T6.1.1.2.2.1.1">1B+ Models</span></th>
</tr>
<tr class="ltx_tr" id="S6.T6.1.1.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S6.T6.1.1.3.3.1">StarCoder2-3B</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S6.T6.1.1.3.3.2">3B</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.1.1.3.3.3">31.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.1.1.3.3.4">30.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.1.1.3.3.5">29.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.1.1.3.3.6">32.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.1.1.3.3.7">39.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.1.1.3.3.8">34.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.1.1.3.3.9">13.9</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S6.T6.1.1.3.3.10">35.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.1.1.3.3.11">31.1</td>
</tr>
<tr class="ltx_tr" id="S6.T6.1.1.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T6.1.1.4.4.1">DS-Coder-1.3B-Base</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S6.T6.1.1.4.4.2">1.3B</th>
<td class="ltx_td ltx_align_center" id="S6.T6.1.1.4.4.3">34.8</td>
<td class="ltx_td ltx_align_center" id="S6.T6.1.1.4.4.4">31.1</td>
<td class="ltx_td ltx_align_center" id="S6.T6.1.1.4.4.5">32.3</td>
<td class="ltx_td ltx_align_center" id="S6.T6.1.1.4.4.6">24.2</td>
<td class="ltx_td ltx_align_center" id="S6.T6.1.1.4.4.7">28.9</td>
<td class="ltx_td ltx_align_center" id="S6.T6.1.1.4.4.8">36.7</td>
<td class="ltx_td ltx_align_center" id="S6.T6.1.1.4.4.9">10.1</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T6.1.1.4.4.10">28.6</td>
<td class="ltx_td ltx_align_center" id="S6.T6.1.1.4.4.11">28.3</td>
</tr>
<tr class="ltx_tr" id="S6.T6.1.1.5.5" style="background-color:#E6E6E6;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T6.1.1.5.5.1"><span class="ltx_text ltx_font_bold" id="S6.T6.1.1.5.5.1.1" style="background-color:#E6E6E6;">Qwen2.5-Coder-1.5B</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S6.T6.1.1.5.5.2"><span class="ltx_text" id="S6.T6.1.1.5.5.2.1" style="background-color:#E6E6E6;">1.5B</span></th>
<td class="ltx_td ltx_align_center" id="S6.T6.1.1.5.5.3"><span class="ltx_text ltx_font_bold" id="S6.T6.1.1.5.5.3.1" style="background-color:#E6E6E6;">42.1</span></td>
<td class="ltx_td ltx_align_center" id="S6.T6.1.1.5.5.4"><span class="ltx_text ltx_font_bold" id="S6.T6.1.1.5.5.4.1" style="background-color:#E6E6E6;">42.9</span></td>
<td class="ltx_td ltx_align_center" id="S6.T6.1.1.5.5.5"><span class="ltx_text ltx_font_bold" id="S6.T6.1.1.5.5.5.1" style="background-color:#E6E6E6;">38.6</span></td>
<td class="ltx_td ltx_align_center" id="S6.T6.1.1.5.5.6"><span class="ltx_text ltx_font_bold" id="S6.T6.1.1.5.5.6.1" style="background-color:#E6E6E6;">41.0</span></td>
<td class="ltx_td ltx_align_center" id="S6.T6.1.1.5.5.7"><span class="ltx_text ltx_font_bold" id="S6.T6.1.1.5.5.7.1" style="background-color:#E6E6E6;">49.1</span></td>
<td class="ltx_td ltx_align_center" id="S6.T6.1.1.5.5.8"><span class="ltx_text ltx_font_bold" id="S6.T6.1.1.5.5.8.1" style="background-color:#E6E6E6;">46.2</span></td>
<td class="ltx_td ltx_align_center" id="S6.T6.1.1.5.5.9"><span class="ltx_text ltx_font_bold" id="S6.T6.1.1.5.5.9.1" style="background-color:#E6E6E6;">20.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T6.1.1.5.5.10"><span class="ltx_text ltx_font_bold" id="S6.T6.1.1.5.5.10.1" style="background-color:#E6E6E6;">49.1</span></td>
<td class="ltx_td ltx_align_center" id="S6.T6.1.1.5.5.11"><span class="ltx_text ltx_font_bold" id="S6.T6.1.1.5.5.11.1" style="background-color:#E6E6E6;">41.1</span></td>
</tr>
<tr class="ltx_tr" id="S6.T6.1.1.6.6">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="11" id="S6.T6.1.1.6.6.1"><span class="ltx_text ltx_font_bold" id="S6.T6.1.1.6.6.1.1">6B+ Models</span></th>
</tr>
<tr class="ltx_tr" id="S6.T6.1.1.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S6.T6.1.1.7.7.1">StarCoder2-7B</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S6.T6.1.1.7.7.2">7B</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.1.1.7.7.3">35.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.1.1.7.7.4">40.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.1.1.7.7.5">38.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.1.1.7.7.6">30.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.1.1.7.7.7">34.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.1.1.7.7.8">46.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.1.1.7.7.9">13.9</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S6.T6.1.1.7.7.10">36.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.1.1.7.7.11">34.3</td>
</tr>
<tr class="ltx_tr" id="S6.T6.1.1.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T6.1.1.8.8.1">StarCoder2-15B</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S6.T6.1.1.8.8.2">15B</th>
<td class="ltx_td ltx_align_center" id="S6.T6.1.1.8.8.3">46.3</td>
<td class="ltx_td ltx_align_center" id="S6.T6.1.1.8.8.4">47.2</td>
<td class="ltx_td ltx_align_center" id="S6.T6.1.1.8.8.5">46.2</td>
<td class="ltx_td ltx_align_center" id="S6.T6.1.1.8.8.6">39.1</td>
<td class="ltx_td ltx_align_center" id="S6.T6.1.1.8.8.7">42.1</td>
<td class="ltx_td ltx_align_center" id="S6.T6.1.1.8.8.8">53.2</td>
<td class="ltx_td ltx_align_center" id="S6.T6.1.1.8.8.9">15.8</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T6.1.1.8.8.10">43.5</td>
<td class="ltx_td ltx_align_center" id="S6.T6.1.1.8.8.11">41.7</td>
</tr>
<tr class="ltx_tr" id="S6.T6.1.1.9.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T6.1.1.9.9.1">DS-Coder-6.7B-Base</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S6.T6.1.1.9.9.2">6.7B</th>
<td class="ltx_td ltx_align_center" id="S6.T6.1.1.9.9.3">49.4</td>
<td class="ltx_td ltx_align_center" id="S6.T6.1.1.9.9.4">50.3</td>
<td class="ltx_td ltx_align_center" id="S6.T6.1.1.9.9.5">43.0</td>
<td class="ltx_td ltx_align_center" id="S6.T6.1.1.9.9.6">38.5</td>
<td class="ltx_td ltx_align_center" id="S6.T6.1.1.9.9.7">49.7</td>
<td class="ltx_td ltx_align_center" id="S6.T6.1.1.9.9.8">50.0</td>
<td class="ltx_td ltx_align_center" id="S6.T6.1.1.9.9.9">28.5</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T6.1.1.9.9.10">48.4</td>
<td class="ltx_td ltx_align_center" id="S6.T6.1.1.9.9.11">44.7</td>
</tr>
<tr class="ltx_tr" id="S6.T6.1.1.10.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T6.1.1.10.10.1">DS-Coder-V2-Lite-Base</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S6.T6.1.1.10.10.2">2.4/16B</th>
<td class="ltx_td ltx_align_center" id="S6.T6.1.1.10.10.3">40.9</td>
<td class="ltx_td ltx_align_center" id="S6.T6.1.1.10.10.4">45.9</td>
<td class="ltx_td ltx_align_center" id="S6.T6.1.1.10.10.5">34.8</td>
<td class="ltx_td ltx_align_center" id="S6.T6.1.1.10.10.6">47.2</td>
<td class="ltx_td ltx_align_center" id="S6.T6.1.1.10.10.7">48.4</td>
<td class="ltx_td ltx_align_center" id="S6.T6.1.1.10.10.8">41.7</td>
<td class="ltx_td ltx_align_center" id="S6.T6.1.1.10.10.9">19.6</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T6.1.1.10.10.10">44.7</td>
<td class="ltx_td ltx_align_center" id="S6.T6.1.1.10.10.11">40.4</td>
</tr>
<tr class="ltx_tr" id="S6.T6.1.1.11.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T6.1.1.11.11.1">CodeQwen1.5-7B-Base</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S6.T6.1.1.11.11.2">7B</th>
<td class="ltx_td ltx_align_center" id="S6.T6.1.1.11.11.3">51.8</td>
<td class="ltx_td ltx_align_center" id="S6.T6.1.1.11.11.4">52.2</td>
<td class="ltx_td ltx_align_center" id="S6.T6.1.1.11.11.5">42.4</td>
<td class="ltx_td ltx_align_center" id="S6.T6.1.1.11.11.6">46.6</td>
<td class="ltx_td ltx_align_center" id="S6.T6.1.1.11.11.7">52.2</td>
<td class="ltx_td ltx_align_center" id="S6.T6.1.1.11.11.8">55.7</td>
<td class="ltx_td ltx_align_center" id="S6.T6.1.1.11.11.9">36.7</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T6.1.1.11.11.10">49.7</td>
<td class="ltx_td ltx_align_center" id="S6.T6.1.1.11.11.11">48.4</td>
</tr>
<tr class="ltx_tr" id="S6.T6.1.1.12.12" style="background-color:#E6E6E6;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T6.1.1.12.12.1"><span class="ltx_text ltx_font_bold" id="S6.T6.1.1.12.12.1.1" style="background-color:#E6E6E6;">Qwen2.5-Coder-7B-Base</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S6.T6.1.1.12.12.2"><span class="ltx_text" id="S6.T6.1.1.12.12.2.1" style="background-color:#E6E6E6;">7B</span></th>
<td class="ltx_td ltx_align_center" id="S6.T6.1.1.12.12.3"><span class="ltx_text ltx_font_bold" id="S6.T6.1.1.12.12.3.1" style="background-color:#E6E6E6;">61.6</span></td>
<td class="ltx_td ltx_align_center" id="S6.T6.1.1.12.12.4"><span class="ltx_text ltx_font_bold" id="S6.T6.1.1.12.12.4.1" style="background-color:#E6E6E6;">62.1</span></td>
<td class="ltx_td ltx_align_center" id="S6.T6.1.1.12.12.5"><span class="ltx_text ltx_font_bold" id="S6.T6.1.1.12.12.5.1" style="background-color:#E6E6E6;">53.2</span></td>
<td class="ltx_td ltx_align_center" id="S6.T6.1.1.12.12.6"><span class="ltx_text ltx_font_bold" id="S6.T6.1.1.12.12.6.1" style="background-color:#E6E6E6;">59.0</span></td>
<td class="ltx_td ltx_align_center" id="S6.T6.1.1.12.12.7"><span class="ltx_text ltx_font_bold" id="S6.T6.1.1.12.12.7.1" style="background-color:#E6E6E6;">64.2</span></td>
<td class="ltx_td ltx_align_center" id="S6.T6.1.1.12.12.8"><span class="ltx_text ltx_font_bold" id="S6.T6.1.1.12.12.8.1" style="background-color:#E6E6E6;">60.8</span></td>
<td class="ltx_td ltx_align_center" id="S6.T6.1.1.12.12.9"><span class="ltx_text ltx_font_bold" id="S6.T6.1.1.12.12.9.1" style="background-color:#E6E6E6;">38.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S6.T6.1.1.12.12.10"><span class="ltx_text ltx_font_bold" id="S6.T6.1.1.12.12.10.1" style="background-color:#E6E6E6;">60.3</span></td>
<td class="ltx_td ltx_align_center" id="S6.T6.1.1.12.12.11"><span class="ltx_text ltx_font_bold" id="S6.T6.1.1.12.12.11.1" style="background-color:#E6E6E6;">57.5</span></td>
</tr>
<tr class="ltx_tr" id="S6.T6.1.1.13.13">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="11" id="S6.T6.1.1.13.13.1"><span class="ltx_text ltx_font_bold" id="S6.T6.1.1.13.13.1.1">20B+ Models</span></th>
</tr>
<tr class="ltx_tr" id="S6.T6.1.1.14.14">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="S6.T6.1.1.14.14.1"><span class="ltx_text" id="S6.T6.1.1.14.14.1.1" style="color:#999999;">DS-Coder-33B-Base</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t" id="S6.T6.1.1.14.14.2"><span class="ltx_text" id="S6.T6.1.1.14.14.2.1" style="color:#999999;">33B</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S6.T6.1.1.14.14.3"><span class="ltx_text" id="S6.T6.1.1.14.14.3.1" style="color:#999999;">56.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S6.T6.1.1.14.14.4"><span class="ltx_text" id="S6.T6.1.1.14.14.4.1" style="color:#999999;">58.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S6.T6.1.1.14.14.5"><span class="ltx_text" id="S6.T6.1.1.14.14.5.1" style="color:#999999;">51.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S6.T6.1.1.14.14.6"><span class="ltx_text" id="S6.T6.1.1.14.14.6.1" style="color:#999999;">44.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S6.T6.1.1.14.14.7"><span class="ltx_text" id="S6.T6.1.1.14.14.7.1" style="color:#999999;">52.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S6.T6.1.1.14.14.8"><span class="ltx_text" id="S6.T6.1.1.14.14.8.1" style="color:#999999;">51.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S6.T6.1.1.14.14.9"><span class="ltx_text" id="S6.T6.1.1.14.14.9.1" style="color:#999999;">32.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S6.T6.1.1.14.14.10"><span class="ltx_text" id="S6.T6.1.1.14.14.10.1" style="color:#999999;">55.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S6.T6.1.1.14.14.11"><span class="ltx_text" id="S6.T6.1.1.14.14.11.1" style="color:#999999;">50.3</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6: </span>Performance of different models on MultiPL-E.</figcaption>
</figure>
<section class="ltx_paragraph" id="S6.SS1.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">HumanEval and MBPP</h5>
<div class="ltx_para ltx_noindent" id="S6.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="S6.SS1.SSS0.Px1.p1.1">Code generation serves as a fundamental capability for code models to handle more complex tasks. We selected two popular code generation benchmarks to evaluate Qwen2.5-Coder, namely HumanEval <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#bib.bib12" title="">2021</a>)</cite> and MBPP <cite class="ltx_cite ltx_citemacro_citep">(Austin et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#bib.bib4" title="">2021</a>)</cite>. HumanEval consists of 164 manually written programming tasks, each providing a Python function signature and a docstring as input to the model. MBPP, on the other hand, comprises 974 programming problems created by crowdsource contributors. Each problem includes a problem statement (i.e., a docstring), a function signature, and three test cases.</p>
</div>
<div class="ltx_para ltx_noindent" id="S6.SS1.SSS0.Px1.p2">
<p class="ltx_p" id="S6.SS1.SSS0.Px1.p2.1">To further ensure accurate evaluation, EvalPlus <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#bib.bib27" title="">2023</a>)</cite> extends HumanEval into HumanEval+ by adding 80 times more unique test cases and correcting inaccurate ground-truth solutions in HumanEval. Similarly, MBPP+ offers 35 times more test cases than the original MBPP.</p>
</div>
<div class="ltx_para ltx_noindent" id="S6.SS1.SSS0.Px1.p3">
<p class="ltx_p" id="S6.SS1.SSS0.Px1.p3.1">Additionally, we should notice that MBPP 3-shot is particularly suitable for monitoring model convergence during training. Early in the convergence process, the model tends to be unstable, causing significant fluctuation in metrics, and simple 3-shot examples effectively mitigate it. Therefore, we also report the results of MBPP 3-shot performance.</p>
</div>
<div class="ltx_para ltx_noindent" id="S6.SS1.SSS0.Px1.p4">
<p class="ltx_p" id="S6.SS1.SSS0.Px1.p4.1">As shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S6.T5" title="Table 5 ‣ 6.1 Code Generation ‣ 6 Evaluation on Base Models ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_tag">5</span></a>, Qwen2.5-Coder have shown impressive performance in basic code generation, achieving state-of-the-art results among open-source models of the same size and surpassing even larger models. In particular, Qwen2.5-Coder-7B-Base outperforms the previous best dense model, DS-Coder-33B-Base, across all five metrics.</p>
</div>
</section>
<section class="ltx_paragraph" id="S6.SS1.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">BigCodeBench-Complete</h5>
<div class="ltx_para ltx_noindent" id="S6.SS1.SSS0.Px2.p1">
<p class="ltx_p" id="S6.SS1.SSS0.Px2.p1.1">BigCodeBench <cite class="ltx_cite ltx_citemacro_citep">(Zhuo et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#bib.bib39" title="">2024</a>)</cite> is a recent and more challenging benchmark for code generation, primarily aimed at evaluating the ability of tool-use and complex instruction following. The base model generates the expected code through a completion mode, given a function signature and documentation, which is referred to as BigCodeBench-Complete. It consists of two subsets: the full set and the hard set. Compared to HumanEval and MBPP, BigCodeBench is suited for out-of-distribution (OOD) evaluation.</p>
</div>
<div class="ltx_para ltx_noindent" id="S6.SS1.SSS0.Px2.p2">
<p class="ltx_p" id="S6.SS1.SSS0.Px2.p2.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S6.T5" title="Table 5 ‣ 6.1 Code Generation ‣ 6 Evaluation on Base Models ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_tag">5</span></a> illustrates that Qwen2.5-Coder continues to show strong performance on BigCodeBench-Complete, underscoring the model’s generalization potential.</p>
</div>
</section>
<section class="ltx_paragraph" id="S6.SS1.SSS0.Px3">
<h5 class="ltx_title ltx_title_paragraph">Multi-Programming Language</h5>
<div class="ltx_para ltx_noindent" id="S6.SS1.SSS0.Px3.p1">
<p class="ltx_p" id="S6.SS1.SSS0.Px3.p1.1">The evaluations mentioned above focus on the Python language. However, we expect a strong code model to be not only proficient in Python but also versatile across multiple programming languages to meet the complex and evolving demands of software development. To more comprehensively evaluate Qwen2.5-Coder’s proficiency in handling multiple programming languages, we selected the MultiPL-E <cite class="ltx_cite ltx_citemacro_citep">(Cassano et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#bib.bib9" title="">2022</a>)</cite> and choose to evaluate eight mainstream languages from these benchmark, including Python, C++, Java, PHP, TypeScript, C#, Bash and JavaScript.</p>
</div>
<div class="ltx_para ltx_noindent" id="S6.SS1.SSS0.Px3.p2">
<p class="ltx_p" id="S6.SS1.SSS0.Px3.p2.1">As shown in the table <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S6.T6" title="Table 6 ‣ 6.1 Code Generation ‣ 6 Evaluation on Base Models ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_tag">6</span></a>, Qwen2.5-Coder also achieved state-of-the-art results in the multi-programming language evaluation, with its capabilities well-balanced across various languages. It scored over 60% in five out of the eight languages.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S6.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2 </span>Code Completion</h3>
<section class="ltx_paragraph" id="S6.SS2.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">HumanEval Infilling</h5>
<div class="ltx_para ltx_noindent" id="S6.SS2.SSS0.Px1.p1">
<p class="ltx_p" id="S6.SS2.SSS0.Px1.p1.1">Many developer aid tools rely on the capability to autocomplete code based on preceding and succeeding code snippets. Qwen2.5-Coder utilizes the Fill-In-the-Middle (FIM) training strategy, as introduced in <cite class="ltx_cite ltx_citemacro_cite">Bavarian et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#bib.bib7" title="">2022</a>)</cite>, enabling the model to generate code that is contextually coherent. To assess its code completion proficiency, we utilize the HumanEval Infilling benchmark <cite class="ltx_cite ltx_citemacro_cite">Allal et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#bib.bib2" title="">2023</a>)</cite>. This benchmark challenges the model to accurately predict missing sections of code within tasks derived from HumanEval.
We use the single-line infilling settings across Python, Java, and JavaScript, focusing on predicting a single line of code within given contexts. Performance was measured using the Exact Match metric, which determines the proportion of the first generated code line that precisely match the ground truth.</p>
</div>
<div class="ltx_para ltx_noindent" id="S6.SS2.SSS0.Px1.p2">
<p class="ltx_p" id="S6.SS2.SSS0.Px1.p2.1">The table <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S6.T7" title="Table 7 ‣ HumanEval Infilling ‣ 6.2 Code Completion ‣ 6 Evaluation on Base Models ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_tag">7</span></a> illustrates that Qwen2.5-Coder surpasses alternative models concerning model size. Specifically, <span class="ltx_text ltx_font_bold" id="S6.SS2.SSS0.Px1.p2.1.1">Qwen2.5-Coder-1.5B</span> achieves an average performance improvement of 3.7%, rivaling the majority of models exceeding 6 billion parameters. Moreover, <span class="ltx_text ltx_font_bold" id="S6.SS2.SSS0.Px1.p2.1.2">Qwen2.5-Coder-7B-Base</span> stands as the leading model among those over 6 billion parameters, matching the performance of the formidable 33 billion parameter model, DS-Coder-33B-Base. Notably, we excluded DS-Coder-v2-236B from comparison due to its design focus not being on code completion tasks.</p>
</div>
<figure class="ltx_table" id="S6.T7">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S6.T7.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S6.T7.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="S6.T7.1.1.1.1" rowspan="2"><span class="ltx_text ltx_font_bold" id="S6.T7.1.1.1.1.1">Model</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_tt" id="S6.T7.1.1.1.2" rowspan="2"><span class="ltx_text ltx_font_bold" id="S6.T7.1.1.1.2.1">Size</span></th>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="4" id="S6.T7.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S6.T7.1.1.1.3.1">HumanEval-Infilling</span></td>
</tr>
<tr class="ltx_tr" id="S6.T7.1.2.2">
<td class="ltx_td ltx_align_center" id="S6.T7.1.2.2.1"><span class="ltx_text ltx_font_italic" id="S6.T7.1.2.2.1.1">Python</span></td>
<td class="ltx_td ltx_align_center" id="S6.T7.1.2.2.2"><span class="ltx_text ltx_font_italic" id="S6.T7.1.2.2.2.1">Java</span></td>
<td class="ltx_td ltx_align_center" id="S6.T7.1.2.2.3"><span class="ltx_text ltx_font_italic" id="S6.T7.1.2.2.3.1">JavaScript</span></td>
<td class="ltx_td ltx_align_center" id="S6.T7.1.2.2.4"><span class="ltx_text ltx_font_italic" id="S6.T7.1.2.2.4.1">Average</span></td>
</tr>
<tr class="ltx_tr" id="S6.T7.1.3.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="6" id="S6.T7.1.3.3.1"><span class="ltx_text ltx_font_bold" id="S6.T7.1.3.3.1.1">1B+ Models</span></th>
</tr>
<tr class="ltx_tr" id="S6.T7.1.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S6.T7.1.4.4.1">StarCoder2-3B</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S6.T7.1.4.4.2">3B</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T7.1.4.4.3">70.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T7.1.4.4.4">84.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T7.1.4.4.5">81.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T7.1.4.4.6">79.0</td>
</tr>
<tr class="ltx_tr" id="S6.T7.1.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T7.1.5.5.1">DS-Coder-1.3B-Base</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S6.T7.1.5.5.2">1.3B</th>
<td class="ltx_td ltx_align_center" id="S6.T7.1.5.5.3">72.8</td>
<td class="ltx_td ltx_align_center" id="S6.T7.1.5.5.4">84.3</td>
<td class="ltx_td ltx_align_center" id="S6.T7.1.5.5.5">81.7</td>
<td class="ltx_td ltx_align_center" id="S6.T7.1.5.5.6">79.6</td>
</tr>
<tr class="ltx_tr" id="S6.T7.1.6.6" style="background-color:#E6E6E6;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T7.1.6.6.1"><span class="ltx_text ltx_font_bold" id="S6.T7.1.6.6.1.1" style="background-color:#E6E6E6;">Qwen2.5-Coder-1.5B</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S6.T7.1.6.6.2"><span class="ltx_text" id="S6.T7.1.6.6.2.1" style="background-color:#E6E6E6;">1.5B</span></th>
<td class="ltx_td ltx_align_center" id="S6.T7.1.6.6.3"><span class="ltx_text ltx_font_bold" id="S6.T7.1.6.6.3.1" style="background-color:#E6E6E6;">77.0</span></td>
<td class="ltx_td ltx_align_center" id="S6.T7.1.6.6.4"><span class="ltx_text ltx_font_bold" id="S6.T7.1.6.6.4.1" style="background-color:#E6E6E6;">85.6</span></td>
<td class="ltx_td ltx_align_center" id="S6.T7.1.6.6.5"><span class="ltx_text ltx_font_bold" id="S6.T7.1.6.6.5.1" style="background-color:#E6E6E6;">85.0</span></td>
<td class="ltx_td ltx_align_center" id="S6.T7.1.6.6.6"><span class="ltx_text ltx_font_bold" id="S6.T7.1.6.6.6.1" style="background-color:#E6E6E6;">82.5</span></td>
</tr>
<tr class="ltx_tr" id="S6.T7.1.7.7">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="6" id="S6.T7.1.7.7.1"><span class="ltx_text ltx_font_bold" id="S6.T7.1.7.7.1.1">6B+ Models</span></th>
</tr>
<tr class="ltx_tr" id="S6.T7.1.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S6.T7.1.8.8.1">StarCoder2-7B</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S6.T7.1.8.8.2">7B</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T7.1.8.8.3">70.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T7.1.8.8.4">86.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T7.1.8.8.5">84.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T7.1.8.8.6">80.4</td>
</tr>
<tr class="ltx_tr" id="S6.T7.1.9.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T7.1.9.9.1">StarCoder2-15B</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S6.T7.1.9.9.2">15B</th>
<td class="ltx_td ltx_align_center" id="S6.T7.1.9.9.3">78.1</td>
<td class="ltx_td ltx_align_center" id="S6.T7.1.9.9.4">87.4</td>
<td class="ltx_td ltx_align_center" id="S6.T7.1.9.9.5">84.1</td>
<td class="ltx_td ltx_align_center" id="S6.T7.1.9.9.6">81.3</td>
</tr>
<tr class="ltx_tr" id="S6.T7.1.10.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T7.1.10.10.1">DS-Coder-6.7B-Base</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S6.T7.1.10.10.2">6.7B</th>
<td class="ltx_td ltx_align_center" id="S6.T7.1.10.10.3">78.1</td>
<td class="ltx_td ltx_align_center" id="S6.T7.1.10.10.4">87.4</td>
<td class="ltx_td ltx_align_center" id="S6.T7.1.10.10.5">84.1</td>
<td class="ltx_td ltx_align_center" id="S6.T7.1.10.10.6">83.2</td>
</tr>
<tr class="ltx_tr" id="S6.T7.1.11.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T7.1.11.11.1">DS-Coder-V2-Lite-Base</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S6.T7.1.11.11.2">2.4/16B</th>
<td class="ltx_td ltx_align_center" id="S6.T7.1.11.11.3">78.7</td>
<td class="ltx_td ltx_align_center" id="S6.T7.1.11.11.4">87.8</td>
<td class="ltx_td ltx_align_center" id="S6.T7.1.11.11.5">85.9</td>
<td class="ltx_td ltx_align_center" id="S6.T7.1.11.11.6">84.1</td>
</tr>
<tr class="ltx_tr" id="S6.T7.1.12.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T7.1.12.12.1">CodeQwen1.5-7B-Base</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S6.T7.1.12.12.2">7B</th>
<td class="ltx_td ltx_align_center" id="S6.T7.1.12.12.3">75.8</td>
<td class="ltx_td ltx_align_center" id="S6.T7.1.12.12.4">85.7</td>
<td class="ltx_td ltx_align_center" id="S6.T7.1.12.12.5">85.0</td>
<td class="ltx_td ltx_align_center" id="S6.T7.1.12.12.6">82.2</td>
</tr>
<tr class="ltx_tr" id="S6.T7.1.13.13" style="background-color:#E6E6E6;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T7.1.13.13.1"><span class="ltx_text ltx_font_bold" id="S6.T7.1.13.13.1.1" style="background-color:#E6E6E6;">Qwen2.5-Coder-7B-Base</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S6.T7.1.13.13.2"><span class="ltx_text" id="S6.T7.1.13.13.2.1" style="background-color:#E6E6E6;">7B</span></th>
<td class="ltx_td ltx_align_center" id="S6.T7.1.13.13.3"><span class="ltx_text ltx_font_bold" id="S6.T7.1.13.13.3.1" style="background-color:#E6E6E6;">79.7</span></td>
<td class="ltx_td ltx_align_center" id="S6.T7.1.13.13.4"><span class="ltx_text ltx_font_bold" id="S6.T7.1.13.13.4.1" style="background-color:#E6E6E6;">88.5</span></td>
<td class="ltx_td ltx_align_center" id="S6.T7.1.13.13.5"><span class="ltx_text ltx_font_bold" id="S6.T7.1.13.13.5.1" style="background-color:#E6E6E6;">87.6</span></td>
<td class="ltx_td ltx_align_center" id="S6.T7.1.13.13.6"><span class="ltx_text ltx_font_bold" id="S6.T7.1.13.13.6.1" style="background-color:#E6E6E6;">85.3</span></td>
</tr>
<tr class="ltx_tr" id="S6.T7.1.14.14">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="6" id="S6.T7.1.14.14.1"><span class="ltx_text ltx_font_bold" id="S6.T7.1.14.14.1.1">20B+ Models</span></th>
</tr>
<tr class="ltx_tr" id="S6.T7.1.15.15">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="S6.T7.1.15.15.1"><span class="ltx_text" id="S6.T7.1.15.15.1.1" style="color:#999999;">DS-Coder-33B-Base</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t" id="S6.T7.1.15.15.2"><span class="ltx_text" id="S6.T7.1.15.15.2.1" style="color:#999999;">33B</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S6.T7.1.15.15.3"><span class="ltx_text" id="S6.T7.1.15.15.3.1" style="color:#999999;">80.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S6.T7.1.15.15.4"><span class="ltx_text" id="S6.T7.1.15.15.4.1" style="color:#999999;">89.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S6.T7.1.15.15.5"><span class="ltx_text" id="S6.T7.1.15.15.5.1" style="color:#999999;">86.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S6.T7.1.15.15.6"><span class="ltx_text" id="S6.T7.1.15.15.6.1" style="color:#999999;">85.3</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 7: </span>Performance of different approaches on the HumanEval Infilling Tasks</figcaption>
</figure>
</section>
</section>
<section class="ltx_subsection" id="S6.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.3 </span>Code Reasoning</h3>
<div class="ltx_para ltx_noindent" id="S6.SS3.p1">
<p class="ltx_p" id="S6.SS3.p1.1">Code is a highly abstract form of logical language, and reasoning based on code helps us determine whether a model truly understands the reasoning flow behind the code. We selected CRUXEval <cite class="ltx_cite ltx_citemacro_citep">(Gu et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#bib.bib18" title="">2024</a>)</cite> as the benchmark, which includes 800 Python functions along with corresponding input-output examples. It consists of two distinct tasks: CRUXEval-I, where the large language model (LLM) must predict the output based on a given input; and CRUXEval-O, where the model must predict the input based on a known output. For both CRUXEval-I and CRUXEval-O, we used a chain-of-thought (CoT) approach, requiring the LLM to output steps sequentially during simulated execution.</p>
</div>
<div class="ltx_para ltx_noindent" id="S6.SS3.p2">
<p class="ltx_p" id="S6.SS3.p2.1">As shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S6.T8" title="Table 8 ‣ 6.3 Code Reasoning ‣ 6 Evaluation on Base Models ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_tag">8</span></a>, Qwen2.5-Coder delivered highly promising results, achieving a score of 56.5 on CRUXEval-I and 56.0 on CRUXEval-O, thanks to our focus on executable quality during the code cleaning process.</p>
</div>
<figure class="ltx_table" id="S6.T8">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S6.T8.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S6.T8.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="S6.T8.1.1.1.1" rowspan="2"><span class="ltx_text ltx_font_bold" id="S6.T8.1.1.1.1.1">Model</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_tt" id="S6.T8.1.1.1.2" rowspan="2"><span class="ltx_text ltx_font_bold" id="S6.T8.1.1.1.2.1">Size</span></th>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S6.T8.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S6.T8.1.1.1.3.1">CRUXEval</span></td>
</tr>
<tr class="ltx_tr" id="S6.T8.1.2.2">
<td class="ltx_td ltx_align_center" id="S6.T8.1.2.2.1"><span class="ltx_text ltx_font_italic" id="S6.T8.1.2.2.1.1">Input-CoT</span></td>
<td class="ltx_td ltx_align_center" id="S6.T8.1.2.2.2"><span class="ltx_text ltx_font_italic" id="S6.T8.1.2.2.2.1">Output-CoT</span></td>
</tr>
<tr class="ltx_tr" id="S6.T8.1.3.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="4" id="S6.T8.1.3.3.1"><span class="ltx_text ltx_font_bold" id="S6.T8.1.3.3.1.1">1B+ Models</span></th>
</tr>
<tr class="ltx_tr" id="S6.T8.1.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S6.T8.1.4.4.1">StarCoder2-3B</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S6.T8.1.4.4.2">3B</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T8.1.4.4.3">42.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T8.1.4.4.4">29.2</td>
</tr>
<tr class="ltx_tr" id="S6.T8.1.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T8.1.5.5.1">DS-Coder-1.3B-Base</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S6.T8.1.5.5.2">1.3B</th>
<td class="ltx_td ltx_align_center" id="S6.T8.1.5.5.3">32.1</td>
<td class="ltx_td ltx_align_center" id="S6.T8.1.5.5.4">28.2</td>
</tr>
<tr class="ltx_tr" id="S6.T8.1.6.6" style="background-color:#E6E6E6;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T8.1.6.6.1"><span class="ltx_text ltx_font_bold" id="S6.T8.1.6.6.1.1" style="background-color:#E6E6E6;">Qwen2.5-Coder-1.5B</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S6.T8.1.6.6.2"><span class="ltx_text" id="S6.T8.1.6.6.2.1" style="background-color:#E6E6E6;">1.5B</span></th>
<td class="ltx_td ltx_align_center" id="S6.T8.1.6.6.3"><span class="ltx_text ltx_font_bold" id="S6.T8.1.6.6.3.1" style="background-color:#E6E6E6;">43.8</span></td>
<td class="ltx_td ltx_align_center" id="S6.T8.1.6.6.4"><span class="ltx_text ltx_font_bold" id="S6.T8.1.6.6.4.1" style="background-color:#E6E6E6;">34.6</span></td>
</tr>
<tr class="ltx_tr" id="S6.T8.1.7.7">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="4" id="S6.T8.1.7.7.1"><span class="ltx_text ltx_font_bold" id="S6.T8.1.7.7.1.1">6B+ Models</span></th>
</tr>
<tr class="ltx_tr" id="S6.T8.1.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S6.T8.1.8.8.1">StarCoder2-7B</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S6.T8.1.8.8.2">7B</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T8.1.8.8.3">39.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T8.1.8.8.4">35.1</td>
</tr>
<tr class="ltx_tr" id="S6.T8.1.9.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T8.1.9.9.1">StarCoder2-15B</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S6.T8.1.9.9.2">15B</th>
<td class="ltx_td ltx_align_center" id="S6.T8.1.9.9.3">46.1</td>
<td class="ltx_td ltx_align_center" id="S6.T8.1.9.9.4">47.6</td>
</tr>
<tr class="ltx_tr" id="S6.T8.1.10.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T8.1.10.10.1">DS-Coder-6.7B-Base</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S6.T8.1.10.10.2">6.7B</th>
<td class="ltx_td ltx_align_center" id="S6.T8.1.10.10.3">39.0</td>
<td class="ltx_td ltx_align_center" id="S6.T8.1.10.10.4">41.0</td>
</tr>
<tr class="ltx_tr" id="S6.T8.1.11.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T8.1.11.11.1">DS-Coder-V2-Lite-Base</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S6.T8.1.11.11.2">2.4/16B</th>
<td class="ltx_td ltx_align_center" id="S6.T8.1.11.11.3">53.4</td>
<td class="ltx_td ltx_align_center" id="S6.T8.1.11.11.4">46.1</td>
</tr>
<tr class="ltx_tr" id="S6.T8.1.12.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T8.1.12.12.1">CodeQwen1.5-7B-Base</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S6.T8.1.12.12.2">7B</th>
<td class="ltx_td ltx_align_center" id="S6.T8.1.12.12.3">44.8</td>
<td class="ltx_td ltx_align_center" id="S6.T8.1.12.12.4">40.1</td>
</tr>
<tr class="ltx_tr" id="S6.T8.1.13.13" style="background-color:#E6E6E6;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T8.1.13.13.1"><span class="ltx_text ltx_font_bold" id="S6.T8.1.13.13.1.1" style="background-color:#E6E6E6;">Qwen2.5-Coder-7B-Base</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S6.T8.1.13.13.2"><span class="ltx_text" id="S6.T8.1.13.13.2.1" style="background-color:#E6E6E6;">7B</span></th>
<td class="ltx_td ltx_align_center" id="S6.T8.1.13.13.3"><span class="ltx_text ltx_font_bold" id="S6.T8.1.13.13.3.1" style="background-color:#E6E6E6;">56.5</span></td>
<td class="ltx_td ltx_align_center" id="S6.T8.1.13.13.4"><span class="ltx_text ltx_font_bold" id="S6.T8.1.13.13.4.1" style="background-color:#E6E6E6;">56.0</span></td>
</tr>
<tr class="ltx_tr" id="S6.T8.1.14.14">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="4" id="S6.T8.1.14.14.1"><span class="ltx_text ltx_font_bold" id="S6.T8.1.14.14.1.1">20B+ Models</span></th>
</tr>
<tr class="ltx_tr" id="S6.T8.1.15.15">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S6.T8.1.15.15.1"><span class="ltx_text" id="S6.T8.1.15.15.1.1" style="color:#999999;">DS-Coder-33B-Base</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S6.T8.1.15.15.2"><span class="ltx_text" id="S6.T8.1.15.15.2.1" style="color:#999999;">33B</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T8.1.15.15.3"><span class="ltx_text" id="S6.T8.1.15.15.3.1" style="color:#999999;">50.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T8.1.15.15.4"><span class="ltx_text" id="S6.T8.1.15.15.4.1" style="color:#999999;">48.8</span></td>
</tr>
<tr class="ltx_tr" id="S6.T8.1.16.16">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S6.T8.1.16.16.1"><span class="ltx_text" id="S6.T8.1.16.16.1.1" style="color:#999999;">DS-Coder-V2-Base</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S6.T8.1.16.16.2"><span class="ltx_text" id="S6.T8.1.16.16.2.1" style="color:#999999;">21/236B</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T8.1.16.16.3"><span class="ltx_text" id="S6.T8.1.16.16.3.1" style="color:#999999;">62.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T8.1.16.16.4"><span class="ltx_text" id="S6.T8.1.16.16.4.1" style="color:#999999;">67.4</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 8: </span>Performance of different models on CRUXEval with <span class="ltx_text ltx_font_italic" id="S6.T8.4.1">Input-CoT</span> and <span class="ltx_text ltx_font_italic" id="S6.T8.5.2">Output-CoT</span> settings.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S6.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.4 </span>Math Reasoning</h3>
<div class="ltx_para ltx_noindent" id="S6.SS4.p1">
<p class="ltx_p" id="S6.SS4.p1.1">Mathematics and coding have always been closely intertwined. Mathematics forms the foundational discipline for coding, while coding serves as a vital tool in mathematical fields. As such, we expect an open and powerful code model to exhibit strong mathematical capabilities as well. To assess Qwen2.5-Coder’s mathematical performance, we selected five popular benchmarks, including MATH <cite class="ltx_cite ltx_citemacro_citep">(Hendrycks et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#bib.bib21" title="">2021</a>)</cite>, GSM8K <cite class="ltx_cite ltx_citemacro_citep">(Cobbe et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#bib.bib15" title="">2021</a>)</cite>, MMLU-STEM <cite class="ltx_cite ltx_citemacro_citep">(Hendrycks et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#bib.bib20" title="">2020</a>)</cite> and TheoremQA <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#bib.bib13" title="">2023</a>)</cite>. As shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S6.T9" title="Table 9 ‣ 6.4 Math Reasoning ‣ 6 Evaluation on Base Models ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_tag">9</span></a>, Table 3 highlights Qwen2.5-Coder’s strengths in mathematics, which likely stem from two key factors: first, the model’s strong foundation built on Qwen2.5, and second, the careful mixing of code and mathematical data during training, which has ensured a well-balanced performance across these domains.</p>
</div>
<figure class="ltx_table" id="S6.T9">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S6.T9.1" style="width:397.5pt;height:268.7pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-1.7pt,1.2pt) scale(0.991404440681233,0.991404440681233) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S6.T9.1.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S6.T9.1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="S6.T9.1.1.1.1.1" rowspan="2"><span class="ltx_text ltx_font_bold" id="S6.T9.1.1.1.1.1.1">Model</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_tt" id="S6.T9.1.1.1.1.2" rowspan="2"><span class="ltx_text ltx_font_bold" id="S6.T9.1.1.1.1.2.1">Size</span></th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S6.T9.1.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S6.T9.1.1.1.1.3.1">MATH</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S6.T9.1.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S6.T9.1.1.1.1.4.1">GSM8K</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S6.T9.1.1.1.1.5"><span class="ltx_text ltx_font_bold" id="S6.T9.1.1.1.1.5.1">MMLU STEM</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S6.T9.1.1.1.1.6"><span class="ltx_text ltx_font_bold" id="S6.T9.1.1.1.1.6.1">TheoremQA</span></td>
</tr>
<tr class="ltx_tr" id="S6.T9.1.1.2.2">
<td class="ltx_td ltx_align_center" id="S6.T9.1.1.2.2.1"><span class="ltx_text ltx_font_italic" id="S6.T9.1.1.2.2.1.1">4-shot</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.1.1.2.2.2"><span class="ltx_text ltx_font_italic" id="S6.T9.1.1.2.2.2.1">4-shot</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.1.1.2.2.3"><span class="ltx_text ltx_font_italic" id="S6.T9.1.1.2.2.3.1">5-shot</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.1.1.2.2.4"><span class="ltx_text ltx_font_italic" id="S6.T9.1.1.2.2.4.1">5-shot</span></td>
</tr>
<tr class="ltx_tr" id="S6.T9.1.1.3.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="6" id="S6.T9.1.1.3.3.1"><span class="ltx_text ltx_font_bold" id="S6.T9.1.1.3.3.1.1">1B+ Models</span></th>
</tr>
<tr class="ltx_tr" id="S6.T9.1.1.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S6.T9.1.1.4.4.1">StarCoder2-3B</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S6.T9.1.1.4.4.2">3B</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T9.1.1.4.4.3">10.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T9.1.1.4.4.4">21.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T9.1.1.4.4.5">34.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T9.1.1.4.4.6">12.1</td>
</tr>
<tr class="ltx_tr" id="S6.T9.1.1.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T9.1.1.5.5.1">DS-Coder-1.3B-Base</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S6.T9.1.1.5.5.2">1.3B</th>
<td class="ltx_td ltx_align_center" id="S6.T9.1.1.5.5.3">4.6</td>
<td class="ltx_td ltx_align_center" id="S6.T9.1.1.5.5.4">4.4</td>
<td class="ltx_td ltx_align_center" id="S6.T9.1.1.5.5.5">24.5</td>
<td class="ltx_td ltx_align_center" id="S6.T9.1.1.5.5.6">8.9</td>
</tr>
<tr class="ltx_tr" id="S6.T9.1.1.6.6" style="background-color:#E6E6E6;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T9.1.1.6.6.1"><span class="ltx_text ltx_font_bold" id="S6.T9.1.1.6.6.1.1" style="background-color:#E6E6E6;">Qwen2.5-Coder-1.5B</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S6.T9.1.1.6.6.2"><span class="ltx_text" id="S6.T9.1.1.6.6.2.1" style="background-color:#E6E6E6;">1.5B</span></th>
<td class="ltx_td ltx_align_center" id="S6.T9.1.1.6.6.3"><span class="ltx_text ltx_font_bold" id="S6.T9.1.1.6.6.3.1" style="background-color:#E6E6E6;">30.9</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.1.1.6.6.4"><span class="ltx_text ltx_font_bold" id="S6.T9.1.1.6.6.4.1" style="background-color:#E6E6E6;">65.8</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.1.1.6.6.5"><span class="ltx_text ltx_font_bold" id="S6.T9.1.1.6.6.5.1" style="background-color:#E6E6E6;">49.0</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.1.1.6.6.6"><span class="ltx_text ltx_font_bold" id="S6.T9.1.1.6.6.6.1" style="background-color:#E6E6E6;">21.4</span></td>
</tr>
<tr class="ltx_tr" id="S6.T9.1.1.7.7">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="6" id="S6.T9.1.1.7.7.1"><span class="ltx_text ltx_font_bold" id="S6.T9.1.1.7.7.1.1">6B+ Models</span></th>
</tr>
<tr class="ltx_tr" id="S6.T9.1.1.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S6.T9.1.1.8.8.1">StarCoder2-7B</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S6.T9.1.1.8.8.2">7B</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T9.1.1.8.8.3">14.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T9.1.1.8.8.4">32.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T9.1.1.8.8.5">39.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T9.1.1.8.8.6">16.0</td>
</tr>
<tr class="ltx_tr" id="S6.T9.1.1.9.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T9.1.1.9.9.1">StarCoder2-15B</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S6.T9.1.1.9.9.2">15B</th>
<td class="ltx_td ltx_align_center" id="S6.T9.1.1.9.9.3">23.7</td>
<td class="ltx_td ltx_align_center" id="S6.T9.1.1.9.9.4">57.7</td>
<td class="ltx_td ltx_align_center" id="S6.T9.1.1.9.9.5">49.2</td>
<td class="ltx_td ltx_align_center" id="S6.T9.1.1.9.9.6">20.5</td>
</tr>
<tr class="ltx_tr" id="S6.T9.1.1.10.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T9.1.1.10.10.1">DS-Coder-6.7B-Base</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S6.T9.1.1.10.10.2">6.7B</th>
<td class="ltx_td ltx_align_center" id="S6.T9.1.1.10.10.3">10.3</td>
<td class="ltx_td ltx_align_center" id="S6.T9.1.1.10.10.4">21.3</td>
<td class="ltx_td ltx_align_center" id="S6.T9.1.1.10.10.5">34.2</td>
<td class="ltx_td ltx_align_center" id="S6.T9.1.1.10.10.6">13.6</td>
</tr>
<tr class="ltx_tr" id="S6.T9.1.1.11.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T9.1.1.11.11.1">DS-Coder-V2-Lite-Base</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S6.T9.1.1.11.11.2">2.4/16B</th>
<td class="ltx_td ltx_align_center" id="S6.T9.1.1.11.11.3">39.0</td>
<td class="ltx_td ltx_align_center" id="S6.T9.1.1.11.11.4">67.1</td>
<td class="ltx_td ltx_align_center" id="S6.T9.1.1.11.11.5">58.5</td>
<td class="ltx_td ltx_align_center" id="S6.T9.1.1.11.11.6">29.3</td>
</tr>
<tr class="ltx_tr" id="S6.T9.1.1.12.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T9.1.1.12.12.1">CodeQwen1.5-7B-Base</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S6.T9.1.1.12.12.2">7B</th>
<td class="ltx_td ltx_align_center" id="S6.T9.1.1.12.12.3">10.6</td>
<td class="ltx_td ltx_align_center" id="S6.T9.1.1.12.12.4">37.7</td>
<td class="ltx_td ltx_align_center" id="S6.T9.1.1.12.12.5">39.6</td>
<td class="ltx_td ltx_align_center" id="S6.T9.1.1.12.12.6">15.8</td>
</tr>
<tr class="ltx_tr" id="S6.T9.1.1.13.13" style="background-color:#E6E6E6;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T9.1.1.13.13.1"><span class="ltx_text ltx_font_bold" id="S6.T9.1.1.13.13.1.1" style="background-color:#E6E6E6;">Qwen2.5-Coder-7B-Base</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S6.T9.1.1.13.13.2"><span class="ltx_text" id="S6.T9.1.1.13.13.2.1" style="background-color:#E6E6E6;">7B</span></th>
<td class="ltx_td ltx_align_center" id="S6.T9.1.1.13.13.3"><span class="ltx_text ltx_font_bold" id="S6.T9.1.1.13.13.3.1" style="background-color:#E6E6E6;">46.6</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.1.1.13.13.4"><span class="ltx_text ltx_font_bold" id="S6.T9.1.1.13.13.4.1" style="background-color:#E6E6E6;">83.9</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.1.1.13.13.5"><span class="ltx_text ltx_font_bold" id="S6.T9.1.1.13.13.5.1" style="background-color:#E6E6E6;">67.6</span></td>
<td class="ltx_td ltx_align_center" id="S6.T9.1.1.13.13.6"><span class="ltx_text ltx_font_bold" id="S6.T9.1.1.13.13.6.1" style="background-color:#E6E6E6;">34.0</span></td>
</tr>
<tr class="ltx_tr" id="S6.T9.1.1.14.14">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="6" id="S6.T9.1.1.14.14.1"><span class="ltx_text ltx_font_bold" id="S6.T9.1.1.14.14.1.1">20B+ Models</span></th>
</tr>
<tr class="ltx_tr" id="S6.T9.1.1.15.15">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="S6.T9.1.1.15.15.1"><span class="ltx_text" id="S6.T9.1.1.15.15.1.1" style="color:#999999;">DS-Coder-33B-Base</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t" id="S6.T9.1.1.15.15.2"><span class="ltx_text" id="S6.T9.1.1.15.15.2.1" style="color:#999999;">33B</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S6.T9.1.1.15.15.3"><span class="ltx_text" id="S6.T9.1.1.15.15.3.1" style="color:#999999;">14.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S6.T9.1.1.15.15.4"><span class="ltx_text" id="S6.T9.1.1.15.15.4.1" style="color:#999999;">35.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S6.T9.1.1.15.15.5"><span class="ltx_text" id="S6.T9.1.1.15.15.5.1" style="color:#999999;">39.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S6.T9.1.1.15.15.6"><span class="ltx_text" id="S6.T9.1.1.15.15.6.1" style="color:#999999;">17.5</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 9: </span>Performance of various models on four math benchmark, named MATH, GSM8K, MMLU STEM and TheoremQA respectively. </figcaption>
</figure>
<figure class="ltx_table" id="S6.T10">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S6.T10.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S6.T10.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="S6.T10.1.1.1.1" rowspan="2"><span class="ltx_text ltx_font_bold" id="S6.T10.1.1.1.1.1">Model</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_tt" id="S6.T10.1.1.1.2" rowspan="2"><span class="ltx_text ltx_font_bold" id="S6.T10.1.1.1.2.1">Size</span></th>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S6.T10.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S6.T10.1.1.1.3.1">MMLU</span></td>
</tr>
<tr class="ltx_tr" id="S6.T10.1.2.2">
<td class="ltx_td ltx_align_center" id="S6.T10.1.2.2.1"><span class="ltx_text ltx_font_bold" id="S6.T10.1.2.2.1.1">Base</span></td>
<td class="ltx_td ltx_align_center" id="S6.T10.1.2.2.2"><span class="ltx_text ltx_font_bold" id="S6.T10.1.2.2.2.1">Redux</span></td>
</tr>
<tr class="ltx_tr" id="S6.T10.1.3.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="4" id="S6.T10.1.3.3.1"><span class="ltx_text ltx_font_bold" id="S6.T10.1.3.3.1.1">1B+ Models</span></th>
</tr>
<tr class="ltx_tr" id="S6.T10.1.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S6.T10.1.4.4.1">StarCoder2-3B</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S6.T10.1.4.4.2">3B</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T10.1.4.4.3">36.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T10.1.4.4.4">37.0</td>
</tr>
<tr class="ltx_tr" id="S6.T10.1.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T10.1.5.5.1">DS-Coder-1.3B-Base</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S6.T10.1.5.5.2">1.3B</th>
<td class="ltx_td ltx_align_center" id="S6.T10.1.5.5.3">25.8</td>
<td class="ltx_td ltx_align_center" id="S6.T10.1.5.5.4">24.5</td>
</tr>
<tr class="ltx_tr" id="S6.T10.1.6.6" style="background-color:#E6E6E6;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T10.1.6.6.1"><span class="ltx_text ltx_font_bold" id="S6.T10.1.6.6.1.1" style="background-color:#E6E6E6;">Qwen2.5-Coder-1.5B</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S6.T10.1.6.6.2"><span class="ltx_text" id="S6.T10.1.6.6.2.1" style="background-color:#E6E6E6;">1.5B</span></th>
<td class="ltx_td ltx_align_center" id="S6.T10.1.6.6.3"><span class="ltx_text ltx_font_bold" id="S6.T10.1.6.6.3.1" style="background-color:#E6E6E6;">53.6</span></td>
<td class="ltx_td ltx_align_center" id="S6.T10.1.6.6.4"><span class="ltx_text ltx_font_bold" id="S6.T10.1.6.6.4.1" style="background-color:#E6E6E6;">50.9</span></td>
</tr>
<tr class="ltx_tr" id="S6.T10.1.7.7">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="4" id="S6.T10.1.7.7.1"><span class="ltx_text ltx_font_bold" id="S6.T10.1.7.7.1.1">6B+ Models</span></th>
</tr>
<tr class="ltx_tr" id="S6.T10.1.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S6.T10.1.8.8.1">StarCoder2-7B</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S6.T10.1.8.8.2">7B</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T10.1.8.8.3">38.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T10.1.8.8.4">38.6</td>
</tr>
<tr class="ltx_tr" id="S6.T10.1.9.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T10.1.9.9.1">StarCoder2-15B</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S6.T10.1.9.9.2">15B</th>
<td class="ltx_td ltx_align_center" id="S6.T10.1.9.9.3">64.1</td>
<td class="ltx_td ltx_align_center" id="S6.T10.1.9.9.4">48.8</td>
</tr>
<tr class="ltx_tr" id="S6.T10.1.10.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T10.1.10.10.1">DS-Coder-6.7B-Base</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S6.T10.1.10.10.2">6.7B</th>
<td class="ltx_td ltx_align_center" id="S6.T10.1.10.10.3">36.4</td>
<td class="ltx_td ltx_align_center" id="S6.T10.1.10.10.4">36.5</td>
</tr>
<tr class="ltx_tr" id="S6.T10.1.11.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T10.1.11.11.1">DS-Coder-V2-Lite-Base</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S6.T10.1.11.11.2">2.4/16B</th>
<td class="ltx_td ltx_align_center" id="S6.T10.1.11.11.3">60.5</td>
<td class="ltx_td ltx_align_center" id="S6.T10.1.11.11.4">58.3</td>
</tr>
<tr class="ltx_tr" id="S6.T10.1.12.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T10.1.12.12.1">CodeQwen1.5-7B-Base</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S6.T10.1.12.12.2">7B</th>
<td class="ltx_td ltx_align_center" id="S6.T10.1.12.12.3">40.5</td>
<td class="ltx_td ltx_align_center" id="S6.T10.1.12.12.4">41.2</td>
</tr>
<tr class="ltx_tr" id="S6.T10.1.13.13" style="background-color:#E6E6E6;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T10.1.13.13.1"><span class="ltx_text ltx_font_bold" id="S6.T10.1.13.13.1.1" style="background-color:#E6E6E6;">Qwen2.5-Coder-7B-Base</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S6.T10.1.13.13.2"><span class="ltx_text" id="S6.T10.1.13.13.2.1" style="background-color:#E6E6E6;">7B</span></th>
<td class="ltx_td ltx_align_center" id="S6.T10.1.13.13.3"><span class="ltx_text ltx_font_bold" id="S6.T10.1.13.13.3.1" style="background-color:#E6E6E6;">68.0</span></td>
<td class="ltx_td ltx_align_center" id="S6.T10.1.13.13.4"><span class="ltx_text ltx_font_bold" id="S6.T10.1.13.13.4.1" style="background-color:#E6E6E6;">66.6</span></td>
</tr>
<tr class="ltx_tr" id="S6.T10.1.14.14">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="4" id="S6.T10.1.14.14.1"><span class="ltx_text ltx_font_bold" id="S6.T10.1.14.14.1.1">20B+ Models</span></th>
</tr>
<tr class="ltx_tr" id="S6.T10.1.15.15">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="S6.T10.1.15.15.1"><span class="ltx_text" id="S6.T10.1.15.15.1.1" style="color:#999999;">DS-Coder-33B-Base</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t" id="S6.T10.1.15.15.2"><span class="ltx_text" id="S6.T10.1.15.15.2.1" style="color:#999999;">33B</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S6.T10.1.15.15.3"><span class="ltx_text" id="S6.T10.1.15.15.3.1" style="color:#999999;">39.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S6.T10.1.15.15.4"><span class="ltx_text" id="S6.T10.1.15.15.4.1" style="color:#999999;">38.7</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 10: </span>MMLU results of different models, a general benchmark for common knowledge.</figcaption>
</figure>
<figure class="ltx_table" id="S6.T11">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S6.T11.1" style="width:397.5pt;height:229.9pt;vertical-align:-0.9pt;"><span class="ltx_transformed_inner" style="transform:translate(-20.0pt,11.5pt) scale(0.908564424614049,0.908564424614049) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S6.T11.1.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S6.T11.1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="S6.T11.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S6.T11.1.1.1.1.1.1">Model</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_tt" id="S6.T11.1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S6.T11.1.1.1.1.2.1">Size</span></th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S6.T11.1.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S6.T11.1.1.1.1.3.1">ARC-Challenge</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S6.T11.1.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S6.T11.1.1.1.1.4.1">TruthfulQA</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S6.T11.1.1.1.1.5"><span class="ltx_text ltx_font_bold" id="S6.T11.1.1.1.1.5.1">WinoGrande</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S6.T11.1.1.1.1.6"><span class="ltx_text ltx_font_bold" id="S6.T11.1.1.1.1.6.1">HellaSwag</span></td>
</tr>
<tr class="ltx_tr" id="S6.T11.1.1.2.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="6" id="S6.T11.1.1.2.2.1"><span class="ltx_text ltx_font_bold" id="S6.T11.1.1.2.2.1.1">1B+ Models</span></th>
</tr>
<tr class="ltx_tr" id="S6.T11.1.1.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S6.T11.1.1.3.3.1">StarCoder2-3B</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S6.T11.1.1.3.3.2">3B</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T11.1.1.3.3.3">34.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T11.1.1.3.3.4">40.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T11.1.1.3.3.5">57.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T11.1.1.3.3.6">48.1</td>
</tr>
<tr class="ltx_tr" id="S6.T11.1.1.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T11.1.1.4.4.1">DS-Coder-1.3B-Base</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S6.T11.1.1.4.4.2">1.3B</th>
<td class="ltx_td ltx_align_center" id="S6.T11.1.1.4.4.3">25.4</td>
<td class="ltx_td ltx_align_center" id="S6.T11.1.1.4.4.4">42.7</td>
<td class="ltx_td ltx_align_center" id="S6.T11.1.1.4.4.5">53.3</td>
<td class="ltx_td ltx_align_center" id="S6.T11.1.1.4.4.6">39.5</td>
</tr>
<tr class="ltx_tr" id="S6.T11.1.1.5.5" style="background-color:#E6E6E6;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T11.1.1.5.5.1"><span class="ltx_text ltx_font_bold" id="S6.T11.1.1.5.5.1.1" style="background-color:#E6E6E6;">Qwen2.5-Coder-1.5B</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S6.T11.1.1.5.5.2"><span class="ltx_text" id="S6.T11.1.1.5.5.2.1" style="background-color:#E6E6E6;">1.5B</span></th>
<td class="ltx_td ltx_align_center" id="S6.T11.1.1.5.5.3"><span class="ltx_text ltx_font_bold" id="S6.T11.1.1.5.5.3.1" style="background-color:#E6E6E6;">45.2</span></td>
<td class="ltx_td ltx_align_center" id="S6.T11.1.1.5.5.4"><span class="ltx_text ltx_font_bold" id="S6.T11.1.1.5.5.4.1" style="background-color:#E6E6E6;">44.0</span></td>
<td class="ltx_td ltx_align_center" id="S6.T11.1.1.5.5.5"><span class="ltx_text ltx_font_bold" id="S6.T11.1.1.5.5.5.1" style="background-color:#E6E6E6;">60.7</span></td>
<td class="ltx_td ltx_align_center" id="S6.T11.1.1.5.5.6"><span class="ltx_text ltx_font_bold" id="S6.T11.1.1.5.5.6.1" style="background-color:#E6E6E6;">61.8</span></td>
</tr>
<tr class="ltx_tr" id="S6.T11.1.1.6.6">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="6" id="S6.T11.1.1.6.6.1"><span class="ltx_text ltx_font_bold" id="S6.T11.1.1.6.6.1.1">6B+ Models</span></th>
</tr>
<tr class="ltx_tr" id="S6.T11.1.1.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S6.T11.1.1.7.7.1">StarCoder2-7B</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S6.T11.1.1.7.7.2">7B</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T11.1.1.7.7.3">38.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T11.1.1.7.7.4">42.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T11.1.1.7.7.5">57.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T11.1.1.7.7.6">52.4</td>
</tr>
<tr class="ltx_tr" id="S6.T11.1.1.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T11.1.1.8.8.1">StarCoder2-15B</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S6.T11.1.1.8.8.2">15B</th>
<td class="ltx_td ltx_align_center" id="S6.T11.1.1.8.8.3">47.2</td>
<td class="ltx_td ltx_align_center" id="S6.T11.1.1.8.8.4">37.9</td>
<td class="ltx_td ltx_align_center" id="S6.T11.1.1.8.8.5">64.3</td>
<td class="ltx_td ltx_align_center" id="S6.T11.1.1.8.8.6">64.1</td>
</tr>
<tr class="ltx_tr" id="S6.T11.1.1.9.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T11.1.1.9.9.1">DS-Coder-6.7B-Base</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S6.T11.1.1.9.9.2">6.7B</th>
<td class="ltx_td ltx_align_center" id="S6.T11.1.1.9.9.3">36.4</td>
<td class="ltx_td ltx_align_center" id="S6.T11.1.1.9.9.4">40.2</td>
<td class="ltx_td ltx_align_center" id="S6.T11.1.1.9.9.5">57.6</td>
<td class="ltx_td ltx_align_center" id="S6.T11.1.1.9.9.6">53.8</td>
</tr>
<tr class="ltx_tr" id="S6.T11.1.1.10.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T11.1.1.10.10.1">DS-Coder-V2-Lite-Base</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S6.T11.1.1.10.10.2">2.4/16B</th>
<td class="ltx_td ltx_align_center" id="S6.T11.1.1.10.10.3">57.3</td>
<td class="ltx_td ltx_align_center" id="S6.T11.1.1.10.10.4">38.8</td>
<td class="ltx_td ltx_align_center" id="S6.T11.1.1.10.10.5">72.9</td>
<td class="ltx_td ltx_align_center" id="S6.T11.1.1.10.10.6">-</td>
</tr>
<tr class="ltx_tr" id="S6.T11.1.1.11.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T11.1.1.11.11.1">CodeQwen1.5-7B-Base</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S6.T11.1.1.11.11.2">7B</th>
<td class="ltx_td ltx_align_center" id="S6.T11.1.1.11.11.3">35.7</td>
<td class="ltx_td ltx_align_center" id="S6.T11.1.1.11.11.4">42.2</td>
<td class="ltx_td ltx_align_center" id="S6.T11.1.1.11.11.5">59.8</td>
<td class="ltx_td ltx_align_center" id="S6.T11.1.1.11.11.6">56.0</td>
</tr>
<tr class="ltx_tr" id="S6.T11.1.1.12.12" style="background-color:#E6E6E6;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T11.1.1.12.12.1"><span class="ltx_text ltx_font_bold" id="S6.T11.1.1.12.12.1.1" style="background-color:#E6E6E6;">Qwen2.5-Coder-7B-Base</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S6.T11.1.1.12.12.2"><span class="ltx_text" id="S6.T11.1.1.12.12.2.1" style="background-color:#E6E6E6;">7B</span></th>
<td class="ltx_td ltx_align_center" id="S6.T11.1.1.12.12.3"><span class="ltx_text ltx_font_bold" id="S6.T11.1.1.12.12.3.1" style="background-color:#E6E6E6;">60.9</span></td>
<td class="ltx_td ltx_align_center" id="S6.T11.1.1.12.12.4"><span class="ltx_text ltx_font_bold" id="S6.T11.1.1.12.12.4.1" style="background-color:#E6E6E6;">50.6</span></td>
<td class="ltx_td ltx_align_center" id="S6.T11.1.1.12.12.5"><span class="ltx_text ltx_font_bold" id="S6.T11.1.1.12.12.5.1" style="background-color:#E6E6E6;">72.9</span></td>
<td class="ltx_td ltx_align_center" id="S6.T11.1.1.12.12.6"><span class="ltx_text ltx_font_bold" id="S6.T11.1.1.12.12.6.1" style="background-color:#E6E6E6;">76.8</span></td>
</tr>
<tr class="ltx_tr" id="S6.T11.1.1.13.13">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="6" id="S6.T11.1.1.13.13.1"><span class="ltx_text ltx_font_bold" id="S6.T11.1.1.13.13.1.1">20B+ Models</span></th>
</tr>
<tr class="ltx_tr" id="S6.T11.1.1.14.14">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="S6.T11.1.1.14.14.1"><span class="ltx_text" id="S6.T11.1.1.14.14.1.1" style="color:#999999;">DS-Coder-33B-Base</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t" id="S6.T11.1.1.14.14.2"><span class="ltx_text" id="S6.T11.1.1.14.14.2.1" style="color:#999999;">33B</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S6.T11.1.1.14.14.3"><span class="ltx_text" id="S6.T11.1.1.14.14.3.1" style="color:#999999;">42.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S6.T11.1.1.14.14.4"><span class="ltx_text" id="S6.T11.1.1.14.14.4.1" style="color:#999999;">40.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S6.T11.1.1.14.14.5"><span class="ltx_text" id="S6.T11.1.1.14.14.5.1" style="color:#999999;">62.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S6.T11.1.1.14.14.6"><span class="ltx_text" id="S6.T11.1.1.14.14.6.1" style="color:#999999;">60.2</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 11: </span>General performance of different models on four popular general benchmark, ARC-Challenge, TruthfulQA, WinoGrande and HellaSwag.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S6.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.5 </span>General Natural Language</h3>
<div class="ltx_para ltx_noindent" id="S6.SS5.p1">
<p class="ltx_p" id="S6.SS5.p1.1">In addition to mathematical ability, we aim to retain as much of the base model’s general-purpose capabilities as possible, such as general knowledge. To evaluate general natural language understanding, we selected MMLU <cite class="ltx_cite ltx_citemacro_citep">(Hendrycks et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#bib.bib21" title="">2021</a>)</cite> and its variant MMLU-Redux <cite class="ltx_cite ltx_citemacro_citep">(Gema et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#bib.bib17" title="">2024</a>)</cite>, along with four other benchmarks: ARC-Challenge <cite class="ltx_cite ltx_citemacro_citep">(Clark et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#bib.bib14" title="">2018</a>)</cite>, TruthfulQA <cite class="ltx_cite ltx_citemacro_citep">(Lin et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#bib.bib26" title="">2021</a>)</cite>, WinoGrande <cite class="ltx_cite ltx_citemacro_citep">(Sakaguchi et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#bib.bib32" title="">2019</a>)</cite>, and HellaSwag <cite class="ltx_cite ltx_citemacro_citep">(Zellers et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#bib.bib38" title="">2019</a>)</cite>. Similar to the results in mathematics, Table <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S6.T11" title="Table 11 ‣ 6.4 Math Reasoning ‣ 6 Evaluation on Base Models ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_tag">11</span></a> highlights Qwen2.5-Coder’s advantage in general natural language capabilities compared to other coders, further validating the effectiveness of Qwen2.5-Coder data mixing strategy.</p>
</div>
</section>
<section class="ltx_subsection" id="S6.SS6">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.6 </span>Long-Context Evaluation</h3>
<div class="ltx_para ltx_noindent" id="S6.SS6.p1">
<p class="ltx_p" id="S6.SS6.p1.1">Long context capability is crucial for code LLMs, serving as the core skill for understanding repository-level code and becoming a code agent. However, most of current code models still have very limited support for length, which hinders their potential for practical application. Qwen2.5-Coder aims to further advance the progress of open-source code models in long context modeling. To achieve this, we have collected and constructed long sequence code data at the repository level for pre-training. Through careful data proportioning and organization, we have enabled it to support input lengths of up to 128K tokens.</p>
</div>
<section class="ltx_paragraph" id="S6.SS6.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Needle in the Code</h5>
<div class="ltx_para ltx_noindent" id="S6.SS6.SSS0.Px1.p1">
<p class="ltx_p" id="S6.SS6.SSS0.Px1.p1.1">We created a simple but basic synthetic task called <span class="ltx_text ltx_font_italic" id="S6.SS6.SSS0.Px1.p1.1.1">Needle in the Code</span>, inspired by popular long-context evaluations in the text domain. In this task, we inserted a very simple custom function at various positions within a code repo (we chose Megatron <span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/NVIDIA/Megatron-LM" title="">https://github.com/NVIDIA/Megatron-LM</a></span></span></span> to honor its contributions to open-source LLMs!) and tested whether the model could replicate this function at the end of the codebase. The figure below shows that Qwen2.5-Coder is capable of successfully completing this task within a 128k length range.</p>
</div>
<figure class="ltx_figure" id="S6.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="264" id="S6.F5.g1" src="x6.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>The long context ability of Qwen2.5-Coder, evaluated by Needle in Code.</figcaption>
</figure>
</section>
</section>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Evaluation on Instruct Models</h2>
<div class="ltx_para ltx_noindent" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">For the evaluation of the instruct models, we rigorously assessed six core areas: <span class="ltx_text ltx_font_italic" id="S7.p1.1.1">code generation</span>, <span class="ltx_text ltx_font_italic" id="S7.p1.1.2">code reasoning</span>, <span class="ltx_text ltx_font_italic" id="S7.p1.1.3">code editing</span>, <span class="ltx_text ltx_font_italic" id="S7.p1.1.4">text-to-sql</span>, <span class="ltx_text ltx_font_italic" id="S7.p1.1.5">mathematical reasoning</span> and <span class="ltx_text ltx_font_italic" id="S7.p1.1.6">general natural language understanding</span>. The evaluation was structured to ensure a fair and thorough comparison across models. All evaluation code is publicly accessible for reproducibility<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/QwenLM/Qwen2.5-Coder" title="">https://github.com/QwenLM/Qwen2.5-Coder</a></span></span></span>. To ensure a broad comparison, we included some of the most popular and widely-used open-source instruction-tuned models, notably versions from the DeepSeek-Coder series and Codestral models. Below is a list of all artifacts referenced in this section.</p>
</div>
<figure class="ltx_table" id="S7.T12">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S7.T12.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S7.T12.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S7.T12.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S7.T12.1.1.1.1.1">Artifact</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S7.T12.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S7.T12.1.1.1.2.1">Public link</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S7.T12.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S7.T12.1.2.1.1">Qwen2.5-Coder-1.5B-Instruct</th>
<td class="ltx_td ltx_align_left ltx_border_t" id="S7.T12.1.2.1.2"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://hf.co/qwen/Qwen/Qwen2.5-Coder-1.5B-Instruct" title="">https://hf.co/qwen/Qwen/Qwen2.5-Coder-1.5B-Instruct</a></td>
</tr>
<tr class="ltx_tr" id="S7.T12.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S7.T12.1.3.2.1">Qwen2.5-Coder-7B-Instruct</th>
<td class="ltx_td ltx_align_left" id="S7.T12.1.3.2.2"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://hf.co/qwen/Qwen/Qwen2.5-Coder-7B-Instruct" title="">https://hf.co/qwen/Qwen/Qwen2.5-Coder-7B-Instruct</a></td>
</tr>
<tr class="ltx_tr" id="S7.T12.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S7.T12.1.4.3.1">CodeQwen1.5-7B-Chat</th>
<td class="ltx_td ltx_align_left ltx_border_t" id="S7.T12.1.4.3.2"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/Qwen/CodeQwen1.5-7B-Chat" title="">https://huggingface.co/Qwen/CodeQwen1.5-7B-Chat</a></td>
</tr>
<tr class="ltx_tr" id="S7.T12.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S7.T12.1.5.4.1">CodeStral-22B</th>
<td class="ltx_td ltx_align_left" id="S7.T12.1.5.4.2"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://hf.co/mistralai/Codestral-22B-v0.1" title="">https://hf.co/mistralai/Codestral-22B-v0.1</a></td>
</tr>
<tr class="ltx_tr" id="S7.T12.1.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S7.T12.1.6.5.1">DS-Coder-1.3B-instruct</th>
<td class="ltx_td ltx_align_left" id="S7.T12.1.6.5.2"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://hf.co/deepseek-ai/deepseek-coder-1.3b-instruct" title="">https://hf.co/deepseek-ai/deepseek-coder-1.3b-instruct</a></td>
</tr>
<tr class="ltx_tr" id="S7.T12.1.7.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S7.T12.1.7.6.1">DS-Coder-6.7B-instruct</th>
<td class="ltx_td ltx_align_left" id="S7.T12.1.7.6.2"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://hf.co/deepseek-ai/deepseek-coder-6.7b-instruct" title="">https://hf.co/deepseek-ai/deepseek-coder-6.7b-instruct</a></td>
</tr>
<tr class="ltx_tr" id="S7.T12.1.8.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S7.T12.1.8.7.1">DS-Coder-33B-instruct</th>
<td class="ltx_td ltx_align_left" id="S7.T12.1.8.7.2"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://hf.co/deepseek-ai/deepseek-coder-33b-instruct" title="">https://hf.co/deepseek-ai/deepseek-coder-33b-instruct</a></td>
</tr>
<tr class="ltx_tr" id="S7.T12.1.9.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S7.T12.1.9.8.1">DS-Coder-V2-Lite-Instruct</th>
<td class="ltx_td ltx_align_left" id="S7.T12.1.9.8.2"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://hf.co/deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct" title="">https://hf.co/deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct</a></td>
</tr>
<tr class="ltx_tr" id="S7.T12.1.10.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S7.T12.1.10.9.1">DS-Coder-V2-Instruct</th>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S7.T12.1.10.9.2"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://hf.co/deepseek-ai/DeepSeek-Coder-V2-Instruct" title="">https://hf.co/deepseek-ai/DeepSeek-Coder-V2-Instruct</a></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 12: </span>All artifacts released and used in this section.</figcaption>
</figure>
<section class="ltx_subsection" id="S7.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.1 </span>Code Generation</h3>
<div class="ltx_para ltx_noindent" id="S7.SS1.p1">
<p class="ltx_p" id="S7.SS1.p1.1">Building on the performance improvements of the Qwen2.5-Coder series base models, our Qwen2.5-Coder series instruct models similarly demonstrated outstanding performance in code generation tasks.</p>
</div>
<section class="ltx_paragraph" id="S7.SS1.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">HumanEval and MBPP</h5>
<div class="ltx_para ltx_noindent" id="S7.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="S7.SS1.SSS0.Px1.p1.1">We also evaluated the code generation capabilities of the Qwen2.5-Coder series instruct models using the EvalPlus <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#bib.bib27" title="">2023</a>)</cite> dataset. As illustrated by the experimental results in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S7.T13" title="Table 13 ‣ HumanEval and MBPP ‣ 7.1 Code Generation ‣ 7 Evaluation on Instruct Models ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_tag">13</span></a>, our Qwen2.5-Coder-7B-Instruct model demonstrated superior accuracy, significantly outperforming other models with a comparable number of parameters. Remarkably, it even exceeded the performance of larger models with over 20 billion parameters, such as CodeStral-22B and DS-Coder-33B-Instruct. Notably, Qwen2.5-Coder-7B-Instruct was the only model in our evaluation to surpass an 80% accuracy rate on HumanEval+, achieving an impressive 84.1%.</p>
</div>
<figure class="ltx_table" id="S7.T13">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S7.T13.1" style="width:397.5pt;height:190.7pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-46.1pt,22.0pt) scale(0.811744605596635,0.811744605596635) ;">
<table class="ltx_tabular ltx_align_middle" id="S7.T13.1.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S7.T13.1.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S7.T13.1.1.1.1.1" rowspan="2"><span class="ltx_text ltx_font_bold" id="S7.T13.1.1.1.1.1.1">Model</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_tt" id="S7.T13.1.1.1.1.2" rowspan="2"><span class="ltx_text ltx_font_bold" id="S7.T13.1.1.1.1.2.1">Size</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2" id="S7.T13.1.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S7.T13.1.1.1.1.3.1">HumanEval</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2" id="S7.T13.1.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S7.T13.1.1.1.1.4.1">MBPP</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2" id="S7.T13.1.1.1.1.5"><span class="ltx_text ltx_font_bold" id="S7.T13.1.1.1.1.5.1">BigCodeBench</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S7.T13.1.1.1.1.6"><span class="ltx_text ltx_font_bold" id="S7.T13.1.1.1.1.6.1">LiveCodeBench</span></td>
</tr>
<tr class="ltx_tr" id="S7.T13.1.1.2.2">
<td class="ltx_td ltx_align_center" id="S7.T13.1.1.2.2.1"><span class="ltx_text ltx_font_italic" id="S7.T13.1.1.2.2.1.1">HE</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S7.T13.1.1.2.2.2"><span class="ltx_text ltx_font_italic" id="S7.T13.1.1.2.2.2.1">HE+</span></td>
<td class="ltx_td ltx_align_center" id="S7.T13.1.1.2.2.3"><span class="ltx_text ltx_font_italic" id="S7.T13.1.1.2.2.3.1">MBPP</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S7.T13.1.1.2.2.4"><span class="ltx_text ltx_font_italic" id="S7.T13.1.1.2.2.4.1">MBPP+</span></td>
<td class="ltx_td ltx_align_center" id="S7.T13.1.1.2.2.5"><span class="ltx_text ltx_font_italic" id="S7.T13.1.1.2.2.5.1">Full</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S7.T13.1.1.2.2.6"><span class="ltx_text ltx_font_italic" id="S7.T13.1.1.2.2.6.1">Hard</span></td>
<td class="ltx_td ltx_align_center" id="S7.T13.1.1.2.2.7"><span class="ltx_text ltx_font_italic" id="S7.T13.1.1.2.2.7.1">Pass@1</span></td>
</tr>
<tr class="ltx_tr" id="S7.T13.1.1.3.3">
<td class="ltx_td ltx_align_center ltx_border_t" colspan="9" id="S7.T13.1.1.3.3.1"><span class="ltx_text ltx_font_bold" id="S7.T13.1.1.3.3.1.1">1B+ Models</span></td>
</tr>
<tr class="ltx_tr" id="S7.T13.1.1.4.4">
<td class="ltx_td ltx_align_left ltx_border_t" id="S7.T13.1.1.4.4.1">DS-Coder-1.3B-Instruct</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S7.T13.1.1.4.4.2">1.3B</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T13.1.1.4.4.3">65.2</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T13.1.1.4.4.4">61.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T13.1.1.4.4.5">61.6</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T13.1.1.4.4.6">52.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T13.1.1.4.4.7">22.8</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T13.1.1.4.4.8">3.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T13.1.1.4.4.9">9.3</td>
</tr>
<tr class="ltx_tr" id="S7.T13.1.1.5.5" style="background-color:#E6E6E6;">
<td class="ltx_td ltx_align_left" id="S7.T13.1.1.5.5.1"><span class="ltx_text ltx_font_bold" id="S7.T13.1.1.5.5.1.1" style="background-color:#E6E6E6;">Qwen2.5-Coder-1.5B-Instruct</span></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S7.T13.1.1.5.5.2"><span class="ltx_text" id="S7.T13.1.1.5.5.2.1" style="background-color:#E6E6E6;">1.5B</span></td>
<td class="ltx_td ltx_align_center" id="S7.T13.1.1.5.5.3"><span class="ltx_text ltx_font_bold" id="S7.T13.1.1.5.5.3.1" style="background-color:#E6E6E6;">70.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S7.T13.1.1.5.5.4"><span class="ltx_text ltx_font_bold" id="S7.T13.1.1.5.5.4.1" style="background-color:#E6E6E6;">66.5</span></td>
<td class="ltx_td ltx_align_center" id="S7.T13.1.1.5.5.5"><span class="ltx_text ltx_font_bold" id="S7.T13.1.1.5.5.5.1" style="background-color:#E6E6E6;">69.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S7.T13.1.1.5.5.6"><span class="ltx_text ltx_font_bold" id="S7.T13.1.1.5.5.6.1" style="background-color:#E6E6E6;">59.4</span></td>
<td class="ltx_td ltx_align_center" id="S7.T13.1.1.5.5.7"><span class="ltx_text ltx_font_bold" id="S7.T13.1.1.5.5.7.1" style="background-color:#E6E6E6;">32.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S7.T13.1.1.5.5.8"><span class="ltx_text ltx_font_bold" id="S7.T13.1.1.5.5.8.1" style="background-color:#E6E6E6;">6.8</span></td>
<td class="ltx_td ltx_align_center" id="S7.T13.1.1.5.5.9"><span class="ltx_text ltx_font_bold" id="S7.T13.1.1.5.5.9.1" style="background-color:#E6E6E6;">15.7</span></td>
</tr>
<tr class="ltx_tr" id="S7.T13.1.1.6.6">
<td class="ltx_td ltx_align_center ltx_border_t" colspan="9" id="S7.T13.1.1.6.6.1"><span class="ltx_text ltx_font_bold" id="S7.T13.1.1.6.6.1.1">6B+ Models</span></td>
</tr>
<tr class="ltx_tr" id="S7.T13.1.1.7.7">
<td class="ltx_td ltx_align_left ltx_border_t" id="S7.T13.1.1.7.7.1">DS-Coder-6.7B-Instruct</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S7.T13.1.1.7.7.2">6.7B</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T13.1.1.7.7.3">78.6</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T13.1.1.7.7.4">70.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T13.1.1.7.7.5">75.1</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T13.1.1.7.7.6">66.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T13.1.1.7.7.7">35.5</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T13.1.1.7.7.8">10.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T13.1.1.7.7.9">20.5</td>
</tr>
<tr class="ltx_tr" id="S7.T13.1.1.8.8">
<td class="ltx_td ltx_align_left" id="S7.T13.1.1.8.8.1">DS-Coder-V2-Lite-Instruct</td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S7.T13.1.1.8.8.2">2.4/16B</td>
<td class="ltx_td ltx_align_center" id="S7.T13.1.1.8.8.3">81.1</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S7.T13.1.1.8.8.4">75.0</td>
<td class="ltx_td ltx_align_center" id="S7.T13.1.1.8.8.5">82.3</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S7.T13.1.1.8.8.6">68.8</td>
<td class="ltx_td ltx_align_center" id="S7.T13.1.1.8.8.7">36.8</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S7.T13.1.1.8.8.8">16.2</td>
<td class="ltx_td ltx_align_center" id="S7.T13.1.1.8.8.9">24.3</td>
</tr>
<tr class="ltx_tr" id="S7.T13.1.1.9.9">
<td class="ltx_td ltx_align_left" id="S7.T13.1.1.9.9.1">CodeQwen1.5-7B-Chat</td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S7.T13.1.1.9.9.2">7B</td>
<td class="ltx_td ltx_align_center" id="S7.T13.1.1.9.9.3">86.0</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S7.T13.1.1.9.9.4">79.3</td>
<td class="ltx_td ltx_align_center" id="S7.T13.1.1.9.9.5">83.3</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S7.T13.1.1.9.9.6">71.4</td>
<td class="ltx_td ltx_align_center" id="S7.T13.1.1.9.9.7">39.6</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S7.T13.1.1.9.9.8">17.2</td>
<td class="ltx_td ltx_align_center" id="S7.T13.1.1.9.9.9">20.1</td>
</tr>
<tr class="ltx_tr" id="S7.T13.1.1.10.10" style="background-color:#E6E6E6;">
<td class="ltx_td ltx_align_left" id="S7.T13.1.1.10.10.1"><span class="ltx_text ltx_font_bold" id="S7.T13.1.1.10.10.1.1" style="background-color:#E6E6E6;">Qwen2.5-Coder-7B-Instruct</span></td>
<td class="ltx_td ltx_align_right ltx_border_r" id="S7.T13.1.1.10.10.2"><span class="ltx_text" id="S7.T13.1.1.10.10.2.1" style="background-color:#E6E6E6;">7B</span></td>
<td class="ltx_td ltx_align_center" id="S7.T13.1.1.10.10.3"><span class="ltx_text ltx_font_bold" id="S7.T13.1.1.10.10.3.1" style="background-color:#E6E6E6;">88.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S7.T13.1.1.10.10.4"><span class="ltx_text ltx_font_bold" id="S7.T13.1.1.10.10.4.1" style="background-color:#E6E6E6;">84.1</span></td>
<td class="ltx_td ltx_align_center" id="S7.T13.1.1.10.10.5"><span class="ltx_text ltx_font_bold" id="S7.T13.1.1.10.10.5.1" style="background-color:#E6E6E6;">83.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S7.T13.1.1.10.10.6"><span class="ltx_text ltx_font_bold" id="S7.T13.1.1.10.10.6.1" style="background-color:#E6E6E6;">71.7</span></td>
<td class="ltx_td ltx_align_center" id="S7.T13.1.1.10.10.7"><span class="ltx_text ltx_font_bold" id="S7.T13.1.1.10.10.7.1" style="background-color:#E6E6E6;">41.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S7.T13.1.1.10.10.8"><span class="ltx_text ltx_font_bold" id="S7.T13.1.1.10.10.8.1" style="background-color:#E6E6E6;">18.2</span></td>
<td class="ltx_td ltx_align_center" id="S7.T13.1.1.10.10.9"><span class="ltx_text ltx_font_bold" id="S7.T13.1.1.10.10.9.1" style="background-color:#E6E6E6;">37.6</span></td>
</tr>
<tr class="ltx_tr" id="S7.T13.1.1.11.11">
<td class="ltx_td ltx_align_center ltx_border_t" colspan="9" id="S7.T13.1.1.11.11.1"><span class="ltx_text ltx_font_bold" id="S7.T13.1.1.11.11.1.1">20B+ Models</span></td>
</tr>
<tr class="ltx_tr" id="S7.T13.1.1.12.12">
<td class="ltx_td ltx_align_left ltx_border_t" id="S7.T13.1.1.12.12.1"><span class="ltx_text" id="S7.T13.1.1.12.12.1.1" style="color:#999999;">CodeStral-22B</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" id="S7.T13.1.1.12.12.2"><span class="ltx_text" id="S7.T13.1.1.12.12.2.1" style="color:#999999;">22B</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T13.1.1.12.12.3"><span class="ltx_text" id="S7.T13.1.1.12.12.3.1" style="color:#999999;">78.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T13.1.1.12.12.4"><span class="ltx_text" id="S7.T13.1.1.12.12.4.1" style="color:#999999;">74.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T13.1.1.12.12.5"><span class="ltx_text" id="S7.T13.1.1.12.12.5.1" style="color:#999999;">73.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T13.1.1.12.12.6"><span class="ltx_text" id="S7.T13.1.1.12.12.6.1" style="color:#999999;">68.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T13.1.1.12.12.7"><span class="ltx_text" id="S7.T13.1.1.12.12.7.1" style="color:#999999;">47.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T13.1.1.12.12.8"><span class="ltx_text" id="S7.T13.1.1.12.12.8.1" style="color:#999999;">20.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T13.1.1.12.12.9"><span class="ltx_text" id="S7.T13.1.1.12.12.9.1" style="color:#999999;">32.9</span></td>
</tr>
<tr class="ltx_tr" id="S7.T13.1.1.13.13">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S7.T13.1.1.13.13.1"><span class="ltx_text" id="S7.T13.1.1.13.13.1.1" style="color:#999999;">DS-Coder-33B-Instruct</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb ltx_border_r" id="S7.T13.1.1.13.13.2"><span class="ltx_text" id="S7.T13.1.1.13.13.2.1" style="color:#999999;">33B</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S7.T13.1.1.13.13.3"><span class="ltx_text" id="S7.T13.1.1.13.13.3.1" style="color:#999999;">79.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S7.T13.1.1.13.13.4"><span class="ltx_text" id="S7.T13.1.1.13.13.4.1" style="color:#999999;">68.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S7.T13.1.1.13.13.5"><span class="ltx_text" id="S7.T13.1.1.13.13.5.1" style="color:#999999;">81.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S7.T13.1.1.13.13.6"><span class="ltx_text" id="S7.T13.1.1.13.13.6.1" style="color:#999999;">70.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S7.T13.1.1.13.13.7"><span class="ltx_text" id="S7.T13.1.1.13.13.7.1" style="color:#999999;">46.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S7.T13.1.1.13.13.8"><span class="ltx_text" id="S7.T13.1.1.13.13.8.1" style="color:#999999;">17.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S7.T13.1.1.13.13.9"><span class="ltx_text" id="S7.T13.1.1.13.13.9.1" style="color:#999999;">27.7</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 13: </span>The performance of different instruct
models on code generation by HumanEval, MBPP, bigcodebench and livecodebench. For bigcodebench here, we report “instruct” tasks score.</figcaption>
</figure>
<figure class="ltx_table" id="S7.T14">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S7.T14.1" style="width:397.5pt;height:184.3pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-54.6pt,25.2pt) scale(0.784336452754913,0.784336452754913) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S7.T14.1.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S7.T14.1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="S7.T14.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S7.T14.1.1.1.1.1.1">Model</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_tt" id="S7.T14.1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S7.T14.1.1.1.1.2.1">Size</span></th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S7.T14.1.1.1.1.3">Python</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S7.T14.1.1.1.1.4">Java</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S7.T14.1.1.1.1.5">C++</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S7.T14.1.1.1.1.6">C#</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S7.T14.1.1.1.1.7">TS</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S7.T14.1.1.1.1.8">JS</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S7.T14.1.1.1.1.9">PHP</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S7.T14.1.1.1.1.10">Bash</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S7.T14.1.1.1.1.11"><span class="ltx_text ltx_font_bold" id="S7.T14.1.1.1.1.11.1">Average</span></td>
</tr>
<tr class="ltx_tr" id="S7.T14.1.1.2.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="11" id="S7.T14.1.1.2.2.1"><span class="ltx_text ltx_font_bold" id="S7.T14.1.1.2.2.1.1">1B+ Models</span></th>
</tr>
<tr class="ltx_tr" id="S7.T14.1.1.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S7.T14.1.1.3.3.1">DS-Coder-1.3B-Instruct</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S7.T14.1.1.3.3.2">1.3B</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T14.1.1.3.3.3">65.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T14.1.1.3.3.4">51.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T14.1.1.3.3.5">45.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T14.1.1.3.3.6">55.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T14.1.1.3.3.7">59.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T14.1.1.3.3.8">52.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T14.1.1.3.3.9">45.3</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T14.1.1.3.3.10">12.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T14.1.1.3.3.11">48.4</td>
</tr>
<tr class="ltx_tr" id="S7.T14.1.1.4.4" style="background-color:#E6E6E6;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S7.T14.1.1.4.4.1"><span class="ltx_text ltx_font_bold" id="S7.T14.1.1.4.4.1.1" style="background-color:#E6E6E6;">Qwen2.5-Coder-1.5B-Instruct</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S7.T14.1.1.4.4.2"><span class="ltx_text" id="S7.T14.1.1.4.4.2.1" style="background-color:#E6E6E6;">1.5B</span></th>
<td class="ltx_td ltx_align_center" id="S7.T14.1.1.4.4.3"><span class="ltx_text ltx_font_bold" id="S7.T14.1.1.4.4.3.1" style="background-color:#E6E6E6;">71.2</span></td>
<td class="ltx_td ltx_align_center" id="S7.T14.1.1.4.4.4"><span class="ltx_text ltx_font_bold" id="S7.T14.1.1.4.4.4.1" style="background-color:#E6E6E6;">55.7</span></td>
<td class="ltx_td ltx_align_center" id="S7.T14.1.1.4.4.5"><span class="ltx_text ltx_font_bold" id="S7.T14.1.1.4.4.5.1" style="background-color:#E6E6E6;">50.9</span></td>
<td class="ltx_td ltx_align_center" id="S7.T14.1.1.4.4.6"><span class="ltx_text ltx_font_bold" id="S7.T14.1.1.4.4.6.1" style="background-color:#E6E6E6;">64.6</span></td>
<td class="ltx_td ltx_align_center" id="S7.T14.1.1.4.4.7"><span class="ltx_text ltx_font_bold" id="S7.T14.1.1.4.4.7.1" style="background-color:#E6E6E6;">61.0</span></td>
<td class="ltx_td ltx_align_center" id="S7.T14.1.1.4.4.8"><span class="ltx_text ltx_font_bold" id="S7.T14.1.1.4.4.8.1" style="background-color:#E6E6E6;">62.1</span></td>
<td class="ltx_td ltx_align_center" id="S7.T14.1.1.4.4.9"><span class="ltx_text ltx_font_bold" id="S7.T14.1.1.4.4.9.1" style="background-color:#E6E6E6;">59.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S7.T14.1.1.4.4.10"><span class="ltx_text ltx_font_bold" id="S7.T14.1.1.4.4.10.1" style="background-color:#E6E6E6;">29.1</span></td>
<td class="ltx_td ltx_align_center" id="S7.T14.1.1.4.4.11"><span class="ltx_text ltx_font_bold" id="S7.T14.1.1.4.4.11.1" style="background-color:#E6E6E6;">56.7</span></td>
</tr>
<tr class="ltx_tr" id="S7.T14.1.1.5.5">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="11" id="S7.T14.1.1.5.5.1"><span class="ltx_text ltx_font_bold" id="S7.T14.1.1.5.5.1.1">6B+ Models</span></th>
</tr>
<tr class="ltx_tr" id="S7.T14.1.1.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S7.T14.1.1.6.6.1">DS-Coder-6.7B-Instruct</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S7.T14.1.1.6.6.2">6.7B</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T14.1.1.6.6.3">78.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T14.1.1.6.6.4">68.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T14.1.1.6.6.5">63.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T14.1.1.6.6.6">72.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T14.1.1.6.6.7">67.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T14.1.1.6.6.8">72.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T14.1.1.6.6.9">68.9</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T14.1.1.6.6.10">36.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T14.1.1.6.6.11">66.1</td>
</tr>
<tr class="ltx_tr" id="S7.T14.1.1.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S7.T14.1.1.7.7.1">DS-Coder-V2-Lite-Instruct</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S7.T14.1.1.7.7.2">2.4/16B</th>
<td class="ltx_td ltx_align_center" id="S7.T14.1.1.7.7.3">81.1</td>
<td class="ltx_td ltx_align_center" id="S7.T14.1.1.7.7.4">76.6</td>
<td class="ltx_td ltx_align_center" id="S7.T14.1.1.7.7.5">75.8</td>
<td class="ltx_td ltx_align_center" id="S7.T14.1.1.7.7.6">76.6</td>
<td class="ltx_td ltx_align_center" id="S7.T14.1.1.7.7.7">80.5</td>
<td class="ltx_td ltx_align_center" id="S7.T14.1.1.7.7.8">77.6</td>
<td class="ltx_td ltx_align_center" id="S7.T14.1.1.7.7.9">74.5</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S7.T14.1.1.7.7.10">43.0</td>
<td class="ltx_td ltx_align_center" id="S7.T14.1.1.7.7.11">73.2</td>
</tr>
<tr class="ltx_tr" id="S7.T14.1.1.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S7.T14.1.1.8.8.1">CodeQwen1.5-7B-Chat</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S7.T14.1.1.8.8.2">7B</th>
<td class="ltx_td ltx_align_center" id="S7.T14.1.1.8.8.3">83.5</td>
<td class="ltx_td ltx_align_center" id="S7.T14.1.1.8.8.4">70.9</td>
<td class="ltx_td ltx_align_center" id="S7.T14.1.1.8.8.5">72</td>
<td class="ltx_td ltx_align_center" id="S7.T14.1.1.8.8.6">75.9</td>
<td class="ltx_td ltx_align_center" id="S7.T14.1.1.8.8.7">76.7</td>
<td class="ltx_td ltx_align_center" id="S7.T14.1.1.8.8.8">77.6</td>
<td class="ltx_td ltx_align_center" id="S7.T14.1.1.8.8.9">73.9</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S7.T14.1.1.8.8.10">41.8</td>
<td class="ltx_td ltx_align_center" id="S7.T14.1.1.8.8.11">71.6</td>
</tr>
<tr class="ltx_tr" id="S7.T14.1.1.9.9" style="background-color:#E6E6E6;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S7.T14.1.1.9.9.1"><span class="ltx_text ltx_font_bold" id="S7.T14.1.1.9.9.1.1" style="background-color:#E6E6E6;">Qwen2.5-Coder-7B-Instruct</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S7.T14.1.1.9.9.2"><span class="ltx_text" id="S7.T14.1.1.9.9.2.1" style="background-color:#E6E6E6;">7B</span></th>
<td class="ltx_td ltx_align_center" id="S7.T14.1.1.9.9.3"><span class="ltx_text ltx_font_bold" id="S7.T14.1.1.9.9.3.1" style="background-color:#E6E6E6;">87.8</span></td>
<td class="ltx_td ltx_align_center" id="S7.T14.1.1.9.9.4"><span class="ltx_text ltx_font_bold" id="S7.T14.1.1.9.9.4.1" style="background-color:#E6E6E6;">76.5</span></td>
<td class="ltx_td ltx_align_center" id="S7.T14.1.1.9.9.5"><span class="ltx_text ltx_font_bold" id="S7.T14.1.1.9.9.5.1" style="background-color:#E6E6E6;">75.6</span></td>
<td class="ltx_td ltx_align_center" id="S7.T14.1.1.9.9.6"><span class="ltx_text ltx_font_bold" id="S7.T14.1.1.9.9.6.1" style="background-color:#E6E6E6;">80.3</span></td>
<td class="ltx_td ltx_align_center" id="S7.T14.1.1.9.9.7"><span class="ltx_text ltx_font_bold" id="S7.T14.1.1.9.9.7.1" style="background-color:#E6E6E6;">81.8</span></td>
<td class="ltx_td ltx_align_center" id="S7.T14.1.1.9.9.8"><span class="ltx_text ltx_font_bold" id="S7.T14.1.1.9.9.8.1" style="background-color:#E6E6E6;">83.2</span></td>
<td class="ltx_td ltx_align_center" id="S7.T14.1.1.9.9.9"><span class="ltx_text ltx_font_bold" id="S7.T14.1.1.9.9.9.1" style="background-color:#E6E6E6;">78.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S7.T14.1.1.9.9.10"><span class="ltx_text ltx_font_bold" id="S7.T14.1.1.9.9.10.1" style="background-color:#E6E6E6;">48.7</span></td>
<td class="ltx_td ltx_align_center" id="S7.T14.1.1.9.9.11"><span class="ltx_text ltx_font_bold" id="S7.T14.1.1.9.9.11.1" style="background-color:#E6E6E6;">76.5</span></td>
</tr>
<tr class="ltx_tr" id="S7.T14.1.1.10.10">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="11" id="S7.T14.1.1.10.10.1"><span class="ltx_text ltx_font_bold" id="S7.T14.1.1.10.10.1.1">20B+ Models</span></th>
</tr>
<tr class="ltx_tr" id="S7.T14.1.1.11.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S7.T14.1.1.11.11.1"><span class="ltx_text" id="S7.T14.1.1.11.11.1.1" style="color:#999999;">CodeStral-22B</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S7.T14.1.1.11.11.2"><span class="ltx_text" id="S7.T14.1.1.11.11.2.1" style="color:#999999;">22B</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T14.1.1.11.11.3"><span class="ltx_text" id="S7.T14.1.1.11.11.3.1" style="color:#999999;">78.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T14.1.1.11.11.4"><span class="ltx_text" id="S7.T14.1.1.11.11.4.1" style="color:#999999;">71.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T14.1.1.11.11.5"><span class="ltx_text" id="S7.T14.1.1.11.11.5.1" style="color:#999999;">71.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T14.1.1.11.11.6"><span class="ltx_text" id="S7.T14.1.1.11.11.6.1" style="color:#999999;">77.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T14.1.1.11.11.7"><span class="ltx_text" id="S7.T14.1.1.11.11.7.1" style="color:#999999;">72.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T14.1.1.11.11.8"><span class="ltx_text" id="S7.T14.1.1.11.11.8.1" style="color:#999999;">73.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T14.1.1.11.11.9"><span class="ltx_text" id="S7.T14.1.1.11.11.9.1" style="color:#999999;">69.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S7.T14.1.1.11.11.10"><span class="ltx_text" id="S7.T14.1.1.11.11.10.1" style="color:#999999;">47.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T14.1.1.11.11.11"><span class="ltx_text" id="S7.T14.1.1.11.11.11.1" style="color:#999999;">70.2</span></td>
</tr>
<tr class="ltx_tr" id="S7.T14.1.1.12.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S7.T14.1.1.12.12.1"><span class="ltx_text" id="S7.T14.1.1.12.12.1.1" style="color:#999999;">DS-Coder-33B-Instruct</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S7.T14.1.1.12.12.2"><span class="ltx_text" id="S7.T14.1.1.12.12.2.1" style="color:#999999;">33B</span></th>
<td class="ltx_td ltx_align_center" id="S7.T14.1.1.12.12.3"><span class="ltx_text" id="S7.T14.1.1.12.12.3.1" style="color:#999999;">79.3</span></td>
<td class="ltx_td ltx_align_center" id="S7.T14.1.1.12.12.4"><span class="ltx_text" id="S7.T14.1.1.12.12.4.1" style="color:#999999;">73.4</span></td>
<td class="ltx_td ltx_align_center" id="S7.T14.1.1.12.12.5"><span class="ltx_text" id="S7.T14.1.1.12.12.5.1" style="color:#999999;">68.9</span></td>
<td class="ltx_td ltx_align_center" id="S7.T14.1.1.12.12.6"><span class="ltx_text" id="S7.T14.1.1.12.12.6.1" style="color:#999999;">74.1</span></td>
<td class="ltx_td ltx_align_center" id="S7.T14.1.1.12.12.7"><span class="ltx_text" id="S7.T14.1.1.12.12.7.1" style="color:#999999;">67.9</span></td>
<td class="ltx_td ltx_align_center" id="S7.T14.1.1.12.12.8"><span class="ltx_text" id="S7.T14.1.1.12.12.8.1" style="color:#999999;">73.9</span></td>
<td class="ltx_td ltx_align_center" id="S7.T14.1.1.12.12.9"><span class="ltx_text" id="S7.T14.1.1.12.12.9.1" style="color:#999999;">72.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S7.T14.1.1.12.12.10"><span class="ltx_text" id="S7.T14.1.1.12.12.10.1" style="color:#999999;">43.0</span></td>
<td class="ltx_td ltx_align_center" id="S7.T14.1.1.12.12.11"><span class="ltx_text" id="S7.T14.1.1.12.12.11.1" style="color:#999999;">69.2</span></td>
</tr>
<tr class="ltx_tr" id="S7.T14.1.1.13.13">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S7.T14.1.1.13.13.1"><span class="ltx_text" id="S7.T14.1.1.13.13.1.1" style="color:#999999;">DS-Coder-V2-Instruct</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S7.T14.1.1.13.13.2"><span class="ltx_text" id="S7.T14.1.1.13.13.2.1" style="color:#999999;">21/236B</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S7.T14.1.1.13.13.3"><span class="ltx_text" id="S7.T14.1.1.13.13.3.1" style="color:#999999;">90.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S7.T14.1.1.13.13.4"><span class="ltx_text" id="S7.T14.1.1.13.13.4.1" style="color:#999999;">82.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S7.T14.1.1.13.13.5"><span class="ltx_text" id="S7.T14.1.1.13.13.5.1" style="color:#999999;">84.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S7.T14.1.1.13.13.6"><span class="ltx_text" id="S7.T14.1.1.13.13.6.1" style="color:#999999;">82.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S7.T14.1.1.13.13.7"><span class="ltx_text" id="S7.T14.1.1.13.13.7.1" style="color:#999999;">83</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S7.T14.1.1.13.13.8"><span class="ltx_text" id="S7.T14.1.1.13.13.8.1" style="color:#999999;">84.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S7.T14.1.1.13.13.9"><span class="ltx_text" id="S7.T14.1.1.13.13.9.1" style="color:#999999;">79.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S7.T14.1.1.13.13.10"><span class="ltx_text" id="S7.T14.1.1.13.13.10.1" style="color:#999999;">52.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S7.T14.1.1.13.13.11"><span class="ltx_text" id="S7.T14.1.1.13.13.11.1" style="color:#999999;">79.9</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 14: </span>The performance of different approaches on instruct format MultiPL-E.</figcaption>
</figure>
</section>
<section class="ltx_paragraph" id="S7.SS1.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">BigCodeBench-Instruct</h5>
<div class="ltx_para ltx_noindent" id="S7.SS1.SSS0.Px2.p1">
<p class="ltx_p" id="S7.SS1.SSS0.Px2.p1.1">The <em class="ltx_emph ltx_font_italic" id="S7.SS1.SSS0.Px2.p1.1.1">instruct</em> split provided by BigCodeBench <cite class="ltx_cite ltx_citemacro_citep">(Zhuo et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#bib.bib39" title="">2024</a>)</cite> is intended for assessing the code generation abilities of instruct models. We assessed the Qwen2.5-Coder series instruct models on the BigCodeBench-Instruct. As shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S7.T13" title="Table 13 ‣ HumanEval and MBPP ‣ 7.1 Code Generation ‣ 7 Evaluation on Instruct Models ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_tag">13</span></a>, the Qwen2.5-Coder-7B-Instruct outperformed other instruct models with similar parameter sizes, achieving higher accuracy scores on both the full and hard subsets, reaching 41.0% on the full subset and 18.2% on the hard subset, demonstrating the Qwen2.5-Coder series instruct models’ powerful code generation capabilities.</p>
</div>
</section>
<section class="ltx_paragraph" id="S7.SS1.SSS0.Px3">
<h5 class="ltx_title ltx_title_paragraph">LiveCodeBench</h5>
<div class="ltx_para ltx_noindent" id="S7.SS1.SSS0.Px3.p1">
<p class="ltx_p" id="S7.SS1.SSS0.Px3.p1.1">LiveCodeBench <cite class="ltx_cite ltx_citemacro_citep">(Jain et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#bib.bib22" title="">2024</a>)</cite> is a comprehensive and contamination-free benchmark designed to evaluate the coding capabilities of LLMs. It continuously gathers new problems from leading competitive programming platforms like LeetCode<span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://leetcode.com" title="">https://leetcode.com</a></span></span></span>, AtCoder<span class="ltx_note ltx_role_footnote" id="footnote6"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://atcoder.jp" title="">https://atcoder.jp</a></span></span></span>, and CodeForces<span class="ltx_note ltx_role_footnote" id="footnote7"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://codeforces.com" title="">https://codeforces.com</a></span></span></span>, ensuring an up-to-date and diverse set of challenges. Currently, it hosts over 600 high-quality coding problems published between May 2023 and September 2024.</p>
</div>
<div class="ltx_para ltx_noindent" id="S7.SS1.SSS0.Px3.p2">
<p class="ltx_p" id="S7.SS1.SSS0.Px3.p2.1">To better demonstrate our model’s effectiveness on real-world competitive programming tasks, we conduct evaluation of the Qwen-2.5-Coder series instruct models on the LiveCodeBench (2305-2409) dataset. As illustrated in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S7.T13" title="Table 13 ‣ HumanEval and MBPP ‣ 7.1 Code Generation ‣ 7 Evaluation on Instruct Models ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_tag">13</span></a>, the Qwen-2.5-Coder-7B-Instruct model achieved an impressive Pass@1 accuracy of 37.6%, significantly outperforming other models of comparable parameter scales. Notably, it also surpassed larger models such as CodeStral-22B and DS-Coder-33B-Instruct, underscoring the Qwen-2.5-Coder series’ exceptional capabilities in handling complex code generation challenges.</p>
</div>
</section>
<section class="ltx_paragraph" id="S7.SS1.SSS0.Px4">
<h5 class="ltx_title ltx_title_paragraph">Multi-Programming Language</h5>
<div class="ltx_para ltx_noindent" id="S7.SS1.SSS0.Px4.p1">
<p class="ltx_p" id="S7.SS1.SSS0.Px4.p1.1">The Qwen2.5-Coder series instruct models have inherited the high performance of the base model on the Multi-Programming Language. To further evaluate their capabilities, we tested the instruct models on two specific benchmarks: MultiPL-E <cite class="ltx_cite ltx_citemacro_citep">(Cassano et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#bib.bib9" title="">2022</a>)</cite> and McEval <cite class="ltx_cite ltx_citemacro_citep">(Chai et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#bib.bib10" title="">2024</a>)</cite>.</p>
</div>
</section>
<section class="ltx_paragraph" id="S7.SS1.SSS0.Px5">
<h5 class="ltx_title ltx_title_paragraph">MultiPL-E</h5>
<div class="ltx_para ltx_noindent" id="S7.SS1.SSS0.Px5.p1">
<p class="ltx_p" id="S7.SS1.SSS0.Px5.p1.1">As demonstrated by the evaluation results in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S7.T14" title="Table 14 ‣ HumanEval and MBPP ‣ 7.1 Code Generation ‣ 7 Evaluation on Instruct Models ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_tag">14</span></a>, Qwen2.5-Coder-7B-Instruct consistently outperforms other models with the same number of parameters, including DS-Coder-V2-Lite-Instruct, in code generation tasks across eight programming languages. With an average accuracy of 76.5%, Qwen2.5-Coder-7B-Instruct surpasses even larger models such as CodeStral-22B and DS-Coder-33B-Instruct (despite having over 20 billion parameters), highlighting its powerful code generation capabilities in multiple programming languages.</p>
</div>
<figure class="ltx_figure" id="S7.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="498" id="S7.F6.g1" src="x7.png" width="498"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>The McEval Performance of Qwen2.5-Coder-7B-Instruct compared with popular open-source large code models with similar size.</figcaption>
</figure>
</section>
<section class="ltx_paragraph" id="S7.SS1.SSS0.Px6">
<h5 class="ltx_title ltx_title_paragraph">McEval</h5>
<div class="ltx_para ltx_noindent" id="S7.SS1.SSS0.Px6.p1">
<p class="ltx_p" id="S7.SS1.SSS0.Px6.p1.1">To comprehensively assess the code generation capabilities of the Qwen2.5-Coder series models across a broader range of programming languages, we evaluated them on the McEval benchmark <cite class="ltx_cite ltx_citemacro_citep">(Chai et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#bib.bib10" title="">2024</a>)</cite>, which spans 40 programming languages and includes 16,000 test cases.
As shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S7.F6" title="Figure 6 ‣ MultiPL-E ‣ 7.1 Code Generation ‣ 7 Evaluation on Instruct Models ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_tag">6</span></a>, the Qwen2.5-Coder-7B-Instruct model excels when compared to other open-source models on the McEval benchmark, particularly across a wide range of programming languages. Its average accuracy not only exceeds that of much larger models such as DS-Coder-33B-Instruct and CodeStral-22B but also demonstrates a notable advantage over models of comparable parameter size.</p>
</div>
<figure class="ltx_table" id="S7.T15">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S7.T15.1" style="width:318.0pt;height:248.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-2.1pt,1.7pt) scale(0.986691197264805,0.986691197264805) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S7.T15.1.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S7.T15.1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="S7.T15.1.1.1.1.1" rowspan="2"><span class="ltx_text ltx_font_bold" id="S7.T15.1.1.1.1.1.1">Model</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_tt" id="S7.T15.1.1.1.1.2" rowspan="2"><span class="ltx_text ltx_font_bold" id="S7.T15.1.1.1.1.2.1">Size</span></th>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S7.T15.1.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S7.T15.1.1.1.1.3.1">CRUXEval</span></td>
</tr>
<tr class="ltx_tr" id="S7.T15.1.1.2.2">
<td class="ltx_td ltx_align_center" id="S7.T15.1.1.2.2.1"><span class="ltx_text ltx_font_italic" id="S7.T15.1.1.2.2.1.1">Input-CoT</span></td>
<td class="ltx_td ltx_align_center" id="S7.T15.1.1.2.2.2"><span class="ltx_text ltx_font_italic" id="S7.T15.1.1.2.2.2.1">Output-CoT</span></td>
</tr>
<tr class="ltx_tr" id="S7.T15.1.1.3.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="4" id="S7.T15.1.1.3.3.1"><span class="ltx_text ltx_font_bold" id="S7.T15.1.1.3.3.1.1">1B+ Models</span></th>
</tr>
<tr class="ltx_tr" id="S7.T15.1.1.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S7.T15.1.1.4.4.1">DS-Coder-1.3B-Instruct</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S7.T15.1.1.4.4.2">1.3B</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T15.1.1.4.4.3">14.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T15.1.1.4.4.4">28.1</td>
</tr>
<tr class="ltx_tr" id="S7.T15.1.1.5.5" style="background-color:#E6E6E6;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S7.T15.1.1.5.5.1"><span class="ltx_text ltx_font_bold" id="S7.T15.1.1.5.5.1.1" style="background-color:#E6E6E6;">Qwen2.5-Coder-1.5B-Instruct</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S7.T15.1.1.5.5.2"><span class="ltx_text" id="S7.T15.1.1.5.5.2.1" style="background-color:#E6E6E6;">1.5B</span></th>
<td class="ltx_td ltx_align_center" id="S7.T15.1.1.5.5.3"><span class="ltx_text ltx_font_bold" id="S7.T15.1.1.5.5.3.1" style="background-color:#E6E6E6;">45.4</span></td>
<td class="ltx_td ltx_align_center" id="S7.T15.1.1.5.5.4"><span class="ltx_text ltx_font_bold" id="S7.T15.1.1.5.5.4.1" style="background-color:#E6E6E6;">37.5</span></td>
</tr>
<tr class="ltx_tr" id="S7.T15.1.1.6.6">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="4" id="S7.T15.1.1.6.6.1"><span class="ltx_text ltx_font_bold" id="S7.T15.1.1.6.6.1.1">6B+ Models</span></th>
</tr>
<tr class="ltx_tr" id="S7.T15.1.1.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S7.T15.1.1.7.7.1">DS-Coder-6.7B-Instruct</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S7.T15.1.1.7.7.2">6.7B</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T15.1.1.7.7.3">42.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T15.1.1.7.7.4">45.1</td>
</tr>
<tr class="ltx_tr" id="S7.T15.1.1.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S7.T15.1.1.8.8.1">DS-Coder-V2-Lite-Instruct</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S7.T15.1.1.8.8.2">2.4/16B</th>
<td class="ltx_td ltx_align_center" id="S7.T15.1.1.8.8.3">53.0</td>
<td class="ltx_td ltx_align_center" id="S7.T15.1.1.8.8.4">52.9</td>
</tr>
<tr class="ltx_tr" id="S7.T15.1.1.9.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S7.T15.1.1.9.9.1">CodeQwen1.5-7B-Chat</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S7.T15.1.1.9.9.2">7B</th>
<td class="ltx_td ltx_align_center" id="S7.T15.1.1.9.9.3">42.1</td>
<td class="ltx_td ltx_align_center" id="S7.T15.1.1.9.9.4">38.5</td>
</tr>
<tr class="ltx_tr" id="S7.T15.1.1.10.10" style="background-color:#E6E6E6;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S7.T15.1.1.10.10.1"><span class="ltx_text ltx_font_bold" id="S7.T15.1.1.10.10.1.1" style="background-color:#E6E6E6;">Qwen2.5-Coder-7B-Instruct</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S7.T15.1.1.10.10.2"><span class="ltx_text" id="S7.T15.1.1.10.10.2.1" style="background-color:#E6E6E6;">7B</span></th>
<td class="ltx_td ltx_align_center" id="S7.T15.1.1.10.10.3"><span class="ltx_text ltx_font_bold" id="S7.T15.1.1.10.10.3.1" style="background-color:#E6E6E6;">65.8</span></td>
<td class="ltx_td ltx_align_center" id="S7.T15.1.1.10.10.4"><span class="ltx_text ltx_font_bold" id="S7.T15.1.1.10.10.4.1" style="background-color:#E6E6E6;">65.9</span></td>
</tr>
<tr class="ltx_tr" id="S7.T15.1.1.11.11">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="4" id="S7.T15.1.1.11.11.1"><span class="ltx_text ltx_font_bold" id="S7.T15.1.1.11.11.1.1">20B+ Models</span></th>
</tr>
<tr class="ltx_tr" id="S7.T15.1.1.12.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S7.T15.1.1.12.12.1"><span class="ltx_text" id="S7.T15.1.1.12.12.1.1" style="color:#999999;">CodeStral-22B</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S7.T15.1.1.12.12.2"><span class="ltx_text" id="S7.T15.1.1.12.12.2.1" style="color:#999999;">22B</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T15.1.1.12.12.3"><span class="ltx_text" id="S7.T15.1.1.12.12.3.1" style="color:#999999;">48.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T15.1.1.12.12.4"><span class="ltx_text" id="S7.T15.1.1.12.12.4.1" style="color:#999999;">60.6</span></td>
</tr>
<tr class="ltx_tr" id="S7.T15.1.1.13.13">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S7.T15.1.1.13.13.1"><span class="ltx_text" id="S7.T15.1.1.13.13.1.1" style="color:#999999;">DS-Coder-33B-Instruct</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S7.T15.1.1.13.13.2"><span class="ltx_text" id="S7.T15.1.1.13.13.2.1" style="color:#999999;">33B</span></th>
<td class="ltx_td ltx_align_center" id="S7.T15.1.1.13.13.3"><span class="ltx_text" id="S7.T15.1.1.13.13.3.1" style="color:#999999;">47.3</span></td>
<td class="ltx_td ltx_align_center" id="S7.T15.1.1.13.13.4"><span class="ltx_text" id="S7.T15.1.1.13.13.4.1" style="color:#999999;">50.6</span></td>
</tr>
<tr class="ltx_tr" id="S7.T15.1.1.14.14">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S7.T15.1.1.14.14.1"><span class="ltx_text" id="S7.T15.1.1.14.14.1.1" style="color:#999999;">DS-Coder-V2-Instruct</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S7.T15.1.1.14.14.2"><span class="ltx_text" id="S7.T15.1.1.14.14.2.1" style="color:#999999;">21/236B</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S7.T15.1.1.14.14.3"><span class="ltx_text" id="S7.T15.1.1.14.14.3.1" style="color:#999999;">70.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S7.T15.1.1.14.14.4"><span class="ltx_text" id="S7.T15.1.1.14.14.4.1" style="color:#999999;">75.1</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 15: </span>The CRUXEval performance of different instruct models, with <span class="ltx_text ltx_font_italic" id="S7.T15.4.1">Input-CoT</span> and <span class="ltx_text ltx_font_italic" id="S7.T15.5.2">Output-CoT</span> settings.</figcaption>
</figure>
</section>
</section>
<section class="ltx_subsection" id="S7.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.2 </span>Code Reasoning</h3>
<figure class="ltx_figure" id="S7.F7"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="325" id="S7.F7.g1" src="x8.png" width="664"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>The relationship between model sizes and code reasoning capabilities. The x-axis represents the parameter sizes of different models, and the y-axis indicates the CRUXEval-O (CoT) scores respectively.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S7.SS2.p1">
<p class="ltx_p" id="S7.SS2.p1.1">To assess the code reasoning capabilities of the Qwen2.5-Coder series instruct models, we performed an evaluation on CRUXEval <cite class="ltx_cite ltx_citemacro_citep">(Gu et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#bib.bib18" title="">2024</a>)</cite>. As illustrated by the experimental results in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S7.T15" title="Table 15 ‣ McEval ‣ 7.1 Code Generation ‣ 7 Evaluation on Instruct Models ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_tag">15</span></a>, the Qwen2.5-Coder-7B-Instruct model achieved Input-CoT and Output-CoT accuracies of 65.8% and 65.9%, respectively. This represents a notable improvement over the DS-Coder-V2-Lite-Instruct model, with gains of 12.8% in Input-CoT accuracy and 13.0% in Output-CoT accuracy. Furthermore, the Qwen2.5-Coder-7B-Instruct model outperformed larger models, such as the CodeStral-22B and DS-Coder-33B-Instruct, underscoring its superior code reasoning capabilities despite its smaller size.</p>
</div>
<div class="ltx_para ltx_noindent" id="S7.SS2.p2">
<p class="ltx_p" id="S7.SS2.p2.1">Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S7.F7" title="Figure 7 ‣ 7.2 Code Reasoning ‣ 7 Evaluation on Instruct Models ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_tag">7</span></a> illustrates the relationship between model sizes and code reasoning capabilities. The Qwen2.5-Coder instruct models stand out for delivering superior code reasoning performance with the fewest parameters, surpassing the results of other open-source large language models by a significant margin. According to this trend, we expect that code reasoning performance comparable to GPT-4o could be achieved with a model around the 30 billion parameters scale.</p>
</div>
<figure class="ltx_table" id="S7.T16">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S7.T16.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S7.T16.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="S7.T16.1.1.1.1" rowspan="2"><span class="ltx_text ltx_font_bold" id="S7.T16.1.1.1.1.1">Model</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_tt" id="S7.T16.1.1.1.2" rowspan="2"><span class="ltx_text ltx_font_bold" id="S7.T16.1.1.1.2.1">Size</span></th>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S7.T16.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S7.T16.1.1.1.3.1">Aider</span></td>
</tr>
<tr class="ltx_tr" id="S7.T16.1.2.2">
<td class="ltx_td ltx_align_center" id="S7.T16.1.2.2.1"><span class="ltx_text ltx_font_italic" id="S7.T16.1.2.2.1.1">Pass@1</span></td>
<td class="ltx_td ltx_align_center" id="S7.T16.1.2.2.2"><span class="ltx_text ltx_font_italic" id="S7.T16.1.2.2.2.1">Pass@2</span></td>
</tr>
<tr class="ltx_tr" id="S7.T16.1.3.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="4" id="S7.T16.1.3.3.1"><span class="ltx_text ltx_font_bold" id="S7.T16.1.3.3.1.1">1B+ Models</span></th>
</tr>
<tr class="ltx_tr" id="S7.T16.1.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S7.T16.1.4.4.1">DS-Coder-1.3B-Instruct</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S7.T16.1.4.4.2">1.3B</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T16.1.4.4.3">17.3*</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T16.1.4.4.4">21.1*</td>
</tr>
<tr class="ltx_tr" id="S7.T16.1.5.5" style="background-color:#E6E6E6;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S7.T16.1.5.5.1"><span class="ltx_text ltx_font_bold" id="S7.T16.1.5.5.1.1" style="background-color:#E6E6E6;">Qwen2.5-Coder-1.5B-Instruct</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S7.T16.1.5.5.2"><span class="ltx_text" id="S7.T16.1.5.5.2.1" style="background-color:#E6E6E6;">1.5B</span></th>
<td class="ltx_td ltx_align_center" id="S7.T16.1.5.5.3"><span class="ltx_text ltx_font_bold" id="S7.T16.1.5.5.3.1" style="background-color:#E6E6E6;">30.1</span></td>
<td class="ltx_td ltx_align_center" id="S7.T16.1.5.5.4"><span class="ltx_text ltx_font_bold" id="S7.T16.1.5.5.4.1" style="background-color:#E6E6E6;">33.1</span></td>
</tr>
<tr class="ltx_tr" id="S7.T16.1.6.6">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="4" id="S7.T16.1.6.6.1"><span class="ltx_text ltx_font_bold" id="S7.T16.1.6.6.1.1">6B+ Models</span></th>
</tr>
<tr class="ltx_tr" id="S7.T16.1.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S7.T16.1.7.7.1">DS-Coder-6.7B-Instruct</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S7.T16.1.7.7.2">6.7B</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T16.1.7.7.3">34.6*</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T16.1.7.7.4">42.1*</td>
</tr>
<tr class="ltx_tr" id="S7.T16.1.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S7.T16.1.8.8.1">DS-Coder-V2-Lite-Instruct</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S7.T16.1.8.8.2">2.4/16B</th>
<td class="ltx_td ltx_align_center" id="S7.T16.1.8.8.3">48.9*</td>
<td class="ltx_td ltx_align_center" id="S7.T16.1.8.8.4">55.6*</td>
</tr>
<tr class="ltx_tr" id="S7.T16.1.9.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S7.T16.1.9.9.1">CodeQwen1.5-7B-Chat</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S7.T16.1.9.9.2">7B</th>
<td class="ltx_td ltx_align_center" id="S7.T16.1.9.9.3">23.3</td>
<td class="ltx_td ltx_align_center" id="S7.T16.1.9.9.4">33.1</td>
</tr>
<tr class="ltx_tr" id="S7.T16.1.10.10" style="background-color:#E6E6E6;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S7.T16.1.10.10.1"><span class="ltx_text ltx_font_bold" id="S7.T16.1.10.10.1.1" style="background-color:#E6E6E6;">Qwen2.5-Coder-7B-Instruct</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S7.T16.1.10.10.2"><span class="ltx_text" id="S7.T16.1.10.10.2.1" style="background-color:#E6E6E6;">7B</span></th>
<td class="ltx_td ltx_align_center" id="S7.T16.1.10.10.3"><span class="ltx_text ltx_font_bold" id="S7.T16.1.10.10.3.1" style="background-color:#E6E6E6;">50.4</span></td>
<td class="ltx_td ltx_align_center" id="S7.T16.1.10.10.4"><span class="ltx_text ltx_font_bold" id="S7.T16.1.10.10.4.1" style="background-color:#E6E6E6;">57.1</span></td>
</tr>
<tr class="ltx_tr" id="S7.T16.1.11.11">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="4" id="S7.T16.1.11.11.1"><span class="ltx_text ltx_font_bold" id="S7.T16.1.11.11.1.1">20B+ Models</span></th>
</tr>
<tr class="ltx_tr" id="S7.T16.1.12.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S7.T16.1.12.12.1"><span class="ltx_text" id="S7.T16.1.12.12.1.1" style="color:#999999;">CodeStral-22B</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S7.T16.1.12.12.2"><span class="ltx_text" id="S7.T16.1.12.12.2.1" style="color:#999999;">22B</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T16.1.12.12.3"><span class="ltx_text" id="S7.T16.1.12.12.3.1" style="color:#999999;">35.3*</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T16.1.12.12.4"><span class="ltx_text" id="S7.T16.1.12.12.4.1" style="color:#999999;">45.1*</span></td>
</tr>
<tr class="ltx_tr" id="S7.T16.1.13.13">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S7.T16.1.13.13.1"><span class="ltx_text" id="S7.T16.1.13.13.1.1" style="color:#999999;">DS-Coder-33B-Instruct</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S7.T16.1.13.13.2"><span class="ltx_text" id="S7.T16.1.13.13.2.1" style="color:#999999;">33B</span></th>
<td class="ltx_td ltx_align_center" id="S7.T16.1.13.13.3"><span class="ltx_text" id="S7.T16.1.13.13.3.1" style="color:#999999;">49.6*</span></td>
<td class="ltx_td ltx_align_center" id="S7.T16.1.13.13.4"><span class="ltx_text" id="S7.T16.1.13.13.4.1" style="color:#999999;">59.4*</span></td>
</tr>
<tr class="ltx_tr" id="S7.T16.1.14.14">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S7.T16.1.14.14.1"><span class="ltx_text" id="S7.T16.1.14.14.1.1" style="color:#999999;">DS-Coder-V2-Instruct</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S7.T16.1.14.14.2"><span class="ltx_text" id="S7.T16.1.14.14.2.1" style="color:#999999;">21/236B</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S7.T16.1.14.14.3"><span class="ltx_text" id="S7.T16.1.14.14.3.1" style="color:#999999;">73.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S7.T16.1.14.14.4"><span class="ltx_text" id="S7.T16.1.14.14.4.1" style="color:#999999;">-</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 16: </span>
The code editing ability of different instruct models evaluated by Aider benchmark. * indicates that the experimental results have been reproduced in our experiments, and the <em class="ltx_emph ltx_font_italic" id="S7.T16.3.1">whole</em> edit-format was consistently applied across all experiments.
</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S7.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.3 </span>Code Editing</h3>
<div class="ltx_para ltx_noindent" id="S7.SS3.p1">
<p class="ltx_p" id="S7.SS3.p1.1">Aider<span class="ltx_note ltx_role_footnote" id="footnote8"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/paul-gauthier/aider" title="">https://github.com/paul-gauthier/aider</a></span></span></span> has created a code editing benchmark designed to quantitatively measure its collaboration with large language models (LLMs). Drawing from a set of 133 Python exercises sourced from Exercism<span class="ltx_note ltx_role_footnote" id="footnote9"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/exercism/python" title="">https://github.com/exercism/python</a></span></span></span>, the benchmark tests the ability of Aider and LLMs to interpret natural language programming requests and translate them into executable code that successfully passes unit tests. This assessment goes beyond evaluating raw coding proficiency; it also examines how effectively LLMs can edit existing code and format those modifications for seamless integration with Aider’s system, ensuring that local source files can be updated without issues. The comprehensive nature of this benchmark reflects both the technical aptitude of the LLMs and their consistency in task completion.</p>
</div>
<div class="ltx_para ltx_noindent" id="S7.SS3.p2">
<p class="ltx_p" id="S7.SS3.p2.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S7.T16" title="Table 16 ‣ 7.2 Code Reasoning ‣ 7 Evaluation on Instruct Models ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_tag">16</span></a> highlights the performance of several language models in the Code Editing task. Among them, Qwen2.5-Coder-7B-Instruct demonstrates outstanding code repair capabilities. Despite its relatively modest size of 7 billion parameters, it achieves an impressive PASS@1 accuracy of 50.4%, significantly outperforming comparable models. Notably, it also surpasses larger models such as CodeStral-22B (22 billion parameters) and DS-Coder-33B-Instruct (33 billion parameters), showcasing its remarkable efficiency and effectiveness in code editing tasks.</p>
</div>
</section>
<section class="ltx_subsection" id="S7.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.4 </span>Text-to-SQL</h3>
<div class="ltx_para ltx_noindent" id="S7.SS4.p1">
<p class="ltx_p" id="S7.SS4.p1.1">SQL is one of the essential tools in daily software development and production, but its steep learning curve often hinders free interaction between non-programming experts and databases. To address this issue, the Text-to-SQL task was introduced, aiming for models to automatically map natural language questions to structured SQL queries. Previous improvements in Text-to-SQL focused primarily on structure-aware learning, domain-specific pre-training, and sophisticated prompt designs.</p>
</div>
<figure class="ltx_figure" id="S7.F8"><code class="ltx_verbatim" id="S7.F8.1"> <svg class="ltx_picture" height="256.1" id="S7.F8.1.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,256.1) matrix(1 0 0 -1 0 0)"><g fill="#000000" fill-opacity="1.0"><path d="M 0 3.15 L 0 252.95 C 0 254.69 1.41 256.1 3.15 256.1 L 596.85 256.1 C 598.59 256.1 600 254.69 600 252.95 L 600 3.15 C 600 1.41 598.59 0 596.85 0 L 3.15 0 C 1.41 0 0 1.41 0 3.15 Z" style="stroke:none"></path></g><g fill="#FFFFFF" fill-opacity="1.0"><path d="M 1.18 3.15 L 1.18 233.56 L 598.82 233.56 L 598.82 3.15 C 598.82 2.06 597.94 1.18 596.85 1.18 L 3.15 1.18 C 2.06 1.18 1.18 2.06 1.18 3.15 Z" style="stroke:none"></path></g><g fill="#B3B3FF" fill-opacity="1.0"><path d="M 1.18 234.74 L 1.18 252.95 C 1.18 254.03 2.06 254.91 3.15 254.91 L 596.85 254.91 C 597.94 254.91 598.82 254.03 598.82 252.95 L 598.82 234.74 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 9.06 238.68)"><foreignobject color="#000000" height="12.3" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="581.89">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="S7.F8.1.pic1.2.2.2.1.1" style="width:420.5pt;">
<span class="ltx_p" id="S7.F8.1.pic1.2.2.2.1.1.1"><span class="ltx_text ltx_font_bold" id="S7.F8.1.pic1.2.2.2.1.1.1.1">Prompt template for text-to-SQL tasks.</span></span>
</span></foreignobject></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 9.06 5.12)"><foreignobject color="#000000" height="224.51" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="581.89"><span class="ltx_inline-logical-block ltx_minipage ltx_align_bottom" id="S7.F8.1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1" style="width:420.5pt;">
<span class="ltx_float ltx_lstlisting" id="S7.F8.1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.tab1">
<span class="ltx_listing ltx_lstlisting ltx_listing" id="S7.F8.1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.tab1.1">
</span>
</span></span></foreignobject></g></g></svg>
</code>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Prompt template of Qwen2.5-Coder for text-to-SQL tasks.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S7.SS4.p2">
<p class="ltx_p" id="S7.SS4.p2.1">Thanks to the use of finely crafted synthetic data during both pre-training and fine-tuning, we significantly enhanced Qwen2.5-Coder’s capability in Text-to-SQL tasks. We selected two well-known benchmarks, Spider <cite class="ltx_cite ltx_citemacro_citep">(Yu et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#bib.bib37" title="">2018</a>)</cite> and BIRD <cite class="ltx_cite ltx_citemacro_citep">(Li et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#bib.bib24" title="">2024</a>)</cite>, for comprehensive evaluation.
To ensure a fair comparison between Qwen2.5-Coder and other open-source language models on this task, we used a unified prompt template as input, following the work of <cite class="ltx_cite ltx_citemacro_citet">Chang &amp; Fosler-Lussier (<a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#bib.bib11" title="">2023</a>)</cite>. As shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S7.F8" title="Figure 8 ‣ 7.4 Text-to-SQL ‣ 7 Evaluation on Instruct Models ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_tag">8</span></a>, the prompt consists of table representations aligned with database instructions, examples of table content, optional additional knowledge, and natural language questions. This standardized prompt template minimizes biases that may arise from prompt variations. As shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S7.F9" title="Figure 9 ‣ 7.4 Text-to-SQL ‣ 7 Evaluation on Instruct Models ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_tag">9</span></a>, Qwen2.5-Coder outperforms other code models of the same size on the Text-to-SQL task.</p>
</div>
<figure class="ltx_figure" id="S7.F9"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="242" id="S7.F9.g1" src="x9.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>The text-to-SQL evaluation on various instruct code models.</figcaption>
</figure>
<figure class="ltx_table" id="S7.T17">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S7.T17.1" style="width:397.5pt;height:78.5pt;vertical-align:-0.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-77.3pt,15.1pt) scale(0.719971457158334,0.719971457158334) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S7.T17.1.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S7.T17.1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="S7.T17.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S7.T17.1.1.1.1.1.1">Model</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_tt" id="S7.T17.1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S7.T17.1.1.1.1.2.1">Size</span></th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S7.T17.1.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S7.T17.1.1.1.1.3.1">MATH</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S7.T17.1.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S7.T17.1.1.1.1.4.1">GSM8K</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S7.T17.1.1.1.1.5"><span class="ltx_text ltx_font_bold" id="S7.T17.1.1.1.1.5.1">GaoKao2023en</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S7.T17.1.1.1.1.6"><span class="ltx_text ltx_font_bold" id="S7.T17.1.1.1.1.6.1">OlympiadBench</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S7.T17.1.1.1.1.7"><span class="ltx_text ltx_font_bold" id="S7.T17.1.1.1.1.7.1">CollegeMath</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S7.T17.1.1.1.1.8"><span class="ltx_text ltx_font_bold" id="S7.T17.1.1.1.1.8.1">AIME24</span></td>
</tr>
<tr class="ltx_tr" id="S7.T17.1.1.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S7.T17.1.1.2.2.1">DS-Coder-V2-Lite-Instruct</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S7.T17.1.1.2.2.2">2.4/16B</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T17.1.1.2.2.3">61.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T17.1.1.2.2.4"><span class="ltx_text ltx_font_bold" id="S7.T17.1.1.2.2.4.1">87.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T17.1.1.2.2.5">56.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T17.1.1.2.2.6">26.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T17.1.1.2.2.7">39.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T17.1.1.2.2.8">6.7</td>
</tr>
<tr class="ltx_tr" id="S7.T17.1.1.3.3" style="background-color:#E6E6E6;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S7.T17.1.1.3.3.1"><span class="ltx_text ltx_font_bold" id="S7.T17.1.1.3.3.1.1" style="background-color:#E6E6E6;">Qwen2.5-Coder-7B-Instruct</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r" id="S7.T17.1.1.3.3.2"><span class="ltx_text" id="S7.T17.1.1.3.3.2.1" style="background-color:#E6E6E6;">7B</span></th>
<td class="ltx_td ltx_align_center" id="S7.T17.1.1.3.3.3"><span class="ltx_text ltx_font_bold" id="S7.T17.1.1.3.3.3.1" style="background-color:#E6E6E6;">66.8</span></td>
<td class="ltx_td ltx_align_center" id="S7.T17.1.1.3.3.4"><span class="ltx_text" id="S7.T17.1.1.3.3.4.1" style="background-color:#E6E6E6;">86.7</span></td>
<td class="ltx_td ltx_align_center" id="S7.T17.1.1.3.3.5"><span class="ltx_text ltx_font_bold" id="S7.T17.1.1.3.3.5.1" style="background-color:#E6E6E6;">60.5</span></td>
<td class="ltx_td ltx_align_center" id="S7.T17.1.1.3.3.6"><span class="ltx_text ltx_font_bold" id="S7.T17.1.1.3.3.6.1" style="background-color:#E6E6E6;">29.8</span></td>
<td class="ltx_td ltx_align_center" id="S7.T17.1.1.3.3.7"><span class="ltx_text ltx_font_bold" id="S7.T17.1.1.3.3.7.1" style="background-color:#E6E6E6;">43.5</span></td>
<td class="ltx_td ltx_align_center" id="S7.T17.1.1.3.3.8"><span class="ltx_text ltx_font_bold" id="S7.T17.1.1.3.3.8.1" style="background-color:#E6E6E6;">10.0</span></td>
</tr>
<tr class="ltx_tr" id="S7.T17.1.1.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt ltx_border_tt" id="S7.T17.1.1.4.4.1"><span class="ltx_text ltx_font_bold" id="S7.T17.1.1.4.4.1.1">Model</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_tt ltx_border_tt" id="S7.T17.1.1.4.4.2"><span class="ltx_text ltx_font_bold" id="S7.T17.1.1.4.4.2.1">Size</span></th>
<td class="ltx_td ltx_align_center ltx_border_tt ltx_border_tt" id="S7.T17.1.1.4.4.3"><span class="ltx_text ltx_font_bold" id="S7.T17.1.1.4.4.3.1">AMC23</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt ltx_border_tt" id="S7.T17.1.1.4.4.4"><span class="ltx_text ltx_font_bold" id="S7.T17.1.1.4.4.4.1">MMLU</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt ltx_border_tt" id="S7.T17.1.1.4.4.5"><span class="ltx_text ltx_font_bold" id="S7.T17.1.1.4.4.5.1">MMLU-Pro</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt ltx_border_tt" id="S7.T17.1.1.4.4.6"><span class="ltx_text ltx_font_bold" id="S7.T17.1.1.4.4.6.1">IFEval</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt ltx_border_tt" id="S7.T17.1.1.4.4.7"><span class="ltx_text ltx_font_bold" id="S7.T17.1.1.4.4.7.1">CEval</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt ltx_border_tt" id="S7.T17.1.1.4.4.8"><span class="ltx_text ltx_font_bold" id="S7.T17.1.1.4.4.8.1">GPQA</span></td>
</tr>
<tr class="ltx_tr" id="S7.T17.1.1.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S7.T17.1.1.5.5.1">DS-Coder-V2-Lite-Instruct</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S7.T17.1.1.5.5.2">2.4/16B</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T17.1.1.5.5.3">40.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T17.1.1.5.5.4">42.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T17.1.1.5.5.5">60.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T17.1.1.5.5.6">38.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T17.1.1.5.5.7">60.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S7.T17.1.1.5.5.8">27.6</td>
</tr>
<tr class="ltx_tr" id="S7.T17.1.1.6.6" style="background-color:#E6E6E6;">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S7.T17.1.1.6.6.1"><span class="ltx_text ltx_font_bold" id="S7.T17.1.1.6.6.1.1" style="background-color:#E6E6E6;">Qwen2.5-Coder-7B-Instruct</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S7.T17.1.1.6.6.2"><span class="ltx_text" id="S7.T17.1.1.6.6.2.1" style="background-color:#E6E6E6;">7B</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S7.T17.1.1.6.6.3"><span class="ltx_text ltx_font_bold" id="S7.T17.1.1.6.6.3.1" style="background-color:#E6E6E6;">42.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S7.T17.1.1.6.6.4"><span class="ltx_text ltx_font_bold" id="S7.T17.1.1.6.6.4.1" style="background-color:#E6E6E6;">45.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S7.T17.1.1.6.6.5"><span class="ltx_text ltx_font_bold" id="S7.T17.1.1.6.6.5.1" style="background-color:#E6E6E6;">68.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S7.T17.1.1.6.6.6"><span class="ltx_text ltx_font_bold" id="S7.T17.1.1.6.6.6.1" style="background-color:#E6E6E6;">58.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S7.T17.1.1.6.6.7"><span class="ltx_text ltx_font_bold" id="S7.T17.1.1.6.6.7.1" style="background-color:#E6E6E6;">61.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S7.T17.1.1.6.6.8"><span class="ltx_text ltx_font_bold" id="S7.T17.1.1.6.6.8.1" style="background-color:#E6E6E6;">35.6</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 17: </span>The performance of math and General.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S7.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.5 </span>Math Reasoning and General Natural Language</h3>
<div class="ltx_para ltx_noindent" id="S7.SS5.p1">
<p class="ltx_p" id="S7.SS5.p1.1">In this section, we present a comparative analysis of the performance between our Qwen2.5-Coder-7B-Instruct model and the DS-Coder-V2-Lite-Instruct model, focusing on both mathematical computation and general natural language processing tasks. As indicated in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.12186v1#S7.T17" title="Table 17 ‣ 7.4 Text-to-SQL ‣ 7 Evaluation on Instruct Models ‣ Qwen2.5-Coder Technical Report"><span class="ltx_text ltx_ref_tag">17</span></a>, the Qwen2.5-Coder-7B-Instruct model outperforms the DS-Coder-V2-Lite-Instruct in 11 out of 12 tasks. This result underscores the model’s versatility, excelling not only in complex coding tasks but also in sophisticated general tasks, thus distinguishing it from its competitors.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S8">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8 </span>Conclusion</h2>
<div class="ltx_para ltx_noindent" id="S8.p1">
<p class="ltx_p" id="S8.p1.1">This work introduces Qwen2.5-Coder, the latest addition to the Qwen series. Built upon Qwen2.5, a top-tier open-source LLM, Qwen2.5-Coder has been developed through extensive pre-training and post-training of Qwen2.5-1.5B and Qwen2.5-7B on large-scale datasets. To ensure the quality of the pre-training data, we have curated a dataset by collecting public code data and extracting high-quality code-related content from web texts, while filtering out low-quality data using advanced classifiers. Additionally, we have constructed a meticulously designed instruction-tuning dataset to transform the base code LLM into a strong coding assistant.</p>
</div>
<div class="ltx_para ltx_noindent" id="S8.p2">
<p class="ltx_p" id="S8.p2.1">Looking ahead, our research will focus on exploring the impact of scaling up code LLMs in terms of both data size and model size. We will also continue to enhance the reasoning capabilities of these models, aiming to push the boundaries of what code LLMs can achieve.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Achiam et al. (2023)</span>
<span class="ltx_bibblock">
Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al.

</span>
<span class="ltx_bibblock">Gpt-4 technical report.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">arXiv preprint arXiv:2303.08774</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Allal et al. (2023)</span>
<span class="ltx_bibblock">
Loubna Ben Allal, Raymond Li, Denis Kocetkov, Chenghao Mou, Christopher Akiki, Carlos Munoz Ferrandis, Niklas Muennighoff, Mayank Mishra, Alex Gu, Manan Dey, et al.

</span>
<span class="ltx_bibblock">Santacoder: don’t reach for the stars!

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">arXiv preprint arXiv:2301.03988</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Anthropic (2024)</span>
<span class="ltx_bibblock">
Anthropic.

</span>
<span class="ltx_bibblock">Claude 3.5 sonnet.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.anthropic.com/news/claude-3-5-sonnet" title="">https://www.anthropic.com/news/claude-3-5-sonnet</a>, 2024.

</span>
<span class="ltx_bibblock">2024.06.21.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Austin et al. (2021)</span>
<span class="ltx_bibblock">
Jacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma, Henryk Michalewski, David Dohan, Ellen Jiang, Carrie Cai, Michael Terry, Quoc Le, et al.

</span>
<span class="ltx_bibblock">Program synthesis with large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">arXiv preprint arXiv:2108.07732</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bai et al. (2023a)</span>
<span class="ltx_bibblock">
Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong Deng, Yang Fan, Wenbin Ge, Yu Han, Fei Huang, et al.

</span>
<span class="ltx_bibblock">Qwen technical report.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">arXiv preprint arXiv:2309.16609</em>, 2023a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bai et al. (2023b)</span>
<span class="ltx_bibblock">
Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong Deng, Yang Fan, Wenbin Ge, Yu Han, Fei Huang, et al.

</span>
<span class="ltx_bibblock">Qwen technical report.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">arXiv preprint arXiv:2309.16609</em>, 2023b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bavarian et al. (2022)</span>
<span class="ltx_bibblock">
Mohammad Bavarian, Heewoo Jun, Nikolas Tezak, John Schulman, Christine McLeavey, Jerry Tworek, and Mark Chen.

</span>
<span class="ltx_bibblock">Efficient training of language models to fill in the middle.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">arXiv preprint arXiv:2207.14255</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown (2020)</span>
<span class="ltx_bibblock">
Tom B Brown.

</span>
<span class="ltx_bibblock">Language models are few-shot learners.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">arXiv preprint arXiv:2005.14165</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cassano et al. (2022)</span>
<span class="ltx_bibblock">
Federico Cassano, John Gouwar, Daniel Nguyen, Sydney Nguyen, Luna Phipps-Costin, Donald Pinckney, Ming-Ho Yee, Yangtian Zi, Carolyn Jane Anderson, Molly Q Feldman, et al.

</span>
<span class="ltx_bibblock">Multipl-e: A scalable and extensible approach to benchmarking neural code generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">arXiv preprint arXiv:2208.08227</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chai et al. (2024)</span>
<span class="ltx_bibblock">
Linzheng Chai, Shukai Liu, Jian Yang, Yuwei Yin, Ke Jin, Jiaheng Liu, Tao Sun, Ge Zhang, Changyu Ren, Hongcheng Guo, et al.

</span>
<span class="ltx_bibblock">Mceval: Massively multilingual code evaluation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">arXiv preprint arXiv:2406.07436</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chang &amp; Fosler-Lussier (2023)</span>
<span class="ltx_bibblock">
Shuaichen Chang and Eric Fosler-Lussier.

</span>
<span class="ltx_bibblock">How to prompt llms for text-to-sql: A study in zero-shot, single-domain, and cross-domain settings.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">arXiv preprint arXiv:2305.11853</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2021)</span>
<span class="ltx_bibblock">
Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde De Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al.

</span>
<span class="ltx_bibblock">Evaluating large language models trained on code.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">arXiv preprint arXiv:2107.03374</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2023)</span>
<span class="ltx_bibblock">
Wenhu Chen, Ming Yin, Max Ku, Pan Lu, Yixin Wan, Xueguang Ma, Jianyu Xu, Xinyi Wang, and Tony Xia.

</span>
<span class="ltx_bibblock">Theoremqa: A theorem-driven question answering dataset.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</em>, pp.  7889–7901, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Clark et al. (2018)</span>
<span class="ltx_bibblock">
Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Carissa Schoenick, and Oyvind Tafjord.

</span>
<span class="ltx_bibblock">Think you have solved question answering? try arc, the ai2 reasoning challenge.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">arXiv preprint arXiv:1803.05457</em>, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cobbe et al. (2021)</span>
<span class="ltx_bibblock">
Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et al.

</span>
<span class="ltx_bibblock">Training verifiers to solve math word problems.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">arXiv preprint arXiv:2110.14168</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dubey et al. (2024)</span>
<span class="ltx_bibblock">
Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, et al.

</span>
<span class="ltx_bibblock">The llama 3 herd of models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">arXiv preprint arXiv:2407.21783</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gema et al. (2024)</span>
<span class="ltx_bibblock">
Aryo Pradipta Gema, Joshua Ong Jun Leang, Giwon Hong, Alessio Devoto, Alberto Carlo Maria Mancino, Rohit Saxena, Xuanli He, Yu Zhao, Xiaotang Du, Mohammad Reza Ghasemi Madani, et al.

</span>
<span class="ltx_bibblock">Are we done with mmlu?

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">arXiv preprint arXiv:2406.04127</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gu et al. (2024)</span>
<span class="ltx_bibblock">
Alex Gu, Baptiste Rozière, Hugh Leather, Armando Solar-Lezama, Gabriel Synnaeve, and Sida I Wang.

</span>
<span class="ltx_bibblock">Cruxeval: A benchmark for code reasoning, understanding and execution.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">arXiv preprint arXiv:2401.03065</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guo et al. (2024)</span>
<span class="ltx_bibblock">
Daya Guo, Qihao Zhu, Dejian Yang, Zhenda Xie, Kai Dong, Wentao Zhang, Guanting Chen, Xiao Bi, Yu Wu, YK Li, et al.

</span>
<span class="ltx_bibblock">Deepseek-coder: When the large language model meets programming–the rise of code intelligence.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">arXiv preprint arXiv:2401.14196</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hendrycks et al. (2020)</span>
<span class="ltx_bibblock">
Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt.

</span>
<span class="ltx_bibblock">Measuring massive multitask language understanding.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">arXiv preprint arXiv:2009.03300</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hendrycks et al. (2021)</span>
<span class="ltx_bibblock">
Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, and Jacob Steinhardt.

</span>
<span class="ltx_bibblock">Measuring mathematical problem solving with the math dataset.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">arXiv preprint arXiv:2103.03874</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jain et al. (2024)</span>
<span class="ltx_bibblock">
Naman Jain, King Han, Alex Gu, Wen-Ding Li, Fanjia Yan, Tianjun Zhang, Sida Wang, Armando Solar-Lezama, Koushik Sen, and Ion Stoica.

</span>
<span class="ltx_bibblock">Livecodebench: Holistic and contamination free evaluation of large language models for code.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">arXiv preprint arXiv:2403.07974</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et al. (2023)</span>
<span class="ltx_bibblock">
AQ Jiang, A Sablayrolles, A Mensch, C Bamford, DS Chaplot, D de las Casas, F Bressand, G Lengyel, G Lample, L Saulnier, et al.

</span>
<span class="ltx_bibblock">Mistral 7b (2023).

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">arXiv preprint arXiv:2310.06825</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2024)</span>
<span class="ltx_bibblock">
Jinyang Li, Binyuan Hui, Ge Qu, Jiaxi Yang, Binhua Li, Bowen Li, Bailin Wang, Bowen Qin, Ruiying Geng, Nan Huo, et al.

</span>
<span class="ltx_bibblock">Can llm already serve as a database interface? a big bench for large-scale database grounded text-to-sqls.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">Advances in Neural Information Processing Systems</em>, 36, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2023)</span>
<span class="ltx_bibblock">
Raymond Li, Loubna Ben Allal, Yangtian Zi, Niklas Muennighoff, Denis Kocetkov, Chenghao Mou, Marc Marone, Christopher Akiki, Jia Li, Jenny Chim, et al.

</span>
<span class="ltx_bibblock">Starcoder: may the source be with you!

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">arXiv preprint arXiv:2305.06161</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et al. (2021)</span>
<span class="ltx_bibblock">
Stephanie Lin, Jacob Hilton, and Owain Evans.

</span>
<span class="ltx_bibblock">Truthfulqa: Measuring how models mimic human falsehoods.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">arXiv preprint arXiv:2109.07958</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2023)</span>
<span class="ltx_bibblock">
J Liu, CS Xia, Y Wang, and L Zhang.

</span>
<span class="ltx_bibblock">Is your code generated by chatgpt really correct? rigorous evaluation of large language models for code generation. arxiv preprint arxiv: 230501210. 2023, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lozhkov et al. (2024)</span>
<span class="ltx_bibblock">
Anton Lozhkov, Raymond Li, Loubna Ben Allal, Federico Cassano, Joel Lamy-Poirier, Nouamane Tazi, Ao Tang, Dmytro Pykhtar, Jiawei Liu, Yuxiang Wei, et al.

</span>
<span class="ltx_bibblock">Starcoder 2 and the stack v2: The next generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">arXiv preprint arXiv:2402.19173</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2024)</span>
<span class="ltx_bibblock">
OpenAI.

</span>
<span class="ltx_bibblock">Gpt-4o.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openai.com/index/hello-gpt-4o" title="">https://openai.com/index/hello-gpt-4o</a>, 2024.

</span>
<span class="ltx_bibblock">2024.05.13.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Peng et al. (2023)</span>
<span class="ltx_bibblock">
Bowen Peng, Jeffrey Quesnelle, Honglu Fan, and Enrico Shippole.

</span>
<span class="ltx_bibblock">Yarn: Efficient context window extension of large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">arXiv preprint arXiv:2309.00071</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Roziere et al. (2023)</span>
<span class="ltx_bibblock">
Baptiste Roziere, Jonas Gehring, Fabian Gloeckle, Sten Sootla, Itai Gat, Xiaoqing Ellen Tan, Yossi Adi, Jingyu Liu, Romain Sauvestre, Tal Remez, et al.

</span>
<span class="ltx_bibblock">Code llama: Open foundation models for code.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">arXiv preprint arXiv:2308.12950</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sakaguchi et al. (2019)</span>
<span class="ltx_bibblock">
Keisuke Sakaguchi, Ronan Le Bras, Chandra Bhagavatula, and Yejin Choi.

</span>
<span class="ltx_bibblock">An adversarial winograd schema challenge at scale.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">arXiv preprint arXiv:1907.10641</em>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et al. (2024)</span>
<span class="ltx_bibblock">
Tao Sun, Linzheng Chai, Jian Yang, Yuwei Yin, Hongcheng Guo, Jiaheng Liu, Bing Wang, Liqun Yang, and Zhoujun Li.

</span>
<span class="ltx_bibblock">Unicoder: Scaling code large language model via universal code.

</span>
<span class="ltx_bibblock">In Lun-Wei Ku, Andre Martins, and Vivek Srikumar (eds.), <em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2024, Bangkok, Thailand, August 11-16, 2024</em>, pp.  1812–1824. Association for Computational Linguistics, 2024.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2024.acl-long.100" title="">https://aclanthology.org/2024.acl-long.100</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">team (2024)</span>
<span class="ltx_bibblock">
Mistral AI team.

</span>
<span class="ltx_bibblock">Codestral.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://mistral.ai/news/codestral" title="">https://mistral.ai/news/codestral</a>, 2024.

</span>
<span class="ltx_bibblock">2024.05.29.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et al. (2023)</span>
<span class="ltx_bibblock">
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al.

</span>
<span class="ltx_bibblock">Llama 2: Open foundation and fine-tuned chat models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">arXiv preprint arXiv:2307.09288</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al. (2024)</span>
<span class="ltx_bibblock">
An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li, Chengyuan Li, Dayiheng Liu, Fei Huang, et al.

</span>
<span class="ltx_bibblock">Qwen2 technical report.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">arXiv preprint arXiv:2407.10671</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al. (2018)</span>
<span class="ltx_bibblock">
Tao Yu, Rui Zhang, Kai Yang, Michihiro Yasunaga, Dongxu Wang, Zifan Li, James Ma, Irene Li, Qingning Yao, Shanelle Roman, et al.

</span>
<span class="ltx_bibblock">Spider: A large-scale human-labeled dataset for complex and cross-domain semantic parsing and text-to-sql task.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">arXiv preprint arXiv:1809.08887</em>, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zellers et al. (2019)</span>
<span class="ltx_bibblock">
Rowan Zellers, Ari Holtzman, Yonatan Bisk, Ali Farhadi, and Yejin Choi.

</span>
<span class="ltx_bibblock">Hellaswag: Can a machine really finish your sentence?

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">arXiv preprint arXiv:1905.07830</em>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhuo et al. (2024)</span>
<span class="ltx_bibblock">
Terry Yue Zhuo, Minh Chien Vu, Jenny Chim, Han Hu, Wenhao Yu, Ratnadira Widyasari, Imam Nur Bani Yusuf, Haolan Zhan, Junda He, Indraneil Paul, et al.

</span>
<span class="ltx_bibblock">Bigcodebench: Benchmarking code generation with diverse function calls and complex instructions.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">arXiv preprint arXiv:2406.15877</em>, 2024.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Wed Sep 18 17:57:22 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
