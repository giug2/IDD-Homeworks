<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2211.16971] A Pipeline for Generating, Annotating and Employing Synthetic Data for Real World Question Answering</title><meta property="og:description" content="Question Answering (QA) is a growing area of research, often used to facilitate the extraction of information from within documents. State-of-the-art QA models are usually pre-trained on domain-general corpora like Wik…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="A Pipeline for Generating, Annotating and Employing Synthetic Data for Real World Question Answering">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="A Pipeline for Generating, Annotating and Employing Synthetic Data for Real World Question Answering">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2211.16971">

<!--Generated on Thu Mar 14 07:19:50 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">A Pipeline for Generating, Annotating and Employing Synthetic Data for Real World Question Answering</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Matt Maufe 
<br class="ltx_break">Filament AI, UK
<br class="ltx_break">University of Warwick, UK 
<br class="ltx_break"><span id="id1.1.id1" class="ltx_text ltx_font_typewriter">matt.maufe@filament.ai</span>    
<br class="ltx_break"><span id="id2.2.id2" class="ltx_ERROR undefined">\And</span>James Ravenscroft 
<br class="ltx_break">Filament AI, UK
<br class="ltx_break">University of Warwick, UK 
<br class="ltx_break"><span id="id3.3.id3" class="ltx_text ltx_font_typewriter">james.ravenscroft@filament.ai</span> 
<br class="ltx_break"><span id="id4.4.id4" class="ltx_ERROR undefined">\AND</span>Rob Procter 
<br class="ltx_break">University of Warwick, UK 
<br class="ltx_break">The Alan Turing Institute, UK 
<br class="ltx_break"><span id="id5.5.id5" class="ltx_text ltx_font_typewriter">Rob.Procter@warwick.ac.uk</span> 
<br class="ltx_break"><span id="id6.6.id6" class="ltx_ERROR undefined">\And</span>Maria Liakata 
<br class="ltx_break">Queen Mary University of London, UK 
<br class="ltx_break">The Alan Turing Institute, UK 
<br class="ltx_break"><span id="id7.7.id7" class="ltx_text ltx_font_typewriter">m.liakata@qmul.ac.uk</span> 
<br class="ltx_break">
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id8.id1" class="ltx_p">Question Answering (QA) is a growing area of research, often used to facilitate the extraction of information from within documents. State-of-the-art QA models are usually pre-trained on domain-general corpora like Wikipedia and thus tend to struggle on out-of-domain documents without fine-tuning. We demonstrate that synthetic domain-specific datasets can be generated easily using domain-general models, while still providing significant improvements to QA performance. We present two new tools for this task: A flexible pipeline for validating the synthetic QA data and training downstream models on it, and an online interface to facilitate human annotation of this generated data. Using this interface, crowdworkers labelled 1117 synthetic QA pairs, which we then used to fine-tune downstream models and improve domain-specific QA performance by 8.75 F1.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Having enough relevant training data is a key factor for achieving strong performance in machine learning and NLP <cite class="ltx_cite ltx_citemacro_cite">Hoffmann et al. (<a href="#bib.bib12" title="" class="ltx_ref">2022</a>)</cite>, but for many tasks, large domain-specific datasets are expensive and time-consuming to create manually. This is especially true for tasks like Extractive Question Answering (QA), which both relies on domain-specific knowledge and requires skilled annotators.
These difficulties have led to increased interest in synthetic data generation recently <cite class="ltx_cite ltx_citemacro_cite">Feng et al. (<a href="#bib.bib9" title="" class="ltx_ref">2021</a>)</cite> through various methods such as bootstrapping from smaller datasets, or through generative models which create entirely new data.
<br class="ltx_break">
<br class="ltx_break">We make the following contributions:</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
<div id="S1.p2" class="ltx_para">
<ul id="S1.p2.1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><math id="S1.I1.i1.1.1.m1.1" class="ltx_Math" alttext="\bullet" display="inline"><semantics id="S1.I1.i1.1.1.m1.1b"><mo id="S1.I1.i1.1.1.m1.1.1" xref="S1.I1.i1.1.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S1.I1.i1.1.1.m1.1c"><ci id="S1.I1.i1.1.1.m1.1.1.cmml" xref="S1.I1.i1.1.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.I1.i1.1.1.m1.1d">\bullet</annotation></semantics></math></span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">A modular architecture-agnostic pipeline that takes as input unstructured documents and produces both synthetic QA pairs and a QA model trained on them; We show in Section <a href="#S4.SS3" title="4.3 Question Answering ‣ 4 Experiments and Results ‣ A Pipeline for Generating, Annotating and Employing Synthetic Data for Real World Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3</span></a> that using this synthetic domain-specific data allows for a dramatic improvement on the QA task compared to baseline state-of-the-art models, especially on unanswerable questions.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><math id="S1.I1.i2.1.1.m1.1" class="ltx_Math" alttext="\bullet" display="inline"><semantics id="S1.I1.i2.1.1.m1.1b"><mo id="S1.I1.i2.1.1.m1.1.1" xref="S1.I1.i2.1.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S1.I1.i2.1.1.m1.1c"><ci id="S1.I1.i2.1.1.m1.1.1.cmml" xref="S1.I1.i2.1.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.I1.i2.1.1.m1.1d">\bullet</annotation></semantics></math></span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">A web-based tool that allows annotators to label various aspects of the synthetic data with ease, alongside guidelines to help ensure consistency and quality in their labels.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><math id="S1.I1.i3.1.1.m1.1" class="ltx_Math" alttext="\bullet" display="inline"><semantics id="S1.I1.i3.1.1.m1.1b"><mo id="S1.I1.i3.1.1.m1.1.1" xref="S1.I1.i3.1.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S1.I1.i3.1.1.m1.1c"><ci id="S1.I1.i3.1.1.m1.1.1.cmml" xref="S1.I1.i3.1.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.I1.i3.1.1.m1.1d">\bullet</annotation></semantics></math></span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">We release<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a target="_blank" href="https://github.com/FilamentAI/qa-annotation" title="" class="ltx_ref ltx_href">GitHub</a></span></span></span> this annotation tool and its guidelines for general use. While we use and evaluate this pipeline in the domain of business news, the pipeline is sufficiently flexible to be applied to other domains, including potentially being applicable to abstractive QA.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Background and Related Work</h2>

<div id="S2.p1" class="ltx_para ltx_noindent">
<p id="S2.p1.1" class="ltx_p"><span id="S2.p1.1.1" class="ltx_text ltx_font_bold">Grammaticality Models</span>
allow for improving the quality of synthetic data and subsequent performance in downstream tasks by better aligning it with real user data. On benchmark datasets, such as the Corpus of Linguistic Acceptability (CoLA, <cite class="ltx_cite ltx_citemacro_citep">Warstadt et al., <a href="#bib.bib35" title="" class="ltx_ref">2019</a></cite>) which contains a wide range of examples from published linguistics literature, current state-of-the-art models <cite class="ltx_cite ltx_citemacro_cite">Sun et al. (<a href="#bib.bib31" title="" class="ltx_ref">2019</a>)</cite> can achieve a Matthew’s Correlation Coefficient score <cite class="ltx_cite ltx_citemacro_cite">Matthews (<a href="#bib.bib19" title="" class="ltx_ref">1975</a>)</cite> of approximately 0.775 <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a href="#bib.bib33" title="" class="ltx_ref">2022</a>)</cite>, exceeding human performance (0.713, <cite class="ltx_cite ltx_citemacro_citep">Warstadt et al., <a href="#bib.bib35" title="" class="ltx_ref">2019</a></cite>) in some cases, though this can vary significantly depending on the sentence’s syntactic complexity and length <cite class="ltx_cite ltx_citemacro_cite">Warstadt and Bowman (<a href="#bib.bib34" title="" class="ltx_ref">2020</a>)</cite>. 
<br class="ltx_break"></p>
</div>
<figure id="S2.F1" class="ltx_figure"><img src="/html/2211.16971/assets/High-level_Overall_Pipeline.png" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="479" height="233" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>The overall pipeline. The question generation process (blue) generates synthetic QA pairs, which are validated by the grammaticality model. The annotation tool is used to present this data to users for annotation, and the resultant labelled data is then used to fine-tune the grammaticality (red) and QA (purple) models.</figcaption>
</figure>
<div id="S2.p2" class="ltx_para ltx_noindent">
<p id="S2.p2.1" class="ltx_p"><span id="S2.p2.1.1" class="ltx_text ltx_font_bold">Synthetic NLP Data Generation</span>

Synthetic data generation is an attractive option for dataset creation, especially for domain-specific tasks. Various methods for bootstrapping from smaller datasets have been devised, such as back-translation <cite class="ltx_cite ltx_citemacro_cite">Sennrich et al. (<a href="#bib.bib29" title="" class="ltx_ref">2015</a>)</cite> and Sibylvariant transformations <cite class="ltx_cite ltx_citemacro_cite">Harel-Canada et al. (<a href="#bib.bib11" title="" class="ltx_ref">2022</a>)</cite>. Backtranslation produces paraphrases through round-trip translation, while Sibylvariant transformations modify or combine texts in predictable ways to create new data with a different label.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">Of particular interest are methods that use text generation models to create entirely new data, rather than simply paraphrasing or combining inputs predictably. A variety of these models have been used to generate new QA pairs <cite class="ltx_cite ltx_citemacro_cite">Grover et al. (<a href="#bib.bib10" title="" class="ltx_ref">2021</a>)</cite>, such as the T5 model <cite class="ltx_cite ltx_citemacro_cite">Raffel et al. (<a href="#bib.bib24" title="" class="ltx_ref">2020</a>)</cite> and BERT <cite class="ltx_cite ltx_citemacro_cite">Devlin et al. (<a href="#bib.bib8" title="" class="ltx_ref">2018</a>)</cite>.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p">Synthetic data generation can be particularly useful when fine-tuning a model on a specific domain, for which manually-curated datasets may not exist. Whilst high quality datasets such as SQuAD 2.0 <cite class="ltx_cite ltx_citemacro_cite">Rajpurkar et al. (<a href="#bib.bib25" title="" class="ltx_ref">2018</a>)</cite> do exist for QA tasks, they tend to only have general content, e.g. from Wikipedia. Thus models trained on them often struggle on more domain-specific tasks (<cite class="ltx_cite ltx_citemacro_citep">Ramponi and Plank, <a href="#bib.bib27" title="" class="ltx_ref">2020</a></cite>, see also Section <a href="#S4.SS3" title="4.3 Question Answering ‣ 4 Experiments and Results ‣ A Pipeline for Generating, Annotating and Employing Synthetic Data for Real World Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3</span></a> below).</p>
</div>
<div id="S2.p5" class="ltx_para ltx_noindent">
<p id="S2.p5.1" class="ltx_p"><span id="S2.p5.1.1" class="ltx_text ltx_font_bold">Evaluation of Synthetic QA Pairs</span> Evaluating Question Generation (QG) models can be difficult due to the nature of the problem: A good question tends to have various qualities (grammatical, answerable, non-trivial to answer, etc.) that are difficult to capture in a single metric, especially one that correlates well with human judgements <cite class="ltx_cite ltx_citemacro_cite">Hosking and Riedel (<a href="#bib.bib13" title="" class="ltx_ref">2019</a>)</cite>. Nonetheless, several metrics such as BLEU <cite class="ltx_cite ltx_citemacro_cite">Papineni et al. (<a href="#bib.bib21" title="" class="ltx_ref">2002</a>)</cite> and BERTScore <cite class="ltx_cite ltx_citemacro_cite">Zhang et al. (<a href="#bib.bib36" title="" class="ltx_ref">2020</a>)</cite> have been proposed, though they rely on having reference questions available and often do not capture whether or not the question is <em id="S2.p5.1.2" class="ltx_emph ltx_font_italic">answerable</em> <cite class="ltx_cite ltx_citemacro_cite">Nema and Khapra (<a href="#bib.bib20" title="" class="ltx_ref">2018</a>)</cite>. However, <cite class="ltx_cite ltx_citemacro_citet">Rajpurkar et al. (<a href="#bib.bib25" title="" class="ltx_ref">2018</a>)</cite> show that the use of unanswerable questions when training QA models is important for real-world performance, making it a metric of interest.</p>
</div>
<div id="S2.p6" class="ltx_para">
<p id="S2.p6.1" class="ltx_p">Round-trip evaluation, such as the methods proposed by <cite class="ltx_cite ltx_citemacro_citet">Alberti et al. (<a href="#bib.bib1" title="" class="ltx_ref">2019</a>)</cite>, allows for evaluating the generated data by checking how consistent downstream model results are when synthetic data is used as the model input, e.g. if the generated answer is found for a synthetic question when the question is input to a QA model. We adopt this approach and discuss it further in Section <a href="#S4.SS2" title="4.2 Synthetic Question-Answer Pair Generation ‣ 4 Experiments and Results ‣ A Pipeline for Generating, Annotating and Employing Synthetic Data for Real World Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>System Overview</h2>

<figure id="S3.F2" class="ltx_figure"><img src="/html/2211.16971/assets/QA_Pair_Generation.drawio.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="538" height="209" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>The question generation pipeline.</figcaption>
</figure>
<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Figure <a href="#S2.F1" title="Figure 1 ‣ 2 Background and Related Work ‣ A Pipeline for Generating, Annotating and Employing Synthetic Data for Real World Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows an overview of our system for creating domain-specific synthetic QA pairs which are used to train downstream models. The QG process (see Section <a href="#S3.SS2" title="3.2 Synthetic Question-Answer Pair Generation ‣ 3 System Overview ‣ A Pipeline for Generating, Annotating and Employing Synthetic Data for Real World Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a> for details) creates domain-specific QA pairs from unlabelled texts. This data is then annotated for grammaticality and correctness using the annotation tool, allowing for the creation of two new domain-specific datasets to fine-tune both grammaticality and QA models.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p">We take a subset of a proprietary knowledge base as our set of input documents and use this to create our domain-specific QA dataset (which we call “SYFTER”). The knowledge base contains documents obtained by scraping online articles and is focused on business news, such as information about corporate structures, and is thus quite distinct in subject matter from our external domain-general data (SQuAD 2.0, see Section <a href="#S3.SS2" title="3.2 Synthetic Question-Answer Pair Generation ‣ 3 System Overview ‣ A Pipeline for Generating, Annotating and Employing Synthetic Data for Real World Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a>).</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Grammaticality Validation</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">We use a pre-trained BERT model<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span> <a target="_blank" href="https://huggingface.co/bert-base-uncased" title="" class="ltx_ref ltx_href">bert-base-uncased</a></span></span></span> <cite class="ltx_cite ltx_citemacro_cite">Devlin et al. (<a href="#bib.bib8" title="" class="ltx_ref">2018</a>)</cite> to evaluate the grammaticality of each synthetic question and answer and we discard ungrammatical ones under the intuition that encouraging the synthetic data to be grammatically correct results in the final dataset being more similar to questions posed by real users and improved performance on the downstream task.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">We use the “in-domain” data from the Corpus of Linguistic Acceptability (CoLA, <cite class="ltx_cite ltx_citemacro_citep">Warstadt et al., <a href="#bib.bib35" title="" class="ltx_ref">2019</a></cite>) dataset to train our grammaticality model in the domain-general setting.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.1" class="ltx_p">While from a linguistic perspective <cite class="ltx_cite ltx_citemacro_cite">Lau et al. (<a href="#bib.bib16" title="" class="ltx_ref">2017</a>)</cite>, grammaticality can be seen as either a binary or a gradient feature, we use it as a binary label to better standardise with other papers and with CoLA. Furthermore, annotators are unlikely to hold consistent beliefs about the <em id="S3.SS1.p3.1.1" class="ltx_emph ltx_font_italic">degree</em> to which something is ungrammatical, given the high level of subjectivity inherent in such a judgement, and so treating it as binary reduces the potential for noise in the labels.</p>
</div>
<div id="S3.SS1.p4" class="ltx_para">
<p id="S3.SS1.p4.1" class="ltx_p">Because both the CoLA and SYFTER grammaticality datasets have a large degree of class imbalance<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>Approximately 25% and 10% ungrammatical respectively</span></span></span>, we use SMOTE <cite class="ltx_cite ltx_citemacro_cite">Chawla et al. (<a href="#bib.bib6" title="" class="ltx_ref">2002</a>)</cite> to oversample the ungrammatical instances and achieve a uniform class distribution.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Synthetic Question-Answer Pair Generation</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">The Question Generation process takes as input a natural language document (in our case, a paragraph or a single sentence) and outputs a QA pair that can be answered from this document. This is done using two models: One to select answer candidates from the document, and one that generates a question based on both the answer and the full document, for each candidate. The full process is shown in Figure <a href="#S3.F2" title="Figure 2 ‣ 3 System Overview ‣ A Pipeline for Generating, Annotating and Employing Synthetic Data for Real World Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">We extend Patil Suraj’s question-generation library <cite class="ltx_cite ltx_citemacro_cite">Patil (<a href="#bib.bib22" title="" class="ltx_ref">2022</a>)</cite> to work with any SQuAD 2.0-format dataset rather than only ones available from <a target="_blank" href="https://huggingface.co/" title="" class="ltx_ref ltx_href">HuggingFace</a>, as well as enabling it to gracefully discard invalid answers without breaking, and partially integrating it into our own pipeline.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.1" class="ltx_p">We use two separate T5 <cite class="ltx_cite ltx_citemacro_cite">Raffel et al. (<a href="#bib.bib24" title="" class="ltx_ref">2020</a>)</cite> models fine-tuned on SQuAD V1<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>Due to time constraints, we did not re-train on SQuAD 2.0, but the model performs well nonetheless (Section <a href="#S4.SS2" title="4.2 Synthetic Question-Answer Pair Generation ‣ 4 Experiments and Results ‣ A Pipeline for Generating, Annotating and Employing Synthetic Data for Real World Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>)</span></span></span> data for both answer selection and question generation<span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><a target="_blank" href="https://huggingface.co/valhalla/t5-small-qa-qg-hl" title="" class="ltx_ref ltx_href">valhalla/t5-small-qa-qg-hl</a> and <a target="_blank" href="https://huggingface.co/valhalla/t5-small-qg-hl" title="" class="ltx_ref ltx_href">valhalla/t5-base-qg-hl</a> respectively.</span></span></span>, and specify the task at inference time in natural language following the prompting paradigm <cite class="ltx_cite ltx_citemacro_cite">Brown et al. (<a href="#bib.bib4" title="" class="ltx_ref">2020</a>)</cite>. We “highlight” the answer token during question generation as described in <cite class="ltx_cite ltx_citemacro_cite">Chan and Fan (<a href="#bib.bib5" title="" class="ltx_ref">2019</a>)</cite>.<span id="footnote6" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span>E.g. “generate question: The ¡hl¿dog¡hl¿ is red”.</span></span></span> Because the underlying model is abstractive rather than extractive, it occasionally produces answer candidates that do not appear in the context and are thus unusable for extractive QA, which we discard.</p>
</div>
<div id="S3.SS2.p4" class="ltx_para">
<p id="S3.SS2.p4.1" class="ltx_p">Prior to answer selection, we filter out unsuitable input documents in two stages: We first filter out documents that are very short<span id="footnote7" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span>Less than 10 tokens</span></span></span> or which match at least one of a set of RegEx filters (see Appendix <a href="#A1" title="Appendix A RegEx Document Filters ‣ A Pipeline for Generating, Annotating and Employing Synthetic Data for Real World Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A</span></a> for details), allowing us to remove any that are clearly semantically null. We then apply a second filter using a BERT Part-of-Speech model<span id="footnote8" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span> <a target="_blank" href="https://huggingface.co/vblagoje/bert-english-uncased-finetuned-pos" title="" class="ltx_ref ltx_href">vblagoje/bert-english-uncased-finetuned-pos</a></span></span></span> such that only documents that contain a verb, or an auxiliary verb and a proper noun, are included so as to remove documents that do not present information that questions can be built around.</p>
</div>
<div id="S3.SS2.p5" class="ltx_para">
<p id="S3.SS2.p5.1" class="ltx_p">Each sentence in each filtered document is input to the answer selection model, which identifies answer candidates within them. Intuitively, a span is an answer candidate if a question can be built around it, and so the model tends to select ones representing entities or relations.</p>
</div>
<div id="S3.SS2.p6" class="ltx_para">
<p id="S3.SS2.p6.1" class="ltx_p">Questions are then generated, conditioned on each answer and the entire associated document, and if validated by the grammaticality model they are added to the synthetic QA dataset.</p>
</div>
<div id="S3.SS2.p7" class="ltx_para">
<p id="S3.SS2.p7.1" class="ltx_p">The resultant dataset can then be input directly into the annotation tool.</p>
</div>
<div id="S3.SS2.p8" class="ltx_para">
<p id="S3.SS2.p8.1" class="ltx_p">An ablation test over the filters (including the grammaticality model) can be found in Appendix <a href="#A3" title="Appendix C Question Generation Filter Ablation ‣ A Pipeline for Generating, Annotating and Employing Synthetic Data for Real World Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">C</span></a>.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Question Answering</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">We use an ALBERT <cite class="ltx_cite ltx_citemacro_cite">Lan et al. (<a href="#bib.bib15" title="" class="ltx_ref">2019</a>)</cite> Question Answering model to predict an answer represented as a span within the document, indicated by two token indices (start and end).</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.1" class="ltx_p">The model is able to provide “null answers”, indicating that the question cannot be answered, either directly or by having its prediction changed to the null answer if the null-answer’s confidence score is above a “null-answer threshold” (regardless of the original prediction’s confidence score).</p>
</div>
<div id="S3.SS3.p3" class="ltx_para">
<p id="S3.SS3.p3.1" class="ltx_p">We utilise SQuAD 2.0 <cite class="ltx_cite ltx_citemacro_cite">Rajpurkar et al. (<a href="#bib.bib25" title="" class="ltx_ref">2018</a>)</cite> for the initial fine-tuning of our QA model, as it is a large high-quality dataset containing both answerable and unanswerable questions, and as a general-domain dataset it allows us to demonstrate the utility of our domain transfer methods.</p>
</div>
<div id="S3.SS3.p4" class="ltx_para">
<p id="S3.SS3.p4.1" class="ltx_p">The resultant QA model is then fine-tuned on our domain-specific “SYFTER” dataset in order to adapt it to our desired domain, which focuses on news articles about commercial events such as product launches and earnings reports (whereas SQuAD’s data comes from Wikipedia and focuses more on history, politics, and geography).<span id="footnote9" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span>SQuAD’s domains can be explored <a target="_blank" href="https://rajpurkar.github.io/SQuAD-explorer/explore/v2.0/dev/" title="" class="ltx_ref ltx_href">here</a>.</span></span></span></p>
</div>
<section id="S3.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.1 </span>Detecting Unanswerable Questions</h4>

<div id="S3.SS3.SSS1.p1" class="ltx_para">
<p id="S3.SS3.SSS1.p1.1" class="ltx_p">During development, we noticed that when trained on a single domain (SQuAD or SYFTER), the QA models could learn to effectively identify if a question from that domain could be answered or not, but performance on this task would drop significantly when trained on both domains.</p>
</div>
<div id="S3.SS3.SSS1.p2" class="ltx_para">
<p id="S3.SS3.SSS1.p2.1" class="ltx_p">This was likely due to a combination of our “unanswerable question” label being applied more broadly (to nonsensical questions as well as unanswerable ones), and due to the significant amount of class imbalance in the dataset (especially for the SYFTER data), as well as a small amount of noise in the labels detected through manual inspection.</p>
</div>
<div id="S3.SS3.SSS1.p3" class="ltx_para">
<p id="S3.SS3.SSS1.p3.1" class="ltx_p">We explored various methods to resolve this problem when using combined training data, and discuss an ablation study over them in Appendix <a href="#A2" title="Appendix B Question Answering Ablation ‣ A Pipeline for Generating, Annotating and Employing Synthetic Data for Real World Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">B</span></a>, with results in Table <a href="#A2.T7" title="Table 7 ‣ Appendix B Question Answering Ablation ‣ A Pipeline for Generating, Annotating and Employing Synthetic Data for Real World Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>.</p>
</div>
<div id="S3.SS3.SSS1.p4" class="ltx_para">
<ul id="S3.SS3.SSS1.p4.1" class="ltx_itemize">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><math id="S3.I1.i1.1.1.m1.1" class="ltx_Math" alttext="\bullet" display="inline"><semantics id="S3.I1.i1.1.1.m1.1b"><mo id="S3.I1.i1.1.1.m1.1.1" xref="S3.I1.i1.1.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S3.I1.i1.1.1.m1.1c"><ci id="S3.I1.i1.1.1.m1.1.1.cmml" xref="S3.I1.i1.1.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i1.1.1.m1.1d">\bullet</annotation></semantics></math></span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.p1.1" class="ltx_p">We appended “source markers” to the end of each question, prior to tokenisation, which indicated the domain that the question came from: either “[SQuAD]” or “[SYFTER]”, in order to allow the model to better learn domain-specific features.</p>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><math id="S3.I1.i2.1.1.m1.1" class="ltx_Math" alttext="\bullet" display="inline"><semantics id="S3.I1.i2.1.1.m1.1b"><mo id="S3.I1.i2.1.1.m1.1.1" xref="S3.I1.i2.1.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S3.I1.i2.1.1.m1.1c"><ci id="S3.I1.i2.1.1.m1.1.1.cmml" xref="S3.I1.i2.1.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i2.1.1.m1.1d">\bullet</annotation></semantics></math></span> 
<div id="S3.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i2.p1.1" class="ltx_p">We tuned the ‘null-answer threshold” on the validation set.</p>
</div>
</li>
<li id="S3.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><math id="S3.I1.i3.1.1.m1.1" class="ltx_Math" alttext="\bullet" display="inline"><semantics id="S3.I1.i3.1.1.m1.1b"><mo id="S3.I1.i3.1.1.m1.1.1" xref="S3.I1.i3.1.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S3.I1.i3.1.1.m1.1c"><ci id="S3.I1.i3.1.1.m1.1.1.cmml" xref="S3.I1.i3.1.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i3.1.1.m1.1d">\bullet</annotation></semantics></math></span> 
<div id="S3.I1.i3.p1" class="ltx_para">
<p id="S3.I1.i3.p1.1" class="ltx_p">We investigated training the model simultaneously for the tasks of both QA and sequence classification as “answerable” / “unanswerable”. This follows findings from <cite class="ltx_cite ltx_citemacro_citet">Crawshaw (<a href="#bib.bib7" title="" class="ltx_ref">2020</a>)</cite> that multitask learning can often improve performance, and given the interdependence between question answering and detecting if a question <em id="S3.I1.i3.p1.1.1" class="ltx_emph ltx_font_italic">can</em> be answered.</p>
</div>
</li>
<li id="S3.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><math id="S3.I1.i4.1.1.m1.1" class="ltx_Math" alttext="\bullet" display="inline"><semantics id="S3.I1.i4.1.1.m1.1b"><mo id="S3.I1.i4.1.1.m1.1.1" xref="S3.I1.i4.1.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S3.I1.i4.1.1.m1.1c"><ci id="S3.I1.i4.1.1.m1.1.1.cmml" xref="S3.I1.i4.1.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i4.1.1.m1.1d">\bullet</annotation></semantics></math></span> 
<div id="S3.I1.i4.p1" class="ltx_para">
<p id="S3.I1.i4.p1.1" class="ltx_p">Finally, we used alpha-weighted Focal Loss <cite class="ltx_cite ltx_citemacro_cite">Lin et al. (<a href="#bib.bib18" title="" class="ltx_ref">2017</a>)</cite> rather than Cross Entropy Loss for sequence classification in the multitask setting to better handle class imbalance.</p>
</div>
</li>
</ul>
</div>
</section>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Data Annotation</h3>

<figure id="S3.F3" class="ltx_figure"><img src="/html/2211.16971/assets/Annotation_Process.drawio.png" id="S3.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="479" height="126" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>The annotation process. The answerability and relevance of questions (blue) is dependent on the document, without considering external knowledge. Answers (purple) must appear within the document to be accepted.</figcaption>
</figure>
<figure id="S3.T1" class="ltx_table">
<table id="S3.T1.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T1.1.1.1" class="ltx_tr">
<th id="S3.T1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r">Model</th>
<th id="S3.T1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r">Training Data</th>
<th id="S3.T1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r"># Train Examples</th>
<th id="S3.T1.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column">Macro F1 Score</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T1.1.2.1" class="ltx_tr">
<td id="S3.T1.1.2.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">BERT</td>
<td id="S3.T1.1.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">CoLA</td>
<td id="S3.T1.1.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">10584</td>
<td id="S3.T1.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t">61.18</td>
</tr>
<tr id="S3.T1.1.3.2" class="ltx_tr">
<td id="S3.T1.1.3.2.1" class="ltx_td ltx_align_center ltx_border_r">BERT</td>
<td id="S3.T1.1.3.2.2" class="ltx_td ltx_align_center ltx_border_r">SYFTER</td>
<td id="S3.T1.1.3.2.3" class="ltx_td ltx_align_center ltx_border_r">2796</td>
<td id="S3.T1.1.3.2.4" class="ltx_td ltx_align_center"><span id="S3.T1.1.3.2.4.1" class="ltx_text ltx_font_bold">75.74</span></td>
</tr>
<tr id="S3.T1.1.4.3" class="ltx_tr">
<td id="S3.T1.1.4.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">BERT</td>
<td id="S3.T1.1.4.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">CoLA + SYFTER</td>
<td id="S3.T1.1.4.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">13608</td>
<td id="S3.T1.1.4.3.4" class="ltx_td ltx_align_center ltx_border_t">74.68</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>The Grammaticality model results. The best setting is indicated in <span id="S3.T1.4.1" class="ltx_text ltx_font_bold">bold</span> text. “# Train Examples” refers to the data <em id="S3.T1.5.2" class="ltx_emph ltx_font_italic">after</em> oversampling.</figcaption>
</figure>
<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p">In order to label the synthetic data for supervised training, we created an annotation tool<span id="footnote10" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup><span class="ltx_tag ltx_tag_note">10</span><a target="_blank" href="https://www.youtube.com/watch?v=VHBHE1pVWzA" title="" class="ltx_ref ltx_href">A video demo can be found here</a></span></span></span> using Streamlit <cite class="ltx_cite ltx_citemacro_cite">Treuille et al. (<a href="#bib.bib32" title="" class="ltx_ref">2018</a>)</cite> which allows annotators to view model-generated QA pairs, along with their associated context document, and annotate them in various ways. An example of how QA pairs are presented within the tool can be found in Figure <a href="#A4.F5" title="Figure 5 ‣ Appendix D Annotation Tool ‣ A Pipeline for Generating, Annotating and Employing Synthetic Data for Real World Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> in Appendix <a href="#A4" title="Appendix D Annotation Tool ‣ A Pipeline for Generating, Annotating and Employing Synthetic Data for Real World Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">D</span></a>.</p>
</div>
<div id="S3.SS4.p2" class="ltx_para">
<p id="S3.SS4.p2.1" class="ltx_p">We used a series of three preliminary studies to iteratively refine our annotation tool and guidelines, with each study involving 10 participants (who did not participate in subsequent studies). This allowed us to identify and fix any points of misunderstanding before using the tool for the final annotation study on the entire dataset. As with the final annotation study, these were done via Prolific<span id="footnote11" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">11</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">11</sup><span class="ltx_tag ltx_tag_note">11</span><a target="_blank" href="https://www.prolific.co/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.prolific.co/</a></span></span></span>
and under the same annotator filters (as well as filtering out previous participants).</p>
</div>
<div id="S3.SS4.p3" class="ltx_para">
<p id="S3.SS4.p3.1" class="ltx_p">Following each preliminary study, we followed up with annotators in cases where they had made unintuitive judgements or appeared to have misunderstood, and used these discussions to refine the guidelines presented. The final guidelines are shown in Appendix <a href="#A4.SS1" title="D.1 Annotation Guidelines ‣ Appendix D Annotation Tool ‣ A Pipeline for Generating, Annotating and Employing Synthetic Data for Real World Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">D.1</span></a>.</p>
</div>
<div id="S3.SS4.p4" class="ltx_para">
<p id="S3.SS4.p4.1" class="ltx_p">Each annotator was assigned to a group with two others, and each group of three annotators provided annotations for 2% of the total dataset, with gold labels coming from majority judgements.</p>
</div>
<div id="S3.SS4.p5" class="ltx_para">
<p id="S3.SS4.p5.1" class="ltx_p">The annotation process is shown in Figure <a href="#S3.F3" title="Figure 3 ‣ 3.4 Data Annotation ‣ 3 System Overview ‣ A Pipeline for Generating, Annotating and Employing Synthetic Data for Real World Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. Questions marked as unsuitable (for either reason) are not labelled further, and comprise the set of unanswerable questions for the SYFTER domain.</p>
</div>
<div id="S3.SS4.p6" class="ltx_para">
<p id="S3.SS4.p6.1" class="ltx_p">Questions were judged on suitability (whether the question is answerable and relevant to the document) as well as grammaticality.</p>
</div>
<div id="S3.SS4.p7" class="ltx_para">
<p id="S3.SS4.p7.1" class="ltx_p">Grammaticality for both questions and answers was posed to annotators as a question of “reading naturally”, in order to better mimic real user questions and avoid the subjective issues inherent to judging grammaticality.</p>
</div>
<div id="S3.SS4.p8" class="ltx_para">
<p id="S3.SS4.p8.1" class="ltx_p">Answers were judged on both naturalness and quality. In the latter case, an answer was considered “adequate” if it answered the question but had either extraneous details or was missing details, and “precise and correct” if it answered the question with all of the relevant details, but no more.</p>
</div>
<div id="S3.SS4.p9" class="ltx_para">
<p id="S3.SS4.p9.1" class="ltx_p">We asked annotators to rewrite questions and answers that did not read naturally, as well as inadequate answers, and did not allow for the submission of the labels until the texts were corrected or the question was marked as unsuitable (e.g. if they could not be corrected within our constraints).</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments and Results</h2>

<figure id="S4.T2" class="ltx_table">
<table id="S4.T2.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T2.1.1.1" class="ltx_tr">
<th id="S4.T2.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r">Test Dataset</th>
<th id="S4.T2.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r">QA Model</th>
<th id="S4.T2.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r">Exact Match</th>
<th id="S4.T2.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r">Similarity</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T2.1.2.1" class="ltx_tr">
<td id="S4.T2.1.2.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">SQuAD 2.0</td>
<td id="S4.T2.1.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">RoBERTa</td>
<td id="S4.T2.1.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.1.2.1.3.1" class="ltx_text ltx_font_bold">67.81%</span></td>
<td id="S4.T2.1.2.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.1.2.1.4.1" class="ltx_text ltx_font_bold">81.89%</span></td>
</tr>
<tr id="S4.T2.1.3.2" class="ltx_tr">
<td id="S4.T2.1.3.2.1" class="ltx_td ltx_align_center ltx_border_r">SYFTER</td>
<td id="S4.T2.1.3.2.2" class="ltx_td ltx_align_center ltx_border_r">RoBERTa</td>
<td id="S4.T2.1.3.2.3" class="ltx_td ltx_align_center ltx_border_r">64.55%</td>
<td id="S4.T2.1.3.2.4" class="ltx_td ltx_align_center ltx_border_r">77.27%</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span>Roundtrip evaluation of our QA datasets’ quality, using an off-the-shelf QA model. The RoBERTa model was trained on SQuAD 2.0. Best results indicated in bold text.</figcaption>
</figure>
<figure id="S4.T3" class="ltx_table">
<table id="S4.T3.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T3.1.1.1" class="ltx_tr">
<th id="S4.T3.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r">Document</th>
<th id="S4.T3.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r">Question</th>
<th id="S4.T3.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column">Answer</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T3.1.2.1" class="ltx_tr">
<td id="S4.T3.1.2.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.1.2.1.1.1" class="ltx_text">"International law firm Ashurst announces the appointment of Matthias Weissinger as partner in Munich.</span></td>
<td id="S4.T3.1.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.1.2.1.2.1" class="ltx_text">Who is the new partner of Ashurst in Munich?</span></td>
<td id="S4.T3.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t">Matthias Weissinger</td>
</tr>
<tr id="S4.T3.1.3.2" class="ltx_tr">
<td id="S4.T3.1.3.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.1.3.2.1.1" class="ltx_text">To date we’ve delivered more than one billion pieces of protective equipment to the frontline.</span></td>
<td id="S4.T3.1.3.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.1.3.2.2.1" class="ltx_text">How many pieces of protective equipment have been delivered to the frontline?</span></td>
<td id="S4.T3.1.3.2.3" class="ltx_td ltx_align_center ltx_border_t">more than one billion</td>
</tr>
<tr id="S4.T3.1.4.3" class="ltx_tr">
<td id="S4.T3.1.4.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.1.4.3.1.1" class="ltx_text">As a major food sector player, Bel fully assumes its duty to do everything possible to ensure the continuity of its operations.</span></td>
<td id="S4.T3.1.4.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.1.4.3.2.1" class="ltx_text">What sector is Bel a major player in?</span></td>
<td id="S4.T3.1.4.3.3" class="ltx_td ltx_align_center ltx_border_t">food</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span>Example Question-Answer Pairs Generated from Documents</figcaption>
</figure>
<figure id="S4.F4" class="ltx_figure"><img src="/html/2211.16971/assets/human_evaluation_annotation_results.png" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="479" height="359" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Human Evaluation results on the annotated data. Only QA pairs that had a suitable question were judged further on the other metrics. Percentages shown are based on annotator consensus rather than individual judgements.</figcaption>
</figure>
<figure id="S4.T4" class="ltx_table">
<table id="S4.T4.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T4.1.1.1" class="ltx_tr">
<th id="S4.T4.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r">Model</th>
<th id="S4.T4.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r">Training Data</th>
<th id="S4.T4.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r">% Synthetic</th>
<th id="S4.T4.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column" colspan="2">Answerable</th>
<th id="S4.T4.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r">Unanswerable</th>
<th id="S4.T4.1.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column" colspan="2">Overall</th>
</tr>
<tr id="S4.T4.1.2.2" class="ltx_tr">
<th id="S4.T4.1.2.2.1" class="ltx_td ltx_th ltx_th_column ltx_border_r"></th>
<th id="S4.T4.1.2.2.2" class="ltx_td ltx_th ltx_th_column ltx_border_r"></th>
<th id="S4.T4.1.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r">Training Data</th>
<th id="S4.T4.1.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r">EM</th>
<th id="S4.T4.1.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r">F1</th>
<th id="S4.T4.1.2.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r">EM</th>
<th id="S4.T4.1.2.2.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r">EM</th>
<th id="S4.T4.1.2.2.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r">F1</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T4.1.3.1" class="ltx_tr">
<td id="S4.T4.1.3.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">ALBERT</td>
<td id="S4.T4.1.3.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">SQuAD 2.0</td>
<td id="S4.T4.1.3.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0%</td>
<td id="S4.T4.1.3.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T4.1.3.1.4.1" class="ltx_text ltx_font_bold">84.87</span></td>
<td id="S4.T4.1.3.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T4.1.3.1.5.1" class="ltx_text ltx_font_bold">91.09</span></td>
<td id="S4.T4.1.3.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">12.16</td>
<td id="S4.T4.1.3.1.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">61.06</td>
<td id="S4.T4.1.3.1.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">65.25</td>
</tr>
<tr id="S4.T4.1.4.2" class="ltx_tr">
<td id="S4.T4.1.4.2.1" class="ltx_td ltx_align_center ltx_border_r">ALBERT</td>
<td id="S4.T4.1.4.2.2" class="ltx_td ltx_align_center ltx_border_r">SYFTER</td>
<td id="S4.T4.1.4.2.3" class="ltx_td ltx_align_center ltx_border_r">100%</td>
<td id="S4.T4.1.4.2.4" class="ltx_td ltx_align_center ltx_border_r">53.26</td>
<td id="S4.T4.1.4.2.5" class="ltx_td ltx_align_center ltx_border_r">59.71</td>
<td id="S4.T4.1.4.2.6" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T4.1.4.2.6.1" class="ltx_text ltx_font_bold">72.00</span></td>
<td id="S4.T4.1.4.2.7" class="ltx_td ltx_align_center ltx_border_r">57.26</td>
<td id="S4.T4.1.4.2.8" class="ltx_td ltx_align_center ltx_border_r">63.34</td>
</tr>
<tr id="S4.T4.1.5.3" class="ltx_tr">
<td id="S4.T4.1.5.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">ALBERT</td>
<td id="S4.T4.1.5.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">SQuAD 2.0 + SYFTER</td>
<td id="S4.T4.1.5.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.62%</td>
<td id="S4.T4.1.5.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">71.74</td>
<td id="S4.T4.1.5.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">83.24</td>
<td id="S4.T4.1.5.3.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">40.00</td>
<td id="S4.T4.1.5.3.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T4.1.5.3.7.1" class="ltx_text ltx_font_bold">64.96</span></td>
<td id="S4.T4.1.5.3.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T4.1.5.3.8.1" class="ltx_text ltx_font_bold">74.00</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4: </span>Question Answering model results on the SYFTER test set. The best settings are shown in <span id="S4.T4.3.1" class="ltx_text ltx_font_bold">bold</span>.</figcaption>
</figure>
<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">The Grammaticality and Question Answering models are tested in both the setting of interest (combined domain-general and domain-specific data) as well as two baseline data settings (domain-general data only<span id="footnote12" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">12</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">12</sup><span class="ltx_tag ltx_tag_note">12</span>CoLA for the grammaticality task, SQuAD for the QA task</span></span></span>, and domain-specific data only). This allows us to both measure how useful the synthetic data is as an addition to domain-general data and to also evaluate the feasibility of fine-tuning using <em id="S4.p1.1.1" class="ltx_emph ltx_font_italic">only</em> synthetic data, which would reduce time and expense significantly given its small size.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p">The combined test sets for the Grammaticality and QA models are produced by combining the appropriate domain-general data (CoLA or SQuAD) with the domain-specific SYFTER data and then testing the model on this combination dataset.</p>
</div>
<div id="S4.p3" class="ltx_para">
<p id="S4.p3.1" class="ltx_p">We evaluate the Question Generation process in both the domain-general and domain-specific settings, but do <em id="S4.p3.1.1" class="ltx_emph ltx_font_italic">not</em> evaluate the combined setting due to the nature of the evaluation (see Section <a href="#S4.SS2" title="4.2 Synthetic Question-Answer Pair Generation ‣ 4 Experiments and Results ‣ A Pipeline for Generating, Annotating and Employing Synthetic Data for Real World Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>).</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Grammaticality Classification</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">We evaluate the grammaticality model using the model’s F1 score, treating grammaticality as a binary sequence classification task, and achieve strong results in both the synthetic-only and combined data settings, as shown in Table <a href="#S3.T1" title="Table 1 ‣ 3.4 Data Annotation ‣ 3 System Overview ‣ A Pipeline for Generating, Annotating and Employing Synthetic Data for Real World Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. The domain-specific model actually performs better than both the domain-general model and the combined-data setting, despite training on only a small amount of synthetic data, indicating the importance of using domain-specific data during training.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Synthetic Question-Answer Pair Generation</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">We evaluate the synthetic questions through roundtrip evaluation as discussed in Section <a href="#S2.F1" title="Figure 1 ‣ 2 Background and Related Work ‣ A Pipeline for Generating, Annotating and Employing Synthetic Data for Real World Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. For each generated QA pair, we use an off-the-shelf QA model<span id="footnote13" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">13</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">13</sup><span class="ltx_tag ltx_tag_note">13</span><a target="_blank" href="https://huggingface.co/deepset/roberta-base-squad2" title="" class="ltx_ref ltx_href">deepset/roberta-base-squad2</a>, which has strong performance on SQuAD 2 data</span></span></span> to answer the generated question (based on its associated context) and then compare the answers in two ways: Exact match; and comparing their similarity with their most-similar question at the token level using length-normalised Levenshtein distance <cite class="ltx_cite ltx_citemacro_cite">Levenshtein (<a href="#bib.bib17" title="" class="ltx_ref">1966</a>)</cite> via NLTK <cite class="ltx_cite ltx_citemacro_cite">Bird et al. (<a href="#bib.bib3" title="" class="ltx_ref">2009</a>)</cite>. Intuitively, if the question is well-formed and precise, and the answer is relevant to it, the QA model should find the correct answer.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">As shown in Table <a href="#S4.T2" title="Table 2 ‣ 4 Experiments and Results ‣ A Pipeline for Generating, Annotating and Employing Synthetic Data for Real World Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, the synthetic data is of high quality, reaching similar levels to SQuAD 2.0, which was manually created by humans. Furthermore, Table <a href="#S4.T3" title="Table 3 ‣ 4 Experiments and Results ‣ A Pipeline for Generating, Annotating and Employing Synthetic Data for Real World Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> shows examples of the synthetic data produced and used. The generated questions are both fluent and of interest, and the answers are both precise and correct. The first question is slightly stilted, but still easily understandable.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.1" class="ltx_p">Finally, the annotation process can also be thought of as a form of human evaluation and, as shown by Figure <a href="#S4.F4" title="Figure 4 ‣ 4 Experiments and Results ‣ A Pipeline for Generating, Annotating and Employing Synthetic Data for Real World Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, the vast majority of the data was found to be of high-quality (suitable, reading naturally, and correct+precise answers). However, 48.6% of the data, including unsuitable questions, did require some input from annotations in some form (not counting data that was imprecise but otherwise good). This indicates that while the data tends to be of high-quality overall, about half of the datapoints do contain a small amount of noise. 69.7% of the questions are suitable and have correct answers, which can be considered the key factors for good synthetic QA data, and as such a high percentage of the data could be used to train a QA system as-is without needing corrections.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Question Answering</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">We take approximately 11.6% of the total annotated SYFTER data (117 questions, approximately 21% of which are unanswerable) to use as the QA test set, and split it at the document-level to avoid potential information leaks from the training data.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.1" class="ltx_p">The QA model is evaluated through both the “Exact Match” (EM) score, and at the token level using F1 score, via the <a target="_blank" href="https://github.com/huggingface/datasets/blob/2.4.0/datasets/squad_v2/squad_v2.py" title="" class="ltx_ref ltx_href">HuggingFace wrapper</a> around the official SQuAD evaluation script. In both cases, the text is first lowercased and normalised to remove articles and standardise whitespace. EM and F1 are identical for unanswerable questions.</p>
</div>
<div id="S4.SS3.p3" class="ltx_para">
<p id="S4.SS3.p3.1" class="ltx_p">We present the results from the best setting, which uses null-answer threshold tuning and multitask learning <em id="S4.SS3.p3.1.1" class="ltx_emph ltx_font_italic">without</em> Focal Loss (see Appendix <a href="#A2" title="Appendix B Question Answering Ablation ‣ A Pipeline for Generating, Annotating and Employing Synthetic Data for Real World Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">B</span></a>), in Table <a href="#S4.T4" title="Table 4 ‣ 4 Experiments and Results ‣ A Pipeline for Generating, Annotating and Employing Synthetic Data for Real World Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<div id="S4.SS3.p4" class="ltx_para">
<p id="S4.SS3.p4.1" class="ltx_p">The SYFTER-only model performs well despite the SYFTER dataset being much smaller than SQuAD 2.0, and is much better at handling unanswerable questions. By combining the two, we achieve the best overall performance, and maintain reasonable performance on unanswerable questions despite the issues discussed in Section <a href="#S3.SS3.SSS1" title="3.3.1 Detecting Unanswerable Questions ‣ 3.3 Question Answering ‣ 3 System Overview ‣ A Pipeline for Generating, Annotating and Employing Synthetic Data for Real World Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3.1</span></a>.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">We present a pipeline for using and evaluating synthetic QA data and an interface for annotating it, as well as annotation guidelines. The combination of domain-general and synthetic data allows our QA model to perform significantly better (+ 9 F1) on domain-specific documents than it did when trained solely on a similar amount of domain-general data. The pipeline is simple to apply to both current and future state-of-the-art models, enabling better performance in low-resource domains.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Acknowledgements</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">This work is supported by an Innovate UK grant under the KTP scheme (KTP 11714) to Rob Procter, Maria Liakata and Filament AI, as well as the Alan Turing Institute (EP/N510129/1). Maria Liakata has been supported by a UKRI/EPSRC Turing AI Fellowship EP/V030302/1.</p>
</div>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Limitations</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">Whilst our system demonstrates that we can achieve significant improvements from synthetic domain-specific data with minimal additional time and expense, it does have certain limitations: We do not consider “adversarial questions” when training, and it thus would likely struggle on these kinds of questions based on findings such as those from <cite class="ltx_cite ltx_citemacro_citet">Bartolo et al. (<a href="#bib.bib2" title="" class="ltx_ref">2021</a>)</cite>.</p>
</div>
<div id="S7.p2" class="ltx_para">
<p id="S7.p2.1" class="ltx_p">We also found that our synthetic data primarily consists of questions which identify entities (e.g. “Who is the CEO of Microsoft?”, “When did Microsoft acquire Bethesda Softworks?”, “What are the five principles of good leadership?”), and does not contain many examples of questions about relationships between entities (e.g. “Is selling ice cream more profitable than selling widgets?”), and answers to the latter may be of relatively poor quality.</p>
</div>
<div id="S7.p3" class="ltx_para">
<p id="S7.p3.1" class="ltx_p">This is likely due to what appears to be a similar trend in SQuAD V1 that the Question Generation model was trained on: SQuAD primarily asks questions with short entity-focused answers (dates, names, etc.) <cite class="ltx_cite ltx_citemacro_cite">Qu et al. (<a href="#bib.bib23" title="" class="ltx_ref">2021</a>)</cite> and approximately half of the answers in SquAD <cite class="ltx_cite ltx_citemacro_cite">Rajpurkar et al. (<a href="#bib.bib26" title="" class="ltx_ref">2016</a>)</cite> are proper nouns, dates, or other numbers indicating that their corresponding questions are likely entity-focused.</p>
</div>
<div id="S7.p4" class="ltx_para">
<p id="S7.p4.1" class="ltx_p">The questions of interest to us are generally entity-based and so this limitation does not directly impact our own usage of the model, but we recognise that it potentially limits its applicability to other domains. In the future, the model’s performance on non-entity questions could be investigated and improved through tools like AdaTest <cite class="ltx_cite ltx_citemacro_cite">Ribeiro and Lundberg (<a href="#bib.bib28" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
<div id="S7.p5" class="ltx_para">
<p id="S7.p5.1" class="ltx_p">The tool also still requires some amount of human involvement to annotate and filter the synthetic data, and the Grammaticality model results (Table <a href="#S3.T1" title="Table 1 ‣ 3.4 Data Annotation ‣ 3 System Overview ‣ A Pipeline for Generating, Annotating and Employing Synthetic Data for Real World Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> indicates that filtering with purely domain-general models would be ineffective. However, it is possible to generate the QA pairs without annotation and, given the high quality of the data (Figure <a href="#S4.F4" title="Figure 4 ‣ 4 Experiments and Results ‣ A Pipeline for Generating, Annotating and Employing Synthetic Data for Real World Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>), it may be reasonably possible to use the data directly (treating it all as suitable and grammatical) to achieve a still-significant boost to domain-specific performance.</p>
</div>
<div id="S7.p6" class="ltx_para">
<p id="S7.p6.1" class="ltx_p">The main problem with not using human annotation would be that our “unanswerable questions” are all ones marked as “unsuitable” by humans, and thus using the synthetic data directly would lead to only having synthetic questions that are considered to be answerable. This could be improved through extending the QG pipeline to also produce deliberately-unanswerable examples, but is not currently possible.</p>
</div>
<div id="S7.p7" class="ltx_para">
<p id="S7.p7.1" class="ltx_p">Finally, whilst we use the grammaticality model for validation during the question generation process, we do not train either the Answer Selection or Question Generation models with grammaticality as a second objective function. Training it in a multitask setting would likely have guided it towards producing better input, and may have produced more (valid) data from the corpus.</p>
</div>
</section>
<section id="S8" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8 </span>Ethics Statement</h2>

<div id="S8.p1" class="ltx_para">
<p id="S8.p1.1" class="ltx_p">Machine learning tasks often involve the potential for ethical issues, especially when using human annotators to label data. We chose to use Prolific<span id="footnote14" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">14</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">14</sup><span class="ltx_tag ltx_tag_note">14</span><a target="_blank" href="https://www.prolific.co/" title="" class="ltx_ref ltx_href">https://www.prolific.co/</a></span></span></span> as a platform to find and pay annotators, as it offered a reputation for enforcing ethical payments as well as useful filters such as education level and native language.</p>
</div>
<div id="S8.p2" class="ltx_para">
<p id="S8.p2.1" class="ltx_p">We also submitted our project to the University of Warwick’s internal ethics process, and were approved without having to make any adjustments.</p>
</div>
<div id="S8.p3" class="ltx_para">
<p id="S8.p3.1" class="ltx_p">Prolific annotators are paid a fixed amount, but if a task’s average hourly payment falls below a minimum (£5 / $6.50 per hour), it is required to rectify this and increase the payments.</p>
</div>
<div id="S8.p4" class="ltx_para">
<p id="S8.p4.1" class="ltx_p">The mean rate of pay for annotators was reported as £15.63 during the preliminary studies and £15.50 during the primary annotation study, though these figures are <em id="S8.p4.1.1" class="ltx_emph ltx_font_italic">under-estimates</em> as our own time-tracking indicates that annotators generally spent a significant amount of time not annotating the data questions (but still recorded by Prolific as being on-task). This is well in excess of the UK living wage of £9.50, as well as the “real living wage” of up to £11.05 proposed by The Living Wage Foundation<span id="footnote15" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">15</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">15</sup><span class="ltx_tag ltx_tag_note">15</span>As discussed <a target="_blank" href="https://www.livingwage.org.uk/" title="" class="ltx_ref ltx_href">here</a>.</span></span></span>.</p>
</div>
<div id="S8.p5" class="ltx_para">
<p id="S8.p5.1" class="ltx_p">The use of synthetic data does have some inherent potential ethical issues: “Model hallucination” is a well-known phenomenon where models can create unfaithful data (e.g. convincing, but false answers to questions) and which can cause real-world harm if the information it provides is acted on <cite class="ltx_cite ltx_citemacro_cite">Ji et al. (<a href="#bib.bib14" title="" class="ltx_ref">2022</a>)</cite>. This can affect our own models if the data generation models hallucinate and lead to the QA model internalising incorrect knowledge.</p>
</div>
<div id="S8.p6" class="ltx_para">
<p id="S8.p6.1" class="ltx_p">Thankfully, there are various ways to identify these occurrences and mitigate this harm, including perhaps the simplest method of specifying the context in which the data was created and used at appropriate downstream points, so that users can better assess its veracity for themselves.</p>
</div>
<div id="S8.p7" class="ltx_para">
<p id="S8.p7.1" class="ltx_p">To limit this harm, we strongly suggest that other researchers take this into account in their own work, and take the appropriate actions, for instance using human annotators to verify the data and actively designing models to be robust against hallucination, as done in work like <cite class="ltx_cite ltx_citemacro_citet">Su et al. (<a href="#bib.bib30" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
<div id="S8.p8" class="ltx_para">
<p id="S8.p8.1" class="ltx_p">Finally, despite using a model to create our QA data, and the fact that synthetic data can clearly be very useful, bias is still likely to exist in the data (carried forward from both the model’s original training data and the human factor of the annotation done), and we suggest that any data produced be investigated and debiased through tools like AdaTest <cite class="ltx_cite ltx_citemacro_cite">Ribeiro and Lundberg (<a href="#bib.bib28" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Alberti et al. (2019)</span>
<span class="ltx_bibblock">
Chris Alberti, Daniel Andor, Emily Pitler, Jacob Devlin, and Michael Collins.
2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.1906.05416" title="" class="ltx_ref ltx_href">Synthetic qa
corpora generation with roundtrip consistency</a>.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bartolo et al. (2021)</span>
<span class="ltx_bibblock">
Max Bartolo, Tristan Thrush, Robin Jia, Sebastian Riedel, Pontus Stenetorp, and
Douwe Kiela. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2021.emnlp-main.696" title="" class="ltx_ref ltx_href">Improving
question answering model robustness with synthetic adversarial data
generation</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021 Conference on Empirical Methods in
Natural Language Processing</em>. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bird et al. (2009)</span>
<span class="ltx_bibblock">
Steven Bird, Ewan Klein, and Edward Loper. 2009.

</span>
<span class="ltx_bibblock"><em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">Natural language processing with Python: analyzing text with
the natural language toolkit</em>.

</span>
<span class="ltx_bibblock">" O’Reilly Media, Inc.".

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et al. (2020)</span>
<span class="ltx_bibblock">
Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan,
Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda
Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan,
Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter,
Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray,
Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford,
Ilya Sutskever, and Dario Amodei. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2005.14165" title="" class="ltx_ref ltx_href">Language models
are few-shot learners</a>.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chan and Fan (2019)</span>
<span class="ltx_bibblock">
Ying-Hong Chan and Yao-Chung Fan. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/D19-5821" title="" class="ltx_ref ltx_href">A recurrent
BERT-based model for question generation</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2nd Workshop on Machine Reading for
Question Answering</em>, pages 154–162, Hong Kong, China. Association for
Computational Linguistics.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chawla et al. (2002)</span>
<span class="ltx_bibblock">
N. V. Chawla, K. W. Bowyer, L. O. Hall, and W. P. Kegelmeyer. 2002.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1613/jair.953" title="" class="ltx_ref ltx_href">SMOTE: Synthetic minority
over-sampling technique</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Journal of Artificial Intelligence Research</em>, 16:321–357.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Crawshaw (2020)</span>
<span class="ltx_bibblock">
Michael Crawshaw. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2009.09796" title="" class="ltx_ref ltx_href">Multi-task
learning with deep neural networks: A survey</a>.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Devlin et al. (2018)</span>
<span class="ltx_bibblock">
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.1810.04805" title="" class="ltx_ref ltx_href">Bert: Pre-training
of deep bidirectional transformers for language understanding</a>.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Feng et al. (2021)</span>
<span class="ltx_bibblock">
Steven Y. Feng, Varun Gangal, Jason Wei, Sarath Chandar, Soroush Vosoughi,
Teruko Mitamura, and Eduard Hovy. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2105.03075" title="" class="ltx_ref ltx_href">A survey of data
augmentation approaches for nlp</a>.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Grover et al. (2021)</span>
<span class="ltx_bibblock">
Khushnuma Grover, Katinder Kaur, Kartikey Tiwari, Rupali, and Parteek Kumar.
2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://link.springer.com/chapter/10.1007/978-981-16-0401-0_18" title="" class="ltx_ref ltx_href">Deep
learning based question generation using t5 transformer</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">Advanced Computing</em>, pages 243–255, Singapore. Springer
Singapore.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Harel-Canada et al. (2022)</span>
<span class="ltx_bibblock">
Fabrice Harel-Canada, Muhammad Ali Gulzar, Nanyun Peng, and Miryung Kim. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2022.findings-acl.140" title="" class="ltx_ref ltx_href">Sibylvariant transformations for robust text classification</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational Linguistics:
ACL 2022</em>, pages 1771–1788, Dublin, Ireland. Association for Computational
Linguistics.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hoffmann et al. (2022)</span>
<span class="ltx_bibblock">
Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor
Cai, Eliza Rutherford, Diego de Las Casas, Lisa Anne Hendricks, Johannes
Welbl, Aidan Clark, Tom Hennigan, Eric Noland, Katie Millican, George van den
Driessche, Bogdan Damoc, Aurelia Guy, Simon Osindero, Karen Simonyan, Erich
Elsen, Jack W. Rae, Oriol Vinyals, and Laurent Sifre. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2203.15556" title="" class="ltx_ref ltx_href">Training
compute-optimal large language models</a>.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hosking and Riedel (2019)</span>
<span class="ltx_bibblock">
Tom Hosking and Sebastian Riedel. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.1902.11049" title="" class="ltx_ref ltx_href">Evaluating rewards
for question generation models</a>.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ji et al. (2022)</span>
<span class="ltx_bibblock">
Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii,
Yejin Bang, Andrea Madotto, and Pascale Fung. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2202.03629" title="" class="ltx_ref ltx_href">Survey of
hallucination in natural language generation</a>.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lan et al. (2019)</span>
<span class="ltx_bibblock">
Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, and
Radu Soricut. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.1909.11942" title="" class="ltx_ref ltx_href">Albert: A lite
bert for self-supervised learning of language representations</a>.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lau et al. (2017)</span>
<span class="ltx_bibblock">
Jey Han Lau, Alexander Clark, and Shalom Lappin. 2017.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/https://doi.org/10.1111/cogs.12414" title="" class="ltx_ref ltx_href">Grammaticality, acceptability, and probability: A probabilistic view of
linguistic knowledge</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">Cognitive Science</em>, 41(5):1202–1241.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Levenshtein (1966)</span>
<span class="ltx_bibblock">
Vladimir I. Levenshtein. 1966.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://www.mathnet.ru/php/archive.phtml?wshow=paper&amp;jrnid=dan&amp;paperid=31411&amp;option_lang=eng" title="" class="ltx_ref ltx_href">Binary codes capable of correcting deletions, insertions, and reversals</a>.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et al. (2017)</span>
<span class="ltx_bibblock">
Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and Piotr Dollár. 2017.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.1708.02002" title="" class="ltx_ref ltx_href">Focal loss for
dense object detection</a>.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Matthews (1975)</span>
<span class="ltx_bibblock">
B.W. Matthews. 1975.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/https://doi.org/10.1016/0005-2795(75)90109-9" title="" class="ltx_ref ltx_href">Comparison of the predicted and observed secondary structure of t4 phage
lysozyme</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">Biochimica et Biophysica Acta (BBA) - Protein Structure</em>,
405(2):442–451.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nema and Khapra (2018)</span>
<span class="ltx_bibblock">
Preksha Nema and Mitesh M. Khapra. 2018.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/D18-1429" title="" class="ltx_ref ltx_href">Towards a better metric
for evaluating question generation systems</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 Conference on Empirical Methods in
Natural Language Processing</em>, pages 3950–3959, Brussels, Belgium.
Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Papineni et al. (2002)</span>
<span class="ltx_bibblock">
Kishore Papineni, Salim Roukos, Todd Ward, , and Wei-Jing Zhu. 2002.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://aclanthology.org/P02-1040.pdf" title="" class="ltx_ref ltx_href">Bleu: a method for
automatic evaluation of machine translation</a>.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Patil (2022)</span>
<span class="ltx_bibblock">
Suraj Patil. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/patil-suraj/question_generation" title="" class="ltx_ref ltx_href">Question
Generation using transformers</a>.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qu et al. (2021)</span>
<span class="ltx_bibblock">
Fanyi Qu, Xin Jia, and Yunfang Wu. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2109.05179" title="" class="ltx_ref ltx_href">Asking questions
like educational experts: Automatically generating question-answer pairs on
real-world examination data</a>.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Raffel et al. (2020)</span>
<span class="ltx_bibblock">
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael
Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/1910.10683" title="" class="ltx_ref ltx_href">Exploring the limits of
transfer learning with a unified text-to-text transformer</a>.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rajpurkar et al. (2018)</span>
<span class="ltx_bibblock">
Pranav Rajpurkar, Robin Jia, and Percy Liang. 2018.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/1806.03822" title="" class="ltx_ref ltx_href">Know what you don’t know:
Unanswerable questions for squad</a>.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rajpurkar et al. (2016)</span>
<span class="ltx_bibblock">
Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. 2016.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/1606.05250" title="" class="ltx_ref ltx_href">Squad: 100,000+ questions
for machine comprehension of text</a>.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ramponi and Plank (2020)</span>
<span class="ltx_bibblock">
Alan Ramponi and Barbara Plank. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2006.00632" title="" class="ltx_ref ltx_href">Neural
unsupervised domain adaptation in nlp—a survey</a>.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ribeiro and Lundberg (2022)</span>
<span class="ltx_bibblock">
Marco Tulio Ribeiro and Scott Lundberg. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2022.acl-long.230" title="" class="ltx_ref ltx_href">Adaptive
testing and debugging of NLP models</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 60th Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Papers)</em>, pages 3253–3267,
Dublin, Ireland. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sennrich et al. (2015)</span>
<span class="ltx_bibblock">
Rico Sennrich, Barry Haddow, and Alexandra Birch. 2015.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.1511.06709" title="" class="ltx_ref ltx_href">Improving neural
machine translation models with monolingual data</a>.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Su et al. (2022)</span>
<span class="ltx_bibblock">
Dan Su, Xiaoguang Li, Jindi Zhang, Lifeng Shang, Xin Jiang, Qun Liu, and
Pascale Fung. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2203.00343" title="" class="ltx_ref ltx_href">Read before
generate! faithful long form question answering with machine reading</a>.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et al. (2019)</span>
<span class="ltx_bibblock">
Yu Sun, Shuohuan Wang, Yukun Li, Shikun Feng, Xuyi Chen, Han Zhang, Xin Tian,
Danxiang Zhu, Hao Tian, and Hua Wu. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.1904.09223" title="" class="ltx_ref ltx_href">Ernie: Enhanced
representation through knowledge integration</a>.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Treuille et al. (2018)</span>
<span class="ltx_bibblock">
Adrien Treuille, Thiago Teixeira, and Amanda Kelly. 2018.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://streamlit.io/" title="" class="ltx_ref ltx_href">Streamlit</a>.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2022)</span>
<span class="ltx_bibblock">
Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and
Samuel R. Bowman. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://gluebenchmark.com/leaderboard" title="" class="ltx_ref ltx_href">Glue benchmark
leaderboard</a>.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Warstadt and Bowman (2020)</span>
<span class="ltx_bibblock">
Alex Warstadt and Samuel R. Bowman. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/1901.03438" title="" class="ltx_ref ltx_href">Linguistic analysis of
pretrained sentence encoders with acceptability judgments</a>.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Warstadt et al. (2019)</span>
<span class="ltx_bibblock">
Alex Warstadt, Amanpreet Singh, and Samuel R. Bowman. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/1805.12471" title="" class="ltx_ref ltx_href">Neural network acceptability
judgments</a>.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2020)</span>
<span class="ltx_bibblock">
Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q. Weinberger, and Yoav Artzi.
2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/1904.09675" title="" class="ltx_ref ltx_href">Bertscore: Evaluating text
generation with bert</a>.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>RegEx Document Filters</h2>

<div id="A1.p1" class="ltx_para">
<p id="A1.p1.1" class="ltx_p">Table <a href="#A1.T5" title="Table 5 ‣ Appendix A RegEx Document Filters ‣ A Pipeline for Generating, Annotating and Employing Synthetic Data for Real World Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> shows the different RegEx filters that we apply to documents in order to filter out ones that are likely to be difficult to select valid answers from. Documents are filtered if <em id="A1.p1.1.1" class="ltx_emph ltx_font_italic">any</em> substring in them is a match for the expression.</p>
</div>
<div id="A1.p2" class="ltx_para">
<p id="A1.p2.1" class="ltx_p">The first expression, which filters out documents that appear to be too similar to contracts, additionally contains certain <em id="A1.p2.1.1" class="ltx_emph ltx_font_italic">whitelist</em> expressions which prevent otherwise-matching documents from being removed. These can be seen in Table <a href="#A1.T6" title="Table 6 ‣ Appendix A RegEx Document Filters ‣ A Pipeline for Generating, Annotating and Employing Synthetic Data for Real World Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>. In order to be whitelisted, the text that matched the initial filter must fully match the whitelist expression (though the entire document does not have to match).</p>
</div>
<div id="A1.p3" class="ltx_para">
<p id="A1.p3.1" class="ltx_p">For clarity when dealing with leading/trailing whitespace, each expression is wrapped in “double quotes”, but these quotes are not part of the actual expression. Matches with each expression are <span id="A1.p3.1.1" class="ltx_text ltx_font_bold">emphasised</span> for clarity.</p>
</div>
<figure id="A1.T5" class="ltx_table">
<table id="A1.T5.1" class="ltx_tabular ltx_align_left ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A1.T5.1.1.1" class="ltx_tr">
<th id="A1.T5.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r">
<span id="A1.T5.1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.1.1.1.1.1.1" class="ltx_p" style="width:260.2pt;">RegEx Expression</span>
</span>
</th>
<th id="A1.T5.1.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r">
<span id="A1.T5.1.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.1.1.1.2.1.1" class="ltx_p" style="width:86.7pt;">Intended Matches</span>
</span>
</th>
<th id="A1.T5.1.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column">
<span id="A1.T5.1.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.1.1.1.3.1.1" class="ltx_p" style="width:86.7pt;">Example Match</span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A1.T5.1.2.1" class="ltx_tr">
<td id="A1.T5.1.2.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="A1.T5.1.2.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.1.2.1.1.1.1" class="ltx_p" style="width:260.2pt;">“<code id="A1.T5.1.2.1.1.1.1.1" class="ltx_verbatim ltx_font_typewriter"> ?\([0-9A-Za-z]+\)(\([0-9A-Za-z]+\))*</code>”</span>
</span>
</td>
<td id="A1.T5.1.2.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="A1.T5.1.2.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.1.2.1.2.1.1" class="ltx_p" style="width:86.7pt;">Contract-like documents</span>
</span>
</td>
<td id="A1.T5.1.2.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="A1.T5.1.2.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.1.2.1.3.1.1" class="ltx_p" style="width:86.7pt;">“B 1: Financial Instruments according to Regulation 17<span id="A1.T5.1.2.1.3.1.1.1" class="ltx_text ltx_font_bold">(1)(a)</span> of the Regulations”</span>
</span>
</td>
</tr>
<tr id="A1.T5.1.3.2" class="ltx_tr">
<td id="A1.T5.1.3.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="A1.T5.1.3.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.1.3.2.1.1.1" class="ltx_p" style="width:260.2pt;">“<code id="A1.T5.1.3.2.1.1.1.1" class="ltx_verbatim ltx_font_typewriter">^[0-9]+\.? ?.+</code>”</span>
</span>
</td>
<td id="A1.T5.1.3.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="A1.T5.1.3.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.1.3.2.2.1.1" class="ltx_p" style="width:86.7pt;">Numeric List</span>
</span>
</td>
<td id="A1.T5.1.3.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="A1.T5.1.3.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.1.3.2.3.1.1" class="ltx_p" style="width:86.7pt;">“<span id="A1.T5.1.3.2.3.1.1.1" class="ltx_text ltx_font_bold">1. Reassure customers and employees</span>”</span>
</span>
</td>
</tr>
<tr id="A1.T5.1.4.3" class="ltx_tr">
<td id="A1.T5.1.4.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="A1.T5.1.4.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.1.4.3.1.1.1" class="ltx_p" style="width:260.2pt;">“<code id="A1.T5.1.4.3.1.1.1.1" class="ltx_verbatim ltx_font_typewriter">^[ivx]+\.? .+</code>”</span>
</span>
</td>
<td id="A1.T5.1.4.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="A1.T5.1.4.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.1.4.3.2.1.1" class="ltx_p" style="width:86.7pt;">Roman-numeric List</span>
</span>
</td>
<td id="A1.T5.1.4.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="A1.T5.1.4.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.1.4.3.3.1.1" class="ltx_p" style="width:86.7pt;">“<span id="A1.T5.1.4.3.3.1.1.1" class="ltx_text ltx_font_bold">xi If the financial instrument has such a period</span>”</span>
</span>
</td>
</tr>
<tr id="A1.T5.1.5.4" class="ltx_tr">
<td id="A1.T5.1.5.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="A1.T5.1.5.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.1.5.4.1.1.1" class="ltx_p" style="width:260.2pt;">“<code id="A1.T5.1.5.4.1.1.1.1" class="ltx_verbatim ltx_font_typewriter">\[ ?\]</code>”</span>
</span>
</td>
<td id="A1.T5.1.5.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="A1.T5.1.5.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.1.5.4.2.1.1" class="ltx_p" style="width:86.7pt;">Empty square brackets</span>
</span>
</td>
<td id="A1.T5.1.5.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="A1.T5.1.5.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.1.5.4.3.1.1" class="ltx_p" style="width:86.7pt;">“<span id="A1.T5.1.5.4.3.1.1.1" class="ltx_text ltx_font_bold">[ ]</span> An acquisition or disposal of financial instruments”</span>
</span>
</td>
</tr>
<tr id="A1.T5.1.6.5" class="ltx_tr">
<td id="A1.T5.1.6.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="A1.T5.1.6.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.1.6.5.1.1.1" class="ltx_p" style="width:260.2pt;">“<code id="A1.T5.1.6.5.1.1.1.1" class="ltx_verbatim ltx_font_typewriter">Regulation(s)? [0-9]+</code>”</span>
</span>
</td>
<td id="A1.T5.1.6.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="A1.T5.1.6.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.1.6.5.2.1.1" class="ltx_p" style="width:86.7pt;">Regulations contract-like</span>
</span>
</td>
<td id="A1.T5.1.6.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="A1.T5.1.6.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.1.6.5.3.1.1" class="ltx_p" style="width:86.7pt;">“B 2: Financial Instruments with similar economic effect according to <span id="A1.T5.1.6.5.3.1.1.1" class="ltx_text ltx_font_bold">Regulation 17</span> of the Regulations”</span>
</span>
</td>
</tr>
<tr id="A1.T5.1.7.6" class="ltx_tr">
<td id="A1.T5.1.7.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="A1.T5.1.7.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.1.7.6.1.1.1" class="ltx_p" style="width:260.2pt;">“<code id="A1.T5.1.7.6.1.1.1.1" class="ltx_verbatim ltx_font_typewriter">^.{0,15}$</code>”</span>
</span>
</td>
<td id="A1.T5.1.7.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="A1.T5.1.7.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.1.7.6.2.1.1" class="ltx_p" style="width:86.7pt;">Very short documents</span>
</span>
</td>
<td id="A1.T5.1.7.6.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="A1.T5.1.7.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.1.7.6.3.1.1" class="ltx_p" style="width:86.7pt;">“<span id="A1.T5.1.7.6.3.1.1.1" class="ltx_text ltx_font_bold">content</span>”</span>
</span>
</td>
</tr>
<tr id="A1.T5.1.8.7" class="ltx_tr">
<td id="A1.T5.1.8.7.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="A1.T5.1.8.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.1.8.7.1.1.1" class="ltx_p" style="width:260.2pt;">“<code id="A1.T5.1.8.7.1.1.1.1" class="ltx_verbatim ltx_font_typewriter">^(.{0.5})?\(.+\).{0,5}$</code>”</span>
</span>
</td>
<td id="A1.T5.1.8.7.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="A1.T5.1.8.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.1.8.7.2.1.1" class="ltx_p" style="width:86.7pt;">Mostly in brackets</span>
</span>
</td>
<td id="A1.T5.1.8.7.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="A1.T5.1.8.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T5.1.8.7.3.1.1" class="ltx_p" style="width:86.7pt;">“<span id="A1.T5.1.8.7.3.1.1.1" class="ltx_text ltx_font_bold">(please tick the appropriate box or boxes):</span>”</span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 5: </span>RegEx Filters for Documents</figcaption>
</figure>
<figure id="A1.T6" class="ltx_table">
<table id="A1.T6.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A1.T6.1.1.1" class="ltx_tr">
<th id="A1.T6.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r">
<span id="A1.T6.1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.1.1.1.1.1.1" class="ltx_p" style="width:170.7pt;">RegEx Expression</span>
</span>
</th>
<th id="A1.T6.1.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r">
<span id="A1.T6.1.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.1.1.1.2.1.1" class="ltx_p" style="width:85.4pt;">Purpose</span>
</span>
</th>
<th id="A1.T6.1.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column">
<span id="A1.T6.1.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.1.1.1.3.1.1" class="ltx_p" style="width:170.7pt;">Example Documents Whitelisted</span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A1.T6.1.2.1" class="ltx_tr">
<td id="A1.T6.1.2.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="A1.T6.1.2.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.1.2.1.1.1.1" class="ltx_p" style="width:170.7pt;">“<code id="A1.T6.1.2.1.1.1.1.1" class="ltx_verbatim ltx_font_typewriter"> ?\([A-Z]+s?\)</code>”</span>
</span>
</td>
<td id="A1.T6.1.2.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="A1.T6.1.2.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.1.2.1.2.1.1" class="ltx_p" style="width:85.4pt;">Allow acronyms</span>
</span>
</td>
<td id="A1.T6.1.2.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="A1.T6.1.2.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.1.2.1.3.1.1" class="ltx_p" style="width:170.7pt;">“CPE Lite is Huawei’s latest mini customer premises equipment<span id="A1.T6.1.2.1.3.1.1.1" class="ltx_text ltx_font_bold"> (CPE)</span>.”</span>
</span>
</td>
</tr>
<tr id="A1.T6.1.3.2" class="ltx_tr">
<td id="A1.T6.1.3.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="A1.T6.1.3.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.1.3.2.1.1.1" class="ltx_p" style="width:170.7pt;">“<code id="A1.T6.1.3.2.1.1.1.1" class="ltx_verbatim ltx_font_typewriter"> ?\([A-Z]?[0-9a-z]{4,}\)</code>”</span>
</span>
</td>
<td id="A1.T6.1.3.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="A1.T6.1.3.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.1.3.2.2.1.1" class="ltx_p" style="width:85.4pt;">Allow short bracketed words</span>
</span>
</td>
<td id="A1.T6.1.3.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="A1.T6.1.3.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T6.1.3.2.3.1.1" class="ltx_p" style="width:170.7pt;">“Bel reported strong sales momentum in the first two months of the year in global<span id="A1.T6.1.3.2.3.1.1.1" class="ltx_text ltx_font_bold">(mature)</span> markets”</span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 6: </span>RegEx Whitelists for Documents, applied to the “Contract-like” filter.</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="A2" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Question Answering Ablation</h2>

<div id="A2.p1" class="ltx_para">
<p id="A2.p1.1" class="ltx_p">We performed an ablation study over the Question Answering Model components discussed in Section <a href="#S3.SS3.SSS1" title="3.3.1 Detecting Unanswerable Questions ‣ 3.3 Question Answering ‣ 3 System Overview ‣ A Pipeline for Generating, Annotating and Employing Synthetic Data for Real World Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3.1</span></a>, and found that in some cases they significantly improve the performance on unanswerable questions, especially the use of multitask learning. The results of this ablation are shown in Table <a href="#A2.T7" title="Table 7 ‣ Appendix B Question Answering Ablation ‣ A Pipeline for Generating, Annotating and Employing Synthetic Data for Real World Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>.</p>
</div>
<div id="A2.p2" class="ltx_para">
<p id="A2.p2.1" class="ltx_p">Whilst we found that some settings (Source Markers, Focal Loss) did not appear to be useful, we nonetheless believe that the utility of source markers when using more domains would be an interesting avenue for future investigation.</p>
</div>
<figure id="A2.T7" class="ltx_table">
<table id="A2.T7.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="A2.T7.1.1.1" class="ltx_tr">
<td id="A2.T7.1.1.1.1" class="ltx_td ltx_align_center ltx_border_r">Source Markers</td>
<td id="A2.T7.1.1.1.2" class="ltx_td ltx_align_center ltx_border_r">Threshold Tuning</td>
<td id="A2.T7.1.1.1.3" class="ltx_td ltx_align_center ltx_border_r">Multitask</td>
<td id="A2.T7.1.1.1.4" class="ltx_td ltx_align_center ltx_border_r">Focal Loss</td>
<td id="A2.T7.1.1.1.5" class="ltx_td ltx_align_center" colspan="3">Performance Gain (F1)</td>
</tr>
<tr id="A2.T7.1.2.2" class="ltx_tr">
<td id="A2.T7.1.2.2.1" class="ltx_td ltx_border_r"></td>
<td id="A2.T7.1.2.2.2" class="ltx_td ltx_border_r"></td>
<td id="A2.T7.1.2.2.3" class="ltx_td ltx_border_r"></td>
<td id="A2.T7.1.2.2.4" class="ltx_td ltx_border_r"></td>
<td id="A2.T7.1.2.2.5" class="ltx_td ltx_align_center ltx_border_r">Answerable</td>
<td id="A2.T7.1.2.2.6" class="ltx_td ltx_align_center ltx_border_r">No Answer</td>
<td id="A2.T7.1.2.2.7" class="ltx_td ltx_align_center">Overall</td>
</tr>
<tr id="A2.T7.1.3.3" class="ltx_tr">
<td id="A2.T7.1.3.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">x</td>
<td id="A2.T7.1.3.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">x</td>
<td id="A2.T7.1.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">x</td>
<td id="A2.T7.1.3.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">x</td>
<td id="A2.T7.1.3.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">91.02</td>
<td id="A2.T7.1.3.3.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">72.97</td>
<td id="A2.T7.1.3.3.7" class="ltx_td ltx_align_center ltx_border_t">85.11</td>
</tr>
<tr id="A2.T7.1.4.4" class="ltx_tr">
<td id="A2.T7.1.4.4.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">✓</td>
<td id="A2.T7.1.4.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">x</td>
<td id="A2.T7.1.4.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">x</td>
<td id="A2.T7.1.4.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">x</td>
<td id="A2.T7.1.4.4.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">- 2.2</td>
<td id="A2.T7.1.4.4.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">+ 0</td>
<td id="A2.T7.1.4.4.7" class="ltx_td ltx_align_center ltx_border_t">- 1.48</td>
</tr>
<tr id="A2.T7.1.5.5" class="ltx_tr">
<td id="A2.T7.1.5.5.1" class="ltx_td ltx_align_center ltx_border_r">x</td>
<td id="A2.T7.1.5.5.2" class="ltx_td ltx_align_center ltx_border_r">✓</td>
<td id="A2.T7.1.5.5.3" class="ltx_td ltx_align_center ltx_border_r">x</td>
<td id="A2.T7.1.5.5.4" class="ltx_td ltx_align_center ltx_border_r">x</td>
<td id="A2.T7.1.5.5.5" class="ltx_td ltx_align_center ltx_border_r">- 0.66</td>
<td id="A2.T7.1.5.5.6" class="ltx_td ltx_align_center ltx_border_r">+ 1.35</td>
<td id="A2.T7.1.5.5.7" class="ltx_td ltx_align_center">+ 0</td>
</tr>
<tr id="A2.T7.1.6.6" class="ltx_tr">
<td id="A2.T7.1.6.6.1" class="ltx_td ltx_align_center ltx_border_r">x</td>
<td id="A2.T7.1.6.6.2" class="ltx_td ltx_align_center ltx_border_r">x</td>
<td id="A2.T7.1.6.6.3" class="ltx_td ltx_align_center ltx_border_r">✓</td>
<td id="A2.T7.1.6.6.4" class="ltx_td ltx_align_center ltx_border_r">x</td>
<td id="A2.T7.1.6.6.5" class="ltx_td ltx_align_center ltx_border_r"><span id="A2.T7.1.6.6.5.1" class="ltx_text ltx_font_bold">- 1.98</span></td>
<td id="A2.T7.1.6.6.6" class="ltx_td ltx_align_center ltx_border_r"><span id="A2.T7.1.6.6.6.1" class="ltx_text ltx_font_bold">+ 4.06</span></td>
<td id="A2.T7.1.6.6.7" class="ltx_td ltx_align_center"><span id="A2.T7.1.6.6.7.1" class="ltx_text ltx_font_bold">+ 0</span></td>
</tr>
<tr id="A2.T7.1.7.7" class="ltx_tr">
<td id="A2.T7.1.7.7.1" class="ltx_td ltx_align_center ltx_border_r">x</td>
<td id="A2.T7.1.7.7.2" class="ltx_td ltx_align_center ltx_border_r">x</td>
<td id="A2.T7.1.7.7.3" class="ltx_td ltx_align_center ltx_border_r">✓</td>
<td id="A2.T7.1.7.7.4" class="ltx_td ltx_align_center ltx_border_r">✓</td>
<td id="A2.T7.1.7.7.5" class="ltx_td ltx_align_center ltx_border_r">- 2.14</td>
<td id="A2.T7.1.7.7.6" class="ltx_td ltx_align_center ltx_border_r">+ 0</td>
<td id="A2.T7.1.7.7.7" class="ltx_td ltx_align_center">- 1.44</td>
</tr>
<tr id="A2.T7.1.8.8" class="ltx_tr">
<td id="A2.T7.1.8.8.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">✓</td>
<td id="A2.T7.1.8.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">✓</td>
<td id="A2.T7.1.8.8.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">✓</td>
<td id="A2.T7.1.8.8.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">✓</td>
<td id="A2.T7.1.8.8.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">- 1.91</td>
<td id="A2.T7.1.8.8.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">+ 1.35</td>
<td id="A2.T7.1.8.8.7" class="ltx_td ltx_align_center ltx_border_t">- 0.84</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 7: </span>Relative performance gains on the ALBERT QA model in different training settings. A checkmark indicates that the component was used, an “x” that it was not. Focal loss is only applicable in the multitask setting. Best setting shown in <span id="A2.T7.3.1" class="ltx_text ltx_font_bold">bold</span>.</figcaption>
</figure>
</section>
<section id="A3" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Question Generation Filter Ablation</h2>

<div id="A3.p1" class="ltx_para">
<p id="A3.p1.1" class="ltx_p">We performed an ablation study over the Question Generation filters discussed in Section <a href="#S3.SS2" title="3.2 Synthetic Question-Answer Pair Generation ‣ 3 System Overview ‣ A Pipeline for Generating, Annotating and Employing Synthetic Data for Real World Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a> and found that the individual filters tend to have a significant impact on the model’s performance on unanswerable questions, but relatively little when considering answerable questions. Given that the filters were primarily designed to filter out documents that were likely to produce low-quality unanswerable questions, this is as expected. The set of filters that we used does not provide the best <em id="A3.p1.1.1" class="ltx_emph ltx_font_italic">overall</em> F1 Score, but provides a model whose performance is significantly more balanced than the nominally best-performing model, a trait that we found valuable.</p>
</div>
<div id="A3.p2" class="ltx_para">
<p id="A3.p2.1" class="ltx_p">For these tests, we trained and tested the QA model <em id="A3.p2.1.1" class="ltx_emph ltx_font_italic">only</em> on SYFTER data so as to most clearly see the effects of the filter(s) used (since SQuAD data is not filtered in our pipeline).</p>
</div>
<figure id="A3.T8" class="ltx_table">
<table id="A3.T8.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="A3.T8.1.1.1" class="ltx_tr">
<td id="A3.T8.1.1.1.1" class="ltx_td ltx_align_center" colspan="4">Filter</td>
<td id="A3.T8.1.1.1.2" class="ltx_td ltx_align_center" colspan="3">Performance Gain (F1)</td>
</tr>
<tr id="A3.T8.1.2.2" class="ltx_tr">
<td id="A3.T8.1.2.2.1" class="ltx_td ltx_align_center ltx_border_r">Length</td>
<td id="A3.T8.1.2.2.2" class="ltx_td ltx_align_center ltx_border_r">RegEx</td>
<td id="A3.T8.1.2.2.3" class="ltx_td ltx_align_center ltx_border_r">Part of Speech</td>
<td id="A3.T8.1.2.2.4" class="ltx_td ltx_align_center ltx_border_r">Grammaticality</td>
<td id="A3.T8.1.2.2.5" class="ltx_td ltx_align_center ltx_border_r">Answerable</td>
<td id="A3.T8.1.2.2.6" class="ltx_td ltx_align_center ltx_border_r">No Answer</td>
<td id="A3.T8.1.2.2.7" class="ltx_td ltx_align_center">Overall</td>
</tr>
<tr id="A3.T8.1.3.3" class="ltx_tr">
<td id="A3.T8.1.3.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">x</td>
<td id="A3.T8.1.3.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">x</td>
<td id="A3.T8.1.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">x</td>
<td id="A3.T8.1.3.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">x</td>
<td id="A3.T8.1.3.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">72.35</td>
<td id="A3.T8.1.3.3.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">40.00</td>
<td id="A3.T8.1.3.3.7" class="ltx_td ltx_align_center ltx_border_t">66.22</td>
</tr>
<tr id="A3.T8.1.4.4" class="ltx_tr">
<td id="A3.T8.1.4.4.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">✓</td>
<td id="A3.T8.1.4.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">x</td>
<td id="A3.T8.1.4.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">x</td>
<td id="A3.T8.1.4.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">x</td>
<td id="A3.T8.1.4.4.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">65.60</td>
<td id="A3.T8.1.4.4.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">48.00</td>
<td id="A3.T8.1.4.4.7" class="ltx_td ltx_align_center ltx_border_t">62.16</td>
</tr>
<tr id="A3.T8.1.5.5" class="ltx_tr">
<td id="A3.T8.1.5.5.1" class="ltx_td ltx_align_center ltx_border_r">x</td>
<td id="A3.T8.1.5.5.2" class="ltx_td ltx_align_center ltx_border_r">✓</td>
<td id="A3.T8.1.5.5.3" class="ltx_td ltx_align_center ltx_border_r">x</td>
<td id="A3.T8.1.5.5.4" class="ltx_td ltx_align_center ltx_border_r">x</td>
<td id="A3.T8.1.5.5.5" class="ltx_td ltx_align_center ltx_border_r">73.8</td>
<td id="A3.T8.1.5.5.6" class="ltx_td ltx_align_center ltx_border_r">24</td>
<td id="A3.T8.1.5.5.7" class="ltx_td ltx_align_center">64</td>
</tr>
<tr id="A3.T8.1.6.6" class="ltx_tr">
<td id="A3.T8.1.6.6.1" class="ltx_td ltx_align_center ltx_border_r">x</td>
<td id="A3.T8.1.6.6.2" class="ltx_td ltx_align_center ltx_border_r">x</td>
<td id="A3.T8.1.6.6.3" class="ltx_td ltx_align_center ltx_border_r">✓</td>
<td id="A3.T8.1.6.6.4" class="ltx_td ltx_align_center ltx_border_r">x</td>
<td id="A3.T8.1.6.6.5" class="ltx_td ltx_align_center ltx_border_r"><span id="A3.T8.1.6.6.5.1" class="ltx_text ltx_font_bold">73.67</span></td>
<td id="A3.T8.1.6.6.6" class="ltx_td ltx_align_center ltx_border_r">52</td>
<td id="A3.T8.1.6.6.7" class="ltx_td ltx_align_center"><span id="A3.T8.1.6.6.7.1" class="ltx_text ltx_font_bold">69.5</span></td>
</tr>
<tr id="A3.T8.1.7.7" class="ltx_tr">
<td id="A3.T8.1.7.7.1" class="ltx_td ltx_align_center ltx_border_r">x</td>
<td id="A3.T8.1.7.7.2" class="ltx_td ltx_align_center ltx_border_r">x</td>
<td id="A3.T8.1.7.7.3" class="ltx_td ltx_align_center ltx_border_r">x</td>
<td id="A3.T8.1.7.7.4" class="ltx_td ltx_align_center ltx_border_r">✓</td>
<td id="A3.T8.1.7.7.5" class="ltx_td ltx_align_center ltx_border_r">71.95</td>
<td id="A3.T8.1.7.7.6" class="ltx_td ltx_align_center ltx_border_r">36</td>
<td id="A3.T8.1.7.7.7" class="ltx_td ltx_align_center">65.24</td>
</tr>
<tr id="A3.T8.1.8.8" class="ltx_tr">
<td id="A3.T8.1.8.8.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">✓</td>
<td id="A3.T8.1.8.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">✓</td>
<td id="A3.T8.1.8.8.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">✓</td>
<td id="A3.T8.1.8.8.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">✓</td>
<td id="A3.T8.1.8.8.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">59.71</td>
<td id="A3.T8.1.8.8.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="A3.T8.1.8.8.6.1" class="ltx_text ltx_font_bold">72.00</span></td>
<td id="A3.T8.1.8.8.7" class="ltx_td ltx_align_center ltx_border_t">63.34</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 8: </span>Relative QA performance gains on the SYFTER test set model using different SYFTER training data filtered in different ways. A checkmark indicates that the component was used, an “x” that it was not. Best setting shown in <span id="A3.T8.3.1" class="ltx_text ltx_font_bold">bold</span>. Only SYFTER data was used for training.</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="A4" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Annotation Tool</h2>

<div id="A4.p1" class="ltx_para">
<p id="A4.p1.1" class="ltx_p">Figure <a href="#A4.F5" title="Figure 5 ‣ Appendix D Annotation Tool ‣ A Pipeline for Generating, Annotating and Employing Synthetic Data for Real World Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> shows an example of how QA Pairs are presented to annotators in the annotation tool. See Section <a href="#S3.SS4" title="3.4 Data Annotation ‣ 3 System Overview ‣ A Pipeline for Generating, Annotating and Employing Synthetic Data for Real World Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.4</span></a> for details.</p>
</div>
<div id="A4.p2" class="ltx_para">
<p id="A4.p2.1" class="ltx_p">A video demo of the tool can be found <a target="_blank" href="https://www.youtube.com/watch?v=VHBHE1pVWzA" title="" class="ltx_ref ltx_href">here</a></p>
</div>
<figure id="A4.F5" class="ltx_figure"><img src="/html/2211.16971/assets/QA_Annotation_Tool-Full.png" id="A4.F5.g1" class="ltx_graphics ltx_img_portrait" width="399" height="698" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>An example of how QA pairs are presented in the annotation tool.</figcaption>
</figure>
<section id="A4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">D.1 </span>Annotation Guidelines</h3>

<div id="A4.SS1.p1" class="ltx_para">
<p id="A4.SS1.p1.1" class="ltx_p">We present a set of annotation guidelines which can be given to annotators in order to obtain consistent labels by “calibrating” their expectations of what is and is not a valid QA pair. The guidelines for labelling questions can be found in Figure <a href="#A4.F6" title="Figure 6 ‣ D.1 Annotation Guidelines ‣ Appendix D Annotation Tool ‣ A Pipeline for Generating, Annotating and Employing Synthetic Data for Real World Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> and for answers in Figure <a href="#A4.F7" title="Figure 7 ‣ D.1 Annotation Guidelines ‣ Appendix D Annotation Tool ‣ A Pipeline for Generating, Annotating and Employing Synthetic Data for Real World Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>.</p>
</div>
<figure id="A4.F6" class="ltx_figure"><img src="/html/2211.16971/assets/Instructions-Questions.png" id="A4.F6.g1" class="ltx_graphics ltx_img_portrait" width="366" height="698" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Annotation guidelines for judging question suitability and naturalness.</figcaption>
</figure>
<figure id="A4.F7" class="ltx_figure"><img src="/html/2211.16971/assets/Instructions-Answers.png" id="A4.F7.g1" class="ltx_graphics ltx_img_portrait" width="299" height="698" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Annotation guidelines for judging answer naturalness and quality.</figcaption>
</figure>
</section>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2211.16970" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2211.16971" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2211.16971">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2211.16971" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2211.16972" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Mar 14 07:19:50 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
