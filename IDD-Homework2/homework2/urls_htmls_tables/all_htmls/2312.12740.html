<!DOCTYPE html>

<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Fine-tuning Large Language Models for Adaptive Machine Translation</title>
<!--Generated on Wed Dec 20 03:21:25 2023 by LaTeXML (version 0.8.7) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv_0.7.4.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2312.12740v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="#S1" title="1 Introduction ‣ Fine-tuning Large Language Models for Adaptive Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="#S2" title="2 Experimental Setup ‣ Fine-tuning Large Language Models for Adaptive Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Experimental Setup</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="#S2.SS1" title="2.1 Data ‣ 2 Experimental Setup ‣ Fine-tuning Large Language Models for Adaptive Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Data</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="#S2.SS2" title="2.2 Information Retrieval ‣ 2 Experimental Setup ‣ Fine-tuning Large Language Models for Adaptive Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Information Retrieval</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="#S2.SS2.SSS0.Px1" title="Embedding: ‣ 2.2 Information Retrieval ‣ 2 Experimental Setup ‣ Fine-tuning Large Language Models for Adaptive Machine Translation"><span class="ltx_text ltx_ref_title">Embedding:</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="#S2.SS2.SSS0.Px2" title="Indexing: ‣ 2.2 Information Retrieval ‣ 2 Experimental Setup ‣ Fine-tuning Large Language Models for Adaptive Machine Translation"><span class="ltx_text ltx_ref_title">Indexing:</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="#S2.SS2.SSS0.Px3" title="Semantic Search: ‣ 2.2 Information Retrieval ‣ 2 Experimental Setup ‣ Fine-tuning Large Language Models for Adaptive Machine Translation"><span class="ltx_text ltx_ref_title">Semantic Search:</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="#S2.SS2.SSS0.Px4" title="Re-ranking: ‣ 2.2 Information Retrieval ‣ 2 Experimental Setup ‣ Fine-tuning Large Language Models for Adaptive Machine Translation"><span class="ltx_text ltx_ref_title">Re-ranking:</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="#S2.SS3" title="2.3 Fine-tuning ‣ 2 Experimental Setup ‣ Fine-tuning Large Language Models for Adaptive Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Fine-tuning</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="#S2.SS4" title="2.4 Inference ‣ 2 Experimental Setup ‣ Fine-tuning Large Language Models for Adaptive Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.4 </span>Inference</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="#S2.SS4.SSS0.Px1" title="Mistral 7B: ‣ 2.4 Inference ‣ 2 Experimental Setup ‣ Fine-tuning Large Language Models for Adaptive Machine Translation"><span class="ltx_text ltx_ref_title">Mistral 7B:</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="#S2.SS4.SSS0.Px2" title="ChatGPT: ‣ 2.4 Inference ‣ 2 Experimental Setup ‣ Fine-tuning Large Language Models for Adaptive Machine Translation"><span class="ltx_text ltx_ref_title">ChatGPT:</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="#S2.SS4.SSS0.Px3" title="NLLB-200: ‣ 2.4 Inference ‣ 2 Experimental Setup ‣ Fine-tuning Large Language Models for Adaptive Machine Translation"><span class="ltx_text ltx_ref_title">NLLB-200:</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="#S3" title="3 Results ‣ Fine-tuning Large Language Models for Adaptive Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="#S4" title="4 Conclusion and Future Work ‣ Fine-tuning Large Language Models for Adaptive Machine Translation"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Conclusion and Future Work</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<div aria-label="”Conversion" been="" class="package-alerts ltx_document" errors="" found”="" have="" role="“status”">
<button aria-label="Dismiss alert" onclick="closePopup()">
<span aria-hidden="true"><svg aria-hidden="true" focusable="false" height="20" role="presentation" viewbox="0 0 44 44" width="20">
<path d="M0.549989 4.44999L4.44999 0.549988L43.45 39.55L39.55 43.45L0.549989 4.44999Z"></path>
<path d="M39.55 0.549988L43.45 4.44999L4.44999 43.45L0.549988 39.55L39.55 0.549988Z"></path>
</svg></span>
</button>
<p>HTML conversions <a href="https://info.dev.arxiv.org/about/accessibility_html_error_messages.html" target="_blank">sometimes display errors</a> due to content that did not convert correctly from the source. This paper uses the following packages that are not yet supported by the HTML conversion tool. Feedback on these issues are not necessary; they are known and are being worked on.</p>
<ul arial-label="Unsupported packages used in this paper">
<li>failed: rawfonts</li>
</ul>
<p>Authors: achieve the best HTML results from your LaTeX submissions by following these <a href="https://info.arxiv.org/help/submit_latex_best_practices.html" target="_blank">best practices</a>.</p>
</div><div class="section" id="target-section"><div id="license-tr">License: CC BY 4.0</div><div id="watermark-tr">arXiv:2312.12740v1 [cs.CL] 20 Dec 2023</div></div>
<script>
            function closePopup() {
                document.querySelector('.package-alerts').style.display = 'none';
            }
        </script>
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Fine-tuning Large Language Models for 
<br class="ltx_break"/>Adaptive Machine Translation</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span class="ltx_ERROR undefined" id="id1.1.id1">\name</span>Yasmin Moslem <span class="ltx_ERROR undefined" id="id2.2.id2">\email</span><span class="ltx_text" id="id3.3.id3" style="font-size:70%;">yasmin.moslem@adaptcentre.ie</span>
<br class="ltx_break"/><span class="ltx_ERROR undefined" id="id4.4.id4">\addr</span><span class="ltx_text" id="id5.5.id5" style="font-size:70%;">ADAPT Centre, School of Computing, Dublin City University 
<br class="ltx_break"/>Dublin, Ireland</span>
<span class="ltx_ERROR undefined" id="id6.6.id6">\AND</span><span class="ltx_ERROR undefined" id="id7.7.id7">\name</span>Rejwanul Haque <span class="ltx_ERROR undefined" id="id8.8.id8">\email</span><span class="ltx_text" id="id9.9.id9" style="font-size:70%;">rejwanul.haque@adaptcentre.ie</span>
<br class="ltx_break"/><span class="ltx_ERROR undefined" id="id10.10.id10">\addr</span><span class="ltx_text" id="id11.11.id11" style="font-size:70%;">ADAPT Centre, Department of Computing, South East Technological University 
<br class="ltx_break"/>Carlow, Ireland</span>
<span class="ltx_ERROR undefined" id="id12.12.id12">\AND</span><span class="ltx_ERROR undefined" id="id13.13.id13">\name</span>Andy Way <span class="ltx_ERROR undefined" id="id14.14.id14">\email</span><span class="ltx_text" id="id15.15.id15" style="font-size:70%;">andy.way@adaptcentre.ie</span>
<br class="ltx_break"/><span class="ltx_ERROR undefined" id="id16.16.id16">\addr</span><span class="ltx_text" id="id17.17.id17" style="font-size:70%;">ADAPT Centre, School of Computing, Dublin City University 
<br class="ltx_break"/>Dublin, Ireland</span>
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id18.id1">This paper presents the outcomes of fine-tuning Mistral 7B, a general-purpose large language model (LLM), for adaptive machine translation (MT). The fine-tuning process involves utilising a combination of zero-shot and one-shot translation prompts within the medical domain. The primary objective is to enhance real-time adaptive MT capabilities of Mistral 7B, enabling it to adapt translations to the required domain at inference time. The results, particularly for Spanish-to-English MT, showcase the efficacy of the fine-tuned model, demonstrating quality improvements in both zero-shot and one-shot translation scenarios, surpassing Mistral 7B’s baseline performance. Notably, the fine-tuned Mistral outperforms ChatGPT “gpt-3.5-turbo” in zero-shot translation while achieving comparable one-shot translation quality. Moreover, the zero-shot translation of the fine-tuned Mistral matches NLLB 3.3B’s performance, and its one-shot translation quality surpasses that of NLLB 3.3B. These findings emphasise the significance of fine-tuning efficient LLMs like Mistral 7B to yield high-quality zero-shot translations comparable to task-oriented models like NLLB 3.3B. Additionally, the adaptive gains achieved in one-shot translation are comparable to those of commercial LLMs such as ChatGPT. Our experiments demonstrate that, with a relatively small dataset of 20,000 segments that incorporate a mix of zero-shot and one-shot prompts, fine-tuning significantly enhances Mistral’s in-context learning ability, especially for real-time adaptive MT.</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Adaptive MT with LLMs is a task that involves employing the in-context learning feature of LLMs to adapt the MT output to approved similar translations <cite class="ltx_cite ltx_citemacro_citep">(Agrawal et al.,, <a class="ltx_ref" href="#bib.bib1" title="">2023</a>; <a class="ltx_ref" href="#bib.bib20" title="">Moslem et al., 2023a, </a>)</cite> or terminology <cite class="ltx_cite ltx_citemacro_citep">(Ghazvininejad et al.,, <a class="ltx_ref" href="#bib.bib12" title="">2023</a>; <a class="ltx_ref" href="#bib.bib21" title="">Moslem et al., 2023b, </a>)</cite>. In this sense, feeding an LLM with extra context can help improve the translation quality and adherence to the domain terminology and style. By definition, in-context learning involves replicating text generation patterns without additional fine-tuning <cite class="ltx_cite ltx_citemacro_citep">(Brown et al.,, <a class="ltx_ref" href="#bib.bib6" title="">2020</a>)</cite>. Nevertheless, fine-tuning can still be an option to improve the in-context learning capability of LLMs.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">The majority of current research that aims at enhancing MT through LLM training involves either: (i) pre-training an LLM to work with zero-shot MT <cite class="ltx_cite ltx_citemacro_citep">(Schioppa et al.,, <a class="ltx_ref" href="#bib.bib29" title="">2023</a>)</cite>; or (ii) fine-tuning LLMs with the main purpose of improving zero-shot capabilities <cite class="ltx_cite ltx_citemacro_citep">(Sia and Duh,, <a class="ltx_ref" href="#bib.bib31" title="">2022</a>; Alves et al.,, <a class="ltx_ref" href="#bib.bib2" title="">2023</a>; Iyer et al.,, <a class="ltx_ref" href="#bib.bib14" title="">2023</a>; Jiao et al.,, <a class="ltx_ref" href="#bib.bib16" title="">2023</a>; Xu et al.,, <a class="ltx_ref" href="#bib.bib38" title="">2023</a>; Zhang et al.,, <a class="ltx_ref" href="#bib.bib41" title="">2023</a>)</cite>. Moreover, there are several works that investigate pre-training or fine-tuning encoder-decoder MT models for adaptive MT <cite class="ltx_cite ltx_citemacro_citep">(Farajian et al.,, <a class="ltx_ref" href="#bib.bib11" title="">2017</a>; Bulte and Tezcan,, <a class="ltx_ref" href="#bib.bib7" title="">2019</a>; Xu et al.,, <a class="ltx_ref" href="#bib.bib39" title="">2020</a>)</cite>, and there is at least one work that compares this with using in-context learning of LLMs for adaptive MT <cite class="ltx_cite ltx_citemacro_citep">(Reinauer et al.,, <a class="ltx_ref" href="#bib.bib28" title="">2023</a>)</cite>. However, there is still a need for research that instead investigates fine-tuning available open-source models to enhance their in-context learning ability for real-time adaptive MT and compares this to current approaches. To this end, these models can be fine-tuned to perform better at in-context learning scenarios, where special prompt templates incorporate in-domain sentences, phrases, or terminology. This direction can improve both translation quality and efficiency, especially as fewer examples might be required for in-context learning.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Among the benefits of fine-tuning open-source LLMs are efficient self-hosting. In other words, those who would like to serve their own LLMs for privacy reasons can utilise an open-source model, and efficiently achieve quality gains comparable to those of strong commercial LLMs. Moreover, so far, for very high-resource languages, LLMs can be used independently. However, for other languages, a hybrid approach using both conventional MT models and LLMs leads to better results, which means we have to deploy/use two models at translation time. If fine-tuning a small “standalone” LLM is possible for both regular (zero-shot) and adaptive (one-shot or few-shot) translation, this would be much more efficient. In addition, researchers can definitely build on this direction rather than having to rely on closed models. Open-source research can lead to more interpretability as we know better what is going on in the background.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">In this work, we aim to investigate enhancing real-time adaptive MT with LLMs via fine-tuning on a mix of zero-shot and one-shot translation prompts. In the case of one-shot prompts, each new source segment is augmented with a similar translation pair (fuzzy match). Our experiments for the Spanish-to-English medical domain show that fine-tuning Mistral 7B on a small dataset, consisting of only 20,000 translation pairs, can improve it in-context learning capability for adaptive MT.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Experimental Setup</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">This section demonstrates our experiments with fine-tuning an LLM, namely Mistral 7B <cite class="ltx_cite ltx_citemacro_citep">(Jiang et al.,, <a class="ltx_ref" href="#bib.bib15" title="">2023</a>)</cite>, for “adaptive” MT. Hence, the model is not only fine-tuned for regular (zero-shot) translation, but also for adaptation to one fuzzy match (one-shot) at translation time. The experiments were conducted for Spanish-to-English medical adaptive MT. The code used for these experiments is publicly available.<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/ymoslem/Adaptive-MT-LLM-Fine-tuning" title="">https://github.com/ymoslem/Adaptive-MT-LLM-Fine-tuning</a></span></span></span></p>
</div>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Data</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">In this experiment, fine-tuning uses a mix of 10,000 segments with zero-shot prompts and 10,000 segments with one-shot prompts. The whole dataset was split into 19,000 segments for training the model and 1,000 randomly selected segments for validation while training. Fuzzy matches are extracted from a “context dataset” including 50,000 translation pairs. The test dataset includes 10,000 sentences, and it has its own unique context dataset, which consists of 50,000 unique translation pairs. Figure <a class="ltx_ref" href="#S2.F1" title="Figure 1 ‣ 2.1 Data ‣ 2 Experimental Setup ‣ Fine-tuning Large Language Models for Adaptive Machine Translation"><span class="ltx_text ltx_ref_tag">1</span></a> shows examples of zero-shot and one-shot prompts. The retrieval process of fuzzy matches is detailed in Section <a class="ltx_ref" href="#S2.SS2" title="2.2 Information Retrieval ‣ 2 Experimental Setup ‣ Fine-tuning Large Language Models for Adaptive Machine Translation"><span class="ltx_text ltx_ref_tag">2.2</span></a>.</p>
</div>
<figure class="ltx_figure" id="S2.F1">
<div class="ltx_pagination ltx_role_start_2_columns"></div>
<br class="ltx_break"/><svg class="ltx_picture" height="106.35" id="S2.F1.pic1" overflow="visible" version="1.1" width="600"><g color="#000000" fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,106.35) matrix(1 0 0 -1 0 0) translate(161.63,0)"><g fill="#737373" fill-opacity="1.000000"><path d="M 0 5.32 L 0 91.54 C 0 94.48 2.38 96.86 5.32 96.86 L 271.42 96.86 C 274.36 96.86 276.74 94.48 276.74 91.54 L 276.74 5.32 C 276.74 2.38 274.36 0 271.42 0 L 5.32 0 C 2.38 0 0 2.38 0 5.32 Z" style="stroke:none"></path></g><g fill="#FCFCFF" fill-opacity="1.000000"><path d="M 1.38 5.32 L 1.38 91.54 C 1.38 93.71 3.15 95.48 5.32 95.48 L 271.42 95.48 C 273.59 95.48 275.36 93.71 275.36 91.54 L 275.36 5.32 C 275.36 3.15 273.59 1.38 271.42 1.38 L 5.32 1.38 C 3.15 1.38 1.38 3.15 1.38 5.32 Z" style="stroke:none"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 11.81 85.05)"><g class="ltx_nestedsvg" fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="matrix(1 0 0 1 0 0)"><g fill="#737373" fill-opacity="1.000000"><path d="M 0 3.15 L 0 18.16 C 0 19.9 1.41 21.31 3.15 21.31 L 218.09 21.31 C 219.83 21.31 221.24 19.9 221.24 18.16 L 221.24 3.15 C 221.24 1.41 219.83 0 218.09 0 L 3.15 0 C 1.41 0 0 1.41 0 3.15 Z" style="stroke:none"></path></g><g fill="#737373" fill-opacity="1.000000"><path d="M 1.18 3.15 L 1.18 18.16 C 1.18 19.24 2.06 20.12 3.15 20.12 L 218.09 20.12 C 219.18 20.12 220.06 19.24 220.06 18.16 L 220.06 3.15 C 220.06 2.06 219.18 1.18 218.09 1.18 L 3.15 1.18 C 2.06 1.18 1.18 2.06 1.18 3.15 Z" style="stroke:none"></path></g><g fill-opacity="1.000000" transform="matrix(1.0 0.0 0.0 1.0 9.06 7.54)"><foreignobject height="11.07" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="203.13"><span class="ltx_text" id="S2.F1.pic1.2.2.2.1.1.1.1" style="font-size:90%;">Prompt: ES-EN zero-shot translation</span></foreignobject></g></g></g><g fill-opacity="1.000000" transform="matrix(1.0 0.0 0.0 1.0 9.47 78.88)"><foreignobject height="8.72" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="246.2"><span class="ltx_inline-para ltx_minipage ltx_align_bottom" id="S2.F1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1" style="width:177.9pt;">
<span class="ltx_para" id="S2.F1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1">
<span class="ltx_p" id="S2.F1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1"><em class="ltx_emph ltx_font_italic" id="S2.F1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.1" style="font-size:70%;"></em></span>
<span class="ltx_itemize" id="S2.I1">
<span class="ltx_item" id="S2.I1.ix1" style="list-style-type:none;">
<span class="ltx_para" id="S2.I1.ix1.p1">
<span class="ltx_p" id="S2.I1.ix1.p1.2"><em class="ltx_emph ltx_font_italic" id="S2.I1.ix1.p1.2.1" style="font-size:70%;">Spanish: </em><math alttext="&lt;" class="ltx_Math" display="inline" id="S2.I1.ix1.p1.1.m1.1"><semantics id="S2.I1.ix1.p1.1.m1.1a"><mo id="S2.I1.ix1.p1.1.m1.1.1" mathsize="70%" xref="S2.I1.ix1.p1.1.m1.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="S2.I1.ix1.p1.1.m1.1b"><lt id="S2.I1.ix1.p1.1.m1.1.1.cmml" xref="S2.I1.ix1.p1.1.m1.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.ix1.p1.1.m1.1c">&lt;</annotation><annotation encoding="application/x-llamapun" id="S2.I1.ix1.p1.1.m1.1d">&lt;</annotation></semantics></math><span class="ltx_text ltx_font_italic" id="S2.I1.ix1.p1.2.2" style="font-size:70%;">source_segment</span><math alttext="&gt;" class="ltx_Math" display="inline" id="S2.I1.ix1.p1.2.m2.1"><semantics id="S2.I1.ix1.p1.2.m2.1a"><mo id="S2.I1.ix1.p1.2.m2.1.1" mathsize="70%" xref="S2.I1.ix1.p1.2.m2.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S2.I1.ix1.p1.2.m2.1b"><gt id="S2.I1.ix1.p1.2.m2.1.1.cmml" xref="S2.I1.ix1.p1.2.m2.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.ix1.p1.2.m2.1c">&gt;</annotation><annotation encoding="application/x-llamapun" id="S2.I1.ix1.p1.2.m2.1d">&gt;</annotation></semantics></math><span class="ltx_text ltx_font_italic" id="S2.I1.ix1.p1.2.3" style="font-size:70%;"></span></span>
</span></span>
<span class="ltx_item" id="S2.I1.ix2" style="list-style-type:none;">
<span class="ltx_para" id="S2.I1.ix2.p1">
<span class="ltx_p" id="S2.I1.ix2.p1.2"><em class="ltx_emph ltx_font_italic" id="S2.I1.ix2.p1.2.1" style="font-size:70%;">English: </em><math alttext="&lt;" class="ltx_Math" display="inline" id="S2.I1.ix2.p1.1.m1.1"><semantics id="S2.I1.ix2.p1.1.m1.1a"><mo id="S2.I1.ix2.p1.1.m1.1.1" mathsize="70%" xref="S2.I1.ix2.p1.1.m1.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="S2.I1.ix2.p1.1.m1.1b"><lt id="S2.I1.ix2.p1.1.m1.1.1.cmml" xref="S2.I1.ix2.p1.1.m1.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.ix2.p1.1.m1.1c">&lt;</annotation><annotation encoding="application/x-llamapun" id="S2.I1.ix2.p1.1.m1.1d">&lt;</annotation></semantics></math><span class="ltx_text ltx_font_italic" id="S2.I1.ix2.p1.2.2" style="font-size:70%;">target_translation</span><math alttext="&gt;" class="ltx_Math" display="inline" id="S2.I1.ix2.p1.2.m2.1"><semantics id="S2.I1.ix2.p1.2.m2.1a"><mo id="S2.I1.ix2.p1.2.m2.1.1" mathsize="70%" xref="S2.I1.ix2.p1.2.m2.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S2.I1.ix2.p1.2.m2.1b"><gt id="S2.I1.ix2.p1.2.m2.1.1.cmml" xref="S2.I1.ix2.p1.2.m2.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.ix2.p1.2.m2.1c">&gt;</annotation><annotation encoding="application/x-llamapun" id="S2.I1.ix2.p1.2.m2.1d">&gt;</annotation></semantics></math><span class="ltx_text ltx_font_italic" id="S2.I1.ix2.p1.2.3" style="font-size:70%;"></span></span>
</span></span>
</span>
</span></span></foreignobject></g></g></svg>
<br class="ltx_break"/>
<br class="ltx_break"/>
<br class="ltx_break"/>
<br class="ltx_break"/><svg class="ltx_picture" height="106.35" id="S2.F1.pic2" overflow="visible" version="1.1" width="600"><g color="#000000" fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,106.35) matrix(1 0 0 -1 0 0) translate(161.63,0)"><g fill="#737373" fill-opacity="1.000000"><path d="M 0 5.32 L 0 91.54 C 0 94.48 2.38 96.86 5.32 96.86 L 271.42 96.86 C 274.36 96.86 276.74 94.48 276.74 91.54 L 276.74 5.32 C 276.74 2.38 274.36 0 271.42 0 L 5.32 0 C 2.38 0 0 2.38 0 5.32 Z" style="stroke:none"></path></g><g fill="#FCFCFF" fill-opacity="1.000000"><path d="M 1.38 5.32 L 1.38 91.54 C 1.38 93.71 3.15 95.48 5.32 95.48 L 271.42 95.48 C 273.59 95.48 275.36 93.71 275.36 91.54 L 275.36 5.32 C 275.36 3.15 273.59 1.38 271.42 1.38 L 5.32 1.38 C 3.15 1.38 1.38 3.15 1.38 5.32 Z" style="stroke:none"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 11.81 85.05)"><g class="ltx_nestedsvg" fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="matrix(1 0 0 1 0 0)"><g fill="#737373" fill-opacity="1.000000"><path d="M 0 3.15 L 0 18.16 C 0 19.9 1.41 21.31 3.15 21.31 L 214.59 21.31 C 216.33 21.31 217.74 19.9 217.74 18.16 L 217.74 3.15 C 217.74 1.41 216.33 0 214.59 0 L 3.15 0 C 1.41 0 0 1.41 0 3.15 Z" style="stroke:none"></path></g><g fill="#737373" fill-opacity="1.000000"><path d="M 1.18 3.15 L 1.18 18.16 C 1.18 19.24 2.06 20.12 3.15 20.12 L 214.59 20.12 C 215.68 20.12 216.56 19.24 216.56 18.16 L 216.56 3.15 C 216.56 2.06 215.68 1.18 214.59 1.18 L 3.15 1.18 C 2.06 1.18 1.18 2.06 1.18 3.15 Z" style="stroke:none"></path></g><g fill-opacity="1.000000" transform="matrix(1.0 0.0 0.0 1.0 9.06 7.54)"><foreignobject height="11.07" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="199.63"><span class="ltx_text" id="S2.F1.pic2.2.2.2.1.1.1.1" style="font-size:90%;">Prompt: ES-EN one-shot translation</span></foreignobject></g></g></g><g fill-opacity="1.000000" transform="matrix(1.0 0.0 0.0 1.0 9.47 78.88)"><foreignobject height="8.72" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="246.2"><span class="ltx_inline-para ltx_minipage ltx_align_bottom" id="S2.F1.pic2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1" style="width:177.9pt;">
<span class="ltx_para" id="S2.F1.pic2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1">
<span class="ltx_p" id="S2.F1.pic2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1"><em class="ltx_emph ltx_font_italic" id="S2.F1.pic2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.1" style="font-size:70%;"></em></span>
<span class="ltx_itemize" id="S2.I2">
<span class="ltx_item" id="S2.I2.ix1" style="list-style-type:none;">
<span class="ltx_para" id="S2.I2.ix1.p1">
<span class="ltx_p" id="S2.I2.ix1.p1.2"><em class="ltx_emph ltx_font_italic" id="S2.I2.ix1.p1.2.1" style="font-size:70%;">Spanish: </em><math alttext="&lt;" class="ltx_Math" display="inline" id="S2.I2.ix1.p1.1.m1.1"><semantics id="S2.I2.ix1.p1.1.m1.1a"><mo id="S2.I2.ix1.p1.1.m1.1.1" mathsize="70%" xref="S2.I2.ix1.p1.1.m1.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="S2.I2.ix1.p1.1.m1.1b"><lt id="S2.I2.ix1.p1.1.m1.1.1.cmml" xref="S2.I2.ix1.p1.1.m1.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="S2.I2.ix1.p1.1.m1.1c">&lt;</annotation><annotation encoding="application/x-llamapun" id="S2.I2.ix1.p1.1.m1.1d">&lt;</annotation></semantics></math><span class="ltx_text ltx_font_italic" id="S2.I2.ix1.p1.2.2" style="font-size:70%;">source_fuzzy_match</span><math alttext="&gt;" class="ltx_Math" display="inline" id="S2.I2.ix1.p1.2.m2.1"><semantics id="S2.I2.ix1.p1.2.m2.1a"><mo id="S2.I2.ix1.p1.2.m2.1.1" mathsize="70%" xref="S2.I2.ix1.p1.2.m2.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S2.I2.ix1.p1.2.m2.1b"><gt id="S2.I2.ix1.p1.2.m2.1.1.cmml" xref="S2.I2.ix1.p1.2.m2.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S2.I2.ix1.p1.2.m2.1c">&gt;</annotation><annotation encoding="application/x-llamapun" id="S2.I2.ix1.p1.2.m2.1d">&gt;</annotation></semantics></math><span class="ltx_text ltx_font_italic" id="S2.I2.ix1.p1.2.3" style="font-size:70%;"></span></span>
</span></span>
<span class="ltx_item" id="S2.I2.ix2" style="list-style-type:none;">
<span class="ltx_para" id="S2.I2.ix2.p1">
<span class="ltx_p" id="S2.I2.ix2.p1.2"><em class="ltx_emph ltx_font_italic" id="S2.I2.ix2.p1.2.1" style="font-size:70%;">English: </em><math alttext="&lt;" class="ltx_Math" display="inline" id="S2.I2.ix2.p1.1.m1.1"><semantics id="S2.I2.ix2.p1.1.m1.1a"><mo id="S2.I2.ix2.p1.1.m1.1.1" mathsize="70%" xref="S2.I2.ix2.p1.1.m1.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="S2.I2.ix2.p1.1.m1.1b"><lt id="S2.I2.ix2.p1.1.m1.1.1.cmml" xref="S2.I2.ix2.p1.1.m1.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="S2.I2.ix2.p1.1.m1.1c">&lt;</annotation><annotation encoding="application/x-llamapun" id="S2.I2.ix2.p1.1.m1.1d">&lt;</annotation></semantics></math><span class="ltx_text ltx_font_italic" id="S2.I2.ix2.p1.2.2" style="font-size:70%;">target_fuzzy_match</span><math alttext="&gt;" class="ltx_Math" display="inline" id="S2.I2.ix2.p1.2.m2.1"><semantics id="S2.I2.ix2.p1.2.m2.1a"><mo id="S2.I2.ix2.p1.2.m2.1.1" mathsize="70%" xref="S2.I2.ix2.p1.2.m2.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S2.I2.ix2.p1.2.m2.1b"><gt id="S2.I2.ix2.p1.2.m2.1.1.cmml" xref="S2.I2.ix2.p1.2.m2.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S2.I2.ix2.p1.2.m2.1c">&gt;</annotation><annotation encoding="application/x-llamapun" id="S2.I2.ix2.p1.2.m2.1d">&gt;</annotation></semantics></math><span class="ltx_text ltx_font_italic" id="S2.I2.ix2.p1.2.3" style="font-size:70%;"></span></span>
</span></span>
<span class="ltx_item" id="S2.I2.ix3" style="list-style-type:none;">
<span class="ltx_para" id="S2.I2.ix3.p1">
<span class="ltx_p" id="S2.I2.ix3.p1.2"><em class="ltx_emph ltx_font_italic" id="S2.I2.ix3.p1.2.1" style="font-size:70%;">Spanish: </em><math alttext="&lt;" class="ltx_Math" display="inline" id="S2.I2.ix3.p1.1.m1.1"><semantics id="S2.I2.ix3.p1.1.m1.1a"><mo id="S2.I2.ix3.p1.1.m1.1.1" mathsize="70%" xref="S2.I2.ix3.p1.1.m1.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="S2.I2.ix3.p1.1.m1.1b"><lt id="S2.I2.ix3.p1.1.m1.1.1.cmml" xref="S2.I2.ix3.p1.1.m1.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="S2.I2.ix3.p1.1.m1.1c">&lt;</annotation><annotation encoding="application/x-llamapun" id="S2.I2.ix3.p1.1.m1.1d">&lt;</annotation></semantics></math><span class="ltx_text ltx_font_italic" id="S2.I2.ix3.p1.2.2" style="font-size:70%;">source_segment</span><math alttext="&gt;" class="ltx_Math" display="inline" id="S2.I2.ix3.p1.2.m2.1"><semantics id="S2.I2.ix3.p1.2.m2.1a"><mo id="S2.I2.ix3.p1.2.m2.1.1" mathsize="70%" xref="S2.I2.ix3.p1.2.m2.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S2.I2.ix3.p1.2.m2.1b"><gt id="S2.I2.ix3.p1.2.m2.1.1.cmml" xref="S2.I2.ix3.p1.2.m2.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S2.I2.ix3.p1.2.m2.1c">&gt;</annotation><annotation encoding="application/x-llamapun" id="S2.I2.ix3.p1.2.m2.1d">&gt;</annotation></semantics></math><span class="ltx_text ltx_font_italic" id="S2.I2.ix3.p1.2.3" style="font-size:70%;"></span></span>
</span></span>
<span class="ltx_item" id="S2.I2.ix4" style="list-style-type:none;">
<span class="ltx_para" id="S2.I2.ix4.p1">
<span class="ltx_p" id="S2.I2.ix4.p1.2"><em class="ltx_emph ltx_font_italic" id="S2.I2.ix4.p1.2.1" style="font-size:70%;">English: </em><math alttext="&lt;" class="ltx_Math" display="inline" id="S2.I2.ix4.p1.1.m1.1"><semantics id="S2.I2.ix4.p1.1.m1.1a"><mo id="S2.I2.ix4.p1.1.m1.1.1" mathsize="70%" xref="S2.I2.ix4.p1.1.m1.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="S2.I2.ix4.p1.1.m1.1b"><lt id="S2.I2.ix4.p1.1.m1.1.1.cmml" xref="S2.I2.ix4.p1.1.m1.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="S2.I2.ix4.p1.1.m1.1c">&lt;</annotation><annotation encoding="application/x-llamapun" id="S2.I2.ix4.p1.1.m1.1d">&lt;</annotation></semantics></math><span class="ltx_text ltx_font_italic" id="S2.I2.ix4.p1.2.2" style="font-size:70%;">target_translation</span><math alttext="&gt;" class="ltx_Math" display="inline" id="S2.I2.ix4.p1.2.m2.1"><semantics id="S2.I2.ix4.p1.2.m2.1a"><mo id="S2.I2.ix4.p1.2.m2.1.1" mathsize="70%" xref="S2.I2.ix4.p1.2.m2.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S2.I2.ix4.p1.2.m2.1b"><gt id="S2.I2.ix4.p1.2.m2.1.1.cmml" xref="S2.I2.ix4.p1.2.m2.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S2.I2.ix4.p1.2.m2.1c">&gt;</annotation><annotation encoding="application/x-llamapun" id="S2.I2.ix4.p1.2.m2.1d">&gt;</annotation></semantics></math><span class="ltx_text ltx_font_italic" id="S2.I2.ix4.p1.2.3" style="font-size:70%;"></span></span>
</span></span>
</span>
</span></span></foreignobject></g></g></svg>
<br class="ltx_break"/>
<div class="ltx_pagination ltx_role_end_2_columns"></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Zero-shot and one-shot prompts used for fine-tuning Mistral</figcaption>
</figure>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1">Originally, we mixed Spanish-to-English medical datasets from OPUS <cite class="ltx_cite ltx_citemacro_citep">(Tiedemann,, <a class="ltx_ref" href="#bib.bib34" title="">2012</a>)</cite>, namely ELRC <cite class="ltx_cite ltx_citemacro_cite">(Berzins et al.,, <a class="ltx_ref" href="#bib.bib5" title="">2019</a>, et al.)</cite>, EMEA <cite class="ltx_cite ltx_citemacro_citep">(EMA,, <a class="ltx_ref" href="#bib.bib10" title="">2012</a>)</cite>, SciELO <cite class="ltx_cite ltx_citemacro_citep">(Soares et al.,, <a class="ltx_ref" href="#bib.bib33" title="">2018</a>)</cite>, and TICO-19 <cite class="ltx_cite ltx_citemacro_citep">(Anastasopoulos et al.,, <a class="ltx_ref" href="#bib.bib3" title="">2020</a>)</cite> datasets. Then we filtered<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>Scripts are available at: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/ymoslem/MT-Preparation" title="">https://github.com/ymoslem/MT-Preparation</a></span></span></span> the resulted dataset, to exclude duplicates and too long segments.<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>As NLLB supports a maximum token length of 512 <span class="ltx_text ltx_font_italic" id="footnote3.1">tokens</span>, we excluded any segment whose source or target text longer than 70 <span class="ltx_text ltx_font_italic" id="footnote3.2">words</span> to also take into account the one-shot case that will augment another segment to the original one. As the context window of Mistral is much larger (8K tokens), it is theoretically possible to translate longer segments.</span></span></span>
The whole dataset includes 1,868,505 segments before filtering, and 922,343 segments after filtering.<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>We observe that almost two-thirds of the EMEA dataset are duplicates.</span></span></span> However, we used only part of it for this preliminary experiment. In the future, we would like to increase the size of the training data and compare the performance. Nevertheless, achieving these results (cf. Table <a class="ltx_ref" href="#S3.T1" title="Table 1 ‣ 3 Results ‣ Fine-tuning Large Language Models for Adaptive Machine Translation"><span class="ltx_text ltx_ref_tag">1</span></a>) with such a small dataset (cf. Section <a class="ltx_ref" href="#S2.SS1" title="2.1 Data ‣ 2 Experimental Setup ‣ Fine-tuning Large Language Models for Adaptive Machine Translation"><span class="ltx_text ltx_ref_tag">2.1</span></a>) shows how promising this approach is.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Information Retrieval</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">For indexing and retrieval of fuzzy matches, we use Sentence-Transformers <cite class="ltx_cite ltx_citemacro_citep">(Reimers and Gurevych,, <a class="ltx_ref" href="#bib.bib27" title="">2019</a>)</cite> and <span class="ltx_text ltx_font_italic" id="S2.SS2.p1.1.1">Faiss</span> <cite class="ltx_cite ltx_citemacro_citep">(Johnson et al.,, <a class="ltx_ref" href="#bib.bib17" title="">2019</a>)</cite>, with a multilingual model to generate the embeddings for the datasets and later to extract fuzzy matches through semantic search.</p>
</div>
<section class="ltx_paragraph" id="S2.SS2.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Embedding:</h4>
<div class="ltx_para" id="S2.SS2.SSS0.Px1.p1">
<p class="ltx_p" id="S2.SS2.SSS0.Px1.p1.1">To encode all the translation segments into embeddings, we employ a <span class="ltx_text ltx_font_italic" id="S2.SS2.SSS0.Px1.p1.1.1">multilingual</span> model, namely Microsoft’s <span class="ltx_text ltx_font_italic" id="S2.SS2.SSS0.Px1.p1.1.2">“Multilingual-MiniLM-L12-H384”</span> <cite class="ltx_cite ltx_citemacro_citep">(Wang et al.,, <a class="ltx_ref" href="#bib.bib36" title="">2020</a>)</cite>. These embeddings will be used later for both indexing and retrieval. The step of generating embeddings can be implemented with the Sentence-Transformers library.<span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.sbert.net/" title="">https://www.sbert.net/</a></span></span></span></p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS2.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Indexing:</h4>
<div class="ltx_para" id="S2.SS2.SSS0.Px2.p1">
<p class="ltx_p" id="S2.SS2.SSS0.Px2.p1.1">For indexing, we use Faiss,<span class="ltx_note ltx_role_footnote" id="footnote6"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/facebookresearch/faiss" title="">https://github.com/facebookresearch/faiss</a></span></span></span> a library for efficient similarity search and clustering of dense vectors. We train an <em class="ltx_emph ltx_font_italic" id="S2.SS2.SSS0.Px2.p1.1.1">IndexIVFFlat</em> index, which uses <em class="ltx_emph ltx_font_italic" id="S2.SS2.SSS0.Px2.p1.1.2">IndexFlatL2</em> as a quantiser.<span class="ltx_note ltx_role_footnote" id="footnote7"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/facebookresearch/faiss/wiki/Faster-search" title="">https://github.com/facebookresearch/faiss/wiki/Faster-search</a></span></span></span>
The embedding size is 384, which is the same as the embedding size of model used.
For the number of clusters at indexing time, the <em class="ltx_emph ltx_font_italic" id="S2.SS2.SSS0.Px2.p1.1.3">nlist</em> parameter was set to 4096, while the number of clusters to explore at search time <span class="ltx_text ltx_font_italic" id="S2.SS2.SSS0.Px2.p1.1.4">nprobe</span> was set to search for nearest neighbours in 32 clusters.<span class="ltx_note ltx_role_footnote" id="footnote8"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span>According to Faiss’ guidelines for choosing an index, the number of clusters is recommended to be between <em class="ltx_emph ltx_font_italic" id="footnote8.1">4*sqrt(N)</em> to <em class="ltx_emph ltx_font_italic" id="footnote8.2">16*sqrt(N)</em>, where <em class="ltx_emph ltx_font_italic" id="footnote8.3">N</em> is the size of the dataset. As the “context dataset” includes 50,000 segments, we might experiment in the future with increasing the number of clusters while training an index. Obviously, this would depend on the available computational resources.</span></span></span></p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS2.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Semantic Search:</h4>
<div class="ltx_para" id="S2.SS2.SSS0.Px3.p1">
<p class="ltx_p" id="S2.SS2.SSS0.Px3.p1.1">This step computes the cosine similarity between the query and all the documents in the corpus based on their embeddings, and retrieves the top <math alttext="k" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px3.p1.1.m1.1"><semantics id="S2.SS2.SSS0.Px3.p1.1.m1.1a"><mi id="S2.SS2.SSS0.Px3.p1.1.m1.1.1" xref="S2.SS2.SSS0.Px3.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px3.p1.1.m1.1b"><ci id="S2.SS2.SSS0.Px3.p1.1.m1.1.1.cmml" xref="S2.SS2.SSS0.Px3.p1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px3.p1.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px3.p1.1.m1.1d">italic_k</annotation></semantics></math> matching entries. In this case, our query is each source segment, and the corpus is the unique “context dataset” (cf. Section <a class="ltx_ref" href="#S2.SS1" title="2.1 Data ‣ 2 Experimental Setup ‣ Fine-tuning Large Language Models for Adaptive Machine Translation"><span class="ltx_text ltx_ref_tag">2.1</span></a>) leveraged to extract fuzzy matches.</p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS2.SSS0.Px4">
<h4 class="ltx_title ltx_title_paragraph">Re-ranking:</h4>
<div class="ltx_para" id="S2.SS2.SSS0.Px4.p1">
<p class="ltx_p" id="S2.SS2.SSS0.Px4.p1.1">The embedding step is usually done by a more efficient model to retrieve the most probable results (e.g. the top 100 results). Later, a re-ranker based on a cross-encoder is used to score the relevancy of all candidates for the given search query. This dual process is supposed to improve both efficiency and quality of the retrieved documents. However, we did not apply this step in our experiments.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Fine-tuning</h3>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1">We used QLoRA <cite class="ltx_cite ltx_citemacro_citep">(Hu et al.,, <a class="ltx_ref" href="#bib.bib13" title="">2021</a>; Dettmers et al.,, <a class="ltx_ref" href="#bib.bib9" title="">2023</a>)</cite> for efficient fine-tuning with 4bit quantization, with Hugging Face Transformers.<span class="ltx_note ltx_role_footnote" id="footnote9"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/huggingface/transformers" title="">https://github.com/huggingface/transformers</a></span></span></span> Fine-tuning was for one epoch, which revealed better results than fine-tuning for 4 epochs. Quantization configuration through <span class="ltx_text ltx_font_italic" id="S2.SS3.p1.1.1">BitsAndBytes</span> includes: <span class="ltx_text ltx_font_italic" id="S2.SS3.p1.1.2" style="font-size:90%;">load_in_4bit=True<span class="ltx_text ltx_font_upright" id="S2.SS3.p1.1.2.1">, </span>bnb_4bit_quant_type“nf4”<span class="ltx_text ltx_font_upright" id="S2.SS3.p1.1.2.2">, </span>bnb_4bit_use_double_quant=True<span class="ltx_text ltx_font_upright" id="S2.SS3.p1.1.2.3">, and </span>bnb_4bit_compute_dtype=torch.bfloat16</span>. LoRA configuration was set via the PEFT library<span class="ltx_note ltx_role_footnote" id="footnote10"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup><span class="ltx_tag ltx_tag_note">10</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/huggingface/peft" title="">https://github.com/huggingface/peft</a></span></span></span> as follows: the dimension of the low-rank matrices <span class="ltx_text ltx_font_italic" id="S2.SS3.p1.1.3">r=64</span>, the scaling factor for the weight matrices <span class="ltx_text ltx_font_italic" id="S2.SS3.p1.1.4">lora_alpha=16</span>, dropout probability of the LoRA layers <span class="ltx_text ltx_font_italic" id="S2.SS3.p1.1.5">lora_dropout=0.1</span>, and without training the bias parameters for better performance <span class="ltx_text ltx_font_italic" id="S2.SS3.p1.1.6">bias=“none”</span>.
Training arguments include: batch size for training and evaluation 32 examples, <span class="ltx_text ltx_font_italic" id="S2.SS3.p1.1.7" style="font-size:90%;">warmup_steps=0.03<span class="ltx_text ltx_font_upright" id="S2.SS3.p1.1.7.1">, </span>learning_rate=2e-3<span class="ltx_text ltx_font_upright" id="S2.SS3.p1.1.7.2">, </span>lr_scheduler_type=“constant”<span class="ltx_text ltx_font_upright" id="S2.SS3.p1.1.7.3">, and </span>bf16=True</span>.
Both training and inference utilise Google Colab Pro+ with one GPU <span class="ltx_text ltx_font_italic" id="S2.SS3.p1.1.8">NVIDIA A100-SXM4-40GB</span>.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.4 </span>Inference</h3>
<div class="ltx_para" id="S2.SS4.p1">
<p class="ltx_p" id="S2.SS4.p1.1">For inference, we experimented with a number of models including NLLB-200 <cite class="ltx_cite ltx_citemacro_citep">(Costa-jussà et al.,, <a class="ltx_ref" href="#bib.bib8" title="">2022</a>)</cite> whose architecture is encoder-decoder Transformer <cite class="ltx_cite ltx_citemacro_citep">(Vaswani et al.,, <a class="ltx_ref" href="#bib.bib35" title="">2017</a>)</cite> as well as ChatGPT <cite class="ltx_cite ltx_citemacro_cite">Brown et al., (<a class="ltx_ref" href="#bib.bib6" title="">2020</a>); Ouyang et al., (<a class="ltx_ref" href="#bib.bib22" title="">2022</a>)</cite> and Mistral 7B, which are autoregressive decoder-only Transformer-based LLMs. Mistral 7B was used both without fine-tuning and after fine-tuning on a mix of zero-shot and one-shot translation prompts.</p>
</div>
<section class="ltx_paragraph" id="S2.SS4.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Mistral 7B:</h4>
<div class="ltx_para" id="S2.SS4.SSS0.Px1.p1">
<p class="ltx_p" id="S2.SS4.SSS0.Px1.p1.1">For inference (translation), we converted both the baseline and our fine-tuned models of Mistral to the CTranslate2 <span class="ltx_note ltx_role_footnote" id="footnote11"><sup class="ltx_note_mark">11</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">11</sup><span class="ltx_tag ltx_tag_note">11</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/OpenNMT/CTranslate2" title="">https://github.com/OpenNMT/CTranslate2</a></span></span></span> <cite class="ltx_cite ltx_citemacro_citep">(Klein et al.,, <a class="ltx_ref" href="#bib.bib18" title="">2020</a>)</cite> format (with 8int quantization) for more efficiency. We employed greedy search by setting <span class="ltx_text ltx_font_italic" id="S2.SS4.SSS0.Px1.p1.1.1">sampling_topk=1</span> and added the new line <code class="ltx_verbatim ltx_font_typewriter" id="S2.SS4.SSS0.Px1.p1.1.2">\n</code> character to <span class="ltx_text ltx_font_italic" id="S2.SS4.SSS0.Px1.p1.1.3">end_token</span> to avoid overgeneration. Mistral through CTranslate2 translates the zero-shot test dataset that includes 10,000 sentences in 2–3 minutes (approx. 80 segments/second). The time almost doubles for the one-shot test dataset. Figure <a class="ltx_ref" href="#S2.F1" title="Figure 1 ‣ 2.1 Data ‣ 2 Experimental Setup ‣ Fine-tuning Large Language Models for Adaptive Machine Translation"><span class="ltx_text ltx_ref_tag">1</span></a> illustrates the prompts used for both inference and fine-tuning. Two versions of Mistral were tested, the baseline model without fine-tuning, and the model we fine-tuned on a mix of zero-shot and one-shot translation prompts. Table <a class="ltx_ref" href="#S3.T1" title="Table 1 ‣ 3 Results ‣ Fine-tuning Large Language Models for Adaptive Machine Translation"><span class="ltx_text ltx_ref_tag">1</span></a> shows translation evaluation results of both models. Fine-tuning Mistral on a mix of zero-shot and one-shot prompts improved both its regular translation quality (i.e. when only the source text is available) and adaptive translation quality (in this case, when one fuzzy match is provided) at inference time.</p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS4.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">ChatGPT:</h4>
<div class="ltx_para" id="S2.SS4.SSS0.Px2.p1">
<p class="ltx_p" id="S2.SS4.SSS0.Px2.p1.1">The model used is “gpt-3.5-turbo” with <span class="ltx_text ltx_font_italic" id="S2.SS4.SSS0.Px2.p1.1.1">temperature=0.3</span> and <span class="ltx_text ltx_font_italic" id="S2.SS4.SSS0.Px2.p1.1.2">top_p=1</span>. Requests are sent in batches of 20 segments, and the <span class="ltx_text ltx_font_italic" id="S2.SS4.SSS0.Px2.p1.1.3">max_tokens</span> argument was set as the largest number of words per source segment in a batch multiplied by 4, which is a rough number that can be increased or decreased based on the language and model. When the source text is augmented with one fuzzy match, the translation quality is improved by several points across all the automatic evaluation metrics. These quality gains are in line with results from previous work <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="#bib.bib20" title="">Moslem et al., 2023a, </a>)</cite> although in this work we are using a different dataset. However, it is worth noting that although batch processing was employed, there is no guarantee of the generation time with ChatGPT, which can range from several minutes to a couple of hours. In this sense, we observe that Mistral 7B is much more efficient, especially when used with CTranslate2.</p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS4.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">NLLB-200:</h4>
<div class="ltx_para" id="S2.SS4.SSS0.Px3.p1">
<p class="ltx_p" id="S2.SS4.SSS0.Px3.p1.1">In this set of experiments, the NLLB model was used as is, i.e. without fine-tuning. The first two rows of Table <a class="ltx_ref" href="#S3.T1" title="Table 1 ‣ 3 Results ‣ Fine-tuning Large Language Models for Adaptive Machine Translation"><span class="ltx_text ltx_ref_tag">1</span></a> show the evaluation scores of using NLLB 3.3B for translation without a fuzzy match (zero-shot) and with a fuzzy match (one-shot). The same test dataset and its unique context dataset were used; however, fuzzy matching augmentation was done differently to match the architecture of the NLLB model. Each source sentence was augmented with its best fuzzy match, and the two sentences were separated by the language code of the source language (in this case “spa_Latn”). As NLLB was mainly pre-trained on sentences, we had to add an extra token that usually comes at the beginning of sentences, such as a bullet point (“<span class="ltx_text" id="S2.SS4.SSS0.Px3.p1.1.1" style="font-size:50%;">•</span>”) after the language code between the two source sentences. Hence, the target fuzzy match was fed to the model as a prefix augmented by the target language code (in this case “eng_Latn”) and the extra token. In this sense, the model was encouraged to complete the translation through teacher-forcing <cite class="ltx_cite ltx_citemacro_citep">(Williams and Zipser,, <a class="ltx_ref" href="#bib.bib37" title="">1989</a>)</cite>, i.e. using the ground truth as input, instead of the model output. In other words, the model is not required to translate the target fuzzy match, but rather to use the provided translation as is to guide the translation of the new untranslated source sentence. Translation arguments include: <span class="ltx_text ltx_font_italic" id="S2.SS4.SSS0.Px3.p1.1.2">batch_type=“tokens”</span>, <span class="ltx_text ltx_font_italic" id="S2.SS4.SSS0.Px3.p1.1.3">max_batch_size=2024</span>, <span class="ltx_text ltx_font_italic" id="S2.SS4.SSS0.Px3.p1.1.4">beam_size=2</span>, <span class="ltx_text ltx_font_italic" id="S2.SS4.SSS0.Px3.p1.1.5">min_decoding_length=2</span>, and <span class="ltx_text ltx_font_italic" id="S2.SS4.SSS0.Px3.p1.1.6">max_decoding_length=512</span>. Although there is a marginal improvement given the BLEU score <cite class="ltx_cite ltx_citemacro_citep">(Papineni et al.,, <a class="ltx_ref" href="#bib.bib23" title="">2002</a>)</cite>, the performance degrades according to the other reported automatic evaluation metrics, chrF++ <cite class="ltx_cite ltx_citemacro_citep">(Popović,, <a class="ltx_ref" href="#bib.bib25" title="">2017</a>)</cite>, TER <cite class="ltx_cite ltx_citemacro_citep">(Snover et al.,, <a class="ltx_ref" href="#bib.bib32" title="">2006</a>)</cite> and COMET <cite class="ltx_cite ltx_citemacro_citep">(Rei et al.,, <a class="ltx_ref" href="#bib.bib26" title="">2020</a>)</cite>. The fact that NLLB was trained to translate individual sentences rather than a series of sentences or full documents could be the main reason for this. In the future, we would like to experiment with fine-tuning NLLB with fuzzy matching augmentation and compare the results.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Results</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">This section demonstrates the results of fine-tuning Mistral 7B for “adaptive” MT. As detailed in Section <a class="ltx_ref" href="#S2" title="2 Experimental Setup ‣ Fine-tuning Large Language Models for Adaptive Machine Translation"><span class="ltx_text ltx_ref_tag">2</span></a>, the model is not only fine-tuned on a mix of zero-shot and one-shot translation prompts to improve enhance real-time adaptive MT. In other words, it was fine-tuned to boost the LLM ability to adapt it output to the required domain at translation time. The experiment was conducted for Spanish-to-English medical adaptive MT.</p>
</div>
<figure class="ltx_table" id="S3.T1">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S3.T1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T1.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T1.1.1.1.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.1.1" style="font-size:90%;">Lang</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T1.1.1.1.2" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.2.1" style="font-size:90%;">Model</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T1.1.1.1.3" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.3.1" style="font-size:90%;">Context</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T1.1.1.1.4" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.4.1" style="font-size:90%;">BLEU ↑</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T1.1.1.1.5" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.5.1" style="font-size:90%;">chrF++ ↑</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T1.1.1.1.6" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.6.1" style="font-size:90%;">TER ↓</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T1.1.1.1.7" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.7.1" style="font-size:90%;">COMET ↑</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T1.1.2.1">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S3.T1.1.2.1.1" rowspan="8" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.1.2.1.1.1" style="font-size:90%;">ES-EN</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.2.1.2" rowspan="2" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S3.T1.1.2.1.2.1" style="font-size:90%;">NLLB 3.3B</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.2.1.3" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S3.T1.1.2.1.3.1" style="font-size:90%;">Source only (zero-shot)</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.2.1.4" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_framed_underline" id="S3.T1.1.2.1.4.1" style="font-size:90%;">47.02</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.2.1.5" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S3.T1.1.2.1.5.1" style="font-size:90%;">68.82</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.2.1.6" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S3.T1.1.2.1.6.1" style="font-size:90%;">43.43</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.2.1.7" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S3.T1.1.2.1.7.1" style="font-size:90%;">66.46</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.3.2">
<td class="ltx_td ltx_align_center" id="S3.T1.1.3.2.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S3.T1.1.3.2.1.1" style="font-size:90%;">+ Fuzzy (one-shot)</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.3.2.2" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S3.T1.1.3.2.2.1" style="font-size:90%;">47.42</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.3.2.3" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S3.T1.1.3.2.3.1" style="font-size:90%;">68.77</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.3.2.4" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S3.T1.1.3.2.4.1" style="font-size:90%;">45.26</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.3.2.5" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S3.T1.1.3.2.5.1" style="font-size:90%;">64.57</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.4.3">
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.4.3.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S3.T1.1.4.3.1.1" style="font-size:90%;">ChatGPT</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.4.3.2" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S3.T1.1.4.3.2.1" style="font-size:90%;">Source only (zero-shot)</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.4.3.3" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S3.T1.1.4.3.3.1" style="font-size:90%;">44.65</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.4.3.4" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S3.T1.1.4.3.4.1" style="font-size:90%;">68.36</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.4.3.5" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S3.T1.1.4.3.5.1" style="font-size:90%;">44.28</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.4.3.6" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S3.T1.1.4.3.6.1" style="font-size:90%;">74.48</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.5.4">
<td class="ltx_td ltx_align_center" id="S3.T1.1.5.4.1" style="padding-left:4.0pt;padding-right:4.0pt;">
<span class="ltx_text" id="S3.T1.1.5.4.1.1" style="font-size:90%;">“</span><span class="ltx_text" id="S3.T1.1.5.4.1.2" style="font-size:80%;">gpt-3.5-turbo”</span>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.5.4.2" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S3.T1.1.5.4.2.1" style="font-size:90%;">+ Fuzzy (one-shot)</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.5.4.3" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S3.T1.1.5.4.3.1" style="font-size:90%;">48.34</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.5.4.4" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S3.T1.1.5.4.4.1" style="font-size:90%;">70.54</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.5.4.5" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S3.T1.1.5.4.5.1" style="font-size:90%;">40.80</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.5.4.6" style="padding-left:4.0pt;padding-right:4.0pt;">
<span class="ltx_text ltx_font_bold" id="S3.T1.1.5.4.6.1" style="font-size:90%;">80.25</span><span class="ltx_text" id="S3.T1.1.5.4.6.2" style="font-size:90%;">*</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.6.5">
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.6.5.1" rowspan="2" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S3.T1.1.6.5.1.1" style="font-size:90%;">Mistral 7B</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.6.5.2" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S3.T1.1.6.5.2.1" style="font-size:90%;">Source only (zero-shot)</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.6.5.3" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S3.T1.1.6.5.3.1" style="font-size:90%;">42.88</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.6.5.4" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S3.T1.1.6.5.4.1" style="font-size:90%;">66.03</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.6.5.5" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S3.T1.1.6.5.5.1" style="font-size:90%;">46.54</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.6.5.6" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S3.T1.1.6.5.6.1" style="font-size:90%;">69.56</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.7.6">
<td class="ltx_td ltx_align_center" id="S3.T1.1.7.6.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S3.T1.1.7.6.1.1" style="font-size:90%;">+ Fuzzy (one-shot)</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.7.6.2" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S3.T1.1.7.6.2.1" style="font-size:90%;">47.35</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.7.6.3" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S3.T1.1.7.6.3.1" style="font-size:90%;">69.25</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.7.6.4" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S3.T1.1.7.6.4.1" style="font-size:90%;">42.53</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.7.6.5" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S3.T1.1.7.6.5.1" style="font-size:90%;">76.37</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.8.7">
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.8.7.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S3.T1.1.8.7.1.1" style="font-size:90%;">Mistral 7B</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.8.7.2" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S3.T1.1.8.7.2.1" style="font-size:90%;">Source only (zero-shot)</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.8.7.3" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S3.T1.1.8.7.3.1" style="font-size:90%;">46.71</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.8.7.4" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_framed_underline" id="S3.T1.1.8.7.4.1" style="font-size:90%;">69.55</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.8.7.5" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_framed_underline" id="S3.T1.1.8.7.5.1" style="font-size:90%;">41.81</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.8.7.6" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_framed_underline" id="S3.T1.1.8.7.6.1" style="font-size:90%;">77.44</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.9.8">
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.1.9.8.1" style="padding-left:4.0pt;padding-right:4.0pt;">
<span class="ltx_text" id="S3.T1.1.9.8.1.1" style="font-size:90%;">“</span><span class="ltx_text ltx_font_bold" id="S3.T1.1.9.8.1.2" style="font-size:90%;">Fine-tuned</span><span class="ltx_text" id="S3.T1.1.9.8.1.3" style="font-size:90%;">”</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.1.9.8.2" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text" id="S3.T1.1.9.8.2.1" style="font-size:90%;">+ Fuzzy (one-shot)</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.1.9.8.3" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.1.9.8.3.1" style="font-size:90%;">49.69</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.1.9.8.4" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.1.9.8.4.1" style="font-size:90%;">70.89</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.1.9.8.5" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.1.9.8.5.1" style="font-size:90%;">40.08</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.1.9.8.6" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.1.9.8.6.1" style="font-size:90%;">79.62</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Comparing adaptive MT with NLLB-200 3.3B, ChatGPT, and Mistral 7B (before and after fine-tuning). Our fine-tuned version of Mistral demonstrates translation quality gains that are on par with the task-oriented NLLB model for zero-shot translation, and outperform both NLLB and ChatGPT for one-shot adaptive MT with one fuzzy match.</figcaption>
</figure>
<div class="ltx_para" id="S3.p2">
<p class="ltx_p" id="S3.p2.1">In Table <a class="ltx_ref" href="#S3.T1" title="Table 1 ‣ 3 Results ‣ Fine-tuning Large Language Models for Adaptive Machine Translation"><span class="ltx_text ltx_ref_tag">1</span></a>, the last two rows show the results for fine-tuning Mistral 7B. The rest of the results are for baselines, i.e. without fine-tuning. As illustrated, fine-tuning has led to quality improvements in terms of both zero-shot and one-shot translation. The fine-tuned version of Mistral outperforms its own baseline (i.e. without fine-tuning) for both zero-shot and one-shot translation. Zero-shot translation of the fine-tuned Mistral outperforms ChatGPT “gpt-3.5-turbo”, while one-shot translation quality of fine-tuned Mistral is on par with that of ChatGPT. Zero-shot translation of the fine-tuned Mistral is on par with NLLB 3.3B, while one-shot translation quality of the fine-tuned Mistral outperforms that of NLLB 3.3B. To conclude, fine-tuning an efficient LLM like Mistral 7B helps to produce a high-quality zero-shot translation comparable to that of MT task-oriented models such as NLLB 3.3B, while achieving adaptive gains of one-shot translation on par with commercial LLMs such as ChatGPT “gpt-3.5-turbo”.</p>
</div>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Conclusion and Future Work</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">In this work, we showed how fine-tuning a general purpose LLM such as Mistral 7B can improve its in-context learning ability, especially for real-time adaptive MT. Moreover, such translation quality gains were achievable through fine-tuning using a relatively small dataset (20,000 segments). Incorporating a mix of zero-shot and one-shot prompts in the training data helps improve both regular zero-shot translation, and one-shot translation that incorporates a fuzzy match. It is worth noting that Mistral 7B is much more efficient than ChatGPT, which is an added benefit in production scenarios.</p>
</div>
<div class="ltx_para" id="S4.p2">
<p class="ltx_p" id="S4.p2.1">In the future, we would like to experiment with other domains and language pairs, including low-resource languages. As currently there are several multilingual LLMs such as BLOOM (46 languages) <cite class="ltx_cite ltx_citemacro_citep">(Le Scao et al.,, <a class="ltx_ref" href="#bib.bib19" title="">2022</a>)</cite>, Falcon (EN-DE-ES-FR) <cite class="ltx_cite ltx_citemacro_citep">(Penedo et al.,, <a class="ltx_ref" href="#bib.bib24" title="">2023</a>)</cite>, larger versions of Mistral/Mixtral (EN-DE-ES-FR-IT) <cite class="ltx_cite ltx_citemacro_citep">(Jiang et al.,, <a class="ltx_ref" href="#bib.bib15" title="">2023</a>)</cite>, Jais (AR-EN) <cite class="ltx_cite ltx_citemacro_citep">(Sengupta et al.,, <a class="ltx_ref" href="#bib.bib30" title="">2023</a>)</cite>, Baichuan (ZH) <cite class="ltx_cite ltx_citemacro_citep">(Yang et al.,, <a class="ltx_ref" href="#bib.bib40" title="">2023</a>)</cite>, and Qwen (ZH) <cite class="ltx_cite ltx_citemacro_citep">(Bai et al.,, <a class="ltx_ref" href="#bib.bib4" title="">2023</a>)</cite>, it can be insightful to apply the same approach with these models. Furthermore, as we experimented with NLLB-200 without fine-tuning, we would like to experiment with fine-tuning for fair comparison. While we fine-tuned Mistral on a small dataset, it is recommended to experiment with fine-tuning on more data, especially from the same domain. It can also be helpful to incorporate different types of prompts, such as few-shot prompts, and terminology-based prompts.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.p3">
<br class="ltx_break"/>
<p class="ltx_p" id="S4.p3.1"><span class="ltx_text ltx_font_bold" id="S4.p3.1.1" style="font-size:120%;">Acknowledgments</span></p>
</div>
<div class="ltx_para ltx_noindent" id="S4.p4">
<p class="ltx_p" id="S4.p4.1">This work is supported by the Science Foundation Ireland (SFI) Centre for Research Training in Digitally-Enhanced Reality (d-real) under Grant No. 18/CRT/6224, the ADAPT Centre for Digital Content Technology under SFI’s Grant No. <span class="ltx_text" id="S4.p4.1.1">13/RC/2106_P2</span>, and <span class="ltx_text" id="S4.p4.1.2">Microsoft</span> Research.</p>
</div>
<div class="ltx_para" id="S4.p5">
<br class="ltx_break"/>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Agrawal et al.,  (2023)</span>
<span class="ltx_bibblock">
Agrawal, S., Zhou, C., Lewis, M., Zettlemoyer, L., and Ghazvininejad, M. (2023).

</span>
<span class="ltx_bibblock">In-context Examples Selection for Machine Translation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib1.1.1">Findings of the Association for Computational Linguistics: ACL 2023</span>, pages 8857–8873, Toronto, Canada. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Alves et al.,  (2023)</span>
<span class="ltx_bibblock">
Alves, D., Guerreiro, N., Alves, J., Pombal, J., Rei, R., de Souza, J., Colombo, P., and Martins, A. (2023).

</span>
<span class="ltx_bibblock">Steering Large Language Models for Machine Translation with Finetuning and In-Context Learning.

</span>
<span class="ltx_bibblock">In Bouamor, H., Pino, J., and Bali, K., editors, <span class="ltx_text ltx_font_italic" id="bib.bib2.1.1">Findings of the Association for Computational Linguistics: EMNLP 2023</span>, pages 11127–11148, Singapore. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Anastasopoulos et al.,  (2020)</span>
<span class="ltx_bibblock">
Anastasopoulos, A., Cattelan, A., Dou, Z.-Y., Federico, M., Federmann, C., Genzel, D., Guzmán, F., Hu, J., Hughes, M., Koehn, P., Lazar, R., Lewis, W., Neubig, G., Niu, M., Öktem, A., Paquin, E., Tang, G., and Tur, S. (2020).

</span>
<span class="ltx_bibblock">TICO-19: the Translation Initiative for COvid-19.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib3.1.1">Proceedings of the 1st Workshop on NLP for COVID-19 (Part 2) at EMNLP 2020</span>, Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bai et al.,  (2023)</span>
<span class="ltx_bibblock">
Bai, J., Bai, S., Chu, Y., Cui, Z., Dang, K., Deng, X., Fan, Y., Ge, W., Han, Y., Huang, F., Hui, B., Ji, L., Li, M., Lin, J., Lin, R., Liu, D., Liu, G., Lu, C., Lu, K., Ma, J., Men, R., Ren, X., Ren, X., Tan, C., Tan, S., Tu, J., Wang, P., Wang, S., Wang, W., Wu, S., Xu, B., Xu, J., Yang, A., Yang, H., Yang, J., Yang, S., Yao, Y., Yu, B., Yuan, H., Yuan, Z., Zhang, J., Zhang, X., Zhang, Y., Zhang, Z., Zhou, C., Zhou, J., Zhou, X., and Zhu, T. (2023).

</span>
<span class="ltx_bibblock">Qwen Technical Report.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">arXiv preprint arXiv:2309.16609 [cs.CL]</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Berzins et al.,  (2019)</span>
<span class="ltx_bibblock">
Berzins, A., Choukri, K., Giagkou, M., Lösch, A., Mazo, H., Piperidis, S., Rigault, M., Schnur, E., Smal, L., van Genabith, J., and Vasiljevs, A. (2019).

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib5.1.1">ELRC White Paper: Sustainable Language Data Sharing to Support Language Equality in Multilingual Europe: why Language Data Matters</span>.

</span>
<span class="ltx_bibblock">European Language Resource Coordination &amp; OVD Verlag.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et al.,  (2020)</span>
<span class="ltx_bibblock">
Brown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D. M., Wu, J., Winter, C., Hesse, C., Chen, M., Sigler, E., Litwin, M., Gray, S., Chess, B., Clark, J., Berner, C., McCandlish, S., Radford, A., Sutskever, I., and Amodei, D. (2020).

</span>
<span class="ltx_bibblock">Language Models are Few-Shot Learners.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib6.1.1">Advances in Neural Information Processing Systems (NeurIPS 2020)</span>, volume 33, pages 1877–1901, Virtual. Curran Associates, Inc.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bulte and Tezcan,  (2019)</span>
<span class="ltx_bibblock">
Bulte, B. and Tezcan, A. (2019).

</span>
<span class="ltx_bibblock">Neural Fuzzy Repair: Integrating Fuzzy Matches into Neural Machine Translation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib7.1.1">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</span>, pages 1800–1809, Florence, Italy. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Costa-jussà et al.,  (2022)</span>
<span class="ltx_bibblock">
Costa-jussà, M. R., Cross, J., Çelebi, O., Elbayad, M., Heafield, K., Heffernan, K., Kalbassi, E., Lam, J., Licht, D., Maillard, J., Sun, A., Wang, S., Wenzek, G., Youngblood, A., Akula, B., Barrault, L., Gonzalez, G. M., Hansanti, P., Hoffman, J., Jarrett, S., Sadagopan, K. R., Rowe, D., Spruit, S., Tran, C., Andrews, P., Ayan, N. F., Bhosale, S., Edunov, S., Fan, A., Gao, C., Goswami, V., Guzmán, F., Koehn, P., Mourachko, A., Ropers, C., Saleem, S., Schwenk, H., and Wang, J. (2022).

</span>
<span class="ltx_bibblock">No Language Left Behind: Scaling human-centered machine translation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">arXiv preprint arXiv:2207.04672 [cs.CL]</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dettmers et al.,  (2023)</span>
<span class="ltx_bibblock">
Dettmers, T., Pagnoni, A., Holtzman, A., and Zettlemoyer, L. (2023).

</span>
<span class="ltx_bibblock">QLoRA: Efficient Finetuning of Quantized LLMs.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">arXiv preprint arXiv:2305.14314 [cs.LG]</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">EMA,  (2012)</span>
<span class="ltx_bibblock">
EMA (2012).

</span>
<span class="ltx_bibblock">European public assessment reports.

</span>
<span class="ltx_bibblock">The European Medicines Agency (EMA).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Farajian et al.,  (2017)</span>
<span class="ltx_bibblock">
Farajian, M. A., Turchi, M., Negri, M., and Federico, M. (2017).

</span>
<span class="ltx_bibblock">Multi-Domain Neural Machine Translation through Unsupervised Adaptation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib11.1.1">Proceedings of the Second Conference on Machine Translation</span>, pages 127–137, Copenhagen, Denmark. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ghazvininejad et al.,  (2023)</span>
<span class="ltx_bibblock">
Ghazvininejad, M., Gonen, H., and Zettlemoyer, L. (2023).

</span>
<span class="ltx_bibblock">Dictionary-based Phrase-level Prompting of Large Language Models for Machine Translation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">arXiv preprint arXiv:2302.07856 [cs.CL]</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et al.,  (2021)</span>
<span class="ltx_bibblock">
Hu, E. J., Shen, Y., Wallis, P., Allen-Zhu, Z., Li, Y., Wang, S., Wang, L., and Chen, W. (2021).

</span>
<span class="ltx_bibblock">LoRA: Low-Rank Adaptation of Large Language Models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">arXiv preprint arXiv:2106.09685 [cs.CL]</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Iyer et al.,  (2023)</span>
<span class="ltx_bibblock">
Iyer, V., Chen, P., and Birch, A. (2023).

</span>
<span class="ltx_bibblock">Towards Effective Disambiguation for Machine Translation with Large Language Models.

</span>
<span class="ltx_bibblock">In Koehn, P., Haddow, B., Kocmi, T., and Monz, C., editors, <span class="ltx_text ltx_font_italic" id="bib.bib14.1.1">Proceedings of the Eighth Conference on Machine Translation</span>, pages 482–495, Singapore. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et al.,  (2023)</span>
<span class="ltx_bibblock">
Jiang, A. Q., Sablayrolles, A., Mensch, A., Bamford, C., Chaplot, D. S., de las Casas, D., Bressand, F., Lengyel, G., Lample, G., Saulnier, L., Lavaud, L. R., Lachaux, M.-A., Stock, P., Le Scao, T., Lavril, T., Wang, T., Lacroix, T., and El Sayed, W. (2023).

</span>
<span class="ltx_bibblock">Mistral 7B.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">arXiv preprint arXiv:2310.06825 [cs.CL]</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiao et al.,  (2023)</span>
<span class="ltx_bibblock">
Jiao, W., Huang, J.-T., Wang, W., Wang, X., Shi, S., and Tu, Z. (2023).

</span>
<span class="ltx_bibblock">ParroT: Translating During Chat Using Large Language Models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">arXiv preprint arXiv:2304.02426 [cs.CL]</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Johnson et al.,  (2019)</span>
<span class="ltx_bibblock">
Johnson, J., Douze, M., and Jégou, H. (2019).

</span>
<span class="ltx_bibblock">Billion-Scale Similarity Search with GPUs.

</span>
<span class="ltx_bibblock">IEEE Transactions on Big Data.

</span>
<span class="ltx_bibblock">7(3):535–547.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Klein et al.,  (2020)</span>
<span class="ltx_bibblock">
Klein, G., Zhang, D., Chouteau, C., Crego, J., and Senellart, J. (2020).

</span>
<span class="ltx_bibblock">Efficient and high-quality neural machine translation with OpenNMT.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib18.1.1">Proceedings of the Fourth Workshop on Neural Generation and Translation</span>, pages 211–217, Stroudsburg, PA, USA. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Le Scao et al.,  (2022)</span>
<span class="ltx_bibblock">
Le Scao, T., Fan, A., Akiki, C., Pavlick, E., Ilić, S., Hesslow, D., Castagné, R., Luccioni, A. S., Yvon, F., Gallé, M., Tow, J., Rush, A. M., Biderman, S., Webson, A., Ammanamanchi, P. S., Wang, T., Sagot, B., Muennighoff, N., del Moral, A. V., Ruwase, O., Bawden, R., Bekman, S., McMillan-Major, A., Beltagy, I., Nguyen, H., Saulnier, L., Tan, S., Suarez, P. O., Sanh, V., Laurençon, H., Jernite, Y., Launay, J., Mitchell, M., Raffel, C., Gokaslan, A., Simhi, A., Soroa, A., Aji, A. F., Alfassy, A., Rogers, A., Nitzav, A. K., Xu, C., Mou, C., Emezue, C., Klamm, C., Leong, C., van Strien, D., Adelani, D. I., Radev, D., Ponferrada, E. G., Levkovizh, E., Kim, E., Natan, E. B., De Toni, F., Dupont, G., Kruszewski, G., Pistilli, G., Elsahar, H., Benyamina, H., Tran, H., Yu, I., Abdulmumin, I., Johnson, I., Gonzalez-Dios, I., de la Rosa, J., Chim, J., Dodge, J., Zhu, J., Chang, J., Frohberg, J., Tobing, J., Bhattacharjee, J., Almubarak, K., Chen, K., Lo, K., Von Werra, L., Weber, L., Phan, L.,
Ben allal, L., Tanguy, L., Dey, M., Muñoz, M. R., Masoud, M., Grandury, M., Šaško, M., Huang, M., Coavoux, M., Singh, M., Jiang, M. T.-J., Vu, M. C., Jauhar, M. A., Ghaleb, M., Subramani, N., Kassner, N., Khamis, N., Nguyen, O., Espejel, O., de Gibert, O., Villegas, P., Henderson, P., Colombo, P., Amuok, P., Lhoest, Q., Harliman, R., Bommasani, R., López, R. L., Ribeiro, R., Osei, S., Pyysalo, S., Nagel, S., Bose, S., Muhammad, S. H., Sharma, S., Longpre, S., Nikpoor, S., Silberberg, S., Pai, S., Zink, S., Torrent, T. T., Schick, T., Thrush, T., Danchev, V., Nikoulina, V., Laippala, V., Lepercq, V., Prabhu, V., Alyafeai, Z., Talat, Z., Raja, A., Heinzerling, B., Si, C., Taşar, D. E., Salesky, E., Mielke, S. J., Lee, W. Y., Sharma, A., Santilli, A., Chaffin, A., Stiegler, A., Datta, D., Szczechla, E., Chhablani, G., Wang, H., Pandey, H., Strobelt, H., Fries, J. A., Rozen, J., Gao, L., Sutawika, L., Saiful Bari, M., Al-shaibani, M. S., Manica, M., Nayak, N., Teehan, R., Albanie, S.,
Shen, S., Ben-David, S., Bach, S. H., Kim, T., Bers, T., Fevry, T., Neeraj, T., Thakker, U., Raunak, V., Tang, X., Yong, Z.-X., Sun, Z., Brody, S., Uri, Y., Tojarieh, H., Roberts, A., Chung, H. W., Tae, J., Phang, J., Ofir Press, Li, C., Narayanan, D., Bourfoune, H., Casper, J., Rasley, J., Ryabinin, M., Mishra, M., Zhang, M., Shoeybi, M., Peyrounette, M., Patry, N., Tazi, N., Sanseviero, O., von Platen, P., Cornette, P., Lavallée, P. F., Lacroix, R., Rajbhandari, S., Gandhi, S., Smith, S., Requena, S., Patil, S., Dettmers, T., Baruwa, A., Singh, A., Cheveleva, A., Ligozat, A.-L., Subramonian, A., Névéol, A., Lovering, C., Garrette, D., Tunuguntla, D., Reiter, E., Taktasheva, E., Voloshina, E., Bogdanov, E., Winata, G. I., Schoelkopf, H., Kalo, J.-C., Novikova, J., Forde, J. Z., Clive, J., Kasai, J., Kawamura, K., Hazan, L., Carpuat, M., Clinciu, M., Kim, N., Cheng, N., Serikov, O., Antverg, O., van der Wal, O., Zhang, R., Zhang, R., Gehrmann, S., Mirkin, S., Pais, S., Shavrina, T., Scialom,
T., Yun, T., Limisiewicz, T., Rieser, V., Protasov, V., Mikhailov, V., Pruksachatkun, Y., Belinkov, Y., Bamberger, Z., Kasner, Z., Rueda, A., Pestana, A., Feizpour, A., Khan, A., Faranak, A., Santos, A., Hevia, A., Unldreaj, A., Aghagol, A., Abdollahi, A., Tammour, A., HajiHosseini, A., Behroozi, B., Ajibade, B., Saxena, B., Ferrandis, C. M., McDuff, D., Contractor, D., Lansky, D., David, D., Kiela, D., Nguyen, D. A., Tan, E., Baylor, E., Ozoani, E., Mirza, F., Ononiwu, F., Rezanejad, H., Jones, H., Bhattacharya, I., Solaiman, I., Sedenko, I., Nejadgholi, I., Passmore, J., Seltzer, J., Sanz, J. B., Dutra, L., Samagaio, M., Elbadri, M., Mieskes, M., Gerchick, M., Akinlolu, M., McKenna, M., Qiu, M., Ghauri, M., Burynok, M., Abrar, N., Rajani, N., Elkott, N., Fahmy, N., Samuel, O., An, R., Kromann, R., Hao, R., Alizadeh, S., Shubber, S., Wang, S., Roy, S., Viguier, S., Le, T., Oyebade, T., Le, T., Yang, Y., Nguyen, Z., Kashyap, A. R., Palasciano, A., Callahan, A., Shukla, A., Miranda-Escalada, A., Singh, A.,
Beilharz, B., Wang, B., Brito, C., Zhou, C., Jain, C., Xu, C., Fourrier, C., Periñán, D. L., Molano, D., Yu, D., Manjavacas, E., Barth, F., Fuhrimann, F., Altay, G., Bayrak, G., Burns, G., Vrabec, H. U., Bello, I., Dash, I., Kang, J., Giorgi, J., Golde, J., Posada, J. D., Sivaraman, K. R., Bulchandani, L., Liu, L., Shinzato, L., de Bykhovetz, M. H., Takeuchi, M., Pàmies, M., Castillo, M. A., Nezhurina, M., Sänger, M., Samwald, M., Cullan, M., Weinberg, M., De Wolf, M., Mihaljcic, M., Liu, M., Freidank, M., Kang, M., Seelam, N., Dahlberg, N., Broad, N. M., Muellner, N., Fung, P., Haller, P., Chandrasekhar, R., Eisenberg, R., Martin, R., Canalli, R., Su, R., Su, R., Cahyawijaya, S., Garda, S., Deshmukh, S. S., Mishra, S., Kiblawi, S., Ott, S., Sang-aroonsiri, S., Kumar, S., Schweter, S., Bharati, S., Laud, T., Gigant, T., Kainuma, T., Kusa, W., Labrak, Y., Bajaj, Y. S., Venkatraman, Y., Xu, Y., Xu, Y., Xu, Y., Tan, Z., Xie, Z., Ye, Z., Bras, M., Belkada, Y., and Wolf, T. (2022).

</span>
<span class="ltx_bibblock">BLOOM: A 176B-Parameter Open-Access Multilingual Language Model.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">arXiv preprint arXiv:2211.05100 [cs.CL]</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(20)</span>
<span class="ltx_bibblock">
Moslem, Y., Haque, R., Kelleher, J. D., and Way, A. (2023a).

</span>
<span class="ltx_bibblock">Adaptive Machine Translation with Large Language Models.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib20.1.1">Proceedings of the 24th Annual Conference of the European Association for Machine Translation</span>, pages 227–237, Tampere, Finland. European Association for Machine Translation.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(21)</span>
<span class="ltx_bibblock">
Moslem, Y., Romani, G., Molaei, M., Kelleher, J. D., Haque, R., and Way, A. (2023b).

</span>
<span class="ltx_bibblock">Domain Terminology Integration into Machine Translation: Leveraging Large Language Models.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib21.1.1">Proceedings of the Eighth Conference on Machine Translation</span>, pages 902–911, Singapore. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ouyang et al.,  (2022)</span>
<span class="ltx_bibblock">
Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C. L., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A., Schulman, J., Hilton, J., Kelton, F., Miller, L., Simens, M., Askell, A., Welinder, P., Christiano, P., Leike, J., and Lowe, R. (2022).

</span>
<span class="ltx_bibblock">Training language models to follow instructions with human feedback.

</span>
<span class="ltx_bibblock">In S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh, editor, <span class="ltx_text ltx_font_italic" id="bib.bib22.1.1">Advances in Neural Information Processing Systems (NeurIPS 2022)</span>, pages 27730–27744, New Orleans, Louisiana, USA. Curran Associates, Inc.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Papineni et al.,  (2002)</span>
<span class="ltx_bibblock">
Papineni, K., Roukos, S., Ward, T., and Zhu, W.-J. (2002).

</span>
<span class="ltx_bibblock">Bleu: a Method for Automatic Evaluation of Machine Translation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib23.1.1">Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics</span>, pages 311–318, Philadelphia, Pennsylvania, USA. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Penedo et al.,  (2023)</span>
<span class="ltx_bibblock">
Penedo, G., Malartic, Q., Hesslow, D., Cojocaru, R., Cappelli, A., Alobeidli, H., Pannier, B., Almazrouei, E., and Launay, J. (2023).

</span>
<span class="ltx_bibblock">The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">arXiv preprint arXiv:2306.01116 [cs.CL]</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Popović,  (2017)</span>
<span class="ltx_bibblock">
Popović, M. (2017).

</span>
<span class="ltx_bibblock">chrF++: words helping character n-grams.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib25.1.1">Proceedings of the Second Conference on Machine Translation</span>, pages 612–618, Copenhagen, Denmark. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rei et al.,  (2020)</span>
<span class="ltx_bibblock">
Rei, R., Stewart, C., Farinha, A. C., and Lavie, A. (2020).

</span>
<span class="ltx_bibblock">COMET: A Neural Framework for MT Evaluation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib26.1.1">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</span>, pages 2685–2702, Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Reimers and Gurevych,  (2019)</span>
<span class="ltx_bibblock">
Reimers, N. and Gurevych, I. (2019).

</span>
<span class="ltx_bibblock">Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib27.1.1">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</span>, pages 3982–3992, Hong Kong, China. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Reinauer et al.,  (2023)</span>
<span class="ltx_bibblock">
Reinauer, R., Simianer, P., Uhlig, K., Mosig, J. E. M., and Wuebker, J. (2023).

</span>
<span class="ltx_bibblock">Neural Machine Translation Models Can Learn to be Few-shot Learners.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">arXiv preprint arXiv:2309.08590 [cs.CL]</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schioppa et al.,  (2023)</span>
<span class="ltx_bibblock">
Schioppa, A., Garcia, X., and Firat, O. (2023).

</span>
<span class="ltx_bibblock">Cross-Lingual Supervision improves Large Language Models Pre-training.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">arXiv preprint arXiv:2305.11778 [cs.CL]</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sengupta et al.,  (2023)</span>
<span class="ltx_bibblock">
Sengupta, N., Sahu, S. K., Jia, B., Katipomu, S., Li, H., Koto, F., Afzal, O. M., Kamboj, S., Pandit, O., Pal, R., Pradhan, L., Mujahid, Z. M., Baali, M., Aji, A. F., Liu, Z., Hock, A., Feldman, A., Lee, J., Jackson, A., Nakov, P., Baldwin, T., and Xing, E. (2023).

</span>
<span class="ltx_bibblock">Jais and Jais-chat: Arabic-Centric Foundation and Instruction-Tuned Open Generative Large Language Models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">arXiv preprint arXiv:2308.16149 [cs.CL]</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sia and Duh,  (2022)</span>
<span class="ltx_bibblock">
Sia, S. and Duh, K. (2022).

</span>
<span class="ltx_bibblock">Prefix Embeddings for In-context Machine Translation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib31.1.1">Proceedings of the 15th biennial conference of the Association for Machine Translation in the Americas (Volume 1: Research Track)</span>, pages 45–57, Orlando, USA. Association for Machine Translation in the Americas.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Snover et al.,  (2006)</span>
<span class="ltx_bibblock">
Snover, M., Dorr, B., Schwartz, R., Micciulla, L., and Makhoul, J. (2006).

</span>
<span class="ltx_bibblock">A Study of Translation Edit Rate with Targeted Human Annotation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib32.1.1">Proceedings of the 7th Conference of the Association for Machine Translation in the Americas: Technical Papers</span>, pages 223–231, Cambridge, Massachusetts, USA. Association for Machine Translation in the Americas.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Soares et al.,  (2018)</span>
<span class="ltx_bibblock">
Soares, F., Moreira, V., and Becker, K. (2018).

</span>
<span class="ltx_bibblock">A Large Parallel Corpus of Full-Text Scientific Articles.

</span>
<span class="ltx_bibblock">In Calzolari, N., Choukri, K., Cieri, C., Declerck, T., Goggi, S., Hasida, K., Isahara, H., Maegaard, B., Mariani, J., Mazo, H., Moreno, A., Odijk, J., Piperidis, S., and Tokunaga, T., editors, <span class="ltx_text ltx_font_italic" id="bib.bib33.1.1">Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018)</span>, Miyazaki, Japan. European Language Resources Association (ELRA).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tiedemann,  (2012)</span>
<span class="ltx_bibblock">
Tiedemann, J. (2012).

</span>
<span class="ltx_bibblock">Parallel Data, Tools and Interfaces in OPUS.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib34.1.1">Proceedings of the Eighth International Conference on Language Resources and Evaluation (LREC’12)</span>, pages 2214–2218, Istanbul, Turkey. European Language Resources Association (ELRA).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vaswani et al.,  (2017)</span>
<span class="ltx_bibblock">
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, L., and Polosukhin, I. (2017).

</span>
<span class="ltx_bibblock">Attention Is All You Need.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib35.1.1">Advances in Neural Information Processing Systems (NIPS 2017)</span>, volume 30. Curran Associates, Inc.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al.,  (2020)</span>
<span class="ltx_bibblock">
Wang, W., Wei, F., Dong, L., Bao, H., Yang, N., and Zhou, M. (2020).

</span>
<span class="ltx_bibblock">MINILM: deep self-attention distillation for task-agnostic compression of pre-trained transformers.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib36.1.1">Proceedings of the 34th International Conference on Neural Information Processing Systems</span>, number Article 485 in NIPS’20, pages 5776–5788, Red Hook, NY, USA. Curran Associates Inc.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Williams and Zipser,  (1989)</span>
<span class="ltx_bibblock">
Williams, R. J. and Zipser, D. (1989).

</span>
<span class="ltx_bibblock">A Learning Algorithm for Continually Running Fully Recurrent Neural Networks.

</span>
<span class="ltx_bibblock">Neural Comput.

</span>
<span class="ltx_bibblock">1(2):270–280.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al.,  (2023)</span>
<span class="ltx_bibblock">
Xu, H., Kim, Y. J., Sharaf, A., and Awadalla, H. H. (2023).

</span>
<span class="ltx_bibblock">A Paradigm Shift in Machine Translation: Boosting Translation Performance of Large Language Models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">arXiv preprint arXiv:2309.11674 [cs.CL]</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al.,  (2020)</span>
<span class="ltx_bibblock">
Xu, J., Crego, J., and Senellart, J. (2020).

</span>
<span class="ltx_bibblock">Boosting Neural Machine Translation with Similar Translations.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib39.1.1">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</span>, pages 1580–1590, Online. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al.,  (2023)</span>
<span class="ltx_bibblock">
Yang, A., Xiao, B., Wang, B., Zhang, B., Bian, C., Yin, C., Lv, C., Pan, D., Wang, D., Yan, D., Yang, F., Deng, F., Wang, F., Liu, F., Ai, G., Dong, G., Zhao, H., Xu, H., Sun, H., Zhang, H., Liu, H., Ji, J., Xie, J., Dai, J., Fang, K., Su, L., Song, L., Liu, L., Ru, L., Ma, L., Wang, M., Liu, M., Lin, M., Nie, N., Guo, P., Sun, R., Zhang, T., Li, T., Li, T., Cheng, W., Chen, W., Zeng, X., Wang, X., Chen, X., Men, X., Yu, X., Pan, X., Shen, Y., Wang, Y., Li, Y., Jiang, Y., Gao, Y., Zhang, Y., Zhou, Z., and Wu, Z. (2023).

</span>
<span class="ltx_bibblock">Baichuan 2: Open Large-scale Language Models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">arXiv preprint arXiv:2309.10305 [cs.CL]</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al.,  (2023)</span>
<span class="ltx_bibblock">
Zhang, X., Rajabi, N., Duh, K., and Koehn, P. (2023).

</span>
<span class="ltx_bibblock">Machine Translation with Large Language Models: Prompting, Few-shot Learning, and Fine-tuning with QLoRA.

</span>
<span class="ltx_bibblock">In Koehn, P., Haddow, B., Kocmi, T., and Monz, C., editors, <span class="ltx_text ltx_font_italic" id="bib.bib41.1.1">Proceedings of the Eighth Conference on Machine Translation</span>, pages 468–481, Singapore. Association for Computational Linguistics.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Wed Dec 20 03:21:25 2023 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span style="font-size:70%;position:relative; bottom:2.2pt;">A</span>T<span style="position:relative; bottom:-0.4ex;">E</span></span><span class="ltx_font_smallcaps">xml</span><img alt="[LOGO]" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
