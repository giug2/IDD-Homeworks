<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Breaking reCAPTCHAv2</title>
<!--Generated on Fri Sep 13 13:39:37 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="
reCAPTCHAv2,  Proof-of-personhood,  Machine Learning,  Image Classification,  Image Segmentation,  YOLO,  Machine Intelligence
" lang="en" name="keywords"/>
<base href="/html/2409.08831v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#S1" title="In Breaking reCAPTCHAv2"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">I </span><span class="ltx_text ltx_font_smallcaps">Introduction</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#S2" title="In Breaking reCAPTCHAv2"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">II </span><span class="ltx_text ltx_font_smallcaps">Related work</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#S2.SS0.SSS0.Px1" title="In II Related work ‣ Breaking reCAPTCHAv2"><span class="ltx_text ltx_ref_title">Early Text-based Captchas</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#S2.SS0.SSS0.Px2" title="In II Related work ‣ Breaking reCAPTCHAv2"><span class="ltx_text ltx_ref_title">Breaking reCAPTCHAv2</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#S2.SS0.SSS0.Px3" title="In II Related work ‣ Breaking reCAPTCHAv2"><span class="ltx_text ltx_ref_title">Deep Learning for Image Classification</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#S2.SS0.SSS0.Px4" title="In II Related work ‣ Breaking reCAPTCHAv2"><span class="ltx_text ltx_ref_title">Advancement in AI Models</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#S2.SS0.SSS0.Px5" title="In II Related work ‣ Breaking reCAPTCHAv2"><span class="ltx_text ltx_ref_title">Advancement in Captchas</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#S2.SS0.SSS0.Px6" title="In II Related work ‣ Breaking reCAPTCHAv2"><span class="ltx_text ltx_ref_title">Audio Captchas</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#S3" title="In Breaking reCAPTCHAv2"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">III </span><span class="ltx_text ltx_font_smallcaps">Understanding reCAPTCHAv2</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#S3.SS1" title="In III Understanding reCAPTCHAv2 ‣ Breaking reCAPTCHAv2"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-A</span> </span><span class="ltx_text ltx_font_italic">Background</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#S3.SS2" title="In III Understanding reCAPTCHAv2 ‣ Breaking reCAPTCHAv2"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-B</span> </span><span class="ltx_text ltx_font_italic">Data</span></span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#S3.SS2.SSS0.Px1" title="In III-B Data ‣ III Understanding reCAPTCHAv2 ‣ Breaking reCAPTCHAv2"><span class="ltx_text ltx_ref_title">Classification</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#S3.SS2.SSS0.Px2" title="In III-B Data ‣ III Understanding reCAPTCHAv2 ‣ Breaking reCAPTCHAv2"><span class="ltx_text ltx_ref_title">Segmentation</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#S4" title="In Breaking reCAPTCHAv2"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">IV </span><span class="ltx_text ltx_font_smallcaps">Proposed solution</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#S5" title="In Breaking reCAPTCHAv2"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">V </span><span class="ltx_text ltx_font_smallcaps">Methodology</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#S5.SS1" title="In V Methodology ‣ Breaking reCAPTCHAv2"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-A</span> </span><span class="ltx_text ltx_font_italic">Evaluation environment</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#S5.SS2" title="In V Methodology ‣ Breaking reCAPTCHAv2"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">V-B</span> </span><span class="ltx_text ltx_font_italic">Experiments</span></span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#S5.SS2.SSS0.Px1" title="In V-B Experiments ‣ V Methodology ‣ Breaking reCAPTCHAv2"><span class="ltx_text ltx_ref_title">VPN</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#S5.SS2.SSS0.Px2" title="In V-B Experiments ‣ V Methodology ‣ Breaking reCAPTCHAv2"><span class="ltx_text ltx_ref_title">Mouse Movement</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#S5.SS2.SSS0.Px3" title="In V-B Experiments ‣ V Methodology ‣ Breaking reCAPTCHAv2"><span class="ltx_text ltx_ref_title">History and Cookies</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#S6" title="In Breaking reCAPTCHAv2"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">VI </span><span class="ltx_text ltx_font_smallcaps">Results</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#S6.SS1" title="In VI Results ‣ Breaking reCAPTCHAv2"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">VI-A</span> </span><span class="ltx_text ltx_font_italic">VPN Usage Versus Non-VPN Conditions</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#S6.SS2" title="In VI Results ‣ Breaking reCAPTCHAv2"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">VI-B</span> </span><span class="ltx_text ltx_font_italic">Mouse Movement</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#S6.SS3" title="In VI Results ‣ Breaking reCAPTCHAv2"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">VI-C</span> </span><span class="ltx_text ltx_font_italic">Impact of Browser History and Cookies on Captcha Solvability</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#S6.SS4" title="In VI Results ‣ Breaking reCAPTCHAv2"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">VI-D</span> </span><span class="ltx_text ltx_font_italic">Comparative Analysis of Human versus Bot Performance in Captcha Solving</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#S7" title="In Breaking reCAPTCHAv2"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">VII </span><span class="ltx_text ltx_font_smallcaps">Conclusion</span></span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">
Breaking reCAPTCHAv2
</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Andreas Plesner
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_font_italic" id="id1.1.id1">ETH Zurich</span>, Switzerland 
<br class="ltx_break"/>aplesner@ethz.ch
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Tobias Vontobel
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_font_italic" id="id2.1.id1">ETH Zurich</span>, Switzerland 
<br class="ltx_break"/>votobias@student.ethz.ch
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Roger Wattenhofer
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_font_italic" id="id3.1.id1">ETH Zurich</span>, Switzerland 
<br class="ltx_break"/>wattenhofer@ethz.ch
</span></span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id4.id1">Our work examines the efficacy of employing advanced machine learning methods to solve captchas from Google’s <span class="ltx_text" id="id4.id1.1">reCAPTCHAv2</span> system. We evaluate the effectiveness of automated systems in solving captchas by utilizing advanced YOLO models for image segmentation and classification. Our main result is that we can solve 100% of the captchas, while previous work only solved 68-71%. Furthermore,
our findings suggest that there is no significant difference in the number of challenges humans and bots must solve to pass the captchas in <span class="ltx_text" id="id4.id1.2">reCAPTCHAv2</span>. This implies that current AI technologies can exploit advanced image-based captchas. We also look under the hood of <span class="ltx_text" id="id4.id1.3">reCAPTCHAv2</span>, and find evidence that <span class="ltx_text" id="id4.id1.4">reCAPTCHAv2</span> is heavily based on cookie and browser history data when evaluating whether a user is human or not.
The code is provided alongside this paper.<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>https://github.com/aplesner/Breaking-reCAPTCHAv2</span></span></span><span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>Corresponding author: Andreas Plesner</span></span></span><span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>Accepted at COMPSAC 2024</span></span></span></p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
reCAPTCHAv2, Proof-of-personhood, Machine Learning, Image Classification, Image Segmentation, YOLO, Machine Intelligence

</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span class="ltx_text ltx_font_smallcaps" id="S1.1.1">Introduction</span>
</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">The challenge of distinguishing between humans and machines has become a critical aspect of online security. Captchas (“Completely Automated Public Turing Tests to Tell Computers and Humans Apart”) have emerged as the front-line defense against automated bots and malicious activities on the Internet.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">In this work, we focus on Google’s <span class="ltx_text" id="S1.p2.1.1">reCAPTCHAv2</span> system <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#bib.bib1" title="">1</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#bib.bib2" title="">2</a>]</cite>, see also <a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#S1.F1" title="In I Introduction ‣ Breaking reCAPTCHAv2"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">1</span></a>. Our decision to use <span class="ltx_text" id="S1.p2.1.2">reCAPTCHAv2</span> is based on its widespread use, indicating its significant role in protecting against automated threats. Moreover, <span class="ltx_text" id="S1.p2.1.3">reCAPTCHAv2</span> is technically advanced, with an excellent trade-off between user experience and security, making it a preferred option for many websites.
Because of this, Google’s <span class="ltx_text" id="S1.p2.1.4">reCAPTCHAv2</span> is a good representative of image-based captcha technology.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">This project aims to analyze the effectiveness of Google’s <span class="ltx_text" id="S1.p3.1.1">reCAPTCHAv2</span> in rejecting bots using advanced deep learning models such as YOLO models.
Our main result is that we can solve 100% of the captchas, while previous work solved 68-71%. In addition, we find evidence that there is no significant difference in the number of challenges required by humans and bots to solve captchas in <span class="ltx_text" id="S1.p3.1.2">reCAPTCHAv2</span>, if anything bots are better than humans. Our study also finds that <span class="ltx_text" id="S1.p3.1.3">reCAPTCHAv2</span> is heavily based on cookie and browser history data when evaluating whether a user is human or not.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">While automatically solving captchas sounds like a mundane job, there is also a deeper philosophical angle. In some sense, <span class="ltx_text ltx_font_italic" id="S1.p4.1.1">a good captcha marks the exact boundary between the most intelligent machine and the least intelligent human</span>. To be effective, literally every human above a certain age, independent of language and cultural background, must be able to solve the captcha. A captcha should never lock out humans. As machine learning models close in on human capabilities, finding good captchas has become more difficult. Bluntly, this paper shows that we are now officially in the age beyond captchas.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">In the past, captchas have often been (ab)used to have humans label data. This goes back to early text recognition captchas. Google’s <span class="ltx_text" id="S1.p5.1.1">reCAPTCHAv2</span> is suspected to be useful in training self-driving cars, as a large number of tests are traffic related. Dozens of companies are publicly working on developing self-driving cars, including Google with Waymo.
Waymo self-driving cars are already a reality. And they are on the verge of really tackling all possible traffic situations, with freeways currently being tested in Phoenix. Consequently, it is not surprising that <span class="ltx_text" id="S1.p5.1.2">reCAPTCHAv2</span> can be solved. However, while it was always clear that Google can solve its captchas, we show that anybody can do so by just cleverly applying publicly available software.</p>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">Google and others declared the end of captchas some years ago. Already <span class="ltx_text" id="S1.p6.1.1">reCAPTCHAv2</span> usually only asks established users to check a box that they are “not a robot.” If enough evidence (browsing history, mouse movements, etc.) confirms that the user is indeed not a robot, <span class="ltx_text" id="S1.p6.1.2">reCAPTCHAv2</span> will grant access directly. Only in a case where <span class="ltx_text" id="S1.p6.1.3">reCAPTCHAv2</span> is insecure do the image recognition tests come into play. These image recognition tasks are quite dreaded by many users. A simple search finds plenty of testimony videos where unhappy users cannot solve a long series of <span class="ltx_text" id="S1.p6.1.4">reCAPTCHAv2</span> tests.</p>
</div>
<div class="ltx_para" id="S1.p7">
<p class="ltx_p" id="S1.p7.1">In fact, with Google’s newest reCAPTCHAv3, a completely “captcha-less captcha” has already existed for several years. It decides the human vs. robot question purely on past interactions. However, some humans will ultimately not have sufficiently convincing browsing data and credentials. These unfortunate users may automatically and instantly be locked out of potentially vital internet services. In this case, to still gain access to a service, web pages often fall back to <span class="ltx_text" id="S1.p7.1.1">reCAPTCHAv2</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#bib.bib3" title="">3</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#bib.bib4" title="">4</a>]</cite>. This is why <span class="ltx_text" id="S1.p7.1.2">reCAPTCHAv2</span> still plays an important role in today’s seemingly captcha-free world and deserves our attention.</p>
</div>
<figure class="ltx_figure" id="S1.F1">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S1.F1.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="866" id="S1.F1.sf1.g1" src="extracted/5853134/figures/type1.png" width="598"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S1.F1.sf1.2.1.1" style="font-size:90%;">(a)</span> </span><span class="ltx_text" id="S1.F1.sf1.3.2" style="font-size:90%;">Type 1 captcha challenge example displaying a 3 by 3 grid of static images with target class ”stairs”. The user must identify all images containing stairs.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S1.F1.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="866" id="S1.F1.sf2.g1" src="extracted/5853134/figures/type2.png" width="598"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S1.F1.sf2.2.1.1" style="font-size:90%;">(b)</span> </span><span class="ltx_text" id="S1.F1.sf2.3.2" style="font-size:90%;">Type 2 captcha challenge example displaying a single image divided into a 4 by 4 grid with target class motorcycles. The user selects all squares containing motorcycles.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S1.F1.sf3"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="866" id="S1.F1.sf3.g1" src="extracted/5853134/figures/type3.png" width="598"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S1.F1.sf3.2.1.1" style="font-size:90%;">(c)</span> </span><span class="ltx_text" id="S1.F1.sf3.3.2" style="font-size:90%;">Type 3 captcha challenge example displaying a 3 by 3 grid of images with target class crosswalks; the images are replaced when the user clicks on them. The user must select all images with crosswalks.</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S1.F1.3.1.1" style="font-size:90%;">Figure 1</span>: </span><span class="ltx_text" id="S1.F1.4.2" style="font-size:90%;">Examples of the three different captcha type challenges used by Google’s <span class="ltx_text" id="S1.F1.4.2.1">reCAPTCHAv2</span>. Each type presents a unique challenge for users to solve to determine whether the user is a bot or not.</span></figcaption>
</figure>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span class="ltx_text ltx_font_smallcaps" id="S2.1.1">Related work</span>
</h2>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Early Text-based Captchas</h4>
<div class="ltx_para" id="S2.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px1.p1.1">Initially, captchas were text-based and designed primarily to prevent automated spam and abuse on websites. However, the introduction of powerful machine learning algorithms has made it possible to automate the solving of many text-based challenges. Some influential works in this area include the work of <cite class="ltx_cite ltx_citemacro_citet">Von Ahn et al. [<a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#bib.bib5" title="">5</a>]</cite> and <cite class="ltx_cite ltx_citemacro_citet">Von Ahn et al. [<a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#bib.bib6" title="">6</a>]</cite> that laid the foundation for the development of captchas, and the work of <cite class="ltx_cite ltx_citemacro_citet">Chellapilla and Simard [<a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#bib.bib7" title="">7</a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#bib.bib8" title="">8</a>]</cite> demonstrate the early success of machine learning in breaking text-based captchas.</p>
</div>
<div class="ltx_para" id="S2.SS0.SSS0.Px1.p2">
<p class="ltx_p" id="S2.SS0.SSS0.Px1.p2.1">Researchers have used different machine learning algorithms, such as neural networks, generative adversarial networks (GANs), and convolutional neural networks (CNNs), to overcome text-based captchas <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#bib.bib9" title="">9</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#bib.bib10" title="">10</a>]</cite>. These algorithms have achieved high success rates, leading to more advanced captcha schemes, such as image-based captchas being developed. The evolution of captcha problems, transitioning from text-based to image-based recognition, highlights the ongoing competition between security measures and solving algorithms.</p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Breaking reCAPTCHAv2</h4>
<div class="ltx_para" id="S2.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px2.p1.1">The studies conducted by <cite class="ltx_cite ltx_citemacro_citet">Wang et al. [<a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#bib.bib11" title="">11</a>], Hossen et al. [<a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#bib.bib12" title="">12</a>]</cite> and <cite class="ltx_cite ltx_citemacro_citet">Sivakorn et al. [<a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#bib.bib13" title="">13</a>]</cite> are key references for this study, as they explore the weaknesses of Google’s <span class="ltx_text" id="S2.SS0.SSS0.Px2.p1.1.1">reCAPTCHAv2</span> when faced with advanced deep learning models. These studies thoroughly examine the strength of image-based captchas, providing a detailed analysis of how the design of captchas interacts with the advanced capabilities of AI solvers. In these studies, the researchers were able to solve 68-71% of captchas <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#bib.bib11" title="">11</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#bib.bib13" title="">13</a>]</cite>.
The mentioned works thoroughly record the effectiveness of deep learning models in solving image-based captchas. The knowledge obtained from these influential works is crucial in determining the course of this research <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#bib.bib11" title="">11</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#bib.bib12" title="">12</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S2.SS0.SSS0.Px2.p2">
<p class="ltx_p" id="S2.SS0.SSS0.Px2.p2.1">Several open-source projects have aimed to automate solving Google’s <span class="ltx_text" id="S2.SS0.SSS0.Px2.p2.1.1">reCAPTCHAv2</span> using machine learning techniques. The ”Recaptcha V2 Solver” repository employs a combination of the BLIP language model for image captioning and YOLOv3 for object detection, achieving a success rate of 23-32% on <span class="ltx_text" id="S2.SS0.SSS0.Px2.p2.1.2">reCAPTCHAv2</span> challenges <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#bib.bib14" title="">14</a>]</cite>. Similarly, the ”RecaptchaV2-IA-Solver” repository utilizes the YOLOv8 model for object detection and supports both dynamic and one-time selection CAPTCHAs, but does not report specific success rates <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#bib.bib15" title="">15</a>]</cite>. The “GoodByeCaptcha” library takes a different approach, using speech recognition APIs like Mozilla’s DeepSpeech and Microsoft Azure’s Speech-to-Text to solve audio reCAPTCHAs, while also incorporating image recognition for image-based challenges <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#bib.bib16" title="">16</a>]</cite>. In contrast, our work focuses solely on image-based reCAPTCHAv2 and achieves a 100% success rate using a fine-tuned YOLOv8 model for image segmentation and classification tasks. We also conduct a more comprehensive analysis, comparing bot and human performance, examining the impact of browser cookies, and highlighting the importance of realistic mouse movements and VPN usage for evading detection.<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>We were unable to run the code in these libraries.</span></span></span></p>
</div>
<div class="ltx_para" id="S2.SS0.SSS0.Px2.p3">
<p class="ltx_p" id="S2.SS0.SSS0.Px2.p3.1">Google has also released reCAPTCHAv3, which does not ask the user to solve any challenges. Instead, reCAPTCHAv3 analyzes how the user interacts with the website and uses this information to calculate a risk score. The back end of the website can then restrict the user if the score falls below a certain threshold. The key is that this is completely hidden from the user when interacting with the website <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#bib.bib17" title="">17</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#bib.bib18" title="">18</a>]</cite>.</p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Deep Learning for Image Classification</h4>
<div class="ltx_para" id="S2.SS0.SSS0.Px3.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px3.p1.1"><cite class="ltx_cite ltx_citemacro_citet">Krizhevsky et al. [<a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#bib.bib19" title="">19</a>]</cite> introduced convolutional neural networks that drastically improved the state-of-the-art for image classification. Later, <cite class="ltx_cite ltx_citemacro_citet">Vaswani et al. [<a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#bib.bib20" title="">20</a>]</cite> introduced ResNet models, making models capable of high-accuracy image classification and object detection, setting a new state-of-the-art. Meanwhile, <cite class="ltx_cite ltx_citemacro_citet">Vaswani et al. [<a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#bib.bib20" title="">20</a>]</cite> introduced the Transformer architecture which has fueled many of the later advancements across domains such as vision <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#bib.bib21" title="">21</a>]</cite>, natural language <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#bib.bib22" title="">22</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#bib.bib23" title="">23</a>]</cite> and image generation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#bib.bib24" title="">24</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S2.SS0.SSS0.Px3.p2">
<p class="ltx_p" id="S2.SS0.SSS0.Px3.p2.1">However, these models are computationally heavy, so this project uses the YOLO v8 model <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#bib.bib25" title="">25</a>]</cite>. YOLO v8 is an accurate and efficient model that belongs to the lineage of the ’You Only Look Once’ models <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#bib.bib26" title="">26</a>]</cite>. It is well known for its ability to detect objects in real-time <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#bib.bib27" title="">27</a>]</cite>. This study specifically uses the YOLO v8 segmentation and classification models. The selection of YOLO v8 is in line with the objective of the study to evaluate image-based captcha security using the latest and most sophisticated machine learning technologies, guaranteeing a thorough and up-to-date examination. Moreover, YOLO models can be used on devices with limited computational power, allowing for large-scale attacks by malicious users.</p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px4">
<h4 class="ltx_title ltx_title_paragraph">Advancement in AI Models</h4>
<div class="ltx_para" id="S2.SS0.SSS0.Px4.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px4.p1.1">At the end of 2022, OpenAI released ChatGPT, an LLM which, along with later iterations, has demonstrated the ability of AI to solve tasks that involve abstract thinking <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#bib.bib22" title="">22</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#bib.bib23" title="">23</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#bib.bib28" title="">28</a>]</cite>. Recently, DeepMind released AlphaGeometry, showcasing how LLMs could solve abstract geometry problems from the International Math Olympiad, IMO, on par with the IMO gold medalists <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#bib.bib29" title="">29</a>]</cite>. And <cite class="ltx_cite ltx_citemacro_citet">Radford et al. [<a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#bib.bib30" title="">30</a>]</cite> showed that computers can learn to represent images using natural language, while <cite class="ltx_cite ltx_citemacro_citet">Betker et al. [<a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#bib.bib24" title="">24</a>]</cite> presents a model capable of generating art. This shows how <span class="ltx_text ltx_font_italic" id="S2.SS0.SSS0.Px4.p1.1.1">artificial</span> intelligence is rapidly catching up to human intelligence.</p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px5">
<h4 class="ltx_title ltx_title_paragraph">Advancement in Captchas</h4>
<div class="ltx_para" id="S2.SS0.SSS0.Px5.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px5.p1.1">Aside from traditional text-based and image-based captchas, the domain also includes several innovative variations, such as Arkose Labs’ FunCAPTCHA and MatchKey <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#bib.bib31" title="">31</a>]</cite>, AWS WAF captcha <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#bib.bib32" title="">32</a>]</cite>, and hCaptcha <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#bib.bib33" title="">33</a>]</cite>. Arkose Labs’ FunCAPTCHA and MatchKey offer engaging minigames and advanced key-pattern analysis, respectively, providing unique user experiences. Integration of AWS WAF captcha with Web Application Firewalls Highlights its focus on robust security measures. hCaptcha, often used as an alternative to Google’s reCAPTCHA, emphasizes user privacy and rewards for website owners. Each of these types of captcha shows different approaches to balancing user experience, security, and privacy, reflecting the diverse strategies in modern captcha design. <cite class="ltx_cite ltx_citemacro_citet">Bursztein et al. [<a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#bib.bib34" title="">34</a>]</cite> highlights that as captchas have become more difficult for computers, the result is that many new captchas are difficult for humans.</p>
</div>
<div class="ltx_para" id="S2.SS0.SSS0.Px5.p2">
<p class="ltx_p" id="S2.SS0.SSS0.Px5.p2.1"><cite class="ltx_cite ltx_citemacro_citet">Osadchy et al. [<a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#bib.bib35" title="">35</a>]</cite> created a series of captchas based on images specifically designed to be difficult for image classification models by generating adversarial examples <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#bib.bib36" title="">36</a>]</cite>. The issue with this method is that it needs to be tuned to each classifier.</p>
</div>
<div class="ltx_para" id="S2.SS0.SSS0.Px5.p3">
<p class="ltx_p" id="S2.SS0.SSS0.Px5.p3.1">An area that shows promise in giving challenges that are suitable for determining whether a user is human or not is the Abstract Reasoning Challenge, ARC, <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#bib.bib37" title="">37</a>]</cite>. These challenges are difficult for computers to solve, with the best programs only solving 31% while humans can solve 80% of the challenges <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#bib.bib38" title="">38</a>]</cite>.</p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px6">
<h4 class="ltx_title ltx_title_paragraph">Audio Captchas</h4>
<div class="ltx_para" id="S2.SS0.SSS0.Px6.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px6.p1.1">Audio captchas are essential to ensure accessibility for users with visual impairments, in addition to visual captcha challenges. An influential study in this field by <cite class="ltx_cite ltx_citemacro_citet">Tam et al. [<a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#bib.bib39" title="">39</a>]</cite> devises a machine learning methodology to effectively solve audio captchas. They achieved significant success by successfully bypassing captchas with an accuracy rate of up to 71% using techniques such as AdaBoost, SVM, and k-NN <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#bib.bib40" title="">40</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#bib.bib41" title="">41</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#bib.bib42" title="">42</a>]</cite>. Consequently, there exists a restricted threshold for the number of audio captchas that a user can successfully solve in reCAPTCHA.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span class="ltx_text ltx_font_smallcaps" id="S3.1.1">Understanding reCAPTCHAv2</span>
</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">This section presents the <span class="ltx_text" id="S3.p1.1.1">reCAPTCHAv2</span> in detail together with the data used for this project.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS1.4.1.1">III-A</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS1.5.2">Background</span>
</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">Google’s <span class="ltx_text" id="S3.SS1.p1.1.1">reCAPTCHAv2</span> consists of three different challenge types, each developed to test a specific aspect of visual reasoning. The type 1 captcha challenge, depicted in <a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#S1.F1.sf1" title="In Figure 1 ‣ I Introduction ‣ Breaking reCAPTCHAv2"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">1(a)</span></a>, is a classification task that requires the user to determine whether each image on a static 3 by 3 grid contains the target object or not. On the other hand, the type 2 captcha challenge, as shown in <a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#S1.F1.sf2" title="In Figure 1 ‣ I Introduction ‣ Breaking reCAPTCHAv2"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">1(b)</span></a>, is notable for being an image segmentation task. The challenge presents a single static image that is divided into a grid of 4 rows and 4 columns. Users are asked to divide and recognize specific parts of the image that are relevant to the challenge. Each type presents a unique task, either classification or segmentation, that requires specific approaches to automated solving. The type 3 captcha challenge, shown in <a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#S1.F1.sf3" title="In Figure 1 ‣ I Introduction ‣ Breaking reCAPTCHAv2"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">1(c)</span></a>, is similar to type 1 in its grid layout, but incorporates dynamic images that refresh upon interaction, also requiring classification.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS2.4.1.1">III-B</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS2.5.2">Data</span>
</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">This subsection discusses the data used for the machine learning model.</p>
</div>
<section class="ltx_paragraph" id="S3.SS2.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Classification</h4>
<div class="ltx_para" id="S3.SS2.SSS0.Px1.p1">
<p class="ltx_p" id="S3.SS2.SSS0.Px1.p1.1">Both type 1 and type 3 captchas use image grids in their classification tasks, as seen in <a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#S1.F1.sf1" title="In Figure 1 ‣ I Introduction ‣ Breaking reCAPTCHAv2"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">1(a)</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#S1.F1.sf3" title="In Figure 1 ‣ I Introduction ‣ Breaking reCAPTCHAv2"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">1(c)</span></a>, which are required for the identification of particular subjects. 11,774 labeled images from a publicly accessible dataset were used to fine-tune the machine learning model for this task <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#bib.bib43" title="">43</a>]</cite>. Furthermore, due to the bot’s operations, a dataset of the current captcha images was collected.</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS0.Px1.p2">
<p class="ltx_p" id="S3.SS2.SSS0.Px1.p2.1">Using a pre-trained YOLOv8 for classification, a semi-automated tool was created to speed up the labeling process. To provide training data of the highest quality, this model first assigned labels to the data, which were subsequently manually checked and modified as needed. This hybrid method greatly reduced labeling time without sacrificing accuracy. Combined with the public data, this resulted in around 14k image/label pairs for fine-tuning the classification model.</p>
</div>
<figure class="ltx_figure" id="S3.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="530" id="S3.F2.g1" src="x1.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F2.2.1.1" style="font-size:90%;">Figure 2</span>: </span><span class="ltx_text" id="S3.F2.3.2" style="font-size:90%;">Normalized confusion matrix of the fine-tuned YOLOv8 model evaluated on the 13 classes seen in captcha challenges. The top 1 accuracy is 82.4% while the top 5 accuracy is 99.5%. The matrix highlights the model’s ability to correctly classify various objects such as bicycles, bridges, buses, cars, and more, with values indicating the proportion of correct predictions. For example, bicycles were correctly identified with an accuracy of 89%, while bridges and buses had an accuracy of 84% and 97%, respectively. The matrix reveals the strengths and weaknesses of the model in different classes, showing high precision in certain categories, such as hydrants (100%), and notable confusion in others, such as varied performance in the identification of cars, illustrating the challenges of distinguishing between closely related objects.</span></figcaption>
</figure>
</section>
<section class="ltx_paragraph" id="S3.SS2.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Segmentation</h4>
<div class="ltx_para" id="S3.SS2.SSS0.Px2.p1">
<p class="ltx_p" id="S3.SS2.SSS0.Px2.p1.1">When it comes to the segmentation task, type 2 represents a distinct challenge in contrast to classification. Precise identification of the individual segments that contain the target objects is necessary. Given the limited availability of publicly accessible datasets specifically designed for segmenting captcha images, and the extensive effort needed to gather and annotate such data, this study adopted an alternative methodology. We utilized the pre-trained YOLOv8 model specifically designed for segmentation tasks. This model was already trained on a broad set of classes, many of which are relevant to objects commonly found in <span class="ltx_text" id="S3.SS2.SSS0.Px2.p1.1.1">reCAPTCHAv2</span> image grids. The use of this pre-trained model allowed us to bypass the need for a large, labeled dataset specific to <span class="ltx_text" id="S3.SS2.SSS0.Px2.p1.1.2">reCAPTCHAv2</span> segmentation tasks.</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span class="ltx_text ltx_font_smallcaps" id="S4.1.1">Proposed solution</span>
</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">First, the captcha type and target class of the challenge are extracted. Second, based on the captcha type, the relevant setting of the YOLO v8 model is then used. For type 1 and type 3, the images in the grid are all classified, implying that the YOLO model predicts a class probability for each of the 13 classes, and if the target class has a probability of more than 0.2, then the model selects the image. For type 3 the process is repeated for all new images. To improve the model, we fine-tune the YOLO v8 classification model on the samples mentioned above in <a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#S3.SS2" title="III-B Data ‣ III Understanding reCAPTCHAv2 ‣ Breaking reCAPTCHAv2"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-B</span></span></a>.</p>
</div>
<div class="ltx_para" id="S4.p2">
<p class="ltx_p" id="S4.p2.1">For type 2 the model segments the image and chooses any cell that overlaps with the segmentation. YOLO v8 for segmentation is only trained for 9 of the 13 possible classes, so if one of the 4 remaining classes appears, then the program will just skip the challenge.</p>
</div>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span class="ltx_text ltx_font_smallcaps" id="S5.1.1">Methodology</span>
</h2>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S5.SS1.4.1.1">V-A</span> </span><span class="ltx_text ltx_font_italic" id="S5.SS1.5.2">Evaluation environment</span>
</h3>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">The foundation of our experimental study is a customized testing environment, designed to allow a complete assessment of captcha solving strategies. The core of this environment is Python 3.9, which was chosen for its established reliability and the wide range of scientific computing tools it offers.</p>
</div>
<div class="ltx_para" id="S5.SS1.p2">
<p class="ltx_p" id="S5.SS1.p2.1">The Selenium WebDriver for Firefox is an essential part of our testing infrastructure, working alongside Python. This combination offers a highly accurate simulation of web browsing scenarios, which is essential to accurately present and interact with captchas in a way that closely mimics real-life user behavior. The automation features of Selenium, along with the reliability and efficiency of the Firefox browser, guarantee that every captcha instance is systematically handled and executed in consistent and replicable circumstances. The careful setup of Python 3.9 and Selenium with Firefox is a tactic to ensure that our methodology adheres to the highest levels of experimental precision. <span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span>We evaluate our system on Google <span class="ltx_text" id="footnote5.1">reCAPTCHAv2</span> demo site <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://www.google.com/recaptcha/api2/demo</span>.</span></span></span></p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S5.SS2.4.1.1">V-B</span> </span><span class="ltx_text ltx_font_italic" id="S5.SS2.5.2">Experiments</span>
</h3>
<section class="ltx_paragraph" id="S5.SS2.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">VPN</h4>
<div class="ltx_para" id="S5.SS2.SSS0.Px1.p1">
<p class="ltx_p" id="S5.SS2.SSS0.Px1.p1.1">The integrity and authenticity of the test environment are enhanced by the implementation of a VPN connection, a crucial element in our experimental design. Our methodology acknowledges the advanced capabilities of captcha systems in identifying and reacting to multiple access attempts from a single IP address. To address this, we employ a VPN connection to dynamically change the IP address for each test run. This method guarantees that every interaction with the captcha challenges is seen as a distinct session, therefore reducing the possibility of being identified as suspicious by the security algorithms. Nevertheless, this strategy has its limitations. An evident drawback is the existence of additional network traffic on the VPN, which is a typical attribute of shared network services. The presence of unnecessary traffic can introduce fluctuations in network conditions, which can impact the assessment of the reCAPTCHA.</p>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS2.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Mouse Movement</h4>
<div class="ltx_para" id="S5.SS2.SSS0.Px2.p1">
<p class="ltx_p" id="S5.SS2.SSS0.Px2.p1.1">An essential element in emulating human interactions with captchas involves replicating natural mouse movements. Our strategy utilizes Bézier curves, a mathematical concept frequently employed in computer graphics to represent smooth and scalable curves, to accurately simulate the movement of a user’s mouse cursor. By utilizing Bézier curves, our approach accurately replicates the natural and unpredictable movement of a human cursor.</p>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS2.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">History and Cookies</h4>
<div class="ltx_para" id="S5.SS2.SSS0.Px3.p1">
<p class="ltx_p" id="S5.SS2.SSS0.Px3.p1.1">The last experiment will focus on the addition of history and cookies<span class="ltx_note ltx_role_footnote" id="footnote6"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span>Web pages should only have access to cookies, but we included all the browser data to ensure that an empty browser history could not impact the results.</span></span></span> to the browser session. For this, we use data from a real user to ensure that the data have a history and variability that would be seen from real users.</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span class="ltx_text ltx_font_smallcaps" id="S6.1.1">Results</span>
</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">This section presents the results of the experiments.</p>
</div>
<section class="ltx_subsection" id="S6.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S6.SS1.4.1.1">VI-A</span> </span><span class="ltx_text ltx_font_italic" id="S6.SS1.5.2">VPN Usage Versus Non-VPN Conditions</span>
</h3>
<figure class="ltx_figure" id="S6.F3">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S6.F3.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="498" id="S6.F3.sf1.g1" src="x2.png" width="790"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F3.sf1.2.1.1" style="font-size:90%;">(a)</span> </span><span class="ltx_text" id="S6.F3.sf1.3.2" style="font-size:90%;">Number of solved challenges per captcha without VPN</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S6.F3.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="499" id="S6.F3.sf2.g1" src="x3.png" width="790"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F3.sf2.2.1.1" style="font-size:90%;">(b)</span> </span><span class="ltx_text" id="S6.F3.sf2.3.2" style="font-size:90%;">Number of solved challenges per captcha with VPN</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F3.2.1.1" style="font-size:90%;">Figure 3</span>: </span><span class="ltx_text" id="S6.F3.3.2" style="font-size:90%;">Comparative analysis of captcha-solving challenges with and without the use of a VPN. The upper graph (a) shows the challenges without VPN, where the bot is flagged after the 19th run. The lower graph (b) demonstrates consistent performance over 100 runs with VPN, avoiding bot detection and subsequent challenge escalation.</span></figcaption>
</figure>
<figure class="ltx_table" id="S6.T1">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S6.T1.2">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S6.T1.2.1.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="S6.T1.2.1.1.1"></th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S6.T1.2.1.1.2">W/O VPN</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S6.T1.2.1.1.3">With VPN</td>
</tr>
<tr class="ltx_tr" id="S6.T1.2.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S6.T1.2.2.2.1">Minimum</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T1.2.2.2.2">1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T1.2.2.2.3">1</td>
</tr>
<tr class="ltx_tr" id="S6.T1.2.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T1.2.3.3.1">Median</th>
<td class="ltx_td ltx_align_center" id="S6.T1.2.3.3.2">9.00</td>
<td class="ltx_td ltx_align_center" id="S6.T1.2.3.3.3">13.00</td>
</tr>
<tr class="ltx_tr" id="S6.T1.2.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T1.2.4.4.1">Mean</th>
<td class="ltx_td ltx_align_center" id="S6.T1.2.4.4.2">19.10</td>
<td class="ltx_td ltx_align_center" id="S6.T1.2.4.4.3">19.23</td>
</tr>
<tr class="ltx_tr" id="S6.T1.2.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T1.2.5.5.1">Maximum</th>
<td class="ltx_td ltx_align_center" id="S6.T1.2.5.5.2">194</td>
<td class="ltx_td ltx_align_center" id="S6.T1.2.5.5.3">91</td>
</tr>
<tr class="ltx_tr" id="S6.T1.2.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T1.2.6.6.1">Std.</th>
<td class="ltx_td ltx_align_center" id="S6.T1.2.6.6.2">40.20</td>
<td class="ltx_td ltx_align_center" id="S6.T1.2.6.6.3">17.54</td>
</tr>
<tr class="ltx_tr" id="S6.T1.2.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S6.T1.2.7.7.1">IQR</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T1.2.7.7.2">13.00</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T1.2.7.7.3">20.00</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S6.T1.3.1.1" style="font-size:90%;">TABLE I</span>: </span><span class="ltx_text" id="S6.T1.4.2" style="font-size:90%;">Statistical comparison of the number of necessary solved captcha challenges with and without a VPN connection. Std. is the standard deviation, and IQR is the interquartile range, the difference between the 75th and 25th percentile; both are used to assess the variability. The addition of the VPN connection improved the maximum, but the median and IQR are now much higher</span></figcaption>
</figure>
<div class="ltx_para" id="S6.SS1.p1">
<p class="ltx_p" id="S6.SS1.p1.1">The results of the experiment can be seen in <a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#S6.F3.sf1" title="In Figure 3 ‣ VI-A VPN Usage Versus Non-VPN Conditions ‣ VI Results ‣ Breaking reCAPTCHAv2"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">3(a)</span></a> with the statistical data seen in <a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#S6.T1" title="In VI-A VPN Usage Versus Non-VPN Conditions ‣ VI Results ‣ Breaking reCAPTCHAv2"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">I</span></a>.
The results emphasize the crucial need to use a VPN to reduce the likelihood of being identified as a bot by the risk assessment algorithms of <span class="ltx_text" id="S6.SS1.p1.1.1">reCAPTCHAv2</span>. In the absence of a VPN, the bot faces an increasing number of difficulties beyond a specific limit of captchas. At first, the bot was capable of successfully solving captchas with a consistently low and steady number of challenges in each run. However, there was a significant change after the 20th run, as illustrated in <a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#S6.F3.sf1" title="In Figure 3 ‣ VI-A VPN Usage Versus Non-VPN Conditions ‣ VI Results ‣ Breaking reCAPTCHAv2"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">3(a)</span></a>.</p>
</div>
<div class="ltx_para" id="S6.SS1.p2">
<p class="ltx_p" id="S6.SS1.p2.1">The graph shows the number of challenges required to successfully solve captchas in consecutive runs. During the initial 20 runs, challenges were tackled with a moderate and steady number of challenges. However, in the 21st iteration, there is a significant increase in the number of obstacles encountered, causing the bot’s progress to come to a halt. The bot was unable to solve the captcha and the experiment was stopped after <math alttext="\sim" class="ltx_Math" display="inline" id="S6.SS1.p2.1.m1.1"><semantics id="S6.SS1.p2.1.m1.1a"><mo id="S6.SS1.p2.1.m1.1.1" xref="S6.SS1.p2.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S6.SS1.p2.1.m1.1b"><csymbol cd="latexml" id="S6.SS1.p2.1.m1.1.1.cmml" xref="S6.SS1.p2.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p2.1.m1.1c">\sim</annotation><annotation encoding="application/x-llamapun" id="S6.SS1.p2.1.m1.1d">∼</annotation></semantics></math>200 challenges. This is also seen in the statistics, as the median is much lower without the VPN connection.</p>
</div>
<div class="ltx_para" id="S6.SS1.p3">
<p class="ltx_p" id="S6.SS1.p3.1">The abrupt increase in the number of challenges indicates that the <span class="ltx_text" id="S6.SS1.p3.1.1">reCAPTCHAv2</span> system most probably identified the bot’s actions as suspicious, prompting a security mechanism that considerably increases the number of challenges. It demonstrates the system’s ability to adjust to apparent automated behavior by implementing a defensive approach that gradually increases the number of challenges, eventually reaching a level that is almost impossible to overcome.</p>
</div>
<div class="ltx_para" id="S6.SS1.p4">
<p class="ltx_p" id="S6.SS1.p4.1">Therefore, the use of a virtual private network (VPN) is crucial in this particular situation. A VPN limits the ability of risk assessment algorithms to monitor and create a profile of the bot over several runs by allocating a different IP address for each run. This enables each captcha to be regarded as a distinct entity, bypassing the <span class="ltx_text" id="S6.SS1.p4.1.1">reCAPTCHAv2</span> system’s increasing security measures and hindering the bot from being obstructed or trapped in an infinite cycle of challenges. The bot using a VPN network could successfully pass the captcha for all 100 runs.</p>
</div>
</section>
<section class="ltx_subsection" id="S6.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S6.SS2.4.1.1">VI-B</span> </span><span class="ltx_text ltx_font_italic" id="S6.SS2.5.2">Mouse Movement</span>
</h3>
<div class="ltx_para" id="S6.SS2.p1">
<p class="ltx_p" id="S6.SS2.p1.1">In the previous tests, the mouse did not move while solving the challenges; therefore, we now include mouse movements. The incorporation of linear mouse motion into the captcha-solving algorithm has resulted in a noticeable enhancement in the bot’s efficiency, as evidenced by the statistics in <a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#S6.T2" title="In VI-B Mouse Movement ‣ VI Results ‣ Breaking reCAPTCHAv2"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">II</span></a>. <a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#S6.F4" title="In VI-B Mouse Movement ‣ VI Results ‣ Breaking reCAPTCHAv2"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">4</span></a> depicts the number of challenges required to successfully solve a captcha during multiple iterations. This figure presents a comparison between the baseline method <a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#S6.F4.sf1" title="In Figure 4 ‣ VI-B Mouse Movement ‣ VI Results ‣ Breaking reCAPTCHAv2"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">4(a)</span></a>, where the bot used the JavaScript click function of Selenium, and the improved strategy <a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#S6.F4.sf2" title="In Figure 4 ‣ VI-B Mouse Movement ‣ VI Results ‣ Breaking reCAPTCHAv2"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">4(b)</span></a> that involved moving the mouse cursor directly to the target elements on the captcha grid.</p>
</div>
<figure class="ltx_figure" id="S6.F4">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S6.F4.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="499" id="S6.F4.sf1.g1" src="x4.png" width="790"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F4.sf1.2.1.1" style="font-size:90%;">(a)</span> </span><span class="ltx_text" id="S6.F4.sf1.3.2" style="font-size:90%;">Without mouse movement. This is the same as <a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#S6.F3.sf2" title="In Figure 3 ‣ VI-A VPN Usage Versus Non-VPN Conditions ‣ VI Results ‣ Breaking reCAPTCHAv2"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">3(b)</span></a> but the scale is different to make comparisons easier.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S6.F4.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="498" id="S6.F4.sf2.g1" src="x5.png" width="790"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F4.sf2.2.1.1" style="font-size:90%;">(b)</span> </span><span class="ltx_text" id="S6.F4.sf2.3.2" style="font-size:90%;">With straight line movement</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S6.F4.sf3"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="498" id="S6.F4.sf3.g1" src="x6.png" width="790"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F4.sf3.2.1.1" style="font-size:90%;">(c)</span> </span><span class="ltx_text" id="S6.F4.sf3.3.2" style="font-size:90%;">With Bézier curve movement</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F4.2.1.1" style="font-size:90%;">Figure 4</span>: </span><span class="ltx_text" id="S6.F4.3.2" style="font-size:90%;">Comparison of different mouse movement strategies in captcha solving. From top to bottom: (a) without mouse movement, (b) with straight line movement, and (c) with Bézier curve movement, illustrating the progressive performance improvement.</span></figcaption>
</figure>
<figure class="ltx_table" id="S6.T2">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S6.T2.2">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S6.T2.2.1.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="S6.T2.2.1.1.1"></th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S6.T2.2.1.1.2">W/O mouse cursor</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S6.T2.2.1.1.3">Straight Lines</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S6.T2.2.1.1.4">Bézier Curves</td>
</tr>
<tr class="ltx_tr" id="S6.T2.2.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S6.T2.2.2.2.1">Minimum</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T2.2.2.2.2">1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T2.2.2.2.3">1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T2.2.2.2.4">1</td>
</tr>
<tr class="ltx_tr" id="S6.T2.2.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T2.2.3.3.1">Median</th>
<td class="ltx_td ltx_align_center" id="S6.T2.2.3.3.2">13.00</td>
<td class="ltx_td ltx_align_center" id="S6.T2.2.3.3.3">7.00</td>
<td class="ltx_td ltx_align_center" id="S6.T2.2.3.3.4">5.00</td>
</tr>
<tr class="ltx_tr" id="S6.T2.2.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T2.2.4.4.1">Mean</th>
<td class="ltx_td ltx_align_center" id="S6.T2.2.4.4.2">19.23</td>
<td class="ltx_td ltx_align_center" id="S6.T2.2.4.4.3">9.72</td>
<td class="ltx_td ltx_align_center" id="S6.T2.2.4.4.4">8.38</td>
</tr>
<tr class="ltx_tr" id="S6.T2.2.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T2.2.5.5.1">Maximum</th>
<td class="ltx_td ltx_align_center" id="S6.T2.2.5.5.2">91</td>
<td class="ltx_td ltx_align_center" id="S6.T2.2.5.5.3">60</td>
<td class="ltx_td ltx_align_center" id="S6.T2.2.5.5.4">58</td>
</tr>
<tr class="ltx_tr" id="S6.T2.2.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T2.2.6.6.1">Std.</th>
<td class="ltx_td ltx_align_center" id="S6.T2.2.6.6.2">17.54</td>
<td class="ltx_td ltx_align_center" id="S6.T2.2.6.6.3">11.56</td>
<td class="ltx_td ltx_align_center" id="S6.T2.2.6.6.4">11.45</td>
</tr>
<tr class="ltx_tr" id="S6.T2.2.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S6.T2.2.7.7.1">IQR</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T2.2.7.7.2">20.00</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T2.2.7.7.3">7.75</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T2.2.7.7.4">7.00</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S6.T2.3.1.1" style="font-size:90%;">TABLE II</span>: </span><span class="ltx_text" id="S6.T2.4.2" style="font-size:90%;">Statistical comparison of how many captcha challenges needed to be solved with and without using the mouse cursor, where the cursor movement was either in straight lines or along Bézier curves. Moving the mouse, regardless of the path type, improved (reduced) the overall number of challenges. However, a t-test comparing the effects of straight lines versus Bézier curves gave a t-statistic of 0.58 and a p-value of 0.57, indicating that there are no significant differences between the two movement types.</span></figcaption>
</figure>
<div class="ltx_para" id="S6.SS2.p2">
<p class="ltx_p" id="S6.SS2.p2.1">The findings demonstrate a significant decrease in the number of challenges needed to solve captchas for all types when using straight-line mouse movement. The incidence of encountering peak issues with each form of captcha, particularly type 3, has dropped considerably. This enhancement highlights the importance of using simulations that closely resemble human interactions. Conventional automated clicks can be easily detected by advanced bot detection systems used by captcha systems. However, incorporating linear mouse trajectories adds a more realistic imitation of human behavior, making it less likely that bots will be immediately identified and subjected to further challenges.</p>
</div>
<div class="ltx_para" id="S6.SS2.p3">
<p class="ltx_p" id="S6.SS2.p3.1">These findings indicate that the mouse path towards the target, rather than just the encounter with the target itself, is a crucial element in successfully passing the captchas. The graph presents empirical data that supports the concept that integrating mouse movements that resemble those of humans can greatly improve the efficiency of automated captcha-solving systems.</p>
</div>
<div class="ltx_para" id="S6.SS2.p4">
<p class="ltx_p" id="S6.SS2.p4.1">The integration of Bézier curve-based mouse movements into our captcha-solving algorithm has resulted in an additional enhancement in performance, surpassing the original increase achieved by integrating straight-line movements. The graph in this section illustrates the progress of the bot’s capacity to overcome captchas by imitating the non-linear and smoother mouse movements facilitated by Bézier curves.</p>
</div>
<div class="ltx_para" id="S6.SS2.p5">
<p class="ltx_p" id="S6.SS2.p5.1">This advanced technique for moving the mouse greatly decreased the number of challenges needed to solve captchas of all kinds, especially the more challenging type 3 captchas. By including Bézier curves, the behavior of cursor navigation closely imitates the subtle actions of humans, making it more difficult for complex bot protection mechanisms like captcha systems to identify. Consequently, bot interactions have a reduced likelihood of triggering security defenses, which can result in an increased number of challenges or complete denial of access.</p>
</div>
<div class="ltx_para" id="S6.SS2.p6">
<p class="ltx_p" id="S6.SS2.p6.1">Additional statistical analysis was performed to compare the efficacy of mouse movements with straight lines and Bézier curves in solving captchas. A t-test was performed to evaluate the disparity in the total number of challenges needed to solve the captchas between these two methods. The analysis resulted in a t-statistic of 0.58 and a p-value of 0.57. This implies that although the use of Bézier curve movements showed a performance improvement, as evidenced by the decrease in the average number of challenges (8.38 for Bézier curves compared to 9.72 for straight lines, as seen in <a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#S6.T2" title="In VI-B Mouse Movement ‣ VI Results ‣ Breaking reCAPTCHAv2"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">II</span></a>), the difference was not statistically significant.</p>
</div>
</section>
<section class="ltx_subsection" id="S6.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S6.SS3.4.1.1">VI-C</span> </span><span class="ltx_text ltx_font_italic" id="S6.SS3.5.2">Impact of Browser History and Cookies on Captcha Solvability</span>
</h3>
<figure class="ltx_figure" id="S6.F5">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S6.F5.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="498" id="S6.F5.sf1.g1" src="x7.png" width="790"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F5.sf1.2.1.1" style="font-size:90%;">(a)</span> </span><span class="ltx_text" id="S6.F5.sf1.3.2" style="font-size:90%;">Without browser history and cookies. This is the same as <a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#S6.F4.sf3" title="In Figure 4 ‣ VI-B Mouse Movement ‣ VI Results ‣ Breaking reCAPTCHAv2"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">4(c)</span></a> but the scale is different to make comparisons easier.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S6.F5.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="498" id="S6.F5.sf2.g1" src="x8.png" width="790"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F5.sf2.2.1.1" style="font-size:90%;">(b)</span> </span><span class="ltx_text" id="S6.F5.sf2.3.2" style="font-size:90%;">With browser history and cookies.</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F5.2.1.1" style="font-size:90%;">Figure 5</span>: </span><span class="ltx_text" id="S6.F5.3.2" style="font-size:90%;">Comparative analysis of captcha-solving challenges with and without browser history and cookies from a browser session with a logged-in Google account. The left graph (a) displays the number of challenges in the absence of cookies and history, while the right graph (b) shows the number of challenges with cookies and history present, indicating the impact of user data on captcha challenge complexity.</span></figcaption>
</figure>
<figure class="ltx_table" id="S6.T3">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S6.T3.2">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S6.T3.2.1.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="S6.T3.2.1.1.1"></th>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S6.T3.2.1.1.2">History and Cookies</td>
</tr>
<tr class="ltx_tr" id="S6.T3.2.2.2">
<th class="ltx_td ltx_th ltx_th_row" id="S6.T3.2.2.2.1"></th>
<td class="ltx_td ltx_align_center" id="S6.T3.2.2.2.2">W/O</td>
<td class="ltx_td ltx_align_center" id="S6.T3.2.2.2.3">With</td>
</tr>
<tr class="ltx_tr" id="S6.T3.2.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S6.T3.2.3.3.1">Minimum</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T3.2.3.3.2">1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T3.2.3.3.3">1</td>
</tr>
<tr class="ltx_tr" id="S6.T3.2.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T3.2.4.4.1">Median</th>
<td class="ltx_td ltx_align_center" id="S6.T3.2.4.4.2">5.00</td>
<td class="ltx_td ltx_align_center" id="S6.T3.2.4.4.3">2.00</td>
</tr>
<tr class="ltx_tr" id="S6.T3.2.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T3.2.5.5.1">Mean</th>
<td class="ltx_td ltx_align_center" id="S6.T3.2.5.5.2">8.38</td>
<td class="ltx_td ltx_align_center" id="S6.T3.2.5.5.3">2.71</td>
</tr>
<tr class="ltx_tr" id="S6.T3.2.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T3.2.6.6.1">Maximum</th>
<td class="ltx_td ltx_align_center" id="S6.T3.2.6.6.2">58</td>
<td class="ltx_td ltx_align_center" id="S6.T3.2.6.6.3">8</td>
</tr>
<tr class="ltx_tr" id="S6.T3.2.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T3.2.7.7.1">Std.</th>
<td class="ltx_td ltx_align_center" id="S6.T3.2.7.7.2">11.45</td>
<td class="ltx_td ltx_align_center" id="S6.T3.2.7.7.3">1.88</td>
</tr>
<tr class="ltx_tr" id="S6.T3.2.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S6.T3.2.8.8.1">IQR</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T3.2.8.8.2">7.00</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T3.2.8.8.3">2.00</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S6.T3.3.1.1" style="font-size:90%;">TABLE III</span>: </span><span class="ltx_text" id="S6.T3.4.2" style="font-size:90%;">Statistical comparison of the number of necessary solved captcha challenges when including or excluding cookies and browser history from a real-world active user. Including the data drastically reduces all statistics. In particular, the variability is much lower, which implies that the addition of browser data makes the performance more stable.</span></figcaption>
</figure>
<div class="ltx_para" id="S6.SS3.p1">
<p class="ltx_p" id="S6.SS3.p1.1">The results and statistics of the experiment can be seen in <a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#S6.F5" title="In VI-C Impact of Browser History and Cookies on Captcha Solvability ‣ VI Results ‣ Breaking reCAPTCHAv2"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">5</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#S6.T3" title="In VI-C Impact of Browser History and Cookies on Captcha Solvability ‣ VI Results ‣ Breaking reCAPTCHAv2"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">III</span></a>, respectively. The results show a drastic drop in the number of challenges required to solve a captcha. Additionally, a statistical test was performed. With a t-statistic of 3.42 and a p-value of 0.00, the tests show a substantial and statistically significant difference in <span class="ltx_text" id="S6.SS3.p1.1.1">reCAPTCHAv2</span>-solving performance by including browser history and cookies. These findings indicate that the inclusion of browser history and cookies significantly affects the solvability of <span class="ltx_text" id="S6.SS3.p1.1.2">reCAPTCHAv2</span>.</p>
</div>
<div class="ltx_para" id="S6.SS3.p2">
<p class="ltx_p" id="S6.SS3.p2.1">This discovery is significant and indicates the importance of user-specific data in <span class="ltx_text" id="S6.SS3.p2.1.1">reCAPTCHAv2</span> challenges. <span class="ltx_text" id="S6.SS3.p2.1.2">reCAPTCHAv2</span> seem to be less challenging to complete when there is browser history or cookies, probably because the security system recognizes an existing trusted user. On the other hand, if a user has no browsing history and cookies, the system may respond by presenting additional captchas, assuming that the user is less likely to be a genuine human.</p>
</div>
<div class="ltx_para" id="S6.SS3.p3">
<p class="ltx_p" id="S6.SS3.p3.1">The findings emphasize the flexible characteristics of contemporary captcha systems, which modify their level of difficulty according to user behavior and past experiences.</p>
</div>
</section>
<section class="ltx_subsection" id="S6.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S6.SS4.4.1.1">VI-D</span> </span><span class="ltx_text ltx_font_italic" id="S6.SS4.5.2">Comparative Analysis of Human versus Bot Performance in Captcha Solving</span>
</h3>
<figure class="ltx_figure" id="S6.F6">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S6.F6.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="498" id="S6.F6.sf1.g1" src="x9.png" width="790"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F6.sf1.2.1.1" style="font-size:90%;">(a)</span> </span><span class="ltx_text" id="S6.F6.sf1.3.2" style="font-size:90%;">Number of challenges the human received to solve captchas.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S6.F6.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="498" id="S6.F6.sf2.g1" src="x10.png" width="790"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F6.sf2.2.1.1" style="font-size:90%;">(b)</span> </span><span class="ltx_text" id="S6.F6.sf2.3.2" style="font-size:90%;">Number of challenges the bot received to solve captchas. This is the same as <a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#S6.F5.sf2" title="In Figure 5 ‣ VI-C Impact of Browser History and Cookies on Captcha Solvability ‣ VI Results ‣ Breaking reCAPTCHAv2"><span class="ltx_text ltx_ref_tag">Fig.</span> <span class="ltx_text ltx_ref_tag">5(b)</span></a>, but the scale is different to make comparisons easier.</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F6.2.1.1" style="font-size:90%;">Figure 6</span>: </span><span class="ltx_text" id="S6.F6.3.2" style="font-size:90%;">Comparative performance of a human and a bot in solving captchas. The upper graph shows the number of challenges for the human user, while the lower graph shows the number of challenges for the bot. Both bot and human use about the same number of challenges per captcha; however, notably humans are mostly served type 3 captchas while our bot is mostly served types 1 and 2, and the human always has to solve at least two challenges.</span></figcaption>
</figure>
<div class="ltx_para" id="S6.SS4.p1">
<p class="ltx_p" id="S6.SS4.p1.1">This study performed a comparative analysis to assess human and bot performance in answering captchas under the same settings (with VPN, within the Selenium Browser, and with cookies and history). The experiment included a sequence of trials in which both a human subject and an automated bot attempted to solve the <span class="ltx_text" id="S6.SS4.p1.1.1">reCAPTCHAv2</span> image-captchas. The results of the experiment can be seen in <a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#S6.F6" title="In VI-D Comparative Analysis of Human versus Bot Performance in Captcha Solving ‣ VI Results ‣ Breaking reCAPTCHAv2"><span class="ltx_text ltx_ref_tag">Figs.</span> <span class="ltx_text ltx_ref_tag">6</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#S6.T4" title="Table IV ‣ VI-D Comparative Analysis of Human versus Bot Performance in Captcha Solving ‣ VI Results ‣ Breaking reCAPTCHAv2"><span class="ltx_text ltx_ref_tag">IV</span></a>.</p>
</div>
<div class="ltx_para" id="S6.SS4.p2">
<p class="ltx_p" id="S6.SS4.p2.1">The results of our study demonstrate that on average the bot exhibited a slightly lower number of challenges to successfully solve the captchas compared to the human solver, as illustrated in the table provided. However, a t-test was performed to assess the statistical significance of differences in efforts between the bot and the human. The resulting p-value was 0.11. The value, which exceeds the standard alpha level of 0.05, indicates that the observed variations in the number of challenges may be attributed to random chance and do not have statistical significance. This means that the bot has a similar behavior to the human statistics. However, as the p-value is relatively low, there is some evidence that there might be a difference between the bot and the human solver. Further studies could investigate this further.</p>
</div>
<figure class="ltx_table" id="S6.T4">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S6.T4.2">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S6.T4.2.1.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="S6.T4.2.1.1.1"></th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S6.T4.2.1.1.2">Bot</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S6.T4.2.1.1.3">Human</td>
</tr>
<tr class="ltx_tr" id="S6.T4.2.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S6.T4.2.2.2.1">Minimum</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T4.2.2.2.2">1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T4.2.2.2.3">2</td>
</tr>
<tr class="ltx_tr" id="S6.T4.2.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T4.2.3.3.1">Median</th>
<td class="ltx_td ltx_align_center" id="S6.T4.2.3.3.2">2.00</td>
<td class="ltx_td ltx_align_center" id="S6.T4.2.3.3.3">2.00</td>
</tr>
<tr class="ltx_tr" id="S6.T4.2.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T4.2.4.4.1">Mean</th>
<td class="ltx_td ltx_align_center" id="S6.T4.2.4.4.2">2.71</td>
<td class="ltx_td ltx_align_center" id="S6.T4.2.4.4.3">3.50</td>
</tr>
<tr class="ltx_tr" id="S6.T4.2.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T4.2.5.5.1">Maximum</th>
<td class="ltx_td ltx_align_center" id="S6.T4.2.5.5.2">8</td>
<td class="ltx_td ltx_align_center" id="S6.T4.2.5.5.3">15</td>
</tr>
<tr class="ltx_tr" id="S6.T4.2.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T4.2.6.6.1">Std.</th>
<td class="ltx_td ltx_align_center" id="S6.T4.2.6.6.2">1.88</td>
<td class="ltx_td ltx_align_center" id="S6.T4.2.6.6.3">2.79</td>
</tr>
<tr class="ltx_tr" id="S6.T4.2.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S6.T4.2.7.7.1">IQR</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T4.2.7.7.2">2.00</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T4.2.7.7.3">1.00</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S6.T4.3.1.1" style="font-size:90%;">TABLE IV</span>: </span><span class="ltx_text" id="S6.T4.4.2" style="font-size:90%;">Statistical comparison of the number of necessary solved captcha challenges between our bot and a human captcha solver. We see that the bot overall has a lower mean and standard deviation than the human solver. However, when performing a t-test we get a t-statistic of 1.63 and a p-value of 0.11. So the difference is not significant at a level of 0.05 or 0.10, but there is some evidence of a potential difference between the two.</span></figcaption>
</figure>
<div class="ltx_para" id="S6.SS4.p3">
<p class="ltx_p" id="S6.SS4.p3.1">Comparison of human and automated bot performance in overcoming captchas provides detailed insights into the advancing capabilities of machine learning algorithms. The absence of a statistically significant disparity in the number of challenges between humans and bots, as evidenced by the t-test findings, questions the conventional belief that image-based captchas are an accurate way of distinguishing between human and nonhuman users. This discovery reinforces the need for ongoing improvement of captcha methods to stay up-to-date with the progressing field of artificial intelligence.</p>
</div>
<div class="ltx_para" id="S6.SS4.p4">
<p class="ltx_p" id="S6.SS4.p4.1">Moreover, the bot’s success raises inquiries regarding the capacity of advanced bots to bypass security protocols that several online services depend on. It highlights a competition between creators of security systems and programmers of bots, where every improvement in bot technology leads to a matching upgrade in security measures.</p>
</div>
<div class="ltx_para" id="S6.SS4.p5">
<p class="ltx_p" id="S6.SS4.p5.1">Finally, we see that our solution is never blocked by the <span class="ltx_text" id="S6.SS4.p5.1.1">reCAPTCHAv2</span> system, while <cite class="ltx_cite ltx_citemacro_citet">Wang et al. [<a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#bib.bib11" title="">11</a>]</cite> and <cite class="ltx_cite ltx_citemacro_citet">Sivakorn et al. [<a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#bib.bib13" title="">13</a>]</cite> only solved 68-71% of the captchas.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VII </span><span class="ltx_text ltx_font_smallcaps" id="S7.1.1">Conclusion</span>
</h2>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">This study aims to evaluate the current status of image-based captcha challenges, with a specific focus on Google’s <span class="ltx_text" id="S7.p1.1.1">reCAPTCHAv2</span> and its vulnerability to advanced machine learning techniques. By conducting systematic experiments, we have shown that automated systems using advanced AI technologies, such as YOLO models, can successfully solve image-based captchas.</p>
</div>
<div class="ltx_para" id="S7.p2">
<p class="ltx_p" id="S7.p2.1">Comparative analysis of captcha-solving challenges by humans and bots demonstrated that although bots can closely mimic human performance, the observed difference was not statistically significant. This finding raises doubts about the reliability of image-based captchas as a definitive method for distinguishing between humans and bots. Our findings indicate that current captcha mechanisms are not immune to the rapidly advancing field of artificial intelligence. Additionally, we find that including browser cookies and history gives a substantial reduction in the number of challenges one is faced with. Our final model can solve 100% of the presented captchas, while other models can only solve 68-71% of the presented captchas from <span class="ltx_text" id="S7.p2.1.1">reCAPTCHAv2</span>.</p>
</div>
<div class="ltx_para" id="S7.p3">
<p class="ltx_p" id="S7.p3.1">Continuous progress in AI requires a simultaneous development of digital security measures. Subsequent investigations should prioritize the development of captcha systems capable of adjusting to the complexity of artificial intelligence or explore alternative methods of human verification that can withstand the progress of technology.</p>
</div>
<div class="ltx_para" id="S7.p4">
<p class="ltx_p" id="S7.p4.1">Future studies might consider expanding the number of runs in every experiment. Currently, our study covers a range of 50 to 100 runs for every experimental configuration. Nevertheless, carrying out a larger quantity of iterations, possibly ranging in the hundreds or thousands, could yield more extensive observations about the enduring efficiency and dependability of the captcha-solving techniques. An expansion of this kind would provide a deeper understanding of the adaptive reactions of captcha systems over time and the enduring effectiveness of automated solving methods.</p>
</div>
<div class="ltx_para" id="S7.p5">
<p class="ltx_p" id="S7.p5.1">Future studies should improve the type 2 captcha dataset, which requires image segmentation. Some object classes from Google’s <span class="ltx_text" id="S7.p5.1.1">reCAPTCHAv2</span> are missing from our dataset, including the ’stairs’ class. Future research should prioritize data collection to capture and label more objects to close this gap.
Furthermore, it would be beneficial for future research to investigate the threshold at which continuous captcha solving occurs before triggering a block. Due to the influence of cookies and user session data on captcha challenge difficulty, there is a valid risk that multiple attempts to solve captchas from the same computer with the same cookies could result in the computer being blocked by captcha systems. Conducting a thorough examination of the number of attempts required to activate countermeasures would provide valuable information.</p>
</div>
<div class="ltx_para" id="S7.p6">
<p class="ltx_p" id="S7.p6.1">The use of Google’s <span class="ltx_text" id="S7.p6.1.1">reCAPTCHAv2</span> has played a crucial role in improving website security on the Internet by successfully differentiating between actual users and automated bots. It fulfills various practical applications, tackling some of the most urgent security issues on the Internet. For example, <span class="ltx_text" id="S7.p6.1.2">reCAPTCHAv2</span> addresses the scraping issue, which undermines the uniqueness of material by preventing automated theft to divert advertising income or gain a competitive advantage. This has become more relevant with the popularity of Large Language Models, LLMs, and the massive amounts of data required to train them <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08831v1#bib.bib22" title="">22</a>]</cite>.
Our findings mark a crucial point in the ongoing dialogue between AI capabilities and digital security. They highlight the necessity for captcha technologies to evolve proactively, staying ahead of AI’s rapid advancements. This is not just an academic challenge; it is a vital step toward ensuring the continued reliability and safety of our online environments.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">BuiltWith [2024a]</span>
<span class="ltx_bibblock">
BuiltWith, “recaptcha v2 usage statistics,” <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://trends.builtwith.com/widgets/reCAPTCHA-v2</span>, 2024, accessed: 2024-02-20.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">BuiltWith [2024b]</span>
<span class="ltx_bibblock">
——, “recaptcha v3 usage statistics,” <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://trends.builtwith.com/widgets/reCAPTCHA-v3</span>, 2024, accessed: 2024-02-20.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Google [2024]</span>
<span class="ltx_bibblock">
Google. (2024) Can i run recaptcha v2 and v3 on the same page? Google. Accessed: 2024-02-20. [Online]. Available: <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://developers.google.com/recaptcha/docs/faq#can-i-run-recaptcha-v2-and-v3-on-the-same-page</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Stack Overflow user “simhumileco” [2020]</span>
<span class="ltx_bibblock">
Stack Overflow user “simhumileco”, “Answer to ”can i run recaptcha v2 and v3 on the same page?”,” <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://stackoverflow.com/a/63344009</span>, 2020, accessed: 2024-02-20.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Von Ahn et al. [2003]</span>
<span class="ltx_bibblock">
L. Von Ahn, M. Blum, N. J. Hopper, and J. Langford, “CAPTCHA: Using hard AI problems for security,” in <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">Advances in Cryptology—EUROCRYPT 2003: International Conference on the Theory and Applications of Cryptographic Techniques</em>, 2003.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Von Ahn et al. [2004]</span>
<span class="ltx_bibblock">
L. Von Ahn, M. Blum, and J. Langford, “Telling humans and computers apart automatically,” <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">Communications of the ACM</em>, vol. 47, no. 2, pp. 56–60, 2004.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chellapilla and Simard [2004]</span>
<span class="ltx_bibblock">
K. Chellapilla and P. Simard, “Using machine learning to break visual human interaction proofs (HIPs),” <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">Advances in neural information processing systems</em>, 2004.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bursztein et al. [2014]</span>
<span class="ltx_bibblock">
E. Bursztein, J. Aigrain, A. Moscicki, and J. C. Mitchell, “The end is nigh: Generic solving of text-based <math alttext="\{" class="ltx_Math" display="inline" id="bib.bib8.1.m1.1"><semantics id="bib.bib8.1.m1.1a"><mo id="bib.bib8.1.m1.1.1" stretchy="false" xref="bib.bib8.1.m1.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib8.1.m1.1b"><ci id="bib.bib8.1.m1.1.1.cmml" xref="bib.bib8.1.m1.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib8.1.m1.1c">\{</annotation><annotation encoding="application/x-llamapun" id="bib.bib8.1.m1.1d">{</annotation></semantics></math>CAPTCHAs<math alttext="\}" class="ltx_Math" display="inline" id="bib.bib8.2.m2.1"><semantics id="bib.bib8.2.m2.1a"><mo id="bib.bib8.2.m2.1.1" stretchy="false" xref="bib.bib8.2.m2.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib8.2.m2.1b"><ci id="bib.bib8.2.m2.1.1.cmml" xref="bib.bib8.2.m2.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib8.2.m2.1c">\}</annotation><annotation encoding="application/x-llamapun" id="bib.bib8.2.m2.1d">}</annotation></semantics></math>,” in <em class="ltx_emph ltx_font_italic" id="bib.bib8.3.1">8th USENIX Workshop on Offensive Technologies (WOOT 14)</em>, 2014.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. [2021]</span>
<span class="ltx_bibblock">
Y. Wang, Y. Wei, M. Zhang, Y. Liu, and B. Wang, “Make complex captchas simple: A fast text captcha solver based on a small number of samples,” <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">Information Sciences</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Noury and Rezaei [2020]</span>
<span class="ltx_bibblock">
Z. Noury and M. Rezaei, “Deep-captcha: a deep learning based captcha solver for vulnerability assessment,” 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. [2020]</span>
<span class="ltx_bibblock">
D. Wang, M. Moh, and T.-S. Moh, “Using deep learning to solve google recaptcha v2’s image challenges,” in <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">International Conference on Ubiquitous Information Management and Communication (IMCOM)</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hossen et al. [2020]</span>
<span class="ltx_bibblock">
M. I. Hossen, Y. Tu, M. F. Rabby, M. N. Islam, H. Cao, and X. Hei, “An object detection based solver for Google’s image reCAPTCHA v2,” in <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">23rd International Symposium on Research in Attacks, Intrusions and Defenses (RAID 2020)</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sivakorn et al. [2016]</span>
<span class="ltx_bibblock">
S. Sivakorn, J. Polakis, and A. D. Keromytis, “I’m not a human: Breaking the google recaptcha,” <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">Black Hat</em>, vol. 14, pp. 1–12, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Artistrazh [2022]</span>
<span class="ltx_bibblock">
Artistrazh, “Recaptcha v2 solver,” <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://github.com/Artistrazh/recaptcha_v2_solver</span>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">LunaPy17 [2023]</span>
<span class="ltx_bibblock">
LunaPy17, “Recaptchav2-ia-solver,” <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://github.com/LunaPy17/RecaptchaV2-IA-Solver</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">MacKey-255 [2018]</span>
<span class="ltx_bibblock">
MacKey-255, “Goodbyecaptcha,” <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://github.com/MacKey-255/GoodByeCatpcha</span>, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Google [a]</span>
<span class="ltx_bibblock">
Google, “recaptcha v2,” <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://developers.google.com/recaptcha/docs/display</span>, accessed: 2024-02-21.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Google [b]</span>
<span class="ltx_bibblock">
——, “recaptcha v3,” <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://developers.google.com/recaptcha/docs/v3</span>, accessed: 2024-02-21.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Krizhevsky et al. [2012]</span>
<span class="ltx_bibblock">
A. Krizhevsky, I. Sutskever, and G. E. Hinton, “Imagenet classification with deep convolutional neural networks,” in <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">Advances in Neural Information Processing Systems</em>, 2012.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vaswani et al. [2017]</span>
<span class="ltx_bibblock">
A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, Ł. Kaiser, and I. Polosukhin, “Attention is all you need,” <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">Advances in neural information processing systems</em>, vol. 30, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Khan et al. [2022]</span>
<span class="ltx_bibblock">
S. Khan, M. Naseer, M. Hayat, S. W. Zamir, F. S. Khan, and M. Shah, “Transformers in vision: A survey,” <em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">ACM computing surveys (CSUR)</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et al. [2020]</span>
<span class="ltx_bibblock">
T. B. Brown, B. Mann, N. Ryder, M. Subbiah, J. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell, S. Agarwal, A. Herbert-Voss, G. Krueger, T. Henighan, R. Child, A. Ramesh, D. M. Ziegler, J. Wu, C. Winter, C. Hesse, M. Chen, E. Sigler, M. Litwin, S. Gray, B. Chess, J. Clark, C. Berner, S. McCandlish, A. Radford, I. Sutskever, and D. Amodei, “Language models are few-shot learners,” 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI [2023]</span>
<span class="ltx_bibblock">
OpenAI, “Gpt-4 technical report,” 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Betker et al. [2023]</span>
<span class="ltx_bibblock">
J. Betker, G. Goh, L. Jing, T. Brooks, J. Wang, L. Li, L. Ouyang, J. Zhuang, J. Lee, Y. Guo <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">et al.</em>, “Improving image generation with better captions,” <em class="ltx_emph ltx_font_italic" id="bib.bib24.2.2">Computer Science</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jocher et al. [2023]</span>
<span class="ltx_bibblock">
G. Jocher, A. Chaurasia, and J. Qiu, “Ultralytics YOLO v8.0.0,” <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://github.com/ultralytics/ultralytics</span>, Jan. 2023, version 8.0.0. License: AGPL-3.0.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Redmon et al. [2016]</span>
<span class="ltx_bibblock">
J. Redmon, S. Divvala, R. Girshick, and A. Farhadi, “You only look once: Unified, real-time object detection,” 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shafiee et al. [2017]</span>
<span class="ltx_bibblock">
M. J. Shafiee, B. Chywl, F. Li, and A. Wong, “Fast yolo: A fast you only look once system for real-time embedded object detection in video,” 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et al. [2023]</span>
<span class="ltx_bibblock">
H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux, T. Lacroix, B. Rozière, N. Goyal, E. Hambro, F. Azhar, A. Rodriguez, A. Joulin, E. Grave, and G. Lample, “Llama: Open and efficient foundation language models,” 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Trinh et al. [2024]</span>
<span class="ltx_bibblock">
T. H. Trinh, Y. Wu, Q. V. Le, H. He, and T. Luong, “Solving olympiad geometry without human demonstrations,” <em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">Nature</em>, vol. 625, no. 7995, pp. 476–482, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et al. [2021]</span>
<span class="ltx_bibblock">
A. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal, G. Sastry, A. Askell, P. Mishkin, J. Clark, G. Krueger, and I. Sutskever, “Learning transferable visual models from natural language supervision,” 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Arkose Labs [2024]</span>
<span class="ltx_bibblock">
Arkose Labs, “Arkose matchkey advanced captcha software,” <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://www.arkoselabs.com/arkose-matchkey/</span>, 2024, accessed: 2024-02-20.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Amazon Web Services [2024]</span>
<span class="ltx_bibblock">
Amazon Web Services, “CAPTCHA and Challenge in AWS WAF,” <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://docs.aws.amazon.com/waf/latest/developerguide/waf-captcha-and-challenge.html</span>, 2024, accessed: 2024-02-20.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">hCaptcha [2024]</span>
<span class="ltx_bibblock">
hCaptcha, “hcaptcha,” <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://www.hcaptcha.com/</span>, 2024, accessed: 2024-02-20.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bursztein et al. [2010]</span>
<span class="ltx_bibblock">
E. Bursztein, S. Bethard, C. Fabry, J. C. Mitchell, and D. Jurafsky, “How good are humans at solving captchas? a large scale evaluation,” in <em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">IEEE Symposium on Security and Privacy</em>, 2010.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Osadchy et al. [2017]</span>
<span class="ltx_bibblock">
M. Osadchy, J. Hernandez-Castro, S. Gibson, O. Dunkelman, and D. Pérez-Cabo, “No bot expects the deepcaptcha! introducing immutable adversarial examples, with applications to captcha generation,” <em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">IEEE Transactions on Information Forensics and Security</em>, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kurakin et al. [2018]</span>
<span class="ltx_bibblock">
A. Kurakin, I. J. Goodfellow, and S. Bengio, “Adversarial examples in the physical world,” in <em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">Artificial intelligence safety and security</em>, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chollet [2019]</span>
<span class="ltx_bibblock">
F. Chollet, “The abstraction and reasoning corpus (arc),” 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lab42 Global [2024]</span>
<span class="ltx_bibblock">
Lab42 Global, “The abstraction and reasoning corpus (arc),” <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://lab42.global/arc/</span>, 2024, accessed: 2024-02-20.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tam et al. [2008]</span>
<span class="ltx_bibblock">
J. Tam, J. Simsa, S. Hyde, and L. Ahn, “Breaking audio captchas,” in <em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">Advances in Neural Information Processing Systems</em>, D. Koller, D. Schuurmans, Y. Bengio, and L. Bottou, Eds., 2008.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cortes and Vapnik [1995]</span>
<span class="ltx_bibblock">
C. Cortes and V. Vapnik, “Support-vector networks,” <em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">Machine learning</em>, vol. 20, pp. 273–297, 1995.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fix and Hodges [1989]</span>
<span class="ltx_bibblock">
E. Fix and J. L. Hodges, “Discriminatory analysis. nonparametric discrimination: Consistency properties,” <em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">International Statistical Review/Revue Internationale de Statistique</em>, vol. 57, no. 3, pp. 238–247, 1989.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Freund and Schapire [1995]</span>
<span class="ltx_bibblock">
Y. Freund and R. E. Schapire, “A desicion-theoretic generalization of on-line learning and an application to boosting,” in <em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">European conference on computational learning theory</em>.   Springer, 1995, pp. 23–37.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mandourah [2024]</span>
<span class="ltx_bibblock">
A. Mandourah, “reCAPTCHA Dataset,” <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://github.com/ajmandourah/recaptcha-dataset</span>, 2024.

</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Fri Sep 13 13:39:37 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
