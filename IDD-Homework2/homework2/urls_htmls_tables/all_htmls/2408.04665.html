<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations</title>
<!--Generated on Tue Aug  6 14:43:34 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2408.04665v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S1" title="In LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S2" title="In LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Results</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S2.SS1" title="In 2 Results ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Human-AI Joint Data Curation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S2.SS2" title="In 2 Results ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Few-Shot Large Language Model with Material Knowledge</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S2.SS3" title="In 2 Results ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Optimization for High-Throughput MOFs Synthesis Extraction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S2.SS4" title="In 2 Results ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.4 </span>MOFs Structure Inference</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S3" title="In LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Methods</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S3.SS1" title="In 3 Methods ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Synthesis paragraph detection</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S3.SS2" title="In 3 Methods ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Few-Shot RAG Algorithms</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S4" title="In LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S5" title="In LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Appendix</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S5.SS1" title="In 5 Appendix ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>MOFs Data</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S5.SS2" title="In 5 Appendix ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Annotation Procedure for Synthesis Paragraphs and Synthesis Conditions</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S5.SS3" title="In 5 Appendix ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3 </span>Post-processing of Synthesis Conditions</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S5.SS3.SSS1" title="In 5.3 Post-processing of Synthesis Conditions ‚Ä£ 5 Appendix ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3.1 </span>Data Cleansing on Textual Conditions</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S5.SS3.SSS2" title="In 5.3 Post-processing of Synthesis Conditions ‚Ä£ 5 Appendix ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3.2 </span>Standardization of Numeric Conditions on Time and Temperature</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S5.SS3.SSS3" title="In 5.3 Post-processing of Synthesis Conditions ‚Ä£ 5 Appendix ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3.3 </span>Data Filtering by Synthesis Condition Distributions</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S5.SS3.SSS4" title="In 5.3 Post-processing of Synthesis Conditions ‚Ä£ 5 Appendix ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3.4 </span>Feature Embedding for Metal, Organic Linker, and Solvent Data</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S5.SS4" title="In 5 Appendix ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.4 </span>Visual MOFs Synthesis Condition Extraction Engine and Database</span></a></li>
</ol>
</li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Lei Shi
</span><span class="ltx_author_notes">Lei Shi (shijim@gmail.com) and Zhimeng Liu contribute equally in this work. Yue Zhang (yue.zhang@wias.org.cn) and Ge Wang (gewang@ustb.edu.cn) are corresponding authors.
<span class="ltx_contact ltx_role_affiliation">Beihang University
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Zhimeng Liu
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">University of Science and Technology Beijing
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yi Yang
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Beihang University
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Weize Wu
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Beihang University
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yuyang Zhang
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Beihang University
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Hongbo Zhang
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Westlake University
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jing Lin
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">University of Science and Technology Beijing
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Siyu Wu
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Beihang University
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Zihan Chen
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Beihang University
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Ruiming Li
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Beihang University
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Nan Wang
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Beihang University
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Zipeng Liu
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Beihang University
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Huobin Tan
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Beihang University
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Hongyi Gao
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">University of Science and Technology Beijing
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yue Zhang
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Westlake University
</span>
<span class="ltx_contact ltx_role_affiliation">
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Ge Wang
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">University of Science and Technology Beijing
</span>
<span class="ltx_contact ltx_role_affiliation">
</span></span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id1.1">The extraction of Metal-Organic Frameworks (MOFs) synthesis conditions from literature text has been challenging but crucial for the logical design of new MOFs with desirable functionality. The recent advent of large language models (LLMs) provides disruptively new solution to this long-standing problem and latest researches have reported over 90% F1 in extracting correct conditions from MOFs literature. We argue in this paper that most existing synthesis extraction practices with LLMs stay with the primitive zero-shot learning, which could lead to downgraded extraction and application performance due to the lack of specialized knowledge. This work pioneers and optimizes the few-shot in-context learning paradigm for LLM extraction of material synthesis conditions. First, we propose a human-AI joint data curation process to secure high-quality ground-truth demonstrations for few-shot learning. Second, we apply a BM25 algorithm based on the retrieval-augmented generation (RAG) technique to adaptively select few-shot demonstrations for each MOF‚Äôs extraction. Over a dataset randomly sampled from 84,898 well-defined MOFs, the proposed few-shot method achieves much higher average F1 performance (0.93 vs. 0.81, +14.8%) than the native zero-shot LLM using the same GPT-4 model, under fully automatic evaluation that are more objective than the previous human evaluation. The proposed method is further validated through real-world material experiments: compared with the baseline zero-shot LLM, the proposed few-shot approach increases the MOFs structural inference performance (<math alttext="R^{2}" class="ltx_Math" display="inline" id="id1.1.m1.1"><semantics id="id1.1.m1.1a"><msup id="id1.1.m1.1.1" xref="id1.1.m1.1.1.cmml"><mi id="id1.1.m1.1.1.2" xref="id1.1.m1.1.1.2.cmml">R</mi><mn id="id1.1.m1.1.1.3" xref="id1.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="id1.1.m1.1b"><apply id="id1.1.m1.1.1.cmml" xref="id1.1.m1.1.1"><csymbol cd="ambiguous" id="id1.1.m1.1.1.1.cmml" xref="id1.1.m1.1.1">superscript</csymbol><ci id="id1.1.m1.1.1.2.cmml" xref="id1.1.m1.1.1.2">ùëÖ</ci><cn id="id1.1.m1.1.1.3.cmml" type="integer" xref="id1.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id1.1.m1.1c">R^{2}</annotation><annotation encoding="application/x-llamapun" id="id1.1.m1.1d">italic_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math>) by 29.4% in average.</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Metal-Organic Frameworks (MOFs), a class of high performance porous material, have been widely applied to catalysis, gas storage, and groundwater remediation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#bib.bib5" title="">5</a>]</cite> for its prestige in structural tunability and functional versatility <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#bib.bib2" title="">2</a>]</cite>. These advantages are deeply rooted in the flexible yet logical synthesis configuration of MOFs. Herein, precise and comprehensive knowledge of MOFs synthesis conditions becomes extremely important to fully understand its structural mechanism and discover new MOFs or sub-types, posing a fundamental challenge to the whole discipline of MOFs and reticular chemistry <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#bib.bib23" title="">23</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Currently, there have been 100k+ MOFs successfully synthesized in the laboratory. Their detailed synthesis conditions are often recorded by academic literature in various textual or tabular formats. Machine learning methods, in particular, text mining algorithms, are normally applied to the literature text to automatically extract synthesis conditions. However, the complexity and volatility of free text limits the accuracy of synthesis condition extraction <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#bib.bib13" title="">13</a>]</cite>, which could jeopardize the effectiveness of downstream material applications over extracted synthesis data.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">The emergence of large language models (LLMs) to some extent resolves the problem of synthesis condition extraction from disparate forms of scientific texts, due to their well-known expertise in the whole-spectrum of text mining tasks <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#bib.bib3" title="">3</a>]</cite>. Recently, Zheng et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#bib.bib24" title="">24</a>]</cite>, Dagdelen et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#bib.bib7" title="">7</a>]</cite>, Polak and Morgan <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#bib.bib16" title="">16</a>]</cite> have applied zero-shot or fine-tuned LLMs to extract synthesis conditions from experimental MOFs literature. They reported extraction performance of close to 0.9 in F1 metric, but mostly over small datasets and evaluated by subjective evaluations. It should be pointed out that the baseline zero-shot LLMs are notorious for their poor performance on sparse scenarios like MOFs synthesis, which are infrequently covered by the general-purpose LLM training data <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#bib.bib6" title="">6</a>]</cite>. Therefore, evaluating the MOFs condition extraction performance with large-scale, real-life datasets become crucial for improving both the quantity and quality of MOFs synthesis knowledgebase. In addition, guided material experiments over extracted synthesis conditions, which are rarely conducted in previous works, should also be an important norm to evaluate the effectiveness of targeted synthesis condition extraction task.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">In this work, we set out to overcome the notable limitations when applying primitive zero-shot LLMs to the problem of MOFs synthesis condition extraction from scientific texts. The main theme of this paper is to introduce the few-shot in-context learning paradigm as the standard approach to augment general-purpose LLMs on the material synthesis condition extraction problem. As shown by our experiment results of Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S1.F1" title="Figure 1 ‚Ä£ 1 Introduction ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_tag">1</span></a>, in a dataset randomly sampled from 84,898 well-defined MOFs, the proposed few-shot method achieves much higher average F1 performance (0.93 vs. 0.81, +14.8%) than the native zero-shot LLMs, both using the state-of-the-art GPT-4 Turbo model<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">‚Ä†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">‚Ä†</sup><span class="ltx_tag ltx_tag_note">‚Ä†</span>The latest GPT-4v model has enhanced video and image analysis capability, but not for text analysis.</span></span></span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#bib.bib1" title="">1</a>]</cite>, as shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S1.F1" title="Figure 1 ‚Ä£ 1 Introduction ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">Nevertheless, deploying few-shot LLMs to solve the current problem still faces multiple nontrivial challenges. First, the superiority of few-shot LLMs depends on the data quality of their ground-truth demonstrations. In the scenario of MOFs synthesis extraction, obtaining ground-truth textual conditions scattered in scientific literature in numerous formats remains a daunting task. It would be extremely costly to apply traditional human annotation approach given that a change of material would require a totally new demonstration dataset. Second, the quantity of ground-truth demonstrations selected for each LLM extraction is also critical as high-performance LLMs are mostly commercial and charged by input size. For example, the fine-tuning technology is known to greatly improve the LLM performance <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#bib.bib7" title="">7</a>]</cite>, but will normally require hundreds of examples and a locally-stored large set of model weights. The application overheads to new synthesis extraction scenarios are quite high, thus reducing the adaptability of fine-tuning methods. In our case, minimizing the number of few-shot demonstrations would require an elaborate algorithm to select the demonstrations adaptively for each MOF‚Äôs raw synthesis text.</p>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">In this paper, we introduce two new methods to resolve the above challenges. First, on the preparation of ground-truth demonstrations, to our surprise, human annotation and AI annotation show complementary advantages, not only in the annotation cost, but also in their output data quality. We then propose a human-AI joint data curation process, which enjoys the best of both worlds and offers the highest data quality in ground-truth demonstrations produced. Second, based on the popular retrieval-augmented generation (RAG) technique, we propose to apply the BM25 algorithm to adaptively select the best combination of few-shot demonstrations for each MOF‚Äôs synthesis extraction, whose performance significantly outruns the baseline random selection method. Our experiment results also suggest the most appropriate number of demonstrations for the trade-off between performance and cost. It is shown that a small overhead of 4-shots could already achieve the optimal performance, contrasting to tens to a hundred shots in other domains. In addition, we study the utility of different kinds of knowledge on our task when incorporated by LLM: the background knowledge on retrieved synthesis conditions, their application constraints on the numerical/textual format, and the few-shot demonstrations. Notably, the few-shot examples are shown to be the most critical. To our knowledge, we are the first to apply and optimize few-shot in-context learning LLM methods for the material synthesis condition extraction problem from scientific text.</p>
</div>
<figure class="ltx_figure" id="S1.F1">
<p class="ltx_p ltx_align_center" id="S1.F1.1"><span class="ltx_text" id="S1.F1.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="523" id="S1.F1.1.1.g1" src="x1.png" width="692"/></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Key indicators (F1, ACC, Precision, Recall) of the synthesis condition extraction performance on 123 MOFs with ground-truth data: (a) our 4-shot RAG algorithm; (b) zero-shot LLM as the baseline; (c) confusion matrix definition for evaluation.</figcaption>
</figure>
<div class="ltx_para" id="S1.p7">
<p class="ltx_p" id="S1.p7.3">Moreover, we have considered the scalability issue for high-throughput synthesis extraction. The additional overhead includes the labor cost to acquire external knowledge (e.g., expert annotations on the literature text), the financial cost to request LLM APIs, and the computational cost to potentially train in-house LLMs. For example, by the latest GPT-4 pricing model (10$ per 1M tokens), a single pass over all the 100k available MOFs synthesis literature (est. 10k words per literature) sums up to a non-negligible cost of 10k$, while performance tuning normally requires several passes. Three techniques adapted to large-scale material data are proposed. First, we learn an offline model to detect the most relevant synthesis paragraphs out of each literature, with an overall accuracy of 98.9%. In this way, the financial cost in using commercial LLMs is reduced by 94% (the average word count of a literature and its synthesis paragraphs are est. 15,000 and 900, respectively). The fully-tuned high-throughput synthesis extraction workflow now processes over 500 millions of scientific texts from all available MOFs literature within 7 hours. Second, we conduct experiments to quantify the size of demonstration pool as material data scales. Though it is shown that larger example pools almost always contribute to the performance, the margin quickly drops as more annotations are available. In the extreme, a pool of size <math alttext="K" class="ltx_Math" display="inline" id="S1.p7.1.m1.1"><semantics id="S1.p7.1.m1.1a"><mi id="S1.p7.1.m1.1.1" xref="S1.p7.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S1.p7.1.m1.1b"><ci id="S1.p7.1.m1.1.1.cmml" xref="S1.p7.1.m1.1.1">ùêæ</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p7.1.m1.1c">K</annotation><annotation encoding="application/x-llamapun" id="S1.p7.1.m1.1d">italic_K</annotation></semantics></math> for <math alttext="K" class="ltx_Math" display="inline" id="S1.p7.2.m2.1"><semantics id="S1.p7.2.m2.1a"><mi id="S1.p7.2.m2.1.1" xref="S1.p7.2.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S1.p7.2.m2.1b"><ci id="S1.p7.2.m2.1.1.cmml" xref="S1.p7.2.m2.1.1">ùêæ</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p7.2.m2.1c">K</annotation><annotation encoding="application/x-llamapun" id="S1.p7.2.m2.1d">italic_K</annotation></semantics></math>-shot (<math alttext="K&gt;1" class="ltx_Math" display="inline" id="S1.p7.3.m3.1"><semantics id="S1.p7.3.m3.1a"><mrow id="S1.p7.3.m3.1.1" xref="S1.p7.3.m3.1.1.cmml"><mi id="S1.p7.3.m3.1.1.2" xref="S1.p7.3.m3.1.1.2.cmml">K</mi><mo id="S1.p7.3.m3.1.1.1" xref="S1.p7.3.m3.1.1.1.cmml">&gt;</mo><mn id="S1.p7.3.m3.1.1.3" xref="S1.p7.3.m3.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S1.p7.3.m3.1b"><apply id="S1.p7.3.m3.1.1.cmml" xref="S1.p7.3.m3.1.1"><gt id="S1.p7.3.m3.1.1.1.cmml" xref="S1.p7.3.m3.1.1.1"></gt><ci id="S1.p7.3.m3.1.1.2.cmml" xref="S1.p7.3.m3.1.1.2">ùêæ</ci><cn id="S1.p7.3.m3.1.1.3.cmml" type="integer" xref="S1.p7.3.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p7.3.m3.1c">K&gt;1</annotation><annotation encoding="application/x-llamapun" id="S1.p7.3.m3.1d">italic_K &gt; 1</annotation></semantics></math>) LLMs is the most cost-effective. Third, we develop a LLM-based coreference resolution method to restore proxy words like ‚ÄúL‚Äù or ‚ÄúH2L‚Äù into its entirety. Though only a small portion of extracted synthesis condition on organic linker suffer from the use of proxy words, it mounts to a big number and affects the downstream material tasks on large-scale data. By applying our method, only 2.3% linkers remain unresolved.</p>
</div>
<div class="ltx_para" id="S1.p8">
<p class="ltx_p" id="S1.p8.1">To validate the importance of our proposal, we set up a real-world MOFs synthesis-structure inference experiment, in which the proposed few-shot LLM method is compared with the existing LLM application in material synthesis extraction scenario (e.g., zero-shot<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#bib.bib24" title="">24</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#bib.bib16" title="">16</a>]</cite>). On a set of 5,269 MOFs curated from the CSD database, we manage to build machine learning models to predict MOFs microstructure properties (framework density, cavity diameter, etc.) with the synthesis conditions obtained by LLM. By 6 off-the-shelf machine learning models, the inference performance (<math alttext="R^{2}" class="ltx_Math" display="inline" id="S1.p8.1.m1.1"><semantics id="S1.p8.1.m1.1a"><msup id="S1.p8.1.m1.1.1" xref="S1.p8.1.m1.1.1.cmml"><mi id="S1.p8.1.m1.1.1.2" xref="S1.p8.1.m1.1.1.2.cmml">R</mi><mn id="S1.p8.1.m1.1.1.3" xref="S1.p8.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S1.p8.1.m1.1b"><apply id="S1.p8.1.m1.1.1.cmml" xref="S1.p8.1.m1.1.1"><csymbol cd="ambiguous" id="S1.p8.1.m1.1.1.1.cmml" xref="S1.p8.1.m1.1.1">superscript</csymbol><ci id="S1.p8.1.m1.1.1.2.cmml" xref="S1.p8.1.m1.1.1.2">ùëÖ</ci><cn id="S1.p8.1.m1.1.1.3.cmml" type="integer" xref="S1.p8.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p8.1.m1.1c">R^{2}</annotation><annotation encoding="application/x-llamapun" id="S1.p8.1.m1.1d">italic_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math>) by the proposed few-shot method is consistently higher than the benchmark zero-shot approach, with an average improvement of 29.4%.</p>
</div>
<div class="ltx_para" id="S1.p9">
<p class="ltx_p" id="S1.p9.1">We also make available an online visual database showing the extracted synthesis conditions of all the 36,177 MOFs with literature available from the CSD database (see the supplemental material for more details).</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Results</h2>
<figure class="ltx_figure" id="S2.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="413" id="S2.F2.g1" src="x2.png" width="692"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>The overall pipeline of the few-shot in-context learning method for synthesis condition extraction from MOFs literature.</figcaption>
</figure>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">As shown in our technology pipeline of Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S2.F2" title="Figure 2 ‚Ä£ 2 Results ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_tag">2</span></a>, the MOFs literature dataset are first collected and pre-processed into compatible input format for LLMs (see Sec. <a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S5.SS1" title="5.1 MOFs Data ‚Ä£ 5 Appendix ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_tag">5.1</span></a> for details). The latest high-performance LLM (i.e., GPT-4) is employed to extract 10 essential conditions for the synthesis of each MOF: metal precursor name &amp; amount, organic linker name &amp; amount, solvent name &amp; amount, modulator name &amp; amount, and synthesis reaction duration &amp; temperature. The synthesis extraction result is first evaluated on their literal accuracy with respect to an expert-curated ground-truth dataset, and then tested on the real-world scenarios of material structure inference and design. On the randomly sampled 123 MOFs synthesis literature from all the 36177 MOFs, the extraction of 1230 synthesis conditions using the proposed few-shot LLM model achieves a best average F1 metric of 0.93 (ACC = 0.90), using a few-shot demonstration of only 4 examples. The full performance result is illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S1.F1" title="Figure 1 ‚Ä£ 1 Introduction ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_tag">1</span></a>(a), in comparison to the baseline zero-shot approach with an average F1 of 0.81 (ACC = 0.77) in Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S1.F1" title="Figure 1 ‚Ä£ 1 Introduction ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_tag">1</span></a>(b). The dataset statistics is listed in Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S2.F4" title="Figure 4 ‚Ä£ 2.2 Few-Shot Large Language Model with Material Knowledge ‚Ä£ 2 Results ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Human-AI Joint Data Curation</h3>
<figure class="ltx_figure" id="S2.F3">
<p class="ltx_p ltx_align_center" id="S2.F3.1"><span class="ltx_text" id="S2.F3.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="228" id="S2.F3.1.1.g1" src="x3.png" width="692"/></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>The human-AI reflection procedure to improve few-shot examples.</figcaption>
</figure>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">To introduce the few-shot LLM method, a prerequisite is to obtain a high-quality demonstration pool on the synthesis condition extraction task, i.e., the ground-truth annotations. Traditionally, human annotations are the sole means to collect these examples for the few-shot learning. In this work, we also start with a standard annotation protocol which includes three steps: 1) <em class="ltx_emph ltx_font_italic" id="S2.SS1.p1.1.1">pilot annotations</em> on 20 typical literature by the leading experts to reach consensus on the rigorous format of MOFs synthesis conditions; 2) <em class="ltx_emph ltx_font_italic" id="S2.SS1.p1.1.2">batch annotations</em> conducted by 6 experts over 180 MOFs synthesis paragraphs randomly chosen from the entire dataset. Each paragraph is double annotated by two experts to ensure reliability; 3) <em class="ltx_emph ltx_font_italic" id="S2.SS1.p1.1.3">finalized annotations</em> by only keeping the MOFs synthesis conditions that are agreeing between the two experts, while removing annotated paragraphs that are inappropriate as examples (e.g., having more than one suite of MOFs synthesis conditions in the same paragraph). Eventually, we obtain a ground-truth human annotation dataset composed of 147 suites of MOFs synthesis conditions. The full detail of our annotation approach and an online software to assist the process is described in Sec. <a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S5.SS2" title="5.2 Annotation Procedure for Synthesis Paragraphs and Synthesis Conditions ‚Ä£ 5 Appendix ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_tag">5.2</span></a>.</p>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.2">Using the human annotations developed above as examples, the performance of few-shot LLM models is depicted by the solid orange+triangle lines of Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S2.F6" title="Figure 6 ‚Ä£ 2.2 Few-Shot Large Language Model with Material Knowledge ‚Ä£ 2 Results ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_tag">6</span></a>. The average F1 metric rises from 0.81 (zero-shot) to the peak of 0.86 (<math alttext="K=2" class="ltx_Math" display="inline" id="S2.SS1.p2.1.m1.1"><semantics id="S2.SS1.p2.1.m1.1a"><mrow id="S2.SS1.p2.1.m1.1.1" xref="S2.SS1.p2.1.m1.1.1.cmml"><mi id="S2.SS1.p2.1.m1.1.1.2" xref="S2.SS1.p2.1.m1.1.1.2.cmml">K</mi><mo id="S2.SS1.p2.1.m1.1.1.1" xref="S2.SS1.p2.1.m1.1.1.1.cmml">=</mo><mn id="S2.SS1.p2.1.m1.1.1.3" xref="S2.SS1.p2.1.m1.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.1.m1.1b"><apply id="S2.SS1.p2.1.m1.1.1.cmml" xref="S2.SS1.p2.1.m1.1.1"><eq id="S2.SS1.p2.1.m1.1.1.1.cmml" xref="S2.SS1.p2.1.m1.1.1.1"></eq><ci id="S2.SS1.p2.1.m1.1.1.2.cmml" xref="S2.SS1.p2.1.m1.1.1.2">ùêæ</ci><cn id="S2.SS1.p2.1.m1.1.1.3.cmml" type="integer" xref="S2.SS1.p2.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.1.m1.1c">K=2</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p2.1.m1.1d">italic_K = 2</annotation></semantics></math>), and does not increase any more. The random example selection shown by the dotted orange line oscillates slightly above the zero-shot performance. Both algorithms over purely human annotation perform much worse than the new annotation approach described later (an average F1 as high as 0.93, solid blue line). It is hypothesized that the key limitation lies in the low data quality of few-shot examples. For more information, we experiment with two other ways to generate annotated demonstrations. In the first trial, LLM is initially applied in a zero-shot mode to extract all synthesis conditions from the input paragraph. The 1st-round LLM output is then used as the data annotation (examples) in the 2nd-round few-shot LLM in-context learning. The green+diamond lines in Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S2.F6" title="Figure 6 ‚Ä£ 2.2 Few-Shot Large Language Model with Material Knowledge ‚Ä£ 2 Results ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_tag">6</span></a> indicate that the performance with this AI-based annotation is still constantly below the best approach. In the final trial, we input synthesis paragraph without annotation as the examples (i.e., the lowest data quality). As expected, the red+square performance charts in Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S2.F6" title="Figure 6 ‚Ä£ 2.2 Few-Shot Large Language Model with Material Knowledge ‚Ä£ 2 Results ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_tag">6</span></a> achieves the lowest F1 and ACC. As more raw paragraphs are used, i.e., increasing <math alttext="K" class="ltx_Math" display="inline" id="S2.SS1.p2.2.m2.1"><semantics id="S2.SS1.p2.2.m2.1a"><mi id="S2.SS1.p2.2.m2.1.1" xref="S2.SS1.p2.2.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.2.m2.1b"><ci id="S2.SS1.p2.2.m2.1.1.cmml" xref="S2.SS1.p2.2.m2.1.1">ùêæ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.2.m2.1c">K</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p2.2.m2.1d">italic_K</annotation></semantics></math>, both metrics drop. The explanation might be that more information without ground-truth distracts the LLM, rather than coaches it.</p>
</div>
<div class="ltx_para" id="S2.SS1.p3">
<p class="ltx_p" id="S2.SS1.p3.1">The above results indicate that neither human annotations nor purely AI-generated examples achieve optimal data quality for LLM few-shot learning. To delve deeper into the issue, several leading MOF experts were consulted to evaluate all errors produced by the few-shot LLM method when using human annotations as the sole examples and ground-truths. Out of 261 potential errors, 103 LLM outputs (39.5%) were identified as correct, 38 (14.6%) had certain issues but contributed to refining the corresponding ground-truth, and only 120 (45.9%) were true errors. The experts then compiled a revised set of ground-truth annotations, including the synthesis conditions for 123 individual MOFs. The remaining 23 annotated conditions were deemed inappropriate because they either involved chiral MOFs with duplicate synthesis conditions and paragraphs or contained multiple MOF synthesis processes within a single paragraph. Although our technical framework can deal with the case of having multiple MOFs in a single paragraph, we chose the paragraphs describing the synthesis of only one MOF for more precise demonstrations.</p>
</div>
<div class="ltx_para" id="S2.SS1.p4">
<p class="ltx_p" id="S2.SS1.p4.1">With this empirical experience, we propose a human-AI joint data curation process for the data quality optimization of ground-truth demonstrations in LLM-based few-shot learning paradigm. As shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S2.F3" title="Figure 3 ‚Ä£ 2.1 Human-AI Joint Data Curation ‚Ä£ 2 Results ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_tag">3</span></a>(a), raw synthesis paragraphs are first processed by LLM in a zero-shot mode. Human experts then work on the initial AI annotation to achieve a best-effort human annotation (Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S2.F3" title="Figure 3 ‚Ä£ 2.1 Human-AI Joint Data Curation ‚Ä£ 2 Results ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_tag">3</span></a>(b)), which is the first round of reflection. After that, these human annotations are used as demonstrations in a LLM-based few-shot synthesis condition extraction Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S2.F3" title="Figure 3 ‚Ä£ 2.1 Human-AI Joint Data Curation ‚Ä£ 2 Results ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_tag">3</span></a>(c), which is the second round of reflection and generates few-shot AI annotations. Lastly, human experts combines human annotations and few-shot AI annotations into the human-AI joint annotation (Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S2.F3" title="Figure 3 ‚Ä£ 2.1 Human-AI Joint Data Curation ‚Ä£ 2 Results ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_tag">3</span></a>(d)), in the final round of reflection. We apply the few-shot LLM model over the final demonstrations with the highest-level of data quality. The best performance (F1=0.93 and ACC=0.9) is achieved at the point of most appropriate few-shot quantity (<math alttext="K=4" class="ltx_Math" display="inline" id="S2.SS1.p4.1.m1.1"><semantics id="S2.SS1.p4.1.m1.1a"><mrow id="S2.SS1.p4.1.m1.1.1" xref="S2.SS1.p4.1.m1.1.1.cmml"><mi id="S2.SS1.p4.1.m1.1.1.2" xref="S2.SS1.p4.1.m1.1.1.2.cmml">K</mi><mo id="S2.SS1.p4.1.m1.1.1.1" xref="S2.SS1.p4.1.m1.1.1.1.cmml">=</mo><mn id="S2.SS1.p4.1.m1.1.1.3" xref="S2.SS1.p4.1.m1.1.1.3.cmml">4</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p4.1.m1.1b"><apply id="S2.SS1.p4.1.m1.1.1.cmml" xref="S2.SS1.p4.1.m1.1.1"><eq id="S2.SS1.p4.1.m1.1.1.1.cmml" xref="S2.SS1.p4.1.m1.1.1.1"></eq><ci id="S2.SS1.p4.1.m1.1.1.2.cmml" xref="S2.SS1.p4.1.m1.1.1.2">ùêæ</ci><cn id="S2.SS1.p4.1.m1.1.1.3.cmml" type="integer" xref="S2.SS1.p4.1.m1.1.1.3">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p4.1.m1.1c">K=4</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p4.1.m1.1d">italic_K = 4</annotation></semantics></math>, as shown by the solid blue lines in Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S2.F6" title="Figure 6 ‚Ä£ 2.2 Few-Shot Large Language Model with Material Knowledge ‚Ä£ 2 Results ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_tag">6</span></a>.</p>
</div>
<div class="ltx_para" id="S2.SS1.p5">
<p class="ltx_p" id="S2.SS1.p5.1">We ascribe the superiority of human-AI joint data curation to three reasons, all due to the complementary nature of human expertise and AI‚Äôs capacity. First, though human are excellent in flexible usage of material knowledge, they often fail to strictly follow pre-defined annotation rules. For example, to standardize the solvent condition, it is required to leave out all modifiers of a common solvent. Human annotators sometimes extract ‚Äúhot water‚Äù instead of ‚Äúwater‚Äù, because his/her focus is on the knowledge extraction and neglects the rules. Human are poor multi-objective task executors compared with AI, who will not introduce error if only these rules are provided in either background prompt or examples. Second, human often suffer from fatigue issue when working with a large set of annotation tasks as ours. Random errors are then generated, i.e., missing or adding a few characters/words. Though redundant annotation by more than one expert can eliminate these random errors, it is at the cost of excluding many useful annotations when the redundant outputs are different. Here AI is applied to alleviate this issue: an initial zero-shot LLM annotation reduces human efforts, their fatigue, and the resulting random errors in the first round of reflection; the few-shot LLM output also works as a caliber to help resolve differences between redundant human annotations in the second round of reflection.</p>
</div>
<div class="ltx_para" id="S2.SS1.p6">
<p class="ltx_p" id="S2.SS1.p6.1">Finally, on the other hand, the current general-purpose LLM alone is not the ultimate solution to our task. According to the medium performance of zero-shot LLM, it lacks specialized knowledge on MOFs synthesis conditions. Though the few-shot demonstrations mitigate this deficiency through in-context learning, the scalability issue makes it very hard to achieve a close to 100% accuracy. For example, retrieving one synthesis condition from a paragraph may require several demonstrations to cover all the lexical and syntactic pattern around the target condition. Retrieving all 10 conditions then demands tens of examples, inducing a cost magnitudes more than the current setting of <math alttext="K=4" class="ltx_Math" display="inline" id="S2.SS1.p6.1.m1.1"><semantics id="S2.SS1.p6.1.m1.1a"><mrow id="S2.SS1.p6.1.m1.1.1" xref="S2.SS1.p6.1.m1.1.1.cmml"><mi id="S2.SS1.p6.1.m1.1.1.2" xref="S2.SS1.p6.1.m1.1.1.2.cmml">K</mi><mo id="S2.SS1.p6.1.m1.1.1.1" xref="S2.SS1.p6.1.m1.1.1.1.cmml">=</mo><mn id="S2.SS1.p6.1.m1.1.1.3" xref="S2.SS1.p6.1.m1.1.1.3.cmml">4</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p6.1.m1.1b"><apply id="S2.SS1.p6.1.m1.1.1.cmml" xref="S2.SS1.p6.1.m1.1.1"><eq id="S2.SS1.p6.1.m1.1.1.1.cmml" xref="S2.SS1.p6.1.m1.1.1.1"></eq><ci id="S2.SS1.p6.1.m1.1.1.2.cmml" xref="S2.SS1.p6.1.m1.1.1.2">ùêæ</ci><cn id="S2.SS1.p6.1.m1.1.1.3.cmml" type="integer" xref="S2.SS1.p6.1.m1.1.1.3">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p6.1.m1.1c">K=4</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p6.1.m1.1d">italic_K = 4</annotation></semantics></math>. Customized few-shot algorithms will be needed to achieve such goal. Therefore, in the final round of reflection, human experts are hired to generate the best-quality ground-truth demonstrations over existing human-AI efforts.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Few-Shot Large Language Model with Material Knowledge</h3>
<figure class="ltx_figure" id="S2.F4">
<p class="ltx_p ltx_align_center" id="S2.F4.1"><span class="ltx_text" id="S2.F4.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="581" id="S2.F4.1.1.g1" src="x4.png" width="692"/></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Optimization of general-purpose LLMs for the MOFs synthesis extraction: few-shot in-context learning and RAG.</figcaption>
</figure>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1"><span class="ltx_text ltx_font_bold" id="S2.SS2.p1.1.1">Few-shot in-context learning with random examples</span></p>
</div>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1">In the research area of natural language processing (NLP), few-shot in-context learning (FS-ICL) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#bib.bib6" title="">6</a>]</cite> generally refers to one typical learning paradigm to adapt the task-agnostic language models to various downstream tasks while achieving optimized performance on each task. In more detail, FS-ICL takes a few prompted examples as input (known as shots), each composed of a context and a labeled completion, in addition to background prompts such as task description (Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S2.F4" title="Figure 4 ‚Ä£ 2.2 Few-Shot Large Language Model with Material Knowledge ‚Ä£ 2 Results ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_tag">4</span></a>). In the task of MOFs synthesis extraction for instance, a context refers to a paragraph containing all the synthesis conditions of a MOF and the labeled completion refers to the ground-truth synthesis conditions annotated and curated by human experts in our work. The top-right part of Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S2.F4" title="Figure 4 ‚Ä£ 2.2 Few-Shot Large Language Model with Material Knowledge ‚Ä£ 2 Results ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_tag">4</span></a> gives an example of the labeled completion. FS-ICL is often discussed in comparison to the fine-tuning (FT) paradigm, which updates the pre-trained language models by incorporating a set of labeled examples via supervised learning. In both FS-ICL and FT, the final prediction is made by prompting a new context and asking the language model to complete it.</p>
</div>
<div class="ltx_para" id="S2.SS2.p3">
<p class="ltx_p" id="S2.SS2.p3.1">The main advantage of FS-ICL vs. FT lies in its versatility to work on many tasks (e.g., synthesis extraction of various materials) without the need to re-train the model, as shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S2.F4" title="Figure 4 ‚Ä£ 2.2 Few-Shot Large Language Model with Material Knowledge ‚Ä£ 2 Results ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_tag">4</span></a>. In comparison, FT requires gradient-based training for each new task to update the model weights and a considerable number of labeled examples for supervision. Though the latest technology of few-shot fine-tuning (FS-FT) has reduced the requirement of examples to the same level of FS-ICL <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#bib.bib11" title="">11</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#bib.bib15" title="">15</a>]</cite>, training and maintaining a small fraction of updated language model weights can still be costly for lightweight LLM usage scenarios such as synthesis extraction in this work. FT also suffers from spurious correlations due to the overfitting effect <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#bib.bib15" title="">15</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S2.SS2.p4">
<p class="ltx_p" id="S2.SS2.p4.4">Despite the superiority of FS-ICT in our scenario, the paradigm also draws concerns due to its disadvantages. First, the inclusion of few-shots in the prompt brings additional computation cost to the language model. In mainstream implementations, the number of shots, denoted as <math alttext="K" class="ltx_Math" display="inline" id="S2.SS2.p4.1.m1.1"><semantics id="S2.SS2.p4.1.m1.1a"><mi id="S2.SS2.p4.1.m1.1.1" xref="S2.SS2.p4.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p4.1.m1.1b"><ci id="S2.SS2.p4.1.m1.1.1.cmml" xref="S2.SS2.p4.1.m1.1.1">ùêæ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p4.1.m1.1c">K</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p4.1.m1.1d">italic_K</annotation></semantics></math>, ranges from 10, 20 to 100 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#bib.bib6" title="">6</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#bib.bib15" title="">15</a>]</cite>. Yet, we will show in this work, for the task of MOFs synthesis extraction, the setting of <math alttext="K=4" class="ltx_Math" display="inline" id="S2.SS2.p4.2.m2.1"><semantics id="S2.SS2.p4.2.m2.1a"><mrow id="S2.SS2.p4.2.m2.1.1" xref="S2.SS2.p4.2.m2.1.1.cmml"><mi id="S2.SS2.p4.2.m2.1.1.2" xref="S2.SS2.p4.2.m2.1.1.2.cmml">K</mi><mo id="S2.SS2.p4.2.m2.1.1.1" xref="S2.SS2.p4.2.m2.1.1.1.cmml">=</mo><mn id="S2.SS2.p4.2.m2.1.1.3" xref="S2.SS2.p4.2.m2.1.1.3.cmml">4</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p4.2.m2.1b"><apply id="S2.SS2.p4.2.m2.1.1.cmml" xref="S2.SS2.p4.2.m2.1.1"><eq id="S2.SS2.p4.2.m2.1.1.1.cmml" xref="S2.SS2.p4.2.m2.1.1.1"></eq><ci id="S2.SS2.p4.2.m2.1.1.2.cmml" xref="S2.SS2.p4.2.m2.1.1.2">ùêæ</ci><cn id="S2.SS2.p4.2.m2.1.1.3.cmml" type="integer" xref="S2.SS2.p4.2.m2.1.1.3">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p4.2.m2.1c">K=4</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p4.2.m2.1d">italic_K = 4</annotation></semantics></math> or even <math alttext="K=1" class="ltx_Math" display="inline" id="S2.SS2.p4.3.m3.1"><semantics id="S2.SS2.p4.3.m3.1a"><mrow id="S2.SS2.p4.3.m3.1.1" xref="S2.SS2.p4.3.m3.1.1.cmml"><mi id="S2.SS2.p4.3.m3.1.1.2" xref="S2.SS2.p4.3.m3.1.1.2.cmml">K</mi><mo id="S2.SS2.p4.3.m3.1.1.1" xref="S2.SS2.p4.3.m3.1.1.1.cmml">=</mo><mn id="S2.SS2.p4.3.m3.1.1.3" xref="S2.SS2.p4.3.m3.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p4.3.m3.1b"><apply id="S2.SS2.p4.3.m3.1.1.cmml" xref="S2.SS2.p4.3.m3.1.1"><eq id="S2.SS2.p4.3.m3.1.1.1.cmml" xref="S2.SS2.p4.3.m3.1.1.1"></eq><ci id="S2.SS2.p4.3.m3.1.1.2.cmml" xref="S2.SS2.p4.3.m3.1.1.2">ùêæ</ci><cn id="S2.SS2.p4.3.m3.1.1.3.cmml" type="integer" xref="S2.SS2.p4.3.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p4.3.m3.1c">K=1</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p4.3.m3.1d">italic_K = 1</annotation></semantics></math> (known as one-shot) can significantly boost the performance over the setting of <math alttext="K=0" class="ltx_Math" display="inline" id="S2.SS2.p4.4.m4.1"><semantics id="S2.SS2.p4.4.m4.1a"><mrow id="S2.SS2.p4.4.m4.1.1" xref="S2.SS2.p4.4.m4.1.1.cmml"><mi id="S2.SS2.p4.4.m4.1.1.2" xref="S2.SS2.p4.4.m4.1.1.2.cmml">K</mi><mo id="S2.SS2.p4.4.m4.1.1.1" xref="S2.SS2.p4.4.m4.1.1.1.cmml">=</mo><mn id="S2.SS2.p4.4.m4.1.1.3" xref="S2.SS2.p4.4.m4.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p4.4.m4.1b"><apply id="S2.SS2.p4.4.m4.1.1.cmml" xref="S2.SS2.p4.4.m4.1.1"><eq id="S2.SS2.p4.4.m4.1.1.1.cmml" xref="S2.SS2.p4.4.m4.1.1.1"></eq><ci id="S2.SS2.p4.4.m4.1.1.2.cmml" xref="S2.SS2.p4.4.m4.1.1.2">ùêæ</ci><cn id="S2.SS2.p4.4.m4.1.1.3.cmml" type="integer" xref="S2.SS2.p4.4.m4.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p4.4.m4.1c">K=0</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p4.4.m4.1d">italic_K = 0</annotation></semantics></math> (known as zero-shot). Second, in previous studies, the format of prompts in FS-ICT (e.g., the wording and ordering of examples) can have unpredictable influence on the final performance. In some cases, FS-ICL even performs well on incorrect examples. We have investigate these issues and demonstrate that our approach can achieve very low variance by fixing the prompt format and example orders according to the algorithm. The data quality of few-shot examples in our task is also shown to be an important factor to the synthesis extraction performance.</p>
</div>
<div class="ltx_para" id="S2.SS2.p5">
<p class="ltx_p" id="S2.SS2.p5.1">It is also previously believed that FT can achieve better performance than FS-ICT, but the latest study reveals that under the same size of shots, both paradigms obtain similar performance and exhibit large variance depending on the task specification <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#bib.bib15" title="">15</a>]</cite>. In our scenario, FS-ICT reaches an excellent performance of F1<math alttext="&gt;" class="ltx_Math" display="inline" id="S2.SS2.p5.1.m1.1"><semantics id="S2.SS2.p5.1.m1.1a"><mo id="S2.SS2.p5.1.m1.1.1" xref="S2.SS2.p5.1.m1.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S2.SS2.p5.1.m1.1b"><gt id="S2.SS2.p5.1.m1.1.1.cmml" xref="S2.SS2.p5.1.m1.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p5.1.m1.1c">&gt;</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p5.1.m1.1d">&gt;</annotation></semantics></math>0.9, which is enough for real-life deployment.</p>
</div>
<div class="ltx_para" id="S2.SS2.p6">
<p class="ltx_p" id="S2.SS2.p6.1"><span class="ltx_text ltx_font_bold" id="S2.SS2.p6.1.1">Using RAG to enhance few-shot data quantity and quality</span></p>
</div>
<figure class="ltx_figure" id="S2.F5">
<p class="ltx_p ltx_align_center" id="S2.F5.1"><span class="ltx_text" id="S2.F5.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="558" id="S2.F5.1.1.g1" src="x5.png" width="692"/></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Comparison of different RAG algorithms and their configurations.</figcaption>
</figure>
<figure class="ltx_figure" id="S2.F6">
<p class="ltx_p ltx_align_center" id="S2.F6.1"><span class="ltx_text" id="S2.F6.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="574" id="S2.F6.1.1.g1" src="x6.png" width="553"/></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>The impact of example data quality on extraction performance, with varying number of shots.</figcaption>
</figure>
<div class="ltx_para" id="S2.SS2.p7">
<p class="ltx_p" id="S2.SS2.p7.3">At the core of FS-ICL approach, we introduce the RAG algorithm which retrieves the aforementioned <math alttext="K" class="ltx_Math" display="inline" id="S2.SS2.p7.1.m1.1"><semantics id="S2.SS2.p7.1.m1.1a"><mi id="S2.SS2.p7.1.m1.1.1" xref="S2.SS2.p7.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p7.1.m1.1b"><ci id="S2.SS2.p7.1.m1.1.1.cmml" xref="S2.SS2.p7.1.m1.1.1">ùêæ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p7.1.m1.1c">K</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p7.1.m1.1d">italic_K</annotation></semantics></math> examples for each input context to augment the LLM and then generates the predicted completion (Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S2.F4" title="Figure 4 ‚Ä£ 2.2 Few-Shot Large Language Model with Material Knowledge ‚Ä£ 2 Results ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_tag">4</span></a>). Quite a few RAG algorithms have been proposed in the literature, with differences on how to compute the similarity between the input context and candidate examples. Sec. <a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S3.SS2" title="3.2 Few-Shot RAG Algorithms ‚Ä£ 3 Methods ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_tag">3.2</span></a> describes in more detail two major classes of these algorithms: term frequency statistics and semantic similarity. We have applied three mainstream algorithms: BM25 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#bib.bib18" title="">18</a>]</cite>, BERT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#bib.bib8" title="">8</a>]</cite>, and Sentence-BERT (SBERT) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#bib.bib17" title="">17</a>]</cite>, in a typical setting of <math alttext="K=4" class="ltx_Math" display="inline" id="S2.SS2.p7.2.m2.1"><semantics id="S2.SS2.p7.2.m2.1a"><mrow id="S2.SS2.p7.2.m2.1.1" xref="S2.SS2.p7.2.m2.1.1.cmml"><mi id="S2.SS2.p7.2.m2.1.1.2" xref="S2.SS2.p7.2.m2.1.1.2.cmml">K</mi><mo id="S2.SS2.p7.2.m2.1.1.1" xref="S2.SS2.p7.2.m2.1.1.1.cmml">=</mo><mn id="S2.SS2.p7.2.m2.1.1.3" xref="S2.SS2.p7.2.m2.1.1.3.cmml">4</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p7.2.m2.1b"><apply id="S2.SS2.p7.2.m2.1.1.cmml" xref="S2.SS2.p7.2.m2.1.1"><eq id="S2.SS2.p7.2.m2.1.1.1.cmml" xref="S2.SS2.p7.2.m2.1.1.1"></eq><ci id="S2.SS2.p7.2.m2.1.1.2.cmml" xref="S2.SS2.p7.2.m2.1.1.2">ùêæ</ci><cn id="S2.SS2.p7.2.m2.1.1.3.cmml" type="integer" xref="S2.SS2.p7.2.m2.1.1.3">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p7.2.m2.1c">K=4</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p7.2.m2.1d">italic_K = 4</annotation></semantics></math>. The test data is the 1230 ground-truth conditions out of 123 MOFs (synthesis paragraph). Note that in the experiment, when the RAG algorithm is applied to one synthesis paragraph, the same paragraph is excluded from the few-shot example selection for legality consideration. The average extraction performance in Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S2.F5" title="Figure 5 ‚Ä£ 2.2 Few-Shot Large Language Model with Material Knowledge ‚Ä£ 2 Results ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_tag">5</span></a>(a)(b) indicates that the BM25 algorithm achieves the best F1 (0.93) and ACC (0.90) in all the compared algorithms and the result is quite stable among 5 repeated runs (95% CI is 0.003 for F1). Notably, any of the tested algorithm is significantly better than a random selection of examples (<math alttext="p&lt;" class="ltx_Math" display="inline" id="S2.SS2.p7.3.m3.1"><semantics id="S2.SS2.p7.3.m3.1a"><mrow id="S2.SS2.p7.3.m3.1.1" xref="S2.SS2.p7.3.m3.1.1.cmml"><mi id="S2.SS2.p7.3.m3.1.1.2" xref="S2.SS2.p7.3.m3.1.1.2.cmml">p</mi><mo id="S2.SS2.p7.3.m3.1.1.1" xref="S2.SS2.p7.3.m3.1.1.1.cmml">&lt;</mo><mi id="S2.SS2.p7.3.m3.1.1.3" xref="S2.SS2.p7.3.m3.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p7.3.m3.1b"><apply id="S2.SS2.p7.3.m3.1.1.cmml" xref="S2.SS2.p7.3.m3.1.1"><lt id="S2.SS2.p7.3.m3.1.1.1.cmml" xref="S2.SS2.p7.3.m3.1.1.1"></lt><ci id="S2.SS2.p7.3.m3.1.1.2.cmml" xref="S2.SS2.p7.3.m3.1.1.2">ùëù</ci><csymbol cd="latexml" id="S2.SS2.p7.3.m3.1.1.3.cmml" xref="S2.SS2.p7.3.m3.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p7.3.m3.1c">p&lt;</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p7.3.m3.1d">italic_p &lt;</annotation></semantics></math>.001 in F1 comparison), showcasing the effectiveness of RAG mechanism. On the best BM25 algorithm, we further test the impact of few shots‚Äô input order as in the LLM prompt. As shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S2.F5" title="Figure 5 ‚Ä£ 2.2 Few-Shot Large Language Model with Material Knowledge ‚Ä£ 2 Results ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_tag">5</span></a>(c), the differences are not significant among most ordering strategies.</p>
</div>
<div class="ltx_para" id="S2.SS2.p8">
<p class="ltx_p" id="S2.SS2.p8.1">Here we note that the F1 and ACC (overall accuracy) metrics used follow the standard definition computed from TP (true positive), FP (false positive), TN (true negative), FN (false negative), throughout this work. The LLM output on each synthesis condition of a MOF will be classified into one of TP/FP/TN/FN by comparing with the predefined ground-truth annotation, as described in the confusion matrix of Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S1.F1" title="Figure 1 ‚Ä£ 1 Introduction ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_tag">1</span></a>(c). Note that our definition is different from the previous research in Zheng et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#bib.bib24" title="">24</a>]</cite> where the TP/FP/TN/FN classification is evaluated by human experts case by case. We argue that the subjective human evaluation may introduce bias while the fully objective classification will ensure a consistent format in retrieved synthesis conditions, which is beneficial for the follow-up material applications (see Sec. <a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S5.SS3" title="5.3 Post-processing of Synthesis Conditions ‚Ä£ 5 Appendix ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_tag">5.3</span></a> for more details).</p>
</div>
<div class="ltx_para" id="S2.SS2.p9">
<p class="ltx_p" id="S2.SS2.p9.6">A key parameter of the RAG algorithm lies in the number of example shots used in the LLM prompt, i.e., <math alttext="K" class="ltx_Math" display="inline" id="S2.SS2.p9.1.m1.1"><semantics id="S2.SS2.p9.1.m1.1a"><mi id="S2.SS2.p9.1.m1.1.1" xref="S2.SS2.p9.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p9.1.m1.1b"><ci id="S2.SS2.p9.1.m1.1.1.cmml" xref="S2.SS2.p9.1.m1.1.1">ùêæ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p9.1.m1.1c">K</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p9.1.m1.1d">italic_K</annotation></semantics></math>. While the original GPT-4 paper claims that a 3-shot approach could achieve considerable performance <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#bib.bib3" title="">3</a>]</cite>, field experiments will be needed in most applications to determine an appropriate choice. As shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S2.F6" title="Figure 6 ‚Ä£ 2.2 Few-Shot Large Language Model with Material Knowledge ‚Ä£ 2 Results ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_tag">6</span></a>, the solid blue lines with circle symbol give the performance variation with different <math alttext="K" class="ltx_Math" display="inline" id="S2.SS2.p9.2.m2.1"><semantics id="S2.SS2.p9.2.m2.1a"><mi id="S2.SS2.p9.2.m2.1.1" xref="S2.SS2.p9.2.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p9.2.m2.1b"><ci id="S2.SS2.p9.2.m2.1.1.cmml" xref="S2.SS2.p9.2.m2.1.1">ùêæ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p9.2.m2.1c">K</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p9.2.m2.1d">italic_K</annotation></semantics></math>s, using the best BM25 as RAG algorithm. Both F1 and ACC increase the most from zero-shot to one-shot, and continue to grow until <math alttext="K=4" class="ltx_Math" display="inline" id="S2.SS2.p9.3.m3.1"><semantics id="S2.SS2.p9.3.m3.1a"><mrow id="S2.SS2.p9.3.m3.1.1" xref="S2.SS2.p9.3.m3.1.1.cmml"><mi id="S2.SS2.p9.3.m3.1.1.2" xref="S2.SS2.p9.3.m3.1.1.2.cmml">K</mi><mo id="S2.SS2.p9.3.m3.1.1.1" xref="S2.SS2.p9.3.m3.1.1.1.cmml">=</mo><mn id="S2.SS2.p9.3.m3.1.1.3" xref="S2.SS2.p9.3.m3.1.1.3.cmml">4</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p9.3.m3.1b"><apply id="S2.SS2.p9.3.m3.1.1.cmml" xref="S2.SS2.p9.3.m3.1.1"><eq id="S2.SS2.p9.3.m3.1.1.1.cmml" xref="S2.SS2.p9.3.m3.1.1.1"></eq><ci id="S2.SS2.p9.3.m3.1.1.2.cmml" xref="S2.SS2.p9.3.m3.1.1.2">ùêæ</ci><cn id="S2.SS2.p9.3.m3.1.1.3.cmml" type="integer" xref="S2.SS2.p9.3.m3.1.1.3">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p9.3.m3.1c">K=4</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p9.3.m3.1d">italic_K = 4</annotation></semantics></math>. After this peak (<math alttext="F1=0.93" class="ltx_Math" display="inline" id="S2.SS2.p9.4.m4.1"><semantics id="S2.SS2.p9.4.m4.1a"><mrow id="S2.SS2.p9.4.m4.1.1" xref="S2.SS2.p9.4.m4.1.1.cmml"><mrow id="S2.SS2.p9.4.m4.1.1.2" xref="S2.SS2.p9.4.m4.1.1.2.cmml"><mi id="S2.SS2.p9.4.m4.1.1.2.2" xref="S2.SS2.p9.4.m4.1.1.2.2.cmml">F</mi><mo id="S2.SS2.p9.4.m4.1.1.2.1" xref="S2.SS2.p9.4.m4.1.1.2.1.cmml">‚Å¢</mo><mn id="S2.SS2.p9.4.m4.1.1.2.3" xref="S2.SS2.p9.4.m4.1.1.2.3.cmml">1</mn></mrow><mo id="S2.SS2.p9.4.m4.1.1.1" xref="S2.SS2.p9.4.m4.1.1.1.cmml">=</mo><mn id="S2.SS2.p9.4.m4.1.1.3" xref="S2.SS2.p9.4.m4.1.1.3.cmml">0.93</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p9.4.m4.1b"><apply id="S2.SS2.p9.4.m4.1.1.cmml" xref="S2.SS2.p9.4.m4.1.1"><eq id="S2.SS2.p9.4.m4.1.1.1.cmml" xref="S2.SS2.p9.4.m4.1.1.1"></eq><apply id="S2.SS2.p9.4.m4.1.1.2.cmml" xref="S2.SS2.p9.4.m4.1.1.2"><times id="S2.SS2.p9.4.m4.1.1.2.1.cmml" xref="S2.SS2.p9.4.m4.1.1.2.1"></times><ci id="S2.SS2.p9.4.m4.1.1.2.2.cmml" xref="S2.SS2.p9.4.m4.1.1.2.2">ùêπ</ci><cn id="S2.SS2.p9.4.m4.1.1.2.3.cmml" type="integer" xref="S2.SS2.p9.4.m4.1.1.2.3">1</cn></apply><cn id="S2.SS2.p9.4.m4.1.1.3.cmml" type="float" xref="S2.SS2.p9.4.m4.1.1.3">0.93</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p9.4.m4.1c">F1=0.93</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p9.4.m4.1d">italic_F 1 = 0.93</annotation></semantics></math>, <math alttext="ACC=0.90" class="ltx_Math" display="inline" id="S2.SS2.p9.5.m5.1"><semantics id="S2.SS2.p9.5.m5.1a"><mrow id="S2.SS2.p9.5.m5.1.1" xref="S2.SS2.p9.5.m5.1.1.cmml"><mrow id="S2.SS2.p9.5.m5.1.1.2" xref="S2.SS2.p9.5.m5.1.1.2.cmml"><mi id="S2.SS2.p9.5.m5.1.1.2.2" xref="S2.SS2.p9.5.m5.1.1.2.2.cmml">A</mi><mo id="S2.SS2.p9.5.m5.1.1.2.1" xref="S2.SS2.p9.5.m5.1.1.2.1.cmml">‚Å¢</mo><mi id="S2.SS2.p9.5.m5.1.1.2.3" xref="S2.SS2.p9.5.m5.1.1.2.3.cmml">C</mi><mo id="S2.SS2.p9.5.m5.1.1.2.1a" xref="S2.SS2.p9.5.m5.1.1.2.1.cmml">‚Å¢</mo><mi id="S2.SS2.p9.5.m5.1.1.2.4" xref="S2.SS2.p9.5.m5.1.1.2.4.cmml">C</mi></mrow><mo id="S2.SS2.p9.5.m5.1.1.1" xref="S2.SS2.p9.5.m5.1.1.1.cmml">=</mo><mn id="S2.SS2.p9.5.m5.1.1.3" xref="S2.SS2.p9.5.m5.1.1.3.cmml">0.90</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p9.5.m5.1b"><apply id="S2.SS2.p9.5.m5.1.1.cmml" xref="S2.SS2.p9.5.m5.1.1"><eq id="S2.SS2.p9.5.m5.1.1.1.cmml" xref="S2.SS2.p9.5.m5.1.1.1"></eq><apply id="S2.SS2.p9.5.m5.1.1.2.cmml" xref="S2.SS2.p9.5.m5.1.1.2"><times id="S2.SS2.p9.5.m5.1.1.2.1.cmml" xref="S2.SS2.p9.5.m5.1.1.2.1"></times><ci id="S2.SS2.p9.5.m5.1.1.2.2.cmml" xref="S2.SS2.p9.5.m5.1.1.2.2">ùê¥</ci><ci id="S2.SS2.p9.5.m5.1.1.2.3.cmml" xref="S2.SS2.p9.5.m5.1.1.2.3">ùê∂</ci><ci id="S2.SS2.p9.5.m5.1.1.2.4.cmml" xref="S2.SS2.p9.5.m5.1.1.2.4">ùê∂</ci></apply><cn id="S2.SS2.p9.5.m5.1.1.3.cmml" type="float" xref="S2.SS2.p9.5.m5.1.1.3">0.90</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p9.5.m5.1c">ACC=0.90</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p9.5.m5.1d">italic_A italic_C italic_C = 0.90</annotation></semantics></math>), the metrics oscillate without surpassing the best performance. Meanwhile, the few-shot method with random example selection (dotted blue lines) shows the same trend as <math alttext="K" class="ltx_Math" display="inline" id="S2.SS2.p9.6.m6.1"><semantics id="S2.SS2.p9.6.m6.1a"><mi id="S2.SS2.p9.6.m6.1.1" xref="S2.SS2.p9.6.m6.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p9.6.m6.1b"><ci id="S2.SS2.p9.6.m6.1.1.cmml" xref="S2.SS2.p9.6.m6.1.1">ùêæ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p9.6.m6.1c">K</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p9.6.m6.1d">italic_K</annotation></semantics></math> increases. However, its performance metrics are consistently below the BM25 algorithm, mostly having gaps more than 0.05 on F1. This result again demonstrates the effectiveness of the proposed RAG algorithm.</p>
</div>
<div class="ltx_para" id="S2.SS2.p10">
<p class="ltx_p" id="S2.SS2.p10.1"><span class="ltx_text ltx_font_bold" id="S2.SS2.p10.1.1">Material knowledge augmentation via prompt engineering</span></p>
</div>
<div class="ltx_para" id="S2.SS2.p11">
<p class="ltx_p" id="S2.SS2.p11.1">In addition to few-shot examples, another way to augment the domain knowledge of general-purpose LLM is through the fixed background prompt <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#bib.bib9" title="">9</a>]</cite>. The previous LLM adaptations on MOFs synthesis extraction by Zheng et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#bib.bib24" title="">24</a>]</cite> introduce a preliminary prompt engineering approach, which include the task description of MOFs synthesis extraction and the output format specification. In our work, based on the latest prompt engineering expertise <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#bib.bib21" title="">21</a>]</cite>, we propose to further incorporate two types of material knowledge into the background prompt: definition of each MOFs synthesis condition, and deterministic constraints on each condition‚Äôs numerical/textual value or structure (if any). As shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S2.F5" title="Figure 5 ‚Ä£ 2.2 Few-Shot Large Language Model with Material Knowledge ‚Ä£ 2 Results ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_tag">5</span></a>(d), by integrating the new material knowledge, the F1 metric increases from 0.91 to 0.93. However, when the few-shot examples are not incorporated, the background material knowledge will not lead to significant improvement by itself.</p>
</div>
<div class="ltx_para" id="S2.SS2.p12">
<p class="ltx_p" id="S2.SS2.p12.1">The details of newly introduced MOFs synthesis definitions and constraints as background prompts are listed in Table <a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S2.T1" title="Table 1 ‚Ä£ 2.2 Few-Shot Large Language Model with Material Knowledge ‚Ä£ 2 Results ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_tag">1</span></a>. Notably, we summarize three types of constraints on synthesis conditions: <em class="ltx_emph ltx_font_italic" id="S2.SS2.p12.1.1">numerical</em> that the value of a condition should fall into certain range according to prior knowledge, <em class="ltx_emph ltx_font_italic" id="S2.SS2.p12.1.2">textual</em> that an extracted condition by text should adhere to certain format to speedup follow-up material application, and <em class="ltx_emph ltx_font_italic" id="S2.SS2.p12.1.3">structural</em> that certain rules related to the condition are followed in all MOFs synthesis process.</p>
</div>
<figure class="ltx_table" id="S2.T1">
<p class="ltx_p ltx_align_center" id="S2.T1.1"><span class="ltx_text" id="S2.T1.1.1">
<span class="ltx_inline-block ltx_transformed_outer" id="S2.T1.1.1.1" style="width:433.6pt;height:4571.5pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<span class="ltx_p" id="S2.T1.1.1.1.1"><span class="ltx_text" id="S2.T1.1.1.1.1.1">
<span class="ltx_tabular ltx_align_middle" id="S2.T1.1.1.1.1.1.1">
<span class="ltx_tr" id="S2.T1.1.1.1.1.1.1.1">
<span class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="S2.T1.1.1.1.1.1.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.1.1.1.1.1.1.1">
<span class="ltx_p" id="S2.T1.1.1.1.1.1.1.1.1.1.1" style="width:76.8pt;"><span class="ltx_text ltx_font_bold" id="S2.T1.1.1.1.1.1.1.1.1.1.1.1">Conditions</span></span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="S2.T1.1.1.1.1.1.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.1.1.1.1.1.2.1">
<span class="ltx_p" id="S2.T1.1.1.1.1.1.1.1.2.1.1" style="width:113.8pt;"><span class="ltx_text ltx_font_bold" id="S2.T1.1.1.1.1.1.1.1.2.1.1.1" style="font-size:90%;">Definition</span></span>
</span></span>
<span class="ltx_td ltx_nopad_r ltx_align_justify ltx_border_tt" id="S2.T1.1.1.1.1.1.1.1.3">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.1.1.1.1.1.3.1">
<span class="ltx_p" id="S2.T1.1.1.1.1.1.1.1.3.1.1"><span class="ltx_text ltx_font_bold" id="S2.T1.1.1.1.1.1.1.1.3.1.1.1" style="font-size:90%;">Constraints by Type</span></span>
</span></span></span>
<span class="ltx_tr" id="S2.T1.1.1.1.1.1.1.2">
<span class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S2.T1.1.1.1.1.1.1.2.1">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.1.1.1.1.2.1.1">
<span class="ltx_p" id="S2.T1.1.1.1.1.1.1.2.1.1.1" style="width:76.8pt;"><span class="ltx_text" id="S2.T1.1.1.1.1.1.1.2.1.1.1.1"></span> <span class="ltx_text" id="S2.T1.1.1.1.1.1.1.2.1.1.1.2">
<span class="ltx_tabular ltx_align_middle" id="S2.T1.1.1.1.1.1.1.2.1.1.1.2.1">
<span class="ltx_tr" id="S2.T1.1.1.1.1.1.1.2.1.1.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S2.T1.1.1.1.1.1.1.2.1.1.1.2.1.1.1">Metal Precursor</span></span>
<span class="ltx_tr" id="S2.T1.1.1.1.1.1.1.2.1.1.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S2.T1.1.1.1.1.1.1.2.1.1.1.2.1.2.1">(name &amp; amount)</span></span>
</span></span><span class="ltx_text" id="S2.T1.1.1.1.1.1.1.2.1.1.1.3"></span></span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S2.T1.1.1.1.1.1.1.2.2">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.1.1.1.1.2.2.1">
<span class="ltx_p" id="S2.T1.1.1.1.1.1.1.2.2.1.1" style="width:113.8pt;"><span class="ltx_text" id="S2.T1.1.1.1.1.1.1.2.2.1.1.1" style="font-size:90%;">The precursor compound(s) containing metal ions ‚Ä¶</span></span>
</span></span>
<span class="ltx_td ltx_nopad_r ltx_align_justify ltx_border_t" id="S2.T1.1.1.1.1.1.1.2.3">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.1.1.1.1.2.3.1">
<span class="ltx_p" id="S2.T1.1.1.1.1.1.1.2.3.1.1"><span class="ltx_text" id="S2.T1.1.1.1.1.1.1.2.3.1.1.1" style="font-size:90%;">Textual: only include adjectives modifying the metal precursor itself‚Ä¶</span></span>
</span></span></span>
<span class="ltx_tr" id="S2.T1.1.1.1.1.1.1.3">
<span class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S2.T1.1.1.1.1.1.1.3.1">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.1.1.1.1.3.1.1">
<span class="ltx_p" id="S2.T1.1.1.1.1.1.1.3.1.1.1" style="width:76.8pt;"><span class="ltx_text" id="S2.T1.1.1.1.1.1.1.3.1.1.1.1"></span> <span class="ltx_text" id="S2.T1.1.1.1.1.1.1.3.1.1.1.2">
<span class="ltx_tabular ltx_align_middle" id="S2.T1.1.1.1.1.1.1.3.1.1.1.2.1">
<span class="ltx_tr" id="S2.T1.1.1.1.1.1.1.3.1.1.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S2.T1.1.1.1.1.1.1.3.1.1.1.2.1.1.1">Organic Linker</span></span>
<span class="ltx_tr" id="S2.T1.1.1.1.1.1.1.3.1.1.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S2.T1.1.1.1.1.1.1.3.1.1.1.2.1.2.1">(name &amp; amount)</span></span>
</span></span><span class="ltx_text" id="S2.T1.1.1.1.1.1.1.3.1.1.1.3"></span></span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S2.T1.1.1.1.1.1.1.3.2">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.1.1.1.1.3.2.1">
<span class="ltx_p" id="S2.T1.1.1.1.1.1.1.3.2.1.1" style="width:113.8pt;"><span class="ltx_text" id="S2.T1.1.1.1.1.1.1.3.2.1.1.1" style="font-size:90%;">The organic precursor linking metal ions or clusters ‚Ä¶</span></span>
</span></span>
<span class="ltx_td ltx_nopad_r ltx_align_justify ltx_border_t" id="S2.T1.1.1.1.1.1.1.3.3">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.1.1.1.1.3.3.1">
<span class="ltx_p" id="S2.T1.1.1.1.1.1.1.3.3.1.1">N/A</span>
</span></span></span>
<span class="ltx_tr" id="S2.T1.1.1.1.1.1.1.4">
<span class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S2.T1.1.1.1.1.1.1.4.1">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.1.1.1.1.4.1.1">
<span class="ltx_p" id="S2.T1.1.1.1.1.1.1.4.1.1.1" style="width:76.8pt;"><span class="ltx_text" id="S2.T1.1.1.1.1.1.1.4.1.1.1.1"></span> <span class="ltx_text" id="S2.T1.1.1.1.1.1.1.4.1.1.1.2">
<span class="ltx_tabular ltx_align_middle" id="S2.T1.1.1.1.1.1.1.4.1.1.1.2.1">
<span class="ltx_tr" id="S2.T1.1.1.1.1.1.1.4.1.1.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S2.T1.1.1.1.1.1.1.4.1.1.1.2.1.1.1">Solvent</span></span>
<span class="ltx_tr" id="S2.T1.1.1.1.1.1.1.4.1.1.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S2.T1.1.1.1.1.1.1.4.1.1.1.2.1.2.1">(name &amp; amount)</span></span>
</span></span><span class="ltx_text" id="S2.T1.1.1.1.1.1.1.4.1.1.1.3"></span></span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S2.T1.1.1.1.1.1.1.4.2">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.1.1.1.1.4.2.1">
<span class="ltx_p" id="S2.T1.1.1.1.1.1.1.4.2.1.1" style="width:113.8pt;"><span class="ltx_text" id="S2.T1.1.1.1.1.1.1.4.2.1.1.1" style="font-size:90%;">The liquid medium in which reactants are dissolved ‚Ä¶</span></span>
</span></span>
<span class="ltx_td ltx_nopad_r ltx_align_justify ltx_border_t" id="S2.T1.1.1.1.1.1.1.4.3">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.1.1.1.1.4.3.1">
<span class="ltx_p" id="S2.T1.1.1.1.1.1.1.4.3.1.1"><span class="ltx_text" id="S2.T1.1.1.1.1.1.1.4.3.1.1.1" style="font-size:90%;">Textual: include ‚Äúsolution‚Äù if the solvent contains water ‚Ä¶</span></span>
</span></span></span>
<span class="ltx_tr" id="S2.T1.1.1.1.1.1.1.5">
<span class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S2.T1.1.1.1.1.1.1.5.1">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.1.1.1.1.5.1.1">
<span class="ltx_p" id="S2.T1.1.1.1.1.1.1.5.1.1.1" style="width:76.8pt;"><span class="ltx_text" id="S2.T1.1.1.1.1.1.1.5.1.1.1.1"></span> <span class="ltx_text" id="S2.T1.1.1.1.1.1.1.5.1.1.1.2">
<span class="ltx_tabular ltx_align_middle" id="S2.T1.1.1.1.1.1.1.5.1.1.1.2.1">
<span class="ltx_tr" id="S2.T1.1.1.1.1.1.1.5.1.1.1.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S2.T1.1.1.1.1.1.1.5.1.1.1.2.1.1.1">Modulator</span></span>
<span class="ltx_tr" id="S2.T1.1.1.1.1.1.1.5.1.1.1.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S2.T1.1.1.1.1.1.1.5.1.1.1.2.1.2.1">(name &amp; amount)</span></span>
</span></span><span class="ltx_text" id="S2.T1.1.1.1.1.1.1.5.1.1.1.3"></span></span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S2.T1.1.1.1.1.1.1.5.2">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.1.1.1.1.5.2.1">
<span class="ltx_p" id="S2.T1.1.1.1.1.1.1.5.2.1.1" style="width:113.8pt;"><span class="ltx_text" id="S2.T1.1.1.1.1.1.1.5.2.1.1.1" style="font-size:90%;">The substance to adjust reaction conditions (e.g., pH value) ‚Ä¶</span></span>
</span></span>
<span class="ltx_td ltx_nopad_r ltx_align_justify ltx_border_t" id="S2.T1.1.1.1.1.1.1.5.3">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.1.1.1.1.5.3.1">
<span class="ltx_p" id="S2.T1.1.1.1.1.1.1.5.3.1.1"><span class="ltx_text" id="S2.T1.1.1.1.1.1.1.5.3.1.1.1" style="font-size:90%;">Structural: the elements of modulator will not become part of the backbone of MOF structure ‚Ä¶</span></span>
</span></span></span>
<span class="ltx_tr" id="S2.T1.1.1.1.1.1.1.6">
<span class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" id="S2.T1.1.1.1.1.1.1.6.1">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.1.1.1.1.6.1.1">
<span class="ltx_p" id="S2.T1.1.1.1.1.1.1.6.1.1.1" style="width:76.8pt;">Reaction process (duration &amp; temperature)</span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" id="S2.T1.1.1.1.1.1.1.6.2">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.1.1.1.1.6.2.1">
<span class="ltx_p" id="S2.T1.1.1.1.1.1.1.6.2.1.1" style="width:113.8pt;"><span class="ltx_text" id="S2.T1.1.1.1.1.1.1.6.2.1.1.1" style="font-size:90%;">The synthesis process producing MOFs ‚Ä¶</span></span>
</span></span>
<span class="ltx_td ltx_nopad_r ltx_align_justify ltx_border_bb ltx_border_t" id="S2.T1.1.1.1.1.1.1.6.3">
<span class="ltx_inline-block ltx_align_top" id="S2.T1.1.1.1.1.1.1.6.3.1">
<span class="ltx_p" id="S2.T1.1.1.1.1.1.1.6.3.1.1"><span class="ltx_text" id="S2.T1.1.1.1.1.1.1.6.3.1.1.1" style="font-size:90%;">Numerical: The reaction duration will last several minutes to hours ‚Ä¶ 
<br class="ltx_break"/>Structural: Crystallization is not a reaction process ‚Ä¶</span></span>
</span></span></span>
</span></span></span>
</span></span></span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Material knowledge as background prompts: synthesis condition definition and numerical/textual/structural constraints.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Optimization for High-Throughput MOFs Synthesis Extraction</h3>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1">Though the proposed LLM-based synthesis extraction method achieves state-of-the-art performance in our medium-scale validation set, scalability issues arise when the method is deployed to high-throughput scenarios involving thousands of real-world literature and millions of material texts. The challenges include but not limited to the large bill from calling commercial LLM APIs, the high cost to annotate enough examples for few-shot learning, and the pragmatic issues in material application.</p>
</div>
<div class="ltx_para" id="S2.SS3.p2">
<p class="ltx_p" id="S2.SS3.p2.1"><span class="ltx_text ltx_font_bold" id="S2.SS3.p2.1.1">Synthesis paragraph detection</span></p>
</div>
<div class="ltx_para" id="S2.SS3.p3">
<p class="ltx_p" id="S2.SS3.p3.1">To train the machine learning model for synthesis paragraph detection, we first annotate a dataset of 440 papers randomly sampled from the large dataset of Sec. <a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S5.SS1" title="5.1 MOFs Data ‚Ä£ 5 Appendix ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_tag">5.1</span></a>. Details can be accessed in Sec. <a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S5.SS2" title="5.2 Annotation Procedure for Synthesis Paragraphs and Synthesis Conditions ‚Ä£ 5 Appendix ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_tag">5.2</span></a>. Finally, this process yields 1,349 synthesis paragraphs as positive samples. To train the classifier, negative samples by non-synthesis paragraphs are obtained after removing all annotated paragraphs from a paper, leading to 11,783 negative samples. We employed the standard BERT model, specifically the pre-trained <span class="ltx_text ltx_font_typewriter" id="S2.SS3.p3.1.1">bert-base-uncased</span> model from HuggingFace, for training. The training and validation processes utilized a 5-fold cross-validation method. Given the imbalance dataset, we used stratified 5-fold cross-validation to ensure that the ratio of positive to negative samples remained consistent in each split. The final classification performance is quite high, with an ACC of 0.989, precision of 0.955, recall of 0.947, and F1 = 0.951.</p>
</div>
<div class="ltx_para" id="S2.SS3.p4">
<p class="ltx_p" id="S2.SS3.p4.1">Paragraphs related to the synthesis process constitute only about 6% of an article‚Äôs total length but concentrate the main synthesis condition. Extracting condition from synthesized paragraphs, rather than the entire text, can significantly reduce the overhead of LLM-based approach and increase the density of synthesis conditions in text, thereby enhancing extraction performance.</p>
</div>
<div class="ltx_para" id="S2.SS3.p5">
<p class="ltx_p" id="S2.SS3.p5.1"><span class="ltx_text ltx_font_bold" id="S2.SS3.p5.1.1">Sizing the few-shot example pool</span></p>
</div>
<figure class="ltx_figure" id="S2.F7">
<p class="ltx_p ltx_align_center" id="S2.F7.1"><span class="ltx_text" id="S2.F7.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="564" id="S2.F7.1.1.g1" src="x7.png" width="553"/></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Synthesis extraction performance with varying sizes of example pool: (a) average F1 and its 95% CI of 123-paragraph and 60-paragraph datasets; (b) 123-paragraph dataset with different <math alttext="K" class="ltx_Math" display="inline" id="S2.F7.3.m1.1"><semantics id="S2.F7.3.m1.1b"><mi id="S2.F7.3.m1.1.1" xref="S2.F7.3.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S2.F7.3.m1.1c"><ci id="S2.F7.3.m1.1.1.cmml" xref="S2.F7.3.m1.1.1">ùêæ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.F7.3.m1.1d">K</annotation><annotation encoding="application/x-llamapun" id="S2.F7.3.m1.1e">italic_K</annotation></semantics></math>-shots.</figcaption>
</figure>
<div class="ltx_para" id="S2.SS3.p6">
<p class="ltx_p" id="S2.SS3.p6.1">In this study, we have discussed both the quantity and quality of few-shot examples. Yet, it is still unknown how many ground-truth annotations, namely the example pool where few-shots are selected from, are required for high-throughput synthesis extraction over thousands of MOFs literature or more. To answer this question, we design an experiment that assumes the entire dataset to be 123 synthesis paragraphs (all with ground-truth synthesis conditions known), and the example pool size (# of annotations) to increase from zero. The example pool in each setting is randomly chosen from the entire dataset. To alleviate the uncertainty from randomness, we give 5 trials on each example pool size setting. Also, to further understand the scalability of example pool sizing, we create a new dataset with 60 synthesis paragraphs from the entire data.</p>
</div>
<div class="ltx_para" id="S2.SS3.p7">
<p class="ltx_p" id="S2.SS3.p7.1">Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S2.F7" title="Figure 7 ‚Ä£ 2.3 Optimization for High-Throughput MOFs Synthesis Extraction ‚Ä£ 2 Results ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_tag">7</span></a>(a) illustrates the result on the effect of example pool size. First, the first few annotations (from 0 to 5 in the figure) contribute the most performance gain, regardless of the size of entire dataset. This is coherent with the effect observed on zero-shot learning vs. one-shot. Second, smaller datasets (i.e., 60-paragraph by the green line) require fewer # of annotations than larger datasets (i.e., 123-paragraph by the red line), while achieving the same level of performance. The green line stays above the red line, especially under smaller example pool size. Third, more annotations will almost always bring performance gains and less uncertainty, though most boosts happen at initial few annotations. On the 60-paragraph data, the performance peak (F1=0.92) appears at the pool size of 40, 66.7% of the data size; on the 123-paragraph data, the peak (F1=0.93) does not happen before the pool size of 65, thus at least larger than 52.8% of the data size. A future work would be studying the active learning mechanism, which may help to reduce the required example pool in few-shot learning of LLM.</p>
</div>
<div class="ltx_para" id="S2.SS3.p8">
<p class="ltx_p" id="S2.SS3.p8.1">Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S2.F7" title="Figure 7 ‚Ä£ 2.3 Optimization for High-Throughput MOFs Synthesis Extraction ‚Ä£ 2 Results ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_tag">7</span></a>(b) further demonstrates the effect of both example pool size and <math alttext="K" class="ltx_Math" display="inline" id="S2.SS3.p8.1.m1.1"><semantics id="S2.SS3.p8.1.m1.1a"><mi id="S2.SS3.p8.1.m1.1.1" xref="S2.SS3.p8.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p8.1.m1.1b"><ci id="S2.SS3.p8.1.m1.1.1.cmml" xref="S2.SS3.p8.1.m1.1.1">ùêæ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p8.1.m1.1c">K</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p8.1.m1.1d">italic_K</annotation></semantics></math>-shots. As shown in the figure, when the labeled pool size increases from 0 to 5, the performance metrics improve rapidly, indicating that a labeled dataset is much more effective than an unlabeled one. Subsequently, the performance metrics increase slowly until the labeled pool size reaches the range of 40-55. The performance metrics then stabilize, with the F1 score fluctuating slightly around 0.91 and ACC around 0.88.</p>
</div>
<div class="ltx_para" id="S2.SS3.p9">
<p class="ltx_p" id="S2.SS3.p9.1"><span class="ltx_text ltx_font_bold" id="S2.SS3.p9.1.1">Coreference Resolution</span></p>
</div>
<div class="ltx_para" id="S2.SS3.p10">
<p class="ltx_p" id="S2.SS3.p10.1">For convenience of writing, proxy words like ‚ÄúL‚Äù or ‚ÄúH2L‚Äù are frequently used in the MOFs literature to represent specific organic linkers, which are called coreference in NLP. In all the extracted synthesis conditions from 5269 paragraphs, 578 coreference cases are identified. These proxy words could refer to substances defined far in the same article, which makes it difficult to use the extraction results in downstream material application.</p>
</div>
<div class="ltx_para" id="S2.SS3.p11">
<p class="ltx_p" id="S2.SS3.p11.1">Due to different writing styles, regular expression can not be employed as the sole method to resolve the coreference of these proxy words. We introduce a hybrid method combining LLM and regular expression for coreference resolution. The resolving of proxy word coreference is done in three steps. First, the synthesis paragraph is located in the literature and all the text before the paragraph is input to LLM. The LLM is asked to extract all anaphoric references and the original words. Second, a regular expression is designed to identify coreference proxy words from all the extracted conditions by LLM. Finally, these proxy words in the synthesis condition are matched with the detected anaphoric reference. If a match exist, the proxy word is resolved into the original words discovered by LLM in the second step.</p>
</div>
<div class="ltx_para" id="S2.SS3.p12">
<p class="ltx_p" id="S2.SS3.p12.1">Overall, in all the 578 organic linker conditions using coreference, 79% of them can be resolved by our method. Only 0.023 linkers per paragraph remain unresolved. As shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S2.T2" title="Table 2 ‚Ä£ 2.3 Optimization for High-Throughput MOFs Synthesis Extraction ‚Ä£ 2 Results ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_tag">2</span></a>, The five most appearing coreference words are ‚ÄúL‚Äù, ‚ÄúH2L‚Äù, ‚ÄúHL‚Äù, ‚ÄúL1‚Äù, and ‚ÄúH4L‚Äù, with all the resolution rates over 85%.</p>
</div>
<figure class="ltx_table" id="S2.T2">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S2.T2.1">
<tr class="ltx_tr" id="S2.T2.1.1">
<td class="ltx_td ltx_align_justify ltx_border_tt" id="S2.T2.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="S2.T2.1.1.1.1">
<span class="ltx_p" id="S2.T2.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S2.T2.1.1.1.1.1.1">Proxy
<br class="ltx_break"/>Words</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_border_tt" id="S2.T2.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="S2.T2.1.1.2.1">
<span class="ltx_p" id="S2.T2.1.1.2.1.1"><span class="ltx_text ltx_font_bold" id="S2.T2.1.1.2.1.1.1">Occurrence
<br class="ltx_break"/>Count</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_border_tt" id="S2.T2.1.1.3">
<span class="ltx_inline-block ltx_align_top" id="S2.T2.1.1.3.1">
<span class="ltx_p" id="S2.T2.1.1.3.1.1"><span class="ltx_text ltx_font_bold" id="S2.T2.1.1.3.1.1.1">Resolution
<br class="ltx_break"/>Count</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_border_tt" id="S2.T2.1.1.4">
<span class="ltx_inline-block ltx_align_top" id="S2.T2.1.1.4.1">
<span class="ltx_p" id="S2.T2.1.1.4.1.1"><span class="ltx_text ltx_font_bold" id="S2.T2.1.1.4.1.1.1">Resolution
<br class="ltx_break"/>Ratio</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.T2.1.2">
<td class="ltx_td ltx_align_justify ltx_border_t" id="S2.T2.1.2.1">
<span class="ltx_inline-block ltx_align_top" id="S2.T2.1.2.1.1">
<span class="ltx_p" id="S2.T2.1.2.1.1.1">L</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_border_t" id="S2.T2.1.2.2">
<span class="ltx_inline-block ltx_align_top" id="S2.T2.1.2.2.1">
<span class="ltx_p" id="S2.T2.1.2.2.1.1">106</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_border_t" id="S2.T2.1.2.3">
<span class="ltx_inline-block ltx_align_top" id="S2.T2.1.2.3.1">
<span class="ltx_p" id="S2.T2.1.2.3.1.1">92</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_border_t" id="S2.T2.1.2.4">
<span class="ltx_inline-block ltx_align_top" id="S2.T2.1.2.4.1">
<span class="ltx_p" id="S2.T2.1.2.4.1.1">86.8%</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.T2.1.3">
<td class="ltx_td ltx_align_justify" id="S2.T2.1.3.1">
<span class="ltx_inline-block ltx_align_top" id="S2.T2.1.3.1.1">
<span class="ltx_p" id="S2.T2.1.3.1.1.1">H2L</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="S2.T2.1.3.2">
<span class="ltx_inline-block ltx_align_top" id="S2.T2.1.3.2.1">
<span class="ltx_p" id="S2.T2.1.3.2.1.1">64</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="S2.T2.1.3.3">
<span class="ltx_inline-block ltx_align_top" id="S2.T2.1.3.3.1">
<span class="ltx_p" id="S2.T2.1.3.3.1.1">58</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="S2.T2.1.3.4">
<span class="ltx_inline-block ltx_align_top" id="S2.T2.1.3.4.1">
<span class="ltx_p" id="S2.T2.1.3.4.1.1">90.6%</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.T2.1.4">
<td class="ltx_td ltx_align_justify" id="S2.T2.1.4.1">
<span class="ltx_inline-block ltx_align_top" id="S2.T2.1.4.1.1">
<span class="ltx_p" id="S2.T2.1.4.1.1.1">HL</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="S2.T2.1.4.2">
<span class="ltx_inline-block ltx_align_top" id="S2.T2.1.4.2.1">
<span class="ltx_p" id="S2.T2.1.4.2.1.1">45</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="S2.T2.1.4.3">
<span class="ltx_inline-block ltx_align_top" id="S2.T2.1.4.3.1">
<span class="ltx_p" id="S2.T2.1.4.3.1.1">45</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="S2.T2.1.4.4">
<span class="ltx_inline-block ltx_align_top" id="S2.T2.1.4.4.1">
<span class="ltx_p" id="S2.T2.1.4.4.1.1">100%</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.T2.1.5">
<td class="ltx_td ltx_align_justify" id="S2.T2.1.5.1">
<span class="ltx_inline-block ltx_align_top" id="S2.T2.1.5.1.1">
<span class="ltx_p" id="S2.T2.1.5.1.1.1">L1</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="S2.T2.1.5.2">
<span class="ltx_inline-block ltx_align_top" id="S2.T2.1.5.2.1">
<span class="ltx_p" id="S2.T2.1.5.2.1.1">39</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="S2.T2.1.5.3">
<span class="ltx_inline-block ltx_align_top" id="S2.T2.1.5.3.1">
<span class="ltx_p" id="S2.T2.1.5.3.1.1">37</span>
</span>
</td>
<td class="ltx_td ltx_align_justify" id="S2.T2.1.5.4">
<span class="ltx_inline-block ltx_align_top" id="S2.T2.1.5.4.1">
<span class="ltx_p" id="S2.T2.1.5.4.1.1">94.9%</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S2.T2.1.6">
<td class="ltx_td ltx_align_justify ltx_border_bb" id="S2.T2.1.6.1">
<span class="ltx_inline-block ltx_align_top" id="S2.T2.1.6.1.1">
<span class="ltx_p" id="S2.T2.1.6.1.1.1">H4L</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_border_bb" id="S2.T2.1.6.2">
<span class="ltx_inline-block ltx_align_top" id="S2.T2.1.6.2.1">
<span class="ltx_p" id="S2.T2.1.6.2.1.1">38</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_border_bb" id="S2.T2.1.6.3">
<span class="ltx_inline-block ltx_align_top" id="S2.T2.1.6.3.1">
<span class="ltx_p" id="S2.T2.1.6.3.1.1">33</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_border_bb" id="S2.T2.1.6.4">
<span class="ltx_inline-block ltx_align_top" id="S2.T2.1.6.4.1">
<span class="ltx_p" id="S2.T2.1.6.4.1.1">86.8%</span>
</span>
</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Five most frequently used proxy words and their resolution results.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S2.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.4 </span>MOFs Structure Inference</h3>
<div class="ltx_para" id="S2.SS4.p1">
<p class="ltx_p" id="S2.SS4.p1.2">To better validate the accuracy and potential of few-shot synthesis extraction method in downstream tasks, we set up a real-world MOFs synthesis-structure inference task and compared it with existing benchmark methods (zero-shot LLM). The specific task is to predict the microscopic property of MOFs: global cavity diameter, pore limiting diameter, largest cavity diameter, and framework density, using the synthesis conditions including metals, organic links, solvents, and reaction duration/temperature. We evaluate the task performance using coefficient of determination (<math alttext="R^{2}" class="ltx_Math" display="inline" id="S2.SS4.p1.1.m1.1"><semantics id="S2.SS4.p1.1.m1.1a"><msup id="S2.SS4.p1.1.m1.1.1" xref="S2.SS4.p1.1.m1.1.1.cmml"><mi id="S2.SS4.p1.1.m1.1.1.2" xref="S2.SS4.p1.1.m1.1.1.2.cmml">R</mi><mn id="S2.SS4.p1.1.m1.1.1.3" xref="S2.SS4.p1.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S2.SS4.p1.1.m1.1b"><apply id="S2.SS4.p1.1.m1.1.1.cmml" xref="S2.SS4.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS4.p1.1.m1.1.1.1.cmml" xref="S2.SS4.p1.1.m1.1.1">superscript</csymbol><ci id="S2.SS4.p1.1.m1.1.1.2.cmml" xref="S2.SS4.p1.1.m1.1.1.2">ùëÖ</ci><cn id="S2.SS4.p1.1.m1.1.1.3.cmml" type="integer" xref="S2.SS4.p1.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p1.1.m1.1c">R^{2}</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p1.1.m1.1d">italic_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math>) of each inference model. The <math alttext="R^{2}" class="ltx_Math" display="inline" id="S2.SS4.p1.2.m2.1"><semantics id="S2.SS4.p1.2.m2.1a"><msup id="S2.SS4.p1.2.m2.1.1" xref="S2.SS4.p1.2.m2.1.1.cmml"><mi id="S2.SS4.p1.2.m2.1.1.2" xref="S2.SS4.p1.2.m2.1.1.2.cmml">R</mi><mn id="S2.SS4.p1.2.m2.1.1.3" xref="S2.SS4.p1.2.m2.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S2.SS4.p1.2.m2.1b"><apply id="S2.SS4.p1.2.m2.1.1.cmml" xref="S2.SS4.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS4.p1.2.m2.1.1.1.cmml" xref="S2.SS4.p1.2.m2.1.1">superscript</csymbol><ci id="S2.SS4.p1.2.m2.1.1.2.cmml" xref="S2.SS4.p1.2.m2.1.1.2">ùëÖ</ci><cn id="S2.SS4.p1.2.m2.1.1.3.cmml" type="integer" xref="S2.SS4.p1.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p1.2.m2.1c">R^{2}</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p1.2.m2.1d">italic_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math> metric effectively quantifies a model‚Äôs explanatory power regarding the actual data variation and the model accuracy. Therefore, it can be used to reflect the impact of different synthesis conditions on MOFs microstructure.</p>
</div>
<div class="ltx_para" id="S2.SS4.p2">
<p class="ltx_p" id="S2.SS4.p2.1">The evaluation data is a subset of the CSD database <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#bib.bib14" title="">14</a>]</cite>, which encompasses 5269 MOFs. As detailed in Sec. <a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S5.SS1" title="5.1 MOFs Data ‚Ä£ 5 Appendix ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_tag">5.1</span></a>, these MOFs are carefully selected so that each MOF is described by only one scientific literature and the literature will only have one synthesis paragraph. The resulting dataset ensures the validity of evaluation by exact correspondence between a MOF‚Äôs microscopic structure and its extracted synthesis conditions.</p>
</div>
<div class="ltx_para" id="S2.SS4.p3">
<p class="ltx_p" id="S2.SS4.p3.1">Using the few-shot/zero-shot LLMs and other benchmark methods, the 10 synthesis conditions under study are extracted from a unique synthesis paragraph linked to each of the 5269 MOFs. The raw textual conditions extracted are post-processed to improve data quality, such as synonym merging and standardization of temperature/time scales (Sec. <a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S5.SS3" title="5.3 Post-processing of Synthesis Conditions ‚Ä£ 5 Appendix ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_tag">5.3</span></a>). On the LLM output by the few-shot method, the top 100, 135, and 20 precursor names of metals, linkers, and solvents are selected, which leads to a smaller dataset of 800 MOFs. On the LLM by zero-shot method, the distribution of conditions are less longer-tailed, so that a stricter filter is applied to obtain the same number of 800 MOFs. These precursor names are embedded into one length-198 feature vector by the methods in Sec. <a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S5.SS3" title="5.3 Post-processing of Synthesis Conditions ‚Ä£ 5 Appendix ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_tag">5.3</span></a>, where serves as the input features in the material inference task. The target outcome variables are the four microstructure property of a MOF. Their calculation procedure is described in Sec. <a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S5.SS1" title="5.1 MOFs Data ‚Ä£ 5 Appendix ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_tag">5.1</span></a>.</p>
</div>
<figure class="ltx_table" id="S2.T3">
<p class="ltx_p ltx_align_center" id="S2.T3.1"><span class="ltx_text" id="S2.T3.1.1">
<span class="ltx_inline-block ltx_transformed_outer" id="S2.T3.1.1.1" style="width:433.6pt;height:923.7pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<span class="ltx_p" id="S2.T3.1.1.1.1"><span class="ltx_text" id="S2.T3.1.1.1.1.1">
<span class="ltx_tabular ltx_align_middle" id="S2.T3.1.1.1.1.1.1">
<span class="ltx_tr" id="S2.T3.1.1.1.1.1.1.1">
<span class="ltx_td ltx_align_justify ltx_border_tt" id="S2.T3.1.1.1.1.1.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="S2.T3.1.1.1.1.1.1.1.1.1">
<span class="ltx_p" id="S2.T3.1.1.1.1.1.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S2.T3.1.1.1.1.1.1.1.1.1.1.1">Model</span></span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_border_tt" id="S2.T3.1.1.1.1.1.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="S2.T3.1.1.1.1.1.1.1.2.1">
<span class="ltx_p" id="S2.T3.1.1.1.1.1.1.1.2.1.1"><span class="ltx_text ltx_font_bold" id="S2.T3.1.1.1.1.1.1.1.2.1.1.1" style="font-size:90%;">Zero-shot R<sup class="ltx_sup" id="S2.T3.1.1.1.1.1.1.1.2.1.1.1.1">2</sup></span></span>
</span></span>
<span class="ltx_td ltx_nopad_r ltx_align_justify ltx_border_tt" id="S2.T3.1.1.1.1.1.1.1.3">
<span class="ltx_inline-block ltx_align_top" id="S2.T3.1.1.1.1.1.1.1.3.1">
<span class="ltx_p" id="S2.T3.1.1.1.1.1.1.1.3.1.1"><span class="ltx_text ltx_font_bold" id="S2.T3.1.1.1.1.1.1.1.3.1.1.1" style="font-size:90%;">Few-shot R<sup class="ltx_sup" id="S2.T3.1.1.1.1.1.1.1.3.1.1.1.1">2</sup></span></span>
</span></span></span>
<span class="ltx_tr" id="S2.T3.1.1.1.1.1.1.2">
<span class="ltx_td ltx_align_justify ltx_border_t" id="S2.T3.1.1.1.1.1.1.2.1">
<span class="ltx_inline-block ltx_align_top" id="S2.T3.1.1.1.1.1.1.2.1.1">
<span class="ltx_p" id="S2.T3.1.1.1.1.1.1.2.1.1.1">Lasso</span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_border_t" id="S2.T3.1.1.1.1.1.1.2.2">
<span class="ltx_inline-block ltx_align_top" id="S2.T3.1.1.1.1.1.1.2.2.1">
<span class="ltx_p" id="S2.T3.1.1.1.1.1.1.2.2.1.1"><span class="ltx_text" id="S2.T3.1.1.1.1.1.1.2.2.1.1.1" style="font-size:90%;">0.1755</span></span>
</span></span>
<span class="ltx_td ltx_nopad_r ltx_align_justify ltx_border_t" id="S2.T3.1.1.1.1.1.1.2.3">
<span class="ltx_inline-block ltx_align_top" id="S2.T3.1.1.1.1.1.1.2.3.1">
<span class="ltx_p" id="S2.T3.1.1.1.1.1.1.2.3.1.1"><span class="ltx_text" id="S2.T3.1.1.1.1.1.1.2.3.1.1.1" style="font-size:90%;">0.2257</span></span>
</span></span></span>
<span class="ltx_tr" id="S2.T3.1.1.1.1.1.1.3">
<span class="ltx_td ltx_align_justify" id="S2.T3.1.1.1.1.1.1.3.1">
<span class="ltx_inline-block ltx_align_top" id="S2.T3.1.1.1.1.1.1.3.1.1">
<span class="ltx_p" id="S2.T3.1.1.1.1.1.1.3.1.1.1">Bayesian Ridge</span>
</span></span>
<span class="ltx_td ltx_align_justify" id="S2.T3.1.1.1.1.1.1.3.2">
<span class="ltx_inline-block ltx_align_top" id="S2.T3.1.1.1.1.1.1.3.2.1">
<span class="ltx_p" id="S2.T3.1.1.1.1.1.1.3.2.1.1"><span class="ltx_text" id="S2.T3.1.1.1.1.1.1.3.2.1.1.1" style="font-size:90%;">0.1758</span></span>
</span></span>
<span class="ltx_td ltx_nopad_r ltx_align_justify" id="S2.T3.1.1.1.1.1.1.3.3">
<span class="ltx_inline-block ltx_align_top" id="S2.T3.1.1.1.1.1.1.3.3.1">
<span class="ltx_p" id="S2.T3.1.1.1.1.1.1.3.3.1.1"><span class="ltx_text" id="S2.T3.1.1.1.1.1.1.3.3.1.1.1" style="font-size:90%;">0.2318</span></span>
</span></span></span>
<span class="ltx_tr" id="S2.T3.1.1.1.1.1.1.4">
<span class="ltx_td ltx_align_justify" id="S2.T3.1.1.1.1.1.1.4.1">
<span class="ltx_inline-block ltx_align_top" id="S2.T3.1.1.1.1.1.1.4.1.1">
<span class="ltx_p" id="S2.T3.1.1.1.1.1.1.4.1.1.1">AdaBoost</span>
</span></span>
<span class="ltx_td ltx_align_justify" id="S2.T3.1.1.1.1.1.1.4.2">
<span class="ltx_inline-block ltx_align_top" id="S2.T3.1.1.1.1.1.1.4.2.1">
<span class="ltx_p" id="S2.T3.1.1.1.1.1.1.4.2.1.1"><span class="ltx_text" id="S2.T3.1.1.1.1.1.1.4.2.1.1.1" style="font-size:90%;">0.2570</span></span>
</span></span>
<span class="ltx_td ltx_nopad_r ltx_align_justify" id="S2.T3.1.1.1.1.1.1.4.3">
<span class="ltx_inline-block ltx_align_top" id="S2.T3.1.1.1.1.1.1.4.3.1">
<span class="ltx_p" id="S2.T3.1.1.1.1.1.1.4.3.1.1"><span class="ltx_text" id="S2.T3.1.1.1.1.1.1.4.3.1.1.1" style="font-size:90%;">0.3298</span></span>
</span></span></span>
<span class="ltx_tr" id="S2.T3.1.1.1.1.1.1.5">
<span class="ltx_td ltx_align_justify" id="S2.T3.1.1.1.1.1.1.5.1">
<span class="ltx_inline-block ltx_align_top" id="S2.T3.1.1.1.1.1.1.5.1.1">
<span class="ltx_p" id="S2.T3.1.1.1.1.1.1.5.1.1.1">Random Forest</span>
</span></span>
<span class="ltx_td ltx_align_justify" id="S2.T3.1.1.1.1.1.1.5.2">
<span class="ltx_inline-block ltx_align_top" id="S2.T3.1.1.1.1.1.1.5.2.1">
<span class="ltx_p" id="S2.T3.1.1.1.1.1.1.5.2.1.1"><span class="ltx_text" id="S2.T3.1.1.1.1.1.1.5.2.1.1.1" style="font-size:90%;">0.2498</span></span>
</span></span>
<span class="ltx_td ltx_nopad_r ltx_align_justify" id="S2.T3.1.1.1.1.1.1.5.3">
<span class="ltx_inline-block ltx_align_top" id="S2.T3.1.1.1.1.1.1.5.3.1">
<span class="ltx_p" id="S2.T3.1.1.1.1.1.1.5.3.1.1"><span class="ltx_text" id="S2.T3.1.1.1.1.1.1.5.3.1.1.1" style="font-size:90%;">0.3468</span></span>
</span></span></span>
<span class="ltx_tr" id="S2.T3.1.1.1.1.1.1.6">
<span class="ltx_td ltx_align_justify" id="S2.T3.1.1.1.1.1.1.6.1">
<span class="ltx_inline-block ltx_align_top" id="S2.T3.1.1.1.1.1.1.6.1.1">
<span class="ltx_p" id="S2.T3.1.1.1.1.1.1.6.1.1.1">Gradient Boosting</span>
</span></span>
<span class="ltx_td ltx_align_justify" id="S2.T3.1.1.1.1.1.1.6.2">
<span class="ltx_inline-block ltx_align_top" id="S2.T3.1.1.1.1.1.1.6.2.1">
<span class="ltx_p" id="S2.T3.1.1.1.1.1.1.6.2.1.1"><span class="ltx_text" id="S2.T3.1.1.1.1.1.1.6.2.1.1.1" style="font-size:90%;">0.2919</span></span>
</span></span>
<span class="ltx_td ltx_nopad_r ltx_align_justify" id="S2.T3.1.1.1.1.1.1.6.3">
<span class="ltx_inline-block ltx_align_top" id="S2.T3.1.1.1.1.1.1.6.3.1">
<span class="ltx_p" id="S2.T3.1.1.1.1.1.1.6.3.1.1"><span class="ltx_text" id="S2.T3.1.1.1.1.1.1.6.3.1.1.1" style="font-size:90%;">0.3632</span></span>
</span></span></span>
<span class="ltx_tr" id="S2.T3.1.1.1.1.1.1.7">
<span class="ltx_td ltx_align_justify ltx_border_bb" id="S2.T3.1.1.1.1.1.1.7.1">
<span class="ltx_inline-block ltx_align_top" id="S2.T3.1.1.1.1.1.1.7.1.1">
<span class="ltx_p" id="S2.T3.1.1.1.1.1.1.7.1.1.1">XGBoost</span>
</span></span>
<span class="ltx_td ltx_align_justify ltx_border_bb" id="S2.T3.1.1.1.1.1.1.7.2">
<span class="ltx_inline-block ltx_align_top" id="S2.T3.1.1.1.1.1.1.7.2.1">
<span class="ltx_p" id="S2.T3.1.1.1.1.1.1.7.2.1.1"><span class="ltx_text" id="S2.T3.1.1.1.1.1.1.7.2.1.1.1" style="font-size:90%;">0.3559</span></span>
</span></span>
<span class="ltx_td ltx_nopad_r ltx_align_justify ltx_border_bb" id="S2.T3.1.1.1.1.1.1.7.3">
<span class="ltx_inline-block ltx_align_top" id="S2.T3.1.1.1.1.1.1.7.3.1">
<span class="ltx_p" id="S2.T3.1.1.1.1.1.1.7.3.1.1"><span class="ltx_text ltx_font_bold" id="S2.T3.1.1.1.1.1.1.7.3.1.1.1" style="font-size:90%;">0.4421</span></span>
</span></span></span>
</span></span></span>
</span></span></span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Performance comparison of few-shot and zero-shot LLMs across different machine learning models on the inference MOFs framework density.</figcaption>
</figure>
<div class="ltx_para" id="S2.SS4.p4">
<p class="ltx_p" id="S2.SS4.p4.2">We apply six machine learning models for the inference: Lasso Regression, Bayesian Ridge Regression, AdaBoost, Random Forest, Gradient Boosting Regression, and Extreme Gradient Boosting (XGBoost). The first five models do not support missing value as input, so we use mean imputation instead. With each model, we compare the two LLM-based method, few-shot learning vs. zero-shot learning, in a 10-fold cross-validation. On the four microstructure properties inferred, the first three lead to negative or close to zero <math alttext="R^{2}" class="ltx_Math" display="inline" id="S2.SS4.p4.1.m1.1"><semantics id="S2.SS4.p4.1.m1.1a"><msup id="S2.SS4.p4.1.m1.1.1" xref="S2.SS4.p4.1.m1.1.1.cmml"><mi id="S2.SS4.p4.1.m1.1.1.2" xref="S2.SS4.p4.1.m1.1.1.2.cmml">R</mi><mn id="S2.SS4.p4.1.m1.1.1.3" xref="S2.SS4.p4.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S2.SS4.p4.1.m1.1b"><apply id="S2.SS4.p4.1.m1.1.1.cmml" xref="S2.SS4.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS4.p4.1.m1.1.1.1.cmml" xref="S2.SS4.p4.1.m1.1.1">superscript</csymbol><ci id="S2.SS4.p4.1.m1.1.1.2.cmml" xref="S2.SS4.p4.1.m1.1.1.2">ùëÖ</ci><cn id="S2.SS4.p4.1.m1.1.1.3.cmml" type="integer" xref="S2.SS4.p4.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p4.1.m1.1c">R^{2}</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p4.1.m1.1d">italic_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math> in every trial. This corresponds to the material knowledge that these properties are not related to synthesis conditions. The last property of framework density is mostly predictable with synthesis conditions, with all positive <math alttext="R^{2}" class="ltx_Math" display="inline" id="S2.SS4.p4.2.m2.1"><semantics id="S2.SS4.p4.2.m2.1a"><msup id="S2.SS4.p4.2.m2.1.1" xref="S2.SS4.p4.2.m2.1.1.cmml"><mi id="S2.SS4.p4.2.m2.1.1.2" xref="S2.SS4.p4.2.m2.1.1.2.cmml">R</mi><mn id="S2.SS4.p4.2.m2.1.1.3" xref="S2.SS4.p4.2.m2.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S2.SS4.p4.2.m2.1b"><apply id="S2.SS4.p4.2.m2.1.1.cmml" xref="S2.SS4.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS4.p4.2.m2.1.1.1.cmml" xref="S2.SS4.p4.2.m2.1.1">superscript</csymbol><ci id="S2.SS4.p4.2.m2.1.1.2.cmml" xref="S2.SS4.p4.2.m2.1.1.2">ùëÖ</ci><cn id="S2.SS4.p4.2.m2.1.1.3.cmml" type="integer" xref="S2.SS4.p4.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p4.2.m2.1c">R^{2}</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p4.2.m2.1d">italic_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math> values larger than 0.2. This also validates the fact that MOFs density is highly correlated with the metal and organic precursors used in MOFs material synthesis, as well as the reaction duration and temperature.</p>
</div>
<div class="ltx_para" id="S2.SS4.p5">
<p class="ltx_p" id="S2.SS4.p5.4">The <math alttext="R^{2}" class="ltx_Math" display="inline" id="S2.SS4.p5.1.m1.1"><semantics id="S2.SS4.p5.1.m1.1a"><msup id="S2.SS4.p5.1.m1.1.1" xref="S2.SS4.p5.1.m1.1.1.cmml"><mi id="S2.SS4.p5.1.m1.1.1.2" xref="S2.SS4.p5.1.m1.1.1.2.cmml">R</mi><mn id="S2.SS4.p5.1.m1.1.1.3" xref="S2.SS4.p5.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S2.SS4.p5.1.m1.1b"><apply id="S2.SS4.p5.1.m1.1.1.cmml" xref="S2.SS4.p5.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS4.p5.1.m1.1.1.1.cmml" xref="S2.SS4.p5.1.m1.1.1">superscript</csymbol><ci id="S2.SS4.p5.1.m1.1.1.2.cmml" xref="S2.SS4.p5.1.m1.1.1.2">ùëÖ</ci><cn id="S2.SS4.p5.1.m1.1.1.3.cmml" type="integer" xref="S2.SS4.p5.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p5.1.m1.1c">R^{2}</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p5.1.m1.1d">italic_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math> metrics on MOFs density inference by the two LLM models is given in Table <a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S2.T3" title="Table 3 ‚Ä£ 2.4 MOFs Structure Inference ‚Ä£ 2 Results ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_tag">3</span></a>. It can be seen that the synthesis conditions obtained by the few-shot method enjoy much higher predictive power than those obtained by the zero-shot method, in all six machine learning models. The average <math alttext="R^{2}" class="ltx_Math" display="inline" id="S2.SS4.p5.2.m2.1"><semantics id="S2.SS4.p5.2.m2.1a"><msup id="S2.SS4.p5.2.m2.1.1" xref="S2.SS4.p5.2.m2.1.1.cmml"><mi id="S2.SS4.p5.2.m2.1.1.2" xref="S2.SS4.p5.2.m2.1.1.2.cmml">R</mi><mn id="S2.SS4.p5.2.m2.1.1.3" xref="S2.SS4.p5.2.m2.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S2.SS4.p5.2.m2.1b"><apply id="S2.SS4.p5.2.m2.1.1.cmml" xref="S2.SS4.p5.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS4.p5.2.m2.1.1.1.cmml" xref="S2.SS4.p5.2.m2.1.1">superscript</csymbol><ci id="S2.SS4.p5.2.m2.1.1.2.cmml" xref="S2.SS4.p5.2.m2.1.1.2">ùëÖ</ci><cn id="S2.SS4.p5.2.m2.1.1.3.cmml" type="integer" xref="S2.SS4.p5.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p5.2.m2.1c">R^{2}</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p5.2.m2.1d">italic_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math> value of zero-shot is only 77.3% of that of the proposed few-shot method. Among the six models, XGBoost achieves best performance, an <math alttext="R^{2}" class="ltx_Math" display="inline" id="S2.SS4.p5.3.m3.1"><semantics id="S2.SS4.p5.3.m3.1a"><msup id="S2.SS4.p5.3.m3.1.1" xref="S2.SS4.p5.3.m3.1.1.cmml"><mi id="S2.SS4.p5.3.m3.1.1.2" xref="S2.SS4.p5.3.m3.1.1.2.cmml">R</mi><mn id="S2.SS4.p5.3.m3.1.1.3" xref="S2.SS4.p5.3.m3.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S2.SS4.p5.3.m3.1b"><apply id="S2.SS4.p5.3.m3.1.1.cmml" xref="S2.SS4.p5.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS4.p5.3.m3.1.1.1.cmml" xref="S2.SS4.p5.3.m3.1.1">superscript</csymbol><ci id="S2.SS4.p5.3.m3.1.1.2.cmml" xref="S2.SS4.p5.3.m3.1.1.2">ùëÖ</ci><cn id="S2.SS4.p5.3.m3.1.1.3.cmml" type="integer" xref="S2.SS4.p5.3.m3.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p5.3.m3.1c">R^{2}</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p5.3.m3.1d">italic_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math> of 0.4421 on the test set for the few-shot synthesis conditions, and a relatively lower <math alttext="R^{2}" class="ltx_Math" display="inline" id="S2.SS4.p5.4.m4.1"><semantics id="S2.SS4.p5.4.m4.1a"><msup id="S2.SS4.p5.4.m4.1.1" xref="S2.SS4.p5.4.m4.1.1.cmml"><mi id="S2.SS4.p5.4.m4.1.1.2" xref="S2.SS4.p5.4.m4.1.1.2.cmml">R</mi><mn id="S2.SS4.p5.4.m4.1.1.3" xref="S2.SS4.p5.4.m4.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S2.SS4.p5.4.m4.1b"><apply id="S2.SS4.p5.4.m4.1.1.cmml" xref="S2.SS4.p5.4.m4.1.1"><csymbol cd="ambiguous" id="S2.SS4.p5.4.m4.1.1.1.cmml" xref="S2.SS4.p5.4.m4.1.1">superscript</csymbol><ci id="S2.SS4.p5.4.m4.1.1.2.cmml" xref="S2.SS4.p5.4.m4.1.1.2">ùëÖ</ci><cn id="S2.SS4.p5.4.m4.1.1.3.cmml" type="integer" xref="S2.SS4.p5.4.m4.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p5.4.m4.1c">R^{2}</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p5.4.m4.1d">italic_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math> of 0.3559 on the test set for the zero-shot method. We illustrate the inference result by XGBoost on the scatterplot of Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S2.F8" title="Figure 8 ‚Ä£ 2.4 MOFs Structure Inference ‚Ä£ 2 Results ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_tag">8</span></a>(a). It shows that the actual vs. predicted distribution of the few-shot method (green dots) preserves higher affinity to the optimal prediction line (red dashed line), than the predictions by zero-shot method (blue dots). The result demonstrates that the proposed few-shot method not only extracts more accurate synthesis conditions in comparison to the baseline, but also significantly improves the performance of downstream material inference tasks.</p>
</div>
<figure class="ltx_figure" id="S2.F8"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="325" id="S2.F8.g1" src="x8.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Performance on MOFs structure inference task: (a) predictive power of the best XGBoost model, few-shot vs. zero-shot; (b) comparison of <math alttext="R^{2}" class="ltx_Math" display="inline" id="S2.F8.2.m1.1"><semantics id="S2.F8.2.m1.1b"><msup id="S2.F8.2.m1.1.1" xref="S2.F8.2.m1.1.1.cmml"><mi id="S2.F8.2.m1.1.1.2" xref="S2.F8.2.m1.1.1.2.cmml">R</mi><mn id="S2.F8.2.m1.1.1.3" xref="S2.F8.2.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S2.F8.2.m1.1c"><apply id="S2.F8.2.m1.1.1.cmml" xref="S2.F8.2.m1.1.1"><csymbol cd="ambiguous" id="S2.F8.2.m1.1.1.1.cmml" xref="S2.F8.2.m1.1.1">superscript</csymbol><ci id="S2.F8.2.m1.1.1.2.cmml" xref="S2.F8.2.m1.1.1.2">ùëÖ</ci><cn id="S2.F8.2.m1.1.1.3.cmml" type="integer" xref="S2.F8.2.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.F8.2.m1.1d">R^{2}</annotation><annotation encoding="application/x-llamapun" id="S2.F8.2.m1.1e">italic_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math> values and data counts across different data filters.</figcaption>
</figure>
<div class="ltx_para" id="S2.SS4.p6">
<p class="ltx_p" id="S2.SS4.p6.2">To further showcase the superiority of the few-shot method, we conducted more trials using the best-performing model, XGBoost. We gradually reduce the test dataset into more densely distributed synthesis conditions, by enforcing stricter data filters and selecting only higher-ranked synthesis condition values. The XGBoost model is tuned with the best hyperparameters on each dataset following the method by Akiba et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#bib.bib4" title="">4</a>]</cite>. As shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S2.F8" title="Figure 8 ‚Ä£ 2.4 MOFs Structure Inference ‚Ä£ 2 Results ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_tag">8</span></a>(b), when the test dataset increases with more conditions, the <math alttext="R^{2}" class="ltx_Math" display="inline" id="S2.SS4.p6.1.m1.1"><semantics id="S2.SS4.p6.1.m1.1a"><msup id="S2.SS4.p6.1.m1.1.1" xref="S2.SS4.p6.1.m1.1.1.cmml"><mi id="S2.SS4.p6.1.m1.1.1.2" xref="S2.SS4.p6.1.m1.1.1.2.cmml">R</mi><mn id="S2.SS4.p6.1.m1.1.1.3" xref="S2.SS4.p6.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S2.SS4.p6.1.m1.1b"><apply id="S2.SS4.p6.1.m1.1.1.cmml" xref="S2.SS4.p6.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS4.p6.1.m1.1.1.1.cmml" xref="S2.SS4.p6.1.m1.1.1">superscript</csymbol><ci id="S2.SS4.p6.1.m1.1.1.2.cmml" xref="S2.SS4.p6.1.m1.1.1.2">ùëÖ</ci><cn id="S2.SS4.p6.1.m1.1.1.3.cmml" type="integer" xref="S2.SS4.p6.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p6.1.m1.1c">R^{2}</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p6.1.m1.1d">italic_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math> of predictive models by few-shot method rises quickly while the <math alttext="R^{2}" class="ltx_Math" display="inline" id="S2.SS4.p6.2.m2.1"><semantics id="S2.SS4.p6.2.m2.1a"><msup id="S2.SS4.p6.2.m2.1.1" xref="S2.SS4.p6.2.m2.1.1.cmml"><mi id="S2.SS4.p6.2.m2.1.1.2" xref="S2.SS4.p6.2.m2.1.1.2.cmml">R</mi><mn id="S2.SS4.p6.2.m2.1.1.3" xref="S2.SS4.p6.2.m2.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S2.SS4.p6.2.m2.1b"><apply id="S2.SS4.p6.2.m2.1.1.cmml" xref="S2.SS4.p6.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS4.p6.2.m2.1.1.1.cmml" xref="S2.SS4.p6.2.m2.1.1">superscript</csymbol><ci id="S2.SS4.p6.2.m2.1.1.2.cmml" xref="S2.SS4.p6.2.m2.1.1.2">ùëÖ</ci><cn id="S2.SS4.p6.2.m2.1.1.3.cmml" type="integer" xref="S2.SS4.p6.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p6.2.m2.1c">R^{2}</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p6.2.m2.1d">italic_R start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math> of zero-shot method stays stable or rises much slowly. The gap between the two methods widens as the dataset includes more unique conditions. Meanwhile, the data size by the number of MOFs used remains comparable between the two methods in every setting, as indicated by the grouped bar charts in Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S2.F8" title="Figure 8 ‚Ä£ 2.4 MOFs Structure Inference ‚Ä£ 2 Results ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_tag">8</span></a>(b). The result indicates that considering less frequently appearing synthesis conditions will significantly improve the accuracy of material structure inference when the few-shot method is applied. In contrast, the zero-shot method showed a steady trend in predictive performance. This also reveals the superior performance of the few-shot method in downstream material inference task compared to the zero-shot method.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Methods</h2>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Synthesis paragraph detection</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">To train a machine learning model for binary classification to determine whether a paragraph is synthesized, we randomly obtained 440 papers from the database in Appendix A for annotation. Each paper was annotated by two different annotators to ensure inner annotator agreement. The 880 annotation tasks were assigned to four annotators who used our platform, shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S5.F9" title="Figure 9 ‚Ä£ 5.2 Annotation Procedure for Synthesis Paragraphs and Synthesis Conditions ‚Ä£ 5 Appendix ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_tag">9</span></a>, to annotate synthesis-related paragraphs. After annotation, only paragraphs annotated by both annotators were considered valid, while paragraphs annotated by only one annotator were discarded. If there was an overlap in the positions of the paragraphs annotated by the two annotators, we found that mismatched paragraphs often occurred because one annotator noted more synthesis parameters and thus marked a larger range. In such cases, the larger annotated paragraph was considered valid. This method also resolved minor annotation deviations within a few characters, allowing two slightly different synthesis paragraphs to be considered valid. This process yielded 1,349 valid annotated paragraphs.</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1">To train the discrimination model, non-synthesis paragraphs were needed as negative samples. After removing all annotated paragraphs from a paper, the remaining paragraphs served as negative samples. This method resulted in 11,783 negative samples. We employed the standard BERT model, specifically the pre-trained <span class="ltx_text ltx_font_typewriter" id="S3.SS1.p2.1.1">bert-base-uncased</span> model from HuggingFace, for training. The training and validation processes utilized a 5-fold cross-validation method (<math alttext="k=5" class="ltx_Math" display="inline" id="S3.SS1.p2.1.m1.1"><semantics id="S3.SS1.p2.1.m1.1a"><mrow id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml"><mi id="S3.SS1.p2.1.m1.1.1.2" xref="S3.SS1.p2.1.m1.1.1.2.cmml">k</mi><mo id="S3.SS1.p2.1.m1.1.1.1" xref="S3.SS1.p2.1.m1.1.1.1.cmml">=</mo><mn id="S3.SS1.p2.1.m1.1.1.3" xref="S3.SS1.p2.1.m1.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><apply id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1"><eq id="S3.SS1.p2.1.m1.1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1.1"></eq><ci id="S3.SS1.p2.1.m1.1.1.2.cmml" xref="S3.SS1.p2.1.m1.1.1.2">ùëò</ci><cn id="S3.SS1.p2.1.m1.1.1.3.cmml" type="integer" xref="S3.SS1.p2.1.m1.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">k=5</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.1.m1.1d">italic_k = 5</annotation></semantics></math>). Given the imbalance dataset, we used stratified k-fold cross-validation to ensure that the ratio of positive to negative samples remained consistent in each split. After training and cross-validation testing, the model‚Äôs evaluation metrics were as follows: Accuracy = 0.989, Precision = 0.955, Recall = 0.947, and F1 Score = 0.951. The trained model achieved high overall accuracy and can be used for synthesized paragraph classification in extracted paragraphs, which will facilitate subsequent chemical named entity recognition tasks.</p>
</div>
<div class="ltx_para" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.1">The results of applying the model to our MOFs dataset in Appendix A are as follows: According to statistics, the dataset contains a total of 36,233 DOIs, corresponding to 78,741 MOF-IDs. Among these, 21,031 DOIs can be used to extract synthesis paragraphs, and 22,461 DOIs remain one DOI corresponding to one MOF-ID. The intersection of these two sets contains 9,855 DOIs. Further filtering for DOIs that contain only one synthesis paragraph results in 5,269 DOIs. In other words, we extracted 5,269 valid synthesis paragraphs from the complete dataset.</p>
</div>
<div class="ltx_para" id="S3.SS1.p4">
<p class="ltx_p" id="S3.SS1.p4.1">Paragraphs related to the synthesis process constitute only about 2% of an article‚Äôs total length but concentrate the main synthesis condition. Extracting condition from synthesized paragraphs, rather than the entire text, can significantly reduce the model‚Äôs extraction overhead and increase the density of field distribution, thereby enhancing data quality.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Few-Shot RAG Algorithms</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.4">To maximize the extraction performance of the model, we provide examples of extraction by human-AI annotation as demonstrations. By using a retrieve <math alttext="K" class="ltx_Math" display="inline" id="S3.SS2.p1.1.m1.1"><semantics id="S3.SS2.p1.1.m1.1a"><mi id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><ci id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">ùêæ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">K</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.1.m1.1d">italic_K</annotation></semantics></math> demonstrations, the performance of LLMs in extracting synthesis conditions on MOFs can be further improved¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#bib.bib9" title="">9</a>, <a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#bib.bib12" title="">12</a>, <a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#bib.bib19" title="">19</a>]</cite>. Given the set of demonstrations <math alttext="D={d_{1},d_{2},\ldots,d_{n}}" class="ltx_Math" display="inline" id="S3.SS2.p1.2.m2.4"><semantics id="S3.SS2.p1.2.m2.4a"><mrow id="S3.SS2.p1.2.m2.4.4" xref="S3.SS2.p1.2.m2.4.4.cmml"><mi id="S3.SS2.p1.2.m2.4.4.5" xref="S3.SS2.p1.2.m2.4.4.5.cmml">D</mi><mo id="S3.SS2.p1.2.m2.4.4.4" xref="S3.SS2.p1.2.m2.4.4.4.cmml">=</mo><mrow id="S3.SS2.p1.2.m2.4.4.3.3" xref="S3.SS2.p1.2.m2.4.4.3.4.cmml"><msub id="S3.SS2.p1.2.m2.2.2.1.1.1" xref="S3.SS2.p1.2.m2.2.2.1.1.1.cmml"><mi id="S3.SS2.p1.2.m2.2.2.1.1.1.2" xref="S3.SS2.p1.2.m2.2.2.1.1.1.2.cmml">d</mi><mn id="S3.SS2.p1.2.m2.2.2.1.1.1.3" xref="S3.SS2.p1.2.m2.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S3.SS2.p1.2.m2.4.4.3.3.4" xref="S3.SS2.p1.2.m2.4.4.3.4.cmml">,</mo><msub id="S3.SS2.p1.2.m2.3.3.2.2.2" xref="S3.SS2.p1.2.m2.3.3.2.2.2.cmml"><mi id="S3.SS2.p1.2.m2.3.3.2.2.2.2" xref="S3.SS2.p1.2.m2.3.3.2.2.2.2.cmml">d</mi><mn id="S3.SS2.p1.2.m2.3.3.2.2.2.3" xref="S3.SS2.p1.2.m2.3.3.2.2.2.3.cmml">2</mn></msub><mo id="S3.SS2.p1.2.m2.4.4.3.3.5" xref="S3.SS2.p1.2.m2.4.4.3.4.cmml">,</mo><mi id="S3.SS2.p1.2.m2.1.1" mathvariant="normal" xref="S3.SS2.p1.2.m2.1.1.cmml">‚Ä¶</mi><mo id="S3.SS2.p1.2.m2.4.4.3.3.6" xref="S3.SS2.p1.2.m2.4.4.3.4.cmml">,</mo><msub id="S3.SS2.p1.2.m2.4.4.3.3.3" xref="S3.SS2.p1.2.m2.4.4.3.3.3.cmml"><mi id="S3.SS2.p1.2.m2.4.4.3.3.3.2" xref="S3.SS2.p1.2.m2.4.4.3.3.3.2.cmml">d</mi><mi id="S3.SS2.p1.2.m2.4.4.3.3.3.3" xref="S3.SS2.p1.2.m2.4.4.3.3.3.3.cmml">n</mi></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.4b"><apply id="S3.SS2.p1.2.m2.4.4.cmml" xref="S3.SS2.p1.2.m2.4.4"><eq id="S3.SS2.p1.2.m2.4.4.4.cmml" xref="S3.SS2.p1.2.m2.4.4.4"></eq><ci id="S3.SS2.p1.2.m2.4.4.5.cmml" xref="S3.SS2.p1.2.m2.4.4.5">ùê∑</ci><list id="S3.SS2.p1.2.m2.4.4.3.4.cmml" xref="S3.SS2.p1.2.m2.4.4.3.3"><apply id="S3.SS2.p1.2.m2.2.2.1.1.1.cmml" xref="S3.SS2.p1.2.m2.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.2.m2.2.2.1.1.1.1.cmml" xref="S3.SS2.p1.2.m2.2.2.1.1.1">subscript</csymbol><ci id="S3.SS2.p1.2.m2.2.2.1.1.1.2.cmml" xref="S3.SS2.p1.2.m2.2.2.1.1.1.2">ùëë</ci><cn id="S3.SS2.p1.2.m2.2.2.1.1.1.3.cmml" type="integer" xref="S3.SS2.p1.2.m2.2.2.1.1.1.3">1</cn></apply><apply id="S3.SS2.p1.2.m2.3.3.2.2.2.cmml" xref="S3.SS2.p1.2.m2.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p1.2.m2.3.3.2.2.2.1.cmml" xref="S3.SS2.p1.2.m2.3.3.2.2.2">subscript</csymbol><ci id="S3.SS2.p1.2.m2.3.3.2.2.2.2.cmml" xref="S3.SS2.p1.2.m2.3.3.2.2.2.2">ùëë</ci><cn id="S3.SS2.p1.2.m2.3.3.2.2.2.3.cmml" type="integer" xref="S3.SS2.p1.2.m2.3.3.2.2.2.3">2</cn></apply><ci id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">‚Ä¶</ci><apply id="S3.SS2.p1.2.m2.4.4.3.3.3.cmml" xref="S3.SS2.p1.2.m2.4.4.3.3.3"><csymbol cd="ambiguous" id="S3.SS2.p1.2.m2.4.4.3.3.3.1.cmml" xref="S3.SS2.p1.2.m2.4.4.3.3.3">subscript</csymbol><ci id="S3.SS2.p1.2.m2.4.4.3.3.3.2.cmml" xref="S3.SS2.p1.2.m2.4.4.3.3.3.2">ùëë</ci><ci id="S3.SS2.p1.2.m2.4.4.3.3.3.3.cmml" xref="S3.SS2.p1.2.m2.4.4.3.3.3.3">ùëõ</ci></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.4c">D={d_{1},d_{2},\ldots,d_{n}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.2.m2.4d">italic_D = italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , ‚Ä¶ , italic_d start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT</annotation></semantics></math> and an input paragraph <math alttext="p" class="ltx_Math" display="inline" id="S3.SS2.p1.3.m3.1"><semantics id="S3.SS2.p1.3.m3.1a"><mi id="S3.SS2.p1.3.m3.1.1" xref="S3.SS2.p1.3.m3.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m3.1b"><ci id="S3.SS2.p1.3.m3.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1">ùëù</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m3.1c">p</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.3.m3.1d">italic_p</annotation></semantics></math>, the top <math alttext="K" class="ltx_Math" display="inline" id="S3.SS2.p1.4.m4.1"><semantics id="S3.SS2.p1.4.m4.1a"><mi id="S3.SS2.p1.4.m4.1.1" xref="S3.SS2.p1.4.m4.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.4.m4.1b"><ci id="S3.SS2.p1.4.m4.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1">ùêæ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.4.m4.1c">K</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.4.m4.1d">italic_K</annotation></semantics></math> similar demonstrations are obtained as:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\text{Top-K}=\text{sort}({(\text{score}(p,d_{i}),d_{i})}^{n}_{i=1})[:k]" class="ltx_math_unparsed" display="block" id="S3.E1.m1.1"><semantics id="S3.E1.m1.1a"><mrow id="S3.E1.m1.1b"><mtext id="S3.E1.m1.1.2">Top-K</mtext><mo id="S3.E1.m1.1.3">=</mo><mtext id="S3.E1.m1.1.4">sort</mtext><mrow id="S3.E1.m1.1.5"><mo id="S3.E1.m1.1.5.1" stretchy="false">(</mo><msubsup id="S3.E1.m1.1.5.2"><mrow id="S3.E1.m1.1.5.2.2.2"><mo id="S3.E1.m1.1.5.2.2.2.1" stretchy="false">(</mo><mtext id="S3.E1.m1.1.5.2.2.2.2">score</mtext><mrow id="S3.E1.m1.1.5.2.2.2.3"><mo id="S3.E1.m1.1.5.2.2.2.3.1" stretchy="false">(</mo><mi id="S3.E1.m1.1.1">p</mi><mo id="S3.E1.m1.1.5.2.2.2.3.2">,</mo><msub id="S3.E1.m1.1.5.2.2.2.3.3"><mi id="S3.E1.m1.1.5.2.2.2.3.3.2">d</mi><mi id="S3.E1.m1.1.5.2.2.2.3.3.3">i</mi></msub><mo id="S3.E1.m1.1.5.2.2.2.3.4" stretchy="false">)</mo></mrow><mo id="S3.E1.m1.1.5.2.2.2.4">,</mo><msub id="S3.E1.m1.1.5.2.2.2.5"><mi id="S3.E1.m1.1.5.2.2.2.5.2">d</mi><mi id="S3.E1.m1.1.5.2.2.2.5.3">i</mi></msub><mo id="S3.E1.m1.1.5.2.2.2.6" stretchy="false">)</mo></mrow><mrow id="S3.E1.m1.1.5.2.3"><mi id="S3.E1.m1.1.5.2.3.2">i</mi><mo id="S3.E1.m1.1.5.2.3.1">=</mo><mn id="S3.E1.m1.1.5.2.3.3">1</mn></mrow><mi id="S3.E1.m1.1.5.2.2.3">n</mi></msubsup><mo id="S3.E1.m1.1.5.3" stretchy="false">)</mo></mrow><mrow id="S3.E1.m1.1.6"><mo id="S3.E1.m1.1.6.1" stretchy="false">[</mo><mo id="S3.E1.m1.1.6.2" rspace="0.278em">:</mo><mi id="S3.E1.m1.1.6.3">k</mi><mo id="S3.E1.m1.1.6.4" stretchy="false">]</mo></mrow></mrow><annotation encoding="application/x-tex" id="S3.E1.m1.1c">\text{Top-K}=\text{sort}({(\text{score}(p,d_{i}),d_{i})}^{n}_{i=1})[:k]</annotation><annotation encoding="application/x-llamapun" id="S3.E1.m1.1d">Top-K = sort ( ( score ( italic_p , italic_d start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) , italic_d start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT ) [ : italic_k ]</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS2.p1.6">Here, the score is used to estimate the similarity between the embeddings of document <math alttext="d_{i}" class="ltx_Math" display="inline" id="S3.SS2.p1.5.m1.1"><semantics id="S3.SS2.p1.5.m1.1a"><msub id="S3.SS2.p1.5.m1.1.1" xref="S3.SS2.p1.5.m1.1.1.cmml"><mi id="S3.SS2.p1.5.m1.1.1.2" xref="S3.SS2.p1.5.m1.1.1.2.cmml">d</mi><mi id="S3.SS2.p1.5.m1.1.1.3" xref="S3.SS2.p1.5.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.5.m1.1b"><apply id="S3.SS2.p1.5.m1.1.1.cmml" xref="S3.SS2.p1.5.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.5.m1.1.1.1.cmml" xref="S3.SS2.p1.5.m1.1.1">subscript</csymbol><ci id="S3.SS2.p1.5.m1.1.1.2.cmml" xref="S3.SS2.p1.5.m1.1.1.2">ùëë</ci><ci id="S3.SS2.p1.5.m1.1.1.3.cmml" xref="S3.SS2.p1.5.m1.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.5.m1.1c">d_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.5.m1.1d">italic_d start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> and paragraph <math alttext="p" class="ltx_Math" display="inline" id="S3.SS2.p1.6.m2.1"><semantics id="S3.SS2.p1.6.m2.1a"><mi id="S3.SS2.p1.6.m2.1.1" xref="S3.SS2.p1.6.m2.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.6.m2.1b"><ci id="S3.SS2.p1.6.m2.1.1.cmml" xref="S3.SS2.p1.6.m2.1.1">ùëù</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.6.m2.1c">p</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.6.m2.1d">italic_p</annotation></semantics></math>. The embedding models can be categorized into traditional sparse vector encoders (e.g., TF-IDF, BM25¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#bib.bib18" title="">18</a>]</cite>) and semantic dense vector encoders (e.g., SBERT¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#bib.bib17" title="">17</a>, <a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#bib.bib8" title="">8</a>]</cite>)¬†<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#bib.bib10" title="">10</a>]</cite>. In our experiments, we compared these two classes of retrieval methods and selected the one that performed best as the final approach.</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1">For the traditional sparse vector retrieval method, we use the BM25 algorithm. BM25 is a probabilistic information retrieval model that ranks documents based on the frequency of query terms within the documents. It balances term frequency (how often a term appears in a document) with inverse document frequency (how rare a term is across the entire document set), thus giving more weight to terms that are significant. The scoring function is defined as:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\text{Score}(p,d)=\sum_{i=1}^{n}\text{IDF}(p_{i})\cdot\frac{f(p_{i},d)\cdot(k_%
{1}+1)}{f(p_{i},d)+k_{1}\cdot(1-b+b\cdot\frac{|d|}{\text{avg\_dl}})}" class="ltx_Math" display="block" id="S3.E2.m1.10"><semantics id="S3.E2.m1.10a"><mrow id="S3.E2.m1.10.10" xref="S3.E2.m1.10.10.cmml"><mrow id="S3.E2.m1.10.10.3" xref="S3.E2.m1.10.10.3.cmml"><mtext id="S3.E2.m1.10.10.3.2" xref="S3.E2.m1.10.10.3.2a.cmml">Score</mtext><mo id="S3.E2.m1.10.10.3.1" xref="S3.E2.m1.10.10.3.1.cmml">‚Å¢</mo><mrow id="S3.E2.m1.10.10.3.3.2" xref="S3.E2.m1.10.10.3.3.1.cmml"><mo id="S3.E2.m1.10.10.3.3.2.1" stretchy="false" xref="S3.E2.m1.10.10.3.3.1.cmml">(</mo><mi id="S3.E2.m1.8.8" xref="S3.E2.m1.8.8.cmml">p</mi><mo id="S3.E2.m1.10.10.3.3.2.2" xref="S3.E2.m1.10.10.3.3.1.cmml">,</mo><mi id="S3.E2.m1.9.9" xref="S3.E2.m1.9.9.cmml">d</mi><mo id="S3.E2.m1.10.10.3.3.2.3" stretchy="false" xref="S3.E2.m1.10.10.3.3.1.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.10.10.2" rspace="0.111em" xref="S3.E2.m1.10.10.2.cmml">=</mo><mrow id="S3.E2.m1.10.10.1" xref="S3.E2.m1.10.10.1.cmml"><munderover id="S3.E2.m1.10.10.1.2" xref="S3.E2.m1.10.10.1.2.cmml"><mo id="S3.E2.m1.10.10.1.2.2.2" movablelimits="false" xref="S3.E2.m1.10.10.1.2.2.2.cmml">‚àë</mo><mrow id="S3.E2.m1.10.10.1.2.2.3" xref="S3.E2.m1.10.10.1.2.2.3.cmml"><mi id="S3.E2.m1.10.10.1.2.2.3.2" xref="S3.E2.m1.10.10.1.2.2.3.2.cmml">i</mi><mo id="S3.E2.m1.10.10.1.2.2.3.1" xref="S3.E2.m1.10.10.1.2.2.3.1.cmml">=</mo><mn id="S3.E2.m1.10.10.1.2.2.3.3" xref="S3.E2.m1.10.10.1.2.2.3.3.cmml">1</mn></mrow><mi id="S3.E2.m1.10.10.1.2.3" xref="S3.E2.m1.10.10.1.2.3.cmml">n</mi></munderover><mrow id="S3.E2.m1.10.10.1.1" xref="S3.E2.m1.10.10.1.1.cmml"><mrow id="S3.E2.m1.10.10.1.1.1" xref="S3.E2.m1.10.10.1.1.1.cmml"><mtext id="S3.E2.m1.10.10.1.1.1.3" xref="S3.E2.m1.10.10.1.1.1.3a.cmml">IDF</mtext><mo id="S3.E2.m1.10.10.1.1.1.2" xref="S3.E2.m1.10.10.1.1.1.2.cmml">‚Å¢</mo><mrow id="S3.E2.m1.10.10.1.1.1.1.1" xref="S3.E2.m1.10.10.1.1.1.1.1.1.cmml"><mo id="S3.E2.m1.10.10.1.1.1.1.1.2" stretchy="false" xref="S3.E2.m1.10.10.1.1.1.1.1.1.cmml">(</mo><msub id="S3.E2.m1.10.10.1.1.1.1.1.1" xref="S3.E2.m1.10.10.1.1.1.1.1.1.cmml"><mi id="S3.E2.m1.10.10.1.1.1.1.1.1.2" xref="S3.E2.m1.10.10.1.1.1.1.1.1.2.cmml">p</mi><mi id="S3.E2.m1.10.10.1.1.1.1.1.1.3" xref="S3.E2.m1.10.10.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.E2.m1.10.10.1.1.1.1.1.3" rspace="0.055em" stretchy="false" xref="S3.E2.m1.10.10.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.10.10.1.1.2" rspace="0.222em" xref="S3.E2.m1.10.10.1.1.2.cmml">‚ãÖ</mo><mfrac id="S3.E2.m1.7.7" xref="S3.E2.m1.7.7.cmml"><mrow id="S3.E2.m1.3.3.3" xref="S3.E2.m1.3.3.3.cmml"><mrow id="S3.E2.m1.2.2.2.2" xref="S3.E2.m1.2.2.2.2.cmml"><mi id="S3.E2.m1.2.2.2.2.3" xref="S3.E2.m1.2.2.2.2.3.cmml">f</mi><mo id="S3.E2.m1.2.2.2.2.2" xref="S3.E2.m1.2.2.2.2.2.cmml">‚Å¢</mo><mrow id="S3.E2.m1.2.2.2.2.1.1" xref="S3.E2.m1.2.2.2.2.1.2.cmml"><mo id="S3.E2.m1.2.2.2.2.1.1.2" stretchy="false" xref="S3.E2.m1.2.2.2.2.1.2.cmml">(</mo><msub id="S3.E2.m1.2.2.2.2.1.1.1" xref="S3.E2.m1.2.2.2.2.1.1.1.cmml"><mi id="S3.E2.m1.2.2.2.2.1.1.1.2" xref="S3.E2.m1.2.2.2.2.1.1.1.2.cmml">p</mi><mi id="S3.E2.m1.2.2.2.2.1.1.1.3" xref="S3.E2.m1.2.2.2.2.1.1.1.3.cmml">i</mi></msub><mo id="S3.E2.m1.2.2.2.2.1.1.3" xref="S3.E2.m1.2.2.2.2.1.2.cmml">,</mo><mi id="S3.E2.m1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.cmml">d</mi><mo id="S3.E2.m1.2.2.2.2.1.1.4" rspace="0.055em" stretchy="false" xref="S3.E2.m1.2.2.2.2.1.2.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.3.3.3.4" rspace="0.222em" xref="S3.E2.m1.3.3.3.4.cmml">‚ãÖ</mo><mrow id="S3.E2.m1.3.3.3.3.1" xref="S3.E2.m1.3.3.3.3.1.1.cmml"><mo id="S3.E2.m1.3.3.3.3.1.2" stretchy="false" xref="S3.E2.m1.3.3.3.3.1.1.cmml">(</mo><mrow id="S3.E2.m1.3.3.3.3.1.1" xref="S3.E2.m1.3.3.3.3.1.1.cmml"><msub id="S3.E2.m1.3.3.3.3.1.1.2" xref="S3.E2.m1.3.3.3.3.1.1.2.cmml"><mi id="S3.E2.m1.3.3.3.3.1.1.2.2" xref="S3.E2.m1.3.3.3.3.1.1.2.2.cmml">k</mi><mn id="S3.E2.m1.3.3.3.3.1.1.2.3" xref="S3.E2.m1.3.3.3.3.1.1.2.3.cmml">1</mn></msub><mo id="S3.E2.m1.3.3.3.3.1.1.1" xref="S3.E2.m1.3.3.3.3.1.1.1.cmml">+</mo><mn id="S3.E2.m1.3.3.3.3.1.1.3" xref="S3.E2.m1.3.3.3.3.1.1.3.cmml">1</mn></mrow><mo id="S3.E2.m1.3.3.3.3.1.3" stretchy="false" xref="S3.E2.m1.3.3.3.3.1.1.cmml">)</mo></mrow></mrow><mrow id="S3.E2.m1.7.7.7" xref="S3.E2.m1.7.7.7.cmml"><mrow id="S3.E2.m1.6.6.6.3" xref="S3.E2.m1.6.6.6.3.cmml"><mi id="S3.E2.m1.6.6.6.3.3" xref="S3.E2.m1.6.6.6.3.3.cmml">f</mi><mo id="S3.E2.m1.6.6.6.3.2" xref="S3.E2.m1.6.6.6.3.2.cmml">‚Å¢</mo><mrow id="S3.E2.m1.6.6.6.3.1.1" xref="S3.E2.m1.6.6.6.3.1.2.cmml"><mo id="S3.E2.m1.6.6.6.3.1.1.2" stretchy="false" xref="S3.E2.m1.6.6.6.3.1.2.cmml">(</mo><msub id="S3.E2.m1.6.6.6.3.1.1.1" xref="S3.E2.m1.6.6.6.3.1.1.1.cmml"><mi id="S3.E2.m1.6.6.6.3.1.1.1.2" xref="S3.E2.m1.6.6.6.3.1.1.1.2.cmml">p</mi><mi id="S3.E2.m1.6.6.6.3.1.1.1.3" xref="S3.E2.m1.6.6.6.3.1.1.1.3.cmml">i</mi></msub><mo id="S3.E2.m1.6.6.6.3.1.1.3" xref="S3.E2.m1.6.6.6.3.1.2.cmml">,</mo><mi id="S3.E2.m1.5.5.5.2" xref="S3.E2.m1.5.5.5.2.cmml">d</mi><mo id="S3.E2.m1.6.6.6.3.1.1.4" stretchy="false" xref="S3.E2.m1.6.6.6.3.1.2.cmml">)</mo></mrow></mrow><mo id="S3.E2.m1.7.7.7.5" xref="S3.E2.m1.7.7.7.5.cmml">+</mo><mrow id="S3.E2.m1.7.7.7.4" xref="S3.E2.m1.7.7.7.4.cmml"><msub id="S3.E2.m1.7.7.7.4.3" xref="S3.E2.m1.7.7.7.4.3.cmml"><mi id="S3.E2.m1.7.7.7.4.3.2" xref="S3.E2.m1.7.7.7.4.3.2.cmml">k</mi><mn id="S3.E2.m1.7.7.7.4.3.3" xref="S3.E2.m1.7.7.7.4.3.3.cmml">1</mn></msub><mo id="S3.E2.m1.7.7.7.4.2" lspace="0.222em" rspace="0.222em" xref="S3.E2.m1.7.7.7.4.2.cmml">‚ãÖ</mo><mrow id="S3.E2.m1.7.7.7.4.1.1" xref="S3.E2.m1.7.7.7.4.1.1.1.cmml"><mo id="S3.E2.m1.7.7.7.4.1.1.2" stretchy="false" xref="S3.E2.m1.7.7.7.4.1.1.1.cmml">(</mo><mrow id="S3.E2.m1.7.7.7.4.1.1.1" xref="S3.E2.m1.7.7.7.4.1.1.1.cmml"><mrow id="S3.E2.m1.7.7.7.4.1.1.1.2" xref="S3.E2.m1.7.7.7.4.1.1.1.2.cmml"><mn id="S3.E2.m1.7.7.7.4.1.1.1.2.2" xref="S3.E2.m1.7.7.7.4.1.1.1.2.2.cmml">1</mn><mo id="S3.E2.m1.7.7.7.4.1.1.1.2.1" xref="S3.E2.m1.7.7.7.4.1.1.1.2.1.cmml">‚àí</mo><mi id="S3.E2.m1.7.7.7.4.1.1.1.2.3" xref="S3.E2.m1.7.7.7.4.1.1.1.2.3.cmml">b</mi></mrow><mo id="S3.E2.m1.7.7.7.4.1.1.1.1" xref="S3.E2.m1.7.7.7.4.1.1.1.1.cmml">+</mo><mrow id="S3.E2.m1.7.7.7.4.1.1.1.3" xref="S3.E2.m1.7.7.7.4.1.1.1.3.cmml"><mi id="S3.E2.m1.7.7.7.4.1.1.1.3.2" xref="S3.E2.m1.7.7.7.4.1.1.1.3.2.cmml">b</mi><mo id="S3.E2.m1.7.7.7.4.1.1.1.3.1" lspace="0.222em" rspace="0.222em" xref="S3.E2.m1.7.7.7.4.1.1.1.3.1.cmml">‚ãÖ</mo><mfrac id="S3.E2.m1.4.4.4.1" xref="S3.E2.m1.4.4.4.1.cmml"><mrow id="S3.E2.m1.4.4.4.1.1.3" xref="S3.E2.m1.4.4.4.1.1.2.cmml"><mo id="S3.E2.m1.4.4.4.1.1.3.1" stretchy="false" xref="S3.E2.m1.4.4.4.1.1.2.1.cmml">|</mo><mi id="S3.E2.m1.4.4.4.1.1.1" xref="S3.E2.m1.4.4.4.1.1.1.cmml">d</mi><mo id="S3.E2.m1.4.4.4.1.1.3.2" stretchy="false" xref="S3.E2.m1.4.4.4.1.1.2.1.cmml">|</mo></mrow><mtext id="S3.E2.m1.4.4.4.1.3" xref="S3.E2.m1.4.4.4.1.3a.cmml">avg_dl</mtext></mfrac></mrow></mrow><mo id="S3.E2.m1.7.7.7.4.1.1.3" stretchy="false" xref="S3.E2.m1.7.7.7.4.1.1.1.cmml">)</mo></mrow></mrow></mrow></mfrac></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.10b"><apply id="S3.E2.m1.10.10.cmml" xref="S3.E2.m1.10.10"><eq id="S3.E2.m1.10.10.2.cmml" xref="S3.E2.m1.10.10.2"></eq><apply id="S3.E2.m1.10.10.3.cmml" xref="S3.E2.m1.10.10.3"><times id="S3.E2.m1.10.10.3.1.cmml" xref="S3.E2.m1.10.10.3.1"></times><ci id="S3.E2.m1.10.10.3.2a.cmml" xref="S3.E2.m1.10.10.3.2"><mtext id="S3.E2.m1.10.10.3.2.cmml" xref="S3.E2.m1.10.10.3.2">Score</mtext></ci><interval closure="open" id="S3.E2.m1.10.10.3.3.1.cmml" xref="S3.E2.m1.10.10.3.3.2"><ci id="S3.E2.m1.8.8.cmml" xref="S3.E2.m1.8.8">ùëù</ci><ci id="S3.E2.m1.9.9.cmml" xref="S3.E2.m1.9.9">ùëë</ci></interval></apply><apply id="S3.E2.m1.10.10.1.cmml" xref="S3.E2.m1.10.10.1"><apply id="S3.E2.m1.10.10.1.2.cmml" xref="S3.E2.m1.10.10.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.10.10.1.2.1.cmml" xref="S3.E2.m1.10.10.1.2">superscript</csymbol><apply id="S3.E2.m1.10.10.1.2.2.cmml" xref="S3.E2.m1.10.10.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.10.10.1.2.2.1.cmml" xref="S3.E2.m1.10.10.1.2">subscript</csymbol><sum id="S3.E2.m1.10.10.1.2.2.2.cmml" xref="S3.E2.m1.10.10.1.2.2.2"></sum><apply id="S3.E2.m1.10.10.1.2.2.3.cmml" xref="S3.E2.m1.10.10.1.2.2.3"><eq id="S3.E2.m1.10.10.1.2.2.3.1.cmml" xref="S3.E2.m1.10.10.1.2.2.3.1"></eq><ci id="S3.E2.m1.10.10.1.2.2.3.2.cmml" xref="S3.E2.m1.10.10.1.2.2.3.2">ùëñ</ci><cn id="S3.E2.m1.10.10.1.2.2.3.3.cmml" type="integer" xref="S3.E2.m1.10.10.1.2.2.3.3">1</cn></apply></apply><ci id="S3.E2.m1.10.10.1.2.3.cmml" xref="S3.E2.m1.10.10.1.2.3">ùëõ</ci></apply><apply id="S3.E2.m1.10.10.1.1.cmml" xref="S3.E2.m1.10.10.1.1"><ci id="S3.E2.m1.10.10.1.1.2.cmml" xref="S3.E2.m1.10.10.1.1.2">‚ãÖ</ci><apply id="S3.E2.m1.10.10.1.1.1.cmml" xref="S3.E2.m1.10.10.1.1.1"><times id="S3.E2.m1.10.10.1.1.1.2.cmml" xref="S3.E2.m1.10.10.1.1.1.2"></times><ci id="S3.E2.m1.10.10.1.1.1.3a.cmml" xref="S3.E2.m1.10.10.1.1.1.3"><mtext id="S3.E2.m1.10.10.1.1.1.3.cmml" xref="S3.E2.m1.10.10.1.1.1.3">IDF</mtext></ci><apply id="S3.E2.m1.10.10.1.1.1.1.1.1.cmml" xref="S3.E2.m1.10.10.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.10.10.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.10.10.1.1.1.1.1">subscript</csymbol><ci id="S3.E2.m1.10.10.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.10.10.1.1.1.1.1.1.2">ùëù</ci><ci id="S3.E2.m1.10.10.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.10.10.1.1.1.1.1.1.3">ùëñ</ci></apply></apply><apply id="S3.E2.m1.7.7.cmml" xref="S3.E2.m1.7.7"><divide id="S3.E2.m1.7.7.8.cmml" xref="S3.E2.m1.7.7"></divide><apply id="S3.E2.m1.3.3.3.cmml" xref="S3.E2.m1.3.3.3"><ci id="S3.E2.m1.3.3.3.4.cmml" xref="S3.E2.m1.3.3.3.4">‚ãÖ</ci><apply id="S3.E2.m1.2.2.2.2.cmml" xref="S3.E2.m1.2.2.2.2"><times id="S3.E2.m1.2.2.2.2.2.cmml" xref="S3.E2.m1.2.2.2.2.2"></times><ci id="S3.E2.m1.2.2.2.2.3.cmml" xref="S3.E2.m1.2.2.2.2.3">ùëì</ci><interval closure="open" id="S3.E2.m1.2.2.2.2.1.2.cmml" xref="S3.E2.m1.2.2.2.2.1.1"><apply id="S3.E2.m1.2.2.2.2.1.1.1.cmml" xref="S3.E2.m1.2.2.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.2.2.1.1.1.1.cmml" xref="S3.E2.m1.2.2.2.2.1.1.1">subscript</csymbol><ci id="S3.E2.m1.2.2.2.2.1.1.1.2.cmml" xref="S3.E2.m1.2.2.2.2.1.1.1.2">ùëù</ci><ci id="S3.E2.m1.2.2.2.2.1.1.1.3.cmml" xref="S3.E2.m1.2.2.2.2.1.1.1.3">ùëñ</ci></apply><ci id="S3.E2.m1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1">ùëë</ci></interval></apply><apply id="S3.E2.m1.3.3.3.3.1.1.cmml" xref="S3.E2.m1.3.3.3.3.1"><plus id="S3.E2.m1.3.3.3.3.1.1.1.cmml" xref="S3.E2.m1.3.3.3.3.1.1.1"></plus><apply id="S3.E2.m1.3.3.3.3.1.1.2.cmml" xref="S3.E2.m1.3.3.3.3.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.3.3.3.3.1.1.2.1.cmml" xref="S3.E2.m1.3.3.3.3.1.1.2">subscript</csymbol><ci id="S3.E2.m1.3.3.3.3.1.1.2.2.cmml" xref="S3.E2.m1.3.3.3.3.1.1.2.2">ùëò</ci><cn id="S3.E2.m1.3.3.3.3.1.1.2.3.cmml" type="integer" xref="S3.E2.m1.3.3.3.3.1.1.2.3">1</cn></apply><cn id="S3.E2.m1.3.3.3.3.1.1.3.cmml" type="integer" xref="S3.E2.m1.3.3.3.3.1.1.3">1</cn></apply></apply><apply id="S3.E2.m1.7.7.7.cmml" xref="S3.E2.m1.7.7.7"><plus id="S3.E2.m1.7.7.7.5.cmml" xref="S3.E2.m1.7.7.7.5"></plus><apply id="S3.E2.m1.6.6.6.3.cmml" xref="S3.E2.m1.6.6.6.3"><times id="S3.E2.m1.6.6.6.3.2.cmml" xref="S3.E2.m1.6.6.6.3.2"></times><ci id="S3.E2.m1.6.6.6.3.3.cmml" xref="S3.E2.m1.6.6.6.3.3">ùëì</ci><interval closure="open" id="S3.E2.m1.6.6.6.3.1.2.cmml" xref="S3.E2.m1.6.6.6.3.1.1"><apply id="S3.E2.m1.6.6.6.3.1.1.1.cmml" xref="S3.E2.m1.6.6.6.3.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.6.6.6.3.1.1.1.1.cmml" xref="S3.E2.m1.6.6.6.3.1.1.1">subscript</csymbol><ci id="S3.E2.m1.6.6.6.3.1.1.1.2.cmml" xref="S3.E2.m1.6.6.6.3.1.1.1.2">ùëù</ci><ci id="S3.E2.m1.6.6.6.3.1.1.1.3.cmml" xref="S3.E2.m1.6.6.6.3.1.1.1.3">ùëñ</ci></apply><ci id="S3.E2.m1.5.5.5.2.cmml" xref="S3.E2.m1.5.5.5.2">ùëë</ci></interval></apply><apply id="S3.E2.m1.7.7.7.4.cmml" xref="S3.E2.m1.7.7.7.4"><ci id="S3.E2.m1.7.7.7.4.2.cmml" xref="S3.E2.m1.7.7.7.4.2">‚ãÖ</ci><apply id="S3.E2.m1.7.7.7.4.3.cmml" xref="S3.E2.m1.7.7.7.4.3"><csymbol cd="ambiguous" id="S3.E2.m1.7.7.7.4.3.1.cmml" xref="S3.E2.m1.7.7.7.4.3">subscript</csymbol><ci id="S3.E2.m1.7.7.7.4.3.2.cmml" xref="S3.E2.m1.7.7.7.4.3.2">ùëò</ci><cn id="S3.E2.m1.7.7.7.4.3.3.cmml" type="integer" xref="S3.E2.m1.7.7.7.4.3.3">1</cn></apply><apply id="S3.E2.m1.7.7.7.4.1.1.1.cmml" xref="S3.E2.m1.7.7.7.4.1.1"><plus id="S3.E2.m1.7.7.7.4.1.1.1.1.cmml" xref="S3.E2.m1.7.7.7.4.1.1.1.1"></plus><apply id="S3.E2.m1.7.7.7.4.1.1.1.2.cmml" xref="S3.E2.m1.7.7.7.4.1.1.1.2"><minus id="S3.E2.m1.7.7.7.4.1.1.1.2.1.cmml" xref="S3.E2.m1.7.7.7.4.1.1.1.2.1"></minus><cn id="S3.E2.m1.7.7.7.4.1.1.1.2.2.cmml" type="integer" xref="S3.E2.m1.7.7.7.4.1.1.1.2.2">1</cn><ci id="S3.E2.m1.7.7.7.4.1.1.1.2.3.cmml" xref="S3.E2.m1.7.7.7.4.1.1.1.2.3">ùëè</ci></apply><apply id="S3.E2.m1.7.7.7.4.1.1.1.3.cmml" xref="S3.E2.m1.7.7.7.4.1.1.1.3"><ci id="S3.E2.m1.7.7.7.4.1.1.1.3.1.cmml" xref="S3.E2.m1.7.7.7.4.1.1.1.3.1">‚ãÖ</ci><ci id="S3.E2.m1.7.7.7.4.1.1.1.3.2.cmml" xref="S3.E2.m1.7.7.7.4.1.1.1.3.2">ùëè</ci><apply id="S3.E2.m1.4.4.4.1.cmml" xref="S3.E2.m1.4.4.4.1"><divide id="S3.E2.m1.4.4.4.1.2.cmml" xref="S3.E2.m1.4.4.4.1"></divide><apply id="S3.E2.m1.4.4.4.1.1.2.cmml" xref="S3.E2.m1.4.4.4.1.1.3"><abs id="S3.E2.m1.4.4.4.1.1.2.1.cmml" xref="S3.E2.m1.4.4.4.1.1.3.1"></abs><ci id="S3.E2.m1.4.4.4.1.1.1.cmml" xref="S3.E2.m1.4.4.4.1.1.1">ùëë</ci></apply><ci id="S3.E2.m1.4.4.4.1.3a.cmml" xref="S3.E2.m1.4.4.4.1.3"><mtext id="S3.E2.m1.4.4.4.1.3.cmml" mathsize="70%" xref="S3.E2.m1.4.4.4.1.3">avg_dl</mtext></ci></apply></apply></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.10c">\text{Score}(p,d)=\sum_{i=1}^{n}\text{IDF}(p_{i})\cdot\frac{f(p_{i},d)\cdot(k_%
{1}+1)}{f(p_{i},d)+k_{1}\cdot(1-b+b\cdot\frac{|d|}{\text{avg\_dl}})}</annotation><annotation encoding="application/x-llamapun" id="S3.E2.m1.10d">Score ( italic_p , italic_d ) = ‚àë start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT IDF ( italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) ‚ãÖ divide start_ARG italic_f ( italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_d ) ‚ãÖ ( italic_k start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + 1 ) end_ARG start_ARG italic_f ( italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_d ) + italic_k start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ‚ãÖ ( 1 - italic_b + italic_b ‚ãÖ divide start_ARG | italic_d | end_ARG start_ARG avg_dl end_ARG ) end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS2.p3">
<table class="ltx_equation ltx_eqn_table" id="S3.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\text{avg\_dl}=\frac{1}{N}\sum_{j=1}^{N}|d_{j}|" class="ltx_Math" display="block" id="S3.E3.m1.1"><semantics id="S3.E3.m1.1a"><mrow id="S3.E3.m1.1.1" xref="S3.E3.m1.1.1.cmml"><mtext id="S3.E3.m1.1.1.3" xref="S3.E3.m1.1.1.3a.cmml">avg_dl</mtext><mo id="S3.E3.m1.1.1.2" xref="S3.E3.m1.1.1.2.cmml">=</mo><mrow id="S3.E3.m1.1.1.1" xref="S3.E3.m1.1.1.1.cmml"><mfrac id="S3.E3.m1.1.1.1.3" xref="S3.E3.m1.1.1.1.3.cmml"><mn id="S3.E3.m1.1.1.1.3.2" xref="S3.E3.m1.1.1.1.3.2.cmml">1</mn><mi id="S3.E3.m1.1.1.1.3.3" xref="S3.E3.m1.1.1.1.3.3.cmml">N</mi></mfrac><mo id="S3.E3.m1.1.1.1.2" xref="S3.E3.m1.1.1.1.2.cmml">‚Å¢</mo><mrow id="S3.E3.m1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.cmml"><munderover id="S3.E3.m1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.2.cmml"><mo id="S3.E3.m1.1.1.1.1.2.2.2" movablelimits="false" rspace="0em" xref="S3.E3.m1.1.1.1.1.2.2.2.cmml">‚àë</mo><mrow id="S3.E3.m1.1.1.1.1.2.2.3" xref="S3.E3.m1.1.1.1.1.2.2.3.cmml"><mi id="S3.E3.m1.1.1.1.1.2.2.3.2" xref="S3.E3.m1.1.1.1.1.2.2.3.2.cmml">j</mi><mo id="S3.E3.m1.1.1.1.1.2.2.3.1" xref="S3.E3.m1.1.1.1.1.2.2.3.1.cmml">=</mo><mn id="S3.E3.m1.1.1.1.1.2.2.3.3" xref="S3.E3.m1.1.1.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S3.E3.m1.1.1.1.1.2.3" xref="S3.E3.m1.1.1.1.1.2.3.cmml">N</mi></munderover><mrow id="S3.E3.m1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.2.cmml"><mo id="S3.E3.m1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E3.m1.1.1.1.1.1.2.1.cmml">|</mo><msub id="S3.E3.m1.1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.1.cmml"><mi id="S3.E3.m1.1.1.1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.1.1.1.2.cmml">d</mi><mi id="S3.E3.m1.1.1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.1.1.3.cmml">j</mi></msub><mo id="S3.E3.m1.1.1.1.1.1.1.3" stretchy="false" xref="S3.E3.m1.1.1.1.1.1.2.1.cmml">|</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.1b"><apply id="S3.E3.m1.1.1.cmml" xref="S3.E3.m1.1.1"><eq id="S3.E3.m1.1.1.2.cmml" xref="S3.E3.m1.1.1.2"></eq><ci id="S3.E3.m1.1.1.3a.cmml" xref="S3.E3.m1.1.1.3"><mtext id="S3.E3.m1.1.1.3.cmml" xref="S3.E3.m1.1.1.3">avg_dl</mtext></ci><apply id="S3.E3.m1.1.1.1.cmml" xref="S3.E3.m1.1.1.1"><times id="S3.E3.m1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.2"></times><apply id="S3.E3.m1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.3"><divide id="S3.E3.m1.1.1.1.3.1.cmml" xref="S3.E3.m1.1.1.1.3"></divide><cn id="S3.E3.m1.1.1.1.3.2.cmml" type="integer" xref="S3.E3.m1.1.1.1.3.2">1</cn><ci id="S3.E3.m1.1.1.1.3.3.cmml" xref="S3.E3.m1.1.1.1.3.3">ùëÅ</ci></apply><apply id="S3.E3.m1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1"><apply id="S3.E3.m1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.2.1.cmml" xref="S3.E3.m1.1.1.1.1.2">superscript</csymbol><apply id="S3.E3.m1.1.1.1.1.2.2.cmml" xref="S3.E3.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.2.2.1.cmml" xref="S3.E3.m1.1.1.1.1.2">subscript</csymbol><sum id="S3.E3.m1.1.1.1.1.2.2.2.cmml" xref="S3.E3.m1.1.1.1.1.2.2.2"></sum><apply id="S3.E3.m1.1.1.1.1.2.2.3.cmml" xref="S3.E3.m1.1.1.1.1.2.2.3"><eq id="S3.E3.m1.1.1.1.1.2.2.3.1.cmml" xref="S3.E3.m1.1.1.1.1.2.2.3.1"></eq><ci id="S3.E3.m1.1.1.1.1.2.2.3.2.cmml" xref="S3.E3.m1.1.1.1.1.2.2.3.2">ùëó</ci><cn id="S3.E3.m1.1.1.1.1.2.2.3.3.cmml" type="integer" xref="S3.E3.m1.1.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="S3.E3.m1.1.1.1.1.2.3.cmml" xref="S3.E3.m1.1.1.1.1.2.3">ùëÅ</ci></apply><apply id="S3.E3.m1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1"><abs id="S3.E3.m1.1.1.1.1.1.2.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.2"></abs><apply id="S3.E3.m1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E3.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.2">ùëë</ci><ci id="S3.E3.m1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.3">ùëó</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.1c">\text{avg\_dl}=\frac{1}{N}\sum_{j=1}^{N}|d_{j}|</annotation><annotation encoding="application/x-llamapun" id="S3.E3.m1.1d">avg_dl = divide start_ARG 1 end_ARG start_ARG italic_N end_ARG ‚àë start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT | italic_d start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT |</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS2.p3.12">where <math alttext="f(p_{i},d)" class="ltx_Math" display="inline" id="S3.SS2.p3.1.m1.2"><semantics id="S3.SS2.p3.1.m1.2a"><mrow id="S3.SS2.p3.1.m1.2.2" xref="S3.SS2.p3.1.m1.2.2.cmml"><mi id="S3.SS2.p3.1.m1.2.2.3" xref="S3.SS2.p3.1.m1.2.2.3.cmml">f</mi><mo id="S3.SS2.p3.1.m1.2.2.2" xref="S3.SS2.p3.1.m1.2.2.2.cmml">‚Å¢</mo><mrow id="S3.SS2.p3.1.m1.2.2.1.1" xref="S3.SS2.p3.1.m1.2.2.1.2.cmml"><mo id="S3.SS2.p3.1.m1.2.2.1.1.2" stretchy="false" xref="S3.SS2.p3.1.m1.2.2.1.2.cmml">(</mo><msub id="S3.SS2.p3.1.m1.2.2.1.1.1" xref="S3.SS2.p3.1.m1.2.2.1.1.1.cmml"><mi id="S3.SS2.p3.1.m1.2.2.1.1.1.2" xref="S3.SS2.p3.1.m1.2.2.1.1.1.2.cmml">p</mi><mi id="S3.SS2.p3.1.m1.2.2.1.1.1.3" xref="S3.SS2.p3.1.m1.2.2.1.1.1.3.cmml">i</mi></msub><mo id="S3.SS2.p3.1.m1.2.2.1.1.3" xref="S3.SS2.p3.1.m1.2.2.1.2.cmml">,</mo><mi id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml">d</mi><mo id="S3.SS2.p3.1.m1.2.2.1.1.4" stretchy="false" xref="S3.SS2.p3.1.m1.2.2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.2b"><apply id="S3.SS2.p3.1.m1.2.2.cmml" xref="S3.SS2.p3.1.m1.2.2"><times id="S3.SS2.p3.1.m1.2.2.2.cmml" xref="S3.SS2.p3.1.m1.2.2.2"></times><ci id="S3.SS2.p3.1.m1.2.2.3.cmml" xref="S3.SS2.p3.1.m1.2.2.3">ùëì</ci><interval closure="open" id="S3.SS2.p3.1.m1.2.2.1.2.cmml" xref="S3.SS2.p3.1.m1.2.2.1.1"><apply id="S3.SS2.p3.1.m1.2.2.1.1.1.cmml" xref="S3.SS2.p3.1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.1.m1.2.2.1.1.1.1.cmml" xref="S3.SS2.p3.1.m1.2.2.1.1.1">subscript</csymbol><ci id="S3.SS2.p3.1.m1.2.2.1.1.1.2.cmml" xref="S3.SS2.p3.1.m1.2.2.1.1.1.2">ùëù</ci><ci id="S3.SS2.p3.1.m1.2.2.1.1.1.3.cmml" xref="S3.SS2.p3.1.m1.2.2.1.1.1.3">ùëñ</ci></apply><ci id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1">ùëë</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.2c">f(p_{i},d)</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.1.m1.2d">italic_f ( italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_d )</annotation></semantics></math> is the term frequency of <math alttext="p_{i}" class="ltx_Math" display="inline" id="S3.SS2.p3.2.m2.1"><semantics id="S3.SS2.p3.2.m2.1a"><msub id="S3.SS2.p3.2.m2.1.1" xref="S3.SS2.p3.2.m2.1.1.cmml"><mi id="S3.SS2.p3.2.m2.1.1.2" xref="S3.SS2.p3.2.m2.1.1.2.cmml">p</mi><mi id="S3.SS2.p3.2.m2.1.1.3" xref="S3.SS2.p3.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m2.1b"><apply id="S3.SS2.p3.2.m2.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.2.m2.1.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.p3.2.m2.1.1.2.cmml" xref="S3.SS2.p3.2.m2.1.1.2">ùëù</ci><ci id="S3.SS2.p3.2.m2.1.1.3.cmml" xref="S3.SS2.p3.2.m2.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m2.1c">p_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.2.m2.1d">italic_p start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> in document <math alttext="d" class="ltx_Math" display="inline" id="S3.SS2.p3.3.m3.1"><semantics id="S3.SS2.p3.3.m3.1a"><mi id="S3.SS2.p3.3.m3.1.1" xref="S3.SS2.p3.3.m3.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.3.m3.1b"><ci id="S3.SS2.p3.3.m3.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1">ùëë</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.3.m3.1c">d</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.3.m3.1d">italic_d</annotation></semantics></math>, <math alttext="|d|" class="ltx_Math" display="inline" id="S3.SS2.p3.4.m4.1"><semantics id="S3.SS2.p3.4.m4.1a"><mrow id="S3.SS2.p3.4.m4.1.2.2" xref="S3.SS2.p3.4.m4.1.2.1.cmml"><mo id="S3.SS2.p3.4.m4.1.2.2.1" stretchy="false" xref="S3.SS2.p3.4.m4.1.2.1.1.cmml">|</mo><mi id="S3.SS2.p3.4.m4.1.1" xref="S3.SS2.p3.4.m4.1.1.cmml">d</mi><mo id="S3.SS2.p3.4.m4.1.2.2.2" stretchy="false" xref="S3.SS2.p3.4.m4.1.2.1.1.cmml">|</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.4.m4.1b"><apply id="S3.SS2.p3.4.m4.1.2.1.cmml" xref="S3.SS2.p3.4.m4.1.2.2"><abs id="S3.SS2.p3.4.m4.1.2.1.1.cmml" xref="S3.SS2.p3.4.m4.1.2.2.1"></abs><ci id="S3.SS2.p3.4.m4.1.1.cmml" xref="S3.SS2.p3.4.m4.1.1">ùëë</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.4.m4.1c">|d|</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.4.m4.1d">| italic_d |</annotation></semantics></math> is the length of document <math alttext="d" class="ltx_Math" display="inline" id="S3.SS2.p3.5.m5.1"><semantics id="S3.SS2.p3.5.m5.1a"><mi id="S3.SS2.p3.5.m5.1.1" xref="S3.SS2.p3.5.m5.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.5.m5.1b"><ci id="S3.SS2.p3.5.m5.1.1.cmml" xref="S3.SS2.p3.5.m5.1.1">ùëë</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.5.m5.1c">d</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.5.m5.1d">italic_d</annotation></semantics></math>, <span class="ltx_text ltx_markedasmath" id="S3.SS2.p3.12.1">avg_dl</span> is the average length of all documents in the set, <math alttext="\text{IDF}(q_{i})" class="ltx_Math" display="inline" id="S3.SS2.p3.7.m7.1"><semantics id="S3.SS2.p3.7.m7.1a"><mrow id="S3.SS2.p3.7.m7.1.1" xref="S3.SS2.p3.7.m7.1.1.cmml"><mtext id="S3.SS2.p3.7.m7.1.1.3" xref="S3.SS2.p3.7.m7.1.1.3a.cmml">IDF</mtext><mo id="S3.SS2.p3.7.m7.1.1.2" xref="S3.SS2.p3.7.m7.1.1.2.cmml">‚Å¢</mo><mrow id="S3.SS2.p3.7.m7.1.1.1.1" xref="S3.SS2.p3.7.m7.1.1.1.1.1.cmml"><mo id="S3.SS2.p3.7.m7.1.1.1.1.2" stretchy="false" xref="S3.SS2.p3.7.m7.1.1.1.1.1.cmml">(</mo><msub id="S3.SS2.p3.7.m7.1.1.1.1.1" xref="S3.SS2.p3.7.m7.1.1.1.1.1.cmml"><mi id="S3.SS2.p3.7.m7.1.1.1.1.1.2" xref="S3.SS2.p3.7.m7.1.1.1.1.1.2.cmml">q</mi><mi id="S3.SS2.p3.7.m7.1.1.1.1.1.3" xref="S3.SS2.p3.7.m7.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.SS2.p3.7.m7.1.1.1.1.3" stretchy="false" xref="S3.SS2.p3.7.m7.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.7.m7.1b"><apply id="S3.SS2.p3.7.m7.1.1.cmml" xref="S3.SS2.p3.7.m7.1.1"><times id="S3.SS2.p3.7.m7.1.1.2.cmml" xref="S3.SS2.p3.7.m7.1.1.2"></times><ci id="S3.SS2.p3.7.m7.1.1.3a.cmml" xref="S3.SS2.p3.7.m7.1.1.3"><mtext id="S3.SS2.p3.7.m7.1.1.3.cmml" xref="S3.SS2.p3.7.m7.1.1.3">IDF</mtext></ci><apply id="S3.SS2.p3.7.m7.1.1.1.1.1.cmml" xref="S3.SS2.p3.7.m7.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.7.m7.1.1.1.1.1.1.cmml" xref="S3.SS2.p3.7.m7.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p3.7.m7.1.1.1.1.1.2.cmml" xref="S3.SS2.p3.7.m7.1.1.1.1.1.2">ùëû</ci><ci id="S3.SS2.p3.7.m7.1.1.1.1.1.3.cmml" xref="S3.SS2.p3.7.m7.1.1.1.1.1.3">ùëñ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.7.m7.1c">\text{IDF}(q_{i})</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.7.m7.1d">IDF ( italic_q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math> is the inverse document frequency of term <math alttext="q_{i}" class="ltx_Math" display="inline" id="S3.SS2.p3.8.m8.1"><semantics id="S3.SS2.p3.8.m8.1a"><msub id="S3.SS2.p3.8.m8.1.1" xref="S3.SS2.p3.8.m8.1.1.cmml"><mi id="S3.SS2.p3.8.m8.1.1.2" xref="S3.SS2.p3.8.m8.1.1.2.cmml">q</mi><mi id="S3.SS2.p3.8.m8.1.1.3" xref="S3.SS2.p3.8.m8.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.8.m8.1b"><apply id="S3.SS2.p3.8.m8.1.1.cmml" xref="S3.SS2.p3.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.8.m8.1.1.1.cmml" xref="S3.SS2.p3.8.m8.1.1">subscript</csymbol><ci id="S3.SS2.p3.8.m8.1.1.2.cmml" xref="S3.SS2.p3.8.m8.1.1.2">ùëû</ci><ci id="S3.SS2.p3.8.m8.1.1.3.cmml" xref="S3.SS2.p3.8.m8.1.1.3">ùëñ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.8.m8.1c">q_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.8.m8.1d">italic_q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>, and <math alttext="k_{1}" class="ltx_Math" display="inline" id="S3.SS2.p3.9.m9.1"><semantics id="S3.SS2.p3.9.m9.1a"><msub id="S3.SS2.p3.9.m9.1.1" xref="S3.SS2.p3.9.m9.1.1.cmml"><mi id="S3.SS2.p3.9.m9.1.1.2" xref="S3.SS2.p3.9.m9.1.1.2.cmml">k</mi><mn id="S3.SS2.p3.9.m9.1.1.3" xref="S3.SS2.p3.9.m9.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.9.m9.1b"><apply id="S3.SS2.p3.9.m9.1.1.cmml" xref="S3.SS2.p3.9.m9.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.9.m9.1.1.1.cmml" xref="S3.SS2.p3.9.m9.1.1">subscript</csymbol><ci id="S3.SS2.p3.9.m9.1.1.2.cmml" xref="S3.SS2.p3.9.m9.1.1.2">ùëò</ci><cn id="S3.SS2.p3.9.m9.1.1.3.cmml" type="integer" xref="S3.SS2.p3.9.m9.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.9.m9.1c">k_{1}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.9.m9.1d">italic_k start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="b" class="ltx_Math" display="inline" id="S3.SS2.p3.10.m10.1"><semantics id="S3.SS2.p3.10.m10.1a"><mi id="S3.SS2.p3.10.m10.1.1" xref="S3.SS2.p3.10.m10.1.1.cmml">b</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.10.m10.1b"><ci id="S3.SS2.p3.10.m10.1.1.cmml" xref="S3.SS2.p3.10.m10.1.1">ùëè</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.10.m10.1c">b</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.10.m10.1d">italic_b</annotation></semantics></math> are hyperparameters. In our experiments, we use the default settings with <math alttext="k_{1}=1.5" class="ltx_Math" display="inline" id="S3.SS2.p3.11.m11.1"><semantics id="S3.SS2.p3.11.m11.1a"><mrow id="S3.SS2.p3.11.m11.1.1" xref="S3.SS2.p3.11.m11.1.1.cmml"><msub id="S3.SS2.p3.11.m11.1.1.2" xref="S3.SS2.p3.11.m11.1.1.2.cmml"><mi id="S3.SS2.p3.11.m11.1.1.2.2" xref="S3.SS2.p3.11.m11.1.1.2.2.cmml">k</mi><mn id="S3.SS2.p3.11.m11.1.1.2.3" xref="S3.SS2.p3.11.m11.1.1.2.3.cmml">1</mn></msub><mo id="S3.SS2.p3.11.m11.1.1.1" xref="S3.SS2.p3.11.m11.1.1.1.cmml">=</mo><mn id="S3.SS2.p3.11.m11.1.1.3" xref="S3.SS2.p3.11.m11.1.1.3.cmml">1.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.11.m11.1b"><apply id="S3.SS2.p3.11.m11.1.1.cmml" xref="S3.SS2.p3.11.m11.1.1"><eq id="S3.SS2.p3.11.m11.1.1.1.cmml" xref="S3.SS2.p3.11.m11.1.1.1"></eq><apply id="S3.SS2.p3.11.m11.1.1.2.cmml" xref="S3.SS2.p3.11.m11.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p3.11.m11.1.1.2.1.cmml" xref="S3.SS2.p3.11.m11.1.1.2">subscript</csymbol><ci id="S3.SS2.p3.11.m11.1.1.2.2.cmml" xref="S3.SS2.p3.11.m11.1.1.2.2">ùëò</ci><cn id="S3.SS2.p3.11.m11.1.1.2.3.cmml" type="integer" xref="S3.SS2.p3.11.m11.1.1.2.3">1</cn></apply><cn id="S3.SS2.p3.11.m11.1.1.3.cmml" type="float" xref="S3.SS2.p3.11.m11.1.1.3">1.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.11.m11.1c">k_{1}=1.5</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.11.m11.1d">italic_k start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 1.5</annotation></semantics></math> and <math alttext="b=0.75" class="ltx_Math" display="inline" id="S3.SS2.p3.12.m12.1"><semantics id="S3.SS2.p3.12.m12.1a"><mrow id="S3.SS2.p3.12.m12.1.1" xref="S3.SS2.p3.12.m12.1.1.cmml"><mi id="S3.SS2.p3.12.m12.1.1.2" xref="S3.SS2.p3.12.m12.1.1.2.cmml">b</mi><mo id="S3.SS2.p3.12.m12.1.1.1" xref="S3.SS2.p3.12.m12.1.1.1.cmml">=</mo><mn id="S3.SS2.p3.12.m12.1.1.3" xref="S3.SS2.p3.12.m12.1.1.3.cmml">0.75</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.12.m12.1b"><apply id="S3.SS2.p3.12.m12.1.1.cmml" xref="S3.SS2.p3.12.m12.1.1"><eq id="S3.SS2.p3.12.m12.1.1.1.cmml" xref="S3.SS2.p3.12.m12.1.1.1"></eq><ci id="S3.SS2.p3.12.m12.1.1.2.cmml" xref="S3.SS2.p3.12.m12.1.1.2">ùëè</ci><cn id="S3.SS2.p3.12.m12.1.1.3.cmml" type="float" xref="S3.SS2.p3.12.m12.1.1.3">0.75</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.12.m12.1c">b=0.75</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.12.m12.1d">italic_b = 0.75</annotation></semantics></math>.</p>
</div>
<div class="ltx_para" id="S3.SS2.p4">
<p class="ltx_p" id="S3.SS2.p4.4">For the semantic information-based method, we use the embedding vector representation of the text obtained from a pre-trained language model:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E4">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\text{Score}(p,d)=\frac{f(p)\cdot f(d)}{|f(p)||f(d)|}" class="ltx_Math" display="block" id="S3.E4.m1.8"><semantics id="S3.E4.m1.8a"><mrow id="S3.E4.m1.8.9" xref="S3.E4.m1.8.9.cmml"><mrow id="S3.E4.m1.8.9.2" xref="S3.E4.m1.8.9.2.cmml"><mtext id="S3.E4.m1.8.9.2.2" xref="S3.E4.m1.8.9.2.2a.cmml">Score</mtext><mo id="S3.E4.m1.8.9.2.1" xref="S3.E4.m1.8.9.2.1.cmml">‚Å¢</mo><mrow id="S3.E4.m1.8.9.2.3.2" xref="S3.E4.m1.8.9.2.3.1.cmml"><mo id="S3.E4.m1.8.9.2.3.2.1" stretchy="false" xref="S3.E4.m1.8.9.2.3.1.cmml">(</mo><mi id="S3.E4.m1.7.7" xref="S3.E4.m1.7.7.cmml">p</mi><mo id="S3.E4.m1.8.9.2.3.2.2" xref="S3.E4.m1.8.9.2.3.1.cmml">,</mo><mi id="S3.E4.m1.8.8" xref="S3.E4.m1.8.8.cmml">d</mi><mo id="S3.E4.m1.8.9.2.3.2.3" stretchy="false" xref="S3.E4.m1.8.9.2.3.1.cmml">)</mo></mrow></mrow><mo id="S3.E4.m1.8.9.1" xref="S3.E4.m1.8.9.1.cmml">=</mo><mfrac id="S3.E4.m1.6.6" xref="S3.E4.m1.6.6.cmml"><mrow id="S3.E4.m1.2.2.2" xref="S3.E4.m1.2.2.2.cmml"><mrow id="S3.E4.m1.2.2.2.4" xref="S3.E4.m1.2.2.2.4.cmml"><mrow id="S3.E4.m1.2.2.2.4.2" xref="S3.E4.m1.2.2.2.4.2.cmml"><mi id="S3.E4.m1.2.2.2.4.2.2" xref="S3.E4.m1.2.2.2.4.2.2.cmml">f</mi><mo id="S3.E4.m1.2.2.2.4.2.1" xref="S3.E4.m1.2.2.2.4.2.1.cmml">‚Å¢</mo><mrow id="S3.E4.m1.2.2.2.4.2.3.2" xref="S3.E4.m1.2.2.2.4.2.cmml"><mo id="S3.E4.m1.2.2.2.4.2.3.2.1" stretchy="false" xref="S3.E4.m1.2.2.2.4.2.cmml">(</mo><mi id="S3.E4.m1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.cmml">p</mi><mo id="S3.E4.m1.2.2.2.4.2.3.2.2" rspace="0.055em" stretchy="false" xref="S3.E4.m1.2.2.2.4.2.cmml">)</mo></mrow></mrow><mo id="S3.E4.m1.2.2.2.4.1" rspace="0.222em" xref="S3.E4.m1.2.2.2.4.1.cmml">‚ãÖ</mo><mi id="S3.E4.m1.2.2.2.4.3" xref="S3.E4.m1.2.2.2.4.3.cmml">f</mi></mrow><mo id="S3.E4.m1.2.2.2.3" xref="S3.E4.m1.2.2.2.3.cmml">‚Å¢</mo><mrow id="S3.E4.m1.2.2.2.5.2" xref="S3.E4.m1.2.2.2.cmml"><mo id="S3.E4.m1.2.2.2.5.2.1" stretchy="false" xref="S3.E4.m1.2.2.2.cmml">(</mo><mi id="S3.E4.m1.2.2.2.2" xref="S3.E4.m1.2.2.2.2.cmml">d</mi><mo id="S3.E4.m1.2.2.2.5.2.2" stretchy="false" xref="S3.E4.m1.2.2.2.cmml">)</mo></mrow></mrow><mrow id="S3.E4.m1.6.6.6" xref="S3.E4.m1.6.6.6.cmml"><mrow id="S3.E4.m1.5.5.5.3.1" xref="S3.E4.m1.5.5.5.3.2.cmml"><mo id="S3.E4.m1.5.5.5.3.1.2" stretchy="false" xref="S3.E4.m1.5.5.5.3.2.1.cmml">|</mo><mrow id="S3.E4.m1.5.5.5.3.1.1" xref="S3.E4.m1.5.5.5.3.1.1.cmml"><mi id="S3.E4.m1.5.5.5.3.1.1.2" xref="S3.E4.m1.5.5.5.3.1.1.2.cmml">f</mi><mo id="S3.E4.m1.5.5.5.3.1.1.1" xref="S3.E4.m1.5.5.5.3.1.1.1.cmml">‚Å¢</mo><mrow id="S3.E4.m1.5.5.5.3.1.1.3.2" xref="S3.E4.m1.5.5.5.3.1.1.cmml"><mo id="S3.E4.m1.5.5.5.3.1.1.3.2.1" stretchy="false" xref="S3.E4.m1.5.5.5.3.1.1.cmml">(</mo><mi id="S3.E4.m1.3.3.3.1" xref="S3.E4.m1.3.3.3.1.cmml">p</mi><mo id="S3.E4.m1.5.5.5.3.1.1.3.2.2" stretchy="false" xref="S3.E4.m1.5.5.5.3.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E4.m1.5.5.5.3.1.3" stretchy="false" xref="S3.E4.m1.5.5.5.3.2.1.cmml">|</mo></mrow><mo id="S3.E4.m1.6.6.6.5" xref="S3.E4.m1.6.6.6.5.cmml">‚Å¢</mo><mrow id="S3.E4.m1.6.6.6.4.1" xref="S3.E4.m1.6.6.6.4.2.cmml"><mo id="S3.E4.m1.6.6.6.4.1.2" stretchy="false" xref="S3.E4.m1.6.6.6.4.2.1.cmml">|</mo><mrow id="S3.E4.m1.6.6.6.4.1.1" xref="S3.E4.m1.6.6.6.4.1.1.cmml"><mi id="S3.E4.m1.6.6.6.4.1.1.2" xref="S3.E4.m1.6.6.6.4.1.1.2.cmml">f</mi><mo id="S3.E4.m1.6.6.6.4.1.1.1" xref="S3.E4.m1.6.6.6.4.1.1.1.cmml">‚Å¢</mo><mrow id="S3.E4.m1.6.6.6.4.1.1.3.2" xref="S3.E4.m1.6.6.6.4.1.1.cmml"><mo id="S3.E4.m1.6.6.6.4.1.1.3.2.1" stretchy="false" xref="S3.E4.m1.6.6.6.4.1.1.cmml">(</mo><mi id="S3.E4.m1.4.4.4.2" xref="S3.E4.m1.4.4.4.2.cmml">d</mi><mo id="S3.E4.m1.6.6.6.4.1.1.3.2.2" stretchy="false" xref="S3.E4.m1.6.6.6.4.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E4.m1.6.6.6.4.1.3" stretchy="false" xref="S3.E4.m1.6.6.6.4.2.1.cmml">|</mo></mrow></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.8b"><apply id="S3.E4.m1.8.9.cmml" xref="S3.E4.m1.8.9"><eq id="S3.E4.m1.8.9.1.cmml" xref="S3.E4.m1.8.9.1"></eq><apply id="S3.E4.m1.8.9.2.cmml" xref="S3.E4.m1.8.9.2"><times id="S3.E4.m1.8.9.2.1.cmml" xref="S3.E4.m1.8.9.2.1"></times><ci id="S3.E4.m1.8.9.2.2a.cmml" xref="S3.E4.m1.8.9.2.2"><mtext id="S3.E4.m1.8.9.2.2.cmml" xref="S3.E4.m1.8.9.2.2">Score</mtext></ci><interval closure="open" id="S3.E4.m1.8.9.2.3.1.cmml" xref="S3.E4.m1.8.9.2.3.2"><ci id="S3.E4.m1.7.7.cmml" xref="S3.E4.m1.7.7">ùëù</ci><ci id="S3.E4.m1.8.8.cmml" xref="S3.E4.m1.8.8">ùëë</ci></interval></apply><apply id="S3.E4.m1.6.6.cmml" xref="S3.E4.m1.6.6"><divide id="S3.E4.m1.6.6.7.cmml" xref="S3.E4.m1.6.6"></divide><apply id="S3.E4.m1.2.2.2.cmml" xref="S3.E4.m1.2.2.2"><times id="S3.E4.m1.2.2.2.3.cmml" xref="S3.E4.m1.2.2.2.3"></times><apply id="S3.E4.m1.2.2.2.4.cmml" xref="S3.E4.m1.2.2.2.4"><ci id="S3.E4.m1.2.2.2.4.1.cmml" xref="S3.E4.m1.2.2.2.4.1">‚ãÖ</ci><apply id="S3.E4.m1.2.2.2.4.2.cmml" xref="S3.E4.m1.2.2.2.4.2"><times id="S3.E4.m1.2.2.2.4.2.1.cmml" xref="S3.E4.m1.2.2.2.4.2.1"></times><ci id="S3.E4.m1.2.2.2.4.2.2.cmml" xref="S3.E4.m1.2.2.2.4.2.2">ùëì</ci><ci id="S3.E4.m1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1">ùëù</ci></apply><ci id="S3.E4.m1.2.2.2.4.3.cmml" xref="S3.E4.m1.2.2.2.4.3">ùëì</ci></apply><ci id="S3.E4.m1.2.2.2.2.cmml" xref="S3.E4.m1.2.2.2.2">ùëë</ci></apply><apply id="S3.E4.m1.6.6.6.cmml" xref="S3.E4.m1.6.6.6"><times id="S3.E4.m1.6.6.6.5.cmml" xref="S3.E4.m1.6.6.6.5"></times><apply id="S3.E4.m1.5.5.5.3.2.cmml" xref="S3.E4.m1.5.5.5.3.1"><abs id="S3.E4.m1.5.5.5.3.2.1.cmml" xref="S3.E4.m1.5.5.5.3.1.2"></abs><apply id="S3.E4.m1.5.5.5.3.1.1.cmml" xref="S3.E4.m1.5.5.5.3.1.1"><times id="S3.E4.m1.5.5.5.3.1.1.1.cmml" xref="S3.E4.m1.5.5.5.3.1.1.1"></times><ci id="S3.E4.m1.5.5.5.3.1.1.2.cmml" xref="S3.E4.m1.5.5.5.3.1.1.2">ùëì</ci><ci id="S3.E4.m1.3.3.3.1.cmml" xref="S3.E4.m1.3.3.3.1">ùëù</ci></apply></apply><apply id="S3.E4.m1.6.6.6.4.2.cmml" xref="S3.E4.m1.6.6.6.4.1"><abs id="S3.E4.m1.6.6.6.4.2.1.cmml" xref="S3.E4.m1.6.6.6.4.1.2"></abs><apply id="S3.E4.m1.6.6.6.4.1.1.cmml" xref="S3.E4.m1.6.6.6.4.1.1"><times id="S3.E4.m1.6.6.6.4.1.1.1.cmml" xref="S3.E4.m1.6.6.6.4.1.1.1"></times><ci id="S3.E4.m1.6.6.6.4.1.1.2.cmml" xref="S3.E4.m1.6.6.6.4.1.1.2">ùëì</ci><ci id="S3.E4.m1.4.4.4.2.cmml" xref="S3.E4.m1.4.4.4.2">ùëë</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.8c">\text{Score}(p,d)=\frac{f(p)\cdot f(d)}{|f(p)||f(d)|}</annotation><annotation encoding="application/x-llamapun" id="S3.E4.m1.8d">Score ( italic_p , italic_d ) = divide start_ARG italic_f ( italic_p ) ‚ãÖ italic_f ( italic_d ) end_ARG start_ARG | italic_f ( italic_p ) | | italic_f ( italic_d ) | end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS2.p4.3">where <math alttext="f(x)=\text{PLM}(x)" class="ltx_Math" display="inline" id="S3.SS2.p4.1.m1.2"><semantics id="S3.SS2.p4.1.m1.2a"><mrow id="S3.SS2.p4.1.m1.2.3" xref="S3.SS2.p4.1.m1.2.3.cmml"><mrow id="S3.SS2.p4.1.m1.2.3.2" xref="S3.SS2.p4.1.m1.2.3.2.cmml"><mi id="S3.SS2.p4.1.m1.2.3.2.2" xref="S3.SS2.p4.1.m1.2.3.2.2.cmml">f</mi><mo id="S3.SS2.p4.1.m1.2.3.2.1" xref="S3.SS2.p4.1.m1.2.3.2.1.cmml">‚Å¢</mo><mrow id="S3.SS2.p4.1.m1.2.3.2.3.2" xref="S3.SS2.p4.1.m1.2.3.2.cmml"><mo id="S3.SS2.p4.1.m1.2.3.2.3.2.1" stretchy="false" xref="S3.SS2.p4.1.m1.2.3.2.cmml">(</mo><mi id="S3.SS2.p4.1.m1.1.1" xref="S3.SS2.p4.1.m1.1.1.cmml">x</mi><mo id="S3.SS2.p4.1.m1.2.3.2.3.2.2" stretchy="false" xref="S3.SS2.p4.1.m1.2.3.2.cmml">)</mo></mrow></mrow><mo id="S3.SS2.p4.1.m1.2.3.1" xref="S3.SS2.p4.1.m1.2.3.1.cmml">=</mo><mrow id="S3.SS2.p4.1.m1.2.3.3" xref="S3.SS2.p4.1.m1.2.3.3.cmml"><mtext id="S3.SS2.p4.1.m1.2.3.3.2" xref="S3.SS2.p4.1.m1.2.3.3.2a.cmml">PLM</mtext><mo id="S3.SS2.p4.1.m1.2.3.3.1" xref="S3.SS2.p4.1.m1.2.3.3.1.cmml">‚Å¢</mo><mrow id="S3.SS2.p4.1.m1.2.3.3.3.2" xref="S3.SS2.p4.1.m1.2.3.3.cmml"><mo id="S3.SS2.p4.1.m1.2.3.3.3.2.1" stretchy="false" xref="S3.SS2.p4.1.m1.2.3.3.cmml">(</mo><mi id="S3.SS2.p4.1.m1.2.2" xref="S3.SS2.p4.1.m1.2.2.cmml">x</mi><mo id="S3.SS2.p4.1.m1.2.3.3.3.2.2" stretchy="false" xref="S3.SS2.p4.1.m1.2.3.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.1.m1.2b"><apply id="S3.SS2.p4.1.m1.2.3.cmml" xref="S3.SS2.p4.1.m1.2.3"><eq id="S3.SS2.p4.1.m1.2.3.1.cmml" xref="S3.SS2.p4.1.m1.2.3.1"></eq><apply id="S3.SS2.p4.1.m1.2.3.2.cmml" xref="S3.SS2.p4.1.m1.2.3.2"><times id="S3.SS2.p4.1.m1.2.3.2.1.cmml" xref="S3.SS2.p4.1.m1.2.3.2.1"></times><ci id="S3.SS2.p4.1.m1.2.3.2.2.cmml" xref="S3.SS2.p4.1.m1.2.3.2.2">ùëì</ci><ci id="S3.SS2.p4.1.m1.1.1.cmml" xref="S3.SS2.p4.1.m1.1.1">ùë•</ci></apply><apply id="S3.SS2.p4.1.m1.2.3.3.cmml" xref="S3.SS2.p4.1.m1.2.3.3"><times id="S3.SS2.p4.1.m1.2.3.3.1.cmml" xref="S3.SS2.p4.1.m1.2.3.3.1"></times><ci id="S3.SS2.p4.1.m1.2.3.3.2a.cmml" xref="S3.SS2.p4.1.m1.2.3.3.2"><mtext id="S3.SS2.p4.1.m1.2.3.3.2.cmml" xref="S3.SS2.p4.1.m1.2.3.3.2">PLM</mtext></ci><ci id="S3.SS2.p4.1.m1.2.2.cmml" xref="S3.SS2.p4.1.m1.2.2">ùë•</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.1.m1.2c">f(x)=\text{PLM}(x)</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.1.m1.2d">italic_f ( italic_x ) = PLM ( italic_x )</annotation></semantics></math>. In this context, PLM refers to a pre-trained language model, such as SBERT. This embedding can be derived by either averaging the token embeddings (mean pooling) or using the embedding of the <math alttext="[CLS]" class="ltx_Math" display="inline" id="S3.SS2.p4.2.m2.1"><semantics id="S3.SS2.p4.2.m2.1a"><mrow id="S3.SS2.p4.2.m2.1.1.1" xref="S3.SS2.p4.2.m2.1.1.2.cmml"><mo id="S3.SS2.p4.2.m2.1.1.1.2" stretchy="false" xref="S3.SS2.p4.2.m2.1.1.2.1.cmml">[</mo><mrow id="S3.SS2.p4.2.m2.1.1.1.1" xref="S3.SS2.p4.2.m2.1.1.1.1.cmml"><mi id="S3.SS2.p4.2.m2.1.1.1.1.2" xref="S3.SS2.p4.2.m2.1.1.1.1.2.cmml">C</mi><mo id="S3.SS2.p4.2.m2.1.1.1.1.1" xref="S3.SS2.p4.2.m2.1.1.1.1.1.cmml">‚Å¢</mo><mi id="S3.SS2.p4.2.m2.1.1.1.1.3" xref="S3.SS2.p4.2.m2.1.1.1.1.3.cmml">L</mi><mo id="S3.SS2.p4.2.m2.1.1.1.1.1a" xref="S3.SS2.p4.2.m2.1.1.1.1.1.cmml">‚Å¢</mo><mi id="S3.SS2.p4.2.m2.1.1.1.1.4" xref="S3.SS2.p4.2.m2.1.1.1.1.4.cmml">S</mi></mrow><mo id="S3.SS2.p4.2.m2.1.1.1.3" stretchy="false" xref="S3.SS2.p4.2.m2.1.1.2.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.2.m2.1b"><apply id="S3.SS2.p4.2.m2.1.1.2.cmml" xref="S3.SS2.p4.2.m2.1.1.1"><csymbol cd="latexml" id="S3.SS2.p4.2.m2.1.1.2.1.cmml" xref="S3.SS2.p4.2.m2.1.1.1.2">delimited-[]</csymbol><apply id="S3.SS2.p4.2.m2.1.1.1.1.cmml" xref="S3.SS2.p4.2.m2.1.1.1.1"><times id="S3.SS2.p4.2.m2.1.1.1.1.1.cmml" xref="S3.SS2.p4.2.m2.1.1.1.1.1"></times><ci id="S3.SS2.p4.2.m2.1.1.1.1.2.cmml" xref="S3.SS2.p4.2.m2.1.1.1.1.2">ùê∂</ci><ci id="S3.SS2.p4.2.m2.1.1.1.1.3.cmml" xref="S3.SS2.p4.2.m2.1.1.1.1.3">ùêø</ci><ci id="S3.SS2.p4.2.m2.1.1.1.1.4.cmml" xref="S3.SS2.p4.2.m2.1.1.1.1.4">ùëÜ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.2.m2.1c">[CLS]</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.2.m2.1d">[ italic_C italic_L italic_S ]</annotation></semantics></math> token from a pre-trained language model. Benefiting from its pre-training on large-scale corpora, the PLM encodes rich semantic information into vector representations, enabling more accurate retrieval based on the meaning of the text. Finally, we concatenate the <math alttext="k" class="ltx_Math" display="inline" id="S3.SS2.p4.3.m3.1"><semantics id="S3.SS2.p4.3.m3.1a"><mi id="S3.SS2.p4.3.m3.1.1" xref="S3.SS2.p4.3.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.3.m3.1b"><ci id="S3.SS2.p4.3.m3.1.1.cmml" xref="S3.SS2.p4.3.m3.1.1">ùëò</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.3.m3.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.3.m3.1d">italic_k</annotation></semantics></math> most relevant paragraphs-extraction pairs obtained in the previous step before the input as few-shot demonstrations.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Conclusion</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">This work studies the new paradigm of applying few-shot in-context learning to the popular approach of LLM literature extraction for discovering MOFs synthesis conditions. It is shown through experiments that both the quality and the quantity of few-shot demonstrations are important in the studied scenario. We introduce both a novel process of human-AI joint data curation to enhance few-shot demonstration quality and a calibrated BM-25 RAG algorithm to size the optimal few-shot quantity. Scalability issues regarding high-throughput MOFs synthesis condition extraction are resolved using many practical methods such as offline synthesis paragraph detection and LLM-based coreference resolution. Our proposal is thoroughly evaluated using large-scale real-life MOFs dataset, on both text extraction performance for synthesis condition discovery and the downstream material task on structural property inference.</p>
</div>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Appendix</h2>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>MOFs Data</h3>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1"><span class="ltx_text ltx_font_bold" id="S5.SS1.p1.1.1">CSD and the retrieved dataset</span></p>
</div>
<div class="ltx_para" id="S5.SS1.p2">
<p class="ltx_p" id="S5.SS1.p2.1">We base our work on the MOF subset of Cambridge Structural Database (CSD) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#bib.bib14" title="">14</a>]</cite> retrieved in June 2022, which lists 84,898 MOFs covering the bonding motifs of all common MOFs in CSD. The entry of a MOF in the database contains its structure in CIF format, the physical properties, a DOI linking to the relevant publication, and a unique MOF ID.</p>
</div>
<div class="ltx_para" id="S5.SS1.p3">
<p class="ltx_p" id="S5.SS1.p3.1">The dataset is then pre-processed according to the goal of this work. First, the full-text describing the MOFs under study should be available. Out of all the 84,898 MOFs, 78,741 has non-empty DOIs. Since the same DOI could be linked to multiple MOFs (one paper reporting more than one MOFs), there leaves 39,579 different DOI links after deduplication and 36,177 downloadable paper full-text. For the convenience of follow-up processing, we focus on the DOIs where the associated publication reports the information of only one MOF in CSD. This leads to a subset of 22,461 MOFs, each with a unique publication file in PDF format.</p>
</div>
<div class="ltx_para" id="S5.SS1.p4">
<p class="ltx_p" id="S5.SS1.p4.1">Next, the PDF of each MOF is converted to plain text <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#bib.bib20" title="">20</a>]</cite> and segmented into paragraphs. The high performance classification model in Sec. <a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S3.SS1" title="3.1 Synthesis paragraph detection ‚Ä£ 3 Methods ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_tag">3.1</span></a> is applied to detect synthesis paragraphs enclosing the desired synthesis condition information. Again, for the sake of convenience and accuracy, we only consider the 5,269 MOFs/publications that contain exactly one synthesis paragraph. Another 12,606 publications do not have any synthesis paragraph, probably because these papers are not related to MOFs experiments. The other 4,586 publications have more than one synthesis paragraphs, as they are describing multiple MOFs or synthesis routes. Our pipeline could work with papers having more than one suite of synthesis conditions, but the potential MOF-synthesis mismatch may downgrade the application performance in evaluation. Therefore, throughout this work we stick to the core dataset of 5,269 MOFs/publications and their unique synthesis paragraph.</p>
</div>
<div class="ltx_para" id="S5.SS1.p5">
<p class="ltx_p" id="S5.SS1.p5.1"><span class="ltx_text ltx_font_bold" id="S5.SS1.p5.1.1">Microstructure Property Computation</span></p>
</div>
<div class="ltx_para" id="S5.SS1.p6">
<p class="ltx_p" id="S5.SS1.p6.1">For material evaluation purpose, we also calculate structural and physical properties of the 5,269 MOFs under consideration. The CIF file of each MOF is retrieved from CSD and input to the Zeo++ tool <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#bib.bib22" title="">22</a>]</cite>. In total, four structural and physical properties are calculated: global cavity diameter, pore limiting diameter, largest cavity diameter, and framework density.  We set the probe radius to 1.29A to simulate helium gas molecules, and the number of Monte Carlo samples to 100,000 to ensure the accuracy of calculations. All Zeo++ parameters adhere to standard routines, guaranteeing that the computed properties accurately represent the behavior of gas molecules within the MOF structure.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Annotation Procedure for Synthesis Paragraphs and Synthesis Conditions</h3>
<figure class="ltx_figure" id="S5.F9"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="419" id="S5.F9.g1" src="x9.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>User interface of the annotation platform.</figcaption>
</figure>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">High-quality annotations are the cornerstone of few-shot in-context learning; only accurate and highly coherence annotations can improve the precision of extracting. Therefore, we enlisted the help of eight experts in materials science and engineering to assist with the annotations. Additionally, we developed a batch interactive annotation platform to enhance the convenience of the annotation process. During the annotation process, we discovered that the task was challenging and had a high error rate done by human only, which led to poor model extraction performance when using erroneously annotated examples. Consequently, we implemented a comprehensive annotation process to improve quality.</p>
</div>
<div class="ltx_para" id="S5.SS2.p2">
<p class="ltx_p" id="S5.SS2.p2.1"><span class="ltx_text ltx_font_bold" id="S5.SS2.p2.1.1">Synthesis Paragraph Annotation</span></p>
</div>
<div class="ltx_para" id="S5.SS2.p3">
<p class="ltx_p" id="S5.SS2.p3.1">To annotate synthesis paragraphs for offline machine learning, 440 papers were randomly obtained from the database in Appendix A. For inner annotator agreement, each paper was annotated by two different annotators. The 880 annotation tasks were assigned to four annotators, who used our platform shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S5.F9" title="Figure 9 ‚Ä£ 5.2 Annotation Procedure for Synthesis Paragraphs and Synthesis Conditions ‚Ä£ 5 Appendix ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_tag">9</span></a> to annotate synthesis-related paragraphs. After annotation, only paragraphs annotated by both annotators were considered valid, and paragraphs annotated by only one annotator were discarded. If there was an overlap in the positions of the paragraphs annotated by the two annotators, we found through checking the annotated data that the common mismatched paragraphs often occurred because one annotator noted more synthesis conditons and thus marked a larger range for the synthesis paragraph. In such cases, the paragraph should also be considered valid. Therefore, we treated the larger annotated paragraph as a valid synthesis paragraph. This method also resolved the issue of minor annotation deviations within a few characters, allowing two slightly different synthesis paragraphs to be considered valid. This process yielded 1,349 valid annotated paragraphs. To train the discrimination model, non-synthesis paragraphs are needed as negative samples. After removing all paragraphs annotated by annotators from a paper, the remaining paragraphs serve as negative samples. This method resulted in 11,783 negative samples used for training the synthesis paragraph discrimination model.</p>
</div>
<div class="ltx_para" id="S5.SS2.p4">
<p class="ltx_p" id="S5.SS2.p4.1"><span class="ltx_text ltx_font_bold" id="S5.SS2.p4.1.1">Synthesis Condition Annotation</span></p>
</div>
<div class="ltx_para" id="S5.SS2.p5">
<p class="ltx_p" id="S5.SS2.p5.1">We randomly selected 200 papers from the paper database constructed in <a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S5.SS1" title="5.1 MOFs Data ‚Ä£ 5 Appendix ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_tag">5.1</span></a>, with each paper only contains less than 3 MOFs IDs. The annotation process can be divided into five sections: task configuration, GPT pre-extraction annotation, pilot annotation, batch annotation, and data curation.</p>
</div>
<div class="ltx_para" id="S5.SS2.p6">
<p class="ltx_p" id="S5.SS2.p6.1">In the task configuration stage, domain experts define the key synthesis condition to be annotated and configure the annotation settings. The core standard for annotation configuration is . Due to the diversity of expressions in material papers, consistent annotation methods help increase the density of the resulting data, thereby reducing the complexity of subsequent data cleaning and enhancing the effectiveness of using ML to infer material structure or properties. The selected annotation synthesis condition must: 1) be common in synthesis paragraphs of related papers, and 2) be beneficial for predicting performance condition. We exclude Active process including active temperature and active time after pilot annotation because we recognized its low frequency. Also, Molecular formula was excluded for it helps little in performance parameter prediction. Once the annotation requirements and background knowledge are set by domain experts, the pre-extraction annotation phase can begin.</p>
</div>
<div class="ltx_para" id="S5.SS2.p7">
<p class="ltx_p" id="S5.SS2.p7.1">Before the pilot annotation, the GPT pre-extraction method can be used to preliminarily locate synthesis paragraphs and relevant condition, assisting experts in annotation. The synthesis paragraph discrimination model extracts relevant paragraphs from the papers. Using the annotation requirements and domain knowledge configured in the task configuration stage, zero-shot prompts are applied for pre-extraction to obtain initial extraction data, which is then imported into the annotation system. Although the accuracy of this process is limited, it helps locate paragraphs and reduces annotation difficulty.</p>
</div>
<div class="ltx_para" id="S5.SS2.p8">
<p class="ltx_p" id="S5.SS2.p8.1"><em class="ltx_emph ltx_font_italic" id="S5.SS2.p8.1.1">Pilot annotation:</em> twenty papers are randomly selected from the 200 candidate papers for pilot annotation to validate and adjust the annotation task settings and platform configuration. The annotation platform is shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S5.F9" title="Figure 9 ‚Ä£ 5.2 Annotation Procedure for Synthesis Paragraphs and Synthesis Conditions ‚Ä£ 5 Appendix ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_tag">9</span></a>. Two annotators independently annotate the 20 papers on the platform. The results are used to check inner annotator agreement to ensure accuracy. This process requires annotators and researchers to analyze and discuss the following: 1) identify ambiguous and unclear parts of the annotation task configuration to clarify specific annotation methods, 2) reanalyze the synthesis condition to determine if some field are too sparse and need to be removed, or if some field are dense enough to be included as synthesis condition for predicting performance, and 3) identify any unreasonable designs in the annotation platform and make necessary modifications.</p>
</div>
<div class="ltx_para" id="S5.SS2.p9">
<p class="ltx_p" id="S5.SS2.p9.1">This pilot annotation stage resulted in 20 valid papers. Annotators and researchers refined the annotation task configuration to maximize the quality of subsequent batch annotations.</p>
</div>
<div class="ltx_para" id="S5.SS2.p10">
<p class="ltx_p" id="S5.SS2.p10.1"><em class="ltx_emph ltx_font_italic" id="S5.SS2.p10.1.1">Batch annotations: </em>the remaining 180 papers will produce 360 annotation tasks, assigned to six annotators. Each annotator is randomly assigned 60 papers, ensuring each paper is annotated by two different annotators. GPT pre-extraction is also used to enhance annotation accuracy and efficiency. Upon completion, the annotation data undergo a simple inner annotator agreement check, using Jaccard similarity to verify the consistency between the two annotators‚Äô results. For each annotation field, a validity threshold of 0.8 overlap between the annotators is required, then the result field was the union of two fields, which is better for subsequent data cleaning than intersection. For each paper, a verified annotation item overlap rate of 80% or higher between the two annotators is considered a valid annotation paper. Non valid papers were not used in follow-up steps and can be used as supplementary data after manual review.</p>
</div>
<div class="ltx_para" id="S5.SS2.p11">
<p class="ltx_p" id="S5.SS2.p11.1">This stage resulted in 147 papers with high overlap rates, used in this experiment. 53 papers are excluded for subsequent process.</p>
</div>
<div class="ltx_para" id="S5.SS2.p12">
<p class="ltx_p" id="S5.SS2.p12.1"><em class="ltx_emph ltx_font_italic" id="S5.SS2.p12.1.1">Joint Human-AI Data Curation:</em> to improve annotation quality, we introduce a joint human-AI data curation process. Experts finalize the data annotations step by double-check the results from both LLM and human annotations. The LLM results, using BM25 few-shot extraction of synthesis condition, are compared with the annotated results to identify inconsistencies. This step helps detect problems in batch annotations and assists in identifying erroneous annotations. Invalid papers will be excluded. We detected and excluded chiral MOFs in annotated papers, with duplicate synthesis conditions and paragraph. Also, for better sampling, we excluded all paragraph with more than one MOF synthesis process. Although our resolution framework can handle multiple MOFs in a single paragraph, we chose one-to-one paragraphs for better samples.</p>
</div>
<div class="ltx_para" id="S5.SS2.p13">
<p class="ltx_p" id="S5.SS2.p13.1">Additionally, common LLM extraction errors by the model are identified, allowing for targeted constraint writing in prompts to improve knowledge-based corrections. Constraints must be presented in the form of knowledge provision and must not contain any examples to avoid overfitting. This human-AI data curation process identified 120 annotation errors and added 5 constraints.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Post-processing of Synthesis Conditions</h3>
<figure class="ltx_figure" id="S5.F10"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="631" id="S5.F10.g1" src="x10.png" width="553"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 10: </span>Frequencies of occurrence for MOFs synthesis conditions: (a) metal precursor; (b) organic linker; (c) solvent.</figcaption>
</figure>
<div class="ltx_para" id="S5.SS3.p1">
<p class="ltx_p" id="S5.SS3.p1.1">The raw synthesis conditions extracted by LLM-based method often suffer from data quality issue, which potentially affects the downstream material inference task. We introduce several data postprocessing methods to improve the quality of derived synthesis conditions so that the input data to the inference model can be more formatted and densely distributed.</p>
</div>
<section class="ltx_subsubsection" id="S5.SS3.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.3.1 </span>Data Cleansing on Textual Conditions</h4>
<div class="ltx_para" id="S5.SS3.SSS1.p1">
<p class="ltx_p" id="S5.SS3.SSS1.p1.1">The synthesis conditions include discrete names for Metal, Organic Linker, Solvent, and additives. These names often have different representations for the same substance (e.g., ‚ÄùH2O‚Äù and ‚ÄùWater‚Äù both represent water, ‚ÄùCd(NO3)2.4H2O‚Äù and ‚ÄùCd(NO3)2?4H2O‚Äù both represent cadmium nitrate tetrahydrate). Using unprocessed discrete names increases redundancy and noise in the dataset, complicating the embedding process and affecting the consistency and performance of the model.</p>
</div>
<div class="ltx_para" id="S5.SS3.SSS1.p2">
<p class="ltx_p" id="S5.SS3.SSS1.p2.1"><span class="ltx_text ltx_font_bold" id="S5.SS3.SSS1.p2.1.1">Similarity Disambiguation</span></p>
</div>
<div class="ltx_para" id="S5.SS3.SSS1.p3">
<p class="ltx_p" id="S5.SS3.SSS1.p3.1">First, we use similarity disambiguation to create an initial list of assimilated names, eliminating some ambiguities caused by inconsistent spelling, based on the Levenshtein distance (edit distance). The specific steps are as follows:</p>
</div>
<div class="ltx_para" id="S5.SS3.SSS1.p4">
<ol class="ltx_enumerate" id="S5.I1">
<li class="ltx_item" id="S5.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S5.I1.i1.p1">
<p class="ltx_p" id="S5.I1.i1.p1.1">Calculate the Levenshtein distance between two strings.</p>
</div>
</li>
<li class="ltx_item" id="S5.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S5.I1.i2.p1">
<p class="ltx_p" id="S5.I1.i2.p1.1">Normalize the similarity score by converting the Levenshtein distance to a score between 0 and 100 using the formula:</p>
<table class="ltx_equation ltx_eqn_table" id="S5.E5">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\text{Similarity\_ratio}=\left(1-\frac{\text{Levenshtein distance}}{\text{%
maximum length of the two strings}}\right)\times 100" class="ltx_Math" display="block" id="S5.E5.m1.1"><semantics id="S5.E5.m1.1a"><mrow id="S5.E5.m1.1.1" xref="S5.E5.m1.1.1.cmml"><mtext id="S5.E5.m1.1.1.3" xref="S5.E5.m1.1.1.3a.cmml">Similarity_ratio</mtext><mo id="S5.E5.m1.1.1.2" xref="S5.E5.m1.1.1.2.cmml">=</mo><mrow id="S5.E5.m1.1.1.1" xref="S5.E5.m1.1.1.1.cmml"><mrow id="S5.E5.m1.1.1.1.1.1" xref="S5.E5.m1.1.1.1.1.1.1.cmml"><mo id="S5.E5.m1.1.1.1.1.1.2" xref="S5.E5.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S5.E5.m1.1.1.1.1.1.1" xref="S5.E5.m1.1.1.1.1.1.1.cmml"><mn id="S5.E5.m1.1.1.1.1.1.1.2" xref="S5.E5.m1.1.1.1.1.1.1.2.cmml">1</mn><mo id="S5.E5.m1.1.1.1.1.1.1.1" xref="S5.E5.m1.1.1.1.1.1.1.1.cmml">‚àí</mo><mfrac id="S5.E5.m1.1.1.1.1.1.1.3" xref="S5.E5.m1.1.1.1.1.1.1.3.cmml"><mtext id="S5.E5.m1.1.1.1.1.1.1.3.2" xref="S5.E5.m1.1.1.1.1.1.1.3.2a.cmml">Levenshtein distance</mtext><mtext id="S5.E5.m1.1.1.1.1.1.1.3.3" xref="S5.E5.m1.1.1.1.1.1.1.3.3a.cmml">maximum length of the two strings</mtext></mfrac></mrow><mo id="S5.E5.m1.1.1.1.1.1.3" rspace="0.055em" xref="S5.E5.m1.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S5.E5.m1.1.1.1.2" rspace="0.222em" xref="S5.E5.m1.1.1.1.2.cmml">√ó</mo><mn id="S5.E5.m1.1.1.1.3" xref="S5.E5.m1.1.1.1.3.cmml">100</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.E5.m1.1b"><apply id="S5.E5.m1.1.1.cmml" xref="S5.E5.m1.1.1"><eq id="S5.E5.m1.1.1.2.cmml" xref="S5.E5.m1.1.1.2"></eq><ci id="S5.E5.m1.1.1.3a.cmml" xref="S5.E5.m1.1.1.3"><mtext id="S5.E5.m1.1.1.3.cmml" xref="S5.E5.m1.1.1.3">Similarity_ratio</mtext></ci><apply id="S5.E5.m1.1.1.1.cmml" xref="S5.E5.m1.1.1.1"><times id="S5.E5.m1.1.1.1.2.cmml" xref="S5.E5.m1.1.1.1.2"></times><apply id="S5.E5.m1.1.1.1.1.1.1.cmml" xref="S5.E5.m1.1.1.1.1.1"><minus id="S5.E5.m1.1.1.1.1.1.1.1.cmml" xref="S5.E5.m1.1.1.1.1.1.1.1"></minus><cn id="S5.E5.m1.1.1.1.1.1.1.2.cmml" type="integer" xref="S5.E5.m1.1.1.1.1.1.1.2">1</cn><apply id="S5.E5.m1.1.1.1.1.1.1.3.cmml" xref="S5.E5.m1.1.1.1.1.1.1.3"><divide id="S5.E5.m1.1.1.1.1.1.1.3.1.cmml" xref="S5.E5.m1.1.1.1.1.1.1.3"></divide><ci id="S5.E5.m1.1.1.1.1.1.1.3.2a.cmml" xref="S5.E5.m1.1.1.1.1.1.1.3.2"><mtext id="S5.E5.m1.1.1.1.1.1.1.3.2.cmml" xref="S5.E5.m1.1.1.1.1.1.1.3.2">Levenshtein distance</mtext></ci><ci id="S5.E5.m1.1.1.1.1.1.1.3.3a.cmml" xref="S5.E5.m1.1.1.1.1.1.1.3.3"><mtext id="S5.E5.m1.1.1.1.1.1.1.3.3.cmml" xref="S5.E5.m1.1.1.1.1.1.1.3.3">maximum length of the two strings</mtext></ci></apply></apply><cn id="S5.E5.m1.1.1.1.3.cmml" type="integer" xref="S5.E5.m1.1.1.1.3">100</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.E5.m1.1c">\text{Similarity\_ratio}=\left(1-\frac{\text{Levenshtein distance}}{\text{%
maximum length of the two strings}}\right)\times 100</annotation><annotation encoding="application/x-llamapun" id="S5.E5.m1.1d">Similarity_ratio = ( 1 - divide start_ARG Levenshtein distance end_ARG start_ARG maximum length of the two strings end_ARG ) √ó 100</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
</div>
</li>
<li class="ltx_item" id="S5.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S5.I1.i3.p1">
<p class="ltx_p" id="S5.I1.i3.p1.1">Set a threshold. We set the threshold at 90 to filter out most unrelated string pairs while ensuring that only truly similar strings are identified as the same object.</p>
</div>
</li>
</ol>
</div>
<div class="ltx_para" id="S5.SS3.SSS1.p5">
<p class="ltx_p" id="S5.SS3.SSS1.p5.1"><span class="ltx_text ltx_font_bold" id="S5.SS3.SSS1.p5.1.1">Synonym Merging Using GPT-4</span></p>
</div>
<div class="ltx_para" id="S5.SS3.SSS1.p6">
<p class="ltx_p" id="S5.SS3.SSS1.p6.1">Next, we use GPT-4 for synonym merging. This method leverages the powerful capabilities of the GPT-4 model to successfully identify and group different names representing the same substance. The system also includes a reflection mechanism to ensure the accuracy of the classifications. The detailed workflow is as follows:</p>
<ol class="ltx_enumerate" id="S5.I2">
<li class="ltx_item" id="S5.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S5.I2.i1.p1">
<p class="ltx_p" id="S5.I2.i1.p1.1">Parse the input text to prepare the chemical substance names.</p>
</div>
</li>
<li class="ltx_item" id="S5.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S5.I2.i2.p1">
<p class="ltx_p" id="S5.I2.i2.p1.1">Use a predefined prompt (PROMPT1) to ask the GPT-4 model to classify the chemical substances and group identical substances. The model returns a JSON array, each item being a list of synonymous substances.</p>
</div>
</li>
<li class="ltx_item" id="S5.I2.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S5.I2.i3.p1">
<p class="ltx_p" id="S5.I2.i3.p1.1">Use a reflection prompt (REFLECT_PROMPT1) to re-evaluate the initial classification results, ensuring classification accuracy. This step checks if the substances within each group belong together and if two groups represent the same substance. Finally, output the final classification results.</p>
</div>
</li>
</ol>
</div>
<div class="ltx_para" id="S5.SS3.SSS1.p7">
<p class="ltx_p" id="S5.SS3.SSS1.p7.1">This method is suitable for synonym merging tasks in materials chemistry, such as Metal Source, Organic Linker, and Solvent. We merged data with frequencies of 8/4/5 and above for Metal Source, Organic Linker, and Solvent, respectively, instead of merging all data. This reduces potential errors from merging low-frequency data and ensures fairness in subsequent comparisons.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S5.SS3.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.3.2 </span>Standardization of Numeric Conditions on Time and Temperature</h4>
<div class="ltx_para" id="S5.SS3.SSS2.p1">
<p class="ltx_p" id="S5.SS3.SSS2.p1.1">After processing the discrete names in the synthesis conditions, we continued to parse and capture numerical data for time and temperature. These data may have quality issues such as inconsistent units and the presence of special characters. To address these issues, we performed the following normalization:</p>
</div>
<div class="ltx_para" id="S5.SS3.SSS2.p2">
<p class="ltx_p" id="S5.SS3.SSS2.p2.1"><span class="ltx_text ltx_font_bold" id="S5.SS3.SSS2.p2.1.1">Extracting and Formatting Data</span></p>
</div>
<div class="ltx_para" id="S5.SS3.SSS2.p3">
<p class="ltx_p" id="S5.SS3.SSS2.p3.1">Using GPT-4, we extracted and formatted relevant data for time and temperature.</p>
</div>
<div class="ltx_para" id="S5.SS3.SSS2.p4">
<p class="ltx_p" id="S5.SS3.SSS2.p4.1"><span class="ltx_text ltx_font_bold" id="S5.SS3.SSS2.p4.1.1">Unit Standardization</span></p>
</div>
<div class="ltx_para" id="S5.SS3.SSS2.p5">
<p class="ltx_p" id="S5.SS3.SSS2.p5.1">We defined standard units for each data type. For example, time was standardized to hours, and temperature was standardized to Celsius (room temperature set at 25<sup class="ltx_sup" id="S5.SS3.SSS2.p5.1.1"><span class="ltx_text ltx_font_italic" id="S5.SS3.SSS2.p5.1.1.1">‚àò</span></sup>C).</p>
</div>
<div class="ltx_para" id="S5.SS3.SSS2.p6">
<p class="ltx_p" id="S5.SS3.SSS2.p6.1"><span class="ltx_text ltx_font_bold" id="S5.SS3.SSS2.p6.1.1">Cleaning Special Characters.</span></p>
</div>
<div class="ltx_para" id="S5.SS3.SSS2.p7">
<p class="ltx_p" id="S5.SS3.SSS2.p7.1">Using regular expressions, we cleaned and formatted data that might contain special characters (such as spaces, commas, etc.).
Through these steps, we ensured the integrity and usability of the data, laying a solid foundation for subsequent processing and analysis.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S5.SS3.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.3.3 </span>Data Filtering by Synthesis Condition Distributions</h4>
<div class="ltx_para" id="S5.SS3.SSS3.p1">
<p class="ltx_p" id="S5.SS3.SSS3.p1.1">After data cleansing and standardization, the distribution of different synthesis conditions becomes more centralized. As shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S5.F10" title="Figure 10 ‚Ä£ 5.3 Post-processing of Synthesis Conditions ‚Ä£ 5 Appendix ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_tag">10</span></a>, the entity lists of both metal source and solvent are shortened. The number of unique organic linkers remains high due to its long-tailed distribution. In the application of MOFs microstructure property inference, we will only select these MOFs synthesized by top entities in metal source, organic linker, and solvent. For example, by default we apply a filter of (100, 135, 20), which select the MOFs having top-100 metal source in the ranked list of Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S5.F10" title="Figure 10 ‚Ä£ 5.3 Post-processing of Synthesis Conditions ‚Ä£ 5 Appendix ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_tag">10</span></a>(a), top-135 organic linker, and top-20 solvent. Note that for LLM models in comparison, different filters may be applied to ensure the same number of MOFs in the dataset.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S5.SS3.SSS4">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.3.4 </span>Feature Embedding for Metal, Organic Linker, and Solvent Data</h4>
<div class="ltx_para" id="S5.SS3.SSS4.p1">
<p class="ltx_p" id="S5.SS3.SSS4.p1.1">After disambiguation and merging, we obtained high-quality precursor/solvent data. To build accurate predictive models, we need to perform corresponding feature embedding to capture the material/structural characteristics of the precursor/solvent data. The specific steps are as follows:</p>
</div>
<div class="ltx_para" id="S5.SS3.SSS4.p2">
<p class="ltx_p" id="S5.SS3.SSS4.p2.1"><span class="ltx_text ltx_font_bold" id="S5.SS3.SSS4.p2.1.1">Obtaining Chemical Formulas and SMILES</span></p>
</div>
<div class="ltx_para" id="S5.SS3.SSS4.p3">
<p class="ltx_p" id="S5.SS3.SSS4.p3.1">Using GPT-4, we obtained the chemical formulas and SMILES for the top 100 Metals and the top 20 Solvents after disambiguation and merging. For Organic Linkers, due to the complexity of their naming, GPT-4 could not accurately obtain the corresponding SMILES. Therefore, we manually collected the SMILES for the top 135 Organic Linkers after disambiguation and merging.</p>
</div>
<div class="ltx_para" id="S5.SS3.SSS4.p4">
<p class="ltx_p" id="S5.SS3.SSS4.p4.1"><span class="ltx_text ltx_font_bold" id="S5.SS3.SSS4.p4.1.1">Calculating Molecular Features</span></p>
</div>
<div class="ltx_para" id="S5.SS3.SSS4.p5">
<p class="ltx_p" id="S5.SS3.SSS4.p5.1">Based on the obtained SMILES, we used RDKit to calculate the molecular features of Metals, Organic Linkers, and Solvents, including molecular weight, LogP values, the number of hydrogen bond donors and acceptors, Labute surface area, maximum molecular distance, molecular length, width, height, and topological polar surface area (TPSA).</p>
</div>
<div class="ltx_para" id="S5.SS3.SSS4.p6">
<p class="ltx_p" id="S5.SS3.SSS4.p6.1"><span class="ltx_text ltx_font_bold" id="S5.SS3.SSS4.p6.1.1">Calculating Metal Salt Features</span></p>
</div>
<div class="ltx_para" id="S5.SS3.SSS4.p7">
<p class="ltx_p" id="S5.SS3.SSS4.p7.1">Using the Composition class from Pymatgen, we automatically inferred and assigned oxidation states for the chemical formulas of metal salts. Using the MultipleFeaturizer class from the Matminer library, we calculated a series of chemical features, including elemental properties, atomic orbitals, electron affinity, and electronegativity differences. Additionally, we included features of the metal elements contained in the MOFs, such as atomic mass, atomic radius, thermal conductivity, and detailed electronic configuration vector representations. These features provide more comprehensive elemental property information for in-depth analysis of the performance and behavior of MOFs.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S5.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4 </span>Visual MOFs Synthesis Condition Extraction Engine and Database</h3>
<div class="ltx_para" id="S5.SS4.p1">
<p class="ltx_p" id="S5.SS4.p1.1"><span class="ltx_text ltx_font_bold" id="S5.SS4.p1.1.1">Database and Engine</span></p>
</div>
<div class="ltx_para" id="S5.SS4.p2">
<p class="ltx_p" id="S5.SS4.p2.1">To streamline the entire workflow and efficiently organize the extraction results from related papers, we developed the Visual MOFs Synthesis Extraction Engine and Database.
Using our approach, we processed over 30,000 papers and extracted 57,081 synthesis paragraphs, on which we then performed synthesis condition extraction. To better view and analyze the vast amount of extraction results, we built a comprehensive database with 2 features: 1) Basic Statistics: The database provides basic statistics on all extraction results, including data on synthesis paragraphs and various synthesis conditions (Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S5.F11" title="Figure 11 ‚Ä£ 5.4 Visual MOFs Synthesis Condition Extraction Engine and Database ‚Ä£ 5 Appendix ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_tag">11</span></a>). 2) Advanced Search Capabilities: This database is designed to support logical expression searches for specific fields, allowing users to search for synthesis conditions, paper titles, and synthesis paragraph content with precision, and enables visualization of the retrieval results.</p>
</div>
<figure class="ltx_figure" id="S5.F11"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="519" id="S5.F11.g1" src="x11.png" width="691"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 11: </span>Statistics on the database containing all the extraction results.</figcaption>
</figure>
<div class="ltx_para" id="S5.SS4.p3">
<p class="ltx_p" id="S5.SS4.p3.1">An entire process is integrated, from uploading synthesis papers, format conversion, paragraph and condition extraction, to the visualization of extraction results:</p>
<ol class="ltx_enumerate" id="S5.I3">
<li class="ltx_item" id="S5.I3.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S5.I3.i1.p1">
<p class="ltx_p" id="S5.I3.i1.p1.1">Upload and Standardization: Users can upload synthesis papers, which are then automatically converted into a standardized format suitable for condition extraction.</p>
</div>
</li>
<li class="ltx_item" id="S5.I3.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S5.I3.i2.p1">
<p class="ltx_p" id="S5.I3.i2.p1.1">Automatic Paragraph Extraction: The system will automatically extract synthesis paragraphs from the uploaded papers for users to select the paragraphs to process and proceed with synthesis condition extraction.</p>
</div>
</li>
<li class="ltx_item" id="S5.I3.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S5.I3.i3.p1">
<p class="ltx_p" id="S5.I3.i3.p1.1">Configurable Extraction: The engine supports configuration for synthesis condition extraction, allowing users to adjust the sample quantity and selection method input into the large model.</p>
</div>
</li>
<li class="ltx_item" id="S5.I3.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span>
<div class="ltx_para" id="S5.I3.i4.p1">
<p class="ltx_p" id="S5.I3.i4.p1.1">Organized and Visualized Data: The extracted conditions are systematically organized and visualized for data interpretation and analysis.</p>
</div>
</li>
</ol>
</div>
<div class="ltx_para" id="S5.SS4.p4">
<p class="ltx_p" id="S5.SS4.p4.1"><span class="ltx_text ltx_font_bold" id="S5.SS4.p4.1.1">Synthesis Visualization</span></p>
</div>
<figure class="ltx_figure" id="S5.F12"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="354" id="S5.F12.g1" src="x12.png" width="692"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 12: </span>Visualization interface for illustrating the synthesis extraction process and result.</figcaption>
</figure>
<div class="ltx_para" id="S5.SS4.p5">
<p class="ltx_p" id="S5.SS4.p5.1">The visualization system we designed can support users in analyzing synthesis paragraphs. Initially, users upload batch PDF papers and process through the LLM. Once extraction is complete, users can utilize the filtering panel to select specific paragraphs for analysis. The overall performance panel (Fig.<a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S5.F12" title="Figure 12 ‚Ä£ 5.4 Visual MOFs Synthesis Condition Extraction Engine and Database ‚Ä£ 5 Appendix ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_tag">12</span></a>(a)) then displays four key performance metrics of the LLM resolution, with a default HeatMap (Fig.<a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S5.F12" title="Figure 12 ‚Ä£ 5.4 Visual MOFs Synthesis Condition Extraction Engine and Database ‚Ä£ 5 Appendix ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_tag">12</span></a>(b).I) providing a detailed view of entity resolution performance across all evaluation metrics. Suppose further detail on specific metrics is needed. In that case, users can access the second tab (Fig.<a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S5.F12" title="Figure 12 ‚Ä£ 5.4 Visual MOFs Synthesis Condition Extraction Engine and Database ‚Ä£ 5 Appendix ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_tag">12</span></a>(b).II), sliding down to the relevant rows to view the distribution of paragraph performance across various parameters in bar charts. To explore similarities with other paragraphs in the database, users can switch to the third tab (Fig.<a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S5.F12" title="Figure 12 ‚Ä£ 5.4 Visual MOFs Synthesis Condition Extraction Engine and Database ‚Ä£ 5 Appendix ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_tag">12</span></a>(b).III). Here, red dots indicate newly extracted paragraphs; users can look for nearby black dots representing similar paragraphs in the database to compare specific composite parameters. Should users decide to replace or re-examine certain paragraphs, they can reselect them in the filtering panel (Fig.<a class="ltx_ref" href="https://arxiv.org/html/2408.04665v1#S5.F12" title="Figure 12 ‚Ä£ 5.4 Visual MOFs Synthesis Condition Extraction Engine and Database ‚Ä£ 5 Appendix ‚Ä£ LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations"><span class="ltx_text ltx_ref_tag">12</span></a>(c)). This action triggers an automatic update of the corresponding performance metrics and visual charts, allowing users to repeat the analysis as needed.</p>
</div>
</section>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
GPT-4, OpenAI.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openai.com/index/gpt-4/" title="">https://openai.com/index/gpt-4/</a>.

</span>
<span class="ltx_bibblock">Retrieved on 2024-01-25.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
What is a MOF, MOF Commission of the International Zeolite Association.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.iza-online.org/MOF/MOFforIZA.pdf" title="">https://www.iza-online.org/MOF/MOFforIZA.pdf</a>.

</span>
<span class="ltx_bibblock">Retrieved on 2024-07-10.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
J.¬†Achiam, S.¬†Adler, S.¬†Agarwal, L.¬†Ahmad, I.¬†Akkaya, F.¬†L. Aleman, D.¬†Almeida, J.¬†Altenschmidt, S.¬†Altman, S.¬†Anadkat, et¬†al.

</span>
<span class="ltx_bibblock">Gpt-4 technical report.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib3.1.1">arXiv preprint arXiv:2303.08774</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
T.¬†Akiba, S.¬†Sano, T.¬†Yanase, T.¬†Ohta, and M.¬†Koyama.

</span>
<span class="ltx_bibblock">Optuna: A next-generation hyperparameter optimization framework.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic" id="bib.bib4.1.1">The 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</span>, pages 2623‚Äì2631, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
A.¬†H. Alawadhi, S.¬†Chheda, G.¬†D. Stroscio, Z.¬†Rong, D.¬†Kurandina, H.¬†L. Nguyen, N.¬†Rampal, Z.¬†Zheng, L.¬†Gagliardi, and O.¬†M. Yaghi.

</span>
<span class="ltx_bibblock">Harvesting water from air with high-capacity, stable furan-based metal‚Äìorganic frameworks.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib5.1.1">Journal of the American Chemical Society</span>, 146(3):2160‚Äì2166, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
T.¬†Brown, B.¬†Mann, N.¬†Ryder, M.¬†Subbiah, J.¬†D. Kaplan, P.¬†Dhariwal, A.¬†Neelakantan, P.¬†Shyam, G.¬†Sastry, A.¬†Askell, et¬†al.

</span>
<span class="ltx_bibblock">Language models are few-shot learners.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib6.1.1">Advances in neural information processing systems</span>, 33:1877‚Äì1901, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
J.¬†Dagdelen, A.¬†Dunn, S.¬†Lee, N.¬†Walker, A.¬†S. Rosen, G.¬†Ceder, K.¬†A. Persson, and A.¬†Jain.

</span>
<span class="ltx_bibblock">Structured information extraction from scientific text with large language models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib7.1.1">Nature Communications</span>, 15(1):1418, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
J.¬†Devlin, M.-W. Chang, K.¬†Lee, and K.¬†Toutanova.

</span>
<span class="ltx_bibblock">Bert: Pre-training of deep bidirectional transformers for language understanding.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib8.1.1">arXiv preprint arXiv:1810.04805</span>, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Q.¬†Dong, L.¬†Li, D.¬†Dai, C.¬†Zheng, Z.¬†Wu, B.¬†Chang, X.¬†Sun, J.¬†Xu, and Z.¬†Sui.

</span>
<span class="ltx_bibblock">A survey on in-context learning.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib9.1.1">arXiv preprint arXiv:2301.00234</span>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Y.¬†Gao, Y.¬†Xiong, X.¬†Gao, K.¬†Jia, J.¬†Pan, Y.¬†Bi, Y.¬†Dai, J.¬†Sun, and H.¬†Wang.

</span>
<span class="ltx_bibblock">Retrieval-augmented generation for large language models: A survey.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib10.1.1">arXiv preprint arXiv:2312.10997</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
H.¬†Liu, D.¬†Tam, M.¬†Muqeeth, J.¬†Mohta, T.¬†Huang, M.¬†Bansal, and C.¬†A. Raffel.

</span>
<span class="ltx_bibblock">Few-shot parameter-efficient fine-tuning is better and cheaper than in-context learning.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib11.1.1">Advances in Neural Information Processing Systems</span>, 35:1950‚Äì1965, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
J.¬†Liu, D.¬†Shen, Y.¬†Zhang, B.¬†Dolan, L.¬†Carin, and W.¬†Chen.

</span>
<span class="ltx_bibblock">What makes good in-context examples for gpt-<math alttext="3" class="ltx_Math" display="inline" id="bib.bib12.1.m1.1"><semantics id="bib.bib12.1.m1.1a"><mn id="bib.bib12.1.m1.1.1" xref="bib.bib12.1.m1.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="bib.bib12.1.m1.1b"><cn id="bib.bib12.1.m1.1.1.cmml" type="integer" xref="bib.bib12.1.m1.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="bib.bib12.1.m1.1c">3</annotation><annotation encoding="application/x-llamapun" id="bib.bib12.1.m1.1d">3</annotation></semantics></math>?

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib12.2.1">arXiv preprint arXiv:2101.06804</span>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Y.¬†Luo, S.¬†Bag, O.¬†Zaremba, A.¬†Cierpka, J.¬†Andreo, S.¬†Wuttke, P.¬†Friederich, and M.¬†Tsotsalas.

</span>
<span class="ltx_bibblock">Mof synthesis prediction enabled by automatic data mining and machine learning.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib13.1.1">Angewandte Chemie International Edition</span>, 61(19):e202200242, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
P.¬†Z. Moghadam, A.¬†Li, S.¬†B. Wiggin, A.¬†Tao, A.¬†G. Maloney, P.¬†A. Wood, S.¬†C. Ward, and D.¬†Fairen-Jimenez.

</span>
<span class="ltx_bibblock">Development of a cambridge structural database subset: a collection of metal‚Äìorganic frameworks for past, present, and future.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib14.1.1">Chemistry of Materials</span>, 29(7):2618‚Äì2625, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
M.¬†Mosbach, T.¬†Pimentel, S.¬†Ravfogel, D.¬†Klakow, and Y.¬†Elazar.

</span>
<span class="ltx_bibblock">Few-shot fine-tuning vs. in-context learning: A fair comparison and evaluation.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib15.1.1">arXiv preprint arXiv:2305.16938</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
M.¬†P. Polak and D.¬†Morgan.

</span>
<span class="ltx_bibblock">Extracting accurate materials data from research papers with conversational language models and prompt engineering.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib16.1.1">Nature Communications</span>, 15(1):1569, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
N.¬†Reimers and I.¬†Gurevych.

</span>
<span class="ltx_bibblock">Sentence-bert: Sentence embeddings using siamese bert-networks.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib17.1.1">arXiv preprint arXiv:1908.10084</span>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
S.¬†Robertson, H.¬†Zaragoza, et¬†al.

</span>
<span class="ltx_bibblock">The probabilistic relevance framework: Bm25 and beyond.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib18.1.1">Foundations and Trends¬Æ in Information Retrieval</span>, 3(4):333‚Äì389, 2009.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
H.¬†Su, J.¬†Kasai, C.¬†H. Wu, W.¬†Shi, T.¬†Wang, J.¬†Xin, R.¬†Zhang, M.¬†Ostendorf, L.¬†Zettlemoyer, N.¬†A. Smith, et¬†al.

</span>
<span class="ltx_bibblock">Selective annotation makes language models better few-shot learners.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib19.1.1">arXiv preprint arXiv:2209.01975</span>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
H.¬†Tian, W.¬†Liu, and other contributors.

</span>
<span class="ltx_bibblock">pdf2htmlex.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/pdf2htmlEX/pdf2htmlEX" title="">https://github.com/pdf2htmlEX/pdf2htmlEX</a>, 2024.

</span>
<span class="ltx_bibblock">Accessed: 2024-07-18.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
J.¬†White, Q.¬†Fu, S.¬†Hays, M.¬†Sandborn, C.¬†Olea, H.¬†Gilbert, A.¬†Elnashar, J.¬†Spencer-Smith, and D.¬†C. Schmidt.

</span>
<span class="ltx_bibblock">A prompt pattern catalog to enhance prompt engineering with chatgpt.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib21.1.1">arXiv preprint arXiv:2302.11382</span>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
T.¬†F. Willems, C.¬†H. Rycroft, M.¬†Kazi, J.¬†C. Meza, and M.¬†Haranczyk.

</span>
<span class="ltx_bibblock">Algorithms and tools for high-throughput geometry-based analysis of crystalline porous materials.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib22.1.1">Microporous and Mesoporous Materials</span>, 149(1):134‚Äì141, 2012.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
O.¬†M. Yaghi, M.¬†O‚ÄôKeeffe, N.¬†W. Ockwig, H.¬†K. Chae, M.¬†Eddaoudi, and J.¬†Kim.

</span>
<span class="ltx_bibblock">Reticular synthesis and the design of new materials.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib23.1.1">Nature</span>, 423(6941):705‚Äì714, 2003.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Z.¬†Zheng, O.¬†Zhang, C.¬†Borgs, J.¬†T. Chayes, and O.¬†M. Yaghi.

</span>
<span class="ltx_bibblock">Chatgpt chemistry assistant for text mining and the prediction of mof synthesis.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic" id="bib.bib24.1.1">Journal of the American Chemical Society</span>, 145(32):18048‚Äì18062, 2023.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Tue Aug  6 14:43:34 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
