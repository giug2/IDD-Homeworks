<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2202.11836] Sky Computing: Accelerating Geo-distributed Computing in Federated Learning</title><meta property="og:description" content="Federated learning is proposed by Google to safeguard data privacy through training models locally on users’ devices. However, with deep learning models growing in size to achieve better results, it becomes increasingl…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Sky Computing: Accelerating Geo-distributed Computing in Federated Learning">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Sky Computing: Accelerating Geo-distributed Computing in Federated Learning">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2202.11836">

<!--Generated on Thu Mar  7 21:14:21 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="
Federated Learning,  Model Parallelism,  Load Balance
">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Sky Computing: Accelerating Geo-distributed Computing in Federated Learning</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jie Zhu<sup id="id1.1.id1" class="ltx_sup">*</sup>
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id2.2.id1" class="ltx_text ltx_font_italic">HPC-AI Technology Inc.</span>
<br class="ltx_break">Equal contribution<sup id="id3.3.id2" class="ltx_sup">*</sup>
<br class="ltx_break">contact@hpcaitech.com
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Shengui Li<sup id="id4.1.id1" class="ltx_sup">*</sup>
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id5.2.id1" class="ltx_text ltx_font_italic">HPC-AI Technology Inc.</span>
<br class="ltx_break">Equal contribution<sup id="id6.3.id2" class="ltx_sup">*</sup>
<br class="ltx_break">lisg@hpcaitech.com
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yang You
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id7.1.id1" class="ltx_text ltx_font_italic">National University of Singapore</span>
<br class="ltx_break">Work done at HPC-AI Technology Inc.
<br class="ltx_break">youy@comp.nus.edu.sg
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id8.id1" class="ltx_p">Federated learning is proposed by Google to safeguard data privacy through training models locally on users’ devices. However, with deep learning models growing in size to achieve better results, it becomes increasingly difficult to accommodate the whole model on one single device. Thus, model parallelism is then used to divide the model weights among several devices. With this logic, the approach currently used evenly allocates weights among devices. However, in reality, a computation bottleneck may occur resulting from variant computing power of different users’ devices. To address this problem, load balancing is needed to allocate the model weights based on the computational capability of the device. In this paper, we proposed Sky Computing, a load-balanced model parallelism framework to adaptively allocate the weights to devices. Sky Computing outperforms the baseline method by 55% in training time when training 160-layer BERT with 64 nodes.
The source code can be found at <a target="_blank" href="https://github.com/hpcaitech/SkyComputing" title="" class="ltx_ref ltx_href"><span id="id8.id1.1.1" class="ltx_text ltx_framed ltx_framed_underline">https://github.com/hpcaitech/SkyComputing</span></a>.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
Federated Learning, Model Parallelism, Load Balance

</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">With the bloom of deep learning, the sizes of the models keep increasing. This is especially significant in Natural Language Processing area as models like BERT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> and GPT-3 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> emerged with billions of parameters. These models have shown their capabilities of exploring and processing the vast amount of semantics embedded in the text, and delivering the state-of-the-art performance with which small models cannot compete. Even though some methods such as knowledge distillation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> and model compression <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> have been used to speed up the training, it is undeniable that these methods generally cause a decrease in performance. Meanwhile, we expect that more powerful computational capability will be brought by new hardware and more large-scale datasets will come out in the future. Thus, the increasing trend of model size is expected to continue.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">At the same time, with the increasing scalability of applications and the explosive growth of computational capability of hardware, more and more companys tend to combine the local devices or traditional cloud resources. This geo-distributed computing will be extremely significant in deep learning, as we mentioned above, the size of model is continuously expanding and thus need more hardware resources.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">In general, training these models requires a large amount of data which are collected by many companies from their users. For example, the text input applications can train a prediction model which recommends the next word for sentence completion. They can use the current sentence as the input data and the user-selected words as the label to train the model. In this way, the model can better capture user behavior and does not require extra data from external parties.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">However, as concerns over data privacy are raised worldwide, it is difficult to directly collect and store the user data in the servers without the user’s consent. To solve this problem, federated learning was proposed by Google which introduces a mechanism for local model training on user’s devices without sharing the data with the service providers <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>. This ensures that data is only kept on the user’s device and stays intact. One disadvantage of federated learning is that the users’ devices are generally mobile phones, tablets, and personal computers, and model training is limited by the device hardware specifications, especially CPU, GPU, and RAM. It is thus challenging to train a large-scale model on these devices since it is impossible to fit the entire model into one single device and there may exist computation bottlenecks due to the variance in computational capability.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">Since the heterogeneity of training equipment is relatively high, we shall consider it as an perfect situation for geo-distributed computing. And thus we can reduce the training time by accelerating geo-distributed computing.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">In this paper, we proposed a new federated learning framework Sky Computing which exploits the feature of geo-distributed computing by using a load-balanced strategy in model parallelism to train large-scale models on the users’ devices in federated learning. Model parallelism distributes the weights on the devices. With more devices participating in federated learning, the average size of model weights allocated to each device is smaller, making it possible to train large-scale models. Load balancing is an efficient method in geo-distributed computing, and it is necessary for model-parallel training as the relatively slow devices can slow down the entire training process and incur the computation bottleneck.</p>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p">It is not ideal if too much computation is allocated to devices with weaker computing power. In federated learning, the users’ devices participating in model training are also changing dynamically and their computing power is unpredictable. Thus, we cannot pre-allocate the model weights to these devices. In contrast, our Sky Computing can adaptively allocate the model layers to the devices based on the model information and device performance. In this way, the Sky Computing can eliminate the computation bottleneck and reduce the training time. In our experiments to train a 160-layer BERT, our approach can outperform the baseline approach by 55% in terms of training time when using 64 nodes. The source code can be found at <a target="_blank" href="https://github.com/hpcaitech/SkyComputing" title="" class="ltx_ref ltx_href"><span id="S1.p7.1.1.1" class="ltx_text ltx_framed ltx_framed_underline">https://github.com/hpcaitech/SkyComputing</span></a>.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Background</span>
</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS1.5.1.1" class="ltx_text">II-A</span> </span><span id="S2.SS1.6.2" class="ltx_text ltx_font_italic">Geo-distributed Computing</span>
</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">The growing ubiquity of computing devices, including smart phones and cloud servers produced large and fluctuating volumes of data and therefore required high-speed, highly available and resource efficient data processing to ensure low response times for specific activities. Plus, aggregating and processing data at a centralized cloud platform is not adequate to meet the requirements of many problems, especially considering data privacy. And the geo-distributed computing, which connects devices at different levels together, is a perfect solution to these two problems. The heterogeneity of computing resources becomes the major hinder to design algorithm and allocation work load, but in the other hand it also could be exploited as a feature.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS2.5.1.1" class="ltx_text">II-B</span> </span><span id="S2.SS2.6.2" class="ltx_text ltx_font_italic">Federated Learning</span>
</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">Federated learning is a paradigm of collaborative learning with distributed training data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>. In standard machine learning, the training data is stored in a centralized location and the data is sent to one or more machines for training. However, in commercial scenarios, engineers need to collect data from the users before the model can be trained. Thus, the standard mechanism cannot be applied with increasing concerns over data privacy.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p">Federated learning was proposed to replace the centralized training fashion with a decentralized training mechanism. The gist of federated learning is that the users can train the model locally on their devices without communicating personal data with others. In current methods, each user’s device holds a copy of the model weights and uses the local data to train the model. To perform a global update of the model, only the gradients are passed back to the central server using encrypted communication. A back-propagation algorithm is performed to update the weights on the remote server using the Federated Averaging algorithm <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>. The updated model weights are then broadcast back to the users’ devices to update the local model as shown in Figure <a href="#S2.F1" title="Figure 1 ‣ II-B Federated Learning ‣ II Background ‣ Sky Computing: Accelerating Geo-distributed Computing in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. In this way, the devices can collaboratively learn a shared and smarter prediction model while the users’ data are kept invisible from the external parties to safeguard user privacy.</p>
</div>
<figure id="S2.F1" class="ltx_figure"><img src="/html/2202.11836/assets/figures/federated.png" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="538" height="372" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F1.2.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S2.F1.3.2" class="ltx_text" style="font-size:90%;">Architecture for Federated Learning</span></figcaption>
</figure>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS3.5.1.1" class="ltx_text">II-C</span> </span><span id="S2.SS3.6.2" class="ltx_text ltx_font_italic">BERT</span>
</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">BERT stands for Bidirectional Encoder Representations from Transformers and is one of the state-of-the-art deep learning models for Natural Language Processing <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. BERT yields superior performance in language tasks such as text classification, translation, and text synthesis and has been widely transferred to other fields such as Computer Vision. Its core module is the encoder layer, which relies on the self-attention mechanism to learn text representation. Self-attention is intrinsical to calculate the output tensor as a weighted sum of the input tensors. The encoder layer provides the self-attention mechanism to explore the correlation between words in a sentence and to better capture the text semantics in different contexts. The encoder layers can be succeeded by various projection heads for different downstream tasks.</p>
</div>
<div id="S2.SS3.p2" class="ltx_para">
<p id="S2.SS3.p2.11" class="ltx_p">In the encoder layer, the self-attention layer plays a pivotal role in understanding the context embedded in the sentence. The input data of the self-attention layer consists of a batch of sentences in the shape of <math id="S2.SS3.p2.1.m1.3" class="ltx_Math" alttext="(b,n,h)" display="inline"><semantics id="S2.SS3.p2.1.m1.3a"><mrow id="S2.SS3.p2.1.m1.3.4.2" xref="S2.SS3.p2.1.m1.3.4.1.cmml"><mo stretchy="false" id="S2.SS3.p2.1.m1.3.4.2.1" xref="S2.SS3.p2.1.m1.3.4.1.cmml">(</mo><mi id="S2.SS3.p2.1.m1.1.1" xref="S2.SS3.p2.1.m1.1.1.cmml">b</mi><mo id="S2.SS3.p2.1.m1.3.4.2.2" xref="S2.SS3.p2.1.m1.3.4.1.cmml">,</mo><mi id="S2.SS3.p2.1.m1.2.2" xref="S2.SS3.p2.1.m1.2.2.cmml">n</mi><mo id="S2.SS3.p2.1.m1.3.4.2.3" xref="S2.SS3.p2.1.m1.3.4.1.cmml">,</mo><mi id="S2.SS3.p2.1.m1.3.3" xref="S2.SS3.p2.1.m1.3.3.cmml">h</mi><mo stretchy="false" id="S2.SS3.p2.1.m1.3.4.2.4" xref="S2.SS3.p2.1.m1.3.4.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.1.m1.3b"><vector id="S2.SS3.p2.1.m1.3.4.1.cmml" xref="S2.SS3.p2.1.m1.3.4.2"><ci id="S2.SS3.p2.1.m1.1.1.cmml" xref="S2.SS3.p2.1.m1.1.1">𝑏</ci><ci id="S2.SS3.p2.1.m1.2.2.cmml" xref="S2.SS3.p2.1.m1.2.2">𝑛</ci><ci id="S2.SS3.p2.1.m1.3.3.cmml" xref="S2.SS3.p2.1.m1.3.3">ℎ</ci></vector></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.1.m1.3c">(b,n,h)</annotation></semantics></math> where <math id="S2.SS3.p2.2.m2.1" class="ltx_Math" alttext="b" display="inline"><semantics id="S2.SS3.p2.2.m2.1a"><mi id="S2.SS3.p2.2.m2.1.1" xref="S2.SS3.p2.2.m2.1.1.cmml">b</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.2.m2.1b"><ci id="S2.SS3.p2.2.m2.1.1.cmml" xref="S2.SS3.p2.2.m2.1.1">𝑏</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.2.m2.1c">b</annotation></semantics></math> is the batch size, <math id="S2.SS3.p2.3.m3.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S2.SS3.p2.3.m3.1a"><mi id="S2.SS3.p2.3.m3.1.1" xref="S2.SS3.p2.3.m3.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.3.m3.1b"><ci id="S2.SS3.p2.3.m3.1.1.cmml" xref="S2.SS3.p2.3.m3.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.3.m3.1c">n</annotation></semantics></math> is the number of tokens in the sentence and <math id="S2.SS3.p2.4.m4.1" class="ltx_Math" alttext="h" display="inline"><semantics id="S2.SS3.p2.4.m4.1a"><mi id="S2.SS3.p2.4.m4.1.1" xref="S2.SS3.p2.4.m4.1.1.cmml">h</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.4.m4.1b"><ci id="S2.SS3.p2.4.m4.1.1.cmml" xref="S2.SS3.p2.4.m4.1.1">ℎ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.4.m4.1c">h</annotation></semantics></math> is the hidden size of the tensor for each token. This embedding tensor is used to compute other three tensors: query <math id="S2.SS3.p2.5.m5.1" class="ltx_Math" alttext="Q" display="inline"><semantics id="S2.SS3.p2.5.m5.1a"><mi id="S2.SS3.p2.5.m5.1.1" xref="S2.SS3.p2.5.m5.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.5.m5.1b"><ci id="S2.SS3.p2.5.m5.1.1.cmml" xref="S2.SS3.p2.5.m5.1.1">𝑄</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.5.m5.1c">Q</annotation></semantics></math>, key <math id="S2.SS3.p2.6.m6.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S2.SS3.p2.6.m6.1a"><mi id="S2.SS3.p2.6.m6.1.1" xref="S2.SS3.p2.6.m6.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.6.m6.1b"><ci id="S2.SS3.p2.6.m6.1.1.cmml" xref="S2.SS3.p2.6.m6.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.6.m6.1c">K</annotation></semantics></math>, and value <math id="S2.SS3.p2.7.m7.1" class="ltx_Math" alttext="V" display="inline"><semantics id="S2.SS3.p2.7.m7.1a"><mi id="S2.SS3.p2.7.m7.1.1" xref="S2.SS3.p2.7.m7.1.1.cmml">V</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.7.m7.1b"><ci id="S2.SS3.p2.7.m7.1.1.cmml" xref="S2.SS3.p2.7.m7.1.1">𝑉</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.7.m7.1c">V</annotation></semantics></math> by multiplying with three different matrices of the same shape <math id="S2.SS3.p2.8.m8.2" class="ltx_Math" alttext="(h,v)" display="inline"><semantics id="S2.SS3.p2.8.m8.2a"><mrow id="S2.SS3.p2.8.m8.2.3.2" xref="S2.SS3.p2.8.m8.2.3.1.cmml"><mo stretchy="false" id="S2.SS3.p2.8.m8.2.3.2.1" xref="S2.SS3.p2.8.m8.2.3.1.cmml">(</mo><mi id="S2.SS3.p2.8.m8.1.1" xref="S2.SS3.p2.8.m8.1.1.cmml">h</mi><mo id="S2.SS3.p2.8.m8.2.3.2.2" xref="S2.SS3.p2.8.m8.2.3.1.cmml">,</mo><mi id="S2.SS3.p2.8.m8.2.2" xref="S2.SS3.p2.8.m8.2.2.cmml">v</mi><mo stretchy="false" id="S2.SS3.p2.8.m8.2.3.2.3" xref="S2.SS3.p2.8.m8.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.8.m8.2b"><interval closure="open" id="S2.SS3.p2.8.m8.2.3.1.cmml" xref="S2.SS3.p2.8.m8.2.3.2"><ci id="S2.SS3.p2.8.m8.1.1.cmml" xref="S2.SS3.p2.8.m8.1.1">ℎ</ci><ci id="S2.SS3.p2.8.m8.2.2.cmml" xref="S2.SS3.p2.8.m8.2.2">𝑣</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.8.m8.2c">(h,v)</annotation></semantics></math> where <math id="S2.SS3.p2.9.m9.1" class="ltx_Math" alttext="h" display="inline"><semantics id="S2.SS3.p2.9.m9.1a"><mi id="S2.SS3.p2.9.m9.1.1" xref="S2.SS3.p2.9.m9.1.1.cmml">h</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.9.m9.1b"><ci id="S2.SS3.p2.9.m9.1.1.cmml" xref="S2.SS3.p2.9.m9.1.1">ℎ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.9.m9.1c">h</annotation></semantics></math> is the token hidden size and <math id="S2.SS3.p2.10.m10.1" class="ltx_Math" alttext="v" display="inline"><semantics id="S2.SS3.p2.10.m10.1a"><mi id="S2.SS3.p2.10.m10.1.1" xref="S2.SS3.p2.10.m10.1.1.cmml">v</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.10.m10.1b"><ci id="S2.SS3.p2.10.m10.1.1.cmml" xref="S2.SS3.p2.10.m10.1.1">𝑣</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.10.m10.1c">v</annotation></semantics></math> is the size of the attention heads. The output of the self-attention layer is obtained as shown in the equation <a href="#S2.E1" title="In II-C BERT ‣ II Background ‣ Sky Computing: Accelerating Geo-distributed Computing in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> where <math id="S2.SS3.p2.11.m11.1" class="ltx_Math" alttext="d_{k}" display="inline"><semantics id="S2.SS3.p2.11.m11.1a"><msub id="S2.SS3.p2.11.m11.1.1" xref="S2.SS3.p2.11.m11.1.1.cmml"><mi id="S2.SS3.p2.11.m11.1.1.2" xref="S2.SS3.p2.11.m11.1.1.2.cmml">d</mi><mi id="S2.SS3.p2.11.m11.1.1.3" xref="S2.SS3.p2.11.m11.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.11.m11.1b"><apply id="S2.SS3.p2.11.m11.1.1.cmml" xref="S2.SS3.p2.11.m11.1.1"><csymbol cd="ambiguous" id="S2.SS3.p2.11.m11.1.1.1.cmml" xref="S2.SS3.p2.11.m11.1.1">subscript</csymbol><ci id="S2.SS3.p2.11.m11.1.1.2.cmml" xref="S2.SS3.p2.11.m11.1.1.2">𝑑</ci><ci id="S2.SS3.p2.11.m11.1.1.3.cmml" xref="S2.SS3.p2.11.m11.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.11.m11.1c">d_{k}</annotation></semantics></math> is the dimension of the key <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. This mechanism allows each token to reference the semantic embedding of other tokens in the same sentence and calculate their relative importance in the context.</p>
</div>
<div id="S2.SS3.p3" class="ltx_para">
<table id="S2.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E1.m1.4" class="ltx_Math" alttext="\text{Attention}(Q,K,V)=\text{softmax}(QK^{T}/\sqrt{d_{k}})V" display="block"><semantics id="S2.E1.m1.4a"><mrow id="S2.E1.m1.4.4" xref="S2.E1.m1.4.4.cmml"><mrow id="S2.E1.m1.4.4.3" xref="S2.E1.m1.4.4.3.cmml"><mtext id="S2.E1.m1.4.4.3.2" xref="S2.E1.m1.4.4.3.2a.cmml">Attention</mtext><mo lspace="0em" rspace="0em" id="S2.E1.m1.4.4.3.1" xref="S2.E1.m1.4.4.3.1.cmml">​</mo><mrow id="S2.E1.m1.4.4.3.3.2" xref="S2.E1.m1.4.4.3.3.1.cmml"><mo stretchy="false" id="S2.E1.m1.4.4.3.3.2.1" xref="S2.E1.m1.4.4.3.3.1.cmml">(</mo><mi id="S2.E1.m1.1.1" xref="S2.E1.m1.1.1.cmml">Q</mi><mo id="S2.E1.m1.4.4.3.3.2.2" xref="S2.E1.m1.4.4.3.3.1.cmml">,</mo><mi id="S2.E1.m1.2.2" xref="S2.E1.m1.2.2.cmml">K</mi><mo id="S2.E1.m1.4.4.3.3.2.3" xref="S2.E1.m1.4.4.3.3.1.cmml">,</mo><mi id="S2.E1.m1.3.3" xref="S2.E1.m1.3.3.cmml">V</mi><mo stretchy="false" id="S2.E1.m1.4.4.3.3.2.4" xref="S2.E1.m1.4.4.3.3.1.cmml">)</mo></mrow></mrow><mo id="S2.E1.m1.4.4.2" xref="S2.E1.m1.4.4.2.cmml">=</mo><mrow id="S2.E1.m1.4.4.1" xref="S2.E1.m1.4.4.1.cmml"><mtext id="S2.E1.m1.4.4.1.3" xref="S2.E1.m1.4.4.1.3a.cmml">softmax</mtext><mo lspace="0em" rspace="0em" id="S2.E1.m1.4.4.1.2" xref="S2.E1.m1.4.4.1.2.cmml">​</mo><mrow id="S2.E1.m1.4.4.1.1.1" xref="S2.E1.m1.4.4.1.1.1.1.cmml"><mo stretchy="false" id="S2.E1.m1.4.4.1.1.1.2" xref="S2.E1.m1.4.4.1.1.1.1.cmml">(</mo><mrow id="S2.E1.m1.4.4.1.1.1.1" xref="S2.E1.m1.4.4.1.1.1.1.cmml"><mrow id="S2.E1.m1.4.4.1.1.1.1.2" xref="S2.E1.m1.4.4.1.1.1.1.2.cmml"><mi id="S2.E1.m1.4.4.1.1.1.1.2.2" xref="S2.E1.m1.4.4.1.1.1.1.2.2.cmml">Q</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.4.4.1.1.1.1.2.1" xref="S2.E1.m1.4.4.1.1.1.1.2.1.cmml">​</mo><msup id="S2.E1.m1.4.4.1.1.1.1.2.3" xref="S2.E1.m1.4.4.1.1.1.1.2.3.cmml"><mi id="S2.E1.m1.4.4.1.1.1.1.2.3.2" xref="S2.E1.m1.4.4.1.1.1.1.2.3.2.cmml">K</mi><mi id="S2.E1.m1.4.4.1.1.1.1.2.3.3" xref="S2.E1.m1.4.4.1.1.1.1.2.3.3.cmml">T</mi></msup></mrow><mo id="S2.E1.m1.4.4.1.1.1.1.1" xref="S2.E1.m1.4.4.1.1.1.1.1.cmml">/</mo><msqrt id="S2.E1.m1.4.4.1.1.1.1.3" xref="S2.E1.m1.4.4.1.1.1.1.3.cmml"><msub id="S2.E1.m1.4.4.1.1.1.1.3.2" xref="S2.E1.m1.4.4.1.1.1.1.3.2.cmml"><mi id="S2.E1.m1.4.4.1.1.1.1.3.2.2" xref="S2.E1.m1.4.4.1.1.1.1.3.2.2.cmml">d</mi><mi id="S2.E1.m1.4.4.1.1.1.1.3.2.3" xref="S2.E1.m1.4.4.1.1.1.1.3.2.3.cmml">k</mi></msub></msqrt></mrow><mo stretchy="false" id="S2.E1.m1.4.4.1.1.1.3" xref="S2.E1.m1.4.4.1.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S2.E1.m1.4.4.1.2a" xref="S2.E1.m1.4.4.1.2.cmml">​</mo><mi id="S2.E1.m1.4.4.1.4" xref="S2.E1.m1.4.4.1.4.cmml">V</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.4b"><apply id="S2.E1.m1.4.4.cmml" xref="S2.E1.m1.4.4"><eq id="S2.E1.m1.4.4.2.cmml" xref="S2.E1.m1.4.4.2"></eq><apply id="S2.E1.m1.4.4.3.cmml" xref="S2.E1.m1.4.4.3"><times id="S2.E1.m1.4.4.3.1.cmml" xref="S2.E1.m1.4.4.3.1"></times><ci id="S2.E1.m1.4.4.3.2a.cmml" xref="S2.E1.m1.4.4.3.2"><mtext id="S2.E1.m1.4.4.3.2.cmml" xref="S2.E1.m1.4.4.3.2">Attention</mtext></ci><vector id="S2.E1.m1.4.4.3.3.1.cmml" xref="S2.E1.m1.4.4.3.3.2"><ci id="S2.E1.m1.1.1.cmml" xref="S2.E1.m1.1.1">𝑄</ci><ci id="S2.E1.m1.2.2.cmml" xref="S2.E1.m1.2.2">𝐾</ci><ci id="S2.E1.m1.3.3.cmml" xref="S2.E1.m1.3.3">𝑉</ci></vector></apply><apply id="S2.E1.m1.4.4.1.cmml" xref="S2.E1.m1.4.4.1"><times id="S2.E1.m1.4.4.1.2.cmml" xref="S2.E1.m1.4.4.1.2"></times><ci id="S2.E1.m1.4.4.1.3a.cmml" xref="S2.E1.m1.4.4.1.3"><mtext id="S2.E1.m1.4.4.1.3.cmml" xref="S2.E1.m1.4.4.1.3">softmax</mtext></ci><apply id="S2.E1.m1.4.4.1.1.1.1.cmml" xref="S2.E1.m1.4.4.1.1.1"><divide id="S2.E1.m1.4.4.1.1.1.1.1.cmml" xref="S2.E1.m1.4.4.1.1.1.1.1"></divide><apply id="S2.E1.m1.4.4.1.1.1.1.2.cmml" xref="S2.E1.m1.4.4.1.1.1.1.2"><times id="S2.E1.m1.4.4.1.1.1.1.2.1.cmml" xref="S2.E1.m1.4.4.1.1.1.1.2.1"></times><ci id="S2.E1.m1.4.4.1.1.1.1.2.2.cmml" xref="S2.E1.m1.4.4.1.1.1.1.2.2">𝑄</ci><apply id="S2.E1.m1.4.4.1.1.1.1.2.3.cmml" xref="S2.E1.m1.4.4.1.1.1.1.2.3"><csymbol cd="ambiguous" id="S2.E1.m1.4.4.1.1.1.1.2.3.1.cmml" xref="S2.E1.m1.4.4.1.1.1.1.2.3">superscript</csymbol><ci id="S2.E1.m1.4.4.1.1.1.1.2.3.2.cmml" xref="S2.E1.m1.4.4.1.1.1.1.2.3.2">𝐾</ci><ci id="S2.E1.m1.4.4.1.1.1.1.2.3.3.cmml" xref="S2.E1.m1.4.4.1.1.1.1.2.3.3">𝑇</ci></apply></apply><apply id="S2.E1.m1.4.4.1.1.1.1.3.cmml" xref="S2.E1.m1.4.4.1.1.1.1.3"><root id="S2.E1.m1.4.4.1.1.1.1.3a.cmml" xref="S2.E1.m1.4.4.1.1.1.1.3"></root><apply id="S2.E1.m1.4.4.1.1.1.1.3.2.cmml" xref="S2.E1.m1.4.4.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S2.E1.m1.4.4.1.1.1.1.3.2.1.cmml" xref="S2.E1.m1.4.4.1.1.1.1.3.2">subscript</csymbol><ci id="S2.E1.m1.4.4.1.1.1.1.3.2.2.cmml" xref="S2.E1.m1.4.4.1.1.1.1.3.2.2">𝑑</ci><ci id="S2.E1.m1.4.4.1.1.1.1.3.2.3.cmml" xref="S2.E1.m1.4.4.1.1.1.1.3.2.3">𝑘</ci></apply></apply></apply><ci id="S2.E1.m1.4.4.1.4.cmml" xref="S2.E1.m1.4.4.1.4">𝑉</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.4c">\text{Attention}(Q,K,V)=\text{softmax}(QK^{T}/\sqrt{d_{k}})V</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div id="S2.SS3.p4" class="ltx_para">
<p id="S2.SS3.p4.3" class="ltx_p">Besides the self-attention layer, there are three more linear layers with residual connection in the encoder layer. The first linear layer keeps the dimension of the output tensor <math id="S2.SS3.p4.1.m1.1" class="ltx_Math" alttext="h" display="inline"><semantics id="S2.SS3.p4.1.m1.1a"><mi id="S2.SS3.p4.1.m1.1.1" xref="S2.SS3.p4.1.m1.1.1.cmml">h</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p4.1.m1.1b"><ci id="S2.SS3.p4.1.m1.1.1.cmml" xref="S2.SS3.p4.1.m1.1.1">ℎ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p4.1.m1.1c">h</annotation></semantics></math> unchanged while the second linear layer projects the output tensor to a higher dimension <math id="S2.SS3.p4.2.m2.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S2.SS3.p4.2.m2.1a"><mi id="S2.SS3.p4.2.m2.1.1" xref="S2.SS3.p4.2.m2.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p4.2.m2.1b"><ci id="S2.SS3.p4.2.m2.1.1.cmml" xref="S2.SS3.p4.2.m2.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p4.2.m2.1c">i</annotation></semantics></math> and the third linear layer projects it back to the hidden size <math id="S2.SS3.p4.3.m3.1" class="ltx_Math" alttext="h" display="inline"><semantics id="S2.SS3.p4.3.m3.1a"><mi id="S2.SS3.p4.3.m3.1.1" xref="S2.SS3.p4.3.m3.1.1.cmml">h</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p4.3.m3.1b"><ci id="S2.SS3.p4.3.m3.1.1.cmml" xref="S2.SS3.p4.3.m3.1.1">ℎ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p4.3.m3.1c">h</annotation></semantics></math>. The architecture of the encoder layer can thus be divided into three components: attention, intermediate, and output as shown in Figure <a href="#S2.F2" title="Figure 2 ‣ II-C BERT ‣ II Background ‣ Sky Computing: Accelerating Geo-distributed Computing in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. The linear layer projection and the residual connection can embed the learned semantics into the output tensor and make the whole model deeper <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>.</p>
</div>
<figure id="S2.F2" class="ltx_figure"><img src="/html/2202.11836/assets/figures/encoder_layer.png" id="S2.F2.g1" class="ltx_graphics ltx_centering ltx_img_square" width="538" height="562" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F2.2.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S2.F2.3.2" class="ltx_text" style="font-size:90%;">Architecture for BERT Encoder Layer</span></figcaption>
</figure>
<div id="S2.SS3.p5" class="ltx_para">
<p id="S2.SS3.p5.2" class="ltx_p">Even though BERT can produce impressive results in many tasks, the time complexity of the self-attention layer is <math id="S2.SS3.p5.1.m1.1" class="ltx_Math" alttext="O(n^{2})" display="inline"><semantics id="S2.SS3.p5.1.m1.1a"><mrow id="S2.SS3.p5.1.m1.1.1" xref="S2.SS3.p5.1.m1.1.1.cmml"><mi id="S2.SS3.p5.1.m1.1.1.3" xref="S2.SS3.p5.1.m1.1.1.3.cmml">O</mi><mo lspace="0em" rspace="0em" id="S2.SS3.p5.1.m1.1.1.2" xref="S2.SS3.p5.1.m1.1.1.2.cmml">​</mo><mrow id="S2.SS3.p5.1.m1.1.1.1.1" xref="S2.SS3.p5.1.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.SS3.p5.1.m1.1.1.1.1.2" xref="S2.SS3.p5.1.m1.1.1.1.1.1.cmml">(</mo><msup id="S2.SS3.p5.1.m1.1.1.1.1.1" xref="S2.SS3.p5.1.m1.1.1.1.1.1.cmml"><mi id="S2.SS3.p5.1.m1.1.1.1.1.1.2" xref="S2.SS3.p5.1.m1.1.1.1.1.1.2.cmml">n</mi><mn id="S2.SS3.p5.1.m1.1.1.1.1.1.3" xref="S2.SS3.p5.1.m1.1.1.1.1.1.3.cmml">2</mn></msup><mo stretchy="false" id="S2.SS3.p5.1.m1.1.1.1.1.3" xref="S2.SS3.p5.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p5.1.m1.1b"><apply id="S2.SS3.p5.1.m1.1.1.cmml" xref="S2.SS3.p5.1.m1.1.1"><times id="S2.SS3.p5.1.m1.1.1.2.cmml" xref="S2.SS3.p5.1.m1.1.1.2"></times><ci id="S2.SS3.p5.1.m1.1.1.3.cmml" xref="S2.SS3.p5.1.m1.1.1.3">𝑂</ci><apply id="S2.SS3.p5.1.m1.1.1.1.1.1.cmml" xref="S2.SS3.p5.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS3.p5.1.m1.1.1.1.1.1.1.cmml" xref="S2.SS3.p5.1.m1.1.1.1.1">superscript</csymbol><ci id="S2.SS3.p5.1.m1.1.1.1.1.1.2.cmml" xref="S2.SS3.p5.1.m1.1.1.1.1.1.2">𝑛</ci><cn type="integer" id="S2.SS3.p5.1.m1.1.1.1.1.1.3.cmml" xref="S2.SS3.p5.1.m1.1.1.1.1.1.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p5.1.m1.1c">O(n^{2})</annotation></semantics></math> where <math id="S2.SS3.p5.2.m2.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S2.SS3.p5.2.m2.1a"><mi id="S2.SS3.p5.2.m2.1.1" xref="S2.SS3.p5.2.m2.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p5.2.m2.1b"><ci id="S2.SS3.p5.2.m2.1.1.cmml" xref="S2.SS3.p5.2.m2.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p5.2.m2.1c">n</annotation></semantics></math> is the sequence length and the linear layers have high hidden dimension, posing challenges to the training speed <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. Moreover, BERT has a large model size. A 24-layer BERT-Large model has 345 million parameters, making it difficult to train BERT on a single GPU.</p>
</div>
</section>
<section id="S2.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS4.5.1.1" class="ltx_text">II-D</span> </span><span id="S2.SS4.6.2" class="ltx_text ltx_font_italic">Model Parallelism</span>
</h3>

<div id="S2.SS4.p1" class="ltx_para">
<p id="S2.SS4.p1.1" class="ltx_p">To speed up the model training, parallel computing is integrated to increase the training throughput and reduce training time. There are mainly two paradigms of parallelism in machine learning, namely data parallelism and model parallelism <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>.</p>
</div>
<div id="S2.SS4.p2" class="ltx_para">
<p id="S2.SS4.p2.1" class="ltx_p">Data parallelism is the mainstream method to train a model. In this paradigm, data is split and distributed to the workers to perform parallel computing. Each worker (GPU) holds a full copy of the model and trains on its data. It performs local backward-propagation to calculate the gradients of parameters. All-reduce is then applied to the gradients on all workers to perform weight updates. In this manner, we can increase the data throughput by having more workers to speed up the training.</p>
</div>
<div id="S2.SS4.p3" class="ltx_para">
<p id="S2.SS4.p3.1" class="ltx_p">However, this method does not work if the size of the model goes beyond the memory limit of a single worker. To address this problem, model parallelism should be used instead, in which the model is split into several parts. There are mainly two paradigms of model parallelism, namely by layer and by tensor. Model parallelism by layer means that the model is split layerwise as shown in Figure <a href="#S2.F3" title="Figure 3 ‣ II-D Model Parallelism ‣ II Background ‣ Sky Computing: Accelerating Geo-distributed Computing in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> when the memory of a single device is insufficient. This is often used together with pipeline parallelism and some examples include GPipe <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> and PipeDream <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>. Meanwhile, model parallelism by tensor is to split the weight tensor among the devices. One example of this paradigm is Megatron <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> which uses tensor splitting on the embedding layer and the encoder layer of Transformer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> to scale up training.</p>
</div>
<figure id="S2.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2202.11836/assets/figures/model_parallelism.png" id="S2.F3.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="538" height="157" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="S2.F3.2" class="ltx_p ltx_figure_panel ltx_align_center">‘</p>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F3.3.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S2.F3.4.2" class="ltx_text" style="font-size:90%;">Model Parallelism by Layer</span></figcaption>
</figure>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Model Parallelism in Federated Learning</span>
</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">In current federated learning methods <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>, each device needs to accommodate the whole model and the maximum model size is limited by the capability of a single device, hindering training of large-scale models. To tackle this problem, we proposed the idea of integrating model parallelism into federated learning to train large-scale models. As the number of devices involved in federated training can be dynamically changing, we adopted model parallelism by layer to allocate the model layers on different devices as shown in Figure <a href="#S3.F4" title="Figure 4 ‣ III Model Parallelism in Federated Learning ‣ Sky Computing: Accelerating Geo-distributed Computing in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. Similar to the normal federated learning, we also need a central server to host a full copy of the model weights as a parameter server <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>. Once the layer allocation is determined, the device can fetch the weights of the allocated layers from the server. Each device computes its output tensor given an input from the previous device and the output tensor is passed to the next device. Once the last device has finished the forward pass, it starts to run the back-propagation algorithm. The gradients are calculated and the weights are updated in the reverse order. In this setting, the workers do not pass the gradients back to the server as the gradients are used to update the weights locally. The central server only communicates the model parameters with the devices as it distributes the model layers at the start of training and collects back the updated parameters at the end of training.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p">When we add more devices to this network, communication cost increases due to the passing of tensors between devices. However, the average computation on each device will decrease given that the total model size is constant. This is important in federated learning, especially in mobile application scenarios. Since the training is conducted on users’ devices, it will undermine the overall user experience of their devices if training consumes too many hardware resources, in turn drawing dissatisfaction from the users.</p>
</div>
<figure id="S3.F4" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2202.11836/assets/figures/model_parallelism_fed_learning.png" id="S3.F4.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="538" height="253" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="S3.F4.2" class="ltx_p ltx_figure_panel ltx_align_center">‘</p>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F4.3.1.1" class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span id="S3.F4.4.2" class="ltx_text" style="font-size:90%;">Model Parallelism in Federated Learning</span></figcaption>
</figure>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Geo-distributed Computing Optimization</span>
</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">As the devices have the different computing power and communication latency, it is of paramount importance to choose an allocation strategy to distribute the layers in federated learning. In this section, we present our Sky Computing to optimize the model parallelism in federated learning by using load-balanced strategy.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS1.5.1.1" class="ltx_text">IV-A</span> </span><span id="S4.SS1.6.2" class="ltx_text ltx_font_italic">Naive Approach</span>
</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">The simplest method to allocate the layers is to distribute an equal number of layers among the devices. This method is easy to implement but fails to take into account the computational power and communication latency of the devices. As a result, devices with weaker computing power and higher communication delays can cause a huge bottleneck in training. In addition, this method is not aware of the amount of memory required for training. The out-of-memory problem can occur if too many layers are allocated to a device with limited RAM. Therefore, more information about the device and the model is needed to allocate the layers more wisely.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS2.5.1.1" class="ltx_text">IV-B</span> </span><span id="S4.SS2.6.2" class="ltx_text ltx_font_italic">Benchmarking</span>
</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">To balance the load of each node and avoid causing the out-of-memory problem, a benchmark stage is needed to test the performance of the devices, that is, to test how much load each device can bear. The benchmark stage is designed to gather information about the devices as well as the training model. We implemented two separate benchmark tests to extract the information about model structure and device capability. The collected information will be used to compute the allocation.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">As the devices have different hardware configurations, it is necessary to understand their performance on the same benchmark. We need to know their relative latency to remove the bottleneck in training, the amount of available memory to avoid the out-of-memory problem. The latency of the devices is mainly caused by two aspects. The first is the delay of communication, which will increase the transfer time between devices. The second is the computational power of the devices. To get this information, we can send a request from the central server to each device and record the time interval between sending and receiving. Besides, the request will run a simple benchmark test to measure the time taken on each device. The benchmark test is to simply run the forward pass of a convolutional neural network or the first few layers of the training model for tens of iterations. This ensures that all devices have the same amount of computation for the sake of fairness. The ratio of time taken on these devices will be used as a reference of their relative computation power. To get the available memory on each device, the request will query for the system hardware information on the receiver device.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.1" class="ltx_p">The model information is also essential in layer distribution. Similar to the device information, we also need to know how fast a layer can be computed and its memory usage. This can be done on the central server without interaction with the devices. For the first one, we can measure the number of floating-point operations of a layer. As this indicates the amount of computation in the forward pass, it can help us match the faster device with more computationally heavy layers and vice versa. For memory usage, we need to estimate the peak memory required for both forward pass and backward pass to avoid the out-of-memory problem. The memory consumption during training involves the input tensor, layer weights, gradients, output tensors, and other optimizer-associated states. The memory consumption of each component can be estimated by counting the number of floating numbers individually.</p>
</div>
<figure id="S4.F5" class="ltx_figure"><img src="/html/2202.11836/assets/figures/training_process.png" id="S4.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="538" height="154" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.2.1.1" class="ltx_text" style="font-size:90%;">Figure 5</span>: </span><span id="S4.F5.3.2" class="ltx_text" style="font-size:90%;">Training process in the Sky Computing</span></figcaption>
</figure>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS3.5.1.1" class="ltx_text">IV-C</span> </span><span id="S4.SS3.6.2" class="ltx_text ltx_font_italic">Mathematical Model</span>
</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.19" class="ltx_p">After getting the relevant hardware information above, we can use this information to write the allocation problem as a linear programming mathematical model. Suppose there are <math id="S4.SS3.p1.1.m1.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S4.SS3.p1.1.m1.1a"><mi id="S4.SS3.p1.1.m1.1.1" xref="S4.SS3.p1.1.m1.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.1.m1.1b"><ci id="S4.SS3.p1.1.m1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.1.m1.1c">L</annotation></semantics></math> layers and <math id="S4.SS3.p1.2.m2.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S4.SS3.p1.2.m2.1a"><mi id="S4.SS3.p1.2.m2.1.1" xref="S4.SS3.p1.2.m2.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.2.m2.1b"><ci id="S4.SS3.p1.2.m2.1.1.cmml" xref="S4.SS3.p1.2.m2.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.2.m2.1c">D</annotation></semantics></math> devices. Use <math id="S4.SS3.p1.3.m3.1" class="ltx_Math" alttext="x_{ij}" display="inline"><semantics id="S4.SS3.p1.3.m3.1a"><msub id="S4.SS3.p1.3.m3.1.1" xref="S4.SS3.p1.3.m3.1.1.cmml"><mi id="S4.SS3.p1.3.m3.1.1.2" xref="S4.SS3.p1.3.m3.1.1.2.cmml">x</mi><mrow id="S4.SS3.p1.3.m3.1.1.3" xref="S4.SS3.p1.3.m3.1.1.3.cmml"><mi id="S4.SS3.p1.3.m3.1.1.3.2" xref="S4.SS3.p1.3.m3.1.1.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.3.m3.1.1.3.1" xref="S4.SS3.p1.3.m3.1.1.3.1.cmml">​</mo><mi id="S4.SS3.p1.3.m3.1.1.3.3" xref="S4.SS3.p1.3.m3.1.1.3.3.cmml">j</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.3.m3.1b"><apply id="S4.SS3.p1.3.m3.1.1.cmml" xref="S4.SS3.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS3.p1.3.m3.1.1.1.cmml" xref="S4.SS3.p1.3.m3.1.1">subscript</csymbol><ci id="S4.SS3.p1.3.m3.1.1.2.cmml" xref="S4.SS3.p1.3.m3.1.1.2">𝑥</ci><apply id="S4.SS3.p1.3.m3.1.1.3.cmml" xref="S4.SS3.p1.3.m3.1.1.3"><times id="S4.SS3.p1.3.m3.1.1.3.1.cmml" xref="S4.SS3.p1.3.m3.1.1.3.1"></times><ci id="S4.SS3.p1.3.m3.1.1.3.2.cmml" xref="S4.SS3.p1.3.m3.1.1.3.2">𝑖</ci><ci id="S4.SS3.p1.3.m3.1.1.3.3.cmml" xref="S4.SS3.p1.3.m3.1.1.3.3">𝑗</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.3.m3.1c">x_{ij}</annotation></semantics></math> as indicator variables such that <math id="S4.SS3.p1.4.m4.1" class="ltx_Math" alttext="x_{ij}=1" display="inline"><semantics id="S4.SS3.p1.4.m4.1a"><mrow id="S4.SS3.p1.4.m4.1.1" xref="S4.SS3.p1.4.m4.1.1.cmml"><msub id="S4.SS3.p1.4.m4.1.1.2" xref="S4.SS3.p1.4.m4.1.1.2.cmml"><mi id="S4.SS3.p1.4.m4.1.1.2.2" xref="S4.SS3.p1.4.m4.1.1.2.2.cmml">x</mi><mrow id="S4.SS3.p1.4.m4.1.1.2.3" xref="S4.SS3.p1.4.m4.1.1.2.3.cmml"><mi id="S4.SS3.p1.4.m4.1.1.2.3.2" xref="S4.SS3.p1.4.m4.1.1.2.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.4.m4.1.1.2.3.1" xref="S4.SS3.p1.4.m4.1.1.2.3.1.cmml">​</mo><mi id="S4.SS3.p1.4.m4.1.1.2.3.3" xref="S4.SS3.p1.4.m4.1.1.2.3.3.cmml">j</mi></mrow></msub><mo id="S4.SS3.p1.4.m4.1.1.1" xref="S4.SS3.p1.4.m4.1.1.1.cmml">=</mo><mn id="S4.SS3.p1.4.m4.1.1.3" xref="S4.SS3.p1.4.m4.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.4.m4.1b"><apply id="S4.SS3.p1.4.m4.1.1.cmml" xref="S4.SS3.p1.4.m4.1.1"><eq id="S4.SS3.p1.4.m4.1.1.1.cmml" xref="S4.SS3.p1.4.m4.1.1.1"></eq><apply id="S4.SS3.p1.4.m4.1.1.2.cmml" xref="S4.SS3.p1.4.m4.1.1.2"><csymbol cd="ambiguous" id="S4.SS3.p1.4.m4.1.1.2.1.cmml" xref="S4.SS3.p1.4.m4.1.1.2">subscript</csymbol><ci id="S4.SS3.p1.4.m4.1.1.2.2.cmml" xref="S4.SS3.p1.4.m4.1.1.2.2">𝑥</ci><apply id="S4.SS3.p1.4.m4.1.1.2.3.cmml" xref="S4.SS3.p1.4.m4.1.1.2.3"><times id="S4.SS3.p1.4.m4.1.1.2.3.1.cmml" xref="S4.SS3.p1.4.m4.1.1.2.3.1"></times><ci id="S4.SS3.p1.4.m4.1.1.2.3.2.cmml" xref="S4.SS3.p1.4.m4.1.1.2.3.2">𝑖</ci><ci id="S4.SS3.p1.4.m4.1.1.2.3.3.cmml" xref="S4.SS3.p1.4.m4.1.1.2.3.3">𝑗</ci></apply></apply><cn type="integer" id="S4.SS3.p1.4.m4.1.1.3.cmml" xref="S4.SS3.p1.4.m4.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.4.m4.1c">x_{ij}=1</annotation></semantics></math> iff <math id="S4.SS3.p1.5.m5.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S4.SS3.p1.5.m5.1a"><mi id="S4.SS3.p1.5.m5.1.1" xref="S4.SS3.p1.5.m5.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.5.m5.1b"><ci id="S4.SS3.p1.5.m5.1.1.cmml" xref="S4.SS3.p1.5.m5.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.5.m5.1c">i</annotation></semantics></math>-th device contains <math id="S4.SS3.p1.6.m6.1" class="ltx_Math" alttext="j" display="inline"><semantics id="S4.SS3.p1.6.m6.1a"><mi id="S4.SS3.p1.6.m6.1.1" xref="S4.SS3.p1.6.m6.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.6.m6.1b"><ci id="S4.SS3.p1.6.m6.1.1.cmml" xref="S4.SS3.p1.6.m6.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.6.m6.1c">j</annotation></semantics></math>-th layer. The time for the <math id="S4.SS3.p1.7.m7.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S4.SS3.p1.7.m7.1a"><mi id="S4.SS3.p1.7.m7.1.1" xref="S4.SS3.p1.7.m7.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.7.m7.1b"><ci id="S4.SS3.p1.7.m7.1.1.cmml" xref="S4.SS3.p1.7.m7.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.7.m7.1c">i</annotation></semantics></math>-th device to complete the benchmark can be denoted as <math id="S4.SS3.p1.8.m8.1" class="ltx_Math" alttext="dt_{i}" display="inline"><semantics id="S4.SS3.p1.8.m8.1a"><mrow id="S4.SS3.p1.8.m8.1.1" xref="S4.SS3.p1.8.m8.1.1.cmml"><mi id="S4.SS3.p1.8.m8.1.1.2" xref="S4.SS3.p1.8.m8.1.1.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.8.m8.1.1.1" xref="S4.SS3.p1.8.m8.1.1.1.cmml">​</mo><msub id="S4.SS3.p1.8.m8.1.1.3" xref="S4.SS3.p1.8.m8.1.1.3.cmml"><mi id="S4.SS3.p1.8.m8.1.1.3.2" xref="S4.SS3.p1.8.m8.1.1.3.2.cmml">t</mi><mi id="S4.SS3.p1.8.m8.1.1.3.3" xref="S4.SS3.p1.8.m8.1.1.3.3.cmml">i</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.8.m8.1b"><apply id="S4.SS3.p1.8.m8.1.1.cmml" xref="S4.SS3.p1.8.m8.1.1"><times id="S4.SS3.p1.8.m8.1.1.1.cmml" xref="S4.SS3.p1.8.m8.1.1.1"></times><ci id="S4.SS3.p1.8.m8.1.1.2.cmml" xref="S4.SS3.p1.8.m8.1.1.2">𝑑</ci><apply id="S4.SS3.p1.8.m8.1.1.3.cmml" xref="S4.SS3.p1.8.m8.1.1.3"><csymbol cd="ambiguous" id="S4.SS3.p1.8.m8.1.1.3.1.cmml" xref="S4.SS3.p1.8.m8.1.1.3">subscript</csymbol><ci id="S4.SS3.p1.8.m8.1.1.3.2.cmml" xref="S4.SS3.p1.8.m8.1.1.3.2">𝑡</ci><ci id="S4.SS3.p1.8.m8.1.1.3.3.cmml" xref="S4.SS3.p1.8.m8.1.1.3.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.8.m8.1c">dt_{i}</annotation></semantics></math>. The available memory of <math id="S4.SS3.p1.9.m9.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S4.SS3.p1.9.m9.1a"><mi id="S4.SS3.p1.9.m9.1.1" xref="S4.SS3.p1.9.m9.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.9.m9.1b"><ci id="S4.SS3.p1.9.m9.1.1.cmml" xref="S4.SS3.p1.9.m9.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.9.m9.1c">i</annotation></semantics></math>-th device is <math id="S4.SS3.p1.10.m10.1" class="ltx_Math" alttext="dm_{i}" display="inline"><semantics id="S4.SS3.p1.10.m10.1a"><mrow id="S4.SS3.p1.10.m10.1.1" xref="S4.SS3.p1.10.m10.1.1.cmml"><mi id="S4.SS3.p1.10.m10.1.1.2" xref="S4.SS3.p1.10.m10.1.1.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.10.m10.1.1.1" xref="S4.SS3.p1.10.m10.1.1.1.cmml">​</mo><msub id="S4.SS3.p1.10.m10.1.1.3" xref="S4.SS3.p1.10.m10.1.1.3.cmml"><mi id="S4.SS3.p1.10.m10.1.1.3.2" xref="S4.SS3.p1.10.m10.1.1.3.2.cmml">m</mi><mi id="S4.SS3.p1.10.m10.1.1.3.3" xref="S4.SS3.p1.10.m10.1.1.3.3.cmml">i</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.10.m10.1b"><apply id="S4.SS3.p1.10.m10.1.1.cmml" xref="S4.SS3.p1.10.m10.1.1"><times id="S4.SS3.p1.10.m10.1.1.1.cmml" xref="S4.SS3.p1.10.m10.1.1.1"></times><ci id="S4.SS3.p1.10.m10.1.1.2.cmml" xref="S4.SS3.p1.10.m10.1.1.2">𝑑</ci><apply id="S4.SS3.p1.10.m10.1.1.3.cmml" xref="S4.SS3.p1.10.m10.1.1.3"><csymbol cd="ambiguous" id="S4.SS3.p1.10.m10.1.1.3.1.cmml" xref="S4.SS3.p1.10.m10.1.1.3">subscript</csymbol><ci id="S4.SS3.p1.10.m10.1.1.3.2.cmml" xref="S4.SS3.p1.10.m10.1.1.3.2">𝑚</ci><ci id="S4.SS3.p1.10.m10.1.1.3.3.cmml" xref="S4.SS3.p1.10.m10.1.1.3.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.10.m10.1c">dm_{i}</annotation></semantics></math>, the communication latency is <math id="S4.SS3.p1.11.m11.1" class="ltx_Math" alttext="ct_{i}" display="inline"><semantics id="S4.SS3.p1.11.m11.1a"><mrow id="S4.SS3.p1.11.m11.1.1" xref="S4.SS3.p1.11.m11.1.1.cmml"><mi id="S4.SS3.p1.11.m11.1.1.2" xref="S4.SS3.p1.11.m11.1.1.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.11.m11.1.1.1" xref="S4.SS3.p1.11.m11.1.1.1.cmml">​</mo><msub id="S4.SS3.p1.11.m11.1.1.3" xref="S4.SS3.p1.11.m11.1.1.3.cmml"><mi id="S4.SS3.p1.11.m11.1.1.3.2" xref="S4.SS3.p1.11.m11.1.1.3.2.cmml">t</mi><mi id="S4.SS3.p1.11.m11.1.1.3.3" xref="S4.SS3.p1.11.m11.1.1.3.3.cmml">i</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.11.m11.1b"><apply id="S4.SS3.p1.11.m11.1.1.cmml" xref="S4.SS3.p1.11.m11.1.1"><times id="S4.SS3.p1.11.m11.1.1.1.cmml" xref="S4.SS3.p1.11.m11.1.1.1"></times><ci id="S4.SS3.p1.11.m11.1.1.2.cmml" xref="S4.SS3.p1.11.m11.1.1.2">𝑐</ci><apply id="S4.SS3.p1.11.m11.1.1.3.cmml" xref="S4.SS3.p1.11.m11.1.1.3"><csymbol cd="ambiguous" id="S4.SS3.p1.11.m11.1.1.3.1.cmml" xref="S4.SS3.p1.11.m11.1.1.3">subscript</csymbol><ci id="S4.SS3.p1.11.m11.1.1.3.2.cmml" xref="S4.SS3.p1.11.m11.1.1.3.2">𝑡</ci><ci id="S4.SS3.p1.11.m11.1.1.3.3.cmml" xref="S4.SS3.p1.11.m11.1.1.3.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.11.m11.1c">ct_{i}</annotation></semantics></math>. <math id="S4.SS3.p1.12.m12.1" class="ltx_Math" alttext="lf_{j}" display="inline"><semantics id="S4.SS3.p1.12.m12.1a"><mrow id="S4.SS3.p1.12.m12.1.1" xref="S4.SS3.p1.12.m12.1.1.cmml"><mi id="S4.SS3.p1.12.m12.1.1.2" xref="S4.SS3.p1.12.m12.1.1.2.cmml">l</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.12.m12.1.1.1" xref="S4.SS3.p1.12.m12.1.1.1.cmml">​</mo><msub id="S4.SS3.p1.12.m12.1.1.3" xref="S4.SS3.p1.12.m12.1.1.3.cmml"><mi id="S4.SS3.p1.12.m12.1.1.3.2" xref="S4.SS3.p1.12.m12.1.1.3.2.cmml">f</mi><mi id="S4.SS3.p1.12.m12.1.1.3.3" xref="S4.SS3.p1.12.m12.1.1.3.3.cmml">j</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.12.m12.1b"><apply id="S4.SS3.p1.12.m12.1.1.cmml" xref="S4.SS3.p1.12.m12.1.1"><times id="S4.SS3.p1.12.m12.1.1.1.cmml" xref="S4.SS3.p1.12.m12.1.1.1"></times><ci id="S4.SS3.p1.12.m12.1.1.2.cmml" xref="S4.SS3.p1.12.m12.1.1.2">𝑙</ci><apply id="S4.SS3.p1.12.m12.1.1.3.cmml" xref="S4.SS3.p1.12.m12.1.1.3"><csymbol cd="ambiguous" id="S4.SS3.p1.12.m12.1.1.3.1.cmml" xref="S4.SS3.p1.12.m12.1.1.3">subscript</csymbol><ci id="S4.SS3.p1.12.m12.1.1.3.2.cmml" xref="S4.SS3.p1.12.m12.1.1.3.2">𝑓</ci><ci id="S4.SS3.p1.12.m12.1.1.3.3.cmml" xref="S4.SS3.p1.12.m12.1.1.3.3">𝑗</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.12.m12.1c">lf_{j}</annotation></semantics></math> and <math id="S4.SS3.p1.13.m13.1" class="ltx_Math" alttext="lm_{j}" display="inline"><semantics id="S4.SS3.p1.13.m13.1a"><mrow id="S4.SS3.p1.13.m13.1.1" xref="S4.SS3.p1.13.m13.1.1.cmml"><mi id="S4.SS3.p1.13.m13.1.1.2" xref="S4.SS3.p1.13.m13.1.1.2.cmml">l</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.13.m13.1.1.1" xref="S4.SS3.p1.13.m13.1.1.1.cmml">​</mo><msub id="S4.SS3.p1.13.m13.1.1.3" xref="S4.SS3.p1.13.m13.1.1.3.cmml"><mi id="S4.SS3.p1.13.m13.1.1.3.2" xref="S4.SS3.p1.13.m13.1.1.3.2.cmml">m</mi><mi id="S4.SS3.p1.13.m13.1.1.3.3" xref="S4.SS3.p1.13.m13.1.1.3.3.cmml">j</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.13.m13.1b"><apply id="S4.SS3.p1.13.m13.1.1.cmml" xref="S4.SS3.p1.13.m13.1.1"><times id="S4.SS3.p1.13.m13.1.1.1.cmml" xref="S4.SS3.p1.13.m13.1.1.1"></times><ci id="S4.SS3.p1.13.m13.1.1.2.cmml" xref="S4.SS3.p1.13.m13.1.1.2">𝑙</ci><apply id="S4.SS3.p1.13.m13.1.1.3.cmml" xref="S4.SS3.p1.13.m13.1.1.3"><csymbol cd="ambiguous" id="S4.SS3.p1.13.m13.1.1.3.1.cmml" xref="S4.SS3.p1.13.m13.1.1.3">subscript</csymbol><ci id="S4.SS3.p1.13.m13.1.1.3.2.cmml" xref="S4.SS3.p1.13.m13.1.1.3.2">𝑚</ci><ci id="S4.SS3.p1.13.m13.1.1.3.3.cmml" xref="S4.SS3.p1.13.m13.1.1.3.3">𝑗</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.13.m13.1c">lm_{j}</annotation></semantics></math> represent the number of flops and size of the <math id="S4.SS3.p1.14.m14.1" class="ltx_Math" alttext="j" display="inline"><semantics id="S4.SS3.p1.14.m14.1a"><mi id="S4.SS3.p1.14.m14.1.1" xref="S4.SS3.p1.14.m14.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.14.m14.1b"><ci id="S4.SS3.p1.14.m14.1.1.cmml" xref="S4.SS3.p1.14.m14.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.14.m14.1c">j</annotation></semantics></math>-th layer, respectively. So the total workload of <math id="S4.SS3.p1.15.m15.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S4.SS3.p1.15.m15.1a"><mi id="S4.SS3.p1.15.m15.1.1" xref="S4.SS3.p1.15.m15.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.15.m15.1b"><ci id="S4.SS3.p1.15.m15.1.1.cmml" xref="S4.SS3.p1.15.m15.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.15.m15.1c">i</annotation></semantics></math>-th device can be denoted as <math id="S4.SS3.p1.16.m16.1" class="ltx_Math" alttext="w_{i}=dt_{i}\sum_{j=1}^{L}x_{ij}lf_{j}+ct_{i}" display="inline"><semantics id="S4.SS3.p1.16.m16.1a"><mrow id="S4.SS3.p1.16.m16.1.1" xref="S4.SS3.p1.16.m16.1.1.cmml"><msub id="S4.SS3.p1.16.m16.1.1.2" xref="S4.SS3.p1.16.m16.1.1.2.cmml"><mi id="S4.SS3.p1.16.m16.1.1.2.2" xref="S4.SS3.p1.16.m16.1.1.2.2.cmml">w</mi><mi id="S4.SS3.p1.16.m16.1.1.2.3" xref="S4.SS3.p1.16.m16.1.1.2.3.cmml">i</mi></msub><mo id="S4.SS3.p1.16.m16.1.1.1" xref="S4.SS3.p1.16.m16.1.1.1.cmml">=</mo><mrow id="S4.SS3.p1.16.m16.1.1.3" xref="S4.SS3.p1.16.m16.1.1.3.cmml"><mrow id="S4.SS3.p1.16.m16.1.1.3.2" xref="S4.SS3.p1.16.m16.1.1.3.2.cmml"><mi id="S4.SS3.p1.16.m16.1.1.3.2.2" xref="S4.SS3.p1.16.m16.1.1.3.2.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.16.m16.1.1.3.2.1" xref="S4.SS3.p1.16.m16.1.1.3.2.1.cmml">​</mo><msub id="S4.SS3.p1.16.m16.1.1.3.2.3" xref="S4.SS3.p1.16.m16.1.1.3.2.3.cmml"><mi id="S4.SS3.p1.16.m16.1.1.3.2.3.2" xref="S4.SS3.p1.16.m16.1.1.3.2.3.2.cmml">t</mi><mi id="S4.SS3.p1.16.m16.1.1.3.2.3.3" xref="S4.SS3.p1.16.m16.1.1.3.2.3.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S4.SS3.p1.16.m16.1.1.3.2.1a" xref="S4.SS3.p1.16.m16.1.1.3.2.1.cmml">​</mo><mrow id="S4.SS3.p1.16.m16.1.1.3.2.4" xref="S4.SS3.p1.16.m16.1.1.3.2.4.cmml"><msubsup id="S4.SS3.p1.16.m16.1.1.3.2.4.1" xref="S4.SS3.p1.16.m16.1.1.3.2.4.1.cmml"><mo id="S4.SS3.p1.16.m16.1.1.3.2.4.1.2.2" xref="S4.SS3.p1.16.m16.1.1.3.2.4.1.2.2.cmml">∑</mo><mrow id="S4.SS3.p1.16.m16.1.1.3.2.4.1.2.3" xref="S4.SS3.p1.16.m16.1.1.3.2.4.1.2.3.cmml"><mi id="S4.SS3.p1.16.m16.1.1.3.2.4.1.2.3.2" xref="S4.SS3.p1.16.m16.1.1.3.2.4.1.2.3.2.cmml">j</mi><mo id="S4.SS3.p1.16.m16.1.1.3.2.4.1.2.3.1" xref="S4.SS3.p1.16.m16.1.1.3.2.4.1.2.3.1.cmml">=</mo><mn id="S4.SS3.p1.16.m16.1.1.3.2.4.1.2.3.3" xref="S4.SS3.p1.16.m16.1.1.3.2.4.1.2.3.3.cmml">1</mn></mrow><mi id="S4.SS3.p1.16.m16.1.1.3.2.4.1.3" xref="S4.SS3.p1.16.m16.1.1.3.2.4.1.3.cmml">L</mi></msubsup><mrow id="S4.SS3.p1.16.m16.1.1.3.2.4.2" xref="S4.SS3.p1.16.m16.1.1.3.2.4.2.cmml"><msub id="S4.SS3.p1.16.m16.1.1.3.2.4.2.2" xref="S4.SS3.p1.16.m16.1.1.3.2.4.2.2.cmml"><mi id="S4.SS3.p1.16.m16.1.1.3.2.4.2.2.2" xref="S4.SS3.p1.16.m16.1.1.3.2.4.2.2.2.cmml">x</mi><mrow id="S4.SS3.p1.16.m16.1.1.3.2.4.2.2.3" xref="S4.SS3.p1.16.m16.1.1.3.2.4.2.2.3.cmml"><mi id="S4.SS3.p1.16.m16.1.1.3.2.4.2.2.3.2" xref="S4.SS3.p1.16.m16.1.1.3.2.4.2.2.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.16.m16.1.1.3.2.4.2.2.3.1" xref="S4.SS3.p1.16.m16.1.1.3.2.4.2.2.3.1.cmml">​</mo><mi id="S4.SS3.p1.16.m16.1.1.3.2.4.2.2.3.3" xref="S4.SS3.p1.16.m16.1.1.3.2.4.2.2.3.3.cmml">j</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S4.SS3.p1.16.m16.1.1.3.2.4.2.1" xref="S4.SS3.p1.16.m16.1.1.3.2.4.2.1.cmml">​</mo><mi id="S4.SS3.p1.16.m16.1.1.3.2.4.2.3" xref="S4.SS3.p1.16.m16.1.1.3.2.4.2.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.16.m16.1.1.3.2.4.2.1a" xref="S4.SS3.p1.16.m16.1.1.3.2.4.2.1.cmml">​</mo><msub id="S4.SS3.p1.16.m16.1.1.3.2.4.2.4" xref="S4.SS3.p1.16.m16.1.1.3.2.4.2.4.cmml"><mi id="S4.SS3.p1.16.m16.1.1.3.2.4.2.4.2" xref="S4.SS3.p1.16.m16.1.1.3.2.4.2.4.2.cmml">f</mi><mi id="S4.SS3.p1.16.m16.1.1.3.2.4.2.4.3" xref="S4.SS3.p1.16.m16.1.1.3.2.4.2.4.3.cmml">j</mi></msub></mrow></mrow></mrow><mo id="S4.SS3.p1.16.m16.1.1.3.1" xref="S4.SS3.p1.16.m16.1.1.3.1.cmml">+</mo><mrow id="S4.SS3.p1.16.m16.1.1.3.3" xref="S4.SS3.p1.16.m16.1.1.3.3.cmml"><mi id="S4.SS3.p1.16.m16.1.1.3.3.2" xref="S4.SS3.p1.16.m16.1.1.3.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.SS3.p1.16.m16.1.1.3.3.1" xref="S4.SS3.p1.16.m16.1.1.3.3.1.cmml">​</mo><msub id="S4.SS3.p1.16.m16.1.1.3.3.3" xref="S4.SS3.p1.16.m16.1.1.3.3.3.cmml"><mi id="S4.SS3.p1.16.m16.1.1.3.3.3.2" xref="S4.SS3.p1.16.m16.1.1.3.3.3.2.cmml">t</mi><mi id="S4.SS3.p1.16.m16.1.1.3.3.3.3" xref="S4.SS3.p1.16.m16.1.1.3.3.3.3.cmml">i</mi></msub></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.16.m16.1b"><apply id="S4.SS3.p1.16.m16.1.1.cmml" xref="S4.SS3.p1.16.m16.1.1"><eq id="S4.SS3.p1.16.m16.1.1.1.cmml" xref="S4.SS3.p1.16.m16.1.1.1"></eq><apply id="S4.SS3.p1.16.m16.1.1.2.cmml" xref="S4.SS3.p1.16.m16.1.1.2"><csymbol cd="ambiguous" id="S4.SS3.p1.16.m16.1.1.2.1.cmml" xref="S4.SS3.p1.16.m16.1.1.2">subscript</csymbol><ci id="S4.SS3.p1.16.m16.1.1.2.2.cmml" xref="S4.SS3.p1.16.m16.1.1.2.2">𝑤</ci><ci id="S4.SS3.p1.16.m16.1.1.2.3.cmml" xref="S4.SS3.p1.16.m16.1.1.2.3">𝑖</ci></apply><apply id="S4.SS3.p1.16.m16.1.1.3.cmml" xref="S4.SS3.p1.16.m16.1.1.3"><plus id="S4.SS3.p1.16.m16.1.1.3.1.cmml" xref="S4.SS3.p1.16.m16.1.1.3.1"></plus><apply id="S4.SS3.p1.16.m16.1.1.3.2.cmml" xref="S4.SS3.p1.16.m16.1.1.3.2"><times id="S4.SS3.p1.16.m16.1.1.3.2.1.cmml" xref="S4.SS3.p1.16.m16.1.1.3.2.1"></times><ci id="S4.SS3.p1.16.m16.1.1.3.2.2.cmml" xref="S4.SS3.p1.16.m16.1.1.3.2.2">𝑑</ci><apply id="S4.SS3.p1.16.m16.1.1.3.2.3.cmml" xref="S4.SS3.p1.16.m16.1.1.3.2.3"><csymbol cd="ambiguous" id="S4.SS3.p1.16.m16.1.1.3.2.3.1.cmml" xref="S4.SS3.p1.16.m16.1.1.3.2.3">subscript</csymbol><ci id="S4.SS3.p1.16.m16.1.1.3.2.3.2.cmml" xref="S4.SS3.p1.16.m16.1.1.3.2.3.2">𝑡</ci><ci id="S4.SS3.p1.16.m16.1.1.3.2.3.3.cmml" xref="S4.SS3.p1.16.m16.1.1.3.2.3.3">𝑖</ci></apply><apply id="S4.SS3.p1.16.m16.1.1.3.2.4.cmml" xref="S4.SS3.p1.16.m16.1.1.3.2.4"><apply id="S4.SS3.p1.16.m16.1.1.3.2.4.1.cmml" xref="S4.SS3.p1.16.m16.1.1.3.2.4.1"><csymbol cd="ambiguous" id="S4.SS3.p1.16.m16.1.1.3.2.4.1.1.cmml" xref="S4.SS3.p1.16.m16.1.1.3.2.4.1">superscript</csymbol><apply id="S4.SS3.p1.16.m16.1.1.3.2.4.1.2.cmml" xref="S4.SS3.p1.16.m16.1.1.3.2.4.1"><csymbol cd="ambiguous" id="S4.SS3.p1.16.m16.1.1.3.2.4.1.2.1.cmml" xref="S4.SS3.p1.16.m16.1.1.3.2.4.1">subscript</csymbol><sum id="S4.SS3.p1.16.m16.1.1.3.2.4.1.2.2.cmml" xref="S4.SS3.p1.16.m16.1.1.3.2.4.1.2.2"></sum><apply id="S4.SS3.p1.16.m16.1.1.3.2.4.1.2.3.cmml" xref="S4.SS3.p1.16.m16.1.1.3.2.4.1.2.3"><eq id="S4.SS3.p1.16.m16.1.1.3.2.4.1.2.3.1.cmml" xref="S4.SS3.p1.16.m16.1.1.3.2.4.1.2.3.1"></eq><ci id="S4.SS3.p1.16.m16.1.1.3.2.4.1.2.3.2.cmml" xref="S4.SS3.p1.16.m16.1.1.3.2.4.1.2.3.2">𝑗</ci><cn type="integer" id="S4.SS3.p1.16.m16.1.1.3.2.4.1.2.3.3.cmml" xref="S4.SS3.p1.16.m16.1.1.3.2.4.1.2.3.3">1</cn></apply></apply><ci id="S4.SS3.p1.16.m16.1.1.3.2.4.1.3.cmml" xref="S4.SS3.p1.16.m16.1.1.3.2.4.1.3">𝐿</ci></apply><apply id="S4.SS3.p1.16.m16.1.1.3.2.4.2.cmml" xref="S4.SS3.p1.16.m16.1.1.3.2.4.2"><times id="S4.SS3.p1.16.m16.1.1.3.2.4.2.1.cmml" xref="S4.SS3.p1.16.m16.1.1.3.2.4.2.1"></times><apply id="S4.SS3.p1.16.m16.1.1.3.2.4.2.2.cmml" xref="S4.SS3.p1.16.m16.1.1.3.2.4.2.2"><csymbol cd="ambiguous" id="S4.SS3.p1.16.m16.1.1.3.2.4.2.2.1.cmml" xref="S4.SS3.p1.16.m16.1.1.3.2.4.2.2">subscript</csymbol><ci id="S4.SS3.p1.16.m16.1.1.3.2.4.2.2.2.cmml" xref="S4.SS3.p1.16.m16.1.1.3.2.4.2.2.2">𝑥</ci><apply id="S4.SS3.p1.16.m16.1.1.3.2.4.2.2.3.cmml" xref="S4.SS3.p1.16.m16.1.1.3.2.4.2.2.3"><times id="S4.SS3.p1.16.m16.1.1.3.2.4.2.2.3.1.cmml" xref="S4.SS3.p1.16.m16.1.1.3.2.4.2.2.3.1"></times><ci id="S4.SS3.p1.16.m16.1.1.3.2.4.2.2.3.2.cmml" xref="S4.SS3.p1.16.m16.1.1.3.2.4.2.2.3.2">𝑖</ci><ci id="S4.SS3.p1.16.m16.1.1.3.2.4.2.2.3.3.cmml" xref="S4.SS3.p1.16.m16.1.1.3.2.4.2.2.3.3">𝑗</ci></apply></apply><ci id="S4.SS3.p1.16.m16.1.1.3.2.4.2.3.cmml" xref="S4.SS3.p1.16.m16.1.1.3.2.4.2.3">𝑙</ci><apply id="S4.SS3.p1.16.m16.1.1.3.2.4.2.4.cmml" xref="S4.SS3.p1.16.m16.1.1.3.2.4.2.4"><csymbol cd="ambiguous" id="S4.SS3.p1.16.m16.1.1.3.2.4.2.4.1.cmml" xref="S4.SS3.p1.16.m16.1.1.3.2.4.2.4">subscript</csymbol><ci id="S4.SS3.p1.16.m16.1.1.3.2.4.2.4.2.cmml" xref="S4.SS3.p1.16.m16.1.1.3.2.4.2.4.2">𝑓</ci><ci id="S4.SS3.p1.16.m16.1.1.3.2.4.2.4.3.cmml" xref="S4.SS3.p1.16.m16.1.1.3.2.4.2.4.3">𝑗</ci></apply></apply></apply></apply><apply id="S4.SS3.p1.16.m16.1.1.3.3.cmml" xref="S4.SS3.p1.16.m16.1.1.3.3"><times id="S4.SS3.p1.16.m16.1.1.3.3.1.cmml" xref="S4.SS3.p1.16.m16.1.1.3.3.1"></times><ci id="S4.SS3.p1.16.m16.1.1.3.3.2.cmml" xref="S4.SS3.p1.16.m16.1.1.3.3.2">𝑐</ci><apply id="S4.SS3.p1.16.m16.1.1.3.3.3.cmml" xref="S4.SS3.p1.16.m16.1.1.3.3.3"><csymbol cd="ambiguous" id="S4.SS3.p1.16.m16.1.1.3.3.3.1.cmml" xref="S4.SS3.p1.16.m16.1.1.3.3.3">subscript</csymbol><ci id="S4.SS3.p1.16.m16.1.1.3.3.3.2.cmml" xref="S4.SS3.p1.16.m16.1.1.3.3.3.2">𝑡</ci><ci id="S4.SS3.p1.16.m16.1.1.3.3.3.3.cmml" xref="S4.SS3.p1.16.m16.1.1.3.3.3.3">𝑖</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.16.m16.1c">w_{i}=dt_{i}\sum_{j=1}^{L}x_{ij}lf_{j}+ct_{i}</annotation></semantics></math>. Use <math id="S4.SS3.p1.17.m17.1" class="ltx_Math" alttext="y_{i}" display="inline"><semantics id="S4.SS3.p1.17.m17.1a"><msub id="S4.SS3.p1.17.m17.1.1" xref="S4.SS3.p1.17.m17.1.1.cmml"><mi id="S4.SS3.p1.17.m17.1.1.2" xref="S4.SS3.p1.17.m17.1.1.2.cmml">y</mi><mi id="S4.SS3.p1.17.m17.1.1.3" xref="S4.SS3.p1.17.m17.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.17.m17.1b"><apply id="S4.SS3.p1.17.m17.1.1.cmml" xref="S4.SS3.p1.17.m17.1.1"><csymbol cd="ambiguous" id="S4.SS3.p1.17.m17.1.1.1.cmml" xref="S4.SS3.p1.17.m17.1.1">subscript</csymbol><ci id="S4.SS3.p1.17.m17.1.1.2.cmml" xref="S4.SS3.p1.17.m17.1.1.2">𝑦</ci><ci id="S4.SS3.p1.17.m17.1.1.3.cmml" xref="S4.SS3.p1.17.m17.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.17.m17.1c">y_{i}</annotation></semantics></math> represents the maximum index of the layers contained by <math id="S4.SS3.p1.18.m18.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S4.SS3.p1.18.m18.1a"><mi id="S4.SS3.p1.18.m18.1.1" xref="S4.SS3.p1.18.m18.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.18.m18.1b"><ci id="S4.SS3.p1.18.m18.1.1.cmml" xref="S4.SS3.p1.18.m18.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.18.m18.1c">i</annotation></semantics></math>-th device, and <math id="S4.SS3.p1.19.m19.1" class="ltx_Math" alttext="z_{i}" display="inline"><semantics id="S4.SS3.p1.19.m19.1a"><msub id="S4.SS3.p1.19.m19.1.1" xref="S4.SS3.p1.19.m19.1.1.cmml"><mi id="S4.SS3.p1.19.m19.1.1.2" xref="S4.SS3.p1.19.m19.1.1.2.cmml">z</mi><mi id="S4.SS3.p1.19.m19.1.1.3" xref="S4.SS3.p1.19.m19.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.19.m19.1b"><apply id="S4.SS3.p1.19.m19.1.1.cmml" xref="S4.SS3.p1.19.m19.1.1"><csymbol cd="ambiguous" id="S4.SS3.p1.19.m19.1.1.1.cmml" xref="S4.SS3.p1.19.m19.1.1">subscript</csymbol><ci id="S4.SS3.p1.19.m19.1.1.2.cmml" xref="S4.SS3.p1.19.m19.1.1.2">𝑧</ci><ci id="S4.SS3.p1.19.m19.1.1.3.cmml" xref="S4.SS3.p1.19.m19.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.19.m19.1c">z_{i}</annotation></semantics></math> represents the minimum. The complete model can be shown as:</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<table id="S8.EGx1" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S4.Ex1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S4.Ex1.m1.1" class="ltx_Math" alttext="\displaystyle\min q" display="inline"><semantics id="S4.Ex1.m1.1a"><mrow id="S4.Ex1.m1.1.1" xref="S4.Ex1.m1.1.1.cmml"><mi id="S4.Ex1.m1.1.1.1" xref="S4.Ex1.m1.1.1.1.cmml">min</mi><mo lspace="0.167em" id="S4.Ex1.m1.1.1a" xref="S4.Ex1.m1.1.1.cmml">⁡</mo><mi id="S4.Ex1.m1.1.1.2" xref="S4.Ex1.m1.1.1.2.cmml">q</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.Ex1.m1.1b"><apply id="S4.Ex1.m1.1.1.cmml" xref="S4.Ex1.m1.1.1"><min id="S4.Ex1.m1.1.1.1.cmml" xref="S4.Ex1.m1.1.1.1"></min><ci id="S4.Ex1.m1.1.1.2.cmml" xref="S4.Ex1.m1.1.1.2">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.Ex1.m1.1c">\displaystyle\min q</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright" colspan="3"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(obj.)</span></td>
</tr></tbody>
<tbody id="S4.Ex2"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><span id="S4.Ex2.3.1.1.1" class="ltx_text ltx_markedasmath">s.t.</span></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S4.Ex2.m2.1" class="ltx_Math" alttext="\displaystyle\sum_{j=1}^{L}x_{ij}lm_{j}\leq dm_{i}," display="inline"><semantics id="S4.Ex2.m2.1a"><mrow id="S4.Ex2.m2.1.1.1" xref="S4.Ex2.m2.1.1.1.1.cmml"><mrow id="S4.Ex2.m2.1.1.1.1" xref="S4.Ex2.m2.1.1.1.1.cmml"><mrow id="S4.Ex2.m2.1.1.1.1.2" xref="S4.Ex2.m2.1.1.1.1.2.cmml"><mstyle displaystyle="true" id="S4.Ex2.m2.1.1.1.1.2.1" xref="S4.Ex2.m2.1.1.1.1.2.1.cmml"><munderover id="S4.Ex2.m2.1.1.1.1.2.1a" xref="S4.Ex2.m2.1.1.1.1.2.1.cmml"><mo movablelimits="false" id="S4.Ex2.m2.1.1.1.1.2.1.2.2" xref="S4.Ex2.m2.1.1.1.1.2.1.2.2.cmml">∑</mo><mrow id="S4.Ex2.m2.1.1.1.1.2.1.2.3" xref="S4.Ex2.m2.1.1.1.1.2.1.2.3.cmml"><mi id="S4.Ex2.m2.1.1.1.1.2.1.2.3.2" xref="S4.Ex2.m2.1.1.1.1.2.1.2.3.2.cmml">j</mi><mo id="S4.Ex2.m2.1.1.1.1.2.1.2.3.1" xref="S4.Ex2.m2.1.1.1.1.2.1.2.3.1.cmml">=</mo><mn id="S4.Ex2.m2.1.1.1.1.2.1.2.3.3" xref="S4.Ex2.m2.1.1.1.1.2.1.2.3.3.cmml">1</mn></mrow><mi id="S4.Ex2.m2.1.1.1.1.2.1.3" xref="S4.Ex2.m2.1.1.1.1.2.1.3.cmml">L</mi></munderover></mstyle><mrow id="S4.Ex2.m2.1.1.1.1.2.2" xref="S4.Ex2.m2.1.1.1.1.2.2.cmml"><msub id="S4.Ex2.m2.1.1.1.1.2.2.2" xref="S4.Ex2.m2.1.1.1.1.2.2.2.cmml"><mi id="S4.Ex2.m2.1.1.1.1.2.2.2.2" xref="S4.Ex2.m2.1.1.1.1.2.2.2.2.cmml">x</mi><mrow id="S4.Ex2.m2.1.1.1.1.2.2.2.3" xref="S4.Ex2.m2.1.1.1.1.2.2.2.3.cmml"><mi id="S4.Ex2.m2.1.1.1.1.2.2.2.3.2" xref="S4.Ex2.m2.1.1.1.1.2.2.2.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.Ex2.m2.1.1.1.1.2.2.2.3.1" xref="S4.Ex2.m2.1.1.1.1.2.2.2.3.1.cmml">​</mo><mi id="S4.Ex2.m2.1.1.1.1.2.2.2.3.3" xref="S4.Ex2.m2.1.1.1.1.2.2.2.3.3.cmml">j</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S4.Ex2.m2.1.1.1.1.2.2.1" xref="S4.Ex2.m2.1.1.1.1.2.2.1.cmml">​</mo><mi id="S4.Ex2.m2.1.1.1.1.2.2.3" xref="S4.Ex2.m2.1.1.1.1.2.2.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S4.Ex2.m2.1.1.1.1.2.2.1a" xref="S4.Ex2.m2.1.1.1.1.2.2.1.cmml">​</mo><msub id="S4.Ex2.m2.1.1.1.1.2.2.4" xref="S4.Ex2.m2.1.1.1.1.2.2.4.cmml"><mi id="S4.Ex2.m2.1.1.1.1.2.2.4.2" xref="S4.Ex2.m2.1.1.1.1.2.2.4.2.cmml">m</mi><mi id="S4.Ex2.m2.1.1.1.1.2.2.4.3" xref="S4.Ex2.m2.1.1.1.1.2.2.4.3.cmml">j</mi></msub></mrow></mrow><mo id="S4.Ex2.m2.1.1.1.1.1" xref="S4.Ex2.m2.1.1.1.1.1.cmml">≤</mo><mrow id="S4.Ex2.m2.1.1.1.1.3" xref="S4.Ex2.m2.1.1.1.1.3.cmml"><mi id="S4.Ex2.m2.1.1.1.1.3.2" xref="S4.Ex2.m2.1.1.1.1.3.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="S4.Ex2.m2.1.1.1.1.3.1" xref="S4.Ex2.m2.1.1.1.1.3.1.cmml">​</mo><msub id="S4.Ex2.m2.1.1.1.1.3.3" xref="S4.Ex2.m2.1.1.1.1.3.3.cmml"><mi id="S4.Ex2.m2.1.1.1.1.3.3.2" xref="S4.Ex2.m2.1.1.1.1.3.3.2.cmml">m</mi><mi id="S4.Ex2.m2.1.1.1.1.3.3.3" xref="S4.Ex2.m2.1.1.1.1.3.3.3.cmml">i</mi></msub></mrow></mrow><mo id="S4.Ex2.m2.1.1.1.2" xref="S4.Ex2.m2.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.Ex2.m2.1b"><apply id="S4.Ex2.m2.1.1.1.1.cmml" xref="S4.Ex2.m2.1.1.1"><leq id="S4.Ex2.m2.1.1.1.1.1.cmml" xref="S4.Ex2.m2.1.1.1.1.1"></leq><apply id="S4.Ex2.m2.1.1.1.1.2.cmml" xref="S4.Ex2.m2.1.1.1.1.2"><apply id="S4.Ex2.m2.1.1.1.1.2.1.cmml" xref="S4.Ex2.m2.1.1.1.1.2.1"><csymbol cd="ambiguous" id="S4.Ex2.m2.1.1.1.1.2.1.1.cmml" xref="S4.Ex2.m2.1.1.1.1.2.1">superscript</csymbol><apply id="S4.Ex2.m2.1.1.1.1.2.1.2.cmml" xref="S4.Ex2.m2.1.1.1.1.2.1"><csymbol cd="ambiguous" id="S4.Ex2.m2.1.1.1.1.2.1.2.1.cmml" xref="S4.Ex2.m2.1.1.1.1.2.1">subscript</csymbol><sum id="S4.Ex2.m2.1.1.1.1.2.1.2.2.cmml" xref="S4.Ex2.m2.1.1.1.1.2.1.2.2"></sum><apply id="S4.Ex2.m2.1.1.1.1.2.1.2.3.cmml" xref="S4.Ex2.m2.1.1.1.1.2.1.2.3"><eq id="S4.Ex2.m2.1.1.1.1.2.1.2.3.1.cmml" xref="S4.Ex2.m2.1.1.1.1.2.1.2.3.1"></eq><ci id="S4.Ex2.m2.1.1.1.1.2.1.2.3.2.cmml" xref="S4.Ex2.m2.1.1.1.1.2.1.2.3.2">𝑗</ci><cn type="integer" id="S4.Ex2.m2.1.1.1.1.2.1.2.3.3.cmml" xref="S4.Ex2.m2.1.1.1.1.2.1.2.3.3">1</cn></apply></apply><ci id="S4.Ex2.m2.1.1.1.1.2.1.3.cmml" xref="S4.Ex2.m2.1.1.1.1.2.1.3">𝐿</ci></apply><apply id="S4.Ex2.m2.1.1.1.1.2.2.cmml" xref="S4.Ex2.m2.1.1.1.1.2.2"><times id="S4.Ex2.m2.1.1.1.1.2.2.1.cmml" xref="S4.Ex2.m2.1.1.1.1.2.2.1"></times><apply id="S4.Ex2.m2.1.1.1.1.2.2.2.cmml" xref="S4.Ex2.m2.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S4.Ex2.m2.1.1.1.1.2.2.2.1.cmml" xref="S4.Ex2.m2.1.1.1.1.2.2.2">subscript</csymbol><ci id="S4.Ex2.m2.1.1.1.1.2.2.2.2.cmml" xref="S4.Ex2.m2.1.1.1.1.2.2.2.2">𝑥</ci><apply id="S4.Ex2.m2.1.1.1.1.2.2.2.3.cmml" xref="S4.Ex2.m2.1.1.1.1.2.2.2.3"><times id="S4.Ex2.m2.1.1.1.1.2.2.2.3.1.cmml" xref="S4.Ex2.m2.1.1.1.1.2.2.2.3.1"></times><ci id="S4.Ex2.m2.1.1.1.1.2.2.2.3.2.cmml" xref="S4.Ex2.m2.1.1.1.1.2.2.2.3.2">𝑖</ci><ci id="S4.Ex2.m2.1.1.1.1.2.2.2.3.3.cmml" xref="S4.Ex2.m2.1.1.1.1.2.2.2.3.3">𝑗</ci></apply></apply><ci id="S4.Ex2.m2.1.1.1.1.2.2.3.cmml" xref="S4.Ex2.m2.1.1.1.1.2.2.3">𝑙</ci><apply id="S4.Ex2.m2.1.1.1.1.2.2.4.cmml" xref="S4.Ex2.m2.1.1.1.1.2.2.4"><csymbol cd="ambiguous" id="S4.Ex2.m2.1.1.1.1.2.2.4.1.cmml" xref="S4.Ex2.m2.1.1.1.1.2.2.4">subscript</csymbol><ci id="S4.Ex2.m2.1.1.1.1.2.2.4.2.cmml" xref="S4.Ex2.m2.1.1.1.1.2.2.4.2">𝑚</ci><ci id="S4.Ex2.m2.1.1.1.1.2.2.4.3.cmml" xref="S4.Ex2.m2.1.1.1.1.2.2.4.3">𝑗</ci></apply></apply></apply><apply id="S4.Ex2.m2.1.1.1.1.3.cmml" xref="S4.Ex2.m2.1.1.1.1.3"><times id="S4.Ex2.m2.1.1.1.1.3.1.cmml" xref="S4.Ex2.m2.1.1.1.1.3.1"></times><ci id="S4.Ex2.m2.1.1.1.1.3.2.cmml" xref="S4.Ex2.m2.1.1.1.1.3.2">𝑑</ci><apply id="S4.Ex2.m2.1.1.1.1.3.3.cmml" xref="S4.Ex2.m2.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S4.Ex2.m2.1.1.1.1.3.3.1.cmml" xref="S4.Ex2.m2.1.1.1.1.3.3">subscript</csymbol><ci id="S4.Ex2.m2.1.1.1.1.3.3.2.cmml" xref="S4.Ex2.m2.1.1.1.1.3.3.2">𝑚</ci><ci id="S4.Ex2.m2.1.1.1.1.3.3.3.cmml" xref="S4.Ex2.m2.1.1.1.1.3.3.3">𝑖</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.Ex2.m2.1c">\displaystyle\sum_{j=1}^{L}x_{ij}lm_{j}\leq dm_{i},</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S4.Ex2.m4.1" class="ltx_Math" alttext="\displaystyle\forall i\in D" display="inline"><semantics id="S4.Ex2.m4.1a"><mrow id="S4.Ex2.m4.1.1" xref="S4.Ex2.m4.1.1.cmml"><mrow id="S4.Ex2.m4.1.1.2" xref="S4.Ex2.m4.1.1.2.cmml"><mo rspace="0.167em" id="S4.Ex2.m4.1.1.2.1" xref="S4.Ex2.m4.1.1.2.1.cmml">∀</mo><mi id="S4.Ex2.m4.1.1.2.2" xref="S4.Ex2.m4.1.1.2.2.cmml">i</mi></mrow><mo id="S4.Ex2.m4.1.1.1" xref="S4.Ex2.m4.1.1.1.cmml">∈</mo><mi id="S4.Ex2.m4.1.1.3" xref="S4.Ex2.m4.1.1.3.cmml">D</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.Ex2.m4.1b"><apply id="S4.Ex2.m4.1.1.cmml" xref="S4.Ex2.m4.1.1"><in id="S4.Ex2.m4.1.1.1.cmml" xref="S4.Ex2.m4.1.1.1"></in><apply id="S4.Ex2.m4.1.1.2.cmml" xref="S4.Ex2.m4.1.1.2"><csymbol cd="latexml" id="S4.Ex2.m4.1.1.2.1.cmml" xref="S4.Ex2.m4.1.1.2.1">for-all</csymbol><ci id="S4.Ex2.m4.1.1.2.2.cmml" xref="S4.Ex2.m4.1.1.2.2">𝑖</ci></apply><ci id="S4.Ex2.m4.1.1.3.cmml" xref="S4.Ex2.m4.1.1.3">𝐷</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.Ex2.m4.1c">\displaystyle\forall i\in D</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="S4.Ex3"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S4.Ex3.m1.1" class="ltx_Math" alttext="\displaystyle y_{i}\geq jx_{ij}," display="inline"><semantics id="S4.Ex3.m1.1a"><mrow id="S4.Ex3.m1.1.1.1" xref="S4.Ex3.m1.1.1.1.1.cmml"><mrow id="S4.Ex3.m1.1.1.1.1" xref="S4.Ex3.m1.1.1.1.1.cmml"><msub id="S4.Ex3.m1.1.1.1.1.2" xref="S4.Ex3.m1.1.1.1.1.2.cmml"><mi id="S4.Ex3.m1.1.1.1.1.2.2" xref="S4.Ex3.m1.1.1.1.1.2.2.cmml">y</mi><mi id="S4.Ex3.m1.1.1.1.1.2.3" xref="S4.Ex3.m1.1.1.1.1.2.3.cmml">i</mi></msub><mo id="S4.Ex3.m1.1.1.1.1.1" xref="S4.Ex3.m1.1.1.1.1.1.cmml">≥</mo><mrow id="S4.Ex3.m1.1.1.1.1.3" xref="S4.Ex3.m1.1.1.1.1.3.cmml"><mi id="S4.Ex3.m1.1.1.1.1.3.2" xref="S4.Ex3.m1.1.1.1.1.3.2.cmml">j</mi><mo lspace="0em" rspace="0em" id="S4.Ex3.m1.1.1.1.1.3.1" xref="S4.Ex3.m1.1.1.1.1.3.1.cmml">​</mo><msub id="S4.Ex3.m1.1.1.1.1.3.3" xref="S4.Ex3.m1.1.1.1.1.3.3.cmml"><mi id="S4.Ex3.m1.1.1.1.1.3.3.2" xref="S4.Ex3.m1.1.1.1.1.3.3.2.cmml">x</mi><mrow id="S4.Ex3.m1.1.1.1.1.3.3.3" xref="S4.Ex3.m1.1.1.1.1.3.3.3.cmml"><mi id="S4.Ex3.m1.1.1.1.1.3.3.3.2" xref="S4.Ex3.m1.1.1.1.1.3.3.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.Ex3.m1.1.1.1.1.3.3.3.1" xref="S4.Ex3.m1.1.1.1.1.3.3.3.1.cmml">​</mo><mi id="S4.Ex3.m1.1.1.1.1.3.3.3.3" xref="S4.Ex3.m1.1.1.1.1.3.3.3.3.cmml">j</mi></mrow></msub></mrow></mrow><mo id="S4.Ex3.m1.1.1.1.2" xref="S4.Ex3.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.Ex3.m1.1b"><apply id="S4.Ex3.m1.1.1.1.1.cmml" xref="S4.Ex3.m1.1.1.1"><geq id="S4.Ex3.m1.1.1.1.1.1.cmml" xref="S4.Ex3.m1.1.1.1.1.1"></geq><apply id="S4.Ex3.m1.1.1.1.1.2.cmml" xref="S4.Ex3.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.Ex3.m1.1.1.1.1.2.1.cmml" xref="S4.Ex3.m1.1.1.1.1.2">subscript</csymbol><ci id="S4.Ex3.m1.1.1.1.1.2.2.cmml" xref="S4.Ex3.m1.1.1.1.1.2.2">𝑦</ci><ci id="S4.Ex3.m1.1.1.1.1.2.3.cmml" xref="S4.Ex3.m1.1.1.1.1.2.3">𝑖</ci></apply><apply id="S4.Ex3.m1.1.1.1.1.3.cmml" xref="S4.Ex3.m1.1.1.1.1.3"><times id="S4.Ex3.m1.1.1.1.1.3.1.cmml" xref="S4.Ex3.m1.1.1.1.1.3.1"></times><ci id="S4.Ex3.m1.1.1.1.1.3.2.cmml" xref="S4.Ex3.m1.1.1.1.1.3.2">𝑗</ci><apply id="S4.Ex3.m1.1.1.1.1.3.3.cmml" xref="S4.Ex3.m1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S4.Ex3.m1.1.1.1.1.3.3.1.cmml" xref="S4.Ex3.m1.1.1.1.1.3.3">subscript</csymbol><ci id="S4.Ex3.m1.1.1.1.1.3.3.2.cmml" xref="S4.Ex3.m1.1.1.1.1.3.3.2">𝑥</ci><apply id="S4.Ex3.m1.1.1.1.1.3.3.3.cmml" xref="S4.Ex3.m1.1.1.1.1.3.3.3"><times id="S4.Ex3.m1.1.1.1.1.3.3.3.1.cmml" xref="S4.Ex3.m1.1.1.1.1.3.3.3.1"></times><ci id="S4.Ex3.m1.1.1.1.1.3.3.3.2.cmml" xref="S4.Ex3.m1.1.1.1.1.3.3.3.2">𝑖</ci><ci id="S4.Ex3.m1.1.1.1.1.3.3.3.3.cmml" xref="S4.Ex3.m1.1.1.1.1.3.3.3.3">𝑗</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.Ex3.m1.1c">\displaystyle y_{i}\geq jx_{ij},</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S4.Ex3.m3.2" class="ltx_Math" alttext="\displaystyle\forall i\in D,\forall j\in L" display="inline"><semantics id="S4.Ex3.m3.2a"><mrow id="S4.Ex3.m3.2.2.2" xref="S4.Ex3.m3.2.2.3.cmml"><mrow id="S4.Ex3.m3.1.1.1.1" xref="S4.Ex3.m3.1.1.1.1.cmml"><mrow id="S4.Ex3.m3.1.1.1.1.2" xref="S4.Ex3.m3.1.1.1.1.2.cmml"><mo rspace="0.167em" id="S4.Ex3.m3.1.1.1.1.2.1" xref="S4.Ex3.m3.1.1.1.1.2.1.cmml">∀</mo><mi id="S4.Ex3.m3.1.1.1.1.2.2" xref="S4.Ex3.m3.1.1.1.1.2.2.cmml">i</mi></mrow><mo id="S4.Ex3.m3.1.1.1.1.1" xref="S4.Ex3.m3.1.1.1.1.1.cmml">∈</mo><mi id="S4.Ex3.m3.1.1.1.1.3" xref="S4.Ex3.m3.1.1.1.1.3.cmml">D</mi></mrow><mo id="S4.Ex3.m3.2.2.2.3" xref="S4.Ex3.m3.2.2.3a.cmml">,</mo><mrow id="S4.Ex3.m3.2.2.2.2" xref="S4.Ex3.m3.2.2.2.2.cmml"><mrow id="S4.Ex3.m3.2.2.2.2.2" xref="S4.Ex3.m3.2.2.2.2.2.cmml"><mo rspace="0.167em" id="S4.Ex3.m3.2.2.2.2.2.1" xref="S4.Ex3.m3.2.2.2.2.2.1.cmml">∀</mo><mi id="S4.Ex3.m3.2.2.2.2.2.2" xref="S4.Ex3.m3.2.2.2.2.2.2.cmml">j</mi></mrow><mo id="S4.Ex3.m3.2.2.2.2.1" xref="S4.Ex3.m3.2.2.2.2.1.cmml">∈</mo><mi id="S4.Ex3.m3.2.2.2.2.3" xref="S4.Ex3.m3.2.2.2.2.3.cmml">L</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.Ex3.m3.2b"><apply id="S4.Ex3.m3.2.2.3.cmml" xref="S4.Ex3.m3.2.2.2"><csymbol cd="ambiguous" id="S4.Ex3.m3.2.2.3a.cmml" xref="S4.Ex3.m3.2.2.2.3">formulae-sequence</csymbol><apply id="S4.Ex3.m3.1.1.1.1.cmml" xref="S4.Ex3.m3.1.1.1.1"><in id="S4.Ex3.m3.1.1.1.1.1.cmml" xref="S4.Ex3.m3.1.1.1.1.1"></in><apply id="S4.Ex3.m3.1.1.1.1.2.cmml" xref="S4.Ex3.m3.1.1.1.1.2"><csymbol cd="latexml" id="S4.Ex3.m3.1.1.1.1.2.1.cmml" xref="S4.Ex3.m3.1.1.1.1.2.1">for-all</csymbol><ci id="S4.Ex3.m3.1.1.1.1.2.2.cmml" xref="S4.Ex3.m3.1.1.1.1.2.2">𝑖</ci></apply><ci id="S4.Ex3.m3.1.1.1.1.3.cmml" xref="S4.Ex3.m3.1.1.1.1.3">𝐷</ci></apply><apply id="S4.Ex3.m3.2.2.2.2.cmml" xref="S4.Ex3.m3.2.2.2.2"><in id="S4.Ex3.m3.2.2.2.2.1.cmml" xref="S4.Ex3.m3.2.2.2.2.1"></in><apply id="S4.Ex3.m3.2.2.2.2.2.cmml" xref="S4.Ex3.m3.2.2.2.2.2"><csymbol cd="latexml" id="S4.Ex3.m3.2.2.2.2.2.1.cmml" xref="S4.Ex3.m3.2.2.2.2.2.1">for-all</csymbol><ci id="S4.Ex3.m3.2.2.2.2.2.2.cmml" xref="S4.Ex3.m3.2.2.2.2.2.2">𝑗</ci></apply><ci id="S4.Ex3.m3.2.2.2.2.3.cmml" xref="S4.Ex3.m3.2.2.2.2.3">𝐿</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.Ex3.m3.2c">\displaystyle\forall i\in D,\forall j\in L</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="S4.Ex4"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S4.Ex4.m1.1" class="ltx_Math" alttext="\displaystyle z_{i}\leq jx_{ij}+M(1-x_{ij})," display="inline"><semantics id="S4.Ex4.m1.1a"><mrow id="S4.Ex4.m1.1.1.1" xref="S4.Ex4.m1.1.1.1.1.cmml"><mrow id="S4.Ex4.m1.1.1.1.1" xref="S4.Ex4.m1.1.1.1.1.cmml"><msub id="S4.Ex4.m1.1.1.1.1.3" xref="S4.Ex4.m1.1.1.1.1.3.cmml"><mi id="S4.Ex4.m1.1.1.1.1.3.2" xref="S4.Ex4.m1.1.1.1.1.3.2.cmml">z</mi><mi id="S4.Ex4.m1.1.1.1.1.3.3" xref="S4.Ex4.m1.1.1.1.1.3.3.cmml">i</mi></msub><mo id="S4.Ex4.m1.1.1.1.1.2" xref="S4.Ex4.m1.1.1.1.1.2.cmml">≤</mo><mrow id="S4.Ex4.m1.1.1.1.1.1" xref="S4.Ex4.m1.1.1.1.1.1.cmml"><mrow id="S4.Ex4.m1.1.1.1.1.1.3" xref="S4.Ex4.m1.1.1.1.1.1.3.cmml"><mi id="S4.Ex4.m1.1.1.1.1.1.3.2" xref="S4.Ex4.m1.1.1.1.1.1.3.2.cmml">j</mi><mo lspace="0em" rspace="0em" id="S4.Ex4.m1.1.1.1.1.1.3.1" xref="S4.Ex4.m1.1.1.1.1.1.3.1.cmml">​</mo><msub id="S4.Ex4.m1.1.1.1.1.1.3.3" xref="S4.Ex4.m1.1.1.1.1.1.3.3.cmml"><mi id="S4.Ex4.m1.1.1.1.1.1.3.3.2" xref="S4.Ex4.m1.1.1.1.1.1.3.3.2.cmml">x</mi><mrow id="S4.Ex4.m1.1.1.1.1.1.3.3.3" xref="S4.Ex4.m1.1.1.1.1.1.3.3.3.cmml"><mi id="S4.Ex4.m1.1.1.1.1.1.3.3.3.2" xref="S4.Ex4.m1.1.1.1.1.1.3.3.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.Ex4.m1.1.1.1.1.1.3.3.3.1" xref="S4.Ex4.m1.1.1.1.1.1.3.3.3.1.cmml">​</mo><mi id="S4.Ex4.m1.1.1.1.1.1.3.3.3.3" xref="S4.Ex4.m1.1.1.1.1.1.3.3.3.3.cmml">j</mi></mrow></msub></mrow><mo id="S4.Ex4.m1.1.1.1.1.1.2" xref="S4.Ex4.m1.1.1.1.1.1.2.cmml">+</mo><mrow id="S4.Ex4.m1.1.1.1.1.1.1" xref="S4.Ex4.m1.1.1.1.1.1.1.cmml"><mi id="S4.Ex4.m1.1.1.1.1.1.1.3" xref="S4.Ex4.m1.1.1.1.1.1.1.3.cmml">M</mi><mo lspace="0em" rspace="0em" id="S4.Ex4.m1.1.1.1.1.1.1.2" xref="S4.Ex4.m1.1.1.1.1.1.1.2.cmml">​</mo><mrow id="S4.Ex4.m1.1.1.1.1.1.1.1.1" xref="S4.Ex4.m1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.Ex4.m1.1.1.1.1.1.1.1.1.2" xref="S4.Ex4.m1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.Ex4.m1.1.1.1.1.1.1.1.1.1" xref="S4.Ex4.m1.1.1.1.1.1.1.1.1.1.cmml"><mn id="S4.Ex4.m1.1.1.1.1.1.1.1.1.1.2" xref="S4.Ex4.m1.1.1.1.1.1.1.1.1.1.2.cmml">1</mn><mo id="S4.Ex4.m1.1.1.1.1.1.1.1.1.1.1" xref="S4.Ex4.m1.1.1.1.1.1.1.1.1.1.1.cmml">−</mo><msub id="S4.Ex4.m1.1.1.1.1.1.1.1.1.1.3" xref="S4.Ex4.m1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S4.Ex4.m1.1.1.1.1.1.1.1.1.1.3.2" xref="S4.Ex4.m1.1.1.1.1.1.1.1.1.1.3.2.cmml">x</mi><mrow id="S4.Ex4.m1.1.1.1.1.1.1.1.1.1.3.3" xref="S4.Ex4.m1.1.1.1.1.1.1.1.1.1.3.3.cmml"><mi id="S4.Ex4.m1.1.1.1.1.1.1.1.1.1.3.3.2" xref="S4.Ex4.m1.1.1.1.1.1.1.1.1.1.3.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.Ex4.m1.1.1.1.1.1.1.1.1.1.3.3.1" xref="S4.Ex4.m1.1.1.1.1.1.1.1.1.1.3.3.1.cmml">​</mo><mi id="S4.Ex4.m1.1.1.1.1.1.1.1.1.1.3.3.3" xref="S4.Ex4.m1.1.1.1.1.1.1.1.1.1.3.3.3.cmml">j</mi></mrow></msub></mrow><mo stretchy="false" id="S4.Ex4.m1.1.1.1.1.1.1.1.1.3" xref="S4.Ex4.m1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S4.Ex4.m1.1.1.1.2" xref="S4.Ex4.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.Ex4.m1.1b"><apply id="S4.Ex4.m1.1.1.1.1.cmml" xref="S4.Ex4.m1.1.1.1"><leq id="S4.Ex4.m1.1.1.1.1.2.cmml" xref="S4.Ex4.m1.1.1.1.1.2"></leq><apply id="S4.Ex4.m1.1.1.1.1.3.cmml" xref="S4.Ex4.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.Ex4.m1.1.1.1.1.3.1.cmml" xref="S4.Ex4.m1.1.1.1.1.3">subscript</csymbol><ci id="S4.Ex4.m1.1.1.1.1.3.2.cmml" xref="S4.Ex4.m1.1.1.1.1.3.2">𝑧</ci><ci id="S4.Ex4.m1.1.1.1.1.3.3.cmml" xref="S4.Ex4.m1.1.1.1.1.3.3">𝑖</ci></apply><apply id="S4.Ex4.m1.1.1.1.1.1.cmml" xref="S4.Ex4.m1.1.1.1.1.1"><plus id="S4.Ex4.m1.1.1.1.1.1.2.cmml" xref="S4.Ex4.m1.1.1.1.1.1.2"></plus><apply id="S4.Ex4.m1.1.1.1.1.1.3.cmml" xref="S4.Ex4.m1.1.1.1.1.1.3"><times id="S4.Ex4.m1.1.1.1.1.1.3.1.cmml" xref="S4.Ex4.m1.1.1.1.1.1.3.1"></times><ci id="S4.Ex4.m1.1.1.1.1.1.3.2.cmml" xref="S4.Ex4.m1.1.1.1.1.1.3.2">𝑗</ci><apply id="S4.Ex4.m1.1.1.1.1.1.3.3.cmml" xref="S4.Ex4.m1.1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S4.Ex4.m1.1.1.1.1.1.3.3.1.cmml" xref="S4.Ex4.m1.1.1.1.1.1.3.3">subscript</csymbol><ci id="S4.Ex4.m1.1.1.1.1.1.3.3.2.cmml" xref="S4.Ex4.m1.1.1.1.1.1.3.3.2">𝑥</ci><apply id="S4.Ex4.m1.1.1.1.1.1.3.3.3.cmml" xref="S4.Ex4.m1.1.1.1.1.1.3.3.3"><times id="S4.Ex4.m1.1.1.1.1.1.3.3.3.1.cmml" xref="S4.Ex4.m1.1.1.1.1.1.3.3.3.1"></times><ci id="S4.Ex4.m1.1.1.1.1.1.3.3.3.2.cmml" xref="S4.Ex4.m1.1.1.1.1.1.3.3.3.2">𝑖</ci><ci id="S4.Ex4.m1.1.1.1.1.1.3.3.3.3.cmml" xref="S4.Ex4.m1.1.1.1.1.1.3.3.3.3">𝑗</ci></apply></apply></apply><apply id="S4.Ex4.m1.1.1.1.1.1.1.cmml" xref="S4.Ex4.m1.1.1.1.1.1.1"><times id="S4.Ex4.m1.1.1.1.1.1.1.2.cmml" xref="S4.Ex4.m1.1.1.1.1.1.1.2"></times><ci id="S4.Ex4.m1.1.1.1.1.1.1.3.cmml" xref="S4.Ex4.m1.1.1.1.1.1.1.3">𝑀</ci><apply id="S4.Ex4.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.Ex4.m1.1.1.1.1.1.1.1.1"><minus id="S4.Ex4.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.Ex4.m1.1.1.1.1.1.1.1.1.1.1"></minus><cn type="integer" id="S4.Ex4.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.Ex4.m1.1.1.1.1.1.1.1.1.1.2">1</cn><apply id="S4.Ex4.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S4.Ex4.m1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.Ex4.m1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S4.Ex4.m1.1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S4.Ex4.m1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S4.Ex4.m1.1.1.1.1.1.1.1.1.1.3.2">𝑥</ci><apply id="S4.Ex4.m1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S4.Ex4.m1.1.1.1.1.1.1.1.1.1.3.3"><times id="S4.Ex4.m1.1.1.1.1.1.1.1.1.1.3.3.1.cmml" xref="S4.Ex4.m1.1.1.1.1.1.1.1.1.1.3.3.1"></times><ci id="S4.Ex4.m1.1.1.1.1.1.1.1.1.1.3.3.2.cmml" xref="S4.Ex4.m1.1.1.1.1.1.1.1.1.1.3.3.2">𝑖</ci><ci id="S4.Ex4.m1.1.1.1.1.1.1.1.1.1.3.3.3.cmml" xref="S4.Ex4.m1.1.1.1.1.1.1.1.1.1.3.3.3">𝑗</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.Ex4.m1.1c">\displaystyle z_{i}\leq jx_{ij}+M(1-x_{ij}),</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S4.Ex4.m3.2" class="ltx_Math" alttext="\displaystyle\forall i\in D,\forall j\in L" display="inline"><semantics id="S4.Ex4.m3.2a"><mrow id="S4.Ex4.m3.2.2.2" xref="S4.Ex4.m3.2.2.3.cmml"><mrow id="S4.Ex4.m3.1.1.1.1" xref="S4.Ex4.m3.1.1.1.1.cmml"><mrow id="S4.Ex4.m3.1.1.1.1.2" xref="S4.Ex4.m3.1.1.1.1.2.cmml"><mo rspace="0.167em" id="S4.Ex4.m3.1.1.1.1.2.1" xref="S4.Ex4.m3.1.1.1.1.2.1.cmml">∀</mo><mi id="S4.Ex4.m3.1.1.1.1.2.2" xref="S4.Ex4.m3.1.1.1.1.2.2.cmml">i</mi></mrow><mo id="S4.Ex4.m3.1.1.1.1.1" xref="S4.Ex4.m3.1.1.1.1.1.cmml">∈</mo><mi id="S4.Ex4.m3.1.1.1.1.3" xref="S4.Ex4.m3.1.1.1.1.3.cmml">D</mi></mrow><mo id="S4.Ex4.m3.2.2.2.3" xref="S4.Ex4.m3.2.2.3a.cmml">,</mo><mrow id="S4.Ex4.m3.2.2.2.2" xref="S4.Ex4.m3.2.2.2.2.cmml"><mrow id="S4.Ex4.m3.2.2.2.2.2" xref="S4.Ex4.m3.2.2.2.2.2.cmml"><mo rspace="0.167em" id="S4.Ex4.m3.2.2.2.2.2.1" xref="S4.Ex4.m3.2.2.2.2.2.1.cmml">∀</mo><mi id="S4.Ex4.m3.2.2.2.2.2.2" xref="S4.Ex4.m3.2.2.2.2.2.2.cmml">j</mi></mrow><mo id="S4.Ex4.m3.2.2.2.2.1" xref="S4.Ex4.m3.2.2.2.2.1.cmml">∈</mo><mi id="S4.Ex4.m3.2.2.2.2.3" xref="S4.Ex4.m3.2.2.2.2.3.cmml">L</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.Ex4.m3.2b"><apply id="S4.Ex4.m3.2.2.3.cmml" xref="S4.Ex4.m3.2.2.2"><csymbol cd="ambiguous" id="S4.Ex4.m3.2.2.3a.cmml" xref="S4.Ex4.m3.2.2.2.3">formulae-sequence</csymbol><apply id="S4.Ex4.m3.1.1.1.1.cmml" xref="S4.Ex4.m3.1.1.1.1"><in id="S4.Ex4.m3.1.1.1.1.1.cmml" xref="S4.Ex4.m3.1.1.1.1.1"></in><apply id="S4.Ex4.m3.1.1.1.1.2.cmml" xref="S4.Ex4.m3.1.1.1.1.2"><csymbol cd="latexml" id="S4.Ex4.m3.1.1.1.1.2.1.cmml" xref="S4.Ex4.m3.1.1.1.1.2.1">for-all</csymbol><ci id="S4.Ex4.m3.1.1.1.1.2.2.cmml" xref="S4.Ex4.m3.1.1.1.1.2.2">𝑖</ci></apply><ci id="S4.Ex4.m3.1.1.1.1.3.cmml" xref="S4.Ex4.m3.1.1.1.1.3">𝐷</ci></apply><apply id="S4.Ex4.m3.2.2.2.2.cmml" xref="S4.Ex4.m3.2.2.2.2"><in id="S4.Ex4.m3.2.2.2.2.1.cmml" xref="S4.Ex4.m3.2.2.2.2.1"></in><apply id="S4.Ex4.m3.2.2.2.2.2.cmml" xref="S4.Ex4.m3.2.2.2.2.2"><csymbol cd="latexml" id="S4.Ex4.m3.2.2.2.2.2.1.cmml" xref="S4.Ex4.m3.2.2.2.2.2.1">for-all</csymbol><ci id="S4.Ex4.m3.2.2.2.2.2.2.cmml" xref="S4.Ex4.m3.2.2.2.2.2.2">𝑗</ci></apply><ci id="S4.Ex4.m3.2.2.2.2.3.cmml" xref="S4.Ex4.m3.2.2.2.2.3">𝐿</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.Ex4.m3.2c">\displaystyle\forall i\in D,\forall j\in L</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="S4.Ex5"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S4.Ex5.m1.1" class="ltx_Math" alttext="\displaystyle y_{i}-z_{i}=\sum_{j=1}^{L}x_{ij}-1," display="inline"><semantics id="S4.Ex5.m1.1a"><mrow id="S4.Ex5.m1.1.1.1" xref="S4.Ex5.m1.1.1.1.1.cmml"><mrow id="S4.Ex5.m1.1.1.1.1" xref="S4.Ex5.m1.1.1.1.1.cmml"><mrow id="S4.Ex5.m1.1.1.1.1.2" xref="S4.Ex5.m1.1.1.1.1.2.cmml"><msub id="S4.Ex5.m1.1.1.1.1.2.2" xref="S4.Ex5.m1.1.1.1.1.2.2.cmml"><mi id="S4.Ex5.m1.1.1.1.1.2.2.2" xref="S4.Ex5.m1.1.1.1.1.2.2.2.cmml">y</mi><mi id="S4.Ex5.m1.1.1.1.1.2.2.3" xref="S4.Ex5.m1.1.1.1.1.2.2.3.cmml">i</mi></msub><mo id="S4.Ex5.m1.1.1.1.1.2.1" xref="S4.Ex5.m1.1.1.1.1.2.1.cmml">−</mo><msub id="S4.Ex5.m1.1.1.1.1.2.3" xref="S4.Ex5.m1.1.1.1.1.2.3.cmml"><mi id="S4.Ex5.m1.1.1.1.1.2.3.2" xref="S4.Ex5.m1.1.1.1.1.2.3.2.cmml">z</mi><mi id="S4.Ex5.m1.1.1.1.1.2.3.3" xref="S4.Ex5.m1.1.1.1.1.2.3.3.cmml">i</mi></msub></mrow><mo id="S4.Ex5.m1.1.1.1.1.1" xref="S4.Ex5.m1.1.1.1.1.1.cmml">=</mo><mrow id="S4.Ex5.m1.1.1.1.1.3" xref="S4.Ex5.m1.1.1.1.1.3.cmml"><mrow id="S4.Ex5.m1.1.1.1.1.3.2" xref="S4.Ex5.m1.1.1.1.1.3.2.cmml"><mstyle displaystyle="true" id="S4.Ex5.m1.1.1.1.1.3.2.1" xref="S4.Ex5.m1.1.1.1.1.3.2.1.cmml"><munderover id="S4.Ex5.m1.1.1.1.1.3.2.1a" xref="S4.Ex5.m1.1.1.1.1.3.2.1.cmml"><mo movablelimits="false" id="S4.Ex5.m1.1.1.1.1.3.2.1.2.2" xref="S4.Ex5.m1.1.1.1.1.3.2.1.2.2.cmml">∑</mo><mrow id="S4.Ex5.m1.1.1.1.1.3.2.1.2.3" xref="S4.Ex5.m1.1.1.1.1.3.2.1.2.3.cmml"><mi id="S4.Ex5.m1.1.1.1.1.3.2.1.2.3.2" xref="S4.Ex5.m1.1.1.1.1.3.2.1.2.3.2.cmml">j</mi><mo id="S4.Ex5.m1.1.1.1.1.3.2.1.2.3.1" xref="S4.Ex5.m1.1.1.1.1.3.2.1.2.3.1.cmml">=</mo><mn id="S4.Ex5.m1.1.1.1.1.3.2.1.2.3.3" xref="S4.Ex5.m1.1.1.1.1.3.2.1.2.3.3.cmml">1</mn></mrow><mi id="S4.Ex5.m1.1.1.1.1.3.2.1.3" xref="S4.Ex5.m1.1.1.1.1.3.2.1.3.cmml">L</mi></munderover></mstyle><msub id="S4.Ex5.m1.1.1.1.1.3.2.2" xref="S4.Ex5.m1.1.1.1.1.3.2.2.cmml"><mi id="S4.Ex5.m1.1.1.1.1.3.2.2.2" xref="S4.Ex5.m1.1.1.1.1.3.2.2.2.cmml">x</mi><mrow id="S4.Ex5.m1.1.1.1.1.3.2.2.3" xref="S4.Ex5.m1.1.1.1.1.3.2.2.3.cmml"><mi id="S4.Ex5.m1.1.1.1.1.3.2.2.3.2" xref="S4.Ex5.m1.1.1.1.1.3.2.2.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.Ex5.m1.1.1.1.1.3.2.2.3.1" xref="S4.Ex5.m1.1.1.1.1.3.2.2.3.1.cmml">​</mo><mi id="S4.Ex5.m1.1.1.1.1.3.2.2.3.3" xref="S4.Ex5.m1.1.1.1.1.3.2.2.3.3.cmml">j</mi></mrow></msub></mrow><mo id="S4.Ex5.m1.1.1.1.1.3.1" xref="S4.Ex5.m1.1.1.1.1.3.1.cmml">−</mo><mn id="S4.Ex5.m1.1.1.1.1.3.3" xref="S4.Ex5.m1.1.1.1.1.3.3.cmml">1</mn></mrow></mrow><mo id="S4.Ex5.m1.1.1.1.2" xref="S4.Ex5.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.Ex5.m1.1b"><apply id="S4.Ex5.m1.1.1.1.1.cmml" xref="S4.Ex5.m1.1.1.1"><eq id="S4.Ex5.m1.1.1.1.1.1.cmml" xref="S4.Ex5.m1.1.1.1.1.1"></eq><apply id="S4.Ex5.m1.1.1.1.1.2.cmml" xref="S4.Ex5.m1.1.1.1.1.2"><minus id="S4.Ex5.m1.1.1.1.1.2.1.cmml" xref="S4.Ex5.m1.1.1.1.1.2.1"></minus><apply id="S4.Ex5.m1.1.1.1.1.2.2.cmml" xref="S4.Ex5.m1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S4.Ex5.m1.1.1.1.1.2.2.1.cmml" xref="S4.Ex5.m1.1.1.1.1.2.2">subscript</csymbol><ci id="S4.Ex5.m1.1.1.1.1.2.2.2.cmml" xref="S4.Ex5.m1.1.1.1.1.2.2.2">𝑦</ci><ci id="S4.Ex5.m1.1.1.1.1.2.2.3.cmml" xref="S4.Ex5.m1.1.1.1.1.2.2.3">𝑖</ci></apply><apply id="S4.Ex5.m1.1.1.1.1.2.3.cmml" xref="S4.Ex5.m1.1.1.1.1.2.3"><csymbol cd="ambiguous" id="S4.Ex5.m1.1.1.1.1.2.3.1.cmml" xref="S4.Ex5.m1.1.1.1.1.2.3">subscript</csymbol><ci id="S4.Ex5.m1.1.1.1.1.2.3.2.cmml" xref="S4.Ex5.m1.1.1.1.1.2.3.2">𝑧</ci><ci id="S4.Ex5.m1.1.1.1.1.2.3.3.cmml" xref="S4.Ex5.m1.1.1.1.1.2.3.3">𝑖</ci></apply></apply><apply id="S4.Ex5.m1.1.1.1.1.3.cmml" xref="S4.Ex5.m1.1.1.1.1.3"><minus id="S4.Ex5.m1.1.1.1.1.3.1.cmml" xref="S4.Ex5.m1.1.1.1.1.3.1"></minus><apply id="S4.Ex5.m1.1.1.1.1.3.2.cmml" xref="S4.Ex5.m1.1.1.1.1.3.2"><apply id="S4.Ex5.m1.1.1.1.1.3.2.1.cmml" xref="S4.Ex5.m1.1.1.1.1.3.2.1"><csymbol cd="ambiguous" id="S4.Ex5.m1.1.1.1.1.3.2.1.1.cmml" xref="S4.Ex5.m1.1.1.1.1.3.2.1">superscript</csymbol><apply id="S4.Ex5.m1.1.1.1.1.3.2.1.2.cmml" xref="S4.Ex5.m1.1.1.1.1.3.2.1"><csymbol cd="ambiguous" id="S4.Ex5.m1.1.1.1.1.3.2.1.2.1.cmml" xref="S4.Ex5.m1.1.1.1.1.3.2.1">subscript</csymbol><sum id="S4.Ex5.m1.1.1.1.1.3.2.1.2.2.cmml" xref="S4.Ex5.m1.1.1.1.1.3.2.1.2.2"></sum><apply id="S4.Ex5.m1.1.1.1.1.3.2.1.2.3.cmml" xref="S4.Ex5.m1.1.1.1.1.3.2.1.2.3"><eq id="S4.Ex5.m1.1.1.1.1.3.2.1.2.3.1.cmml" xref="S4.Ex5.m1.1.1.1.1.3.2.1.2.3.1"></eq><ci id="S4.Ex5.m1.1.1.1.1.3.2.1.2.3.2.cmml" xref="S4.Ex5.m1.1.1.1.1.3.2.1.2.3.2">𝑗</ci><cn type="integer" id="S4.Ex5.m1.1.1.1.1.3.2.1.2.3.3.cmml" xref="S4.Ex5.m1.1.1.1.1.3.2.1.2.3.3">1</cn></apply></apply><ci id="S4.Ex5.m1.1.1.1.1.3.2.1.3.cmml" xref="S4.Ex5.m1.1.1.1.1.3.2.1.3">𝐿</ci></apply><apply id="S4.Ex5.m1.1.1.1.1.3.2.2.cmml" xref="S4.Ex5.m1.1.1.1.1.3.2.2"><csymbol cd="ambiguous" id="S4.Ex5.m1.1.1.1.1.3.2.2.1.cmml" xref="S4.Ex5.m1.1.1.1.1.3.2.2">subscript</csymbol><ci id="S4.Ex5.m1.1.1.1.1.3.2.2.2.cmml" xref="S4.Ex5.m1.1.1.1.1.3.2.2.2">𝑥</ci><apply id="S4.Ex5.m1.1.1.1.1.3.2.2.3.cmml" xref="S4.Ex5.m1.1.1.1.1.3.2.2.3"><times id="S4.Ex5.m1.1.1.1.1.3.2.2.3.1.cmml" xref="S4.Ex5.m1.1.1.1.1.3.2.2.3.1"></times><ci id="S4.Ex5.m1.1.1.1.1.3.2.2.3.2.cmml" xref="S4.Ex5.m1.1.1.1.1.3.2.2.3.2">𝑖</ci><ci id="S4.Ex5.m1.1.1.1.1.3.2.2.3.3.cmml" xref="S4.Ex5.m1.1.1.1.1.3.2.2.3.3">𝑗</ci></apply></apply></apply><cn type="integer" id="S4.Ex5.m1.1.1.1.1.3.3.cmml" xref="S4.Ex5.m1.1.1.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.Ex5.m1.1c">\displaystyle y_{i}-z_{i}=\sum_{j=1}^{L}x_{ij}-1,</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S4.Ex5.m3.1" class="ltx_Math" alttext="\displaystyle\forall i\in D" display="inline"><semantics id="S4.Ex5.m3.1a"><mrow id="S4.Ex5.m3.1.1" xref="S4.Ex5.m3.1.1.cmml"><mrow id="S4.Ex5.m3.1.1.2" xref="S4.Ex5.m3.1.1.2.cmml"><mo rspace="0.167em" id="S4.Ex5.m3.1.1.2.1" xref="S4.Ex5.m3.1.1.2.1.cmml">∀</mo><mi id="S4.Ex5.m3.1.1.2.2" xref="S4.Ex5.m3.1.1.2.2.cmml">i</mi></mrow><mo id="S4.Ex5.m3.1.1.1" xref="S4.Ex5.m3.1.1.1.cmml">∈</mo><mi id="S4.Ex5.m3.1.1.3" xref="S4.Ex5.m3.1.1.3.cmml">D</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.Ex5.m3.1b"><apply id="S4.Ex5.m3.1.1.cmml" xref="S4.Ex5.m3.1.1"><in id="S4.Ex5.m3.1.1.1.cmml" xref="S4.Ex5.m3.1.1.1"></in><apply id="S4.Ex5.m3.1.1.2.cmml" xref="S4.Ex5.m3.1.1.2"><csymbol cd="latexml" id="S4.Ex5.m3.1.1.2.1.cmml" xref="S4.Ex5.m3.1.1.2.1">for-all</csymbol><ci id="S4.Ex5.m3.1.1.2.2.cmml" xref="S4.Ex5.m3.1.1.2.2">𝑖</ci></apply><ci id="S4.Ex5.m3.1.1.3.cmml" xref="S4.Ex5.m3.1.1.3">𝐷</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.Ex5.m3.1c">\displaystyle\forall i\in D</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="S4.Ex6"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S4.Ex6.m1.1" class="ltx_Math" alttext="\displaystyle\sum_{i=1}^{D}x_{ij}=1," display="inline"><semantics id="S4.Ex6.m1.1a"><mrow id="S4.Ex6.m1.1.1.1" xref="S4.Ex6.m1.1.1.1.1.cmml"><mrow id="S4.Ex6.m1.1.1.1.1" xref="S4.Ex6.m1.1.1.1.1.cmml"><mrow id="S4.Ex6.m1.1.1.1.1.2" xref="S4.Ex6.m1.1.1.1.1.2.cmml"><mstyle displaystyle="true" id="S4.Ex6.m1.1.1.1.1.2.1" xref="S4.Ex6.m1.1.1.1.1.2.1.cmml"><munderover id="S4.Ex6.m1.1.1.1.1.2.1a" xref="S4.Ex6.m1.1.1.1.1.2.1.cmml"><mo movablelimits="false" id="S4.Ex6.m1.1.1.1.1.2.1.2.2" xref="S4.Ex6.m1.1.1.1.1.2.1.2.2.cmml">∑</mo><mrow id="S4.Ex6.m1.1.1.1.1.2.1.2.3" xref="S4.Ex6.m1.1.1.1.1.2.1.2.3.cmml"><mi id="S4.Ex6.m1.1.1.1.1.2.1.2.3.2" xref="S4.Ex6.m1.1.1.1.1.2.1.2.3.2.cmml">i</mi><mo id="S4.Ex6.m1.1.1.1.1.2.1.2.3.1" xref="S4.Ex6.m1.1.1.1.1.2.1.2.3.1.cmml">=</mo><mn id="S4.Ex6.m1.1.1.1.1.2.1.2.3.3" xref="S4.Ex6.m1.1.1.1.1.2.1.2.3.3.cmml">1</mn></mrow><mi id="S4.Ex6.m1.1.1.1.1.2.1.3" xref="S4.Ex6.m1.1.1.1.1.2.1.3.cmml">D</mi></munderover></mstyle><msub id="S4.Ex6.m1.1.1.1.1.2.2" xref="S4.Ex6.m1.1.1.1.1.2.2.cmml"><mi id="S4.Ex6.m1.1.1.1.1.2.2.2" xref="S4.Ex6.m1.1.1.1.1.2.2.2.cmml">x</mi><mrow id="S4.Ex6.m1.1.1.1.1.2.2.3" xref="S4.Ex6.m1.1.1.1.1.2.2.3.cmml"><mi id="S4.Ex6.m1.1.1.1.1.2.2.3.2" xref="S4.Ex6.m1.1.1.1.1.2.2.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.Ex6.m1.1.1.1.1.2.2.3.1" xref="S4.Ex6.m1.1.1.1.1.2.2.3.1.cmml">​</mo><mi id="S4.Ex6.m1.1.1.1.1.2.2.3.3" xref="S4.Ex6.m1.1.1.1.1.2.2.3.3.cmml">j</mi></mrow></msub></mrow><mo id="S4.Ex6.m1.1.1.1.1.1" xref="S4.Ex6.m1.1.1.1.1.1.cmml">=</mo><mn id="S4.Ex6.m1.1.1.1.1.3" xref="S4.Ex6.m1.1.1.1.1.3.cmml">1</mn></mrow><mo id="S4.Ex6.m1.1.1.1.2" xref="S4.Ex6.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.Ex6.m1.1b"><apply id="S4.Ex6.m1.1.1.1.1.cmml" xref="S4.Ex6.m1.1.1.1"><eq id="S4.Ex6.m1.1.1.1.1.1.cmml" xref="S4.Ex6.m1.1.1.1.1.1"></eq><apply id="S4.Ex6.m1.1.1.1.1.2.cmml" xref="S4.Ex6.m1.1.1.1.1.2"><apply id="S4.Ex6.m1.1.1.1.1.2.1.cmml" xref="S4.Ex6.m1.1.1.1.1.2.1"><csymbol cd="ambiguous" id="S4.Ex6.m1.1.1.1.1.2.1.1.cmml" xref="S4.Ex6.m1.1.1.1.1.2.1">superscript</csymbol><apply id="S4.Ex6.m1.1.1.1.1.2.1.2.cmml" xref="S4.Ex6.m1.1.1.1.1.2.1"><csymbol cd="ambiguous" id="S4.Ex6.m1.1.1.1.1.2.1.2.1.cmml" xref="S4.Ex6.m1.1.1.1.1.2.1">subscript</csymbol><sum id="S4.Ex6.m1.1.1.1.1.2.1.2.2.cmml" xref="S4.Ex6.m1.1.1.1.1.2.1.2.2"></sum><apply id="S4.Ex6.m1.1.1.1.1.2.1.2.3.cmml" xref="S4.Ex6.m1.1.1.1.1.2.1.2.3"><eq id="S4.Ex6.m1.1.1.1.1.2.1.2.3.1.cmml" xref="S4.Ex6.m1.1.1.1.1.2.1.2.3.1"></eq><ci id="S4.Ex6.m1.1.1.1.1.2.1.2.3.2.cmml" xref="S4.Ex6.m1.1.1.1.1.2.1.2.3.2">𝑖</ci><cn type="integer" id="S4.Ex6.m1.1.1.1.1.2.1.2.3.3.cmml" xref="S4.Ex6.m1.1.1.1.1.2.1.2.3.3">1</cn></apply></apply><ci id="S4.Ex6.m1.1.1.1.1.2.1.3.cmml" xref="S4.Ex6.m1.1.1.1.1.2.1.3">𝐷</ci></apply><apply id="S4.Ex6.m1.1.1.1.1.2.2.cmml" xref="S4.Ex6.m1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S4.Ex6.m1.1.1.1.1.2.2.1.cmml" xref="S4.Ex6.m1.1.1.1.1.2.2">subscript</csymbol><ci id="S4.Ex6.m1.1.1.1.1.2.2.2.cmml" xref="S4.Ex6.m1.1.1.1.1.2.2.2">𝑥</ci><apply id="S4.Ex6.m1.1.1.1.1.2.2.3.cmml" xref="S4.Ex6.m1.1.1.1.1.2.2.3"><times id="S4.Ex6.m1.1.1.1.1.2.2.3.1.cmml" xref="S4.Ex6.m1.1.1.1.1.2.2.3.1"></times><ci id="S4.Ex6.m1.1.1.1.1.2.2.3.2.cmml" xref="S4.Ex6.m1.1.1.1.1.2.2.3.2">𝑖</ci><ci id="S4.Ex6.m1.1.1.1.1.2.2.3.3.cmml" xref="S4.Ex6.m1.1.1.1.1.2.2.3.3">𝑗</ci></apply></apply></apply><cn type="integer" id="S4.Ex6.m1.1.1.1.1.3.cmml" xref="S4.Ex6.m1.1.1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.Ex6.m1.1c">\displaystyle\sum_{i=1}^{D}x_{ij}=1,</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S4.Ex6.m3.1" class="ltx_Math" alttext="\displaystyle\forall j\in L" display="inline"><semantics id="S4.Ex6.m3.1a"><mrow id="S4.Ex6.m3.1.1" xref="S4.Ex6.m3.1.1.cmml"><mrow id="S4.Ex6.m3.1.1.2" xref="S4.Ex6.m3.1.1.2.cmml"><mo rspace="0.167em" id="S4.Ex6.m3.1.1.2.1" xref="S4.Ex6.m3.1.1.2.1.cmml">∀</mo><mi id="S4.Ex6.m3.1.1.2.2" xref="S4.Ex6.m3.1.1.2.2.cmml">j</mi></mrow><mo id="S4.Ex6.m3.1.1.1" xref="S4.Ex6.m3.1.1.1.cmml">∈</mo><mi id="S4.Ex6.m3.1.1.3" xref="S4.Ex6.m3.1.1.3.cmml">L</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.Ex6.m3.1b"><apply id="S4.Ex6.m3.1.1.cmml" xref="S4.Ex6.m3.1.1"><in id="S4.Ex6.m3.1.1.1.cmml" xref="S4.Ex6.m3.1.1.1"></in><apply id="S4.Ex6.m3.1.1.2.cmml" xref="S4.Ex6.m3.1.1.2"><csymbol cd="latexml" id="S4.Ex6.m3.1.1.2.1.cmml" xref="S4.Ex6.m3.1.1.2.1">for-all</csymbol><ci id="S4.Ex6.m3.1.1.2.2.cmml" xref="S4.Ex6.m3.1.1.2.2">𝑗</ci></apply><ci id="S4.Ex6.m3.1.1.3.cmml" xref="S4.Ex6.m3.1.1.3">𝐿</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.Ex6.m3.1c">\displaystyle\forall j\in L</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="S4.Ex7"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S4.Ex7.m1.1" class="ltx_Math" alttext="\displaystyle q\geq dt_{i}\sum_{j=1}^{L}x_{ij}lf_{j}+ct_{i}," display="inline"><semantics id="S4.Ex7.m1.1a"><mrow id="S4.Ex7.m1.1.1.1" xref="S4.Ex7.m1.1.1.1.1.cmml"><mrow id="S4.Ex7.m1.1.1.1.1" xref="S4.Ex7.m1.1.1.1.1.cmml"><mi id="S4.Ex7.m1.1.1.1.1.2" xref="S4.Ex7.m1.1.1.1.1.2.cmml">q</mi><mo id="S4.Ex7.m1.1.1.1.1.1" xref="S4.Ex7.m1.1.1.1.1.1.cmml">≥</mo><mrow id="S4.Ex7.m1.1.1.1.1.3" xref="S4.Ex7.m1.1.1.1.1.3.cmml"><mrow id="S4.Ex7.m1.1.1.1.1.3.2" xref="S4.Ex7.m1.1.1.1.1.3.2.cmml"><mi id="S4.Ex7.m1.1.1.1.1.3.2.2" xref="S4.Ex7.m1.1.1.1.1.3.2.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="S4.Ex7.m1.1.1.1.1.3.2.1" xref="S4.Ex7.m1.1.1.1.1.3.2.1.cmml">​</mo><msub id="S4.Ex7.m1.1.1.1.1.3.2.3" xref="S4.Ex7.m1.1.1.1.1.3.2.3.cmml"><mi id="S4.Ex7.m1.1.1.1.1.3.2.3.2" xref="S4.Ex7.m1.1.1.1.1.3.2.3.2.cmml">t</mi><mi id="S4.Ex7.m1.1.1.1.1.3.2.3.3" xref="S4.Ex7.m1.1.1.1.1.3.2.3.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S4.Ex7.m1.1.1.1.1.3.2.1a" xref="S4.Ex7.m1.1.1.1.1.3.2.1.cmml">​</mo><mrow id="S4.Ex7.m1.1.1.1.1.3.2.4" xref="S4.Ex7.m1.1.1.1.1.3.2.4.cmml"><mstyle displaystyle="true" id="S4.Ex7.m1.1.1.1.1.3.2.4.1" xref="S4.Ex7.m1.1.1.1.1.3.2.4.1.cmml"><munderover id="S4.Ex7.m1.1.1.1.1.3.2.4.1a" xref="S4.Ex7.m1.1.1.1.1.3.2.4.1.cmml"><mo movablelimits="false" id="S4.Ex7.m1.1.1.1.1.3.2.4.1.2.2" xref="S4.Ex7.m1.1.1.1.1.3.2.4.1.2.2.cmml">∑</mo><mrow id="S4.Ex7.m1.1.1.1.1.3.2.4.1.2.3" xref="S4.Ex7.m1.1.1.1.1.3.2.4.1.2.3.cmml"><mi id="S4.Ex7.m1.1.1.1.1.3.2.4.1.2.3.2" xref="S4.Ex7.m1.1.1.1.1.3.2.4.1.2.3.2.cmml">j</mi><mo id="S4.Ex7.m1.1.1.1.1.3.2.4.1.2.3.1" xref="S4.Ex7.m1.1.1.1.1.3.2.4.1.2.3.1.cmml">=</mo><mn id="S4.Ex7.m1.1.1.1.1.3.2.4.1.2.3.3" xref="S4.Ex7.m1.1.1.1.1.3.2.4.1.2.3.3.cmml">1</mn></mrow><mi id="S4.Ex7.m1.1.1.1.1.3.2.4.1.3" xref="S4.Ex7.m1.1.1.1.1.3.2.4.1.3.cmml">L</mi></munderover></mstyle><mrow id="S4.Ex7.m1.1.1.1.1.3.2.4.2" xref="S4.Ex7.m1.1.1.1.1.3.2.4.2.cmml"><msub id="S4.Ex7.m1.1.1.1.1.3.2.4.2.2" xref="S4.Ex7.m1.1.1.1.1.3.2.4.2.2.cmml"><mi id="S4.Ex7.m1.1.1.1.1.3.2.4.2.2.2" xref="S4.Ex7.m1.1.1.1.1.3.2.4.2.2.2.cmml">x</mi><mrow id="S4.Ex7.m1.1.1.1.1.3.2.4.2.2.3" xref="S4.Ex7.m1.1.1.1.1.3.2.4.2.2.3.cmml"><mi id="S4.Ex7.m1.1.1.1.1.3.2.4.2.2.3.2" xref="S4.Ex7.m1.1.1.1.1.3.2.4.2.2.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.Ex7.m1.1.1.1.1.3.2.4.2.2.3.1" xref="S4.Ex7.m1.1.1.1.1.3.2.4.2.2.3.1.cmml">​</mo><mi id="S4.Ex7.m1.1.1.1.1.3.2.4.2.2.3.3" xref="S4.Ex7.m1.1.1.1.1.3.2.4.2.2.3.3.cmml">j</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S4.Ex7.m1.1.1.1.1.3.2.4.2.1" xref="S4.Ex7.m1.1.1.1.1.3.2.4.2.1.cmml">​</mo><mi id="S4.Ex7.m1.1.1.1.1.3.2.4.2.3" xref="S4.Ex7.m1.1.1.1.1.3.2.4.2.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S4.Ex7.m1.1.1.1.1.3.2.4.2.1a" xref="S4.Ex7.m1.1.1.1.1.3.2.4.2.1.cmml">​</mo><msub id="S4.Ex7.m1.1.1.1.1.3.2.4.2.4" xref="S4.Ex7.m1.1.1.1.1.3.2.4.2.4.cmml"><mi id="S4.Ex7.m1.1.1.1.1.3.2.4.2.4.2" xref="S4.Ex7.m1.1.1.1.1.3.2.4.2.4.2.cmml">f</mi><mi id="S4.Ex7.m1.1.1.1.1.3.2.4.2.4.3" xref="S4.Ex7.m1.1.1.1.1.3.2.4.2.4.3.cmml">j</mi></msub></mrow></mrow></mrow><mo id="S4.Ex7.m1.1.1.1.1.3.1" xref="S4.Ex7.m1.1.1.1.1.3.1.cmml">+</mo><mrow id="S4.Ex7.m1.1.1.1.1.3.3" xref="S4.Ex7.m1.1.1.1.1.3.3.cmml"><mi id="S4.Ex7.m1.1.1.1.1.3.3.2" xref="S4.Ex7.m1.1.1.1.1.3.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.Ex7.m1.1.1.1.1.3.3.1" xref="S4.Ex7.m1.1.1.1.1.3.3.1.cmml">​</mo><msub id="S4.Ex7.m1.1.1.1.1.3.3.3" xref="S4.Ex7.m1.1.1.1.1.3.3.3.cmml"><mi id="S4.Ex7.m1.1.1.1.1.3.3.3.2" xref="S4.Ex7.m1.1.1.1.1.3.3.3.2.cmml">t</mi><mi id="S4.Ex7.m1.1.1.1.1.3.3.3.3" xref="S4.Ex7.m1.1.1.1.1.3.3.3.3.cmml">i</mi></msub></mrow></mrow></mrow><mo id="S4.Ex7.m1.1.1.1.2" xref="S4.Ex7.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.Ex7.m1.1b"><apply id="S4.Ex7.m1.1.1.1.1.cmml" xref="S4.Ex7.m1.1.1.1"><geq id="S4.Ex7.m1.1.1.1.1.1.cmml" xref="S4.Ex7.m1.1.1.1.1.1"></geq><ci id="S4.Ex7.m1.1.1.1.1.2.cmml" xref="S4.Ex7.m1.1.1.1.1.2">𝑞</ci><apply id="S4.Ex7.m1.1.1.1.1.3.cmml" xref="S4.Ex7.m1.1.1.1.1.3"><plus id="S4.Ex7.m1.1.1.1.1.3.1.cmml" xref="S4.Ex7.m1.1.1.1.1.3.1"></plus><apply id="S4.Ex7.m1.1.1.1.1.3.2.cmml" xref="S4.Ex7.m1.1.1.1.1.3.2"><times id="S4.Ex7.m1.1.1.1.1.3.2.1.cmml" xref="S4.Ex7.m1.1.1.1.1.3.2.1"></times><ci id="S4.Ex7.m1.1.1.1.1.3.2.2.cmml" xref="S4.Ex7.m1.1.1.1.1.3.2.2">𝑑</ci><apply id="S4.Ex7.m1.1.1.1.1.3.2.3.cmml" xref="S4.Ex7.m1.1.1.1.1.3.2.3"><csymbol cd="ambiguous" id="S4.Ex7.m1.1.1.1.1.3.2.3.1.cmml" xref="S4.Ex7.m1.1.1.1.1.3.2.3">subscript</csymbol><ci id="S4.Ex7.m1.1.1.1.1.3.2.3.2.cmml" xref="S4.Ex7.m1.1.1.1.1.3.2.3.2">𝑡</ci><ci id="S4.Ex7.m1.1.1.1.1.3.2.3.3.cmml" xref="S4.Ex7.m1.1.1.1.1.3.2.3.3">𝑖</ci></apply><apply id="S4.Ex7.m1.1.1.1.1.3.2.4.cmml" xref="S4.Ex7.m1.1.1.1.1.3.2.4"><apply id="S4.Ex7.m1.1.1.1.1.3.2.4.1.cmml" xref="S4.Ex7.m1.1.1.1.1.3.2.4.1"><csymbol cd="ambiguous" id="S4.Ex7.m1.1.1.1.1.3.2.4.1.1.cmml" xref="S4.Ex7.m1.1.1.1.1.3.2.4.1">superscript</csymbol><apply id="S4.Ex7.m1.1.1.1.1.3.2.4.1.2.cmml" xref="S4.Ex7.m1.1.1.1.1.3.2.4.1"><csymbol cd="ambiguous" id="S4.Ex7.m1.1.1.1.1.3.2.4.1.2.1.cmml" xref="S4.Ex7.m1.1.1.1.1.3.2.4.1">subscript</csymbol><sum id="S4.Ex7.m1.1.1.1.1.3.2.4.1.2.2.cmml" xref="S4.Ex7.m1.1.1.1.1.3.2.4.1.2.2"></sum><apply id="S4.Ex7.m1.1.1.1.1.3.2.4.1.2.3.cmml" xref="S4.Ex7.m1.1.1.1.1.3.2.4.1.2.3"><eq id="S4.Ex7.m1.1.1.1.1.3.2.4.1.2.3.1.cmml" xref="S4.Ex7.m1.1.1.1.1.3.2.4.1.2.3.1"></eq><ci id="S4.Ex7.m1.1.1.1.1.3.2.4.1.2.3.2.cmml" xref="S4.Ex7.m1.1.1.1.1.3.2.4.1.2.3.2">𝑗</ci><cn type="integer" id="S4.Ex7.m1.1.1.1.1.3.2.4.1.2.3.3.cmml" xref="S4.Ex7.m1.1.1.1.1.3.2.4.1.2.3.3">1</cn></apply></apply><ci id="S4.Ex7.m1.1.1.1.1.3.2.4.1.3.cmml" xref="S4.Ex7.m1.1.1.1.1.3.2.4.1.3">𝐿</ci></apply><apply id="S4.Ex7.m1.1.1.1.1.3.2.4.2.cmml" xref="S4.Ex7.m1.1.1.1.1.3.2.4.2"><times id="S4.Ex7.m1.1.1.1.1.3.2.4.2.1.cmml" xref="S4.Ex7.m1.1.1.1.1.3.2.4.2.1"></times><apply id="S4.Ex7.m1.1.1.1.1.3.2.4.2.2.cmml" xref="S4.Ex7.m1.1.1.1.1.3.2.4.2.2"><csymbol cd="ambiguous" id="S4.Ex7.m1.1.1.1.1.3.2.4.2.2.1.cmml" xref="S4.Ex7.m1.1.1.1.1.3.2.4.2.2">subscript</csymbol><ci id="S4.Ex7.m1.1.1.1.1.3.2.4.2.2.2.cmml" xref="S4.Ex7.m1.1.1.1.1.3.2.4.2.2.2">𝑥</ci><apply id="S4.Ex7.m1.1.1.1.1.3.2.4.2.2.3.cmml" xref="S4.Ex7.m1.1.1.1.1.3.2.4.2.2.3"><times id="S4.Ex7.m1.1.1.1.1.3.2.4.2.2.3.1.cmml" xref="S4.Ex7.m1.1.1.1.1.3.2.4.2.2.3.1"></times><ci id="S4.Ex7.m1.1.1.1.1.3.2.4.2.2.3.2.cmml" xref="S4.Ex7.m1.1.1.1.1.3.2.4.2.2.3.2">𝑖</ci><ci id="S4.Ex7.m1.1.1.1.1.3.2.4.2.2.3.3.cmml" xref="S4.Ex7.m1.1.1.1.1.3.2.4.2.2.3.3">𝑗</ci></apply></apply><ci id="S4.Ex7.m1.1.1.1.1.3.2.4.2.3.cmml" xref="S4.Ex7.m1.1.1.1.1.3.2.4.2.3">𝑙</ci><apply id="S4.Ex7.m1.1.1.1.1.3.2.4.2.4.cmml" xref="S4.Ex7.m1.1.1.1.1.3.2.4.2.4"><csymbol cd="ambiguous" id="S4.Ex7.m1.1.1.1.1.3.2.4.2.4.1.cmml" xref="S4.Ex7.m1.1.1.1.1.3.2.4.2.4">subscript</csymbol><ci id="S4.Ex7.m1.1.1.1.1.3.2.4.2.4.2.cmml" xref="S4.Ex7.m1.1.1.1.1.3.2.4.2.4.2">𝑓</ci><ci id="S4.Ex7.m1.1.1.1.1.3.2.4.2.4.3.cmml" xref="S4.Ex7.m1.1.1.1.1.3.2.4.2.4.3">𝑗</ci></apply></apply></apply></apply><apply id="S4.Ex7.m1.1.1.1.1.3.3.cmml" xref="S4.Ex7.m1.1.1.1.1.3.3"><times id="S4.Ex7.m1.1.1.1.1.3.3.1.cmml" xref="S4.Ex7.m1.1.1.1.1.3.3.1"></times><ci id="S4.Ex7.m1.1.1.1.1.3.3.2.cmml" xref="S4.Ex7.m1.1.1.1.1.3.3.2">𝑐</ci><apply id="S4.Ex7.m1.1.1.1.1.3.3.3.cmml" xref="S4.Ex7.m1.1.1.1.1.3.3.3"><csymbol cd="ambiguous" id="S4.Ex7.m1.1.1.1.1.3.3.3.1.cmml" xref="S4.Ex7.m1.1.1.1.1.3.3.3">subscript</csymbol><ci id="S4.Ex7.m1.1.1.1.1.3.3.3.2.cmml" xref="S4.Ex7.m1.1.1.1.1.3.3.3.2">𝑡</ci><ci id="S4.Ex7.m1.1.1.1.1.3.3.3.3.cmml" xref="S4.Ex7.m1.1.1.1.1.3.3.3.3">𝑖</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.Ex7.m1.1c">\displaystyle q\geq dt_{i}\sum_{j=1}^{L}x_{ij}lf_{j}+ct_{i},</annotation></semantics></math></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S4.Ex7.m3.1" class="ltx_Math" alttext="\displaystyle\forall i\in D" display="inline"><semantics id="S4.Ex7.m3.1a"><mrow id="S4.Ex7.m3.1.1" xref="S4.Ex7.m3.1.1.cmml"><mrow id="S4.Ex7.m3.1.1.2" xref="S4.Ex7.m3.1.1.2.cmml"><mo rspace="0.167em" id="S4.Ex7.m3.1.1.2.1" xref="S4.Ex7.m3.1.1.2.1.cmml">∀</mo><mi id="S4.Ex7.m3.1.1.2.2" xref="S4.Ex7.m3.1.1.2.2.cmml">i</mi></mrow><mo id="S4.Ex7.m3.1.1.1" xref="S4.Ex7.m3.1.1.1.cmml">∈</mo><mi id="S4.Ex7.m3.1.1.3" xref="S4.Ex7.m3.1.1.3.cmml">D</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.Ex7.m3.1b"><apply id="S4.Ex7.m3.1.1.cmml" xref="S4.Ex7.m3.1.1"><in id="S4.Ex7.m3.1.1.1.cmml" xref="S4.Ex7.m3.1.1.1"></in><apply id="S4.Ex7.m3.1.1.2.cmml" xref="S4.Ex7.m3.1.1.2"><csymbol cd="latexml" id="S4.Ex7.m3.1.1.2.1.cmml" xref="S4.Ex7.m3.1.1.2.1">for-all</csymbol><ci id="S4.Ex7.m3.1.1.2.2.cmml" xref="S4.Ex7.m3.1.1.2.2">𝑖</ci></apply><ci id="S4.Ex7.m3.1.1.3.cmml" xref="S4.Ex7.m3.1.1.3">𝐷</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.Ex7.m3.1c">\displaystyle\forall i\in D</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="S4.Ex8"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S4.Ex8.m1.3" class="ltx_Math" alttext="\displaystyle x\text{ is binary},y,z\text{ are non-zero integer}" display="inline"><semantics id="S4.Ex8.m1.3a"><mrow id="S4.Ex8.m1.3.3.2" xref="S4.Ex8.m1.3.3.3.cmml"><mrow id="S4.Ex8.m1.2.2.1.1" xref="S4.Ex8.m1.2.2.1.1.cmml"><mi id="S4.Ex8.m1.2.2.1.1.2" xref="S4.Ex8.m1.2.2.1.1.2.cmml">x</mi><mo lspace="0em" rspace="0em" id="S4.Ex8.m1.2.2.1.1.1" xref="S4.Ex8.m1.2.2.1.1.1.cmml">​</mo><mtext id="S4.Ex8.m1.2.2.1.1.3" xref="S4.Ex8.m1.2.2.1.1.3a.cmml"> is binary</mtext></mrow><mo id="S4.Ex8.m1.3.3.2.3" xref="S4.Ex8.m1.3.3.3.cmml">,</mo><mi id="S4.Ex8.m1.1.1" xref="S4.Ex8.m1.1.1.cmml">y</mi><mo id="S4.Ex8.m1.3.3.2.4" xref="S4.Ex8.m1.3.3.3.cmml">,</mo><mrow id="S4.Ex8.m1.3.3.2.2" xref="S4.Ex8.m1.3.3.2.2.cmml"><mi id="S4.Ex8.m1.3.3.2.2.2" xref="S4.Ex8.m1.3.3.2.2.2.cmml">z</mi><mo lspace="0em" rspace="0em" id="S4.Ex8.m1.3.3.2.2.1" xref="S4.Ex8.m1.3.3.2.2.1.cmml">​</mo><mtext id="S4.Ex8.m1.3.3.2.2.3" xref="S4.Ex8.m1.3.3.2.2.3a.cmml"> are non-zero integer</mtext></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.Ex8.m1.3b"><list id="S4.Ex8.m1.3.3.3.cmml" xref="S4.Ex8.m1.3.3.2"><apply id="S4.Ex8.m1.2.2.1.1.cmml" xref="S4.Ex8.m1.2.2.1.1"><times id="S4.Ex8.m1.2.2.1.1.1.cmml" xref="S4.Ex8.m1.2.2.1.1.1"></times><ci id="S4.Ex8.m1.2.2.1.1.2.cmml" xref="S4.Ex8.m1.2.2.1.1.2">𝑥</ci><ci id="S4.Ex8.m1.2.2.1.1.3a.cmml" xref="S4.Ex8.m1.2.2.1.1.3"><mtext id="S4.Ex8.m1.2.2.1.1.3.cmml" xref="S4.Ex8.m1.2.2.1.1.3"> is binary</mtext></ci></apply><ci id="S4.Ex8.m1.1.1.cmml" xref="S4.Ex8.m1.1.1">𝑦</ci><apply id="S4.Ex8.m1.3.3.2.2.cmml" xref="S4.Ex8.m1.3.3.2.2"><times id="S4.Ex8.m1.3.3.2.2.1.cmml" xref="S4.Ex8.m1.3.3.2.2.1"></times><ci id="S4.Ex8.m1.3.3.2.2.2.cmml" xref="S4.Ex8.m1.3.3.2.2.2">𝑧</ci><ci id="S4.Ex8.m1.3.3.2.2.3a.cmml" xref="S4.Ex8.m1.3.3.2.2.3"><mtext id="S4.Ex8.m1.3.3.2.2.3.cmml" xref="S4.Ex8.m1.3.3.2.2.3"> are non-zero integer</mtext></ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S4.Ex8.m1.3c">\displaystyle x\text{ is binary},y,z\text{ are non-zero integer}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright" colspan="3"></td>
</tr></tbody>
</table>
</div>
<div id="S4.SS3.p3" class="ltx_para">
<p id="S4.SS3.p3.1" class="ltx_p">Since it is a Mixed Integer Programming problem, we cannot get an optimal solution in polynomial time. With the increasing number of model layers as well as devices, the cost of obtaining the optimal solution is unacceptable. Therefore, we proposed a heuristic allocation approach.</p>
</div>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS4.5.1.1" class="ltx_text">IV-D</span> </span><span id="S4.SS4.6.2" class="ltx_text ltx_font_italic">Heuristic Allocation</span>
</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p">For NP-hard problems, we can construct a heuristic algorithm to quickly obtain a feasible solution within an acceptable gap. In this paper, we designed a heuristic allocation algorithm that is only applicable in this problem, and we found in the experiment that the gap between the heuristic allocation and the optimal allocation is merely 10% in the worst case.</p>
</div>
<div id="S4.SS4.p2" class="ltx_para">
<p id="S4.SS4.p2.1" class="ltx_p">Our goal is to allocate layers such that each device has a similar workload. To achieve this goal, there are two conditions. Firstly, the layers allocated do not occupy more memory than the device memory limit. This is to make sure that training can at least be run even though the load is not balanced. Secondly, the workload on the devices should be similar to avoid computation bottlenecks and speed up training. Thus, we split the allocation into two sub-stages which are coarse allocation and workload fine-tuning.</p>
</div>
<div id="S4.SS4.p3" class="ltx_para">
<p id="S4.SS4.p3.14" class="ltx_p">From the previous benchmarking stage, we have gathered information about the devices and the model. Suppose we have <math id="S4.SS4.p3.1.m1.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S4.SS4.p3.1.m1.1a"><mi id="S4.SS4.p3.1.m1.1.1" xref="S4.SS4.p3.1.m1.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p3.1.m1.1b"><ci id="S4.SS4.p3.1.m1.1.1.cmml" xref="S4.SS4.p3.1.m1.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p3.1.m1.1c">L</annotation></semantics></math> layers and <math id="S4.SS4.p3.2.m2.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S4.SS4.p3.2.m2.1a"><mi id="S4.SS4.p3.2.m2.1.1" xref="S4.SS4.p3.2.m2.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p3.2.m2.1b"><ci id="S4.SS4.p3.2.m2.1.1.cmml" xref="S4.SS4.p3.2.m2.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p3.2.m2.1c">D</annotation></semantics></math> devices in the federated learning network, we let <math id="S4.SS4.p3.3.m3.1" class="ltx_Math" alttext="dt" display="inline"><semantics id="S4.SS4.p3.3.m3.1a"><mrow id="S4.SS4.p3.3.m3.1.1" xref="S4.SS4.p3.3.m3.1.1.cmml"><mi id="S4.SS4.p3.3.m3.1.1.2" xref="S4.SS4.p3.3.m3.1.1.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="S4.SS4.p3.3.m3.1.1.1" xref="S4.SS4.p3.3.m3.1.1.1.cmml">​</mo><mi id="S4.SS4.p3.3.m3.1.1.3" xref="S4.SS4.p3.3.m3.1.1.3.cmml">t</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p3.3.m3.1b"><apply id="S4.SS4.p3.3.m3.1.1.cmml" xref="S4.SS4.p3.3.m3.1.1"><times id="S4.SS4.p3.3.m3.1.1.1.cmml" xref="S4.SS4.p3.3.m3.1.1.1"></times><ci id="S4.SS4.p3.3.m3.1.1.2.cmml" xref="S4.SS4.p3.3.m3.1.1.2">𝑑</ci><ci id="S4.SS4.p3.3.m3.1.1.3.cmml" xref="S4.SS4.p3.3.m3.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p3.3.m3.1c">dt</annotation></semantics></math>, <math id="S4.SS4.p3.4.m4.1" class="ltx_Math" alttext="dm" display="inline"><semantics id="S4.SS4.p3.4.m4.1a"><mrow id="S4.SS4.p3.4.m4.1.1" xref="S4.SS4.p3.4.m4.1.1.cmml"><mi id="S4.SS4.p3.4.m4.1.1.2" xref="S4.SS4.p3.4.m4.1.1.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="S4.SS4.p3.4.m4.1.1.1" xref="S4.SS4.p3.4.m4.1.1.1.cmml">​</mo><mi id="S4.SS4.p3.4.m4.1.1.3" xref="S4.SS4.p3.4.m4.1.1.3.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p3.4.m4.1b"><apply id="S4.SS4.p3.4.m4.1.1.cmml" xref="S4.SS4.p3.4.m4.1.1"><times id="S4.SS4.p3.4.m4.1.1.1.cmml" xref="S4.SS4.p3.4.m4.1.1.1"></times><ci id="S4.SS4.p3.4.m4.1.1.2.cmml" xref="S4.SS4.p3.4.m4.1.1.2">𝑑</ci><ci id="S4.SS4.p3.4.m4.1.1.3.cmml" xref="S4.SS4.p3.4.m4.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p3.4.m4.1c">dm</annotation></semantics></math> and <math id="S4.SS4.p3.5.m5.1" class="ltx_Math" alttext="ct" display="inline"><semantics id="S4.SS4.p3.5.m5.1a"><mrow id="S4.SS4.p3.5.m5.1.1" xref="S4.SS4.p3.5.m5.1.1.cmml"><mi id="S4.SS4.p3.5.m5.1.1.2" xref="S4.SS4.p3.5.m5.1.1.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.SS4.p3.5.m5.1.1.1" xref="S4.SS4.p3.5.m5.1.1.1.cmml">​</mo><mi id="S4.SS4.p3.5.m5.1.1.3" xref="S4.SS4.p3.5.m5.1.1.3.cmml">t</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p3.5.m5.1b"><apply id="S4.SS4.p3.5.m5.1.1.cmml" xref="S4.SS4.p3.5.m5.1.1"><times id="S4.SS4.p3.5.m5.1.1.1.cmml" xref="S4.SS4.p3.5.m5.1.1.1"></times><ci id="S4.SS4.p3.5.m5.1.1.2.cmml" xref="S4.SS4.p3.5.m5.1.1.2">𝑐</ci><ci id="S4.SS4.p3.5.m5.1.1.3.cmml" xref="S4.SS4.p3.5.m5.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p3.5.m5.1c">ct</annotation></semantics></math> be arrays of length <math id="S4.SS4.p3.6.m6.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S4.SS4.p3.6.m6.1a"><mi id="S4.SS4.p3.6.m6.1.1" xref="S4.SS4.p3.6.m6.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p3.6.m6.1b"><ci id="S4.SS4.p3.6.m6.1.1.cmml" xref="S4.SS4.p3.6.m6.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p3.6.m6.1c">D</annotation></semantics></math> where <math id="S4.SS4.p3.7.m7.1" class="ltx_Math" alttext="dt" display="inline"><semantics id="S4.SS4.p3.7.m7.1a"><mrow id="S4.SS4.p3.7.m7.1.1" xref="S4.SS4.p3.7.m7.1.1.cmml"><mi id="S4.SS4.p3.7.m7.1.1.2" xref="S4.SS4.p3.7.m7.1.1.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="S4.SS4.p3.7.m7.1.1.1" xref="S4.SS4.p3.7.m7.1.1.1.cmml">​</mo><mi id="S4.SS4.p3.7.m7.1.1.3" xref="S4.SS4.p3.7.m7.1.1.3.cmml">t</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p3.7.m7.1b"><apply id="S4.SS4.p3.7.m7.1.1.cmml" xref="S4.SS4.p3.7.m7.1.1"><times id="S4.SS4.p3.7.m7.1.1.1.cmml" xref="S4.SS4.p3.7.m7.1.1.1"></times><ci id="S4.SS4.p3.7.m7.1.1.2.cmml" xref="S4.SS4.p3.7.m7.1.1.2">𝑑</ci><ci id="S4.SS4.p3.7.m7.1.1.3.cmml" xref="S4.SS4.p3.7.m7.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p3.7.m7.1c">dt</annotation></semantics></math> stores the time ratio for the benchmarking test, <math id="S4.SS4.p3.8.m8.1" class="ltx_Math" alttext="dm" display="inline"><semantics id="S4.SS4.p3.8.m8.1a"><mrow id="S4.SS4.p3.8.m8.1.1" xref="S4.SS4.p3.8.m8.1.1.cmml"><mi id="S4.SS4.p3.8.m8.1.1.2" xref="S4.SS4.p3.8.m8.1.1.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="S4.SS4.p3.8.m8.1.1.1" xref="S4.SS4.p3.8.m8.1.1.1.cmml">​</mo><mi id="S4.SS4.p3.8.m8.1.1.3" xref="S4.SS4.p3.8.m8.1.1.3.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p3.8.m8.1b"><apply id="S4.SS4.p3.8.m8.1.1.cmml" xref="S4.SS4.p3.8.m8.1.1"><times id="S4.SS4.p3.8.m8.1.1.1.cmml" xref="S4.SS4.p3.8.m8.1.1.1"></times><ci id="S4.SS4.p3.8.m8.1.1.2.cmml" xref="S4.SS4.p3.8.m8.1.1.2">𝑑</ci><ci id="S4.SS4.p3.8.m8.1.1.3.cmml" xref="S4.SS4.p3.8.m8.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p3.8.m8.1c">dm</annotation></semantics></math> stores the memory available on the devices and <math id="S4.SS4.p3.9.m9.1" class="ltx_Math" alttext="ct" display="inline"><semantics id="S4.SS4.p3.9.m9.1a"><mrow id="S4.SS4.p3.9.m9.1.1" xref="S4.SS4.p3.9.m9.1.1.cmml"><mi id="S4.SS4.p3.9.m9.1.1.2" xref="S4.SS4.p3.9.m9.1.1.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.SS4.p3.9.m9.1.1.1" xref="S4.SS4.p3.9.m9.1.1.1.cmml">​</mo><mi id="S4.SS4.p3.9.m9.1.1.3" xref="S4.SS4.p3.9.m9.1.1.3.cmml">t</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p3.9.m9.1b"><apply id="S4.SS4.p3.9.m9.1.1.cmml" xref="S4.SS4.p3.9.m9.1.1"><times id="S4.SS4.p3.9.m9.1.1.1.cmml" xref="S4.SS4.p3.9.m9.1.1.1"></times><ci id="S4.SS4.p3.9.m9.1.1.2.cmml" xref="S4.SS4.p3.9.m9.1.1.2">𝑐</ci><ci id="S4.SS4.p3.9.m9.1.1.3.cmml" xref="S4.SS4.p3.9.m9.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p3.9.m9.1c">ct</annotation></semantics></math> stores the communication time of devices. The <math id="S4.SS4.p3.10.m10.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S4.SS4.p3.10.m10.1a"><mi id="S4.SS4.p3.10.m10.1.1" xref="S4.SS4.p3.10.m10.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p3.10.m10.1b"><ci id="S4.SS4.p3.10.m10.1.1.cmml" xref="S4.SS4.p3.10.m10.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p3.10.m10.1c">i</annotation></semantics></math>-th element in these arrays refers to the time result or memory of the <math id="S4.SS4.p3.11.m11.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S4.SS4.p3.11.m11.1a"><mi id="S4.SS4.p3.11.m11.1.1" xref="S4.SS4.p3.11.m11.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p3.11.m11.1b"><ci id="S4.SS4.p3.11.m11.1.1.cmml" xref="S4.SS4.p3.11.m11.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p3.11.m11.1c">i</annotation></semantics></math>-th device. <math id="S4.SS4.p3.12.m12.1" class="ltx_Math" alttext="lf" display="inline"><semantics id="S4.SS4.p3.12.m12.1a"><mrow id="S4.SS4.p3.12.m12.1.1" xref="S4.SS4.p3.12.m12.1.1.cmml"><mi id="S4.SS4.p3.12.m12.1.1.2" xref="S4.SS4.p3.12.m12.1.1.2.cmml">l</mi><mo lspace="0em" rspace="0em" id="S4.SS4.p3.12.m12.1.1.1" xref="S4.SS4.p3.12.m12.1.1.1.cmml">​</mo><mi id="S4.SS4.p3.12.m12.1.1.3" xref="S4.SS4.p3.12.m12.1.1.3.cmml">f</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p3.12.m12.1b"><apply id="S4.SS4.p3.12.m12.1.1.cmml" xref="S4.SS4.p3.12.m12.1.1"><times id="S4.SS4.p3.12.m12.1.1.1.cmml" xref="S4.SS4.p3.12.m12.1.1.1"></times><ci id="S4.SS4.p3.12.m12.1.1.2.cmml" xref="S4.SS4.p3.12.m12.1.1.2">𝑙</ci><ci id="S4.SS4.p3.12.m12.1.1.3.cmml" xref="S4.SS4.p3.12.m12.1.1.3">𝑓</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p3.12.m12.1c">lf</annotation></semantics></math> and <math id="S4.SS4.p3.13.m13.1" class="ltx_Math" alttext="lm" display="inline"><semantics id="S4.SS4.p3.13.m13.1a"><mrow id="S4.SS4.p3.13.m13.1.1" xref="S4.SS4.p3.13.m13.1.1.cmml"><mi id="S4.SS4.p3.13.m13.1.1.2" xref="S4.SS4.p3.13.m13.1.1.2.cmml">l</mi><mo lspace="0em" rspace="0em" id="S4.SS4.p3.13.m13.1.1.1" xref="S4.SS4.p3.13.m13.1.1.1.cmml">​</mo><mi id="S4.SS4.p3.13.m13.1.1.3" xref="S4.SS4.p3.13.m13.1.1.3.cmml">m</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p3.13.m13.1b"><apply id="S4.SS4.p3.13.m13.1.1.cmml" xref="S4.SS4.p3.13.m13.1.1"><times id="S4.SS4.p3.13.m13.1.1.1.cmml" xref="S4.SS4.p3.13.m13.1.1.1"></times><ci id="S4.SS4.p3.13.m13.1.1.2.cmml" xref="S4.SS4.p3.13.m13.1.1.2">𝑙</ci><ci id="S4.SS4.p3.13.m13.1.1.3.cmml" xref="S4.SS4.p3.13.m13.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p3.13.m13.1c">lm</annotation></semantics></math> are arrays of length <math id="S4.SS4.p3.14.m14.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S4.SS4.p3.14.m14.1a"><mi id="S4.SS4.p3.14.m14.1.1" xref="S4.SS4.p3.14.m14.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p3.14.m14.1b"><ci id="S4.SS4.p3.14.m14.1.1.cmml" xref="S4.SS4.p3.14.m14.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p3.14.m14.1c">L</annotation></semantics></math> which stores the number of FLOPs and required memory of each layer.</p>
</div>
<div id="S4.SS4.p4" class="ltx_para">
<p id="S4.SS4.p4.4" class="ltx_p">In coarse allocation stage as shown in Algorithm <a href="#algorithm1" title="In IV-D Heuristic Allocation ‣ IV Geo-distributed Computing Optimization ‣ Sky Computing: Accelerating Geo-distributed Computing in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, we firstly initialize a partition index <math id="S4.SS4.p4.1.m1.1" class="ltx_Math" alttext="pi" display="inline"><semantics id="S4.SS4.p4.1.m1.1a"><mrow id="S4.SS4.p4.1.m1.1.1" xref="S4.SS4.p4.1.m1.1.1.cmml"><mi id="S4.SS4.p4.1.m1.1.1.2" xref="S4.SS4.p4.1.m1.1.1.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S4.SS4.p4.1.m1.1.1.1" xref="S4.SS4.p4.1.m1.1.1.1.cmml">​</mo><mi id="S4.SS4.p4.1.m1.1.1.3" xref="S4.SS4.p4.1.m1.1.1.3.cmml">i</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p4.1.m1.1b"><apply id="S4.SS4.p4.1.m1.1.1.cmml" xref="S4.SS4.p4.1.m1.1.1"><times id="S4.SS4.p4.1.m1.1.1.1.cmml" xref="S4.SS4.p4.1.m1.1.1.1"></times><ci id="S4.SS4.p4.1.m1.1.1.2.cmml" xref="S4.SS4.p4.1.m1.1.1.2">𝑝</ci><ci id="S4.SS4.p4.1.m1.1.1.3.cmml" xref="S4.SS4.p4.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p4.1.m1.1c">pi</annotation></semantics></math>. The partition index <math id="S4.SS4.p4.2.m2.1" class="ltx_Math" alttext="pi" display="inline"><semantics id="S4.SS4.p4.2.m2.1a"><mrow id="S4.SS4.p4.2.m2.1.1" xref="S4.SS4.p4.2.m2.1.1.cmml"><mi id="S4.SS4.p4.2.m2.1.1.2" xref="S4.SS4.p4.2.m2.1.1.2.cmml">p</mi><mo lspace="0em" rspace="0em" id="S4.SS4.p4.2.m2.1.1.1" xref="S4.SS4.p4.2.m2.1.1.1.cmml">​</mo><mi id="S4.SS4.p4.2.m2.1.1.3" xref="S4.SS4.p4.2.m2.1.1.3.cmml">i</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p4.2.m2.1b"><apply id="S4.SS4.p4.2.m2.1.1.cmml" xref="S4.SS4.p4.2.m2.1.1"><times id="S4.SS4.p4.2.m2.1.1.1.cmml" xref="S4.SS4.p4.2.m2.1.1.1"></times><ci id="S4.SS4.p4.2.m2.1.1.2.cmml" xref="S4.SS4.p4.2.m2.1.1.2">𝑝</ci><ci id="S4.SS4.p4.2.m2.1.1.3.cmml" xref="S4.SS4.p4.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p4.2.m2.1c">pi</annotation></semantics></math> is an array of integers of length <math id="S4.SS4.p4.3.m3.1" class="ltx_Math" alttext="D+1" display="inline"><semantics id="S4.SS4.p4.3.m3.1a"><mrow id="S4.SS4.p4.3.m3.1.1" xref="S4.SS4.p4.3.m3.1.1.cmml"><mi id="S4.SS4.p4.3.m3.1.1.2" xref="S4.SS4.p4.3.m3.1.1.2.cmml">D</mi><mo id="S4.SS4.p4.3.m3.1.1.1" xref="S4.SS4.p4.3.m3.1.1.1.cmml">+</mo><mn id="S4.SS4.p4.3.m3.1.1.3" xref="S4.SS4.p4.3.m3.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p4.3.m3.1b"><apply id="S4.SS4.p4.3.m3.1.1.cmml" xref="S4.SS4.p4.3.m3.1.1"><plus id="S4.SS4.p4.3.m3.1.1.1.cmml" xref="S4.SS4.p4.3.m3.1.1.1"></plus><ci id="S4.SS4.p4.3.m3.1.1.2.cmml" xref="S4.SS4.p4.3.m3.1.1.2">𝐷</ci><cn type="integer" id="S4.SS4.p4.3.m3.1.1.3.cmml" xref="S4.SS4.p4.3.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p4.3.m3.1c">D+1</annotation></semantics></math>. The element in the partition index refers to the index of the layer in the model. Thus, the partition index specifies the range of layers allocated to each device as the <math id="S4.SS4.p4.4.m4.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S4.SS4.p4.4.m4.1a"><mi id="S4.SS4.p4.4.m4.1.1" xref="S4.SS4.p4.4.m4.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p4.4.m4.1b"><ci id="S4.SS4.p4.4.m4.1.1.cmml" xref="S4.SS4.p4.4.m4.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p4.4.m4.1c">i</annotation></semantics></math>-th device will be allocated with <span id="S4.SS4.p4.4.1" class="ltx_text ltx_font_typewriter">pi[i]</span> to <span id="S4.SS4.p4.4.2" class="ltx_text ltx_font_typewriter">pi[i+1]-1</span> layers. The partition index is initialized such that each device has the same number of layers. The layer allocation is then turned into a partitioning problem. We need to change the number of layers on each device to fulfill the memory requirement such that all devices have sufficient memory for the layers allocated. The strategy in the coarse allocation stage is that a device should take in more layers if it has enough memory and gives away some layers when the memory limit is exceeded. At the same time, it needs to ensure that each device has at least one layer. Our algorithm will iteratively update the partition index until the memory requirements are fulfilled on all devices. At this stage, we should be able to ensure training can be run successfully without concerns about out-of-memory problems.</p>
</div>
<figure id="algorithm1" class="ltx_float ltx_algorithm">
<div id="algorithm1.15" class="ltx_listing ltx_lst_numbers_left ltx_listing">
<div id="algorithm1.15.16" class="ltx_listingline">
<span id="algorithm1.15.16.1" class="ltx_text"><span id="algorithm1.15.16.1.1" class="ltx_text ltx_font_bold">Result:</span> </span>pi 
</div>
<div id="algorithm1.15.17" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">1</span>
// dt: device time, dm: device memory 
</div>
<div id="algorithm1.15.18" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">2</span>
dt, dm, ct = device_benchmark();
</div>
<div id="algorithm1.15.19" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">3</span>

</div>
<div id="algorithm1.15.20" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">4</span>// lf: layer flops, lm: layer memory 
</div>
<div id="algorithm1.15.21" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">5</span>
lf, lm = model_benchmark();
</div>
<div id="algorithm1.15.22" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">6</span>

</div>
<div id="algorithm1.15.23" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">7</span>// pi: partition index 
</div>
<div id="algorithm1.15.24" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">8</span>
pi = initialize_partition_index();
</div>
<div id="algorithm1.15.25" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">9</span>

</div>
<div id="algorithm1.15.26" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">10</span>// am: allocated memory on devices 
</div>
<div id="algorithm1.15.27" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">11</span>
am = compute_allocated_memory(lm, pi);
</div>
<div id="algorithm1.15.28" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="algorithm1.15.28.1.1.1" class="ltx_text ltx_font_typewriter">12</span></span>

</div>
<div id="algorithm1.15.29" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">13</span><span id="algorithm1.15.29.1" class="ltx_text">
</span>
</div>
<div id="algorithm1.15.30" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">14</span><span id="algorithm1.15.30.1" class="ltx_text ltx_font_bold">while</span> <em id="algorithm1.15.30.2" class="ltx_emph ltx_font_italic">true</em> <span id="algorithm1.15.30.3" class="ltx_text ltx_font_bold">do</span> 
</div>
<div id="algorithm1.15.31" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">15</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
<span id="algorithm1.15.31.1" class="ltx_text ltx_font_bold">if</span> <em id="algorithm1.15.31.2" class="ltx_emph ltx_font_italic">is_memory_satisfied</em> <span id="algorithm1.15.31.3" class="ltx_text ltx_font_bold">then</span>
</div>
<div id="algorithm1.15.32" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">16</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
return pi;
</div>
<div id="algorithm1.15.33" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">17</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   

</div>
<div id="algorithm1.15.34" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="algorithm1.15.34.1.1.1" class="ltx_text ltx_font_typewriter">18</span></span><span id="algorithm1.15.34.2" class="ltx_text ltx_font_typewriter">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   </span>

</div>
<div id="algorithm1.15.35" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">19</span><span id="algorithm1.15.35.1" class="ltx_text">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   </span><span id="algorithm1.15.35.2" class="ltx_text">
</span>
</div>
<div id="algorithm1.2.2" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">20</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   <span id="algorithm1.2.2.3" class="ltx_text ltx_font_bold">for</span> <em id="algorithm1.2.2.2" class="ltx_emph ltx_font_italic"><math id="algorithm1.1.1.1.m1.1" class="ltx_Math" alttext="i\leftarrow 0" display="inline"><semantics id="algorithm1.1.1.1.m1.1a"><mrow id="algorithm1.1.1.1.m1.1.1" xref="algorithm1.1.1.1.m1.1.1.cmml"><mi id="algorithm1.1.1.1.m1.1.1.2" xref="algorithm1.1.1.1.m1.1.1.2.cmml">i</mi><mo stretchy="false" id="algorithm1.1.1.1.m1.1.1.1" xref="algorithm1.1.1.1.m1.1.1.1.cmml">←</mo><mn id="algorithm1.1.1.1.m1.1.1.3" xref="algorithm1.1.1.1.m1.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="algorithm1.1.1.1.m1.1b"><apply id="algorithm1.1.1.1.m1.1.1.cmml" xref="algorithm1.1.1.1.m1.1.1"><ci id="algorithm1.1.1.1.m1.1.1.1.cmml" xref="algorithm1.1.1.1.m1.1.1.1">←</ci><ci id="algorithm1.1.1.1.m1.1.1.2.cmml" xref="algorithm1.1.1.1.m1.1.1.2">𝑖</ci><cn type="integer" id="algorithm1.1.1.1.m1.1.1.3.cmml" xref="algorithm1.1.1.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.1.1.1.m1.1c">i\leftarrow 0</annotation></semantics></math> <span id="algorithm1.2.2.2.1" class="ltx_text ltx_font_bold ltx_font_upright">to</span> <math id="algorithm1.2.2.2.m2.1" class="ltx_Math" alttext="D" display="inline"><semantics id="algorithm1.2.2.2.m2.1a"><mi id="algorithm1.2.2.2.m2.1.1" xref="algorithm1.2.2.2.m2.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="algorithm1.2.2.2.m2.1b"><ci id="algorithm1.2.2.2.m2.1.1.cmml" xref="algorithm1.2.2.2.m2.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.2.2.2.m2.1c">D</annotation></semantics></math>-2</em> <span id="algorithm1.2.2.4" class="ltx_text ltx_font_bold">do</span> 
</div>
<div id="algorithm1.7.7" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">21</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
<span id="algorithm1.7.7.6" class="ltx_text ltx_font_bold">while</span> <em id="algorithm1.7.7.5" class="ltx_emph ltx_font_italic">am[<math id="algorithm1.3.3.1.m1.1" class="ltx_Math" alttext="i" display="inline"><semantics id="algorithm1.3.3.1.m1.1a"><mi id="algorithm1.3.3.1.m1.1.1" xref="algorithm1.3.3.1.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="algorithm1.3.3.1.m1.1b"><ci id="algorithm1.3.3.1.m1.1.1.cmml" xref="algorithm1.3.3.1.m1.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.3.3.1.m1.1c">i</annotation></semantics></math>] <math id="algorithm1.4.4.2.m2.1" class="ltx_Math" alttext="&gt;" display="inline"><semantics id="algorithm1.4.4.2.m2.1a"><mo id="algorithm1.4.4.2.m2.1.1" xref="algorithm1.4.4.2.m2.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="algorithm1.4.4.2.m2.1b"><gt id="algorithm1.4.4.2.m2.1.1.cmml" xref="algorithm1.4.4.2.m2.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.4.4.2.m2.1c">&gt;</annotation></semantics></math> dm[<math id="algorithm1.5.5.3.m3.1" class="ltx_Math" alttext="i" display="inline"><semantics id="algorithm1.5.5.3.m3.1a"><mi id="algorithm1.5.5.3.m3.1.1" xref="algorithm1.5.5.3.m3.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="algorithm1.5.5.3.m3.1b"><ci id="algorithm1.5.5.3.m3.1.1.cmml" xref="algorithm1.5.5.3.m3.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.5.5.3.m3.1c">i</annotation></semantics></math>] &amp;&amp; get_num_layer(pi, <math id="algorithm1.6.6.4.m4.1" class="ltx_Math" alttext="i" display="inline"><semantics id="algorithm1.6.6.4.m4.1a"><mi id="algorithm1.6.6.4.m4.1.1" xref="algorithm1.6.6.4.m4.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="algorithm1.6.6.4.m4.1b"><ci id="algorithm1.6.6.4.m4.1.1.cmml" xref="algorithm1.6.6.4.m4.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.6.6.4.m4.1c">i</annotation></semantics></math>) <math id="algorithm1.7.7.5.m5.1" class="ltx_Math" alttext="&gt;" display="inline"><semantics id="algorithm1.7.7.5.m5.1a"><mo id="algorithm1.7.7.5.m5.1.1" xref="algorithm1.7.7.5.m5.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="algorithm1.7.7.5.m5.1b"><gt id="algorithm1.7.7.5.m5.1.1.cmml" xref="algorithm1.7.7.5.m5.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.7.7.5.m5.1c">&gt;</annotation></semantics></math> 1 </em> <span id="algorithm1.7.7.7" class="ltx_text ltx_font_bold">do</span> 
</div>
<div id="algorithm1.8.8" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">22</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
pi[<math id="algorithm1.8.8.m1.1" class="ltx_Math" alttext="i" display="inline"><semantics id="algorithm1.8.8.m1.1a"><mi id="algorithm1.8.8.m1.1.1" xref="algorithm1.8.8.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="algorithm1.8.8.m1.1b"><ci id="algorithm1.8.8.m1.1.1.cmml" xref="algorithm1.8.8.m1.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.8.8.m1.1c">i</annotation></semantics></math>+1] -= 1;
</div>
<div id="algorithm1.15.36" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">23</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
update_allocated_memory();
</div>
<div id="algorithm1.15.37" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">24</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   

</div>
<div id="algorithm1.15.38" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">25</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>    end while
</div>
<div id="algorithm1.15.39" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">26</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
</div>
<div id="algorithm1.14.14" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">27</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   <span id="algorithm1.14.14.7" class="ltx_text ltx_font_bold">while</span> <em id="algorithm1.14.14.6" class="ltx_emph ltx_font_italic">dm[<math id="algorithm1.9.9.1.m1.1" class="ltx_Math" alttext="i" display="inline"><semantics id="algorithm1.9.9.1.m1.1a"><mi id="algorithm1.9.9.1.m1.1.1" xref="algorithm1.9.9.1.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="algorithm1.9.9.1.m1.1b"><ci id="algorithm1.9.9.1.m1.1.1.cmml" xref="algorithm1.9.9.1.m1.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.9.9.1.m1.1c">i</annotation></semantics></math>] <math id="algorithm1.10.10.2.m2.1" class="ltx_Math" alttext="&gt;" display="inline"><semantics id="algorithm1.10.10.2.m2.1a"><mo id="algorithm1.10.10.2.m2.1.1" xref="algorithm1.10.10.2.m2.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="algorithm1.10.10.2.m2.1b"><gt id="algorithm1.10.10.2.m2.1.1.cmml" xref="algorithm1.10.10.2.m2.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.10.10.2.m2.1c">&gt;</annotation></semantics></math> am[<math id="algorithm1.11.11.3.m3.1" class="ltx_Math" alttext="i" display="inline"><semantics id="algorithm1.11.11.3.m3.1a"><mi id="algorithm1.11.11.3.m3.1.1" xref="algorithm1.11.11.3.m3.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="algorithm1.11.11.3.m3.1b"><ci id="algorithm1.11.11.3.m3.1.1.cmml" xref="algorithm1.11.11.3.m3.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.11.11.3.m3.1c">i</annotation></semantics></math>] + lm[pi[<math id="algorithm1.12.12.4.m4.1" class="ltx_Math" alttext="i" display="inline"><semantics id="algorithm1.12.12.4.m4.1a"><mi id="algorithm1.12.12.4.m4.1.1" xref="algorithm1.12.12.4.m4.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="algorithm1.12.12.4.m4.1b"><ci id="algorithm1.12.12.4.m4.1.1.cmml" xref="algorithm1.12.12.4.m4.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.12.12.4.m4.1c">i</annotation></semantics></math>+1]] &amp;&amp; get_num_layer(pi, <math id="algorithm1.13.13.5.m5.1" class="ltx_Math" alttext="i" display="inline"><semantics id="algorithm1.13.13.5.m5.1a"><mi id="algorithm1.13.13.5.m5.1.1" xref="algorithm1.13.13.5.m5.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="algorithm1.13.13.5.m5.1b"><ci id="algorithm1.13.13.5.m5.1.1.cmml" xref="algorithm1.13.13.5.m5.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.13.13.5.m5.1c">i</annotation></semantics></math>+1) <math id="algorithm1.14.14.6.m6.1" class="ltx_Math" alttext="&gt;" display="inline"><semantics id="algorithm1.14.14.6.m6.1a"><mo id="algorithm1.14.14.6.m6.1.1" xref="algorithm1.14.14.6.m6.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="algorithm1.14.14.6.m6.1b"><gt id="algorithm1.14.14.6.m6.1.1.cmml" xref="algorithm1.14.14.6.m6.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.14.14.6.m6.1c">&gt;</annotation></semantics></math> 1</em> <span id="algorithm1.14.14.8" class="ltx_text ltx_font_bold">do</span> 
</div>
<div id="algorithm1.15.15" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">28</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
pi[<math id="algorithm1.15.15.m1.1" class="ltx_Math" alttext="i" display="inline"><semantics id="algorithm1.15.15.m1.1a"><mi id="algorithm1.15.15.m1.1.1" xref="algorithm1.15.15.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="algorithm1.15.15.m1.1b"><ci id="algorithm1.15.15.m1.1.1.cmml" xref="algorithm1.15.15.m1.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.15.15.m1.1c">i</annotation></semantics></math>+1] += 1;
</div>
<div id="algorithm1.15.40" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">29</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
update_allocated_memory();
</div>
<div id="algorithm1.15.41" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">30</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   

</div>
<div id="algorithm1.15.42" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">31</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>    end while
</div>
<div id="algorithm1.15.43" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">32</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
</div>
<div id="algorithm1.15.44" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">33</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>    end for
</div>
<div id="algorithm1.15.45" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="algorithm1.15.45.1.1.1" class="ltx_text ltx_font_typewriter">34</span></span><span id="algorithm1.15.45.2" class="ltx_text ltx_font_typewriter">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   </span>
</div>
<div id="algorithm1.15.46" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">35</span><span id="algorithm1.15.46.1" class="ltx_text">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   </span><span id="algorithm1.15.46.2" class="ltx_text">
</span>
</div>
<div id="algorithm1.15.47" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">36</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   <span id="algorithm1.15.47.1" class="ltx_text ltx_font_bold">if</span> <em id="algorithm1.15.47.2" class="ltx_emph ltx_font_italic">is_pi_unchanged</em> <span id="algorithm1.15.47.3" class="ltx_text ltx_font_bold">then</span>
</div>
<div id="algorithm1.15.48" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">37</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
raise exception(Cannot fulfill memory requirement);
</div>
<div id="algorithm1.15.49" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">38</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   

</div>
<div id="algorithm1.15.50" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">39</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   

</div>
<div id="algorithm1.15.51" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">40</span> end while
</div>
<div id="algorithm1.15.52" class="ltx_listingline">

</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span id="algorithm1.17.1.1" class="ltx_text ltx_font_bold">Algorithm 1</span> </span>coarse allocation by memory</figcaption>
</figure>
<div id="S4.SS4.p5" class="ltx_para">
<p id="S4.SS4.p5.2" class="ltx_p">In the workload fine-tuning stage, we need to optimize the partition index such that each device has a similar workload. We define the workload of <math id="S4.SS4.p5.1.m1.1" class="ltx_Math" alttext="j" display="inline"><semantics id="S4.SS4.p5.1.m1.1a"><mi id="S4.SS4.p5.1.m1.1.1" xref="S4.SS4.p5.1.m1.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p5.1.m1.1b"><ci id="S4.SS4.p5.1.m1.1.1.cmml" xref="S4.SS4.p5.1.m1.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p5.1.m1.1c">j</annotation></semantics></math>-th layer on the <math id="S4.SS4.p5.2.m2.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S4.SS4.p5.2.m2.1a"><mi id="S4.SS4.p5.2.m2.1.1" xref="S4.SS4.p5.2.m2.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S4.SS4.p5.2.m2.1b"><ci id="S4.SS4.p5.2.m2.1.1.cmml" xref="S4.SS4.p5.2.m2.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p5.2.m2.1c">i</annotation></semantics></math>-th device as <span id="S4.SS4.p5.2.1" class="ltx_text ltx_font_typewriter">dt[i]</span> * <span id="S4.SS4.p5.2.2" class="ltx_text ltx_font_typewriter">lf[j]</span> + <span id="S4.SS4.p5.2.3" class="ltx_text ltx_font_typewriter">ct[i]</span>. The total workload on a device is then the sum of the workload of the layers allocated to it.</p>
</div>
<div id="S4.SS4.p6" class="ltx_para">
<p id="S4.SS4.p6.1" class="ltx_p">The workload is used as a heuristic to guide each device to adjust its allocated layers. We adopted an iterative approach to optimize the load balance, by calculating the workload on all the devices and setting the average workload as the target workload. If a device has a workload that is less than the target, it should take one more layer from the next device. If the device has a workload that is higher than the target, it needs to consider whether the next device has a workload below the target value. If so, it is better to give away its last layer to the next device.</p>
</div>
<div id="S4.SS4.p7" class="ltx_para">
<p id="S4.SS4.p7.1" class="ltx_p">To prevent the device workload from wandering around the target value, the device will only give away its last layer when its remaining workload is still higher than the target workload. In this way, the devices with longer benchmark time (weaker computation power) will be allocated with fewer layers and vice versa. While the layer distribution is changing, it is always necessary to make sure the memory requirement is still fulfilled so as not to step into the out-of-memory problem. When the maximum iteration is reached or the partition index does not change anymore, we can use the final partition index to allocate the layers to the devices. The full flow of the algorithm is shown in Algorithm <a href="#algorithm2" title="In IV-D Heuristic Allocation ‣ IV Geo-distributed Computing Optimization ‣ Sky Computing: Accelerating Geo-distributed Computing in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<figure id="algorithm2" class="ltx_float ltx_algorithm">
<div id="algorithm2.13" class="ltx_listing ltx_lst_numbers_left ltx_listing">
<div id="algorithm2.13.14" class="ltx_listingline">

<span id="algorithm2.13.14.1" class="ltx_text ltx_font_bold">Data :</span>  dt, dm, ct, lf, lm, pi, max_iter
</div>
<div id="algorithm2.13.15" class="ltx_listingline">
<span id="algorithm2.13.15.1" class="ltx_text ltx_font_bold">Result :</span>  pi
</div>
<div id="algorithm2.13.16" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">1</span>

</div>
<div id="algorithm2.13.17" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">2</span>counter = 0;
</div>
<div id="algorithm2.13.18" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="algorithm2.13.18.1.1.1" class="ltx_text ltx_font_typewriter">3</span></span>

</div>
<div id="algorithm2.13.19" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">4</span><span id="algorithm2.13.19.1" class="ltx_text">
</span>
</div>
<div id="algorithm2.13.20" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">5</span><span id="algorithm2.13.20.1" class="ltx_text ltx_font_bold">while</span> <em id="algorithm2.13.20.2" class="ltx_emph ltx_font_italic">counter ¡ max_iter</em> <span id="algorithm2.13.20.3" class="ltx_text ltx_font_bold">do</span> 
</div>
<div id="algorithm2.13.21" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">6</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
target = compute_mean_workload(dt, lf, ct, pi);
</div>
<div id="algorithm2.13.22" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="algorithm2.13.22.1.1.1" class="ltx_text ltx_font_typewriter">7</span></span><span id="algorithm2.13.22.2" class="ltx_text ltx_font_typewriter">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   </span>

</div>
<div id="algorithm2.13.23" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">8</span><span id="algorithm2.13.23.1" class="ltx_text">  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   </span><span id="algorithm2.13.23.2" class="ltx_text">
</span>
</div>
<div id="algorithm2.2.2" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">9</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   <span id="algorithm2.2.2.3" class="ltx_text ltx_font_bold">for</span> <em id="algorithm2.2.2.2" class="ltx_emph ltx_font_italic"><math id="algorithm2.1.1.1.m1.1" class="ltx_Math" alttext="i\leftarrow 0" display="inline"><semantics id="algorithm2.1.1.1.m1.1a"><mrow id="algorithm2.1.1.1.m1.1.1" xref="algorithm2.1.1.1.m1.1.1.cmml"><mi id="algorithm2.1.1.1.m1.1.1.2" xref="algorithm2.1.1.1.m1.1.1.2.cmml">i</mi><mo stretchy="false" id="algorithm2.1.1.1.m1.1.1.1" xref="algorithm2.1.1.1.m1.1.1.1.cmml">←</mo><mn id="algorithm2.1.1.1.m1.1.1.3" xref="algorithm2.1.1.1.m1.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="algorithm2.1.1.1.m1.1b"><apply id="algorithm2.1.1.1.m1.1.1.cmml" xref="algorithm2.1.1.1.m1.1.1"><ci id="algorithm2.1.1.1.m1.1.1.1.cmml" xref="algorithm2.1.1.1.m1.1.1.1">←</ci><ci id="algorithm2.1.1.1.m1.1.1.2.cmml" xref="algorithm2.1.1.1.m1.1.1.2">𝑖</ci><cn type="integer" id="algorithm2.1.1.1.m1.1.1.3.cmml" xref="algorithm2.1.1.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.1.1.1.m1.1c">i\leftarrow 0</annotation></semantics></math> <span id="algorithm2.2.2.2.1" class="ltx_text ltx_font_bold ltx_font_upright">to</span> <math id="algorithm2.2.2.2.m2.1" class="ltx_Math" alttext="D" display="inline"><semantics id="algorithm2.2.2.2.m2.1a"><mi id="algorithm2.2.2.2.m2.1.1" xref="algorithm2.2.2.2.m2.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="algorithm2.2.2.2.m2.1b"><ci id="algorithm2.2.2.2.m2.1.1.cmml" xref="algorithm2.2.2.2.m2.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.2.2.2.m2.1c">D</annotation></semantics></math>-2</em> <span id="algorithm2.2.2.4" class="ltx_text ltx_font_bold">do</span> 
</div>
<div id="algorithm2.13.24" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">10</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   

</div>
<div id="algorithm2.5.5" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">11</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   <span id="algorithm2.5.5.4" class="ltx_text ltx_font_bold">if</span> <em id="algorithm2.5.5.3" class="ltx_emph ltx_font_italic">this_device_workload <math id="algorithm2.3.3.1.m1.1" class="ltx_Math" alttext="&lt;" display="inline"><semantics id="algorithm2.3.3.1.m1.1a"><mo id="algorithm2.3.3.1.m1.1.1" xref="algorithm2.3.3.1.m1.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="algorithm2.3.3.1.m1.1b"><lt id="algorithm2.3.3.1.m1.1.1.cmml" xref="algorithm2.3.3.1.m1.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.3.3.1.m1.1c">&lt;</annotation></semantics></math> target &amp;&amp; get_num_layer(pi, <math id="algorithm2.4.4.2.m2.1" class="ltx_Math" alttext="i" display="inline"><semantics id="algorithm2.4.4.2.m2.1a"><mi id="algorithm2.4.4.2.m2.1.1" xref="algorithm2.4.4.2.m2.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="algorithm2.4.4.2.m2.1b"><ci id="algorithm2.4.4.2.m2.1.1.cmml" xref="algorithm2.4.4.2.m2.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.4.4.2.m2.1c">i</annotation></semantics></math>+1) <math id="algorithm2.5.5.3.m3.1" class="ltx_Math" alttext="&gt;" display="inline"><semantics id="algorithm2.5.5.3.m3.1a"><mo id="algorithm2.5.5.3.m3.1.1" xref="algorithm2.5.5.3.m3.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="algorithm2.5.5.3.m3.1b"><gt id="algorithm2.5.5.3.m3.1.1.cmml" xref="algorithm2.5.5.3.m3.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.5.5.3.m3.1c">&gt;</annotation></semantics></math> 1 &amp;&amp; is_memory_satisfied_after_change</em> <span id="algorithm2.5.5.5" class="ltx_text ltx_font_bold">then</span> 
</div>
<div id="algorithm2.6.6" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">12</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
pi[<math id="algorithm2.6.6.m1.1" class="ltx_Math" alttext="i" display="inline"><semantics id="algorithm2.6.6.m1.1a"><mi id="algorithm2.6.6.m1.1.1" xref="algorithm2.6.6.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="algorithm2.6.6.m1.1b"><ci id="algorithm2.6.6.m1.1.1.cmml" xref="algorithm2.6.6.m1.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.6.6.m1.1c">i</annotation></semantics></math>+1] += 1;
</div>
<div id="algorithm2.13.25" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">13</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   

</div>
<div id="algorithm2.13.26" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">14</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>    end if
</div>
<div id="algorithm2.13.27" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">15</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   <span id="algorithm2.13.27.1" class="ltx_text ltx_font_bold">else</span> 
</div>
<div id="algorithm2.11.11" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">16</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
<span id="algorithm2.11.11.6" class="ltx_text ltx_font_bold">if</span> <em id="algorithm2.11.11.5" class="ltx_emph ltx_font_italic"> next_device_workload <math id="algorithm2.7.7.1.m1.1" class="ltx_Math" alttext="&lt;" display="inline"><semantics id="algorithm2.7.7.1.m1.1a"><mo id="algorithm2.7.7.1.m1.1.1" xref="algorithm2.7.7.1.m1.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="algorithm2.7.7.1.m1.1b"><lt id="algorithm2.7.7.1.m1.1.1.cmml" xref="algorithm2.7.7.1.m1.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.7.7.1.m1.1c">&lt;</annotation></semantics></math> target &amp;&amp;
this_device_workload <math id="algorithm2.8.8.2.m2.1" class="ltx_Math" alttext="-" display="inline"><semantics id="algorithm2.8.8.2.m2.1a"><mo id="algorithm2.8.8.2.m2.1.1" xref="algorithm2.8.8.2.m2.1.1.cmml">−</mo><annotation-xml encoding="MathML-Content" id="algorithm2.8.8.2.m2.1b"><minus id="algorithm2.8.8.2.m2.1.1.cmml" xref="algorithm2.8.8.2.m2.1.1"></minus></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.8.8.2.m2.1c">-</annotation></semantics></math> this_device_last_layer_workload <math id="algorithm2.9.9.3.m3.1" class="ltx_Math" alttext="&gt;" display="inline"><semantics id="algorithm2.9.9.3.m3.1a"><mo id="algorithm2.9.9.3.m3.1.1" xref="algorithm2.9.9.3.m3.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="algorithm2.9.9.3.m3.1b"><gt id="algorithm2.9.9.3.m3.1.1.cmml" xref="algorithm2.9.9.3.m3.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.9.9.3.m3.1c">&gt;</annotation></semantics></math> target &amp;&amp;
get_num_layer(pi, <math id="algorithm2.10.10.4.m4.1" class="ltx_Math" alttext="i" display="inline"><semantics id="algorithm2.10.10.4.m4.1a"><mi id="algorithm2.10.10.4.m4.1.1" xref="algorithm2.10.10.4.m4.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="algorithm2.10.10.4.m4.1b"><ci id="algorithm2.10.10.4.m4.1.1.cmml" xref="algorithm2.10.10.4.m4.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.10.10.4.m4.1c">i</annotation></semantics></math>) <math id="algorithm2.11.11.5.m5.1" class="ltx_Math" alttext="&gt;" display="inline"><semantics id="algorithm2.11.11.5.m5.1a"><mo id="algorithm2.11.11.5.m5.1.1" xref="algorithm2.11.11.5.m5.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="algorithm2.11.11.5.m5.1b"><gt id="algorithm2.11.11.5.m5.1.1.cmml" xref="algorithm2.11.11.5.m5.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.11.11.5.m5.1c">&gt;</annotation></semantics></math> 1 &amp;&amp;
is_memory_satisfied_after_change
</em> <span id="algorithm2.11.11.7" class="ltx_text ltx_font_bold">then</span> 
</div>
<div id="algorithm2.12.12" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">17</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
pi[<math id="algorithm2.12.12.m1.1" class="ltx_Math" alttext="i" display="inline"><semantics id="algorithm2.12.12.m1.1a"><mi id="algorithm2.12.12.m1.1.1" xref="algorithm2.12.12.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="algorithm2.12.12.m1.1b"><ci id="algorithm2.12.12.m1.1.1.cmml" xref="algorithm2.12.12.m1.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="algorithm2.12.12.m1.1c">i</annotation></semantics></math>+1] -= 1;
</div>
<div id="algorithm2.13.28" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">18</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   

</div>
<div id="algorithm2.13.29" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">19</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>    end if
</div>
<div id="algorithm2.13.30" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">20</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
</div>
<div id="algorithm2.13.31" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">21</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>    end if
</div>
<div id="algorithm2.13.32" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">22</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
</div>
<div id="algorithm2.13.33" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">23</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>    end for
</div>
<div id="algorithm2.13.34" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">24</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
</div>
<div id="algorithm2.13.13" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">25</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   <span id="algorithm2.13.13.2" class="ltx_text ltx_font_bold">if</span> <em id="algorithm2.13.13.1" class="ltx_emph ltx_font_italic">is_pi_unchanged <math id="algorithm2.13.13.1.m1.1" class="ltx_math_unparsed" alttext="||" display="inline"><semantics id="algorithm2.13.13.1.m1.1a"><mrow id="algorithm2.13.13.1.m1.1b"><mo fence="false" rspace="0.167em" stretchy="false" id="algorithm2.13.13.1.m1.1.1">|</mo><mo fence="false" stretchy="false" id="algorithm2.13.13.1.m1.1.2">|</mo></mrow><annotation encoding="application/x-tex" id="algorithm2.13.13.1.m1.1c">||</annotation></semantics></math> counter == max_iter</em> <span id="algorithm2.13.13.3" class="ltx_text ltx_font_bold">then</span>
</div>
<div id="algorithm2.13.35" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">26</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
return pi;
</div>
<div id="algorithm2.13.36" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">27</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   

</div>
<div id="algorithm2.13.37" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">28</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   

</div>
<div id="algorithm2.13.38" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">29</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   counter += 1

</div>
<div id="algorithm2.13.39" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">30</span> end while
</div>
<div id="algorithm2.13.40" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">31</span>
</div>
<div id="algorithm2.13.41" class="ltx_listingline">

</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span id="algorithm2.15.1.1" class="ltx_text ltx_font_bold">Algorithm 2</span> </span>Optimize workload</figcaption>
</figure>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Implementation</span>
</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">To integrate model parallelism, load balance optimization, and federated learning, we implemented a Python library called SCAELUM, which stands for SCAling Extreme Large models with Unified geo-distributed Mechanism. SCAELUM is built on PyTorch <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> and provides a simple API to establish model parallelism for training using PyTorch remote procedure call (RPC).</p>
</div>
<figure id="S5.F6" class="ltx_figure"><img src="/html/2202.11836/assets/figures/dllb_arch.png" id="S5.F6.g1" class="ltx_graphics ltx_centering ltx_img_square" width="538" height="493" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F6.2.1.1" class="ltx_text" style="font-size:90%;">Figure 6</span>: </span><span id="S5.F6.3.2" class="ltx_text" style="font-size:90%;">Architecture of SCAELUM library</span></figcaption>
</figure>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS1.5.1.1" class="ltx_text">V-A</span> </span><span id="S5.SS1.6.2" class="ltx_text ltx_font_italic">Architecture of SCAELUM</span>
</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">The layered architecture of SCAELUM has shown in Figure <a href="#S5.F6" title="Figure 6 ‣ V Implementation ‣ Sky Computing: Accelerating Geo-distributed Computing in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>. This architecture splits the library into individual modules and makes the library flexible and maintainable.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.1" class="ltx_p">The Registry Layer contains modules for various datasets and deep learning models. The Dataset Registry currently contains three dataset modules for CIFAR10 dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>, GLUE dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> as well as random two-dimension floating tensors. In the Model Registry, we have registered the commonly-used layers in PyTorch as well as the various layers of ResNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> and BERT<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. If the user wants to add the customized module to this framework, he can register the customized module to the respective registry easily.</p>
</div>
<div id="S5.SS1.p3" class="ltx_para">
<p id="S5.SS1.p3.1" class="ltx_p">The Builder Layer relies on the Registry Layer to build the objects involved in training. Users can specify the architecture of the training model by declaring the layers in a sequential manner as well as the parameters for the data loader in the configuration file. The corresponding builder will take in the configuration, which is usually a Python dictionary, and create an object. In this way, users can conduct different experiments, only need to modify the configuration file.</p>
</div>
<div id="S5.SS1.p4" class="ltx_para">
<p id="S5.SS1.p4.1" class="ltx_p">The RPC Layer provides wrappers for the normal PyTorch modules for easy RPC calls. The wrapper module objects are instantiated remotely on the workers and provide RPC-related methods for the central server to call. For example, in RPC-based distributed training, PyTorch requires the central server to hold the references to all trainable parameters for back-propagation. The wrapper module can collect the allocated trainable parameters on the worker and pass their references back to the central server. Moreover, the wrapper module provides an interface to interact with the central server to distribute and gather weights to save the distributed weights into a single checkpoint file.</p>
</div>
<div id="S5.SS1.p5" class="ltx_para">
<p id="S5.SS1.p5.1" class="ltx_p">The Dynamics Layer is the core of the SCAELUM library and is designed to allocate the layers to the workers. The Parameter Server object hosts the full copy of the model weights and the Allocator is tasked to distribute the weights to the workers. The allocator supports three options, which are even allocation, heuristic-based Sky Computing, and optimal allocation calculated by Gurobi <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> solver. Since the allocation problem is NP-hard, we provide the optimal allocation option only for experimental purposes. When the last two strategies are selected, the Benchmarker will take charge to gather information about the devices and the training model for allocation.</p>
</div>
<div id="S5.SS1.p6" class="ltx_para">
<p id="S5.SS1.p6.1" class="ltx_p">Lastly, the Training Layer provides a Runner to conduct RPC-based distributed training, and Hook modules are provided to control the training workflow. For example, the CheckpointHook component allows the runner to save the distributed weights into a single file at a fixed interval.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS2.5.1.1" class="ltx_text">V-B</span> </span><span id="S5.SS2.6.2" class="ltx_text ltx_font_italic">Simulating Heterogeneous Systems</span>
</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.2" class="ltx_p">As the devices involved in federated learning have different computing power, the whole system can be seen as a heterogeneous system. However, in most cases, the HPC cluster havs the same hardware specifications. To address this difference, we implemented speed control in the RPC module of SCAELUM to artificially adjust the computing power of the device. An iteration of training includes a forward pass and a backward pass. Our strategy is to measure the time taken in the forward and backward pass and let the process sleep for a period of time. By setting the value of the parameter <em id="S5.SS2.p1.2.1" class="ltx_emph ltx_font_italic">slow_down</em>, the sleep time is calculated by <em id="S5.SS2.p1.2.2" class="ltx_emph ltx_font_italic">slow_down</em> <math id="S5.SS2.p1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.SS2.p1.1.m1.1a"><mo id="S5.SS2.p1.1.m1.1.1" xref="S5.SS2.p1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.1.m1.1b"><times id="S5.SS2.p1.1.m1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.1.m1.1c">\times</annotation></semantics></math> <em id="S5.SS2.p1.2.3" class="ltx_emph ltx_font_italic">forward_time</em> or <em id="S5.SS2.p1.2.4" class="ltx_emph ltx_font_italic">slow_down</em> <math id="S5.SS2.p1.2.m2.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.SS2.p1.2.m2.1a"><mo id="S5.SS2.p1.2.m2.1.1" xref="S5.SS2.p1.2.m2.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.2.m2.1b"><times id="S5.SS2.p1.2.m2.1.1.cmml" xref="S5.SS2.p1.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.2.m2.1c">\times</annotation></semantics></math> <em id="S5.SS2.p1.2.5" class="ltx_emph ltx_font_italic">backward_time</em>. For example, if <em id="S5.SS2.p1.2.6" class="ltx_emph ltx_font_italic">slow_down</em> = 1, the time for forward and backward computation will be 2 times the original value.</p>
</div>
<div id="S5.SS2.p2" class="ltx_para">
<p id="S5.SS2.p2.1" class="ltx_p">It is easy to implement this in the forward pass as we can directly measure the time in the <em id="S5.SS2.p2.1.1" class="ltx_emph ltx_font_italic">forward</em> method of the PyTorch module. Meanwhile, it is more difficult to measure the time in the backward pass since the backward computation is handled automatically by the autograd package. To tackle this problem, we applied our customized autograd function to the module. This autograd function comes with a distributed timer which measures the time taken to run the backward pass on this module. In this way, we can slow down both the forward and backward pass to simulate devices with variant computing power.</p>
</div>
<figure id="S5.F7" class="ltx_figure"><img src="/html/2202.11836/assets/figures/dllb_fed.png" id="S5.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="538" height="389" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F7.2.1.1" class="ltx_text" style="font-size:90%;">Figure 7</span>: </span><span id="S5.F7.3.2" class="ltx_text" style="font-size:90%;">Workflow of DLLB-Fed</span></figcaption>
</figure>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS3.5.1.1" class="ltx_text">V-C</span> </span><span id="S5.SS3.6.2" class="ltx_text ltx_font_italic">Training using SCAELUM</span>
</h3>

<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.1" class="ltx_p">The SCAELUM library provides the necessary modules for model parallelism training with load balance optimization. We provided two methods to utilize SCAELUM for experiments.</p>
</div>
<section id="S5.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S5.SS3.SSS1.5.1.1" class="ltx_text">V-C</span>1 </span>Training with SCAELUM-Fed</h4>

<div id="S5.SS3.SSS1.p1" class="ltx_para">
<p id="S5.SS3.SSS1.p1.1" class="ltx_p">We designed and implemented a new testing framework called SCAELUM-Fed which uses SCAELUM to simulate the real federated learning scenario. SCAELUM-Fed wraps the central server and the user’s device as individual services and provides a user-friendly command-line interface to interact with these services. The workflow of SCAELUM-Fed is shown in Figure <a href="#S5.F7" title="Figure 7 ‣ V-B Simulating Heterogeneous Systems ‣ V Implementation ‣ Sky Computing: Accelerating Geo-distributed Computing in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>.</p>
</div>
<div id="S5.SS3.SSS1.p2" class="ltx_para">
<p id="S5.SS3.SSS1.p2.1" class="ltx_p">To use SCAELUM-Fed for training, the user first needs to start a central service. The central service contains the core modules of SCAELUM such as benchmarkers, allocator, worker manager, and runner. The worker manager of the central service will keep track of the worker service participating in training. Next, one or more worker services can be started. These worker services should subscribe to the central service, registering themselves to the worker manager of the central service. Once the central service has received subscriptions from some workers, it can start to gather information about the training model and the worker services by conducting benchmarking tests. The central service will then allocate the model using the Sky Computing. At last, the central service can send the request to all the subscribed worker services to start model-parallel distributed training. All the actions can be done via the command-line interface. By using SCAELUM-Fed, we can simulate how users’ devices interact with the central server and conduct experiments to evaluate the effectiveness of our load balance optimization algorithm by adding or removing the worker service.</p>
</div>
</section>
<section id="S5.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S5.SS3.SSS2.5.1.1" class="ltx_text">V-C</span>2 </span>Training with MPI</h4>

<div id="S5.SS3.SSS2.p1" class="ltx_para">
<p id="S5.SS3.SSS2.p1.1" class="ltx_p">One disadvantage of SCAELUM-Fed is that it becomes troublesome to manage the worker services by command line when the number of worker services becomes large. It is reasonably not a good choice if we wish to explore the performance of our allocation framework on large-scale distributed systems. To address this issue, instead of running some services, we extract the workflow from SCAELUM-Fed and use MPI to launch multiple processes on supercomputers.</p>
</div>
</section>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span id="S6.1.1" class="ltx_text ltx_font_smallcaps">Experiments</span>
</h2>

<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S6.SS1.5.1.1" class="ltx_text">VI-A</span> </span><span id="S6.SS1.6.2" class="ltx_text ltx_font_italic">Hardware Specification</span>
</h3>

<div id="S6.SS1.p1" class="ltx_para">
<p id="S6.SS1.p1.2" class="ltx_p">To evaluate the effectiveness of the Sky Computing, we conducted experiments on an HPC cluster where each node has one P100 GPU. We chose to run our experiments on 16, 32, and 64 compute nodes. As the central parameter server needs to take one GPU, the number of devices that participate in federated learning is <math id="S6.SS1.p1.1.m1.1" class="ltx_Math" alttext="D-1" display="inline"><semantics id="S6.SS1.p1.1.m1.1a"><mrow id="S6.SS1.p1.1.m1.1.1" xref="S6.SS1.p1.1.m1.1.1.cmml"><mi id="S6.SS1.p1.1.m1.1.1.2" xref="S6.SS1.p1.1.m1.1.1.2.cmml">D</mi><mo id="S6.SS1.p1.1.m1.1.1.1" xref="S6.SS1.p1.1.m1.1.1.1.cmml">−</mo><mn id="S6.SS1.p1.1.m1.1.1.3" xref="S6.SS1.p1.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.SS1.p1.1.m1.1b"><apply id="S6.SS1.p1.1.m1.1.1.cmml" xref="S6.SS1.p1.1.m1.1.1"><minus id="S6.SS1.p1.1.m1.1.1.1.cmml" xref="S6.SS1.p1.1.m1.1.1.1"></minus><ci id="S6.SS1.p1.1.m1.1.1.2.cmml" xref="S6.SS1.p1.1.m1.1.1.2">𝐷</ci><cn type="integer" id="S6.SS1.p1.1.m1.1.1.3.cmml" xref="S6.SS1.p1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p1.1.m1.1c">D-1</annotation></semantics></math> where <math id="S6.SS1.p1.2.m2.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S6.SS1.p1.2.m2.1a"><mi id="S6.SS1.p1.2.m2.1.1" xref="S6.SS1.p1.2.m2.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S6.SS1.p1.2.m2.1b"><ci id="S6.SS1.p1.2.m2.1.1.cmml" xref="S6.SS1.p1.2.m2.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p1.2.m2.1c">D</annotation></semantics></math> is the total number of GPUs used. Even though this does not make the number of devices a multiple of two, our experiments still demonstrate the effectiveness of our algorithm.</p>
</div>
</section>
<section id="S6.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S6.SS2.5.1.1" class="ltx_text">VI-B</span> </span><span id="S6.SS2.6.2" class="ltx_text ltx_font_italic">Task Description</span>
</h3>

<div id="S6.SS2.p1" class="ltx_para">
<p id="S6.SS2.p1.1" class="ltx_p">In our experiments, we chose BERT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> as the model to tackle the MNLI task <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> on GLUE dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>. MNLI stands for Multi-Genre Natural Language Inference. In this task, we give a pair of sentences as input data to BERT and classify whether the second sentence is a contradiction, entailment, or neutral statement of the first premise sentence. The architecture of BERT can be split into the embedding layer, the encoder layers, the pooling layer, and the classification head as shown in Figure <a href="#S6.F8" title="Figure 8 ‣ VI-B Task Description ‣ VI Experiments ‣ Sky Computing: Accelerating Geo-distributed Computing in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>. The encoder layer can be further divided into the self-attention layer, the intermediate layer, and the output layer as discussed in Figure <a href="#S2.F2" title="Figure 2 ‣ II-C BERT ‣ II Background ‣ Sky Computing: Accelerating Geo-distributed Computing in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> and it can be repeated infinitely since the input and output have the same shape. Therefore, we can change the number of encoder layers in BERT to have a different amount of computation when we change the scale of our experiments. In the official BERT-Large model, 24 encoder layers are used and each layer has 16 attention heads. In our experiments, we use a maximum of 160 encoder layers, which is almost 7 times larger than the BERT-Large model. We stick to 16 attention heads as used in the official configurations and train the model with a batch size of 32.</p>
</div>
<figure id="S6.F8" class="ltx_figure"><img src="/html/2202.11836/assets/figures/bert.png" id="S6.F8.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="538" height="410" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S6.F8.2.1.1" class="ltx_text" style="font-size:90%;">Figure 8</span>: </span><span id="S6.F8.3.2" class="ltx_text" style="font-size:90%;">Architecture of BERT</span></figcaption>
</figure>
</section>
<section id="S6.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S6.SS3.5.1.1" class="ltx_text">VI-C</span> </span><span id="S6.SS3.6.2" class="ltx_text ltx_font_italic">Memory Control</span>
</h3>

<div id="S6.SS3.p1" class="ltx_para">
<p id="S6.SS3.p1.1" class="ltx_p">When allocating the layers to devices, the essential condition is that the memory usage does not exceed the memory limit on the device to avoid the out-of-memory problem. This is critical as training will fail with insufficient memory. Our framework ensures the memory limit is not exceeded and the training can be executed successfully.</p>
</div>
</section>
<section id="S6.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S6.SS4.5.1.1" class="ltx_text">VI-D</span> </span><span id="S6.SS4.6.2" class="ltx_text ltx_font_italic">Speed Control</span>
</h3>

<div id="S6.SS4.p1" class="ltx_para">
<p id="S6.SS4.p1.1" class="ltx_p">To simulate devices with different computational power, we multiply the forward time and backward time with a reproducible random-generated penalty factor <em id="S6.SS4.p1.1.1" class="ltx_emph ltx_font_italic">slow_down</em>. In our experiments, the values of <em id="S6.SS4.p1.1.2" class="ltx_emph ltx_font_italic">slow_down</em> are between 1 and 7. The larger the penalty factor, the slower the device. The adjusted computational power of devices is normally distributed. This allows us to observe the performance of our algorithm in a heterogeneous-like setting.</p>
</div>
<div id="S6.SS4.p2" class="ltx_para">
<p id="S6.SS4.p2.1" class="ltx_p">To measure the computation power of the devices in federated learning, the central server sends a request to each device and runs a simple benchmark test. In our experiments, we run the forward pass of a 10-layer convolutional neural network for 30 iterations. The input data has a shape of (32, 256, 64, 64) while the convolution layer has the same input and output dimension of 256 with a kernel size of 3 and padding size of 1.</p>
</div>
</section>
<section id="S6.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S6.SS5.5.1.1" class="ltx_text">VI-E</span> </span><span id="S6.SS5.6.2" class="ltx_text ltx_font_italic">Communication Control</span>
</h3>

<div id="S6.SS5.p1" class="ltx_para">
<p id="S6.SS5.p1.1" class="ltx_p">In model parallelism, P2P communication is used when passing tensors between devices, and the communication latency, which depends on the physical distance between two devices, cannot be ignored. Therefore, we test the communication time at the benchmark stage and treat it as a part of the performance of the devices. In the experiments, all experiments were run in the same SLURM job on the same HPC cluster and this ensures the same latency between consecutive workers for the sake of fairness.</p>
</div>
</section>
<section id="S6.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S6.SS6.5.1.1" class="ltx_text">VI-F</span> </span><span id="S6.SS6.6.2" class="ltx_text ltx_font_italic">Overall Results</span>
</h3>

<div id="S6.SS6.p1" class="ltx_para">
<p id="S6.SS6.p1.1" class="ltx_p">From the training results in Figure <a href="#S6.F9" title="Figure 9 ‣ VI-G Strong Scaling ‣ VI Experiments ‣ Sky Computing: Accelerating Geo-distributed Computing in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>, it can be observed that the Sky Computing outperforms the even allocation strategy in all scales. Because the allocation problem is NP-hard, it will consume an unnecessary huge amount of power and take an unbearable long time to wait when scale grows large. So there is no need to figure out an optimal solution by using significant power, thus we only apply optimal allocation up to 32 nodes.</p>
</div>
</section>
<section id="S6.SS7" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S6.SS7.5.1.1" class="ltx_text">VI-G</span> </span><span id="S6.SS7.6.2" class="ltx_text ltx_font_italic">Strong Scaling</span>
</h3>

<div id="S6.SS7.p1" class="ltx_para">
<p id="S6.SS7.p1.1" class="ltx_p">In strong scaling experiments, we used a very large BERT model by setting the number of encoder layers to be 80 so that we have 403 discrete layers in total. By keeping the model size constant, we use 16, 32, and 64 nodes for training. Since model parallelism by layer is adopted, the communication time for an iteration is expected to increase with an increasing number of devices participating in training.</p>
</div>
<figure id="S6.F9" class="ltx_figure"><img src="/html/2202.11836/assets/figures/train_time_per_iter.png" id="S6.F9.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="288" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S6.F9.2.1.1" class="ltx_text" style="font-size:90%;">Figure 9</span>: </span><span id="S6.F9.3.2" class="ltx_text" style="font-size:90%;">Average Forward/Backward Time</span></figcaption>
</figure>
<figure id="S6.F10" class="ltx_figure"><img src="/html/2202.11836/assets/x1.png" id="S6.F10.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="461" height="652" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S6.F10.2.1.1" class="ltx_text" style="font-size:90%;">Figure 10</span>: </span><span id="S6.F10.3.2" class="ltx_text" style="font-size:90%;">Strong Scaling Results</span></figcaption>
</figure>
<div id="S6.SS7.p2" class="ltx_para">
<p id="S6.SS7.p2.1" class="ltx_p">Figure <a href="#S6.F10" title="Figure 10 ‣ VI-G Strong Scaling ‣ VI Experiments ‣ Sky Computing: Accelerating Geo-distributed Computing in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a> shows the forward time and backward time for 30 iterations during training. The forward and backward times are lower with the Sky Computing for all cases. The optimal allocation can reduce 35%, 19.4% training time for 16, 32 nodes respectively. And the heuristic allocation can reduce 22.2%, 10.5%, 15.4% training time for 16, 32, 64 nodes respectively.</p>
</div>
</section>
<section id="S6.SS8" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S6.SS8.5.1.1" class="ltx_text">VI-H</span> </span><span id="S6.SS8.6.2" class="ltx_text ltx_font_italic">Weak Scaling</span>
</h3>

<div id="S6.SS8.p1" class="ltx_para">
<p id="S6.SS8.p1.1" class="ltx_p">To perform weak scaling experiments, we increase the number of encoder layers and the number of devices at the same rate to keep the problem size on each device constant. Even though the embedding layer, pooling layer, and the classification head cannot be repeated proportionally, the increase in the total number of layers is still approximately linear.</p>
</div>
<div id="S6.SS8.p2" class="ltx_para">
<p id="S6.SS8.p2.1" class="ltx_p">We used the same number of nodes as the strong scaling experiments and set the number of encoder layers to be 40, 80, and 160. The run time results for the weak scaling experiments are reported in Figure <a href="#S6.F11" title="Figure 11 ‣ VI-H Weak Scaling ‣ VI Experiments ‣ Sky Computing: Accelerating Geo-distributed Computing in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a>. In all experiments, our load-balanced allocation strategy can outperform the even allocation counterpart by a large margin. The optimal allocation can reduce 25%, 19.4% training time for 16, 32 nodes respectively. And the heuristic allocation can reduce 21.7%, 10.5%, 55.6% training time for 16, 32, 64 nodes respectively.</p>
</div>
<figure id="S6.F11" class="ltx_figure"><img src="/html/2202.11836/assets/x2.png" id="S6.F11.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="461" height="652" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S6.F11.2.1.1" class="ltx_text" style="font-size:90%;">Figure 11</span>: </span><span id="S6.F11.3.2" class="ltx_text" style="font-size:90%;">Weak Scaling Results</span></figcaption>
</figure>
</section>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VII </span><span id="S7.1.1" class="ltx_text ltx_font_smallcaps">Discussion</span>
</h2>

<section id="S7.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S7.SS1.5.1.1" class="ltx_text">VII-A</span> </span><span id="S7.SS1.6.2" class="ltx_text ltx_font_italic">Real-world Geo-distributed Computing</span>
</h3>

<div id="S7.SS1.p1" class="ltx_para">
<p id="S7.SS1.p1.1" class="ltx_p">As a new type of heterogeneous computing, geo-distributed computing has attracted more and more attention. In our paper, we use HPC to simulate a real-world situation by setting normally distributed factors. However, we also noticed some flaws caused by this stimulation:</p>
</div>
<div id="S7.SS1.p2" class="ltx_para">
<ol id="S7.I1" class="ltx_enumerate">
<li id="S7.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S7.I1.i1.p1" class="ltx_para">
<p id="S7.I1.i1.p1.1" class="ltx_p">Communication Latency: Since different heterogeneous devices are often connected through the Internet, communication latency is extremely high and it will dominate the overall time cost in some cases. In our simulation, the devices are connected by a high-speed local area network, which currently is not consistent with the actual situation.</p>
</div>
</li>
<li id="S7.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S7.I1.i2.p1" class="ltx_para">
<p id="S7.I1.i2.p1.1" class="ltx_p">Computing Power: In real-world scenarios, the computing power of devices may vary widely, especially with the continuous development of SoCs in the past years, the graphics performance of smart devices has been explosively improved. According to GeekBench<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>https://browser.geekbench.com/ios-benchmarks</span></span></span>, iPhone’s graphics performance quadrupled in four years and will continue to grow for the foreseeable future. As a result, the heterogeneity of computing speed will be more significant in real scenarios, and we only do a preliminary simulation in our experiments</p>
</div>
</li>
<li id="S7.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S7.I1.i3.p1" class="ltx_para">
<p id="S7.I1.i3.p1.1" class="ltx_p">Available Memory: Due to the high homogeneity of HPC hardware, the difference in available memory obtained by the benchmark stage is almost imperceptible, but in the real world, there may be some specific differences.</p>
</div>
</li>
</ol>
</div>
<div id="S7.SS1.p3" class="ltx_para">
<p id="S7.SS1.p3.1" class="ltx_p">Sky Computing is currently under heavy development, and many of its features have not been added. In the next, we will first focus on fixing these problems and providing a user-friendly system. With this project, we hope to extend Sky Computing to more fields and bring some new inspiration to geo-distributed computing.</p>
</div>
</section>
<section id="S7.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S7.SS2.5.1.1" class="ltx_text">VII-B</span> </span><span id="S7.SS2.6.2" class="ltx_text ltx_font_italic">Data privacy</span>
</h3>

<div id="S7.SS2.p1" class="ltx_para">
<p id="S7.SS2.p1.1" class="ltx_p">One difference between our training set and the general federated learning is that the feature map is passed between workers to perform the feed-forward computation. One concern raised is whether data privacy is still preserved in our case. Three reasons are provided below to explain why user privacy is not infringed even though there is data passing between the devices.</p>
<ul id="S7.I2" class="ltx_itemize">
<li id="S7.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S7.I2.i1.p1" class="ltx_para">
<p id="S7.I2.i1.p1.1" class="ltx_p">In traditional federated learning, each device will hold a full copy of the model while in our case, each device only holds a part of the model. When a worker receives a feature map from the previous worker, it does not have information about the model architecture and weights on the previous worker. Thus, it cannot compute reversely to recover the input data generated by the user.</p>
</div>
</li>
<li id="S7.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S7.I2.i2.p1" class="ltx_para">
<p id="S7.I2.i2.p1.1" class="ltx_p">To make sure the data is securely transferred, the intermediate feature map must be encrypted when the device sends out the feature map to the next device. Before sending out the feature map, other existing techniques such as differential privacy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> can be applied to mask the feature map as well. In this way, it becomes even more difficult to recover useful information from the transferred data.</p>
</div>
</li>
<li id="S7.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S7.I2.i3.p1" class="ltx_para">
<p id="S7.I2.i3.p1.1" class="ltx_p">In our current framework, only one device is receiving the raw input data as it holds the first layer of the model. Meanwhile, all devices have the raw user data in reality. However, we should not transfer the raw user data from one device to another device to prevent possible data leakage. To solve this problem, we propose that each device should at least hold a copy of the first layer. In this way, the device only passes the output of the first layer to other workers when raw user data is used for training. The output feature map of the first layer can be passed securely to other workers with encryption or differential privacy. The raw user data is still kept intact on the user’s device to safeguard their privacy.</p>
</div>
</li>
</ul>
</div>
</section>
</section>
<section id="S8" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VIII </span><span id="S8.1.1" class="ltx_text ltx_font_smallcaps">Conclusion</span>
</h2>

<div id="S8.p1" class="ltx_para">
<p id="S8.p1.1" class="ltx_p">In this paper, we proposed a method to conduct training of large-scale models in federating learning and proposed a method that optimizes the load balance in order to remove the computation bottleneck and increase training speed. Our Sky Computing guides the devices to decide the layers they should fetch from the parameter server. In heuristic allocation, it iteratively updates the model allocation to reduce the average workload on devices based on both the model and device information. As shown in our experiments, we compared the performance produced by the naive even-allocation method and our Sky Computing. Our framework provides a consistent speedup for the training and outperforms the naive approach by 55.0% when training 160-layer BERT on 64 nodes.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, “BERT: Pre-training of
deep bidirectional transformers for language understanding,” in
<em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 Conference of the North American Chapter of
the Association for Computational Linguistics: Human Language Technologies,
Volume 1 (Long and Short Papers)</em>.   Minneapolis, Minnesota: Association for Computational Linguistics, Jun. 2019,
pp. 4171–4186. [Online]. Available:
<a target="_blank" href="https://www.aclweb.org/anthology/N19-1423" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/N19-1423</a>

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal,
A. Neelakantan, P. Shyam, G. Sastry, A. Askell, S. Agarwal, A. Herbert-Voss,
G. Krueger, T. Henighan, R. Child, A. Ramesh, D. Ziegler, J. Wu, C. Winter,
C. Hesse, M. Chen, E. Sigler, M. Litwin, S. Gray, B. Chess, J. Clark,
C. Berner, S. McCandlish, A. Radford, I. Sutskever, and D. Amodei, “Language
models are few-shot learners,” in <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information
Processing Systems</em>, H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, and
H. Lin, Eds., vol. 33.   Curran
Associates, Inc., 2020, pp. 1877–1901. [Online]. Available:
<a target="_blank" href="https://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf</a>

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
G. Hinton, O. Vinyals, and J. Dean, “Distilling the knowledge in a neural
network,” in <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">NIPS Deep Learning and Representation Learning Workshop</em>,
2015. [Online]. Available: <a target="_blank" href="http://arxiv.org/abs/1503.02531" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/1503.02531</a>

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
H. Kim, M. U. K. Khan, and C. Kyung, “Efficient neural network
compression,” in <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">2019 IEEE/CVF Conference on Computer Vision and
Pattern Recognition (CVPR)</em>, 2019, pp. 12 561–12 569.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
H. B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. Y. Arcas,
“Communication-efficient learning of deep networks from decentralized
data,” in <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">AISTATS</em>, 2017.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Y. Dong, J.-B. Cordonnier, and A. Loukas, “Attention is not all you need: Pure
attention loses rank doubly exponentially with depth,” 2021.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
T. Ben-Nun and T. Hoefler, “Demystifying parallel and distributed deep
learning: An in-depth concurrency analysis,” <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">ACM Comput. Surv.</em>,
vol. 52, no. 4, Aug. 2019. [Online]. Available:
<a target="_blank" href="https://doi.org/10.1145/3320060" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3320060</a>

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Y. Huang, Y. Cheng, A. Bapna, O. Firat, D. Chen, M. Chen, H. Lee, J. Ngiam,
Q. V. Le, Y. Wu, and z. Chen, “Gpipe: Efficient training of giant neural
networks using pipeline parallelism,” in <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">Advances in Neural
Information Processing Systems</em>, H. Wallach, H. Larochelle, A. Beygelzimer,
F. d'Alché-Buc, E. Fox, and R. Garnett, Eds.,
vol. 32.   Curran Associates, Inc.,
2019. [Online]. Available:
<a target="_blank" href="https://proceedings.neurips.cc/paper/2019/file/093f65e080a295f8076b1c5722a46aa2-Paper.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.neurips.cc/paper/2019/file/093f65e080a295f8076b1c5722a46aa2-Paper.pdf</a>

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
D. Narayanan, A. Harlap, A. Phanishayee, V. Seshadri, N. R. Devanur, G. R.
Ganger, P. B. Gibbons, and M. Zaharia, “Pipedream: Generalized pipeline
parallelism for dnn training,” in <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 27th ACM
Symposium on Operating Systems Principles</em>, ser. SOSP ’19.   New York, NY, USA: Association for Computing
Machinery, 2019, p. 1–15. [Online]. Available:
<a target="_blank" href="https://doi.org/10.1145/3341301.3359646" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3341301.3359646</a>

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
M. Shoeybi, M. Patwary, R. Puri, P. LeGresley, J. Casper, and B. Catanzaro,
“Megatron-lm: Training multi-billion parameter language models using model
parallelism,” 2020.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
S. Yun, M. Jeong, R. Kim, J. Kang, and H. J. Kim, “Graph transformer
networks,” in <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>,
H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alché-Buc, E. Fox, and R. Garnett, Eds., vol. 32.   Curran Associates, Inc., 2019. [Online]. Available:
<a target="_blank" href="https://proceedings.neurips.cc/paper/2019/file/9d63484abb477c97640154d40595a3bb-Paper.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.neurips.cc/paper/2019/file/9d63484abb477c97640154d40595a3bb-Paper.pdf</a>

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
K. A. Bonawitz, H. Eichner, W. Grieskamp, D. Huba, A. Ingerman, V. Ivanov,
C. M. Kiddon, J. Konečný, S. Mazzocchi, B. McMahan, T. V. Overveldt,
D. Petrou, D. Ramage, and J. Roselander, “Towards federated learning at
scale: System design,” in <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">SysML 2019</em>, 2019, to appear. [Online].
Available: <a target="_blank" href="https://arxiv.org/abs/1902.01046" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/1902.01046</a>

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Q. Yang, Y. Liu, T. Chen, and Y. Tong, “Federated machine learning: Concept
and applications,” <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">ACM Trans. Intell. Syst. Technol.</em>, vol. 10, no. 2,
Jan. 2019. [Online]. Available: <a target="_blank" href="https://doi.org/10.1145/3298981" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3298981</a>

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
M. Li, D. G. Andersen, A. J. Smola, and K. Yu, “Communication efficient
distributed machine learning with the parameter server,” in <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">Advances
in Neural Information Processing Systems</em>, Z. Ghahramani, M. Welling,
C. Cortes, N. Lawrence, and K. Q. Weinberger, Eds., vol. 27.   Curran Associates, Inc., 2014. [Online]. Available:
<a target="_blank" href="https://proceedings.neurips.cc/paper/2014/file/1ff1de774005f8da13f42943881c655f-Paper.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.neurips.cc/paper/2014/file/1ff1de774005f8da13f42943881c655f-Paper.pdf</a>

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury, G. Chanan, T. Killeen,
Z. Lin, N. Gimelshein, L. Antiga, A. Desmaison, A. Kopf, E. Yang, Z. DeVito,
M. Raison, A. Tejani, S. Chilamkurthy, B. Steiner, L. Fang, J. Bai, and
S. Chintala, “Pytorch: An imperative style, high-performance deep learning
library,” in <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems 32</em>,
H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alché-Buc, E. Fox, and R. Garnett, Eds.   Curran Associates, Inc., 2019, pp. 8024–8035. [Online].
Available:
<a target="_blank" href="http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf</a>

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
A. Krizhevsky, “Learning multiple layers of features from tiny images,” 2009.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
A. Wang, A. Singh, J. Michael, F. Hill, O. Levy, and S. Bowman, “GLUE: A
multi-task benchmark and analysis platform for natural language
understanding,” in <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 EMNLP Workshop
BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP</em>.   Brussels, Belgium: Association for
Computational Linguistics, Nov. 2018, pp. 353–355. [Online]. Available:
<a target="_blank" href="https://www.aclweb.org/anthology/W18-5446" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/W18-5446</a>

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image
recognition,” in <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">2016 IEEE Conference on Computer Vision and Pattern
Recognition (CVPR)</em>, 2016, pp. 770–778.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Gurobi Optimization, LLC, “Gurobi Optimizer Reference Manual,” 2021.
[Online]. Available: <a target="_blank" href="https://www.gurobi.com" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.gurobi.com</a>

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
A. Williams, N. Nangia, and S. Bowman, “A broad-coverage challenge corpus for
sentence understanding through inference,” in <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018
Conference of the North American Chapter of the Association for Computational
Linguistics: Human Language Technologies, Volume 1 (Long Papers)</em>.   Association for Computational Linguistics, 2018,
pp. 1112–1122. [Online]. Available:
<a target="_blank" href="http://aclweb.org/anthology/N18-1101" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://aclweb.org/anthology/N18-1101</a>

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Z. Chuanxin, S. Yi, and W. Degang, “Federated learning with gaussian
differential privacy,” in <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020 2nd International
Conference on Robotics, Intelligent Control and Artificial Intelligence</em>,
ser. RICAI 2020.   New York, NY, USA:
Association for Computing Machinery, 2020, p. 296–301. [Online]. Available:
<a target="_blank" href="https://doi.org/10.1145/3438872.3439097" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3438872.3439097</a>

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2202.11835" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2202.11836" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2202.11836">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2202.11836" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2202.11837" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Mar  7 21:14:21 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
