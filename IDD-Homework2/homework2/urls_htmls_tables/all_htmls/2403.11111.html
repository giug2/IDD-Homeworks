<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2403.11111] 3D Human Reconstruction in the Wild with Synthetic Data Using Generative ModelsWork was done when YG was visiting Zhejiang University. HC is the corresponding author.</title><meta property="og:description" content="Despite remarkable progress has been made on the problem of 3D human pose and shape estimation (HPS), current state-of-the-art methods rely heavily on either confined indoor mocap datasets or datasets generated by rendâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="3D Human Reconstruction in the Wild with Synthetic Data Using Generative ModelsWork was done when YG was visiting Zhejiang University. HC is the corresponding author.">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="3D Human Reconstruction in the Wild with Synthetic Data Using Generative ModelsWork was done when YG was visiting Zhejiang University. HC is the corresponding author.">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2403.11111">

<!--Generated on Fri Apr  5 13:44:39 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="Controllable Human Generation Synthetic Dataset 3D Human Reconstruction Diffusion Model
">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div id="p1" class="ltx_para">
<p id="p1.1" class="ltx_p">(eccv)                Package eccv Warning: Package â€˜hyperrefâ€™ is loaded with option â€˜pagebackrefâ€™, which is *not* recommended for camera-ready version</p>
</div>
<span id="id3" class="ltx_note ltx_role_institutetext"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">institutetext: </span>
<sup id="id3.1" class="ltx_sup">1</sup>Zhejiang University Â Â Â 
<sup id="id3.2" class="ltx_sup">2</sup>The University of Adelaide
Â Â Â 
<sup id="id3.3" class="ltx_sup">3</sup>The University of Hong Kong

<br class="ltx_break">Project Page: <a target="_blank" href="https://yongtaoge.github.io/projects/humanwild" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://yongtaoge.github.io/projects/humanwild</a>
</span></span></span>
<h1 class="ltx_title ltx_title_document">3D Human Reconstruction in the Wild with Synthetic Data Using Generative Models<span id="id5.id1" class="ltx_note ltx_role_thanks"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">thanks: </span>Work was done when YG was visiting Zhejiang University. HC is the corresponding author.</span></span></span>
</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yongtao Ge
Â 
Wenjia Wang
Â 
Yongfan Chen
Â 
Hao Chen
Â 
Chunhua Shen

</span><span class="ltx_author_notes">221133111111</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id4.1" class="ltx_p">Despite remarkable progress has been made on the problem of 3D human pose and shape estimation (HPS), current state-of-the-art methods rely heavily on either confined indoor mocap datasets or datasets generated by rendering engine
using computer graphics (CG).
Both categories of datasets exhibit inadequacies in furnishing adequate human identities and authentic in-the-wild background scenes, which are crucial for accurately simulating real-world distributions.
In this work, we show that synthetic data created by generative models is complementary to CG-rendered data for achieving remarkable generalization performance on diverse real-world scenes.
Specifically, we propose an effective approach based on recent diffusion models, termed <math id="id4.1.m1.1" class="ltx_Math" alttext="\tt HumanWild" display="inline"><semantics id="id4.1.m1.1a"><mi id="id4.1.m1.1.1" xref="id4.1.m1.1.1.cmml">ğ™·ğšğš–ğšŠğš—ğš†ğš’ğš•ğš</mi><annotation-xml encoding="MathML-Content" id="id4.1.m1.1b"><ci id="id4.1.m1.1.1.cmml" xref="id4.1.m1.1.1">ğ™·ğšğš–ğšŠğš—ğš†ğš’ğš•ğš</ci></annotation-xml><annotation encoding="application/x-tex" id="id4.1.m1.1c">\tt HumanWild</annotation></semantics></math>, which can effortlessly generate human images and corresponding 3D mesh annotations.
We first collect a large-scale human-centric dataset with comprehensive annotations, <em id="id4.1.1" class="ltx_emph ltx_font_italic">e.g.</em>, text captions and surface normal images.
Then, we train a customized ControlNet model upon this dataset to generate diverse human images and initial ground-truth labels. At the core of this step is that we can easily obtain numerous surface normal images from a 3D human parametric model, <em id="id4.1.2" class="ltx_emph ltx_font_italic">e.g.</em>, SMPL-X, by rendering the 3D mesh onto the image plane.
As there exists inevitable noise in the initial labels, we then
apply an off-the-shelf foundation segmentation model, <em id="id4.1.3" class="ltx_emph ltx_font_italic">i.e.</em>, SAM, to filter negative data samples.
Our data generation pipeline is flexible and customizable to facilitate different real-world tasks, <em id="id4.1.4" class="ltx_emph ltx_font_italic">e.g.</em>, ego-centric scenes and perspective-distortion scenes. By exclusively employing generative models, we generate large-scale in-the-wild human images and high-quality annotations, eliminating the need for real-world data collection. The generated dataset comprises 0.79M images with corresponding 3D annotations, covering versatile viewpoints, scenes, and human identities. We train various HPS regressors on top of the generated data and evaluate them on a wide range of benchmarks (3DPW, RICH, EgoBody, AGORA, SSP-3D) to verify the effectiveness of the generated data.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Keywords: </h6>Controllable Human Generation Synthetic Dataset 3D Human Reconstruction Diffusion Model

</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Estimating human pose and shape (HPS)Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib41" title="" class="ltx_ref">41</a>, <a href="#bib.bib36" title="" class="ltx_ref">36</a>, <a href="#bib.bib39" title="" class="ltx_ref">39</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> from a single RGB image is a core challenge in computer vision and has many applications in roboticsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib82" title="" class="ltx_ref">82</a>, <a href="#bib.bib75" title="" class="ltx_ref">75</a>]</cite>, computer graphicsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib90" title="" class="ltx_ref">90</a>, <a href="#bib.bib74" title="" class="ltx_ref">74</a>]</cite>, and digital content creationÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib76" title="" class="ltx_ref">76</a>]</cite>.
Current HPS estimation methods require well-annotated datasets to achieve good performance.
Unfortunately, collecting large-scale 3D human body data is time-consuming and expensive.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2403.11111/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="368" height="274" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.2.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S1.F1.3.2" class="ltx_text" style="font-size:90%;">Dataset appearance distributions of synthesized datasets and in-the-wild real-world datasets.</span></figcaption>
</figure>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">As shown inÂ <a href="#S1.T1" title="In 1 Introduction â€£ 3D Human Reconstruction in the Wild with Synthetic Data Using Generative ModelsWork was done when YG was visiting Zhejiang University. HC is the corresponding author." class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">1</span></a>, contemporary methodologies for acquiring precise 3D human body data predominantly employ two primary pipelines. The initial pipeline encompasses indoor motion capture (mocap) systems, such as marker-based and vision-based systems, utilized by numerous existing datasetsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>, <a href="#bib.bib71" title="" class="ltx_ref">71</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite> for human body attribute capture. Nonetheless, this mocap pipeline confronts two primary limitations: firstly, the intricate and costly nature of mocap systems, involving synchronization and operation complexities necessitating specialized expertise; secondly, the restricted number of actors in datasets, typically set against indoor or laboratory backgrounds, precluding large-scale human data collection in diverse settings.
The alternative pipeline involves synthesizing 3D human datasets via CG rendering <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib84" title="" class="ltx_ref">84</a>, <a href="#bib.bib79" title="" class="ltx_ref">79</a>]</cite>. However, this approach also presents twofold challenges: firstly, the collection costs incurred in acquiring high-quality 3D assets, including avatars and scene elements, alongside the requisite expertise in 3D rendering; secondly, ensuring realism in synthetic human bodies and background scenes, despite persistent appearance domain gaps between rendered and real-world images. This domain gap is discernible inÂ <a href="#S1.F1" title="In 1 Introduction â€£ 3D Human Reconstruction in the Wild with Synthetic Data Using Generative ModelsWork was done when YG was visiting Zhejiang University. HC is the corresponding author." class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">1</span></a>. where we visualize feature distributions extracted by DINO-v2Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite> through UMAP dimension reductionÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite>, with red points denoting real-world in-the-wild data and blue points representing CG-rendered data. Evidently, a conspicuous domain gap exists between real-world and CG-rendered data.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Since both mocap-based and CG-rendered datasets fail to provide diverse, complex in-the-wild images,
some researchers have considered capturing pseudo 3D ground truth by estimating from 2D clues or using additional sensors.
SMPLifyÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> proposed to fit the parameters of a 3D human model to the location of 2D keypoints.
EFTÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> introduced the Exemplar Fine-Tuning strategy by overfitting a pre-trained 3D pose regressor with 2D keypoint reprojection loss, taking the final output of the regressor as pseudo labels. Nevertheless, these methodologies encounter challenges in accurately generating camera parameters and body parameters, resulting in suboptimal performance on 3D human pose estimation benchmarks.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Contemporary generative models, <em id="S1.p4.1.1" class="ltx_emph ltx_font_italic">e.g.</em>, Stable Diffusion XLÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite> are trained on billion-scale text-image pairs. This extensive training regime has demonstrated efficacy in faithfully simulating real-world distributions.
In this paper, we focus on creating a new automatic and scalable synthetic data generation pipeline solely through generative models.
The challenge of the pipeline lies in the sampling of diverse data pairs from the prior distribution inherent to generative models.
Itâ€™s crucial to ensure diversity in pose, shape, and scene representation within generated human images, which is paramount for accurately simulating real-world human distribution.
Conversely, ensuring precise alignment between human images and generated annotations stands as another critical facet. This alignment is indispensable for facilitating the effective training of downstream tasks.
DiffusionHPCÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib78" title="" class="ltx_ref">78</a>]</cite> proposes a simple solution by providing diverse text prompts to the model and subsequently utilizing pre-trained 3D human pose estimation (HPS) models to obtain pseudo labels. Nonetheless, relying solely on textual prompts lacks the necessary granularity to precisely control aspects such as pose, shape, and spatial positioning of human bodies. Furthermore, the resultant 3D pseudo labels often exhibit significant levels of noise.
In contrast, we propose a method that begins by sampling SMPL-X parameters, which represent human body configurations, from large-scale human motion capture datasets such as AMASSÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>.
Subsequently, we utilize a random camera setup to render the human mesh into a normal map, thereby adding an extra input condition. This normal map provides supplementary information about the surface orientation of the human body.
Finally, we feed text prompts and normal maps to a customized ControlNetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib88" title="" class="ltx_ref">88</a>]</cite> for generating human images.
Notably, we collect over 1M image-text-normal pairs from LAION5BÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite> and MOYO-700MÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib71" title="" class="ltx_ref">71</a>]</cite>, Hi4DÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib86" title="" class="ltx_ref">86</a>]</cite>, and BEDLAMÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> to train the normal-based ControlNet.
As such, our method attains precise control over the visual characteristics of generated human images while simultaneously acquiring initial training data pairs derived from the input conditions and resultant human images.
Empirical investigations have uncovered instances of label noise within initial training data pairs, including occurrences where the generated human and input conditions form mirror pairs, or where the human head orientation in the image diverges from the input SMPL-X parameters. To mitigate this challenge, we leverage a pre-trained segmentation foundation model, namely SAMÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>, to forecast the human mask of the generated images. Subsequently, we compute the intersection-over-union (mIoU) between the ground-truth human mask and the predicted human mask, thereby enabling the filtration of data samples with an IoU below a predetermined threshold.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">With the aforementioned pipeline, we can finally generate a large-scale 3D human dataset in the wild, with around 0.79M samples at <math id="S1.p5.1.m1.1" class="ltx_Math" alttext="768\times 768" display="inline"><semantics id="S1.p5.1.m1.1a"><mrow id="S1.p5.1.m1.1.1" xref="S1.p5.1.m1.1.1.cmml"><mn id="S1.p5.1.m1.1.1.2" xref="S1.p5.1.m1.1.1.2.cmml">768</mn><mo lspace="0.222em" rspace="0.222em" id="S1.p5.1.m1.1.1.1" xref="S1.p5.1.m1.1.1.1.cmml">Ã—</mo><mn id="S1.p5.1.m1.1.1.3" xref="S1.p5.1.m1.1.1.3.cmml">768</mn></mrow><annotation-xml encoding="MathML-Content" id="S1.p5.1.m1.1b"><apply id="S1.p5.1.m1.1.1.cmml" xref="S1.p5.1.m1.1.1"><times id="S1.p5.1.m1.1.1.1.cmml" xref="S1.p5.1.m1.1.1.1"></times><cn type="integer" id="S1.p5.1.m1.1.1.2.cmml" xref="S1.p5.1.m1.1.1.2">768</cn><cn type="integer" id="S1.p5.1.m1.1.1.3.cmml" xref="S1.p5.1.m1.1.1.3">768</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p5.1.m1.1c">768\times 768</annotation></semantics></math> resolution. Compared to previous datasets, our pipeline can generate diverse human identities and various in-the-wild scenes. Notably, the pipeline is much cheaper than both mocap-based and CG-based counterparts and is scalable to generate 3D human datasets in the wild with versatile human identities and real-world scenes.</p>
</div>
<figure id="S1.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S1.T1.4.1.1" class="ltx_text" style="font-size:90%;">Table 1</span>: </span><span id="S1.T1.5.2" class="ltx_text" style="font-size:90%;">Comparison of different types of 3D HPS datasets.</span></figcaption>
<p id="S1.T1.2" class="ltx_p"><span id="S1.T1.2.2" class="ltx_text ltx_inline-block" style="width:433.6pt;">
<span id="S1.T1.2.2.2.2" class="ltx_inline-block ltx_transformed_outer" style="width:604.0pt;height:296.7pt;vertical-align:-10.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<span id="S1.T1.2.2.2.2.2" class="ltx_p"><span id="S1.T1.2.2.2.2.2.2" class="ltx_text">
<span id="S1.T1.2.2.2.2.2.2.2" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<span class="ltx_tbody">
<span id="S1.T1.2.2.2.2.2.2.2.3.1" class="ltx_tr">
<span id="S1.T1.2.2.2.2.2.2.2.3.1.1" class="ltx_td ltx_align_center ltx_align_top ltx_th ltx_th_row ltx_border_tt ltx_rowspan ltx_rowspan_2 ltx_colspan ltx_colspan_2"><span id="S1.T1.2.2.2.2.2.2.2.3.1.1.1" class="ltx_text">Data type</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.3.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S1.T1.2.2.2.2.2.2.2.3.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.3.1.2.1.1" class="ltx_p" style="width:90.0pt;"><span id="S1.T1.2.2.2.2.2.2.2.3.1.2.1.1.1" class="ltx_text">Datasets</span></span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.3.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S1.T1.2.2.2.2.2.2.2.3.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.3.1.3.1.1" class="ltx_p" style="width:40.0pt;"><span id="S1.T1.2.2.2.2.2.2.2.3.1.3.1.1.1" class="ltx_text">Subjects</span></span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.3.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S1.T1.2.2.2.2.2.2.2.3.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.3.1.4.1.1" class="ltx_p" style="width:30.0pt;"><span id="S1.T1.2.2.2.2.2.2.2.3.1.4.1.1.1" class="ltx_text">Scene</span></span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.3.1.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S1.T1.2.2.2.2.2.2.2.3.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.3.1.5.1.1" class="ltx_p" style="width:40.0pt;"><span id="S1.T1.2.2.2.2.2.2.2.3.1.5.1.1.1" class="ltx_text">Frame</span></span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.3.1.6" class="ltx_td ltx_align_center ltx_align_top ltx_border_tt ltx_colspan ltx_colspan_6">Modalities</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.4.2" class="ltx_tr">
<span id="S1.T1.2.2.2.2.2.2.2.4.2.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.4.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.4.2.1.1.1" class="ltx_p" style="width:90.0pt;"></span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.4.2.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.4.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.4.2.2.1.1" class="ltx_p" style="width:40.0pt;"></span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.4.2.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.4.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.4.2.3.1.1" class="ltx_p" style="width:30.0pt;"></span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.4.2.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.4.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.4.2.4.1.1" class="ltx_p" style="width:40.0pt;"></span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.4.2.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.2.2.2.2.2.2.2.4.2.5.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.4.2.5.1.1" class="ltx_p" style="width:30.0pt;">RGB</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.4.2.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.2.2.2.2.2.2.2.4.2.6.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.4.2.6.1.1" class="ltx_p" style="width:30.0pt;">D/N</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.4.2.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.2.2.2.2.2.2.2.4.2.7.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.4.2.7.1.1" class="ltx_p" style="width:30.0pt;">K2D</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.4.2.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.2.2.2.2.2.2.2.4.2.8.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.4.2.8.1.1" class="ltx_p" style="width:30.0pt;">K3D</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.4.2.9" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.2.2.2.2.2.2.2.4.2.9.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.4.2.9.1.1" class="ltx_p" style="width:30.0pt;">B.P.</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.4.2.10" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.2.2.2.2.2.2.2.4.2.10.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.4.2.10.1.1" class="ltx_p" style="width:30.0pt;">WB.P.</span>
</span></span></span>
<span id="S1.T1.2.2.2.2.2.2.2.5.3" class="ltx_tr">
<span id="S1.T1.2.2.2.2.2.2.2.5.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_t">
<span id="S1.T1.2.2.2.2.2.2.2.5.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.5.3.1.1.1" class="ltx_p" style="width:20.0pt;"><span id="S1.T1.2.2.2.2.2.2.2.5.3.1.1.1.1" class="ltx_text">
<span id="S1.T1.2.2.2.2.2.2.2.5.3.1.1.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:6.9pt;height:47.1pt;vertical-align:-47.1pt;"><span class="ltx_transformed_inner" style="width:47.1pt;transform:translate(-20.08pt,-27.03pt) rotate(-270deg) ;">
<span id="S1.T1.2.2.2.2.2.2.2.5.3.1.1.1.1.1.1" class="ltx_p">Real-world</span>
</span></span></span></span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.5.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_t">
<span id="S1.T1.2.2.2.2.2.2.2.5.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.5.3.2.1.1" class="ltx_p" style="width:60.0pt;"><span id="S1.T1.2.2.2.2.2.2.2.5.3.2.1.1.1" class="ltx_text">Monocular</span></span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.5.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.2.2.2.2.2.2.2.5.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.5.3.3.1.1" class="ltx_p" style="width:90.0pt;">COCOÂ <cite class="ltx_cite ltx_align_left ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite></span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.5.3.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.2.2.2.2.2.2.2.5.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.5.3.4.1.1" class="ltx_p" style="width:40.0pt;">-</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.5.3.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.2.2.2.2.2.2.2.5.3.5.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.5.3.5.1.1" class="ltx_p" style="width:30.0pt;">-</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.5.3.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.2.2.2.2.2.2.2.5.3.6.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.5.3.6.1.1" class="ltx_p" style="width:40.0pt;">104K</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.5.3.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.2.2.2.2.2.2.2.5.3.7.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.5.3.7.1.1" class="ltx_p" style="width:30.0pt;">âœ“</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.5.3.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.2.2.2.2.2.2.2.5.3.8.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.5.3.8.1.1" class="ltx_p" style="width:30.0pt;"></span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.5.3.9" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.2.2.2.2.2.2.2.5.3.9.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.5.3.9.1.1" class="ltx_p" style="width:30.0pt;">âœ“</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.5.3.10" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.2.2.2.2.2.2.2.5.3.10.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.5.3.10.1.1" class="ltx_p" style="width:30.0pt;"></span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.5.3.11" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.2.2.2.2.2.2.2.5.3.11.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.5.3.11.1.1" class="ltx_p" style="width:30.0pt;"></span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.5.3.12" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.2.2.2.2.2.2.2.5.3.12.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.5.3.12.1.1" class="ltx_p" style="width:30.0pt;"></span>
</span></span></span>
<span id="S1.T1.2.2.2.2.2.2.2.6.4" class="ltx_tr">
<span id="S1.T1.2.2.2.2.2.2.2.6.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row">
<span id="S1.T1.2.2.2.2.2.2.2.6.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.6.4.1.1.1" class="ltx_p" style="width:20.0pt;"></span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.6.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row">
<span id="S1.T1.2.2.2.2.2.2.2.6.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.6.4.2.1.1" class="ltx_p" style="width:60.0pt;"></span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.6.4.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.6.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.6.4.3.1.1" class="ltx_p" style="width:90.0pt;">MPI-INF-3DHPÂ <cite class="ltx_cite ltx_align_left ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite></span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.6.4.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.6.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.6.4.4.1.1" class="ltx_p" style="width:40.0pt;">8</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.6.4.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.6.4.5.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.6.4.5.1.1" class="ltx_p" style="width:30.0pt;">-</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.6.4.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.6.4.6.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.6.4.6.1.1" class="ltx_p" style="width:40.0pt;">1.4M</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.6.4.7" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.6.4.7.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.6.4.7.1.1" class="ltx_p" style="width:30.0pt;">âœ“</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.6.4.8" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.6.4.8.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.6.4.8.1.1" class="ltx_p" style="width:30.0pt;"></span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.6.4.9" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.6.4.9.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.6.4.9.1.1" class="ltx_p" style="width:30.0pt;">âœ“</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.6.4.10" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.6.4.10.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.6.4.10.1.1" class="ltx_p" style="width:30.0pt;">âœ“</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.6.4.11" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.6.4.11.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.6.4.11.1.1" class="ltx_p" style="width:30.0pt;"></span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.6.4.12" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.6.4.12.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.6.4.12.1.1" class="ltx_p" style="width:30.0pt;"></span>
</span></span></span>
<span id="S1.T1.2.2.2.2.2.2.2.7.5" class="ltx_tr">
<span id="S1.T1.2.2.2.2.2.2.2.7.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row">
<span id="S1.T1.2.2.2.2.2.2.2.7.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.7.5.1.1.1" class="ltx_p" style="width:20.0pt;"></span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.7.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row">
<span id="S1.T1.2.2.2.2.2.2.2.7.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.7.5.2.1.1" class="ltx_p" style="width:60.0pt;"></span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.7.5.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.7.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.7.5.3.1.1" class="ltx_p" style="width:90.0pt;">MPIIÂ <cite class="ltx_cite ltx_align_left ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite></span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.7.5.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.7.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.7.5.4.1.1" class="ltx_p" style="width:40.0pt;">-</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.7.5.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.7.5.5.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.7.5.5.1.1" class="ltx_p" style="width:30.0pt;">-</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.7.5.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.7.5.6.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.7.5.6.1.1" class="ltx_p" style="width:40.0pt;">24K</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.7.5.7" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.7.5.7.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.7.5.7.1.1" class="ltx_p" style="width:30.0pt;">âœ“</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.7.5.8" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.7.5.8.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.7.5.8.1.1" class="ltx_p" style="width:30.0pt;"></span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.7.5.9" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.7.5.9.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.7.5.9.1.1" class="ltx_p" style="width:30.0pt;">âœ“</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.7.5.10" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.7.5.10.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.7.5.10.1.1" class="ltx_p" style="width:30.0pt;"></span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.7.5.11" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.7.5.11.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.7.5.11.1.1" class="ltx_p" style="width:30.0pt;"></span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.7.5.12" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.7.5.12.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.7.5.12.1.1" class="ltx_p" style="width:30.0pt;"></span>
</span></span></span>
<span id="S1.T1.2.2.2.2.2.2.2.8.6" class="ltx_tr">
<span id="S1.T1.2.2.2.2.2.2.2.8.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row">
<span id="S1.T1.2.2.2.2.2.2.2.8.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.8.6.1.1.1" class="ltx_p" style="width:20.0pt;"></span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.8.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_t">
<span id="S1.T1.2.2.2.2.2.2.2.8.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.8.6.2.1.1" class="ltx_p" style="width:60.0pt;"><span id="S1.T1.2.2.2.2.2.2.2.8.6.2.1.1.1" class="ltx_text">Multi-view</span></span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.8.6.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.2.2.2.2.2.2.2.8.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.8.6.3.1.1" class="ltx_p" style="width:90.0pt;">HuMMan</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.8.6.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.2.2.2.2.2.2.2.8.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.8.6.4.1.1" class="ltx_p" style="width:40.0pt;">1000</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.8.6.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.2.2.2.2.2.2.2.8.6.5.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.8.6.5.1.1" class="ltx_p" style="width:30.0pt;">1</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.8.6.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.2.2.2.2.2.2.2.8.6.6.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.8.6.6.1.1" class="ltx_p" style="width:40.0pt;">60M</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.8.6.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.2.2.2.2.2.2.2.8.6.7.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.8.6.7.1.1" class="ltx_p" style="width:30.0pt;">âœ“</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.8.6.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.2.2.2.2.2.2.2.8.6.8.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.8.6.8.1.1" class="ltx_p" style="width:30.0pt;">âœ“</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.8.6.9" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.2.2.2.2.2.2.2.8.6.9.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.8.6.9.1.1" class="ltx_p" style="width:30.0pt;">âœ“</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.8.6.10" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.2.2.2.2.2.2.2.8.6.10.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.8.6.10.1.1" class="ltx_p" style="width:30.0pt;">âœ“</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.8.6.11" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.2.2.2.2.2.2.2.8.6.11.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.8.6.11.1.1" class="ltx_p" style="width:30.0pt;">âœ“</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.8.6.12" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.2.2.2.2.2.2.2.8.6.12.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.8.6.12.1.1" class="ltx_p" style="width:30.0pt;">âœ“</span>
</span></span></span>
<span id="S1.T1.2.2.2.2.2.2.2.9.7" class="ltx_tr">
<span id="S1.T1.2.2.2.2.2.2.2.9.7.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row">
<span id="S1.T1.2.2.2.2.2.2.2.9.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.9.7.1.1.1" class="ltx_p" style="width:20.0pt;"></span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.9.7.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row">
<span id="S1.T1.2.2.2.2.2.2.2.9.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.9.7.2.1.1" class="ltx_p" style="width:60.0pt;"></span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.9.7.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.9.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.9.7.3.1.1" class="ltx_p" style="width:90.0pt;">ZJU MocapÂ <cite class="ltx_cite ltx_align_left ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite></span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.9.7.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.9.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.9.7.4.1.1" class="ltx_p" style="width:40.0pt;">6</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.9.7.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.9.7.5.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.9.7.5.1.1" class="ltx_p" style="width:30.0pt;">1</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.9.7.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.9.7.6.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.9.7.6.1.1" class="ltx_p" style="width:40.0pt;">&gt;1K</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.9.7.7" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.9.7.7.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.9.7.7.1.1" class="ltx_p" style="width:30.0pt;">âœ“</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.9.7.8" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.9.7.8.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.9.7.8.1.1" class="ltx_p" style="width:30.0pt;"></span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.9.7.9" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.9.7.9.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.9.7.9.1.1" class="ltx_p" style="width:30.0pt;">âœ“</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.9.7.10" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.9.7.10.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.9.7.10.1.1" class="ltx_p" style="width:30.0pt;">âœ“</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.9.7.11" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.9.7.11.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.9.7.11.1.1" class="ltx_p" style="width:30.0pt;">âœ“</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.9.7.12" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.9.7.12.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.9.7.12.1.1" class="ltx_p" style="width:30.0pt;"></span>
</span></span></span>
<span id="S1.T1.2.2.2.2.2.2.2.10.8" class="ltx_tr">
<span id="S1.T1.2.2.2.2.2.2.2.10.8.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row">
<span id="S1.T1.2.2.2.2.2.2.2.10.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.10.8.1.1.1" class="ltx_p" style="width:20.0pt;"></span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.10.8.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row">
<span id="S1.T1.2.2.2.2.2.2.2.10.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.10.8.2.1.1" class="ltx_p" style="width:60.0pt;"></span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.10.8.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.10.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.10.8.3.1.1" class="ltx_p" style="width:90.0pt;">AIST++Â <cite class="ltx_cite ltx_align_left ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite></span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.10.8.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.10.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.10.8.4.1.1" class="ltx_p" style="width:40.0pt;">30</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.10.8.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.10.8.5.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.10.8.5.1.1" class="ltx_p" style="width:30.0pt;">1</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.10.8.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.10.8.6.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.10.8.6.1.1" class="ltx_p" style="width:40.0pt;">10.1M</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.10.8.7" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.10.8.7.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.10.8.7.1.1" class="ltx_p" style="width:30.0pt;">âœ“</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.10.8.8" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.10.8.8.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.10.8.8.1.1" class="ltx_p" style="width:30.0pt;"></span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.10.8.9" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.10.8.9.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.10.8.9.1.1" class="ltx_p" style="width:30.0pt;">âœ“</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.10.8.10" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.10.8.10.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.10.8.10.1.1" class="ltx_p" style="width:30.0pt;">âœ“</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.10.8.11" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.10.8.11.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.10.8.11.1.1" class="ltx_p" style="width:30.0pt;">âœ“</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.10.8.12" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.10.8.12.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.10.8.12.1.1" class="ltx_p" style="width:30.0pt;"></span>
</span></span></span>
<span id="S1.T1.2.2.2.2.2.2.2.11.9" class="ltx_tr">
<span id="S1.T1.2.2.2.2.2.2.2.11.9.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row">
<span id="S1.T1.2.2.2.2.2.2.2.11.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.11.9.1.1.1" class="ltx_p" style="width:20.0pt;"></span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.11.9.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_t">
<span id="S1.T1.2.2.2.2.2.2.2.11.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.11.9.2.1.1" class="ltx_p" style="width:60.0pt;"><span id="S1.T1.2.2.2.2.2.2.2.11.9.2.1.1.1" class="ltx_text">MOCAP</span></span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.11.9.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.2.2.2.2.2.2.2.11.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.11.9.3.1.1" class="ltx_p" style="width:90.0pt;">3DPWÂ <cite class="ltx_cite ltx_align_left ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite></span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.11.9.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.2.2.2.2.2.2.2.11.9.4.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.11.9.4.1.1" class="ltx_p" style="width:40.0pt;">5</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.11.9.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.2.2.2.2.2.2.2.11.9.5.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.11.9.5.1.1" class="ltx_p" style="width:30.0pt;">&lt;60</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.11.9.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.2.2.2.2.2.2.2.11.9.6.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.11.9.6.1.1" class="ltx_p" style="width:40.0pt;">51K</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.11.9.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.2.2.2.2.2.2.2.11.9.7.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.11.9.7.1.1" class="ltx_p" style="width:30.0pt;">âœ“</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.11.9.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.2.2.2.2.2.2.2.11.9.8.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.11.9.8.1.1" class="ltx_p" style="width:30.0pt;"></span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.11.9.9" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.2.2.2.2.2.2.2.11.9.9.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.11.9.9.1.1" class="ltx_p" style="width:30.0pt;">âœ“</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.11.9.10" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.2.2.2.2.2.2.2.11.9.10.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.11.9.10.1.1" class="ltx_p" style="width:30.0pt;">âœ“</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.11.9.11" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.2.2.2.2.2.2.2.11.9.11.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.11.9.11.1.1" class="ltx_p" style="width:30.0pt;">âœ“</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.11.9.12" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t"></span></span>
<span id="S1.T1.2.2.2.2.2.2.2.12.10" class="ltx_tr">
<span id="S1.T1.2.2.2.2.2.2.2.12.10.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row">
<span id="S1.T1.2.2.2.2.2.2.2.12.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.12.10.1.1.1" class="ltx_p" style="width:20.0pt;"></span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.12.10.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row">
<span id="S1.T1.2.2.2.2.2.2.2.12.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.12.10.2.1.1" class="ltx_p" style="width:60.0pt;"></span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.12.10.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.12.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.12.10.3.1.1" class="ltx_p" style="width:90.0pt;">Human3.6MÂ <cite class="ltx_cite ltx_align_left ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite></span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.12.10.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.12.10.4.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.12.10.4.1.1" class="ltx_p" style="width:40.0pt;">11</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.12.10.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.12.10.5.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.12.10.5.1.1" class="ltx_p" style="width:30.0pt;">1</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.12.10.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.12.10.6.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.12.10.6.1.1" class="ltx_p" style="width:40.0pt;">3.6M</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.12.10.7" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.12.10.7.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.12.10.7.1.1" class="ltx_p" style="width:30.0pt;">âœ“</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.12.10.8" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.12.10.8.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.12.10.8.1.1" class="ltx_p" style="width:30.0pt;">âœ“</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.12.10.9" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.12.10.9.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.12.10.9.1.1" class="ltx_p" style="width:30.0pt;">âœ“</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.12.10.10" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.12.10.10.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.12.10.10.1.1" class="ltx_p" style="width:30.0pt;">âœ“</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.12.10.11" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.12.10.11.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.12.10.11.1.1" class="ltx_p" style="width:30.0pt;">âœ“</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.12.10.12" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.12.10.12.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.12.10.12.1.1" class="ltx_p" style="width:30.0pt;"></span>
</span></span></span>
<span id="S1.T1.2.2.2.2.2.2.2.13.11" class="ltx_tr">
<span id="S1.T1.2.2.2.2.2.2.2.13.11.1" class="ltx_td ltx_align_center ltx_align_top ltx_th ltx_th_row ltx_border_t ltx_rowspan ltx_rowspan_3 ltx_colspan ltx_colspan_2"><span id="S1.T1.2.2.2.2.2.2.2.13.11.1.1" class="ltx_text">Synthetic</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.13.11.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.2.2.2.2.2.2.2.13.11.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.13.11.2.1.1" class="ltx_p" style="width:90.0pt;">AGORAÂ <cite class="ltx_cite ltx_align_left ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite></span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.13.11.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.2.2.2.2.2.2.2.13.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.13.11.3.1.1" class="ltx_p" style="width:40.0pt;">&gt;350</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.13.11.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.2.2.2.2.2.2.2.13.11.4.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.13.11.4.1.1" class="ltx_p" style="width:30.0pt;">-</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.13.11.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.2.2.2.2.2.2.2.13.11.5.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.13.11.5.1.1" class="ltx_p" style="width:40.0pt;">18K</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.13.11.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.2.2.2.2.2.2.2.13.11.6.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.13.11.6.1.1" class="ltx_p" style="width:30.0pt;">âœ“</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.13.11.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.2.2.2.2.2.2.2.13.11.7.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.13.11.7.1.1" class="ltx_p" style="width:30.0pt;">âœ“</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.13.11.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.2.2.2.2.2.2.2.13.11.8.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.13.11.8.1.1" class="ltx_p" style="width:30.0pt;">âœ“</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.13.11.9" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.2.2.2.2.2.2.2.13.11.9.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.13.11.9.1.1" class="ltx_p" style="width:30.0pt;">âœ“</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.13.11.10" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.2.2.2.2.2.2.2.13.11.10.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.13.11.10.1.1" class="ltx_p" style="width:30.0pt;">âœ“</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.13.11.11" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S1.T1.2.2.2.2.2.2.2.13.11.11.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.13.11.11.1.1" class="ltx_p" style="width:30.0pt;">âœ“</span>
</span></span></span>
<span id="S1.T1.2.2.2.2.2.2.2.14.12" class="ltx_tr">
<span id="S1.T1.2.2.2.2.2.2.2.14.12.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.14.12.1.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.14.12.1.1.1" class="ltx_p" style="width:90.0pt;">SynbodyÂ <cite class="ltx_cite ltx_align_left ltx_citemacro_cite">[<a href="#bib.bib84" title="" class="ltx_ref">84</a>]</cite></span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.14.12.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.14.12.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.14.12.2.1.1" class="ltx_p" style="width:40.0pt;">10K</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.14.12.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.14.12.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.14.12.3.1.1" class="ltx_p" style="width:30.0pt;">6</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.14.12.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.14.12.4.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.14.12.4.1.1" class="ltx_p" style="width:40.0pt;">1.2M</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.14.12.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.14.12.5.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.14.12.5.1.1" class="ltx_p" style="width:30.0pt;">âœ“</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.14.12.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.14.12.6.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.14.12.6.1.1" class="ltx_p" style="width:30.0pt;">âœ“</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.14.12.7" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.14.12.7.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.14.12.7.1.1" class="ltx_p" style="width:30.0pt;">âœ“</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.14.12.8" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.14.12.8.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.14.12.8.1.1" class="ltx_p" style="width:30.0pt;">âœ“</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.14.12.9" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.14.12.9.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.14.12.9.1.1" class="ltx_p" style="width:30.0pt;">âœ“</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.14.12.10" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.14.12.10.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.14.12.10.1.1" class="ltx_p" style="width:30.0pt;">âœ“</span>
</span></span></span>
<span id="S1.T1.2.2.2.2.2.2.2.15.13" class="ltx_tr">
<span id="S1.T1.2.2.2.2.2.2.2.15.13.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.15.13.1.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.15.13.1.1.1" class="ltx_p" style="width:90.0pt;">BEDLAMÂ <cite class="ltx_cite ltx_align_left ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite></span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.15.13.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.15.13.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.15.13.2.1.1" class="ltx_p" style="width:40.0pt;">217</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.15.13.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.15.13.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.15.13.3.1.1" class="ltx_p" style="width:30.0pt;">103</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.15.13.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.15.13.4.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.15.13.4.1.1" class="ltx_p" style="width:40.0pt;">280K</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.15.13.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.15.13.5.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.15.13.5.1.1" class="ltx_p" style="width:30.0pt;">âœ“</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.15.13.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.15.13.6.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.15.13.6.1.1" class="ltx_p" style="width:30.0pt;">âœ“</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.15.13.7" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.15.13.7.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.15.13.7.1.1" class="ltx_p" style="width:30.0pt;">âœ“</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.15.13.8" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.15.13.8.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.15.13.8.1.1" class="ltx_p" style="width:30.0pt;">âœ“</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.15.13.9" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.15.13.9.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.15.13.9.1.1" class="ltx_p" style="width:30.0pt;">âœ“</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.15.13.10" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.15.13.10.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.15.13.10.1.1" class="ltx_p" style="width:30.0pt;">âœ“</span>
</span></span></span>
<span id="S1.T1.2.2.2.2.2.2.2.2" class="ltx_tr">
<span id="S1.T1.2.2.2.2.2.2.2.2.3" class="ltx_td ltx_align_center ltx_align_top ltx_th ltx_th_row ltx_border_bb ltx_border_t ltx_colspan ltx_colspan_2">Generated</span>
<span id="S1.T1.2.2.2.2.2.2.2.2.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S1.T1.2.2.2.2.2.2.2.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.2.4.1.1" class="ltx_p" style="width:90.0pt;">HumanWild</span>
</span></span>
<span id="S1.T1.1.1.1.1.1.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S1.T1.1.1.1.1.1.1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.1.1.1.1.1.1.1.1.1.1.1" class="ltx_p" style="width:40.0pt;"><math id="S1.T1.1.1.1.1.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\infty" display="inline"><semantics id="S1.T1.1.1.1.1.1.1.1.1.1.1.1.m1.1a"><mi mathvariant="normal" id="S1.T1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1" xref="S1.T1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">âˆ</mi><annotation-xml encoding="MathML-Content" id="S1.T1.1.1.1.1.1.1.1.1.1.1.1.m1.1b"><infinity id="S1.T1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S1.T1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1"></infinity></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.1.1.1.1.1.1.1.1.1.1.1.m1.1c">\infty</annotation></semantics></math></span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S1.T1.2.2.2.2.2.2.2.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.2.2.1.1" class="ltx_p" style="width:30.0pt;"><math id="S1.T1.2.2.2.2.2.2.2.2.2.1.1.m1.1" class="ltx_Math" alttext="\infty" display="inline"><semantics id="S1.T1.2.2.2.2.2.2.2.2.2.1.1.m1.1a"><mi mathvariant="normal" id="S1.T1.2.2.2.2.2.2.2.2.2.1.1.m1.1.1" xref="S1.T1.2.2.2.2.2.2.2.2.2.1.1.m1.1.1.cmml">âˆ</mi><annotation-xml encoding="MathML-Content" id="S1.T1.2.2.2.2.2.2.2.2.2.1.1.m1.1b"><infinity id="S1.T1.2.2.2.2.2.2.2.2.2.1.1.m1.1.1.cmml" xref="S1.T1.2.2.2.2.2.2.2.2.2.1.1.m1.1.1"></infinity></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.2.2.2.2.2.2.2.2.2.1.1.m1.1c">\infty</annotation></semantics></math></span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.2.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S1.T1.2.2.2.2.2.2.2.2.5.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.2.5.1.1" class="ltx_p" style="width:40.0pt;">0.79M</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.2.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S1.T1.2.2.2.2.2.2.2.2.6.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.2.6.1.1" class="ltx_p" style="width:30.0pt;">âœ“</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.2.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S1.T1.2.2.2.2.2.2.2.2.7.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.2.7.1.1" class="ltx_p" style="width:30.0pt;">âœ“</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.2.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S1.T1.2.2.2.2.2.2.2.2.8.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.2.8.1.1" class="ltx_p" style="width:30.0pt;">âœ“</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.2.9" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S1.T1.2.2.2.2.2.2.2.2.9.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.2.9.1.1" class="ltx_p" style="width:30.0pt;">âœ“</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.2.10" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S1.T1.2.2.2.2.2.2.2.2.10.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.2.10.1.1" class="ltx_p" style="width:30.0pt;">âœ“</span>
</span></span>
<span id="S1.T1.2.2.2.2.2.2.2.2.11" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S1.T1.2.2.2.2.2.2.2.2.11.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.2.2.2.2.2.2.2.2.11.1.1" class="ltx_p" style="width:30.0pt;">âœ“</span>
</span></span></span>
</span>
</span></span></span>
</span></span></span></p>
</figure>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">Our contributions can be summarised as follows. 1). We propose a fully automatic pipeline to synthesize realistic and diverse human images with well-aligned annotations, including SMPL-X parameters and text descriptions. The dataset can empower a wide range of downstream perception tasks by rendering SMPL-X mesh into corresponding annotation format, <em id="S1.p6.1.1" class="ltx_emph ltx_font_italic">e.g.</em>, human pose and shape estimation, human part segmentation, and human surface normal estimation. 2). We verify the quality of the generated dataset on the 3D HPS task.
Experimental results indicate that the proposed pipeline is compositional with CG-rendered data, enhancing performance across multiple challenging HPS benchmarks under consistent settings.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Works</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Human Pose and Shape Estimation Datasets</h3>

<div id="S2.SS1.p1" class="ltx_para ltx_noindent">
<p id="S2.SS1.p1.1" class="ltx_p"><span id="S2.SS1.p1.1.1" class="ltx_text ltx_font_bold">Real-world human pose data</span> plays a pivotal role in achieving precision and realism in 3D HPS tasks.
High-quality 3D human data is typically captured using advanced motion capture devices like Inertial Measurement Units (IMUs)Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>, <a href="#bib.bib44" title="" class="ltx_ref">44</a>, <a href="#bib.bib66" title="" class="ltx_ref">66</a>]</cite> or Optical sensorsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>, designed to capture precise marker movements or joint rotations.
Nevertheless, the utilization of these tools may present challenges attributable to factors such as financial expenses, intricacies in configuration, and spatial constraints.
To facilitate these challenges, researchers have explored alternative methods to capture pseudo labels from diverse image types, including single-view imagesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>, RGBDÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>, and multi-viewÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>, eliminating the need for motion capture gear. SLOPER4DÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> consolidates data from IMU sensors, LiDAR, and RGB information to construct a large-scale urban human-scene dataset. Such methods often leverage perception models to derive 2D cues from images, which are further optimized by a 3D joint re-projecting loss.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para ltx_noindent">
<p id="S2.SS1.p2.1" class="ltx_p"><span id="S2.SS1.p2.1.1" class="ltx_text ltx_font_bold">Synthetic human pose datasets,</span> developed with computer graphic techniques, has been used for many years.
SURREALÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib72" title="" class="ltx_ref">72</a>]</cite> applies human skin and cloth textures to bare SMPL meshes, which lack realistic details. AGORAÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite> uses high-quality static human scans for image rendering, but this routine also suffers from a high workload of scanning and rigging.
However, rendering realistic manipulatable synthetic human datasets involves many challenges, including the need for diverse virtual properties for realistic data.
BEDLAMÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> and SynbodyÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib84" title="" class="ltx_ref">84</a>]</cite> augment SMPL-X meshesÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite> with diverse hair models and skin textures, facilitating the simulation of physically realistic cloth and hair dynamics.
These processes can be resource-intensive.
Furthermore, the use of rendering engines demands many professional skills. Thus, the rendering process can be computationally expensive and time-consuming.</p>
</div>
<div id="S2.SS1.p3" class="ltx_para ltx_noindent">
<p id="S2.SS1.p3.1" class="ltx_p"><span id="S2.SS1.p3.1.1" class="ltx_text ltx_font_bold">Controllable human image generation</span> has gained greate traction with the advancement of Stable DiffusionÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib60" title="" class="ltx_ref">60</a>, <a href="#bib.bib88" title="" class="ltx_ref">88</a>]</cite>. Text2HumanÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite> uses a diffusion-based transformer sampler in response to text prompts and predicts indices from a hierarchical texture-aware codebook to conditionally generate realistic human images.
HumanSDÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite> introduces a skeleton-guided diffusion model with a novel heatmap loss for pose-conditioned human image generation. HyperHumanÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite> proposes to jointly denoise surface normal and depth along with the synthesized RGB image conditioned on text prompt and pose skeleton.</p>
</div>
<div id="S2.SS1.p4" class="ltx_para ltx_noindent">
<p id="S2.SS1.p4.1" class="ltx_p"><span id="S2.SS1.p4.1.1" class="ltx_text ltx_font_bold">Generative models for perception tasks</span> is a promising field, which aims to enhance the performance of perception models with the capability of generative models.
Several pioneer works have proposed to generate perception datasets with diffusion models.
For instance, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib73" title="" class="ltx_ref">73</a>]</cite> verified the effectiveness of datasets synthesized by generative models in fundamental perception tasks, <em id="S2.SS1.p4.1.2" class="ltx_emph ltx_font_italic">i.e.</em>, image classification, and object detection.
StableRepÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib69" title="" class="ltx_ref">69</a>]</cite> argues that training modern self-supervised methods on synthetic images from Stable Diffusion Models can yield impressive results. The learned representations often surpass those learned from real images of the same sample size.
DatasetDMÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib80" title="" class="ltx_ref">80</a>]</cite> leverages the prior of stable diffusion model by training customized perception decoders upon the output of the UNetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref">61</a>]</cite>, and then employs it to generate pseudo labels for semantic segmentation, depth estimation, and 2D human pose estimation.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Method</h2>

<figure id="S3.F2" class="ltx_figure"><img src="/html/2403.11111/assets/x2.png" id="S3.F2.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="442" height="143" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F2.3.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S3.F2.4.2" class="ltx_text" style="font-size:90%;">
The overall
pipeline of the proposed controllable data generation. Our ControlNet could be conditioned on fine-grained normal maps and structual text prompts. Our text prompt includes human appearance, pose, and indoor/outdoor scene types based on w. or w/o background normals.
</span></figcaption>
</figure>
<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">We present <math id="S3.p1.1.m1.1" class="ltx_Math" alttext="\tt HumanWild" display="inline"><semantics id="S3.p1.1.m1.1a"><mi id="S3.p1.1.m1.1.1" xref="S3.p1.1.m1.1.1.cmml">ğ™·ğšğš–ğšŠğš—ğš†ğš’ğš•ğš</mi><annotation-xml encoding="MathML-Content" id="S3.p1.1.m1.1b"><ci id="S3.p1.1.m1.1.1.cmml" xref="S3.p1.1.m1.1.1">ğ™·ğšğš–ğšŠğš—ğš†ğš’ğš•ğš</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.1.m1.1c">\tt HumanWild</annotation></semantics></math>, a simple yet effective approach for creating versatile human body images and corresponding perception annotations in a fully automated fashion, which can be used for many downstream human perception tasks, such as 2D/3D human pose and shape estimation (seeÂ <a href="#S3.F2" title="In 3 Method â€£ 3D Human Reconstruction in the Wild with Synthetic Data Using Generative ModelsWork was done when YG was visiting Zhejiang University. HC is the corresponding author." class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">2</span></a>). The core idea of the proposed pipeline is creating large-scale image-mesh-caption pairs by incorporating 2D generative models, <em id="S3.p1.1.1" class="ltx_emph ltx_font_italic">e.g.</em>, ControlNetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib88" title="" class="ltx_ref">88</a>]</cite> and 3D human parametric modelsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite>. For the sake of completeness, we give a brief review of the controllable text-to-image (T2I), image-to-image (I2I) generative models and the 3D human parametric model, SMPL-X <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite> inÂ <a href="#S3.SS1" title="3.1 Prerequisites â€£ 3 Method â€£ 3D Human Reconstruction in the Wild with Synthetic Data Using Generative ModelsWork was done when YG was visiting Zhejiang University. HC is the corresponding author." class="ltx_ref"><span class="ltx_text ltx_ref_tag">Sec.</span>Â <span class="ltx_text ltx_ref_tag">3.1</span></a>.
In the following subsections, we illustrate how we generate the initial human image-annotation pairs inÂ <a href="#S3.SS2" title="3.2 Surface Normal Estimation â€£ 3 Method â€£ 3D Human Reconstruction in the Wild with Synthetic Data Using Generative ModelsWork was done when YG was visiting Zhejiang University. HC is the corresponding author." class="ltx_ref"><span class="ltx_text ltx_ref_tag">Sec.</span>Â <span class="ltx_text ltx_ref_tag">3.2</span></a> andÂ <a href="#S3.SS3" title="3.3 Initial Human Image and Annotation Generation â€£ 3 Method â€£ 3D Human Reconstruction in the Wild with Synthetic Data Using Generative ModelsWork was done when YG was visiting Zhejiang University. HC is the corresponding author." class="ltx_ref"><span class="ltx_text ltx_ref_tag">Sec.</span>Â <span class="ltx_text ltx_ref_tag">3.3</span></a>. Finally, we show how we filter out the noisy labels to get high-quality training pairs inÂ <a href="#S3.SS4" title="3.4 Label Denoising â€£ 3 Method â€£ 3D Human Reconstruction in the Wild with Synthetic Data Using Generative ModelsWork was done when YG was visiting Zhejiang University. HC is the corresponding author." class="ltx_ref"><span class="ltx_text ltx_ref_tag">Sec.</span>Â <span class="ltx_text ltx_ref_tag">3.4</span></a>.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Prerequisites</h3>

<div id="S3.SS1.p1" class="ltx_para ltx_noindent">
<p id="S3.SS1.p1.3" class="ltx_p"><span id="S3.SS1.p1.3.1" class="ltx_text ltx_font_bold">Stable Diffusion Models</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib60" title="" class="ltx_ref">60</a>, <a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite> are text-to-image diffusion models capable of generating near photo-realistic images given any text input. It consists of an autoencoder and a U-Net.
During training, U-Net model is designed to take a textual description and noise map <math id="S3.SS1.p1.1.m1.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S3.SS1.p1.1.m1.1a"><mi id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">Ïµ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><ci id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">italic-Ïµ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">\epsilon</annotation></semantics></math> as input, learning a forward noising process by gradually transforming an image latent variable, denoted as <math id="S3.SS1.p1.2.m2.1" class="ltx_Math" alttext="\bar{y}\in\mathbb{R}^{h\times w\times c}" display="inline"><semantics id="S3.SS1.p1.2.m2.1a"><mrow id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml"><mover accent="true" id="S3.SS1.p1.2.m2.1.1.2" xref="S3.SS1.p1.2.m2.1.1.2.cmml"><mi id="S3.SS1.p1.2.m2.1.1.2.2" xref="S3.SS1.p1.2.m2.1.1.2.2.cmml">y</mi><mo id="S3.SS1.p1.2.m2.1.1.2.1" xref="S3.SS1.p1.2.m2.1.1.2.1.cmml">Â¯</mo></mover><mo id="S3.SS1.p1.2.m2.1.1.1" xref="S3.SS1.p1.2.m2.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS1.p1.2.m2.1.1.3" xref="S3.SS1.p1.2.m2.1.1.3.cmml"><mi id="S3.SS1.p1.2.m2.1.1.3.2" xref="S3.SS1.p1.2.m2.1.1.3.2.cmml">â„</mi><mrow id="S3.SS1.p1.2.m2.1.1.3.3" xref="S3.SS1.p1.2.m2.1.1.3.3.cmml"><mi id="S3.SS1.p1.2.m2.1.1.3.3.2" xref="S3.SS1.p1.2.m2.1.1.3.3.2.cmml">h</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p1.2.m2.1.1.3.3.1" xref="S3.SS1.p1.2.m2.1.1.3.3.1.cmml">Ã—</mo><mi id="S3.SS1.p1.2.m2.1.1.3.3.3" xref="S3.SS1.p1.2.m2.1.1.3.3.3.cmml">w</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p1.2.m2.1.1.3.3.1a" xref="S3.SS1.p1.2.m2.1.1.3.3.1.cmml">Ã—</mo><mi id="S3.SS1.p1.2.m2.1.1.3.3.4" xref="S3.SS1.p1.2.m2.1.1.3.3.4.cmml">c</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><apply id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1"><in id="S3.SS1.p1.2.m2.1.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1.1"></in><apply id="S3.SS1.p1.2.m2.1.1.2.cmml" xref="S3.SS1.p1.2.m2.1.1.2"><ci id="S3.SS1.p1.2.m2.1.1.2.1.cmml" xref="S3.SS1.p1.2.m2.1.1.2.1">Â¯</ci><ci id="S3.SS1.p1.2.m2.1.1.2.2.cmml" xref="S3.SS1.p1.2.m2.1.1.2.2">ğ‘¦</ci></apply><apply id="S3.SS1.p1.2.m2.1.1.3.cmml" xref="S3.SS1.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.1.1.3.1.cmml" xref="S3.SS1.p1.2.m2.1.1.3">superscript</csymbol><ci id="S3.SS1.p1.2.m2.1.1.3.2.cmml" xref="S3.SS1.p1.2.m2.1.1.3.2">â„</ci><apply id="S3.SS1.p1.2.m2.1.1.3.3.cmml" xref="S3.SS1.p1.2.m2.1.1.3.3"><times id="S3.SS1.p1.2.m2.1.1.3.3.1.cmml" xref="S3.SS1.p1.2.m2.1.1.3.3.1"></times><ci id="S3.SS1.p1.2.m2.1.1.3.3.2.cmml" xref="S3.SS1.p1.2.m2.1.1.3.3.2">â„</ci><ci id="S3.SS1.p1.2.m2.1.1.3.3.3.cmml" xref="S3.SS1.p1.2.m2.1.1.3.3.3">ğ‘¤</ci><ci id="S3.SS1.p1.2.m2.1.1.3.3.4.cmml" xref="S3.SS1.p1.2.m2.1.1.3.3.4">ğ‘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">\bar{y}\in\mathbb{R}^{h\times w\times c}</annotation></semantics></math> into a noise map <math id="S3.SS1.p1.3.m3.1" class="ltx_Math" alttext="\bar{y_{t}}\in\mathbb{R}^{h\times w\times c}" display="inline"><semantics id="S3.SS1.p1.3.m3.1a"><mrow id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml"><mover accent="true" id="S3.SS1.p1.3.m3.1.1.2" xref="S3.SS1.p1.3.m3.1.1.2.cmml"><msub id="S3.SS1.p1.3.m3.1.1.2.2" xref="S3.SS1.p1.3.m3.1.1.2.2.cmml"><mi id="S3.SS1.p1.3.m3.1.1.2.2.2" xref="S3.SS1.p1.3.m3.1.1.2.2.2.cmml">y</mi><mi id="S3.SS1.p1.3.m3.1.1.2.2.3" xref="S3.SS1.p1.3.m3.1.1.2.2.3.cmml">t</mi></msub><mo id="S3.SS1.p1.3.m3.1.1.2.1" xref="S3.SS1.p1.3.m3.1.1.2.1.cmml">Â¯</mo></mover><mo id="S3.SS1.p1.3.m3.1.1.1" xref="S3.SS1.p1.3.m3.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS1.p1.3.m3.1.1.3" xref="S3.SS1.p1.3.m3.1.1.3.cmml"><mi id="S3.SS1.p1.3.m3.1.1.3.2" xref="S3.SS1.p1.3.m3.1.1.3.2.cmml">â„</mi><mrow id="S3.SS1.p1.3.m3.1.1.3.3" xref="S3.SS1.p1.3.m3.1.1.3.3.cmml"><mi id="S3.SS1.p1.3.m3.1.1.3.3.2" xref="S3.SS1.p1.3.m3.1.1.3.3.2.cmml">h</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p1.3.m3.1.1.3.3.1" xref="S3.SS1.p1.3.m3.1.1.3.3.1.cmml">Ã—</mo><mi id="S3.SS1.p1.3.m3.1.1.3.3.3" xref="S3.SS1.p1.3.m3.1.1.3.3.3.cmml">w</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p1.3.m3.1.1.3.3.1a" xref="S3.SS1.p1.3.m3.1.1.3.3.1.cmml">Ã—</mo><mi id="S3.SS1.p1.3.m3.1.1.3.3.4" xref="S3.SS1.p1.3.m3.1.1.3.3.4.cmml">c</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><apply id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1"><in id="S3.SS1.p1.3.m3.1.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1.1"></in><apply id="S3.SS1.p1.3.m3.1.1.2.cmml" xref="S3.SS1.p1.3.m3.1.1.2"><ci id="S3.SS1.p1.3.m3.1.1.2.1.cmml" xref="S3.SS1.p1.3.m3.1.1.2.1">Â¯</ci><apply id="S3.SS1.p1.3.m3.1.1.2.2.cmml" xref="S3.SS1.p1.3.m3.1.1.2.2"><csymbol cd="ambiguous" id="S3.SS1.p1.3.m3.1.1.2.2.1.cmml" xref="S3.SS1.p1.3.m3.1.1.2.2">subscript</csymbol><ci id="S3.SS1.p1.3.m3.1.1.2.2.2.cmml" xref="S3.SS1.p1.3.m3.1.1.2.2.2">ğ‘¦</ci><ci id="S3.SS1.p1.3.m3.1.1.2.2.3.cmml" xref="S3.SS1.p1.3.m3.1.1.2.2.3">ğ‘¡</ci></apply></apply><apply id="S3.SS1.p1.3.m3.1.1.3.cmml" xref="S3.SS1.p1.3.m3.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.3.m3.1.1.3.1.cmml" xref="S3.SS1.p1.3.m3.1.1.3">superscript</csymbol><ci id="S3.SS1.p1.3.m3.1.1.3.2.cmml" xref="S3.SS1.p1.3.m3.1.1.3.2">â„</ci><apply id="S3.SS1.p1.3.m3.1.1.3.3.cmml" xref="S3.SS1.p1.3.m3.1.1.3.3"><times id="S3.SS1.p1.3.m3.1.1.3.3.1.cmml" xref="S3.SS1.p1.3.m3.1.1.3.3.1"></times><ci id="S3.SS1.p1.3.m3.1.1.3.3.2.cmml" xref="S3.SS1.p1.3.m3.1.1.3.3.2">â„</ci><ci id="S3.SS1.p1.3.m3.1.1.3.3.3.cmml" xref="S3.SS1.p1.3.m3.1.1.3.3.3">ğ‘¤</ci><ci id="S3.SS1.p1.3.m3.1.1.3.3.4.cmml" xref="S3.SS1.p1.3.m3.1.1.3.3.4">ğ‘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">\bar{y_{t}}\in\mathbb{R}^{h\times w\times c}</annotation></semantics></math>:</p>
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.3" class="ltx_Math" alttext="y_{t}=\sqrt{\bar{\alpha}_{t}}y+\sqrt{1-\bar{\alpha}_{t}}\epsilon_{t}\quad\epsilon\sim\mathcal{N}(\mathbf{0},\mathbf{I})," display="block"><semantics id="S3.E1.m1.3a"><mrow id="S3.E1.m1.3.3.1"><mrow id="S3.E1.m1.3.3.1.1.2" xref="S3.E1.m1.3.3.1.1.3.cmml"><mrow id="S3.E1.m1.3.3.1.1.1.1" xref="S3.E1.m1.3.3.1.1.1.1.cmml"><msub id="S3.E1.m1.3.3.1.1.1.1.2" xref="S3.E1.m1.3.3.1.1.1.1.2.cmml"><mi id="S3.E1.m1.3.3.1.1.1.1.2.2" xref="S3.E1.m1.3.3.1.1.1.1.2.2.cmml">y</mi><mi id="S3.E1.m1.3.3.1.1.1.1.2.3" xref="S3.E1.m1.3.3.1.1.1.1.2.3.cmml">t</mi></msub><mo id="S3.E1.m1.3.3.1.1.1.1.1" xref="S3.E1.m1.3.3.1.1.1.1.1.cmml">=</mo><mrow id="S3.E1.m1.3.3.1.1.1.1.3" xref="S3.E1.m1.3.3.1.1.1.1.3.cmml"><mrow id="S3.E1.m1.3.3.1.1.1.1.3.2" xref="S3.E1.m1.3.3.1.1.1.1.3.2.cmml"><msqrt id="S3.E1.m1.3.3.1.1.1.1.3.2.2" xref="S3.E1.m1.3.3.1.1.1.1.3.2.2.cmml"><msub id="S3.E1.m1.3.3.1.1.1.1.3.2.2.2" xref="S3.E1.m1.3.3.1.1.1.1.3.2.2.2.cmml"><mover accent="true" id="S3.E1.m1.3.3.1.1.1.1.3.2.2.2.2" xref="S3.E1.m1.3.3.1.1.1.1.3.2.2.2.2.cmml"><mi id="S3.E1.m1.3.3.1.1.1.1.3.2.2.2.2.2" xref="S3.E1.m1.3.3.1.1.1.1.3.2.2.2.2.2.cmml">Î±</mi><mo id="S3.E1.m1.3.3.1.1.1.1.3.2.2.2.2.1" xref="S3.E1.m1.3.3.1.1.1.1.3.2.2.2.2.1.cmml">Â¯</mo></mover><mi id="S3.E1.m1.3.3.1.1.1.1.3.2.2.2.3" xref="S3.E1.m1.3.3.1.1.1.1.3.2.2.2.3.cmml">t</mi></msub></msqrt><mo lspace="0em" rspace="0em" id="S3.E1.m1.3.3.1.1.1.1.3.2.1" xref="S3.E1.m1.3.3.1.1.1.1.3.2.1.cmml">â€‹</mo><mi id="S3.E1.m1.3.3.1.1.1.1.3.2.3" xref="S3.E1.m1.3.3.1.1.1.1.3.2.3.cmml">y</mi></mrow><mo id="S3.E1.m1.3.3.1.1.1.1.3.1" xref="S3.E1.m1.3.3.1.1.1.1.3.1.cmml">+</mo><mrow id="S3.E1.m1.3.3.1.1.1.1.3.3" xref="S3.E1.m1.3.3.1.1.1.1.3.3.cmml"><msqrt id="S3.E1.m1.3.3.1.1.1.1.3.3.2" xref="S3.E1.m1.3.3.1.1.1.1.3.3.2.cmml"><mrow id="S3.E1.m1.3.3.1.1.1.1.3.3.2.2" xref="S3.E1.m1.3.3.1.1.1.1.3.3.2.2.cmml"><mn id="S3.E1.m1.3.3.1.1.1.1.3.3.2.2.2" xref="S3.E1.m1.3.3.1.1.1.1.3.3.2.2.2.cmml">1</mn><mo id="S3.E1.m1.3.3.1.1.1.1.3.3.2.2.1" xref="S3.E1.m1.3.3.1.1.1.1.3.3.2.2.1.cmml">âˆ’</mo><msub id="S3.E1.m1.3.3.1.1.1.1.3.3.2.2.3" xref="S3.E1.m1.3.3.1.1.1.1.3.3.2.2.3.cmml"><mover accent="true" id="S3.E1.m1.3.3.1.1.1.1.3.3.2.2.3.2" xref="S3.E1.m1.3.3.1.1.1.1.3.3.2.2.3.2.cmml"><mi id="S3.E1.m1.3.3.1.1.1.1.3.3.2.2.3.2.2" xref="S3.E1.m1.3.3.1.1.1.1.3.3.2.2.3.2.2.cmml">Î±</mi><mo id="S3.E1.m1.3.3.1.1.1.1.3.3.2.2.3.2.1" xref="S3.E1.m1.3.3.1.1.1.1.3.3.2.2.3.2.1.cmml">Â¯</mo></mover><mi id="S3.E1.m1.3.3.1.1.1.1.3.3.2.2.3.3" xref="S3.E1.m1.3.3.1.1.1.1.3.3.2.2.3.3.cmml">t</mi></msub></mrow></msqrt><mo lspace="0em" rspace="0em" id="S3.E1.m1.3.3.1.1.1.1.3.3.1" xref="S3.E1.m1.3.3.1.1.1.1.3.3.1.cmml">â€‹</mo><msub id="S3.E1.m1.3.3.1.1.1.1.3.3.3" xref="S3.E1.m1.3.3.1.1.1.1.3.3.3.cmml"><mi id="S3.E1.m1.3.3.1.1.1.1.3.3.3.2" xref="S3.E1.m1.3.3.1.1.1.1.3.3.3.2.cmml">Ïµ</mi><mi id="S3.E1.m1.3.3.1.1.1.1.3.3.3.3" xref="S3.E1.m1.3.3.1.1.1.1.3.3.3.3.cmml">t</mi></msub></mrow></mrow></mrow><mspace width="1em" id="S3.E1.m1.3.3.1.1.2.3" xref="S3.E1.m1.3.3.1.1.3a.cmml"></mspace><mrow id="S3.E1.m1.3.3.1.1.2.2" xref="S3.E1.m1.3.3.1.1.2.2.cmml"><mi id="S3.E1.m1.3.3.1.1.2.2.2" xref="S3.E1.m1.3.3.1.1.2.2.2.cmml">Ïµ</mi><mo id="S3.E1.m1.3.3.1.1.2.2.1" xref="S3.E1.m1.3.3.1.1.2.2.1.cmml">âˆ¼</mo><mrow id="S3.E1.m1.3.3.1.1.2.2.3" xref="S3.E1.m1.3.3.1.1.2.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.3.3.1.1.2.2.3.2" xref="S3.E1.m1.3.3.1.1.2.2.3.2.cmml">ğ’©</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.3.3.1.1.2.2.3.1" xref="S3.E1.m1.3.3.1.1.2.2.3.1.cmml">â€‹</mo><mrow id="S3.E1.m1.3.3.1.1.2.2.3.3.2" xref="S3.E1.m1.3.3.1.1.2.2.3.3.1.cmml"><mo stretchy="false" id="S3.E1.m1.3.3.1.1.2.2.3.3.2.1" xref="S3.E1.m1.3.3.1.1.2.2.3.3.1.cmml">(</mo><mn id="S3.E1.m1.1.1" xref="S3.E1.m1.1.1.cmml">ğŸ</mn><mo id="S3.E1.m1.3.3.1.1.2.2.3.3.2.2" xref="S3.E1.m1.3.3.1.1.2.2.3.3.1.cmml">,</mo><mi id="S3.E1.m1.2.2" xref="S3.E1.m1.2.2.cmml">ğˆ</mi><mo stretchy="false" id="S3.E1.m1.3.3.1.1.2.2.3.3.2.3" xref="S3.E1.m1.3.3.1.1.2.2.3.3.1.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S3.E1.m1.3.3.1.2">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.3b"><apply id="S3.E1.m1.3.3.1.1.3.cmml" xref="S3.E1.m1.3.3.1.1.2"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.1.1.3a.cmml" xref="S3.E1.m1.3.3.1.1.2.3">formulae-sequence</csymbol><apply id="S3.E1.m1.3.3.1.1.1.1.cmml" xref="S3.E1.m1.3.3.1.1.1.1"><eq id="S3.E1.m1.3.3.1.1.1.1.1.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1"></eq><apply id="S3.E1.m1.3.3.1.1.1.1.2.cmml" xref="S3.E1.m1.3.3.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.1.1.1.1.2.1.cmml" xref="S3.E1.m1.3.3.1.1.1.1.2">subscript</csymbol><ci id="S3.E1.m1.3.3.1.1.1.1.2.2.cmml" xref="S3.E1.m1.3.3.1.1.1.1.2.2">ğ‘¦</ci><ci id="S3.E1.m1.3.3.1.1.1.1.2.3.cmml" xref="S3.E1.m1.3.3.1.1.1.1.2.3">ğ‘¡</ci></apply><apply id="S3.E1.m1.3.3.1.1.1.1.3.cmml" xref="S3.E1.m1.3.3.1.1.1.1.3"><plus id="S3.E1.m1.3.3.1.1.1.1.3.1.cmml" xref="S3.E1.m1.3.3.1.1.1.1.3.1"></plus><apply id="S3.E1.m1.3.3.1.1.1.1.3.2.cmml" xref="S3.E1.m1.3.3.1.1.1.1.3.2"><times id="S3.E1.m1.3.3.1.1.1.1.3.2.1.cmml" xref="S3.E1.m1.3.3.1.1.1.1.3.2.1"></times><apply id="S3.E1.m1.3.3.1.1.1.1.3.2.2.cmml" xref="S3.E1.m1.3.3.1.1.1.1.3.2.2"><root id="S3.E1.m1.3.3.1.1.1.1.3.2.2a.cmml" xref="S3.E1.m1.3.3.1.1.1.1.3.2.2"></root><apply id="S3.E1.m1.3.3.1.1.1.1.3.2.2.2.cmml" xref="S3.E1.m1.3.3.1.1.1.1.3.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.1.1.1.1.3.2.2.2.1.cmml" xref="S3.E1.m1.3.3.1.1.1.1.3.2.2.2">subscript</csymbol><apply id="S3.E1.m1.3.3.1.1.1.1.3.2.2.2.2.cmml" xref="S3.E1.m1.3.3.1.1.1.1.3.2.2.2.2"><ci id="S3.E1.m1.3.3.1.1.1.1.3.2.2.2.2.1.cmml" xref="S3.E1.m1.3.3.1.1.1.1.3.2.2.2.2.1">Â¯</ci><ci id="S3.E1.m1.3.3.1.1.1.1.3.2.2.2.2.2.cmml" xref="S3.E1.m1.3.3.1.1.1.1.3.2.2.2.2.2">ğ›¼</ci></apply><ci id="S3.E1.m1.3.3.1.1.1.1.3.2.2.2.3.cmml" xref="S3.E1.m1.3.3.1.1.1.1.3.2.2.2.3">ğ‘¡</ci></apply></apply><ci id="S3.E1.m1.3.3.1.1.1.1.3.2.3.cmml" xref="S3.E1.m1.3.3.1.1.1.1.3.2.3">ğ‘¦</ci></apply><apply id="S3.E1.m1.3.3.1.1.1.1.3.3.cmml" xref="S3.E1.m1.3.3.1.1.1.1.3.3"><times id="S3.E1.m1.3.3.1.1.1.1.3.3.1.cmml" xref="S3.E1.m1.3.3.1.1.1.1.3.3.1"></times><apply id="S3.E1.m1.3.3.1.1.1.1.3.3.2.cmml" xref="S3.E1.m1.3.3.1.1.1.1.3.3.2"><root id="S3.E1.m1.3.3.1.1.1.1.3.3.2a.cmml" xref="S3.E1.m1.3.3.1.1.1.1.3.3.2"></root><apply id="S3.E1.m1.3.3.1.1.1.1.3.3.2.2.cmml" xref="S3.E1.m1.3.3.1.1.1.1.3.3.2.2"><minus id="S3.E1.m1.3.3.1.1.1.1.3.3.2.2.1.cmml" xref="S3.E1.m1.3.3.1.1.1.1.3.3.2.2.1"></minus><cn type="integer" id="S3.E1.m1.3.3.1.1.1.1.3.3.2.2.2.cmml" xref="S3.E1.m1.3.3.1.1.1.1.3.3.2.2.2">1</cn><apply id="S3.E1.m1.3.3.1.1.1.1.3.3.2.2.3.cmml" xref="S3.E1.m1.3.3.1.1.1.1.3.3.2.2.3"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.1.1.1.1.3.3.2.2.3.1.cmml" xref="S3.E1.m1.3.3.1.1.1.1.3.3.2.2.3">subscript</csymbol><apply id="S3.E1.m1.3.3.1.1.1.1.3.3.2.2.3.2.cmml" xref="S3.E1.m1.3.3.1.1.1.1.3.3.2.2.3.2"><ci id="S3.E1.m1.3.3.1.1.1.1.3.3.2.2.3.2.1.cmml" xref="S3.E1.m1.3.3.1.1.1.1.3.3.2.2.3.2.1">Â¯</ci><ci id="S3.E1.m1.3.3.1.1.1.1.3.3.2.2.3.2.2.cmml" xref="S3.E1.m1.3.3.1.1.1.1.3.3.2.2.3.2.2">ğ›¼</ci></apply><ci id="S3.E1.m1.3.3.1.1.1.1.3.3.2.2.3.3.cmml" xref="S3.E1.m1.3.3.1.1.1.1.3.3.2.2.3.3">ğ‘¡</ci></apply></apply></apply><apply id="S3.E1.m1.3.3.1.1.1.1.3.3.3.cmml" xref="S3.E1.m1.3.3.1.1.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.1.1.1.1.3.3.3.1.cmml" xref="S3.E1.m1.3.3.1.1.1.1.3.3.3">subscript</csymbol><ci id="S3.E1.m1.3.3.1.1.1.1.3.3.3.2.cmml" xref="S3.E1.m1.3.3.1.1.1.1.3.3.3.2">italic-Ïµ</ci><ci id="S3.E1.m1.3.3.1.1.1.1.3.3.3.3.cmml" xref="S3.E1.m1.3.3.1.1.1.1.3.3.3.3">ğ‘¡</ci></apply></apply></apply></apply><apply id="S3.E1.m1.3.3.1.1.2.2.cmml" xref="S3.E1.m1.3.3.1.1.2.2"><csymbol cd="latexml" id="S3.E1.m1.3.3.1.1.2.2.1.cmml" xref="S3.E1.m1.3.3.1.1.2.2.1">similar-to</csymbol><ci id="S3.E1.m1.3.3.1.1.2.2.2.cmml" xref="S3.E1.m1.3.3.1.1.2.2.2">italic-Ïµ</ci><apply id="S3.E1.m1.3.3.1.1.2.2.3.cmml" xref="S3.E1.m1.3.3.1.1.2.2.3"><times id="S3.E1.m1.3.3.1.1.2.2.3.1.cmml" xref="S3.E1.m1.3.3.1.1.2.2.3.1"></times><ci id="S3.E1.m1.3.3.1.1.2.2.3.2.cmml" xref="S3.E1.m1.3.3.1.1.2.2.3.2">ğ’©</ci><interval closure="open" id="S3.E1.m1.3.3.1.1.2.2.3.3.1.cmml" xref="S3.E1.m1.3.3.1.1.2.2.3.3.2"><cn type="integer" id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1">0</cn><ci id="S3.E1.m1.2.2.cmml" xref="S3.E1.m1.2.2">ğˆ</ci></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.3c">y_{t}=\sqrt{\bar{\alpha}_{t}}y+\sqrt{1-\bar{\alpha}_{t}}\epsilon_{t}\quad\epsilon\sim\mathcal{N}(\mathbf{0},\mathbf{I}),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.p1.8" class="ltx_p">where <math id="S3.SS1.p1.4.m1.3" class="ltx_Math" alttext="t=[1,\cdots,T]" display="inline"><semantics id="S3.SS1.p1.4.m1.3a"><mrow id="S3.SS1.p1.4.m1.3.4" xref="S3.SS1.p1.4.m1.3.4.cmml"><mi id="S3.SS1.p1.4.m1.3.4.2" xref="S3.SS1.p1.4.m1.3.4.2.cmml">t</mi><mo id="S3.SS1.p1.4.m1.3.4.1" xref="S3.SS1.p1.4.m1.3.4.1.cmml">=</mo><mrow id="S3.SS1.p1.4.m1.3.4.3.2" xref="S3.SS1.p1.4.m1.3.4.3.1.cmml"><mo stretchy="false" id="S3.SS1.p1.4.m1.3.4.3.2.1" xref="S3.SS1.p1.4.m1.3.4.3.1.cmml">[</mo><mn id="S3.SS1.p1.4.m1.1.1" xref="S3.SS1.p1.4.m1.1.1.cmml">1</mn><mo id="S3.SS1.p1.4.m1.3.4.3.2.2" xref="S3.SS1.p1.4.m1.3.4.3.1.cmml">,</mo><mi mathvariant="normal" id="S3.SS1.p1.4.m1.2.2" xref="S3.SS1.p1.4.m1.2.2.cmml">â‹¯</mi><mo id="S3.SS1.p1.4.m1.3.4.3.2.3" xref="S3.SS1.p1.4.m1.3.4.3.1.cmml">,</mo><mi id="S3.SS1.p1.4.m1.3.3" xref="S3.SS1.p1.4.m1.3.3.cmml">T</mi><mo stretchy="false" id="S3.SS1.p1.4.m1.3.4.3.2.4" xref="S3.SS1.p1.4.m1.3.4.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m1.3b"><apply id="S3.SS1.p1.4.m1.3.4.cmml" xref="S3.SS1.p1.4.m1.3.4"><eq id="S3.SS1.p1.4.m1.3.4.1.cmml" xref="S3.SS1.p1.4.m1.3.4.1"></eq><ci id="S3.SS1.p1.4.m1.3.4.2.cmml" xref="S3.SS1.p1.4.m1.3.4.2">ğ‘¡</ci><list id="S3.SS1.p1.4.m1.3.4.3.1.cmml" xref="S3.SS1.p1.4.m1.3.4.3.2"><cn type="integer" id="S3.SS1.p1.4.m1.1.1.cmml" xref="S3.SS1.p1.4.m1.1.1">1</cn><ci id="S3.SS1.p1.4.m1.2.2.cmml" xref="S3.SS1.p1.4.m1.2.2">â‹¯</ci><ci id="S3.SS1.p1.4.m1.3.3.cmml" xref="S3.SS1.p1.4.m1.3.3">ğ‘‡</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m1.3c">t=[1,\cdots,T]</annotation></semantics></math> is the timestep for controlling the noise level and <math id="S3.SS1.p1.5.m2.1" class="ltx_Math" alttext="{\alpha}_{t}" display="inline"><semantics id="S3.SS1.p1.5.m2.1a"><msub id="S3.SS1.p1.5.m2.1.1" xref="S3.SS1.p1.5.m2.1.1.cmml"><mi id="S3.SS1.p1.5.m2.1.1.2" xref="S3.SS1.p1.5.m2.1.1.2.cmml">Î±</mi><mi id="S3.SS1.p1.5.m2.1.1.3" xref="S3.SS1.p1.5.m2.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.5.m2.1b"><apply id="S3.SS1.p1.5.m2.1.1.cmml" xref="S3.SS1.p1.5.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m2.1.1.1.cmml" xref="S3.SS1.p1.5.m2.1.1">subscript</csymbol><ci id="S3.SS1.p1.5.m2.1.1.2.cmml" xref="S3.SS1.p1.5.m2.1.1.2">ğ›¼</ci><ci id="S3.SS1.p1.5.m2.1.1.3.cmml" xref="S3.SS1.p1.5.m2.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.5.m2.1c">{\alpha}_{t}</annotation></semantics></math> is the noise schedulerÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>, <math id="S3.SS1.p1.6.m3.1" class="ltx_Math" alttext="h" display="inline"><semantics id="S3.SS1.p1.6.m3.1a"><mi id="S3.SS1.p1.6.m3.1.1" xref="S3.SS1.p1.6.m3.1.1.cmml">h</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.6.m3.1b"><ci id="S3.SS1.p1.6.m3.1.1.cmml" xref="S3.SS1.p1.6.m3.1.1">â„</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.6.m3.1c">h</annotation></semantics></math>, <math id="S3.SS1.p1.7.m4.1" class="ltx_Math" alttext="w" display="inline"><semantics id="S3.SS1.p1.7.m4.1a"><mi id="S3.SS1.p1.7.m4.1.1" xref="S3.SS1.p1.7.m4.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.7.m4.1b"><ci id="S3.SS1.p1.7.m4.1.1.cmml" xref="S3.SS1.p1.7.m4.1.1">ğ‘¤</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.7.m4.1c">w</annotation></semantics></math> and <math id="S3.SS1.p1.8.m5.1" class="ltx_Math" alttext="c" display="inline"><semantics id="S3.SS1.p1.8.m5.1a"><mi id="S3.SS1.p1.8.m5.1.1" xref="S3.SS1.p1.8.m5.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.8.m5.1b"><ci id="S3.SS1.p1.8.m5.1.1.cmml" xref="S3.SS1.p1.8.m5.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.8.m5.1c">c</annotation></semantics></math> are the height, width, and channels of the latent variable. During inference, UNet takes a noise map as input and generates an approximation of the original latent variable using a denoise schedulerÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib67" title="" class="ltx_ref">67</a>]</cite>.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para ltx_noindent">
<p id="S3.SS1.p2.7" class="ltx_p"><span id="S3.SS1.p2.7.1" class="ltx_text ltx_font_bold">SMPL-X</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite>, defined as <math id="S3.SS1.p2.1.m1.6" class="ltx_Math" alttext="M(\boldsymbol{\beta},\boldsymbol{\theta},\boldsymbol{\psi}):\mathbb{R}^{|\theta|\times|\beta|\times|\psi|}\rightarrow\mathbb{R}^{3N}" display="inline"><semantics id="S3.SS1.p2.1.m1.6a"><mrow id="S3.SS1.p2.1.m1.6.7" xref="S3.SS1.p2.1.m1.6.7.cmml"><mrow id="S3.SS1.p2.1.m1.6.7.2" xref="S3.SS1.p2.1.m1.6.7.2.cmml"><mi id="S3.SS1.p2.1.m1.6.7.2.2" xref="S3.SS1.p2.1.m1.6.7.2.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p2.1.m1.6.7.2.1" xref="S3.SS1.p2.1.m1.6.7.2.1.cmml">â€‹</mo><mrow id="S3.SS1.p2.1.m1.6.7.2.3.2" xref="S3.SS1.p2.1.m1.6.7.2.3.1.cmml"><mo stretchy="false" id="S3.SS1.p2.1.m1.6.7.2.3.2.1" xref="S3.SS1.p2.1.m1.6.7.2.3.1.cmml">(</mo><mi id="S3.SS1.p2.1.m1.4.4" xref="S3.SS1.p2.1.m1.4.4.cmml">ğœ·</mi><mo id="S3.SS1.p2.1.m1.6.7.2.3.2.2" xref="S3.SS1.p2.1.m1.6.7.2.3.1.cmml">,</mo><mi id="S3.SS1.p2.1.m1.5.5" xref="S3.SS1.p2.1.m1.5.5.cmml">ğœ½</mi><mo id="S3.SS1.p2.1.m1.6.7.2.3.2.3" xref="S3.SS1.p2.1.m1.6.7.2.3.1.cmml">,</mo><mi id="S3.SS1.p2.1.m1.6.6" xref="S3.SS1.p2.1.m1.6.6.cmml">ğ</mi><mo rspace="0.278em" stretchy="false" id="S3.SS1.p2.1.m1.6.7.2.3.2.4" xref="S3.SS1.p2.1.m1.6.7.2.3.1.cmml">)</mo></mrow></mrow><mo rspace="0.278em" id="S3.SS1.p2.1.m1.6.7.1" xref="S3.SS1.p2.1.m1.6.7.1.cmml">:</mo><mrow id="S3.SS1.p2.1.m1.6.7.3" xref="S3.SS1.p2.1.m1.6.7.3.cmml"><msup id="S3.SS1.p2.1.m1.6.7.3.2" xref="S3.SS1.p2.1.m1.6.7.3.2.cmml"><mi id="S3.SS1.p2.1.m1.6.7.3.2.2" xref="S3.SS1.p2.1.m1.6.7.3.2.2.cmml">â„</mi><mrow id="S3.SS1.p2.1.m1.3.3.3" xref="S3.SS1.p2.1.m1.3.3.3.cmml"><mrow id="S3.SS1.p2.1.m1.3.3.3.5.2" xref="S3.SS1.p2.1.m1.3.3.3.5.1.cmml"><mo stretchy="false" id="S3.SS1.p2.1.m1.3.3.3.5.2.1" xref="S3.SS1.p2.1.m1.3.3.3.5.1.1.cmml">|</mo><mi id="S3.SS1.p2.1.m1.1.1.1.1" xref="S3.SS1.p2.1.m1.1.1.1.1.cmml">Î¸</mi><mo rspace="0.055em" stretchy="false" id="S3.SS1.p2.1.m1.3.3.3.5.2.2" xref="S3.SS1.p2.1.m1.3.3.3.5.1.1.cmml">|</mo></mrow><mo rspace="0.222em" id="S3.SS1.p2.1.m1.3.3.3.4" xref="S3.SS1.p2.1.m1.3.3.3.4.cmml">Ã—</mo><mrow id="S3.SS1.p2.1.m1.3.3.3.6.2" xref="S3.SS1.p2.1.m1.3.3.3.6.1.cmml"><mo stretchy="false" id="S3.SS1.p2.1.m1.3.3.3.6.2.1" xref="S3.SS1.p2.1.m1.3.3.3.6.1.1.cmml">|</mo><mi id="S3.SS1.p2.1.m1.2.2.2.2" xref="S3.SS1.p2.1.m1.2.2.2.2.cmml">Î²</mi><mo rspace="0.055em" stretchy="false" id="S3.SS1.p2.1.m1.3.3.3.6.2.2" xref="S3.SS1.p2.1.m1.3.3.3.6.1.1.cmml">|</mo></mrow><mo rspace="0.222em" id="S3.SS1.p2.1.m1.3.3.3.4a" xref="S3.SS1.p2.1.m1.3.3.3.4.cmml">Ã—</mo><mrow id="S3.SS1.p2.1.m1.3.3.3.7.2" xref="S3.SS1.p2.1.m1.3.3.3.7.1.cmml"><mo stretchy="false" id="S3.SS1.p2.1.m1.3.3.3.7.2.1" xref="S3.SS1.p2.1.m1.3.3.3.7.1.1.cmml">|</mo><mi id="S3.SS1.p2.1.m1.3.3.3.3" xref="S3.SS1.p2.1.m1.3.3.3.3.cmml">Ïˆ</mi><mo stretchy="false" id="S3.SS1.p2.1.m1.3.3.3.7.2.2" xref="S3.SS1.p2.1.m1.3.3.3.7.1.1.cmml">|</mo></mrow></mrow></msup><mo stretchy="false" id="S3.SS1.p2.1.m1.6.7.3.1" xref="S3.SS1.p2.1.m1.6.7.3.1.cmml">â†’</mo><msup id="S3.SS1.p2.1.m1.6.7.3.3" xref="S3.SS1.p2.1.m1.6.7.3.3.cmml"><mi id="S3.SS1.p2.1.m1.6.7.3.3.2" xref="S3.SS1.p2.1.m1.6.7.3.3.2.cmml">â„</mi><mrow id="S3.SS1.p2.1.m1.6.7.3.3.3" xref="S3.SS1.p2.1.m1.6.7.3.3.3.cmml"><mn id="S3.SS1.p2.1.m1.6.7.3.3.3.2" xref="S3.SS1.p2.1.m1.6.7.3.3.3.2.cmml">3</mn><mo lspace="0em" rspace="0em" id="S3.SS1.p2.1.m1.6.7.3.3.3.1" xref="S3.SS1.p2.1.m1.6.7.3.3.3.1.cmml">â€‹</mo><mi id="S3.SS1.p2.1.m1.6.7.3.3.3.3" xref="S3.SS1.p2.1.m1.6.7.3.3.3.3.cmml">N</mi></mrow></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.6b"><apply id="S3.SS1.p2.1.m1.6.7.cmml" xref="S3.SS1.p2.1.m1.6.7"><ci id="S3.SS1.p2.1.m1.6.7.1.cmml" xref="S3.SS1.p2.1.m1.6.7.1">:</ci><apply id="S3.SS1.p2.1.m1.6.7.2.cmml" xref="S3.SS1.p2.1.m1.6.7.2"><times id="S3.SS1.p2.1.m1.6.7.2.1.cmml" xref="S3.SS1.p2.1.m1.6.7.2.1"></times><ci id="S3.SS1.p2.1.m1.6.7.2.2.cmml" xref="S3.SS1.p2.1.m1.6.7.2.2">ğ‘€</ci><vector id="S3.SS1.p2.1.m1.6.7.2.3.1.cmml" xref="S3.SS1.p2.1.m1.6.7.2.3.2"><ci id="S3.SS1.p2.1.m1.4.4.cmml" xref="S3.SS1.p2.1.m1.4.4">ğœ·</ci><ci id="S3.SS1.p2.1.m1.5.5.cmml" xref="S3.SS1.p2.1.m1.5.5">ğœ½</ci><ci id="S3.SS1.p2.1.m1.6.6.cmml" xref="S3.SS1.p2.1.m1.6.6">ğ</ci></vector></apply><apply id="S3.SS1.p2.1.m1.6.7.3.cmml" xref="S3.SS1.p2.1.m1.6.7.3"><ci id="S3.SS1.p2.1.m1.6.7.3.1.cmml" xref="S3.SS1.p2.1.m1.6.7.3.1">â†’</ci><apply id="S3.SS1.p2.1.m1.6.7.3.2.cmml" xref="S3.SS1.p2.1.m1.6.7.3.2"><csymbol cd="ambiguous" id="S3.SS1.p2.1.m1.6.7.3.2.1.cmml" xref="S3.SS1.p2.1.m1.6.7.3.2">superscript</csymbol><ci id="S3.SS1.p2.1.m1.6.7.3.2.2.cmml" xref="S3.SS1.p2.1.m1.6.7.3.2.2">â„</ci><apply id="S3.SS1.p2.1.m1.3.3.3.cmml" xref="S3.SS1.p2.1.m1.3.3.3"><times id="S3.SS1.p2.1.m1.3.3.3.4.cmml" xref="S3.SS1.p2.1.m1.3.3.3.4"></times><apply id="S3.SS1.p2.1.m1.3.3.3.5.1.cmml" xref="S3.SS1.p2.1.m1.3.3.3.5.2"><abs id="S3.SS1.p2.1.m1.3.3.3.5.1.1.cmml" xref="S3.SS1.p2.1.m1.3.3.3.5.2.1"></abs><ci id="S3.SS1.p2.1.m1.1.1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1.1.1">ğœƒ</ci></apply><apply id="S3.SS1.p2.1.m1.3.3.3.6.1.cmml" xref="S3.SS1.p2.1.m1.3.3.3.6.2"><abs id="S3.SS1.p2.1.m1.3.3.3.6.1.1.cmml" xref="S3.SS1.p2.1.m1.3.3.3.6.2.1"></abs><ci id="S3.SS1.p2.1.m1.2.2.2.2.cmml" xref="S3.SS1.p2.1.m1.2.2.2.2">ğ›½</ci></apply><apply id="S3.SS1.p2.1.m1.3.3.3.7.1.cmml" xref="S3.SS1.p2.1.m1.3.3.3.7.2"><abs id="S3.SS1.p2.1.m1.3.3.3.7.1.1.cmml" xref="S3.SS1.p2.1.m1.3.3.3.7.2.1"></abs><ci id="S3.SS1.p2.1.m1.3.3.3.3.cmml" xref="S3.SS1.p2.1.m1.3.3.3.3">ğœ“</ci></apply></apply></apply><apply id="S3.SS1.p2.1.m1.6.7.3.3.cmml" xref="S3.SS1.p2.1.m1.6.7.3.3"><csymbol cd="ambiguous" id="S3.SS1.p2.1.m1.6.7.3.3.1.cmml" xref="S3.SS1.p2.1.m1.6.7.3.3">superscript</csymbol><ci id="S3.SS1.p2.1.m1.6.7.3.3.2.cmml" xref="S3.SS1.p2.1.m1.6.7.3.3.2">â„</ci><apply id="S3.SS1.p2.1.m1.6.7.3.3.3.cmml" xref="S3.SS1.p2.1.m1.6.7.3.3.3"><times id="S3.SS1.p2.1.m1.6.7.3.3.3.1.cmml" xref="S3.SS1.p2.1.m1.6.7.3.3.3.1"></times><cn type="integer" id="S3.SS1.p2.1.m1.6.7.3.3.3.2.cmml" xref="S3.SS1.p2.1.m1.6.7.3.3.3.2">3</cn><ci id="S3.SS1.p2.1.m1.6.7.3.3.3.3.cmml" xref="S3.SS1.p2.1.m1.6.7.3.3.3.3">ğ‘</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.6c">M(\boldsymbol{\beta},\boldsymbol{\theta},\boldsymbol{\psi}):\mathbb{R}^{|\theta|\times|\beta|\times|\psi|}\rightarrow\mathbb{R}^{3N}</annotation></semantics></math>,
is a 3D wholebody human parametric model, employing shape <math id="S3.SS1.p2.2.m2.1" class="ltx_Math" alttext="\boldsymbol{\beta}\in\mathbb{R}^{200}" display="inline"><semantics id="S3.SS1.p2.2.m2.1a"><mrow id="S3.SS1.p2.2.m2.1.1" xref="S3.SS1.p2.2.m2.1.1.cmml"><mi id="S3.SS1.p2.2.m2.1.1.2" xref="S3.SS1.p2.2.m2.1.1.2.cmml">ğœ·</mi><mo id="S3.SS1.p2.2.m2.1.1.1" xref="S3.SS1.p2.2.m2.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS1.p2.2.m2.1.1.3" xref="S3.SS1.p2.2.m2.1.1.3.cmml"><mi id="S3.SS1.p2.2.m2.1.1.3.2" xref="S3.SS1.p2.2.m2.1.1.3.2.cmml">â„</mi><mn id="S3.SS1.p2.2.m2.1.1.3.3" xref="S3.SS1.p2.2.m2.1.1.3.3.cmml">200</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.1b"><apply id="S3.SS1.p2.2.m2.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1"><in id="S3.SS1.p2.2.m2.1.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1.1"></in><ci id="S3.SS1.p2.2.m2.1.1.2.cmml" xref="S3.SS1.p2.2.m2.1.1.2">ğœ·</ci><apply id="S3.SS1.p2.2.m2.1.1.3.cmml" xref="S3.SS1.p2.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p2.2.m2.1.1.3.1.cmml" xref="S3.SS1.p2.2.m2.1.1.3">superscript</csymbol><ci id="S3.SS1.p2.2.m2.1.1.3.2.cmml" xref="S3.SS1.p2.2.m2.1.1.3.2">â„</ci><cn type="integer" id="S3.SS1.p2.2.m2.1.1.3.3.cmml" xref="S3.SS1.p2.2.m2.1.1.3.3">200</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.1c">\boldsymbol{\beta}\in\mathbb{R}^{200}</annotation></semantics></math>, expression <math id="S3.SS1.p2.3.m3.1" class="ltx_Math" alttext="\boldsymbol{\psi}\in\mathbb{R}^{50}" display="inline"><semantics id="S3.SS1.p2.3.m3.1a"><mrow id="S3.SS1.p2.3.m3.1.1" xref="S3.SS1.p2.3.m3.1.1.cmml"><mi id="S3.SS1.p2.3.m3.1.1.2" xref="S3.SS1.p2.3.m3.1.1.2.cmml">ğ</mi><mo id="S3.SS1.p2.3.m3.1.1.1" xref="S3.SS1.p2.3.m3.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS1.p2.3.m3.1.1.3" xref="S3.SS1.p2.3.m3.1.1.3.cmml"><mi id="S3.SS1.p2.3.m3.1.1.3.2" xref="S3.SS1.p2.3.m3.1.1.3.2.cmml">â„</mi><mn id="S3.SS1.p2.3.m3.1.1.3.3" xref="S3.SS1.p2.3.m3.1.1.3.3.cmml">50</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.3.m3.1b"><apply id="S3.SS1.p2.3.m3.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1"><in id="S3.SS1.p2.3.m3.1.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1.1"></in><ci id="S3.SS1.p2.3.m3.1.1.2.cmml" xref="S3.SS1.p2.3.m3.1.1.2">ğ</ci><apply id="S3.SS1.p2.3.m3.1.1.3.cmml" xref="S3.SS1.p2.3.m3.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m3.1.1.3.1.cmml" xref="S3.SS1.p2.3.m3.1.1.3">superscript</csymbol><ci id="S3.SS1.p2.3.m3.1.1.3.2.cmml" xref="S3.SS1.p2.3.m3.1.1.3.2">â„</ci><cn type="integer" id="S3.SS1.p2.3.m3.1.1.3.3.cmml" xref="S3.SS1.p2.3.m3.1.1.3.3">50</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.3.m3.1c">\boldsymbol{\psi}\in\mathbb{R}^{50}</annotation></semantics></math>, and pose <math id="S3.SS1.p2.4.m4.1" class="ltx_Math" alttext="\boldsymbol{\theta}\in\mathbb{R}^{55\times 3}" display="inline"><semantics id="S3.SS1.p2.4.m4.1a"><mrow id="S3.SS1.p2.4.m4.1.1" xref="S3.SS1.p2.4.m4.1.1.cmml"><mi id="S3.SS1.p2.4.m4.1.1.2" xref="S3.SS1.p2.4.m4.1.1.2.cmml">ğœ½</mi><mo id="S3.SS1.p2.4.m4.1.1.1" xref="S3.SS1.p2.4.m4.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS1.p2.4.m4.1.1.3" xref="S3.SS1.p2.4.m4.1.1.3.cmml"><mi id="S3.SS1.p2.4.m4.1.1.3.2" xref="S3.SS1.p2.4.m4.1.1.3.2.cmml">â„</mi><mrow id="S3.SS1.p2.4.m4.1.1.3.3" xref="S3.SS1.p2.4.m4.1.1.3.3.cmml"><mn id="S3.SS1.p2.4.m4.1.1.3.3.2" xref="S3.SS1.p2.4.m4.1.1.3.3.2.cmml">55</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p2.4.m4.1.1.3.3.1" xref="S3.SS1.p2.4.m4.1.1.3.3.1.cmml">Ã—</mo><mn id="S3.SS1.p2.4.m4.1.1.3.3.3" xref="S3.SS1.p2.4.m4.1.1.3.3.3.cmml">3</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.4.m4.1b"><apply id="S3.SS1.p2.4.m4.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1"><in id="S3.SS1.p2.4.m4.1.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1.1"></in><ci id="S3.SS1.p2.4.m4.1.1.2.cmml" xref="S3.SS1.p2.4.m4.1.1.2">ğœ½</ci><apply id="S3.SS1.p2.4.m4.1.1.3.cmml" xref="S3.SS1.p2.4.m4.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p2.4.m4.1.1.3.1.cmml" xref="S3.SS1.p2.4.m4.1.1.3">superscript</csymbol><ci id="S3.SS1.p2.4.m4.1.1.3.2.cmml" xref="S3.SS1.p2.4.m4.1.1.3.2">â„</ci><apply id="S3.SS1.p2.4.m4.1.1.3.3.cmml" xref="S3.SS1.p2.4.m4.1.1.3.3"><times id="S3.SS1.p2.4.m4.1.1.3.3.1.cmml" xref="S3.SS1.p2.4.m4.1.1.3.3.1"></times><cn type="integer" id="S3.SS1.p2.4.m4.1.1.3.3.2.cmml" xref="S3.SS1.p2.4.m4.1.1.3.3.2">55</cn><cn type="integer" id="S3.SS1.p2.4.m4.1.1.3.3.3.cmml" xref="S3.SS1.p2.4.m4.1.1.3.3.3">3</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.4.m4.1c">\boldsymbol{\theta}\in\mathbb{R}^{55\times 3}</annotation></semantics></math> to control the entire body mesh.
The function of SMPL-X provides a differentiable skinning process that uses pose, shape, and expression parameters as inputs and delivers a triangulated mesh <math id="S3.SS1.p2.5.m5.1" class="ltx_Math" alttext="V\in\mathbb{R}^{N\times 3}" display="inline"><semantics id="S3.SS1.p2.5.m5.1a"><mrow id="S3.SS1.p2.5.m5.1.1" xref="S3.SS1.p2.5.m5.1.1.cmml"><mi id="S3.SS1.p2.5.m5.1.1.2" xref="S3.SS1.p2.5.m5.1.1.2.cmml">V</mi><mo id="S3.SS1.p2.5.m5.1.1.1" xref="S3.SS1.p2.5.m5.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS1.p2.5.m5.1.1.3" xref="S3.SS1.p2.5.m5.1.1.3.cmml"><mi id="S3.SS1.p2.5.m5.1.1.3.2" xref="S3.SS1.p2.5.m5.1.1.3.2.cmml">â„</mi><mrow id="S3.SS1.p2.5.m5.1.1.3.3" xref="S3.SS1.p2.5.m5.1.1.3.3.cmml"><mi id="S3.SS1.p2.5.m5.1.1.3.3.2" xref="S3.SS1.p2.5.m5.1.1.3.3.2.cmml">N</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p2.5.m5.1.1.3.3.1" xref="S3.SS1.p2.5.m5.1.1.3.3.1.cmml">Ã—</mo><mn id="S3.SS1.p2.5.m5.1.1.3.3.3" xref="S3.SS1.p2.5.m5.1.1.3.3.3.cmml">3</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.5.m5.1b"><apply id="S3.SS1.p2.5.m5.1.1.cmml" xref="S3.SS1.p2.5.m5.1.1"><in id="S3.SS1.p2.5.m5.1.1.1.cmml" xref="S3.SS1.p2.5.m5.1.1.1"></in><ci id="S3.SS1.p2.5.m5.1.1.2.cmml" xref="S3.SS1.p2.5.m5.1.1.2">ğ‘‰</ci><apply id="S3.SS1.p2.5.m5.1.1.3.cmml" xref="S3.SS1.p2.5.m5.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p2.5.m5.1.1.3.1.cmml" xref="S3.SS1.p2.5.m5.1.1.3">superscript</csymbol><ci id="S3.SS1.p2.5.m5.1.1.3.2.cmml" xref="S3.SS1.p2.5.m5.1.1.3.2">â„</ci><apply id="S3.SS1.p2.5.m5.1.1.3.3.cmml" xref="S3.SS1.p2.5.m5.1.1.3.3"><times id="S3.SS1.p2.5.m5.1.1.3.3.1.cmml" xref="S3.SS1.p2.5.m5.1.1.3.3.1"></times><ci id="S3.SS1.p2.5.m5.1.1.3.3.2.cmml" xref="S3.SS1.p2.5.m5.1.1.3.3.2">ğ‘</ci><cn type="integer" id="S3.SS1.p2.5.m5.1.1.3.3.3.cmml" xref="S3.SS1.p2.5.m5.1.1.3.3.3">3</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.5.m5.1c">V\in\mathbb{R}^{N\times 3}</annotation></semantics></math> with <math id="S3.SS1.p2.6.m6.1" class="ltx_Math" alttext="N=10475" display="inline"><semantics id="S3.SS1.p2.6.m6.1a"><mrow id="S3.SS1.p2.6.m6.1.1" xref="S3.SS1.p2.6.m6.1.1.cmml"><mi id="S3.SS1.p2.6.m6.1.1.2" xref="S3.SS1.p2.6.m6.1.1.2.cmml">N</mi><mo id="S3.SS1.p2.6.m6.1.1.1" xref="S3.SS1.p2.6.m6.1.1.1.cmml">=</mo><mn id="S3.SS1.p2.6.m6.1.1.3" xref="S3.SS1.p2.6.m6.1.1.3.cmml">10475</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.6.m6.1b"><apply id="S3.SS1.p2.6.m6.1.1.cmml" xref="S3.SS1.p2.6.m6.1.1"><eq id="S3.SS1.p2.6.m6.1.1.1.cmml" xref="S3.SS1.p2.6.m6.1.1.1"></eq><ci id="S3.SS1.p2.6.m6.1.1.2.cmml" xref="S3.SS1.p2.6.m6.1.1.2">ğ‘</ci><cn type="integer" id="S3.SS1.p2.6.m6.1.1.3.cmml" xref="S3.SS1.p2.6.m6.1.1.3">10475</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.6.m6.1c">N=10475</annotation></semantics></math> vertices. The reconstructed 3D joints <math id="S3.SS1.p2.7.m7.1" class="ltx_Math" alttext="J\in\mathbb{R}^{144\times 3}" display="inline"><semantics id="S3.SS1.p2.7.m7.1a"><mrow id="S3.SS1.p2.7.m7.1.1" xref="S3.SS1.p2.7.m7.1.1.cmml"><mi id="S3.SS1.p2.7.m7.1.1.2" xref="S3.SS1.p2.7.m7.1.1.2.cmml">J</mi><mo id="S3.SS1.p2.7.m7.1.1.1" xref="S3.SS1.p2.7.m7.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS1.p2.7.m7.1.1.3" xref="S3.SS1.p2.7.m7.1.1.3.cmml"><mi id="S3.SS1.p2.7.m7.1.1.3.2" xref="S3.SS1.p2.7.m7.1.1.3.2.cmml">â„</mi><mrow id="S3.SS1.p2.7.m7.1.1.3.3" xref="S3.SS1.p2.7.m7.1.1.3.3.cmml"><mn id="S3.SS1.p2.7.m7.1.1.3.3.2" xref="S3.SS1.p2.7.m7.1.1.3.3.2.cmml">144</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.p2.7.m7.1.1.3.3.1" xref="S3.SS1.p2.7.m7.1.1.3.3.1.cmml">Ã—</mo><mn id="S3.SS1.p2.7.m7.1.1.3.3.3" xref="S3.SS1.p2.7.m7.1.1.3.3.3.cmml">3</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.7.m7.1b"><apply id="S3.SS1.p2.7.m7.1.1.cmml" xref="S3.SS1.p2.7.m7.1.1"><in id="S3.SS1.p2.7.m7.1.1.1.cmml" xref="S3.SS1.p2.7.m7.1.1.1"></in><ci id="S3.SS1.p2.7.m7.1.1.2.cmml" xref="S3.SS1.p2.7.m7.1.1.2">ğ½</ci><apply id="S3.SS1.p2.7.m7.1.1.3.cmml" xref="S3.SS1.p2.7.m7.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p2.7.m7.1.1.3.1.cmml" xref="S3.SS1.p2.7.m7.1.1.3">superscript</csymbol><ci id="S3.SS1.p2.7.m7.1.1.3.2.cmml" xref="S3.SS1.p2.7.m7.1.1.3.2">â„</ci><apply id="S3.SS1.p2.7.m7.1.1.3.3.cmml" xref="S3.SS1.p2.7.m7.1.1.3.3"><times id="S3.SS1.p2.7.m7.1.1.3.3.1.cmml" xref="S3.SS1.p2.7.m7.1.1.3.3.1"></times><cn type="integer" id="S3.SS1.p2.7.m7.1.1.3.3.2.cmml" xref="S3.SS1.p2.7.m7.1.1.3.3.2">144</cn><cn type="integer" id="S3.SS1.p2.7.m7.1.1.3.3.3.cmml" xref="S3.SS1.p2.7.m7.1.1.3.3.3">3</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.7.m7.1c">J\in\mathbb{R}^{144\times 3}</annotation></semantics></math> can be obtained using a forward kinematics process. We use the SMPL-X model to parameterize the human body.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Surface Normal Estimation</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.4" class="ltx_p">The training of the ControlNet requires large-scale in-the-wild image and surface normal map pairs. However, it is impossible to manually annotate such data. Previous workÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite> employed an off-the-shelf method, OmnidataÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> for generating pseudo surface normal maps. Unfortunately, in our pilot studies, we observed that surface normal maps generated by OmnidataÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> tend to lose details. Inspired by recent works that leverage diffusion prior for downstream perception tasksÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>, <a href="#bib.bib34" title="" class="ltx_ref">34</a>, <a href="#bib.bib80" title="" class="ltx_ref">80</a>]</cite>, we fine-tune a pretrained latent diffusion model for surface normal estimation. This refinement results in a deterministic mapping between input images and output surface normal maps. Drawing from strategies proposed inÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>, we introduce a blending strategy and redesign the diffusion process. Specifically, we treat the input image <math id="S3.SS2.p1.1.m1.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S3.SS2.p1.1.m1.1a"><mi id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><ci id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">ğ‘¥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">x</annotation></semantics></math> as the noise map and surface normal map <math id="S3.SS2.p1.2.m2.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S3.SS2.p1.2.m2.1a"><mi id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><ci id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">ğ‘›</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">n</annotation></semantics></math> as the generation target. We then extract corresponding latent variables <math id="S3.SS2.p1.3.m3.1" class="ltx_Math" alttext="\bar{x}" display="inline"><semantics id="S3.SS2.p1.3.m3.1a"><mover accent="true" id="S3.SS2.p1.3.m3.1.1" xref="S3.SS2.p1.3.m3.1.1.cmml"><mi id="S3.SS2.p1.3.m3.1.1.2" xref="S3.SS2.p1.3.m3.1.1.2.cmml">x</mi><mo id="S3.SS2.p1.3.m3.1.1.1" xref="S3.SS2.p1.3.m3.1.1.1.cmml">Â¯</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m3.1b"><apply id="S3.SS2.p1.3.m3.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1"><ci id="S3.SS2.p1.3.m3.1.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1.1">Â¯</ci><ci id="S3.SS2.p1.3.m3.1.1.2.cmml" xref="S3.SS2.p1.3.m3.1.1.2">ğ‘¥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m3.1c">\bar{x}</annotation></semantics></math> and <math id="S3.SS2.p1.4.m4.1" class="ltx_Math" alttext="\bar{n}" display="inline"><semantics id="S3.SS2.p1.4.m4.1a"><mover accent="true" id="S3.SS2.p1.4.m4.1.1" xref="S3.SS2.p1.4.m4.1.1.cmml"><mi id="S3.SS2.p1.4.m4.1.1.2" xref="S3.SS2.p1.4.m4.1.1.2.cmml">n</mi><mo id="S3.SS2.p1.4.m4.1.1.1" xref="S3.SS2.p1.4.m4.1.1.1.cmml">Â¯</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.4.m4.1b"><apply id="S3.SS2.p1.4.m4.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1"><ci id="S3.SS2.p1.4.m4.1.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1.1">Â¯</ci><ci id="S3.SS2.p1.4.m4.1.1.2.cmml" xref="S3.SS2.p1.4.m4.1.1.2">ğ‘›</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.4.m4.1c">\bar{n}</annotation></semantics></math> through the pre-trained VAE encoder. Finally, we reformulate the diffusion process described inÂ <a href="#S3.E1" title="In 3.1 Prerequisites â€£ 3 Method â€£ 3D Human Reconstruction in the Wild with Synthetic Data Using Generative ModelsWork was done when YG was visiting Zhejiang University. HC is the corresponding author." class="ltx_ref"><span class="ltx_text ltx_ref_tag">Eq.</span>Â <span class="ltx_text ltx_ref_tag">1</span></a> as:</p>
<table id="S3.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E2.m1.4" class="ltx_Math" alttext="\bar{n_{t}}=\sqrt{\bar{\alpha}_{t}}\bar{n}+\sqrt{1-\bar{\alpha}_{t}}\bar{x}\quad t=[1,\cdots,T]." display="block"><semantics id="S3.E2.m1.4a"><mrow id="S3.E2.m1.4.4.1"><mrow id="S3.E2.m1.4.4.1.1.2" xref="S3.E2.m1.4.4.1.1.3.cmml"><mrow id="S3.E2.m1.4.4.1.1.1.1" xref="S3.E2.m1.4.4.1.1.1.1.cmml"><mover accent="true" id="S3.E2.m1.4.4.1.1.1.1.2" xref="S3.E2.m1.4.4.1.1.1.1.2.cmml"><msub id="S3.E2.m1.4.4.1.1.1.1.2.2" xref="S3.E2.m1.4.4.1.1.1.1.2.2.cmml"><mi id="S3.E2.m1.4.4.1.1.1.1.2.2.2" xref="S3.E2.m1.4.4.1.1.1.1.2.2.2.cmml">n</mi><mi id="S3.E2.m1.4.4.1.1.1.1.2.2.3" xref="S3.E2.m1.4.4.1.1.1.1.2.2.3.cmml">t</mi></msub><mo id="S3.E2.m1.4.4.1.1.1.1.2.1" xref="S3.E2.m1.4.4.1.1.1.1.2.1.cmml">Â¯</mo></mover><mo id="S3.E2.m1.4.4.1.1.1.1.1" xref="S3.E2.m1.4.4.1.1.1.1.1.cmml">=</mo><mrow id="S3.E2.m1.4.4.1.1.1.1.3" xref="S3.E2.m1.4.4.1.1.1.1.3.cmml"><mrow id="S3.E2.m1.4.4.1.1.1.1.3.2" xref="S3.E2.m1.4.4.1.1.1.1.3.2.cmml"><msqrt id="S3.E2.m1.4.4.1.1.1.1.3.2.2" xref="S3.E2.m1.4.4.1.1.1.1.3.2.2.cmml"><msub id="S3.E2.m1.4.4.1.1.1.1.3.2.2.2" xref="S3.E2.m1.4.4.1.1.1.1.3.2.2.2.cmml"><mover accent="true" id="S3.E2.m1.4.4.1.1.1.1.3.2.2.2.2" xref="S3.E2.m1.4.4.1.1.1.1.3.2.2.2.2.cmml"><mi id="S3.E2.m1.4.4.1.1.1.1.3.2.2.2.2.2" xref="S3.E2.m1.4.4.1.1.1.1.3.2.2.2.2.2.cmml">Î±</mi><mo id="S3.E2.m1.4.4.1.1.1.1.3.2.2.2.2.1" xref="S3.E2.m1.4.4.1.1.1.1.3.2.2.2.2.1.cmml">Â¯</mo></mover><mi id="S3.E2.m1.4.4.1.1.1.1.3.2.2.2.3" xref="S3.E2.m1.4.4.1.1.1.1.3.2.2.2.3.cmml">t</mi></msub></msqrt><mo lspace="0em" rspace="0em" id="S3.E2.m1.4.4.1.1.1.1.3.2.1" xref="S3.E2.m1.4.4.1.1.1.1.3.2.1.cmml">â€‹</mo><mover accent="true" id="S3.E2.m1.4.4.1.1.1.1.3.2.3" xref="S3.E2.m1.4.4.1.1.1.1.3.2.3.cmml"><mi id="S3.E2.m1.4.4.1.1.1.1.3.2.3.2" xref="S3.E2.m1.4.4.1.1.1.1.3.2.3.2.cmml">n</mi><mo id="S3.E2.m1.4.4.1.1.1.1.3.2.3.1" xref="S3.E2.m1.4.4.1.1.1.1.3.2.3.1.cmml">Â¯</mo></mover></mrow><mo id="S3.E2.m1.4.4.1.1.1.1.3.1" xref="S3.E2.m1.4.4.1.1.1.1.3.1.cmml">+</mo><mrow id="S3.E2.m1.4.4.1.1.1.1.3.3" xref="S3.E2.m1.4.4.1.1.1.1.3.3.cmml"><msqrt id="S3.E2.m1.4.4.1.1.1.1.3.3.2" xref="S3.E2.m1.4.4.1.1.1.1.3.3.2.cmml"><mrow id="S3.E2.m1.4.4.1.1.1.1.3.3.2.2" xref="S3.E2.m1.4.4.1.1.1.1.3.3.2.2.cmml"><mn id="S3.E2.m1.4.4.1.1.1.1.3.3.2.2.2" xref="S3.E2.m1.4.4.1.1.1.1.3.3.2.2.2.cmml">1</mn><mo id="S3.E2.m1.4.4.1.1.1.1.3.3.2.2.1" xref="S3.E2.m1.4.4.1.1.1.1.3.3.2.2.1.cmml">âˆ’</mo><msub id="S3.E2.m1.4.4.1.1.1.1.3.3.2.2.3" xref="S3.E2.m1.4.4.1.1.1.1.3.3.2.2.3.cmml"><mover accent="true" id="S3.E2.m1.4.4.1.1.1.1.3.3.2.2.3.2" xref="S3.E2.m1.4.4.1.1.1.1.3.3.2.2.3.2.cmml"><mi id="S3.E2.m1.4.4.1.1.1.1.3.3.2.2.3.2.2" xref="S3.E2.m1.4.4.1.1.1.1.3.3.2.2.3.2.2.cmml">Î±</mi><mo id="S3.E2.m1.4.4.1.1.1.1.3.3.2.2.3.2.1" xref="S3.E2.m1.4.4.1.1.1.1.3.3.2.2.3.2.1.cmml">Â¯</mo></mover><mi id="S3.E2.m1.4.4.1.1.1.1.3.3.2.2.3.3" xref="S3.E2.m1.4.4.1.1.1.1.3.3.2.2.3.3.cmml">t</mi></msub></mrow></msqrt><mo lspace="0em" rspace="0em" id="S3.E2.m1.4.4.1.1.1.1.3.3.1" xref="S3.E2.m1.4.4.1.1.1.1.3.3.1.cmml">â€‹</mo><mover accent="true" id="S3.E2.m1.4.4.1.1.1.1.3.3.3" xref="S3.E2.m1.4.4.1.1.1.1.3.3.3.cmml"><mi id="S3.E2.m1.4.4.1.1.1.1.3.3.3.2" xref="S3.E2.m1.4.4.1.1.1.1.3.3.3.2.cmml">x</mi><mo id="S3.E2.m1.4.4.1.1.1.1.3.3.3.1" xref="S3.E2.m1.4.4.1.1.1.1.3.3.3.1.cmml">Â¯</mo></mover></mrow></mrow></mrow><mspace width="1em" id="S3.E2.m1.4.4.1.1.2.3" xref="S3.E2.m1.4.4.1.1.3a.cmml"></mspace><mrow id="S3.E2.m1.4.4.1.1.2.2" xref="S3.E2.m1.4.4.1.1.2.2.cmml"><mi id="S3.E2.m1.4.4.1.1.2.2.2" xref="S3.E2.m1.4.4.1.1.2.2.2.cmml">t</mi><mo id="S3.E2.m1.4.4.1.1.2.2.1" xref="S3.E2.m1.4.4.1.1.2.2.1.cmml">=</mo><mrow id="S3.E2.m1.4.4.1.1.2.2.3.2" xref="S3.E2.m1.4.4.1.1.2.2.3.1.cmml"><mo stretchy="false" id="S3.E2.m1.4.4.1.1.2.2.3.2.1" xref="S3.E2.m1.4.4.1.1.2.2.3.1.cmml">[</mo><mn id="S3.E2.m1.1.1" xref="S3.E2.m1.1.1.cmml">1</mn><mo id="S3.E2.m1.4.4.1.1.2.2.3.2.2" xref="S3.E2.m1.4.4.1.1.2.2.3.1.cmml">,</mo><mi mathvariant="normal" id="S3.E2.m1.2.2" xref="S3.E2.m1.2.2.cmml">â‹¯</mi><mo id="S3.E2.m1.4.4.1.1.2.2.3.2.3" xref="S3.E2.m1.4.4.1.1.2.2.3.1.cmml">,</mo><mi id="S3.E2.m1.3.3" xref="S3.E2.m1.3.3.cmml">T</mi><mo stretchy="false" id="S3.E2.m1.4.4.1.1.2.2.3.2.4" xref="S3.E2.m1.4.4.1.1.2.2.3.1.cmml">]</mo></mrow></mrow></mrow><mo lspace="0em" id="S3.E2.m1.4.4.1.2">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.4b"><apply id="S3.E2.m1.4.4.1.1.3.cmml" xref="S3.E2.m1.4.4.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.4.4.1.1.3a.cmml" xref="S3.E2.m1.4.4.1.1.2.3">formulae-sequence</csymbol><apply id="S3.E2.m1.4.4.1.1.1.1.cmml" xref="S3.E2.m1.4.4.1.1.1.1"><eq id="S3.E2.m1.4.4.1.1.1.1.1.cmml" xref="S3.E2.m1.4.4.1.1.1.1.1"></eq><apply id="S3.E2.m1.4.4.1.1.1.1.2.cmml" xref="S3.E2.m1.4.4.1.1.1.1.2"><ci id="S3.E2.m1.4.4.1.1.1.1.2.1.cmml" xref="S3.E2.m1.4.4.1.1.1.1.2.1">Â¯</ci><apply id="S3.E2.m1.4.4.1.1.1.1.2.2.cmml" xref="S3.E2.m1.4.4.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.4.4.1.1.1.1.2.2.1.cmml" xref="S3.E2.m1.4.4.1.1.1.1.2.2">subscript</csymbol><ci id="S3.E2.m1.4.4.1.1.1.1.2.2.2.cmml" xref="S3.E2.m1.4.4.1.1.1.1.2.2.2">ğ‘›</ci><ci id="S3.E2.m1.4.4.1.1.1.1.2.2.3.cmml" xref="S3.E2.m1.4.4.1.1.1.1.2.2.3">ğ‘¡</ci></apply></apply><apply id="S3.E2.m1.4.4.1.1.1.1.3.cmml" xref="S3.E2.m1.4.4.1.1.1.1.3"><plus id="S3.E2.m1.4.4.1.1.1.1.3.1.cmml" xref="S3.E2.m1.4.4.1.1.1.1.3.1"></plus><apply id="S3.E2.m1.4.4.1.1.1.1.3.2.cmml" xref="S3.E2.m1.4.4.1.1.1.1.3.2"><times id="S3.E2.m1.4.4.1.1.1.1.3.2.1.cmml" xref="S3.E2.m1.4.4.1.1.1.1.3.2.1"></times><apply id="S3.E2.m1.4.4.1.1.1.1.3.2.2.cmml" xref="S3.E2.m1.4.4.1.1.1.1.3.2.2"><root id="S3.E2.m1.4.4.1.1.1.1.3.2.2a.cmml" xref="S3.E2.m1.4.4.1.1.1.1.3.2.2"></root><apply id="S3.E2.m1.4.4.1.1.1.1.3.2.2.2.cmml" xref="S3.E2.m1.4.4.1.1.1.1.3.2.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.4.4.1.1.1.1.3.2.2.2.1.cmml" xref="S3.E2.m1.4.4.1.1.1.1.3.2.2.2">subscript</csymbol><apply id="S3.E2.m1.4.4.1.1.1.1.3.2.2.2.2.cmml" xref="S3.E2.m1.4.4.1.1.1.1.3.2.2.2.2"><ci id="S3.E2.m1.4.4.1.1.1.1.3.2.2.2.2.1.cmml" xref="S3.E2.m1.4.4.1.1.1.1.3.2.2.2.2.1">Â¯</ci><ci id="S3.E2.m1.4.4.1.1.1.1.3.2.2.2.2.2.cmml" xref="S3.E2.m1.4.4.1.1.1.1.3.2.2.2.2.2">ğ›¼</ci></apply><ci id="S3.E2.m1.4.4.1.1.1.1.3.2.2.2.3.cmml" xref="S3.E2.m1.4.4.1.1.1.1.3.2.2.2.3">ğ‘¡</ci></apply></apply><apply id="S3.E2.m1.4.4.1.1.1.1.3.2.3.cmml" xref="S3.E2.m1.4.4.1.1.1.1.3.2.3"><ci id="S3.E2.m1.4.4.1.1.1.1.3.2.3.1.cmml" xref="S3.E2.m1.4.4.1.1.1.1.3.2.3.1">Â¯</ci><ci id="S3.E2.m1.4.4.1.1.1.1.3.2.3.2.cmml" xref="S3.E2.m1.4.4.1.1.1.1.3.2.3.2">ğ‘›</ci></apply></apply><apply id="S3.E2.m1.4.4.1.1.1.1.3.3.cmml" xref="S3.E2.m1.4.4.1.1.1.1.3.3"><times id="S3.E2.m1.4.4.1.1.1.1.3.3.1.cmml" xref="S3.E2.m1.4.4.1.1.1.1.3.3.1"></times><apply id="S3.E2.m1.4.4.1.1.1.1.3.3.2.cmml" xref="S3.E2.m1.4.4.1.1.1.1.3.3.2"><root id="S3.E2.m1.4.4.1.1.1.1.3.3.2a.cmml" xref="S3.E2.m1.4.4.1.1.1.1.3.3.2"></root><apply id="S3.E2.m1.4.4.1.1.1.1.3.3.2.2.cmml" xref="S3.E2.m1.4.4.1.1.1.1.3.3.2.2"><minus id="S3.E2.m1.4.4.1.1.1.1.3.3.2.2.1.cmml" xref="S3.E2.m1.4.4.1.1.1.1.3.3.2.2.1"></minus><cn type="integer" id="S3.E2.m1.4.4.1.1.1.1.3.3.2.2.2.cmml" xref="S3.E2.m1.4.4.1.1.1.1.3.3.2.2.2">1</cn><apply id="S3.E2.m1.4.4.1.1.1.1.3.3.2.2.3.cmml" xref="S3.E2.m1.4.4.1.1.1.1.3.3.2.2.3"><csymbol cd="ambiguous" id="S3.E2.m1.4.4.1.1.1.1.3.3.2.2.3.1.cmml" xref="S3.E2.m1.4.4.1.1.1.1.3.3.2.2.3">subscript</csymbol><apply id="S3.E2.m1.4.4.1.1.1.1.3.3.2.2.3.2.cmml" xref="S3.E2.m1.4.4.1.1.1.1.3.3.2.2.3.2"><ci id="S3.E2.m1.4.4.1.1.1.1.3.3.2.2.3.2.1.cmml" xref="S3.E2.m1.4.4.1.1.1.1.3.3.2.2.3.2.1">Â¯</ci><ci id="S3.E2.m1.4.4.1.1.1.1.3.3.2.2.3.2.2.cmml" xref="S3.E2.m1.4.4.1.1.1.1.3.3.2.2.3.2.2">ğ›¼</ci></apply><ci id="S3.E2.m1.4.4.1.1.1.1.3.3.2.2.3.3.cmml" xref="S3.E2.m1.4.4.1.1.1.1.3.3.2.2.3.3">ğ‘¡</ci></apply></apply></apply><apply id="S3.E2.m1.4.4.1.1.1.1.3.3.3.cmml" xref="S3.E2.m1.4.4.1.1.1.1.3.3.3"><ci id="S3.E2.m1.4.4.1.1.1.1.3.3.3.1.cmml" xref="S3.E2.m1.4.4.1.1.1.1.3.3.3.1">Â¯</ci><ci id="S3.E2.m1.4.4.1.1.1.1.3.3.3.2.cmml" xref="S3.E2.m1.4.4.1.1.1.1.3.3.3.2">ğ‘¥</ci></apply></apply></apply></apply><apply id="S3.E2.m1.4.4.1.1.2.2.cmml" xref="S3.E2.m1.4.4.1.1.2.2"><eq id="S3.E2.m1.4.4.1.1.2.2.1.cmml" xref="S3.E2.m1.4.4.1.1.2.2.1"></eq><ci id="S3.E2.m1.4.4.1.1.2.2.2.cmml" xref="S3.E2.m1.4.4.1.1.2.2.2">ğ‘¡</ci><list id="S3.E2.m1.4.4.1.1.2.2.3.1.cmml" xref="S3.E2.m1.4.4.1.1.2.2.3.2"><cn type="integer" id="S3.E2.m1.1.1.cmml" xref="S3.E2.m1.1.1">1</cn><ci id="S3.E2.m1.2.2.cmml" xref="S3.E2.m1.2.2">â‹¯</ci><ci id="S3.E2.m1.3.3.cmml" xref="S3.E2.m1.3.3">ğ‘‡</ci></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.4c">\bar{n_{t}}=\sqrt{\bar{\alpha}_{t}}\bar{n}+\sqrt{1-\bar{\alpha}_{t}}\bar{x}\quad t=[1,\cdots,T].</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.p1.5" class="ltx_p">See Â <a href="#S3.F3" title="In 3.2 Surface Normal Estimation â€£ 3 Method â€£ 3D Human Reconstruction in the Wild with Synthetic Data Using Generative ModelsWork was done when YG was visiting Zhejiang University. HC is the corresponding author." class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">3</span></a> for illustration.
To predict surface normals from a pre-trained T2I model, we fine-tune a UNet using the v-prediction objectiveÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref">62</a>]</cite> on a synthetic dataset, HypersimÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite>. During inference, the UNet progressively denoises input images and extracts surface normals using the DDIM schedulerÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib67" title="" class="ltx_ref">67</a>]</cite>.</p>
</div>
<figure id="S3.F3" class="ltx_figure"><img src="/html/2403.11111/assets/x3.png" id="S3.F3.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="346" height="158" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.3.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S3.F3.4.2" class="ltx_text" style="font-size:90%;">
The overall training pipeline of the surface normal estimation.
</span></figcaption>
</figure>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Initial Human Image and Annotation Generation</h3>

<div id="S3.SS3.p1" class="ltx_para ltx_noindent">
<p id="S3.SS3.p1.8" class="ltx_p"><span id="S3.SS3.p1.8.1" class="ltx_text ltx_font_bold">Camera simulation.</span> One drawback of vision-based motion capture systems is that they need to calibrate and synchronize the cameraâ€™s intrinsic and extrinsic parameters during the capturing. Thus, the collected human data are limited in terms of the scales and view diversity. On the contrary, our pipeline gets rid of the physical RGBD cameras and can simulate arbitrary human scales and body orientation.
Specifically, we randomly determine the orthographic scale <math id="S3.SS3.p1.1.m1.1" class="ltx_Math" alttext="s" display="inline"><semantics id="S3.SS3.p1.1.m1.1a"><mi id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><ci id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">ğ‘ </ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">s</annotation></semantics></math> of the human body (<math id="S3.SS3.p1.2.m2.2" class="ltx_Math" alttext="s\in[0.45,1.1]" display="inline"><semantics id="S3.SS3.p1.2.m2.2a"><mrow id="S3.SS3.p1.2.m2.2.3" xref="S3.SS3.p1.2.m2.2.3.cmml"><mi id="S3.SS3.p1.2.m2.2.3.2" xref="S3.SS3.p1.2.m2.2.3.2.cmml">s</mi><mo id="S3.SS3.p1.2.m2.2.3.1" xref="S3.SS3.p1.2.m2.2.3.1.cmml">âˆˆ</mo><mrow id="S3.SS3.p1.2.m2.2.3.3.2" xref="S3.SS3.p1.2.m2.2.3.3.1.cmml"><mo stretchy="false" id="S3.SS3.p1.2.m2.2.3.3.2.1" xref="S3.SS3.p1.2.m2.2.3.3.1.cmml">[</mo><mn id="S3.SS3.p1.2.m2.1.1" xref="S3.SS3.p1.2.m2.1.1.cmml">0.45</mn><mo id="S3.SS3.p1.2.m2.2.3.3.2.2" xref="S3.SS3.p1.2.m2.2.3.3.1.cmml">,</mo><mn id="S3.SS3.p1.2.m2.2.2" xref="S3.SS3.p1.2.m2.2.2.cmml">1.1</mn><mo stretchy="false" id="S3.SS3.p1.2.m2.2.3.3.2.3" xref="S3.SS3.p1.2.m2.2.3.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.2.m2.2b"><apply id="S3.SS3.p1.2.m2.2.3.cmml" xref="S3.SS3.p1.2.m2.2.3"><in id="S3.SS3.p1.2.m2.2.3.1.cmml" xref="S3.SS3.p1.2.m2.2.3.1"></in><ci id="S3.SS3.p1.2.m2.2.3.2.cmml" xref="S3.SS3.p1.2.m2.2.3.2">ğ‘ </ci><interval closure="closed" id="S3.SS3.p1.2.m2.2.3.3.1.cmml" xref="S3.SS3.p1.2.m2.2.3.3.2"><cn type="float" id="S3.SS3.p1.2.m2.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1">0.45</cn><cn type="float" id="S3.SS3.p1.2.m2.2.2.cmml" xref="S3.SS3.p1.2.m2.2.2">1.1</cn></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.2.m2.2c">s\in[0.45,1.1]</annotation></semantics></math>), along with the horizontal shift (<math id="S3.SS3.p1.3.m3.2" class="ltx_Math" alttext="t_{x},t_{y}" display="inline"><semantics id="S3.SS3.p1.3.m3.2a"><mrow id="S3.SS3.p1.3.m3.2.2.2" xref="S3.SS3.p1.3.m3.2.2.3.cmml"><msub id="S3.SS3.p1.3.m3.1.1.1.1" xref="S3.SS3.p1.3.m3.1.1.1.1.cmml"><mi id="S3.SS3.p1.3.m3.1.1.1.1.2" xref="S3.SS3.p1.3.m3.1.1.1.1.2.cmml">t</mi><mi id="S3.SS3.p1.3.m3.1.1.1.1.3" xref="S3.SS3.p1.3.m3.1.1.1.1.3.cmml">x</mi></msub><mo id="S3.SS3.p1.3.m3.2.2.2.3" xref="S3.SS3.p1.3.m3.2.2.3.cmml">,</mo><msub id="S3.SS3.p1.3.m3.2.2.2.2" xref="S3.SS3.p1.3.m3.2.2.2.2.cmml"><mi id="S3.SS3.p1.3.m3.2.2.2.2.2" xref="S3.SS3.p1.3.m3.2.2.2.2.2.cmml">t</mi><mi id="S3.SS3.p1.3.m3.2.2.2.2.3" xref="S3.SS3.p1.3.m3.2.2.2.2.3.cmml">y</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.3.m3.2b"><list id="S3.SS3.p1.3.m3.2.2.3.cmml" xref="S3.SS3.p1.3.m3.2.2.2"><apply id="S3.SS3.p1.3.m3.1.1.1.1.cmml" xref="S3.SS3.p1.3.m3.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.3.m3.1.1.1.1.1.cmml" xref="S3.SS3.p1.3.m3.1.1.1.1">subscript</csymbol><ci id="S3.SS3.p1.3.m3.1.1.1.1.2.cmml" xref="S3.SS3.p1.3.m3.1.1.1.1.2">ğ‘¡</ci><ci id="S3.SS3.p1.3.m3.1.1.1.1.3.cmml" xref="S3.SS3.p1.3.m3.1.1.1.1.3">ğ‘¥</ci></apply><apply id="S3.SS3.p1.3.m3.2.2.2.2.cmml" xref="S3.SS3.p1.3.m3.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS3.p1.3.m3.2.2.2.2.1.cmml" xref="S3.SS3.p1.3.m3.2.2.2.2">subscript</csymbol><ci id="S3.SS3.p1.3.m3.2.2.2.2.2.cmml" xref="S3.SS3.p1.3.m3.2.2.2.2.2">ğ‘¡</ci><ci id="S3.SS3.p1.3.m3.2.2.2.2.3.cmml" xref="S3.SS3.p1.3.m3.2.2.2.2.3">ğ‘¦</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.3.m3.2c">t_{x},t_{y}</annotation></semantics></math>) within a range of <math id="S3.SS3.p1.4.m4.2" class="ltx_Math" alttext="[-0.4/s,0.4/s]" display="inline"><semantics id="S3.SS3.p1.4.m4.2a"><mrow id="S3.SS3.p1.4.m4.2.2.2" xref="S3.SS3.p1.4.m4.2.2.3.cmml"><mo stretchy="false" id="S3.SS3.p1.4.m4.2.2.2.3" xref="S3.SS3.p1.4.m4.2.2.3.cmml">[</mo><mrow id="S3.SS3.p1.4.m4.1.1.1.1" xref="S3.SS3.p1.4.m4.1.1.1.1.cmml"><mo id="S3.SS3.p1.4.m4.1.1.1.1a" xref="S3.SS3.p1.4.m4.1.1.1.1.cmml">âˆ’</mo><mrow id="S3.SS3.p1.4.m4.1.1.1.1.2" xref="S3.SS3.p1.4.m4.1.1.1.1.2.cmml"><mn id="S3.SS3.p1.4.m4.1.1.1.1.2.2" xref="S3.SS3.p1.4.m4.1.1.1.1.2.2.cmml">0.4</mn><mo id="S3.SS3.p1.4.m4.1.1.1.1.2.1" xref="S3.SS3.p1.4.m4.1.1.1.1.2.1.cmml">/</mo><mi id="S3.SS3.p1.4.m4.1.1.1.1.2.3" xref="S3.SS3.p1.4.m4.1.1.1.1.2.3.cmml">s</mi></mrow></mrow><mo id="S3.SS3.p1.4.m4.2.2.2.4" xref="S3.SS3.p1.4.m4.2.2.3.cmml">,</mo><mrow id="S3.SS3.p1.4.m4.2.2.2.2" xref="S3.SS3.p1.4.m4.2.2.2.2.cmml"><mn id="S3.SS3.p1.4.m4.2.2.2.2.2" xref="S3.SS3.p1.4.m4.2.2.2.2.2.cmml">0.4</mn><mo id="S3.SS3.p1.4.m4.2.2.2.2.1" xref="S3.SS3.p1.4.m4.2.2.2.2.1.cmml">/</mo><mi id="S3.SS3.p1.4.m4.2.2.2.2.3" xref="S3.SS3.p1.4.m4.2.2.2.2.3.cmml">s</mi></mrow><mo stretchy="false" id="S3.SS3.p1.4.m4.2.2.2.5" xref="S3.SS3.p1.4.m4.2.2.3.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.4.m4.2b"><interval closure="closed" id="S3.SS3.p1.4.m4.2.2.3.cmml" xref="S3.SS3.p1.4.m4.2.2.2"><apply id="S3.SS3.p1.4.m4.1.1.1.1.cmml" xref="S3.SS3.p1.4.m4.1.1.1.1"><minus id="S3.SS3.p1.4.m4.1.1.1.1.1.cmml" xref="S3.SS3.p1.4.m4.1.1.1.1"></minus><apply id="S3.SS3.p1.4.m4.1.1.1.1.2.cmml" xref="S3.SS3.p1.4.m4.1.1.1.1.2"><divide id="S3.SS3.p1.4.m4.1.1.1.1.2.1.cmml" xref="S3.SS3.p1.4.m4.1.1.1.1.2.1"></divide><cn type="float" id="S3.SS3.p1.4.m4.1.1.1.1.2.2.cmml" xref="S3.SS3.p1.4.m4.1.1.1.1.2.2">0.4</cn><ci id="S3.SS3.p1.4.m4.1.1.1.1.2.3.cmml" xref="S3.SS3.p1.4.m4.1.1.1.1.2.3">ğ‘ </ci></apply></apply><apply id="S3.SS3.p1.4.m4.2.2.2.2.cmml" xref="S3.SS3.p1.4.m4.2.2.2.2"><divide id="S3.SS3.p1.4.m4.2.2.2.2.1.cmml" xref="S3.SS3.p1.4.m4.2.2.2.2.1"></divide><cn type="float" id="S3.SS3.p1.4.m4.2.2.2.2.2.cmml" xref="S3.SS3.p1.4.m4.2.2.2.2.2">0.4</cn><ci id="S3.SS3.p1.4.m4.2.2.2.2.3.cmml" xref="S3.SS3.p1.4.m4.2.2.2.2.3">ğ‘ </ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.4.m4.2c">[-0.4/s,0.4/s]</annotation></semantics></math>. This methodology ensures that the majority of body parts are visible in the image. Following <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib77" title="" class="ltx_ref">77</a>]</cite>, we determine the translation of the body as <math id="S3.SS3.p1.5.m5.3" class="ltx_Math" alttext="transl=[t_{x},t_{y},f/s]" display="inline"><semantics id="S3.SS3.p1.5.m5.3a"><mrow id="S3.SS3.p1.5.m5.3.3" xref="S3.SS3.p1.5.m5.3.3.cmml"><mrow id="S3.SS3.p1.5.m5.3.3.5" xref="S3.SS3.p1.5.m5.3.3.5.cmml"><mi id="S3.SS3.p1.5.m5.3.3.5.2" xref="S3.SS3.p1.5.m5.3.3.5.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.5.m5.3.3.5.1" xref="S3.SS3.p1.5.m5.3.3.5.1.cmml">â€‹</mo><mi id="S3.SS3.p1.5.m5.3.3.5.3" xref="S3.SS3.p1.5.m5.3.3.5.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.5.m5.3.3.5.1a" xref="S3.SS3.p1.5.m5.3.3.5.1.cmml">â€‹</mo><mi id="S3.SS3.p1.5.m5.3.3.5.4" xref="S3.SS3.p1.5.m5.3.3.5.4.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.5.m5.3.3.5.1b" xref="S3.SS3.p1.5.m5.3.3.5.1.cmml">â€‹</mo><mi id="S3.SS3.p1.5.m5.3.3.5.5" xref="S3.SS3.p1.5.m5.3.3.5.5.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.5.m5.3.3.5.1c" xref="S3.SS3.p1.5.m5.3.3.5.1.cmml">â€‹</mo><mi id="S3.SS3.p1.5.m5.3.3.5.6" xref="S3.SS3.p1.5.m5.3.3.5.6.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.5.m5.3.3.5.1d" xref="S3.SS3.p1.5.m5.3.3.5.1.cmml">â€‹</mo><mi id="S3.SS3.p1.5.m5.3.3.5.7" xref="S3.SS3.p1.5.m5.3.3.5.7.cmml">l</mi></mrow><mo id="S3.SS3.p1.5.m5.3.3.4" xref="S3.SS3.p1.5.m5.3.3.4.cmml">=</mo><mrow id="S3.SS3.p1.5.m5.3.3.3.3" xref="S3.SS3.p1.5.m5.3.3.3.4.cmml"><mo stretchy="false" id="S3.SS3.p1.5.m5.3.3.3.3.4" xref="S3.SS3.p1.5.m5.3.3.3.4.cmml">[</mo><msub id="S3.SS3.p1.5.m5.1.1.1.1.1" xref="S3.SS3.p1.5.m5.1.1.1.1.1.cmml"><mi id="S3.SS3.p1.5.m5.1.1.1.1.1.2" xref="S3.SS3.p1.5.m5.1.1.1.1.1.2.cmml">t</mi><mi id="S3.SS3.p1.5.m5.1.1.1.1.1.3" xref="S3.SS3.p1.5.m5.1.1.1.1.1.3.cmml">x</mi></msub><mo id="S3.SS3.p1.5.m5.3.3.3.3.5" xref="S3.SS3.p1.5.m5.3.3.3.4.cmml">,</mo><msub id="S3.SS3.p1.5.m5.2.2.2.2.2" xref="S3.SS3.p1.5.m5.2.2.2.2.2.cmml"><mi id="S3.SS3.p1.5.m5.2.2.2.2.2.2" xref="S3.SS3.p1.5.m5.2.2.2.2.2.2.cmml">t</mi><mi id="S3.SS3.p1.5.m5.2.2.2.2.2.3" xref="S3.SS3.p1.5.m5.2.2.2.2.2.3.cmml">y</mi></msub><mo id="S3.SS3.p1.5.m5.3.3.3.3.6" xref="S3.SS3.p1.5.m5.3.3.3.4.cmml">,</mo><mrow id="S3.SS3.p1.5.m5.3.3.3.3.3" xref="S3.SS3.p1.5.m5.3.3.3.3.3.cmml"><mi id="S3.SS3.p1.5.m5.3.3.3.3.3.2" xref="S3.SS3.p1.5.m5.3.3.3.3.3.2.cmml">f</mi><mo id="S3.SS3.p1.5.m5.3.3.3.3.3.1" xref="S3.SS3.p1.5.m5.3.3.3.3.3.1.cmml">/</mo><mi id="S3.SS3.p1.5.m5.3.3.3.3.3.3" xref="S3.SS3.p1.5.m5.3.3.3.3.3.3.cmml">s</mi></mrow><mo stretchy="false" id="S3.SS3.p1.5.m5.3.3.3.3.7" xref="S3.SS3.p1.5.m5.3.3.3.4.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.5.m5.3b"><apply id="S3.SS3.p1.5.m5.3.3.cmml" xref="S3.SS3.p1.5.m5.3.3"><eq id="S3.SS3.p1.5.m5.3.3.4.cmml" xref="S3.SS3.p1.5.m5.3.3.4"></eq><apply id="S3.SS3.p1.5.m5.3.3.5.cmml" xref="S3.SS3.p1.5.m5.3.3.5"><times id="S3.SS3.p1.5.m5.3.3.5.1.cmml" xref="S3.SS3.p1.5.m5.3.3.5.1"></times><ci id="S3.SS3.p1.5.m5.3.3.5.2.cmml" xref="S3.SS3.p1.5.m5.3.3.5.2">ğ‘¡</ci><ci id="S3.SS3.p1.5.m5.3.3.5.3.cmml" xref="S3.SS3.p1.5.m5.3.3.5.3">ğ‘Ÿ</ci><ci id="S3.SS3.p1.5.m5.3.3.5.4.cmml" xref="S3.SS3.p1.5.m5.3.3.5.4">ğ‘</ci><ci id="S3.SS3.p1.5.m5.3.3.5.5.cmml" xref="S3.SS3.p1.5.m5.3.3.5.5">ğ‘›</ci><ci id="S3.SS3.p1.5.m5.3.3.5.6.cmml" xref="S3.SS3.p1.5.m5.3.3.5.6">ğ‘ </ci><ci id="S3.SS3.p1.5.m5.3.3.5.7.cmml" xref="S3.SS3.p1.5.m5.3.3.5.7">ğ‘™</ci></apply><list id="S3.SS3.p1.5.m5.3.3.3.4.cmml" xref="S3.SS3.p1.5.m5.3.3.3.3"><apply id="S3.SS3.p1.5.m5.1.1.1.1.1.cmml" xref="S3.SS3.p1.5.m5.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.5.m5.1.1.1.1.1.1.cmml" xref="S3.SS3.p1.5.m5.1.1.1.1.1">subscript</csymbol><ci id="S3.SS3.p1.5.m5.1.1.1.1.1.2.cmml" xref="S3.SS3.p1.5.m5.1.1.1.1.1.2">ğ‘¡</ci><ci id="S3.SS3.p1.5.m5.1.1.1.1.1.3.cmml" xref="S3.SS3.p1.5.m5.1.1.1.1.1.3">ğ‘¥</ci></apply><apply id="S3.SS3.p1.5.m5.2.2.2.2.2.cmml" xref="S3.SS3.p1.5.m5.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS3.p1.5.m5.2.2.2.2.2.1.cmml" xref="S3.SS3.p1.5.m5.2.2.2.2.2">subscript</csymbol><ci id="S3.SS3.p1.5.m5.2.2.2.2.2.2.cmml" xref="S3.SS3.p1.5.m5.2.2.2.2.2.2">ğ‘¡</ci><ci id="S3.SS3.p1.5.m5.2.2.2.2.2.3.cmml" xref="S3.SS3.p1.5.m5.2.2.2.2.2.3">ğ‘¦</ci></apply><apply id="S3.SS3.p1.5.m5.3.3.3.3.3.cmml" xref="S3.SS3.p1.5.m5.3.3.3.3.3"><divide id="S3.SS3.p1.5.m5.3.3.3.3.3.1.cmml" xref="S3.SS3.p1.5.m5.3.3.3.3.3.1"></divide><ci id="S3.SS3.p1.5.m5.3.3.3.3.3.2.cmml" xref="S3.SS3.p1.5.m5.3.3.3.3.3.2">ğ‘“</ci><ci id="S3.SS3.p1.5.m5.3.3.3.3.3.3.cmml" xref="S3.SS3.p1.5.m5.3.3.3.3.3.3">ğ‘ </ci></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.5.m5.3c">transl=[t_{x},t_{y},f/s]</annotation></semantics></math>.
The focal length in normalized device coordinate (NDC) space, denoted as <math id="S3.SS3.p1.6.m6.1" class="ltx_Math" alttext="f" display="inline"><semantics id="S3.SS3.p1.6.m6.1a"><mi id="S3.SS3.p1.6.m6.1.1" xref="S3.SS3.p1.6.m6.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.6.m6.1b"><ci id="S3.SS3.p1.6.m6.1.1.cmml" xref="S3.SS3.p1.6.m6.1.1">ğ‘“</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.6.m6.1c">f</annotation></semantics></math>, can be computed using the formula <math id="S3.SS3.p1.7.m7.2" class="ltx_Math" alttext="f=1/\tan(FoV/2)" display="inline"><semantics id="S3.SS3.p1.7.m7.2a"><mrow id="S3.SS3.p1.7.m7.2.2" xref="S3.SS3.p1.7.m7.2.2.cmml"><mi id="S3.SS3.p1.7.m7.2.2.3" xref="S3.SS3.p1.7.m7.2.2.3.cmml">f</mi><mo id="S3.SS3.p1.7.m7.2.2.2" xref="S3.SS3.p1.7.m7.2.2.2.cmml">=</mo><mrow id="S3.SS3.p1.7.m7.2.2.1" xref="S3.SS3.p1.7.m7.2.2.1.cmml"><mn id="S3.SS3.p1.7.m7.2.2.1.3" xref="S3.SS3.p1.7.m7.2.2.1.3.cmml">1</mn><mo id="S3.SS3.p1.7.m7.2.2.1.2" xref="S3.SS3.p1.7.m7.2.2.1.2.cmml">/</mo><mrow id="S3.SS3.p1.7.m7.2.2.1.1.1" xref="S3.SS3.p1.7.m7.2.2.1.1.2.cmml"><mi id="S3.SS3.p1.7.m7.1.1" xref="S3.SS3.p1.7.m7.1.1.cmml">tan</mi><mo id="S3.SS3.p1.7.m7.2.2.1.1.1a" xref="S3.SS3.p1.7.m7.2.2.1.1.2.cmml">â¡</mo><mrow id="S3.SS3.p1.7.m7.2.2.1.1.1.1" xref="S3.SS3.p1.7.m7.2.2.1.1.2.cmml"><mo stretchy="false" id="S3.SS3.p1.7.m7.2.2.1.1.1.1.2" xref="S3.SS3.p1.7.m7.2.2.1.1.2.cmml">(</mo><mrow id="S3.SS3.p1.7.m7.2.2.1.1.1.1.1" xref="S3.SS3.p1.7.m7.2.2.1.1.1.1.1.cmml"><mrow id="S3.SS3.p1.7.m7.2.2.1.1.1.1.1.2" xref="S3.SS3.p1.7.m7.2.2.1.1.1.1.1.2.cmml"><mi id="S3.SS3.p1.7.m7.2.2.1.1.1.1.1.2.2" xref="S3.SS3.p1.7.m7.2.2.1.1.1.1.1.2.2.cmml">F</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.7.m7.2.2.1.1.1.1.1.2.1" xref="S3.SS3.p1.7.m7.2.2.1.1.1.1.1.2.1.cmml">â€‹</mo><mi id="S3.SS3.p1.7.m7.2.2.1.1.1.1.1.2.3" xref="S3.SS3.p1.7.m7.2.2.1.1.1.1.1.2.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.7.m7.2.2.1.1.1.1.1.2.1a" xref="S3.SS3.p1.7.m7.2.2.1.1.1.1.1.2.1.cmml">â€‹</mo><mi id="S3.SS3.p1.7.m7.2.2.1.1.1.1.1.2.4" xref="S3.SS3.p1.7.m7.2.2.1.1.1.1.1.2.4.cmml">V</mi></mrow><mo id="S3.SS3.p1.7.m7.2.2.1.1.1.1.1.1" xref="S3.SS3.p1.7.m7.2.2.1.1.1.1.1.1.cmml">/</mo><mn id="S3.SS3.p1.7.m7.2.2.1.1.1.1.1.3" xref="S3.SS3.p1.7.m7.2.2.1.1.1.1.1.3.cmml">2</mn></mrow><mo stretchy="false" id="S3.SS3.p1.7.m7.2.2.1.1.1.1.3" xref="S3.SS3.p1.7.m7.2.2.1.1.2.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.7.m7.2b"><apply id="S3.SS3.p1.7.m7.2.2.cmml" xref="S3.SS3.p1.7.m7.2.2"><eq id="S3.SS3.p1.7.m7.2.2.2.cmml" xref="S3.SS3.p1.7.m7.2.2.2"></eq><ci id="S3.SS3.p1.7.m7.2.2.3.cmml" xref="S3.SS3.p1.7.m7.2.2.3">ğ‘“</ci><apply id="S3.SS3.p1.7.m7.2.2.1.cmml" xref="S3.SS3.p1.7.m7.2.2.1"><divide id="S3.SS3.p1.7.m7.2.2.1.2.cmml" xref="S3.SS3.p1.7.m7.2.2.1.2"></divide><cn type="integer" id="S3.SS3.p1.7.m7.2.2.1.3.cmml" xref="S3.SS3.p1.7.m7.2.2.1.3">1</cn><apply id="S3.SS3.p1.7.m7.2.2.1.1.2.cmml" xref="S3.SS3.p1.7.m7.2.2.1.1.1"><tan id="S3.SS3.p1.7.m7.1.1.cmml" xref="S3.SS3.p1.7.m7.1.1"></tan><apply id="S3.SS3.p1.7.m7.2.2.1.1.1.1.1.cmml" xref="S3.SS3.p1.7.m7.2.2.1.1.1.1.1"><divide id="S3.SS3.p1.7.m7.2.2.1.1.1.1.1.1.cmml" xref="S3.SS3.p1.7.m7.2.2.1.1.1.1.1.1"></divide><apply id="S3.SS3.p1.7.m7.2.2.1.1.1.1.1.2.cmml" xref="S3.SS3.p1.7.m7.2.2.1.1.1.1.1.2"><times id="S3.SS3.p1.7.m7.2.2.1.1.1.1.1.2.1.cmml" xref="S3.SS3.p1.7.m7.2.2.1.1.1.1.1.2.1"></times><ci id="S3.SS3.p1.7.m7.2.2.1.1.1.1.1.2.2.cmml" xref="S3.SS3.p1.7.m7.2.2.1.1.1.1.1.2.2">ğ¹</ci><ci id="S3.SS3.p1.7.m7.2.2.1.1.1.1.1.2.3.cmml" xref="S3.SS3.p1.7.m7.2.2.1.1.1.1.1.2.3">ğ‘œ</ci><ci id="S3.SS3.p1.7.m7.2.2.1.1.1.1.1.2.4.cmml" xref="S3.SS3.p1.7.m7.2.2.1.1.1.1.1.2.4">ğ‘‰</ci></apply><cn type="integer" id="S3.SS3.p1.7.m7.2.2.1.1.1.1.1.3.cmml" xref="S3.SS3.p1.7.m7.2.2.1.1.1.1.1.3">2</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.7.m7.2c">f=1/\tan(FoV/2)</annotation></semantics></math>. Here, <math id="S3.SS3.p1.8.m8.1" class="ltx_Math" alttext="FoV" display="inline"><semantics id="S3.SS3.p1.8.m8.1a"><mrow id="S3.SS3.p1.8.m8.1.1" xref="S3.SS3.p1.8.m8.1.1.cmml"><mi id="S3.SS3.p1.8.m8.1.1.2" xref="S3.SS3.p1.8.m8.1.1.2.cmml">F</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.8.m8.1.1.1" xref="S3.SS3.p1.8.m8.1.1.1.cmml">â€‹</mo><mi id="S3.SS3.p1.8.m8.1.1.3" xref="S3.SS3.p1.8.m8.1.1.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p1.8.m8.1.1.1a" xref="S3.SS3.p1.8.m8.1.1.1.cmml">â€‹</mo><mi id="S3.SS3.p1.8.m8.1.1.4" xref="S3.SS3.p1.8.m8.1.1.4.cmml">V</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.8.m8.1b"><apply id="S3.SS3.p1.8.m8.1.1.cmml" xref="S3.SS3.p1.8.m8.1.1"><times id="S3.SS3.p1.8.m8.1.1.1.cmml" xref="S3.SS3.p1.8.m8.1.1.1"></times><ci id="S3.SS3.p1.8.m8.1.1.2.cmml" xref="S3.SS3.p1.8.m8.1.1.2">ğ¹</ci><ci id="S3.SS3.p1.8.m8.1.1.3.cmml" xref="S3.SS3.p1.8.m8.1.1.3">ğ‘œ</ci><ci id="S3.SS3.p1.8.m8.1.1.4.cmml" xref="S3.SS3.p1.8.m8.1.1.4">ğ‘‰</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.8.m8.1c">FoV</annotation></semantics></math> represents the Horizontal Field of View angle, which is randomly zoomed in from 25 to 120 degrees by following <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib77" title="" class="ltx_ref">77</a>]</cite>.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para ltx_noindent">
<p id="S3.SS3.p2.1" class="ltx_p"><span id="S3.SS3.p2.1.1" class="ltx_text ltx_font_bold">Image condition generation.</span> To synthesize realistic human images with paired pose annotations, we leverage ControlNet, equipped with the state-of-the-art diffusion model, SDXL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite>, as our image generator. Existing ControlNet variants take a 2D skeleton, depth map, or canny map as condition inputs. These inputs are typically detected from real-world images by pre-trained perception models. However, there exist two main drawbacks to generating image conditions from these pre-trained perception models. On one hand, itâ€™s laborious to crawl diverse human pose and shape images from the Internet. On the other, the perception models cannot ensure the generation of fully accurate annotations, thus the different modalities annotations have discrepancies, <em id="S3.SS3.p2.1.2" class="ltx_emph ltx_font_italic">e.g.</em>, the 2D keypoint heatmap from a 2D pose estimator and the depth map from a depth estimator are not aligned. In such cases, if we take the perception results as the multi-condition inputs of ControlNet, the generated images would probably have weird artifacts.</p>
</div>
<div id="S3.SS3.p3" class="ltx_para">
<p id="S3.SS3.p3.1" class="ltx_p">To resolve the problem, we construct the input of ControlNet by taking advantage of the 3D human parametric model, SMPL-X.
There exist several large-scale human motion capture databases <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> with diverse body poses and shapes in SMPL-X format.
Thanks to the disentanglement of the pose and shape parameters of the SMPL-X model, we can even recombine the two parameters to generate a human mesh that does not exist in the databases. For example, an overweight man doing an extremely difficult yoga pose.
Upon getting the simulated camera parameters aforementioned inÂ <a href="#S3.SS3" title="3.3 Initial Human Image and Annotation Generation â€£ 3 Method â€£ 3D Human Reconstruction in the Wild with Synthetic Data Using Generative ModelsWork was done when YG was visiting Zhejiang University. HC is the corresponding author." class="ltx_ref"><span class="ltx_text ltx_ref_tag">Sec.</span>Â <span class="ltx_text ltx_ref_tag">3.3</span></a> and 3D human mesh from SMPL-X, we can render an existing 3D human mesh into the image plane, as such, getting the corresponding surce normal map.
Notably, the surface normal map is proven to be crucial to generating accurate body shapes and orientation.</p>
</div>
<div id="S3.SS3.p4" class="ltx_para ltx_noindent">
<p id="S3.SS3.p4.1" class="ltx_p"><span id="S3.SS3.p4.1.1" class="ltx_text ltx_font_bold">Human <math id="S3.SS3.p4.1.1.m1.1" class="ltx_Math" alttext="\&amp;" display="inline"><semantics id="S3.SS3.p4.1.1.m1.1a"><mo id="S3.SS3.p4.1.1.m1.1.1" xref="S3.SS3.p4.1.1.m1.1.1.cmml">&amp;</mo><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.1.1.m1.1b"><and id="S3.SS3.p4.1.1.m1.1.1.cmml" xref="S3.SS3.p4.1.1.m1.1.1"></and></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.1.1.m1.1c">\&amp;</annotation></semantics></math> scene positioning.</span>
We offer an optional flexible background selection feature, allowing users to generate scenes based on text prompts solely or in conjunction with normal maps. To integrate specific backgrounds, we randomly select scene meshes from the ScanNet++ datasetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib85" title="" class="ltx_ref">85</a>]</cite> and utilize OctreeÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite> to partition the room mesh into discrete voxels. With vertex-level classification annotations, we efficiently identify ground plane normals and height to anchor the human mesh. We randomly allocate human mesh within unoccupied areas of the voxel space. Subsequently, we refine human mesh positioning by optimizing the translation using the Chamfer distance to preclude inter-mesh collisions. Finally, we simulate a random camera perspective. The intrinsic matrix is obtained with previous rules, while the extrinsic matrix is crafted using a random azimuth angle. We sample the cameraâ€™s height range [-1m, +1m] relative to the pelvis height, and look at a random point on the human torso, to achieve a realistic viewpoint.</p>
</div>
<div id="S3.SS3.p5" class="ltx_para ltx_noindent">
<p id="S3.SS3.p5.1" class="ltx_p"><span id="S3.SS3.p5.1.1" class="ltx_text ltx_font_bold">Text prompt generation.</span>
The aforementioned normal maps have two choices, with or without room mesh as backgrounds.
Since our background information is retrieved from Scannet++Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib85" title="" class="ltx_ref">85</a>]</cite>, for in-the-wild data, we need text prompts to provide background information. Moreover, the human bodyâ€™s normal maps are not fine-grained enough to determine the gender and appearance of the human.
Thus, we incorporate a structured text prompt template to handle this issue. In particular, we designed a simple text template as â€œA {gender} {action} {environment}". The gender and the action of the person are determined by the SMPL-X annotations. The environment is generated by a large language model, <em id="S3.SS3.p5.1.2" class="ltx_emph ltx_font_italic">i.e.</em>, ChatGPTÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref">51</a>]</cite> and LLAMAÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib70" title="" class="ltx_ref">70</a>]</cite>. To create photo-realistic humans, we also feed negative text prompts, <em id="S3.SS3.p5.1.3" class="ltx_emph ltx_font_italic">e.g.</em>, â€œugly, extra limbs, poorly drawn face, poorly drawn hands, poorly drawn feetâ€, to the model.
Finally, we have
all of the input conditions of the ControlNet. We apply a total of 40 inference steps for each sample. The resolution of the generated images are all <math id="S3.SS3.p5.1.m1.1" class="ltx_Math" alttext="768\times 768" display="inline"><semantics id="S3.SS3.p5.1.m1.1a"><mrow id="S3.SS3.p5.1.m1.1.1" xref="S3.SS3.p5.1.m1.1.1.cmml"><mn id="S3.SS3.p5.1.m1.1.1.2" xref="S3.SS3.p5.1.m1.1.1.2.cmml">768</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS3.p5.1.m1.1.1.1" xref="S3.SS3.p5.1.m1.1.1.1.cmml">Ã—</mo><mn id="S3.SS3.p5.1.m1.1.1.3" xref="S3.SS3.p5.1.m1.1.1.3.cmml">768</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.1.m1.1b"><apply id="S3.SS3.p5.1.m1.1.1.cmml" xref="S3.SS3.p5.1.m1.1.1"><times id="S3.SS3.p5.1.m1.1.1.1.cmml" xref="S3.SS3.p5.1.m1.1.1.1"></times><cn type="integer" id="S3.SS3.p5.1.m1.1.1.2.cmml" xref="S3.SS3.p5.1.m1.1.1.2">768</cn><cn type="integer" id="S3.SS3.p5.1.m1.1.1.3.cmml" xref="S3.SS3.p5.1.m1.1.1.3">768</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.1.m1.1c">768\times 768</annotation></semantics></math>. The generated images and the input conditions (normal maps, SMPL-X parameters) are regarded as the initial data pairs. See Sup. Mat. for detail analysis.</p>
</div>
<figure id="S3.F4" class="ltx_figure"><img src="/html/2403.11111/assets/x4.png" id="S3.F4.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="456" height="569" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F4.6.3.1" class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span id="S3.F4.4.2" class="ltx_text" style="font-size:90%;">Data sample visualization of <math id="S3.F4.3.1.m1.1" class="ltx_Math" alttext="\tt HumanWild" display="inline"><semantics id="S3.F4.3.1.m1.1b"><mi id="S3.F4.3.1.m1.1.1" xref="S3.F4.3.1.m1.1.1.cmml">ğ™·ğšğš–ğšŠğš—ğš†ğš’ğš•ğš</mi><annotation-xml encoding="MathML-Content" id="S3.F4.3.1.m1.1c"><ci id="S3.F4.3.1.m1.1.1.cmml" xref="S3.F4.3.1.m1.1.1">ğ™·ğšğš–ğšŠğš—ğš†ğš’ğš•ğš</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F4.3.1.m1.1d">\tt HumanWild</annotation></semantics></math>. For each data sample, the left side is the normal image rendered from SMPL-X model, the right side is the image generated by <math id="S3.F4.4.2.m2.1" class="ltx_Math" alttext="\tt HumanWild" display="inline"><semantics id="S3.F4.4.2.m2.1b"><mi id="S3.F4.4.2.m2.1.1" xref="S3.F4.4.2.m2.1.1.cmml">ğ™·ğšğš–ğšŠğš—ğš†ğš’ğš•ğš</mi><annotation-xml encoding="MathML-Content" id="S3.F4.4.2.m2.1c"><ci id="S3.F4.4.2.m2.1.1.cmml" xref="S3.F4.4.2.m2.1.1">ğ™·ğšğš–ğšŠğš—ğš†ğš’ğš•ğš</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F4.4.2.m2.1d">\tt HumanWild</annotation></semantics></math> pipeline. The first two rows demonstrate the indoor activities. The third row shows the generated images with huge distortion. The fourth row describes the diverse camera views. The fifth row shows overweight human bodies. </span></figcaption>
</figure>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Label Denoising</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p">The generated images are not always well-aligned with the input conditions. The most common incorrect case is the generated human and the input conditions form a mirror pair. To resolve this problem, we employ an off-the-shelf foundation segmentation model, <em id="S3.SS4.p1.1.1" class="ltx_emph ltx_font_italic">i.e.</em>, SAMÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>, to filter negative samples from the final dataset. Specifically, we first calculate the ground-truth mesh segmentation mask by rendering the 3D mesh into the image plane. Then, we sample a random point coordinate from the ground-truth segmentation mask and feed the generated image and this point coordinate into the SAM model, thereby we can get the predicted human mask for the generated image. Finally, we compute the intersection-over-union (IoU) metric between the ground-truth mask and prediction mask. We filter data samples with IoU lower than <math id="S3.SS4.p1.1.m1.1" class="ltx_Math" alttext="0.8" display="inline"><semantics id="S3.SS4.p1.1.m1.1a"><mn id="S3.SS4.p1.1.m1.1.1" xref="S3.SS4.p1.1.m1.1.1.cmml">0.8</mn><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.1.m1.1b"><cn type="float" id="S3.SS4.p1.1.m1.1.1.cmml" xref="S3.SS4.p1.1.m1.1.1">0.8</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.1.m1.1c">0.8</annotation></semantics></math>.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>

<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Implement Details and Evaluation Metrics</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">To illustrate the effectiveness and efficiency of our proposed <math id="S4.SS1.p1.1.m1.1" class="ltx_Math" alttext="\tt HumanWild" display="inline"><semantics id="S4.SS1.p1.1.m1.1a"><mi id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml">ğ™·ğšğš–ğšŠğš—ğš†ğš’ğš•ğš</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><ci id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1">ğ™·ğšğš–ğšŠğš—ğš†ğš’ğš•ğš</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">\tt HumanWild</annotation></semantics></math>, we report Frechet Inception Distance (FIDÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>) and Kernel Inception Distance (KIDÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>), which are widely used to measure the quality of the synthesized images.
We measure the alignment accuracy between the SMPLX-rendered mask and the generated images with mean intersection over union (mIoU).
We use standard metrics to evaluate body pose and shape accuracy. PVE and MPJPE represent the average error in vertices and joints positions, respectively, after aligning the pelvis. PA-MPJPE further aligns the rotation and scale before computing distance. PVE-T-SC is a per-vertex error in a neutral pose (T-pose) after scale correction. For a fair comparison with the CG-rendered counterpart, we sample SMPL-X parameters from the BEDLAMÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> dataset and render them into surface normal maps with random camera parameters illustrated inÂ <a href="#S3" title="3 Method â€£ 3D Human Reconstruction in the Wild with Synthetic Data Using Generative ModelsWork was done when YG was visiting Zhejiang University. HC is the corresponding author." class="ltx_ref"><span class="ltx_text ltx_ref_tag">Sec.</span>Â <span class="ltx_text ltx_ref_tag">3</span></a>. We re-implemented a regression-based HPS method, CLIFFÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>, for evaluating the effectiveness of the synthesized dataset on a variety of evaluation benchmarks, 3DPWÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite>, AGORAÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite>, EgoBodyÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib89" title="" class="ltx_ref">89</a>]</cite>, RICHÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>, and SSP-3DÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite> (for shape evaluation).</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Ablation on ControlNet Input Conditions</h3>

<figure id="S4.F5" class="ltx_figure"><img src="/html/2403.11111/assets/x5.png" id="S4.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="438" height="72" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.2.1.1" class="ltx_text" style="font-size:90%;">Figure 5</span>: </span><span id="S4.F5.3.2" class="ltx_text" style="font-size:90%;">Surface normal visualization. (a), (d) are two images sampled from LAION5BÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite>. (b), (e) are estimated by our method. (c), (f) are estimated by OmniData.</span></figcaption>
</figure>
<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">In the initial stages of our research, we employed various input conditions, including 2D keypoint heatmaps, depth images, and normal images, to generate data samples. However, a notable challenge emerged with regard to the ambiguity inherent in both the keypoint and depth conditions. Specifically, the diffusion model struggled to accurately discern the front and back of individuals depicted in these data modalities and had difficulty in aligning generated hands and faces with ground-truths (See Sup. Mat. for some failure cases),
yet we found surface normal conditional can greatly reduce this kind of ambiguity. Thus, we choose it as the input condition of the ControlNet. To get accurate surface normal maps in the wild, we train a customized diffusion model based on a photo-realistic synthetic indoor dataset, HypersimÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite>. As shown inÂ <a href="#S4.T3" title="In 4.2 Ablation on ControlNet Input Conditions â€£ 4 Experiments â€£ 3D Human Reconstruction in the Wild with Synthetic Data Using Generative ModelsWork was done when YG was visiting Zhejiang University. HC is the corresponding author." class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">3</span></a>, our surface normal estimator outperforms OmniDataÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> trained on a mixture of datasets, including HypersimÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite> dataset.
We also show qualitative surface normal results in Â <a href="#S4.F5" title="In 4.2 Ablation on ControlNet Input Conditions â€£ 4 Experiments â€£ 3D Human Reconstruction in the Wild with Synthetic Data Using Generative ModelsWork was done when YG was visiting Zhejiang University. HC is the corresponding author." class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">5</span></a>. The results show that our diffusion-based estimator can generate more detailed normal maps when compared with OmniDataÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> in real-world scenes. We annotate around 1M image/surface normal pairs from LAION5BÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite> and COYO-700MÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> for training ControlNet. Please refer to the supplementary material for more details.
<a href="#S4.T3" title="In 4.2 Ablation on ControlNet Input Conditions â€£ 4 Experiments â€£ 3D Human Reconstruction in the Wild with Synthetic Data Using Generative ModelsWork was done when YG was visiting Zhejiang University. HC is the corresponding author." class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">3</span></a> compares our trained ControlNet with two publicly available keypoint-based and depth-based ControlNetsÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib68" title="" class="ltx_ref">68</a>]</cite> in terms of generated image quality and image/ground-truth alignment accuracy. In order to ensure equitable comparison, all ControlNets employ aligned sets of 1,000 input conditions derived from identical SMPL-X parameters and camera specifications.
The results demonstrate that our ControlNet consistently outperforms the keypoint-based and depth-based ControlNet.</p>
</div>
<figure id="S4.T3" class="ltx_table">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.T3.3" class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_top" style="width:203.8pt;">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.T3.3.4.1.1" class="ltx_text" style="font-size:90%;">Table 2</span>: </span><span id="S4.T3.3.5.2" class="ltx_text" style="font-size:90%;">Ablation of different input conditions of ControlNet.</span></figcaption>
<div id="S4.T3.3.3" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:319.7pt;height:69pt;vertical-align:-1.5pt;"><span class="ltx_transformed_inner" style="transform:translate(-53.3pt,11.3pt) scale(0.75,0.75) ;">
<table id="S4.T3.3.3.3" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T3.3.3.3.4.1" class="ltx_tr">
<th id="S4.T3.3.3.3.4.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt">ControlNet</th>
<th id="S4.T3.3.3.3.4.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2">Image Quality</th>
<th id="S4.T3.3.3.3.4.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Alignment Accuracy</th>
</tr>
<tr id="S4.T3.3.3.3.3" class="ltx_tr">
<th id="S4.T3.3.3.3.3.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row">Condition</th>
<th id="S4.T3.1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">FID <math id="S4.T3.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T3.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S4.T3.1.1.1.1.1.m1.1.1" xref="S4.T3.1.1.1.1.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S4.T3.1.1.1.1.1.m1.1b"><ci id="S4.T3.1.1.1.1.1.m1.1.1.cmml" xref="S4.T3.1.1.1.1.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.1.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math>
</th>
<th id="S4.T3.2.2.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><math id="S4.T3.2.2.2.2.2.m1.1" class="ltx_Math" alttext="\text{KID}\downarrow" display="inline"><semantics id="S4.T3.2.2.2.2.2.m1.1a"><mrow id="S4.T3.2.2.2.2.2.m1.1.1" xref="S4.T3.2.2.2.2.2.m1.1.1.cmml"><mtext id="S4.T3.2.2.2.2.2.m1.1.1.2" xref="S4.T3.2.2.2.2.2.m1.1.1.2a.cmml">KID</mtext><mo stretchy="false" id="S4.T3.2.2.2.2.2.m1.1.1.1" xref="S4.T3.2.2.2.2.2.m1.1.1.1.cmml">â†“</mo><mi id="S4.T3.2.2.2.2.2.m1.1.1.3" xref="S4.T3.2.2.2.2.2.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.2.2.2.2.2.m1.1b"><apply id="S4.T3.2.2.2.2.2.m1.1.1.cmml" xref="S4.T3.2.2.2.2.2.m1.1.1"><ci id="S4.T3.2.2.2.2.2.m1.1.1.1.cmml" xref="S4.T3.2.2.2.2.2.m1.1.1.1">â†“</ci><ci id="S4.T3.2.2.2.2.2.m1.1.1.2a.cmml" xref="S4.T3.2.2.2.2.2.m1.1.1.2"><mtext id="S4.T3.2.2.2.2.2.m1.1.1.2.cmml" xref="S4.T3.2.2.2.2.2.m1.1.1.2">KID</mtext></ci><csymbol cd="latexml" id="S4.T3.2.2.2.2.2.m1.1.1.3.cmml" xref="S4.T3.2.2.2.2.2.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.2.2.2.2.2.m1.1c">\text{KID}\downarrow</annotation></semantics></math></th>
<th id="S4.T3.3.3.3.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">mIoU <math id="S4.T3.3.3.3.3.3.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T3.3.3.3.3.3.m1.1a"><mo stretchy="false" id="S4.T3.3.3.3.3.3.m1.1.1" xref="S4.T3.3.3.3.3.3.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S4.T3.3.3.3.3.3.m1.1b"><ci id="S4.T3.3.3.3.3.3.m1.1.1.cmml" xref="S4.T3.3.3.3.3.3.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.3.3.3.3.3.m1.1c">\uparrow</annotation></semantics></math>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T3.3.3.3.5.1" class="ltx_tr">
<th id="S4.T3.3.3.3.5.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">KeypointÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib68" title="" class="ltx_ref">68</a>]</cite>
</th>
<td id="S4.T3.3.3.3.5.1.2" class="ltx_td ltx_align_center ltx_border_t">29.6</td>
<td id="S4.T3.3.3.3.5.1.3" class="ltx_td ltx_align_center ltx_border_t">2.92</td>
<td id="S4.T3.3.3.3.5.1.4" class="ltx_td ltx_align_center ltx_border_t">41.3</td>
</tr>
<tr id="S4.T3.3.3.3.6.2" class="ltx_tr">
<th id="S4.T3.3.3.3.6.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">DepthÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>
</th>
<td id="S4.T3.3.3.3.6.2.2" class="ltx_td ltx_align_center">28.1</td>
<td id="S4.T3.3.3.3.6.2.3" class="ltx_td ltx_align_center">2.87</td>
<td id="S4.T3.3.3.3.6.2.4" class="ltx_td ltx_align_center">49.2</td>
</tr>
<tr id="S4.T3.3.3.3.7.3" class="ltx_tr">
<th id="S4.T3.3.3.3.7.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">Normal</th>
<td id="S4.T3.3.3.3.7.3.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T3.3.3.3.7.3.2.1" class="ltx_text ltx_font_bold">24.5</span></td>
<td id="S4.T3.3.3.3.7.3.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T3.3.3.3.7.3.3.1" class="ltx_text ltx_font_bold">2.83</span></td>
<td id="S4.T3.3.3.3.7.3.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T3.3.3.3.7.3.4.1" class="ltx_text ltx_font_bold">56.8</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.T3.6" class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_top" style="width:225.5pt;">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.T3.6.4.1.1" class="ltx_text" style="font-size:90%;">Table 3</span>: </span><span id="S4.T3.6.5.2" class="ltx_text" style="font-size:90%;">Surface normal evaluation on Hypersim dataset.</span></figcaption>
<div id="S4.T3.6.3" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:364.8pt;height:42.8pt;vertical-align:-2.3pt;"><span class="ltx_transformed_inner" style="transform:translate(-60.8pt,6.8pt) scale(0.75,0.75) ;">
<table id="S4.T3.6.3.3" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T3.6.3.3.3" class="ltx_tr">
<th id="S4.T3.6.3.3.3.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt">Model</th>
<th id="S4.T3.6.3.3.3.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt">encoder</th>
<th id="S4.T3.6.3.3.3.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt">train</th>
<th id="S4.T3.4.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Mean<math id="S4.T3.4.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T3.4.1.1.1.1.m1.1a"><mo stretchy="false" id="S4.T3.4.1.1.1.1.m1.1.1" xref="S4.T3.4.1.1.1.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S4.T3.4.1.1.1.1.m1.1b"><ci id="S4.T3.4.1.1.1.1.m1.1.1.cmml" xref="S4.T3.4.1.1.1.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.4.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math>
</th>
<th id="S4.T3.5.2.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Med<math id="S4.T3.5.2.2.2.2.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T3.5.2.2.2.2.m1.1a"><mo stretchy="false" id="S4.T3.5.2.2.2.2.m1.1.1" xref="S4.T3.5.2.2.2.2.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S4.T3.5.2.2.2.2.m1.1b"><ci id="S4.T3.5.2.2.2.2.m1.1.1.cmml" xref="S4.T3.5.2.2.2.2.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.5.2.2.2.2.m1.1c">\downarrow</annotation></semantics></math>
</th>
<th id="S4.T3.6.3.3.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">RMS<math id="S4.T3.6.3.3.3.3.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T3.6.3.3.3.3.m1.1a"><mo stretchy="false" id="S4.T3.6.3.3.3.3.m1.1.1" xref="S4.T3.6.3.3.3.3.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S4.T3.6.3.3.3.3.m1.1b"><ci id="S4.T3.6.3.3.3.3.m1.1.1.cmml" xref="S4.T3.6.3.3.3.3.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.6.3.3.3.3.m1.1c">\downarrow</annotation></semantics></math>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T3.6.3.3.4.1" class="ltx_tr">
<th id="S4.T3.6.3.3.4.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">OmniDataÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib83" title="" class="ltx_ref">83</a>]</cite>
</th>
<th id="S4.T3.6.3.3.4.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">DPT</th>
<th id="S4.T3.6.3.3.4.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">mix</th>
<td id="S4.T3.6.3.3.4.1.4" class="ltx_td ltx_align_center ltx_border_t">25.3</td>
<td id="S4.T3.6.3.3.4.1.5" class="ltx_td ltx_align_center ltx_border_t">16.2</td>
<td id="S4.T3.6.3.3.4.1.6" class="ltx_td ltx_align_center ltx_border_t">30.4</td>
</tr>
<tr id="S4.T3.6.3.3.5.2" class="ltx_tr">
<th id="S4.T3.6.3.3.5.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r">Ours</th>
<th id="S4.T3.6.3.3.5.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r">UNet</th>
<th id="S4.T3.6.3.3.5.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r">Hypersim</th>
<td id="S4.T3.6.3.3.5.2.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T3.6.3.3.5.2.4.1" class="ltx_text ltx_font_bold">18.9</span></td>
<td id="S4.T3.6.3.3.5.2.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T3.6.3.3.5.2.5.1" class="ltx_text ltx_font_bold">9.5</span></td>
<td id="S4.T3.6.3.3.5.2.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T3.6.3.3.5.2.6.1" class="ltx_text ltx_font_bold">23.2</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</div>
</div>
</figure>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Verification of the Necessity of In-the-wild 3D Data</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">Proper initialization of backbone weights is crucial for the performance of HPS models.
Different weight initialization strategies profoundly impact a HPS modelâ€™s convergence speed and final accuracy. HMR-benchmarksÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite> conduct systematic analysis by initializing the same backbone pre-trained with different sources, <em id="S4.SS3.p1.1.1" class="ltx_emph ltx_font_italic">i.e.</em>, ImageNet classification weights, 2D pose estimation weights from MPII and COCO. The first three columns of <a href="#S4.T4" title="In 4.3 Verification of the Necessity of In-the-wild 3D Data â€£ 4 Experiments â€£ 3D Human Reconstruction in the Wild with Synthetic Data Using Generative ModelsWork was done when YG was visiting Zhejiang University. HC is the corresponding author." class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">4</span></a> show the result of their paper. In conclusion, employing a backbone pre-trained on in-the-wild pose estimation datasets proves to be beneficial for HPS tasks. Furthermore, the selection of the pose estimation dataset for pretraining significantly influences model performance. Notably, datasets like COCO demonstrate superior performance compared to MPII, likely due to the greater diversity and complexity of wild scenes contained within COCO. Columns 4 to 6 of the <a href="#S4.T4" title="In 4.3 Verification of the Necessity of In-the-wild 3D Data â€£ 4 Experiments â€£ 3D Human Reconstruction in the Wild with Synthetic Data Using Generative ModelsWork was done when YG was visiting Zhejiang University. HC is the corresponding author." class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">4</span></a> elucidate the impact of backbone pretraining on CG-rendered datasets, BEDLAMÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> and AGORAÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite>. A consistent conclusion is drawn from these results that pretraining with 2D wild data also has a great positive impact on CG-rendered datasets. We posit that neither indoor-mocap datasets nor CG-rendered datasets offer a sufficiently varied array of photo-realistic, in-the-wild scenes. Consequently, the network may struggle to acquire robust features conducive to generalizable testing.
In the final column of Â <a href="#S4.T4" title="In 4.3 Verification of the Necessity of In-the-wild 3D Data â€£ 4 Experiments â€£ 3D Human Reconstruction in the Wild with Synthetic Data Using Generative ModelsWork was done when YG was visiting Zhejiang University. HC is the corresponding author." class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">4</span></a>, the inclusion of in-the-wild synthesized 3D data generated by <math id="S4.SS3.p1.1.m1.1" class="ltx_Math" alttext="\tt HumanWild" display="inline"><semantics id="S4.SS3.p1.1.m1.1a"><mi id="S4.SS3.p1.1.m1.1.1" xref="S4.SS3.p1.1.m1.1.1.cmml">ğ™·ğšğš–ğšŠğš—ğš†ğš’ğš•ğš</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.1.m1.1b"><ci id="S4.SS3.p1.1.m1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1">ğ™·ğšğš–ğšŠğš—ğš†ğš’ğš•ğš</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.1.m1.1c">\tt HumanWild</annotation></semantics></math> significantly enhances the HPS performance of the CG-rendered datasets.
Hence, data synthesized by diffusion models, featuring diverse human identities and real-world scenes, complements CG-rendered data effectively.</p>
</div>
<figure id="S4.T4" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 4: </span>Ablation experiments on 3D pose and shape estimation. â€˜Râ€™ denotes mixed real-world datasets, â€˜Hâ€™ denotes <math id="S4.T4.2.m1.1" class="ltx_Math" alttext="\tt HumanWild" display="inline"><semantics id="S4.T4.2.m1.1b"><mi id="S4.T4.2.m1.1.1" xref="S4.T4.2.m1.1.1.cmml">ğ™·ğšğš–ğšŠğš—ğš†ğš’ğš•ğš</mi><annotation-xml encoding="MathML-Content" id="S4.T4.2.m1.1c"><ci id="S4.T4.2.m1.1.1.cmml" xref="S4.T4.2.m1.1.1">ğ™·ğšğš–ğšŠğš—ğš†ğš’ğš•ğš</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.2.m1.1d">\tt HumanWild</annotation></semantics></math>, â€˜Bâ€™ denotes BEDLAM and â€˜Aâ€™ denotes AGORA. PA-MPJPE, MPJPE and PVE are evaluated on 3DPW. PVE-T-SC is evaluated on SSP-3D.</figcaption>
<div id="S4.T4.6" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:403.3pt;height:120.4pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-41.1pt,12.2pt) scale(0.830644802631635,0.830644802631635) ;">
<table id="S4.T4.6.4" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T4.6.4.4" class="ltx_tr">
<th id="S4.T4.6.4.4.5" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_tt" style="padding-left:8.0pt;padding-right:8.0pt;"><span id="S4.T4.6.4.4.5.1" class="ltx_text" style="font-size:90%;">Method</span></th>
<th id="S4.T4.6.4.4.6" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_tt" style="padding-left:8.0pt;padding-right:8.0pt;"><span id="S4.T4.6.4.4.6.1" class="ltx_text" style="font-size:90%;">Dataset</span></th>
<th id="S4.T4.6.4.4.7" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_tt" style="padding-left:8.0pt;padding-right:8.0pt;"><span id="S4.T4.6.4.4.7.1" class="ltx_text" style="font-size:90%;">Pretrain</span></th>
<td id="S4.T4.3.1.1.1" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:8.0pt;padding-right:8.0pt;">
<span id="S4.T4.3.1.1.1.1" class="ltx_text" style="font-size:90%;">PA-MPJPE</span><math id="S4.T4.3.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T4.3.1.1.1.m1.1a"><mo mathsize="90%" stretchy="false" id="S4.T4.3.1.1.1.m1.1.1" xref="S4.T4.3.1.1.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S4.T4.3.1.1.1.m1.1b"><ci id="S4.T4.3.1.1.1.m1.1.1.cmml" xref="S4.T4.3.1.1.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.3.1.1.1.m1.1c">\downarrow</annotation></semantics></math>
</td>
<td id="S4.T4.4.2.2.2" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:8.0pt;padding-right:8.0pt;">
<span id="S4.T4.4.2.2.2.1" class="ltx_text" style="font-size:90%;">MPJPE</span><math id="S4.T4.4.2.2.2.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T4.4.2.2.2.m1.1a"><mo mathsize="90%" stretchy="false" id="S4.T4.4.2.2.2.m1.1.1" xref="S4.T4.4.2.2.2.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S4.T4.4.2.2.2.m1.1b"><ci id="S4.T4.4.2.2.2.m1.1.1.cmml" xref="S4.T4.4.2.2.2.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.4.2.2.2.m1.1c">\downarrow</annotation></semantics></math>
</td>
<td id="S4.T4.5.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:8.0pt;padding-right:8.0pt;">
<span id="S4.T4.5.3.3.3.1" class="ltx_text" style="font-size:90%;">PVE</span><math id="S4.T4.5.3.3.3.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T4.5.3.3.3.m1.1a"><mo mathsize="90%" stretchy="false" id="S4.T4.5.3.3.3.m1.1.1" xref="S4.T4.5.3.3.3.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S4.T4.5.3.3.3.m1.1b"><ci id="S4.T4.5.3.3.3.m1.1.1.cmml" xref="S4.T4.5.3.3.3.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.5.3.3.3.m1.1c">\downarrow</annotation></semantics></math>
</td>
<td id="S4.T4.6.4.4.4" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:8.0pt;padding-right:8.0pt;">
<span id="S4.T4.6.4.4.4.1" class="ltx_text" style="font-size:90%;">PVE-T-SC</span><math id="S4.T4.6.4.4.4.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T4.6.4.4.4.m1.1a"><mo mathsize="90%" stretchy="false" id="S4.T4.6.4.4.4.m1.1.1" xref="S4.T4.6.4.4.4.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S4.T4.6.4.4.4.m1.1b"><ci id="S4.T4.6.4.4.4.m1.1.1.cmml" xref="S4.T4.6.4.4.4.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.6.4.4.4.m1.1c">\downarrow</annotation></semantics></math>
</td>
</tr>
<tr id="S4.T4.6.4.5.1" class="ltx_tr">
<th id="S4.T4.6.4.5.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">
<span id="S4.T4.6.4.5.1.1.1" class="ltx_text" style="font-size:90%;">PAREÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T4.6.4.5.1.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib31" title="" class="ltx_ref">31</a>, <a href="#bib.bib54" title="" class="ltx_ref">54</a><span id="S4.T4.6.4.5.1.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</th>
<th id="S4.T4.6.4.5.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;"><span id="S4.T4.6.4.5.1.2.1" class="ltx_text" style="font-size:90%;">R</span></th>
<th id="S4.T4.6.4.5.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;"><span id="S4.T4.6.4.5.1.3.1" class="ltx_text" style="font-size:90%;">ImageNet</span></th>
<td id="S4.T4.6.4.5.1.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;"><span id="S4.T4.6.4.5.1.4.1" class="ltx_text" style="font-size:90%;">54.8</span></td>
<td id="S4.T4.6.4.5.1.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;"><span id="S4.T4.6.4.5.1.5.1" class="ltx_text" style="font-size:90%;">N/A</span></td>
<td id="S4.T4.6.4.5.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;"><span id="S4.T4.6.4.5.1.6.1" class="ltx_text" style="font-size:90%;">N/A</span></td>
<td id="S4.T4.6.4.5.1.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;"><span id="S4.T4.6.4.5.1.7.1" class="ltx_text" style="font-size:90%;">N/A</span></td>
</tr>
<tr id="S4.T4.6.4.6.2" class="ltx_tr">
<th id="S4.T4.6.4.6.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:8.0pt;padding-right:8.0pt;">
<span id="S4.T4.6.4.6.2.1.1" class="ltx_text" style="font-size:90%;">PAREÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T4.6.4.6.2.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib31" title="" class="ltx_ref">31</a>, <a href="#bib.bib54" title="" class="ltx_ref">54</a><span id="S4.T4.6.4.6.2.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</th>
<th id="S4.T4.6.4.6.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:8.0pt;padding-right:8.0pt;"><span id="S4.T4.6.4.6.2.2.1" class="ltx_text" style="font-size:90%;">R</span></th>
<th id="S4.T4.6.4.6.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:8.0pt;padding-right:8.0pt;"><span id="S4.T4.6.4.6.2.3.1" class="ltx_text" style="font-size:90%;">MPII</span></th>
<td id="S4.T4.6.4.6.2.4" class="ltx_td ltx_align_center" style="padding-left:8.0pt;padding-right:8.0pt;"><span id="S4.T4.6.4.6.2.4.1" class="ltx_text" style="font-size:90%;">51.5</span></td>
<td id="S4.T4.6.4.6.2.5" class="ltx_td ltx_align_center" style="padding-left:8.0pt;padding-right:8.0pt;"><span id="S4.T4.6.4.6.2.5.1" class="ltx_text" style="font-size:90%;">N/A</span></td>
<td id="S4.T4.6.4.6.2.6" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:8.0pt;padding-right:8.0pt;"><span id="S4.T4.6.4.6.2.6.1" class="ltx_text" style="font-size:90%;">N/A</span></td>
<td id="S4.T4.6.4.6.2.7" class="ltx_td ltx_align_center" style="padding-left:8.0pt;padding-right:8.0pt;"><span id="S4.T4.6.4.6.2.7.1" class="ltx_text" style="font-size:90%;">N/A</span></td>
</tr>
<tr id="S4.T4.6.4.7.3" class="ltx_tr">
<th id="S4.T4.6.4.7.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:8.0pt;padding-right:8.0pt;">
<span id="S4.T4.6.4.7.3.1.1" class="ltx_text" style="font-size:90%;">PAREÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T4.6.4.7.3.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib31" title="" class="ltx_ref">31</a>, <a href="#bib.bib54" title="" class="ltx_ref">54</a><span id="S4.T4.6.4.7.3.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</th>
<th id="S4.T4.6.4.7.3.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:8.0pt;padding-right:8.0pt;"><span id="S4.T4.6.4.7.3.2.1" class="ltx_text" style="font-size:90%;">R</span></th>
<th id="S4.T4.6.4.7.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:8.0pt;padding-right:8.0pt;"><span id="S4.T4.6.4.7.3.3.1" class="ltx_text" style="font-size:90%;">COCO</span></th>
<td id="S4.T4.6.4.7.3.4" class="ltx_td ltx_align_center" style="padding-left:8.0pt;padding-right:8.0pt;"><span id="S4.T4.6.4.7.3.4.1" class="ltx_text" style="font-size:90%;">49.5</span></td>
<td id="S4.T4.6.4.7.3.5" class="ltx_td ltx_align_center" style="padding-left:8.0pt;padding-right:8.0pt;"><span id="S4.T4.6.4.7.3.5.1" class="ltx_text" style="font-size:90%;">N/A</span></td>
<td id="S4.T4.6.4.7.3.6" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:8.0pt;padding-right:8.0pt;"><span id="S4.T4.6.4.7.3.6.1" class="ltx_text" style="font-size:90%;">N/A</span></td>
<td id="S4.T4.6.4.7.3.7" class="ltx_td ltx_align_center" style="padding-left:8.0pt;padding-right:8.0pt;"><span id="S4.T4.6.4.7.3.7.1" class="ltx_text" style="font-size:90%;">N/A</span></td>
</tr>
<tr id="S4.T4.6.4.8.4" class="ltx_tr">
<th id="S4.T4.6.4.8.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">
<span id="S4.T4.6.4.8.4.1.1" class="ltx_text" style="font-size:90%;">CLIFFÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T4.6.4.8.4.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib39" title="" class="ltx_ref">39</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a><span id="S4.T4.6.4.8.4.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</th>
<th id="S4.T4.6.4.8.4.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;"><span id="S4.T4.6.4.8.4.2.1" class="ltx_text" style="font-size:90%;">B+A</span></th>
<th id="S4.T4.6.4.8.4.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;"><span id="S4.T4.6.4.8.4.3.1" class="ltx_text" style="font-size:90%;">scratch</span></th>
<td id="S4.T4.6.4.8.4.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;"><span id="S4.T4.6.4.8.4.4.1" class="ltx_text" style="font-size:90%;">61.7</span></td>
<td id="S4.T4.6.4.8.4.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;"><span id="S4.T4.6.4.8.4.5.1" class="ltx_text" style="font-size:90%;">96.5</span></td>
<td id="S4.T4.6.4.8.4.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;"><span id="S4.T4.6.4.8.4.6.1" class="ltx_text" style="font-size:90%;">115.0</span></td>
<td id="S4.T4.6.4.8.4.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;"><span id="S4.T4.6.4.8.4.7.1" class="ltx_text" style="font-size:90%;">N/A</span></td>
</tr>
<tr id="S4.T4.6.4.9.5" class="ltx_tr">
<th id="S4.T4.6.4.9.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:8.0pt;padding-right:8.0pt;">
<span id="S4.T4.6.4.9.5.1.1" class="ltx_text" style="font-size:90%;">CLIFFÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T4.6.4.9.5.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib39" title="" class="ltx_ref">39</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a><span id="S4.T4.6.4.9.5.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</th>
<th id="S4.T4.6.4.9.5.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:8.0pt;padding-right:8.0pt;"><span id="S4.T4.6.4.9.5.2.1" class="ltx_text" style="font-size:90%;">B+A</span></th>
<th id="S4.T4.6.4.9.5.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:8.0pt;padding-right:8.0pt;"><span id="S4.T4.6.4.9.5.3.1" class="ltx_text" style="font-size:90%;">ImageNet</span></th>
<td id="S4.T4.6.4.9.5.4" class="ltx_td ltx_align_center" style="padding-left:8.0pt;padding-right:8.0pt;"><span id="S4.T4.6.4.9.5.4.1" class="ltx_text" style="font-size:90%;">51.8</span></td>
<td id="S4.T4.6.4.9.5.5" class="ltx_td ltx_align_center" style="padding-left:8.0pt;padding-right:8.0pt;"><span id="S4.T4.6.4.9.5.5.1" class="ltx_text" style="font-size:90%;">82.1</span></td>
<td id="S4.T4.6.4.9.5.6" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:8.0pt;padding-right:8.0pt;"><span id="S4.T4.6.4.9.5.6.1" class="ltx_text" style="font-size:90%;">96.9</span></td>
<td id="S4.T4.6.4.9.5.7" class="ltx_td ltx_align_center" style="padding-left:8.0pt;padding-right:8.0pt;"><span id="S4.T4.6.4.9.5.7.1" class="ltx_text" style="font-size:90%;">N/A</span></td>
</tr>
<tr id="S4.T4.6.4.10.6" class="ltx_tr">
<th id="S4.T4.6.4.10.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:8.0pt;padding-right:8.0pt;">
<span id="S4.T4.6.4.10.6.1.1" class="ltx_text" style="font-size:90%;">CLIFFÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T4.6.4.10.6.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib39" title="" class="ltx_ref">39</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a><span id="S4.T4.6.4.10.6.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</th>
<th id="S4.T4.6.4.10.6.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:8.0pt;padding-right:8.0pt;"><span id="S4.T4.6.4.10.6.2.1" class="ltx_text" style="font-size:90%;">B+A</span></th>
<th id="S4.T4.6.4.10.6.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" style="padding-left:8.0pt;padding-right:8.0pt;"><span id="S4.T4.6.4.10.6.3.1" class="ltx_text" style="font-size:90%;">COCO</span></th>
<td id="S4.T4.6.4.10.6.4" class="ltx_td ltx_align_center" style="padding-left:8.0pt;padding-right:8.0pt;"><span id="S4.T4.6.4.10.6.4.1" class="ltx_text" style="font-size:90%;">47.4</span></td>
<td id="S4.T4.6.4.10.6.5" class="ltx_td ltx_align_center" style="padding-left:8.0pt;padding-right:8.0pt;"><span id="S4.T4.6.4.10.6.5.1" class="ltx_text" style="font-size:90%;">73.0</span></td>
<td id="S4.T4.6.4.10.6.6" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:8.0pt;padding-right:8.0pt;"><span id="S4.T4.6.4.10.6.6.1" class="ltx_text" style="font-size:90%;">86.6</span></td>
<td id="S4.T4.6.4.10.6.7" class="ltx_td ltx_align_center" style="padding-left:8.0pt;padding-right:8.0pt;"><span id="S4.T4.6.4.10.6.7.1" class="ltx_text" style="font-size:90%;">14.2</span></td>
</tr>
<tr id="S4.T4.6.4.11.7" class="ltx_tr">
<th id="S4.T4.6.4.11.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">
<span id="S4.T4.6.4.11.7.1.1" class="ltx_text" style="font-size:90%;">CLIFFÂ </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S4.T4.6.4.11.7.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib39" title="" class="ltx_ref">39</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a><span id="S4.T4.6.4.11.7.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</th>
<th id="S4.T4.6.4.11.7.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;">
<span id="S4.T4.6.4.11.7.2.1" class="ltx_text" style="font-size:90%;">B+A+</span><span id="S4.T4.6.4.11.7.2.2" class="ltx_text ltx_font_bold" style="font-size:90%;">H</span>
</th>
<th id="S4.T4.6.4.11.7.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;"><span id="S4.T4.6.4.11.7.3.1" class="ltx_text" style="font-size:90%;">COCO</span></th>
<td id="S4.T4.6.4.11.7.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;"><span id="S4.T4.6.4.11.7.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">44.9</span></td>
<td id="S4.T4.6.4.11.7.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;"><span id="S4.T4.6.4.11.7.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">70.2</span></td>
<td id="S4.T4.6.4.11.7.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;"><span id="S4.T4.6.4.11.7.6.1" class="ltx_text ltx_font_bold" style="font-size:90%;">82.7</span></td>
<td id="S4.T4.6.4.11.7.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:8.0pt;padding-right:8.0pt;"><span id="S4.T4.6.4.11.7.7.1" class="ltx_text ltx_font_bold" style="font-size:90%;">13.9</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Scale-up </h3>

<figure id="S4.T5" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S4.T5.3.1.1" class="ltx_text" style="font-size:90%;">Table 5</span>: </span><span id="S4.T5.4.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Scale-up ablation.<span id="S4.T5.4.2.1" class="ltx_text ltx_font_medium"> We study the scaling law of the amount of data and the model sizes. The metrics are MPJPE for Human36MÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> and PVE for other evaluation benchmarks.
Foundation models are named â€œViT-M", where M indicates the size of ViT backbone (S, B, L, H).
MPE: mean primary error cross 5 evaluation benchmarks. AGORA uses the validation set, and EgoBody uses the EgoSet.
</span></span></figcaption>
<div id="S4.T5.5" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:80.4pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-123.1pt,22.8pt) scale(0.637782496968887,0.637782496968887) ;">
<table id="S4.T5.5.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T5.5.1.1.1" class="ltx_tr">
<th id="S4.T5.5.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt">#Crops</th>
<th id="S4.T5.5.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt">#Inst.</th>
<th id="S4.T5.5.1.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt">Model</th>
<th id="S4.T5.5.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt">#Param.</th>
<th id="S4.T5.5.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">AGORAÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite>
</th>
<th id="S4.T5.5.1.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">EgoBodyÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib89" title="" class="ltx_ref">89</a>]</cite>
</th>
<th id="S4.T5.5.1.1.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">RICHÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>
</th>
<th id="S4.T5.5.1.1.1.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">3DPWÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite>
</th>
<th id="S4.T5.5.1.1.1.9" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt">H36MÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>
</th>
<th id="S4.T5.5.1.1.1.10" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">MPE</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T5.5.1.2.1" class="ltx_tr">
<th id="S4.T5.5.1.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">25%</th>
<th id="S4.T5.5.1.2.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">0.19M</th>
<th id="S4.T5.5.1.2.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">ViT-S</th>
<th id="S4.T5.5.1.2.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">23M</th>
<td id="S4.T5.5.1.2.1.5" class="ltx_td ltx_align_center ltx_border_t">125.0</td>
<td id="S4.T5.5.1.2.1.6" class="ltx_td ltx_align_center ltx_border_t">114.2</td>
<td id="S4.T5.5.1.2.1.7" class="ltx_td ltx_align_center ltx_border_t">116.5</td>
<td id="S4.T5.5.1.2.1.8" class="ltx_td ltx_align_center ltx_border_t">118.2</td>
<td id="S4.T5.5.1.2.1.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">102.3</td>
<td id="S4.T5.5.1.2.1.10" class="ltx_td ltx_align_center ltx_border_t">115.2</td>
</tr>
<tr id="S4.T5.5.1.3.2" class="ltx_tr">
<th id="S4.T5.5.1.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">50%</th>
<th id="S4.T5.5.1.3.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">0.39M</th>
<th id="S4.T5.5.1.3.2.3" class="ltx_td ltx_align_left ltx_th ltx_th_row">ViT-S</th>
<th id="S4.T5.5.1.3.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">23M</th>
<td id="S4.T5.5.1.3.2.5" class="ltx_td ltx_align_center">116.2</td>
<td id="S4.T5.5.1.3.2.6" class="ltx_td ltx_align_center">103.6</td>
<td id="S4.T5.5.1.3.2.7" class="ltx_td ltx_align_center">104.1</td>
<td id="S4.T5.5.1.3.2.8" class="ltx_td ltx_align_center">110.4</td>
<td id="S4.T5.5.1.3.2.9" class="ltx_td ltx_align_center ltx_border_r">95.6</td>
<td id="S4.T5.5.1.3.2.10" class="ltx_td ltx_align_center">106.0</td>
</tr>
<tr id="S4.T5.5.1.4.3" class="ltx_tr">
<th id="S4.T5.5.1.4.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">100%</th>
<th id="S4.T5.5.1.4.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">0.79M</th>
<th id="S4.T5.5.1.4.3.3" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">ViT-S</th>
<th id="S4.T5.5.1.4.3.4" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">23M</th>
<td id="S4.T5.5.1.4.3.5" class="ltx_td ltx_align_center ltx_border_t">106.8</td>
<td id="S4.T5.5.1.4.3.6" class="ltx_td ltx_align_center ltx_border_t">97.3</td>
<td id="S4.T5.5.1.4.3.7" class="ltx_td ltx_align_center ltx_border_t">107.7</td>
<td id="S4.T5.5.1.4.3.8" class="ltx_td ltx_align_center ltx_border_t">106.5</td>
<td id="S4.T5.5.1.4.3.9" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">87.1</td>
<td id="S4.T5.5.1.4.3.10" class="ltx_td ltx_align_center ltx_border_t">101.1</td>
</tr>
<tr id="S4.T5.5.1.5.4" class="ltx_tr">
<th id="S4.T5.5.1.5.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">100%</th>
<th id="S4.T5.5.1.5.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">0.79M</th>
<th id="S4.T5.5.1.5.4.3" class="ltx_td ltx_align_left ltx_th ltx_th_row">ViT-B</th>
<th id="S4.T5.5.1.5.4.4" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">88M</th>
<td id="S4.T5.5.1.5.4.5" class="ltx_td ltx_align_center">103.6</td>
<td id="S4.T5.5.1.5.4.6" class="ltx_td ltx_align_center">94.2</td>
<td id="S4.T5.5.1.5.4.7" class="ltx_td ltx_align_center">105.1</td>
<td id="S4.T5.5.1.5.4.8" class="ltx_td ltx_align_center">103.5</td>
<td id="S4.T5.5.1.5.4.9" class="ltx_td ltx_align_center ltx_border_r">82.5</td>
<td id="S4.T5.5.1.5.4.10" class="ltx_td ltx_align_center">97.8</td>
</tr>
<tr id="S4.T5.5.1.6.5" class="ltx_tr">
<th id="S4.T5.5.1.6.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">100%</th>
<th id="S4.T5.5.1.6.5.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">0.79M</th>
<th id="S4.T5.5.1.6.5.3" class="ltx_td ltx_align_left ltx_th ltx_th_row">ViT-L</th>
<th id="S4.T5.5.1.6.5.4" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">305M</th>
<td id="S4.T5.5.1.6.5.5" class="ltx_td ltx_align_center">97.5</td>
<td id="S4.T5.5.1.6.5.6" class="ltx_td ltx_align_center">85.6</td>
<td id="S4.T5.5.1.6.5.7" class="ltx_td ltx_align_center">97.2</td>
<td id="S4.T5.5.1.6.5.8" class="ltx_td ltx_align_center">97.4</td>
<td id="S4.T5.5.1.6.5.9" class="ltx_td ltx_align_center ltx_border_r">75.7</td>
<td id="S4.T5.5.1.6.5.10" class="ltx_td ltx_align_center">90.7</td>
</tr>
<tr id="S4.T5.5.1.7.6" class="ltx_tr">
<th id="S4.T5.5.1.7.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb">100%</th>
<th id="S4.T5.5.1.7.6.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb">0.79M</th>
<th id="S4.T5.5.1.7.6.3" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">ViT-H</th>
<th id="S4.T5.5.1.7.6.4" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r">633M</th>
<td id="S4.T5.5.1.7.6.5" class="ltx_td ltx_align_center ltx_border_bb">90.2</td>
<td id="S4.T5.5.1.7.6.6" class="ltx_td ltx_align_center ltx_border_bb">82.3</td>
<td id="S4.T5.5.1.7.6.7" class="ltx_td ltx_align_center ltx_border_bb">92.1</td>
<td id="S4.T5.5.1.7.6.8" class="ltx_td ltx_align_center ltx_border_bb">90.3</td>
<td id="S4.T5.5.1.7.6.9" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">72.4</td>
<td id="S4.T5.5.1.7.6.10" class="ltx_td ltx_align_center ltx_border_bb">85.5</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p">We perform experiments to show the effectiveness of the generated datasets by studying the scaling law of the amount of data and the model sizes inÂ <a href="#S4.T5" title="In 4.4 Scale-up â€£ 4 Experiments â€£ 3D Human Reconstruction in the Wild with Synthetic Data Using Generative ModelsWork was done when YG was visiting Zhejiang University. HC is the corresponding author." class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">5</span></a>. Notably, our training set is independent of the evaluation benchmarks inÂ <a href="#S4.T5" title="In 4.4 Scale-up â€£ 4 Experiments â€£ 3D Human Reconstruction in the Wild with Synthetic Data Using Generative ModelsWork was done when YG was visiting Zhejiang University. HC is the corresponding author." class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">5</span></a>. We show results with various ViT backbones and percentages of the proposed dataset. It is observed that 1). more training data leads to better performance. 2). A larger backbone achieves higher performance on the proposed dataset.</p>
</div>
</section>
<section id="S4.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5 </span>Comparing with Other Real/Synthetic Datasets</h3>

<div id="S4.SS5.p1" class="ltx_para">
<p id="S4.SS5.p1.1" class="ltx_p">In Table <a href="#S4.T6" title="Table 6 â€£ 4.5 Comparing with Other Real/Synthetic Datasets â€£ 4 Experiments â€£ 3D Human Reconstruction in the Wild with Synthetic Data Using Generative ModelsWork was done when YG was visiting Zhejiang University. HC is the corresponding author." class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>, we analyze the performance of different training datasets using mixed strategies on CLIFF with HRNet-W48 backbone. Key findings are:
1). CG-rendered data outperforms real-world data (motion-capture, pseudo-labeled) on 3DPW and RICH datasets, suggesting synthetic data advantages.
2). Solely training on HumanWild yields slightly lower performance than BEDLAM, we conjecture that there still exists label noise, especially in hand and face parameters.
3). Combining HumanWild with CG-rendered datasets (BEDLAM, AGORA) and marker-based dataset (3DPW) enhances performance, emphasizing the benefit of diverse data integration.</p>
</div>
<figure id="S4.T6" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T6.10.2.1" class="ltx_text" style="font-size:90%;">Table 6</span>: </span><span id="S4.T6.2.1" class="ltx_text" style="font-size:90%;">Reconstruction error on 3DPW and RICH. â€˜Râ€™ denotes mixed real-world datasets, â€˜Hâ€™ denotes <math id="S4.T6.2.1.m1.1" class="ltx_Math" alttext="\tt HumanWild" display="inline"><semantics id="S4.T6.2.1.m1.1b"><mi id="S4.T6.2.1.m1.1.1" xref="S4.T6.2.1.m1.1.1.cmml">ğ™·ğšğš–ğšŠğš—ğš†ğš’ğš•ğš</mi><annotation-xml encoding="MathML-Content" id="S4.T6.2.1.m1.1c"><ci id="S4.T6.2.1.m1.1.1.cmml" xref="S4.T6.2.1.m1.1.1">ğ™·ğšğš–ğšŠğš—ğš†ğš’ğš•ğš</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.2.1.m1.1d">\tt HumanWild</annotation></semantics></math>, â€˜Bâ€™ denotes BEDLAMÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>, and â€˜Aâ€™ denotes AGORAÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite>. â€˜Pâ€™ denotes 3DPWÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite>.</span></figcaption>
<div id="S4.T6.8" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:390.3pt;height:220pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-45.3pt,25.4pt) scale(0.811668285352416,0.811668285352416) ;">
<table id="S4.T6.8.6" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T6.8.6.7.1" class="ltx_tr">
<th id="S4.T6.8.6.7.1.1" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_tt" rowspan="2"><span id="S4.T6.8.6.7.1.1.1" class="ltx_text">Methods</span></th>
<th id="S4.T6.8.6.7.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_tt" rowspan="2"><span id="S4.T6.8.6.7.1.2.1" class="ltx_text">Training Data</span></th>
<td id="S4.T6.8.6.7.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="3">3DPW (14)</td>
<td id="S4.T6.8.6.7.1.4" class="ltx_td ltx_align_center ltx_border_tt" colspan="3">RICH (24)</td>
</tr>
<tr id="S4.T6.8.6.6" class="ltx_tr">
<td id="S4.T6.3.1.1.1" class="ltx_td ltx_align_left"><span id="S4.T6.3.1.1.1.1" class="ltx_text" style="font-size:80%;">PA-MPJPE<math id="S4.T6.3.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T6.3.1.1.1.1.m1.1a"><mo stretchy="false" id="S4.T6.3.1.1.1.1.m1.1.1" xref="S4.T6.3.1.1.1.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S4.T6.3.1.1.1.1.m1.1b"><ci id="S4.T6.3.1.1.1.1.m1.1.1.cmml" xref="S4.T6.3.1.1.1.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.3.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math></span></td>
<td id="S4.T6.4.2.2.2" class="ltx_td ltx_align_left"><span id="S4.T6.4.2.2.2.1" class="ltx_text" style="font-size:80%;">MPJPE<math id="S4.T6.4.2.2.2.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T6.4.2.2.2.1.m1.1a"><mo stretchy="false" id="S4.T6.4.2.2.2.1.m1.1.1" xref="S4.T6.4.2.2.2.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S4.T6.4.2.2.2.1.m1.1b"><ci id="S4.T6.4.2.2.2.1.m1.1.1.cmml" xref="S4.T6.4.2.2.2.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.4.2.2.2.1.m1.1c">\downarrow</annotation></semantics></math></span></td>
<td id="S4.T6.5.3.3.3" class="ltx_td ltx_align_left ltx_border_r"><span id="S4.T6.5.3.3.3.1" class="ltx_text" style="font-size:80%;">PVE<math id="S4.T6.5.3.3.3.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T6.5.3.3.3.1.m1.1a"><mo stretchy="false" id="S4.T6.5.3.3.3.1.m1.1.1" xref="S4.T6.5.3.3.3.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S4.T6.5.3.3.3.1.m1.1b"><ci id="S4.T6.5.3.3.3.1.m1.1.1.cmml" xref="S4.T6.5.3.3.3.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.5.3.3.3.1.m1.1c">\downarrow</annotation></semantics></math></span></td>
<td id="S4.T6.6.4.4.4" class="ltx_td ltx_align_left"><span id="S4.T6.6.4.4.4.1" class="ltx_text" style="font-size:80%;">PA-MPJPE<math id="S4.T6.6.4.4.4.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T6.6.4.4.4.1.m1.1a"><mo stretchy="false" id="S4.T6.6.4.4.4.1.m1.1.1" xref="S4.T6.6.4.4.4.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S4.T6.6.4.4.4.1.m1.1b"><ci id="S4.T6.6.4.4.4.1.m1.1.1.cmml" xref="S4.T6.6.4.4.4.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.6.4.4.4.1.m1.1c">\downarrow</annotation></semantics></math></span></td>
<td id="S4.T6.7.5.5.5" class="ltx_td ltx_align_left"><span id="S4.T6.7.5.5.5.1" class="ltx_text" style="font-size:80%;">MPJPE<math id="S4.T6.7.5.5.5.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T6.7.5.5.5.1.m1.1a"><mo stretchy="false" id="S4.T6.7.5.5.5.1.m1.1.1" xref="S4.T6.7.5.5.5.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S4.T6.7.5.5.5.1.m1.1b"><ci id="S4.T6.7.5.5.5.1.m1.1.1.cmml" xref="S4.T6.7.5.5.5.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.7.5.5.5.1.m1.1c">\downarrow</annotation></semantics></math></span></td>
<td id="S4.T6.8.6.6.6" class="ltx_td ltx_align_left"><span id="S4.T6.8.6.6.6.1" class="ltx_text" style="font-size:80%;">PVE<math id="S4.T6.8.6.6.6.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T6.8.6.6.6.1.m1.1a"><mo stretchy="false" id="S4.T6.8.6.6.6.1.m1.1.1" xref="S4.T6.8.6.6.6.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S4.T6.8.6.6.6.1.m1.1b"><ci id="S4.T6.8.6.6.6.1.m1.1.1.cmml" xref="S4.T6.8.6.6.6.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.8.6.6.6.1.m1.1c">\downarrow</annotation></semantics></math></span></td>
</tr>
<tr id="S4.T6.8.6.8.2" class="ltx_tr">
<th id="S4.T6.8.6.8.2.1" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_t">HMR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>
</th>
<th id="S4.T6.8.6.8.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Real</th>
<td id="S4.T6.8.6.8.2.3" class="ltx_td ltx_align_center ltx_border_t">76.7</td>
<td id="S4.T6.8.6.8.2.4" class="ltx_td ltx_align_center ltx_border_t">130</td>
<td id="S4.T6.8.6.8.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">N/A</td>
<td id="S4.T6.8.6.8.2.6" class="ltx_td ltx_align_center ltx_border_t">90.0</td>
<td id="S4.T6.8.6.8.2.7" class="ltx_td ltx_align_center ltx_border_t">158.3</td>
<td id="S4.T6.8.6.8.2.8" class="ltx_td ltx_align_center ltx_border_t">186.0</td>
</tr>
<tr id="S4.T6.8.6.9.3" class="ltx_tr">
<th id="S4.T6.8.6.9.3.1" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r">SPIN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>
</th>
<th id="S4.T6.8.6.9.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Real</th>
<td id="S4.T6.8.6.9.3.3" class="ltx_td ltx_align_center">59.2</td>
<td id="S4.T6.8.6.9.3.4" class="ltx_td ltx_align_center">96.9</td>
<td id="S4.T6.8.6.9.3.5" class="ltx_td ltx_align_center ltx_border_r">116.4</td>
<td id="S4.T6.8.6.9.3.6" class="ltx_td ltx_align_center">69.7</td>
<td id="S4.T6.8.6.9.3.7" class="ltx_td ltx_align_center">122.9</td>
<td id="S4.T6.8.6.9.3.8" class="ltx_td ltx_align_center">144.2</td>
</tr>
<tr id="S4.T6.8.6.10.4" class="ltx_tr">
<th id="S4.T6.8.6.10.4.1" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r">SPEC <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>
</th>
<th id="S4.T6.8.6.10.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Real</th>
<td id="S4.T6.8.6.10.4.3" class="ltx_td ltx_align_center">53.2</td>
<td id="S4.T6.8.6.10.4.4" class="ltx_td ltx_align_center">96.5</td>
<td id="S4.T6.8.6.10.4.5" class="ltx_td ltx_align_center ltx_border_r">118.5</td>
<td id="S4.T6.8.6.10.4.6" class="ltx_td ltx_align_center">72.5</td>
<td id="S4.T6.8.6.10.4.7" class="ltx_td ltx_align_center">127.5</td>
<td id="S4.T6.8.6.10.4.8" class="ltx_td ltx_align_center">146.5</td>
</tr>
<tr id="S4.T6.8.6.11.5" class="ltx_tr">
<th id="S4.T6.8.6.11.5.1" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r">PARE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>
</th>
<th id="S4.T6.8.6.11.5.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Real</th>
<td id="S4.T6.8.6.11.5.3" class="ltx_td ltx_align_center">50.9</td>
<td id="S4.T6.8.6.11.5.4" class="ltx_td ltx_align_center">82.0</td>
<td id="S4.T6.8.6.11.5.5" class="ltx_td ltx_align_center ltx_border_r">97.9</td>
<td id="S4.T6.8.6.11.5.6" class="ltx_td ltx_align_center">64.9</td>
<td id="S4.T6.8.6.11.5.7" class="ltx_td ltx_align_center">104.0</td>
<td id="S4.T6.8.6.11.5.8" class="ltx_td ltx_align_center">119.7</td>
</tr>
<tr id="S4.T6.8.6.12.6" class="ltx_tr">
<th id="S4.T6.8.6.12.6.1" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r">HybrIK <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>
</th>
<th id="S4.T6.8.6.12.6.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Real</th>
<td id="S4.T6.8.6.12.6.3" class="ltx_td ltx_align_center">48.8</td>
<td id="S4.T6.8.6.12.6.4" class="ltx_td ltx_align_center">80</td>
<td id="S4.T6.8.6.12.6.5" class="ltx_td ltx_align_center ltx_border_r">94.5</td>
<td id="S4.T6.8.6.12.6.6" class="ltx_td ltx_align_center">56.4</td>
<td id="S4.T6.8.6.12.6.7" class="ltx_td ltx_align_center">96.8</td>
<td id="S4.T6.8.6.12.6.8" class="ltx_td ltx_align_center">110.4</td>
</tr>
<tr id="S4.T6.8.6.13.7" class="ltx_tr">
<th id="S4.T6.8.6.13.7.1" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r">CLIFF <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>
</th>
<th id="S4.T6.8.6.13.7.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Real</th>
<td id="S4.T6.8.6.13.7.3" class="ltx_td ltx_align_center">46.4</td>
<td id="S4.T6.8.6.13.7.4" class="ltx_td ltx_align_center">73.9</td>
<td id="S4.T6.8.6.13.7.5" class="ltx_td ltx_align_center ltx_border_r">87.6</td>
<td id="S4.T6.8.6.13.7.6" class="ltx_td ltx_align_center">55.7</td>
<td id="S4.T6.8.6.13.7.7" class="ltx_td ltx_align_center">90.0</td>
<td id="S4.T6.8.6.13.7.8" class="ltx_td ltx_align_center">102.0</td>
</tr>
<tr id="S4.T6.8.6.14.8" class="ltx_tr">
<th id="S4.T6.8.6.14.8.1" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_t">CLIFF <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>
</th>
<th id="S4.T6.8.6.14.8.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">B</th>
<td id="S4.T6.8.6.14.8.3" class="ltx_td ltx_align_center ltx_border_t">50.5</td>
<td id="S4.T6.8.6.14.8.4" class="ltx_td ltx_align_center ltx_border_t">76.1</td>
<td id="S4.T6.8.6.14.8.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">90.6</td>
<td id="S4.T6.8.6.14.8.6" class="ltx_td ltx_align_center ltx_border_t">-</td>
<td id="S4.T6.8.6.14.8.7" class="ltx_td ltx_align_center ltx_border_t">-</td>
<td id="S4.T6.8.6.14.8.8" class="ltx_td ltx_align_center ltx_border_t">-</td>
</tr>
<tr id="S4.T6.8.6.15.9" class="ltx_tr">
<th id="S4.T6.8.6.15.9.1" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r">CLIFF <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>
</th>
<th id="S4.T6.8.6.15.9.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S4.T6.8.6.15.9.2.1" class="ltx_text ltx_font_bold">H</span></th>
<td id="S4.T6.8.6.15.9.3" class="ltx_td ltx_align_center">52.7</td>
<td id="S4.T6.8.6.15.9.4" class="ltx_td ltx_align_center">87.3</td>
<td id="S4.T6.8.6.15.9.5" class="ltx_td ltx_align_center ltx_border_r">102.1</td>
<td id="S4.T6.8.6.15.9.6" class="ltx_td ltx_align_center">-</td>
<td id="S4.T6.8.6.15.9.7" class="ltx_td ltx_align_center">-</td>
<td id="S4.T6.8.6.15.9.8" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S4.T6.8.6.16.10" class="ltx_tr">
<th id="S4.T6.8.6.16.10.1" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_t">CLIFF <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>
</th>
<th id="S4.T6.8.6.16.10.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">B+A</th>
<td id="S4.T6.8.6.16.10.3" class="ltx_td ltx_align_center ltx_border_t">46.6</td>
<td id="S4.T6.8.6.16.10.4" class="ltx_td ltx_align_center ltx_border_t">72.0</td>
<td id="S4.T6.8.6.16.10.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">85.0</td>
<td id="S4.T6.8.6.16.10.6" class="ltx_td ltx_align_center ltx_border_t">51.2</td>
<td id="S4.T6.8.6.16.10.7" class="ltx_td ltx_align_center ltx_border_t">84.5</td>
<td id="S4.T6.8.6.16.10.8" class="ltx_td ltx_align_center ltx_border_t">96.6</td>
</tr>
<tr id="S4.T6.8.6.17.11" class="ltx_tr">
<th id="S4.T6.8.6.17.11.1" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r">CLIFF <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>
</th>
<th id="S4.T6.8.6.17.11.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">
<span id="S4.T6.8.6.17.11.2.1" class="ltx_text ltx_font_bold">H</span>+A</th>
<td id="S4.T6.8.6.17.11.3" class="ltx_td ltx_align_center">47.5</td>
<td id="S4.T6.8.6.17.11.4" class="ltx_td ltx_align_center">74.1</td>
<td id="S4.T6.8.6.17.11.5" class="ltx_td ltx_align_center ltx_border_r">87.8</td>
<td id="S4.T6.8.6.17.11.6" class="ltx_td ltx_align_center">51.9</td>
<td id="S4.T6.8.6.17.11.7" class="ltx_td ltx_align_center">85.3</td>
<td id="S4.T6.8.6.17.11.8" class="ltx_td ltx_align_center">97.4</td>
</tr>
<tr id="S4.T6.8.6.18.12" class="ltx_tr">
<th id="S4.T6.8.6.18.12.1" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r">CLIFF<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>
</th>
<th id="S4.T6.8.6.18.12.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">
<span id="S4.T6.8.6.18.12.2.1" class="ltx_text ltx_font_bold">H</span>+B+A</th>
<td id="S4.T6.8.6.18.12.3" class="ltx_td ltx_align_center"><span id="S4.T6.8.6.18.12.3.1" class="ltx_text ltx_font_bold">44.9</span></td>
<td id="S4.T6.8.6.18.12.4" class="ltx_td ltx_align_center"><span id="S4.T6.8.6.18.12.4.1" class="ltx_text ltx_font_bold">70.2</span></td>
<td id="S4.T6.8.6.18.12.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T6.8.6.18.12.5.1" class="ltx_text ltx_font_bold">82.7</span></td>
<td id="S4.T6.8.6.18.12.6" class="ltx_td ltx_align_center"><span id="S4.T6.8.6.18.12.6.1" class="ltx_text ltx_font_bold">51.0</span></td>
<td id="S4.T6.8.6.18.12.7" class="ltx_td ltx_align_center"><span id="S4.T6.8.6.18.12.7.1" class="ltx_text ltx_font_bold">84.4</span></td>
<td id="S4.T6.8.6.18.12.8" class="ltx_td ltx_align_center"><span id="S4.T6.8.6.18.12.8.1" class="ltx_text ltx_font_bold">96.1</span></td>
</tr>
<tr id="S4.T6.8.6.19.13" class="ltx_tr">
<th id="S4.T6.8.6.19.13.1" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_r ltx_border_t">CLIFF<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>
</th>
<th id="S4.T6.8.6.19.13.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">B+A+P</th>
<td id="S4.T6.8.6.19.13.3" class="ltx_td ltx_align_center ltx_border_t">43.0</td>
<td id="S4.T6.8.6.19.13.4" class="ltx_td ltx_align_center ltx_border_t">66.9</td>
<td id="S4.T6.8.6.19.13.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">78.5</td>
<td id="S4.T6.8.6.19.13.6" class="ltx_td ltx_align_center ltx_border_t">50.2</td>
<td id="S4.T6.8.6.19.13.7" class="ltx_td ltx_align_center ltx_border_t">84.4</td>
<td id="S4.T6.8.6.19.13.8" class="ltx_td ltx_align_center ltx_border_t">95.6</td>
</tr>
<tr id="S4.T6.8.6.20.14" class="ltx_tr">
<th id="S4.T6.8.6.20.14.1" class="ltx_td ltx_align_right ltx_th ltx_th_row ltx_border_bb ltx_border_r">CLIFF<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>
</th>
<th id="S4.T6.8.6.20.14.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r">
<span id="S4.T6.8.6.20.14.2.1" class="ltx_text ltx_font_bold">H</span>+B+A+P</th>
<td id="S4.T6.8.6.20.14.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T6.8.6.20.14.3.1" class="ltx_text ltx_font_bold">41.9</span></td>
<td id="S4.T6.8.6.20.14.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T6.8.6.20.14.4.1" class="ltx_text ltx_font_bold">65.2</span></td>
<td id="S4.T6.8.6.20.14.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S4.T6.8.6.20.14.5.1" class="ltx_text ltx_font_bold">76.8</span></td>
<td id="S4.T6.8.6.20.14.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T6.8.6.20.14.6.1" class="ltx_text ltx_font_bold">48.4</span></td>
<td id="S4.T6.8.6.20.14.7" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T6.8.6.20.14.7.1" class="ltx_text ltx_font_bold">79.7</span></td>
<td id="S4.T6.8.6.20.14.8" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T6.8.6.20.14.8.1" class="ltx_text ltx_font_bold">91.1</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div id="S4.SS5.p2" class="ltx_para">
<p id="S4.SS5.p2.1" class="ltx_p">These results provide additional validation for the efficacy of the generated HumanWild dataset. Specifically, they demonstrate that incorporating HumanWild data enables the HPS regressor to encounter a more diverse range of scenarios, thereby enhancing its ability to generalize to in-the-wild scenes.</p>
</div>
</section>
<section id="S4.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.6 </span>Result on Challenging Benchmarks</h3>

<div id="S4.SS6.p1" class="ltx_para">
<p id="S4.SS6.p1.5" class="ltx_p">To verify the effectiveness of <math id="S4.SS6.p1.1.m1.1" class="ltx_Math" alttext="\tt HumanWild" display="inline"><semantics id="S4.SS6.p1.1.m1.1a"><mi id="S4.SS6.p1.1.m1.1.1" xref="S4.SS6.p1.1.m1.1.1.cmml">ğ™·ğšğš–ğšŠğš—ğš†ğš’ğš•ğš</mi><annotation-xml encoding="MathML-Content" id="S4.SS6.p1.1.m1.1b"><ci id="S4.SS6.p1.1.m1.1.1.cmml" xref="S4.SS6.p1.1.m1.1.1">ğ™·ğšğš–ğšŠğš—ğš†ğš’ğš•ğš</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS6.p1.1.m1.1c">\tt HumanWild</annotation></semantics></math> on different scenerios, we report the detailed performance on three challenging benchmarks.
Firstly, we evaluate the capability of <math id="S4.SS6.p1.2.m2.1" class="ltx_Math" alttext="\tt HumanWild" display="inline"><semantics id="S4.SS6.p1.2.m2.1a"><mi id="S4.SS6.p1.2.m2.1.1" xref="S4.SS6.p1.2.m2.1.1.cmml">ğ™·ğšğš–ğšŠğš—ğš†ğš’ğš•ğš</mi><annotation-xml encoding="MathML-Content" id="S4.SS6.p1.2.m2.1b"><ci id="S4.SS6.p1.2.m2.1.1.cmml" xref="S4.SS6.p1.2.m2.1.1">ğ™·ğšğš–ğšŠğš—ğš†ğš’ğš•ğš</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS6.p1.2.m2.1c">\tt HumanWild</annotation></semantics></math> in handling perspective distortion tasks, by performing fair ablation using ZollyÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib77" title="" class="ltx_ref">77</a>]</cite> with ResNet50Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> backbone. The results inÂ <a href="#S4.T8" title="In 4.6 Result on Challenging Benchmarks â€£ 4 Experiments â€£ 3D Human Reconstruction in the Wild with Synthetic Data Using Generative ModelsWork was done when YG was visiting Zhejiang University. HC is the corresponding author." class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">8</span></a> show that <math id="S4.SS6.p1.3.m3.1" class="ltx_Math" alttext="\tt HumanWild" display="inline"><semantics id="S4.SS6.p1.3.m3.1a"><mi id="S4.SS6.p1.3.m3.1.1" xref="S4.SS6.p1.3.m3.1.1.cmml">ğ™·ğšğš–ğšŠğš—ğš†ğš’ğš•ğš</mi><annotation-xml encoding="MathML-Content" id="S4.SS6.p1.3.m3.1b"><ci id="S4.SS6.p1.3.m3.1.1.cmml" xref="S4.SS6.p1.3.m3.1.1">ğ™·ğšğš–ğšŠğš—ğš†ğš’ğš•ğš</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS6.p1.3.m3.1c">\tt HumanWild</annotation></semantics></math> dataset achieves higher generalization performance on SPEC-MTPÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite> when compared with PDhumanÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib77" title="" class="ltx_ref">77</a>]</cite>, which is a CG-rendered perspective distortion dataset. Secondly, MOYOÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib71" title="" class="ltx_ref">71</a>]</cite> encompasses challenging yoga poses not present in BEDLAM and <math id="S4.SS6.p1.4.m4.1" class="ltx_Math" alttext="\tt HumanWild" display="inline"><semantics id="S4.SS6.p1.4.m4.1a"><mi id="S4.SS6.p1.4.m4.1.1" xref="S4.SS6.p1.4.m4.1.1.cmml">ğ™·ğšğš–ğšŠğš—ğš†ğš’ğš•ğš</mi><annotation-xml encoding="MathML-Content" id="S4.SS6.p1.4.m4.1b"><ci id="S4.SS6.p1.4.m4.1.1.cmml" xref="S4.SS6.p1.4.m4.1.1">ğ™·ğšğš–ğšŠğš—ğš†ğš’ğš•ğš</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS6.p1.4.m4.1c">\tt HumanWild</annotation></semantics></math> datasets, providing a unique testbed for evaluating the modelâ€™s generalization ability on hard poses. The results inÂ <a href="#S4.T8" title="In 4.6 Result on Challenging Benchmarks â€£ 4 Experiments â€£ 3D Human Reconstruction in the Wild with Synthetic Data Using Generative ModelsWork was done when YG was visiting Zhejiang University. HC is the corresponding author." class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">8</span></a> demonstrate that <math id="S4.SS6.p1.5.m5.1" class="ltx_Math" alttext="\tt HumanWild" display="inline"><semantics id="S4.SS6.p1.5.m5.1a"><mi id="S4.SS6.p1.5.m5.1.1" xref="S4.SS6.p1.5.m5.1.1.cmml">ğ™·ğšğš–ğšŠğš—ğš†ğš’ğš•ğš</mi><annotation-xml encoding="MathML-Content" id="S4.SS6.p1.5.m5.1b"><ci id="S4.SS6.p1.5.m5.1.1.cmml" xref="S4.SS6.p1.5.m5.1.1">ğ™·ğšğš–ğšŠğš—ğš†ğš’ğš•ğš</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS6.p1.5.m5.1c">\tt HumanWild</annotation></semantics></math>, complements existing datasets, resulting in improved generalization performance on the MOYO test set.
InÂ <a href="#S4.T9" title="In 4.6 Result on Challenging Benchmarks â€£ 4 Experiments â€£ 3D Human Reconstruction in the Wild with Synthetic Data Using Generative ModelsWork was done when YG was visiting Zhejiang University. HC is the corresponding author." class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">9</span></a>, our analysis reveals that while Humanwild demonstrates superior performance over BEDLAM on body metrics, it exhibits relatively poorer performance on hand and face metrics, particularly evident in comparison to the AGORA test set. We hypothesize that the alignment of hand and facial annotations with generated images remains noisy, primarily due to inherent limitations in current diffusion modelsâ€™ ability to accurately generate hand poses, particularly within small resolutions.</p>
</div>
<figure id="S4.T8" class="ltx_table">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.T8.4" class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_top" style="width:212.5pt;">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.T8.4.5.1.1" class="ltx_text" style="font-size:90%;">Table 7</span>: </span><span id="S4.T8.4.6.2" class="ltx_text" style="font-size:90%;">SPEC-MTP.</span></figcaption>
<div id="S4.T8.4.4" class="ltx_inline-block ltx_transformed_outer" style="width:188.5pt;height:37.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-40.4pt,8.1pt) scale(0.7,0.7) ;">
<table id="S4.T8.4.4.4" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T8.3.3.3.3" class="ltx_tr">
<th id="S4.T8.3.3.3.3.4" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S4.T8.3.3.3.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.3.3.3.3.4.1.1" class="ltx_p" style="width:65.0pt;">Training Data</span>
</span>
</th>
<th id="S4.T8.1.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt"><span id="S4.T8.1.1.1.1.1.1" class="ltx_text" style="font-size:80%;">PA-MPJPE<math id="S4.T8.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T8.1.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S4.T8.1.1.1.1.1.1.m1.1.1" xref="S4.T8.1.1.1.1.1.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S4.T8.1.1.1.1.1.1.m1.1b"><ci id="S4.T8.1.1.1.1.1.1.m1.1.1.cmml" xref="S4.T8.1.1.1.1.1.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.1.1.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math></span></th>
<th id="S4.T8.2.2.2.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt"><span id="S4.T8.2.2.2.2.2.1" class="ltx_text" style="font-size:80%;">MPJPE<math id="S4.T8.2.2.2.2.2.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T8.2.2.2.2.2.1.m1.1a"><mo stretchy="false" id="S4.T8.2.2.2.2.2.1.m1.1.1" xref="S4.T8.2.2.2.2.2.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S4.T8.2.2.2.2.2.1.m1.1b"><ci id="S4.T8.2.2.2.2.2.1.m1.1.1.cmml" xref="S4.T8.2.2.2.2.2.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.2.2.2.2.2.1.m1.1c">\downarrow</annotation></semantics></math></span></th>
<th id="S4.T8.3.3.3.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt"><span id="S4.T8.3.3.3.3.3.1" class="ltx_text" style="font-size:80%;">PVE<math id="S4.T8.3.3.3.3.3.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T8.3.3.3.3.3.1.m1.1a"><mo stretchy="false" id="S4.T8.3.3.3.3.3.1.m1.1.1" xref="S4.T8.3.3.3.3.3.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S4.T8.3.3.3.3.3.1.m1.1b"><ci id="S4.T8.3.3.3.3.3.1.m1.1.1.cmml" xref="S4.T8.3.3.3.3.3.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.3.3.3.3.3.1.m1.1c">\downarrow</annotation></semantics></math></span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T8.4.4.4.5.1" class="ltx_tr">
<td id="S4.T8.4.4.4.5.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T8.4.4.4.5.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.4.4.4.5.1.1.1.1" class="ltx_p" style="width:65.0pt;">PDHuman</span>
</span>
</td>
<td id="S4.T8.4.4.4.5.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T8.4.4.4.5.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.4.4.4.5.1.2.1.1" class="ltx_p" style="width:55.0pt;">102.4</span>
</span>
</td>
<td id="S4.T8.4.4.4.5.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T8.4.4.4.5.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.4.4.4.5.1.3.1.1" class="ltx_p" style="width:50.0pt;">159.1</span>
</span>
</td>
<td id="S4.T8.4.4.4.5.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T8.4.4.4.5.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.4.4.4.5.1.4.1.1" class="ltx_p" style="width:40.0pt;">168.0</span>
</span>
</td>
</tr>
<tr id="S4.T8.4.4.4.4" class="ltx_tr">
<td id="S4.T8.4.4.4.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="S4.T8.4.4.4.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.4.4.4.4.1.1.1" class="ltx_p" style="width:65.0pt;"><math id="S4.T8.4.4.4.4.1.1.1.m1.1" class="ltx_Math" alttext="\tt HumanWild" display="inline"><semantics id="S4.T8.4.4.4.4.1.1.1.m1.1a"><mi id="S4.T8.4.4.4.4.1.1.1.m1.1.1" xref="S4.T8.4.4.4.4.1.1.1.m1.1.1.cmml">ğ™·ğšğš–ğšŠğš—ğš†ğš’ğš•ğš</mi><annotation-xml encoding="MathML-Content" id="S4.T8.4.4.4.4.1.1.1.m1.1b"><ci id="S4.T8.4.4.4.4.1.1.1.m1.1.1.cmml" xref="S4.T8.4.4.4.4.1.1.1.m1.1.1">ğ™·ğšğš–ğšŠğš—ğš†ğš’ğš•ğš</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.4.4.4.4.1.1.1.m1.1c">\tt HumanWild</annotation></semantics></math></span>
</span>
</td>
<td id="S4.T8.4.4.4.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="S4.T8.4.4.4.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.4.4.4.4.2.1.1" class="ltx_p" style="width:55.0pt;"><span id="S4.T8.4.4.4.4.2.1.1.1" class="ltx_text ltx_font_bold">90.0</span></span>
</span>
</td>
<td id="S4.T8.4.4.4.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="S4.T8.4.4.4.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.4.4.4.4.3.1.1" class="ltx_p" style="width:50.0pt;"><span id="S4.T8.4.4.4.4.3.1.1.1" class="ltx_text ltx_font_bold">151.8</span></span>
</span>
</td>
<td id="S4.T8.4.4.4.4.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="S4.T8.4.4.4.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.4.4.4.4.4.1.1" class="ltx_p" style="width:40.0pt;"><span id="S4.T8.4.4.4.4.4.1.1.1" class="ltx_text ltx_font_bold">160.9</span></span>
</span>
</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.T8.8" class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_top" style="width:212.5pt;">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.T8.8.5.1.1" class="ltx_text" style="font-size:90%;">Table 8</span>: </span><span id="S4.T8.8.6.2" class="ltx_text" style="font-size:90%;">MOYO.</span></figcaption>
<div id="S4.T8.8.4" class="ltx_inline-block ltx_transformed_outer" style="width:216.0pt;height:37.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-46.3pt,8.1pt) scale(0.7,0.7) ;">
<table id="S4.T8.8.4.4" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T8.8.4.4.4" class="ltx_tr">
<th id="S4.T8.8.4.4.4.5" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_th_row ltx_border_tt">
<span id="S4.T8.8.4.4.4.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.8.4.4.4.5.1.1" class="ltx_p" style="width:65.0pt;">Training Data</span>
</span>
</th>
<th id="S4.T8.5.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">MPJPEÂ <math id="S4.T8.5.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T8.5.1.1.1.1.m1.1a"><mo stretchy="false" id="S4.T8.5.1.1.1.1.m1.1.1" xref="S4.T8.5.1.1.1.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S4.T8.5.1.1.1.1.m1.1b"><ci id="S4.T8.5.1.1.1.1.m1.1.1.cmml" xref="S4.T8.5.1.1.1.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.5.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math>
</th>
<th id="S4.T8.6.2.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">PA-MPJPEÂ <math id="S4.T8.6.2.2.2.2.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T8.6.2.2.2.2.m1.1a"><mo stretchy="false" id="S4.T8.6.2.2.2.2.m1.1.1" xref="S4.T8.6.2.2.2.2.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S4.T8.6.2.2.2.2.m1.1b"><ci id="S4.T8.6.2.2.2.2.m1.1.1.cmml" xref="S4.T8.6.2.2.2.2.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.6.2.2.2.2.m1.1c">\downarrow</annotation></semantics></math>
</th>
<th id="S4.T8.7.3.3.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">PVEÂ <math id="S4.T8.7.3.3.3.3.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T8.7.3.3.3.3.m1.1a"><mo stretchy="false" id="S4.T8.7.3.3.3.3.m1.1.1" xref="S4.T8.7.3.3.3.3.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S4.T8.7.3.3.3.3.m1.1b"><ci id="S4.T8.7.3.3.3.3.m1.1.1.cmml" xref="S4.T8.7.3.3.3.3.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.7.3.3.3.3.m1.1c">\downarrow</annotation></semantics></math>
</th>
<th id="S4.T8.8.4.4.4.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">PA-PVEÂ <math id="S4.T8.8.4.4.4.4.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T8.8.4.4.4.4.m1.1a"><mo stretchy="false" id="S4.T8.8.4.4.4.4.m1.1.1" xref="S4.T8.8.4.4.4.4.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S4.T8.8.4.4.4.4.m1.1b"><ci id="S4.T8.8.4.4.4.4.m1.1.1.cmml" xref="S4.T8.8.4.4.4.4.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.8.4.4.4.4.m1.1c">\downarrow</annotation></semantics></math>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T8.8.4.4.5.1" class="ltx_tr">
<th id="S4.T8.8.4.4.5.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_t">
<span id="S4.T8.8.4.4.5.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.8.4.4.5.1.1.1.1" class="ltx_p" style="width:65.0pt;">B+A+P</span>
</span>
</th>
<td id="S4.T8.8.4.4.5.1.2" class="ltx_td ltx_align_center ltx_border_t">143.1</td>
<td id="S4.T8.8.4.4.5.1.3" class="ltx_td ltx_align_center ltx_border_t">94.9</td>
<td id="S4.T8.8.4.4.5.1.4" class="ltx_td ltx_align_center ltx_border_t">163.9</td>
<td id="S4.T8.8.4.4.5.1.5" class="ltx_td ltx_align_center ltx_border_t">95.7</td>
</tr>
<tr id="S4.T8.8.4.4.6.2" class="ltx_tr">
<th id="S4.T8.8.4.4.6.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_bb">
<span id="S4.T8.8.4.4.6.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T8.8.4.4.6.2.1.1.1" class="ltx_p" style="width:65.0pt;">B+A+P+H</span>
</span>
</th>
<td id="S4.T8.8.4.4.6.2.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T8.8.4.4.6.2.2.1" class="ltx_text ltx_font_bold">134.6</span></td>
<td id="S4.T8.8.4.4.6.2.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T8.8.4.4.6.2.3.1" class="ltx_text ltx_font_bold">89.1</span></td>
<td id="S4.T8.8.4.4.6.2.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T8.8.4.4.6.2.4.1" class="ltx_text ltx_font_bold">154.1</span></td>
<td id="S4.T8.8.4.4.6.2.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T8.8.4.4.6.2.5.1" class="ltx_text ltx_font_bold">88.9</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</div>
</div>
</figure>
<figure id="S4.T9" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S4.T9.17.3.1" class="ltx_text" style="font-size:90%;">Table 9</span>: </span><span id="S4.T9.4.2" class="ltx_text ltx_font_bold" style="font-size:90%;">AGORA test set.<span id="S4.T9.4.2.2" class="ltx_text ltx_font_medium"> <math id="S4.T9.3.1.1.m1.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="S4.T9.3.1.1.m1.1b"><mo id="S4.T9.3.1.1.m1.1.1" xref="S4.T9.3.1.1.m1.1.1.cmml">â€ </mo><annotation-xml encoding="MathML-Content" id="S4.T9.3.1.1.m1.1c"><ci id="S4.T9.3.1.1.m1.1.1.cmml" xref="S4.T9.3.1.1.m1.1.1">â€ </ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T9.3.1.1.m1.1d">\dagger</annotation></semantics></math> denotes the methods that are finetuned on the AGORA training set. <math id="S4.T9.4.2.2.m2.1" class="ltx_Math" alttext="\ast" display="inline"><semantics id="S4.T9.4.2.2.m2.1b"><mo id="S4.T9.4.2.2.m2.1.1" xref="S4.T9.4.2.2.m2.1.1.cmml">âˆ—</mo><annotation-xml encoding="MathML-Content" id="S4.T9.4.2.2.m2.1c"><ci id="S4.T9.4.2.2.m2.1.1.cmml" xref="S4.T9.4.2.2.m2.1.1">âˆ—</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T9.4.2.2.m2.1d">\ast</annotation></semantics></math> denotes the methods that are trained on AGORA training set only.</span></span></figcaption>
<div id="S4.T9.14" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:93.7pt;vertical-align:-0.6pt;"><span class="ltx_transformed_inner" style="transform:translate(-118.6pt,25.5pt) scale(0.646392088727048,0.646392088727048) ;">
<table id="S4.T9.14.10" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T9.8.4.4" class="ltx_tr">
<th id="S4.T9.8.4.4.5" class="ltx_td ltx_th ltx_th_row ltx_border_tt"></th>
<th id="S4.T9.5.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2">NMVE<math id="S4.T9.5.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T9.5.1.1.1.m1.1a"><mo stretchy="false" id="S4.T9.5.1.1.1.m1.1.1" xref="S4.T9.5.1.1.1.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S4.T9.5.1.1.1.m1.1b"><ci id="S4.T9.5.1.1.1.m1.1.1.cmml" xref="S4.T9.5.1.1.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T9.5.1.1.1.m1.1c">\downarrow</annotation></semantics></math> (<em id="S4.T9.5.1.1.1.1" class="ltx_emph ltx_font_italic">mm</em>)</th>
<th id="S4.T9.6.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2">NMJE<math id="S4.T9.6.2.2.2.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T9.6.2.2.2.m1.1a"><mo stretchy="false" id="S4.T9.6.2.2.2.m1.1.1" xref="S4.T9.6.2.2.2.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S4.T9.6.2.2.2.m1.1b"><ci id="S4.T9.6.2.2.2.m1.1.1.cmml" xref="S4.T9.6.2.2.2.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T9.6.2.2.2.m1.1c">\downarrow</annotation></semantics></math> (<em id="S4.T9.6.2.2.2.1" class="ltx_emph ltx_font_italic">mm</em>)</th>
<th id="S4.T9.7.3.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="5">MVE<math id="S4.T9.7.3.3.3.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T9.7.3.3.3.m1.1a"><mo stretchy="false" id="S4.T9.7.3.3.3.m1.1.1" xref="S4.T9.7.3.3.3.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S4.T9.7.3.3.3.m1.1b"><ci id="S4.T9.7.3.3.3.m1.1.1.cmml" xref="S4.T9.7.3.3.3.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T9.7.3.3.3.m1.1c">\downarrow</annotation></semantics></math> (<em id="S4.T9.7.3.3.3.1" class="ltx_emph ltx_font_italic">mm</em>)</th>
<th id="S4.T9.8.4.4.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="5">MPJPE<math id="S4.T9.8.4.4.4.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T9.8.4.4.4.m1.1a"><mo stretchy="false" id="S4.T9.8.4.4.4.m1.1.1" xref="S4.T9.8.4.4.4.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S4.T9.8.4.4.4.m1.1b"><ci id="S4.T9.8.4.4.4.m1.1.1.cmml" xref="S4.T9.8.4.4.4.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T9.8.4.4.4.m1.1c">\downarrow</annotation></semantics></math> (<em id="S4.T9.8.4.4.4.1" class="ltx_emph ltx_font_italic">mm</em>)</th>
</tr>
<tr id="S4.T9.14.10.11.1" class="ltx_tr">
<th id="S4.T9.14.10.11.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row">Method</th>
<th id="S4.T9.14.10.11.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">All</th>
<th id="S4.T9.14.10.11.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Body</th>
<th id="S4.T9.14.10.11.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">All</th>
<th id="S4.T9.14.10.11.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Body</th>
<th id="S4.T9.14.10.11.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">All</th>
<th id="S4.T9.14.10.11.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Body</th>
<th id="S4.T9.14.10.11.1.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Face</th>
<th id="S4.T9.14.10.11.1.9" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">LHand</th>
<th id="S4.T9.14.10.11.1.10" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">RHand</th>
<th id="S4.T9.14.10.11.1.11" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">All</th>
<th id="S4.T9.14.10.11.1.12" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Body</th>
<th id="S4.T9.14.10.11.1.13" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Face</th>
<th id="S4.T9.14.10.11.1.14" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">LHand</th>
<th id="S4.T9.14.10.11.1.15" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">RHhand</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T9.14.10.12.1" class="ltx_tr">
<th id="S4.T9.14.10.12.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">BEDLAMÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>
</th>
<td id="S4.T9.14.10.12.1.2" class="ltx_td ltx_align_center ltx_border_t">179.5</td>
<td id="S4.T9.14.10.12.1.3" class="ltx_td ltx_align_center ltx_border_t">132.2</td>
<td id="S4.T9.14.10.12.1.4" class="ltx_td ltx_align_center ltx_border_t">177.5</td>
<td id="S4.T9.14.10.12.1.5" class="ltx_td ltx_align_center ltx_border_t">131.4</td>
<td id="S4.T9.14.10.12.1.6" class="ltx_td ltx_align_center ltx_border_t">131.0</td>
<td id="S4.T9.14.10.12.1.7" class="ltx_td ltx_align_center ltx_border_t">96.5</td>
<td id="S4.T9.14.10.12.1.8" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T9.14.10.12.1.8.1" class="ltx_text ltx_framed ltx_framed_underline">25.8</span></td>
<td id="S4.T9.14.10.12.1.9" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T9.14.10.12.1.9.1" class="ltx_text ltx_framed ltx_framed_underline">38.8</span></td>
<td id="S4.T9.14.10.12.1.10" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T9.14.10.12.1.10.1" class="ltx_text ltx_framed ltx_framed_underline">39.0</span></td>
<td id="S4.T9.14.10.12.1.11" class="ltx_td ltx_align_center ltx_border_t">129.6</td>
<td id="S4.T9.14.10.12.1.12" class="ltx_td ltx_align_center ltx_border_t">95.9</td>
<td id="S4.T9.14.10.12.1.13" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T9.14.10.12.1.13.1" class="ltx_text ltx_framed ltx_framed_underline">27.8</span></td>
<td id="S4.T9.14.10.12.1.14" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T9.14.10.12.1.14.1" class="ltx_text ltx_framed ltx_framed_underline">36.6</span></td>
<td id="S4.T9.14.10.12.1.15" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T9.14.10.12.1.15.1" class="ltx_text ltx_framed ltx_framed_underline">36.7</span></td>
</tr>
<tr id="S4.T9.9.5.5" class="ltx_tr">
<th id="S4.T9.9.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Hand4WholeÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref">50</a>]</cite><math id="S4.T9.9.5.5.1.m1.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="S4.T9.9.5.5.1.m1.1a"><mo id="S4.T9.9.5.5.1.m1.1.1" xref="S4.T9.9.5.5.1.m1.1.1.cmml">â€ </mo><annotation-xml encoding="MathML-Content" id="S4.T9.9.5.5.1.m1.1b"><ci id="S4.T9.9.5.5.1.m1.1.1.cmml" xref="S4.T9.9.5.5.1.m1.1.1">â€ </ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T9.9.5.5.1.m1.1c">\dagger</annotation></semantics></math>
</th>
<td id="S4.T9.9.5.5.2" class="ltx_td ltx_align_center">144.1</td>
<td id="S4.T9.9.5.5.3" class="ltx_td ltx_align_center">96.0</td>
<td id="S4.T9.9.5.5.4" class="ltx_td ltx_align_center">141.1</td>
<td id="S4.T9.9.5.5.5" class="ltx_td ltx_align_center">92.7</td>
<td id="S4.T9.9.5.5.6" class="ltx_td ltx_align_center">135.5</td>
<td id="S4.T9.9.5.5.7" class="ltx_td ltx_align_center">90.2</td>
<td id="S4.T9.9.5.5.8" class="ltx_td ltx_align_center">41.6</td>
<td id="S4.T9.9.5.5.9" class="ltx_td ltx_align_center">46.3</td>
<td id="S4.T9.9.5.5.10" class="ltx_td ltx_align_center">48.1</td>
<td id="S4.T9.9.5.5.11" class="ltx_td ltx_align_center">132.6</td>
<td id="S4.T9.9.5.5.12" class="ltx_td ltx_align_center">87.1</td>
<td id="S4.T9.9.5.5.13" class="ltx_td ltx_align_center">46.1</td>
<td id="S4.T9.9.5.5.14" class="ltx_td ltx_align_center">44.3</td>
<td id="S4.T9.9.5.5.15" class="ltx_td ltx_align_center">46.2</td>
</tr>
<tr id="S4.T9.10.6.6" class="ltx_tr">
<th id="S4.T9.10.6.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">BEDLAMÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite><math id="S4.T9.10.6.6.1.m1.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="S4.T9.10.6.6.1.m1.1a"><mo id="S4.T9.10.6.6.1.m1.1.1" xref="S4.T9.10.6.6.1.m1.1.1.cmml">â€ </mo><annotation-xml encoding="MathML-Content" id="S4.T9.10.6.6.1.m1.1b"><ci id="S4.T9.10.6.6.1.m1.1.1.cmml" xref="S4.T9.10.6.6.1.m1.1.1">â€ </ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T9.10.6.6.1.m1.1c">\dagger</annotation></semantics></math>
</th>
<td id="S4.T9.10.6.6.2" class="ltx_td ltx_align_center">142.2</td>
<td id="S4.T9.10.6.6.3" class="ltx_td ltx_align_center">102.1</td>
<td id="S4.T9.10.6.6.4" class="ltx_td ltx_align_center">141.0</td>
<td id="S4.T9.10.6.6.5" class="ltx_td ltx_align_center">101.8</td>
<td id="S4.T9.10.6.6.6" class="ltx_td ltx_align_center"><span id="S4.T9.10.6.6.6.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline">103.8</span></td>
<td id="S4.T9.10.6.6.7" class="ltx_td ltx_align_center">74.5</td>
<td id="S4.T9.10.6.6.8" class="ltx_td ltx_align_center"><span id="S4.T9.10.6.6.8.1" class="ltx_text ltx_font_bold">23.1</span></td>
<td id="S4.T9.10.6.6.9" class="ltx_td ltx_align_center"><span id="S4.T9.10.6.6.9.1" class="ltx_text ltx_font_bold">31.7</span></td>
<td id="S4.T9.10.6.6.10" class="ltx_td ltx_align_center"><span id="S4.T9.10.6.6.10.1" class="ltx_text ltx_font_bold">33.2</span></td>
<td id="S4.T9.10.6.6.11" class="ltx_td ltx_align_center"><span id="S4.T9.10.6.6.11.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline">102.9</span></td>
<td id="S4.T9.10.6.6.12" class="ltx_td ltx_align_center">74.3</td>
<td id="S4.T9.10.6.6.13" class="ltx_td ltx_align_center"><span id="S4.T9.10.6.6.13.1" class="ltx_text ltx_font_bold">24.7</span></td>
<td id="S4.T9.10.6.6.14" class="ltx_td ltx_align_center"><span id="S4.T9.10.6.6.14.1" class="ltx_text ltx_font_bold">29.9</span></td>
<td id="S4.T9.10.6.6.15" class="ltx_td ltx_align_center"><span id="S4.T9.10.6.6.15.1" class="ltx_text ltx_font_bold">31.3</span></td>
</tr>
<tr id="S4.T9.11.7.7" class="ltx_tr">
<th id="S4.T9.11.7.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">PyMaF-XÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib87" title="" class="ltx_ref">87</a>]</cite><math id="S4.T9.11.7.7.1.m1.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="S4.T9.11.7.7.1.m1.1a"><mo id="S4.T9.11.7.7.1.m1.1.1" xref="S4.T9.11.7.7.1.m1.1.1.cmml">â€ </mo><annotation-xml encoding="MathML-Content" id="S4.T9.11.7.7.1.m1.1b"><ci id="S4.T9.11.7.7.1.m1.1.1.cmml" xref="S4.T9.11.7.7.1.m1.1.1">â€ </ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T9.11.7.7.1.m1.1c">\dagger</annotation></semantics></math>
</th>
<td id="S4.T9.11.7.7.2" class="ltx_td ltx_align_center">141.2</td>
<td id="S4.T9.11.7.7.3" class="ltx_td ltx_align_center">94.4</td>
<td id="S4.T9.11.7.7.4" class="ltx_td ltx_align_center">140.0</td>
<td id="S4.T9.11.7.7.5" class="ltx_td ltx_align_center">93.5</td>
<td id="S4.T9.11.7.7.6" class="ltx_td ltx_align_center">125.7</td>
<td id="S4.T9.11.7.7.7" class="ltx_td ltx_align_center">84.0</td>
<td id="S4.T9.11.7.7.8" class="ltx_td ltx_align_center">35.0</td>
<td id="S4.T9.11.7.7.9" class="ltx_td ltx_align_center">44.6</td>
<td id="S4.T9.11.7.7.10" class="ltx_td ltx_align_center">45.6</td>
<td id="S4.T9.11.7.7.11" class="ltx_td ltx_align_center">124.6</td>
<td id="S4.T9.11.7.7.12" class="ltx_td ltx_align_center">83.2</td>
<td id="S4.T9.11.7.7.13" class="ltx_td ltx_align_center">37.9</td>
<td id="S4.T9.11.7.7.14" class="ltx_td ltx_align_center">42.5</td>
<td id="S4.T9.11.7.7.15" class="ltx_td ltx_align_center">43.7</td>
</tr>
<tr id="S4.T9.12.8.8" class="ltx_tr">
<th id="S4.T9.12.8.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">OSXÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite><math id="S4.T9.12.8.8.1.m1.1" class="ltx_Math" alttext="\ast" display="inline"><semantics id="S4.T9.12.8.8.1.m1.1a"><mo id="S4.T9.12.8.8.1.m1.1.1" xref="S4.T9.12.8.8.1.m1.1.1.cmml">âˆ—</mo><annotation-xml encoding="MathML-Content" id="S4.T9.12.8.8.1.m1.1b"><ci id="S4.T9.12.8.8.1.m1.1.1.cmml" xref="S4.T9.12.8.8.1.m1.1.1">âˆ—</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T9.12.8.8.1.m1.1c">\ast</annotation></semantics></math>
</th>
<td id="S4.T9.12.8.8.2" class="ltx_td ltx_align_center">130.6</td>
<td id="S4.T9.12.8.8.3" class="ltx_td ltx_align_center">85.3</td>
<td id="S4.T9.12.8.8.4" class="ltx_td ltx_align_center">127.6</td>
<td id="S4.T9.12.8.8.5" class="ltx_td ltx_align_center">83.3</td>
<td id="S4.T9.12.8.8.6" class="ltx_td ltx_align_center">122.8</td>
<td id="S4.T9.12.8.8.7" class="ltx_td ltx_align_center">80.2</td>
<td id="S4.T9.12.8.8.8" class="ltx_td ltx_align_center">36.2</td>
<td id="S4.T9.12.8.8.9" class="ltx_td ltx_align_center">45.4</td>
<td id="S4.T9.12.8.8.10" class="ltx_td ltx_align_center">46.1</td>
<td id="S4.T9.12.8.8.11" class="ltx_td ltx_align_center">119.9</td>
<td id="S4.T9.12.8.8.12" class="ltx_td ltx_align_center">78.3</td>
<td id="S4.T9.12.8.8.13" class="ltx_td ltx_align_center">37.9</td>
<td id="S4.T9.12.8.8.14" class="ltx_td ltx_align_center">43.0</td>
<td id="S4.T9.12.8.8.15" class="ltx_td ltx_align_center">43.9</td>
</tr>
<tr id="S4.T9.14.10.10" class="ltx_tr">
<th id="S4.T9.14.10.10.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">
<math id="S4.T9.13.9.9.1.m1.1" class="ltx_Math" alttext="\tt HumanWild" display="inline"><semantics id="S4.T9.13.9.9.1.m1.1a"><mi id="S4.T9.13.9.9.1.m1.1.1" xref="S4.T9.13.9.9.1.m1.1.1.cmml">ğ™·ğšğš–ğšŠğš—ğš†ğš’ğš•ğš</mi><annotation-xml encoding="MathML-Content" id="S4.T9.13.9.9.1.m1.1b"><ci id="S4.T9.13.9.9.1.m1.1.1.cmml" xref="S4.T9.13.9.9.1.m1.1.1">ğ™·ğšğš–ğšŠğš—ğš†ğš’ğš•ğš</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T9.13.9.9.1.m1.1c">\tt HumanWild</annotation></semantics></math> <math id="S4.T9.14.10.10.2.m2.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="S4.T9.14.10.10.2.m2.1a"><mo id="S4.T9.14.10.10.2.m2.1.1" xref="S4.T9.14.10.10.2.m2.1.1.cmml">â€ </mo><annotation-xml encoding="MathML-Content" id="S4.T9.14.10.10.2.m2.1b"><ci id="S4.T9.14.10.10.2.m2.1.1.cmml" xref="S4.T9.14.10.10.2.m2.1.1">â€ </ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T9.14.10.10.2.m2.1c">\dagger</annotation></semantics></math>
</th>
<td id="S4.T9.14.10.10.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T9.14.10.10.3.1" class="ltx_text ltx_font_bold">120.5</span></td>
<td id="S4.T9.14.10.10.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T9.14.10.10.4.1" class="ltx_text ltx_font_bold">73.7</span></td>
<td id="S4.T9.14.10.10.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T9.14.10.10.5.1" class="ltx_text ltx_font_bold">115.7</span></td>
<td id="S4.T9.14.10.10.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T9.14.10.10.6.1" class="ltx_text ltx_font_bold">72.3</span></td>
<td id="S4.T9.14.10.10.7" class="ltx_td ltx_align_center ltx_border_bb">112.1</td>
<td id="S4.T9.14.10.10.8" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T9.14.10.10.8.1" class="ltx_text ltx_font_bold">68.5</span></td>
<td id="S4.T9.14.10.10.9" class="ltx_td ltx_align_center ltx_border_bb">37.0</td>
<td id="S4.T9.14.10.10.10" class="ltx_td ltx_align_center ltx_border_bb">46.7</td>
<td id="S4.T9.14.10.10.11" class="ltx_td ltx_align_center ltx_border_bb">47.0</td>
<td id="S4.T9.14.10.10.12" class="ltx_td ltx_align_center ltx_border_bb">107.6</td>
<td id="S4.T9.14.10.10.13" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T9.14.10.10.13.1" class="ltx_text ltx_font_bold">67.2</span></td>
<td id="S4.T9.14.10.10.14" class="ltx_td ltx_align_center ltx_border_bb">38.5</td>
<td id="S4.T9.14.10.10.15" class="ltx_td ltx_align_center ltx_border_bb">41.2</td>
<td id="S4.T9.14.10.10.16" class="ltx_td ltx_align_center ltx_border_bb">41.4</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Discussion and Conclusions</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">Based on the experiments, we can answer the question â€œIs synthetic data generated by generative models complementary to CG-rendered data for the 3D HPS task?â€ Our results strongly suggest that through the integration of 3D human priors with ControlNet, it becomes feasible to produce high-fidelity pseudo labels encompassing a wide array of real-world scenarios.
As the landscape sees the emergence of increasingly large generative models, there arises a promising prospect for the expansion of diverse 3D human training datasets without intricate mocap systems and CG pipelines.
We hope that our endeavors could pave the way for leveraging generative models to generate high-quality datasets conducive to enhancing the efficacy of 3D human perception tasks.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">Our pipeline can apply to a series of similar tasks where high-quality data pairs are hard to collect, <em id="S5.p2.1.1" class="ltx_emph ltx_font_italic">e.g.</em>, 3D animal pose estimation and 3D reconstruction of human-object/human-human interaction. Addressing these challenges requires further advancements in our methodology.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgement</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">This work was supported by National Key R&amp;D Program of China (No.Â 2022ZD0118700).</p>
</div>
</section>
<section id="Pt0.A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix 0.A </span>Appendix</h2>

<section id="Pt0.A1.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">0.A.1 </span>Implement Details for training ControlNet</h3>

<div id="Pt0.A1.SS1.p1" class="ltx_para">
<p id="Pt0.A1.SS1.p1.1" class="ltx_p"><math id="Pt0.A1.SS1.p1.1.m1.1" class="ltx_Math" alttext="\tt HumanWild" display="inline"><semantics id="Pt0.A1.SS1.p1.1.m1.1a"><mi id="Pt0.A1.SS1.p1.1.m1.1.1" xref="Pt0.A1.SS1.p1.1.m1.1.1.cmml">ğ™·ğšğš–ğšŠğš—ğš†ğš’ğš•ğš</mi><annotation-xml encoding="MathML-Content" id="Pt0.A1.SS1.p1.1.m1.1b"><ci id="Pt0.A1.SS1.p1.1.m1.1.1.cmml" xref="Pt0.A1.SS1.p1.1.m1.1.1">ğ™·ğšğš–ğšŠğš—ğš†ğš’ğš•ğš</ci></annotation-xml><annotation encoding="application/x-tex" id="Pt0.A1.SS1.p1.1.m1.1c">\tt HumanWild</annotation></semantics></math> employs a customized ControlNet to generate human images and corresponding
annotations. In the preliminary phase of our research, we adopt the off-the-shelf depth-to-image ControlNet, and keypoint-to-image ControlNet, which are trained on the LAION5B dataset without filtering low-quality images. Experiments show that the pre-trained models face challenges when it comes to generating human images
with hard poses. To resolve this issue, we collect high-quality human images from multiple datasets and then conduct finetuning on the collected datasets for better generation performance.</p>
</div>
<section id="Pt0.A1.SS1.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Data preprocessing.</h4>

<div id="Pt0.A1.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="Pt0.A1.SS1.SSS0.Px1.p1.1" class="ltx_p">We curate from four datasets
LAION5BÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite>, COYOÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>, HI4DÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib86" title="" class="ltx_ref">86</a>]</cite> and BEDLAMÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>. Following HyperHumanÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite>, we employ YOLOSÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> for human detection on LAION5BÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite> and COYO-700MÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> datasets, images containing 1 to 3 human bounding boxes are retained. We use BLIPÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite> to get text captions for BEDLAMÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> and HI4DÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib86" title="" class="ltx_ref">86</a>]</cite>.</p>
</div>
</section>
<section id="Pt0.A1.SS1.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Training.</h4>

<div id="Pt0.A1.SS1.SSS0.Px2.p1" class="ltx_para">
<p id="Pt0.A1.SS1.SSS0.Px2.p1.2" class="ltx_p">We train the customized ControlNet with with AdamWÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> in 1e<math id="Pt0.A1.SS1.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="-5" display="inline"><semantics id="Pt0.A1.SS1.SSS0.Px2.p1.1.m1.1a"><mrow id="Pt0.A1.SS1.SSS0.Px2.p1.1.m1.1.1" xref="Pt0.A1.SS1.SSS0.Px2.p1.1.m1.1.1.cmml"><mo id="Pt0.A1.SS1.SSS0.Px2.p1.1.m1.1.1a" xref="Pt0.A1.SS1.SSS0.Px2.p1.1.m1.1.1.cmml">âˆ’</mo><mn id="Pt0.A1.SS1.SSS0.Px2.p1.1.m1.1.1.2" xref="Pt0.A1.SS1.SSS0.Px2.p1.1.m1.1.1.2.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="Pt0.A1.SS1.SSS0.Px2.p1.1.m1.1b"><apply id="Pt0.A1.SS1.SSS0.Px2.p1.1.m1.1.1.cmml" xref="Pt0.A1.SS1.SSS0.Px2.p1.1.m1.1.1"><minus id="Pt0.A1.SS1.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="Pt0.A1.SS1.SSS0.Px2.p1.1.m1.1.1"></minus><cn type="integer" id="Pt0.A1.SS1.SSS0.Px2.p1.1.m1.1.1.2.cmml" xref="Pt0.A1.SS1.SSS0.Px2.p1.1.m1.1.1.2">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Pt0.A1.SS1.SSS0.Px2.p1.1.m1.1c">-5</annotation></semantics></math> learning rate, and 0.01 weight decay for <math id="Pt0.A1.SS1.SSS0.Px2.p1.2.m2.2" class="ltx_Math" alttext="80,000" display="inline"><semantics id="Pt0.A1.SS1.SSS0.Px2.p1.2.m2.2a"><mrow id="Pt0.A1.SS1.SSS0.Px2.p1.2.m2.2.3.2" xref="Pt0.A1.SS1.SSS0.Px2.p1.2.m2.2.3.1.cmml"><mn id="Pt0.A1.SS1.SSS0.Px2.p1.2.m2.1.1" xref="Pt0.A1.SS1.SSS0.Px2.p1.2.m2.1.1.cmml">80</mn><mo id="Pt0.A1.SS1.SSS0.Px2.p1.2.m2.2.3.2.1" xref="Pt0.A1.SS1.SSS0.Px2.p1.2.m2.2.3.1.cmml">,</mo><mn id="Pt0.A1.SS1.SSS0.Px2.p1.2.m2.2.2" xref="Pt0.A1.SS1.SSS0.Px2.p1.2.m2.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="Pt0.A1.SS1.SSS0.Px2.p1.2.m2.2b"><list id="Pt0.A1.SS1.SSS0.Px2.p1.2.m2.2.3.1.cmml" xref="Pt0.A1.SS1.SSS0.Px2.p1.2.m2.2.3.2"><cn type="integer" id="Pt0.A1.SS1.SSS0.Px2.p1.2.m2.1.1.cmml" xref="Pt0.A1.SS1.SSS0.Px2.p1.2.m2.1.1">80</cn><cn type="integer" id="Pt0.A1.SS1.SSS0.Px2.p1.2.m2.2.2.cmml" xref="Pt0.A1.SS1.SSS0.Px2.p1.2.m2.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="Pt0.A1.SS1.SSS0.Px2.p1.2.m2.2c">80,000</annotation></semantics></math> iterations on 8 A100 GPUs.</p>
</div>
</section>
</section>
<section id="Pt0.A1.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">0.A.2 </span>Failure Cases of the keypoint and depth-based ControlNet</h3>

<div id="Pt0.A1.SS2.p1" class="ltx_para">
<p id="Pt0.A1.SS2.p1.1" class="ltx_p">InÂ <a href="#Pt0.A1.F6" title="In 0.A.2 Failure Cases of the keypoint and depth-based ControlNet â€£ Appendix 0.A Appendix â€£ 3D Human Reconstruction in the Wild with Synthetic Data Using Generative ModelsWork was done when YG was visiting Zhejiang University. HC is the corresponding author." class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">6</span></a>, we show some failure cases of the initial data pairs generated by a multi-condition, <em id="Pt0.A1.SS2.p1.1.1" class="ltx_emph ltx_font_italic">i.e.</em>, depth and keypoint-based, ControlNet The inconsistency of the image and 3D mesh would affect the performance of the 3D human pose estimation. Thus, it is necessary to retrain a customized ControlNet with the surface normal condition proposed in this work.</p>
</div>
<figure id="Pt0.A1.F6" class="ltx_figure"><img src="/html/2403.11111/assets/x6.png" id="Pt0.A1.F6.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="233" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="Pt0.A1.F6.3.1.1" class="ltx_text" style="font-size:90%;">Figure 6</span>: </span><span id="Pt0.A1.F6.4.2" class="ltx_text" style="font-size:90%;">Failure cases of the initial data pairs generated by ControlNet. See
highlighted regions with red circles.</span></figcaption>
</figure>
</section>
<section id="Pt0.A1.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">0.A.3 </span>More Visualizations of Human Interactions</h3>

<div id="Pt0.A1.SS3.p1" class="ltx_para">
<p id="Pt0.A1.SS3.p1.1" class="ltx_p">We show visualization results on human interactions.
<a href="#Pt0.A1.F7" title="In 0.A.3 More Visualizations of Human Interactions â€£ Appendix 0.A Appendix â€£ 3D Human Reconstruction in the Wild with Synthetic Data Using Generative ModelsWork was done when YG was visiting Zhejiang University. HC is the corresponding author." class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">7</span></a> demonstrates that our pipeline can generate well-aligned
image-annotation pairs where people are with close interactions. The generated data
pairs are of great value in enhancing existing human interaction datasets collected
in the studio environment. (<em id="Pt0.A1.SS3.p1.1.1" class="ltx_emph ltx_font_italic">e.g.</em>, Hi4DÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib86" title="" class="ltx_ref">86</a>]</cite> and CHI3DÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>)</p>
</div>
<figure id="Pt0.A1.F7" class="ltx_figure"><img src="/html/2403.11111/assets/x7.png" id="Pt0.A1.F7.1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="461" height="526" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="Pt0.A1.F7.3.1.1" class="ltx_text" style="font-size:90%;">Figure 7</span>: </span><span id="Pt0.A1.F7.4.2" class="ltx_text" style="font-size:90%;">Visualization of Human interaction. The SMPL interaction annotations
are sampled from the Hi4DÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib86" title="" class="ltx_ref">86</a>]</cite> dataset.</span></figcaption>
</figure>
</section>
<section id="Pt0.A1.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">0.A.4 </span>Text prompt examples generated by LLM</h3>

<div id="Pt0.A1.SS4.p1" class="ltx_para">
<p id="Pt0.A1.SS4.p1.1" class="ltx_p">InÂ <a href="#Pt0.A1.T10" title="In 0.A.4 Text prompt examples generated by LLM â€£ Appendix 0.A Appendix â€£ 3D Human Reconstruction in the Wild with Synthetic Data Using Generative ModelsWork was done when YG was visiting Zhejiang University. HC is the corresponding author." class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">10</span></a>, we show some text prompt examples, which are generated
by ChatGPTÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>]</cite> with diverse human actions and scenes.</p>
</div>
<figure id="Pt0.A1.T10" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="Pt0.A1.T10.2.1.1" class="ltx_text" style="font-size:90%;">Table 10</span>: </span><span id="Pt0.A1.T10.3.2" class="ltx_text" style="font-size:90%;">Text prompt examples.</span></figcaption>
<div id="Pt0.A1.T10.4" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:238.5pt;height:222.3pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(42.0pt,-39.1pt) scale(1.54349990934433,1.54349990934433) ;">
<table id="Pt0.A1.T10.4.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="Pt0.A1.T10.4.1.1.1" class="ltx_tr">
<th id="Pt0.A1.T10.4.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt"><span id="Pt0.A1.T10.4.1.1.1.1.1" class="ltx_text" style="font-size:70%;">gender</span></th>
<th id="Pt0.A1.T10.4.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt"><span id="Pt0.A1.T10.4.1.1.1.2.1" class="ltx_text" style="font-size:70%;">action</span></th>
<th id="Pt0.A1.T10.4.1.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span id="Pt0.A1.T10.4.1.1.1.3.1" class="ltx_text" style="font-size:70%;">environment</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="Pt0.A1.T10.4.1.2.1" class="ltx_tr">
<td id="Pt0.A1.T10.4.1.2.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="Pt0.A1.T10.4.1.2.1.1.1" class="ltx_text" style="font-size:70%;">a man</span></td>
<td id="Pt0.A1.T10.4.1.2.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="Pt0.A1.T10.4.1.2.1.2.1" class="ltx_text" style="font-size:70%;">playing soccer</span></td>
<td id="Pt0.A1.T10.4.1.2.1.3" class="ltx_td ltx_align_left ltx_border_t"><span id="Pt0.A1.T10.4.1.2.1.3.1" class="ltx_text" style="font-size:70%;">at the park</span></td>
</tr>
<tr id="Pt0.A1.T10.4.1.3.2" class="ltx_tr">
<td id="Pt0.A1.T10.4.1.3.2.1" class="ltx_td ltx_align_left ltx_border_r"><span id="Pt0.A1.T10.4.1.3.2.1.1" class="ltx_text" style="font-size:70%;">a woman</span></td>
<td id="Pt0.A1.T10.4.1.3.2.2" class="ltx_td ltx_align_left ltx_border_r"><span id="Pt0.A1.T10.4.1.3.2.2.1" class="ltx_text" style="font-size:70%;">swimming</span></td>
<td id="Pt0.A1.T10.4.1.3.2.3" class="ltx_td ltx_align_left"><span id="Pt0.A1.T10.4.1.3.2.3.1" class="ltx_text" style="font-size:70%;">in the pool</span></td>
</tr>
<tr id="Pt0.A1.T10.4.1.4.3" class="ltx_tr">
<td id="Pt0.A1.T10.4.1.4.3.1" class="ltx_td ltx_align_left ltx_border_r"><span id="Pt0.A1.T10.4.1.4.3.1.1" class="ltx_text" style="font-size:70%;">a man</span></td>
<td id="Pt0.A1.T10.4.1.4.3.2" class="ltx_td ltx_align_left ltx_border_r"><span id="Pt0.A1.T10.4.1.4.3.2.1" class="ltx_text" style="font-size:70%;">shopping</span></td>
<td id="Pt0.A1.T10.4.1.4.3.3" class="ltx_td ltx_align_left"><span id="Pt0.A1.T10.4.1.4.3.3.1" class="ltx_text" style="font-size:70%;">at the mall</span></td>
</tr>
<tr id="Pt0.A1.T10.4.1.5.4" class="ltx_tr">
<td id="Pt0.A1.T10.4.1.5.4.1" class="ltx_td ltx_align_left ltx_border_r"><span id="Pt0.A1.T10.4.1.5.4.1.1" class="ltx_text" style="font-size:70%;">a woman</span></td>
<td id="Pt0.A1.T10.4.1.5.4.2" class="ltx_td ltx_align_left ltx_border_r"><span id="Pt0.A1.T10.4.1.5.4.2.1" class="ltx_text" style="font-size:70%;">running</span></td>
<td id="Pt0.A1.T10.4.1.5.4.3" class="ltx_td ltx_align_left"><span id="Pt0.A1.T10.4.1.5.4.3.1" class="ltx_text" style="font-size:70%;">in the park</span></td>
</tr>
<tr id="Pt0.A1.T10.4.1.6.5" class="ltx_tr">
<td id="Pt0.A1.T10.4.1.6.5.1" class="ltx_td ltx_align_left ltx_border_r"><span id="Pt0.A1.T10.4.1.6.5.1.1" class="ltx_text" style="font-size:70%;">a man</span></td>
<td id="Pt0.A1.T10.4.1.6.5.2" class="ltx_td ltx_align_left ltx_border_r"><span id="Pt0.A1.T10.4.1.6.5.2.1" class="ltx_text" style="font-size:70%;">studying</span></td>
<td id="Pt0.A1.T10.4.1.6.5.3" class="ltx_td ltx_align_left"><span id="Pt0.A1.T10.4.1.6.5.3.1" class="ltx_text" style="font-size:70%;">at the library</span></td>
</tr>
<tr id="Pt0.A1.T10.4.1.7.6" class="ltx_tr">
<td id="Pt0.A1.T10.4.1.7.6.1" class="ltx_td ltx_align_left ltx_border_r"><span id="Pt0.A1.T10.4.1.7.6.1.1" class="ltx_text" style="font-size:70%;">a man</span></td>
<td id="Pt0.A1.T10.4.1.7.6.2" class="ltx_td ltx_align_left ltx_border_r"><span id="Pt0.A1.T10.4.1.7.6.2.1" class="ltx_text" style="font-size:70%;">working</span></td>
<td id="Pt0.A1.T10.4.1.7.6.3" class="ltx_td ltx_align_left"><span id="Pt0.A1.T10.4.1.7.6.3.1" class="ltx_text" style="font-size:70%;">at the office</span></td>
</tr>
<tr id="Pt0.A1.T10.4.1.8.7" class="ltx_tr">
<td id="Pt0.A1.T10.4.1.8.7.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r"><span id="Pt0.A1.T10.4.1.8.7.1.1" class="ltx_text" style="font-size:70%;">a man</span></td>
<td id="Pt0.A1.T10.4.1.8.7.2" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r"><span id="Pt0.A1.T10.4.1.8.7.2.1" class="ltx_text" style="font-size:70%;">chatting</span></td>
<td id="Pt0.A1.T10.4.1.8.7.3" class="ltx_td ltx_align_left ltx_border_bb"><span id="Pt0.A1.T10.4.1.8.7.3.1" class="ltx_text" style="font-size:70%;">at a cafe</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section id="Pt0.A1.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">0.A.5 </span>Misalignment Analysis of Complicated Prompts and Normals</h3>

<div id="Pt0.A1.SS5.p1" class="ltx_para">
<p id="Pt0.A1.SS5.p1.2" class="ltx_p">We present instances of failure where text prompts conflict with the surface normal condition. Specifically, when the text prompt suggests an action that deviates from the surface normal map, the resulting images often fail to adhere to the text prompt, particularly when the control factor of the surface normal map approaches <math id="Pt0.A1.SS5.p1.1.m1.1" class="ltx_Math" alttext="1.0" display="inline"><semantics id="Pt0.A1.SS5.p1.1.m1.1a"><mn id="Pt0.A1.SS5.p1.1.m1.1.1" xref="Pt0.A1.SS5.p1.1.m1.1.1.cmml">1.0</mn><annotation-xml encoding="MathML-Content" id="Pt0.A1.SS5.p1.1.m1.1b"><cn type="float" id="Pt0.A1.SS5.p1.1.m1.1.1.cmml" xref="Pt0.A1.SS5.p1.1.m1.1.1">1.0</cn></annotation-xml><annotation encoding="application/x-tex" id="Pt0.A1.SS5.p1.1.m1.1c">1.0</annotation></semantics></math>.
As shown in <a href="#Pt0.A1.F8" title="In 0.A.5 Misalignment Analysis of Complicated Prompts and Normals â€£ Appendix 0.A Appendix â€£ 3D Human Reconstruction in the Wild with Synthetic Data Using Generative ModelsWork was done when YG was visiting Zhejiang University. HC is the corresponding author." class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">8</span></a>, despite employing the same input surface normal map and a control factor of <math id="Pt0.A1.SS5.p1.2.m2.1" class="ltx_Math" alttext="0.95" display="inline"><semantics id="Pt0.A1.SS5.p1.2.m2.1a"><mn id="Pt0.A1.SS5.p1.2.m2.1.1" xref="Pt0.A1.SS5.p1.2.m2.1.1.cmml">0.95</mn><annotation-xml encoding="MathML-Content" id="Pt0.A1.SS5.p1.2.m2.1b"><cn type="float" id="Pt0.A1.SS5.p1.2.m2.1.1.cmml" xref="Pt0.A1.SS5.p1.2.m2.1.1">0.95</cn></annotation-xml><annotation encoding="application/x-tex" id="Pt0.A1.SS5.p1.2.m2.1c">0.95</annotation></semantics></math>, the generated images exhibit similar foreground human identities but differ in background elements corresponding to distinct text prompts.
<a href="#Pt0.A1.F9" title="In 0.A.5 Misalignment Analysis of Complicated Prompts and Normals â€£ Appendix 0.A Appendix â€£ 3D Human Reconstruction in the Wild with Synthetic Data Using Generative ModelsWork was done when YG was visiting Zhejiang University. HC is the corresponding author." class="ltx_ref"><span class="ltx_text ltx_ref_tag">Fig.</span>Â <span class="ltx_text ltx_ref_tag">9</span></a> illustrates that when the control factor of the surface normal is extremely low, the generated images may disregard the surface normal map condition.</p>
</div>
<figure id="Pt0.A1.F8" class="ltx_figure"><img src="/html/2403.11111/assets/x8.png" id="Pt0.A1.F8.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="201" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="Pt0.A1.F8.2.1.1" class="ltx_text" style="font-size:90%;">Figure 8</span>: </span><span id="Pt0.A1.F8.3.2" class="ltx_text" style="font-size:90%;">Utilizing identical surface normal maps and control scale factor of the surface normal as input, we change the input text prompts.</span></figcaption>
</figure>
<figure id="Pt0.A1.F9" class="ltx_figure"><img src="/html/2403.11111/assets/x9.png" id="Pt0.A1.F9.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="202" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="Pt0.A1.F9.8.4.1" class="ltx_text" style="font-size:90%;">Figure 9</span>: </span><span id="Pt0.A1.F9.6.3" class="ltx_text" style="font-size:90%;">Utilizing identical surface normal maps and text prompts as input, we manipulate the control scale factor of the surface normal map across values of <math id="Pt0.A1.F9.4.1.m1.1" class="ltx_Math" alttext="0.75" display="inline"><semantics id="Pt0.A1.F9.4.1.m1.1b"><mn id="Pt0.A1.F9.4.1.m1.1.1" xref="Pt0.A1.F9.4.1.m1.1.1.cmml">0.75</mn><annotation-xml encoding="MathML-Content" id="Pt0.A1.F9.4.1.m1.1c"><cn type="float" id="Pt0.A1.F9.4.1.m1.1.1.cmml" xref="Pt0.A1.F9.4.1.m1.1.1">0.75</cn></annotation-xml><annotation encoding="application/x-tex" id="Pt0.A1.F9.4.1.m1.1d">0.75</annotation></semantics></math>, <math id="Pt0.A1.F9.5.2.m2.1" class="ltx_Math" alttext="0.5" display="inline"><semantics id="Pt0.A1.F9.5.2.m2.1b"><mn id="Pt0.A1.F9.5.2.m2.1.1" xref="Pt0.A1.F9.5.2.m2.1.1.cmml">0.5</mn><annotation-xml encoding="MathML-Content" id="Pt0.A1.F9.5.2.m2.1c"><cn type="float" id="Pt0.A1.F9.5.2.m2.1.1.cmml" xref="Pt0.A1.F9.5.2.m2.1.1">0.5</cn></annotation-xml><annotation encoding="application/x-tex" id="Pt0.A1.F9.5.2.m2.1d">0.5</annotation></semantics></math>, and <math id="Pt0.A1.F9.6.3.m3.1" class="ltx_Math" alttext="0.25" display="inline"><semantics id="Pt0.A1.F9.6.3.m3.1b"><mn id="Pt0.A1.F9.6.3.m3.1.1" xref="Pt0.A1.F9.6.3.m3.1.1.cmml">0.25</mn><annotation-xml encoding="MathML-Content" id="Pt0.A1.F9.6.3.m3.1c"><cn type="float" id="Pt0.A1.F9.6.3.m3.1.1.cmml" xref="Pt0.A1.F9.6.3.m3.1.1">0.25</cn></annotation-xml><annotation encoding="application/x-tex" id="Pt0.A1.F9.6.3.m3.1d">0.25</annotation></semantics></math>, respectively. </span></figcaption>
</figure>
</section>
<section id="Pt0.A1.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">0.A.6 </span>Results on 2D HPE</h3>

<div id="Pt0.A1.SS6.p1" class="ltx_para ltx_noindent">
<p id="Pt0.A1.SS6.p1.1" class="ltx_p"><span id="Pt0.A1.SS6.p1.1.1" class="ltx_text ltx_font_bold">2D keypoint refinement.</span> <math id="Pt0.A1.SS6.p1.1.m1.1" class="ltx_Math" alttext="\tt HumanWild" display="inline"><semantics id="Pt0.A1.SS6.p1.1.m1.1a"><mi id="Pt0.A1.SS6.p1.1.m1.1.1" xref="Pt0.A1.SS6.p1.1.m1.1.1.cmml">ğ™·ğšğš–ğšŠğš—ğš†ğš’ğš•ğš</mi><annotation-xml encoding="MathML-Content" id="Pt0.A1.SS6.p1.1.m1.1b"><ci id="Pt0.A1.SS6.p1.1.m1.1.1.cmml" xref="Pt0.A1.SS6.p1.1.m1.1.1">ğ™·ğšğš–ğšŠğš—ğš†ğš’ğš•ğš</ci></annotation-xml><annotation encoding="application/x-tex" id="Pt0.A1.SS6.p1.1.m1.1c">\tt HumanWild</annotation></semantics></math> can also be applied for the 2D human pose estimation task. Specifically, we obtain the initial 2D keypoints by projecting the 3D joints of SMPL-X into the image plane with the simulated camera parameters. The intuition of the 2D keypoint refinement is that different pose datasets provide different skeleton formats <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib63" title="" class="ltx_ref">63</a>]</cite>, even though they sometimes share the same joint names. To tackle the label discrepancies, it is necessary to refine the initial 2D keypoints to the formulation of the target 2D pose dataset. Here, we take the COCO dataset as an example to explain the proposed strategy for refining the initial 2D keypoints converted from the SMPL-X model.</p>
</div>
<div id="Pt0.A1.SS6.p2" class="ltx_para">
<p id="Pt0.A1.SS6.p2.1" class="ltx_p">We leverage a COCO pre-trained keypoint decoder proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite> to get more accurate 2D keypoint labels. Concretely, we replace the coarse proposals from fully connected layers with the initial 2D keypoints converted from SMPL-X, and then several deformable cross-attention <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib91" title="" class="ltx_ref">91</a>]</cite> operations are performed between the image features and keypoint queries to gradually generate the 2D keypoints in
the
COCO format. Compared to the pure pseudo-labeling process, our refinement strategy has more reliable initial keypoint proposals. Thus, our method has a higher upper bound of the final generated 2D keypoint labels.</p>
</div>
<div id="Pt0.A1.SS6.p3" class="ltx_para">
<p id="Pt0.A1.SS6.p3.3" class="ltx_p">InÂ <a href="#Pt0.A1.T12" title="In 0.A.6 Results on 2D HPE â€£ Appendix 0.A Appendix â€£ 3D Human Reconstruction in the Wild with Synthetic Data Using Generative ModelsWork was done when YG was visiting Zhejiang University. HC is the corresponding author." class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">12</span></a>, we adopt two types of 2D pose estimators, RTMPoseÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> and RLEPoseÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>, to verify the effectiveness of the proposed data generation pipeline.
For a fair comparison, all the models are trained with 10 epochs.
Our pipeline can consistently improve the detection performance when mixed with different COCO training subsets (from <math id="Pt0.A1.SS6.p3.1.m1.1" class="ltx_Math" alttext="1\%" display="inline"><semantics id="Pt0.A1.SS6.p3.1.m1.1a"><mrow id="Pt0.A1.SS6.p3.1.m1.1.1" xref="Pt0.A1.SS6.p3.1.m1.1.1.cmml"><mn id="Pt0.A1.SS6.p3.1.m1.1.1.2" xref="Pt0.A1.SS6.p3.1.m1.1.1.2.cmml">1</mn><mo id="Pt0.A1.SS6.p3.1.m1.1.1.1" xref="Pt0.A1.SS6.p3.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="Pt0.A1.SS6.p3.1.m1.1b"><apply id="Pt0.A1.SS6.p3.1.m1.1.1.cmml" xref="Pt0.A1.SS6.p3.1.m1.1.1"><csymbol cd="latexml" id="Pt0.A1.SS6.p3.1.m1.1.1.1.cmml" xref="Pt0.A1.SS6.p3.1.m1.1.1.1">percent</csymbol><cn type="integer" id="Pt0.A1.SS6.p3.1.m1.1.1.2.cmml" xref="Pt0.A1.SS6.p3.1.m1.1.1.2">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Pt0.A1.SS6.p3.1.m1.1c">1\%</annotation></semantics></math> to <math id="Pt0.A1.SS6.p3.2.m2.1" class="ltx_Math" alttext="100\%" display="inline"><semantics id="Pt0.A1.SS6.p3.2.m2.1a"><mrow id="Pt0.A1.SS6.p3.2.m2.1.1" xref="Pt0.A1.SS6.p3.2.m2.1.1.cmml"><mn id="Pt0.A1.SS6.p3.2.m2.1.1.2" xref="Pt0.A1.SS6.p3.2.m2.1.1.2.cmml">100</mn><mo id="Pt0.A1.SS6.p3.2.m2.1.1.1" xref="Pt0.A1.SS6.p3.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="Pt0.A1.SS6.p3.2.m2.1b"><apply id="Pt0.A1.SS6.p3.2.m2.1.1.cmml" xref="Pt0.A1.SS6.p3.2.m2.1.1"><csymbol cd="latexml" id="Pt0.A1.SS6.p3.2.m2.1.1.1.cmml" xref="Pt0.A1.SS6.p3.2.m2.1.1.1">percent</csymbol><cn type="integer" id="Pt0.A1.SS6.p3.2.m2.1.1.2.cmml" xref="Pt0.A1.SS6.p3.2.m2.1.1.2">100</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Pt0.A1.SS6.p3.2.m2.1c">100\%</annotation></semantics></math>).
The performance of <math id="Pt0.A1.SS6.p3.3.m3.1" class="ltx_Math" alttext="\tt HumanWild" display="inline"><semantics id="Pt0.A1.SS6.p3.3.m3.1a"><mi id="Pt0.A1.SS6.p3.3.m3.1.1" xref="Pt0.A1.SS6.p3.3.m3.1.1.cmml">ğ™·ğšğš–ğšŠğš—ğš†ğš’ğš•ğš</mi><annotation-xml encoding="MathML-Content" id="Pt0.A1.SS6.p3.3.m3.1b"><ci id="Pt0.A1.SS6.p3.3.m3.1.1.cmml" xref="Pt0.A1.SS6.p3.3.m3.1.1">ğ™·ğšğš–ğšŠğš—ğš†ğš’ğš•ğš</ci></annotation-xml><annotation encoding="application/x-tex" id="Pt0.A1.SS6.p3.3.m3.1c">\tt HumanWild</annotation></semantics></math> is comparable with BEDLAM in all data crops.
When joint training with all three datasets, both 2D pose regressors get the best performance.</p>
</div>
<div id="Pt0.A1.SS6.p4" class="ltx_para">
<p id="Pt0.A1.SS6.p4.3" class="ltx_p">We summarize the key results inÂ <a href="#Pt0.A1.T11" title="In 0.A.6 Results on 2D HPE â€£ Appendix 0.A Appendix â€£ 3D Human Reconstruction in the Wild with Synthetic Data Using Generative ModelsWork was done when YG was visiting Zhejiang University. HC is the corresponding author." class="ltx_ref"><span class="ltx_text ltx_ref_tag">Tab.</span>Â <span class="ltx_text ltx_ref_tag">11</span></a>. (1) Due to the lack of occlusion and multi-person scenes in the generated images, <math id="Pt0.A1.SS6.p4.1.m1.1" class="ltx_Math" alttext="\tt HumanWild" display="inline"><semantics id="Pt0.A1.SS6.p4.1.m1.1a"><mi id="Pt0.A1.SS6.p4.1.m1.1.1" xref="Pt0.A1.SS6.p4.1.m1.1.1.cmml">ğ™·ğšğš–ğšŠğš—ğš†ğš’ğš•ğš</mi><annotation-xml encoding="MathML-Content" id="Pt0.A1.SS6.p4.1.m1.1b"><ci id="Pt0.A1.SS6.p4.1.m1.1.1.cmml" xref="Pt0.A1.SS6.p4.1.m1.1.1">ğ™·ğšğš–ğšŠğš—ğš†ğš’ğš•ğš</ci></annotation-xml><annotation encoding="application/x-tex" id="Pt0.A1.SS6.p4.1.m1.1c">\tt HumanWild</annotation></semantics></math> cannot improve the results on the OCHuman validation set. (2) <math id="Pt0.A1.SS6.p4.2.m2.1" class="ltx_Math" alttext="\tt HumanWild" display="inline"><semantics id="Pt0.A1.SS6.p4.2.m2.1a"><mi id="Pt0.A1.SS6.p4.2.m2.1.1" xref="Pt0.A1.SS6.p4.2.m2.1.1.cmml">ğ™·ğšğš–ğšŠğš—ğš†ğš’ğš•ğš</mi><annotation-xml encoding="MathML-Content" id="Pt0.A1.SS6.p4.2.m2.1b"><ci id="Pt0.A1.SS6.p4.2.m2.1.1.cmml" xref="Pt0.A1.SS6.p4.2.m2.1.1">ğ™·ğšğš–ğšŠğš—ğš†ğš’ğš•ğš</ci></annotation-xml><annotation encoding="application/x-tex" id="Pt0.A1.SS6.p4.2.m2.1c">\tt HumanWild</annotation></semantics></math> can outperform DatasetDM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib80" title="" class="ltx_ref">80</a>]</cite> by a large margin on the COCO validation set under the same training setting.
We conjecture that the generated dataset only has one person per image, which lacks human-scene occlusion and human-human interaction.
We also find that classification-based RTMPose is less data-hungry than regression-base RLEPose in low data regime, <em id="Pt0.A1.SS6.p4.3.1" class="ltx_emph ltx_font_italic">e.g.</em>, achieving much higher AP on <math id="Pt0.A1.SS6.p4.3.m3.1" class="ltx_Math" alttext="1\%" display="inline"><semantics id="Pt0.A1.SS6.p4.3.m3.1a"><mrow id="Pt0.A1.SS6.p4.3.m3.1.1" xref="Pt0.A1.SS6.p4.3.m3.1.1.cmml"><mn id="Pt0.A1.SS6.p4.3.m3.1.1.2" xref="Pt0.A1.SS6.p4.3.m3.1.1.2.cmml">1</mn><mo id="Pt0.A1.SS6.p4.3.m3.1.1.1" xref="Pt0.A1.SS6.p4.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="Pt0.A1.SS6.p4.3.m3.1b"><apply id="Pt0.A1.SS6.p4.3.m3.1.1.cmml" xref="Pt0.A1.SS6.p4.3.m3.1.1"><csymbol cd="latexml" id="Pt0.A1.SS6.p4.3.m3.1.1.1.cmml" xref="Pt0.A1.SS6.p4.3.m3.1.1.1">percent</csymbol><cn type="integer" id="Pt0.A1.SS6.p4.3.m3.1.1.2.cmml" xref="Pt0.A1.SS6.p4.3.m3.1.1.2">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Pt0.A1.SS6.p4.3.m3.1c">1\%</annotation></semantics></math> COCO training set.</p>
</div>
<figure id="Pt0.A1.T11" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 11: </span>Main Results on 2D Human Pose Estimation. â€˜Pâ€™ denotes <math id="Pt0.A1.T11.2.m1.1" class="ltx_Math" alttext="\tt HumanWild" display="inline"><semantics id="Pt0.A1.T11.2.m1.1b"><mi id="Pt0.A1.T11.2.m1.1.1" xref="Pt0.A1.T11.2.m1.1.1.cmml">ğ™·ğšğš–ğšŠğš—ğš†ğš’ğš•ğš</mi><annotation-xml encoding="MathML-Content" id="Pt0.A1.T11.2.m1.1c"><ci id="Pt0.A1.T11.2.m1.1.1.cmml" xref="Pt0.A1.T11.2.m1.1.1">ğ™·ğšğš–ğšŠğš—ğš†ğš’ğš•ğš</ci></annotation-xml><annotation encoding="application/x-tex" id="Pt0.A1.T11.2.m1.1d">\tt HumanWild</annotation></semantics></math>; â€˜Dâ€™ denotes DatasetDM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib80" title="" class="ltx_ref">80</a>]</cite>, â€˜Câ€™ denotes COCO; â€˜Bâ€™ denotes BEDLAM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>. Crops % only applies to COCO during the training. We evaluate results on the COCO and OCHuman Datasets.</figcaption>
<div id="Pt0.A1.T11.6" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:131.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(9.0pt,-2.7pt) scale(1.04343313961323,1.04343313961323) ;">
<table id="Pt0.A1.T11.6.4" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="Pt0.A1.T11.6.4.5.1" class="ltx_tr">
<td id="Pt0.A1.T11.6.4.5.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" style="padding-left:3.4pt;padding-right:3.4pt;" rowspan="2"><span id="Pt0.A1.T11.6.4.5.1.1.1" class="ltx_text" style="font-size:90%;">Method</span></td>
<td id="Pt0.A1.T11.6.4.5.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:3.4pt;padding-right:3.4pt;" rowspan="2"><span id="Pt0.A1.T11.6.4.5.1.2.1" class="ltx_text" style="font-size:90%;">Backbone</span></td>
<td id="Pt0.A1.T11.6.4.5.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:3.4pt;padding-right:3.4pt;" rowspan="2"><span id="Pt0.A1.T11.6.4.5.1.3.1" class="ltx_text" style="font-size:90%;">Training Set</span></td>
<td id="Pt0.A1.T11.6.4.5.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:3.4pt;padding-right:3.4pt;" rowspan="2"><span id="Pt0.A1.T11.6.4.5.1.4.1" class="ltx_text" style="font-size:90%;">Crop</span></td>
<td id="Pt0.A1.T11.6.4.5.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:3.4pt;padding-right:3.4pt;" colspan="3"><span id="Pt0.A1.T11.6.4.5.1.5.1" class="ltx_text" style="font-size:90%;">COCO</span></td>
<td id="Pt0.A1.T11.6.4.5.1.6" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.4pt;padding-right:3.4pt;" colspan="3"><span id="Pt0.A1.T11.6.4.5.1.6.1" class="ltx_text" style="font-size:90%;">OCHuman</span></td>
</tr>
<tr id="Pt0.A1.T11.6.4.4" class="ltx_tr">
<td id="Pt0.A1.T11.6.4.4.5" class="ltx_td ltx_align_left" style="padding-left:3.4pt;padding-right:3.4pt;"><span id="Pt0.A1.T11.6.4.4.5.1" class="ltx_text" style="font-size:80%;">AP</span></td>
<td id="Pt0.A1.T11.3.1.1.1" class="ltx_td ltx_align_left" style="padding-left:3.4pt;padding-right:3.4pt;">
<span id="Pt0.A1.T11.3.1.1.1.1" class="ltx_text" style="font-size:80%;">AP</span><sub id="Pt0.A1.T11.3.1.1.1.2" class="ltx_sub"><span id="Pt0.A1.T11.3.1.1.1.2.1" class="ltx_text ltx_font_italic" style="font-size:80%;">m</span></sub>
</td>
<td id="Pt0.A1.T11.4.2.2.2" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:3.4pt;padding-right:3.4pt;">
<span id="Pt0.A1.T11.4.2.2.2.1" class="ltx_text" style="font-size:80%;">AP</span><sub id="Pt0.A1.T11.4.2.2.2.2" class="ltx_sub"><span id="Pt0.A1.T11.4.2.2.2.2.1" class="ltx_text ltx_font_italic" style="font-size:80%;">l</span></sub>
</td>
<td id="Pt0.A1.T11.6.4.4.6" class="ltx_td ltx_align_left" style="padding-left:3.4pt;padding-right:3.4pt;"><span id="Pt0.A1.T11.6.4.4.6.1" class="ltx_text" style="font-size:80%;">AP</span></td>
<td id="Pt0.A1.T11.5.3.3.3" class="ltx_td ltx_align_left" style="padding-left:3.4pt;padding-right:3.4pt;">
<span id="Pt0.A1.T11.5.3.3.3.1" class="ltx_text" style="font-size:80%;">AP</span><sub id="Pt0.A1.T11.5.3.3.3.2" class="ltx_sub"><span id="Pt0.A1.T11.5.3.3.3.2.1" class="ltx_text ltx_font_italic" style="font-size:80%;">m</span></sub>
</td>
<td id="Pt0.A1.T11.6.4.4.4" class="ltx_td ltx_align_left" style="padding-left:3.4pt;padding-right:3.4pt;">
<span id="Pt0.A1.T11.6.4.4.4.1" class="ltx_text" style="font-size:80%;">AP</span><sub id="Pt0.A1.T11.6.4.4.4.2" class="ltx_sub"><span id="Pt0.A1.T11.6.4.4.4.2.1" class="ltx_text ltx_font_italic" style="font-size:80%;">l</span></sub>
</td>
</tr>
<tr id="Pt0.A1.T11.6.4.6.2" class="ltx_tr">
<td id="Pt0.A1.T11.6.4.6.2.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:3.4pt;padding-right:3.4pt;">
<span id="Pt0.A1.T11.6.4.6.2.1.1" class="ltx_text" style="font-size:90%;">RTMPose </span><cite class="ltx_cite ltx_citemacro_cite"><span id="Pt0.A1.T11.6.4.6.2.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib23" title="" class="ltx_ref">23</a><span id="Pt0.A1.T11.6.4.6.2.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</td>
<td id="Pt0.A1.T11.6.4.6.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:3.4pt;padding-right:3.4pt;"><span id="Pt0.A1.T11.6.4.6.2.2.1" class="ltx_text" style="font-size:90%;">CSPNeXt</span></td>
<td id="Pt0.A1.T11.6.4.6.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:3.4pt;padding-right:3.4pt;"><span id="Pt0.A1.T11.6.4.6.2.3.1" class="ltx_text" style="font-size:90%;">C</span></td>
<td id="Pt0.A1.T11.6.4.6.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:3.4pt;padding-right:3.4pt;"><span id="Pt0.A1.T11.6.4.6.2.4.1" class="ltx_text" style="font-size:90%;">100</span></td>
<td id="Pt0.A1.T11.6.4.6.2.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.4pt;padding-right:3.4pt;"><span id="Pt0.A1.T11.6.4.6.2.5.1" class="ltx_text" style="font-size:90%;">75.2</span></td>
<td id="Pt0.A1.T11.6.4.6.2.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.4pt;padding-right:3.4pt;"><span id="Pt0.A1.T11.6.4.6.2.6.1" class="ltx_text" style="font-size:90%;">71.6</span></td>
<td id="Pt0.A1.T11.6.4.6.2.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:3.4pt;padding-right:3.4pt;"><span id="Pt0.A1.T11.6.4.6.2.7.1" class="ltx_text" style="font-size:90%;">81.9</span></td>
<td id="Pt0.A1.T11.6.4.6.2.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.4pt;padding-right:3.4pt;"><span id="Pt0.A1.T11.6.4.6.2.8.1" class="ltx_text" style="font-size:90%;">69.9</span></td>
<td id="Pt0.A1.T11.6.4.6.2.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.4pt;padding-right:3.4pt;"><span id="Pt0.A1.T11.6.4.6.2.9.1" class="ltx_text" style="font-size:90%;">67.0</span></td>
<td id="Pt0.A1.T11.6.4.6.2.10" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.4pt;padding-right:3.4pt;"><span id="Pt0.A1.T11.6.4.6.2.10.1" class="ltx_text" style="font-size:90%;">69.8</span></td>
</tr>
<tr id="Pt0.A1.T11.6.4.7.3" class="ltx_tr">
<td id="Pt0.A1.T11.6.4.7.3.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:3.4pt;padding-right:3.4pt;">
<span id="Pt0.A1.T11.6.4.7.3.1.1" class="ltx_text" style="font-size:90%;">RTMPose </span><cite class="ltx_cite ltx_citemacro_cite"><span id="Pt0.A1.T11.6.4.7.3.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib23" title="" class="ltx_ref">23</a><span id="Pt0.A1.T11.6.4.7.3.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</td>
<td id="Pt0.A1.T11.6.4.7.3.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.4pt;padding-right:3.4pt;"><span id="Pt0.A1.T11.6.4.7.3.2.1" class="ltx_text" style="font-size:90%;">CSPNeXt</span></td>
<td id="Pt0.A1.T11.6.4.7.3.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.4pt;padding-right:3.4pt;"><span id="Pt0.A1.T11.6.4.7.3.3.1" class="ltx_text" style="font-size:90%;">P+C</span></td>
<td id="Pt0.A1.T11.6.4.7.3.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.4pt;padding-right:3.4pt;"><span id="Pt0.A1.T11.6.4.7.3.4.1" class="ltx_text" style="font-size:90%;">100</span></td>
<td id="Pt0.A1.T11.6.4.7.3.5" class="ltx_td ltx_align_center" style="padding-left:3.4pt;padding-right:3.4pt;"><span id="Pt0.A1.T11.6.4.7.3.5.1" class="ltx_text" style="font-size:90%;">75.7</span></td>
<td id="Pt0.A1.T11.6.4.7.3.6" class="ltx_td ltx_align_center" style="padding-left:3.4pt;padding-right:3.4pt;"><span id="Pt0.A1.T11.6.4.7.3.6.1" class="ltx_text" style="font-size:90%;">72.4</span></td>
<td id="Pt0.A1.T11.6.4.7.3.7" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.4pt;padding-right:3.4pt;"><span id="Pt0.A1.T11.6.4.7.3.7.1" class="ltx_text" style="font-size:90%;">82.9</span></td>
<td id="Pt0.A1.T11.6.4.7.3.8" class="ltx_td ltx_align_center" style="padding-left:3.4pt;padding-right:3.4pt;"><span id="Pt0.A1.T11.6.4.7.3.8.1" class="ltx_text" style="font-size:90%;">67.2</span></td>
<td id="Pt0.A1.T11.6.4.7.3.9" class="ltx_td ltx_align_center" style="padding-left:3.4pt;padding-right:3.4pt;"><span id="Pt0.A1.T11.6.4.7.3.9.1" class="ltx_text" style="font-size:90%;">62.5</span></td>
<td id="Pt0.A1.T11.6.4.7.3.10" class="ltx_td ltx_align_center" style="padding-left:3.4pt;padding-right:3.4pt;"><span id="Pt0.A1.T11.6.4.7.3.10.1" class="ltx_text" style="font-size:90%;">67.2</span></td>
</tr>
<tr id="Pt0.A1.T11.6.4.8.4" class="ltx_tr">
<td id="Pt0.A1.T11.6.4.8.4.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="padding-left:3.4pt;padding-right:3.4pt;">
<span id="Pt0.A1.T11.6.4.8.4.1.1" class="ltx_text" style="font-size:90%;">SimplePose </span><cite class="ltx_cite ltx_citemacro_cite"><span id="Pt0.A1.T11.6.4.8.4.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib81" title="" class="ltx_ref">81</a><span id="Pt0.A1.T11.6.4.8.4.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</td>
<td id="Pt0.A1.T11.6.4.8.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:3.4pt;padding-right:3.4pt;"><span id="Pt0.A1.T11.6.4.8.4.2.1" class="ltx_text" style="font-size:90%;">HRNet-W32</span></td>
<td id="Pt0.A1.T11.6.4.8.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:3.4pt;padding-right:3.4pt;"><span id="Pt0.A1.T11.6.4.8.4.3.1" class="ltx_text" style="font-size:90%;">C</span></td>
<td id="Pt0.A1.T11.6.4.8.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:3.4pt;padding-right:3.4pt;"><span id="Pt0.A1.T11.6.4.8.4.4.1" class="ltx_text" style="font-size:90%;">100</span></td>
<td id="Pt0.A1.T11.6.4.8.4.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.4pt;padding-right:3.4pt;"><span id="Pt0.A1.T11.6.4.8.4.5.1" class="ltx_text" style="font-size:90%;">74.9</span></td>
<td id="Pt0.A1.T11.6.4.8.4.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.4pt;padding-right:3.4pt;"><span id="Pt0.A1.T11.6.4.8.4.6.1" class="ltx_text" style="font-size:90%;">71.3</span></td>
<td id="Pt0.A1.T11.6.4.8.4.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:3.4pt;padding-right:3.4pt;"><span id="Pt0.A1.T11.6.4.8.4.7.1" class="ltx_text" style="font-size:90%;">81.5</span></td>
<td id="Pt0.A1.T11.6.4.8.4.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.4pt;padding-right:3.4pt;"><span id="Pt0.A1.T11.6.4.8.4.8.1" class="ltx_text" style="font-size:90%;">59.8</span></td>
<td id="Pt0.A1.T11.6.4.8.4.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.4pt;padding-right:3.4pt;"><span id="Pt0.A1.T11.6.4.8.4.9.1" class="ltx_text" style="font-size:90%;">65.3</span></td>
<td id="Pt0.A1.T11.6.4.8.4.10" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.4pt;padding-right:3.4pt;"><span id="Pt0.A1.T11.6.4.8.4.10.1" class="ltx_text" style="font-size:90%;">59.8</span></td>
</tr>
<tr id="Pt0.A1.T11.6.4.9.5" class="ltx_tr">
<td id="Pt0.A1.T11.6.4.9.5.1" class="ltx_td ltx_align_left ltx_border_r" style="padding-left:3.4pt;padding-right:3.4pt;">
<span id="Pt0.A1.T11.6.4.9.5.1.1" class="ltx_text" style="font-size:90%;">SimplePose </span><cite class="ltx_cite ltx_citemacro_cite"><span id="Pt0.A1.T11.6.4.9.5.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib81" title="" class="ltx_ref">81</a><span id="Pt0.A1.T11.6.4.9.5.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</td>
<td id="Pt0.A1.T11.6.4.9.5.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.4pt;padding-right:3.4pt;"><span id="Pt0.A1.T11.6.4.9.5.2.1" class="ltx_text" style="font-size:90%;">HRNet-W32</span></td>
<td id="Pt0.A1.T11.6.4.9.5.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.4pt;padding-right:3.4pt;"><span id="Pt0.A1.T11.6.4.9.5.3.1" class="ltx_text" style="font-size:90%;">D+C</span></td>
<td id="Pt0.A1.T11.6.4.9.5.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.4pt;padding-right:3.4pt;"><span id="Pt0.A1.T11.6.4.9.5.4.1" class="ltx_text" style="font-size:90%;">1</span></td>
<td id="Pt0.A1.T11.6.4.9.5.5" class="ltx_td ltx_align_center" style="padding-left:3.4pt;padding-right:3.4pt;"><span id="Pt0.A1.T11.6.4.9.5.5.1" class="ltx_text" style="font-size:90%;">47.5</span></td>
<td id="Pt0.A1.T11.6.4.9.5.6" class="ltx_td ltx_align_center" style="padding-left:3.4pt;padding-right:3.4pt;"><span id="Pt0.A1.T11.6.4.9.5.6.1" class="ltx_text" style="font-size:90%;">44.2</span></td>
<td id="Pt0.A1.T11.6.4.9.5.7" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:3.4pt;padding-right:3.4pt;"><span id="Pt0.A1.T11.6.4.9.5.7.1" class="ltx_text" style="font-size:90%;">52.6</span></td>
<td id="Pt0.A1.T11.6.4.9.5.8" class="ltx_td ltx_align_center" style="padding-left:3.4pt;padding-right:3.4pt;"><span id="Pt0.A1.T11.6.4.9.5.8.1" class="ltx_text" style="font-size:90%;">N/A</span></td>
<td id="Pt0.A1.T11.6.4.9.5.9" class="ltx_td ltx_align_center" style="padding-left:3.4pt;padding-right:3.4pt;"><span id="Pt0.A1.T11.6.4.9.5.9.1" class="ltx_text" style="font-size:90%;">N/A</span></td>
<td id="Pt0.A1.T11.6.4.9.5.10" class="ltx_td ltx_align_center" style="padding-left:3.4pt;padding-right:3.4pt;"><span id="Pt0.A1.T11.6.4.9.5.10.1" class="ltx_text" style="font-size:90%;">N/A</span></td>
</tr>
<tr id="Pt0.A1.T11.6.4.10.6" class="ltx_tr">
<td id="Pt0.A1.T11.6.4.10.6.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" style="padding-left:3.4pt;padding-right:3.4pt;">
<span id="Pt0.A1.T11.6.4.10.6.1.1" class="ltx_text" style="font-size:90%;">SimplePose </span><cite class="ltx_cite ltx_citemacro_cite"><span id="Pt0.A1.T11.6.4.10.6.1.2.1" class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib81" title="" class="ltx_ref">81</a><span id="Pt0.A1.T11.6.4.10.6.1.3.2" class="ltx_text" style="font-size:90%;">]</span></cite>
</td>
<td id="Pt0.A1.T11.6.4.10.6.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:3.4pt;padding-right:3.4pt;"><span id="Pt0.A1.T11.6.4.10.6.2.1" class="ltx_text" style="font-size:90%;">HRNet-W32</span></td>
<td id="Pt0.A1.T11.6.4.10.6.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:3.4pt;padding-right:3.4pt;"><span id="Pt0.A1.T11.6.4.10.6.3.1" class="ltx_text" style="font-size:90%;">P+C</span></td>
<td id="Pt0.A1.T11.6.4.10.6.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:3.4pt;padding-right:3.4pt;"><span id="Pt0.A1.T11.6.4.10.6.4.1" class="ltx_text" style="font-size:90%;">1</span></td>
<td id="Pt0.A1.T11.6.4.10.6.5" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.4pt;padding-right:3.4pt;"><span id="Pt0.A1.T11.6.4.10.6.5.1" class="ltx_text" style="font-size:90%;">50.3</span></td>
<td id="Pt0.A1.T11.6.4.10.6.6" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.4pt;padding-right:3.4pt;"><span id="Pt0.A1.T11.6.4.10.6.6.1" class="ltx_text" style="font-size:90%;">44.7</span></td>
<td id="Pt0.A1.T11.6.4.10.6.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:3.4pt;padding-right:3.4pt;"><span id="Pt0.A1.T11.6.4.10.6.7.1" class="ltx_text" style="font-size:90%;">59.1</span></td>
<td id="Pt0.A1.T11.6.4.10.6.8" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.4pt;padding-right:3.4pt;"><span id="Pt0.A1.T11.6.4.10.6.8.1" class="ltx_text" style="font-size:90%;">29.5</span></td>
<td id="Pt0.A1.T11.6.4.10.6.9" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.4pt;padding-right:3.4pt;"><span id="Pt0.A1.T11.6.4.10.6.9.1" class="ltx_text" style="font-size:90%;">18.7</span></td>
<td id="Pt0.A1.T11.6.4.10.6.10" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.4pt;padding-right:3.4pt;"><span id="Pt0.A1.T11.6.4.10.6.10.1" class="ltx_text" style="font-size:90%;">29.5</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure id="Pt0.A1.F10" class="ltx_figure"><img src="/html/2403.11111/assets/x10.png" id="Pt0.A1.F10.g1" class="ltx_graphics ltx_centering ltx_img_square" width="461" height="454" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="Pt0.A1.F10.4.2.1" class="ltx_text" style="font-size:90%;">Figure 10</span>: </span><span id="Pt0.A1.F10.2.1" class="ltx_text" style="font-size:90%;">More Visualization of <math id="Pt0.A1.F10.2.1.m1.1" class="ltx_Math" alttext="\tt HumanWild" display="inline"><semantics id="Pt0.A1.F10.2.1.m1.1b"><mi id="Pt0.A1.F10.2.1.m1.1.1" xref="Pt0.A1.F10.2.1.m1.1.1.cmml">ğ™·ğšğš–ğšŠğš—ğš†ğš’ğš•ğš</mi><annotation-xml encoding="MathML-Content" id="Pt0.A1.F10.2.1.m1.1c"><ci id="Pt0.A1.F10.2.1.m1.1.1.cmml" xref="Pt0.A1.F10.2.1.m1.1.1">ğ™·ğšğš–ğšŠğš—ğš†ğš’ğš•ğš</ci></annotation-xml><annotation encoding="application/x-tex" id="Pt0.A1.F10.2.1.m1.1d">\tt HumanWild</annotation></semantics></math> with background surface normal information extracted from ScanNet++Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib85" title="" class="ltx_ref">85</a>]</cite>. The first two columns are compositional meshes with both SMPL-XÂ 
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite> model and indoor background meshes. The third column is the surface normal extracted from the compositional meshes. The fourth and fifth columns are images generated from the third column. The sixth column is the surface normal map without background normal. The last two columns are images generated from the sixth column.</span></figcaption>
</figure>
<figure id="Pt0.A1.T12" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="Pt0.A1.T12.8.2.1" class="ltx_text" style="font-size:90%;">Table 12</span>: </span><span id="Pt0.A1.T12.2.1" class="ltx_text" style="font-size:90%;">Ablation experiments on 2D human pose estimation. â€˜Câ€™ denotes COCO;
â€˜Bâ€™ denotes BEDLAM; â€˜Pâ€™ denotes <math id="Pt0.A1.T12.2.1.m1.1" class="ltx_Math" alttext="\tt HumanWild" display="inline"><semantics id="Pt0.A1.T12.2.1.m1.1b"><mi id="Pt0.A1.T12.2.1.m1.1.1" xref="Pt0.A1.T12.2.1.m1.1.1.cmml">ğ™·ğšğš–ğšŠğš—ğš†ğš’ğš•ğš</mi><annotation-xml encoding="MathML-Content" id="Pt0.A1.T12.2.1.m1.1c"><ci id="Pt0.A1.T12.2.1.m1.1.1.cmml" xref="Pt0.A1.T12.2.1.m1.1.1">ğ™·ğšğš–ğšŠğš—ğš†ğš’ğš•ğš</ci></annotation-xml><annotation encoding="application/x-tex" id="Pt0.A1.T12.2.1.m1.1d">\tt HumanWild</annotation></semantics></math>, and Crops % only applies to COCO. All
experiments are evaluated on the COCO validation set. AP is used as the
evaluation metric.</span></figcaption>
<div id="Pt0.A1.T12.6" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:332.8pt;height:129.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-41.6pt,16.2pt) scale(0.8,0.8) ;">
<table id="Pt0.A1.T12.6.4" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="Pt0.A1.T12.6.4.4" class="ltx_tr">
<th id="Pt0.A1.T12.6.4.4.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.4.5.1" class="ltx_text" style="font-size:90%;">Method</span></th>
<th id="Pt0.A1.T12.6.4.4.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.4.6.1" class="ltx_text" style="font-size:90%;">Dataset</span></th>
<th id="Pt0.A1.T12.6.4.4.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.4.7.1" class="ltx_text" style="font-size:90%;">Output Type</span></th>
<th id="Pt0.A1.T12.6.4.4.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.4.8.1" class="ltx_text" style="font-size:90%;">Backbone</span></th>
<th id="Pt0.A1.T12.3.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="Pt0.A1.T12.3.1.1.1.1" class="ltx_text" style="font-size:90%;">1% Crops</span><math id="Pt0.A1.T12.3.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="Pt0.A1.T12.3.1.1.1.m1.1a"><mo mathsize="90%" stretchy="false" id="Pt0.A1.T12.3.1.1.1.m1.1.1" xref="Pt0.A1.T12.3.1.1.1.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="Pt0.A1.T12.3.1.1.1.m1.1b"><ci id="Pt0.A1.T12.3.1.1.1.m1.1.1.cmml" xref="Pt0.A1.T12.3.1.1.1.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="Pt0.A1.T12.3.1.1.1.m1.1c">\uparrow</annotation></semantics></math>
</th>
<th id="Pt0.A1.T12.4.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="Pt0.A1.T12.4.2.2.2.1" class="ltx_text" style="font-size:90%;">5% Crops</span><math id="Pt0.A1.T12.4.2.2.2.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="Pt0.A1.T12.4.2.2.2.m1.1a"><mo mathsize="90%" stretchy="false" id="Pt0.A1.T12.4.2.2.2.m1.1.1" xref="Pt0.A1.T12.4.2.2.2.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="Pt0.A1.T12.4.2.2.2.m1.1b"><ci id="Pt0.A1.T12.4.2.2.2.m1.1.1.cmml" xref="Pt0.A1.T12.4.2.2.2.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="Pt0.A1.T12.4.2.2.2.m1.1c">\uparrow</annotation></semantics></math>
</th>
<th id="Pt0.A1.T12.5.3.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="Pt0.A1.T12.5.3.3.3.1" class="ltx_text" style="font-size:90%;">10% Crops</span><math id="Pt0.A1.T12.5.3.3.3.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="Pt0.A1.T12.5.3.3.3.m1.1a"><mo mathsize="90%" stretchy="false" id="Pt0.A1.T12.5.3.3.3.m1.1.1" xref="Pt0.A1.T12.5.3.3.3.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="Pt0.A1.T12.5.3.3.3.m1.1b"><ci id="Pt0.A1.T12.5.3.3.3.m1.1.1.cmml" xref="Pt0.A1.T12.5.3.3.3.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="Pt0.A1.T12.5.3.3.3.m1.1c">\uparrow</annotation></semantics></math>
</th>
<th id="Pt0.A1.T12.6.4.4.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="Pt0.A1.T12.6.4.4.4.1" class="ltx_text" style="font-size:90%;">100% Crops</span><math id="Pt0.A1.T12.6.4.4.4.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="Pt0.A1.T12.6.4.4.4.m1.1a"><mo mathsize="90%" stretchy="false" id="Pt0.A1.T12.6.4.4.4.m1.1.1" xref="Pt0.A1.T12.6.4.4.4.m1.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="Pt0.A1.T12.6.4.4.4.m1.1b"><ci id="Pt0.A1.T12.6.4.4.4.m1.1.1.cmml" xref="Pt0.A1.T12.6.4.4.4.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="Pt0.A1.T12.6.4.4.4.m1.1c">\uparrow</annotation></semantics></math>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="Pt0.A1.T12.6.4.5.1" class="ltx_tr">
<th id="Pt0.A1.T12.6.4.5.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.5.1.1.1" class="ltx_text" style="font-size:90%;">RTMPose</span></th>
<td id="Pt0.A1.T12.6.4.5.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.5.1.2.1" class="ltx_text" style="font-size:90%;">C</span></td>
<td id="Pt0.A1.T12.6.4.5.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.5.1.3.1" class="ltx_text" style="font-size:90%;">Classification</span></td>
<td id="Pt0.A1.T12.6.4.5.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.5.1.4.1" class="ltx_text" style="font-size:90%;">CSPNeXt</span></td>
<td id="Pt0.A1.T12.6.4.5.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.5.1.5.1" class="ltx_text" style="font-size:90%;">0.0</span></td>
<td id="Pt0.A1.T12.6.4.5.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.5.1.6.1" class="ltx_text" style="font-size:90%;">7.2</span></td>
<td id="Pt0.A1.T12.6.4.5.1.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.5.1.7.1" class="ltx_text" style="font-size:90%;">23.6</span></td>
<td id="Pt0.A1.T12.6.4.5.1.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.5.1.8.1" class="ltx_text" style="font-size:90%;">67.9</span></td>
</tr>
<tr id="Pt0.A1.T12.6.4.6.2" class="ltx_tr">
<th id="Pt0.A1.T12.6.4.6.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.6.2.1.1" class="ltx_text" style="font-size:90%;">RTMPose</span></th>
<td id="Pt0.A1.T12.6.4.6.2.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.6.2.2.1" class="ltx_text" style="font-size:90%;">B+C</span></td>
<td id="Pt0.A1.T12.6.4.6.2.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.6.2.3.1" class="ltx_text" style="font-size:90%;">Classification</span></td>
<td id="Pt0.A1.T12.6.4.6.2.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.6.2.4.1" class="ltx_text" style="font-size:90%;">CSPNeXt</span></td>
<td id="Pt0.A1.T12.6.4.6.2.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.6.2.5.1" class="ltx_text" style="font-size:90%;">46.4</span></td>
<td id="Pt0.A1.T12.6.4.6.2.6" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.6.2.6.1" class="ltx_text" style="font-size:90%;">55.9</span></td>
<td id="Pt0.A1.T12.6.4.6.2.7" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.6.2.7.1" class="ltx_text" style="font-size:90%;">58.7</span></td>
<td id="Pt0.A1.T12.6.4.6.2.8" class="ltx_td ltx_align_center" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.6.2.8.1" class="ltx_text" style="font-size:90%;">68.4</span></td>
</tr>
<tr id="Pt0.A1.T12.6.4.7.3" class="ltx_tr">
<th id="Pt0.A1.T12.6.4.7.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.7.3.1.1" class="ltx_text" style="font-size:90%;">RTMPose</span></th>
<td id="Pt0.A1.T12.6.4.7.3.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.7.3.2.1" class="ltx_text" style="font-size:90%;">P+C</span></td>
<td id="Pt0.A1.T12.6.4.7.3.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.7.3.3.1" class="ltx_text" style="font-size:90%;">Classification</span></td>
<td id="Pt0.A1.T12.6.4.7.3.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.7.3.4.1" class="ltx_text" style="font-size:90%;">CSPNeXt</span></td>
<td id="Pt0.A1.T12.6.4.7.3.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.7.3.5.1" class="ltx_text" style="font-size:90%;">49.1</span></td>
<td id="Pt0.A1.T12.6.4.7.3.6" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.7.3.6.1" class="ltx_text" style="font-size:90%;">55.7</span></td>
<td id="Pt0.A1.T12.6.4.7.3.7" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.7.3.7.1" class="ltx_text" style="font-size:90%;">58.0</span></td>
<td id="Pt0.A1.T12.6.4.7.3.8" class="ltx_td ltx_align_center" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.7.3.8.1" class="ltx_text" style="font-size:90%;">68.1</span></td>
</tr>
<tr id="Pt0.A1.T12.6.4.8.4" class="ltx_tr">
<th id="Pt0.A1.T12.6.4.8.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.8.4.1.1" class="ltx_text" style="font-size:90%;">RTMPose</span></th>
<td id="Pt0.A1.T12.6.4.8.4.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.8.4.2.1" class="ltx_text" style="font-size:90%;">P+B+C</span></td>
<td id="Pt0.A1.T12.6.4.8.4.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.8.4.3.1" class="ltx_text" style="font-size:90%;">Classification</span></td>
<td id="Pt0.A1.T12.6.4.8.4.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.8.4.4.1" class="ltx_text" style="font-size:90%;">CSPNeXt</span></td>
<td id="Pt0.A1.T12.6.4.8.4.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.8.4.5.1" class="ltx_text" style="font-size:90%;">61.9</span></td>
<td id="Pt0.A1.T12.6.4.8.4.6" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.8.4.6.1" class="ltx_text" style="font-size:90%;">63.1</span></td>
<td id="Pt0.A1.T12.6.4.8.4.7" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.8.4.7.1" class="ltx_text" style="font-size:90%;">64.4</span></td>
<td id="Pt0.A1.T12.6.4.8.4.8" class="ltx_td ltx_align_center" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.8.4.8.1" class="ltx_text" style="font-size:90%;">71.3</span></td>
</tr>
<tr id="Pt0.A1.T12.6.4.9.5" class="ltx_tr">
<th id="Pt0.A1.T12.6.4.9.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.9.5.1.1" class="ltx_text" style="font-size:90%;">RLEPose</span></th>
<td id="Pt0.A1.T12.6.4.9.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.9.5.2.1" class="ltx_text" style="font-size:90%;">C</span></td>
<td id="Pt0.A1.T12.6.4.9.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.9.5.3.1" class="ltx_text" style="font-size:90%;">Regression</span></td>
<td id="Pt0.A1.T12.6.4.9.5.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.9.5.4.1" class="ltx_text" style="font-size:90%;">ResNet50</span></td>
<td id="Pt0.A1.T12.6.4.9.5.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.9.5.5.1" class="ltx_text" style="font-size:90%;">0.0</span></td>
<td id="Pt0.A1.T12.6.4.9.5.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.9.5.6.1" class="ltx_text" style="font-size:90%;">3.9</span></td>
<td id="Pt0.A1.T12.6.4.9.5.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.9.5.7.1" class="ltx_text" style="font-size:90%;">19.2</span></td>
<td id="Pt0.A1.T12.6.4.9.5.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.9.5.8.1" class="ltx_text" style="font-size:90%;">53.5</span></td>
</tr>
<tr id="Pt0.A1.T12.6.4.10.6" class="ltx_tr">
<th id="Pt0.A1.T12.6.4.10.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.10.6.1.1" class="ltx_text" style="font-size:90%;">RLEPose</span></th>
<td id="Pt0.A1.T12.6.4.10.6.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.10.6.2.1" class="ltx_text" style="font-size:90%;">B+C</span></td>
<td id="Pt0.A1.T12.6.4.10.6.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.10.6.3.1" class="ltx_text" style="font-size:90%;">Regression</span></td>
<td id="Pt0.A1.T12.6.4.10.6.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.10.6.4.1" class="ltx_text" style="font-size:90%;">ResNet50</span></td>
<td id="Pt0.A1.T12.6.4.10.6.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.10.6.5.1" class="ltx_text" style="font-size:90%;">40.6</span></td>
<td id="Pt0.A1.T12.6.4.10.6.6" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.10.6.6.1" class="ltx_text" style="font-size:90%;">47.7</span></td>
<td id="Pt0.A1.T12.6.4.10.6.7" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.10.6.7.1" class="ltx_text" style="font-size:90%;">55.3</span></td>
<td id="Pt0.A1.T12.6.4.10.6.8" class="ltx_td ltx_align_center" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.10.6.8.1" class="ltx_text" style="font-size:90%;">64.8</span></td>
</tr>
<tr id="Pt0.A1.T12.6.4.11.7" class="ltx_tr">
<th id="Pt0.A1.T12.6.4.11.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.11.7.1.1" class="ltx_text" style="font-size:90%;">RLEPose</span></th>
<td id="Pt0.A1.T12.6.4.11.7.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.11.7.2.1" class="ltx_text" style="font-size:90%;">P+C</span></td>
<td id="Pt0.A1.T12.6.4.11.7.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.11.7.3.1" class="ltx_text" style="font-size:90%;">Regression</span></td>
<td id="Pt0.A1.T12.6.4.11.7.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.11.7.4.1" class="ltx_text" style="font-size:90%;">ResNet50</span></td>
<td id="Pt0.A1.T12.6.4.11.7.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.11.7.5.1" class="ltx_text" style="font-size:90%;">31.5</span></td>
<td id="Pt0.A1.T12.6.4.11.7.6" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.11.7.6.1" class="ltx_text" style="font-size:90%;">39.0</span></td>
<td id="Pt0.A1.T12.6.4.11.7.7" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.11.7.7.1" class="ltx_text" style="font-size:90%;">50.3</span></td>
<td id="Pt0.A1.T12.6.4.11.7.8" class="ltx_td ltx_align_center" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.11.7.8.1" class="ltx_text" style="font-size:90%;">65.1</span></td>
</tr>
<tr id="Pt0.A1.T12.6.4.12.8" class="ltx_tr">
<th id="Pt0.A1.T12.6.4.12.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.12.8.1.1" class="ltx_text" style="font-size:90%;">RLEPose</span></th>
<td id="Pt0.A1.T12.6.4.12.8.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.12.8.2.1" class="ltx_text" style="font-size:90%;">P+B+C</span></td>
<td id="Pt0.A1.T12.6.4.12.8.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.12.8.3.1" class="ltx_text" style="font-size:90%;">Regression</span></td>
<td id="Pt0.A1.T12.6.4.12.8.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.12.8.4.1" class="ltx_text" style="font-size:90%;">ResNet50</span></td>
<td id="Pt0.A1.T12.6.4.12.8.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.12.8.5.1" class="ltx_text" style="font-size:90%;">51.8</span></td>
<td id="Pt0.A1.T12.6.4.12.8.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.12.8.6.1" class="ltx_text" style="font-size:90%;">56.3</span></td>
<td id="Pt0.A1.T12.6.4.12.8.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.12.8.7.1" class="ltx_text" style="font-size:90%;">58.5</span></td>
<td id="Pt0.A1.T12.6.4.12.8.8" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="Pt0.A1.T12.6.4.12.8.8.1" class="ltx_text" style="font-size:90%;">66.6</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Andriluka, M., Pishchulin, L., Gehler, P., Schiele, B.: 2d human pose estimation: New benchmark and state of the art analysis. In: Proc. IEEE Conf. Comp. Vis. Patt. Recogn. pp. 3686â€“3693 (2014)

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Azizi, S., Kornblith, S., Saharia, C., Norouzi, M., Fleet, D.J.: Synthetic data from diffusion models improves imagenet classification. arXiv preprint arXiv:2304.08466 (2023)

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Bansal, A., Borgnia, E., Chu, H.M., Li, J.S., Kazemi, H., Huang, F., Goldblum, M., Geiping, J., Goldstein, T.: Cold diffusion: Inverting arbitrary image transforms without noise. In: Proc. Int. Conf. Learn. Representations (2022)

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
BiÅ„kowski, M., Sutherland, D.J., Arbel, M., Gretton, A.: Demystifying mmd gans. arXiv preprint arXiv:1801.01401 (2018)

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Black, M.J., Patel, P., Tesch, J., Yang, J.: Bedlam: A synthetic dataset of bodies exhibiting detailed lifelike animated motion. In: Proc. IEEE Conf. Comp. Vis. Patt. Recogn. pp. 8726â€“8737 (2023)

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Bogo, F., Kanazawa, A., Lassner, C., Gehler, P., Romero, J., Black, M.J.: Keep it smpl: Automatic estimation of 3d human pose and shape from a single image. In: Proc. Eur. Conf. Comp. Vis. pp. 561â€“578. Springer (2016)

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Byeon, M., Park, B., Kim, H., Lee, S., Baek, W., Kim, S.: Coyo-700m: Image-text pair dataset. <a target="_blank" href="https://github.com/kakaobrain/coyo-dataset" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/kakaobrain/coyo-dataset</a> (2022)

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Cai, Z., Ren, D., Zeng, A., Lin, Z., Yu, T., Wang, W., Fan, X., Gao, Y., Yu, Y., Pan, L., etÂ al.: Humman: Multi-modal 4d human dataset for versatile sensing and modeling. In: Proc. Eur. Conf. Comp. Vis. pp. 557â€“577. Springer (2022)

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Dai, Y., Lin, Y., Lin, X., Wen, C., Xu, L., Yi, H., Shen, S., Ma, Y., Wang, C.: Sloper4d: A scene-aware dataset for global 4d human pose estimation in urban environments. In: Proc. IEEE Conf. Comp. Vis. Patt. Recogn. pp. 682â€“692 (2023)

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Dou, Z., Chen, X., Fan, Q., Komura, T., Wang, W.: CÂ· ase: Learning conditional adversarial skillembeddings for physics-based characters. In: SIGGRAPH Asia 2023 Conference Papers. pp. 1â€“11 (2023)

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Dou, Z., Wu, Q., Lin, C., Cao, Z., Wu, Q., Wan, W., Komura, T., Wang, W.: Tore: Token reduction for efficient human mesh recovery with transformer. arXiv preprint arXiv:2211.10705 (2022)

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Eftekhar, A., Sax, A., Malik, J., Zamir, A.: Omnidata: A scalable pipeline for making multi-task mid-level vision datasets from 3d scans. In: Proceedings of the IEEE/CVF International Conference on Computer Vision. pp. 10786â€“10796 (2021)

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Fang, Y., Liao, B., Wang, X., Fang, J., Qi, J., Wu, R., Niu, J., Liu, W.: You only look at one sequence: Rethinking transformer in vision through object detection. In: Proc. Advances in Neural Inf. Process. Syst. (2021)

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Fieraru, M., Zanfir, M., Oneata, E., Popa, A.I., Olaru, V., Sminchisescu, C.: Three-dimensional reconstruction of human interactions. In: Proc. IEEE Conf. Comp. Vis. Patt. Recogn. (June 2020)

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Hassan, M., Choutas, V., Tzionas, D., Black, M.J.: Resolving 3d human pose ambiguities with 3d scene constraints. In: Proc. IEEE Int. Conf. Comp. Vis. pp. 2282â€“2292 (2019)

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition. In: Proc. IEEE Conf. Comp. Vis. Patt. Recogn. pp. 770â€“778 (2016)

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Heitz, E., Belcour, L., Chambon, T.: Iterative <math id="bib.bib17.1.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="bib.bib17.1.m1.1a"><mi id="bib.bib17.1.m1.1.1" xref="bib.bib17.1.m1.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="bib.bib17.1.m1.1b"><ci id="bib.bib17.1.m1.1.1.cmml" xref="bib.bib17.1.m1.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib17.1.m1.1c">\alpha</annotation></semantics></math>-(de) blending: a minimalist deterministic diffusion model. arXiv preprint arXiv:2305.03486 (2023)

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Heusel, M., Ramsauer, H., Unterthiner, T., Nessler, B., Hochreiter, S.: Gans trained by a two time-scale update rule converge to a local nash equilibrium. Advances in neural information processing systems <span id="bib.bib18.1.1" class="ltx_text ltx_font_bold">30</span> (2017)

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Ho, J., Jain, A., Abbeel, P.: Denoising diffusion probabilistic models. In: Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M., Lin, H. (eds.) NIPS. vol.Â 33, pp. 6840â€“6851. Curran Associates, Inc. (2020), <a target="_blank" href="https://proceedings.neurips.cc/paper_files/paper/2020/file/4c5bcfec8584af0d967f1ab10179ca4b-Paper.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.neurips.cc/paper_files/paper/2020/file/4c5bcfec8584af0d967f1ab10179ca4b-Paper.pdf</a>

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Huang, C.H.P., Yi, H., HÃ¶schle, M., Safroshkin, M., Alexiadis, T., Polikovsky, S., Scharstein, D., Black, M.J.: Capturing and inferring dense full-body human-scene contact. In: Proc. IEEE Conf. Comp. Vis. Patt. Recogn. pp. 13274â€“13285 (2022)

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
huggingface: Sdxl-controlnet: Depth (2023), <a target="_blank" href="https://huggingface.co/diffusers/controlnet-depth-sdxl-1.0" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://huggingface.co/diffusers/controlnet-depth-sdxl-1.0</a>

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Ionescu, C., Papava, D., Olaru, V., Sminchisescu, C.: Human3. 6m: Large scale datasets and predictive methods for 3d human sensing in natural environments. IEEE Trans. Pattern Anal. Mach. Intell. <span id="bib.bib22.1.1" class="ltx_text ltx_font_bold">36</span>(7), 1325â€“1339 (2013)

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Jiang, T., Lu, P., Zhang, L., Ma, N., Han, R., Lyu, C., Li, Y., Chen, K.: Rtmpose: Real-time multi-person pose estimation based on mmpose (2023). https://doi.org/10.48550/ARXIV.2303.07399, <a target="_blank" href="https://arxiv.org/abs/2303.07399" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2303.07399</a>

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Jiang, Y., Yang, S., Qiu, H., Wu, W., Loy, C.C., Liu, Z.: Text2human: Text-driven controllable human image generation. ACM Trans. Graphics <span id="bib.bib24.1.1" class="ltx_text ltx_font_bold">41</span>(4), 1â€“11 (2022)

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Joo, H., Neverova, N., Vedaldi, A.: Exemplar fine-tuning for 3d human model fitting towards in-the-wild 3d human pose estimation. In: Int. Conf. 3D. Vis. pp. 42â€“52. IEEE (2021)

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
Ju, X., Zeng, A., Zhao, C., Wang, J., Zhang, L., Xu, Q.: Humansd: A native skeleton-guided diffusion model for human image generation. arXiv preprint arXiv:2304.04269 (2023)

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Kanazawa, A., Black, M.J., Jacobs, D.W., Malik, J.: End-to-end recovery of human shape and pose. In: Proc. IEEE Conf. Comp. Vis. Patt. Recogn. pp. 7122â€“7131 (2018)

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Ke, B., Obukhov, A., Huang, S., Metzger, N., Daudt, R.C., Schindler, K.: Repurposing diffusion-based image generators for monocular depth estimation. arXiv preprint arXiv:2312.02145 (2023)

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
Kingma, D.P., Ba, J.: Adam: A method for stochastic optimization. arXiv: Comp. Res. Repository (2014)

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
Kirillov, A., Mintun, E., Ravi, N., Mao, H., Rolland, C., Gustafson, L., Xiao, T., Whitehead, S., Berg, A.C., Lo, W.Y., DollÃ¡r, P., Girshick, R.: Segment anything. arXiv:2304.02643 (2023)

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
Kocabas, M., Huang, C.H.P., Hilliges, O., Black, M.J.: Pare: Part attention regressor for 3d human body estimation. In: Proc. IEEE Int. Conf. Comp. Vis. pp. 11127â€“11137 (2021)

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
Kocabas, M., Huang, C.H.P., Tesch, J., MÃ¼ller, L., Hilliges, O., Black, M.J.: Spec: Seeing people in the wild with an estimated camera. In: Proc. IEEE Int. Conf. Comp. Vis. pp. 11035â€“11045 (2021)

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
Kolotouros, N., Pavlakos, G., Black, M.J., Daniilidis, K.: Learning to reconstruct 3d human pose and shape via model-fitting in the loop. In: Proc. IEEE Int. Conf. Comp. Vis. pp. 2252â€“2261 (2019)

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
Lee, H.Y., Tseng, H.Y., Lee, H.Y., Yang, M.H.: Exploiting diffusion prior for generalizable pixel-level semantic prediction. arXiv preprint arXiv:2311.18832 (2023)

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
Li, J., Bian, S., Zeng, A., Wang, C., Pang, B., Liu, W., Lu, C.: Human pose regression with residual log-likelihood estimation. In: Proc. IEEE Int. Conf. Comp. Vis. (2021)

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
Li, J., Xu, C., Chen, Z., Bian, S., Yang, L., Lu, C.: Hybrik: A hybrid analytical-neural inverse kinematics solution for 3d human pose and shape estimation. In: Proc. IEEE Conf. Comp. Vis. Patt. Recogn. pp. 3383â€“3393 (2021)

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
Li, J., Li, D., Xiong, C., Hoi, S.: Blip: Bootstrapping language-image pre-training for unified vision-language understanding and generation. In: ICML (2022)

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
Li, R., Yang, S., Ross, D.A., Kanazawa, A.: Ai choreographer: Music conditioned 3d dance generation with aist++. In: Proceedings of the IEEE/CVF International Conference on Computer Vision. pp. 13401â€“13412 (2021)

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
Li, Z., Liu, J., Zhang, Z., Xu, S., Yan, Y.: Cliff: Carrying location information in full frames into human pose and shape estimation. arXiv: Comp. Res. Repository (2022)

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
Lin, J., Zeng, A., Wang, H., Zhang, L., Li, Y.: One-stage 3d whole-body mesh recovery with component aware transformer. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 21159â€“21168 (2023)

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
Lin, K., Wang, L., Liu, Z.: Mesh graphormer. In: Proc. IEEE Int. Conf. Comp. Vis. pp. 12939â€“12948 (2021)

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
Lin, T.Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D., DollÃ¡r, P., Zitnick, C.L.: Microsoft coco: Common objects in context. In: Proc. Eur. Conf. Comp. Vis. (2014)

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
Liu, X., Ren, J., Siarohin, A., Skorokhodov, I., Li, Y., Lin, D., Liu, X., Liu, Z., Tulyakov, S.: Hyperhuman: Hyper-realistic human generation with latent structural diffusion. arXiv preprint arXiv:2310.08579 (2023)

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
Mahmood, N., Ghorbani, N., Troje, N.F., Pons-Moll, G., Black, M.J.: Amass: Archive of motion capture as surface shapes. In: Proc. IEEE Int. Conf. Comp. Vis. pp. 5442â€“5451 (2019)

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
Mao, W., Ge, Y., Shen, C., Tian, Z., Wang, X., Wang, Z., Hengel, A.v.d.: Poseur: Direct human pose regression with transformers. In: Proc. Eur. Conf. Comp. Vis. (October 2022)

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
von Marcard, T., Henschel, R., Black, M., Rosenhahn, B., Pons-Moll, G.: Recovering accurate 3D human pose in the wild using IMUs and a moving camera. In: Proc. Eur. Conf. Comp. Vis. (2018)

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
McInnes, L., Healy, J., Melville, J.: Umap: Uniform manifold approximation and projection for dimension reduction. arXiv preprint arXiv:1802.03426 (2018)

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
Meagher, D.: Geometric modeling using octree encoding. Computer graphics and image processing <span id="bib.bib48.1.1" class="ltx_text ltx_font_bold">19</span>(2), 129â€“147 (1982)

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
Mehta, D., Rhodin, H., Casas, D., Fua, P., Sotnychenko, O., Xu, W., Theobalt, C.: Monocular 3D human pose estimation in the wild using improved CNN supervision. In: Int. Conf. 3D. Vis. (2017)

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
Moon, G., Choi, H., Lee, K.M.: Accurate 3d hand pose estimation for whole-body 3d human mesh estimation. In: Proc. IEEE Conf. Comp. Vis. Patt. Recogn. pp. 2308â€“2317 (2022)

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
OpenAI: Gpt-3: Generative pre-trained transformer 3. <a target="_blank" href="https://openai.com/research/gpt-3" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openai.com/research/gpt-3</a> (2020)

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
OpenAI: Gpt-4 technical report (2023)

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
Oquab, M., Darcet, T., Moutakanni, T., Vo, H., <span id="bib.bib53.1.1" class="ltx_text ltx_font_italic">et al.</span>, M.S.: DINOv2: Learning robust visual features without supervision. TMLR (2024)

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock">
Pang, H.E., Cai, Z., Yang, L., Zhang, T., Liu, Z.: Benchmarking and analyzing 3d human pose and shape estimation beyond algorithms. In: Proc. Advances in Neural Inf. Process. Syst. (2022)

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
Patel, P., Huang, C.H.P., Tesch, J., Hoffmann, D.T., Tripathi, S., Black, M.J.: AGORA: Avatars in geography optimized for regression analysis. In: Proc. IEEE Conf. Comp. Vis. Patt. Recogn. (Jun 2021)

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock">
Pavlakos, G., Choutas, V., Ghorbani, N., Bolkart, T., Osman, A.A., Tzionas, D., Black, M.J.: Expressive body capture: 3d hands, face, and body from a single image. In: Proc. IEEE Conf. Comp. Vis. Patt. Recogn. pp. 10975â€“10985 (2019)

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock">
Peng, S., Zhang, Y., Xu, Y., Wang, Q., Shuai, Q., Bao, H., Zhou, X.: Neural body: Implicit neural representations with structured latent codes for novel view synthesis of dynamic humans. In: Proc. IEEE Conf. Comp. Vis. Patt. Recogn. pp. 9054â€“9063 (2021)

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock">
Podell, D., English, Z., Lacey, K., Blattmann, A., Dockhorn, T., MÃ¼ller, J., Penna, J., Rombach, R.: Sdxl: improving latent diffusion models for high-resolution image synthesis. arXiv preprint arXiv:2307.01952 (2023)

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock">
Roberts, M., Ramapuram, J., Ranjan, A., Kumar, A., Bautista, M.A., Paczan, N., Webb, R., Susskind, J.M.: Hypersim: A photorealistic synthetic dataset for holistic indoor scene understanding. In: International Conference on Computer Vision (ICCV) 2021 (2021)

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock">
Rombach, R., Blattmann, A., Lorenz, D., Esser, P., Ommer, B.: High-resolution image synthesis with latent diffusion models. In: Proc. IEEE Conf. Comp. Vis. Patt. Recogn. pp. 10684â€“10695 (2022)

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock">
Ronneberger, O., Fischer, P., Brox, T.: U-net: Convolutional networks for biomedical image segmentation. In: Medical Image Computing and Computer-Assisted Interventionâ€“MICCAI 2015: 18th International Conference, Munich, Germany, October 5-9, 2015, Proceedings, Part III 18. pp. 234â€“241. Springer (2015)

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[62]</span>
<span class="ltx_bibblock">
Salimans, T., Ho, J.: Progressive distillation for fast sampling of diffusion models. In: Proc. Int. Conf. Learn. Representations (2022)

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[63]</span>
<span class="ltx_bibblock">
SÃ¡rÃ¡ndi, I., Hermans, A., Leibe, B.: Learning 3D human pose estimation from dozens of datasets using a geometry-aware autoencoder to bridge between skeleton formats. In: Proc. Winter Conf. on Appl. of Comp. Vis. (2023)

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[64]</span>
<span class="ltx_bibblock">
Schuhmann, C., Beaumont, R., Vencu, R., Gordon, C., Wightman, R., Cherti, M., Coombes, T., Katta, A., Mullis, C., Wortsman, M., Schramowski, P., Kundurthy, S., Crowson, K., Schmidt, L., Kaczmarczyk, R., Jitsev, J.: Laion-5b: An open large-scale dataset for training next generation image-text models (2022)

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[65]</span>
<span class="ltx_bibblock">
Sengupta, A., Budvytis, I., Cipolla, R.: Synthetic training for accurate 3d human pose and shape estimation in the wild. arXiv preprint arXiv:2009.10013 (2020)

</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[66]</span>
<span class="ltx_bibblock">
Sigal, L., Balan, A.O., Black, M.J.: Humaneva: Synchronized video and motion capture dataset and baseline algorithm for evaluation of articulated human motion. International journal of computer vision <span id="bib.bib66.1.1" class="ltx_text ltx_font_bold">87</span>(1-2), 4â€“27 (2010)

</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[67]</span>
<span class="ltx_bibblock">
Song, J., Meng, C., Ermon, S.: Denoising diffusion implicit models. arXiv:2010.02502 (October 2020), <a target="_blank" href="https://arxiv.org/abs/2010.02502" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2010.02502</a>

</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[68]</span>
<span class="ltx_bibblock">
thibaud: Sdxl-controlnet: Pose (2023), <a target="_blank" href="https://huggingface.co/thibaud/controlnet-openpose-sdxl-1.0" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://huggingface.co/thibaud/controlnet-openpose-sdxl-1.0</a>

</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[69]</span>
<span class="ltx_bibblock">
Tian, Y., Fan, L., Isola, P., Chang, H., Krishnan, D.: Stablerep: Synthetic images from text-to-image models make strong visual representation learners. arXiv preprint arXiv:2306.00984 (2023)

</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[70]</span>
<span class="ltx_bibblock">
Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.A., Lacroix, T., RoziÃ¨re, B., Goyal, N., Hambro, E., Azhar, F., etÂ al.: Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971 (2023)

</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[71]</span>
<span class="ltx_bibblock">
Tripathi, S., MÃ¼ller, L., Huang, C.H.P., Omid, T., Black, M.J., Tzionas, D.: 3D human pose estimation via intuitive physics. In: Proc. IEEE Conf. Comp. Vis. Patt. Recogn. (June 2023)

</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[72]</span>
<span class="ltx_bibblock">
Varol, G., Romero, J., Martin, X., Mahmood, N., Black, M.J., Laptev, I., Schmid, C.: Learning from synthetic humans. In: Proc. IEEE Conf. Comp. Vis. Patt. Recogn. (2017)

</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[73]</span>
<span class="ltx_bibblock">
Voetman, R., Aghaei, M., Dijkstra, K.: The big data myth: Using diffusion models for dataset generation to train deep detection models. arXiv preprint arXiv:2306.09762 (2023)

</span>
</li>
<li id="bib.bib74" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[74]</span>
<span class="ltx_bibblock">
Wan, W., Dou, Z., Komura, T., Wang, W., Jayaraman, D., Liu, L.: Tlcontrol: Trajectory and language control for human motion synthesis. arXiv preprint arXiv:2311.17135 (2023)

</span>
</li>
<li id="bib.bib75" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[75]</span>
<span class="ltx_bibblock">
Wang, J., Yuan, Y., Luo, Z., Xie, K., Lin, D., Iqbal, U., Fidler, S., Khamis, S.: Learning human dynamics in autonomous driving scenarios. In: Proceedings of the IEEE/CVF International Conference on Computer Vision. pp. 20796â€“20806 (2023)

</span>
</li>
<li id="bib.bib76" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[76]</span>
<span class="ltx_bibblock">
Wang, J., Liu, Y., Dou, Z., Yu, Z., Liang, Y., Li, X., Wang, W., Xie, R., Song, L.: Disentangled clothed avatargeneration from text descriptions. arXiv preprint arXiv:2312.05295 (2023)

</span>
</li>
<li id="bib.bib77" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[77]</span>
<span class="ltx_bibblock">
Wang, W., Ge, Y., Mei, H., Cai, Z., Sun, Q., Wang, Y., Shen, C., Yang, L., Komura, T.: Zolly: Zoom focal length correctly for perspective-distorted human mesh reconstruction. arXiv preprint arXiv:2303.13796 (2023)

</span>
</li>
<li id="bib.bib78" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[78]</span>
<span class="ltx_bibblock">
Weng, Z., Bravo-SÃ¡nchez, L., Yeung, S.: Diffusion-hpc: Generating synthetic images with realistic humans. arXiv preprint arXiv:2303.09541 (2023)

</span>
</li>
<li id="bib.bib79" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[79]</span>
<span class="ltx_bibblock">
Wood, E., BaltruÅ¡aitis, T., Hewitt, C., Johnson, M., Shen, J., MilosavljeviÄ‡, N., Wilde, D., Garbin, S., Sharp, T., StojiljkoviÄ‡, I., etÂ al.: 3d face reconstruction with dense landmarks. In: Proc. Eur. Conf. Comp. Vis. pp. 160â€“177. Springer (2022)

</span>
</li>
<li id="bib.bib80" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[80]</span>
<span class="ltx_bibblock">
Wu, W., Zhao, Y., Chen, H., Gu, Y., Zhao, R., He, Y., Zhou, H., Shou, M.Z., Shen, C.: Datasetdm: Synthesizing data with perception annotations using diffusion models. arXiv: Comp. Res. Repository (2023)

</span>
</li>
<li id="bib.bib81" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[81]</span>
<span class="ltx_bibblock">
Xiao, B., Wu, H., Wei, Y.: Simple baselines for human pose estimation and tracking. In: Proc. Eur. Conf. Comp. Vis. pp. 466â€“481 (2018)

</span>
</li>
<li id="bib.bib82" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[82]</span>
<span class="ltx_bibblock">
Xiao, Z., Wang, T., Wang, J., Cao, J., Zhang, W., Dai, B., Lin, D., Pang, J.: Unified human-scene interaction via prompted chain-of-contacts. arXiv preprint arXiv:2309.07918 (2023)

</span>
</li>
<li id="bib.bib83" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[83]</span>
<span class="ltx_bibblock">
Yang, X., Yuan, L., Wilber, K., Sharma, A., Gu, X., Qiao, S., Debats, S., Wang, H., Adam, H., Sirotenko, M., etÂ al.: Polymax: General dense prediction with mask transformer. In: Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision. pp. 1050â€“1061 (2024)

</span>
</li>
<li id="bib.bib84" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[84]</span>
<span class="ltx_bibblock">
Yang, Z., Cai, Z., Mei, H., Liu, S., Chen, Z., Xiao, W., Wei, Y., Qing, Z., Wei, C., Dai, B., etÂ al.: Synbody: Synthetic dataset with layered human models for 3d human perception and modeling. arXiv preprint arXiv:2303.17368 (2023)

</span>
</li>
<li id="bib.bib85" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[85]</span>
<span class="ltx_bibblock">
Yeshwanth, C., Liu, Y.C., NieÃŸner, M., Dai, A.: Scannet++: A high-fidelity dataset of 3d indoor scenes. In: Proceedings of the IEEE/CVF International Conference on Computer Vision. pp. 12â€“22 (2023)

</span>
</li>
<li id="bib.bib86" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[86]</span>
<span class="ltx_bibblock">
Yin, Y., Guo, C., Kaufmann, M., Zarate, J., Song, J., Hilliges, O.: Hi4d: 4d instance segmentation of close human interaction. In: Proc. IEEE Conf. Comp. Vis. Patt. Recogn. (2023)

</span>
</li>
<li id="bib.bib87" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[87]</span>
<span class="ltx_bibblock">
Zhang, H., Tian, Y., Zhang, Y., Li, M., An, L., Sun, Z., Liu, Y.: Pymaf-x: Towards well-aligned full-body model regression from monocular images. arXiv preprint arXiv:2207.06400 (2022)

</span>
</li>
<li id="bib.bib88" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[88]</span>
<span class="ltx_bibblock">
Zhang, L., Agrawala, M.: Adding conditional control to text-to-image diffusion models. arXiv preprint arXiv:2302.05543 (2023)

</span>
</li>
<li id="bib.bib89" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[89]</span>
<span class="ltx_bibblock">
Zhang, S., Ma, Q., Zhang, Y., Qian, Z., Kwon, T., Pollefeys, M., Bogo, F., Tang, S.: Egobody: Human body shape and motion of interacting people from head-mounted devices. In: Proc. Eur. Conf. Comp. Vis. pp. 180â€“200. Springer (2022)

</span>
</li>
<li id="bib.bib90" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[90]</span>
<span class="ltx_bibblock">
Zhou, W., Dou, Z., Cao, Z., Liao, Z., Wang, J., Wang, W., Liu, Y., Komura, T., Wang, W., Liu, L.: Emdm: Efficient motion diffusion model for fast, high-quality motion generation. arXiv preprint arXiv:2312.02256 (2023)

</span>
</li>
<li id="bib.bib91" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[91]</span>
<span class="ltx_bibblock">
Zhu, X., Su, W., Lu, L., Li, B., Wang, X., Dai, J.: Deformable DETR: Deformable Transformers for end-to-end object detection. In: Proc. Int. Conf. Learn. Representations (2021)

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2403.11110" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2403.11111" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2403.11111">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2403.11111" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2403.11112" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Apr  5 13:44:39 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
