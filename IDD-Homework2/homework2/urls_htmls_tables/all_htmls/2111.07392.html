<!DOCTYPE html><html lang="en-GB">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2111.07392] Edge-Native Intelligence for 6G Communications Driven by Federated Learning: A Survey of Trends and Challenges</title><meta property="og:description" content="New technological advancements in wireless networks have enlarged the number of connected devices. The unprecedented surge of data volume in wireless systems empowered by artificial intelligence (AI) opens up new horiz…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Edge-Native Intelligence for 6G Communications Driven by Federated Learning: A Survey of Trends and Challenges">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Edge-Native Intelligence for 6G Communications Driven by Federated Learning: A Survey of Trends and Challenges">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2111.07392">

<!--Generated on Tue Mar 12 12:36:54 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en-GB" content="">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line" lang="en-GB">
<h1 class="ltx_title ltx_title_document">Edge-Native Intelligence for 6G Communications Driven by Federated Learning: A Survey of Trends and Challenges </h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Mohammad Al-Quraan,  Lina Mohjazi,  Lina Bariah,  Anthony Centeno, Ahmed Zoha,  Kamran Arshad, Khaled Assaleh, Sami Muhaidat,  Mérouane Debbah,  and Muhammad Ali Imran
</span><span class="ltx_author_notes">M. Al-Quraan, L. Mohjazi, A. Centeno, and A. Zoha are with the James Watt School of Engineering, University of Glasgow, Glasgow, G12 8QQ, UK, (e-mail: m.alquraan.1@research.gla.ac.uk, {Lina.Mohjazi, Anthony.Centeno, Ahmed.Zoha}@glasgow.ac.uk).L. Bariah is with the Technology Innovation Institute, 9639 Masdar City, Abu Dhabi, UAE, (e-mail: lina.bariah@ieee.org).K. Arshad and K. Assaleh are with the Artificial Intelligence Research Center (AIRC), College of Engineering and Information Technology, Ajman University, Ajman, UAE, (e-mail: {k.arshad, k.assaleh}@ajman.ac.ae).S. Muhaidat is with the Center for Cyber-Physical Systems, Department of Electrical Engineering and Computer Science, Khalifa University, Abu Dhabi 127788, UAE, and also with the Department of Systems and Computer Engineering, Carleton University, Ottawa, ON K1S 5B6, Canada, (e-mail: muhaidat@ieee.org).M. Debbah is with the Technology Innovation Institute, 9639 Masdar City, Abu Dhabi, UAE, (email: merouane.debbah@tii.ae) and also with CentraleSupelec, University Paris-Saclay, 91192 Gif-sur-Yvette, France.M. A. Imran is with the James Watt School of Engineering, University of Glasgow, Glasgow, G12 8QQ, UK, and also with Artificial Intelligence Research Center (AIRC), College of Engineering and Information Technology, Ajman University, Ajman, UAE, (e-mail: Muhammad.Imran@glasgow.ac.uk)</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id11.id1" class="ltx_p"><span id="id11.id1.1" class="ltx_text">New technological advancements in wireless networks have enlarged the number of connected devices. The unprecedented surge of data volume in wireless systems empowered by artificial intelligence (AI) opens up new horizons for providing ubiquitous data-driven intelligent services. Traditional cloud-centric machine learning (ML)-based services are implemented by centrally collecting datasets and training models. However, this conventional training technique encompasses two challenges: (i) high communication and energy cost and (ii) threatened data privacy. In this article, we introduce a comprehensive survey of the fundamentals and enabling technologies of federated learning (FL), a newly emerging technique coined to bring ML to the edge of wireless networks. Moreover, an extensive study is presented detailing various applications of FL in wireless networks and highlighting their challenges and limitations. The efficacy of FL is further explored with emerging prospective beyond fifth-generation (B5G) and sixth-generation (6G) communication systems. This survey aims to provide an overview of the state-of-the-art FL applications in key wireless technologies that will serve as a foundation to establish a firm understanding of the topic. Lastly, we offer a road forward for future research directions.
<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span> Copyright © 2023 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works.</span></span></span></span></p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
<span id="id12.id1" class="ltx_text">
5G, 6G, artificial intelligence, federated learning, wireless networks.
</span>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">INTRODUCTION</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Recent years have witnessed an unprecedented increase in the number of connected objects, which is attributed to the emergence of novel technological trends as well as the evolution of connected intelligence paradigms, promoting massive scale connectivity <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. In specific, the number of internet-of-things (IoT) devices per human was 1.84 in 2010 with a total of 12.5 billion devices, while in 2020, this number increased to 6.58 devices per human with nearly a total of 50 billion devices <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. With the remarkable revolutionary advancements in the field of wireless communications, it is envisioned that these numbers will continue to rise exponentially. Accordingly, enlarging connected devices, such as IoT, smartphones, industry machines, etc., will create a bottleneck on the limited resources of wireless networks. Therefore, there will be a continuous need to develop the existing network infrastructure to meet diversified demands.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">According to the International Telecommunications Union (ITU) and the 3rd Generation Partnership Project (3GPP), the fifth generation (5G) wireless networks are designed to deliver improved quality of experience (QoE) by offering enhanced data rate, reliability, capacity, and energy efficiency. In light of this, 5G wireless systems were mapped out based on three fundamental concepts, namely, enhanced mobile broadband (eMBB), ultra-reliable and low latency communications (URLLC), and massive machine-type communications (mMTC) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>. Nevertheless, the rise of services like extended reality and massive IoT, and the expected future applications such as holographic communications and multi-sense experience, impose far more stringent requirements than 5G networks and shed light on the next network improvements. Hence, the research will be shifted towards sixth-generation (6G) communication networks.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">The fast-growing number of connected devices, coupled with the development of wireless communication infrastructures and the capability of embracing a wide range of intelligent applications, have resulted in unprecedented volumes of produced data traffic that need to be stored and processed; yielding the new concept of big data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>. To harness the benefits of this data, artificial intelligence (AI), especially machine learning (ML), has become the cutting-edge technology that has the potential to exploit big data to deliver pervasive smart services and applications <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>. ML models are trained to perform diversified tasks by exploring hidden data patterns and drawing the value of such data to predict useful outcomes for several use cases, such as medical diagnosis and natural language processing <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">In conventional ML algorithms, model training is performed centrally in cloud-based servers<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. Datasets are collected and stored in one location, processed, and then employed to train ML models using one or multiple servers. This centralised nature of ML models limits their applicability for several emerging wireless network applications. The limitations include the following:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">Increased communication overhead between the end devices and the cloud resulting in network congestion and high energy consumption.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">The privacy is not by design, so security and data privacy are always a concern for conventional approaches.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">The propagation delay experienced in such ML techniques limits the implementation of centralised learning in real-time applications.</p>
</div>
</li>
</ul>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">In light of this, federated learning (FL) has emerged as a promising solution to tackle the aforementioned challenges of centralised ML <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>. FL is a collaborative ML algorithm that uses distributed entities’ datasets for local model training without the need to exchange any raw data with a central server. In FL, the role of cloud-based servers is limited to aggregating local models to develop a global model to be shared with all nodes in the network. Initially, a centralised server broadcasts initial model parameters to participating nodes, which leverage these parameters and their onboard resource capabilities for local model training. Next, once the training round is finished, each participant will send the local model updates to the FL server to aggregate the received local models. For enhanced accuracy, model training in FL is performed over multiple iterations; hence, after each training round, the server shares updated model parameters with participating devices to be utilised for the next training round. By using FL, the amount of data that needs to be sent to the server is reduced significantly, allowing only model updates to be sent to the server and hence, alleviating the pressure on the network resources. Furthermore, FL protects the endpoints’ data privacy and security by allowing model training locally, where the data is generated.</p>
</div>
<section id="S1.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S1.SS1.4.1.1" class="ltx_text">I-A</span> </span><span id="S1.SS1.5.2" class="ltx_text ltx_font_italic">Related Surveys in the Literature</span>
</h3>

<div id="S1.SS1.p1" class="ltx_para">
<p id="S1.SS1.p1.1" class="ltx_p">FL has attracted numerous interests and has been implemented in diverse applications across many areas. Notably, several surveys have been published since the advent of the FL algorithm. Table <a href="#S1.T1" title="Table I ‣ I-A Related Surveys in the Literature ‣ I INTRODUCTION ‣ Edge-Native Intelligence for 6G Communications Driven by Federated Learning: A Survey of Trends and Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a> summarises these surveys and highlights their significance. Here we outline the surveys in chronological order based on the publication date. The work in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> categorises the FL systems into three categories, namely, vertical, horizontal, and federated transfer learning (FTL), and discusses the privacy techniques used in FL. The authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> highlight the need to implement ML at the wireless network edge to facilitate reliable and low-latency communication. They explore the key building blocks of ML that allow for the transition from centralised, cloud-based model training to decentralised training techniques such as FL. Furthermore, a thorough investigation of the technical and theoretical frameworks of several case studies illustrates the importance of edge intelligence for beyond 5G (B5G) networks. Later, Kairouz <em id="S1.SS1.p1.1.1" class="ltx_emph ltx_font_italic">et al.</em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> introduce recent advances in FL by discussing techniques used to improve FL efficiency, explaining the methods used to preserve user data privacy, and how to make FL algorithms robust against attacks. The authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> discuss possible threats and attacks, and highlight their implications to future FL algorithms, whereas <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> discusses FL properties and associated challenges in comparison to traditional distributed data centre computing. Du <em id="S1.SS1.p1.1.2" class="ltx_emph ltx_font_italic">et al.</em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> outline the importance and technical challenges of implementing FL in vehicular IoT networks.</p>
</div>
<figure id="S1.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S1.T1.2.1.1" class="ltx_text" style="font-size:90%;">Table I</span>: </span><span id="S1.T1.3.2" class="ltx_text" style="font-size:90%;">Summary of Relevant FL Surveys. </span></figcaption>
<table id="S1.T1.4" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S1.T1.4.1.1" class="ltx_tr">
<th id="S1.T1.4.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S1.T1.4.1.1.1.1" class="ltx_text ltx_font_bold">Ref.</span></th>
<th id="S1.T1.4.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">
<table id="S1.T1.4.1.1.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S1.T1.4.1.1.2.1.1" class="ltx_tr">
<td id="S1.T1.4.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S1.T1.4.1.1.2.1.1.1.1" class="ltx_text ltx_font_bold">Date</span></td>
</tr>
</table>
</th>
<th id="S1.T1.4.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span id="S1.T1.4.1.1.3.1" class="ltx_text ltx_font_bold">Authors</span></th>
<th id="S1.T1.4.1.1.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t"><span id="S1.T1.4.1.1.4.1" class="ltx_text ltx_font_bold">Article Main Topic</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S1.T1.4.2.1" class="ltx_tr">
<td id="S1.T1.4.2.1.1" class="ltx_td ltx_align_center ltx_border_tt"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite></td>
<td id="S1.T1.4.2.1.2" class="ltx_td ltx_align_left ltx_border_tt">Jan. 2019</td>
<td id="S1.T1.4.2.1.3" class="ltx_td ltx_align_left ltx_border_tt">Q. Yang, <em id="S1.T1.4.2.1.3.1" class="ltx_emph ltx_font_italic">et al.</em>
</td>
<td id="S1.T1.4.2.1.4" class="ltx_td ltx_align_left ltx_border_tt">
<table id="S1.T1.4.2.1.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S1.T1.4.2.1.4.1.1" class="ltx_tr">
<td id="S1.T1.4.2.1.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Categories of FL and Privacy</td>
</tr>
<tr id="S1.T1.4.2.1.4.1.2" class="ltx_tr">
<td id="S1.T1.4.2.1.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Techniques</td>
</tr>
</table>
</td>
</tr>
<tr id="S1.T1.4.3.2" class="ltx_tr">
<td id="S1.T1.4.3.2.1" class="ltx_td ltx_align_center ltx_border_t"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite></td>
<td id="S1.T1.4.3.2.2" class="ltx_td ltx_align_left ltx_border_t">Oct. 2019</td>
<td id="S1.T1.4.3.2.3" class="ltx_td ltx_align_left ltx_border_t">J. Park, <em id="S1.T1.4.3.2.3.1" class="ltx_emph ltx_font_italic">et al.</em>
</td>
<td id="S1.T1.4.3.2.4" class="ltx_td ltx_align_left ltx_border_t">
<table id="S1.T1.4.3.2.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S1.T1.4.3.2.4.1.1" class="ltx_tr">
<td id="S1.T1.4.3.2.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Edge ML in Beyond 5G</td>
</tr>
<tr id="S1.T1.4.3.2.4.1.2" class="ltx_tr">
<td id="S1.T1.4.3.2.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Networks</td>
</tr>
</table>
</td>
</tr>
<tr id="S1.T1.4.4.3" class="ltx_tr">
<td id="S1.T1.4.4.3.1" class="ltx_td ltx_align_center ltx_border_t"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite></td>
<td id="S1.T1.4.4.3.2" class="ltx_td ltx_align_left ltx_border_t">Dec. 2019</td>
<td id="S1.T1.4.4.3.3" class="ltx_td ltx_align_left ltx_border_t">P. Kairouz, <em id="S1.T1.4.4.3.3.1" class="ltx_emph ltx_font_italic">et al.</em>
</td>
<td id="S1.T1.4.4.3.4" class="ltx_td ltx_align_left ltx_border_t">
<table id="S1.T1.4.4.3.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S1.T1.4.4.3.4.1.1" class="ltx_tr">
<td id="S1.T1.4.4.3.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">FL Advances, Problems and</td>
</tr>
<tr id="S1.T1.4.4.3.4.1.2" class="ltx_tr">
<td id="S1.T1.4.4.3.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Challenges</td>
</tr>
</table>
</td>
</tr>
<tr id="S1.T1.4.5.4" class="ltx_tr">
<td id="S1.T1.4.5.4.1" class="ltx_td ltx_align_center ltx_border_t"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite></td>
<td id="S1.T1.4.5.4.2" class="ltx_td ltx_align_left ltx_border_t">Mar. 2020</td>
<td id="S1.T1.4.5.4.3" class="ltx_td ltx_align_left ltx_border_t">L. Lyu, H. Yu, Q. Yang</td>
<td id="S1.T1.4.5.4.4" class="ltx_td ltx_align_left ltx_border_t">FL Threats and Attacks</td>
</tr>
<tr id="S1.T1.4.6.5" class="ltx_tr">
<td id="S1.T1.4.6.5.1" class="ltx_td ltx_align_center ltx_border_t"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite></td>
<td id="S1.T1.4.6.5.2" class="ltx_td ltx_align_left ltx_border_t">May 2020</td>
<td id="S1.T1.4.6.5.3" class="ltx_td ltx_align_left ltx_border_t">T. Li, <em id="S1.T1.4.6.5.3.1" class="ltx_emph ltx_font_italic">et al.</em>
</td>
<td id="S1.T1.4.6.5.4" class="ltx_td ltx_align_left ltx_border_t">FL Implementation Challenges</td>
</tr>
<tr id="S1.T1.4.7.6" class="ltx_tr">
<td id="S1.T1.4.7.6.1" class="ltx_td ltx_align_center ltx_border_t"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite></td>
<td id="S1.T1.4.7.6.2" class="ltx_td ltx_align_left ltx_border_t">May 2020</td>
<td id="S1.T1.4.7.6.3" class="ltx_td ltx_align_left ltx_border_t">Z. Du, <em id="S1.T1.4.7.6.3.1" class="ltx_emph ltx_font_italic">et al.</em>
</td>
<td id="S1.T1.4.7.6.4" class="ltx_td ltx_align_left ltx_border_t">
<table id="S1.T1.4.7.6.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S1.T1.4.7.6.4.1.1" class="ltx_tr">
<td id="S1.T1.4.7.6.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">FL Challenges in Vehicular</td>
</tr>
<tr id="S1.T1.4.7.6.4.1.2" class="ltx_tr">
<td id="S1.T1.4.7.6.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Networks</td>
</tr>
</table>
</td>
</tr>
<tr id="S1.T1.4.8.7" class="ltx_tr">
<td id="S1.T1.4.8.7.1" class="ltx_td ltx_align_center ltx_border_t"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite></td>
<td id="S1.T1.4.8.7.2" class="ltx_td ltx_align_left ltx_border_t">July 2020</td>
<td id="S1.T1.4.8.7.3" class="ltx_td ltx_align_left ltx_border_t">M. Aledhari, <em id="S1.T1.4.8.7.3.1" class="ltx_emph ltx_font_italic">et al.</em>
</td>
<td id="S1.T1.4.8.7.4" class="ltx_td ltx_align_left ltx_border_t">
<table id="S1.T1.4.8.7.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S1.T1.4.8.7.4.1.1" class="ltx_tr">
<td id="S1.T1.4.8.7.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">FL Protocols and Enabling</td>
</tr>
<tr id="S1.T1.4.8.7.4.1.2" class="ltx_tr">
<td id="S1.T1.4.8.7.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Technologies</td>
</tr>
</table>
</td>
</tr>
<tr id="S1.T1.4.9.8" class="ltx_tr">
<td id="S1.T1.4.9.8.1" class="ltx_td ltx_align_center ltx_border_t"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite></td>
<td id="S1.T1.4.9.8.2" class="ltx_td ltx_align_left ltx_border_t">July 2020</td>
<td id="S1.T1.4.9.8.3" class="ltx_td ltx_align_left ltx_border_t">
<table id="S1.T1.4.9.8.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S1.T1.4.9.8.3.1.1" class="ltx_tr">
<td id="S1.T1.4.9.8.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">V. Kulkarni, M. Kulkarni,</td>
</tr>
<tr id="S1.T1.4.9.8.3.1.2" class="ltx_tr">
<td id="S1.T1.4.9.8.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">A. Pant</td>
</tr>
</table>
</td>
<td id="S1.T1.4.9.8.4" class="ltx_td ltx_align_left ltx_border_t">FL Personalisation Techniques</td>
</tr>
<tr id="S1.T1.4.10.9" class="ltx_tr">
<td id="S1.T1.4.10.9.1" class="ltx_td ltx_align_center ltx_border_t"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite></td>
<td id="S1.T1.4.10.9.2" class="ltx_td ltx_align_left ltx_border_t">July 2020</td>
<td id="S1.T1.4.10.9.3" class="ltx_td ltx_align_left ltx_border_t">W. Yang, <em id="S1.T1.4.10.9.3.1" class="ltx_emph ltx_font_italic">et al.</em>
</td>
<td id="S1.T1.4.10.9.4" class="ltx_td ltx_align_left ltx_border_t">FL in Mobile Edge Networks</td>
</tr>
<tr id="S1.T1.4.11.10" class="ltx_tr">
<td id="S1.T1.4.11.10.1" class="ltx_td ltx_align_center ltx_border_t"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite></td>
<td id="S1.T1.4.11.10.2" class="ltx_td ltx_align_left ltx_border_t">Dec. 2020</td>
<td id="S1.T1.4.11.10.3" class="ltx_td ltx_align_left ltx_border_t">M. Chen, <em id="S1.T1.4.11.10.3.1" class="ltx_emph ltx_font_italic">et al.</em>
</td>
<td id="S1.T1.4.11.10.4" class="ltx_td ltx_align_left ltx_border_t">Collaborative FL</td>
</tr>
<tr id="S1.T1.4.12.11" class="ltx_tr">
<td id="S1.T1.4.12.11.1" class="ltx_td ltx_align_center ltx_border_t"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite></td>
<td id="S1.T1.4.12.11.2" class="ltx_td ltx_align_left ltx_border_t">Jan. 2021</td>
<td id="S1.T1.4.12.11.3" class="ltx_td ltx_align_left ltx_border_t">Q. Li, <em id="S1.T1.4.12.11.3.1" class="ltx_emph ltx_font_italic">et al.</em>
</td>
<td id="S1.T1.4.12.11.4" class="ltx_td ltx_align_left ltx_border_t">Thorough FL Categorisation</td>
</tr>
<tr id="S1.T1.4.13.12" class="ltx_tr">
<td id="S1.T1.4.13.12.1" class="ltx_td ltx_align_center ltx_border_t"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite></td>
<td id="S1.T1.4.13.12.2" class="ltx_td ltx_align_left ltx_border_t">Feb. 2021</td>
<td id="S1.T1.4.13.12.3" class="ltx_td ltx_align_left ltx_border_t">O. A. Wahab, <em id="S1.T1.4.13.12.3.1" class="ltx_emph ltx_font_italic">et al.</em>
</td>
<td id="S1.T1.4.13.12.4" class="ltx_td ltx_align_left ltx_border_t">
<table id="S1.T1.4.13.12.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S1.T1.4.13.12.4.1.1" class="ltx_tr">
<td id="S1.T1.4.13.12.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">FL in Communication and</td>
</tr>
<tr id="S1.T1.4.13.12.4.1.2" class="ltx_tr">
<td id="S1.T1.4.13.12.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Networking Systems</td>
</tr>
</table>
</td>
</tr>
<tr id="S1.T1.4.14.13" class="ltx_tr">
<td id="S1.T1.4.14.13.1" class="ltx_td ltx_align_center ltx_border_t"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite></td>
<td id="S1.T1.4.14.13.2" class="ltx_td ltx_align_left ltx_border_t">Apr. 2021</td>
<td id="S1.T1.4.14.13.3" class="ltx_td ltx_align_left ltx_border_t">S. Abdulrahman, <em id="S1.T1.4.14.13.3.1" class="ltx_emph ltx_font_italic">et al.</em>
</td>
<td id="S1.T1.4.14.13.4" class="ltx_td ltx_align_left ltx_border_t">
<table id="S1.T1.4.14.13.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S1.T1.4.14.13.4.1.1" class="ltx_tr">
<td id="S1.T1.4.14.13.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">FL Architecture Extensive</td>
</tr>
<tr id="S1.T1.4.14.13.4.1.2" class="ltx_tr">
<td id="S1.T1.4.14.13.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Explanation</td>
</tr>
</table>
</td>
</tr>
<tr id="S1.T1.4.15.14" class="ltx_tr">
<td id="S1.T1.4.15.14.1" class="ltx_td ltx_align_center ltx_border_t"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite></td>
<td id="S1.T1.4.15.14.2" class="ltx_td ltx_align_left ltx_border_t">June 2021</td>
<td id="S1.T1.4.15.14.3" class="ltx_td ltx_align_left ltx_border_t">L. Khan, <em id="S1.T1.4.15.14.3.1" class="ltx_emph ltx_font_italic">et al.</em>
</td>
<td id="S1.T1.4.15.14.4" class="ltx_td ltx_align_left ltx_border_t">
<table id="S1.T1.4.15.14.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S1.T1.4.15.14.4.1.1" class="ltx_tr">
<td id="S1.T1.4.15.14.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">FL Integration with IoT</td>
</tr>
<tr id="S1.T1.4.15.14.4.1.2" class="ltx_tr">
<td id="S1.T1.4.15.14.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Networks</td>
</tr>
</table>
</td>
</tr>
<tr id="S1.T1.4.16.15" class="ltx_tr">
<td id="S1.T1.4.16.15.1" class="ltx_td ltx_align_center ltx_border_t"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite></td>
<td id="S1.T1.4.16.15.2" class="ltx_td ltx_align_left ltx_border_t">Dec. 2021</td>
<td id="S1.T1.4.16.15.3" class="ltx_td ltx_align_left ltx_border_t">Z. Yang, <em id="S1.T1.4.16.15.3.1" class="ltx_emph ltx_font_italic">et al.</em>
</td>
<td id="S1.T1.4.16.15.4" class="ltx_td ltx_align_left ltx_border_t">
<table id="S1.T1.4.16.15.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S1.T1.4.16.15.4.1.1" class="ltx_tr">
<td id="S1.T1.4.16.15.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">FL Implementation in Wireless</td>
</tr>
<tr id="S1.T1.4.16.15.4.1.2" class="ltx_tr">
<td id="S1.T1.4.16.15.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Communications</td>
</tr>
</table>
</td>
</tr>
<tr id="S1.T1.4.17.16" class="ltx_tr">
<td id="S1.T1.4.17.16.1" class="ltx_td ltx_align_center ltx_border_t"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite></td>
<td id="S1.T1.4.17.16.2" class="ltx_td ltx_align_left ltx_border_t">Mar. 2022</td>
<td id="S1.T1.4.17.16.3" class="ltx_td ltx_align_left ltx_border_t">A. Z. Tan, <em id="S1.T1.4.17.16.3.1" class="ltx_emph ltx_font_italic">et al.</em>
</td>
<td id="S1.T1.4.17.16.4" class="ltx_td ltx_align_left ltx_border_t">Taxonomy of personalised FL</td>
</tr>
<tr id="S1.T1.4.18.17" class="ltx_tr">
<td id="S1.T1.4.18.17.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite></td>
<td id="S1.T1.4.18.17.2" class="ltx_td ltx_align_left ltx_border_b ltx_border_t">June 2022</td>
<td id="S1.T1.4.18.17.3" class="ltx_td ltx_align_left ltx_border_b ltx_border_t">B. Ghimire, D. B. Rawat</td>
<td id="S1.T1.4.18.17.4" class="ltx_td ltx_align_left ltx_border_b ltx_border_t">Cybersecurity and FL in IoT</td>
</tr>
</tbody>
</table>
</figure>
<div id="S1.SS1.p2" class="ltx_para">
<p id="S1.SS1.p2.1" class="ltx_p">The contribution in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> spots the light on the concept of FL and illustrates some of the enabling technologies and recent research that addresses different FL perspectives. The study in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> discusses the implications of training the FL model using heterogeneous datasets, and presents recent research that applies personalisation to overcome the data heterogeneity problem. While <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> is restricted in presenting the challenges associated with deploying FL in mobile edge networks only and provides the developed solutions that optimise these networks. Reliance on a central controller to organise the FL training process in IoT networks can limit the FL applications, and this issue is the authors’ main focus in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>. Accordingly, they have proposed a collaborative FL (CFL) framework where clients can implement FL with less dependence on the central server. CFL enables clients to engage in FL directly or indirectly, where some users are directly connected to the server while others are associated with neighbouring clients. Furthermore, this survey presents the original FL’s architecture, benefits, and shortcomings compared to CFL. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>, the authors present a thorough categorisation of FL in different aspects and discuss the existing solutions with their limitations in enabling FL. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> presents a tutorial on FL technologies and the associated challenges in communication and networking systems. The survey in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> explains the FL architecture, system model and design, application areas, privacy and security, and resource management. The work in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> presents a new taxonomy of FL in the context of IoT networks and explores FL’s recent developments toward enabling intelligent IoT applications. Moreover, this survey introduces a set of metrics that can be considered when evaluating the performance of new FL algorithms. The review paper <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> highlights the requirements for FL in wireless communications, particularly for envisioned 6G systems. Besides, the motivation for using FL and the main obstacles accompanying FL implementation are discussed. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite> introduces the key motivation and the taxonomy of personalised FL, which is the technique used to handle the statistical heterogeneity of real-world datasets to learn ML models collaboratively. The authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> study the use of FL in cybersecurity and vice versa, and discuss several approaches that address IoT networks’ performance issues when deploying FL.</p>
</div>
</section>
<section id="S1.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S1.SS2.4.1.1" class="ltx_text">I-B</span> </span><span id="S1.SS2.5.2" class="ltx_text ltx_font_italic">Contributions</span>
</h3>

<div id="S1.SS2.p1" class="ltx_para">
<p id="S1.SS2.p1.1" class="ltx_p">It is worth emphasising that to the best of our knowledge, no prior works presented a comprehensive study of FL potentials and applications for various existing/next-generation wireless networks. Besides, most of the aforementioned survey papers generally focus on specific technological trends or aspects associated with FL applications. Conversely, in this survey, we provide a systematic review with a featured presentation that leads the reader to a thorough understanding of the FL algorithm and its recent advents, as well as its envisioned implementations in various types of B5G/6G wireless networks. Moreover, this article offers numerous future research opportunities derived from the latest trending technologies that have not been covered by any previous surveys to the best of the authors’ knowledge.
The following points demonstrate our main contributions:</p>
<ul id="S1.I2" class="ltx_itemize">
<li id="S1.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i1.p1" class="ltx_para">
<p id="S1.I2.i1.p1.1" class="ltx_p">We present a concrete conceptual background on the working principles of the FL algorithm. Also, we describe its architecture, categories, operation, and optimisation schemes.</p>
</div>
</li>
<li id="S1.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i2.p1" class="ltx_para">
<p id="S1.I2.i2.p1.1" class="ltx_p">We explore the enabling technologies that create the stepping stones for facilitating the operation of FL.</p>
</div>
</li>
<li id="S1.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i3.p1" class="ltx_para">
<p id="S1.I2.i3.p1.1" class="ltx_p">We provide an in-depth discussion of the key drivers for deploying FL in state-of-the-art wireless applications, taking into account the associated performance metrics and ongoing research. Moreover, we discuss the vision for integrating FL with new potential prospective areas in future wireless networks.</p>
</div>
</li>
<li id="S1.I2.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i4.p1" class="ltx_para">
<p id="S1.I2.i4.p1.1" class="ltx_p">The survey delves into highlighting the challenges associated with the operation of FL in emerging wireless technologies, and identifies the approaches proposed to tackle them.</p>
</div>
</li>
<li id="S1.I2.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i5.p1" class="ltx_para">
<p id="S1.I2.i5.p1.1" class="ltx_p">We offer a look ahead towards unexplored possibilities drawn from modern technology trends to reap the benefits of FL implementations in the context of cutting-edge future research directions.</p>
</div>
</li>
</ul>
<p id="S1.SS2.p1.2" class="ltx_p">It is noteworthy that the survey structure is organised and written in a distinct taxonomy to make it easier for the reader to navigate and recognise the contributions made in each area.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2111.07392/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="179" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.2.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S1.F1.3.2" class="ltx_text" style="font-size:90%;">Illustrative diagram of the paper structure.</span></figcaption>
</figure>
</section>
<section id="S1.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S1.SS3.4.1.1" class="ltx_text">I-C</span> </span><span id="S1.SS3.5.2" class="ltx_text ltx_font_italic">Organisation</span>
</h3>

<div id="S1.SS3.p1" class="ltx_para">
<p id="S1.SS3.p1.1" class="ltx_p">The rest of this paper is organised as follows. Section <a href="#S2" title="II PRELIMINARY: FL Fundamentals ‣ Edge-Native Intelligence for 6G Communications Driven by Federated Learning: A Survey of Trends and Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a> introduces the fundamental aspects of the FL framework covering architecture, categories, operation, and aggregation schemes. Then, we give the key enabling technologies of FL in Section <a href="#S3" title="III FL Enabling Technologies ‣ Edge-Native Intelligence for 6G Communications Driven by Federated Learning: A Survey of Trends and Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a>. Section <a href="#S4" title="IV FL APPLICATIONS IN WIRELESS NETWORKS ‣ Edge-Native Intelligence for 6G Communications Driven by Federated Learning: A Survey of Trends and Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV</span></a> presents a comprehensive study of FL applications in various wireless networks. In addition, this section discusses its applicability in new potential areas of B5G/6G networks. After that, the FL challenges and corresponding mitigating techniques are outlined in Section <a href="#S5" title="V FL CHALLENGES ‣ Edge-Native Intelligence for 6G Communications Driven by Federated Learning: A Survey of Trends and Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">V</span></a>. Section <a href="#S6" title="VI FUTURE RESEARCH DIRECTIONS ‣ Edge-Native Intelligence for 6G Communications Driven by Federated Learning: A Survey of Trends and Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">VI</span></a> points out future research directions from different perspectives. Finally, Section <a href="#S7" title="VII CONCLUSIONS ‣ Edge-Native Intelligence for 6G Communications Driven by Federated Learning: A Survey of Trends and Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">VII</span></a> gives concluding remarks. Fig. <a href="#S1.F1" title="Figure 1 ‣ I-B Contributions ‣ I INTRODUCTION ‣ Edge-Native Intelligence for 6G Communications Driven by Federated Learning: A Survey of Trends and Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> illustrates the detailed outline of this survey.</p>
</div>
</section>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">PRELIMINARY: FL Fundamentals</span>
</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">The concept of FL has attracted significant attention in academia and industry <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>. The key principle of FL is to construct a generalised global model by performing distributed model training. The recent advancement in edge devices’ communication and computation capabilities and the large amount of data generated and stored locally on the devices facilitate the spread of this emerging technology widely. This section presents the fundamentals, architecture, categories, operation principles, and aggregation schemes of FL algorithms.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS1.4.1.1" class="ltx_text">II-A</span> </span><span id="S2.SS1.5.2" class="ltx_text ltx_font_italic">FL Architecture</span>
</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Based on the nature of the network, the architecture of FL can be categorised into classical and hierarchical FL (HFL). The classical FL approach consists of two main parts: the server and the participating clients <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>, as illustrated in Fig. <a href="#S2.F2" title="Figure 2 ‣ II-A FL Architecture ‣ II PRELIMINARY: FL Fundamentals ‣ Edge-Native Intelligence for 6G Communications Driven by Federated Learning: A Survey of Trends and Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>(a). The FL server must have certain specifications to orchestrate the FL process efficiently. These specifications are drawn from the considered ML technique and the number of clients. For instance, training a deep learning (DL) model through many clients requires a high server capacity, a huge computation capability, high-speed interfaces, and locating the server in close proximity to the clients. On the other hand, the specifications may be less stringent when considering simpler models of neural networks and a few clients. At the beginning of the FL process, the server will initiate the training procedure by sharing a new or pretrained model with the participating clients. After that, the clients will personalise the received model by training it based on their local data, and then share their local models with the server for aggregation and global model update. On the other hand, HFL framework <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>, depicted in Fig. 2(b), optimally fits in heterogeneous networks that include different cell coverage. This architecture is introduced to alleviate the bandwidth (BW) overhead at the FL servers, resulting from the large number of model updates communicated from the clients. Furthermore, HFL can reduce the communication latency experienced between the clients and the server by reducing the link distance. The HFL framework consists of two stages; in the first one, the clients send and receive the model parameters by communicating with a server located at the small base station (SBS), i.e., the edge server, and the server performs local model aggregation. Meanwhile, in the second stage, the edge servers send the aggregated models to a central server that can be located at the macro base station (MBS) or in the cloud, in which the server performs edge model aggregation for global model update and sends it back to the edge servers.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">It is worth mentioning that the need for robust communications between the clients and the FL server, mainly when the latter is located in the cloud, is mandatory to guarantee a seamless FL training process. However, the current internet links’ capacity is insufficient to meet the emergency demands, along with the growing connectivity needs from different sectors, such as industry, education, and transportation. This results in the need to move to the new concept of worldwide decentralised internet, which can be achieved using decentralised mesh networks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>. Such networks rely on establishing connections between different nodes, i.e., consumers and businesses, to make alternative ways of connectivity other than the known centralised internet service provider connection. Decentralised mesh networks are reliable for maintaining the connections between the participating clients and the FL server and ensuring a smooth training process.</p>
</div>
<figure id="S2.F2" class="ltx_figure"><img src="/html/2111.07392/assets/x2.png" id="S2.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="207" height="150" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F2.2.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S2.F2.3.2" class="ltx_text" style="font-size:90%;">Types of FL architecture (a) Classical FL in client-server architecture (b) Hierarchical FL in client-edge-server architecture.</span></figcaption>
</figure>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS2.4.1.1" class="ltx_text">II-B</span> </span><span id="S2.SS2.5.2" class="ltx_text ltx_font_italic">FL Categories</span>
</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">Given the significant role of local datasets in realising efficient training and assuming the data is maintained in a 2D matrix form, rows represent data samples, and columns indicate features. FL systems can be classified based on the data distribution characteristics between different parties into horizontal, vertical, and FTL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>.</p>
</div>
<section id="S2.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S2.SS2.SSS1.4.1.1" class="ltx_text">II-B</span>1 </span><span id="S2.SS2.SSS1.5.2" class="ltx_text ltx_font_bold">Horizontal FL</span>
</h4>

<div id="S2.SS2.SSS1.p1" class="ltx_para">
<p id="S2.SS2.SSS1.p1.1" class="ltx_p">This is the most common category of FL, also called sample-based FL. The unique characteristic of this category is that the datasets of different parties share the same feature space while differing in the sample space. For example, two regional educational institutes have similar interests in monitoring the research outcomes, representing the feature space, while they have different research groups that denote the sample space. This category facilitates the adoption of a unified ML model with the same architecture for all datasets. Therefore, the global model can be obtained by averaging all local updates. FedAvg technique <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> is an example of this type of FL system.</p>
</div>
</section>
<section id="S2.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S2.SS2.SSS2.4.1.1" class="ltx_text">II-B</span>2 </span><span id="S2.SS2.SSS2.5.2" class="ltx_text ltx_font_bold">Vertical FL</span>
</h4>

<div id="S2.SS2.SSS2.p1" class="ltx_para">
<p id="S2.SS2.SSS2.p1.1" class="ltx_p">This category, referred to as feature-based FL, can be exploited when two or more datasets share the same sample space while their feature spaces are distinct. For instance, considering two different parties in the same city, one is a healthcare institute, whereas the other is an e-commerce company that records the customers’ buying habits. Their user sets are most likely to have residents from that area, which means the same sample space. The objective here is to exploit the different features of these two parties to build a model that predicts the future health status of the residents based on their buying practices. When implementing vertical FL, the participating parties may be curious to know each other’s data, so a trusted third-party coordinator can protect the data confidentiality during the training process. However, if a certain level of trust exists between the participating parties, the need for a third party can be eliminated, and one of the parties can be the coordinator.</p>
</div>
</section>
<section id="S2.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S2.SS2.SSS3.4.1.1" class="ltx_text">II-B</span>3 </span><span id="S2.SS2.SSS3.5.2" class="ltx_text ltx_font_bold">FTL</span>
</h4>

<div id="S2.SS2.SSS3.p1" class="ltx_para">
<p id="S2.SS2.SSS3.p1.1" class="ltx_p">When the dataset of different clients slightly intersects in the feature and sample spaces, FTL (or hybrid learning) is the best candidate. FTL enables knowledge transfer from one domain to another, which helps in achieving better learning results. Specifically, a local model trained in one party is transferred to another party to leverage information extracted from the non-overlapping regions for enhanced model training at the other party. The most common example of transfer learning is the image classification problem. Several models exist that are tailored for classifying specific datasets, and they can be used to classify other types of datasets after making a minor tuning.</p>
</div>
</section>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS3.4.1.1" class="ltx_text">II-C</span> </span><span id="S2.SS3.5.2" class="ltx_text ltx_font_italic">FL Operation</span>
</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">FL protocol consists of three main phases <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> detailed as the following:</p>
</div>
<div id="S2.SS3.p2" class="ltx_para">
<p id="S2.SS3.p2.1" class="ltx_p">1. <span id="S2.SS3.p2.1.1" class="ltx_text ltx_font_bold">Clients selection</span>: Albeit large-scale deployment is an attractive feature in FL, compared to classical ML, the number of clients participating in model training can easily reach thousands or millions of devices. This enormous number of endpoints reflects the capacity enhancements anticipated to be delivered by B5G (1 million/km<sup id="S2.SS3.p2.1.2" class="ltx_sup">2</sup>) and 6G networks (100/m<sup id="S2.SS3.p2.1.3" class="ltx_sup">3</sup>). As a result, end-device onboard capabilities and data distribution will vary considerably among the participants, rendering client selection a critical design aspect in FL. Several methods are proposed to address this issue, such as <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>, where the authors propose a technique that improves the time-to-accuracy training performance by guiding the FL developers to select participants even at the scale of millions of clients. Further approaches are discussed in Section <a href="#S5.SS2" title="V-B Clients Selection ‣ V FL CHALLENGES ‣ Edge-Native Intelligence for 6G Communications Driven by Federated Learning: A Survey of Trends and Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">V-B</span></span></a>.</p>
</div>
<div id="S2.SS3.p3" class="ltx_para">
<p id="S2.SS3.p3.13" class="ltx_p">2. <span id="S2.SS3.p3.13.1" class="ltx_text ltx_font_bold">Configuration</span>: In this phase, the selected participants receive the initial model parameters and train their local models based on the local datasets. In particular, after selecting participating devices successfully, <math id="S2.SS3.p3.1.m1.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S2.SS3.p3.1.m1.1a"><mi id="S2.SS3.p3.1.m1.1.1" xref="S2.SS3.p3.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p3.1.m1.1b"><ci id="S2.SS3.p3.1.m1.1.1.cmml" xref="S2.SS3.p3.1.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p3.1.m1.1c">K</annotation></semantics></math> edge nodes are ready to begin the training process. Fig. <a href="#S2.F3" title="Figure 3 ‣ II-C FL Operation ‣ II PRELIMINARY: FL Fundamentals ‣ Edge-Native Intelligence for 6G Communications Driven by Federated Learning: A Survey of Trends and Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> illustrates the FL’s architecture and the operation steps. The device, <math id="S2.SS3.p3.2.m2.4" class="ltx_Math" alttext="k\in\{1,2,...,K\}" display="inline"><semantics id="S2.SS3.p3.2.m2.4a"><mrow id="S2.SS3.p3.2.m2.4.5" xref="S2.SS3.p3.2.m2.4.5.cmml"><mi id="S2.SS3.p3.2.m2.4.5.2" xref="S2.SS3.p3.2.m2.4.5.2.cmml">k</mi><mo id="S2.SS3.p3.2.m2.4.5.1" xref="S2.SS3.p3.2.m2.4.5.1.cmml">∈</mo><mrow id="S2.SS3.p3.2.m2.4.5.3.2" xref="S2.SS3.p3.2.m2.4.5.3.1.cmml"><mo stretchy="false" id="S2.SS3.p3.2.m2.4.5.3.2.1" xref="S2.SS3.p3.2.m2.4.5.3.1.cmml">{</mo><mn id="S2.SS3.p3.2.m2.1.1" xref="S2.SS3.p3.2.m2.1.1.cmml">1</mn><mo id="S2.SS3.p3.2.m2.4.5.3.2.2" xref="S2.SS3.p3.2.m2.4.5.3.1.cmml">,</mo><mn id="S2.SS3.p3.2.m2.2.2" xref="S2.SS3.p3.2.m2.2.2.cmml">2</mn><mo id="S2.SS3.p3.2.m2.4.5.3.2.3" xref="S2.SS3.p3.2.m2.4.5.3.1.cmml">,</mo><mi mathvariant="normal" id="S2.SS3.p3.2.m2.3.3" xref="S2.SS3.p3.2.m2.3.3.cmml">…</mi><mo id="S2.SS3.p3.2.m2.4.5.3.2.4" xref="S2.SS3.p3.2.m2.4.5.3.1.cmml">,</mo><mi id="S2.SS3.p3.2.m2.4.4" xref="S2.SS3.p3.2.m2.4.4.cmml">K</mi><mo stretchy="false" id="S2.SS3.p3.2.m2.4.5.3.2.5" xref="S2.SS3.p3.2.m2.4.5.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p3.2.m2.4b"><apply id="S2.SS3.p3.2.m2.4.5.cmml" xref="S2.SS3.p3.2.m2.4.5"><in id="S2.SS3.p3.2.m2.4.5.1.cmml" xref="S2.SS3.p3.2.m2.4.5.1"></in><ci id="S2.SS3.p3.2.m2.4.5.2.cmml" xref="S2.SS3.p3.2.m2.4.5.2">𝑘</ci><set id="S2.SS3.p3.2.m2.4.5.3.1.cmml" xref="S2.SS3.p3.2.m2.4.5.3.2"><cn type="integer" id="S2.SS3.p3.2.m2.1.1.cmml" xref="S2.SS3.p3.2.m2.1.1">1</cn><cn type="integer" id="S2.SS3.p3.2.m2.2.2.cmml" xref="S2.SS3.p3.2.m2.2.2">2</cn><ci id="S2.SS3.p3.2.m2.3.3.cmml" xref="S2.SS3.p3.2.m2.3.3">…</ci><ci id="S2.SS3.p3.2.m2.4.4.cmml" xref="S2.SS3.p3.2.m2.4.4">𝐾</ci></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p3.2.m2.4c">k\in\{1,2,...,K\}</annotation></semantics></math>, has a local dataset, <math id="S2.SS3.p3.3.m3.4" class="ltx_Math" alttext="D_{k}\in\{D_{1},D_{2},...,D_{K}\}" display="inline"><semantics id="S2.SS3.p3.3.m3.4a"><mrow id="S2.SS3.p3.3.m3.4.4" xref="S2.SS3.p3.3.m3.4.4.cmml"><msub id="S2.SS3.p3.3.m3.4.4.5" xref="S2.SS3.p3.3.m3.4.4.5.cmml"><mi id="S2.SS3.p3.3.m3.4.4.5.2" xref="S2.SS3.p3.3.m3.4.4.5.2.cmml">D</mi><mi id="S2.SS3.p3.3.m3.4.4.5.3" xref="S2.SS3.p3.3.m3.4.4.5.3.cmml">k</mi></msub><mo id="S2.SS3.p3.3.m3.4.4.4" xref="S2.SS3.p3.3.m3.4.4.4.cmml">∈</mo><mrow id="S2.SS3.p3.3.m3.4.4.3.3" xref="S2.SS3.p3.3.m3.4.4.3.4.cmml"><mo stretchy="false" id="S2.SS3.p3.3.m3.4.4.3.3.4" xref="S2.SS3.p3.3.m3.4.4.3.4.cmml">{</mo><msub id="S2.SS3.p3.3.m3.2.2.1.1.1" xref="S2.SS3.p3.3.m3.2.2.1.1.1.cmml"><mi id="S2.SS3.p3.3.m3.2.2.1.1.1.2" xref="S2.SS3.p3.3.m3.2.2.1.1.1.2.cmml">D</mi><mn id="S2.SS3.p3.3.m3.2.2.1.1.1.3" xref="S2.SS3.p3.3.m3.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S2.SS3.p3.3.m3.4.4.3.3.5" xref="S2.SS3.p3.3.m3.4.4.3.4.cmml">,</mo><msub id="S2.SS3.p3.3.m3.3.3.2.2.2" xref="S2.SS3.p3.3.m3.3.3.2.2.2.cmml"><mi id="S2.SS3.p3.3.m3.3.3.2.2.2.2" xref="S2.SS3.p3.3.m3.3.3.2.2.2.2.cmml">D</mi><mn id="S2.SS3.p3.3.m3.3.3.2.2.2.3" xref="S2.SS3.p3.3.m3.3.3.2.2.2.3.cmml">2</mn></msub><mo id="S2.SS3.p3.3.m3.4.4.3.3.6" xref="S2.SS3.p3.3.m3.4.4.3.4.cmml">,</mo><mi mathvariant="normal" id="S2.SS3.p3.3.m3.1.1" xref="S2.SS3.p3.3.m3.1.1.cmml">…</mi><mo id="S2.SS3.p3.3.m3.4.4.3.3.7" xref="S2.SS3.p3.3.m3.4.4.3.4.cmml">,</mo><msub id="S2.SS3.p3.3.m3.4.4.3.3.3" xref="S2.SS3.p3.3.m3.4.4.3.3.3.cmml"><mi id="S2.SS3.p3.3.m3.4.4.3.3.3.2" xref="S2.SS3.p3.3.m3.4.4.3.3.3.2.cmml">D</mi><mi id="S2.SS3.p3.3.m3.4.4.3.3.3.3" xref="S2.SS3.p3.3.m3.4.4.3.3.3.3.cmml">K</mi></msub><mo stretchy="false" id="S2.SS3.p3.3.m3.4.4.3.3.8" xref="S2.SS3.p3.3.m3.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p3.3.m3.4b"><apply id="S2.SS3.p3.3.m3.4.4.cmml" xref="S2.SS3.p3.3.m3.4.4"><in id="S2.SS3.p3.3.m3.4.4.4.cmml" xref="S2.SS3.p3.3.m3.4.4.4"></in><apply id="S2.SS3.p3.3.m3.4.4.5.cmml" xref="S2.SS3.p3.3.m3.4.4.5"><csymbol cd="ambiguous" id="S2.SS3.p3.3.m3.4.4.5.1.cmml" xref="S2.SS3.p3.3.m3.4.4.5">subscript</csymbol><ci id="S2.SS3.p3.3.m3.4.4.5.2.cmml" xref="S2.SS3.p3.3.m3.4.4.5.2">𝐷</ci><ci id="S2.SS3.p3.3.m3.4.4.5.3.cmml" xref="S2.SS3.p3.3.m3.4.4.5.3">𝑘</ci></apply><set id="S2.SS3.p3.3.m3.4.4.3.4.cmml" xref="S2.SS3.p3.3.m3.4.4.3.3"><apply id="S2.SS3.p3.3.m3.2.2.1.1.1.cmml" xref="S2.SS3.p3.3.m3.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.SS3.p3.3.m3.2.2.1.1.1.1.cmml" xref="S2.SS3.p3.3.m3.2.2.1.1.1">subscript</csymbol><ci id="S2.SS3.p3.3.m3.2.2.1.1.1.2.cmml" xref="S2.SS3.p3.3.m3.2.2.1.1.1.2">𝐷</ci><cn type="integer" id="S2.SS3.p3.3.m3.2.2.1.1.1.3.cmml" xref="S2.SS3.p3.3.m3.2.2.1.1.1.3">1</cn></apply><apply id="S2.SS3.p3.3.m3.3.3.2.2.2.cmml" xref="S2.SS3.p3.3.m3.3.3.2.2.2"><csymbol cd="ambiguous" id="S2.SS3.p3.3.m3.3.3.2.2.2.1.cmml" xref="S2.SS3.p3.3.m3.3.3.2.2.2">subscript</csymbol><ci id="S2.SS3.p3.3.m3.3.3.2.2.2.2.cmml" xref="S2.SS3.p3.3.m3.3.3.2.2.2.2">𝐷</ci><cn type="integer" id="S2.SS3.p3.3.m3.3.3.2.2.2.3.cmml" xref="S2.SS3.p3.3.m3.3.3.2.2.2.3">2</cn></apply><ci id="S2.SS3.p3.3.m3.1.1.cmml" xref="S2.SS3.p3.3.m3.1.1">…</ci><apply id="S2.SS3.p3.3.m3.4.4.3.3.3.cmml" xref="S2.SS3.p3.3.m3.4.4.3.3.3"><csymbol cd="ambiguous" id="S2.SS3.p3.3.m3.4.4.3.3.3.1.cmml" xref="S2.SS3.p3.3.m3.4.4.3.3.3">subscript</csymbol><ci id="S2.SS3.p3.3.m3.4.4.3.3.3.2.cmml" xref="S2.SS3.p3.3.m3.4.4.3.3.3.2">𝐷</ci><ci id="S2.SS3.p3.3.m3.4.4.3.3.3.3.cmml" xref="S2.SS3.p3.3.m3.4.4.3.3.3.3">𝐾</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p3.3.m3.4c">D_{k}\in\{D_{1},D_{2},...,D_{K}\}</annotation></semantics></math>, which includes input-output pairs of samples <math id="S2.SS3.p3.4.m4.3" class="ltx_Math" alttext="\left(x_{i},y_{i}\right),x_{i},y_{i}\in\mathbb{R}" display="inline"><semantics id="S2.SS3.p3.4.m4.3a"><mrow id="S2.SS3.p3.4.m4.3.3" xref="S2.SS3.p3.4.m4.3.3.cmml"><mrow id="S2.SS3.p3.4.m4.3.3.3.3" xref="S2.SS3.p3.4.m4.3.3.3.4.cmml"><mrow id="S2.SS3.p3.4.m4.1.1.1.1.1.2" xref="S2.SS3.p3.4.m4.1.1.1.1.1.3.cmml"><mo id="S2.SS3.p3.4.m4.1.1.1.1.1.2.3" xref="S2.SS3.p3.4.m4.1.1.1.1.1.3.cmml">(</mo><msub id="S2.SS3.p3.4.m4.1.1.1.1.1.1.1" xref="S2.SS3.p3.4.m4.1.1.1.1.1.1.1.cmml"><mi id="S2.SS3.p3.4.m4.1.1.1.1.1.1.1.2" xref="S2.SS3.p3.4.m4.1.1.1.1.1.1.1.2.cmml">x</mi><mi id="S2.SS3.p3.4.m4.1.1.1.1.1.1.1.3" xref="S2.SS3.p3.4.m4.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S2.SS3.p3.4.m4.1.1.1.1.1.2.4" xref="S2.SS3.p3.4.m4.1.1.1.1.1.3.cmml">,</mo><msub id="S2.SS3.p3.4.m4.1.1.1.1.1.2.2" xref="S2.SS3.p3.4.m4.1.1.1.1.1.2.2.cmml"><mi id="S2.SS3.p3.4.m4.1.1.1.1.1.2.2.2" xref="S2.SS3.p3.4.m4.1.1.1.1.1.2.2.2.cmml">y</mi><mi id="S2.SS3.p3.4.m4.1.1.1.1.1.2.2.3" xref="S2.SS3.p3.4.m4.1.1.1.1.1.2.2.3.cmml">i</mi></msub><mo id="S2.SS3.p3.4.m4.1.1.1.1.1.2.5" xref="S2.SS3.p3.4.m4.1.1.1.1.1.3.cmml">)</mo></mrow><mo id="S2.SS3.p3.4.m4.3.3.3.3.4" xref="S2.SS3.p3.4.m4.3.3.3.4.cmml">,</mo><msub id="S2.SS3.p3.4.m4.2.2.2.2.2" xref="S2.SS3.p3.4.m4.2.2.2.2.2.cmml"><mi id="S2.SS3.p3.4.m4.2.2.2.2.2.2" xref="S2.SS3.p3.4.m4.2.2.2.2.2.2.cmml">x</mi><mi id="S2.SS3.p3.4.m4.2.2.2.2.2.3" xref="S2.SS3.p3.4.m4.2.2.2.2.2.3.cmml">i</mi></msub><mo id="S2.SS3.p3.4.m4.3.3.3.3.5" xref="S2.SS3.p3.4.m4.3.3.3.4.cmml">,</mo><msub id="S2.SS3.p3.4.m4.3.3.3.3.3" xref="S2.SS3.p3.4.m4.3.3.3.3.3.cmml"><mi id="S2.SS3.p3.4.m4.3.3.3.3.3.2" xref="S2.SS3.p3.4.m4.3.3.3.3.3.2.cmml">y</mi><mi id="S2.SS3.p3.4.m4.3.3.3.3.3.3" xref="S2.SS3.p3.4.m4.3.3.3.3.3.3.cmml">i</mi></msub></mrow><mo id="S2.SS3.p3.4.m4.3.3.4" xref="S2.SS3.p3.4.m4.3.3.4.cmml">∈</mo><mi id="S2.SS3.p3.4.m4.3.3.5" xref="S2.SS3.p3.4.m4.3.3.5.cmml">ℝ</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p3.4.m4.3b"><apply id="S2.SS3.p3.4.m4.3.3.cmml" xref="S2.SS3.p3.4.m4.3.3"><in id="S2.SS3.p3.4.m4.3.3.4.cmml" xref="S2.SS3.p3.4.m4.3.3.4"></in><list id="S2.SS3.p3.4.m4.3.3.3.4.cmml" xref="S2.SS3.p3.4.m4.3.3.3.3"><interval closure="open" id="S2.SS3.p3.4.m4.1.1.1.1.1.3.cmml" xref="S2.SS3.p3.4.m4.1.1.1.1.1.2"><apply id="S2.SS3.p3.4.m4.1.1.1.1.1.1.1.cmml" xref="S2.SS3.p3.4.m4.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS3.p3.4.m4.1.1.1.1.1.1.1.1.cmml" xref="S2.SS3.p3.4.m4.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.SS3.p3.4.m4.1.1.1.1.1.1.1.2.cmml" xref="S2.SS3.p3.4.m4.1.1.1.1.1.1.1.2">𝑥</ci><ci id="S2.SS3.p3.4.m4.1.1.1.1.1.1.1.3.cmml" xref="S2.SS3.p3.4.m4.1.1.1.1.1.1.1.3">𝑖</ci></apply><apply id="S2.SS3.p3.4.m4.1.1.1.1.1.2.2.cmml" xref="S2.SS3.p3.4.m4.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S2.SS3.p3.4.m4.1.1.1.1.1.2.2.1.cmml" xref="S2.SS3.p3.4.m4.1.1.1.1.1.2.2">subscript</csymbol><ci id="S2.SS3.p3.4.m4.1.1.1.1.1.2.2.2.cmml" xref="S2.SS3.p3.4.m4.1.1.1.1.1.2.2.2">𝑦</ci><ci id="S2.SS3.p3.4.m4.1.1.1.1.1.2.2.3.cmml" xref="S2.SS3.p3.4.m4.1.1.1.1.1.2.2.3">𝑖</ci></apply></interval><apply id="S2.SS3.p3.4.m4.2.2.2.2.2.cmml" xref="S2.SS3.p3.4.m4.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.SS3.p3.4.m4.2.2.2.2.2.1.cmml" xref="S2.SS3.p3.4.m4.2.2.2.2.2">subscript</csymbol><ci id="S2.SS3.p3.4.m4.2.2.2.2.2.2.cmml" xref="S2.SS3.p3.4.m4.2.2.2.2.2.2">𝑥</ci><ci id="S2.SS3.p3.4.m4.2.2.2.2.2.3.cmml" xref="S2.SS3.p3.4.m4.2.2.2.2.2.3">𝑖</ci></apply><apply id="S2.SS3.p3.4.m4.3.3.3.3.3.cmml" xref="S2.SS3.p3.4.m4.3.3.3.3.3"><csymbol cd="ambiguous" id="S2.SS3.p3.4.m4.3.3.3.3.3.1.cmml" xref="S2.SS3.p3.4.m4.3.3.3.3.3">subscript</csymbol><ci id="S2.SS3.p3.4.m4.3.3.3.3.3.2.cmml" xref="S2.SS3.p3.4.m4.3.3.3.3.3.2">𝑦</ci><ci id="S2.SS3.p3.4.m4.3.3.3.3.3.3.cmml" xref="S2.SS3.p3.4.m4.3.3.3.3.3.3">𝑖</ci></apply></list><ci id="S2.SS3.p3.4.m4.3.3.5.cmml" xref="S2.SS3.p3.4.m4.3.3.5">ℝ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p3.4.m4.3c">\left(x_{i},y_{i}\right),x_{i},y_{i}\in\mathbb{R}</annotation></semantics></math>. In step <span id="S2.SS3.p3.13.2" class="ltx_text" style="font-size:120%;">\small1⃝</span>, the FL server initiates the global model created to perform a specific task and shares it with the selected participants. Next, at the <math id="S2.SS3.p3.5.m5.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S2.SS3.p3.5.m5.1a"><mi id="S2.SS3.p3.5.m5.1.1" xref="S2.SS3.p3.5.m5.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p3.5.m5.1b"><ci id="S2.SS3.p3.5.m5.1.1.cmml" xref="S2.SS3.p3.5.m5.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p3.5.m5.1c">t</annotation></semantics></math>-th iteration, each participating node acquires the model weights <math id="S2.SS3.p3.6.m6.1" class="ltx_Math" alttext="W_{t-1}" display="inline"><semantics id="S2.SS3.p3.6.m6.1a"><msub id="S2.SS3.p3.6.m6.1.1" xref="S2.SS3.p3.6.m6.1.1.cmml"><mi id="S2.SS3.p3.6.m6.1.1.2" xref="S2.SS3.p3.6.m6.1.1.2.cmml">W</mi><mrow id="S2.SS3.p3.6.m6.1.1.3" xref="S2.SS3.p3.6.m6.1.1.3.cmml"><mi id="S2.SS3.p3.6.m6.1.1.3.2" xref="S2.SS3.p3.6.m6.1.1.3.2.cmml">t</mi><mo id="S2.SS3.p3.6.m6.1.1.3.1" xref="S2.SS3.p3.6.m6.1.1.3.1.cmml">−</mo><mn id="S2.SS3.p3.6.m6.1.1.3.3" xref="S2.SS3.p3.6.m6.1.1.3.3.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS3.p3.6.m6.1b"><apply id="S2.SS3.p3.6.m6.1.1.cmml" xref="S2.SS3.p3.6.m6.1.1"><csymbol cd="ambiguous" id="S2.SS3.p3.6.m6.1.1.1.cmml" xref="S2.SS3.p3.6.m6.1.1">subscript</csymbol><ci id="S2.SS3.p3.6.m6.1.1.2.cmml" xref="S2.SS3.p3.6.m6.1.1.2">𝑊</ci><apply id="S2.SS3.p3.6.m6.1.1.3.cmml" xref="S2.SS3.p3.6.m6.1.1.3"><minus id="S2.SS3.p3.6.m6.1.1.3.1.cmml" xref="S2.SS3.p3.6.m6.1.1.3.1"></minus><ci id="S2.SS3.p3.6.m6.1.1.3.2.cmml" xref="S2.SS3.p3.6.m6.1.1.3.2">𝑡</ci><cn type="integer" id="S2.SS3.p3.6.m6.1.1.3.3.cmml" xref="S2.SS3.p3.6.m6.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p3.6.m6.1c">W_{t-1}</annotation></semantics></math> and begins the model training by exploiting the data samples on their local storage. The objective of model training is to minimise the loss function <math id="S2.SS3.p3.7.m7.1" class="ltx_Math" alttext="F_{k}(W_{t}^{k})" display="inline"><semantics id="S2.SS3.p3.7.m7.1a"><mrow id="S2.SS3.p3.7.m7.1.1" xref="S2.SS3.p3.7.m7.1.1.cmml"><msub id="S2.SS3.p3.7.m7.1.1.3" xref="S2.SS3.p3.7.m7.1.1.3.cmml"><mi id="S2.SS3.p3.7.m7.1.1.3.2" xref="S2.SS3.p3.7.m7.1.1.3.2.cmml">F</mi><mi id="S2.SS3.p3.7.m7.1.1.3.3" xref="S2.SS3.p3.7.m7.1.1.3.3.cmml">k</mi></msub><mo lspace="0em" rspace="0em" id="S2.SS3.p3.7.m7.1.1.2" xref="S2.SS3.p3.7.m7.1.1.2.cmml">​</mo><mrow id="S2.SS3.p3.7.m7.1.1.1.1" xref="S2.SS3.p3.7.m7.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.SS3.p3.7.m7.1.1.1.1.2" xref="S2.SS3.p3.7.m7.1.1.1.1.1.cmml">(</mo><msubsup id="S2.SS3.p3.7.m7.1.1.1.1.1" xref="S2.SS3.p3.7.m7.1.1.1.1.1.cmml"><mi id="S2.SS3.p3.7.m7.1.1.1.1.1.2.2" xref="S2.SS3.p3.7.m7.1.1.1.1.1.2.2.cmml">W</mi><mi id="S2.SS3.p3.7.m7.1.1.1.1.1.2.3" xref="S2.SS3.p3.7.m7.1.1.1.1.1.2.3.cmml">t</mi><mi id="S2.SS3.p3.7.m7.1.1.1.1.1.3" xref="S2.SS3.p3.7.m7.1.1.1.1.1.3.cmml">k</mi></msubsup><mo stretchy="false" id="S2.SS3.p3.7.m7.1.1.1.1.3" xref="S2.SS3.p3.7.m7.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p3.7.m7.1b"><apply id="S2.SS3.p3.7.m7.1.1.cmml" xref="S2.SS3.p3.7.m7.1.1"><times id="S2.SS3.p3.7.m7.1.1.2.cmml" xref="S2.SS3.p3.7.m7.1.1.2"></times><apply id="S2.SS3.p3.7.m7.1.1.3.cmml" xref="S2.SS3.p3.7.m7.1.1.3"><csymbol cd="ambiguous" id="S2.SS3.p3.7.m7.1.1.3.1.cmml" xref="S2.SS3.p3.7.m7.1.1.3">subscript</csymbol><ci id="S2.SS3.p3.7.m7.1.1.3.2.cmml" xref="S2.SS3.p3.7.m7.1.1.3.2">𝐹</ci><ci id="S2.SS3.p3.7.m7.1.1.3.3.cmml" xref="S2.SS3.p3.7.m7.1.1.3.3">𝑘</ci></apply><apply id="S2.SS3.p3.7.m7.1.1.1.1.1.cmml" xref="S2.SS3.p3.7.m7.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS3.p3.7.m7.1.1.1.1.1.1.cmml" xref="S2.SS3.p3.7.m7.1.1.1.1">superscript</csymbol><apply id="S2.SS3.p3.7.m7.1.1.1.1.1.2.cmml" xref="S2.SS3.p3.7.m7.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS3.p3.7.m7.1.1.1.1.1.2.1.cmml" xref="S2.SS3.p3.7.m7.1.1.1.1">subscript</csymbol><ci id="S2.SS3.p3.7.m7.1.1.1.1.1.2.2.cmml" xref="S2.SS3.p3.7.m7.1.1.1.1.1.2.2">𝑊</ci><ci id="S2.SS3.p3.7.m7.1.1.1.1.1.2.3.cmml" xref="S2.SS3.p3.7.m7.1.1.1.1.1.2.3">𝑡</ci></apply><ci id="S2.SS3.p3.7.m7.1.1.1.1.1.3.cmml" xref="S2.SS3.p3.7.m7.1.1.1.1.1.3">𝑘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p3.7.m7.1c">F_{k}(W_{t}^{k})</annotation></semantics></math> of all data samples in the training dataset, <math id="S2.SS3.p3.8.m8.2" class="ltx_Math" alttext="F_{k}(W_{t}^{k})=\frac{1}{D_{k}}\sum_{i\in D_{k}}f_{i}(W_{t}^{k})" display="inline"><semantics id="S2.SS3.p3.8.m8.2a"><mrow id="S2.SS3.p3.8.m8.2.2" xref="S2.SS3.p3.8.m8.2.2.cmml"><mrow id="S2.SS3.p3.8.m8.1.1.1" xref="S2.SS3.p3.8.m8.1.1.1.cmml"><msub id="S2.SS3.p3.8.m8.1.1.1.3" xref="S2.SS3.p3.8.m8.1.1.1.3.cmml"><mi id="S2.SS3.p3.8.m8.1.1.1.3.2" xref="S2.SS3.p3.8.m8.1.1.1.3.2.cmml">F</mi><mi id="S2.SS3.p3.8.m8.1.1.1.3.3" xref="S2.SS3.p3.8.m8.1.1.1.3.3.cmml">k</mi></msub><mo lspace="0em" rspace="0em" id="S2.SS3.p3.8.m8.1.1.1.2" xref="S2.SS3.p3.8.m8.1.1.1.2.cmml">​</mo><mrow id="S2.SS3.p3.8.m8.1.1.1.1.1" xref="S2.SS3.p3.8.m8.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.SS3.p3.8.m8.1.1.1.1.1.2" xref="S2.SS3.p3.8.m8.1.1.1.1.1.1.cmml">(</mo><msubsup id="S2.SS3.p3.8.m8.1.1.1.1.1.1" xref="S2.SS3.p3.8.m8.1.1.1.1.1.1.cmml"><mi id="S2.SS3.p3.8.m8.1.1.1.1.1.1.2.2" xref="S2.SS3.p3.8.m8.1.1.1.1.1.1.2.2.cmml">W</mi><mi id="S2.SS3.p3.8.m8.1.1.1.1.1.1.2.3" xref="S2.SS3.p3.8.m8.1.1.1.1.1.1.2.3.cmml">t</mi><mi id="S2.SS3.p3.8.m8.1.1.1.1.1.1.3" xref="S2.SS3.p3.8.m8.1.1.1.1.1.1.3.cmml">k</mi></msubsup><mo stretchy="false" id="S2.SS3.p3.8.m8.1.1.1.1.1.3" xref="S2.SS3.p3.8.m8.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.SS3.p3.8.m8.2.2.3" xref="S2.SS3.p3.8.m8.2.2.3.cmml">=</mo><mrow id="S2.SS3.p3.8.m8.2.2.2" xref="S2.SS3.p3.8.m8.2.2.2.cmml"><mfrac id="S2.SS3.p3.8.m8.2.2.2.3" xref="S2.SS3.p3.8.m8.2.2.2.3.cmml"><mn id="S2.SS3.p3.8.m8.2.2.2.3.2" xref="S2.SS3.p3.8.m8.2.2.2.3.2.cmml">1</mn><msub id="S2.SS3.p3.8.m8.2.2.2.3.3" xref="S2.SS3.p3.8.m8.2.2.2.3.3.cmml"><mi id="S2.SS3.p3.8.m8.2.2.2.3.3.2" xref="S2.SS3.p3.8.m8.2.2.2.3.3.2.cmml">D</mi><mi id="S2.SS3.p3.8.m8.2.2.2.3.3.3" xref="S2.SS3.p3.8.m8.2.2.2.3.3.3.cmml">k</mi></msub></mfrac><mo lspace="0em" rspace="0em" id="S2.SS3.p3.8.m8.2.2.2.2" xref="S2.SS3.p3.8.m8.2.2.2.2.cmml">​</mo><mrow id="S2.SS3.p3.8.m8.2.2.2.1" xref="S2.SS3.p3.8.m8.2.2.2.1.cmml"><msub id="S2.SS3.p3.8.m8.2.2.2.1.2" xref="S2.SS3.p3.8.m8.2.2.2.1.2.cmml"><mo id="S2.SS3.p3.8.m8.2.2.2.1.2.2" xref="S2.SS3.p3.8.m8.2.2.2.1.2.2.cmml">∑</mo><mrow id="S2.SS3.p3.8.m8.2.2.2.1.2.3" xref="S2.SS3.p3.8.m8.2.2.2.1.2.3.cmml"><mi id="S2.SS3.p3.8.m8.2.2.2.1.2.3.2" xref="S2.SS3.p3.8.m8.2.2.2.1.2.3.2.cmml">i</mi><mo id="S2.SS3.p3.8.m8.2.2.2.1.2.3.1" xref="S2.SS3.p3.8.m8.2.2.2.1.2.3.1.cmml">∈</mo><msub id="S2.SS3.p3.8.m8.2.2.2.1.2.3.3" xref="S2.SS3.p3.8.m8.2.2.2.1.2.3.3.cmml"><mi id="S2.SS3.p3.8.m8.2.2.2.1.2.3.3.2" xref="S2.SS3.p3.8.m8.2.2.2.1.2.3.3.2.cmml">D</mi><mi id="S2.SS3.p3.8.m8.2.2.2.1.2.3.3.3" xref="S2.SS3.p3.8.m8.2.2.2.1.2.3.3.3.cmml">k</mi></msub></mrow></msub><mrow id="S2.SS3.p3.8.m8.2.2.2.1.1" xref="S2.SS3.p3.8.m8.2.2.2.1.1.cmml"><msub id="S2.SS3.p3.8.m8.2.2.2.1.1.3" xref="S2.SS3.p3.8.m8.2.2.2.1.1.3.cmml"><mi id="S2.SS3.p3.8.m8.2.2.2.1.1.3.2" xref="S2.SS3.p3.8.m8.2.2.2.1.1.3.2.cmml">f</mi><mi id="S2.SS3.p3.8.m8.2.2.2.1.1.3.3" xref="S2.SS3.p3.8.m8.2.2.2.1.1.3.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S2.SS3.p3.8.m8.2.2.2.1.1.2" xref="S2.SS3.p3.8.m8.2.2.2.1.1.2.cmml">​</mo><mrow id="S2.SS3.p3.8.m8.2.2.2.1.1.1.1" xref="S2.SS3.p3.8.m8.2.2.2.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.SS3.p3.8.m8.2.2.2.1.1.1.1.2" xref="S2.SS3.p3.8.m8.2.2.2.1.1.1.1.1.cmml">(</mo><msubsup id="S2.SS3.p3.8.m8.2.2.2.1.1.1.1.1" xref="S2.SS3.p3.8.m8.2.2.2.1.1.1.1.1.cmml"><mi id="S2.SS3.p3.8.m8.2.2.2.1.1.1.1.1.2.2" xref="S2.SS3.p3.8.m8.2.2.2.1.1.1.1.1.2.2.cmml">W</mi><mi id="S2.SS3.p3.8.m8.2.2.2.1.1.1.1.1.2.3" xref="S2.SS3.p3.8.m8.2.2.2.1.1.1.1.1.2.3.cmml">t</mi><mi id="S2.SS3.p3.8.m8.2.2.2.1.1.1.1.1.3" xref="S2.SS3.p3.8.m8.2.2.2.1.1.1.1.1.3.cmml">k</mi></msubsup><mo stretchy="false" id="S2.SS3.p3.8.m8.2.2.2.1.1.1.1.3" xref="S2.SS3.p3.8.m8.2.2.2.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p3.8.m8.2b"><apply id="S2.SS3.p3.8.m8.2.2.cmml" xref="S2.SS3.p3.8.m8.2.2"><eq id="S2.SS3.p3.8.m8.2.2.3.cmml" xref="S2.SS3.p3.8.m8.2.2.3"></eq><apply id="S2.SS3.p3.8.m8.1.1.1.cmml" xref="S2.SS3.p3.8.m8.1.1.1"><times id="S2.SS3.p3.8.m8.1.1.1.2.cmml" xref="S2.SS3.p3.8.m8.1.1.1.2"></times><apply id="S2.SS3.p3.8.m8.1.1.1.3.cmml" xref="S2.SS3.p3.8.m8.1.1.1.3"><csymbol cd="ambiguous" id="S2.SS3.p3.8.m8.1.1.1.3.1.cmml" xref="S2.SS3.p3.8.m8.1.1.1.3">subscript</csymbol><ci id="S2.SS3.p3.8.m8.1.1.1.3.2.cmml" xref="S2.SS3.p3.8.m8.1.1.1.3.2">𝐹</ci><ci id="S2.SS3.p3.8.m8.1.1.1.3.3.cmml" xref="S2.SS3.p3.8.m8.1.1.1.3.3">𝑘</ci></apply><apply id="S2.SS3.p3.8.m8.1.1.1.1.1.1.cmml" xref="S2.SS3.p3.8.m8.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS3.p3.8.m8.1.1.1.1.1.1.1.cmml" xref="S2.SS3.p3.8.m8.1.1.1.1.1">superscript</csymbol><apply id="S2.SS3.p3.8.m8.1.1.1.1.1.1.2.cmml" xref="S2.SS3.p3.8.m8.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS3.p3.8.m8.1.1.1.1.1.1.2.1.cmml" xref="S2.SS3.p3.8.m8.1.1.1.1.1">subscript</csymbol><ci id="S2.SS3.p3.8.m8.1.1.1.1.1.1.2.2.cmml" xref="S2.SS3.p3.8.m8.1.1.1.1.1.1.2.2">𝑊</ci><ci id="S2.SS3.p3.8.m8.1.1.1.1.1.1.2.3.cmml" xref="S2.SS3.p3.8.m8.1.1.1.1.1.1.2.3">𝑡</ci></apply><ci id="S2.SS3.p3.8.m8.1.1.1.1.1.1.3.cmml" xref="S2.SS3.p3.8.m8.1.1.1.1.1.1.3">𝑘</ci></apply></apply><apply id="S2.SS3.p3.8.m8.2.2.2.cmml" xref="S2.SS3.p3.8.m8.2.2.2"><times id="S2.SS3.p3.8.m8.2.2.2.2.cmml" xref="S2.SS3.p3.8.m8.2.2.2.2"></times><apply id="S2.SS3.p3.8.m8.2.2.2.3.cmml" xref="S2.SS3.p3.8.m8.2.2.2.3"><divide id="S2.SS3.p3.8.m8.2.2.2.3.1.cmml" xref="S2.SS3.p3.8.m8.2.2.2.3"></divide><cn type="integer" id="S2.SS3.p3.8.m8.2.2.2.3.2.cmml" xref="S2.SS3.p3.8.m8.2.2.2.3.2">1</cn><apply id="S2.SS3.p3.8.m8.2.2.2.3.3.cmml" xref="S2.SS3.p3.8.m8.2.2.2.3.3"><csymbol cd="ambiguous" id="S2.SS3.p3.8.m8.2.2.2.3.3.1.cmml" xref="S2.SS3.p3.8.m8.2.2.2.3.3">subscript</csymbol><ci id="S2.SS3.p3.8.m8.2.2.2.3.3.2.cmml" xref="S2.SS3.p3.8.m8.2.2.2.3.3.2">𝐷</ci><ci id="S2.SS3.p3.8.m8.2.2.2.3.3.3.cmml" xref="S2.SS3.p3.8.m8.2.2.2.3.3.3">𝑘</ci></apply></apply><apply id="S2.SS3.p3.8.m8.2.2.2.1.cmml" xref="S2.SS3.p3.8.m8.2.2.2.1"><apply id="S2.SS3.p3.8.m8.2.2.2.1.2.cmml" xref="S2.SS3.p3.8.m8.2.2.2.1.2"><csymbol cd="ambiguous" id="S2.SS3.p3.8.m8.2.2.2.1.2.1.cmml" xref="S2.SS3.p3.8.m8.2.2.2.1.2">subscript</csymbol><sum id="S2.SS3.p3.8.m8.2.2.2.1.2.2.cmml" xref="S2.SS3.p3.8.m8.2.2.2.1.2.2"></sum><apply id="S2.SS3.p3.8.m8.2.2.2.1.2.3.cmml" xref="S2.SS3.p3.8.m8.2.2.2.1.2.3"><in id="S2.SS3.p3.8.m8.2.2.2.1.2.3.1.cmml" xref="S2.SS3.p3.8.m8.2.2.2.1.2.3.1"></in><ci id="S2.SS3.p3.8.m8.2.2.2.1.2.3.2.cmml" xref="S2.SS3.p3.8.m8.2.2.2.1.2.3.2">𝑖</ci><apply id="S2.SS3.p3.8.m8.2.2.2.1.2.3.3.cmml" xref="S2.SS3.p3.8.m8.2.2.2.1.2.3.3"><csymbol cd="ambiguous" id="S2.SS3.p3.8.m8.2.2.2.1.2.3.3.1.cmml" xref="S2.SS3.p3.8.m8.2.2.2.1.2.3.3">subscript</csymbol><ci id="S2.SS3.p3.8.m8.2.2.2.1.2.3.3.2.cmml" xref="S2.SS3.p3.8.m8.2.2.2.1.2.3.3.2">𝐷</ci><ci id="S2.SS3.p3.8.m8.2.2.2.1.2.3.3.3.cmml" xref="S2.SS3.p3.8.m8.2.2.2.1.2.3.3.3">𝑘</ci></apply></apply></apply><apply id="S2.SS3.p3.8.m8.2.2.2.1.1.cmml" xref="S2.SS3.p3.8.m8.2.2.2.1.1"><times id="S2.SS3.p3.8.m8.2.2.2.1.1.2.cmml" xref="S2.SS3.p3.8.m8.2.2.2.1.1.2"></times><apply id="S2.SS3.p3.8.m8.2.2.2.1.1.3.cmml" xref="S2.SS3.p3.8.m8.2.2.2.1.1.3"><csymbol cd="ambiguous" id="S2.SS3.p3.8.m8.2.2.2.1.1.3.1.cmml" xref="S2.SS3.p3.8.m8.2.2.2.1.1.3">subscript</csymbol><ci id="S2.SS3.p3.8.m8.2.2.2.1.1.3.2.cmml" xref="S2.SS3.p3.8.m8.2.2.2.1.1.3.2">𝑓</ci><ci id="S2.SS3.p3.8.m8.2.2.2.1.1.3.3.cmml" xref="S2.SS3.p3.8.m8.2.2.2.1.1.3.3">𝑖</ci></apply><apply id="S2.SS3.p3.8.m8.2.2.2.1.1.1.1.1.cmml" xref="S2.SS3.p3.8.m8.2.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS3.p3.8.m8.2.2.2.1.1.1.1.1.1.cmml" xref="S2.SS3.p3.8.m8.2.2.2.1.1.1.1">superscript</csymbol><apply id="S2.SS3.p3.8.m8.2.2.2.1.1.1.1.1.2.cmml" xref="S2.SS3.p3.8.m8.2.2.2.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS3.p3.8.m8.2.2.2.1.1.1.1.1.2.1.cmml" xref="S2.SS3.p3.8.m8.2.2.2.1.1.1.1">subscript</csymbol><ci id="S2.SS3.p3.8.m8.2.2.2.1.1.1.1.1.2.2.cmml" xref="S2.SS3.p3.8.m8.2.2.2.1.1.1.1.1.2.2">𝑊</ci><ci id="S2.SS3.p3.8.m8.2.2.2.1.1.1.1.1.2.3.cmml" xref="S2.SS3.p3.8.m8.2.2.2.1.1.1.1.1.2.3">𝑡</ci></apply><ci id="S2.SS3.p3.8.m8.2.2.2.1.1.1.1.1.3.cmml" xref="S2.SS3.p3.8.m8.2.2.2.1.1.1.1.1.3">𝑘</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p3.8.m8.2c">F_{k}(W_{t}^{k})=\frac{1}{D_{k}}\sum_{i\in D_{k}}f_{i}(W_{t}^{k})</annotation></semantics></math>, i.e., obtaining the optimum model parameters <math id="S2.SS3.p3.9.m9.1" class="ltx_Math" alttext="W_{t}^{k}" display="inline"><semantics id="S2.SS3.p3.9.m9.1a"><msubsup id="S2.SS3.p3.9.m9.1.1" xref="S2.SS3.p3.9.m9.1.1.cmml"><mi id="S2.SS3.p3.9.m9.1.1.2.2" xref="S2.SS3.p3.9.m9.1.1.2.2.cmml">W</mi><mi id="S2.SS3.p3.9.m9.1.1.2.3" xref="S2.SS3.p3.9.m9.1.1.2.3.cmml">t</mi><mi id="S2.SS3.p3.9.m9.1.1.3" xref="S2.SS3.p3.9.m9.1.1.3.cmml">k</mi></msubsup><annotation-xml encoding="MathML-Content" id="S2.SS3.p3.9.m9.1b"><apply id="S2.SS3.p3.9.m9.1.1.cmml" xref="S2.SS3.p3.9.m9.1.1"><csymbol cd="ambiguous" id="S2.SS3.p3.9.m9.1.1.1.cmml" xref="S2.SS3.p3.9.m9.1.1">superscript</csymbol><apply id="S2.SS3.p3.9.m9.1.1.2.cmml" xref="S2.SS3.p3.9.m9.1.1"><csymbol cd="ambiguous" id="S2.SS3.p3.9.m9.1.1.2.1.cmml" xref="S2.SS3.p3.9.m9.1.1">subscript</csymbol><ci id="S2.SS3.p3.9.m9.1.1.2.2.cmml" xref="S2.SS3.p3.9.m9.1.1.2.2">𝑊</ci><ci id="S2.SS3.p3.9.m9.1.1.2.3.cmml" xref="S2.SS3.p3.9.m9.1.1.2.3">𝑡</ci></apply><ci id="S2.SS3.p3.9.m9.1.1.3.cmml" xref="S2.SS3.p3.9.m9.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p3.9.m9.1c">W_{t}^{k}</annotation></semantics></math> that minimise the loss function at each round of training which can be represented mathematically as, <math id="S2.SS3.p3.10.m10.1" class="ltx_Math" alttext="\arg\min_{W_{t}^{k}\in\mathbb{R}}F_{k}(W_{t}^{k})" display="inline"><semantics id="S2.SS3.p3.10.m10.1a"><mrow id="S2.SS3.p3.10.m10.1.1" xref="S2.SS3.p3.10.m10.1.1.cmml"><mrow id="S2.SS3.p3.10.m10.1.1.3" xref="S2.SS3.p3.10.m10.1.1.3.cmml"><mi id="S2.SS3.p3.10.m10.1.1.3.1" xref="S2.SS3.p3.10.m10.1.1.3.1.cmml">arg</mi><mo lspace="0.167em" id="S2.SS3.p3.10.m10.1.1.3a" xref="S2.SS3.p3.10.m10.1.1.3.cmml">⁡</mo><mrow id="S2.SS3.p3.10.m10.1.1.3.2" xref="S2.SS3.p3.10.m10.1.1.3.2.cmml"><msub id="S2.SS3.p3.10.m10.1.1.3.2.1" xref="S2.SS3.p3.10.m10.1.1.3.2.1.cmml"><mi id="S2.SS3.p3.10.m10.1.1.3.2.1.2" xref="S2.SS3.p3.10.m10.1.1.3.2.1.2.cmml">min</mi><mrow id="S2.SS3.p3.10.m10.1.1.3.2.1.3" xref="S2.SS3.p3.10.m10.1.1.3.2.1.3.cmml"><msubsup id="S2.SS3.p3.10.m10.1.1.3.2.1.3.2" xref="S2.SS3.p3.10.m10.1.1.3.2.1.3.2.cmml"><mi id="S2.SS3.p3.10.m10.1.1.3.2.1.3.2.2.2" xref="S2.SS3.p3.10.m10.1.1.3.2.1.3.2.2.2.cmml">W</mi><mi id="S2.SS3.p3.10.m10.1.1.3.2.1.3.2.2.3" xref="S2.SS3.p3.10.m10.1.1.3.2.1.3.2.2.3.cmml">t</mi><mi id="S2.SS3.p3.10.m10.1.1.3.2.1.3.2.3" xref="S2.SS3.p3.10.m10.1.1.3.2.1.3.2.3.cmml">k</mi></msubsup><mo id="S2.SS3.p3.10.m10.1.1.3.2.1.3.1" xref="S2.SS3.p3.10.m10.1.1.3.2.1.3.1.cmml">∈</mo><mi id="S2.SS3.p3.10.m10.1.1.3.2.1.3.3" xref="S2.SS3.p3.10.m10.1.1.3.2.1.3.3.cmml">ℝ</mi></mrow></msub><mo lspace="0.167em" id="S2.SS3.p3.10.m10.1.1.3.2a" xref="S2.SS3.p3.10.m10.1.1.3.2.cmml">⁡</mo><msub id="S2.SS3.p3.10.m10.1.1.3.2.2" xref="S2.SS3.p3.10.m10.1.1.3.2.2.cmml"><mi id="S2.SS3.p3.10.m10.1.1.3.2.2.2" xref="S2.SS3.p3.10.m10.1.1.3.2.2.2.cmml">F</mi><mi id="S2.SS3.p3.10.m10.1.1.3.2.2.3" xref="S2.SS3.p3.10.m10.1.1.3.2.2.3.cmml">k</mi></msub></mrow></mrow><mo lspace="0em" rspace="0em" id="S2.SS3.p3.10.m10.1.1.2" xref="S2.SS3.p3.10.m10.1.1.2.cmml">​</mo><mrow id="S2.SS3.p3.10.m10.1.1.1.1" xref="S2.SS3.p3.10.m10.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.SS3.p3.10.m10.1.1.1.1.2" xref="S2.SS3.p3.10.m10.1.1.1.1.1.cmml">(</mo><msubsup id="S2.SS3.p3.10.m10.1.1.1.1.1" xref="S2.SS3.p3.10.m10.1.1.1.1.1.cmml"><mi id="S2.SS3.p3.10.m10.1.1.1.1.1.2.2" xref="S2.SS3.p3.10.m10.1.1.1.1.1.2.2.cmml">W</mi><mi id="S2.SS3.p3.10.m10.1.1.1.1.1.2.3" xref="S2.SS3.p3.10.m10.1.1.1.1.1.2.3.cmml">t</mi><mi id="S2.SS3.p3.10.m10.1.1.1.1.1.3" xref="S2.SS3.p3.10.m10.1.1.1.1.1.3.cmml">k</mi></msubsup><mo stretchy="false" id="S2.SS3.p3.10.m10.1.1.1.1.3" xref="S2.SS3.p3.10.m10.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p3.10.m10.1b"><apply id="S2.SS3.p3.10.m10.1.1.cmml" xref="S2.SS3.p3.10.m10.1.1"><times id="S2.SS3.p3.10.m10.1.1.2.cmml" xref="S2.SS3.p3.10.m10.1.1.2"></times><apply id="S2.SS3.p3.10.m10.1.1.3.cmml" xref="S2.SS3.p3.10.m10.1.1.3"><arg id="S2.SS3.p3.10.m10.1.1.3.1.cmml" xref="S2.SS3.p3.10.m10.1.1.3.1"></arg><apply id="S2.SS3.p3.10.m10.1.1.3.2.cmml" xref="S2.SS3.p3.10.m10.1.1.3.2"><apply id="S2.SS3.p3.10.m10.1.1.3.2.1.cmml" xref="S2.SS3.p3.10.m10.1.1.3.2.1"><csymbol cd="ambiguous" id="S2.SS3.p3.10.m10.1.1.3.2.1.1.cmml" xref="S2.SS3.p3.10.m10.1.1.3.2.1">subscript</csymbol><min id="S2.SS3.p3.10.m10.1.1.3.2.1.2.cmml" xref="S2.SS3.p3.10.m10.1.1.3.2.1.2"></min><apply id="S2.SS3.p3.10.m10.1.1.3.2.1.3.cmml" xref="S2.SS3.p3.10.m10.1.1.3.2.1.3"><in id="S2.SS3.p3.10.m10.1.1.3.2.1.3.1.cmml" xref="S2.SS3.p3.10.m10.1.1.3.2.1.3.1"></in><apply id="S2.SS3.p3.10.m10.1.1.3.2.1.3.2.cmml" xref="S2.SS3.p3.10.m10.1.1.3.2.1.3.2"><csymbol cd="ambiguous" id="S2.SS3.p3.10.m10.1.1.3.2.1.3.2.1.cmml" xref="S2.SS3.p3.10.m10.1.1.3.2.1.3.2">superscript</csymbol><apply id="S2.SS3.p3.10.m10.1.1.3.2.1.3.2.2.cmml" xref="S2.SS3.p3.10.m10.1.1.3.2.1.3.2"><csymbol cd="ambiguous" id="S2.SS3.p3.10.m10.1.1.3.2.1.3.2.2.1.cmml" xref="S2.SS3.p3.10.m10.1.1.3.2.1.3.2">subscript</csymbol><ci id="S2.SS3.p3.10.m10.1.1.3.2.1.3.2.2.2.cmml" xref="S2.SS3.p3.10.m10.1.1.3.2.1.3.2.2.2">𝑊</ci><ci id="S2.SS3.p3.10.m10.1.1.3.2.1.3.2.2.3.cmml" xref="S2.SS3.p3.10.m10.1.1.3.2.1.3.2.2.3">𝑡</ci></apply><ci id="S2.SS3.p3.10.m10.1.1.3.2.1.3.2.3.cmml" xref="S2.SS3.p3.10.m10.1.1.3.2.1.3.2.3">𝑘</ci></apply><ci id="S2.SS3.p3.10.m10.1.1.3.2.1.3.3.cmml" xref="S2.SS3.p3.10.m10.1.1.3.2.1.3.3">ℝ</ci></apply></apply><apply id="S2.SS3.p3.10.m10.1.1.3.2.2.cmml" xref="S2.SS3.p3.10.m10.1.1.3.2.2"><csymbol cd="ambiguous" id="S2.SS3.p3.10.m10.1.1.3.2.2.1.cmml" xref="S2.SS3.p3.10.m10.1.1.3.2.2">subscript</csymbol><ci id="S2.SS3.p3.10.m10.1.1.3.2.2.2.cmml" xref="S2.SS3.p3.10.m10.1.1.3.2.2.2">𝐹</ci><ci id="S2.SS3.p3.10.m10.1.1.3.2.2.3.cmml" xref="S2.SS3.p3.10.m10.1.1.3.2.2.3">𝑘</ci></apply></apply></apply><apply id="S2.SS3.p3.10.m10.1.1.1.1.1.cmml" xref="S2.SS3.p3.10.m10.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS3.p3.10.m10.1.1.1.1.1.1.cmml" xref="S2.SS3.p3.10.m10.1.1.1.1">superscript</csymbol><apply id="S2.SS3.p3.10.m10.1.1.1.1.1.2.cmml" xref="S2.SS3.p3.10.m10.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS3.p3.10.m10.1.1.1.1.1.2.1.cmml" xref="S2.SS3.p3.10.m10.1.1.1.1">subscript</csymbol><ci id="S2.SS3.p3.10.m10.1.1.1.1.1.2.2.cmml" xref="S2.SS3.p3.10.m10.1.1.1.1.1.2.2">𝑊</ci><ci id="S2.SS3.p3.10.m10.1.1.1.1.1.2.3.cmml" xref="S2.SS3.p3.10.m10.1.1.1.1.1.2.3">𝑡</ci></apply><ci id="S2.SS3.p3.10.m10.1.1.1.1.1.3.cmml" xref="S2.SS3.p3.10.m10.1.1.1.1.1.3">𝑘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p3.10.m10.1c">\arg\min_{W_{t}^{k}\in\mathbb{R}}F_{k}(W_{t}^{k})</annotation></semantics></math>. Where <math id="S2.SS3.p3.11.m11.1" class="ltx_Math" alttext="f_{i}(W_{t}^{k})" display="inline"><semantics id="S2.SS3.p3.11.m11.1a"><mrow id="S2.SS3.p3.11.m11.1.1" xref="S2.SS3.p3.11.m11.1.1.cmml"><msub id="S2.SS3.p3.11.m11.1.1.3" xref="S2.SS3.p3.11.m11.1.1.3.cmml"><mi id="S2.SS3.p3.11.m11.1.1.3.2" xref="S2.SS3.p3.11.m11.1.1.3.2.cmml">f</mi><mi id="S2.SS3.p3.11.m11.1.1.3.3" xref="S2.SS3.p3.11.m11.1.1.3.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S2.SS3.p3.11.m11.1.1.2" xref="S2.SS3.p3.11.m11.1.1.2.cmml">​</mo><mrow id="S2.SS3.p3.11.m11.1.1.1.1" xref="S2.SS3.p3.11.m11.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.SS3.p3.11.m11.1.1.1.1.2" xref="S2.SS3.p3.11.m11.1.1.1.1.1.cmml">(</mo><msubsup id="S2.SS3.p3.11.m11.1.1.1.1.1" xref="S2.SS3.p3.11.m11.1.1.1.1.1.cmml"><mi id="S2.SS3.p3.11.m11.1.1.1.1.1.2.2" xref="S2.SS3.p3.11.m11.1.1.1.1.1.2.2.cmml">W</mi><mi id="S2.SS3.p3.11.m11.1.1.1.1.1.2.3" xref="S2.SS3.p3.11.m11.1.1.1.1.1.2.3.cmml">t</mi><mi id="S2.SS3.p3.11.m11.1.1.1.1.1.3" xref="S2.SS3.p3.11.m11.1.1.1.1.1.3.cmml">k</mi></msubsup><mo stretchy="false" id="S2.SS3.p3.11.m11.1.1.1.1.3" xref="S2.SS3.p3.11.m11.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p3.11.m11.1b"><apply id="S2.SS3.p3.11.m11.1.1.cmml" xref="S2.SS3.p3.11.m11.1.1"><times id="S2.SS3.p3.11.m11.1.1.2.cmml" xref="S2.SS3.p3.11.m11.1.1.2"></times><apply id="S2.SS3.p3.11.m11.1.1.3.cmml" xref="S2.SS3.p3.11.m11.1.1.3"><csymbol cd="ambiguous" id="S2.SS3.p3.11.m11.1.1.3.1.cmml" xref="S2.SS3.p3.11.m11.1.1.3">subscript</csymbol><ci id="S2.SS3.p3.11.m11.1.1.3.2.cmml" xref="S2.SS3.p3.11.m11.1.1.3.2">𝑓</ci><ci id="S2.SS3.p3.11.m11.1.1.3.3.cmml" xref="S2.SS3.p3.11.m11.1.1.3.3">𝑖</ci></apply><apply id="S2.SS3.p3.11.m11.1.1.1.1.1.cmml" xref="S2.SS3.p3.11.m11.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS3.p3.11.m11.1.1.1.1.1.1.cmml" xref="S2.SS3.p3.11.m11.1.1.1.1">superscript</csymbol><apply id="S2.SS3.p3.11.m11.1.1.1.1.1.2.cmml" xref="S2.SS3.p3.11.m11.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS3.p3.11.m11.1.1.1.1.1.2.1.cmml" xref="S2.SS3.p3.11.m11.1.1.1.1">subscript</csymbol><ci id="S2.SS3.p3.11.m11.1.1.1.1.1.2.2.cmml" xref="S2.SS3.p3.11.m11.1.1.1.1.1.2.2">𝑊</ci><ci id="S2.SS3.p3.11.m11.1.1.1.1.1.2.3.cmml" xref="S2.SS3.p3.11.m11.1.1.1.1.1.2.3">𝑡</ci></apply><ci id="S2.SS3.p3.11.m11.1.1.1.1.1.3.cmml" xref="S2.SS3.p3.11.m11.1.1.1.1.1.3">𝑘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p3.11.m11.1c">f_{i}(W_{t}^{k})</annotation></semantics></math> indicates the loss on data sample <math id="S2.SS3.p3.12.m12.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S2.SS3.p3.12.m12.1a"><mi id="S2.SS3.p3.12.m12.1.1" xref="S2.SS3.p3.12.m12.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p3.12.m12.1b"><ci id="S2.SS3.p3.12.m12.1.1.cmml" xref="S2.SS3.p3.12.m12.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p3.12.m12.1c">i</annotation></semantics></math> given the parametrisation <math id="S2.SS3.p3.13.m13.1" class="ltx_Math" alttext="W_{t}^{k}" display="inline"><semantics id="S2.SS3.p3.13.m13.1a"><msubsup id="S2.SS3.p3.13.m13.1.1" xref="S2.SS3.p3.13.m13.1.1.cmml"><mi id="S2.SS3.p3.13.m13.1.1.2.2" xref="S2.SS3.p3.13.m13.1.1.2.2.cmml">W</mi><mi id="S2.SS3.p3.13.m13.1.1.2.3" xref="S2.SS3.p3.13.m13.1.1.2.3.cmml">t</mi><mi id="S2.SS3.p3.13.m13.1.1.3" xref="S2.SS3.p3.13.m13.1.1.3.cmml">k</mi></msubsup><annotation-xml encoding="MathML-Content" id="S2.SS3.p3.13.m13.1b"><apply id="S2.SS3.p3.13.m13.1.1.cmml" xref="S2.SS3.p3.13.m13.1.1"><csymbol cd="ambiguous" id="S2.SS3.p3.13.m13.1.1.1.cmml" xref="S2.SS3.p3.13.m13.1.1">superscript</csymbol><apply id="S2.SS3.p3.13.m13.1.1.2.cmml" xref="S2.SS3.p3.13.m13.1.1"><csymbol cd="ambiguous" id="S2.SS3.p3.13.m13.1.1.2.1.cmml" xref="S2.SS3.p3.13.m13.1.1">subscript</csymbol><ci id="S2.SS3.p3.13.m13.1.1.2.2.cmml" xref="S2.SS3.p3.13.m13.1.1.2.2">𝑊</ci><ci id="S2.SS3.p3.13.m13.1.1.2.3.cmml" xref="S2.SS3.p3.13.m13.1.1.2.3">𝑡</ci></apply><ci id="S2.SS3.p3.13.m13.1.1.3.cmml" xref="S2.SS3.p3.13.m13.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p3.13.m13.1c">W_{t}^{k}</annotation></semantics></math>, (steps <span id="S2.SS3.p3.13.3" class="ltx_text" style="font-size:120%;">\small2⃝</span>, <span id="S2.SS3.p3.13.4" class="ltx_text" style="font-size:120%;">\small3⃝</span>).</p>
</div>
<div id="S2.SS3.p4" class="ltx_para">
<p id="S2.SS3.p4.2" class="ltx_p">3. <span id="S2.SS3.p4.2.1" class="ltx_text ltx_font_bold">Reporting</span>: At this point, the participants share the local model updates with the central server in a synchronous, or asynchronous manner <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>. The synchronous strategy can produce a high-precision, fast-converging model in the absence of stragglers that are attributed to poor hardware or network resources. Stragglers threaten the scalability of FL as they slow down the training process. In contrast, the asynchronous mechanism handles stragglers naturally by incorporating participants’ updates as soon as they arrive but has the threat of model quality degradation and insecure aggregation, resulting in an undesirable level of privacy. Several works have considered this issue by proposing different schemes, such as a secure buffer in FedBuff <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>, staleness-awareness in FedSA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>, and semi-asynchronous in SAFA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>. Finally, the server aggregates the shared parameters to update the global model. Specifically, models aggregation and global model parameters computation are performed at the server as the following <math id="S2.SS3.p4.1.m1.1" class="ltx_Math" alttext="W_{t}=\sum_{k=1}^{K}\frac{D_{k}}{D}W_{t}^{k}" display="inline"><semantics id="S2.SS3.p4.1.m1.1a"><mrow id="S2.SS3.p4.1.m1.1.1" xref="S2.SS3.p4.1.m1.1.1.cmml"><msub id="S2.SS3.p4.1.m1.1.1.2" xref="S2.SS3.p4.1.m1.1.1.2.cmml"><mi id="S2.SS3.p4.1.m1.1.1.2.2" xref="S2.SS3.p4.1.m1.1.1.2.2.cmml">W</mi><mi id="S2.SS3.p4.1.m1.1.1.2.3" xref="S2.SS3.p4.1.m1.1.1.2.3.cmml">t</mi></msub><mo rspace="0.111em" id="S2.SS3.p4.1.m1.1.1.1" xref="S2.SS3.p4.1.m1.1.1.1.cmml">=</mo><mrow id="S2.SS3.p4.1.m1.1.1.3" xref="S2.SS3.p4.1.m1.1.1.3.cmml"><msubsup id="S2.SS3.p4.1.m1.1.1.3.1" xref="S2.SS3.p4.1.m1.1.1.3.1.cmml"><mo id="S2.SS3.p4.1.m1.1.1.3.1.2.2" xref="S2.SS3.p4.1.m1.1.1.3.1.2.2.cmml">∑</mo><mrow id="S2.SS3.p4.1.m1.1.1.3.1.2.3" xref="S2.SS3.p4.1.m1.1.1.3.1.2.3.cmml"><mi id="S2.SS3.p4.1.m1.1.1.3.1.2.3.2" xref="S2.SS3.p4.1.m1.1.1.3.1.2.3.2.cmml">k</mi><mo id="S2.SS3.p4.1.m1.1.1.3.1.2.3.1" xref="S2.SS3.p4.1.m1.1.1.3.1.2.3.1.cmml">=</mo><mn id="S2.SS3.p4.1.m1.1.1.3.1.2.3.3" xref="S2.SS3.p4.1.m1.1.1.3.1.2.3.3.cmml">1</mn></mrow><mi id="S2.SS3.p4.1.m1.1.1.3.1.3" xref="S2.SS3.p4.1.m1.1.1.3.1.3.cmml">K</mi></msubsup><mrow id="S2.SS3.p4.1.m1.1.1.3.2" xref="S2.SS3.p4.1.m1.1.1.3.2.cmml"><mfrac id="S2.SS3.p4.1.m1.1.1.3.2.2" xref="S2.SS3.p4.1.m1.1.1.3.2.2.cmml"><msub id="S2.SS3.p4.1.m1.1.1.3.2.2.2" xref="S2.SS3.p4.1.m1.1.1.3.2.2.2.cmml"><mi id="S2.SS3.p4.1.m1.1.1.3.2.2.2.2" xref="S2.SS3.p4.1.m1.1.1.3.2.2.2.2.cmml">D</mi><mi id="S2.SS3.p4.1.m1.1.1.3.2.2.2.3" xref="S2.SS3.p4.1.m1.1.1.3.2.2.2.3.cmml">k</mi></msub><mi id="S2.SS3.p4.1.m1.1.1.3.2.2.3" xref="S2.SS3.p4.1.m1.1.1.3.2.2.3.cmml">D</mi></mfrac><mo lspace="0em" rspace="0em" id="S2.SS3.p4.1.m1.1.1.3.2.1" xref="S2.SS3.p4.1.m1.1.1.3.2.1.cmml">​</mo><msubsup id="S2.SS3.p4.1.m1.1.1.3.2.3" xref="S2.SS3.p4.1.m1.1.1.3.2.3.cmml"><mi id="S2.SS3.p4.1.m1.1.1.3.2.3.2.2" xref="S2.SS3.p4.1.m1.1.1.3.2.3.2.2.cmml">W</mi><mi id="S2.SS3.p4.1.m1.1.1.3.2.3.2.3" xref="S2.SS3.p4.1.m1.1.1.3.2.3.2.3.cmml">t</mi><mi id="S2.SS3.p4.1.m1.1.1.3.2.3.3" xref="S2.SS3.p4.1.m1.1.1.3.2.3.3.cmml">k</mi></msubsup></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p4.1.m1.1b"><apply id="S2.SS3.p4.1.m1.1.1.cmml" xref="S2.SS3.p4.1.m1.1.1"><eq id="S2.SS3.p4.1.m1.1.1.1.cmml" xref="S2.SS3.p4.1.m1.1.1.1"></eq><apply id="S2.SS3.p4.1.m1.1.1.2.cmml" xref="S2.SS3.p4.1.m1.1.1.2"><csymbol cd="ambiguous" id="S2.SS3.p4.1.m1.1.1.2.1.cmml" xref="S2.SS3.p4.1.m1.1.1.2">subscript</csymbol><ci id="S2.SS3.p4.1.m1.1.1.2.2.cmml" xref="S2.SS3.p4.1.m1.1.1.2.2">𝑊</ci><ci id="S2.SS3.p4.1.m1.1.1.2.3.cmml" xref="S2.SS3.p4.1.m1.1.1.2.3">𝑡</ci></apply><apply id="S2.SS3.p4.1.m1.1.1.3.cmml" xref="S2.SS3.p4.1.m1.1.1.3"><apply id="S2.SS3.p4.1.m1.1.1.3.1.cmml" xref="S2.SS3.p4.1.m1.1.1.3.1"><csymbol cd="ambiguous" id="S2.SS3.p4.1.m1.1.1.3.1.1.cmml" xref="S2.SS3.p4.1.m1.1.1.3.1">superscript</csymbol><apply id="S2.SS3.p4.1.m1.1.1.3.1.2.cmml" xref="S2.SS3.p4.1.m1.1.1.3.1"><csymbol cd="ambiguous" id="S2.SS3.p4.1.m1.1.1.3.1.2.1.cmml" xref="S2.SS3.p4.1.m1.1.1.3.1">subscript</csymbol><sum id="S2.SS3.p4.1.m1.1.1.3.1.2.2.cmml" xref="S2.SS3.p4.1.m1.1.1.3.1.2.2"></sum><apply id="S2.SS3.p4.1.m1.1.1.3.1.2.3.cmml" xref="S2.SS3.p4.1.m1.1.1.3.1.2.3"><eq id="S2.SS3.p4.1.m1.1.1.3.1.2.3.1.cmml" xref="S2.SS3.p4.1.m1.1.1.3.1.2.3.1"></eq><ci id="S2.SS3.p4.1.m1.1.1.3.1.2.3.2.cmml" xref="S2.SS3.p4.1.m1.1.1.3.1.2.3.2">𝑘</ci><cn type="integer" id="S2.SS3.p4.1.m1.1.1.3.1.2.3.3.cmml" xref="S2.SS3.p4.1.m1.1.1.3.1.2.3.3">1</cn></apply></apply><ci id="S2.SS3.p4.1.m1.1.1.3.1.3.cmml" xref="S2.SS3.p4.1.m1.1.1.3.1.3">𝐾</ci></apply><apply id="S2.SS3.p4.1.m1.1.1.3.2.cmml" xref="S2.SS3.p4.1.m1.1.1.3.2"><times id="S2.SS3.p4.1.m1.1.1.3.2.1.cmml" xref="S2.SS3.p4.1.m1.1.1.3.2.1"></times><apply id="S2.SS3.p4.1.m1.1.1.3.2.2.cmml" xref="S2.SS3.p4.1.m1.1.1.3.2.2"><divide id="S2.SS3.p4.1.m1.1.1.3.2.2.1.cmml" xref="S2.SS3.p4.1.m1.1.1.3.2.2"></divide><apply id="S2.SS3.p4.1.m1.1.1.3.2.2.2.cmml" xref="S2.SS3.p4.1.m1.1.1.3.2.2.2"><csymbol cd="ambiguous" id="S2.SS3.p4.1.m1.1.1.3.2.2.2.1.cmml" xref="S2.SS3.p4.1.m1.1.1.3.2.2.2">subscript</csymbol><ci id="S2.SS3.p4.1.m1.1.1.3.2.2.2.2.cmml" xref="S2.SS3.p4.1.m1.1.1.3.2.2.2.2">𝐷</ci><ci id="S2.SS3.p4.1.m1.1.1.3.2.2.2.3.cmml" xref="S2.SS3.p4.1.m1.1.1.3.2.2.2.3">𝑘</ci></apply><ci id="S2.SS3.p4.1.m1.1.1.3.2.2.3.cmml" xref="S2.SS3.p4.1.m1.1.1.3.2.2.3">𝐷</ci></apply><apply id="S2.SS3.p4.1.m1.1.1.3.2.3.cmml" xref="S2.SS3.p4.1.m1.1.1.3.2.3"><csymbol cd="ambiguous" id="S2.SS3.p4.1.m1.1.1.3.2.3.1.cmml" xref="S2.SS3.p4.1.m1.1.1.3.2.3">superscript</csymbol><apply id="S2.SS3.p4.1.m1.1.1.3.2.3.2.cmml" xref="S2.SS3.p4.1.m1.1.1.3.2.3"><csymbol cd="ambiguous" id="S2.SS3.p4.1.m1.1.1.3.2.3.2.1.cmml" xref="S2.SS3.p4.1.m1.1.1.3.2.3">subscript</csymbol><ci id="S2.SS3.p4.1.m1.1.1.3.2.3.2.2.cmml" xref="S2.SS3.p4.1.m1.1.1.3.2.3.2.2">𝑊</ci><ci id="S2.SS3.p4.1.m1.1.1.3.2.3.2.3.cmml" xref="S2.SS3.p4.1.m1.1.1.3.2.3.2.3">𝑡</ci></apply><ci id="S2.SS3.p4.1.m1.1.1.3.2.3.3.cmml" xref="S2.SS3.p4.1.m1.1.1.3.2.3.3">𝑘</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p4.1.m1.1c">W_{t}=\sum_{k=1}^{K}\frac{D_{k}}{D}W_{t}^{k}</annotation></semantics></math>, where D represents the entire dataset of all clients, i.e., <math id="S2.SS3.p4.2.m2.1" class="ltx_Math" alttext="D=\sum_{k=1}^{K}D_{k}" display="inline"><semantics id="S2.SS3.p4.2.m2.1a"><mrow id="S2.SS3.p4.2.m2.1.1" xref="S2.SS3.p4.2.m2.1.1.cmml"><mi id="S2.SS3.p4.2.m2.1.1.2" xref="S2.SS3.p4.2.m2.1.1.2.cmml">D</mi><mo rspace="0.111em" id="S2.SS3.p4.2.m2.1.1.1" xref="S2.SS3.p4.2.m2.1.1.1.cmml">=</mo><mrow id="S2.SS3.p4.2.m2.1.1.3" xref="S2.SS3.p4.2.m2.1.1.3.cmml"><msubsup id="S2.SS3.p4.2.m2.1.1.3.1" xref="S2.SS3.p4.2.m2.1.1.3.1.cmml"><mo id="S2.SS3.p4.2.m2.1.1.3.1.2.2" xref="S2.SS3.p4.2.m2.1.1.3.1.2.2.cmml">∑</mo><mrow id="S2.SS3.p4.2.m2.1.1.3.1.2.3" xref="S2.SS3.p4.2.m2.1.1.3.1.2.3.cmml"><mi id="S2.SS3.p4.2.m2.1.1.3.1.2.3.2" xref="S2.SS3.p4.2.m2.1.1.3.1.2.3.2.cmml">k</mi><mo id="S2.SS3.p4.2.m2.1.1.3.1.2.3.1" xref="S2.SS3.p4.2.m2.1.1.3.1.2.3.1.cmml">=</mo><mn id="S2.SS3.p4.2.m2.1.1.3.1.2.3.3" xref="S2.SS3.p4.2.m2.1.1.3.1.2.3.3.cmml">1</mn></mrow><mi id="S2.SS3.p4.2.m2.1.1.3.1.3" xref="S2.SS3.p4.2.m2.1.1.3.1.3.cmml">K</mi></msubsup><msub id="S2.SS3.p4.2.m2.1.1.3.2" xref="S2.SS3.p4.2.m2.1.1.3.2.cmml"><mi id="S2.SS3.p4.2.m2.1.1.3.2.2" xref="S2.SS3.p4.2.m2.1.1.3.2.2.cmml">D</mi><mi id="S2.SS3.p4.2.m2.1.1.3.2.3" xref="S2.SS3.p4.2.m2.1.1.3.2.3.cmml">k</mi></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p4.2.m2.1b"><apply id="S2.SS3.p4.2.m2.1.1.cmml" xref="S2.SS3.p4.2.m2.1.1"><eq id="S2.SS3.p4.2.m2.1.1.1.cmml" xref="S2.SS3.p4.2.m2.1.1.1"></eq><ci id="S2.SS3.p4.2.m2.1.1.2.cmml" xref="S2.SS3.p4.2.m2.1.1.2">𝐷</ci><apply id="S2.SS3.p4.2.m2.1.1.3.cmml" xref="S2.SS3.p4.2.m2.1.1.3"><apply id="S2.SS3.p4.2.m2.1.1.3.1.cmml" xref="S2.SS3.p4.2.m2.1.1.3.1"><csymbol cd="ambiguous" id="S2.SS3.p4.2.m2.1.1.3.1.1.cmml" xref="S2.SS3.p4.2.m2.1.1.3.1">superscript</csymbol><apply id="S2.SS3.p4.2.m2.1.1.3.1.2.cmml" xref="S2.SS3.p4.2.m2.1.1.3.1"><csymbol cd="ambiguous" id="S2.SS3.p4.2.m2.1.1.3.1.2.1.cmml" xref="S2.SS3.p4.2.m2.1.1.3.1">subscript</csymbol><sum id="S2.SS3.p4.2.m2.1.1.3.1.2.2.cmml" xref="S2.SS3.p4.2.m2.1.1.3.1.2.2"></sum><apply id="S2.SS3.p4.2.m2.1.1.3.1.2.3.cmml" xref="S2.SS3.p4.2.m2.1.1.3.1.2.3"><eq id="S2.SS3.p4.2.m2.1.1.3.1.2.3.1.cmml" xref="S2.SS3.p4.2.m2.1.1.3.1.2.3.1"></eq><ci id="S2.SS3.p4.2.m2.1.1.3.1.2.3.2.cmml" xref="S2.SS3.p4.2.m2.1.1.3.1.2.3.2">𝑘</ci><cn type="integer" id="S2.SS3.p4.2.m2.1.1.3.1.2.3.3.cmml" xref="S2.SS3.p4.2.m2.1.1.3.1.2.3.3">1</cn></apply></apply><ci id="S2.SS3.p4.2.m2.1.1.3.1.3.cmml" xref="S2.SS3.p4.2.m2.1.1.3.1.3">𝐾</ci></apply><apply id="S2.SS3.p4.2.m2.1.1.3.2.cmml" xref="S2.SS3.p4.2.m2.1.1.3.2"><csymbol cd="ambiguous" id="S2.SS3.p4.2.m2.1.1.3.2.1.cmml" xref="S2.SS3.p4.2.m2.1.1.3.2">subscript</csymbol><ci id="S2.SS3.p4.2.m2.1.1.3.2.2.cmml" xref="S2.SS3.p4.2.m2.1.1.3.2.2">𝐷</ci><ci id="S2.SS3.p4.2.m2.1.1.3.2.3.cmml" xref="S2.SS3.p4.2.m2.1.1.3.2.3">𝑘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p4.2.m2.1c">D=\sum_{k=1}^{K}D_{k}</annotation></semantics></math>, (steps <span id="S2.SS3.p4.2.2" class="ltx_text" style="font-size:120%;">\small4⃝</span>, <span id="S2.SS3.p4.2.3" class="ltx_text" style="font-size:120%;">\small5⃝</span>). The steps from <span id="S2.SS3.p4.2.4" class="ltx_text" style="font-size:120%;">\small2⃝</span> to <span id="S2.SS3.p4.2.5" class="ltx_text" style="font-size:120%;">\small5⃝</span> are repeated until the global model converges to a desired accuracy.</p>
</div>
<figure id="S2.F3" class="ltx_figure"><img src="/html/2111.07392/assets/x3.png" id="S2.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="207" height="139" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F3.4.2.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S2.F3.2.1" class="ltx_text" style="font-size:90%;">Sequential operation steps of FL involving <math id="S2.F3.2.1.m1.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S2.F3.2.1.m1.1b"><mi id="S2.F3.2.1.m1.1.1" xref="S2.F3.2.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S2.F3.2.1.m1.1c"><ci id="S2.F3.2.1.m1.1.1.cmml" xref="S2.F3.2.1.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.F3.2.1.m1.1d">K</annotation></semantics></math> participants.</span></figcaption>
</figure>
</section>
<section id="S2.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS4.4.1.1" class="ltx_text">II-D</span> </span><span id="S2.SS4.5.2" class="ltx_text ltx_font_italic">FL Aggregation Schemes</span>
</h3>

<div id="S2.SS4.p1" class="ltx_para">
<p id="S2.SS4.p1.1" class="ltx_p">Gradient descent (GD) algorithm that aims to find the minimum of a differentiable function is commonly used in various ML algorithms, especially NN models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>. However, the computational complexity of GD increases with the dataset size, making it unsuitable for FL systems due to the slow convergence rate. An alternative to GD is stochastic GD (SGD), which can perform gradient calculation over a subset of data, significantly enhancing the convergence rate. In the FL setting, SGD (FedSGD) is exploited as an approach to quantify how often the global FL model needs to be updated <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>. FedSGD is the basic aggregation scheme for FL-enabled systems, where clients compute gradients using random data samples. However, the FedSGD technique requires many communication rounds proportional to the volume of nodes’ datasets, which will burden the communication links and consume BW.</p>
</div>
<div id="S2.SS4.p2" class="ltx_para">
<p id="S2.SS4.p2.1" class="ltx_p">To address the above problem, the federated averaging (FedAvg) strategy has been proposed to alleviate the pressure on communication resources <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>. FedAvg is a generalisation of FedSGD, where each node repeatedly runs SGD locally over different local data subsets and finds the optimum model parameters by averaging the locally evaluated gradients. Three main parameters control the performance of FedAvg: (i) the fraction of the selected nodes that perform computation at each round, (ii) the size of data subsets, and (iii) the number of epochs that the node passes over its dataset in every round. In FedAvg, instead of sending the computed gradients, each node will only send the model parameters. Thus, compared to FedSGD, the FedAvg algorithm performs more local computation and less communication with the server.</p>
</div>
<div id="S2.SS4.p3" class="ltx_para">
<p id="S2.SS4.p3.1" class="ltx_p">Nevertheless, in real-world scenarios, in which network devices are heterogeneous and the local datasets are non-identically distributed, FedAvg experiences poor convergence behaviour. Therefore, some variants of the FedAvg algorithm have been introduced to develop faster aggregation techniques. FedProx was proposed to solve the heterogeneity issue in federated networks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>. The FedProx principle is similar to that of FedAvg but with a small critical modification that improves performance. Instead of forcing every node to perform the same computation work, FedProx considers system heterogeneity by allowing each node to perform an amount of local computation proportional to its resources. Accordingly, enabling parameter aggregation from a set of heterogeneous nodes.</p>
</div>
<div id="S2.SS4.p4" class="ltx_para">
<p id="S2.SS4.p4.1" class="ltx_p">Another extension to the FedAvg scheme is the FedSplit algorithm <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>, which relies on the operator splitting procedure for convex optimisation problems. Operator splitting is an efficient method for solving large-scale convex problems by performing iterations of simple and computationally inexpensive operations. It converts the problem into simpler sub-problems and makes progress on them separately. Motivated by the failure of FedAvg and FedProx to preserve the fixed points of the original optimisation problem, FedSplit is proposed as a splitting algorithm for federated optimisation to achieve rapid convergence. Moreover, the work in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite> applied the adaptive optimisers ADAGRAD, ADAM, and YOGI in the FL setting, i.e., FedAdaGrad, FedAdam, and FedYogi. Extensive experimental evaluations are performed to examine these algorithms compared to the FedAvg algorithm. Furthermore, the Qsparse-local-SGD algorithm <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite> considers both local computation and communication reduction in distributed settings. Convergence analysis is made in synchronous and asynchronous FL, showing that the Qsparse-local-SGD algorithm achieves the same convergence rate as FedSGD.</p>
</div>
<div id="S2.SS4.p5" class="ltx_para">
<p id="S2.SS4.p5.1" class="ltx_p">The above approaches are mainly designed for NN models where the parameters, i.e. weights and biases, are the main elements to update the global model. Despite numerous attempts to enhance the aggregation process, NN and DL models incur high communication and computation costs. Therefore, several studies have begun to explore other low-complexity techniques, such as ensemble learning under the FL settings, like FedBoost <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite> and FedTrees <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite>. It has been demonstrated in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite> that when the federated model is trained according to these algorithms, an excellent performance is achieved in terms of accuracy, computation time, and communication rounds. This paves the way for exploring other ML techniques in the FL environment.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">FL Enabling Technologies</span>
</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">With the aim to realise the full potential of FL, several enabling technologies can be leveraged in order to improve the performance of FL and hence, accentuate its promising features. This section is devoted to discussing some of these enabling technologies.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS1.4.1.1" class="ltx_text">III-A</span> </span><span id="S3.SS1.5.2" class="ltx_text ltx_font_italic">Multi-Access Edge Computing (MEC)</span>
</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">The rapid evolution of the internet-of-everything (IoE) paradigm has resulted in a plentitude of end devices. The abundance of resource-intensive devices, coupled with the emergence of QoE-oriented applications, has led to a wealth of data being generated at the edge of wireless networks. Exploiting this data requires sending it across the networks to reach the cloud server where the significant computation and storage resources are located. Accordingly, cloud computing has become unsuitable for resource-limited real-time applications, owing to the increased overhead occurring in the network, in terms of energy and spectrum resources, in addition to the increased latency and compromised security. Therefore, the European telecommunications standards institute (ETSI) has introduced a new computing paradigm called MEC, which brings cloud computing capabilities to the edge of the radio access network <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite>. The key motivation behind MEC is that running applications closer to the end-users with their associated computation tasks will reduce network congestion and preserve the network resources, enabling enhanced user experience.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">The proliferation of smart end devices with the employment of MEC provides a suitable environment for employing FL algorithms. Shifting to decentralised ML model training at the network edge allows for greater scalability by distributing the computation from centralised architectures of the network core/cloud to the edge closer to the users. Moreover, MEC enables FL algorithms to offer latency optimisation for real-time applications where data aggregation, analytics, and computation are handled within user proximity. In fact, the capabilities of the edge server enable it to act as an FL server, whereas the widely dispersed edge devices are used as FL clients. Thus, MEC and FL provide rich services and applications close to the end users.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS2.4.1.1" class="ltx_text">III-B</span> </span><span id="S3.SS2.5.2" class="ltx_text ltx_font_italic">Blockchain</span>
</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">As a decentralised learning algorithm, FL has benefits in two main aspects: load balancing and privacy-preserving. However, FL has shortcomings as it does not keep records of participants’ training contributions along with reliance on a central server prone to a single point of failure. In this regard, blockchain, a decentralised database managed by distributed nodes, can play an essential role in FL. Blockchain was initially introduced in 2009 as a type of distributed ledger technology <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite>. In particular, blockchain was primarily proposed to serve as a ledger of the public transactions for the cryptocurrency Bitcoin. For improved security, the principle operation of blockchain relies on grouping multiple transactions and storing them in a block encrypted by a hash signature. After that, each new block is time-stamped and chained with the previous one, creating a long chain of encrypted chronologically-ordered transactions. Therefore, blockchain has a high level of security, as altering the content of any block requires an agreement from all nodes connected to the chain. These merits motivate the authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite> to design an incentive mechanism for a blockchain-enabled FL platform that can record and secure the workers’ updates and reward them accordingly. Whereas the study in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite> sheds light on the distributed ledger feature of blockchain to realise decentralised FL training without needing a central server, and proposes a new paradigm called FLchain.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">Furthermore, the blockchain provides a fully transparent network in which all nodes can observe all transactions coming in and going out. When a new transaction is stored in the blockchain, it is considered immutable because it is verified based on a consensus mechanism. The consensus mechanism validates the data in each block and verifies its availability since all blocks will store the same copy of the data. This has been exploited in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite> when the authors designed a blockchain-based FL system that can prevent malicious model updates using blockchain’s immutability and decentralised trust property. Moreover, the work in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite> uses blockchain to support the operation of the FL utilised to provide up-to-date service provisioning and support device communication in vehicular environments. Blockchain technology is adopted to ensure the credibility and integrity of sensitive services, such that the local models are verified using a consensus algorithm. Similarly, the authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite> integrated blockchain with FL to maintain and secure local model parameters, improve learning quality, and optimise the allocation of varying resources in B5G networks. In light of the above discussion, decentralisation, availability, transparency, immutability, and security are the most promising features of the blockchain, which are well-suited for the FL system and constitute one of its enabling factors.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS3.4.1.1" class="ltx_text">III-C</span> </span><span id="S3.SS3.5.2" class="ltx_text ltx_font_italic">Network Slicing (NS)</span>
</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">NS is one of the key enablers in B5G wireless networks, where it exploits the network’s physical structure to create several independent logical networks called slices <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref">50</a>]</cite>. Each slice comprises an end-to-end isolated network tailored to fulfil diverse application requirements. In this respect, millimetre wave (mmWave) and terahertz communications (THz) in B5G/6G networks enable improved capacity for devices operating in a small coverage area, allowing the realisation of different IoE networks. These networks will require resources that meet the diverse quality-of-service (QoS) requirements. The unique characteristic of NS is that it grants each network segment an isolated and tailored slice to enable a particular service. However, configuration, activation, association, and management of network slices constitute a challenging factor that requires developing dedicated intelligent techniques. Therefore, using AI is a must to optimise real-time resource allocation and distribution among different slices according to their requirements. In light of this, FL and NS are considered promising enablers for each other. The work in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref">51</a>]</cite> presents an FL-based framework that predicts slices’ service-oriented key performance indicators (KPIs). The concept of an in-slice manager was introduced for monitoring and collecting slices’ KPIs and local decision-making to ensure optimal performance.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.1" class="ltx_p">NS allows future mobile communications to ensure the efficient allocation of services while guaranteeing the QoS. For this reason, the study in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>]</cite> proposes an FL-based forecasting algorithm to predict base station level traffic in sliced network architecture to facilitate intelligent and predictive management of resources. Whereas the authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite> present a federated deep reinforcement learning (DRL) scheme to manage the transmission power and spreading factor resources in LoRa-based industrial IoT (IIoT) slices. A multi-agent self-model is trained under the FL environment to obtain an optimal decision of LoRa parameters that fulfil the QoS of IIoT virtual network slices. Furthermore, the proposed work in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite> offers a hybrid federated RL framework to find the optimal device association for radio access network (RAN) slices to maximise the network throughput.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">FL APPLICATIONS IN WIRELESS NETWORKS</span>
</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">Since the advent of FL by Google in 2016, extensive research has been conducted to promote, enhance, and determine the best usage of this decentralised learning algorithm. Wireless networks are one of the forerunners to adopt FL in their architecture, as depicted in Fig. <a href="#S4.F4" title="Figure 4 ‣ IV-A FL State-of-the-Art Applications ‣ IV FL APPLICATIONS IN WIRELESS NETWORKS ‣ Edge-Native Intelligence for 6G Communications Driven by Federated Learning: A Survey of Trends and Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. This section will thoroughly present the key driving applications of FL in wireless networks; more specifically, Section <a href="#S4.SS1" title="IV-A FL State-of-the-Art Applications ‣ IV FL APPLICATIONS IN WIRELESS NETWORKS ‣ Edge-Native Intelligence for 6G Communications Driven by Federated Learning: A Survey of Trends and Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">IV-A</span></span></a> sheds light on the existing FL applications and accompanying challenges along with their potential solutions. Whereas Section <a href="#S4.SS2" title="IV-B FL Potential Future Applications ‣ IV FL APPLICATIONS IN WIRELESS NETWORKS ‣ Edge-Native Intelligence for 6G Communications Driven by Federated Learning: A Survey of Trends and Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">IV-B</span></span></a> describes the significance of FL in new and promising application areas of the forthcoming B5G and 6G networks.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS1.4.1.1" class="ltx_text">IV-A</span> </span><span id="S4.SS1.5.2" class="ltx_text ltx_font_italic">FL State-of-the-Art Applications</span>
</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">This section presents the research that has been done on utilising FL in current wireless networks.</p>
</div>
<figure id="S4.F4" class="ltx_figure"><img src="/html/2111.07392/assets/x4.png" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="251" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F4.2.1.1" class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span id="S4.F4.3.2" class="ltx_text" style="font-size:90%;">FL in various wireless networks; FL algorithm in the context of single or multiple wireless networks.</span></figcaption>
</figure>
<section id="S4.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS1.SSS1.4.1.1" class="ltx_text">IV-A</span>1 </span>Cellular Networks</h4>

<div id="S4.SS1.SSS1.p1" class="ltx_para">
<p id="S4.SS1.SSS1.p1.1" class="ltx_p">The rollout of 5G in late 2020 has allowed operators to launch numerous commercial services that benefit from the enhanced features provided by this new technology <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite>. In addition, the use of FL in these networks has many applications in different areas, as described below.</p>
</div>
<section id="S4.SS1.SSS1.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_font_bold ltx_title_paragraph">Homogeneous Cellular Networks</h5>

<div id="S4.SS1.SSS1.Px1.p1" class="ltx_para">
<p id="S4.SS1.SSS1.Px1.p1.1" class="ltx_p">This type refers to low-frequency wireless networks with macrocells, alluding to their wide coverage. Two main concerns for FL at the network edge are heterogeneous devices with different computation and communication capabilities and securing local model updates. The work in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite> presents a blockchain-enabled FL framework to ensure security in a trustless environment using a distributed ledger between entities. Blockchain is an intermediary between the FL server and edge nodes to verify model parameters based on the consensus process. Also, FL has applications for network function virtualisation (NFV), which is introduced as an innovative concept that enables adaptive resource allocation for future wireless networks. Subramanya <em id="S4.SS1.SSS1.Px1.p1.1.1" class="ltx_emph ltx_font_italic">et al.</em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite> leverages the FL technique to build a model that can proactively predict the auto-scaling setting for MEC virtual services and ensure data protection policies.</p>
</div>
</section>
<section id="S4.SS1.SSS1.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_font_bold ltx_title_paragraph">Heterogeneous Cellular Networks</h5>

<div id="S4.SS1.SSS1.Px2.p1" class="ltx_para">
<p id="S4.SS1.SSS1.Px2.p1.1" class="ltx_p">Heterogeneous networks (HetNets), which comprise different cell types, expand wireless networks’ coverage and capacity. FL can be implemented in HetNets for resource allocation purposes. It was demonstrated in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> that applying HFL by grouping the users and assigning the needed resources for transmission can reduce the end-to-end communication latency in HetNets. This can be achieved by dividing users into clusters and assigning each cluster to the closest SBS. On the other hand, 5G HetNets are vulnerable to attacks, like denial of service (DoS), evil twinning, and port scanning. The work in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite> proposes a node-edge-cloud framework empowered by HFL to detect attacks throughout the 5G HetNets. Specifically, multiple dedicated nodes are distributed inside the network, each of which performs model training by employing the RL technique to enable adaptive learning that can capture the rapidly changing nature of the HetNets environment. In addition, the work in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite> presents FL-empowered MEC framework to tackle the communication overhead and delay between the edge server and clients in FL to enhance the training efficiency.</p>
</div>
</section>
<section id="S4.SS1.SSS1.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_font_bold ltx_title_paragraph">Multiple-Input Multiple-Output (MIMO)</h5>

<div id="S4.SS1.SSS1.Px3.p1" class="ltx_para">
<p id="S4.SS1.SSS1.Px3.p1.1" class="ltx_p">FL has many applications associated with MIMO technology. Given the high dynamicity of mmWave systems, the study in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite> enhances the performance of massive MIMO systems by estimating channel state information. FL is leveraged to conduct decentralised learning on the user side using local pilot signals to predict channel matrix, which helps determine the best beamforming design and improve the system’s performance. Moreover, the work in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib60" title="" class="ltx_ref">60</a>]</cite> presents an energy-efficient solution to support multiple FL groups in future wireless systems. Massive MIMO is utilised to assist model updates and ensure a stable operation of multiple FL processes executed within the same coherence time.</p>
</div>
</section>
<section id="S4.SS1.SSS1.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_font_bold ltx_title_paragraph">Fog-Cloud RAN</h5>

<div id="S4.SS1.SSS1.Px4.p1" class="ltx_para">
<p id="S4.SS1.SSS1.Px4.p1.1" class="ltx_p">The ever-increasing number of connected devices in 5G and beyond networks necessitates the transition to an ultra-efficient air interface. As a result, two air interface structures evolved, namely cloud-RAN (CRAN) and fog-RAN (FRAN). When surveying the literature, we observed many FL applications in FRAN networks, but using FL in CRAN networks is scarce. For example, the study in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref">61</a>]</cite> optimises the latency and BW resources when deploying FL in reconfigurable intelligent surface (RIS)-aided CRAN systems. The RIS controls channel propagation conditions and supports over-the-air computation (AirComp) technique to perform coherent on-air aggregation for local models by allowing simultaneous transmissions from clients to the parameter server. On the other hand, the FRAN paradigm fully uses edge networks and provides vital features such as content caching for optimal application performance and user experience. The authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref">62</a>]</cite> propose an FL-based mobility-aware content-caching framework in FRAN-based networks. Mobility and content demand statistics are exploited to improve users’ QoE by predicting and caching the most likely future content.</p>
</div>
</section>
<section id="S4.SS1.SSS1.Px5" class="ltx_paragraph">
<h5 class="ltx_title ltx_font_bold ltx_title_paragraph">5G New Radio (5G-NR)</h5>

<div id="S4.SS1.SSS1.Px5.p1" class="ltx_para">
<p id="S4.SS1.SSS1.Px5.p1.1" class="ltx_p">5G-NR is a new radio interface standard designed by 3GPP to satisfy the growing demands of 5G mobile networks. This new radio access technology allows user equipment to switch dynamically between different resource blocks with different BWs. However, such a technique raises resource allocation challenges in B5G networks. FL has many applications in resource allocation in terms of computation, communication, and energy efficiency. For example, the study in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib63" title="" class="ltx_ref">63</a>]</cite> uses FL to develop an ML model that aids in performing distributed resource management in cellular networks while minimising uplinks transmit power.</p>
</div>
</section>
</section>
<section id="S4.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS1.SSS2.4.1.1" class="ltx_text">IV-A</span>2 </span>Internet-of-Vehicular (IoV) Networks</h4>

<div id="S4.SS1.SSS2.p1" class="ltx_para">
<p id="S4.SS1.SSS2.p1.1" class="ltx_p">IoV has recently emerged as a key enabler for intelligent transportation systems (ITSs), combining two key concepts, namely, vehicle networking and intelligence <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite>. Within this context, the IoV paradigm aims to achieve smart information interaction between a vehicle and all network entities. Whereas vehicle computation capabilities realise vehicular intelligence by exploiting DL algorithms, cloud and edge computing, and big data analytics.</p>
</div>
<section id="S4.SS1.SSS2.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_font_bold ltx_title_paragraph">FL in ITS</h5>

<div id="S4.SS1.SSS2.Px1.p1" class="ltx_para">
<p id="S4.SS1.SSS2.Px1.p1.1" class="ltx_p">Communication reliability and latency are particularly significant in ITSs, owing to the severe consequences that might affect human safety. The proposed work in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite> exploits the integration of FL with blockchain to realise a distributed, privacy-aware, and efficient model designed for autonomous vehicular networks. The diverse nature of the vehicles in ITSs is particularly appealing for FL applications. The heterogeneous data helps improve the model accuracy by incorporating all network scenarios experienced by different vehicles. In addition to latency, FL has shortcomings in server centralisation, where exchanging large updates between the participants and the server yield a high overhead on the server. To overcome this challenge, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite> employs the blockchain technique, in which the distributed ledger is shared with each vehicle and maintains copies of the global and private models available and verified by each vehicle, relieving the pressure imposed on the central server. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib66" title="" class="ltx_ref">66</a>]</cite> studies the use of FL setting within the context of URLLC in vehicular networks. It mainly focuses on proposing a distributed joint transmit power and resource allocation framework that can reduce the power consumption of vehicular users while ensuring low-latency communications.</p>
</div>
</section>
<section id="S4.SS1.SSS2.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_font_bold ltx_title_paragraph">Vehicular Edge Computing (VEC)</h5>

<div id="S4.SS1.SSS2.Px2.p1" class="ltx_para">
<p id="S4.SS1.SSS2.Px2.p1.1" class="ltx_p">Following a similar concept to MEC, VEC exploits the communication and computation capabilities at the network edge. Ye <em id="S4.SS1.SSS2.Px2.p1.1.1" class="ltx_emph ltx_font_italic">et al.</em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib67" title="" class="ltx_ref">67</a>]</cite> implement FL with VEC to perform image classification to support diverse applications in ITSs. A model-selective approach was proposed to select clients with the highest computational capabilities and select models with the best image quality for aggregation. In an asymmetric FL setting, the server has no information about clients’ data and resources. To this end, a two-dimensional contract mechanism is proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib67" title="" class="ltx_ref">67</a>]</cite>, in which the server designs contract bundles that include various levels of data quality, computation capability, and rewards, and then the clients select the bundles that increase their utility. As part of IoV networks, electric vehicle (EV) networks are becoming more popular as the number of EVs increases; such networks are expected to take over from traditional vehicles in the coming years. The work in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib68" title="" class="ltx_ref">68</a>]</cite> studies energy efficiency and profit maximisation at charging stations (CSs). It proposes an FL-based economically efficient framework to investigate the historical energy transactions to increase CSs profit. Specifically, FL is used to train a local model using CS private data to predict the EVs’ energy demands. After that, the local models of every CS are aggregated and shared amongst them to benefit from other CS information, yielding more accurate results.</p>
</div>
</section>
<section id="S4.SS1.SSS2.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_font_bold ltx_title_paragraph">Traffic Perdiction</h5>

<div id="S4.SS1.SSS2.Px3.p1" class="ltx_para">
<p id="S4.SS1.SSS2.Px3.p1.1" class="ltx_p">Traffic prediction in smart cities brings up many benefits for ITSs, such as road safety, congestion avoidance, and shortest route selection. These gains are pronounced when exploiting information gathered from the edge in parallel with FL. One enhancement technique for FL is selecting the best hyperparameters of the local models in edge devices. As most of the literature focused on FL global optimisation, privacy, and communication, very few studied optimising model parameters. Qolomany <em id="S4.SS1.SSS2.Px3.p1.1.1" class="ltx_emph ltx_font_italic">et al.</em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib69" title="" class="ltx_ref">69</a>]</cite> proposed a particle swarm optimisation (PSO)-based technique to optimise local hyperparameters at the edge devices. Specifically, PSO optimises the local NN parameters, including the number of layers, neurons per layer, and epochs. This optimisation technique has been evaluated in traffic prediction as a use case. The work shows that the number of client-server communication rounds to find the best parameters is significantly reduced. This technique is attractive due to its low complexity implementation. However, its limitation lies in the reliance on a random search for the best initial parameters, which requires an unpredicted time that may affect the whole learning process.</p>
</div>
</section>
</section>
<section id="S4.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS1.SSS3.4.1.1" class="ltx_text">IV-A</span>3 </span>Unmanned Aerial Vehicle (UAV) Networks</h4>

<div id="S4.SS1.SSS3.p1" class="ltx_para">
<p id="S4.SS1.SSS3.p1.1" class="ltx_p">The flying vehicles in a UAV network have many attractive features, such as low cost, mobility flexibility, and ease of deployment, enabling them to participate in many tasks considered hard to perform. The application of AI algorithms and the recent advancements in UAV technology have widened the use-cases ambit of UAV networks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib70" title="" class="ltx_ref">70</a>]</cite>.</p>
</div>
<section id="S4.SS1.SSS3.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_font_bold ltx_title_paragraph">AI-empowered UAV</h5>

<div id="S4.SS1.SSS3.Px1.p1" class="ltx_para">
<p id="S4.SS1.SSS3.Px1.p1.1" class="ltx_p">The interplay between AI and UAV networks opens a new horizon for exploiting UAVs in more complicated tasks; however, data security and privacy remain significant challenges. In UAV-enabled mobile crowdsensing (MCS) applications, FL is particularly appealing for preserving the privacy of sensed data. In this regard, the authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib71" title="" class="ltx_ref">71</a>]</cite> integrated an FL-based UAV network with blockchain technology to eliminate the need for a central server. In addition, blockchain enhances FL network security by expulsing the adversary clients and sharing safe model updates between clients. On the other hand, the work in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib72" title="" class="ltx_ref">72</a>]</cite> proposed an FL-enabled air quality monitoring framework for secure MCS. A UAV swarm is utilised to measure the air quality, and the sensed data is used to train a lightweight model to predict the air quality index. FL is considered a promising candidate that can exploit the data silos collected by different agencies to produce a global model while preserving data privacy.</p>
</div>
<div id="S4.SS1.SSS3.Px1.p2" class="ltx_para">
<p id="S4.SS1.SSS3.Px1.p2.1" class="ltx_p">Following the MEC concept, federated edge learning (FEEL) can potentially reduce the end-to-end latency and communication overhead in UAV networks. Yet, as demonstrated in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib73" title="" class="ltx_ref">73</a>]</cite>, the efficient implementation of FEEL in UAV-based IoT networks is restrained by the battery lifetime of UAVs. In this respect, computation resource and BW allocation optimisation were formulated in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib73" title="" class="ltx_ref">73</a>]</cite> to enhance the FEEL performance in a UAV network. Also, in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib74" title="" class="ltx_ref">74</a>]</cite>, FL has been utilised as an aided technique to reduce the communication cost between multiple UAVs and a ground fusion centre in the context of image classification for remote area exploration missions.</p>
</div>
</section>
<section id="S4.SS1.SSS3.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_font_bold ltx_title_paragraph">Flying Ad-hoc Networks (FANETs)</h5>

<div id="S4.SS1.SSS3.Px2.p1" class="ltx_para">
<p id="S4.SS1.SSS3.Px2.p1.1" class="ltx_p">With the interest of accomplishing complicated tasks in UAV networks, UAVs are grouped in an Ad-hoc manner to create a local network, which allows UAVs to cooperate to perform joint tasks. Recent trajectory design and remote monitoring developments rely primarily on ML algorithms <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib75" title="" class="ltx_ref">75</a>]</cite>. To recall, such classical algorithms do not fit in the context of UAV networks due to their high mobility and constrained energy resources. FL was proposed to reduce the communication overhead as an efficient paradigm for FANETs, in which all participating UAVs collaborate to estimate the initial model parameters. Then, initial model parameters from all UAVs are shared and leveraged for local model training. A FEEL server is employed for model aggregation to exploit the local models to develop an enhanced global model.</p>
</div>
<div id="S4.SS1.SSS3.Px2.p2" class="ltx_para">
<p id="S4.SS1.SSS3.Px2.p2.1" class="ltx_p">Attributed to the inherent non-centrality nature of FANETs, such networks are vulnerable to several security threats that intend to disrupt their functionality, such as impersonation and jamming attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib76" title="" class="ltx_ref">76</a>]</cite>. Centralised attack detection and mitigation approaches are impractical, owing to the highly dynamic topology of FANETs. Thus, decentralised techniques are mandatory for such types of networks. To this end, in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib77" title="" class="ltx_ref">77</a>]</cite>, an FL-based device jamming detection for UAVs in FANETs was proposed. In addition to the enhanced security, the framework in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib77" title="" class="ltx_ref">77</a>]</cite> has considered the data heterogeneity issue between different UAVs. In particular, a Dempster-Shafer technique categorises UAV clients based on their data quality into groups. Then the FEEL server selects high-quality data group(s) for model training purposes.</p>
</div>
</section>
</section>
<section id="S4.SS1.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS1.SSS4.4.1.1" class="ltx_text">IV-A</span>4 </span>Reconfigurable Intelligent Surface (RIS)-Assisted Networks</h4>

<div id="S4.SS1.SSS4.p1" class="ltx_para">
<p id="S4.SS1.SSS4.p1.1" class="ltx_p">The emergence of numerous mmWave and THz applications has flagged several concerns attributed to the vulnerability of such applications to signal blockage and shadowing effects. Motivated by this and with the recent advancements in the solid-state industry, RISs have emerged as enablers of future wireless networks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib78" title="" class="ltx_ref">78</a>]</cite>. An RIS, comprising several reflective elements, can be artificially engineered to control the electromagnetic properties of wireless signals and enable diverse functionalities, including wave splitting, reflection, absorption, etc. Leveraging an RIS is particularly beneficial in AirComp-enabled FL scenarios, in which some clients may be experiencing blockage or weak channel conditions, affecting the global model training quality <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib79" title="" class="ltx_ref">79</a>, <a href="#bib.bib80" title="" class="ltx_ref">80</a>, <a href="#bib.bib81" title="" class="ltx_ref">81</a>]</cite>. AirComp is a technique that exploits the superposition nature of the wireless channel to transmit simultaneous model updates from multiple clients. Section <a href="#S5.SS4.SSS0.Px1" title="Models scaling and superposition ‣ V-D Communication Cost ‣ V FL CHALLENGES ‣ Edge-Native Intelligence for 6G Communications Driven by Federated Learning: A Survey of Trends and Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">V-D</span></span></a> covers the details of this technique. Yang <em id="S4.SS1.SSS4.p1.1.1" class="ltx_emph ltx_font_italic">et al.</em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib79" title="" class="ltx_ref">79</a>]</cite> use the AirComp technique assisted by RIS to boost fast global model aggregation, which reduces the required radio spectrum for parameter transmission since the clients collectively send their updates using the same channel. Also, to further enhance and boost the global model aggregation quality, an RIS is used to reduce aggregation errors by strengthening the quality of combined signals. In this respect, aiming to unleash the full potential of RIS in FL settings, Liu <em id="S4.SS1.SSS4.p1.1.2" class="ltx_emph ltx_font_italic">et al.</em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib80" title="" class="ltx_ref">80</a>]</cite> formulated a joint communication and learning optimisation problem by taking into consideration device selection, transceiver design, as well as RIS parameters.</p>
</div>
<div id="S4.SS1.SSS4.p2" class="ltx_para">
<p id="S4.SS1.SSS4.p2.1" class="ltx_p">The aforementioned contributions have assumed perfect channel state information (CSI) at the server and clients’ sides. However, acquiring CSI at the transmitter (CSIT) is not always attainable due to dynamic channel conditions, leading to a significant delay in receiving the CSI information, thus curbing the FEEL global model convergence. The proposed work in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib81" title="" class="ltx_ref">81</a>]</cite> investigated the CSIT-free over-the-air model aggregation based on RIS-assisted FEEL. The CSI at the transmitter side is assumed to be unavailable, while perfect CSI is assumed at the server side. Besides, the RIS adjusts and aligns the channel coefficients with the model aggregation weights. To this end, the successive channel coefficients are constrained, as a function of RIS phase shifts, to be proportional to the weights of the local models. Moreover, the received scaling factor is optimised by minimising the aggregation mean square error. To solve this optimisation problem, a difference-of-convex algorithm was adopted. Furthermore, RIS has proven its efficiency in converting wireless channels into a smart electromagnetic environment. To realise high-speed RIS-based communication, the authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib82" title="" class="ltx_ref">82</a>]</cite> proposed two FL-based RIS optimisation schemes: RIS-assisted outdoor and indoor IoT mmWave communications. In the former scenario, the RIS controller is considered the FL server, while the user equipment (UE) is a client. The clients’ data represents the CSI corresponding to their location and optimum RIS configuration. The trained model is aimed to optimise the achievable rate to enable high-speed mmWave communications. The latter scenario considers an access point (AP) connected to multiple IoT devices assisted by RISs and acts as an FL server, while the RIS and IoT devices are considered clients. The FL model is trained based on location information and optimal RIS configuration. As a result, the trained FL model can achieve high transmission sum rates in IoT networks.</p>
</div>
</section>
<section id="S4.SS1.SSS5" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS1.SSS5.4.1.1" class="ltx_text">IV-A</span>5 </span>IoT Networks</h4>

<div id="S4.SS1.SSS5.p1" class="ltx_para">
<p id="S4.SS1.SSS5.p1.1" class="ltx_p">High-dimensional data analytics will shift the traditional IoT paradigms from connected things to connected intelligence. It is envisaged that FL will be an indispensable tool in intelligent IoT-based applications, which are spreading in diverse fields <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib83" title="" class="ltx_ref">83</a>, <a href="#bib.bib84" title="" class="ltx_ref">84</a>]</cite>. In this section, we outline the usage of FL in various sectors associated with IoT networks.</p>
</div>
<section id="S4.SS1.SSS5.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_font_bold ltx_title_paragraph"> Industrial IoT (IIoT)</h5>

<div id="S4.SS1.SSS5.Px1.p1" class="ltx_para">
<p id="S4.SS1.SSS5.Px1.p1.1" class="ltx_p">The fourth industrial revolution (Industry 4.0) was triggered by the advancements in automation and manufacturing industries, coupled with the emergence of IIoT devices. Albeit the promising features of FL can be beneficial for IIoT networks, the upsurge number of nodes that may participate in the training process might produce colossal traffic that burdens the network. Reliable participant selection schemes can reduce network overhead and alleviate communication costs. The work in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib85" title="" class="ltx_ref">85</a>]</cite> presents a budgeted client selection algorithm that enhances the global model accuracy by choosing the best clients. This algorithm finds <math id="S4.SS1.SSS5.Px1.p1.1.m1.1" class="ltx_Math" alttext="R" display="inline"><semantics id="S4.SS1.SSS5.Px1.p1.1.m1.1a"><mi id="S4.SS1.SSS5.Px1.p1.1.m1.1.1" xref="S4.SS1.SSS5.Px1.p1.1.m1.1.1.cmml">R</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS5.Px1.p1.1.m1.1b"><ci id="S4.SS1.SSS5.Px1.p1.1.m1.1.1.cmml" xref="S4.SS1.SSS5.Px1.p1.1.m1.1.1">𝑅</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS5.Px1.p1.1.m1.1c">R</annotation></semantics></math> clients with the best test accuracy based on the secretary problem. More specifically, clients are interviewed sequentially and marked as selected or rejected, and then these clients will be ranked from the best to the worst to facilitate the selection process. Another serious design aspect in FL-empowered IIoT networks is edge device failure, which causes severe fluctuations in production quality. The authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib86" title="" class="ltx_ref">86</a>]</cite> shed light on such aspects and propose an anomaly detection framework that uses FL to train edge devices to predict abnormalities, enabling enhanced communication efficiency.</p>
</div>
</section>
<section id="S4.SS1.SSS5.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_font_bold ltx_title_paragraph"> Healthcare applications</h5>

<div id="S4.SS1.SSS5.Px2.p1" class="ltx_para">
<p id="S4.SS1.SSS5.Px2.p1.1" class="ltx_p">FL has become very popular in the field of healthcare applications <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib87" title="" class="ltx_ref">87</a>]</cite>. Pandemics negatively affect human health and cause negative impacts on economics. Recently, Covid-19 swept the world, causing health problems and mortality. Covid-19’s primary manifestation is pneumonia which is detected using X-ray scanning. ML can play a vital role in such medical cases, in which collected data can be exploited to train an ML model that can predict the infectious state. By emphasising that patient data across different medical centres should be handled privately, the FL setting is the natural option for such applications. Therefore, Liu <em id="S4.SS1.SSS5.Px2.p1.1.1" class="ltx_emph ltx_font_italic">et al.</em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib88" title="" class="ltx_ref">88</a>]</cite> applied FL to datasets of various clinical centres; FL clients exploited the available local X-ray images of Covid-19 cases at each hospital to train a model that helps practitioners to determine if a patient has been infected, without leaking any personal information.</p>
</div>
</section>
<section id="S4.SS1.SSS5.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_font_bold ltx_title_paragraph"> Financial Perspective</h5>

<div id="S4.SS1.SSS5.Px3.p1" class="ltx_para">
<p id="S4.SS1.SSS5.Px3.p1.1" class="ltx_p">The financial sector plays a central role in all societies. In particular, the dependency on credit cards has exponentially increased in recent years, facilitating everyday life. Security attacks constitute a major threat to credit card systems, resulting in critical information leakage and money loss. Currently, banks utilise their datasets individually to develop centralised ML algorithms for fraud detection to mitigate such threats, but this was unavailing as the datasets did not help create an accurate model due to their insufficiency. To overcome this challenge, the work in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib89" title="" class="ltx_ref">89</a>]</cite> presented a framework that depends on FL to build a fraud detection system that is collaboratively trained using datasets from multiple banks. The problem is that the number of fraudulent transactions is too small compared with legitimate transactions; this can obstruct FL performance. To this end, the synthetic minority over-sampling technique (SMOTE) is used to oversample the minority class by producing synthetic datasets that can be used to train the FL model for enhanced model inference.</p>
</div>
</section>
</section>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS2.4.1.1" class="ltx_text">IV-B</span> </span><span id="S4.SS2.5.2" class="ltx_text ltx_font_italic">FL Potential Future Applications</span>
</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">After describing FL and presenting its applications in various wireless networks, we outline some prospective application scenarios in new and promising areas. Our vision is primarily inspired by the applications anticipated to be inherent in B5G and 6G networks.</p>
</div>
<section id="S4.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS2.SSS1.4.1.1" class="ltx_text">IV-B</span>1 </span>Visible Light Communications (VLCs)</h4>

<div id="S4.SS2.SSS1.p1" class="ltx_para">
<p id="S4.SS2.SSS1.p1.1" class="ltx_p">VLC is a new nascent wireless communication technology that relies on the visible spectrum for data transmission. VLC exploits the advantageous properties of light-emitting diodes (LEDs), such as low-power consumption, high brightness, and a long lifetime, to provide high data rate, low latency, and green indoor communications <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib90" title="" class="ltx_ref">90</a>]</cite>. VLC will play a major role in relieving the pressure on the scarce spectrum of the current wireless networks and provide a new connectivity method for the ever-increasing IoT devices. Fig. <a href="#S4.F5" title="Figure 5 ‣ IV-B1 Visible Light Communications (VLCs) ‣ IV-B FL Potential Future Applications ‣ IV FL APPLICATIONS IN WIRELESS NETWORKS ‣ Edge-Native Intelligence for 6G Communications Driven by Federated Learning: A Survey of Trends and Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> represents the VLC communication system that consists of LED units, called APs, connected to a gateway that, in turn, is connected to the external network through wired or wireless links. As a subfield of AI, FL will have a role to play in promoting VLC applications. The features that characterise VLC systems, including high spatial reuse, ultra-low-latency, ultra-high-data rates, and inherent security, provide the ingredients needed for the efficient implementation of FL algorithms <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib91" title="" class="ltx_ref">91</a>]</cite>. The main purpose of FL is to secure data privacy and reduce communication overhead. Accordingly, in the VLC network, the external server can be the FL server, and the deployed indoor devices can play the role of FL clients. In this case, clients may leverage the fast, secure, and reliable transmission environment to update the global model through the gateway, while the FL server can reach the required level of convergence faster.</p>
</div>
<figure id="S4.F5" class="ltx_figure"><img src="/html/2111.07392/assets/x5.png" id="S4.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="230" height="127" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.2.1.1" class="ltx_text" style="font-size:90%;">Figure 5</span>: </span><span id="S4.F5.3.2" class="ltx_text" style="font-size:90%;">VLC system uses visible light as a medium for communication for wireless devices.</span></figcaption>
</figure>
<div id="S4.SS2.SSS1.p2" class="ltx_para">
<p id="S4.SS2.SSS1.p2.1" class="ltx_p">FL training latency highly depends on client selection and scheduling. Therefore, how to properly select FL clients in the VLC network is an important question that needs to be addressed. Besides, as the number of participants increases, the global model can better infer accuracies. Nevertheless, the field of view of the LED units is limited and covers a limited number of clients so that a few devices can participate in the FL training process. To increase the number of participants in the VLC network, the HFL can be utilised, where the APs are used to aggregate the model updates of the clients under their coverage. Once this step is completed, the APs send the aggregated models to the central FL server. One interesting application of FL in VLC is predicting when an LED will stop illuminating due to, for example, LED life expiration or LED light-off time and instructing the endpoints to an alternate connection. Additionally, FL can play a major role in predicting clients’ mobility, LED beam assignment, and client-LED association, to name a few.</p>
</div>
<figure id="S4.F6" class="ltx_figure"><img src="/html/2111.07392/assets/x6.png" id="S4.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="195" height="146" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F6.2.1.1" class="ltx_text" style="font-size:90%;">Figure 6</span>: </span><span id="S4.F6.3.2" class="ltx_text" style="font-size:90%;">Cell-free mMIMO network which shows number of UEs surrounded by many APs.</span></figcaption>
</figure>
</section>
<section id="S4.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS2.SSS2.4.1.1" class="ltx_text">IV-B</span>2 </span>Cell-Free Massive MIMO (CFmMIMO)</h4>

<div id="S4.SS2.SSS2.p1" class="ltx_para">
<p id="S4.SS2.SSS2.p1.1" class="ltx_p">The implementation of massive multiple-input multiple-output (mMIMO) networks includes two types based on the antenna deployment strategy: collocated and distributed antenna setup. The collocated type is easier to implement and has low data sharing overhead, which requires less backhaul. In contrast, the distributed implementation is more complex but gives the network an improved performance, especially in coverage gain. Recently, a new promising technology called CFmMIMO has been proposed as an incarnation of the distributed antenna setup <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib92" title="" class="ltx_ref">92</a>]</cite>. CFmMIMO constitutes a radical change in the cellular network paradigm as it eliminates the concept of cells. Many small, simple, geographically distributed BSs, called APs, jointly serve a small number of UEs using the same time-frequency resources via time division duplexing. APs are connected to a CPU through backhaul links and use the fronthaul to serve the UEs simultaneously, as shown in Fig. <a href="#S4.F6" title="Figure 6 ‣ IV-B1 Visible Light Communications (VLCs) ‣ IV-B FL Potential Future Applications ‣ IV FL APPLICATIONS IN WIRELESS NETWORKS ‣ Edge-Native Intelligence for 6G Communications Driven by Federated Learning: A Survey of Trends and Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>. CFmMIMO enhances the UEs connectivity by eliminating inter-cell interference and reducing the path attenuation due to the presence of the UEs near the APs.</p>
</div>
<div id="S4.SS2.SSS2.p2" class="ltx_para">
<p id="S4.SS2.SSS2.p2.1" class="ltx_p">CFmMIMO embraces distinct features that have a significant advantage in favour of FL. One such features is channel hardening <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib93" title="" class="ltx_ref">93</a>]</cite>, which means that the fading channel will behave as an almost deterministic scalar channel. Channel hardening greatly benefits FL, especially when selecting the clients to participate in the training process. Selecting UEs with stable connections eliminates any unfavourable transmission failure when uploading local updates to the FL server, i.e., CPU, thereby enhancing the FL performance. Moreover, when many APs surround the UEs, this will lead to high coverage gain and reduced distance between the UE and the AP. As a result, this will facilitate training the global model that requires a large number of clients to participate in the training process, thus reducing training latency and improving performance. Furthermore, FL can realise potential applications in CFmMIMO, for instance, creating FL models capable of assigning users to the optimal APs that fulfil the desired QoS by measuring the received signal strength of many surrounding APs. On the other hand, FL can be used to alleviate the congestion on the APs by training a model that can monitor, predict, and distribute UEs to APs in a way that maintains network performance.</p>
</div>
</section>
<section id="S4.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS2.SSS3.4.1.1" class="ltx_text">IV-B</span>3 </span>Satellite-Aerial-Terrestrial Networks</h4>

<div id="S4.SS2.SSS3.p1" class="ltx_para">
<p id="S4.SS2.SSS3.p1.1" class="ltx_p">Terrestrial cellular networks aim to serve populated regions while building such networks to serve sparsely populated areas like islands, oceans, and mountains is impractical. Satellite communication systems address this issue by providing rural areas with network connectivity. However, the quality of satellite links is not guaranteed due to challenges such as large path loss and limited UE power transmission. For this reason, the research has been directed toward utilising aerial platforms to aid satellite communications. High altitude platforms (HAPs) can be used to provide broadband services over a large coverage area <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib94" title="" class="ltx_ref">94</a>]</cite>. Moreover, HAPs provide more reliable communication links than terrestrial networks because they are less susceptible to ground blockages and multipath signal effects. Integrating the aerial-satellite network forms a space-backbone network layer that can provide wireless connectivity to ground users anywhere. As a result, the hybrid satellite-aerial-terrestrial networks have drawn the research community’s attention for further improvements, which are envisioned to be an essential part of the B5G/6G networks. Fig. <a href="#S4.F7" title="Figure 7 ‣ IV-B3 Satellite-Aerial-Terrestrial Networks ‣ IV-B FL Potential Future Applications ‣ IV FL APPLICATIONS IN WIRELESS NETWORKS ‣ Edge-Native Intelligence for 6G Communications Driven by Federated Learning: A Survey of Trends and Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> represents the topology of the satellite-aerial-terrestrial network.</p>
</div>
<figure id="S4.F7" class="ltx_figure"><img src="/html/2111.07392/assets/x7.png" id="S4.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="230" height="144" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F7.2.1.1" class="ltx_text" style="font-size:90%;">Figure 7</span>: </span><span id="S4.F7.3.2" class="ltx_text" style="font-size:90%;">Illustration of satellite-aerial-terrestrial integrated networks. Satellites are used as a relay for communication between UAVs and terrestrial BS.</span></figcaption>
</figure>
<div id="S4.SS2.SSS3.p2" class="ltx_para">
<p id="S4.SS2.SSS3.p2.1" class="ltx_p">Recently, ML techniques have been considered in solving challenges related to satellite communications <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib95" title="" class="ltx_ref">95</a>]</cite>. Employing FL in satellite-aerial-terrestrial networks is still in its infancy; thus, there is plenty of room to explore the potential of FL in such networks. For instance, FL can tackle the network’s limited resources, security, and energy usage challenges. Furthermore, satellite and aerial platforms have received significant attention due to their ability to deliver services in emergency scenarios such as disaster relief, and rescue missions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib96" title="" class="ltx_ref">96</a>]</cite>. To achieve this, it is necessary to maintain robust and reliable communication between satellite, aerial, and ground-based networks. For instance, the terrestrial networks may be overloaded or destroyed if a large-scale disaster occurs, demanding a rapid establishment of a network to serve the afflicted area. Airborne vehicles can cover and monitor this area and send information to an emergency centre. However, in some cases, the vehicles may be outside the coverage of terrestrial BS; therefore, the vehicles can establish a connection with a satellite to act as a relay point between the air vehicle and the terrestrial BS, as demonstrated in Fig.<a href="#S4.F7" title="Figure 7 ‣ IV-B3 Satellite-Aerial-Terrestrial Networks ‣ IV-B FL Potential Future Applications ‣ IV FL APPLICATIONS IN WIRELESS NETWORKS ‣ Edge-Native Intelligence for 6G Communications Driven by Federated Learning: A Survey of Trends and Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>. Airborne vehicles provide the needed multimodal information; however, transferring a large amount of data burdens the communication links and consumes much time, which is critical in such situations. In this case, employing FL can eliminate the drawbacks. Equipping the vehicles with a pre-trained FL object detection and localisation model allows for sending lower-size vital information to locate survivors. Simultaneously, the vehicles can train the model using the collected data to enhance its accuracy and then send the model updates to the FL server. Accordingly, saving time and relieves communication links.</p>
</div>
</section>
<section id="S4.SS2.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS2.SSS4.4.1.1" class="ltx_text">IV-B</span>4 </span>Semantic Communication</h4>

<div id="S4.SS2.SSS4.p1" class="ltx_para">
<p id="S4.SS2.SSS4.p1.1" class="ltx_p">The main theme of communication systems up to 5G networks was to ensure the correct reception of every single transmitted bit, regardless of the meaning conveyed by the transmitted bits. However, this classical communication-theoretic framework does not meet the aspiration of B5G/6G networks, as the research community agrees on the need to upgrade this framework to a smarter and more informative one. The overlooked meaning behind transmitted data is expected to play a significant role in next-generation communication systems, forming an interface between machine intelligence and human intelligence. Therefore, considering data content’s high-level meaning or relevance to support machine-intelligent services necessitates a shift from semantic-neural toward semantic communication systems <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib97" title="" class="ltx_ref">97</a>]</cite>.</p>
</div>
<div id="S4.SS2.SSS4.p2" class="ltx_para">
<p id="S4.SS2.SSS4.p2.1" class="ltx_p">The interplay between human beings and AI has resulted in many revolutionary applications like virtual reality (VR)/augmented reality (AR) and haptic communications. Several studies have begun to envision the integration of FL with semantic communications, VR/AR, and haptic communications. Similarly, in this article, we discuss several wireless scenarios where FL can be applied in these emerging fields. In semantic communications, using FL helps improve the network’s BW utilisation by training a model that can extract relevant/contextual information from the data and filter out irrelevant information. FL-based semantic communication can effectively preserve the network’s resources by transmitting semantic information rather than bits or symbols. On the other hand, VR/AR are real-time technologies that bridge the real and digital worlds by replacing or enhancing the physical environment with a computer-generated one. In the AR/VR environment, detecting users’ movement and location is essential and heavily influences the wireless network’s resources. FL is effective in predicting user movement and actions, which can be used to optimise the allocation of wireless resources to users <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib98" title="" class="ltx_ref">98</a>]</cite>. Finally, haptic communications bring a new dimension over conventional communication modalities by enabling real-time haptic experiences between tactile parties. Haptic communication will have diverse applications, particularly in industry and health sectors, which poses a critical need to protect such communications. FL is a vital tool for securing haptic-based applications through training an ML model that can discriminate between genuine and counterfeit actions based on previous signatures and warn the system of possible suspicious measures.</p>
</div>
</section>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">FL CHALLENGES</span>
</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">Deploying FL in various fields demonstrates its efficiency and highlights its main advantages. However, the successful implementation of FL is restricted by some challenges and limitations that must be resolved to realise its full potential. In this section, we articulate the most common challenges of FL and outline their proposed solutions. Table <a href="#S5.T2" title="Table II ‣ Peer-to-Peer approach ‣ V-A Server Centralisation ‣ V FL CHALLENGES ‣ Edge-Native Intelligence for 6G Communications Driven by Federated Learning: A Survey of Trends and Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a> summarises the key FL challenges and the associated solutions.</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS1.4.1.1" class="ltx_text">V-A</span> </span><span id="S5.SS1.5.2" class="ltx_text ltx_font_italic">Server Centralisation</span>
</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">The performance of employing FL depends by large on the server and the participants. The bottleneck of either classical FL or HFL systems relies on the dependency on a centralised server to orchestrate the learning process, representing a single point of failure. Additionally, the large number of model updates sent to the central server can overwhelm the network, resulting in traffic congestion and degrading the network performance. Two approaches were used to address this challenge, namely blockchain and peer-to-peer.</p>
</div>
<section id="S5.SS1.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_font_bold ltx_title_paragraph">Blockchain approach</h5>

<div id="S5.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="S5.SS1.SSS0.Px1.p1.1" class="ltx_p">Adopting FL systems integrated with blockchain instead of a central server avoids malfunctions that may result from using a single centralised server. Blockchain has been widely used in the literature <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib65" title="" class="ltx_ref">65</a>, <a href="#bib.bib71" title="" class="ltx_ref">71</a>]</cite>, where it can provide a distributed, end-to-end trustworthy training environment. The blockchain consists of miners and devices; miners can be randomly selected devices or separate nodes (such as cellular BSs or WiFi APs) that are computationally powerful to perform the mining process. The operation of blockchain-based FL systems can be summarised as follows: the process begins at the participating devices by computing and sending the local model updates to the associated miner in the blockchain network. Next, miners verify and exchange the local model updates using one of the consensus algorithms, generating a new block where the verified updates are recorded. Finally, the generated blocks that store the model updates are added to the blockchain and can be downloaded by the devices to perform the next round of computation. Leveraging the blockchain will not adversely impact the overall network system when a failure or malfunction happens in a miner, making the FL system more robust.</p>
</div>
</section>
<section id="S5.SS1.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_font_bold ltx_title_paragraph">Peer-to-Peer approach</h5>

<div id="S5.SS1.SSS0.Px2.p1" class="ltx_para">
<p id="S5.SS1.SSS0.Px2.p1.1" class="ltx_p">The study in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib99" title="" class="ltx_ref">99</a>]</cite> proposed a new technique called BrainTorrent, in which a centralised server is not required. This technique is aimed at medical applications where data sharing is prohibited due to privacy concerns. According to the authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib99" title="" class="ltx_ref">99</a>]</cite>, BrainTorrent is a peer-to-peer procedure where each centre shares its model updates directly with the others without needing a central body to coordinate the process. Initially, every client maintains a version of the trained and old models. One of the clients in the network initiates the training process by sending ping requests to all other clients to update the model. Other clients will respond by sending their model weights and the training sample size. Then, the model weights are aggregated and averaged at the request initiator based on the clients’ dataset size to produce a new version of the trained model, followed by repeating the process until a certain level of accuracy is attained. The main drawback of this technique is that it is feasible for networks containing a limited number of clients, while in an environment with a large set of clients, such a technique is impractical.</p>
</div>
<figure id="S5.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S5.T2.2.1.1" class="ltx_text" style="font-size:90%;">Table II</span>: </span><span id="S5.T2.3.2" class="ltx_text" style="font-size:90%;">Summary of FL challenges, impacts, and proposed solutions.</span></figcaption><img src="/html/2111.07392/assets/x8.png" id="S5.T2.g1" class="ltx_graphics ltx_centering ltx_img_square" width="406" height="430" alt="[Uncaptioned image]">
</figure>
</section>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS2.4.1.1" class="ltx_text">V-B</span> </span><span id="S5.SS2.5.2" class="ltx_text ltx_font_italic">Clients Selection</span>
</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">To recall, the FL process consists of three main phases: selection, configuration, and reporting <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>. These three phases are performed iteratively until the FL model achieves a satisfying level of model accuracy. In the selection phase, the server determines the optimum users allowed to participate in the training process according to predefined selection criteria, i.e. whether or not the device is available and its resources. Concerning clients, two main factors directly impact the model convergence speed and efficiency.</p>
</div>
<section id="S5.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S5.SS2.SSS1.4.1.1" class="ltx_text">V-B</span>1 </span><span id="S5.SS2.SSS1.5.2" class="ltx_text ltx_font_bold">Clients heterogeneity</span>
</h4>

<div id="S5.SS2.SSS1.p1" class="ltx_para">
<p id="S5.SS2.SSS1.p1.1" class="ltx_p">In practical wireless networks, end devices have different hardware characteristics and experience varying channel transmission conditions, in addition to data heterogeneity. For instance, clients with high hardware capabilities and high-quality data can produce a well-trained model in a relatively short period compared to others. Furthermore, clients experiencing good transmission circumstances support low latency model transmission, enabling timely parameter aggregation. Failing to consider these aspects will reduce the efficiency of the FL training process. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib100" title="" class="ltx_ref">100</a>]</cite>, a participant selection scheme based on the available client resources has been proposed. Rather than selecting random clients, this scheme sends a resource request to the clients to collect information about their hardware specifications, communication reliability, and data availability. Based on this information, the server estimates the time required to complete a specific task and then selects clients that will participate in the following training round accordingly. In a similar context, the scheme in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib67" title="" class="ltx_ref">67</a>]</cite> relies on selecting local models based on the clients’ computation capability and data quality.</p>
</div>
</section>
<section id="S5.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S5.SS2.SSS2.4.1.1" class="ltx_text">V-B</span>2 </span><span id="S5.SS2.SSS2.5.2" class="ltx_text ltx_font_bold">Clients incentivisation</span>
</h4>

<div id="S5.SS2.SSS2.p1" class="ltx_para">
<p id="S5.SS2.SSS2.p1.1" class="ltx_p">FL depends on the participants and the on-device datasets. The high computation resources and valuable data attract FL to select these clients for training. However, nothing forces the end device to participate in a learning process that will deplete its resources and leads to unsolicited costs. Thus, a reward procedure must be considered to encourage the end devices to participate in the FL training process. In this context, various client incentivisation schemes are released <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib65" title="" class="ltx_ref">65</a>, <a href="#bib.bib71" title="" class="ltx_ref">71</a>, <a href="#bib.bib101" title="" class="ltx_ref">101</a>]</cite>. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite>, a loyalty program based on the blockchain technique is presented to motivate users with large samples of useful data to participate in FL training. According to their contribution, the loyalty program rewards the participants, attracting users with high data quality to participate in the training process.</p>
</div>
<div id="S5.SS2.SSS2.p2" class="ltx_para">
<p id="S5.SS2.SSS2.p2.1" class="ltx_p">Furthermore, a two-tier RL-based incentive mechanism is presented in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib71" title="" class="ltx_ref">71</a>]</cite>. The two-tier RL mechanism enables obtaining the best scenarios for the task publisher and clients in a dynamic environment by encouraging the workers to provide high-quality model training when explicit network parameters are unavailable. The reward of each client is maximised based on the contribution provided to enhance the global model. The work in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib102" title="" class="ltx_ref">102</a>]</cite> improves the reliability of FL by proposing an incentivisation scheme that combines the client reputation and a contract theory to encourage clients with high-quality data to participate in model learning.</p>
</div>
</section>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS3.4.1.1" class="ltx_text">V-C</span> </span><span id="S5.SS3.5.2" class="ltx_text ltx_font_italic">Data Heterogeniety</span>
</h3>

<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.1" class="ltx_p">Data is the main driver of ML algorithms, and high-accuracy model training requires a large amount of data. Generally, practical datasets are heterogeneous and require pre-processing before they can be used for model training.</p>
</div>
<section id="S5.SS3.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_font_bold ltx_title_paragraph">Data quality</h5>

<div id="S5.SS3.SSS0.Px1.p1" class="ltx_para">
<p id="S5.SS3.SSS0.Px1.p1.1" class="ltx_p">The characteristics of the locally generated data differ from one user to another. Datasets can be classified into two categories, independent and identically distributed (IID) and non-IID data. In practical scenarios, datasets are usually non-IID <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib103" title="" class="ltx_ref">103</a>]</cite>, while most of the existing literature in FL is based on the assumption of IID data. Given data heterogeneity, Ye <em id="S5.SS3.SSS0.Px1.p1.1.1" class="ltx_emph ltx_font_italic">et al.</em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib67" title="" class="ltx_ref">67</a>]</cite> employ a selective model aggregation approach to evaluate the quality of the images and then quantify it. The central server evaluates the image quality based on the clients’ historical records and prepares a contract to select fine clients with fine models. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib77" title="" class="ltx_ref">77</a>]</cite> Dempster_Shafer technique is used at the global node to classify and prioritise the UAV clients into groups according to data quality. The highest priority group can contribute more to model training and produce better model weights.</p>
</div>
<div id="S5.SS3.SSS0.Px1.p2" class="ltx_para">
<p id="S5.SS3.SSS0.Px1.p2.1" class="ltx_p">Fairness in FL has recently received more attention. As data heterogeneity increases among clients, the training process will produce a skewed model that may ignore some of the clients, resulting in fairness issues. A possible solution is to employ the personalisation concept <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib104" title="" class="ltx_ref">104</a>]</cite>, where the global model with coarse-grained features is sent to each participating device, and then the clients train the model using their data to build a model with fine-grained features. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib105" title="" class="ltx_ref">105</a>]</cite>, FairFed, a fairness-aware aggregation algorithm, is proposed. It relies on local debiasing techniques to give slightly higher weights to clients with similar local fairness to the global fairness metric, steering the next model update towards a fair global model. Likewise, the authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib106" title="" class="ltx_ref">106</a>]</cite> consider fairness alongside the client selection problem and introduce a long-term fairness constraint to ensure that the average participation rate per client is no less than the expected guaranteed rate.</p>
</div>
</section>
<section id="S5.SS3.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_font_bold ltx_title_paragraph">Data insufficiency</h5>

<div id="S5.SS3.SSS0.Px2.p1" class="ltx_para">
<p id="S5.SS3.SSS0.Px2.p1.1" class="ltx_p">In some cases, the data collected by the devices may not be large enough to conduct model training. On the other hand, the percentage of high-quality data could be small compared to the total datasets, which affects the model inferencing and classification tasks. The proposed work in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib89" title="" class="ltx_ref">89</a>]</cite> uses the SMOTE technique, which attempts to rebalance the classes in the datasets by oversampling the required features’ data. SMOTE generates new synthesised data examples close to the observed datasets. Another approach that can be used to provide more data samples is based on generative adversarial networks (GANs) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib107" title="" class="ltx_ref">107</a>]</cite>. The goal of GAN models is to study and determine the distribution of the training data samples to generate more close to actual data samples from the estimated distribution.</p>
</div>
</section>
<section id="S5.SS3.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_font_bold ltx_title_paragraph">Data annotation</h5>

<div id="S5.SS3.SSS0.Px3.p1" class="ltx_para">
<p id="S5.SS3.SSS0.Px3.p1.1" class="ltx_p">Most studies considering FL assume a supervised training approach, where the data is processed and classified to facilitate the training process. However, in real situations, most of the generated data is unlabelled; in this case, the unsupervised FL is the method that should be considered. Data annotation is a challenging task that requires high cost and significant effort. The presented work in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib108" title="" class="ltx_ref">108</a>]</cite> uses a pseudo-labelling technique to classify the unlabeled data based on the labelled data. Instead of manually labelling, which is time-consuming and requires much cost and effort, pseudo-labelling gives approximate labels depending on the model trained by the labelled data. The FL algorithm is used to train the model in two phases. First, the global model is trained by the distributed devices’ labelled data until reaching a certain convergence level. Second, improving the performance of the trained global model by training it again using the classified unlabeled data.</p>
</div>
</section>
</section>
<section id="S5.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS4.4.1.1" class="ltx_text">V-D</span> </span><span id="S5.SS4.5.2" class="ltx_text ltx_font_italic">Communication Cost</span>
</h3>

<div id="S5.SS4.p1" class="ltx_para">
<p id="S5.SS4.p1.1" class="ltx_p">The model convergence speed and accuracy in FL highly depend on the hardware specifications of the server and the clients. Despite the recent advancements in the computational and communication capabilities of end devices, model training and transmission overhead over multiple training rounds remain major design issue that potentially affects the global model training quality. Furthermore, a large number of model updates exchanged between the server and the clients can severely exhaust the network communication resources. In the following, we outline the main approaches to tackling this challenge.</p>
</div>
<section id="S5.SS4.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_font_bold ltx_title_paragraph">Models scaling and superposition</h5>

<div id="S5.SS4.SSS0.Px1.p1" class="ltx_para">
<p id="S5.SS4.SSS0.Px1.p1.1" class="ltx_p">Despite the significant advancements in edge computing, the lack of communication resources in current FL-enabled systems seriously affects the latency performance and reduces the model convergence rate. To this end, AirComp has been proposed to provide a co-design approach for the FL aggregation procedure by utilising the superposition nature of radio channels for simultaneously transmitting model updates from different clients <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib109" title="" class="ltx_ref">109</a>]</cite>. Therefore, improving communication efficiency by reducing the required BW resources and providing fast convergence. Later, a new variant of AirComp was introduced, called broadband analog aggregation (BAA) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib110" title="" class="ltx_ref">110</a>]</cite> to cover wideband channels that can carry the multidimensional updates of local models. Furthermore, in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib111" title="" class="ltx_ref">111</a>]</cite>, the authors propose a framework for model aggregation that relies on digital modulation. The proposed scheme utilises a single-bit gradient quantisation and quadrature amplitude modulation at the edge devices to achieve fast model convergence.</p>
</div>
</section>
<section id="S5.SS4.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_font_bold ltx_title_paragraph">Resource allocation</h5>

<div id="S5.SS4.SSS0.Px2.p1" class="ltx_para">
<p id="S5.SS4.SSS0.Px2.p1.1" class="ltx_p">It was demonstrated in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib73" title="" class="ltx_ref">73</a>]</cite> that joint optimisation of onboard computation resources and BW allocation can be a promising solution to the computation/communication overhead in resource-constrained devices. This issue is more pronounced in ultra-dense networks, where an excessive number of model updates must be exchanged for global model convergence, and this further yields traffic congestion. Thus, selecting a subset of clients has proved its efficiency in tackling the communication cost problem. In particular, employing only clients with high-quality data in the training process can speed up the convergence rate. Subsequently, a reduced number of training rounds will be performed. Yao <em id="S5.SS4.SSS0.Px2.p1.1.1" class="ltx_emph ltx_font_italic">et al.</em><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib112" title="" class="ltx_ref">112</a>]</cite> propose a two-stream model approach to reduce the FL communication cost. In this approach, the single model that was typically used to be trained by the clients is replaced by a two-stream model. The authors exploit the transfer learning mechanism and maximum mean discrepancy to force nodes to learn other nodes’ knowledge. The experimental results showed a reduction in the required communication rounds and reduced communication costs.</p>
</div>
</section>
<section id="S5.SS4.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_font_bold ltx_title_paragraph">Gradients compression</h5>

<div id="S5.SS4.SSS0.Px3.p1" class="ltx_para">
<p id="S5.SS4.SSS0.Px3.p1.1" class="ltx_p">Large-scale deployment of FL requires significant communication rounds between the central server and the clients. This necessitates expensive network resources to perform model parameter exchange, which can limit the scalability of the FL system. The work in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib113" title="" class="ltx_ref">113</a>]</cite> significantly reduces communication costs by using deep gradient compression. The work shows that most SGD parameters are redundant, so the compression technique is employed to considerably reduce the number of transmitted parameters while preserving the model’s accuracy. Moreover, the compression minimises the gradients by sending only the necessary gradients to the central server in each round, reducing communication latency and alleviating the utilisation of limited wireless resources. On the other hand, by exploiting non-orthogonal multiple access (NOMA), a new 5G medium access technology that improves spectrum efficiency by allowing simultaneous transmission over the same channel, the work in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib114" title="" class="ltx_ref">114</a>]</cite> proposes a NOMA-enabled adaptive gradient compression FL system. In this work, the authors exploit NOMA and adaptive gradient quantisation and sparsification to facilitate uploading model updates over fading wireless channels.</p>
</div>
</section>
</section>
<section id="S5.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS5.4.1.1" class="ltx_text">V-E</span> </span><span id="S5.SS5.5.2" class="ltx_text ltx_font_italic">FL Latency and Convergence</span>
</h3>

<div id="S5.SS5.p1" class="ltx_para">
<p id="S5.SS5.p1.1" class="ltx_p">The network and devices heterogeneity, data statistics heterogeneity, dynamic wireless environment, and acquiring the CSI are the most important factors influencing FL performance in terms of latency and convergence rate. An appropriate client scheduling mechanism can be the key to an accurate and fast model convergence. The authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib115" title="" class="ltx_ref">115</a>]</cite> formulate an optimisation problem that jointly selects a group of clients with local models that significantly impact the global model and assigns the limited resource blocks to those clients. Furthermore, Huang <em id="S5.SS5.p1.1.1" class="ltx_emph ltx_font_italic">et al.</em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib116" title="" class="ltx_ref">116</a>]</cite> proposed a stochastic client selection algorithm that jointly considers the cumulative effect of participants and selection fairness to maintain a high-quality training performance while ensuring fairness among high-qualified and low-qualified clients. Moreover, enabling edge computing can remarkably reduce the FL latency, in which APs are placed close to the edge device, and hence, reduced latency can be achieved. Within the same context, the authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib117" title="" class="ltx_ref">117</a>]</cite> proposed a framework to reduce the average time per round by considering latency-based scheduling, in which clients are selected based on their computation and communication delay.</p>
</div>
<div id="S5.SS5.p2" class="ltx_para">
<p id="S5.SS5.p2.1" class="ltx_p">Generally, ML algorithms are sensitive to hyperparameters, which play a critical role in the model convergence rate. Therefore, to further reduce FL training latency and enhance the convergence time, careful consideration should be taken in the design of efficient hyperparameters. In this regard, several hyperparameter tuning algorithms have been developed to manage many of these parameters with their wide ranges. This includes Bayesian optimisation, grid search, and random search. The work in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib118" title="" class="ltx_ref">118</a>]</cite> develops a scheme that can efficiently determine the optimum learning rate (LR) values. In the proposed technique, referred as cyclical LR (CLR), the CLR is bounded by a range of carefully selected values, in which its value can vary. This approach aims to avoid random LR initialisation. The presented results in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib118" title="" class="ltx_ref">118</a>]</cite> showed the efficiency of such a technique in reducing the FL latency by minimising the number of training operations while ensuring a particular level of accuracy.</p>
</div>
</section>
<section id="S5.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS6.4.1.1" class="ltx_text">V-F</span> </span><span id="S5.SS6.5.2" class="ltx_text ltx_font_italic">Securing Model Updates</span>
</h3>

<div id="S5.SS6.p1" class="ltx_para">
<p id="S5.SS6.p1.1" class="ltx_p">Although FL is motivated by inherent privacy-preserving and security features, sophisticated intruders can retrieve critical information about the participating nodes from the shared model updates. Besides, malicious devices may opt to participate in the training model process to inject false model updates, affecting the accuracy of the trained model. The following approaches are developed in order to ensure secure model transmission:</p>
</div>
<section id="S5.SS6.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S5.SS6.SSS1.4.1.1" class="ltx_text">V-F</span>1 </span><span id="S5.SS6.SSS1.5.2" class="ltx_text ltx_font_bold">Secure multi-party computation (SMC)</span>
</h4>

<div id="S5.SS6.SSS1.p1" class="ltx_para">
<p id="S5.SS6.SSS1.p1.1" class="ltx_p">A cryptographic protocol that aims to conceal personal information and guarantee zero-knowledge between multiple involved parties <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib119" title="" class="ltx_ref">119</a>]</cite>. Its main idea is to distribute the computation between multiple parties without exposing or moving private information. Its working mechanism can be summarised as follows: first, the participated organisations’ datasets are split and masked by adding random numbers, and then these encoded segments are shared between organisations to perform the required computation, thus guaranteeing data privacy and trust. SMC allows organisations to work together without knowing one anothers’ confidential information.</p>
</div>
</section>
<section id="S5.SS6.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S5.SS6.SSS2.4.1.1" class="ltx_text">V-F</span>2 </span><span id="S5.SS6.SSS2.5.2" class="ltx_text ltx_font_bold">Differential privacy (DP)</span>
</h4>

<div id="S5.SS6.SSS2.p1" class="ltx_para">
<p id="S5.SS6.SSS2.p1.1" class="ltx_p">This approach prevents leaking model parameters to intruders by leveraging artificial noise, which is added to the locally trained model before transmission <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib120" title="" class="ltx_ref">120</a>]</cite>. However, enhanced security comes at the expense of model accuracy; hence, joint optimisation is essential to strike a balance between security and model accuracy. Such technique has been used in the literature, e.g., <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib121" title="" class="ltx_ref">121</a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib71" title="" class="ltx_ref">71</a>]</cite>, in which random Gaussian noise is utilised to enhance the privacy of model parameters.</p>
</div>
</section>
<section id="S5.SS6.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S5.SS6.SSS3.4.1.1" class="ltx_text">V-F</span>3 </span><span id="S5.SS6.SSS3.5.2" class="ltx_text ltx_font_bold">Homomorphic encryption (HE)</span>
</h4>

<div id="S5.SS6.SSS3.p1" class="ltx_para">
<p id="S5.SS6.SSS3.p1.1" class="ltx_p">HE is a key-based security mechanism which allows performing calculations on encrypted data. In the context of FL, participating clients generate public and private keys, where the former is used to encrypt locally trained models. After that, the model updates received from all clients are aggregated on the server side in an encrypted mode. The clients leverage the private keys in order to decrypt the global model updates. Albeit the enhanced security achieved by exploiting the HE mechanism, the computation complexity of the cryptographic operations imposes additional overhead on the resource-constrained clients in terms of time, power consumption, and communication cost. In this regard, Zhang <em id="S5.SS6.SSS3.p1.1.1" class="ltx_emph ltx_font_italic">et al.</em> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib122" title="" class="ltx_ref">122</a>]</cite> proposed a batch encryption
technique, which minimises the encryption and communication cost resulting when using HE. Specifically, each client quantises the gradients to be represented in a low-bit integer format, and then a batch of the encoded gradients is encrypted for transmission. Consequently, the encryption overhead and the size of the total ciphertext will be considerably decreased.</p>
</div>
</section>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span id="S6.1.1" class="ltx_text ltx_font_smallcaps">FUTURE RESEARCH DIRECTIONS</span>
</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">Despite the prospects brought by the advancements of FL, its application is still in its early stages. This necessitates dedicating the research efforts toward addressing the associated challenges and exploring new horizons of implementation possibilities. In the following, we list a number of interesting future research directions.</p>
</div>
<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S6.SS1.4.1.1" class="ltx_text">VI-A</span> </span><span id="S6.SS1.5.2" class="ltx_text ltx_font_italic">Data Freshness</span>
</h3>

<div id="S6.SS1.p1" class="ltx_para">
<p id="S6.SS1.p1.1" class="ltx_p">In information technology, data is marked by the date of its creation and can become meaningless, i.e., outdated. Access to timely information (i.e., data freshness) is paramount for time-based systems driven by datasets <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib123" title="" class="ltx_ref">123</a>]</cite>. In order to quantify the data freshness, the age of information (AoI) metric is introduced <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib124" title="" class="ltx_ref">124</a>]</cite>, and is considered an essential parameter in realistic scenarios of data networks. From the perspective of FL, AoI can be defined as the time that elapses between collecting data from clients and completing the FL training task. Considering applications with tight latency and throughput requirements, e.g., ITS, the AoI becomes crucial in network design principles. Accordingly, future research may focus on proposing novel schemes that select FL clients based on their data freshness to ensure that the required network reliability is achieved. Additionally, distributed client datasets can be highly temporal and change rapidly; thus, incorporating the rapidly changing data and determining the correct timing of model updates is essential to enhance FL performance in highly dynamic environments.</p>
</div>
</section>
<section id="S6.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S6.SS2.4.1.1" class="ltx_text">VI-B</span> </span><span id="S6.SS2.5.2" class="ltx_text ltx_font_italic">Spectrum Sharing</span>
</h3>

<div id="S6.SS2.p1" class="ltx_para">
<p id="S6.SS2.p1.1" class="ltx_p">The widespread use of IoT devices and the new technological trends make the limited spectrum bands insufficient to meet the requirements of BW-hungry applications. To this end, spectrum sharing is proposed to mitigate the pressure on frequency bands by allowing multiple networks to operate using the same portions of the licenced or unlicensed spectrum, provided that they do not interfere with each other <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib125" title="" class="ltx_ref">125</a>]</cite>. Coexisting networks should consider interference problems, i.e., co-channel and adjacent channel interference, addressed by imposing strict rules from telecom regulators. Multiple networks from the same or different technologies can coexist and use the same spectrum band, where this coexistence is categorised into equal and different access rights. The major concerns associated with equal rights coexisted networks are maintaining seamless operation, mitigating harmful interference between them, and ensuring fairness. By exploring the literature, we conclude that it is difficult to satisfy these concerns without the intervention of a third party who must receive information from the coexisting networks and manage transmissions. However, this method is undesirable as it requires information disclosure and incurs additional communication costs. Therefore, the FL algorithm is a potential solution that preserves network data privacy and eliminates the need for a third party. Coexisted networks transmission demands and local spectrum utilisation can collaboratively train a global FL model, for instance, deep RL, to address coexisting issues. This model is fed back to each network to make the right spectrum access decisions.</p>
</div>
</section>
<section id="S6.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S6.SS3.4.1.1" class="ltx_text">VI-C</span> </span><span id="S6.SS3.5.2" class="ltx_text ltx_font_italic">FL at Scale</span>
</h3>

<div id="S6.SS3.p1" class="ltx_para">
<p id="S6.SS3.p1.1" class="ltx_p">The applications mentioned in Section <a href="#S4.SS1" title="IV-A FL State-of-the-Art Applications ‣ IV FL APPLICATIONS IN WIRELESS NETWORKS ‣ Edge-Native Intelligence for 6G Communications Driven by Federated Learning: A Survey of Trends and Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">IV-A</span></span></a> are considered small-scale scenarios. However, many applications require a wide deployment of FL to take advantage of the data collected in different locations. This helps to get feature-rich datasets from extensive scenarios that can train an effective global model. Designing an FL system that covers large-scale environments requires special attention to the FL server capabilities in addition to cellular and backhaul communications. The number of participants can easily reach millions spread in broad areas and produce massive model updates that must be transmitted through the wireless network. Therefore, considering the network’s communication efficiency alongside selecting an FL server with efficient hardware to handle enormous amounts of updates is crucial. To this end, future research should consider wireless network design and the specifications of the FL server suitable for large-scale deployments and develop a technique that intelligently selects the optimum participants among many devices willing to participate promptly.</p>
</div>
</section>
<section id="S6.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S6.SS4.4.1.1" class="ltx_text">VI-D</span> </span><span id="S6.SS4.5.2" class="ltx_text ltx_font_italic">Meta-Learning</span>
</h3>

<div id="S6.SS4.p1" class="ltx_para">
<p id="S6.SS4.p1.1" class="ltx_p">The shortcoming of existing ML techniques, especially DL algorithms, is that they rely on large datasets to develop a good model. In most cases, it is not possible to obtain a high amount of dataset, while in other cases, the number of samples that hold the desired features is small compared to the entire dataset. Therefore, finding a mechanism to train models based only on a small dataset sample is necessary. In light of the preceding discussion, the meta-learning technique is introduced to address data insufficiency <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib126" title="" class="ltx_ref">126</a>]</cite>. Meta-learning, also known as learn to learn, uses the metadata of other tasks, like data patterns, properties of the learning problem, and the algorithm performance to learn how to learn and then learn the new task more efficiently from a small set of data. This new learning method in the FL algorithm is expected to improve its performance in several aspects. First, using only a small amount of data samples in meta-learning leads to a more convenient client selection. Moreover, the operating cost will be reduced, thus saving many resources and training time. The optimal client selection will also lead to rapid model convergence and lower latency which is crucial for B5G and 6G networks. Finally, meta-learning can help adapt the global model to each user, especially when data heterogeneity exists among clients.</p>
</div>
</section>
<section id="S6.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S6.SS5.4.1.1" class="ltx_text">VI-E</span> </span><span id="S6.SS5.5.2" class="ltx_text ltx_font_italic">Modality Agnostic Learning</span>
</h3>

<div id="S6.SS5.p1" class="ltx_para">
<p id="S6.SS5.p1.1" class="ltx_p">In current ML approaches, the models are designed based on the characteristics of input data dedicated to a specific task. However, B5G/6G networks allow the creation of different dataset modalities, such as vision, audio, time series, and point cloud. When a specific model needs to be used with a different data configuration, its architecture must be redesigned. This means that best-practice models cannot be used in different domains without modification. Perceiver <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib127" title="" class="ltx_ref">127</a>]</cite> is an interesting solution proposed to handle the configuration of different data shapes based on Transformers networks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib128" title="" class="ltx_ref">128</a>]</cite>, which are sequence transduction models that rely entirely on the attention mechanism. The usage of Transformers in computer vision has shown their efficiency in classification tasks using considerably lower computation resources. Therefore, utilising dynamic models that suit multimodal inputs, like Perceiver, in the FL setting will help in its realisation and wide adoption to perform different network optimisation tasks that render the network more reliable. In more detail, dynamic models will allow clients with different data shapes to participate in the FL process, facilitating FL operation. This new research direction needs further investigation under the umbrella of FL systems.</p>
</div>
</section>
<section id="S6.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S6.SS6.4.1.1" class="ltx_text">VI-F</span> </span><span id="S6.SS6.5.2" class="ltx_text ltx_font_italic">FL Carbon Footprint</span>
</h3>

<div id="S6.SS6.p1" class="ltx_para">
<p id="S6.SS6.p1.1" class="ltx_p">DL-based approaches are highly dependent on heavy computations, resulting in high power consumption. Higher energy cost increases carbon dioxide equivalent (CO<sub id="S6.SS6.p1.1.1" class="ltx_sub">2</sub>e) emissions, constituting the main reason for climate change <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib129" title="" class="ltx_ref">129</a>]</cite>. Recent studies have been devoted to investigating the impact of ML on Earth’s climate, steering the focus to the environmental effects of training large-scale ML models connected to network grids powered using fossil fuels. The environmental consequences of FL in wireless networks have not been explored much; few studies have recently begun to detail such implications. In addition, the transition from centralised to distributed learning seems more energy efficient. Avoiding transmitting big data to a central location saves much network energy and eliminates the need for cooling and other auxiliary tasks. However, the ML technique and the number of participants determine how efficient the network is. With this in mind, the study in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib130" title="" class="ltx_ref">130</a>]</cite> proposes a sustainable FL-based framework by considering energy harvesting technology. Our vision is that future wireless networks will highly depend on renewable energy resources; for instance, we may see more dependence on solar power at the edge devices. This aspect opens the horizons for exploring FL approaches that can potentially contribute to achieving carbon-friendly wireless networks. To this end, future research should be dedicated to assessing the environmental impacts of FL-empowered networks before being widely used in broader scopes.</p>
</div>
</section>
<section id="S6.SS7" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S6.SS7.4.1.1" class="ltx_text">VI-G</span> </span><span id="S6.SS7.5.2" class="ltx_text ltx_font_italic">Low-Precision FL</span>
</h3>

<div id="S6.SS7.p1" class="ltx_para">
<p id="S6.SS7.p1.1" class="ltx_p">Computational capabilities are a significant factor in determining the best clients involved in the FL process. However, edge devices often have limited computing resources, making implementing FL more complex. For instance, the computational complexity of DL models increases as the model becomes deeper, requiring high-performance hardware, while in reality, resource-limited devices are available. The use of full-precision DL models that perform floating-point mathematical operations is a major reason for the increased computational complexity of such models. Various approaches are introduced to compress deep networks, such as parameter pruning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib131" title="" class="ltx_ref">131</a>]</cite> and parameter quantisation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib132" title="" class="ltx_ref">132</a>]</cite>. Much interest has focused on the model quantisation technique as it produces more compact models than their floating-point counterparts. Binary neural networks (BNN) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib133" title="" class="ltx_ref">133</a>]</cite> is a promising approach that recently emerged to facilitate deploying DL models in resource-limited devices. In BNNs, model weights are quantised using binary values. The merits of BNNs represented in memory saving, computation reduction, and energy efficiency make them appealing for use under the FL setting. The combination of FL and BNNs will form a new low-precision framework that can be used at the edge of wireless networks. Although the usage of BNNs addresses the scalability of the FL process, their performance is degraded compared to other full-precision counterparts. Using BNNs in FL is a promising solution; nonetheless, more research should focus on optimising BNN-based FL frameworks and closing the performance gap.</p>
</div>
</section>
<section id="S6.SS8" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S6.SS8.4.1.1" class="ltx_text">VI-H</span> </span><span id="S6.SS8.5.2" class="ltx_text ltx_font_italic">Digital Twin (DT)</span>
</h3>

<div id="S6.SS8.p1" class="ltx_para">
<p id="S6.SS8.p1.1" class="ltx_p">DT is a technology representing a physical object, service, or even an entire system in its counterpart digital version <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib134" title="" class="ltx_ref">134</a>]</cite>. The DT framework aids the operation of complex systems by providing insights into how these assets behave under various simulated circumstances that will help improve decision-making and optimise these systems. As reported by Gartner, DT is envisioned to be one of the most influential industry 4.0 technologies in the next decade. Furthermore, DT is a data-driven technology that can provide system operation excellency by leveraging real-time analysis when paired with AI. However, The DT faces the challenges associated with big data and privacy protection. Accordingly, a novel collaborative paradigm can be achieved when fusing FL with DT systems to meet these challenges. As two emerging and promising techniques, FL and DT can help reduce wireless networks’ operation complexity and realise 6G-based IoE applications <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib135" title="" class="ltx_ref">135</a>]</cite>. Despite the literature’s scarcity of works that leverage such fusion, it is envisioned to become an essential part of the next generations of wireless networks. Future research may consider using FL with DT to share knowledge between DT nodes and develop a common understanding. In addition, the DT can assist FL tasks, for example, by quantifying the DT node’s trust and selecting clients based on the degree of trust.</p>
</div>
</section>
<section id="S6.SS9" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S6.SS9.4.1.1" class="ltx_text">VI-I</span> </span><span id="S6.SS9.5.2" class="ltx_text ltx_font_italic">FL Task-Reward Announcement</span>
</h3>

<div id="S6.SS9.p1" class="ltx_para">
<p id="S6.SS9.p1.1" class="ltx_p">FL model training depends on the participating clients’ resources and the corresponding on-device datasets. Data quality differs from client to client based on usage, and behaviour <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib136" title="" class="ltx_ref">136</a>]</cite>. The selection of devices is based on predefined conditions like being connected to an unmetered network, idle, and in a charging state. Moreover, choosing the optimal clients for a particular task helps relieve the pressure on wireless spectrum resources by lowering the training rounds required in FL and improving network latency. However, to encourage users to participate in the FL process, a reward mechanism should be developed to compensate for their consumed resources and data used while training. How to determine and select participants based on their resources and data quality is ongoing research. FL task-reward announcement is a necessary approach. With an effective announcement technique, users with high-quality data and resources may be encouraged to make themselves ready to participate in the FL process by matching the terms of participation required to receive some rewards. Announcement techniques can enhance the overall performance of the FL system.</p>
</div>
</section>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VII </span><span id="S7.1.1" class="ltx_text ltx_font_smallcaps">CONCLUSIONS</span>
</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">The emergence of FL and its distinctive features pave the way for numerous advancements in the industry. Motivated by the various implementation scenarios in different wireless networks, we conducted a survey demonstrating the salient merits of FL. In this context, this review paper presented the basic operational principles of FL and discussed the essential enabling technologies. This is followed by a discussion of state-of-the-art wireless network applications optimised by utilising the FL mechanism. Moreover, we shed light on promising research directions that may unlock the potential of FL in new areas of B5G and 6G wireless communication systems. Furthermore, we focused on the challenges associated with implementing FL and outlined the techniques used to address those challenges in literature, and then we offered insights to improve the design of the FL algorithm. We believe that the way this survey is harmonised can offer a firm understanding of FL usage in various areas, facilitating the focus on new research directions.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_font_smallcaps ltx_title_section">Acknowledgement</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">This article is supported by Ajman University Internal Research Grant No. 2022-IRG-ENIT-18. The research findings presented in this article are solely the author(s) responsibility.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
D. Gil <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Internet of things: A review of surveys based on
context aware intelligent services,” <em id="bib.bib1.2.2" class="ltx_emph ltx_font_italic">Sensors</em>, vol. 16, no. 7, p.
1069, July 2016.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Z. Rehena, “Internet of Things,” <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Interoperability IoT Smart Syst.</em>,
p. 1, Dec. 2020.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
M. Shafi <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “5G: A tutorial overview of standards, trials,
challenges, deployment, and practice,” <em id="bib.bib3.2.2" class="ltx_emph ltx_font_italic">IEEE J. Sel. Areas Commun.</em>,
vol. 25, no. 6, pp. 1201–1221, Apr. 2017.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
H. N. Dai <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Big data analytics for large scale wireless
networks: Challenges and opportunities,” <em id="bib.bib4.2.2" class="ltx_emph ltx_font_italic">ACM Comput. Surv.</em>, vol. 52,
no. 5, pp. 1–36, Sept. 2019.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
M. Obschonka and D. B. Audretsch, “Artificial intelligence and big data in
entrepreneurship: a new era has begun,” <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Small Business Economics</em>, pp.
1–11, June 2019.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
P. P. Shinde and S. Shah, “A review of machine learning and deep learning
applications,” in <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Proc. Fourth int. conf. comput. commun. control
automat. (ICCUBEA), Pune, India</em>, Aug. 2018, pp. 1–6.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
P. Li <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Multi-key privacy-preserving deep learning in cloud
computing,” <em id="bib.bib7.2.2" class="ltx_emph ltx_font_italic">Future Generation Comput. Syst.</em>, vol. 74, pp. 76–85,
Sept. 2017.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
B. McMahan <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Communication-efficient learning of deep networks
from decentralized data,” in <em id="bib.bib8.2.2" class="ltx_emph ltx_font_italic">Proc. Int. Conf. Artif. Intell.
Statist.</em>   PMLR, Apr. 2017, pp.
1273–1282.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Q. Yang <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Federated machine learning: Concept and
applications,” <em id="bib.bib9.2.2" class="ltx_emph ltx_font_italic">ACM Trans. Intell. Syst. and Technol. (TIST)</em>, vol. 10,
no. 2, Jan. 2019.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
J. Park, S. Samarakoon, M. Bennis, and M. Debbah, “Wireless network
intelligence at the edge,” <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">Proc. IEEE</em>, vol. 107, no. 11, pp.
2204–2239, Oct. 2019.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
P. Kairouz <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Advances and open problems in federated learning,”
<em id="bib.bib11.2.2" class="ltx_emph ltx_font_italic">arXiv:1912.04977</em>, Dec. 2019. [Online]. Available:
http://arxiv.org/abs/1912.04977

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
L. Lyu, H. Yu, and Q. Yang, “Threats to federated learning: A survey,”
<em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">arXiv:2003.02133</em>, Mar. 2020. [Online]. Available:
https://arxiv.org/abs/2003.02133

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
T. Li <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Federated learning: Challenges, methods, and future
directions,” <em id="bib.bib13.2.2" class="ltx_emph ltx_font_italic">IEEE Signal Process.</em>, vol. 37, no. 3, pp. 50–60, May
2020.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Z. Du <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Federated learning for vehicular internet of things:
Recent advances and open issues,” <em id="bib.bib14.2.2" class="ltx_emph ltx_font_italic">IEEE Open J. Comput. Soc.</em>, vol. 1,
pp. 45–61, May 2020.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
M. Aledhari <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Federated learning: A survey on enabling
technologies, protocols, and applications,” <em id="bib.bib15.2.2" class="ltx_emph ltx_font_italic">IEEE Access</em>, vol. 8,
pp. 140 699–140 725, July 2020.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
V. Kulkarni, M. Kulkarni, and A. Pant, “Survey of personalization techniques
for federated learning,” in <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">Proc. Fourth World Conf. Smart Trends
Syst., Sec. and Sustain. (WorldS4)</em>, July 2020.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
W. Yang <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Federated learning in mobile edge networks: A
comprehensive survey,” <em id="bib.bib17.2.2" class="ltx_emph ltx_font_italic">IEEE Commun. Surv. Tuts.</em>, vol. 22, no. 3, pp.
2031–2063, July-Sept. 2020.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
M. Chen <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Wireless communications for collaborative federated
learning,” <em id="bib.bib18.2.2" class="ltx_emph ltx_font_italic">IEEE Communi. Mag.</em>, vol. 58, no. 12, pp. 48–54, Dec.
2020.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Q. Li <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “A survey on federated learning systems: vision, hype and
reality for data privacy and protection,” <em id="bib.bib19.2.2" class="ltx_emph ltx_font_italic">arXiv:1907.09693</em>, Jan.
2021. [Online]. Available: http://arxiv.org/abs/1907.09693

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
O. A. Wahab <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Federated machine learning: Survey, multi-level
classification, desirable criteria and future directions in communication and
networking systems,” <em id="bib.bib20.2.2" class="ltx_emph ltx_font_italic">IEEE Commun. Surv. Tuts.</em>, pp. 1–1, Feb. 2021.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
S. Abdulrahman <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “A survey on federated learning: The journey
from centralized to distributed on-site learning and beyond,” <em id="bib.bib21.2.2" class="ltx_emph ltx_font_italic">IEEE
Internet Things J.</em>, vol. 8, no. 7, pp. 5476–5497, Apr. 2021.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
L. U. Khan <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Federated learning for internet of things: Recent
advances, taxonomy, and open challenges,” <em id="bib.bib22.2.2" class="ltx_emph ltx_font_italic">IEEE Commun. Surv. &amp;
Tuts.</em>, June 2021.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Z. Yang <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Federated learning for 6G: Applications, challenges,
and opportunities,” <em id="bib.bib23.2.2" class="ltx_emph ltx_font_italic">Eng.</em>, Dec. 2021.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
A. Z. Tan <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Towards personalized federated learning,”
<em id="bib.bib24.2.2" class="ltx_emph ltx_font_italic">IEEE Trans. Neural Netw. Learn. Syst.</em>, Mar. 2022.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
B. Ghimire and D. B. Rawat, “Recent advances on federated learning for
cybersecurity and cybersecurity for federated learning for internet of
things,” <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">IEEE Internet Things J.</em>, June 2022.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
M. Hao <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Efficient and privacy-enhanced federated learning for
industrial artificial intelligence,” <em id="bib.bib26.2.2" class="ltx_emph ltx_font_italic">IEEE Trans. on Ind. Informat.</em>,
vol. 16, no. 10, pp. 6532–6542, Oct. 2019.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
M. Salehi <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Hierarchical federated learning across heterogeneous
cellular networks,” in <em id="bib.bib27.2.2" class="ltx_emph ltx_font_italic">Proc. IEEE Int. Conf. Acoust. Speech and
Signal Process. (ICASSP), Barcelona, Spain</em>, May 2020, pp. 8866–8870.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Y. Luo and J. Wang, “Technical introduction of wireless mesh network,”
<em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">Monitoring and Control (ANMC) Cooperate: Xi’an Technological University
(CHINA) West Virginia University (USA) Huddersfield University of UK (UK)</em>,
p. 73, June 2021.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
H. B. McMahan <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Federated learning of deep networks using model
averaging,” <em id="bib.bib29.2.2" class="ltx_emph ltx_font_italic">arXiv:1602.05629</em>, Feb. 2016. [Online]. Available:
http://arxiv.org/abs/1602.05629

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
K. Bonawitz <em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Towards federated learning at scale: System
design,” <em id="bib.bib30.2.2" class="ltx_emph ltx_font_italic">arXiv:1902.01046</em>, Feb. 2019. [Online]. Available:
https://arxiv.org/abs/1902.01046

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
F. Lai <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Oort: Informed participant selection for scalable
federated learning,” <em id="bib.bib31.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2010.06081</em>, Oct. 2020.
[Online]. Available: https://arxiv.org/abs/2010.06081

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
M. R. Sprague <em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Asynchronous federated learning for geospatial
applications,” in <em id="bib.bib32.2.2" class="ltx_emph ltx_font_italic">Proc. Conf. Mach. Learn. Knowl. Discov.
Databases</em>.   Springer, Nov. 2018, pp.
21–28.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
J. Nguyen <em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Federated learning with buffered asynchronous
aggregation,” in <em id="bib.bib33.2.2" class="ltx_emph ltx_font_italic">Int. Conf. Artif. Intell. Stat.</em>   PMLR, May 2022, pp. 3581–3607.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
M. Chen, B. Mao, and T. Ma, “FedSA: A staleness-aware asynchronous federated
learning algorithm with non-IID data,” <em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">Future Generation Computer
Systems</em>, vol. 120, pp. 1–12, July 2021.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
W. Wu <em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “SAFA: A semi-asynchronous protocol for fast federated
learning with low overhead,” <em id="bib.bib35.2.2" class="ltx_emph ltx_font_italic">IEEE Trans. Computers</em>, vol. 70, no. 5,
pp. 655–668, May 2020.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
S. Ruder, “An overview of gradient descent optimization algorithms,”
<em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1609.04747</em>, Sept. 2016. [Online]. Available:
https://arxiv.org/abs/1609.04747

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
T. Li <em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Federated optimization in heterogeneous networks,”
<em id="bib.bib37.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1812.06127</em>, 2018. [Online]. Available:
https://arxiv.org/abs/1812.06127

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
R. Pathak and M. J. Wainwright, “FedSplit: An algorithmic framework for fast
federated optimization,” <em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2005.05238</em>, May 2020.
[Online]. Available: https://arxiv.org/abs/2005.05238

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
S. Reddi <em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Adaptive federated optimization,” <em id="bib.bib39.2.2" class="ltx_emph ltx_font_italic">arXiv
preprint arXiv:2003.00295</em>, Feb. 2020. [Online]. Available:
https://arxiv.org/abs/2003.00295

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
D. Basu <em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Qsparse-local-SGD: Distributed SGD with
quantization, sparsification, and local computations,” <em id="bib.bib40.2.2" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:1906.02367</em>, June 2019. [Online]. Available:
https://arxiv.org/abs/1906.02367

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
J. Hamer, M. Mohri, and A. T. Suresh, “Fedboost: A communication-efficient
algorithm for federated learning,” in <em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">Proc. Int. Conf. Mach.
Learn.</em>   PMLR, Nov. 2020, pp.
3973–3983.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
M. Al-Quraan <em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Fedtrees: A novel computation-communication
efficient federated learning framework investigated in smart grids,”
<em id="bib.bib42.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2210.00060</em>, Oct. 2022. [Online]. Available:
http://arxiv.org/abs/2210.00060

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
D. Lhuissier, “Etsi - multi-access edge computing - standards for MEC,”
2021. [Online]. Available:
https://www.etsi.org/technologies/multi-access-edge-computing?jjj=1622661275132

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
C. S. Wright, “Bitcoin: A peer-to-peer electronic cash system,”
<em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">Available at SSRN 3440802</em>, Oct. 2008.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
K. Toyoda and A. N. Zhang, “Mechanism design for an incentive-aware
blockchain-enabled federated learning platform,” in <em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">Proc. IEEE Int.
Conf. Big Data (Big Data), Los Angeles, CA, USA</em>, Dec. 2019, pp. 395–403.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
D. C. Nguyen <em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Federated learning meets blockchain in edge
computing: Opportunities and challenges,” <em id="bib.bib46.2.2" class="ltx_emph ltx_font_italic">IEEE Internet Things J.</em>,
Apr. 2021.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
Y. Zhao <em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Privacy-preserving blockchain-based federated learning
for IoT devices,” <em id="bib.bib47.2.2" class="ltx_emph ltx_font_italic">IEEE Internet Things J.</em>, vol. 8, no. 3, pp.
1817–1829, Aug. 2020.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
M. Aloqaily, I. Al Ridhawi, and M. Guizani, “Energy-aware blockchain and
federated learning-supported vehicular networks,” <em id="bib.bib48.1.1" class="ltx_emph ltx_font_italic">IEEE Trans. Intell.
Transp. Syst.</em>, Aug. 2021.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
Y. Lu <em id="bib.bib49.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Blockchain and federated learning for 5G beyond,”
<em id="bib.bib49.2.2" class="ltx_emph ltx_font_italic">IEEE Netw.</em>, vol. 35, no. 1, pp. 219–225, Jan./Feb. 2021.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
X. Foukas, G. Patounas, A. Elmokashfi, and M. K. Marina, “Network slicing in
5G: Survey and challenges,” <em id="bib.bib50.1.1" class="ltx_emph ltx_font_italic">IEEE Commun. Mag.</em>, vol. 55, no. 5, pp.
94–100, May 2017.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
B. Brik and A. Ksentini, “On predicting service-oriented network slices
performances in 5G: A federated learning approach,” in <em id="bib.bib51.1.1" class="ltx_emph ltx_font_italic">Proc. 45th
IEEE Conf. Local Comput. Netw. (LCN), Sydney, NSW, Australia</em>, Nov. 2020,
pp. 164–171.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
H. P. Phyu, D. Naboulsi, and R. Stanica, “Mobile traffic forecasting for
network slices: A federated-learning approach,” in <em id="bib.bib52.1.1" class="ltx_emph ltx_font_italic">Proc. 33rd Int.
Symp. Pers. Indoor Mobile Radio Commun. (PIMRC)</em>.   IEEE, Sept. 2022.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
S. Messaoud <em id="bib.bib53.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Deep federated Q-learning-based network slicing
for industrial IoT,” <em id="bib.bib53.2.2" class="ltx_emph ltx_font_italic">IEEE Trans. Ind. Inform.</em>, vol. 17, no. 8, pp.
5572–5582, Oct. 2020.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock">
Y. Liu <em id="bib.bib54.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Device association for RAN slicing based on hybrid
federated deep reinforcement learning,” <em id="bib.bib54.2.2" class="ltx_emph ltx_font_italic">IEEE Trans. Veh. Technol</em>,
vol. 69, no. 12, pp. 15 731–15 745, Dec. 2020.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
A. Aissioui <em id="bib.bib55.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “On enabling 5G automotive systems using follow
me edge-cloud concept,” <em id="bib.bib55.2.2" class="ltx_emph ltx_font_italic">IEEE Trans. Veh. Technol.</em>, vol. 67, no. 6,
pp. 5302–5316, Feb. 2018.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock">
T. Subramanya and R. Riggio, “Centralized and federated learning for
predictive VNF autoscaling in multi-domain 5G networks and beyond,”
<em id="bib.bib56.1.1" class="ltx_emph ltx_font_italic">IEEE Trans. Netw. Service Manag.</em>, vol. 18, no. 1, pp. 63–78, Mar.
2021.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock">
Y. Wei <em id="bib.bib57.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Federated learning empowered end-edge-cloud cooperation
for 5G HetNet security,” <em id="bib.bib57.2.2" class="ltx_emph ltx_font_italic">IEEE Netw.</em>, vol. 35, no. 2, pp. 88–94,
Mar./Apr. 2021.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock">
S. Jere <em id="bib.bib58.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Federated learning in mobile edge computing: An
edge-learning perspective for beyond 5G,” <em id="bib.bib58.2.2" class="ltx_emph ltx_font_italic">arXiv:2007.08030</em>, July
2020. [Online]. Available: https://arxiv.org/abs/2007.08030

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock">
A. M. Elbir and S. Coleri, “Federated learning for channel estimation in
conventional and RIS-assisted massive MIMO,” <em id="bib.bib59.1.1" class="ltx_emph ltx_font_italic">IEEE Trans. Wireless
Commun.</em>, Nov. 2021.

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock">
T. Vu <em id="bib.bib60.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Energy-efficient massive MIMO for serving multiple
federated learning groups,” in <em id="bib.bib60.2.2" class="ltx_emph ltx_font_italic">Proc. Global Commun. Conf. (GLOBECOM),
Madrid, Spain</em>.   IEEE, Dec. 2021, pp.
1–6.

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock">
D. Yu <em id="bib.bib61.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Optimizing over-the-air computation in IRS-aided C-RAN
systems,” in <em id="bib.bib61.2.2" class="ltx_emph ltx_font_italic">21st Int. Workshop Signal Process. Adv. Wireless Commun.
(SPAWC), Atlanta, GA, USA</em>.   IEEE, May
2020, pp. 1–5.

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[62]</span>
<span class="ltx_bibblock">
S. Manzoor <em id="bib.bib62.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Federated learning empowered mobility-aware
proactive content offloading framework for fog radio access networks,”
<em id="bib.bib62.2.2" class="ltx_emph ltx_font_italic">Future Gener. Comput. Syst.</em>, vol. 133, pp. 307–319, Aug. 2022.

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[63]</span>
<span class="ltx_bibblock">
Z. Ji and Z. Qin, “Federated learning for distributed energy-efficient
resource allocation,” <em id="bib.bib63.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2204.09602</em>, Apr. 2022.
[Online]. Available: http://arxiv.org/abs/2204.09602

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[64]</span>
<span class="ltx_bibblock">
A. Hammoud <em id="bib.bib64.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “AI, blockchain, and vehicular edge computing for
smart and secure IoV: Challenges and directions,” <em id="bib.bib64.2.2" class="ltx_emph ltx_font_italic">IEEE Internet
Things Mag.</em>, vol. 3, no. 2, pp. 68–73, June 2020.

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[65]</span>
<span class="ltx_bibblock">
S. R. Pokhrel and J. Choi, “Federated learning with blockchain for autonomous
vehicles: Analysis and design challenges,” <em id="bib.bib65.1.1" class="ltx_emph ltx_font_italic">IEEE Trans. Commun.</em>,
vol. 68, no. 8, pp. 4734–4746, Aug. 2020.

</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[66]</span>
<span class="ltx_bibblock">
S. Samarakoon, M. Bennis, W. Saad, and M. Debbah, “Distributed federated
learning for ultra-reliable low-latency vehicular communications,”
<em id="bib.bib66.1.1" class="ltx_emph ltx_font_italic">IEEE Trans. Commun.</em>, vol. 68, no. 2, pp. 1146–1159, Nov. 2019.

</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[67]</span>
<span class="ltx_bibblock">
D. Ye <em id="bib.bib67.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Federated learning in vehicular edge computing: A
selective model aggregation approach,” <em id="bib.bib67.2.2" class="ltx_emph ltx_font_italic">IEEE Access</em>, vol. 8, pp.
23 920–23 935, Jan. 2020.

</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[68]</span>
<span class="ltx_bibblock">
Y. M. Saputra <em id="bib.bib68.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Federated learning meets contract theory:
Economic-efficiency framework for electric vehicle networks,” <em id="bib.bib68.2.2" class="ltx_emph ltx_font_italic">IEEE
Trans. Mobile Comput.</em>, pp. 1–1, Dec. 2020.

</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[69]</span>
<span class="ltx_bibblock">
B. Qolomany <em id="bib.bib69.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Particle swarm optimized federated learning for
industrial IoT and smart city services,” in <em id="bib.bib69.2.2" class="ltx_emph ltx_font_italic">Proc. IEEE Global
Commun. Conf. (GLOBECOM)</em>, Dec. 2020, pp. 1–6.

</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[70]</span>
<span class="ltx_bibblock">
A. Rovira-Sugranes <em id="bib.bib70.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “A review of AI-enabled routing protocols
for UAV networks: Trends, challenges, and future outlook,” <em id="bib.bib70.2.2" class="ltx_emph ltx_font_italic">arXiv
preprint arXiv:2104.01283</em>, Apr. 2021. [Online]. Available:
http://arxiv.org/abs/2104.01283

</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[71]</span>
<span class="ltx_bibblock">
Y. Wang <em id="bib.bib71.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Learning in the air: Secure federated learning for
UAV-assisted crowdsensing,” <em id="bib.bib71.2.2" class="ltx_emph ltx_font_italic">IEEE Trans. Netw. Sci. Eng.</em>, pp. 1–1,
Aug. 2021.

</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[72]</span>
<span class="ltx_bibblock">
Y. Liu <em id="bib.bib72.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Federated learning in the sky: Aerial-ground air
quality sensing framework with UAV swarms,” <em id="bib.bib72.2.2" class="ltx_emph ltx_font_italic">IEEE Internet Things
J.</em>, Sept. 2020.

</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[73]</span>
<span class="ltx_bibblock">
S. Tang <em id="bib.bib73.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Battery-constrained federated edge learning in
UAV-enabled IoT for B5G/6G networks,” <em id="bib.bib73.2.2" class="ltx_emph ltx_font_italic">arXiv:2101.12472</em>, Jan.
2021. [Online]. Available: https://arxiv.org/abs/2101.12472

</span>
</li>
<li id="bib.bib74" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[74]</span>
<span class="ltx_bibblock">
H. Zhang and L. Hanzo, “Federated learning assisted multi-UAV networks,”
<em id="bib.bib74.1.1" class="ltx_emph ltx_font_italic">IEEE Trans. Veh. Technol.</em>, vol. 69, no. 11, pp. 14 104–14 109, Nov.
2020.

</span>
</li>
<li id="bib.bib75" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[75]</span>
<span class="ltx_bibblock">
W. Ni <em id="bib.bib75.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Optimal transmission control and learning-based
trajectory design for UAV-assisted detection and communication,” in
<em id="bib.bib75.2.2" class="ltx_emph ltx_font_italic">Proc. IEEE 31st Ann. Int. Symp. Pers., Indoor Mobile Radio Commun.
(PIMRC), London, UK</em>, Oct. 2020, pp. 1–6.

</span>
</li>
<li id="bib.bib76" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[76]</span>
<span class="ltx_bibblock">
H. A. B. Salameh <em id="bib.bib76.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Jamming-aware simultaneous multi-channel
decisions for opportunistic access in delay-critical IoT-based sensor
networks,” <em id="bib.bib76.2.2" class="ltx_emph ltx_font_italic">IEEE Sensors J.</em>, vol. 22, no. 3, pp. 2889–2898, Dec.
2021.

</span>
</li>
<li id="bib.bib77" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[77]</span>
<span class="ltx_bibblock">
N. I. Mowla <em id="bib.bib77.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Federated learning-based cognitive detection of
jamming attack in flying Ad-Hoc network,” <em id="bib.bib77.2.2" class="ltx_emph ltx_font_italic">IEEE Access</em>, vol. 8,
pp. 4338–4350, Dec. 2019.

</span>
</li>
<li id="bib.bib78" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[78]</span>
<span class="ltx_bibblock">
E. Basar <em id="bib.bib78.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Wireless communications through reconfigurable
intelligent surfaces,” <em id="bib.bib78.2.2" class="ltx_emph ltx_font_italic">IEEE Access</em>, vol. 7, pp. 116 753–116 773,
Aug. 2019.

</span>
</li>
<li id="bib.bib79" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[79]</span>
<span class="ltx_bibblock">
K. Yang <em id="bib.bib79.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Federated machine learning for intelligent IoT via
reconfigurable intelligent surface,” <em id="bib.bib79.2.2" class="ltx_emph ltx_font_italic">IEEE Netw.</em>, vol. 34, no. 5, pp.
16–22, Sept. 2020.

</span>
</li>
<li id="bib.bib80" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[80]</span>
<span class="ltx_bibblock">
H. Liu, X. Yuan, and Y.-J. A. Zhang, “Reconfigurable intelligent surface
enabled federated learning: A unified communication-learning design
approach,” <em id="bib.bib80.1.1" class="ltx_emph ltx_font_italic">IEEE Trans. Wireless Commun.</em>, June 2021.

</span>
</li>
<li id="bib.bib81" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[81]</span>
<span class="ltx_bibblock">
H. Liu, X. Yuan, and Y. A. Zhang, “CSIT-Free federated edge learning via
reconfigurable intelligent surface,” <em id="bib.bib81.1.1" class="ltx_emph ltx_font_italic">arXiv:2102.10749</em>, Feb. 2021.
[Online]. Available: https://arxiv.org/abs/2102.10749

</span>
</li>
<li id="bib.bib82" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[82]</span>
<span class="ltx_bibblock">
L. Li <em id="bib.bib82.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Enhanced reconfigurable intelligent surface assisted
mmWave communication: A federated learning approach,” <em id="bib.bib82.2.2" class="ltx_emph ltx_font_italic">Chin.
Commun.</em>, vol. 17, no. 10, pp. 115–128, Oct. 2020.

</span>
</li>
<li id="bib.bib83" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[83]</span>
<span class="ltx_bibblock">
Y. Shaikh <em id="bib.bib83.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Survey of smart healthcare systems using internet of
things IoT,” in <em id="bib.bib83.2.2" class="ltx_emph ltx_font_italic">Proc. IEEE Int. Conf. Commun. Comput. Internet
Things (IC3IoT), Chennai, India</em>, Feb. 2018, pp. 508–513.

</span>
</li>
<li id="bib.bib84" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[84]</span>
<span class="ltx_bibblock">
L. Romeo <em id="bib.bib84.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Internet of robotic things in smart domains:
Applications and challenges,” <em id="bib.bib84.2.2" class="ltx_emph ltx_font_italic">Sensors</em>, vol. 20, no. 12, p. 3355, Jan.
2020.

</span>
</li>
<li id="bib.bib85" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[85]</span>
<span class="ltx_bibblock">
I. Mohammed <em id="bib.bib85.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Budgeted online selection of candidate IoT
clients to participate in federated learning,” <em id="bib.bib85.2.2" class="ltx_emph ltx_font_italic">IEEE Internet Things
J.</em>, vol. 8, no. 7, pp. 5938 – 5952, Apr. 2020.

</span>
</li>
<li id="bib.bib86" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[86]</span>
<span class="ltx_bibblock">
Y. Liu <em id="bib.bib86.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Deep anomaly detection for time-series data in
industrial IoT: A communication-efficient on-device federated learning
approach,” <em id="bib.bib86.2.2" class="ltx_emph ltx_font_italic">IEEE Internet Things J.</em>, vol. 8, no. 8, pp. 6348 – 6358,
Apr. 2020.

</span>
</li>
<li id="bib.bib87" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[87]</span>
<span class="ltx_bibblock">
Y. Chen <em id="bib.bib87.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Fedhealth: A federated transfer learning framework for
wearable healthcare,” <em id="bib.bib87.2.2" class="ltx_emph ltx_font_italic">IEEE Intell. Syst.</em>, vol. 35, no. 4, pp. 83–93,
Apr. 2020.

</span>
</li>
<li id="bib.bib88" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[88]</span>
<span class="ltx_bibblock">
B. Liu <em id="bib.bib88.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Experiments of federated learning for COVID-19 chest
X-ray images,” <em id="bib.bib88.2.2" class="ltx_emph ltx_font_italic">arXiv:2007.05592</em>, July 2020. [Online]. Available:
https://arxiv.org/abs/2007.05592

</span>
</li>
<li id="bib.bib89" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[89]</span>
<span class="ltx_bibblock">
W. Yang <em id="bib.bib89.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “FFD: A federated learning based method for credit
card fraud detection,” in <em id="bib.bib89.2.2" class="ltx_emph ltx_font_italic">Proc. Big Data 8th Int. Congr., Services
Conf. Federation, (SCF), San Diego, CA, USA</em>, K. Chen, S. Seshadri, and
L. Zhang, Eds., vol. 11514, June 2019, pp. 18–32.

</span>
</li>
<li id="bib.bib90" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[90]</span>
<span class="ltx_bibblock">
J. Singh <em id="bib.bib90.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Micro-LED as a promising candidate for high-speed
visible light communication,” <em id="bib.bib90.2.2" class="ltx_emph ltx_font_italic">Appl. Sci.</em>, vol. 10, no. 20, p. 7384,
Jan. 2020.

</span>
</li>
<li id="bib.bib91" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[91]</span>
<span class="ltx_bibblock">
S. Idris <em id="bib.bib91.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Visible light communication: A potential 5G and
beyond communication technology,” in <em id="bib.bib91.2.2" class="ltx_emph ltx_font_italic">Proc. 15th Int. Conf. Electron.,
Comput. Comput. (ICECCO), Abuja, Nigeria</em>, Dec. 2019, pp. 1–6.

</span>
</li>
<li id="bib.bib92" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[92]</span>
<span class="ltx_bibblock">
J. Zhang <em id="bib.bib92.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Cell-free massive MIMO: A new next-generation
paradigm,” <em id="bib.bib92.2.2" class="ltx_emph ltx_font_italic">IEEE Access</em>, vol. 7, pp. 99 878–99 888, July 2019.

</span>
</li>
<li id="bib.bib93" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[93]</span>
<span class="ltx_bibblock">
T. L. Marzetta, <em id="bib.bib93.1.1" class="ltx_emph ltx_font_italic">Fundamentals of massive MIMO</em>.   Cambridge University Press, Nov. 2016.

</span>
</li>
<li id="bib.bib94" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[94]</span>
<span class="ltx_bibblock">
T. Tozer and D. Grace, “High-altitude platforms for wireless communications,”
<em id="bib.bib94.1.1" class="ltx_emph ltx_font_italic">Electron. &amp; Commun. Eng. J.</em>, vol. 13, no. 3, pp. 127–137, June 2001.

</span>
</li>
<li id="bib.bib95" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[95]</span>
<span class="ltx_bibblock">
L. Lei <em id="bib.bib95.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Beam illumination pattern design in satellite networks:
Learning and optimization for efficient beam hopping,” <em id="bib.bib95.2.2" class="ltx_emph ltx_font_italic">IEEE Access</em>,
vol. 8, pp. 136 655–136 667, July 2020.

</span>
</li>
<li id="bib.bib96" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[96]</span>
<span class="ltx_bibblock">
M. Azmat and S. Kummer, “Potential applications of unmanned ground and aerial
vehicles to mitigate challenges of transport and logistics-related critical
success factors in the humanitarian supply chain,” <em id="bib.bib96.1.1" class="ltx_emph ltx_font_italic">Asian J. Sustain.
Social Responsib.</em>, vol. 5, no. 1, pp. 1–22, Dec. 2020.

</span>
</li>
<li id="bib.bib97" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[97]</span>
<span class="ltx_bibblock">
Q. Lan <em id="bib.bib97.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “What is semantic communication? a view on conveying
meaning in the era of machine intelligence,” <em id="bib.bib97.2.2" class="ltx_emph ltx_font_italic">J. Commun. Inform.
Netw.</em>, vol. 6, no. 4, pp. 336–371, Dec. 2021.

</span>
</li>
<li id="bib.bib98" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[98]</span>
<span class="ltx_bibblock">
V. Balasubramanian <em id="bib.bib98.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Intelligent resource management at the
edge for ubiquitous IoT: an SDN-based federated learning approach,”
<em id="bib.bib98.2.2" class="ltx_emph ltx_font_italic">IEEE netw.</em>, vol. 35, no. 5, pp. 114–121, Nov. 2021.

</span>
</li>
<li id="bib.bib99" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[99]</span>
<span class="ltx_bibblock">
A. G. Roy <em id="bib.bib99.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “BrainTorrent: A peer-to-peer environment for
decentralized federated learning,” <em id="bib.bib99.2.2" class="ltx_emph ltx_font_italic">arXiv:1905.06731</em>, May 2019.
[Online]. Available: http://arxiv.org/abs/1905.06731

</span>
</li>
<li id="bib.bib100" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[100]</span>
<span class="ltx_bibblock">
T. Nishio and R. Yonetani, “Client selection for federated learning with
heterogeneous resources in mobile edge,” <em id="bib.bib100.1.1" class="ltx_emph ltx_font_italic">IEEE Int. Conf. Commun.
(ICC)</em>, pp. 1–7, May 2019.

</span>
</li>
<li id="bib.bib101" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[101]</span>
<span class="ltx_bibblock">
Y. Zhan <em id="bib.bib101.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “A learning-based incentive mechanism for federated
learning,” <em id="bib.bib101.2.2" class="ltx_emph ltx_font_italic">IEEE Internet Things J.</em>, vol. 7, no. 7, pp. 6360–6368,
Jan. 2020.

</span>
</li>
<li id="bib.bib102" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[102]</span>
<span class="ltx_bibblock">
J. Kang and Xothers, “Incentive mechanism for reliable federated learning: A
joint optimization approach to combining reputation and contract theory,”
<em id="bib.bib102.1.1" class="ltx_emph ltx_font_italic">IEEE Internet Things J.</em>, vol. 6, no. 6, pp. 10 700–10 714, Sept.
2019.

</span>
</li>
<li id="bib.bib103" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[103]</span>
<span class="ltx_bibblock">
H. Yang, M. Fang, and J. Liu, “Achieving linear speedup with partial worker
participation in non-IID federated learning,” <em id="bib.bib103.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:2101.11203</em>, Jan. 2021. [Online]. Available:
http://arxiv.org/abs/2101.11203

</span>
</li>
<li id="bib.bib104" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[104]</span>
<span class="ltx_bibblock">
Q. Wu, K. He, and X. Chen, “Personalized federated learning for intelligent
IoT applications: A cloud-edge based framework,” <em id="bib.bib104.1.1" class="ltx_emph ltx_font_italic">IEEE Open J.
Comput. Soc.</em>, vol. 1, pp. 35–44, Feb. 2020.

</span>
</li>
<li id="bib.bib105" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[105]</span>
<span class="ltx_bibblock">
Y. Ezzeldin <em id="bib.bib105.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “FairFed: Enabling group fairness in federated
learning,” <em id="bib.bib105.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2110.00857</em>, Oct. 2021. [Online].
Available: http://arxiv.org/abs/2110.00857

</span>
</li>
<li id="bib.bib106" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[106]</span>
<span class="ltx_bibblock">
T. Huang <em id="bib.bib106.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “An efficiency-boosting client selection scheme for
federated learning with fairness guarantee,” <em id="bib.bib106.2.2" class="ltx_emph ltx_font_italic">IEEE Trans. Parall.
Distrib. Syst.</em>, vol. 32, no. 7, pp. 1552–1564, Nov. 2020.

</span>
</li>
<li id="bib.bib107" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[107]</span>
<span class="ltx_bibblock">
S. Augenstein <em id="bib.bib107.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Generative models for effective ML on private,
decentralized datasets,” <em id="bib.bib107.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1911.06679</em>, Nov. 2019.
[Online]. Available: http://arxiv.org/abs/1911.06679

</span>
</li>
<li id="bib.bib108" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[108]</span>
<span class="ltx_bibblock">
A. Albaseer <em id="bib.bib108.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Exploiting unlabeled data in smart cities using
federated edge learning,” in <em id="bib.bib108.2.2" class="ltx_emph ltx_font_italic">Proc. 16th Int. Wireless Commun. Mobile
Comput. Conf. (IWCMC), Limassol, Cyprus</em>, June 2020, pp. 1666–1671.

</span>
</li>
<li id="bib.bib109" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[109]</span>
<span class="ltx_bibblock">
K. Yang <em id="bib.bib109.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Federated learning via over-the-air computation,”
<em id="bib.bib109.2.2" class="ltx_emph ltx_font_italic">IEEE Trans. Wireless Commun.</em>, vol. 19, no. 3, pp. 2022–2035, Jan.
2020.

</span>
</li>
<li id="bib.bib110" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[110]</span>
<span class="ltx_bibblock">
G. Zhu, Y. Wang, and K. Huang, “Broadband analog aggregation for low-latency
federated edge learning,” <em id="bib.bib110.1.1" class="ltx_emph ltx_font_italic">IEEE Trans. Wireless Commun.</em>, vol. 19,
no. 1, pp. 491–506, Oct. 2019.

</span>
</li>
<li id="bib.bib111" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[111]</span>
<span class="ltx_bibblock">
G. Zhu <em id="bib.bib111.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “One-bit over-the-air aggregation for
communication-efficient federated edge learning: Design and convergence
analysis,” <em id="bib.bib111.2.2" class="ltx_emph ltx_font_italic">IEEE Trans. Wireless Commun.</em>, vol. 20, no. 3, pp.
2120–2135, Nov. 2020.

</span>
</li>
<li id="bib.bib112" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[112]</span>
<span class="ltx_bibblock">
X. Yao, C. Huang, and L. Sun, “Two-stream federated learning: Reduce the
communication costs,” in <em id="bib.bib112.1.1" class="ltx_emph ltx_font_italic">Proc. IEEE Vis. Commun. Imag. Process.
(VCIP), Taichung, Taiwan</em>, Dec. 2018, pp. 1–4.

</span>
</li>
<li id="bib.bib113" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[113]</span>
<span class="ltx_bibblock">
Y. Lin <em id="bib.bib113.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Deep gradient compression: Reducing the communication
bandwidth for distributed training,” <em id="bib.bib113.2.2" class="ltx_emph ltx_font_italic">arXiv:1712.01887</em>, Dec. 2017.
[Online]. Available: https://arxiv.org/abs/1712.01887

</span>
</li>
<li id="bib.bib114" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[114]</span>
<span class="ltx_bibblock">
H. Sun, X. Ma, and R. Q. Hu, “Adaptive federated learning with gradient
compression in uplink NOMA,” <em id="bib.bib114.1.1" class="ltx_emph ltx_font_italic">IEEE Trans. Veh. Technol.</em>, vol. 69,
no. 12, pp. 16 325–16 329, Sept. 2020.

</span>
</li>
<li id="bib.bib115" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[115]</span>
<span class="ltx_bibblock">
M. Chen <em id="bib.bib115.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Convergence time optimization for federated learning
over wireless networks,” <em id="bib.bib115.2.2" class="ltx_emph ltx_font_italic">IEEE Trans. Wireless Commun.</em>, vol. 20,
no. 4, pp. 2457–2471, Dec. 2020.

</span>
</li>
<li id="bib.bib116" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[116]</span>
<span class="ltx_bibblock">
T. Huang <em id="bib.bib116.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Stochastic client selection for federated learning
with volatile clients,” <em id="bib.bib116.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2011.08756</em>, Nov. 2020.
[Online]. Available: https://arxiv.org/abs/2011.08756

</span>
</li>
<li id="bib.bib117" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[117]</span>
<span class="ltx_bibblock">
W. Xia, W. Wen, K.-K. Wong, T. Q. Quek, J. Zhang, and H. Zhu,
“Federated-learning-based client scheduling for low-latency wireless
communications,” <em id="bib.bib117.1.1" class="ltx_emph ltx_font_italic">IEEE Wireless Commun.</em>, vol. 28, no. 2, pp. 32–38,
May 2021.

</span>
</li>
<li id="bib.bib118" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[118]</span>
<span class="ltx_bibblock">
L. N. Smith, “Cyclical learning rates for training neural networks,” in
<em id="bib.bib118.1.1" class="ltx_emph ltx_font_italic">Proc. IEEE winter conf. appl. comput. vision (WACV), Santa Rosa, CA,
USA</em>, Mar. 2017, pp. 464–472.

</span>
</li>
<li id="bib.bib119" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[119]</span>
<span class="ltx_bibblock">
C. Zhao <em id="bib.bib119.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Secure multi-party computation: theory, practice and
applications,” <em id="bib.bib119.2.2" class="ltx_emph ltx_font_italic">Inform. Sci.</em>, vol. 476, pp. 357–372, Feb. 2019.

</span>
</li>
<li id="bib.bib120" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[120]</span>
<span class="ltx_bibblock">
H. B. McMahan <em id="bib.bib120.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Learning differentially private recurrent
language models,” <em id="bib.bib120.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1710.06963</em>, Oct. 2017.
[Online]. Available: http://arxiv.org/abs/1710.06963

</span>
</li>
<li id="bib.bib121" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[121]</span>
<span class="ltx_bibblock">
Y. Lu <em id="bib.bib121.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Differentially private asynchronous federated learning
for mobile edge computing in urban informatics,” <em id="bib.bib121.2.2" class="ltx_emph ltx_font_italic">IEEE Trans. Ind.
Informat.</em>, vol. 16, no. 3, pp. 2134–2143, Mar. 2020.

</span>
</li>
<li id="bib.bib122" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[122]</span>
<span class="ltx_bibblock">
C. Zhang <em id="bib.bib122.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “BatchCrypt: Efficient homomorphic encryption for
cross-silo federated learning,” in <em id="bib.bib122.2.2" class="ltx_emph ltx_font_italic">Proc. USENIX Annu. Techn. Conf.
(ATC)</em>, July 2020, pp. 493–506.

</span>
</li>
<li id="bib.bib123" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[123]</span>
<span class="ltx_bibblock">
Y. Sun <em id="bib.bib123.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Update or wait: How to keep your data fresh,”
<em id="bib.bib123.2.2" class="ltx_emph ltx_font_italic">IEEE Trans. Inform. Theory</em>, vol. 63, no. 11, pp. 7492–7508, Aug.
2017.

</span>
</li>
<li id="bib.bib124" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[124]</span>
<span class="ltx_bibblock">
M. Costa, M. Codreanu, and A. Ephremides, “On the age of information in status
update systems with packet management,” <em id="bib.bib124.1.1" class="ltx_emph ltx_font_italic">IEEE Trans. Inform. Theory</em>,
vol. 62, no. 4, pp. 1897–1910, Feb. 2016.

</span>
</li>
<li id="bib.bib125" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[125]</span>
<span class="ltx_bibblock">
S. Bayhan, G. Gür, and A. Zubow, “The future is unlicensed: Coexistence in
the unlicensed spectrum for 5G,” <em id="bib.bib125.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1801.04964</em>,
Jan. 2018. [Online]. Available: http://arxiv.org/abs/1801.04964

</span>
</li>
<li id="bib.bib126" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[126]</span>
<span class="ltx_bibblock">
T. Hospedales <em id="bib.bib126.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Meta-learning in neural networks: A survey,”
<em id="bib.bib126.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2004.05439</em>, Apr. 2020. [Online]. Available:
http://arxiv.org/abs/2004.05439

</span>
</li>
<li id="bib.bib127" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[127]</span>
<span class="ltx_bibblock">
A. Jaegle <em id="bib.bib127.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Perceiver: General perception with iterative
attention,” <em id="bib.bib127.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2103.03206</em>, Mar. 2021. [Online].
Available: http://arxiv.org/abs/2103.03206

</span>
</li>
<li id="bib.bib128" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[128]</span>
<span class="ltx_bibblock">
A. Vaswani <em id="bib.bib128.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Attention is all you need,” in <em id="bib.bib128.2.2" class="ltx_emph ltx_font_italic">Proc. Adv.
neural inform. process. syst.</em>, 2017, pp. 5998–6008.

</span>
</li>
<li id="bib.bib129" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[129]</span>
<span class="ltx_bibblock">
C.-J. Wu <em id="bib.bib129.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Sustainable AI: Environmental implications,
challenges and opportunities,” <em id="bib.bib129.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2111.00364</em>, Oct.
2021. [Online]. Available: http://arxiv.org/abs/2111.00364

</span>
</li>
<li id="bib.bib130" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[130]</span>
<span class="ltx_bibblock">
B. Guler and A. Yener, “Sustainable federated learning,” <em id="bib.bib130.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:2102.11274</em>, Feb. 2021. [Online]. Available:
http://arxiv.org/abs/2102.11274

</span>
</li>
<li id="bib.bib131" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[131]</span>
<span class="ltx_bibblock">
Y. He, X. Zhang, and J. Sun, “Channel pruning for accelerating very deep
neural networks,” in <em id="bib.bib131.1.1" class="ltx_emph ltx_font_italic">Proc. IEEE int. conf. comput. vis. (ICCV)</em>, 2017,
pp. 1389–1397.

</span>
</li>
<li id="bib.bib132" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[132]</span>
<span class="ltx_bibblock">
S. Chen, W. Wang, and S. J. Pan, “Metaquant: Learning to quantize by learning
to penetrate non-differentiable quantization,” <em id="bib.bib132.1.1" class="ltx_emph ltx_font_italic">Adv. Neural Inform.
Process. Syst.</em>, vol. 32, pp. 3916–3926, 2019.

</span>
</li>
<li id="bib.bib133" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[133]</span>
<span class="ltx_bibblock">
H. Qin <em id="bib.bib133.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Binary neural networks: A survey,” <em id="bib.bib133.2.2" class="ltx_emph ltx_font_italic">Pattern
Recognit.</em>, vol. 105, p. 107281, Sept. 2020.

</span>
</li>
<li id="bib.bib134" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[134]</span>
<span class="ltx_bibblock">
L. U. Khan <em id="bib.bib134.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Digital-Twin-Enabled 6G: Vision, architectural
trends, and future directions,” <em id="bib.bib134.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2102.12169</em>, Feb.
2021. [Online]. Available: http://arxiv.org/abs/2102.12169

</span>
</li>
<li id="bib.bib135" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[135]</span>
<span class="ltx_bibblock">
H. Sami <em id="bib.bib135.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “AI-based resource provisioning of IoE services in 6G:
A deep reinforcement learning approach,” <em id="bib.bib135.2.2" class="ltx_emph ltx_font_italic">IEEE Trans. Net. Service
Manage.</em>, vol. 18, no. 3, pp. 3527–3540, Mar. 2021.

</span>
</li>
<li id="bib.bib136" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[136]</span>
<span class="ltx_bibblock">
L. L. Pipino, Y. W. Lee, and R. Y. Wang, “Data quality assessment,”
<em id="bib.bib136.1.1" class="ltx_emph ltx_font_italic">Commun. ACM</em>, vol. 45, no. 4, pp. 211–218, Apr. 2002.

</span>
</li>
</ul>
</section>
<figure id="id1" class="ltx_float biography">
<table id="id1.1" class="ltx_tabular">
<tr id="id1.1.1" class="ltx_tr">
<td id="id1.1.1.1" class="ltx_td"><img src="/html/2111.07392/assets/x9.jpg" id="id1.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="101" height="138" alt="[Uncaptioned image]"></td>
<td id="id1.1.1.2" class="ltx_td">
<span id="id1.1.1.2.1" class="ltx_inline-block">
<span id="id1.1.1.2.1.1" class="ltx_p"><span id="id1.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Mohammad M. Al-Quraan</span> 
received the BSc. (Honours) degree in telecommunications engineering and MSc. (Excellence) degree in wireless telecommunications engineering from Yarmouk University, Irbid, Jordan in 2011 and 2019, respectively. From 2012 to 2018, he was a senior network and telecommunications engineer at Jordan University of Science and Technology (JUST). Then until 2020, he has been the head of the network and telecommunications Department at JUST. He is currently pursuing the Ph.D. degree in electronics and electrical engineering at the University of Glasgow, Glasgow, UK. His research interests include machine learning, computer vision, cognitive radio, and beyond 5G wireless technologies.</span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="id2" class="ltx_float biography">
<table id="id2.1" class="ltx_tabular">
<tr id="id2.1.1" class="ltx_tr">
<td id="id2.1.1.1" class="ltx_td"><img src="/html/2111.07392/assets/Figures/Lina_Mohjazi.jpg" id="id2.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="100" height="125" alt="[Uncaptioned image]"></td>
<td id="id2.1.1.2" class="ltx_td">
<span id="id2.1.1.2.1" class="ltx_inline-block">
<span id="id2.1.1.2.1.1" class="ltx_p"><span id="id2.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Lina Mohjazi</span> 
is an Assistant Professor (Lecturer) at the James Watt School of Engineering, University of Glasgow, U.K. She received the B.Sc. (Honours) degree from the United Arab Emirates (UAE) University, UAE, in 2008, the M.Sc. degree from Khalifa University (KU), UAE, in 2012 (Distinction), and the Ph.D. degree from the Institute for Communication Systems, University of Surrey, U.K., in 2018, all in electrical and electronic engineering. Her research interests include beyond 5G wireless technologies, physical-layer optimization and performance analysis, wireless power transfer, machine learning for future wireless systems, and reconfigurable intelligent surfaces. She is an Associate Editor for the IEEE Communications Letters and the IEEE Open Journal of the Communications Society. She is an Affiliate Member of the Mohammed bin Rashid Academy of Scientists, UAE, a Fellow of the Women’s Engineering Society, and a Senior Member of the IEEE.</span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="id3" class="ltx_float biography">
<table id="id3.1" class="ltx_tabular">
<tr id="id3.1.1" class="ltx_tr">
<td id="id3.1.1.1" class="ltx_td"><img src="/html/2111.07392/assets/x10.jpg" id="id3.1.1.1.g1" class="ltx_graphics ltx_img_square" width="111" height="108" alt="[Uncaptioned image]"></td>
<td id="id3.1.1.2" class="ltx_td">
<span id="id3.1.1.2.1" class="ltx_inline-block">
<span id="id3.1.1.2.1.1" class="ltx_p"><span id="id3.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Lina Bariah</span>  received the M.Sc. and Ph.D. degrees in communications engineering from Khalifa University, Abu Dhabi, UAE, in 2015 and 2018, respectively. She was a Visiting Researcher with the Department of Systems and Computer Engineering, Carleton University, Ottawa, ON, Canada, in 2019, and an affiliate research fellow, James Watt School of Engineering, University of Glasgow, UK. She is currently a Senior Researcher at the technology Innovation institute, a visiting research scientist at Khalifa University, and an affiliate researcher in the University at Albany, USA. Dr. Bariah is a senior member of the IEEE, IEEE Communications Society, IEEE Vehicular Technology Society, and IEEE Women in Engineering. She is currently an Associate Editor for the IEEE Communication Letters, an Associate Editor for the IEEE Open Journal of the Communications Society, and an Area Editor for Physical Communication (Elsevier). She is a Guest Editor in IEEE Network Magazine, and the RS Open Journal on Innovative Communication Technologies (RS-OJICT). Dr. Bariah was a member of the technical program committee of a number of IEEE conferences, such as ICC and Globecom. She is currently organizing/chairing a number of workshops. She serves as a session chair and an active reviewer for numerous IEEE conferences and journals.</span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="id4" class="ltx_float biography">
<table id="id4.1" class="ltx_tabular">
<tr id="id4.1.1" class="ltx_tr">
<td id="id4.1.1.1" class="ltx_td"><img src="/html/2111.07392/assets/Figures/Anthony_Centeno.jpg" id="id4.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="95" height="125" alt="[Uncaptioned image]"></td>
<td id="id4.1.1.2" class="ltx_td">
<span id="id4.1.1.2.1" class="ltx_inline-block">
<span id="id4.1.1.2.1.1" class="ltx_p"><span id="id4.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Anthony Centeno</span> 
is currently a lecturer at the University of Glasgow. He has over 25 years’ experience in industry, the UK civil service and academia. His most recent positions prior to joining Glasgow University in 2020 were as an Associate Professor at Xi’an Jiaotong Liverpool University (2017-2020) and the Malaysia-Japan International Institute of Technology (MJIIT) (2012-2017). His research is focussed on applied electromagnetism in high frequency communications, electromagnetic materials, plasmonics and electromagnetic compatibility. He has BEng and PhD degrees from Cardiff University, is a Chartered Engineer, a member of the Institute of Physics and a member of the Institute of Engineering and Technology. He is also a visiting honorary fellow in the Materials Department, Imperial College London.</span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="id5" class="ltx_float biography">
<table id="id5.1" class="ltx_tabular">
<tr id="id5.1.1" class="ltx_tr">
<td id="id5.1.1.1" class="ltx_td"><img src="/html/2111.07392/assets/Figures/Ahmed_Zoha.jpg" id="id5.1.1.1.g1" class="ltx_graphics ltx_img_square" width="100" height="100" alt="[Uncaptioned image]"></td>
<td id="id5.1.1.2" class="ltx_td">
<span id="id5.1.1.2.1" class="ltx_inline-block">
<span id="id5.1.1.2.1.1" class="ltx_p"><span id="id5.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Ahmed Zoha</span> 
earned his PhD in Electrical and Electronics Engineering in July 2014 from the 6G/5GIC Centre, University of Surrey (UniS), UK, and his MSc degree in Communication Engineering from Chalmers University, Sweden. Dr Zoha has research expertise in the areas of artificial intelligence (AI) and machine learning, advanced signal processing, and state-of-the-art self-learning strategies, and he has more than 13 years of experience in designing intelligent applications and algorithms in the domain of 5G and beyond wireless communication systems, connected healthcare, internet of everything and smart energy monitoring systems. His research has been cited by national and international bodies, regulators, and the media, and he has also received two IEEE best paper awards. Dr Zoha is also a recipient of the best presentation award at GPECOMM2022 and two best paper awards at IEEE IS 2012 and IEEE SSNIP 2013 as part of his contribution to the EPSRC-funded project Reshaping Energy Demands using ICT. Dr Zoha is endorsed as a UK exceptional talent by the Royal Academy of Engineering awarded to early-career world-leading innovators and scientists. Dr Zoha has been actively involved in the organization of several IEEE and EAI conferences and served as a chair, and track chair for special sessions as well as a technical programme committee member.</span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="id6" class="ltx_float biography">
<table id="id6.1" class="ltx_tabular">
<tr id="id6.1.1" class="ltx_tr">
<td id="id6.1.1.1" class="ltx_td"><img src="/html/2111.07392/assets/x11.jpg" id="id6.1.1.1.g1" class="ltx_graphics ltx_img_square" width="111" height="110" alt="[Uncaptioned image]"></td>
<td id="id6.1.1.2" class="ltx_td">
<span id="id6.1.1.2.1" class="ltx_inline-block">
<span id="id6.1.1.2.1.1" class="ltx_p"><span id="id6.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Kamran Arshad</span> 
is a Senior Member of the Institute of Electrical and Electronics Engineers (IEEE), currently holds the distinguished position of Dean of Research and Graduate Studies and Professor of Electrical Engineering at Ajman University in the United Arab Emirates. Dr. Arshad has played a pivotal role in leading numerous locally and internationally funded research projects that encompass the fields of cognitive radio, LTE/LTE-Advanced, 5G, optimization, and cognitive machine-to-machine communications. He has made significant contributions to several European and international large-scale research projects and has over 150 technical peer-reviewed articles published in esteemed journals and international conferences. He has been the recipient of three Best Paper Awards, one Best Research and Development Track Award, and has chaired technical sessions in several leading international conferences. Dr. Arshad holds the position of Associate Editor of the Journal on Wireless Communications and Networking (EURASIP).</span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="id7" class="ltx_float biography">
<table id="id7.1" class="ltx_tabular">
<tr id="id7.1.1" class="ltx_tr">
<td id="id7.1.1.1" class="ltx_td"><img src="/html/2111.07392/assets/x12.jpg" id="id7.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="98" height="138" alt="[Uncaptioned image]"></td>
<td id="id7.1.1.2" class="ltx_td">
<span id="id7.1.1.2.1" class="ltx_inline-block">
<span id="id7.1.1.2.1.1" class="ltx_p"><span id="id7.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Khaled Assaleh</span>  is currently the Vice Chancellor for Academic Affairs and a Professor of Electrical Engineering at Ajman University. From 2002 through 2017, he was with the American University of Sharjah (AUS). Prior to joining AUS, Khaled had a 9-year R&amp;D career in the Telecom Industry in the USA with Rutgers, Motorola and Rockwell/Skyworks. He earned his Ph.D. in Electrical Engineering from Rutgers, the State University of New Jersey in 1993; M.S in Electronic Engineering from Monmouth University, New Jersey in 1990; and a B.Sc. in Electrical Engineering from the University of Jordan in 1988. He holds 11 US patents and has published over 130 articles on signal/image processing and machine learning and their applications. He has served on organization committees of several international conferences including ICIP, ISSPA, ICCSPA, MECBME and ISMA. He has also served as a guest editor for several special issues of journals. Dr. Assaleh is a senior member of the IEEE. His research interests include bio-signal processing, biometrics, speech and image processing, and pattern recognition.</span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="id8" class="ltx_float biography">
<table id="id8.1" class="ltx_tabular">
<tr id="id8.1.1" class="ltx_tr">
<td id="id8.1.1.1" class="ltx_td"><img src="/html/2111.07392/assets/x13.jpg" id="id8.1.1.1.g1" class="ltx_graphics ltx_img_square" width="111" height="135" alt="[Uncaptioned image]"></td>
<td id="id8.1.1.2" class="ltx_td">
<span id="id8.1.1.2.1" class="ltx_inline-block">
<span id="id8.1.1.2.1.1" class="ltx_p"><span id="id8.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Sami Muhaidat</span>  received the Ph.D. degree in Electrical and Computer Engineering from the University of Waterloo, Waterloo, Ontario, in 2006. From 2007 to 2008, he was an NSERC Postdoctoral Fellow in the Department of Electrical and Computer Engineering, University of Toronto, Canada. From 2008-2012, he was an Assistant Professor in the School of Engineering Science, Simon Fraser University, BC, Canada. He is currently a Professor at Khalifa University and an Adjunct Professor with Carleton University, Ontario, Canada. Sami’s research interests focus on advanced digital signal processing techniques for wireless communications, intelligent surfaces, MIMO, optical communications, massive multiple access techniques, backscatter communications, and machine learning for communications. He is currently an Area Editor of the IEEE Transactions on Communications, a Guest Editor of the IEEE Network “Native Artificial Intelligence in Integrated Terrestrial and Non-Terrestrial Networks in 6G” special issue, and a Guest Editor of the IEEE OJVT “Recent Advances in Security and Privacy for 6G Networks” special issue. He served as a Senior Editor and Editor of the IEEE Communications Letters, an Editor of the IEEE Transactions on Communications, and an Associate Editor of the IEEE Transactions on Vehicular Technology.</span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="id9" class="ltx_float biography">
<table id="id9.1" class="ltx_tabular">
<tr id="id9.1.1" class="ltx_tr">
<td id="id9.1.1.1" class="ltx_td"><img src="/html/2111.07392/assets/x14.jpg" id="id9.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="110" height="138" alt="[Uncaptioned image]"></td>
<td id="id9.1.1.2" class="ltx_td">
<span id="id9.1.1.2.1" class="ltx_inline-block">
<span id="id9.1.1.2.1.1" class="ltx_p"><span id="id9.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Merouane Debbah</span>  received the M.Sc. and Ph.D. degrees from the Ecole Normale Supérieure Paris-Saclay, France. He was with Motorola Labs, Saclay, France, from 1999 to 2002, and also with the Vienna Research Center for Telecommunications, Vienna, Austria, until 2003. From 2003 to 2007, he was an Assistant Professor with the Mobile Communications Department, Institut Eurecom, Sophia Antipolis, France. In 2007, he was appointed Full Professor at CentraleSupelec, Gif-sur-Yvette, France. From 2007 to 2014, he was the Director of the Alcatel-Lucent Chair on Flexible Radio. From 2014 to 2021, he was Vice-President of the Huawei France Research Center. He was jointly the director of the Mathematical and Algorithmic Sciences Lab as well as the director of the Lagrange Mathematical and Computing Research Center. Since 2021, he is Chief Research Officer at the Technology Innovation Institute in Abu Dhabi. He leads jointly the AI and Telecommunication centers. He has managed 8 EU projects and more than 24 national and international projects. He is an IEEE Fellow, a WWRF Fellow, a Eurasip Fellow, an Institut Louis Bachelier Fellow and a Membre émérite SEE. He was a recipient of the ERC Grant (Advanced Mathematical Tools for Complex Network Engineering) from 2012 to 2017.</span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="id10" class="ltx_float biography">
<table id="id10.1" class="ltx_tabular">
<tr id="id10.1.1" class="ltx_tr">
<td id="id10.1.1.1" class="ltx_td"><img src="/html/2111.07392/assets/Figures/Muhammad_Imran.jpg" id="id10.1.1.1.g1" class="ltx_graphics ltx_img_square" width="100" height="108" alt="[Uncaptioned image]"></td>
<td id="id10.1.1.2" class="ltx_td">
<span id="id10.1.1.2.1" class="ltx_inline-block">
<span id="id10.1.1.2.1.1" class="ltx_p"><span id="id10.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Muhammad Ali Imran</span> 
received the M.Sc. (Hons.) and Ph.D. degrees from Imperial College London, U.K., in 2002 and 2007, respectively. He is currently the Dean of University of Glasgow UESTC, Head of Autonomous Systems and Connectivity Division and a Professor of communication systems with the James Watt School of Engineering, University of Glasgow, U.K. He is an Affiliate Professor at the University of Oklahoma, USA and 5G Innovation Centre, University of Surrey, U.K. He is leading research at the University of Glasgow for Scotland 5G Centre. He has over 20 years of combined academic and industry experience with several leading roles in multi-million pounds funded projects, working primarily in the research areas of cellular communication systems. He has been awarded 10 patents, has authored/co-authored over 500 journals and conference publications, and has supervised more than 50 successful Ph.D. graduates. He has an Award of Excellence in recognition of his academic achievements, conferred by the President of Pakistan. He was awarded the IEEE Comsoc’s Fred Ellersick Award 2014, the FEPS Learning and Teaching Award 2014, and the Sentinel of Science Award 2016. He is a Fellow of Royal Society of Edinburgh, Fellow of the Institution of Engineering and Technology, Fellow of Royal Society of Arts and a Senior Fellow of the Higher Education Academy. He is speciality chief editor for IoT section of Frontiers in Communications and Networks and an Associate Editor for IEEE Transactions on Communications, and previously served in editorial roles for the IEEE Communications Letters, the IEEE Access, and the IET Communications Journals. He is a Senior Member of IEEE.</span>
</span>
</td>
</tr>
</table>
</figure>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2111.07391" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2111.07392" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2111.07392">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2111.07392" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2111.07393" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Tue Mar 12 12:36:54 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
