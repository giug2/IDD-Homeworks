<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2305.08070] A Survey of Federated Evaluation in Federated Learning</title><meta property="og:description" content="In traditional machine learning, it is trivial to conduct model evaluation since all data samples are managed centrally by a server. However, model evaluation becomes a challenging problem in federated learning (FL), w…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="A Survey of Federated Evaluation in Federated Learning">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="A Survey of Federated Evaluation in Federated Learning">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2305.08070">

<!--Generated on Mon Feb 26 20:48:52 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<!--Document created on  %**** ijcai23.tex Line 50 **** .-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">A Survey of Federated Evaluation in Federated Learning</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Behnaz Soltani<sup id="id7.2.id1" class="ltx_sup">1</sup>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yipeng Zhou<sup id="id8.2.id1" class="ltx_sup">1</sup><span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Corresponding author.</span></span></span>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Venus Haghighi<sup id="id9.5.id1" class="ltx_sup">1</sup>&amp;John C.S. Lui<sup id="id10.6.id2" class="ltx_sup">2</sup>
<sup id="id11.7.id3" class="ltx_sup">1</sup> School of Computing, Macquarie University, Sydney, Australia
<br class="ltx_break"><sup id="id12.8.id4" class="ltx_sup">2</sup> Department of Computer Science and Engineering, The Chinese University of Hong Kong, HKSAR
{behnaz.soltani@hdr., yipeng.zhou@, venus.haghighi@hdr.}mq.edu.au,
cslui@cse.cuhk.edu.hk
</span></span>
</div>
<div class="ltx_dates">(November 2022)</div>

<h1 class="ltx_title ltx_title_document">A Survey of Federated Evaluation in Federated Learning</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Behnaz Soltani<sup id="id7.2.id1" class="ltx_sup">1</sup>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yipeng Zhou<sup id="id8.2.id1" class="ltx_sup">1</sup><span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Corresponding author.</span></span></span>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Venus Haghighi<sup id="id9.5.id1" class="ltx_sup">1</sup>&amp;John C.S. Lui<sup id="id10.6.id2" class="ltx_sup">2</sup>
<sup id="id11.7.id3" class="ltx_sup">1</sup> School of Computing, Macquarie University, Sydney, Australia
<br class="ltx_break"><sup id="id12.8.id4" class="ltx_sup">2</sup> Department of Computer Science and Engineering, The Chinese University of Hong Kong, HKSAR
{behnaz.soltani@hdr., yipeng.zhou@, venus.haghighi@hdr.}mq.edu.au,
cslui@cse.cuhk.edu.hk
</span></span>
</div>
<div class="ltx_dates">(November 2022)</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id13.id1" class="ltx_p">In traditional machine learning, it is trivial to conduct model evaluation since all data samples are managed centrally by a server. However, model evaluation becomes a challenging problem in federated learning (FL), which is called <em id="id13.id1.1" class="ltx_emph ltx_font_italic">federated evaluation</em> in this work. This is because clients do not expose their original data to preserve data privacy. Federated evaluation plays a vital role in client selection, incentive mechanism design, malicious attack detection, etc. In this paper, we provide the first comprehensive survey of existing federated evaluation methods. Moreover, we explore various applications of federated evaluation for enhancing FL performance and finally present future research directions by envisioning some challenges.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Recently, federated learning (FL) has emerged as a privacy-preserving framework, in which clients collaboratively train shared machine learning models without exposing their own local data during the training process <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">McMahan </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib35" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2017</span></a>)</cite>.
FL can extensively exploit massive data samples scattered on decentralized clients such as Internet-of-Things (IoTs) and mobile devices for model training <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Zhou </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib53" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2019</span></a>)</cite>. With FL, clients only expose model information rather than original data samples for training models.
More specifically, the FL server distributes the global model to selected clients; participants train local models iteratively on their own data and send their local models to the server; the server aggregates the local models to generate the updated global model. The above steps are repeated for a certain number of iterations.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">In traditional machine learning, it is trivial to conduct model evaluation with centrally collected data samples from clients. Yet, the model evaluation problem becomes very challenging in FL since all data samples are owned and privately retained by clients. Without owning any data, the server cannot manipulate data for model evaluation.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">In FL, model evaluation plays a significant role in model training, which is much more complicated than traditional machine learning.
On the one hand, evaluating a model accurately in FL is essential for designing incentive mechanisms by reasonably rewarding each participating client <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Zhang </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib48" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021a</span></a>); <span class="ltx_text" style="font-size:90%;">Gao </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib13" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>); <span class="ltx_text" style="font-size:90%;">Deng </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib9" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>)</cite>, devising efficient client selection strategies <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Li </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib26" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021a</span></a>); <span class="ltx_text" style="font-size:90%;">Lai </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib24" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>)</cite>, detecting malicious attacks <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Che </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib5" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2022</span></a>); <span class="ltx_text" style="font-size:90%;">Gao </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib13" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>)</cite> and deriving personalized models <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Jia </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib19" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2019</span></a>); <span class="ltx_text" style="font-size:90%;">Huang </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib18" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>)</cite> based on evaluation results. On the other hand, each FL client has a local model trained on their own local data implying that each individual FL client can be evaluated independently. However, without the knowledge about clients’ data, it is a challenging problem to evaluate the importance of clients.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">To make model evaluation feasible in FL, tremendous efforts have been dedicated by existing works. We propose two different ways to categorize existing methods. Firstly, its architecture can be categorized as: centralized federated evaluation and decentralized federated evaluation. The former one assumes that a single FL server or task owner evaluates the quality of FL models. The latter one recruits a number of independent clients to conduct federated evaluation of models in a distributed fashion. Secondly, federated evaluation methods can be categorized based on their evaluation approaches such as data-level evaluation, utility-based approach, Shapley values approach, and statistical metric-based approach.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">To the best of our knowledge, there are no existing works that explore federated
evaluation in different scenarios. To bridge this gap, we review existing methods, survey the applications of federated evaluation results, discuss the challenges of federated evaluation and envision potential future work.
</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Federated Evaluation Architecture</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">In this section, we briefly introduce the workflow of FL and discuss two kinds of federated evaluation architectures: centralized architectures and decentralized architectures.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>FL System</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">In a FL system, there are typically multiple decentralized clients that participate in the training process. Each client owns a training dataset and a test dataset.
The objective of FL clients is to collaboratively train a shared model.
FL is usually conducted for multiple global iterations (a.k.a. rounds). At the beginning of each global iteration, a global model is distributed by the server to participating clients.
On each participating client, the global model is updated with their local dataset to obtain a local model. Then, each client returns model information (e.g. model parameters and model gradients) to the server. The server aggregates collected models from participating clients to update the global model. </p>
</div>
<figure id="S2.F1" class="ltx_figure"><img src="/html/2305.08070/assets/x1.png" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="242" height="184" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>An overview of the federated learning process.</figcaption>
</figure>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">In Fig. <a href="#S2.F1" title="Figure 1 ‣ 2.1 FL System ‣ 2 Federated Evaluation Architecture ‣ A Survey of Federated Evaluation in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, we present a snapshot of FL for a particular global iteration. It is worth noting that:</p>
<ul id="S2.I1" class="ltx_itemize">
<li id="S2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i1.p1" class="ltx_para">
<p id="S2.I1.i1.p1.1" class="ltx_p">In FL, each individual client contributes a local model trained based on private local data. It implies that each model can be evaluated independently.</p>
</div>
</li>
<li id="S2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i2.p1" class="ltx_para">
<p id="S2.I1.i2.p1.1" class="ltx_p">The FL server cannot touch data samples owned by clients, and hence the server is unable to directly conduct evaluation of models. To overcome this shortcoming, the FL server can exploit its auxiliary data or employ statistical methods to evaluate clients.</p>
</div>
</li>
</ul>
<p id="S2.SS1.p2.2" class="ltx_p">Based on Fig. <a href="#S2.F1" title="Figure 1 ‣ 2.1 FL System ‣ 2 Federated Evaluation Architecture ‣ A Survey of Federated Evaluation in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, we broadly discuss how existing works conduct federated evaluation to evaluate models including both the global model and local models in a FL system.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Centralized Federated Evaluation</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">Clients can be evaluated using a single FL server or task owner based on statistical information uploaded by clients. The most straightforward way is to evaluate clients based on their data sizes <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Feng </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib11" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2019</span></a>)</cite>. The server can evaluate clients more accurately if clients can share label distributions to the server <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Ma </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib31" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021a</span></a>)</cite>.
More complicated statistical metrics can be designed to evaluate local models on the server side based on model information (e.g. model parameters and model gradients), which are uploaded from clients to the server <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Deng </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib9" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>); <span class="ltx_text" style="font-size:90%;">Gao </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib13" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>)</cite>.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p">If test data is available at the server, the server can evaluate local models using test data directly, though the assumption that the server holds test data is strong and impracticable in many scenarios.
A number of centralized evaluation methods are introduced as follows.
In <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Zhang </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib48" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021a</span></a>)</cite>, local models are evaluated using the validation set on the server. A key idea here is that if a high-quality local model participates in the aggregation process, the loss value of the global model should be decreased.
FIFL <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Gao </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib13" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>)</cite> defines the marginal test loss to detect malicious clients in FL. It uses the first Taylor’s first-order expansion to simplify its calculation. Therefore, the similarity distance between the local gradients and the server gradient obtained from the test dataset at the server is computed for detecting abnormal local models. In <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Deng </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib9" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>)</cite>, local models are evaluated based on the difference between the average loss value of the global model on the test dataset and the average training loss value of the local models. The evaluation process also takes historical records into account. It allocates larger weights to recent records due to their higher level of informativeness.
Clients are selected with the aim of maximizing the sum of evaluated qualities subject to a budget. The test performance difference with or without a local model is another metric to evaluate the importance of clients <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Kang </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib20" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2019</span></a>)</cite>.</p>
</div>
<div id="S2.SS2.p3" class="ltx_para">
<p id="S2.SS2.p3.1" class="ltx_p">Even if the test data is not available on the server,
clients can still be centrally evaluated using their local model information. For example, the difference between local model parameters before and after a training round is considered as a quality metric evaluated by the server <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Zhao </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib52" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2022</span></a>)</cite>.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Decentralized Federated Evaluation</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">Federated evaluation can be performed on multiple decentralized clients or third parties instead of a single server because of two main reasons: serverless FL and decentrally distributed test data across clients.</p>
</div>
<div id="S2.SS3.p2" class="ltx_para">
<p id="S2.SS3.p2.1" class="ltx_p">In decentralized FL (DFL), there is no dedicated server to conduct centralized evaluation of models <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Su </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib40" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2022</span></a>)</cite>. For example, blockchain-based FL consists of miners and devices without relying on a central server <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Kim </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib23" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2019</span></a>)</cite>. Miners, possibly from clients or third parties’ devices such as base stations, are responsible for evaluating local models in a decentralized manner to exclude malicious attackers.
Only local models that are verified by miners can be recorded in a generated block with a consensus algorithm. A hierarchical blockchain-based architecture is proposed by <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Kang </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib21" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2020a</span></a>)</cite> which utilizes multiple consortium blockchains as subchains to conduct decentralized model evaluation based on model accuracy.
A committee-based serverless FL is designed by <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Che </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib5" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2022</span></a>)</cite>, in which honest clients are selected as committee members to decentrally evaluate local models based on the difference between the local gradients and the committee gradients. Similarly, Refiner <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Zhang </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib50" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021c</span></a>)</cite> selects a committee of randomly selected validators to evaluate local models based on loss values.</p>
</div>
<div id="S2.SS3.p3" class="ltx_para">
<p id="S2.SS3.p3.1" class="ltx_p">When test data is privately distributed on decentralized clients, model evaluation using test data must be performed in a distributed manner on clients.
In this case, it is common to select clients to evaluate model performance using their own test data. The test results can be collected by the server for other purposes. For example, Oort <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Lai </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib24" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>)</cite> selects participants to serve the developer-specified criteria on testing data. FedFomo <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Zhang </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib47" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2020</span></a>)</cite> and L2C <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Li </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib29" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2022</span></a>)</cite> are personalized FL algorithms, which locally evaluate models collected from other clients to locally customize aggregation weights so as to pursue personalized models.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Federated Evaluation Approaches</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Due to the inaccessibility of local data in FL, it is challenging to directly evaluate local models. Therefore, we introduce various approaches for indirect evaluation of models.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Data-level Evaluation</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">Although accessing original data is forbidden in FL, it is still possible to obtain data quantity information from FL clients. To a certain extent, the local model quality can be evaluated by data quantity information.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">In original FL, FedAvg simply uses the local dataset size to determine the aggregation weight of a particular client’s local model <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">McMahan </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib35" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2017</span></a>)</cite>. However, the non-IID (Identical and Independently Distributed) distribution of data across clients can degrade the utility of the model.
In <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Feng </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib11" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2019</span></a>)</cite>, the server negotiates with clients about the sizes of their data, and in return, clients receive rewards based on their data sizes. The goal is to maximize the total amount of training data in order to achieve higher learning accuracy.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.1" class="ltx_p">Later on, more advanced methods are proposed that evaluate the quality of clients based on their data distribution. In <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Li </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib26" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021a</span></a>)</cite>, prior to the training process, the server quantifies the intersection between the label sets of clients and the target label set. Clients with an intersection higher than a specified threshold are considered as relevant clients.
To preserve privacy, the calculation of intersection is performed using a private set intersection (PSI) method <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Agrawal </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib1" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2003</span></a>)</cite>. Next, the server selects clients for training based on their high statistical homogeneity and content diversity.
Statistical homogeneity is evaluated using the similarity between a uniform distribution generated on the server and clients’ distributions based on homomorphic encryption.
Content diversity is evaluated by computing the similarity of clients’ data using a noisy content sketch, which is obtained as follows. Each client generates a content embedding vector for each sample using a general deep learning model. The client’s data is encoded into a low-dimensional vector based on JL-transformation <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Biswas </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib3" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2019</span></a>)</cite> as a content sketch.</p>
</div>
<div id="S3.SS1.p4" class="ltx_para">
<p id="S3.SS1.p4.1" class="ltx_p">Label quantity information can also be utilized to evaluate clients. In a grouping-based mechanism, clients are divided into multiple groups based on their label quantity information shared with the server. Only clients in the same group are selected for training <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Ma </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib31" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021a</span></a>)</cite>. This approach introduces a new metric named Group Earth Mover’s Distance (GEMD) inspired by Earth Mover’s Distance (EMD) <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Zhao </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib51" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2018</span></a>)</cite> to evaluate the difference between the global data distribution and the selected local distributions. A smaller GEMD implies that the data distribution is closer to IID. A pair-wise grouping mechanism is proposed in which each client is initially considered as a separate group. Based on GEMD, each group is merged into a pair iteratively to complement missing labels. The objective is to make the aggregated data distribution close to the global distribution.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Model Utility</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">Similar to traditional machine learning, the quality of a local model can be evaluated based on its utility, which can be measured in terms of the loss value or model accuracy.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">A new client selection framework called Oort has been introduced in <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Lai </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib24" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>)</cite>, which tries to select the most significant clients for training in each global iteration.
Its metric to evaluate a client’s importance is the loss value obtained by training the model with local data on each client.
Based on the aggregate training loss across all data samples, Oort can dedicatedly select the most important clients to participate in FL.
Similarly, FedSAE <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Li </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib27" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021b</span></a>)</cite> evaluates the importance of each client based on the local training loss and the number of local samples. According to the importance values, the server determines the selection probability of each client per global iteration.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.1" class="ltx_p">In <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Wu and Wang</span> (<a href="#bib.bib45" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2022</span></a>)</cite>, an optimal aggregation mechanism is proposed to reduce overall data heterogeneity by excluding adverse local models with the objective of enlarging the expected decrement of the global loss. The proposed method iteratively removes a local model
and compares the expected inner product between the local gradients and the global gradient before and after excluding the local model by assuming that the inner product implicitly represents the difference between local data distributions and global data distribution.
To ensure that excluding local models leads to a faster convergence, global losses are measured for both global models (i.e. with and without the aforementioned local model) using a test dataset. Based on the change of loss values, the decision is made for removing a local model.
A tier-based FL system is proposed in <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Chai </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib4" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2020</span></a>)</cite>, which divides clients into tiers based on their response latencies. Clients from the same tier are selected to participate in FL in case that the training process is slowed down by a slow client. However, a tier-based client selection can incur training bias since a faster tier is prone to be selected with a higher probability. To eliminate bias, the global model is evaluated by each tier to estimate the importance of that tier. The selection probability of a tier is adjusted based on the test accuracy obtained at different rounds.
</p>
</div>
<div id="S3.SS2.p4" class="ltx_para">
<p id="S3.SS2.p4.1" class="ltx_p">Blockchain-based FL is proposed to make the FL process traceable and tamper-proofing without relying on a single server <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Kim </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib23" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2019</span></a>); <span class="ltx_text" style="font-size:90%;">Qu </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib36" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2020</span></a>)</cite>. Blockchain-based FL widely adopts model utility to evaluate the quality of models contributed by clients. Refiner <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Zhang </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib50" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021c</span></a>)</cite> introduces a FL system implemented upon Ethereum, a public blockchain to deal with self-interested and malicious devices. A committee of randomly selected validators are employed to evaluate local models and prevent corrupted local models from participating in the aggregation process. Local models are evaluated by computing the loss function on the validation dataset provided by the FL task owner. If the loss values of the local models are lower than a specified threshold, they will be considered qualified and included in the aggregated global model.
A hierarchical blockchain framework has been introduced in <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Kang </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib21" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2020a</span></a>)</cite>, which consists of a public blockchain as a main blockchain, and multiple consortium blockchains as subchains to store local models for model quality evaluation. In a subchain, the miners evaluate the quality of local models by evaluating their accuracy on a test dataset provided by the FL task owner. Local models are qualified if their accuracy is higher than a defined threshold, which will be recorded in a pending block later.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Shapley Values</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">FL can be regarded as a cooperative game played by multiple FL clients. It is proposed that
Shapley values (SV) <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Jia </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib19" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2019</span></a>); <span class="ltx_text" style="font-size:90%;">Ghorbani and Zou</span> (<a href="#bib.bib14" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2019</span></a>)</cite>, a method in cooperative game theory, can efficiently evaluate the merit of each FL client.
The computation of SV is based on the average contribution (in terms of model utility) of a data source to every subset of data sources. In the computation of SV, it is unnecessary to consider the order of data sources during training. However, the computation complexity of SV is exponential, which makes it unaffordable in reality. Different variants have been devised to approximately compute SV in FL.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.1" class="ltx_p">A variant named federated SV has been introduced in <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Wang </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib44" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2020</span></a>)</cite> which computes SV from local models without extra communication costs. It also captures the effect of the order of participation because data sources employed earlier have more impact on the model performance compared to those used at the end of the training.
The federated SV is estimated using algorithms such as permutation sampling-based approximation and group testing-based approximation. However, federated SV may lead to unfairness on a large scale since only a subset of clients are selected in each round and non-selected ones receive zero credit in the corresponding global iteration. Therefore, clients with identical local data may receive different credits. Completed federated SV has been introduced in <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Fan </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib10" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2022</span></a>)</cite> to address the aforementioned challenges. It introduces a utility matrix that consists of the contributions of all possible subsets of clients across all training iterations. Due to the partially observed utility matrix caused by the partial selection of clients in each round, the goal is to complete missing entries in the utility matrix. To achieve this, a low-rank matrix completion problem is designed. A group-based SV computation for blockchain-based FL is proposed in <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Ma </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib32" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021b</span></a>)</cite>. It divides clients into several groups according to a permutation sample, and the aggregated global model is obtained for each group. A new model is generated by aggregating different group models. Finally, the SV of each group is estimated based on model utility and assigned to its client members.</p>
</div>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Statistical Metric</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p">Models can be indirectly evaluated based on statistical metrics. The most widely used one is
model distance metrics such as distances between model parameters, gradients, or model performances.</p>
</div>
<div id="S3.SS4.p2" class="ltx_para">
<p id="S3.SS4.p2.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Zhao </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib52" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2022</span></a>)</cite> evaluates a local model using the model parameter difference metric before and after a training round. Clients providing higher model parameter divergence are considered to have higher quality, as clients with IID data have larger parameter differences than those with non-IID data. However, clients with large amounts of data can prolong the duration of a round, causing other clients to wait for those slow clients to complete their training. Therefore, a size-related ratio is added to the divergence metric to take into account both data distribution and data size. <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Zhang </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib49" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021b</span></a>)</cite> further proposes to use the model parameter divergence between a local model and a model trained on an auxiliary IID dataset residing on the server to evaluate the degree of non-IID datasets. Clients with a lower degree of non-IID data lead to a lower divergence, which can accelerate the FL convergence.</p>
</div>
<div id="S3.SS4.p3" class="ltx_para">
<p id="S3.SS4.p3.1" class="ltx_p">The quality-aware framework proposed in <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Deng </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib9" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>)</cite> designs a mechanism to remove unreliable local models from the aggregation process. To evaluate the model quality, the framework measures the median, mean, and standard deviation of the cosine similarity between the local model parameters and the global model parameter. Since clients are selected based on the loss reduction during the learning process, the majority of the received updates are expected to be of high quality. Therefore, If the mean is greater than the median, then the similarity values of low-quality models are higher than the median; otherwise, they are lower.
The distance between local and global gradients is computed in <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Gao </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib13" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>)</cite> using the square of the Euclidean norm to evaluate the contribution of clients.
To differentiate between positive and negative contributions, a threshold is set based on the gradient distance. Clients with a gradient distance above the threshold are considered to have a negative contribution, while those below it have a positive contribution.</p>
</div>
<div id="S3.SS4.p4" class="ltx_para">
<p id="S3.SS4.p4.1" class="ltx_p">FOCUS <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Chen </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib7" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2020a</span></a>)</cite> is proposed to evaluate local models by evaluating the quality of local data labels. Each client evaluates the performance of the global model on its local dataset and sends the evaluation results to the server. The server evaluates each local model on its benchmark dataset and calculates the cross entropy between the two sets of evaluation results to measure the quality of the clients’ local labels. In <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Wang </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib43" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2019</span></a>)</cite>, a deletion method is introduced where data samples from each client are deleted, the model is retrained, and the difference in prediction results between the new global model and the original one is computed to determine the contribution of each client.</p>
</div>
<div id="S3.SS4.p5" class="ltx_para">
<p id="S3.SS4.p5.1" class="ltx_p">A reputation system can be maintained to evaluate the reliability and quality of local models in FL. A client’s reputation can be determined using the combination of a direct reputation (i.e. the reputation evaluated by the task requester) and an indirect reputation (i.e. the reputation evaluated by other requesters). Reputation values are used to conduct client selection in <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Kang </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib20" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2019</span></a>, <a href="#bib.bib22" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2020b</span></a>)</cite>, where the reputation of each client is calculated using the multiweight subjective logic model <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Liu </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib30" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2011</span></a>)</cite>. The model considers three weights: interaction effects (i.e. positive or negative interaction evaluated by quality measurement), interaction timeliness, and interaction frequency.
To evaluate the quality of local models, attack detection mechanisms such as Reject on Negative Influence (RONI) <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Shayan </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib38" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2018</span></a>)</cite> and FoolsGold <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Fung </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib12" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2018</span></a>)</cite> are used for IID and non-IID data distributions, respectively.
RONI evaluates local models by computing the difference between the performance with and without a local model on a dataset specified by the task publisher. The corresponding local model is discarded from the aggregation process if the performance difference falls below a certain threshold. FoolsGold evaluates clients based on the gradient diversity of their local models. Clients uploading similar gradients in each round are identified as unreliable workers which may contribute unreliable models, and are excluded from the aggregation process.
In the collaborative FL proposed in <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Zhang </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib48" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021a</span></a>)</cite>, each individual client can be a task requester or a participant. To evaluate the contribution of local models, all local models and the global model are recorded at each global iteration. A local model that moves more towards the target model has a higher contribution to the global model, leading to a faster convergence speed. To measure the contribution of each client in each round, first, the direction vector is obtained between the initial global model and the final global model. Then, the local model is projected onto the direction vector and multiplied by the absolute value of the cosine of the angle between the local model and the direction vector. Eventually, the sum of the contributions of each client’s local model across multiple rounds is calculated to obtain the overall contribution of clients. </p>
</div>
<div id="S3.SS4.p6" class="ltx_para">
<p id="S3.SS4.p6.1" class="ltx_p">In serverless FL, local models can also be evaluated based on statistical metrics.
A committee-based serverless FL framework is proposed in <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Che </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib5" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2022</span></a>)</cite> where honest clients are selected as committee members to filter local gradients for defending against Byzantine attacks or accelerating FL convergence.
To exclude attackers, the local gradients close to the committee gradients are selected for model aggregation based on the Euclidean distance. This is because the Euclidean distance between a malicious gradient and an honest gradient is larger than the distance between two honest gradients. However, this strategy may degrade the performance of FL since honest clients with large gradient differences have less opportunity to participate in aggregation.
Therefore, to accelerate FL convergence in a non-attack scenario, clients with different local updates are accepted. To obtain the final score of each client calculated using the Euclidean distance, the committee members broadcast their evaluation scores to each other.
To reach a consensus, a client is selected randomly as the primary client, which sends a request to the other committee members to confirm the correctness of its aggregation set. If so, the aggregation process is performed on the committee clients, and if the result is consistent with the request, it is sent back to the primary client. If the primary client receives a sufficient number of consistent results, a consensus is reached. Otherwise, the primary committee member is reallocated and the process is repeated.</p>
</div>
<div id="S3.SS4.p7" class="ltx_para">
<p id="S3.SS4.p7.1" class="ltx_p">In FL, it is possible that there are multiple learning tasks such as personalization. The challenge for training multiple tasks is to customize the training progress for each individual task based on federated evaluation results.
A personalized FL framework is introduced in <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Huang </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib18" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>)</cite> where clients have separate personalized target models for learning at the server. It investigates pair-wise collaborations among clients. Specifically, the server collects local personalized model parameters from clients to update the model for each client by a weighted convex combination of received model parameters. The weights (i.e. contributions) of clients for each personalized target model are evaluated by the similarity between the model parameters of two clients. Therefore, clients with similar model parameters have more contributions to each other. Each client can request its respective model parameters from the server to optimize its local personalized model using their private data.
A similar personalized FL architecture (i.e. a personalized target model for each client) has been introduced in <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Ma </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib33" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2022</span></a>)</cite> which assigns different weights for model layers when aggregating personalized models. More specifically, local features are more related to shallow model layers while global features correspond to deeper model layers. The proposed method employs layer-wise aggregation to achieve higher performance for personalized model training. A hypernetwork <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Ha </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib15" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2016</span></a>)</cite> for each client is employed on the server to generate the aggregation weight for each layer of different clients. Clients with a similar data distribution have higher weights for aggregation.
FedDist algorithm <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Sannara </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib37" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>)</cite>
uses distances between neurons to measure how different neurons are between the global and local models.
First, the server performs weighted averaging which is similar to the generation of the initial aggregated model in FedAvg. Then, the pairwise Euclidean distance is computed for each neuron in a layer between the local models and the aggregated model to identify diverging neurons. If the Euclidean distance between a specific neuron in any local model and the aggregated model is above a predetermined threshold the neuron is added to the aggregated model in order to improve model generalization.
Thus, neurons that are specific to clients are incorporated into the aggregated model.
</p>
</div>
<div id="S3.SS4.p8" class="ltx_para">
<p id="S3.SS4.p8.1" class="ltx_p">A personalized FL algorithm based on local memorization has been proposed in <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Marfoq </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib34" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2022</span></a>)</cite>. It combines an aggregated global model with a k-nearest
neighbors (kNN) model on each client. The global model is employed to compute the shared representation used by the local kNN. Each client computes and stores a representation-label pair for each sample. At inference time, the client queries the representation-label pair to obtain its k-nearest neighbors based on
the model distance. Finally, the personalized model for a sample is obtained by interpolating the nearest neighbor distribution with the global model.</p>
</div>
<div id="S3.SS4.p9" class="ltx_para">
<p id="S3.SS4.p9.1" class="ltx_p">Mutual Information (MI) between model parameters or gradients is another kind of useful statistical metric for evaluating local models.
In <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Uddin </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib42" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2020</span></a>)</cite>, a novel FL mechanism is introduced that exploits MI for both the client-side weight update and the server-side aggregation. The clients’ model weights are updated by minimizing the MI between their local models and the aggregated global model. To extract distinct information, the correlation between two models must be minimized, which leads to minimized MI between them.
For the model aggregation step, clients send MI values between their local models and the global model to the server. The server defines local models that are either similar to other models (with too high MI values) or significantly different from others (with too low MI values) as outliers. The FL server ranks the uploaded MI values to select the top useful local models for aggregation. Model-contrastive FL (MOON) <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Li </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib28" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021c</span></a>)</cite> utilizes contrastive learning at the model level. MOON is built upon FedAvg which incorporates modifications in the local training phase. Its local objective is to decrease the distance between the representation learned by each local model and the global model while increasing the distance between the representation learned by the current local model and the previous local model.</p>
</div>
<div id="S3.SS4.p10" class="ltx_para">
<p id="S3.SS4.p10.1" class="ltx_p">Class imbalance in FL has been investigated in <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Yang </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib46" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>)</cite> without having access to raw data in order to evaluate the importance of local models. The class distribution of clients can be obtained using their updated gradients, assuming that a balanced auxiliary dataset exists on the server for the classification problem. The correlation between the gradients with respect to the corresponding classes brought by auxiliary data on the server and class distribution <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Anand </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib2" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">1993</span></a>)</cite> allows for the calculation of the class imbalance of each client using the Kullback-Leibler (KL) divergence. The statistics of class distributions are learned using Combinatorial Multi-Armed Bandit (CMAB) <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Chen </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib6" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2013</span></a>)</cite>, and the client selection process is considered as a CMAB problem in order to identify clients with minimal class imbalance.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<div id="S3.T1.1" class="ltx_inline-block ltx_transformed_outer" style="width:433.6pt;height:21373.4pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-59.7pt,2942.1pt) scale(0.78412146392378,0.78412146392378) ;">
<table id="S3.T1.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T1.1.1.1.1" class="ltx_tr">
<th id="S3.T1.1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_ll ltx_border_rr ltx_border_t">Evaluation Methods</th>
<th id="S3.T1.1.1.1.1.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_column ltx_border_r ltx_border_t" style="width:85.4pt;">
<span id="S3.T1.1.1.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.1.1.2.1.1" class="ltx_p">Ref.</span>
</span>
</th>
<th id="S3.T1.1.1.1.1.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_column ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S3.T1.1.1.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.1.1.3.1.1" class="ltx_p">Applications</span>
</span>
</th>
<th id="S3.T1.1.1.1.1.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_th ltx_th_column ltx_border_r ltx_border_t" style="width:455.2pt;">
<span id="S3.T1.1.1.1.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.1.1.4.1.1" class="ltx_p">Key Ideas</span>
</span>
</th>
<th id="S3.T1.1.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_rr ltx_border_t">Architecture</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T1.1.1.2.1" class="ltx_tr">
<td id="S3.T1.1.1.2.1.1" class="ltx_td ltx_align_center ltx_border_ll ltx_border_rr ltx_border_tt" rowspan="4"><span id="S3.T1.1.1.2.1.1.1" class="ltx_text">Data-level Evaluation</span></td>
<td id="S3.T1.1.1.2.1.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_tt" style="width:85.4pt;">
<span id="S3.T1.1.1.2.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.2.1.2.1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Feng </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib11" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2019</span></a>)</cite></span>
</span>
</td>
<td id="S3.T1.1.1.2.1.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_tt" style="width:113.8pt;">
<span id="S3.T1.1.1.2.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.2.1.3.1.1" class="ltx_p">Incentive Mechanism</span>
</span>
</td>
<td id="S3.T1.1.1.2.1.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_tt" style="width:455.2pt;">
<span id="S3.T1.1.1.2.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.2.1.4.1.1" class="ltx_p">Obtaining revenue based on data size</span>
</span>
</td>
<td id="S3.T1.1.1.2.1.5" class="ltx_td ltx_align_center ltx_border_rr ltx_border_tt">Centralized</td>
</tr>
<tr id="S3.T1.1.1.3.2" class="ltx_tr">
<td id="S3.T1.1.1.3.2.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:85.4pt;">
<span id="S3.T1.1.1.3.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.3.2.1.1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Li </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib26" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021a</span></a>)</cite></span>
</span>
</td>
<td id="S3.T1.1.1.3.2.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S3.T1.1.1.3.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.3.2.2.1.1" class="ltx_p">Client Selection</span>
</span>
</td>
<td id="S3.T1.1.1.3.2.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:455.2pt;">
<span id="S3.T1.1.1.3.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.3.2.3.1.1" class="ltx_p">Filtering clients based on their labels and selecting clients with high statistical homogeneity and content diversity</span>
</span>
</td>
<td id="S3.T1.1.1.3.2.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">Centralized</td>
</tr>
<tr id="S3.T1.1.1.4.3" class="ltx_tr">
<td id="S3.T1.1.1.4.3.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:85.4pt;">
<span id="S3.T1.1.1.4.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.4.3.1.1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Zhao </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib51" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2018</span></a>)</cite></span>
</span>
</td>
<td id="S3.T1.1.1.4.3.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S3.T1.1.1.4.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.4.3.2.1.1" class="ltx_p">Client Selection</span>
</span>
</td>
<td id="S3.T1.1.1.4.3.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:455.2pt;">
<span id="S3.T1.1.1.4.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.4.3.3.1.1" class="ltx_p">Pair-wise grouping mechanism to complement missing labels</span>
</span>
</td>
<td id="S3.T1.1.1.4.3.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">Centralized</td>
</tr>
<tr id="S3.T1.1.1.5.4" class="ltx_tr">
<td id="S3.T1.1.1.5.4.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:85.4pt;">
<span id="S3.T1.1.1.5.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.5.4.1.1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Lai </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib24" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>)</cite></span>
</span>
</td>
<td id="S3.T1.1.1.5.4.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S3.T1.1.1.5.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.5.4.2.1.1" class="ltx_p">Understanding Global Model</span>
</span>
</td>
<td id="S3.T1.1.1.5.4.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:455.2pt;">
<span id="S3.T1.1.1.5.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.5.4.3.1.1" class="ltx_p">Preserving the deviation target of the data formed by the participants from the global distribution</span>
</span>
</td>
<td id="S3.T1.1.1.5.4.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">Decentralized</td>
</tr>
<tr id="S3.T1.1.1.6.5" class="ltx_tr">
<td id="S3.T1.1.1.6.5.1" class="ltx_td ltx_align_center ltx_border_ll ltx_border_rr ltx_border_t" rowspan="6"><span id="S3.T1.1.1.6.5.1.1" class="ltx_text">Model Utility</span></td>
<td id="S3.T1.1.1.6.5.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:85.4pt;">
<span id="S3.T1.1.1.6.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.6.5.2.1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Lai </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib24" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>)</cite></span>
</span>
</td>
<td id="S3.T1.1.1.6.5.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S3.T1.1.1.6.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.6.5.3.1.1" class="ltx_p">Client Selection</span>
</span>
</td>
<td id="S3.T1.1.1.6.5.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:455.2pt;">
<span id="S3.T1.1.1.6.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.6.5.4.1.1" class="ltx_p">Sampling based on the aggregate training loss computed locally on the client and duration of the training round</span>
</span>
</td>
<td id="S3.T1.1.1.6.5.5" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">Centralized</td>
</tr>
<tr id="S3.T1.1.1.7.6" class="ltx_tr">
<td id="S3.T1.1.1.7.6.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:85.4pt;">
<span id="S3.T1.1.1.7.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.7.6.1.1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Li </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib27" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021b</span></a>)</cite></span>
</span>
</td>
<td id="S3.T1.1.1.7.6.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S3.T1.1.1.7.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.7.6.2.1.1" class="ltx_p">Client Selection</span>
</span>
</td>
<td id="S3.T1.1.1.7.6.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:455.2pt;">
<span id="S3.T1.1.1.7.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.7.6.3.1.1" class="ltx_p">Selecting clients based their training loss</span>
</span>
</td>
<td id="S3.T1.1.1.7.6.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">Centralized</td>
</tr>
<tr id="S3.T1.1.1.8.7" class="ltx_tr">
<td id="S3.T1.1.1.8.7.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:85.4pt;">
<span id="S3.T1.1.1.8.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.8.7.1.1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Chai </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib4" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2020</span></a>)</cite></span>
</span>
</td>
<td id="S3.T1.1.1.8.7.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S3.T1.1.1.8.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.8.7.2.1.1" class="ltx_p">Client Selection</span>
</span>
</td>
<td id="S3.T1.1.1.8.7.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:455.2pt;">
<span id="S3.T1.1.1.8.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.8.7.3.1.1" class="ltx_p">Dividing clients into tiers based on their response latencies and selecting tiers based on their accuracy</span>
</span>
</td>
<td id="S3.T1.1.1.8.7.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">Centtralized</td>
</tr>
<tr id="S3.T1.1.1.9.8" class="ltx_tr">
<td id="S3.T1.1.1.9.8.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:85.4pt;">
<span id="S3.T1.1.1.9.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.9.8.1.1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Li </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib26" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021a</span></a>)</cite></span>
</span>
</td>
<td id="S3.T1.1.1.9.8.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S3.T1.1.1.9.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.9.8.2.1.1" class="ltx_p">Client Selection</span>
</span>
</td>
<td id="S3.T1.1.1.9.8.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:455.2pt;">
<span id="S3.T1.1.1.9.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.9.8.3.1.1" class="ltx_p">Measuring the gradient upper bound norm of the aggregated global loss with respect to the pre-activation outputs</span>
</span>
</td>
<td id="S3.T1.1.1.9.8.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">Centralized</td>
</tr>
<tr id="S3.T1.1.1.10.9" class="ltx_tr">
<td id="S3.T1.1.1.10.9.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:85.4pt;">
<span id="S3.T1.1.1.10.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.10.9.1.1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Zhang </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib50" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021c</span></a>)</cite></span>
</span>
</td>
<td id="S3.T1.1.1.10.9.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S3.T1.1.1.10.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.10.9.2.1.1" class="ltx_p">Incentive Mechanism, attack Detection</span>
</span>
</td>
<td id="S3.T1.1.1.10.9.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:455.2pt;">
<span id="S3.T1.1.1.10.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.10.9.3.1.1" class="ltx_p">Evaluating local models on the validation set and computing marginal loss</span>
</span>
</td>
<td id="S3.T1.1.1.10.9.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">Decentralized</td>
</tr>
<tr id="S3.T1.1.1.11.10" class="ltx_tr">
<td id="S3.T1.1.1.11.10.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:85.4pt;">
<span id="S3.T1.1.1.11.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.11.10.1.1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Kang </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib21" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2020a</span></a>)</cite></span>
</span>
</td>
<td id="S3.T1.1.1.11.10.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S3.T1.1.1.11.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.11.10.2.1.1" class="ltx_p">Attack Detection</span>
</span>
</td>
<td id="S3.T1.1.1.11.10.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:455.2pt;">
<span id="S3.T1.1.1.11.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.11.10.3.1.1" class="ltx_p">A Proof-of-Verifying consensus scheme to verify the quality of local models on test data</span>
</span>
</td>
<td id="S3.T1.1.1.11.10.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">Decentralized</td>
</tr>
<tr id="S3.T1.1.1.12.11" class="ltx_tr">
<td id="S3.T1.1.1.12.11.1" class="ltx_td ltx_align_center ltx_border_ll ltx_border_rr ltx_border_t" rowspan="2"><span id="S3.T1.1.1.12.11.1.1" class="ltx_text">Shapley Values</span></td>
<td id="S3.T1.1.1.12.11.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:85.4pt;">
<span id="S3.T1.1.1.12.11.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.12.11.2.1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Wang </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib44" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2020</span></a>); <span class="ltx_text" style="font-size:90%;">Fan </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib10" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2022</span></a>)</cite></span>
</span>
</td>
<td id="S3.T1.1.1.12.11.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S3.T1.1.1.12.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.12.11.3.1.1" class="ltx_p">Incentive Mechanism</span>
</span>
</td>
<td id="S3.T1.1.1.12.11.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:455.2pt;">
<span id="S3.T1.1.1.12.11.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.12.11.4.1.1" class="ltx_p">Contribution evaluation based on Shapley Value</span>
</span>
</td>
<td id="S3.T1.1.1.12.11.5" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">Centralized</td>
</tr>
<tr id="S3.T1.1.1.13.12" class="ltx_tr">
<td id="S3.T1.1.1.13.12.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:85.4pt;">
<span id="S3.T1.1.1.13.12.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.13.12.1.1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Ma </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib32" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021b</span></a>)</cite></span>
</span>
</td>
<td id="S3.T1.1.1.13.12.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S3.T1.1.1.13.12.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.13.12.2.1.1" class="ltx_p">Incentive Mechanism</span>
</span>
</td>
<td id="S3.T1.1.1.13.12.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:455.2pt;">
<span id="S3.T1.1.1.13.12.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.13.12.3.1.1" class="ltx_p">Contribution evaluation based on Shapley Value</span>
</span>
</td>
<td id="S3.T1.1.1.13.12.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">Decentralized</td>
</tr>
<tr id="S3.T1.1.1.14.13" class="ltx_tr">
<td id="S3.T1.1.1.14.13.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_ll ltx_border_rr ltx_border_t" rowspan="16"><span id="S3.T1.1.1.14.13.1.1" class="ltx_text">Statistical Metric</span></td>
<td id="S3.T1.1.1.14.13.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:85.4pt;">
<span id="S3.T1.1.1.14.13.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.14.13.2.1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Zhao </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib52" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2022</span></a>)</cite></span>
</span>
</td>
<td id="S3.T1.1.1.14.13.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S3.T1.1.1.14.13.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.14.13.3.1.1" class="ltx_p">Client Selection</span>
</span>
</td>
<td id="S3.T1.1.1.14.13.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:455.2pt;">
<span id="S3.T1.1.1.14.13.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.14.13.4.1.1" class="ltx_p">Evaluating weight difference before and after a round of training</span>
</span>
</td>
<td id="S3.T1.1.1.14.13.5" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">Centralized</td>
</tr>
<tr id="S3.T1.1.1.15.14" class="ltx_tr">
<td id="S3.T1.1.1.15.14.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:85.4pt;">
<span id="S3.T1.1.1.15.14.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.15.14.1.1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Zhang </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib49" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021b</span></a>)</cite></span>
</span>
</td>
<td id="S3.T1.1.1.15.14.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S3.T1.1.1.15.14.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.15.14.2.1.1" class="ltx_p">Client Selection</span>
</span>
</td>
<td id="S3.T1.1.1.15.14.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:455.2pt;">
<span id="S3.T1.1.1.15.14.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.15.14.3.1.1" class="ltx_p">Evaluating weight divergence between a local model and an auxiliary model</span>
</span>
</td>
<td id="S3.T1.1.1.15.14.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">Centralized</td>
</tr>
<tr id="S3.T1.1.1.16.15" class="ltx_tr">
<td id="S3.T1.1.1.16.15.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:85.4pt;">
<span id="S3.T1.1.1.16.15.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.16.15.1.1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Deng </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib9" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>)</cite></span>
</span>
</td>
<td id="S3.T1.1.1.16.15.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S3.T1.1.1.16.15.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.16.15.2.1.1" class="ltx_p">Attack Detection</span>
</span>
</td>
<td id="S3.T1.1.1.16.15.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:455.2pt;">
<span id="S3.T1.1.1.16.15.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.16.15.3.1.1" class="ltx_p">Statistical analysis of the similarity values between the local models and the global model</span>
</span>
</td>
<td id="S3.T1.1.1.16.15.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">Centralized</td>
</tr>
<tr id="S3.T1.1.1.17.16" class="ltx_tr">
<td id="S3.T1.1.1.17.16.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:85.4pt;">
<span id="S3.T1.1.1.17.16.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.17.16.1.1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Gao </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib13" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>)</cite></span>
</span>
</td>
<td id="S3.T1.1.1.17.16.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S3.T1.1.1.17.16.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.17.16.2.1.1" class="ltx_p">Attack Detection, Incentive Mechanism</span>
</span>
</td>
<td id="S3.T1.1.1.17.16.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:455.2pt;">
<span id="S3.T1.1.1.17.16.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.17.16.3.1.1" class="ltx_p">The measurement of the distance between the local and benchmark gradients, and the local and global gradients</span>
</span>
</td>
<td id="S3.T1.1.1.17.16.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">Centralized</td>
</tr>
<tr id="S3.T1.1.1.18.17" class="ltx_tr">
<td id="S3.T1.1.1.18.17.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:85.4pt;">
<span id="S3.T1.1.1.18.17.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.18.17.1.1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Wang </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib43" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2019</span></a>)</cite></span>
</span>
</td>
<td id="S3.T1.1.1.18.17.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S3.T1.1.1.18.17.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.18.17.2.1.1" class="ltx_p">Incentive Mechanism</span>
</span>
</td>
<td id="S3.T1.1.1.18.17.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:455.2pt;">
<span id="S3.T1.1.1.18.17.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.18.17.3.1.1" class="ltx_p">Computing the difference between the new global model and original one after deleting some data points</span>
</span>
</td>
<td id="S3.T1.1.1.18.17.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">Centralized</td>
</tr>
<tr id="S3.T1.1.1.19.18" class="ltx_tr">
<td id="S3.T1.1.1.19.18.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:85.4pt;">
<span id="S3.T1.1.1.19.18.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.19.18.1.1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Zhang </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib48" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021a</span></a>)</cite></span>
</span>
</td>
<td id="S3.T1.1.1.19.18.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S3.T1.1.1.19.18.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.19.18.2.1.1" class="ltx_p">Client Selection, Incentive Mechanism</span>
</span>
</td>
<td id="S3.T1.1.1.19.18.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:455.2pt;">
<span id="S3.T1.1.1.19.18.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.19.18.3.1.1" class="ltx_p">Reputation-based evaluation based on the direction vector between the initial and final global model</span>
</span>
</td>
<td id="S3.T1.1.1.19.18.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">Centralized</td>
</tr>
<tr id="S3.T1.1.1.20.19" class="ltx_tr">
<td id="S3.T1.1.1.20.19.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:85.4pt;">
<span id="S3.T1.1.1.20.19.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.20.19.1.1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Kang </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib20" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2019</span></a>, <a href="#bib.bib22" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2020b</span></a>)</cite></span>
</span>
</td>
<td id="S3.T1.1.1.20.19.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S3.T1.1.1.20.19.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.20.19.2.1.1" class="ltx_p">Client Selection, Incentive Mechanism, Attack Detection</span>
</span>
</td>
<td id="S3.T1.1.1.20.19.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:455.2pt;">
<span id="S3.T1.1.1.20.19.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.20.19.3.1.1" class="ltx_p">Reputation-based evaluation using multiweight subjective logic based on attack detection mechanisms</span>
</span>
</td>
<td id="S3.T1.1.1.20.19.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">Centralized</td>
</tr>
<tr id="S3.T1.1.1.21.20" class="ltx_tr">
<td id="S3.T1.1.1.21.20.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:85.4pt;">
<span id="S3.T1.1.1.21.20.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.21.20.1.1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Che </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib5" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2022</span></a>)</cite></span>
</span>
</td>
<td id="S3.T1.1.1.21.20.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S3.T1.1.1.21.20.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.21.20.2.1.1" class="ltx_p">Attack Detection</span>
</span>
</td>
<td id="S3.T1.1.1.21.20.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:455.2pt;">
<span id="S3.T1.1.1.21.20.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.21.20.3.1.1" class="ltx_p">Evaluating the distance between the local gradients and the committee gradients</span>
</span>
</td>
<td id="S3.T1.1.1.21.20.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">Decentralized</td>
</tr>
<tr id="S3.T1.1.1.22.21" class="ltx_tr">
<td id="S3.T1.1.1.22.21.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:85.4pt;">
<span id="S3.T1.1.1.22.21.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.22.21.1.1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Huang </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib18" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>)</cite></span>
</span>
</td>
<td id="S3.T1.1.1.22.21.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S3.T1.1.1.22.21.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.22.21.2.1.1" class="ltx_p">Pesronalization</span>
</span>
</td>
<td id="S3.T1.1.1.22.21.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:455.2pt;">
<span id="S3.T1.1.1.22.21.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.22.21.3.1.1" class="ltx_p">Pair-wise similarity evaluation between clients</span>
</span>
</td>
<td id="S3.T1.1.1.22.21.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">Centralized</td>
</tr>
<tr id="S3.T1.1.1.23.22" class="ltx_tr">
<td id="S3.T1.1.1.23.22.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:85.4pt;">
<span id="S3.T1.1.1.23.22.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.23.22.1.1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Ma </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib33" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2022</span></a>)</cite></span>
</span>
</td>
<td id="S3.T1.1.1.23.22.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S3.T1.1.1.23.22.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.23.22.2.1.1" class="ltx_p">Personalization</span>
</span>
</td>
<td id="S3.T1.1.1.23.22.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:455.2pt;">
<span id="S3.T1.1.1.23.22.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.23.22.3.1.1" class="ltx_p">Layer-wise similarity evaluation for identifying aggregation weights</span>
</span>
</td>
<td id="S3.T1.1.1.23.22.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">Centralized</td>
</tr>
<tr id="S3.T1.1.1.24.23" class="ltx_tr">
<td id="S3.T1.1.1.24.23.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:85.4pt;">
<span id="S3.T1.1.1.24.23.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.24.23.1.1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Sannara </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib37" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>)</cite></span>
</span>
</td>
<td id="S3.T1.1.1.24.23.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S3.T1.1.1.24.23.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.24.23.2.1.1" class="ltx_p">Personalization</span>
</span>
</td>
<td id="S3.T1.1.1.24.23.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:455.2pt;">
<span id="S3.T1.1.1.24.23.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.24.23.3.1.1" class="ltx_p">Evaluating pairwise distances of neurons between the local models and the initial global model</span>
</span>
</td>
<td id="S3.T1.1.1.24.23.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">Centralized</td>
</tr>
<tr id="S3.T1.1.1.25.24" class="ltx_tr">
<td id="S3.T1.1.1.25.24.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:85.4pt;">
<span id="S3.T1.1.1.25.24.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.25.24.1.1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Marfoq </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib34" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2022</span></a>)</cite></span>
</span>
</td>
<td id="S3.T1.1.1.25.24.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S3.T1.1.1.25.24.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.25.24.2.1.1" class="ltx_p">Personalization</span>
</span>
</td>
<td id="S3.T1.1.1.25.24.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:455.2pt;">
<span id="S3.T1.1.1.25.24.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.25.24.3.1.1" class="ltx_p">Interpolating nearest neighbor distribution with the global model</span>
</span>
</td>
<td id="S3.T1.1.1.25.24.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">Centralized</td>
</tr>
<tr id="S3.T1.1.1.26.25" class="ltx_tr">
<td id="S3.T1.1.1.26.25.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:85.4pt;">
<span id="S3.T1.1.1.26.25.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.26.25.1.1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Uddin </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib42" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2020</span></a>)</cite></span>
</span>
</td>
<td id="S3.T1.1.1.26.25.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S3.T1.1.1.26.25.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.26.25.2.1.1" class="ltx_p">Personalization</span>
</span>
</td>
<td id="S3.T1.1.1.26.25.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:455.2pt;">
<span id="S3.T1.1.1.26.25.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.26.25.3.1.1" class="ltx_p">Client-side weight update and server-side aggregation based on Mutual Information (MI)</span>
</span>
</td>
<td id="S3.T1.1.1.26.25.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">Centralized</td>
</tr>
<tr id="S3.T1.1.1.27.26" class="ltx_tr">
<td id="S3.T1.1.1.27.26.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:85.4pt;">
<span id="S3.T1.1.1.27.26.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.27.26.1.1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Yang </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib46" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>)</cite></span>
</span>
</td>
<td id="S3.T1.1.1.27.26.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S3.T1.1.1.27.26.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.27.26.2.1.1" class="ltx_p">Client Selection</span>
</span>
</td>
<td id="S3.T1.1.1.27.26.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:455.2pt;">
<span id="S3.T1.1.1.27.26.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.27.26.3.1.1" class="ltx_p">Evaluating the class imbalance of clients using the Kullback-Leibler (KL) divergence</span>
</span>
</td>
<td id="S3.T1.1.1.27.26.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">Centralized</td>
</tr>
<tr id="S3.T1.1.1.28.27" class="ltx_tr">
<td id="S3.T1.1.1.28.27.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r ltx_border_t" style="width:85.4pt;">
<span id="S3.T1.1.1.28.27.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.28.27.1.1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Deng </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib9" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>)</cite></span>
</span>
</td>
<td id="S3.T1.1.1.28.27.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S3.T1.1.1.28.27.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.28.27.2.1.1" class="ltx_p">Incentive Mechanism, Client Selection</span>
</span>
</td>
<td id="S3.T1.1.1.28.27.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r ltx_border_t" style="width:455.2pt;">
<span id="S3.T1.1.1.28.27.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.1.1.28.27.3.1.1" class="ltx_p">Maximization of the sum of the qualities of local models based on loss reduction within the learning budget</span>
</span>
</td>
<td id="S3.T1.1.1.28.27.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_rr ltx_border_t">Centralized</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>A summary of existing federated evaluation works.</figcaption>
</figure>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Applications of Federated Evaluation</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">Federated evaluation can enhance FL performance from multiple aspects. In this section, we
discuss the applications of federated evaluation results in FL to illustrate its importance.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Understanding Global Model</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">It is vital to evaluate the global model performance on test datasets during training to understand the performance of FL and determine the cut-off accuracy.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p">In the ideal scenario, the server holds the test dataset and can centrally evaluate the global model.
However, in most cases, the test data is not available on the FL server. As a result, the server resorts to conducting federated evaluation on selected clients. However, randomly selecting testing clients can lead to data deviations from the target distribution and may result in biased testing results. In <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Lai </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib24" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>)</cite>,
a method is proposed to evaluate data deviations from the global distribution before selecting clients to test the global model. If data characteristics are not available, the proposed method estimates the number of participants in a way that bounds the deviation. If data characteristics are provided,
the method iteratively select clients with the most number of samples until pre-defined conditions are met.
</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Incentive Mechanism Design</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">FL is unsealed in the sense that clients can depart the system at any time. Without centrally owning data by the server, it is difficult to force clients to contribute their models. Due to computation and communication costs for model training, clients are inherently reluctant to contribute to FL altruistically without any rewards. Thus, incentive mechanisms are indispensable to motivate clients to participate in FL.
Pioneering works have designed incentive mechanisms to prevent free-riders and encourage the contribution of high-quality models from clients by allocating rewards to clients in accordance with their contributions <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Deng </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib9" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>); <span class="ltx_text" style="font-size:90%;">Zhang </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib48" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021a</span></a>); <span class="ltx_text" style="font-size:90%;">Hu </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib16" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2022a</span></a>, <a href="#bib.bib17" title="" class="ltx_ref">b</a>)</cite>.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">A critical challenge in designing incentive mechanisms is how to allocate rewards among clients based on their contributions in a reasonable manner. The evaluation results of local models can exactly guide the allocation of rewards to incentivize clients.
There are multiple works that have investigated incentive mechanisms in FL. In a simple way, data-level approaches simply consider the data size to determine the reward of a client <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Feng </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib11" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2019</span></a>)</cite>. More complicated methods can employ model distance metrics to design incentive mechanisms. Fair <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Deng </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib9" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>)</cite> establishes a reverse auction mechanism in which clients submit their bids to the server for participating in FL. It formulates a learning quality maximization problem (LQM) to maximize the sum of the qualities of all selected participants within the learning budget and uses a greedy algorithm to solve this problem.
Another incentive mechanism based on reputation and reverse auction is proposed in <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Zhang </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib48" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021a</span></a>)</cite>. Participants are rewarded by combining their bids and reputation scores. The reputation of clients is evaluated based on a model distance metric.
FIFL <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Gao </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib13" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>)</cite> designs an incentive mechanism that rewards clients based on their contributions and reputations. It uses a model distance metric based on gradient similarity to evaluate clients’ contributions. Some existing works use Shapley values to evaluate the contribution of clients and determine reward allocation <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Wang </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib44" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2020</span></a>); <span class="ltx_text" style="font-size:90%;">Fan </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib10" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2022</span></a>); <span class="ltx_text" style="font-size:90%;">Ma </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib32" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021b</span></a>)</cite>. In Refiner <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Zhang </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib50" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021c</span></a>)</cite>, clients are rewarded based on their contributions which are evaluated using both a model distance metric and marginal performance loss.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Client Selection</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">Due to the limited processing capacity of the server in FL, only a limited number of clients can be selected to participate in FL at each global iteration. How to select clients to participate in FL is a crucial problem that can significantly influence the model utility <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Yang </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib46" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>); <span class="ltx_text" style="font-size:90%;">Li </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib26" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021a</span></a>); <span class="ltx_text" style="font-size:90%;">Zhao </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib52" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2022</span></a>); <span class="ltx_text" style="font-size:90%;">Zhang </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib49" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021b</span></a>)</cite>.
Advanced client selection schemes can be devised based on federated evaluation results. More specifically, clients that can contribute more valuable models should be selected with higher priority. A well-designed client selection scheme can not only improve the final model utility but also shorten the training time by expediting the convergence of FL <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Soltani </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib39" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2022</span></a>)</cite>.
For example, Oort <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Lai </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib24" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>)</cite> selects clients based on their local model utility evaluated on clients when making client selection decisions. Similarly, FedSAE <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Li </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib27" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021b</span></a>)</cite> considers local training loss as a utility metric to select clients.
In a data-level approach, the server can select clients based on statistical homogeneity and content diversity of their data <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Li </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib26" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021a</span></a>)</cite>. The grouping-based scheduling method proposed in <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Ma </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib31" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021a</span></a>)</cite>, divides clients into several groups to complement their missing labels. Clients within the same group are selected for training.
Some existing works develop model distance metrics for designing client selection schemes. Fair <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Deng </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib9" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>)</cite> employs the loss reduction to select participants in a way that maximizes the sum of the qualities of all participants. Methods proposed in <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Zhao </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib52" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2022</span></a>); <span class="ltx_text" style="font-size:90%;">Zhang </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib49" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021b</span></a>)</cite> utilize the divergence of model parameters to evaluate the quality of local models.</p>
</div>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Malicious Attack Detection</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p">In FL, malicious clients may easily launch attacks such as poisoning attacks by tampering with data labels or model gradients to deteriorate model utility. Since data is not exposed by FL clients, malicious attack detection algorithms designed for conventional machine learning are not applicable for FL.</p>
</div>
<div id="S4.SS4.p2" class="ltx_para">
<p id="S4.SS4.p2.1" class="ltx_p">Malicious attackers in FL can be identified and excluded from the model aggregation through accurate and efficient evaluation of local models. FIFL <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Gao </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib13" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>)</cite> employs gradient similarity as a model distance metric to detect abnormal gradients and malicious attackers. In <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Kang </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib20" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2019</span></a>, <a href="#bib.bib22" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2020b</span></a>)</cite>, a client contributing a very low-quality model is considered as a malicious attacker and excluded from the aggregation process based on a model distance metric, i.e. the performance difference for IID datasets and gradient diversity of local models for non-IID datasets.</p>
</div>
</section>
<section id="S4.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5 </span>Personalized Federated Learning</h3>

<div id="S4.SS5.p1" class="ltx_para">
<p id="S4.SS5.p1.1" class="ltx_p">It is well-known that data distribution across different clients is often non-IID, which can lead to poor generalization performance of the global model on all local data distributions <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Li </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib25" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2020</span></a>); <span class="ltx_text" style="font-size:90%;">Tan </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib41" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2022</span></a>)</cite>. Personalized federated learning (PFL) is proposed to address this problem <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Tan </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib41" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2022</span></a>)</cite>. For PFL, each individual client has a learning objective slightly different from other clients. Thus, each individual client seeks to closely collaborate with clients owning a more similar data distribution. How to learn the similarity between data distributions can be accomplished using federated evaluation. For example, in <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Huang </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib18" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2021</span></a>)</cite>, the distance between models is used as a metric to evaluate the similarity of data distributions on different clients. A personalized model aggregation algorithm is devised which enables each client to assign higher weights to more similar clients when aggregating models. Similarly, in a layer-wised personalized FL <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Ma </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib33" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2022</span></a>)</cite>, each layer from different clients is assigned different aggregation weights based on the similarity between the data distribution of clients.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Summary and Challenges</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">Federated evaluation is indispensable for FL to achieve high-performance models without accessing clients’ data. In Table <a href="#S3.T1" title="Table 1 ‣ 3.4 Statistical Metric ‣ 3 Federated Evaluation Approaches ‣ A Survey of Federated Evaluation in Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, we summarize a number of existing federated evaluation studies, which are categorized based on their approaches. Their applications, evaluation architectures, and the key idea of each work are briefly illustrated.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">In spite of tremendous efforts made by existing works, there are several challenges calling for more significant novel contributions, which are summarized as follows.</p>
<ol id="S5.I1" class="ltx_enumerate">
<li id="S5.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S5.I1.i1.p1" class="ltx_para">
<p id="S5.I1.i1.p1.1" class="ltx_p">Differentially private FL, which injects zero-mean noises to obfuscate exposed information <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Zhou </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib54" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2023</span></a>)</cite>, can greatly complicate federated evaluation. Differentially private (DP) noises will disturb the accurate evaluation of model quality. Meanwhile, the noise scale will be amplified by the number of model exposure times, which considerably restricts the number of times to evaluate a local model.</p>
</div>
</li>
<li id="S5.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S5.I1.i2.p1" class="ltx_para">
<p id="S5.I1.i2.p1.1" class="ltx_p">If federated evaluation tasks are offloaded to clients or third parties, it is difficult to guarantee that these evaluators will return genuine and accurate evaluation results. They can easily attack federated evaluation by returning falsified evaluation results.</p>
</div>
</li>
<li id="S5.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S5.I1.i3.p1" class="ltx_para">
<p id="S5.I1.i3.p1.1" class="ltx_p">For fully decentralized FL (DFL), clients contact each other in an ad hoc manner to exchange model parameters <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Su </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib40" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2022</span></a>)</cite>. Without the coordination of a server, federated evaluation becomes more difficult since the collected information of each DFL client is very limited to fully support evaluation of models.</p>
</div>
</li>
<li id="S5.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="S5.I1.i4.p1" class="ltx_para">
<p id="S5.I1.i4.p1.1" class="ltx_p">In online FL, data is continuously collected and generated by clients <cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">Chen </span><span class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span> (<a href="#bib.bib8" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2020b</span></a>)</cite>. To conduct federated evaluation in online FL, it is required to continuously track the change of model evaluation results with the arrival of new data.</p>
</div>
</li>
</ol>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgment</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">This work was supported by ARC DP210101723.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib1.5.5.1" class="ltx_text" style="font-size:90%;">Agrawal </span><span id="bib.bib1.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib1.7.7.3" class="ltx_text" style="font-size:90%;"> [2003]</span></span>
<span class="ltx_bibblock"><span id="bib.bib1.9.1" class="ltx_text" style="font-size:90%;">
Rakesh Agrawal, Alexandre Evfimievski, and Ramakrishnan Srikant.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.10.1" class="ltx_text" style="font-size:90%;">Information sharing across private databases.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.11.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib1.12.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the 2003 ACM SIGMOD international conference
on Management of data</span><span id="bib.bib1.13.3" class="ltx_text" style="font-size:90%;">, pages 86–97, 2003.
</span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib2.5.5.1" class="ltx_text" style="font-size:90%;">Anand </span><span id="bib.bib2.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib2.7.7.3" class="ltx_text" style="font-size:90%;"> [1993]</span></span>
<span class="ltx_bibblock"><span id="bib.bib2.9.1" class="ltx_text" style="font-size:90%;">
Rangachari Anand, Kishan G Mehrotra, Chilukuri K Mohan, and Sanjay Ranka.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.10.1" class="ltx_text" style="font-size:90%;">An improved algorithm for neural network classification of imbalanced
training sets.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.11.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Neural Networks</span><span id="bib.bib2.12.2" class="ltx_text" style="font-size:90%;">, 4(6):962–969, 1993.
</span>
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib3.5.5.1" class="ltx_text" style="font-size:90%;">Biswas </span><span id="bib.bib3.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib3.7.7.3" class="ltx_text" style="font-size:90%;"> [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib3.9.1" class="ltx_text" style="font-size:90%;">
Chandan Biswas, Debasis Ganguly, Dwaipayan Roy, and Ujjwal Bhattacharya.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.10.1" class="ltx_text" style="font-size:90%;">Privacy preserving approximate k-means clustering.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.11.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib3.12.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the 28th ACM International Conference on
Information and Knowledge Management</span><span id="bib.bib3.13.3" class="ltx_text" style="font-size:90%;">, pages 1321–1330, 2019.
</span>
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib4.5.5.1" class="ltx_text" style="font-size:90%;">Chai </span><span id="bib.bib4.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib4.7.7.3" class="ltx_text" style="font-size:90%;"> [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib4.9.1" class="ltx_text" style="font-size:90%;">
Zheng Chai, Ahsan Ali, Syed Zawad, Stacey Truex, Ali Anwar, Nathalie Baracaldo,
Yi Zhou, Heiko Ludwig, Feng Yan, and Yue Cheng.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.10.1" class="ltx_text" style="font-size:90%;">Tifl: A tier-based federated learning system.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.11.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib4.12.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the 29th International Symposium on
High-Performance Parallel and Distributed Computing</span><span id="bib.bib4.13.3" class="ltx_text" style="font-size:90%;">, pages 125–136, 2020.
</span>
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib5.5.5.1" class="ltx_text" style="font-size:90%;">Che </span><span id="bib.bib5.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib5.7.7.3" class="ltx_text" style="font-size:90%;"> [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib5.9.1" class="ltx_text" style="font-size:90%;">
Chunjiang Che, Xiaoli Li, Chuan Chen, Xiaoyu He, and Zibin Zheng.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.10.1" class="ltx_text" style="font-size:90%;">A decentralized federated learning framework via committee mechanism
with convergence guarantee.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.11.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Parallel and Distributed Systems</span><span id="bib.bib5.12.2" class="ltx_text" style="font-size:90%;">,
33(12):4783–4800, 2022.
</span>
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib6.5.5.1" class="ltx_text" style="font-size:90%;">Chen </span><span id="bib.bib6.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib6.7.7.3" class="ltx_text" style="font-size:90%;"> [2013]</span></span>
<span class="ltx_bibblock"><span id="bib.bib6.9.1" class="ltx_text" style="font-size:90%;">
Wei Chen, Yajun Wang, and Yang Yuan.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.10.1" class="ltx_text" style="font-size:90%;">Combinatorial multi-armed bandit: General framework and applications.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.11.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib6.12.2" class="ltx_text ltx_font_italic" style="font-size:90%;">International conference on machine learning</span><span id="bib.bib6.13.3" class="ltx_text" style="font-size:90%;">, pages
151–159. PMLR, 2013.
</span>
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib7.5.5.1" class="ltx_text" style="font-size:90%;">Chen </span><span id="bib.bib7.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib7.7.7.3" class="ltx_text" style="font-size:90%;"> [2020a]</span></span>
<span class="ltx_bibblock"><span id="bib.bib7.9.1" class="ltx_text" style="font-size:90%;">
Yiqiang Chen, Xiaodong Yang, Xin Qin, Han Yu, Biao Chen, and Zhiqi Shen.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.10.1" class="ltx_text" style="font-size:90%;">Focus: Dealing with label quality disparity in federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.11.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2001.11359</span><span id="bib.bib7.12.2" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib8.5.5.1" class="ltx_text" style="font-size:90%;">Chen </span><span id="bib.bib8.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib8.7.7.3" class="ltx_text" style="font-size:90%;"> [2020b]</span></span>
<span class="ltx_bibblock"><span id="bib.bib8.9.1" class="ltx_text" style="font-size:90%;">
Yujing Chen, Yue Ning, Martin Slawski, and Huzefa Rangwala.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.10.1" class="ltx_text" style="font-size:90%;">Asynchronous online federated learning for edge devices with non-iid
data.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.11.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib8.12.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2020 IEEE International Conference on Big Data (Big Data)</span><span id="bib.bib8.13.3" class="ltx_text" style="font-size:90%;">,
pages 15–24. IEEE, 2020.
</span>
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib9.5.5.1" class="ltx_text" style="font-size:90%;">Deng </span><span id="bib.bib9.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib9.7.7.3" class="ltx_text" style="font-size:90%;"> [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib9.9.1" class="ltx_text" style="font-size:90%;">
Yongheng Deng, Feng Lyu, Ju Ren, Yi-Chao Chen, Peng Yang, Yuezhi Zhou, and
Yaoxue Zhang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.10.1" class="ltx_text" style="font-size:90%;">Fair: Quality-aware federated learning with precise user incentive
and model aggregation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.11.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib9.12.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE INFOCOM 2021-IEEE Conference on Computer
Communications</span><span id="bib.bib9.13.3" class="ltx_text" style="font-size:90%;">, pages 1–10. IEEE, 2021.
</span>
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib10.5.5.1" class="ltx_text" style="font-size:90%;">Fan </span><span id="bib.bib10.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib10.7.7.3" class="ltx_text" style="font-size:90%;"> [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib10.9.1" class="ltx_text" style="font-size:90%;">
Zhenan Fan, Huang Fang, Zirui Zhou, Jian Pei, Michael P Friedlander, Changxin
Liu, and Yong Zhang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.10.1" class="ltx_text" style="font-size:90%;">Improving fairness for data valuation in horizontal federated
learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.11.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib10.12.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2022 IEEE 38th International Conference on Data Engineering
(ICDE)</span><span id="bib.bib10.13.3" class="ltx_text" style="font-size:90%;">, pages 2440–2453. IEEE, 2022.
</span>
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib11.5.5.1" class="ltx_text" style="font-size:90%;">Feng </span><span id="bib.bib11.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib11.7.7.3" class="ltx_text" style="font-size:90%;"> [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib11.9.1" class="ltx_text" style="font-size:90%;">
Shaohan Feng, Dusit Niyato, Ping Wang, Dong In Kim, and Ying-Chang Liang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.10.1" class="ltx_text" style="font-size:90%;">Joint service pricing and cooperative relay communication for
federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.11.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib11.12.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2019 International Conference on Internet of Things (iThings)
and IEEE Green Computing and Communications (GreenCom) and IEEE Cyber,
Physical and Social Computing (CPSCom) and IEEE Smart Data (SmartData)</span><span id="bib.bib11.13.3" class="ltx_text" style="font-size:90%;">,
pages 815–820. IEEE, 2019.
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib12.5.5.1" class="ltx_text" style="font-size:90%;">Fung </span><span id="bib.bib12.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib12.7.7.3" class="ltx_text" style="font-size:90%;"> [2018]</span></span>
<span class="ltx_bibblock"><span id="bib.bib12.9.1" class="ltx_text" style="font-size:90%;">
Clement Fung, Chris JM Yoon, and Ivan Beschastnikh.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.10.1" class="ltx_text" style="font-size:90%;">Mitigating sybils in federated learning poisoning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.11.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1808.04866</span><span id="bib.bib12.12.2" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib13.5.5.1" class="ltx_text" style="font-size:90%;">Gao </span><span id="bib.bib13.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib13.7.7.3" class="ltx_text" style="font-size:90%;"> [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib13.9.1" class="ltx_text" style="font-size:90%;">
Liang Gao, Li Li, Yingwen Chen, Wenli Zheng, ChengZhong Xu, and Ming Xu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.10.1" class="ltx_text" style="font-size:90%;">Fifl: A fair incentive mechanism for federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.11.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib13.12.2" class="ltx_text ltx_font_italic" style="font-size:90%;">50th International Conference on Parallel Processing</span><span id="bib.bib13.13.3" class="ltx_text" style="font-size:90%;">, pages
1–10, 2021.
</span>
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib14.4.4.1" class="ltx_text" style="font-size:90%;">Ghorbani and Zou [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib14.6.1" class="ltx_text" style="font-size:90%;">
Amirata Ghorbani and James Zou.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.7.1" class="ltx_text" style="font-size:90%;">Data shapley: Equitable valuation of data for machine learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.8.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib14.9.2" class="ltx_text ltx_font_italic" style="font-size:90%;">International Conference on Machine Learning</span><span id="bib.bib14.10.3" class="ltx_text" style="font-size:90%;">, pages
2242–2251. PMLR, 2019.
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib15.5.5.1" class="ltx_text" style="font-size:90%;">Ha </span><span id="bib.bib15.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib15.7.7.3" class="ltx_text" style="font-size:90%;"> [2016]</span></span>
<span class="ltx_bibblock"><span id="bib.bib15.9.1" class="ltx_text" style="font-size:90%;">
David Ha, Andrew Dai, and Quoc V Le.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.10.1" class="ltx_text" style="font-size:90%;">Hypernetworks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.11.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1609.09106</span><span id="bib.bib15.12.2" class="ltx_text" style="font-size:90%;">, 2016.
</span>
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib16.5.5.1" class="ltx_text" style="font-size:90%;">Hu </span><span id="bib.bib16.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib16.7.7.3" class="ltx_text" style="font-size:90%;"> [2022a]</span></span>
<span class="ltx_bibblock"><span id="bib.bib16.9.1" class="ltx_text" style="font-size:90%;">
Miao Hu, Di Wu, Yipeng Zhou, Xu Chen, and Min Chen.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.10.1" class="ltx_text" style="font-size:90%;">Incentive-aware autonomous client participation in federated
learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.11.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Parallel and Distributed Systems</span><span id="bib.bib16.12.2" class="ltx_text" style="font-size:90%;">,
33(10):2612–2627, 2022.
</span>
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib17.5.5.1" class="ltx_text" style="font-size:90%;">Hu </span><span id="bib.bib17.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib17.7.7.3" class="ltx_text" style="font-size:90%;"> [2022b]</span></span>
<span class="ltx_bibblock"><span id="bib.bib17.9.1" class="ltx_text" style="font-size:90%;">
Miao Hu, Wenzhuo Yang, Zhenxiao Luo, Xuezheng Liu, Yipeng Zhou, Xu Chen, and
Di Wu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.10.1" class="ltx_text" style="font-size:90%;">Autofl: A bayesian game approach for autonomous client participation
in federated edge learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.11.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Mobile Computing</span><span id="bib.bib17.12.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib18.5.5.1" class="ltx_text" style="font-size:90%;">Huang </span><span id="bib.bib18.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib18.7.7.3" class="ltx_text" style="font-size:90%;"> [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib18.9.1" class="ltx_text" style="font-size:90%;">
Yutao Huang, Lingyang Chu, Zirui Zhou, Lanjun Wang, Jiangchuan Liu, Jian Pei,
and Yong Zhang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.10.1" class="ltx_text" style="font-size:90%;">Personalized cross-silo federated learning on non-iid data.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.11.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib18.12.2" class="ltx_text ltx_font_italic" style="font-size:90%;">AAAI</span><span id="bib.bib18.13.3" class="ltx_text" style="font-size:90%;">, pages 7865–7873, 2021.
</span>
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib19.5.5.1" class="ltx_text" style="font-size:90%;">Jia </span><span id="bib.bib19.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib19.7.7.3" class="ltx_text" style="font-size:90%;"> [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib19.9.1" class="ltx_text" style="font-size:90%;">
Ruoxi Jia, David Dao, Boxin Wang, Frances Ann Hubis, Nick Hynes, Nezihe Merve
Gürel, Bo Li, Ce Zhang, Dawn Song, and Costas J Spanos.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.10.1" class="ltx_text" style="font-size:90%;">Towards efficient data valuation based on the shapley value.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.11.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib19.12.2" class="ltx_text ltx_font_italic" style="font-size:90%;">The 22nd International Conference on Artificial Intelligence
and Statistics</span><span id="bib.bib19.13.3" class="ltx_text" style="font-size:90%;">, pages 1167–1176. PMLR, 2019.
</span>
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib20.5.5.1" class="ltx_text" style="font-size:90%;">Kang </span><span id="bib.bib20.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib20.7.7.3" class="ltx_text" style="font-size:90%;"> [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib20.9.1" class="ltx_text" style="font-size:90%;">
Jiawen Kang, Zehui Xiong, Dusit Niyato, Shengli Xie, and Junshan Zhang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.10.1" class="ltx_text" style="font-size:90%;">Incentive mechanism for reliable federated learning: A joint
optimization approach to combining reputation and contract theory.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.11.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Internet of Things Journal</span><span id="bib.bib20.12.2" class="ltx_text" style="font-size:90%;">, 6(6):10700–10714, 2019.
</span>
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib21.5.5.1" class="ltx_text" style="font-size:90%;">Kang </span><span id="bib.bib21.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib21.7.7.3" class="ltx_text" style="font-size:90%;"> [2020a]</span></span>
<span class="ltx_bibblock"><span id="bib.bib21.9.1" class="ltx_text" style="font-size:90%;">
Jiawen Kang, Zehui Xiong, Chunxiao Jiang, Yi Liu, Song Guo, Yang Zhang, Dusit
Niyato, Cyril Leung, and Chunyan Miao.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.10.1" class="ltx_text" style="font-size:90%;">Scalable and communication-efficient decentralized federated edge
learning with multi-blockchain framework.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.11.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib21.12.2" class="ltx_text ltx_font_italic" style="font-size:90%;">International Conference on Blockchain and Trustworthy
Systems</span><span id="bib.bib21.13.3" class="ltx_text" style="font-size:90%;">, pages 152–165. Springer, 2020.
</span>
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib22.5.5.1" class="ltx_text" style="font-size:90%;">Kang </span><span id="bib.bib22.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib22.7.7.3" class="ltx_text" style="font-size:90%;"> [2020b]</span></span>
<span class="ltx_bibblock"><span id="bib.bib22.9.1" class="ltx_text" style="font-size:90%;">
Jiawen Kang, Zehui Xiong, Dusit Niyato, Yuze Zou, Yang Zhang, and Mohsen
Guizani.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.10.1" class="ltx_text" style="font-size:90%;">Reliable federated learning for mobile networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.11.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Wireless Communications</span><span id="bib.bib22.12.2" class="ltx_text" style="font-size:90%;">, 27(2):72–80, 2020.
</span>
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib23.5.5.1" class="ltx_text" style="font-size:90%;">Kim </span><span id="bib.bib23.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib23.7.7.3" class="ltx_text" style="font-size:90%;"> [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib23.9.1" class="ltx_text" style="font-size:90%;">
Hyesung Kim, Jihong Park, Mehdi Bennis, and Seong-Lyun Kim.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.10.1" class="ltx_text" style="font-size:90%;">Blockchained on-device federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.11.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Communications Letters</span><span id="bib.bib23.12.2" class="ltx_text" style="font-size:90%;">, 24(6):1279–1283, 2019.
</span>
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib24.9.5.1" class="ltx_text" style="font-size:90%;">Lai </span><span id="bib.bib24.10.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib24.11.7.3" class="ltx_text" style="font-size:90%;"> [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib24.13.1" class="ltx_text" style="font-size:90%;">
Fan Lai, Xiangfeng Zhu, Harsha V Madhyastha, and Mosharaf Chowdhury.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.14.1" class="ltx_text" style="font-size:90%;">Oort: Efficient federated learning via guided participant selection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.15.5" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib24.4.4" class="ltx_text ltx_font_italic" style="font-size:90%;">15th <math id="bib.bib24.1.1.m1.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib24.1.1.m1.1a"><mo stretchy="false" id="bib.bib24.1.1.m1.1.1" xref="bib.bib24.1.1.m1.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib24.1.1.m1.1b"><ci id="bib.bib24.1.1.m1.1.1.cmml" xref="bib.bib24.1.1.m1.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib24.1.1.m1.1c">\{</annotation></semantics></math>USENIX<math id="bib.bib24.2.2.m2.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib24.2.2.m2.1a"><mo stretchy="false" id="bib.bib24.2.2.m2.1.1" xref="bib.bib24.2.2.m2.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib24.2.2.m2.1b"><ci id="bib.bib24.2.2.m2.1.1.cmml" xref="bib.bib24.2.2.m2.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib24.2.2.m2.1c">\}</annotation></semantics></math> Symposium on Operating Systems Design and
Implementation (<math id="bib.bib24.3.3.m3.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib24.3.3.m3.1a"><mo stretchy="false" id="bib.bib24.3.3.m3.1.1" xref="bib.bib24.3.3.m3.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib24.3.3.m3.1b"><ci id="bib.bib24.3.3.m3.1.1.cmml" xref="bib.bib24.3.3.m3.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib24.3.3.m3.1c">\{</annotation></semantics></math>OSDI<math id="bib.bib24.4.4.m4.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib24.4.4.m4.1a"><mo stretchy="false" id="bib.bib24.4.4.m4.1.1" xref="bib.bib24.4.4.m4.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib24.4.4.m4.1b"><ci id="bib.bib24.4.4.m4.1.1.cmml" xref="bib.bib24.4.4.m4.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib24.4.4.m4.1c">\}</annotation></semantics></math> 21)</span><span id="bib.bib24.16.6" class="ltx_text" style="font-size:90%;">, pages 19–35, 2021.
</span>
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib25.5.5.1" class="ltx_text" style="font-size:90%;">Li </span><span id="bib.bib25.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib25.7.7.3" class="ltx_text" style="font-size:90%;"> [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib25.9.1" class="ltx_text" style="font-size:90%;">
Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and
Virginia Smith.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.10.1" class="ltx_text" style="font-size:90%;">Federated optimization in heterogeneous networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.11.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of Machine Learning and Systems</span><span id="bib.bib25.12.2" class="ltx_text" style="font-size:90%;">, 2:429–450, 2020.
</span>
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib26.5.5.1" class="ltx_text" style="font-size:90%;">Li </span><span id="bib.bib26.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib26.7.7.3" class="ltx_text" style="font-size:90%;"> [2021a]</span></span>
<span class="ltx_bibblock"><span id="bib.bib26.9.1" class="ltx_text" style="font-size:90%;">
Anran Li, Lan Zhang, Juntao Tan, Yaxuan Qin, Junhao Wang, and Xiang-Yang Li.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.10.1" class="ltx_text" style="font-size:90%;">Sample-level data selection for federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.11.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib26.12.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE INFOCOM 2021-IEEE Conference on Computer
Communications</span><span id="bib.bib26.13.3" class="ltx_text" style="font-size:90%;">, pages 1–10. IEEE, 2021.
</span>
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib27.5.5.1" class="ltx_text" style="font-size:90%;">Li </span><span id="bib.bib27.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib27.7.7.3" class="ltx_text" style="font-size:90%;"> [2021b]</span></span>
<span class="ltx_bibblock"><span id="bib.bib27.9.1" class="ltx_text" style="font-size:90%;">
Li Li, Moming Duan, Duo Liu, Yu Zhang, Ao Ren, Xianzhang Chen, Yujuan Tan, and
Chengliang Wang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.10.1" class="ltx_text" style="font-size:90%;">Fedsae: A novel self-adaptive federated learning framework in
heterogeneous systems.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.11.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib27.12.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2021 International Joint Conference on Neural Networks
(IJCNN)</span><span id="bib.bib27.13.3" class="ltx_text" style="font-size:90%;">, pages 1–10. IEEE, 2021.
</span>
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib28.5.5.1" class="ltx_text" style="font-size:90%;">Li </span><span id="bib.bib28.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib28.7.7.3" class="ltx_text" style="font-size:90%;"> [2021c]</span></span>
<span class="ltx_bibblock"><span id="bib.bib28.9.1" class="ltx_text" style="font-size:90%;">
Qinbin Li, Bingsheng He, and Dawn Song.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.10.1" class="ltx_text" style="font-size:90%;">Model-contrastive federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.11.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib28.12.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib28.13.3" class="ltx_text" style="font-size:90%;">, pages 10713–10722, 2021.
</span>
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib29.5.5.1" class="ltx_text" style="font-size:90%;">Li </span><span id="bib.bib29.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib29.7.7.3" class="ltx_text" style="font-size:90%;"> [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib29.9.1" class="ltx_text" style="font-size:90%;">
Shuangtong Li, Tianyi Zhou, Xinmei Tian, and Dacheng Tao.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.10.1" class="ltx_text" style="font-size:90%;">Learning to collaborate in decentralized learning of personalized
models.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.11.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib29.12.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib29.13.3" class="ltx_text" style="font-size:90%;">, pages 9766–9775, 2022.
</span>
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib30.5.5.1" class="ltx_text" style="font-size:90%;">Liu </span><span id="bib.bib30.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib30.7.7.3" class="ltx_text" style="font-size:90%;"> [2011]</span></span>
<span class="ltx_bibblock"><span id="bib.bib30.9.1" class="ltx_text" style="font-size:90%;">
Yining Liu, Keqiu Li, Yingwei Jin, Yong Zhang, and Wenyu Qu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.10.1" class="ltx_text" style="font-size:90%;">A novel reputation computation model based on subjective logic for
mobile ad hoc networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.11.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Future Generation Computer Systems</span><span id="bib.bib30.12.2" class="ltx_text" style="font-size:90%;">, 27(5):547–554, 2011.
</span>
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib31.5.5.1" class="ltx_text" style="font-size:90%;">Ma </span><span id="bib.bib31.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib31.7.7.3" class="ltx_text" style="font-size:90%;"> [2021a]</span></span>
<span class="ltx_bibblock"><span id="bib.bib31.9.1" class="ltx_text" style="font-size:90%;">
Jiahua Ma, Xinghua Sun, Wenchao Xia, Xijun Wang, Xiang Chen, and Hongbo Zhu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.10.1" class="ltx_text" style="font-size:90%;">Client selection based on label quantity information for federated
learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.11.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib31.12.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2021 IEEE 32nd Annual International Symposium on Personal,
Indoor and Mobile Radio Communications (PIMRC)</span><span id="bib.bib31.13.3" class="ltx_text" style="font-size:90%;">, pages 1–6. IEEE, 2021.
</span>
</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib32.5.5.1" class="ltx_text" style="font-size:90%;">Ma </span><span id="bib.bib32.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib32.7.7.3" class="ltx_text" style="font-size:90%;"> [2021b]</span></span>
<span class="ltx_bibblock"><span id="bib.bib32.9.1" class="ltx_text" style="font-size:90%;">
Shuaicheng Ma, Yang Cao, and Li Xiong.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.10.1" class="ltx_text" style="font-size:90%;">Transparent contribution evaluation for secure federated learning on
blockchain.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.11.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib32.12.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2021 IEEE 37th International Conference on Data Engineering
Workshops (ICDEW)</span><span id="bib.bib32.13.3" class="ltx_text" style="font-size:90%;">, pages 88–91. IEEE, 2021.
</span>
</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib33.5.5.1" class="ltx_text" style="font-size:90%;">Ma </span><span id="bib.bib33.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib33.7.7.3" class="ltx_text" style="font-size:90%;"> [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib33.9.1" class="ltx_text" style="font-size:90%;">
Xiaosong Ma, Jie Zhang, Song Guo, and Wenchao Xu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.10.1" class="ltx_text" style="font-size:90%;">Layer-wised model aggregation for personalized federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.11.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib33.12.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib33.13.3" class="ltx_text" style="font-size:90%;">, pages 10092–10101, 2022.
</span>
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib34.5.5.1" class="ltx_text" style="font-size:90%;">Marfoq </span><span id="bib.bib34.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib34.7.7.3" class="ltx_text" style="font-size:90%;"> [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib34.9.1" class="ltx_text" style="font-size:90%;">
Othmane Marfoq, Giovanni Neglia, Richard Vidal, and Laetitia Kameni.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.10.1" class="ltx_text" style="font-size:90%;">Personalized federated learning through local memorization.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.11.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib34.12.2" class="ltx_text ltx_font_italic" style="font-size:90%;">International Conference on Machine Learning</span><span id="bib.bib34.13.3" class="ltx_text" style="font-size:90%;">, pages
15070–15092. PMLR, 2022.
</span>
</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib35.5.5.1" class="ltx_text" style="font-size:90%;">McMahan </span><span id="bib.bib35.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib35.7.7.3" class="ltx_text" style="font-size:90%;"> [2017]</span></span>
<span class="ltx_bibblock"><span id="bib.bib35.9.1" class="ltx_text" style="font-size:90%;">
Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera
y Arcas.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.10.1" class="ltx_text" style="font-size:90%;">Communication-efficient learning of deep networks from decentralized
data.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.11.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib35.12.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Artificial intelligence and statistics</span><span id="bib.bib35.13.3" class="ltx_text" style="font-size:90%;">, pages 1273–1282.
PMLR, 2017.
</span>
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib36.5.5.1" class="ltx_text" style="font-size:90%;">Qu </span><span id="bib.bib36.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib36.7.7.3" class="ltx_text" style="font-size:90%;"> [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib36.9.1" class="ltx_text" style="font-size:90%;">
Youyang Qu, Longxiang Gao, Tom H Luan, Yong Xiang, Shui Yu, Bai Li, and Gavin
Zheng.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.10.1" class="ltx_text" style="font-size:90%;">Decentralized privacy using blockchain-enabled federated learning in
fog computing.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.11.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Internet of Things Journal</span><span id="bib.bib36.12.2" class="ltx_text" style="font-size:90%;">, 7(6):5171–5183, 2020.
</span>
</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib37.5.5.1" class="ltx_text" style="font-size:90%;">Sannara </span><span id="bib.bib37.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib37.7.7.3" class="ltx_text" style="font-size:90%;"> [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib37.9.1" class="ltx_text" style="font-size:90%;">
EK Sannara, François Portet, Philippe Lalanda, and VEGA German.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.10.1" class="ltx_text" style="font-size:90%;">A federated learning aggregation algorithm for pervasive computing:
Evaluation and comparison.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.11.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib37.12.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2021 IEEE International Conference on Pervasive Computing and
Communications (PerCom)</span><span id="bib.bib37.13.3" class="ltx_text" style="font-size:90%;">, pages 1–10. IEEE, 2021.
</span>
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib38.5.5.1" class="ltx_text" style="font-size:90%;">Shayan </span><span id="bib.bib38.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib38.7.7.3" class="ltx_text" style="font-size:90%;"> [2018]</span></span>
<span class="ltx_bibblock"><span id="bib.bib38.9.1" class="ltx_text" style="font-size:90%;">
Muhammad Shayan, Clement Fung, Chris JM Yoon, and Ivan Beschastnikh.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.10.1" class="ltx_text" style="font-size:90%;">Biscotti: A ledger for private and secure peer-to-peer machine
learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.11.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1811.09904</span><span id="bib.bib38.12.2" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib39.5.5.1" class="ltx_text" style="font-size:90%;">Soltani </span><span id="bib.bib39.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib39.7.7.3" class="ltx_text" style="font-size:90%;"> [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib39.9.1" class="ltx_text" style="font-size:90%;">
Behnaz Soltani, Venus Haghighi, Adnan Mahmood, Quan Z Sheng, and Lina Yao.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.10.1" class="ltx_text" style="font-size:90%;">A survey on participant selection for federated learning in mobile
networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.11.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib39.12.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the 17th ACM Workshop on Mobility in the
Evolving Internet Architecture</span><span id="bib.bib39.13.3" class="ltx_text" style="font-size:90%;">, pages 19–24, 2022.
</span>
</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib40.5.5.1" class="ltx_text" style="font-size:90%;">Su </span><span id="bib.bib40.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib40.7.7.3" class="ltx_text" style="font-size:90%;"> [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib40.9.1" class="ltx_text" style="font-size:90%;">
Dongyuan Su, Yipeng Zhou, and Laizhong Cui.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.10.1" class="ltx_text" style="font-size:90%;">Boost decentralized federated learning in vehicular networks by
diversifying data sources.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.11.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib40.12.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2022 IEEE 30th International Conference on Network Protocols
(ICNP)</span><span id="bib.bib40.13.3" class="ltx_text" style="font-size:90%;">, pages 1–11. IEEE, 2022.
</span>
</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib41.5.5.1" class="ltx_text" style="font-size:90%;">Tan </span><span id="bib.bib41.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib41.7.7.3" class="ltx_text" style="font-size:90%;"> [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib41.9.1" class="ltx_text" style="font-size:90%;">
Alysa Ziying Tan, Han Yu, Lizhen Cui, and Qiang Yang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.10.1" class="ltx_text" style="font-size:90%;">Towards personalized federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.11.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Neural Networks and Learning Systems</span><span id="bib.bib41.12.2" class="ltx_text" style="font-size:90%;">,
2022.
</span>
</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib42.5.5.1" class="ltx_text" style="font-size:90%;">Uddin </span><span id="bib.bib42.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib42.7.7.3" class="ltx_text" style="font-size:90%;"> [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib42.9.1" class="ltx_text" style="font-size:90%;">
Md Palash Uddin, Yong Xiang, Xuequan Lu, John Yearwood, and Longxiang Gao.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.10.1" class="ltx_text" style="font-size:90%;">Mutual information driven federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.11.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Parallel and Distributed Systems</span><span id="bib.bib42.12.2" class="ltx_text" style="font-size:90%;">,
32(7):1526–1538, 2020.
</span>
</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib43.5.5.1" class="ltx_text" style="font-size:90%;">Wang </span><span id="bib.bib43.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib43.7.7.3" class="ltx_text" style="font-size:90%;"> [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib43.9.1" class="ltx_text" style="font-size:90%;">
Guan Wang, Charlie Xiaoqian Dang, and Ziye Zhou.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.10.1" class="ltx_text" style="font-size:90%;">Measure contribution of participants in federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.11.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib43.12.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2019 IEEE International Conference on Big Data (Big Data)</span><span id="bib.bib43.13.3" class="ltx_text" style="font-size:90%;">,
pages 2597–2604. IEEE, 2019.
</span>
</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib44.5.5.1" class="ltx_text" style="font-size:90%;">Wang </span><span id="bib.bib44.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib44.7.7.3" class="ltx_text" style="font-size:90%;"> [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib44.9.1" class="ltx_text" style="font-size:90%;">
Tianhao Wang, Johannes Rausch, Ce Zhang, Ruoxi Jia, and Dawn Song.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib44.10.1" class="ltx_text" style="font-size:90%;">A principled approach to data valuation for federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib44.11.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib44.12.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Federated Learning</span><span id="bib.bib44.13.3" class="ltx_text" style="font-size:90%;">, pages 153–167. Springer, 2020.
</span>
</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib45.4.4.1" class="ltx_text" style="font-size:90%;">Wu and Wang [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib45.6.1" class="ltx_text" style="font-size:90%;">
Hongda Wu and Ping Wang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib45.7.1" class="ltx_text" style="font-size:90%;">Node selection toward faster convergence for federated learning on
non-iid data.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib45.8.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Network Science and Engineering</span><span id="bib.bib45.9.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib46.5.5.1" class="ltx_text" style="font-size:90%;">Yang </span><span id="bib.bib46.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib46.7.7.3" class="ltx_text" style="font-size:90%;"> [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib46.9.1" class="ltx_text" style="font-size:90%;">
Miao Yang, Ximin Wang, Hongbin Zhu, Haifeng Wang, and Hua Qian.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib46.10.1" class="ltx_text" style="font-size:90%;">Federated learning with class imbalance reduction.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib46.11.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib46.12.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2021 29th European Signal Processing Conference (EUSIPCO)</span><span id="bib.bib46.13.3" class="ltx_text" style="font-size:90%;">,
pages 2174–2178. IEEE, 2021.
</span>
</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib47.5.5.1" class="ltx_text" style="font-size:90%;">Zhang </span><span id="bib.bib47.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib47.7.7.3" class="ltx_text" style="font-size:90%;"> [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib47.9.1" class="ltx_text" style="font-size:90%;">
Michael Zhang, Karan Sapra, Sanja Fidler, Serena Yeung, and Jose M Alvarez.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib47.10.1" class="ltx_text" style="font-size:90%;">Personalized federated learning with first order model optimization.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib47.11.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2012.08565</span><span id="bib.bib47.12.2" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib48.5.5.1" class="ltx_text" style="font-size:90%;">Zhang </span><span id="bib.bib48.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib48.7.7.3" class="ltx_text" style="font-size:90%;"> [2021a]</span></span>
<span class="ltx_bibblock"><span id="bib.bib48.9.1" class="ltx_text" style="font-size:90%;">
Jingwen Zhang, Yuezhou Wu, and Rong Pan.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib48.10.1" class="ltx_text" style="font-size:90%;">Incentive mechanism for horizontal federated learning based on
reputation and reverse auction.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib48.11.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib48.12.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the Web Conference 2021</span><span id="bib.bib48.13.3" class="ltx_text" style="font-size:90%;">, pages 947–956,
2021.
</span>
</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib49.5.5.1" class="ltx_text" style="font-size:90%;">Zhang </span><span id="bib.bib49.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib49.7.7.3" class="ltx_text" style="font-size:90%;"> [2021b]</span></span>
<span class="ltx_bibblock"><span id="bib.bib49.9.1" class="ltx_text" style="font-size:90%;">
Wenyu Zhang, Xiumin Wang, Pan Zhou, Weiwei Wu, and Xinglin Zhang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib49.10.1" class="ltx_text" style="font-size:90%;">Client selection for federated learning with non-iid data in mobile
edge computing.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib49.11.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Access</span><span id="bib.bib49.12.2" class="ltx_text" style="font-size:90%;">, 9:24462–24474, 2021.
</span>
</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib50.5.5.1" class="ltx_text" style="font-size:90%;">Zhang </span><span id="bib.bib50.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib50.7.7.3" class="ltx_text" style="font-size:90%;"> [2021c]</span></span>
<span class="ltx_bibblock"><span id="bib.bib50.9.1" class="ltx_text" style="font-size:90%;">
Zhebin Zhang, Dajie Dong, Yuhang Ma, Yilong Ying, Dawei Jiang, Ke Chen, Lidan
Shou, and Gang Chen.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib50.10.1" class="ltx_text" style="font-size:90%;">Refiner: A reliable incentive-driven federated learning system
powered by blockchain.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib50.11.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the VLDB Endowment</span><span id="bib.bib50.12.2" class="ltx_text" style="font-size:90%;">, 14(12):2659–2662, 2021.
</span>
</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib51.5.5.1" class="ltx_text" style="font-size:90%;">Zhao </span><span id="bib.bib51.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib51.7.7.3" class="ltx_text" style="font-size:90%;"> [2018]</span></span>
<span class="ltx_bibblock"><span id="bib.bib51.9.1" class="ltx_text" style="font-size:90%;">
Yue Zhao, Meng Li, Liangzhen Lai, Naveen Suda, Damon Civin, and Vikas Chandra.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib51.10.1" class="ltx_text" style="font-size:90%;">Federated learning with non-iid data.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib51.11.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1806.00582</span><span id="bib.bib51.12.2" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib52.5.5.1" class="ltx_text" style="font-size:90%;">Zhao </span><span id="bib.bib52.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib52.7.7.3" class="ltx_text" style="font-size:90%;"> [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib52.9.1" class="ltx_text" style="font-size:90%;">
Jianxin Zhao, Xinyu Chang, Yanhao Feng, Chi Harold Liu, and Ningbo Liu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib52.10.1" class="ltx_text" style="font-size:90%;">Participant selection for federated learning with heterogeneous data
in intelligent transport system.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib52.11.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Intelligent Transportation Systems</span><span id="bib.bib52.12.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib53.5.5.1" class="ltx_text" style="font-size:90%;">Zhou </span><span id="bib.bib53.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib53.7.7.3" class="ltx_text" style="font-size:90%;"> [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib53.9.1" class="ltx_text" style="font-size:90%;">
Zhi Zhou, Xu Chen, En Li, Liekang Zeng, Ke Luo, and Junshan Zhang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib53.10.1" class="ltx_text" style="font-size:90%;">Edge intelligence: Paving the last mile of artificial intelligence
with edge computing.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib53.11.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE</span><span id="bib.bib53.12.2" class="ltx_text" style="font-size:90%;">, 107(8):1738–1762, 2019.
</span>
</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib54.5.5.1" class="ltx_text" style="font-size:90%;">Zhou </span><span id="bib.bib54.6.6.2" class="ltx_text ltx_font_italic" style="font-size:90%;">et al.</span><span id="bib.bib54.7.7.3" class="ltx_text" style="font-size:90%;"> [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib54.9.1" class="ltx_text" style="font-size:90%;">
Yipeng Zhou, Xuezheng Liu, Yao Fu, Di Wu, Jessie Hui Wang, and Shui Yu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib54.10.1" class="ltx_text" style="font-size:90%;">Optimizing the numbers of queries and replies in convex federated
learning with differential privacy.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib54.11.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Dependable and Secure Computing</span><span id="bib.bib54.12.2" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2305.08069" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2305.08070" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2305.08070">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2305.08070" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2305.08071" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Mon Feb 26 20:48:52 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
