<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2207.03637] OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering</title><meta property="og:description" content="The information in tables can be an important complement to text, making table-based question answering (QA) systems of great value.
The intrinsic complexity of handling tables often adds an extra burden to both model â€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2207.03637">

<!--Generated on Wed Mar 13 12:19:44 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">OmniTab: Pretraining with Natural and Synthetic Data 
<br class="ltx_break">for Few-shot Table-based Question Answering</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Zhengbao Jiang<sup id="id8.8.id1" class="ltx_sup"><span id="id8.8.id1.1" class="ltx_text ltx_font_italic">1</span></sup>, Yi Mao<sup id="id9.9.id2" class="ltx_sup">2</sup>, Pengcheng He<sup id="id10.10.id3" class="ltx_sup">2</sup>, Graham Neubig<sup id="id11.11.id4" class="ltx_sup">1</sup>, Weizhu Chen<sup id="id12.12.id5" class="ltx_sup">2</sup> 
<br class="ltx_break"><sup id="id13.13.id6" class="ltx_sup">1</sup>Language Technologies Institute, Carnegie Mellon University â€ƒ<sup id="id14.14.id7" class="ltx_sup">2</sup>Microsoft Azure AI 
<br class="ltx_break"><span id="id15.15.id8" class="ltx_text ltx_font_typewriter">{zhengbaj,gneubig}@cs.cmu.edu</span> 
<br class="ltx_break"><span id="id16.16.id9" class="ltx_text ltx_font_typewriter">{maoyi,penhe,wzchen}@microsoft.com</span>
</span><span class="ltx_author_notes">Â Â Work was done when interning at Microsoft Azure AI.</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id17.id1" class="ltx_p">The information in tables can be an important complement to text, making table-based question answering (QA) systems of great value.
The intrinsic complexity of handling tables often adds an extra burden to both model design and data annotation.
In this paper, we aim to develop a simple table-based QA model with minimal annotation effort.
Motivated by the fact that table-based QA requires both alignment between questions and tables and the ability to perform complicated reasoning over multiple table elements, we propose an omnivorous pretraining approach that consumes both <em id="id17.id1.1" class="ltx_emph ltx_font_italic">natural</em> and <em id="id17.id1.2" class="ltx_emph ltx_font_italic">synthetic</em> data to endow models with these respective abilities.
Specifically, given freely available tables, we leverage retrieval to pair them with relevant natural sentences for mask-based pretraining, and synthesize NL questions by converting SQL sampled from tables for pretraining with a QA loss.
We perform extensive experiments in both few-shot and full settings, and the results clearly demonstrate the superiority of our model OmniTab, with the best multitasking approach achieving an absolute gain of 16.2% and 2.7% in 128-shot and full settings respectively, also establishing a new state-of-the-art on WikiTableQuestions.
Detailed ablations and analyses reveal different characteristics of natural and synthetic data, shedding light on future directions in omnivorous pretraining.<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Code, pretraining data, and pretrained models are available at <a target="_blank" href="https://github.com/jzbjyb/OmniTab" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/jzbjyb/OmniTab</a>.</span></span></span></p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<figure id="S1.4" class="ltx_figure">
<div id="S1.4.4" class="ltx_logical-block ltx_minipage ltx_align_middle" style="width:433.6pt;">
<div id="S1.2.2.2" class="ltx_logical-block ltx_minipage ltx_align_bottom" style="width:264.5pt;">
<div id="S1.2.2.2.p1" class="ltx_para">
<img src="/html/2207.03637/assets/x1.png" id="S1.1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="461" height="272" alt="[Uncaptioned image]">
</div>
<figure id="S1.F1" class="ltx_figure ltx_align_center">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Example of natural and synthetic pretraining data and a manually annotated finetuning question. Phrases aligned with table elements and reasoning operations are marked with <span id="S1.F1.3.1" class="ltx_text" style="color:#800080;">violet</span> and <span id="S1.F1.4.2" class="ltx_text" style="color:#FF0000;">red</span> respectively. [Table] denotes the linearized table.</figcaption>
</figure>
</div>
<div id="S1.4.4.4" class="ltx_logical-block ltx_minipage ltx_align_bottom" style="width:160.4pt;">
<div id="S1.4.4.4.p1" class="ltx_para">
<img src="/html/2207.03637/assets/x2.png" id="S1.3.3.3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="361" alt="[Uncaptioned image]">
</div>
<figure id="S1.F2" class="ltx_figure ltx_align_center">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>The overall framework of generating and pretraining with natural data (<span id="S1.F2.4.1" class="ltx_text" style="color:#007AA6;">blue</span> pipeline), synthetic data (<span id="S1.F2.5.2" class="ltx_text" style="color:#006B3D;">green</span> pipeline), and finetuning with limited annotated questions (<span id="S1.F2.6.3" class="ltx_text" style="color:#ED872E;">orange</span> pipeline) for our OmniTab model.</figcaption>
</figure>
</div>
</div>
</figure>
<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Humans are voracious information omnivores, consuming information in a number of forms.
Unstructured text is the form covered in most work in NLP, but another form widely used on the web, academic papers, and reports is the <em id="S1.p1.1.1" class="ltx_emph ltx_font_italic">table</em>, where elements are organized in rows and columns and presented in a structured and succinct way.
Because of this, systems to aid information access over tables, such as table-based question answering (QA) <cite class="ltx_cite ltx_citemacro_cite">Pasupat and Liang (<a href="#bib.bib19" title="" class="ltx_ref">2015</a>); Iyyer etÂ al. (<a href="#bib.bib9" title="" class="ltx_ref">2017</a>); Zhong etÂ al. (<a href="#bib.bib27" title="" class="ltx_ref">2017</a>)</cite>, hold significant promise.
However, they also require understanding of the table structure and sophisticated reasoning across multiple elements to get the final answer.
This intrinsic complexity not only often requires special-purpose model designs such as pipeline systems that generate structured queries as intermediate steps <cite class="ltx_cite ltx_citemacro_cite">Liang etÂ al. (<a href="#bib.bib15" title="" class="ltx_ref">2018</a>); Wang etÂ al. (<a href="#bib.bib23" title="" class="ltx_ref">2019</a>); Yin etÂ al. (<a href="#bib.bib25" title="" class="ltx_ref">2020</a>); Yu etÂ al. (<a href="#bib.bib26" title="" class="ltx_ref">2021</a>)</cite>, but also adds an extra burden to the process of data annotation <cite class="ltx_cite ltx_citemacro_cite">Pasupat and Liang (<a href="#bib.bib19" title="" class="ltx_ref">2015</a>); Shi etÂ al. (<a href="#bib.bib22" title="" class="ltx_ref">2020</a>)</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Given the challenges above, we ask the question: â€œcan we create a <em id="S1.p2.1.1" class="ltx_emph ltx_font_italic">simple</em> model that is able to answer complex table-based questions with <em id="S1.p2.1.2" class="ltx_emph ltx_font_italic">minimal annotation effort</em>?â€
Both modeling simplicity and limited assumptions regarding data availability would make it easier to apply table-based QA systems in practical scenarios.
To this end, we focus on developing a simple and generic end2end table-based QA model where only a limited number of annotated natural language (NL) questions are available; the first attempt to address this problem under few-shot settings.
In order to answer table-related questions, an end2end model needs to understand both the NL question and the table, build connections between the two formats, then perform complex reasoning.
Taking the manually annotated question in <a href="#S1.F1" title="Figure 1 â€£ 1 Introduction â€£ OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Fig.Â 1</span></a> as an example, models need to align entities (â€œCollateral Damageâ€) and concepts (â€œfilmâ€, â€œairâ€) in the question to elements in the table (the â€œCollateral Damageâ€ cell and the â€œFilmâ€ and â€œDateâ€ columns) and perform comparative reasoning based on chronological order (indicated by â€œpreviousâ€ and â€œbeforeâ€) to find the final answer.
Motivated by this, we propose <span id="S1.p2.1.3" class="ltx_text ltx_font_bold">OmniTab</span>, an omnivorous pretraining approach that consumes <em id="S1.p2.1.4" class="ltx_emph ltx_font_italic">natural</em> data to endow models with the ability to understand and align NL with tables, and <em id="S1.p2.1.5" class="ltx_emph ltx_font_italic">synthetic</em> data to train models to perform reasoning.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">To obtain natural NL-table pairs, we propose a novel approach that leverages the multitude of tables freely available from the web, and uses <em id="S1.p3.1.1" class="ltx_emph ltx_font_italic">retrieval</em> to pair them with relevant NL sentences.
Compared with manually defined heuristics used in previous work <cite class="ltx_cite ltx_citemacro_cite">Herzig etÂ al. (<a href="#bib.bib8" title="" class="ltx_ref">2020</a>); Yin etÂ al. (<a href="#bib.bib25" title="" class="ltx_ref">2020</a>)</cite>, retrieval-based methods have the potential to discover better-aligned sentences.
We explore different retrieval methods including string-based matching, sparse retrieval, and dense retrieval <cite class="ltx_cite ltx_citemacro_cite">Karpukhin etÂ al. (<a href="#bib.bib10" title="" class="ltx_ref">2020</a>); Khattab and Zaharia (<a href="#bib.bib11" title="" class="ltx_ref">2020</a>); Gao etÂ al. (<a href="#bib.bib5" title="" class="ltx_ref">2021</a>)</cite>.
Given these retrieved pairs, phrases in the sentence that align with table elements are then masked and the model takes both the masked sentence and the linearized table as input to predict masked mentions.
For example, in <a href="#S1.F1" title="Figure 1 â€£ 1 Introduction â€£ OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Fig.Â 1</span></a> the retrieved sentence describes a particular row and contains two phrases matching cells in the table (i.e., â€œSpider-Manâ€ and â€œ$114.8 millionâ€) which are masked for prediction.
To perform this sort of masked prediction, models need to understand that the sentence is about a record-breaking movie and refer to the table to extract the correct cells.
Thus, training on this data endows models with better understanding and alignment across both formats.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">For the synthetic data approach, we propose a method where structured queries such as SQL are first sampled and then converted into NL questions using an SQL2NL model, which allows for control of the reasoning operations covered by the SQL.
Compared to existing work that trains directly on SQL <cite class="ltx_cite ltx_citemacro_cite">Liu etÂ al. (<a href="#bib.bib16" title="" class="ltx_ref">2021</a>)</cite>, an approach hindered by the gap between structured and natural language, training on synthetic NL questions can close the gap, especially when limited annotated NL questions are available.
We train the SQL2NL model with a small number of SQL-NL pairs and further boost its performance using verification-based self-training, which selects high-quality generated NL questions based on their likelihood to generate the gold answer.
The converted NL question concatenated with the linearized table is fed into the model to directly generate the final answer, as shown in the synthetic example in <a href="#S1.F1" title="Figure 1 â€£ 1 Introduction â€£ OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Fig.Â 1</span></a> which involves comparative reasoning indicated by the phrase â€œmore thanâ€.
Although the fluency and naturalness of synthetic data is usually lower than natural data, learning on synthetic data provides a direct way to simulate different reasoning skills, which is relatively sparse in natural data.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">Our overall framework is shown in <a href="#S1.F2" title="Figure 2 â€£ 1 Introduction â€£ OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Fig.Â 2</span></a>.
We use tables from Wikipedia and retrieve relevant sentences from the same page to generate natural text-table parallel data after masking mentions aligned to table elements (the blue pipeline on the left of <a href="#S1.F2" title="Figure 2 â€£ 1 Introduction â€£ OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Fig.Â 2</span></a>).
We use SQL queries sampled by <cite class="ltx_cite ltx_citemacro_citet">Liu etÂ al. (<a href="#bib.bib16" title="" class="ltx_ref">2021</a>)</cite> and convert them to NL questions as synthetic text-table parallel data (the green pipeline on the right of <a href="#S1.F2" title="Figure 2 â€£ 1 Introduction â€£ OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Fig.Â 2</span></a>).
We use WikiTableQuestions (WTQ) <cite class="ltx_cite ltx_citemacro_cite">Pasupat and Liang (<a href="#bib.bib19" title="" class="ltx_ref">2015</a>)</cite>, a widely used table-based QA dataset consisting of complex questions, as our major benchmark to evaluate our pretraining methods, and further use WikiSQL <cite class="ltx_cite ltx_citemacro_cite">Zhong etÂ al. (<a href="#bib.bib27" title="" class="ltx_ref">2017</a>)</cite> and topic-categorized WTQ <cite class="ltx_cite ltx_citemacro_cite">Chemmengath etÂ al. (<a href="#bib.bib1" title="" class="ltx_ref">2021</a>)</cite> to evaluate the robustness of our methods, all under few-shot setting with sizes ranging from 16 to 1,024.
When using only 128 annotated questions, our model OmniTab improves over the best-performing baseline by an absolute gain of 13.2% and 12.3% with natural and synthetic pretraining separately and 16.2% when combined, demonstrating the effectiveness of the approach.
We also achieve state-of-the-art performance on the full WTQ with an absolute gain of 2.7%.
Extensive ablations and analyses reveal that natural and synthetic data indeed play the role of enhancing alignment and injecting reasoning, shedding light on future works on omnivorous pretraining.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>End2End Table-based QA</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">In this section, we first explain the setting of table-based QA, then introduce the input format as well as our model architecture.</p>
</div>
<section id="S2.SS0.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Table-based QA</h5>

<div id="S2.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S2.SS0.SSS0.Px1.p1.13" class="ltx_p">Each example in table-based QA consists of an NL question <math id="S2.SS0.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="\bm{q}" display="inline"><semantics id="S2.SS0.SSS0.Px1.p1.1.m1.1a"><mi id="S2.SS0.SSS0.Px1.p1.1.m1.1.1" xref="S2.SS0.SSS0.Px1.p1.1.m1.1.1.cmml">ğ’’</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p1.1.m1.1b"><ci id="S2.SS0.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.1.m1.1.1">ğ’’</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p1.1.m1.1c">\bm{q}</annotation></semantics></math>, a table <math id="S2.SS0.SSS0.Px1.p1.2.m2.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S2.SS0.SSS0.Px1.p1.2.m2.1a"><mi id="S2.SS0.SSS0.Px1.p1.2.m2.1.1" xref="S2.SS0.SSS0.Px1.p1.2.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p1.2.m2.1b"><ci id="S2.SS0.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.2.m2.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p1.2.m2.1c">T</annotation></semantics></math>, and an answer <math id="S2.SS0.SSS0.Px1.p1.3.m3.1" class="ltx_Math" alttext="\bm{a}" display="inline"><semantics id="S2.SS0.SSS0.Px1.p1.3.m3.1a"><mi id="S2.SS0.SSS0.Px1.p1.3.m3.1.1" xref="S2.SS0.SSS0.Px1.p1.3.m3.1.1.cmml">ğ’‚</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p1.3.m3.1b"><ci id="S2.SS0.SSS0.Px1.p1.3.m3.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.3.m3.1.1">ğ’‚</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p1.3.m3.1c">\bm{a}</annotation></semantics></math>.
Both questions and answers are a sequence of tokens.
Each table consists of <math id="S2.SS0.SSS0.Px1.p1.4.m4.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S2.SS0.SSS0.Px1.p1.4.m4.1a"><mi id="S2.SS0.SSS0.Px1.p1.4.m4.1.1" xref="S2.SS0.SSS0.Px1.p1.4.m4.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p1.4.m4.1b"><ci id="S2.SS0.SSS0.Px1.p1.4.m4.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.4.m4.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p1.4.m4.1c">N</annotation></semantics></math> rows <math id="S2.SS0.SSS0.Px1.p1.5.m5.1" class="ltx_Math" alttext="\{r_{i}\}_{i=1}^{N}" display="inline"><semantics id="S2.SS0.SSS0.Px1.p1.5.m5.1a"><msubsup id="S2.SS0.SSS0.Px1.p1.5.m5.1.1" xref="S2.SS0.SSS0.Px1.p1.5.m5.1.1.cmml"><mrow id="S2.SS0.SSS0.Px1.p1.5.m5.1.1.1.1.1" xref="S2.SS0.SSS0.Px1.p1.5.m5.1.1.1.1.2.cmml"><mo stretchy="false" id="S2.SS0.SSS0.Px1.p1.5.m5.1.1.1.1.1.2" xref="S2.SS0.SSS0.Px1.p1.5.m5.1.1.1.1.2.cmml">{</mo><msub id="S2.SS0.SSS0.Px1.p1.5.m5.1.1.1.1.1.1" xref="S2.SS0.SSS0.Px1.p1.5.m5.1.1.1.1.1.1.cmml"><mi id="S2.SS0.SSS0.Px1.p1.5.m5.1.1.1.1.1.1.2" xref="S2.SS0.SSS0.Px1.p1.5.m5.1.1.1.1.1.1.2.cmml">r</mi><mi id="S2.SS0.SSS0.Px1.p1.5.m5.1.1.1.1.1.1.3" xref="S2.SS0.SSS0.Px1.p1.5.m5.1.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S2.SS0.SSS0.Px1.p1.5.m5.1.1.1.1.1.3" xref="S2.SS0.SSS0.Px1.p1.5.m5.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S2.SS0.SSS0.Px1.p1.5.m5.1.1.1.3" xref="S2.SS0.SSS0.Px1.p1.5.m5.1.1.1.3.cmml"><mi id="S2.SS0.SSS0.Px1.p1.5.m5.1.1.1.3.2" xref="S2.SS0.SSS0.Px1.p1.5.m5.1.1.1.3.2.cmml">i</mi><mo id="S2.SS0.SSS0.Px1.p1.5.m5.1.1.1.3.1" xref="S2.SS0.SSS0.Px1.p1.5.m5.1.1.1.3.1.cmml">=</mo><mn id="S2.SS0.SSS0.Px1.p1.5.m5.1.1.1.3.3" xref="S2.SS0.SSS0.Px1.p1.5.m5.1.1.1.3.3.cmml">1</mn></mrow><mi id="S2.SS0.SSS0.Px1.p1.5.m5.1.1.3" xref="S2.SS0.SSS0.Px1.p1.5.m5.1.1.3.cmml">N</mi></msubsup><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p1.5.m5.1b"><apply id="S2.SS0.SSS0.Px1.p1.5.m5.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px1.p1.5.m5.1.1.2.cmml" xref="S2.SS0.SSS0.Px1.p1.5.m5.1.1">superscript</csymbol><apply id="S2.SS0.SSS0.Px1.p1.5.m5.1.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px1.p1.5.m5.1.1.1.2.cmml" xref="S2.SS0.SSS0.Px1.p1.5.m5.1.1">subscript</csymbol><set id="S2.SS0.SSS0.Px1.p1.5.m5.1.1.1.1.2.cmml" xref="S2.SS0.SSS0.Px1.p1.5.m5.1.1.1.1.1"><apply id="S2.SS0.SSS0.Px1.p1.5.m5.1.1.1.1.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.5.m5.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px1.p1.5.m5.1.1.1.1.1.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.5.m5.1.1.1.1.1.1">subscript</csymbol><ci id="S2.SS0.SSS0.Px1.p1.5.m5.1.1.1.1.1.1.2.cmml" xref="S2.SS0.SSS0.Px1.p1.5.m5.1.1.1.1.1.1.2">ğ‘Ÿ</ci><ci id="S2.SS0.SSS0.Px1.p1.5.m5.1.1.1.1.1.1.3.cmml" xref="S2.SS0.SSS0.Px1.p1.5.m5.1.1.1.1.1.1.3">ğ‘–</ci></apply></set><apply id="S2.SS0.SSS0.Px1.p1.5.m5.1.1.1.3.cmml" xref="S2.SS0.SSS0.Px1.p1.5.m5.1.1.1.3"><eq id="S2.SS0.SSS0.Px1.p1.5.m5.1.1.1.3.1.cmml" xref="S2.SS0.SSS0.Px1.p1.5.m5.1.1.1.3.1"></eq><ci id="S2.SS0.SSS0.Px1.p1.5.m5.1.1.1.3.2.cmml" xref="S2.SS0.SSS0.Px1.p1.5.m5.1.1.1.3.2">ğ‘–</ci><cn type="integer" id="S2.SS0.SSS0.Px1.p1.5.m5.1.1.1.3.3.cmml" xref="S2.SS0.SSS0.Px1.p1.5.m5.1.1.1.3.3">1</cn></apply></apply><ci id="S2.SS0.SSS0.Px1.p1.5.m5.1.1.3.cmml" xref="S2.SS0.SSS0.Px1.p1.5.m5.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p1.5.m5.1c">\{r_{i}\}_{i=1}^{N}</annotation></semantics></math> and <math id="S2.SS0.SSS0.Px1.p1.6.m6.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S2.SS0.SSS0.Px1.p1.6.m6.1a"><mi id="S2.SS0.SSS0.Px1.p1.6.m6.1.1" xref="S2.SS0.SSS0.Px1.p1.6.m6.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p1.6.m6.1b"><ci id="S2.SS0.SSS0.Px1.p1.6.m6.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.6.m6.1.1">ğ‘€</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p1.6.m6.1c">M</annotation></semantics></math> columns, where the token sequence in the cell located at the <math id="S2.SS0.SSS0.Px1.p1.7.m7.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S2.SS0.SSS0.Px1.p1.7.m7.1a"><mi id="S2.SS0.SSS0.Px1.p1.7.m7.1.1" xref="S2.SS0.SSS0.Px1.p1.7.m7.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p1.7.m7.1b"><ci id="S2.SS0.SSS0.Px1.p1.7.m7.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.7.m7.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p1.7.m7.1c">i</annotation></semantics></math>-th row and <math id="S2.SS0.SSS0.Px1.p1.8.m8.1" class="ltx_Math" alttext="j" display="inline"><semantics id="S2.SS0.SSS0.Px1.p1.8.m8.1a"><mi id="S2.SS0.SSS0.Px1.p1.8.m8.1.1" xref="S2.SS0.SSS0.Px1.p1.8.m8.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p1.8.m8.1b"><ci id="S2.SS0.SSS0.Px1.p1.8.m8.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.8.m8.1.1">ğ‘—</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p1.8.m8.1c">j</annotation></semantics></math>-th column is denoted as <math id="S2.SS0.SSS0.Px1.p1.9.m9.2" class="ltx_Math" alttext="\bm{c}_{i,j}" display="inline"><semantics id="S2.SS0.SSS0.Px1.p1.9.m9.2a"><msub id="S2.SS0.SSS0.Px1.p1.9.m9.2.3" xref="S2.SS0.SSS0.Px1.p1.9.m9.2.3.cmml"><mi id="S2.SS0.SSS0.Px1.p1.9.m9.2.3.2" xref="S2.SS0.SSS0.Px1.p1.9.m9.2.3.2.cmml">ğ’„</mi><mrow id="S2.SS0.SSS0.Px1.p1.9.m9.2.2.2.4" xref="S2.SS0.SSS0.Px1.p1.9.m9.2.2.2.3.cmml"><mi id="S2.SS0.SSS0.Px1.p1.9.m9.1.1.1.1" xref="S2.SS0.SSS0.Px1.p1.9.m9.1.1.1.1.cmml">i</mi><mo id="S2.SS0.SSS0.Px1.p1.9.m9.2.2.2.4.1" xref="S2.SS0.SSS0.Px1.p1.9.m9.2.2.2.3.cmml">,</mo><mi id="S2.SS0.SSS0.Px1.p1.9.m9.2.2.2.2" xref="S2.SS0.SSS0.Px1.p1.9.m9.2.2.2.2.cmml">j</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p1.9.m9.2b"><apply id="S2.SS0.SSS0.Px1.p1.9.m9.2.3.cmml" xref="S2.SS0.SSS0.Px1.p1.9.m9.2.3"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px1.p1.9.m9.2.3.1.cmml" xref="S2.SS0.SSS0.Px1.p1.9.m9.2.3">subscript</csymbol><ci id="S2.SS0.SSS0.Px1.p1.9.m9.2.3.2.cmml" xref="S2.SS0.SSS0.Px1.p1.9.m9.2.3.2">ğ’„</ci><list id="S2.SS0.SSS0.Px1.p1.9.m9.2.2.2.3.cmml" xref="S2.SS0.SSS0.Px1.p1.9.m9.2.2.2.4"><ci id="S2.SS0.SSS0.Px1.p1.9.m9.1.1.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.9.m9.1.1.1.1">ğ‘–</ci><ci id="S2.SS0.SSS0.Px1.p1.9.m9.2.2.2.2.cmml" xref="S2.SS0.SSS0.Px1.p1.9.m9.2.2.2.2">ğ‘—</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p1.9.m9.2c">\bm{c}_{i,j}</annotation></semantics></math>.
The first row <math id="S2.SS0.SSS0.Px1.p1.10.m10.1" class="ltx_Math" alttext="r_{1}" display="inline"><semantics id="S2.SS0.SSS0.Px1.p1.10.m10.1a"><msub id="S2.SS0.SSS0.Px1.p1.10.m10.1.1" xref="S2.SS0.SSS0.Px1.p1.10.m10.1.1.cmml"><mi id="S2.SS0.SSS0.Px1.p1.10.m10.1.1.2" xref="S2.SS0.SSS0.Px1.p1.10.m10.1.1.2.cmml">r</mi><mn id="S2.SS0.SSS0.Px1.p1.10.m10.1.1.3" xref="S2.SS0.SSS0.Px1.p1.10.m10.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p1.10.m10.1b"><apply id="S2.SS0.SSS0.Px1.p1.10.m10.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.10.m10.1.1"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px1.p1.10.m10.1.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.10.m10.1.1">subscript</csymbol><ci id="S2.SS0.SSS0.Px1.p1.10.m10.1.1.2.cmml" xref="S2.SS0.SSS0.Px1.p1.10.m10.1.1.2">ğ‘Ÿ</ci><cn type="integer" id="S2.SS0.SSS0.Px1.p1.10.m10.1.1.3.cmml" xref="S2.SS0.SSS0.Px1.p1.10.m10.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p1.10.m10.1c">r_{1}</annotation></semantics></math> is the header row, indicating the meaning of each column.
Table-based QA aims to generate the answer <math id="S2.SS0.SSS0.Px1.p1.11.m11.1" class="ltx_Math" alttext="\bm{a}" display="inline"><semantics id="S2.SS0.SSS0.Px1.p1.11.m11.1a"><mi id="S2.SS0.SSS0.Px1.p1.11.m11.1.1" xref="S2.SS0.SSS0.Px1.p1.11.m11.1.1.cmml">ğ’‚</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p1.11.m11.1b"><ci id="S2.SS0.SSS0.Px1.p1.11.m11.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.11.m11.1.1">ğ’‚</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p1.11.m11.1c">\bm{a}</annotation></semantics></math> given both the question <math id="S2.SS0.SSS0.Px1.p1.12.m12.1" class="ltx_Math" alttext="\bm{q}" display="inline"><semantics id="S2.SS0.SSS0.Px1.p1.12.m12.1a"><mi id="S2.SS0.SSS0.Px1.p1.12.m12.1.1" xref="S2.SS0.SSS0.Px1.p1.12.m12.1.1.cmml">ğ’’</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p1.12.m12.1b"><ci id="S2.SS0.SSS0.Px1.p1.12.m12.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.12.m12.1.1">ğ’’</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p1.12.m12.1c">\bm{q}</annotation></semantics></math> and the table <math id="S2.SS0.SSS0.Px1.p1.13.m13.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S2.SS0.SSS0.Px1.p1.13.m13.1a"><mi id="S2.SS0.SSS0.Px1.p1.13.m13.1.1" xref="S2.SS0.SSS0.Px1.p1.13.m13.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p1.13.m13.1b"><ci id="S2.SS0.SSS0.Px1.p1.13.m13.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.13.m13.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p1.13.m13.1c">T</annotation></semantics></math> as the input.</p>
</div>
</section>
<section id="S2.SS0.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Input Format</h5>

<div id="S2.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S2.SS0.SSS0.Px2.p1.14" class="ltx_p">We follow <cite class="ltx_cite ltx_citemacro_citet">Liu etÂ al. (<a href="#bib.bib16" title="" class="ltx_ref">2021</a>)</cite> in concatenating the NL context with the linearized table as input.
We flatten the table following a top-to-bottom and left-to-right order, where we prepend â€œcol:â€ to the beginning of the header and â€œrow <math id="S2.SS0.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S2.SS0.SSS0.Px2.p1.1.m1.1a"><mi id="S2.SS0.SSS0.Px2.p1.1.m1.1.1" xref="S2.SS0.SSS0.Px2.p1.1.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p1.1.m1.1b"><ci id="S2.SS0.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.1.m1.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p1.1.m1.1c">i</annotation></semantics></math>:â€ to the beginning of the <math id="S2.SS0.SSS0.Px2.p1.2.m2.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S2.SS0.SSS0.Px2.p1.2.m2.1a"><mi id="S2.SS0.SSS0.Px2.p1.2.m2.1.1" xref="S2.SS0.SSS0.Px2.p1.2.m2.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p1.2.m2.1b"><ci id="S2.SS0.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.2.m2.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p1.2.m2.1c">i</annotation></semantics></math>-th row to separate different rows: <math id="S2.SS0.SSS0.Px2.p1.3.m3.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S2.SS0.SSS0.Px2.p1.3.m3.1a"><mi id="S2.SS0.SSS0.Px2.p1.3.m3.1.1" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p1.3.m3.1b"><ci id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p1.3.m3.1c">T</annotation></semantics></math> = [col: <math id="S2.SS0.SSS0.Px2.p1.4.m4.1" class="ltx_Math" alttext="r_{1}" display="inline"><semantics id="S2.SS0.SSS0.Px2.p1.4.m4.1a"><msub id="S2.SS0.SSS0.Px2.p1.4.m4.1.1" xref="S2.SS0.SSS0.Px2.p1.4.m4.1.1.cmml"><mi id="S2.SS0.SSS0.Px2.p1.4.m4.1.1.2" xref="S2.SS0.SSS0.Px2.p1.4.m4.1.1.2.cmml">r</mi><mn id="S2.SS0.SSS0.Px2.p1.4.m4.1.1.3" xref="S2.SS0.SSS0.Px2.p1.4.m4.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p1.4.m4.1b"><apply id="S2.SS0.SSS0.Px2.p1.4.m4.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px2.p1.4.m4.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.4.m4.1.1">subscript</csymbol><ci id="S2.SS0.SSS0.Px2.p1.4.m4.1.1.2.cmml" xref="S2.SS0.SSS0.Px2.p1.4.m4.1.1.2">ğ‘Ÿ</ci><cn type="integer" id="S2.SS0.SSS0.Px2.p1.4.m4.1.1.3.cmml" xref="S2.SS0.SSS0.Px2.p1.4.m4.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p1.4.m4.1c">r_{1}</annotation></semantics></math> row 1: <math id="S2.SS0.SSS0.Px2.p1.5.m5.1" class="ltx_Math" alttext="r_{2}" display="inline"><semantics id="S2.SS0.SSS0.Px2.p1.5.m5.1a"><msub id="S2.SS0.SSS0.Px2.p1.5.m5.1.1" xref="S2.SS0.SSS0.Px2.p1.5.m5.1.1.cmml"><mi id="S2.SS0.SSS0.Px2.p1.5.m5.1.1.2" xref="S2.SS0.SSS0.Px2.p1.5.m5.1.1.2.cmml">r</mi><mn id="S2.SS0.SSS0.Px2.p1.5.m5.1.1.3" xref="S2.SS0.SSS0.Px2.p1.5.m5.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p1.5.m5.1b"><apply id="S2.SS0.SSS0.Px2.p1.5.m5.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px2.p1.5.m5.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.5.m5.1.1">subscript</csymbol><ci id="S2.SS0.SSS0.Px2.p1.5.m5.1.1.2.cmml" xref="S2.SS0.SSS0.Px2.p1.5.m5.1.1.2">ğ‘Ÿ</ci><cn type="integer" id="S2.SS0.SSS0.Px2.p1.5.m5.1.1.3.cmml" xref="S2.SS0.SSS0.Px2.p1.5.m5.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p1.5.m5.1c">r_{2}</annotation></semantics></math> â€¦ row <math id="S2.SS0.SSS0.Px2.p1.6.m6.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S2.SS0.SSS0.Px2.p1.6.m6.1a"><mi id="S2.SS0.SSS0.Px2.p1.6.m6.1.1" xref="S2.SS0.SSS0.Px2.p1.6.m6.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p1.6.m6.1b"><ci id="S2.SS0.SSS0.Px2.p1.6.m6.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.6.m6.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p1.6.m6.1c">N</annotation></semantics></math>: <math id="S2.SS0.SSS0.Px2.p1.7.m7.1" class="ltx_Math" alttext="r_{N}" display="inline"><semantics id="S2.SS0.SSS0.Px2.p1.7.m7.1a"><msub id="S2.SS0.SSS0.Px2.p1.7.m7.1.1" xref="S2.SS0.SSS0.Px2.p1.7.m7.1.1.cmml"><mi id="S2.SS0.SSS0.Px2.p1.7.m7.1.1.2" xref="S2.SS0.SSS0.Px2.p1.7.m7.1.1.2.cmml">r</mi><mi id="S2.SS0.SSS0.Px2.p1.7.m7.1.1.3" xref="S2.SS0.SSS0.Px2.p1.7.m7.1.1.3.cmml">N</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p1.7.m7.1b"><apply id="S2.SS0.SSS0.Px2.p1.7.m7.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px2.p1.7.m7.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.7.m7.1.1">subscript</csymbol><ci id="S2.SS0.SSS0.Px2.p1.7.m7.1.1.2.cmml" xref="S2.SS0.SSS0.Px2.p1.7.m7.1.1.2">ğ‘Ÿ</ci><ci id="S2.SS0.SSS0.Px2.p1.7.m7.1.1.3.cmml" xref="S2.SS0.SSS0.Px2.p1.7.m7.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p1.7.m7.1c">r_{N}</annotation></semantics></math>].
Cells within each row are separated by a vertical bar â€œ|â€ <math id="S2.SS0.SSS0.Px2.p1.8.m8.1" class="ltx_Math" alttext="r_{i}" display="inline"><semantics id="S2.SS0.SSS0.Px2.p1.8.m8.1a"><msub id="S2.SS0.SSS0.Px2.p1.8.m8.1.1" xref="S2.SS0.SSS0.Px2.p1.8.m8.1.1.cmml"><mi id="S2.SS0.SSS0.Px2.p1.8.m8.1.1.2" xref="S2.SS0.SSS0.Px2.p1.8.m8.1.1.2.cmml">r</mi><mi id="S2.SS0.SSS0.Px2.p1.8.m8.1.1.3" xref="S2.SS0.SSS0.Px2.p1.8.m8.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p1.8.m8.1b"><apply id="S2.SS0.SSS0.Px2.p1.8.m8.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.8.m8.1.1"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px2.p1.8.m8.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.8.m8.1.1">subscript</csymbol><ci id="S2.SS0.SSS0.Px2.p1.8.m8.1.1.2.cmml" xref="S2.SS0.SSS0.Px2.p1.8.m8.1.1.2">ğ‘Ÿ</ci><ci id="S2.SS0.SSS0.Px2.p1.8.m8.1.1.3.cmml" xref="S2.SS0.SSS0.Px2.p1.8.m8.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p1.8.m8.1c">r_{i}</annotation></semantics></math> = [<math id="S2.SS0.SSS0.Px2.p1.9.m9.2" class="ltx_Math" alttext="\bm{c}_{i,1}" display="inline"><semantics id="S2.SS0.SSS0.Px2.p1.9.m9.2a"><msub id="S2.SS0.SSS0.Px2.p1.9.m9.2.3" xref="S2.SS0.SSS0.Px2.p1.9.m9.2.3.cmml"><mi id="S2.SS0.SSS0.Px2.p1.9.m9.2.3.2" xref="S2.SS0.SSS0.Px2.p1.9.m9.2.3.2.cmml">ğ’„</mi><mrow id="S2.SS0.SSS0.Px2.p1.9.m9.2.2.2.4" xref="S2.SS0.SSS0.Px2.p1.9.m9.2.2.2.3.cmml"><mi id="S2.SS0.SSS0.Px2.p1.9.m9.1.1.1.1" xref="S2.SS0.SSS0.Px2.p1.9.m9.1.1.1.1.cmml">i</mi><mo id="S2.SS0.SSS0.Px2.p1.9.m9.2.2.2.4.1" xref="S2.SS0.SSS0.Px2.p1.9.m9.2.2.2.3.cmml">,</mo><mn id="S2.SS0.SSS0.Px2.p1.9.m9.2.2.2.2" xref="S2.SS0.SSS0.Px2.p1.9.m9.2.2.2.2.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p1.9.m9.2b"><apply id="S2.SS0.SSS0.Px2.p1.9.m9.2.3.cmml" xref="S2.SS0.SSS0.Px2.p1.9.m9.2.3"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px2.p1.9.m9.2.3.1.cmml" xref="S2.SS0.SSS0.Px2.p1.9.m9.2.3">subscript</csymbol><ci id="S2.SS0.SSS0.Px2.p1.9.m9.2.3.2.cmml" xref="S2.SS0.SSS0.Px2.p1.9.m9.2.3.2">ğ’„</ci><list id="S2.SS0.SSS0.Px2.p1.9.m9.2.2.2.3.cmml" xref="S2.SS0.SSS0.Px2.p1.9.m9.2.2.2.4"><ci id="S2.SS0.SSS0.Px2.p1.9.m9.1.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.9.m9.1.1.1.1">ğ‘–</ci><cn type="integer" id="S2.SS0.SSS0.Px2.p1.9.m9.2.2.2.2.cmml" xref="S2.SS0.SSS0.Px2.p1.9.m9.2.2.2.2">1</cn></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p1.9.m9.2c">\bm{c}_{i,1}</annotation></semantics></math> | <math id="S2.SS0.SSS0.Px2.p1.10.m10.2" class="ltx_Math" alttext="\bm{c}_{i,2}" display="inline"><semantics id="S2.SS0.SSS0.Px2.p1.10.m10.2a"><msub id="S2.SS0.SSS0.Px2.p1.10.m10.2.3" xref="S2.SS0.SSS0.Px2.p1.10.m10.2.3.cmml"><mi id="S2.SS0.SSS0.Px2.p1.10.m10.2.3.2" xref="S2.SS0.SSS0.Px2.p1.10.m10.2.3.2.cmml">ğ’„</mi><mrow id="S2.SS0.SSS0.Px2.p1.10.m10.2.2.2.4" xref="S2.SS0.SSS0.Px2.p1.10.m10.2.2.2.3.cmml"><mi id="S2.SS0.SSS0.Px2.p1.10.m10.1.1.1.1" xref="S2.SS0.SSS0.Px2.p1.10.m10.1.1.1.1.cmml">i</mi><mo id="S2.SS0.SSS0.Px2.p1.10.m10.2.2.2.4.1" xref="S2.SS0.SSS0.Px2.p1.10.m10.2.2.2.3.cmml">,</mo><mn id="S2.SS0.SSS0.Px2.p1.10.m10.2.2.2.2" xref="S2.SS0.SSS0.Px2.p1.10.m10.2.2.2.2.cmml">2</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p1.10.m10.2b"><apply id="S2.SS0.SSS0.Px2.p1.10.m10.2.3.cmml" xref="S2.SS0.SSS0.Px2.p1.10.m10.2.3"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px2.p1.10.m10.2.3.1.cmml" xref="S2.SS0.SSS0.Px2.p1.10.m10.2.3">subscript</csymbol><ci id="S2.SS0.SSS0.Px2.p1.10.m10.2.3.2.cmml" xref="S2.SS0.SSS0.Px2.p1.10.m10.2.3.2">ğ’„</ci><list id="S2.SS0.SSS0.Px2.p1.10.m10.2.2.2.3.cmml" xref="S2.SS0.SSS0.Px2.p1.10.m10.2.2.2.4"><ci id="S2.SS0.SSS0.Px2.p1.10.m10.1.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.10.m10.1.1.1.1">ğ‘–</ci><cn type="integer" id="S2.SS0.SSS0.Px2.p1.10.m10.2.2.2.2.cmml" xref="S2.SS0.SSS0.Px2.p1.10.m10.2.2.2.2">2</cn></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p1.10.m10.2c">\bm{c}_{i,2}</annotation></semantics></math> | â€¦ | <math id="S2.SS0.SSS0.Px2.p1.11.m11.2" class="ltx_Math" alttext="\bm{c}_{i,M}" display="inline"><semantics id="S2.SS0.SSS0.Px2.p1.11.m11.2a"><msub id="S2.SS0.SSS0.Px2.p1.11.m11.2.3" xref="S2.SS0.SSS0.Px2.p1.11.m11.2.3.cmml"><mi id="S2.SS0.SSS0.Px2.p1.11.m11.2.3.2" xref="S2.SS0.SSS0.Px2.p1.11.m11.2.3.2.cmml">ğ’„</mi><mrow id="S2.SS0.SSS0.Px2.p1.11.m11.2.2.2.4" xref="S2.SS0.SSS0.Px2.p1.11.m11.2.2.2.3.cmml"><mi id="S2.SS0.SSS0.Px2.p1.11.m11.1.1.1.1" xref="S2.SS0.SSS0.Px2.p1.11.m11.1.1.1.1.cmml">i</mi><mo id="S2.SS0.SSS0.Px2.p1.11.m11.2.2.2.4.1" xref="S2.SS0.SSS0.Px2.p1.11.m11.2.2.2.3.cmml">,</mo><mi id="S2.SS0.SSS0.Px2.p1.11.m11.2.2.2.2" xref="S2.SS0.SSS0.Px2.p1.11.m11.2.2.2.2.cmml">M</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p1.11.m11.2b"><apply id="S2.SS0.SSS0.Px2.p1.11.m11.2.3.cmml" xref="S2.SS0.SSS0.Px2.p1.11.m11.2.3"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px2.p1.11.m11.2.3.1.cmml" xref="S2.SS0.SSS0.Px2.p1.11.m11.2.3">subscript</csymbol><ci id="S2.SS0.SSS0.Px2.p1.11.m11.2.3.2.cmml" xref="S2.SS0.SSS0.Px2.p1.11.m11.2.3.2">ğ’„</ci><list id="S2.SS0.SSS0.Px2.p1.11.m11.2.2.2.3.cmml" xref="S2.SS0.SSS0.Px2.p1.11.m11.2.2.2.4"><ci id="S2.SS0.SSS0.Px2.p1.11.m11.1.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.11.m11.1.1.1.1">ğ‘–</ci><ci id="S2.SS0.SSS0.Px2.p1.11.m11.2.2.2.2.cmml" xref="S2.SS0.SSS0.Px2.p1.11.m11.2.2.2.2">ğ‘€</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p1.11.m11.2c">\bm{c}_{i,M}</annotation></semantics></math>].
Finally, the question <math id="S2.SS0.SSS0.Px2.p1.12.m12.1" class="ltx_Math" alttext="\bm{q}" display="inline"><semantics id="S2.SS0.SSS0.Px2.p1.12.m12.1a"><mi id="S2.SS0.SSS0.Px2.p1.12.m12.1.1" xref="S2.SS0.SSS0.Px2.p1.12.m12.1.1.cmml">ğ’’</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p1.12.m12.1b"><ci id="S2.SS0.SSS0.Px2.p1.12.m12.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.12.m12.1.1">ğ’’</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p1.12.m12.1c">\bm{q}</annotation></semantics></math> is prepended to the linearized table: [<math id="S2.SS0.SSS0.Px2.p1.13.m13.1" class="ltx_Math" alttext="\bm{q}" display="inline"><semantics id="S2.SS0.SSS0.Px2.p1.13.m13.1a"><mi id="S2.SS0.SSS0.Px2.p1.13.m13.1.1" xref="S2.SS0.SSS0.Px2.p1.13.m13.1.1.cmml">ğ’’</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p1.13.m13.1b"><ci id="S2.SS0.SSS0.Px2.p1.13.m13.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.13.m13.1.1">ğ’’</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p1.13.m13.1c">\bm{q}</annotation></semantics></math> <math id="S2.SS0.SSS0.Px2.p1.14.m14.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S2.SS0.SSS0.Px2.p1.14.m14.1a"><mi id="S2.SS0.SSS0.Px2.p1.14.m14.1.1" xref="S2.SS0.SSS0.Px2.p1.14.m14.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p1.14.m14.1b"><ci id="S2.SS0.SSS0.Px2.p1.14.m14.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.14.m14.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p1.14.m14.1c">T</annotation></semantics></math>].</p>
</div>
</section>
<section id="S2.SS0.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Model Architecture</h5>

<div id="S2.SS0.SSS0.Px3.p1" class="ltx_para">
<p id="S2.SS0.SSS0.Px3.p1.1" class="ltx_p">We use the state-of-the-art table-based QA model TAPEX <cite class="ltx_cite ltx_citemacro_cite">Liu etÂ al. (<a href="#bib.bib16" title="" class="ltx_ref">2021</a>)</cite> as our base model, which is based on BART <cite class="ltx_cite ltx_citemacro_cite">Lewis etÂ al. (<a href="#bib.bib14" title="" class="ltx_ref">2020b</a>)</cite>. It feeds questions and tables into the encoder and generates answers from the decoder: <math id="S2.SS0.SSS0.Px3.p1.1.m1.3" class="ltx_Math" alttext="P(\bm{a}|\bm{q},T)" display="inline"><semantics id="S2.SS0.SSS0.Px3.p1.1.m1.3a"><mrow id="S2.SS0.SSS0.Px3.p1.1.m1.3.3" xref="S2.SS0.SSS0.Px3.p1.1.m1.3.3.cmml"><mi id="S2.SS0.SSS0.Px3.p1.1.m1.3.3.3" xref="S2.SS0.SSS0.Px3.p1.1.m1.3.3.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="S2.SS0.SSS0.Px3.p1.1.m1.3.3.2" xref="S2.SS0.SSS0.Px3.p1.1.m1.3.3.2.cmml">â€‹</mo><mrow id="S2.SS0.SSS0.Px3.p1.1.m1.3.3.1.1" xref="S2.SS0.SSS0.Px3.p1.1.m1.3.3.1.1.1.cmml"><mo stretchy="false" id="S2.SS0.SSS0.Px3.p1.1.m1.3.3.1.1.2" xref="S2.SS0.SSS0.Px3.p1.1.m1.3.3.1.1.1.cmml">(</mo><mrow id="S2.SS0.SSS0.Px3.p1.1.m1.3.3.1.1.1" xref="S2.SS0.SSS0.Px3.p1.1.m1.3.3.1.1.1.cmml"><mi id="S2.SS0.SSS0.Px3.p1.1.m1.3.3.1.1.1.2" xref="S2.SS0.SSS0.Px3.p1.1.m1.3.3.1.1.1.2.cmml">ğ’‚</mi><mo fence="false" id="S2.SS0.SSS0.Px3.p1.1.m1.3.3.1.1.1.1" xref="S2.SS0.SSS0.Px3.p1.1.m1.3.3.1.1.1.1.cmml">|</mo><mrow id="S2.SS0.SSS0.Px3.p1.1.m1.3.3.1.1.1.3.2" xref="S2.SS0.SSS0.Px3.p1.1.m1.3.3.1.1.1.3.1.cmml"><mi id="S2.SS0.SSS0.Px3.p1.1.m1.1.1" xref="S2.SS0.SSS0.Px3.p1.1.m1.1.1.cmml">ğ’’</mi><mo id="S2.SS0.SSS0.Px3.p1.1.m1.3.3.1.1.1.3.2.1" xref="S2.SS0.SSS0.Px3.p1.1.m1.3.3.1.1.1.3.1.cmml">,</mo><mi id="S2.SS0.SSS0.Px3.p1.1.m1.2.2" xref="S2.SS0.SSS0.Px3.p1.1.m1.2.2.cmml">T</mi></mrow></mrow><mo stretchy="false" id="S2.SS0.SSS0.Px3.p1.1.m1.3.3.1.1.3" xref="S2.SS0.SSS0.Px3.p1.1.m1.3.3.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px3.p1.1.m1.3b"><apply id="S2.SS0.SSS0.Px3.p1.1.m1.3.3.cmml" xref="S2.SS0.SSS0.Px3.p1.1.m1.3.3"><times id="S2.SS0.SSS0.Px3.p1.1.m1.3.3.2.cmml" xref="S2.SS0.SSS0.Px3.p1.1.m1.3.3.2"></times><ci id="S2.SS0.SSS0.Px3.p1.1.m1.3.3.3.cmml" xref="S2.SS0.SSS0.Px3.p1.1.m1.3.3.3">ğ‘ƒ</ci><apply id="S2.SS0.SSS0.Px3.p1.1.m1.3.3.1.1.1.cmml" xref="S2.SS0.SSS0.Px3.p1.1.m1.3.3.1.1"><csymbol cd="latexml" id="S2.SS0.SSS0.Px3.p1.1.m1.3.3.1.1.1.1.cmml" xref="S2.SS0.SSS0.Px3.p1.1.m1.3.3.1.1.1.1">conditional</csymbol><ci id="S2.SS0.SSS0.Px3.p1.1.m1.3.3.1.1.1.2.cmml" xref="S2.SS0.SSS0.Px3.p1.1.m1.3.3.1.1.1.2">ğ’‚</ci><list id="S2.SS0.SSS0.Px3.p1.1.m1.3.3.1.1.1.3.1.cmml" xref="S2.SS0.SSS0.Px3.p1.1.m1.3.3.1.1.1.3.2"><ci id="S2.SS0.SSS0.Px3.p1.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px3.p1.1.m1.1.1">ğ’’</ci><ci id="S2.SS0.SSS0.Px3.p1.1.m1.2.2.cmml" xref="S2.SS0.SSS0.Px3.p1.1.m1.2.2">ğ‘‡</ci></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px3.p1.1.m1.3c">P(\bm{a}|\bm{q},T)</annotation></semantics></math>.
Multiple answers are joined with commas into a single output sequence.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>OmniTab: Pretraining with Natural and Synthetic Data</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">As mentioned in the introduction, table-based QA requires both (1) the ability to align NL phrases with table elements that could be expressed in different wording and (2) perform reasoning such as filtering, aggregation, superlatives, comparatives, and arithmetic.
Compared to synthetic data, real NL sentences relevant to the table excel at enhancing the first capability since they are more natural and fluent, exhibiting various language variations.
Learning on real sentences can endow models to grasp the nuances in language and align with structured tables.
On the other hand, synthetic data is flexible, manipulable, and easy to obtain.
It is costless to generate synthetic data via manipulating different aspects of the generated data to incorporate various desired properties.
As a result, we can generate large amounts of complicated synthetic data covering various reasoning operations, which is lacking in the NL corpora.
This motivates us to explore both types of data.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>NL-Table Alignment Through Retrieval</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">Using the Wikipedia table corpus released by <cite class="ltx_cite ltx_citemacro_citet">Herzig etÂ al. (<a href="#bib.bib8" title="" class="ltx_ref">2020</a>)</cite>, we explore three retrieval methods to construct aligned NL-Table pairs and propose a new pretraining objective.</p>
</div>
<section id="S3.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.1 </span>Retrieval Protocol</h4>

<div id="S3.SS1.SSS1.p1" class="ltx_para">
<p id="S3.SS1.SSS1.p1.1" class="ltx_p">Since sentences relevant to a table are usually included in the same document, we restrict our retrieval models to only consider the document containing the table, with the purpose of reducing noise and increasing efficiency.</p>
</div>
<section id="S3.SS1.SSS1.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">String-based Matching</h5>

<div id="S3.SS1.SSS1.Px1.p1" class="ltx_para">
<p id="S3.SS1.SSS1.Px1.p1.2" class="ltx_p">For each sentence, we enumerate over all cells in the table and find the longest common substring (LCS) between a cell <math id="S3.SS1.SSS1.Px1.p1.1.m1.2" class="ltx_Math" alttext="\bm{c}_{i,j}" display="inline"><semantics id="S3.SS1.SSS1.Px1.p1.1.m1.2a"><msub id="S3.SS1.SSS1.Px1.p1.1.m1.2.3" xref="S3.SS1.SSS1.Px1.p1.1.m1.2.3.cmml"><mi id="S3.SS1.SSS1.Px1.p1.1.m1.2.3.2" xref="S3.SS1.SSS1.Px1.p1.1.m1.2.3.2.cmml">ğ’„</mi><mrow id="S3.SS1.SSS1.Px1.p1.1.m1.2.2.2.4" xref="S3.SS1.SSS1.Px1.p1.1.m1.2.2.2.3.cmml"><mi id="S3.SS1.SSS1.Px1.p1.1.m1.1.1.1.1" xref="S3.SS1.SSS1.Px1.p1.1.m1.1.1.1.1.cmml">i</mi><mo id="S3.SS1.SSS1.Px1.p1.1.m1.2.2.2.4.1" xref="S3.SS1.SSS1.Px1.p1.1.m1.2.2.2.3.cmml">,</mo><mi id="S3.SS1.SSS1.Px1.p1.1.m1.2.2.2.2" xref="S3.SS1.SSS1.Px1.p1.1.m1.2.2.2.2.cmml">j</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.Px1.p1.1.m1.2b"><apply id="S3.SS1.SSS1.Px1.p1.1.m1.2.3.cmml" xref="S3.SS1.SSS1.Px1.p1.1.m1.2.3"><csymbol cd="ambiguous" id="S3.SS1.SSS1.Px1.p1.1.m1.2.3.1.cmml" xref="S3.SS1.SSS1.Px1.p1.1.m1.2.3">subscript</csymbol><ci id="S3.SS1.SSS1.Px1.p1.1.m1.2.3.2.cmml" xref="S3.SS1.SSS1.Px1.p1.1.m1.2.3.2">ğ’„</ci><list id="S3.SS1.SSS1.Px1.p1.1.m1.2.2.2.3.cmml" xref="S3.SS1.SSS1.Px1.p1.1.m1.2.2.2.4"><ci id="S3.SS1.SSS1.Px1.p1.1.m1.1.1.1.1.cmml" xref="S3.SS1.SSS1.Px1.p1.1.m1.1.1.1.1">ğ‘–</ci><ci id="S3.SS1.SSS1.Px1.p1.1.m1.2.2.2.2.cmml" xref="S3.SS1.SSS1.Px1.p1.1.m1.2.2.2.2">ğ‘—</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.Px1.p1.1.m1.2c">\bm{c}_{i,j}</annotation></semantics></math> and a sentence <math id="S3.SS1.SSS1.Px1.p1.2.m2.1" class="ltx_Math" alttext="\bm{s}" display="inline"><semantics id="S3.SS1.SSS1.Px1.p1.2.m2.1a"><mi id="S3.SS1.SSS1.Px1.p1.2.m2.1.1" xref="S3.SS1.SSS1.Px1.p1.2.m2.1.1.cmml">ğ’”</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.Px1.p1.2.m2.1b"><ci id="S3.SS1.SSS1.Px1.p1.2.m2.1.1.cmml" xref="S3.SS1.SSS1.Px1.p1.2.m2.1.1">ğ’”</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.Px1.p1.2.m2.1c">\bm{s}</annotation></semantics></math>.
An LCS is considered as a mention to be masked if it (1) is not a stopword, (2) contains alphanumeric characters, (3) is a complete word, and (4) is longer than 70% of the length of the cell.
We choose the sentence with the largest number of mentions to pair with the table.</p>
</div>
</section>
<section id="S3.SS1.SSS1.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Sparse Retrieval with BM25</h5>

<div id="S3.SS1.SSS1.Px2.p1" class="ltx_para">
<p id="S3.SS1.SSS1.Px2.p1.1" class="ltx_p">Another method of string-based matching is BM25 with tables as queries and sentences as candidates.
Different from the above method matching whole cells, BM25 treats tables as a bag of tokens.
We linearize tables as queries and choose the most relevant sentence to compose the pair.
Since BM25 retrieval does not return aligned phrases and cells, we resort to the above method detect mentions.</p>
</div>
</section>
<section id="S3.SS1.SSS1.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Dense Retrieval with Token Representations</h5>

<div id="S3.SS1.SSS1.Px3.p1" class="ltx_para">
<p id="S3.SS1.SSS1.Px3.p1.1" class="ltx_p">The above two methods can only consider exact string matches, which is sub-optimal because different expressions might be used between sentences and tables such as â€œ$114,844,116â€ and â€œ$114.8 millionâ€ in <a href="#S1.F1" title="Figure 1 â€£ 1 Introduction â€£ OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Fig.Â 1</span></a>.
Tables tend to use full and formal expressions, while expressions in NL tend to be casual, often with abbreviations.
To address this issue, we propose to use dense representations to perform soft matching.
Many works use a single dense vector to represent the whole query/document for retrieval <cite class="ltx_cite ltx_citemacro_cite">Guu etÂ al. (<a href="#bib.bib6" title="" class="ltx_ref">2020</a>); Karpukhin etÂ al. (<a href="#bib.bib10" title="" class="ltx_ref">2020</a>)</cite>.
However, in our case, queries are tables usually consisting of many cells,<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>Wiki tables have 26 cells on avg with extreme cases 500+.</span></span></span> thus representing a whole table as a single vector might lead to information loss, which performs well below BM25 in our preliminary experiments.
Additionally, retrieval based on a single vector only returns sentence-table pairs without revealing phrase-cell alignment, which is required for masking purposes.
Thus, we propose to use token representation to directly match phrases and cells, similar to token-level dense retrieval <cite class="ltx_cite ltx_citemacro_cite">Khattab and Zaharia (<a href="#bib.bib11" title="" class="ltx_ref">2020</a>); Gao etÂ al. (<a href="#bib.bib5" title="" class="ltx_ref">2021</a>)</cite> in spirit.</p>
</div>
<figure id="S3.F3" class="ltx_figure"><img src="/html/2207.03637/assets/x3.png" id="S3.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="180" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Applying max-sparsify on a relevance matrix of cells and phrases on two dimensions consecutively.</figcaption>
</figure>
<div id="S3.SS1.SSS1.Px3.p2" class="ltx_para">
<p id="S3.SS1.SSS1.Px3.p2.15" class="ltx_p">Specifically, we use BART to obtain token representations for each sentence <math id="S3.SS1.SSS1.Px3.p2.1.m1.1" class="ltx_Math" alttext="\bm{s}" display="inline"><semantics id="S3.SS1.SSS1.Px3.p2.1.m1.1a"><mi id="S3.SS1.SSS1.Px3.p2.1.m1.1.1" xref="S3.SS1.SSS1.Px3.p2.1.m1.1.1.cmml">ğ’”</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.Px3.p2.1.m1.1b"><ci id="S3.SS1.SSS1.Px3.p2.1.m1.1.1.cmml" xref="S3.SS1.SSS1.Px3.p2.1.m1.1.1">ğ’”</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.Px3.p2.1.m1.1c">\bm{s}</annotation></semantics></math> and table <math id="S3.SS1.SSS1.Px3.p2.2.m2.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S3.SS1.SSS1.Px3.p2.2.m2.1a"><mi id="S3.SS1.SSS1.Px3.p2.2.m2.1.1" xref="S3.SS1.SSS1.Px3.p2.2.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.Px3.p2.2.m2.1b"><ci id="S3.SS1.SSS1.Px3.p2.2.m2.1.1.cmml" xref="S3.SS1.SSS1.Px3.p2.2.m2.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.Px3.p2.2.m2.1c">T</annotation></semantics></math> separately.
We then use a named entity recognition (NER) model to detect candidate phrases <math id="S3.SS1.SSS1.Px3.p2.3.m3.1" class="ltx_Math" alttext="\{\bm{p}_{l}\}_{l=1}^{L}" display="inline"><semantics id="S3.SS1.SSS1.Px3.p2.3.m3.1a"><msubsup id="S3.SS1.SSS1.Px3.p2.3.m3.1.1" xref="S3.SS1.SSS1.Px3.p2.3.m3.1.1.cmml"><mrow id="S3.SS1.SSS1.Px3.p2.3.m3.1.1.1.1.1" xref="S3.SS1.SSS1.Px3.p2.3.m3.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.SS1.SSS1.Px3.p2.3.m3.1.1.1.1.1.2" xref="S3.SS1.SSS1.Px3.p2.3.m3.1.1.1.1.2.cmml">{</mo><msub id="S3.SS1.SSS1.Px3.p2.3.m3.1.1.1.1.1.1" xref="S3.SS1.SSS1.Px3.p2.3.m3.1.1.1.1.1.1.cmml"><mi id="S3.SS1.SSS1.Px3.p2.3.m3.1.1.1.1.1.1.2" xref="S3.SS1.SSS1.Px3.p2.3.m3.1.1.1.1.1.1.2.cmml">ğ’‘</mi><mi id="S3.SS1.SSS1.Px3.p2.3.m3.1.1.1.1.1.1.3" xref="S3.SS1.SSS1.Px3.p2.3.m3.1.1.1.1.1.1.3.cmml">l</mi></msub><mo stretchy="false" id="S3.SS1.SSS1.Px3.p2.3.m3.1.1.1.1.1.3" xref="S3.SS1.SSS1.Px3.p2.3.m3.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S3.SS1.SSS1.Px3.p2.3.m3.1.1.1.3" xref="S3.SS1.SSS1.Px3.p2.3.m3.1.1.1.3.cmml"><mi id="S3.SS1.SSS1.Px3.p2.3.m3.1.1.1.3.2" xref="S3.SS1.SSS1.Px3.p2.3.m3.1.1.1.3.2.cmml">l</mi><mo id="S3.SS1.SSS1.Px3.p2.3.m3.1.1.1.3.1" xref="S3.SS1.SSS1.Px3.p2.3.m3.1.1.1.3.1.cmml">=</mo><mn id="S3.SS1.SSS1.Px3.p2.3.m3.1.1.1.3.3" xref="S3.SS1.SSS1.Px3.p2.3.m3.1.1.1.3.3.cmml">1</mn></mrow><mi id="S3.SS1.SSS1.Px3.p2.3.m3.1.1.3" xref="S3.SS1.SSS1.Px3.p2.3.m3.1.1.3.cmml">L</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.Px3.p2.3.m3.1b"><apply id="S3.SS1.SSS1.Px3.p2.3.m3.1.1.cmml" xref="S3.SS1.SSS1.Px3.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.Px3.p2.3.m3.1.1.2.cmml" xref="S3.SS1.SSS1.Px3.p2.3.m3.1.1">superscript</csymbol><apply id="S3.SS1.SSS1.Px3.p2.3.m3.1.1.1.cmml" xref="S3.SS1.SSS1.Px3.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.Px3.p2.3.m3.1.1.1.2.cmml" xref="S3.SS1.SSS1.Px3.p2.3.m3.1.1">subscript</csymbol><set id="S3.SS1.SSS1.Px3.p2.3.m3.1.1.1.1.2.cmml" xref="S3.SS1.SSS1.Px3.p2.3.m3.1.1.1.1.1"><apply id="S3.SS1.SSS1.Px3.p2.3.m3.1.1.1.1.1.1.cmml" xref="S3.SS1.SSS1.Px3.p2.3.m3.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.Px3.p2.3.m3.1.1.1.1.1.1.1.cmml" xref="S3.SS1.SSS1.Px3.p2.3.m3.1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.SSS1.Px3.p2.3.m3.1.1.1.1.1.1.2.cmml" xref="S3.SS1.SSS1.Px3.p2.3.m3.1.1.1.1.1.1.2">ğ’‘</ci><ci id="S3.SS1.SSS1.Px3.p2.3.m3.1.1.1.1.1.1.3.cmml" xref="S3.SS1.SSS1.Px3.p2.3.m3.1.1.1.1.1.1.3">ğ‘™</ci></apply></set><apply id="S3.SS1.SSS1.Px3.p2.3.m3.1.1.1.3.cmml" xref="S3.SS1.SSS1.Px3.p2.3.m3.1.1.1.3"><eq id="S3.SS1.SSS1.Px3.p2.3.m3.1.1.1.3.1.cmml" xref="S3.SS1.SSS1.Px3.p2.3.m3.1.1.1.3.1"></eq><ci id="S3.SS1.SSS1.Px3.p2.3.m3.1.1.1.3.2.cmml" xref="S3.SS1.SSS1.Px3.p2.3.m3.1.1.1.3.2">ğ‘™</ci><cn type="integer" id="S3.SS1.SSS1.Px3.p2.3.m3.1.1.1.3.3.cmml" xref="S3.SS1.SSS1.Px3.p2.3.m3.1.1.1.3.3">1</cn></apply></apply><ci id="S3.SS1.SSS1.Px3.p2.3.m3.1.1.3.cmml" xref="S3.SS1.SSS1.Px3.p2.3.m3.1.1.3">ğ¿</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.Px3.p2.3.m3.1c">\{\bm{p}_{l}\}_{l=1}^{L}</annotation></semantics></math> in the sentence.
Each phrase and cell are represented as the average token representation, denoted as <math id="S3.SS1.SSS1.Px3.p2.4.m4.1" class="ltx_Math" alttext="\bm{e}_{\bm{p}_{l}}" display="inline"><semantics id="S3.SS1.SSS1.Px3.p2.4.m4.1a"><msub id="S3.SS1.SSS1.Px3.p2.4.m4.1.1" xref="S3.SS1.SSS1.Px3.p2.4.m4.1.1.cmml"><mi id="S3.SS1.SSS1.Px3.p2.4.m4.1.1.2" xref="S3.SS1.SSS1.Px3.p2.4.m4.1.1.2.cmml">ğ’†</mi><msub id="S3.SS1.SSS1.Px3.p2.4.m4.1.1.3" xref="S3.SS1.SSS1.Px3.p2.4.m4.1.1.3.cmml"><mi id="S3.SS1.SSS1.Px3.p2.4.m4.1.1.3.2" xref="S3.SS1.SSS1.Px3.p2.4.m4.1.1.3.2.cmml">ğ’‘</mi><mi id="S3.SS1.SSS1.Px3.p2.4.m4.1.1.3.3" xref="S3.SS1.SSS1.Px3.p2.4.m4.1.1.3.3.cmml">l</mi></msub></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.Px3.p2.4.m4.1b"><apply id="S3.SS1.SSS1.Px3.p2.4.m4.1.1.cmml" xref="S3.SS1.SSS1.Px3.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.Px3.p2.4.m4.1.1.1.cmml" xref="S3.SS1.SSS1.Px3.p2.4.m4.1.1">subscript</csymbol><ci id="S3.SS1.SSS1.Px3.p2.4.m4.1.1.2.cmml" xref="S3.SS1.SSS1.Px3.p2.4.m4.1.1.2">ğ’†</ci><apply id="S3.SS1.SSS1.Px3.p2.4.m4.1.1.3.cmml" xref="S3.SS1.SSS1.Px3.p2.4.m4.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.SSS1.Px3.p2.4.m4.1.1.3.1.cmml" xref="S3.SS1.SSS1.Px3.p2.4.m4.1.1.3">subscript</csymbol><ci id="S3.SS1.SSS1.Px3.p2.4.m4.1.1.3.2.cmml" xref="S3.SS1.SSS1.Px3.p2.4.m4.1.1.3.2">ğ’‘</ci><ci id="S3.SS1.SSS1.Px3.p2.4.m4.1.1.3.3.cmml" xref="S3.SS1.SSS1.Px3.p2.4.m4.1.1.3.3">ğ‘™</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.Px3.p2.4.m4.1c">\bm{e}_{\bm{p}_{l}}</annotation></semantics></math> and <math id="S3.SS1.SSS1.Px3.p2.5.m5.2" class="ltx_Math" alttext="\bm{e}_{\bm{c}_{i,j}}" display="inline"><semantics id="S3.SS1.SSS1.Px3.p2.5.m5.2a"><msub id="S3.SS1.SSS1.Px3.p2.5.m5.2.3" xref="S3.SS1.SSS1.Px3.p2.5.m5.2.3.cmml"><mi id="S3.SS1.SSS1.Px3.p2.5.m5.2.3.2" xref="S3.SS1.SSS1.Px3.p2.5.m5.2.3.2.cmml">ğ’†</mi><msub id="S3.SS1.SSS1.Px3.p2.5.m5.2.2.2" xref="S3.SS1.SSS1.Px3.p2.5.m5.2.2.2.cmml"><mi id="S3.SS1.SSS1.Px3.p2.5.m5.2.2.2.4" xref="S3.SS1.SSS1.Px3.p2.5.m5.2.2.2.4.cmml">ğ’„</mi><mrow id="S3.SS1.SSS1.Px3.p2.5.m5.2.2.2.2.2.4" xref="S3.SS1.SSS1.Px3.p2.5.m5.2.2.2.2.2.3.cmml"><mi id="S3.SS1.SSS1.Px3.p2.5.m5.1.1.1.1.1.1" xref="S3.SS1.SSS1.Px3.p2.5.m5.1.1.1.1.1.1.cmml">i</mi><mo id="S3.SS1.SSS1.Px3.p2.5.m5.2.2.2.2.2.4.1" xref="S3.SS1.SSS1.Px3.p2.5.m5.2.2.2.2.2.3.cmml">,</mo><mi id="S3.SS1.SSS1.Px3.p2.5.m5.2.2.2.2.2.2" xref="S3.SS1.SSS1.Px3.p2.5.m5.2.2.2.2.2.2.cmml">j</mi></mrow></msub></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.Px3.p2.5.m5.2b"><apply id="S3.SS1.SSS1.Px3.p2.5.m5.2.3.cmml" xref="S3.SS1.SSS1.Px3.p2.5.m5.2.3"><csymbol cd="ambiguous" id="S3.SS1.SSS1.Px3.p2.5.m5.2.3.1.cmml" xref="S3.SS1.SSS1.Px3.p2.5.m5.2.3">subscript</csymbol><ci id="S3.SS1.SSS1.Px3.p2.5.m5.2.3.2.cmml" xref="S3.SS1.SSS1.Px3.p2.5.m5.2.3.2">ğ’†</ci><apply id="S3.SS1.SSS1.Px3.p2.5.m5.2.2.2.cmml" xref="S3.SS1.SSS1.Px3.p2.5.m5.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.SSS1.Px3.p2.5.m5.2.2.2.3.cmml" xref="S3.SS1.SSS1.Px3.p2.5.m5.2.2.2">subscript</csymbol><ci id="S3.SS1.SSS1.Px3.p2.5.m5.2.2.2.4.cmml" xref="S3.SS1.SSS1.Px3.p2.5.m5.2.2.2.4">ğ’„</ci><list id="S3.SS1.SSS1.Px3.p2.5.m5.2.2.2.2.2.3.cmml" xref="S3.SS1.SSS1.Px3.p2.5.m5.2.2.2.2.2.4"><ci id="S3.SS1.SSS1.Px3.p2.5.m5.1.1.1.1.1.1.cmml" xref="S3.SS1.SSS1.Px3.p2.5.m5.1.1.1.1.1.1">ğ‘–</ci><ci id="S3.SS1.SSS1.Px3.p2.5.m5.2.2.2.2.2.2.cmml" xref="S3.SS1.SSS1.Px3.p2.5.m5.2.2.2.2.2.2">ğ‘—</ci></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.Px3.p2.5.m5.2c">\bm{e}_{\bm{c}_{i,j}}</annotation></semantics></math> respectively after normalized to a unit vector.
We compute a similarity for each cell-phrase pair using dot product <math id="S3.SS1.SSS1.Px3.p2.6.m6.2" class="ltx_Math" alttext="\bm{e}_{\bm{c}_{i,j}}\cdot\bm{e}_{\bm{p}_{l}}" display="inline"><semantics id="S3.SS1.SSS1.Px3.p2.6.m6.2a"><mrow id="S3.SS1.SSS1.Px3.p2.6.m6.2.3" xref="S3.SS1.SSS1.Px3.p2.6.m6.2.3.cmml"><msub id="S3.SS1.SSS1.Px3.p2.6.m6.2.3.2" xref="S3.SS1.SSS1.Px3.p2.6.m6.2.3.2.cmml"><mi id="S3.SS1.SSS1.Px3.p2.6.m6.2.3.2.2" xref="S3.SS1.SSS1.Px3.p2.6.m6.2.3.2.2.cmml">ğ’†</mi><msub id="S3.SS1.SSS1.Px3.p2.6.m6.2.2.2" xref="S3.SS1.SSS1.Px3.p2.6.m6.2.2.2.cmml"><mi id="S3.SS1.SSS1.Px3.p2.6.m6.2.2.2.4" xref="S3.SS1.SSS1.Px3.p2.6.m6.2.2.2.4.cmml">ğ’„</mi><mrow id="S3.SS1.SSS1.Px3.p2.6.m6.2.2.2.2.2.4" xref="S3.SS1.SSS1.Px3.p2.6.m6.2.2.2.2.2.3.cmml"><mi id="S3.SS1.SSS1.Px3.p2.6.m6.1.1.1.1.1.1" xref="S3.SS1.SSS1.Px3.p2.6.m6.1.1.1.1.1.1.cmml">i</mi><mo id="S3.SS1.SSS1.Px3.p2.6.m6.2.2.2.2.2.4.1" xref="S3.SS1.SSS1.Px3.p2.6.m6.2.2.2.2.2.3.cmml">,</mo><mi id="S3.SS1.SSS1.Px3.p2.6.m6.2.2.2.2.2.2" xref="S3.SS1.SSS1.Px3.p2.6.m6.2.2.2.2.2.2.cmml">j</mi></mrow></msub></msub><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.SSS1.Px3.p2.6.m6.2.3.1" xref="S3.SS1.SSS1.Px3.p2.6.m6.2.3.1.cmml">â‹…</mo><msub id="S3.SS1.SSS1.Px3.p2.6.m6.2.3.3" xref="S3.SS1.SSS1.Px3.p2.6.m6.2.3.3.cmml"><mi id="S3.SS1.SSS1.Px3.p2.6.m6.2.3.3.2" xref="S3.SS1.SSS1.Px3.p2.6.m6.2.3.3.2.cmml">ğ’†</mi><msub id="S3.SS1.SSS1.Px3.p2.6.m6.2.3.3.3" xref="S3.SS1.SSS1.Px3.p2.6.m6.2.3.3.3.cmml"><mi id="S3.SS1.SSS1.Px3.p2.6.m6.2.3.3.3.2" xref="S3.SS1.SSS1.Px3.p2.6.m6.2.3.3.3.2.cmml">ğ’‘</mi><mi id="S3.SS1.SSS1.Px3.p2.6.m6.2.3.3.3.3" xref="S3.SS1.SSS1.Px3.p2.6.m6.2.3.3.3.3.cmml">l</mi></msub></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.Px3.p2.6.m6.2b"><apply id="S3.SS1.SSS1.Px3.p2.6.m6.2.3.cmml" xref="S3.SS1.SSS1.Px3.p2.6.m6.2.3"><ci id="S3.SS1.SSS1.Px3.p2.6.m6.2.3.1.cmml" xref="S3.SS1.SSS1.Px3.p2.6.m6.2.3.1">â‹…</ci><apply id="S3.SS1.SSS1.Px3.p2.6.m6.2.3.2.cmml" xref="S3.SS1.SSS1.Px3.p2.6.m6.2.3.2"><csymbol cd="ambiguous" id="S3.SS1.SSS1.Px3.p2.6.m6.2.3.2.1.cmml" xref="S3.SS1.SSS1.Px3.p2.6.m6.2.3.2">subscript</csymbol><ci id="S3.SS1.SSS1.Px3.p2.6.m6.2.3.2.2.cmml" xref="S3.SS1.SSS1.Px3.p2.6.m6.2.3.2.2">ğ’†</ci><apply id="S3.SS1.SSS1.Px3.p2.6.m6.2.2.2.cmml" xref="S3.SS1.SSS1.Px3.p2.6.m6.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.SSS1.Px3.p2.6.m6.2.2.2.3.cmml" xref="S3.SS1.SSS1.Px3.p2.6.m6.2.2.2">subscript</csymbol><ci id="S3.SS1.SSS1.Px3.p2.6.m6.2.2.2.4.cmml" xref="S3.SS1.SSS1.Px3.p2.6.m6.2.2.2.4">ğ’„</ci><list id="S3.SS1.SSS1.Px3.p2.6.m6.2.2.2.2.2.3.cmml" xref="S3.SS1.SSS1.Px3.p2.6.m6.2.2.2.2.2.4"><ci id="S3.SS1.SSS1.Px3.p2.6.m6.1.1.1.1.1.1.cmml" xref="S3.SS1.SSS1.Px3.p2.6.m6.1.1.1.1.1.1">ğ‘–</ci><ci id="S3.SS1.SSS1.Px3.p2.6.m6.2.2.2.2.2.2.cmml" xref="S3.SS1.SSS1.Px3.p2.6.m6.2.2.2.2.2.2">ğ‘—</ci></list></apply></apply><apply id="S3.SS1.SSS1.Px3.p2.6.m6.2.3.3.cmml" xref="S3.SS1.SSS1.Px3.p2.6.m6.2.3.3"><csymbol cd="ambiguous" id="S3.SS1.SSS1.Px3.p2.6.m6.2.3.3.1.cmml" xref="S3.SS1.SSS1.Px3.p2.6.m6.2.3.3">subscript</csymbol><ci id="S3.SS1.SSS1.Px3.p2.6.m6.2.3.3.2.cmml" xref="S3.SS1.SSS1.Px3.p2.6.m6.2.3.3.2">ğ’†</ci><apply id="S3.SS1.SSS1.Px3.p2.6.m6.2.3.3.3.cmml" xref="S3.SS1.SSS1.Px3.p2.6.m6.2.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.SSS1.Px3.p2.6.m6.2.3.3.3.1.cmml" xref="S3.SS1.SSS1.Px3.p2.6.m6.2.3.3.3">subscript</csymbol><ci id="S3.SS1.SSS1.Px3.p2.6.m6.2.3.3.3.2.cmml" xref="S3.SS1.SSS1.Px3.p2.6.m6.2.3.3.3.2">ğ’‘</ci><ci id="S3.SS1.SSS1.Px3.p2.6.m6.2.3.3.3.3.cmml" xref="S3.SS1.SSS1.Px3.p2.6.m6.2.3.3.3.3">ğ‘™</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.Px3.p2.6.m6.2c">\bm{e}_{\bm{c}_{i,j}}\cdot\bm{e}_{\bm{p}_{l}}</annotation></semantics></math>, resulting in a two-dimensional similarity matrix <math id="S3.SS1.SSS1.Px3.p2.7.m7.1" class="ltx_Math" alttext="A\in\mathbb{R}^{NM\times L}" display="inline"><semantics id="S3.SS1.SSS1.Px3.p2.7.m7.1a"><mrow id="S3.SS1.SSS1.Px3.p2.7.m7.1.1" xref="S3.SS1.SSS1.Px3.p2.7.m7.1.1.cmml"><mi id="S3.SS1.SSS1.Px3.p2.7.m7.1.1.2" xref="S3.SS1.SSS1.Px3.p2.7.m7.1.1.2.cmml">A</mi><mo id="S3.SS1.SSS1.Px3.p2.7.m7.1.1.1" xref="S3.SS1.SSS1.Px3.p2.7.m7.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS1.SSS1.Px3.p2.7.m7.1.1.3" xref="S3.SS1.SSS1.Px3.p2.7.m7.1.1.3.cmml"><mi id="S3.SS1.SSS1.Px3.p2.7.m7.1.1.3.2" xref="S3.SS1.SSS1.Px3.p2.7.m7.1.1.3.2.cmml">â„</mi><mrow id="S3.SS1.SSS1.Px3.p2.7.m7.1.1.3.3" xref="S3.SS1.SSS1.Px3.p2.7.m7.1.1.3.3.cmml"><mrow id="S3.SS1.SSS1.Px3.p2.7.m7.1.1.3.3.2" xref="S3.SS1.SSS1.Px3.p2.7.m7.1.1.3.3.2.cmml"><mi id="S3.SS1.SSS1.Px3.p2.7.m7.1.1.3.3.2.2" xref="S3.SS1.SSS1.Px3.p2.7.m7.1.1.3.3.2.2.cmml">N</mi><mo lspace="0em" rspace="0em" id="S3.SS1.SSS1.Px3.p2.7.m7.1.1.3.3.2.1" xref="S3.SS1.SSS1.Px3.p2.7.m7.1.1.3.3.2.1.cmml">â€‹</mo><mi id="S3.SS1.SSS1.Px3.p2.7.m7.1.1.3.3.2.3" xref="S3.SS1.SSS1.Px3.p2.7.m7.1.1.3.3.2.3.cmml">M</mi></mrow><mo lspace="0.222em" rspace="0.222em" id="S3.SS1.SSS1.Px3.p2.7.m7.1.1.3.3.1" xref="S3.SS1.SSS1.Px3.p2.7.m7.1.1.3.3.1.cmml">Ã—</mo><mi id="S3.SS1.SSS1.Px3.p2.7.m7.1.1.3.3.3" xref="S3.SS1.SSS1.Px3.p2.7.m7.1.1.3.3.3.cmml">L</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.Px3.p2.7.m7.1b"><apply id="S3.SS1.SSS1.Px3.p2.7.m7.1.1.cmml" xref="S3.SS1.SSS1.Px3.p2.7.m7.1.1"><in id="S3.SS1.SSS1.Px3.p2.7.m7.1.1.1.cmml" xref="S3.SS1.SSS1.Px3.p2.7.m7.1.1.1"></in><ci id="S3.SS1.SSS1.Px3.p2.7.m7.1.1.2.cmml" xref="S3.SS1.SSS1.Px3.p2.7.m7.1.1.2">ğ´</ci><apply id="S3.SS1.SSS1.Px3.p2.7.m7.1.1.3.cmml" xref="S3.SS1.SSS1.Px3.p2.7.m7.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.SSS1.Px3.p2.7.m7.1.1.3.1.cmml" xref="S3.SS1.SSS1.Px3.p2.7.m7.1.1.3">superscript</csymbol><ci id="S3.SS1.SSS1.Px3.p2.7.m7.1.1.3.2.cmml" xref="S3.SS1.SSS1.Px3.p2.7.m7.1.1.3.2">â„</ci><apply id="S3.SS1.SSS1.Px3.p2.7.m7.1.1.3.3.cmml" xref="S3.SS1.SSS1.Px3.p2.7.m7.1.1.3.3"><times id="S3.SS1.SSS1.Px3.p2.7.m7.1.1.3.3.1.cmml" xref="S3.SS1.SSS1.Px3.p2.7.m7.1.1.3.3.1"></times><apply id="S3.SS1.SSS1.Px3.p2.7.m7.1.1.3.3.2.cmml" xref="S3.SS1.SSS1.Px3.p2.7.m7.1.1.3.3.2"><times id="S3.SS1.SSS1.Px3.p2.7.m7.1.1.3.3.2.1.cmml" xref="S3.SS1.SSS1.Px3.p2.7.m7.1.1.3.3.2.1"></times><ci id="S3.SS1.SSS1.Px3.p2.7.m7.1.1.3.3.2.2.cmml" xref="S3.SS1.SSS1.Px3.p2.7.m7.1.1.3.3.2.2">ğ‘</ci><ci id="S3.SS1.SSS1.Px3.p2.7.m7.1.1.3.3.2.3.cmml" xref="S3.SS1.SSS1.Px3.p2.7.m7.1.1.3.3.2.3">ğ‘€</ci></apply><ci id="S3.SS1.SSS1.Px3.p2.7.m7.1.1.3.3.3.cmml" xref="S3.SS1.SSS1.Px3.p2.7.m7.1.1.3.3.3">ğ¿</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.Px3.p2.7.m7.1c">A\in\mathbb{R}^{NM\times L}</annotation></semantics></math>, where each row and column correspond to a cell and a phrase respectively.
We aggregate the relevance matrix <math id="S3.SS1.SSS1.Px3.p2.8.m8.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S3.SS1.SSS1.Px3.p2.8.m8.1a"><mi id="S3.SS1.SSS1.Px3.p2.8.m8.1.1" xref="S3.SS1.SSS1.Px3.p2.8.m8.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.Px3.p2.8.m8.1b"><ci id="S3.SS1.SSS1.Px3.p2.8.m8.1.1.cmml" xref="S3.SS1.SSS1.Px3.p2.8.m8.1.1">ğ´</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.Px3.p2.8.m8.1c">A</annotation></semantics></math> to derive relevance scores for ranking sentences and an assessment score for each phrase to choose salient mentions for masking.
Given the fact that soft match based on dense vectors usually yields a non-zero relevance score even for irrelevant pairs, we apply the max-sparsify operator to emphasize relevant matches and eliminate noisy irrelevant matches, similarly to the max operator in <cite class="ltx_cite ltx_citemacro_citet">Khattab and Zaharia (<a href="#bib.bib11" title="" class="ltx_ref">2020</a>); Gao etÂ al. (<a href="#bib.bib5" title="" class="ltx_ref">2021</a>)</cite>.
The <math id="S3.SS1.SSS1.Px3.p2.9.m9.3" class="ltx_Math" alttext="\text{max-sp}(A,\text{dim}=i)" display="inline"><semantics id="S3.SS1.SSS1.Px3.p2.9.m9.3a"><mrow id="S3.SS1.SSS1.Px3.p2.9.m9.3.3" xref="S3.SS1.SSS1.Px3.p2.9.m9.3.3.cmml"><mtext id="S3.SS1.SSS1.Px3.p2.9.m9.3.3.3" xref="S3.SS1.SSS1.Px3.p2.9.m9.3.3.3a.cmml">max-sp</mtext><mo lspace="0em" rspace="0em" id="S3.SS1.SSS1.Px3.p2.9.m9.3.3.2" xref="S3.SS1.SSS1.Px3.p2.9.m9.3.3.2.cmml">â€‹</mo><mrow id="S3.SS1.SSS1.Px3.p2.9.m9.3.3.1.1" xref="S3.SS1.SSS1.Px3.p2.9.m9.3.3.1.1.1.cmml"><mo stretchy="false" id="S3.SS1.SSS1.Px3.p2.9.m9.3.3.1.1.2" xref="S3.SS1.SSS1.Px3.p2.9.m9.3.3.1.1.1.cmml">(</mo><mrow id="S3.SS1.SSS1.Px3.p2.9.m9.3.3.1.1.1" xref="S3.SS1.SSS1.Px3.p2.9.m9.3.3.1.1.1.cmml"><mrow id="S3.SS1.SSS1.Px3.p2.9.m9.3.3.1.1.1.2.2" xref="S3.SS1.SSS1.Px3.p2.9.m9.3.3.1.1.1.2.1.cmml"><mi id="S3.SS1.SSS1.Px3.p2.9.m9.1.1" xref="S3.SS1.SSS1.Px3.p2.9.m9.1.1.cmml">A</mi><mo id="S3.SS1.SSS1.Px3.p2.9.m9.3.3.1.1.1.2.2.1" xref="S3.SS1.SSS1.Px3.p2.9.m9.3.3.1.1.1.2.1.cmml">,</mo><mtext id="S3.SS1.SSS1.Px3.p2.9.m9.2.2" xref="S3.SS1.SSS1.Px3.p2.9.m9.2.2a.cmml">dim</mtext></mrow><mo id="S3.SS1.SSS1.Px3.p2.9.m9.3.3.1.1.1.1" xref="S3.SS1.SSS1.Px3.p2.9.m9.3.3.1.1.1.1.cmml">=</mo><mi id="S3.SS1.SSS1.Px3.p2.9.m9.3.3.1.1.1.3" xref="S3.SS1.SSS1.Px3.p2.9.m9.3.3.1.1.1.3.cmml">i</mi></mrow><mo stretchy="false" id="S3.SS1.SSS1.Px3.p2.9.m9.3.3.1.1.3" xref="S3.SS1.SSS1.Px3.p2.9.m9.3.3.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.Px3.p2.9.m9.3b"><apply id="S3.SS1.SSS1.Px3.p2.9.m9.3.3.cmml" xref="S3.SS1.SSS1.Px3.p2.9.m9.3.3"><times id="S3.SS1.SSS1.Px3.p2.9.m9.3.3.2.cmml" xref="S3.SS1.SSS1.Px3.p2.9.m9.3.3.2"></times><ci id="S3.SS1.SSS1.Px3.p2.9.m9.3.3.3a.cmml" xref="S3.SS1.SSS1.Px3.p2.9.m9.3.3.3"><mtext id="S3.SS1.SSS1.Px3.p2.9.m9.3.3.3.cmml" xref="S3.SS1.SSS1.Px3.p2.9.m9.3.3.3">max-sp</mtext></ci><apply id="S3.SS1.SSS1.Px3.p2.9.m9.3.3.1.1.1.cmml" xref="S3.SS1.SSS1.Px3.p2.9.m9.3.3.1.1"><eq id="S3.SS1.SSS1.Px3.p2.9.m9.3.3.1.1.1.1.cmml" xref="S3.SS1.SSS1.Px3.p2.9.m9.3.3.1.1.1.1"></eq><list id="S3.SS1.SSS1.Px3.p2.9.m9.3.3.1.1.1.2.1.cmml" xref="S3.SS1.SSS1.Px3.p2.9.m9.3.3.1.1.1.2.2"><ci id="S3.SS1.SSS1.Px3.p2.9.m9.1.1.cmml" xref="S3.SS1.SSS1.Px3.p2.9.m9.1.1">ğ´</ci><ci id="S3.SS1.SSS1.Px3.p2.9.m9.2.2a.cmml" xref="S3.SS1.SSS1.Px3.p2.9.m9.2.2"><mtext id="S3.SS1.SSS1.Px3.p2.9.m9.2.2.cmml" xref="S3.SS1.SSS1.Px3.p2.9.m9.2.2">dim</mtext></ci></list><ci id="S3.SS1.SSS1.Px3.p2.9.m9.3.3.1.1.1.3.cmml" xref="S3.SS1.SSS1.Px3.p2.9.m9.3.3.1.1.1.3">ğ‘–</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.Px3.p2.9.m9.3c">\text{max-sp}(A,\text{dim}=i)</annotation></semantics></math> keeps the max entry along dimension <math id="S3.SS1.SSS1.Px3.p2.10.m10.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.SS1.SSS1.Px3.p2.10.m10.1a"><mi id="S3.SS1.SSS1.Px3.p2.10.m10.1.1" xref="S3.SS1.SSS1.Px3.p2.10.m10.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.Px3.p2.10.m10.1b"><ci id="S3.SS1.SSS1.Px3.p2.10.m10.1.1.cmml" xref="S3.SS1.SSS1.Px3.p2.10.m10.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.Px3.p2.10.m10.1c">i</annotation></semantics></math> of the matrix <math id="S3.SS1.SSS1.Px3.p2.11.m11.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S3.SS1.SSS1.Px3.p2.11.m11.1a"><mi id="S3.SS1.SSS1.Px3.p2.11.m11.1.1" xref="S3.SS1.SSS1.Px3.p2.11.m11.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.Px3.p2.11.m11.1b"><ci id="S3.SS1.SSS1.Px3.p2.11.m11.1.1.cmml" xref="S3.SS1.SSS1.Px3.p2.11.m11.1.1">ğ´</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.Px3.p2.11.m11.1c">A</annotation></semantics></math> and changes other entries to zero.
As illustrated in <a href="#S3.F3" title="Figure 3 â€£ Dense Retrieval with Token Representations â€£ 3.1.1 Retrieval Protocol â€£ 3.1 NL-Table Alignment Through Retrieval â€£ 3 OmniTab: Pretraining with Natural and Synthetic Data â€£ OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Fig.Â 3</span></a>, we first apply this operator over all phrases (<math id="S3.SS1.SSS1.Px3.p2.12.m12.1" class="ltx_Math" alttext="\text{dim}=1" display="inline"><semantics id="S3.SS1.SSS1.Px3.p2.12.m12.1a"><mrow id="S3.SS1.SSS1.Px3.p2.12.m12.1.1" xref="S3.SS1.SSS1.Px3.p2.12.m12.1.1.cmml"><mtext id="S3.SS1.SSS1.Px3.p2.12.m12.1.1.2" xref="S3.SS1.SSS1.Px3.p2.12.m12.1.1.2a.cmml">dim</mtext><mo id="S3.SS1.SSS1.Px3.p2.12.m12.1.1.1" xref="S3.SS1.SSS1.Px3.p2.12.m12.1.1.1.cmml">=</mo><mn id="S3.SS1.SSS1.Px3.p2.12.m12.1.1.3" xref="S3.SS1.SSS1.Px3.p2.12.m12.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.Px3.p2.12.m12.1b"><apply id="S3.SS1.SSS1.Px3.p2.12.m12.1.1.cmml" xref="S3.SS1.SSS1.Px3.p2.12.m12.1.1"><eq id="S3.SS1.SSS1.Px3.p2.12.m12.1.1.1.cmml" xref="S3.SS1.SSS1.Px3.p2.12.m12.1.1.1"></eq><ci id="S3.SS1.SSS1.Px3.p2.12.m12.1.1.2a.cmml" xref="S3.SS1.SSS1.Px3.p2.12.m12.1.1.2"><mtext id="S3.SS1.SSS1.Px3.p2.12.m12.1.1.2.cmml" xref="S3.SS1.SSS1.Px3.p2.12.m12.1.1.2">dim</mtext></ci><cn type="integer" id="S3.SS1.SSS1.Px3.p2.12.m12.1.1.3.cmml" xref="S3.SS1.SSS1.Px3.p2.12.m12.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.Px3.p2.12.m12.1c">\text{dim}=1</annotation></semantics></math>), assigning each cell the best-matching phrase, then apply it over all cells (<math id="S3.SS1.SSS1.Px3.p2.13.m13.1" class="ltx_Math" alttext="\text{dim}=0" display="inline"><semantics id="S3.SS1.SSS1.Px3.p2.13.m13.1a"><mrow id="S3.SS1.SSS1.Px3.p2.13.m13.1.1" xref="S3.SS1.SSS1.Px3.p2.13.m13.1.1.cmml"><mtext id="S3.SS1.SSS1.Px3.p2.13.m13.1.1.2" xref="S3.SS1.SSS1.Px3.p2.13.m13.1.1.2a.cmml">dim</mtext><mo id="S3.SS1.SSS1.Px3.p2.13.m13.1.1.1" xref="S3.SS1.SSS1.Px3.p2.13.m13.1.1.1.cmml">=</mo><mn id="S3.SS1.SSS1.Px3.p2.13.m13.1.1.3" xref="S3.SS1.SSS1.Px3.p2.13.m13.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.Px3.p2.13.m13.1b"><apply id="S3.SS1.SSS1.Px3.p2.13.m13.1.1.cmml" xref="S3.SS1.SSS1.Px3.p2.13.m13.1.1"><eq id="S3.SS1.SSS1.Px3.p2.13.m13.1.1.1.cmml" xref="S3.SS1.SSS1.Px3.p2.13.m13.1.1.1"></eq><ci id="S3.SS1.SSS1.Px3.p2.13.m13.1.1.2a.cmml" xref="S3.SS1.SSS1.Px3.p2.13.m13.1.1.2"><mtext id="S3.SS1.SSS1.Px3.p2.13.m13.1.1.2.cmml" xref="S3.SS1.SSS1.Px3.p2.13.m13.1.1.2">dim</mtext></ci><cn type="integer" id="S3.SS1.SSS1.Px3.p2.13.m13.1.1.3.cmml" xref="S3.SS1.SSS1.Px3.p2.13.m13.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.Px3.p2.13.m13.1c">\text{dim}=0</annotation></semantics></math>), assigning each remaining phrase to its best-matching cell.
We use the sum of the sparsified matrix as the relevance score to choose the best-matching sentences, rank remaining phrases in that sentence (<math id="S3.SS1.SSS1.Px3.p2.14.m14.1" class="ltx_Math" alttext="\bm{p}_{2}&gt;\bm{p}_{3}&gt;\bm{p}_{1}" display="inline"><semantics id="S3.SS1.SSS1.Px3.p2.14.m14.1a"><mrow id="S3.SS1.SSS1.Px3.p2.14.m14.1.1" xref="S3.SS1.SSS1.Px3.p2.14.m14.1.1.cmml"><msub id="S3.SS1.SSS1.Px3.p2.14.m14.1.1.2" xref="S3.SS1.SSS1.Px3.p2.14.m14.1.1.2.cmml"><mi id="S3.SS1.SSS1.Px3.p2.14.m14.1.1.2.2" xref="S3.SS1.SSS1.Px3.p2.14.m14.1.1.2.2.cmml">ğ’‘</mi><mn id="S3.SS1.SSS1.Px3.p2.14.m14.1.1.2.3" xref="S3.SS1.SSS1.Px3.p2.14.m14.1.1.2.3.cmml">2</mn></msub><mo id="S3.SS1.SSS1.Px3.p2.14.m14.1.1.3" xref="S3.SS1.SSS1.Px3.p2.14.m14.1.1.3.cmml">&gt;</mo><msub id="S3.SS1.SSS1.Px3.p2.14.m14.1.1.4" xref="S3.SS1.SSS1.Px3.p2.14.m14.1.1.4.cmml"><mi id="S3.SS1.SSS1.Px3.p2.14.m14.1.1.4.2" xref="S3.SS1.SSS1.Px3.p2.14.m14.1.1.4.2.cmml">ğ’‘</mi><mn id="S3.SS1.SSS1.Px3.p2.14.m14.1.1.4.3" xref="S3.SS1.SSS1.Px3.p2.14.m14.1.1.4.3.cmml">3</mn></msub><mo id="S3.SS1.SSS1.Px3.p2.14.m14.1.1.5" xref="S3.SS1.SSS1.Px3.p2.14.m14.1.1.5.cmml">&gt;</mo><msub id="S3.SS1.SSS1.Px3.p2.14.m14.1.1.6" xref="S3.SS1.SSS1.Px3.p2.14.m14.1.1.6.cmml"><mi id="S3.SS1.SSS1.Px3.p2.14.m14.1.1.6.2" xref="S3.SS1.SSS1.Px3.p2.14.m14.1.1.6.2.cmml">ğ’‘</mi><mn id="S3.SS1.SSS1.Px3.p2.14.m14.1.1.6.3" xref="S3.SS1.SSS1.Px3.p2.14.m14.1.1.6.3.cmml">1</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.Px3.p2.14.m14.1b"><apply id="S3.SS1.SSS1.Px3.p2.14.m14.1.1.cmml" xref="S3.SS1.SSS1.Px3.p2.14.m14.1.1"><and id="S3.SS1.SSS1.Px3.p2.14.m14.1.1a.cmml" xref="S3.SS1.SSS1.Px3.p2.14.m14.1.1"></and><apply id="S3.SS1.SSS1.Px3.p2.14.m14.1.1b.cmml" xref="S3.SS1.SSS1.Px3.p2.14.m14.1.1"><gt id="S3.SS1.SSS1.Px3.p2.14.m14.1.1.3.cmml" xref="S3.SS1.SSS1.Px3.p2.14.m14.1.1.3"></gt><apply id="S3.SS1.SSS1.Px3.p2.14.m14.1.1.2.cmml" xref="S3.SS1.SSS1.Px3.p2.14.m14.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.SSS1.Px3.p2.14.m14.1.1.2.1.cmml" xref="S3.SS1.SSS1.Px3.p2.14.m14.1.1.2">subscript</csymbol><ci id="S3.SS1.SSS1.Px3.p2.14.m14.1.1.2.2.cmml" xref="S3.SS1.SSS1.Px3.p2.14.m14.1.1.2.2">ğ’‘</ci><cn type="integer" id="S3.SS1.SSS1.Px3.p2.14.m14.1.1.2.3.cmml" xref="S3.SS1.SSS1.Px3.p2.14.m14.1.1.2.3">2</cn></apply><apply id="S3.SS1.SSS1.Px3.p2.14.m14.1.1.4.cmml" xref="S3.SS1.SSS1.Px3.p2.14.m14.1.1.4"><csymbol cd="ambiguous" id="S3.SS1.SSS1.Px3.p2.14.m14.1.1.4.1.cmml" xref="S3.SS1.SSS1.Px3.p2.14.m14.1.1.4">subscript</csymbol><ci id="S3.SS1.SSS1.Px3.p2.14.m14.1.1.4.2.cmml" xref="S3.SS1.SSS1.Px3.p2.14.m14.1.1.4.2">ğ’‘</ci><cn type="integer" id="S3.SS1.SSS1.Px3.p2.14.m14.1.1.4.3.cmml" xref="S3.SS1.SSS1.Px3.p2.14.m14.1.1.4.3">3</cn></apply></apply><apply id="S3.SS1.SSS1.Px3.p2.14.m14.1.1c.cmml" xref="S3.SS1.SSS1.Px3.p2.14.m14.1.1"><gt id="S3.SS1.SSS1.Px3.p2.14.m14.1.1.5.cmml" xref="S3.SS1.SSS1.Px3.p2.14.m14.1.1.5"></gt><share href="#S3.SS1.SSS1.Px3.p2.14.m14.1.1.4.cmml" id="S3.SS1.SSS1.Px3.p2.14.m14.1.1d.cmml" xref="S3.SS1.SSS1.Px3.p2.14.m14.1.1"></share><apply id="S3.SS1.SSS1.Px3.p2.14.m14.1.1.6.cmml" xref="S3.SS1.SSS1.Px3.p2.14.m14.1.1.6"><csymbol cd="ambiguous" id="S3.SS1.SSS1.Px3.p2.14.m14.1.1.6.1.cmml" xref="S3.SS1.SSS1.Px3.p2.14.m14.1.1.6">subscript</csymbol><ci id="S3.SS1.SSS1.Px3.p2.14.m14.1.1.6.2.cmml" xref="S3.SS1.SSS1.Px3.p2.14.m14.1.1.6.2">ğ’‘</ci><cn type="integer" id="S3.SS1.SSS1.Px3.p2.14.m14.1.1.6.3.cmml" xref="S3.SS1.SSS1.Px3.p2.14.m14.1.1.6.3">1</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.Px3.p2.14.m14.1c">\bm{p}_{2}&gt;\bm{p}_{3}&gt;\bm{p}_{1}</annotation></semantics></math> in <a href="#S3.F3" title="Figure 3 â€£ Dense Retrieval with Token Representations â€£ 3.1.1 Retrieval Protocol â€£ 3.1 NL-Table Alignment Through Retrieval â€£ 3 OmniTab: Pretraining with Natural and Synthetic Data â€£ OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Fig.Â 3</span></a>), and choose phrases with scores higher than a threshold <math id="S3.SS1.SSS1.Px3.p2.15.m15.1" class="ltx_Math" alttext="\tau" display="inline"><semantics id="S3.SS1.SSS1.Px3.p2.15.m15.1a"><mi id="S3.SS1.SSS1.Px3.p2.15.m15.1.1" xref="S3.SS1.SSS1.Px3.p2.15.m15.1.1.cmml">Ï„</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.Px3.p2.15.m15.1b"><ci id="S3.SS1.SSS1.Px3.p2.15.m15.1.1.cmml" xref="S3.SS1.SSS1.Px3.p2.15.m15.1.1">ğœ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.Px3.p2.15.m15.1c">\tau</annotation></semantics></math> as mentions to be masked.</p>
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.6" class="ltx_Math" alttext="\text{rel}(\bm{s},T)=\text{sum}(\text{max-sp}(\text{max-sp}(A,1),0))." display="block"><semantics id="S3.E1.m1.6a"><mrow id="S3.E1.m1.6.6.1" xref="S3.E1.m1.6.6.1.1.cmml"><mrow id="S3.E1.m1.6.6.1.1" xref="S3.E1.m1.6.6.1.1.cmml"><mrow id="S3.E1.m1.6.6.1.1.3" xref="S3.E1.m1.6.6.1.1.3.cmml"><mtext id="S3.E1.m1.6.6.1.1.3.2" xref="S3.E1.m1.6.6.1.1.3.2a.cmml">rel</mtext><mo lspace="0em" rspace="0em" id="S3.E1.m1.6.6.1.1.3.1" xref="S3.E1.m1.6.6.1.1.3.1.cmml">â€‹</mo><mrow id="S3.E1.m1.6.6.1.1.3.3.2" xref="S3.E1.m1.6.6.1.1.3.3.1.cmml"><mo stretchy="false" id="S3.E1.m1.6.6.1.1.3.3.2.1" xref="S3.E1.m1.6.6.1.1.3.3.1.cmml">(</mo><mi id="S3.E1.m1.1.1" xref="S3.E1.m1.1.1.cmml">ğ’”</mi><mo id="S3.E1.m1.6.6.1.1.3.3.2.2" xref="S3.E1.m1.6.6.1.1.3.3.1.cmml">,</mo><mi id="S3.E1.m1.2.2" xref="S3.E1.m1.2.2.cmml">T</mi><mo stretchy="false" id="S3.E1.m1.6.6.1.1.3.3.2.3" xref="S3.E1.m1.6.6.1.1.3.3.1.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.6.6.1.1.2" xref="S3.E1.m1.6.6.1.1.2.cmml">=</mo><mrow id="S3.E1.m1.6.6.1.1.1" xref="S3.E1.m1.6.6.1.1.1.cmml"><mtext id="S3.E1.m1.6.6.1.1.1.3" xref="S3.E1.m1.6.6.1.1.1.3a.cmml">sum</mtext><mo lspace="0em" rspace="0em" id="S3.E1.m1.6.6.1.1.1.2" xref="S3.E1.m1.6.6.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E1.m1.6.6.1.1.1.1.1" xref="S3.E1.m1.6.6.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E1.m1.6.6.1.1.1.1.1.2" xref="S3.E1.m1.6.6.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E1.m1.6.6.1.1.1.1.1.1" xref="S3.E1.m1.6.6.1.1.1.1.1.1.cmml"><mtext id="S3.E1.m1.6.6.1.1.1.1.1.1.3" xref="S3.E1.m1.6.6.1.1.1.1.1.1.3a.cmml">max-sp</mtext><mo lspace="0em" rspace="0em" id="S3.E1.m1.6.6.1.1.1.1.1.1.2" xref="S3.E1.m1.6.6.1.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E1.m1.6.6.1.1.1.1.1.1.1.1" xref="S3.E1.m1.6.6.1.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E1.m1.6.6.1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.6.6.1.1.1.1.1.1.1.2.cmml">(</mo><mrow id="S3.E1.m1.6.6.1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.6.6.1.1.1.1.1.1.1.1.1.cmml"><mtext id="S3.E1.m1.6.6.1.1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.6.6.1.1.1.1.1.1.1.1.1.2a.cmml">max-sp</mtext><mo lspace="0em" rspace="0em" id="S3.E1.m1.6.6.1.1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.6.6.1.1.1.1.1.1.1.1.1.1.cmml">â€‹</mo><mrow id="S3.E1.m1.6.6.1.1.1.1.1.1.1.1.1.3.2" xref="S3.E1.m1.6.6.1.1.1.1.1.1.1.1.1.3.1.cmml"><mo stretchy="false" id="S3.E1.m1.6.6.1.1.1.1.1.1.1.1.1.3.2.1" xref="S3.E1.m1.6.6.1.1.1.1.1.1.1.1.1.3.1.cmml">(</mo><mi id="S3.E1.m1.3.3" xref="S3.E1.m1.3.3.cmml">A</mi><mo id="S3.E1.m1.6.6.1.1.1.1.1.1.1.1.1.3.2.2" xref="S3.E1.m1.6.6.1.1.1.1.1.1.1.1.1.3.1.cmml">,</mo><mn id="S3.E1.m1.4.4" xref="S3.E1.m1.4.4.cmml">1</mn><mo stretchy="false" id="S3.E1.m1.6.6.1.1.1.1.1.1.1.1.1.3.2.3" xref="S3.E1.m1.6.6.1.1.1.1.1.1.1.1.1.3.1.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.6.6.1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.6.6.1.1.1.1.1.1.1.2.cmml">,</mo><mn id="S3.E1.m1.5.5" xref="S3.E1.m1.5.5.cmml">0</mn><mo stretchy="false" id="S3.E1.m1.6.6.1.1.1.1.1.1.1.1.4" xref="S3.E1.m1.6.6.1.1.1.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.E1.m1.6.6.1.1.1.1.1.3" xref="S3.E1.m1.6.6.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo lspace="0em" id="S3.E1.m1.6.6.1.2" xref="S3.E1.m1.6.6.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.6b"><apply id="S3.E1.m1.6.6.1.1.cmml" xref="S3.E1.m1.6.6.1"><eq id="S3.E1.m1.6.6.1.1.2.cmml" xref="S3.E1.m1.6.6.1.1.2"></eq><apply id="S3.E1.m1.6.6.1.1.3.cmml" xref="S3.E1.m1.6.6.1.1.3"><times id="S3.E1.m1.6.6.1.1.3.1.cmml" xref="S3.E1.m1.6.6.1.1.3.1"></times><ci id="S3.E1.m1.6.6.1.1.3.2a.cmml" xref="S3.E1.m1.6.6.1.1.3.2"><mtext id="S3.E1.m1.6.6.1.1.3.2.cmml" xref="S3.E1.m1.6.6.1.1.3.2">rel</mtext></ci><interval closure="open" id="S3.E1.m1.6.6.1.1.3.3.1.cmml" xref="S3.E1.m1.6.6.1.1.3.3.2"><ci id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1">ğ’”</ci><ci id="S3.E1.m1.2.2.cmml" xref="S3.E1.m1.2.2">ğ‘‡</ci></interval></apply><apply id="S3.E1.m1.6.6.1.1.1.cmml" xref="S3.E1.m1.6.6.1.1.1"><times id="S3.E1.m1.6.6.1.1.1.2.cmml" xref="S3.E1.m1.6.6.1.1.1.2"></times><ci id="S3.E1.m1.6.6.1.1.1.3a.cmml" xref="S3.E1.m1.6.6.1.1.1.3"><mtext id="S3.E1.m1.6.6.1.1.1.3.cmml" xref="S3.E1.m1.6.6.1.1.1.3">sum</mtext></ci><apply id="S3.E1.m1.6.6.1.1.1.1.1.1.cmml" xref="S3.E1.m1.6.6.1.1.1.1.1"><times id="S3.E1.m1.6.6.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.6.6.1.1.1.1.1.1.2"></times><ci id="S3.E1.m1.6.6.1.1.1.1.1.1.3a.cmml" xref="S3.E1.m1.6.6.1.1.1.1.1.1.3"><mtext id="S3.E1.m1.6.6.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.6.6.1.1.1.1.1.1.3">max-sp</mtext></ci><interval closure="open" id="S3.E1.m1.6.6.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.6.6.1.1.1.1.1.1.1.1"><apply id="S3.E1.m1.6.6.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.6.6.1.1.1.1.1.1.1.1.1"><times id="S3.E1.m1.6.6.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.6.6.1.1.1.1.1.1.1.1.1.1"></times><ci id="S3.E1.m1.6.6.1.1.1.1.1.1.1.1.1.2a.cmml" xref="S3.E1.m1.6.6.1.1.1.1.1.1.1.1.1.2"><mtext id="S3.E1.m1.6.6.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.6.6.1.1.1.1.1.1.1.1.1.2">max-sp</mtext></ci><interval closure="open" id="S3.E1.m1.6.6.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E1.m1.6.6.1.1.1.1.1.1.1.1.1.3.2"><ci id="S3.E1.m1.3.3.cmml" xref="S3.E1.m1.3.3">ğ´</ci><cn type="integer" id="S3.E1.m1.4.4.cmml" xref="S3.E1.m1.4.4">1</cn></interval></apply><cn type="integer" id="S3.E1.m1.5.5.cmml" xref="S3.E1.m1.5.5">0</cn></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.6c">\text{rel}(\bm{s},T)=\text{sum}(\text{max-sp}(\text{max-sp}(A,1),0)).</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
</section>
</section>
<section id="S3.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.2 </span>Learning Objective</h4>

<div id="S3.SS1.SSS2.p1" class="ltx_para">
<p id="S3.SS1.SSS2.p1.2" class="ltx_p">Given a retrieved sentence <math id="S3.SS1.SSS2.p1.1.m1.1" class="ltx_Math" alttext="\bm{s}" display="inline"><semantics id="S3.SS1.SSS2.p1.1.m1.1a"><mi id="S3.SS1.SSS2.p1.1.m1.1.1" xref="S3.SS1.SSS2.p1.1.m1.1.1.cmml">ğ’”</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p1.1.m1.1b"><ci id="S3.SS1.SSS2.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS2.p1.1.m1.1.1">ğ’”</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p1.1.m1.1c">\bm{s}</annotation></semantics></math> associated with the table <math id="S3.SS1.SSS2.p1.2.m2.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S3.SS1.SSS2.p1.2.m2.1a"><mi id="S3.SS1.SSS2.p1.2.m2.1.1" xref="S3.SS1.SSS2.p1.2.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p1.2.m2.1b"><ci id="S3.SS1.SSS2.p1.2.m2.1.1.cmml" xref="S3.SS1.SSS2.p1.2.m2.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p1.2.m2.1c">T</annotation></semantics></math>, we apply two masking strategies: (1) randomly mask tokens in the sentence or cells in the table (2) salient mention masking where we first identify phrases in the sentence that align with table elements, then mask aligned phrases (denoted as mentions).
Compared to random masking, salient masking specifically focuses on masking shared information, enabling the model to better learn the correspondence across formats, which we will verify in <a href="#S4.SS3" title="4.3 Ablation Study â€£ 4 Experiments â€£ OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Â§Â 4.3</span></a>.
Since we use TAPEX as the base model, which is based on BART, we follow the pretraining format of BART to generate the original unmasked sequence given the input with masked tokens (in either NL or table).
Instead of computing the negative log likelihood loss (NLL) over all tokens, we only compute at masked positions to emphasize the recovery of missing information:</p>
<table id="S3.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E2.m1.2" class="ltx_Math" alttext="\mathcal{L}_{\text{mask}}=-\log P_{\text{mask}}(\bm{s},T|\bm{s}^{*},T^{*})," display="block"><semantics id="S3.E2.m1.2a"><mrow id="S3.E2.m1.2.2.1" xref="S3.E2.m1.2.2.1.1.cmml"><mrow id="S3.E2.m1.2.2.1.1" xref="S3.E2.m1.2.2.1.1.cmml"><msub id="S3.E2.m1.2.2.1.1.3" xref="S3.E2.m1.2.2.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.2.2.1.1.3.2" xref="S3.E2.m1.2.2.1.1.3.2.cmml">â„’</mi><mtext id="S3.E2.m1.2.2.1.1.3.3" xref="S3.E2.m1.2.2.1.1.3.3a.cmml">mask</mtext></msub><mo id="S3.E2.m1.2.2.1.1.2" xref="S3.E2.m1.2.2.1.1.2.cmml">=</mo><mrow id="S3.E2.m1.2.2.1.1.1" xref="S3.E2.m1.2.2.1.1.1.cmml"><mo rspace="0.167em" id="S3.E2.m1.2.2.1.1.1a" xref="S3.E2.m1.2.2.1.1.1.cmml">âˆ’</mo><mrow id="S3.E2.m1.2.2.1.1.1.1" xref="S3.E2.m1.2.2.1.1.1.1.cmml"><mrow id="S3.E2.m1.2.2.1.1.1.1.3" xref="S3.E2.m1.2.2.1.1.1.1.3.cmml"><mi id="S3.E2.m1.2.2.1.1.1.1.3.1" xref="S3.E2.m1.2.2.1.1.1.1.3.1.cmml">log</mi><mo lspace="0.167em" id="S3.E2.m1.2.2.1.1.1.1.3a" xref="S3.E2.m1.2.2.1.1.1.1.3.cmml">â¡</mo><msub id="S3.E2.m1.2.2.1.1.1.1.3.2" xref="S3.E2.m1.2.2.1.1.1.1.3.2.cmml"><mi id="S3.E2.m1.2.2.1.1.1.1.3.2.2" xref="S3.E2.m1.2.2.1.1.1.1.3.2.2.cmml">P</mi><mtext id="S3.E2.m1.2.2.1.1.1.1.3.2.3" xref="S3.E2.m1.2.2.1.1.1.1.3.2.3a.cmml">mask</mtext></msub></mrow><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.1.1.2" xref="S3.E2.m1.2.2.1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E2.m1.2.2.1.1.1.1.1.1" xref="S3.E2.m1.2.2.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E2.m1.2.2.1.1.1.1.1.1.2" xref="S3.E2.m1.2.2.1.1.1.1.1.2.cmml">(</mo><mi id="S3.E2.m1.1.1" xref="S3.E2.m1.1.1.cmml">ğ’”</mi><mo id="S3.E2.m1.2.2.1.1.1.1.1.1.3" xref="S3.E2.m1.2.2.1.1.1.1.1.2.cmml">,</mo><mrow id="S3.E2.m1.2.2.1.1.1.1.1.1.1" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.cmml"><mi id="S3.E2.m1.2.2.1.1.1.1.1.1.1.4" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.4.cmml">T</mi><mo fence="false" id="S3.E2.m1.2.2.1.1.1.1.1.1.1.3" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.3.cmml">|</mo><mrow id="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.2" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.3.cmml"><msup id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.cmml">ğ’”</mi><mo id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.cmml">âˆ—</mo></msup><mo id="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.2.3" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.3.cmml">,</mo><msup id="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.2.2" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.2.2.cmml"><mi id="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.2.2.2" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.2.2.2.cmml">T</mi><mo id="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.2.2.3" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.2.2.3.cmml">âˆ—</mo></msup></mrow></mrow><mo stretchy="false" id="S3.E2.m1.2.2.1.1.1.1.1.1.4" xref="S3.E2.m1.2.2.1.1.1.1.1.2.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S3.E2.m1.2.2.1.2" xref="S3.E2.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.2b"><apply id="S3.E2.m1.2.2.1.1.cmml" xref="S3.E2.m1.2.2.1"><eq id="S3.E2.m1.2.2.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.2"></eq><apply id="S3.E2.m1.2.2.1.1.3.cmml" xref="S3.E2.m1.2.2.1.1.3"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.3.1.cmml" xref="S3.E2.m1.2.2.1.1.3">subscript</csymbol><ci id="S3.E2.m1.2.2.1.1.3.2.cmml" xref="S3.E2.m1.2.2.1.1.3.2">â„’</ci><ci id="S3.E2.m1.2.2.1.1.3.3a.cmml" xref="S3.E2.m1.2.2.1.1.3.3"><mtext mathsize="70%" id="S3.E2.m1.2.2.1.1.3.3.cmml" xref="S3.E2.m1.2.2.1.1.3.3">mask</mtext></ci></apply><apply id="S3.E2.m1.2.2.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1"><minus id="S3.E2.m1.2.2.1.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.1"></minus><apply id="S3.E2.m1.2.2.1.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1"><times id="S3.E2.m1.2.2.1.1.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.2"></times><apply id="S3.E2.m1.2.2.1.1.1.1.3.cmml" xref="S3.E2.m1.2.2.1.1.1.1.3"><log id="S3.E2.m1.2.2.1.1.1.1.3.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.3.1"></log><apply id="S3.E2.m1.2.2.1.1.1.1.3.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.1.1.3.2.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.3.2">subscript</csymbol><ci id="S3.E2.m1.2.2.1.1.1.1.3.2.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.3.2.2">ğ‘ƒ</ci><ci id="S3.E2.m1.2.2.1.1.1.1.3.2.3a.cmml" xref="S3.E2.m1.2.2.1.1.1.1.3.2.3"><mtext mathsize="70%" id="S3.E2.m1.2.2.1.1.1.1.3.2.3.cmml" xref="S3.E2.m1.2.2.1.1.1.1.3.2.3">mask</mtext></ci></apply></apply><interval closure="open" id="S3.E2.m1.2.2.1.1.1.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1"><ci id="S3.E2.m1.1.1.cmml" xref="S3.E2.m1.1.1">ğ’”</ci><apply id="S3.E2.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E2.m1.2.2.1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.3">conditional</csymbol><ci id="S3.E2.m1.2.2.1.1.1.1.1.1.1.4.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.4">ğ‘‡</ci><list id="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.2"><apply id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1">superscript</csymbol><ci id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.2">ğ’”</ci><times id="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.1.1.1.3"></times></apply><apply id="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.2.2.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.2.2">superscript</csymbol><ci id="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.2.2.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.2.2.2">ğ‘‡</ci><times id="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.2.2.3.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1.1.2.2.2.3"></times></apply></list></apply></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.2c">\mathcal{L}_{\text{mask}}=-\log P_{\text{mask}}(\bm{s},T|\bm{s}^{*},T^{*}),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.SSS2.p1.5" class="ltx_p">where <math id="S3.SS1.SSS2.p1.3.m1.1" class="ltx_Math" alttext="\bm{s}^{*}" display="inline"><semantics id="S3.SS1.SSS2.p1.3.m1.1a"><msup id="S3.SS1.SSS2.p1.3.m1.1.1" xref="S3.SS1.SSS2.p1.3.m1.1.1.cmml"><mi id="S3.SS1.SSS2.p1.3.m1.1.1.2" xref="S3.SS1.SSS2.p1.3.m1.1.1.2.cmml">ğ’”</mi><mo id="S3.SS1.SSS2.p1.3.m1.1.1.3" xref="S3.SS1.SSS2.p1.3.m1.1.1.3.cmml">âˆ—</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p1.3.m1.1b"><apply id="S3.SS1.SSS2.p1.3.m1.1.1.cmml" xref="S3.SS1.SSS2.p1.3.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p1.3.m1.1.1.1.cmml" xref="S3.SS1.SSS2.p1.3.m1.1.1">superscript</csymbol><ci id="S3.SS1.SSS2.p1.3.m1.1.1.2.cmml" xref="S3.SS1.SSS2.p1.3.m1.1.1.2">ğ’”</ci><times id="S3.SS1.SSS2.p1.3.m1.1.1.3.cmml" xref="S3.SS1.SSS2.p1.3.m1.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p1.3.m1.1c">\bm{s}^{*}</annotation></semantics></math>/<math id="S3.SS1.SSS2.p1.4.m2.1" class="ltx_Math" alttext="T^{*}" display="inline"><semantics id="S3.SS1.SSS2.p1.4.m2.1a"><msup id="S3.SS1.SSS2.p1.4.m2.1.1" xref="S3.SS1.SSS2.p1.4.m2.1.1.cmml"><mi id="S3.SS1.SSS2.p1.4.m2.1.1.2" xref="S3.SS1.SSS2.p1.4.m2.1.1.2.cmml">T</mi><mo id="S3.SS1.SSS2.p1.4.m2.1.1.3" xref="S3.SS1.SSS2.p1.4.m2.1.1.3.cmml">âˆ—</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p1.4.m2.1b"><apply id="S3.SS1.SSS2.p1.4.m2.1.1.cmml" xref="S3.SS1.SSS2.p1.4.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p1.4.m2.1.1.1.cmml" xref="S3.SS1.SSS2.p1.4.m2.1.1">superscript</csymbol><ci id="S3.SS1.SSS2.p1.4.m2.1.1.2.cmml" xref="S3.SS1.SSS2.p1.4.m2.1.1.2">ğ‘‡</ci><times id="S3.SS1.SSS2.p1.4.m2.1.1.3.cmml" xref="S3.SS1.SSS2.p1.4.m2.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p1.4.m2.1c">T^{*}</annotation></semantics></math> denote the masked sentence/table, and <math id="S3.SS1.SSS2.p1.5.m3.1" class="ltx_math_unparsed" alttext="P_{\text{mask}}(\cdot|\cdot)" display="inline"><semantics id="S3.SS1.SSS2.p1.5.m3.1a"><mrow id="S3.SS1.SSS2.p1.5.m3.1b"><msub id="S3.SS1.SSS2.p1.5.m3.1.1"><mi id="S3.SS1.SSS2.p1.5.m3.1.1.2">P</mi><mtext id="S3.SS1.SSS2.p1.5.m3.1.1.3">mask</mtext></msub><mrow id="S3.SS1.SSS2.p1.5.m3.1.2"><mo stretchy="false" id="S3.SS1.SSS2.p1.5.m3.1.2.1">(</mo><mo lspace="0em" rspace="0em" id="S3.SS1.SSS2.p1.5.m3.1.2.2">â‹…</mo><mo fence="false" stretchy="false" id="S3.SS1.SSS2.p1.5.m3.1.2.3">|</mo><mo lspace="0em" rspace="0em" id="S3.SS1.SSS2.p1.5.m3.1.2.4">â‹…</mo><mo stretchy="false" id="S3.SS1.SSS2.p1.5.m3.1.2.5">)</mo></mrow></mrow><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p1.5.m3.1c">P_{\text{mask}}(\cdot|\cdot)</annotation></semantics></math> only computes loss at masked positions.</p>
</div>
</section>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Synthetic Questions Converted from SQL</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.2" class="ltx_p">We use synthetic questions to simulate real table-based questions that involve various reasoning operations, such as the comparative operation in <a href="#S1.F1" title="Figure 1 â€£ 1 Introduction â€£ OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Fig.Â 1</span></a>.
While directly synthesizing complex NL questions is challenging, it is easier to generate complex structured queries such as SQL because they follow predefined syntax, and different reasoning operations can be implemented with different SQL templates.
For example, the SQL query in <a href="#S1.F1" title="Figure 1 â€£ 1 Introduction â€£ OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Fig.Â 1</span></a> is based on a template that compares entries w.r.t.Â a numerical property.
This motivates us to first generate SQL (<math id="S3.SS2.p1.1.m1.1" class="ltx_Math" alttext="\bm{o}" display="inline"><semantics id="S3.SS2.p1.1.m1.1a"><mi id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml">ğ’</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><ci id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">ğ’</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">\bm{o}</annotation></semantics></math>) then convert them to NL questions (<math id="S3.SS2.p1.2.m2.1" class="ltx_Math" alttext="\bm{q}" display="inline"><semantics id="S3.SS2.p1.2.m2.1a"><mi id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml">ğ’’</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><ci id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">ğ’’</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">\bm{q}</annotation></semantics></math>).</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">Fortunately, <cite class="ltx_cite ltx_citemacro_citet">Liu etÂ al. (<a href="#bib.bib16" title="" class="ltx_ref">2021</a>)</cite> already sampled a large corpus of SQL with associated answers based on tables from Wikipedia and used SQL plus tables as input to pretrain their model TAPEX.
They achieved state-of-the-art performance on table-based QA, making TAPEX a strong base model.
However, there is a large gap between SQL and NL questions, and training solely on SQL might hinder it from closing this gap.
Instead, we use NL questions in the pretraining directly.
Given synthesized NL questions, we pretrain with a standard generative QA loss that takes NL questions concatenated with tables as input and decode answers obtained by executing SQL queries over tables:</p>
<table id="S3.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E3.m1.3" class="ltx_Math" alttext="\mathcal{L}_{\text{QA}}=-\log P(\bm{a}|\bm{q},T)." display="block"><semantics id="S3.E3.m1.3a"><mrow id="S3.E3.m1.3.3.1" xref="S3.E3.m1.3.3.1.1.cmml"><mrow id="S3.E3.m1.3.3.1.1" xref="S3.E3.m1.3.3.1.1.cmml"><msub id="S3.E3.m1.3.3.1.1.3" xref="S3.E3.m1.3.3.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.3.3.1.1.3.2" xref="S3.E3.m1.3.3.1.1.3.2.cmml">â„’</mi><mtext id="S3.E3.m1.3.3.1.1.3.3" xref="S3.E3.m1.3.3.1.1.3.3a.cmml">QA</mtext></msub><mo id="S3.E3.m1.3.3.1.1.2" xref="S3.E3.m1.3.3.1.1.2.cmml">=</mo><mrow id="S3.E3.m1.3.3.1.1.1" xref="S3.E3.m1.3.3.1.1.1.cmml"><mo rspace="0.167em" id="S3.E3.m1.3.3.1.1.1a" xref="S3.E3.m1.3.3.1.1.1.cmml">âˆ’</mo><mrow id="S3.E3.m1.3.3.1.1.1.1" xref="S3.E3.m1.3.3.1.1.1.1.cmml"><mrow id="S3.E3.m1.3.3.1.1.1.1.3" xref="S3.E3.m1.3.3.1.1.1.1.3.cmml"><mi id="S3.E3.m1.3.3.1.1.1.1.3.1" xref="S3.E3.m1.3.3.1.1.1.1.3.1.cmml">log</mi><mo lspace="0.167em" id="S3.E3.m1.3.3.1.1.1.1.3a" xref="S3.E3.m1.3.3.1.1.1.1.3.cmml">â¡</mo><mi id="S3.E3.m1.3.3.1.1.1.1.3.2" xref="S3.E3.m1.3.3.1.1.1.1.3.2.cmml">P</mi></mrow><mo lspace="0em" rspace="0em" id="S3.E3.m1.3.3.1.1.1.1.2" xref="S3.E3.m1.3.3.1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E3.m1.3.3.1.1.1.1.1.1" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E3.m1.3.3.1.1.1.1.1.1.2" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E3.m1.3.3.1.1.1.1.1.1.1" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.cmml"><mi id="S3.E3.m1.3.3.1.1.1.1.1.1.1.2" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.2.cmml">ğ’‚</mi><mo fence="false" id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.cmml">|</mo><mrow id="S3.E3.m1.3.3.1.1.1.1.1.1.1.3.2" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.3.1.cmml"><mi id="S3.E3.m1.1.1" xref="S3.E3.m1.1.1.cmml">ğ’’</mi><mo id="S3.E3.m1.3.3.1.1.1.1.1.1.1.3.2.1" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.3.1.cmml">,</mo><mi id="S3.E3.m1.2.2" xref="S3.E3.m1.2.2.cmml">T</mi></mrow></mrow><mo stretchy="false" id="S3.E3.m1.3.3.1.1.1.1.1.1.3" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><mo lspace="0em" id="S3.E3.m1.3.3.1.2" xref="S3.E3.m1.3.3.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.3b"><apply id="S3.E3.m1.3.3.1.1.cmml" xref="S3.E3.m1.3.3.1"><eq id="S3.E3.m1.3.3.1.1.2.cmml" xref="S3.E3.m1.3.3.1.1.2"></eq><apply id="S3.E3.m1.3.3.1.1.3.cmml" xref="S3.E3.m1.3.3.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.1.1.3.1.cmml" xref="S3.E3.m1.3.3.1.1.3">subscript</csymbol><ci id="S3.E3.m1.3.3.1.1.3.2.cmml" xref="S3.E3.m1.3.3.1.1.3.2">â„’</ci><ci id="S3.E3.m1.3.3.1.1.3.3a.cmml" xref="S3.E3.m1.3.3.1.1.3.3"><mtext mathsize="70%" id="S3.E3.m1.3.3.1.1.3.3.cmml" xref="S3.E3.m1.3.3.1.1.3.3">QA</mtext></ci></apply><apply id="S3.E3.m1.3.3.1.1.1.cmml" xref="S3.E3.m1.3.3.1.1.1"><minus id="S3.E3.m1.3.3.1.1.1.2.cmml" xref="S3.E3.m1.3.3.1.1.1"></minus><apply id="S3.E3.m1.3.3.1.1.1.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1"><times id="S3.E3.m1.3.3.1.1.1.1.2.cmml" xref="S3.E3.m1.3.3.1.1.1.1.2"></times><apply id="S3.E3.m1.3.3.1.1.1.1.3.cmml" xref="S3.E3.m1.3.3.1.1.1.1.3"><log id="S3.E3.m1.3.3.1.1.1.1.3.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1.3.1"></log><ci id="S3.E3.m1.3.3.1.1.1.1.3.2.cmml" xref="S3.E3.m1.3.3.1.1.1.1.3.2">ğ‘ƒ</ci></apply><apply id="S3.E3.m1.3.3.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.1">conditional</csymbol><ci id="S3.E3.m1.3.3.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.2">ğ’‚</ci><list id="S3.E3.m1.3.3.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.3.2"><ci id="S3.E3.m1.1.1.cmml" xref="S3.E3.m1.1.1">ğ’’</ci><ci id="S3.E3.m1.2.2.cmml" xref="S3.E3.m1.2.2">ğ‘‡</ci></list></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.3c">\mathcal{L}_{\text{QA}}=-\log P(\bm{a}|\bm{q},T).</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
</div>
<figure id="S3.F4" class="ltx_figure"><img src="/html/2207.03637/assets/x4.png" id="S3.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="391" height="247" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>The procedure of learning a SQL2NL model with verification-based self-training. Annotated / generated NL questions are denoted as <span id="S3.F4.3.1" class="ltx_text" style="color:#ED872E;">orange</span> / <span id="S3.F4.4.2" class="ltx_text" style="color:#006B3D;">green</span>.</figcaption>
</figure>
<section id="S3.SS2.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Sampling SQL Based on Templates</h5>

<div id="S3.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px1.p1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citet">Liu etÂ al. (<a href="#bib.bib16" title="" class="ltx_ref">2021</a>)</cite> leverage tables from WTQ and instantiate different templates over them to sample large amounts of SQL, where answers are obtained by execution.
Templates are automatically extracted from SQUALL <cite class="ltx_cite ltx_citemacro_cite">Shi etÂ al. (<a href="#bib.bib22" title="" class="ltx_ref">2020</a>)</cite>, which includes SQL corresponding to NL questions in WTQ.</p>
</div>
</section>
<section id="S3.SS2.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Training SQL2NL Models</h5>

<div id="S3.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px2.p1.1" class="ltx_p">We use BART as our base model and finetune it with limited SQL-NL pairs to strictly conform to the few-shot setting.
We use SQUALL to simulate few-shot scenarios, by assuming that only a limited number of SQL queries have annotated NL questions, which we elaborate in <a href="#S4.SS1" title="4.1 Experimental Settings â€£ 4 Experiments â€£ OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Â§Â 4.1</span></a>.
The model takes SQL as input and generates NL questions autoregressively.<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>We tried adding the corresponding table as an additional input but found no gain despite increased computational cost.</span></span></span></p>
</div>
</section>
<section id="S3.SS2.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Self-training with Verification-based Selection</h5>

<div id="S3.SS2.SSS0.Px3.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px3.p1.1" class="ltx_p">Even with a strong model like BART, the accuracy of SQL2NL is not perfect, especially in the face of limited data.
To further improve performance, we devise a verification-based self-training approach that selects high-quality NL questions generated from unlabeled SQL by assessing how likely they elicit correct answers from the table-QA model.</p>
</div>
<div id="S3.SS2.SSS0.Px3.p2" class="ltx_para">
<p id="S3.SS2.SSS0.Px3.p2.4" class="ltx_p">As illustrated in <a href="#S3.F4" title="Figure 4 â€£ 3.2 Synthetic Questions Converted from SQL â€£ 3 OmniTab: Pretraining with Natural and Synthetic Data â€£ OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Fig.Â 4</span></a>, we first finetune BART model on supervised SQL-NL pairs to obtain the initial SQL2NL model (â‘ ), which is used to generate NL questions for unlabeled SQL (â‘¡) in the second step.
We attempted two generation methods including beam search and top-k sampling <cite class="ltx_cite ltx_citemacro_cite">Fan etÂ al. (<a href="#bib.bib4" title="" class="ltx_ref">2018</a>)</cite> and found that beam search leads to more diverse results. Thus we use a beam size of 50 to generate candidate NL questions <math id="S3.SS2.SSS0.Px3.p2.1.m1.1" class="ltx_Math" alttext="\hat{\bm{q}}" display="inline"><semantics id="S3.SS2.SSS0.Px3.p2.1.m1.1a"><mover accent="true" id="S3.SS2.SSS0.Px3.p2.1.m1.1.1" xref="S3.SS2.SSS0.Px3.p2.1.m1.1.1.cmml"><mi id="S3.SS2.SSS0.Px3.p2.1.m1.1.1.2" xref="S3.SS2.SSS0.Px3.p2.1.m1.1.1.2.cmml">ğ’’</mi><mo id="S3.SS2.SSS0.Px3.p2.1.m1.1.1.1" xref="S3.SS2.SSS0.Px3.p2.1.m1.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px3.p2.1.m1.1b"><apply id="S3.SS2.SSS0.Px3.p2.1.m1.1.1.cmml" xref="S3.SS2.SSS0.Px3.p2.1.m1.1.1"><ci id="S3.SS2.SSS0.Px3.p2.1.m1.1.1.1.cmml" xref="S3.SS2.SSS0.Px3.p2.1.m1.1.1.1">^</ci><ci id="S3.SS2.SSS0.Px3.p2.1.m1.1.1.2.cmml" xref="S3.SS2.SSS0.Px3.p2.1.m1.1.1.2">ğ’’</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px3.p2.1.m1.1c">\hat{\bm{q}}</annotation></semantics></math>.
Third, we choose high-quality candidates for self-training based on various criteria.
The most straightforward criterion is to choose questions with the highest generation probabilities for self-training <math id="S3.SS2.SSS0.Px3.p2.2.m2.2" class="ltx_Math" alttext="\text{score}_{\text{gen.}}(\hat{\bm{q}})=P^{\text{SQL2NL}}(\hat{\bm{q}}|\bm{o})" display="inline"><semantics id="S3.SS2.SSS0.Px3.p2.2.m2.2a"><mrow id="S3.SS2.SSS0.Px3.p2.2.m2.2.2" xref="S3.SS2.SSS0.Px3.p2.2.m2.2.2.cmml"><mrow id="S3.SS2.SSS0.Px3.p2.2.m2.2.2.3" xref="S3.SS2.SSS0.Px3.p2.2.m2.2.2.3.cmml"><msub id="S3.SS2.SSS0.Px3.p2.2.m2.2.2.3.2" xref="S3.SS2.SSS0.Px3.p2.2.m2.2.2.3.2.cmml"><mtext id="S3.SS2.SSS0.Px3.p2.2.m2.2.2.3.2.2" xref="S3.SS2.SSS0.Px3.p2.2.m2.2.2.3.2.2a.cmml">score</mtext><mtext id="S3.SS2.SSS0.Px3.p2.2.m2.2.2.3.2.3" xref="S3.SS2.SSS0.Px3.p2.2.m2.2.2.3.2.3a.cmml">gen.</mtext></msub><mo lspace="0em" rspace="0em" id="S3.SS2.SSS0.Px3.p2.2.m2.2.2.3.1" xref="S3.SS2.SSS0.Px3.p2.2.m2.2.2.3.1.cmml">â€‹</mo><mrow id="S3.SS2.SSS0.Px3.p2.2.m2.2.2.3.3.2" xref="S3.SS2.SSS0.Px3.p2.2.m2.1.1.cmml"><mo stretchy="false" id="S3.SS2.SSS0.Px3.p2.2.m2.2.2.3.3.2.1" xref="S3.SS2.SSS0.Px3.p2.2.m2.1.1.cmml">(</mo><mover accent="true" id="S3.SS2.SSS0.Px3.p2.2.m2.1.1" xref="S3.SS2.SSS0.Px3.p2.2.m2.1.1.cmml"><mi id="S3.SS2.SSS0.Px3.p2.2.m2.1.1.2" xref="S3.SS2.SSS0.Px3.p2.2.m2.1.1.2.cmml">ğ’’</mi><mo id="S3.SS2.SSS0.Px3.p2.2.m2.1.1.1" xref="S3.SS2.SSS0.Px3.p2.2.m2.1.1.1.cmml">^</mo></mover><mo stretchy="false" id="S3.SS2.SSS0.Px3.p2.2.m2.2.2.3.3.2.2" xref="S3.SS2.SSS0.Px3.p2.2.m2.1.1.cmml">)</mo></mrow></mrow><mo id="S3.SS2.SSS0.Px3.p2.2.m2.2.2.2" xref="S3.SS2.SSS0.Px3.p2.2.m2.2.2.2.cmml">=</mo><mrow id="S3.SS2.SSS0.Px3.p2.2.m2.2.2.1" xref="S3.SS2.SSS0.Px3.p2.2.m2.2.2.1.cmml"><msup id="S3.SS2.SSS0.Px3.p2.2.m2.2.2.1.3" xref="S3.SS2.SSS0.Px3.p2.2.m2.2.2.1.3.cmml"><mi id="S3.SS2.SSS0.Px3.p2.2.m2.2.2.1.3.2" xref="S3.SS2.SSS0.Px3.p2.2.m2.2.2.1.3.2.cmml">P</mi><mtext id="S3.SS2.SSS0.Px3.p2.2.m2.2.2.1.3.3" xref="S3.SS2.SSS0.Px3.p2.2.m2.2.2.1.3.3a.cmml">SQL2NL</mtext></msup><mo lspace="0em" rspace="0em" id="S3.SS2.SSS0.Px3.p2.2.m2.2.2.1.2" xref="S3.SS2.SSS0.Px3.p2.2.m2.2.2.1.2.cmml">â€‹</mo><mrow id="S3.SS2.SSS0.Px3.p2.2.m2.2.2.1.1.1" xref="S3.SS2.SSS0.Px3.p2.2.m2.2.2.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS2.SSS0.Px3.p2.2.m2.2.2.1.1.1.2" xref="S3.SS2.SSS0.Px3.p2.2.m2.2.2.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.SSS0.Px3.p2.2.m2.2.2.1.1.1.1" xref="S3.SS2.SSS0.Px3.p2.2.m2.2.2.1.1.1.1.cmml"><mover accent="true" id="S3.SS2.SSS0.Px3.p2.2.m2.2.2.1.1.1.1.2" xref="S3.SS2.SSS0.Px3.p2.2.m2.2.2.1.1.1.1.2.cmml"><mi id="S3.SS2.SSS0.Px3.p2.2.m2.2.2.1.1.1.1.2.2" xref="S3.SS2.SSS0.Px3.p2.2.m2.2.2.1.1.1.1.2.2.cmml">ğ’’</mi><mo id="S3.SS2.SSS0.Px3.p2.2.m2.2.2.1.1.1.1.2.1" xref="S3.SS2.SSS0.Px3.p2.2.m2.2.2.1.1.1.1.2.1.cmml">^</mo></mover><mo fence="false" id="S3.SS2.SSS0.Px3.p2.2.m2.2.2.1.1.1.1.1" xref="S3.SS2.SSS0.Px3.p2.2.m2.2.2.1.1.1.1.1.cmml">|</mo><mi id="S3.SS2.SSS0.Px3.p2.2.m2.2.2.1.1.1.1.3" xref="S3.SS2.SSS0.Px3.p2.2.m2.2.2.1.1.1.1.3.cmml">ğ’</mi></mrow><mo stretchy="false" id="S3.SS2.SSS0.Px3.p2.2.m2.2.2.1.1.1.3" xref="S3.SS2.SSS0.Px3.p2.2.m2.2.2.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px3.p2.2.m2.2b"><apply id="S3.SS2.SSS0.Px3.p2.2.m2.2.2.cmml" xref="S3.SS2.SSS0.Px3.p2.2.m2.2.2"><eq id="S3.SS2.SSS0.Px3.p2.2.m2.2.2.2.cmml" xref="S3.SS2.SSS0.Px3.p2.2.m2.2.2.2"></eq><apply id="S3.SS2.SSS0.Px3.p2.2.m2.2.2.3.cmml" xref="S3.SS2.SSS0.Px3.p2.2.m2.2.2.3"><times id="S3.SS2.SSS0.Px3.p2.2.m2.2.2.3.1.cmml" xref="S3.SS2.SSS0.Px3.p2.2.m2.2.2.3.1"></times><apply id="S3.SS2.SSS0.Px3.p2.2.m2.2.2.3.2.cmml" xref="S3.SS2.SSS0.Px3.p2.2.m2.2.2.3.2"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px3.p2.2.m2.2.2.3.2.1.cmml" xref="S3.SS2.SSS0.Px3.p2.2.m2.2.2.3.2">subscript</csymbol><ci id="S3.SS2.SSS0.Px3.p2.2.m2.2.2.3.2.2a.cmml" xref="S3.SS2.SSS0.Px3.p2.2.m2.2.2.3.2.2"><mtext id="S3.SS2.SSS0.Px3.p2.2.m2.2.2.3.2.2.cmml" xref="S3.SS2.SSS0.Px3.p2.2.m2.2.2.3.2.2">score</mtext></ci><ci id="S3.SS2.SSS0.Px3.p2.2.m2.2.2.3.2.3a.cmml" xref="S3.SS2.SSS0.Px3.p2.2.m2.2.2.3.2.3"><mtext mathsize="70%" id="S3.SS2.SSS0.Px3.p2.2.m2.2.2.3.2.3.cmml" xref="S3.SS2.SSS0.Px3.p2.2.m2.2.2.3.2.3">gen.</mtext></ci></apply><apply id="S3.SS2.SSS0.Px3.p2.2.m2.1.1.cmml" xref="S3.SS2.SSS0.Px3.p2.2.m2.2.2.3.3.2"><ci id="S3.SS2.SSS0.Px3.p2.2.m2.1.1.1.cmml" xref="S3.SS2.SSS0.Px3.p2.2.m2.1.1.1">^</ci><ci id="S3.SS2.SSS0.Px3.p2.2.m2.1.1.2.cmml" xref="S3.SS2.SSS0.Px3.p2.2.m2.1.1.2">ğ’’</ci></apply></apply><apply id="S3.SS2.SSS0.Px3.p2.2.m2.2.2.1.cmml" xref="S3.SS2.SSS0.Px3.p2.2.m2.2.2.1"><times id="S3.SS2.SSS0.Px3.p2.2.m2.2.2.1.2.cmml" xref="S3.SS2.SSS0.Px3.p2.2.m2.2.2.1.2"></times><apply id="S3.SS2.SSS0.Px3.p2.2.m2.2.2.1.3.cmml" xref="S3.SS2.SSS0.Px3.p2.2.m2.2.2.1.3"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px3.p2.2.m2.2.2.1.3.1.cmml" xref="S3.SS2.SSS0.Px3.p2.2.m2.2.2.1.3">superscript</csymbol><ci id="S3.SS2.SSS0.Px3.p2.2.m2.2.2.1.3.2.cmml" xref="S3.SS2.SSS0.Px3.p2.2.m2.2.2.1.3.2">ğ‘ƒ</ci><ci id="S3.SS2.SSS0.Px3.p2.2.m2.2.2.1.3.3a.cmml" xref="S3.SS2.SSS0.Px3.p2.2.m2.2.2.1.3.3"><mtext mathsize="70%" id="S3.SS2.SSS0.Px3.p2.2.m2.2.2.1.3.3.cmml" xref="S3.SS2.SSS0.Px3.p2.2.m2.2.2.1.3.3">SQL2NL</mtext></ci></apply><apply id="S3.SS2.SSS0.Px3.p2.2.m2.2.2.1.1.1.1.cmml" xref="S3.SS2.SSS0.Px3.p2.2.m2.2.2.1.1.1"><csymbol cd="latexml" id="S3.SS2.SSS0.Px3.p2.2.m2.2.2.1.1.1.1.1.cmml" xref="S3.SS2.SSS0.Px3.p2.2.m2.2.2.1.1.1.1.1">conditional</csymbol><apply id="S3.SS2.SSS0.Px3.p2.2.m2.2.2.1.1.1.1.2.cmml" xref="S3.SS2.SSS0.Px3.p2.2.m2.2.2.1.1.1.1.2"><ci id="S3.SS2.SSS0.Px3.p2.2.m2.2.2.1.1.1.1.2.1.cmml" xref="S3.SS2.SSS0.Px3.p2.2.m2.2.2.1.1.1.1.2.1">^</ci><ci id="S3.SS2.SSS0.Px3.p2.2.m2.2.2.1.1.1.1.2.2.cmml" xref="S3.SS2.SSS0.Px3.p2.2.m2.2.2.1.1.1.1.2.2">ğ’’</ci></apply><ci id="S3.SS2.SSS0.Px3.p2.2.m2.2.2.1.1.1.1.3.cmml" xref="S3.SS2.SSS0.Px3.p2.2.m2.2.2.1.1.1.1.3">ğ’</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px3.p2.2.m2.2c">\text{score}_{\text{gen.}}(\hat{\bm{q}})=P^{\text{SQL2NL}}(\hat{\bm{q}}|\bm{o})</annotation></semantics></math>, which does not lead to improvement as we will show in the ablations (<a href="#S4.SS3" title="4.3 Ablation Study â€£ 4 Experiments â€£ OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Â§Â 4.3</span></a>).
Motivated by the fact that OmniTab has a strong capacity to answer table-related questions after large-scale pretraining and finetuning, we rank generated sentences by verifying how likely they elicit the correct answer using OmniTab <math id="S3.SS2.SSS0.Px3.p2.3.m3.4" class="ltx_Math" alttext="\text{score}_{\text{ver.}}(\hat{\bm{q}})=P(\bm{a}|\hat{\bm{q}},T)" display="inline"><semantics id="S3.SS2.SSS0.Px3.p2.3.m3.4a"><mrow id="S3.SS2.SSS0.Px3.p2.3.m3.4.4" xref="S3.SS2.SSS0.Px3.p2.3.m3.4.4.cmml"><mrow id="S3.SS2.SSS0.Px3.p2.3.m3.4.4.3" xref="S3.SS2.SSS0.Px3.p2.3.m3.4.4.3.cmml"><msub id="S3.SS2.SSS0.Px3.p2.3.m3.4.4.3.2" xref="S3.SS2.SSS0.Px3.p2.3.m3.4.4.3.2.cmml"><mtext id="S3.SS2.SSS0.Px3.p2.3.m3.4.4.3.2.2" xref="S3.SS2.SSS0.Px3.p2.3.m3.4.4.3.2.2a.cmml">score</mtext><mtext id="S3.SS2.SSS0.Px3.p2.3.m3.4.4.3.2.3" xref="S3.SS2.SSS0.Px3.p2.3.m3.4.4.3.2.3a.cmml">ver.</mtext></msub><mo lspace="0em" rspace="0em" id="S3.SS2.SSS0.Px3.p2.3.m3.4.4.3.1" xref="S3.SS2.SSS0.Px3.p2.3.m3.4.4.3.1.cmml">â€‹</mo><mrow id="S3.SS2.SSS0.Px3.p2.3.m3.4.4.3.3.2" xref="S3.SS2.SSS0.Px3.p2.3.m3.1.1.cmml"><mo stretchy="false" id="S3.SS2.SSS0.Px3.p2.3.m3.4.4.3.3.2.1" xref="S3.SS2.SSS0.Px3.p2.3.m3.1.1.cmml">(</mo><mover accent="true" id="S3.SS2.SSS0.Px3.p2.3.m3.1.1" xref="S3.SS2.SSS0.Px3.p2.3.m3.1.1.cmml"><mi id="S3.SS2.SSS0.Px3.p2.3.m3.1.1.2" xref="S3.SS2.SSS0.Px3.p2.3.m3.1.1.2.cmml">ğ’’</mi><mo id="S3.SS2.SSS0.Px3.p2.3.m3.1.1.1" xref="S3.SS2.SSS0.Px3.p2.3.m3.1.1.1.cmml">^</mo></mover><mo stretchy="false" id="S3.SS2.SSS0.Px3.p2.3.m3.4.4.3.3.2.2" xref="S3.SS2.SSS0.Px3.p2.3.m3.1.1.cmml">)</mo></mrow></mrow><mo id="S3.SS2.SSS0.Px3.p2.3.m3.4.4.2" xref="S3.SS2.SSS0.Px3.p2.3.m3.4.4.2.cmml">=</mo><mrow id="S3.SS2.SSS0.Px3.p2.3.m3.4.4.1" xref="S3.SS2.SSS0.Px3.p2.3.m3.4.4.1.cmml"><mi id="S3.SS2.SSS0.Px3.p2.3.m3.4.4.1.3" xref="S3.SS2.SSS0.Px3.p2.3.m3.4.4.1.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS0.Px3.p2.3.m3.4.4.1.2" xref="S3.SS2.SSS0.Px3.p2.3.m3.4.4.1.2.cmml">â€‹</mo><mrow id="S3.SS2.SSS0.Px3.p2.3.m3.4.4.1.1.1" xref="S3.SS2.SSS0.Px3.p2.3.m3.4.4.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS2.SSS0.Px3.p2.3.m3.4.4.1.1.1.2" xref="S3.SS2.SSS0.Px3.p2.3.m3.4.4.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.SSS0.Px3.p2.3.m3.4.4.1.1.1.1" xref="S3.SS2.SSS0.Px3.p2.3.m3.4.4.1.1.1.1.cmml"><mi id="S3.SS2.SSS0.Px3.p2.3.m3.4.4.1.1.1.1.2" xref="S3.SS2.SSS0.Px3.p2.3.m3.4.4.1.1.1.1.2.cmml">ğ’‚</mi><mo fence="false" id="S3.SS2.SSS0.Px3.p2.3.m3.4.4.1.1.1.1.1" xref="S3.SS2.SSS0.Px3.p2.3.m3.4.4.1.1.1.1.1.cmml">|</mo><mrow id="S3.SS2.SSS0.Px3.p2.3.m3.4.4.1.1.1.1.3.2" xref="S3.SS2.SSS0.Px3.p2.3.m3.4.4.1.1.1.1.3.1.cmml"><mover accent="true" id="S3.SS2.SSS0.Px3.p2.3.m3.2.2" xref="S3.SS2.SSS0.Px3.p2.3.m3.2.2.cmml"><mi id="S3.SS2.SSS0.Px3.p2.3.m3.2.2.2" xref="S3.SS2.SSS0.Px3.p2.3.m3.2.2.2.cmml">ğ’’</mi><mo id="S3.SS2.SSS0.Px3.p2.3.m3.2.2.1" xref="S3.SS2.SSS0.Px3.p2.3.m3.2.2.1.cmml">^</mo></mover><mo id="S3.SS2.SSS0.Px3.p2.3.m3.4.4.1.1.1.1.3.2.1" xref="S3.SS2.SSS0.Px3.p2.3.m3.4.4.1.1.1.1.3.1.cmml">,</mo><mi id="S3.SS2.SSS0.Px3.p2.3.m3.3.3" xref="S3.SS2.SSS0.Px3.p2.3.m3.3.3.cmml">T</mi></mrow></mrow><mo stretchy="false" id="S3.SS2.SSS0.Px3.p2.3.m3.4.4.1.1.1.3" xref="S3.SS2.SSS0.Px3.p2.3.m3.4.4.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px3.p2.3.m3.4b"><apply id="S3.SS2.SSS0.Px3.p2.3.m3.4.4.cmml" xref="S3.SS2.SSS0.Px3.p2.3.m3.4.4"><eq id="S3.SS2.SSS0.Px3.p2.3.m3.4.4.2.cmml" xref="S3.SS2.SSS0.Px3.p2.3.m3.4.4.2"></eq><apply id="S3.SS2.SSS0.Px3.p2.3.m3.4.4.3.cmml" xref="S3.SS2.SSS0.Px3.p2.3.m3.4.4.3"><times id="S3.SS2.SSS0.Px3.p2.3.m3.4.4.3.1.cmml" xref="S3.SS2.SSS0.Px3.p2.3.m3.4.4.3.1"></times><apply id="S3.SS2.SSS0.Px3.p2.3.m3.4.4.3.2.cmml" xref="S3.SS2.SSS0.Px3.p2.3.m3.4.4.3.2"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px3.p2.3.m3.4.4.3.2.1.cmml" xref="S3.SS2.SSS0.Px3.p2.3.m3.4.4.3.2">subscript</csymbol><ci id="S3.SS2.SSS0.Px3.p2.3.m3.4.4.3.2.2a.cmml" xref="S3.SS2.SSS0.Px3.p2.3.m3.4.4.3.2.2"><mtext id="S3.SS2.SSS0.Px3.p2.3.m3.4.4.3.2.2.cmml" xref="S3.SS2.SSS0.Px3.p2.3.m3.4.4.3.2.2">score</mtext></ci><ci id="S3.SS2.SSS0.Px3.p2.3.m3.4.4.3.2.3a.cmml" xref="S3.SS2.SSS0.Px3.p2.3.m3.4.4.3.2.3"><mtext mathsize="70%" id="S3.SS2.SSS0.Px3.p2.3.m3.4.4.3.2.3.cmml" xref="S3.SS2.SSS0.Px3.p2.3.m3.4.4.3.2.3">ver.</mtext></ci></apply><apply id="S3.SS2.SSS0.Px3.p2.3.m3.1.1.cmml" xref="S3.SS2.SSS0.Px3.p2.3.m3.4.4.3.3.2"><ci id="S3.SS2.SSS0.Px3.p2.3.m3.1.1.1.cmml" xref="S3.SS2.SSS0.Px3.p2.3.m3.1.1.1">^</ci><ci id="S3.SS2.SSS0.Px3.p2.3.m3.1.1.2.cmml" xref="S3.SS2.SSS0.Px3.p2.3.m3.1.1.2">ğ’’</ci></apply></apply><apply id="S3.SS2.SSS0.Px3.p2.3.m3.4.4.1.cmml" xref="S3.SS2.SSS0.Px3.p2.3.m3.4.4.1"><times id="S3.SS2.SSS0.Px3.p2.3.m3.4.4.1.2.cmml" xref="S3.SS2.SSS0.Px3.p2.3.m3.4.4.1.2"></times><ci id="S3.SS2.SSS0.Px3.p2.3.m3.4.4.1.3.cmml" xref="S3.SS2.SSS0.Px3.p2.3.m3.4.4.1.3">ğ‘ƒ</ci><apply id="S3.SS2.SSS0.Px3.p2.3.m3.4.4.1.1.1.1.cmml" xref="S3.SS2.SSS0.Px3.p2.3.m3.4.4.1.1.1"><csymbol cd="latexml" id="S3.SS2.SSS0.Px3.p2.3.m3.4.4.1.1.1.1.1.cmml" xref="S3.SS2.SSS0.Px3.p2.3.m3.4.4.1.1.1.1.1">conditional</csymbol><ci id="S3.SS2.SSS0.Px3.p2.3.m3.4.4.1.1.1.1.2.cmml" xref="S3.SS2.SSS0.Px3.p2.3.m3.4.4.1.1.1.1.2">ğ’‚</ci><list id="S3.SS2.SSS0.Px3.p2.3.m3.4.4.1.1.1.1.3.1.cmml" xref="S3.SS2.SSS0.Px3.p2.3.m3.4.4.1.1.1.1.3.2"><apply id="S3.SS2.SSS0.Px3.p2.3.m3.2.2.cmml" xref="S3.SS2.SSS0.Px3.p2.3.m3.2.2"><ci id="S3.SS2.SSS0.Px3.p2.3.m3.2.2.1.cmml" xref="S3.SS2.SSS0.Px3.p2.3.m3.2.2.1">^</ci><ci id="S3.SS2.SSS0.Px3.p2.3.m3.2.2.2.cmml" xref="S3.SS2.SSS0.Px3.p2.3.m3.2.2.2">ğ’’</ci></apply><ci id="S3.SS2.SSS0.Px3.p2.3.m3.3.3.cmml" xref="S3.SS2.SSS0.Px3.p2.3.m3.3.3">ğ‘‡</ci></list></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px3.p2.3.m3.4c">\text{score}_{\text{ver.}}(\hat{\bm{q}})=P(\bm{a}|\hat{\bm{q}},T)</annotation></semantics></math>, which provides a simple and effective way to leverage the QA capacity of OmniTab to indirectly provide feedback to the SQL2NL model (â‘¢).
Given the verification scores, we first pair each unlabeled SQL with the sentence with the highest score among 50 candidates, then keep the top-<math id="S3.SS2.SSS0.Px3.p2.4.m4.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.SS2.SSS0.Px3.p2.4.m4.1a"><mi id="S3.SS2.SSS0.Px3.p2.4.m4.1.1" xref="S3.SS2.SSS0.Px3.p2.4.m4.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px3.p2.4.m4.1b"><ci id="S3.SS2.SSS0.Px3.p2.4.m4.1.1.cmml" xref="S3.SS2.SSS0.Px3.p2.4.m4.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px3.p2.4.m4.1c">K</annotation></semantics></math> SQL-NL ranked based on the score as our self-training data.
At the last step, the small supervised data is combined with the enlarged self-training data to train the final SQL2NL model (â‘£).</p>
</div>
</section>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Combining Natural and Synthetic Data</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.2" class="ltx_p">We perform multitasking using the two previously defined objectives (<a href="#S3.E2" title="2 â€£ 3.1.2 Learning Objective â€£ 3.1 NL-Table Alignment Through Retrieval â€£ 3 OmniTab: Pretraining with Natural and Synthetic Data â€£ OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Eq.Â 2</span></a>, <a href="#S3.E3" title="3 â€£ 3.2 Synthetic Questions Converted from SQL â€£ 3 OmniTab: Pretraining with Natural and Synthetic Data â€£ OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Eq.Â 3</span></a>) to combine natural and synthetic data.
In addition, since we use TAPEX as initialization and their SQL-based pretraining has demonstrated effective in endowing models with reasoning capability, we add SQL-based pretraining in the multitask setting.
<math id="S3.SS3.p1.1.m1.3" class="ltx_Math" alttext="\mathcal{L}_{\text{sql}}=-\log P(\bm{a}|\bm{o},T)" display="inline"><semantics id="S3.SS3.p1.1.m1.3a"><mrow id="S3.SS3.p1.1.m1.3.3" xref="S3.SS3.p1.1.m1.3.3.cmml"><msub id="S3.SS3.p1.1.m1.3.3.3" xref="S3.SS3.p1.1.m1.3.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p1.1.m1.3.3.3.2" xref="S3.SS3.p1.1.m1.3.3.3.2.cmml">â„’</mi><mtext id="S3.SS3.p1.1.m1.3.3.3.3" xref="S3.SS3.p1.1.m1.3.3.3.3a.cmml">sql</mtext></msub><mo id="S3.SS3.p1.1.m1.3.3.2" xref="S3.SS3.p1.1.m1.3.3.2.cmml">=</mo><mrow id="S3.SS3.p1.1.m1.3.3.1" xref="S3.SS3.p1.1.m1.3.3.1.cmml"><mo rspace="0.167em" id="S3.SS3.p1.1.m1.3.3.1a" xref="S3.SS3.p1.1.m1.3.3.1.cmml">âˆ’</mo><mrow id="S3.SS3.p1.1.m1.3.3.1.1" xref="S3.SS3.p1.1.m1.3.3.1.1.cmml"><mrow id="S3.SS3.p1.1.m1.3.3.1.1.3" xref="S3.SS3.p1.1.m1.3.3.1.1.3.cmml"><mi id="S3.SS3.p1.1.m1.3.3.1.1.3.1" xref="S3.SS3.p1.1.m1.3.3.1.1.3.1.cmml">log</mi><mo lspace="0.167em" id="S3.SS3.p1.1.m1.3.3.1.1.3a" xref="S3.SS3.p1.1.m1.3.3.1.1.3.cmml">â¡</mo><mi id="S3.SS3.p1.1.m1.3.3.1.1.3.2" xref="S3.SS3.p1.1.m1.3.3.1.1.3.2.cmml">P</mi></mrow><mo lspace="0em" rspace="0em" id="S3.SS3.p1.1.m1.3.3.1.1.2" xref="S3.SS3.p1.1.m1.3.3.1.1.2.cmml">â€‹</mo><mrow id="S3.SS3.p1.1.m1.3.3.1.1.1.1" xref="S3.SS3.p1.1.m1.3.3.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS3.p1.1.m1.3.3.1.1.1.1.2" xref="S3.SS3.p1.1.m1.3.3.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS3.p1.1.m1.3.3.1.1.1.1.1" xref="S3.SS3.p1.1.m1.3.3.1.1.1.1.1.cmml"><mi id="S3.SS3.p1.1.m1.3.3.1.1.1.1.1.2" xref="S3.SS3.p1.1.m1.3.3.1.1.1.1.1.2.cmml">ğ’‚</mi><mo fence="false" id="S3.SS3.p1.1.m1.3.3.1.1.1.1.1.1" xref="S3.SS3.p1.1.m1.3.3.1.1.1.1.1.1.cmml">|</mo><mrow id="S3.SS3.p1.1.m1.3.3.1.1.1.1.1.3.2" xref="S3.SS3.p1.1.m1.3.3.1.1.1.1.1.3.1.cmml"><mi id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml">ğ’</mi><mo id="S3.SS3.p1.1.m1.3.3.1.1.1.1.1.3.2.1" xref="S3.SS3.p1.1.m1.3.3.1.1.1.1.1.3.1.cmml">,</mo><mi id="S3.SS3.p1.1.m1.2.2" xref="S3.SS3.p1.1.m1.2.2.cmml">T</mi></mrow></mrow><mo stretchy="false" id="S3.SS3.p1.1.m1.3.3.1.1.1.1.3" xref="S3.SS3.p1.1.m1.3.3.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.3b"><apply id="S3.SS3.p1.1.m1.3.3.cmml" xref="S3.SS3.p1.1.m1.3.3"><eq id="S3.SS3.p1.1.m1.3.3.2.cmml" xref="S3.SS3.p1.1.m1.3.3.2"></eq><apply id="S3.SS3.p1.1.m1.3.3.3.cmml" xref="S3.SS3.p1.1.m1.3.3.3"><csymbol cd="ambiguous" id="S3.SS3.p1.1.m1.3.3.3.1.cmml" xref="S3.SS3.p1.1.m1.3.3.3">subscript</csymbol><ci id="S3.SS3.p1.1.m1.3.3.3.2.cmml" xref="S3.SS3.p1.1.m1.3.3.3.2">â„’</ci><ci id="S3.SS3.p1.1.m1.3.3.3.3a.cmml" xref="S3.SS3.p1.1.m1.3.3.3.3"><mtext mathsize="70%" id="S3.SS3.p1.1.m1.3.3.3.3.cmml" xref="S3.SS3.p1.1.m1.3.3.3.3">sql</mtext></ci></apply><apply id="S3.SS3.p1.1.m1.3.3.1.cmml" xref="S3.SS3.p1.1.m1.3.3.1"><minus id="S3.SS3.p1.1.m1.3.3.1.2.cmml" xref="S3.SS3.p1.1.m1.3.3.1"></minus><apply id="S3.SS3.p1.1.m1.3.3.1.1.cmml" xref="S3.SS3.p1.1.m1.3.3.1.1"><times id="S3.SS3.p1.1.m1.3.3.1.1.2.cmml" xref="S3.SS3.p1.1.m1.3.3.1.1.2"></times><apply id="S3.SS3.p1.1.m1.3.3.1.1.3.cmml" xref="S3.SS3.p1.1.m1.3.3.1.1.3"><log id="S3.SS3.p1.1.m1.3.3.1.1.3.1.cmml" xref="S3.SS3.p1.1.m1.3.3.1.1.3.1"></log><ci id="S3.SS3.p1.1.m1.3.3.1.1.3.2.cmml" xref="S3.SS3.p1.1.m1.3.3.1.1.3.2">ğ‘ƒ</ci></apply><apply id="S3.SS3.p1.1.m1.3.3.1.1.1.1.1.cmml" xref="S3.SS3.p1.1.m1.3.3.1.1.1.1"><csymbol cd="latexml" id="S3.SS3.p1.1.m1.3.3.1.1.1.1.1.1.cmml" xref="S3.SS3.p1.1.m1.3.3.1.1.1.1.1.1">conditional</csymbol><ci id="S3.SS3.p1.1.m1.3.3.1.1.1.1.1.2.cmml" xref="S3.SS3.p1.1.m1.3.3.1.1.1.1.1.2">ğ’‚</ci><list id="S3.SS3.p1.1.m1.3.3.1.1.1.1.1.3.1.cmml" xref="S3.SS3.p1.1.m1.3.3.1.1.1.1.1.3.2"><ci id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">ğ’</ci><ci id="S3.SS3.p1.1.m1.2.2.cmml" xref="S3.SS3.p1.1.m1.2.2">ğ‘‡</ci></list></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.3c">\mathcal{L}_{\text{sql}}=-\log P(\bm{a}|\bm{o},T)</annotation></semantics></math>, resulting a combination of three parts <math id="S3.SS3.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{L}_{\text{mask}}+\mathcal{L}_{\text{QA}}+\mathcal{L}_{\text{sql}}" display="inline"><semantics id="S3.SS3.p1.2.m2.1a"><mrow id="S3.SS3.p1.2.m2.1.1" xref="S3.SS3.p1.2.m2.1.1.cmml"><msub id="S3.SS3.p1.2.m2.1.1.2" xref="S3.SS3.p1.2.m2.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p1.2.m2.1.1.2.2" xref="S3.SS3.p1.2.m2.1.1.2.2.cmml">â„’</mi><mtext id="S3.SS3.p1.2.m2.1.1.2.3" xref="S3.SS3.p1.2.m2.1.1.2.3a.cmml">mask</mtext></msub><mo id="S3.SS3.p1.2.m2.1.1.1" xref="S3.SS3.p1.2.m2.1.1.1.cmml">+</mo><msub id="S3.SS3.p1.2.m2.1.1.3" xref="S3.SS3.p1.2.m2.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p1.2.m2.1.1.3.2" xref="S3.SS3.p1.2.m2.1.1.3.2.cmml">â„’</mi><mtext id="S3.SS3.p1.2.m2.1.1.3.3" xref="S3.SS3.p1.2.m2.1.1.3.3a.cmml">QA</mtext></msub><mo id="S3.SS3.p1.2.m2.1.1.1a" xref="S3.SS3.p1.2.m2.1.1.1.cmml">+</mo><msub id="S3.SS3.p1.2.m2.1.1.4" xref="S3.SS3.p1.2.m2.1.1.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p1.2.m2.1.1.4.2" xref="S3.SS3.p1.2.m2.1.1.4.2.cmml">â„’</mi><mtext id="S3.SS3.p1.2.m2.1.1.4.3" xref="S3.SS3.p1.2.m2.1.1.4.3a.cmml">sql</mtext></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.2.m2.1b"><apply id="S3.SS3.p1.2.m2.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1"><plus id="S3.SS3.p1.2.m2.1.1.1.cmml" xref="S3.SS3.p1.2.m2.1.1.1"></plus><apply id="S3.SS3.p1.2.m2.1.1.2.cmml" xref="S3.SS3.p1.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p1.2.m2.1.1.2.1.cmml" xref="S3.SS3.p1.2.m2.1.1.2">subscript</csymbol><ci id="S3.SS3.p1.2.m2.1.1.2.2.cmml" xref="S3.SS3.p1.2.m2.1.1.2.2">â„’</ci><ci id="S3.SS3.p1.2.m2.1.1.2.3a.cmml" xref="S3.SS3.p1.2.m2.1.1.2.3"><mtext mathsize="70%" id="S3.SS3.p1.2.m2.1.1.2.3.cmml" xref="S3.SS3.p1.2.m2.1.1.2.3">mask</mtext></ci></apply><apply id="S3.SS3.p1.2.m2.1.1.3.cmml" xref="S3.SS3.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p1.2.m2.1.1.3.1.cmml" xref="S3.SS3.p1.2.m2.1.1.3">subscript</csymbol><ci id="S3.SS3.p1.2.m2.1.1.3.2.cmml" xref="S3.SS3.p1.2.m2.1.1.3.2">â„’</ci><ci id="S3.SS3.p1.2.m2.1.1.3.3a.cmml" xref="S3.SS3.p1.2.m2.1.1.3.3"><mtext mathsize="70%" id="S3.SS3.p1.2.m2.1.1.3.3.cmml" xref="S3.SS3.p1.2.m2.1.1.3.3">QA</mtext></ci></apply><apply id="S3.SS3.p1.2.m2.1.1.4.cmml" xref="S3.SS3.p1.2.m2.1.1.4"><csymbol cd="ambiguous" id="S3.SS3.p1.2.m2.1.1.4.1.cmml" xref="S3.SS3.p1.2.m2.1.1.4">subscript</csymbol><ci id="S3.SS3.p1.2.m2.1.1.4.2.cmml" xref="S3.SS3.p1.2.m2.1.1.4.2">â„’</ci><ci id="S3.SS3.p1.2.m2.1.1.4.3a.cmml" xref="S3.SS3.p1.2.m2.1.1.4.3"><mtext mathsize="70%" id="S3.SS3.p1.2.m2.1.1.4.3.cmml" xref="S3.SS3.p1.2.m2.1.1.4.3">sql</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.2.m2.1c">\mathcal{L}_{\text{mask}}+\mathcal{L}_{\text{QA}}+\mathcal{L}_{\text{sql}}</annotation></semantics></math> as the multitask loss.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">We first detail the experimental settings (<a href="#S4.SS1" title="4.1 Experimental Settings â€£ 4 Experiments â€£ OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Â§Â 4.1</span></a>).
Then we report on extensive experiments, starting with the overall result including all design elements to achieve the best results (<a href="#S4.SS2" title="4.2 Overall Results â€£ 4 Experiments â€£ OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Â§Â 4.2</span></a>), then breaking down into each design choice to analyze their individual contribution (<a href="#S4.SS3" title="4.3 Ablation Study â€£ 4 Experiments â€£ OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Â§Â 4.3</span></a>).
Finally, we analyze concrete examples to provide insight on different characteristics of natural and synthetic data (<a href="#S4.SS4" title="4.4 Analysis â€£ 4 Experiments â€£ OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Â§Â 4.4</span></a>).</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Experimental Settings</h3>

<section id="S4.SS1.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Few-shot Settings</h5>

<div id="S4.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px1.p1.1" class="ltx_p">We use WikiTableQuestions <cite class="ltx_cite ltx_citemacro_cite">Pasupat and Liang (<a href="#bib.bib19" title="" class="ltx_ref">2015</a>)</cite> as our major benchmark, as it is a widely used table-based QA dataset involving various complex reasoning operations, and report the answer accuracy given by the official evaluator.
Following work on few-shot QA <cite class="ltx_cite ltx_citemacro_cite">Ram etÂ al. (<a href="#bib.bib20" title="" class="ltx_ref">2021</a>)</cite>, we create few-shot settings of WTQ by sampling a subset from the original training containing 11K examples in total, with sizes changing on a logarithmic scale from 16 to 1024.</p>
</div>
<div id="S4.SS1.SSS0.Px1.p2" class="ltx_para">
<p id="S4.SS1.SSS0.Px1.p2.8" class="ltx_p">Another component that requires annotated NL questions is the SQL2NL model.
We use SQUALL <cite class="ltx_cite ltx_citemacro_cite">Shi etÂ al. (<a href="#bib.bib22" title="" class="ltx_ref">2020</a>)</cite>, which contains <math id="S4.SS1.SSS0.Px1.p2.1.m1.1" class="ltx_Math" alttext="\approx" display="inline"><semantics id="S4.SS1.SSS0.Px1.p2.1.m1.1a"><mo id="S4.SS1.SSS0.Px1.p2.1.m1.1.1" xref="S4.SS1.SSS0.Px1.p2.1.m1.1.1.cmml">â‰ˆ</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px1.p2.1.m1.1b"><approx id="S4.SS1.SSS0.Px1.p2.1.m1.1.1.cmml" xref="S4.SS1.SSS0.Px1.p2.1.m1.1.1"></approx></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px1.p2.1.m1.1c">\approx</annotation></semantics></math>10K annotations in total, to simulate few-shot scenarios by varying the number of SQL annotated with NL from 16 to 4,096.
In the <math id="S4.SS1.SSS0.Px1.p2.2.m2.1" class="ltx_Math" alttext="f" display="inline"><semantics id="S4.SS1.SSS0.Px1.p2.2.m2.1a"><mi id="S4.SS1.SSS0.Px1.p2.2.m2.1.1" xref="S4.SS1.SSS0.Px1.p2.2.m2.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px1.p2.2.m2.1b"><ci id="S4.SS1.SSS0.Px1.p2.2.m2.1.1.cmml" xref="S4.SS1.SSS0.Px1.p2.2.m2.1.1">ğ‘“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px1.p2.2.m2.1c">f</annotation></semantics></math>-shot setting, we use SQUALL-<math id="S4.SS1.SSS0.Px1.p2.3.m3.1" class="ltx_Math" alttext="f" display="inline"><semantics id="S4.SS1.SSS0.Px1.p2.3.m3.1a"><mi id="S4.SS1.SSS0.Px1.p2.3.m3.1.1" xref="S4.SS1.SSS0.Px1.p2.3.m3.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px1.p2.3.m3.1b"><ci id="S4.SS1.SSS0.Px1.p2.3.m3.1.1.cmml" xref="S4.SS1.SSS0.Px1.p2.3.m3.1.1">ğ‘“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px1.p2.3.m3.1c">f</annotation></semantics></math> to train the SQL2NL model and WTQ-<math id="S4.SS1.SSS0.Px1.p2.4.m4.1" class="ltx_Math" alttext="f" display="inline"><semantics id="S4.SS1.SSS0.Px1.p2.4.m4.1a"><mi id="S4.SS1.SSS0.Px1.p2.4.m4.1.1" xref="S4.SS1.SSS0.Px1.p2.4.m4.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px1.p2.4.m4.1b"><ci id="S4.SS1.SSS0.Px1.p2.4.m4.1.1.cmml" xref="S4.SS1.SSS0.Px1.p2.4.m4.1.1">ğ‘“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px1.p2.4.m4.1c">f</annotation></semantics></math> to finetune QA models.
Since SQUALL and WTQ share the same set of NL questions, we make sure that SQUALL-<math id="S4.SS1.SSS0.Px1.p2.5.m5.1" class="ltx_Math" alttext="f" display="inline"><semantics id="S4.SS1.SSS0.Px1.p2.5.m5.1a"><mi id="S4.SS1.SSS0.Px1.p2.5.m5.1.1" xref="S4.SS1.SSS0.Px1.p2.5.m5.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px1.p2.5.m5.1b"><ci id="S4.SS1.SSS0.Px1.p2.5.m5.1.1.cmml" xref="S4.SS1.SSS0.Px1.p2.5.m5.1.1">ğ‘“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px1.p2.5.m5.1c">f</annotation></semantics></math> also includes the same questions as WTQ-<math id="S4.SS1.SSS0.Px1.p2.6.m6.1" class="ltx_Math" alttext="f" display="inline"><semantics id="S4.SS1.SSS0.Px1.p2.6.m6.1a"><mi id="S4.SS1.SSS0.Px1.p2.6.m6.1.1" xref="S4.SS1.SSS0.Px1.p2.6.m6.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px1.p2.6.m6.1b"><ci id="S4.SS1.SSS0.Px1.p2.6.m6.1.1.cmml" xref="S4.SS1.SSS0.Px1.p2.6.m6.1.1">ğ‘“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px1.p2.6.m6.1c">f</annotation></semantics></math>, so in total only <math id="S4.SS1.SSS0.Px1.p2.7.m7.1" class="ltx_Math" alttext="f" display="inline"><semantics id="S4.SS1.SSS0.Px1.p2.7.m7.1a"><mi id="S4.SS1.SSS0.Px1.p2.7.m7.1.1" xref="S4.SS1.SSS0.Px1.p2.7.m7.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px1.p2.7.m7.1b"><ci id="S4.SS1.SSS0.Px1.p2.7.m7.1.1.cmml" xref="S4.SS1.SSS0.Px1.p2.7.m7.1.1">ğ‘“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px1.p2.7.m7.1c">f</annotation></semantics></math> annotated questions are used in the <math id="S4.SS1.SSS0.Px1.p2.8.m8.1" class="ltx_Math" alttext="f" display="inline"><semantics id="S4.SS1.SSS0.Px1.p2.8.m8.1a"><mi id="S4.SS1.SSS0.Px1.p2.8.m8.1.1" xref="S4.SS1.SSS0.Px1.p2.8.m8.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px1.p2.8.m8.1b"><ci id="S4.SS1.SSS0.Px1.p2.8.m8.1.1.cmml" xref="S4.SS1.SSS0.Px1.p2.8.m8.1.1">ğ‘“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px1.p2.8.m8.1c">f</annotation></semantics></math>-shot setting.</p>
</div>
<div id="S4.SS1.SSS0.Px1.p3" class="ltx_para">
<p id="S4.SS1.SSS0.Px1.p3.1" class="ltx_p">We also report on WikiSQL <cite class="ltx_cite ltx_citemacro_cite">Zhong etÂ al. (<a href="#bib.bib27" title="" class="ltx_ref">2017</a>)</cite>, another table-based QA benchmark with relatively simple questions.
To evaluate robustness under topical shift, we further use WikiTableQuestions-TS which split WTQ into five topics <cite class="ltx_cite ltx_citemacro_cite">Chemmengath etÂ al. (<a href="#bib.bib1" title="" class="ltx_ref">2021</a>)</cite> based on Wikipedia categories.
We follow their creation procedure to reproduce the split, and evaluate our methods by finetuning on one topic and testing on the other four topics.</p>
</div>
</section>
<section id="S4.SS1.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Pretraining Corpora</h5>

<div id="S4.SS1.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px2.p1.1" class="ltx_p">We use the table corpus by <cite class="ltx_cite ltx_citemacro_citet">Herzig etÂ al. (<a href="#bib.bib8" title="" class="ltx_ref">2020</a>)</cite> extracted from Wikipedia as our source of tables for retrieval.
All tables are preprocessed into a two-dimensional structure with a single header and one or multiple data rows.
We use a subset of this corpus and find the corresponding Wikipedia page through its URL, which is preprocessed into sentences using SLING.
Since some tables are noisy and some Wikipedia pages do not contain meaningful sentences, eventually we pair approximately 0.5M tables with sentences using our three retrieval methods.
To make the synthetic data of similar size, we also use 0.5M SQL sampled by <cite class="ltx_cite ltx_citemacro_citet">Liu etÂ al. (<a href="#bib.bib16" title="" class="ltx_ref">2021</a>)</cite> to generate synthetic questions.</p>
</div>
</section>
<section id="S4.SS1.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Baselines</h5>

<div id="S4.SS1.SSS0.Px3.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px3.p1.1" class="ltx_p">We consider two types of models as baselines (1) pipeline methods that execute generated SQL to get answers such as <span id="S4.SS1.SSS0.Px3.p1.1.2" class="ltx_text ltx_font_bold">TaBERT</span> <cite class="ltx_cite ltx_citemacro_cite">Yin etÂ al. (<a href="#bib.bib25" title="" class="ltx_ref">2020</a>)</cite> with <span id="S4.SS1.SSS0.Px3.p1.1.3" class="ltx_text ltx_font_bold">MAPO</span> <cite class="ltx_cite ltx_citemacro_cite">Liang etÂ al. (<a href="#bib.bib15" title="" class="ltx_ref">2018</a>)</cite> as the semantic parser and (2) end2end methods that directly generate answers, such as <span id="S4.SS1.SSS0.Px3.p1.1.4" class="ltx_text ltx_font_bold">BART</span> <cite class="ltx_cite ltx_citemacro_cite">Lewis etÂ al. (<a href="#bib.bib14" title="" class="ltx_ref">2020b</a>)</cite>, <span id="S4.SS1.SSS0.Px3.p1.1.5" class="ltx_text ltx_font_bold">TAPAS</span> <cite class="ltx_cite ltx_citemacro_cite">Herzig etÂ al. (<a href="#bib.bib8" title="" class="ltx_ref">2020</a>)</cite>, and <span id="S4.SS1.SSS0.Px3.p1.1.6" class="ltx_text ltx_font_bold">TAPEX</span> <cite class="ltx_cite ltx_citemacro_cite">Liu etÂ al. (<a href="#bib.bib16" title="" class="ltx_ref">2021</a>)</cite>.
More discussions about table-related models can be found in the related work section in <a href="#S5" title="5 Related Work â€£ OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Â§Â 5</span></a>.
Since we also incorporate the SQL data used by TAPEX in our final multitask setting, we report <span id="S4.SS1.SSS0.Px3.p1.1.1" class="ltx_text ltx_font_bold">TAPEX<sup id="S4.SS1.SSS0.Px3.p1.1.1.1" class="ltx_sup"><span id="S4.SS1.SSS0.Px3.p1.1.1.1.1" class="ltx_text ltx_font_medium">âˆ—</span></sup></span> when comparing with our multitask setting, which continued to train TAPEX on SQL data for as many steps as OmniTab to make a fair and rigorous comparison.
We use <span id="S4.SS1.SSS0.Px3.p1.1.7" class="ltx_text ltx_font_bold">OmniTab</span> to denote our full model trained in the multitask setting with both natural, synthetic, and SQL data (<a href="#S3.SS3" title="3.3 Combining Natural and Synthetic Data â€£ 3 OmniTab: Pretraining with Natural and Synthetic Data â€£ OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Â§Â 3.3</span></a>).</p>
</div>
</section>
<section id="S4.SS1.SSS0.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Implementation Details</h5>

<div id="S4.SS1.SSS0.Px4.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px4.p1.4" class="ltx_p">During pretraining, we use a batch size of 512 and train OmniTab for 5 epochs, which takes about 20 hours on 8 V100 GPUs for multitasking on both natural and synthetic data.
During finetuning, we use a batch size of 96 and finetune OmniTab for 50 epochs, which takes about 30 minutes on 8 V100 GPUs.
We use a learning rate of 2e-5 for both pretraining, finetuning.
We use BART-large and TAPEX-large in all experiments.
For dense retrieval, since we use the max operation, all phrases have scores <math id="S4.SS1.SSS0.Px4.p1.1.m1.2" class="ltx_Math" alttext="\in[-1,1]" display="inline"><semantics id="S4.SS1.SSS0.Px4.p1.1.m1.2a"><mrow id="S4.SS1.SSS0.Px4.p1.1.m1.2.2" xref="S4.SS1.SSS0.Px4.p1.1.m1.2.2.cmml"><mi id="S4.SS1.SSS0.Px4.p1.1.m1.2.2.3" xref="S4.SS1.SSS0.Px4.p1.1.m1.2.2.3.cmml"></mi><mo id="S4.SS1.SSS0.Px4.p1.1.m1.2.2.2" xref="S4.SS1.SSS0.Px4.p1.1.m1.2.2.2.cmml">âˆˆ</mo><mrow id="S4.SS1.SSS0.Px4.p1.1.m1.2.2.1.1" xref="S4.SS1.SSS0.Px4.p1.1.m1.2.2.1.2.cmml"><mo stretchy="false" id="S4.SS1.SSS0.Px4.p1.1.m1.2.2.1.1.2" xref="S4.SS1.SSS0.Px4.p1.1.m1.2.2.1.2.cmml">[</mo><mrow id="S4.SS1.SSS0.Px4.p1.1.m1.2.2.1.1.1" xref="S4.SS1.SSS0.Px4.p1.1.m1.2.2.1.1.1.cmml"><mo id="S4.SS1.SSS0.Px4.p1.1.m1.2.2.1.1.1a" xref="S4.SS1.SSS0.Px4.p1.1.m1.2.2.1.1.1.cmml">âˆ’</mo><mn id="S4.SS1.SSS0.Px4.p1.1.m1.2.2.1.1.1.2" xref="S4.SS1.SSS0.Px4.p1.1.m1.2.2.1.1.1.2.cmml">1</mn></mrow><mo id="S4.SS1.SSS0.Px4.p1.1.m1.2.2.1.1.3" xref="S4.SS1.SSS0.Px4.p1.1.m1.2.2.1.2.cmml">,</mo><mn id="S4.SS1.SSS0.Px4.p1.1.m1.1.1" xref="S4.SS1.SSS0.Px4.p1.1.m1.1.1.cmml">1</mn><mo stretchy="false" id="S4.SS1.SSS0.Px4.p1.1.m1.2.2.1.1.4" xref="S4.SS1.SSS0.Px4.p1.1.m1.2.2.1.2.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px4.p1.1.m1.2b"><apply id="S4.SS1.SSS0.Px4.p1.1.m1.2.2.cmml" xref="S4.SS1.SSS0.Px4.p1.1.m1.2.2"><in id="S4.SS1.SSS0.Px4.p1.1.m1.2.2.2.cmml" xref="S4.SS1.SSS0.Px4.p1.1.m1.2.2.2"></in><csymbol cd="latexml" id="S4.SS1.SSS0.Px4.p1.1.m1.2.2.3.cmml" xref="S4.SS1.SSS0.Px4.p1.1.m1.2.2.3">absent</csymbol><interval closure="closed" id="S4.SS1.SSS0.Px4.p1.1.m1.2.2.1.2.cmml" xref="S4.SS1.SSS0.Px4.p1.1.m1.2.2.1.1"><apply id="S4.SS1.SSS0.Px4.p1.1.m1.2.2.1.1.1.cmml" xref="S4.SS1.SSS0.Px4.p1.1.m1.2.2.1.1.1"><minus id="S4.SS1.SSS0.Px4.p1.1.m1.2.2.1.1.1.1.cmml" xref="S4.SS1.SSS0.Px4.p1.1.m1.2.2.1.1.1"></minus><cn type="integer" id="S4.SS1.SSS0.Px4.p1.1.m1.2.2.1.1.1.2.cmml" xref="S4.SS1.SSS0.Px4.p1.1.m1.2.2.1.1.1.2">1</cn></apply><cn type="integer" id="S4.SS1.SSS0.Px4.p1.1.m1.1.1.cmml" xref="S4.SS1.SSS0.Px4.p1.1.m1.1.1">1</cn></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px4.p1.1.m1.2c">\in[-1,1]</annotation></semantics></math>.
We bucket phrases into bins with an interval of 0.1, manually inspect the quality of some randomly sampled phrases from each bin, and found that phrases with scores larger than <math id="S4.SS1.SSS0.Px4.p1.2.m2.1" class="ltx_Math" alttext="\tau=0.6" display="inline"><semantics id="S4.SS1.SSS0.Px4.p1.2.m2.1a"><mrow id="S4.SS1.SSS0.Px4.p1.2.m2.1.1" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1.cmml"><mi id="S4.SS1.SSS0.Px4.p1.2.m2.1.1.2" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1.2.cmml">Ï„</mi><mo id="S4.SS1.SSS0.Px4.p1.2.m2.1.1.1" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1.1.cmml">=</mo><mn id="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.cmml">0.6</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px4.p1.2.m2.1b"><apply id="S4.SS1.SSS0.Px4.p1.2.m2.1.1.cmml" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1"><eq id="S4.SS1.SSS0.Px4.p1.2.m2.1.1.1.cmml" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1.1"></eq><ci id="S4.SS1.SSS0.Px4.p1.2.m2.1.1.2.cmml" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1.2">ğœ</ci><cn type="float" id="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3.cmml" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1.3">0.6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px4.p1.2.m2.1c">\tau=0.6</annotation></semantics></math> are of high quality.
We use spaCy<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a target="_blank" href="https://spacy.io/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://spacy.io/</a></span></span></span> to detect named entities for dense retrieval.
For self-training of the SQL2NL model, we use the best-performing OmniTab model without self-training as the verification QA model, and make sure that it uses the same amount of annotations as the final model (i.e. if the final model is a <math id="S4.SS1.SSS0.Px4.p1.3.m3.1" class="ltx_Math" alttext="f" display="inline"><semantics id="S4.SS1.SSS0.Px4.p1.3.m3.1a"><mi id="S4.SS1.SSS0.Px4.p1.3.m3.1.1" xref="S4.SS1.SSS0.Px4.p1.3.m3.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px4.p1.3.m3.1b"><ci id="S4.SS1.SSS0.Px4.p1.3.m3.1.1.cmml" xref="S4.SS1.SSS0.Px4.p1.3.m3.1.1">ğ‘“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px4.p1.3.m3.1c">f</annotation></semantics></math>-shot model, we also use <math id="S4.SS1.SSS0.Px4.p1.4.m4.1" class="ltx_Math" alttext="f" display="inline"><semantics id="S4.SS1.SSS0.Px4.p1.4.m4.1a"><mi id="S4.SS1.SSS0.Px4.p1.4.m4.1.1" xref="S4.SS1.SSS0.Px4.p1.4.m4.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px4.p1.4.m4.1b"><ci id="S4.SS1.SSS0.Px4.p1.4.m4.1.1.cmml" xref="S4.SS1.SSS0.Px4.p1.4.m4.1.1">ğ‘“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px4.p1.4.m4.1c">f</annotation></semantics></math> annotations to train the verification model).
In our final model, we added approximately 10K SQL-NL pairs for self-training.</p>
</div>
<figure id="S4.T1" class="ltx_table">
<table id="S4.T1.2" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T1.1.1" class="ltx_tr">
<td id="S4.T1.1.1.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S4.T1.1.1.1.1" class="ltx_text ltx_font_bold">Model  <math id="S4.T1.1.1.1.1.m1.1" class="ltx_Math" alttext="f" display="inline"><semantics id="S4.T1.1.1.1.1.m1.1a"><mi id="S4.T1.1.1.1.1.m1.1.1" xref="S4.T1.1.1.1.1.m1.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="S4.T1.1.1.1.1.m1.1b"><ci id="S4.T1.1.1.1.1.m1.1.1.cmml" xref="S4.T1.1.1.1.1.m1.1.1">ğ‘“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.1.1.1.1.m1.1c">f</annotation></semantics></math>-shot:</span></td>
<td id="S4.T1.1.1.2" class="ltx_td ltx_align_right ltx_border_tt"><span id="S4.T1.1.1.2.1" class="ltx_text ltx_font_bold">16</span></td>
<td id="S4.T1.1.1.3" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_tt"><span id="S4.T1.1.1.3.1" class="ltx_text ltx_font_bold">128</span></td>
<td id="S4.T1.1.1.4" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_tt"><span id="S4.T1.1.1.4.1" class="ltx_text ltx_font_bold">1024</span></td>
<td id="S4.T1.1.1.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_tt"><span id="S4.T1.1.1.5.1" class="ltx_text ltx_font_bold">full</span></td>
</tr>
<tr id="S4.T1.2.3.1" class="ltx_tr">
<td id="S4.T1.2.3.1.1" class="ltx_td ltx_align_center ltx_border_t" colspan="5"><em id="S4.T1.2.3.1.1.1" class="ltx_emph ltx_font_italic">Pipeline systems</em></td>
</tr>
<tr id="S4.T1.2.4.2" class="ltx_tr">
<td id="S4.T1.2.4.2.1" class="ltx_td ltx_align_left">TaBERT+MAPO <cite class="ltx_cite ltx_citemacro_cite">Yin etÂ al. (<a href="#bib.bib25" title="" class="ltx_ref">2020</a>)</cite>
</td>
<td id="S4.T1.2.4.2.2" class="ltx_td ltx_align_right">7.7</td>
<td id="S4.T1.2.4.2.3" class="ltx_td ltx_nopad_l ltx_align_right">15.1</td>
<td id="S4.T1.2.4.2.4" class="ltx_td ltx_nopad_l ltx_align_right">33.3</td>
<td id="S4.T1.2.4.2.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right">52.3</td>
</tr>
<tr id="S4.T1.2.5.3" class="ltx_tr">
<td id="S4.T1.2.5.3.1" class="ltx_td ltx_align_center ltx_border_t" colspan="5"><em id="S4.T1.2.5.3.1.1" class="ltx_emph ltx_font_italic">End2end systems</em></td>
</tr>
<tr id="S4.T1.2.6.4" class="ltx_tr">
<td id="S4.T1.2.6.4.1" class="ltx_td ltx_align_left">BART <cite class="ltx_cite ltx_citemacro_cite">Lewis etÂ al. (<a href="#bib.bib14" title="" class="ltx_ref">2020b</a>)</cite>
</td>
<td id="S4.T1.2.6.4.2" class="ltx_td ltx_align_right">2.9</td>
<td id="S4.T1.2.6.4.3" class="ltx_td ltx_nopad_l ltx_align_right">8.4</td>
<td id="S4.T1.2.6.4.4" class="ltx_td ltx_nopad_l ltx_align_right">17.3</td>
<td id="S4.T1.2.6.4.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right">38.0</td>
</tr>
<tr id="S4.T1.2.7.5" class="ltx_tr">
<td id="S4.T1.2.7.5.1" class="ltx_td ltx_align_left">TAPAS <cite class="ltx_cite ltx_citemacro_cite">Herzig etÂ al. (<a href="#bib.bib8" title="" class="ltx_ref">2020</a>)</cite>
</td>
<td id="S4.T1.2.7.5.2" class="ltx_td ltx_align_right">9.8</td>
<td id="S4.T1.2.7.5.3" class="ltx_td ltx_nopad_l ltx_align_right">18.9</td>
<td id="S4.T1.2.7.5.4" class="ltx_td ltx_nopad_l ltx_align_right">33.6</td>
<td id="S4.T1.2.7.5.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right">48.8</td>
</tr>
<tr id="S4.T1.2.8.6" class="ltx_tr">
<td id="S4.T1.2.8.6.1" class="ltx_td ltx_align_left">TAPEX <cite class="ltx_cite ltx_citemacro_cite">Liu etÂ al. (<a href="#bib.bib16" title="" class="ltx_ref">2021</a>)</cite>
</td>
<td id="S4.T1.2.8.6.2" class="ltx_td ltx_align_right">10.4</td>
<td id="S4.T1.2.8.6.3" class="ltx_td ltx_nopad_l ltx_align_right">23.1</td>
<td id="S4.T1.2.8.6.4" class="ltx_td ltx_nopad_l ltx_align_right"><em id="S4.T1.2.8.6.4.1" class="ltx_emph ltx_font_italic">45.5</em></td>
<td id="S4.T1.2.8.6.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right">59.5</td>
</tr>
<tr id="S4.T1.2.2" class="ltx_tr">
<td id="S4.T1.2.2.1" class="ltx_td ltx_align_left">TAPEX<sup id="S4.T1.2.2.1.1" class="ltx_sup">âˆ—</sup>
</td>
<td id="S4.T1.2.2.2" class="ltx_td ltx_align_right"><em id="S4.T1.2.2.2.1" class="ltx_emph ltx_font_italic">15.7</em></td>
<td id="S4.T1.2.2.3" class="ltx_td ltx_nopad_l ltx_align_right"><em id="S4.T1.2.2.3.1" class="ltx_emph ltx_font_italic">25.2</em></td>
<td id="S4.T1.2.2.4" class="ltx_td ltx_nopad_l ltx_align_right">44.6</td>
<td id="S4.T1.2.2.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right"><em id="S4.T1.2.2.5.1" class="ltx_emph ltx_font_italic">60.1</em></td>
</tr>
<tr id="S4.T1.2.9.7" class="ltx_tr">
<td id="S4.T1.2.9.7.1" class="ltx_td ltx_align_center ltx_border_t" colspan="5"><em id="S4.T1.2.9.7.1.1" class="ltx_emph ltx_font_italic">Ours (end2end)</em></td>
</tr>
<tr id="S4.T1.2.10.8" class="ltx_tr">
<td id="S4.T1.2.10.8.1" class="ltx_td ltx_align_left">OmniTab w/ natural data</td>
<td id="S4.T1.2.10.8.2" class="ltx_td ltx_align_right">22.8</td>
<td id="S4.T1.2.10.8.3" class="ltx_td ltx_nopad_l ltx_align_right">38.4</td>
<td id="S4.T1.2.10.8.4" class="ltx_td ltx_nopad_l ltx_align_right">49.8</td>
<td id="S4.T1.2.10.8.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right">61.3</td>
</tr>
<tr id="S4.T1.2.11.9" class="ltx_tr">
<td id="S4.T1.2.11.9.1" class="ltx_td ltx_align_left">OmniTab w/ synthetic data</td>
<td id="S4.T1.2.11.9.2" class="ltx_td ltx_align_right">21.5</td>
<td id="S4.T1.2.11.9.3" class="ltx_td ltx_nopad_l ltx_align_right">37.5</td>
<td id="S4.T1.2.11.9.4" class="ltx_td ltx_nopad_l ltx_align_right">48.8</td>
<td id="S4.T1.2.11.9.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right">61.3</td>
</tr>
<tr id="S4.T1.2.12.10" class="ltx_tr">
<td id="S4.T1.2.12.10.1" class="ltx_td ltx_align_left ltx_border_bb">OmniTab (w/ all)</td>
<td id="S4.T1.2.12.10.2" class="ltx_td ltx_align_right ltx_border_bb"><span id="S4.T1.2.12.10.2.1" class="ltx_text ltx_font_bold">26.8</span></td>
<td id="S4.T1.2.12.10.3" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb"><span id="S4.T1.2.12.10.3.1" class="ltx_text ltx_font_bold">41.4</span></td>
<td id="S4.T1.2.12.10.4" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb"><span id="S4.T1.2.12.10.4.1" class="ltx_text ltx_font_bold">51.9</span></td>
<td id="S4.T1.2.12.10.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_bb"><span id="S4.T1.2.12.10.5.1" class="ltx_text ltx_font_bold">62.8</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Accuracy on WTQ test comparing OmniTab with baselines. Overall best results and best baseline results are in <span id="S4.T1.5.1" class="ltx_text ltx_font_bold">bold</span> and <em id="S4.T1.6.2" class="ltx_emph ltx_font_italic">italic</em> separately.</figcaption>
</figure>
<figure id="S4.F5" class="ltx_figure"><img src="/html/2207.03637/assets/x5.png" id="S4.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="196" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>WTQ test accuracy in all settings.</figcaption>
</figure>
</section>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Overall Results</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">The overall results comparing OmniTab with other baselines are listed in <a href="#S4.T1" title="Table 1 â€£ Implementation Details â€£ 4.1 Experimental Settings â€£ 4 Experiments â€£ OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Tab.Â 1</span></a>.
Across three few-shot settings, simulating low, medium, and high resource scenarios, pretraining on natural or synthetic data individually both outperform baselines significantly, and multitasking further increases the performance by a large margin.
OmniTab improves over the best baseline performance by 11.1%, 16.2%, and 6.4% across the three settings, clearly demonstrating that pretraining on natural sentences relevant to tables and synthetic questions provides OmniTab with a stronger capacity to align text and tables and perform reasoning.
The two types of data are complementary to each other, which we will analyze in detail in <a href="#S4.SS4" title="4.4 Analysis â€£ 4 Experiments â€£ OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Â§Â 4.4</span></a>.
Despite the fact that we focus on the few-shot setting, we also observe significant improvements of 2.7% on the full setting, establishing a new state-of-the-art on WTQ.
The performance in all few-shot/full settings shown in <a href="#S4.F5" title="Figure 5 â€£ Implementation Details â€£ 4.1 Experimental Settings â€£ 4 Experiments â€£ OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Fig.Â 5</span></a> clearly indicates the superiority of OmniTab across the whole spectrum.
The improvement is larger when annotations are fewer, indicating the value of pretraining especially when fewer annotations are available.
We also observe improvements on WikiSQL as shown in <a href="#S4.T2" title="Table 2 â€£ 4.2 Overall Results â€£ 4 Experiments â€£ OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Tab.Â 2</span></a>, reinforcing the effectiveness of our methods.</p>
</div>
<figure id="S4.T2" class="ltx_table">
<table id="S4.T2.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T2.1.1" class="ltx_tr">
<th id="S4.T2.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt"><span id="S4.T2.1.1.1.1" class="ltx_text ltx_font_bold">Model  <math id="S4.T2.1.1.1.1.m1.1" class="ltx_Math" alttext="f" display="inline"><semantics id="S4.T2.1.1.1.1.m1.1a"><mi id="S4.T2.1.1.1.1.m1.1.1" xref="S4.T2.1.1.1.1.m1.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="S4.T2.1.1.1.1.m1.1b"><ci id="S4.T2.1.1.1.1.m1.1.1.cmml" xref="S4.T2.1.1.1.1.m1.1.1">ğ‘“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.1.1.1.1.m1.1c">f</annotation></semantics></math>-shot:</span></th>
<th id="S4.T2.1.1.2" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt"><span id="S4.T2.1.1.2.1" class="ltx_text ltx_font_bold">16</span></th>
<th id="S4.T2.1.1.3" class="ltx_td ltx_nopad_l ltx_align_right ltx_th ltx_th_column ltx_border_tt"><span id="S4.T2.1.1.3.1" class="ltx_text ltx_font_bold">128</span></th>
<th id="S4.T2.1.1.4" class="ltx_td ltx_nopad_l ltx_align_right ltx_th ltx_th_column ltx_border_tt"><span id="S4.T2.1.1.4.1" class="ltx_text ltx_font_bold">1024</span></th>
<th id="S4.T2.1.1.5" class="ltx_td ltx_nopad_l ltx_align_right ltx_th ltx_th_column ltx_border_tt"><span id="S4.T2.1.1.5.1" class="ltx_text ltx_font_bold">full</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T2.2.2" class="ltx_tr">
<th id="S4.T2.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">TAPEX<sup id="S4.T2.2.2.1.1" class="ltx_sup">âˆ—</sup>
</th>
<td id="S4.T2.2.2.2" class="ltx_td ltx_align_right ltx_border_t">43.4</td>
<td id="S4.T2.2.2.3" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t">63.6</td>
<td id="S4.T2.2.2.4" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t">75.6</td>
<td id="S4.T2.2.2.5" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t">88.1</td>
</tr>
<tr id="S4.T2.2.3.1" class="ltx_tr">
<th id="S4.T2.2.3.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">OmniTab</th>
<td id="S4.T2.2.3.1.2" class="ltx_td ltx_align_right ltx_border_bb"><span id="S4.T2.2.3.1.2.1" class="ltx_text ltx_font_bold">63.6</span></td>
<td id="S4.T2.2.3.1.3" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb"><span id="S4.T2.2.3.1.3.1" class="ltx_text ltx_font_bold">75.6</span></td>
<td id="S4.T2.2.3.1.4" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb"><span id="S4.T2.2.3.1.4.1" class="ltx_text ltx_font_bold">82.9</span></td>
<td id="S4.T2.2.3.1.5" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb"><span id="S4.T2.2.3.1.5.1" class="ltx_text ltx_font_bold">88.7</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Accuracy on WikiSQL test.</figcaption>
</figure>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Ablation Study</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">Next, we study the contribution of individual components, including different retrieval methods, masking strategies, self-training methods, and varying the number of training pairs.</p>
</div>
<section id="S4.SS3.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Comparison of Different Retrieval Methods</h5>

<div id="S4.SS3.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS3.SSS0.Px1.p1.1" class="ltx_p">Our first ablation concerns the influence of different retrieval methods on the final performance.
We examined three retrieval methods to pair tables with a relevant sentence, including string-based matching, BM25, and dense retrieval (<a href="#S3.SS1" title="3.1 NL-Table Alignment Through Retrieval â€£ 3 OmniTab: Pretraining with Natural and Synthetic Data â€£ OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Â§Â 3.1</span></a>), as summarized in <a href="#S4.T3" title="Table 3 â€£ Comparison of Different Retrieval Methods â€£ 4.3 Ablation Study â€£ 4 Experiments â€£ OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Tab.Â 3</span></a>.
We also add a baseline (title-based heuristic) that pairs a table with the caption, article title, and description used by <cite class="ltx_cite ltx_citemacro_citet">Herzig etÂ al. (<a href="#bib.bib8" title="" class="ltx_ref">2020</a>)</cite> to validate the utility of retrieval.
(1) Our three retrieval methods usually perform better than the title-based heuristic, indicating that retrieving sentences based on the table content is better than fixed heuristics that always pair a table with pre-specified content.
(2) By comparing two string-based matching variants, we found that selecting the sentence with the maximal number of mentions is better than sentences with minimal overlap,<span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span>Average #mentions for max and min are 2.0 vs 1.2.</span></span></span> confirming our intuition that sentences more aligned with the table enable models to learn better alignment.
(3) BM25 performs similarly to string-based matching, partially because we still rely on string-based matching to locate mentions after BM25 returns a similar sentence.
(4) Dense retrieval with threshold <math id="S4.SS3.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="\tau=0.6" display="inline"><semantics id="S4.SS3.SSS0.Px1.p1.1.m1.1a"><mrow id="S4.SS3.SSS0.Px1.p1.1.m1.1.1" xref="S4.SS3.SSS0.Px1.p1.1.m1.1.1.cmml"><mi id="S4.SS3.SSS0.Px1.p1.1.m1.1.1.2" xref="S4.SS3.SSS0.Px1.p1.1.m1.1.1.2.cmml">Ï„</mi><mo id="S4.SS3.SSS0.Px1.p1.1.m1.1.1.1" xref="S4.SS3.SSS0.Px1.p1.1.m1.1.1.1.cmml">=</mo><mn id="S4.SS3.SSS0.Px1.p1.1.m1.1.1.3" xref="S4.SS3.SSS0.Px1.p1.1.m1.1.1.3.cmml">0.6</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px1.p1.1.m1.1b"><apply id="S4.SS3.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S4.SS3.SSS0.Px1.p1.1.m1.1.1"><eq id="S4.SS3.SSS0.Px1.p1.1.m1.1.1.1.cmml" xref="S4.SS3.SSS0.Px1.p1.1.m1.1.1.1"></eq><ci id="S4.SS3.SSS0.Px1.p1.1.m1.1.1.2.cmml" xref="S4.SS3.SSS0.Px1.p1.1.m1.1.1.2">ğœ</ci><cn type="float" id="S4.SS3.SSS0.Px1.p1.1.m1.1.1.3.cmml" xref="S4.SS3.SSS0.Px1.p1.1.m1.1.1.3">0.6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px1.p1.1.m1.1c">\tau=0.6</annotation></semantics></math> achieves the best overall performance, but it is relatively sensitive to the threshold.
A high threshold only keeps highly relevant phrase-cell pairs, while a low threshold can discover more partial matches for masked pretraining, leading to a trade-off between quality and quantity.
Given that this initial attempt to use dense retrieval for text-table alignment directly uses BART without further tuning, further advances in retriever could likely improve this trade-off.</p>
</div>
<figure id="S4.T3" class="ltx_table">
<table id="S4.T3.5" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T3.1.1" class="ltx_tr">
<th id="S4.T3.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt"><span id="S4.T3.1.1.2.1" class="ltx_text ltx_font_bold">Model</span></th>
<th id="S4.T3.1.1.1" class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt">
<math id="S4.T3.1.1.1.m1.1" class="ltx_Math" alttext="f" display="inline"><semantics id="S4.T3.1.1.1.m1.1a"><mi id="S4.T3.1.1.1.m1.1.1" xref="S4.T3.1.1.1.m1.1.1.cmml">f</mi><annotation-xml encoding="MathML-Content" id="S4.T3.1.1.1.m1.1b"><ci id="S4.T3.1.1.1.m1.1.1.cmml" xref="S4.T3.1.1.1.m1.1.1">ğ‘“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.1.1.1.m1.1c">f</annotation></semantics></math><span id="S4.T3.1.1.1.1" class="ltx_text ltx_font_bold">-shot:</span>
</th>
<th id="S4.T3.1.1.3" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt"><span id="S4.T3.1.1.3.1" class="ltx_text ltx_font_bold">16</span></th>
<th id="S4.T3.1.1.4" class="ltx_td ltx_nopad_l ltx_align_right ltx_th ltx_th_column ltx_border_tt"><span id="S4.T3.1.1.4.1" class="ltx_text ltx_font_bold">128</span></th>
<th id="S4.T3.1.1.5" class="ltx_td ltx_nopad_l ltx_align_right ltx_th ltx_th_column ltx_border_tt"><span id="S4.T3.1.1.5.1" class="ltx_text ltx_font_bold">1024</span></th>
</tr>
<tr id="S4.T3.5.6.1" class="ltx_tr">
<th id="S4.T3.5.6.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t" colspan="2">TAPEX <cite class="ltx_cite ltx_citemacro_cite">Liu etÂ al. (<a href="#bib.bib16" title="" class="ltx_ref">2021</a>)</cite>
</th>
<th id="S4.T3.5.6.1.2" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t">10.4</th>
<th id="S4.T3.5.6.1.3" class="ltx_td ltx_nopad_l ltx_align_right ltx_th ltx_th_column ltx_border_t">23.1</th>
<th id="S4.T3.5.6.1.4" class="ltx_td ltx_nopad_l ltx_align_right ltx_th ltx_th_column ltx_border_t">45.5</th>
</tr>
<tr id="S4.T3.5.7.2" class="ltx_tr">
<th id="S4.T3.5.7.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_t" colspan="5"><em id="S4.T3.5.7.2.1.1" class="ltx_emph ltx_font_italic">OmniTab w/ natural data obtained by</em></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T3.5.8.1" class="ltx_tr">
<th id="S4.T3.5.8.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" colspan="2">title-based heuristic</th>
<td id="S4.T3.5.8.1.2" class="ltx_td ltx_align_right">21.5</td>
<td id="S4.T3.5.8.1.3" class="ltx_td ltx_nopad_l ltx_align_right">34.2</td>
<td id="S4.T3.5.8.1.4" class="ltx_td ltx_nopad_l ltx_align_right">48.4</td>
</tr>
<tr id="S4.T3.5.9.2" class="ltx_tr">
<th id="S4.T3.5.9.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><em id="S4.T3.5.9.2.1.1" class="ltx_emph ltx_font_italic">retrieval method</em></th>
<th id="S4.T3.5.9.2.2" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row"><em id="S4.T3.5.9.2.2.1" class="ltx_emph ltx_font_italic">other option</em></th>
<td id="S4.T3.5.9.2.3" class="ltx_td"></td>
<td id="S4.T3.5.9.2.4" class="ltx_td"></td>
<td id="S4.T3.5.9.2.5" class="ltx_td"></td>
</tr>
<tr id="S4.T3.5.10.3" class="ltx_tr">
<th id="S4.T3.5.10.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" rowspan="2"><span id="S4.T3.5.10.3.1.1" class="ltx_text">string-based</span></th>
<th id="S4.T3.5.10.3.2" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row">(min)</th>
<td id="S4.T3.5.10.3.3" class="ltx_td ltx_align_right">23.3</td>
<td id="S4.T3.5.10.3.4" class="ltx_td ltx_nopad_l ltx_align_right">35.5</td>
<td id="S4.T3.5.10.3.5" class="ltx_td ltx_nopad_l ltx_align_right">47.5</td>
</tr>
<tr id="S4.T3.5.11.4" class="ltx_tr">
<th id="S4.T3.5.11.4.1" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row">(max)</th>
<td id="S4.T3.5.11.4.2" class="ltx_td ltx_align_right"><span id="S4.T3.5.11.4.2.1" class="ltx_text ltx_font_bold">24.2</span></td>
<td id="S4.T3.5.11.4.3" class="ltx_td ltx_nopad_l ltx_align_right">36.7</td>
<td id="S4.T3.5.11.4.4" class="ltx_td ltx_nopad_l ltx_align_right">49.2</td>
</tr>
<tr id="S4.T3.5.12.5" class="ltx_tr">
<th id="S4.T3.5.12.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" colspan="2">BM25</th>
<td id="S4.T3.5.12.5.2" class="ltx_td ltx_align_right">23.8</td>
<td id="S4.T3.5.12.5.3" class="ltx_td ltx_nopad_l ltx_align_right">36.4</td>
<td id="S4.T3.5.12.5.4" class="ltx_td ltx_nopad_l ltx_align_right">49.1</td>
</tr>
<tr id="S4.T3.2.2" class="ltx_tr">
<th id="S4.T3.2.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_row" rowspan="3"><span id="S4.T3.2.2.2.1" class="ltx_text"><span id="S4.T3.2.2.2.1.1" class="ltx_text ltx_framed ltx_framed_underline">dense retrieval</span></span></th>
<th id="S4.T3.2.2.1" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row">(<math id="S4.T3.2.2.1.m1.1" class="ltx_Math" alttext="\tau=0.5" display="inline"><semantics id="S4.T3.2.2.1.m1.1a"><mrow id="S4.T3.2.2.1.m1.1.1" xref="S4.T3.2.2.1.m1.1.1.cmml"><mi id="S4.T3.2.2.1.m1.1.1.2" xref="S4.T3.2.2.1.m1.1.1.2.cmml">Ï„</mi><mo id="S4.T3.2.2.1.m1.1.1.1" xref="S4.T3.2.2.1.m1.1.1.1.cmml">=</mo><mn id="S4.T3.2.2.1.m1.1.1.3" xref="S4.T3.2.2.1.m1.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.2.2.1.m1.1b"><apply id="S4.T3.2.2.1.m1.1.1.cmml" xref="S4.T3.2.2.1.m1.1.1"><eq id="S4.T3.2.2.1.m1.1.1.1.cmml" xref="S4.T3.2.2.1.m1.1.1.1"></eq><ci id="S4.T3.2.2.1.m1.1.1.2.cmml" xref="S4.T3.2.2.1.m1.1.1.2">ğœ</ci><cn type="float" id="S4.T3.2.2.1.m1.1.1.3.cmml" xref="S4.T3.2.2.1.m1.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.2.2.1.m1.1c">\tau=0.5</annotation></semantics></math>)</th>
<td id="S4.T3.2.2.3" class="ltx_td ltx_align_right">22.7</td>
<td id="S4.T3.2.2.4" class="ltx_td ltx_nopad_l ltx_align_right">35.9</td>
<td id="S4.T3.2.2.5" class="ltx_td ltx_nopad_l ltx_align_right">48.4</td>
</tr>
<tr id="S4.T3.3.3" class="ltx_tr">
<th id="S4.T3.3.3.1" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row">(<math id="S4.T3.3.3.1.m1.1" class="ltx_Math" alttext="\tau=0.7" display="inline"><semantics id="S4.T3.3.3.1.m1.1a"><mrow id="S4.T3.3.3.1.m1.1.1" xref="S4.T3.3.3.1.m1.1.1.cmml"><mi id="S4.T3.3.3.1.m1.1.1.2" xref="S4.T3.3.3.1.m1.1.1.2.cmml">Ï„</mi><mo id="S4.T3.3.3.1.m1.1.1.1" xref="S4.T3.3.3.1.m1.1.1.1.cmml">=</mo><mn id="S4.T3.3.3.1.m1.1.1.3" xref="S4.T3.3.3.1.m1.1.1.3.cmml">0.7</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.3.3.1.m1.1b"><apply id="S4.T3.3.3.1.m1.1.1.cmml" xref="S4.T3.3.3.1.m1.1.1"><eq id="S4.T3.3.3.1.m1.1.1.1.cmml" xref="S4.T3.3.3.1.m1.1.1.1"></eq><ci id="S4.T3.3.3.1.m1.1.1.2.cmml" xref="S4.T3.3.3.1.m1.1.1.2">ğœ</ci><cn type="float" id="S4.T3.3.3.1.m1.1.1.3.cmml" xref="S4.T3.3.3.1.m1.1.1.3">0.7</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.3.3.1.m1.1c">\tau=0.7</annotation></semantics></math>)</th>
<td id="S4.T3.3.3.2" class="ltx_td ltx_align_right">19.8</td>
<td id="S4.T3.3.3.3" class="ltx_td ltx_nopad_l ltx_align_right">36.8</td>
<td id="S4.T3.3.3.4" class="ltx_td ltx_nopad_l ltx_align_right">48.2</td>
</tr>
<tr id="S4.T3.4.4" class="ltx_tr">
<th id="S4.T3.4.4.1" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row"><span id="S4.T3.4.4.1.1" class="ltx_text ltx_framed ltx_framed_underline">(<math id="S4.T3.4.4.1.1.m1.1" class="ltx_Math" alttext="\tau=0.6" display="inline"><semantics id="S4.T3.4.4.1.1.m1.1a"><mrow id="S4.T3.4.4.1.1.m1.1.1" xref="S4.T3.4.4.1.1.m1.1.1.cmml"><mi id="S4.T3.4.4.1.1.m1.1.1.2" xref="S4.T3.4.4.1.1.m1.1.1.2.cmml">Ï„</mi><mo id="S4.T3.4.4.1.1.m1.1.1.1" xref="S4.T3.4.4.1.1.m1.1.1.1.cmml">=</mo><mn id="S4.T3.4.4.1.1.m1.1.1.3" xref="S4.T3.4.4.1.1.m1.1.1.3.cmml">0.6</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.4.4.1.1.m1.1b"><apply id="S4.T3.4.4.1.1.m1.1.1.cmml" xref="S4.T3.4.4.1.1.m1.1.1"><eq id="S4.T3.4.4.1.1.m1.1.1.1.cmml" xref="S4.T3.4.4.1.1.m1.1.1.1"></eq><ci id="S4.T3.4.4.1.1.m1.1.1.2.cmml" xref="S4.T3.4.4.1.1.m1.1.1.2">ğœ</ci><cn type="float" id="S4.T3.4.4.1.1.m1.1.1.3.cmml" xref="S4.T3.4.4.1.1.m1.1.1.3">0.6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.4.4.1.1.m1.1c">\tau=0.6</annotation></semantics></math>)</span></th>
<td id="S4.T3.4.4.2" class="ltx_td ltx_align_right">22.8</td>
<td id="S4.T3.4.4.3" class="ltx_td ltx_nopad_l ltx_align_right"><span id="S4.T3.4.4.3.1" class="ltx_text ltx_font_bold">38.4</span></td>
<td id="S4.T3.4.4.4" class="ltx_td ltx_nopad_l ltx_align_right"><span id="S4.T3.4.4.4.1" class="ltx_text ltx_font_bold">49.8</span></td>
</tr>
<tr id="S4.T3.5.5" class="ltx_tr">
<th id="S4.T3.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" rowspan="2"><span id="S4.T3.5.5.1.1" class="ltx_text">
<span id="S4.T3.5.5.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T3.5.5.1.1.1.2" class="ltx_tr">
<span id="S4.T3.5.5.1.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">dense retrieval</span></span>
<span id="S4.T3.5.5.1.1.1.1" class="ltx_tr">
<span id="S4.T3.5.5.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">(<math id="S4.T3.5.5.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\tau=0.6" display="inline"><semantics id="S4.T3.5.5.1.1.1.1.1.m1.1a"><mrow id="S4.T3.5.5.1.1.1.1.1.m1.1.1" xref="S4.T3.5.5.1.1.1.1.1.m1.1.1.cmml"><mi id="S4.T3.5.5.1.1.1.1.1.m1.1.1.2" xref="S4.T3.5.5.1.1.1.1.1.m1.1.1.2.cmml">Ï„</mi><mo id="S4.T3.5.5.1.1.1.1.1.m1.1.1.1" xref="S4.T3.5.5.1.1.1.1.1.m1.1.1.1.cmml">=</mo><mn id="S4.T3.5.5.1.1.1.1.1.m1.1.1.3" xref="S4.T3.5.5.1.1.1.1.1.m1.1.1.3.cmml">0.6</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.5.5.1.1.1.1.1.m1.1b"><apply id="S4.T3.5.5.1.1.1.1.1.m1.1.1.cmml" xref="S4.T3.5.5.1.1.1.1.1.m1.1.1"><eq id="S4.T3.5.5.1.1.1.1.1.m1.1.1.1.cmml" xref="S4.T3.5.5.1.1.1.1.1.m1.1.1.1"></eq><ci id="S4.T3.5.5.1.1.1.1.1.m1.1.1.2.cmml" xref="S4.T3.5.5.1.1.1.1.1.m1.1.1.2">ğœ</ci><cn type="float" id="S4.T3.5.5.1.1.1.1.1.m1.1.1.3.cmml" xref="S4.T3.5.5.1.1.1.1.1.m1.1.1.3">0.6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.5.5.1.1.1.1.1.m1.1c">\tau=0.6</annotation></semantics></math>)</span></span>
</span></span></th>
<th id="S4.T3.5.5.2" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row ltx_border_t">w/o salient mask</th>
<td id="S4.T3.5.5.3" class="ltx_td ltx_align_right ltx_border_t">17.5</td>
<td id="S4.T3.5.5.4" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t">33.6</td>
<td id="S4.T3.5.5.5" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t">47.1</td>
</tr>
<tr id="S4.T3.5.13.6" class="ltx_tr">
<th id="S4.T3.5.13.6.1" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row ltx_border_bb">w/o random mask</th>
<td id="S4.T3.5.13.6.2" class="ltx_td ltx_align_right ltx_border_bb">23.1</td>
<td id="S4.T3.5.13.6.3" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb">37.8</td>
<td id="S4.T3.5.13.6.4" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb">48.5</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>WTQ test accuracy when pretraining on natural data obtained by different retrieval methods, and using two masking strategies separately. Design choices used in our final model are <span id="S4.T3.7.1" class="ltx_text ltx_framed ltx_framed_underline">underlined</span>.</figcaption>
</figure>
</section>
<section id="S4.SS3.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Random Masking vs. Salient Masking</h5>

<div id="S4.SS3.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS3.SSS0.Px2.p1.1" class="ltx_p">We use both salient mention masking that only masks mentions of cells in the sentence and random masking in our final model.
To examine the contribution of each masking strategy, we remove one masking strategy from the underlined model at the bottom of <a href="#S4.T3" title="Table 3 â€£ Comparison of Different Retrieval Methods â€£ 4.3 Ablation Study â€£ 4 Experiments â€£ OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Tab.Â 3</span></a>.
It is clear that both maskings help, with salient masking being the major contributor, which indicates that masking tokens indicative of alignment is more effective than aimless masking.</p>
</div>
</section>
<section id="S4.SS3.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Comparison of Different Self-training Methods</h5>

<div id="S4.SS3.SSS0.Px3.p1" class="ltx_para">
<p id="S4.SS3.SSS0.Px3.p1.1" class="ltx_p">To study which element is crucial in self-training, we perform ablations to study various aspects of self-training including (1) selection criterion for questions (generation- vs verification-based) and (2) models used for verification (BART vs OmniTab) by comparing all variants under the same setting of 128 annotated SQL-NL.
As summarized in <a href="#S4.T4" title="Table 4 â€£ Comparison of Different Self-training Methods â€£ 4.3 Ablation Study â€£ 4 Experiments â€£ OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Tab.Â 4</span></a>, self-training on selected questions with the highest generation probabilities given by the SQL2NL model does not improve over the baseline without self-training, which is mainly because the SQL2NL model is too weak to output reliable generation probabilities.
However, our method that selects questions with the highest probabilities to elicit answers from OmniTab (last line) improve over no self-training by a large margin (4.3%, 2.5%, and 1.8%), validating the idea of leveraging the strong QA capacity of OmniTab to assess the quality of generated questions.
To confirm the source of success, we perform a sanity check that selects sentences most <em id="S4.SS3.SSS0.Px3.p1.1.1" class="ltx_emph ltx_font_italic">unlikely</em> to elicit answers (min), and the performance indeed becomes much lower.
We also replace OmniTab with BART that is only finetuned with 128 annotations, and the performance is significantly lower, confirming that stronger QA models can provide a better assessment.</p>
</div>
<figure id="S4.T4" class="ltx_table">
<table id="S4.T4.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T4.1.1.1" class="ltx_tr">
<th id="S4.T4.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" colspan="3">
<span id="S4.T4.1.1.1.1.1" class="ltx_text ltx_font_bold">Model</span>  <span id="S4.T4.1.1.1.1.2" class="ltx_text ltx_font_bold">WTQ-</span>
</th>
<th id="S4.T4.1.1.1.2" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt"><span id="S4.T4.1.1.1.2.1" class="ltx_text ltx_font_bold">16</span></th>
<th id="S4.T4.1.1.1.3" class="ltx_td ltx_nopad_l ltx_align_right ltx_th ltx_th_column ltx_border_tt"><span id="S4.T4.1.1.1.3.1" class="ltx_text ltx_font_bold">128</span></th>
<th id="S4.T4.1.1.1.4" class="ltx_td ltx_nopad_l ltx_align_right ltx_th ltx_th_column ltx_border_tt"><span id="S4.T4.1.1.1.4.1" class="ltx_text ltx_font_bold">1024</span></th>
</tr>
<tr id="S4.T4.1.2.2" class="ltx_tr">
<th id="S4.T4.1.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t" colspan="3">TAPEX <cite class="ltx_cite ltx_citemacro_cite">Liu etÂ al. (<a href="#bib.bib16" title="" class="ltx_ref">2021</a>)</cite>
</th>
<th id="S4.T4.1.2.2.2" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t">10.4</th>
<th id="S4.T4.1.2.2.3" class="ltx_td ltx_nopad_l ltx_align_right ltx_th ltx_th_column ltx_border_t">23.1</th>
<th id="S4.T4.1.2.2.4" class="ltx_td ltx_nopad_l ltx_align_right ltx_th ltx_th_column ltx_border_t">45.5</th>
</tr>
<tr id="S4.T4.1.3.3" class="ltx_tr">
<th id="S4.T4.1.3.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="6"><em id="S4.T4.1.3.3.1.1" class="ltx_emph ltx_font_italic">OmniTab w/ synthetic data from SQL2NL trained</em></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T4.1.4.1" class="ltx_tr">
<th id="S4.T4.1.4.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><em id="S4.T4.1.4.1.1.1" class="ltx_emph ltx_font_italic">criteria</em></th>
<th id="S4.T4.1.4.1.2" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row"><em id="S4.T4.1.4.1.2.1" class="ltx_emph ltx_font_italic">op.</em></th>
<th id="S4.T4.1.4.1.3" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row"><em id="S4.T4.1.4.1.3.1" class="ltx_emph ltx_font_italic">verify</em></th>
<td id="S4.T4.1.4.1.4" class="ltx_td"></td>
<td id="S4.T4.1.4.1.5" class="ltx_td"></td>
<td id="S4.T4.1.4.1.6" class="ltx_td"></td>
</tr>
<tr id="S4.T4.1.5.2" class="ltx_tr">
<th id="S4.T4.1.5.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">w/o self-training</th>
<th id="S4.T4.1.5.2.2" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row">-</th>
<th id="S4.T4.1.5.2.3" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row">-</th>
<td id="S4.T4.1.5.2.4" class="ltx_td ltx_align_right">26.5</td>
<td id="S4.T4.1.5.2.5" class="ltx_td ltx_nopad_l ltx_align_right">35.0</td>
<td id="S4.T4.1.5.2.6" class="ltx_td ltx_nopad_l ltx_align_right">45.5</td>
</tr>
<tr id="S4.T4.1.6.3" class="ltx_tr">
<th id="S4.T4.1.6.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">w/ generation-based</th>
<th id="S4.T4.1.6.3.2" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row">max</th>
<th id="S4.T4.1.6.3.3" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row">-</th>
<td id="S4.T4.1.6.3.4" class="ltx_td ltx_align_right">24.0</td>
<td id="S4.T4.1.6.3.5" class="ltx_td ltx_nopad_l ltx_align_right">35.8</td>
<td id="S4.T4.1.6.3.6" class="ltx_td ltx_nopad_l ltx_align_right">44.3</td>
</tr>
<tr id="S4.T4.1.7.4" class="ltx_tr">
<th id="S4.T4.1.7.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" rowspan="3"><span id="S4.T4.1.7.4.1.1" class="ltx_text"><span id="S4.T4.1.7.4.1.1.1" class="ltx_text ltx_framed ltx_framed_underline">w/ verification-based</span></span></th>
<th id="S4.T4.1.7.4.2" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row">min</th>
<th id="S4.T4.1.7.4.3" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row">OmniTab</th>
<td id="S4.T4.1.7.4.4" class="ltx_td ltx_align_right">15.5</td>
<td id="S4.T4.1.7.4.5" class="ltx_td ltx_nopad_l ltx_align_right">27.4</td>
<td id="S4.T4.1.7.4.6" class="ltx_td ltx_nopad_l ltx_align_right">41.9</td>
</tr>
<tr id="S4.T4.1.8.5" class="ltx_tr">
<th id="S4.T4.1.8.5.1" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row">max</th>
<th id="S4.T4.1.8.5.2" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row">BART</th>
<td id="S4.T4.1.8.5.3" class="ltx_td ltx_align_right">28.9</td>
<td id="S4.T4.1.8.5.4" class="ltx_td ltx_nopad_l ltx_align_right">36.4</td>
<td id="S4.T4.1.8.5.5" class="ltx_td ltx_nopad_l ltx_align_right">45.4</td>
</tr>
<tr id="S4.T4.1.9.6" class="ltx_tr">
<th id="S4.T4.1.9.6.1" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row ltx_border_bb"><span id="S4.T4.1.9.6.1.1" class="ltx_text ltx_framed ltx_framed_underline">max</span></th>
<th id="S4.T4.1.9.6.2" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row ltx_border_bb"><span id="S4.T4.1.9.6.2.1" class="ltx_text ltx_framed ltx_framed_underline">OmniTab</span></th>
<td id="S4.T4.1.9.6.3" class="ltx_td ltx_align_right ltx_border_bb"><span id="S4.T4.1.9.6.3.1" class="ltx_text ltx_font_bold">30.8</span></td>
<td id="S4.T4.1.9.6.4" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb"><span id="S4.T4.1.9.6.4.1" class="ltx_text ltx_font_bold">37.5</span></td>
<td id="S4.T4.1.9.6.5" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb"><span id="S4.T4.1.9.6.5.1" class="ltx_text ltx_font_bold">47.3</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>WTQ test accuracy when pretraining on synthetic data generated from an SQL2NL model trained with 128 annotations and various self-training methods. Design choices used in our final model are <span id="S4.T4.3.1" class="ltx_text ltx_framed ltx_framed_underline">underlined</span>.</figcaption>
</figure>
<figure id="S4.F6" class="ltx_figure"><img src="/html/2207.03637/assets/x6.png" id="S4.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="172" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>WTQ test accuracy (128-shot) using different numbers of annotated and self-training SQL-NL pairs.</figcaption>
</figure>
</section>
<section id="S4.SS3.SSS0.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Performance w.r.t.Â Number of Annotated and Self-training Pairs</h5>

<div id="S4.SS3.SSS0.Px4.p1" class="ltx_para">
<p id="S4.SS3.SSS0.Px4.p1.1" class="ltx_p">Here we study the influence of increasing either annotated or self-training SQL-NL pairs.
We use the SQL2NL model trained with 128 annotated pairs as a starting point, and additionally using more annotated or self-training pairs.
As shown in <a href="#S4.F6" title="Figure 6 â€£ Comparison of Different Self-training Methods â€£ 4.3 Ablation Study â€£ 4 Experiments â€£ OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Fig.Â 6</span></a>, using more annotated or self-training pairs both improves over the initial performance of 35.0%.
However, the improvement due to self-training still falls far behind the supervised approach, demonstrating the challenge of learning a robust SQL2NL model with very few annotations.
The increasing trend of self-training suggests that further improvements may be provided by using more pairs in self-training.</p>
</div>
<figure id="S4.T5" class="ltx_table">
<table id="S4.T5.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T5.1.1.1" class="ltx_tr">
<th id="S4.T5.1.1.1.1" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_th_row ltx_border_tt"><span id="S4.T5.1.1.1.1.1" class="ltx_text ltx_font_bold">Cases favoring:</span></th>
<th id="S4.T5.1.1.1.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T5.1.1.1.2.1" class="ltx_text ltx_font_bold">Natural</span></th>
<th id="S4.T5.1.1.1.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T5.1.1.1.3.1" class="ltx_text ltx_font_bold">Synthetic</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T5.1.2.1" class="ltx_tr">
<th id="S4.T5.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Avg #tok in questions / SQL</th>
<td id="S4.T5.1.2.1.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t">10.6 / 11.4</td>
<td id="S4.T5.1.2.1.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t">10.8 / <span id="S4.T5.1.2.1.3.1" class="ltx_text ltx_font_bold">12.9</span>
</td>
</tr>
<tr id="S4.T5.1.3.2" class="ltx_tr">
<th id="S4.T5.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">Avg #aligned question tok with tables</th>
<td id="S4.T5.1.3.2.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb"><span id="S4.T5.1.3.2.2.1" class="ltx_text ltx_font_bold">1.8</span></td>
<td id="S4.T5.1.3.2.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb">1.0</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>Statistics of cases favoring natural vs synthetic data. Numbers indicating advantages are in <span id="S4.T5.3.1" class="ltx_text ltx_font_bold">bold</span>.</figcaption>
</figure>
<figure id="S4.F7" class="ltx_figure"><img src="/html/2207.03637/assets/x7.png" id="S4.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="165" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Frequent SQL keywords in cases favoring natural vs synthetic data. Keywords with a large frequency difference are annotated with frequencies.</figcaption>
</figure>
</section>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Analysis</h3>

<section id="S4.SS4.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Roles of Natural and Synthetic Data</h5>

<div id="S4.SS4.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS4.SSS0.Px1.p1.1" class="ltx_p">We quantitatively verified using the multitasking experiment that natural and synthetic are complementary to each other, with the hypothetical reason that natural data excels at enhancing alignment while synthetic data is more targeted on endowing reasoning capabilities.
Our analysis on cases where natural pretraining succeeds but synthetic fails and the opposite cases confirms that this is <em id="S4.SS4.SSS0.Px1.p1.1.1" class="ltx_emph ltx_font_italic">indeed</em> the case.
Enabled by the fine-grained annotation in SQUALL <cite class="ltx_cite ltx_citemacro_cite">Shi etÂ al. (<a href="#bib.bib22" title="" class="ltx_ref">2020</a>)</cite>, we compare OmniTab trained on natural or synthetic data separately in the 128-shot setting, and study on the two groups of cases in the development set of WikiTableQuestions.
Based on 309/315 cases favoring natural/synthetic pretraining, we witness a clear distinction on the average number of question tokens aligned with tables between the two groups in <a href="#S4.T5" title="Table 5 â€£ Performance w.r.t. Number of Annotated and Self-training Pairs â€£ 4.3 Ablation Study â€£ 4 Experiments â€£ OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Tab.Â 5</span></a>, indicating that natural data is indeed more targeted at addressing the alignment across formats.
We also compute the frequency of each SQL keyword for the two contrasting groups of cases. As shown in <a href="#S4.F7" title="Figure 7 â€£ Performance w.r.t. Number of Annotated and Self-training Pairs â€£ 4.3 Ablation Study â€£ 4 Experiments â€£ OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Fig.Â 7</span></a>, cases favoring synthetic data indeed involves reasoning-rich keywords more frequently, such as â€œwhere = ( )â€ which are often used in nested queries, and â€œcount * idâ€ which are often used in aggregation.</p>
</div>
</section>
<section id="S4.SS4.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Performance under Topical Distributional Shift</h5>

<div id="S4.SS4.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS4.SSS0.Px2.p1.1" class="ltx_p">Last, we analyze the robustness of OmniTab under topical distributional shift on WTQ-TS, which splits WTQ into five topics.
We finetune OmniTab on one topic (128-shot) and test the resulting model on all five topics.
As indicated by <a href="#S4.T6" title="Table 6 â€£ Performance under Topical Distributional Shift â€£ 4.4 Analysis â€£ 4 Experiments â€£ OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Tab.Â 6</span></a>, OmniTab outperforms TAPEX by a large margin across all topics, validating the robustness of our methods under topical shift.</p>
</div>
<figure id="S4.T6" class="ltx_table">
<table id="S4.T6.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T6.1.1.1" class="ltx_tr">
<th id="S4.T6.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt"><span id="S4.T6.1.1.1.1.1" class="ltx_text ltx_font_bold">Train/test</span></th>
<th id="S4.T6.1.1.1.2" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt"><span id="S4.T6.1.1.1.2.1" class="ltx_text ltx_font_bold">Sports</span></th>
<th id="S4.T6.1.1.1.3" class="ltx_td ltx_nopad_l ltx_align_right ltx_th ltx_th_column ltx_border_tt"><span id="S4.T6.1.1.1.3.1" class="ltx_text ltx_font_bold">Culture</span></th>
<th id="S4.T6.1.1.1.4" class="ltx_td ltx_nopad_l ltx_align_right ltx_th ltx_th_column ltx_border_tt"><span id="S4.T6.1.1.1.4.1" class="ltx_text ltx_font_bold">People</span></th>
<th id="S4.T6.1.1.1.5" class="ltx_td ltx_nopad_l ltx_align_right ltx_th ltx_th_column ltx_border_tt"><span id="S4.T6.1.1.1.5.1" class="ltx_text ltx_font_bold">Politics</span></th>
<th id="S4.T6.1.1.1.6" class="ltx_td ltx_nopad_l ltx_align_right ltx_th ltx_th_column ltx_border_tt"><span id="S4.T6.1.1.1.6.1" class="ltx_text ltx_font_bold">Misc</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T6.1.2.1" class="ltx_tr">
<th id="S4.T6.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><span id="S4.T6.1.2.1.1.1" class="ltx_text ltx_font_bold">Sports</span></th>
<td id="S4.T6.1.2.1.2" class="ltx_td ltx_align_right ltx_border_t">+16.3</td>
<td id="S4.T6.1.2.1.3" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t">+14.1</td>
<td id="S4.T6.1.2.1.4" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t">+15.8</td>
<td id="S4.T6.1.2.1.5" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t">+14.4</td>
<td id="S4.T6.1.2.1.6" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t">+18.8</td>
</tr>
<tr id="S4.T6.1.3.2" class="ltx_tr">
<th id="S4.T6.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T6.1.3.2.1.1" class="ltx_text ltx_font_bold">Culture</span></th>
<td id="S4.T6.1.3.2.2" class="ltx_td ltx_align_right">+13.9</td>
<td id="S4.T6.1.3.2.3" class="ltx_td ltx_nopad_l ltx_align_right">+12.7</td>
<td id="S4.T6.1.3.2.4" class="ltx_td ltx_nopad_l ltx_align_right">+14.3</td>
<td id="S4.T6.1.3.2.5" class="ltx_td ltx_nopad_l ltx_align_right">+13.0</td>
<td id="S4.T6.1.3.2.6" class="ltx_td ltx_nopad_l ltx_align_right">+10.3</td>
</tr>
<tr id="S4.T6.1.4.3" class="ltx_tr">
<th id="S4.T6.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T6.1.4.3.1.1" class="ltx_text ltx_font_bold">People</span></th>
<td id="S4.T6.1.4.3.2" class="ltx_td ltx_align_right">+21.5</td>
<td id="S4.T6.1.4.3.3" class="ltx_td ltx_nopad_l ltx_align_right">+14.6</td>
<td id="S4.T6.1.4.3.4" class="ltx_td ltx_nopad_l ltx_align_right">+20.6</td>
<td id="S4.T6.1.4.3.5" class="ltx_td ltx_nopad_l ltx_align_right">+14.6</td>
<td id="S4.T6.1.4.3.6" class="ltx_td ltx_nopad_l ltx_align_right">+17.5</td>
</tr>
<tr id="S4.T6.1.5.4" class="ltx_tr">
<th id="S4.T6.1.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T6.1.5.4.1.1" class="ltx_text ltx_font_bold">Politics</span></th>
<td id="S4.T6.1.5.4.2" class="ltx_td ltx_align_right">+18.5</td>
<td id="S4.T6.1.5.4.3" class="ltx_td ltx_nopad_l ltx_align_right">+14.3</td>
<td id="S4.T6.1.5.4.4" class="ltx_td ltx_nopad_l ltx_align_right">+17.8</td>
<td id="S4.T6.1.5.4.5" class="ltx_td ltx_nopad_l ltx_align_right">+16.0</td>
<td id="S4.T6.1.5.4.6" class="ltx_td ltx_nopad_l ltx_align_right">+13.5</td>
</tr>
<tr id="S4.T6.1.6.5" class="ltx_tr">
<th id="S4.T6.1.6.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb"><span id="S4.T6.1.6.5.1.1" class="ltx_text ltx_font_bold">Misc</span></th>
<td id="S4.T6.1.6.5.2" class="ltx_td ltx_align_right ltx_border_bb">+18.3</td>
<td id="S4.T6.1.6.5.3" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb">+14.7</td>
<td id="S4.T6.1.6.5.4" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb">+17.2</td>
<td id="S4.T6.1.6.5.5" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb">+14.6</td>
<td id="S4.T6.1.6.5.6" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb">+14.9</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6: </span>Accuracy gain (128-shot) of OmniTab over TAPEX when finetuned on one topic and tested on all.</figcaption>
</figure>
</section>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Related Work</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">Table-based QA is a well-studied area from early systems using structured queries as intermediate steps <cite class="ltx_cite ltx_citemacro_cite">Krishnamurthy etÂ al. (<a href="#bib.bib12" title="" class="ltx_ref">2017</a>); Liang etÂ al. (<a href="#bib.bib15" title="" class="ltx_ref">2018</a>); Wang etÂ al. (<a href="#bib.bib23" title="" class="ltx_ref">2019</a>); Yin etÂ al. (<a href="#bib.bib25" title="" class="ltx_ref">2020</a>); Yu etÂ al. (<a href="#bib.bib26" title="" class="ltx_ref">2021</a>)</cite> to recent advances that generate answers in an end2end fashion <cite class="ltx_cite ltx_citemacro_cite">Herzig etÂ al. (<a href="#bib.bib8" title="" class="ltx_ref">2020</a>); Liu etÂ al. (<a href="#bib.bib16" title="" class="ltx_ref">2021</a>)</cite>.
Our methods follow the end2end approach because of its modeling simplicity and higher flexibility.
Given large amounts of table and text on the web, table-based QA and other table-related tasks such as semantic parsing <cite class="ltx_cite ltx_citemacro_cite">Deng etÂ al. (<a href="#bib.bib2" title="" class="ltx_ref">2021</a>); Shi etÂ al. (<a href="#bib.bib21" title="" class="ltx_ref">2021</a>)</cite> and table understanding <cite class="ltx_cite ltx_citemacro_cite">Deng etÂ al. (<a href="#bib.bib3" title="" class="ltx_ref">2020</a>); Wang etÂ al. (<a href="#bib.bib24" title="" class="ltx_ref">2021</a>)</cite> start witnessing efforts invested in pretraining on both structured and unstructured information.
Most works leveraging retrieval to find relevant information to assist pretraining are designed for text format only <cite class="ltx_cite ltx_citemacro_cite">Guu etÂ al. (<a href="#bib.bib6" title="" class="ltx_ref">2020</a>); Lewis etÂ al. (<a href="#bib.bib13" title="" class="ltx_ref">2020a</a>)</cite>, while the majority of table-based pretraining still use alignment heuristics <cite class="ltx_cite ltx_citemacro_cite">Herzig etÂ al. (<a href="#bib.bib8" title="" class="ltx_ref">2020</a>); Yin etÂ al. (<a href="#bib.bib25" title="" class="ltx_ref">2020</a>)</cite>.
There are some initial attempts to perform retrieval over tables <cite class="ltx_cite ltx_citemacro_cite">OÄŸuz etÂ al. (<a href="#bib.bib18" title="" class="ltx_ref">2020</a>); Herzig etÂ al. (<a href="#bib.bib7" title="" class="ltx_ref">2021</a>); Ma etÂ al. (<a href="#bib.bib17" title="" class="ltx_ref">2021</a>)</cite>, but they mainly use tables as an additional information source while we focus on pairing tables with text for pretraining.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">We propose an omnivorous pretraining approach that consumes both natural and synthetic data to enhance the ability to understand and align text and tables and the ability to perform reasoning.
Our extensive results demonstrate the effectiveness of both data and verify their complementary value.
Our empirical results together with the case analysis indicate that omnivorous pretraining can indeed benefit from the merits of both data, encouraging future advances in retrieval and synthesis to obtain higher-quality data and better pretraining strategies to combine heterogeneous data.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgments</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">We thank Qian Liu and Pengcheng Yin for their insightful comments and suggestions.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chemmengath etÂ al. (2021)</span>
<span class="ltx_bibblock">
SaneemÂ A. Chemmengath, Vishwajeet Kumar, Samarth Bharadwaj, Jaydeep Sen,
Mustafa Canim, Soumen Chakrabarti, Alfio Gliozzo, and Karthik
Sankaranarayanan. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://aclanthology.org/2021.emnlp-main.342" title="" class="ltx_ref ltx_href">Topic
transferable table question answering</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021 Conference on Empirical Methods in
Natural Language Processing, EMNLP 2021, Virtual Event / Punta Cana,
Dominican Republic, 7-11 November, 2021</em>, pages 4159â€“4172. Association for
Computational Linguistics.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Deng etÂ al. (2021)</span>
<span class="ltx_bibblock">
Xiang Deng, AhmedÂ Hassan Awadallah, Christopher Meek, Oleksandr Polozov, Huan
Sun, and Matthew Richardson. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2021.naacl-main.105" title="" class="ltx_ref ltx_href">Structure-grounded pretraining for text-to-sql</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies, NAACL-HLT 2021, Online, June 6-11, 2021</em>, pages 1337â€“1350.
Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Deng etÂ al. (2020)</span>
<span class="ltx_bibblock">
Xiang Deng, Huan Sun, Alyssa Lees, You Wu, and Cong Yu. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.5555/3430915.3442430" title="" class="ltx_ref ltx_href">TURL: table
understanding through representation learning</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">Proc. VLDB Endow.</em>, 14(3):307â€“319.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fan etÂ al. (2018)</span>
<span class="ltx_bibblock">
Angela Fan, Mike Lewis, and YannÂ N. Dauphin. 2018.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/P18-1082" title="" class="ltx_ref ltx_href">Hierarchical neural
story generation</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 56th Annual Meeting of the Association
for Computational Linguistics, ACL 2018, Melbourne, Australia, July 15-20,
2018, Volume 1: Long Papers</em>, pages 889â€“898. Association for Computational
Linguistics.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao etÂ al. (2021)</span>
<span class="ltx_bibblock">
Luyu Gao, Zhuyun Dai, and Jamie Callan. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2021.naacl-main.241" title="" class="ltx_ref ltx_href">COIL:
revisit exact lexical match in information retrieval with contextualized
inverted list</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies, NAACL-HLT 2021, Online, June 6-11, 2021</em>, pages 3030â€“3042.
Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guu etÂ al. (2020)</span>
<span class="ltx_bibblock">
Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, and Ming-Wei Chang.
2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2002.08909" title="" class="ltx_ref ltx_href">REALM: retrieval-augmented
language model pre-training</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2002.08909.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Herzig etÂ al. (2021)</span>
<span class="ltx_bibblock">
Jonathan Herzig, Thomas MÃ¼ller, Syrine Krichene, and Julian Eisenschlos.
2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2021.naacl-main.43" title="" class="ltx_ref ltx_href">Open domain
question answering over tables via dense retrieval</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies, NAACL-HLT 2021, Online, June 6-11, 2021</em>, pages 512â€“519.
Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Herzig etÂ al. (2020)</span>
<span class="ltx_bibblock">
Jonathan Herzig, PawelÂ Krzysztof Nowak, Thomas MÃ¼ller, Francesco
Piccinno, and JulianÂ Martin Eisenschlos. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2020.acl-main.398" title="" class="ltx_ref ltx_href">Tapas: Weakly
supervised table parsing via pre-training</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual Meeting of the Association
for Computational Linguistics, ACL 2020, Online, July 5-10, 2020</em>, pages
4320â€“4333. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Iyyer etÂ al. (2017)</span>
<span class="ltx_bibblock">
Mohit Iyyer, Wen-tau Yih, and Ming-Wei Chang. 2017.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/P17-1167" title="" class="ltx_ref ltx_href">Search-based neural
structured learning for sequential question answering</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 55th Annual Meeting of the Association
for Computational Linguistics, ACL 2017, Vancouver, Canada, July 30 -
August 4, Volume 1: Long Papers</em>, pages 1821â€“1831. Association for
Computational Linguistics.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Karpukhin etÂ al. (2020)</span>
<span class="ltx_bibblock">
Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick S.Â H. Lewis, Ledell Wu,
Sergey Edunov, Danqi Chen, and Wen-tau Yih. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2020.emnlp-main.550" title="" class="ltx_ref ltx_href">Dense
passage retrieval for open-domain question answering</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020 Conference on Empirical Methods in
Natural Language Processing, EMNLP 2020, Online, November 16-20, 2020</em>,
pages 6769â€“6781. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Khattab and Zaharia (2020)</span>
<span class="ltx_bibblock">
Omar Khattab and Matei Zaharia. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1145/3397271.3401075" title="" class="ltx_ref ltx_href">Colbert: Efficient
and effective passage search via contextualized late interaction over
BERT</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 43rd International ACM SIGIR
conference on research and development in Information Retrieval, SIGIR
2020, Virtual Event, China, July 25-30, 2020</em>, pages 39â€“48. ACM.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Krishnamurthy etÂ al. (2017)</span>
<span class="ltx_bibblock">
Jayant Krishnamurthy, Pradeep Dasigi, and Matt Gardner. 2017.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/d17-1160" title="" class="ltx_ref ltx_href">Neural semantic parsing
with type constraints for semi-structured tables</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2017 Conference on Empirical Methods in
Natural Language Processing, EMNLP 2017, Copenhagen, Denmark, September
9-11, 2017</em>, pages 1516â€“1526. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lewis etÂ al. (2020a)</span>
<span class="ltx_bibblock">
Mike Lewis, Marjan Ghazvininejad, Gargi Ghosh, Armen Aghajanyan, SidaÂ I. Wang,
and Luke Zettlemoyer. 2020a.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://proceedings.neurips.cc/paper/2020/hash/d6f1dd034aabde7657e6680444ceff62-Abstract.html" title="" class="ltx_ref ltx_href">Pre-training via paraphrasing</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems 33: Annual
Conference on Neural Information Processing Systems 2020, NeurIPS 2020,
December 6-12, 2020, virtual</em>.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lewis etÂ al. (2020b)</span>
<span class="ltx_bibblock">
Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed,
Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer. 2020b.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2020.acl-main.703" title="" class="ltx_ref ltx_href">BART:
denoising sequence-to-sequence pre-training for natural language generation,
translation, and comprehension</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual Meeting of the Association
for Computational Linguistics, ACL 2020, Online, July 5-10, 2020</em>, pages
7871â€“7880. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liang etÂ al. (2018)</span>
<span class="ltx_bibblock">
Chen Liang, Mohammad Norouzi, Jonathan Berant, QuocÂ V. Le, and NiÂ Lao. 2018.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://proceedings.neurips.cc/paper/2018/hash/f4e369c0a468d3aeeda0593ba90b5e55-Abstract.html" title="" class="ltx_ref ltx_href">Memory augmented policy optimization for program synthesis and semantic
parsing</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems 31: Annual
Conference on Neural Information Processing Systems 2018, NeurIPS 2018,
December 3-8, 2018, MontrÃ©al, Canada</em>, pages 10015â€“10027.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu etÂ al. (2021)</span>
<span class="ltx_bibblock">
Qian Liu, Bei Chen, Jiaqi Guo, Zeqi Lin, and Jian-Guang Lou. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2107.07653" title="" class="ltx_ref ltx_href">TAPEX: table pre-training
via learning a neural SQL executor</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2107.07653.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ma etÂ al. (2021)</span>
<span class="ltx_bibblock">
Kaixin Ma, Hao Cheng, Xiaodong Liu, Eric Nyberg, and Jianfeng Gao. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2110.08417" title="" class="ltx_ref ltx_href">Open domain question
answering over virtual documents: A unified approach for data and text</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2110.08417.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OÄŸuz etÂ al. (2020)</span>
<span class="ltx_bibblock">
Barlas OÄŸuz, Xilun Chen, Vladimir Karpukhin, Stanislav Peshterliev, Dmytro
Okhonko, M.Â Schlichtkrull, Sonal Gupta, Yashar Mehdad, and Scott Yih. 2020.

</span>
<span class="ltx_bibblock">Unik-qa: Unified representations of structured and unstructured
knowledge for open-domain question answering.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pasupat and Liang (2015)</span>
<span class="ltx_bibblock">
Panupong Pasupat and Percy Liang. 2015.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.3115/v1/p15-1142" title="" class="ltx_ref ltx_href">Compositional semantic
parsing on semi-structured tables</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 53rd Annual Meeting of the Association
for Computational Linguistics and the 7th International Joint Conference on
Natural Language Processing of the Asian Federation of Natural Language
Processing, ACL 2015, July 26-31, 2015, Beijing, China, Volume 1: Long
Papers</em>, pages 1470â€“1480. The Association for Computer Linguistics.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ram etÂ al. (2021)</span>
<span class="ltx_bibblock">
Ori Ram, Yuval Kirstain, Jonathan Berant, Amir Globerson, and Omer Levy. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2021.acl-long.239" title="" class="ltx_ref ltx_href">Few-shot
question answering by pretraining span selection</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 59th Annual Meeting of the Association
for Computational Linguistics and the 11th International Joint Conference on
Natural Language Processing, ACL/IJCNLP 2021, (Volume 1: Long Papers),
Virtual Event, August 1-6, 2021</em>, pages 3066â€“3079. Association for
Computational Linguistics.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shi etÂ al. (2021)</span>
<span class="ltx_bibblock">
Peng Shi, Patrick Ng, Zhiguo Wang, Henghui Zhu, AlexanderÂ Hanbo Li, Jun Wang,
CÃ­ceroÂ Nogueira dos Santos, and Bing Xiang. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://ojs.aaai.org/index.php/AAAI/article/view/17627" title="" class="ltx_ref ltx_href">Learning contextual representations for semantic parsing with
generation-augmented pre-training</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Thirty-Fifth AAAI Conference on Artificial Intelligence,
AAAI 2021, Thirty-Third Conference on Innovative Applications of Artificial
Intelligence, IAAI 2021, The Eleventh Symposium on Educational Advances in
Artificial Intelligence, EAAI 2021, Virtual Event, February 2-9, 2021</em>,
pages 13806â€“13814. AAAI Press.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shi etÂ al. (2020)</span>
<span class="ltx_bibblock">
Tianze Shi, Chen Zhao, JordanÂ L. Boyd-Graber, HalÂ DaumÃ© III, and
Lillian Lee. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2020.findings-emnlp.167" title="" class="ltx_ref ltx_href">On the
potential of lexico-logical alignments for semantic parsing to SQL
queries</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational Linguistics:
EMNLP 2020, Online Event, 16-20 November 2020</em>, volume EMNLP 2020 of
<em id="bib.bib22.2.2" class="ltx_emph ltx_font_italic">Findings of ACL</em>, pages 1849â€“1864. Association for Computational
Linguistics.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang etÂ al. (2019)</span>
<span class="ltx_bibblock">
Bailin Wang, Ivan Titov, and Mirella Lapata. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/D19-1391" title="" class="ltx_ref ltx_href">Learning semantic
parsers from denotations with latent structured alignments and abstract
programs</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 Conference on Empirical Methods in
Natural Language Processing and the 9th International Joint Conference on
Natural Language Processing, EMNLP-IJCNLP 2019, Hong Kong, China, November
3-7, 2019</em>, pages 3772â€“3783. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang etÂ al. (2021)</span>
<span class="ltx_bibblock">
Zhiruo Wang, Haoyu Dong, Ran Jia, Jia Li, Zhiyi Fu, Shi Han, and Dongmei Zhang.
2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1145/3447548.3467434" title="" class="ltx_ref ltx_href">TUTA: tree-based
transformers for generally structured table pre-training</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">KDD â€™21: The 27th ACM SIGKDD Conference on Knowledge
Discovery and Data Mining, Virtual Event, Singapore, August 14-18, 2021</em>,
pages 1780â€“1790. ACM.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yin etÂ al. (2020)</span>
<span class="ltx_bibblock">
Pengcheng Yin, Graham Neubig, Wen-tau Yih, and Sebastian Riedel. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2020.acl-main.745" title="" class="ltx_ref ltx_href">Tabert:
Pretraining for joint understanding of textual and tabular data</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual Meeting of the Association
for Computational Linguistics, ACL 2020, Online, July 5-10, 2020</em>, pages
8413â€“8426. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu etÂ al. (2021)</span>
<span class="ltx_bibblock">
Tao Yu, Chien-Sheng Wu, XiÂ Victoria Lin, Bailin Wang, YiÂ Chern Tan, Xinyi
Yang, DragomirÂ R. Radev, Richard Socher, and Caiming Xiong. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://openreview.net/forum?id=kyaIeYj4zZ" title="" class="ltx_ref ltx_href">Grappa:
Grammar-augmented pre-training for table semantic parsing</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">9th International Conference on Learning Representations,
ICLR 2021, Virtual Event, Austria, May 3-7, 2021</em>. OpenReview.net.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhong etÂ al. (2017)</span>
<span class="ltx_bibblock">
Victor Zhong, Caiming Xiong, and Richard Socher. 2017.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/1709.00103" title="" class="ltx_ref ltx_href">Seq2sql: Generating
structured queries from natural language using reinforcement learning</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/1709.00103.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2207.03636" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2207.03637" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2207.03637">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2207.03637" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2207.03638" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Wed Mar 13 12:19:44 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
