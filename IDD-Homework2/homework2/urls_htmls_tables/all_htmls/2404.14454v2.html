<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Reinforcement of Explainability of ChatGPT Prompts by Embedding Breast Cancer Self-Screening Rules into AI Responses</title>
<!--Generated on Sun Jun  2 22:37:50 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="
Reinforcement Explainability,  ChatGPT,  Prompt Engineering,  Breast Cancer
" lang="en" name="keywords"/>
<base href="/html/2404.14454v2/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2404.14454v2#S1" title="In Reinforcement of Explainability of ChatGPT Prompts by Embedding Breast Cancer Self-Screening Rules into AI Responses"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">I </span><span class="ltx_text ltx_font_smallcaps">Introduction</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2404.14454v2#S2" title="In Reinforcement of Explainability of ChatGPT Prompts by Embedding Breast Cancer Self-Screening Rules into AI Responses"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">II </span><span class="ltx_text ltx_font_smallcaps">Data</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2404.14454v2#S3" title="In Reinforcement of Explainability of ChatGPT Prompts by Embedding Breast Cancer Self-Screening Rules into AI Responses"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">III </span><span class="ltx_text ltx_font_smallcaps">Methods</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.14454v2#S3.SS1" title="In III Methods ‣ Reinforcement of Explainability of ChatGPT Prompts by Embedding Breast Cancer Self-Screening Rules into AI Responses"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-A</span> </span><span class="ltx_text ltx_font_italic">Phase I: Rule Extraction, Rule Encoding, and Prompt-Engineering</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.14454v2#S3.SS2" title="In III Methods ‣ Reinforcement of Explainability of ChatGPT Prompts by Embedding Breast Cancer Self-Screening Rules into AI Responses"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-B</span> </span><span class="ltx_text ltx_font_italic">Phase II: Testing the rules using Generated Use-Cases</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.14454v2#S3.SS3" title="In III Methods ‣ Reinforcement of Explainability of ChatGPT Prompts by Embedding Breast Cancer Self-Screening Rules into AI Responses"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">III-C</span> </span><span class="ltx_text ltx_font_italic">Rule Testing using Explainable Prompt-Engineering</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2404.14454v2#S4" title="In Reinforcement of Explainability of ChatGPT Prompts by Embedding Breast Cancer Self-Screening Rules into AI Responses"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">IV </span><span class="ltx_text ltx_font_smallcaps">Results</span></span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.14454v2#S4.SS1" title="In IV Results ‣ Reinforcement of Explainability of ChatGPT Prompts by Embedding Breast Cancer Self-Screening Rules into AI Responses"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-A</span> </span><span class="ltx_text ltx_font_italic">Structured Use Case Analysis</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.14454v2#S4.SS2" title="In IV Results ‣ Reinforcement of Explainability of ChatGPT Prompts by Embedding Breast Cancer Self-Screening Rules into AI Responses"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text">IV-B</span> </span><span class="ltx_text ltx_font_italic">Unstructured Use Case Analysis</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2404.14454v2#S5" title="In Reinforcement of Explainability of ChatGPT Prompts by Embedding Breast Cancer Self-Screening Rules into AI Responses"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">V </span><span class="ltx_text ltx_font_smallcaps">Discussion</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2404.14454v2#S6" title="In Reinforcement of Explainability of ChatGPT Prompts by Embedding Breast Cancer Self-Screening Rules into AI Responses"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">VI </span><span class="ltx_text ltx_font_smallcaps">Conclusions and Future Directions</span></span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Reinforcement of Explainability of ChatGPT Prompts by Embedding Breast Cancer Self-Screening Rules into AI Responses
</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">1<sup class="ltx_sup" id="id1.1.id1">st</sup> Yousef Khan
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_font_italic" id="id2.2.id1">Sano Centre for Computational Medicine</span>
<br class="ltx_break"/>Krakow, Poland 
<br class="ltx_break"/>y.khan@sanoscience.org
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">2<sup class="ltx_sup" id="id3.1.id1">nd</sup> Ahmed Abdeen Hamed
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_font_italic" id="id4.2.id1">SSIE Department, CASCI Laboratory</span>
<br class="ltx_break"/><span class="ltx_text ltx_font_italic" id="id5.3.id2">Binghamton University
<br class="ltx_break"/></span>New York, USA 
<br class="ltx_break"/>Corresponding: ahamed1@binghamton.edu*
</span></span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id6.id1"><span class="ltx_text ltx_font_bold" id="id6.id1.1">Background:</span> Addressing the global challenge of breast cancer, this research explores the fusion of generative AI, focusing on ChatGPT 3.5 turbo model, and the intricacies of breast cancer risk assessment. <span class="ltx_text ltx_font_bold" id="id6.id1.2">Objective:</span> The research aims to evaluate ChatGPT’s reasoning capabilities, emphasizing its potential to process rules and provide explanations for screening recommendations. The study seeks to bridge the technology gap between intelligent machines and clinicians by demonstrating ChatGPT’s unique proficiency in natural language reasoning. <span class="ltx_text ltx_font_bold" id="id6.id1.3">Methods:</span> The methodology employs a supervised prompt-engineering approach to enforce detailed explanations for ChatGPT’s recommendations. Synthetic use cases, generated algorithmically, serve as the testing ground for the encoded rules, evaluating the model’s processing prowess. <span class="ltx_text ltx_font_bold" id="id6.id1.4">Conclusion:</span> Findings highlight ChatGPT’s promising capacity in processing rules comparable to Expert System Shells, with a focus on natural language reasoning. The research introduces the concept of reinforcement explainability, showcasing its potential in elucidating outcomes and facilitating user-friendly interfaces for breast cancer risk assessment.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
Reinforcement Explainability, ChatGPT, Prompt Engineering, Breast Cancer

</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span class="ltx_text ltx_font_smallcaps" id="S1.1.1">Introduction</span>
</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Generative Artificial Intelligence (AI) represents a departure from traditional rule-driven systems, offering the capacity to generate contextually relevant responses and insights. Unlike conventional AI approaches, generative models possess the flexibility to learn patterns, adapt to diverse datasets, and generate novel outputs. New Generative AI tools come with a lot of skepticism due to issues of lack of credibility and transparency, making it prevalent that these new tools come with explainable algorithms to help give reassurance in results produced from LLMs <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.14454v2#bib.bib1" title="">1</a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.14454v2#bib.bib2" title="">2</a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.14454v2#bib.bib3" title="">3</a>]</cite>. Through analysis, such as medical literature, Large Language Models (LLMs) can offer doctors valuable insights into uncommon conditions, propose potential treatment approaches, and even forecast patient outcomes <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.14454v2#bib.bib4" title="">4</a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.14454v2#bib.bib5" title="">5</a>]</cite>. Recent advancements in AI have even shown significant improvements in detecting skin cancer and lymphoma from medical imaging <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.14454v2#bib.bib6" title="">6</a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.14454v2#bib.bib7" title="">7</a>]</cite>. AI-driven methodologies have demonstrated high performance in oncology, highlighting AI’s potential for widespread application in healthcare <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.14454v2#bib.bib7" title="">7</a>]</cite> such as building decision making systems <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.14454v2#bib.bib8" title="">8</a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.14454v2#bib.bib9" title="">9</a>]</cite> and accelerate diagnosis <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.14454v2#bib.bib10" title="">10</a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.14454v2#bib.bib11" title="">11</a>]</cite>. These capabilities highlight the transformative potential of generative AI in the healthcare industry, in areas like disease diagnosis, treatment, and patient education <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.14454v2#bib.bib12" title="">12</a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.14454v2#bib.bib13" title="">13</a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.14454v2#bib.bib14" title="">14</a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.14454v2#bib.bib15" title="">15</a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.14454v2#bib.bib16" title="">16</a>]</cite>. A prominent exemplar of generative AI, ChatGPT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.14454v2#bib.bib17" title="">17</a>]</cite>, leverages a vast array of pre-existing knowledge to understand and respond to user inputs with remarkable coherence and context-awareness. This paradigm shift in AI methodology opens doors to dynamic, adaptive decision-making systems that can navigate nuanced scenarios with a level of sophistication previously unparalleled.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Though ample evidence highlights the risks associated with searching for health information online <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.14454v2#bib.bib18" title="">18</a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.14454v2#bib.bib19" title="">19</a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.14454v2#bib.bib20" title="">20</a>]</cite>, individuals persist in turning to online platforms for such information <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.14454v2#bib.bib21" title="">21</a>]</cite>. While research has explored the efficacy of traditional search engines in delivering health-related answers <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.14454v2#bib.bib20" title="">20</a>]</cite>, in comparison, investigation into LLMs is absent. While health chatbots based on preLLM technology have been introduced <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.14454v2#bib.bib22" title="">22</a>]</cite>, there remains a gap in comprehensively evaluating and understanding chatbot solutions utilizing the latest methods in generative LLMs. This paper aims to further explore this matter by examining two primary experimental conditions and focusing on the particular widely-used LLM called ChatGPT, which is currently relied upon by end-users.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Integral to this research is the concept of prompt engineering, a method by which diction and arrangement of examples within a prompt significantly impact the behavior of the model, its guided-to process and ability to understand specific information <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.14454v2#bib.bib23" title="">23</a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.14454v2#bib.bib24" title="">24</a>]</cite>, this technique that differs from fine-tuning as it doesn’t alter the pretrained model’s weights for downstream tasks <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.14454v2#bib.bib25" title="">25</a>]</cite>. Previous research has demonstrated the significant influence of prompt engineering on the efficacy of LLMs like ChatGPT, commonly employed to facilitate few-shot or zero-shot learning tasks <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.14454v2#bib.bib26" title="">26</a>, <a class="ltx_ref" href="https://arxiv.org/html/2404.14454v2#bib.bib27" title="">27</a>]</cite>, diminishes the necessity for model fine-tuning and dependence on supervised labels as it refines the behaviour of LLMs to improve its performance.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">In the context of breast cancer risk assessment, supervised prompt engineering involves the systematic feeding of rules one at a time to train ChatGPT. This supervised approach ensures that the model accurately processes and makes decisions based on the encoded rules, simulating an expert system shell. The objective is not only to elicit accurate recommendations from ChatGPT but also to force detailed explanations of the underlying rules, providing transparency and interpretability to the decision-making process. The subsequent sections outline the structured process of supervised prompt engineering, shedding light on its pivotal role in training ChatGPT for effective breast cancer risk assessment.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">Breast cancer is a pervasive global health challenge, demanding innovative approaches for early detection and accurate risk assessment. In the pursuit of advancing these efforts, this research navigates the crossroads of generative AI, with a specific focus on ChatGPT, and the intricacies of breast cancer risk assessment. Here we investigate and scrutinize ChatGPT’s capacity for reasoning, particularly in its ability to comprehend rules extracted from the guidelines established by the American Cancer Society (ACS) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.14454v2#bib.bib28" title="">28</a>]</cite>. But most importantly, it’s ability to explain and justify the utilization of rules to make a screening recommendation. As large language models become more prevalent for information seeking tasks, especially those influencing critical health-related decisions like treatment options, it is crucial to enhance our comprehension of these models, encompassing aspects such as the accuracy of their responses <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.14454v2#bib.bib29" title="">29</a>]</cite>.Our investigations have demonstrated a promising capability comparable in ways to expert system shells in a way rules are processed and recommendations are explained. More interestingly, ChatGPT reasoning engine enables the processing of rules in a natural language, making it possible for domain experts and clinicians to overcome the difficulties of programming Expert System Shells (ESS), which may bridge the technology gap between intelligent machines and clinicians.</p>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">While conventional rule-based systems have been the norm, the integration of generative AI, as demonstrated by ChatGPT presents a new promising avenue that may enhance the early detection of breast cancer. AI’s ability to analyze large datasets accurately and rapidly is proving transformative in early cancer detection and treatment (Nature, 2023)<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.14454v2#bib.bib30" title="">30</a>]</cite>. The evolution from traditional methods to AI-powered diagnostic tools has not only improved diagnostic accuracy but also enhanced early disease detection, crucial for effective treatment <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.14454v2#bib.bib7" title="">7</a>]</cite>.In the next sections, we present our generative AI on encoding knowledge embedded in the ACS guidelines as rule which we use to “train” the ChatGPT prompt-engineering engine. Using the different features presented in each of the guidelines, we generated 50 use cases to test these rules and determine the performance of the ChatGPT engine in processing the rule and make recommendations. Another important aspect we present in this paper is what we call “Explainability Enforcement” where we inject certain “commands” to trigger ChatGPT to explain its prompt response, and we present the results.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span class="ltx_text ltx_font_smallcaps" id="S2.1.1">Data</span>
</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">The data used in this publication is from two different sources of different types: (1) Rules extracted from the American Cancer Society website <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.14454v2#bib.bib28" title="">28</a>]</cite>; (2) Algorithmically generated use cases which we describe in the methods section.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span class="ltx_text ltx_font_smallcaps" id="S3.1.1">Methods</span>
</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">The foundation of this research rests at the intersection of generative AI, with a specific focus on ChatGPT, and breast cancer risk assessment. Therefore, the Methods paper are designed around the premise of (1) whether we prompt ChatGPT using clinical rules and trigger responses similar in the same way Expert System Shells made in the past, (2) whether we can enforce the default behavior of ChatGPT to provide detailed explanations for the recommendations it makes. In the remaining part of the section, we show these two steps on two phases: <span class="ltx_text ltx_font_bold" id="S3.p1.1.1">Phase I:</span> how to encode the breast cancer self-screening rules using (If/Else) style prompt-engineer ChatGPT in a supervised fashioned. The reason for describing this phase as “supervised” is because the true purpose of this phase is train ChatGPT using the set of encoded rules, without expectation of any answers, other than a confirmation of the rules being entered; <span class="ltx_text ltx_font_bold" id="S3.p1.1.2">Phase II:</span> is how the rules are tested using use cases we designed algorithmically to test the rules using a set of configurations.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS1.4.1.1">III-A</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS1.5.2">Phase I: Rule Extraction, Rule Encoding, and Prompt-Engineering</span>
</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">In the initial phase, we undertook the manual extraction of rules from the guidelines outlined by the American Cancer Society (ACS) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2404.14454v2#bib.bib28" title="">28</a>]</cite>. These rules, organized as if-then statements, were identified and documented for the purpose of self-screening for breast cancer. Following the manual extraction, the identified rules were encoded programmatically to facilitate integration with ChatGPT API prompt-engineering. We encoded the rules one at a time, ensuring accurate representation and adherence to the guidelines provided by the ACS. This encoding process aimed to enhance the model’s understanding of the rules, enabling it to effectively apply them during subsequent analyses.</p>
</div>
<figure class="ltx_figure" id="S3.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="305" id="S3.F1.g1" src="extracted/5638558/images/rule-samples.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Sample of Rules Extracted.</figcaption>
</figure>
<figure class="ltx_float ltx_float_algorithm ltx_framed ltx_framed_top" id="alg1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_bold" id="alg1.2.1.1">Algorithm 1</span> </span> Supervised Prompt Engineering of Rules</figcaption>
<div class="ltx_listing ltx_listing" id="alg1.3">
<div class="ltx_listingline" id="alg1.l1">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l1.1.1.1" style="font-size:80%;">1:</span></span><span class="ltx_text ltx_font_bold" id="alg1.l1.2">input:</span> System role is an Expert System Shell

</div>
<div class="ltx_listingline" id="alg1.l2">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l2.1.1.1" style="font-size:80%;">2:</span></span><span class="ltx_text ltx_font_bold" id="alg1.l2.2">request content:</span>
</div>
<div class="ltx_listingline" id="alg1.l3">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l3.2.1.1" style="font-size:80%;">3:</span></span>Assign a session_id for retrieval <span class="ltx_text" id="alg1.l3.1" style="float:right;"><math alttext="\triangleright" class="ltx_Math" display="inline" id="alg1.l3.1.m1.1"><semantics id="alg1.l3.1.m1.1a"><mo id="alg1.l3.1.m1.1.1" xref="alg1.l3.1.m1.1.1.cmml">▷</mo><annotation-xml encoding="MathML-Content" id="alg1.l3.1.m1.1b"><ci id="alg1.l3.1.m1.1.1.cmml" xref="alg1.l3.1.m1.1.1">▷</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l3.1.m1.1c">\triangleright</annotation><annotation encoding="application/x-llamapun" id="alg1.l3.1.m1.1d">▷</annotation></semantics></math> Create a session for all the rules
</span>
</div>
<div class="ltx_listingline" id="alg1.l4">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l4.1.1.1" style="font-size:80%;">4:</span></span><span class="ltx_text ltx_font_bold" id="alg1.l4.2">for</span> Each rule in the set of rules <span class="ltx_text ltx_font_bold" id="alg1.l4.3">do</span>
</div>
<div class="ltx_listingline" id="alg1.l5">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l5.1.1.1" style="font-size:80%;">5:</span></span>     Encode the rule in the content

</div>
<div class="ltx_listingline" id="alg1.l6">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l6.1.1.1" style="font-size:80%;">6:</span></span>     Request ChatGPT to assign a rule_ID

</div>
<div class="ltx_listingline" id="alg1.l7">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l7.1.1.1" style="font-size:80%;">7:</span></span>     Request confirmation from ChatGPT

</div>
<div class="ltx_listingline" id="alg1.l8">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l8.1.1.1" style="font-size:80%;">8:</span></span><span class="ltx_text ltx_font_bold" id="alg1.l8.2">end</span> <span class="ltx_text ltx_font_bold" id="alg1.l8.3">for</span>
</div>
</div>
</figure>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS2.4.1.1">III-B</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS2.5.2">Phase II: Testing the rules using Generated Use-Cases</span>
</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">To evaluate the performance of ChatGPT in reasoning with the encoded rules, we generated 50 synthetic use cases of structured and unstructured use cases also to determine if ChatGPT can comprehend one type of prompt more accurately than another or if they are evaluated at the same success rate. These use cases included information such as an individual’s medical history, gender, and risk factors for breast cancer. The synthetic data set serves as a controlled environment to systematically test the capabilities of ChatGPT in applying the encoded rules to diverse scenarios. The process of generating 50 synthetic use cases to test the rules which were extracted from the data collection section described above were observed using a python algorithm developed based off known correlations between those who have risk factors related to breast cancer vs those who are less impacted extracted from the ACS. This algorithm performs the following precise steps: (1) Enumerate risk factors such as known BRCA1/BRCA2 gene mutations, family history, radiation therapy, specific syndromes, and personal history of breast cancer, among others; (2) The algorithm goes on to systematically create diverse synthetic use cases with random combinations of gender, age, and breast cancer risk factors. These synthetic use cases are instrumental in evaluating the rules’ efficacy in identifying potential breast cancer risks.; (3) the actual encoding of the script to perform the task of generating synthetic use cases can be captured algorithmically in Algorithm <a class="ltx_ref" href="https://arxiv.org/html/2404.14454v2#alg2" title="Algorithm 2 ‣ III-B Phase II: Testing the rules using Generated Use-Cases ‣ III Methods ‣ Reinforcement of Explainability of ChatGPT Prompts by Embedding Breast Cancer Self-Screening Rules into AI Responses"><span class="ltx_text ltx_ref_tag">2</span></a>:</p>
</div>
<figure class="ltx_float ltx_float_algorithm ltx_framed ltx_framed_top" id="alg2">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_bold" id="alg2.2.1.1">Algorithm 2</span> </span> Algorithmic Generation Use Cases Algorithm</figcaption>
<div class="ltx_listing ltx_listing" id="alg2.3">
<div class="ltx_listingline" id="alg2.l1">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l1.1.1.1" style="font-size:80%;">1:</span></span><span class="ltx_text ltx_font_bold" id="alg2.l1.2">Require:</span> List of 50 synthetic use cases

</div>
<div class="ltx_listingline" id="alg2.l2">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l2.1.1.1" style="font-size:80%;">2:</span></span><span class="ltx_text ltx_font_bold" id="alg2.l2.2">Require:</span> List of screening features contains (gender, age, medical history, and risk factors related to breast cancer)

</div>
<div class="ltx_listingline" id="alg2.l3">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l3.2.1.1" style="font-size:80%;">3:</span></span><span class="ltx_text ltx_font_bold" id="alg2.l3.3">for</span> each useCase in range of 50 <span class="ltx_text ltx_font_bold" id="alg2.l3.4">do</span> <span class="ltx_text" id="alg2.l3.1" style="float:right;"><math alttext="\triangleright" class="ltx_Math" display="inline" id="alg2.l3.1.m1.1"><semantics id="alg2.l3.1.m1.1a"><mo id="alg2.l3.1.m1.1.1" xref="alg2.l3.1.m1.1.1.cmml">▷</mo><annotation-xml encoding="MathML-Content" id="alg2.l3.1.m1.1b"><ci id="alg2.l3.1.m1.1.1.cmml" xref="alg2.l3.1.m1.1.1">▷</ci></annotation-xml><annotation encoding="application/x-tex" id="alg2.l3.1.m1.1c">\triangleright</annotation><annotation encoding="application/x-llamapun" id="alg2.l3.1.m1.1d">▷</annotation></semantics></math>  – Data Generation Step –
</span>
</div>
<div class="ltx_listingline" id="alg2.l4">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l4.1.1.1" style="font-size:80%;">4:</span></span>     <span class="ltx_text ltx_font_bold" id="alg2.l4.2">for</span> each config_param in screening features <span class="ltx_text ltx_font_bold" id="alg2.l4.3">do</span>
</div>
<div class="ltx_listingline" id="alg2.l5">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l5.1.1.1" style="font-size:80%;">5:</span></span>         Randomly choose gender

</div>
<div class="ltx_listingline" id="alg2.l6">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l6.1.1.1" style="font-size:80%;">6:</span></span>         Randomly choose age between 16 and 90

</div>
<div class="ltx_listingline" id="alg2.l7">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l7.1.1.1" style="font-size:80%;">7:</span></span>         Randomly choose 1-4 risk factors

</div>
<div class="ltx_listingline" id="alg2.l8">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l8.1.1.1" style="font-size:80%;">8:</span></span>         Create a background history for the person

</div>
<div class="ltx_listingline" id="alg2.l9">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l9.1.1.1" style="font-size:80%;">9:</span></span>         Append the use case to the list

</div>
<div class="ltx_listingline" id="alg2.l10">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l10.1.1.1" style="font-size:80%;">10:</span></span>     <span class="ltx_text ltx_font_bold" id="alg2.l10.2">end</span> <span class="ltx_text ltx_font_bold" id="alg2.l10.3">for</span>
</div>
<div class="ltx_listingline" id="alg2.l11">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l11.1.1.1" style="font-size:80%;">11:</span></span><span class="ltx_text ltx_font_bold" id="alg2.l11.2">end</span> <span class="ltx_text ltx_font_bold" id="alg2.l11.3">for</span>
</div>
</div>
</figure>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S3.SS3.4.1.1">III-C</span> </span><span class="ltx_text ltx_font_italic" id="S3.SS3.5.2">Rule Testing using Explainable Prompt-Engineering</span>
</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">Here we describe the process of feeding the rules which were extracted from the data collection section described above. Using what we call “Supervised prompt-engieering” which we instructed ChatGPT engine to perform the following precise steps: (1) instructed ChatGPT to act as an expert system shell and start a session specifically for this project, which can be referred to later by an ID. This serves the purpose of making sure we have control over the input to the engine vs using the default behavior of the main ChatGPT engine; (2)Supervised-prompt where we encode the rules one at a time, to train the ChatGPT engine to process and made a decision based on a given use case to also be entered; (3) the expectation of this supervised prompt is to force explanation of the recommendations made by the rules upon firing which is the premise of this work; (4) the actual encoding of the prompt performing the task of supervised prompt-engineering can be captured algorithmically in Algorithm <a class="ltx_ref" href="https://arxiv.org/html/2404.14454v2#alg3" title="Algorithm 3 ‣ III-C Rule Testing using Explainable Prompt-Engineering ‣ III Methods ‣ Reinforcement of Explainability of ChatGPT Prompts by Embedding Breast Cancer Self-Screening Rules into AI Responses"><span class="ltx_text ltx_ref_tag">3</span></a>:</p>
</div>
<figure class="ltx_float ltx_float_algorithm ltx_framed ltx_framed_top" id="alg3">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_bold" id="alg3.2.1.1">Algorithm 3</span> </span> Prompt Engineering of Use Cases</figcaption>
<div class="ltx_listing ltx_listing" id="alg3.3">
<div class="ltx_listingline" id="alg3.l1">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg3.l1.1.1.1" style="font-size:80%;">1:</span></span><span class="ltx_text ltx_font_bold" id="alg3.l1.2">input:</span> System role is an Expert System Shell

</div>
<div class="ltx_listingline" id="alg3.l2">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg3.l2.1.1.1" style="font-size:80%;">2:</span></span><span class="ltx_text ltx_font_bold" id="alg3.l2.2">request content:</span>
</div>
<div class="ltx_listingline" id="alg3.l3">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg3.l3.2.1.1" style="font-size:80%;">3:</span></span>Assign a session_id for retrieval <span class="ltx_text" id="alg3.l3.1" style="float:right;"><math alttext="\triangleright" class="ltx_Math" display="inline" id="alg3.l3.1.m1.1"><semantics id="alg3.l3.1.m1.1a"><mo id="alg3.l3.1.m1.1.1" xref="alg3.l3.1.m1.1.1.cmml">▷</mo><annotation-xml encoding="MathML-Content" id="alg3.l3.1.m1.1b"><ci id="alg3.l3.1.m1.1.1.cmml" xref="alg3.l3.1.m1.1.1">▷</ci></annotation-xml><annotation encoding="application/x-tex" id="alg3.l3.1.m1.1c">\triangleright</annotation><annotation encoding="application/x-llamapun" id="alg3.l3.1.m1.1d">▷</annotation></semantics></math>  – Supervised Step –
</span>
</div>
<div class="ltx_listingline" id="alg3.l4">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg3.l4.2.1.1" style="font-size:80%;">4:</span></span><span class="ltx_text ltx_font_bold" id="alg3.l4.3">for</span> Each use case in the list of cases <span class="ltx_text ltx_font_bold" id="alg3.l4.4">do</span> <span class="ltx_text" id="alg3.l4.1" style="float:right;"><math alttext="\triangleright" class="ltx_Math" display="inline" id="alg3.l4.1.m1.1"><semantics id="alg3.l4.1.m1.1a"><mo id="alg3.l4.1.m1.1.1" xref="alg3.l4.1.m1.1.1.cmml">▷</mo><annotation-xml encoding="MathML-Content" id="alg3.l4.1.m1.1b"><ci id="alg3.l4.1.m1.1.1.cmml" xref="alg3.l4.1.m1.1.1">▷</ci></annotation-xml><annotation encoding="application/x-tex" id="alg3.l4.1.m1.1c">\triangleright</annotation><annotation encoding="application/x-llamapun" id="alg3.l4.1.m1.1d">▷</annotation></semantics></math>  – Testing Step –
</span>
</div>
<div class="ltx_listingline" id="alg3.l5">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg3.l5.1.1.1" style="font-size:80%;">5:</span></span>     Prompt the case

</div>
<div class="ltx_listingline" id="alg3.l6">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg3.l6.1.1.1" style="font-size:80%;">6:</span></span>     Request a recommendation

</div>
<div class="ltx_listingline" id="alg3.l7">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg3.l7.1.1.1" style="font-size:80%;">7:</span></span>     Request the explanation of which rule(s) are triggered

</div>
<div class="ltx_listingline" id="alg3.l8">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg3.l8.1.1.1" style="font-size:80%;">8:</span></span><span class="ltx_text ltx_font_bold" id="alg3.l8.2">end</span> <span class="ltx_text ltx_font_bold" id="alg3.l8.3">for</span>
</div>
</div>
</figure>
<div class="ltx_para" id="S3.SS3.p2">
<p class="ltx_p" id="S3.SS3.p2.1">This algorithm systematically evaluated each use case against the encoded rules, determining their effectiveness in identifying potential risks for breast cancer. The algorithm considered various factors such as the accuracy of rule application and the model’s ability to correctly interpret and respond to each use case.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span class="ltx_text ltx_font_smallcaps" id="S4.1.1">Results</span>
</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">Our experiment measures the performance for two different types of experiments: (1) testing against a structured use case prompts, (2) unstructured use cases, written in natural languages and formatted as plain-text.</p>
</div>
<figure class="ltx_table" id="S4.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE I: </span>Outcome of Use Case Evaluation:</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T1.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S4.T1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.1.1.1">Use Case Type</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.1.2.1"># of Correct</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S4.T1.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.1.3.1"># of Incorrect</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T1.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.1.4.1">1-Rule Triggered</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T1.1.1.1.5"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.1.5.1">N-Rule(s) Triggered</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T1.1.2.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S4.T1.1.2.1.1">Structured Use Case</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.2.1.2">47</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T1.1.2.1.3">3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.2.1.4">47</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.2.1.5">3</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.3.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb" id="S4.T1.1.3.2.1">Unstructured Use Case</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.1.3.2.2">41</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T1.1.3.2.3">9</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.1.3.2.4">46</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.1.3.2.5">4</td>
</tr>
</tbody>
</table>
</figure>
<figure class="ltx_figure" id="S4.F2">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="304" id="S4.F2.g1" src="extracted/5638558/images/1_rule.png" width="568"/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="343" id="S4.F2.g2" src="extracted/5638558/images/n_rules.png" width="568"/></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Comparing Results Between Use Case Type</figcaption>
</figure>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS1.4.1.1">IV-A</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS1.5.2">Structured Use Case Analysis</span>
</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">The results in Figure <a class="ltx_ref" href="https://arxiv.org/html/2404.14454v2#S4.F2" title="Figure 2 ‣ IV Results ‣ Reinforcement of Explainability of ChatGPT Prompts by Embedding Breast Cancer Self-Screening Rules into AI Responses"><span class="ltx_text ltx_ref_tag">2</span></a> reveal that, for the 50 structured use cases, there were a total of 47 cases where only 1 rule was triggered, while 3 cases had zero rules triggered (seen in the N-Rule(s) Triggered). Regarding the recommendations, 47 cases produced correct recommendations, while 3 cases received incorrect recommendations as shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2404.14454v2#S4.T1" title="TABLE I ‣ IV Results ‣ Reinforcement of Explainability of ChatGPT Prompts by Embedding Breast Cancer Self-Screening Rules into AI Responses"><span class="ltx_text ltx_ref_tag">I</span></a>. It is noteworthy to mention that the 3 cases with incorrect recommendations does not correlate at all with the 3 cases that had 0 rules triggered. In other words, the absence of a rule or rules being triggered does not guarantee incorrect recommendations in these instances. Out of the 50 rules triggered, the distribution indicates a prevalence of single rule triggers across structured use cases.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span class="ltx_text" id="S4.SS2.4.1.1">IV-B</span> </span><span class="ltx_text ltx_font_italic" id="S4.SS2.5.2">Unstructured Use Case Analysis</span>
</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">For the 50 unstructured use cases, we observe in Table <a class="ltx_ref" href="https://arxiv.org/html/2404.14454v2#S4.T1" title="TABLE I ‣ IV Results ‣ Reinforcement of Explainability of ChatGPT Prompts by Embedding Breast Cancer Self-Screening Rules into AI Responses"><span class="ltx_text ltx_ref_tag">I</span></a> that 46 cases had only 1 rule triggered, and 4 cases had multiple rules triggered (N-Rule(s) Triggered). Interestingly, in the unstructured cases, there were no instances where 0 rules were triggered for a use case. Regarding the recommendations, 41 cases had correct recommendations, while 9 cases received incorrect recommendations. The absence of cases with zero rule triggers in unstructured use cases suggests a consistent application of rules, even if only a single rule is triggered. This could indicate a higher level of complexity in rule application for unstructured use cases.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span class="ltx_text ltx_font_smallcaps" id="S5.1.1">Discussion</span>
</h2>
<figure class="ltx_figure" id="S5.F3">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="117" id="S5.F3.g1" src="extracted/5638558/images/struct.png" width="177"/></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="116" id="S5.F3.g2" src="extracted/5638558/images/unstruct.png" width="177"/></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Comparing Results Between Use Case Type</figcaption>
</figure>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">The outcomes of our use case evaluation uncover intriguing disparities in ChatGPT’s responses to structured and unstructured scenarios. In structured use cases, where a predefined framework guides the evaluation, ChatGPT demonstrated an impressive accuracy of 94%, primarily attributed to the consistent triggering of a single rule in 47 out of 50 cases, as illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2404.14454v2#S5.F3" title="Figure 3 ‣ V Discussion ‣ Reinforcement of Explainability of ChatGPT Prompts by Embedding Breast Cancer Self-Screening Rules into AI Responses"><span class="ltx_text ltx_ref_tag">3</span></a>. This underscores the efficacy of applied rules in generating accurate recommendations within a structured context. However, the revelation of three instances with incorrect recommendations in structured cases emphasizes the necessity for a nuanced understanding of contextual intricacies.</p>
</div>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.1">In contrast, the evaluation of unstructured use cases, marked by a lack of predefined structure, yielded a slightly lower accuracy of 82%, highlighting the inherent challenges in handling natural language within unstructured scenarios seen in Figure <a class="ltx_ref" href="https://arxiv.org/html/2404.14454v2#S5.F3" title="Figure 3 ‣ V Discussion ‣ Reinforcement of Explainability of ChatGPT Prompts by Embedding Breast Cancer Self-Screening Rules into AI Responses"><span class="ltx_text ltx_ref_tag">3</span></a>. Notably, the absence of instances with zero rules triggered in unstructured cases suggests a consistent application of rules even in cases with multiple rules triggered. This disparity in accuracy between structured and unstructured scenarios underscores the potential impact of structure on the effectiveness of the rule-based system, indicating that a predefined structure can enhance recommendation accuracy in specific contexts.</p>
</div>
<div class="ltx_para" id="S5.p3">
<p class="ltx_p" id="S5.p3.1">Examining the rules triggered provides further insights. In structured cases, the consistent triggering of a single rule suggests a well-tailored rule set that aligns with the structured nature of the use cases. However, the cases with incorrect recommendations prompt a closer examination of the rules triggered to understand potential shortcomings or misinterpretations. In unstructured cases, the absence of instances with zero rules triggered indicates the robustness of the rule-based system in consistently applying rules. As this work remains a work-in-progress, further exploration into the nature of incorrect recommendations and a detailed analysis of rule applications in both structured and unstructured cases will be pivotal for refining ChatGPT’s performance across diverse use case scenarios. While initial results provide valuable insights into ChatGPT’s responsiveness, additional tests are warranted to strengthen our initial results, considering the potential variation in how each model weighs different features.</p>
</div>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span class="ltx_text ltx_font_smallcaps" id="S6.1.1">Conclusions and Future Directions</span>
</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">Our work demonstrates the effectiveness of training ChatGPT with reinforcement explainability to process rules and provide clear explanations. The implemented Clinical Decision Support System (CDSS) successfully encodes publicly available knowledge, making it accessible for clinicians and user-friendly for the general public. The democratization of knowledge and rules using ChatGPT holds promise for enhancing accessibility and usability in healthcare decision support systems.</p>
</div>
<div class="ltx_para" id="S6.p2">
<p class="ltx_p" id="S6.p2.1">Looking forward, we envision a future where explainability is prioritized, and large repositories of universal knowledge are incorporated into ChatGPT engines through collaboration with domain experts. This collaborative effort aims to refine ChatGPT’s capabilities for providing accurate, contextually relevant, and explainable recommendations. Additionally, our ongoing research explores the impact of ”prompt engineering” roles, such as clinicians, female patients, and oncologists, on the system’s accuracy, offering insights into tailoring the CDSS to diverse user needs. We continue to extend the system’s capabilities by incorporating additional rules, protocols, and guidelines to handle a broader range of scenarios and address potential conflicts for further advancements in AI-driven decision support systems in healthcare.</p>
</div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_font_smallcaps ltx_title_section">Acknowledgment</h2>
<div class="ltx_para" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">This publication is created as part of the Ministry of Science and Higher Education’s initiative to support the activities of Excellence Centers established in Poland under the Horizon 2020 program based on the agreement No MEiN/2023/DIR/3796.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
A. Abdeen Hamed and X. Wu, “Improving Detection of ChatGPT-Generated Fake
Science Using Real Publication Text: Introducing xFakeBibs a
Supervised-Learning Network Algorithm,” <em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">arXiv e-prints</em>, p.
arXiv:2308.11767, Aug. 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
A. A. Hamed, B. S. Lee, A. Crimi, and M. M. Misiak, “Challenging the machinery
of generative ai with fact-checking: Ontology-driven biological graphs for
verifying human disease-gene links,” 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
A. A. Hamed, M. Zachara-Szymanska, and X. Wu, “Safeguarding authenticity for
mitigating the harms of generative ai: Issues, research agenda, and policies
for detection, fact-checking, and ethical ai,” <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">iScience</em>, vol. 27,
no. 2, p. 108782, 2024. [Online]. Available:
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://www.sciencedirect.com/science/article/pii/S2589004224000038</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
A. Choudhury and O. Asan, “Role of artificial intelligence in patient safety
outcomes: Systematic literature review,” <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">JMIR Med Inform</em>, vol. 8,
no. 7, p. e18599, Jul 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Technische Universität Dresden, “Using artificial intelligence for early
detection and treatment of illnesses,” <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">ScienceDaily</em>, 2021, accessed:
2024-05-28. [Online]. Available:
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://www.sciencedaily.com/releases/2021/08/210820135346.htm</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
J. Amann, A. Blasimme, E. Vayena, D. Frey, and V. Madai, “Explainability for
artificial intelligence in healthcare: a multidisciplinary perspective,”
<em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">BMC Medical Informatics and Decision Making</em>, vol. 20, p. 310, 2020.
[Online]. Available:
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911-020-01332-6</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
R. Deepa, S. Arunkumar, V. Jayaraj, and A. Sivasamy, “Healthcare’s new
Frontier: AI-driven early cancer detection for improved well-being,”
<em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">AIP Advances</em>, vol. 13, no. 11, p. 115331, 11 2023. [Online].
Available: <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://doi.org/10.1063/5.0177640</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
A. Lederman, R. Lederman, and K. Verspoor, “Tasks as needs: reframing the
paradigm of clinical natural language processing research for real-world
decision support,” <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">Journal of the American Medical Informatics
Association</em>, vol. 29, no. 10, pp. 1810–1817, 07 2022. [Online]. Available:
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://doi.org/10.1093/jamia/ocac121</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
A. Mittal, R. Soundararajan, and A. C. Bovik, “No-reference video quality
assessment using space-time chips,” <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">arXiv preprint arXiv:2008.00032</em>,
2020. [Online]. Available: <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://arxiv.org/abs/2008.00032</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Y.-H. Wang and G.-Y. Lin, “Exploring ai-healthcare innovation: natural
language processing-based patents analysis for technology-driven
roadmapping,” <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">Kybernetes: The International Journal of Systems &amp;
Cybernetics</em>, vol. 52, no. 4, pp. 1173–1189, 2022. [Online]. Available:
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://www.ingentaconnect.com/content/mcb/067/2022/00000052/00000004/art00001</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
K. Liang, C. Yue, J. Wang, L. Liu, and Y. Zhou, “Integrating physiological
time series and clinical notes with transformer for early prediction of
sepsis,” <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">arXiv preprint arXiv:2203.14469</em>, 2022. [Online]. Available:
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://arxiv.org/abs/2203.14469</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
S. Biswas, “Chatgpt and the future of medical writing,” <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">Radiology</em>,
vol. 307, no. 2, p. e223312, 2023, pMID: 36728748. [Online]. Available:
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://doi.org/10.1148/radiol.223312</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
T. H. Kung, M. Cheatham, A. Medenilla, C. Sillos, L. De Leon, C. Elepaño,
M. Madriaga, R. Aggabao, G. Diaz-Candido, J. Maningo, and V. Tseng,
“Performance of chatgpt on usmle: Potential for ai-assisted medical
education using large language models,” <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">PLOS Digit Health</em>, vol. 2,
no. 2, p. e0000198, Feb. 2023, eCollection 2023 Feb. [Online]. Available:
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9931230/</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
S. B. Patel and K. Lam, “Chatgpt: the future of discharge summaries?”
<em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">Lancet Digit Health</em>, vol. 5, no. 3, pp. e107–e108, Mar. 2023, epub
2023 Feb 6. [Online]. Available:
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://pubmed.ncbi.nlm.nih.gov/36754724/</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
K. Singhal, S. Azizi, T. Tu, S. S. Mahdavi, J. Wei, H. W. Chung, N. Scales,
A. Tanwani, H. Cole-Lewis, S. Pfohl, P. Payne, M. Seneviratne, P. Gamble,
C. Kelly, A. Babiker, N. Schärli, A. Chowdhery, P. Mansfield,
D. Demner-Fushman, B. A. y Arcas, D. Webster, G. S. Corrado, Y. Matias,
K. Chou, J. Gottweis, N. Tomasev, Y. Liu, A. Rajkomar, J. Barral, C. Semturs,
A. Karthikesalingam, and V. Natarajan, “Large language models encode
clinical knowledge,” <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">Nature</em>, vol. 620, no. 7972, pp. 172–180, aug
2023. [Online]. Available: <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://doi.org/10.1038/s41586-023-06291-2</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
K. V. Yuxia Wang and T. Baldwin, “Are large language models ready for
healthcare? a comparative study on clinical language understanding,” 2023.
[Online]. Available: <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://arxiv.org/abs/2304.05368</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
OpenAI, “Chatgpt,” 2023, accessed on January 26, 2024. [Online]. Available:
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://www.openai.com/gpt-3</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
M. Benigeri and P. Pluye, “Shortcomings of health information on the
Internet,” <em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">Health Promotion International</em>, vol. 18, no. 4, pp.
381–386, 12 2003. [Online]. Available:
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://doi.org/10.1093/heapro/dag409</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
R. W. White and E. Horvitz, “Cyberchondria: Studies of the escalation of
medical concerns in web search,” <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">ACM Trans. Inf. Syst.</em>, vol. 27,
no. 4, nov 2009. [Online]. Available:
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://doi.org/10.1145/1629096.1629101</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
G. Zuccon, B. Koopman, and J. Palotti, “Diagnose this if you can,” in
<em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">Advances in Information Retrieval</em>, A. Hanbury, G. Kazai, A. Rauber,
and N. Fuhr, Eds.   Cham: Springer
International Publishing, 2015, pp. 562–567.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
S. Fox and M. Duggan. (2011) The social life of health information. Accessed on
January 26, 2024. [Online]. Available:
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://www.pewresearch.org/internet/wp-content/uploads/sites/9/media/Files/Reports/2011/PIP_Social_Life_of_Health_Info.pdf</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Y. You, C.-H. Tsai, Y. Li, F. Ma, C. Heron, and X. Gui, “Beyond
self-diagnosis: How a chatbot-based symptom checker should respond,”
<em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">ACM Trans. Comput.-Hum. Interact.</em>, vol. 30, no. 4, sep 2023. [Online].
Available: <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://doi.org/10.1145/3589959</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Y. Lu, M. Bartolo, A. Moore, S. Riedel, and P. Stenetorp, “Fantastically
ordered prompts and where to find them: Overcoming few-shot prompt order
sensitivity,” in <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">Proceedings of the 60th Annual Meeting of the
Association for Computational Linguistics (Volume 1: Long Papers)</em>,
S. Muresan, P. Nakov, and A. Villavicencio, Eds.   Dublin, Ireland: Association for Computational Linguistics, May
2022, pp. 8086–8098. [Online]. Available:
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://aclanthology.org/2022.acl-long.556</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
A. Webson and E. Pavlick, “Do prompt-based models really understand the
meaning of their prompts?” in <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">Proceedings of the 2022 Conference of
the North American Chapter of the Association for Computational Linguistics:
Human Language Technologies</em>, M. Carpuat, M.-C. de Marneffe, and I. V.
Meza Ruiz, Eds.   Seattle, United
States: Association for Computational Linguistics, Jul. 2022, pp. 2300–2344.
[Online]. Available: <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://aclanthology.org/2022.naacl-main.167</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
P. Liu, W. Yuan, J. Fu, Z. Jiang, H. Hayashi, and G. Neubig, “Pre-train,
prompt, and predict: A systematic survey of prompting methods in natural
language processing,” <em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">ACM Comput. Surv.</em>, vol. 55, no. 9, jan 2023.
[Online]. Available: <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://doi.org/10.1145/3560815</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal,
A. Neelakantan, P. Shyam, G. Sastry, A. Askell, S. Agarwal, A. Herbert-Voss,
G. Krueger, T. Henighan, R. Child, A. Ramesh, D. Ziegler, J. Wu, C. Winter,
C. Hesse, M. Chen, E. Sigler, M. Litwin, S. Gray, B. Chess, J. Clark,
C. Berner, S. McCandlish, A. Radford, I. Sutskever, and D. Amodei, “Language
models are few-shot learners,” in <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">Advances in Neural Information
Processing Systems</em>, H. Larochelle, M. Ranzato, R. Hadsell, M. Balcan, and
H. Lin, Eds., vol. 33.   Curran
Associates, Inc., 2020, pp. 1877–1901. [Online]. Available:
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
T. Kojima, M. Reid, Y. Matsuo, and Y. Iwasawa, “Large language models are
zero-shot reasoners,” <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">arXiv preprint arXiv:2205.11916</em>, 2022.
[Online]. Available: <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://arxiv.org/abs/2205.11916</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
A. C. Society, “American cancer society recommendations for the early
detection of breast cancer,”
https://www.cancer.org/cancer/types/breast-cancer/screening-tests-and-early-detection/american-cancer-society-recommendations-for-the-early-detection-of-breast-cancer.html,
2024, accessed on January 26, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
B. Koopman and G. Zuccon, “Dr ChatGPT tell me what I want to hear: How
different prompts impact health answer correctness,” in <em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">Proceedings of
the 2023 Conference on Empirical Methods in Natural Language Processing</em>,
H. Bouamor, J. Pino, and K. Bali, Eds.   Singapore: Association for Computational Linguistics, Dec. 2023, pp.
15 012–15 022. [Online]. Available:
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://aclanthology.org/2023.emnlp-main.928</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
M. Foronda, “The ai revolution in cancer,” <em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">Nature</em>, vol. 10 December
2020, 2020. [Online]. Available:
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://www.nature.com/articles/d42859-020-00082-9</span>
</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Sun Jun  2 22:37:50 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
