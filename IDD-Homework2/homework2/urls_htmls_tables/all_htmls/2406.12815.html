<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2406.12815] Privacy Preserving Federated Learning in Medical Imaging with Uncertainty Estimation</title><meta property="og:description" content="Machine learning (ML) and Artificial Intelligence (AI) have fueled remarkable advancements, particularly in healthcare. Within medical imaging, ML models hold the promise of improving disease diagnoses, treatment plann…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Privacy Preserving Federated Learning in Medical Imaging with Uncertainty Estimation">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Privacy Preserving Federated Learning in Medical Imaging with Uncertainty Estimation">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2406.12815">

<!--Generated on Sat Jul  6 01:35:34 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_fleqn">
<h1 class="ltx_title ltx_title_document">Privacy Preserving Federated Learning in Medical Imaging with Uncertainty Estimation</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Nikolas Koutsoubis
</span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yasin Yilmaz
</span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Ravi P. Ramachandran
</span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Matthew Schabath
</span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Ghulam Rasool
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_address">Department of Machine Learning, Moffitt Cancer Center, Tampa, FL
</span>
<span class="ltx_contact ltx_role_address">Department of Cancer Epidemiology, Moffitt Cancer Center, Tampa, FL
</span>
<span class="ltx_contact ltx_role_address">Electrical Engineering Department, University of South Florida, FL,
</span>
<span class="ltx_contact ltx_role_address">Electrical &amp; Computer Engineering Department, Rowan University, NJ
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">Machine learning (ML) and Artificial Intelligence (AI) have fueled remarkable advancements, particularly in healthcare. Within medical imaging, ML models hold the promise of improving disease diagnoses, treatment planning, and post-treatment monitoring. Various computer vision tasks like image classification, object detection, and image segmentation are poised to become routine in clinical analysis. However, privacy concerns surrounding patient data hinder the assembly of large training datasets needed for developing and training accurate, robust, and generalizable models. Federated Learning (FL) emerges as a compelling solution, enabling organizations to collaborate on ML model training by sharing model training information (gradients) rather than data (e.g., medical images). FL’s distributed learning framework facilitates inter-institutional collaboration while preserving patient privacy. However, FL, while robust in privacy preservation, faces several challenges. Sensitive information can still be gleaned from shared gradients that are passed on between organizations during model training. Additionally, in medical imaging, quantifying model confidence/uncertainty accurately is crucial due to the noise and artifacts present in the data. Uncertainty estimation in FL encounters unique hurdles due to data heterogeneity across organizations. This paper offers a comprehensive review of FL, privacy preservation, and uncertainty estimation, with a focus on medical imaging. Alongside a survey of current research, we identify gaps in the field and suggest future directions for FL research to enhance privacy and address noisy medical imaging data challenges.</p>
</div>
<div class="ltx_classification">
<h6 class="ltx_title ltx_title_classification">keywords: </h6>
Federated Learning , Medical Imaging , Privacy Preservation , Uncertainty Estimation , Review

</div>
<span id="id1" class="ltx_note ltx_note_frontmatter ltx_role_journal"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">journal: </span>Medical Image Analysis</span></span></span>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Notably over the last decade, machine learning (ML) approaches have been leveraged for the analysis of medical imaging to improve the prediction of risk, early detection, diagnosis, treatment, and survival outcomes of numerous diseases <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>. ML models have been used in clinical research applications leveraging radiological data, such as CT, MRI, PET, and more <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>. These ML models enable research scientists and clinical care teams to comprehend and interpret complex healthcare data accurately and efficiently. One key component in training effective ML models is curating large datasets necessary for training in the selected domain. This critical requirement presents a problem in the analysis of medical imaging due to privacy regulations regarding private health data, such as the Health Insurance Portability and Accountability Act (HIPAA)<cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> in the USA and the General Data Protection Regulation (GDPR)<cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> in Europe. These regulations are designed to keep patient data secure and private, which makes it challenging to curate and combine large-scale training datasets across multiple sites.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">A conventional method of training ML models is centralized learning, which involves pooling data at a single location from all sources (e.g., sites). This may be challenging for medical datasets. A solution to circumvent centralized learning that has risen in popularity in recent years is Federated Learning (FL). FL was first proposed by Google for training ML models on edge devices without sharing client data <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>. FL provides a method for training on data from multiple sites without data ever leaving the local site. This allows large-scale model training without violating privacy regulations that often hinder transferring and sharing data across sites. The overarching premise behind FL is that rather than transferring data, FL transfers training information (gradients) updates between sites. This permits multiple sites to act as clients and train a global model located at the central server. The global model is expected to outperform all local models on all data as it will learn from all local models without sharing private data.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">In real-world settings, however, data distributions may differ across sites attributed to patient demographics, location, and other factors <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. This violates the independent and identically distributed (<em id="S1.p3.1.1" class="ltx_emph ltx_font_italic">i.i.d</em>) assumption of data and poses technical challenges for effective learning in a distributed FL setting. Many advances in FL techniques have come about in recent years, modifying the methods used to optimize FL’s ability to learn from heterogeneous data while limiting communication costs to improve accuracy and efficiency. However, retaining client data locally is not enough to guarantee data privacy. It has been shown in multiple implementations of FL that through carefully planned methods, private data can be extracted from the communications that take place in an FL setting. Communications such as gradient updates can be used to reconstruct patient data through attacks such as gradient dis-aggregation <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>, model inversion attack <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>, and other methods <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>. Further enhancements in privacy preservation are critical for FL to be a paradigm-shifting technology to improve ML models in medical imaging. Methods such as differential privacy (DP) <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> and homomorphic encryption (HE) <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> have been leveraged to improve communications security. The advantages of these privacy preservation methods are that they can provide mathematical guarantees and show theoretical maximum accuracies based on different levels of privacy. An inherent trade-off exists in many privacy preservation techniques where, as privacy increases, model performance decreases. Sidestepping this trade-off is explored in further detail in Section <a href="#S3" title="3 Privacy Preservation in FL ‣ Privacy Preserving Federated Learning in Medical Imaging with Uncertainty Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2406.12815/assets/figs/1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="195" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>An overview of FL, privacy preservation, and uncertainty estimation is presented.</figcaption>
</figure>
<figure id="S1.F2" class="ltx_figure"><img src="/html/2406.12815/assets/figs/2.png" id="S1.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="337" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Summary of topics covered in this review</figcaption>
</figure>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Another key area in which FL needs to excel in medical imaging is uncertainty estimation, which is the process of measuring the reliability of a prediction/classification made by an ML model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>. ML models in the medical domain will ultimately be used to aid clinicians in the diagnosis and treatment of potentially life-threatening diseases. Hence, it is of utmost importance that the models have a way to notify users when they make uncertain or low-confidence predictions. Uncertainty estimation is a widely studied field <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>. However, FL presents unique challenges for uncertainty estimation. The non-i.i.d. nature of data in many FL applications, data imbalances on the client side, and variable computational overhead require modifications to traditional uncertainty estimation methods to work in FL environments successfully <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>. Various methods have been explored in recent years and will be discussed further in Section <a href="#S4" title="4 Uncertainty Estimation in FL ‣ Privacy Preserving Federated Learning in Medical Imaging with Uncertainty Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">FL holds the potential to significantly improve the role of ML models in the medical imaging domain, helping clinicians better diagnose and treat patients. However, FL alone cannot work in the medical imaging domain due to heterogeneous datasets, privacy regulations, and concerns about confidence in the model output. Extensive work has been conducted in recent years to mitigate and solve these challenges to elevate FL as a mainstream method for training ML models in medical imaging <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>, <a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>. Solving these issues would allow large-scale models to be trained on a wide variety of data, significantly improving the utility of these models for clinicians and researchers alike. This work presents a comprehensive review of the state-of-the-art methods of FL in the medical imaging domain. A summary of the aspects of FL and the topics covered in this paper can be seen in Figures <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Privacy Preserving Federated Learning in Medical Imaging with Uncertainty Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> and <a href="#S1.F2" title="Figure 2 ‣ 1 Introduction ‣ Privacy Preserving Federated Learning in Medical Imaging with Uncertainty Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, respectively. The primary contributions of this work include:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">A review of the current state-of-the-art (last 5 years) FL methods proposed in the medical imaging domain to deal with non-i.i.d. data in real-world settings.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">A review of the state-of-the-art privacy preservation methods extended to FL to guarantee data privacy.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">A review of uncertainty estimation methods effectively applied in FL settings, enabling trustworthy and reliable model development.</p>
</div>
</li>
<li id="S1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="S1.I1.i4.p1" class="ltx_para">
<p id="S1.I1.i4.p1.1" class="ltx_p">Exploration of a number of real-world use cases of FL in the medical imaging domain and what can be learned from these success stories.</p>
</div>
</li>
<li id="S1.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">5.</span> 
<div id="S1.I1.i5.p1" class="ltx_para">
<p id="S1.I1.i5.p1.1" class="ltx_p">Current challenges in FL, data privacy, uncertainty estimation, and potential opportunities and direction for future research.</p>
</div>
</li>
</ul>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">The paper is organized as follows: Section <a href="#S2" title="2 Federated Learning (FL) ‣ Privacy Preserving Federated Learning in Medical Imaging with Uncertainty Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> presents a review of FL methods. Section <a href="#S3" title="3 Privacy Preservation in FL ‣ Privacy Preserving Federated Learning in Medical Imaging with Uncertainty Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> reviews the current state of privacy preservation in FL. Section <a href="#S4" title="4 Uncertainty Estimation in FL ‣ Privacy Preserving Federated Learning in Medical Imaging with Uncertainty Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> explores recent advancements in uncertainty estimation in FL. Section <a href="#S5" title="5 Real-World Applications ‣ Privacy Preserving Federated Learning in Medical Imaging with Uncertainty Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> covers the real-world applications of FL in medical imaging. Section <a href="#S6" title="6 Challenges and Opportunities ‣ Privacy Preserving Federated Learning in Medical Imaging with Uncertainty Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> covers some current challenges and opportunities for research in FL for medical imaging. Finally, Section <a href="#S7" title="7 Conclusion ‣ Privacy Preserving Federated Learning in Medical Imaging with Uncertainty Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> concludes the paper. A repository with links to papers reviewed in this work can be found in this <a target="_blank" href="https://github.com/Niko-k98/Awesome-list-Federated-Learning-Review/tree/main" title="" class="ltx_ref ltx_href" style="color:#0000FF;">Awesome List</a>.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Federated Learning (FL)</h2>

<figure id="S2.F3" class="ltx_figure"><img src="/html/2406.12815/assets/figs/3.png" id="S2.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="327" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Summary of FL topics</figcaption>
</figure>
<figure id="S2.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span> FL algorithms</figcaption>
<table id="S2.T1.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S2.T1.1.1.1" class="ltx_tr">
<th id="S2.T1.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_th_row ltx_border_tt">
<span id="S2.T1.1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.1.1.1.1" class="ltx_p" style="width:28.5pt;"><span id="S2.T1.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Algorithm</span></span>
</span>
</th>
<th id="S2.T1.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt"><span id="S2.T1.1.1.1.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Ref</span></th>
<th id="S2.T1.1.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S2.T1.1.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.1.3.1.1" class="ltx_p" style="width:28.5pt;"><span id="S2.T1.1.1.1.3.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Central Server</span></span>
</span>
</th>
<th id="S2.T1.1.1.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S2.T1.1.1.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.1.4.1.1" class="ltx_p" style="width:34.1pt;"><span id="S2.T1.1.1.1.4.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Local Forgetting</span></span>
</span>
</th>
<th id="S2.T1.1.1.1.5" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S2.T1.1.1.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.1.5.1.1" class="ltx_p" style="width:256.1pt;"><span id="S2.T1.1.1.1.5.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Summary</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S2.T1.1.2.1" class="ltx_tr">
<th id="S2.T1.1.2.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_tt">
<span id="S2.T1.1.2.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.2.1.1.1.1" class="ltx_p" style="width:28.5pt;"><span id="S2.T1.1.2.1.1.1.1.1" class="ltx_text" style="font-size:80%;">FedAvg</span></span>
</span>
</th>
<th id="S2.T1.1.2.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt"><cite class="ltx_cite ltx_citemacro_citep"><span id="S2.T1.1.2.1.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib12" title="" class="ltx_ref">12</a><span id="S2.T1.1.2.1.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></th>
<td id="S2.T1.1.2.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S2.T1.1.2.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.2.1.3.1.1" class="ltx_p" style="width:28.5pt;"><span id="S2.T1.1.2.1.3.1.1.1" class="ltx_text" style="font-size:80%;">yes</span></span>
</span>
</td>
<td id="S2.T1.1.2.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S2.T1.1.2.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.2.1.4.1.1" class="ltx_p" style="width:34.1pt;"><span id="S2.T1.1.2.1.4.1.1.1" class="ltx_text" style="font-size:80%;">no</span></span>
</span>
</td>
<td id="S2.T1.1.2.1.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S2.T1.1.2.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.2.1.5.1.1" class="ltx_p" style="width:256.1pt;"><span id="S2.T1.1.2.1.5.1.1.1" class="ltx_text" style="font-size:80%;">Train local models across various clients and then average the gradient updates at the central server to update the global mode; first proposed method of FL.</span></span>
</span>
</td>
</tr>
<tr id="S2.T1.1.3.2" class="ltx_tr">
<th id="S2.T1.1.3.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_t">
<span id="S2.T1.1.3.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.3.2.1.1.1" class="ltx_p" style="width:28.5pt;"><span id="S2.T1.1.3.2.1.1.1.1" class="ltx_text" style="font-size:80%;">FedProx</span></span>
</span>
</th>
<th id="S2.T1.1.3.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><cite class="ltx_cite ltx_citemacro_citep"><span id="S2.T1.1.3.2.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib24" title="" class="ltx_ref">24</a><span id="S2.T1.1.3.2.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></th>
<td id="S2.T1.1.3.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.1.3.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.3.2.3.1.1" class="ltx_p" style="width:28.5pt;"><span id="S2.T1.1.3.2.3.1.1.1" class="ltx_text" style="font-size:80%;">yes</span></span>
</span>
</td>
<td id="S2.T1.1.3.2.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.1.3.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.3.2.4.1.1" class="ltx_p" style="width:34.1pt;"><span id="S2.T1.1.3.2.4.1.1.1" class="ltx_text" style="font-size:80%;">no</span></span>
</span>
</td>
<td id="S2.T1.1.3.2.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.1.3.2.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.3.2.5.1.1" class="ltx_p" style="width:256.1pt;"><span id="S2.T1.1.3.2.5.1.1.1" class="ltx_text" style="font-size:80%;">Excels in heterogeneous settings; generalization of the FedAvg algorithm; allows for partial updates to be sent to the server instead of simply dropping them from a federated round; adds proximal term that prevents any one client from having too much of an impact on the global model.</span></span>
</span>
</td>
</tr>
<tr id="S2.T1.1.4.3" class="ltx_tr">
<th id="S2.T1.1.4.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_t">
<span id="S2.T1.1.4.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.4.3.1.1.1" class="ltx_p" style="width:28.5pt;"><span id="S2.T1.1.4.3.1.1.1.1" class="ltx_text" style="font-size:80%;">FedBN</span></span>
</span>
</th>
<th id="S2.T1.1.4.3.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><cite class="ltx_cite ltx_citemacro_citep"><span id="S2.T1.1.4.3.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib25" title="" class="ltx_ref">25</a><span id="S2.T1.1.4.3.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></th>
<td id="S2.T1.1.4.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.1.4.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.4.3.3.1.1" class="ltx_p" style="width:28.5pt;"><span id="S2.T1.1.4.3.3.1.1.1" class="ltx_text" style="font-size:80%;">yes</span></span>
</span>
</td>
<td id="S2.T1.1.4.3.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.1.4.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.4.3.4.1.1" class="ltx_p" style="width:34.1pt;"><span id="S2.T1.1.4.3.4.1.1.1" class="ltx_text" style="font-size:80%;">no</span></span>
</span>
</td>
<td id="S2.T1.1.4.3.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.1.4.3.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.4.3.5.1.1" class="ltx_p" style="width:256.1pt;"><span id="S2.T1.1.4.3.5.1.1.1" class="ltx_text" style="font-size:80%;">Addresses the issue of non-i.i.d. data by leveraging batch normalization; follows a similar procedure to Fed-Avg but assumes local models have batch norm layers and excludes their parameters from the averaging step.</span></span>
</span>
</td>
</tr>
<tr id="S2.T1.1.5.4" class="ltx_tr">
<th id="S2.T1.1.5.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_t">
<span id="S2.T1.1.5.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.5.4.1.1.1" class="ltx_p" style="width:28.5pt;"><span id="S2.T1.1.5.4.1.1.1.1" class="ltx_text" style="font-size:80%;">TCT</span></span>
</span>
</th>
<th id="S2.T1.1.5.4.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><cite class="ltx_cite ltx_citemacro_citep"><span id="S2.T1.1.5.4.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib26" title="" class="ltx_ref">26</a><span id="S2.T1.1.5.4.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></th>
<td id="S2.T1.1.5.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.1.5.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.5.4.3.1.1" class="ltx_p" style="width:28.5pt;"><span id="S2.T1.1.5.4.3.1.1.1" class="ltx_text" style="font-size:80%;">yes</span></span>
</span>
</td>
<td id="S2.T1.1.5.4.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.1.5.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.5.4.4.1.1" class="ltx_p" style="width:34.1pt;"><span id="S2.T1.1.5.4.4.1.1.1" class="ltx_text" style="font-size:80%;">yes</span></span>
</span>
</td>
<td id="S2.T1.1.5.4.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.1.5.4.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.5.4.5.1.1" class="ltx_p" style="width:256.1pt;"><span id="S2.T1.1.5.4.5.1.1.1" class="ltx_text" style="font-size:80%;">Train-Convexify-Train: Learn features with an off-the-shelf method (i.e., Fedavg) and then optimize a convexified problem obtained using the model’s empirical neural tangent kernel approximation; involves two stages where the first stage learns useful features from the data, and the second stage learns to use these features to generate a well-performing model.</span></span>
</span>
</td>
</tr>
<tr id="S2.T1.1.6.5" class="ltx_tr">
<th id="S2.T1.1.6.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_t">
<span id="S2.T1.1.6.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.6.5.1.1.1" class="ltx_p" style="width:28.5pt;"><span id="S2.T1.1.6.5.1.1.1.1" class="ltx_text" style="font-size:80%;">FedAP</span></span>
</span>
</th>
<th id="S2.T1.1.6.5.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><cite class="ltx_cite ltx_citemacro_citep"><span id="S2.T1.1.6.5.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib27" title="" class="ltx_ref">27</a><span id="S2.T1.1.6.5.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></th>
<td id="S2.T1.1.6.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.1.6.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.6.5.3.1.1" class="ltx_p" style="width:28.5pt;"><span id="S2.T1.1.6.5.3.1.1.1" class="ltx_text" style="font-size:80%;">yes</span></span>
</span>
</td>
<td id="S2.T1.1.6.5.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.1.6.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.6.5.4.1.1" class="ltx_p" style="width:34.1pt;"><span id="S2.T1.1.6.5.4.1.1.1" class="ltx_text" style="font-size:80%;">no</span></span>
</span>
</td>
<td id="S2.T1.1.6.5.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.1.6.5.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.6.5.5.1.1" class="ltx_p" style="width:256.1pt;"><span id="S2.T1.1.6.5.5.1.1.1" class="ltx_text" style="font-size:80%;">Learns similarities between clients by calculating distances between batch normalization layer statistics obtained from a pre-trained model; these similarities are used to aggregate client models; each client preserves its batch normalization layers to maintain personalized features; the server aggregates client model parameters weighted by client similarities in a personalized manner to generate a unique final model for each client.</span></span>
</span>
</td>
</tr>
<tr id="S2.T1.1.7.6" class="ltx_tr">
<th id="S2.T1.1.7.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_t">
<span id="S2.T1.1.7.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.7.6.1.1.1" class="ltx_p" style="width:28.5pt;"><span id="S2.T1.1.7.6.1.1.1.1" class="ltx_text" style="font-size:80%;">FedGen</span></span>
</span>
</th>
<th id="S2.T1.1.7.6.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><cite class="ltx_cite ltx_citemacro_citep"><span id="S2.T1.1.7.6.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib28" title="" class="ltx_ref">28</a><span id="S2.T1.1.7.6.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></th>
<td id="S2.T1.1.7.6.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.1.7.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.7.6.3.1.1" class="ltx_p" style="width:28.5pt;"><span id="S2.T1.1.7.6.3.1.1.1" class="ltx_text" style="font-size:80%;">yes</span></span>
</span>
</td>
<td id="S2.T1.1.7.6.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.1.7.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.7.6.4.1.1" class="ltx_p" style="width:34.1pt;"><span id="S2.T1.1.7.6.4.1.1.1" class="ltx_text" style="font-size:80%;">no</span></span>
</span>
</td>
<td id="S2.T1.1.7.6.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.1.7.6.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.7.6.5.1.1" class="ltx_p" style="width:256.1pt;"><span id="S2.T1.1.7.6.5.1.1.1" class="ltx_text" style="font-size:80%;">Learns a generator model on the server to ensemble user models’ predictions, creating augmented samples that encapsulate consensual knowledge from user models; generate augmented samples that are shared with users to regularize local model training, leading to better accuracy and faster convergence.</span></span>
</span>
</td>
</tr>
<tr id="S2.T1.1.8.7" class="ltx_tr">
<th id="S2.T1.1.8.7.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_t">
<span id="S2.T1.1.8.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.8.7.1.1.1" class="ltx_p" style="width:28.5pt;"><span id="S2.T1.1.8.7.1.1.1.1" class="ltx_text" style="font-size:80%;">FOLA</span></span>
</span>
</th>
<th id="S2.T1.1.8.7.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><cite class="ltx_cite ltx_citemacro_citep"><span id="S2.T1.1.8.7.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib29" title="" class="ltx_ref">29</a><span id="S2.T1.1.8.7.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></th>
<td id="S2.T1.1.8.7.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.1.8.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.8.7.3.1.1" class="ltx_p" style="width:28.5pt;"><span id="S2.T1.1.8.7.3.1.1.1" class="ltx_text" style="font-size:80%;">yes</span></span>
</span>
</td>
<td id="S2.T1.1.8.7.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.1.8.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.8.7.4.1.1" class="ltx_p" style="width:34.1pt;"><span id="S2.T1.1.8.7.4.1.1.1" class="ltx_text" style="font-size:80%;">yes</span></span>
</span>
</td>
<td id="S2.T1.1.8.7.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.1.8.7.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.8.7.5.1.1" class="ltx_p" style="width:256.1pt;"><span id="S2.T1.1.8.7.5.1.1.1" class="ltx_text" style="font-size:80%;">Bayesian federated learning framework utilizing online Laplace approximation to address local catastrophic forgetting and data heterogeneity; maximizes the posteriors of the server and clients simultaneously to reduce aggregation error and mitigate local forgetting.</span></span>
</span>
</td>
</tr>
<tr id="S2.T1.1.9.8" class="ltx_tr">
<th id="S2.T1.1.9.8.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_t">
<span id="S2.T1.1.9.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.9.8.1.1.1" class="ltx_p" style="width:28.5pt;"><span id="S2.T1.1.9.8.1.1.1.1" class="ltx_text" style="font-size:80%;">FCCL</span></span>
</span>
</th>
<th id="S2.T1.1.9.8.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><cite class="ltx_cite ltx_citemacro_citep"><span id="S2.T1.1.9.8.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib30" title="" class="ltx_ref">30</a><span id="S2.T1.1.9.8.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></th>
<td id="S2.T1.1.9.8.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.1.9.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.9.8.3.1.1" class="ltx_p" style="width:28.5pt;"><span id="S2.T1.1.9.8.3.1.1.1" class="ltx_text" style="font-size:80%;">yes</span></span>
</span>
</td>
<td id="S2.T1.1.9.8.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.1.9.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.9.8.4.1.1" class="ltx_p" style="width:34.1pt;"><span id="S2.T1.1.9.8.4.1.1.1" class="ltx_text" style="font-size:80%;">yes</span></span>
</span>
</td>
<td id="S2.T1.1.9.8.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.1.9.8.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.9.8.5.1.1" class="ltx_p" style="width:256.1pt;"><span id="S2.T1.1.9.8.5.1.1.1" class="ltx_text" style="font-size:80%;">Federated cross-correlational and continual learning uses unlabeled public data to address heterogeneity across models and non-i.i.d data, enhancing model generalizability; constructs a cross-correlation matrix on model outputs to encourage class invariance and diversity; employs knowledge distillation, utilizing both the updated global model and the trained local model to balance inter-domain and intra-domain knowledge to mitigate local forgetting.</span></span>
</span>
</td>
</tr>
<tr id="S2.T1.1.10.9" class="ltx_tr">
<th id="S2.T1.1.10.9.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_t">
<span id="S2.T1.1.10.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.10.9.1.1.1" class="ltx_p" style="width:28.5pt;"><span id="S2.T1.1.10.9.1.1.1.1" class="ltx_text" style="font-size:80%;">Swarm Learning</span></span>
</span>
</th>
<th id="S2.T1.1.10.9.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><cite class="ltx_cite ltx_citemacro_citep"><span id="S2.T1.1.10.9.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib31" title="" class="ltx_ref">31</a><span id="S2.T1.1.10.9.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></th>
<td id="S2.T1.1.10.9.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.1.10.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.10.9.3.1.1" class="ltx_p" style="width:28.5pt;"><span id="S2.T1.1.10.9.3.1.1.1" class="ltx_text" style="font-size:80%;">no</span></span>
</span>
</td>
<td id="S2.T1.1.10.9.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.1.10.9.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.10.9.4.1.1" class="ltx_p" style="width:34.1pt;"><span id="S2.T1.1.10.9.4.1.1.1" class="ltx_text" style="font-size:80%;">yes</span></span>
</span>
</td>
<td id="S2.T1.1.10.9.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.1.10.9.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.10.9.5.1.1" class="ltx_p" style="width:256.1pt;"><span id="S2.T1.1.10.9.5.1.1.1" class="ltx_text" style="font-size:80%;">Model parameters are shared via a swarm network, and the model is built independently on private data at the individual sites; only pre-authorized clients are allowed to execute transactions; on-boarding new clients can be done dynamically.</span></span>
</span>
</td>
</tr>
<tr id="S2.T1.1.11.10" class="ltx_tr">
<th id="S2.T1.1.11.10.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_t">
<span id="S2.T1.1.11.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.11.10.1.1.1" class="ltx_p" style="width:28.5pt;"><span id="S2.T1.1.11.10.1.1.1.1" class="ltx_text" style="font-size:80%;">ProxyFL</span></span>
</span>
</th>
<th id="S2.T1.1.11.10.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><cite class="ltx_cite ltx_citemacro_citep"><span id="S2.T1.1.11.10.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib32" title="" class="ltx_ref">32</a><span id="S2.T1.1.11.10.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></th>
<td id="S2.T1.1.11.10.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.1.11.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.11.10.3.1.1" class="ltx_p" style="width:28.5pt;"><span id="S2.T1.1.11.10.3.1.1.1" class="ltx_text" style="font-size:80%;">yes</span></span>
</span>
</td>
<td id="S2.T1.1.11.10.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.1.11.10.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.11.10.4.1.1" class="ltx_p" style="width:34.1pt;"><span id="S2.T1.1.11.10.4.1.1.1" class="ltx_text" style="font-size:80%;">no</span></span>
</span>
</td>
<td id="S2.T1.1.11.10.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.1.11.10.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.11.10.5.1.1" class="ltx_p" style="width:256.1pt;"><span id="S2.T1.1.11.10.5.1.1.1" class="ltx_text" style="font-size:80%;">Clients maintain two models, a private model that is never shared and a publicly shared proxy model that is designed to preserve patient privacy; proxy models allow for efficient information exchange among clients without needing a centralized server; clients can have different model architectures.</span></span>
</span>
</td>
</tr>
<tr id="S2.T1.1.12.11" class="ltx_tr">
<th id="S2.T1.1.12.11.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_bb ltx_border_t">
<span id="S2.T1.1.12.11.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.12.11.1.1.1" class="ltx_p" style="width:28.5pt;"><span id="S2.T1.1.12.11.1.1.1.1" class="ltx_text" style="font-size:80%;">FogML</span></span>
</span>
</th>
<th id="S2.T1.1.12.11.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t"><cite class="ltx_cite ltx_citemacro_citep"><span id="S2.T1.1.12.11.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib33" title="" class="ltx_ref">33</a><span id="S2.T1.1.12.11.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></th>
<td id="S2.T1.1.12.11.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S2.T1.1.12.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.12.11.3.1.1" class="ltx_p" style="width:28.5pt;"><span id="S2.T1.1.12.11.3.1.1.1" class="ltx_text" style="font-size:80%;">no</span></span>
</span>
</td>
<td id="S2.T1.1.12.11.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S2.T1.1.12.11.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.12.11.4.1.1" class="ltx_p" style="width:34.1pt;"><span id="S2.T1.1.12.11.4.1.1.1" class="ltx_text" style="font-size:80%;">no</span></span>
</span>
</td>
<td id="S2.T1.1.12.11.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S2.T1.1.12.11.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.12.11.5.1.1" class="ltx_p" style="width:256.1pt;"><span id="S2.T1.1.12.11.5.1.1.1" class="ltx_text" style="font-size:80%;">Fog computing nodes reside on the local area networks of each site; fog nodes can pre-process data and aggregate updates from the locally trained models before transmitting, reducing data traffic over sending raw data.</span></span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">FL was first proposed in <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> with the FedAvg algorithm for training models on edge devices without exposing private data. This led to a paradigm shift in how ML models could be trained on sensitive and private data in distributed settings <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>, <a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>. The general idea of FL is that multiple clients train local ML models on their data and send gradient information to a central server to update a global model that, in theory, can outperform all local models on all data <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>. FL is particularly powerful and applicable in medical ML research because the data never has to leave local sites, sidestepping many privacy regulations to protect private health data <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>. Additionally, medical imaging research often requires large volumes of data, frequently reaching terabytes or more, making data transfer challenging for centralized training. The first notable FL algorithm, FedAvg, trains local models across various clients and then averages the gradient updates at the central server to update the global model <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>. The ML models trained with FL can perform at the same level of accuracy compared to those obtained using traditional centralized learning in many real-world medical applications <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>. We have identified four main challenges/bottlenecks that still exist in creating a reliable FL framework for training medical imaging ML models <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>:</p>
<ul id="S2.I1" class="ltx_itemize">
<li id="S2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S2.I1.i1.p1" class="ltx_para">
<p id="S2.I1.i1.p1.1" class="ltx_p"><span id="S2.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Privacy and security challenges</span>: While data remains local to each site, private data can still be extracted from the gradient updates sent to and from the central server or between sites <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>. This calls for enhanced privacy preservation techniques, which will be discussed in Section <a href="#S3" title="3 Privacy Preservation in FL ‣ Privacy Preserving Federated Learning in Medical Imaging with Uncertainty Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
</li>
<li id="S2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S2.I1.i2.p1" class="ltx_para">
<p id="S2.I1.i2.p1.1" class="ltx_p"><span id="S2.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Heterogeneous and non-i.i.d. data distribution</span>: Due to variations in demographics, location, medical imaging equipment, and a variety of other factors, data between sites often violate the i.i.d. assumption, which can inhibit the models’ ability to learn <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>. Various strategies are being developed to address this issue.</p>
</div>
</li>
<li id="S2.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S2.I1.i3.p1" class="ltx_para">
<p id="S2.I1.i3.p1.1" class="ltx_p"><span id="S2.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">Significant communication overhead</span>: Since data never leaves the client’s site, there must be significant communication between clients and the central server. This could be costly, especially with large gradient updates being sent very frequently. Communication-efficient FL frameworks must be designed for FL to succeed in medical imaging tasks <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>.</p>
</div>
</li>
<li id="S2.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="S2.I1.i4.p1" class="ltx_para">
<p id="S2.I1.i4.p1.1" class="ltx_p"><span id="S2.I1.i4.p1.1.1" class="ltx_text ltx_font_bold">Uncertainty estimation</span>: The models used in medical imaging will aid clinicians in the diagnosis and treatment of potentially life-threatening diseases. Therefore, a method for quantifying the uncertainty in model prediction must be integrated into FL frameworks<cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>. Due to the non-i.i.d. nature of the data in FL, new methods must be developed, or the existing methods must be adapted for FL. The current state of progress on the uncertainty estimation is discussed in Section <a href="#S4" title="4 Uncertainty Estimation in FL ‣ Privacy Preserving Federated Learning in Medical Imaging with Uncertainty Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
</li>
</ul>
<p id="S2.p1.2" class="ltx_p">A summary of the topics covered in this section can be seen in Figure <a href="#S2.F3" title="Figure 3 ‣ 2 Federated Learning (FL) ‣ Privacy Preserving Federated Learning in Medical Imaging with Uncertainty Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, and a table of comparisons as well as a short description of each FL algorithm reviewed is presented in Table <a href="#S2.T1" title="Table 1 ‣ 2 Federated Learning (FL) ‣ Privacy Preserving Federated Learning in Medical Imaging with Uncertainty Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>FL Algorithms</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">FL frameworks can be divided into three main categories <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>:</p>
<ul id="S2.I2" class="ltx_itemize">
<li id="S2.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S2.I2.i1.p1" class="ltx_para">
<p id="S2.I2.i1.p1.1" class="ltx_p">Horizontal FL - The dataset of each client has a larger overlap of data features than sites. This means there are more shared data features and fewer shared users. Horizontal FL focuses on the feature dimension of the data and extracts parts with the same characteristics but different users for joint training<cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>. Horizontal FL finds its usage in fields such as keyword spotting, emoji prediction, and blockchain <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>, <a href="#bib.bib40" title="" class="ltx_ref">40</a>, <a href="#bib.bib41" title="" class="ltx_ref">41</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>. Horizontal FL offers significant benefits in terms of privacy and data security <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>. It enables collaborative model training without exposing individual data points, thereby safeguarding sensitive information and enhancing privacy. By aggregating insights from diverse sources, horizontal FL improves model accuracy and robustness due to the abundance of data. This approach also reduces the risks associated with centralized data storage, such as breaches and misuse, and supports regulatory compliance efforts, like GDPR, by keeping data localized and within regulatory boundaries. Horizontal FL faces several challenges that can impact its efficiency and effectiveness <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite>. The frequent exchange of model updates between participants and the central server, known as communication overhead, can be bandwidth-intensive. Additionally, heterogeneity in data distribution, device capabilities, and network connectivity can hinder model convergence and performance. As the number of participants grows, scalability issues arise, making it difficult to coordinate updates and maintain model quality. Moreover, Horizontal FL is susceptible to security threats, including model poisoning and inference attacks, which can compromise the model’s integrity and potentially reveal sensitive information.</p>
</div>
</li>
<li id="S2.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S2.I2.i2.p1" class="ltx_para">
<p id="S2.I2.i2.p1.1" class="ltx_p">Vertical FL - VFL is characterized by a scenario where client datasets have more overlapping users than overlapping data features. Each client dataset has more shared users, but data features are rarely duplicated. Vertical FL is based on feature dimensions and requires data alignment based on common users during joint training. After aligning samples from each participant’s data, training is conducted on the selected datasets <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite>. Vertical FL has seen usage in the medical domain, financial domain, and malware detection <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>, <a href="#bib.bib45" title="" class="ltx_ref">45</a>, <a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite> Vertical FL proves to be exceptionally efficient in scenarios that demand the integration of datasets to uncover new insights, thereby facilitating cross-industry collaborations <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite>. Additionally, its alignment with regulatory compliance mandates makes it an attractive option for industries looking to leverage collective data insights while maintaining strict privacy standards. The requirement for precise data alignment across different datasets introduces complexity, particularly with large-scale data from multiple sources, making the process challenging <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite>. Vertical FL incurs significant communication overhead during model training, which can strain bandwidth and latency, thereby acting as a potential bottleneck. Its applicability is also somewhat limited, as it necessitates conditions where datasets share the same sample space but differ in feature space, restricting its use to specific scenarios. Moreover, despite its advantages in privacy preservation, Vertical FL remains vulnerable to security threats, including inference attacks <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite>, where adversaries could potentially extract sensitive information from the model updates, thereby posing a risk to data privacy.</p>
</div>
</li>
<li id="S2.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S2.I2.i3.p1" class="ltx_para">
<p id="S2.I2.i3.p1.1" class="ltx_p">Federated Transfer Learning - In many real-world scenarios, the datasets owned by each client can vary considerably. Federated transfer learning addresses these situations by enabling the construction of an effective global model despite minimal overlap in dataset features and samples. Federated transfer learning facilitates the development of models with limited data and fewer labels while adhering to data privacy and security regulations.</p>
</div>
</li>
</ul>
</div>
<section id="S2.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.1.1 </span>FedProx</h4>

<div id="S2.SS1.SSS1.p1" class="ltx_para">
<p id="S2.SS1.SSS1.p1.1" class="ltx_p">A variety of extensions to the original FedAvg algorithm have been proposed, such as FedProX <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>. FedProX is an algorithm for FL that excels in heterogeneous data settings and serves as a generalization of the FedAvg algorithm, and FedAvg is considered a special case of FedProX <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>. FedProX allows partial updates to be sent to the server instead of simply dropping them from a federated round and adding a proximal term that prevents any client from contributing too much to the global model, thereby increasing model stability.</p>
</div>
</section>
<section id="S2.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.1.2 </span>FedBN</h4>

<div id="S2.SS1.SSS2.p1" class="ltx_para">
<p id="S2.SS1.SSS2.p1.6" class="ltx_p">Another notable high-performing FL algorithm is FedBN <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>. This method outperforms both FedAvg and FedproX. This method addresses the issue of non-i.i.d. data by leveraging batch normalization. The authors introduce the concept of feature shift in FL as a novel category of a client’s non-i.i.d data distribution, where the following types of feature shifts can occur: 1) covariate shift: the marginal distributions <math id="S2.SS1.SSS2.p1.1.m1.1" class="ltx_Math" alttext="Pi(x)" display="inline"><semantics id="S2.SS1.SSS2.p1.1.m1.1a"><mrow id="S2.SS1.SSS2.p1.1.m1.1.2" xref="S2.SS1.SSS2.p1.1.m1.1.2.cmml"><mi id="S2.SS1.SSS2.p1.1.m1.1.2.2" xref="S2.SS1.SSS2.p1.1.m1.1.2.2.cmml">P</mi><mo lspace="0em" rspace="0em" id="S2.SS1.SSS2.p1.1.m1.1.2.1" xref="S2.SS1.SSS2.p1.1.m1.1.2.1.cmml">​</mo><mi id="S2.SS1.SSS2.p1.1.m1.1.2.3" xref="S2.SS1.SSS2.p1.1.m1.1.2.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S2.SS1.SSS2.p1.1.m1.1.2.1a" xref="S2.SS1.SSS2.p1.1.m1.1.2.1.cmml">​</mo><mrow id="S2.SS1.SSS2.p1.1.m1.1.2.4.2" xref="S2.SS1.SSS2.p1.1.m1.1.2.cmml"><mo stretchy="false" id="S2.SS1.SSS2.p1.1.m1.1.2.4.2.1" xref="S2.SS1.SSS2.p1.1.m1.1.2.cmml">(</mo><mi id="S2.SS1.SSS2.p1.1.m1.1.1" xref="S2.SS1.SSS2.p1.1.m1.1.1.cmml">x</mi><mo stretchy="false" id="S2.SS1.SSS2.p1.1.m1.1.2.4.2.2" xref="S2.SS1.SSS2.p1.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS2.p1.1.m1.1b"><apply id="S2.SS1.SSS2.p1.1.m1.1.2.cmml" xref="S2.SS1.SSS2.p1.1.m1.1.2"><times id="S2.SS1.SSS2.p1.1.m1.1.2.1.cmml" xref="S2.SS1.SSS2.p1.1.m1.1.2.1"></times><ci id="S2.SS1.SSS2.p1.1.m1.1.2.2.cmml" xref="S2.SS1.SSS2.p1.1.m1.1.2.2">𝑃</ci><ci id="S2.SS1.SSS2.p1.1.m1.1.2.3.cmml" xref="S2.SS1.SSS2.p1.1.m1.1.2.3">𝑖</ci><ci id="S2.SS1.SSS2.p1.1.m1.1.1.cmml" xref="S2.SS1.SSS2.p1.1.m1.1.1">𝑥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS2.p1.1.m1.1c">Pi(x)</annotation></semantics></math> varies across clients, even if <math id="S2.SS1.SSS2.p1.2.m2.1" class="ltx_Math" alttext="Pi(y|x)" display="inline"><semantics id="S2.SS1.SSS2.p1.2.m2.1a"><mrow id="S2.SS1.SSS2.p1.2.m2.1.1" xref="S2.SS1.SSS2.p1.2.m2.1.1.cmml"><mi id="S2.SS1.SSS2.p1.2.m2.1.1.3" xref="S2.SS1.SSS2.p1.2.m2.1.1.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="S2.SS1.SSS2.p1.2.m2.1.1.2" xref="S2.SS1.SSS2.p1.2.m2.1.1.2.cmml">​</mo><mi id="S2.SS1.SSS2.p1.2.m2.1.1.4" xref="S2.SS1.SSS2.p1.2.m2.1.1.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="S2.SS1.SSS2.p1.2.m2.1.1.2a" xref="S2.SS1.SSS2.p1.2.m2.1.1.2.cmml">​</mo><mrow id="S2.SS1.SSS2.p1.2.m2.1.1.1.1" xref="S2.SS1.SSS2.p1.2.m2.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.SS1.SSS2.p1.2.m2.1.1.1.1.2" xref="S2.SS1.SSS2.p1.2.m2.1.1.1.1.1.cmml">(</mo><mrow id="S2.SS1.SSS2.p1.2.m2.1.1.1.1.1" xref="S2.SS1.SSS2.p1.2.m2.1.1.1.1.1.cmml"><mi id="S2.SS1.SSS2.p1.2.m2.1.1.1.1.1.2" xref="S2.SS1.SSS2.p1.2.m2.1.1.1.1.1.2.cmml">y</mi><mo fence="false" id="S2.SS1.SSS2.p1.2.m2.1.1.1.1.1.1" xref="S2.SS1.SSS2.p1.2.m2.1.1.1.1.1.1.cmml">|</mo><mi id="S2.SS1.SSS2.p1.2.m2.1.1.1.1.1.3" xref="S2.SS1.SSS2.p1.2.m2.1.1.1.1.1.3.cmml">x</mi></mrow><mo stretchy="false" id="S2.SS1.SSS2.p1.2.m2.1.1.1.1.3" xref="S2.SS1.SSS2.p1.2.m2.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS2.p1.2.m2.1b"><apply id="S2.SS1.SSS2.p1.2.m2.1.1.cmml" xref="S2.SS1.SSS2.p1.2.m2.1.1"><times id="S2.SS1.SSS2.p1.2.m2.1.1.2.cmml" xref="S2.SS1.SSS2.p1.2.m2.1.1.2"></times><ci id="S2.SS1.SSS2.p1.2.m2.1.1.3.cmml" xref="S2.SS1.SSS2.p1.2.m2.1.1.3">𝑃</ci><ci id="S2.SS1.SSS2.p1.2.m2.1.1.4.cmml" xref="S2.SS1.SSS2.p1.2.m2.1.1.4">𝑖</ci><apply id="S2.SS1.SSS2.p1.2.m2.1.1.1.1.1.cmml" xref="S2.SS1.SSS2.p1.2.m2.1.1.1.1"><csymbol cd="latexml" id="S2.SS1.SSS2.p1.2.m2.1.1.1.1.1.1.cmml" xref="S2.SS1.SSS2.p1.2.m2.1.1.1.1.1.1">conditional</csymbol><ci id="S2.SS1.SSS2.p1.2.m2.1.1.1.1.1.2.cmml" xref="S2.SS1.SSS2.p1.2.m2.1.1.1.1.1.2">𝑦</ci><ci id="S2.SS1.SSS2.p1.2.m2.1.1.1.1.1.3.cmml" xref="S2.SS1.SSS2.p1.2.m2.1.1.1.1.1.3">𝑥</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS2.p1.2.m2.1c">Pi(y|x)</annotation></semantics></math> is the same for all client; and 2) concept shift: the conditional distribution <math id="S2.SS1.SSS2.p1.3.m3.1" class="ltx_Math" alttext="Pi(x|y)" display="inline"><semantics id="S2.SS1.SSS2.p1.3.m3.1a"><mrow id="S2.SS1.SSS2.p1.3.m3.1.1" xref="S2.SS1.SSS2.p1.3.m3.1.1.cmml"><mi id="S2.SS1.SSS2.p1.3.m3.1.1.3" xref="S2.SS1.SSS2.p1.3.m3.1.1.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="S2.SS1.SSS2.p1.3.m3.1.1.2" xref="S2.SS1.SSS2.p1.3.m3.1.1.2.cmml">​</mo><mi id="S2.SS1.SSS2.p1.3.m3.1.1.4" xref="S2.SS1.SSS2.p1.3.m3.1.1.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="S2.SS1.SSS2.p1.3.m3.1.1.2a" xref="S2.SS1.SSS2.p1.3.m3.1.1.2.cmml">​</mo><mrow id="S2.SS1.SSS2.p1.3.m3.1.1.1.1" xref="S2.SS1.SSS2.p1.3.m3.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.SS1.SSS2.p1.3.m3.1.1.1.1.2" xref="S2.SS1.SSS2.p1.3.m3.1.1.1.1.1.cmml">(</mo><mrow id="S2.SS1.SSS2.p1.3.m3.1.1.1.1.1" xref="S2.SS1.SSS2.p1.3.m3.1.1.1.1.1.cmml"><mi id="S2.SS1.SSS2.p1.3.m3.1.1.1.1.1.2" xref="S2.SS1.SSS2.p1.3.m3.1.1.1.1.1.2.cmml">x</mi><mo fence="false" id="S2.SS1.SSS2.p1.3.m3.1.1.1.1.1.1" xref="S2.SS1.SSS2.p1.3.m3.1.1.1.1.1.1.cmml">|</mo><mi id="S2.SS1.SSS2.p1.3.m3.1.1.1.1.1.3" xref="S2.SS1.SSS2.p1.3.m3.1.1.1.1.1.3.cmml">y</mi></mrow><mo stretchy="false" id="S2.SS1.SSS2.p1.3.m3.1.1.1.1.3" xref="S2.SS1.SSS2.p1.3.m3.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS2.p1.3.m3.1b"><apply id="S2.SS1.SSS2.p1.3.m3.1.1.cmml" xref="S2.SS1.SSS2.p1.3.m3.1.1"><times id="S2.SS1.SSS2.p1.3.m3.1.1.2.cmml" xref="S2.SS1.SSS2.p1.3.m3.1.1.2"></times><ci id="S2.SS1.SSS2.p1.3.m3.1.1.3.cmml" xref="S2.SS1.SSS2.p1.3.m3.1.1.3">𝑃</ci><ci id="S2.SS1.SSS2.p1.3.m3.1.1.4.cmml" xref="S2.SS1.SSS2.p1.3.m3.1.1.4">𝑖</ci><apply id="S2.SS1.SSS2.p1.3.m3.1.1.1.1.1.cmml" xref="S2.SS1.SSS2.p1.3.m3.1.1.1.1"><csymbol cd="latexml" id="S2.SS1.SSS2.p1.3.m3.1.1.1.1.1.1.cmml" xref="S2.SS1.SSS2.p1.3.m3.1.1.1.1.1.1">conditional</csymbol><ci id="S2.SS1.SSS2.p1.3.m3.1.1.1.1.1.2.cmml" xref="S2.SS1.SSS2.p1.3.m3.1.1.1.1.1.2">𝑥</ci><ci id="S2.SS1.SSS2.p1.3.m3.1.1.1.1.1.3.cmml" xref="S2.SS1.SSS2.p1.3.m3.1.1.1.1.1.3">𝑦</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS2.p1.3.m3.1c">Pi(x|y)</annotation></semantics></math> varies across clients and <math id="S2.SS1.SSS2.p1.4.m4.1" class="ltx_Math" alttext="P(y)" display="inline"><semantics id="S2.SS1.SSS2.p1.4.m4.1a"><mrow id="S2.SS1.SSS2.p1.4.m4.1.2" xref="S2.SS1.SSS2.p1.4.m4.1.2.cmml"><mi id="S2.SS1.SSS2.p1.4.m4.1.2.2" xref="S2.SS1.SSS2.p1.4.m4.1.2.2.cmml">P</mi><mo lspace="0em" rspace="0em" id="S2.SS1.SSS2.p1.4.m4.1.2.1" xref="S2.SS1.SSS2.p1.4.m4.1.2.1.cmml">​</mo><mrow id="S2.SS1.SSS2.p1.4.m4.1.2.3.2" xref="S2.SS1.SSS2.p1.4.m4.1.2.cmml"><mo stretchy="false" id="S2.SS1.SSS2.p1.4.m4.1.2.3.2.1" xref="S2.SS1.SSS2.p1.4.m4.1.2.cmml">(</mo><mi id="S2.SS1.SSS2.p1.4.m4.1.1" xref="S2.SS1.SSS2.p1.4.m4.1.1.cmml">y</mi><mo stretchy="false" id="S2.SS1.SSS2.p1.4.m4.1.2.3.2.2" xref="S2.SS1.SSS2.p1.4.m4.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS2.p1.4.m4.1b"><apply id="S2.SS1.SSS2.p1.4.m4.1.2.cmml" xref="S2.SS1.SSS2.p1.4.m4.1.2"><times id="S2.SS1.SSS2.p1.4.m4.1.2.1.cmml" xref="S2.SS1.SSS2.p1.4.m4.1.2.1"></times><ci id="S2.SS1.SSS2.p1.4.m4.1.2.2.cmml" xref="S2.SS1.SSS2.p1.4.m4.1.2.2">𝑃</ci><ci id="S2.SS1.SSS2.p1.4.m4.1.1.cmml" xref="S2.SS1.SSS2.p1.4.m4.1.1">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS2.p1.4.m4.1c">P(y)</annotation></semantics></math> is the same, where features are <math id="S2.SS1.SSS2.p1.5.m5.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S2.SS1.SSS2.p1.5.m5.1a"><mi id="S2.SS1.SSS2.p1.5.m5.1.1" xref="S2.SS1.SSS2.p1.5.m5.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS2.p1.5.m5.1b"><ci id="S2.SS1.SSS2.p1.5.m5.1.1.cmml" xref="S2.SS1.SSS2.p1.5.m5.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS2.p1.5.m5.1c">x</annotation></semantics></math> and labels are <math id="S2.SS1.SSS2.p1.6.m6.1" class="ltx_Math" alttext="y" display="inline"><semantics id="S2.SS1.SSS2.p1.6.m6.1a"><mi id="S2.SS1.SSS2.p1.6.m6.1.1" xref="S2.SS1.SSS2.p1.6.m6.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS2.p1.6.m6.1b"><ci id="S2.SS1.SSS2.p1.6.m6.1.1.cmml" xref="S2.SS1.SSS2.p1.6.m6.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS2.p1.6.m6.1c">y</annotation></semantics></math> on each client. FedBN uses the same premise as FedAvg, sending local updates and averaging at a coordinator. However, FedBN assumes local models have batch normalization layers and excludes their parameters from the averaging step.</p>
</div>
</section>
<section id="S2.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.1.3 </span>Train-Convexify-Train</h4>

<div id="S2.SS1.SSS3.p1" class="ltx_para">
<p id="S2.SS1.SSS3.p1.1" class="ltx_p">Despite advancements offered by FedBN, Yu et al. point out the challenges due to the non-convexity of data <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>. The authors point out that local models with different local optima can cause the global model to struggle to converge and hinder accuracy improvement <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>. They find that the early layers of an FL model do learn useful features, but the final layers do not make use of them. That is, federated optimization applied to this non-convex problem distorts the learning of the final layers. To solve this issue, they propose a Train-Convexify-Train procedure, which involves learning features with an off-the-shelf method (i.e., Fedavg) and then optimizing a convexified problem obtained using the model’s empirical neural tangent kernel (eNTK) approximation. This technique provided up to 37% improvements in accuracy on dissimilar data over FedAvg alone. The convexity aspect attempts to compute a convex approximation of the model using its eNTK based on the concept of the neural tangent kernel (NTK) <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite>. The eNTK approximates the fine-tuning of a pre-trained model. Train-Convexify-Train has two stages <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>:</p>
<ul id="S2.I3" class="ltx_itemize">
<li id="S2.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S2.I3.i1.p1" class="ltx_para">
<p id="S2.I3.i1.p1.1" class="ltx_p">Stage 1 - Extract eNTK features from a trained FedAvg model. FedAvg is first used to train the model for a number of communication rounds. Then, each client locally computes sub-sampled eNTK features.</p>
</div>
</li>
<li id="S2.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S2.I3.i2.p1" class="ltx_para">
<p id="S2.I3.i2.p1.2" class="ltx_p">Stage 2 - Decentralized linear regression with gradient correction. Given samples on each client <math id="S2.I3.i2.p1.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S2.I3.i2.p1.1.m1.1a"><mi id="S2.I3.i2.p1.1.m1.1.1" xref="S2.I3.i2.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.I3.i2.p1.1.m1.1b"><ci id="S2.I3.i2.p1.1.m1.1.1.cmml" xref="S2.I3.i2.p1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I3.i2.p1.1.m1.1c">k</annotation></semantics></math>, first, normalize the eNTK inputs of all clients with a single communication round. Then, solve the linear regression problem with standard local learning rate and local steps <math id="S2.I3.i2.p1.2.m2.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S2.I3.i2.p1.2.m2.1a"><mi id="S2.I3.i2.p1.2.m2.1.1" xref="S2.I3.i2.p1.2.m2.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S2.I3.i2.p1.2.m2.1b"><ci id="S2.I3.i2.p1.2.m2.1.1.cmml" xref="S2.I3.i2.p1.2.m2.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I3.i2.p1.2.m2.1c">M</annotation></semantics></math>.</p>
</div>
</li>
</ul>
<p id="S2.SS1.SSS3.p1.2" class="ltx_p">In this procedure, the first stage learns useful features from the data, and the second stage learns to use these features to generate a well-performing model <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>.</p>
</div>
</section>
<section id="S2.SS1.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.1.4 </span>FedAP</h4>

<div id="S2.SS1.SSS4.p1" class="ltx_para">
<p id="S2.SS1.SSS4.p1.1" class="ltx_p">Personalized FL involves training personalized models for various clients to deal with large data heterogeneity. Personalized FL balances the need for a generalized model and the benefits of localized, personalized models, making it a promising approach in applications where data privacy and customization are key concerns. One notable personalized FL algorithm is FedAP <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>. FedAP learns similarities between clients by calculating distances between batch normalization layer statistics obtained from a pre-trained model. These similarities are used to aggregate client models. Each client preserves its batch normalization layers to maintain personalized features. The server aggregates client model parameters weighted by client similarities in a personalized manner to generate a unique final model for each client. The authors evaluated FedAP on five healthcare datasets across modalities <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> including the public human activity recognition dataset, PAMAP2 <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite>, COVID-19 chest scan dataset <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib50" title="" class="ltx_ref">50</a>]</cite>, MedMNIST, MedMNISTv2 <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib51" title="" class="ltx_ref">51</a>, <a href="#bib.bib52" title="" class="ltx_ref">52</a>]</cite>, the liver tumor segmentation benchmark <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite>, and OrganAMNIST, OrganCMNIST, OrganSMNIST <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite>. FedAP achieves more than <math id="S2.SS1.SSS4.p1.1.m1.1" class="ltx_Math" alttext="10\%" display="inline"><semantics id="S2.SS1.SSS4.p1.1.m1.1a"><mrow id="S2.SS1.SSS4.p1.1.m1.1.1" xref="S2.SS1.SSS4.p1.1.m1.1.1.cmml"><mn id="S2.SS1.SSS4.p1.1.m1.1.1.2" xref="S2.SS1.SSS4.p1.1.m1.1.1.2.cmml">10</mn><mo id="S2.SS1.SSS4.p1.1.m1.1.1.1" xref="S2.SS1.SSS4.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS4.p1.1.m1.1b"><apply id="S2.SS1.SSS4.p1.1.m1.1.1.cmml" xref="S2.SS1.SSS4.p1.1.m1.1.1"><csymbol cd="latexml" id="S2.SS1.SSS4.p1.1.m1.1.1.1.cmml" xref="S2.SS1.SSS4.p1.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S2.SS1.SSS4.p1.1.m1.1.1.2.cmml" xref="S2.SS1.SSS4.p1.1.m1.1.1.2">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS4.p1.1.m1.1c">10\%</annotation></semantics></math> accuracy over state-of-the-art FL models. FedAP converges faster than other methods, 10 rounds vs. more than 400 rounds for FedBN while being robust to varying hyperparameters and different degrees of non-i.i.d data distribution shifts among clients.</p>
</div>
</section>
<section id="S2.SS1.SSS5" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.1.5 </span>FedGeN</h4>

<div id="S2.SS1.SSS5.p1" class="ltx_para">
<p id="S2.SS1.SSS5.p1.3" class="ltx_p">Knowledge distillation is another emerging method for dealing with the challenge of data heterogeneity in FL. Based on work done by Hinton et al. <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite>. Yang et al. <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite> implemented knowledge distillation for multi-organ segmentation in a federated paradigm. Knowledge distillation involves extracting useful knowledge from an ensemble of models. This has a natural extension to FL as multiple clients can serve as an ensemble from which knowledge can be distilled. One
successful implementation of Federated knowledge distillation is FedGen <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>. Most knowledge distillation methods require a proxy dataset to distill the knowledge. FedGen proposes a data-free method, thereby removing the need for this proxy and making knowledge distillation more accessible to applications where a proxy dataset cannot be created due to lack of data or privacy restrictions <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>. FedGen learns a generator model on the server that ensembles the prediction rules from user models. This generator can produce augmented samples that convey consensual knowledge from the user models. The generator is shared with the users and provides additional samples that regularize local model training. This distills the aggregated knowledge into the user models. Sharing the lightweight generator introduces minimal communication overhead and increases security because the full model is not shared. FedGen achieves better accuracy and faster convergence than state-of-the-art methods under heterogeneous settings. Benefits are especially notable as the data heterogeneity increases. To model non-iid data distributions, the authors follow the work done by Lin et al. <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite> and Hsu et al. <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite>, using a Dirichlet distribution Dir <math id="S2.SS1.SSS5.p1.1.m1.1" class="ltx_Math" alttext="(\alpha)" display="inline"><semantics id="S2.SS1.SSS5.p1.1.m1.1a"><mrow id="S2.SS1.SSS5.p1.1.m1.1.2.2"><mo stretchy="false" id="S2.SS1.SSS5.p1.1.m1.1.2.2.1">(</mo><mi id="S2.SS1.SSS5.p1.1.m1.1.1" xref="S2.SS1.SSS5.p1.1.m1.1.1.cmml">α</mi><mo stretchy="false" id="S2.SS1.SSS5.p1.1.m1.1.2.2.2">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS5.p1.1.m1.1b"><ci id="S2.SS1.SSS5.p1.1.m1.1.1.cmml" xref="S2.SS1.SSS5.p1.1.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS5.p1.1.m1.1c">(\alpha)</annotation></semantics></math> in which a smaller <math id="S2.SS1.SSS5.p1.2.m2.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S2.SS1.SSS5.p1.2.m2.1a"><mi id="S2.SS1.SSS5.p1.2.m2.1.1" xref="S2.SS1.SSS5.p1.2.m2.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS5.p1.2.m2.1b"><ci id="S2.SS1.SSS5.p1.2.m2.1.1.cmml" xref="S2.SS1.SSS5.p1.2.m2.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS5.p1.2.m2.1c">\alpha</annotation></semantics></math> indicates higher data heterogeneity, as it makes the distribution more biased for a user <math id="S2.SS1.SSS5.p1.3.m3.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S2.SS1.SSS5.p1.3.m3.1a"><mi id="S2.SS1.SSS5.p1.3.m3.1.1" xref="S2.SS1.SSS5.p1.3.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS5.p1.3.m3.1b"><ci id="S2.SS1.SSS5.p1.3.m3.1.1.cmml" xref="S2.SS1.SSS5.p1.3.m3.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS5.p1.3.m3.1c">k</annotation></semantics></math>.</p>
</div>
</section>
<section id="S2.SS1.SSS6" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.1.6 </span>Federated Online Laplace Approximation (FOLA)</h4>

<div id="S2.SS1.SSS6.p1" class="ltx_para">
<p id="S2.SS1.SSS6.p1.1" class="ltx_p">In addition to data heterogeneity, another challenging issue in FL is local catastrophic forgetting. That is, the local models forget the specific attributes of their data when they are updated with the global model because the global weights overwrite the model weights. Catastrophic forgetting is also a challenge in continual learning <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib59" title="" class="ltx_ref">59</a>, <a href="#bib.bib60" title="" class="ltx_ref">60</a>]</cite>. To combat this problem and data heterogeneity, a Bayesian FL algorithm with online Laplace approximation is proposed by <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>. Federated Online Laplace Approximation (FOLA) operates by integrating Bayesian principles with an online approximation approach, thereby effectively estimating probabilistic parameters of both global and local models in real-time. This approach addresses aggregation error and local forgetting by efficiently approximating Gaussian posterior distributions in a distributed setting. A Gaussian product method is used to construct a global posterior on the server side and a prior iteration strategy to update the local posteriors on the client sides, both of which are easy to optimize. Successfully maximizing these posteriors of the server and clients simultaneously reduces aggregation error and local forgetting <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>.</p>
</div>
</section>
<section id="S2.SS1.SSS7" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.1.7 </span>Federated Cross-Correlation and Continual Learning (FCCL)</h4>

<div id="S2.SS1.SSS7.p1" class="ltx_para">
<p id="S2.SS1.SSS7.p1.1" class="ltx_p">Another method that addresses local forgetting is Federated Cross-Correlation and Continual Learning (FCCL) <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>. To handle heterogeneity across models and non-i.i.d data, FCCL leverages unlabeled public data and constructs a cross-correlation matrix on the models’ logit outputs. This encourages correlation among the same logit dimensions (class invariance) while de-correlating different dimensions (class diversity) to learn a more generalizable representation. To alleviate catastrophic forgetting during local updates, FCCL employs knowledge distillation using the updated global model (to retain inter-domain information learned from others) and a trained local model (to retain intra-domain information) without leaking privacy. This continually balances knowledge, helping to alleviate catastrophic forgetting.</p>
</div>
</section>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Decentralized FL algorithms</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">Many FL algorithms utilize a central server where local model updates are sent from clients to update the local model. However, many FL implementations do not utilize a central server <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>, <a href="#bib.bib32" title="" class="ltx_ref">32</a>, <a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>. This subsection describes some recent decentralized FL algorithms.</p>
</div>
<section id="S2.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.2.1 </span>Swarm Learning</h4>

<div id="S2.SS2.SSS1.p1" class="ltx_para">
<p id="S2.SS2.SSS1.p1.1" class="ltx_p">Swarm learning <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite> is a decentralized learning method that unites edge computing with blockchain-based peer-to-peer networking, eliminating the need for a central coordinating server. This approach combines decentralized hardware infrastructures and distributed ML using standardized engines with a permissioned blockchain to securely onboard members, dynamically elect the leader, and merge model parameters. Model parameters are shared via a swarm network, allowing independent model building on private data at individual sites. Security and confidentiality are ensured by the permissioned blockchain (making each client well-defined as a participant), which restricts execution to pre-authorized clients. New clients can be dynamically onboarded.</p>
</div>
</section>
<section id="S2.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.2.2 </span>ProxyFL</h4>

<div id="S2.SS2.SSS2.p1" class="ltx_para">
<p id="S2.SS2.SSS2.p1.1" class="ltx_p">ProxyFL <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite> was proposed by Kalra et al. as a communication-efficient scheme for decentralized FL. Each client maintains two models: a private model that is never shared and a publicly shared proxy model that is designed to preserve privacy. Using proxy models allows for efficient information exchange among clients without needing a centralized server. One massive step forward from traditional FL is that ProxyFL allows each client to have model heterogeneity, meaning that each client’s private model can have any architecture. The proxy models also utilize DP to improve privacy. ProxyFL can outperform existing alternatives with much less communication overhead and stronger privacy.</p>
</div>
</section>
<section id="S2.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.2.3 </span>Fog-FL</h4>

<div id="S2.SS2.SSS3.p1" class="ltx_para">
<p id="S2.SS2.SSS3.p1.1" class="ltx_p">Fog-FL enhances the efficiency and reliability of computing using a decentralized computing infrastructure between the data source and the cloud, known as fog computing<cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>. It provides computing, storage, and networking services closer to where the data is generated, i.e., at the network edge. Fog computing nodes reside on the local area networks of each medical institution. These Fog computing nodes can pre-process data and aggregate updates from the locally trained models before transmitting them to the central FL server in the cloud. Fog computing reduces the data traffic and latency compared to sending all raw data directly to the cloud. It also enhances privacy and security as sensitive data stays on the local network.</p>
</div>
</section>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Software Frameworks for FL Implementation</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">An FL project involves many moving parts, requiring coordination between all clients and the central server. To facilitate this process, several open-source frameworks have been developed to aid in setting up and managing federated runs.</p>
</div>
<section id="S2.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.3.1 </span>OpenFL</h4>

<div id="S2.SS3.SSS1.p1" class="ltx_para">
<p id="S2.SS3.SSS1.p1.1" class="ltx_p">OpenFL is an open-source Python library for FL<cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib61" title="" class="ltx_ref">61</a>]</cite>. This framework supports both Tensorflow and PyTorch projects, and the workflow is defined by a federation plan that all sites agree upon before beginning. OpenFL uses a static network topology with clients connecting to a central aggregating server over encrypted channels. OpenFL was designed with medical imaging in mind and is set up for horizontal FL but can be extended to other types. OpenFL allows easy migration of centralized ML models into a federated training pipeline and is designed for real-world scalability and trusted execution.</p>
</div>
</section>
</section>
<section id="S2.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.4 </span>NVIDIA MONAI, FLARE, and Clara</h3>

<div id="S2.SS4.p1" class="ltx_para">
<p id="S2.SS4.p1.1" class="ltx_p">NVIDIA MONAI, FLARE, and Clara are three integral frameworks developed by NVIDIA to advance FL and medical imaging <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib62" title="" class="ltx_ref">62</a>]</cite>, <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib63" title="" class="ltx_ref">63</a>]</cite>, <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite>. Medical Open Network for AI (MONAI) is an open-source framework optimized for healthcare, providing domain-specific tools and deep learning models to streamline the development of medical imaging solutions. It integrates seamlessly with Federated Learning Application Runtime Environment (FLARE), another open-source SDK by NVIDIA designed to facilitate FL. FLARE supports various FL architectures and incorporates robust privacy-preserving techniques like DP and HE. Clara, specifically Clara Train, is a medical imaging platform that leverages FLARE to enable FL within its ecosystem. Some key components of this NVIDIA FLARE include <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite>:</p>
<ul id="S2.I4" class="ltx_itemize">
<li id="S2.I4.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S2.I4.i1.p1" class="ltx_para">
<p id="S2.I4.i1.p1.1" class="ltx_p">An FL simulator for rapid development and prototyping.</p>
</div>
</li>
<li id="S2.I4.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S2.I4.i2.p1" class="ltx_para">
<p id="S2.I4.i2.p1.1" class="ltx_p">A dashboard for simplified project management, secure provisioning, and deployment orchestration.</p>
</div>
</li>
<li id="S2.I4.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S2.I4.i3.p1" class="ltx_para">
<p id="S2.I4.i3.p1.1" class="ltx_p">Reference FL algorithms like Fedavg, fedproX, and FedOpt, with workflows like scatter and gather.</p>
</div>
</li>
<li id="S2.I4.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="S2.I4.i4.p1" class="ltx_para">
<p id="S2.I4.i4.p1.1" class="ltx_p">Privacy preservation options like DP, HE, and others.</p>
</div>
</li>
<li id="S2.I4.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">5.</span> 
<div id="S2.I4.i5.p1" class="ltx_para">
<p id="S2.I4.i5.p1.1" class="ltx_p">Specification-based API for custom implementations</p>
</div>
</li>
<li id="S2.I4.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">6.</span> 
<div id="S2.I4.i6.p1" class="ltx_para">
<p id="S2.I4.i6.p1.1" class="ltx_p">Tight integration with frameworks like MONAI.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.5 </span>Convergence of Model Learning in FL</h3>

<div id="S2.SS5.p1" class="ltx_para">
<p id="S2.SS5.p1.1" class="ltx_p">ML models trained using federated runs can struggle to converge due to the non-i.i.d nature of the model training data. Conventional ML training convergence analysis methods are not necessarily suited for FL settings. Huang et al. propose FL Neural Tangent Kernel (FL-NTK) <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite> to perform convergence analysis of FL algorithms. FL-NTK analyzes the convergence and generalization of FL algorithms in the context of over-parameterized Rectified Linear Unit (ReLU) neural networks. The authors show that FL-NTK converges to a global-optimal solution at a linear rate with properly tuned learning parameters, such as quartic width <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite>. The framework offers insights into different FL optimization and aggregation methods. The authors conducted experiments using the CIFAR-10 <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib66" title="" class="ltx_ref">66</a>]</cite> dataset and ResNet56 model and explored FL with different numbers of clients (<math id="S2.SS5.p1.1.m1.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S2.SS5.p1.1.m1.1a"><mi id="S2.SS5.p1.1.m1.1.1" xref="S2.SS5.p1.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S2.SS5.p1.1.m1.1b"><ci id="S2.SS5.p1.1.m1.1.1.cmml" xref="S2.SS5.p1.1.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS5.p1.1.m1.1c">N</annotation></semantics></math>) and two types of data distributions, i.i.d and non-i.i.d <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite>. 
<br class="ltx_break"></p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Privacy Preservation in FL</h2>

<figure id="S3.F4" class="ltx_figure"><img src="/html/2406.12815/assets/figs/4.png" id="S3.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="302" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Summary of privacy preservation methods in FL.</figcaption>
</figure>
<figure id="S3.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Privacy Preservation Methods in FL.</figcaption>
<table id="S3.T2.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T2.1.1.1" class="ltx_tr">
<th id="S3.T2.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_th_row ltx_border_tt">
<span id="S3.T2.1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.1.1.1.1" class="ltx_p" style="width:42.7pt;"><span id="S3.T2.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Algorithm</span></span>
</span>
</th>
<th id="S3.T2.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt"><span id="S3.T2.1.1.1.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Ref</span></th>
<th id="S3.T2.1.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S3.T2.1.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.1.3.1.1" class="ltx_p" style="width:42.7pt;"><span id="S3.T2.1.1.1.3.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Differential Privacy (DP)</span></span>
</span>
</th>
<th id="S3.T2.1.1.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S3.T2.1.1.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.1.4.1.1" class="ltx_p" style="width:56.9pt;"><span id="S3.T2.1.1.1.4.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Homomorphic Encryption (HE)</span></span>
</span>
</th>
<th id="S3.T2.1.1.1.5" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S3.T2.1.1.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.1.5.1.1" class="ltx_p" style="width:256.1pt;"><span id="S3.T2.1.1.1.5.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Summary</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T2.1.2.1" class="ltx_tr">
<th id="S3.T2.1.2.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_tt">
<span id="S3.T2.1.2.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.2.1.1.1.1" class="ltx_p" style="width:42.7pt;"><span id="S3.T2.1.2.1.1.1.1.1" class="ltx_text" style="font-size:80%;">NbAFL</span></span>
</span>
</th>
<th id="S3.T2.1.2.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt"><cite class="ltx_cite ltx_citemacro_citep"><span id="S3.T2.1.2.1.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib67" title="" class="ltx_ref">67</a><span id="S3.T2.1.2.1.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></th>
<td id="S3.T2.1.2.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S3.T2.1.2.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.2.1.3.1.1" class="ltx_p" style="width:42.7pt;"><span id="S3.T2.1.2.1.3.1.1.1" class="ltx_text" style="font-size:80%;">yes</span></span>
</span>
</td>
<td id="S3.T2.1.2.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S3.T2.1.2.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.2.1.4.1.1" class="ltx_p" style="width:56.9pt;"><span id="S3.T2.1.2.1.4.1.1.1" class="ltx_text" style="font-size:80%;">no</span></span>
</span>
</td>
<td id="S3.T2.1.2.1.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S3.T2.1.2.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.2.1.5.1.1" class="ltx_p" style="width:256.1pt;"><span id="S3.T2.1.2.1.5.1.1.1" class="ltx_text" style="font-size:80%;">Noising before aggregation FL (NbAFL) Uses K-random scheduling to optimize the privacy and accuracy trade-off by introducing artificial noise into the parameters of each client before aggregation.</span></span>
</span>
</td>
</tr>
<tr id="S3.T2.1.3.2" class="ltx_tr">
<th id="S3.T2.1.3.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_t">
<span id="S3.T2.1.3.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.3.2.1.1.1" class="ltx_p" style="width:42.7pt;"><span id="S3.T2.1.3.2.1.1.1.1" class="ltx_text" style="font-size:80%;">Adaptive privacy</span></span>
</span>
</th>
<th id="S3.T2.1.3.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><cite class="ltx_cite ltx_citemacro_citep"><span id="S3.T2.1.3.2.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib68" title="" class="ltx_ref">68</a><span id="S3.T2.1.3.2.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></th>
<td id="S3.T2.1.3.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.1.3.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.3.2.3.1.1" class="ltx_p" style="width:42.7pt;"><span id="S3.T2.1.3.2.3.1.1.1" class="ltx_text" style="font-size:80%;">yes</span></span>
</span>
</td>
<td id="S3.T2.1.3.2.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.1.3.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.3.2.4.1.1" class="ltx_p" style="width:56.9pt;"><span id="S3.T2.1.3.2.4.1.1.1" class="ltx_text" style="font-size:80%;">no</span></span>
</span>
</td>
<td id="S3.T2.1.3.2.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.1.3.2.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.3.2.5.1.1" class="ltx_p" style="width:256.1pt;"><span id="S3.T2.1.3.2.5.1.1.1" class="ltx_text" style="font-size:80%;">Adaptive allocation of the privacy budget across FL iterations; the aim is to optimize the use of the privacy budget based on the data distribution and the model’s learning status; higher privacy budget allocated earlier in training, and lower budget later to optimize privacy budget utilization.</span></span>
</span>
</td>
</tr>
<tr id="S3.T2.1.4.3" class="ltx_tr">
<th id="S3.T2.1.4.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_t">
<span id="S3.T2.1.4.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.4.3.1.1.1" class="ltx_p" style="width:42.7pt;"><span id="S3.T2.1.4.3.1.1.1.1" class="ltx_text" style="font-size:80%;">FedOpt</span></span>
</span>
</th>
<th id="S3.T2.1.4.3.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><cite class="ltx_cite ltx_citemacro_citep"><span id="S3.T2.1.4.3.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib69" title="" class="ltx_ref">69</a><span id="S3.T2.1.4.3.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></th>
<td id="S3.T2.1.4.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.1.4.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.4.3.3.1.1" class="ltx_p" style="width:42.7pt;"><span id="S3.T2.1.4.3.3.1.1.1" class="ltx_text" style="font-size:80%;">yes</span></span>
</span>
</td>
<td id="S3.T2.1.4.3.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.1.4.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.4.3.4.1.1" class="ltx_p" style="width:56.9pt;"><span id="S3.T2.1.4.3.4.1.1.1" class="ltx_text" style="font-size:80%;">yes</span></span>
</span>
</td>
<td id="S3.T2.1.4.3.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.1.4.3.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.4.3.5.1.1" class="ltx_p" style="width:256.1pt;"><span id="S3.T2.1.4.3.5.1.1.1" class="ltx_text" style="font-size:80%;">Utilizes sparse compression and HE for secure gradient aggregation and DP for enhanced privacy.</span></span>
</span>
</td>
</tr>
<tr id="S3.T2.1.5.4" class="ltx_tr">
<th id="S3.T2.1.5.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_t">
<span id="S3.T2.1.5.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.5.4.1.1.1" class="ltx_p" style="width:42.7pt;"><span id="S3.T2.1.5.4.1.1.1.1" class="ltx_text" style="font-size:80%;">SHEFL</span></span>
</span>
</th>
<th id="S3.T2.1.5.4.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><cite class="ltx_cite ltx_citemacro_citep"><span id="S3.T2.1.5.4.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib70" title="" class="ltx_ref">70</a><span id="S3.T2.1.5.4.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></th>
<td id="S3.T2.1.5.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.1.5.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.5.4.3.1.1" class="ltx_p" style="width:42.7pt;"><span id="S3.T2.1.5.4.3.1.1.1" class="ltx_text" style="font-size:80%;">yes</span></span>
</span>
</td>
<td id="S3.T2.1.5.4.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.1.5.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.5.4.4.1.1" class="ltx_p" style="width:56.9pt;"><span id="S3.T2.1.5.4.4.1.1.1" class="ltx_text" style="font-size:80%;">yes</span></span>
</span>
</td>
<td id="S3.T2.1.5.4.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.1.5.4.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.5.4.5.1.1" class="ltx_p" style="width:256.1pt;"><span id="S3.T2.1.5.4.5.1.1.1" class="ltx_text" style="font-size:80%;">Somewhat homomorphically encrypted FL (SHEFL); only communicating encrypted weights; all model updates are conducted in an encrypted space.</span></span>
</span>
</td>
</tr>
<tr id="S3.T2.1.6.5" class="ltx_tr">
<th id="S3.T2.1.6.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_t">
<span id="S3.T2.1.6.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.6.5.1.1.1" class="ltx_p" style="width:42.7pt;"><span id="S3.T2.1.6.5.1.1.1.1" class="ltx_text" style="font-size:80%;">Hybrid Approach</span></span>
</span>
</th>
<th id="S3.T2.1.6.5.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><cite class="ltx_cite ltx_citemacro_citep"><span id="S3.T2.1.6.5.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib71" title="" class="ltx_ref">71</a><span id="S3.T2.1.6.5.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></th>
<td id="S3.T2.1.6.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.1.6.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.6.5.3.1.1" class="ltx_p" style="width:42.7pt;"><span id="S3.T2.1.6.5.3.1.1.1" class="ltx_text" style="font-size:80%;">yes</span></span>
</span>
</td>
<td id="S3.T2.1.6.5.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.1.6.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.6.5.4.1.1" class="ltx_p" style="width:56.9pt;"><span id="S3.T2.1.6.5.4.1.1.1" class="ltx_text" style="font-size:80%;">yes</span></span>
</span>
</td>
<td id="S3.T2.1.6.5.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.1.6.5.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.6.5.5.1.1" class="ltx_p" style="width:256.1pt;"><span id="S3.T2.1.6.5.5.1.1.1" class="ltx_text" style="font-size:80%;">Combining DP with secure multiparty computation enables this method to reduce the growth of noise injection as the number of parties increases without sacrificing privacy; the trust parameter allows for maintaining a set level of trust.</span></span>
</span>
</td>
</tr>
<tr id="S3.T2.1.7.6" class="ltx_tr">
<th id="S3.T2.1.7.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_t">
<span id="S3.T2.1.7.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.7.6.1.1.1" class="ltx_p" style="width:42.7pt;"><span id="S3.T2.1.7.6.1.1.1.1" class="ltx_text" style="font-size:80%;">PrivateKT</span></span>
</span>
</th>
<th id="S3.T2.1.7.6.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><cite class="ltx_cite ltx_citemacro_citep"><span id="S3.T2.1.7.6.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib72" title="" class="ltx_ref">72</a><span id="S3.T2.1.7.6.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></th>
<td id="S3.T2.1.7.6.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.1.7.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.7.6.3.1.1" class="ltx_p" style="width:42.7pt;"><span id="S3.T2.1.7.6.3.1.1.1" class="ltx_text" style="font-size:80%;">yes</span></span>
</span>
</td>
<td id="S3.T2.1.7.6.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.1.7.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.7.6.4.1.1" class="ltx_p" style="width:56.9pt;"><span id="S3.T2.1.7.6.4.1.1.1" class="ltx_text" style="font-size:80%;">no</span></span>
</span>
</td>
<td id="S3.T2.1.7.6.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.1.7.6.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.7.6.5.1.1" class="ltx_p" style="width:256.1pt;"><span id="S3.T2.1.7.6.5.1.1.1" class="ltx_text" style="font-size:80%;">Private knowledge transfer method that uses a small subset of public data to transfer knowledge with local DP guarantee; selects public data points based on informativeness rather than randomly to maximize the knowledge quality.</span></span>
</span>
</td>
</tr>
<tr id="S3.T2.1.8.7" class="ltx_tr">
<th id="S3.T2.1.8.7.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_t">
<span id="S3.T2.1.8.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.8.7.1.1.1" class="ltx_p" style="width:42.7pt;"><span id="S3.T2.1.8.7.1.1.1.1" class="ltx_text" style="font-size:80%;">Multi-RoundSecAgg</span></span>
</span>
</th>
<th id="S3.T2.1.8.7.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><cite class="ltx_cite ltx_citemacro_citep"><span id="S3.T2.1.8.7.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib73" title="" class="ltx_ref">73</a><span id="S3.T2.1.8.7.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></th>
<td id="S3.T2.1.8.7.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.1.8.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.8.7.3.1.1" class="ltx_p" style="width:42.7pt;"><span id="S3.T2.1.8.7.3.1.1.1" class="ltx_text" style="font-size:80%;">yes</span></span>
</span>
</td>
<td id="S3.T2.1.8.7.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.1.8.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.8.7.4.1.1" class="ltx_p" style="width:56.9pt;"><span id="S3.T2.1.8.7.4.1.1.1" class="ltx_text" style="font-size:80%;">no</span></span>
</span>
</td>
<td id="S3.T2.1.8.7.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.1.8.7.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.8.7.5.1.1" class="ltx_p" style="width:256.1pt;"><span id="S3.T2.1.8.7.5.1.1.1" class="ltx_text" style="font-size:80%;">Provides privacy guarantees over multiple training rounds; develops a structured user section strategy that guarantees the long-term privacy of each use.</span></span>
</span>
</td>
</tr>
<tr id="S3.T2.1.9.8" class="ltx_tr">
<th id="S3.T2.1.9.8.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_t">
<span id="S3.T2.1.9.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.9.8.1.1.1" class="ltx_p" style="width:42.7pt;"><span id="S3.T2.1.9.8.1.1.1.1" class="ltx_text" style="font-size:80%;">LDS-FL</span></span>
</span>
</th>
<th id="S3.T2.1.9.8.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><cite class="ltx_cite ltx_citemacro_citep"><span id="S3.T2.1.9.8.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib74" title="" class="ltx_ref">74</a><span id="S3.T2.1.9.8.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></th>
<td id="S3.T2.1.9.8.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.1.9.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.9.8.3.1.1" class="ltx_p" style="width:42.7pt;"><span id="S3.T2.1.9.8.3.1.1.1" class="ltx_text" style="font-size:80%;">no</span></span>
</span>
</td>
<td id="S3.T2.1.9.8.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.1.9.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.9.8.4.1.1" class="ltx_p" style="width:56.9pt;"><span id="S3.T2.1.9.8.4.1.1.1" class="ltx_text" style="font-size:80%;">no</span></span>
</span>
</td>
<td id="S3.T2.1.9.8.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T2.1.9.8.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.9.8.5.1.1" class="ltx_p" style="width:256.1pt;"><span id="S3.T2.1.9.8.5.1.1.1" class="ltx_text" style="font-size:80%;">Maintain the performance of a private model preserved through parameter replacement with multi-user participation to reduce the efficiency of privacy attacks.</span></span>
</span>
</td>
</tr>
<tr id="S3.T2.1.10.9" class="ltx_tr">
<th id="S3.T2.1.10.9.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_bb ltx_border_t">
<span id="S3.T2.1.10.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.10.9.1.1.1" class="ltx_p" style="width:42.7pt;"><span id="S3.T2.1.10.9.1.1.1.1" class="ltx_text" style="font-size:80%;">DeTrust-FL</span></span>
</span>
</th>
<th id="S3.T2.1.10.9.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t"><cite class="ltx_cite ltx_citemacro_citep"><span id="S3.T2.1.10.9.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib75" title="" class="ltx_ref">75</a><span id="S3.T2.1.10.9.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></th>
<td id="S3.T2.1.10.9.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S3.T2.1.10.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.10.9.3.1.1" class="ltx_p" style="width:42.7pt;"><span id="S3.T2.1.10.9.3.1.1.1" class="ltx_text" style="font-size:80%;">no</span></span>
</span>
</td>
<td id="S3.T2.1.10.9.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S3.T2.1.10.9.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.10.9.4.1.1" class="ltx_p" style="width:56.9pt;"><span id="S3.T2.1.10.9.4.1.1.1" class="ltx_text" style="font-size:80%;">no</span></span>
</span>
</td>
<td id="S3.T2.1.10.9.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S3.T2.1.10.9.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.10.9.5.1.1" class="ltx_p" style="width:256.1pt;"><span id="S3.T2.1.10.9.5.1.1.1" class="ltx_text" style="font-size:80%;">Provides secure aggregation of model updates in a decentralized trust setting; implements a decentralized functional encryption scheme where clients collaboratively generate decryption key fragments based on an agreed participation matrix.</span></span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Ensuring the secure processing of protected and identifiable information is a critical priority in the medical field. Federal regulations strictly prohibit the sharing of patient data to prevent privacy breaches. FL addresses this issue by keeping data localized at each site. However, even with data remaining local, privacy can still be compromised. The gradient updates exchanged between clients and the server can potentially reveal information about the training data, leading to privacy leaks. The attacks like the gradient dis-aggregation attack <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> highlight the need for enhanced privacy measures in FL to safeguard sensitive information effectively. The topics covered in this section are summarized in Figure <a href="#S3.F4" title="Figure 4 ‣ 3 Privacy Preservation in FL ‣ Privacy Preserving Federated Learning in Medical Imaging with Uncertainty Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> and Table <a href="#S3.T2" title="Table 2 ‣ 3 Privacy Preservation in FL ‣ Privacy Preserving Federated Learning in Medical Imaging with Uncertainty Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Differential Privacy (DP)</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">One of the most popular methods for privacy preservation is DP <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>, which introduces noise into the gradients to prevent private information leakage. DP has been used in medical imaging applications <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib76" title="" class="ltx_ref">76</a>]</cite>. The DP method provides mathematical guarantees of privacy. However, the guarantees come at the cost of accuracy and convergence <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib77" title="" class="ltx_ref">77</a>, <a href="#bib.bib78" title="" class="ltx_ref">78</a>, <a href="#bib.bib79" title="" class="ltx_ref">79</a>]</cite>.</p>
</div>
<section id="S3.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.1 </span>Noising before model aggregation FL (nbAFL)</h4>

<div id="S3.SS1.SSS1.p1" class="ltx_para">
<p id="S3.SS1.SSS1.p1.1" class="ltx_p">nbAFL adds artificial noise to parameters at the client side before aggregation to ensure DP and then proposes K-random scheduling to find optimal convergence <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib67" title="" class="ltx_ref">67</a>]</cite>. In K-random scheduling, K clients are chosen randomly to participate in the aggregation process, ensuring not all information is communicated in every round. This makes it harder for attackers to extract useful information. An optimal value of <math id="S3.SS1.SSS1.p1.1.m1.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.SS1.SSS1.p1.1.m1.1a"><mi id="S3.SS1.SSS1.p1.1.m1.1.1" xref="S3.SS1.SSS1.p1.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p1.1.m1.1b"><ci id="S3.SS1.SSS1.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS1.p1.1.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p1.1.m1.1c">K</annotation></semantics></math> must be found for a given privacy level. This trade-off is often referred to as privacy budget allocation. nbAFL can balance the privacy level and the desired accuracy based on the application.</p>
</div>
</section>
<section id="S3.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.2 </span>Adaptive privacy budget allocation</h4>

<div id="S3.SS1.SSS2.p1" class="ltx_para">
<p id="S3.SS1.SSS2.p1.1" class="ltx_p">One method for a well-designed privacy budget was proposed by Nampelle et al. <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib68" title="" class="ltx_ref">68</a>]</cite>. The authors demonstrate that strategic calibration of the privacy budget in DP can uphold robust performance while providing substantial privacy guarantees. They propose an adaptive privacy budget allocation strategy for FL rounds that best updates the privacy budget in each round based on the data distribution and model learning progress. The key aspect of their methods is the adaptive allocation of the privacy budget across FL iterations. The aim is to optimize the use of the privacy budget based on the data distribution and the model’s learning status. The strategy is to allocate more of the budget in the earlier iterations of FL, where the models learn more from the data. Later iterations have less privacy budget allocated as the gradients have less information about the data. This design optimizes the trade-off between learning and privacy.</p>
</div>
</section>
<section id="S3.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.3 </span>Privacy-performance trade-offs</h4>

<div id="S3.SS1.SSS3.p1" class="ltx_para">
<p id="S3.SS1.SSS3.p1.1" class="ltx_p">Differentially private FL can provide comparable performance to centralized learning <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib80" title="" class="ltx_ref">80</a>]</cite>. The authors in <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib80" title="" class="ltx_ref">80</a>]</cite>implement a two-step method for DP. First, multiple patches are extracted, and a mosaic is formed for training using a memory network and an attention-based multiple instant learning algorithm that provides privacy bounds locally. The local models with DP are then aggregated at the central server. The method was tested on simulated real-world data in both i.i.d and non-i.i.d. settings. Contrarily, Choudhury et al. <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib81" title="" class="ltx_ref">81</a>]</cite> found that although DP guarantees a given level of privacy as set by its parameters, it significantly deteriorates the utility of the FL model. The model’s performance can only be preserved with a very large number of sites, on the order of <math id="S3.SS1.SSS3.p1.1.m1.1" class="ltx_Math" alttext="10^{3}" display="inline"><semantics id="S3.SS1.SSS3.p1.1.m1.1a"><msup id="S3.SS1.SSS3.p1.1.m1.1.1" xref="S3.SS1.SSS3.p1.1.m1.1.1.cmml"><mn id="S3.SS1.SSS3.p1.1.m1.1.1.2" xref="S3.SS1.SSS3.p1.1.m1.1.1.2.cmml">10</mn><mn id="S3.SS1.SSS3.p1.1.m1.1.1.3" xref="S3.SS1.SSS3.p1.1.m1.1.1.3.cmml">3</mn></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS3.p1.1.m1.1b"><apply id="S3.SS1.SSS3.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS3.p1.1.m1.1.1.1.cmml" xref="S3.SS1.SSS3.p1.1.m1.1.1">superscript</csymbol><cn type="integer" id="S3.SS1.SSS3.p1.1.m1.1.1.2.cmml" xref="S3.SS1.SSS3.p1.1.m1.1.1.2">10</cn><cn type="integer" id="S3.SS1.SSS3.p1.1.m1.1.1.3.cmml" xref="S3.SS1.SSS3.p1.1.m1.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS3.p1.1.m1.1c">10^{3}</annotation></semantics></math>, but suffers severely in cases with fewer sites. Such an assumption of large-scale setup is unrealistic for healthcare applications, where sites are typically hospitals or providers, and each site may not have sufficient data for independently training deep learning models.</p>
</div>
</section>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Homomorphic Encryption (HE)</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">While DP has proven useful, HE has also been extensively explored in FL <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib82" title="" class="ltx_ref">82</a>, <a href="#bib.bib83" title="" class="ltx_ref">83</a>, <a href="#bib.bib84" title="" class="ltx_ref">84</a>]</cite>. HE is a form of encryption that allows computations (mathematical operations) to be carried out on ciphertexts, generating encrypted results that, when decrypted, match the result of operations performed on the plain data. Thus, the data can be encrypted and shared with a third party for processing without the third party having access to the decrypted data.</p>
</div>
<section id="S3.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.1 </span>FedOpt</h4>

<div id="S3.SS2.SSS1.p1" class="ltx_para">
<p id="S3.SS2.SSS1.p1.1" class="ltx_p">FedOpt <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib69" title="" class="ltx_ref">69</a>]</cite> provides a communication-efficient method for privacy preservation in FL. This method uses a novel sparse compression algorithm to reduce communication overhead by extending top-k gradient compression with a downstream compression mechanism. The authors adopt lightweight HE for efficient and secure aggregation of gradients, using additive HE without key-switching to increase plain-text space <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib69" title="" class="ltx_ref">69</a>]</cite>. The authors also employ DP. FedOpt is robust to user dropouts during training, with little impact on accuracy. Evaluations show that FedOpt outperforms state-of-the-art approaches like FedAvg and PPDL in model accuracy, communication efficiency, and computation overhead.</p>
</div>
</section>
<section id="S3.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.2 </span>Somewhat Homomorphic Encryption (SHE)</h4>

<div id="S3.SS2.SSS2.p1" class="ltx_para">
<p id="S3.SS2.SSS2.p1.1" class="ltx_p">SHE is a subset method of HE <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib85" title="" class="ltx_ref">85</a>]</cite> and is a type of encryption that allows for a limited number of arithmetic operations on encrypted data. Unlike Fully Homomorphic Encryption (FHE), which supports unlimited operations, SHE has constraints on the number and type of operations that can be executed. SHE is generally more efficient than FHE because it deals with a restricted set of operations <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib85" title="" class="ltx_ref">85</a>]</cite>. This makes it more practical for applications where the computational overhead of FHE would be prohibitive <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib85" title="" class="ltx_ref">85</a>]</cite>.</p>
</div>
</section>
<section id="S3.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.3 </span>Somewhat Homomorphically Encrypted FL (SHEFL)</h4>

<div id="S3.SS2.SSS3.p1" class="ltx_para">
<p id="S3.SS2.SSS3.p1.1" class="ltx_p">Truhn et al. leveraged SHE and proposed SHEFL, which enables multiple parties to co-train ML models for pathology and radiology images securely, reaching state-of-the-art performance with privacy guarantees while requiring negligible extra computational resources <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib70" title="" class="ltx_ref">70</a>]</cite>. SHEFL provides a solution to privacy concerns by only communicating encrypted weights, and model updates are conducted in an encrypted space. The authors implement SHEFL on two clinical use cases - segmenting brain tumors <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib86" title="" class="ltx_ref">86</a>]</cite> and predicting biomarkers from histopathology slides in colorectal cancer<cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib87" title="" class="ltx_ref">87</a>]</cite>. The models trained with SHEFL are on par with regular FL while providing privacy guarantees, showing that encryption does not negatively impact accuracy <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib70" title="" class="ltx_ref">70</a>]</cite>. The methods only encrypt the vulnerable areas of the FL with a less than <math id="S3.SS2.SSS3.p1.1.m1.1" class="ltx_Math" alttext="5\%" display="inline"><semantics id="S3.SS2.SSS3.p1.1.m1.1a"><mrow id="S3.SS2.SSS3.p1.1.m1.1.1" xref="S3.SS2.SSS3.p1.1.m1.1.1.cmml"><mn id="S3.SS2.SSS3.p1.1.m1.1.1.2" xref="S3.SS2.SSS3.p1.1.m1.1.1.2.cmml">5</mn><mo id="S3.SS2.SSS3.p1.1.m1.1.1.1" xref="S3.SS2.SSS3.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p1.1.m1.1b"><apply id="S3.SS2.SSS3.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS3.p1.1.m1.1.1"><csymbol cd="latexml" id="S3.SS2.SSS3.p1.1.m1.1.1.1.cmml" xref="S3.SS2.SSS3.p1.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S3.SS2.SSS3.p1.1.m1.1.1.2.cmml" xref="S3.SS2.SSS3.p1.1.m1.1.1.2">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p1.1.m1.1c">5\%</annotation></semantics></math> increase in train time or compute. The authors show the encryption/decryption process is negligible compared to backpropagation. When faced with an inversion attack, a normal FL algorithm could have its data reconstructed in 120 iterations, but with SHELF, the data was secure after 40,000 iterations <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib70" title="" class="ltx_ref">70</a>]</cite>.</p>
</div>
</section>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Other methods of privacy preservation</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">In addition to DP and HE, other methods have been used to preserve privacy in FL, such as using the aforementioned methods in conjunction with other techniques to optimize security.</p>
</div>
<section id="S3.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.1 </span>A hybrid approach</h4>

<div id="S3.SS3.SSS1.p1" class="ltx_para">
<p id="S3.SS3.SSS1.p1.5" class="ltx_p">A hybrid approach to privacy-preserving FL is proposed in <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib71" title="" class="ltx_ref">71</a>]</cite> that uses DP and secure multi-party computation to balance the trade-off between privacy and accuracy. Combining DP with secure multiparty computation enables this method to reduce the growth of noise injection as the number of parties increases without sacrificing privacy while maintaining a pre-defined rate of trust with a tuneable trust parameter that can account for various scenarios. The trust parameter <math id="S3.SS3.SSS1.p1.1.m1.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S3.SS3.SSS1.p1.1.m1.1a"><mi id="S3.SS3.SSS1.p1.1.m1.1.1" xref="S3.SS3.SSS1.p1.1.m1.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p1.1.m1.1b"><ci id="S3.SS3.SSS1.p1.1.m1.1.1.cmml" xref="S3.SS3.SSS1.p1.1.m1.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p1.1.m1.1c">t</annotation></semantics></math> refers to the minimum number of honest, non-colluding parties the system assumes <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib71" title="" class="ltx_ref">71</a>]</cite>. This parameter captures the degree of possible adversarial knowledge by specifying the maximum number of colluding parties the system can tolerate while still providing privacy guarantees. The noise added by each honest party depends on <math id="S3.SS3.SSS1.p1.2.m2.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S3.SS3.SSS1.p1.2.m2.1a"><mi id="S3.SS3.SSS1.p1.2.m2.1.1" xref="S3.SS3.SSS1.p1.2.m2.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p1.2.m2.1b"><ci id="S3.SS3.SSS1.p1.2.m2.1.1.cmml" xref="S3.SS3.SSS1.p1.2.m2.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p1.2.m2.1c">t</annotation></semantics></math>. As <math id="S3.SS3.SSS1.p1.3.m3.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S3.SS3.SSS1.p1.3.m3.1a"><mi id="S3.SS3.SSS1.p1.3.m3.1.1" xref="S3.SS3.SSS1.p1.3.m3.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p1.3.m3.1b"><ci id="S3.SS3.SSS1.p1.3.m3.1.1.cmml" xref="S3.SS3.SSS1.p1.3.m3.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p1.3.m3.1c">t</annotation></semantics></math> decreases (less trust), more noise needs to be added by each honest party to account for more potential colluders. The threshold encryption scheme uses <math id="S3.SS3.SSS1.p1.4.m4.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S3.SS3.SSS1.p1.4.m4.1a"><mi id="S3.SS3.SSS1.p1.4.m4.1.1" xref="S3.SS3.SSS1.p1.4.m4.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p1.4.m4.1b"><ci id="S3.SS3.SSS1.p1.4.m4.1.1.cmml" xref="S3.SS3.SSS1.p1.4.m4.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p1.4.m4.1c">t</annotation></semantics></math> to set the threshold so that no set of parties less than this threshold can decrypt data. This prevents smaller colluding groups from learning honest parties’ data. The trust parameter <math id="S3.SS3.SSS1.p1.5.m5.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S3.SS3.SSS1.p1.5.m5.1a"><mi id="S3.SS3.SSS1.p1.5.m5.1.1" xref="S3.SS3.SSS1.p1.5.m5.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p1.5.m5.1b"><ci id="S3.SS3.SSS1.p1.5.m5.1.1.cmml" xref="S3.SS3.SSS1.p1.5.m5.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p1.5.m5.1c">t</annotation></semantics></math> is useful in preventing dishonest parties from acting as clients and gaining access to honest clients’ data.</p>
</div>
</section>
<section id="S3.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.2 </span>PrivateKT</h4>

<div id="S3.SS3.SSS2.p1" class="ltx_para">
<p id="S3.SS3.SSS2.p1.1" class="ltx_p">One method that leverages DP to implement private knowledge transfer is PrivateKT <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib72" title="" class="ltx_ref">72</a>]</cite>, a private knowledge transfer method that uses a small subset of public data to transfer knowledge with local DP guarantees. This method actively selects public data points based on the information contents rather than randomly to maximize the knowledge quality. The knowledge transfer method contains three steps:</p>
<ul id="S3.I1" class="ltx_itemize">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.p1.1" class="ltx_p"><em id="S3.I1.i1.p1.1.1" class="ltx_emph ltx_font_italic">Knowledge Extraction</em>: The clients train their models on local private data, then make predictions with their models on a small set of specifically selected public data points (KT data) <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib72" title="" class="ltx_ref">72</a>]</cite>. This process extracts knowledge from private data and uses it to make predictions about public data.</p>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S3.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i2.p1.1" class="ltx_p"><em id="S3.I1.i2.p1.1.1" class="ltx_emph ltx_font_italic">Knowledge Exchange</em>: The clients locally add DP to the public data predictions using a randomized response mechanism to guarantee DP. These DP predictions are then sent to the central server <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib72" title="" class="ltx_ref">72</a>]</cite>.</p>
</div>
</li>
<li id="S3.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S3.I1.i3.p1" class="ltx_para">
<p id="S3.I1.i3.p1.1" class="ltx_p"><em id="S3.I1.i3.p1.1.1" class="ltx_emph ltx_font_italic">Knowledge Aggregation</em>: The central server aggregates DP predictions from all clients and stores them in a knowledge buffer <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib72" title="" class="ltx_ref">72</a>]</cite>.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS3.SSS2.p2" class="ltx_para">
<p id="S3.SS3.SSS2.p2.1" class="ltx_p">knowledge transfer can securely transfer data between models and also provide uncertainty estimation through its functionality. Two methods are implemented to improve the effectiveness of knowledge transfer on a small amount of public data.</p>
<ul id="S3.I2" class="ltx_itemize">
<li id="S3.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S3.I2.i1.p1" class="ltx_para">
<p id="S3.I2.i1.p1.1" class="ltx_p"><em id="S3.I2.i1.p1.1.1" class="ltx_emph ltx_font_italic">Importance Sampling</em> - The model’s uncertainty is measured on each public data point using information entropy, and a higher sampling probability is assigned to data with higher uncertainty <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib72" title="" class="ltx_ref">72</a>]</cite>. This maximizes the information and quality of the knowledge sampled in a small dataset <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib72" title="" class="ltx_ref">72</a>]</cite>.</p>
</div>
</li>
<li id="S3.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S3.I2.i2.p1" class="ltx_para">
<p id="S3.I2.i2.p1.1" class="ltx_p"><em id="S3.I2.i2.p1.1.1" class="ltx_emph ltx_font_italic">Knowledge Buffer</em> - The server stores the DP aggregated predictions from clients in a buffer that maintains a history of past aggregated knowledge <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib72" title="" class="ltx_ref">72</a>]</cite>. This buffer is used to fine-tune the global model, encoding historical knowledge to help mitigate the limitations of a small dataset <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib72" title="" class="ltx_ref">72</a>]</cite>. A knowledge buffer is typically implemented during the knowledge aggregation step.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS3.SSS2.p3" class="ltx_para">
<p id="S3.SS3.SSS2.p3.1" class="ltx_p">PrivateKT is tested on MNIST <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib88" title="" class="ltx_ref">88</a>]</cite>, METText, and a Kaggle X-ray image dataset for pneumonia detection. Under a strict privacy budget, PrivateKT reduces the performance gap with centralized learning by up to <math id="S3.SS3.SSS2.p3.1.m1.1" class="ltx_Math" alttext="84\%" display="inline"><semantics id="S3.SS3.SSS2.p3.1.m1.1a"><mrow id="S3.SS3.SSS2.p3.1.m1.1.1" xref="S3.SS3.SSS2.p3.1.m1.1.1.cmml"><mn id="S3.SS3.SSS2.p3.1.m1.1.1.2" xref="S3.SS3.SSS2.p3.1.m1.1.1.2.cmml">84</mn><mo id="S3.SS3.SSS2.p3.1.m1.1.1.1" xref="S3.SS3.SSS2.p3.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p3.1.m1.1b"><apply id="S3.SS3.SSS2.p3.1.m1.1.1.cmml" xref="S3.SS3.SSS2.p3.1.m1.1.1"><csymbol cd="latexml" id="S3.SS3.SSS2.p3.1.m1.1.1.1.cmml" xref="S3.SS3.SSS2.p3.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S3.SS3.SSS2.p3.1.m1.1.1.2.cmml" xref="S3.SS3.SSS2.p3.1.m1.1.1.2">84</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p3.1.m1.1c">84\%</annotation></semantics></math> compared to other FL methods <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib72" title="" class="ltx_ref">72</a>]</cite>.</p>
</div>
</section>
<section id="S3.SS3.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.3 </span>Multi-RoundSecAgg</h4>

<div id="S3.SS3.SSS3.p1" class="ltx_para">
<p id="S3.SS3.SSS3.p1.1" class="ltx_p">So et al. point out that many privacy preservation methods only provide privacy guarantees for a single communication round <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib73" title="" class="ltx_ref">73</a>]</cite>. The authors propose Multi-RoundSecAgg, which provides privacy guarantees over multiple training rounds. The authors also introduce a new metric to quantify the privacy guarantees of FL over multiple training rounds and develop a structured user section strategy that guarantees the long-term privacy of each user. Multi-RoundSecAgg contains two components: (1) a family of sets of users that satisfy the multi-round privacy requirement, and (2) a set from this family to satisfy a fairness guarantee. The authors found a trade-off between long-term privacy guarantees and the number of participants. As the average number of users increases, long-term privacy becomes weaker <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib73" title="" class="ltx_ref">73</a>]</cite>. Random user selection schemes are shown to provide very weak multi-round privacy. After sufficient rounds (linear in number of users), the server can reconstruct all user models. Multi-RoundSecAgg is a structured user selection strategy with provable multi-round privacy. It partitions users into batches that always participate together. Multi-RoundSecAgg provides a trade-off between privacy and convergence rate. More privacy reduces the average number of users per round, slowing down training. The authors show that structured user selection is necessary for long-term privacy <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib73" title="" class="ltx_ref">73</a>]</cite>.</p>
</div>
</section>
<section id="S3.SS3.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.4 </span>Loss Differential Strategy for Parameter replacement (LDS-FL)</h4>

<div id="S3.SS3.SSS4.p1" class="ltx_para">
<p id="S3.SS3.SSS4.p1.2" class="ltx_p">One method for privacy preservation that takes a different approach entirely is the loss differential strategy for parameter replacement (LDS-FL) <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib74" title="" class="ltx_ref">74</a>]</cite>. The key idea of this strategy is to maintain the performance of a <em id="S3.SS3.SSS4.p1.2.1" class="ltx_emph ltx_font_italic">private model</em> preserved through parameter replacement with multi-user participation. LDS-FL introduces a public participant that shares parameters to enable other private participants to construct <em id="S3.SS3.SSS4.p1.2.2" class="ltx_emph ltx_font_italic">loss differential models</em> without exposing private data. These satisfy an inequality that bounds loss on public, private, and other data. Wang et al. propose a loss differential strategy (LDS) where private participants replace some public parameters with their own to create models that resist privacy attacks. This balances privacy and accuracy <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib74" title="" class="ltx_ref">74</a>]</cite>. The authors formally prove the privacy guarantees of the LDS approach against membership inference attacks. Experiments show that LDS-FL reduces attack accuracy while maintaining model accuracy. The multi-round LDS algorithm enables participants to iteratively construct loss differential models in a privacy-preserving and convergent way during FL <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib74" title="" class="ltx_ref">74</a>]</cite>. Comprehensive experiments on image datasets demonstrate that LDS-FL reduces attack accuracy by over <math id="S3.SS3.SSS4.p1.1.m1.1" class="ltx_Math" alttext="10\%" display="inline"><semantics id="S3.SS3.SSS4.p1.1.m1.1a"><mrow id="S3.SS3.SSS4.p1.1.m1.1.1" xref="S3.SS3.SSS4.p1.1.m1.1.1.cmml"><mn id="S3.SS3.SSS4.p1.1.m1.1.1.2" xref="S3.SS3.SSS4.p1.1.m1.1.1.2.cmml">10</mn><mo id="S3.SS3.SSS4.p1.1.m1.1.1.1" xref="S3.SS3.SSS4.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS4.p1.1.m1.1b"><apply id="S3.SS3.SSS4.p1.1.m1.1.1.cmml" xref="S3.SS3.SSS4.p1.1.m1.1.1"><csymbol cd="latexml" id="S3.SS3.SSS4.p1.1.m1.1.1.1.cmml" xref="S3.SS3.SSS4.p1.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S3.SS3.SSS4.p1.1.m1.1.1.2.cmml" xref="S3.SS3.SSS4.p1.1.m1.1.1.2">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS4.p1.1.m1.1c">10\%</annotation></semantics></math> on MNIST while reducing model accuracy by just <math id="S3.SS3.SSS4.p1.2.m2.1" class="ltx_Math" alttext="0.17\%" display="inline"><semantics id="S3.SS3.SSS4.p1.2.m2.1a"><mrow id="S3.SS3.SSS4.p1.2.m2.1.1" xref="S3.SS3.SSS4.p1.2.m2.1.1.cmml"><mn id="S3.SS3.SSS4.p1.2.m2.1.1.2" xref="S3.SS3.SSS4.p1.2.m2.1.1.2.cmml">0.17</mn><mo id="S3.SS3.SSS4.p1.2.m2.1.1.1" xref="S3.SS3.SSS4.p1.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS4.p1.2.m2.1b"><apply id="S3.SS3.SSS4.p1.2.m2.1.1.cmml" xref="S3.SS3.SSS4.p1.2.m2.1.1"><csymbol cd="latexml" id="S3.SS3.SSS4.p1.2.m2.1.1.1.cmml" xref="S3.SS3.SSS4.p1.2.m2.1.1.1">percent</csymbol><cn type="float" id="S3.SS3.SSS4.p1.2.m2.1.1.2.cmml" xref="S3.SS3.SSS4.p1.2.m2.1.1.2">0.17</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS4.p1.2.m2.1c">0.17\%</annotation></semantics></math> <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib74" title="" class="ltx_ref">74</a>]</cite>. LDS-FL outperforms DP defenses in accuracy and attack resistance. This method does not use DP or HE but rather provides an alternative method for preserving privacy, suggesting other ways to solve the issue of privacy preservation in FL.</p>
</div>
</section>
<section id="S3.SS3.SSS5" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.5 </span>DeTrust-FL</h4>

<div id="S3.SS3.SSS5.p1" class="ltx_para">
<p id="S3.SS3.SSS5.p1.1" class="ltx_p">DeTrust-FL <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib75" title="" class="ltx_ref">75</a>]</cite> proposes a solution to enhance the privacy of FL in a decentralized setting and provides secure aggregation of model updates in a decentralized trust setting. DeTrust-FL improves other PPFL methods by not relying on a centralized trusted authority and vulnerability to inference attacks like dis-aggregation attacks. DeTrust uses a decentralized functional encryption scheme where clients collaboratively generate decryption key fragments based on an agreed participation matrix. using a participation matrix provides transparency and control over the aggregation process, as all participants know what they agree to. Detrust-FL incorporates batch partitioning to prevent dis-aggregation attacks and encrypts model updates with round labels to prevent replay attacks. The authors show that DeTrust-FL achieves state-of-the-art communication efficiency and reduces reliance on a centralized trust entity <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib75" title="" class="ltx_ref">75</a>]</cite>.</p>
</div>
</section>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Privacy preserving FL Frameworks</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p">This section presents Frameworks that have been created to streamline the process of privacy preservation in FL.</p>
</div>
<section id="S3.SS4.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.4.1 </span>Argonne Privacy-Preserving Framework (APPFL)</h4>

<div id="S3.SS4.SSS1.p1" class="ltx_para">
<p id="S3.SS4.SSS1.p1.1" class="ltx_p">APPFL provides an open-source Python package that provides tools for users to run FL experiments with additional privacy preservation tools <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib89" title="" class="ltx_ref">89</a>]</cite>. There are five main components of this framework:</p>
<ul id="S3.I3" class="ltx_itemize">
<li id="S3.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S3.I3.i1.p1" class="ltx_para">
<p id="S3.I3.i1.p1.1" class="ltx_p">FL algorithms</p>
</div>
</li>
<li id="S3.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S3.I3.i2.p1" class="ltx_para">
<p id="S3.I3.i2.p1.1" class="ltx_p">DP schemes</p>
</div>
</li>
<li id="S3.I3.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S3.I3.i3.p1" class="ltx_para">
<p id="S3.I3.i3.p1.1" class="ltx_p">Communication protocols</p>
</div>
</li>
<li id="S3.I3.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="S3.I3.i4.p1" class="ltx_para">
<p id="S3.I3.i4.p1.1" class="ltx_p">Neural network models</p>
</div>
</li>
<li id="S3.I3.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">5.</span> 
<div id="S3.I3.i5.p1" class="ltx_para">
<p id="S3.I3.i5.p1.1" class="ltx_p">Data for training and testing</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS4.SSS1.p2" class="ltx_para">
<p id="S3.SS4.SSS1.p2.1" class="ltx_p">The APPFL framework provides users with the tools to conduct their experiments with FL and allows for flexibility in model choice and the ability to implement custom models <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib89" title="" class="ltx_ref">89</a>]</cite>. APPFL also provides a communication-efficient inexact alternating direction method of multipliers (IIADMM) based on the Alternating Direction Method of Multipliers (ADMM) <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib90" title="" class="ltx_ref">90</a>]</cite>. The IIADMM algorithm significantly reduces the amount of information transferred between the server and the clients compared to similar algorithms.</p>
</div>
</section>
<section id="S3.SS4.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.4.2 </span>Privacy-preserving Medical Image Analysis (PriMIA)</h4>

<div id="S3.SS4.SSS2.p1" class="ltx_para">
<p id="S3.SS4.SSS2.p1.1" class="ltx_p">PriMIA is an open-source software framework for differentially private, securely aggregated FL and encrypted inference on medical imaging data <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib91" title="" class="ltx_ref">91</a>]</cite>. The authors tested PriMIA using a real-life case study on pediatric chest X-rays. They found their privacy-preserving federated model was on par with local non-securely trained models. They theoretically and empirically evaluate the framework’s performance and privacy guarantees and demonstrate that the protections provided prevent the reconstruction of usable data by a gradient-based model inversion attack <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib91" title="" class="ltx_ref">91</a>]</cite>. The authors successfully employ the trained model in an end-to-end encrypted remote inference scenario using secure multi-party computation to prevent the disclosure of the data and the model.</p>
</div>
</section>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Uncertainty Estimation in FL</h2>

<figure id="S4.F5" class="ltx_figure"><img src="/html/2406.12815/assets/figs/5.png" id="S4.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="285" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Summary of uncertainty estimation methods in FL.</figcaption>
</figure>
<figure id="S4.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span> Uncertainty Estimation Methods in FL.</figcaption>
<table id="S4.T3.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T3.1.1.1" class="ltx_tr">
<th id="S4.T3.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_th_row ltx_border_tt">
<span id="S4.T3.1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.1.1.1.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Algorithm</span></span>
</span>
</th>
<th id="S4.T3.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt"><span id="S4.T3.1.1.1.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Ref</span></th>
<th id="S4.T3.1.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S4.T3.1.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.1.1.3.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.1.1.3.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Conformal Prediction (CP)</span></span>
</span>
</th>
<th id="S4.T3.1.1.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S4.T3.1.1.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.1.1.4.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.1.1.4.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Distilled Prediction</span></span>
</span>
</th>
<th id="S4.T3.1.1.1.5" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S4.T3.1.1.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.1.1.5.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.1.1.5.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Bayesian</span></span>
</span>
</th>
<th id="S4.T3.1.1.1.6" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S4.T3.1.1.1.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.1.1.6.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.1.1.6.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Calibration</span></span>
</span>
</th>
<th id="S4.T3.1.1.1.7" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S4.T3.1.1.1.7.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.1.1.7.1.1" class="ltx_p" style="width:199.2pt;"><span id="S4.T3.1.1.1.7.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Summary</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T3.1.2.1" class="ltx_tr">
<th id="S4.T3.1.2.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_tt">
<span id="S4.T3.1.2.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.2.1.1.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.2.1.1.1.1.1" class="ltx_text" style="font-size:80%;">Fed-ensemble</span></span>
</span>
</th>
<th id="S4.T3.1.2.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt"><cite class="ltx_cite ltx_citemacro_citep"><span id="S4.T3.1.2.1.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib92" title="" class="ltx_ref">92</a><span id="S4.T3.1.2.1.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></th>
<td id="S4.T3.1.2.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S4.T3.1.2.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.2.1.3.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.2.1.3.1.1.1" class="ltx_text" style="font-size:80%;">no</span></span>
</span>
</td>
<td id="S4.T3.1.2.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S4.T3.1.2.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.2.1.4.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.2.1.4.1.1.1" class="ltx_text" style="font-size:80%;">no</span></span>
</span>
</td>
<td id="S4.T3.1.2.1.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S4.T3.1.2.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.2.1.5.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.2.1.5.1.1.1" class="ltx_text" style="font-size:80%;">no</span></span>
</span>
</td>
<td id="S4.T3.1.2.1.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S4.T3.1.2.1.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.2.1.6.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.2.1.6.1.1.1" class="ltx_text" style="font-size:80%;">no</span></span>
</span>
</td>
<td id="S4.T3.1.2.1.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S4.T3.1.2.1.7.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.2.1.7.1.1" class="ltx_p" style="width:199.2pt;"><span id="S4.T3.1.2.1.7.1.1.1" class="ltx_text" style="font-size:80%;">Extends ensembling methods to FL; characterizes uncertainty in predictions by using the variance in the predictions as a measure of knowledge uncertainty.</span></span>
</span>
</td>
</tr>
<tr id="S4.T3.1.3.2" class="ltx_tr">
<th id="S4.T3.1.3.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_t">
<span id="S4.T3.1.3.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.3.2.1.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.3.2.1.1.1.1" class="ltx_text" style="font-size:80%;">DP-fedCP</span></span>
</span>
</th>
<th id="S4.T3.1.3.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><cite class="ltx_cite ltx_citemacro_citep"><span id="S4.T3.1.3.2.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib93" title="" class="ltx_ref">93</a><span id="S4.T3.1.3.2.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></th>
<td id="S4.T3.1.3.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.3.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.3.2.3.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.3.2.3.1.1.1" class="ltx_text" style="font-size:80%;">yes</span></span>
</span>
</td>
<td id="S4.T3.1.3.2.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.3.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.3.2.4.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.3.2.4.1.1.1" class="ltx_text" style="font-size:80%;">no</span></span>
</span>
</td>
<td id="S4.T3.1.3.2.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.3.2.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.3.2.5.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.3.2.5.1.1.1" class="ltx_text" style="font-size:80%;">no</span></span>
</span>
</td>
<td id="S4.T3.1.3.2.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.3.2.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.3.2.6.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.3.2.6.1.1.1" class="ltx_text" style="font-size:80%;">no</span></span>
</span>
</td>
<td id="S4.T3.1.3.2.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.3.2.7.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.3.2.7.1.1" class="ltx_p" style="width:199.2pt;"><span id="S4.T3.1.3.2.7.1.1.1" class="ltx_text" style="font-size:80%;">Differentially Private Federated Average Quantile Estimation (DP-fedCP); the method is designed to construct personalized CP sets in an FL scenario.</span></span>
</span>
</td>
</tr>
<tr id="S4.T3.1.4.3" class="ltx_tr">
<th id="S4.T3.1.4.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_t">
<span id="S4.T3.1.4.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.4.3.1.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.4.3.1.1.1.1" class="ltx_text" style="font-size:80%;">FCP</span></span>
</span>
</th>
<th id="S4.T3.1.4.3.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><cite class="ltx_cite ltx_citemacro_citep"><span id="S4.T3.1.4.3.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib94" title="" class="ltx_ref">94</a><span id="S4.T3.1.4.3.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></th>
<td id="S4.T3.1.4.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.4.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.4.3.3.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.4.3.3.1.1.1" class="ltx_text" style="font-size:80%;">yes</span></span>
</span>
</td>
<td id="S4.T3.1.4.3.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.4.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.4.3.4.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.4.3.4.1.1.1" class="ltx_text" style="font-size:80%;">no</span></span>
</span>
</td>
<td id="S4.T3.1.4.3.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.4.3.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.4.3.5.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.4.3.5.1.1.1" class="ltx_text" style="font-size:80%;">no</span></span>
</span>
</td>
<td id="S4.T3.1.4.3.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.4.3.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.4.3.6.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.4.3.6.1.1.1" class="ltx_text" style="font-size:80%;">no</span></span>
</span>
</td>
<td id="S4.T3.1.4.3.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.4.3.7.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.4.3.7.1.1" class="ltx_p" style="width:199.2pt;"><span id="S4.T3.1.4.3.7.1.1.1" class="ltx_text" style="font-size:80%;">Federated CP, a framework for extending CP to FL that addresses the non-i.i.d. nature of data in FL.</span></span>
</span>
</td>
</tr>
<tr id="S4.T3.1.5.4" class="ltx_tr">
<th id="S4.T3.1.5.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_t">
<span id="S4.T3.1.5.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.5.4.1.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.5.4.1.1.1.1" class="ltx_text" style="font-size:80%;">FedPPD</span></span>
</span>
</th>
<th id="S4.T3.1.5.4.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><cite class="ltx_cite ltx_citemacro_citep"><span id="S4.T3.1.5.4.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib95" title="" class="ltx_ref">95</a><span id="S4.T3.1.5.4.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></th>
<td id="S4.T3.1.5.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.5.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.5.4.3.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.5.4.3.1.1.1" class="ltx_text" style="font-size:80%;">no</span></span>
</span>
</td>
<td id="S4.T3.1.5.4.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.5.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.5.4.4.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.5.4.4.1.1.1" class="ltx_text" style="font-size:80%;">yes</span></span>
</span>
</td>
<td id="S4.T3.1.5.4.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.5.4.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.5.4.5.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.5.4.5.1.1.1" class="ltx_text" style="font-size:80%;">no</span></span>
</span>
</td>
<td id="S4.T3.1.5.4.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.5.4.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.5.4.6.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.5.4.6.1.1.1" class="ltx_text" style="font-size:80%;">no</span></span>
</span>
</td>
<td id="S4.T3.1.5.4.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.5.4.7.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.5.4.7.1.1" class="ltx_p" style="width:199.2pt;"><span id="S4.T3.1.5.4.7.1.1.1" class="ltx_text" style="font-size:80%;">Framework for FL with uncertainty, where, in every round, each client infers the posterior distribution over its parameters
and the posterior predictive distribution (PPD); PPD is sent to the server.</span></span>
</span>
</td>
</tr>
<tr id="S4.T3.1.6.5" class="ltx_tr">
<th id="S4.T3.1.6.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_t">
<span id="S4.T3.1.6.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.6.5.1.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.6.5.1.1.1.1" class="ltx_text" style="font-size:80%;">FedUA</span></span>
</span>
</th>
<th id="S4.T3.1.6.5.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><cite class="ltx_cite ltx_citemacro_citep"><span id="S4.T3.1.6.5.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib96" title="" class="ltx_ref">96</a><span id="S4.T3.1.6.5.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></th>
<td id="S4.T3.1.6.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.6.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.6.5.3.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.6.5.3.1.1.1" class="ltx_text" style="font-size:80%;">no</span></span>
</span>
</td>
<td id="S4.T3.1.6.5.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.6.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.6.5.4.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.6.5.4.1.1.1" class="ltx_text" style="font-size:80%;">yes</span></span>
</span>
</td>
<td id="S4.T3.1.6.5.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.6.5.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.6.5.5.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.6.5.5.1.1.1" class="ltx_text" style="font-size:80%;">no</span></span>
</span>
</td>
<td id="S4.T3.1.6.5.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.6.5.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.6.5.6.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.6.5.6.1.1.1" class="ltx_text" style="font-size:80%;">no</span></span>
</span>
</td>
<td id="S4.T3.1.6.5.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.6.5.7.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.6.5.7.1.1" class="ltx_p" style="width:199.2pt;"><span id="S4.T3.1.6.5.7.1.1.1" class="ltx_text" style="font-size:80%;">Fed uncertainty aware - Each client’s uncertainty is quantified; a sample quality evaluator selects high-quality samples for global model training; knowledge distillation s used in the aggregation process to transfer inter-class relationships from the local models and suppress noise from incomplete client data.</span></span>
</span>
</td>
</tr>
<tr id="S4.T3.1.7.6" class="ltx_tr">
<th id="S4.T3.1.7.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_t">
<span id="S4.T3.1.7.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.7.6.1.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.7.6.1.1.1.1" class="ltx_text" style="font-size:80%;">FedBNN</span></span>
</span>
</th>
<th id="S4.T3.1.7.6.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><cite class="ltx_cite ltx_citemacro_citep"><span id="S4.T3.1.7.6.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib97" title="" class="ltx_ref">97</a><span id="S4.T3.1.7.6.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></th>
<td id="S4.T3.1.7.6.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.7.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.7.6.3.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.7.6.3.1.1.1" class="ltx_text" style="font-size:80%;">no</span></span>
</span>
</td>
<td id="S4.T3.1.7.6.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.7.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.7.6.4.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.7.6.4.1.1.1" class="ltx_text" style="font-size:80%;">no</span></span>
</span>
</td>
<td id="S4.T3.1.7.6.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.7.6.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.7.6.5.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.7.6.5.1.1.1" class="ltx_text" style="font-size:80%;">yes</span></span>
</span>
</td>
<td id="S4.T3.1.7.6.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.7.6.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.7.6.6.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.7.6.6.1.1.1" class="ltx_text" style="font-size:80%;">no</span></span>
</span>
</td>
<td id="S4.T3.1.7.6.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.7.6.7.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.7.6.7.1.1" class="ltx_p" style="width:199.2pt;"><span id="S4.T3.1.7.6.7.1.1.1" class="ltx_text" style="font-size:80%;">FL framework based on training a customized local Bayesian model for each client.</span></span>
</span>
</td>
</tr>
<tr id="S4.T3.1.8.7" class="ltx_tr">
<th id="S4.T3.1.8.7.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_t">
<span id="S4.T3.1.8.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.8.7.1.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.8.7.1.1.1.1" class="ltx_text" style="font-size:80%;">pFL</span></span>
</span>
</th>
<th id="S4.T3.1.8.7.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><cite class="ltx_cite ltx_citemacro_citep"><span id="S4.T3.1.8.7.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib98" title="" class="ltx_ref">98</a><span id="S4.T3.1.8.7.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></th>
<td id="S4.T3.1.8.7.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.8.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.8.7.3.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.8.7.3.1.1.1" class="ltx_text" style="font-size:80%;">no</span></span>
</span>
</td>
<td id="S4.T3.1.8.7.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.8.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.8.7.4.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.8.7.4.1.1.1" class="ltx_text" style="font-size:80%;">no</span></span>
</span>
</td>
<td id="S4.T3.1.8.7.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.8.7.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.8.7.5.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.8.7.5.1.1.1" class="ltx_text" style="font-size:80%;">yes</span></span>
</span>
</td>
<td id="S4.T3.1.8.7.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.8.7.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.8.7.6.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.8.7.6.1.1.1" class="ltx_text" style="font-size:80%;">no</span></span>
</span>
</td>
<td id="S4.T3.1.8.7.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.8.7.7.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.8.7.7.1.1" class="ltx_p" style="width:199.2pt;"><span id="S4.T3.1.8.7.7.1.1.1" class="ltx_text" style="font-size:80%;">The personalized FL (pFL) trains personalized local models to cater to the datasets while still being able to learn from a larger data pool.</span></span>
</span>
</td>
</tr>
<tr id="S4.T3.1.9.8" class="ltx_tr">
<th id="S4.T3.1.9.8.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_t">
<span id="S4.T3.1.9.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.9.8.1.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.9.8.1.1.1.1" class="ltx_text" style="font-size:80%;">Self-FL</span></span>
</span>
</th>
<th id="S4.T3.1.9.8.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><cite class="ltx_cite ltx_citemacro_citep"><span id="S4.T3.1.9.8.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib99" title="" class="ltx_ref">99</a><span id="S4.T3.1.9.8.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></th>
<td id="S4.T3.1.9.8.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.9.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.9.8.3.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.9.8.3.1.1.1" class="ltx_text" style="font-size:80%;">no</span></span>
</span>
</td>
<td id="S4.T3.1.9.8.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.9.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.9.8.4.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.9.8.4.1.1.1" class="ltx_text" style="font-size:80%;">no</span></span>
</span>
</td>
<td id="S4.T3.1.9.8.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.9.8.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.9.8.5.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.9.8.5.1.1.1" class="ltx_text" style="font-size:80%;">yes</span></span>
</span>
</td>
<td id="S4.T3.1.9.8.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.9.8.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.9.8.6.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.9.8.6.1.1.1" class="ltx_text" style="font-size:80%;">no</span></span>
</span>
</td>
<td id="S4.T3.1.9.8.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.9.8.7.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.9.8.7.1.1" class="ltx_p" style="width:199.2pt;"><span id="S4.T3.1.9.8.7.1.1.1" class="ltx_text" style="font-size:80%;">Self-aware personalized FL method that uses intra-client and inter-client uncertainty estimation to balance the training of its local personal model and global model.</span></span>
</span>
</td>
</tr>
<tr id="S4.T3.1.10.9" class="ltx_tr">
<th id="S4.T3.1.10.9.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_t">
<span id="S4.T3.1.10.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.10.9.1.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.10.9.1.1.1.1" class="ltx_text" style="font-size:80%;">pFedBays</span></span>
</span>
</th>
<th id="S4.T3.1.10.9.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><cite class="ltx_cite ltx_citemacro_citep"><span id="S4.T3.1.10.9.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib100" title="" class="ltx_ref">100</a><span id="S4.T3.1.10.9.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></th>
<td id="S4.T3.1.10.9.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.10.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.10.9.3.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.10.9.3.1.1.1" class="ltx_text" style="font-size:80%;">no</span></span>
</span>
</td>
<td id="S4.T3.1.10.9.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.10.9.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.10.9.4.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.10.9.4.1.1.1" class="ltx_text" style="font-size:80%;">no</span></span>
</span>
</td>
<td id="S4.T3.1.10.9.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.10.9.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.10.9.5.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.10.9.5.1.1.1" class="ltx_text" style="font-size:80%;">yes</span></span>
</span>
</td>
<td id="S4.T3.1.10.9.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.10.9.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.10.9.6.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.10.9.6.1.1.1" class="ltx_text" style="font-size:80%;">no</span></span>
</span>
</td>
<td id="S4.T3.1.10.9.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.10.9.7.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.10.9.7.1.1" class="ltx_p" style="width:199.2pt;"><span id="S4.T3.1.10.9.7.1.1.1" class="ltx_text" style="font-size:80%;">Weight uncertainty is introduced in client and server neural networks; to achieve personalization, each client updates its local distribution parameters by balancing its construction error over private data.</span></span>
</span>
</td>
</tr>
<tr id="S4.T3.1.11.10" class="ltx_tr">
<th id="S4.T3.1.11.10.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_t">
<span id="S4.T3.1.11.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.11.10.1.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.11.10.1.1.1.1" class="ltx_text" style="font-size:80%;">Fedpop</span></span>
</span>
</th>
<th id="S4.T3.1.11.10.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><cite class="ltx_cite ltx_citemacro_citep"><span id="S4.T3.1.11.10.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib101" title="" class="ltx_ref">101</a><span id="S4.T3.1.11.10.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></th>
<td id="S4.T3.1.11.10.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.11.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.11.10.3.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.11.10.3.1.1.1" class="ltx_text" style="font-size:80%;">no</span></span>
</span>
</td>
<td id="S4.T3.1.11.10.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.11.10.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.11.10.4.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.11.10.4.1.1.1" class="ltx_text" style="font-size:80%;">no</span></span>
</span>
</td>
<td id="S4.T3.1.11.10.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.11.10.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.11.10.5.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.11.10.5.1.1.1" class="ltx_text" style="font-size:80%;">yes</span></span>
</span>
</td>
<td id="S4.T3.1.11.10.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.11.10.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.11.10.6.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.11.10.6.1.1.1" class="ltx_text" style="font-size:80%;">no</span></span>
</span>
</td>
<td id="S4.T3.1.11.10.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.11.10.7.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.11.10.7.1.1" class="ltx_p" style="width:199.2pt;"><span id="S4.T3.1.11.10.7.1.1.1" class="ltx_text" style="font-size:80%;">Each client has a local model composed of fixed population parameters that are shared across clients, as well as random effects that explain heterogeneity in the local data.</span></span>
</span>
</td>
</tr>
<tr id="S4.T3.1.12.11" class="ltx_tr">
<th id="S4.T3.1.12.11.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_t">
<span id="S4.T3.1.12.11.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.12.11.1.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.12.11.1.1.1.1" class="ltx_text" style="font-size:80%;">FedFA</span></span>
</span>
</th>
<th id="S4.T3.1.12.11.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><cite class="ltx_cite ltx_citemacro_citep"><span id="S4.T3.1.12.11.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib102" title="" class="ltx_ref">102</a><span id="S4.T3.1.12.11.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></th>
<td id="S4.T3.1.12.11.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.12.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.12.11.3.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.12.11.3.1.1.1" class="ltx_text" style="font-size:80%;">no</span></span>
</span>
</td>
<td id="S4.T3.1.12.11.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.12.11.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.12.11.4.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.12.11.4.1.1.1" class="ltx_text" style="font-size:80%;">no</span></span>
</span>
</td>
<td id="S4.T3.1.12.11.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.12.11.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.12.11.5.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.12.11.5.1.1.1" class="ltx_text" style="font-size:80%;">no</span></span>
</span>
</td>
<td id="S4.T3.1.12.11.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.12.11.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.12.11.6.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.12.11.6.1.1.1" class="ltx_text" style="font-size:80%;">no</span></span>
</span>
</td>
<td id="S4.T3.1.12.11.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.12.11.7.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.12.11.7.1.1" class="ltx_p" style="width:199.2pt;"><span id="S4.T3.1.12.11.7.1.1.1" class="ltx_text" style="font-size:80%;">Feature anchors are used to align features and calibrate classifiers across clients simultaneously; this enables client models to be updated in a shared feature space with consistent classifiers during local training.</span></span>
</span>
</td>
</tr>
<tr id="S4.T3.1.13.12" class="ltx_tr">
<th id="S4.T3.1.13.12.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_t">
<span id="S4.T3.1.13.12.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.13.12.1.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.13.12.1.1.1.1" class="ltx_text" style="font-size:80%;">FedAG</span></span>
</span>
</th>
<th id="S4.T3.1.13.12.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">
<cite class="ltx_cite ltx_citemacro_citep"><span id="S4.T3.1.13.12.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib103" title="" class="ltx_ref">103</a><span id="S4.T3.1.13.12.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite><span id="S4.T3.1.13.12.2.3" class="ltx_text" style="font-size:80%;">)</span>
</th>
<td id="S4.T3.1.13.12.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.13.12.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.13.12.3.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.13.12.3.1.1.1" class="ltx_text" style="font-size:80%;">no</span></span>
</span>
</td>
<td id="S4.T3.1.13.12.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.13.12.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.13.12.4.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.13.12.4.1.1.1" class="ltx_text" style="font-size:80%;">no</span></span>
</span>
</td>
<td id="S4.T3.1.13.12.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.13.12.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.13.12.5.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.13.12.5.1.1.1" class="ltx_text" style="font-size:80%;">no</span></span>
</span>
</td>
<td id="S4.T3.1.13.12.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.13.12.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.13.12.6.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.13.12.6.1.1.1" class="ltx_text" style="font-size:80%;">no</span></span>
</span>
</td>
<td id="S4.T3.1.13.12.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.13.12.7.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.13.12.7.1.1" class="ltx_p" style="width:199.2pt;"><span id="S4.T3.1.13.12.7.1.1.1" class="ltx_text" style="font-size:80%;">By introducing weight uncertainty in the aggregation step of FedAvg algorithm, the end devices can calculate probabilistic predictions but only have to learn conventional, deterministic models.</span></span>
</span>
</td>
</tr>
<tr id="S4.T3.1.14.13" class="ltx_tr">
<th id="S4.T3.1.14.13.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_t">
<span id="S4.T3.1.14.13.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.14.13.1.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.14.13.1.1.1.1" class="ltx_text" style="font-size:80%;">CCVR</span></span>
</span>
</th>
<th id="S4.T3.1.14.13.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><cite class="ltx_cite ltx_citemacro_citep"><span id="S4.T3.1.14.13.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib104" title="" class="ltx_ref">104</a><span id="S4.T3.1.14.13.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></th>
<td id="S4.T3.1.14.13.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.14.13.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.14.13.3.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.14.13.3.1.1.1" class="ltx_text" style="font-size:80%;">no</span></span>
</span>
</td>
<td id="S4.T3.1.14.13.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.14.13.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.14.13.4.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.14.13.4.1.1.1" class="ltx_text" style="font-size:80%;">no</span></span>
</span>
</td>
<td id="S4.T3.1.14.13.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.14.13.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.14.13.5.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.14.13.5.1.1.1" class="ltx_text" style="font-size:80%;">no</span></span>
</span>
</td>
<td id="S4.T3.1.14.13.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.14.13.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.14.13.6.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.14.13.6.1.1.1" class="ltx_text" style="font-size:80%;">yes</span></span>
</span>
</td>
<td id="S4.T3.1.14.13.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.14.13.7.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.14.13.7.1.1" class="ltx_p" style="width:199.2pt;"><span id="S4.T3.1.14.13.7.1.1.1" class="ltx_text" style="font-size:80%;">Classifier calibration with Virtual Representation (CCVR) Found a greater bias in representations learned in the deeper layers of a model trained with FL; they show that the classifier contains the greatest bias toward local client data and that classification performance can be greatly improved with post-training classifier calibration calibration</span></span>
</span>
</td>
</tr>
<tr id="S4.T3.1.15.14" class="ltx_tr">
<th id="S4.T3.1.15.14.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_bb ltx_border_t">
<span id="S4.T3.1.15.14.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.15.14.1.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.15.14.1.1.1.1" class="ltx_text" style="font-size:80%;">FedCSPC</span></span>
</span>
</th>
<th id="S4.T3.1.15.14.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t"><cite class="ltx_cite ltx_citemacro_citep"><span id="S4.T3.1.15.14.2.1.1" class="ltx_text" style="font-size:80%;">[</span><a href="#bib.bib105" title="" class="ltx_ref">105</a><span id="S4.T3.1.15.14.2.2.2" class="ltx_text" style="font-size:80%;">]</span></cite></th>
<td id="S4.T3.1.15.14.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S4.T3.1.15.14.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.15.14.3.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.15.14.3.1.1.1" class="ltx_text" style="font-size:80%;">no</span></span>
</span>
</td>
<td id="S4.T3.1.15.14.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S4.T3.1.15.14.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.15.14.4.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.15.14.4.1.1.1" class="ltx_text" style="font-size:80%;">no</span></span>
</span>
</td>
<td id="S4.T3.1.15.14.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S4.T3.1.15.14.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.15.14.5.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.15.14.5.1.1.1" class="ltx_text" style="font-size:80%;">no</span></span>
</span>
</td>
<td id="S4.T3.1.15.14.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S4.T3.1.15.14.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.15.14.6.1.1" class="ltx_p" style="width:28.5pt;"><span id="S4.T3.1.15.14.6.1.1.1" class="ltx_text" style="font-size:80%;">yes</span></span>
</span>
</td>
<td id="S4.T3.1.15.14.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S4.T3.1.15.14.7.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.15.14.7.1.1" class="ltx_p" style="width:199.2pt;"><span id="S4.T3.1.15.14.7.1.1.1" class="ltx_text" style="font-size:80%;">This method takes additional prototype information from the clients to learn a unified feature space on the server side while maintaining
clear boundaries.</span></span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">Another critical area in FL for medical imaging is uncertainty quantification or estimation. Once data privacy is ensured, assessing the quality of the model becomes a crucial focus for researchers. For FL to excel in the medical imaging field, it is essential to have a method for measuring how certain the model is about its predictions. Additionally, there should be a mechanism to alert a human operator when the model’s certainty falls below acceptable levels. The unique challenge in FL for medical imaging arises from its non-i.i.d nature, which complicates the quantification of certainty. This complexity is further exacerbated by the phenomenon where local certainty might be high, but global certainty is low, and vice versa. This section will discuss various methods to implement uncertainty estimation in FL settings. Figure <a href="#S4.F5" title="Figure 5 ‣ 4 Uncertainty Estimation in FL ‣ Privacy Preserving Federated Learning in Medical Imaging with Uncertainty Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> and Table <a href="#S4.T3" title="Table 3 ‣ 4 Uncertainty Estimation in FL ‣ Privacy Preserving Federated Learning in Medical Imaging with Uncertainty Estimation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> summarize the uncertainty estimation methods presented in this section.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Model Ensembling</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">Model ensembling is a popular uncertainty estimation method and involves running inference with an ensemble of models and taking the average <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib106" title="" class="ltx_ref">106</a>]</cite>. This naturally extends to FL because of the distributed nature of the FL setup involving multiple clients that can serve as multiple models. The approach in <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> Integrates multiple ensembling methods into an uncertainty estimation framework for FL. The variations of FL ensembling used include <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>:</p>
<ul id="S4.I1" class="ltx_itemize">
<li id="S4.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S4.I1.i1.p1" class="ltx_para">
<p id="S4.I1.i1.p1.1" class="ltx_p"><span id="S4.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Ensemble of local models</span>:
This method is a naive way of incorporating deep ensemble-based uncertainty estimation into FL <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>. This method treats each worker’s local model as an ensemble member. Not all the workers communicate with the coordinator, which leads to a <math id="S4.I1.i1.p1.1.m1.1" class="ltx_Math" alttext="m" display="inline"><semantics id="S4.I1.i1.p1.1.m1.1a"><mi id="S4.I1.i1.p1.1.m1.1.1" xref="S4.I1.i1.p1.1.m1.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S4.I1.i1.p1.1.m1.1b"><ci id="S4.I1.i1.p1.1.m1.1.1.cmml" xref="S4.I1.i1.p1.1.m1.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i1.p1.1.m1.1c">m</annotation></semantics></math> number of separately trained models. These models are then used for final prediction. However, the main idea of FL is lost here due to the lack of communication <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>.</p>
</div>
</li>
<li id="S4.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S4.I1.i2.p1" class="ltx_para">
<p id="S4.I1.i2.p1.3" class="ltx_p"><span id="S4.I1.i2.p1.3.1" class="ltx_text ltx_font_bold">Ensemble of global models</span>: In this approach, the idea of FL is preserved, however computational overhead is increased <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>. Each worker trains <math id="S4.I1.i2.p1.1.m1.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S4.I1.i2.p1.1.m1.1a"><mi id="S4.I1.i2.p1.1.m1.1.1" xref="S4.I1.i2.p1.1.m1.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S4.I1.i2.p1.1.m1.1b"><ci id="S4.I1.i2.p1.1.m1.1.1.cmml" xref="S4.I1.i2.p1.1.m1.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i2.p1.1.m1.1c">S</annotation></semantics></math> ML models with different random initialization seeds to train each model. For each <math id="S4.I1.i2.p1.2.m2.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S4.I1.i2.p1.2.m2.1a"><mi id="S4.I1.i2.p1.2.m2.1.1" xref="S4.I1.i2.p1.2.m2.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S4.I1.i2.p1.2.m2.1b"><ci id="S4.I1.i2.p1.2.m2.1.1.cmml" xref="S4.I1.i2.p1.2.m2.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i2.p1.2.m2.1c">S</annotation></semantics></math> model, an FL workflow is executed. This can quickly become computationally expensive as <math id="S4.I1.i2.p1.3.m3.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S4.I1.i2.p1.3.m3.1a"><mi id="S4.I1.i2.p1.3.m3.1.1" xref="S4.I1.i2.p1.3.m3.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S4.I1.i2.p1.3.m3.1b"><ci id="S4.I1.i2.p1.3.m3.1.1.cmml" xref="S4.I1.i2.p1.3.m3.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i2.p1.3.m3.1c">S</annotation></semantics></math> increases <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>.</p>
</div>
</li>
<li id="S4.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S4.I1.i3.p1" class="ltx_para">
<p id="S4.I1.i3.p1.1" class="ltx_p"><span id="S4.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">Ensemble based on multiple coordinators</span>: These methods split the workers into subgroups and assign a coordinator to each subgroup <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>. FL is carried out as normal among the subgroups, and the outputs of each subgroup are averaged to produce the final prediction.</p>
</div>
</li>
</ul>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p">Each method presents advantages and challenges, necessitating careful consideration when used in FL applications in real-world settings.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.1" class="ltx_p">The ensemble of local models emphasizes privacy and simplicity by treating each worker’s model as an independent ensemble member. While this approach maximizes data privacy and is straightforward to implement, it diverges from the collaborative essence of FL. It may result in inconsistent model performance due to isolated training environments. Conversely, the ensemble of global models aligns with the collaborative learning principle of FL, enhancing model robustness by integrating diverse perspectives. However, this method significantly increases computational and communication demands, posing scalability challenges as the number of clients grows.
The third approach, employing multiple coordinators, offers improved scalability by distributing the workload and tailoring learning strategies within subgroups. However, this method introduces additional complexity in coordination and risks learning fragmentation across subgroups.
To navigate these trade-offs, considering hybrid or adaptive ensembling strategies that balance computational efficiency with the benefits of collaborative learning could be beneficial. Ultimately, selecting an ensembling method should be guided by the application’s specific needs, including privacy requirements, available computational resources, and data heterogeneity.</p>
</div>
<section id="S4.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.1 </span>Fed-ensemble</h4>

<div id="S4.SS1.SSS1.p1" class="ltx_para">
<p id="S4.SS1.SSS1.p1.5" class="ltx_p">Fed-ensemble <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib92" title="" class="ltx_ref">92</a>]</cite> extends ensembling methods for FL using a different approach. Instead of aggregating local models to update a single global model, this method uses random permutations to update a group of <math id="S4.SS1.SSS1.p1.1.m1.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S4.SS1.SSS1.p1.1.m1.1a"><mi id="S4.SS1.SSS1.p1.1.m1.1.1" xref="S4.SS1.SSS1.p1.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p1.1.m1.1b"><ci id="S4.SS1.SSS1.p1.1.m1.1.1.cmml" xref="S4.SS1.SSS1.p1.1.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.p1.1.m1.1c">K</annotation></semantics></math> models and obtains predictions using model averaging. This method imposes no additional computational costs and can readily be utilized within established FL algorithms. The authors empirically show that the proposed approach performs superior to other methods on many datasets. It also excels in heterogeneous settings, which is consistent with many FL applications like medical imaging. Fed-ensemble can characterize uncertainty in predictions by using the variance in the predictions as a measure of knowledge uncertainty. Shi et. al <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib92" title="" class="ltx_ref">92</a>]</cite> propose performing ensemble FL that updates <math id="S4.SS1.SSS1.p1.2.m2.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S4.SS1.SSS1.p1.2.m2.1a"><mi id="S4.SS1.SSS1.p1.2.m2.1.1" xref="S4.SS1.SSS1.p1.2.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p1.2.m2.1b"><ci id="S4.SS1.SSS1.p1.2.m2.1.1.cmml" xref="S4.SS1.SSS1.p1.2.m2.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.p1.2.m2.1c">K</annotation></semantics></math> models over local datasets. Point predictions are obtained by model averaging. The authors show that the Fed-ensemble excels at uncertainty quantification when tested on CIFAR-10 <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib66" title="" class="ltx_ref">66</a>]</cite> CIFAR-100 <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib107" title="" class="ltx_ref">107</a>]</cite>, MNIST, and the Openimagesv4 dataset <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib108" title="" class="ltx_ref">108</a>]</cite> in both homogeneous and heterogeneous settings. Using NTK, they show that predictions at new data points from all <math id="S4.SS1.SSS1.p1.3.m3.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S4.SS1.SSS1.p1.3.m3.1a"><mi id="S4.SS1.SSS1.p1.3.m3.1.1" xref="S4.SS1.SSS1.p1.3.m3.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p1.3.m3.1b"><ci id="S4.SS1.SSS1.p1.3.m3.1.1.cmml" xref="S4.SS1.SSS1.p1.3.m3.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.p1.3.m3.1c">K</annotation></semantics></math> models converge to samples from the same, limiting the Gaussian process in sufficiently over-parameterized regimes <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib92" title="" class="ltx_ref">92</a>]</cite>. The server sends one of the <math id="S4.SS1.SSS1.p1.4.m4.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S4.SS1.SSS1.p1.4.m4.1a"><mi id="S4.SS1.SSS1.p1.4.m4.1.1" xref="S4.SS1.SSS1.p1.4.m4.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p1.4.m4.1b"><ci id="S4.SS1.SSS1.p1.4.m4.1.1.cmml" xref="S4.SS1.SSS1.p1.4.m4.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.p1.4.m4.1c">K</annotation></semantics></math> models to every client in each training round to train on local data. The server then aggregates the updated model from each client; this way, the burden on clients is not increased, and all <math id="S4.SS1.SSS1.p1.5.m5.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S4.SS1.SSS1.p1.5.m5.1a"><mi id="S4.SS1.SSS1.p1.5.m5.1.1" xref="S4.SS1.SSS1.p1.5.m5.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p1.5.m5.1b"><ci id="S4.SS1.SSS1.p1.5.m5.1.1.cmml" xref="S4.SS1.SSS1.p1.5.m5.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.p1.5.m5.1c">K</annotation></semantics></math> models eventually see all the clients’ data. To obtain uncertainty predictions in an ensemble of models, the sample variance can be used to estimate the uncertainty. Fed-ensemble can appropriately characterize knowledge uncertainty on regions without labeled data. Fed-ensemble enhances existing FL techniques by systematically quantifying uncertainty and increasing model capacity without raising communication costs. Unlike Fedavg, which tends to be overconfident in predictions, Fed-ensemble offers convergence guarantees and effectively manages data heterogeneity through ensembling, outperforming methods that rely on strong regularizers.</p>
</div>
</section>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Conformal Prediction (CP)</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">CP is another method for uncertainty estimation that has been extensively explored in FL. The idea was first proposed in <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib109" title="" class="ltx_ref">109</a>]</cite> and then improved upon by <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib110" title="" class="ltx_ref">110</a>]</cite> around the turn of the century. CP is a statistical framework that is used to provide reliable and valid confidence measures for the predictions made by ML models. CP begins by defining a nonconformity measure, which quantifies how different a new example is from a set of previously seen examples <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib110" title="" class="ltx_ref">110</a>]</cite>. This measure is based on an ML algorithm trained on a dataset. The non-conformity of an example can be something like the distance from a decision boundary in classification or the error of a prediction in regression.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">For a new data sample, CP generates prediction regions (or sets) likely to contain the true label or value. This is done by considering all possible labels for the new example, calculating the nonconformity score for each label, and comparing these scores to the scores from the calibration set. Lu et al. <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib111" title="" class="ltx_ref">111</a>]</cite> point out that since CP is primarily a post-processing method for uncertainty estimation, integrating it into an FL framework is generally straightforward. The authors also correlate class entropy with prediction set size to determine task uncertainty. CP can produce confidence predictions for any ML model that outputs a score function.</p>
</div>
<section id="S4.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.1 </span>Differentialy Private Federated Average Quantile Estimation (DP-FedAvgQE)</h4>

<div id="S4.SS2.SSS1.p1" class="ltx_para">
<p id="S4.SS2.SSS1.p1.1" class="ltx_p">DP-FedAvgQE brings CP and DP to FL and provides theoretical privacy guarantees to ensure additional security <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib93" title="" class="ltx_ref">93</a>]</cite>. DP-FedAvgQE provided strong benchmarks on ImageNet <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib112" title="" class="ltx_ref">112</a>]</cite> and CIFAR-10 <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib66" title="" class="ltx_ref">66</a>]</cite> datasets and simulated data experiments. DP-FedAvgQE takes advantage of importance weighting to address the label shift between agents effectively.</p>
</div>
</section>
<section id="S4.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.2 </span>Federated Conformal Prediction (FCP)</h4>

<div id="S4.SS2.SSS2.p1" class="ltx_para">
<p id="S4.SS2.SSS2.p1.1" class="ltx_p">FCP is another method for extending CP to FL that addresses the non-i.i.d. nature of data in FL<cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib94" title="" class="ltx_ref">94</a>]</cite>. The inherent heterogeneity of FL datasets violates the fundamental tenet of exchangeability between the calibration data distribution and the test data distribution during inference in CP, implying that the calibration and test data have identical distributions <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib113" title="" class="ltx_ref">113</a>]</cite>. To solve this violation, the authors propose using partial exchangeability, which is a generalization of exchangeability <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib94" title="" class="ltx_ref">94</a>]</cite>. FCP makes no assumptions between clients <math id="S4.SS2.SSS2.p1.1.m1.2" class="ltx_Math" alttext="P1,...,PK." display="inline"><semantics id="S4.SS2.SSS2.p1.1.m1.2a"><mrow id="S4.SS2.SSS2.p1.1.m1.2.2.1"><mrow id="S4.SS2.SSS2.p1.1.m1.2.2.1.1.2" xref="S4.SS2.SSS2.p1.1.m1.2.2.1.1.3.cmml"><mrow id="S4.SS2.SSS2.p1.1.m1.2.2.1.1.1.1" xref="S4.SS2.SSS2.p1.1.m1.2.2.1.1.1.1.cmml"><mi id="S4.SS2.SSS2.p1.1.m1.2.2.1.1.1.1.2" xref="S4.SS2.SSS2.p1.1.m1.2.2.1.1.1.1.2.cmml">P</mi><mo lspace="0em" rspace="0em" id="S4.SS2.SSS2.p1.1.m1.2.2.1.1.1.1.1" xref="S4.SS2.SSS2.p1.1.m1.2.2.1.1.1.1.1.cmml">​</mo><mn id="S4.SS2.SSS2.p1.1.m1.2.2.1.1.1.1.3" xref="S4.SS2.SSS2.p1.1.m1.2.2.1.1.1.1.3.cmml">1</mn></mrow><mo id="S4.SS2.SSS2.p1.1.m1.2.2.1.1.2.3" xref="S4.SS2.SSS2.p1.1.m1.2.2.1.1.3.cmml">,</mo><mi mathvariant="normal" id="S4.SS2.SSS2.p1.1.m1.1.1" xref="S4.SS2.SSS2.p1.1.m1.1.1.cmml">…</mi><mo id="S4.SS2.SSS2.p1.1.m1.2.2.1.1.2.4" xref="S4.SS2.SSS2.p1.1.m1.2.2.1.1.3.cmml">,</mo><mrow id="S4.SS2.SSS2.p1.1.m1.2.2.1.1.2.2" xref="S4.SS2.SSS2.p1.1.m1.2.2.1.1.2.2.cmml"><mi id="S4.SS2.SSS2.p1.1.m1.2.2.1.1.2.2.2" xref="S4.SS2.SSS2.p1.1.m1.2.2.1.1.2.2.2.cmml">P</mi><mo lspace="0em" rspace="0em" id="S4.SS2.SSS2.p1.1.m1.2.2.1.1.2.2.1" xref="S4.SS2.SSS2.p1.1.m1.2.2.1.1.2.2.1.cmml">​</mo><mi id="S4.SS2.SSS2.p1.1.m1.2.2.1.1.2.2.3" xref="S4.SS2.SSS2.p1.1.m1.2.2.1.1.2.2.3.cmml">K</mi></mrow></mrow><mo lspace="0em" id="S4.SS2.SSS2.p1.1.m1.2.2.1.2">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS2.p1.1.m1.2b"><list id="S4.SS2.SSS2.p1.1.m1.2.2.1.1.3.cmml" xref="S4.SS2.SSS2.p1.1.m1.2.2.1.1.2"><apply id="S4.SS2.SSS2.p1.1.m1.2.2.1.1.1.1.cmml" xref="S4.SS2.SSS2.p1.1.m1.2.2.1.1.1.1"><times id="S4.SS2.SSS2.p1.1.m1.2.2.1.1.1.1.1.cmml" xref="S4.SS2.SSS2.p1.1.m1.2.2.1.1.1.1.1"></times><ci id="S4.SS2.SSS2.p1.1.m1.2.2.1.1.1.1.2.cmml" xref="S4.SS2.SSS2.p1.1.m1.2.2.1.1.1.1.2">𝑃</ci><cn type="integer" id="S4.SS2.SSS2.p1.1.m1.2.2.1.1.1.1.3.cmml" xref="S4.SS2.SSS2.p1.1.m1.2.2.1.1.1.1.3">1</cn></apply><ci id="S4.SS2.SSS2.p1.1.m1.1.1.cmml" xref="S4.SS2.SSS2.p1.1.m1.1.1">…</ci><apply id="S4.SS2.SSS2.p1.1.m1.2.2.1.1.2.2.cmml" xref="S4.SS2.SSS2.p1.1.m1.2.2.1.1.2.2"><times id="S4.SS2.SSS2.p1.1.m1.2.2.1.1.2.2.1.cmml" xref="S4.SS2.SSS2.p1.1.m1.2.2.1.1.2.2.1"></times><ci id="S4.SS2.SSS2.p1.1.m1.2.2.1.1.2.2.2.cmml" xref="S4.SS2.SSS2.p1.1.m1.2.2.1.1.2.2.2">𝑃</ci><ci id="S4.SS2.SSS2.p1.1.m1.2.2.1.1.2.2.3.cmml" xref="S4.SS2.SSS2.p1.1.m1.2.2.1.1.2.2.3">𝐾</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS2.p1.1.m1.2c">P1,...,PK.</annotation></semantics></math>. Specifically,
this assumption does not require independence or identical distributions among clients. FCP provides rigorous theoretical guarantees and excellent empirical performance on multiple computer vision and medical imaging datasets.</p>
</div>
</section>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Distilled Predictions</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">The distilled prediction method leverages knowledge distillation to quantify uncertainty <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib95" title="" class="ltx_ref">95</a>]</cite>.</p>
</div>
<section id="S4.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.1 </span>Federated Posterior Predictive Distribution (FedPPD)</h4>

<div id="S4.SS3.SSS1.p1" class="ltx_para">
<p id="S4.SS3.SSS1.p1.1" class="ltx_p">FedPPD is a framework for FL with uncertainty estimation where, in every round, each client infers the posterior distribution over its parameters and the posterior predictive distribution (PPD) <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib95" title="" class="ltx_ref">95</a>]</cite>. The estimated PPD is sent to the server. Making predictions at test time does not require computationally expensive Monte-Carlo averaging over the posterior distribution because this approach maintains the PPD in the form of a single deep neural network. Moreover, this approach makes no restrictive assumptions, such as the form of the clients’ posterior distributions or their PPDs. FedPPD follows a two-step process <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib95" title="" class="ltx_ref">95</a>]</cite>:</p>
<ul id="S4.I2" class="ltx_itemize">
<li id="S4.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S4.I2.i1.p1" class="ltx_para">
<p id="S4.I2.i1.p1.1" class="ltx_p"><span id="S4.I2.i1.p1.1.1" class="ltx_text ltx_font_bold">Step 1</span> - For each client, the authors perform approximate Bayesian inference for the posterior distribution of the client model weights using Markov Chain Monte Carlo (MCMC) sampling <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib95" title="" class="ltx_ref">95</a>]</cite>. This produces a set of samples from the client’s posterior, and these samples are used as teacher models, which are distilled into a student model. The authors use stochastic gradient Langevin dynamics (SGLD) sampling since it provides an online method to distill these posterior samples efficiently into a student model.</p>
</div>
</li>
<li id="S4.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S4.I2.i2.p1" class="ltx_para">
<p id="S4.I2.i2.p1.1" class="ltx_p"><span id="S4.I2.i2.p1.1.1" class="ltx_text ltx_font_bold">Step 2</span> - For each client, the authors distill the MCMC samples (teacher models) directly into the PPD, which is the student model <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib95" title="" class="ltx_ref">95</a>]</cite>. Notably, in this distillation-based approach, the PPD for each client is represented succinctly by a single deep neural network instead of via an ensemble of deep neural networks. This makes the prediction stage much faster than typical Bayesian approaches.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S4.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.2 </span>Fed Uncertainty Aware FedUA</h4>

<div id="S4.SS3.SSS2.p1" class="ltx_para">
<p id="S4.SS3.SSS2.p1.1" class="ltx_p">FedUA provides another approach to distill predictions focusing on non-i.i.d. data while limiting communication bandwidth <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib96" title="" class="ltx_ref">96</a>]</cite>. This framework implements two core components: (1) uncertainty measurement to quantify each client’s uncertainty and (2) a sample quality evaluator to select high-quality samples for global model training. Knowledge distillation is used in the aggregation process to transfer inter-class relationships from the local models and suppress noise from incomplete client data. The authors empirically show that FedUA improves accuracy compared to other FL models while limiting communication costs on image classification tasks. The authors also reported that the uncertainty measurement using feature space density was more robust to native data uncertainty than softmax entropy.</p>
</div>
<div id="S4.SS3.SSS2.p2" class="ltx_para">
<p id="S4.SS3.SSS2.p2.1" class="ltx_p">Knowledge distillation provides two promising improvements for FL: it can alleviate overfitting on client-side data by sifting through informative and valuable information for learning, mitigating the bias caused by incomplete or over-trained data on a given client. Knowledge distillation also allows the global model to learn inter-class relationships, which helps to transfer knowledge from a general multi-purposed model to a specific target-oriented model. For the sample evaluator, the method used when finding quality samples can be described as “samples that do not reach consensus among local models should be taken with a higher priority”. These samples are more important for optimizing the local model on the server side. For uncertainty estimation, a single deterministic model is used to quantify uncertainty by estimating feature space density for each client model. For a new input sample, features are extracted and evaluated to get the probability density function in the client’s feature space. A lower density indicates a higher uncertainty and vice versa. Leveraging knowledge distillation is a powerful way of implementing uncertainty estimation into an FL framework with non-i.i.d data <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib96" title="" class="ltx_ref">96</a>]</cite>.</p>
</div>
</section>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Bayesian FL</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p">A popular class of models for providing uncertainty quantification in ML belongs to Bayesian or probabilistic models <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib114" title="" class="ltx_ref">114</a>]</cite>. These models utilize Bayesian methods to give probabilistic predictions rather than point predictions <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib115" title="" class="ltx_ref">115</a>]</cite>.</p>
</div>
<section id="S4.SS4.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.4.1 </span>Federated Bayesian Neural Network (FedBNN)</h4>

<div id="S4.SS4.SSS1.p1" class="ltx_para">
<p id="S4.SS4.SSS1.p1.1" class="ltx_p">The probabilistic predictions can give insight into model uncertainty <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib97" title="" class="ltx_ref">97</a>]</cite>. The authors present a unified FL framework based on training a customized local Bayesian model for each client. These models can learn in the absence of large local datasets. The Bayesian nature of these models allows for incorporating supervision in the form of prior distributions. The authors use the prior of the functional output space of the network to aid in collaboration across heterogeneous clients <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib97" title="" class="ltx_ref">97</a>]</cite>.</p>
</div>
</section>
<section id="S4.SS4.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.4.2 </span>Personalized FL (pFL)</h4>

<div id="S4.SS4.SSS2.p1" class="ltx_para">
<p id="S4.SS4.SSS2.p1.1" class="ltx_p">In some settings with heterogeneous data, it makes sense to personalize local models to cater to their respective datasets while still being able to learn from a larger data pool, like the work done by <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib116" title="" class="ltx_ref">116</a>]</cite> for multi-contrast MRI synthesis. This practice is known as personalized FL (pFL) and can be carried out in two primary ways with Bayesian techniques according to <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib98" title="" class="ltx_ref">98</a>]</cite>:</p>
<ul id="S4.I3" class="ltx_itemize">
<li id="S4.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S4.I3.i1.p1" class="ltx_para">
<p id="S4.I3.i1.p1.1" class="ltx_p"><span id="S4.I3.i1.p1.1.1" class="ltx_text ltx_font_bold">Global model personalization</span>: The global model personalization strategy begins with the training of a global model on data distributed across many devices or nodes. The model is trained by aggregating locally computed updates from each node without sharing the data itself. Once this global model has been trained, it can be personalized for individual users or clients.</p>
</div>
</li>
<li id="S4.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S4.I3.i2.p1" class="ltx_para">
<p id="S4.I3.i2.p1.1" class="ltx_p"><span id="S4.I3.i2.p1.1.1" class="ltx_text ltx_font_bold">Personalized model learning</span>: With personalized model learning in a federated setting, the focus shifts to training individual models for each site from the outset, leveraging the local data while still occasionally sharing insights or parameters (in a privacy-preserving manner) across the network to improve the models collectively.</p>
</div>
</li>
</ul>
</div>
<div id="S4.SS4.SSS2.p2" class="ltx_para">
<p id="S4.SS4.SSS2.p2.1" class="ltx_p">The study by Zhang et al. <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib98" title="" class="ltx_ref">98</a>]</cite> shows that personalization in FL improves classification accuracy and increases the quality of estimated uncertainty <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib98" title="" class="ltx_ref">98</a>]</cite>. Thus, personalization is a promising research direction in local client deployment and uncertainty quantification for healthcare applications <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib98" title="" class="ltx_ref">98</a>]</cite>. Bayesian methods are heavily used for creating pFL algorithms <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib98" title="" class="ltx_ref">98</a>]</cite>.</p>
</div>
</section>
<section id="S4.SS4.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.4.3 </span>Self-FL</h4>

<div id="S4.SS4.SSS3.p1" class="ltx_para">
<p id="S4.SS4.SSS3.p1.1" class="ltx_p">Self-aware personalized FL (Self-FL) uses intra-client and inter-client uncertainty to balance the training of local personal and global models <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib99" title="" class="ltx_ref">99</a>]</cite>. Larger inter-client variation implies more personalization is needed. Self-FL uses uncertainty-driven local training steps and aggregation rules instead of conventional local fine-tuning and sample size-based aggregation. The authors interpret personalized FL through a two-level Bayesian hierarchical model perspective to characterize client-specific and globally-shared information. The method uses uncertainty to drive client-side training with an adaptive number of local steps and server-side aggregation (variance-weighted averaging). The authors evaluate their method using synthetic data, images (MNIST, FEMNIST <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib117" title="" class="ltx_ref">117</a>]</cite>, CIFAR10 <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib66" title="" class="ltx_ref">66</a>]</cite>), text (Sent140 <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib118" title="" class="ltx_ref">118</a>]</cite>), and audio (wake-word detection) and show robust personalization capability under data heterogeneity. Some key advantages of the Self-FL model are principled connections to hierarchical Bayesian modeling and built-in auto-tuning of hyper-parameters for each client, all while maintaining the same computation and communication overhead as FedAvg <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib99" title="" class="ltx_ref">99</a>]</cite>.</p>
</div>
</section>
<section id="S4.SS4.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.4.4 </span>Personalized federated learning with Bayesian inference (pFedBays)</h4>

<div id="S4.SS4.SSS4.p1" class="ltx_para">
<p id="S4.SS4.SSS4.p1.1" class="ltx_p">In pFedBays, weight uncertainty is introduced in neural networks for clients and the server <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib100" title="" class="ltx_ref">100</a>]</cite>. To achieve personalization, each client updates its local distribution parameters by balancing its construction error over private data and its Kullback–Leibler (KL) divergence with global probability distribution from the server. pFedBays method tackles two issues in FL: training on non-i.i.d data across clients and overfitting due to limited data <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib100" title="" class="ltx_ref">100</a>]</cite>. pFedBays formulates both the local clients’ models and the global server model as Bayesian neural networks, where the parameters are modeled as probability distributions rather than point estimates. This helps address overfitting.
The server optimizes to find a global distribution that is close to the local distributions by minimizing KL divergence. Each client balances minimizing a local data fit term and the KL divergence from the global distribution to find its personalized distribution. The global distribution acts as a prior for the local models. By replacing the prior distribution with a trained global distribution, the authors find a relatively good distribution without making assumptions about the prior distribution <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib100" title="" class="ltx_ref">100</a>]</cite>. This is critical because estimating a prior in many real-world scenarios is not feasible <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib100" title="" class="ltx_ref">100</a>]</cite>. The authors provide a theoretical analysis bounding the generalization error and showing the convergence rate is minimax optimal up to a logarithmic factor. Being a Bayesian network, uncertainty estimates for the parameters can be monitored to understand the model’s confidence in its predictions.</p>
</div>
</section>
<section id="S4.SS4.SSS5" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.4.5 </span>Fedpop</h4>

<div id="S4.SS4.SSS5.p1" class="ltx_para">
<p id="S4.SS4.SSS5.p1.1" class="ltx_p">The Fedpop <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib101" title="" class="ltx_ref">101</a>]</cite> framework recasts the method of pFL into a population modeling paradigm. Clients integrate fixed common population parameters with random effects, expanding data heterogeneity. Each client has a local model composed of fixed population parameters shared across clients and random effects that explain heterogeneity in the local data. Kotelevskii et al. developed a new stochastic optimization algorithm based on MCMC to perform inference under this model <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib101" title="" class="ltx_ref">101</a>]</cite>. The algorithm allows uncertainty estimation, handles issues like client drift, and works well even with limited client participation. The authors show that, in practice, the added computational cost from the Monte Carlo chain is negligible. FedPop allows for uncertainty estimation by having each client model involve a fixed effect parameter shared across clients and a low-dimensional random effect parameter sampled for each client. Introducing a common prior on the local parameters addresses the local overfitting problem where clients have highly heterogeneous and small datasets<cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib101" title="" class="ltx_ref">101</a>]</cite>.</p>
</div>
</section>
</section>
<section id="S4.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5 </span>Other methods for Uncertainty Estimation in FL</h3>

<div id="S4.SS5.p1" class="ltx_para">
<p id="S4.SS5.p1.1" class="ltx_p">Some methods take a different approach to quantifying uncertainty in FL setups.</p>
</div>
<section id="S4.SS5.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.5.1 </span>Feature Anchors</h4>

<div id="S4.SS5.SSS1.p1" class="ltx_para">
<p id="S4.SS5.SSS1.p1.1" class="ltx_p">Zhou et al. propose using feature anchors to align features and classifiers for heterogeneous data in their framework <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib102" title="" class="ltx_ref">102</a>]</cite>. FedFA is designed to address the challenges posed by heterogeneous data. This method utilizes feature anchors to align features and calibrate classifiers across clients simultaneously. This enables client models to be updated in a shared feature space with consistent classifiers during local training. The authors explain the vicious and virtuous cycles of FL with heterogeneous data:</p>
<ul id="S4.I4" class="ltx_itemize">
<li id="S4.I4.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S4.I4.i1.p1" class="ltx_para">
<p id="S4.I4.i1.p1.1" class="ltx_p"><span id="S4.I4.i1.p1.1.1" class="ltx_text ltx_font_bold">Vicious Cycle</span>: In traditional FL approaches, data heterogeneity leads to feature inconsistency across client models. This inconsistency causes classifier updates to diverge, forcing feature extractors to map to more inconsistent feature spaces. This cycle of increasing divergence in classifiers and inconsistency in features degrades the performance and convergence of the federated model.</p>
</div>
</li>
<li id="S4.I4.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S4.I4.i2.p1" class="ltx_para">
<p id="S4.I4.i2.p1.1" class="ltx_p"><span id="S4.I4.i2.p1.1.1" class="ltx_text ltx_font_bold">Virtuous Cycle</span>: FedFA introduces feature anchors to break this vicious cycle. By aligning features and calibrating classifiers across clients, FedFA creates a virtuous cycle. The aligned features and classifiers promote consistency in client features and classifiers. This alignment ensures that client models are updated in a shared, consistent feature space with similar classifiers, leading to improved performance and more stable convergence.</p>
</div>
</li>
</ul>
</div>
<div id="S4.SS5.SSS1.p2" class="ltx_para">
<p id="S4.SS5.SSS1.p2.1" class="ltx_p">The FedFA framework integrates feature anchor loss to minimize local objective functions. This mechanism is designed to align class-specific features and diminish the distance within classes at the client level <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib102" title="" class="ltx_ref">102</a>]</cite>. Moreover, the FedFA algorithm encompasses a server-side component where both class feature anchors and the global model undergo aggregation. This process employs a weighted averaging scheme akin to that of the FedAvg algorithm, facilitating the integration of local updates into a cohesive global model.</p>
</div>
</section>
<section id="S4.SS5.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.5.2 </span>FedAvg-Gaussian FedAG</h4>

<div id="S4.SS5.SSS2.p1" class="ltx_para">
<p id="S4.SS5.SSS2.p1.1" class="ltx_p">FedAvg-Gaussian FedAG takes a Gaussian approach to generating probabilistic predictions in FL <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib103" title="" class="ltx_ref">103</a>]</cite>. By introducing weight uncertainty in the aggregation step of the FedAvg algorithm, the end devices can calculate probabilistic predictions but only have to learn conventional, deterministic models. This allows for uncertainty estimation in an FL framework. The key idea in FedAG is to treat the probability distribution of the local model weights from different devices as an approximation of the posterior distribution over the global model weights <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib103" title="" class="ltx_ref">103</a>]</cite>. This allows the global model to make probabilistic predictions. For linear models, FedAG performs on par with Bayesian linear regression. For neural networks, FedAG outperforms variational inference methods and approaches the performance of deep ensembles for probabilistic predictions after several rounds of training <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib103" title="" class="ltx_ref">103</a>]</cite>. FedAG provides an efficient and privacy-preserving way to enable probabilistic predictions in FL settings, with performance competitive to non-federated methods. FedAG has comparable accuracy to non-FL and non-distributed learning frameworks. There are two variations to this algorithm:</p>
<ul id="S4.I5" class="ltx_itemize">
<li id="S4.I5.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S4.I5.i1.p1" class="ltx_para">
<p id="S4.I5.i1.p1.3" class="ltx_p"><span id="S4.I5.i1.p1.3.1" class="ltx_text ltx_font_bold">Monte Carlo and non-parametric bootstrapping</span>: In Monte Carlo and non-parametric bootstrapping, <math id="S4.I5.i1.p1.1.m1.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S4.I5.i1.p1.1.m1.1a"><mi id="S4.I5.i1.p1.1.m1.1.1" xref="S4.I5.i1.p1.1.m1.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S4.I5.i1.p1.1.m1.1b"><ci id="S4.I5.i1.p1.1.m1.1.1.cmml" xref="S4.I5.i1.p1.1.m1.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I5.i1.p1.1.m1.1c">M</annotation></semantics></math> sets of weights are randomly drawn from the posterior weight distributions learned during federated aggregation. Each of these <math id="S4.I5.i1.p1.2.m2.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S4.I5.i1.p1.2.m2.1a"><mi id="S4.I5.i1.p1.2.m2.1.1" xref="S4.I5.i1.p1.2.m2.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S4.I5.i1.p1.2.m2.1b"><ci id="S4.I5.i1.p1.2.m2.1.1.cmml" xref="S4.I5.i1.p1.2.m2.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I5.i1.p1.2.m2.1c">M</annotation></semantics></math> weight sets is used to generate a prediction on the test input. These <math id="S4.I5.i1.p1.3.m3.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S4.I5.i1.p1.3.m3.1a"><mi id="S4.I5.i1.p1.3.m3.1.1" xref="S4.I5.i1.p1.3.m3.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S4.I5.i1.p1.3.m3.1b"><ci id="S4.I5.i1.p1.3.m3.1.1.cmml" xref="S4.I5.i1.p1.3.m3.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I5.i1.p1.3.m3.1c">M</annotation></semantics></math> predictions are aggregated (by taking mean and variance) to approximate a predictive distribution.</p>
</div>
</li>
<li id="S4.I5.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S4.I5.i2.p1" class="ltx_para">
<p id="S4.I5.i2.p1.1" class="ltx_p"><span id="S4.I5.i2.p1.1.1" class="ltx_text ltx_font_bold">Non-parametric bootstrapping</span>: This approach uses the local weight updates from client devices directly, rather than drawing samples from the fitted posterior probability distributions, to generate predictions. Each client’s weight update is used directly to generate a prediction. These predictions approximate the predictive distribution. Non-parametric bootstrapping is conceptually similar to bootstrap aggregating <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib119" title="" class="ltx_ref">119</a>]</cite>, where re-sampling the training data is replaced by re-sampling the client weights.</p>
</div>
</li>
</ul>
</div>
<div id="S4.SS5.SSS2.p2" class="ltx_para">
<p id="S4.SS5.SSS2.p2.1" class="ltx_p">FedFA used its feature anchors to calibrate the model’s classifier. Calibration is a different way of dealing with model uncertainty, and it will be discussed in the next part of paper.</p>
</div>
</section>
</section>
<section id="S4.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.6 </span>Calibration</h3>

<div id="S4.SS6.p1" class="ltx_para">
<p id="S4.SS6.p1.1" class="ltx_p">Calibration is another method of dealing with uncertainty estimation by correcting an ML model’s tendency to be overconfident in incorrect predictions due to the Softmax function <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib120" title="" class="ltx_ref">120</a>]</cite>. By calibrating the confidence, a better assumption about the quality of a prediction can be made <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib120" title="" class="ltx_ref">120</a>]</cite>.</p>
</div>
<section id="S4.SS6.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.6.1 </span>Classifier Calibration with Virtual Representation (CCVR)</h4>

<div id="S4.SS6.SSS1.p1" class="ltx_para">
<p id="S4.SS6.SSS1.p1.1" class="ltx_p">CCVR calibrates a global model to improve performance on non-i.i.d data in heterogeneous settings <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib104" title="" class="ltx_ref">104</a>]</cite>. The authors found a greater bias in representations learned in the deeper layers of a model trained with FL. They show that the classifier contains the greatest bias and that post-calibration can greatly improve classification performance. Specifically, the classifiers learned on different clients show the lowest feature similarity. The classifiers tend to get biased toward the classes over-represented in the local client data, leading to poor performance in under-represented classes. This classifier bias is a key reason behind performance degradation on non-i.i.d federated data. Regularizing the classifier during federated training brings minor improvements <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib104" title="" class="ltx_ref">104</a>]</cite>. However, post-training calibration of the classifier significantly improves classification accuracy across various FL algorithms and datasets <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib104" title="" class="ltx_ref">104</a>]</cite>. CCVR generates virtual representations using Gaussian probability distributions fitted on client feature statistics. CCVR then retrains the classifier on these virtual representations while fixing the feature extractor. Experimental results show state-of-the-art accuracies on common benchmark datasets like CIFAR-10. CCVR is built on top of the off-the-shelf feature extractor and requires no transmission of the representations of the original data, thus raising no additional privacy concerns.</p>
</div>
</section>
<section id="S4.SS6.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.6.2 </span>FedCSPC</h4>

<div id="S4.SS6.SSS2.p1" class="ltx_para">
<p id="S4.SS6.SSS2.p1.1" class="ltx_p">FedCSPC method addresses the issue of heterogeneous data distributions across clients in FL <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib105" title="" class="ltx_ref">105</a>]</cite>. This method takes additional prototype information from the clients to learn a unified feature space on the server side while maintaining clear boundaries. There are two main modules to this framework: (1) The Data Prototypical Modeling (DPM) module and (2) the Cross-Silo Prototypical Calibration (CSPC) module <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib105" title="" class="ltx_ref">105</a>]</cite>. The DPM module uses clustering to model representation distributions for each client and generate class-specific prototypes for the server. This helps capture diversity within each class. The CSPC module on the server aligns the heterogeneous prototype features from different clients into a unified space. It uses an augmented contrastive learning approach with positive mixing and hard negative mining to improve robustness. Knowledge-based predictions using the calibrated exemplar prototypes from the unified space to supplement the network predictions. FedCSPC alleviates the feature gap between data sources, which can significantly improve generalization ability.The authors test the proposed framework on CIFAR10, CIFAR100 <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib107" title="" class="ltx_ref">107</a>]</cite>, TinyImageNet <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib121" title="" class="ltx_ref">121</a>]</cite>, and VireoFood172 <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib122" title="" class="ltx_ref">122</a>]</cite> datasets. The proposed CSPC module is an orthogonal improvement to client-based methods and has a plug-and-play design that makes it easy to integrate into existing FL frameworks. Calibration is an attractive method for FL as it introduces little additional communication overhead and can effectively provide quality information about model certainty <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib105" title="" class="ltx_ref">105</a>]</cite>.</p>
</div>
</section>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Real-World Applications</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.5" class="ltx_p">With the influx of research in the field of FL for medical imaging, some successful real-world applications showcase FL’s potential for the medical imaging domain <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib123" title="" class="ltx_ref">123</a>]</cite>. The Federated Tumor Segmentation (FeTS-1.0) Challenge <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib123" title="" class="ltx_ref">123</a>]</cite> was the first real-world FL challenge for medical images. The goals for this challenge were:</p>
<ul id="S5.I1" class="ltx_itemize">
<li id="S5.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S5.I1.i1.p1" class="ltx_para">
<p id="S5.I1.i1.p1.1" class="ltx_p">The identification of the optimal weight aggregation approach towards training a consensus model that has gained knowledge via FL from multiple geographically distinct institutions while their data are always retained within each institution.</p>
</div>
</li>
<li id="S5.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S5.I1.i2.p1" class="ltx_para">
<p id="S5.I1.i2.p1.1" class="ltx_p">The federated evaluation of the generalizability of brain tumor segmentation models “in the wild”, i.e., on data from institutional distributions that were not part of the training datasets.</p>
</div>
</li>
</ul>
<p id="S5.p1.4" class="ltx_p">The FeTS-1.0 study opened the door for FL in a medical environment. Participants were given a U-net <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib124" title="" class="ltx_ref">124</a>]</cite> model and tasked with finding the best method for weight aggregation. The FeTS-1.0 challenge also focused on the real-world evaluation of the consensus model to show if it could perform well on real unseen data. The success of this first challenge paved the way for the FeTS-2.0 Challenge <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib125" title="" class="ltx_ref">125</a>]</cite>, where the objective was to address out-of-sample generalizability for rare Glioblastoma cancer boundary detection. Due to this disease’s rarity and privacy concerns regarding medical data, it is a challenge to gather a large amount of data to train a model on this task <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib125" title="" class="ltx_ref">125</a>]</cite>. Traditional approaches to this problem involve sharing multi-site data <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib125" title="" class="ltx_ref">125</a>]</cite>, but centralizing such data is often difficult or infeasible due to various limitations regarding privacy. The study presented in this paper is the largest FL project to date, incorporating data from <math id="S5.p1.1.m1.1" class="ltx_Math" alttext="71" display="inline"><semantics id="S5.p1.1.m1.1a"><mn id="S5.p1.1.m1.1.1" xref="S5.p1.1.m1.1.1.cmml">71</mn><annotation-xml encoding="MathML-Content" id="S5.p1.1.m1.1b"><cn type="integer" id="S5.p1.1.m1.1.1.cmml" xref="S5.p1.1.m1.1.1">71</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.1.m1.1c">71</annotation></semantics></math> sites around the globe <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib125" title="" class="ltx_ref">125</a>]</cite>. With this approach, the authors created the largest Glioblastoma dataset with <math id="S5.p1.2.m2.2" class="ltx_Math" alttext="6,214" display="inline"><semantics id="S5.p1.2.m2.2a"><mrow id="S5.p1.2.m2.2.3.2" xref="S5.p1.2.m2.2.3.1.cmml"><mn id="S5.p1.2.m2.1.1" xref="S5.p1.2.m2.1.1.cmml">6</mn><mo id="S5.p1.2.m2.2.3.2.1" xref="S5.p1.2.m2.2.3.1.cmml">,</mo><mn id="S5.p1.2.m2.2.2" xref="S5.p1.2.m2.2.2.cmml">214</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.p1.2.m2.2b"><list id="S5.p1.2.m2.2.3.1.cmml" xref="S5.p1.2.m2.2.3.2"><cn type="integer" id="S5.p1.2.m2.1.1.cmml" xref="S5.p1.2.m2.1.1">6</cn><cn type="integer" id="S5.p1.2.m2.2.2.cmml" xref="S5.p1.2.m2.2.2">214</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.2.m2.2c">6,214</annotation></semantics></math> samples.
The authors reported a <math id="S5.p1.3.m3.1" class="ltx_Math" alttext="33\%" display="inline"><semantics id="S5.p1.3.m3.1a"><mrow id="S5.p1.3.m3.1.1" xref="S5.p1.3.m3.1.1.cmml"><mn id="S5.p1.3.m3.1.1.2" xref="S5.p1.3.m3.1.1.2.cmml">33</mn><mo id="S5.p1.3.m3.1.1.1" xref="S5.p1.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.p1.3.m3.1b"><apply id="S5.p1.3.m3.1.1.cmml" xref="S5.p1.3.m3.1.1"><csymbol cd="latexml" id="S5.p1.3.m3.1.1.1.cmml" xref="S5.p1.3.m3.1.1.1">percent</csymbol><cn type="integer" id="S5.p1.3.m3.1.1.2.cmml" xref="S5.p1.3.m3.1.1.2">33</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.3.m3.1c">33\%</annotation></semantics></math> improvement in segmenting the surgically targetable portion of the tumor and a <math id="S5.p1.4.m4.1" class="ltx_Math" alttext="23\%" display="inline"><semantics id="S5.p1.4.m4.1a"><mrow id="S5.p1.4.m4.1.1" xref="S5.p1.4.m4.1.1.cmml"><mn id="S5.p1.4.m4.1.1.2" xref="S5.p1.4.m4.1.1.2.cmml">23</mn><mo id="S5.p1.4.m4.1.1.1" xref="S5.p1.4.m4.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.p1.4.m4.1b"><apply id="S5.p1.4.m4.1.1.cmml" xref="S5.p1.4.m4.1.1"><csymbol cd="latexml" id="S5.p1.4.m4.1.1.1.cmml" xref="S5.p1.4.m4.1.1.1">percent</csymbol><cn type="integer" id="S5.p1.4.m4.1.1.2.cmml" xref="S5.p1.4.m4.1.1.2">23</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.4.m4.1c">23\%</annotation></semantics></math> improvement for the complete tumor compared to a publicly trained model <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib125" title="" class="ltx_ref">125</a>]</cite>.
This research demonstrates that FL enhances the efficacy of ML methodologies within the medical sector, reinforcing the notion that FL could be a transformative technology for amplifying the impact of ML in medical imaging.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Challenges and Opportunities</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">While there has been significant progress in FL in recent years, some challenges remain to be solved. These challenges present potential opportunities for researchers to further explore and improve the state of FL for medical imaging. One particular challenge is the inherent trade-off between privacy and security in FL. Further research into the efficient allocation of the privacy budget to enhance model performance without compromising privacy is a key area that requires further research. In addition to privacy and security, communication efficiency must also be considered. Alternate noise addition methods are also a possible route for increasing the effectiveness of DP, as current methods may not be optimal. Another trade-off that still presents a challenge is personalization versus overfitting. Personalization in FL can increase accuracy but risks affecting uncertainty estimation performance due to overfitting. Methods for optimizing personalization to balance overfitting are open areas for research. Computational efficiency remains an issue for many aspects of FL, particularly with deep ensembles like fed-ensemble. Finding more computationally efficient methods could progress FL further. uncertainty estimation for out-of-distribution and noisy labels is an under-researched area, and there is a need to investigate how uncertainty estimation can be leveraged to address these issues. Exploring generative AI models to provide application-specific alignment datasets could be a promising direction. Generative AI could make up for a lack of data by providing simulated data. Conformal prediction has been shown to perform well for uncertainty estimation in FL, but little research has been conducted on conformal prediction in a personalized setting, making it an open research area. Ensemble modes have been integrated into FL and could potentially address and detect client drift, anomalies, or fairness challenges during model training. Applying data-free knowledge transfer methods could improve practicability in scenarios where shared datasets are not available, providing a secure way to transfer knowledge across clients.</p>
</div>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusion</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">Machine learning holds the potential to dramatically improve the effectiveness of medical imaging for disease diagnoses and treatment. However, to succeed, methods need to be implemented to address both privacy concerns and uncertainty estimation. FL is a powerful solution for training on multiple private datasets without exposing any private data, and enhanced privacy preservation and uncertainty estimation methods can be an effective approach for training large medical imaging models. This paper provided a comprehensive review of the current state of FL algorithms, privacy preservation, and uncertainty estimation in the context of medical imaging. Significant progress has been made in recent years to make FL viable for the medical imaging domain, with work being done to optimize the aggregation process, privacy preservation, and uncertainty estimation.</p>
</div>
</section>
<section id="S8" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8 </span>Acknowledgements</h2>

<div id="S8.p1" class="ltx_para">
<p id="S8.p1.1" class="ltx_p">This work was funded by NSF grants 2234468 and 2234836. The content is the responsibility of the authors and does not reflect the official views of the National Science Foundation</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
B. Erickson, P. Korfiatis, Z. Akkus, and T. Kline, “Machine learning for medical imaging,” <span id="bib.bib1.1.1" class="ltx_text ltx_font_italic">Radiographics</span>, 2017.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
J. Latif, C. Xiao, A. Imran, and S. Tu, “Medical imaging using machine learning and deep learning algorithms: A review,” in <span id="bib.bib2.1.1" class="ltx_text ltx_font_italic">ICOMET</span>, 2019.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
A. M. Barragán-Montero <span id="bib.bib3.1.1" class="ltx_text ltx_font_italic">et al.</span>, “Artificial intelligence and machine learning for medical imaging: A technology review,” <span id="bib.bib3.2.2" class="ltx_text ltx_font_italic">Physica Medica</span>, 2021.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
M. Willemink <span id="bib.bib4.1.1" class="ltx_text ltx_font_italic">et al.</span>, “Preparing medical imaging data for machine learning,” <span id="bib.bib4.2.2" class="ltx_text ltx_font_italic">Radiology</span>, 2020.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
J. Jager, T. Gremeaux, T. Gonzalez, S. Bonnafous, C. Debard, M. Laville, and H. Vidal, “Adipose tissue-derived stem cells promote monocyte recruitment in adipose tissue and liver,” <span id="bib.bib5.1.1" class="ltx_text ltx_font_italic">Mol Metab</span>, vol. 3, no. 4, pp. 417–425, 2014.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
C. Wu, H. Ying, F. Grinnell, G. Bryant-Greenwood, R. Riha, J. Nguyen, Z. Li, M. Parsons, B. Parry, D. Rotstein, A. Lightfoot, and S. Cassar, “Vitamin d receptor localization and activity in early human fetal development,” <span id="bib.bib6.1.1" class="ltx_text ltx_font_italic">J Clin Endocrinol Metab</span>, vol. 100, no. 12, pp. E1568–E1575, 2015.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
G. Sahay, D. Y. Alakhova, and A. V. Kabanov, “Endocytosis of nanomedicines,” <span id="bib.bib7.1.1" class="ltx_text ltx_font_italic">J Control Release</span>, vol. 145, no. 3, pp. 182–195, 2010.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
N. Bettencourt, J. P. Ferreira, I. P. Culotta, J. J. McMurray, S. Jacob, J. L. Rouleau, K. Swedberg, S. J. Pocock, S. D. Solomon, F. Zannad, and P. Rossignol, “Impact of intensive versus standard blood pressure lowering in chronic kidney disease patients with and without diabetes mellitus: A subanalysis of the sprint study,” <span id="bib.bib8.1.1" class="ltx_text ltx_font_italic">Hypertension</span>, vol. 76, no. 4, pp. 979–987, 2020.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
S. Dayarathna, K. T. Islam, S. Uribe, G. Yang, M. Hayat, and Z. Chen, “Deep learning based synthesis of mri, ct and pet: Review and analysis,” <span id="bib.bib9.1.1" class="ltx_text ltx_font_italic">Medical Image Analysis</span>, vol. 92, p. 103046, 2024.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
“Health Insurance Portability and Accountability Act of 1996.” Pub. L. No. 104-191, 110 Stat. 1936, 1996.

</span>
<span class="ltx_bibblock">Available from: U.S. Government Printing Office, via: <a target="_blank" href="https://www.govinfo.gov/content/pkg/PLAW-104publ191/pdf/PLAW-104publ191.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.govinfo.gov/content/pkg/PLAW-104publ191/pdf/PLAW-104publ191.pdf</a>.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
“General Data Protection Regulation (GDPR).” Regulation (EU) 2016/679 of the European Parliament and of the Council of 27 April 2016, 2016.

</span>
<span class="ltx_bibblock">Available from: <a target="_blank" href="https://eur-lex.europa.eu/eli/reg/2016/679/oj" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://eur-lex.europa.eu/eli/reg/2016/679/oj</a>.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y. Arcas, “Communication-Efficient Learning of Deep Networks from Decentralized Data,” in <span id="bib.bib12.1.1" class="ltx_text ltx_font_italic">Proceedings of the 20th International Conference on Artificial Intelligence and Statistics</span> (A. Singh and J. Zhu, eds.), vol. 54 of <span id="bib.bib12.2.2" class="ltx_text ltx_font_italic">Proceedings of Machine Learning Research</span>, pp. 1273–1282, PMLR, 20–22 Apr 2017.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
L. Qu, N. Balachandar, and D. Rubin, “An experimental study of data heterogeneity in federated learning methods for medical imaging,” <span id="bib.bib13.1.1" class="ltx_text ltx_font_italic">arXiv</span>, 2021.

</span>
<span class="ltx_bibblock">Available at arXiv:2107.08371.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
M. Lam, G. Wei, D. Brooks, V. J. Reddi, and M. Mitzenmacher, “Gradient disaggregation: Breaking privacy in federated learning by reconstructing the user participant matrix,” <span id="bib.bib14.1.1" class="ltx_text ltx_font_italic">CoRR</span>, vol. abs/2106.06089, 2021.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
R. Wu, X. Chen, C. Guo, and K. Q. Weinberger, “Learning to invert: Simple adaptive attacks for gradient inversion in federated learning,” <span id="bib.bib15.1.1" class="ltx_text ltx_font_italic">arXiv</span>, 2022.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
M. Jere, T. Farnan, and F. Koushanfar, “A taxonomy of attacks on federated learning,” <span id="bib.bib16.1.1" class="ltx_text ltx_font_italic">IEEE Security &amp; Privacy</span>, 2021.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
C. Dwork, “Differential privacy,” in <span id="bib.bib17.1.1" class="ltx_text ltx_font_italic">33rd International Colloquium on Automata, Languages and Programming, part II (ICALP 2006)</span>, pp. 1–12, Springer, 2006.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
C. Gentry, <span id="bib.bib18.1.1" class="ltx_text ltx_font_italic">A Fully Homomorphic Encryption Scheme</span>.

</span>
<span class="ltx_bibblock">PhD thesis, Stanford University, 2009.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
F. Linsner, L. Adilova, S. Däubener, M. Kamp, and A. Fischer, “Approaches to uncertainty quantification in federated deep learning,” in <span id="bib.bib19.1.1" class="ltx_text ltx_font_italic">PKDD/ECML Workshops</span>, 2021.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
A. F. Psaros, X. Meng, Z. Zou, L. Guo, and G. Karniadakis, “Uncertainty quantification in scientific machine learning: Methods, metrics, and comparisons,” <span id="bib.bib20.1.1" class="ltx_text ltx_font_italic">Journal of Computational Physics</span>, 2022.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
E. Darzidehkalani, M. Ghasemi-rad, and P. V. van Ooijen, “Federated learning in medical imaging: Part ii: Methods, challenges, and considerations,” <span id="bib.bib21.1.1" class="ltx_text ltx_font_italic">Journal of the American College of Radiology</span>, vol. 19, no. 4, pp. P755–765, 2022.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
G. Kaissis, M. Makowski, D. Rückert, and R. Braren, “Secure, privacy-preserving and federated machine learning in medical imaging,” <span id="bib.bib22.1.1" class="ltx_text ltx_font_italic">Nature Machine Intelligence</span>, vol. 2, 06 2020.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
N. Mouhni, A. Elkalay, M. Chakraoui, A. Abdali, A. Ammoumou, and I. Amalou, “Federated learning for medical imaging: An updated state of the art,” <span id="bib.bib23.1.1" class="ltx_text ltx_font_italic">Ingenierie des Systemes d’Information</span>, vol. 27, no. 1, pp. 117–122, 2022.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
T. Li, A. K. Sahu, M. Zaheer, M. Sanjabi, A. Talwalkar, and V. Smith, “Federated optimization in heterogeneous networks,” 2020.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
X. Li, M. Jiang, X. Zhang, M. Kamp, and Q. Dou, “Fedbn: Federated learning on non-iid features via local batch normalization,” <span id="bib.bib25.1.1" class="ltx_text ltx_font_italic">ArXiv</span>, vol. abs/2102.07623, 2021.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
Y. Yu, A. Wei, S. Karimireddy, Y. Ma, and M. Jordan, “Tct: Convexifying federated learning using bootstrapped neural tangent kernels,” 07 2022.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
W. Lu, J. Wang, Y. Chen, X. Qin, R. Xu, D. Dimitriadis, and T. Qin, “Personalized federated learning with adaptive batchnorm for healthcare,” <span id="bib.bib27.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Big Data</span>, pp. 1–1, 2022.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Z. Zhu, J. Hong, and J. Zhou, “Data-free knowledge distillation for heterogeneous federated learning,” <span id="bib.bib28.1.1" class="ltx_text ltx_font_italic">Proceedings of machine learning research</span>, vol. 139, pp. 12878–12889, 07 2021.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
L. Liu, X. Jiang, F. Zheng, H. Chen, G.-J. Qi, H. Huang, and L. Shao, “A bayesian federated learning framework with online laplace approximation.,” <span id="bib.bib29.1.1" class="ltx_text ltx_font_italic">IEEE transactions on pattern analysis and machine intelligence</span>, vol. PP, 2021.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
W. Huang, M. Ye, and B. Du, “Learn from others and be yourself in heterogeneous federated learning,” in <span id="bib.bib30.1.1" class="ltx_text ltx_font_italic">2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</span>, pp. 10133–10143, 2022.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
S. Warnat-Herresthal, H. Schultze, K. Shastry, S. Manamohan, S. Mukherjee, V. Garg, R. Sarveswara, K. Händler, P. Pickkers, N. A. Aziz, M. Breteler, E. Giamarellos-Bourboulis, M. Kox, M. Becker, S. Cheran, M. Woodacre, E. Goh, J. Schultze, and H. Grundmann, “Swarm learning for decentralized and confidential clinical machine learning,” 01 2021.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
S. Kalra, J. Wen, J. C. Cresswell, M. Volkovs, and H. R. Tizhoosh, “Decentralized federated learning through proxy model sharing,” <span id="bib.bib32.1.1" class="ltx_text ltx_font_italic">Nature Communications</span>, vol. 14, p. 2899, May 2023.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
M. Butt, N. Tariq, M. Ashraf, H. S. Alsagri, S. A. Moqurrab, H. A. A. Alhakbani, and Y. A. Alduraywish, “A fog-based privacy-preserving federated learning system for smart healthcare applications,” <span id="bib.bib33.1.1" class="ltx_text ltx_font_italic">Electronics</span>, vol. 12, no. 19, 2023.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
J. Wu, Q. Xia, and Q. Li, “Efficient privacy-preserving federated learning for resource-constrained edge devices,” in <span id="bib.bib34.1.1" class="ltx_text ltx_font_italic">IEEE International Conference on Mobile Ad-Hoc and Smart Systems (MASS)</span>, 2021.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
J. Mills, J. Hu, and G. Min, “Communication-efficient federated learning for wireless edge intelligence in iot,” <span id="bib.bib35.1.1" class="ltx_text ltx_font_italic">IEEE Internet of Things Journal</span>, vol. 7, no. 7, pp. 5986–5994, 2020.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
M. Sheller, B. Edwards, G. Reina, J. Martin, S. Pati, A. Kotrotsou, M. Milchenko, W. Xu, D. Marcus, R. Colen, and S. Bakas, “Federated learning in medicine: facilitating multi-institutional collaborations without sharing patient data,” <span id="bib.bib36.1.1" class="ltx_text ltx_font_italic">Scientific Reports</span>, vol. 10, 07 2020.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
J. Wen, Z. Zhang, Y. Lan, Z.-s. Cui, J. Cai, and W. Zhang, “A survey on federated learning: challenges and applications,” <span id="bib.bib37.1.1" class="ltx_text ltx_font_italic">International Journal of Machine Learning and Cybernetics</span>, 2022.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
D. Liu, L. Bai, T. Yu, and A. Zhang, “Towards method of horizontal federated learning: A survey,” <span id="bib.bib38.1.1" class="ltx_text ltx_font_italic">2022 IEEE 5th International Conference on Big Data and Artificial Intelligence (BDAI)</span>, 2022.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
D. Leroy, A. Coucke, T. Lavril, T. Gisselbrecht, and J. Dureau, “Federated learning for keyword spotting,” in <span id="bib.bib39.1.1" class="ltx_text ltx_font_italic">Proceedings of IEEE International Conference on Acoustics, Speech and Signal Processing</span>, pp. 6341–6345, 2019.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
S. Ramaswamy, R. Mathews, K. Rao, and F. Beaufays, “Federated learning for emoji prediction in a mobile keyboard,” <span id="bib.bib40.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1906.04329</span>, 2019.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
A. Fallah, A. Mokhtari, and A. Ozdaglar, “Personalized federated learning with theoretical guarantees: A model-agnostic meta-learning approach,” in <span id="bib.bib41.1.1" class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems</span>, vol. 33, 2020.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
K. Zhang, X. Song, C. Zhang, and C. Yu, “Challenges and future directions of secure federated learning: a survey,” <span id="bib.bib42.1.1" class="ltx_text ltx_font_italic">Frontiers in Computer Science</span>, vol. 16, no. 5, p. 165817, 2022.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
Y. Liu, Y. Kang, T. Zou, Y. Pu, Y. He, X. Ye, Y. Ouyang, Y. Zhang, and Q. Yang, “Vertical federated learning,” <span id="bib.bib43.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2211.12814</span>, 2022.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
L. Yang, D. Chai, J. Zhang, Y. Jin, L. Wang, H. Liu, H. Tian, Q. Xu, and K. Chen, “A survey on vertical federated learning: From a layered perspective,” <span id="bib.bib44.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2304.01829</span>, 2023.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
A. Khan, M. T. Thij, and A. Wilbik, “Communication-efficient vertical federated learning,” <span id="bib.bib45.1.1" class="ltx_text ltx_font_italic">Algorithms</span>, vol. 15, no. 8, p. 273, 2022.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
D. Serpanos and G. Xenos, “Vertical federated learning in malware detection for smart cities,” in <span id="bib.bib46.1.1" class="ltx_text ltx_font_italic">IEEE International Conference on Security</span>, 2023.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
C. Fu, X. Zhang, S. Ji, J. Chen, J. Wu, S. Guo, J. Zhou, A. X. Liu, and T. Wang, “Label inference attacks against vertical federated learning,” 2022.

</span>
<span class="ltx_bibblock">DBLP conference proceedings.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
A. Jacot, F. Gabriel, and C. Hongler, “Neural tangent kernel: Convergence and generalization in neural networks,” <span id="bib.bib48.1.1" class="ltx_text ltx_font_italic">Proceedings of the National Academy of Sciences</span>, vol. 115, no. 34, pp. E7665–E7671, 2018.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
A. Reiss and D. Stricker, “Introducing a new benchmarked dataset for activity monitoring,” in <span id="bib.bib49.1.1" class="ltx_text ltx_font_italic">2012 16th International Symposium on Wearable Computers</span>, pp. 108–109, IEEE, 2012.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
U. Sait, K. G. Lal, S. Prajapati, R. Bhaumik, T. Kumar, S. Sanjana, and K. Bhalla, “Curated dataset for covid-19 posterior-anterior chest radiography images (x-rays),” 2020.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
J. Yang, R. Shi, and B. Ni, “Medmnist classification decathlon: A lightweight automl benchmark for medical image analysis,” in <span id="bib.bib51.1.1" class="ltx_text ltx_font_italic">2021 IEEE 18th International Symposium on Biomedical Imaging (ISBI)</span>, pp. 191–195, IEEE, 2021.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
J. Yang, R. Shi, D. Wei, Z. Liu, L. Zhao, B. Ke, H. Pfister, and B. Ni, “MedMNIST v2-a large-scale lightweight benchmark for 2d and 3d biomedical image classification,” <span id="bib.bib52.1.1" class="ltx_text ltx_font_italic">Scientific Data</span>, vol. 10, no. 1, p. 41, 2023.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
P. Bilic, P. F. Christ, E. Vorontsov, G. Chlebus, H. Chen, Q. Dou, C.-W. Fu, X. Han, P.-A. Heng, J. Hesser, <span id="bib.bib53.1.1" class="ltx_text ltx_font_italic">et al.</span>, “The liver tumor segmentation benchmark (lits),” <span id="bib.bib53.2.2" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1901.04056</span>, 2019.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock">
X. Xu, F. Zhou, B. Liu, D. Fu, and X. Bai, “Efficient multiple organ localization in ct image using 3d region proposal network,” <span id="bib.bib54.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Medical Imaging</span>, vol. 38, no. 8, pp. 1885–1898, 2019.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
G. Hinton, O. Vinyals, and J. Dean, “Distilling the knowledge in a neural network,” <span id="bib.bib55.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1503.02531</span>, 2015.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock">
D. Yang <span id="bib.bib56.1.1" class="ltx_text ltx_font_italic">et al.</span>, “Federated learning with knowledge distillation for multi-organ segmentation with partially labeled datasets,” <span id="bib.bib56.2.2" class="ltx_text ltx_font_italic">Medical Image Analysis</span>, vol. 95, p. 102967, 2024.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock">
T. Lin, L. Kong, S. U. Stich, and M. Jaggi, “Ensemble distillation for robust model fusion in federated learning,” <span id="bib.bib57.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2006.07242</span>, 2020.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock">
T.-M. H. Hsu, H. Qi, and M. Brown, “Measuring the effects of non-identical data distribution for federated visual classification,” <span id="bib.bib58.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1909.06335</span>, 2019.

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock">
H. Khan, N. C. Bouaynaya, and G. Rasool, “Brain-inspired continual learning: Robust feature distillation and re-consolidation for class incremental learning,” <span id="bib.bib59.1.1" class="ltx_text ltx_font_italic">IEEE Access</span>, 2024.

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock">
H. Khan, N. Bouaynaya, and G. Rasool, “The Importance of Robust Features in Mitigating Catastrophic Forgetting,” in <span id="bib.bib60.1.1" class="ltx_text ltx_font_italic">accepted for publication in 28th IEEE Symposium on Computers and Communications (ISCC 2023)</span>, 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2306.17091" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2306.17091</a>.

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock">
Patrick Foley and Micah J Sheller and Brandon Edwards and Sarthak Pati and Walter Riviera and Mansi Sharma and Prakash Narayana Moorthy and Shih-han Wang and Jason Martin and Parsa Mirhaji and Prashant Shah and Spyridon Bakas, “Openfl: the open federated learning library,” <span id="bib.bib61.1.1" class="ltx_text ltx_font_italic">Physics in Medicine &amp; Biology</span>, vol. 67, p. 214001, oct 2022.

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[62]</span>
<span class="ltx_bibblock">
MONAI Team, “MONAI Deploy,” 2023.

</span>
<span class="ltx_bibblock">available at: <a target="_blank" href="https://monai.io/deploy.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://monai.io/deploy.html</a>. Last accessed on Feb 1, 2023.

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[63]</span>
<span class="ltx_bibblock">
NVIDIA Team, “NVIDIA Clara,” 2023.

</span>
<span class="ltx_bibblock">available at: <a target="_blank" href="https://www.nvidia.com/en-us/clara/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.nvidia.com/en-us/clara/</a>. Last accessed on Feb 1, 2023.

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[64]</span>
<span class="ltx_bibblock">
H. Roth, Y. Cheng, Y. Wen, I. Yang, Z. Xu, Y.-T. Hsieh, K. Kersten, A. Harouni, C. Zhao, K. Lu, Z. Zhang, W. Li, A. Myronenko, D. Yang, S. Yang, N. Rieke, A. Quraini, C. Chen, D. Xu, and A. Feng, “Nvidia flare: Federated learning from simulation to real-world,” 10 2022.

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[65]</span>
<span class="ltx_bibblock">
B. Huang, X. Li, Z. Song, and X. Yang, “Fl-ntk: A neural tangent kernel-based framework for federated learning analysis,” in <span id="bib.bib65.1.1" class="ltx_text ltx_font_italic">Proceedings of the 38th International Conference on Machine Learning</span> (M. Meila and T. Zhang, eds.), vol. 139 of <span id="bib.bib65.2.2" class="ltx_text ltx_font_italic">Proceedings of Machine Learning Research</span>, pp. 4423–4434, PMLR, 18–24 Jul 2021.

</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[66]</span>
<span class="ltx_bibblock">
A. Krizhevsky and G. Hinton, “Cifar-10 (canadian institute for advanced research),” tech. rep., Canadian Institute for Advanced Research, 2009.

</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[67]</span>
<span class="ltx_bibblock">
K. Wei, J. Li, M. Ding, C. Ma, H. H. Yang, F. Farokhi, S. Jin, T. Q. S. Quek, and H. Vincent Poor, “Federated learning with differential privacy: Algorithms and performance analysis,” <span id="bib.bib67.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Information Forensics and Security</span>, vol. 15, pp. 3454–3469, 2020.

</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[68]</span>
<span class="ltx_bibblock">
K. B. Nampalle, P. Singh, U. Narayan, and B. Raman, “Vision through the veil: Differential privacy in federated learning for medical image classification,” 06 2023.

</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[69]</span>
<span class="ltx_bibblock">
M. Asad, A. Moustafa, and T. Ito, “Fedopt: Towards communication efficiency and privacy preservation in federated learning,” <span id="bib.bib69.1.1" class="ltx_text ltx_font_italic">Applied Sciences</span>, vol. 10, pp. 1–17, 04 2020.

</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[70]</span>
<span class="ltx_bibblock">
D. Truhn, S. T. Arasteh, O. L. Saldanha, G. Müller-Franzes, F. Khader, P. Quirke, N. P. West, R. Gray, G. G. Hutchins, J. A. James, M. B. Loughrey, M. Salto-Tellez, H. Brenner, A. Brobeil, T. Yuan, J. Chang-Claude, M. Hoffmeister, S. Foersch, T. Han, S. Keil, M. Schulze-Hagen, P. Isfort, P. Bruners, G. Kaissis, C. Kuhl, S. Nebelung, and J. N. Kather, “Encrypted federated learning for secure decentralized collaboration in cancer image analysis,” <span id="bib.bib70.1.1" class="ltx_text ltx_font_italic">Medical Image Analysis</span>, p. 103059, 2023.

</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[71]</span>
<span class="ltx_bibblock">
S. Truex, N. Baracaldo, A. Anwar, T. Steinke, H. Ludwig, R. Zhang, and Y. Zhou, “A hybrid approach to privacy-preserving federated learning,” AISec’19, (New York, NY, USA), p. 1–11, Association for Computing Machinery, 2019.

</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[72]</span>
<span class="ltx_bibblock">
T. Qi, F. Wu, C. Wu, L. He, Y. Huang, and X. Xie, “Differentially private knowledge transfer for federated learning,” <span id="bib.bib72.1.1" class="ltx_text ltx_font_italic">Nature Communications</span>, vol. 14, p. 3785, June 2023.

</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[73]</span>
<span class="ltx_bibblock">
J. So, R. E. Ali, B. Güler, J. Jiao, and A. S. Avestimehr, “Securing secure aggregation: Mitigating multi-round privacy leakage in federated learning,” AAAI’23/IAAI’23/EAAI’23, AAAI Press, 2023.

</span>
</li>
<li id="bib.bib74" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[74]</span>
<span class="ltx_bibblock">
T. Wang, Q. Yang, K. Zhu, J. Wang, C. Su, and K. Sato, “Lds-fl: Loss differential strategy based federated learning for privacy preserving,” <span id="bib.bib74.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Information Forensics and Security</span>, vol. 19, pp. 1015–1030, 2024.

</span>
</li>
<li id="bib.bib75" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[75]</span>
<span class="ltx_bibblock">
R. Xu, N. Baracaldo, Y. Zhou, A. Anwar, S. Kadhe, and H. Ludwig, “Detrust-fl: Privacy-preserving federated learning in decentralized trust setting,” <span id="bib.bib75.1.1" class="ltx_text ltx_font_italic">2022 IEEE 15th International Conference on Cloud Computing (CLOUD)</span>, pp. 417–426, 2022.

</span>
</li>
<li id="bib.bib76" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[76]</span>
<span class="ltx_bibblock">
M. Y. Lu, R. J. Chen, D. Kong, J. Lipkova, R. Singh, D. F. Williamson, T. Y. Chen, and F. Mahmood, “Federated learning for computational pathology on gigapixel whole slide images,” <span id="bib.bib76.1.1" class="ltx_text ltx_font_italic">Medical Image Analysis</span>, vol. 76, p. 102298, 2022.

</span>
</li>
<li id="bib.bib77" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[77]</span>
<span class="ltx_bibblock">
W. Li, F. Milletarì, D. Xu, N. Rieke, J. Hancox, W. Zhu, M. Baust, Y. Cheng, S. Ourselin, M. Cardoso, and A. Feng, “Privacy-preserving federated brain tumour segmentation,” <span id="bib.bib77.1.1" class="ltx_text ltx_font_italic">Hindawi</span>, 2019.

</span>
</li>
<li id="bib.bib78" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[78]</span>
<span class="ltx_bibblock">
P. Nanayakkara, J. Bater, X. He, J. Hullman, and J. Duggan, “Visualizing privacy-utility trade-offs in differentially private data releases,” <span id="bib.bib78.1.1" class="ltx_text ltx_font_italic">Proceedings on Privacy Enhancing Technologies</span>, 2022.

</span>
</li>
<li id="bib.bib79" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[79]</span>
<span class="ltx_bibblock">
L. Xu, C. Jiang, Y. Qian, J. Li, Y. Zhao, and Y. Ren, “Privacy-accuracy trade-off in differentially-private distributed classification: A game theoretical approach,” <span id="bib.bib79.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Big Data</span>, 2021.

</span>
</li>
<li id="bib.bib80" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[80]</span>
<span class="ltx_bibblock">
M. Adnan, S. Kalra, J. C. Cresswell, G. W. Taylor, and H. Tizhoosh, “Federated learning and differential privacy for medical image analysis,” <span id="bib.bib80.1.1" class="ltx_text ltx_font_italic">Nature</span>, 2021.

</span>
</li>
<li id="bib.bib81" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[81]</span>
<span class="ltx_bibblock">
O. Choudhury, A. Gkoulalas-Divanis, T. Salonidis, I. Sylla, Y. Park, G. Hsu, and A. K. Das, “Differential privacy-enabled federated learning for sensitive health data,” <span id="bib.bib81.1.1" class="ltx_text ltx_font_italic">ArXiv</span>, vol. abs/1910.02578, 2019.

</span>
</li>
<li id="bib.bib82" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[82]</span>
<span class="ltx_bibblock">
S. Dhiman, S. Nayak, G. K. Mahato, A. Ram, and S. K. Chakraborty, “Homomorphic encryption based federated learning for financial data security,” in <span id="bib.bib82.1.1" class="ltx_text ltx_font_italic">IEEE International Conference on Innovations in Computer Science and Engineering (I3CS)</span>, 2023.

</span>
</li>
<li id="bib.bib83" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[83]</span>
<span class="ltx_bibblock">
D. Stripelis, H. Saleem, T. Ghai, N. J. Dhinagar, U. Gupta, C. Anastasiou, G. V. Steeg, S. Ravi, M. Naveed, P. M. Thompson, and J. Ambite, “Secure neuroimaging analysis using federated learning with homomorphic encryption,” in <span id="bib.bib83.1.1" class="ltx_text ltx_font_italic">SPIE Medical Imaging</span>, 2021.

</span>
</li>
<li id="bib.bib84" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[84]</span>
<span class="ltx_bibblock">
K. Burlachenko, A. Alrowithi, F. A. Albalawi, and P. Richtárik, “Federated learning is better with non-homomorphic encryption,” in <span id="bib.bib84.1.1" class="ltx_text ltx_font_italic">Proceedings of the ACM Symposium on Cloud Computing</span>, 2023.

</span>
</li>
<li id="bib.bib85" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[85]</span>
<span class="ltx_bibblock">
A. Acar, H. Aksu, A. S. Uluagac, and M. Conti, “A survey on homomorphic encryption schemes: Theory and implementation,” 2017.

</span>
</li>
<li id="bib.bib86" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[86]</span>
<span class="ltx_bibblock">
B. H. Menze, A. Jakab, S. Bauer, J. Kalpathy-Cramer, K. Farahani, J. Kirby, Y. Burren, N. Porz, J. Slotboom, R. Wiest, <span id="bib.bib86.1.1" class="ltx_text ltx_font_italic">et al.</span>, “The multimodal brain tumor image segmentation benchmark (brats),” <span id="bib.bib86.2.2" class="ltx_text ltx_font_italic">IEEE transactions on medical imaging</span>, vol. 34, no. 10, pp. 1993–2024, 2015.

</span>
</li>
<li id="bib.bib87" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[87]</span>
<span class="ltx_bibblock">
T. C. G. A. Network, “Comprehensive molecular characterization of human colon and rectal cancer,” <span id="bib.bib87.1.1" class="ltx_text ltx_font_italic">Nature</span>, vol. 487, no. 7407, pp. 330–337, 2012.

</span>
</li>
<li id="bib.bib88" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[88]</span>
<span class="ltx_bibblock">
Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner, “Gradient-based learning applied to document recognition,” <span id="bib.bib88.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE</span>, vol. 86, no. 11, pp. 2278–2324, 1998.

</span>
</li>
<li id="bib.bib89" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[89]</span>
<span class="ltx_bibblock">
M. Ryu, Y. Kim, K. Kim, and R. K. Madduri, “Appfl: Open-source software framework for privacy-preserving federated learning,” in <span id="bib.bib89.1.1" class="ltx_text ltx_font_italic">2022 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)</span>, (Los Alamitos, CA, USA), pp. 1074–1083, IEEE Computer Society, jun 2022.

</span>
</li>
<li id="bib.bib90" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[90]</span>
<span class="ltx_bibblock">
S. Boyd, N. Parikh, E. Chu, B. Peleato, and J. Eckstein, “Distributed optimization and statistical learning via the alternating direction method of multipliers,” <span id="bib.bib90.1.1" class="ltx_text ltx_font_italic">Foundations and Trends in Machine Learning</span>, vol. 3, no. 1, pp. 1–122, 2011.

</span>
</li>
<li id="bib.bib91" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[91]</span>
<span class="ltx_bibblock">
G. Kaissis, A. Ziller, J. Passerat-Palmbach, T. Ryffel, D. Usynin, A. Trask, I. Lima, J. Mancuso, F. Jungmann, M.-M. Steinborn, A. Saleh, M. Makowski, D. Rueckert, and R. Braren, “End-to-end privacy preserving deep learning on multi-institutional medical imaging,” <span id="bib.bib91.1.1" class="ltx_text ltx_font_italic">Nature Machine Intelligence</span>, vol. 3, pp. 1–12, 06 2021.

</span>
</li>
<li id="bib.bib92" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[92]</span>
<span class="ltx_bibblock">
N. Shi, F. Lai, R. A. Kontar, and M. Chowdhury, “Fed-ensemble: Ensemble models in federated learning for improved generalization and uncertainty quantification,” <span id="bib.bib92.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Automation Science and Engineering</span>, pp. 1–0, 2023.

</span>
</li>
<li id="bib.bib93" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[93]</span>
<span class="ltx_bibblock">
V. Plassier, M. Makni, A. Rubashevskii, E. Moulines, and M. Panov, “Conformal prediction for federated uncertainty quantification under label shift,” in <span id="bib.bib93.1.1" class="ltx_text ltx_font_italic">SEFM</span>, vol. 11724 of <span id="bib.bib93.2.2" class="ltx_text ltx_font_italic">Lecture Notes in Computer Science</span>, pp. 183–202, Springer, 2023.

</span>
</li>
<li id="bib.bib94" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[94]</span>
<span class="ltx_bibblock">
C. Lu, Y. Yu, S. P. Karimireddy, M. I. Jordan, and R. Raskar, “Federated conformal predictors for distributed uncertainty quantification,” in <span id="bib.bib94.1.1" class="ltx_text ltx_font_italic">Proceedings of the 40th International Conference on Machine Learning</span>, ICML’23, JMLR.org, 2023.

</span>
</li>
<li id="bib.bib95" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[95]</span>
<span class="ltx_bibblock">
S. Bhatt, A. Gupta, and P. Rai, “Federated learning with uncertainty via distilled predictive distributions,” 2023.

</span>
</li>
<li id="bib.bib96" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[96]</span>
<span class="ltx_bibblock">
S.-M. Lee and J.-L. Wu, “Fedua: An uncertainty-aware distillation-based federated learning scheme for image classification,” <span id="bib.bib96.1.1" class="ltx_text ltx_font_italic">Information</span>, vol. 14, p. 234, Apr 2023.

</span>
</li>
<li id="bib.bib97" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[97]</span>
<span class="ltx_bibblock">
D. Makhija, J. Ghosh, and N. Ho, “Privacy preserving bayesian federated learning in heterogeneous settings,” <span id="bib.bib97.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2306.07959</span>, 2023.

</span>
</li>
<li id="bib.bib98" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[98]</span>
<span class="ltx_bibblock">
Y. Zhang, T. Xia, A. Ghosh, and C. Mascolo, “Uncertainty quantification in federated learning for heterogeneous health data,” in <span id="bib.bib98.1.1" class="ltx_text ltx_font_italic">International Workshop on Federated Learning for Distributed Data Mining</span>, 2023.

</span>
</li>
<li id="bib.bib99" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[99]</span>
<span class="ltx_bibblock">
H. Chen, J. Ding, E. W. Tramel, S. Wu, A. K. Sahu, S. Avestimehr, and T. Zhang, “Self-aware personalized federated learning,” <span id="bib.bib99.1.1" class="ltx_text ltx_font_italic">ArXiv</span>, vol. abs/2204.08069, 2022.

</span>
</li>
<li id="bib.bib100" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[100]</span>
<span class="ltx_bibblock">
X. Zhang, Y. Li, W. Li, K. Guo, and Y. Shao, “Personalized federated learning via variational Bayesian inference,” in <span id="bib.bib100.1.1" class="ltx_text ltx_font_italic">Proceedings of the 39th International Conference on Machine Learning</span> (K. Chaudhuri, S. Jegelka, L. Song, C. Szepesvari, G. Niu, and S. Sabato, eds.), vol. 162 of <span id="bib.bib100.2.2" class="ltx_text ltx_font_italic">Proceedings of Machine Learning Research</span>, pp. 26293–26310, PMLR, 17–23 Jul 2022.

</span>
</li>
<li id="bib.bib101" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[101]</span>
<span class="ltx_bibblock">
N. Kotelevskii, M. Vono, A. Durmus, and E. Moulines, “Fedpop: A bayesian approach for personalised federated learning,” in <span id="bib.bib101.1.1" class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems</span> (S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh, eds.), vol. 35, pp. 8687–8701, Curran Associates, Inc., 2022.

</span>
</li>
<li id="bib.bib102" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[102]</span>
<span class="ltx_bibblock">
T. Zhou, J. Zhang, and D. H. Tsang, “Fedfa: Federated learning with feature anchors to align features and classifiers for heterogeneous data,” <span id="bib.bib102.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Mobile Computing</span>, pp. 1–12, 2023.

</span>
</li>
<li id="bib.bib103" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[103]</span>
<span class="ltx_bibblock">
A. T. Thorgeirsson and F. Gauterin, “Probabilistic predictions with federated learning,” <span id="bib.bib103.1.1" class="ltx_text ltx_font_italic">Entropy</span>, vol. 23, 2020.

</span>
</li>
<li id="bib.bib104" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[104]</span>
<span class="ltx_bibblock">
M. Luo, F. Chen, D. Hu, Y. Zhang, J. Liang, and J. Feng, “No fear of heterogeneity: Classifier calibration for federated learning with non-iid data,” <span id="bib.bib104.1.1" class="ltx_text ltx_font_italic">ArXiv</span>, vol. abs/2106.05001, 2021.

</span>
</li>
<li id="bib.bib105" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[105]</span>
<span class="ltx_bibblock">
Z. Qi, L. Meng, Z. Chen, H. Hu, H. Lin, and X. Meng, “Cross-silo prototypical calibration for federated learning with non-iid data,” MM ’23, (New York, NY, USA), p. 3099–3107, Association for Computing Machinery, 2023.

</span>
</li>
<li id="bib.bib106" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[106]</span>
<span class="ltx_bibblock">
B. Sanderson, “Uncertainty quantification in multi-model ensembles,” <span id="bib.bib106.1.1" class="ltx_text ltx_font_italic">Oxford Research Encyclopedia of Climate Science</span>, 2018.

</span>
</li>
<li id="bib.bib107" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[107]</span>
<span class="ltx_bibblock">
A. Krizhevsky, “Learning multiple layers of features from tiny images. university of toronto (2012),” <a target="_blank" href="http://www.cs.toronto.edu/kriz/cifar.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://www.cs.toronto.edu/kriz/cifar.html</a><span id="bib.bib107.1.1" class="ltx_text ltx_font_italic">, last accessed</span>, vol. 5, p. 13, 2022.

</span>
</li>
<li id="bib.bib108" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[108]</span>
<span class="ltx_bibblock">
A. Kuznetsova, H. Rom, N. Alldrin, J. Uijlings, I. Krasin, J. Pont-Tuset, S. Kamali, S. Popov, M. Malloci, A. Kolesnikov, <span id="bib.bib108.1.1" class="ltx_text ltx_font_italic">et al.</span>, “The open images dataset v4,” <span id="bib.bib108.2.2" class="ltx_text ltx_font_italic">International Journal of Computer Vision</span>, pp. 1–26, 2020.

</span>
</li>
<li id="bib.bib109" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[109]</span>
<span class="ltx_bibblock">
A. Gammerman, V. Vovk, and V. Vapnik, “Learning by transduction,” in <span id="bib.bib109.1.1" class="ltx_text ltx_font_italic">Proceedings of the Fourteenth Conference on Uncertainty in Artificial Intelligence</span>, UAI’98, (San Francisco, CA, USA), p. 148–155, Morgan Kaufmann Publishers Inc., 1998.

</span>
</li>
<li id="bib.bib110" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[110]</span>
<span class="ltx_bibblock">
C. Saunders, A. Gammerman, and V. Vovk, “Transduction with confidence and credibility.,” pp. 722–726, 01 1999.

</span>
</li>
<li id="bib.bib111" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[111]</span>
<span class="ltx_bibblock">
C. Lu and J. Kalpathy-Cramer, “Distribution-free federated learning with conformal predictions,” <span id="bib.bib111.1.1" class="ltx_text ltx_font_italic">ArXiv</span>, vol. abs/2110.07661, 2021.

</span>
</li>
<li id="bib.bib112" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[112]</span>
<span class="ltx_bibblock">
O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. S. Bernstein, A. C. Berg, and L. Fei-Fei, “Imagenet large scale visual recognition challenge,” <span id="bib.bib112.1.1" class="ltx_text ltx_font_italic">Int. J. Comput. Vis.</span>, vol. 115, no. 3, pp. 211–252, 2015.

</span>
</li>
<li id="bib.bib113" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[113]</span>
<span class="ltx_bibblock">
V. Vovk, A. Gammerman, and G. Shafer, <span id="bib.bib113.1.1" class="ltx_text ltx_font_italic">Algorithmic Learning in a Random World</span>.

</span>
<span class="ltx_bibblock">Statistics for Engineering and Information Science, Springer, 2005.

</span>
</li>
<li id="bib.bib114" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[114]</span>
<span class="ltx_bibblock">
K. E. Brown and D. A. Talbert, “A simple direct uncertainty quantification technique based on machine learning regression,” <span id="bib.bib114.1.1" class="ltx_text ltx_font_italic">FLAIRS Conference</span>, 2022.

</span>
</li>
<li id="bib.bib115" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[115]</span>
<span class="ltx_bibblock">
M. Swaminathan, O. W. Bhatti, Y. Guo, E. Huang, and O. Akinwande, “Bayesian learning for uncertainty quantification, optimization, and inverse design,” <span id="bib.bib115.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Microwave Theory and Techniques</span>, 2022.

</span>
</li>
<li id="bib.bib116" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[116]</span>
<span class="ltx_bibblock">
O. Dalmaz, M. U. Mirza, G. Elmas, M. Ozbey, S. U. Dar, E. Ceyani, K. K. Oguz, S. Avestimehr, and T. Çukur, “One model to unite them all: Personalized federated learning of multi-contrast mri synthesis,” <span id="bib.bib116.1.1" class="ltx_text ltx_font_italic">Medical Image Analysis</span>, vol. 94, p. 103121, 2024.

</span>
</li>
<li id="bib.bib117" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[117]</span>
<span class="ltx_bibblock">
S. Caldas, S. M. K. Duddu, P. Wu, T. Li, J. Konečnỳ, H. B. McMahan, V. Smith, and A. Talwalkar, “Federated extended mnist (femnist).” <a target="_blank" href="https://github.com/TalwalkarLab/leaf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/TalwalkarLab/leaf</a>, 2018.

</span>
</li>
<li id="bib.bib118" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[118]</span>
<span class="ltx_bibblock">
A. Go, R. Bhayani, and L. Huang, “Sentiment140.” <a target="_blank" href="http://help.sentiment140.com/for-students" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://help.sentiment140.com/for-students</a>, 2009.

</span>
</li>
<li id="bib.bib119" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[119]</span>
<span class="ltx_bibblock">
L. Breiman, “Bagging predictors,” <span id="bib.bib119.1.1" class="ltx_text ltx_font_italic">Machine Learning</span>, vol. 24, no. 2, pp. 123–140, 1996.

</span>
</li>
<li id="bib.bib120" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[120]</span>
<span class="ltx_bibblock">
T. Pearce, A. Brintrup, and J. Zhu, “Understanding softmax confidence and uncertainty,” <span id="bib.bib120.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2106.04972</span>, 2021.

</span>
</li>
<li id="bib.bib121" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[121]</span>
<span class="ltx_bibblock">
“Tiny imagenet.” <a target="_blank" href="https://tiny-imagenet.herokuapp.com/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://tiny-imagenet.herokuapp.com/</a>.

</span>
</li>
<li id="bib.bib122" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[122]</span>
<span class="ltx_bibblock">
“Vireofood-172.” <a target="_blank" href="https://fvl.fudan.edu.cn/dataset/vireofood172/list.htm" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://fvl.fudan.edu.cn/dataset/vireofood172/list.htm</a>.

</span>
</li>
<li id="bib.bib123" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[123]</span>
<span class="ltx_bibblock">
S. Pati, U. Baid, M. Zenk, B. Edwards, M. Sheller, G. A. Reina, P. Foley, A. Gruzdev, J. Martin, S. Albarqouni, Y. Chen, R. T. Shinohara, A. Reinke, D. Zimmerer, J. B. Freymann, J. S. Kirby, C. Davatzikos, R. R. Colen, A. Kotrotsou, D. Marcus, M. Milchenko, A. Nazeri, H. Fathallah-Shaykh, R. Wiest, A. Jakab, M.-A. Weber, A. Mahajan, L. Maier-Hein, J. Kleesiek, B. Menze, K. Maier-Hein, and S. Bakas, “The federated tumor segmentation (fets) challenge,” 2021.

</span>
</li>
<li id="bib.bib124" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[124]</span>
<span class="ltx_bibblock">
O. Ronneberger, P. Fischer, and T. Brox, “U-net: Convolutional networks for biomedical image segmentation,” in <span id="bib.bib124.1.1" class="ltx_text ltx_font_italic">Medical Image Computing and Computer-Assisted Intervention – MICCAI 2015</span>, (Cham), pp. 234–241, Springer International Publishing, 2015.

</span>
</li>
<li id="bib.bib125" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">[125]</span>
<span class="ltx_bibblock">
S. Pati, U. Baid, B. Edwards, M. Sheller, S.-H. Wang, G. A. Reina, P. Foley, A. Gruzdev, D. Karkada, C. Davatzikos, <span id="bib.bib125.1.1" class="ltx_text ltx_font_italic">et al.</span>, “Federated learning enables big data for rare cancer boundary detection,” <span id="bib.bib125.2.2" class="ltx_text ltx_font_italic">Nature communications</span>, vol. 13, no. 1, p. 7346, 2022.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2406.12814" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2406.12815" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2406.12815">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2406.12815" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2406.12816" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sat Jul  6 01:35:34 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
