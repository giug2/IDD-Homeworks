<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2302.12883] 3D Surface Reconstruction in the Wild by Deforming Shape Priors from Synthetic Data</title><meta property="og:description" content="Reconstructing the underlying 3D surface of an object from a single image is a challenging problem that has received extensive attention from the computer vision community. Many learning-based approaches tackle this prâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="3D Surface Reconstruction in the Wild by Deforming Shape Priors from Synthetic Data">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="3D Surface Reconstruction in the Wild by Deforming Shape Priors from Synthetic Data">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2302.12883">

<!--Generated on Fri Mar  1 00:07:29 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">3D Surface Reconstruction in the Wild by Deforming Shape Priors from Synthetic Data</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Nicolai HÃ¤ni
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">University of Minnesota
<br class="ltx_break">Minneapolis, Minnesota 55455
<br class="ltx_break">Email: haeni001@umn.edu
</span></span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jun-Jee Chao
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">University of Minnesota
<br class="ltx_break">Minneapolis, Minnesota 55455
<br class="ltx_break">Email: chao0107@umn.edu 
</span></span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Volkan Isler
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">University of Minnesota
<br class="ltx_break">Minneapolis, Minnesota 55455
<br class="ltx_break">Email: isler@umn.edu
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">Reconstructing the underlying 3D surface of an object from a single image is a challenging problem that has received extensive attention from the computer vision community. Many learning-based approaches tackle this problem by learning a 3D shape prior from either ground truth 3D data or multi-view observations. To achieve state-of-the-art results, these methods assume that the objects are specified with respect to a fixed canonical coordinate frame, where instances of the same category are perfectly aligned. In this work, we present a new method for joint category-specific 3D reconstruction and object pose estimation from a single image. We show that one can leverage shape priors learned on purely synthetic 3D data together with a point cloud pose canonicalization method to achieve high quality 3D reconstruction in the wild. Given a single depth image at test time, we first transform this partial point cloud into a learned canonical frame. Then, we use a neural deformation field in to reconstruct the 3D surface of the object. Finally, we jointly optimize object pose and 3D shape to fit the partial depth observation. Our approach achieves state-of-the-art reconstruction performance across several real-world datasets, even when trained only on synthetic data. We further show that our method generalizes to different input modalities, from dense depth images to sparse and noisy LIDAR scans.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Surface reconstruction of a 3D object from a partial observation, such as a depth image or a LIDAR scan, is a longstanding problem in computer visionÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref">61</a>, <a href="#bib.bib65" title="" class="ltx_ref">65</a>, <a href="#bib.bib38" title="" class="ltx_ref">38</a>, <a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite>. Discovering the full shape of an object from a partial input has many applications, including in visual servoingÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>, robotic manipulationÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib39" title="" class="ltx_ref">39</a>, <a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite>, autonomous drivingÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib67" title="" class="ltx_ref">67</a>]</cite> and content creationÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Every computational approach aimed at 3D reconstruction must choose a representation for the D model.
An increasingly popular choice is to use neural fieldsÂ <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>, <a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> for this task. These neural fields, trained on 3D ground truth data, represent the de-facto gold standard regarding reconstruction quality. At inference time, the learned 3D shape prior is adapted to the partial observation. However, these methods suffer from two major limitations: i) they require 3D ground truth data in the form of occupancy values or signed distance functions and ii) these models expect shapes to be aligned and normalized in a fixed canonical coordinate frame - a frame of reference that is shared between all instances in the shape category. These two limitations have for now, limited these approaches to synthetic data, such as ShapenetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">To remove the reliance on 3D data, the community has shifted to denseÂ <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>, or sparseÂ <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib68" title="" class="ltx_ref">68</a>]</cite> multi-view supervision with known camera poses, which can be estimated using Structure from Motion (SfM). Similarly, single-view 3D reconstruction methods have also made considerable progress by using neural fields as their shape representationÂ <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. While these single-view methods can be trained from unconstrained image collections, they have not achieved the high quality of multi-view or 3D ground truth supervised models. In this work, we aim to answer the question: <span id="S1.p3.1.1" class="ltx_text ltx_font_italic">How can we achieve the reconstruction quality of 3D supervised methods from single view observations in the wild?</span></p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2302.12883/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="348" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>We pretrain a 3D shape prior on synthetic 3D data. Using the Equi-poseÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> canonicalization algorithm, we register the depth image to the canonical coordinate frame and use a finetuning scheme to jointly estimate the surface reconstruction and object pose from a single observation, leading to a model that generates diverse 3D reconstructions and object poses.</figcaption>
</figure>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">We propose to use a single depth image from a calibrated camera together with a pretrained canonicalization network to register the partial point clouds to the canonical coordinate space. We reduce the effect of errors in the canonicalization process by jointly fine-tuning the latent shape descriptor and object pose using only the partial observation as input (FigureÂ <a href="#S1.F1" title="Figure 1 â€£ I Introduction â€£ 3D Surface Reconstruction in the Wild by Deforming Shape Priors from Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>).
We achieve 3D reconstruction results on synthetic data close to or better than the state-of-the-art. Furthermore, we show that using depth images as input allows for generalization across various datasets, from dense depth in synthetic and natural images to sparse depth inputs from LIDAR scans.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Related Work</span>
</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">3D object reconstruction based on a conditional input, such as images or depth is an active research areaÂ <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib35" title="" class="ltx_ref">35</a>, <a href="#bib.bib36" title="" class="ltx_ref">36</a>, <a href="#bib.bib47" title="" class="ltx_ref">47</a>, <a href="#bib.bib52" title="" class="ltx_ref">52</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>. The defacto gold standard in terms of reconstruction quality uses 3D ground truth dataÂ <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>, <a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>. These approaches are largely limited to synthetic data, such as ShapenetÂ <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> as they require shapes that are aligned in a common canonical coordinate frame. Reconstruction of real-world shapes has been performed by transferring the learned representation across domainsÂ <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> or with the use of special depth sensorsÂ <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>. However, collecting 3D ground truth data in the real world can be difficult. With the development of neural rendering and inverse graphics methods, the requirement for 3D ground truth has been relaxed in favor of dense multi-view supervisionÂ <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib59" title="" class="ltx_ref">59</a>, <a href="#bib.bib36" title="" class="ltx_ref">36</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib68" title="" class="ltx_ref">68</a>]</cite> or single view methods that require ground truth camera poses for trainingÂ <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. However, not all applications allow for the collection of multi-view images, and estimating camera poses from images remains challenging. With the advent of generative models for 3D shapesÂ <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>, using 3D supervision has become an interesting prospect once more. Our work shows how we can leverage shape canonicalization for shape reconstruction in the wild.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS1.5.1.1" class="ltx_text">II-A</span> </span><span id="S2.SS1.6.2" class="ltx_text ltx_font_italic">Pose Registration and 3D Shape Canonicalization</span>
</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Reliance on camera poses is an issue for many real-world datasets but a necessary step for neural rendering or deformation-based models.
Point cloud registration can estimate the object pose directly and has achieved good performance when matching point clouds of the same object; however, these methods are unsuitable for single view pose estimation without a ground truth 3D modelÂ <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>, <a href="#bib.bib54" title="" class="ltx_ref">54</a>, <a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite>. Category-level object pose estimation methods achieve tremendous results, for supervised training mechanismsÂ <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>, <a href="#bib.bib41" title="" class="ltx_ref">41</a>, <a href="#bib.bib53" title="" class="ltx_ref">53</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>, and using only self-supervision Â <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>, <a href="#bib.bib50" title="" class="ltx_ref">50</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib45" title="" class="ltx_ref">45</a>, <a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>. For example, Canonical CapsulesÂ <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib50" title="" class="ltx_ref">50</a>]</cite> learn to represent object parts with pose-invariant capsules by training a Siamese network in a self-supervised manner. Although the learned capsules can reconstruct the input point cloud in the learned canonical frame, Canonical Capsules only works on complete point clouds. In contrast, Equi-poseÂ <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> can canonicalize both complete and partial point clouds. By leveraging an SE(3) equivariant network, Equi-pose simultaneously learns to estimate object pose and canonical point cloud completion. Our work shows that one can leverage Equi-pose with test time pose refinement to get accurate shape reconstructions in canonical space.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS2.5.1.1" class="ltx_text">II-B</span> </span><span id="S2.SS2.6.2" class="ltx_text ltx_font_italic">Pointcloud Completion</span>
</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">Instead of relying on ground truth camera poses, we use depth images to register the partial 3D point cloud into a canonical frame. As we use depth images as input, our method closely relates to point cloud completion algorithms. Early work on point cloud completion used 3D convolutions to learn shape completionÂ <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>. However, 3D convolutions are costly and operate on a canonical voxel grid. More recently, PointNet encoders were used for shape completionÂ <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>, <a href="#bib.bib66" title="" class="ltx_ref">66</a>]</cite>. Transformers have also been shown to work well on this taskÂ <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib65" title="" class="ltx_ref">65</a>, <a href="#bib.bib61" title="" class="ltx_ref">61</a>]</cite>. However, these methods rely on points already in a canonical coordinate frame. Further, these methods do not reconstruct the underlying surface of the object but output a limited number of points. In contrast, out method does not rely on canonical input points and reconstructs the underlying object surface with high fidelity.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS3.5.1.1" class="ltx_text">II-C</span> </span><span id="S2.SS3.6.2" class="ltx_text ltx_font_italic">Surface Reconstruction from a Single View</span>
</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">There have been extensive studies on 3D reconstruction from single view images using various 3D representations, such as voxelsÂ <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib60" title="" class="ltx_ref">60</a>, <a href="#bib.bib52" title="" class="ltx_ref">52</a>, <a href="#bib.bib56" title="" class="ltx_ref">56</a>, <a href="#bib.bib62" title="" class="ltx_ref">62</a>, <a href="#bib.bib56" title="" class="ltx_ref">56</a>, <a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite>, pointsÂ <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib63" title="" class="ltx_ref">63</a>]</cite>, primitivesÂ <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> or meshesÂ <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>. Most of the methods above use explicit representations, which suffer from limited resolution or fixed topology. Neural rendering and neural fields provide an alternative representation to overcome these limitations. Recent methods showed how to learn Signed Distance Functions (SDFs)Â <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib59" title="" class="ltx_ref">59</a>, <a href="#bib.bib31" title="" class="ltx_ref">31</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> or volumetric representations such as occupancyÂ <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite>, which have shown great promise in learning category-specific 3D reconstructions from unstructured image collections. However, these methods usually require additional information, such as ground truth camera poses or aligned 3D shapes, which limits their applicability. In our work, we propose a method that does not require ground truth camera poses or aligned 3D data and leverages widely available synthetic data to learn a category-specific 3D prior model.</p>
</div>
</section>
<section id="S2.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS4.5.1.1" class="ltx_text">II-D</span> </span><span id="S2.SS4.6.2" class="ltx_text ltx_font_italic">Learning Shape Reconstruction through Deformation</span>
</h3>

<div id="S2.SS4.p1" class="ltx_para">
<p id="S2.SS4.p1.1" class="ltx_p">Learning a generalizable model that maps a low-dimensional latent code to 3D surfaces can suffer from low-quality reconstructions. Category-specific deformable shape priors are useful to improve the quality of the reconstructionÂ <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib24" title="" class="ltx_ref">24</a>, <a href="#bib.bib25" title="" class="ltx_ref">25</a>, <a href="#bib.bib33" title="" class="ltx_ref">33</a>, <a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>. These methods generally learn the deformation to an initial base shape. More recent work has used neural rendering together with SDFsÂ <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> to learn 3D shape priors from image collections and their associated camera poses. Other methodsÂ <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib69" title="" class="ltx_ref">69</a>]</cite> jointly learn the deformation and the template shape in a canonical frame. In this work, we go one step further and show how we can leverage template shape and deformation models for incomplete observations registered to the template coordinate frame.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Method</span>
</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Given a single segmented RGB-D image of an object, our goal is to jointly estimate the object pose and reconstruct the underlying 3D surface. To do so, we first learn a category-specific 3D template in the canonical coordinate frame together with an instance specific deformation field by leveraging synthetic 3D data. During test time, rather than directly reconstructing the shape in the camera coordinate frame, we use recent advances in point cloud canonicalization to transform a partial depth scan to the canonical space for surface reconstruction. Next, we describe first how we learn the 3D shape prior purely on synthetic data. Then we discuss how we reconstruct the surface of an observed depth image by deforming the learned canonical template shape.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2302.12883/assets/x2.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="152" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>We train a DIF-Net as our 3D representation on purely synthetic data in an auto-decoder fashion. During inference, we lift the depth image onto 3D using the known camera intrinsics and estimate an initial transformation between the camera frame and the canonical frame. We jointly optimize the object pose and 3D shape to fit the partial observation. Trainable parameters/network parts are marked in red.</figcaption>
</figure>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS1.5.1.1" class="ltx_text">III-A</span> </span><span id="S3.SS1.6.2" class="ltx_text ltx_font_italic">3D Shape Prior</span>
</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.5" class="ltx_p">Given a set of 3D objects <math id="S3.SS1.p1.1.m1.1" class="ltx_Math" alttext="{\mathcal{O}_{i}}" display="inline"><semantics id="S3.SS1.p1.1.m1.1a"><msub id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p1.1.m1.1.1.2" xref="S3.SS1.p1.1.m1.1.1.2.cmml">ğ’ª</mi><mi id="S3.SS1.p1.1.m1.1.1.3" xref="S3.SS1.p1.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><apply id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p1.1.m1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.1.1.2">ğ’ª</ci><ci id="S3.SS1.p1.1.m1.1.1.3.cmml" xref="S3.SS1.p1.1.m1.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">{\mathcal{O}_{i}}</annotation></semantics></math>, our goal is to learn a category-specific 3D shape prior together with a latent space describing the variation in shapes. Instead of directly mapping a low dimensional latent code <math id="S3.SS1.p1.2.m2.1" class="ltx_Math" alttext="z_{i}\in\mathbb{R}^{n}" display="inline"><semantics id="S3.SS1.p1.2.m2.1a"><mrow id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml"><msub id="S3.SS1.p1.2.m2.1.1.2" xref="S3.SS1.p1.2.m2.1.1.2.cmml"><mi id="S3.SS1.p1.2.m2.1.1.2.2" xref="S3.SS1.p1.2.m2.1.1.2.2.cmml">z</mi><mi id="S3.SS1.p1.2.m2.1.1.2.3" xref="S3.SS1.p1.2.m2.1.1.2.3.cmml">i</mi></msub><mo id="S3.SS1.p1.2.m2.1.1.1" xref="S3.SS1.p1.2.m2.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS1.p1.2.m2.1.1.3" xref="S3.SS1.p1.2.m2.1.1.3.cmml"><mi id="S3.SS1.p1.2.m2.1.1.3.2" xref="S3.SS1.p1.2.m2.1.1.3.2.cmml">â„</mi><mi id="S3.SS1.p1.2.m2.1.1.3.3" xref="S3.SS1.p1.2.m2.1.1.3.3.cmml">n</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><apply id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1"><in id="S3.SS1.p1.2.m2.1.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1.1"></in><apply id="S3.SS1.p1.2.m2.1.1.2.cmml" xref="S3.SS1.p1.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.1.1.2.1.cmml" xref="S3.SS1.p1.2.m2.1.1.2">subscript</csymbol><ci id="S3.SS1.p1.2.m2.1.1.2.2.cmml" xref="S3.SS1.p1.2.m2.1.1.2.2">ğ‘§</ci><ci id="S3.SS1.p1.2.m2.1.1.2.3.cmml" xref="S3.SS1.p1.2.m2.1.1.2.3">ğ‘–</ci></apply><apply id="S3.SS1.p1.2.m2.1.1.3.cmml" xref="S3.SS1.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.1.1.3.1.cmml" xref="S3.SS1.p1.2.m2.1.1.3">superscript</csymbol><ci id="S3.SS1.p1.2.m2.1.1.3.2.cmml" xref="S3.SS1.p1.2.m2.1.1.3.2">â„</ci><ci id="S3.SS1.p1.2.m2.1.1.3.3.cmml" xref="S3.SS1.p1.2.m2.1.1.3.3">ğ‘›</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">z_{i}\in\mathbb{R}^{n}</annotation></semantics></math> to the 3D shape, we follow recent advances in learning 3D shape priors through deformation of a canonical templateÂ <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib69" title="" class="ltx_ref">69</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>. We jointly learn our 3D shape prior, represented as a neural network, and latent codes <math id="S3.SS1.p1.3.m3.1" class="ltx_Math" alttext="z_{i}" display="inline"><semantics id="S3.SS1.p1.3.m3.1a"><msub id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml"><mi id="S3.SS1.p1.3.m3.1.1.2" xref="S3.SS1.p1.3.m3.1.1.2.cmml">z</mi><mi id="S3.SS1.p1.3.m3.1.1.3" xref="S3.SS1.p1.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><apply id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.3.m3.1.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.p1.3.m3.1.1.2.cmml" xref="S3.SS1.p1.3.m3.1.1.2">ğ‘§</ci><ci id="S3.SS1.p1.3.m3.1.1.3.cmml" xref="S3.SS1.p1.3.m3.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">z_{i}</annotation></semantics></math> through the auto-decoder framework presented inÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite>.
To generate high-quality 3D reconstructions, we use signed distance fields (SDFs). SDF is a function that assigns each point <math id="S3.SS1.p1.4.m4.1" class="ltx_Math" alttext="x_{j}\in\mathbb{R}^{3}" display="inline"><semantics id="S3.SS1.p1.4.m4.1a"><mrow id="S3.SS1.p1.4.m4.1.1" xref="S3.SS1.p1.4.m4.1.1.cmml"><msub id="S3.SS1.p1.4.m4.1.1.2" xref="S3.SS1.p1.4.m4.1.1.2.cmml"><mi id="S3.SS1.p1.4.m4.1.1.2.2" xref="S3.SS1.p1.4.m4.1.1.2.2.cmml">x</mi><mi id="S3.SS1.p1.4.m4.1.1.2.3" xref="S3.SS1.p1.4.m4.1.1.2.3.cmml">j</mi></msub><mo id="S3.SS1.p1.4.m4.1.1.1" xref="S3.SS1.p1.4.m4.1.1.1.cmml">âˆˆ</mo><msup id="S3.SS1.p1.4.m4.1.1.3" xref="S3.SS1.p1.4.m4.1.1.3.cmml"><mi id="S3.SS1.p1.4.m4.1.1.3.2" xref="S3.SS1.p1.4.m4.1.1.3.2.cmml">â„</mi><mn id="S3.SS1.p1.4.m4.1.1.3.3" xref="S3.SS1.p1.4.m4.1.1.3.3.cmml">3</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.1b"><apply id="S3.SS1.p1.4.m4.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1"><in id="S3.SS1.p1.4.m4.1.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1.1"></in><apply id="S3.SS1.p1.4.m4.1.1.2.cmml" xref="S3.SS1.p1.4.m4.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p1.4.m4.1.1.2.1.cmml" xref="S3.SS1.p1.4.m4.1.1.2">subscript</csymbol><ci id="S3.SS1.p1.4.m4.1.1.2.2.cmml" xref="S3.SS1.p1.4.m4.1.1.2.2">ğ‘¥</ci><ci id="S3.SS1.p1.4.m4.1.1.2.3.cmml" xref="S3.SS1.p1.4.m4.1.1.2.3">ğ‘—</ci></apply><apply id="S3.SS1.p1.4.m4.1.1.3.cmml" xref="S3.SS1.p1.4.m4.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.4.m4.1.1.3.1.cmml" xref="S3.SS1.p1.4.m4.1.1.3">superscript</csymbol><ci id="S3.SS1.p1.4.m4.1.1.3.2.cmml" xref="S3.SS1.p1.4.m4.1.1.3.2">â„</ci><cn type="integer" id="S3.SS1.p1.4.m4.1.1.3.3.cmml" xref="S3.SS1.p1.4.m4.1.1.3.3">3</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.1c">x_{j}\in\mathbb{R}^{3}</annotation></semantics></math> a scalar value <math id="S3.SS1.p1.5.m5.1" class="ltx_Math" alttext="s_{j}\in\mathbb{R}" display="inline"><semantics id="S3.SS1.p1.5.m5.1a"><mrow id="S3.SS1.p1.5.m5.1.1" xref="S3.SS1.p1.5.m5.1.1.cmml"><msub id="S3.SS1.p1.5.m5.1.1.2" xref="S3.SS1.p1.5.m5.1.1.2.cmml"><mi id="S3.SS1.p1.5.m5.1.1.2.2" xref="S3.SS1.p1.5.m5.1.1.2.2.cmml">s</mi><mi id="S3.SS1.p1.5.m5.1.1.2.3" xref="S3.SS1.p1.5.m5.1.1.2.3.cmml">j</mi></msub><mo id="S3.SS1.p1.5.m5.1.1.1" xref="S3.SS1.p1.5.m5.1.1.1.cmml">âˆˆ</mo><mi id="S3.SS1.p1.5.m5.1.1.3" xref="S3.SS1.p1.5.m5.1.1.3.cmml">â„</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.5.m5.1b"><apply id="S3.SS1.p1.5.m5.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1"><in id="S3.SS1.p1.5.m5.1.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1.1"></in><apply id="S3.SS1.p1.5.m5.1.1.2.cmml" xref="S3.SS1.p1.5.m5.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m5.1.1.2.1.cmml" xref="S3.SS1.p1.5.m5.1.1.2">subscript</csymbol><ci id="S3.SS1.p1.5.m5.1.1.2.2.cmml" xref="S3.SS1.p1.5.m5.1.1.2.2">ğ‘ </ci><ci id="S3.SS1.p1.5.m5.1.1.2.3.cmml" xref="S3.SS1.p1.5.m5.1.1.2.3">ğ‘—</ci></apply><ci id="S3.SS1.p1.5.m5.1.1.3.cmml" xref="S3.SS1.p1.5.m5.1.1.3">â„</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.5.m5.1c">s_{j}\in\mathbb{R}</annotation></semantics></math></p>
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.1" class="ltx_Math" alttext="SDF(x_{j})=s_{j}," display="block"><semantics id="S3.E1.m1.1a"><mrow id="S3.E1.m1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml"><mrow id="S3.E1.m1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml"><mrow id="S3.E1.m1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.cmml"><mi id="S3.E1.m1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.3.cmml">S</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.2.cmml">â€‹</mo><mi id="S3.E1.m1.1.1.1.1.1.4" xref="S3.E1.m1.1.1.1.1.1.4.cmml">D</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.1.1.1.2a" xref="S3.E1.m1.1.1.1.1.1.2.cmml">â€‹</mo><mi id="S3.E1.m1.1.1.1.1.1.5" xref="S3.E1.m1.1.1.1.1.1.5.cmml">F</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.1.1.1.2b" xref="S3.E1.m1.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E1.m1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E1.m1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S3.E1.m1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.cmml">x</mi><mi id="S3.E1.m1.1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3.cmml">j</mi></msub><mo stretchy="false" id="S3.E1.m1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.2.cmml">=</mo><msub id="S3.E1.m1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.3.cmml"><mi id="S3.E1.m1.1.1.1.1.3.2" xref="S3.E1.m1.1.1.1.1.3.2.cmml">s</mi><mi id="S3.E1.m1.1.1.1.1.3.3" xref="S3.E1.m1.1.1.1.1.3.3.cmml">j</mi></msub></mrow><mo id="S3.E1.m1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.1b"><apply id="S3.E1.m1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1"><eq id="S3.E1.m1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.2"></eq><apply id="S3.E1.m1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1"><times id="S3.E1.m1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1.2"></times><ci id="S3.E1.m1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.1.3">ğ‘†</ci><ci id="S3.E1.m1.1.1.1.1.1.4.cmml" xref="S3.E1.m1.1.1.1.1.1.4">ğ·</ci><ci id="S3.E1.m1.1.1.1.1.1.5.cmml" xref="S3.E1.m1.1.1.1.1.1.5">ğ¹</ci><apply id="S3.E1.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2">ğ‘¥</ci><ci id="S3.E1.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3">ğ‘—</ci></apply></apply><apply id="S3.E1.m1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.3.1.cmml" xref="S3.E1.m1.1.1.1.1.3">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.3.2.cmml" xref="S3.E1.m1.1.1.1.1.3.2">ğ‘ </ci><ci id="S3.E1.m1.1.1.1.1.3.3.cmml" xref="S3.E1.m1.1.1.1.1.3.3">ğ‘—</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.1c">SDF(x_{j})=s_{j},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.p1.8" class="ltx_p">representing the distance to the closest object surface. The sign of <math id="S3.SS1.p1.6.m1.1" class="ltx_Math" alttext="s_{j}" display="inline"><semantics id="S3.SS1.p1.6.m1.1a"><msub id="S3.SS1.p1.6.m1.1.1" xref="S3.SS1.p1.6.m1.1.1.cmml"><mi id="S3.SS1.p1.6.m1.1.1.2" xref="S3.SS1.p1.6.m1.1.1.2.cmml">s</mi><mi id="S3.SS1.p1.6.m1.1.1.3" xref="S3.SS1.p1.6.m1.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.6.m1.1b"><apply id="S3.SS1.p1.6.m1.1.1.cmml" xref="S3.SS1.p1.6.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.6.m1.1.1.1.cmml" xref="S3.SS1.p1.6.m1.1.1">subscript</csymbol><ci id="S3.SS1.p1.6.m1.1.1.2.cmml" xref="S3.SS1.p1.6.m1.1.1.2">ğ‘ </ci><ci id="S3.SS1.p1.6.m1.1.1.3.cmml" xref="S3.SS1.p1.6.m1.1.1.3">ğ‘—</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.6.m1.1c">s_{j}</annotation></semantics></math> indicates whether a point is inside (negative) or outside (positive) of the object, and the surface can be extracted as a mesh through marching cubesÂ <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>.
We use a DIF-Net as our 3D shape prior networkÂ <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>.
The 3D representation network consists of a neural template field and a deformation field. We use the template field to capture common structures among a category of shapes by keeping the weights shared across all instances in the training set. The template field takes a 3D coordinate <math id="S3.SS1.p1.7.m2.1" class="ltx_Math" alttext="x_{j}" display="inline"><semantics id="S3.SS1.p1.7.m2.1a"><msub id="S3.SS1.p1.7.m2.1.1" xref="S3.SS1.p1.7.m2.1.1.cmml"><mi id="S3.SS1.p1.7.m2.1.1.2" xref="S3.SS1.p1.7.m2.1.1.2.cmml">x</mi><mi id="S3.SS1.p1.7.m2.1.1.3" xref="S3.SS1.p1.7.m2.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.7.m2.1b"><apply id="S3.SS1.p1.7.m2.1.1.cmml" xref="S3.SS1.p1.7.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.7.m2.1.1.1.cmml" xref="S3.SS1.p1.7.m2.1.1">subscript</csymbol><ci id="S3.SS1.p1.7.m2.1.1.2.cmml" xref="S3.SS1.p1.7.m2.1.1.2">ğ‘¥</ci><ci id="S3.SS1.p1.7.m2.1.1.3.cmml" xref="S3.SS1.p1.7.m2.1.1.3">ğ‘—</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.7.m2.1c">x_{j}</annotation></semantics></math> as input and predicts the signed distance to the closest surface <math id="S3.SS1.p1.8.m3.1" class="ltx_Math" alttext="\hat{s}" display="inline"><semantics id="S3.SS1.p1.8.m3.1a"><mover accent="true" id="S3.SS1.p1.8.m3.1.1" xref="S3.SS1.p1.8.m3.1.1.cmml"><mi id="S3.SS1.p1.8.m3.1.1.2" xref="S3.SS1.p1.8.m3.1.1.2.cmml">s</mi><mo id="S3.SS1.p1.8.m3.1.1.1" xref="S3.SS1.p1.8.m3.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.8.m3.1b"><apply id="S3.SS1.p1.8.m3.1.1.cmml" xref="S3.SS1.p1.8.m3.1.1"><ci id="S3.SS1.p1.8.m3.1.1.1.cmml" xref="S3.SS1.p1.8.m3.1.1.1">^</ci><ci id="S3.SS1.p1.8.m3.1.1.2.cmml" xref="S3.SS1.p1.8.m3.1.1.2">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.8.m3.1c">\hat{s}</annotation></semantics></math>:</p>
<table id="S3.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E2.m1.1" class="ltx_Math" alttext="T:x_{j}\in\mathbb{R}^{3}\rightarrow\hat{s}\in\mathbb{R}" display="block"><semantics id="S3.E2.m1.1a"><mrow id="S3.E2.m1.1.1" xref="S3.E2.m1.1.1.cmml"><mi id="S3.E2.m1.1.1.2" xref="S3.E2.m1.1.1.2.cmml">T</mi><mo lspace="0.278em" rspace="0.278em" id="S3.E2.m1.1.1.1" xref="S3.E2.m1.1.1.1.cmml">:</mo><mrow id="S3.E2.m1.1.1.3" xref="S3.E2.m1.1.1.3.cmml"><msub id="S3.E2.m1.1.1.3.2" xref="S3.E2.m1.1.1.3.2.cmml"><mi id="S3.E2.m1.1.1.3.2.2" xref="S3.E2.m1.1.1.3.2.2.cmml">x</mi><mi id="S3.E2.m1.1.1.3.2.3" xref="S3.E2.m1.1.1.3.2.3.cmml">j</mi></msub><mo id="S3.E2.m1.1.1.3.3" xref="S3.E2.m1.1.1.3.3.cmml">âˆˆ</mo><msup id="S3.E2.m1.1.1.3.4" xref="S3.E2.m1.1.1.3.4.cmml"><mi id="S3.E2.m1.1.1.3.4.2" xref="S3.E2.m1.1.1.3.4.2.cmml">â„</mi><mn id="S3.E2.m1.1.1.3.4.3" xref="S3.E2.m1.1.1.3.4.3.cmml">3</mn></msup><mo stretchy="false" id="S3.E2.m1.1.1.3.5" xref="S3.E2.m1.1.1.3.5.cmml">â†’</mo><mover accent="true" id="S3.E2.m1.1.1.3.6" xref="S3.E2.m1.1.1.3.6.cmml"><mi id="S3.E2.m1.1.1.3.6.2" xref="S3.E2.m1.1.1.3.6.2.cmml">s</mi><mo id="S3.E2.m1.1.1.3.6.1" xref="S3.E2.m1.1.1.3.6.1.cmml">^</mo></mover><mo id="S3.E2.m1.1.1.3.7" xref="S3.E2.m1.1.1.3.7.cmml">âˆˆ</mo><mi id="S3.E2.m1.1.1.3.8" xref="S3.E2.m1.1.1.3.8.cmml">â„</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.1b"><apply id="S3.E2.m1.1.1.cmml" xref="S3.E2.m1.1.1"><ci id="S3.E2.m1.1.1.1.cmml" xref="S3.E2.m1.1.1.1">:</ci><ci id="S3.E2.m1.1.1.2.cmml" xref="S3.E2.m1.1.1.2">ğ‘‡</ci><apply id="S3.E2.m1.1.1.3.cmml" xref="S3.E2.m1.1.1.3"><and id="S3.E2.m1.1.1.3a.cmml" xref="S3.E2.m1.1.1.3"></and><apply id="S3.E2.m1.1.1.3b.cmml" xref="S3.E2.m1.1.1.3"><in id="S3.E2.m1.1.1.3.3.cmml" xref="S3.E2.m1.1.1.3.3"></in><apply id="S3.E2.m1.1.1.3.2.cmml" xref="S3.E2.m1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.3.2.1.cmml" xref="S3.E2.m1.1.1.3.2">subscript</csymbol><ci id="S3.E2.m1.1.1.3.2.2.cmml" xref="S3.E2.m1.1.1.3.2.2">ğ‘¥</ci><ci id="S3.E2.m1.1.1.3.2.3.cmml" xref="S3.E2.m1.1.1.3.2.3">ğ‘—</ci></apply><apply id="S3.E2.m1.1.1.3.4.cmml" xref="S3.E2.m1.1.1.3.4"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.3.4.1.cmml" xref="S3.E2.m1.1.1.3.4">superscript</csymbol><ci id="S3.E2.m1.1.1.3.4.2.cmml" xref="S3.E2.m1.1.1.3.4.2">â„</ci><cn type="integer" id="S3.E2.m1.1.1.3.4.3.cmml" xref="S3.E2.m1.1.1.3.4.3">3</cn></apply></apply><apply id="S3.E2.m1.1.1.3c.cmml" xref="S3.E2.m1.1.1.3"><ci id="S3.E2.m1.1.1.3.5.cmml" xref="S3.E2.m1.1.1.3.5">â†’</ci><share href="#S3.E2.m1.1.1.3.4.cmml" id="S3.E2.m1.1.1.3d.cmml" xref="S3.E2.m1.1.1.3"></share><apply id="S3.E2.m1.1.1.3.6.cmml" xref="S3.E2.m1.1.1.3.6"><ci id="S3.E2.m1.1.1.3.6.1.cmml" xref="S3.E2.m1.1.1.3.6.1">^</ci><ci id="S3.E2.m1.1.1.3.6.2.cmml" xref="S3.E2.m1.1.1.3.6.2">ğ‘ </ci></apply></apply><apply id="S3.E2.m1.1.1.3e.cmml" xref="S3.E2.m1.1.1.3"><in id="S3.E2.m1.1.1.3.7.cmml" xref="S3.E2.m1.1.1.3.7"></in><share href="#S3.E2.m1.1.1.3.6.cmml" id="S3.E2.m1.1.1.3f.cmml" xref="S3.E2.m1.1.1.3"></share><ci id="S3.E2.m1.1.1.3.8.cmml" xref="S3.E2.m1.1.1.3.8">â„</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.1c">T:x_{j}\in\mathbb{R}^{3}\rightarrow\hat{s}\in\mathbb{R}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.p1.15" class="ltx_p">To deform the template to a specific object instance, we use a deformation field together with a structural correction field</p>
<table id="S3.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E3.m1.2" class="ltx_Math" alttext="D:x_{j}\in\mathbb{R}^{3}\rightarrow(v,\Delta s)\in\mathbb{R}^{4}." display="block"><semantics id="S3.E3.m1.2a"><mrow id="S3.E3.m1.2.2.1" xref="S3.E3.m1.2.2.1.1.cmml"><mrow id="S3.E3.m1.2.2.1.1" xref="S3.E3.m1.2.2.1.1.cmml"><mi id="S3.E3.m1.2.2.1.1.3" xref="S3.E3.m1.2.2.1.1.3.cmml">D</mi><mo lspace="0.278em" rspace="0.278em" id="S3.E3.m1.2.2.1.1.2" xref="S3.E3.m1.2.2.1.1.2.cmml">:</mo><mrow id="S3.E3.m1.2.2.1.1.1" xref="S3.E3.m1.2.2.1.1.1.cmml"><msub id="S3.E3.m1.2.2.1.1.1.3" xref="S3.E3.m1.2.2.1.1.1.3.cmml"><mi id="S3.E3.m1.2.2.1.1.1.3.2" xref="S3.E3.m1.2.2.1.1.1.3.2.cmml">x</mi><mi id="S3.E3.m1.2.2.1.1.1.3.3" xref="S3.E3.m1.2.2.1.1.1.3.3.cmml">j</mi></msub><mo id="S3.E3.m1.2.2.1.1.1.4" xref="S3.E3.m1.2.2.1.1.1.4.cmml">âˆˆ</mo><msup id="S3.E3.m1.2.2.1.1.1.5" xref="S3.E3.m1.2.2.1.1.1.5.cmml"><mi id="S3.E3.m1.2.2.1.1.1.5.2" xref="S3.E3.m1.2.2.1.1.1.5.2.cmml">â„</mi><mn id="S3.E3.m1.2.2.1.1.1.5.3" xref="S3.E3.m1.2.2.1.1.1.5.3.cmml">3</mn></msup><mo stretchy="false" id="S3.E3.m1.2.2.1.1.1.6" xref="S3.E3.m1.2.2.1.1.1.6.cmml">â†’</mo><mrow id="S3.E3.m1.2.2.1.1.1.1.1" xref="S3.E3.m1.2.2.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E3.m1.2.2.1.1.1.1.1.2" xref="S3.E3.m1.2.2.1.1.1.1.2.cmml">(</mo><mi id="S3.E3.m1.1.1" xref="S3.E3.m1.1.1.cmml">v</mi><mo id="S3.E3.m1.2.2.1.1.1.1.1.3" xref="S3.E3.m1.2.2.1.1.1.1.2.cmml">,</mo><mrow id="S3.E3.m1.2.2.1.1.1.1.1.1" xref="S3.E3.m1.2.2.1.1.1.1.1.1.cmml"><mi mathvariant="normal" id="S3.E3.m1.2.2.1.1.1.1.1.1.2" xref="S3.E3.m1.2.2.1.1.1.1.1.1.2.cmml">Î”</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.1.1.1.1.1.1.1" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1.cmml">â€‹</mo><mi id="S3.E3.m1.2.2.1.1.1.1.1.1.3" xref="S3.E3.m1.2.2.1.1.1.1.1.1.3.cmml">s</mi></mrow><mo stretchy="false" id="S3.E3.m1.2.2.1.1.1.1.1.4" xref="S3.E3.m1.2.2.1.1.1.1.2.cmml">)</mo></mrow><mo id="S3.E3.m1.2.2.1.1.1.7" xref="S3.E3.m1.2.2.1.1.1.7.cmml">âˆˆ</mo><msup id="S3.E3.m1.2.2.1.1.1.8" xref="S3.E3.m1.2.2.1.1.1.8.cmml"><mi id="S3.E3.m1.2.2.1.1.1.8.2" xref="S3.E3.m1.2.2.1.1.1.8.2.cmml">â„</mi><mn id="S3.E3.m1.2.2.1.1.1.8.3" xref="S3.E3.m1.2.2.1.1.1.8.3.cmml">4</mn></msup></mrow></mrow><mo lspace="0em" id="S3.E3.m1.2.2.1.2" xref="S3.E3.m1.2.2.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.2b"><apply id="S3.E3.m1.2.2.1.1.cmml" xref="S3.E3.m1.2.2.1"><ci id="S3.E3.m1.2.2.1.1.2.cmml" xref="S3.E3.m1.2.2.1.1.2">:</ci><ci id="S3.E3.m1.2.2.1.1.3.cmml" xref="S3.E3.m1.2.2.1.1.3">ğ·</ci><apply id="S3.E3.m1.2.2.1.1.1.cmml" xref="S3.E3.m1.2.2.1.1.1"><and id="S3.E3.m1.2.2.1.1.1a.cmml" xref="S3.E3.m1.2.2.1.1.1"></and><apply id="S3.E3.m1.2.2.1.1.1b.cmml" xref="S3.E3.m1.2.2.1.1.1"><in id="S3.E3.m1.2.2.1.1.1.4.cmml" xref="S3.E3.m1.2.2.1.1.1.4"></in><apply id="S3.E3.m1.2.2.1.1.1.3.cmml" xref="S3.E3.m1.2.2.1.1.1.3"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.1.3.1.cmml" xref="S3.E3.m1.2.2.1.1.1.3">subscript</csymbol><ci id="S3.E3.m1.2.2.1.1.1.3.2.cmml" xref="S3.E3.m1.2.2.1.1.1.3.2">ğ‘¥</ci><ci id="S3.E3.m1.2.2.1.1.1.3.3.cmml" xref="S3.E3.m1.2.2.1.1.1.3.3">ğ‘—</ci></apply><apply id="S3.E3.m1.2.2.1.1.1.5.cmml" xref="S3.E3.m1.2.2.1.1.1.5"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.1.5.1.cmml" xref="S3.E3.m1.2.2.1.1.1.5">superscript</csymbol><ci id="S3.E3.m1.2.2.1.1.1.5.2.cmml" xref="S3.E3.m1.2.2.1.1.1.5.2">â„</ci><cn type="integer" id="S3.E3.m1.2.2.1.1.1.5.3.cmml" xref="S3.E3.m1.2.2.1.1.1.5.3">3</cn></apply></apply><apply id="S3.E3.m1.2.2.1.1.1c.cmml" xref="S3.E3.m1.2.2.1.1.1"><ci id="S3.E3.m1.2.2.1.1.1.6.cmml" xref="S3.E3.m1.2.2.1.1.1.6">â†’</ci><share href="#S3.E3.m1.2.2.1.1.1.5.cmml" id="S3.E3.m1.2.2.1.1.1d.cmml" xref="S3.E3.m1.2.2.1.1.1"></share><interval closure="open" id="S3.E3.m1.2.2.1.1.1.1.2.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1"><ci id="S3.E3.m1.1.1.cmml" xref="S3.E3.m1.1.1">ğ‘£</ci><apply id="S3.E3.m1.2.2.1.1.1.1.1.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1"><times id="S3.E3.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.1"></times><ci id="S3.E3.m1.2.2.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.2">Î”</ci><ci id="S3.E3.m1.2.2.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.2.2.1.1.1.1.1.1.3">ğ‘ </ci></apply></interval></apply><apply id="S3.E3.m1.2.2.1.1.1e.cmml" xref="S3.E3.m1.2.2.1.1.1"><in id="S3.E3.m1.2.2.1.1.1.7.cmml" xref="S3.E3.m1.2.2.1.1.1.7"></in><share href="#S3.E3.m1.2.2.1.1.1.1.cmml" id="S3.E3.m1.2.2.1.1.1f.cmml" xref="S3.E3.m1.2.2.1.1.1"></share><apply id="S3.E3.m1.2.2.1.1.1.8.cmml" xref="S3.E3.m1.2.2.1.1.1.8"><csymbol cd="ambiguous" id="S3.E3.m1.2.2.1.1.1.8.1.cmml" xref="S3.E3.m1.2.2.1.1.1.8">superscript</csymbol><ci id="S3.E3.m1.2.2.1.1.1.8.2.cmml" xref="S3.E3.m1.2.2.1.1.1.8.2">â„</ci><cn type="integer" id="S3.E3.m1.2.2.1.1.1.8.3.cmml" xref="S3.E3.m1.2.2.1.1.1.8.3">4</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.2c">D:x_{j}\in\mathbb{R}^{3}\rightarrow(v,\Delta s)\in\mathbb{R}^{4}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.p1.14" class="ltx_p">The vector <math id="S3.SS1.p1.9.m1.1" class="ltx_Math" alttext="v" display="inline"><semantics id="S3.SS1.p1.9.m1.1a"><mi id="S3.SS1.p1.9.m1.1.1" xref="S3.SS1.p1.9.m1.1.1.cmml">v</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.9.m1.1b"><ci id="S3.SS1.p1.9.m1.1.1.cmml" xref="S3.SS1.p1.9.m1.1.1">ğ‘£</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.9.m1.1c">v</annotation></semantics></math> deforms a point in the instance space to the template space, and the correction factor <math id="S3.SS1.p1.10.m2.1" class="ltx_Math" alttext="\Delta s" display="inline"><semantics id="S3.SS1.p1.10.m2.1a"><mrow id="S3.SS1.p1.10.m2.1.1" xref="S3.SS1.p1.10.m2.1.1.cmml"><mi mathvariant="normal" id="S3.SS1.p1.10.m2.1.1.2" xref="S3.SS1.p1.10.m2.1.1.2.cmml">Î”</mi><mo lspace="0em" rspace="0em" id="S3.SS1.p1.10.m2.1.1.1" xref="S3.SS1.p1.10.m2.1.1.1.cmml">â€‹</mo><mi id="S3.SS1.p1.10.m2.1.1.3" xref="S3.SS1.p1.10.m2.1.1.3.cmml">s</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.10.m2.1b"><apply id="S3.SS1.p1.10.m2.1.1.cmml" xref="S3.SS1.p1.10.m2.1.1"><times id="S3.SS1.p1.10.m2.1.1.1.cmml" xref="S3.SS1.p1.10.m2.1.1.1"></times><ci id="S3.SS1.p1.10.m2.1.1.2.cmml" xref="S3.SS1.p1.10.m2.1.1.2">Î”</ci><ci id="S3.SS1.p1.10.m2.1.1.3.cmml" xref="S3.SS1.p1.10.m2.1.1.3">ğ‘ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.10.m2.1c">\Delta s</annotation></semantics></math> modifies the SDF value of point <math id="S3.SS1.p1.11.m3.1" class="ltx_Math" alttext="x_{j}" display="inline"><semantics id="S3.SS1.p1.11.m3.1a"><msub id="S3.SS1.p1.11.m3.1.1" xref="S3.SS1.p1.11.m3.1.1.cmml"><mi id="S3.SS1.p1.11.m3.1.1.2" xref="S3.SS1.p1.11.m3.1.1.2.cmml">x</mi><mi id="S3.SS1.p1.11.m3.1.1.3" xref="S3.SS1.p1.11.m3.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.11.m3.1b"><apply id="S3.SS1.p1.11.m3.1.1.cmml" xref="S3.SS1.p1.11.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.11.m3.1.1.1.cmml" xref="S3.SS1.p1.11.m3.1.1">subscript</csymbol><ci id="S3.SS1.p1.11.m3.1.1.2.cmml" xref="S3.SS1.p1.11.m3.1.1.2">ğ‘¥</ci><ci id="S3.SS1.p1.11.m3.1.1.3.cmml" xref="S3.SS1.p1.11.m3.1.1.3">ğ‘—</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.11.m3.1c">x_{j}</annotation></semantics></math> if it still differs from the ground truth value. The correction factor has been shown to be beneficial for categories with significant shape variations. For example, for chairs, there exist instances with and without armrests.
We use a Hyper-NetworkÂ <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>, <a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite> to condition the deformation field on a latent code. With a learned template field <math id="S3.SS1.p1.12.m4.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S3.SS1.p1.12.m4.1a"><mi id="S3.SS1.p1.12.m4.1.1" xref="S3.SS1.p1.12.m4.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.12.m4.1b"><ci id="S3.SS1.p1.12.m4.1.1.cmml" xref="S3.SS1.p1.12.m4.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.12.m4.1c">T</annotation></semantics></math> and deformation field <math id="S3.SS1.p1.13.m5.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S3.SS1.p1.13.m5.1a"><mi id="S3.SS1.p1.13.m5.1.1" xref="S3.SS1.p1.13.m5.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.13.m5.1b"><ci id="S3.SS1.p1.13.m5.1.1.cmml" xref="S3.SS1.p1.13.m5.1.1">ğ·</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.13.m5.1c">D</annotation></semantics></math>, the SDF value of a point <math id="S3.SS1.p1.14.m6.1" class="ltx_Math" alttext="x_{j}" display="inline"><semantics id="S3.SS1.p1.14.m6.1a"><msub id="S3.SS1.p1.14.m6.1.1" xref="S3.SS1.p1.14.m6.1.1.cmml"><mi id="S3.SS1.p1.14.m6.1.1.2" xref="S3.SS1.p1.14.m6.1.1.2.cmml">x</mi><mi id="S3.SS1.p1.14.m6.1.1.3" xref="S3.SS1.p1.14.m6.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.14.m6.1b"><apply id="S3.SS1.p1.14.m6.1.1.cmml" xref="S3.SS1.p1.14.m6.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.14.m6.1.1.1.cmml" xref="S3.SS1.p1.14.m6.1.1">subscript</csymbol><ci id="S3.SS1.p1.14.m6.1.1.2.cmml" xref="S3.SS1.p1.14.m6.1.1.2">ğ‘¥</ci><ci id="S3.SS1.p1.14.m6.1.1.3.cmml" xref="S3.SS1.p1.14.m6.1.1.3">ğ‘—</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.14.m6.1c">x_{j}</annotation></semantics></math> can be obtained with</p>
<table id="S3.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E4.m1.1" class="ltx_Math" alttext="s_{j}=T(x_{j}+v)+\Delta s=T(x_{j}+D_{v}(x_{j}))+D_{\Delta}(x_{j})." display="block"><semantics id="S3.E4.m1.1a"><mrow id="S3.E4.m1.1.1.1" xref="S3.E4.m1.1.1.1.1.cmml"><mrow id="S3.E4.m1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.cmml"><msub id="S3.E4.m1.1.1.1.1.5" xref="S3.E4.m1.1.1.1.1.5.cmml"><mi id="S3.E4.m1.1.1.1.1.5.2" xref="S3.E4.m1.1.1.1.1.5.2.cmml">s</mi><mi id="S3.E4.m1.1.1.1.1.5.3" xref="S3.E4.m1.1.1.1.1.5.3.cmml">j</mi></msub><mo id="S3.E4.m1.1.1.1.1.6" xref="S3.E4.m1.1.1.1.1.6.cmml">=</mo><mrow id="S3.E4.m1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.cmml"><mrow id="S3.E4.m1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.cmml"><mi id="S3.E4.m1.1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.1.3.cmml">T</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E4.m1.1.1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E4.m1.1.1.1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E4.m1.1.1.1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.cmml"><msub id="S3.E4.m1.1.1.1.1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.2" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.2.cmml">x</mi><mi id="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.3" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.3.cmml">j</mi></msub><mo id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.cmml">+</mo><mi id="S3.E4.m1.1.1.1.1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.3.cmml">v</mi></mrow><mo stretchy="false" id="S3.E4.m1.1.1.1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E4.m1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.1.2.cmml">+</mo><mrow id="S3.E4.m1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.1.3.cmml"><mi mathvariant="normal" id="S3.E4.m1.1.1.1.1.1.3.2" xref="S3.E4.m1.1.1.1.1.1.3.2.cmml">Î”</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.1.1.1.1.1.3.1" xref="S3.E4.m1.1.1.1.1.1.3.1.cmml">â€‹</mo><mi id="S3.E4.m1.1.1.1.1.1.3.3" xref="S3.E4.m1.1.1.1.1.1.3.3.cmml">s</mi></mrow></mrow><mo id="S3.E4.m1.1.1.1.1.7" xref="S3.E4.m1.1.1.1.1.7.cmml">=</mo><mrow id="S3.E4.m1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.3.cmml"><mrow id="S3.E4.m1.1.1.1.1.2.1" xref="S3.E4.m1.1.1.1.1.2.1.cmml"><mi id="S3.E4.m1.1.1.1.1.2.1.3" xref="S3.E4.m1.1.1.1.1.2.1.3.cmml">T</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.1.1.1.1.2.1.2" xref="S3.E4.m1.1.1.1.1.2.1.2.cmml">â€‹</mo><mrow id="S3.E4.m1.1.1.1.1.2.1.1.1" xref="S3.E4.m1.1.1.1.1.2.1.1.1.1.cmml"><mo stretchy="false" id="S3.E4.m1.1.1.1.1.2.1.1.1.2" xref="S3.E4.m1.1.1.1.1.2.1.1.1.1.cmml">(</mo><mrow id="S3.E4.m1.1.1.1.1.2.1.1.1.1" xref="S3.E4.m1.1.1.1.1.2.1.1.1.1.cmml"><msub id="S3.E4.m1.1.1.1.1.2.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.2.1.1.1.1.3.cmml"><mi id="S3.E4.m1.1.1.1.1.2.1.1.1.1.3.2" xref="S3.E4.m1.1.1.1.1.2.1.1.1.1.3.2.cmml">x</mi><mi id="S3.E4.m1.1.1.1.1.2.1.1.1.1.3.3" xref="S3.E4.m1.1.1.1.1.2.1.1.1.1.3.3.cmml">j</mi></msub><mo id="S3.E4.m1.1.1.1.1.2.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.2.1.1.1.1.2.cmml">+</mo><mrow id="S3.E4.m1.1.1.1.1.2.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.2.1.1.1.1.1.cmml"><msub id="S3.E4.m1.1.1.1.1.2.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.2.1.1.1.1.1.3.cmml"><mi id="S3.E4.m1.1.1.1.1.2.1.1.1.1.1.3.2" xref="S3.E4.m1.1.1.1.1.2.1.1.1.1.1.3.2.cmml">D</mi><mi id="S3.E4.m1.1.1.1.1.2.1.1.1.1.1.3.3" xref="S3.E4.m1.1.1.1.1.2.1.1.1.1.1.3.3.cmml">v</mi></msub><mo lspace="0em" rspace="0em" id="S3.E4.m1.1.1.1.1.2.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.2.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E4.m1.1.1.1.1.2.1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.2.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E4.m1.1.1.1.1.2.1.1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.2.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S3.E4.m1.1.1.1.1.2.1.1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.2.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E4.m1.1.1.1.1.2.1.1.1.1.1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.2.1.1.1.1.1.1.1.1.2.cmml">x</mi><mi id="S3.E4.m1.1.1.1.1.2.1.1.1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.2.1.1.1.1.1.1.1.1.3.cmml">j</mi></msub><mo stretchy="false" id="S3.E4.m1.1.1.1.1.2.1.1.1.1.1.1.1.3" xref="S3.E4.m1.1.1.1.1.2.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo stretchy="false" id="S3.E4.m1.1.1.1.1.2.1.1.1.3" xref="S3.E4.m1.1.1.1.1.2.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E4.m1.1.1.1.1.3.3" xref="S3.E4.m1.1.1.1.1.3.3.cmml">+</mo><mrow id="S3.E4.m1.1.1.1.1.3.2" xref="S3.E4.m1.1.1.1.1.3.2.cmml"><msub id="S3.E4.m1.1.1.1.1.3.2.3" xref="S3.E4.m1.1.1.1.1.3.2.3.cmml"><mi id="S3.E4.m1.1.1.1.1.3.2.3.2" xref="S3.E4.m1.1.1.1.1.3.2.3.2.cmml">D</mi><mi mathvariant="normal" id="S3.E4.m1.1.1.1.1.3.2.3.3" xref="S3.E4.m1.1.1.1.1.3.2.3.3.cmml">Î”</mi></msub><mo lspace="0em" rspace="0em" id="S3.E4.m1.1.1.1.1.3.2.2" xref="S3.E4.m1.1.1.1.1.3.2.2.cmml">â€‹</mo><mrow id="S3.E4.m1.1.1.1.1.3.2.1.1" xref="S3.E4.m1.1.1.1.1.3.2.1.1.1.cmml"><mo stretchy="false" id="S3.E4.m1.1.1.1.1.3.2.1.1.2" xref="S3.E4.m1.1.1.1.1.3.2.1.1.1.cmml">(</mo><msub id="S3.E4.m1.1.1.1.1.3.2.1.1.1" xref="S3.E4.m1.1.1.1.1.3.2.1.1.1.cmml"><mi id="S3.E4.m1.1.1.1.1.3.2.1.1.1.2" xref="S3.E4.m1.1.1.1.1.3.2.1.1.1.2.cmml">x</mi><mi id="S3.E4.m1.1.1.1.1.3.2.1.1.1.3" xref="S3.E4.m1.1.1.1.1.3.2.1.1.1.3.cmml">j</mi></msub><mo stretchy="false" id="S3.E4.m1.1.1.1.1.3.2.1.1.3" xref="S3.E4.m1.1.1.1.1.3.2.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><mo lspace="0em" id="S3.E4.m1.1.1.1.2" xref="S3.E4.m1.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.1b"><apply id="S3.E4.m1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1"><and id="S3.E4.m1.1.1.1.1a.cmml" xref="S3.E4.m1.1.1.1"></and><apply id="S3.E4.m1.1.1.1.1b.cmml" xref="S3.E4.m1.1.1.1"><eq id="S3.E4.m1.1.1.1.1.6.cmml" xref="S3.E4.m1.1.1.1.1.6"></eq><apply id="S3.E4.m1.1.1.1.1.5.cmml" xref="S3.E4.m1.1.1.1.1.5"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.5.1.cmml" xref="S3.E4.m1.1.1.1.1.5">subscript</csymbol><ci id="S3.E4.m1.1.1.1.1.5.2.cmml" xref="S3.E4.m1.1.1.1.1.5.2">ğ‘ </ci><ci id="S3.E4.m1.1.1.1.1.5.3.cmml" xref="S3.E4.m1.1.1.1.1.5.3">ğ‘—</ci></apply><apply id="S3.E4.m1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1"><plus id="S3.E4.m1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.1.2"></plus><apply id="S3.E4.m1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1"><times id="S3.E4.m1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.2"></times><ci id="S3.E4.m1.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.3">ğ‘‡</ci><apply id="S3.E4.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1"><plus id="S3.E4.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.1"></plus><apply id="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.2">ğ‘¥</ci><ci id="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.2.3">ğ‘—</ci></apply><ci id="S3.E4.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.1.1.1.1.1.3">ğ‘£</ci></apply></apply><apply id="S3.E4.m1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.1.3"><times id="S3.E4.m1.1.1.1.1.1.3.1.cmml" xref="S3.E4.m1.1.1.1.1.1.3.1"></times><ci id="S3.E4.m1.1.1.1.1.1.3.2.cmml" xref="S3.E4.m1.1.1.1.1.1.3.2">Î”</ci><ci id="S3.E4.m1.1.1.1.1.1.3.3.cmml" xref="S3.E4.m1.1.1.1.1.1.3.3">ğ‘ </ci></apply></apply></apply><apply id="S3.E4.m1.1.1.1.1c.cmml" xref="S3.E4.m1.1.1.1"><eq id="S3.E4.m1.1.1.1.1.7.cmml" xref="S3.E4.m1.1.1.1.1.7"></eq><share href="#S3.E4.m1.1.1.1.1.1.cmml" id="S3.E4.m1.1.1.1.1d.cmml" xref="S3.E4.m1.1.1.1"></share><apply id="S3.E4.m1.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.3"><plus id="S3.E4.m1.1.1.1.1.3.3.cmml" xref="S3.E4.m1.1.1.1.1.3.3"></plus><apply id="S3.E4.m1.1.1.1.1.2.1.cmml" xref="S3.E4.m1.1.1.1.1.2.1"><times id="S3.E4.m1.1.1.1.1.2.1.2.cmml" xref="S3.E4.m1.1.1.1.1.2.1.2"></times><ci id="S3.E4.m1.1.1.1.1.2.1.3.cmml" xref="S3.E4.m1.1.1.1.1.2.1.3">ğ‘‡</ci><apply id="S3.E4.m1.1.1.1.1.2.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.2.1.1.1"><plus id="S3.E4.m1.1.1.1.1.2.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.2.1.1.1.1.2"></plus><apply id="S3.E4.m1.1.1.1.1.2.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.2.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.2.1.1.1.1.3.1.cmml" xref="S3.E4.m1.1.1.1.1.2.1.1.1.1.3">subscript</csymbol><ci id="S3.E4.m1.1.1.1.1.2.1.1.1.1.3.2.cmml" xref="S3.E4.m1.1.1.1.1.2.1.1.1.1.3.2">ğ‘¥</ci><ci id="S3.E4.m1.1.1.1.1.2.1.1.1.1.3.3.cmml" xref="S3.E4.m1.1.1.1.1.2.1.1.1.1.3.3">ğ‘—</ci></apply><apply id="S3.E4.m1.1.1.1.1.2.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.2.1.1.1.1.1"><times id="S3.E4.m1.1.1.1.1.2.1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.2.1.1.1.1.1.2"></times><apply id="S3.E4.m1.1.1.1.1.2.1.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.2.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.2.1.1.1.1.1.3.1.cmml" xref="S3.E4.m1.1.1.1.1.2.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E4.m1.1.1.1.1.2.1.1.1.1.1.3.2.cmml" xref="S3.E4.m1.1.1.1.1.2.1.1.1.1.1.3.2">ğ·</ci><ci id="S3.E4.m1.1.1.1.1.2.1.1.1.1.1.3.3.cmml" xref="S3.E4.m1.1.1.1.1.2.1.1.1.1.1.3.3">ğ‘£</ci></apply><apply id="S3.E4.m1.1.1.1.1.2.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.2.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.2.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E4.m1.1.1.1.1.2.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.2.1.1.1.1.1.1.1.1.2">ğ‘¥</ci><ci id="S3.E4.m1.1.1.1.1.2.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.2.1.1.1.1.1.1.1.1.3">ğ‘—</ci></apply></apply></apply></apply><apply id="S3.E4.m1.1.1.1.1.3.2.cmml" xref="S3.E4.m1.1.1.1.1.3.2"><times id="S3.E4.m1.1.1.1.1.3.2.2.cmml" xref="S3.E4.m1.1.1.1.1.3.2.2"></times><apply id="S3.E4.m1.1.1.1.1.3.2.3.cmml" xref="S3.E4.m1.1.1.1.1.3.2.3"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.3.2.3.1.cmml" xref="S3.E4.m1.1.1.1.1.3.2.3">subscript</csymbol><ci id="S3.E4.m1.1.1.1.1.3.2.3.2.cmml" xref="S3.E4.m1.1.1.1.1.3.2.3.2">ğ·</ci><ci id="S3.E4.m1.1.1.1.1.3.2.3.3.cmml" xref="S3.E4.m1.1.1.1.1.3.2.3.3">Î”</ci></apply><apply id="S3.E4.m1.1.1.1.1.3.2.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.3.2.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.1.1.3.2.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.3.2.1.1">subscript</csymbol><ci id="S3.E4.m1.1.1.1.1.3.2.1.1.1.2.cmml" xref="S3.E4.m1.1.1.1.1.3.2.1.1.1.2">ğ‘¥</ci><ci id="S3.E4.m1.1.1.1.1.3.2.1.1.1.3.cmml" xref="S3.E4.m1.1.1.1.1.3.2.1.1.1.3">ğ‘—</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.1c">s_{j}=T(x_{j}+v)+\Delta s=T(x_{j}+D_{v}(x_{j}))+D_{\Delta}(x_{j}).</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS2.5.1.1" class="ltx_text">III-B</span> </span><span id="S3.SS2.6.2" class="ltx_text ltx_font_italic">Training DIF</span>
</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.2" class="ltx_p">During training we use the auto-decoder frameworkÂ <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>, <a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite> to jointly learn latent codes <math id="S3.SS2.p1.1.m1.1" class="ltx_Math" alttext="z_{i}" display="inline"><semantics id="S3.SS2.p1.1.m1.1a"><msub id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml"><mi id="S3.SS2.p1.1.m1.1.1.2" xref="S3.SS2.p1.1.m1.1.1.2.cmml">z</mi><mi id="S3.SS2.p1.1.m1.1.1.3" xref="S3.SS2.p1.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><apply id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.1.m1.1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.p1.1.m1.1.1.2.cmml" xref="S3.SS2.p1.1.m1.1.1.2">ğ‘§</ci><ci id="S3.SS2.p1.1.m1.1.1.3.cmml" xref="S3.SS2.p1.1.m1.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">z_{i}</annotation></semantics></math> and the weights of the DIF network that predicts SDF values <math id="S3.SS2.p1.2.m2.1" class="ltx_Math" alttext="\hat{s}=\Psi(x)" display="inline"><semantics id="S3.SS2.p1.2.m2.1a"><mrow id="S3.SS2.p1.2.m2.1.2" xref="S3.SS2.p1.2.m2.1.2.cmml"><mover accent="true" id="S3.SS2.p1.2.m2.1.2.2" xref="S3.SS2.p1.2.m2.1.2.2.cmml"><mi id="S3.SS2.p1.2.m2.1.2.2.2" xref="S3.SS2.p1.2.m2.1.2.2.2.cmml">s</mi><mo id="S3.SS2.p1.2.m2.1.2.2.1" xref="S3.SS2.p1.2.m2.1.2.2.1.cmml">^</mo></mover><mo id="S3.SS2.p1.2.m2.1.2.1" xref="S3.SS2.p1.2.m2.1.2.1.cmml">=</mo><mrow id="S3.SS2.p1.2.m2.1.2.3" xref="S3.SS2.p1.2.m2.1.2.3.cmml"><mi mathvariant="normal" id="S3.SS2.p1.2.m2.1.2.3.2" xref="S3.SS2.p1.2.m2.1.2.3.2.cmml">Î¨</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p1.2.m2.1.2.3.1" xref="S3.SS2.p1.2.m2.1.2.3.1.cmml">â€‹</mo><mrow id="S3.SS2.p1.2.m2.1.2.3.3.2" xref="S3.SS2.p1.2.m2.1.2.3.cmml"><mo stretchy="false" id="S3.SS2.p1.2.m2.1.2.3.3.2.1" xref="S3.SS2.p1.2.m2.1.2.3.cmml">(</mo><mi id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml">x</mi><mo stretchy="false" id="S3.SS2.p1.2.m2.1.2.3.3.2.2" xref="S3.SS2.p1.2.m2.1.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><apply id="S3.SS2.p1.2.m2.1.2.cmml" xref="S3.SS2.p1.2.m2.1.2"><eq id="S3.SS2.p1.2.m2.1.2.1.cmml" xref="S3.SS2.p1.2.m2.1.2.1"></eq><apply id="S3.SS2.p1.2.m2.1.2.2.cmml" xref="S3.SS2.p1.2.m2.1.2.2"><ci id="S3.SS2.p1.2.m2.1.2.2.1.cmml" xref="S3.SS2.p1.2.m2.1.2.2.1">^</ci><ci id="S3.SS2.p1.2.m2.1.2.2.2.cmml" xref="S3.SS2.p1.2.m2.1.2.2.2">ğ‘ </ci></apply><apply id="S3.SS2.p1.2.m2.1.2.3.cmml" xref="S3.SS2.p1.2.m2.1.2.3"><times id="S3.SS2.p1.2.m2.1.2.3.1.cmml" xref="S3.SS2.p1.2.m2.1.2.3.1"></times><ci id="S3.SS2.p1.2.m2.1.2.3.2.cmml" xref="S3.SS2.p1.2.m2.1.2.3.2">Î¨</ci><ci id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">ğ‘¥</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">\hat{s}=\Psi(x)</annotation></semantics></math>. Given a collection of shapes with ground truth SDF values on the object surface and in free space, we first apply an SDF regression loss fromÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite> as</p>
<table id="S3.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E5.m1.65" class="ltx_Math" alttext="\mathcal{L}_{sdf}=\sum_{i}(\sum_{x\in\Omega}|\Psi_{i}(x)-s|+\sum_{x\in S_{i}}(1-\langle\nabla\Psi_{i}(x),n\rangle)\\
+\sum_{x\in\Omega}|||\nabla\Psi_{i}(x)|-1||+\sum_{p\in\Omega\setminus S_{i}}\rho(\Psi_{i}(x)))," display="block"><semantics id="S3.E5.m1.65a"><mtable displaystyle="true" rowspacing="0pt" id="S3.E5.m1.64.64"><mtr id="S3.E5.m1.64.64a"><mtd class="ltx_align_left" columnalign="left" id="S3.E5.m1.64.64b"><mrow id="S3.E5.m1.34.34.34.34.34"><msub id="S3.E5.m1.34.34.34.34.34.35"><mi class="ltx_font_mathcaligraphic" id="S3.E5.m1.1.1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.1.1.cmml">â„’</mi><mrow id="S3.E5.m1.2.2.2.2.2.2.1" xref="S3.E5.m1.2.2.2.2.2.2.1.cmml"><mi id="S3.E5.m1.2.2.2.2.2.2.1.2" xref="S3.E5.m1.2.2.2.2.2.2.1.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.2.2.2.2.2.2.1.1" xref="S3.E5.m1.2.2.2.2.2.2.1.1.cmml">â€‹</mo><mi id="S3.E5.m1.2.2.2.2.2.2.1.3" xref="S3.E5.m1.2.2.2.2.2.2.1.3.cmml">d</mi><mo lspace="0em" rspace="0em" id="S3.E5.m1.2.2.2.2.2.2.1.1a" xref="S3.E5.m1.2.2.2.2.2.2.1.1.cmml">â€‹</mo><mi id="S3.E5.m1.2.2.2.2.2.2.1.4" xref="S3.E5.m1.2.2.2.2.2.2.1.4.cmml">f</mi></mrow></msub><mo rspace="0.111em" id="S3.E5.m1.3.3.3.3.3.3" xref="S3.E5.m1.3.3.3.3.3.3.cmml">=</mo><munder id="S3.E5.m1.34.34.34.34.34.36"><mo movablelimits="false" rspace="0em" id="S3.E5.m1.4.4.4.4.4.4" xref="S3.E5.m1.4.4.4.4.4.4.cmml">âˆ‘</mo><mi id="S3.E5.m1.5.5.5.5.5.5.1" xref="S3.E5.m1.5.5.5.5.5.5.1.cmml">i</mi></munder><mrow id="S3.E5.m1.34.34.34.34.34.37"><mo stretchy="false" id="S3.E5.m1.6.6.6.6.6.6" xref="S3.E5.m1.65.65.1.1.1.cmml">(</mo><munder id="S3.E5.m1.34.34.34.34.34.37.1"><mo lspace="0em" movablelimits="false" rspace="0em" id="S3.E5.m1.7.7.7.7.7.7" xref="S3.E5.m1.7.7.7.7.7.7.cmml">âˆ‘</mo><mrow id="S3.E5.m1.8.8.8.8.8.8.1" xref="S3.E5.m1.8.8.8.8.8.8.1.cmml"><mi id="S3.E5.m1.8.8.8.8.8.8.1.2" xref="S3.E5.m1.8.8.8.8.8.8.1.2.cmml">x</mi><mo id="S3.E5.m1.8.8.8.8.8.8.1.1" xref="S3.E5.m1.8.8.8.8.8.8.1.1.cmml">âˆˆ</mo><mi mathvariant="normal" id="S3.E5.m1.8.8.8.8.8.8.1.3" xref="S3.E5.m1.8.8.8.8.8.8.1.3.cmml">Î©</mi></mrow></munder><mo fence="false" rspace="0.167em" stretchy="false" id="S3.E5.m1.9.9.9.9.9.9" xref="S3.E5.m1.65.65.1.1.1.cmml">|</mo><msub id="S3.E5.m1.34.34.34.34.34.37.2"><mi mathvariant="normal" id="S3.E5.m1.10.10.10.10.10.10" xref="S3.E5.m1.10.10.10.10.10.10.cmml">Î¨</mi><mi id="S3.E5.m1.11.11.11.11.11.11.1" xref="S3.E5.m1.11.11.11.11.11.11.1.cmml">i</mi></msub><mrow id="S3.E5.m1.34.34.34.34.34.37.3"><mo stretchy="false" id="S3.E5.m1.12.12.12.12.12.12" xref="S3.E5.m1.65.65.1.1.1.cmml">(</mo><mi id="S3.E5.m1.13.13.13.13.13.13" xref="S3.E5.m1.13.13.13.13.13.13.cmml">x</mi><mo stretchy="false" id="S3.E5.m1.14.14.14.14.14.14" xref="S3.E5.m1.65.65.1.1.1.cmml">)</mo></mrow><mo id="S3.E5.m1.15.15.15.15.15.15" xref="S3.E5.m1.15.15.15.15.15.15.cmml">âˆ’</mo><mi id="S3.E5.m1.16.16.16.16.16.16" xref="S3.E5.m1.16.16.16.16.16.16.cmml">s</mi><mo fence="false" stretchy="false" id="S3.E5.m1.17.17.17.17.17.17" xref="S3.E5.m1.65.65.1.1.1.cmml">|</mo><mo lspace="0em" rspace="0.055em" id="S3.E5.m1.18.18.18.18.18.18" xref="S3.E5.m1.18.18.18.18.18.18.cmml">+</mo><munder id="S3.E5.m1.34.34.34.34.34.37.4"><mo movablelimits="false" rspace="0em" id="S3.E5.m1.19.19.19.19.19.19" xref="S3.E5.m1.19.19.19.19.19.19.cmml">âˆ‘</mo><mrow id="S3.E5.m1.20.20.20.20.20.20.1" xref="S3.E5.m1.20.20.20.20.20.20.1.cmml"><mi id="S3.E5.m1.20.20.20.20.20.20.1.2" xref="S3.E5.m1.20.20.20.20.20.20.1.2.cmml">x</mi><mo id="S3.E5.m1.20.20.20.20.20.20.1.1" xref="S3.E5.m1.20.20.20.20.20.20.1.1.cmml">âˆˆ</mo><msub id="S3.E5.m1.20.20.20.20.20.20.1.3" xref="S3.E5.m1.20.20.20.20.20.20.1.3.cmml"><mi id="S3.E5.m1.20.20.20.20.20.20.1.3.2" xref="S3.E5.m1.20.20.20.20.20.20.1.3.2.cmml">S</mi><mi id="S3.E5.m1.20.20.20.20.20.20.1.3.3" xref="S3.E5.m1.20.20.20.20.20.20.1.3.3.cmml">i</mi></msub></mrow></munder><mrow id="S3.E5.m1.34.34.34.34.34.37.5"><mo stretchy="false" id="S3.E5.m1.21.21.21.21.21.21" xref="S3.E5.m1.65.65.1.1.1.cmml">(</mo><mn id="S3.E5.m1.22.22.22.22.22.22" xref="S3.E5.m1.22.22.22.22.22.22.cmml">1</mn><mo id="S3.E5.m1.23.23.23.23.23.23" xref="S3.E5.m1.23.23.23.23.23.23.cmml">âˆ’</mo><mrow id="S3.E5.m1.34.34.34.34.34.37.5.1"><mo stretchy="false" id="S3.E5.m1.24.24.24.24.24.24" xref="S3.E5.m1.65.65.1.1.1.cmml">âŸ¨</mo><mo rspace="0.167em" id="S3.E5.m1.25.25.25.25.25.25" xref="S3.E5.m1.25.25.25.25.25.25.cmml">âˆ‡</mo><msub id="S3.E5.m1.34.34.34.34.34.37.5.1.1"><mi mathvariant="normal" id="S3.E5.m1.26.26.26.26.26.26" xref="S3.E5.m1.26.26.26.26.26.26.cmml">Î¨</mi><mi id="S3.E5.m1.27.27.27.27.27.27.1" xref="S3.E5.m1.27.27.27.27.27.27.1.cmml">i</mi></msub><mrow id="S3.E5.m1.34.34.34.34.34.37.5.1.2"><mo stretchy="false" id="S3.E5.m1.28.28.28.28.28.28" xref="S3.E5.m1.65.65.1.1.1.cmml">(</mo><mi id="S3.E5.m1.29.29.29.29.29.29" xref="S3.E5.m1.29.29.29.29.29.29.cmml">x</mi><mo stretchy="false" id="S3.E5.m1.30.30.30.30.30.30" xref="S3.E5.m1.65.65.1.1.1.cmml">)</mo></mrow><mo id="S3.E5.m1.31.31.31.31.31.31" xref="S3.E5.m1.65.65.1.1.1.cmml">,</mo><mi id="S3.E5.m1.32.32.32.32.32.32" xref="S3.E5.m1.32.32.32.32.32.32.cmml">n</mi><mo stretchy="false" id="S3.E5.m1.33.33.33.33.33.33" xref="S3.E5.m1.65.65.1.1.1.cmml">âŸ©</mo></mrow><mo stretchy="false" id="S3.E5.m1.34.34.34.34.34.34" xref="S3.E5.m1.65.65.1.1.1.cmml">)</mo></mrow></mrow></mrow></mtd></mtr><mtr id="S3.E5.m1.64.64c"><mtd class="ltx_align_right" columnalign="right" id="S3.E5.m1.64.64d"><mrow id="S3.E5.m1.64.64.64.30.30"><mo rspace="0.055em" id="S3.E5.m1.35.35.35.1.1.1" xref="S3.E5.m1.35.35.35.1.1.1.cmml">+</mo><munder id="S3.E5.m1.64.64.64.30.30.31"><mo movablelimits="false" rspace="0em" id="S3.E5.m1.36.36.36.2.2.2" xref="S3.E5.m1.36.36.36.2.2.2.cmml">âˆ‘</mo><mrow id="S3.E5.m1.37.37.37.3.3.3.1" xref="S3.E5.m1.37.37.37.3.3.3.1.cmml"><mi id="S3.E5.m1.37.37.37.3.3.3.1.2" xref="S3.E5.m1.37.37.37.3.3.3.1.2.cmml">x</mi><mo id="S3.E5.m1.37.37.37.3.3.3.1.1" xref="S3.E5.m1.37.37.37.3.3.3.1.1.cmml">âˆˆ</mo><mi mathvariant="normal" id="S3.E5.m1.37.37.37.3.3.3.1.3" xref="S3.E5.m1.37.37.37.3.3.3.1.3.cmml">Î©</mi></mrow></munder><mo fence="false" rspace="0.167em" stretchy="false" id="S3.E5.m1.38.38.38.4.4.4" xref="S3.E5.m1.65.65.1.1.1.cmml">|</mo><mo fence="false" rspace="0.167em" stretchy="false" id="S3.E5.m1.39.39.39.5.5.5" xref="S3.E5.m1.65.65.1.1.1.cmml">|</mo><mo fence="false" rspace="0.167em" stretchy="false" id="S3.E5.m1.40.40.40.6.6.6" xref="S3.E5.m1.65.65.1.1.1.cmml">|</mo><mo rspace="0.167em" id="S3.E5.m1.41.41.41.7.7.7" xref="S3.E5.m1.41.41.41.7.7.7.cmml">âˆ‡</mo><msub id="S3.E5.m1.64.64.64.30.30.32"><mi mathvariant="normal" id="S3.E5.m1.42.42.42.8.8.8" xref="S3.E5.m1.42.42.42.8.8.8.cmml">Î¨</mi><mi id="S3.E5.m1.43.43.43.9.9.9.1" xref="S3.E5.m1.43.43.43.9.9.9.1.cmml">i</mi></msub><mrow id="S3.E5.m1.64.64.64.30.30.33"><mo stretchy="false" id="S3.E5.m1.44.44.44.10.10.10" xref="S3.E5.m1.65.65.1.1.1.cmml">(</mo><mi id="S3.E5.m1.45.45.45.11.11.11" xref="S3.E5.m1.45.45.45.11.11.11.cmml">x</mi><mo stretchy="false" id="S3.E5.m1.46.46.46.12.12.12" xref="S3.E5.m1.65.65.1.1.1.cmml">)</mo></mrow><mo fence="false" stretchy="false" id="S3.E5.m1.47.47.47.13.13.13" xref="S3.E5.m1.65.65.1.1.1.cmml">|</mo><mo lspace="0em" id="S3.E5.m1.48.48.48.14.14.14" xref="S3.E5.m1.48.48.48.14.14.14.cmml">âˆ’</mo><mn id="S3.E5.m1.49.49.49.15.15.15" xref="S3.E5.m1.49.49.49.15.15.15.cmml">1</mn><mo fence="false" rspace="0.167em" stretchy="false" id="S3.E5.m1.50.50.50.16.16.16" xref="S3.E5.m1.65.65.1.1.1.cmml">|</mo><mo fence="false" stretchy="false" id="S3.E5.m1.51.51.51.17.17.17" xref="S3.E5.m1.65.65.1.1.1.cmml">|</mo><mo lspace="0em" rspace="0.055em" id="S3.E5.m1.52.52.52.18.18.18" xref="S3.E5.m1.52.52.52.18.18.18.cmml">+</mo><munder id="S3.E5.m1.64.64.64.30.30.34"><mo movablelimits="false" id="S3.E5.m1.53.53.53.19.19.19" xref="S3.E5.m1.53.53.53.19.19.19.cmml">âˆ‘</mo><mrow id="S3.E5.m1.54.54.54.20.20.20.1" xref="S3.E5.m1.54.54.54.20.20.20.1.cmml"><mi id="S3.E5.m1.54.54.54.20.20.20.1.2" xref="S3.E5.m1.54.54.54.20.20.20.1.2.cmml">p</mi><mo id="S3.E5.m1.54.54.54.20.20.20.1.1" xref="S3.E5.m1.54.54.54.20.20.20.1.1.cmml">âˆˆ</mo><mrow id="S3.E5.m1.54.54.54.20.20.20.1.3" xref="S3.E5.m1.54.54.54.20.20.20.1.3.cmml"><mi mathvariant="normal" id="S3.E5.m1.54.54.54.20.20.20.1.3.2" xref="S3.E5.m1.54.54.54.20.20.20.1.3.2.cmml">Î©</mi><mo id="S3.E5.m1.54.54.54.20.20.20.1.3.1" xref="S3.E5.m1.54.54.54.20.20.20.1.3.1.cmml">âˆ–</mo><msub id="S3.E5.m1.54.54.54.20.20.20.1.3.3" xref="S3.E5.m1.54.54.54.20.20.20.1.3.3.cmml"><mi id="S3.E5.m1.54.54.54.20.20.20.1.3.3.2" xref="S3.E5.m1.54.54.54.20.20.20.1.3.3.2.cmml">S</mi><mi id="S3.E5.m1.54.54.54.20.20.20.1.3.3.3" xref="S3.E5.m1.54.54.54.20.20.20.1.3.3.3.cmml">i</mi></msub></mrow></mrow></munder><mi id="S3.E5.m1.55.55.55.21.21.21" xref="S3.E5.m1.55.55.55.21.21.21.cmml">Ï</mi><mrow id="S3.E5.m1.64.64.64.30.30.35"><mo stretchy="false" id="S3.E5.m1.56.56.56.22.22.22" xref="S3.E5.m1.65.65.1.1.1.cmml">(</mo><msub id="S3.E5.m1.64.64.64.30.30.35.1"><mi mathvariant="normal" id="S3.E5.m1.57.57.57.23.23.23" xref="S3.E5.m1.57.57.57.23.23.23.cmml">Î¨</mi><mi id="S3.E5.m1.58.58.58.24.24.24.1" xref="S3.E5.m1.58.58.58.24.24.24.1.cmml">i</mi></msub><mrow id="S3.E5.m1.64.64.64.30.30.35.2"><mo stretchy="false" id="S3.E5.m1.59.59.59.25.25.25" xref="S3.E5.m1.65.65.1.1.1.cmml">(</mo><mi id="S3.E5.m1.60.60.60.26.26.26" xref="S3.E5.m1.60.60.60.26.26.26.cmml">x</mi><mo stretchy="false" id="S3.E5.m1.61.61.61.27.27.27" xref="S3.E5.m1.65.65.1.1.1.cmml">)</mo></mrow><mo stretchy="false" id="S3.E5.m1.62.62.62.28.28.28" xref="S3.E5.m1.65.65.1.1.1.cmml">)</mo></mrow><mo stretchy="false" id="S3.E5.m1.63.63.63.29.29.29" xref="S3.E5.m1.65.65.1.1.1.cmml">)</mo><mo id="S3.E5.m1.64.64.64.30.30.30" xref="S3.E5.m1.65.65.1.1.1.cmml">,</mo></mrow></mtd></mtr></mtable><annotation-xml encoding="MathML-Content" id="S3.E5.m1.65b"><apply id="S3.E5.m1.65.65.1.1.1.cmml" xref="S3.E5.m1.6.6.6.6.6.6"><eq id="S3.E5.m1.3.3.3.3.3.3.cmml" xref="S3.E5.m1.3.3.3.3.3.3"></eq><apply id="S3.E5.m1.65.65.1.1.1.3.cmml" xref="S3.E5.m1.6.6.6.6.6.6"><csymbol cd="ambiguous" id="S3.E5.m1.65.65.1.1.1.3.1.cmml" xref="S3.E5.m1.6.6.6.6.6.6">subscript</csymbol><ci id="S3.E5.m1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1">â„’</ci><apply id="S3.E5.m1.2.2.2.2.2.2.1.cmml" xref="S3.E5.m1.2.2.2.2.2.2.1"><times id="S3.E5.m1.2.2.2.2.2.2.1.1.cmml" xref="S3.E5.m1.2.2.2.2.2.2.1.1"></times><ci id="S3.E5.m1.2.2.2.2.2.2.1.2.cmml" xref="S3.E5.m1.2.2.2.2.2.2.1.2">ğ‘ </ci><ci id="S3.E5.m1.2.2.2.2.2.2.1.3.cmml" xref="S3.E5.m1.2.2.2.2.2.2.1.3">ğ‘‘</ci><ci id="S3.E5.m1.2.2.2.2.2.2.1.4.cmml" xref="S3.E5.m1.2.2.2.2.2.2.1.4">ğ‘“</ci></apply></apply><apply id="S3.E5.m1.65.65.1.1.1.1.cmml" xref="S3.E5.m1.6.6.6.6.6.6"><apply id="S3.E5.m1.65.65.1.1.1.1.2.cmml" xref="S3.E5.m1.6.6.6.6.6.6"><csymbol cd="ambiguous" id="S3.E5.m1.65.65.1.1.1.1.2.1.cmml" xref="S3.E5.m1.6.6.6.6.6.6">subscript</csymbol><sum id="S3.E5.m1.4.4.4.4.4.4.cmml" xref="S3.E5.m1.4.4.4.4.4.4"></sum><ci id="S3.E5.m1.5.5.5.5.5.5.1.cmml" xref="S3.E5.m1.5.5.5.5.5.5.1">ğ‘–</ci></apply><apply id="S3.E5.m1.65.65.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.6.6.6.6.6.6"><plus id="S3.E5.m1.52.52.52.18.18.18.cmml" xref="S3.E5.m1.52.52.52.18.18.18"></plus><apply id="S3.E5.m1.65.65.1.1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.6.6.6.6.6.6"><apply id="S3.E5.m1.65.65.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E5.m1.6.6.6.6.6.6"><csymbol cd="ambiguous" id="S3.E5.m1.65.65.1.1.1.1.1.1.1.2.3.1.cmml" xref="S3.E5.m1.6.6.6.6.6.6">subscript</csymbol><sum id="S3.E5.m1.7.7.7.7.7.7.cmml" xref="S3.E5.m1.7.7.7.7.7.7"></sum><apply id="S3.E5.m1.8.8.8.8.8.8.1.cmml" xref="S3.E5.m1.8.8.8.8.8.8.1"><in id="S3.E5.m1.8.8.8.8.8.8.1.1.cmml" xref="S3.E5.m1.8.8.8.8.8.8.1.1"></in><ci id="S3.E5.m1.8.8.8.8.8.8.1.2.cmml" xref="S3.E5.m1.8.8.8.8.8.8.1.2">ğ‘¥</ci><ci id="S3.E5.m1.8.8.8.8.8.8.1.3.cmml" xref="S3.E5.m1.8.8.8.8.8.8.1.3">Î©</ci></apply></apply><apply id="S3.E5.m1.65.65.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E5.m1.6.6.6.6.6.6"><times id="S3.E5.m1.65.65.1.1.1.1.1.1.1.2.2.3.cmml" xref="S3.E5.m1.6.6.6.6.6.6"></times><apply id="S3.E5.m1.65.65.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.6.6.6.6.6.6"><abs id="S3.E5.m1.65.65.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E5.m1.6.6.6.6.6.6"></abs><apply id="S3.E5.m1.65.65.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.6.6.6.6.6.6"><minus id="S3.E5.m1.15.15.15.15.15.15.cmml" xref="S3.E5.m1.15.15.15.15.15.15"></minus><apply id="S3.E5.m1.65.65.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E5.m1.6.6.6.6.6.6"><times id="S3.E5.m1.65.65.1.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E5.m1.6.6.6.6.6.6"></times><apply id="S3.E5.m1.65.65.1.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E5.m1.6.6.6.6.6.6"><csymbol cd="ambiguous" id="S3.E5.m1.65.65.1.1.1.1.1.1.1.1.1.1.1.1.3.2.1.cmml" xref="S3.E5.m1.6.6.6.6.6.6">subscript</csymbol><ci id="S3.E5.m1.10.10.10.10.10.10.cmml" xref="S3.E5.m1.10.10.10.10.10.10">Î¨</ci><ci id="S3.E5.m1.11.11.11.11.11.11.1.cmml" xref="S3.E5.m1.11.11.11.11.11.11.1">ğ‘–</ci></apply><ci id="S3.E5.m1.13.13.13.13.13.13.cmml" xref="S3.E5.m1.13.13.13.13.13.13">ğ‘¥</ci></apply><apply id="S3.E5.m1.65.65.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.6.6.6.6.6.6"><times id="S3.E5.m1.65.65.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.6.6.6.6.6.6"></times><ci id="S3.E5.m1.16.16.16.16.16.16.cmml" xref="S3.E5.m1.16.16.16.16.16.16">ğ‘ </ci><apply id="S3.E5.m1.65.65.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.6.6.6.6.6.6"><abs id="S3.E5.m1.65.65.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E5.m1.6.6.6.6.6.6"></abs><apply id="S3.E5.m1.65.65.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.6.6.6.6.6.6"><plus id="S3.E5.m1.35.35.35.1.1.1.cmml" xref="S3.E5.m1.35.35.35.1.1.1"></plus><apply id="S3.E5.m1.65.65.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.6.6.6.6.6.6"><plus id="S3.E5.m1.18.18.18.18.18.18.cmml" xref="S3.E5.m1.18.18.18.18.18.18"></plus><apply id="S3.E5.m1.65.65.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.6.6.6.6.6.6"><apply id="S3.E5.m1.65.65.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.6.6.6.6.6.6"><csymbol cd="ambiguous" id="S3.E5.m1.65.65.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E5.m1.6.6.6.6.6.6">subscript</csymbol><sum id="S3.E5.m1.19.19.19.19.19.19.cmml" xref="S3.E5.m1.19.19.19.19.19.19"></sum><apply id="S3.E5.m1.20.20.20.20.20.20.1.cmml" xref="S3.E5.m1.20.20.20.20.20.20.1"><in id="S3.E5.m1.20.20.20.20.20.20.1.1.cmml" xref="S3.E5.m1.20.20.20.20.20.20.1.1"></in><ci id="S3.E5.m1.20.20.20.20.20.20.1.2.cmml" xref="S3.E5.m1.20.20.20.20.20.20.1.2">ğ‘¥</ci><apply id="S3.E5.m1.20.20.20.20.20.20.1.3.cmml" xref="S3.E5.m1.20.20.20.20.20.20.1.3"><csymbol cd="ambiguous" id="S3.E5.m1.20.20.20.20.20.20.1.3.1.cmml" xref="S3.E5.m1.20.20.20.20.20.20.1.3">subscript</csymbol><ci id="S3.E5.m1.20.20.20.20.20.20.1.3.2.cmml" xref="S3.E5.m1.20.20.20.20.20.20.1.3.2">ğ‘†</ci><ci id="S3.E5.m1.20.20.20.20.20.20.1.3.3.cmml" xref="S3.E5.m1.20.20.20.20.20.20.1.3.3">ğ‘–</ci></apply></apply></apply><apply id="S3.E5.m1.65.65.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.6.6.6.6.6.6"><minus id="S3.E5.m1.23.23.23.23.23.23.cmml" xref="S3.E5.m1.23.23.23.23.23.23"></minus><cn type="integer" id="S3.E5.m1.22.22.22.22.22.22.cmml" xref="S3.E5.m1.22.22.22.22.22.22">1</cn><list id="S3.E5.m1.65.65.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.6.6.6.6.6.6"><apply id="S3.E5.m1.65.65.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.6.6.6.6.6.6"><times id="S3.E5.m1.65.65.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.6.6.6.6.6.6"></times><apply id="S3.E5.m1.65.65.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.6.6.6.6.6.6"><ci id="S3.E5.m1.25.25.25.25.25.25.cmml" xref="S3.E5.m1.25.25.25.25.25.25">âˆ‡</ci><apply id="S3.E5.m1.65.65.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E5.m1.6.6.6.6.6.6"><csymbol cd="ambiguous" id="S3.E5.m1.65.65.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.2.1.cmml" xref="S3.E5.m1.6.6.6.6.6.6">subscript</csymbol><ci id="S3.E5.m1.26.26.26.26.26.26.cmml" xref="S3.E5.m1.26.26.26.26.26.26">Î¨</ci><ci id="S3.E5.m1.27.27.27.27.27.27.1.cmml" xref="S3.E5.m1.27.27.27.27.27.27.1">ğ‘–</ci></apply></apply><ci id="S3.E5.m1.29.29.29.29.29.29.cmml" xref="S3.E5.m1.29.29.29.29.29.29">ğ‘¥</ci></apply><ci id="S3.E5.m1.32.32.32.32.32.32.cmml" xref="S3.E5.m1.32.32.32.32.32.32">ğ‘›</ci></list></apply></apply></apply><apply id="S3.E5.m1.65.65.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E5.m1.6.6.6.6.6.6"><csymbol cd="ambiguous" id="S3.E5.m1.65.65.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E5.m1.6.6.6.6.6.6">subscript</csymbol><sum id="S3.E5.m1.36.36.36.2.2.2.cmml" xref="S3.E5.m1.36.36.36.2.2.2"></sum><apply id="S3.E5.m1.37.37.37.3.3.3.1.cmml" xref="S3.E5.m1.37.37.37.3.3.3.1"><in id="S3.E5.m1.37.37.37.3.3.3.1.1.cmml" xref="S3.E5.m1.37.37.37.3.3.3.1.1"></in><ci id="S3.E5.m1.37.37.37.3.3.3.1.2.cmml" xref="S3.E5.m1.37.37.37.3.3.3.1.2">ğ‘¥</ci><ci id="S3.E5.m1.37.37.37.3.3.3.1.3.cmml" xref="S3.E5.m1.37.37.37.3.3.3.1.3">Î©</ci></apply></apply></apply></apply></apply></apply></apply><apply id="S3.E5.m1.65.65.1.1.1.1.1.1.1.2.2.2.2.cmml" xref="S3.E5.m1.6.6.6.6.6.6"><abs id="S3.E5.m1.65.65.1.1.1.1.1.1.1.2.2.2.2.1.cmml" xref="S3.E5.m1.6.6.6.6.6.6"></abs><apply id="S3.E5.m1.65.65.1.1.1.1.1.1.1.2.2.2.1.1.cmml" xref="S3.E5.m1.6.6.6.6.6.6"><times id="S3.E5.m1.65.65.1.1.1.1.1.1.1.2.2.2.1.1.2.cmml" xref="S3.E5.m1.6.6.6.6.6.6"></times><apply id="S3.E5.m1.65.65.1.1.1.1.1.1.1.2.2.2.1.1.3.cmml" xref="S3.E5.m1.6.6.6.6.6.6"><ci id="S3.E5.m1.41.41.41.7.7.7.cmml" xref="S3.E5.m1.41.41.41.7.7.7">âˆ‡</ci><apply id="S3.E5.m1.65.65.1.1.1.1.1.1.1.2.2.2.1.1.3.2.cmml" xref="S3.E5.m1.6.6.6.6.6.6"><csymbol cd="ambiguous" id="S3.E5.m1.65.65.1.1.1.1.1.1.1.2.2.2.1.1.3.2.1.cmml" xref="S3.E5.m1.6.6.6.6.6.6">subscript</csymbol><ci id="S3.E5.m1.42.42.42.8.8.8.cmml" xref="S3.E5.m1.42.42.42.8.8.8">Î¨</ci><ci id="S3.E5.m1.43.43.43.9.9.9.1.cmml" xref="S3.E5.m1.43.43.43.9.9.9.1">ğ‘–</ci></apply></apply><ci id="S3.E5.m1.45.45.45.11.11.11.cmml" xref="S3.E5.m1.45.45.45.11.11.11">ğ‘¥</ci><apply id="S3.E5.m1.65.65.1.1.1.1.1.1.1.2.2.2.1.1.1.2.cmml" xref="S3.E5.m1.6.6.6.6.6.6"><abs id="S3.E5.m1.65.65.1.1.1.1.1.1.1.2.2.2.1.1.1.2.1.cmml" xref="S3.E5.m1.6.6.6.6.6.6"></abs><apply id="S3.E5.m1.65.65.1.1.1.1.1.1.1.2.2.2.1.1.1.1.1.cmml" xref="S3.E5.m1.6.6.6.6.6.6"><minus id="S3.E5.m1.48.48.48.14.14.14.cmml" xref="S3.E5.m1.48.48.48.14.14.14"></minus><cn type="integer" id="S3.E5.m1.49.49.49.15.15.15.cmml" xref="S3.E5.m1.49.49.49.15.15.15">1</cn></apply></apply></apply></apply></apply></apply><apply id="S3.E5.m1.65.65.1.1.1.1.1.1.1.3.cmml" xref="S3.E5.m1.6.6.6.6.6.6"><apply id="S3.E5.m1.65.65.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E5.m1.6.6.6.6.6.6"><csymbol cd="ambiguous" id="S3.E5.m1.65.65.1.1.1.1.1.1.1.3.2.1.cmml" xref="S3.E5.m1.6.6.6.6.6.6">subscript</csymbol><sum id="S3.E5.m1.53.53.53.19.19.19.cmml" xref="S3.E5.m1.53.53.53.19.19.19"></sum><apply id="S3.E5.m1.54.54.54.20.20.20.1.cmml" xref="S3.E5.m1.54.54.54.20.20.20.1"><in id="S3.E5.m1.54.54.54.20.20.20.1.1.cmml" xref="S3.E5.m1.54.54.54.20.20.20.1.1"></in><ci id="S3.E5.m1.54.54.54.20.20.20.1.2.cmml" xref="S3.E5.m1.54.54.54.20.20.20.1.2">ğ‘</ci><apply id="S3.E5.m1.54.54.54.20.20.20.1.3.cmml" xref="S3.E5.m1.54.54.54.20.20.20.1.3"><setdiff id="S3.E5.m1.54.54.54.20.20.20.1.3.1.cmml" xref="S3.E5.m1.54.54.54.20.20.20.1.3.1"></setdiff><ci id="S3.E5.m1.54.54.54.20.20.20.1.3.2.cmml" xref="S3.E5.m1.54.54.54.20.20.20.1.3.2">Î©</ci><apply id="S3.E5.m1.54.54.54.20.20.20.1.3.3.cmml" xref="S3.E5.m1.54.54.54.20.20.20.1.3.3"><csymbol cd="ambiguous" id="S3.E5.m1.54.54.54.20.20.20.1.3.3.1.cmml" xref="S3.E5.m1.54.54.54.20.20.20.1.3.3">subscript</csymbol><ci id="S3.E5.m1.54.54.54.20.20.20.1.3.3.2.cmml" xref="S3.E5.m1.54.54.54.20.20.20.1.3.3.2">ğ‘†</ci><ci id="S3.E5.m1.54.54.54.20.20.20.1.3.3.3.cmml" xref="S3.E5.m1.54.54.54.20.20.20.1.3.3.3">ğ‘–</ci></apply></apply></apply></apply><apply id="S3.E5.m1.65.65.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E5.m1.6.6.6.6.6.6"><times id="S3.E5.m1.65.65.1.1.1.1.1.1.1.3.1.2.cmml" xref="S3.E5.m1.6.6.6.6.6.6"></times><ci id="S3.E5.m1.55.55.55.21.21.21.cmml" xref="S3.E5.m1.55.55.55.21.21.21">ğœŒ</ci><apply id="S3.E5.m1.65.65.1.1.1.1.1.1.1.3.1.1.1.1.cmml" xref="S3.E5.m1.6.6.6.6.6.6"><times id="S3.E5.m1.65.65.1.1.1.1.1.1.1.3.1.1.1.1.1.cmml" xref="S3.E5.m1.6.6.6.6.6.6"></times><apply id="S3.E5.m1.65.65.1.1.1.1.1.1.1.3.1.1.1.1.2.cmml" xref="S3.E5.m1.6.6.6.6.6.6"><csymbol cd="ambiguous" id="S3.E5.m1.65.65.1.1.1.1.1.1.1.3.1.1.1.1.2.1.cmml" xref="S3.E5.m1.6.6.6.6.6.6">subscript</csymbol><ci id="S3.E5.m1.57.57.57.23.23.23.cmml" xref="S3.E5.m1.57.57.57.23.23.23">Î¨</ci><ci id="S3.E5.m1.58.58.58.24.24.24.1.cmml" xref="S3.E5.m1.58.58.58.24.24.24.1">ğ‘–</ci></apply><ci id="S3.E5.m1.60.60.60.26.26.26.cmml" xref="S3.E5.m1.60.60.60.26.26.26">ğ‘¥</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5.m1.65c">\mathcal{L}_{sdf}=\sum_{i}(\sum_{x\in\Omega}|\Psi_{i}(x)-s|+\sum_{x\in S_{i}}(1-\langle\nabla\Psi_{i}(x),n\rangle)\\
+\sum_{x\in\Omega}|||\nabla\Psi_{i}(x)|-1||+\sum_{p\in\Omega\setminus S_{i}}\rho(\Psi_{i}(x))),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.9" class="ltx_p">where <math id="S3.SS2.p2.1.m1.1" class="ltx_Math" alttext="s" display="inline"><semantics id="S3.SS2.p2.1.m1.1a"><mi id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><ci id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1">ğ‘ </ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">s</annotation></semantics></math> and <math id="S3.SS2.p2.2.m2.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S3.SS2.p2.2.m2.1a"><mi id="S3.SS2.p2.2.m2.1.1" xref="S3.SS2.p2.2.m2.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m2.1b"><ci id="S3.SS2.p2.2.m2.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1">ğ‘›</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m2.1c">n</annotation></semantics></math> denote the ground truth SDF value and normal, <math id="S3.SS2.p2.3.m3.1" class="ltx_Math" alttext="\nabla" display="inline"><semantics id="S3.SS2.p2.3.m3.1a"><mo id="S3.SS2.p2.3.m3.1.1" xref="S3.SS2.p2.3.m3.1.1.cmml">âˆ‡</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.3.m3.1b"><ci id="S3.SS2.p2.3.m3.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1">âˆ‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.3.m3.1c">\nabla</annotation></semantics></math> is the spatial gradient of the neural field, <math id="S3.SS2.p2.4.m4.1" class="ltx_Math" alttext="\Omega" display="inline"><semantics id="S3.SS2.p2.4.m4.1a"><mi mathvariant="normal" id="S3.SS2.p2.4.m4.1.1" xref="S3.SS2.p2.4.m4.1.1.cmml">Î©</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.4.m4.1b"><ci id="S3.SS2.p2.4.m4.1.1.cmml" xref="S3.SS2.p2.4.m4.1.1">Î©</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.4.m4.1c">\Omega</annotation></semantics></math> is the 3D space in which values are sampled, and <math id="S3.SS2.p2.5.m5.1" class="ltx_Math" alttext="s_{j}" display="inline"><semantics id="S3.SS2.p2.5.m5.1a"><msub id="S3.SS2.p2.5.m5.1.1" xref="S3.SS2.p2.5.m5.1.1.cmml"><mi id="S3.SS2.p2.5.m5.1.1.2" xref="S3.SS2.p2.5.m5.1.1.2.cmml">s</mi><mi id="S3.SS2.p2.5.m5.1.1.3" xref="S3.SS2.p2.5.m5.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.5.m5.1b"><apply id="S3.SS2.p2.5.m5.1.1.cmml" xref="S3.SS2.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.5.m5.1.1.1.cmml" xref="S3.SS2.p2.5.m5.1.1">subscript</csymbol><ci id="S3.SS2.p2.5.m5.1.1.2.cmml" xref="S3.SS2.p2.5.m5.1.1.2">ğ‘ </ci><ci id="S3.SS2.p2.5.m5.1.1.3.cmml" xref="S3.SS2.p2.5.m5.1.1.3">ğ‘—</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.5.m5.1c">s_{j}</annotation></semantics></math> is the shape surface. We select an equal number of surface and free space points uniformly at random to compute this loss. The first term in Equ.Â <a href="#S3.E5" title="In III-B Training DIF â€£ III Method â€£ 3D Surface Reconstruction in the Wild by Deforming Shape Priors from Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> regresses the SDF value; the second term learns consistent normals on the shape surface, the third term is the eikonal equation that enforces unit norm or the spatial gradients, and the last term penalizes SDF values close to <math id="S3.SS2.p2.6.m6.1" class="ltx_Math" alttext="0" display="inline"><semantics id="S3.SS2.p2.6.m6.1a"><mn id="S3.SS2.p2.6.m6.1.1" xref="S3.SS2.p2.6.m6.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.6.m6.1b"><cn type="integer" id="S3.SS2.p2.6.m6.1.1.cmml" xref="S3.SS2.p2.6.m6.1.1">0</cn></annotation-xml></semantics></math> which are far away from the object surface with <math id="S3.SS2.p2.7.m7.5" class="ltx_Math" alttext="\rho(s)=\exp(-\delta\cdot|s|),\delta&gt;&gt;1" display="inline"><semantics id="S3.SS2.p2.7.m7.5a"><mrow id="S3.SS2.p2.7.m7.5.5.2" xref="S3.SS2.p2.7.m7.5.5.3.cmml"><mrow id="S3.SS2.p2.7.m7.4.4.1.1" xref="S3.SS2.p2.7.m7.4.4.1.1.cmml"><mrow id="S3.SS2.p2.7.m7.4.4.1.1.3" xref="S3.SS2.p2.7.m7.4.4.1.1.3.cmml"><mi id="S3.SS2.p2.7.m7.4.4.1.1.3.2" xref="S3.SS2.p2.7.m7.4.4.1.1.3.2.cmml">Ï</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p2.7.m7.4.4.1.1.3.1" xref="S3.SS2.p2.7.m7.4.4.1.1.3.1.cmml">â€‹</mo><mrow id="S3.SS2.p2.7.m7.4.4.1.1.3.3.2" xref="S3.SS2.p2.7.m7.4.4.1.1.3.cmml"><mo stretchy="false" id="S3.SS2.p2.7.m7.4.4.1.1.3.3.2.1" xref="S3.SS2.p2.7.m7.4.4.1.1.3.cmml">(</mo><mi id="S3.SS2.p2.7.m7.1.1" xref="S3.SS2.p2.7.m7.1.1.cmml">s</mi><mo stretchy="false" id="S3.SS2.p2.7.m7.4.4.1.1.3.3.2.2" xref="S3.SS2.p2.7.m7.4.4.1.1.3.cmml">)</mo></mrow></mrow><mo id="S3.SS2.p2.7.m7.4.4.1.1.2" xref="S3.SS2.p2.7.m7.4.4.1.1.2.cmml">=</mo><mrow id="S3.SS2.p2.7.m7.4.4.1.1.1.1" xref="S3.SS2.p2.7.m7.4.4.1.1.1.2.cmml"><mi id="S3.SS2.p2.7.m7.3.3" xref="S3.SS2.p2.7.m7.3.3.cmml">exp</mi><mo id="S3.SS2.p2.7.m7.4.4.1.1.1.1a" xref="S3.SS2.p2.7.m7.4.4.1.1.1.2.cmml">â¡</mo><mrow id="S3.SS2.p2.7.m7.4.4.1.1.1.1.1" xref="S3.SS2.p2.7.m7.4.4.1.1.1.2.cmml"><mo stretchy="false" id="S3.SS2.p2.7.m7.4.4.1.1.1.1.1.2" xref="S3.SS2.p2.7.m7.4.4.1.1.1.2.cmml">(</mo><mrow id="S3.SS2.p2.7.m7.4.4.1.1.1.1.1.1" xref="S3.SS2.p2.7.m7.4.4.1.1.1.1.1.1.cmml"><mo id="S3.SS2.p2.7.m7.4.4.1.1.1.1.1.1a" xref="S3.SS2.p2.7.m7.4.4.1.1.1.1.1.1.cmml">âˆ’</mo><mrow id="S3.SS2.p2.7.m7.4.4.1.1.1.1.1.1.2" xref="S3.SS2.p2.7.m7.4.4.1.1.1.1.1.1.2.cmml"><mi id="S3.SS2.p2.7.m7.4.4.1.1.1.1.1.1.2.2" xref="S3.SS2.p2.7.m7.4.4.1.1.1.1.1.1.2.2.cmml">Î´</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p2.7.m7.4.4.1.1.1.1.1.1.2.1" xref="S3.SS2.p2.7.m7.4.4.1.1.1.1.1.1.2.1.cmml">â‹…</mo><mrow id="S3.SS2.p2.7.m7.4.4.1.1.1.1.1.1.2.3.2" xref="S3.SS2.p2.7.m7.4.4.1.1.1.1.1.1.2.3.1.cmml"><mo stretchy="false" id="S3.SS2.p2.7.m7.4.4.1.1.1.1.1.1.2.3.2.1" xref="S3.SS2.p2.7.m7.4.4.1.1.1.1.1.1.2.3.1.1.cmml">|</mo><mi id="S3.SS2.p2.7.m7.2.2" xref="S3.SS2.p2.7.m7.2.2.cmml">s</mi><mo stretchy="false" id="S3.SS2.p2.7.m7.4.4.1.1.1.1.1.1.2.3.2.2" xref="S3.SS2.p2.7.m7.4.4.1.1.1.1.1.1.2.3.1.1.cmml">|</mo></mrow></mrow></mrow><mo stretchy="false" id="S3.SS2.p2.7.m7.4.4.1.1.1.1.1.3" xref="S3.SS2.p2.7.m7.4.4.1.1.1.2.cmml">)</mo></mrow></mrow></mrow><mo id="S3.SS2.p2.7.m7.5.5.2.3" xref="S3.SS2.p2.7.m7.5.5.3a.cmml">,</mo><mrow id="S3.SS2.p2.7.m7.5.5.2.2" xref="S3.SS2.p2.7.m7.5.5.2.2.cmml"><mi id="S3.SS2.p2.7.m7.5.5.2.2.2" xref="S3.SS2.p2.7.m7.5.5.2.2.2.cmml">Î´</mi><mo lspace="0.278em" rspace="0.278em" id="S3.SS2.p2.7.m7.5.5.2.2.1" xref="S3.SS2.p2.7.m7.5.5.2.2.1.cmml">&gt;&gt;</mo><mn id="S3.SS2.p2.7.m7.5.5.2.2.3" xref="S3.SS2.p2.7.m7.5.5.2.2.3.cmml">1</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.7.m7.5b"><apply id="S3.SS2.p2.7.m7.5.5.3.cmml" xref="S3.SS2.p2.7.m7.5.5.2"><csymbol cd="ambiguous" id="S3.SS2.p2.7.m7.5.5.3a.cmml" xref="S3.SS2.p2.7.m7.5.5.2.3">formulae-sequence</csymbol><apply id="S3.SS2.p2.7.m7.4.4.1.1.cmml" xref="S3.SS2.p2.7.m7.4.4.1.1"><eq id="S3.SS2.p2.7.m7.4.4.1.1.2.cmml" xref="S3.SS2.p2.7.m7.4.4.1.1.2"></eq><apply id="S3.SS2.p2.7.m7.4.4.1.1.3.cmml" xref="S3.SS2.p2.7.m7.4.4.1.1.3"><times id="S3.SS2.p2.7.m7.4.4.1.1.3.1.cmml" xref="S3.SS2.p2.7.m7.4.4.1.1.3.1"></times><ci id="S3.SS2.p2.7.m7.4.4.1.1.3.2.cmml" xref="S3.SS2.p2.7.m7.4.4.1.1.3.2">ğœŒ</ci><ci id="S3.SS2.p2.7.m7.1.1.cmml" xref="S3.SS2.p2.7.m7.1.1">ğ‘ </ci></apply><apply id="S3.SS2.p2.7.m7.4.4.1.1.1.2.cmml" xref="S3.SS2.p2.7.m7.4.4.1.1.1.1"><exp id="S3.SS2.p2.7.m7.3.3.cmml" xref="S3.SS2.p2.7.m7.3.3"></exp><apply id="S3.SS2.p2.7.m7.4.4.1.1.1.1.1.1.cmml" xref="S3.SS2.p2.7.m7.4.4.1.1.1.1.1.1"><minus id="S3.SS2.p2.7.m7.4.4.1.1.1.1.1.1.1.cmml" xref="S3.SS2.p2.7.m7.4.4.1.1.1.1.1.1"></minus><apply id="S3.SS2.p2.7.m7.4.4.1.1.1.1.1.1.2.cmml" xref="S3.SS2.p2.7.m7.4.4.1.1.1.1.1.1.2"><ci id="S3.SS2.p2.7.m7.4.4.1.1.1.1.1.1.2.1.cmml" xref="S3.SS2.p2.7.m7.4.4.1.1.1.1.1.1.2.1">â‹…</ci><ci id="S3.SS2.p2.7.m7.4.4.1.1.1.1.1.1.2.2.cmml" xref="S3.SS2.p2.7.m7.4.4.1.1.1.1.1.1.2.2">ğ›¿</ci><apply id="S3.SS2.p2.7.m7.4.4.1.1.1.1.1.1.2.3.1.cmml" xref="S3.SS2.p2.7.m7.4.4.1.1.1.1.1.1.2.3.2"><abs id="S3.SS2.p2.7.m7.4.4.1.1.1.1.1.1.2.3.1.1.cmml" xref="S3.SS2.p2.7.m7.4.4.1.1.1.1.1.1.2.3.2.1"></abs><ci id="S3.SS2.p2.7.m7.2.2.cmml" xref="S3.SS2.p2.7.m7.2.2">ğ‘ </ci></apply></apply></apply></apply></apply><apply id="S3.SS2.p2.7.m7.5.5.2.2.cmml" xref="S3.SS2.p2.7.m7.5.5.2.2"><csymbol cd="latexml" id="S3.SS2.p2.7.m7.5.5.2.2.1.cmml" xref="S3.SS2.p2.7.m7.5.5.2.2.1">much-greater-than</csymbol><ci id="S3.SS2.p2.7.m7.5.5.2.2.2.cmml" xref="S3.SS2.p2.7.m7.5.5.2.2.2">ğ›¿</ci><cn type="integer" id="S3.SS2.p2.7.m7.5.5.2.2.3.cmml" xref="S3.SS2.p2.7.m7.5.5.2.2.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.7.m7.5c">\rho(s)=\exp(-\delta\cdot|s|),\delta&gt;&gt;1</annotation></semantics></math>. For more details on this loss, checkÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite>. We further apply multiple regularization terms to help learn smooth deformations and consistent latent space. The first regularization term applies <math id="S3.SS2.p2.8.m8.1" class="ltx_Math" alttext="L_{2}" display="inline"><semantics id="S3.SS2.p2.8.m8.1a"><msub id="S3.SS2.p2.8.m8.1.1" xref="S3.SS2.p2.8.m8.1.1.cmml"><mi id="S3.SS2.p2.8.m8.1.1.2" xref="S3.SS2.p2.8.m8.1.1.2.cmml">L</mi><mn id="S3.SS2.p2.8.m8.1.1.3" xref="S3.SS2.p2.8.m8.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.8.m8.1b"><apply id="S3.SS2.p2.8.m8.1.1.cmml" xref="S3.SS2.p2.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.8.m8.1.1.1.cmml" xref="S3.SS2.p2.8.m8.1.1">subscript</csymbol><ci id="S3.SS2.p2.8.m8.1.1.2.cmml" xref="S3.SS2.p2.8.m8.1.1.2">ğ¿</ci><cn type="integer" id="S3.SS2.p2.8.m8.1.1.3.cmml" xref="S3.SS2.p2.8.m8.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.8.m8.1c">L_{2}</annotation></semantics></math> regularization on the embeddings as <math id="S3.SS2.p2.9.m9.1" class="ltx_Math" alttext="\mathcal{L}_{z}=\sum_{i}||z_{i}||_{2}" display="inline"><semantics id="S3.SS2.p2.9.m9.1a"><mrow id="S3.SS2.p2.9.m9.1.1" xref="S3.SS2.p2.9.m9.1.1.cmml"><msub id="S3.SS2.p2.9.m9.1.1.3" xref="S3.SS2.p2.9.m9.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p2.9.m9.1.1.3.2" xref="S3.SS2.p2.9.m9.1.1.3.2.cmml">â„’</mi><mi id="S3.SS2.p2.9.m9.1.1.3.3" xref="S3.SS2.p2.9.m9.1.1.3.3.cmml">z</mi></msub><mo rspace="0.111em" id="S3.SS2.p2.9.m9.1.1.2" xref="S3.SS2.p2.9.m9.1.1.2.cmml">=</mo><mrow id="S3.SS2.p2.9.m9.1.1.1" xref="S3.SS2.p2.9.m9.1.1.1.cmml"><msub id="S3.SS2.p2.9.m9.1.1.1.2" xref="S3.SS2.p2.9.m9.1.1.1.2.cmml"><mo rspace="0em" id="S3.SS2.p2.9.m9.1.1.1.2.2" xref="S3.SS2.p2.9.m9.1.1.1.2.2.cmml">âˆ‘</mo><mi id="S3.SS2.p2.9.m9.1.1.1.2.3" xref="S3.SS2.p2.9.m9.1.1.1.2.3.cmml">i</mi></msub><msub id="S3.SS2.p2.9.m9.1.1.1.1" xref="S3.SS2.p2.9.m9.1.1.1.1.cmml"><mrow id="S3.SS2.p2.9.m9.1.1.1.1.1.1" xref="S3.SS2.p2.9.m9.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.SS2.p2.9.m9.1.1.1.1.1.1.2" xref="S3.SS2.p2.9.m9.1.1.1.1.1.2.1.cmml">â€–</mo><msub id="S3.SS2.p2.9.m9.1.1.1.1.1.1.1" xref="S3.SS2.p2.9.m9.1.1.1.1.1.1.1.cmml"><mi id="S3.SS2.p2.9.m9.1.1.1.1.1.1.1.2" xref="S3.SS2.p2.9.m9.1.1.1.1.1.1.1.2.cmml">z</mi><mi id="S3.SS2.p2.9.m9.1.1.1.1.1.1.1.3" xref="S3.SS2.p2.9.m9.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S3.SS2.p2.9.m9.1.1.1.1.1.1.3" xref="S3.SS2.p2.9.m9.1.1.1.1.1.2.1.cmml">â€–</mo></mrow><mn id="S3.SS2.p2.9.m9.1.1.1.1.3" xref="S3.SS2.p2.9.m9.1.1.1.1.3.cmml">2</mn></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.9.m9.1b"><apply id="S3.SS2.p2.9.m9.1.1.cmml" xref="S3.SS2.p2.9.m9.1.1"><eq id="S3.SS2.p2.9.m9.1.1.2.cmml" xref="S3.SS2.p2.9.m9.1.1.2"></eq><apply id="S3.SS2.p2.9.m9.1.1.3.cmml" xref="S3.SS2.p2.9.m9.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p2.9.m9.1.1.3.1.cmml" xref="S3.SS2.p2.9.m9.1.1.3">subscript</csymbol><ci id="S3.SS2.p2.9.m9.1.1.3.2.cmml" xref="S3.SS2.p2.9.m9.1.1.3.2">â„’</ci><ci id="S3.SS2.p2.9.m9.1.1.3.3.cmml" xref="S3.SS2.p2.9.m9.1.1.3.3">ğ‘§</ci></apply><apply id="S3.SS2.p2.9.m9.1.1.1.cmml" xref="S3.SS2.p2.9.m9.1.1.1"><apply id="S3.SS2.p2.9.m9.1.1.1.2.cmml" xref="S3.SS2.p2.9.m9.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p2.9.m9.1.1.1.2.1.cmml" xref="S3.SS2.p2.9.m9.1.1.1.2">subscript</csymbol><sum id="S3.SS2.p2.9.m9.1.1.1.2.2.cmml" xref="S3.SS2.p2.9.m9.1.1.1.2.2"></sum><ci id="S3.SS2.p2.9.m9.1.1.1.2.3.cmml" xref="S3.SS2.p2.9.m9.1.1.1.2.3">ğ‘–</ci></apply><apply id="S3.SS2.p2.9.m9.1.1.1.1.cmml" xref="S3.SS2.p2.9.m9.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.9.m9.1.1.1.1.2.cmml" xref="S3.SS2.p2.9.m9.1.1.1.1">subscript</csymbol><apply id="S3.SS2.p2.9.m9.1.1.1.1.1.2.cmml" xref="S3.SS2.p2.9.m9.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.SS2.p2.9.m9.1.1.1.1.1.2.1.cmml" xref="S3.SS2.p2.9.m9.1.1.1.1.1.1.2">norm</csymbol><apply id="S3.SS2.p2.9.m9.1.1.1.1.1.1.1.cmml" xref="S3.SS2.p2.9.m9.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.9.m9.1.1.1.1.1.1.1.1.cmml" xref="S3.SS2.p2.9.m9.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p2.9.m9.1.1.1.1.1.1.1.2.cmml" xref="S3.SS2.p2.9.m9.1.1.1.1.1.1.1.2">ğ‘§</ci><ci id="S3.SS2.p2.9.m9.1.1.1.1.1.1.1.3.cmml" xref="S3.SS2.p2.9.m9.1.1.1.1.1.1.1.3">ğ‘–</ci></apply></apply><cn type="integer" id="S3.SS2.p2.9.m9.1.1.1.1.3.cmml" xref="S3.SS2.p2.9.m9.1.1.1.1.3">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.9.m9.1c">\mathcal{L}_{z}=\sum_{i}||z_{i}||_{2}</annotation></semantics></math>.
Prior work byÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> showed that learning a template shape that captures common attributes across a category is improved by enforcing normal consistency across all shapes by regularizing the normals of the template networks with</p>
<table id="S3.E6" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E6.m1.3" class="ltx_Math" alttext="\mathcal{L}_{normal}=\sum_{i}\sum_{x\in S_{i}}(1-\langle\nabla T(x+D_{v}(x)),n\rangle)." display="block"><semantics id="S3.E6.m1.3a"><mrow id="S3.E6.m1.3.3.1" xref="S3.E6.m1.3.3.1.1.cmml"><mrow id="S3.E6.m1.3.3.1.1" xref="S3.E6.m1.3.3.1.1.cmml"><msub id="S3.E6.m1.3.3.1.1.3" xref="S3.E6.m1.3.3.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E6.m1.3.3.1.1.3.2" xref="S3.E6.m1.3.3.1.1.3.2.cmml">â„’</mi><mrow id="S3.E6.m1.3.3.1.1.3.3" xref="S3.E6.m1.3.3.1.1.3.3.cmml"><mi id="S3.E6.m1.3.3.1.1.3.3.2" xref="S3.E6.m1.3.3.1.1.3.3.2.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.3.3.1.1.3.3.1" xref="S3.E6.m1.3.3.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.E6.m1.3.3.1.1.3.3.3" xref="S3.E6.m1.3.3.1.1.3.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.3.3.1.1.3.3.1a" xref="S3.E6.m1.3.3.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.E6.m1.3.3.1.1.3.3.4" xref="S3.E6.m1.3.3.1.1.3.3.4.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.3.3.1.1.3.3.1b" xref="S3.E6.m1.3.3.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.E6.m1.3.3.1.1.3.3.5" xref="S3.E6.m1.3.3.1.1.3.3.5.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.3.3.1.1.3.3.1c" xref="S3.E6.m1.3.3.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.E6.m1.3.3.1.1.3.3.6" xref="S3.E6.m1.3.3.1.1.3.3.6.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E6.m1.3.3.1.1.3.3.1d" xref="S3.E6.m1.3.3.1.1.3.3.1.cmml">â€‹</mo><mi id="S3.E6.m1.3.3.1.1.3.3.7" xref="S3.E6.m1.3.3.1.1.3.3.7.cmml">l</mi></mrow></msub><mo rspace="0.111em" id="S3.E6.m1.3.3.1.1.2" xref="S3.E6.m1.3.3.1.1.2.cmml">=</mo><mrow id="S3.E6.m1.3.3.1.1.1" xref="S3.E6.m1.3.3.1.1.1.cmml"><munder id="S3.E6.m1.3.3.1.1.1.2" xref="S3.E6.m1.3.3.1.1.1.2.cmml"><mo movablelimits="false" rspace="0em" id="S3.E6.m1.3.3.1.1.1.2.2" xref="S3.E6.m1.3.3.1.1.1.2.2.cmml">âˆ‘</mo><mi id="S3.E6.m1.3.3.1.1.1.2.3" xref="S3.E6.m1.3.3.1.1.1.2.3.cmml">i</mi></munder><mrow id="S3.E6.m1.3.3.1.1.1.1" xref="S3.E6.m1.3.3.1.1.1.1.cmml"><munder id="S3.E6.m1.3.3.1.1.1.1.2" xref="S3.E6.m1.3.3.1.1.1.1.2.cmml"><mo movablelimits="false" rspace="0em" id="S3.E6.m1.3.3.1.1.1.1.2.2" xref="S3.E6.m1.3.3.1.1.1.1.2.2.cmml">âˆ‘</mo><mrow id="S3.E6.m1.3.3.1.1.1.1.2.3" xref="S3.E6.m1.3.3.1.1.1.1.2.3.cmml"><mi id="S3.E6.m1.3.3.1.1.1.1.2.3.2" xref="S3.E6.m1.3.3.1.1.1.1.2.3.2.cmml">x</mi><mo id="S3.E6.m1.3.3.1.1.1.1.2.3.1" xref="S3.E6.m1.3.3.1.1.1.1.2.3.1.cmml">âˆˆ</mo><msub id="S3.E6.m1.3.3.1.1.1.1.2.3.3" xref="S3.E6.m1.3.3.1.1.1.1.2.3.3.cmml"><mi id="S3.E6.m1.3.3.1.1.1.1.2.3.3.2" xref="S3.E6.m1.3.3.1.1.1.1.2.3.3.2.cmml">S</mi><mi id="S3.E6.m1.3.3.1.1.1.1.2.3.3.3" xref="S3.E6.m1.3.3.1.1.1.1.2.3.3.3.cmml">i</mi></msub></mrow></munder><mrow id="S3.E6.m1.3.3.1.1.1.1.1.1" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E6.m1.3.3.1.1.1.1.1.1.2" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E6.m1.3.3.1.1.1.1.1.1.1" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.cmml"><mn id="S3.E6.m1.3.3.1.1.1.1.1.1.1.3" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.3.cmml">1</mn><mo id="S3.E6.m1.3.3.1.1.1.1.1.1.1.2" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.2.cmml">âˆ’</mo><mrow id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.2" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.2.cmml">âŸ¨</mo><mrow id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.cmml"><mrow id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.3.cmml"><mo rspace="0.167em" id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.3.1" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.3.1.cmml">âˆ‡</mo><mi id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.3.2" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.3.2.cmml">T</mi></mrow><mo lspace="0em" rspace="0em" id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">x</mi><mo id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">+</mo><mrow id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml"><msub id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.3.2" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml"><mi id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.3.2.2" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.3.2.2.cmml">D</mi><mi id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.3.2.3" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.3.2.3.cmml">v</mi></msub><mo lspace="0em" rspace="0em" id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.3.1" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml">â€‹</mo><mrow id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.3.3.2" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml"><mo stretchy="false" id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.3.3.2.1" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">(</mo><mi id="S3.E6.m1.1.1" xref="S3.E6.m1.1.1.cmml">x</mi><mo stretchy="false" id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.3.3.2.2" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">)</mo></mrow></mrow></mrow><mo stretchy="false" id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.3" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.2.cmml">,</mo><mi id="S3.E6.m1.2.2" xref="S3.E6.m1.2.2.cmml">n</mi><mo stretchy="false" id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.4" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.2.cmml">âŸ©</mo></mrow></mrow><mo stretchy="false" id="S3.E6.m1.3.3.1.1.1.1.1.1.3" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><mo lspace="0em" id="S3.E6.m1.3.3.1.2" xref="S3.E6.m1.3.3.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E6.m1.3b"><apply id="S3.E6.m1.3.3.1.1.cmml" xref="S3.E6.m1.3.3.1"><eq id="S3.E6.m1.3.3.1.1.2.cmml" xref="S3.E6.m1.3.3.1.1.2"></eq><apply id="S3.E6.m1.3.3.1.1.3.cmml" xref="S3.E6.m1.3.3.1.1.3"><csymbol cd="ambiguous" id="S3.E6.m1.3.3.1.1.3.1.cmml" xref="S3.E6.m1.3.3.1.1.3">subscript</csymbol><ci id="S3.E6.m1.3.3.1.1.3.2.cmml" xref="S3.E6.m1.3.3.1.1.3.2">â„’</ci><apply id="S3.E6.m1.3.3.1.1.3.3.cmml" xref="S3.E6.m1.3.3.1.1.3.3"><times id="S3.E6.m1.3.3.1.1.3.3.1.cmml" xref="S3.E6.m1.3.3.1.1.3.3.1"></times><ci id="S3.E6.m1.3.3.1.1.3.3.2.cmml" xref="S3.E6.m1.3.3.1.1.3.3.2">ğ‘›</ci><ci id="S3.E6.m1.3.3.1.1.3.3.3.cmml" xref="S3.E6.m1.3.3.1.1.3.3.3">ğ‘œ</ci><ci id="S3.E6.m1.3.3.1.1.3.3.4.cmml" xref="S3.E6.m1.3.3.1.1.3.3.4">ğ‘Ÿ</ci><ci id="S3.E6.m1.3.3.1.1.3.3.5.cmml" xref="S3.E6.m1.3.3.1.1.3.3.5">ğ‘š</ci><ci id="S3.E6.m1.3.3.1.1.3.3.6.cmml" xref="S3.E6.m1.3.3.1.1.3.3.6">ğ‘</ci><ci id="S3.E6.m1.3.3.1.1.3.3.7.cmml" xref="S3.E6.m1.3.3.1.1.3.3.7">ğ‘™</ci></apply></apply><apply id="S3.E6.m1.3.3.1.1.1.cmml" xref="S3.E6.m1.3.3.1.1.1"><apply id="S3.E6.m1.3.3.1.1.1.2.cmml" xref="S3.E6.m1.3.3.1.1.1.2"><csymbol cd="ambiguous" id="S3.E6.m1.3.3.1.1.1.2.1.cmml" xref="S3.E6.m1.3.3.1.1.1.2">subscript</csymbol><sum id="S3.E6.m1.3.3.1.1.1.2.2.cmml" xref="S3.E6.m1.3.3.1.1.1.2.2"></sum><ci id="S3.E6.m1.3.3.1.1.1.2.3.cmml" xref="S3.E6.m1.3.3.1.1.1.2.3">ğ‘–</ci></apply><apply id="S3.E6.m1.3.3.1.1.1.1.cmml" xref="S3.E6.m1.3.3.1.1.1.1"><apply id="S3.E6.m1.3.3.1.1.1.1.2.cmml" xref="S3.E6.m1.3.3.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E6.m1.3.3.1.1.1.1.2.1.cmml" xref="S3.E6.m1.3.3.1.1.1.1.2">subscript</csymbol><sum id="S3.E6.m1.3.3.1.1.1.1.2.2.cmml" xref="S3.E6.m1.3.3.1.1.1.1.2.2"></sum><apply id="S3.E6.m1.3.3.1.1.1.1.2.3.cmml" xref="S3.E6.m1.3.3.1.1.1.1.2.3"><in id="S3.E6.m1.3.3.1.1.1.1.2.3.1.cmml" xref="S3.E6.m1.3.3.1.1.1.1.2.3.1"></in><ci id="S3.E6.m1.3.3.1.1.1.1.2.3.2.cmml" xref="S3.E6.m1.3.3.1.1.1.1.2.3.2">ğ‘¥</ci><apply id="S3.E6.m1.3.3.1.1.1.1.2.3.3.cmml" xref="S3.E6.m1.3.3.1.1.1.1.2.3.3"><csymbol cd="ambiguous" id="S3.E6.m1.3.3.1.1.1.1.2.3.3.1.cmml" xref="S3.E6.m1.3.3.1.1.1.1.2.3.3">subscript</csymbol><ci id="S3.E6.m1.3.3.1.1.1.1.2.3.3.2.cmml" xref="S3.E6.m1.3.3.1.1.1.1.2.3.3.2">ğ‘†</ci><ci id="S3.E6.m1.3.3.1.1.1.1.2.3.3.3.cmml" xref="S3.E6.m1.3.3.1.1.1.1.2.3.3.3">ğ‘–</ci></apply></apply></apply><apply id="S3.E6.m1.3.3.1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1"><minus id="S3.E6.m1.3.3.1.1.1.1.1.1.1.2.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.2"></minus><cn type="integer" id="S3.E6.m1.3.3.1.1.1.1.1.1.1.3.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.3">1</cn><list id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1"><apply id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1"><times id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.2"></times><apply id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.3"><ci id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.3.1">âˆ‡</ci><ci id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.3.2">ğ‘‡</ci></apply><apply id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1"><plus id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.1"></plus><ci id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.2">ğ‘¥</ci><apply id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.3"><times id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.3.1"></times><apply id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.3.2.1.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.3.2">subscript</csymbol><ci id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.3.2.2.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.3.2.2">ğ·</ci><ci id="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.3.2.3.cmml" xref="S3.E6.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.1.3.2.3">ğ‘£</ci></apply><ci id="S3.E6.m1.1.1.cmml" xref="S3.E6.m1.1.1">ğ‘¥</ci></apply></apply></apply><ci id="S3.E6.m1.2.2.cmml" xref="S3.E6.m1.2.2">ğ‘›</ci></list></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E6.m1.3c">\mathcal{L}_{normal}=\sum_{i}\sum_{x\in S_{i}}(1-\langle\nabla T(x+D_{v}(x)),n\rangle).</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.p2.11" class="ltx_p">We further want deformations to be smooth and the optional corrections to the SDF field to be small, which is enforced with the following two loss terms <math id="S3.SS2.p2.10.m1.2" class="ltx_Math" alttext="\mathcal{L}_{smooth}=\sum_{i}\sum_{x\in\Omega}||\nabla D_{v}(x)||_{2}" display="inline"><semantics id="S3.SS2.p2.10.m1.2a"><mrow id="S3.SS2.p2.10.m1.2.2" xref="S3.SS2.p2.10.m1.2.2.cmml"><msub id="S3.SS2.p2.10.m1.2.2.3" xref="S3.SS2.p2.10.m1.2.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p2.10.m1.2.2.3.2" xref="S3.SS2.p2.10.m1.2.2.3.2.cmml">â„’</mi><mrow id="S3.SS2.p2.10.m1.2.2.3.3" xref="S3.SS2.p2.10.m1.2.2.3.3.cmml"><mi id="S3.SS2.p2.10.m1.2.2.3.3.2" xref="S3.SS2.p2.10.m1.2.2.3.3.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p2.10.m1.2.2.3.3.1" xref="S3.SS2.p2.10.m1.2.2.3.3.1.cmml">â€‹</mo><mi id="S3.SS2.p2.10.m1.2.2.3.3.3" xref="S3.SS2.p2.10.m1.2.2.3.3.3.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p2.10.m1.2.2.3.3.1a" xref="S3.SS2.p2.10.m1.2.2.3.3.1.cmml">â€‹</mo><mi id="S3.SS2.p2.10.m1.2.2.3.3.4" xref="S3.SS2.p2.10.m1.2.2.3.3.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p2.10.m1.2.2.3.3.1b" xref="S3.SS2.p2.10.m1.2.2.3.3.1.cmml">â€‹</mo><mi id="S3.SS2.p2.10.m1.2.2.3.3.5" xref="S3.SS2.p2.10.m1.2.2.3.3.5.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p2.10.m1.2.2.3.3.1c" xref="S3.SS2.p2.10.m1.2.2.3.3.1.cmml">â€‹</mo><mi id="S3.SS2.p2.10.m1.2.2.3.3.6" xref="S3.SS2.p2.10.m1.2.2.3.3.6.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p2.10.m1.2.2.3.3.1d" xref="S3.SS2.p2.10.m1.2.2.3.3.1.cmml">â€‹</mo><mi id="S3.SS2.p2.10.m1.2.2.3.3.7" xref="S3.SS2.p2.10.m1.2.2.3.3.7.cmml">h</mi></mrow></msub><mo rspace="0.111em" id="S3.SS2.p2.10.m1.2.2.2" xref="S3.SS2.p2.10.m1.2.2.2.cmml">=</mo><mrow id="S3.SS2.p2.10.m1.2.2.1" xref="S3.SS2.p2.10.m1.2.2.1.cmml"><msub id="S3.SS2.p2.10.m1.2.2.1.2" xref="S3.SS2.p2.10.m1.2.2.1.2.cmml"><mo rspace="0em" id="S3.SS2.p2.10.m1.2.2.1.2.2" xref="S3.SS2.p2.10.m1.2.2.1.2.2.cmml">âˆ‘</mo><mi id="S3.SS2.p2.10.m1.2.2.1.2.3" xref="S3.SS2.p2.10.m1.2.2.1.2.3.cmml">i</mi></msub><mrow id="S3.SS2.p2.10.m1.2.2.1.1" xref="S3.SS2.p2.10.m1.2.2.1.1.cmml"><msub id="S3.SS2.p2.10.m1.2.2.1.1.2" xref="S3.SS2.p2.10.m1.2.2.1.1.2.cmml"><mo rspace="0em" id="S3.SS2.p2.10.m1.2.2.1.1.2.2" xref="S3.SS2.p2.10.m1.2.2.1.1.2.2.cmml">âˆ‘</mo><mrow id="S3.SS2.p2.10.m1.2.2.1.1.2.3" xref="S3.SS2.p2.10.m1.2.2.1.1.2.3.cmml"><mi id="S3.SS2.p2.10.m1.2.2.1.1.2.3.2" xref="S3.SS2.p2.10.m1.2.2.1.1.2.3.2.cmml">x</mi><mo id="S3.SS2.p2.10.m1.2.2.1.1.2.3.1" xref="S3.SS2.p2.10.m1.2.2.1.1.2.3.1.cmml">âˆˆ</mo><mi mathvariant="normal" id="S3.SS2.p2.10.m1.2.2.1.1.2.3.3" xref="S3.SS2.p2.10.m1.2.2.1.1.2.3.3.cmml">Î©</mi></mrow></msub><msub id="S3.SS2.p2.10.m1.2.2.1.1.1" xref="S3.SS2.p2.10.m1.2.2.1.1.1.cmml"><mrow id="S3.SS2.p2.10.m1.2.2.1.1.1.1.1" xref="S3.SS2.p2.10.m1.2.2.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.SS2.p2.10.m1.2.2.1.1.1.1.1.2" xref="S3.SS2.p2.10.m1.2.2.1.1.1.1.2.1.cmml">â€–</mo><mrow id="S3.SS2.p2.10.m1.2.2.1.1.1.1.1.1" xref="S3.SS2.p2.10.m1.2.2.1.1.1.1.1.1.cmml"><mrow id="S3.SS2.p2.10.m1.2.2.1.1.1.1.1.1.2" xref="S3.SS2.p2.10.m1.2.2.1.1.1.1.1.1.2.cmml"><mo rspace="0.167em" id="S3.SS2.p2.10.m1.2.2.1.1.1.1.1.1.2.1" xref="S3.SS2.p2.10.m1.2.2.1.1.1.1.1.1.2.1.cmml">âˆ‡</mo><msub id="S3.SS2.p2.10.m1.2.2.1.1.1.1.1.1.2.2" xref="S3.SS2.p2.10.m1.2.2.1.1.1.1.1.1.2.2.cmml"><mi id="S3.SS2.p2.10.m1.2.2.1.1.1.1.1.1.2.2.2" xref="S3.SS2.p2.10.m1.2.2.1.1.1.1.1.1.2.2.2.cmml">D</mi><mi id="S3.SS2.p2.10.m1.2.2.1.1.1.1.1.1.2.2.3" xref="S3.SS2.p2.10.m1.2.2.1.1.1.1.1.1.2.2.3.cmml">v</mi></msub></mrow><mo lspace="0em" rspace="0em" id="S3.SS2.p2.10.m1.2.2.1.1.1.1.1.1.1" xref="S3.SS2.p2.10.m1.2.2.1.1.1.1.1.1.1.cmml">â€‹</mo><mrow id="S3.SS2.p2.10.m1.2.2.1.1.1.1.1.1.3.2" xref="S3.SS2.p2.10.m1.2.2.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS2.p2.10.m1.2.2.1.1.1.1.1.1.3.2.1" xref="S3.SS2.p2.10.m1.2.2.1.1.1.1.1.1.cmml">(</mo><mi id="S3.SS2.p2.10.m1.1.1" xref="S3.SS2.p2.10.m1.1.1.cmml">x</mi><mo stretchy="false" id="S3.SS2.p2.10.m1.2.2.1.1.1.1.1.1.3.2.2" xref="S3.SS2.p2.10.m1.2.2.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.SS2.p2.10.m1.2.2.1.1.1.1.1.3" xref="S3.SS2.p2.10.m1.2.2.1.1.1.1.2.1.cmml">â€–</mo></mrow><mn id="S3.SS2.p2.10.m1.2.2.1.1.1.3" xref="S3.SS2.p2.10.m1.2.2.1.1.1.3.cmml">2</mn></msub></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.10.m1.2b"><apply id="S3.SS2.p2.10.m1.2.2.cmml" xref="S3.SS2.p2.10.m1.2.2"><eq id="S3.SS2.p2.10.m1.2.2.2.cmml" xref="S3.SS2.p2.10.m1.2.2.2"></eq><apply id="S3.SS2.p2.10.m1.2.2.3.cmml" xref="S3.SS2.p2.10.m1.2.2.3"><csymbol cd="ambiguous" id="S3.SS2.p2.10.m1.2.2.3.1.cmml" xref="S3.SS2.p2.10.m1.2.2.3">subscript</csymbol><ci id="S3.SS2.p2.10.m1.2.2.3.2.cmml" xref="S3.SS2.p2.10.m1.2.2.3.2">â„’</ci><apply id="S3.SS2.p2.10.m1.2.2.3.3.cmml" xref="S3.SS2.p2.10.m1.2.2.3.3"><times id="S3.SS2.p2.10.m1.2.2.3.3.1.cmml" xref="S3.SS2.p2.10.m1.2.2.3.3.1"></times><ci id="S3.SS2.p2.10.m1.2.2.3.3.2.cmml" xref="S3.SS2.p2.10.m1.2.2.3.3.2">ğ‘ </ci><ci id="S3.SS2.p2.10.m1.2.2.3.3.3.cmml" xref="S3.SS2.p2.10.m1.2.2.3.3.3">ğ‘š</ci><ci id="S3.SS2.p2.10.m1.2.2.3.3.4.cmml" xref="S3.SS2.p2.10.m1.2.2.3.3.4">ğ‘œ</ci><ci id="S3.SS2.p2.10.m1.2.2.3.3.5.cmml" xref="S3.SS2.p2.10.m1.2.2.3.3.5">ğ‘œ</ci><ci id="S3.SS2.p2.10.m1.2.2.3.3.6.cmml" xref="S3.SS2.p2.10.m1.2.2.3.3.6">ğ‘¡</ci><ci id="S3.SS2.p2.10.m1.2.2.3.3.7.cmml" xref="S3.SS2.p2.10.m1.2.2.3.3.7">â„</ci></apply></apply><apply id="S3.SS2.p2.10.m1.2.2.1.cmml" xref="S3.SS2.p2.10.m1.2.2.1"><apply id="S3.SS2.p2.10.m1.2.2.1.2.cmml" xref="S3.SS2.p2.10.m1.2.2.1.2"><csymbol cd="ambiguous" id="S3.SS2.p2.10.m1.2.2.1.2.1.cmml" xref="S3.SS2.p2.10.m1.2.2.1.2">subscript</csymbol><sum id="S3.SS2.p2.10.m1.2.2.1.2.2.cmml" xref="S3.SS2.p2.10.m1.2.2.1.2.2"></sum><ci id="S3.SS2.p2.10.m1.2.2.1.2.3.cmml" xref="S3.SS2.p2.10.m1.2.2.1.2.3">ğ‘–</ci></apply><apply id="S3.SS2.p2.10.m1.2.2.1.1.cmml" xref="S3.SS2.p2.10.m1.2.2.1.1"><apply id="S3.SS2.p2.10.m1.2.2.1.1.2.cmml" xref="S3.SS2.p2.10.m1.2.2.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p2.10.m1.2.2.1.1.2.1.cmml" xref="S3.SS2.p2.10.m1.2.2.1.1.2">subscript</csymbol><sum id="S3.SS2.p2.10.m1.2.2.1.1.2.2.cmml" xref="S3.SS2.p2.10.m1.2.2.1.1.2.2"></sum><apply id="S3.SS2.p2.10.m1.2.2.1.1.2.3.cmml" xref="S3.SS2.p2.10.m1.2.2.1.1.2.3"><in id="S3.SS2.p2.10.m1.2.2.1.1.2.3.1.cmml" xref="S3.SS2.p2.10.m1.2.2.1.1.2.3.1"></in><ci id="S3.SS2.p2.10.m1.2.2.1.1.2.3.2.cmml" xref="S3.SS2.p2.10.m1.2.2.1.1.2.3.2">ğ‘¥</ci><ci id="S3.SS2.p2.10.m1.2.2.1.1.2.3.3.cmml" xref="S3.SS2.p2.10.m1.2.2.1.1.2.3.3">Î©</ci></apply></apply><apply id="S3.SS2.p2.10.m1.2.2.1.1.1.cmml" xref="S3.SS2.p2.10.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.10.m1.2.2.1.1.1.2.cmml" xref="S3.SS2.p2.10.m1.2.2.1.1.1">subscript</csymbol><apply id="S3.SS2.p2.10.m1.2.2.1.1.1.1.2.cmml" xref="S3.SS2.p2.10.m1.2.2.1.1.1.1.1"><csymbol cd="latexml" id="S3.SS2.p2.10.m1.2.2.1.1.1.1.2.1.cmml" xref="S3.SS2.p2.10.m1.2.2.1.1.1.1.1.2">norm</csymbol><apply id="S3.SS2.p2.10.m1.2.2.1.1.1.1.1.1.cmml" xref="S3.SS2.p2.10.m1.2.2.1.1.1.1.1.1"><times id="S3.SS2.p2.10.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S3.SS2.p2.10.m1.2.2.1.1.1.1.1.1.1"></times><apply id="S3.SS2.p2.10.m1.2.2.1.1.1.1.1.1.2.cmml" xref="S3.SS2.p2.10.m1.2.2.1.1.1.1.1.1.2"><ci id="S3.SS2.p2.10.m1.2.2.1.1.1.1.1.1.2.1.cmml" xref="S3.SS2.p2.10.m1.2.2.1.1.1.1.1.1.2.1">âˆ‡</ci><apply id="S3.SS2.p2.10.m1.2.2.1.1.1.1.1.1.2.2.cmml" xref="S3.SS2.p2.10.m1.2.2.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S3.SS2.p2.10.m1.2.2.1.1.1.1.1.1.2.2.1.cmml" xref="S3.SS2.p2.10.m1.2.2.1.1.1.1.1.1.2.2">subscript</csymbol><ci id="S3.SS2.p2.10.m1.2.2.1.1.1.1.1.1.2.2.2.cmml" xref="S3.SS2.p2.10.m1.2.2.1.1.1.1.1.1.2.2.2">ğ·</ci><ci id="S3.SS2.p2.10.m1.2.2.1.1.1.1.1.1.2.2.3.cmml" xref="S3.SS2.p2.10.m1.2.2.1.1.1.1.1.1.2.2.3">ğ‘£</ci></apply></apply><ci id="S3.SS2.p2.10.m1.1.1.cmml" xref="S3.SS2.p2.10.m1.1.1">ğ‘¥</ci></apply></apply><cn type="integer" id="S3.SS2.p2.10.m1.2.2.1.1.1.3.cmml" xref="S3.SS2.p2.10.m1.2.2.1.1.1.3">2</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.10.m1.2c">\mathcal{L}_{smooth}=\sum_{i}\sum_{x\in\Omega}||\nabla D_{v}(x)||_{2}</annotation></semantics></math> and <math id="S3.SS2.p2.11.m2.2" class="ltx_Math" alttext="\mathcal{L}_{c}=\sum_{i}\sum_{x\in\Omega}|D_{\Delta s}(x)|" display="inline"><semantics id="S3.SS2.p2.11.m2.2a"><mrow id="S3.SS2.p2.11.m2.2.2" xref="S3.SS2.p2.11.m2.2.2.cmml"><msub id="S3.SS2.p2.11.m2.2.2.3" xref="S3.SS2.p2.11.m2.2.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p2.11.m2.2.2.3.2" xref="S3.SS2.p2.11.m2.2.2.3.2.cmml">â„’</mi><mi id="S3.SS2.p2.11.m2.2.2.3.3" xref="S3.SS2.p2.11.m2.2.2.3.3.cmml">c</mi></msub><mo rspace="0.111em" id="S3.SS2.p2.11.m2.2.2.2" xref="S3.SS2.p2.11.m2.2.2.2.cmml">=</mo><mrow id="S3.SS2.p2.11.m2.2.2.1" xref="S3.SS2.p2.11.m2.2.2.1.cmml"><msub id="S3.SS2.p2.11.m2.2.2.1.2" xref="S3.SS2.p2.11.m2.2.2.1.2.cmml"><mo rspace="0em" id="S3.SS2.p2.11.m2.2.2.1.2.2" xref="S3.SS2.p2.11.m2.2.2.1.2.2.cmml">âˆ‘</mo><mi id="S3.SS2.p2.11.m2.2.2.1.2.3" xref="S3.SS2.p2.11.m2.2.2.1.2.3.cmml">i</mi></msub><mrow id="S3.SS2.p2.11.m2.2.2.1.1" xref="S3.SS2.p2.11.m2.2.2.1.1.cmml"><msub id="S3.SS2.p2.11.m2.2.2.1.1.2" xref="S3.SS2.p2.11.m2.2.2.1.1.2.cmml"><mo rspace="0em" id="S3.SS2.p2.11.m2.2.2.1.1.2.2" xref="S3.SS2.p2.11.m2.2.2.1.1.2.2.cmml">âˆ‘</mo><mrow id="S3.SS2.p2.11.m2.2.2.1.1.2.3" xref="S3.SS2.p2.11.m2.2.2.1.1.2.3.cmml"><mi id="S3.SS2.p2.11.m2.2.2.1.1.2.3.2" xref="S3.SS2.p2.11.m2.2.2.1.1.2.3.2.cmml">x</mi><mo id="S3.SS2.p2.11.m2.2.2.1.1.2.3.1" xref="S3.SS2.p2.11.m2.2.2.1.1.2.3.1.cmml">âˆˆ</mo><mi mathvariant="normal" id="S3.SS2.p2.11.m2.2.2.1.1.2.3.3" xref="S3.SS2.p2.11.m2.2.2.1.1.2.3.3.cmml">Î©</mi></mrow></msub><mrow id="S3.SS2.p2.11.m2.2.2.1.1.1.1" xref="S3.SS2.p2.11.m2.2.2.1.1.1.2.cmml"><mo stretchy="false" id="S3.SS2.p2.11.m2.2.2.1.1.1.1.2" xref="S3.SS2.p2.11.m2.2.2.1.1.1.2.1.cmml">|</mo><mrow id="S3.SS2.p2.11.m2.2.2.1.1.1.1.1" xref="S3.SS2.p2.11.m2.2.2.1.1.1.1.1.cmml"><msub id="S3.SS2.p2.11.m2.2.2.1.1.1.1.1.2" xref="S3.SS2.p2.11.m2.2.2.1.1.1.1.1.2.cmml"><mi id="S3.SS2.p2.11.m2.2.2.1.1.1.1.1.2.2" xref="S3.SS2.p2.11.m2.2.2.1.1.1.1.1.2.2.cmml">D</mi><mrow id="S3.SS2.p2.11.m2.2.2.1.1.1.1.1.2.3" xref="S3.SS2.p2.11.m2.2.2.1.1.1.1.1.2.3.cmml"><mi mathvariant="normal" id="S3.SS2.p2.11.m2.2.2.1.1.1.1.1.2.3.2" xref="S3.SS2.p2.11.m2.2.2.1.1.1.1.1.2.3.2.cmml">Î”</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p2.11.m2.2.2.1.1.1.1.1.2.3.1" xref="S3.SS2.p2.11.m2.2.2.1.1.1.1.1.2.3.1.cmml">â€‹</mo><mi id="S3.SS2.p2.11.m2.2.2.1.1.1.1.1.2.3.3" xref="S3.SS2.p2.11.m2.2.2.1.1.1.1.1.2.3.3.cmml">s</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.SS2.p2.11.m2.2.2.1.1.1.1.1.1" xref="S3.SS2.p2.11.m2.2.2.1.1.1.1.1.1.cmml">â€‹</mo><mrow id="S3.SS2.p2.11.m2.2.2.1.1.1.1.1.3.2" xref="S3.SS2.p2.11.m2.2.2.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS2.p2.11.m2.2.2.1.1.1.1.1.3.2.1" xref="S3.SS2.p2.11.m2.2.2.1.1.1.1.1.cmml">(</mo><mi id="S3.SS2.p2.11.m2.1.1" xref="S3.SS2.p2.11.m2.1.1.cmml">x</mi><mo stretchy="false" id="S3.SS2.p2.11.m2.2.2.1.1.1.1.1.3.2.2" xref="S3.SS2.p2.11.m2.2.2.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.SS2.p2.11.m2.2.2.1.1.1.1.3" xref="S3.SS2.p2.11.m2.2.2.1.1.1.2.1.cmml">|</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.11.m2.2b"><apply id="S3.SS2.p2.11.m2.2.2.cmml" xref="S3.SS2.p2.11.m2.2.2"><eq id="S3.SS2.p2.11.m2.2.2.2.cmml" xref="S3.SS2.p2.11.m2.2.2.2"></eq><apply id="S3.SS2.p2.11.m2.2.2.3.cmml" xref="S3.SS2.p2.11.m2.2.2.3"><csymbol cd="ambiguous" id="S3.SS2.p2.11.m2.2.2.3.1.cmml" xref="S3.SS2.p2.11.m2.2.2.3">subscript</csymbol><ci id="S3.SS2.p2.11.m2.2.2.3.2.cmml" xref="S3.SS2.p2.11.m2.2.2.3.2">â„’</ci><ci id="S3.SS2.p2.11.m2.2.2.3.3.cmml" xref="S3.SS2.p2.11.m2.2.2.3.3">ğ‘</ci></apply><apply id="S3.SS2.p2.11.m2.2.2.1.cmml" xref="S3.SS2.p2.11.m2.2.2.1"><apply id="S3.SS2.p2.11.m2.2.2.1.2.cmml" xref="S3.SS2.p2.11.m2.2.2.1.2"><csymbol cd="ambiguous" id="S3.SS2.p2.11.m2.2.2.1.2.1.cmml" xref="S3.SS2.p2.11.m2.2.2.1.2">subscript</csymbol><sum id="S3.SS2.p2.11.m2.2.2.1.2.2.cmml" xref="S3.SS2.p2.11.m2.2.2.1.2.2"></sum><ci id="S3.SS2.p2.11.m2.2.2.1.2.3.cmml" xref="S3.SS2.p2.11.m2.2.2.1.2.3">ğ‘–</ci></apply><apply id="S3.SS2.p2.11.m2.2.2.1.1.cmml" xref="S3.SS2.p2.11.m2.2.2.1.1"><apply id="S3.SS2.p2.11.m2.2.2.1.1.2.cmml" xref="S3.SS2.p2.11.m2.2.2.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p2.11.m2.2.2.1.1.2.1.cmml" xref="S3.SS2.p2.11.m2.2.2.1.1.2">subscript</csymbol><sum id="S3.SS2.p2.11.m2.2.2.1.1.2.2.cmml" xref="S3.SS2.p2.11.m2.2.2.1.1.2.2"></sum><apply id="S3.SS2.p2.11.m2.2.2.1.1.2.3.cmml" xref="S3.SS2.p2.11.m2.2.2.1.1.2.3"><in id="S3.SS2.p2.11.m2.2.2.1.1.2.3.1.cmml" xref="S3.SS2.p2.11.m2.2.2.1.1.2.3.1"></in><ci id="S3.SS2.p2.11.m2.2.2.1.1.2.3.2.cmml" xref="S3.SS2.p2.11.m2.2.2.1.1.2.3.2">ğ‘¥</ci><ci id="S3.SS2.p2.11.m2.2.2.1.1.2.3.3.cmml" xref="S3.SS2.p2.11.m2.2.2.1.1.2.3.3">Î©</ci></apply></apply><apply id="S3.SS2.p2.11.m2.2.2.1.1.1.2.cmml" xref="S3.SS2.p2.11.m2.2.2.1.1.1.1"><abs id="S3.SS2.p2.11.m2.2.2.1.1.1.2.1.cmml" xref="S3.SS2.p2.11.m2.2.2.1.1.1.1.2"></abs><apply id="S3.SS2.p2.11.m2.2.2.1.1.1.1.1.cmml" xref="S3.SS2.p2.11.m2.2.2.1.1.1.1.1"><times id="S3.SS2.p2.11.m2.2.2.1.1.1.1.1.1.cmml" xref="S3.SS2.p2.11.m2.2.2.1.1.1.1.1.1"></times><apply id="S3.SS2.p2.11.m2.2.2.1.1.1.1.1.2.cmml" xref="S3.SS2.p2.11.m2.2.2.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p2.11.m2.2.2.1.1.1.1.1.2.1.cmml" xref="S3.SS2.p2.11.m2.2.2.1.1.1.1.1.2">subscript</csymbol><ci id="S3.SS2.p2.11.m2.2.2.1.1.1.1.1.2.2.cmml" xref="S3.SS2.p2.11.m2.2.2.1.1.1.1.1.2.2">ğ·</ci><apply id="S3.SS2.p2.11.m2.2.2.1.1.1.1.1.2.3.cmml" xref="S3.SS2.p2.11.m2.2.2.1.1.1.1.1.2.3"><times id="S3.SS2.p2.11.m2.2.2.1.1.1.1.1.2.3.1.cmml" xref="S3.SS2.p2.11.m2.2.2.1.1.1.1.1.2.3.1"></times><ci id="S3.SS2.p2.11.m2.2.2.1.1.1.1.1.2.3.2.cmml" xref="S3.SS2.p2.11.m2.2.2.1.1.1.1.1.2.3.2">Î”</ci><ci id="S3.SS2.p2.11.m2.2.2.1.1.1.1.1.2.3.3.cmml" xref="S3.SS2.p2.11.m2.2.2.1.1.1.1.1.2.3.3">ğ‘ </ci></apply></apply><ci id="S3.SS2.p2.11.m2.1.1.cmml" xref="S3.SS2.p2.11.m2.1.1">ğ‘¥</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.11.m2.2c">\mathcal{L}_{c}=\sum_{i}\sum_{x\in\Omega}|D_{\Delta s}(x)|</annotation></semantics></math>. The overall loss to training the 3D shape prior is</p>
<table id="S3.E7" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E7.m1.1" class="ltx_Math" alttext="\mathcal{L}=\mathcal{L}_{sdf}+\lambda_{1}{L}_{normal}+\lambda_{2}\mathcal{L}_{z}+\lambda_{3}\mathcal{L}_{smooth}+\lambda_{3}\mathcal{L}_{c}," display="block"><semantics id="S3.E7.m1.1a"><mrow id="S3.E7.m1.1.1.1" xref="S3.E7.m1.1.1.1.1.cmml"><mrow id="S3.E7.m1.1.1.1.1" xref="S3.E7.m1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E7.m1.1.1.1.1.2" xref="S3.E7.m1.1.1.1.1.2.cmml">â„’</mi><mo id="S3.E7.m1.1.1.1.1.1" xref="S3.E7.m1.1.1.1.1.1.cmml">=</mo><mrow id="S3.E7.m1.1.1.1.1.3" xref="S3.E7.m1.1.1.1.1.3.cmml"><msub id="S3.E7.m1.1.1.1.1.3.2" xref="S3.E7.m1.1.1.1.1.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E7.m1.1.1.1.1.3.2.2" xref="S3.E7.m1.1.1.1.1.3.2.2.cmml">â„’</mi><mrow id="S3.E7.m1.1.1.1.1.3.2.3" xref="S3.E7.m1.1.1.1.1.3.2.3.cmml"><mi id="S3.E7.m1.1.1.1.1.3.2.3.2" xref="S3.E7.m1.1.1.1.1.3.2.3.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E7.m1.1.1.1.1.3.2.3.1" xref="S3.E7.m1.1.1.1.1.3.2.3.1.cmml">â€‹</mo><mi id="S3.E7.m1.1.1.1.1.3.2.3.3" xref="S3.E7.m1.1.1.1.1.3.2.3.3.cmml">d</mi><mo lspace="0em" rspace="0em" id="S3.E7.m1.1.1.1.1.3.2.3.1a" xref="S3.E7.m1.1.1.1.1.3.2.3.1.cmml">â€‹</mo><mi id="S3.E7.m1.1.1.1.1.3.2.3.4" xref="S3.E7.m1.1.1.1.1.3.2.3.4.cmml">f</mi></mrow></msub><mo id="S3.E7.m1.1.1.1.1.3.1" xref="S3.E7.m1.1.1.1.1.3.1.cmml">+</mo><mrow id="S3.E7.m1.1.1.1.1.3.3" xref="S3.E7.m1.1.1.1.1.3.3.cmml"><msub id="S3.E7.m1.1.1.1.1.3.3.2" xref="S3.E7.m1.1.1.1.1.3.3.2.cmml"><mi id="S3.E7.m1.1.1.1.1.3.3.2.2" xref="S3.E7.m1.1.1.1.1.3.3.2.2.cmml">Î»</mi><mn id="S3.E7.m1.1.1.1.1.3.3.2.3" xref="S3.E7.m1.1.1.1.1.3.3.2.3.cmml">1</mn></msub><mo lspace="0em" rspace="0em" id="S3.E7.m1.1.1.1.1.3.3.1" xref="S3.E7.m1.1.1.1.1.3.3.1.cmml">â€‹</mo><msub id="S3.E7.m1.1.1.1.1.3.3.3" xref="S3.E7.m1.1.1.1.1.3.3.3.cmml"><mi id="S3.E7.m1.1.1.1.1.3.3.3.2" xref="S3.E7.m1.1.1.1.1.3.3.3.2.cmml">L</mi><mrow id="S3.E7.m1.1.1.1.1.3.3.3.3" xref="S3.E7.m1.1.1.1.1.3.3.3.3.cmml"><mi id="S3.E7.m1.1.1.1.1.3.3.3.3.2" xref="S3.E7.m1.1.1.1.1.3.3.3.3.2.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.E7.m1.1.1.1.1.3.3.3.3.1" xref="S3.E7.m1.1.1.1.1.3.3.3.3.1.cmml">â€‹</mo><mi id="S3.E7.m1.1.1.1.1.3.3.3.3.3" xref="S3.E7.m1.1.1.1.1.3.3.3.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E7.m1.1.1.1.1.3.3.3.3.1a" xref="S3.E7.m1.1.1.1.1.3.3.3.3.1.cmml">â€‹</mo><mi id="S3.E7.m1.1.1.1.1.3.3.3.3.4" xref="S3.E7.m1.1.1.1.1.3.3.3.3.4.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.E7.m1.1.1.1.1.3.3.3.3.1b" xref="S3.E7.m1.1.1.1.1.3.3.3.3.1.cmml">â€‹</mo><mi id="S3.E7.m1.1.1.1.1.3.3.3.3.5" xref="S3.E7.m1.1.1.1.1.3.3.3.3.5.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.E7.m1.1.1.1.1.3.3.3.3.1c" xref="S3.E7.m1.1.1.1.1.3.3.3.3.1.cmml">â€‹</mo><mi id="S3.E7.m1.1.1.1.1.3.3.3.3.6" xref="S3.E7.m1.1.1.1.1.3.3.3.3.6.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E7.m1.1.1.1.1.3.3.3.3.1d" xref="S3.E7.m1.1.1.1.1.3.3.3.3.1.cmml">â€‹</mo><mi id="S3.E7.m1.1.1.1.1.3.3.3.3.7" xref="S3.E7.m1.1.1.1.1.3.3.3.3.7.cmml">l</mi></mrow></msub></mrow><mo id="S3.E7.m1.1.1.1.1.3.1a" xref="S3.E7.m1.1.1.1.1.3.1.cmml">+</mo><mrow id="S3.E7.m1.1.1.1.1.3.4" xref="S3.E7.m1.1.1.1.1.3.4.cmml"><msub id="S3.E7.m1.1.1.1.1.3.4.2" xref="S3.E7.m1.1.1.1.1.3.4.2.cmml"><mi id="S3.E7.m1.1.1.1.1.3.4.2.2" xref="S3.E7.m1.1.1.1.1.3.4.2.2.cmml">Î»</mi><mn id="S3.E7.m1.1.1.1.1.3.4.2.3" xref="S3.E7.m1.1.1.1.1.3.4.2.3.cmml">2</mn></msub><mo lspace="0em" rspace="0em" id="S3.E7.m1.1.1.1.1.3.4.1" xref="S3.E7.m1.1.1.1.1.3.4.1.cmml">â€‹</mo><msub id="S3.E7.m1.1.1.1.1.3.4.3" xref="S3.E7.m1.1.1.1.1.3.4.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E7.m1.1.1.1.1.3.4.3.2" xref="S3.E7.m1.1.1.1.1.3.4.3.2.cmml">â„’</mi><mi id="S3.E7.m1.1.1.1.1.3.4.3.3" xref="S3.E7.m1.1.1.1.1.3.4.3.3.cmml">z</mi></msub></mrow><mo id="S3.E7.m1.1.1.1.1.3.1b" xref="S3.E7.m1.1.1.1.1.3.1.cmml">+</mo><mrow id="S3.E7.m1.1.1.1.1.3.5" xref="S3.E7.m1.1.1.1.1.3.5.cmml"><msub id="S3.E7.m1.1.1.1.1.3.5.2" xref="S3.E7.m1.1.1.1.1.3.5.2.cmml"><mi id="S3.E7.m1.1.1.1.1.3.5.2.2" xref="S3.E7.m1.1.1.1.1.3.5.2.2.cmml">Î»</mi><mn id="S3.E7.m1.1.1.1.1.3.5.2.3" xref="S3.E7.m1.1.1.1.1.3.5.2.3.cmml">3</mn></msub><mo lspace="0em" rspace="0em" id="S3.E7.m1.1.1.1.1.3.5.1" xref="S3.E7.m1.1.1.1.1.3.5.1.cmml">â€‹</mo><msub id="S3.E7.m1.1.1.1.1.3.5.3" xref="S3.E7.m1.1.1.1.1.3.5.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E7.m1.1.1.1.1.3.5.3.2" xref="S3.E7.m1.1.1.1.1.3.5.3.2.cmml">â„’</mi><mrow id="S3.E7.m1.1.1.1.1.3.5.3.3" xref="S3.E7.m1.1.1.1.1.3.5.3.3.cmml"><mi id="S3.E7.m1.1.1.1.1.3.5.3.3.2" xref="S3.E7.m1.1.1.1.1.3.5.3.3.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E7.m1.1.1.1.1.3.5.3.3.1" xref="S3.E7.m1.1.1.1.1.3.5.3.3.1.cmml">â€‹</mo><mi id="S3.E7.m1.1.1.1.1.3.5.3.3.3" xref="S3.E7.m1.1.1.1.1.3.5.3.3.3.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.E7.m1.1.1.1.1.3.5.3.3.1a" xref="S3.E7.m1.1.1.1.1.3.5.3.3.1.cmml">â€‹</mo><mi id="S3.E7.m1.1.1.1.1.3.5.3.3.4" xref="S3.E7.m1.1.1.1.1.3.5.3.3.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E7.m1.1.1.1.1.3.5.3.3.1b" xref="S3.E7.m1.1.1.1.1.3.5.3.3.1.cmml">â€‹</mo><mi id="S3.E7.m1.1.1.1.1.3.5.3.3.5" xref="S3.E7.m1.1.1.1.1.3.5.3.3.5.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E7.m1.1.1.1.1.3.5.3.3.1c" xref="S3.E7.m1.1.1.1.1.3.5.3.3.1.cmml">â€‹</mo><mi id="S3.E7.m1.1.1.1.1.3.5.3.3.6" xref="S3.E7.m1.1.1.1.1.3.5.3.3.6.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.E7.m1.1.1.1.1.3.5.3.3.1d" xref="S3.E7.m1.1.1.1.1.3.5.3.3.1.cmml">â€‹</mo><mi id="S3.E7.m1.1.1.1.1.3.5.3.3.7" xref="S3.E7.m1.1.1.1.1.3.5.3.3.7.cmml">h</mi></mrow></msub></mrow><mo id="S3.E7.m1.1.1.1.1.3.1c" xref="S3.E7.m1.1.1.1.1.3.1.cmml">+</mo><mrow id="S3.E7.m1.1.1.1.1.3.6" xref="S3.E7.m1.1.1.1.1.3.6.cmml"><msub id="S3.E7.m1.1.1.1.1.3.6.2" xref="S3.E7.m1.1.1.1.1.3.6.2.cmml"><mi id="S3.E7.m1.1.1.1.1.3.6.2.2" xref="S3.E7.m1.1.1.1.1.3.6.2.2.cmml">Î»</mi><mn id="S3.E7.m1.1.1.1.1.3.6.2.3" xref="S3.E7.m1.1.1.1.1.3.6.2.3.cmml">3</mn></msub><mo lspace="0em" rspace="0em" id="S3.E7.m1.1.1.1.1.3.6.1" xref="S3.E7.m1.1.1.1.1.3.6.1.cmml">â€‹</mo><msub id="S3.E7.m1.1.1.1.1.3.6.3" xref="S3.E7.m1.1.1.1.1.3.6.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E7.m1.1.1.1.1.3.6.3.2" xref="S3.E7.m1.1.1.1.1.3.6.3.2.cmml">â„’</mi><mi id="S3.E7.m1.1.1.1.1.3.6.3.3" xref="S3.E7.m1.1.1.1.1.3.6.3.3.cmml">c</mi></msub></mrow></mrow></mrow><mo id="S3.E7.m1.1.1.1.2" xref="S3.E7.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E7.m1.1b"><apply id="S3.E7.m1.1.1.1.1.cmml" xref="S3.E7.m1.1.1.1"><eq id="S3.E7.m1.1.1.1.1.1.cmml" xref="S3.E7.m1.1.1.1.1.1"></eq><ci id="S3.E7.m1.1.1.1.1.2.cmml" xref="S3.E7.m1.1.1.1.1.2">â„’</ci><apply id="S3.E7.m1.1.1.1.1.3.cmml" xref="S3.E7.m1.1.1.1.1.3"><plus id="S3.E7.m1.1.1.1.1.3.1.cmml" xref="S3.E7.m1.1.1.1.1.3.1"></plus><apply id="S3.E7.m1.1.1.1.1.3.2.cmml" xref="S3.E7.m1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.1.1.3.2.1.cmml" xref="S3.E7.m1.1.1.1.1.3.2">subscript</csymbol><ci id="S3.E7.m1.1.1.1.1.3.2.2.cmml" xref="S3.E7.m1.1.1.1.1.3.2.2">â„’</ci><apply id="S3.E7.m1.1.1.1.1.3.2.3.cmml" xref="S3.E7.m1.1.1.1.1.3.2.3"><times id="S3.E7.m1.1.1.1.1.3.2.3.1.cmml" xref="S3.E7.m1.1.1.1.1.3.2.3.1"></times><ci id="S3.E7.m1.1.1.1.1.3.2.3.2.cmml" xref="S3.E7.m1.1.1.1.1.3.2.3.2">ğ‘ </ci><ci id="S3.E7.m1.1.1.1.1.3.2.3.3.cmml" xref="S3.E7.m1.1.1.1.1.3.2.3.3">ğ‘‘</ci><ci id="S3.E7.m1.1.1.1.1.3.2.3.4.cmml" xref="S3.E7.m1.1.1.1.1.3.2.3.4">ğ‘“</ci></apply></apply><apply id="S3.E7.m1.1.1.1.1.3.3.cmml" xref="S3.E7.m1.1.1.1.1.3.3"><times id="S3.E7.m1.1.1.1.1.3.3.1.cmml" xref="S3.E7.m1.1.1.1.1.3.3.1"></times><apply id="S3.E7.m1.1.1.1.1.3.3.2.cmml" xref="S3.E7.m1.1.1.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.1.1.3.3.2.1.cmml" xref="S3.E7.m1.1.1.1.1.3.3.2">subscript</csymbol><ci id="S3.E7.m1.1.1.1.1.3.3.2.2.cmml" xref="S3.E7.m1.1.1.1.1.3.3.2.2">ğœ†</ci><cn type="integer" id="S3.E7.m1.1.1.1.1.3.3.2.3.cmml" xref="S3.E7.m1.1.1.1.1.3.3.2.3">1</cn></apply><apply id="S3.E7.m1.1.1.1.1.3.3.3.cmml" xref="S3.E7.m1.1.1.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.1.1.3.3.3.1.cmml" xref="S3.E7.m1.1.1.1.1.3.3.3">subscript</csymbol><ci id="S3.E7.m1.1.1.1.1.3.3.3.2.cmml" xref="S3.E7.m1.1.1.1.1.3.3.3.2">ğ¿</ci><apply id="S3.E7.m1.1.1.1.1.3.3.3.3.cmml" xref="S3.E7.m1.1.1.1.1.3.3.3.3"><times id="S3.E7.m1.1.1.1.1.3.3.3.3.1.cmml" xref="S3.E7.m1.1.1.1.1.3.3.3.3.1"></times><ci id="S3.E7.m1.1.1.1.1.3.3.3.3.2.cmml" xref="S3.E7.m1.1.1.1.1.3.3.3.3.2">ğ‘›</ci><ci id="S3.E7.m1.1.1.1.1.3.3.3.3.3.cmml" xref="S3.E7.m1.1.1.1.1.3.3.3.3.3">ğ‘œ</ci><ci id="S3.E7.m1.1.1.1.1.3.3.3.3.4.cmml" xref="S3.E7.m1.1.1.1.1.3.3.3.3.4">ğ‘Ÿ</ci><ci id="S3.E7.m1.1.1.1.1.3.3.3.3.5.cmml" xref="S3.E7.m1.1.1.1.1.3.3.3.3.5">ğ‘š</ci><ci id="S3.E7.m1.1.1.1.1.3.3.3.3.6.cmml" xref="S3.E7.m1.1.1.1.1.3.3.3.3.6">ğ‘</ci><ci id="S3.E7.m1.1.1.1.1.3.3.3.3.7.cmml" xref="S3.E7.m1.1.1.1.1.3.3.3.3.7">ğ‘™</ci></apply></apply></apply><apply id="S3.E7.m1.1.1.1.1.3.4.cmml" xref="S3.E7.m1.1.1.1.1.3.4"><times id="S3.E7.m1.1.1.1.1.3.4.1.cmml" xref="S3.E7.m1.1.1.1.1.3.4.1"></times><apply id="S3.E7.m1.1.1.1.1.3.4.2.cmml" xref="S3.E7.m1.1.1.1.1.3.4.2"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.1.1.3.4.2.1.cmml" xref="S3.E7.m1.1.1.1.1.3.4.2">subscript</csymbol><ci id="S3.E7.m1.1.1.1.1.3.4.2.2.cmml" xref="S3.E7.m1.1.1.1.1.3.4.2.2">ğœ†</ci><cn type="integer" id="S3.E7.m1.1.1.1.1.3.4.2.3.cmml" xref="S3.E7.m1.1.1.1.1.3.4.2.3">2</cn></apply><apply id="S3.E7.m1.1.1.1.1.3.4.3.cmml" xref="S3.E7.m1.1.1.1.1.3.4.3"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.1.1.3.4.3.1.cmml" xref="S3.E7.m1.1.1.1.1.3.4.3">subscript</csymbol><ci id="S3.E7.m1.1.1.1.1.3.4.3.2.cmml" xref="S3.E7.m1.1.1.1.1.3.4.3.2">â„’</ci><ci id="S3.E7.m1.1.1.1.1.3.4.3.3.cmml" xref="S3.E7.m1.1.1.1.1.3.4.3.3">ğ‘§</ci></apply></apply><apply id="S3.E7.m1.1.1.1.1.3.5.cmml" xref="S3.E7.m1.1.1.1.1.3.5"><times id="S3.E7.m1.1.1.1.1.3.5.1.cmml" xref="S3.E7.m1.1.1.1.1.3.5.1"></times><apply id="S3.E7.m1.1.1.1.1.3.5.2.cmml" xref="S3.E7.m1.1.1.1.1.3.5.2"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.1.1.3.5.2.1.cmml" xref="S3.E7.m1.1.1.1.1.3.5.2">subscript</csymbol><ci id="S3.E7.m1.1.1.1.1.3.5.2.2.cmml" xref="S3.E7.m1.1.1.1.1.3.5.2.2">ğœ†</ci><cn type="integer" id="S3.E7.m1.1.1.1.1.3.5.2.3.cmml" xref="S3.E7.m1.1.1.1.1.3.5.2.3">3</cn></apply><apply id="S3.E7.m1.1.1.1.1.3.5.3.cmml" xref="S3.E7.m1.1.1.1.1.3.5.3"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.1.1.3.5.3.1.cmml" xref="S3.E7.m1.1.1.1.1.3.5.3">subscript</csymbol><ci id="S3.E7.m1.1.1.1.1.3.5.3.2.cmml" xref="S3.E7.m1.1.1.1.1.3.5.3.2">â„’</ci><apply id="S3.E7.m1.1.1.1.1.3.5.3.3.cmml" xref="S3.E7.m1.1.1.1.1.3.5.3.3"><times id="S3.E7.m1.1.1.1.1.3.5.3.3.1.cmml" xref="S3.E7.m1.1.1.1.1.3.5.3.3.1"></times><ci id="S3.E7.m1.1.1.1.1.3.5.3.3.2.cmml" xref="S3.E7.m1.1.1.1.1.3.5.3.3.2">ğ‘ </ci><ci id="S3.E7.m1.1.1.1.1.3.5.3.3.3.cmml" xref="S3.E7.m1.1.1.1.1.3.5.3.3.3">ğ‘š</ci><ci id="S3.E7.m1.1.1.1.1.3.5.3.3.4.cmml" xref="S3.E7.m1.1.1.1.1.3.5.3.3.4">ğ‘œ</ci><ci id="S3.E7.m1.1.1.1.1.3.5.3.3.5.cmml" xref="S3.E7.m1.1.1.1.1.3.5.3.3.5">ğ‘œ</ci><ci id="S3.E7.m1.1.1.1.1.3.5.3.3.6.cmml" xref="S3.E7.m1.1.1.1.1.3.5.3.3.6">ğ‘¡</ci><ci id="S3.E7.m1.1.1.1.1.3.5.3.3.7.cmml" xref="S3.E7.m1.1.1.1.1.3.5.3.3.7">â„</ci></apply></apply></apply><apply id="S3.E7.m1.1.1.1.1.3.6.cmml" xref="S3.E7.m1.1.1.1.1.3.6"><times id="S3.E7.m1.1.1.1.1.3.6.1.cmml" xref="S3.E7.m1.1.1.1.1.3.6.1"></times><apply id="S3.E7.m1.1.1.1.1.3.6.2.cmml" xref="S3.E7.m1.1.1.1.1.3.6.2"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.1.1.3.6.2.1.cmml" xref="S3.E7.m1.1.1.1.1.3.6.2">subscript</csymbol><ci id="S3.E7.m1.1.1.1.1.3.6.2.2.cmml" xref="S3.E7.m1.1.1.1.1.3.6.2.2">ğœ†</ci><cn type="integer" id="S3.E7.m1.1.1.1.1.3.6.2.3.cmml" xref="S3.E7.m1.1.1.1.1.3.6.2.3">3</cn></apply><apply id="S3.E7.m1.1.1.1.1.3.6.3.cmml" xref="S3.E7.m1.1.1.1.1.3.6.3"><csymbol cd="ambiguous" id="S3.E7.m1.1.1.1.1.3.6.3.1.cmml" xref="S3.E7.m1.1.1.1.1.3.6.3">subscript</csymbol><ci id="S3.E7.m1.1.1.1.1.3.6.3.2.cmml" xref="S3.E7.m1.1.1.1.1.3.6.3.2">â„’</ci><ci id="S3.E7.m1.1.1.1.1.3.6.3.3.cmml" xref="S3.E7.m1.1.1.1.1.3.6.3.3">ğ‘</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E7.m1.1c">\mathcal{L}=\mathcal{L}_{sdf}+\lambda_{1}{L}_{normal}+\lambda_{2}\mathcal{L}_{z}+\lambda_{3}\mathcal{L}_{smooth}+\lambda_{3}\mathcal{L}_{c},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(7)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.p2.12" class="ltx_p">with the <math id="S3.SS2.p2.12.m1.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S3.SS2.p2.12.m1.1a"><mi id="S3.SS2.p2.12.m1.1.1" xref="S3.SS2.p2.12.m1.1.1.cmml">Î»</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.12.m1.1b"><ci id="S3.SS2.p2.12.m1.1.1.cmml" xref="S3.SS2.p2.12.m1.1.1">ğœ†</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.12.m1.1c">\lambda</annotation></semantics></math> terms weighing the relative importance of each loss term.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS3.5.1.1" class="ltx_text">III-C</span> </span><span id="S3.SS3.6.2" class="ltx_text ltx_font_italic">Point Cloud Lifting and Canonicalization during testing</span>
</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">During inference, we use a single RGB-D image and known camera intrinsic parameters to lift the depth image to a partial 3D point cloud. In order to predict the deformation field, we first transform the partial point cloud to the canonical coordinate frame using Equi-poseÂ <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> as our pose estimation module.
Equi-pose is a SE(3)-equivariant network that learns category-specific canonical shape reconstruction and pose estimation in a self-supervised manner. By enforcing consistency between the invariant shape reconstruction and the input point cloud transformed by the estimated pose, Equi-pose can estimate the pose of the input point cloud with respect to the learned canonical frame.
Therefore, we first input a complete template shape in our canonical frame to Equi-pose such that the transformation between our canonical frame and Equi-poseâ€™s canonical frame can be obtained. This way, we can transform any observed partial point cloud to our canonical frame using Equi-pose as a pose estimator. However, the estimated pose from Equi-pose can only serve as a noisy initialization. We show in SectionÂ <a href="#S3.SS4" title="III-D Jointly Optimizing Shape and Pose â€£ III Method â€£ 3D Surface Reconstruction in the Wild by Deforming Shape Priors from Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-D</span></span></a> how our method further finetunes the pose to achieve accurate shape reconstruction.</p>
</div>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS4.5.1.1" class="ltx_text">III-D</span> </span><span id="S3.SS4.6.2" class="ltx_text ltx_font_italic">Jointly Optimizing Shape and Pose</span>
</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.2" class="ltx_p">Once we train the 3D shape prior network and the partial input point cloud is roughly aligned in the canonical space, we reconstruct the object surface by optimizing the latent code and the object pose while keeping the SDF network weights fixed. As canonical 3D reconstruction methods are sensitive to minor deviations between estimated and canonical coordinate frames, we jointly optimize the latent code <math id="S3.SS4.p1.1.m1.1" class="ltx_Math" alttext="z_{i}" display="inline"><semantics id="S3.SS4.p1.1.m1.1a"><msub id="S3.SS4.p1.1.m1.1.1" xref="S3.SS4.p1.1.m1.1.1.cmml"><mi id="S3.SS4.p1.1.m1.1.1.2" xref="S3.SS4.p1.1.m1.1.1.2.cmml">z</mi><mi id="S3.SS4.p1.1.m1.1.1.3" xref="S3.SS4.p1.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.1.m1.1b"><apply id="S3.SS4.p1.1.m1.1.1.cmml" xref="S3.SS4.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS4.p1.1.m1.1.1.1.cmml" xref="S3.SS4.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS4.p1.1.m1.1.1.2.cmml" xref="S3.SS4.p1.1.m1.1.1.2">ğ‘§</ci><ci id="S3.SS4.p1.1.m1.1.1.3.cmml" xref="S3.SS4.p1.1.m1.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.1.m1.1c">z_{i}</annotation></semantics></math> and the initial transformation by minimizing the SDF values at the observed depth points. At the same time, we sample random points in free space for the Eikonal term to ensure that the neural field is an SDF. We represent the translation as a three-dimensional vector initialized to zero and use the continuous 6D rotation parametrization fromÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib70" title="" class="ltx_ref">70</a>]</cite> for rotations. We choose a random latent code from the learned latent space as our initialization <math id="S3.SS4.p1.2.m2.1" class="ltx_Math" alttext="z_{i}" display="inline"><semantics id="S3.SS4.p1.2.m2.1a"><msub id="S3.SS4.p1.2.m2.1.1" xref="S3.SS4.p1.2.m2.1.1.cmml"><mi id="S3.SS4.p1.2.m2.1.1.2" xref="S3.SS4.p1.2.m2.1.1.2.cmml">z</mi><mi id="S3.SS4.p1.2.m2.1.1.3" xref="S3.SS4.p1.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.2.m2.1b"><apply id="S3.SS4.p1.2.m2.1.1.cmml" xref="S3.SS4.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS4.p1.2.m2.1.1.1.cmml" xref="S3.SS4.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS4.p1.2.m2.1.1.2.cmml" xref="S3.SS4.p1.2.m2.1.1.2">ğ‘§</ci><ci id="S3.SS4.p1.2.m2.1.1.3.cmml" xref="S3.SS4.p1.2.m2.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.2.m2.1c">z_{i}</annotation></semantics></math> and optimize</p>
</div>
<div id="S3.SS4.p2" class="ltx_para">
<table id="S3.E8" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E8.m1.4" class="ltx_Math" alttext="\text{min}_{z_{i},R,t}\mathcal{L}_{sdf}+\lambda_{2}\mathcal{L}_{z}." display="block"><semantics id="S3.E8.m1.4a"><mrow id="S3.E8.m1.4.4.1" xref="S3.E8.m1.4.4.1.1.cmml"><mrow id="S3.E8.m1.4.4.1.1" xref="S3.E8.m1.4.4.1.1.cmml"><mrow id="S3.E8.m1.4.4.1.1.2" xref="S3.E8.m1.4.4.1.1.2.cmml"><msub id="S3.E8.m1.4.4.1.1.2.2" xref="S3.E8.m1.4.4.1.1.2.2.cmml"><mtext id="S3.E8.m1.4.4.1.1.2.2.2" xref="S3.E8.m1.4.4.1.1.2.2.2a.cmml">min</mtext><mrow id="S3.E8.m1.3.3.3.3" xref="S3.E8.m1.3.3.3.4.cmml"><msub id="S3.E8.m1.3.3.3.3.1" xref="S3.E8.m1.3.3.3.3.1.cmml"><mi id="S3.E8.m1.3.3.3.3.1.2" xref="S3.E8.m1.3.3.3.3.1.2.cmml">z</mi><mi id="S3.E8.m1.3.3.3.3.1.3" xref="S3.E8.m1.3.3.3.3.1.3.cmml">i</mi></msub><mo id="S3.E8.m1.3.3.3.3.2" xref="S3.E8.m1.3.3.3.4.cmml">,</mo><mi id="S3.E8.m1.1.1.1.1" xref="S3.E8.m1.1.1.1.1.cmml">R</mi><mo id="S3.E8.m1.3.3.3.3.3" xref="S3.E8.m1.3.3.3.4.cmml">,</mo><mi id="S3.E8.m1.2.2.2.2" xref="S3.E8.m1.2.2.2.2.cmml">t</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E8.m1.4.4.1.1.2.1" xref="S3.E8.m1.4.4.1.1.2.1.cmml">â€‹</mo><msub id="S3.E8.m1.4.4.1.1.2.3" xref="S3.E8.m1.4.4.1.1.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E8.m1.4.4.1.1.2.3.2" xref="S3.E8.m1.4.4.1.1.2.3.2.cmml">â„’</mi><mrow id="S3.E8.m1.4.4.1.1.2.3.3" xref="S3.E8.m1.4.4.1.1.2.3.3.cmml"><mi id="S3.E8.m1.4.4.1.1.2.3.3.2" xref="S3.E8.m1.4.4.1.1.2.3.3.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E8.m1.4.4.1.1.2.3.3.1" xref="S3.E8.m1.4.4.1.1.2.3.3.1.cmml">â€‹</mo><mi id="S3.E8.m1.4.4.1.1.2.3.3.3" xref="S3.E8.m1.4.4.1.1.2.3.3.3.cmml">d</mi><mo lspace="0em" rspace="0em" id="S3.E8.m1.4.4.1.1.2.3.3.1a" xref="S3.E8.m1.4.4.1.1.2.3.3.1.cmml">â€‹</mo><mi id="S3.E8.m1.4.4.1.1.2.3.3.4" xref="S3.E8.m1.4.4.1.1.2.3.3.4.cmml">f</mi></mrow></msub></mrow><mo id="S3.E8.m1.4.4.1.1.1" xref="S3.E8.m1.4.4.1.1.1.cmml">+</mo><mrow id="S3.E8.m1.4.4.1.1.3" xref="S3.E8.m1.4.4.1.1.3.cmml"><msub id="S3.E8.m1.4.4.1.1.3.2" xref="S3.E8.m1.4.4.1.1.3.2.cmml"><mi id="S3.E8.m1.4.4.1.1.3.2.2" xref="S3.E8.m1.4.4.1.1.3.2.2.cmml">Î»</mi><mn id="S3.E8.m1.4.4.1.1.3.2.3" xref="S3.E8.m1.4.4.1.1.3.2.3.cmml">2</mn></msub><mo lspace="0em" rspace="0em" id="S3.E8.m1.4.4.1.1.3.1" xref="S3.E8.m1.4.4.1.1.3.1.cmml">â€‹</mo><msub id="S3.E8.m1.4.4.1.1.3.3" xref="S3.E8.m1.4.4.1.1.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E8.m1.4.4.1.1.3.3.2" xref="S3.E8.m1.4.4.1.1.3.3.2.cmml">â„’</mi><mi id="S3.E8.m1.4.4.1.1.3.3.3" xref="S3.E8.m1.4.4.1.1.3.3.3.cmml">z</mi></msub></mrow></mrow><mo lspace="0em" id="S3.E8.m1.4.4.1.2" xref="S3.E8.m1.4.4.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E8.m1.4b"><apply id="S3.E8.m1.4.4.1.1.cmml" xref="S3.E8.m1.4.4.1"><plus id="S3.E8.m1.4.4.1.1.1.cmml" xref="S3.E8.m1.4.4.1.1.1"></plus><apply id="S3.E8.m1.4.4.1.1.2.cmml" xref="S3.E8.m1.4.4.1.1.2"><times id="S3.E8.m1.4.4.1.1.2.1.cmml" xref="S3.E8.m1.4.4.1.1.2.1"></times><apply id="S3.E8.m1.4.4.1.1.2.2.cmml" xref="S3.E8.m1.4.4.1.1.2.2"><csymbol cd="ambiguous" id="S3.E8.m1.4.4.1.1.2.2.1.cmml" xref="S3.E8.m1.4.4.1.1.2.2">subscript</csymbol><ci id="S3.E8.m1.4.4.1.1.2.2.2a.cmml" xref="S3.E8.m1.4.4.1.1.2.2.2"><mtext id="S3.E8.m1.4.4.1.1.2.2.2.cmml" xref="S3.E8.m1.4.4.1.1.2.2.2">min</mtext></ci><list id="S3.E8.m1.3.3.3.4.cmml" xref="S3.E8.m1.3.3.3.3"><apply id="S3.E8.m1.3.3.3.3.1.cmml" xref="S3.E8.m1.3.3.3.3.1"><csymbol cd="ambiguous" id="S3.E8.m1.3.3.3.3.1.1.cmml" xref="S3.E8.m1.3.3.3.3.1">subscript</csymbol><ci id="S3.E8.m1.3.3.3.3.1.2.cmml" xref="S3.E8.m1.3.3.3.3.1.2">ğ‘§</ci><ci id="S3.E8.m1.3.3.3.3.1.3.cmml" xref="S3.E8.m1.3.3.3.3.1.3">ğ‘–</ci></apply><ci id="S3.E8.m1.1.1.1.1.cmml" xref="S3.E8.m1.1.1.1.1">ğ‘…</ci><ci id="S3.E8.m1.2.2.2.2.cmml" xref="S3.E8.m1.2.2.2.2">ğ‘¡</ci></list></apply><apply id="S3.E8.m1.4.4.1.1.2.3.cmml" xref="S3.E8.m1.4.4.1.1.2.3"><csymbol cd="ambiguous" id="S3.E8.m1.4.4.1.1.2.3.1.cmml" xref="S3.E8.m1.4.4.1.1.2.3">subscript</csymbol><ci id="S3.E8.m1.4.4.1.1.2.3.2.cmml" xref="S3.E8.m1.4.4.1.1.2.3.2">â„’</ci><apply id="S3.E8.m1.4.4.1.1.2.3.3.cmml" xref="S3.E8.m1.4.4.1.1.2.3.3"><times id="S3.E8.m1.4.4.1.1.2.3.3.1.cmml" xref="S3.E8.m1.4.4.1.1.2.3.3.1"></times><ci id="S3.E8.m1.4.4.1.1.2.3.3.2.cmml" xref="S3.E8.m1.4.4.1.1.2.3.3.2">ğ‘ </ci><ci id="S3.E8.m1.4.4.1.1.2.3.3.3.cmml" xref="S3.E8.m1.4.4.1.1.2.3.3.3">ğ‘‘</ci><ci id="S3.E8.m1.4.4.1.1.2.3.3.4.cmml" xref="S3.E8.m1.4.4.1.1.2.3.3.4">ğ‘“</ci></apply></apply></apply><apply id="S3.E8.m1.4.4.1.1.3.cmml" xref="S3.E8.m1.4.4.1.1.3"><times id="S3.E8.m1.4.4.1.1.3.1.cmml" xref="S3.E8.m1.4.4.1.1.3.1"></times><apply id="S3.E8.m1.4.4.1.1.3.2.cmml" xref="S3.E8.m1.4.4.1.1.3.2"><csymbol cd="ambiguous" id="S3.E8.m1.4.4.1.1.3.2.1.cmml" xref="S3.E8.m1.4.4.1.1.3.2">subscript</csymbol><ci id="S3.E8.m1.4.4.1.1.3.2.2.cmml" xref="S3.E8.m1.4.4.1.1.3.2.2">ğœ†</ci><cn type="integer" id="S3.E8.m1.4.4.1.1.3.2.3.cmml" xref="S3.E8.m1.4.4.1.1.3.2.3">2</cn></apply><apply id="S3.E8.m1.4.4.1.1.3.3.cmml" xref="S3.E8.m1.4.4.1.1.3.3"><csymbol cd="ambiguous" id="S3.E8.m1.4.4.1.1.3.3.1.cmml" xref="S3.E8.m1.4.4.1.1.3.3">subscript</csymbol><ci id="S3.E8.m1.4.4.1.1.3.3.2.cmml" xref="S3.E8.m1.4.4.1.1.3.3.2">â„’</ci><ci id="S3.E8.m1.4.4.1.1.3.3.3.cmml" xref="S3.E8.m1.4.4.1.1.3.3.3">ğ‘§</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E8.m1.4c">\text{min}_{z_{i},R,t}\mathcal{L}_{sdf}+\lambda_{2}\mathcal{L}_{z}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(8)</span></td>
</tr></tbody>
</table>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Experiments</span>
</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p"><span id="S4.p1.1.1" class="ltx_text ltx_font_bold">Datasets</span> According with other works in the literature, we include three categories in our experiments: car, chair, and airplane. These categories are present across multiple datasets, facilitating comparison between approaches and enabling evaluation of a methods generalization capabilities. We use synthetic data from the ShapeNet datasetÂ <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> to train our deformation and template networks using 3D ground truth. Then our method trained on Shapenet is directly evaluated on the following datasets: ShapeNetÂ <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>, Pix3D chairsÂ <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>, Pascal3D+Â <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite> and the DDADÂ <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>, without retraining. Since Pascal3D+ and Pix3D do not contain depth scans, we generate the partial point clouds by removing invisible points of the CAD models using the ground truth camera poses. As DDAD does not provide reconstruction ground truth, we show the performance of our method on real-world noisy scans qualitatively only. See the appendix for additional information on datasets, baselines, and implementation details.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.4" class="ltx_p"><span id="S4.p2.4.1" class="ltx_text ltx_font_bold">Implementation Details</span> In line with prior work we train the 3D shape network on three categories in the ShapenetÂ <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> dataset, namely <span id="S4.p2.4.2" class="ltx_text ltx_font_italic">car, chair</span> and <span id="S4.p2.4.3" class="ltx_text ltx_font_italic">plane</span>. The networks are trained using the Adam optimizerÂ <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>. We use batch size <math id="S4.p2.1.m1.1" class="ltx_Math" alttext="128" display="inline"><semantics id="S4.p2.1.m1.1a"><mn id="S4.p2.1.m1.1.1" xref="S4.p2.1.m1.1.1.cmml">128</mn><annotation-xml encoding="MathML-Content" id="S4.p2.1.m1.1b"><cn type="integer" id="S4.p2.1.m1.1.1.cmml" xref="S4.p2.1.m1.1.1">128</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.1.m1.1c">128</annotation></semantics></math> shapes per iteration and use <math id="S4.p2.2.m2.1" class="ltx_Math" alttext="4000" display="inline"><semantics id="S4.p2.2.m2.1a"><mn id="S4.p2.2.m2.1.1" xref="S4.p2.2.m2.1.1.cmml">4000</mn><annotation-xml encoding="MathML-Content" id="S4.p2.2.m2.1b"><cn type="integer" id="S4.p2.2.m2.1.1.cmml" xref="S4.p2.2.m2.1.1">4000</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.2.m2.1c">4000</annotation></semantics></math> points on the surface, and <math id="S4.p2.3.m3.1" class="ltx_Math" alttext="4000" display="inline"><semantics id="S4.p2.3.m3.1a"><mn id="S4.p2.3.m3.1.1" xref="S4.p2.3.m3.1.1.cmml">4000</mn><annotation-xml encoding="MathML-Content" id="S4.p2.3.m3.1b"><cn type="integer" id="S4.p2.3.m3.1.1.cmml" xref="S4.p2.3.m3.1.1">4000</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.3.m3.1c">4000</annotation></semantics></math> randomly sampled points in free space per object. Training takes <math id="S4.p2.4.m4.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S4.p2.4.m4.1a"><mn id="S4.p2.4.m4.1.1" xref="S4.p2.4.m4.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S4.p2.4.m4.1b"><cn type="integer" id="S4.p2.4.m4.1.1.cmml" xref="S4.p2.4.m4.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.4.m4.1c">10</annotation></semantics></math> hours on four NVIDIA V100 GPUs.</p>
</div>
<div id="S4.p3" class="ltx_para">
<p id="S4.p3.1" class="ltx_p"><span id="S4.p3.1.1" class="ltx_text ltx_font_bold">Baselines</span> We compare against the state-of-the-art in single view, category-specific 3D object reconstruction: i) SDF-SRNÂ <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>, a neural field method that represents the object in camera coordinate frame and uses a neural renderer with silhouette supervision. ii) TARS-3DÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> is a method that uses ground truth camera poses to render a deformed template shape in canonical space to the image coordinate frame. Note that TARS-3D does not require ground truth camera poses during inference, but also does not estimate the object pose. Rather, it outputs the estimates surface reconstruction in the canonical coordinate frame. Instead, both TARS and SDF-SRN output the 3D surface reconstruction in the canonical coordinate frame.</p>
</div>
<div id="S4.p4" class="ltx_para">
<p id="S4.p4.1" class="ltx_p">As our method is closely related to point cloud completion, we further compare our method against a transformer-based point cloud completion method, PoinTrÂ <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite>. In contrast to the baselines, our model is only trained on Shapenet and does not require camera pose information during both training and testing time. Only a partial depth scan is needed during inference.</p>
</div>
<figure id="S4.F3" class="ltx_figure"><img src="/html/2302.12883/assets/x3.png" id="S4.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="265" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Qualitative result on the occluded Shapenet dataset. Our model outputs more accurate 3D shapes, as we do not condition on the input image, but can finetune the latent shape based on the partial depth observation.</figcaption>
</figure>
<div id="S4.p5" class="ltx_para">
<p id="S4.p5.2" class="ltx_p"><span id="S4.p5.2.1" class="ltx_text ltx_font_bold">Evaluation Metrics</span> In this work, we followÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref">51</a>]</cite> and report the F1-score at threshold <math id="S4.p5.1.m1.1" class="ltx_Math" alttext="1\%" display="inline"><semantics id="S4.p5.1.m1.1a"><mrow id="S4.p5.1.m1.1.1" xref="S4.p5.1.m1.1.1.cmml"><mn id="S4.p5.1.m1.1.1.2" xref="S4.p5.1.m1.1.1.2.cmml">1</mn><mo id="S4.p5.1.m1.1.1.1" xref="S4.p5.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.p5.1.m1.1b"><apply id="S4.p5.1.m1.1.1.cmml" xref="S4.p5.1.m1.1.1"><csymbol cd="latexml" id="S4.p5.1.m1.1.1.1.cmml" xref="S4.p5.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S4.p5.1.m1.1.1.2.cmml" xref="S4.p5.1.m1.1.1.2">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p5.1.m1.1c">1\%</annotation></semantics></math> as our primary evaluation metric. Tatarchenko et. al showed, that common metrics, such as chamfer distance and IoU allow for large variations from the ground truth model. In contrast, F1 score with a tight threshold requires the prediction to closely follow the ground truth to achieve high score. We additionally report the bidirectional chamfer distance (CD), multiplied by a factor of <math id="S4.p5.2.m2.1" class="ltx_Math" alttext="1e4" display="inline"><semantics id="S4.p5.2.m2.1a"><mrow id="S4.p5.2.m2.1.1" xref="S4.p5.2.m2.1.1.cmml"><mn id="S4.p5.2.m2.1.1.2" xref="S4.p5.2.m2.1.1.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="S4.p5.2.m2.1.1.1" xref="S4.p5.2.m2.1.1.1.cmml">â€‹</mo><mi id="S4.p5.2.m2.1.1.3" xref="S4.p5.2.m2.1.1.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.p5.2.m2.1.1.1a" xref="S4.p5.2.m2.1.1.1.cmml">â€‹</mo><mn id="S4.p5.2.m2.1.1.4" xref="S4.p5.2.m2.1.1.4.cmml">4</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.p5.2.m2.1b"><apply id="S4.p5.2.m2.1.1.cmml" xref="S4.p5.2.m2.1.1"><times id="S4.p5.2.m2.1.1.1.cmml" xref="S4.p5.2.m2.1.1.1"></times><cn type="integer" id="S4.p5.2.m2.1.1.2.cmml" xref="S4.p5.2.m2.1.1.2">1</cn><ci id="S4.p5.2.m2.1.1.3.cmml" xref="S4.p5.2.m2.1.1.3">ğ‘’</ci><cn type="integer" id="S4.p5.2.m2.1.1.4.cmml" xref="S4.p5.2.m2.1.1.4">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p5.2.m2.1c">1e4</annotation></semantics></math> for readability.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS1.5.1.1" class="ltx_text">IV-A</span> </span><span id="S4.SS1.6.2" class="ltx_text ltx_font_italic">3D Reconstruction on synthetic Shapenet data</span>
</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">TableÂ <a href="#S4.T1" title="TABLE I â€£ IV-A 3D Reconstruction on synthetic Shapenet data â€£ IV Experiments â€£ 3D Surface Reconstruction in the Wild by Deforming Shape Priors from Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a> shows quantitative results of testing all approaches on the holdout test set of Shapenet. Our method outperforms the baselines in the car and plane categories with ground truth camera poses and is competitive in the chair category. We investigate cases where no ground truth camera poses are available and initialize our method and PoinTr with the Equi-pose estimates. Even without access to ground truth camera poses, our method performs comparable to or better than the baseline methods. We can see that PoinTr suffers greatly when the coordinates are not in the canonical coordinate system, showing that our approach of combining canonicalization with shape reconstruction is necessary for 3D shape reconstruction on real-world depth data. Our methodâ€™s 3D reconstructions are more faithful to the underlying ground truth mesh, shown by the fact that we outperform all other methods on the F1 metric. PoinTr outputs only a limited number of points and does not reconstruct the underlying surface, nor does it give us correspondences between shapes in a category.</p>
</div>
<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE I: </span>3D reconstruction results on synthetic test data. We report chamfer distance (CD) <math id="S4.T1.6.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T1.6.m1.1b"><mo stretchy="false" id="S4.T1.6.m1.1.1" xref="S4.T1.6.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S4.T1.6.m1.1c"><ci id="S4.T1.6.m1.1.1.cmml" xref="S4.T1.6.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.6.m1.1d">\downarrow</annotation></semantics></math> and F-score at threshold <math id="S4.T1.7.m2.1" class="ltx_Math" alttext="0.01" display="inline"><semantics id="S4.T1.7.m2.1b"><mn id="S4.T1.7.m2.1.1" xref="S4.T1.7.m2.1.1.cmml">0.01</mn><annotation-xml encoding="MathML-Content" id="S4.T1.7.m2.1c"><cn type="float" id="S4.T1.7.m2.1.1.cmml" xref="S4.T1.7.m2.1.1">0.01</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.7.m2.1d">0.01</annotation></semantics></math> (F@<math id="S4.T1.8.m3.1" class="ltx_Math" alttext="1\%" display="inline"><semantics id="S4.T1.8.m3.1b"><mrow id="S4.T1.8.m3.1.1" xref="S4.T1.8.m3.1.1.cmml"><mn id="S4.T1.8.m3.1.1.2" xref="S4.T1.8.m3.1.1.2.cmml">1</mn><mo id="S4.T1.8.m3.1.1.1" xref="S4.T1.8.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.8.m3.1c"><apply id="S4.T1.8.m3.1.1.cmml" xref="S4.T1.8.m3.1.1"><csymbol cd="latexml" id="S4.T1.8.m3.1.1.1.cmml" xref="S4.T1.8.m3.1.1.1">percent</csymbol><cn type="integer" id="S4.T1.8.m3.1.1.2.cmml" xref="S4.T1.8.m3.1.1.2">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.8.m3.1d">1\%</annotation></semantics></math>)<math id="S4.T1.9.m4.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T1.9.m4.1b"><mo stretchy="false" id="S4.T1.9.m4.1.1" xref="S4.T1.9.m4.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S4.T1.9.m4.1c"><ci id="S4.T1.9.m4.1.1.cmml" xref="S4.T1.9.m4.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.9.m4.1d">\uparrow</annotation></semantics></math>. <sup id="S4.T1.20.1" class="ltx_sup">â€ </sup> with ground truth camera poses.</figcaption>
<p id="S4.T1.18" class="ltx_p"><span id="S4.T1.18.8" class="ltx_text">
<span id="S4.T1.18.8.8" class="ltx_inline-block ltx_transformed_outer" style="width:330.0pt;height:144pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<span id="S4.T1.18.8.8.8" class="ltx_p"><span id="S4.T1.18.8.8.8.8" class="ltx_text">

<span id="S4.T1.18.8.8.8.8.8" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<span class="ltx_tbody">
<span id="S4.T1.18.8.8.8.8.8.9.1" class="ltx_tr">
<span id="S4.T1.18.8.8.8.8.8.9.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt">Methods</span>
<span id="S4.T1.18.8.8.8.8.8.9.1.2" class="ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_2">Car</span>
<span id="S4.T1.18.8.8.8.8.8.9.1.3" class="ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_2">Chair</span>
<span id="S4.T1.18.8.8.8.8.8.9.1.4" class="ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_2">Plane</span></span>
<span id="S4.T1.16.6.6.6.6.6.6" class="ltx_tr">
<span id="S4.T1.16.6.6.6.6.6.6.7" class="ltx_td ltx_th ltx_th_row"></span>
<span id="S4.T1.11.1.1.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t">CD <math id="S4.T1.11.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="(\downarrow)" display="inline"><semantics id="S4.T1.11.1.1.1.1.1.1.1.m1.1a"><mrow id="S4.T1.11.1.1.1.1.1.1.1.m1.1.2.2"><mo stretchy="false" id="S4.T1.11.1.1.1.1.1.1.1.m1.1.2.2.1">(</mo><mo lspace="0em" rspace="0em" stretchy="false" id="S4.T1.11.1.1.1.1.1.1.1.m1.1.1" xref="S4.T1.11.1.1.1.1.1.1.1.m1.1.1.cmml">â†“</mo><mo stretchy="false" id="S4.T1.11.1.1.1.1.1.1.1.m1.1.2.2.2">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.11.1.1.1.1.1.1.1.m1.1b"><ci id="S4.T1.11.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S4.T1.11.1.1.1.1.1.1.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.11.1.1.1.1.1.1.1.m1.1c">(\downarrow)</annotation></semantics></math></span>
<span id="S4.T1.12.2.2.2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_t">F@1 <math id="S4.T1.12.2.2.2.2.2.2.2.m1.1" class="ltx_Math" alttext="(\uparrow)" display="inline"><semantics id="S4.T1.12.2.2.2.2.2.2.2.m1.1a"><mrow id="S4.T1.12.2.2.2.2.2.2.2.m1.1.2.2"><mo stretchy="false" id="S4.T1.12.2.2.2.2.2.2.2.m1.1.2.2.1">(</mo><mo lspace="0em" rspace="0em" stretchy="false" id="S4.T1.12.2.2.2.2.2.2.2.m1.1.1" xref="S4.T1.12.2.2.2.2.2.2.2.m1.1.1.cmml">â†‘</mo><mo stretchy="false" id="S4.T1.12.2.2.2.2.2.2.2.m1.1.2.2.2">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.12.2.2.2.2.2.2.2.m1.1b"><ci id="S4.T1.12.2.2.2.2.2.2.2.m1.1.1.cmml" xref="S4.T1.12.2.2.2.2.2.2.2.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.12.2.2.2.2.2.2.2.m1.1c">(\uparrow)</annotation></semantics></math></span>
<span id="S4.T1.13.3.3.3.3.3.3.3" class="ltx_td ltx_align_center ltx_border_t">CD <math id="S4.T1.13.3.3.3.3.3.3.3.m1.1" class="ltx_Math" alttext="(\downarrow)" display="inline"><semantics id="S4.T1.13.3.3.3.3.3.3.3.m1.1a"><mrow id="S4.T1.13.3.3.3.3.3.3.3.m1.1.2.2"><mo stretchy="false" id="S4.T1.13.3.3.3.3.3.3.3.m1.1.2.2.1">(</mo><mo lspace="0em" rspace="0em" stretchy="false" id="S4.T1.13.3.3.3.3.3.3.3.m1.1.1" xref="S4.T1.13.3.3.3.3.3.3.3.m1.1.1.cmml">â†“</mo><mo stretchy="false" id="S4.T1.13.3.3.3.3.3.3.3.m1.1.2.2.2">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.13.3.3.3.3.3.3.3.m1.1b"><ci id="S4.T1.13.3.3.3.3.3.3.3.m1.1.1.cmml" xref="S4.T1.13.3.3.3.3.3.3.3.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.13.3.3.3.3.3.3.3.m1.1c">(\downarrow)</annotation></semantics></math></span>
<span id="S4.T1.14.4.4.4.4.4.4.4" class="ltx_td ltx_align_center ltx_border_t">F@1 <math id="S4.T1.14.4.4.4.4.4.4.4.m1.1" class="ltx_Math" alttext="(\uparrow)" display="inline"><semantics id="S4.T1.14.4.4.4.4.4.4.4.m1.1a"><mrow id="S4.T1.14.4.4.4.4.4.4.4.m1.1.2.2"><mo stretchy="false" id="S4.T1.14.4.4.4.4.4.4.4.m1.1.2.2.1">(</mo><mo lspace="0em" rspace="0em" stretchy="false" id="S4.T1.14.4.4.4.4.4.4.4.m1.1.1" xref="S4.T1.14.4.4.4.4.4.4.4.m1.1.1.cmml">â†‘</mo><mo stretchy="false" id="S4.T1.14.4.4.4.4.4.4.4.m1.1.2.2.2">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.14.4.4.4.4.4.4.4.m1.1b"><ci id="S4.T1.14.4.4.4.4.4.4.4.m1.1.1.cmml" xref="S4.T1.14.4.4.4.4.4.4.4.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.14.4.4.4.4.4.4.4.m1.1c">(\uparrow)</annotation></semantics></math></span>
<span id="S4.T1.15.5.5.5.5.5.5.5" class="ltx_td ltx_align_center ltx_border_t">CD <math id="S4.T1.15.5.5.5.5.5.5.5.m1.1" class="ltx_Math" alttext="(\downarrow)" display="inline"><semantics id="S4.T1.15.5.5.5.5.5.5.5.m1.1a"><mrow id="S4.T1.15.5.5.5.5.5.5.5.m1.1.2.2"><mo stretchy="false" id="S4.T1.15.5.5.5.5.5.5.5.m1.1.2.2.1">(</mo><mo lspace="0em" rspace="0em" stretchy="false" id="S4.T1.15.5.5.5.5.5.5.5.m1.1.1" xref="S4.T1.15.5.5.5.5.5.5.5.m1.1.1.cmml">â†“</mo><mo stretchy="false" id="S4.T1.15.5.5.5.5.5.5.5.m1.1.2.2.2">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.15.5.5.5.5.5.5.5.m1.1b"><ci id="S4.T1.15.5.5.5.5.5.5.5.m1.1.1.cmml" xref="S4.T1.15.5.5.5.5.5.5.5.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.15.5.5.5.5.5.5.5.m1.1c">(\downarrow)</annotation></semantics></math></span>
<span id="S4.T1.16.6.6.6.6.6.6.6" class="ltx_td ltx_align_center ltx_border_t">F@1 <math id="S4.T1.16.6.6.6.6.6.6.6.m1.1" class="ltx_Math" alttext="(\uparrow)" display="inline"><semantics id="S4.T1.16.6.6.6.6.6.6.6.m1.1a"><mrow id="S4.T1.16.6.6.6.6.6.6.6.m1.1.2.2"><mo stretchy="false" id="S4.T1.16.6.6.6.6.6.6.6.m1.1.2.2.1">(</mo><mo lspace="0em" rspace="0em" stretchy="false" id="S4.T1.16.6.6.6.6.6.6.6.m1.1.1" xref="S4.T1.16.6.6.6.6.6.6.6.m1.1.1.cmml">â†‘</mo><mo stretchy="false" id="S4.T1.16.6.6.6.6.6.6.6.m1.1.2.2.2">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.16.6.6.6.6.6.6.6.m1.1b"><ci id="S4.T1.16.6.6.6.6.6.6.6.m1.1.1.cmml" xref="S4.T1.16.6.6.6.6.6.6.6.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.16.6.6.6.6.6.6.6.m1.1c">(\uparrow)</annotation></semantics></math></span></span>
<span id="S4.T1.18.8.8.8.8.8.10.2" class="ltx_tr">
<span id="S4.T1.18.8.8.8.8.8.10.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">SDF-SRN</span>
<span id="S4.T1.18.8.8.8.8.8.10.2.2" class="ltx_td ltx_align_center ltx_border_t">9.965</span>
<span id="S4.T1.18.8.8.8.8.8.10.2.3" class="ltx_td ltx_align_center ltx_border_t">0.404</span>
<span id="S4.T1.18.8.8.8.8.8.10.2.4" class="ltx_td ltx_align_center ltx_border_t">27.562</span>
<span id="S4.T1.18.8.8.8.8.8.10.2.5" class="ltx_td ltx_align_center ltx_border_t">0.283</span>
<span id="S4.T1.18.8.8.8.8.8.10.2.6" class="ltx_td ltx_align_center ltx_border_t">12.374</span>
<span id="S4.T1.18.8.8.8.8.8.10.2.7" class="ltx_td ltx_align_center ltx_border_t">0.459</span></span>
<span id="S4.T1.18.8.8.8.8.8.11.3" class="ltx_tr">
<span id="S4.T1.18.8.8.8.8.8.11.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">TARS-3D</span>
<span id="S4.T1.18.8.8.8.8.8.11.3.2" class="ltx_td ltx_align_center">10.175</span>
<span id="S4.T1.18.8.8.8.8.8.11.3.3" class="ltx_td ltx_align_center">0.412</span>
<span id="S4.T1.18.8.8.8.8.8.11.3.4" class="ltx_td ltx_align_center"><span id="S4.T1.18.8.8.8.8.8.11.3.4.1" class="ltx_text ltx_font_bold">28.823</span></span>
<span id="S4.T1.18.8.8.8.8.8.11.3.5" class="ltx_td ltx_align_center">0.272</span>
<span id="S4.T1.18.8.8.8.8.8.11.3.6" class="ltx_td ltx_align_center">11.302</span>
<span id="S4.T1.18.8.8.8.8.8.11.3.7" class="ltx_td ltx_align_center">0.418</span></span>
<span id="S4.T1.18.8.8.8.8.8.12.4" class="ltx_tr">
<span id="S4.T1.18.8.8.8.8.8.12.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">PoinTr</span>
<span id="S4.T1.18.8.8.8.8.8.12.4.2" class="ltx_td ltx_align_center">56.435</span>
<span id="S4.T1.18.8.8.8.8.8.12.4.3" class="ltx_td ltx_align_center">0.125</span>
<span id="S4.T1.18.8.8.8.8.8.12.4.4" class="ltx_td ltx_align_center">36.714</span>
<span id="S4.T1.18.8.8.8.8.8.12.4.5" class="ltx_td ltx_align_center">0.230</span>
<span id="S4.T1.18.8.8.8.8.8.12.4.6" class="ltx_td ltx_align_center">23.713</span>
<span id="S4.T1.18.8.8.8.8.8.12.4.7" class="ltx_td ltx_align_center">0.302</span></span>
<span id="S4.T1.18.8.8.8.8.8.13.5" class="ltx_tr">
<span id="S4.T1.18.8.8.8.8.8.13.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Ours</span>
<span id="S4.T1.18.8.8.8.8.8.13.5.2" class="ltx_td ltx_align_center"><span id="S4.T1.18.8.8.8.8.8.13.5.2.1" class="ltx_text ltx_font_bold">9.371</span></span>
<span id="S4.T1.18.8.8.8.8.8.13.5.3" class="ltx_td ltx_align_center"><span id="S4.T1.18.8.8.8.8.8.13.5.3.1" class="ltx_text ltx_font_bold">0.439</span></span>
<span id="S4.T1.18.8.8.8.8.8.13.5.4" class="ltx_td ltx_align_center">32.138</span>
<span id="S4.T1.18.8.8.8.8.8.13.5.5" class="ltx_td ltx_align_center"><span id="S4.T1.18.8.8.8.8.8.13.5.5.1" class="ltx_text ltx_font_bold">0.334</span></span>
<span id="S4.T1.18.8.8.8.8.8.13.5.6" class="ltx_td ltx_align_center"><span id="S4.T1.18.8.8.8.8.8.13.5.6.1" class="ltx_text ltx_font_bold">16.562</span></span>
<span id="S4.T1.18.8.8.8.8.8.13.5.7" class="ltx_td ltx_align_center"><span id="S4.T1.18.8.8.8.8.8.13.5.7.1" class="ltx_text ltx_font_bold">0.631</span></span></span>
<span id="S4.T1.17.7.7.7.7.7.7" class="ltx_tr">
<span id="S4.T1.17.7.7.7.7.7.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">PoinTr <sup id="S4.T1.17.7.7.7.7.7.7.1.1" class="ltx_sup">â€ </sup></span>
<span id="S4.T1.17.7.7.7.7.7.7.2" class="ltx_td ltx_align_center ltx_border_t">13.249</span>
<span id="S4.T1.17.7.7.7.7.7.7.3" class="ltx_td ltx_align_center ltx_border_t">0.264</span>
<span id="S4.T1.17.7.7.7.7.7.7.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.17.7.7.7.7.7.7.4.1" class="ltx_text ltx_font_bold">12.834</span></span>
<span id="S4.T1.17.7.7.7.7.7.7.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.17.7.7.7.7.7.7.5.1" class="ltx_text ltx_font_bold">0.352</span></span>
<span id="S4.T1.17.7.7.7.7.7.7.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.17.7.7.7.7.7.7.6.1" class="ltx_text ltx_font_bold">3.637</span></span>
<span id="S4.T1.17.7.7.7.7.7.7.7" class="ltx_td ltx_align_center ltx_border_t">0.685</span></span>
<span id="S4.T1.18.8.8.8.8.8.8" class="ltx_tr">
<span id="S4.T1.18.8.8.8.8.8.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Ours <sup id="S4.T1.18.8.8.8.8.8.8.1.1" class="ltx_sup">â€ </sup></span>
<span id="S4.T1.18.8.8.8.8.8.8.2" class="ltx_td ltx_align_center"><span id="S4.T1.18.8.8.8.8.8.8.2.1" class="ltx_text ltx_font_bold">6.181</span></span>
<span id="S4.T1.18.8.8.8.8.8.8.3" class="ltx_td ltx_align_center"><span id="S4.T1.18.8.8.8.8.8.8.3.1" class="ltx_text ltx_font_bold">0.497</span></span>
<span id="S4.T1.18.8.8.8.8.8.8.4" class="ltx_td ltx_align_center">27.292</span>
<span id="S4.T1.18.8.8.8.8.8.8.5" class="ltx_td ltx_align_center">0.343</span>
<span id="S4.T1.18.8.8.8.8.8.8.6" class="ltx_td ltx_align_center">4.495</span>
<span id="S4.T1.18.8.8.8.8.8.8.7" class="ltx_td ltx_align_center"><span id="S4.T1.18.8.8.8.8.8.8.7.1" class="ltx_text ltx_font_bold">0.768</span></span></span>
</span>
</span></span></span>
</span></span></span></p>
</figure>
<figure id="S4.F4" class="ltx_figure"><img src="/html/2302.12883/assets/x4.png" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="266" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Qualitative results on the Pascal3D+ (top) and Pix3D (bottom) datasets.</figcaption>
</figure>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS2.5.1.1" class="ltx_text">IV-B</span> </span><span id="S4.SS2.6.2" class="ltx_text ltx_font_italic">3D reconstruction on Shapenet with Occlusion</span>
</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">This section investigates how our method performs when the observed object is occluded. For this experiment, we generate occluded area on the RGB-D images and remove the occluded points from the Shapenet test data as presented in FigureÂ <a href="#S4.F3" title="Figure 3 â€£ IV Experiments â€£ 3D Surface Reconstruction in the Wild by Deforming Shape Priors from Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. To study the influence of a wide variety of occlusions, we use rectangular overlap regions and generate overlap ratios from 5 - 85%. We apply models trained on Shapenet on the occlusion task for all methods. We remove the occluded region from the RGB-D images and canonicalize the occluded, partial pointclouds, before finetuning the surface reconstruction to fit the available points. As shown in TableÂ <a href="#S4.T2" title="TABLE II â€£ IV-B 3D reconstruction on Shapenet with Occlusion â€£ IV Experiments â€£ 3D Surface Reconstruction in the Wild by Deforming Shape Priors from Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a>, our method outperforms all the baselines without access to ground truth camera poses despite not seeing any occluded data during training. Compared to the other baselines, PoinTr has a higher tolerance to occlusion. However, point cloud completion methods cannot predict the objectâ€™s surface.
Moreover, these methods usually predict the complete point cloud by adding predicted points to the input. Therefore, the predicted point clouds are not guaranteed to be uniformly distributed and can have a higher density around the input points, resulting in lower chamfer distance, as shown in FigureÂ <a href="#S4.F3" title="Figure 3 â€£ IV Experiments â€£ 3D Surface Reconstruction in the Wild by Deforming Shape Priors from Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. In contrast, our method does not have these drawbacks and can reconstruct the occluded surface by leveraging the learned category-level prior with high fidelity in terms of F-score.</p>
</div>
<figure id="S4.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE II: </span>3D reconstruction results on occluded data from the synthetic test set. We report chamfer distance (CD) <math id="S4.T2.6.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T2.6.m1.1b"><mo stretchy="false" id="S4.T2.6.m1.1.1" xref="S4.T2.6.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S4.T2.6.m1.1c"><ci id="S4.T2.6.m1.1.1.cmml" xref="S4.T2.6.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.6.m1.1d">\downarrow</annotation></semantics></math> and F-score at threshold <math id="S4.T2.7.m2.1" class="ltx_Math" alttext="0.01" display="inline"><semantics id="S4.T2.7.m2.1b"><mn id="S4.T2.7.m2.1.1" xref="S4.T2.7.m2.1.1.cmml">0.01</mn><annotation-xml encoding="MathML-Content" id="S4.T2.7.m2.1c"><cn type="float" id="S4.T2.7.m2.1.1.cmml" xref="S4.T2.7.m2.1.1">0.01</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.7.m2.1d">0.01</annotation></semantics></math> (F@<math id="S4.T2.8.m3.1" class="ltx_Math" alttext="1\%" display="inline"><semantics id="S4.T2.8.m3.1b"><mrow id="S4.T2.8.m3.1.1" xref="S4.T2.8.m3.1.1.cmml"><mn id="S4.T2.8.m3.1.1.2" xref="S4.T2.8.m3.1.1.2.cmml">1</mn><mo id="S4.T2.8.m3.1.1.1" xref="S4.T2.8.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.8.m3.1c"><apply id="S4.T2.8.m3.1.1.cmml" xref="S4.T2.8.m3.1.1"><csymbol cd="latexml" id="S4.T2.8.m3.1.1.1.cmml" xref="S4.T2.8.m3.1.1.1">percent</csymbol><cn type="integer" id="S4.T2.8.m3.1.1.2.cmml" xref="S4.T2.8.m3.1.1.2">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.8.m3.1d">1\%</annotation></semantics></math>)<math id="S4.T2.9.m4.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T2.9.m4.1b"><mo stretchy="false" id="S4.T2.9.m4.1.1" xref="S4.T2.9.m4.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S4.T2.9.m4.1c"><ci id="S4.T2.9.m4.1.1.cmml" xref="S4.T2.9.m4.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.9.m4.1d">\uparrow</annotation></semantics></math>. <sup id="S4.T2.20.1" class="ltx_sup">â€ </sup> with ground truth camera poses.</figcaption>
<p id="S4.T2.18" class="ltx_p"><span id="S4.T2.18.8" class="ltx_text">
<span id="S4.T2.18.8.8" class="ltx_inline-block ltx_transformed_outer" style="width:331.8pt;height:144pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<span id="S4.T2.18.8.8.8" class="ltx_p"><span id="S4.T2.18.8.8.8.8" class="ltx_text">

<span id="S4.T2.18.8.8.8.8.8" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<span class="ltx_tbody">
<span id="S4.T2.18.8.8.8.8.8.9.1" class="ltx_tr">
<span id="S4.T2.18.8.8.8.8.8.9.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt">Methods</span>
<span id="S4.T2.18.8.8.8.8.8.9.1.2" class="ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_2">Car</span>
<span id="S4.T2.18.8.8.8.8.8.9.1.3" class="ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_2">Chair</span>
<span id="S4.T2.18.8.8.8.8.8.9.1.4" class="ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_2">Plane</span></span>
<span id="S4.T2.16.6.6.6.6.6.6" class="ltx_tr">
<span id="S4.T2.16.6.6.6.6.6.6.7" class="ltx_td ltx_th ltx_th_row"></span>
<span id="S4.T2.11.1.1.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t">CD <math id="S4.T2.11.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="(\downarrow)" display="inline"><semantics id="S4.T2.11.1.1.1.1.1.1.1.m1.1a"><mrow id="S4.T2.11.1.1.1.1.1.1.1.m1.1.2.2"><mo stretchy="false" id="S4.T2.11.1.1.1.1.1.1.1.m1.1.2.2.1">(</mo><mo lspace="0em" rspace="0em" stretchy="false" id="S4.T2.11.1.1.1.1.1.1.1.m1.1.1" xref="S4.T2.11.1.1.1.1.1.1.1.m1.1.1.cmml">â†“</mo><mo stretchy="false" id="S4.T2.11.1.1.1.1.1.1.1.m1.1.2.2.2">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.11.1.1.1.1.1.1.1.m1.1b"><ci id="S4.T2.11.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S4.T2.11.1.1.1.1.1.1.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.11.1.1.1.1.1.1.1.m1.1c">(\downarrow)</annotation></semantics></math></span>
<span id="S4.T2.12.2.2.2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_t">F@1 <math id="S4.T2.12.2.2.2.2.2.2.2.m1.1" class="ltx_Math" alttext="(\uparrow)" display="inline"><semantics id="S4.T2.12.2.2.2.2.2.2.2.m1.1a"><mrow id="S4.T2.12.2.2.2.2.2.2.2.m1.1.2.2"><mo stretchy="false" id="S4.T2.12.2.2.2.2.2.2.2.m1.1.2.2.1">(</mo><mo lspace="0em" rspace="0em" stretchy="false" id="S4.T2.12.2.2.2.2.2.2.2.m1.1.1" xref="S4.T2.12.2.2.2.2.2.2.2.m1.1.1.cmml">â†‘</mo><mo stretchy="false" id="S4.T2.12.2.2.2.2.2.2.2.m1.1.2.2.2">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.12.2.2.2.2.2.2.2.m1.1b"><ci id="S4.T2.12.2.2.2.2.2.2.2.m1.1.1.cmml" xref="S4.T2.12.2.2.2.2.2.2.2.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.12.2.2.2.2.2.2.2.m1.1c">(\uparrow)</annotation></semantics></math></span>
<span id="S4.T2.13.3.3.3.3.3.3.3" class="ltx_td ltx_align_center ltx_border_t">CD <math id="S4.T2.13.3.3.3.3.3.3.3.m1.1" class="ltx_Math" alttext="(\downarrow)" display="inline"><semantics id="S4.T2.13.3.3.3.3.3.3.3.m1.1a"><mrow id="S4.T2.13.3.3.3.3.3.3.3.m1.1.2.2"><mo stretchy="false" id="S4.T2.13.3.3.3.3.3.3.3.m1.1.2.2.1">(</mo><mo lspace="0em" rspace="0em" stretchy="false" id="S4.T2.13.3.3.3.3.3.3.3.m1.1.1" xref="S4.T2.13.3.3.3.3.3.3.3.m1.1.1.cmml">â†“</mo><mo stretchy="false" id="S4.T2.13.3.3.3.3.3.3.3.m1.1.2.2.2">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.13.3.3.3.3.3.3.3.m1.1b"><ci id="S4.T2.13.3.3.3.3.3.3.3.m1.1.1.cmml" xref="S4.T2.13.3.3.3.3.3.3.3.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.13.3.3.3.3.3.3.3.m1.1c">(\downarrow)</annotation></semantics></math></span>
<span id="S4.T2.14.4.4.4.4.4.4.4" class="ltx_td ltx_align_center ltx_border_t">F@1 <math id="S4.T2.14.4.4.4.4.4.4.4.m1.1" class="ltx_Math" alttext="(\uparrow)" display="inline"><semantics id="S4.T2.14.4.4.4.4.4.4.4.m1.1a"><mrow id="S4.T2.14.4.4.4.4.4.4.4.m1.1.2.2"><mo stretchy="false" id="S4.T2.14.4.4.4.4.4.4.4.m1.1.2.2.1">(</mo><mo lspace="0em" rspace="0em" stretchy="false" id="S4.T2.14.4.4.4.4.4.4.4.m1.1.1" xref="S4.T2.14.4.4.4.4.4.4.4.m1.1.1.cmml">â†‘</mo><mo stretchy="false" id="S4.T2.14.4.4.4.4.4.4.4.m1.1.2.2.2">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.14.4.4.4.4.4.4.4.m1.1b"><ci id="S4.T2.14.4.4.4.4.4.4.4.m1.1.1.cmml" xref="S4.T2.14.4.4.4.4.4.4.4.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.14.4.4.4.4.4.4.4.m1.1c">(\uparrow)</annotation></semantics></math></span>
<span id="S4.T2.15.5.5.5.5.5.5.5" class="ltx_td ltx_align_center ltx_border_t">CD <math id="S4.T2.15.5.5.5.5.5.5.5.m1.1" class="ltx_Math" alttext="(\downarrow)" display="inline"><semantics id="S4.T2.15.5.5.5.5.5.5.5.m1.1a"><mrow id="S4.T2.15.5.5.5.5.5.5.5.m1.1.2.2"><mo stretchy="false" id="S4.T2.15.5.5.5.5.5.5.5.m1.1.2.2.1">(</mo><mo lspace="0em" rspace="0em" stretchy="false" id="S4.T2.15.5.5.5.5.5.5.5.m1.1.1" xref="S4.T2.15.5.5.5.5.5.5.5.m1.1.1.cmml">â†“</mo><mo stretchy="false" id="S4.T2.15.5.5.5.5.5.5.5.m1.1.2.2.2">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.15.5.5.5.5.5.5.5.m1.1b"><ci id="S4.T2.15.5.5.5.5.5.5.5.m1.1.1.cmml" xref="S4.T2.15.5.5.5.5.5.5.5.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.15.5.5.5.5.5.5.5.m1.1c">(\downarrow)</annotation></semantics></math></span>
<span id="S4.T2.16.6.6.6.6.6.6.6" class="ltx_td ltx_align_center ltx_border_t">F@1 <math id="S4.T2.16.6.6.6.6.6.6.6.m1.1" class="ltx_Math" alttext="(\uparrow)" display="inline"><semantics id="S4.T2.16.6.6.6.6.6.6.6.m1.1a"><mrow id="S4.T2.16.6.6.6.6.6.6.6.m1.1.2.2"><mo stretchy="false" id="S4.T2.16.6.6.6.6.6.6.6.m1.1.2.2.1">(</mo><mo lspace="0em" rspace="0em" stretchy="false" id="S4.T2.16.6.6.6.6.6.6.6.m1.1.1" xref="S4.T2.16.6.6.6.6.6.6.6.m1.1.1.cmml">â†‘</mo><mo stretchy="false" id="S4.T2.16.6.6.6.6.6.6.6.m1.1.2.2.2">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.16.6.6.6.6.6.6.6.m1.1b"><ci id="S4.T2.16.6.6.6.6.6.6.6.m1.1.1.cmml" xref="S4.T2.16.6.6.6.6.6.6.6.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.16.6.6.6.6.6.6.6.m1.1c">(\uparrow)</annotation></semantics></math></span></span>
<span id="S4.T2.18.8.8.8.8.8.10.2" class="ltx_tr">
<span id="S4.T2.18.8.8.8.8.8.10.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt">SDF-SRN</span>
<span id="S4.T2.18.8.8.8.8.8.10.2.2" class="ltx_td ltx_align_center ltx_border_tt">25.863</span>
<span id="S4.T2.18.8.8.8.8.8.10.2.3" class="ltx_td ltx_align_center ltx_border_tt">0.243</span>
<span id="S4.T2.18.8.8.8.8.8.10.2.4" class="ltx_td ltx_align_center ltx_border_tt">156.825</span>
<span id="S4.T2.18.8.8.8.8.8.10.2.5" class="ltx_td ltx_align_center ltx_border_tt">0.122</span>
<span id="S4.T2.18.8.8.8.8.8.10.2.6" class="ltx_td ltx_align_center ltx_border_tt">72.255</span>
<span id="S4.T2.18.8.8.8.8.8.10.2.7" class="ltx_td ltx_align_center ltx_border_tt">0.256</span></span>
<span id="S4.T2.18.8.8.8.8.8.11.3" class="ltx_tr">
<span id="S4.T2.18.8.8.8.8.8.11.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">TARS-3D</span>
<span id="S4.T2.18.8.8.8.8.8.11.3.2" class="ltx_td ltx_align_center">23.806</span>
<span id="S4.T2.18.8.8.8.8.8.11.3.3" class="ltx_td ltx_align_center">0.241</span>
<span id="S4.T2.18.8.8.8.8.8.11.3.4" class="ltx_td ltx_align_center">108.976</span>
<span id="S4.T2.18.8.8.8.8.8.11.3.5" class="ltx_td ltx_align_center">0.131</span>
<span id="S4.T2.18.8.8.8.8.8.11.3.6" class="ltx_td ltx_align_center">58.998</span>
<span id="S4.T2.18.8.8.8.8.8.11.3.7" class="ltx_td ltx_align_center">0.263</span></span>
<span id="S4.T2.18.8.8.8.8.8.12.4" class="ltx_tr">
<span id="S4.T2.18.8.8.8.8.8.12.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">PoinTr</span>
<span id="S4.T2.18.8.8.8.8.8.12.4.2" class="ltx_td ltx_align_center">59.292</span>
<span id="S4.T2.18.8.8.8.8.8.12.4.3" class="ltx_td ltx_align_center">0.1225</span>
<span id="S4.T2.18.8.8.8.8.8.12.4.4" class="ltx_td ltx_align_center">54.327</span>
<span id="S4.T2.18.8.8.8.8.8.12.4.5" class="ltx_td ltx_align_center">0.184</span>
<span id="S4.T2.18.8.8.8.8.8.12.4.6" class="ltx_td ltx_align_center">37.425</span>
<span id="S4.T2.18.8.8.8.8.8.12.4.7" class="ltx_td ltx_align_center">0.322</span></span>
<span id="S4.T2.18.8.8.8.8.8.13.5" class="ltx_tr">
<span id="S4.T2.18.8.8.8.8.8.13.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Ours</span>
<span id="S4.T2.18.8.8.8.8.8.13.5.2" class="ltx_td ltx_align_center"><span id="S4.T2.18.8.8.8.8.8.13.5.2.1" class="ltx_text ltx_font_bold">11.155</span></span>
<span id="S4.T2.18.8.8.8.8.8.13.5.3" class="ltx_td ltx_align_center"><span id="S4.T2.18.8.8.8.8.8.13.5.3.1" class="ltx_text ltx_font_bold">0.390</span></span>
<span id="S4.T2.18.8.8.8.8.8.13.5.4" class="ltx_td ltx_align_center"><span id="S4.T2.18.8.8.8.8.8.13.5.4.1" class="ltx_text ltx_font_bold">45.886</span></span>
<span id="S4.T2.18.8.8.8.8.8.13.5.5" class="ltx_td ltx_align_center"><span id="S4.T2.18.8.8.8.8.8.13.5.5.1" class="ltx_text ltx_font_bold">0.273</span></span>
<span id="S4.T2.18.8.8.8.8.8.13.5.6" class="ltx_td ltx_align_center"><span id="S4.T2.18.8.8.8.8.8.13.5.6.1" class="ltx_text ltx_font_bold">22.223</span></span>
<span id="S4.T2.18.8.8.8.8.8.13.5.7" class="ltx_td ltx_align_center"><span id="S4.T2.18.8.8.8.8.8.13.5.7.1" class="ltx_text ltx_font_bold">0.580</span></span></span>
<span id="S4.T2.17.7.7.7.7.7.7" class="ltx_tr">
<span id="S4.T2.17.7.7.7.7.7.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">PoinTr <sup id="S4.T2.17.7.7.7.7.7.7.1.1" class="ltx_sup">â€ </sup></span>
<span id="S4.T2.17.7.7.7.7.7.7.2" class="ltx_td ltx_align_center ltx_border_t">22.110</span>
<span id="S4.T2.17.7.7.7.7.7.7.3" class="ltx_td ltx_align_center ltx_border_t">0.208</span>
<span id="S4.T2.17.7.7.7.7.7.7.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.17.7.7.7.7.7.7.4.1" class="ltx_text ltx_font_bold">19.079</span></span>
<span id="S4.T2.17.7.7.7.7.7.7.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.17.7.7.7.7.7.7.5.1" class="ltx_text ltx_font_bold">0.297</span></span>
<span id="S4.T2.17.7.7.7.7.7.7.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.17.7.7.7.7.7.7.6.1" class="ltx_text ltx_font_bold">6.168</span></span>
<span id="S4.T2.17.7.7.7.7.7.7.7" class="ltx_td ltx_align_center ltx_border_t">0.601</span></span>
<span id="S4.T2.18.8.8.8.8.8.8" class="ltx_tr">
<span id="S4.T2.18.8.8.8.8.8.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Ours<sup id="S4.T2.18.8.8.8.8.8.8.1.1" class="ltx_sup">â€ </sup></span>
<span id="S4.T2.18.8.8.8.8.8.8.2" class="ltx_td ltx_align_center"><span id="S4.T2.18.8.8.8.8.8.8.2.1" class="ltx_text ltx_font_bold">6.457</span></span>
<span id="S4.T2.18.8.8.8.8.8.8.3" class="ltx_td ltx_align_center"><span id="S4.T2.18.8.8.8.8.8.8.3.1" class="ltx_text ltx_font_bold">0.497</span></span>
<span id="S4.T2.18.8.8.8.8.8.8.4" class="ltx_td ltx_align_center">35.972</span>
<span id="S4.T2.18.8.8.8.8.8.8.5" class="ltx_td ltx_align_center"><span id="S4.T2.18.8.8.8.8.8.8.5.1" class="ltx_text ltx_font_bold">0.297</span></span>
<span id="S4.T2.18.8.8.8.8.8.8.6" class="ltx_td ltx_align_center">15.725</span>
<span id="S4.T2.18.8.8.8.8.8.8.7" class="ltx_td ltx_align_center"><span id="S4.T2.18.8.8.8.8.8.8.7.1" class="ltx_text ltx_font_bold">0.654</span></span></span>
</span>
</span></span></span>
</span></span></span></p>
</figure>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS3.5.1.1" class="ltx_text">IV-C</span> </span><span id="S4.SS3.6.2" class="ltx_text ltx_font_italic">3D reconstruction on Pascal3D+ and Pix3D</span>
</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">For this experiment, we test the generalization capabilities of our approach. We directly apply our model trained on Shapenet for reconstructing Pascal3D+ objects. TARS-3D and PoinTr also apply network weights trained on Shapenet to this task, while SDF-SRN is trained directly on the Pascal3D+ dataset.
As shown in TableÂ <a href="#S4.T3" title="TABLE III â€£ IV-C 3D reconstruction on Pascal3D+ and Pix3D â€£ IV Experiments â€£ 3D Surface Reconstruction in the Wild by Deforming Shape Priors from Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a>, our method again outperforms the other surface reconstruction methods without access to ground truth camera poses. FigureÂ <a href="#S4.F4" title="Figure 4 â€£ IV-A 3D Reconstruction on synthetic Shapenet data â€£ IV Experiments â€£ 3D Surface Reconstruction in the Wild by Deforming Shape Priors from Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows that our method generates reasonable outputs.</p>
</div>
<figure id="S4.T3" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE III: </span>3D reconstruction results on the Pascal3D+ and Pix3D dataset. We report chamfer distance (CD) <math id="S4.T3.6.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S4.T3.6.m1.1b"><mo stretchy="false" id="S4.T3.6.m1.1.1" xref="S4.T3.6.m1.1.1.cmml">â†“</mo><annotation-xml encoding="MathML-Content" id="S4.T3.6.m1.1c"><ci id="S4.T3.6.m1.1.1.cmml" xref="S4.T3.6.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.6.m1.1d">\downarrow</annotation></semantics></math> and F-score at threshold <math id="S4.T3.7.m2.1" class="ltx_Math" alttext="1\%" display="inline"><semantics id="S4.T3.7.m2.1b"><mrow id="S4.T3.7.m2.1.1" xref="S4.T3.7.m2.1.1.cmml"><mn id="S4.T3.7.m2.1.1.2" xref="S4.T3.7.m2.1.1.2.cmml">1</mn><mo id="S4.T3.7.m2.1.1.1" xref="S4.T3.7.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.7.m2.1c"><apply id="S4.T3.7.m2.1.1.cmml" xref="S4.T3.7.m2.1.1"><csymbol cd="latexml" id="S4.T3.7.m2.1.1.1.cmml" xref="S4.T3.7.m2.1.1.1">percent</csymbol><cn type="integer" id="S4.T3.7.m2.1.1.2.cmml" xref="S4.T3.7.m2.1.1.2">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.7.m2.1d">1\%</annotation></semantics></math> (F@<math id="S4.T3.8.m3.1" class="ltx_Math" alttext="1\%" display="inline"><semantics id="S4.T3.8.m3.1b"><mrow id="S4.T3.8.m3.1.1" xref="S4.T3.8.m3.1.1.cmml"><mn id="S4.T3.8.m3.1.1.2" xref="S4.T3.8.m3.1.1.2.cmml">1</mn><mo id="S4.T3.8.m3.1.1.1" xref="S4.T3.8.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.8.m3.1c"><apply id="S4.T3.8.m3.1.1.cmml" xref="S4.T3.8.m3.1.1"><csymbol cd="latexml" id="S4.T3.8.m3.1.1.1.cmml" xref="S4.T3.8.m3.1.1.1">percent</csymbol><cn type="integer" id="S4.T3.8.m3.1.1.2.cmml" xref="S4.T3.8.m3.1.1.2">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.8.m3.1d">1\%</annotation></semantics></math>)<math id="S4.T3.9.m4.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T3.9.m4.1b"><mo stretchy="false" id="S4.T3.9.m4.1.1" xref="S4.T3.9.m4.1.1.cmml">â†‘</mo><annotation-xml encoding="MathML-Content" id="S4.T3.9.m4.1c"><ci id="S4.T3.9.m4.1.1.cmml" xref="S4.T3.9.m4.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.9.m4.1d">\uparrow</annotation></semantics></math>. <sup id="S4.T3.22.1" class="ltx_sup">â€ </sup> with ground truth camera poses.</figcaption>
<p id="S4.T3.20" class="ltx_p"><span id="S4.T3.20.10" class="ltx_text">
<span id="S4.T3.20.10.10" class="ltx_inline-block ltx_transformed_outer" style="width:424.0pt;height:162pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<span id="S4.T3.20.10.10.10" class="ltx_p"><span id="S4.T3.20.10.10.10.10" class="ltx_text">

<span id="S4.T3.20.10.10.10.10.10" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<span class="ltx_tbody">
<span id="S4.T3.20.10.10.10.10.10.11.1" class="ltx_tr">
<span id="S4.T3.20.10.10.10.10.10.11.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_tt"></span>
<span id="S4.T3.20.10.10.10.10.10.11.1.2" class="ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_6">Pascal3D+</span>
<span id="S4.T3.20.10.10.10.10.10.11.1.3" class="ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_2">Pix3D</span></span>
<span id="S4.T3.20.10.10.10.10.10.12.2" class="ltx_tr">
<span id="S4.T3.20.10.10.10.10.10.12.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Methods</span>
<span id="S4.T3.20.10.10.10.10.10.12.2.2" class="ltx_td ltx_align_center ltx_colspan ltx_colspan_2">Car</span>
<span id="S4.T3.20.10.10.10.10.10.12.2.3" class="ltx_td ltx_align_center ltx_colspan ltx_colspan_2">Chair</span>
<span id="S4.T3.20.10.10.10.10.10.12.2.4" class="ltx_td ltx_align_center ltx_colspan ltx_colspan_2">Plane</span>
<span id="S4.T3.20.10.10.10.10.10.12.2.5" class="ltx_td ltx_align_center ltx_colspan ltx_colspan_2">Chair</span></span>
<span id="S4.T3.18.8.8.8.8.8.8" class="ltx_tr">
<span id="S4.T3.18.8.8.8.8.8.8.9" class="ltx_td ltx_th ltx_th_row"></span>
<span id="S4.T3.11.1.1.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t">CD <math id="S4.T3.11.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="(\downarrow)" display="inline"><semantics id="S4.T3.11.1.1.1.1.1.1.1.m1.1a"><mrow id="S4.T3.11.1.1.1.1.1.1.1.m1.1.2.2"><mo stretchy="false" id="S4.T3.11.1.1.1.1.1.1.1.m1.1.2.2.1">(</mo><mo lspace="0em" rspace="0em" stretchy="false" id="S4.T3.11.1.1.1.1.1.1.1.m1.1.1" xref="S4.T3.11.1.1.1.1.1.1.1.m1.1.1.cmml">â†“</mo><mo stretchy="false" id="S4.T3.11.1.1.1.1.1.1.1.m1.1.2.2.2">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.11.1.1.1.1.1.1.1.m1.1b"><ci id="S4.T3.11.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S4.T3.11.1.1.1.1.1.1.1.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.11.1.1.1.1.1.1.1.m1.1c">(\downarrow)</annotation></semantics></math></span>
<span id="S4.T3.12.2.2.2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_t">F@1 <math id="S4.T3.12.2.2.2.2.2.2.2.m1.1" class="ltx_Math" alttext="(\uparrow)" display="inline"><semantics id="S4.T3.12.2.2.2.2.2.2.2.m1.1a"><mrow id="S4.T3.12.2.2.2.2.2.2.2.m1.1.2.2"><mo stretchy="false" id="S4.T3.12.2.2.2.2.2.2.2.m1.1.2.2.1">(</mo><mo lspace="0em" rspace="0em" stretchy="false" id="S4.T3.12.2.2.2.2.2.2.2.m1.1.1" xref="S4.T3.12.2.2.2.2.2.2.2.m1.1.1.cmml">â†‘</mo><mo stretchy="false" id="S4.T3.12.2.2.2.2.2.2.2.m1.1.2.2.2">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.12.2.2.2.2.2.2.2.m1.1b"><ci id="S4.T3.12.2.2.2.2.2.2.2.m1.1.1.cmml" xref="S4.T3.12.2.2.2.2.2.2.2.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.12.2.2.2.2.2.2.2.m1.1c">(\uparrow)</annotation></semantics></math></span>
<span id="S4.T3.13.3.3.3.3.3.3.3" class="ltx_td ltx_align_center ltx_border_t">CD <math id="S4.T3.13.3.3.3.3.3.3.3.m1.1" class="ltx_Math" alttext="(\downarrow)" display="inline"><semantics id="S4.T3.13.3.3.3.3.3.3.3.m1.1a"><mrow id="S4.T3.13.3.3.3.3.3.3.3.m1.1.2.2"><mo stretchy="false" id="S4.T3.13.3.3.3.3.3.3.3.m1.1.2.2.1">(</mo><mo lspace="0em" rspace="0em" stretchy="false" id="S4.T3.13.3.3.3.3.3.3.3.m1.1.1" xref="S4.T3.13.3.3.3.3.3.3.3.m1.1.1.cmml">â†“</mo><mo stretchy="false" id="S4.T3.13.3.3.3.3.3.3.3.m1.1.2.2.2">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.13.3.3.3.3.3.3.3.m1.1b"><ci id="S4.T3.13.3.3.3.3.3.3.3.m1.1.1.cmml" xref="S4.T3.13.3.3.3.3.3.3.3.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.13.3.3.3.3.3.3.3.m1.1c">(\downarrow)</annotation></semantics></math></span>
<span id="S4.T3.14.4.4.4.4.4.4.4" class="ltx_td ltx_align_center ltx_border_t">F@1 <math id="S4.T3.14.4.4.4.4.4.4.4.m1.1" class="ltx_Math" alttext="(\uparrow)" display="inline"><semantics id="S4.T3.14.4.4.4.4.4.4.4.m1.1a"><mrow id="S4.T3.14.4.4.4.4.4.4.4.m1.1.2.2"><mo stretchy="false" id="S4.T3.14.4.4.4.4.4.4.4.m1.1.2.2.1">(</mo><mo lspace="0em" rspace="0em" stretchy="false" id="S4.T3.14.4.4.4.4.4.4.4.m1.1.1" xref="S4.T3.14.4.4.4.4.4.4.4.m1.1.1.cmml">â†‘</mo><mo stretchy="false" id="S4.T3.14.4.4.4.4.4.4.4.m1.1.2.2.2">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.14.4.4.4.4.4.4.4.m1.1b"><ci id="S4.T3.14.4.4.4.4.4.4.4.m1.1.1.cmml" xref="S4.T3.14.4.4.4.4.4.4.4.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.14.4.4.4.4.4.4.4.m1.1c">(\uparrow)</annotation></semantics></math></span>
<span id="S4.T3.15.5.5.5.5.5.5.5" class="ltx_td ltx_align_center ltx_border_t">CD <math id="S4.T3.15.5.5.5.5.5.5.5.m1.1" class="ltx_Math" alttext="(\downarrow)" display="inline"><semantics id="S4.T3.15.5.5.5.5.5.5.5.m1.1a"><mrow id="S4.T3.15.5.5.5.5.5.5.5.m1.1.2.2"><mo stretchy="false" id="S4.T3.15.5.5.5.5.5.5.5.m1.1.2.2.1">(</mo><mo lspace="0em" rspace="0em" stretchy="false" id="S4.T3.15.5.5.5.5.5.5.5.m1.1.1" xref="S4.T3.15.5.5.5.5.5.5.5.m1.1.1.cmml">â†“</mo><mo stretchy="false" id="S4.T3.15.5.5.5.5.5.5.5.m1.1.2.2.2">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.15.5.5.5.5.5.5.5.m1.1b"><ci id="S4.T3.15.5.5.5.5.5.5.5.m1.1.1.cmml" xref="S4.T3.15.5.5.5.5.5.5.5.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.15.5.5.5.5.5.5.5.m1.1c">(\downarrow)</annotation></semantics></math></span>
<span id="S4.T3.16.6.6.6.6.6.6.6" class="ltx_td ltx_align_center ltx_border_t">F@1 <math id="S4.T3.16.6.6.6.6.6.6.6.m1.1" class="ltx_Math" alttext="(\uparrow)" display="inline"><semantics id="S4.T3.16.6.6.6.6.6.6.6.m1.1a"><mrow id="S4.T3.16.6.6.6.6.6.6.6.m1.1.2.2"><mo stretchy="false" id="S4.T3.16.6.6.6.6.6.6.6.m1.1.2.2.1">(</mo><mo lspace="0em" rspace="0em" stretchy="false" id="S4.T3.16.6.6.6.6.6.6.6.m1.1.1" xref="S4.T3.16.6.6.6.6.6.6.6.m1.1.1.cmml">â†‘</mo><mo stretchy="false" id="S4.T3.16.6.6.6.6.6.6.6.m1.1.2.2.2">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.16.6.6.6.6.6.6.6.m1.1b"><ci id="S4.T3.16.6.6.6.6.6.6.6.m1.1.1.cmml" xref="S4.T3.16.6.6.6.6.6.6.6.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.16.6.6.6.6.6.6.6.m1.1c">(\uparrow)</annotation></semantics></math></span>
<span id="S4.T3.17.7.7.7.7.7.7.7" class="ltx_td ltx_align_center ltx_border_t">CD <math id="S4.T3.17.7.7.7.7.7.7.7.m1.1" class="ltx_Math" alttext="(\downarrow)" display="inline"><semantics id="S4.T3.17.7.7.7.7.7.7.7.m1.1a"><mrow id="S4.T3.17.7.7.7.7.7.7.7.m1.1.2.2"><mo stretchy="false" id="S4.T3.17.7.7.7.7.7.7.7.m1.1.2.2.1">(</mo><mo lspace="0em" rspace="0em" stretchy="false" id="S4.T3.17.7.7.7.7.7.7.7.m1.1.1" xref="S4.T3.17.7.7.7.7.7.7.7.m1.1.1.cmml">â†“</mo><mo stretchy="false" id="S4.T3.17.7.7.7.7.7.7.7.m1.1.2.2.2">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.17.7.7.7.7.7.7.7.m1.1b"><ci id="S4.T3.17.7.7.7.7.7.7.7.m1.1.1.cmml" xref="S4.T3.17.7.7.7.7.7.7.7.m1.1.1">â†“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.17.7.7.7.7.7.7.7.m1.1c">(\downarrow)</annotation></semantics></math></span>
<span id="S4.T3.18.8.8.8.8.8.8.8" class="ltx_td ltx_align_center ltx_border_t">F@1 <math id="S4.T3.18.8.8.8.8.8.8.8.m1.1" class="ltx_Math" alttext="(\uparrow)" display="inline"><semantics id="S4.T3.18.8.8.8.8.8.8.8.m1.1a"><mrow id="S4.T3.18.8.8.8.8.8.8.8.m1.1.2.2"><mo stretchy="false" id="S4.T3.18.8.8.8.8.8.8.8.m1.1.2.2.1">(</mo><mo lspace="0em" rspace="0em" stretchy="false" id="S4.T3.18.8.8.8.8.8.8.8.m1.1.1" xref="S4.T3.18.8.8.8.8.8.8.8.m1.1.1.cmml">â†‘</mo><mo stretchy="false" id="S4.T3.18.8.8.8.8.8.8.8.m1.1.2.2.2">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T3.18.8.8.8.8.8.8.8.m1.1b"><ci id="S4.T3.18.8.8.8.8.8.8.8.m1.1.1.cmml" xref="S4.T3.18.8.8.8.8.8.8.8.m1.1.1">â†‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.18.8.8.8.8.8.8.8.m1.1c">(\uparrow)</annotation></semantics></math></span></span>
<span id="S4.T3.20.10.10.10.10.10.13.3" class="ltx_tr">
<span id="S4.T3.20.10.10.10.10.10.13.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">SDF-SRN</span>
<span id="S4.T3.20.10.10.10.10.10.13.3.2" class="ltx_td ltx_align_center ltx_border_t">16.740</span>
<span id="S4.T3.20.10.10.10.10.10.13.3.3" class="ltx_td ltx_align_center ltx_border_t">0.245</span>
<span id="S4.T3.20.10.10.10.10.10.13.3.4" class="ltx_td ltx_align_center ltx_border_t">24.374</span>
<span id="S4.T3.20.10.10.10.10.10.13.3.5" class="ltx_td ltx_align_center ltx_border_t">0.216</span>
<span id="S4.T3.20.10.10.10.10.10.13.3.6" class="ltx_td ltx_align_center ltx_border_t">29.7457</span>
<span id="S4.T3.20.10.10.10.10.10.13.3.7" class="ltx_td ltx_align_center ltx_border_t">0.169</span>
<span id="S4.T3.20.10.10.10.10.10.13.3.8" class="ltx_td ltx_align_center ltx_border_t">60.432</span>
<span id="S4.T3.20.10.10.10.10.10.13.3.9" class="ltx_td ltx_align_center ltx_border_t">0.158</span></span>
<span id="S4.T3.20.10.10.10.10.10.14.4" class="ltx_tr">
<span id="S4.T3.20.10.10.10.10.10.14.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">TARS-3D</span>
<span id="S4.T3.20.10.10.10.10.10.14.4.2" class="ltx_td ltx_align_center">19.129</span>
<span id="S4.T3.20.10.10.10.10.10.14.4.3" class="ltx_td ltx_align_center">0.2427</span>
<span id="S4.T3.20.10.10.10.10.10.14.4.4" class="ltx_td ltx_align_center">79.8922</span>
<span id="S4.T3.20.10.10.10.10.10.14.4.5" class="ltx_td ltx_align_center">0.1577</span>
<span id="S4.T3.20.10.10.10.10.10.14.4.6" class="ltx_td ltx_align_center">83.866</span>
<span id="S4.T3.20.10.10.10.10.10.14.4.7" class="ltx_td ltx_align_center">0.140</span>
<span id="S4.T3.20.10.10.10.10.10.14.4.8" class="ltx_td ltx_align_center">55.555</span>
<span id="S4.T3.20.10.10.10.10.10.14.4.9" class="ltx_td ltx_align_center">0.197</span></span>
<span id="S4.T3.20.10.10.10.10.10.15.5" class="ltx_tr">
<span id="S4.T3.20.10.10.10.10.10.15.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">PoinTr</span>
<span id="S4.T3.20.10.10.10.10.10.15.5.2" class="ltx_td ltx_align_center">80.896</span>
<span id="S4.T3.20.10.10.10.10.10.15.5.3" class="ltx_td ltx_align_center">0.064</span>
<span id="S4.T3.20.10.10.10.10.10.15.5.4" class="ltx_td ltx_align_center">21.251</span>
<span id="S4.T3.20.10.10.10.10.10.15.5.5" class="ltx_td ltx_align_center">0.216</span>
<span id="S4.T3.20.10.10.10.10.10.15.5.6" class="ltx_td ltx_align_center"><span id="S4.T3.20.10.10.10.10.10.15.5.6.1" class="ltx_text ltx_font_bold">35.095</span></span>
<span id="S4.T3.20.10.10.10.10.10.15.5.7" class="ltx_td ltx_align_center">0.231</span>
<span id="S4.T3.20.10.10.10.10.10.15.5.8" class="ltx_td ltx_align_center"><span id="S4.T3.20.10.10.10.10.10.15.5.8.1" class="ltx_text ltx_font_bold">35.527</span></span>
<span id="S4.T3.20.10.10.10.10.10.15.5.9" class="ltx_td ltx_align_center">0.283</span></span>
<span id="S4.T3.20.10.10.10.10.10.16.6" class="ltx_tr">
<span id="S4.T3.20.10.10.10.10.10.16.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Ours</span>
<span id="S4.T3.20.10.10.10.10.10.16.6.2" class="ltx_td ltx_align_center"><span id="S4.T3.20.10.10.10.10.10.16.6.2.1" class="ltx_text ltx_font_bold">15.516</span></span>
<span id="S4.T3.20.10.10.10.10.10.16.6.3" class="ltx_td ltx_align_center"><span id="S4.T3.20.10.10.10.10.10.16.6.3.1" class="ltx_text ltx_font_bold">0.283</span></span>
<span id="S4.T3.20.10.10.10.10.10.16.6.4" class="ltx_td ltx_align_center"><span id="S4.T3.20.10.10.10.10.10.16.6.4.1" class="ltx_text ltx_font_bold">17.328</span></span>
<span id="S4.T3.20.10.10.10.10.10.16.6.5" class="ltx_td ltx_align_center"><span id="S4.T3.20.10.10.10.10.10.16.6.5.1" class="ltx_text ltx_font_bold">0.275</span></span>
<span id="S4.T3.20.10.10.10.10.10.16.6.6" class="ltx_td ltx_align_center">54.849</span>
<span id="S4.T3.20.10.10.10.10.10.16.6.7" class="ltx_td ltx_align_center"><span id="S4.T3.20.10.10.10.10.10.16.6.7.1" class="ltx_text ltx_font_bold">0.276</span></span>
<span id="S4.T3.20.10.10.10.10.10.16.6.8" class="ltx_td ltx_align_center">35.729</span>
<span id="S4.T3.20.10.10.10.10.10.16.6.9" class="ltx_td ltx_align_center"><span id="S4.T3.20.10.10.10.10.10.16.6.9.1" class="ltx_text ltx_font_bold">0.335</span></span></span>
<span id="S4.T3.19.9.9.9.9.9.9" class="ltx_tr">
<span id="S4.T3.19.9.9.9.9.9.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">PoinTr<sup id="S4.T3.19.9.9.9.9.9.9.1.1" class="ltx_sup">â€ </sup></span>
<span id="S4.T3.19.9.9.9.9.9.9.2" class="ltx_td ltx_align_center ltx_border_t">17.859</span>
<span id="S4.T3.19.9.9.9.9.9.9.3" class="ltx_td ltx_align_center ltx_border_t">0.221</span>
<span id="S4.T3.19.9.9.9.9.9.9.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.19.9.9.9.9.9.9.4.1" class="ltx_text ltx_font_bold">11.769</span></span>
<span id="S4.T3.19.9.9.9.9.9.9.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.19.9.9.9.9.9.9.5.1" class="ltx_text ltx_font_bold">0.302</span></span>
<span id="S4.T3.19.9.9.9.9.9.9.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.19.9.9.9.9.9.9.6.1" class="ltx_text ltx_font_bold">4.701</span></span>
<span id="S4.T3.19.9.9.9.9.9.9.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.19.9.9.9.9.9.9.7.1" class="ltx_text ltx_font_bold">0.525</span></span>
<span id="S4.T3.19.9.9.9.9.9.9.8" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.19.9.9.9.9.9.9.8.1" class="ltx_text ltx_font_bold">13.092</span></span>
<span id="S4.T3.19.9.9.9.9.9.9.9" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T3.19.9.9.9.9.9.9.9.1" class="ltx_text ltx_font_bold">0.377</span></span></span>
<span id="S4.T3.20.10.10.10.10.10.10" class="ltx_tr">
<span id="S4.T3.20.10.10.10.10.10.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Ours<sup id="S4.T3.20.10.10.10.10.10.10.1.1" class="ltx_sup">â€ </sup></span>
<span id="S4.T3.20.10.10.10.10.10.10.2" class="ltx_td ltx_align_center"><span id="S4.T3.20.10.10.10.10.10.10.2.1" class="ltx_text ltx_font_bold">13.370</span></span>
<span id="S4.T3.20.10.10.10.10.10.10.3" class="ltx_td ltx_align_center"><span id="S4.T3.20.10.10.10.10.10.10.3.1" class="ltx_text ltx_font_bold">0.302</span></span>
<span id="S4.T3.20.10.10.10.10.10.10.4" class="ltx_td ltx_align_center">16.804</span>
<span id="S4.T3.20.10.10.10.10.10.10.5" class="ltx_td ltx_align_center">0.274</span>
<span id="S4.T3.20.10.10.10.10.10.10.6" class="ltx_td ltx_align_center">54.286</span>
<span id="S4.T3.20.10.10.10.10.10.10.7" class="ltx_td ltx_align_center">0.289</span>
<span id="S4.T3.20.10.10.10.10.10.10.8" class="ltx_td ltx_align_center">31.165</span>
<span id="S4.T3.20.10.10.10.10.10.10.9" class="ltx_td ltx_align_center">0.335</span></span>
</span>
</span></span></span>
</span></span></span></p>
</figure>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.1" class="ltx_p">We further test our method on another chair dataset, namely the chair category of the Pix3D dataset. As shown in TableÂ <a href="#S4.T3" title="TABLE III â€£ IV-C 3D reconstruction on Pascal3D+ and Pix3D â€£ IV Experiments â€£ 3D Surface Reconstruction in the Wild by Deforming Shape Priors from Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a>, our method outperforms the baselines. PoinTr again achieves a lower chamfer distance, which does not fully represent the reconstruction quality. As shown in FigureÂ <a href="#S4.F4" title="Figure 4 â€£ IV-A 3D Reconstruction on synthetic Shapenet data â€£ IV Experiments â€£ 3D Surface Reconstruction in the Wild by Deforming Shape Priors from Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, PoinTr generates point clouds that are not uniformly distributed while our method predicts smooth surfaces.</p>
</div>
<figure id="S4.F5" class="ltx_figure"><img src="/html/2302.12883/assets/x5.png" id="S4.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="239" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Qualitative results on the DDAD dataset.</figcaption>
</figure>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS4.5.1.1" class="ltx_text">IV-D</span> </span><span id="S4.SS4.6.2" class="ltx_text ltx_font_italic">Ablation Study and Failure Cases</span>
</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p">In this section, we conduct an ablation study to asses the importance of optimizing the pose during inference. The main results are shown in TableÂ <a href="#S4.T4" title="TABLE IV â€£ IV-D Ablation Study and Failure Cases â€£ IV Experiments â€£ 3D Surface Reconstruction in the Wild by Deforming Shape Priors from Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV</span></a>. On the left, we show the ground truth mesh overlaid with the partial input points with pose optimization (blue) and without (green). We can see a noticeable reduction in F1 scores and a significant reduction in the reconstruction quality. The chamfer score difference between reconstruction methods across the dataset is slight, though, confirmingÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref">51</a>]</cite> in that chamfer distance is not an ideal metric for 3D reconstruction. This ablation study shows that canonical reconstruction methods are sensitive to deviations in the estimated canonical coordinate frame. This result is also confirmed by the poor performance of PoinTr on input points where the estimated canonical coordinate frame is off (see TablesÂ <a href="#S4.T1" title="TABLE I â€£ IV-A 3D Reconstruction on synthetic Shapenet data â€£ IV Experiments â€£ 3D Surface Reconstruction in the Wild by Deforming Shape Priors from Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a> and Â <a href="#S4.T3" title="TABLE III â€£ IV-C 3D reconstruction on Pascal3D+ and Pix3D â€£ IV Experiments â€£ 3D Surface Reconstruction in the Wild by Deforming Shape Priors from Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a>).</p>
</div>
<figure id="S4.T4" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE IV: </span>Ablation of our method with and without pose optimization during inference. Left, we show the ground truth mesh overlayed with the optimized and non-optimized pose. We show the resulting optimized surfaces with and without pose optimization in the middle and right.</figcaption>
<p id="S4.T4.3" class="ltx_p ltx_align_center"><span id="S4.T4.3.3" class="ltx_text">
<span id="S4.T4.3.3.3" class="ltx_inline-block ltx_transformed_outer" style="width:329.2pt;height:146.1pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<span id="S4.T4.3.3.3.3" class="ltx_p"><span id="S4.T4.3.3.3.3.3" class="ltx_text">

<span id="S4.T4.3.3.3.3.3.3" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<span class="ltx_thead">
<span id="S4.T4.3.3.3.3.3.3.4.1" class="ltx_tr">
<span id="S4.T4.3.3.3.3.3.3.4.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt">Pose optim.</span>
<span id="S4.T4.3.3.3.3.3.3.4.1.2" class="ltx_td ltx_th ltx_th_column ltx_border_r ltx_border_tt"></span>
<span id="S4.T4.3.3.3.3.3.3.4.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">âœ“</span></span>
</span>
<span class="ltx_tbody">
<span id="S4.T4.3.3.3.3.3.3.5.1" class="ltx_tr">
<span id="S4.T4.3.3.3.3.3.3.5.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">CD</span>
<span id="S4.T4.3.3.3.3.3.3.5.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">23.008</span>
<span id="S4.T4.3.3.3.3.3.3.5.1.3" class="ltx_td ltx_align_center ltx_border_t">22.223</span></span>
<span id="S4.T4.3.3.3.3.3.3.6.2" class="ltx_tr">
<span id="S4.T4.3.3.3.3.3.3.6.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">F1</span>
<span id="S4.T4.3.3.3.3.3.3.6.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.313</span>
<span id="S4.T4.3.3.3.3.3.3.6.2.3" class="ltx_td ltx_align_center ltx_border_t">0.580</span></span>
<span id="S4.T4.3.3.3.3.3.3.3" class="ltx_tr">
<span id="S4.T4.1.1.1.1.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t">Shape <span id="S4.T4.1.1.1.1.1.1.1.1.1" class="ltx_text" style="position:relative; bottom:0.0pt;"><img src="/html/2302.12883/assets/x6.png" id="S4.T4.1.1.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="92" height="92" alt="[Uncaptioned image]"></span></span>
<span id="S4.T4.2.2.2.2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t"><span id="S4.T4.2.2.2.2.2.2.2.2.1" class="ltx_text" style="position:relative; bottom:0.0pt;"><img src="/html/2302.12883/assets/x7.png" id="S4.T4.2.2.2.2.2.2.2.2.1.g1" class="ltx_graphics ltx_img_square" width="92" height="92" alt="[Uncaptioned image]"></span></span>
<span id="S4.T4.3.3.3.3.3.3.3.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S4.T4.3.3.3.3.3.3.3.3.1" class="ltx_text" style="position:relative; bottom:0.0pt;"><img src="/html/2302.12883/assets/x8.png" id="S4.T4.3.3.3.3.3.3.3.3.1.g1" class="ltx_graphics ltx_img_square" width="92" height="92" alt="[Uncaptioned image]"></span></span></span>
</span>
</span></span></span>
</span></span></span></p>
</figure>
</section>
<section id="S4.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS5.5.1.1" class="ltx_text">IV-E</span> </span><span id="S4.SS5.6.2" class="ltx_text ltx_font_italic">3D reconstruction on real-world noisy scans</span>
</h3>

<div id="S4.SS5.p1" class="ltx_para">
<p id="S4.SS5.p1.1" class="ltx_p">Finally, we apply our method trained on Shapenet directly to real-world noisy LIDAR scans. To demonstrate our tolerance to noise in the point clouds, we test our method on an autonomous driving benchmark DDADÂ <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>. DDAD contains urban scenes scanned using LiDARs mounted on self-driving cars. To showcase our method, we extract frames that include other driving cars and crop the LiDAR scans of other cars with masked images. Finally, these noisy LiDAR scans are fed to the pose estimation module and our deformation field to reconstruct the surfaces. Since DDAD does not contain ground truth CAD models, we present the qualitative results in FigureÂ <a href="#S4.F5" title="Figure 5 â€£ IV-C 3D reconstruction on Pascal3D+ and Pix3D â€£ IV Experiments â€£ 3D Surface Reconstruction in the Wild by Deforming Shape Priors from Synthetic Data" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>. Note that our method does not have access to the image but only the noisy LiDAR point clouds. Despite large portions of missing parts and the noise in the LiDAR scans, our method can still reconstruct reasonable car surfaces without access to ground truth camera poses.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Conclusion and future work</span>
</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">We introduced a new method for complete 3D surface reconstruction of an object from real-world depth images. Our method relies on a representation obtained solely by training on synthetic data, which allows for extracting high-quality, category-specific geometry. We showed that even small errors in pose estimation lead to significant errors in 3D reconstruction. Therefore a simple method which uses an independently trained pose estimator followed by reconstruction in the object frame does not yield good reconstruction results. Instead, we presented a finetuning scheme to optimize the object surface and pose jointly during inference. We also showed that learning strong 3D priors benefits the 3D reconstruction of occluded objects. Our method generalizes across datasets and input modalities, from dense depth images to sparse LIDAR point clouds. While our process still exhibits failure modes when the error in the estimated pose is large, this could be alleviated by combining pose estimation and 3D reconstruction in an end-to-end trainable manner. We hope our work will inspire further work in this direction.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bechtold etÂ al. [2021]</span>
<span class="ltx_bibblock">
Jan Bechtold, Maxim Tatarchenko, Volker Fischer, and Thomas Brox.

</span>
<span class="ltx_bibblock">Fostering Generalization in Single-view 3D Reconstruction by
Learning a Hierarchy of Local and Global Shape Priors.

</span>
<span class="ltx_bibblock">In <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">2021 IEEE/CVF Conference on Computer Vision and
Pattern Recognition (CVPR)</em>, pages 15875â€“15884, Nashville, TN, USA,
June 2021. IEEE.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Blanz and Vetter [1999]</span>
<span class="ltx_bibblock">
Volker Blanz and Thomas Vetter.

</span>
<span class="ltx_bibblock">A morphable model for the synthesis of 3D faces.

</span>
<span class="ltx_bibblock">In <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 26th annual conference on Computer
graphics and interactive techniques</em>, pages 187â€“194, 1999.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bylow etÂ al. [2013]</span>
<span class="ltx_bibblock">
Erik Bylow, JÃ¼rgen Sturm, Christian Kerl, Fredrik Kahl, and Daniel Cremers.

</span>
<span class="ltx_bibblock">Real-time camera tracking and 3D reconstruction using signed
distance functions.

</span>
<span class="ltx_bibblock">In <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">Robotics: Science and Systems</em>, volumeÂ 2, pageÂ 2, 2013.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Campbell etÂ al. [2010]</span>
<span class="ltx_bibblock">
Mark Campbell, Magnus Egerstedt, JonathanÂ P How, and RichardÂ M Murray.

</span>
<span class="ltx_bibblock">Autonomous driving in urban environments: approaches, lessons and
challenges.

</span>
<span class="ltx_bibblock"><em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Philosophical Transactions of the Royal Society A:
Mathematical, Physical and Engineering Sciences</em>, 368(1928):4649â€“4672, 2010.

</span>
<span class="ltx_bibblock">Publisher: The Royal Society Publishing.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chang etÂ al. [2015]</span>
<span class="ltx_bibblock">
AngelÂ X. Chang, Thomas Funkhouser, Leonidas Guibas, Pat Hanrahan, Qixing Huang,
Zimo Li, Silvio Savarese, Manolis Savva, Shuran Song, Hao Su, Jianxiong Xiao,
LiÂ Yi, and Fisher Yu.

</span>
<span class="ltx_bibblock">ShapeNet: An Information-Rich 3D Model Repository.

</span>
<span class="ltx_bibblock">Technical Report arXiv:1512.03012 [cs.GR], Stanford University â€”
Princeton University â€” Toyota Technological Institute at Chicago, 2015.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chao etÂ al. [2022]</span>
<span class="ltx_bibblock">
Jun-Jee Chao, Selim Engin, Nicolai HÃ¤ni, and Volkan Isler.

</span>
<span class="ltx_bibblock">Category-Level Global Camera Pose Estimation with
Multi-Hypothesis Point Cloud Correspondences.

</span>
<span class="ltx_bibblock"><em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2209.14419</em>, 2022.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen etÂ al. [2019]</span>
<span class="ltx_bibblock">
Wenzheng Chen, Huan Ling, Jun Gao, Edward Smith, Jaakko Lehtinen, Alec
Jacobson, and Sanja Fidler.

</span>
<span class="ltx_bibblock">Learning to predict 3d objects with an interpolation-based
differentiable renderer.

</span>
<span class="ltx_bibblock"><em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, 32, 2019.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen etÂ al. [2020]</span>
<span class="ltx_bibblock">
Zhiqin Chen, Andrea Tagliasacchi, and Hao Zhang.

</span>
<span class="ltx_bibblock">Bsp-net: Generating compact meshes via binary space partitioning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition</em>, pages 45â€“54, 2020.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Choe etÂ al. [2021]</span>
<span class="ltx_bibblock">
Jaesung Choe, Sunghoon Im, Francois Rameau, Minjun Kang, and InÂ So Kweon.

</span>
<span class="ltx_bibblock">Volumefusion: Deep depth fusion for 3d scene reconstruction.

</span>
<span class="ltx_bibblock">In <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF International Conference
on Computer Vision</em>, pages 16086â€“16095, 2021.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dai etÂ al. [2017]</span>
<span class="ltx_bibblock">
Angela Dai, Charles RuizhongtaiÂ Qi, and Matthias NieÃŸner.

</span>
<span class="ltx_bibblock">Shape completion using 3d-encoder-predictor cnns and shape synthesis.

</span>
<span class="ltx_bibblock">In <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE conference on computer vision and
pattern recognition</em>, pages 5868â€“5877, 2017.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Deng etÂ al. [2020]</span>
<span class="ltx_bibblock">
Boyang Deng, Kyle Genova, Soroosh Yazdani, Sofien Bouaziz, Geoffrey Hinton, and
Andrea Tagliasacchi.

</span>
<span class="ltx_bibblock">Cvxnet: Learnable convex decomposition.

</span>
<span class="ltx_bibblock">In <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition</em>, pages 31â€“44, 2020.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Deng etÂ al. [2021]</span>
<span class="ltx_bibblock">
YuÂ Deng, Jiaolong Yang, and Xin Tong.

</span>
<span class="ltx_bibblock">Deformed implicit field: Modeling 3d shapes with learned dense
correspondence.

</span>
<span class="ltx_bibblock">In <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition</em>, pages 10286â€“10296, 2021.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Duggal and Pathak [2022]</span>
<span class="ltx_bibblock">
Shivam Duggal and Deepak Pathak.

</span>
<span class="ltx_bibblock">Topologically-Aware Deformation Fields for Single-View 3D
Reconstruction.

</span>
<span class="ltx_bibblock">In <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition</em>, pages 1536â€“1546, 2022.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Duggal etÂ al. [2022]</span>
<span class="ltx_bibblock">
Shivam Duggal, Zihao Wang, Wei-Chiu Ma, Sivabalan Manivasagam, Justin Liang,
Shenlong Wang, and Raquel Urtasun.

</span>
<span class="ltx_bibblock">Mending Neural Implicit Modeling for 3D Vehicle
Reconstruction in the Wild.

</span>
<span class="ltx_bibblock">In <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Winter Conference on
Applications of Computer Vision</em>, pages 1900â€“1909, 2022.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Engelmann etÂ al. [2017]</span>
<span class="ltx_bibblock">
Francis Engelmann, JÃ¶rg StÃ¼ckler, and Bastian Leibe.

</span>
<span class="ltx_bibblock">SAMP: shape and motion priors for 4d vehicle reconstruction.

</span>
<span class="ltx_bibblock">In <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">2017 IEEE Winter Conference on Applications of
Computer Vision (WACV)</em>, pages 400â€“408. IEEE, 2017.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fan etÂ al. [2017]</span>
<span class="ltx_bibblock">
Haoqiang Fan, Hao Su, and LeonidasÂ J Guibas.

</span>
<span class="ltx_bibblock">A point set generation network for 3d object reconstruction from a
single image.

</span>
<span class="ltx_bibblock">In <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE conference on computer vision and
pattern recognition</em>, pages 605â€“613, 2017.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao etÂ al. [2022]</span>
<span class="ltx_bibblock">
Jun Gao, Tianchang Shen, Zian Wang, Wenzheng Chen, Kangxue Yin, Daiqing Li,
OrÂ Litany, Zan Gojcic, and Sanja Fidler.

</span>
<span class="ltx_bibblock">GET3D: A Generative Model of High Quality 3D Textured
Shapes Learned from Images.

</span>
<span class="ltx_bibblock">In <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">Advances In Neural Information Processing
Systems</em>, 2022.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Goel etÂ al. [2022]</span>
<span class="ltx_bibblock">
Shubham Goel, Georgia Gkioxari, and Jitendra Malik.

</span>
<span class="ltx_bibblock">Differentiable Stereopsis: Meshes from multiple views using
differentiable rendering.

</span>
<span class="ltx_bibblock">In <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition</em>, pages 8635â€“8644, 2022.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guizilini etÂ al. [2020]</span>
<span class="ltx_bibblock">
Vitor Guizilini, Rares Ambrus, Sudeep Pillai, Allan Raventos, and Adrien
Gaidon.

</span>
<span class="ltx_bibblock">3D Packing for Self-Supervised Monocular Depth
Estimation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">IEEE Conference on Computer Vision and Pattern
Recognition (CVPR)</em>, 2020.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang etÂ al. [2017]</span>
<span class="ltx_bibblock">
Jingwei Huang, Angela Dai, Leonidas Guibas, and Matthias NieÃŸner.

</span>
<span class="ltx_bibblock">3DLite: Towards Commodity 3D Scanning for Content
Creation.

</span>
<span class="ltx_bibblock"><em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">ACM Transactions on Graphics 2017 (TOG)</em>, 2017.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang etÂ al. [2020]</span>
<span class="ltx_bibblock">
Zitian Huang, Yikuan Yu, Jiawen Xu, Feng Ni, and Xinyi Le.

</span>
<span class="ltx_bibblock">Pf-net: Point fractal network for 3d point cloud completion.

</span>
<span class="ltx_bibblock">In <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF conference on computer
vision and pattern recognition</em>, pages 7662â€“7670, 2020.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">HÃ¤ni etÂ al. [2020]</span>
<span class="ltx_bibblock">
Nicolai HÃ¤ni, Selim Engin, Jun-Jee Chao, and Volkan Isler.

</span>
<span class="ltx_bibblock">Continuous Object Representation Networks: Novel View
Synthesis without Target View Supervision.

</span>
<span class="ltx_bibblock">In <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>,
2020.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang etÂ al. [2021]</span>
<span class="ltx_bibblock">
Haobo Jiang, Yaqi Shen, Jin Xie, Jun Li, Jianjun Qian, and Jian Yang.

</span>
<span class="ltx_bibblock">Sampling network guided cross-entropy method for unsupervised point
cloud registration.

</span>
<span class="ltx_bibblock">In <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF International Conference
on Computer Vision</em>, pages 6128â€“6137, 2021.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kanazawa etÂ al. [2018]</span>
<span class="ltx_bibblock">
Angjoo Kanazawa, Shubham Tulsiani, AlexeiÂ A Efros, and Jitendra Malik.

</span>
<span class="ltx_bibblock">Learning category-specific mesh reconstruction from image
collections.

</span>
<span class="ltx_bibblock">In <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">Proceedings of the European Conference on Computer
Vision (ECCV)</em>, pages 371â€“386, 2018.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kar etÂ al. [2015]</span>
<span class="ltx_bibblock">
Abhishek Kar, Shubham Tulsiani, Joao Carreira, and Jitendra Malik.

</span>
<span class="ltx_bibblock">Category-Specific Object Reconstruction From a Single
Image.

</span>
<span class="ltx_bibblock">In <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE Conference on Computer
Vision and Pattern Recognition (CVPR)</em>, June 2015.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Katzir etÂ al. [2022]</span>
<span class="ltx_bibblock">
Oren Katzir, Dani Lischinski, and Daniel Cohen-Or.

</span>
<span class="ltx_bibblock">Shape-Pose Disentanglement using SE (3)-equivariant Vector
Neurons.

</span>
<span class="ltx_bibblock"><em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2204.01159</em>, 2022.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kingma and Ba [2014]</span>
<span class="ltx_bibblock">
DiederikÂ P Kingma and Jimmy Ba.

</span>
<span class="ltx_bibblock">Adam: A method for stochastic optimization.

</span>
<span class="ltx_bibblock"><em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1412.6980</em>, 2014.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kumar etÂ al. [2017]</span>
<span class="ltx_bibblock">
Gourav Kumar, Harit Pandya, Ayush Gaud, and KÂ Madhava Krishna.

</span>
<span class="ltx_bibblock">Pose induction for visual servoing to a novel object instance.

</span>
<span class="ltx_bibblock">In <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">2017 IEEE/RSJ International Conference on
Intelligent Robots and Systems (IROS)</em>, pages 2953â€“2959. IEEE, 2017.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li etÂ al. [2021]</span>
<span class="ltx_bibblock">
Xiaolong Li, Yijia Weng, LiÂ Yi, Leonidas Guibas, AÂ Lynn Abbott, Shuran Song,
and HeÂ Wang.

</span>
<span class="ltx_bibblock">Leveraging SE(3) Equivariance for Self-Supervised
Category-Level Object Pose Estimation.

</span>
<span class="ltx_bibblock"><em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">Thirty-Fifth Conference on Neural Information Processing
Systems</em>, 2021.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lim etÂ al. [2013]</span>
<span class="ltx_bibblock">
JosephÂ J Lim, Hamed Pirsiavash, and Antonio Torralba.

</span>
<span class="ltx_bibblock">Parsing ikea objects: Fine pose estimation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE international conference on
computer vision</em>, pages 2992â€“2999, 2013.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin etÂ al. [2020]</span>
<span class="ltx_bibblock">
Chen-Hsuan Lin, Chaoyang Wang, and Simon Lucey.

</span>
<span class="ltx_bibblock">Sdf-srn: Learning signed distance 3d object reconstruction from
static images.

</span>
<span class="ltx_bibblock"><em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>,
33:11453â€“11464, 2020.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu etÂ al. [2020]</span>
<span class="ltx_bibblock">
Minghua Liu, LuÂ Sheng, Sheng Yang, Jing Shao, and Shi-Min Hu.

</span>
<span class="ltx_bibblock">Morphing and sampling network for dense point cloud completion.

</span>
<span class="ltx_bibblock">In <em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI conference on artificial
intelligence</em>, volumeÂ 34, pages 11596â€“11603, 2020.

</span>
<span class="ltx_bibblock">Issue: 07.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Loper etÂ al. [2015]</span>
<span class="ltx_bibblock">
Matthew Loper, Naureen Mahmood, Javier Romero, Gerard Pons-Moll, and MichaelÂ J
Black.

</span>
<span class="ltx_bibblock">SMPL: A skinned multi-person linear model.

</span>
<span class="ltx_bibblock"><em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">ACM transactions on graphics (TOG)</em>, 34(6):1â€“16, 2015.

</span>
<span class="ltx_bibblock">Publisher: ACM New York, NY, USA.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lorensen and Cline [1987]</span>
<span class="ltx_bibblock">
WilliamÂ E Lorensen and HarveyÂ E Cline.

</span>
<span class="ltx_bibblock">Marching cubes: A high resolution 3D surface construction
algorithm.

</span>
<span class="ltx_bibblock"><em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">ACM siggraph computer graphics</em>, 21(4):163â€“169, 1987.

</span>
<span class="ltx_bibblock">Publisher: ACM New York, NY, USA.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mescheder etÂ al. [2019]</span>
<span class="ltx_bibblock">
Lars Mescheder, Michael Oechsle, Michael Niemeyer, Sebastian Nowozin, and
Andreas Geiger.

</span>
<span class="ltx_bibblock">Occupancy networks: Learning 3d reconstruction in function space.

</span>
<span class="ltx_bibblock">In <em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE Conference on Computer
Vision and Pattern Recognition</em>, pages 4460â€“4470, 2019.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mildenhall etÂ al. [2020]</span>
<span class="ltx_bibblock">
Ben Mildenhall, PratulÂ P Srinivasan, Matthew Tancik, JonathanÂ T Barron, Ravi
Ramamoorthi, and Ren Ng.

</span>
<span class="ltx_bibblock">NeRF: Representing Scenes as Neural Radiance Fields for
View Synthesis.

</span>
<span class="ltx_bibblock">In <em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">Proceedings of the European Conference on Computer
Vision</em>, pages 405â€“421. Springer, 2020.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mitchell etÂ al. [2019]</span>
<span class="ltx_bibblock">
Eric Mitchell, Selim Engin, Volkan Isler, and DanielÂ D Lee.

</span>
<span class="ltx_bibblock">Higher-Order Function Networks for Learning Composable 3D
Object Representations.

</span>
<span class="ltx_bibblock">In <em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations</em>,
2019.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mittal etÂ al. [2022]</span>
<span class="ltx_bibblock">
Paritosh Mittal, Yen-Chi Cheng, Maneesh Singh, and Shubham Tulsiani.

</span>
<span class="ltx_bibblock">AutoSDF: Shape Priors for 3D Completion, Reconstruction
and Generation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">CVPR</em>, 2022.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mousavian etÂ al. [2019]</span>
<span class="ltx_bibblock">
Arsalan Mousavian, Clemens Eppner, and Dieter Fox.

</span>
<span class="ltx_bibblock">6-dof graspnet: Variational grasp generation for object
manipulation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF International Conference
on Computer Vision</em>, pages 2901â€“2910, 2019.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Newcombe etÂ al. [2011]</span>
<span class="ltx_bibblock">
RichardÂ A Newcombe, Shahram Izadi, Otmar Hilliges, David Molyneaux, David Kim,
AndrewÂ J Davison, Pushmeet Kohi, Jamie Shotton, Steve Hodges, and Andrew
Fitzgibbon.

</span>
<span class="ltx_bibblock">Kinectfusion: Real-time dense surface mapping and tracking.

</span>
<span class="ltx_bibblock">In <em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">2011 10th IEEE international symposium on mixed and
augmented reality</em>, pages 127â€“136. Ieee, 2011.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Novotny etÂ al. [2019]</span>
<span class="ltx_bibblock">
David Novotny, Nikhila Ravi, Benjamin Graham, Natalia Neverova, and Andrea
Vedaldi.

</span>
<span class="ltx_bibblock">C3dpo: Canonical 3d pose networks for non-rigid structure from
motion.

</span>
<span class="ltx_bibblock">In <em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF International Conference
on Computer Vision</em>, pages 7688â€“7697, 2019.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Park etÂ al. [2019]</span>
<span class="ltx_bibblock">
JeongÂ Joon Park, Peter Florence, Julian Straub, Richard Newcombe, and Steven
Lovegrove.

</span>
<span class="ltx_bibblock">Deepsdf: Learning continuous signed distance functions for shape
representation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF conference on computer
vision and pattern recognition</em>, pages 165â€“174, 2019.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qin etÂ al. [2022]</span>
<span class="ltx_bibblock">
Zheng Qin, Hao Yu, Changjian Wang, Yulan Guo, Yuxing Peng, and Kai Xu.

</span>
<span class="ltx_bibblock">Geometric Transformer for Fast and Robust Point Cloud
Registration.

</span>
<span class="ltx_bibblock">In <em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition (CVPR)</em>, pages 11143â€“11152, June
2022.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rempe etÂ al. [2020]</span>
<span class="ltx_bibblock">
Davis Rempe, Tolga Birdal, Yongheng Zhao, Zan Gojcic, Srinath Sridhar, and
LeonidasÂ J Guibas.

</span>
<span class="ltx_bibblock">Caspr: Learning canonical spatiotemporal point cloud
representations.

</span>
<span class="ltx_bibblock"><em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>,
33:13688â€“13701, 2020.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sajnani etÂ al. [2022]</span>
<span class="ltx_bibblock">
Rahul Sajnani, Adrien Poulenard, Jivitesh Jain, Radhika Dua, LeonidasÂ J.
Guibas, and Srinath Sridhar.

</span>
<span class="ltx_bibblock">ConDor: Self-Supervised Canonicalization of 3D Pose for
Partial Shapes.

</span>
<span class="ltx_bibblock">In <em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">The IEEE Conference on Computer Vision and Pattern
Recognition (CVPR)</em>, June 2022.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sen etÂ al. [2023]</span>
<span class="ltx_bibblock">
Bipasha Sen, Aditya Agarwal, Gaurav Singh, Srinath Sridhar, Madhava Krishna,
and others.

</span>
<span class="ltx_bibblock">SCARP: 3D Shape Completion in ARbitrary Poses for
Improved Grasping.

</span>
<span class="ltx_bibblock"><em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2301.07213</em>, 2023.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sitzmann etÂ al. [2019]</span>
<span class="ltx_bibblock">
Vincent Sitzmann, Michael ZollhÃ¶fer, and Gordon Wetzstein.

</span>
<span class="ltx_bibblock">Scene representation networks: Continuous 3D-structure-aware
neural scene representations.

</span>
<span class="ltx_bibblock">In <em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>,
volumeÂ 32, pages 1119â€“1130, 2019.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sitzmann etÂ al. [2020]</span>
<span class="ltx_bibblock">
Vincent Sitzmann, Julien Martel, Alexander Bergman, David Lindell, and Gordon
Wetzstein.

</span>
<span class="ltx_bibblock">Implicit neural representations with periodic activation functions.

</span>
<span class="ltx_bibblock"><em id="bib.bib48.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>,
33:7462â€“7473, 2020.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Spezialetti etÂ al. [2020]</span>
<span class="ltx_bibblock">
Riccardo Spezialetti, Federico Stella, Marlon Marcon, Luciano Silva, Samuele
Salti, and Luigi DiÂ Stefano.

</span>
<span class="ltx_bibblock">Learning to orient surfaces by self-supervised spherical cnns.

</span>
<span class="ltx_bibblock"><em id="bib.bib49.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>,
33:5381â€“5392, 2020.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun etÂ al. [2021]</span>
<span class="ltx_bibblock">
Weiwei Sun, Andrea Tagliasacchi, Boyang Deng, Sara Sabour, Soroosh Yazdani,
Geoffrey Hinton, and KwangÂ Moo Yi.

</span>
<span class="ltx_bibblock">Canonical Capsules: Self-Supervised Capsules in Canonical
Pose.

</span>
<span class="ltx_bibblock">In <em id="bib.bib50.1.1" class="ltx_emph ltx_font_italic">Neural Information Processing Systems</em>, 2021.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tatarchenko etÂ al. [2019]</span>
<span class="ltx_bibblock">
Maxim Tatarchenko, StephanÂ R Richter, RenÃ© Ranftl, Zhuwen Li, Vladlen Koltun,
and Thomas Brox.

</span>
<span class="ltx_bibblock">What do single-view 3d reconstruction networks learn?

</span>
<span class="ltx_bibblock">In <em id="bib.bib51.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF conference on computer
vision and pattern recognition</em>, pages 3405â€“3414, 2019.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tulsiani etÂ al. [2017]</span>
<span class="ltx_bibblock">
Shubham Tulsiani, Tinghui Zhou, AlexeiÂ A. Efros, and Jitendra Malik.

</span>
<span class="ltx_bibblock">Multi-View Supervision for Single-View Reconstruction via
Differentiable Ray Consistency.

</span>
<span class="ltx_bibblock">In <em id="bib.bib52.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE Conference on Computer
Vision and Pattern Recognition (CVPR)</em>, July 2017.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang etÂ al. [2019]</span>
<span class="ltx_bibblock">
HeÂ Wang, Srinath Sridhar, Jingwei Huang, Julien Valentin, Shuran Song, and
LeonidasÂ J Guibas.

</span>
<span class="ltx_bibblock">Normalized object coordinate space for category-level 6d object pose
and size estimation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib53.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition</em>, pages 2642â€“2651, 2019.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu etÂ al. [2021]</span>
<span class="ltx_bibblock">
Bingli Wu, Jie Ma, Gaojie Chen, and Pei An.

</span>
<span class="ltx_bibblock">Feature interactive representation for point cloud registration.

</span>
<span class="ltx_bibblock">In <em id="bib.bib54.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF International Conference
on Computer Vision</em>, pages 5530â€“5539, 2021.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu etÂ al. [2017]</span>
<span class="ltx_bibblock">
Jiajun Wu, Yifan Wang, Tianfan Xue, Xingyuan Sun, Bill Freeman, and Josh
Tenenbaum.

</span>
<span class="ltx_bibblock">Marrnet: 3d shape reconstruction via 2.5 d sketches.

</span>
<span class="ltx_bibblock"><em id="bib.bib55.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, 30, 2017.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu etÂ al. [2018]</span>
<span class="ltx_bibblock">
Jiajun Wu, Chengkai Zhang, Xiuming Zhang, Zhoutong Zhang, WilliamÂ T Freeman,
and JoshuaÂ B Tenenbaum.

</span>
<span class="ltx_bibblock">Learning shape priors for single-view 3d completion and
reconstruction.

</span>
<span class="ltx_bibblock">In <em id="bib.bib56.1.1" class="ltx_emph ltx_font_italic">Proceedings of the European Conference on Computer
Vision (ECCV)</em>, pages 646â€“662, 2018.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu etÂ al. [2015]</span>
<span class="ltx_bibblock">
Zhirong Wu, Shuran Song, Aditya Khosla, Fisher Yu, Linguang Zhang, Xiaoou Tang,
and Jianxiong Xiao.

</span>
<span class="ltx_bibblock">3d shapenets: A deep representation for volumetric shapes.

</span>
<span class="ltx_bibblock">In <em id="bib.bib57.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE conference on computer vision and
pattern recognition</em>, pages 1912â€“1920, 2015.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xiang etÂ al. [2014]</span>
<span class="ltx_bibblock">
YuÂ Xiang, Roozbeh Mottaghi, and Silvio Savarese.

</span>
<span class="ltx_bibblock">Beyond pascal: A benchmark for 3d object detection in the wild.

</span>
<span class="ltx_bibblock">In <em id="bib.bib58.1.1" class="ltx_emph ltx_font_italic">IEEE winter conference on applications of computer
vision</em>, pages 75â€“82. IEEE, 2014.

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu etÂ al. [2019]</span>
<span class="ltx_bibblock">
Qiangeng Xu, Weiyue Wang, Duygu Ceylan, Radomir Mech, and Ulrich Neumann.

</span>
<span class="ltx_bibblock">Disn: Deep implicit surface network for high-quality single-view 3d
reconstruction.

</span>
<span class="ltx_bibblock">In <em id="bib.bib59.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>,
volumeÂ 32, 2019.

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yan etÂ al. [2016]</span>
<span class="ltx_bibblock">
Xinchen Yan, Jimei Yang, Ersin Yumer, Yijie Guo, and Honglak Lee.

</span>
<span class="ltx_bibblock">Perspective transformer nets: Learning single-view 3d object
reconstruction without 3d supervision.

</span>
<span class="ltx_bibblock"><em id="bib.bib60.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, 29, 2016.

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yan etÂ al. [2022]</span>
<span class="ltx_bibblock">
Xingguang Yan, Liqiang Lin, NiloyÂ J. Mitra, Dani Lischinski, Daniel Cohen-Or,
and Hui Huang.

</span>
<span class="ltx_bibblock">ShapeFormer: Transformer-Based Shape Completion via
Sparse Representation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib61.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition (CVPR)</em>, pages 6239â€“6249, June 2022.

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang etÂ al. [2018]</span>
<span class="ltx_bibblock">
Guandao Yang, Yin Cui, Serge Belongie, and Bharath Hariharan.

</span>
<span class="ltx_bibblock">Learning single-view 3d reconstruction with limited pose supervision.

</span>
<span class="ltx_bibblock">In <em id="bib.bib62.1.1" class="ltx_emph ltx_font_italic">Proceedings of the European Conference on Computer
Vision (ECCV)</em>, pages 86â€“101, 2018.

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang etÂ al. [2019]</span>
<span class="ltx_bibblock">
Guandao Yang, Xun Huang, Zekun Hao, Ming-Yu Liu, Serge Belongie, and Bharath
Hariharan.

</span>
<span class="ltx_bibblock">Pointflow: 3d point cloud generation with continuous normalizing
flows.

</span>
<span class="ltx_bibblock">In <em id="bib.bib63.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF International Conference
on Computer Vision</em>, pages 4541â€“4550, 2019.

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ye etÂ al. [2021]</span>
<span class="ltx_bibblock">
Yufei Ye, Shubham Tulsiani, and Abhinav Gupta.

</span>
<span class="ltx_bibblock">Shelf-Supervised Mesh Prediction in the Wild.

</span>
<span class="ltx_bibblock">In <em id="bib.bib64.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition (CVPR)</em>, pages 8843â€“8852, June 2021.

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu etÂ al. [2021]</span>
<span class="ltx_bibblock">
Xumin Yu, Yongming Rao, Ziyi Wang, Zuyan Liu, Jiwen Lu, and Jie Zhou.

</span>
<span class="ltx_bibblock">Pointr: Diverse point cloud completion with geometry-aware
transformers.

</span>
<span class="ltx_bibblock">In <em id="bib.bib65.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF international conference on
computer vision</em>, pages 12498â€“12507, 2021.

</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yuan etÂ al. [2018]</span>
<span class="ltx_bibblock">
Wentao Yuan, Tejas Khot, David Held, Christoph Mertz, and Martial Hebert.

</span>
<span class="ltx_bibblock">Pcn: Point completion network.

</span>
<span class="ltx_bibblock">In <em id="bib.bib66.1.1" class="ltx_emph ltx_font_italic">2018 International Conference on 3D Vision (3DV)</em>,
pages 728â€“737. IEEE, 2018.

</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zeng etÂ al. [2020]</span>
<span class="ltx_bibblock">
Wenyuan Zeng, Shenlong Wang, Renjie Liao, Yun Chen, Bin Yang, and Raquel
Urtasun.

</span>
<span class="ltx_bibblock">Dsdnet: Deep structured self-driving network.

</span>
<span class="ltx_bibblock">In <em id="bib.bib67.1.1" class="ltx_emph ltx_font_italic">Computer Visionâ€“ECCV 2020: 16th European
Conference, Glasgow, UK, August 23â€“28, 2020, Proceedings, Part
XXI 16</em>, pages 156â€“172. Springer, 2020.

</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang etÂ al. [2021]</span>
<span class="ltx_bibblock">
Jason Zhang, Gengshan Yang, Shubham Tulsiani, and Deva Ramanan.

</span>
<span class="ltx_bibblock">NeRS: Neural reflectance surfaces for sparse-view 3d
reconstruction in the wild.

</span>
<span class="ltx_bibblock"><em id="bib.bib68.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>,
34:29835â€“29847, 2021.

</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zheng etÂ al. [2021]</span>
<span class="ltx_bibblock">
Zerong Zheng, Tao Yu, Qionghai Dai, and Yebin Liu.

</span>
<span class="ltx_bibblock">Deep implicit templates for 3d shape representation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib69.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition</em>, pages 1429â€“1439, 2021.

</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou etÂ al. [2019]</span>
<span class="ltx_bibblock">
YiÂ Zhou, Connelly Barnes, Jingwan Lu, Jimei Yang, and Hao Li.

</span>
<span class="ltx_bibblock">On the continuity of rotation representations in neural networks.

</span>
<span class="ltx_bibblock">In <em id="bib.bib70.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition</em>, pages 5745â€“5753, 2019.

</span>
</li>
</ul>
</section>
<section id="A0.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="A0.SS1.5.1.1" class="ltx_text">-A</span> </span><span id="A0.SS1.6.2" class="ltx_text ltx_font_italic">Dataset Details</span>
</h3>

<div id="A0.SS1.p1" class="ltx_para">
<p id="A0.SS1.p1.1" class="ltx_p"><span id="A0.SS1.p1.1.1" class="ltx_text ltx_font_bold">Shapenet</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>:
For training on Shapenet, we followÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> and extract 500,000 SDF values on the objectâ€™s surface and 500,000 randomly sampled in a cube of side length 2. We also render a single RGB-D image with a camera sampled on the viewing hemisphere for testing according toÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. We use the same train/test split for each category as DIF-NetÂ <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>, but only keep the intersection of objects in both ours and the baselines test sets.</p>
</div>
<div id="A0.SS1.p2" class="ltx_para">
<p id="A0.SS1.p2.1" class="ltx_p"><span id="A0.SS1.p2.1.1" class="ltx_text ltx_font_bold">Pascal3D+</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite>:
Pascal3D+ is a real-world dataset containing camera images. The dataset provides object silhouettes, camera poses, and the CAD models used to annotate the camera poses. Since the same set of CAD models is used to annotate both the training and testing set, the dataset is considered to possess a biasÂ <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>]</cite>. However, unlike the other baselines, our method is only trained on Shapenet and therefore has not seen any of the CAD models from Pascal3D+ during training. We evaluate our method on the car, chair, and airplane category of Pascal3D+. We follow the testing split that is used by SDF-SRNÂ <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>. To generate partial point clouds in the camera frame as the input for our method, we first transform the CAD models into the camera frame using the ground truth camera poses. We remove points that are invisible from the camera origin. We do not have access to either ground truth poses or the complete CAD model during training and testing.</p>
</div>
<div id="A0.SS1.p3" class="ltx_para">
<p id="A0.SS1.p3.1" class="ltx_p"><span id="A0.SS1.p3.1.1" class="ltx_text ltx_font_bold">Pix3D</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>:
Like Pascal3D+, Pix3D contains real-world 2D images annotated with 3D CAD models. Unlike Pascal3D+, Pix3D uses a variety of CAD models that align better with the images. We randomly select 200 images from the Pix3D chair dataset as the test set. We follow the same process as Pascal3D+ to generate the partial point clouds in the camera frame. Again, our method does not access the complete CAD models, and ground truth camera poses.</p>
</div>
<div id="A0.SS1.p4" class="ltx_para">
<p id="A0.SS1.p4.1" class="ltx_p"><span id="A0.SS1.p4.1.1" class="ltx_text ltx_font_bold">DDAD</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>:
DDAD is an autonomous driving benchmark containing diverse urban scenes captured using car sensors. The dataset includes RGB videos captured using six cameras covering the 360-degree surrounding of the vehicle. DDAD also provides depth data across an entire 360-degree field of view scanned using long-range LiDAR sensors. We test our method on one scene with 100 frames. We extract only the frames that contain other cars in the cameraâ€™s field of view. To generate the partial point clouds of the observed cars, we crop the LiDAR data with the ground truth poses and the masked images. The cropped LiDAR scans in the camera frame serve as our methodâ€™s input. The DDAD dataset does not provide ground truth models of the observed cars, and our method does not have access to the ground truth camera poses. We therefore show only qualitative results.</p>
</div>
</section>
<section id="A0.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="A0.SS2.5.1.1" class="ltx_text">-B</span> </span><span id="A0.SS2.6.2" class="ltx_text ltx_font_italic">Implementation Details</span>
</h3>

<div id="A0.SS2.p1" class="ltx_para">
<p id="A0.SS2.p1.1" class="ltx_p"><span id="A0.SS2.p1.1.1" class="ltx_text ltx_font_bold">DIF-Net Architecture</span> DIF-Net uses a SIRENÂ <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite> network as the MLP backbone for both, the deformation and template networks. The Hyper-network is a ReLU network, where each MLP predicts the weights of one of the layers in the deformation network <math id="A0.SS2.p1.1.m1.1" class="ltx_Math" alttext="D" display="inline"><semantics id="A0.SS2.p1.1.m1.1a"><mi id="A0.SS2.p1.1.m1.1.1" xref="A0.SS2.p1.1.m1.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="A0.SS2.p1.1.m1.1b"><ci id="A0.SS2.p1.1.m1.1.1.cmml" xref="A0.SS2.p1.1.m1.1.1">ğ·</ci></annotation-xml><annotation encoding="application/x-tex" id="A0.SS2.p1.1.m1.1c">D</annotation></semantics></math>.</p>
</div>
<div id="A0.SS2.p2" class="ltx_para">
<p id="A0.SS2.p2.6" class="ltx_p"><span id="A0.SS2.p2.6.1" class="ltx_text ltx_font_bold">Training Details</span>
We initialize the latent codes to small values from <math id="A0.SS2.p2.1.m1.2" class="ltx_Math" alttext="\mathcal{N}(0,0.01)" display="inline"><semantics id="A0.SS2.p2.1.m1.2a"><mrow id="A0.SS2.p2.1.m1.2.3" xref="A0.SS2.p2.1.m1.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="A0.SS2.p2.1.m1.2.3.2" xref="A0.SS2.p2.1.m1.2.3.2.cmml">ğ’©</mi><mo lspace="0em" rspace="0em" id="A0.SS2.p2.1.m1.2.3.1" xref="A0.SS2.p2.1.m1.2.3.1.cmml">â€‹</mo><mrow id="A0.SS2.p2.1.m1.2.3.3.2" xref="A0.SS2.p2.1.m1.2.3.3.1.cmml"><mo stretchy="false" id="A0.SS2.p2.1.m1.2.3.3.2.1" xref="A0.SS2.p2.1.m1.2.3.3.1.cmml">(</mo><mn id="A0.SS2.p2.1.m1.1.1" xref="A0.SS2.p2.1.m1.1.1.cmml">0</mn><mo id="A0.SS2.p2.1.m1.2.3.3.2.2" xref="A0.SS2.p2.1.m1.2.3.3.1.cmml">,</mo><mn id="A0.SS2.p2.1.m1.2.2" xref="A0.SS2.p2.1.m1.2.2.cmml">0.01</mn><mo stretchy="false" id="A0.SS2.p2.1.m1.2.3.3.2.3" xref="A0.SS2.p2.1.m1.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A0.SS2.p2.1.m1.2b"><apply id="A0.SS2.p2.1.m1.2.3.cmml" xref="A0.SS2.p2.1.m1.2.3"><times id="A0.SS2.p2.1.m1.2.3.1.cmml" xref="A0.SS2.p2.1.m1.2.3.1"></times><ci id="A0.SS2.p2.1.m1.2.3.2.cmml" xref="A0.SS2.p2.1.m1.2.3.2">ğ’©</ci><interval closure="open" id="A0.SS2.p2.1.m1.2.3.3.1.cmml" xref="A0.SS2.p2.1.m1.2.3.3.2"><cn type="integer" id="A0.SS2.p2.1.m1.1.1.cmml" xref="A0.SS2.p2.1.m1.1.1">0</cn><cn type="float" id="A0.SS2.p2.1.m1.2.2.cmml" xref="A0.SS2.p2.1.m1.2.2">0.01</cn></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="A0.SS2.p2.1.m1.2c">\mathcal{N}(0,0.01)</annotation></semantics></math>. Each model is optimized for 60 epochs and during each epoch, the model has access to 200,000 free and 200,000 surface points. We set the weights for the SDF loss <math id="A0.SS2.p2.2.m2.1" class="ltx_Math" alttext="\mathcal{L}_{sdf}" display="inline"><semantics id="A0.SS2.p2.2.m2.1a"><msub id="A0.SS2.p2.2.m2.1.1" xref="A0.SS2.p2.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="A0.SS2.p2.2.m2.1.1.2" xref="A0.SS2.p2.2.m2.1.1.2.cmml">â„’</mi><mrow id="A0.SS2.p2.2.m2.1.1.3" xref="A0.SS2.p2.2.m2.1.1.3.cmml"><mi id="A0.SS2.p2.2.m2.1.1.3.2" xref="A0.SS2.p2.2.m2.1.1.3.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="A0.SS2.p2.2.m2.1.1.3.1" xref="A0.SS2.p2.2.m2.1.1.3.1.cmml">â€‹</mo><mi id="A0.SS2.p2.2.m2.1.1.3.3" xref="A0.SS2.p2.2.m2.1.1.3.3.cmml">d</mi><mo lspace="0em" rspace="0em" id="A0.SS2.p2.2.m2.1.1.3.1a" xref="A0.SS2.p2.2.m2.1.1.3.1.cmml">â€‹</mo><mi id="A0.SS2.p2.2.m2.1.1.3.4" xref="A0.SS2.p2.2.m2.1.1.3.4.cmml">f</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="A0.SS2.p2.2.m2.1b"><apply id="A0.SS2.p2.2.m2.1.1.cmml" xref="A0.SS2.p2.2.m2.1.1"><csymbol cd="ambiguous" id="A0.SS2.p2.2.m2.1.1.1.cmml" xref="A0.SS2.p2.2.m2.1.1">subscript</csymbol><ci id="A0.SS2.p2.2.m2.1.1.2.cmml" xref="A0.SS2.p2.2.m2.1.1.2">â„’</ci><apply id="A0.SS2.p2.2.m2.1.1.3.cmml" xref="A0.SS2.p2.2.m2.1.1.3"><times id="A0.SS2.p2.2.m2.1.1.3.1.cmml" xref="A0.SS2.p2.2.m2.1.1.3.1"></times><ci id="A0.SS2.p2.2.m2.1.1.3.2.cmml" xref="A0.SS2.p2.2.m2.1.1.3.2">ğ‘ </ci><ci id="A0.SS2.p2.2.m2.1.1.3.3.cmml" xref="A0.SS2.p2.2.m2.1.1.3.3">ğ‘‘</ci><ci id="A0.SS2.p2.2.m2.1.1.3.4.cmml" xref="A0.SS2.p2.2.m2.1.1.3.4">ğ‘“</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A0.SS2.p2.2.m2.1c">\mathcal{L}_{sdf}</annotation></semantics></math> to 3e3, 1e2, 5e1 and 5e2 according toÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite>. We followÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> in choosing the weighting parameters as follows. <math id="A0.SS2.p2.3.m3.1" class="ltx_Math" alttext="\lambda_{1}" display="inline"><semantics id="A0.SS2.p2.3.m3.1a"><msub id="A0.SS2.p2.3.m3.1.1" xref="A0.SS2.p2.3.m3.1.1.cmml"><mi id="A0.SS2.p2.3.m3.1.1.2" xref="A0.SS2.p2.3.m3.1.1.2.cmml">Î»</mi><mn id="A0.SS2.p2.3.m3.1.1.3" xref="A0.SS2.p2.3.m3.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="A0.SS2.p2.3.m3.1b"><apply id="A0.SS2.p2.3.m3.1.1.cmml" xref="A0.SS2.p2.3.m3.1.1"><csymbol cd="ambiguous" id="A0.SS2.p2.3.m3.1.1.1.cmml" xref="A0.SS2.p2.3.m3.1.1">subscript</csymbol><ci id="A0.SS2.p2.3.m3.1.1.2.cmml" xref="A0.SS2.p2.3.m3.1.1.2">ğœ†</ci><cn type="integer" id="A0.SS2.p2.3.m3.1.1.3.cmml" xref="A0.SS2.p2.3.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A0.SS2.p2.3.m3.1c">\lambda_{1}</annotation></semantics></math> and <math id="A0.SS2.p2.4.m4.1" class="ltx_Math" alttext="\lambda_{4}" display="inline"><semantics id="A0.SS2.p2.4.m4.1a"><msub id="A0.SS2.p2.4.m4.1.1" xref="A0.SS2.p2.4.m4.1.1.cmml"><mi id="A0.SS2.p2.4.m4.1.1.2" xref="A0.SS2.p2.4.m4.1.1.2.cmml">Î»</mi><mn id="A0.SS2.p2.4.m4.1.1.3" xref="A0.SS2.p2.4.m4.1.1.3.cmml">4</mn></msub><annotation-xml encoding="MathML-Content" id="A0.SS2.p2.4.m4.1b"><apply id="A0.SS2.p2.4.m4.1.1.cmml" xref="A0.SS2.p2.4.m4.1.1"><csymbol cd="ambiguous" id="A0.SS2.p2.4.m4.1.1.1.cmml" xref="A0.SS2.p2.4.m4.1.1">subscript</csymbol><ci id="A0.SS2.p2.4.m4.1.1.2.cmml" xref="A0.SS2.p2.4.m4.1.1.2">ğœ†</ci><cn type="integer" id="A0.SS2.p2.4.m4.1.1.3.cmml" xref="A0.SS2.p2.4.m4.1.1.3">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A0.SS2.p2.4.m4.1c">\lambda_{4}</annotation></semantics></math> are 1e2 and 1e6 for all categories. <math id="A0.SS2.p2.5.m5.1" class="ltx_Math" alttext="lambda_{2}" display="inline"><semantics id="A0.SS2.p2.5.m5.1a"><mrow id="A0.SS2.p2.5.m5.1.1" xref="A0.SS2.p2.5.m5.1.1.cmml"><mi id="A0.SS2.p2.5.m5.1.1.2" xref="A0.SS2.p2.5.m5.1.1.2.cmml">l</mi><mo lspace="0em" rspace="0em" id="A0.SS2.p2.5.m5.1.1.1" xref="A0.SS2.p2.5.m5.1.1.1.cmml">â€‹</mo><mi id="A0.SS2.p2.5.m5.1.1.3" xref="A0.SS2.p2.5.m5.1.1.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="A0.SS2.p2.5.m5.1.1.1a" xref="A0.SS2.p2.5.m5.1.1.1.cmml">â€‹</mo><mi id="A0.SS2.p2.5.m5.1.1.4" xref="A0.SS2.p2.5.m5.1.1.4.cmml">m</mi><mo lspace="0em" rspace="0em" id="A0.SS2.p2.5.m5.1.1.1b" xref="A0.SS2.p2.5.m5.1.1.1.cmml">â€‹</mo><mi id="A0.SS2.p2.5.m5.1.1.5" xref="A0.SS2.p2.5.m5.1.1.5.cmml">b</mi><mo lspace="0em" rspace="0em" id="A0.SS2.p2.5.m5.1.1.1c" xref="A0.SS2.p2.5.m5.1.1.1.cmml">â€‹</mo><mi id="A0.SS2.p2.5.m5.1.1.6" xref="A0.SS2.p2.5.m5.1.1.6.cmml">d</mi><mo lspace="0em" rspace="0em" id="A0.SS2.p2.5.m5.1.1.1d" xref="A0.SS2.p2.5.m5.1.1.1.cmml">â€‹</mo><msub id="A0.SS2.p2.5.m5.1.1.7" xref="A0.SS2.p2.5.m5.1.1.7.cmml"><mi id="A0.SS2.p2.5.m5.1.1.7.2" xref="A0.SS2.p2.5.m5.1.1.7.2.cmml">a</mi><mn id="A0.SS2.p2.5.m5.1.1.7.3" xref="A0.SS2.p2.5.m5.1.1.7.3.cmml">2</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="A0.SS2.p2.5.m5.1b"><apply id="A0.SS2.p2.5.m5.1.1.cmml" xref="A0.SS2.p2.5.m5.1.1"><times id="A0.SS2.p2.5.m5.1.1.1.cmml" xref="A0.SS2.p2.5.m5.1.1.1"></times><ci id="A0.SS2.p2.5.m5.1.1.2.cmml" xref="A0.SS2.p2.5.m5.1.1.2">ğ‘™</ci><ci id="A0.SS2.p2.5.m5.1.1.3.cmml" xref="A0.SS2.p2.5.m5.1.1.3">ğ‘</ci><ci id="A0.SS2.p2.5.m5.1.1.4.cmml" xref="A0.SS2.p2.5.m5.1.1.4">ğ‘š</ci><ci id="A0.SS2.p2.5.m5.1.1.5.cmml" xref="A0.SS2.p2.5.m5.1.1.5">ğ‘</ci><ci id="A0.SS2.p2.5.m5.1.1.6.cmml" xref="A0.SS2.p2.5.m5.1.1.6">ğ‘‘</ci><apply id="A0.SS2.p2.5.m5.1.1.7.cmml" xref="A0.SS2.p2.5.m5.1.1.7"><csymbol cd="ambiguous" id="A0.SS2.p2.5.m5.1.1.7.1.cmml" xref="A0.SS2.p2.5.m5.1.1.7">subscript</csymbol><ci id="A0.SS2.p2.5.m5.1.1.7.2.cmml" xref="A0.SS2.p2.5.m5.1.1.7.2">ğ‘</ci><cn type="integer" id="A0.SS2.p2.5.m5.1.1.7.3.cmml" xref="A0.SS2.p2.5.m5.1.1.7.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A0.SS2.p2.5.m5.1c">lambda_{2}</annotation></semantics></math> is 5, 2, 5 for <span id="A0.SS2.p2.6.2" class="ltx_text ltx_font_italic">car, plane and chair</span>. <math id="A0.SS2.p2.6.m6.1" class="ltx_Math" alttext="\lambda_{3}" display="inline"><semantics id="A0.SS2.p2.6.m6.1a"><msub id="A0.SS2.p2.6.m6.1.1" xref="A0.SS2.p2.6.m6.1.1.cmml"><mi id="A0.SS2.p2.6.m6.1.1.2" xref="A0.SS2.p2.6.m6.1.1.2.cmml">Î»</mi><mn id="A0.SS2.p2.6.m6.1.1.3" xref="A0.SS2.p2.6.m6.1.1.3.cmml">3</mn></msub><annotation-xml encoding="MathML-Content" id="A0.SS2.p2.6.m6.1b"><apply id="A0.SS2.p2.6.m6.1.1.cmml" xref="A0.SS2.p2.6.m6.1.1"><csymbol cd="ambiguous" id="A0.SS2.p2.6.m6.1.1.1.cmml" xref="A0.SS2.p2.6.m6.1.1">subscript</csymbol><ci id="A0.SS2.p2.6.m6.1.1.2.cmml" xref="A0.SS2.p2.6.m6.1.1.2">ğœ†</ci><cn type="integer" id="A0.SS2.p2.6.m6.1.1.3.cmml" xref="A0.SS2.p2.6.m6.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A0.SS2.p2.6.m6.1c">\lambda_{3}</annotation></semantics></math> is 1e2, 1e2 and 5e1 for each of the above categories.</p>
</div>
<div id="A0.SS2.p3" class="ltx_para">
<p id="A0.SS2.p3.2" class="ltx_p"><span id="A0.SS2.p3.2.1" class="ltx_text ltx_font_bold">Inference Details</span>
We jointly optimize the object pose and shape using the Adam optmizer with a learning rate of <math id="A0.SS2.p3.1.m1.1" class="ltx_Math" alttext="0.001" display="inline"><semantics id="A0.SS2.p3.1.m1.1a"><mn id="A0.SS2.p3.1.m1.1.1" xref="A0.SS2.p3.1.m1.1.1.cmml">0.001</mn><annotation-xml encoding="MathML-Content" id="A0.SS2.p3.1.m1.1b"><cn type="float" id="A0.SS2.p3.1.m1.1.1.cmml" xref="A0.SS2.p3.1.m1.1.1">0.001</cn></annotation-xml><annotation encoding="application/x-tex" id="A0.SS2.p3.1.m1.1c">0.001</annotation></semantics></math> for the shape and <math id="A0.SS2.p3.2.m2.1" class="ltx_Math" alttext="0.01" display="inline"><semantics id="A0.SS2.p3.2.m2.1a"><mn id="A0.SS2.p3.2.m2.1.1" xref="A0.SS2.p3.2.m2.1.1.cmml">0.01</mn><annotation-xml encoding="MathML-Content" id="A0.SS2.p3.2.m2.1b"><cn type="float" id="A0.SS2.p3.2.m2.1.1.cmml" xref="A0.SS2.p3.2.m2.1.1">0.01</cn></annotation-xml><annotation encoding="application/x-tex" id="A0.SS2.p3.2.m2.1c">0.01</annotation></semantics></math> for the pose. We optimize each shape for a total of 30 iterations, taking roughly 4 seconds.</p>
</div>
<div id="A0.SS2.p4" class="ltx_para">
<p id="A0.SS2.p4.1" class="ltx_p"><span id="A0.SS2.p4.1.1" class="ltx_text ltx_font_bold">Equi-pose</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>:
In this paper, we directly apply Equi-pose as an off-the-shelf pose estimation module. Since our method does not require accurate camera poses but rough initialization, we use the model weights trained on ModelNet40Â <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite> provided by the authors for all the experiments in this paper.</p>
</div>
</section>
<section id="A0.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="A0.SS3.5.1.1" class="ltx_text">-C</span> </span><span id="A0.SS3.6.2" class="ltx_text ltx_font_italic">Baselines</span>
</h3>

<div id="A0.SS3.p1" class="ltx_para">
<p id="A0.SS3.p1.1" class="ltx_p"><span id="A0.SS3.p1.1.1" class="ltx_text ltx_font_bold">SDF-SRN</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>:
We directly use the source code and pre-trained weights for Pascal3D+ and Shapenet provided by the original authors. In this paper, we follow SDF-SRNâ€™s test split for Pascal3D+ dataset. As for Shapenet, we take the union between our test set and SDF-SRNâ€™s test set as the Shapenet test set.</p>
</div>
<div id="A0.SS3.p2" class="ltx_para">
<p id="A0.SS3.p2.1" class="ltx_p"><span id="A0.SS3.p2.1.1" class="ltx_text ltx_font_bold">TARS-3D</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>:
We use the original implementation of TARS-3D from the authors. Since TARS-3D follows the same dataset setup as SDF-SRN, we use the network weights trained on Shapenet provided by the authors.</p>
</div>
<div id="A0.SS3.p3" class="ltx_para">
<p id="A0.SS3.p3.1" class="ltx_p"><span id="A0.SS3.p3.1.1" class="ltx_text ltx_font_bold">PoinTr</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite>:
We directly adopt the original code and network weights trained on Shapenet provided by the authors. For fair comparison, we transform the input partial point clouds into their coordinate frame with both ground truth and estimated camera poses. Furthermore, we follow their original training setup where the input point clouds are downsampled to 2048 points using farthest point sampling, and predict 8192 points as the complete point cloud.</p>
</div>
</section>
<section id="A0.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="A0.SS4.5.1.1" class="ltx_text">-D</span> </span><span id="A0.SS4.6.2" class="ltx_text ltx_font_italic">Additional Results</span>
</h3>

<div id="A0.SS4.p1" class="ltx_para">
<p id="A0.SS4.p1.1" class="ltx_p"><span id="A0.SS4.p1.1.1" class="ltx_text ltx_font_bold">Extracted Template Shapes</span>
Here we show the extracted template shapes from our pretrained 3D prior network. We extract the zero-level set of the neural field using marching cubes. We can observe that the template represents shapes close to the â€meanâ€ object for cars and chairs. For planes however, the neural field does not represent an object, but fuses common aspects of different shapes together.</p>
</div>
<figure id="A0.F6" class="ltx_figure"><img src="/html/2302.12883/assets/x9.png" id="A0.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="145" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Extracted learned template shapes</figcaption>
</figure>
<figure id="A0.F7" class="ltx_figure"><img src="/html/2302.12883/assets/x10.png" id="A0.F7.g1" class="ltx_graphics ltx_centering ltx_img_square" width="461" height="517" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Additional results on the Pascal3D+ dataset</figcaption>
</figure>
<figure id="A0.F8" class="ltx_figure"><img src="/html/2302.12883/assets/x11.png" id="A0.F8.g1" class="ltx_graphics ltx_centering ltx_img_square" width="461" height="446" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Additional results on the Pix3D dataset</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2302.12882" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2302.12883" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2302.12883">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2302.12883" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2302.12884" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Mar  1 00:07:29 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
