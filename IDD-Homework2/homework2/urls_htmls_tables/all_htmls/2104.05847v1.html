<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2104.05847] Targeted Adversarial Training for Natural Language Understanding</title><meta property="og:description" content="We present a simple yet effective Targeted Adversarial Training (TAT) algorithm to improve adversarial training for natural language understanding. The key idea is to introspect current mistakes and prioritize adversar…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Targeted Adversarial Training for Natural Language Understanding">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Targeted Adversarial Training for Natural Language Understanding">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2104.05847">

<!--Generated on Thu Mar  7 00:50:07 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">
Targeted Adversarial Training for Natural Language Understanding
</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Lis Pereira<sup id="id2.2.id1" class="ltx_sup">1</sup>, Xiaodong Liu<sup id="id3.3.id2" class="ltx_sup">2</sup><sup id="id4.4.id3" class="ltx_sup">∗</sup>, Hao Cheng<sup id="id5.5.id4" class="ltx_sup">2</sup>, Hoifung Poon<sup id="id6.6.id5" class="ltx_sup">2</sup>, Jianfeng Gao<sup id="id7.7.id6" class="ltx_sup">2</sup>, Ichiro Kobayashi<sup id="id8.8.id7" class="ltx_sup">1</sup>

<br class="ltx_break"><sup id="id9.9.id8" class="ltx_sup">1</sup> Ochanomizu University       
<sup id="id10.10.id9" class="ltx_sup">2</sup> Microsoft Research 
<br class="ltx_break"><span id="id11.11.id10" class="ltx_text ltx_font_typewriter">{kanashiro.pereira,kobayashi.ichiro}@ocha.ac.jp</span> 
<br class="ltx_break"><span id="id12.12.id11" class="ltx_text ltx_font_typewriter">{xiaodl,chehao,hoifung,jfgao}@microsoft.com</span>
</span><span class="ltx_author_notes">  Equal contribution.</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id13.id1" class="ltx_p">We present a simple yet effective <span id="id13.id1.1" class="ltx_text ltx_font_bold">T</span>argeted <span id="id13.id1.2" class="ltx_text ltx_font_bold">A</span>dversarial <span id="id13.id1.3" class="ltx_text ltx_font_bold">T</span>raining (<span id="id13.id1.4" class="ltx_text ltx_font_bold">TAT</span>) algorithm to improve adversarial training for natural language understanding. The key idea is to introspect current mistakes and prioritize adversarial training steps to where the model errs the most. Experiments show that TAT can significantly improve accuracy over standard adversarial training on GLUE and attain new state-of-the-art zero-shot results on XNLI. Our code will be released at: <a target="_blank" href="https://github.com/namisan/mt-dnn" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/namisan/mt-dnn</a>.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Adversarial training has proven effective in improving model generalization and robustness in computer vision <cite class="ltx_cite ltx_citemacro_cite">Madry et al. (<a href="#bib.bib30" title="" class="ltx_ref">2017</a>); Goodfellow et al. (<a href="#bib.bib17" title="" class="ltx_ref">2014</a>)</cite> and natural language processing (NLP) <cite class="ltx_cite ltx_citemacro_cite">Zhu et al. (<a href="#bib.bib43" title="" class="ltx_ref">2019</a>); Jiang et al. (<a href="#bib.bib21" title="" class="ltx_ref">2019</a>); Cheng et al. (<a href="#bib.bib8" title="" class="ltx_ref">2019</a>); Liu et al. (<a href="#bib.bib28" title="" class="ltx_ref">2020a</a>); Pereira et al. (<a href="#bib.bib33" title="" class="ltx_ref">2020</a>); Cheng et al. (<a href="#bib.bib7" title="" class="ltx_ref">2020</a>)</cite>.</p>
</div>
<figure id="S1.F1" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S1.F1.sf1" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S1.F1.sf1.1" class="ltx_inline-block ltx_transformed_outer" style="width:395.5pt;height:274.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="S1.F1.sf1.1.1" class="ltx_p"><span id="S1.F1.sf1.1.1.1" class="ltx_text ltx_inline-block" style="width:395.5pt;position:relative; bottom:-11.7pt;">
<img src="/html/2104.05847/assets/figures/mnli-bs-cmt.png" id="S1.F1.sf1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="538" height="404" alt="Refer to caption"></span></p>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>BERT with standard fine-tuning</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S1.F1.sf2" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S1.F1.sf2.1" class="ltx_inline-block ltx_transformed_outer" style="width:395.5pt;height:274.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="S1.F1.sf2.1.1" class="ltx_p"><span id="S1.F1.sf2.1.1.1" class="ltx_text ltx_inline-block" style="width:395.5pt;position:relative; bottom:-11.7pt;">
<img src="/html/2104.05847/assets/figures/mnli-tat-cmt.png" id="S1.F1.sf2.1.1.1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="538" height="404" alt="Refer to caption"></span></p>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>BERT with TAT fine-tuning</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>
Comparison of confusion matrices on MNLI development set (in-domain). X-axis and Y-axis represent the predicted and gold labels, respectively. TAT produces an accuracy gain of 1.7 absolute points.
</figcaption>
</figure>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">It works by augmenting the input with a small perturbation to steer the current model prediction away from the correct label, thus forcing subsequent training to make the model more robust and generalizable. Aside from some prior work in computer vision <cite class="ltx_cite ltx_citemacro_cite">Dong et al. (<a href="#bib.bib15" title="" class="ltx_ref">2018</a>); Tramèr et al. (<a href="#bib.bib38" title="" class="ltx_ref">2017</a>)</cite>, most adversarial training approaches adopt <span id="S1.p2.1.1" class="ltx_text ltx_font_italic">non-targeted</span> attacks, where the model prediction is not driven towards a specific incorrect label. In NLP, the cutting-edge research in adversarial training tends to focus on making adversarial training less expensive (e.g., by reusing backward steps in FreeLB <cite class="ltx_cite ltx_citemacro_cite">Zhu et al. (<a href="#bib.bib43" title="" class="ltx_ref">2019</a>)</cite>) or regularizing rather than replacing the standard training objective (e.g., in virtual adversarial training (VAT) <cite class="ltx_cite ltx_citemacro_cite">Jiang et al. (<a href="#bib.bib21" title="" class="ltx_ref">2019</a>)</cite>).</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">By contrast, in this paper, we investigate an orthogonal direction by augmenting adversarial training with introspection capability and adopting <span id="S1.p3.1.1" class="ltx_text ltx_font_italic">targeted</span> attacks to focus on where the model errs the most. We observe that in many NLP applications, the error patterns are non-uniform. For example, in the MNLI development set (in-domain), standard fine-tuned BERT model tends to misclassify a non-neutral instance as “neutral” more often than the opposite label (Figure <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Targeted Adversarial Training for Natural Language Understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> top). We thus propose <span id="S1.p3.1.2" class="ltx_text ltx_font_italic">Targeted Adversarial Training</span> (TAT), a simple yet effective algorithm for adversarial training. For each instance, instead of taking adversarial steps <span id="S1.p3.1.3" class="ltx_text ltx_font_italic">away</span> from the gold label, TAT samples an incorrect label proportional to how often the current model makes the same error in general, and takes adversarial steps <span id="S1.p3.1.4" class="ltx_text ltx_font_italic">towards</span> the chosen incorrect label.
To our knowledge, this is the first attempt to apply targeted adversarial training to NLP tasks.
In our experiments, this leads to significant improvement over standard non-adversarial and adversarial training alike. For example, in the MNLI development set, TAT produced an accuracy gain of 1.7 absolute points (Figure <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Targeted Adversarial Training for Natural Language Understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> bottom). On the overall GLUE benchmark, TAT outperforms state-of-the-art non-targeted adversarial training methods such as FreeLB and VAT, and enables the BERT<sub id="S1.p3.1.5" class="ltx_sub">BASE</sub> model to perform comparably to the BERT<sub id="S1.p3.1.6" class="ltx_sub">LARGE</sub> model with standard training. The benefit of TAT is particularly pronounced in out-domain settings, such as in zero-shot learning in natural language inference, attaining new state-of-the-art cross-lingual results on XNLI.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Targeted Adversarial Training (TAT)</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">In this paper, we focus on fine-tuning BERT models <cite class="ltx_cite ltx_citemacro_cite">Devlin et al. (<a href="#bib.bib13" title="" class="ltx_ref">2018</a>)</cite> in our investigation of targeted adversarial training, as this approach has proven very effective for a wide range of NLP tasks.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.6" class="ltx_p">The training algorithm seeks to learn a function <math id="S2.p2.1.m1.2" class="ltx_Math" alttext="f(x;\theta):x\rightarrow C" display="inline"><semantics id="S2.p2.1.m1.2a"><mrow id="S2.p2.1.m1.2.3" xref="S2.p2.1.m1.2.3.cmml"><mrow id="S2.p2.1.m1.2.3.2" xref="S2.p2.1.m1.2.3.2.cmml"><mi id="S2.p2.1.m1.2.3.2.2" xref="S2.p2.1.m1.2.3.2.2.cmml">f</mi><mo lspace="0em" rspace="0em" id="S2.p2.1.m1.2.3.2.1" xref="S2.p2.1.m1.2.3.2.1.cmml">​</mo><mrow id="S2.p2.1.m1.2.3.2.3.2" xref="S2.p2.1.m1.2.3.2.3.1.cmml"><mo stretchy="false" id="S2.p2.1.m1.2.3.2.3.2.1" xref="S2.p2.1.m1.2.3.2.3.1.cmml">(</mo><mi id="S2.p2.1.m1.1.1" xref="S2.p2.1.m1.1.1.cmml">x</mi><mo id="S2.p2.1.m1.2.3.2.3.2.2" xref="S2.p2.1.m1.2.3.2.3.1.cmml">;</mo><mi id="S2.p2.1.m1.2.2" xref="S2.p2.1.m1.2.2.cmml">θ</mi><mo rspace="0.278em" stretchy="false" id="S2.p2.1.m1.2.3.2.3.2.3" xref="S2.p2.1.m1.2.3.2.3.1.cmml">)</mo></mrow></mrow><mo rspace="0.278em" id="S2.p2.1.m1.2.3.1" xref="S2.p2.1.m1.2.3.1.cmml">:</mo><mrow id="S2.p2.1.m1.2.3.3" xref="S2.p2.1.m1.2.3.3.cmml"><mi id="S2.p2.1.m1.2.3.3.2" xref="S2.p2.1.m1.2.3.3.2.cmml">x</mi><mo stretchy="false" id="S2.p2.1.m1.2.3.3.1" xref="S2.p2.1.m1.2.3.3.1.cmml">→</mo><mi id="S2.p2.1.m1.2.3.3.3" xref="S2.p2.1.m1.2.3.3.3.cmml">C</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p2.1.m1.2b"><apply id="S2.p2.1.m1.2.3.cmml" xref="S2.p2.1.m1.2.3"><ci id="S2.p2.1.m1.2.3.1.cmml" xref="S2.p2.1.m1.2.3.1">:</ci><apply id="S2.p2.1.m1.2.3.2.cmml" xref="S2.p2.1.m1.2.3.2"><times id="S2.p2.1.m1.2.3.2.1.cmml" xref="S2.p2.1.m1.2.3.2.1"></times><ci id="S2.p2.1.m1.2.3.2.2.cmml" xref="S2.p2.1.m1.2.3.2.2">𝑓</ci><list id="S2.p2.1.m1.2.3.2.3.1.cmml" xref="S2.p2.1.m1.2.3.2.3.2"><ci id="S2.p2.1.m1.1.1.cmml" xref="S2.p2.1.m1.1.1">𝑥</ci><ci id="S2.p2.1.m1.2.2.cmml" xref="S2.p2.1.m1.2.2">𝜃</ci></list></apply><apply id="S2.p2.1.m1.2.3.3.cmml" xref="S2.p2.1.m1.2.3.3"><ci id="S2.p2.1.m1.2.3.3.1.cmml" xref="S2.p2.1.m1.2.3.3.1">→</ci><ci id="S2.p2.1.m1.2.3.3.2.cmml" xref="S2.p2.1.m1.2.3.3.2">𝑥</ci><ci id="S2.p2.1.m1.2.3.3.3.cmml" xref="S2.p2.1.m1.2.3.3.3">𝐶</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.1.m1.2c">f(x;\theta):x\rightarrow C</annotation></semantics></math> as parametrized by <math id="S2.p2.2.m2.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="S2.p2.2.m2.1a"><mi id="S2.p2.2.m2.1.1" xref="S2.p2.2.m2.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="S2.p2.2.m2.1b"><ci id="S2.p2.2.m2.1.1.cmml" xref="S2.p2.2.m2.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.2.m2.1c">\theta</annotation></semantics></math>, where <math id="S2.p2.3.m3.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S2.p2.3.m3.1a"><mi id="S2.p2.3.m3.1.1" xref="S2.p2.3.m3.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S2.p2.3.m3.1b"><ci id="S2.p2.3.m3.1.1.cmml" xref="S2.p2.3.m3.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.3.m3.1c">C</annotation></semantics></math> is the class label set.
Given a training dataset <math id="S2.p2.4.m4.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S2.p2.4.m4.1a"><mi id="S2.p2.4.m4.1.1" xref="S2.p2.4.m4.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S2.p2.4.m4.1b"><ci id="S2.p2.4.m4.1.1.cmml" xref="S2.p2.4.m4.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.4.m4.1c">D</annotation></semantics></math> of input-output pairs <math id="S2.p2.5.m5.2" class="ltx_Math" alttext="(x,y)" display="inline"><semantics id="S2.p2.5.m5.2a"><mrow id="S2.p2.5.m5.2.3.2" xref="S2.p2.5.m5.2.3.1.cmml"><mo stretchy="false" id="S2.p2.5.m5.2.3.2.1" xref="S2.p2.5.m5.2.3.1.cmml">(</mo><mi id="S2.p2.5.m5.1.1" xref="S2.p2.5.m5.1.1.cmml">x</mi><mo id="S2.p2.5.m5.2.3.2.2" xref="S2.p2.5.m5.2.3.1.cmml">,</mo><mi id="S2.p2.5.m5.2.2" xref="S2.p2.5.m5.2.2.cmml">y</mi><mo stretchy="false" id="S2.p2.5.m5.2.3.2.3" xref="S2.p2.5.m5.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.p2.5.m5.2b"><interval closure="open" id="S2.p2.5.m5.2.3.1.cmml" xref="S2.p2.5.m5.2.3.2"><ci id="S2.p2.5.m5.1.1.cmml" xref="S2.p2.5.m5.1.1">𝑥</ci><ci id="S2.p2.5.m5.2.2.cmml" xref="S2.p2.5.m5.2.2">𝑦</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.5.m5.2c">(x,y)</annotation></semantics></math> and the loss function <math id="S2.p2.6.m6.1" class="ltx_math_unparsed" alttext="l(.,.)" display="inline"><semantics id="S2.p2.6.m6.1a"><mrow id="S2.p2.6.m6.1b"><mi id="S2.p2.6.m6.1.1">l</mi><mrow id="S2.p2.6.m6.1.2"><mo stretchy="false" id="S2.p2.6.m6.1.2.1">(</mo><mo lspace="0em" rspace="0.167em" id="S2.p2.6.m6.1.2.2">.</mo><mo id="S2.p2.6.m6.1.2.3">,</mo><mo lspace="0em" rspace="0.167em" id="S2.p2.6.m6.1.2.4">.</mo><mo stretchy="false" id="S2.p2.6.m6.1.2.5">)</mo></mrow></mrow><annotation encoding="application/x-tex" id="S2.p2.6.m6.1c">l(.,.)</annotation></semantics></math> (e.g., cross entropy), the standard training objective would minimize the empirical risk:</p>
<table id="S2.Ex1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.Ex1.m1.6" class="ltx_Math" alttext="\min_{\theta}\mathbb{E}_{(x,y)\sim D}[l(f(x;\theta),y)]." display="block"><semantics id="S2.Ex1.m1.6a"><mrow id="S2.Ex1.m1.6.6.1" xref="S2.Ex1.m1.6.6.1.1.cmml"><mrow id="S2.Ex1.m1.6.6.1.1" xref="S2.Ex1.m1.6.6.1.1.cmml"><mrow id="S2.Ex1.m1.6.6.1.1.3" xref="S2.Ex1.m1.6.6.1.1.3.cmml"><munder id="S2.Ex1.m1.6.6.1.1.3.1" xref="S2.Ex1.m1.6.6.1.1.3.1.cmml"><mi id="S2.Ex1.m1.6.6.1.1.3.1.2" xref="S2.Ex1.m1.6.6.1.1.3.1.2.cmml">min</mi><mi id="S2.Ex1.m1.6.6.1.1.3.1.3" xref="S2.Ex1.m1.6.6.1.1.3.1.3.cmml">θ</mi></munder><mo lspace="0.167em" id="S2.Ex1.m1.6.6.1.1.3a" xref="S2.Ex1.m1.6.6.1.1.3.cmml">⁡</mo><msub id="S2.Ex1.m1.6.6.1.1.3.2" xref="S2.Ex1.m1.6.6.1.1.3.2.cmml"><mi id="S2.Ex1.m1.6.6.1.1.3.2.2" xref="S2.Ex1.m1.6.6.1.1.3.2.2.cmml">𝔼</mi><mrow id="S2.Ex1.m1.2.2.2" xref="S2.Ex1.m1.2.2.2.cmml"><mrow id="S2.Ex1.m1.2.2.2.4.2" xref="S2.Ex1.m1.2.2.2.4.1.cmml"><mo stretchy="false" id="S2.Ex1.m1.2.2.2.4.2.1" xref="S2.Ex1.m1.2.2.2.4.1.cmml">(</mo><mi id="S2.Ex1.m1.1.1.1.1" xref="S2.Ex1.m1.1.1.1.1.cmml">x</mi><mo id="S2.Ex1.m1.2.2.2.4.2.2" xref="S2.Ex1.m1.2.2.2.4.1.cmml">,</mo><mi id="S2.Ex1.m1.2.2.2.2" xref="S2.Ex1.m1.2.2.2.2.cmml">y</mi><mo stretchy="false" id="S2.Ex1.m1.2.2.2.4.2.3" xref="S2.Ex1.m1.2.2.2.4.1.cmml">)</mo></mrow><mo id="S2.Ex1.m1.2.2.2.3" xref="S2.Ex1.m1.2.2.2.3.cmml">∼</mo><mi id="S2.Ex1.m1.2.2.2.5" xref="S2.Ex1.m1.2.2.2.5.cmml">D</mi></mrow></msub></mrow><mo lspace="0em" rspace="0em" id="S2.Ex1.m1.6.6.1.1.2" xref="S2.Ex1.m1.6.6.1.1.2.cmml">​</mo><mrow id="S2.Ex1.m1.6.6.1.1.1.1" xref="S2.Ex1.m1.6.6.1.1.1.2.cmml"><mo stretchy="false" id="S2.Ex1.m1.6.6.1.1.1.1.2" xref="S2.Ex1.m1.6.6.1.1.1.2.1.cmml">[</mo><mrow id="S2.Ex1.m1.6.6.1.1.1.1.1" xref="S2.Ex1.m1.6.6.1.1.1.1.1.cmml"><mi id="S2.Ex1.m1.6.6.1.1.1.1.1.3" xref="S2.Ex1.m1.6.6.1.1.1.1.1.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S2.Ex1.m1.6.6.1.1.1.1.1.2" xref="S2.Ex1.m1.6.6.1.1.1.1.1.2.cmml">​</mo><mrow id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.2" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.2.cmml">(</mo><mrow id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.cmml"><mi id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.2" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.2.cmml">f</mi><mo lspace="0em" rspace="0em" id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.cmml">​</mo><mrow id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.3.2" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.3.1.cmml"><mo stretchy="false" id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.3.2.1" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.3.1.cmml">(</mo><mi id="S2.Ex1.m1.3.3" xref="S2.Ex1.m1.3.3.cmml">x</mi><mo id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.3.2.2" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.3.1.cmml">;</mo><mi id="S2.Ex1.m1.4.4" xref="S2.Ex1.m1.4.4.cmml">θ</mi><mo stretchy="false" id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.3.2.3" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.3.1.cmml">)</mo></mrow></mrow><mo id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.3" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.2.cmml">,</mo><mi id="S2.Ex1.m1.5.5" xref="S2.Ex1.m1.5.5.cmml">y</mi><mo stretchy="false" id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.4" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S2.Ex1.m1.6.6.1.1.1.1.3" xref="S2.Ex1.m1.6.6.1.1.1.2.1.cmml">]</mo></mrow></mrow><mo lspace="0em" id="S2.Ex1.m1.6.6.1.2" xref="S2.Ex1.m1.6.6.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.Ex1.m1.6b"><apply id="S2.Ex1.m1.6.6.1.1.cmml" xref="S2.Ex1.m1.6.6.1"><times id="S2.Ex1.m1.6.6.1.1.2.cmml" xref="S2.Ex1.m1.6.6.1.1.2"></times><apply id="S2.Ex1.m1.6.6.1.1.3.cmml" xref="S2.Ex1.m1.6.6.1.1.3"><apply id="S2.Ex1.m1.6.6.1.1.3.1.cmml" xref="S2.Ex1.m1.6.6.1.1.3.1"><csymbol cd="ambiguous" id="S2.Ex1.m1.6.6.1.1.3.1.1.cmml" xref="S2.Ex1.m1.6.6.1.1.3.1">subscript</csymbol><min id="S2.Ex1.m1.6.6.1.1.3.1.2.cmml" xref="S2.Ex1.m1.6.6.1.1.3.1.2"></min><ci id="S2.Ex1.m1.6.6.1.1.3.1.3.cmml" xref="S2.Ex1.m1.6.6.1.1.3.1.3">𝜃</ci></apply><apply id="S2.Ex1.m1.6.6.1.1.3.2.cmml" xref="S2.Ex1.m1.6.6.1.1.3.2"><csymbol cd="ambiguous" id="S2.Ex1.m1.6.6.1.1.3.2.1.cmml" xref="S2.Ex1.m1.6.6.1.1.3.2">subscript</csymbol><ci id="S2.Ex1.m1.6.6.1.1.3.2.2.cmml" xref="S2.Ex1.m1.6.6.1.1.3.2.2">𝔼</ci><apply id="S2.Ex1.m1.2.2.2.cmml" xref="S2.Ex1.m1.2.2.2"><csymbol cd="latexml" id="S2.Ex1.m1.2.2.2.3.cmml" xref="S2.Ex1.m1.2.2.2.3">similar-to</csymbol><interval closure="open" id="S2.Ex1.m1.2.2.2.4.1.cmml" xref="S2.Ex1.m1.2.2.2.4.2"><ci id="S2.Ex1.m1.1.1.1.1.cmml" xref="S2.Ex1.m1.1.1.1.1">𝑥</ci><ci id="S2.Ex1.m1.2.2.2.2.cmml" xref="S2.Ex1.m1.2.2.2.2">𝑦</ci></interval><ci id="S2.Ex1.m1.2.2.2.5.cmml" xref="S2.Ex1.m1.2.2.2.5">𝐷</ci></apply></apply></apply><apply id="S2.Ex1.m1.6.6.1.1.1.2.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1"><csymbol cd="latexml" id="S2.Ex1.m1.6.6.1.1.1.2.1.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.2">delimited-[]</csymbol><apply id="S2.Ex1.m1.6.6.1.1.1.1.1.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.1"><times id="S2.Ex1.m1.6.6.1.1.1.1.1.2.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.1.2"></times><ci id="S2.Ex1.m1.6.6.1.1.1.1.1.3.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.1.3">𝑙</ci><interval closure="open" id="S2.Ex1.m1.6.6.1.1.1.1.1.1.2.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1"><apply id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1"><times id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1"></times><ci id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.2.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.2">𝑓</ci><list id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.3.1.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.3.2"><ci id="S2.Ex1.m1.3.3.cmml" xref="S2.Ex1.m1.3.3">𝑥</ci><ci id="S2.Ex1.m1.4.4.cmml" xref="S2.Ex1.m1.4.4">𝜃</ci></list></apply><ci id="S2.Ex1.m1.5.5.cmml" xref="S2.Ex1.m1.5.5">𝑦</ci></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex1.m1.6c">\min_{\theta}\mathbb{E}_{(x,y)\sim D}[l(f(x;\theta),y)].</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">By contrast, in adversarial training, as pioneered in computer vision <cite class="ltx_cite ltx_citemacro_cite">Goodfellow et al. (<a href="#bib.bib17" title="" class="ltx_ref">2014</a>); Hsieh et al. (<a href="#bib.bib20" title="" class="ltx_ref">2019</a>); Madry et al. (<a href="#bib.bib30" title="" class="ltx_ref">2017</a>); Jin et al. (<a href="#bib.bib22" title="" class="ltx_ref">2019</a>)</cite>, the input would be augmented with a small perturbation that maximize the adversarial loss:</p>
<table id="S2.Ex2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.Ex2.m1.5" class="ltx_Math" alttext="\min_{\theta}\mathbb{E}_{(x,y)\sim D}[\max_{\delta}l(f(x+\delta;\theta),y)]," display="block"><semantics id="S2.Ex2.m1.5a"><mrow id="S2.Ex2.m1.5.5.1" xref="S2.Ex2.m1.5.5.1.1.cmml"><mrow id="S2.Ex2.m1.5.5.1.1" xref="S2.Ex2.m1.5.5.1.1.cmml"><mrow id="S2.Ex2.m1.5.5.1.1.3" xref="S2.Ex2.m1.5.5.1.1.3.cmml"><munder id="S2.Ex2.m1.5.5.1.1.3.1" xref="S2.Ex2.m1.5.5.1.1.3.1.cmml"><mi id="S2.Ex2.m1.5.5.1.1.3.1.2" xref="S2.Ex2.m1.5.5.1.1.3.1.2.cmml">min</mi><mi id="S2.Ex2.m1.5.5.1.1.3.1.3" xref="S2.Ex2.m1.5.5.1.1.3.1.3.cmml">θ</mi></munder><mo lspace="0.167em" id="S2.Ex2.m1.5.5.1.1.3a" xref="S2.Ex2.m1.5.5.1.1.3.cmml">⁡</mo><msub id="S2.Ex2.m1.5.5.1.1.3.2" xref="S2.Ex2.m1.5.5.1.1.3.2.cmml"><mi id="S2.Ex2.m1.5.5.1.1.3.2.2" xref="S2.Ex2.m1.5.5.1.1.3.2.2.cmml">𝔼</mi><mrow id="S2.Ex2.m1.2.2.2" xref="S2.Ex2.m1.2.2.2.cmml"><mrow id="S2.Ex2.m1.2.2.2.4.2" xref="S2.Ex2.m1.2.2.2.4.1.cmml"><mo stretchy="false" id="S2.Ex2.m1.2.2.2.4.2.1" xref="S2.Ex2.m1.2.2.2.4.1.cmml">(</mo><mi id="S2.Ex2.m1.1.1.1.1" xref="S2.Ex2.m1.1.1.1.1.cmml">x</mi><mo id="S2.Ex2.m1.2.2.2.4.2.2" xref="S2.Ex2.m1.2.2.2.4.1.cmml">,</mo><mi id="S2.Ex2.m1.2.2.2.2" xref="S2.Ex2.m1.2.2.2.2.cmml">y</mi><mo stretchy="false" id="S2.Ex2.m1.2.2.2.4.2.3" xref="S2.Ex2.m1.2.2.2.4.1.cmml">)</mo></mrow><mo id="S2.Ex2.m1.2.2.2.3" xref="S2.Ex2.m1.2.2.2.3.cmml">∼</mo><mi id="S2.Ex2.m1.2.2.2.5" xref="S2.Ex2.m1.2.2.2.5.cmml">D</mi></mrow></msub></mrow><mo lspace="0em" rspace="0em" id="S2.Ex2.m1.5.5.1.1.2" xref="S2.Ex2.m1.5.5.1.1.2.cmml">​</mo><mrow id="S2.Ex2.m1.5.5.1.1.1.1" xref="S2.Ex2.m1.5.5.1.1.1.2.cmml"><mo stretchy="false" id="S2.Ex2.m1.5.5.1.1.1.1.2" xref="S2.Ex2.m1.5.5.1.1.1.2.1.cmml">[</mo><mrow id="S2.Ex2.m1.5.5.1.1.1.1.1" xref="S2.Ex2.m1.5.5.1.1.1.1.1.cmml"><mrow id="S2.Ex2.m1.5.5.1.1.1.1.1.3" xref="S2.Ex2.m1.5.5.1.1.1.1.1.3.cmml"><munder id="S2.Ex2.m1.5.5.1.1.1.1.1.3.1" xref="S2.Ex2.m1.5.5.1.1.1.1.1.3.1.cmml"><mi id="S2.Ex2.m1.5.5.1.1.1.1.1.3.1.2" xref="S2.Ex2.m1.5.5.1.1.1.1.1.3.1.2.cmml">max</mi><mi id="S2.Ex2.m1.5.5.1.1.1.1.1.3.1.3" xref="S2.Ex2.m1.5.5.1.1.1.1.1.3.1.3.cmml">δ</mi></munder><mo lspace="0.167em" id="S2.Ex2.m1.5.5.1.1.1.1.1.3a" xref="S2.Ex2.m1.5.5.1.1.1.1.1.3.cmml">⁡</mo><mi id="S2.Ex2.m1.5.5.1.1.1.1.1.3.2" xref="S2.Ex2.m1.5.5.1.1.1.1.1.3.2.cmml">l</mi></mrow><mo lspace="0em" rspace="0em" id="S2.Ex2.m1.5.5.1.1.1.1.1.2" xref="S2.Ex2.m1.5.5.1.1.1.1.1.2.cmml">​</mo><mrow id="S2.Ex2.m1.5.5.1.1.1.1.1.1.1" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.2" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.2.cmml">(</mo><mrow id="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.cmml"><mi id="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.3" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.3.cmml">f</mi><mo lspace="0em" rspace="0em" id="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.2" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.2.cmml">​</mo><mrow id="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.1" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.1.2" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.2.cmml">(</mo><mrow id="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.1.1" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.2" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.2.cmml">x</mi><mo id="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1.cmml">+</mo><mi id="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.3" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.3.cmml">δ</mi></mrow><mo id="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.1.3" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.2.cmml">;</mo><mi id="S2.Ex2.m1.3.3" xref="S2.Ex2.m1.3.3.cmml">θ</mi><mo stretchy="false" id="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.1.4" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.3" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.2.cmml">,</mo><mi id="S2.Ex2.m1.4.4" xref="S2.Ex2.m1.4.4.cmml">y</mi><mo stretchy="false" id="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.4" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S2.Ex2.m1.5.5.1.1.1.1.3" xref="S2.Ex2.m1.5.5.1.1.1.2.1.cmml">]</mo></mrow></mrow><mo id="S2.Ex2.m1.5.5.1.2" xref="S2.Ex2.m1.5.5.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.Ex2.m1.5b"><apply id="S2.Ex2.m1.5.5.1.1.cmml" xref="S2.Ex2.m1.5.5.1"><times id="S2.Ex2.m1.5.5.1.1.2.cmml" xref="S2.Ex2.m1.5.5.1.1.2"></times><apply id="S2.Ex2.m1.5.5.1.1.3.cmml" xref="S2.Ex2.m1.5.5.1.1.3"><apply id="S2.Ex2.m1.5.5.1.1.3.1.cmml" xref="S2.Ex2.m1.5.5.1.1.3.1"><csymbol cd="ambiguous" id="S2.Ex2.m1.5.5.1.1.3.1.1.cmml" xref="S2.Ex2.m1.5.5.1.1.3.1">subscript</csymbol><min id="S2.Ex2.m1.5.5.1.1.3.1.2.cmml" xref="S2.Ex2.m1.5.5.1.1.3.1.2"></min><ci id="S2.Ex2.m1.5.5.1.1.3.1.3.cmml" xref="S2.Ex2.m1.5.5.1.1.3.1.3">𝜃</ci></apply><apply id="S2.Ex2.m1.5.5.1.1.3.2.cmml" xref="S2.Ex2.m1.5.5.1.1.3.2"><csymbol cd="ambiguous" id="S2.Ex2.m1.5.5.1.1.3.2.1.cmml" xref="S2.Ex2.m1.5.5.1.1.3.2">subscript</csymbol><ci id="S2.Ex2.m1.5.5.1.1.3.2.2.cmml" xref="S2.Ex2.m1.5.5.1.1.3.2.2">𝔼</ci><apply id="S2.Ex2.m1.2.2.2.cmml" xref="S2.Ex2.m1.2.2.2"><csymbol cd="latexml" id="S2.Ex2.m1.2.2.2.3.cmml" xref="S2.Ex2.m1.2.2.2.3">similar-to</csymbol><interval closure="open" id="S2.Ex2.m1.2.2.2.4.1.cmml" xref="S2.Ex2.m1.2.2.2.4.2"><ci id="S2.Ex2.m1.1.1.1.1.cmml" xref="S2.Ex2.m1.1.1.1.1">𝑥</ci><ci id="S2.Ex2.m1.2.2.2.2.cmml" xref="S2.Ex2.m1.2.2.2.2">𝑦</ci></interval><ci id="S2.Ex2.m1.2.2.2.5.cmml" xref="S2.Ex2.m1.2.2.2.5">𝐷</ci></apply></apply></apply><apply id="S2.Ex2.m1.5.5.1.1.1.2.cmml" xref="S2.Ex2.m1.5.5.1.1.1.1"><csymbol cd="latexml" id="S2.Ex2.m1.5.5.1.1.1.2.1.cmml" xref="S2.Ex2.m1.5.5.1.1.1.1.2">delimited-[]</csymbol><apply id="S2.Ex2.m1.5.5.1.1.1.1.1.cmml" xref="S2.Ex2.m1.5.5.1.1.1.1.1"><times id="S2.Ex2.m1.5.5.1.1.1.1.1.2.cmml" xref="S2.Ex2.m1.5.5.1.1.1.1.1.2"></times><apply id="S2.Ex2.m1.5.5.1.1.1.1.1.3.cmml" xref="S2.Ex2.m1.5.5.1.1.1.1.1.3"><apply id="S2.Ex2.m1.5.5.1.1.1.1.1.3.1.cmml" xref="S2.Ex2.m1.5.5.1.1.1.1.1.3.1"><csymbol cd="ambiguous" id="S2.Ex2.m1.5.5.1.1.1.1.1.3.1.1.cmml" xref="S2.Ex2.m1.5.5.1.1.1.1.1.3.1">subscript</csymbol><max id="S2.Ex2.m1.5.5.1.1.1.1.1.3.1.2.cmml" xref="S2.Ex2.m1.5.5.1.1.1.1.1.3.1.2"></max><ci id="S2.Ex2.m1.5.5.1.1.1.1.1.3.1.3.cmml" xref="S2.Ex2.m1.5.5.1.1.1.1.1.3.1.3">𝛿</ci></apply><ci id="S2.Ex2.m1.5.5.1.1.1.1.1.3.2.cmml" xref="S2.Ex2.m1.5.5.1.1.1.1.1.3.2">𝑙</ci></apply><interval closure="open" id="S2.Ex2.m1.5.5.1.1.1.1.1.1.2.cmml" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.1"><apply id="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.cmml" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1"><times id="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.2.cmml" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.2"></times><ci id="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.3.cmml" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.3">𝑓</ci><list id="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.1"><apply id="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.1.1"><plus id="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.1"></plus><ci id="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.2">𝑥</ci><ci id="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.Ex2.m1.5.5.1.1.1.1.1.1.1.1.1.1.1.3">𝛿</ci></apply><ci id="S2.Ex2.m1.3.3.cmml" xref="S2.Ex2.m1.3.3">𝜃</ci></list></apply><ci id="S2.Ex2.m1.4.4.cmml" xref="S2.Ex2.m1.4.4">𝑦</ci></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex2.m1.5c">\min_{\theta}\mathbb{E}_{(x,y)\sim D}[\max_{\delta}l(f(x+\delta;\theta),y)],</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S2.p3.2" class="ltx_p">where the inner maximization can be solved by projected gradient descent <cite class="ltx_cite ltx_citemacro_cite">Madry et al. (<a href="#bib.bib30" title="" class="ltx_ref">2017</a>)</cite>.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.2" class="ltx_p">Recently, adversarial training has been successfully applied to NLP as well <cite class="ltx_cite ltx_citemacro_cite">Zhu et al. (<a href="#bib.bib43" title="" class="ltx_ref">2019</a>); Jiang et al. (<a href="#bib.bib21" title="" class="ltx_ref">2019</a>); Pereira et al. (<a href="#bib.bib33" title="" class="ltx_ref">2020</a>)</cite>. In particular,
FreeLB <cite class="ltx_cite ltx_citemacro_cite">Zhu et al. (<a href="#bib.bib43" title="" class="ltx_ref">2019</a>)</cite> leverages the <span id="S2.p4.2.1" class="ltx_text ltx_font_italic">free adversarial training</span> idea <cite class="ltx_cite ltx_citemacro_cite">Shafahi et al. (<a href="#bib.bib36" title="" class="ltx_ref">2019</a>)</cite> by reusing the backward pass in gradient computation to carry out inner ascent and outer descent steps simultaneously. SMART <cite class="ltx_cite ltx_citemacro_cite">Jiang et al. (<a href="#bib.bib21" title="" class="ltx_ref">2019</a>)</cite> instead regularizes the standard training objective using <span id="S2.p4.2.2" class="ltx_text ltx_font_italic">virtual adversarial training</span> <cite class="ltx_cite ltx_citemacro_cite">Miyato et al. (<a href="#bib.bib32" title="" class="ltx_ref">2018</a>)</cite>:</p>
<table id="S2.E1" class="ltx_equationgroup ltx_eqn_table">
<tbody>
<tr id="S2.E1X" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S2.E1X.2.1.1.m1.5" class="ltx_math_unparsed" alttext="\displaystyle\min_{\theta}\mathbb{E}_{(x,y)\sim D}[l(f(x;\theta),y)+" display="inline"><semantics id="S2.E1X.2.1.1.m1.5a"><mrow id="S2.E1X.2.1.1.m1.5b"><munder id="S2.E1X.2.1.1.m1.5.6"><mi id="S2.E1X.2.1.1.m1.5.6.2">min</mi><mi id="S2.E1X.2.1.1.m1.5.6.3">θ</mi></munder><msub id="S2.E1X.2.1.1.m1.5.7"><mi id="S2.E1X.2.1.1.m1.5.7.2">𝔼</mi><mrow id="S2.E1X.2.1.1.m1.2.2.2"><mrow id="S2.E1X.2.1.1.m1.2.2.2.4.2"><mo stretchy="false" id="S2.E1X.2.1.1.m1.2.2.2.4.2.1">(</mo><mi id="S2.E1X.2.1.1.m1.1.1.1.1">x</mi><mo id="S2.E1X.2.1.1.m1.2.2.2.4.2.2">,</mo><mi id="S2.E1X.2.1.1.m1.2.2.2.2">y</mi><mo stretchy="false" id="S2.E1X.2.1.1.m1.2.2.2.4.2.3">)</mo></mrow><mo id="S2.E1X.2.1.1.m1.2.2.2.3">∼</mo><mi id="S2.E1X.2.1.1.m1.2.2.2.5">D</mi></mrow></msub><mrow id="S2.E1X.2.1.1.m1.5.8"><mo stretchy="false" id="S2.E1X.2.1.1.m1.5.8.1">[</mo><mi id="S2.E1X.2.1.1.m1.5.8.2">l</mi><mrow id="S2.E1X.2.1.1.m1.5.8.3"><mo stretchy="false" id="S2.E1X.2.1.1.m1.5.8.3.1">(</mo><mi id="S2.E1X.2.1.1.m1.5.8.3.2">f</mi><mrow id="S2.E1X.2.1.1.m1.5.8.3.3"><mo stretchy="false" id="S2.E1X.2.1.1.m1.5.8.3.3.1">(</mo><mi id="S2.E1X.2.1.1.m1.3.3">x</mi><mo id="S2.E1X.2.1.1.m1.5.8.3.3.2">;</mo><mi id="S2.E1X.2.1.1.m1.4.4">θ</mi><mo stretchy="false" id="S2.E1X.2.1.1.m1.5.8.3.3.3">)</mo></mrow><mo id="S2.E1X.2.1.1.m1.5.8.3.4">,</mo><mi id="S2.E1X.2.1.1.m1.5.5">y</mi><mo stretchy="false" id="S2.E1X.2.1.1.m1.5.8.3.5">)</mo></mrow><mo id="S2.E1X.2.1.1.m1.5.8.4">+</mo></mrow></mrow><annotation encoding="application/x-tex" id="S2.E1X.2.1.1.m1.5c">\displaystyle\min_{\theta}\mathbb{E}_{(x,y)\sim D}[l(f(x;\theta),y)+</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="2" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(1)</span></td>
</tr>
<tr id="S2.E1Xa" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S2.E1Xa.2.1.1.m1.3" class="ltx_math_unparsed" alttext="\displaystyle\alpha\max_{\delta}l(f(x+\delta;\theta),f(x;\theta))]" display="inline"><semantics id="S2.E1Xa.2.1.1.m1.3a"><mrow id="S2.E1Xa.2.1.1.m1.3b"><mi id="S2.E1Xa.2.1.1.m1.3.4">α</mi><munder id="S2.E1Xa.2.1.1.m1.3.5"><mi id="S2.E1Xa.2.1.1.m1.3.5.2">max</mi><mi id="S2.E1Xa.2.1.1.m1.3.5.3">δ</mi></munder><mi id="S2.E1Xa.2.1.1.m1.3.6">l</mi><mrow id="S2.E1Xa.2.1.1.m1.3.7"><mo stretchy="false" id="S2.E1Xa.2.1.1.m1.3.7.1">(</mo><mi id="S2.E1Xa.2.1.1.m1.3.7.2">f</mi><mrow id="S2.E1Xa.2.1.1.m1.3.7.3"><mo stretchy="false" id="S2.E1Xa.2.1.1.m1.3.7.3.1">(</mo><mi id="S2.E1Xa.2.1.1.m1.3.7.3.2">x</mi><mo id="S2.E1Xa.2.1.1.m1.3.7.3.3">+</mo><mi id="S2.E1Xa.2.1.1.m1.3.7.3.4">δ</mi><mo id="S2.E1Xa.2.1.1.m1.3.7.3.5">;</mo><mi id="S2.E1Xa.2.1.1.m1.1.1">θ</mi><mo stretchy="false" id="S2.E1Xa.2.1.1.m1.3.7.3.6">)</mo></mrow><mo id="S2.E1Xa.2.1.1.m1.3.7.4">,</mo><mi id="S2.E1Xa.2.1.1.m1.3.7.5">f</mi><mrow id="S2.E1Xa.2.1.1.m1.3.7.6"><mo stretchy="false" id="S2.E1Xa.2.1.1.m1.3.7.6.1">(</mo><mi id="S2.E1Xa.2.1.1.m1.2.2">x</mi><mo id="S2.E1Xa.2.1.1.m1.3.7.6.2">;</mo><mi id="S2.E1Xa.2.1.1.m1.3.3">θ</mi><mo stretchy="false" id="S2.E1Xa.2.1.1.m1.3.7.6.3">)</mo></mrow><mo stretchy="false" id="S2.E1Xa.2.1.1.m1.3.7.7">)</mo></mrow><mo stretchy="false" id="S2.E1Xa.2.1.1.m1.3.8">]</mo></mrow><annotation encoding="application/x-tex" id="S2.E1Xa.2.1.1.m1.3c">\displaystyle\alpha\max_{\delta}l(f(x+\delta;\theta),f(x;\theta))]</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
</tbody>
</table>
<p id="S2.p4.1" class="ltx_p">Effectively, the adversarial term encourages smoothness in the input neighborhood, and <math id="S2.p4.1.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S2.p4.1.m1.1a"><mi id="S2.p4.1.m1.1.1" xref="S2.p4.1.m1.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S2.p4.1.m1.1b"><ci id="S2.p4.1.m1.1.1.cmml" xref="S2.p4.1.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p4.1.m1.1c">\alpha</annotation></semantics></math> is a hyperparameter that controls the trade-off between standard errors and adversarial errors.</p>
</div>
<figure id="alg1" class="ltx_float ltx_float_algorithm ltx_framed ltx_framed_top">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span id="alg1.2.1.1" class="ltx_text ltx_font_bold">Algorithm 1</span> </span> TAT</figcaption>
<div id="alg1.3" class="ltx_listing ltx_listing">
<div id="alg1.l1" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">1:</span><math id="alg1.l1.m1.1" class="ltx_Math" alttext="T" display="inline"><semantics id="alg1.l1.m1.1a"><mi id="alg1.l1.m1.1.1" xref="alg1.l1.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="alg1.l1.m1.1b"><ci id="alg1.l1.m1.1.1.cmml" xref="alg1.l1.m1.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m1.1c">T</annotation></semantics></math>: the total number of iterations, <math id="alg1.l1.m2.3" class="ltx_Math" alttext="\mathcal{X}=\{(x_{1},y_{1}),...,(x_{n},y_{n})\}" display="inline"><semantics id="alg1.l1.m2.3a"><mrow id="alg1.l1.m2.3.3" xref="alg1.l1.m2.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="alg1.l1.m2.3.3.4" xref="alg1.l1.m2.3.3.4.cmml">𝒳</mi><mo id="alg1.l1.m2.3.3.3" xref="alg1.l1.m2.3.3.3.cmml">=</mo><mrow id="alg1.l1.m2.3.3.2.2" xref="alg1.l1.m2.3.3.2.3.cmml"><mo stretchy="false" id="alg1.l1.m2.3.3.2.2.3" xref="alg1.l1.m2.3.3.2.3.cmml">{</mo><mrow id="alg1.l1.m2.2.2.1.1.1.2" xref="alg1.l1.m2.2.2.1.1.1.3.cmml"><mo stretchy="false" id="alg1.l1.m2.2.2.1.1.1.2.3" xref="alg1.l1.m2.2.2.1.1.1.3.cmml">(</mo><msub id="alg1.l1.m2.2.2.1.1.1.1.1" xref="alg1.l1.m2.2.2.1.1.1.1.1.cmml"><mi id="alg1.l1.m2.2.2.1.1.1.1.1.2" xref="alg1.l1.m2.2.2.1.1.1.1.1.2.cmml">x</mi><mn id="alg1.l1.m2.2.2.1.1.1.1.1.3" xref="alg1.l1.m2.2.2.1.1.1.1.1.3.cmml">1</mn></msub><mo id="alg1.l1.m2.2.2.1.1.1.2.4" xref="alg1.l1.m2.2.2.1.1.1.3.cmml">,</mo><msub id="alg1.l1.m2.2.2.1.1.1.2.2" xref="alg1.l1.m2.2.2.1.1.1.2.2.cmml"><mi id="alg1.l1.m2.2.2.1.1.1.2.2.2" xref="alg1.l1.m2.2.2.1.1.1.2.2.2.cmml">y</mi><mn id="alg1.l1.m2.2.2.1.1.1.2.2.3" xref="alg1.l1.m2.2.2.1.1.1.2.2.3.cmml">1</mn></msub><mo stretchy="false" id="alg1.l1.m2.2.2.1.1.1.2.5" xref="alg1.l1.m2.2.2.1.1.1.3.cmml">)</mo></mrow><mo id="alg1.l1.m2.3.3.2.2.4" xref="alg1.l1.m2.3.3.2.3.cmml">,</mo><mi mathvariant="normal" id="alg1.l1.m2.1.1" xref="alg1.l1.m2.1.1.cmml">…</mi><mo id="alg1.l1.m2.3.3.2.2.5" xref="alg1.l1.m2.3.3.2.3.cmml">,</mo><mrow id="alg1.l1.m2.3.3.2.2.2.2" xref="alg1.l1.m2.3.3.2.2.2.3.cmml"><mo stretchy="false" id="alg1.l1.m2.3.3.2.2.2.2.3" xref="alg1.l1.m2.3.3.2.2.2.3.cmml">(</mo><msub id="alg1.l1.m2.3.3.2.2.2.1.1" xref="alg1.l1.m2.3.3.2.2.2.1.1.cmml"><mi id="alg1.l1.m2.3.3.2.2.2.1.1.2" xref="alg1.l1.m2.3.3.2.2.2.1.1.2.cmml">x</mi><mi id="alg1.l1.m2.3.3.2.2.2.1.1.3" xref="alg1.l1.m2.3.3.2.2.2.1.1.3.cmml">n</mi></msub><mo id="alg1.l1.m2.3.3.2.2.2.2.4" xref="alg1.l1.m2.3.3.2.2.2.3.cmml">,</mo><msub id="alg1.l1.m2.3.3.2.2.2.2.2" xref="alg1.l1.m2.3.3.2.2.2.2.2.cmml"><mi id="alg1.l1.m2.3.3.2.2.2.2.2.2" xref="alg1.l1.m2.3.3.2.2.2.2.2.2.cmml">y</mi><mi id="alg1.l1.m2.3.3.2.2.2.2.2.3" xref="alg1.l1.m2.3.3.2.2.2.2.2.3.cmml">n</mi></msub><mo stretchy="false" id="alg1.l1.m2.3.3.2.2.2.2.5" xref="alg1.l1.m2.3.3.2.2.2.3.cmml">)</mo></mrow><mo stretchy="false" id="alg1.l1.m2.3.3.2.2.6" xref="alg1.l1.m2.3.3.2.3.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l1.m2.3b"><apply id="alg1.l1.m2.3.3.cmml" xref="alg1.l1.m2.3.3"><eq id="alg1.l1.m2.3.3.3.cmml" xref="alg1.l1.m2.3.3.3"></eq><ci id="alg1.l1.m2.3.3.4.cmml" xref="alg1.l1.m2.3.3.4">𝒳</ci><set id="alg1.l1.m2.3.3.2.3.cmml" xref="alg1.l1.m2.3.3.2.2"><interval closure="open" id="alg1.l1.m2.2.2.1.1.1.3.cmml" xref="alg1.l1.m2.2.2.1.1.1.2"><apply id="alg1.l1.m2.2.2.1.1.1.1.1.cmml" xref="alg1.l1.m2.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="alg1.l1.m2.2.2.1.1.1.1.1.1.cmml" xref="alg1.l1.m2.2.2.1.1.1.1.1">subscript</csymbol><ci id="alg1.l1.m2.2.2.1.1.1.1.1.2.cmml" xref="alg1.l1.m2.2.2.1.1.1.1.1.2">𝑥</ci><cn type="integer" id="alg1.l1.m2.2.2.1.1.1.1.1.3.cmml" xref="alg1.l1.m2.2.2.1.1.1.1.1.3">1</cn></apply><apply id="alg1.l1.m2.2.2.1.1.1.2.2.cmml" xref="alg1.l1.m2.2.2.1.1.1.2.2"><csymbol cd="ambiguous" id="alg1.l1.m2.2.2.1.1.1.2.2.1.cmml" xref="alg1.l1.m2.2.2.1.1.1.2.2">subscript</csymbol><ci id="alg1.l1.m2.2.2.1.1.1.2.2.2.cmml" xref="alg1.l1.m2.2.2.1.1.1.2.2.2">𝑦</ci><cn type="integer" id="alg1.l1.m2.2.2.1.1.1.2.2.3.cmml" xref="alg1.l1.m2.2.2.1.1.1.2.2.3">1</cn></apply></interval><ci id="alg1.l1.m2.1.1.cmml" xref="alg1.l1.m2.1.1">…</ci><interval closure="open" id="alg1.l1.m2.3.3.2.2.2.3.cmml" xref="alg1.l1.m2.3.3.2.2.2.2"><apply id="alg1.l1.m2.3.3.2.2.2.1.1.cmml" xref="alg1.l1.m2.3.3.2.2.2.1.1"><csymbol cd="ambiguous" id="alg1.l1.m2.3.3.2.2.2.1.1.1.cmml" xref="alg1.l1.m2.3.3.2.2.2.1.1">subscript</csymbol><ci id="alg1.l1.m2.3.3.2.2.2.1.1.2.cmml" xref="alg1.l1.m2.3.3.2.2.2.1.1.2">𝑥</ci><ci id="alg1.l1.m2.3.3.2.2.2.1.1.3.cmml" xref="alg1.l1.m2.3.3.2.2.2.1.1.3">𝑛</ci></apply><apply id="alg1.l1.m2.3.3.2.2.2.2.2.cmml" xref="alg1.l1.m2.3.3.2.2.2.2.2"><csymbol cd="ambiguous" id="alg1.l1.m2.3.3.2.2.2.2.2.1.cmml" xref="alg1.l1.m2.3.3.2.2.2.2.2">subscript</csymbol><ci id="alg1.l1.m2.3.3.2.2.2.2.2.2.cmml" xref="alg1.l1.m2.3.3.2.2.2.2.2.2">𝑦</ci><ci id="alg1.l1.m2.3.3.2.2.2.2.2.3.cmml" xref="alg1.l1.m2.3.3.2.2.2.2.2.3">𝑛</ci></apply></interval></set></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m2.3c">\mathcal{X}=\{(x_{1},y_{1}),...,(x_{n},y_{n})\}</annotation></semantics></math>: the dataset,
<math id="alg1.l1.m3.2" class="ltx_Math" alttext="f(x;\theta)" display="inline"><semantics id="alg1.l1.m3.2a"><mrow id="alg1.l1.m3.2.3" xref="alg1.l1.m3.2.3.cmml"><mi id="alg1.l1.m3.2.3.2" xref="alg1.l1.m3.2.3.2.cmml">f</mi><mo lspace="0em" rspace="0em" id="alg1.l1.m3.2.3.1" xref="alg1.l1.m3.2.3.1.cmml">​</mo><mrow id="alg1.l1.m3.2.3.3.2" xref="alg1.l1.m3.2.3.3.1.cmml"><mo stretchy="false" id="alg1.l1.m3.2.3.3.2.1" xref="alg1.l1.m3.2.3.3.1.cmml">(</mo><mi id="alg1.l1.m3.1.1" xref="alg1.l1.m3.1.1.cmml">x</mi><mo id="alg1.l1.m3.2.3.3.2.2" xref="alg1.l1.m3.2.3.3.1.cmml">;</mo><mi id="alg1.l1.m3.2.2" xref="alg1.l1.m3.2.2.cmml">θ</mi><mo stretchy="false" id="alg1.l1.m3.2.3.3.2.3" xref="alg1.l1.m3.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l1.m3.2b"><apply id="alg1.l1.m3.2.3.cmml" xref="alg1.l1.m3.2.3"><times id="alg1.l1.m3.2.3.1.cmml" xref="alg1.l1.m3.2.3.1"></times><ci id="alg1.l1.m3.2.3.2.cmml" xref="alg1.l1.m3.2.3.2">𝑓</ci><list id="alg1.l1.m3.2.3.3.1.cmml" xref="alg1.l1.m3.2.3.3.2"><ci id="alg1.l1.m3.1.1.cmml" xref="alg1.l1.m3.1.1">𝑥</ci><ci id="alg1.l1.m3.2.2.cmml" xref="alg1.l1.m3.2.2">𝜃</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m3.2c">f(x;\theta)</annotation></semantics></math>: the machine learning model parametrized by <math id="alg1.l1.m4.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="alg1.l1.m4.1a"><mi id="alg1.l1.m4.1.1" xref="alg1.l1.m4.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="alg1.l1.m4.1b"><ci id="alg1.l1.m4.1.1.cmml" xref="alg1.l1.m4.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m4.1c">\theta</annotation></semantics></math>, <math id="alg1.l1.m5.1" class="ltx_Math" alttext="\sigma^{2}" display="inline"><semantics id="alg1.l1.m5.1a"><msup id="alg1.l1.m5.1.1" xref="alg1.l1.m5.1.1.cmml"><mi id="alg1.l1.m5.1.1.2" xref="alg1.l1.m5.1.1.2.cmml">σ</mi><mn id="alg1.l1.m5.1.1.3" xref="alg1.l1.m5.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="alg1.l1.m5.1b"><apply id="alg1.l1.m5.1.1.cmml" xref="alg1.l1.m5.1.1"><csymbol cd="ambiguous" id="alg1.l1.m5.1.1.1.cmml" xref="alg1.l1.m5.1.1">superscript</csymbol><ci id="alg1.l1.m5.1.1.2.cmml" xref="alg1.l1.m5.1.1.2">𝜎</ci><cn type="integer" id="alg1.l1.m5.1.1.3.cmml" xref="alg1.l1.m5.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m5.1c">\sigma^{2}</annotation></semantics></math>: the variance of the random initialization of perturbation <math id="alg1.l1.m6.1" class="ltx_Math" alttext="\delta" display="inline"><semantics id="alg1.l1.m6.1a"><mi id="alg1.l1.m6.1.1" xref="alg1.l1.m6.1.1.cmml">δ</mi><annotation-xml encoding="MathML-Content" id="alg1.l1.m6.1b"><ci id="alg1.l1.m6.1.1.cmml" xref="alg1.l1.m6.1.1">𝛿</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m6.1c">\delta</annotation></semantics></math>, <math id="alg1.l1.m7.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="alg1.l1.m7.1a"><mi id="alg1.l1.m7.1.1" xref="alg1.l1.m7.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="alg1.l1.m7.1b"><ci id="alg1.l1.m7.1.1.cmml" xref="alg1.l1.m7.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m7.1c">\epsilon</annotation></semantics></math>: perturbation bound, <math id="alg1.l1.m8.1" class="ltx_Math" alttext="K" display="inline"><semantics id="alg1.l1.m8.1a"><mi id="alg1.l1.m8.1.1" xref="alg1.l1.m8.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="alg1.l1.m8.1b"><ci id="alg1.l1.m8.1.1.cmml" xref="alg1.l1.m8.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m8.1c">K</annotation></semantics></math>: the number of iterations for perturbation estimation, <math id="alg1.l1.m9.1" class="ltx_Math" alttext="\eta" display="inline"><semantics id="alg1.l1.m9.1a"><mi id="alg1.l1.m9.1.1" xref="alg1.l1.m9.1.1.cmml">η</mi><annotation-xml encoding="MathML-Content" id="alg1.l1.m9.1b"><ci id="alg1.l1.m9.1.1.cmml" xref="alg1.l1.m9.1.1">𝜂</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m9.1c">\eta</annotation></semantics></math>: the step size for updating perturbation, <math id="alg1.l1.m10.1" class="ltx_Math" alttext="\tau" display="inline"><semantics id="alg1.l1.m10.1a"><mi id="alg1.l1.m10.1.1" xref="alg1.l1.m10.1.1.cmml">τ</mi><annotation-xml encoding="MathML-Content" id="alg1.l1.m10.1b"><ci id="alg1.l1.m10.1.1.cmml" xref="alg1.l1.m10.1.1">𝜏</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m10.1c">\tau</annotation></semantics></math>: the global learning rate, <math id="alg1.l1.m11.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="alg1.l1.m11.1a"><mi id="alg1.l1.m11.1.1" xref="alg1.l1.m11.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="alg1.l1.m11.1b"><ci id="alg1.l1.m11.1.1.cmml" xref="alg1.l1.m11.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m11.1c">\alpha</annotation></semantics></math>: the smoothing proportion of adversarial training in the augmented learning objective, <math id="alg1.l1.m12.1" class="ltx_Math" alttext="\Pi" display="inline"><semantics id="alg1.l1.m12.1a"><mi mathvariant="normal" id="alg1.l1.m12.1.1" xref="alg1.l1.m12.1.1.cmml">Π</mi><annotation-xml encoding="MathML-Content" id="alg1.l1.m12.1b"><ci id="alg1.l1.m12.1.1.cmml" xref="alg1.l1.m12.1.1">Π</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m12.1c">\Pi</annotation></semantics></math>: the projection operation and <math id="alg1.l1.m13.1" class="ltx_Math" alttext="C" display="inline"><semantics id="alg1.l1.m13.1a"><mi id="alg1.l1.m13.1.1" xref="alg1.l1.m13.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="alg1.l1.m13.1b"><ci id="alg1.l1.m13.1.1.cmml" xref="alg1.l1.m13.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m13.1c">C</annotation></semantics></math>: the classes.

</div>
<div id="alg1.l2" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">2:</span><span id="alg1.l2.1" class="ltx_text ltx_font_bold">for</span> <math id="alg1.l2.m1.1" class="ltx_math_unparsed" alttext="t=1,..,T" display="inline"><semantics id="alg1.l2.m1.1a"><mrow id="alg1.l2.m1.1b"><mi id="alg1.l2.m1.1.1">t</mi><mo id="alg1.l2.m1.1.2">=</mo><mn id="alg1.l2.m1.1.3">1</mn><mo id="alg1.l2.m1.1.4">,</mo><mo lspace="0em" rspace="0.0835em" id="alg1.l2.m1.1.5">.</mo><mo lspace="0.0835em" rspace="0.167em" id="alg1.l2.m1.1.6">.</mo><mo id="alg1.l2.m1.1.7">,</mo><mi id="alg1.l2.m1.1.8">T</mi></mrow><annotation encoding="application/x-tex" id="alg1.l2.m1.1c">t=1,..,T</annotation></semantics></math> <span id="alg1.l2.2" class="ltx_text ltx_font_bold">do</span>

</div>
<div id="alg1.l3" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">3:</span>     <span id="alg1.l3.1" class="ltx_text ltx_font_bold">for</span> <math id="alg1.l3.m1.2" class="ltx_Math" alttext="(x,y)\in" display="inline"><semantics id="alg1.l3.m1.2a"><mrow id="alg1.l3.m1.2.3" xref="alg1.l3.m1.2.3.cmml"><mrow id="alg1.l3.m1.2.3.2.2" xref="alg1.l3.m1.2.3.2.1.cmml"><mo stretchy="false" id="alg1.l3.m1.2.3.2.2.1" xref="alg1.l3.m1.2.3.2.1.cmml">(</mo><mi id="alg1.l3.m1.1.1" xref="alg1.l3.m1.1.1.cmml">x</mi><mo id="alg1.l3.m1.2.3.2.2.2" xref="alg1.l3.m1.2.3.2.1.cmml">,</mo><mi id="alg1.l3.m1.2.2" xref="alg1.l3.m1.2.2.cmml">y</mi><mo stretchy="false" id="alg1.l3.m1.2.3.2.2.3" xref="alg1.l3.m1.2.3.2.1.cmml">)</mo></mrow><mo id="alg1.l3.m1.2.3.1" xref="alg1.l3.m1.2.3.1.cmml">∈</mo><mi id="alg1.l3.m1.2.3.3" xref="alg1.l3.m1.2.3.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.l3.m1.2b"><apply id="alg1.l3.m1.2.3.cmml" xref="alg1.l3.m1.2.3"><in id="alg1.l3.m1.2.3.1.cmml" xref="alg1.l3.m1.2.3.1"></in><interval closure="open" id="alg1.l3.m1.2.3.2.1.cmml" xref="alg1.l3.m1.2.3.2.2"><ci id="alg1.l3.m1.1.1.cmml" xref="alg1.l3.m1.1.1">𝑥</ci><ci id="alg1.l3.m1.2.2.cmml" xref="alg1.l3.m1.2.2">𝑦</ci></interval><csymbol cd="latexml" id="alg1.l3.m1.2.3.3.cmml" xref="alg1.l3.m1.2.3.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l3.m1.2c">(x,y)\in</annotation></semantics></math> <math id="alg1.l3.m2.1" class="ltx_Math" alttext="\mathcal{X}" display="inline"><semantics id="alg1.l3.m2.1a"><mi class="ltx_font_mathcaligraphic" id="alg1.l3.m2.1.1" xref="alg1.l3.m2.1.1.cmml">𝒳</mi><annotation-xml encoding="MathML-Content" id="alg1.l3.m2.1b"><ci id="alg1.l3.m2.1.1.cmml" xref="alg1.l3.m2.1.1">𝒳</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l3.m2.1c">\mathcal{X}</annotation></semantics></math> <span id="alg1.l3.2" class="ltx_text ltx_font_bold">do</span>

</div>
<div id="alg1.l4" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">4:</span>         <math id="alg1.l4.m1.2" class="ltx_Math" alttext="\delta\sim\mathcal{N}(0,\sigma^{2}I)" display="inline"><semantics id="alg1.l4.m1.2a"><mrow id="alg1.l4.m1.2.2" xref="alg1.l4.m1.2.2.cmml"><mi id="alg1.l4.m1.2.2.3" xref="alg1.l4.m1.2.2.3.cmml">δ</mi><mo id="alg1.l4.m1.2.2.2" xref="alg1.l4.m1.2.2.2.cmml">∼</mo><mrow id="alg1.l4.m1.2.2.1" xref="alg1.l4.m1.2.2.1.cmml"><mi class="ltx_font_mathcaligraphic" id="alg1.l4.m1.2.2.1.3" xref="alg1.l4.m1.2.2.1.3.cmml">𝒩</mi><mo lspace="0em" rspace="0em" id="alg1.l4.m1.2.2.1.2" xref="alg1.l4.m1.2.2.1.2.cmml">​</mo><mrow id="alg1.l4.m1.2.2.1.1.1" xref="alg1.l4.m1.2.2.1.1.2.cmml"><mo stretchy="false" id="alg1.l4.m1.2.2.1.1.1.2" xref="alg1.l4.m1.2.2.1.1.2.cmml">(</mo><mn id="alg1.l4.m1.1.1" xref="alg1.l4.m1.1.1.cmml">0</mn><mo id="alg1.l4.m1.2.2.1.1.1.3" xref="alg1.l4.m1.2.2.1.1.2.cmml">,</mo><mrow id="alg1.l4.m1.2.2.1.1.1.1" xref="alg1.l4.m1.2.2.1.1.1.1.cmml"><msup id="alg1.l4.m1.2.2.1.1.1.1.2" xref="alg1.l4.m1.2.2.1.1.1.1.2.cmml"><mi id="alg1.l4.m1.2.2.1.1.1.1.2.2" xref="alg1.l4.m1.2.2.1.1.1.1.2.2.cmml">σ</mi><mn id="alg1.l4.m1.2.2.1.1.1.1.2.3" xref="alg1.l4.m1.2.2.1.1.1.1.2.3.cmml">2</mn></msup><mo lspace="0em" rspace="0em" id="alg1.l4.m1.2.2.1.1.1.1.1" xref="alg1.l4.m1.2.2.1.1.1.1.1.cmml">​</mo><mi id="alg1.l4.m1.2.2.1.1.1.1.3" xref="alg1.l4.m1.2.2.1.1.1.1.3.cmml">I</mi></mrow><mo stretchy="false" id="alg1.l4.m1.2.2.1.1.1.4" xref="alg1.l4.m1.2.2.1.1.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l4.m1.2b"><apply id="alg1.l4.m1.2.2.cmml" xref="alg1.l4.m1.2.2"><csymbol cd="latexml" id="alg1.l4.m1.2.2.2.cmml" xref="alg1.l4.m1.2.2.2">similar-to</csymbol><ci id="alg1.l4.m1.2.2.3.cmml" xref="alg1.l4.m1.2.2.3">𝛿</ci><apply id="alg1.l4.m1.2.2.1.cmml" xref="alg1.l4.m1.2.2.1"><times id="alg1.l4.m1.2.2.1.2.cmml" xref="alg1.l4.m1.2.2.1.2"></times><ci id="alg1.l4.m1.2.2.1.3.cmml" xref="alg1.l4.m1.2.2.1.3">𝒩</ci><interval closure="open" id="alg1.l4.m1.2.2.1.1.2.cmml" xref="alg1.l4.m1.2.2.1.1.1"><cn type="integer" id="alg1.l4.m1.1.1.cmml" xref="alg1.l4.m1.1.1">0</cn><apply id="alg1.l4.m1.2.2.1.1.1.1.cmml" xref="alg1.l4.m1.2.2.1.1.1.1"><times id="alg1.l4.m1.2.2.1.1.1.1.1.cmml" xref="alg1.l4.m1.2.2.1.1.1.1.1"></times><apply id="alg1.l4.m1.2.2.1.1.1.1.2.cmml" xref="alg1.l4.m1.2.2.1.1.1.1.2"><csymbol cd="ambiguous" id="alg1.l4.m1.2.2.1.1.1.1.2.1.cmml" xref="alg1.l4.m1.2.2.1.1.1.1.2">superscript</csymbol><ci id="alg1.l4.m1.2.2.1.1.1.1.2.2.cmml" xref="alg1.l4.m1.2.2.1.1.1.1.2.2">𝜎</ci><cn type="integer" id="alg1.l4.m1.2.2.1.1.1.1.2.3.cmml" xref="alg1.l4.m1.2.2.1.1.1.1.2.3">2</cn></apply><ci id="alg1.l4.m1.2.2.1.1.1.1.3.cmml" xref="alg1.l4.m1.2.2.1.1.1.1.3">𝐼</ci></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l4.m1.2c">\delta\sim\mathcal{N}(0,\sigma^{2}I)</annotation></semantics></math>

</div>
<div id="alg1.l5" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">5:</span>         <math id="alg1.l5.m1.1" class="ltx_Math" alttext="y_{t}=sample(C_{\setminus y})" display="inline"><semantics id="alg1.l5.m1.1a"><mrow id="alg1.l5.m1.1.1" xref="alg1.l5.m1.1.1.cmml"><msub id="alg1.l5.m1.1.1.3" xref="alg1.l5.m1.1.1.3.cmml"><mi mathcolor="#0000FF" id="alg1.l5.m1.1.1.3.2" xref="alg1.l5.m1.1.1.3.2.cmml">y</mi><mi mathcolor="#0000FF" id="alg1.l5.m1.1.1.3.3" xref="alg1.l5.m1.1.1.3.3.cmml">t</mi></msub><mo mathcolor="#0000FF" id="alg1.l5.m1.1.1.2" xref="alg1.l5.m1.1.1.2.cmml">=</mo><mrow id="alg1.l5.m1.1.1.1" xref="alg1.l5.m1.1.1.1.cmml"><mi mathcolor="#0000FF" id="alg1.l5.m1.1.1.1.3" xref="alg1.l5.m1.1.1.1.3.cmml">s</mi><mo lspace="0em" rspace="0em" id="alg1.l5.m1.1.1.1.2" xref="alg1.l5.m1.1.1.1.2.cmml">​</mo><mi mathcolor="#0000FF" id="alg1.l5.m1.1.1.1.4" xref="alg1.l5.m1.1.1.1.4.cmml">a</mi><mo lspace="0em" rspace="0em" id="alg1.l5.m1.1.1.1.2a" xref="alg1.l5.m1.1.1.1.2.cmml">​</mo><mi mathcolor="#0000FF" id="alg1.l5.m1.1.1.1.5" xref="alg1.l5.m1.1.1.1.5.cmml">m</mi><mo lspace="0em" rspace="0em" id="alg1.l5.m1.1.1.1.2b" xref="alg1.l5.m1.1.1.1.2.cmml">​</mo><mi mathcolor="#0000FF" id="alg1.l5.m1.1.1.1.6" xref="alg1.l5.m1.1.1.1.6.cmml">p</mi><mo lspace="0em" rspace="0em" id="alg1.l5.m1.1.1.1.2c" xref="alg1.l5.m1.1.1.1.2.cmml">​</mo><mi mathcolor="#0000FF" id="alg1.l5.m1.1.1.1.7" xref="alg1.l5.m1.1.1.1.7.cmml">l</mi><mo lspace="0em" rspace="0em" id="alg1.l5.m1.1.1.1.2d" xref="alg1.l5.m1.1.1.1.2.cmml">​</mo><mi mathcolor="#0000FF" id="alg1.l5.m1.1.1.1.8" xref="alg1.l5.m1.1.1.1.8.cmml">e</mi><mo lspace="0em" rspace="0em" id="alg1.l5.m1.1.1.1.2e" xref="alg1.l5.m1.1.1.1.2.cmml">​</mo><mrow id="alg1.l5.m1.1.1.1.1.1" xref="alg1.l5.m1.1.1.1.1.1.1.cmml"><mo mathcolor="#0000FF" stretchy="false" id="alg1.l5.m1.1.1.1.1.1.2" xref="alg1.l5.m1.1.1.1.1.1.1.cmml">(</mo><msub id="alg1.l5.m1.1.1.1.1.1.1" xref="alg1.l5.m1.1.1.1.1.1.1.cmml"><mi mathcolor="#0000FF" id="alg1.l5.m1.1.1.1.1.1.1.2" xref="alg1.l5.m1.1.1.1.1.1.1.2.cmml">C</mi><mrow id="alg1.l5.m1.1.1.1.1.1.1.3" xref="alg1.l5.m1.1.1.1.1.1.1.3.cmml"><mo mathcolor="#0000FF" rspace="0em" id="alg1.l5.m1.1.1.1.1.1.1.3a" xref="alg1.l5.m1.1.1.1.1.1.1.3.cmml">∖</mo><mi mathcolor="#0000FF" id="alg1.l5.m1.1.1.1.1.1.1.3.2" xref="alg1.l5.m1.1.1.1.1.1.1.3.2.cmml">y</mi></mrow></msub><mo mathcolor="#0000FF" stretchy="false" id="alg1.l5.m1.1.1.1.1.1.3" xref="alg1.l5.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l5.m1.1b"><apply id="alg1.l5.m1.1.1.cmml" xref="alg1.l5.m1.1.1"><eq id="alg1.l5.m1.1.1.2.cmml" xref="alg1.l5.m1.1.1.2"></eq><apply id="alg1.l5.m1.1.1.3.cmml" xref="alg1.l5.m1.1.1.3"><csymbol cd="ambiguous" id="alg1.l5.m1.1.1.3.1.cmml" xref="alg1.l5.m1.1.1.3">subscript</csymbol><ci id="alg1.l5.m1.1.1.3.2.cmml" xref="alg1.l5.m1.1.1.3.2">𝑦</ci><ci id="alg1.l5.m1.1.1.3.3.cmml" xref="alg1.l5.m1.1.1.3.3">𝑡</ci></apply><apply id="alg1.l5.m1.1.1.1.cmml" xref="alg1.l5.m1.1.1.1"><times id="alg1.l5.m1.1.1.1.2.cmml" xref="alg1.l5.m1.1.1.1.2"></times><ci id="alg1.l5.m1.1.1.1.3.cmml" xref="alg1.l5.m1.1.1.1.3">𝑠</ci><ci id="alg1.l5.m1.1.1.1.4.cmml" xref="alg1.l5.m1.1.1.1.4">𝑎</ci><ci id="alg1.l5.m1.1.1.1.5.cmml" xref="alg1.l5.m1.1.1.1.5">𝑚</ci><ci id="alg1.l5.m1.1.1.1.6.cmml" xref="alg1.l5.m1.1.1.1.6">𝑝</ci><ci id="alg1.l5.m1.1.1.1.7.cmml" xref="alg1.l5.m1.1.1.1.7">𝑙</ci><ci id="alg1.l5.m1.1.1.1.8.cmml" xref="alg1.l5.m1.1.1.1.8">𝑒</ci><apply id="alg1.l5.m1.1.1.1.1.1.1.cmml" xref="alg1.l5.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="alg1.l5.m1.1.1.1.1.1.1.1.cmml" xref="alg1.l5.m1.1.1.1.1.1">subscript</csymbol><ci id="alg1.l5.m1.1.1.1.1.1.1.2.cmml" xref="alg1.l5.m1.1.1.1.1.1.1.2">𝐶</ci><apply id="alg1.l5.m1.1.1.1.1.1.1.3.cmml" xref="alg1.l5.m1.1.1.1.1.1.1.3"><setdiff id="alg1.l5.m1.1.1.1.1.1.1.3.1.cmml" xref="alg1.l5.m1.1.1.1.1.1.1.3"></setdiff><ci id="alg1.l5.m1.1.1.1.1.1.1.3.2.cmml" xref="alg1.l5.m1.1.1.1.1.1.1.3.2">𝑦</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l5.m1.1c">y_{t}=sample(C_{\setminus y})</annotation></semantics></math>

</div>
<div id="alg1.l6" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">6:</span>         <span id="alg1.l6.1" class="ltx_text ltx_font_bold">for</span> <math id="alg1.l6.m1.1" class="ltx_math_unparsed" alttext="m=1,..,K" display="inline"><semantics id="alg1.l6.m1.1a"><mrow id="alg1.l6.m1.1b"><mi id="alg1.l6.m1.1.1">m</mi><mo id="alg1.l6.m1.1.2">=</mo><mn id="alg1.l6.m1.1.3">1</mn><mo id="alg1.l6.m1.1.4">,</mo><mo lspace="0em" rspace="0.0835em" id="alg1.l6.m1.1.5">.</mo><mo lspace="0.0835em" rspace="0.167em" id="alg1.l6.m1.1.6">.</mo><mo id="alg1.l6.m1.1.7">,</mo><mi id="alg1.l6.m1.1.8">K</mi></mrow><annotation encoding="application/x-tex" id="alg1.l6.m1.1c">m=1,..,K</annotation></semantics></math> <span id="alg1.l6.2" class="ltx_text ltx_font_bold">do</span>

</div>
<div id="alg1.l7" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">7:</span>              <math id="alg1.l7.m1.3" class="ltx_Math" alttext="g_{adv}\leftarrow\nabla_{\delta}l(f(x+\delta;\theta),y_{t})" display="inline"><semantics id="alg1.l7.m1.3a"><mrow id="alg1.l7.m1.3.3" xref="alg1.l7.m1.3.3.cmml"><msub id="alg1.l7.m1.3.3.4" xref="alg1.l7.m1.3.3.4.cmml"><mi id="alg1.l7.m1.3.3.4.2" xref="alg1.l7.m1.3.3.4.2.cmml">g</mi><mrow id="alg1.l7.m1.3.3.4.3" xref="alg1.l7.m1.3.3.4.3.cmml"><mi id="alg1.l7.m1.3.3.4.3.2" xref="alg1.l7.m1.3.3.4.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="alg1.l7.m1.3.3.4.3.1" xref="alg1.l7.m1.3.3.4.3.1.cmml">​</mo><mi id="alg1.l7.m1.3.3.4.3.3" xref="alg1.l7.m1.3.3.4.3.3.cmml">d</mi><mo lspace="0em" rspace="0em" id="alg1.l7.m1.3.3.4.3.1a" xref="alg1.l7.m1.3.3.4.3.1.cmml">​</mo><mi id="alg1.l7.m1.3.3.4.3.4" xref="alg1.l7.m1.3.3.4.3.4.cmml">v</mi></mrow></msub><mo stretchy="false" id="alg1.l7.m1.3.3.3" xref="alg1.l7.m1.3.3.3.cmml">←</mo><mrow id="alg1.l7.m1.3.3.2" xref="alg1.l7.m1.3.3.2.cmml"><mrow id="alg1.l7.m1.3.3.2.4" xref="alg1.l7.m1.3.3.2.4.cmml"><msub id="alg1.l7.m1.3.3.2.4.1" xref="alg1.l7.m1.3.3.2.4.1.cmml"><mo rspace="0.167em" id="alg1.l7.m1.3.3.2.4.1.2" xref="alg1.l7.m1.3.3.2.4.1.2.cmml">∇</mo><mi id="alg1.l7.m1.3.3.2.4.1.3" xref="alg1.l7.m1.3.3.2.4.1.3.cmml">δ</mi></msub><mi id="alg1.l7.m1.3.3.2.4.2" xref="alg1.l7.m1.3.3.2.4.2.cmml">l</mi></mrow><mo lspace="0em" rspace="0em" id="alg1.l7.m1.3.3.2.3" xref="alg1.l7.m1.3.3.2.3.cmml">​</mo><mrow id="alg1.l7.m1.3.3.2.2.2" xref="alg1.l7.m1.3.3.2.2.3.cmml"><mo stretchy="false" id="alg1.l7.m1.3.3.2.2.2.3" xref="alg1.l7.m1.3.3.2.2.3.cmml">(</mo><mrow id="alg1.l7.m1.2.2.1.1.1.1" xref="alg1.l7.m1.2.2.1.1.1.1.cmml"><mi id="alg1.l7.m1.2.2.1.1.1.1.3" xref="alg1.l7.m1.2.2.1.1.1.1.3.cmml">f</mi><mo lspace="0em" rspace="0em" id="alg1.l7.m1.2.2.1.1.1.1.2" xref="alg1.l7.m1.2.2.1.1.1.1.2.cmml">​</mo><mrow id="alg1.l7.m1.2.2.1.1.1.1.1.1" xref="alg1.l7.m1.2.2.1.1.1.1.1.2.cmml"><mo stretchy="false" id="alg1.l7.m1.2.2.1.1.1.1.1.1.2" xref="alg1.l7.m1.2.2.1.1.1.1.1.2.cmml">(</mo><mrow id="alg1.l7.m1.2.2.1.1.1.1.1.1.1" xref="alg1.l7.m1.2.2.1.1.1.1.1.1.1.cmml"><mi id="alg1.l7.m1.2.2.1.1.1.1.1.1.1.2" xref="alg1.l7.m1.2.2.1.1.1.1.1.1.1.2.cmml">x</mi><mo id="alg1.l7.m1.2.2.1.1.1.1.1.1.1.1" xref="alg1.l7.m1.2.2.1.1.1.1.1.1.1.1.cmml">+</mo><mi id="alg1.l7.m1.2.2.1.1.1.1.1.1.1.3" xref="alg1.l7.m1.2.2.1.1.1.1.1.1.1.3.cmml">δ</mi></mrow><mo id="alg1.l7.m1.2.2.1.1.1.1.1.1.3" xref="alg1.l7.m1.2.2.1.1.1.1.1.2.cmml">;</mo><mi id="alg1.l7.m1.1.1" xref="alg1.l7.m1.1.1.cmml">θ</mi><mo stretchy="false" id="alg1.l7.m1.2.2.1.1.1.1.1.1.4" xref="alg1.l7.m1.2.2.1.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="alg1.l7.m1.3.3.2.2.2.4" xref="alg1.l7.m1.3.3.2.2.3.cmml">,</mo><msub id="alg1.l7.m1.3.3.2.2.2.2" xref="alg1.l7.m1.3.3.2.2.2.2.cmml"><mi id="alg1.l7.m1.3.3.2.2.2.2.2" xref="alg1.l7.m1.3.3.2.2.2.2.2.cmml">y</mi><mi id="alg1.l7.m1.3.3.2.2.2.2.3" xref="alg1.l7.m1.3.3.2.2.2.2.3.cmml">t</mi></msub><mo stretchy="false" id="alg1.l7.m1.3.3.2.2.2.5" xref="alg1.l7.m1.3.3.2.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l7.m1.3b"><apply id="alg1.l7.m1.3.3.cmml" xref="alg1.l7.m1.3.3"><ci id="alg1.l7.m1.3.3.3.cmml" xref="alg1.l7.m1.3.3.3">←</ci><apply id="alg1.l7.m1.3.3.4.cmml" xref="alg1.l7.m1.3.3.4"><csymbol cd="ambiguous" id="alg1.l7.m1.3.3.4.1.cmml" xref="alg1.l7.m1.3.3.4">subscript</csymbol><ci id="alg1.l7.m1.3.3.4.2.cmml" xref="alg1.l7.m1.3.3.4.2">𝑔</ci><apply id="alg1.l7.m1.3.3.4.3.cmml" xref="alg1.l7.m1.3.3.4.3"><times id="alg1.l7.m1.3.3.4.3.1.cmml" xref="alg1.l7.m1.3.3.4.3.1"></times><ci id="alg1.l7.m1.3.3.4.3.2.cmml" xref="alg1.l7.m1.3.3.4.3.2">𝑎</ci><ci id="alg1.l7.m1.3.3.4.3.3.cmml" xref="alg1.l7.m1.3.3.4.3.3">𝑑</ci><ci id="alg1.l7.m1.3.3.4.3.4.cmml" xref="alg1.l7.m1.3.3.4.3.4">𝑣</ci></apply></apply><apply id="alg1.l7.m1.3.3.2.cmml" xref="alg1.l7.m1.3.3.2"><times id="alg1.l7.m1.3.3.2.3.cmml" xref="alg1.l7.m1.3.3.2.3"></times><apply id="alg1.l7.m1.3.3.2.4.cmml" xref="alg1.l7.m1.3.3.2.4"><apply id="alg1.l7.m1.3.3.2.4.1.cmml" xref="alg1.l7.m1.3.3.2.4.1"><csymbol cd="ambiguous" id="alg1.l7.m1.3.3.2.4.1.1.cmml" xref="alg1.l7.m1.3.3.2.4.1">subscript</csymbol><ci id="alg1.l7.m1.3.3.2.4.1.2.cmml" xref="alg1.l7.m1.3.3.2.4.1.2">∇</ci><ci id="alg1.l7.m1.3.3.2.4.1.3.cmml" xref="alg1.l7.m1.3.3.2.4.1.3">𝛿</ci></apply><ci id="alg1.l7.m1.3.3.2.4.2.cmml" xref="alg1.l7.m1.3.3.2.4.2">𝑙</ci></apply><interval closure="open" id="alg1.l7.m1.3.3.2.2.3.cmml" xref="alg1.l7.m1.3.3.2.2.2"><apply id="alg1.l7.m1.2.2.1.1.1.1.cmml" xref="alg1.l7.m1.2.2.1.1.1.1"><times id="alg1.l7.m1.2.2.1.1.1.1.2.cmml" xref="alg1.l7.m1.2.2.1.1.1.1.2"></times><ci id="alg1.l7.m1.2.2.1.1.1.1.3.cmml" xref="alg1.l7.m1.2.2.1.1.1.1.3">𝑓</ci><list id="alg1.l7.m1.2.2.1.1.1.1.1.2.cmml" xref="alg1.l7.m1.2.2.1.1.1.1.1.1"><apply id="alg1.l7.m1.2.2.1.1.1.1.1.1.1.cmml" xref="alg1.l7.m1.2.2.1.1.1.1.1.1.1"><plus id="alg1.l7.m1.2.2.1.1.1.1.1.1.1.1.cmml" xref="alg1.l7.m1.2.2.1.1.1.1.1.1.1.1"></plus><ci id="alg1.l7.m1.2.2.1.1.1.1.1.1.1.2.cmml" xref="alg1.l7.m1.2.2.1.1.1.1.1.1.1.2">𝑥</ci><ci id="alg1.l7.m1.2.2.1.1.1.1.1.1.1.3.cmml" xref="alg1.l7.m1.2.2.1.1.1.1.1.1.1.3">𝛿</ci></apply><ci id="alg1.l7.m1.1.1.cmml" xref="alg1.l7.m1.1.1">𝜃</ci></list></apply><apply id="alg1.l7.m1.3.3.2.2.2.2.cmml" xref="alg1.l7.m1.3.3.2.2.2.2"><csymbol cd="ambiguous" id="alg1.l7.m1.3.3.2.2.2.2.1.cmml" xref="alg1.l7.m1.3.3.2.2.2.2">subscript</csymbol><ci id="alg1.l7.m1.3.3.2.2.2.2.2.cmml" xref="alg1.l7.m1.3.3.2.2.2.2.2">𝑦</ci><ci id="alg1.l7.m1.3.3.2.2.2.2.3.cmml" xref="alg1.l7.m1.3.3.2.2.2.2.3">𝑡</ci></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l7.m1.3c">g_{adv}\leftarrow\nabla_{\delta}l(f(x+\delta;\theta),y_{t})</annotation></semantics></math>

</div>
<div id="alg1.l8" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">8:</span>              <math id="alg1.l8.m1.2" class="ltx_Math" alttext="\delta\leftarrow\Pi_{\|\delta\|_{\infty}\leq\epsilon}({\color[rgb]{0,0,1}\definecolor[named]{pgfstrokecolor}{rgb}{0,0,1}\delta-\eta g_{adv}})" display="inline"><semantics id="alg1.l8.m1.2a"><mrow id="alg1.l8.m1.2.2" xref="alg1.l8.m1.2.2.cmml"><mi id="alg1.l8.m1.2.2.3" xref="alg1.l8.m1.2.2.3.cmml">δ</mi><mo stretchy="false" id="alg1.l8.m1.2.2.2" xref="alg1.l8.m1.2.2.2.cmml">←</mo><mrow id="alg1.l8.m1.2.2.1" xref="alg1.l8.m1.2.2.1.cmml"><msub id="alg1.l8.m1.2.2.1.3" xref="alg1.l8.m1.2.2.1.3.cmml"><mi mathvariant="normal" id="alg1.l8.m1.2.2.1.3.2" xref="alg1.l8.m1.2.2.1.3.2.cmml">Π</mi><mrow id="alg1.l8.m1.1.1.1" xref="alg1.l8.m1.1.1.1.cmml"><msub id="alg1.l8.m1.1.1.1.3" xref="alg1.l8.m1.1.1.1.3.cmml"><mrow id="alg1.l8.m1.1.1.1.3.2.2" xref="alg1.l8.m1.1.1.1.3.2.1.cmml"><mo stretchy="false" id="alg1.l8.m1.1.1.1.3.2.2.1" xref="alg1.l8.m1.1.1.1.3.2.1.1.cmml">‖</mo><mi id="alg1.l8.m1.1.1.1.1" xref="alg1.l8.m1.1.1.1.1.cmml">δ</mi><mo stretchy="false" id="alg1.l8.m1.1.1.1.3.2.2.2" xref="alg1.l8.m1.1.1.1.3.2.1.1.cmml">‖</mo></mrow><mi mathvariant="normal" id="alg1.l8.m1.1.1.1.3.3" xref="alg1.l8.m1.1.1.1.3.3.cmml">∞</mi></msub><mo id="alg1.l8.m1.1.1.1.2" xref="alg1.l8.m1.1.1.1.2.cmml">≤</mo><mi id="alg1.l8.m1.1.1.1.4" xref="alg1.l8.m1.1.1.1.4.cmml">ϵ</mi></mrow></msub><mo lspace="0em" rspace="0em" id="alg1.l8.m1.2.2.1.2" xref="alg1.l8.m1.2.2.1.2.cmml">​</mo><mrow id="alg1.l8.m1.2.2.1.1.1" xref="alg1.l8.m1.2.2.1.1.1.1.cmml"><mo stretchy="false" id="alg1.l8.m1.2.2.1.1.1.2" xref="alg1.l8.m1.2.2.1.1.1.1.cmml">(</mo><mrow id="alg1.l8.m1.2.2.1.1.1.1" xref="alg1.l8.m1.2.2.1.1.1.1.cmml"><mi mathcolor="#0000FF" id="alg1.l8.m1.2.2.1.1.1.1.2" xref="alg1.l8.m1.2.2.1.1.1.1.2.cmml">δ</mi><mo mathcolor="#0000FF" id="alg1.l8.m1.2.2.1.1.1.1.1" xref="alg1.l8.m1.2.2.1.1.1.1.1.cmml">−</mo><mrow id="alg1.l8.m1.2.2.1.1.1.1.3" xref="alg1.l8.m1.2.2.1.1.1.1.3.cmml"><mi mathcolor="#0000FF" id="alg1.l8.m1.2.2.1.1.1.1.3.2" xref="alg1.l8.m1.2.2.1.1.1.1.3.2.cmml">η</mi><mo lspace="0em" rspace="0em" id="alg1.l8.m1.2.2.1.1.1.1.3.1" xref="alg1.l8.m1.2.2.1.1.1.1.3.1.cmml">​</mo><msub id="alg1.l8.m1.2.2.1.1.1.1.3.3" xref="alg1.l8.m1.2.2.1.1.1.1.3.3.cmml"><mi mathcolor="#0000FF" id="alg1.l8.m1.2.2.1.1.1.1.3.3.2" xref="alg1.l8.m1.2.2.1.1.1.1.3.3.2.cmml">g</mi><mrow id="alg1.l8.m1.2.2.1.1.1.1.3.3.3" xref="alg1.l8.m1.2.2.1.1.1.1.3.3.3.cmml"><mi mathcolor="#0000FF" id="alg1.l8.m1.2.2.1.1.1.1.3.3.3.2" xref="alg1.l8.m1.2.2.1.1.1.1.3.3.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="alg1.l8.m1.2.2.1.1.1.1.3.3.3.1" xref="alg1.l8.m1.2.2.1.1.1.1.3.3.3.1.cmml">​</mo><mi mathcolor="#0000FF" id="alg1.l8.m1.2.2.1.1.1.1.3.3.3.3" xref="alg1.l8.m1.2.2.1.1.1.1.3.3.3.3.cmml">d</mi><mo lspace="0em" rspace="0em" id="alg1.l8.m1.2.2.1.1.1.1.3.3.3.1a" xref="alg1.l8.m1.2.2.1.1.1.1.3.3.3.1.cmml">​</mo><mi mathcolor="#0000FF" id="alg1.l8.m1.2.2.1.1.1.1.3.3.3.4" xref="alg1.l8.m1.2.2.1.1.1.1.3.3.3.4.cmml">v</mi></mrow></msub></mrow></mrow><mo stretchy="false" id="alg1.l8.m1.2.2.1.1.1.3" xref="alg1.l8.m1.2.2.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l8.m1.2b"><apply id="alg1.l8.m1.2.2.cmml" xref="alg1.l8.m1.2.2"><ci id="alg1.l8.m1.2.2.2.cmml" xref="alg1.l8.m1.2.2.2">←</ci><ci id="alg1.l8.m1.2.2.3.cmml" xref="alg1.l8.m1.2.2.3">𝛿</ci><apply id="alg1.l8.m1.2.2.1.cmml" xref="alg1.l8.m1.2.2.1"><times id="alg1.l8.m1.2.2.1.2.cmml" xref="alg1.l8.m1.2.2.1.2"></times><apply id="alg1.l8.m1.2.2.1.3.cmml" xref="alg1.l8.m1.2.2.1.3"><csymbol cd="ambiguous" id="alg1.l8.m1.2.2.1.3.1.cmml" xref="alg1.l8.m1.2.2.1.3">subscript</csymbol><ci id="alg1.l8.m1.2.2.1.3.2.cmml" xref="alg1.l8.m1.2.2.1.3.2">Π</ci><apply id="alg1.l8.m1.1.1.1.cmml" xref="alg1.l8.m1.1.1.1"><leq id="alg1.l8.m1.1.1.1.2.cmml" xref="alg1.l8.m1.1.1.1.2"></leq><apply id="alg1.l8.m1.1.1.1.3.cmml" xref="alg1.l8.m1.1.1.1.3"><csymbol cd="ambiguous" id="alg1.l8.m1.1.1.1.3.1.cmml" xref="alg1.l8.m1.1.1.1.3">subscript</csymbol><apply id="alg1.l8.m1.1.1.1.3.2.1.cmml" xref="alg1.l8.m1.1.1.1.3.2.2"><csymbol cd="latexml" id="alg1.l8.m1.1.1.1.3.2.1.1.cmml" xref="alg1.l8.m1.1.1.1.3.2.2.1">norm</csymbol><ci id="alg1.l8.m1.1.1.1.1.cmml" xref="alg1.l8.m1.1.1.1.1">𝛿</ci></apply><infinity id="alg1.l8.m1.1.1.1.3.3.cmml" xref="alg1.l8.m1.1.1.1.3.3"></infinity></apply><ci id="alg1.l8.m1.1.1.1.4.cmml" xref="alg1.l8.m1.1.1.1.4">italic-ϵ</ci></apply></apply><apply id="alg1.l8.m1.2.2.1.1.1.1.cmml" xref="alg1.l8.m1.2.2.1.1.1"><minus id="alg1.l8.m1.2.2.1.1.1.1.1.cmml" xref="alg1.l8.m1.2.2.1.1.1.1.1"></minus><ci id="alg1.l8.m1.2.2.1.1.1.1.2.cmml" xref="alg1.l8.m1.2.2.1.1.1.1.2">𝛿</ci><apply id="alg1.l8.m1.2.2.1.1.1.1.3.cmml" xref="alg1.l8.m1.2.2.1.1.1.1.3"><times id="alg1.l8.m1.2.2.1.1.1.1.3.1.cmml" xref="alg1.l8.m1.2.2.1.1.1.1.3.1"></times><ci id="alg1.l8.m1.2.2.1.1.1.1.3.2.cmml" xref="alg1.l8.m1.2.2.1.1.1.1.3.2">𝜂</ci><apply id="alg1.l8.m1.2.2.1.1.1.1.3.3.cmml" xref="alg1.l8.m1.2.2.1.1.1.1.3.3"><csymbol cd="ambiguous" id="alg1.l8.m1.2.2.1.1.1.1.3.3.1.cmml" xref="alg1.l8.m1.2.2.1.1.1.1.3.3">subscript</csymbol><ci id="alg1.l8.m1.2.2.1.1.1.1.3.3.2.cmml" xref="alg1.l8.m1.2.2.1.1.1.1.3.3.2">𝑔</ci><apply id="alg1.l8.m1.2.2.1.1.1.1.3.3.3.cmml" xref="alg1.l8.m1.2.2.1.1.1.1.3.3.3"><times id="alg1.l8.m1.2.2.1.1.1.1.3.3.3.1.cmml" xref="alg1.l8.m1.2.2.1.1.1.1.3.3.3.1"></times><ci id="alg1.l8.m1.2.2.1.1.1.1.3.3.3.2.cmml" xref="alg1.l8.m1.2.2.1.1.1.1.3.3.3.2">𝑎</ci><ci id="alg1.l8.m1.2.2.1.1.1.1.3.3.3.3.cmml" xref="alg1.l8.m1.2.2.1.1.1.1.3.3.3.3">𝑑</ci><ci id="alg1.l8.m1.2.2.1.1.1.1.3.3.3.4.cmml" xref="alg1.l8.m1.2.2.1.1.1.1.3.3.3.4">𝑣</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l8.m1.2c">\delta\leftarrow\Pi_{\|\delta\|_{\infty}\leq\epsilon}({\color[rgb]{0,0,1}\definecolor[named]{pgfstrokecolor}{rgb}{0,0,1}\delta-\eta g_{adv}})</annotation></semantics></math>

</div>
<div id="alg1.l9" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">9:</span>         <span id="alg1.l9.1" class="ltx_text ltx_font_bold">end</span> <span id="alg1.l9.2" class="ltx_text ltx_font_bold">for</span>
</div>
<div id="alg1.l10" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">10:</span>         <math id="alg1.l10.m1.4" class="ltx_Math" alttext="g_{\theta}\leftarrow\nabla_{\theta}l(f(x;\theta),y)" display="inline"><semantics id="alg1.l10.m1.4a"><mrow id="alg1.l10.m1.4.4" xref="alg1.l10.m1.4.4.cmml"><msub id="alg1.l10.m1.4.4.3" xref="alg1.l10.m1.4.4.3.cmml"><mi id="alg1.l10.m1.4.4.3.2" xref="alg1.l10.m1.4.4.3.2.cmml">g</mi><mi id="alg1.l10.m1.4.4.3.3" xref="alg1.l10.m1.4.4.3.3.cmml">θ</mi></msub><mo stretchy="false" id="alg1.l10.m1.4.4.2" xref="alg1.l10.m1.4.4.2.cmml">←</mo><mrow id="alg1.l10.m1.4.4.1" xref="alg1.l10.m1.4.4.1.cmml"><mrow id="alg1.l10.m1.4.4.1.3" xref="alg1.l10.m1.4.4.1.3.cmml"><msub id="alg1.l10.m1.4.4.1.3.1" xref="alg1.l10.m1.4.4.1.3.1.cmml"><mo rspace="0.167em" id="alg1.l10.m1.4.4.1.3.1.2" xref="alg1.l10.m1.4.4.1.3.1.2.cmml">∇</mo><mi id="alg1.l10.m1.4.4.1.3.1.3" xref="alg1.l10.m1.4.4.1.3.1.3.cmml">θ</mi></msub><mi id="alg1.l10.m1.4.4.1.3.2" xref="alg1.l10.m1.4.4.1.3.2.cmml">l</mi></mrow><mo lspace="0em" rspace="0em" id="alg1.l10.m1.4.4.1.2" xref="alg1.l10.m1.4.4.1.2.cmml">​</mo><mrow id="alg1.l10.m1.4.4.1.1.1" xref="alg1.l10.m1.4.4.1.1.2.cmml"><mo stretchy="false" id="alg1.l10.m1.4.4.1.1.1.2" xref="alg1.l10.m1.4.4.1.1.2.cmml">(</mo><mrow id="alg1.l10.m1.4.4.1.1.1.1" xref="alg1.l10.m1.4.4.1.1.1.1.cmml"><mi id="alg1.l10.m1.4.4.1.1.1.1.2" xref="alg1.l10.m1.4.4.1.1.1.1.2.cmml">f</mi><mo lspace="0em" rspace="0em" id="alg1.l10.m1.4.4.1.1.1.1.1" xref="alg1.l10.m1.4.4.1.1.1.1.1.cmml">​</mo><mrow id="alg1.l10.m1.4.4.1.1.1.1.3.2" xref="alg1.l10.m1.4.4.1.1.1.1.3.1.cmml"><mo stretchy="false" id="alg1.l10.m1.4.4.1.1.1.1.3.2.1" xref="alg1.l10.m1.4.4.1.1.1.1.3.1.cmml">(</mo><mi id="alg1.l10.m1.1.1" xref="alg1.l10.m1.1.1.cmml">x</mi><mo id="alg1.l10.m1.4.4.1.1.1.1.3.2.2" xref="alg1.l10.m1.4.4.1.1.1.1.3.1.cmml">;</mo><mi id="alg1.l10.m1.2.2" xref="alg1.l10.m1.2.2.cmml">θ</mi><mo stretchy="false" id="alg1.l10.m1.4.4.1.1.1.1.3.2.3" xref="alg1.l10.m1.4.4.1.1.1.1.3.1.cmml">)</mo></mrow></mrow><mo id="alg1.l10.m1.4.4.1.1.1.3" xref="alg1.l10.m1.4.4.1.1.2.cmml">,</mo><mi id="alg1.l10.m1.3.3" xref="alg1.l10.m1.3.3.cmml">y</mi><mo stretchy="false" id="alg1.l10.m1.4.4.1.1.1.4" xref="alg1.l10.m1.4.4.1.1.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l10.m1.4b"><apply id="alg1.l10.m1.4.4.cmml" xref="alg1.l10.m1.4.4"><ci id="alg1.l10.m1.4.4.2.cmml" xref="alg1.l10.m1.4.4.2">←</ci><apply id="alg1.l10.m1.4.4.3.cmml" xref="alg1.l10.m1.4.4.3"><csymbol cd="ambiguous" id="alg1.l10.m1.4.4.3.1.cmml" xref="alg1.l10.m1.4.4.3">subscript</csymbol><ci id="alg1.l10.m1.4.4.3.2.cmml" xref="alg1.l10.m1.4.4.3.2">𝑔</ci><ci id="alg1.l10.m1.4.4.3.3.cmml" xref="alg1.l10.m1.4.4.3.3">𝜃</ci></apply><apply id="alg1.l10.m1.4.4.1.cmml" xref="alg1.l10.m1.4.4.1"><times id="alg1.l10.m1.4.4.1.2.cmml" xref="alg1.l10.m1.4.4.1.2"></times><apply id="alg1.l10.m1.4.4.1.3.cmml" xref="alg1.l10.m1.4.4.1.3"><apply id="alg1.l10.m1.4.4.1.3.1.cmml" xref="alg1.l10.m1.4.4.1.3.1"><csymbol cd="ambiguous" id="alg1.l10.m1.4.4.1.3.1.1.cmml" xref="alg1.l10.m1.4.4.1.3.1">subscript</csymbol><ci id="alg1.l10.m1.4.4.1.3.1.2.cmml" xref="alg1.l10.m1.4.4.1.3.1.2">∇</ci><ci id="alg1.l10.m1.4.4.1.3.1.3.cmml" xref="alg1.l10.m1.4.4.1.3.1.3">𝜃</ci></apply><ci id="alg1.l10.m1.4.4.1.3.2.cmml" xref="alg1.l10.m1.4.4.1.3.2">𝑙</ci></apply><interval closure="open" id="alg1.l10.m1.4.4.1.1.2.cmml" xref="alg1.l10.m1.4.4.1.1.1"><apply id="alg1.l10.m1.4.4.1.1.1.1.cmml" xref="alg1.l10.m1.4.4.1.1.1.1"><times id="alg1.l10.m1.4.4.1.1.1.1.1.cmml" xref="alg1.l10.m1.4.4.1.1.1.1.1"></times><ci id="alg1.l10.m1.4.4.1.1.1.1.2.cmml" xref="alg1.l10.m1.4.4.1.1.1.1.2">𝑓</ci><list id="alg1.l10.m1.4.4.1.1.1.1.3.1.cmml" xref="alg1.l10.m1.4.4.1.1.1.1.3.2"><ci id="alg1.l10.m1.1.1.cmml" xref="alg1.l10.m1.1.1">𝑥</ci><ci id="alg1.l10.m1.2.2.cmml" xref="alg1.l10.m1.2.2">𝜃</ci></list></apply><ci id="alg1.l10.m1.3.3.cmml" xref="alg1.l10.m1.3.3">𝑦</ci></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l10.m1.4c">g_{\theta}\leftarrow\nabla_{\theta}l(f(x;\theta),y)</annotation></semantics></math>
<math id="alg1.l10.m2.5" class="ltx_Math" alttext="\qquad\quad+\alpha\nabla_{\theta}l(f(x;\theta),f(x+\delta;\theta))" display="inline"><semantics id="alg1.l10.m2.5a"><mrow id="alg1.l10.m2.5.5" xref="alg1.l10.m2.5.5.cmml"><mo id="alg1.l10.m2.5.5a" xref="alg1.l10.m2.5.5.cmml">+</mo><mrow id="alg1.l10.m2.5.5.2" xref="alg1.l10.m2.5.5.2.cmml"><mi id="alg1.l10.m2.5.5.2.4" xref="alg1.l10.m2.5.5.2.4.cmml">α</mi><mo lspace="0.167em" rspace="0em" id="alg1.l10.m2.5.5.2.3" xref="alg1.l10.m2.5.5.2.3.cmml">​</mo><mrow id="alg1.l10.m2.5.5.2.5" xref="alg1.l10.m2.5.5.2.5.cmml"><msub id="alg1.l10.m2.5.5.2.5.1" xref="alg1.l10.m2.5.5.2.5.1.cmml"><mo rspace="0.167em" id="alg1.l10.m2.5.5.2.5.1.2" xref="alg1.l10.m2.5.5.2.5.1.2.cmml">∇</mo><mi id="alg1.l10.m2.5.5.2.5.1.3" xref="alg1.l10.m2.5.5.2.5.1.3.cmml">θ</mi></msub><mi id="alg1.l10.m2.5.5.2.5.2" xref="alg1.l10.m2.5.5.2.5.2.cmml">l</mi></mrow><mo lspace="0em" rspace="0em" id="alg1.l10.m2.5.5.2.3a" xref="alg1.l10.m2.5.5.2.3.cmml">​</mo><mrow id="alg1.l10.m2.5.5.2.2.2" xref="alg1.l10.m2.5.5.2.2.3.cmml"><mo stretchy="false" id="alg1.l10.m2.5.5.2.2.2.3" xref="alg1.l10.m2.5.5.2.2.3.cmml">(</mo><mrow id="alg1.l10.m2.4.4.1.1.1.1" xref="alg1.l10.m2.4.4.1.1.1.1.cmml"><mi id="alg1.l10.m2.4.4.1.1.1.1.2" xref="alg1.l10.m2.4.4.1.1.1.1.2.cmml">f</mi><mo lspace="0em" rspace="0em" id="alg1.l10.m2.4.4.1.1.1.1.1" xref="alg1.l10.m2.4.4.1.1.1.1.1.cmml">​</mo><mrow id="alg1.l10.m2.4.4.1.1.1.1.3.2" xref="alg1.l10.m2.4.4.1.1.1.1.3.1.cmml"><mo stretchy="false" id="alg1.l10.m2.4.4.1.1.1.1.3.2.1" xref="alg1.l10.m2.4.4.1.1.1.1.3.1.cmml">(</mo><mi id="alg1.l10.m2.1.1" xref="alg1.l10.m2.1.1.cmml">x</mi><mo id="alg1.l10.m2.4.4.1.1.1.1.3.2.2" xref="alg1.l10.m2.4.4.1.1.1.1.3.1.cmml">;</mo><mi id="alg1.l10.m2.2.2" xref="alg1.l10.m2.2.2.cmml">θ</mi><mo stretchy="false" id="alg1.l10.m2.4.4.1.1.1.1.3.2.3" xref="alg1.l10.m2.4.4.1.1.1.1.3.1.cmml">)</mo></mrow></mrow><mo id="alg1.l10.m2.5.5.2.2.2.4" xref="alg1.l10.m2.5.5.2.2.3.cmml">,</mo><mrow id="alg1.l10.m2.5.5.2.2.2.2" xref="alg1.l10.m2.5.5.2.2.2.2.cmml"><mi id="alg1.l10.m2.5.5.2.2.2.2.3" xref="alg1.l10.m2.5.5.2.2.2.2.3.cmml">f</mi><mo lspace="0em" rspace="0em" id="alg1.l10.m2.5.5.2.2.2.2.2" xref="alg1.l10.m2.5.5.2.2.2.2.2.cmml">​</mo><mrow id="alg1.l10.m2.5.5.2.2.2.2.1.1" xref="alg1.l10.m2.5.5.2.2.2.2.1.2.cmml"><mo stretchy="false" id="alg1.l10.m2.5.5.2.2.2.2.1.1.2" xref="alg1.l10.m2.5.5.2.2.2.2.1.2.cmml">(</mo><mrow id="alg1.l10.m2.5.5.2.2.2.2.1.1.1" xref="alg1.l10.m2.5.5.2.2.2.2.1.1.1.cmml"><mi id="alg1.l10.m2.5.5.2.2.2.2.1.1.1.2" xref="alg1.l10.m2.5.5.2.2.2.2.1.1.1.2.cmml">x</mi><mo id="alg1.l10.m2.5.5.2.2.2.2.1.1.1.1" xref="alg1.l10.m2.5.5.2.2.2.2.1.1.1.1.cmml">+</mo><mi id="alg1.l10.m2.5.5.2.2.2.2.1.1.1.3" xref="alg1.l10.m2.5.5.2.2.2.2.1.1.1.3.cmml">δ</mi></mrow><mo id="alg1.l10.m2.5.5.2.2.2.2.1.1.3" xref="alg1.l10.m2.5.5.2.2.2.2.1.2.cmml">;</mo><mi id="alg1.l10.m2.3.3" xref="alg1.l10.m2.3.3.cmml">θ</mi><mo stretchy="false" id="alg1.l10.m2.5.5.2.2.2.2.1.1.4" xref="alg1.l10.m2.5.5.2.2.2.2.1.2.cmml">)</mo></mrow></mrow><mo stretchy="false" id="alg1.l10.m2.5.5.2.2.2.5" xref="alg1.l10.m2.5.5.2.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l10.m2.5b"><apply id="alg1.l10.m2.5.5.cmml" xref="alg1.l10.m2.5.5"><plus id="alg1.l10.m2.5.5.3.cmml" xref="alg1.l10.m2.5.5"></plus><apply id="alg1.l10.m2.5.5.2.cmml" xref="alg1.l10.m2.5.5.2"><times id="alg1.l10.m2.5.5.2.3.cmml" xref="alg1.l10.m2.5.5.2.3"></times><ci id="alg1.l10.m2.5.5.2.4.cmml" xref="alg1.l10.m2.5.5.2.4">𝛼</ci><apply id="alg1.l10.m2.5.5.2.5.cmml" xref="alg1.l10.m2.5.5.2.5"><apply id="alg1.l10.m2.5.5.2.5.1.cmml" xref="alg1.l10.m2.5.5.2.5.1"><csymbol cd="ambiguous" id="alg1.l10.m2.5.5.2.5.1.1.cmml" xref="alg1.l10.m2.5.5.2.5.1">subscript</csymbol><ci id="alg1.l10.m2.5.5.2.5.1.2.cmml" xref="alg1.l10.m2.5.5.2.5.1.2">∇</ci><ci id="alg1.l10.m2.5.5.2.5.1.3.cmml" xref="alg1.l10.m2.5.5.2.5.1.3">𝜃</ci></apply><ci id="alg1.l10.m2.5.5.2.5.2.cmml" xref="alg1.l10.m2.5.5.2.5.2">𝑙</ci></apply><interval closure="open" id="alg1.l10.m2.5.5.2.2.3.cmml" xref="alg1.l10.m2.5.5.2.2.2"><apply id="alg1.l10.m2.4.4.1.1.1.1.cmml" xref="alg1.l10.m2.4.4.1.1.1.1"><times id="alg1.l10.m2.4.4.1.1.1.1.1.cmml" xref="alg1.l10.m2.4.4.1.1.1.1.1"></times><ci id="alg1.l10.m2.4.4.1.1.1.1.2.cmml" xref="alg1.l10.m2.4.4.1.1.1.1.2">𝑓</ci><list id="alg1.l10.m2.4.4.1.1.1.1.3.1.cmml" xref="alg1.l10.m2.4.4.1.1.1.1.3.2"><ci id="alg1.l10.m2.1.1.cmml" xref="alg1.l10.m2.1.1">𝑥</ci><ci id="alg1.l10.m2.2.2.cmml" xref="alg1.l10.m2.2.2">𝜃</ci></list></apply><apply id="alg1.l10.m2.5.5.2.2.2.2.cmml" xref="alg1.l10.m2.5.5.2.2.2.2"><times id="alg1.l10.m2.5.5.2.2.2.2.2.cmml" xref="alg1.l10.m2.5.5.2.2.2.2.2"></times><ci id="alg1.l10.m2.5.5.2.2.2.2.3.cmml" xref="alg1.l10.m2.5.5.2.2.2.2.3">𝑓</ci><list id="alg1.l10.m2.5.5.2.2.2.2.1.2.cmml" xref="alg1.l10.m2.5.5.2.2.2.2.1.1"><apply id="alg1.l10.m2.5.5.2.2.2.2.1.1.1.cmml" xref="alg1.l10.m2.5.5.2.2.2.2.1.1.1"><plus id="alg1.l10.m2.5.5.2.2.2.2.1.1.1.1.cmml" xref="alg1.l10.m2.5.5.2.2.2.2.1.1.1.1"></plus><ci id="alg1.l10.m2.5.5.2.2.2.2.1.1.1.2.cmml" xref="alg1.l10.m2.5.5.2.2.2.2.1.1.1.2">𝑥</ci><ci id="alg1.l10.m2.5.5.2.2.2.2.1.1.1.3.cmml" xref="alg1.l10.m2.5.5.2.2.2.2.1.1.1.3">𝛿</ci></apply><ci id="alg1.l10.m2.3.3.cmml" xref="alg1.l10.m2.3.3">𝜃</ci></list></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l10.m2.5c">\qquad\quad+\alpha\nabla_{\theta}l(f(x;\theta),f(x+\delta;\theta))</annotation></semantics></math>

</div>
<div id="alg1.l11" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">11:</span>         <math id="alg1.l11.m1.1" class="ltx_Math" alttext="\theta\leftarrow\theta-\tau g_{\theta}" display="inline"><semantics id="alg1.l11.m1.1a"><mrow id="alg1.l11.m1.1.1" xref="alg1.l11.m1.1.1.cmml"><mi id="alg1.l11.m1.1.1.2" xref="alg1.l11.m1.1.1.2.cmml">θ</mi><mo stretchy="false" id="alg1.l11.m1.1.1.1" xref="alg1.l11.m1.1.1.1.cmml">←</mo><mrow id="alg1.l11.m1.1.1.3" xref="alg1.l11.m1.1.1.3.cmml"><mi id="alg1.l11.m1.1.1.3.2" xref="alg1.l11.m1.1.1.3.2.cmml">θ</mi><mo id="alg1.l11.m1.1.1.3.1" xref="alg1.l11.m1.1.1.3.1.cmml">−</mo><mrow id="alg1.l11.m1.1.1.3.3" xref="alg1.l11.m1.1.1.3.3.cmml"><mi id="alg1.l11.m1.1.1.3.3.2" xref="alg1.l11.m1.1.1.3.3.2.cmml">τ</mi><mo lspace="0em" rspace="0em" id="alg1.l11.m1.1.1.3.3.1" xref="alg1.l11.m1.1.1.3.3.1.cmml">​</mo><msub id="alg1.l11.m1.1.1.3.3.3" xref="alg1.l11.m1.1.1.3.3.3.cmml"><mi id="alg1.l11.m1.1.1.3.3.3.2" xref="alg1.l11.m1.1.1.3.3.3.2.cmml">g</mi><mi id="alg1.l11.m1.1.1.3.3.3.3" xref="alg1.l11.m1.1.1.3.3.3.3.cmml">θ</mi></msub></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l11.m1.1b"><apply id="alg1.l11.m1.1.1.cmml" xref="alg1.l11.m1.1.1"><ci id="alg1.l11.m1.1.1.1.cmml" xref="alg1.l11.m1.1.1.1">←</ci><ci id="alg1.l11.m1.1.1.2.cmml" xref="alg1.l11.m1.1.1.2">𝜃</ci><apply id="alg1.l11.m1.1.1.3.cmml" xref="alg1.l11.m1.1.1.3"><minus id="alg1.l11.m1.1.1.3.1.cmml" xref="alg1.l11.m1.1.1.3.1"></minus><ci id="alg1.l11.m1.1.1.3.2.cmml" xref="alg1.l11.m1.1.1.3.2">𝜃</ci><apply id="alg1.l11.m1.1.1.3.3.cmml" xref="alg1.l11.m1.1.1.3.3"><times id="alg1.l11.m1.1.1.3.3.1.cmml" xref="alg1.l11.m1.1.1.3.3.1"></times><ci id="alg1.l11.m1.1.1.3.3.2.cmml" xref="alg1.l11.m1.1.1.3.3.2">𝜏</ci><apply id="alg1.l11.m1.1.1.3.3.3.cmml" xref="alg1.l11.m1.1.1.3.3.3"><csymbol cd="ambiguous" id="alg1.l11.m1.1.1.3.3.3.1.cmml" xref="alg1.l11.m1.1.1.3.3.3">subscript</csymbol><ci id="alg1.l11.m1.1.1.3.3.3.2.cmml" xref="alg1.l11.m1.1.1.3.3.3.2">𝑔</ci><ci id="alg1.l11.m1.1.1.3.3.3.3.cmml" xref="alg1.l11.m1.1.1.3.3.3.3">𝜃</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l11.m1.1c">\theta\leftarrow\theta-\tau g_{\theta}</annotation></semantics></math>

</div>
<div id="alg1.l12" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">12:</span>     <span id="alg1.l12.1" class="ltx_text ltx_font_bold">end</span> <span id="alg1.l12.2" class="ltx_text ltx_font_bold">for</span>
</div>
<div id="alg1.l13" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">13:</span><span id="alg1.l13.1" class="ltx_text ltx_font_bold">end</span> <span id="alg1.l13.2" class="ltx_text ltx_font_bold">for</span>
</div>
<div id="alg1.l14" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">14:</span><math id="alg1.l14.m1.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="alg1.l14.m1.1a"><mi id="alg1.l14.m1.1.1" xref="alg1.l14.m1.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="alg1.l14.m1.1b"><ci id="alg1.l14.m1.1.1.cmml" xref="alg1.l14.m1.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l14.m1.1c">\theta</annotation></semantics></math>

</div>
</div>
</figure>
<figure id="S2.T1" class="ltx_table">
<table id="S2.T1.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S2.T1.1.1" class="ltx_tr">
<td id="S2.T1.1.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt"><span id="S2.T1.1.1.1.1" class="ltx_text ltx_font_bold">Methods</span></td>
<td id="S2.T1.1.1.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_tt">MNLI-m/mm</td>
<td id="S2.T1.1.1.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_tt">QQP</td>
<td id="S2.T1.1.1.4" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_tt">RTE</td>
<td id="S2.T1.1.1.5" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_tt">QNLI</td>
<td id="S2.T1.1.1.6" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_tt">MRPC</td>
<td id="S2.T1.1.1.7" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_tt">CoLA</td>
<td id="S2.T1.1.1.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_tt">SST</td>
<td id="S2.T1.1.1.9" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_tt">STS-B</td>
<td id="S2.T1.1.1.10" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_tt">Average</td>
</tr>
<tr id="S2.T1.1.2" class="ltx_tr">
<td id="S2.T1.1.2.1" class="ltx_td ltx_border_r"></td>
<td id="S2.T1.1.2.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">Acc</td>
<td id="S2.T1.1.2.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">Acc/F1</td>
<td id="S2.T1.1.2.4" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">Acc</td>
<td id="S2.T1.1.2.5" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">Acc</td>
<td id="S2.T1.1.2.6" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">Acc/F1</td>
<td id="S2.T1.1.2.7" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">Mcc</td>
<td id="S2.T1.1.2.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r">Acc</td>
<td id="S2.T1.1.2.9" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">P/S Corr</td>
<td id="S2.T1.1.2.10" class="ltx_td ltx_nopad_l ltx_align_center">Score</td>
</tr>
<tr id="S2.T1.1.3" class="ltx_tr">
<td id="S2.T1.1.3.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Standard (BERT<sub id="S2.T1.1.3.1.1" class="ltx_sub">LARGE</sub>)<sup id="S2.T1.1.3.1.2" class="ltx_sup">dev</sup>
</td>
<td id="S2.T1.1.3.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_t">86.3/86.2</td>
<td id="S2.T1.1.3.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_t">91.3/88.4</td>
<td id="S2.T1.1.3.4" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_t">71.1</td>
<td id="S2.T1.1.3.5" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_t">92.4</td>
<td id="S2.T1.1.3.6" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_t">85.8/89.5</td>
<td id="S2.T1.1.3.7" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_t">61.8</td>
<td id="S2.T1.1.3.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t">93.5</td>
<td id="S2.T1.1.3.9" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_t">89.6/89.3</td>
<td id="S2.T1.1.3.10" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t">84.0</td>
</tr>
<tr id="S2.T1.1.4" class="ltx_tr">
<td id="S2.T1.1.4.1" class="ltx_td ltx_align_left ltx_border_r">Standard (BERT<sub id="S2.T1.1.4.1.1" class="ltx_sub">LARGE</sub>)<sup id="S2.T1.1.4.1.2" class="ltx_sup">test</sup>
</td>
<td id="S2.T1.1.4.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">86.7/85.9</td>
<td id="S2.T1.1.4.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">72.1/89.3</td>
<td id="S2.T1.1.4.4" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">70.1</td>
<td id="S2.T1.1.4.5" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">92.7</td>
<td id="S2.T1.1.4.6" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">85.4/89.3</td>
<td id="S2.T1.1.4.7" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">60.5</td>
<td id="S2.T1.1.4.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r">94.9</td>
<td id="S2.T1.1.4.9" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">87.6/86.5</td>
<td id="S2.T1.1.4.10" class="ltx_td ltx_nopad_l ltx_align_center">82.4</td>
</tr>
<tr id="S2.T1.1.5" class="ltx_tr">
<td id="S2.T1.1.5.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Standard<sup id="S2.T1.1.5.1.1" class="ltx_sup">dev</sup>
</td>
<td id="S2.T1.1.5.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_t">84.5/84.4</td>
<td id="S2.T1.1.5.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_t">90.9/88.3</td>
<td id="S2.T1.1.5.4" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_t">63.5</td>
<td id="S2.T1.1.5.5" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_t">91.1</td>
<td id="S2.T1.1.5.6" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_t">84.1/89.0</td>
<td id="S2.T1.1.5.7" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_t">54.7</td>
<td id="S2.T1.1.5.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t">92.9</td>
<td id="S2.T1.1.5.9" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_t">89.2/88.8</td>
<td id="S2.T1.1.5.10" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t">81.5</td>
</tr>
<tr id="S2.T1.1.6" class="ltx_tr">
<td id="S2.T1.1.6.1" class="ltx_td ltx_align_left ltx_border_r">FreeLB<sup id="S2.T1.1.6.1.1" class="ltx_sup">dev</sup>
</td>
<td id="S2.T1.1.6.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">85.4/85.5</td>
<td id="S2.T1.1.6.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">91.4/88.4</td>
<td id="S2.T1.1.6.4" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">70.4</td>
<td id="S2.T1.1.6.5" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">91.5</td>
<td id="S2.T1.1.6.6" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">86.2/90.3</td>
<td id="S2.T1.1.6.7" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r"><span id="S2.T1.1.6.7.1" class="ltx_text ltx_font_bold">59.1</span></td>
<td id="S2.T1.1.6.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r">93.2</td>
<td id="S2.T1.1.6.9" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">89.7/89.1</td>
<td id="S2.T1.1.6.10" class="ltx_td ltx_nopad_l ltx_align_center">83.5</td>
</tr>
<tr id="S2.T1.1.7" class="ltx_tr">
<td id="S2.T1.1.7.1" class="ltx_td ltx_align_left ltx_border_r">VAT<sup id="S2.T1.1.7.1.1" class="ltx_sup">dev</sup>
</td>
<td id="S2.T1.1.7.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">85.5/85.7</td>
<td id="S2.T1.1.7.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">91.5/88.5</td>
<td id="S2.T1.1.7.4" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">71.2</td>
<td id="S2.T1.1.7.5" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">91.7</td>
<td id="S2.T1.1.7.6" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">87.7/91.3</td>
<td id="S2.T1.1.7.7" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">58.2</td>
<td id="S2.T1.1.7.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r">93.3</td>
<td id="S2.T1.1.7.9" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">90.0/89.4</td>
<td id="S2.T1.1.7.10" class="ltx_td ltx_nopad_l ltx_align_center">83.7</td>
</tr>
<tr id="S2.T1.1.8" class="ltx_tr">
<td id="S2.T1.1.8.1" class="ltx_td ltx_align_left ltx_border_r">TAT<sup id="S2.T1.1.8.1.1" class="ltx_sup">dev</sup>
</td>
<td id="S2.T1.1.8.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r"><span id="S2.T1.1.8.2.1" class="ltx_text ltx_font_bold">86.2/85.9</span></td>
<td id="S2.T1.1.8.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r"><span id="S2.T1.1.8.3.1" class="ltx_text ltx_font_bold">91.8/89.1</span></td>
<td id="S2.T1.1.8.4" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r"><span id="S2.T1.1.8.4.1" class="ltx_text ltx_font_bold">72.6</span></td>
<td id="S2.T1.1.8.5" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r"><span id="S2.T1.1.8.5.1" class="ltx_text ltx_font_bold">92.2</span></td>
<td id="S2.T1.1.8.6" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r"><span id="S2.T1.1.8.6.1" class="ltx_text ltx_font_bold">88.2/91.5</span></td>
<td id="S2.T1.1.8.7" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">58.5</td>
<td id="S2.T1.1.8.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r"><span id="S2.T1.1.8.8.1" class="ltx_text ltx_font_bold">93.6</span></td>
<td id="S2.T1.1.8.9" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r"><span id="S2.T1.1.8.9.1" class="ltx_text ltx_font_bold">90.8/89.6</span></td>
<td id="S2.T1.1.8.10" class="ltx_td ltx_nopad_l ltx_align_center"><span id="S2.T1.1.8.10.1" class="ltx_text ltx_font_bold">84.2</span></td>
</tr>
<tr id="S2.T1.1.9" class="ltx_tr">
<td id="S2.T1.1.9.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Standard<sup id="S2.T1.1.9.1.1" class="ltx_sup">test</sup>
</td>
<td id="S2.T1.1.9.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_t">84.6/83.4</td>
<td id="S2.T1.1.9.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_t">71.2/89.2</td>
<td id="S2.T1.1.9.4" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_t">66.4</td>
<td id="S2.T1.1.9.5" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_t">90.5</td>
<td id="S2.T1.1.9.6" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_t">84.8/88.9</td>
<td id="S2.T1.1.9.7" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_t">52.1</td>
<td id="S2.T1.1.9.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_r ltx_border_t">93.5</td>
<td id="S2.T1.1.9.9" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_t">87.1/85.8</td>
<td id="S2.T1.1.9.10" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t">80.0</td>
</tr>
<tr id="S2.T1.1.10" class="ltx_tr">
<td id="S2.T1.1.10.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">TAT<sup id="S2.T1.1.10.1.1" class="ltx_sup">test</sup>
</td>
<td id="S2.T1.1.10.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb ltx_border_r"><span id="S2.T1.1.10.2.1" class="ltx_text ltx_font_bold">85.8/84.8</span></td>
<td id="S2.T1.1.10.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb ltx_border_r"><span id="S2.T1.1.10.3.1" class="ltx_text ltx_font_bold">72.8/89.6</span></td>
<td id="S2.T1.1.10.4" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb ltx_border_r"><span id="S2.T1.1.10.4.1" class="ltx_text ltx_font_bold">69.7</span></td>
<td id="S2.T1.1.10.5" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb ltx_border_r"><span id="S2.T1.1.10.5.1" class="ltx_text ltx_font_bold">92.4</span></td>
<td id="S2.T1.1.10.6" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb ltx_border_r"><span id="S2.T1.1.10.6.1" class="ltx_text ltx_font_bold">88.2/91.1</span></td>
<td id="S2.T1.1.10.7" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb ltx_border_r"><span id="S2.T1.1.10.7.1" class="ltx_text ltx_font_bold">59.8</span></td>
<td id="S2.T1.1.10.8" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_r"><span id="S2.T1.1.10.8.1" class="ltx_text ltx_font_bold">94.5</span></td>
<td id="S2.T1.1.10.9" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb ltx_border_r"><span id="S2.T1.1.10.9.1" class="ltx_text ltx_font_bold">89.7/89.0</span></td>
<td id="S2.T1.1.10.10" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb"><span id="S2.T1.1.10.10.1" class="ltx_text ltx_font_bold">82.8</span></td>
</tr>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>Comparison of standard and adversarial training methods on GLUE. All rows except the top two use standard BERT<sub id="S2.T1.5.1" class="ltx_sub">BASE</sub> model. The GLUE test results are scored using the GLUE evaluation server. Note that the test results of Standard including BERT<sub id="S2.T1.6.2" class="ltx_sub">BASE</sub> and BERT<sub id="S2.T1.7.3" class="ltx_sub">LARGE</sub> are taken from https://gluebenchmark.com/leaderboard.
</figcaption>
</figure>
<div id="S2.p5" class="ltx_para">
<p id="S2.p5.14" class="ltx_p">In standard adversarial training, the algorithm simply tries to perturb the input <math id="S2.p5.1.m1.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S2.p5.1.m1.1a"><mi id="S2.p5.1.m1.1.1" xref="S2.p5.1.m1.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S2.p5.1.m1.1b"><ci id="S2.p5.1.m1.1.1.cmml" xref="S2.p5.1.m1.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.1.m1.1c">x</annotation></semantics></math> away from the gold label <math id="S2.p5.2.m2.1" class="ltx_Math" alttext="y" display="inline"><semantics id="S2.p5.2.m2.1a"><mi id="S2.p5.2.m2.1.1" xref="S2.p5.2.m2.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S2.p5.2.m2.1b"><ci id="S2.p5.2.m2.1.1.cmml" xref="S2.p5.2.m2.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.2.m2.1c">y</annotation></semantics></math> given the current parameters <math id="S2.p5.3.m3.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="S2.p5.3.m3.1a"><mi id="S2.p5.3.m3.1.1" xref="S2.p5.3.m3.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="S2.p5.3.m3.1b"><ci id="S2.p5.3.m3.1.1.cmml" xref="S2.p5.3.m3.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.3.m3.1c">\theta</annotation></semantics></math>. It is agnostic to which incorrect label <math id="S2.p5.4.m4.1" class="ltx_Math" alttext="f(x)" display="inline"><semantics id="S2.p5.4.m4.1a"><mrow id="S2.p5.4.m4.1.2" xref="S2.p5.4.m4.1.2.cmml"><mi id="S2.p5.4.m4.1.2.2" xref="S2.p5.4.m4.1.2.2.cmml">f</mi><mo lspace="0em" rspace="0em" id="S2.p5.4.m4.1.2.1" xref="S2.p5.4.m4.1.2.1.cmml">​</mo><mrow id="S2.p5.4.m4.1.2.3.2" xref="S2.p5.4.m4.1.2.cmml"><mo stretchy="false" id="S2.p5.4.m4.1.2.3.2.1" xref="S2.p5.4.m4.1.2.cmml">(</mo><mi id="S2.p5.4.m4.1.1" xref="S2.p5.4.m4.1.1.cmml">x</mi><mo stretchy="false" id="S2.p5.4.m4.1.2.3.2.2" xref="S2.p5.4.m4.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p5.4.m4.1b"><apply id="S2.p5.4.m4.1.2.cmml" xref="S2.p5.4.m4.1.2"><times id="S2.p5.4.m4.1.2.1.cmml" xref="S2.p5.4.m4.1.2.1"></times><ci id="S2.p5.4.m4.1.2.2.cmml" xref="S2.p5.4.m4.1.2.2">𝑓</ci><ci id="S2.p5.4.m4.1.1.cmml" xref="S2.p5.4.m4.1.1">𝑥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.4.m4.1c">f(x)</annotation></semantics></math> might be steered towards. By contrast, in Targeted Adversarial Training (TAT), we would explicitly pick a target <math id="S2.p5.5.m5.1" class="ltx_Math" alttext="y_{t}\neq y" display="inline"><semantics id="S2.p5.5.m5.1a"><mrow id="S2.p5.5.m5.1.1" xref="S2.p5.5.m5.1.1.cmml"><msub id="S2.p5.5.m5.1.1.2" xref="S2.p5.5.m5.1.1.2.cmml"><mi id="S2.p5.5.m5.1.1.2.2" xref="S2.p5.5.m5.1.1.2.2.cmml">y</mi><mi id="S2.p5.5.m5.1.1.2.3" xref="S2.p5.5.m5.1.1.2.3.cmml">t</mi></msub><mo id="S2.p5.5.m5.1.1.1" xref="S2.p5.5.m5.1.1.1.cmml">≠</mo><mi id="S2.p5.5.m5.1.1.3" xref="S2.p5.5.m5.1.1.3.cmml">y</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.p5.5.m5.1b"><apply id="S2.p5.5.m5.1.1.cmml" xref="S2.p5.5.m5.1.1"><neq id="S2.p5.5.m5.1.1.1.cmml" xref="S2.p5.5.m5.1.1.1"></neq><apply id="S2.p5.5.m5.1.1.2.cmml" xref="S2.p5.5.m5.1.1.2"><csymbol cd="ambiguous" id="S2.p5.5.m5.1.1.2.1.cmml" xref="S2.p5.5.m5.1.1.2">subscript</csymbol><ci id="S2.p5.5.m5.1.1.2.2.cmml" xref="S2.p5.5.m5.1.1.2.2">𝑦</ci><ci id="S2.p5.5.m5.1.1.2.3.cmml" xref="S2.p5.5.m5.1.1.2.3">𝑡</ci></apply><ci id="S2.p5.5.m5.1.1.3.cmml" xref="S2.p5.5.m5.1.1.3">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.5.m5.1c">y_{t}\neq y</annotation></semantics></math> and try to steer the model towards <math id="S2.p5.6.m6.1" class="ltx_Math" alttext="y_{t}" display="inline"><semantics id="S2.p5.6.m6.1a"><msub id="S2.p5.6.m6.1.1" xref="S2.p5.6.m6.1.1.cmml"><mi id="S2.p5.6.m6.1.1.2" xref="S2.p5.6.m6.1.1.2.cmml">y</mi><mi id="S2.p5.6.m6.1.1.3" xref="S2.p5.6.m6.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.p5.6.m6.1b"><apply id="S2.p5.6.m6.1.1.cmml" xref="S2.p5.6.m6.1.1"><csymbol cd="ambiguous" id="S2.p5.6.m6.1.1.1.cmml" xref="S2.p5.6.m6.1.1">subscript</csymbol><ci id="S2.p5.6.m6.1.1.2.cmml" xref="S2.p5.6.m6.1.1.2">𝑦</ci><ci id="S2.p5.6.m6.1.1.3.cmml" xref="S2.p5.6.m6.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.6.m6.1c">y_{t}</annotation></semantics></math>. Intuitively, we would like to focus training on where the model currently errs the most. We accomplish this by keeping a running tally of <math id="S2.p5.7.m7.2" class="ltx_Math" alttext="e(y,y_{t})" display="inline"><semantics id="S2.p5.7.m7.2a"><mrow id="S2.p5.7.m7.2.2" xref="S2.p5.7.m7.2.2.cmml"><mi id="S2.p5.7.m7.2.2.3" xref="S2.p5.7.m7.2.2.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S2.p5.7.m7.2.2.2" xref="S2.p5.7.m7.2.2.2.cmml">​</mo><mrow id="S2.p5.7.m7.2.2.1.1" xref="S2.p5.7.m7.2.2.1.2.cmml"><mo stretchy="false" id="S2.p5.7.m7.2.2.1.1.2" xref="S2.p5.7.m7.2.2.1.2.cmml">(</mo><mi id="S2.p5.7.m7.1.1" xref="S2.p5.7.m7.1.1.cmml">y</mi><mo id="S2.p5.7.m7.2.2.1.1.3" xref="S2.p5.7.m7.2.2.1.2.cmml">,</mo><msub id="S2.p5.7.m7.2.2.1.1.1" xref="S2.p5.7.m7.2.2.1.1.1.cmml"><mi id="S2.p5.7.m7.2.2.1.1.1.2" xref="S2.p5.7.m7.2.2.1.1.1.2.cmml">y</mi><mi id="S2.p5.7.m7.2.2.1.1.1.3" xref="S2.p5.7.m7.2.2.1.1.1.3.cmml">t</mi></msub><mo stretchy="false" id="S2.p5.7.m7.2.2.1.1.4" xref="S2.p5.7.m7.2.2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p5.7.m7.2b"><apply id="S2.p5.7.m7.2.2.cmml" xref="S2.p5.7.m7.2.2"><times id="S2.p5.7.m7.2.2.2.cmml" xref="S2.p5.7.m7.2.2.2"></times><ci id="S2.p5.7.m7.2.2.3.cmml" xref="S2.p5.7.m7.2.2.3">𝑒</ci><interval closure="open" id="S2.p5.7.m7.2.2.1.2.cmml" xref="S2.p5.7.m7.2.2.1.1"><ci id="S2.p5.7.m7.1.1.cmml" xref="S2.p5.7.m7.1.1">𝑦</ci><apply id="S2.p5.7.m7.2.2.1.1.1.cmml" xref="S2.p5.7.m7.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.p5.7.m7.2.2.1.1.1.1.cmml" xref="S2.p5.7.m7.2.2.1.1.1">subscript</csymbol><ci id="S2.p5.7.m7.2.2.1.1.1.2.cmml" xref="S2.p5.7.m7.2.2.1.1.1.2">𝑦</ci><ci id="S2.p5.7.m7.2.2.1.1.1.3.cmml" xref="S2.p5.7.m7.2.2.1.1.1.3">𝑡</ci></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.7.m7.2c">e(y,y_{t})</annotation></semantics></math>, which is the current expected error of predicting <math id="S2.p5.8.m8.1" class="ltx_Math" alttext="y_{t}" display="inline"><semantics id="S2.p5.8.m8.1a"><msub id="S2.p5.8.m8.1.1" xref="S2.p5.8.m8.1.1.cmml"><mi id="S2.p5.8.m8.1.1.2" xref="S2.p5.8.m8.1.1.2.cmml">y</mi><mi id="S2.p5.8.m8.1.1.3" xref="S2.p5.8.m8.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.p5.8.m8.1b"><apply id="S2.p5.8.m8.1.1.cmml" xref="S2.p5.8.m8.1.1"><csymbol cd="ambiguous" id="S2.p5.8.m8.1.1.1.cmml" xref="S2.p5.8.m8.1.1">subscript</csymbol><ci id="S2.p5.8.m8.1.1.2.cmml" xref="S2.p5.8.m8.1.1.2">𝑦</ci><ci id="S2.p5.8.m8.1.1.3.cmml" xref="S2.p5.8.m8.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.8.m8.1c">y_{t}</annotation></semantics></math> when the gold label is <math id="S2.p5.9.m9.1" class="ltx_Math" alttext="y" display="inline"><semantics id="S2.p5.9.m9.1a"><mi id="S2.p5.9.m9.1.1" xref="S2.p5.9.m9.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S2.p5.9.m9.1b"><ci id="S2.p5.9.m9.1.1.cmml" xref="S2.p5.9.m9.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.9.m9.1c">y</annotation></semantics></math>, and sample <math id="S2.p5.10.m10.1" class="ltx_Math" alttext="y_{t}" display="inline"><semantics id="S2.p5.10.m10.1a"><msub id="S2.p5.10.m10.1.1" xref="S2.p5.10.m10.1.1.cmml"><mi id="S2.p5.10.m10.1.1.2" xref="S2.p5.10.m10.1.1.2.cmml">y</mi><mi id="S2.p5.10.m10.1.1.3" xref="S2.p5.10.m10.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.p5.10.m10.1b"><apply id="S2.p5.10.m10.1.1.cmml" xref="S2.p5.10.m10.1.1"><csymbol cd="ambiguous" id="S2.p5.10.m10.1.1.1.cmml" xref="S2.p5.10.m10.1.1">subscript</csymbol><ci id="S2.p5.10.m10.1.1.2.cmml" xref="S2.p5.10.m10.1.1.2">𝑦</ci><ci id="S2.p5.10.m10.1.1.3.cmml" xref="S2.p5.10.m10.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.10.m10.1c">y_{t}</annotation></semantics></math> from <math id="S2.p5.11.m11.1" class="ltx_Math" alttext="C_{\setminus y}=C-\{y\}" display="inline"><semantics id="S2.p5.11.m11.1a"><mrow id="S2.p5.11.m11.1.2" xref="S2.p5.11.m11.1.2.cmml"><msub id="S2.p5.11.m11.1.2.2" xref="S2.p5.11.m11.1.2.2.cmml"><mi id="S2.p5.11.m11.1.2.2.2" xref="S2.p5.11.m11.1.2.2.2.cmml">C</mi><mrow id="S2.p5.11.m11.1.2.2.3" xref="S2.p5.11.m11.1.2.2.3.cmml"><mo rspace="0em" id="S2.p5.11.m11.1.2.2.3a" xref="S2.p5.11.m11.1.2.2.3.cmml">∖</mo><mi id="S2.p5.11.m11.1.2.2.3.2" xref="S2.p5.11.m11.1.2.2.3.2.cmml">y</mi></mrow></msub><mo id="S2.p5.11.m11.1.2.1" xref="S2.p5.11.m11.1.2.1.cmml">=</mo><mrow id="S2.p5.11.m11.1.2.3" xref="S2.p5.11.m11.1.2.3.cmml"><mi id="S2.p5.11.m11.1.2.3.2" xref="S2.p5.11.m11.1.2.3.2.cmml">C</mi><mo id="S2.p5.11.m11.1.2.3.1" xref="S2.p5.11.m11.1.2.3.1.cmml">−</mo><mrow id="S2.p5.11.m11.1.2.3.3.2" xref="S2.p5.11.m11.1.2.3.3.1.cmml"><mo stretchy="false" id="S2.p5.11.m11.1.2.3.3.2.1" xref="S2.p5.11.m11.1.2.3.3.1.cmml">{</mo><mi id="S2.p5.11.m11.1.1" xref="S2.p5.11.m11.1.1.cmml">y</mi><mo stretchy="false" id="S2.p5.11.m11.1.2.3.3.2.2" xref="S2.p5.11.m11.1.2.3.3.1.cmml">}</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p5.11.m11.1b"><apply id="S2.p5.11.m11.1.2.cmml" xref="S2.p5.11.m11.1.2"><eq id="S2.p5.11.m11.1.2.1.cmml" xref="S2.p5.11.m11.1.2.1"></eq><apply id="S2.p5.11.m11.1.2.2.cmml" xref="S2.p5.11.m11.1.2.2"><csymbol cd="ambiguous" id="S2.p5.11.m11.1.2.2.1.cmml" xref="S2.p5.11.m11.1.2.2">subscript</csymbol><ci id="S2.p5.11.m11.1.2.2.2.cmml" xref="S2.p5.11.m11.1.2.2.2">𝐶</ci><apply id="S2.p5.11.m11.1.2.2.3.cmml" xref="S2.p5.11.m11.1.2.2.3"><setdiff id="S2.p5.11.m11.1.2.2.3.1.cmml" xref="S2.p5.11.m11.1.2.2.3"></setdiff><ci id="S2.p5.11.m11.1.2.2.3.2.cmml" xref="S2.p5.11.m11.1.2.2.3.2">𝑦</ci></apply></apply><apply id="S2.p5.11.m11.1.2.3.cmml" xref="S2.p5.11.m11.1.2.3"><minus id="S2.p5.11.m11.1.2.3.1.cmml" xref="S2.p5.11.m11.1.2.3.1"></minus><ci id="S2.p5.11.m11.1.2.3.2.cmml" xref="S2.p5.11.m11.1.2.3.2">𝐶</ci><set id="S2.p5.11.m11.1.2.3.3.1.cmml" xref="S2.p5.11.m11.1.2.3.3.2"><ci id="S2.p5.11.m11.1.1.cmml" xref="S2.p5.11.m11.1.1">𝑦</ci></set></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.11.m11.1c">C_{\setminus y}=C-\{y\}</annotation></semantics></math> in proportion to <math id="S2.p5.12.m12.2" class="ltx_Math" alttext="e(y,y_{t})" display="inline"><semantics id="S2.p5.12.m12.2a"><mrow id="S2.p5.12.m12.2.2" xref="S2.p5.12.m12.2.2.cmml"><mi id="S2.p5.12.m12.2.2.3" xref="S2.p5.12.m12.2.2.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S2.p5.12.m12.2.2.2" xref="S2.p5.12.m12.2.2.2.cmml">​</mo><mrow id="S2.p5.12.m12.2.2.1.1" xref="S2.p5.12.m12.2.2.1.2.cmml"><mo stretchy="false" id="S2.p5.12.m12.2.2.1.1.2" xref="S2.p5.12.m12.2.2.1.2.cmml">(</mo><mi id="S2.p5.12.m12.1.1" xref="S2.p5.12.m12.1.1.cmml">y</mi><mo id="S2.p5.12.m12.2.2.1.1.3" xref="S2.p5.12.m12.2.2.1.2.cmml">,</mo><msub id="S2.p5.12.m12.2.2.1.1.1" xref="S2.p5.12.m12.2.2.1.1.1.cmml"><mi id="S2.p5.12.m12.2.2.1.1.1.2" xref="S2.p5.12.m12.2.2.1.1.1.2.cmml">y</mi><mi id="S2.p5.12.m12.2.2.1.1.1.3" xref="S2.p5.12.m12.2.2.1.1.1.3.cmml">t</mi></msub><mo stretchy="false" id="S2.p5.12.m12.2.2.1.1.4" xref="S2.p5.12.m12.2.2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p5.12.m12.2b"><apply id="S2.p5.12.m12.2.2.cmml" xref="S2.p5.12.m12.2.2"><times id="S2.p5.12.m12.2.2.2.cmml" xref="S2.p5.12.m12.2.2.2"></times><ci id="S2.p5.12.m12.2.2.3.cmml" xref="S2.p5.12.m12.2.2.3">𝑒</ci><interval closure="open" id="S2.p5.12.m12.2.2.1.2.cmml" xref="S2.p5.12.m12.2.2.1.1"><ci id="S2.p5.12.m12.1.1.cmml" xref="S2.p5.12.m12.1.1">𝑦</ci><apply id="S2.p5.12.m12.2.2.1.1.1.cmml" xref="S2.p5.12.m12.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.p5.12.m12.2.2.1.1.1.1.cmml" xref="S2.p5.12.m12.2.2.1.1.1">subscript</csymbol><ci id="S2.p5.12.m12.2.2.1.1.1.2.cmml" xref="S2.p5.12.m12.2.2.1.1.1.2">𝑦</ci><ci id="S2.p5.12.m12.2.2.1.1.1.3.cmml" xref="S2.p5.12.m12.2.2.1.1.1.3">𝑡</ci></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.12.m12.2c">e(y,y_{t})</annotation></semantics></math>. See Algorithm <a href="#alg1" title="Algorithm 1 ‣ 2 Targeted Adversarial Training (TAT) ‣ Targeted Adversarial Training for Natural Language Understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> for details.
TAT can be applied to the original adversarial training or virtual adversarial training alike. In this paper, we focus on adapting virtual adversarial training (VAT) <cite class="ltx_cite ltx_citemacro_cite">Jiang et al. (<a href="#bib.bib21" title="" class="ltx_ref">2019</a>)</cite>.
The two lines in blue color are the only change from VAT.
We initialize <math id="S2.p5.13.m13.2" class="ltx_Math" alttext="e(y,y_{t})" display="inline"><semantics id="S2.p5.13.m13.2a"><mrow id="S2.p5.13.m13.2.2" xref="S2.p5.13.m13.2.2.cmml"><mi id="S2.p5.13.m13.2.2.3" xref="S2.p5.13.m13.2.2.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S2.p5.13.m13.2.2.2" xref="S2.p5.13.m13.2.2.2.cmml">​</mo><mrow id="S2.p5.13.m13.2.2.1.1" xref="S2.p5.13.m13.2.2.1.2.cmml"><mo stretchy="false" id="S2.p5.13.m13.2.2.1.1.2" xref="S2.p5.13.m13.2.2.1.2.cmml">(</mo><mi id="S2.p5.13.m13.1.1" xref="S2.p5.13.m13.1.1.cmml">y</mi><mo id="S2.p5.13.m13.2.2.1.1.3" xref="S2.p5.13.m13.2.2.1.2.cmml">,</mo><msub id="S2.p5.13.m13.2.2.1.1.1" xref="S2.p5.13.m13.2.2.1.1.1.cmml"><mi id="S2.p5.13.m13.2.2.1.1.1.2" xref="S2.p5.13.m13.2.2.1.1.1.2.cmml">y</mi><mi id="S2.p5.13.m13.2.2.1.1.1.3" xref="S2.p5.13.m13.2.2.1.1.1.3.cmml">t</mi></msub><mo stretchy="false" id="S2.p5.13.m13.2.2.1.1.4" xref="S2.p5.13.m13.2.2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p5.13.m13.2b"><apply id="S2.p5.13.m13.2.2.cmml" xref="S2.p5.13.m13.2.2"><times id="S2.p5.13.m13.2.2.2.cmml" xref="S2.p5.13.m13.2.2.2"></times><ci id="S2.p5.13.m13.2.2.3.cmml" xref="S2.p5.13.m13.2.2.3">𝑒</ci><interval closure="open" id="S2.p5.13.m13.2.2.1.2.cmml" xref="S2.p5.13.m13.2.2.1.1"><ci id="S2.p5.13.m13.1.1.cmml" xref="S2.p5.13.m13.1.1">𝑦</ci><apply id="S2.p5.13.m13.2.2.1.1.1.cmml" xref="S2.p5.13.m13.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.p5.13.m13.2.2.1.1.1.1.cmml" xref="S2.p5.13.m13.2.2.1.1.1">subscript</csymbol><ci id="S2.p5.13.m13.2.2.1.1.1.2.cmml" xref="S2.p5.13.m13.2.2.1.1.1.2">𝑦</ci><ci id="S2.p5.13.m13.2.2.1.1.1.3.cmml" xref="S2.p5.13.m13.2.2.1.1.1.3">𝑡</ci></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.13.m13.2c">e(y,y_{t})</annotation></semantics></math> with uniform distribution and update them in each epoch. We conducted an oracle experiment where <math id="S2.p5.14.m14.2" class="ltx_Math" alttext="e(y,y_{t})" display="inline"><semantics id="S2.p5.14.m14.2a"><mrow id="S2.p5.14.m14.2.2" xref="S2.p5.14.m14.2.2.cmml"><mi id="S2.p5.14.m14.2.2.3" xref="S2.p5.14.m14.2.2.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S2.p5.14.m14.2.2.2" xref="S2.p5.14.m14.2.2.2.cmml">​</mo><mrow id="S2.p5.14.m14.2.2.1.1" xref="S2.p5.14.m14.2.2.1.2.cmml"><mo stretchy="false" id="S2.p5.14.m14.2.2.1.1.2" xref="S2.p5.14.m14.2.2.1.2.cmml">(</mo><mi id="S2.p5.14.m14.1.1" xref="S2.p5.14.m14.1.1.cmml">y</mi><mo id="S2.p5.14.m14.2.2.1.1.3" xref="S2.p5.14.m14.2.2.1.2.cmml">,</mo><msub id="S2.p5.14.m14.2.2.1.1.1" xref="S2.p5.14.m14.2.2.1.1.1.cmml"><mi id="S2.p5.14.m14.2.2.1.1.1.2" xref="S2.p5.14.m14.2.2.1.1.1.2.cmml">y</mi><mi id="S2.p5.14.m14.2.2.1.1.1.3" xref="S2.p5.14.m14.2.2.1.1.1.3.cmml">t</mi></msub><mo stretchy="false" id="S2.p5.14.m14.2.2.1.1.4" xref="S2.p5.14.m14.2.2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p5.14.m14.2b"><apply id="S2.p5.14.m14.2.2.cmml" xref="S2.p5.14.m14.2.2"><times id="S2.p5.14.m14.2.2.2.cmml" xref="S2.p5.14.m14.2.2.2"></times><ci id="S2.p5.14.m14.2.2.3.cmml" xref="S2.p5.14.m14.2.2.3">𝑒</ci><interval closure="open" id="S2.p5.14.m14.2.2.1.2.cmml" xref="S2.p5.14.m14.2.2.1.1"><ci id="S2.p5.14.m14.1.1.cmml" xref="S2.p5.14.m14.1.1">𝑦</ci><apply id="S2.p5.14.m14.2.2.1.1.1.cmml" xref="S2.p5.14.m14.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.p5.14.m14.2.2.1.1.1.1.cmml" xref="S2.p5.14.m14.2.2.1.1.1">subscript</csymbol><ci id="S2.p5.14.m14.2.2.1.1.1.2.cmml" xref="S2.p5.14.m14.2.2.1.1.1.2">𝑦</ci><ci id="S2.p5.14.m14.2.2.1.1.1.3.cmml" xref="S2.p5.14.m14.2.2.1.1.1.3">𝑡</ci></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.14.m14.2c">e(y,y_{t})</annotation></semantics></math> was taken from the confusion matrix from standard training and found that it performed similarly as our online version.</p>
</div>
<div id="S2.p6" class="ltx_para">
<p id="S2.p6.1" class="ltx_p">It is more challenging to apply TAT to regression tasks, as we would need to keep track of a continuous error distribution. To address this problem, we quantize the value range into ten bins and apply TAT similarly as in the classification setting (once a bin is chosen, a value is sampled uniformly within).</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Experiments</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.2" class="ltx_p">We compare targeted adversarial training (TAT) with standard training and state-of-the-art adversarial training methods such as FreeLB <cite class="ltx_cite ltx_citemacro_cite">Zhu et al. (<a href="#bib.bib43" title="" class="ltx_ref">2019</a>)</cite> and VAT <cite class="ltx_cite ltx_citemacro_cite">Miyato et al. (<a href="#bib.bib32" title="" class="ltx_ref">2018</a>); Jiang et al. (<a href="#bib.bib21" title="" class="ltx_ref">2019</a>)</cite>.
We use the standard uncased BERT<sub id="S3.p1.2.1" class="ltx_sub">BASE</sub> model <cite class="ltx_cite ltx_citemacro_cite">Devlin et al. (<a href="#bib.bib13" title="" class="ltx_ref">2018</a>)</cite>, unless noted otherwise.
Due to the additional overhead incurred during training, adversarial methods are somewhat slower than standard training. Like VAT, TAT requires an additional <math id="S3.p1.1.m1.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.p1.1.m1.1a"><mi id="S3.p1.1.m1.1.1" xref="S3.p1.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.p1.1.m1.1b"><ci id="S3.p1.1.m1.1.1.cmml" xref="S3.p1.1.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.1.m1.1c">K</annotation></semantics></math> adversarial steps compared to standard training. In practice, <math id="S3.p1.2.m2.1" class="ltx_Math" alttext="K=1" display="inline"><semantics id="S3.p1.2.m2.1a"><mrow id="S3.p1.2.m2.1.1" xref="S3.p1.2.m2.1.1.cmml"><mi id="S3.p1.2.m2.1.1.2" xref="S3.p1.2.m2.1.1.2.cmml">K</mi><mo id="S3.p1.2.m2.1.1.1" xref="S3.p1.2.m2.1.1.1.cmml">=</mo><mn id="S3.p1.2.m2.1.1.3" xref="S3.p1.2.m2.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.p1.2.m2.1b"><apply id="S3.p1.2.m2.1.1.cmml" xref="S3.p1.2.m2.1.1"><eq id="S3.p1.2.m2.1.1.1.cmml" xref="S3.p1.2.m2.1.1.1"></eq><ci id="S3.p1.2.m2.1.1.2.cmml" xref="S3.p1.2.m2.1.1.2">𝐾</ci><cn type="integer" id="S3.p1.2.m2.1.1.3.cmml" xref="S3.p1.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.2.m2.1c">K=1</annotation></semantics></math> suffices for TAT and VAT, so they are just slightly slower (roughly 2 times compared to standard training). FreeLB, by contrast, typically requires 2-5 steps to attain good performance, so is significantly slower.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Implementation Details</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.6" class="ltx_p">Our implementation is based on the MT-DNN toolkit <cite class="ltx_cite ltx_citemacro_cite">Liu et al. (<a href="#bib.bib29" title="" class="ltx_ref">2020b</a>)</cite>. We follow the default hyperparameters used for fine-tuning the uncased BERT base model <cite class="ltx_cite ltx_citemacro_cite">Devlin et al. (<a href="#bib.bib13" title="" class="ltx_ref">2018</a>); Liu et al. (<a href="#bib.bib29" title="" class="ltx_ref">2020b</a>)</cite>.
Specifically, we use <math id="S3.SS1.p1.1.m1.1" class="ltx_Math" alttext="0.1" display="inline"><semantics id="S3.SS1.p1.1.m1.1a"><mn id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">0.1</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><cn type="float" id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">0.1</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">0.1</annotation></semantics></math> for the dropout rate except 0.2 for MNLI, <math id="S3.SS1.p1.2.m2.1" class="ltx_Math" alttext="0.01" display="inline"><semantics id="S3.SS1.p1.2.m2.1a"><mn id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml">0.01</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><cn type="float" id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">0.01</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">0.01</annotation></semantics></math> for the weight decay rate and the Adamax <cite class="ltx_cite ltx_citemacro_cite">Kingma and Ba (<a href="#bib.bib25" title="" class="ltx_ref">2014</a>)</cite> optimizer with the default Lookahead <cite class="ltx_cite ltx_citemacro_cite">Zhang et al. (<a href="#bib.bib42" title="" class="ltx_ref">2019</a>)</cite> to stabilize training.
We select the learning rate from <math id="S3.SS1.p1.3.m3.2" class="ltx_Math" alttext="\{5\mathrm{e}{-5},1\mathrm{e}{-4}\}" display="inline"><semantics id="S3.SS1.p1.3.m3.2a"><mrow id="S3.SS1.p1.3.m3.2.2.2" xref="S3.SS1.p1.3.m3.2.2.3.cmml"><mo stretchy="false" id="S3.SS1.p1.3.m3.2.2.2.3" xref="S3.SS1.p1.3.m3.2.2.3.cmml">{</mo><mrow id="S3.SS1.p1.3.m3.1.1.1.1" xref="S3.SS1.p1.3.m3.1.1.1.1.cmml"><mrow id="S3.SS1.p1.3.m3.1.1.1.1.2" xref="S3.SS1.p1.3.m3.1.1.1.1.2.cmml"><mn id="S3.SS1.p1.3.m3.1.1.1.1.2.2" xref="S3.SS1.p1.3.m3.1.1.1.1.2.2.cmml">5</mn><mo lspace="0em" rspace="0em" id="S3.SS1.p1.3.m3.1.1.1.1.2.1" xref="S3.SS1.p1.3.m3.1.1.1.1.2.1.cmml">​</mo><mi mathvariant="normal" id="S3.SS1.p1.3.m3.1.1.1.1.2.3" xref="S3.SS1.p1.3.m3.1.1.1.1.2.3.cmml">e</mi></mrow><mo id="S3.SS1.p1.3.m3.1.1.1.1.1" xref="S3.SS1.p1.3.m3.1.1.1.1.1.cmml">−</mo><mn id="S3.SS1.p1.3.m3.1.1.1.1.3" xref="S3.SS1.p1.3.m3.1.1.1.1.3.cmml">5</mn></mrow><mo id="S3.SS1.p1.3.m3.2.2.2.4" xref="S3.SS1.p1.3.m3.2.2.3.cmml">,</mo><mrow id="S3.SS1.p1.3.m3.2.2.2.2" xref="S3.SS1.p1.3.m3.2.2.2.2.cmml"><mrow id="S3.SS1.p1.3.m3.2.2.2.2.2" xref="S3.SS1.p1.3.m3.2.2.2.2.2.cmml"><mn id="S3.SS1.p1.3.m3.2.2.2.2.2.2" xref="S3.SS1.p1.3.m3.2.2.2.2.2.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="S3.SS1.p1.3.m3.2.2.2.2.2.1" xref="S3.SS1.p1.3.m3.2.2.2.2.2.1.cmml">​</mo><mi mathvariant="normal" id="S3.SS1.p1.3.m3.2.2.2.2.2.3" xref="S3.SS1.p1.3.m3.2.2.2.2.2.3.cmml">e</mi></mrow><mo id="S3.SS1.p1.3.m3.2.2.2.2.1" xref="S3.SS1.p1.3.m3.2.2.2.2.1.cmml">−</mo><mn id="S3.SS1.p1.3.m3.2.2.2.2.3" xref="S3.SS1.p1.3.m3.2.2.2.2.3.cmml">4</mn></mrow><mo stretchy="false" id="S3.SS1.p1.3.m3.2.2.2.5" xref="S3.SS1.p1.3.m3.2.2.3.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.2b"><set id="S3.SS1.p1.3.m3.2.2.3.cmml" xref="S3.SS1.p1.3.m3.2.2.2"><apply id="S3.SS1.p1.3.m3.1.1.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1.1.1"><minus id="S3.SS1.p1.3.m3.1.1.1.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1.1.1.1"></minus><apply id="S3.SS1.p1.3.m3.1.1.1.1.2.cmml" xref="S3.SS1.p1.3.m3.1.1.1.1.2"><times id="S3.SS1.p1.3.m3.1.1.1.1.2.1.cmml" xref="S3.SS1.p1.3.m3.1.1.1.1.2.1"></times><cn type="integer" id="S3.SS1.p1.3.m3.1.1.1.1.2.2.cmml" xref="S3.SS1.p1.3.m3.1.1.1.1.2.2">5</cn><ci id="S3.SS1.p1.3.m3.1.1.1.1.2.3.cmml" xref="S3.SS1.p1.3.m3.1.1.1.1.2.3">e</ci></apply><cn type="integer" id="S3.SS1.p1.3.m3.1.1.1.1.3.cmml" xref="S3.SS1.p1.3.m3.1.1.1.1.3">5</cn></apply><apply id="S3.SS1.p1.3.m3.2.2.2.2.cmml" xref="S3.SS1.p1.3.m3.2.2.2.2"><minus id="S3.SS1.p1.3.m3.2.2.2.2.1.cmml" xref="S3.SS1.p1.3.m3.2.2.2.2.1"></minus><apply id="S3.SS1.p1.3.m3.2.2.2.2.2.cmml" xref="S3.SS1.p1.3.m3.2.2.2.2.2"><times id="S3.SS1.p1.3.m3.2.2.2.2.2.1.cmml" xref="S3.SS1.p1.3.m3.2.2.2.2.2.1"></times><cn type="integer" id="S3.SS1.p1.3.m3.2.2.2.2.2.2.cmml" xref="S3.SS1.p1.3.m3.2.2.2.2.2.2">1</cn><ci id="S3.SS1.p1.3.m3.2.2.2.2.2.3.cmml" xref="S3.SS1.p1.3.m3.2.2.2.2.2.3">e</ci></apply><cn type="integer" id="S3.SS1.p1.3.m3.2.2.2.2.3.cmml" xref="S3.SS1.p1.3.m3.2.2.2.2.3">4</cn></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.2c">\{5\mathrm{e}{-5},1\mathrm{e}{-4}\}</annotation></semantics></math> for all the models. The maximum training epoch is set to 6, and the we follow <cite class="ltx_cite ltx_citemacro_cite">Jiang et al. (<a href="#bib.bib21" title="" class="ltx_ref">2019</a>)</cite> to set adversarial training hyperparameters: <math id="S3.SS1.p1.4.m4.1" class="ltx_Math" alttext="\epsilon=1\mathrm{e}{-5}" display="inline"><semantics id="S3.SS1.p1.4.m4.1a"><mrow id="S3.SS1.p1.4.m4.1.1" xref="S3.SS1.p1.4.m4.1.1.cmml"><mi id="S3.SS1.p1.4.m4.1.1.2" xref="S3.SS1.p1.4.m4.1.1.2.cmml">ϵ</mi><mo id="S3.SS1.p1.4.m4.1.1.1" xref="S3.SS1.p1.4.m4.1.1.1.cmml">=</mo><mrow id="S3.SS1.p1.4.m4.1.1.3" xref="S3.SS1.p1.4.m4.1.1.3.cmml"><mrow id="S3.SS1.p1.4.m4.1.1.3.2" xref="S3.SS1.p1.4.m4.1.1.3.2.cmml"><mn id="S3.SS1.p1.4.m4.1.1.3.2.2" xref="S3.SS1.p1.4.m4.1.1.3.2.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="S3.SS1.p1.4.m4.1.1.3.2.1" xref="S3.SS1.p1.4.m4.1.1.3.2.1.cmml">​</mo><mi mathvariant="normal" id="S3.SS1.p1.4.m4.1.1.3.2.3" xref="S3.SS1.p1.4.m4.1.1.3.2.3.cmml">e</mi></mrow><mo id="S3.SS1.p1.4.m4.1.1.3.1" xref="S3.SS1.p1.4.m4.1.1.3.1.cmml">−</mo><mn id="S3.SS1.p1.4.m4.1.1.3.3" xref="S3.SS1.p1.4.m4.1.1.3.3.cmml">5</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.1b"><apply id="S3.SS1.p1.4.m4.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1"><eq id="S3.SS1.p1.4.m4.1.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1.1"></eq><ci id="S3.SS1.p1.4.m4.1.1.2.cmml" xref="S3.SS1.p1.4.m4.1.1.2">italic-ϵ</ci><apply id="S3.SS1.p1.4.m4.1.1.3.cmml" xref="S3.SS1.p1.4.m4.1.1.3"><minus id="S3.SS1.p1.4.m4.1.1.3.1.cmml" xref="S3.SS1.p1.4.m4.1.1.3.1"></minus><apply id="S3.SS1.p1.4.m4.1.1.3.2.cmml" xref="S3.SS1.p1.4.m4.1.1.3.2"><times id="S3.SS1.p1.4.m4.1.1.3.2.1.cmml" xref="S3.SS1.p1.4.m4.1.1.3.2.1"></times><cn type="integer" id="S3.SS1.p1.4.m4.1.1.3.2.2.cmml" xref="S3.SS1.p1.4.m4.1.1.3.2.2">1</cn><ci id="S3.SS1.p1.4.m4.1.1.3.2.3.cmml" xref="S3.SS1.p1.4.m4.1.1.3.2.3">e</ci></apply><cn type="integer" id="S3.SS1.p1.4.m4.1.1.3.3.cmml" xref="S3.SS1.p1.4.m4.1.1.3.3">5</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.1c">\epsilon=1\mathrm{e}{-5}</annotation></semantics></math> and <math id="S3.SS1.p1.5.m5.1" class="ltx_Math" alttext="\eta=1\mathrm{e}{-4}" display="inline"><semantics id="S3.SS1.p1.5.m5.1a"><mrow id="S3.SS1.p1.5.m5.1.1" xref="S3.SS1.p1.5.m5.1.1.cmml"><mi id="S3.SS1.p1.5.m5.1.1.2" xref="S3.SS1.p1.5.m5.1.1.2.cmml">η</mi><mo id="S3.SS1.p1.5.m5.1.1.1" xref="S3.SS1.p1.5.m5.1.1.1.cmml">=</mo><mrow id="S3.SS1.p1.5.m5.1.1.3" xref="S3.SS1.p1.5.m5.1.1.3.cmml"><mrow id="S3.SS1.p1.5.m5.1.1.3.2" xref="S3.SS1.p1.5.m5.1.1.3.2.cmml"><mn id="S3.SS1.p1.5.m5.1.1.3.2.2" xref="S3.SS1.p1.5.m5.1.1.3.2.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="S3.SS1.p1.5.m5.1.1.3.2.1" xref="S3.SS1.p1.5.m5.1.1.3.2.1.cmml">​</mo><mi mathvariant="normal" id="S3.SS1.p1.5.m5.1.1.3.2.3" xref="S3.SS1.p1.5.m5.1.1.3.2.3.cmml">e</mi></mrow><mo id="S3.SS1.p1.5.m5.1.1.3.1" xref="S3.SS1.p1.5.m5.1.1.3.1.cmml">−</mo><mn id="S3.SS1.p1.5.m5.1.1.3.3" xref="S3.SS1.p1.5.m5.1.1.3.3.cmml">4</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.5.m5.1b"><apply id="S3.SS1.p1.5.m5.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1"><eq id="S3.SS1.p1.5.m5.1.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1.1"></eq><ci id="S3.SS1.p1.5.m5.1.1.2.cmml" xref="S3.SS1.p1.5.m5.1.1.2">𝜂</ci><apply id="S3.SS1.p1.5.m5.1.1.3.cmml" xref="S3.SS1.p1.5.m5.1.1.3"><minus id="S3.SS1.p1.5.m5.1.1.3.1.cmml" xref="S3.SS1.p1.5.m5.1.1.3.1"></minus><apply id="S3.SS1.p1.5.m5.1.1.3.2.cmml" xref="S3.SS1.p1.5.m5.1.1.3.2"><times id="S3.SS1.p1.5.m5.1.1.3.2.1.cmml" xref="S3.SS1.p1.5.m5.1.1.3.2.1"></times><cn type="integer" id="S3.SS1.p1.5.m5.1.1.3.2.2.cmml" xref="S3.SS1.p1.5.m5.1.1.3.2.2">1</cn><ci id="S3.SS1.p1.5.m5.1.1.3.2.3.cmml" xref="S3.SS1.p1.5.m5.1.1.3.2.3">e</ci></apply><cn type="integer" id="S3.SS1.p1.5.m5.1.1.3.3.cmml" xref="S3.SS1.p1.5.m5.1.1.3.3">4</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.5.m5.1c">\eta=1\mathrm{e}{-4}</annotation></semantics></math>. In our experiments, we simply set <math id="S3.SS1.p1.6.m6.1" class="ltx_Math" alttext="\alpha=1" display="inline"><semantics id="S3.SS1.p1.6.m6.1a"><mrow id="S3.SS1.p1.6.m6.1.1" xref="S3.SS1.p1.6.m6.1.1.cmml"><mi id="S3.SS1.p1.6.m6.1.1.2" xref="S3.SS1.p1.6.m6.1.1.2.cmml">α</mi><mo id="S3.SS1.p1.6.m6.1.1.1" xref="S3.SS1.p1.6.m6.1.1.1.cmml">=</mo><mn id="S3.SS1.p1.6.m6.1.1.3" xref="S3.SS1.p1.6.m6.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.6.m6.1b"><apply id="S3.SS1.p1.6.m6.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1"><eq id="S3.SS1.p1.6.m6.1.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1.1"></eq><ci id="S3.SS1.p1.6.m6.1.1.2.cmml" xref="S3.SS1.p1.6.m6.1.1.2">𝛼</ci><cn type="integer" id="S3.SS1.p1.6.m6.1.1.3.cmml" xref="S3.SS1.p1.6.m6.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.6.m6.1c">\alpha=1</annotation></semantics></math> in Eq 1.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Standard GLUE Evaluation</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">We first compare adversarial training methods on the standard GLUE benchmark <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a href="#bib.bib39" title="" class="ltx_ref">2018</a>)</cite>. See <a href="#S2.T1" title="Table 1 ‣ 2 Targeted Adversarial Training (TAT) ‣ Targeted Adversarial Training for Natural Language Understanding" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table 1</span></a> for the results <span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Due to restriction on the number of submissions by the GLUE organizers, we only compared TAT with the published results from <cite class="ltx_cite ltx_citemacro_cite">Devlin et al. (<a href="#bib.bib13" title="" class="ltx_ref">2018</a>)</cite> on the test set.</span></span></span>.
TAT consistently outperforms both standard training and the state-of-the-art adversarial training methods of FreeLB and VAT.
Remarkably, BERT<sub id="S3.SS2.p1.1.1" class="ltx_sub">BASE</sub> with targeted adversarial training performs on par with BERT<sub id="S3.SS2.p1.1.2" class="ltx_sub">LARGE</sub> with standard training overall, and outperforms the latter by a large margin on tasks with smaller datasets such as RTE, MRPC and STS-B, which illustrates the benefit of TAT in improving model generalizability.</p>
</div>
<figure id="S3.T2" class="ltx_table">
<table id="S3.T2.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S3.T2.1.1" class="ltx_tr">
<td id="S3.T2.1.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt ltx_border_t" rowspan="2"><span id="S3.T2.1.1.1.1" class="ltx_text ltx_font_bold">Method</span></td>
<td id="S3.T2.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_t">HANS</td>
<td id="S3.T2.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_t">SNLI</td>
<td id="S3.T2.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt ltx_border_t">SciTail</td>
<td id="S3.T2.1.1.5" class="ltx_td ltx_align_center ltx_border_tt ltx_border_t">MedNLI</td>
</tr>
<tr id="S3.T2.1.2" class="ltx_tr">
<td id="S3.T2.1.2.1" class="ltx_td ltx_align_center ltx_border_r">Acc</td>
<td id="S3.T2.1.2.2" class="ltx_td ltx_align_center ltx_border_r">Acc</td>
<td id="S3.T2.1.2.3" class="ltx_td ltx_align_center ltx_border_r">Acc</td>
<td id="S3.T2.1.2.4" class="ltx_td ltx_align_center">Acc</td>
</tr>
<tr id="S3.T2.1.3" class="ltx_tr">
<td id="S3.T2.1.3.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Standard</td>
<td id="S3.T2.1.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">55.4</td>
<td id="S3.T2.1.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">80.1</td>
<td id="S3.T2.1.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">77.3</td>
<td id="S3.T2.1.3.5" class="ltx_td ltx_align_center ltx_border_t">43.2</td>
</tr>
<tr id="S3.T2.1.4" class="ltx_tr">
<td id="S3.T2.1.4.1" class="ltx_td ltx_align_left ltx_border_r">FreeLB</td>
<td id="S3.T2.1.4.2" class="ltx_td ltx_align_center ltx_border_r">62.0</td>
<td id="S3.T2.1.4.3" class="ltx_td ltx_align_center ltx_border_r">80.5</td>
<td id="S3.T2.1.4.4" class="ltx_td ltx_align_center ltx_border_r">78.6</td>
<td id="S3.T2.1.4.5" class="ltx_td ltx_align_center">56.8</td>
</tr>
<tr id="S3.T2.1.5" class="ltx_tr">
<td id="S3.T2.1.5.1" class="ltx_td ltx_align_left ltx_border_r">VAT</td>
<td id="S3.T2.1.5.2" class="ltx_td ltx_align_center ltx_border_r">62.5</td>
<td id="S3.T2.1.5.3" class="ltx_td ltx_align_center ltx_border_r">80.8</td>
<td id="S3.T2.1.5.4" class="ltx_td ltx_align_center ltx_border_r">78.5</td>
<td id="S3.T2.1.5.5" class="ltx_td ltx_align_center">58.1</td>
</tr>
<tr id="S3.T2.1.6" class="ltx_tr">
<td id="S3.T2.1.6.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">TAT</td>
<td id="S3.T2.1.6.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S3.T2.1.6.2.1" class="ltx_text ltx_font_bold">65.8</span></td>
<td id="S3.T2.1.6.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S3.T2.1.6.3.1" class="ltx_text ltx_font_bold">81.0</span></td>
<td id="S3.T2.1.6.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S3.T2.1.6.4.1" class="ltx_text ltx_font_bold">78.8</span></td>
<td id="S3.T2.1.6.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T2.1.6.5.1" class="ltx_text ltx_font_bold">60.6</span></td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Comparison of standard and adversarial training in zero-shot evaluation on various natural language inference datasets, where the standard BERT<sub id="S3.T2.3.1" class="ltx_sub">BASE</sub> model is fine-tuned on the MNLI training data.</figcaption>
</figure>
<figure id="S3.T3" class="ltx_table">
<table id="S3.T3.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S3.T3.1.1" class="ltx_tr">
<td id="S3.T3.1.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt"><span id="S3.T3.1.1.1.1" class="ltx_text ltx_font_bold">Model</span></td>
<td id="S3.T3.1.1.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_tt">en</td>
<td id="S3.T3.1.1.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_tt">fr</td>
<td id="S3.T3.1.1.4" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_tt">es</td>
<td id="S3.T3.1.1.5" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_tt">de</td>
<td id="S3.T3.1.1.6" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_tt">el</td>
<td id="S3.T3.1.1.7" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_tt">bg</td>
<td id="S3.T3.1.1.8" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_tt">ru</td>
<td id="S3.T3.1.1.9" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_tt">tr</td>
<td id="S3.T3.1.1.10" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_tt">ar</td>
<td id="S3.T3.1.1.11" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_tt">vi</td>
<td id="S3.T3.1.1.12" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_tt">th</td>
<td id="S3.T3.1.1.13" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_tt">zh</td>
<td id="S3.T3.1.1.14" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_tt">hi</td>
<td id="S3.T3.1.1.15" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_tt">sw</td>
<td id="S3.T3.1.1.16" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_tt">ur</td>
<td id="S3.T3.1.1.17" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_tt">Avg.</td>
</tr>
<tr id="S3.T3.1.2" class="ltx_tr">
<td id="S3.T3.1.2.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt">XLM-R</td>
<td id="S3.T3.1.2.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_tt">89.1</td>
<td id="S3.T3.1.2.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_tt">84.1</td>
<td id="S3.T3.1.2.4" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_tt">85.1</td>
<td id="S3.T3.1.2.5" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_tt">83.9</td>
<td id="S3.T3.1.2.6" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_tt">82.9</td>
<td id="S3.T3.1.2.7" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_tt">84.0</td>
<td id="S3.T3.1.2.8" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_tt">81.2</td>
<td id="S3.T3.1.2.9" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_tt">79.6</td>
<td id="S3.T3.1.2.10" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_tt">79.8</td>
<td id="S3.T3.1.2.11" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_tt">80.8</td>
<td id="S3.T3.1.2.12" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_tt">78.1</td>
<td id="S3.T3.1.2.13" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_tt">80.2</td>
<td id="S3.T3.1.2.14" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_tt">76.9</td>
<td id="S3.T3.1.2.15" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_tt">73.9</td>
<td id="S3.T3.1.2.16" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_tt">73.8</td>
<td id="S3.T3.1.2.17" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_tt">80.9</td>
</tr>
<tr id="S3.T3.1.3" class="ltx_tr">
<td id="S3.T3.1.3.1" class="ltx_td ltx_align_left ltx_border_r">XLM-R<sub id="S3.T3.1.3.1.1" class="ltx_sub">Reprod</sub>
</td>
<td id="S3.T3.1.3.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">88.1</td>
<td id="S3.T3.1.3.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">83.6</td>
<td id="S3.T3.1.3.4" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">84.1</td>
<td id="S3.T3.1.3.5" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">83.0</td>
<td id="S3.T3.1.3.6" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">82.6</td>
<td id="S3.T3.1.3.7" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">83.8</td>
<td id="S3.T3.1.3.8" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">81.7</td>
<td id="S3.T3.1.3.9" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">80.7</td>
<td id="S3.T3.1.3.10" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">80.4</td>
<td id="S3.T3.1.3.11" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">80.7</td>
<td id="S3.T3.1.3.12" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">78.9</td>
<td id="S3.T3.1.3.13" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">80.1</td>
<td id="S3.T3.1.3.14" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">77.8</td>
<td id="S3.T3.1.3.15" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">74.2</td>
<td id="S3.T3.1.3.16" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">74.0</td>
<td id="S3.T3.1.3.17" class="ltx_td ltx_nopad_l ltx_align_center">80.9</td>
</tr>
<tr id="S3.T3.1.4" class="ltx_tr">
<td id="S3.T3.1.4.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">XLM-R+R3F</td>
<td id="S3.T3.1.4.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_t">89.4</td>
<td id="S3.T3.1.4.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_t">84.2</td>
<td id="S3.T3.1.4.4" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_t">85.1</td>
<td id="S3.T3.1.4.5" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_t">83.7</td>
<td id="S3.T3.1.4.6" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_t">83.6</td>
<td id="S3.T3.1.4.7" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_t">84.6</td>
<td id="S3.T3.1.4.8" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_t">82.3</td>
<td id="S3.T3.1.4.9" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_t">80.7</td>
<td id="S3.T3.1.4.10" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_t">80.6</td>
<td id="S3.T3.1.4.11" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_t">81.1</td>
<td id="S3.T3.1.4.12" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_t">79.4</td>
<td id="S3.T3.1.4.13" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_t">80.1</td>
<td id="S3.T3.1.4.14" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_t">77.3</td>
<td id="S3.T3.1.4.15" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_t">72.6</td>
<td id="S3.T3.1.4.16" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r ltx_border_t">74.2</td>
<td id="S3.T3.1.4.17" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_t">81.2</td>
</tr>
<tr id="S3.T3.1.5" class="ltx_tr">
<td id="S3.T3.1.5.1" class="ltx_td ltx_align_left ltx_border_r">XLM-R+R4F</td>
<td id="S3.T3.1.5.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">89.6</td>
<td id="S3.T3.1.5.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r"><span id="S3.T3.1.5.3.1" class="ltx_text ltx_font_bold">84.7</span></td>
<td id="S3.T3.1.5.4" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">85.2</td>
<td id="S3.T3.1.5.5" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r"><span id="S3.T3.1.5.5.1" class="ltx_text ltx_font_bold">84.2</span></td>
<td id="S3.T3.1.5.6" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">83.6</td>
<td id="S3.T3.1.5.7" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">84.6</td>
<td id="S3.T3.1.5.8" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r"><span id="S3.T3.1.5.8.1" class="ltx_text ltx_font_bold">82.5</span></td>
<td id="S3.T3.1.5.9" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">80.3</td>
<td id="S3.T3.1.5.10" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">80.5</td>
<td id="S3.T3.1.5.11" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">80.9</td>
<td id="S3.T3.1.5.12" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">79.2</td>
<td id="S3.T3.1.5.13" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">80.6</td>
<td id="S3.T3.1.5.14" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">78.2</td>
<td id="S3.T3.1.5.15" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">72.7</td>
<td id="S3.T3.1.5.16" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">73.9</td>
<td id="S3.T3.1.5.17" class="ltx_td ltx_nopad_l ltx_align_center">81.4</td>
</tr>
<tr id="S3.T3.1.6" class="ltx_tr">
<td id="S3.T3.1.6.1" class="ltx_td ltx_align_left ltx_border_r">InfoXLM</td>
<td id="S3.T3.1.6.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r"><span id="S3.T3.1.6.2.1" class="ltx_text ltx_font_bold">89.7</span></td>
<td id="S3.T3.1.6.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">84.5</td>
<td id="S3.T3.1.6.4" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">85.5</td>
<td id="S3.T3.1.6.5" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">84.1</td>
<td id="S3.T3.1.6.6" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">83.4</td>
<td id="S3.T3.1.6.7" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">84.2</td>
<td id="S3.T3.1.6.8" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">81.3</td>
<td id="S3.T3.1.6.9" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">80.9</td>
<td id="S3.T3.1.6.10" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">80.4</td>
<td id="S3.T3.1.6.11" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">80.8</td>
<td id="S3.T3.1.6.12" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">78.9</td>
<td id="S3.T3.1.6.13" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">80.9</td>
<td id="S3.T3.1.6.14" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">77.9</td>
<td id="S3.T3.1.6.15" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r"><span id="S3.T3.1.6.15.1" class="ltx_text ltx_font_bold">74.8</span></td>
<td id="S3.T3.1.6.16" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_r">73.7</td>
<td id="S3.T3.1.6.17" class="ltx_td ltx_nopad_l ltx_align_center">81.4</td>
</tr>
<tr id="S3.T3.1.7" class="ltx_tr">
<td id="S3.T3.1.7.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t"><span id="S3.T3.1.7.1.1" class="ltx_text ltx_font_bold">XLM-R+TAT</span></td>
<td id="S3.T3.1.7.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb ltx_border_r ltx_border_t">89.3</td>
<td id="S3.T3.1.7.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb ltx_border_r ltx_border_t">84.2</td>
<td id="S3.T3.1.7.4" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb ltx_border_r ltx_border_t"><span id="S3.T3.1.7.4.1" class="ltx_text ltx_font_bold">85.7</span></td>
<td id="S3.T3.1.7.5" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb ltx_border_r ltx_border_t">83.9</td>
<td id="S3.T3.1.7.6" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb ltx_border_r ltx_border_t"><span id="S3.T3.1.7.6.1" class="ltx_text ltx_font_bold">83.7</span></td>
<td id="S3.T3.1.7.7" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb ltx_border_r ltx_border_t"><span id="S3.T3.1.7.7.1" class="ltx_text ltx_font_bold">85.0</span></td>
<td id="S3.T3.1.7.8" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb ltx_border_r ltx_border_t">82.1</td>
<td id="S3.T3.1.7.9" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb ltx_border_r ltx_border_t"><span id="S3.T3.1.7.9.1" class="ltx_text ltx_font_bold">81.0</span></td>
<td id="S3.T3.1.7.10" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb ltx_border_r ltx_border_t"><span id="S3.T3.1.7.10.1" class="ltx_text ltx_font_bold">80.7</span></td>
<td id="S3.T3.1.7.11" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb ltx_border_r ltx_border_t"><span id="S3.T3.1.7.11.1" class="ltx_text ltx_font_bold">81.3</span></td>
<td id="S3.T3.1.7.12" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb ltx_border_r ltx_border_t"><span id="S3.T3.1.7.12.1" class="ltx_text ltx_font_bold">79.7</span></td>
<td id="S3.T3.1.7.13" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb ltx_border_r ltx_border_t"><span id="S3.T3.1.7.13.1" class="ltx_text ltx_font_bold">81.0</span></td>
<td id="S3.T3.1.7.14" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb ltx_border_r ltx_border_t"><span id="S3.T3.1.7.14.1" class="ltx_text ltx_font_bold">78.4</span></td>
<td id="S3.T3.1.7.15" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb ltx_border_r ltx_border_t">74.1</td>
<td id="S3.T3.1.7.16" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb ltx_border_r ltx_border_t"><span id="S3.T3.1.7.16.1" class="ltx_text ltx_font_bold">75.1</span></td>
<td id="S3.T3.1.7.17" class="ltx_td ltx_nopad_l ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T3.1.7.17.1" class="ltx_text ltx_font_bold">81.7</span></td>
</tr>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span>Comparison of targeted adversarial training (TAT) and prior state of the art in zero-shot cross-lingual learning on the XNLI test set.</figcaption>
</figure>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Zero-Shot Learning on Natural Language Inference</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">Next, we compare standard and adversarial training in generalizability to out-domain datasets.
Specifically, we fine-tune BERT<sub id="S3.SS3.p1.1.1" class="ltx_sub">BASE</sub> on the MNLI training data and evaluate it on various natural language inference test sets: HANS <cite class="ltx_cite ltx_citemacro_cite">McCoy et al. (<a href="#bib.bib31" title="" class="ltx_ref">2019</a>)</cite>, SNLI <cite class="ltx_cite ltx_citemacro_cite">Bowman et al. (<a href="#bib.bib5" title="" class="ltx_ref">2015</a>)</cite>, SciTail <cite class="ltx_cite ltx_citemacro_cite">Khot et al. (<a href="#bib.bib24" title="" class="ltx_ref">2018</a>)</cite>, MeNLI <cite class="ltx_cite ltx_citemacro_cite">Romanov and Shivade (<a href="#bib.bib35" title="" class="ltx_ref">2018</a>)</cite>.
See <a href="#S3.T2" title="Table 2 ‣ 3.2 Standard GLUE Evaluation ‣ 3 Experiments ‣ Targeted Adversarial Training for Natural Language Understanding" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table 2</span></a> for the results. TAT substantially outperforms standard training and state-of-the-art adversarial training methods. Interestingly, the gains are particularly pronounced on the two hardest datasets, HANS and MedNLI.
HANS used heuristic rules to identify easy instances for MNLI-trained BERT models and introduced modifications to make them harder.
MedNLI is from the biomedical domain, which is substantially different from the general domain of MNLI. This provides additional evidence that targeted adversarial training is especially effective in enhancing generalizability in out domains.</p>
</div>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Zero-Shot Learning on Cross-Lingual Natural Language Inference</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p">We also conducted zero-shot evaluation in the cross-lingual setting by comparing standard and adversarial training on XNLI <cite class="ltx_cite ltx_citemacro_cite">Conneau et al. (<a href="#bib.bib11" title="" class="ltx_ref">2018</a>)</cite>.
Specifically, a cross-lingual language model is fine-tuned using the English NLI dataset and then tested on datasets of other languages. Following <cite class="ltx_cite ltx_citemacro_citet">Conneau et al. (<a href="#bib.bib10" title="" class="ltx_ref">2019</a>)</cite>, we used the pre-trained XLM-R large model in our experiments, and compare targeted adversarial training (XLM-R+TAT) with state-of-the-art systems that use standard training (XLM-R) and adversarial training (XLM-R+R3F/R4F) <cite class="ltx_cite ltx_citemacro_cite">Aghajanyan et al. (<a href="#bib.bib1" title="" class="ltx_ref">2020</a>)</cite>, as well as another state-of-the-art language model InfoXLM <cite class="ltx_cite ltx_citemacro_cite">Chi et al. (<a href="#bib.bib9" title="" class="ltx_ref">2020</a>)</cite>.
To ensure fair comparison, we also report the results from our reimplementation of XLM-R <cite class="ltx_cite ltx_citemacro_cite">Conneau et al. (<a href="#bib.bib11" title="" class="ltx_ref">2018</a>)</cite> (XLM-R<sub id="S3.SS4.p1.1.1" class="ltx_sub">Reprod</sub>).
See <a href="#S3.T3" title="Table 3 ‣ 3.2 Standard GLUE Evaluation ‣ 3 Experiments ‣ Targeted Adversarial Training for Natural Language Understanding" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table 3</span></a> for the results.
Targeted adversarial training (TAT) demonstrates a clear advantage in improving zero-shot transfer learning across languages, especially for languages most different from English, such as Urdu. Overall, TAT produces a new state-of-the-art result of 81.7% over 15 languages on XNLI.</p>
</div>
</section>
<section id="S3.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.5 </span>Analysis</h3>

<figure id="S3.F2" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S3.F2.sf1" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S3.F2.sf1.1" class="ltx_inline-block ltx_transformed_outer" style="width:413.8pt;height:221.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="S3.F2.sf1.1.1" class="ltx_p"><span id="S3.F2.sf1.1.1.1" class="ltx_text ltx_inline-block" style="width:413.8pt;position:relative; bottom:-16.7pt;">
<img src="/html/2104.05847/assets/figures/tat-matched.png" id="S3.F2.sf1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="568" height="330" alt="Refer to caption"></span></p>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>MNLI Development (in-domain)</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S3.F2.sf2" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S3.F2.sf2.1" class="ltx_inline-block ltx_transformed_outer" style="width:431.2pt;height:217.1pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="S3.F2.sf2.1.1" class="ltx_p"><span id="S3.F2.sf2.1.1.1" class="ltx_text ltx_inline-block" style="width:431.2pt;position:relative; bottom:-18.3pt;">
<img src="/html/2104.05847/assets/figures/tat-mismatched.png" id="S3.F2.sf2.1.1.1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="592" height="362" alt="Refer to caption"></span></p>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>MNLI Development (out-domain)</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>
Comparison of standard and targeted adversarial training on MNLI, subdivided per agreement.
</figcaption>
</figure>
<div id="S3.SS5.p1" class="ltx_para">
<p id="S3.SS5.p1.1" class="ltx_p">As we have seen in Figure <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Targeted Adversarial Training for Natural Language Understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> earlier, TAT reduces the errors across the board on MNLI development set.
To understand how TAT improves performance, we conducted a more detailed analysis by subdividing the dataset based on the degree of human agreement. Here, there are three label classes and each sample instance has 5 human annotations. The samples can be divided into four categories:
5-0-0, 4-1-0, 3-2-0, 3-1-1. E.g., 3-1-1 signifies that there are three votes for one label and one for each of the other two labels. In Figure <a href="#S3.F2" title="Figure 2 ‣ 3.5 Analysis ‣ 3 Experiments ‣ Targeted Adversarial Training for Natural Language Understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, we see that TAT outperforms the baseline consistently over all categories, with higher improvement on the more ambiguous samples, especially for out-domain samples. This suggests that TAT is most helpful for the challenging instances that exhibit higher ambiguity and are more different from training examples.</p>
</div>
<figure id="S3.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S3.F3.sf1" class="ltx_figure ltx_figure_panel ltx_align_center">
<div id="S3.F3.sf1.1" class="ltx_inline-block ltx_transformed_outer" style="width:395.5pt;height:308.4pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="S3.F3.sf1.1.1" class="ltx_p"><span id="S3.F3.sf1.1.1.1" class="ltx_text ltx_inline-block" style="width:395.5pt;position:relative; bottom:-3.2pt;">
<img src="/html/2104.05847/assets/x1.png" id="S3.F3.sf1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="415" height="339" alt="Refer to caption"></span></p>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>Loss surface of traditional training</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S3.F3.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2104.05847/assets/x2.png" id="S3.F3.sf2.g1" class="ltx_graphics ltx_img_square" width="415" height="339" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Loss surface of TAT</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>
Training loss surfaces of traditional training vs TAT on MNLI.
</figcaption>
</figure>
<div id="S3.SS5.p2" class="ltx_para">
<p id="S3.SS5.p2.1" class="ltx_p">We also visualize the loss landscape of both the standard training and TAT, shown in Figure <a href="#S3.F3" title="Figure 3 ‣ 3.5 Analysis ‣ 3 Experiments ‣ Targeted Adversarial Training for Natural Language Understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. TAT has a wider and flatter loss surface, which generally indicates better generalization <cite class="ltx_cite ltx_citemacro_cite">Hochreiter and Schmidhuber (<a href="#bib.bib19" title="" class="ltx_ref">1997</a>); Hao et al. (<a href="#bib.bib18" title="" class="ltx_ref">2019</a>); Li et al. (<a href="#bib.bib27" title="" class="ltx_ref">2018</a>)</cite>.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Conclusion</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">We present the first study to apply targeted attacks in adversarial training for natural language understanding. Our TAT algorithm is simple yet effective in improving model generalizability for various NLP tasks, especially in zero-shot learning and for out-domain data.
Future directions include: applying TAT in pretraining and other NLP tasks e.g., sequence labeling, exploring alternative approaches for target sampling.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgments</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">We thank Microsoft Research Technology Engineering team for setting up GPU machines. We also thank the anonymous reviewers for valuable discussions.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Aghajanyan et al. (2020)</span>
<span class="ltx_bibblock">
Armen Aghajanyan, Akshat Shrivastava, Anchit Gupta, Naman Goyal, Luke
Zettlemoyer, and Sonal Gupta. 2020.

</span>
<span class="ltx_bibblock">Better fine-tuning by reducing representational collapse.

</span>
<span class="ltx_bibblock"><em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2008.03156</em>.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Artetxe and Schwenk (2019)</span>
<span class="ltx_bibblock">
Mikel Artetxe and Holger Schwenk. 2019.

</span>
<span class="ltx_bibblock">Massively multilingual sentence embeddings for zero-shot
cross-lingual transfer and beyond.

</span>
<span class="ltx_bibblock"><em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Transactions of the Association for Computational Linguistics</em>,
7:597–610.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bar-Haim et al. (2006)</span>
<span class="ltx_bibblock">
Roy Bar-Haim, Ido Dagan, Bill Dolan, Lisa Ferro, and Danilo Giampiccolo. 2006.

</span>
<span class="ltx_bibblock">The second PASCAL recognising textual entailment challenge.

</span>
<span class="ltx_bibblock">In <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Second PASCAL Challenges Workshop on
Recognising Textual Entailment</em>.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bentivogli et al. (2009)</span>
<span class="ltx_bibblock">
Luisa Bentivogli, Ido Dagan, Hoa Trang Dang, Danilo Giampiccolo, and Bernardo
Magnini. 2009.

</span>
<span class="ltx_bibblock">The fifth pascal recognizing textual entailment challenge.

</span>
<span class="ltx_bibblock">In <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">In Proc Text Analysis Conference (TAC’09</em>.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bowman et al. (2015)</span>
<span class="ltx_bibblock">
Samuel R. Bowman, Gabor Angeli, Christopher Potts, and Christopher D. Manning.
2015.

</span>
<span class="ltx_bibblock">A large annotated corpus for learning natural language inference.

</span>
<span class="ltx_bibblock">In <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2015 Conference on Empirical Methods in
Natural Language Processing (EMNLP)</em>. Association for Computational
Linguistics.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cer et al. (2017)</span>
<span class="ltx_bibblock">
Daniel Cer, Mona Diab, Eneko Agirre, Inigo Lopez-Gazpio, and Lucia Specia.
2017.

</span>
<span class="ltx_bibblock">Semeval-2017 task 1: Semantic textual similarity-multilingual and
cross-lingual focused evaluation.

</span>
<span class="ltx_bibblock"><em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1708.00055</em>.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cheng et al. (2020)</span>
<span class="ltx_bibblock">
Hao Cheng, Xiaodong Liu, Lis Pereira, Yaoliang Yu, and Jianfeng Gao. 2020.

</span>
<span class="ltx_bibblock">Posterior differential regularization with f-divergence for improving
model robustness.

</span>
<span class="ltx_bibblock"><em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2010.12638</em>.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cheng et al. (2019)</span>
<span class="ltx_bibblock">
Yong Cheng, Lu Jiang, and Wolfgang Macherey. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/P19-1425" title="" class="ltx_ref ltx_href">Robust neural machine
translation with doubly adversarial inputs</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 57th Annual Meeting of the Association
for Computational Linguistics</em>, pages 4324–4333, Florence, Italy.
Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chi et al. (2020)</span>
<span class="ltx_bibblock">
Zewen Chi, Li Dong, Furu Wei, Nan Yang, Saksham Singhal, Wenhui Wang, Xia Song,
Xian-Ling Mao, Heyan Huang, and Ming Zhou. 2020.

</span>
<span class="ltx_bibblock">Infoxlm: An information-theoretic framework for cross-lingual
language model pre-training.

</span>
<span class="ltx_bibblock"><em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2007.07834</em>.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Conneau et al. (2019)</span>
<span class="ltx_bibblock">
Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume
Wenzek, Francisco Guzmán, Edouard Grave, Myle Ott, Luke Zettlemoyer, and
Veselin Stoyanov. 2019.

</span>
<span class="ltx_bibblock">Unsupervised cross-lingual representation learning at scale.

</span>
<span class="ltx_bibblock"><em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1911.02116</em>.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Conneau et al. (2018)</span>
<span class="ltx_bibblock">
Alexis Conneau, Ruty Rinott, Guillaume Lample, Adina Williams, Samuel Bowman,
Holger Schwenk, and Veselin Stoyanov. 2018.

</span>
<span class="ltx_bibblock">Xnli: Evaluating cross-lingual sentence representations.

</span>
<span class="ltx_bibblock">In <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 Conference on Empirical Methods in
Natural Language Processing</em>, pages 2475–2485.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dagan et al. (2006)</span>
<span class="ltx_bibblock">
Ido Dagan, Oren Glickman, and Bernardo Magnini. 2006.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1007/11736790_9" title="" class="ltx_ref ltx_href">The pascal recognising
textual entailment challenge</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Proceedings of the First International Conference on Machine
Learning Challenges: Evaluating Predictive Uncertainty Visual Object
Classification, and Recognizing Textual Entailment</em>, MLCW’05, pages 177–190,
Berlin, Heidelberg. Springer-Verlag.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Devlin et al. (2018)</span>
<span class="ltx_bibblock">
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018.

</span>
<span class="ltx_bibblock">Bert: Pre-training of deep bidirectional transformers for language
understanding.

</span>
<span class="ltx_bibblock"><em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1810.04805</em>.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dolan and Brockett (2005)</span>
<span class="ltx_bibblock">
William B Dolan and Chris Brockett. 2005.

</span>
<span class="ltx_bibblock">Automatically constructing a corpus of sentential paraphrases.

</span>
<span class="ltx_bibblock">In <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Third International Workshop on
Paraphrasing (IWP2005)</em>.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dong et al. (2018)</span>
<span class="ltx_bibblock">
Yinpeng Dong, Fangzhou Liao, Tianyu Pang, Hang Su, Jun Zhu, Xiaolin Hu, and
Jianguo Li. 2018.

</span>
<span class="ltx_bibblock">Boosting adversarial attacks with momentum.

</span>
<span class="ltx_bibblock">In <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE conference on computer vision and
pattern recognition</em>, pages 9185–9193.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Giampiccolo et al. (2007)</span>
<span class="ltx_bibblock">
Danilo Giampiccolo, Bernardo Magnini, Ido Dagan, and Bill Dolan. 2007.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.aclweb.org/anthology/W07-1401" title="" class="ltx_ref ltx_href">The third PASCAL
recognizing textual entailment challenge</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">Proceedings of the ACL-PASCAL Workshop on Textual
Entailment and Paraphrasing</em>, pages 1–9, Prague. Association for
Computational Linguistics.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Goodfellow et al. (2014)</span>
<span class="ltx_bibblock">
Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. 2014.

</span>
<span class="ltx_bibblock">Explaining and harnessing adversarial examples.

</span>
<span class="ltx_bibblock"><em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1412.6572</em>.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hao et al. (2019)</span>
<span class="ltx_bibblock">
Yaru Hao, Li Dong, Furu Wei, and Ke Xu. 2019.

</span>
<span class="ltx_bibblock">Visualizing and understanding the effectiveness of bert.

</span>
<span class="ltx_bibblock">In <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 Conference on Empirical Methods in
Natural Language Processing and the 9th International Joint Conference on
Natural Language Processing (EMNLP-IJCNLP)</em>, pages 4134–4143.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hochreiter and Schmidhuber (1997)</span>
<span class="ltx_bibblock">
Sepp Hochreiter and Jürgen Schmidhuber. 1997.

</span>
<span class="ltx_bibblock">Flat minima.

</span>
<span class="ltx_bibblock"><em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">Neural Computation</em>, 9(1):1–42.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hsieh et al. (2019)</span>
<span class="ltx_bibblock">
Yu-Lun Hsieh, Minhao Cheng, Da-Cheng Juan, Wei Wei, Wen-Lian Hsu, and Cho-Jui
Hsieh. 2019.

</span>
<span class="ltx_bibblock">On the robustness of self-attentive models.

</span>
<span class="ltx_bibblock">In <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 57th Annual Meeting of the Association
for Computational Linguistics</em>, pages 1520–1529.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et al. (2019)</span>
<span class="ltx_bibblock">
Haoming Jiang, Pengcheng He, Weizhu Chen, Xiaodong Liu, Jianfeng Gao, and Tuo
Zhao. 2019.

</span>
<span class="ltx_bibblock">Smart: Robust and efficient fine-tuning for pre-trained natural
language models through principled regularized optimization.

</span>
<span class="ltx_bibblock"><em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1911.03437</em>.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jin et al. (2019)</span>
<span class="ltx_bibblock">
Di Jin, Zhijing Jin, Joey Tianyi Zhou, and Peter Szolovits. 2019.

</span>
<span class="ltx_bibblock">Is bert really robust? natural language attack on text classification
and entailment.

</span>
<span class="ltx_bibblock"><em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1907.11932</em>.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Johnson et al. (2016)</span>
<span class="ltx_bibblock">
Alistair EW Johnson, Tom J Pollard, Lu Shen, H Lehman Li-Wei, Mengling Feng,
Mohammad Ghassemi, Benjamin Moody, Peter Szolovits, Leo Anthony Celi, and
Roger G Mark. 2016.

</span>
<span class="ltx_bibblock">Mimic-iii, a freely accessible critical care database.

</span>
<span class="ltx_bibblock"><em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">Scientific data</em>, 3(1):1–9.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Khot et al. (2018)</span>
<span class="ltx_bibblock">
Tushar Khot, Ashish Sabharwal, and Peter Clark. 2018.

</span>
<span class="ltx_bibblock">SciTail: A textual entailment dataset from science question
answering.

</span>
<span class="ltx_bibblock">In <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">AAAI</em>.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kingma and Ba (2014)</span>
<span class="ltx_bibblock">
Diederik Kingma and Jimmy Ba. 2014.

</span>
<span class="ltx_bibblock">Adam: A method for stochastic optimization.

</span>
<span class="ltx_bibblock"><em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1412.6980</em>.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Levesque et al. (2012)</span>
<span class="ltx_bibblock">
Hector Levesque, Ernest Davis, and Leora Morgenstern. 2012.

</span>
<span class="ltx_bibblock">The winograd schema challenge.

</span>
<span class="ltx_bibblock">In <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">Thirteenth International Conference on the Principles of
Knowledge Representation and Reasoning</em>.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2018)</span>
<span class="ltx_bibblock">
Hao Li, Zheng Xu, Gavin Taylor, Christoph Studer, and Tom Goldstein. 2018.

</span>
<span class="ltx_bibblock">Visualizing the loss landscape of neural nets.

</span>
<span class="ltx_bibblock">In <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, pages
6389–6399.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2020a)</span>
<span class="ltx_bibblock">
Xiaodong Liu, Hao Cheng, Pengcheng He, Weizhu Chen, Yu Wang, Hoifung Poon, and
Jianfeng Gao. 2020a.

</span>
<span class="ltx_bibblock">Adversarial training for large neural language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2004.08994</em>.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2020b)</span>
<span class="ltx_bibblock">
Xiaodong Liu, Yu Wang, Jianshu Ji, Hao Cheng, Xueyun Zhu, Emmanuel Awa,
Pengcheng He, Weizhu Chen, Hoifung Poon, Guihong Cao, and Jianfeng Gao.
2020b.

</span>
<span class="ltx_bibblock">The Microsoft toolkit of multi-task deep neural networks for
natural language understanding.

</span>
<span class="ltx_bibblock">In <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual Meeting of the Association
for Computational Linguistics: System Demonstrations</em>.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Madry et al. (2017)</span>
<span class="ltx_bibblock">
Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and
Adrian Vladu. 2017.

</span>
<span class="ltx_bibblock">Towards deep learning models resistant to adversarial attacks.

</span>
<span class="ltx_bibblock"><em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1706.06083</em>.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McCoy et al. (2019)</span>
<span class="ltx_bibblock">
Tom McCoy, Ellie Pavlick, and Tal Linzen. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/P19-1334" title="" class="ltx_ref ltx_href">Right for the wrong
reasons: Diagnosing syntactic heuristics in natural language inference</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 57th Annual Meeting of the Association
for Computational Linguistics</em>, pages 3428–3448, Florence, Italy.
Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Miyato et al. (2018)</span>
<span class="ltx_bibblock">
Takeru Miyato, Shin-ichi Maeda, Masanori Koyama, and Shin Ishii. 2018.

</span>
<span class="ltx_bibblock">Virtual adversarial training: a regularization method for supervised
and semi-supervised learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">IEEE transactions on pattern analysis and machine
intelligence</em>, 41(8):1979–1993.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pereira et al. (2020)</span>
<span class="ltx_bibblock">
Lis Pereira, Xiaodong Liu, Fei Cheng, Masayuki Asahara, and Ichiro Kobayashi.
2020.

</span>
<span class="ltx_bibblock">Adversarial training for commonsense inference.

</span>
<span class="ltx_bibblock"><em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2005.08156</em>.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rajpurkar et al. (2016)</span>
<span class="ltx_bibblock">
Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. 2016.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/D16-1264" title="" class="ltx_ref ltx_href">SQuAD: 100,000+
questions for machine comprehension of text</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2016 Conference on Empirical Methods in
Natural Language Processing</em>, pages 2383–2392, Austin, Texas. Association
for Computational Linguistics.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Romanov and Shivade (2018)</span>
<span class="ltx_bibblock">
Alexey Romanov and Chaitanya Shivade. 2018.

</span>
<span class="ltx_bibblock">Lessons from natural language inference in the clinical domain.

</span>
<span class="ltx_bibblock">In <em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 Conference on Empirical Methods in
Natural Language Processing</em>, pages 1586–1596.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shafahi et al. (2019)</span>
<span class="ltx_bibblock">
Ali Shafahi, Mahyar Najibi, Amin Ghiasi, Zheng Xu, John Dickerson, Christoph
Studer, Larry S Davis, Gavin Taylor, and Tom Goldstein. 2019.

</span>
<span class="ltx_bibblock">Adversarial training for free!

</span>
<span class="ltx_bibblock"><em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1904.12843</em>.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Socher et al. (2013)</span>
<span class="ltx_bibblock">
Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D Manning,
Andrew Ng, and Christopher Potts. 2013.

</span>
<span class="ltx_bibblock">Recursive deep models for semantic compositionality over a sentiment
treebank.

</span>
<span class="ltx_bibblock">In <em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2013 conference on empirical methods in
natural language processing</em>, pages 1631–1642.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tramèr et al. (2017)</span>
<span class="ltx_bibblock">
Florian Tramèr, Alexey Kurakin, Nicolas Papernot, Ian Goodfellow, Dan
Boneh, and Patrick McDaniel. 2017.

</span>
<span class="ltx_bibblock">Ensemble adversarial training: Attacks and defenses.

</span>
<span class="ltx_bibblock"><em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1705.07204</em>.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2018)</span>
<span class="ltx_bibblock">
Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel R
Bowman. 2018.

</span>
<span class="ltx_bibblock">Glue: A multi-task benchmark and analysis platform for natural
language understanding.

</span>
<span class="ltx_bibblock"><em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1804.07461</em>.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Warstadt et al. (2018)</span>
<span class="ltx_bibblock">
Alex Warstadt, Amanpreet Singh, and Samuel R Bowman. 2018.

</span>
<span class="ltx_bibblock">Neural network acceptability judgments.

</span>
<span class="ltx_bibblock"><em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1805.12471</em>.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Williams et al. (2018)</span>
<span class="ltx_bibblock">
Adina Williams, Nikita Nangia, and Samuel Bowman. 2018.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://aclweb.org/anthology/N18-1101" title="" class="ltx_ref ltx_href">A broad-coverage
challenge corpus for sentence understanding through inference</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies, Volume 1 (Long Papers)</em>, pages 1112–1122. Association for
Computational Linguistics.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2019)</span>
<span class="ltx_bibblock">
Michael Zhang, James Lucas, Jimmy Ba, and Geoffrey E Hinton. 2019.

</span>
<span class="ltx_bibblock">Lookahead optimizer: k steps forward, 1 step back.

</span>
<span class="ltx_bibblock">In <em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, pages
9597–9608.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu et al. (2019)</span>
<span class="ltx_bibblock">
Chen Zhu, Yu Cheng, Zhe Gan, Siqi Sun, Thomas Goldstein, and Jingjing Liu.
2019.

</span>
<span class="ltx_bibblock">Freelb: Enhanced adversarial training for language understanding.

</span>
<span class="ltx_bibblock"><em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1909.11764</em>.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>NLU Benchmarks</h2>

<figure id="A1.T4" class="ltx_table">
<table id="A1.T4.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="A1.T4.1.1" class="ltx_tr">
<td id="A1.T4.1.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt"><span id="A1.T4.1.1.1.1" class="ltx_text ltx_font_bold">Corpus</span></td>
<td id="A1.T4.1.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt">Task</td>
<td id="A1.T4.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">#Train</td>
<td id="A1.T4.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">#Dev</td>
<td id="A1.T4.1.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">#Test</td>
<td id="A1.T4.1.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">#Label</td>
<td id="A1.T4.1.1.7" class="ltx_td ltx_align_center ltx_border_tt">Metrics</td>
</tr>
<tr id="A1.T4.1.2" class="ltx_tr">
<td id="A1.T4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_right ltx_border_tt" colspan="6">Single-Sentence Classification (GLUE)</td>
<td id="A1.T4.1.2.2" class="ltx_td ltx_border_tt"></td>
</tr>
<tr id="A1.T4.1.3" class="ltx_tr">
<td id="A1.T4.1.3.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">CoLA</td>
<td id="A1.T4.1.3.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Acceptability</td>
<td id="A1.T4.1.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">8.5k</td>
<td id="A1.T4.1.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1k</td>
<td id="A1.T4.1.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1k</td>
<td id="A1.T4.1.3.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">2</td>
<td id="A1.T4.1.3.7" class="ltx_td ltx_align_center ltx_border_t">Matthews corr</td>
</tr>
<tr id="A1.T4.1.4" class="ltx_tr">
<td id="A1.T4.1.4.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">SST</td>
<td id="A1.T4.1.4.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Sentiment</td>
<td id="A1.T4.1.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">67k</td>
<td id="A1.T4.1.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">872</td>
<td id="A1.T4.1.4.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.8k</td>
<td id="A1.T4.1.4.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">2</td>
<td id="A1.T4.1.4.7" class="ltx_td ltx_align_center ltx_border_t">Accuracy</td>
</tr>
<tr id="A1.T4.1.5" class="ltx_tr">
<td id="A1.T4.1.5.1" class="ltx_td ltx_nopad_r ltx_align_right ltx_border_tt" colspan="6">Pairwise Text Classification (GLUE)</td>
<td id="A1.T4.1.5.2" class="ltx_td ltx_border_tt"></td>
</tr>
<tr id="A1.T4.1.6" class="ltx_tr">
<td id="A1.T4.1.6.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">MNLI</td>
<td id="A1.T4.1.6.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">NLI</td>
<td id="A1.T4.1.6.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">393k</td>
<td id="A1.T4.1.6.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">20k</td>
<td id="A1.T4.1.6.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">20k</td>
<td id="A1.T4.1.6.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">3</td>
<td id="A1.T4.1.6.7" class="ltx_td ltx_align_center ltx_border_t">Accuracy</td>
</tr>
<tr id="A1.T4.1.7" class="ltx_tr">
<td id="A1.T4.1.7.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">RTE</td>
<td id="A1.T4.1.7.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">NLI</td>
<td id="A1.T4.1.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">2.5k</td>
<td id="A1.T4.1.7.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">276</td>
<td id="A1.T4.1.7.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">3k</td>
<td id="A1.T4.1.7.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">2</td>
<td id="A1.T4.1.7.7" class="ltx_td ltx_align_center ltx_border_t">Accuracy</td>
</tr>
<tr id="A1.T4.1.8" class="ltx_tr">
<td id="A1.T4.1.8.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">WNLI</td>
<td id="A1.T4.1.8.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">NLI</td>
<td id="A1.T4.1.8.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">634</td>
<td id="A1.T4.1.8.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">71</td>
<td id="A1.T4.1.8.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">146</td>
<td id="A1.T4.1.8.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">2</td>
<td id="A1.T4.1.8.7" class="ltx_td ltx_align_center ltx_border_t">Accuracy</td>
</tr>
<tr id="A1.T4.1.9" class="ltx_tr">
<td id="A1.T4.1.9.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">QQP</td>
<td id="A1.T4.1.9.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Paraphrase</td>
<td id="A1.T4.1.9.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">364k</td>
<td id="A1.T4.1.9.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">40k</td>
<td id="A1.T4.1.9.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">391k</td>
<td id="A1.T4.1.9.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">2</td>
<td id="A1.T4.1.9.7" class="ltx_td ltx_align_center ltx_border_t">Accuracy/F1</td>
</tr>
<tr id="A1.T4.1.10" class="ltx_tr">
<td id="A1.T4.1.10.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">MRPC</td>
<td id="A1.T4.1.10.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Paraphrase</td>
<td id="A1.T4.1.10.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">3.7k</td>
<td id="A1.T4.1.10.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">408</td>
<td id="A1.T4.1.10.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.7k</td>
<td id="A1.T4.1.10.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">2</td>
<td id="A1.T4.1.10.7" class="ltx_td ltx_align_center ltx_border_t">Accuracy/F1</td>
</tr>
<tr id="A1.T4.1.11" class="ltx_tr">
<td id="A1.T4.1.11.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">QNLI</td>
<td id="A1.T4.1.11.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">QA/NLI</td>
<td id="A1.T4.1.11.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">108k</td>
<td id="A1.T4.1.11.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">5.7k</td>
<td id="A1.T4.1.11.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">5.7k</td>
<td id="A1.T4.1.11.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">2</td>
<td id="A1.T4.1.11.7" class="ltx_td ltx_align_center ltx_border_t">Accuracy</td>
</tr>
<tr id="A1.T4.1.12" class="ltx_tr">
<td id="A1.T4.1.12.1" class="ltx_td ltx_nopad_r ltx_align_right ltx_border_tt" colspan="5">Text Similarity (GLUE)</td>
<td id="A1.T4.1.12.2" class="ltx_td ltx_border_tt"></td>
<td id="A1.T4.1.12.3" class="ltx_td ltx_border_tt"></td>
</tr>
<tr id="A1.T4.1.13" class="ltx_tr">
<td id="A1.T4.1.13.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">STS-B</td>
<td id="A1.T4.1.13.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Similarity</td>
<td id="A1.T4.1.13.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">7k</td>
<td id="A1.T4.1.13.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.5k</td>
<td id="A1.T4.1.13.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.4k</td>
<td id="A1.T4.1.13.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1</td>
<td id="A1.T4.1.13.7" class="ltx_td ltx_align_center ltx_border_t">Pearson/Spearman corr</td>
</tr>
<tr id="A1.T4.1.14" class="ltx_tr">
<td id="A1.T4.1.14.1" class="ltx_td ltx_nopad_r ltx_align_right ltx_border_t" colspan="6">Pairwise Text Classification for the Zero-shot setting</td>
<td id="A1.T4.1.14.2" class="ltx_td ltx_border_t"></td>
</tr>
<tr id="A1.T4.1.15" class="ltx_tr">
<td id="A1.T4.1.15.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">SNLI</td>
<td id="A1.T4.1.15.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">NLI</td>
<td id="A1.T4.1.15.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">-</td>
<td id="A1.T4.1.15.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">-</td>
<td id="A1.T4.1.15.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">9.8k</td>
<td id="A1.T4.1.15.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">3</td>
<td id="A1.T4.1.15.7" class="ltx_td ltx_align_center ltx_border_t">Accuracy</td>
</tr>
<tr id="A1.T4.1.16" class="ltx_tr">
<td id="A1.T4.1.16.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">SciTail</td>
<td id="A1.T4.1.16.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">NLI</td>
<td id="A1.T4.1.16.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">-</td>
<td id="A1.T4.1.16.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">-</td>
<td id="A1.T4.1.16.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">2.1k</td>
<td id="A1.T4.1.16.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">2</td>
<td id="A1.T4.1.16.7" class="ltx_td ltx_align_center ltx_border_t">Accuracy</td>
</tr>
<tr id="A1.T4.1.17" class="ltx_tr">
<td id="A1.T4.1.17.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">HANS</td>
<td id="A1.T4.1.17.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">NLI</td>
<td id="A1.T4.1.17.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">-</td>
<td id="A1.T4.1.17.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">-</td>
<td id="A1.T4.1.17.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">3k</td>
<td id="A1.T4.1.17.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">2</td>
<td id="A1.T4.1.17.7" class="ltx_td ltx_align_center ltx_border_t">Accuracy</td>
</tr>
<tr id="A1.T4.1.18" class="ltx_tr">
<td id="A1.T4.1.18.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">MedNLI</td>
<td id="A1.T4.1.18.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">NLI</td>
<td id="A1.T4.1.18.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">-</td>
<td id="A1.T4.1.18.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">-</td>
<td id="A1.T4.1.18.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.4k</td>
<td id="A1.T4.1.18.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">3</td>
<td id="A1.T4.1.18.7" class="ltx_td ltx_align_center ltx_border_t">Accuracy</td>
</tr>
<tr id="A1.T4.1.19" class="ltx_tr">
<td id="A1.T4.1.19.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t">XNLI</td>
<td id="A1.T4.1.19.2" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t">NLI</td>
<td id="A1.T4.1.19.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t">-</td>
<td id="A1.T4.1.19.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t">-</td>
<td id="A1.T4.1.19.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t">75k</td>
<td id="A1.T4.1.19.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t">3</td>
<td id="A1.T4.1.19.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">Accuracy</td>
</tr>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4: </span>Summary information of the NLU benchmarks.
</figcaption>
</figure>
<div id="A1.p1" class="ltx_para">
<p id="A1.p1.1" class="ltx_p">The NLU benchmarks used in our experiments, i.e. GLUE benchmark <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a href="#bib.bib39" title="" class="ltx_ref">2018</a>)</cite>, SNLI <cite class="ltx_cite ltx_citemacro_cite">Bowman et al. (<a href="#bib.bib5" title="" class="ltx_ref">2015</a>)</cite>, SciTail <cite class="ltx_cite ltx_citemacro_cite">Khot et al. (<a href="#bib.bib24" title="" class="ltx_ref">2018</a>)</cite>, HANS <cite class="ltx_cite ltx_citemacro_cite">McCoy et al. (<a href="#bib.bib31" title="" class="ltx_ref">2019</a>)</cite>, MedNLI <cite class="ltx_cite ltx_citemacro_cite">Romanov and Shivade (<a href="#bib.bib35" title="" class="ltx_ref">2018</a>)</cite> and XNLI <cite class="ltx_cite ltx_citemacro_cite">Conneau et al. (<a href="#bib.bib11" title="" class="ltx_ref">2018</a>)</cite>,
are briefly introduced in the following sections. Table <a href="#A1.T4" title="Table 4 ‣ Appendix A NLU Benchmarks ‣ Targeted Adversarial Training for Natural Language Understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> summarizes the information of these tasks. In the experiments, GLUE is used for the normal setting, while the other datasets are used for the zero-shot setting.</p>
</div>
<div id="A1.p2" class="ltx_para ltx_noindent">
<p id="A1.p2.1" class="ltx_p"><math id="A1.p2.1.m1.1" class="ltx_Math" alttext="\bullet" display="inline"><semantics id="A1.p2.1.m1.1a"><mo id="A1.p2.1.m1.1.1" xref="A1.p2.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="A1.p2.1.m1.1b"><ci id="A1.p2.1.m1.1.1.cmml" xref="A1.p2.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.p2.1.m1.1c">\bullet</annotation></semantics></math> <span id="A1.p2.1.1" class="ltx_text ltx_font_bold">GLUE</span>. The General Language Understanding Evaluation (GLUE) benchmark is a collection of nine natural language understanding (NLU) tasks. As shown in Table <a href="#A1.T4" title="Table 4 ‣ Appendix A NLU Benchmarks ‣ Targeted Adversarial Training for Natural Language Understanding" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>,
it includes question answering <cite class="ltx_cite ltx_citemacro_cite">Rajpurkar et al. (<a href="#bib.bib34" title="" class="ltx_ref">2016</a>)</cite>, linguistic acceptability <cite class="ltx_cite ltx_citemacro_cite">Warstadt et al. (<a href="#bib.bib40" title="" class="ltx_ref">2018</a>)</cite>, sentiment analysis <cite class="ltx_cite ltx_citemacro_cite">Socher et al. (<a href="#bib.bib37" title="" class="ltx_ref">2013</a>)</cite>, text similarity <cite class="ltx_cite ltx_citemacro_cite">Cer et al. (<a href="#bib.bib6" title="" class="ltx_ref">2017</a>)</cite>, paraphrase detection <cite class="ltx_cite ltx_citemacro_cite">Dolan and Brockett (<a href="#bib.bib14" title="" class="ltx_ref">2005</a>)</cite>, and natural language inference (NLI) <cite class="ltx_cite ltx_citemacro_cite">Dagan et al. (<a href="#bib.bib12" title="" class="ltx_ref">2006</a>); Bar-Haim et al. (<a href="#bib.bib3" title="" class="ltx_ref">2006</a>); Giampiccolo et al. (<a href="#bib.bib16" title="" class="ltx_ref">2007</a>); Bentivogli et al. (<a href="#bib.bib4" title="" class="ltx_ref">2009</a>); Levesque et al. (<a href="#bib.bib26" title="" class="ltx_ref">2012</a>); Williams et al. (<a href="#bib.bib41" title="" class="ltx_ref">2018</a>)</cite>. The diversity of the tasks makes GLUE very suitable for evaluating the generalization and robustness of NLU models.</p>
</div>
<div id="A1.p3" class="ltx_para ltx_noindent">
<p id="A1.p3.1" class="ltx_p"><math id="A1.p3.1.m1.1" class="ltx_Math" alttext="\bullet" display="inline"><semantics id="A1.p3.1.m1.1a"><mo id="A1.p3.1.m1.1.1" xref="A1.p3.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="A1.p3.1.m1.1b"><ci id="A1.p3.1.m1.1.1.cmml" xref="A1.p3.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.p3.1.m1.1c">\bullet</annotation></semantics></math> <span id="A1.p3.1.1" class="ltx_text ltx_font_bold">SNLI</span>.
The Stanford Natural Language Inference (SNLI) dataset contains 570k human annotated sentence pairs, in which the premises are drawn from the captions of the Flickr30 corpus and hypotheses are manually annotated <cite class="ltx_cite ltx_citemacro_cite">Bowman et al. (<a href="#bib.bib5" title="" class="ltx_ref">2015</a>)</cite>.
This is the most widely used entailment dataset for NLI.</p>
</div>
<div id="A1.p4" class="ltx_para ltx_noindent">
<p id="A1.p4.1" class="ltx_p"><math id="A1.p4.1.m1.1" class="ltx_Math" alttext="\bullet" display="inline"><semantics id="A1.p4.1.m1.1a"><mo id="A1.p4.1.m1.1.1" xref="A1.p4.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="A1.p4.1.m1.1b"><ci id="A1.p4.1.m1.1.1.cmml" xref="A1.p4.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.p4.1.m1.1c">\bullet</annotation></semantics></math> <span id="A1.p4.1.1" class="ltx_text ltx_font_bold">SciTail</span>.
This is a textual entailment dataset derived from a science question answering (SciQ) dataset <cite class="ltx_cite ltx_citemacro_cite">Khot et al. (<a href="#bib.bib24" title="" class="ltx_ref">2018</a>)</cite>. The task involves assessing whether a given premise entails a given hypothesis.
In contrast to other entailment datasets mentioned previously, the hypotheses in SciTail are created from science questions while the corresponding answer candidates and premises come from relevant web sentences retrieved from a large corpus. As a result, these sentences are linguistically challenging and the lexical similarity of premise and hypothesis is often high, thus making SciTail particularly difficult.</p>
</div>
<div id="A1.p5" class="ltx_para ltx_noindent">
<p id="A1.p5.1" class="ltx_p"><math id="A1.p5.1.m1.1" class="ltx_Math" alttext="\bullet" display="inline"><semantics id="A1.p5.1.m1.1a"><mo id="A1.p5.1.m1.1.1" xref="A1.p5.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="A1.p5.1.m1.1b"><ci id="A1.p5.1.m1.1.1.cmml" xref="A1.p5.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.p5.1.m1.1c">\bullet</annotation></semantics></math> <span id="A1.p5.1.1" class="ltx_text ltx_font_bold">MedNLI</span>.
This is a textual entailment dataset in the clinical domain. It was derived from medical history of patients and annotated by doctors. The task involves assessing whether a given premise entails a given hypothesis. The hypothesis sentences in this dataset were generated by clinicians, while corresponding answer candidates and premises come from MIMIC-III v1.3 <cite class="ltx_cite ltx_citemacro_cite">Johnson et al. (<a href="#bib.bib23" title="" class="ltx_ref">2016</a>)</cite>, a database containing 2,078,705 clinical notes written by healthcare professionals. Its specialized domain nature makes MedNLI a challenging dataset.</p>
</div>
<div id="A1.p6" class="ltx_para ltx_noindent">
<p id="A1.p6.1" class="ltx_p"><math id="A1.p6.1.m1.1" class="ltx_Math" alttext="\bullet" display="inline"><semantics id="A1.p6.1.m1.1a"><mo id="A1.p6.1.m1.1.1" xref="A1.p6.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="A1.p6.1.m1.1b"><ci id="A1.p6.1.m1.1.1.cmml" xref="A1.p6.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.p6.1.m1.1c">\bullet</annotation></semantics></math> <span id="A1.p6.1.1" class="ltx_text ltx_font_bold">HANS</span>.
This is an NLI evaluation set that tests three hypotheses about invalid heuristics that NLI models are likely to learn: lexical overlap (assume that a premise entails all hypotheses constructed from words in the premise), subsequence (assume that a premise entails all of its contiguous subsequences), and constituent. HANS is a challenging dataset that aims to test how much models are vulnerable to such heuristics, and standard training often results in models failing catastrophically, even models such as BERT <cite class="ltx_cite ltx_citemacro_cite">McCoy et al. (<a href="#bib.bib31" title="" class="ltx_ref">2019</a>)</cite>.</p>
</div>
<div id="A1.p7" class="ltx_para ltx_noindent">
<p id="A1.p7.1" class="ltx_p"><math id="A1.p7.1.m1.1" class="ltx_Math" alttext="\bullet" display="inline"><semantics id="A1.p7.1.m1.1a"><mo id="A1.p7.1.m1.1.1" xref="A1.p7.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="A1.p7.1.m1.1b"><ci id="A1.p7.1.m1.1.1.cmml" xref="A1.p7.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.p7.1.m1.1c">\bullet</annotation></semantics></math> <span id="A1.p7.1.1" class="ltx_text ltx_font_bold">XNLI</span>.
This is a cross-lingual natural language inference dataset built by extending the development and test sets of the Multi-Genre Natural Language Inference Corpus <cite class="ltx_cite ltx_citemacro_cite">Williams et al. (<a href="#bib.bib41" title="" class="ltx_ref">2018</a>)</cite> to 15 languages, including low-resource languages such as Swahili. This corpus was designed to evaluate cross-language sentence understanding, where models are supposed to be trained in one language and tested in different ones. Validation and test sets are translated from English to 14 languages by professional translators, making results across different languages directly comparable <cite class="ltx_cite ltx_citemacro_cite">Artetxe and Schwenk (<a href="#bib.bib2" title="" class="ltx_ref">2019</a>)</cite>.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2104.05846" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2104.05847" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2104.05847">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2104.05847" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2104.05848" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Mar  7 00:50:07 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
