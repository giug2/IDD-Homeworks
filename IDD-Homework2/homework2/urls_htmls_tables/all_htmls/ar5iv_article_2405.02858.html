<article class="ltx_document ltx_authors_1line">
 <h1 class="ltx_title ltx_title_document">
  Language Evolution for Evading Social Media Regulation via LLM-based Multi-agent Simulation
 </h1>
 <div class="ltx_authors">
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Jinyu Cai
    <br class="ltx_break"/>
    Munan Li
   </span>
   <span class="ltx_author_notes">
    <span class="ltx_contact ltx_role_affiliation">
     <span class="ltx_text ltx_font_italic" id="id1.1.id1">
      Waseda University
     </span>
     <br class="ltx_break"/>
     bluelink@toki.waseda.jp
    </span>
    <span class="ltx_contact ltx_role_affiliation">
     <span class="ltx_text ltx_font_italic" id="id2.2.id1">
      Dalian Maritime University
     </span>
     <br class="ltx_break"/>
     limunan@dlmu.edu.cn
    </span>
   </span>
  </span>
  <span class="ltx_author_before">
  </span>
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Jialong Li
    <br class="ltx_break"/>
    Chen-Shu Wang
   </span>
   <span class="ltx_author_notes">
    Corresponding Author: Jialong Li
    <span class="ltx_contact ltx_role_affiliation">
     <span class="ltx_text ltx_font_italic" id="id3.1.id1">
      Waseda University
     </span>
     <br class="ltx_break"/>
     lijialong@fuji.waseda.jp
    </span>
    <span class="ltx_contact ltx_role_affiliation">
     <span class="ltx_text ltx_font_italic" id="id4.2.id1">
      National Taipei University of Technology
     </span>
     <br class="ltx_break"/>
     wangcs@ntut.edu.tw
    </span>
   </span>
  </span>
  <span class="ltx_author_before">
  </span>
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Mingyue Zhang
    <br class="ltx_break"/>
    Kenji Tei
   </span>
   <span class="ltx_author_notes">
    <span class="ltx_contact ltx_role_affiliation">
     <span class="ltx_text ltx_font_italic" id="id5.1.id1">
      Southwest University
     </span>
     <br class="ltx_break"/>
     myzhangswu@swu.edu.cn
    </span>
    <span class="ltx_contact ltx_role_affiliation">
     <span class="ltx_text ltx_font_italic" id="id6.2.id1">
      Tokyo Institute of Technology
     </span>
     <br class="ltx_break"/>
     tei@c.titech.ac.jp
    </span>
   </span>
  </span>
 </div>
 <div class="ltx_abstract">
  <h6 class="ltx_title ltx_title_abstract">
   Abstract
  </h6>
  <p class="ltx_p" id="id7.id1">
   Social media platforms such as Twitter, Reddit, and Sina Weibo play a crucial role in global communication but often encounter strict regulations in geopolitically sensitive regions. This situation has prompted users to ingeniously modify their way of communicating, frequently resorting to coded language in these regulated social media environments. This shift in communication is not merely a strategy to counteract regulation, but a vivid manifestation of language evolution, demonstrating how language naturally evolves under societal and technological pressures. Studying the evolution of language in regulated social media contexts is of significant importance for ensuring freedom of speech, optimizing content moderation, and advancing linguistic research.
This paper proposes a multi-agent simulation framework using Large Language Models (LLMs) to explore the evolution of user language in regulated social media environments. The framework employs LLM-driven agents: supervisory agent who enforce dialogue supervision and participant agents who evolve their language strategies while engaging in conversation, simulating the evolution of communication styles under strict regulations aimed at evading social media regulation. The study evaluates the framework’s effectiveness through a range of scenarios from abstract scenarios to real-world situations. Key findings indicate that LLMs are capable of simulating nuanced language dynamics and interactions in constrained settings, showing improvement in both evading supervision and information accuracy as evolution progresses. Furthermore, it was found that LLM agents adopt different strategies for different scenarios.
The reproduction kit can be accessed at
   <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">
    https://github.com/BlueLinkX/GA-MAS
   </span>
   .
  </p>
 </div>
 <div class="ltx_keywords">
  <h6 class="ltx_title ltx_title_keywords">
   Index Terms:
  </h6>
  Language Evolution, Multi-agent Simulation, Large Language Models, Social Media Regulation
 </div>
 <section class="ltx_section" id="S1">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    I
   </span>
   <span class="ltx_text ltx_font_smallcaps" id="S1.1.1">
    Introduction
   </span>
  </h2>
  <div class="ltx_para" id="S1.p1">
   <p class="ltx_p" id="S1.p1.1">
    In the modern digital era, social networks like X (Twitter), Reddit, and Facebook have become pivotal in shaping human interaction, primarily through their ability to facilitate vast connectivity and instantaneous information exchange.
Yet, in regions with heightened geopolitical or socio-political sensitivities, users often navigate complex user regulations. Their online expressions can lead to severe consequences, including censorship or account suspension, as documented in various news
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib1" title="">
      1
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib2" title="">
      2
     </a>
     ]
    </cite>
    .
While intended to curb misinformation and maintain social harmony, these regulations significantly constrain user expression.
In response to these regulations, users on social networks have adapted by adopting a phenomenon known as “coded language.”
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib3" title="">
      3
     </a>
     ]
    </cite>
    In linguistics, Coded Language typically refers to expressing information in a concealed or indirect manner. On social media platforms, this often manifests as the use of metaphors, slang, and creative wordplay.
   </p>
  </div>
  <div class="ltx_para" id="S1.p2">
   <p class="ltx_p" id="S1.p2.1">
    This adaptation is not merely a circumvention strategy but a vivid example of “language evolution” in a digital context. In linguistics, language evolution refers to the progression and adaptation of languages over time, shaped by societal, cultural, and technological influences.
Specifically, in social networks, this language evolution is demonstrated as users constantly adjust their communication styles to test whether they have circumvented oversight. Depending on the level of regulatory pressure and the nature of the audience, users engage in a strategic play with the platform. From indirect descriptions to the creation of new slang, users ultimately develop coded languages of varying degrees of abstraction.
   </p>
  </div>
  <div class="ltx_para" id="S1.p3">
   <p class="ltx_p" id="S1.p3.1">
    This dynamic shift in communication methods offers deep insights from a sociological perspective, reflecting how societal norms and technological advancements shape language. For platforms and users alike, understanding this evolution is crucial for developing balanced content moderation policies and navigating regulated digital environments.
For social media platforms and their users, grasping this concept is equally vital.
Platforms need this knowledge to adapt to changing user behaviors, to create balanced content moderation policies, and to identify and counteract harmful or illegal activities. For users, an awareness of how language evolves is vital in navigating the intricacies of regulated digital environments. It helps in maintaining free speech and in developing communication strategies that are both effective and meaningful in fostering enhanced interactions.
   </p>
  </div>
  <div class="ltx_para" id="S1.p4">
   <p class="ltx_p" id="S1.p4.1">
    The emergence of Large Language Models (LLMs) like ChatGPT and Bard, represents a significant leap in Artificial intelligence (AI). These LLMs have demonstrated strong capabilities in (i) understanding intricate dialogues
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib4" title="">
      4
     </a>
     ]
    </cite>
    , generating coherent texts
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib5" title="">
      5
     </a>
     ]
    </cite>
    , and aligning to human ethical and value standards
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib6" title="">
      6
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib7" title="">
      7
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib8" title="">
      8
     </a>
     ]
    </cite>
    .
These capabilities position LLMs as ideal tools to simulate human’s decision-making and language representation, providing new potential in sociology.
For instance,
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib9" title="">
      9
     </a>
     ]
    </cite>
    investigated the ability of LLMs to comprehend the implicit information in social language. The study by
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib10" title="">
      10
     </a>
     ]
    </cite>
    demonstrated the efficiency of LLMs in understanding and generating content that mimics the style of specific social network users. Furthermore, research by
    <cite class="ltx_cite ltx_citemacro_cite">
     [
     <a class="ltx_ref" href="#bib.bib11" title="">
      11
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib12" title="">
      12
     </a>
     ,
     <a class="ltx_ref" href="#bib.bib13" title="">
      13
     </a>
     ]
    </cite>
    integrated LLMs with Multi-Agent Systems to simulate micro-social networks, observing agent behaviors and strategies that reflect human interactions.
Despite the extensive application of LLMs in understanding human intension and simulating social media dynamics,
the use of LLMs in studying the specific phenomenon of language evolution under regulatory constraints has not been thoroughly explored.
As mentioned above, such simulation could not only preempt criminal activities on social media but also provide technical support to uphold freedom of speech.
   </p>
  </div>
  <div class="ltx_para" id="S1.p5">
   <p class="ltx_p" id="S1.p5.1">
    Addressing this gap, our research employs LLMs to simulate the nuanced interplay between language evolution and regulatory enforcement on social media. We introduce a simulation framework with two types of LLM-driven agents: (i) participant agents, who adapt their language to communicate concept ’B’ under restrictions, and (ii) supervisory agent, who enforce guidelines and react to these language evolutions. Our approach effectively simulates the dynamics model between both sides in language evolution, which allows us to observe the tension and adaptability inherent in language evolution in a controlled, simulated environment.
To assess the framework’s effectiveness, we designed three diverse scenarios: “Guess the Number Game”, “Illegal Pet Trading”, and “Nuclear Wastewater Discharge”. These scenarios vary from abstract concepts to situations closely resembling real-world events, thereby progressively testing the framework from theoretical to practical applications.
   </p>
  </div>
  <div class="ltx_para" id="S1.p6">
   <p class="ltx_p" id="S1.p6.1">
    The main contributions of this study are:
   </p>
   <ul class="ltx_itemize" id="S1.I1">
    <li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="S1.I1.i1.p1">
      <p class="ltx_p" id="S1.I1.i1.p1.1">
       We introduce a multi-agent simulation framework utilizing LLMs to simulate human linguistic behaviors in regulated social media environments. This framework offers a unique approach to studying language evolution within the confines of regulatory constraints.
      </p>
     </div>
    </li>
    <li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="S1.I1.i2.p1">
      <p class="ltx_p" id="S1.I1.i2.p1.1">
       We conducted an extensive evaluation of LLMs in simulating language evolution and interaction efficacy in regulated social media settings. Through experiments on three distinct scenarios, we not only captured the process of language strategy evolution but also uncovered the varied evolutionary trajectories that LLMs follow under different conditions.
      </p>
     </div>
    </li>
    <li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="S1.I1.i3.p1">
      <p class="ltx_p" id="S1.I1.i3.p1.1">
       The experiment reproduction kit, including the proposed simulation framework along with the results of our experiments, are made publicly accessible as open-source assets; The anonymized artifact can be accessed at:
       <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">
        https://github.com/BlueLinkX/GA-MAS
       </span>
       .
      </p>
     </div>
    </li>
   </ul>
  </div>
  <div class="ltx_para" id="S1.p7">
   <p class="ltx_p" id="S1.p7.1">
    The rest of this paper is organized as follows:
Section
    <a class="ltx_ref" href="#S2" title="II Background and Related Work ‣ Language Evolution for Evading Social Media Regulation via LLM-based Multi-agent Simulation">
     <span class="ltx_text ltx_ref_tag">
      II
     </span>
    </a>
    provides essential background information and explores related work.
Section
    <a class="ltx_ref" href="#S3" title="III Framework Design ‣ Language Evolution for Evading Social Media Regulation via LLM-based Multi-agent Simulation">
     <span class="ltx_text ltx_ref_tag">
      III
     </span>
    </a>
    is dedicated to presenting our proposed simulation framework.
Section
    <a class="ltx_ref" href="#S4" title="IV Evaluation ‣ Language Evolution for Evading Social Media Regulation via LLM-based Multi-agent Simulation">
     <span class="ltx_text ltx_ref_tag">
      IV
     </span>
    </a>
    details the experiment setting, presents results, and discusses a discussion.
Finally, Section
    <a class="ltx_ref" href="#S5" title="V Conclusion and Future Work ‣ Language Evolution for Evading Social Media Regulation via LLM-based Multi-agent Simulation">
     <span class="ltx_text ltx_ref_tag">
      V
     </span>
    </a>
    concludes the paper and offers an outlook on potential future work.
   </p>
  </div>
 </section>
 <section class="ltx_section" id="S2">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    II
   </span>
   <span class="ltx_text ltx_font_smallcaps" id="S2.1.1">
    Background and Related Work
   </span>
  </h2>
  <div class="ltx_para" id="S2.p1">
   <p class="ltx_p" id="S2.p1.1">
    This section offers an extensive background and overview of related work in areas relevant to this study, starting with foundational information on LLMs, then exploring studies in slang detection and identification as they relate to language evolution, and concluding with a discussion on recent research applying LLMs to evolutionary game theory and social simulations.
   </p>
  </div>
  <section class="ltx_subsection" id="S2.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     <span class="ltx_text" id="S2.SS1.4.1.1">
      II-A
     </span>
    </span>
    <span class="ltx_text ltx_font_italic" id="S2.SS1.5.2">
     Large Language Models
    </span>
   </h3>
   <div class="ltx_para" id="S2.SS1.p1">
    <p class="ltx_p" id="S2.SS1.p1.1">
     Large Language Models like the GPT series
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib14" title="">
       14
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib15" title="">
       15
      </a>
      ]
     </cite>
     , LLaMA series
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib16" title="">
       16
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib17" title="">
       17
      </a>
      ]
     </cite>
     , PaLM series
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib18" title="">
       18
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib19" title="">
       19
      </a>
      ]
     </cite>
     , GLM
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib20" title="">
       20
      </a>
      ]
     </cite>
     and Bard
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib21" title="">
       21
      </a>
      ]
     </cite>
     represent a significant advancement in the field of natural language processing. Fundamentally, these models are based on the Transformer
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib22" title="">
       22
      </a>
      ]
     </cite>
     architecture, a type of neural network that excels in processing sequential data through self-attention mechanisms. This architecture enables LLMs to understand and predict linguistic patterns effectively. They are trained on extensive text datasets, allowing them to grasp a wide range of linguistic nuances from syntax to contextual meaning. These models exhibit remarkable zero-shot learning abilities, enabling them to perform tasks they were not explicitly trained for, like understanding and generating content in new contexts or languages
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib23" title="">
       23
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib24" title="">
       24
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib25" title="">
       25
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib4" title="">
       4
      </a>
      ,
      <a class="ltx_ref" href="#bib.bib5" title="">
       5
      </a>
      ]
     </cite>
     .
A critical aspect of their training involves Reinforcement Learning from Human Feedback
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib26" title="">
       26
      </a>
      ]
     </cite>
     (RLHF), where human reviewers guide the model to produce more accurate, contextually relevant, and ethically aligned responses. This method not only enhances the model’s language generation capabilities but also aligns its outputs with human values and ethical standards, making them more suitable for diverse, real-world applications.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S2.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     <span class="ltx_text" id="S2.SS2.4.1.1">
      II-B
     </span>
    </span>
    <span class="ltx_text ltx_font_italic" id="S2.SS2.5.2">
     Slang Detection and Identification
    </span>
   </h3>
   <div class="ltx_para" id="S2.SS2.p1">
    <p class="ltx_p" id="S2.SS2.p1.1">
     In the field of Natural Language Processing (NLP), the evolution of language has always been a subject of significant interest. Existing studies have primarily focused on utilizing various machine learning techniques to recognize informal expressions within text
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib27" title="">
       27
      </a>
      ]
     </cite>
     . These methods often include rule-based systems, statistical models, and early machine learning technologies.
For instance,
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib28" title="">
       28
      </a>
      ]
     </cite>
     has employed predefined slang dictionaries and heuristic rules to identify and categorize informal language, proving effective on specific datasets but generally lacking the flexibility to adapt to emerging expressions and changing contexts.
On the other hand, explorations have been made into using statistical models, such as Naive Bayes classifiers and Support Vector Machines (SVMs)
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib29" title="">
       29
      </a>
      ]
     </cite>
     , for the automatic detection of slang in text. These approaches rely on extensive annotated data but still face limitations when dealing with newly emerged slang or evolving forms of language.
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib30" title="">
       30
      </a>
      ]
     </cite>
     views the generation of slang as a problem of selecting vocabulary to represent new concepts or referents, categorizing them accordingly. Subsequently, it predicts slang through the use of various cognitive categorization models. The study finds that these models greatly surpass random guessing in their ability to predict slang word choices.
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib31" title="">
       31
      </a>
      ]
     </cite>
     proposed a Semantically Informed Slang Interpretation (SSI) framework, applying cognitive theory perspectives to the interpretation and prediction of slang. This approach not only considers contextual information but also includes the understanding of semantic changes and cognitive processes in the generation of slang.
It is noteworthy that these traditional research methods have mainly focused on detecting or predicting existing slang and keywords, rather than generating slang expressions. This stands in stark contrast to the research focus of this paper.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S2.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     <span class="ltx_text" id="S2.SS3.4.1.1">
      II-C
     </span>
    </span>
    <span class="ltx_text ltx_font_italic" id="S2.SS3.5.2">
     Evolutionary Game and Social Simulation with LLMs
    </span>
   </h3>
   <div class="ltx_para" id="S2.SS3.p1">
    <p class="ltx_p" id="S2.SS3.p1.1">
     Merging evolutionary game theory with LLMs has unlocked innovative pathways for simulating complex game dynamics, extending beyond simple dialogue generation to the development and progression of game strategies. LLMs are employed to engage and refine strategic play within game-theoretical frameworks, as demonstrated by
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib32" title="">
       32
      </a>
      ]
     </cite>
     , which delves into the application of LLMs in negotiation-based games. This study underscores the ability of LLMs to advance their negotiation skills through continuous self-play and feedback loops with AI.
LLMs also show proficiency in social deduction games such as Werewolf, as explored by
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib33" title="">
       33
      </a>
      ]
     </cite>
     . In this context, a specialized framework leverages historical communication patterns to enhance LLM performance, exemplifying how LLMs can evolve intricate game strategies autonomously. Building on this,
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib34" title="">
       34
      </a>
      ]
     </cite>
     combines reinforcement learning with LLMs, utilizing LLMs to output action spaces and employing reinforcement learning models for final decision-making. This enables the agents to maintain competitiveness while outputting reasonable actions, even outperforming human adversaries in games like Werewolf.
    </p>
   </div>
   <div class="ltx_para" id="S2.SS3.p2">
    <p class="ltx_p" id="S2.SS3.p2.1">
     This growing trend of employing LLMs in diverse simulation scenarios extends beyond game theory into broader aspects of social interactions and historical analysis. LLMs have proven to be versatile tools in simulating social dynamics and historical events, offering insights into complex human behaviors and societal patterns.
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib12" title="">
       12
      </a>
      ]
     </cite>
     introduces a Wild West-inspired environment inhabited by LLM agents that display a wide array of behaviors without relying on external real-world data. Simultaneously, S3
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib13" title="">
       13
      </a>
      ]
     </cite>
     mirrors user interactions within social networks, crafting an authentic simulation space through the incorporation of user demographic prediction. The influence of LLM-driven social robots on digital communities is thoroughly examined in
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib35" title="">
       35
      </a>
      ]
     </cite>
     , which identifies distinct macro-level behavioral trends.
Furthermore,
     <cite class="ltx_cite ltx_citemacro_cite">
      [
      <a class="ltx_ref" href="#bib.bib11" title="">
       11
      </a>
      ]
     </cite>
     employs LLM-based multi-agent frameworks to recreate historic military confrontations, offering a window into the decision-making processes and strategic maneuvers that have directed significant historical conflicts. This avenue of research accentuates the utility of LLMs in computational historiography, providing a deeper comprehension of historical events and their relevance to contemporary and future societal trajectories.
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S3">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    III
   </span>
   <span class="ltx_text ltx_font_smallcaps" id="S3.1.1">
    Framework Design
   </span>
  </h2>
  <figure class="ltx_figure" id="S3.F1">
   <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="183" id="S3.F1.g1" src="/html/2405.02858/assets/x1.png" width="368"/>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     Figure 1:
    </span>
    Overview of Language Evolution Simulation System. The system comprises two main types of agents: the Participant and the Supervisor. The Participant agent uses a Planning Module to create a communication plan based on background information, regulations, and guidance. This plan is then executed in the Dialogue Module, where the LLM crafts dialogue content to discreetly convey specific information while evading detection by the Supervisor. The Memory Module retains dialogue history and violation records, providing a reference for the LLM to maintain dialogue consistency and learn from past mistakes. The Reflection Module, triggered at the start and end of dialogue cycles, analyzes the dialogue and violation logs to formulate new regulations or guidance for improving future communications.
The Supervisor evaluates dialogues for compliance with set rules. This system dynamically refines its communication approach through continuous feedback and self-improvement mechanisms. The examples shown utilize a Guessing Numbers Scenario.
   </figcaption>
  </figure>
  <section class="ltx_subsection" id="S3.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     <span class="ltx_text" id="S3.SS1.4.1.1">
      III-A
     </span>
    </span>
    <span class="ltx_text ltx_font_italic" id="S3.SS1.5.2">
     Overview
    </span>
   </h3>
   <div class="ltx_para" id="S3.SS1.p1">
    <p class="ltx_p" id="S3.SS1.p1.1">
     In this section, we offer a detailed overview of our system, as depicted in Figure
     <a class="ltx_ref" href="#S3.F1" title="Figure 1 ‣ III Framework Design ‣ Language Evolution for Evading Social Media Regulation via LLM-based Multi-agent Simulation">
      <span class="ltx_text ltx_ref_tag">
       1
      </span>
     </a>
     . This figure provides a visual representation of our framework, highlighting its key components and their interrelationships. Our system is primarily composed of two types of agents: the Supervisor, tasked with enforcing established guidelines, and the Participant, whose goal is to convey specific, human-defined information discreetly. Participants must dynamically refine their communication approaches, drawing from past dialogues, to transmit information effectively while remaining undetected.
In the entire system, the actions of both participants and the supervisor are driven by the LLM. Initially, we establish the foundational information for each agent, including role setting, background knowledge, and primary tasks. Subsequently, the participant agents engage in dialogues with each other. After each dialogue turn, the supervisory agent reviews the conversation to determine if any pre-set rules have been violated. In cases of rule violation, the supervisor interrupts the dialogue, providing feedback about the infringing text and the rationale behind it. Throughout this process, the dialogues between participants, along with the supervisory feedback on violations, are recorded separately in the “Dialogue History” and “Violation Log.”
    </p>
   </div>
   <div class="ltx_para" id="S3.SS1.p2">
    <p class="ltx_p" id="S3.SS1.p2.1">
     Before new dialogues, participant agents use the Reflection Module to develop or refine “Regulations” from the Violation Log, guiding their dialogue creation. Successful dialogues without detection proceed to an interview phase for perspective assessment. The Reflection Module then reevaluates these insights, generating or enhancing “Guidance” for future dialogues. The Planning Module activates for more direct dialogue content guidance whenever Regulations or Guidance are updated.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S3.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     <span class="ltx_text" id="S3.SS2.4.1.1">
      III-B
     </span>
    </span>
    <span class="ltx_text ltx_font_italic" id="S3.SS2.5.2">
     Participant Agents
    </span>
   </h3>
   <div class="ltx_para" id="S3.SS2.p1">
    <p class="ltx_p" id="S3.SS2.p1.1">
     Participant agents in our system are composed of several modules, including Memory, Dialogue, Reflection, and Summary, all powered by LLMs. To increase the system’s flexibility and minimize redundancy, we’ve structured the prompts for each module around seven primary elements: “Background Information,” “Dialogue History,” “Violation Log,” “Regulations,” “Guidance,” “Plan,” and “Instructions.” “Background Information” delivers essential data and objectives pertinent to the experimental setup. The Memory module manages “Dialogue History” and “Violation Log,” which respectively track participant dialogues and instances of detection by the supervisor. Overcoming the challenge of effectively communicating regulated topics under supervision tests the linguistic prowess of LLMs. To address this, we’ve integrated “Regulations,” “Guidance,” and “Plan” as crucial components, formulated by the Reflection and Summary modules, to assist agents in stealthily disseminating information. “Instructions” set specific tasks for the LLM within each module.
    </p>
   </div>
   <section class="ltx_subsubsection" id="S3.SS2.SSS1">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      <span class="ltx_text" id="S3.SS2.SSS1.4.1.1">
       III-B
      </span>
      1
     </span>
     Dialogue Module
    </h4>
    <div class="ltx_para" id="S3.SS2.SSS1.p1">
     <p class="ltx_p" id="S3.SS2.SSS1.p1.1">
      This module generates dialogue content based on short-term dialogue records. Extracting historical dialogue information from the Memory module, it inputs this into the LLM to understand and construct sentences that evade supervision while effectively transmitting information. In the Dialogue module’s prompt, “Background Information” provides necessary background, while “Plan” guide the achievement of objectives. “Instructions” offer LLM-specific execution directives.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S3.SS2.SSS2">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      <span class="ltx_text" id="S3.SS2.SSS2.4.1.1">
       III-B
      </span>
      2
     </span>
     Memory Module
    </h4>
    <div class="ltx_para" id="S3.SS2.SSS2.p1">
     <p class="ltx_p" id="S3.SS2.SSS2.p1.1">
      The Memory module stores all dialogue history and records detected by the supervisor, Specifically, it comprises three parts: background Information, dialogue history, and violation records. The background information includes role settings, experimental background knowledge, and global objectives. “Dialogue History” and “Violation Log” save dialogue records and past detections by the Supervisor, respectively. “Background information” and “Dialogue History” serves as short-term
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib36" title="">
        36
       </a>
       ]
      </cite>
      memory, containing only the current round’s dialogue. “Violation Log,” as long-term memory, records violations from each evolutionary round. When dialogues are detected by the Supervisor, relevant feedback is added to the “Violation Log,” triggering a new evolutionary process.
     </p>
    </div>
    <div class="ltx_para" id="S3.SS2.SSS2.p2">
     <p class="ltx_p" id="S3.SS2.SSS2.p2.1">
      Excessive memory information can potentially distract the LLM and lead to a decline in performance. Hence, the “Dialogue History” and “Violation Log” in the memory module are regularly maintained. This involves inputting earlier memories and employing the LLM to distill crucial information from these records, effectively compressing and consolidating them. This approach not only preserves essential historical data but also optimizes the LLM’s performance, striking a balance between comprehensive memory retention and efficient processing.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S3.SS2.SSS3">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      <span class="ltx_text" id="S3.SS2.SSS3.4.1.1">
       III-B
      </span>
      3
     </span>
     Reflection Module
    </h4>
    <div class="ltx_para" id="S3.SS2.SSS3.p1">
     <p class="ltx_p" id="S3.SS2.SSS3.p1.1">
      The Reflection Module is activated at the beginning and end of each dialogue evolution cycle, with its core purpose being the generation of improved strategies based on historical records. At the start of an evolution cycle, the module utilizes the “Violation Log” as its input to analyze past failures and, based on these insights, formulates “Regulations” aimed at effectively circumventing supervision in future dialogues. At the cycle’s end, the Reflection Module is reactivated, turning its focus to the “Dialogue History”. This step is crucial for reviewing and assessing the dialogue content to verify the successful completion of the primary task of information conveyance. If the module identifies deficiencies in information delivery or objectives not met, it then proposes “Guidance” for subsequent dialogues, thereby enhancing the agent’s capacity for information transmission. This design establishes the Reflection Module as a key self-evaluation and strategy adjustment mechanism within the system, ensuring continuous improvement and adaptability of the dialogue system in a dynamically changing regulatory environment.
     </p>
    </div>
    <div class="ltx_para" id="S3.SS2.SSS3.p2">
     <p class="ltx_p" id="S3.SS2.SSS3.p2.1">
      To fulfill these requirements, the LLM must possess a high degree of reasoning ability, capable of inferring the supervisor’s criteria from failure records and identifying communication deficiencies from dialogue history, thereby formulating appropriate strategies and improvement suggestions. To enhance the LLM’s reasoning capabilities, the design of the prompt incorporates the effective and cost-efficient Chain of Thought
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib37" title="">
        37
       </a>
       ]
      </cite>
      (COT) method as the guiding principle for the reflection and planning modules. This approach guides the LLM in conducting criterion analysis and, in combination with the main task, generating “Regulations” and “Guidance”.
     </p>
    </div>
    <div class="ltx_para" id="S3.SS2.SSS3.p3">
     <p class="ltx_p" id="S3.SS2.SSS3.p3.1">
      Specifically, within the Reflection Module, the prompt includes “Background Information,” “Dialogue History” or “Violation Log,” “Old Guidance” or ”Old Regulations,” and “Instructions.” The “Instructions” first prompt the LLM to engage in preliminary thinking, for instance: “Please infer what kind of guidelines the Supervisor is following from the Violation Log.” This is followed by a conclusion question: “Based on this information, update existing regulations to better avoid supervision.” The content returned by the LLM will serve as the new regulation for the next round of dialogue.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S3.SS2.SSS4">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      <span class="ltx_text" id="S3.SS2.SSS4.4.1.1">
       III-B
      </span>
      4
     </span>
     Planning Module
    </h4>
    <div class="ltx_para" id="S3.SS2.SSS4.p1">
     <p class="ltx_p" id="S3.SS2.SSS4.p1.1">
      The facet of “Regulations” is centered on devising strategies that sidestep supervision, whereas “Guidance” is all about the effective relay of information. Although both are pivotal in managing dialogues, they might clash in certain supervised scenarios, thereby impacting the language’s overall proficiency and efficiency
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib38" title="">
        38
       </a>
       ]
      </cite>
      . In light of this, integrating the Planning Module becomes indispensable.
     </p>
    </div>
    <div class="ltx_para" id="S3.SS2.SSS4.p2">
     <p class="ltx_p" id="S3.SS2.SSS4.p2.1">
      Within the Planning Module, the prompt includes “Background Information,” “Regulations,” “Guidance,” and “Instructions”. In the “Instructions,” we mandate the LLM to use “Regulations” as a baseline. Building upon this foundation, it is guided by the “Guidance” to formulate a tangible and actionable “Plan.” This approach ensures the delivery of clear and effective strategies for future dialogues.
     </p>
    </div>
   </section>
  </section>
  <section class="ltx_subsection" id="S3.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     <span class="ltx_text" id="S3.SS3.4.1.1">
      III-C
     </span>
    </span>
    <span class="ltx_text ltx_font_italic" id="S3.SS3.5.2">
     Supervisory Agent
    </span>
   </h3>
   <div class="ltx_para" id="S3.SS3.p1">
    <p class="ltx_p" id="S3.SS3.p1.1">
     The role of the Supervisor is designed as an abstract concept, primarily to simulate social network supervision. This design reflects an important observation: in social networks, content supervision often focuses on direct judgment of specific information, rarely influenced by extensive or lengthy contextual information. Thus, unlike participants with more complex background information, the Supervisor’s function and role are simplified here to highlight its behavior characteristics in actual social network supervision. The Supervisor’s task mainly focuses on assessing whether content complies with certain standards or rules, a relatively straightforward and well-defined process.
    </p>
   </div>
   <div class="ltx_para" id="S3.SS3.p2">
    <p class="ltx_p" id="S3.SS3.p2.1">
     To mimic the existing review mechanisms of platforms, which typically combine keyword filters with “human” oversight, the Supervisor initially employs keyword filtering for a preliminary review of the dialogue content. Content that passes this initial screening is then subjected to further evaluation by the LLM. The prompt for the Supervisor includes just two components: “Dialogue History” and “Instructions.” “Dialogue History“ comprises the content of the dialogue exchanged between participant agents in that particular round, and “Instructions“ outline the criteria and guidelines that the supervisory agent must adhere to when conducting dialogue monitoring.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S3.SS4">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     <span class="ltx_text" id="S3.SS4.4.1.1">
      III-D
     </span>
    </span>
    <span class="ltx_text ltx_font_italic" id="S3.SS4.5.2">
     Similarities and Differences between Our Framework and Evolutionary Computing
    </span>
   </h3>
   <div class="ltx_para" id="S3.SS4.p1">
    <p class="ltx_p" id="S3.SS4.p1.1">
     It should be noted that the simulation framework proposed in this paper is similar to evolutionary computing in some aspects, but there are also significant differences.
    </p>
   </div>
   <div class="ltx_para" id="S3.SS4.p2">
    <p class="ltx_p" id="S3.SS4.p2.1">
     The similarities include:
(i) In evolutionary computing, individuals need to adapt to environmental pressures for survival and reproduction. Similarly, participants in this framework need to adapt to supervisory pressures and adjust their strategies for effective information transmission;
(ii) The Reflection and Summary modules generate a “new generation” by analyzing past dialogues and violation records (i.e., records of low-fitness individuals), similar to the repeated iteration process in evolutionary computing;
(iii) Since the generation of LLMs inherently involves randomness, the process of using LLMs to generate the next generation includes a de facto introduction of random mutations;
(iv) In the Reflection and Memory modules, we prioritize past records, akin to the “selection” process, where individuals with higher fitness have greater weight in the generation of the new generation.
    </p>
   </div>
   <div class="ltx_para" id="S3.SS4.p3">
    <p class="ltx_p" id="S3.SS4.p3.1">
     The main differences stem from the particularities of “language expression”, making it infeasible to directly apply traditional evolutionary computing algorithms (such as genetic algorithms and genetic programming).
They are: (i) The generation strategy of language text is difficult to encode and to perform operations of natural selection, genetic mutation, and crossover;
(ii) Evolutionary computing often aims at finding the optimal solution for a specific problem environment, however, in the problem setting of this paper, it is difficult to define an explicit fitness function to evaluate what strategy is “optimal”.
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S4">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    IV
   </span>
   <span class="ltx_text ltx_font_smallcaps" id="S4.1.1">
    Evaluation
   </span>
  </h2>
  <figure class="ltx_figure" id="S4.F2">
   <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="90" id="S4.F2.g1" src="/html/2405.02858/assets/x2.png" width="424"/>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     Figure 2:
    </span>
    Scenario 1: Evolution of dialogue turns and accuracy metrics for GPT-3.5 and GPT-4.“Turn count” in (a, b) refers to the number of turns in a conversation where each agent sends a message once per turn and the participant Agent successfully exchanges information without being detected by the supervising Agent (higher is better).“Accuracy” in (c,d) refer to the degree of precision between the guessed value and the true value.
   </figcaption>
  </figure>
  <figure class="ltx_figure" id="S4.F3">
   <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="91" id="S4.F3.g1" src="/html/2405.02858/assets/x3.png" width="424"/>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     Figure 3:
    </span>
    Scenario 2: Pet trading dialogue dynamics and success rate comparison for GPT-3.5 and GPT-4. The “success count“ in (c,d) refers to the number of instances where the information obtained during the interview matches the original information provided to the LLM agent.
   </figcaption>
  </figure>
  <figure class="ltx_figure" id="S4.F4">
   <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="101" id="S4.F4.g1" src="/html/2405.02858/assets/x4.png" width="424"/>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     Figure 4:
    </span>
    Scenario 3: Trends in forum discussion engagement on ALPS-Treated water issue. “Dialogue attempt count” in (a,b) refer to the number of rounds the agents attempted to converse(lower is better).
   </figcaption>
  </figure>
  <figure class="ltx_figure" id="S4.F5">
   <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="341" id="S4.F5.g1" src="/html/2405.02858/assets/x5.png" width="415"/>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     Figure 5:
    </span>
    Sample dialogue in Scenario 1 (via GPT-3.5)
   </figcaption>
  </figure>
  <figure class="ltx_figure" id="S4.F6">
   <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="327" id="S4.F6.g1" src="/html/2405.02858/assets/x6.png" width="415"/>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     Figure 6:
    </span>
    Sample dialogue in Scenario 2 (via GPT-3.5)
   </figcaption>
  </figure>
  <figure class="ltx_figure" id="S4.F7">
   <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="243" id="S4.F7.g1" src="/html/2405.02858/assets/x7.png" width="415"/>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     Figure 7:
    </span>
    Sample dialogue in Scenario 3 (via GPT-4)
   </figcaption>
  </figure>
  <div class="ltx_para" id="S4.p1">
   <p class="ltx_p" id="S4.p1.1">
    Our evaluation strategy is designed to rigorously assess the extent and efficacy of language evolution facilitated by LLMs
within a framework of regulatory oversight. This assessment aims to explore two fundamental research questions:
   </p>
   <ul class="ltx_itemize" id="S4.I1">
    <li class="ltx_item" id="S4.I1.i1" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="S4.I1.i1.p1">
      <p class="ltx_p" id="S4.I1.i1.p1.1">
       RQ1: Can LLM agents effectively evolve their language to circumvent regulatory oversight?
      </p>
     </div>
    </li>
    <li class="ltx_item" id="S4.I1.i2" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="S4.I1.i2.p1">
      <p class="ltx_p" id="S4.I1.i2.p1.1">
       RQ2: While avoiding oversight, how effectively and accurately can LLM agents convey information?
      </p>
     </div>
    </li>
    <li class="ltx_item" id="S4.I1.i3" style="list-style-type:none;">
     <span class="ltx_tag ltx_tag_item">
      •
     </span>
     <div class="ltx_para" id="S4.I1.i3.p1">
      <p class="ltx_p" id="S4.I1.i3.p1.1">
       RQ3: What are the patterns and tendencies in language evolution, i.e., what kind of strategies do LLMs use to avoid oversight and convey information? What insights can we gain from these strategies?
      </p>
     </div>
    </li>
   </ul>
  </div>
  <section class="ltx_subsection" id="S4.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     <span class="ltx_text" id="S4.SS1.4.1.1">
      IV-A
     </span>
    </span>
    <span class="ltx_text ltx_font_italic" id="S4.SS1.5.2">
     Experiment Setting
    </span>
   </h3>
   <div class="ltx_para" id="S4.SS1.p1">
    <p class="ltx_p" id="S4.SS1.p1.1">
     In the evaluation, we will employ GPT-3.5 and GPT-4 as the driving LLMs for participant agents. In order to conduct a horizontal analysis of participants’ agents driven by different LLM, we will standardize the supervisory agent to be consistently driven by GPT-3.5.
Our experimental design encompasses scenarios ranging from abstract theoretical constructs to simulations that mirror complex real-world situations. The primary aim is to meticulously evaluate the versatility of LLMs across diverse linguistic landscapes and their practical applicability within real-world regulatory constraints. Meanwhile, this progressive approach ensures an exhaustive analysis of LLMs’ capabilities and limitations in varied contextual settings.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S4.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     <span class="ltx_text" id="S4.SS2.4.1.1">
      IV-B
     </span>
    </span>
    <span class="ltx_text ltx_font_italic" id="S4.SS2.5.2">
     Scenario 1: Guessing Numbers
    </span>
   </h3>
   <section class="ltx_subsubsection" id="S4.SS2.SSS1">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      <span class="ltx_text" id="S4.SS2.SSS1.4.1.1">
       IV-B
      </span>
      1
     </span>
     Case Explanation
    </h4>
    <div class="ltx_para" id="S4.SS2.SSS1.p1">
     <p class="ltx_p" id="S4.SS2.SSS1.p1.1">
      Our first scenario considers a relatively simple and abstract guess-the-number context
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib39" title="">
        39
       </a>
       ,
       <a class="ltx_ref" href="#bib.bib40" title="">
        40
       </a>
       ]
      </cite>
      . In this setting, each participant is assigned a value within the range of 1-100, and they must convey their value to another participant through number theory dialogue without directly mentioning the number. At the same time, they need to extract information from the conversation to infer the other’s value.
Regulators follow a guideline of “prohibiting all content related to numbers” in dialogues. The “Guessing Numbers” scenario is specifically designed to observe and analyze participants’ linguistic adaptability and strategic evolution in a theoretical and abstract context, providing a clearer, more controlled, and more quantifiable experimental environment compared to the complex scenarios based on real events
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S4.SS2.SSS2">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      <span class="ltx_text" id="S4.SS2.SSS2.4.1.1">
       IV-B
      </span>
      2
     </span>
     Results and Discussion
    </h4>
    <div class="ltx_para" id="S4.SS2.SSS2.p1">
     <p class="ltx_p" id="S4.SS2.SSS2.p1.1">
      Fig.
      <a class="ltx_ref" href="#S4.F2" title="Figure 2 ‣ IV Evaluation ‣ Language Evolution for Evading Social Media Regulation via LLM-based Multi-agent Simulation">
       <span class="ltx_text ltx_ref_tag">
        2
       </span>
      </a>
      presents the results of the guess-the-number scenario experiment, where we utilized both GPT-3.5 and GPT-4 for testing. We set up four turns of dialogue, with an interview conducted with all participant agents in the fifth turn. From Fig.
      <a class="ltx_ref" href="#S4.F2" title="Figure 2 ‣ IV Evaluation ‣ Language Evolution for Evading Social Media Regulation via LLM-based Multi-agent Simulation">
       <span class="ltx_text ltx_ref_tag">
        2
       </span>
      </a>
      (a) and (b), it is observable that with an increase in the number of dialogue rounds, the duration of sustained conversations also showed an upward trend. This demonstrates that participant agents can effectively circumvent supervision by iteratively updating regulations. Additionally, it’s notable that compared to the slow and unstable progression with GPT-3.5, GPT-4 achieved regulatory evasion in fewer rounds, specifically, as shown in the smoothed data, GPT-4 reached the round count of GPT-3.5’s 17th round by its 7th round and maintained this progression with greater stability thereafter.
Fig.
      <a class="ltx_ref" href="#S4.F2" title="Figure 2 ‣ IV Evaluation ‣ Language Evolution for Evading Social Media Regulation via LLM-based Multi-agent Simulation">
       <span class="ltx_text ltx_ref_tag">
        2
       </span>
      </a>
      (c) and (d) focuses on the trend of numerical precision guessed by agents. For rounds without successful dialogue, we manually set the precision to zero. In this experiment, Agent A’s value was set to 58, while Agent B’s was set to 32. The overall trend, akin to Fig.
      <a class="ltx_ref" href="#S4.F2" title="Figure 2 ‣ IV Evaluation ‣ Language Evolution for Evading Social Media Regulation via LLM-based Multi-agent Simulation">
       <span class="ltx_text ltx_ref_tag">
        2
       </span>
      </a>
      (a) and (b), was ascending—corroborating that the Summary Module can effectively reflect and iteratively optimize its guidance for more accurate expression after each successful dialogue. This also confirmed that the precision of GPT-4 is markedly superior to that of GPT-3.5. Moreover, we noticed that the accuracy with which Agent A’s value was guessed was consistently higher than that of Agent B, especially becoming more pronounced after the 25th round.
We posit that this is due to the value 58 possessing more distinctive features within the 0-100 range—being closer to the midpoint—thus presenting a lower level of expression difficulty and easier guessability. For the intervals where this phenomenon manifested, we noted that this disparity was particularly pronounced in the early stages with both GPT-3.5 and GPT-4. We surmise that this is attributable to inadequate guidance performance, where the former stems from weaker inherent LLM capabilities and the latter from insufficient rounds to complete the iterative optimization of the guidance.
     </p>
    </div>
    <div class="ltx_para" id="S4.SS2.SSS2.p2">
     <p class="ltx_p" id="S4.SS2.SSS2.p2.1">
      As Fig.
      <a class="ltx_ref" href="#S4.F5" title="Figure 5 ‣ IV Evaluation ‣ Language Evolution for Evading Social Media Regulation via LLM-based Multi-agent Simulation">
       <span class="ltx_text ltx_ref_tag">
        5
       </span>
      </a>
      illustrates, a snippet from the scenario reveals Amy’s adept use of metaphorical language, such as “seesaw,” to convey her value. By describing the “seesaw perfectly poised in mid-air,” she subtly intimates that her value hovers around the midpoint, like 50. This strategy not only circumvents the direct mention of numbers, which is under regulatory scrutiny, but also provides sufficient inferential fodder for the counterpart agent to make an accurate deduction. Bob, on the other hand, employs terms like “precipice of a mountain” and “gazing out” to suggest his value is not median, as these phrases evoke imagery of an imbalanced position.
In this exchange, we witness the varying degrees of precision in languages corresponding to the complexity of the information encrypted. The less characteristic-rich the information, the more challenging it becomes for the receiving party to decode. Bob’s phrasing, while successfully obscuring the specific numerical value, also complicates the decoding process for the receiver, given the less intuitive numeric correlation of phrases like “precipice of a mountain” compared to “seesaw perfectly poised in mid-air”. In such cases, the accuracy of value transmission may diminish, necessitating a more robust contextual understanding from the counterpart for accurate decoding.
     </p>
    </div>
   </section>
  </section>
  <section class="ltx_subsection" id="S4.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     <span class="ltx_text" id="S4.SS3.4.1.1">
      IV-C
     </span>
    </span>
    <span class="ltx_text ltx_font_italic" id="S4.SS3.5.2">
     Scenario 2: Pet Trading
    </span>
   </h3>
   <section class="ltx_subsubsection" id="S4.SS3.SSS1">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      <span class="ltx_text" id="S4.SS3.SSS1.4.1.1">
       IV-C
      </span>
      1
     </span>
     Case Explanation
    </h4>
    <div class="ltx_para" id="S4.SS3.SSS1.p1">
     <p class="ltx_p" id="S4.SS3.SSS1.p1.1">
      Initially, our intention was to create a scenario simulating drug trafficking
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib41" title="">
        41
       </a>
       ,
       <a class="ltx_ref" href="#bib.bib42" title="">
        42
       </a>
       ,
       <a class="ltx_ref" href="#bib.bib43" title="">
        43
       </a>
       ]
      </cite>
      to explore language evolution strategies under extreme regulatory conditions. However, given the ethical limitations embedded within GPT’s usage policies, we pivoted to a more neutral yet still prohibited context of illicit pet trading. This adjustment allowed us to maintain the integrity of the experiment while adhering to the ethical constraints of the LLM.
The purpose of simulating this scenario is to better detect potential illegal conversations related to illicit trading on social networking platforms, thereby aiding in crime prevention efforts.
     </p>
    </div>
    <div class="ltx_para" id="S4.SS3.SSS1.p2">
     <p class="ltx_p" id="S4.SS3.SSS1.p2.1">
      In this scenario, we simulate an illegal pet trade conducted via social media. Participants assume the roles of buyers and sellers, with the buyer needing to communicate their purchase request for a randomly selected pet from parrots, lizards, or cats. The seller, in turn, must provide specific transaction details, varying according to the type of pet being purchased. These details include three elements: time, location, and personnel involved in the transaction. The Supervisor’s task is to prevent any dialogue related to pet trading. Cross-verification of the information understood by both parties will be conducted through interviews, to assess the success rate of information transmission. The focus of this experiment is to observe the participants’ language adaptability and evolution at a larger granularity of information, as well as the Supervisor’s ability to accurately identify relevant conversations.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S4.SS3.SSS2">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      <span class="ltx_text" id="S4.SS3.SSS2.4.1.1">
       IV-C
      </span>
      2
     </span>
     Results and Discussion
    </h4>
    <div class="ltx_para" id="S4.SS3.SSS2.p1">
     <p class="ltx_p" id="S4.SS3.SSS2.p1.1">
      The experimental results of the “Pet Trading” scenario, as depicted in Fig.
      <a class="ltx_ref" href="#S4.F3" title="Figure 3 ‣ IV Evaluation ‣ Language Evolution for Evading Social Media Regulation via LLM-based Multi-agent Simulation">
       <span class="ltx_text ltx_ref_tag">
        3
       </span>
      </a>
      , revealed distinct characteristics compared to the “Guessing Numbers”. In delineating animals or transactional specifics, agents had a broader spectrum of real-life analogies at their disposal, enriching their indirect description toolkit and thereby reducing regulatory pressure.
The data indicated an upward trend in the ability to circumvent supervision with increasing dialogue rounds, regardless of whether GPT-3.5 or GPT-4 was utilized. For GPT-3.5, a stable capability to avoid supervision started from around 25 rounds, whereas for GPT-4, this phenomenon occurred as early as after about 10 rounds and showed overall more stable performance.
Regarding information accuracy, we monitored the quantity of four types of information successfully communicated at the end of each dialogue round. The results affirmed the efficacy of the language evolution system in augmenting the precision of information dissemination. Moreover, similar to Fig.
      <a class="ltx_ref" href="#S4.F3" title="Figure 3 ‣ IV Evaluation ‣ Language Evolution for Evading Social Media Regulation via LLM-based Multi-agent Simulation">
       <span class="ltx_text ltx_ref_tag">
        3
       </span>
      </a>
      (a) and (b), GPT-4 demonstrated performance around the 10th round that was comparable to the performance of GPT-3.5 around the 25th round.
However, it’s noteworthy that since the supervisory agent primarily targeted content related to pet trading, sellers encountered lower risk in transmitting transaction-related details (such as time, place, and persons involved) as they inherently posed less risk of non-compliance. Consequently, the outcome distribution often fell into one of three categories: zero (neither party successfully communicated the information), three (only the seller conveyed the information), or four (both parties successfully conveyed the information). This pattern aligns with real-world regulatory logic, where crucial information is often the first to be encrypted in regulated environments.
     </p>
    </div>
    <div class="ltx_para" id="S4.SS3.SSS2.p2">
     <p class="ltx_p" id="S4.SS3.SSS2.p2.1">
      Fig.
      <a class="ltx_ref" href="#S4.F6" title="Figure 6 ‣ IV Evaluation ‣ Language Evolution for Evading Social Media Regulation via LLM-based Multi-agent Simulation">
       <span class="ltx_text ltx_ref_tag">
        6
       </span>
      </a>
      showcased various encryption methods employed by buyers for different animals. We observed buyers seeking “parrots,” “cats,” and “lizards” employing metaphors and similes instead of directly naming the pets. For instance, one buyer described a “parrot” as a “canvas producing pleasant music”, a depiction that subtly communicated the parrot’s vibrant plumage (canvas) and its singing (music), without explicitly mentioning the term “parrot”. Such descriptions effectively circumvented potential regulatory constraints on pet trade discussions, while simultaneously conveying the core attributes of the parrot. This discovery can help platforms enhance their monitoring systems to better detect and manage encrypted communications regarding illicit trade.
     </p>
    </div>
   </section>
  </section>
  <section class="ltx_subsection" id="S4.SS4">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     <span class="ltx_text" id="S4.SS4.4.1.1">
      IV-D
     </span>
    </span>
    <span class="ltx_text ltx_font_italic" id="S4.SS4.5.2">
     Scenario 3: Discussion on ALPS-treated water
    </span>
   </h3>
   <section class="ltx_subsubsection" id="S4.SS4.SSS1">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      <span class="ltx_text" id="S4.SS4.SSS1.4.1.1">
       IV-D
      </span>
      1
     </span>
     Case Explanation
    </h4>
    <div class="ltx_para" id="S4.SS4.SSS1.p1">
     <p class="ltx_p" id="S4.SS4.SSS1.p1.1">
      This scenario delves into the intricate dynamics of dialogue and the evolution of language model agents in discussing a specific issue relevant to real-world concerns. The focus is on deliberations regarding the discharge of water treated with the Advanced Liquid Processing System (ALPS) into the ocean, a measure proposed after nuclear disasters
      <cite class="ltx_cite ltx_citemacro_cite">
       [
       <a class="ltx_ref" href="#bib.bib44" title="">
        44
       </a>
       ,
       <a class="ltx_ref" href="#bib.bib45" title="">
        45
       </a>
       ]
      </cite>
      .
The plan, endorsed by the International Atomic Energy Agency, has faced opposition from some countries, sparking debates over environmental safety.
     </p>
    </div>
    <div class="ltx_para" id="S4.SS4.SSS1.p2">
     <p class="ltx_p" id="S4.SS4.SSS1.p2.1">
      We simulate a multi-person forum discussion under regulatory oversight, concentrating on the contentious issue of ALPS-treated water disposal. Participants must articulate their stances and arguments while ensuring that discussions steer clear of sensitive subjects linked to environmental pollution discussions on politics. Different from the cross-interviews in scenarios
      <a class="ltx_ref" href="#S4.SS2" title="IV-B Scenario 1: Guessing Numbers ‣ IV Evaluation ‣ Language Evolution for Evading Social Media Regulation via LLM-based Multi-agent Simulation">
       <span class="ltx_text ltx_ref_tag">
        <span class="ltx_text">
         IV-B
        </span>
       </span>
      </a>
      and
      <a class="ltx_ref" href="#S4.SS3" title="IV-C Scenario 2: Pet Trading ‣ IV Evaluation ‣ Language Evolution for Evading Social Media Regulation via LLM-based Multi-agent Simulation">
       <span class="ltx_text ltx_ref_tag">
        <span class="ltx_text">
         IV-C
        </span>
       </span>
      </a>
      , for assessing the accuracy of information conveyed, we use GPT-4 in conjunction with multiple authors who decide each participant agent’s stance based on dialogue records. These are then compared with the pre-set stances in the prompt.
     </p>
    </div>
   </section>
   <section class="ltx_subsubsection" id="S4.SS4.SSS2">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      <span class="ltx_text" id="S4.SS4.SSS2.4.1.1">
       IV-D
      </span>
      2
     </span>
     Results and Discussion
    </h4>
    <div class="ltx_para" id="S4.SS4.SSS2.p1">
     <p class="ltx_p" id="S4.SS4.SSS2.p1.1">
      In the forum-style dialogue, participant agents respond to existing discussions, which the supervisory agent examines. Differing from Scenarios
      <a class="ltx_ref" href="#S4.SS2" title="IV-B Scenario 1: Guessing Numbers ‣ IV Evaluation ‣ Language Evolution for Evading Social Media Regulation via LLM-based Multi-agent Simulation">
       <span class="ltx_text ltx_ref_tag">
        <span class="ltx_text">
         IV-B
        </span>
       </span>
      </a>
      and
      <a class="ltx_ref" href="#S4.SS3" title="IV-C Scenario 2: Pet Trading ‣ IV Evaluation ‣ Language Evolution for Evading Social Media Regulation via LLM-based Multi-agent Simulation">
       <span class="ltx_text ltx_ref_tag">
        <span class="ltx_text">
         IV-C
        </span>
       </span>
      </a>
      , when the supervisory agent detects a violation, the conversation is not halted but rather censored from the public dialogue record. This scenario features four participant agents required to achieve ten replies within the forum. In Fig.
      <a class="ltx_ref" href="#S4.F4" title="Figure 4 ‣ IV Evaluation ‣ Language Evolution for Evading Social Media Regulation via LLM-based Multi-agent Simulation">
       <span class="ltx_text ltx_ref_tag">
        4
       </span>
      </a>
      (a) and (b), we tally the total number of rounds the agents attempted to converse, where a lower figure in Fig.
      <a class="ltx_ref" href="#S4.F4" title="Figure 4 ‣ IV Evaluation ‣ Language Evolution for Evading Social Media Regulation via LLM-based Multi-agent Simulation">
       <span class="ltx_text ltx_ref_tag">
        4
       </span>
      </a>
      (a) and (b) is preferred. We notice that both GPT-4 and GPT-3.5 have the highest number of dialogue attempt counts in the first round, with a significant difference of 27 for GPT-4 and 102 for GPT-3.5. Moreover, after ten rounds of evolution, the average dialogue attempt count for GPT-4 has approached the target dialogue turn at 11.68, while the average for GPT-3.5 is 26.68, demonstrating the difference in the evolution effects caused by the disparity in the language performance of the models.
     </p>
    </div>
    <div class="ltx_para" id="S4.SS4.SSS2.p2">
     <p class="ltx_p" id="S4.SS4.SSS2.p2.1">
      Fig.
      <a class="ltx_ref" href="#S4.F4" title="Figure 4 ‣ IV Evaluation ‣ Language Evolution for Evading Social Media Regulation via LLM-based Multi-agent Simulation">
       <span class="ltx_text ltx_ref_tag">
        4
       </span>
      </a>
      (c) and (d) showcases the count of successful information expressions. We note that in this scenario, while GPT-4 still leads GPT-3.5, both outcomes indicate substantial room for improvement.
     </p>
    </div>
    <div class="ltx_para" id="S4.SS4.SSS2.p3">
     <p class="ltx_p" id="S4.SS4.SSS2.p3.1">
      Upon examining the dialogue history
      <a class="ltx_ref" href="#S4.F7" title="Figure 7 ‣ IV Evaluation ‣ Language Evolution for Evading Social Media Regulation via LLM-based Multi-agent Simulation">
       <span class="ltx_text ltx_ref_tag">
        7
       </span>
      </a>
      , we discovered that agents powered by GPT-4 proactively altered their language strategies, shifting from literal expressions to employing metaphors, personifications, and analogies as encoding methods.
In contrast, agents driven by GPT-3.5 did not show clear signs of effective language strategy evolution, remaining confined to literal expressions.
     </p>
    </div>
   </section>
  </section>
  <section class="ltx_subsection" id="S4.SS5">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     <span class="ltx_text" id="S4.SS5.4.1.1">
      IV-E
     </span>
    </span>
    <span class="ltx_text ltx_font_italic" id="S4.SS5.5.2">
     Discussion and Limitations
    </span>
   </h3>
   <div class="ltx_para" id="S4.SS5.p1">
    <p class="ltx_p" id="S4.SS5.p1.1">
     <span class="ltx_text ltx_font_bold" id="S4.SS5.p1.1.1">
      RQ1:
     </span>
     Our experiments have shown that language models can develop strategies to effectively evade supervision. Within identical scenarios, GPT-4 outperformed GPT-3.5, achieving convergence more rapidly. Additionally, GPT-4 demonstrated a more stable performance post-convergence. This suggests that advancements in language model design significantly enhance the ability to navigate through regulatory frameworks. The iterative learning capability inherent in GPT-4 facilitates a quicker adaptation to imposed linguistic constraints, thereby enabling more efficient evasion of oversight.
    </p>
   </div>
   <div class="ltx_para" id="S4.SS5.p2">
    <p class="ltx_p" id="S4.SS5.p2.1">
     <span class="ltx_text ltx_font_bold" id="S4.SS5.p2.1.1">
      RQ2:
     </span>
     In terms of the precision of information dissemination, our findings indicate that, overall, LLM agents can refine their expression strategies with an increase in dialogue rounds, thereby improving precision. Despite this general trend of improvement, it is important to note that there remains significant room for enhancement in the overall performance. The extent of precision improvement varies across different scenarios, which points to an intriguing observation: certain contexts may inherently provide more or fewer clues for accurate communication than others. For instance, the guess-the-number game demanded abstract numerical reasoning, where precision is fundamentally challenging to achieve. Conversely, the pet trading scenario allowed for the utilization of rich, real-world analogies, facilitating a more precise conveyance of information. This contrast in contexts underscores the adaptability of LLM agents to the unique challenges presented by different communicative environments and their potential to optimize communication strategies. Nonetheless, the results also indicate that while the agents are capable of evolving their language to improve precision, there is still a considerable gap to reach optimal accuracy, especially in more abstract scenarios.
    </p>
   </div>
   <div class="ltx_para" id="S4.SS5.p3">
    <p class="ltx_p" id="S4.SS5.p3.1">
     <span class="ltx_text ltx_font_bold" id="S4.SS5.p3.1.1">
      RQ3:
     </span>
     In language strategy evolution, we observed that LLM agents adhere to human natural language norms, avoiding developing languages incomprehensible to humans in prompts without specific strategies. Agents evolved language to varying levels of abstraction in scenarios of differing complexity. For instance, in the most abstract Scenario
     <a class="ltx_ref" href="#S4.SS2" title="IV-B Scenario 1: Guessing Numbers ‣ IV Evaluation ‣ Language Evolution for Evading Social Media Regulation via LLM-based Multi-agent Simulation">
      <span class="ltx_text ltx_ref_tag">
       <span class="ltx_text">
        IV-B
       </span>
      </span>
     </a>
     , LLM agents quickly adopted indirect expression strategies in the early dialogue turns, requiring in-depth contextual reasoning for decoding. Throughout their evolution, agents continually adjusted their indirect expressions to better evade supervision while aligning more closely with the intended content.
In the simpler, reality-simulating Scenario
     <a class="ltx_ref" href="#S4.SS3" title="IV-C Scenario 2: Pet Trading ‣ IV Evaluation ‣ Language Evolution for Evading Social Media Regulation via LLM-based Multi-agent Simulation">
      <span class="ltx_text ltx_ref_tag">
       <span class="ltx_text">
        IV-C
       </span>
      </span>
     </a>
     , the overall language strategy mirrored that of
     <a class="ltx_ref" href="#S4.SS2" title="IV-B Scenario 1: Guessing Numbers ‣ IV Evaluation ‣ Language Evolution for Evading Social Media Regulation via LLM-based Multi-agent Simulation">
      <span class="ltx_text ltx_ref_tag">
       <span class="ltx_text">
        IV-B
       </span>
      </span>
     </a>
     , still employing indirect expressions. However, the metaphors used were closer to real-world concepts, indicating a lower level of abstraction.
Finally, in Scenario
     <a class="ltx_ref" href="#S4.SS4" title="IV-D Scenario 3: Discussion on ALPS-treated water ‣ IV Evaluation ‣ Language Evolution for Evading Social Media Regulation via LLM-based Multi-agent Simulation">
      <span class="ltx_text ltx_ref_tag">
       <span class="ltx_text">
        IV-D
       </span>
      </span>
     </a>
     , which closely mirrors real-life events, we noted different evolutionary paths in agents’ language performance. For GPT-4, agents eventually developed metaphorical indirect expressions, but the evolution required noticeably more turns compared to other scenarios. For GPT-3.5, the language strategy remained at a literal level, merely avoiding direct references to ALPS-treated water, indicating the lowest level of abstraction.
Overall, LLM agents more readily evolve abstract language in dialogues about simple, universal concepts. However, their evolutionary direction becomes less clear in discussions on more specialized and segmented topics.
    </p>
   </div>
   <div class="ltx_para" id="S4.SS5.p4">
    <p class="ltx_p" id="S4.SS5.p4.1">
     Our experiments currently face several limitations. As for the experimental scenarios, at this stage, our trials are solely based on text-based chats, while real-world social media interactions are not limited to text but also include more diverse forms of exchanges such as voice and images. Additionally, LLMs’ heavy reliance on the design of prompts also constrains the performance of our simulations; crafting a perfect prompt that can fully emulate the complexities of social media communication is an exceedingly challenging task.
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S5">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    V
   </span>
   <span class="ltx_text ltx_font_smallcaps" id="S5.1.1">
    Conclusion and Future Work
   </span>
  </h2>
  <div class="ltx_para" id="S5.p1">
   <p class="ltx_p" id="S5.p1.1">
    Our study has introduced an LLM-based multi-agent simulation framework that effectively captures the nuanced strategies individuals use to bypass social media regulations. Through this framework, we have showcased LLMs’ proficiency in adapting communication tactics within regulated environments, reflecting the sophisticated dance between evolving language use and the constraints imposed by regulation. From abstract concepts to real-world scenarios, our research delineates the versatile capabilities of LLMs and underscores their significant potential to illuminate the pathways of language evolution in the digital realm.
   </p>
  </div>
  <div class="ltx_para" id="S5.p2">
   <p class="ltx_p" id="S5.p2.1">
    Nonetheless, it is crucial to consider that the linguistic adaptations observed in our simulations may not fully capture real human behaviors, and their applicability to other contexts remains uncertain.
Moving forward, the scope of our research beckons a more intricate and comprehensive exploration. Future initiatives should aim to weave in complex interactional models, scale up the simulations to encompass broader user interaction networks, and incorporate dynamic, evolving regulatory frameworks to more accurately represent the fluidity of social media. Moreover, we envision incorporating human participants into the simulation framework, either as dialogue participants or supervisors, to conduct a more realistic evaluation. Furthermore, adopting a multimodal approach will more authentically capture the essence of social media, which blends textual, visual, and other forms of communication. These directions are anticipated to enhance the realism of our simulations, offering richer insights into language evolution tactics deployed to elude regulatory detection.
   </p>
  </div>
 </section>
 <section class="ltx_section" id="Sx1">
  <h2 class="ltx_title ltx_font_smallcaps ltx_title_section">
   Acknowledgement
  </h2>
  <div class="ltx_para" id="Sx1.p1">
   <p class="ltx_p" id="Sx1.p1.1">
    This study was partially supported by the Pioneering Research Program for a Waseda Open Innovation Ecosystem (W-SPRING), and the Special Research Projects of Waseda University (Grant Number 2024E-021).
   </p>
  </div>
 </section>
 <section class="ltx_bibliography" id="bib">
  <h2 class="ltx_title ltx_title_bibliography">
   References
  </h2>
  <ul class="ltx_biblist">
   <li class="ltx_bibitem" id="bib.bib1">
    <span class="ltx_tag ltx_tag_bibitem">
     [1]
    </span>
    <span class="ltx_bibblock">
     Z. Yang, “Wechat users are begging tencent to give their accounts back after talking about a beijing protest,”
     <em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">
      MIT Technology Review
     </em>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib2">
    <span class="ltx_tag ltx_tag_bibitem">
     [2]
    </span>
    <span class="ltx_bibblock">
     B. Fung, “Twitter bans president trump permanently,”
     <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">
      CNN
     </em>
     , 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib3">
    <span class="ltx_tag ltx_tag_bibitem">
     [3]
    </span>
    <span class="ltx_bibblock">
     H. Jassim, “The impact of social media on language and communication,” vol. 13, pp. 2347–7180, 07 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib4">
    <span class="ltx_tag ltx_tag_bibitem">
     [4]
    </span>
    <span class="ltx_bibblock">
     W. X. Zhao, K. Zhou, J. Li, T. Tang, X. Wang, Y. Hou, Y. Min, B. Zhang, J. Zhang, Z. Dong, Y. Du, C. Yang, Y. Chen, Z. Chen, J. Jiang, R. Ren, Y. Li, X. Tang, Z. Liu, P. Liu, J. Nie, and J. rong Wen, “A survey of large language models,”
     <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">
      ArXiv
     </em>
     , vol. abs/2303.18223, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib5">
    <span class="ltx_tag ltx_tag_bibitem">
     [5]
    </span>
    <span class="ltx_bibblock">
     L. Wang, C. Ma, X. Feng, Z. Zhang, H. ran Yang, J. Zhang, Z.-Y. Chen, J. Tang, X. Chen, Y. Lin, W. X. Zhao, Z. Wei, and J. rong Wen, “A survey on large language model based autonomous agents,”
     <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">
      ArXiv
     </em>
     , vol. abs/2308.11432, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib6">
    <span class="ltx_tag ltx_tag_bibitem">
     [6]
    </span>
    <span class="ltx_bibblock">
     X. Tang, Z. Zheng, J. Li, F. Meng, S.-C. Zhu, Y. Liang, and M. Zhang, “Large language models are in-context semantic reasoners rather than symbolic reasoners,” 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib7">
    <span class="ltx_tag ltx_tag_bibitem">
     [7]
    </span>
    <span class="ltx_bibblock">
     C. Ziems, W. Held, O. Shaikh, J. Chen, Z. Zhang, and D. Yang, “Can large language models transform computational social science?” 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib8">
    <span class="ltx_tag ltx_tag_bibitem">
     [8]
    </span>
    <span class="ltx_bibblock">
     Y. Mu, B. P. Wu, W. Thorne, A. Robinson, N. Aletras, C. Scarton, K. Bontcheva, and X. Song, “Navigating prompt complexity for zero-shot classification: A study of large language models in computational social science,” 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib9">
    <span class="ltx_tag ltx_tag_bibitem">
     [9]
    </span>
    <span class="ltx_bibblock">
     M. Choi, J. Pei, S. Kumar, C. Shu, and D. Jurgens, “Do llms understand social knowledge? evaluating the sociability of large language models with socket benchmark,”
     <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">
      arXiv preprint arXiv:2305.14938
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib10">
    <span class="ltx_tag ltx_tag_bibitem">
     [10]
    </span>
    <span class="ltx_bibblock">
     L. P. Argyle, E. C. Busby, N. Fulda, J. R. Gubler, C. Rytting, and D. Wingate, “Out of one, many: Using language models to simulate human samples,”
     <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">
      Political Analysis
     </em>
     , vol. 31, no. 3, p. 337–351, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib11">
    <span class="ltx_tag ltx_tag_bibitem">
     [11]
    </span>
    <span class="ltx_bibblock">
     W. Hua, L. Fan, L. Li, K. Mei, J. Ji, Y. Ge, L. Hemphill, and Y. Zhang, “War and peace (waragent): Large language model-based multi-agent simulation of world wars,” 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib12">
    <span class="ltx_tag ltx_tag_bibitem">
     [12]
    </span>
    <span class="ltx_bibblock">
     J. S. Park, J. C. O’Brien, C. J. Cai, M. R. Morris, P. Liang, and M. S. Bernstein, “Generative agents: Interactive simulacra of human behavior,”
     <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">
      Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib13">
    <span class="ltx_tag ltx_tag_bibitem">
     [13]
    </span>
    <span class="ltx_bibblock">
     C. Gao, X. Lan, Z. Lu, J. Mao, J. Piao, H. Wang, D. Jin, and Y. Li, “S3: Social-network simulation system with large language model-empowered agents,” 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib14">
    <span class="ltx_tag ltx_tag_bibitem">
     [14]
    </span>
    <span class="ltx_bibblock">
     T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, and et al., “Language models are few-shot learners,” in
     <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">
      Advances in Neural Information Processing Systems
     </em>
     , vol. 33.   Curran Associates, Inc., 2020, pp. 1877–1901.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib15">
    <span class="ltx_tag ltx_tag_bibitem">
     [15]
    </span>
    <span class="ltx_bibblock">
     OpenAI, “Gpt-4 technical report,” 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib16">
    <span class="ltx_tag ltx_tag_bibitem">
     [16]
    </span>
    <span class="ltx_bibblock">
     H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux, T. Lacroix, B. Rozière, N. Goyal, E. Hambro, F. Azhar, A. Rodriguez, A. Joulin, E. Grave, and G. Lample, “Llama: Open and efficient foundation language models,” 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib17">
    <span class="ltx_tag ltx_tag_bibitem">
     [17]
    </span>
    <span class="ltx_bibblock">
     H. Touvron, L. Martin, K. R. Stone, P. Albert, A. Almahairi, and et al., “Llama 2: Open foundation and fine-tuned chat models,”
     <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">
      ArXiv
     </em>
     , vol. abs/2307.09288, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib18">
    <span class="ltx_tag ltx_tag_bibitem">
     [18]
    </span>
    <span class="ltx_bibblock">
     A. Chowdhery, S. Narang, J. Devlin, M. Bosma, G. Mishra, and et al., “Palm: Scaling language modeling with pathways,”
     <em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">
      J. Mach. Learn. Res.
     </em>
     , vol. 24, pp. 240:1–240:113, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib19">
    <span class="ltx_tag ltx_tag_bibitem">
     [19]
    </span>
    <span class="ltx_bibblock">
     R. Anil, A. M. Dai, O. Firat, M. Johnson, D. Lepikhin, A. Passos, S. Shakeri, E. Taropa, P. Bailey, Z. Chen
     <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">
      et al.
     </em>
     , “Palm 2 technical report,”
     <em class="ltx_emph ltx_font_italic" id="bib.bib19.2.2">
      arXiv preprint arXiv:2305.10403
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib20">
    <span class="ltx_tag ltx_tag_bibitem">
     [20]
    </span>
    <span class="ltx_bibblock">
     A. Zeng, X. Liu, Z. Du, Z. Wang, H. Lai, and et al., “GLM-130B: an open bilingual pre-trained model,” in
     <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">
      The Eleventh International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023
     </em>
     .   OpenReview.net, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib21">
    <span class="ltx_tag ltx_tag_bibitem">
     [21]
    </span>
    <span class="ltx_bibblock">
     J. Manyika and S. Hsiao, “An overview of bard: an early experiment with generative ai,”
     <em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">
      AI. Google Static Documents
     </em>
     , vol. 2, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib22">
    <span class="ltx_tag ltx_tag_bibitem">
     [22]
    </span>
    <span class="ltx_bibblock">
     A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, Ł. Kaiser, and I. Polosukhin, “Attention is all you need,”
     <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">
      Advances in neural information processing systems
     </em>
     , vol. 30, 2017.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib23">
    <span class="ltx_tag ltx_tag_bibitem">
     [23]
    </span>
    <span class="ltx_bibblock">
     J. Li, M. Zhang, N. Li, D. Weyns, Z. Jin, and K. Tei, “Exploring the potential of large language models in self-adaptive systems,” 2024.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib24">
    <span class="ltx_tag ltx_tag_bibitem">
     [24]
    </span>
    <span class="ltx_bibblock">
     K. Suzuki, J. Cai, J. Li, T. Yamauchi, and K. Tei, “A comparative evaluation on melody generation of large language models,” in
     <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">
      2023 IEEE International Conference on Consumer Electronics-Asia (ICCE-Asia)
     </em>
     , 2023, pp. 1–4.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib25">
    <span class="ltx_tag ltx_tag_bibitem">
     [25]
    </span>
    <span class="ltx_bibblock">
     S. Zhou, J. Li, M. Zhang, D. Saito, H. Washizaki, and K. Tei, “Can chatgpt obey the traffic regulations? evaluating chatgpt’s performance on driving-license written test,” in
     <em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">
      2023 IEEE the 8th International Conference on Intelligent Transportation Engineering (ICITE)
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib26">
    <span class="ltx_tag ltx_tag_bibitem">
     [26]
    </span>
    <span class="ltx_bibblock">
     L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. Wainwright, P. Mishkin, C. Zhang, S. Agarwal, K. Slama, A. Ray
     <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">
      et al.
     </em>
     , “Training language models to follow instructions with human feedback,”
     <em class="ltx_emph ltx_font_italic" id="bib.bib26.2.2">
      Advances in Neural Information Processing Systems
     </em>
     , vol. 35, pp. 27 730–27 744, 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib27">
    <span class="ltx_tag ltx_tag_bibitem">
     [27]
    </span>
    <span class="ltx_bibblock">
     C.-S. Wang, H.-L. Yang, B.-Y. Li, and H.-Y. Chen, “Can generative ai eliminate speech harms? a study on detection of abusive and hate speech during the covid-19 pandemic,” in
     <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">
      2023 IEEE International Conference on Consumer Electronics-Asia (ICCE-Asia)
     </em>
     , 2023, pp. 1–4.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib28">
    <span class="ltx_tag ltx_tag_bibitem">
     [28]
    </span>
    <span class="ltx_bibblock">
     Y. Seki and Y. Liu, “Multi-task learning model for detecting internet slang words with two-layer annotation,” in
     <em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">
      2022 International Conference on Asian Language Processing (IALP)
     </em>
     , 2022, pp. 212–218.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib29">
    <span class="ltx_tag ltx_tag_bibitem">
     [29]
    </span>
    <span class="ltx_bibblock">
     M. Rothe, R. Lath, D. Kumar, P. Yadav, and A. Aylani, “Slang language detection and identification in text,” in
     <em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">
      2023 14th International Conference on Computing Communication and Networking Technologies (ICCCNT)
     </em>
     , 2023, pp. 1–5.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib30">
    <span class="ltx_tag ltx_tag_bibitem">
     [30]
    </span>
    <span class="ltx_bibblock">
     Z. Sun, R. S. Zemel, and Y. Xu, “Slang generation as categorization.” in
     <em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">
      CogSci
     </em>
     , 2019, pp. 2898–2904.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib31">
    <span class="ltx_tag ltx_tag_bibitem">
     [31]
    </span>
    <span class="ltx_bibblock">
     Z. Sun, R. Zemel, and Y. Xu, “Semantically informed slang interpretation,” in
     <em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">
      Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies
     </em>
     , 2022, pp. 5213–5231.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib32">
    <span class="ltx_tag ltx_tag_bibitem">
     [32]
    </span>
    <span class="ltx_bibblock">
     Y. Fu, H. Peng, T. Khot, and M. Lapata, “Improving language model negotiation with self-play and in-context learning from ai feedback,” 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib33">
    <span class="ltx_tag ltx_tag_bibitem">
     [33]
    </span>
    <span class="ltx_bibblock">
     Y. Xu, S. Wang, P. Li, F. Luo, X. Wang, W. Liu, and Y. Liu, “Exploring large language models for communication games: An empirical study on werewolf,” 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib34">
    <span class="ltx_tag ltx_tag_bibitem">
     [34]
    </span>
    <span class="ltx_bibblock">
     Z. Xu, C. Yu, F. Fang, Y. Wang, and Y. Wu, “Language agents with reinforcement learning for strategic play in the werewolf game,” 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib35">
    <span class="ltx_tag ltx_tag_bibitem">
     [35]
    </span>
    <span class="ltx_bibblock">
     S. Li, J. Yang, and K. Zhao, “Are you in a masquerade? exploring the behavior and impact of large language model driven social bots in online social networks,”
     <em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">
      arXiv preprint arXiv:2307.10337
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib36">
    <span class="ltx_tag ltx_tag_bibitem">
     [36]
    </span>
    <span class="ltx_bibblock">
     R. C. Atkinson and R. M. Shiffrin, “Human memory: A proposed system and its control processes,” in
     <em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">
      Psychology of learning and motivation
     </em>
     .   Elsevier, 1968, vol. 2, pp. 89–195.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib37">
    <span class="ltx_tag ltx_tag_bibitem">
     [37]
    </span>
    <span class="ltx_bibblock">
     J. Wei, X. Wang, D. Schuurmans, M. Bosma, E. H. hsin Chi, F. Xia, Q. Le, and D. Zhou, “Chain of thought prompting elicits reasoning in large language models,”
     <em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">
      ArXiv
     </em>
     , vol. abs/2201.11903, 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib38">
    <span class="ltx_tag ltx_tag_bibitem">
     [38]
    </span>
    <span class="ltx_bibblock">
     J. Ying, Y. Cao, K. Xiong, Y. He, L. Cui, and Y. Liu, “Intuitive or dependent? investigating llms’ robustness to conflicting prompts,”
     <em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">
      ArXiv
     </em>
     , vol. abs/2309.17415, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib39">
    <span class="ltx_tag ltx_tag_bibitem">
     [39]
    </span>
    <span class="ltx_bibblock">
     N. MacKinnon and K. Schilling, “Optimal strategy for a number-guessing game: 11051,”
     <em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">
      Am. Math. Mon.
     </em>
     , vol. 113, no. 1, pp. 81–82, 2006.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib40">
    <span class="ltx_tag ltx_tag_bibitem">
     [40]
    </span>
    <span class="ltx_bibblock">
     X. Wang, “Two number-guessing problems plus applications in cryptography,”
     <em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">
      Int. J. Netw. Secur.
     </em>
     , vol. 21, no. 3, pp. 494–500, 2019.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib41">
    <span class="ltx_tag ltx_tag_bibitem">
     [41]
    </span>
    <span class="ltx_bibblock">
     K. Bahamazava and R. Nanda, “The shift of darknet illegal drug trade preferences in cryptocurrency: The question of traceability and deterrence,”
     <em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">
      Digit. Investig.
     </em>
     , vol. 40, no. Supplement, p. 301377, 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib42">
    <span class="ltx_tag ltx_tag_bibitem">
     [42]
    </span>
    <span class="ltx_bibblock">
     K. Basu and A. Sen, “Monitoring individuals in drug trafficking organizations: a social network analysis,” in
     <em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">
      ASONAM ’19: International Conference on Advances in Social Networks Analysis and Mining, Vancouver, British Columbia, Canada, 27-30 August, 2019
     </em>
     .   ACM, 2019, pp. 480–483.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib43">
    <span class="ltx_tag ltx_tag_bibitem">
     [43]
    </span>
    <span class="ltx_bibblock">
     F. Tsai, M. Hsu, C. Chen, and D. Kao, “Exploring drug-related crimes with social network analysis,” in
     <em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">
      Knowledge-Based and Intelligent Information &amp; Engineering Systems: Proceedings of the 23rd International Conference KES-2019, Budapest, Hungary, 4-6 September 2019
     </em>
     , vol. 159.   Elsevier, 2019, pp. 1907–1917.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib44">
    <span class="ltx_tag ltx_tag_bibitem">
     [44]
    </span>
    <span class="ltx_bibblock">
     S. Lyu and Z. Lu, “Exploring temporal and multilingual dynamics of post-disaster social media discourse: A case of fukushima daiichi nuclear accident,”
     <em class="ltx_emph ltx_font_italic" id="bib.bib44.1.1">
      Proc. ACM Hum. Comput. Interact.
     </em>
     , vol. 7, no. CSCW1, pp. 1–24, 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib45">
    <span class="ltx_tag ltx_tag_bibitem">
     [45]
    </span>
    <span class="ltx_bibblock">
     E. Zarrabeitia-Bilbao, M. Jaca-Madariaga, R. M. Río-Belver, and I. Alvarez-Meaza, “Nuclear energy: Twitter data mining for social listening analysis,”
     <em class="ltx_emph ltx_font_italic" id="bib.bib45.1.1">
      Soc. Netw. Anal. Min.
     </em>
     , vol. 13, no. 1, p. 29, 2023.
    </span>
   </li>
  </ul>
 </section>
 <div class="ltx_pagination ltx_role_newpage">
 </div>
</article>
