<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2409.15242] Skeletal Data Matching and Merging from Multiple RGB-D Sensors for Room-Scale Human Behaviour Tracking</title><meta property="og:description" content="A popular and affordable option to provide room-scale human behaviour tracking is to rely on commodity RGB-D sensors as such devices offer body tracking capabilities at a reasonable price point.
While their capabilitie…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Skeletal Data Matching and Merging from Multiple RGB-D Sensors for Room-Scale Human Behaviour Tracking">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Skeletal Data Matching and Merging from Multiple RGB-D Sensors for Room-Scale Human Behaviour Tracking">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2409.15242">

<!--Generated on Sat Oct  5 23:56:11 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="Body tracking Room-scale interaction Multiple RGB-D sensors Skeleton matching Skeleton merging Tracking data fusion Human behaviour tracking.">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line"><span id="id1" class="ltx_note ltx_role_institutetext"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">institutetext: </span>Luxembourg Institute of Science and Technology, Esch-sur-Alzette, Luxembourg
<span id="id1.1" class="ltx_note ltx_role_email"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">email: </span>firstname.lastname@list.lu</span></span></span></span></span></span>
<h1 class="ltx_title ltx_title_document">Skeletal Data Matching and Merging from Multiple RGB-D Sensors for Room-Scale Human Behaviour Tracking</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Adrien Coppens

</span><span class="ltx_author_notes">11
<span class="ltx_contact ltx_role_orcid"><a target="_blank" href="https://orcid.org/0000-0002-2841-6708" title="ORCID identifier" class="ltx_ref">0000-0002-2841-6708</a></span>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Valerie Maquil
</span><span class="ltx_author_notes">11
<span class="ltx_contact ltx_role_orcid"><a target="_blank" href="https://orcid.org/0000-0002-0198-3729" title="ORCID identifier" class="ltx_ref">0000-0002-0198-3729</a></span>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">A popular and affordable option to provide room-scale human behaviour tracking is to rely on commodity RGB-D sensors as such devices offer body tracking capabilities at a reasonable price point.
While their capabilities may be sufficient for applications such as entertainment systems where a person plays in front of a television, RGB-D sensors are sensitive to occlusions from objects or other persons that might be in the way in more complex room-scale setups.
To alleviate the occlusion issue but also in order to extend the tracking range and strengthen its accuracy, it is possible to rely on multiple RGB-D sensors and perform data fusion. Unfortunately, fusing the data in a meaningful manner raises additional challenges related to the calibration of the sensors relative to each other to provide a common frame of reference, but also regarding skeleton matching and merging when actually combining the data.
In this paper, we discuss our approach to tackle these challenges and present the results we achieved, through aligned point clouds and combined skeleton lists. These results successfully enable unobtrusive and occlusion-resilient human behaviour tracking at room scale, that may be used as input for interactive applications as well as (possibly remote) collaborative systems.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Keywords: </h6>Body tracking Room-scale interaction Multiple RGB-D sensors Skeleton matching Skeleton merging Tracking data fusion Human behaviour tracking.
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Room-scale interaction tracking concerns many scenarios and setups, with varying numbers of users and interaction needs beyond those of standard desktops.
Various types of interactive surfaces including displays might be spread across the room.
As part of an ongoing project, we work with wall-sized displays, which are frequently used to present large amounts of data and to support collaborative work and decision-making in group settings. The peculiarity of that project is that we look at interconnecting two such displays to enable remote collaboration scenarios. As the resulting interactions happen at room-scale, we need a human behaviour tracking and analysis system adapted to such physical space.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Wall-sized displays are often equipped with touch frames that provide natural and efficient interaction for users standing close to the display <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>. However, touch input is not always sufficient, both in terms of interaction options (as they involve physical navigation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>) and with regards to behaviour tracking, e.g. as input to support our remote collaboration system.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Many existing tracking systems rely on hand-held or body-worn equipment to enable distant interaction capabilities, e.g. through telepointers <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>, markers <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> or full-on body suits <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>.
While these options typically provide good tracking accuracy and demonstrate high reliability and robustness to occlusions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>, they can be obtrusive as they require users to hold or wear additional devices.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Therefore, previous work has explored the use of unobtrusive tracking devices such as video cameras.
By processing the recordings of such standard (RGB) cameras, it is possible to enable skeletal tracking (e.g. through OpenPose <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>, that tracks whole bodies, including hands and faces specifically <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>).</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">That approach might be sufficient for some cases but the issue with these RGB cameras is that they are limited to two-dimensional input images, which makes three-dimensional inferences complex. While some have tackled that issue by using several RGB cameras <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>, many researchers have instead opted for RGB-D sensors <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>, that also gather depth information (e.g. through Time-of-Flight <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> measurements). Such devices enable better skeletal tracking capabilities to an extent that enables gaze <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>, gesture <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> and mid-air interactions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">However the capture range of RGB-D sensors is limited and cannot cover the whole space required for room-scale tracking. Furthermore, when several objects or users are present, occlusion problems might occur frequently.</p>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p">In this paper, we study the feasibility of relying on multiple RGB-D sensors to support room-scale tracking. The combination of the resulting data raises additional challenges, including the gathering of knowledge on the relative placement of the sensors, but also the skeletal data fusion itself. To tackle these challenges, we describe our approach consisting of i) multi-sensor calibration, ii) skeleton matching, and iii) skeleton merging, and present the rationale behind the implementation in each of these steps. We then discuss the potential merits and limitations of that system.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Multi-sensor calibration</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">In order to feed our room-scale tracking system, we rely on two Azure Kinect RGB-D sensors, that each continuously provide depth images as well as body tracking data (through the Azure Kinect Sensor SDK<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a target="_blank" href="https://github.com/microsoft/Azure-Kinect-Sensor-SDK" title="" class="ltx_ref ltx_url">https://github.com/microsoft/Azure-Kinect-Sensor-SDK</a></span></span></span>).
To facilitate the synchronisation and combination of the input data from these sensors, we rely on the \psi framework <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> to build our processing pipeline. The framework comes with components ensuring the easy integration of Azure Kinect devices, but also includes data manipulation, recording and visualisation tools, which helps in alleviating some of the burden of dealing with streams of temporal data.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">For example, simultaneous captures of the same tracking area by multiple sensors would result in significant inaccuracies. The hardware sync feature of the SDK<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a target="_blank" href="https://learn.microsoft.com/en-us/azure/kinect-dk/multi-camera-sync" title="" class="ltx_ref ltx_url">https://learn.microsoft.com/en-us/azure/kinect-dk/multi-camera-sync</a></span></span></span> solves that issue by making sure the capture intervals are shifted, by relying on connections through 3.5-mm audio cables between the sensors. These time modulations introduce offsets between captures from different but overlapping sensors, but the resulting adversary effects can easily be reduced through time-based interpolation with \psi.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">Solving this time synchronisation issue is however insufficient to combine data from multiple sensors as part of a room-scale tracking system, as their relative placement (to each other or to a reference coordinate system) still needs to be known, so that the data they gather separately may be converted into a common frame of reference.
In the literature, this is typically represented by a transformation matrix (one per sensor) that contains what is often referred to as <span id="S2.p3.1.1" class="ltx_text ltx_font_italic">extrinsic</span> (or sometimes external) parameters. That <span id="S2.p3.1.2" class="ltx_text ltx_font_italic">extrinsic matrix</span> essentially represents the sensor’s pose in the <span id="S2.p3.1.3" class="ltx_text ltx_font_italic">world coordinate system</span>, and enables transformations between the sensor and that world <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p">For a well-defined setup with precise measurements regarding the dimensions and placement of the RGB-D sensors, it is of course possible to opt for a manual approach in which the data is provided directly to the system by a human.</p>
</div>
<div id="S2.p5" class="ltx_para">
<p id="S2.p5.1" class="ltx_p">A common approach to avoid potentially tricky placements and measurements is to rely on markers and known 2D motifs for calibration, in particular based on checkerboards <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> whose square-based patterns are recognised by two sensors to determine the extrinsic parameters. The previously mentioned Azure Kinect SDK even provides an example project using that approach<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a target="_blank" href="https://github.com/microsoft/Azure-Kinect-Sensor-SDK/tree/develop/examples/green_screen" title="" class="ltx_ref ltx_url">https://github.com/microsoft/Azure-Kinect-Sensor-SDK/tree/develop/examples/green˙screen</a></span></span></span>.</p>
</div>
<div id="S2.p6" class="ltx_para">
<p id="S2.p6.1" class="ltx_p">We therefore tried the checkerboard approach based on the aforementioned example project but the results we obtained were not satisfactory. This might partly be due to our reliance on a checkerboard we printed ourselves on an A3 sheet of paper that we placed on a sturdy cardboard plate, as a “commercial” checkerboard that might have produced better calibration outcomes.</p>
</div>
<div id="S2.p7" class="ltx_para">
<p id="S2.p7.1" class="ltx_p">Another possibility is to capitalise on the tracking data itself: with only one person in the tracking area being tracked by the two sensors, the corresponding skeletons (one per sensor) can be used as a reference <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>.</p>
</div>
<div id="S2.p8" class="ltx_para">
<p id="S2.p8.1" class="ltx_p">We tried that approach, by selecting a set of candidate joints
to act as references from which we compute an average transformation matrix. We do so by splitting translations (straightforward average computation) and rotations transformations to average them separately (see Hartley et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> for a tutorial on rotation averaging). Note that only candidate joints whose reported tracking state was at least “medium” were used in the computation. While the calibration process with that approach was convenient, the results were unsatisfactory and led to ambiguities with the skeleton matching logic we describe in section <a href="#S3" title="3 Skeleton Matching ‣ Skeletal Data Matching and Merging from Multiple RGB-D Sensors for Room-Scale Human Behaviour Tracking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<figure id="S2.F1" class="ltx_figure"><img src="/html/2409.15242/assets/img/pointcloudfromdepth.png" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="538" height="181" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F1.2.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S2.F1.3.2" class="ltx_text" style="font-size:90%;">Generation of a partial point cloud (right) from a depth image (left). The blue circles show a selection of three points on the depth image, replicated on the image plane seen on the right picture. As these points have a similar colour on the depth image, they are at similar distance from the sensor (visualised as blue lines of similar length on the right picture) and the combination of that distance information with a projection of the image points using the sensor’s intrinsic parameters generates resulting points to be included in the point cloud.</span></figcaption>
</figure>
<div id="S2.p9" class="ltx_para">
<p id="S2.p9.1" class="ltx_p">Another opportunity provided by RGB-D sensors is that they generate depth data that may be converted point clouds, as illustrated in Figure <a href="#S2.F1" title="Figure 1 ‣ 2 Multi-sensor calibration ‣ Skeletal Data Matching and Merging from Multiple RGB-D Sensors for Room-Scale Human Behaviour Tracking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
As seen in the Figure, the generated point cloud can be considered as partial in the sense that it can only ever contain the front facing part of any entity in range (any possible line starting from the sensor may only lead to a maximum of one corresponding point that belongs to the closest element encountered along that line).</p>
</div>
<div id="S2.p10" class="ltx_para">
<p id="S2.p10.1" class="ltx_p">Two sensors roughly looking at the same scene should generate similar point clouds, which can therefore be matched to compute the transformation matrix between the source sensors.
A popular (family of) algorithm(s) to perform such matchings is named Iterative Closest Point (ICP) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>.</p>
</div>
<div id="S2.p11" class="ltx_para">
<p id="S2.p11.1" class="ltx_p">We therefore decided to implement an approach based on that algorithm. As made clear by its name, ICP is an iterative process, that requires an initialisation step to be used as a starting point. We chose to simply use the skeleton-based calibration described above as that starting point.</p>
</div>
<div id="S2.p12" class="ltx_para">
<p id="S2.p12.1" class="ltx_p">However, the initial results we obtained with the ICP approach were also insufficient, in the sense that the floor looked aligned but objects on it were not.
This was because planar surfaces such as floor parts will generate very similar (planar) point clouds. Assuming the floor is homogeneously leveled in the target room, running ICP on point clouds that contain many floor points will likely result in a combined floor that is indeed aligned.
The problem is that our setups rely on pairs of sensors that are capturing their respective scene from different viewpointsand that therefore do not contain that many points from commonly seen surfaces. This means that the floor points largely outnumber the other surfaces and ICP will essentially perform the alignment mostly based on floor points that are mostly not even from the same exact portions of the floor.
</p>
</div>
<div id="S2.p13" class="ltx_para">
<p id="S2.p13.1" class="ltx_p">We therefore decided to filter the generated point clouds in an attempt to focus on points that should mostly correspond to the same surfaces (and should therefore indeed be matched by ICP to generate a good transformation matrix).</p>
</div>
<figure id="S2.F2" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S2.F2.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2409.15242/assets/img/pc-icp-filtered-frontright.png" id="S2.F2.sf1.g1" class="ltx_graphics ltx_img_portrait" width="113" height="169" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S2.F2.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S2.F2.sf1.3.2" class="ltx_text" style="font-size:90%;">Single user   (front-right view).</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S2.F2.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2409.15242/assets/img/pc-icp-filtered-left.png" id="S2.F2.sf2.g1" class="ltx_graphics ltx_img_square" width="208" height="169" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S2.F2.sf2.3.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S2.F2.sf2.4.2" class="ltx_text" style="font-size:90%;">The same user from the same   <span id="S2.F2.sf2.4.2.1" class="ltx_text">capture</span>, from a different (left) view.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S2.F2.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2409.15242/assets/img/pc-icp-filtered-many.png" id="S2.F2.sf3.g1" class="ltx_graphics ltx_img_square" width="141" height="169" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S2.F2.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="S2.F2.sf3.3.2" class="ltx_text" style="font-size:90%;">Another capture with users scattered in a room.</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F2.2.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S2.F2.3.2" class="ltx_text" style="font-size:90%;">Calibration results using the ICP approach with filtered point clouds, with green and red (full) point clouds corresponding to two separate sensors. In the first two subfigures, the shapes of calibration objects (a standing desk and a cardboard box) may be perceived, with the single user standing near them.</span></figcaption>
</figure>
<div id="S2.p14" class="ltx_para">
<p id="S2.p14.1" class="ltx_p">To do so, we place a few non-reflective objects (cardboard box, chair, etc.) in both of their tracking ranges. we place such objects in line, about 2.5-3 meters away from both sensors, to maximise the jointly tracked surfaces while staying at good tracking distance.
We then ask the person (whose skeleton is used as common reference to initiate the ICP process) to stand close to these objects and only consider point cloud points that are close to that person. This normally result in two point clouds that contain many common points for the floor below the reference person, but also the previously mentioned jointly tracked (“front-facing”) surfaces as well as the front part of the person’s body. Our hope with that approach is that the inclusion of floor points should produce an ICP result whose transformation matrix will lead to fused data where floor points are aligned. The jointly tracked surfaces should themselves help with the rest of the degrees of freedom and the combination of floor and front-facing surface points should therefore lead to pairs of point clouds suitable for alignment. After a couple of ICP runs following the aforementioned process, we indeed ended up with properly aligned results, as seen in Figure <a href="#S2.F2" title="Figure 2 ‣ 2 Multi-sensor calibration ‣ Skeletal Data Matching and Merging from Multiple RGB-D Sensors for Room-Scale Human Behaviour Tracking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Skeleton Matching</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">A proper calibration is enough to generate combined point clouds that may then cover bigger areas as we may transform the data from the different sensors within the same room as being expressed in the same coordinate system.</p>
</div>
<figure id="S3.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F3.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2409.15242/assets/img/justskeletons-removebg.png" id="S3.F3.sf1.g1" class="ltx_graphics ltx_img_square" width="538" height="481" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S3.F3.sf1.3.2" class="ltx_text" style="font-size:90%;">Skeletons from two (green- and pink-coded) sensors. Notice the isolated skeletons: a green one on the top right, and two pink ones in the bottom.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F3.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2409.15242/assets/img/justmergedskeletons-removebg.png" id="S3.F3.sf2.g1" class="ltx_graphics ltx_img_square" width="538" height="459" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S3.F3.sf2.3.2" class="ltx_text" style="font-size:90%;">The merged skeletons following our skeletal data fusion algorithm, showing the successful pairing of overlapping skeletons but also the inclusion of isolated ones.</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.2.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S3.F3.3.2" class="ltx_text" style="font-size:90%;">The skeleton matching problem, with skeletons from two different sensors that are matched to form a merged set of skeletons. While most persons in the room are tracked by both sensors and therefore result in two overlapping skeletons, some are isolated as only one of the sensors currently sees them.</span></figcaption>
</figure>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p">While we could theoretically merge the transformed point clouds and use the result as input for a hypothetical body tracking model, most of the existing tools relying on RGB-D sensors expect non-fused data, in the sense that they were trained with setups involving only one sensor and front-facing users. Providing merged point clouds to them might lead to inaccurate results, and we therefore opted to perform the data fusion at the skeletal tracking level, i.e. analyse the individual sets of skeletons coming from each sensor to decide whether (and which) skeletons from different sets belong to the same person.
This is illustrated through a rather crowded case in Figure <a href="#S3.F3" title="Figure 3 ‣ 3 Skeleton Matching ‣ Skeletal Data Matching and Merging from Multiple RGB-D Sensors for Room-Scale Human Behaviour Tracking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, where input skeletons from two sensors (Figure <a href="#S3.F3.sf1" title="In Figure 3 ‣ 3 Skeleton Matching ‣ Skeletal Data Matching and Merging from Multiple RGB-D Sensors for Room-Scale Human Behaviour Tracking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3(a)</span></a>) are combined into a merged set (Figure <a href="#S3.F3.sf2" title="In Figure 3 ‣ 3 Skeleton Matching ‣ Skeletal Data Matching and Merging from Multiple RGB-D Sensors for Room-Scale Human Behaviour Tracking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3(b)</span></a>).</p>
</div>
<div id="S3.p3" class="ltx_para">
<p id="S3.p3.1" class="ltx_p">After converting the body tracking information to a common coordinate system and filtering non-suitable skeletons (too close to the sensor or outside the tracking area), our logic for dealing with skeleton matching boils down to 4 steps:
(1) settle easy cases where it seems clear which skeletons to match based on a distance threshold,
(2) perform a first pass through the remaining ambiguities to see whether some where lifted by the previous step which might have removed all but one candidates,
(3) perform a second pass through the remaining ambiguities to see whether previous matchings help in choosing one candidate,
(4) solve the remaining ambiguities through a greedy approach that minimises the maximum inter-pelvis distance of the worst matching.
Following that 4-step process, we produce a list combining both matched and isolated skeletons. </p>
</div>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Skeleton Merging</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.4" class="ltx_p">While isolated skeletons do not require any further processing, pairs of matched skeletons must be merged to form one single skeleton. Many approaches to perform this merging have been explored. They typically filter or attribute weights to data based on known or observed properties of the tracking system, such as whether a given joint is currently occluded for a given sensor.
As we primarily put our focus on the matching logic, the merging of skeletons we perform simply relies on a weighted average based on the tracking confidences reported by the Azure Kinect SDK. We associate a reported confidence of “None” to a weight of <math id="S4.p1.1.m1.1" class="ltx_Math" alttext="0" display="inline"><semantics id="S4.p1.1.m1.1a"><mn id="S4.p1.1.m1.1.1" xref="S4.p1.1.m1.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S4.p1.1.m1.1b"><cn type="integer" id="S4.p1.1.m1.1.1.cmml" xref="S4.p1.1.m1.1.1">0</cn></annotation-xml></semantics></math>, “Low” to <math id="S4.p1.2.m2.1" class="ltx_Math" alttext="0.25" display="inline"><semantics id="S4.p1.2.m2.1a"><mn id="S4.p1.2.m2.1.1" xref="S4.p1.2.m2.1.1.cmml">0.25</mn><annotation-xml encoding="MathML-Content" id="S4.p1.2.m2.1b"><cn type="float" id="S4.p1.2.m2.1.1.cmml" xref="S4.p1.2.m2.1.1">0.25</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.2.m2.1c">0.25</annotation></semantics></math>, “Medium” to <math id="S4.p1.3.m3.1" class="ltx_Math" alttext="0.5" display="inline"><semantics id="S4.p1.3.m3.1a"><mn id="S4.p1.3.m3.1.1" xref="S4.p1.3.m3.1.1.cmml">0.5</mn><annotation-xml encoding="MathML-Content" id="S4.p1.3.m3.1b"><cn type="float" id="S4.p1.3.m3.1.1.cmml" xref="S4.p1.3.m3.1.1">0.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.3.m3.1c">0.5</annotation></semantics></math>, and “High” to <math id="S4.p1.4.m4.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S4.p1.4.m4.1a"><mn id="S4.p1.4.m4.1.1" xref="S4.p1.4.m4.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S4.p1.4.m4.1b"><cn type="integer" id="S4.p1.4.m4.1.1.cmml" xref="S4.p1.4.m4.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.4.m4.1c">1</annotation></semantics></math>, although that latter value does not seem to practically be used at all in the current version of the SDK.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.12" class="ltx_p">For joint <math id="S4.p2.1.m1.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S4.p2.1.m1.1a"><mi id="S4.p2.1.m1.1.1" xref="S4.p2.1.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S4.p2.1.m1.1b"><ci id="S4.p2.1.m1.1.1.cmml" xref="S4.p2.1.m1.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.1.m1.1c">i</annotation></semantics></math> with position <math id="S4.p2.2.m2.1" class="ltx_Math" alttext="\overrightarrow{p_{i}}" display="inline"><semantics id="S4.p2.2.m2.1a"><mover accent="true" id="S4.p2.2.m2.1.1" xref="S4.p2.2.m2.1.1.cmml"><msub id="S4.p2.2.m2.1.1.2" xref="S4.p2.2.m2.1.1.2.cmml"><mi id="S4.p2.2.m2.1.1.2.2" xref="S4.p2.2.m2.1.1.2.2.cmml">p</mi><mi id="S4.p2.2.m2.1.1.2.3" xref="S4.p2.2.m2.1.1.2.3.cmml">i</mi></msub><mo stretchy="false" id="S4.p2.2.m2.1.1.1" xref="S4.p2.2.m2.1.1.1.cmml">→</mo></mover><annotation-xml encoding="MathML-Content" id="S4.p2.2.m2.1b"><apply id="S4.p2.2.m2.1.1.cmml" xref="S4.p2.2.m2.1.1"><ci id="S4.p2.2.m2.1.1.1.cmml" xref="S4.p2.2.m2.1.1.1">→</ci><apply id="S4.p2.2.m2.1.1.2.cmml" xref="S4.p2.2.m2.1.1.2"><csymbol cd="ambiguous" id="S4.p2.2.m2.1.1.2.1.cmml" xref="S4.p2.2.m2.1.1.2">subscript</csymbol><ci id="S4.p2.2.m2.1.1.2.2.cmml" xref="S4.p2.2.m2.1.1.2.2">𝑝</ci><ci id="S4.p2.2.m2.1.1.2.3.cmml" xref="S4.p2.2.m2.1.1.2.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.2.m2.1c">\overrightarrow{p_{i}}</annotation></semantics></math> and whose orientation is encoded as three axis vectors <math id="S4.p2.3.m3.1" class="ltx_Math" alttext="\overrightarrow{x_{i}}" display="inline"><semantics id="S4.p2.3.m3.1a"><mover accent="true" id="S4.p2.3.m3.1.1" xref="S4.p2.3.m3.1.1.cmml"><msub id="S4.p2.3.m3.1.1.2" xref="S4.p2.3.m3.1.1.2.cmml"><mi id="S4.p2.3.m3.1.1.2.2" xref="S4.p2.3.m3.1.1.2.2.cmml">x</mi><mi id="S4.p2.3.m3.1.1.2.3" xref="S4.p2.3.m3.1.1.2.3.cmml">i</mi></msub><mo stretchy="false" id="S4.p2.3.m3.1.1.1" xref="S4.p2.3.m3.1.1.1.cmml">→</mo></mover><annotation-xml encoding="MathML-Content" id="S4.p2.3.m3.1b"><apply id="S4.p2.3.m3.1.1.cmml" xref="S4.p2.3.m3.1.1"><ci id="S4.p2.3.m3.1.1.1.cmml" xref="S4.p2.3.m3.1.1.1">→</ci><apply id="S4.p2.3.m3.1.1.2.cmml" xref="S4.p2.3.m3.1.1.2"><csymbol cd="ambiguous" id="S4.p2.3.m3.1.1.2.1.cmml" xref="S4.p2.3.m3.1.1.2">subscript</csymbol><ci id="S4.p2.3.m3.1.1.2.2.cmml" xref="S4.p2.3.m3.1.1.2.2">𝑥</ci><ci id="S4.p2.3.m3.1.1.2.3.cmml" xref="S4.p2.3.m3.1.1.2.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.3.m3.1c">\overrightarrow{x_{i}}</annotation></semantics></math>, <math id="S4.p2.4.m4.1" class="ltx_Math" alttext="\overrightarrow{y_{i}}" display="inline"><semantics id="S4.p2.4.m4.1a"><mover accent="true" id="S4.p2.4.m4.1.1" xref="S4.p2.4.m4.1.1.cmml"><msub id="S4.p2.4.m4.1.1.2" xref="S4.p2.4.m4.1.1.2.cmml"><mi id="S4.p2.4.m4.1.1.2.2" xref="S4.p2.4.m4.1.1.2.2.cmml">y</mi><mi id="S4.p2.4.m4.1.1.2.3" xref="S4.p2.4.m4.1.1.2.3.cmml">i</mi></msub><mo stretchy="false" id="S4.p2.4.m4.1.1.1" xref="S4.p2.4.m4.1.1.1.cmml">→</mo></mover><annotation-xml encoding="MathML-Content" id="S4.p2.4.m4.1b"><apply id="S4.p2.4.m4.1.1.cmml" xref="S4.p2.4.m4.1.1"><ci id="S4.p2.4.m4.1.1.1.cmml" xref="S4.p2.4.m4.1.1.1">→</ci><apply id="S4.p2.4.m4.1.1.2.cmml" xref="S4.p2.4.m4.1.1.2"><csymbol cd="ambiguous" id="S4.p2.4.m4.1.1.2.1.cmml" xref="S4.p2.4.m4.1.1.2">subscript</csymbol><ci id="S4.p2.4.m4.1.1.2.2.cmml" xref="S4.p2.4.m4.1.1.2.2">𝑦</ci><ci id="S4.p2.4.m4.1.1.2.3.cmml" xref="S4.p2.4.m4.1.1.2.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.4.m4.1c">\overrightarrow{y_{i}}</annotation></semantics></math> and <math id="S4.p2.5.m5.1" class="ltx_Math" alttext="\overrightarrow{z_{i}}" display="inline"><semantics id="S4.p2.5.m5.1a"><mover accent="true" id="S4.p2.5.m5.1.1" xref="S4.p2.5.m5.1.1.cmml"><msub id="S4.p2.5.m5.1.1.2" xref="S4.p2.5.m5.1.1.2.cmml"><mi id="S4.p2.5.m5.1.1.2.2" xref="S4.p2.5.m5.1.1.2.2.cmml">z</mi><mi id="S4.p2.5.m5.1.1.2.3" xref="S4.p2.5.m5.1.1.2.3.cmml">i</mi></msub><mo stretchy="false" id="S4.p2.5.m5.1.1.1" xref="S4.p2.5.m5.1.1.1.cmml">→</mo></mover><annotation-xml encoding="MathML-Content" id="S4.p2.5.m5.1b"><apply id="S4.p2.5.m5.1.1.cmml" xref="S4.p2.5.m5.1.1"><ci id="S4.p2.5.m5.1.1.1.cmml" xref="S4.p2.5.m5.1.1.1">→</ci><apply id="S4.p2.5.m5.1.1.2.cmml" xref="S4.p2.5.m5.1.1.2"><csymbol cd="ambiguous" id="S4.p2.5.m5.1.1.2.1.cmml" xref="S4.p2.5.m5.1.1.2">subscript</csymbol><ci id="S4.p2.5.m5.1.1.2.2.cmml" xref="S4.p2.5.m5.1.1.2.2">𝑧</ci><ci id="S4.p2.5.m5.1.1.2.3.cmml" xref="S4.p2.5.m5.1.1.2.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.5.m5.1c">\overrightarrow{z_{i}}</annotation></semantics></math>, we therefore define a weight <math id="S4.p2.6.m6.1" class="ltx_Math" alttext="w_{i}" display="inline"><semantics id="S4.p2.6.m6.1a"><msub id="S4.p2.6.m6.1.1" xref="S4.p2.6.m6.1.1.cmml"><mi id="S4.p2.6.m6.1.1.2" xref="S4.p2.6.m6.1.1.2.cmml">w</mi><mi id="S4.p2.6.m6.1.1.3" xref="S4.p2.6.m6.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.p2.6.m6.1b"><apply id="S4.p2.6.m6.1.1.cmml" xref="S4.p2.6.m6.1.1"><csymbol cd="ambiguous" id="S4.p2.6.m6.1.1.1.cmml" xref="S4.p2.6.m6.1.1">subscript</csymbol><ci id="S4.p2.6.m6.1.1.2.cmml" xref="S4.p2.6.m6.1.1.2">𝑤</ci><ci id="S4.p2.6.m6.1.1.3.cmml" xref="S4.p2.6.m6.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.6.m6.1c">w_{i}</annotation></semantics></math> based on the above confidence associations.
Similarly, we define a weight <math id="S4.p2.7.m7.1" class="ltx_Math" alttext="w_{j}" display="inline"><semantics id="S4.p2.7.m7.1a"><msub id="S4.p2.7.m7.1.1" xref="S4.p2.7.m7.1.1.cmml"><mi id="S4.p2.7.m7.1.1.2" xref="S4.p2.7.m7.1.1.2.cmml">w</mi><mi id="S4.p2.7.m7.1.1.3" xref="S4.p2.7.m7.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S4.p2.7.m7.1b"><apply id="S4.p2.7.m7.1.1.cmml" xref="S4.p2.7.m7.1.1"><csymbol cd="ambiguous" id="S4.p2.7.m7.1.1.1.cmml" xref="S4.p2.7.m7.1.1">subscript</csymbol><ci id="S4.p2.7.m7.1.1.2.cmml" xref="S4.p2.7.m7.1.1.2">𝑤</ci><ci id="S4.p2.7.m7.1.1.3.cmml" xref="S4.p2.7.m7.1.1.3">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.7.m7.1c">w_{j}</annotation></semantics></math> for joint <math id="S4.p2.8.m8.1" class="ltx_Math" alttext="j" display="inline"><semantics id="S4.p2.8.m8.1a"><mi id="S4.p2.8.m8.1.1" xref="S4.p2.8.m8.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S4.p2.8.m8.1b"><ci id="S4.p2.8.m8.1.1.cmml" xref="S4.p2.8.m8.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.8.m8.1c">j</annotation></semantics></math>, with position <math id="S4.p2.9.m9.1" class="ltx_Math" alttext="\overrightarrow{p_{j}}" display="inline"><semantics id="S4.p2.9.m9.1a"><mover accent="true" id="S4.p2.9.m9.1.1" xref="S4.p2.9.m9.1.1.cmml"><msub id="S4.p2.9.m9.1.1.2" xref="S4.p2.9.m9.1.1.2.cmml"><mi id="S4.p2.9.m9.1.1.2.2" xref="S4.p2.9.m9.1.1.2.2.cmml">p</mi><mi id="S4.p2.9.m9.1.1.2.3" xref="S4.p2.9.m9.1.1.2.3.cmml">j</mi></msub><mo stretchy="false" id="S4.p2.9.m9.1.1.1" xref="S4.p2.9.m9.1.1.1.cmml">→</mo></mover><annotation-xml encoding="MathML-Content" id="S4.p2.9.m9.1b"><apply id="S4.p2.9.m9.1.1.cmml" xref="S4.p2.9.m9.1.1"><ci id="S4.p2.9.m9.1.1.1.cmml" xref="S4.p2.9.m9.1.1.1">→</ci><apply id="S4.p2.9.m9.1.1.2.cmml" xref="S4.p2.9.m9.1.1.2"><csymbol cd="ambiguous" id="S4.p2.9.m9.1.1.2.1.cmml" xref="S4.p2.9.m9.1.1.2">subscript</csymbol><ci id="S4.p2.9.m9.1.1.2.2.cmml" xref="S4.p2.9.m9.1.1.2.2">𝑝</ci><ci id="S4.p2.9.m9.1.1.2.3.cmml" xref="S4.p2.9.m9.1.1.2.3">𝑗</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.9.m9.1c">\overrightarrow{p_{j}}</annotation></semantics></math> and orientation <math id="S4.p2.10.m10.3" class="ltx_Math" alttext="(\overrightarrow{x_{j}},\overrightarrow{y_{j}},\overrightarrow{z_{j}})" display="inline"><semantics id="S4.p2.10.m10.3a"><mrow id="S4.p2.10.m10.3.4.2" xref="S4.p2.10.m10.3.4.1.cmml"><mo stretchy="false" id="S4.p2.10.m10.3.4.2.1" xref="S4.p2.10.m10.3.4.1.cmml">(</mo><mover accent="true" id="S4.p2.10.m10.1.1" xref="S4.p2.10.m10.1.1.cmml"><msub id="S4.p2.10.m10.1.1.2" xref="S4.p2.10.m10.1.1.2.cmml"><mi id="S4.p2.10.m10.1.1.2.2" xref="S4.p2.10.m10.1.1.2.2.cmml">x</mi><mi id="S4.p2.10.m10.1.1.2.3" xref="S4.p2.10.m10.1.1.2.3.cmml">j</mi></msub><mo stretchy="false" id="S4.p2.10.m10.1.1.1" xref="S4.p2.10.m10.1.1.1.cmml">→</mo></mover><mo id="S4.p2.10.m10.3.4.2.2" xref="S4.p2.10.m10.3.4.1.cmml">,</mo><mover accent="true" id="S4.p2.10.m10.2.2" xref="S4.p2.10.m10.2.2.cmml"><msub id="S4.p2.10.m10.2.2.2" xref="S4.p2.10.m10.2.2.2.cmml"><mi id="S4.p2.10.m10.2.2.2.2" xref="S4.p2.10.m10.2.2.2.2.cmml">y</mi><mi id="S4.p2.10.m10.2.2.2.3" xref="S4.p2.10.m10.2.2.2.3.cmml">j</mi></msub><mo stretchy="false" id="S4.p2.10.m10.2.2.1" xref="S4.p2.10.m10.2.2.1.cmml">→</mo></mover><mo id="S4.p2.10.m10.3.4.2.3" xref="S4.p2.10.m10.3.4.1.cmml">,</mo><mover accent="true" id="S4.p2.10.m10.3.3" xref="S4.p2.10.m10.3.3.cmml"><msub id="S4.p2.10.m10.3.3.2" xref="S4.p2.10.m10.3.3.2.cmml"><mi id="S4.p2.10.m10.3.3.2.2" xref="S4.p2.10.m10.3.3.2.2.cmml">z</mi><mi id="S4.p2.10.m10.3.3.2.3" xref="S4.p2.10.m10.3.3.2.3.cmml">j</mi></msub><mo stretchy="false" id="S4.p2.10.m10.3.3.1" xref="S4.p2.10.m10.3.3.1.cmml">→</mo></mover><mo stretchy="false" id="S4.p2.10.m10.3.4.2.4" xref="S4.p2.10.m10.3.4.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.p2.10.m10.3b"><vector id="S4.p2.10.m10.3.4.1.cmml" xref="S4.p2.10.m10.3.4.2"><apply id="S4.p2.10.m10.1.1.cmml" xref="S4.p2.10.m10.1.1"><ci id="S4.p2.10.m10.1.1.1.cmml" xref="S4.p2.10.m10.1.1.1">→</ci><apply id="S4.p2.10.m10.1.1.2.cmml" xref="S4.p2.10.m10.1.1.2"><csymbol cd="ambiguous" id="S4.p2.10.m10.1.1.2.1.cmml" xref="S4.p2.10.m10.1.1.2">subscript</csymbol><ci id="S4.p2.10.m10.1.1.2.2.cmml" xref="S4.p2.10.m10.1.1.2.2">𝑥</ci><ci id="S4.p2.10.m10.1.1.2.3.cmml" xref="S4.p2.10.m10.1.1.2.3">𝑗</ci></apply></apply><apply id="S4.p2.10.m10.2.2.cmml" xref="S4.p2.10.m10.2.2"><ci id="S4.p2.10.m10.2.2.1.cmml" xref="S4.p2.10.m10.2.2.1">→</ci><apply id="S4.p2.10.m10.2.2.2.cmml" xref="S4.p2.10.m10.2.2.2"><csymbol cd="ambiguous" id="S4.p2.10.m10.2.2.2.1.cmml" xref="S4.p2.10.m10.2.2.2">subscript</csymbol><ci id="S4.p2.10.m10.2.2.2.2.cmml" xref="S4.p2.10.m10.2.2.2.2">𝑦</ci><ci id="S4.p2.10.m10.2.2.2.3.cmml" xref="S4.p2.10.m10.2.2.2.3">𝑗</ci></apply></apply><apply id="S4.p2.10.m10.3.3.cmml" xref="S4.p2.10.m10.3.3"><ci id="S4.p2.10.m10.3.3.1.cmml" xref="S4.p2.10.m10.3.3.1">→</ci><apply id="S4.p2.10.m10.3.3.2.cmml" xref="S4.p2.10.m10.3.3.2"><csymbol cd="ambiguous" id="S4.p2.10.m10.3.3.2.1.cmml" xref="S4.p2.10.m10.3.3.2">subscript</csymbol><ci id="S4.p2.10.m10.3.3.2.2.cmml" xref="S4.p2.10.m10.3.3.2.2">𝑧</ci><ci id="S4.p2.10.m10.3.3.2.3.cmml" xref="S4.p2.10.m10.3.3.2.3">𝑗</ci></apply></apply></vector></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.10.m10.3c">(\overrightarrow{x_{j}},\overrightarrow{y_{j}},\overrightarrow{z_{j}})</annotation></semantics></math>.
We compute the merged position <math id="S4.p2.11.m11.1" class="ltx_Math" alttext="\overrightarrow{p_{m}}=\overrightarrow{p_{i}}+\frac{w_{j}}{w_{i}+w_{j}}*(\overrightarrow{p_{j}}-\overrightarrow{p_{i}})" display="inline"><semantics id="S4.p2.11.m11.1a"><mrow id="S4.p2.11.m11.1.1" xref="S4.p2.11.m11.1.1.cmml"><mover accent="true" id="S4.p2.11.m11.1.1.3" xref="S4.p2.11.m11.1.1.3.cmml"><msub id="S4.p2.11.m11.1.1.3.2" xref="S4.p2.11.m11.1.1.3.2.cmml"><mi id="S4.p2.11.m11.1.1.3.2.2" xref="S4.p2.11.m11.1.1.3.2.2.cmml">p</mi><mi id="S4.p2.11.m11.1.1.3.2.3" xref="S4.p2.11.m11.1.1.3.2.3.cmml">m</mi></msub><mo stretchy="false" id="S4.p2.11.m11.1.1.3.1" xref="S4.p2.11.m11.1.1.3.1.cmml">→</mo></mover><mo id="S4.p2.11.m11.1.1.2" xref="S4.p2.11.m11.1.1.2.cmml">=</mo><mrow id="S4.p2.11.m11.1.1.1" xref="S4.p2.11.m11.1.1.1.cmml"><mover accent="true" id="S4.p2.11.m11.1.1.1.3" xref="S4.p2.11.m11.1.1.1.3.cmml"><msub id="S4.p2.11.m11.1.1.1.3.2" xref="S4.p2.11.m11.1.1.1.3.2.cmml"><mi id="S4.p2.11.m11.1.1.1.3.2.2" xref="S4.p2.11.m11.1.1.1.3.2.2.cmml">p</mi><mi id="S4.p2.11.m11.1.1.1.3.2.3" xref="S4.p2.11.m11.1.1.1.3.2.3.cmml">i</mi></msub><mo stretchy="false" id="S4.p2.11.m11.1.1.1.3.1" xref="S4.p2.11.m11.1.1.1.3.1.cmml">→</mo></mover><mo id="S4.p2.11.m11.1.1.1.2" xref="S4.p2.11.m11.1.1.1.2.cmml">+</mo><mrow id="S4.p2.11.m11.1.1.1.1" xref="S4.p2.11.m11.1.1.1.1.cmml"><mfrac id="S4.p2.11.m11.1.1.1.1.3" xref="S4.p2.11.m11.1.1.1.1.3.cmml"><msub id="S4.p2.11.m11.1.1.1.1.3.2" xref="S4.p2.11.m11.1.1.1.1.3.2.cmml"><mi id="S4.p2.11.m11.1.1.1.1.3.2.2" xref="S4.p2.11.m11.1.1.1.1.3.2.2.cmml">w</mi><mi id="S4.p2.11.m11.1.1.1.1.3.2.3" xref="S4.p2.11.m11.1.1.1.1.3.2.3.cmml">j</mi></msub><mrow id="S4.p2.11.m11.1.1.1.1.3.3" xref="S4.p2.11.m11.1.1.1.1.3.3.cmml"><msub id="S4.p2.11.m11.1.1.1.1.3.3.2" xref="S4.p2.11.m11.1.1.1.1.3.3.2.cmml"><mi id="S4.p2.11.m11.1.1.1.1.3.3.2.2" xref="S4.p2.11.m11.1.1.1.1.3.3.2.2.cmml">w</mi><mi id="S4.p2.11.m11.1.1.1.1.3.3.2.3" xref="S4.p2.11.m11.1.1.1.1.3.3.2.3.cmml">i</mi></msub><mo id="S4.p2.11.m11.1.1.1.1.3.3.1" xref="S4.p2.11.m11.1.1.1.1.3.3.1.cmml">+</mo><msub id="S4.p2.11.m11.1.1.1.1.3.3.3" xref="S4.p2.11.m11.1.1.1.1.3.3.3.cmml"><mi id="S4.p2.11.m11.1.1.1.1.3.3.3.2" xref="S4.p2.11.m11.1.1.1.1.3.3.3.2.cmml">w</mi><mi id="S4.p2.11.m11.1.1.1.1.3.3.3.3" xref="S4.p2.11.m11.1.1.1.1.3.3.3.3.cmml">j</mi></msub></mrow></mfrac><mo lspace="0.222em" rspace="0.222em" id="S4.p2.11.m11.1.1.1.1.2" xref="S4.p2.11.m11.1.1.1.1.2.cmml">∗</mo><mrow id="S4.p2.11.m11.1.1.1.1.1.1" xref="S4.p2.11.m11.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.p2.11.m11.1.1.1.1.1.1.2" xref="S4.p2.11.m11.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.p2.11.m11.1.1.1.1.1.1.1" xref="S4.p2.11.m11.1.1.1.1.1.1.1.cmml"><mover accent="true" id="S4.p2.11.m11.1.1.1.1.1.1.1.2" xref="S4.p2.11.m11.1.1.1.1.1.1.1.2.cmml"><msub id="S4.p2.11.m11.1.1.1.1.1.1.1.2.2" xref="S4.p2.11.m11.1.1.1.1.1.1.1.2.2.cmml"><mi id="S4.p2.11.m11.1.1.1.1.1.1.1.2.2.2" xref="S4.p2.11.m11.1.1.1.1.1.1.1.2.2.2.cmml">p</mi><mi id="S4.p2.11.m11.1.1.1.1.1.1.1.2.2.3" xref="S4.p2.11.m11.1.1.1.1.1.1.1.2.2.3.cmml">j</mi></msub><mo stretchy="false" id="S4.p2.11.m11.1.1.1.1.1.1.1.2.1" xref="S4.p2.11.m11.1.1.1.1.1.1.1.2.1.cmml">→</mo></mover><mo id="S4.p2.11.m11.1.1.1.1.1.1.1.1" xref="S4.p2.11.m11.1.1.1.1.1.1.1.1.cmml">−</mo><mover accent="true" id="S4.p2.11.m11.1.1.1.1.1.1.1.3" xref="S4.p2.11.m11.1.1.1.1.1.1.1.3.cmml"><msub id="S4.p2.11.m11.1.1.1.1.1.1.1.3.2" xref="S4.p2.11.m11.1.1.1.1.1.1.1.3.2.cmml"><mi id="S4.p2.11.m11.1.1.1.1.1.1.1.3.2.2" xref="S4.p2.11.m11.1.1.1.1.1.1.1.3.2.2.cmml">p</mi><mi id="S4.p2.11.m11.1.1.1.1.1.1.1.3.2.3" xref="S4.p2.11.m11.1.1.1.1.1.1.1.3.2.3.cmml">i</mi></msub><mo stretchy="false" id="S4.p2.11.m11.1.1.1.1.1.1.1.3.1" xref="S4.p2.11.m11.1.1.1.1.1.1.1.3.1.cmml">→</mo></mover></mrow><mo stretchy="false" id="S4.p2.11.m11.1.1.1.1.1.1.3" xref="S4.p2.11.m11.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.p2.11.m11.1b"><apply id="S4.p2.11.m11.1.1.cmml" xref="S4.p2.11.m11.1.1"><eq id="S4.p2.11.m11.1.1.2.cmml" xref="S4.p2.11.m11.1.1.2"></eq><apply id="S4.p2.11.m11.1.1.3.cmml" xref="S4.p2.11.m11.1.1.3"><ci id="S4.p2.11.m11.1.1.3.1.cmml" xref="S4.p2.11.m11.1.1.3.1">→</ci><apply id="S4.p2.11.m11.1.1.3.2.cmml" xref="S4.p2.11.m11.1.1.3.2"><csymbol cd="ambiguous" id="S4.p2.11.m11.1.1.3.2.1.cmml" xref="S4.p2.11.m11.1.1.3.2">subscript</csymbol><ci id="S4.p2.11.m11.1.1.3.2.2.cmml" xref="S4.p2.11.m11.1.1.3.2.2">𝑝</ci><ci id="S4.p2.11.m11.1.1.3.2.3.cmml" xref="S4.p2.11.m11.1.1.3.2.3">𝑚</ci></apply></apply><apply id="S4.p2.11.m11.1.1.1.cmml" xref="S4.p2.11.m11.1.1.1"><plus id="S4.p2.11.m11.1.1.1.2.cmml" xref="S4.p2.11.m11.1.1.1.2"></plus><apply id="S4.p2.11.m11.1.1.1.3.cmml" xref="S4.p2.11.m11.1.1.1.3"><ci id="S4.p2.11.m11.1.1.1.3.1.cmml" xref="S4.p2.11.m11.1.1.1.3.1">→</ci><apply id="S4.p2.11.m11.1.1.1.3.2.cmml" xref="S4.p2.11.m11.1.1.1.3.2"><csymbol cd="ambiguous" id="S4.p2.11.m11.1.1.1.3.2.1.cmml" xref="S4.p2.11.m11.1.1.1.3.2">subscript</csymbol><ci id="S4.p2.11.m11.1.1.1.3.2.2.cmml" xref="S4.p2.11.m11.1.1.1.3.2.2">𝑝</ci><ci id="S4.p2.11.m11.1.1.1.3.2.3.cmml" xref="S4.p2.11.m11.1.1.1.3.2.3">𝑖</ci></apply></apply><apply id="S4.p2.11.m11.1.1.1.1.cmml" xref="S4.p2.11.m11.1.1.1.1"><times id="S4.p2.11.m11.1.1.1.1.2.cmml" xref="S4.p2.11.m11.1.1.1.1.2"></times><apply id="S4.p2.11.m11.1.1.1.1.3.cmml" xref="S4.p2.11.m11.1.1.1.1.3"><divide id="S4.p2.11.m11.1.1.1.1.3.1.cmml" xref="S4.p2.11.m11.1.1.1.1.3"></divide><apply id="S4.p2.11.m11.1.1.1.1.3.2.cmml" xref="S4.p2.11.m11.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S4.p2.11.m11.1.1.1.1.3.2.1.cmml" xref="S4.p2.11.m11.1.1.1.1.3.2">subscript</csymbol><ci id="S4.p2.11.m11.1.1.1.1.3.2.2.cmml" xref="S4.p2.11.m11.1.1.1.1.3.2.2">𝑤</ci><ci id="S4.p2.11.m11.1.1.1.1.3.2.3.cmml" xref="S4.p2.11.m11.1.1.1.1.3.2.3">𝑗</ci></apply><apply id="S4.p2.11.m11.1.1.1.1.3.3.cmml" xref="S4.p2.11.m11.1.1.1.1.3.3"><plus id="S4.p2.11.m11.1.1.1.1.3.3.1.cmml" xref="S4.p2.11.m11.1.1.1.1.3.3.1"></plus><apply id="S4.p2.11.m11.1.1.1.1.3.3.2.cmml" xref="S4.p2.11.m11.1.1.1.1.3.3.2"><csymbol cd="ambiguous" id="S4.p2.11.m11.1.1.1.1.3.3.2.1.cmml" xref="S4.p2.11.m11.1.1.1.1.3.3.2">subscript</csymbol><ci id="S4.p2.11.m11.1.1.1.1.3.3.2.2.cmml" xref="S4.p2.11.m11.1.1.1.1.3.3.2.2">𝑤</ci><ci id="S4.p2.11.m11.1.1.1.1.3.3.2.3.cmml" xref="S4.p2.11.m11.1.1.1.1.3.3.2.3">𝑖</ci></apply><apply id="S4.p2.11.m11.1.1.1.1.3.3.3.cmml" xref="S4.p2.11.m11.1.1.1.1.3.3.3"><csymbol cd="ambiguous" id="S4.p2.11.m11.1.1.1.1.3.3.3.1.cmml" xref="S4.p2.11.m11.1.1.1.1.3.3.3">subscript</csymbol><ci id="S4.p2.11.m11.1.1.1.1.3.3.3.2.cmml" xref="S4.p2.11.m11.1.1.1.1.3.3.3.2">𝑤</ci><ci id="S4.p2.11.m11.1.1.1.1.3.3.3.3.cmml" xref="S4.p2.11.m11.1.1.1.1.3.3.3.3">𝑗</ci></apply></apply></apply><apply id="S4.p2.11.m11.1.1.1.1.1.1.1.cmml" xref="S4.p2.11.m11.1.1.1.1.1.1"><minus id="S4.p2.11.m11.1.1.1.1.1.1.1.1.cmml" xref="S4.p2.11.m11.1.1.1.1.1.1.1.1"></minus><apply id="S4.p2.11.m11.1.1.1.1.1.1.1.2.cmml" xref="S4.p2.11.m11.1.1.1.1.1.1.1.2"><ci id="S4.p2.11.m11.1.1.1.1.1.1.1.2.1.cmml" xref="S4.p2.11.m11.1.1.1.1.1.1.1.2.1">→</ci><apply id="S4.p2.11.m11.1.1.1.1.1.1.1.2.2.cmml" xref="S4.p2.11.m11.1.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S4.p2.11.m11.1.1.1.1.1.1.1.2.2.1.cmml" xref="S4.p2.11.m11.1.1.1.1.1.1.1.2.2">subscript</csymbol><ci id="S4.p2.11.m11.1.1.1.1.1.1.1.2.2.2.cmml" xref="S4.p2.11.m11.1.1.1.1.1.1.1.2.2.2">𝑝</ci><ci id="S4.p2.11.m11.1.1.1.1.1.1.1.2.2.3.cmml" xref="S4.p2.11.m11.1.1.1.1.1.1.1.2.2.3">𝑗</ci></apply></apply><apply id="S4.p2.11.m11.1.1.1.1.1.1.1.3.cmml" xref="S4.p2.11.m11.1.1.1.1.1.1.1.3"><ci id="S4.p2.11.m11.1.1.1.1.1.1.1.3.1.cmml" xref="S4.p2.11.m11.1.1.1.1.1.1.1.3.1">→</ci><apply id="S4.p2.11.m11.1.1.1.1.1.1.1.3.2.cmml" xref="S4.p2.11.m11.1.1.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S4.p2.11.m11.1.1.1.1.1.1.1.3.2.1.cmml" xref="S4.p2.11.m11.1.1.1.1.1.1.1.3.2">subscript</csymbol><ci id="S4.p2.11.m11.1.1.1.1.1.1.1.3.2.2.cmml" xref="S4.p2.11.m11.1.1.1.1.1.1.1.3.2.2">𝑝</ci><ci id="S4.p2.11.m11.1.1.1.1.1.1.1.3.2.3.cmml" xref="S4.p2.11.m11.1.1.1.1.1.1.1.3.2.3">𝑖</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.11.m11.1c">\overrightarrow{p_{m}}=\overrightarrow{p_{i}}+\frac{w_{j}}{w_{i}+w_{j}}*(\overrightarrow{p_{j}}-\overrightarrow{p_{i}})</annotation></semantics></math>, as well as the merged orientation <math id="S4.p2.12.m12.3" class="ltx_Math" alttext="(\overrightarrow{x_{m}},\overrightarrow{y_{m}},\overrightarrow{z_{m}})" display="inline"><semantics id="S4.p2.12.m12.3a"><mrow id="S4.p2.12.m12.3.4.2" xref="S4.p2.12.m12.3.4.1.cmml"><mo stretchy="false" id="S4.p2.12.m12.3.4.2.1" xref="S4.p2.12.m12.3.4.1.cmml">(</mo><mover accent="true" id="S4.p2.12.m12.1.1" xref="S4.p2.12.m12.1.1.cmml"><msub id="S4.p2.12.m12.1.1.2" xref="S4.p2.12.m12.1.1.2.cmml"><mi id="S4.p2.12.m12.1.1.2.2" xref="S4.p2.12.m12.1.1.2.2.cmml">x</mi><mi id="S4.p2.12.m12.1.1.2.3" xref="S4.p2.12.m12.1.1.2.3.cmml">m</mi></msub><mo stretchy="false" id="S4.p2.12.m12.1.1.1" xref="S4.p2.12.m12.1.1.1.cmml">→</mo></mover><mo id="S4.p2.12.m12.3.4.2.2" xref="S4.p2.12.m12.3.4.1.cmml">,</mo><mover accent="true" id="S4.p2.12.m12.2.2" xref="S4.p2.12.m12.2.2.cmml"><msub id="S4.p2.12.m12.2.2.2" xref="S4.p2.12.m12.2.2.2.cmml"><mi id="S4.p2.12.m12.2.2.2.2" xref="S4.p2.12.m12.2.2.2.2.cmml">y</mi><mi id="S4.p2.12.m12.2.2.2.3" xref="S4.p2.12.m12.2.2.2.3.cmml">m</mi></msub><mo stretchy="false" id="S4.p2.12.m12.2.2.1" xref="S4.p2.12.m12.2.2.1.cmml">→</mo></mover><mo id="S4.p2.12.m12.3.4.2.3" xref="S4.p2.12.m12.3.4.1.cmml">,</mo><mover accent="true" id="S4.p2.12.m12.3.3" xref="S4.p2.12.m12.3.3.cmml"><msub id="S4.p2.12.m12.3.3.2" xref="S4.p2.12.m12.3.3.2.cmml"><mi id="S4.p2.12.m12.3.3.2.2" xref="S4.p2.12.m12.3.3.2.2.cmml">z</mi><mi id="S4.p2.12.m12.3.3.2.3" xref="S4.p2.12.m12.3.3.2.3.cmml">m</mi></msub><mo stretchy="false" id="S4.p2.12.m12.3.3.1" xref="S4.p2.12.m12.3.3.1.cmml">→</mo></mover><mo stretchy="false" id="S4.p2.12.m12.3.4.2.4" xref="S4.p2.12.m12.3.4.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.p2.12.m12.3b"><vector id="S4.p2.12.m12.3.4.1.cmml" xref="S4.p2.12.m12.3.4.2"><apply id="S4.p2.12.m12.1.1.cmml" xref="S4.p2.12.m12.1.1"><ci id="S4.p2.12.m12.1.1.1.cmml" xref="S4.p2.12.m12.1.1.1">→</ci><apply id="S4.p2.12.m12.1.1.2.cmml" xref="S4.p2.12.m12.1.1.2"><csymbol cd="ambiguous" id="S4.p2.12.m12.1.1.2.1.cmml" xref="S4.p2.12.m12.1.1.2">subscript</csymbol><ci id="S4.p2.12.m12.1.1.2.2.cmml" xref="S4.p2.12.m12.1.1.2.2">𝑥</ci><ci id="S4.p2.12.m12.1.1.2.3.cmml" xref="S4.p2.12.m12.1.1.2.3">𝑚</ci></apply></apply><apply id="S4.p2.12.m12.2.2.cmml" xref="S4.p2.12.m12.2.2"><ci id="S4.p2.12.m12.2.2.1.cmml" xref="S4.p2.12.m12.2.2.1">→</ci><apply id="S4.p2.12.m12.2.2.2.cmml" xref="S4.p2.12.m12.2.2.2"><csymbol cd="ambiguous" id="S4.p2.12.m12.2.2.2.1.cmml" xref="S4.p2.12.m12.2.2.2">subscript</csymbol><ci id="S4.p2.12.m12.2.2.2.2.cmml" xref="S4.p2.12.m12.2.2.2.2">𝑦</ci><ci id="S4.p2.12.m12.2.2.2.3.cmml" xref="S4.p2.12.m12.2.2.2.3">𝑚</ci></apply></apply><apply id="S4.p2.12.m12.3.3.cmml" xref="S4.p2.12.m12.3.3"><ci id="S4.p2.12.m12.3.3.1.cmml" xref="S4.p2.12.m12.3.3.1">→</ci><apply id="S4.p2.12.m12.3.3.2.cmml" xref="S4.p2.12.m12.3.3.2"><csymbol cd="ambiguous" id="S4.p2.12.m12.3.3.2.1.cmml" xref="S4.p2.12.m12.3.3.2">subscript</csymbol><ci id="S4.p2.12.m12.3.3.2.2.cmml" xref="S4.p2.12.m12.3.3.2.2">𝑧</ci><ci id="S4.p2.12.m12.3.3.2.3.cmml" xref="S4.p2.12.m12.3.3.2.3">𝑚</ci></apply></apply></vector></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.12.m12.3c">(\overrightarrow{x_{m}},\overrightarrow{y_{m}},\overrightarrow{z_{m}})</annotation></semantics></math> through:</p>
<table id="S4.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E1.m1.6" class="ltx_Math" alttext="\begin{cases}\overrightarrow{x_{m}}=&amp;\overrightarrow{x_{i}}+\frac{w_{j}}{w_{i}+w_{j}}*(\overrightarrow{x_{j}}-\overrightarrow{x_{i}})\\
\overrightarrow{y_{m}}=&amp;\overrightarrow{y_{i}}+\frac{w_{j}}{w_{i}+w_{j}}*(\overrightarrow{y_{j}}-\overrightarrow{y_{i}})\\
\overrightarrow{z_{m}}=&amp;\overrightarrow{z_{i}}+\frac{w_{j}}{w_{i}+w_{j}}*(\overrightarrow{z_{j}}-\overrightarrow{z_{i}})\end{cases}" display="block"><semantics id="S4.E1.m1.6a"><mrow id="S4.E1.m1.6.6" xref="S4.E1.m1.6.7.1.cmml"><mo id="S4.E1.m1.6.6.7" xref="S4.E1.m1.6.7.1.1.cmml">{</mo><mtable columnspacing="5pt" displaystyle="true" rowspacing="0pt" id="S4.E1.m1.6.6.6" xref="S4.E1.m1.6.7.1.cmml"><mtr id="S4.E1.m1.6.6.6a" xref="S4.E1.m1.6.7.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S4.E1.m1.6.6.6b" xref="S4.E1.m1.6.7.1.cmml"><mrow id="S4.E1.m1.1.1.1.1.1.1" xref="S4.E1.m1.1.1.1.1.1.1.cmml"><mover accent="true" id="S4.E1.m1.1.1.1.1.1.1.2" xref="S4.E1.m1.1.1.1.1.1.1.2.cmml"><msub id="S4.E1.m1.1.1.1.1.1.1.2.2" xref="S4.E1.m1.1.1.1.1.1.1.2.2.cmml"><mi id="S4.E1.m1.1.1.1.1.1.1.2.2.2" xref="S4.E1.m1.1.1.1.1.1.1.2.2.2.cmml">x</mi><mi id="S4.E1.m1.1.1.1.1.1.1.2.2.3" xref="S4.E1.m1.1.1.1.1.1.1.2.2.3.cmml">m</mi></msub><mo stretchy="false" id="S4.E1.m1.1.1.1.1.1.1.2.1" xref="S4.E1.m1.1.1.1.1.1.1.2.1.cmml">→</mo></mover><mo id="S4.E1.m1.1.1.1.1.1.1.1" xref="S4.E1.m1.1.1.1.1.1.1.1.cmml">=</mo><mi id="S4.E1.m1.1.1.1.1.1.1.3" xref="S4.E1.m1.1.1.1.1.1.1.3.cmml"></mi></mrow></mtd><mtd class="ltx_align_left" columnalign="left" id="S4.E1.m1.6.6.6c" xref="S4.E1.m1.6.7.1.cmml"><mrow id="S4.E1.m1.2.2.2.2.2.1" xref="S4.E1.m1.2.2.2.2.2.1.cmml"><mover accent="true" id="S4.E1.m1.2.2.2.2.2.1.3" xref="S4.E1.m1.2.2.2.2.2.1.3.cmml"><msub id="S4.E1.m1.2.2.2.2.2.1.3.2" xref="S4.E1.m1.2.2.2.2.2.1.3.2.cmml"><mi id="S4.E1.m1.2.2.2.2.2.1.3.2.2" xref="S4.E1.m1.2.2.2.2.2.1.3.2.2.cmml">x</mi><mi id="S4.E1.m1.2.2.2.2.2.1.3.2.3" xref="S4.E1.m1.2.2.2.2.2.1.3.2.3.cmml">i</mi></msub><mo stretchy="false" id="S4.E1.m1.2.2.2.2.2.1.3.1" xref="S4.E1.m1.2.2.2.2.2.1.3.1.cmml">→</mo></mover><mo id="S4.E1.m1.2.2.2.2.2.1.2" xref="S4.E1.m1.2.2.2.2.2.1.2.cmml">+</mo><mrow id="S4.E1.m1.2.2.2.2.2.1.1" xref="S4.E1.m1.2.2.2.2.2.1.1.cmml"><mstyle displaystyle="false" id="S4.E1.m1.2.2.2.2.2.1.1.3" xref="S4.E1.m1.2.2.2.2.2.1.1.3.cmml"><mfrac id="S4.E1.m1.2.2.2.2.2.1.1.3a" xref="S4.E1.m1.2.2.2.2.2.1.1.3.cmml"><msub id="S4.E1.m1.2.2.2.2.2.1.1.3.2" xref="S4.E1.m1.2.2.2.2.2.1.1.3.2.cmml"><mi id="S4.E1.m1.2.2.2.2.2.1.1.3.2.2" xref="S4.E1.m1.2.2.2.2.2.1.1.3.2.2.cmml">w</mi><mi id="S4.E1.m1.2.2.2.2.2.1.1.3.2.3" xref="S4.E1.m1.2.2.2.2.2.1.1.3.2.3.cmml">j</mi></msub><mrow id="S4.E1.m1.2.2.2.2.2.1.1.3.3" xref="S4.E1.m1.2.2.2.2.2.1.1.3.3.cmml"><msub id="S4.E1.m1.2.2.2.2.2.1.1.3.3.2" xref="S4.E1.m1.2.2.2.2.2.1.1.3.3.2.cmml"><mi id="S4.E1.m1.2.2.2.2.2.1.1.3.3.2.2" xref="S4.E1.m1.2.2.2.2.2.1.1.3.3.2.2.cmml">w</mi><mi id="S4.E1.m1.2.2.2.2.2.1.1.3.3.2.3" xref="S4.E1.m1.2.2.2.2.2.1.1.3.3.2.3.cmml">i</mi></msub><mo id="S4.E1.m1.2.2.2.2.2.1.1.3.3.1" xref="S4.E1.m1.2.2.2.2.2.1.1.3.3.1.cmml">+</mo><msub id="S4.E1.m1.2.2.2.2.2.1.1.3.3.3" xref="S4.E1.m1.2.2.2.2.2.1.1.3.3.3.cmml"><mi id="S4.E1.m1.2.2.2.2.2.1.1.3.3.3.2" xref="S4.E1.m1.2.2.2.2.2.1.1.3.3.3.2.cmml">w</mi><mi id="S4.E1.m1.2.2.2.2.2.1.1.3.3.3.3" xref="S4.E1.m1.2.2.2.2.2.1.1.3.3.3.3.cmml">j</mi></msub></mrow></mfrac></mstyle><mo lspace="0.222em" rspace="0.222em" id="S4.E1.m1.2.2.2.2.2.1.1.2" xref="S4.E1.m1.2.2.2.2.2.1.1.2.cmml">∗</mo><mrow id="S4.E1.m1.2.2.2.2.2.1.1.1.1" xref="S4.E1.m1.2.2.2.2.2.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.E1.m1.2.2.2.2.2.1.1.1.1.2" xref="S4.E1.m1.2.2.2.2.2.1.1.1.1.1.cmml">(</mo><mrow id="S4.E1.m1.2.2.2.2.2.1.1.1.1.1" xref="S4.E1.m1.2.2.2.2.2.1.1.1.1.1.cmml"><mover accent="true" id="S4.E1.m1.2.2.2.2.2.1.1.1.1.1.2" xref="S4.E1.m1.2.2.2.2.2.1.1.1.1.1.2.cmml"><msub id="S4.E1.m1.2.2.2.2.2.1.1.1.1.1.2.2" xref="S4.E1.m1.2.2.2.2.2.1.1.1.1.1.2.2.cmml"><mi id="S4.E1.m1.2.2.2.2.2.1.1.1.1.1.2.2.2" xref="S4.E1.m1.2.2.2.2.2.1.1.1.1.1.2.2.2.cmml">x</mi><mi id="S4.E1.m1.2.2.2.2.2.1.1.1.1.1.2.2.3" xref="S4.E1.m1.2.2.2.2.2.1.1.1.1.1.2.2.3.cmml">j</mi></msub><mo stretchy="false" id="S4.E1.m1.2.2.2.2.2.1.1.1.1.1.2.1" xref="S4.E1.m1.2.2.2.2.2.1.1.1.1.1.2.1.cmml">→</mo></mover><mo id="S4.E1.m1.2.2.2.2.2.1.1.1.1.1.1" xref="S4.E1.m1.2.2.2.2.2.1.1.1.1.1.1.cmml">−</mo><mover accent="true" id="S4.E1.m1.2.2.2.2.2.1.1.1.1.1.3" xref="S4.E1.m1.2.2.2.2.2.1.1.1.1.1.3.cmml"><msub id="S4.E1.m1.2.2.2.2.2.1.1.1.1.1.3.2" xref="S4.E1.m1.2.2.2.2.2.1.1.1.1.1.3.2.cmml"><mi id="S4.E1.m1.2.2.2.2.2.1.1.1.1.1.3.2.2" xref="S4.E1.m1.2.2.2.2.2.1.1.1.1.1.3.2.2.cmml">x</mi><mi id="S4.E1.m1.2.2.2.2.2.1.1.1.1.1.3.2.3" xref="S4.E1.m1.2.2.2.2.2.1.1.1.1.1.3.2.3.cmml">i</mi></msub><mo stretchy="false" id="S4.E1.m1.2.2.2.2.2.1.1.1.1.1.3.1" xref="S4.E1.m1.2.2.2.2.2.1.1.1.1.1.3.1.cmml">→</mo></mover></mrow><mo stretchy="false" id="S4.E1.m1.2.2.2.2.2.1.1.1.1.3" xref="S4.E1.m1.2.2.2.2.2.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mtd></mtr><mtr id="S4.E1.m1.6.6.6d" xref="S4.E1.m1.6.7.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S4.E1.m1.6.6.6e" xref="S4.E1.m1.6.7.1.cmml"><mrow id="S4.E1.m1.3.3.3.3.1.1" xref="S4.E1.m1.3.3.3.3.1.1.cmml"><mover accent="true" id="S4.E1.m1.3.3.3.3.1.1.2" xref="S4.E1.m1.3.3.3.3.1.1.2.cmml"><msub id="S4.E1.m1.3.3.3.3.1.1.2.2" xref="S4.E1.m1.3.3.3.3.1.1.2.2.cmml"><mi id="S4.E1.m1.3.3.3.3.1.1.2.2.2" xref="S4.E1.m1.3.3.3.3.1.1.2.2.2.cmml">y</mi><mi id="S4.E1.m1.3.3.3.3.1.1.2.2.3" xref="S4.E1.m1.3.3.3.3.1.1.2.2.3.cmml">m</mi></msub><mo stretchy="false" id="S4.E1.m1.3.3.3.3.1.1.2.1" xref="S4.E1.m1.3.3.3.3.1.1.2.1.cmml">→</mo></mover><mo id="S4.E1.m1.3.3.3.3.1.1.1" xref="S4.E1.m1.3.3.3.3.1.1.1.cmml">=</mo><mi id="S4.E1.m1.3.3.3.3.1.1.3" xref="S4.E1.m1.3.3.3.3.1.1.3.cmml"></mi></mrow></mtd><mtd class="ltx_align_left" columnalign="left" id="S4.E1.m1.6.6.6f" xref="S4.E1.m1.6.7.1.cmml"><mrow id="S4.E1.m1.4.4.4.4.2.1" xref="S4.E1.m1.4.4.4.4.2.1.cmml"><mover accent="true" id="S4.E1.m1.4.4.4.4.2.1.3" xref="S4.E1.m1.4.4.4.4.2.1.3.cmml"><msub id="S4.E1.m1.4.4.4.4.2.1.3.2" xref="S4.E1.m1.4.4.4.4.2.1.3.2.cmml"><mi id="S4.E1.m1.4.4.4.4.2.1.3.2.2" xref="S4.E1.m1.4.4.4.4.2.1.3.2.2.cmml">y</mi><mi id="S4.E1.m1.4.4.4.4.2.1.3.2.3" xref="S4.E1.m1.4.4.4.4.2.1.3.2.3.cmml">i</mi></msub><mo stretchy="false" id="S4.E1.m1.4.4.4.4.2.1.3.1" xref="S4.E1.m1.4.4.4.4.2.1.3.1.cmml">→</mo></mover><mo id="S4.E1.m1.4.4.4.4.2.1.2" xref="S4.E1.m1.4.4.4.4.2.1.2.cmml">+</mo><mrow id="S4.E1.m1.4.4.4.4.2.1.1" xref="S4.E1.m1.4.4.4.4.2.1.1.cmml"><mstyle displaystyle="false" id="S4.E1.m1.4.4.4.4.2.1.1.3" xref="S4.E1.m1.4.4.4.4.2.1.1.3.cmml"><mfrac id="S4.E1.m1.4.4.4.4.2.1.1.3a" xref="S4.E1.m1.4.4.4.4.2.1.1.3.cmml"><msub id="S4.E1.m1.4.4.4.4.2.1.1.3.2" xref="S4.E1.m1.4.4.4.4.2.1.1.3.2.cmml"><mi id="S4.E1.m1.4.4.4.4.2.1.1.3.2.2" xref="S4.E1.m1.4.4.4.4.2.1.1.3.2.2.cmml">w</mi><mi id="S4.E1.m1.4.4.4.4.2.1.1.3.2.3" xref="S4.E1.m1.4.4.4.4.2.1.1.3.2.3.cmml">j</mi></msub><mrow id="S4.E1.m1.4.4.4.4.2.1.1.3.3" xref="S4.E1.m1.4.4.4.4.2.1.1.3.3.cmml"><msub id="S4.E1.m1.4.4.4.4.2.1.1.3.3.2" xref="S4.E1.m1.4.4.4.4.2.1.1.3.3.2.cmml"><mi id="S4.E1.m1.4.4.4.4.2.1.1.3.3.2.2" xref="S4.E1.m1.4.4.4.4.2.1.1.3.3.2.2.cmml">w</mi><mi id="S4.E1.m1.4.4.4.4.2.1.1.3.3.2.3" xref="S4.E1.m1.4.4.4.4.2.1.1.3.3.2.3.cmml">i</mi></msub><mo id="S4.E1.m1.4.4.4.4.2.1.1.3.3.1" xref="S4.E1.m1.4.4.4.4.2.1.1.3.3.1.cmml">+</mo><msub id="S4.E1.m1.4.4.4.4.2.1.1.3.3.3" xref="S4.E1.m1.4.4.4.4.2.1.1.3.3.3.cmml"><mi id="S4.E1.m1.4.4.4.4.2.1.1.3.3.3.2" xref="S4.E1.m1.4.4.4.4.2.1.1.3.3.3.2.cmml">w</mi><mi id="S4.E1.m1.4.4.4.4.2.1.1.3.3.3.3" xref="S4.E1.m1.4.4.4.4.2.1.1.3.3.3.3.cmml">j</mi></msub></mrow></mfrac></mstyle><mo lspace="0.222em" rspace="0.222em" id="S4.E1.m1.4.4.4.4.2.1.1.2" xref="S4.E1.m1.4.4.4.4.2.1.1.2.cmml">∗</mo><mrow id="S4.E1.m1.4.4.4.4.2.1.1.1.1" xref="S4.E1.m1.4.4.4.4.2.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.E1.m1.4.4.4.4.2.1.1.1.1.2" xref="S4.E1.m1.4.4.4.4.2.1.1.1.1.1.cmml">(</mo><mrow id="S4.E1.m1.4.4.4.4.2.1.1.1.1.1" xref="S4.E1.m1.4.4.4.4.2.1.1.1.1.1.cmml"><mover accent="true" id="S4.E1.m1.4.4.4.4.2.1.1.1.1.1.2" xref="S4.E1.m1.4.4.4.4.2.1.1.1.1.1.2.cmml"><msub id="S4.E1.m1.4.4.4.4.2.1.1.1.1.1.2.2" xref="S4.E1.m1.4.4.4.4.2.1.1.1.1.1.2.2.cmml"><mi id="S4.E1.m1.4.4.4.4.2.1.1.1.1.1.2.2.2" xref="S4.E1.m1.4.4.4.4.2.1.1.1.1.1.2.2.2.cmml">y</mi><mi id="S4.E1.m1.4.4.4.4.2.1.1.1.1.1.2.2.3" xref="S4.E1.m1.4.4.4.4.2.1.1.1.1.1.2.2.3.cmml">j</mi></msub><mo stretchy="false" id="S4.E1.m1.4.4.4.4.2.1.1.1.1.1.2.1" xref="S4.E1.m1.4.4.4.4.2.1.1.1.1.1.2.1.cmml">→</mo></mover><mo id="S4.E1.m1.4.4.4.4.2.1.1.1.1.1.1" xref="S4.E1.m1.4.4.4.4.2.1.1.1.1.1.1.cmml">−</mo><mover accent="true" id="S4.E1.m1.4.4.4.4.2.1.1.1.1.1.3" xref="S4.E1.m1.4.4.4.4.2.1.1.1.1.1.3.cmml"><msub id="S4.E1.m1.4.4.4.4.2.1.1.1.1.1.3.2" xref="S4.E1.m1.4.4.4.4.2.1.1.1.1.1.3.2.cmml"><mi id="S4.E1.m1.4.4.4.4.2.1.1.1.1.1.3.2.2" xref="S4.E1.m1.4.4.4.4.2.1.1.1.1.1.3.2.2.cmml">y</mi><mi id="S4.E1.m1.4.4.4.4.2.1.1.1.1.1.3.2.3" xref="S4.E1.m1.4.4.4.4.2.1.1.1.1.1.3.2.3.cmml">i</mi></msub><mo stretchy="false" id="S4.E1.m1.4.4.4.4.2.1.1.1.1.1.3.1" xref="S4.E1.m1.4.4.4.4.2.1.1.1.1.1.3.1.cmml">→</mo></mover></mrow><mo stretchy="false" id="S4.E1.m1.4.4.4.4.2.1.1.1.1.3" xref="S4.E1.m1.4.4.4.4.2.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mtd></mtr><mtr id="S4.E1.m1.6.6.6g" xref="S4.E1.m1.6.7.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S4.E1.m1.6.6.6h" xref="S4.E1.m1.6.7.1.cmml"><mrow id="S4.E1.m1.5.5.5.5.1.1" xref="S4.E1.m1.5.5.5.5.1.1.cmml"><mover accent="true" id="S4.E1.m1.5.5.5.5.1.1.2" xref="S4.E1.m1.5.5.5.5.1.1.2.cmml"><msub id="S4.E1.m1.5.5.5.5.1.1.2.2" xref="S4.E1.m1.5.5.5.5.1.1.2.2.cmml"><mi id="S4.E1.m1.5.5.5.5.1.1.2.2.2" xref="S4.E1.m1.5.5.5.5.1.1.2.2.2.cmml">z</mi><mi id="S4.E1.m1.5.5.5.5.1.1.2.2.3" xref="S4.E1.m1.5.5.5.5.1.1.2.2.3.cmml">m</mi></msub><mo stretchy="false" id="S4.E1.m1.5.5.5.5.1.1.2.1" xref="S4.E1.m1.5.5.5.5.1.1.2.1.cmml">→</mo></mover><mo id="S4.E1.m1.5.5.5.5.1.1.1" xref="S4.E1.m1.5.5.5.5.1.1.1.cmml">=</mo><mi id="S4.E1.m1.5.5.5.5.1.1.3" xref="S4.E1.m1.5.5.5.5.1.1.3.cmml"></mi></mrow></mtd><mtd class="ltx_align_left" columnalign="left" id="S4.E1.m1.6.6.6i" xref="S4.E1.m1.6.7.1.cmml"><mrow id="S4.E1.m1.6.6.6.6.2.1" xref="S4.E1.m1.6.6.6.6.2.1.cmml"><mover accent="true" id="S4.E1.m1.6.6.6.6.2.1.3" xref="S4.E1.m1.6.6.6.6.2.1.3.cmml"><msub id="S4.E1.m1.6.6.6.6.2.1.3.2" xref="S4.E1.m1.6.6.6.6.2.1.3.2.cmml"><mi id="S4.E1.m1.6.6.6.6.2.1.3.2.2" xref="S4.E1.m1.6.6.6.6.2.1.3.2.2.cmml">z</mi><mi id="S4.E1.m1.6.6.6.6.2.1.3.2.3" xref="S4.E1.m1.6.6.6.6.2.1.3.2.3.cmml">i</mi></msub><mo stretchy="false" id="S4.E1.m1.6.6.6.6.2.1.3.1" xref="S4.E1.m1.6.6.6.6.2.1.3.1.cmml">→</mo></mover><mo id="S4.E1.m1.6.6.6.6.2.1.2" xref="S4.E1.m1.6.6.6.6.2.1.2.cmml">+</mo><mrow id="S4.E1.m1.6.6.6.6.2.1.1" xref="S4.E1.m1.6.6.6.6.2.1.1.cmml"><mstyle displaystyle="false" id="S4.E1.m1.6.6.6.6.2.1.1.3" xref="S4.E1.m1.6.6.6.6.2.1.1.3.cmml"><mfrac id="S4.E1.m1.6.6.6.6.2.1.1.3a" xref="S4.E1.m1.6.6.6.6.2.1.1.3.cmml"><msub id="S4.E1.m1.6.6.6.6.2.1.1.3.2" xref="S4.E1.m1.6.6.6.6.2.1.1.3.2.cmml"><mi id="S4.E1.m1.6.6.6.6.2.1.1.3.2.2" xref="S4.E1.m1.6.6.6.6.2.1.1.3.2.2.cmml">w</mi><mi id="S4.E1.m1.6.6.6.6.2.1.1.3.2.3" xref="S4.E1.m1.6.6.6.6.2.1.1.3.2.3.cmml">j</mi></msub><mrow id="S4.E1.m1.6.6.6.6.2.1.1.3.3" xref="S4.E1.m1.6.6.6.6.2.1.1.3.3.cmml"><msub id="S4.E1.m1.6.6.6.6.2.1.1.3.3.2" xref="S4.E1.m1.6.6.6.6.2.1.1.3.3.2.cmml"><mi id="S4.E1.m1.6.6.6.6.2.1.1.3.3.2.2" xref="S4.E1.m1.6.6.6.6.2.1.1.3.3.2.2.cmml">w</mi><mi id="S4.E1.m1.6.6.6.6.2.1.1.3.3.2.3" xref="S4.E1.m1.6.6.6.6.2.1.1.3.3.2.3.cmml">i</mi></msub><mo id="S4.E1.m1.6.6.6.6.2.1.1.3.3.1" xref="S4.E1.m1.6.6.6.6.2.1.1.3.3.1.cmml">+</mo><msub id="S4.E1.m1.6.6.6.6.2.1.1.3.3.3" xref="S4.E1.m1.6.6.6.6.2.1.1.3.3.3.cmml"><mi id="S4.E1.m1.6.6.6.6.2.1.1.3.3.3.2" xref="S4.E1.m1.6.6.6.6.2.1.1.3.3.3.2.cmml">w</mi><mi id="S4.E1.m1.6.6.6.6.2.1.1.3.3.3.3" xref="S4.E1.m1.6.6.6.6.2.1.1.3.3.3.3.cmml">j</mi></msub></mrow></mfrac></mstyle><mo lspace="0.222em" rspace="0.222em" id="S4.E1.m1.6.6.6.6.2.1.1.2" xref="S4.E1.m1.6.6.6.6.2.1.1.2.cmml">∗</mo><mrow id="S4.E1.m1.6.6.6.6.2.1.1.1.1" xref="S4.E1.m1.6.6.6.6.2.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.E1.m1.6.6.6.6.2.1.1.1.1.2" xref="S4.E1.m1.6.6.6.6.2.1.1.1.1.1.cmml">(</mo><mrow id="S4.E1.m1.6.6.6.6.2.1.1.1.1.1" xref="S4.E1.m1.6.6.6.6.2.1.1.1.1.1.cmml"><mover accent="true" id="S4.E1.m1.6.6.6.6.2.1.1.1.1.1.2" xref="S4.E1.m1.6.6.6.6.2.1.1.1.1.1.2.cmml"><msub id="S4.E1.m1.6.6.6.6.2.1.1.1.1.1.2.2" xref="S4.E1.m1.6.6.6.6.2.1.1.1.1.1.2.2.cmml"><mi id="S4.E1.m1.6.6.6.6.2.1.1.1.1.1.2.2.2" xref="S4.E1.m1.6.6.6.6.2.1.1.1.1.1.2.2.2.cmml">z</mi><mi id="S4.E1.m1.6.6.6.6.2.1.1.1.1.1.2.2.3" xref="S4.E1.m1.6.6.6.6.2.1.1.1.1.1.2.2.3.cmml">j</mi></msub><mo stretchy="false" id="S4.E1.m1.6.6.6.6.2.1.1.1.1.1.2.1" xref="S4.E1.m1.6.6.6.6.2.1.1.1.1.1.2.1.cmml">→</mo></mover><mo id="S4.E1.m1.6.6.6.6.2.1.1.1.1.1.1" xref="S4.E1.m1.6.6.6.6.2.1.1.1.1.1.1.cmml">−</mo><mover accent="true" id="S4.E1.m1.6.6.6.6.2.1.1.1.1.1.3" xref="S4.E1.m1.6.6.6.6.2.1.1.1.1.1.3.cmml"><msub id="S4.E1.m1.6.6.6.6.2.1.1.1.1.1.3.2" xref="S4.E1.m1.6.6.6.6.2.1.1.1.1.1.3.2.cmml"><mi id="S4.E1.m1.6.6.6.6.2.1.1.1.1.1.3.2.2" xref="S4.E1.m1.6.6.6.6.2.1.1.1.1.1.3.2.2.cmml">z</mi><mi id="S4.E1.m1.6.6.6.6.2.1.1.1.1.1.3.2.3" xref="S4.E1.m1.6.6.6.6.2.1.1.1.1.1.3.2.3.cmml">i</mi></msub><mo stretchy="false" id="S4.E1.m1.6.6.6.6.2.1.1.1.1.1.3.1" xref="S4.E1.m1.6.6.6.6.2.1.1.1.1.1.3.1.cmml">→</mo></mover></mrow><mo stretchy="false" id="S4.E1.m1.6.6.6.6.2.1.1.1.1.3" xref="S4.E1.m1.6.6.6.6.2.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mtd></mtr></mtable></mrow><annotation-xml encoding="MathML-Content" id="S4.E1.m1.6b"><apply id="S4.E1.m1.6.7.1.cmml" xref="S4.E1.m1.6.6"><csymbol cd="latexml" id="S4.E1.m1.6.7.1.1.cmml" xref="S4.E1.m1.6.6.7">cases</csymbol><apply id="S4.E1.m1.1.1.1.1.1.1.cmml" xref="S4.E1.m1.1.1.1.1.1.1"><eq id="S4.E1.m1.1.1.1.1.1.1.1.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1"></eq><apply id="S4.E1.m1.1.1.1.1.1.1.2.cmml" xref="S4.E1.m1.1.1.1.1.1.1.2"><ci id="S4.E1.m1.1.1.1.1.1.1.2.1.cmml" xref="S4.E1.m1.1.1.1.1.1.1.2.1">→</ci><apply id="S4.E1.m1.1.1.1.1.1.1.2.2.cmml" xref="S4.E1.m1.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S4.E1.m1.1.1.1.1.1.1.2.2.1.cmml" xref="S4.E1.m1.1.1.1.1.1.1.2.2">subscript</csymbol><ci id="S4.E1.m1.1.1.1.1.1.1.2.2.2.cmml" xref="S4.E1.m1.1.1.1.1.1.1.2.2.2">𝑥</ci><ci id="S4.E1.m1.1.1.1.1.1.1.2.2.3.cmml" xref="S4.E1.m1.1.1.1.1.1.1.2.2.3">𝑚</ci></apply></apply><csymbol cd="latexml" id="S4.E1.m1.1.1.1.1.1.1.3.cmml" xref="S4.E1.m1.1.1.1.1.1.1.3">absent</csymbol></apply><apply id="S4.E1.m1.2.2.2.2.2.1.cmml" xref="S4.E1.m1.2.2.2.2.2.1"><plus id="S4.E1.m1.2.2.2.2.2.1.2.cmml" xref="S4.E1.m1.2.2.2.2.2.1.2"></plus><apply id="S4.E1.m1.2.2.2.2.2.1.3.cmml" xref="S4.E1.m1.2.2.2.2.2.1.3"><ci id="S4.E1.m1.2.2.2.2.2.1.3.1.cmml" xref="S4.E1.m1.2.2.2.2.2.1.3.1">→</ci><apply id="S4.E1.m1.2.2.2.2.2.1.3.2.cmml" xref="S4.E1.m1.2.2.2.2.2.1.3.2"><csymbol cd="ambiguous" id="S4.E1.m1.2.2.2.2.2.1.3.2.1.cmml" xref="S4.E1.m1.2.2.2.2.2.1.3.2">subscript</csymbol><ci id="S4.E1.m1.2.2.2.2.2.1.3.2.2.cmml" xref="S4.E1.m1.2.2.2.2.2.1.3.2.2">𝑥</ci><ci id="S4.E1.m1.2.2.2.2.2.1.3.2.3.cmml" xref="S4.E1.m1.2.2.2.2.2.1.3.2.3">𝑖</ci></apply></apply><apply id="S4.E1.m1.2.2.2.2.2.1.1.cmml" xref="S4.E1.m1.2.2.2.2.2.1.1"><times id="S4.E1.m1.2.2.2.2.2.1.1.2.cmml" xref="S4.E1.m1.2.2.2.2.2.1.1.2"></times><apply id="S4.E1.m1.2.2.2.2.2.1.1.3.cmml" xref="S4.E1.m1.2.2.2.2.2.1.1.3"><divide id="S4.E1.m1.2.2.2.2.2.1.1.3.1.cmml" xref="S4.E1.m1.2.2.2.2.2.1.1.3"></divide><apply id="S4.E1.m1.2.2.2.2.2.1.1.3.2.cmml" xref="S4.E1.m1.2.2.2.2.2.1.1.3.2"><csymbol cd="ambiguous" id="S4.E1.m1.2.2.2.2.2.1.1.3.2.1.cmml" xref="S4.E1.m1.2.2.2.2.2.1.1.3.2">subscript</csymbol><ci id="S4.E1.m1.2.2.2.2.2.1.1.3.2.2.cmml" xref="S4.E1.m1.2.2.2.2.2.1.1.3.2.2">𝑤</ci><ci id="S4.E1.m1.2.2.2.2.2.1.1.3.2.3.cmml" xref="S4.E1.m1.2.2.2.2.2.1.1.3.2.3">𝑗</ci></apply><apply id="S4.E1.m1.2.2.2.2.2.1.1.3.3.cmml" xref="S4.E1.m1.2.2.2.2.2.1.1.3.3"><plus id="S4.E1.m1.2.2.2.2.2.1.1.3.3.1.cmml" xref="S4.E1.m1.2.2.2.2.2.1.1.3.3.1"></plus><apply id="S4.E1.m1.2.2.2.2.2.1.1.3.3.2.cmml" xref="S4.E1.m1.2.2.2.2.2.1.1.3.3.2"><csymbol cd="ambiguous" id="S4.E1.m1.2.2.2.2.2.1.1.3.3.2.1.cmml" xref="S4.E1.m1.2.2.2.2.2.1.1.3.3.2">subscript</csymbol><ci id="S4.E1.m1.2.2.2.2.2.1.1.3.3.2.2.cmml" xref="S4.E1.m1.2.2.2.2.2.1.1.3.3.2.2">𝑤</ci><ci id="S4.E1.m1.2.2.2.2.2.1.1.3.3.2.3.cmml" xref="S4.E1.m1.2.2.2.2.2.1.1.3.3.2.3">𝑖</ci></apply><apply id="S4.E1.m1.2.2.2.2.2.1.1.3.3.3.cmml" xref="S4.E1.m1.2.2.2.2.2.1.1.3.3.3"><csymbol cd="ambiguous" id="S4.E1.m1.2.2.2.2.2.1.1.3.3.3.1.cmml" xref="S4.E1.m1.2.2.2.2.2.1.1.3.3.3">subscript</csymbol><ci id="S4.E1.m1.2.2.2.2.2.1.1.3.3.3.2.cmml" xref="S4.E1.m1.2.2.2.2.2.1.1.3.3.3.2">𝑤</ci><ci id="S4.E1.m1.2.2.2.2.2.1.1.3.3.3.3.cmml" xref="S4.E1.m1.2.2.2.2.2.1.1.3.3.3.3">𝑗</ci></apply></apply></apply><apply id="S4.E1.m1.2.2.2.2.2.1.1.1.1.1.cmml" xref="S4.E1.m1.2.2.2.2.2.1.1.1.1"><minus id="S4.E1.m1.2.2.2.2.2.1.1.1.1.1.1.cmml" xref="S4.E1.m1.2.2.2.2.2.1.1.1.1.1.1"></minus><apply id="S4.E1.m1.2.2.2.2.2.1.1.1.1.1.2.cmml" xref="S4.E1.m1.2.2.2.2.2.1.1.1.1.1.2"><ci id="S4.E1.m1.2.2.2.2.2.1.1.1.1.1.2.1.cmml" xref="S4.E1.m1.2.2.2.2.2.1.1.1.1.1.2.1">→</ci><apply id="S4.E1.m1.2.2.2.2.2.1.1.1.1.1.2.2.cmml" xref="S4.E1.m1.2.2.2.2.2.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S4.E1.m1.2.2.2.2.2.1.1.1.1.1.2.2.1.cmml" xref="S4.E1.m1.2.2.2.2.2.1.1.1.1.1.2.2">subscript</csymbol><ci id="S4.E1.m1.2.2.2.2.2.1.1.1.1.1.2.2.2.cmml" xref="S4.E1.m1.2.2.2.2.2.1.1.1.1.1.2.2.2">𝑥</ci><ci id="S4.E1.m1.2.2.2.2.2.1.1.1.1.1.2.2.3.cmml" xref="S4.E1.m1.2.2.2.2.2.1.1.1.1.1.2.2.3">𝑗</ci></apply></apply><apply id="S4.E1.m1.2.2.2.2.2.1.1.1.1.1.3.cmml" xref="S4.E1.m1.2.2.2.2.2.1.1.1.1.1.3"><ci id="S4.E1.m1.2.2.2.2.2.1.1.1.1.1.3.1.cmml" xref="S4.E1.m1.2.2.2.2.2.1.1.1.1.1.3.1">→</ci><apply id="S4.E1.m1.2.2.2.2.2.1.1.1.1.1.3.2.cmml" xref="S4.E1.m1.2.2.2.2.2.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S4.E1.m1.2.2.2.2.2.1.1.1.1.1.3.2.1.cmml" xref="S4.E1.m1.2.2.2.2.2.1.1.1.1.1.3.2">subscript</csymbol><ci id="S4.E1.m1.2.2.2.2.2.1.1.1.1.1.3.2.2.cmml" xref="S4.E1.m1.2.2.2.2.2.1.1.1.1.1.3.2.2">𝑥</ci><ci id="S4.E1.m1.2.2.2.2.2.1.1.1.1.1.3.2.3.cmml" xref="S4.E1.m1.2.2.2.2.2.1.1.1.1.1.3.2.3">𝑖</ci></apply></apply></apply></apply></apply><apply id="S4.E1.m1.3.3.3.3.1.1.cmml" xref="S4.E1.m1.3.3.3.3.1.1"><eq id="S4.E1.m1.3.3.3.3.1.1.1.cmml" xref="S4.E1.m1.3.3.3.3.1.1.1"></eq><apply id="S4.E1.m1.3.3.3.3.1.1.2.cmml" xref="S4.E1.m1.3.3.3.3.1.1.2"><ci id="S4.E1.m1.3.3.3.3.1.1.2.1.cmml" xref="S4.E1.m1.3.3.3.3.1.1.2.1">→</ci><apply id="S4.E1.m1.3.3.3.3.1.1.2.2.cmml" xref="S4.E1.m1.3.3.3.3.1.1.2.2"><csymbol cd="ambiguous" id="S4.E1.m1.3.3.3.3.1.1.2.2.1.cmml" xref="S4.E1.m1.3.3.3.3.1.1.2.2">subscript</csymbol><ci id="S4.E1.m1.3.3.3.3.1.1.2.2.2.cmml" xref="S4.E1.m1.3.3.3.3.1.1.2.2.2">𝑦</ci><ci id="S4.E1.m1.3.3.3.3.1.1.2.2.3.cmml" xref="S4.E1.m1.3.3.3.3.1.1.2.2.3">𝑚</ci></apply></apply><csymbol cd="latexml" id="S4.E1.m1.3.3.3.3.1.1.3.cmml" xref="S4.E1.m1.3.3.3.3.1.1.3">absent</csymbol></apply><apply id="S4.E1.m1.4.4.4.4.2.1.cmml" xref="S4.E1.m1.4.4.4.4.2.1"><plus id="S4.E1.m1.4.4.4.4.2.1.2.cmml" xref="S4.E1.m1.4.4.4.4.2.1.2"></plus><apply id="S4.E1.m1.4.4.4.4.2.1.3.cmml" xref="S4.E1.m1.4.4.4.4.2.1.3"><ci id="S4.E1.m1.4.4.4.4.2.1.3.1.cmml" xref="S4.E1.m1.4.4.4.4.2.1.3.1">→</ci><apply id="S4.E1.m1.4.4.4.4.2.1.3.2.cmml" xref="S4.E1.m1.4.4.4.4.2.1.3.2"><csymbol cd="ambiguous" id="S4.E1.m1.4.4.4.4.2.1.3.2.1.cmml" xref="S4.E1.m1.4.4.4.4.2.1.3.2">subscript</csymbol><ci id="S4.E1.m1.4.4.4.4.2.1.3.2.2.cmml" xref="S4.E1.m1.4.4.4.4.2.1.3.2.2">𝑦</ci><ci id="S4.E1.m1.4.4.4.4.2.1.3.2.3.cmml" xref="S4.E1.m1.4.4.4.4.2.1.3.2.3">𝑖</ci></apply></apply><apply id="S4.E1.m1.4.4.4.4.2.1.1.cmml" xref="S4.E1.m1.4.4.4.4.2.1.1"><times id="S4.E1.m1.4.4.4.4.2.1.1.2.cmml" xref="S4.E1.m1.4.4.4.4.2.1.1.2"></times><apply id="S4.E1.m1.4.4.4.4.2.1.1.3.cmml" xref="S4.E1.m1.4.4.4.4.2.1.1.3"><divide id="S4.E1.m1.4.4.4.4.2.1.1.3.1.cmml" xref="S4.E1.m1.4.4.4.4.2.1.1.3"></divide><apply id="S4.E1.m1.4.4.4.4.2.1.1.3.2.cmml" xref="S4.E1.m1.4.4.4.4.2.1.1.3.2"><csymbol cd="ambiguous" id="S4.E1.m1.4.4.4.4.2.1.1.3.2.1.cmml" xref="S4.E1.m1.4.4.4.4.2.1.1.3.2">subscript</csymbol><ci id="S4.E1.m1.4.4.4.4.2.1.1.3.2.2.cmml" xref="S4.E1.m1.4.4.4.4.2.1.1.3.2.2">𝑤</ci><ci id="S4.E1.m1.4.4.4.4.2.1.1.3.2.3.cmml" xref="S4.E1.m1.4.4.4.4.2.1.1.3.2.3">𝑗</ci></apply><apply id="S4.E1.m1.4.4.4.4.2.1.1.3.3.cmml" xref="S4.E1.m1.4.4.4.4.2.1.1.3.3"><plus id="S4.E1.m1.4.4.4.4.2.1.1.3.3.1.cmml" xref="S4.E1.m1.4.4.4.4.2.1.1.3.3.1"></plus><apply id="S4.E1.m1.4.4.4.4.2.1.1.3.3.2.cmml" xref="S4.E1.m1.4.4.4.4.2.1.1.3.3.2"><csymbol cd="ambiguous" id="S4.E1.m1.4.4.4.4.2.1.1.3.3.2.1.cmml" xref="S4.E1.m1.4.4.4.4.2.1.1.3.3.2">subscript</csymbol><ci id="S4.E1.m1.4.4.4.4.2.1.1.3.3.2.2.cmml" xref="S4.E1.m1.4.4.4.4.2.1.1.3.3.2.2">𝑤</ci><ci id="S4.E1.m1.4.4.4.4.2.1.1.3.3.2.3.cmml" xref="S4.E1.m1.4.4.4.4.2.1.1.3.3.2.3">𝑖</ci></apply><apply id="S4.E1.m1.4.4.4.4.2.1.1.3.3.3.cmml" xref="S4.E1.m1.4.4.4.4.2.1.1.3.3.3"><csymbol cd="ambiguous" id="S4.E1.m1.4.4.4.4.2.1.1.3.3.3.1.cmml" xref="S4.E1.m1.4.4.4.4.2.1.1.3.3.3">subscript</csymbol><ci id="S4.E1.m1.4.4.4.4.2.1.1.3.3.3.2.cmml" xref="S4.E1.m1.4.4.4.4.2.1.1.3.3.3.2">𝑤</ci><ci id="S4.E1.m1.4.4.4.4.2.1.1.3.3.3.3.cmml" xref="S4.E1.m1.4.4.4.4.2.1.1.3.3.3.3">𝑗</ci></apply></apply></apply><apply id="S4.E1.m1.4.4.4.4.2.1.1.1.1.1.cmml" xref="S4.E1.m1.4.4.4.4.2.1.1.1.1"><minus id="S4.E1.m1.4.4.4.4.2.1.1.1.1.1.1.cmml" xref="S4.E1.m1.4.4.4.4.2.1.1.1.1.1.1"></minus><apply id="S4.E1.m1.4.4.4.4.2.1.1.1.1.1.2.cmml" xref="S4.E1.m1.4.4.4.4.2.1.1.1.1.1.2"><ci id="S4.E1.m1.4.4.4.4.2.1.1.1.1.1.2.1.cmml" xref="S4.E1.m1.4.4.4.4.2.1.1.1.1.1.2.1">→</ci><apply id="S4.E1.m1.4.4.4.4.2.1.1.1.1.1.2.2.cmml" xref="S4.E1.m1.4.4.4.4.2.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S4.E1.m1.4.4.4.4.2.1.1.1.1.1.2.2.1.cmml" xref="S4.E1.m1.4.4.4.4.2.1.1.1.1.1.2.2">subscript</csymbol><ci id="S4.E1.m1.4.4.4.4.2.1.1.1.1.1.2.2.2.cmml" xref="S4.E1.m1.4.4.4.4.2.1.1.1.1.1.2.2.2">𝑦</ci><ci id="S4.E1.m1.4.4.4.4.2.1.1.1.1.1.2.2.3.cmml" xref="S4.E1.m1.4.4.4.4.2.1.1.1.1.1.2.2.3">𝑗</ci></apply></apply><apply id="S4.E1.m1.4.4.4.4.2.1.1.1.1.1.3.cmml" xref="S4.E1.m1.4.4.4.4.2.1.1.1.1.1.3"><ci id="S4.E1.m1.4.4.4.4.2.1.1.1.1.1.3.1.cmml" xref="S4.E1.m1.4.4.4.4.2.1.1.1.1.1.3.1">→</ci><apply id="S4.E1.m1.4.4.4.4.2.1.1.1.1.1.3.2.cmml" xref="S4.E1.m1.4.4.4.4.2.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S4.E1.m1.4.4.4.4.2.1.1.1.1.1.3.2.1.cmml" xref="S4.E1.m1.4.4.4.4.2.1.1.1.1.1.3.2">subscript</csymbol><ci id="S4.E1.m1.4.4.4.4.2.1.1.1.1.1.3.2.2.cmml" xref="S4.E1.m1.4.4.4.4.2.1.1.1.1.1.3.2.2">𝑦</ci><ci id="S4.E1.m1.4.4.4.4.2.1.1.1.1.1.3.2.3.cmml" xref="S4.E1.m1.4.4.4.4.2.1.1.1.1.1.3.2.3">𝑖</ci></apply></apply></apply></apply></apply><apply id="S4.E1.m1.5.5.5.5.1.1.cmml" xref="S4.E1.m1.5.5.5.5.1.1"><eq id="S4.E1.m1.5.5.5.5.1.1.1.cmml" xref="S4.E1.m1.5.5.5.5.1.1.1"></eq><apply id="S4.E1.m1.5.5.5.5.1.1.2.cmml" xref="S4.E1.m1.5.5.5.5.1.1.2"><ci id="S4.E1.m1.5.5.5.5.1.1.2.1.cmml" xref="S4.E1.m1.5.5.5.5.1.1.2.1">→</ci><apply id="S4.E1.m1.5.5.5.5.1.1.2.2.cmml" xref="S4.E1.m1.5.5.5.5.1.1.2.2"><csymbol cd="ambiguous" id="S4.E1.m1.5.5.5.5.1.1.2.2.1.cmml" xref="S4.E1.m1.5.5.5.5.1.1.2.2">subscript</csymbol><ci id="S4.E1.m1.5.5.5.5.1.1.2.2.2.cmml" xref="S4.E1.m1.5.5.5.5.1.1.2.2.2">𝑧</ci><ci id="S4.E1.m1.5.5.5.5.1.1.2.2.3.cmml" xref="S4.E1.m1.5.5.5.5.1.1.2.2.3">𝑚</ci></apply></apply><csymbol cd="latexml" id="S4.E1.m1.5.5.5.5.1.1.3.cmml" xref="S4.E1.m1.5.5.5.5.1.1.3">absent</csymbol></apply><apply id="S4.E1.m1.6.6.6.6.2.1.cmml" xref="S4.E1.m1.6.6.6.6.2.1"><plus id="S4.E1.m1.6.6.6.6.2.1.2.cmml" xref="S4.E1.m1.6.6.6.6.2.1.2"></plus><apply id="S4.E1.m1.6.6.6.6.2.1.3.cmml" xref="S4.E1.m1.6.6.6.6.2.1.3"><ci id="S4.E1.m1.6.6.6.6.2.1.3.1.cmml" xref="S4.E1.m1.6.6.6.6.2.1.3.1">→</ci><apply id="S4.E1.m1.6.6.6.6.2.1.3.2.cmml" xref="S4.E1.m1.6.6.6.6.2.1.3.2"><csymbol cd="ambiguous" id="S4.E1.m1.6.6.6.6.2.1.3.2.1.cmml" xref="S4.E1.m1.6.6.6.6.2.1.3.2">subscript</csymbol><ci id="S4.E1.m1.6.6.6.6.2.1.3.2.2.cmml" xref="S4.E1.m1.6.6.6.6.2.1.3.2.2">𝑧</ci><ci id="S4.E1.m1.6.6.6.6.2.1.3.2.3.cmml" xref="S4.E1.m1.6.6.6.6.2.1.3.2.3">𝑖</ci></apply></apply><apply id="S4.E1.m1.6.6.6.6.2.1.1.cmml" xref="S4.E1.m1.6.6.6.6.2.1.1"><times id="S4.E1.m1.6.6.6.6.2.1.1.2.cmml" xref="S4.E1.m1.6.6.6.6.2.1.1.2"></times><apply id="S4.E1.m1.6.6.6.6.2.1.1.3.cmml" xref="S4.E1.m1.6.6.6.6.2.1.1.3"><divide id="S4.E1.m1.6.6.6.6.2.1.1.3.1.cmml" xref="S4.E1.m1.6.6.6.6.2.1.1.3"></divide><apply id="S4.E1.m1.6.6.6.6.2.1.1.3.2.cmml" xref="S4.E1.m1.6.6.6.6.2.1.1.3.2"><csymbol cd="ambiguous" id="S4.E1.m1.6.6.6.6.2.1.1.3.2.1.cmml" xref="S4.E1.m1.6.6.6.6.2.1.1.3.2">subscript</csymbol><ci id="S4.E1.m1.6.6.6.6.2.1.1.3.2.2.cmml" xref="S4.E1.m1.6.6.6.6.2.1.1.3.2.2">𝑤</ci><ci id="S4.E1.m1.6.6.6.6.2.1.1.3.2.3.cmml" xref="S4.E1.m1.6.6.6.6.2.1.1.3.2.3">𝑗</ci></apply><apply id="S4.E1.m1.6.6.6.6.2.1.1.3.3.cmml" xref="S4.E1.m1.6.6.6.6.2.1.1.3.3"><plus id="S4.E1.m1.6.6.6.6.2.1.1.3.3.1.cmml" xref="S4.E1.m1.6.6.6.6.2.1.1.3.3.1"></plus><apply id="S4.E1.m1.6.6.6.6.2.1.1.3.3.2.cmml" xref="S4.E1.m1.6.6.6.6.2.1.1.3.3.2"><csymbol cd="ambiguous" id="S4.E1.m1.6.6.6.6.2.1.1.3.3.2.1.cmml" xref="S4.E1.m1.6.6.6.6.2.1.1.3.3.2">subscript</csymbol><ci id="S4.E1.m1.6.6.6.6.2.1.1.3.3.2.2.cmml" xref="S4.E1.m1.6.6.6.6.2.1.1.3.3.2.2">𝑤</ci><ci id="S4.E1.m1.6.6.6.6.2.1.1.3.3.2.3.cmml" xref="S4.E1.m1.6.6.6.6.2.1.1.3.3.2.3">𝑖</ci></apply><apply id="S4.E1.m1.6.6.6.6.2.1.1.3.3.3.cmml" xref="S4.E1.m1.6.6.6.6.2.1.1.3.3.3"><csymbol cd="ambiguous" id="S4.E1.m1.6.6.6.6.2.1.1.3.3.3.1.cmml" xref="S4.E1.m1.6.6.6.6.2.1.1.3.3.3">subscript</csymbol><ci id="S4.E1.m1.6.6.6.6.2.1.1.3.3.3.2.cmml" xref="S4.E1.m1.6.6.6.6.2.1.1.3.3.3.2">𝑤</ci><ci id="S4.E1.m1.6.6.6.6.2.1.1.3.3.3.3.cmml" xref="S4.E1.m1.6.6.6.6.2.1.1.3.3.3.3">𝑗</ci></apply></apply></apply><apply id="S4.E1.m1.6.6.6.6.2.1.1.1.1.1.cmml" xref="S4.E1.m1.6.6.6.6.2.1.1.1.1"><minus id="S4.E1.m1.6.6.6.6.2.1.1.1.1.1.1.cmml" xref="S4.E1.m1.6.6.6.6.2.1.1.1.1.1.1"></minus><apply id="S4.E1.m1.6.6.6.6.2.1.1.1.1.1.2.cmml" xref="S4.E1.m1.6.6.6.6.2.1.1.1.1.1.2"><ci id="S4.E1.m1.6.6.6.6.2.1.1.1.1.1.2.1.cmml" xref="S4.E1.m1.6.6.6.6.2.1.1.1.1.1.2.1">→</ci><apply id="S4.E1.m1.6.6.6.6.2.1.1.1.1.1.2.2.cmml" xref="S4.E1.m1.6.6.6.6.2.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S4.E1.m1.6.6.6.6.2.1.1.1.1.1.2.2.1.cmml" xref="S4.E1.m1.6.6.6.6.2.1.1.1.1.1.2.2">subscript</csymbol><ci id="S4.E1.m1.6.6.6.6.2.1.1.1.1.1.2.2.2.cmml" xref="S4.E1.m1.6.6.6.6.2.1.1.1.1.1.2.2.2">𝑧</ci><ci id="S4.E1.m1.6.6.6.6.2.1.1.1.1.1.2.2.3.cmml" xref="S4.E1.m1.6.6.6.6.2.1.1.1.1.1.2.2.3">𝑗</ci></apply></apply><apply id="S4.E1.m1.6.6.6.6.2.1.1.1.1.1.3.cmml" xref="S4.E1.m1.6.6.6.6.2.1.1.1.1.1.3"><ci id="S4.E1.m1.6.6.6.6.2.1.1.1.1.1.3.1.cmml" xref="S4.E1.m1.6.6.6.6.2.1.1.1.1.1.3.1">→</ci><apply id="S4.E1.m1.6.6.6.6.2.1.1.1.1.1.3.2.cmml" xref="S4.E1.m1.6.6.6.6.2.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S4.E1.m1.6.6.6.6.2.1.1.1.1.1.3.2.1.cmml" xref="S4.E1.m1.6.6.6.6.2.1.1.1.1.1.3.2">subscript</csymbol><ci id="S4.E1.m1.6.6.6.6.2.1.1.1.1.1.3.2.2.cmml" xref="S4.E1.m1.6.6.6.6.2.1.1.1.1.1.3.2.2">𝑧</ci><ci id="S4.E1.m1.6.6.6.6.2.1.1.1.1.1.3.2.3.cmml" xref="S4.E1.m1.6.6.6.6.2.1.1.1.1.1.3.2.3">𝑖</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E1.m1.6c">\begin{cases}\overrightarrow{x_{m}}=&amp;\overrightarrow{x_{i}}+\frac{w_{j}}{w_{i}+w_{j}}*(\overrightarrow{x_{j}}-\overrightarrow{x_{i}})\\
\overrightarrow{y_{m}}=&amp;\overrightarrow{y_{i}}+\frac{w_{j}}{w_{i}+w_{j}}*(\overrightarrow{y_{j}}-\overrightarrow{y_{i}})\\
\overrightarrow{z_{m}}=&amp;\overrightarrow{z_{i}}+\frac{w_{j}}{w_{i}+w_{j}}*(\overrightarrow{z_{j}}-\overrightarrow{z_{i}})\end{cases}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Discussion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">The presented work essentially describes the implementation process and the rationale behind our multi-sensor system for room-scale behaviour tracking, based on the literature and informal tests with the project team.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">One of the main challenges was to obtain a suitable transformation matrix to convert the tracking data to a common coordinate system. Based on our experiences, we found that this can be best tackled with an ICP-based approach. Regarding the skeletal matching, tracking inaccuracies led to difficulties in pairing skeletons based on proximity alone and there is a need to lift ambiguities in a meaningful manner. Finally, the skeletal merging method was more straightforward, as the weighted average approach we opted for seemed to produce satisfactory results.</p>
</div>
<div id="S5.p3" class="ltx_para">
<p id="S5.p3.1" class="ltx_p">By fusing such data from separate RGB-D sensors, we extend the tracking range of our system and make it more robust to occlusions, which effectively strengthen the system’s tracking stability and accuracy for jointly tracked areas. This tracking system and the resulting implementation show great potential as a basis to be built upon, for behaviour and collaboration analysis but also for distant interaction. As we aim at enabling efficient and pleasant remote collaboration across distant wall-sized displays, the skeletal data gathered by this tracking system will be extremely valuable to understand and transmit the necessary collaboration information to the remote side.</p>
</div>
<div id="S5.p4" class="ltx_para">
<p id="S5.p4.1" class="ltx_p">A natural extension to the presented work will be to add an extra scene calibration step, in which we will gather knowledge on the placement of interactive surfaces relative to the coordinate system of the tracking system. This will allow to link tracking data such as pointing and gazing information to target location on these surfaces, including interactive displays.</p>
</div>
<div id="S5.p5" class="ltx_para">
<p id="S5.p5.1" class="ltx_p">Our matching logic could also be made more “defensive”, through approaches such as delays before a matching is created or removed, or before isolated skeletons are taken into account. We could also simply ignore isolated skeletons until they are matched confidently (e.g. with strict proximity conditions for all joints).
These approaches would incur a cost related to the rapid and exhaustive inclusion of users, but would likely improve the stability and reliability of the matchings.</p>
</div>
<div id="S5.p6" class="ltx_para">
<p id="S5.p6.1" class="ltx_p">As part of our future work, we plan on implementing and evaluating these alternatives, but also explore additional options regarding the merging strategy, through formal evaluations based on user studies.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Limitations</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">Despite the addition of a second sensor, some occlusions can still happen, be it with two users hiding a third one (in between them) from the two sensors, or because of a “tracking dead zone” where none of the two sensors can capture data from.
More sensors could be added following the same calibration and data fusion procedure but this would increase both the needs in terms of computing power and the risks of some of the skeletons being wrongly matched.</p>
</div>
<div id="S6.p2" class="ltx_para">
<p id="S6.p2.1" class="ltx_p">Another limitation of our setup is the reliance on Azure Kinect sensors which have been retired as of 2023, although the underlying technology has been transferred and alternatives do exist
. This is however simply a limitation of our practical setup as the procedures, algorithms, and general logic presented in the paper remain valid with other RGB-D sensors.</p>
</div>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusion</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">In this paper, we contributed a multi-sensor tracking system for unobtrusive room-scale
human behaviour analysis based on affordable RGB-D sensors. By presenting our rationale and the challenges we tackled while implementing it, we contributed to the knowledge on building such systems.
This covers approaches for determining the placement of the sensors themselves but also tracking data fusion techniques. We then discussed the proposed system and the remaining limitations.
</p>
</div>
<div id="S7.p2" class="ltx_para">
<p id="S7.p2.1" class="ltx_p">In its current state, the implemented system is suitable for room-scale tracking and may readily provide good input to run behavioural analysis on users. It will be extended to drive distant interactions with interactive surfaces and displays and will be the foundation on which we built an awareness support system for remote collaboration across wall-sized displays.</p>
</div>
<div id="S7.p3" class="ltx_para">
<span id="S7.p3.1" class="ltx_ERROR undefined">{credits}</span>
</div>
<section id="S7.SS0.SSS1" class="ltx_subsubsection">
<h3 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">7.0.1 </span>Acknowledgements</h3>

<div id="S7.SS0.SSS1.p1" class="ltx_para">
<p id="S7.SS0.SSS1.p1.1" class="ltx_p">Authors would like to thank the Luxembourg National Research Fund (FNR) for funding this research work under the FNR CORE ReSurf project (Grant nr C21/IS/15883550).</p>
</div>
</section>
<section id="S7.SS0.SSS2" class="ltx_subsubsection">
<h3 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">7.0.2 </span><span id="S7.SS0.SSS2.1.1" class="ltx_ERROR undefined">\discintname</span>
</h3>

<div id="S7.SS0.SSS2.p1" class="ltx_para">
<p id="S7.SS0.SSS2.p1.1" class="ltx_p">The authors have no competing interests to declare that are
relevant to the content of this article.


</p>
</div>
</section>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Baek, S., Kim, M.: Dance Experience System Using Multiple Kinects.
International Journal of Future Computer and Communication <span id="bib.bib1.1.1" class="ltx_text ltx_font_bold">4</span>(1),
45–49 (Feb 2015). https://doi.org/10.7763/IJFCC.2015.V4.353

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Bai, H., Sasikumar, P., Yang, J., Billinghurst, M.: A user study on mixed
reality remote collaboration with eye gaze and hand gesture sharing. In:
Proceedings of the 2020 CHI conference on human factors in computing systems.
pp. 1–13 (2020). https://doi.org/10.1145/3313831.3376550

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Bohus, D., Andrist, S., Feniello, A., Saw, N., Jalobeanu, M., Sweeney, P.,
Thompson, A.L., Horvitz, E.: Platform for situated intelligence. arXiv
preprint arXiv:2103.15975 (2021). https://doi.org/10.48550/arXiv.2103.15975

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Camplani, M., Paiement, A., Mirmehdi, M., Damen, D., Hannuna, S., Burghardt,
T., Tao, L.: Multiple human tracking in rgb-depth data: a survey. IET
computer vision <span id="bib.bib4.1.1" class="ltx_text ltx_font_bold">11</span>(4), 265–285 (2017).
https://doi.org/10.1049/iet-cvi.2016.0178

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Cao, Z., Hidalgo Martinez, G., Simon, T., Wei, S., Sheikh, Y.A.:
Openpose: Realtime multi-person 2d pose estimation using part affinity
fields. IEEE Transactions on Pattern Analysis and Machine Intelligence
(2019). https://doi.org/10.48550/arXiv.1611.08050

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Chu, C.W., Nevatia, R.: Real-time 3d body pose tracking from multiple 2d
images. In: International Conference on Articulated Motion and Deformable
Objects. pp. 42–52. Springer (2008). https://doi.org/10.1007/978-3-540-70517-8_5

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Febretti, A., Nishimoto, A., Thigpen, T., Talandis, J., Long, L., Pirtle, J.,
Peterka, T., Verlo, A., Brown, M., Plepys, D., et al.: Cave2: a hybrid
reality environment for immersive simulation and information analysis. In:
The Engineering Reality of Virtual Reality 2013. vol. 8649, pp. 9–20. SPIE
(2013). https://doi.org/10.1117/12.2005484

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Hartley, R., Trumpf, J., Dai, Y., Li, H.: Rotation averaging. International
journal of computer vision <span id="bib.bib8.1.1" class="ltx_text ltx_font_bold">103</span>, 267–305 (2013).
https://doi.org/10.1007/s11263-012-0601-0

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Jakobsen, M., Hornbæk, K.: Proximity and physical navigation in
collaborative work with a multi-touch wall-display. In: CHI’12 Extended
Abstracts on Human Factors in Computing Systems, pp. 2519–2524. Association
for Computing Machinery (2012). https://doi.org/10.1145/2212776.2223829

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Kim, D., Kwon, J., Han, S., Park, Y.L., Jo, S.: Deep full-body motion network
for a soft wearable motion sensing suit. IEEE/ASME Transactions on
Mechatronics <span id="bib.bib10.1.1" class="ltx_text ltx_font_bold">24</span>(1), 56–66 (2018).
https://doi.org/10.1109/TMECH.2018.2874647

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Kim, K., Kim, J., Choi, J., Kim, J., Lee, S.: Depth camera-based 3d hand
gesture controls with immersive tactile feedback for natural mid-air gesture
interactions. Sensors <span id="bib.bib11.1.1" class="ltx_text ltx_font_bold">15</span>(1), 1022–1046 (2015).
https://doi.org/10.3390/s150101022

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Kolb, A., Barth, E., Koch, R., Larsen, R.: Time-of-flight cameras in computer
graphics. In: Computer Graphics Forum. vol. 29, pp. 141–159. Wiley Online
Library (2010). https://doi.org/10.1111/j.1467-8659.2009.01583.x

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Kopper, R., Silva, M.G., McMahan, R.P., Bowman, D.A.: Increasing the precision
of distant pointing for large high-resolution displays. Tech. rep.,
Department of Computer Science, Virginia Tech (2008)

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Maimone, A., Fuchs, H.: Encumbrance-free telepresence system with real-time 3d
capture and display using commodity depth cameras. In: 2011 10th IEEE
International Symposium on Mixed and Augmented Reality. pp. 137–146. IEEE
(2011). https://doi.org/10.1109/ISMAR.2011.6092379

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Nancel, M., Chapuis, O., Pietriga, E., Yang, X.D., Irani, P.P.,
Beaudouin-Lafon, M.: High-precision pointing on large wall displays using
small handheld devices. In: Proceedings of the SIGCHI Conference on Human
Factors in Computing Systems. pp. 831–840 (2013).
https://doi.org/10.1145/2470654.2470773

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Nancel, M., Wagner, J., Pietriga, E., Chapuis, O., Mackay, W.: Mid-air
pan-and-zoom on wall-sized displays. In: Proceedings of the SIGCHI Conference
on Human Factors in Computing Systems. pp. 177–186 (2011).
https://doi.org/10.1145/1978942.1978969

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Oehl, M., Sutter, C., Ziefle, M.: Considerations on efficient touch
interfaces–how display size influences the performance in an applied
pointing task. In: Human Interface and the Management of Information.
Methods, Techniques and Tools in Information Design: Symposium on Human
Interface 2007, Held as Part of HCI International 2007, Beijing, China, July
22-27, 2007, Proceedings Part I. pp. 136–143. Springer (2007).
https://doi.org/10.1007/978-3-540-73345-4_17

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Polacek, O., Klima, M., Sporka, A.J., Zak, P., Hradis, M., Zemcik, P.,
Prochazka, V.: A comparative study on distant free-hand pointing. In:
Proceedings of the 10th European conference on Interactive tv and video. pp.
139–142 (2012). https://doi.org/10.1145/2325616.2325644

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Simon, T., Joo, H., Matthews, I., Sheikh, Y.: Hand keypoint detection in single
images using multiview bootstrapping. In: CVPR (2017).
https://doi.org/10.48550/arXiv.1704.07809

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Vogel, D., Balakrishnan, R.: Distant freehand pointing and clicking on very
large, high resolution displays. In: Proceedings of the 18th annual ACM
symposium on User interface software and technology. pp. 33–42 (2005).
https://doi.org/10.1145/1095034.1095041

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Wang, F., Zhao, Z.: A survey of iterative closest point algorithm. In: 2017
Chinese Automation Congress (CAC). pp. 4395–4399. IEEE (2017).
https://doi.org/10.1109/CAC.2017.8243553

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Zhang, Z.: Camera parameters (intrinsic, extrinsic). In: Computer Vision: A
Reference Guide, pp. 135–140. Springer (2021).
https://doi.org/10.1007/978-3-030-63416-2_152

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2409.15241" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2409.15242" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2409.15242">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2409.15242" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2409.15243" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sat Oct  5 23:56:11 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
