<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2303.01230] What Is Synthetic Data? The Good, The Bad, and The Ugly</title><meta property="og:description" content="Sharing data can often enable compelling applications and analytics.
However, more often than not, valuable datasets contain information of sensitive nature, and thus sharing them can endanger the privacy of users and …">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="What Is Synthetic Data? The Good, The Bad, and The Ugly">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="What Is Synthetic Data? The Good, The Bad, and The Ugly">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2303.01230">

<!--Generated on Thu Feb 29 22:06:39 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_font_bold ltx_title_document">What Is Synthetic Data? The Good, The Bad, and The Ugly</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Emiliano De Cristofaro, University College London
<br class="ltx_break">
e.decristofaro@ucl.ac.uk
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">Sharing data can often enable compelling applications and analytics.
However, more often than not, valuable datasets contain information of sensitive nature, and thus sharing them can endanger the privacy of users and organizations.
A possible alternative gaining momentum in the research community is to share <span id="id1.id1.1" class="ltx_text ltx_font_italic">synthetic data</span> instead.
The idea is to release artificially generated datasets that resemble the actual data – more precisely, having similar statistical properties.</p>
<p id="id2.id2" class="ltx_p">So how do you generate synthetic data? What is that useful for? What are the benefits and the risks? What are the open research questions that remain unanswered?
In this article, we provide a gentle introduction to synthetic data and discuss its use cases, the privacy challenges that are still unaddressed, and its inherent limitations as an effective privacy-enhancing technology.</p>
</div>
<section id="Sx1" class="ltx_section ltx_indentfirst">
<h2 class="ltx_title ltx_title_section">How To Safely Release Data?</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">Before discussing synthetic data, let’s first consider the “alternatives.”</p>
</div>
<div id="Sx1.p2" class="ltx_para ltx_noindent">
<p id="Sx1.p2.1" class="ltx_p"><span id="Sx1.p2.1.1" class="ltx_text ltx_font_italic">Anonymization:</span> Theoretically, one could remove personally identifiable information before sharing it.
However, in practice, anonymization fails to provide realistic privacy guarantees because a malevolent actor often has auxiliary information that allows them to re-identify anonymized data.
For example, when Netflix de-identified movie rankings (as part of a challenge seeking better recommendation systems), Arvind Narayanan and Vitaly Shmatikov <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref"><span class="ltx_text ltx_font_italic" style="font-size:90%;">1</span></a>]</cite> de-anonymized a large chunk by cross-referencing them with public information on IMDb.</p>
</div>
<div id="Sx1.p3" class="ltx_para ltx_noindent">
<p id="Sx1.p3.1" class="ltx_p"><span id="Sx1.p3.1.1" class="ltx_text ltx_font_italic">Aggregation:</span> Another approach is to share aggregate statistics about a dataset.
For example, telcos can provide statistics about how many people are in some specific locations at a given time — e.g., to assess footfall and decide where one should open a new store.
However, this is often ineffective too <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref"><span class="ltx_text ltx_font_italic" style="font-size:90%;">2</span></a>, <a href="#bib.bib3" title="" class="ltx_ref"><span class="ltx_text ltx_font_italic" style="font-size:90%;">3</span></a>]</cite>, as the aggregates can still help an adversary learn something about specific individuals.</p>
</div>
<div id="Sx1.p4" class="ltx_para ltx_noindent">
<p id="Sx1.p4.1" class="ltx_p"><span id="Sx1.p4.1.1" class="ltx_text ltx_font_italic">Differential Privacy:</span> More promising attempts come from providing access to statistics obtained from the data while adding noise to the queries’ response, guaranteeing <a target="_blank" href="https://towardsdatascience.com/understanding-differential-privacy-85ce191e198a" title="" class="ltx_ref ltx_href">differential privacy</a> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref"><span class="ltx_text ltx_font_italic" style="font-size:90%;">4</span></a>]</cite>.
However, this approach generally lowers the dataset’s utility, especially on high-dimensional data.
Additionally, allowing unlimited non-trivial queries on a dataset can reveal the whole dataset, so this approach needs to keep track of the privacy budget over time.</p>
</div>
</section>
<section id="Sx2" class="ltx_section ltx_indentfirst">
<h2 class="ltx_title ltx_title_section">Types of Synthetic Data</h2>

<div id="Sx2.p1" class="ltx_para">
<p id="Sx2.p1.1" class="ltx_p">There are different approaches to generating synthetic data.
Derek Snow of the Alan Turing Institute lists <a target="_blank" href="https://blog.ml-quant.com/p/deep-generative-models-are-privacy" title="" class="ltx_ref ltx_href">three main methods</a>:</p>
</div>
<div id="Sx2.p2" class="ltx_para">
<ol id="Sx2.I1" class="ltx_enumerate">
<li id="Sx2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="Sx2.I1.i1.p1" class="ltx_para">
<p id="Sx2.I1.i1.p1.1" class="ltx_p"><span id="Sx2.I1.i1.p1.1.1" class="ltx_text ltx_font_italic">Hand-engineered methods</span> identify an underlying distribution from real data using expert opinion and seek to imitate it.</p>
</div>
</li>
<li id="Sx2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="Sx2.I1.i2.p1" class="ltx_para">
<p id="Sx2.I1.i2.p1.1" class="ltx_p"><span id="Sx2.I1.i2.p1.1.1" class="ltx_text ltx_font_italic">Agent-based models</span> establish known agents and allow them to interact according to prescribed rules hoping that this interaction would ultimately amount to distribution profiles that look similar to the original dataset.</p>
</div>
</li>
<li id="Sx2.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="Sx2.I1.i3.p1" class="ltx_para">
<p id="Sx2.I1.i3.p1.1" class="ltx_p"><span id="Sx2.I1.i3.p1.1.1" class="ltx_text ltx_font_italic">Generative machine models</span> learn how a dataset is generated using a probabilistic model and create synthetic data by sampling from the learned distribution.</p>
</div>
</li>
</ol>
</div>
<div id="Sx2.p3" class="ltx_para">
<p id="Sx2.p3.1" class="ltx_p">In the rest of this article, we will focus on <span id="Sx2.p3.1.1" class="ltx_text ltx_font_bold ltx_font_italic">generative models</span>, as they are generally considered state-of-the-art.
(Additional methods include imputation models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref"><span class="ltx_text ltx_font_italic" style="font-size:90%;">5</span></a>]</cite>.)</p>
</div>
</section>
<section id="Sx3" class="ltx_section ltx_indentfirst">
<h2 class="ltx_title ltx_title_section">Background: Generative vs. Discriminative Models</h2>

<div id="Sx3.p1" class="ltx_para">
<p id="Sx3.p1.1" class="ltx_p">A good way to understand how generative models work is to look at how they differ from discriminative models.
Let’s say we want to recognize which paintings are by Vincent Van Gogh.
First, we label a dataset of artworks we know whether or not were painted by Van Gogh.
Then, we train a <span id="Sx3.p1.1.1" class="ltx_text ltx_font_italic">discriminative</span> model to learn that specific characteristics (e.g., colors, shapes, or textures) are typical of Van Gogh.
We can now use that model to predict whether Van Gogh authored any painting.
<br class="ltx_break"></p>
</div>
<figure id="Sx3.F1" class="ltx_figure"><img src="/html/2303.01230/assets/figures/gedl_0102.png" id="Sx3.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="509" height="164" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span><span id="Sx3.F1.2.1" class="ltx_text ltx_font_italic">Discriminative</span> Machine Learning Models. (Source: David Foster, “<a target="_blank" href="https://learning.oreilly.com/library/view/generative-deep-learning/9781492041931/" title="" class="ltx_ref ltx_href">Generative Deep Learning.</a>”)</figcaption>
</figure>
<div id="Sx3.p2" class="ltx_para">
<p id="Sx3.p2.1" class="ltx_p">Now let’s say we want to generate a new image of a horse that doesn’t exist but still looks real.
We train a <span id="Sx3.p2.1.1" class="ltx_text ltx_font_italic">generative</span> model to learn <span id="Sx3.p2.1.2" class="ltx_text ltx_font_italic">what horses look like</span>.
To do so, we need a dataset with many examples (observations) of horses.
<br class="ltx_break"></p>
</div>
<figure id="Sx3.F2" class="ltx_figure"><img src="/html/2303.01230/assets/figures/gedl_0101.png" id="Sx3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="479" height="177" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span><span id="Sx3.F2.2.1" class="ltx_text ltx_font_italic">Generative</span> Machine Learning Models. (Source: David Foster, “<a target="_blank" href="https://learning.oreilly.com/library/view/generative-deep-learning/9781492041931/" title="" class="ltx_ref ltx_href">Generative Deep Learning.</a>”)</figcaption>
</figure>
<div id="Sx3.p3" class="ltx_para">
<p id="Sx3.p3.1" class="ltx_p">Each observation has many characteristics (or <span id="Sx3.p3.1.1" class="ltx_text ltx_font_italic">features</span>), e.g., each pixel value.
The goal is to build a model that can generate new sets of features that look like they have been created using the same rules as the original data.</p>
</div>
</section>
<section id="Sx4" class="ltx_section ltx_indentfirst">
<h2 class="ltx_title ltx_title_section">Algorithms</h2>

<div id="Sx4.p1" class="ltx_para">
<p id="Sx4.p1.1" class="ltx_p">Generative models used to produce synthetic data may use a number of architectures.
You may have heard of Generative Adversarial Networks, or GANs <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref"><span class="ltx_text ltx_font_italic" style="font-size:90%;">6</span></a>]</cite>, which can be used to generate artificial images, videos, etc.
(Heard of <a target="_blank" href="https://en.wikipedia.org/wiki/Deepfake" title="" class="ltx_ref ltx_href">deep fakes</a>?).
The basic idea behind GANs is to pit two neural networks against each other: a generator tries to fool the discriminator by producing real-looking images while the discriminator tries to distinguish between real and fake images.
The process ends when the discriminator can no longer discern.
<br class="ltx_break"></p>
</div>
<figure id="Sx4.F3" class="ltx_figure"><img src="/html/2303.01230/assets/figures/nvidia.jpg" id="Sx4.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="389" height="195" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span><span id="Sx4.F3.2.1" class="ltx_text ltx_font_italic">Generative</span> GAN-generated, artificial images. (Source: <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref"><span class="ltx_text ltx_font_italic" style="font-size:90%;">7</span></a>]</cite>)</figcaption>
</figure>
<div id="Sx4.p2" class="ltx_para">
<p id="Sx4.p2.1" class="ltx_p">Besides GANs, there are several other architectures used to produce synthetic data.
For instance, Variational Autoencoders try to compress the data to a lower dimensional space and then reconstruct it back to the original.
More methods include Restricted Boltzmann Machines, Bayesian networks, Markov chain Monte Carlo methods, etc.
(Btw did you know that <a target="_blank" href="https://en.wikipedia.org/wiki/ChatGPT" title="" class="ltx_ref ltx_href">ChatGPT</a> is also a generative model?)</p>
</div>
<div id="Sx4.p3" class="ltx_para">
<p id="Sx4.p3.1" class="ltx_p"><span id="Sx4.p3.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Note:</span> Throughout the article, I somewhat abuse the term “generative models.”
While all the synthetic data techniques we consider use machine learning models (they train a model to learn the dataset distribution), some are not technically generative models.
Please let this one slide :-)</p>
</div>
</section>
<section id="Sx5" class="ltx_section ltx_indentfirst">
<h2 class="ltx_title ltx_title_section">What Can Synthetic Data Be Used For?</h2>

<div id="Sx5.p1" class="ltx_para">
<p id="Sx5.p1.1" class="ltx_p">Let’s start with how companies <a target="_blank" href="https://techcrunch.com/2022/05/10/the-market-for-synthetic-data-is-bigger-than-you-think/" title="" class="ltx_ref ltx_href">market</a> their synthetic data technologies in this space, looking at material by <a target="_blank" href="https://datagen.tech" title="" class="ltx_ref ltx_href">Datagen</a>, <a target="_blank" href="https://mostly.ai" title="" class="ltx_ref ltx_href">Mostly.ai</a>, <a target="_blank" href="https://hazy.com" title="" class="ltx_ref ltx_href">Hazy</a>, <a target="_blank" href="https://gretel.ai" title="" class="ltx_ref ltx_href">Gretel.ai</a>, and <a target="_blank" href="https://aindo.com" title="" class="ltx_ref ltx_href">Aindo</a>.
They mention several use cases, including:</p>
</div>
<div id="Sx5.p2" class="ltx_para">
<ol id="Sx5.I2" class="ltx_enumerate">
<li id="Sx5.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="Sx5.I2.i1.p1" class="ltx_para">
<p id="Sx5.I2.i1.p1.1" class="ltx_p"><span id="Sx5.I2.i1.p1.1.1" class="ltx_text ltx_font_italic">Training Machine Learning Models:</span> synthetic data can be used to augment real data, upsample/rebalance under-represented classes, or make models more robust to special events, e.g., in the context of fraud detection <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref"><span class="ltx_text ltx_font_italic" style="font-size:90%;">8</span></a>]</cite>, healthcare <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref"><span class="ltx_text ltx_font_italic" style="font-size:90%;">9</span></a>]</cite>, etc.</p>
</div>
</li>
<li id="Sx5.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="Sx5.I2.i2.p1" class="ltx_para">
<p id="Sx5.I2.i2.p1.1" class="ltx_p"><span id="Sx5.I2.i2.p1.1.1" class="ltx_text ltx_font_italic">Product and Software Testing:</span> generating synthetic test data can be easier than obtaining real rule-based test data to provide “<a target="_blank" href="https://datagen.tech/guides/synthetic-data/synthetic-data/" title="" class="ltx_ref ltx_href">flexibility, scalability, and realism</a>” during testing.
For example, companies often can’t legally use production data for testing purposes.</p>
</div>
</li>
<li id="Sx5.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="Sx5.I2.i3.p1" class="ltx_para">
<p id="Sx5.I2.i3.p1.1" class="ltx_p"><span id="Sx5.I2.i3.p1.1.1" class="ltx_text ltx_font_italic">Governance:</span> synthetic data can help remove biases, stress-test models, and increase explainability.</p>
</div>
</li>
<li id="Sx5.I2.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="Sx5.I2.i4.p1" class="ltx_para">
<p id="Sx5.I2.i4.p1.1" class="ltx_p"><span id="Sx5.I2.i4.p1.1.1" class="ltx_text ltx_font_italic">Privacy:</span> synthetic data can mitigate privacy concerns when sharing or using data across and within organizations.
Datasets are considered “anonymous,” “safe,” or void of personally identifiable information.
This allows data scientists to comply with data protection regulations like <a target="_blank" href="https://en.wikipedia.org/wiki/Health_Insurance_Portability_and_Accountability_Act" title="" class="ltx_ref ltx_href">HIPAA</a> (in the US), <a target="_blank" href="https://en.wikipedia.org/wiki/General_Data_Protection_Regulation" title="" class="ltx_ref ltx_href">GDPR</a> (in the EU), or <a target="_blank" href="https://en.wikipedia.org/wiki/California_Consumer_Privacy_Act" title="" class="ltx_ref ltx_href">CCPA</a> (in California), etc.</p>
</div>
</li>
</ol>
</div>
<div id="Sx5.p3" class="ltx_para">
<p id="Sx5.p3.1" class="ltx_p">Overall, over the past few years, there have been several initiatives and efforts both in industry and government.
For example, the UK’s National Health Service piloted a project to <a target="_blank" href="https://data.england.nhs.uk/dataset/a-e-synthetic-data" title="" class="ltx_ref ltx_href">release synthetic data</a> from “A&amp;E” (i.e., Emergency Rooms in England) activity data and admitted patient care.
In 2018 and 2020, the US National Institute of Standards and Technology (NIST) ran two challenges related to synthetic data: the Differential Privacy <a target="_blank" href="https://www.nist.gov/ctl/pscr/open-innovation-prize-challenges/past-prize-challenges/2018-differential-privacy-synthetic" title="" class="ltx_ref ltx_href">Synthetic Data</a> and <a target="_blank" href="https://www.nist.gov/ctl/pscr/open-innovation-prize-challenges/past-prize-challenges/2020-differential-privacy-temporal" title="" class="ltx_ref ltx_href">Temporal Map</a> challenges, awarding cash prizes seeking innovative synthetic data algorithms and metrics.</p>
</div>
</section>
<section id="Sx6" class="ltx_section ltx_indentfirst">
<h2 class="ltx_title ltx_title_section">Risks of Using Synthetic Data</h2>

<div id="Sx6.p1" class="ltx_para">
<p id="Sx6.p1.1" class="ltx_p">To reason around the risks of synthetic data, researchers have used a few “metrics” to measure privacy properties.</p>
</div>
<div id="Sx6.p2" class="ltx_para ltx_noindent">
<p id="Sx6.p2.1" class="ltx_p"><span id="Sx6.p2.1.1" class="ltx_text ltx_font_bold">Linkage.</span>
Because synthetic data is “artificial,” a common argument is that there is no direct link between real and synthetic records, unlike anonymized records.
Thus, researchers have used similarity tests between real and synthetic records to support the safety of synthetic data.
Unfortunately, however, this kind of metric fails to grasp the real risks of a strategic adversary using features that are likely to be influenced by the target’s presence.</p>
</div>
<div id="Sx6.p3" class="ltx_para ltx_noindent">
<p id="Sx6.p3.1" class="ltx_p"><span id="Sx6.p3.1.1" class="ltx_text ltx_font_bold">Attribute Disclosure.</span>
This kind of privacy violation happens whenever access to data allows an attacker to learn <span id="Sx6.p3.1.2" class="ltx_text ltx_font_italic">new</span> information about a specific individual <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref"><span class="ltx_text ltx_font_italic" style="font-size:90%;">10</span></a>]</cite>, e.g., the value of a particular attribute like race, age, income, etc.
Unfortunately, if the real data contains strong correlations between attributes, these correlations will likely be replicated in the synthetic data and available to the adversary <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref"><span class="ltx_text ltx_font_italic" style="font-size:90%;">11</span></a>]</cite>.
Furthermore, Theresa Stadler et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref"><span class="ltx_text ltx_font_italic" style="font-size:90%;">11</span></a>]</cite> show that records with rare attributes or whose presence affects the ranges of numerical attributes remain highly vulnerable to disclosure.</p>
</div>
<div id="Sx6.p4" class="ltx_para ltx_noindent">
<p id="Sx6.p4.1" class="ltx_p"><span id="Sx6.p4.1.1" class="ltx_text ltx_font_bold">Attacks.</span>
Roughly speaking, linkage is often formulated as a successful <span id="Sx6.p4.1.2" class="ltx_text ltx_font_italic">membership inference</span> attack.
Here an adversary aims to infer if the data from specific target individuals were relied upon by the synthetic data generation process:
<br class="ltx_break"></p>
</div>
<figure id="Sx6.F4" class="ltx_figure"><img src="/html/2303.01230/assets/figures/membership.jpg" id="Sx6.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="479" height="257" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Membership Inference Attack (Source: <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref"><span class="ltx_text ltx_font_italic" style="font-size:90%;">12</span></a>]</cite>)</figcaption>
</figure>
<div id="Sx6.p5" class="ltx_para ltx_noindent">
<p id="Sx6.p5.1" class="ltx_p">Consider the example in the figure above where synthetic health images are used for research: discovering that a specific record was used in a study leaks information about the individual’s health.</p>
</div>
<div id="Sx6.p6" class="ltx_para">
<p id="Sx6.p6.1" class="ltx_p">Attribute disclosure is usually formulated as an <span id="Sx6.p6.1.1" class="ltx_text ltx_font_italic">attribute/property inference</span> attack.
Here, the adversary, given some public information, tries to reconstruct some private attributes of some target users.</p>
</div>
<figure id="Sx6.F5" class="ltx_figure"><img src="/html/2303.01230/assets/figures/attribute.png" id="Sx6.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="538" height="230" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Attribute Inference Attack.</figcaption>
</figure>
<div id="Sx6.p7" class="ltx_para ltx_noindent">
<p id="Sx6.p7.1" class="ltx_p"><span id="Sx6.p7.1.1" class="ltx_text ltx_font_bold">How realistic are the attacks?</span>
One important thing to understand about most privacy studies is that they do not provide <span id="Sx6.p7.1.2" class="ltx_text ltx_font_italic">“binary”</span> answers, e.g., telling us that some method either provides perfect privacy or none at all.
Instead, they provide probability distributions vis-à-vis different systems/threat models, adversarial assumptions, datasets, etc.</p>
</div>
<div id="Sx6.p8" class="ltx_para">
<p id="Sx6.p8.1" class="ltx_p">However, the picture is quite bleak, with a significant number of gaps identified by state-of-the-art research studies.
In practice, synthetic data provides little additional protection compared to anonymization techniques, with privacy-utility trade-offs being even harder to predict <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref"><span class="ltx_text ltx_font_italic" style="font-size:90%;">11</span></a>]</cite>.</p>
</div>
<div id="Sx6.p9" class="ltx_para ltx_noindent">
<p id="Sx6.p9.1" class="ltx_p"><span id="Sx6.p9.1.1" class="ltx_text ltx_font_bold">Enter Differential Privacy.</span>
What can we do to increase the privacy protection of synthetic data?
The state-of-the-art method for providing access to information free from inferences is to satisfy <a target="_blank" href="https://towardsdatascience.com/understanding-differential-privacy-85ce191e198a" title="" class="ltx_ref ltx_href">differential privacy</a> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref"><span class="ltx_text ltx_font_italic" style="font-size:90%;">4</span></a>]</cite>.
Generally speaking, differential privacy provides mathematical guarantees against what an adversary can infer from learning the result of some algorithm.
In other words, it guarantees that an individual will be exposed to the same privacy risk whether or not her data is included in a differentially private analysis.
Overall, differential privacy is generally achieved by adding noise at various steps.</p>
</div>
<div id="Sx6.p10" class="ltx_para">
<p id="Sx6.p10.1" class="ltx_p">In the context of synthetic data, the idea is to train the generative models used to produce synthetic data in a differentially private manner.
Typically, one of three methods is used: using the Laplace mechanism, sanitizing the gradients during stochastic gradient descent, or using a technique called PATE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref"><span class="ltx_text ltx_font_italic" style="font-size:90%;">13</span></a>]</cite>. 
The resulting methods tend to combine generative model architectures with differential privacy; state-of-the-art tools include DP-GAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref"><span class="ltx_text ltx_font_italic" style="font-size:90%;">14</span></a>]</cite>, DP-WGAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref"><span class="ltx_text ltx_font_italic" style="font-size:90%;">15</span></a>]</cite>, DP-Syn <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref"><span class="ltx_text ltx_font_italic" style="font-size:90%;">16</span></a>]</cite>, PrivBayes <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref"><span class="ltx_text ltx_font_italic" style="font-size:90%;">17</span></a>]</cite>, PATE-GAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref"><span class="ltx_text ltx_font_italic" style="font-size:90%;">18</span></a>]</cite>, etc. 
A list of relevant papers (with code) is available on Georgi Ganev’s <a target="_blank" href="https://github.com/ganevgv/dp-generative-models" title="" class="ltx_ref ltx_href">GitHub page</a>.</p>
</div>
</section>
<section id="Sx7" class="ltx_section ltx_indentfirst">
<h2 class="ltx_title ltx_title_section">The Inherent Limitations</h2>

<div id="Sx7.p1" class="ltx_para">
<p id="Sx7.p1.1" class="ltx_p">As a privacy researcher, my focus on the limitations of synthetic data is mainly on its security and privacy shortcomings.
There likely are other challenges, e.g., regarding usability, fidelity, and interpretability, but I leave it to my more qualified colleagues to chime in.</p>
</div>
<div id="Sx7.p2" class="ltx_para">
<p id="Sx7.p2.1" class="ltx_p">When it comes to privacy, it is unlikely that synthetic data will provide a silver bullet to sanitize sensitive data or safely share confidential information across the board.
Instead, there could be specific use cases where training a generative model provides better flexibility and privacy protection than the alternatives.
For instance, financial companies can use synthetic data to ensure production data is not used during testing or shared across different sub-organizations.
Or perhaps governmental agencies could enable citizens and entities to extract high-level statistics from certain data distributions without doing it themselves.</p>
</div>
<div id="Sx7.p3" class="ltx_para">
<p id="Sx7.p3.1" class="ltx_p">But those case studies are arguably not going to generalize.
Put simply, generative models trained without differential privacy (or with very large privacy budgets) do not provide high safety, privacy, or confidentiality levels.
Conversely, differential privacy can but with a non-negligible cost to utility/accuracy.
More precisely, protecting privacy inherently means you must “hide” vulnerable data points like outliers, etc.
So if you want to use synthetic data to upsample an under-represented class, train a fraud/anomaly detection model, etc., you will have <span id="Sx7.p3.1.1" class="ltx_text ltx_font_italic">either</span> privacy <span id="Sx7.p3.1.2" class="ltx_text ltx_font_italic">or</span> utility.</p>
</div>
<div id="Sx7.p4" class="ltx_para">
<p id="Sx7.p4.1" class="ltx_p">Another limitation is that usable privacy mechanisms must be <a target="_blank" href="https://edps.europa.eu/sites/edp/files/publication/18-05-31_preliminary_opinion_on_privacy_by_design_en_0.pdf" title="" class="ltx_ref ltx_href ltx_font_italic">predictable</a><span id="Sx7.p4.1.1" class="ltx_text ltx_font_italic">, i.e., building on a <a target="_blank" href="https://blog.lukaszolejnik.com/privacy-engineering-principles-recommended-by-nist/" title="" class="ltx_ref ltx_href">good understanding</a> of how data will be handled and protected.
That’s not always the case with synthetic data, because of the probabilistic nature of generative models and the inherent difficulty of predicting what signals a synthetic dataset will preserve and what information will be lost <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref"><span class="ltx_text ltx_font_italic" style="font-size:90%;">11</span></a>]</cite>.</span></p>
</div>
</section>
<section id="Sx8" class="ltx_section ltx_indentfirst">
<h2 class="ltx_title ltx_font_italic ltx_title_section">Looking Ahead</h2>

<div id="Sx8.p1" class="ltx_para">
<p id="Sx8.p1.1" class="ltx_p"><span id="Sx8.p1.1.1" class="ltx_text ltx_font_italic">There are several interesting open research questions in this field.
For instance, the differential privacy framework often provides an overly conservative approach to privacy.
This is for good measure, as we want a worst-case definition that is as agnostic as possible to any adversarial assumption.
But in practice, the accuracy of the attacks we can realistically implement is measurably far from the theoretical bounds.</span></p>
</div>
<div id="Sx8.p2" class="ltx_para">
<p id="Sx8.p2.1" class="ltx_p"><span id="Sx8.p2.1.1" class="ltx_text ltx_font_italic">The privacy engineering community can help practitioners and stakeholders identify the use cases where synthetic data can be used safely, perhaps even in a semi-automated way.
At the very least, the research community should provide actionable guidelines to understand the distributions, types of data, tasks, settings, etc. where we could, at least in principle, achieve reasonable privacy-utility tradeoffs via synthetic data produced by generative models.</span></p>
</div>
<section id="Sx8.SSx1" class="ltx_subsection ltx_indentfirst">
<h3 class="ltx_title ltx_font_italic ltx_title_subsection">Acknowledgements</h3>

<div id="Sx8.SSx1.p1" class="ltx_para ltx_noindent">
<p id="Sx8.SSx1.p1.1" class="ltx_p"><span id="Sx8.SSx1.p1.1.1" class="ltx_text ltx_font_italic">Many thanks to </span><a target="_blank" href="https://ganevgv.github.io/" title="" class="ltx_ref ltx_href ltx_font_italic">Georgi Ganev</a><span id="Sx8.SSx1.p1.1.2" class="ltx_text ltx_font_italic">, </span><a target="_blank" href="https://www.linkedin.com/in/maria-bristena-oprisanu-phd-61a5a35b/" title="" class="ltx_ref ltx_href ltx_font_italic">Bristena Oprisanu</a><span id="Sx8.SSx1.p1.1.3" class="ltx_text ltx_font_italic">, and </span><a target="_blank" href="https://msundarmsa.github.io/" title="" class="ltx_ref ltx_href ltx_font_italic">Meenatchi Sundaram Muthu Selva Annamalai</a><span id="Sx8.SSx1.p1.1.4" class="ltx_text ltx_font_italic"> for reviewing a draft of this article.
A preliminary version of this article appeared on </span><a target="_blank" href="https://www.benthamsgaze.org/2023/03/01/what-is-synthetic-data-the-good-the-bad-and-the-ugly/" title="" class="ltx_ref ltx_href ltx_font_italic">benthamsgaze.org</a><span id="Sx8.SSx1.p1.1.5" class="ltx_text ltx_font_italic">.</span></p>
</div>
</section>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_font_italic ltx_title_bibliography" style="font-size:90%;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib1.2.2.1" class="ltx_text ltx_font_italic" style="font-size:90%;">[1]</span></span>
<span class="ltx_bibblock"><span id="bib.bib1.4.1" class="ltx_text ltx_font_italic" style="font-size:90%;">
Arvind Narayanan and Vitaly Shmatikov.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.5.1" class="ltx_text ltx_font_italic" style="font-size:90%;">De-anonymizing social networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">In </span><span id="bib.bib1.7.2" class="ltx_text ltx_font_normal" style="font-size:90%;">IEEE S&amp;P</span><span id="bib.bib1.8.3" class="ltx_text ltx_font_italic" style="font-size:90%;">, 2009.
</span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib2.2.2.1" class="ltx_text ltx_font_italic" style="font-size:90%;">[2]</span></span>
<span class="ltx_bibblock"><span id="bib.bib2.4.1" class="ltx_text ltx_font_italic" style="font-size:90%;">
Apostolos Pyrgelis.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.5.1" class="ltx_text ltx_font_italic" style="font-size:90%;">On Location, Time, and Membership: Studying How Aggregate Location
Data Can Harm Users’ Privacy.
</span>
</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.benthamsgaze.org/2018/10/02/on-location-time-and-membership-studying-how-aggregate-location-data-can-harm-users-privacy/" title="" class="ltx_ref ltx_url ltx_font_italic" style="font-size:90%;">https://www.benthamsgaze.org/2018/10/02/on-location-time-and-membership-studying-how-aggregate-location-data-can-harm-users-privacy/</a><span id="bib.bib2.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">,
2018.
</span>
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib3.2.2.1" class="ltx_text ltx_font_italic" style="font-size:90%;">[3]</span></span>
<span class="ltx_bibblock"><span id="bib.bib3.4.1" class="ltx_text ltx_font_italic" style="font-size:90%;">
Apostolos Pyrgelis, Carmela Troncoso, and Emiliano De Cristofaro.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.5.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Knock Knock, Who’s There? Membership Inference on Aggregate Location
Data.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">In </span><span id="bib.bib3.7.2" class="ltx_text ltx_font_normal" style="font-size:90%;">NDSS</span><span id="bib.bib3.8.3" class="ltx_text ltx_font_italic" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib4.2.2.1" class="ltx_text ltx_font_italic" style="font-size:90%;">[4]</span></span>
<span class="ltx_bibblock"><span id="bib.bib4.4.1" class="ltx_text ltx_font_italic" style="font-size:90%;">
Kobbi Nissim, Thomas Steinke, Alexandra Wood, Micah Altman, Aaron Bembenek,
Mark Bun, Marco Gaboardi, David R O’Brien, and Salil Vadhan.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.5.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Differential privacy: A primer for a non-technical audience.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">In </span><span id="bib.bib4.7.2" class="ltx_text ltx_font_normal" style="font-size:90%;">Privacy Law Scholars Conference</span><span id="bib.bib4.8.3" class="ltx_text ltx_font_italic" style="font-size:90%;">, 2017.
</span>
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib5.2.2.1" class="ltx_text ltx_font_italic" style="font-size:90%;">[5]</span></span>
<span class="ltx_bibblock"><span id="bib.bib5.4.1" class="ltx_text ltx_font_italic" style="font-size:90%;">
Donald B Rubin.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.5.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Statistical disclosure limitation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.6.1" class="ltx_text ltx_font_normal" style="font-size:90%;">Journal of official Statistics</span><span id="bib.bib5.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">, 1993.
</span>
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib6.2.2.1" class="ltx_text ltx_font_italic" style="font-size:90%;">[6]</span></span>
<span class="ltx_bibblock"><span id="bib.bib6.4.1" class="ltx_text ltx_font_italic" style="font-size:90%;">
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,
Sherjil Ozair, Aaron Courville, and Yoshua Bengio.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.5.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Generative Adversarial Nets.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">In </span><span id="bib.bib6.7.2" class="ltx_text ltx_font_normal" style="font-size:90%;">NIPS</span><span id="bib.bib6.8.3" class="ltx_text ltx_font_italic" style="font-size:90%;">, 2014.
</span>
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib7.2.2.1" class="ltx_text ltx_font_italic" style="font-size:90%;">[7]</span></span>
<span class="ltx_bibblock"><span id="bib.bib7.4.1" class="ltx_text ltx_font_italic" style="font-size:90%;">
Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.5.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Progressive growing of gans for improved quality, stability, and
variation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.6.1" class="ltx_text ltx_font_normal" style="font-size:90%;">arXiv:1710.10196</span><span id="bib.bib7.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">, 2017.
</span>
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib8.2.2.1" class="ltx_text ltx_font_italic" style="font-size:90%;">[8]</span></span>
<span class="ltx_bibblock"><span id="bib.bib8.4.1" class="ltx_text ltx_font_italic" style="font-size:90%;">
Mostly.ai.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.5.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Synthetic training data for improving fraud and anomaly AI’s
performance.
</span>
</span>
<span class="ltx_bibblock"><a target="_blank" href="https://mostly.ai/case-study/synthetic-training-data-for-machine-learning-fraud-detection/" title="" class="ltx_ref ltx_url ltx_font_italic" style="font-size:90%;">https://mostly.ai/case-study/synthetic-training-data-for-machine-learning-fraud-detection/</a><span id="bib.bib8.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">,
2023.
</span>
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib9.2.2.1" class="ltx_text ltx_font_italic" style="font-size:90%;">[9]</span></span>
<span class="ltx_bibblock"><span id="bib.bib9.4.1" class="ltx_text ltx_font_italic" style="font-size:90%;">
Allan Tucker, Zhenchen Wang, Ylenia Rotalinti, and Puja Myles.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.5.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Generating high-fidelity synthetic patient data for assessing machine
learning healthcare software.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.6.1" class="ltx_text ltx_font_normal" style="font-size:90%;">NPJ digital medicine</span><span id="bib.bib9.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">, 3(1), 2020.
</span>
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib10.2.2.1" class="ltx_text ltx_font_italic" style="font-size:90%;">[10]</span></span>
<span class="ltx_bibblock"><span id="bib.bib10.4.1" class="ltx_text ltx_font_italic" style="font-size:90%;">
Markus Hittmeir, Rudolf Mayer, and Andreas Ekelhart.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.5.1" class="ltx_text ltx_font_italic" style="font-size:90%;">A baseline for attribute disclosure risk in synthetic data.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">In </span><span id="bib.bib10.7.2" class="ltx_text ltx_font_normal" style="font-size:90%;">ACM CODASPY</span><span id="bib.bib10.8.3" class="ltx_text ltx_font_italic" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib11.2.2.1" class="ltx_text ltx_font_italic" style="font-size:90%;">[11]</span></span>
<span class="ltx_bibblock"><span id="bib.bib11.4.1" class="ltx_text ltx_font_italic" style="font-size:90%;">
Theresa Stadler, Bristena Oprisanu, and Carmela Troncoso.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.5.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Synthetic data–anonymisation groundhog day.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">In </span><span id="bib.bib11.7.2" class="ltx_text ltx_font_normal" style="font-size:90%;">USENIX Security Symposium</span><span id="bib.bib11.8.3" class="ltx_text ltx_font_italic" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib12.2.2.1" class="ltx_text ltx_font_italic" style="font-size:90%;">[12]</span></span>
<span class="ltx_bibblock"><span id="bib.bib12.4.1" class="ltx_text ltx_font_italic" style="font-size:90%;">
Ziqi Zhang, Chao Yan, and Bradley A Malin.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.5.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Membership inference attacks against synthetic health data.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.6.1" class="ltx_text ltx_font_normal" style="font-size:90%;">Journal of biomedical informatics</span><span id="bib.bib12.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">, 125, 2022.
</span>
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib13.2.2.1" class="ltx_text ltx_font_italic" style="font-size:90%;">[13]</span></span>
<span class="ltx_bibblock"><span id="bib.bib13.4.1" class="ltx_text ltx_font_italic" style="font-size:90%;">
Nicolas Papernot, Shuang Song, Ilya Mironov, Ananth Raghunathan, Kunal Talwar,
and Úlfar Erlingsson.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.5.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Scalable private learning with PATE.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.6.1" class="ltx_text ltx_font_normal" style="font-size:90%;">arXiv:1802.08908</span><span id="bib.bib13.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib14.2.2.1" class="ltx_text ltx_font_italic" style="font-size:90%;">[14]</span></span>
<span class="ltx_bibblock"><span id="bib.bib14.4.1" class="ltx_text ltx_font_italic" style="font-size:90%;">
Liyang Xie, Kaixiang Lin, Shu Wang, Fei Wang, and Jiayu Zhou.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.5.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Differentially private generative adversarial network.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.6.1" class="ltx_text ltx_font_normal" style="font-size:90%;">arXiv:1802.06739</span><span id="bib.bib14.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib15.2.2.1" class="ltx_text ltx_font_italic" style="font-size:90%;">[15]</span></span>
<span class="ltx_bibblock"><span id="bib.bib15.4.1" class="ltx_text ltx_font_italic" style="font-size:90%;">
Moustafa Alzantot and Mani Srivastava.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.5.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Differential Privacy Synthetic Data Generation using WGANs.
</span>
</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/nesl/nist_differential_privacy_synthetic_data_challenge/" title="" class="ltx_ref ltx_url ltx_font_italic" style="font-size:90%;">https://github.com/nesl/nist_differential_privacy_synthetic_data_challenge/</a><span id="bib.bib15.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">,
2019.
</span>
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib16.2.2.1" class="ltx_text ltx_font_italic" style="font-size:90%;">[16]</span></span>
<span class="ltx_bibblock"><span id="bib.bib16.4.1" class="ltx_text ltx_font_italic" style="font-size:90%;">
Ninghui Li, Zhikun Zhang, and Tianhao Wang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.5.1" class="ltx_text ltx_font_italic" style="font-size:90%;">DPSyn: Experiences in the nist differential privacy data synthesis
challenges.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.6.1" class="ltx_text ltx_font_normal" style="font-size:90%;">arXiv:2106.12949</span><span id="bib.bib16.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib17.2.2.1" class="ltx_text ltx_font_italic" style="font-size:90%;">[17]</span></span>
<span class="ltx_bibblock"><span id="bib.bib17.4.1" class="ltx_text ltx_font_italic" style="font-size:90%;">
Jun Zhang, Graham Cormode, Cecilia M. Procopiuc, Divesh Srivastava, and Xiaokui
Xiao.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.5.1" class="ltx_text ltx_font_italic" style="font-size:90%;">PrivBayes: Private Data Release via Bayesian Networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.6.1" class="ltx_text ltx_font_normal" style="font-size:90%;">ACM Transactions on Database Systems</span><span id="bib.bib17.7.2" class="ltx_text ltx_font_italic" style="font-size:90%;">, 2017.
</span>
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib18.2.2.1" class="ltx_text ltx_font_italic" style="font-size:90%;">[18]</span></span>
<span class="ltx_bibblock"><span id="bib.bib18.4.1" class="ltx_text ltx_font_italic" style="font-size:90%;">
James Jordon, Jinsung Yoon, and Mihaela Van Der Schaar.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.5.1" class="ltx_text ltx_font_italic" style="font-size:90%;">PATE-GAN: Generating synthetic data with differential privacy
guarantees.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.6.1" class="ltx_text ltx_font_italic" style="font-size:90%;">In </span><span id="bib.bib18.7.2" class="ltx_text ltx_font_normal" style="font-size:90%;">ICLR</span><span id="bib.bib18.8.3" class="ltx_text ltx_font_italic" style="font-size:90%;">, 2018.
</span>
</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2303.01229" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2303.01230" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2303.01230">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2303.01230" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2303.01231" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Feb 29 22:06:39 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
