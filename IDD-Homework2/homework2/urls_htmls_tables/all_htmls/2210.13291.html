<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2210.13291] NVIDIA FLARE: Federated Learning from Simulation to Real-World</title><meta property="og:description" content="Federated learning (FL) enables building robust and generalizable AI models by leveraging diverse datasets from multiple collaborators without centralizing the data. We created NVIDIA FLARE111Code is available at https…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="NVIDIA FLARE: Federated Learning from Simulation to Real-World">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="NVIDIA FLARE: Federated Learning from Simulation to Real-World">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2210.13291">

<!--Generated on Tue Feb 27 02:34:11 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">NVIDIA FLARE:
<br class="ltx_break">Federated Learning from Simulation to Real-World</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Holger R. Roth Yan Cheng Yuhong Wen Isaac Yang Ziyue Xu Yuan-Ting Hsieh 
<br class="ltx_break">Kristopher Kersten Ahmed Harouni Can Zhao Kevin Lu Zhihong Zhang Wenqi Li 
<br class="ltx_break">Andriy Myronenko Dong Yang Sean Yang Nicola Rieke Abood Quraini Chester Chen 
<br class="ltx_break">Daguang Xu Nic Ma Prerna Dogra Mona Flores Andrew Feng
<br class="ltx_break">
<br class="ltx_break">NVIDIA Corporation
<br class="ltx_break">Shanghai, China
<br class="ltx_break">Munich, Germany
<br class="ltx_break">Bethesda, Santa Clara, USA
<br class="ltx_break">
</span><span class="ltx_author_notes">Contact: <span id="id1.1.id1" class="ltx_text ltx_font_typewriter">{hroth,yanc,chesterc,daguangx,pdogra,andyf}@nvidia.com</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id2.id1" class="ltx_p">Federated learning (FL) enables building robust and generalizable AI models by leveraging diverse datasets from multiple collaborators without centralizing the data. We created NVIDIA FLARE<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Code is available at <a target="_blank" href="https://github.com/NVIDIA/NVFlare" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/NVIDIA/NVFlare</a>.</span></span></span> as an open-source software development kit (SDK) to make it easier for data scientists to use FL in their research and real-world applications.
The SDK includes solutions for state-of-the-art FL algorithms and federated machine learning approaches, which facilitate building workflows for distributed learning across enterprises and enable platform developers to create a secure, privacy-preserving offering for multiparty collaboration utilizing homomorphic encryption or differential privacy.
The SDK is a lightweight, flexible, and scalable Python package. It allows researchers to apply their data science workflows in any training libraries (PyTorch, TensorFlow, XGBoost, or even NumPy) in real-world FL settings. This paper introduces the key design principles of NVFlare and illustrates some use cases (e.g., COVID analysis) with customizable FL workflows that implement different privacy-preserving algorithms.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Federated learning (FL) has become a reality for many real-world applications <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>. It enables multinational collaborations on a global scale to build more robust and generalizable machine learning and AI models.
In this paper, we introduce NVIDIA FLARE (NVFlare), an open-source software development kit (SDK) that makes it easier for data scientists to collaborate to develop more generalizable and robust AI models by sharing model weights rather than private data.
While FL is attractive in many industries, it is particularly beneficial for healthcare applications where patient data needs to be protected. For example, FL has been used for predicting clinical outcomes in patients with COVID-19 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> or to segment brain lesions in magnetic resonance imaging <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>, <a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>. NVFlare is not limited to applications in healthcare and is designed to allow cross-silo FL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> across enterprises for different industries and researchers.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">In recent years, several efforts (both open-source and commercial) have been made to bring FL technology into the healthcare sector and other industries, like TensorFlow Federated <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>, PySyft <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite>, FedML <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, FATE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>, Flower <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>, OpenFL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>, Fed-BioMed <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>, IBM Federated Learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>, HP Swarm Learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>, FederatedScope <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>, FLUTE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>, and more. Some focus on simulated FL settings for researchers, while others prioritize production settings. NVFlare aims to be useful for both scenarios: 1) for researchers by providing efficient and extensible simulation tools and 2) by providing an easy path to transfer research into real-world production settings, supporting high availability and server failover, and by providing additional productivity tools such as multi-tasking and admin commands.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>NVIDIA FLARE Overview</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">NVIDIA FLARE – or short NVFlare – stands for “<span id="S2.p1.1.1" class="ltx_text ltx_font_bold">NV</span>IDIA <span id="S2.p1.1.2" class="ltx_text ltx_font_bold">F</span>ederated <span id="S2.p1.1.3" class="ltx_text ltx_font_bold">L</span>earning <span id="S2.p1.1.4" class="ltx_text ltx_font_bold">A</span>pplication <span id="S2.p1.1.5" class="ltx_text ltx_font_bold">R</span>untime <span id="S2.p1.1.6" class="ltx_text ltx_font_bold">E</span>nvironment”.
The SDK enables researchers and data scientists to adapt their machine learning and deep learning workflows to a federated paradigm. It enables platform developers to build a secure, privacy-preserving offering for distributed multiparty collaboration.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">NVFlare is a lightweight, flexible, and scalable FL framework implemented in Python that is agnostic to the underlying training library. Developers can bring their own data science workflows implemented in PyTorch, TensorFlow, or even in pure NumPy, and apply them in a federated setting.
A typical FL workflow such as the popular federated averaging (FedAvg) algorithm <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>, can be implemented in NVFlare using the following main steps. Starting from an initial global model, each FL client trains the model on their local data for a while and sends model updates to the server for aggregation. The server then uses the aggregated updates to update the global model for the next round of training. This process is iterated many times until the model converges.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">Though used heavily for federated deep learning, NVFlare is a generic approach for supporting collaborative computing across multiple clients. NVFlare provides the <span id="S2.p3.1.1" class="ltx_text ltx_font_italic">Controller</span> programming API for researchers to create workflows for coordinating clients for collaboration. FedAvg is one such workflow. Another example is cyclic weight transfer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>.
The central concept of collaboration is the notion of “task”. An FL controller assigns tasks (e.g., deep-learning training with model weights) to one or more FL clients and processes results returned from clients (e.g., model weight updates). The controller may assign additional tasks to clients based on the processed results and other factors (e.g., a pre-configured number of training rounds). This task-based interaction continues until the objectives of the study are achieved.</p>
</div>
<figure id="S2.F1" class="ltx_figure"><img src="/html/2210.13291/assets/fig/controller_worker_flow.png" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="303" height="169" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F1.6.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S2.F1.7.2" class="ltx_text" style="font-size:90%;">NVFlare job execution. The <span id="S2.F1.7.2.1" class="ltx_text ltx_font_italic">Controller</span> is a Python object that controls or coordinates the <span id="S2.F1.7.2.2" class="ltx_text ltx_font_italic">Workers</span> to get a job done. The controller is run on the FL server. A <span id="S2.F1.7.2.3" class="ltx_text ltx_font_italic">Worker</span> is capable of performing tasks. <span id="S2.F1.7.2.4" class="ltx_text ltx_font_italic">Workers</span> run on FL clients. </span></figcaption>
</figure>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p">The API supports typical controller-client interaction patterns like broadcasting a task to multiple clients, sending a task to one or more specified clients, or relaying a task to multiple clients sequentially. Each interaction pattern has two flavors: wait (block until client results are received) or no-wait. A workflow developer can use these interaction patterns to create innovative workflows. For example, the <span id="S2.p4.1.1" class="ltx_text ltx_font_italic">ScatterAndGather</span> controller (typically used for FedAvg-like algorithms) is implemented with the <span id="S2.p4.1.2" class="ltx_text ltx_font_italic">broadcast_and_wait</span> pattern, and the <span id="S2.p4.1.3" class="ltx_text ltx_font_italic">CyclicController</span> is implemented with the <span id="S2.p4.1.4" class="ltx_text ltx_font_italic">relay_and_wait pattern</span>. The controller API allows the researcher to focus on the control logic without needing to deal with underlying communication issues. Figure <a href="#S2.F1" title="Figure 1 ‣ 2 NVIDIA FLARE Overview ‣ NVIDIA FLARE: Federated Learning from Simulation to Real-World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows the principle.
Each FL client acts as a worker that simply executes tasks assigned to it (e.g., model training) and returns execution results to the controller. At each task interaction, there can be optional filters that process the task data or results before passing it to the <span id="S2.p4.1.5" class="ltx_text ltx_font_italic">Controller</span> (on the server side) or task executor (client side). The filter mechanism can be used for data privacy protection (e.g., homomorphic encryption/decryption or differential privacy) without having to alter the training algorithms.</p>
</div>
<section id="S2.SS0.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Key Components</h4>

<div id="S2.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S2.SS0.SSS0.Px1.p1.1" class="ltx_p">NVFlare is built on a componentized architecture that allows FL workloads to move from research and simulation to real-world production deployment. Some of the key components of this SDK include:</p>
</div>
<div id="S2.SS0.SSS0.Px1.p2" class="ltx_para">
<ul id="S2.I1" class="ltx_itemize">
<li id="S2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i1.p1" class="ltx_para">
<p id="S2.I1.i1.p1.1" class="ltx_p"><span id="S2.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">FL Simulator</span> for rapid development and prototyping.</p>
</div>
</li>
<li id="S2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i2.p1" class="ltx_para">
<p id="S2.I1.i2.p1.1" class="ltx_p"><span id="S2.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">NVFlare Dashboard</span> for simplified project management, secure provisioning, and deployment, orchestration.</p>
</div>
</li>
<li id="S2.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i3.p1" class="ltx_para">
<p id="S2.I1.i3.p1.1" class="ltx_p"><span id="S2.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">Reference FL algorithms</span> (e.g., FedAvg, FedProx, SCAFFOLD) and workflows, like scatter and gather, cyclic, etc.</p>
</div>
</li>
<li id="S2.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i4.p1" class="ltx_para">
<p id="S2.I1.i4.p1.1" class="ltx_p"><span id="S2.I1.i4.p1.1.1" class="ltx_text ltx_font_bold">Privacy preservation</span> with differential privacy, homomorphic encryption, and more.</p>
</div>
</li>
<li id="S2.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i5.p1" class="ltx_para">
<p id="S2.I1.i5.p1.1" class="ltx_p"><span id="S2.I1.i5.p1.1.1" class="ltx_text ltx_font_bold">Specification-based API</span> for extensibility, allowing customization with plug-able components.</p>
</div>
</li>
<li id="S2.I1.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i6.p1" class="ltx_para">
<p id="S2.I1.i6.p1.1" class="ltx_p"><span id="S2.I1.i6.p1.1.1" class="ltx_text ltx_font_bold">Tight integration</span> with other learning frameworks like MONAI <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>, XGBoost <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>, and more.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2.SS0.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">High-Level Architecture</h4>

<div id="S2.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S2.SS0.SSS0.Px2.p1.1" class="ltx_p">NVFlare is designed with the idea that less is more, using a specification-based design principle to focus on what is essential.
This allows other people to be able to do what they want to do in real-world applications by following clear API definitions. FL is an open-ended space. The API-based design allows others to bring their implementations and solutions for various components. Controllers, task executors, and filters are just examples of such extensible components.
NVFlare provides an end-to-end operation environment for different personas. It provides a comprehensive provisioning system that creates security credentials for secure communications to enable the easy and secure deployment of FL applications in the real world. It also provides an FL Simulator for running proof-of-concept studies locally.
In production mode, the researcher conducts an FL study by submitting jobs using admin commands using Notebooks or the NVFlare Console – an interactive command tool. NVFlare provides many commands for system operation and job management. With these commands, one can start and stop a specific client or the entire system, submit new jobs, check the status of jobs, create a job by cloning from an existing one, and much more.</p>
</div>
<div id="S2.SS0.SSS0.Px2.p2" class="ltx_para">
<p id="S2.SS0.SSS0.Px2.p2.1" class="ltx_p">With NVFlare’s component-based design, a job is just a configuration of components needed for the study. For the control logic, the job specifies the controller component to be used and any components required by the controller.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>System Concepts</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">A NVFlare system is a typical client-server communication system that comprises one or more FL server(s), one or more FL client(s), and one or more admin clients. The FL Servers open two ports for communication with FL clients and admin clients. FL clients and admin clients connect to the opened ports. FL clients and admin clients do not open any ports and do not directly communicate with each other.
The following is an overview of the key concepts and objects available in NVFlare and the information that can be passed between them.</p>
</div>
<section id="S3.SS0.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Workers and Controller</h4>

<div id="S3.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS0.SSS0.Px1.p1.1" class="ltx_p">NVFlare’s collaborative computing is achieved through the <span id="S3.SS0.SSS0.Px1.p1.1.1" class="ltx_text ltx_font_italic">Controller</span>/<span id="S3.SS0.SSS0.Px1.p1.1.2" class="ltx_text ltx_font_italic">Worker</span> interactions.</p>
</div>
</section>
<section id="S3.SS0.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Shareable</h4>

<div id="S3.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S3.SS0.SSS0.Px2.p1.1" class="ltx_p">Object that represents a communication between server and client. Technically, the <span id="S3.SS0.SSS0.Px2.p1.1.1" class="ltx_text ltx_font_italic">Shareable</span> is implemented as a Python dictionary that could contain different information, e.g., model weights.</p>
</div>
</section>
<section id="S3.SS0.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Data Exchange Object (DXO)</h4>

<div id="S3.SS0.SSS0.Px3.p1" class="ltx_para">
<p id="S3.SS0.SSS0.Px3.p1.1" class="ltx_p">Standardizes the data passed between the communicating parties. One can think of the <span id="S3.SS0.SSS0.Px3.p1.1.1" class="ltx_text ltx_font_italic">Shareable</span> as the envelope and the <span id="S3.SS0.SSS0.Px3.p1.1.2" class="ltx_text ltx_font_italic">DXO</span> as the letter. Together, they comprise a message to be shared between communicating parties.</p>
</div>
</section>
<section id="S3.SS0.SSS0.Px4" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">FLComponent</h4>

<div id="S3.SS0.SSS0.Px4.p1" class="ltx_para">
<p id="S3.SS0.SSS0.Px4.p1.1" class="ltx_p">The base class of all the FL components. Executors, controllers, filters, aggregators, and their subtypes are all <span id="S3.SS0.SSS0.Px4.p1.1.1" class="ltx_text ltx_font_italic">FLComponents</span>.
<span id="S3.SS0.SSS0.Px4.p1.1.2" class="ltx_text ltx_font_italic">FLComponent</span> comes with some useful built-in methods for logging, event handling, auditing, and error handling.</p>
</div>
</section>
<section id="S3.SS0.SSS0.Px5" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Executors</h4>

<div id="S3.SS0.SSS0.Px5.p1" class="ltx_para">
<p id="S3.SS0.SSS0.Px5.p1.1" class="ltx_p">Type of <span id="S3.SS0.SSS0.Px5.p1.1.1" class="ltx_text ltx_font_italic">FLComponent</span> for FL clients that has an execute method that produces a <span id="S3.SS0.SSS0.Px5.p1.1.2" class="ltx_text ltx_font_italic">Shareable</span> from an input <span id="S3.SS0.SSS0.Px5.p1.1.3" class="ltx_text ltx_font_italic">Shareable</span>. NVFlare provides both single- and multi-process executors to implement different computing workloads.</p>
</div>
</section>
<section id="S3.SS0.SSS0.Px6" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">FLContext</h4>

<div id="S3.SS0.SSS0.Px6.p1" class="ltx_para">
<p id="S3.SS0.SSS0.Px6.p1.1" class="ltx_p">One of the most important features of NVFlare is to pass data between the FL components. <span id="S3.SS0.SSS0.Px6.p1.1.1" class="ltx_text ltx_font_italic">FLContext</span> is available to every method of all common FLComponent types. Through <span id="S3.SS0.SSS0.Px6.p1.1.2" class="ltx_text ltx_font_italic">FLContext</span>, the component developer can get services provided by the underlying infrastructure and share data with other components of the FL system.</p>
</div>
</section>
<section id="S3.SS0.SSS0.Px7" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Communication Drivers</h4>

<div id="S3.SS0.SSS0.Px7.p1" class="ltx_para">
<p id="S3.SS0.SSS0.Px7.p1.1" class="ltx_p">NVFlare abstracts the communication layers out so that different deployment scenarios can implement customizable communication drivers. By default, we use GRPC for data communication in task-based communication. However, the driver can be replaced to run other communication protocols, for example, TCP. The customizable nature of communication in NVFlare allows for both server-centric and peer-to-peer communication patterns. This enables the user to utilize both scatter and gather-type workflows like FedAvg <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>, decentralized training patterns like swarm learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>, or direct peer-to-peer communication as in split learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>.</p>
</div>
<div id="S3.SS0.SSS0.Px7.p2" class="ltx_para">
<p id="S3.SS0.SSS0.Px7.p2.1" class="ltx_p">Fig. <a href="#S3.F2" title="Figure 2 ‣ Communication Drivers ‣ 3 System Concepts ‣ NVIDIA FLARE: Federated Learning from Simulation to Real-World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> compares the times for model upload and download from the client’s perspective using different communication protocols available in NVFlare using a model of <math id="S3.SS0.SSS0.Px7.p2.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S3.SS0.SSS0.Px7.p2.1.m1.1a"><mo id="S3.SS0.SSS0.Px7.p2.1.m1.1.1" xref="S3.SS0.SSS0.Px7.p2.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px7.p2.1.m1.1b"><csymbol cd="latexml" id="S3.SS0.SSS0.Px7.p2.1.m1.1.1.cmml" xref="S3.SS0.SSS0.Px7.p2.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px7.p2.1.m1.1c">\sim</annotation></semantics></math>18MB in size.</p>
</div>
<div id="S3.SS0.SSS0.Px7.p3" class="ltx_para">
<p id="S3.SS0.SSS0.Px7.p3.1" class="ltx_p">The experiment runs in a multi-cloud environment with the server and eight clients running on Azure, while two clients run on AWS. One can observe that the global model download is slower as all clients are trying to download the global model at the same time, and hence the server is more busy. In contrast, the clients’ model uploads happen at slightly different times and therefore are faster. One can also see how this multi-cloud setup causes the clients on AWS to take slightly longer during model download due to communication across different cloud infrastructures.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2210.13291/assets/x1.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="389" height="227" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F2.4.2.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S3.F2.2.1" class="ltx_text" style="font-size:90%;">Comparison of GRPC and TCP communication drivers in NVFlare. The server is running on Azure. The clients are distributed between Azure and AWS. The message size is <math id="S3.F2.2.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S3.F2.2.1.m1.1b"><mo id="S3.F2.2.1.m1.1.1" xref="S3.F2.2.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S3.F2.2.1.m1.1c"><csymbol cd="latexml" id="S3.F2.2.1.m1.1.1.cmml" xref="S3.F2.2.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.2.1.m1.1d">\sim</annotation></semantics></math>18MB. Communication times were measured over 100 rounds of FedAvg. Error bars indicate the 95% confidence intervals. </span></figcaption>
</figure>
</section>
<section id="S3.SS0.SSS0.Px8" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Filters</h4>

<div id="S3.SS0.SSS0.Px8.p1" class="ltx_para">
<p id="S3.SS0.SSS0.Px8.p1.1" class="ltx_p">Filters in NVFlare are a type of <span id="S3.SS0.SSS0.Px8.p1.1.1" class="ltx_text ltx_font_italic">FLComponent</span> that have a process method to transform the <span id="S3.SS0.SSS0.Px8.p1.1.2" class="ltx_text ltx_font_italic">Shareable</span> object between the communicating parties. A Filter can provide additional processing to shareable data before sending or after receiving from a peer. Filters can convert data formats and a lot more and are NVFlare’s primary mechanism for data privacy protection <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>:</p>
<ul id="S3.I1" class="ltx_itemize">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.p1.1" class="ltx_p"><span id="S3.I1.i1.p1.1.1" class="ltx_text ltx_font_italic">ExcludeVars</span> to exclude variables from shareable.</p>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i2.p1.1" class="ltx_p"><span id="S3.I1.i2.p1.1.1" class="ltx_text ltx_font_italic">PercentilePrivacy</span> for truncation of weights by percentile.</p>
</div>
</li>
<li id="S3.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i3.p1" class="ltx_para">
<p id="S3.I1.i3.p1.1" class="ltx_p"><span id="S3.I1.i3.p1.1.1" class="ltx_text ltx_font_italic">SVTPrivacy</span> for differential privacy through sparse vector techniques.</p>
</div>
</li>
<li id="S3.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i4.p1" class="ltx_para">
<p id="S3.I1.i4.p1.1" class="ltx_p">Homomorphic encryption filters used for secure aggregation.</p>
</div>
</li>
</ul>
<p id="S3.SS0.SSS0.Px8.p1.2" class="ltx_p">As an example, we show the average encryption, decryption, and upload times when using homomorphic encryption for secure aggregation<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a target="_blank" href="https://developer.nvidia.com/blog/federated-learning-with-homomorphic-encryption" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://developer.nvidia.com/blog/federated-learning-with-homomorphic-encryption</a></span></span></span>. We compare raw data to encrypted model gradients uploaded in Table <a href="#S3.T1" title="Table 1 ‣ Filters ‣ 3 System Concepts ‣ NVIDIA FLARE: Federated Learning from Simulation to Real-World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> when hosting the server on AWS<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>For reference, we used an <a target="_blank" href="https://aws.amazon.com/ec2/instance-types" title="" class="ltx_ref ltx_href">m5a.2xlarge</a> instance with eight vCPUs, 32-GB memory, and up to 2,880 Gbps network bandwidth.</span></span></span> and connecting 30 client instances using an on-premise GPU cluster. One can see the longer upload times due to the larger message sizes needed by homomorphic encryption.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S3.T1.2.1.1" class="ltx_text" style="font-size:90%;">Table 1</span>: </span><span id="S3.T1.3.2" class="ltx_text" style="font-size:90%;">Federated learning exchanging homomorphic encrypted vs. raw model updates. </span></figcaption>
<table id="S3.T1.4" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T1.4.1.1" class="ltx_tr">
<th id="S3.T1.4.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_ll ltx_border_t" style="padding-bottom:1.72221pt;"><span id="S3.T1.4.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Time in seconds</span></th>
<th id="S3.T1.4.1.1.2" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t" style="padding-bottom:1.72221pt;"><span id="S3.T1.4.1.1.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Mean</span></th>
<th id="S3.T1.4.1.1.3" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_rr ltx_border_t" style="padding-bottom:1.72221pt;"><span id="S3.T1.4.1.1.3.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Std. Dev.</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T1.4.2.1" class="ltx_tr">
<th id="S3.T1.4.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_ll ltx_border_tt"><span id="S3.T1.4.2.1.1.1" class="ltx_text" style="font-size:80%;">Encryption</span></th>
<td id="S3.T1.4.2.1.2" class="ltx_td ltx_align_right ltx_border_tt"><span id="S3.T1.4.2.1.2.1" class="ltx_text" style="font-size:80%;">5.01</span></td>
<td id="S3.T1.4.2.1.3" class="ltx_td ltx_align_right ltx_border_rr ltx_border_tt"><span id="S3.T1.4.2.1.3.1" class="ltx_text" style="font-size:80%;">1.18</span></td>
</tr>
<tr id="S3.T1.4.3.2" class="ltx_tr">
<th id="S3.T1.4.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_ll"><span id="S3.T1.4.3.2.1.1" class="ltx_text" style="font-size:80%;">Decryption</span></th>
<td id="S3.T1.4.3.2.2" class="ltx_td ltx_align_right"><span id="S3.T1.4.3.2.2.1" class="ltx_text" style="font-size:80%;">0.95</span></td>
<td id="S3.T1.4.3.2.3" class="ltx_td ltx_align_right ltx_border_rr"><span id="S3.T1.4.3.2.3.1" class="ltx_text" style="font-size:80%;">0.04</span></td>
</tr>
<tr id="S3.T1.4.4.3" class="ltx_tr">
<th id="S3.T1.4.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_ll"><span id="S3.T1.4.4.3.1.1" class="ltx_text" style="font-size:80%;">Enc. upload</span></th>
<td id="S3.T1.4.4.3.2" class="ltx_td ltx_align_right"><span id="S3.T1.4.4.3.2.1" class="ltx_text" style="font-size:80%;">38.00</span></td>
<td id="S3.T1.4.4.3.3" class="ltx_td ltx_align_right ltx_border_rr"><span id="S3.T1.4.4.3.3.1" class="ltx_text" style="font-size:80%;">71.17</span></td>
</tr>
<tr id="S3.T1.4.5.4" class="ltx_tr">
<th id="S3.T1.4.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_ll" style="padding-bottom:3.44444pt;"><span id="S3.T1.4.5.4.1.1" class="ltx_text" style="font-size:80%;">Raw upload</span></th>
<td id="S3.T1.4.5.4.2" class="ltx_td ltx_align_right ltx_border_b" style="padding-bottom:3.44444pt;"><span id="S3.T1.4.5.4.2.1" class="ltx_text" style="font-size:80%;">21.57</span></td>
<td id="S3.T1.4.5.4.3" class="ltx_td ltx_align_right ltx_border_b ltx_border_rr" style="padding-bottom:3.44444pt;"><span id="S3.T1.4.5.4.3.1" class="ltx_text" style="font-size:80%;">74.23</span></td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S3.SS0.SSS0.Px9" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Event Mechanism</h4>

<div id="S3.SS0.SSS0.Px9.p1" class="ltx_para">
<p id="S3.SS0.SSS0.Px9.p1.1" class="ltx_p">NVFlare comes with a powerful event mechanism that allows dynamic notifications to be sent to all event handlers. This mechanism enables data-based communication among decoupled components: one component fires an event when a certain condition occurs, and other components can listen to that event and processes the event data. Each <span id="S3.SS0.SSS0.Px9.p1.1.1" class="ltx_text ltx_font_italic">FLComponent</span> is automatically an event handler. To listen to and process an event, one can simply implement the <span id="S3.SS0.SSS0.Px9.p1.1.2" class="ltx_text ltx_font_italic">handle_event()</span> method and process desired event types. Events represent some important moments during the execution of the system logic. For example, before and after aggregation or when important data becomes available, e.g., a new “best” model was selected.</p>
</div>
</section>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Productivity Features</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">NVFlare contains features that enable efficient, collaborative, and robust computing workflows.</p>
</div>
<section id="S3.SS1.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Multi-tasking</h4>

<div id="S3.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS1.SSS0.Px1.p1.1" class="ltx_p">For systems with a large capacity, computing resources could be idle most of the time. NVFlare implements a resource-based multi-tasking solution, where multiple jobs can be run concurrently when overall system resources are available.
Multi-tasking is made possible by a job scheduler on the server side that constantly tries to schedule a new job.
For each job to be scheduled, the scheduler asks each client whether they can satisfy the required resources of the job (e.g., number of GPU devices) by querying the client’s resource manager. If all clients can meet the requirement, the job will be scheduled and deployed to the clients.</p>
</div>
</section>
<section id="S3.SS1.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">High Availability and Server Failover</h4>

<div id="S3.SS1.SSS0.Px2.p1" class="ltx_para">
<p id="S3.SS1.SSS0.Px2.p1.1" class="ltx_p">To avoid the FL server as a single point of failure, a solution has been implemented to support multiple FL servers with automatic cut-over when the currently active server becomes unavailable.
Therefore, a component called <span id="S3.SS1.SSS0.Px2.p1.1.1" class="ltx_text ltx_font_italic">Overseer</span> is added to facilitate automatic cut-over. The <span id="S3.SS1.SSS0.Px2.p1.1.2" class="ltx_text ltx_font_italic">Overseer</span> provides the authoritative endpoint info of the active FL server. All other system entities (FL servers, FL clients, admin clients) constantly communicate (i.e., every 5 seconds) with the Overseer to obtain and act on such information.
If the server cutover happens during the execution of a job, then the job will continue to run on the new server. Depending on how the controller is written, the job may or may not need to restart from the beginning but can continue from a previously saved snapshot.</p>
</div>
</section>
<section id="S3.SS1.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Simulator</h4>

<div id="S3.SS1.SSS0.Px3.p1" class="ltx_para">
<p id="S3.SS1.SSS0.Px3.p1.1" class="ltx_p">NVFlare provides a simulator to allow data scientists and system developers to easily write new <span id="S3.SS1.SSS0.Px3.p1.1.1" class="ltx_text ltx_font_italic">FLComponents</span> and novel workflows.
The simulator is a command line tool to run a NVFlare job. To allow simple experimentation and debugging, the FL server and multiple clients run in the same process during simulation. A multi-process option allows efficient use of resources, e.g., training multiple clients on different GPUs. The simulator follows the same job execution as in real-world NVFlare deployment. Therefore, components developed in simulation can be directly deployed in real-world federated scenarios.</p>
</div>
</section>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Secure Provisioning in NVFlare</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">Security is an important requirement for FL systems. NVFlare provides security solutions in the following areas: authentication, communication confidentiality, user authorization, data privacy protection, auditing, and local client policies.</p>
</div>
<figure id="S3.F3" class="ltx_figure"><img src="/html/2210.13291/assets/x2.png" id="S3.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="311" height="205" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.2.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S3.F3.3.2" class="ltx_text" style="font-size:90%;">High-level steps for running a real-world study with secure provisioning with NVFlare. </span></figcaption>
</figure>
<section id="S3.SS2.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Authentication</h4>

<div id="S3.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px1.p1.1" class="ltx_p">NVFlare ensures the identities of communicating peers using mutual Transport Layer Security (TLS). Each participating party (FL Servers, Overseer, FL Clients, Admin Clients) must be properly provisioned. Once provisioned, each party receives a startup kit containing TLS credentials (public cert of the root, the party’s own private key and certificate) and system endpoint information, see Fig. <a href="#S3.F3" title="Figure 3 ‣ 3.2 Secure Provisioning in NVFlare ‣ 3 System Concepts ‣ NVIDIA FLARE: Federated Learning from Simulation to Real-World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. Each party can only connect to the NVFlare system with the startup kit.
Communication confidentiality is also achieved with the use of TLS-based messaging.</p>
</div>
</section>
<section id="S3.SS2.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Federated Authorization</h4>

<div id="S3.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px2.p1.1" class="ltx_p">NVFlare’s admin command system is very rich and powerful. Not every command is for everyone. NVFlare implements a role-based user authorization system that controls what a user can or cannot do. At the time of provision, each user is assigned a role. Authorization policies specify which commands are permitted for which roles.
Each FL client can define its authorization policy that specifies what a role can or cannot do to the client. For example, one client could allow a role to run jobs from any researchers. In contrast, another client may only allow jobs submitted by its researchers (i.e., the client and the job submitter belong to the same organization).</p>
</div>
<div id="S3.SS2.SSS0.Px2.p2" class="ltx_para">
<p id="S3.SS2.SSS0.Px2.p2.1" class="ltx_p">NVFlare automatically records all user commands and job events in system audit files on both the server and client sides. In addition, the audit API can be used by application developers to record additional events in the audit files.</p>
</div>
</section>
<section id="S3.SS2.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Client-Privacy</h4>

<div id="S3.SS2.SSS0.Px3.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px3.p1.1" class="ltx_p">NVFlare enhances the overall system security by allowing each client to define its policies for authorization, data privacy (filters), and computing resource management. The client can change its policies at any time after the system is up and running without having to be re-provisioned. For example, the client could require all jobs running on it to be subject to a set of filters. The client could also change the number of computing resources (e.g., GPU devices) to be used by the FL client.</p>
</div>
</section>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Federated Data Science</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">As a general distributed computing platform, NVFlare can be used for various applications in different industries. Here we describe some of the most common use cases where NVFlare was deployed.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Federated Deep Learning</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">A go-to example dataset for benchmarking different FL algorithms is CIFAR-10 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>. NVFlare allows users to experiment with different algorithms and data splits using different levels of heterogeneity based on a Dirichlet sampling strategy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>. Figure <a href="#S4.F4.sf1" title="In Figure 4 ‣ 4.1 Federated Deep Learning ‣ 4 Federated Data Science ‣ NVIDIA FLARE: Federated Learning from Simulation to Real-World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4(a)</span></a> shows the impact of varying alpha values, where lower values cause higher heterogeneity on the performance of the FedAvg.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p">Apart from FedAvg, currently available in NVFlare include FedProx <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>, FedOpt <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>, and SCAFFOLD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>. Figure <a href="#S4.F4.sf2" title="In Figure 4 ‣ 4.1 Federated Deep Learning ‣ 4 Federated Data Science ‣ NVIDIA FLARE: Federated Learning from Simulation to Real-World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4(b)</span></a> compares an <math id="S4.SS1.p2.1.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S4.SS1.p2.1.m1.1a"><mi id="S4.SS1.p2.1.m1.1.1" xref="S4.SS1.p2.1.m1.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.1b"><ci id="S4.SS1.p2.1.m1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.1.m1.1c">\alpha</annotation></semantics></math> setting of 0.1, causing a high data heterogeneity across clients and its impact on more advanced FL algorithms, namely FedProx, FedOpt, and SCAFFOLD.
FedOpt and SCAFFOLD show markedly better convergence rates and achieve better performance than FedAvg and FedProx with the same alpha setting.
SCAFFOLD achieves this by adding a correction term when updating the client models, while FedOpt utilizes SGD with momentum to update the global model on the server. Therefore, both perform better with the same number of training steps as FedAvg and FedProx.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.1" class="ltx_p">Other algorithms available in or coming soon to NVFlare include federated XGBoost <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>, Ditto <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>, FedSM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>, Auto-FedRL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>, and more.</p>
</div>
<figure id="S4.F4" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F4.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2210.13291/assets/fig/fedavg_alpha.png" id="S4.F4.sf1.g1" class="ltx_graphics ltx_img_landscape" width="673" height="505" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F4.sf1.4.2.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S4.F4.sf1.2.1" class="ltx_text" style="font-size:80%;">FedAvg with increasing levels of heterogeneity (smaller <math id="S4.F4.sf1.2.1.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S4.F4.sf1.2.1.m1.1b"><mi id="S4.F4.sf1.2.1.m1.1.1" xref="S4.F4.sf1.2.1.m1.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S4.F4.sf1.2.1.m1.1c"><ci id="S4.F4.sf1.2.1.m1.1.1.cmml" xref="S4.F4.sf1.2.1.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.sf1.2.1.m1.1d">\alpha</annotation></semantics></math> values). </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F4.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2210.13291/assets/fig/fedopt_fedprox_scaffold.png" id="S4.F4.sf2.g1" class="ltx_graphics ltx_img_landscape" width="673" height="505" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F4.sf2.4.2.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S4.F4.sf2.2.1" class="ltx_text" style="font-size:80%;">FL algorithms with a heterogeneous data split (<math id="S4.F4.sf2.2.1.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S4.F4.sf2.2.1.m1.1b"><mi id="S4.F4.sf2.2.1.m1.1.1" xref="S4.F4.sf2.2.1.m1.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S4.F4.sf2.2.1.m1.1c"><ci id="S4.F4.sf2.2.1.m1.1.1.cmml" xref="S4.F4.sf2.2.1.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.sf2.2.1.m1.1d">\alpha</annotation></semantics></math>=0.1). </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F4.2.1.1" class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span id="S4.F4.3.2" class="ltx_text" style="font-size:90%;">Federated learning experiments with NVFlare. </span></figcaption>
</figure>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Federated Machine Learning</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">Traditional machine learning methods, such as linear models, support vector machine (SVM), and k-means clustering, can be formulated under a federated setting.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">With certain libraries, the federated machine learning algorithms need to be designed considering two factors: algorithm-wise, each of these models has distinct training schemes and model representations; and implementation-wise, popular libraries providing these functionalities (e.g., scikit-learn, XGBoost) have different APIs and inner logics. Hence, when developing an FL variant of a particular traditional machine learning method, several questions need to be answered at these two levels:</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.1" class="ltx_p">First, at the algorithm level, we need to break down the optimization process into individual steps/rounds (if possible) and have answers to three major questions:</p>
<ol id="S4.I1" class="ltx_enumerate">
<li id="S4.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S4.I1.i1.p1" class="ltx_para">
<p id="S4.I1.i1.p1.1" class="ltx_p">What information should clients share with the server?</p>
</div>
</li>
<li id="S4.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S4.I1.i2.p1" class="ltx_para">
<p id="S4.I1.i2.p1.1" class="ltx_p">How should the server aggregate the collected information from clients?</p>
</div>
</li>
<li id="S4.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S4.I1.i3.p1" class="ltx_para">
<p id="S4.I1.i3.p1.1" class="ltx_p">What should clients do with the global aggregated information received from the server?</p>
</div>
</li>
</ol>
</div>
<div id="S4.SS2.p4" class="ltx_para">
<p id="S4.SS2.p4.1" class="ltx_p">Second, at the implementation level, we need to know what APIs are available and how to utilize them in a federated pipeline to implement a distributed version of the algorithm.</p>
</div>
<div id="S4.SS2.p5" class="ltx_para">
<p id="S4.SS2.p5.1" class="ltx_p">A major difference between federated traditional machine learning and federated deep learning is that, for traditional machine learning methods, the boundary between “federated” and “distributed”, or even “ensemble”, can be much more vague than for deep learning. Due to the characteristics of a given algorithm and its API design, the concepts can be equivalent. Take XGBoost and SVM, for example:
Algorithm-wise, XGBoost can distribute the training samples to several workers and construct trees based on the collected histograms from each worker. Such a process can be directly adopted under a federated setting because the communication cost is affordable. In this case, “federated” is equivalent to “distributed” learning.
API-wise, some algorithms can be constrained by their implementation. Take scikit-learn’s SVM for instance. Although theoretically SVM can be formulated as an iterative optimization process, the API only supports one-shot “fitting” without the capability of separately calling the optimization steps. Hence a federated SVM algorithm using the scikit-learn library can only be implemented as a two-step process. In this case, “federated” is equivalent to “ensemble”.</p>
</div>
<div id="S4.SS2.p6" class="ltx_para">
<p id="S4.SS2.p6.1" class="ltx_p">For clarification, we provide the full formulation for tree-based federated XGBoost, illustrated in Fig. <a href="#S4.F5" title="Figure 5 ‣ 4.2 Federated Machine Learning ‣ 4 Federated Data Science ‣ NVIDIA FLARE: Federated Learning from Simulation to Real-World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>:</p>
<ol id="S4.I2" class="ltx_enumerate">
<li id="S4.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S4.I2.i1.p1" class="ltx_para">
<p id="S4.I2.i1.p1.1" class="ltx_p">XGBoost, by definition, is a sequential optimization process: each step adds one extra tree to the model to reduce the residual error. Hence, federated XGBoost can be formulated as follows: each round of FL corresponds to one boosting step at the local level. Clients share the newly added tree trained on local data with the server at the end of local boosting.</p>
</div>
</li>
<li id="S4.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S4.I2.i2.p1" class="ltx_para">
<p id="S4.I2.i2.p1.1" class="ltx_p">The model representation is a decision/regression tree. To aggregate the information from all clients, the server will bag all received trees to form a “forest” to be added to the global boosting model.</p>
</div>
</li>
<li id="S4.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S4.I2.i3.p1" class="ltx_para">
<p id="S4.I2.i3.p1.1" class="ltx_p">With the updated global model from the server, each client will continue the boosting process by learning a new tree starting from the global model of the boosted forest.</p>
</div>
</li>
</ol>
</div>
<figure id="S4.F5" class="ltx_figure"><img src="/html/2210.13291/assets/x3.png" id="S4.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="144" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.2.1.1" class="ltx_text" style="font-size:90%;">Figure 5</span>: </span><span id="S4.F5.3.2" class="ltx_text" style="font-size:90%;">Tree-based federated XGBoost: a “boosting of forests.” </span></figcaption>
</figure>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Split learning</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">Split learning assumes a vertical data partitioning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite> that can be useful in many distributed learning scenarios involving neural network architectures <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.1" class="ltx_p">As an introductory example, we can assume that one client holds the images, and the other holds the labels to compute losses and accuracy metrics. Activations and corresponding gradients are being exchanged between the clients using NVFlare, as illustrated in Fig. <a href="#S4.F6" title="Figure 6 ‣ 4.3 Split learning ‣ 4 Federated Data Science ‣ NVIDIA FLARE: Federated Learning from Simulation to Real-World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>.</p>
</div>
<figure id="S4.F6" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2210.13291/assets/x4.png" id="S4.F6.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" width="130" height="138" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<table id="S4.F6.2" class="ltx_tabular ltx_centering ltx_figure_panel ltx_guessed_headers ltx_align_bottom">
<thead class="ltx_thead">
<tr id="S4.F6.2.1.1" class="ltx_tr">
<th id="S4.F6.2.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_ll ltx_border_t" style="padding-bottom:1.72221pt;"><span id="S4.F6.2.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Setup</span></th>
<th id="S4.F6.2.1.1.2" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_rr ltx_border_t" style="padding-bottom:1.72221pt;"><span id="S4.F6.2.1.1.2.1" class="ltx_text ltx_font_bold" style="font-size:80%;">Training Time [min]</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.F6.2.2.1" class="ltx_tr">
<th id="S4.F6.2.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_ll ltx_border_tt"><span id="S4.F6.2.2.1.1.1" class="ltx_text" style="font-size:80%;">Simulated PyTorch</span></th>
<td id="S4.F6.2.2.1.2" class="ltx_td ltx_align_right ltx_border_rr ltx_border_tt"><span id="S4.F6.2.2.1.2.1" class="ltx_text" style="font-size:80%;">19</span></td>
</tr>
<tr id="S4.F6.2.3.2" class="ltx_tr">
<th id="S4.F6.2.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_ll"><span id="S4.F6.2.3.2.1.1" class="ltx_text" style="font-size:80%;">Routing through server (TCP)</span></th>
<td id="S4.F6.2.3.2.2" class="ltx_td ltx_align_right ltx_border_rr"><span id="S4.F6.2.3.2.2.1" class="ltx_text" style="font-size:80%;">27</span></td>
</tr>
<tr id="S4.F6.2.4.3" class="ltx_tr">
<th id="S4.F6.2.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_ll" style="padding-bottom:3.44444pt;"><span id="S4.F6.2.4.3.1.1" class="ltx_text" style="font-size:80%;">Peer-to-peer (TCP)</span></th>
<td id="S4.F6.2.4.3.2" class="ltx_td ltx_align_right ltx_border_b ltx_border_rr" style="padding-bottom:3.44444pt;"><span id="S4.F6.2.4.3.2.1" class="ltx_text" style="font-size:80%;">25</span></td>
</tr>
</tbody>
</table>
</div>
</div>
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_figure"><span id="S4.F6.5.1.1" class="ltx_text" style="font-size:113%;">Figure 6</span>: </span><span id="S4.F6.6.2" class="ltx_text" style="font-size:113%;">Simple split learning scenario using CIFAR-10. The table compares multiple communication patterns. Using 50,000 training samples and 15,625 rounds of communication with a batch size of 64. </span></figcaption>
</figure>
<div id="S4.SS3.p3" class="ltx_para">
<p id="S4.SS3.p3.1" class="ltx_p">We use a cryptographic technique called private set intersection (PSI) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite> to compute the alignment between images and labels on both clients. NVFlare’s implementation of PSI can be extended to multiple parties and applied to other use cases than split learning, e.g., requiring a secure and privacy-preserving alignment of different databases.</p>
</div>
<div id="S4.SS3.p4" class="ltx_para">
<p id="S4.SS3.p4.1" class="ltx_p">Using NVFlare’s capability to implement different communication patterns, we can investigate the communication speed-ups one can achieve by implementing split learning using direct peer-to-peer communication as opposed to routing the messages between the two clients through a central server.</p>
</div>
<div id="S4.SS3.p5" class="ltx_para">
<p id="S4.SS3.p5.1" class="ltx_p">The table in Fig. <a href="#S4.F6" title="Figure 6 ‣ 4.3 Split learning ‣ 4 Federated Data Science ‣ NVIDIA FLARE: Federated Learning from Simulation to Real-World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> compares the training speeds of split learning on the CIFAR-10 dataset in a local simulation scenario. First, we use the same PyTorch script to simulate split learning. Then, we implement two distributed solutions using NVFlare. One that routes the messages through the server and one using a direct peer-to-peer connection between the clients. As expected, the direct peer-to-peer connection is more efficient, achieving only a slight overhead in total training time compared to the standalone PyTorch script, which could not be translated to real-world scenarios.</p>
</div>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Federated Statistics</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p">NVFlare provides built-in federated statistics operators (<span id="S4.SS4.p1.1.1" class="ltx_text ltx_font_italic">Controller</span> and <span id="S4.SS4.p1.1.2" class="ltx_text ltx_font_italic">Executors</span>) that will generate global statistics based on local client statistics.
Each client could have one or more datasets, such as “train” and “test” datasets. Each dataset may have many features.
NVFlare will calculate and combine the statistics for each feature in the dataset to produce global statistics for all the numeric features. The output gathered on the server will be the complete statistics for all datasets in clients and global, as illustrated in Fig. <a href="#S4.F7" title="Figure 7 ‣ 4.4 Federated Statistics ‣ 4 Federated Data Science ‣ NVIDIA FLARE: Federated Learning from Simulation to Real-World" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>.</p>
</div>
<figure id="S4.F7" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F7.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2210.13291/assets/fig/covid_stats.png" id="S4.F7.sf1.g1" class="ltx_graphics ltx_img_landscape" width="673" height="266" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F7.sf1.3.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S4.F7.sf1.4.2" class="ltx_text" style="font-size:80%;">Federated statistics. Note the data of “site-4” violates the client’s privacy policy and therefore does not share its statistics with the server. </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F7.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2210.13291/assets/fig/covid_hist.png" id="S4.F7.sf2.g1" class="ltx_graphics ltx_img_square" width="673" height="566" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F7.sf2.3.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S4.F7.sf2.4.2" class="ltx_text" style="font-size:80%;">Histogram visualization. </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F7.2.1.1" class="ltx_text" style="font-size:90%;">Figure 7</span>: </span><span id="S4.F7.3.2" class="ltx_text" style="font-size:90%;">Federated statistics with NVFlare. </span></figcaption>
</figure>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Real-world Use Cases</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">NVFlare and its predecessors have been used in several real-world studies exploring FL for healthcare scenarios.
The collaborations between multinational institutions tested and validated the utility of federated learning, pushing the
envelope for training robust, generalizable AI models. These initiatives included FL for breast mammography classification <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>, prostate segmentation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>, pancreas segmentation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>, and most recently, chest X-ray (CXR) and electronic health record (EHR) analysis to predict the oxygen requirement for patients arriving in the emergency department with symptoms of COVID-19 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>.</p>
</div>
<figure id="S5.F8" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S5.F8.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2210.13291/assets/x5.png" id="S5.F8.sf1.g1" class="ltx_graphics ltx_img_square" width="123" height="115" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F8.sf1.3.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S5.F8.sf1.4.2" class="ltx_text" style="font-size:80%;">Mammography. </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S5.F8.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2210.13291/assets/x6.png" id="S5.F8.sf2.g1" class="ltx_graphics ltx_img_square" width="138" height="115" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F8.sf2.3.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S5.F8.sf2.4.2" class="ltx_text" style="font-size:80%;">Prostate. </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S5.F8.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2210.13291/assets/x7.png" id="S5.F8.sf3.g1" class="ltx_graphics ltx_img_square" width="133" height="115" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F8.sf3.3.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="S5.F8.sf3.4.2" class="ltx_text" style="font-size:80%;">Pancreas. </span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S5.F8.sf4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2210.13291/assets/x8.png" id="S5.F8.sf4.g1" class="ltx_graphics ltx_img_square" width="137" height="115" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F8.sf4.3.1.1" class="ltx_text" style="font-size:90%;">(d)</span> </span><span id="S5.F8.sf4.4.2" class="ltx_text" style="font-size:80%;">CXR &amp; EHR. </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F8.2.1.1" class="ltx_text" style="font-size:90%;">Figure 8</span>: </span><span id="S5.F8.3.2" class="ltx_text" style="font-size:90%;">Real-world use cases of NVFlare. </span></figcaption>
</figure>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Summary &amp; Conclusion</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">We described NVFlare, an open-source SDK to make it easier for data scientists to use FL in their research and to allow an easy transition from research to real-world deployment.
As discussed above, NVFlare’s <span id="S6.p1.1.1" class="ltx_text ltx_font_italic">Controller</span> programming API supports various interaction patterns between the server and clients over internet connections, which could be unstable.
Therefore, the API design mitigates various failure conditions and unexpected crashes of the client machines, such as allowing developers to process timeout conditions properly.</p>
</div>
<div id="S6.p2" class="ltx_para">
<p id="S6.p2.1" class="ltx_p">NVFLare’s unique flexibility and agnostic approach towards the deployed training libraries make it the perfect solution for integrating with different deep learning frameworks, including popular ones used for training large language models (LLM). With our dedication to addressing the current limitations of communication protocols, we are working towards supporting the communication of large message sizes, enabling the federated fine-tuning of AI models with billions of parameters, such as those used for ChatGPT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite> and GPT-4 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>.
Moreover, our team is implementing parameter-efficient federated methods to adapt LLM models to downstream tasks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite>, utilizing techniques such as prompt tuning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> and p-tuning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>, adapters <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>, LoRA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>, showing promising performance. Our commitment to innovation and excellence in this field ensures that we continue to push the boundaries of what is possible with federated learning.</p>
</div>
<div id="S6.p3" class="ltx_para">
<p id="S6.p3.1" class="ltx_p">We did not go into all details of exciting features available in NVFlare, like homomorphic encryption, TensorBoard streaming, provisioning web dashboard, integration with MONAI<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a target="_blank" href="https://monai.io" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://monai.io</a></span></span></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>, etc. However, we hope that this overview of NVFlare gives a good starting point for developers and researchers on their journey to using FL and federated data science in simulation and the real world.</p>
</div>
<div id="S6.p4" class="ltx_para">
<p id="S6.p4.1" class="ltx_p">NVFlare is an open-source project. We invite the community to contribute and grow NVFlare. For more information, please visit the code repository at <a target="_blank" href="https://github.com/NVIDIA/NVFlare" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/NVIDIA/NVFlare</a>.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock"><span id="bib.bib1.5.1" class="ltx_text" style="font-size:90%;">
M. Abadi, P. Barham, J. Chen, Z. Chen, A. Davis, J. Dean, M. Devin,
S. Ghemawat, G. Irving, M. Isard, et al.
</span>
</span>
<span class="ltx_bibblock"><math id="bib.bib1.1.m1.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib1.1.m1.1a"><mo maxsize="90%" minsize="90%" id="bib.bib1.1.m1.1.1" xref="bib.bib1.1.m1.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib1.1.m1.1b"><ci id="bib.bib1.1.m1.1.1.cmml" xref="bib.bib1.1.m1.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib1.1.m1.1c">\{</annotation></semantics></math><span id="bib.bib1.6.1" class="ltx_text" style="font-size:90%;">TensorFlow</span><math id="bib.bib1.2.m2.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib1.2.m2.1a"><mo maxsize="90%" minsize="90%" id="bib.bib1.2.m2.1.1" xref="bib.bib1.2.m2.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib1.2.m2.1b"><ci id="bib.bib1.2.m2.1.1.cmml" xref="bib.bib1.2.m2.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib1.2.m2.1c">\}</annotation></semantics></math><span id="bib.bib1.7.2" class="ltx_text" style="font-size:90%;">: a system for </span><math id="bib.bib1.3.m3.1" class="ltx_Math" alttext="\{" display="inline"><semantics id="bib.bib1.3.m3.1a"><mo maxsize="90%" minsize="90%" id="bib.bib1.3.m3.1.1" xref="bib.bib1.3.m3.1.1.cmml">{</mo><annotation-xml encoding="MathML-Content" id="bib.bib1.3.m3.1b"><ci id="bib.bib1.3.m3.1.1.cmml" xref="bib.bib1.3.m3.1.1">{</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib1.3.m3.1c">\{</annotation></semantics></math><span id="bib.bib1.8.3" class="ltx_text" style="font-size:90%;">Large-Scale</span><math id="bib.bib1.4.m4.1" class="ltx_Math" alttext="\}" display="inline"><semantics id="bib.bib1.4.m4.1a"><mo maxsize="90%" minsize="90%" id="bib.bib1.4.m4.1.1" xref="bib.bib1.4.m4.1.1.cmml">}</mo><annotation-xml encoding="MathML-Content" id="bib.bib1.4.m4.1b"><ci id="bib.bib1.4.m4.1.1.cmml" xref="bib.bib1.4.m4.1.1">}</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib1.4.m4.1c">\}</annotation></semantics></math><span id="bib.bib1.9.4" class="ltx_text" style="font-size:90%;"> machine
learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.10.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib1.11.2" class="ltx_text ltx_font_italic" style="font-size:90%;">12th USENIX symposium on operating systems design and
implementation (OSDI 16)</span><span id="bib.bib1.12.3" class="ltx_text" style="font-size:90%;">, pages 265–283, 2016.
</span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text" style="font-size:90%;">
D. J. Beutel, T. Topal, A. Mathur, X. Qiu, T. Parcollet, P. P. de Gusmão,
and N. D. Lane.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.2.1" class="ltx_text" style="font-size:90%;">Flower: A friendly federated learning research framework.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2007.14390</span><span id="bib.bib2.4.2" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text" style="font-size:90%;">
M. J. Cardoso, W. Li, R. Brown, N. Ma, E. Kerfoot, Y. Wang, B. Murrey,
A. Myronenko, C. Zhao, D. Yang, et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.2.1" class="ltx_text" style="font-size:90%;">Monai: An open-source framework for deep learning in healthcare.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2211.02701</span><span id="bib.bib3.4.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock"><span id="bib.bib4.1.1" class="ltx_text" style="font-size:90%;">
K. Chang, N. Balachandar, C. Lam, D. Yi, J. Brown, A. Beers, B. Rosen, D. L.
Rubin, and J. Kalpathy-Cramer.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.2.1" class="ltx_text" style="font-size:90%;">Distributed deep learning networks among institutions for medical
imaging.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Journal of the American Medical Informatics Association</span><span id="bib.bib4.4.2" class="ltx_text" style="font-size:90%;">,
25(8):945–954, 2018.
</span>
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text" style="font-size:90%;">
T. Chen and C. Guestrin.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.2.1" class="ltx_text" style="font-size:90%;">XGBoost: A scalable tree boosting system.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib5.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the 22nd ACM SIGKDD International Conference
on Knowledge Discovery and Data Mining</span><span id="bib.bib5.5.3" class="ltx_text" style="font-size:90%;">, KDD ’16, pages 785–794, New York,
NY, USA, 2016. ACM.
</span>
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text" style="font-size:90%;">
I. Dayan, H. R. Roth, A. Zhong, A. Harouni, A. Gentili, A. Z. Abidin, A. Liu,
A. B. Costa, B. J. Wood, C.-S. Tsai, et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.2.1" class="ltx_text" style="font-size:90%;">Federated learning for predicting clinical outcomes in patients with
covid-19.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Nature medicine</span><span id="bib.bib6.4.2" class="ltx_text" style="font-size:90%;">, 27(10):1735–1743, 2021.
</span>
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text" style="font-size:90%;">
D. Dimitriadis, M. H. Garcia, D. M. Diaz, A. Manoel, and R. Sim.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.2.1" class="ltx_text" style="font-size:90%;">Flute: A scalable, extensible framework for high-performance
federated learning simulations.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2203.13789</span><span id="bib.bib7.4.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text" style="font-size:90%;">
P. Guo, D. Yang, A. Hatamizadeh, A. Xu, Z. Xu, W. Li, C. Zhao, D. Xu,
S. Harmon, E. Turkbey, et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.2.1" class="ltx_text" style="font-size:90%;">Auto-fedrl: Federated hyperparameter optimization for
multi-institutional medical image segmentation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2203.06338</span><span id="bib.bib8.4.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text" style="font-size:90%;">
O. Gupta and R. Raskar.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.2.1" class="ltx_text" style="font-size:90%;">Distributed learning of deep neural network over multiple agents.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Journal of Network and Computer Applications</span><span id="bib.bib9.4.2" class="ltx_text" style="font-size:90%;">, 116:1–8, 2018.
</span>
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text" style="font-size:90%;">
A. Hatamizadeh, H. Yin, P. Molchanov, A. Myronenko, W. Li, P. Dogra, A. Feng,
M. G. Flores, J. Kautz, D. Xu, et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.2.1" class="ltx_text" style="font-size:90%;">Do gradient inversion attacks make federated learning unsafe?
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2202.06924</span><span id="bib.bib10.4.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text" style="font-size:90%;">
C. He, S. Li, J. So, X. Zeng, M. Zhang, H. Wang, X. Wang, P. Vepakomma,
A. Singh, H. Qiu, et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.2.1" class="ltx_text" style="font-size:90%;">FedML: A research library and benchmark for federated machine
learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2007.13518</span><span id="bib.bib11.4.2" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock"><span id="bib.bib12.1.1" class="ltx_text" style="font-size:90%;">
J. He, C. Zhou, X. Ma, T. Berg-Kirkpatrick, and G. Neubig.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.2.1" class="ltx_text" style="font-size:90%;">Towards a unified view of parameter-efficient transfer learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2110.04366</span><span id="bib.bib12.4.2" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text" style="font-size:90%;">
N. Houlsby, A. Giurgiu, S. Jastrzebski, B. Morrone, Q. De Laroussilhe,
A. Gesmundo, M. Attariyan, and S. Gelly.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.2.1" class="ltx_text" style="font-size:90%;">Parameter-efficient transfer learning for nlp.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib13.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">International Conference on Machine Learning</span><span id="bib.bib13.5.3" class="ltx_text" style="font-size:90%;">, pages
2790–2799. PMLR, 2019.
</span>
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock"><span id="bib.bib14.1.1" class="ltx_text" style="font-size:90%;">
E. J. Hu, Y. Shen, P. Wallis, Z. Allen-Zhu, Y. Li, S. Wang, L. Wang, and
W. Chen.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.2.1" class="ltx_text" style="font-size:90%;">Lora: Low-rank adaptation of large language models.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2106.09685</span><span id="bib.bib14.4.2" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock"><span id="bib.bib15.1.1" class="ltx_text" style="font-size:90%;">
P. Kairouz, H. B. McMahan, B. Avent, A. Bellet, M. Bennis, A. N. Bhagoji,
K. Bonawitz, Z. Charles, G. Cormode, R. Cummings, et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.2.1" class="ltx_text" style="font-size:90%;">Advances and open problems in federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1912.04977</span><span id="bib.bib15.4.2" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text" style="font-size:90%;">
S. P. Karimireddy, S. Kale, M. Mohri, S. Reddi, S. Stich, and A. T. Suresh.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.2.1" class="ltx_text" style="font-size:90%;">Scaffold: Stochastic controlled averaging for federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib16.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">International Conference on Machine Learning</span><span id="bib.bib16.5.3" class="ltx_text" style="font-size:90%;">, pages
5132–5143. PMLR, 2020.
</span>
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock"><span id="bib.bib17.1.1" class="ltx_text" style="font-size:90%;">
A. Krizhevsky, G. Hinton, et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.2.1" class="ltx_text" style="font-size:90%;">Learning multiple layers of features from tiny images.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.3.1" class="ltx_text" style="font-size:90%;">2009.
</span>
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock"><span id="bib.bib18.1.1" class="ltx_text" style="font-size:90%;">
B. Lester, R. Al-Rfou, and N. Constant.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.2.1" class="ltx_text" style="font-size:90%;">The power of scale for parameter-efficient prompt tuning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2104.08691</span><span id="bib.bib18.4.2" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock"><span id="bib.bib19.1.1" class="ltx_text" style="font-size:90%;">
T. Li, S. Hu, A. Beirami, and V. Smith.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.2.1" class="ltx_text" style="font-size:90%;">Ditto: Fair and robust federated learning through personalization.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib19.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">International Conference on Machine Learning</span><span id="bib.bib19.5.3" class="ltx_text" style="font-size:90%;">, pages
6357–6368. PMLR, 2021.
</span>
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock"><span id="bib.bib20.1.1" class="ltx_text" style="font-size:90%;">
T. Li, A. K. Sahu, M. Zaheer, M. Sanjabi, A. Talwalkar, and V. Smith.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.2.1" class="ltx_text" style="font-size:90%;">Federated optimization in heterogeneous networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of Machine Learning and Systems</span><span id="bib.bib20.4.2" class="ltx_text" style="font-size:90%;">, 2:429–450, 2020.
</span>
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock"><span id="bib.bib21.1.1" class="ltx_text" style="font-size:90%;">
W. Li, F. Milletarì, D. Xu, N. Rieke, J. Hancox, W. Zhu, M. Baust,
Y. Cheng, S. Ourselin, M. J. Cardoso, et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.2.1" class="ltx_text" style="font-size:90%;">Privacy-preserving federated brain tumour segmentation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib21.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">International workshop on machine learning in medical
imaging</span><span id="bib.bib21.5.3" class="ltx_text" style="font-size:90%;">, pages 133–141. Springer, 2019.
</span>
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock"><span id="bib.bib22.1.1" class="ltx_text" style="font-size:90%;">
X. Liu, Y. Zheng, Z. Du, M. Ding, Y. Qian, Z. Yang, and J. Tang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.2.1" class="ltx_text" style="font-size:90%;">Gpt understands, too.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2103.10385</span><span id="bib.bib22.4.2" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock"><span id="bib.bib23.1.1" class="ltx_text" style="font-size:90%;">
Y. Liu, T. Fan, T. Chen, Q. Xu, and Q. Yang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.2.1" class="ltx_text" style="font-size:90%;">Fate: An industrial grade platform for collaborative learning with
data protection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">J. Mach. Learn. Res.</span><span id="bib.bib23.4.2" class="ltx_text" style="font-size:90%;">, 22(226):1–6, 2021.
</span>
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock"><span id="bib.bib24.1.1" class="ltx_text" style="font-size:90%;">
H. Ludwig, N. Baracaldo, G. Thomas, Y. Zhou, A. Anwar, S. Rajamoni, Y. Ong,
J. Radhakrishnan, A. Verma, M. Sinn, et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.2.1" class="ltx_text" style="font-size:90%;">Ibm federated learning: an enterprise framework white paper v0. 1.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2007.10987</span><span id="bib.bib24.4.2" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock"><span id="bib.bib25.1.1" class="ltx_text" style="font-size:90%;">
B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.2.1" class="ltx_text" style="font-size:90%;">Communication-efficient learning of deep networks from decentralized
data.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib25.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Artificial intelligence and statistics</span><span id="bib.bib25.5.3" class="ltx_text" style="font-size:90%;">, pages 1273–1282.
PMLR, 2017.
</span>
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock"><span id="bib.bib26.1.1" class="ltx_text" style="font-size:90%;">
MONAI Consortium.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.2.1" class="ltx_text" style="font-size:90%;">MONAI: Medical Open Network for AI, 9 2022.
</span>
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock"><span id="bib.bib27.1.1" class="ltx_text" style="font-size:90%;">
OpenAI.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.2.1" class="ltx_text" style="font-size:90%;">Gpt-4 technical report, 2023.
</span>
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock"><span id="bib.bib28.1.1" class="ltx_text" style="font-size:90%;">
L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. Wainwright, P. Mishkin, C. Zhang,
S. Agarwal, K. Slama, A. Ray, et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.2.1" class="ltx_text" style="font-size:90%;">Training language models to follow instructions with human feedback.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Advances in Neural Information Processing Systems</span><span id="bib.bib28.4.2" class="ltx_text" style="font-size:90%;">,
35:27730–27744, 2022.
</span>
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock"><span id="bib.bib29.1.1" class="ltx_text" style="font-size:90%;">
S. Reddi, Z. Charles, M. Zaheer, Z. Garrett, K. Rush, J. Konečnỳ,
S. Kumar, and H. B. McMahan.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.2.1" class="ltx_text" style="font-size:90%;">Adaptive federated optimization.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2003.00295</span><span id="bib.bib29.4.2" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock"><span id="bib.bib30.1.1" class="ltx_text" style="font-size:90%;">
G. A. Reina, A. Gruzdev, P. Foley, O. Perepelkina, M. Sharma, I. Davidyuk,
I. Trushkin, M. Radionov, A. Mokrov, D. Agapov, et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.2.1" class="ltx_text" style="font-size:90%;">Openfl: An open-source framework for federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2105.06413</span><span id="bib.bib30.4.2" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock"><span id="bib.bib31.1.1" class="ltx_text" style="font-size:90%;">
N. Rieke, J. Hancox, W. Li, F. Milletari, H. R. Roth, S. Albarqouni, S. Bakas,
M. N. Galtier, B. A. Landman, K. Maier-Hein, et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.2.1" class="ltx_text" style="font-size:90%;">The future of digital health with federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">NPJ digital medicine</span><span id="bib.bib31.4.2" class="ltx_text" style="font-size:90%;">, 3(1):1–7, 2020.
</span>
</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock"><span id="bib.bib32.1.1" class="ltx_text" style="font-size:90%;">
H. R. Roth, K. Chang, P. Singh, N. Neumark, W. Li, V. Gupta, S. Gupta, L. Qu,
A. Ihsani, B. C. Bizzo, et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.2.1" class="ltx_text" style="font-size:90%;">Federated learning for breast density classification: A real-world
implementation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib32.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Domain Adaptation and Representation Transfer, and
Distributed and Collaborative Learning</span><span id="bib.bib32.5.3" class="ltx_text" style="font-size:90%;">, pages 181–191. Springer, 2020.
</span>
</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock"><span id="bib.bib33.1.1" class="ltx_text" style="font-size:90%;">
K. V. Sarma, S. Harmon, T. Sanford, H. R. Roth, Z. Xu, J. Tetreault, D. Xu,
M. G. Flores, A. G. Raman, R. Kulkarni, et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.2.1" class="ltx_text" style="font-size:90%;">Federated learning improves site performance in multicenter deep
learning without data sharing.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Journal of the American Medical Informatics Association</span><span id="bib.bib33.4.2" class="ltx_text" style="font-size:90%;">,
28(6):1259–1264, 2021.
</span>
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock"><span id="bib.bib34.1.1" class="ltx_text" style="font-size:90%;">
M. J. Sheller, B. Edwards, G. A. Reina, J. Martin, S. Pati, A. Kotrotsou,
M. Milchenko, W. Xu, D. Marcus, R. R. Colen, et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.2.1" class="ltx_text" style="font-size:90%;">Federated learning in medicine: facilitating multi-institutional
collaborations without sharing patient data.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Scientific reports</span><span id="bib.bib34.4.2" class="ltx_text" style="font-size:90%;">, 10(1):1–12, 2020.
</span>
</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock"><span id="bib.bib35.1.1" class="ltx_text" style="font-size:90%;">
M. J. Sheller, G. A. Reina, B. Edwards, J. Martin, and S. Bakas.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.2.1" class="ltx_text" style="font-size:90%;">Multi-institutional deep learning modeling without sharing patient
data: A feasibility study on brain tumor segmentation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib35.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">International MICCAI Brainlesion Workshop</span><span id="bib.bib35.5.3" class="ltx_text" style="font-size:90%;">, pages 92–104.
Springer, 2018.
</span>
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock"><span id="bib.bib36.1.1" class="ltx_text" style="font-size:90%;">
S. Silva, A. Altmann, B. Gutman, and M. Lorenzi.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.2.1" class="ltx_text" style="font-size:90%;">Fed-biomed: A general open-source frontend framework for federated
learning in healthcare.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib36.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Domain Adaptation and Representation Transfer, and
Distributed and Collaborative Learning</span><span id="bib.bib36.5.3" class="ltx_text" style="font-size:90%;">, pages 201–210. Springer, 2020.
</span>
</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock"><span id="bib.bib37.1.1" class="ltx_text" style="font-size:90%;">
H. Wang, M. Yurochkin, Y. Sun, D. Papailiopoulos, and Y. Khazaeni.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.2.1" class="ltx_text" style="font-size:90%;">Federated learning with matched averaging.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2002.06440</span><span id="bib.bib37.4.2" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock"><span id="bib.bib38.1.1" class="ltx_text" style="font-size:90%;">
S. Warnat-Herresthal, H. Schultze, K. L. Shastry, S. Manamohan, S. Mukherjee,
V. Garg, R. Sarveswara, K. Händler, P. Pickkers, N. A. Aziz, et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.2.1" class="ltx_text" style="font-size:90%;">Swarm learning for decentralized and confidential clinical machine
learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Nature</span><span id="bib.bib38.4.2" class="ltx_text" style="font-size:90%;">, 594(7862):265–270, 2021.
</span>
</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock"><span id="bib.bib39.1.1" class="ltx_text" style="font-size:90%;">
Wikipedia contributors.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.2.1" class="ltx_text" style="font-size:90%;">Private set intersection — Wikipedia, the free encyclopedia,
2023.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.3.1" class="ltx_text" style="font-size:90%;">[Online; accessed 27-April-2023].
</span>
</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock"><span id="bib.bib40.1.1" class="ltx_text" style="font-size:90%;">
Y. Xie, Z. Wang, D. Chen, D. Gao, L. Yao, W. Kuang, Y. Li, B. Ding, and
J. Zhou.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.2.1" class="ltx_text" style="font-size:90%;">Federatedscope: A comprehensive and flexible federated learning
platform via message passing.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2204.05011</span><span id="bib.bib40.4.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock"><span id="bib.bib41.1.1" class="ltx_text" style="font-size:90%;">
A. Xu, W. Li, P. Guo, D. Yang, H. R. Roth, A. Hatamizadeh, C. Zhao, D. Xu,
H. Huang, and Z. Xu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.2.1" class="ltx_text" style="font-size:90%;">Closing the generalization gap of cross-silo federated medical image
segmentation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib41.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib41.5.3" class="ltx_text" style="font-size:90%;">, pages 20866–20875, 2022.
</span>
</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock"><span id="bib.bib42.1.1" class="ltx_text" style="font-size:90%;">
Q. Yang, Y. Liu, T. Chen, and Y. Tong.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.2.1" class="ltx_text" style="font-size:90%;">Federated machine learning: Concept and applications.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">ACM Transactions on Intelligent Systems and Technology (TIST)</span><span id="bib.bib42.4.2" class="ltx_text" style="font-size:90%;">,
10(2):1–19, 2019.
</span>
</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock"><span id="bib.bib43.1.1" class="ltx_text" style="font-size:90%;">
H. Zhao, W. Du, F. Li, P. Li, and G. Liu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.2.1" class="ltx_text" style="font-size:90%;">Reduce communication costs and preserve privacy: Prompt tuning method
in federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2208.12268</span><span id="bib.bib43.4.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock"><span id="bib.bib44.1.1" class="ltx_text" style="font-size:90%;">
A. Ziller, A. Trask, A. Lopardo, B. Szymkow, B. Wagner, E. Bluemke, J.-M.
Nounahon, J. Passerat-Palmbach, K. Prakash, N. Rose, et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib44.2.1" class="ltx_text" style="font-size:90%;">Pysyft: A library for easy federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib44.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib44.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Federated Learning Systems</span><span id="bib.bib44.5.3" class="ltx_text" style="font-size:90%;">, pages 111–139. Springer, 2021.
</span>
</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2210.13289" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2210.13291" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2210.13291">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2210.13291" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2210.13292" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Tue Feb 27 02:34:11 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
