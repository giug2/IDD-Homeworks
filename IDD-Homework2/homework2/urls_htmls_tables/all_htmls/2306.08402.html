<!DOCTYPE html><html prefix="dcterms: http://purl.org/dc/terms/" lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2306.08402] Fairness and Privacy-Preserving in Federated Learning: A Survey</title><meta property="og:description" content="Federated learning (FL) as a distributed machine learning strategy has gained immense popularity as privacy-aware Machine Learning (ML) systems have emerged as the solution to prevent privacy leakage by building a glob…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Fairness and Privacy-Preserving in Federated Learning: A Survey">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Fairness and Privacy-Preserving in Federated Learning: A Survey">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2306.08402">

<!--Generated on Thu Feb 29 00:17:50 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="
Federated learning; privacy-preserving; fairness; distributed machine learning.
">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Fairness and Privacy-Preserving in Federated Learning: A Survey</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Taki Hasan Rafi,
Faiza Anan Noor,
Tahmid Hussain,
and Dong-Kyu Chae<sup id="id3.3.id1" class="ltx_sup">†</sup>
</span><span class="ltx_author_notes">T. H. Rafi and D.K. Chae are with the Department of Computer Science, Hanyang University, South Korea.
<br class="ltx_break">E-mail:{takihr, dongkyu}@hanyang.ac.kr
F. A. Noor was with the Department of Computer Science and Engineering, Ahsaullah University of Science and Technology, Bangladesh.
<br class="ltx_break">E-mail: faizanoor.cse@aust.edu
T. Hussain is with the Department of Mathematical and Physical Sciences, East West University, Bangladesh.
<br class="ltx_break">E-mail: tahmid.hussain@upaybd.com
<sup id="id4.4.id1" class="ltx_sup">†</sup>Corresponding Author.
Repo: <a target="_blank" href="https://github.com/takihasan/Fairness-and-Privacy-in-FL-Survey" title="" class="ltx_ref ltx_href" style="color:#0000FF;">https://github.com/takihasan/Fairness-and-Privacy-in-FL-Survey</a>.

<br class="ltx_break"></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id5.id1" class="ltx_p">Federated learning (FL) as a distributed machine learning strategy has gained immense popularity as privacy-aware Machine Learning (ML) systems have emerged as the solution to prevent privacy leakage by building a global model, and conducting individualized training of decentralized edge clients on their own private data. Prior existing works, however, employ privacy mechanisms such as Secure Multiparty Computing (SMC), Differential Privacy (DP), etc, which are immensely susceptible to interference, massive computational overhead, low accuracy, etc. With the increasingly broad deployment of FL systems (FLs), it is challenging to ensure fairness and maintain active client participation in FL systems. Very few works ensure reasonably satisfactory performances for the numerous diverse clients and fail to prevent potential bias against particular demographics in FL systems. The current efforts fail to strike a compromise between privacy, fairness, and model performance in FL systems and are vulnerable to a number of additional problems. In this paper, we provide a comprehensive survey stating the basic concepts of FL, the existing privacy challenges, techniques, and relevant works concerning privacy in FL. We also provide an extensive overview of the increasing fairness challenges, existing fairness notions, and the limited works that attempt both privacy and fairness in FL. By comprehensively describing the existing FL systems, we present the potential future directions pertaining to the challenges of privacy-preserving and fairness-aware FL systems.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
Federated learning; privacy-preserving; fairness; distributed machine learning.

</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Due to the widespread adoption of personal gadgets, and edge devices in recent years, there has been an explosion in data generation, and a majority of this data are now spread across personal devices, different geographic locations, or institutions. Traditional machine-learning approaches rely on gathering raw data from multiple devices or institutions to a single central location (server or data center) in order to train models. Due to factors such as high communication costs, high computational power requirements, etc., collecting data at a central location is impractical in real-world scenarios <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib67" title="" class="ltx_ref">67</a>]</cite>. In addition, the security and privacy of end users or organizations are severely compromised when data from multiple sources are combined, sent to a centralized server, or shared directly between organizations or data centers <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib103" title="" class="ltx_ref">103</a>]</cite>. In such cases, a Collaborative Learning method, which does not involve collecting the users’ private data, such as FL, can be effective and useful. FL is a distributed machine learning technique where multiple data owners, i.e., clients, collaborate together to accomplish learning tasks without the exchange of local data. This training scheme can utilize both centralized (server-controlled) and decentralized (server-less) settings. Since its inception in 2016, this learning strategy has been at the forefront of contemporary machine learning research. FL prohibits the transmission of distributed raw data between collaborating entities in order to ensure the confidentiality of user data. It only allows the participants to share intermediate data among themselves, which in most cases, is updated local gradients or models from the clients. Moreover, immediate aggregation of the updates (gradients or models) is performed as soon as feasible to provide additional protection against the disclosure of sensitive information <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib78" title="" class="ltx_ref">78</a>]</cite>. Besides, it also provides flexibility for the participants in the training process to join and leave the federation according to their own accord.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Nevertheless, recent research has revealed that FL systems may not always offer enough privacy and security guarantees for the participants. In general, security and privacy issues can be caused by a hostile server that intends to infer sensitive information from the local models’ updates over time, meddle with the training process, or any adversarial participant that has the ability to deduce confidential data from other participants, manipulate the local parameter aggregation process, or corrupt the global model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib118" title="" class="ltx_ref">118</a>]</cite>. On the other hand, unfairness in FL systems may arise in different stages of the training process. Existing FL systems mostly suffer from unfairness issues from the following perspectives <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib161" title="" class="ltx_ref">161</a>]</cite>:</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">(i) In the <em id="S1.p3.1.1" class="ltx_emph ltx_font_italic">client selection</em> phase of FL, where methods prioritize the server’s interests and exclude clients with inferior capabilities, unfairness may arise. This decreases the weaker participants’ likelihood of obtaining a global model that corresponds well with their local data distributions. As a result, the global model may not generalize well, as clients ignored in the training process may contain data samples that are not covered by the present model.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">(ii) <em id="S1.p4.1.1" class="ltx_emph ltx_font_italic">FL incentive distribution</em> can also be unfair. Rewards may be needed in the FL training process to compensate for clients’ resources and contributions. The FL system distributes the same global model to all clients as rewards under the standard FL configuration. However, such a strategy ignores the possibility that local client updates are frequently of varied quality due to differences in the quality of data samples and training capabilities. This scheme may be perceived as unjust by clients, who usually have a greater contribution than others to the global model’s performance.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">(iii) To ensure fairness in client selection and incentive distribution, <em id="S1.p5.1.1" class="ltx_emph ltx_font_italic">contribution evaluation</em> is a crucial step in FL. Contribution evaluation may be based on self-reported information from the clients’ side or observations of incremental model enhancement. Existing FL systems use client contribution as an important criterion for selecting high-quality clients, and incentive schemes frequently take client contribution evaluation results into consideration. Unfairness in the evaluation of client contributions can have far-reaching effects on the entire FL training process.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">(iv) Last but not least, ensuring <em id="S1.p6.1.1" class="ltx_emph ltx_font_italic">group fairness</em> in FL system has been a major concern in the past few years. Lately, it has been observed that the outcome of FL systems may be biased towards a population subgroup characterized by a sensitive attribute, such as gender, race, or ethnicity.</p>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p">These privacy and fairness problems, if not addressed properly, might have a severe impact on the dependability of FL as an alternative to centralized ML systems. Unfair treatment and privacy threats may strongly discourage clients from participating in the FL training process. So, it is needless to say that ensuring privacy and fairness in FL systems is of paramount importance.</p>
</div>
<div id="S1.p8" class="ltx_para">
<p id="S1.p8.1" class="ltx_p"><span id="S1.p8.1.1" class="ltx_text ltx_font_bold">Motivation.</span> As FL research has received a growing amount of attention in recent years, numerous survey papers on FL have been published. Various FL-related topics have been the focus of these surveys. Over the years, there have been a few attempts at surveys regarding growing privacy and fairness concerns in FL. However, there is a lack of enough high-quality surveys on these topics, particularly regarding issues of unfairness in FL. Till now, there is only one comprehensive survey that tried to provide a review of fairness concerns and measures in FL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib161" title="" class="ltx_ref">161</a>]</cite>. However, this survey did not provide a comprehensive analysis of the group fairness issue in FL, which has been a significant concern for FL systems in recent years. Some noteworthy surveys on security and privacy issues and privacy preservation approaches in FL have been published recently. Although some privacy issues pertinent to FL were discussed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib119" title="" class="ltx_ref">119</a>]</cite>, there was no discussion on privacy-preserving strategies that could be implemented to guarantee privacy in FL systems. The surveys in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib209" title="" class="ltx_ref">209</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib118" title="" class="ltx_ref">118</a>]</cite> analyze in depth the privacy and security threats to FL systems, along with potential attacks and defense mechanisms. A few surveys, such as <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib113" title="" class="ltx_ref">113</a>]</cite> have tried to provide an extensive review of Privacy-Preserving Aggregation approaches in FL, a key privacy-preserving technique adopted in FL systems.
Despite the fact that there have been distinct surveys on privacy and fairness issues, no survey till now has attempted to provide insights on both fairness and privacy concerns combined. This is our primary motivation behind this combined survey on privacy and fairness concerns in FL, as ensuring both fairness and privacy is of paramount significance for ensuring the quick adoption of Federated Learning systems in real-world scenarios.</p>
</div>
<div id="S1.p9" class="ltx_para">
<p id="S1.p9.1" class="ltx_p"><span id="S1.p9.1.1" class="ltx_text ltx_font_bold">Our Contributions.</span> In particular, our contributions in comparison to earlier works are as follows:</p>
</div>
<div id="S1.p10" class="ltx_para">
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">To the best of our knowledge, our survey is the first paper that comprehensively reviews two dominant categories together, namely privacy-preserving and fairness in Federated Learning (FL).</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">We provide a broad outline of recent and existing privacy and fairness methods, challenges, and relevant works in the context of FL.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">Our survey investigates privacy concerns in FL, evaluating the advantages and limitations of prominent methods used to ensure privacy in FL systems. Additionally, we summarize common metrics employed to evaluate privacy in FL systems.</p>
</div>
</li>
<li id="S1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i4.p1" class="ltx_para">
<p id="S1.I1.i4.p1.1" class="ltx_p">We outline the concept of fairness in FL systems, identifying factors that contribute to bias and lack of fairness. Furthermore, we provide an overview of various aspects of fairness in FL, highlighting challenges, limitations, and evaluation metrics in depth.</p>
</div>
</li>
<li id="S1.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i5.p1" class="ltx_para">
<p id="S1.I1.i5.p1.1" class="ltx_p">Finally, we establish potential challenges and future directions for effectively preserving both privacy and fairness in FL.</p>
</div>
</li>
</ul>
</div>
<div id="S1.p11" class="ltx_para">
<p id="S1.p11.1" class="ltx_p"><span id="S1.p11.1.1" class="ltx_text ltx_font_bold">Organization of the paper.</span>
In Section 2, we provide an overview of the fundamental ideas behind federated learning (FL). Section 3 discusses the privacy challenges and adversaries that a typical FL system encounters, despite promising to be the ultimate tool for establishing privacy through decentralized training of ML systems. In Section 4, we explore the most common methodologies used to tackle privacy risks and challenges. Section 5 introduces the metrics for measuring the level of privacy established in an FL system. In Section 6, we introduce the concept of fairness in FL systems and present the plausible causes of bias creation among diverse clients or certain demographic groups in FL. Section 7 presents works that attempt to establish fairness in FL systems by eradicating the existing bias sources. This section also discusses different notions that aim to establish fairness from various perspectives. In Section 8, we describe how fairness in FL can be measured or quantified. Section 9 discusses the limited amount of work that equally emphasizes both fairness and privacy in FL. In Section 10, we highlight the challenges that current FL systems face regarding privacy and fairness, and we propose future research directions. An illustration of privacy and fairness in FL is shown in Figure 2.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Federated Learning: An Overview</span>
</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">In general, FL refers to a machine learning strategy that attempts to jointly train an ML model globally using model parameters across numerous clients. Its core methodology involves creating local models from local datasets and then using local clients to exchange parameters (such as model weights or gradients) to construct a global model. A typical FL system comprises two main parties. An illustration of an overview of FL is shown in Figure 1.</p>
</div>
<figure id="S2.F1" class="ltx_figure"><img src="/html/2306.08402/assets/x1.png" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="181" height="115" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>A typical overview of a federated learning environment.</figcaption>
</figure>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span><span id="S2.SS1.1.1" class="ltx_text ltx_font_italic">FL Categorization</span>
</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p"><span id="S2.SS1.p1.1.1" class="ltx_text ltx_font_bold">Horizontal Federated Learning (HFL).</span>
HFL is employed for situations where there is a small intersection on the sample space, but the various parties are involved to share the same feature space. Generally, most FL systems fall under this category and are prevalent in situations when each device possesses data containing identical feature space but varying sample space. Since all the local data exist in the same feature space, the clients have the advantage of using the same model architecture for training the models with that local data. By averaging all of the local individual models, the aggregated model can easily be updated using all the weights shared by the local models.
<br class="ltx_break"><span id="S2.SS1.p1.1.2" class="ltx_text ltx_font_bold">Vertical Federated Learning (VFL).</span>
Vertical Federated Learning, a less common category of FL, is employed in cases where each device has a dataset with unique characteristics derived from sample data. For instance, Vertical FL may be used to create a shared ML model across two organizations that have data on the same group of individuals but distinct feature sets. Since the local data lie in different feature spaces, it becomes difficult for the parties to share the same model architecture to train the local individual models with the same local data.
<br class="ltx_break"><span id="S2.SS1.p1.1.3" class="ltx_text ltx_font_bold">Federated Transfer Learning (FTL).</span>
FTL is appropriate when the feature space of the data varies together with the sample space. FTL normally exists as a mix of horizontal and vertical partitions. Most FL systems, however, commonly concentrate on horizontal partitioning. In case of instances where we only have enough training data for classification in one of our target domains, even when the classification task itself is in a different feature space or has a different data distribution from the training data, federated transfer learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib140" title="" class="ltx_ref">140</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib108" title="" class="ltx_ref">108</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib156" title="" class="ltx_ref">156</a>]</cite> can be used.
<br class="ltx_break"></p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span><span id="S2.SS2.1.1" class="ltx_text ltx_font_italic">FL Phases</span>
</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">The four key phases of an FL system are <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib103" title="" class="ltx_ref">103</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib86" title="" class="ltx_ref">86</a>]</cite>: 
<br class="ltx_break"><span id="S2.SS2.p1.1.1" class="ltx_text ltx_font_bold">Client Selection Phase.</span> In this phase, the curator or global model or server either chooses the required clients at random from a group of devices or employs an algorithm for client selection. 
<br class="ltx_break"><span id="S2.SS2.p1.1.2" class="ltx_text ltx_font_bold">Broadcasting of Weights.</span>
After the server manages the mandatory task and data requirements and completes the hyperparameter specification, it broadcasts the global model weights or parameters. Additionally, it assigns work to the participants chosen in the client selection phase.
<br class="ltx_break"><span id="S2.SS2.p1.1.3" class="ltx_text ltx_font_bold">Local Training.</span> This phase refers to the concurrent and individual training of each client, using each client’s local data. 
<br class="ltx_break"><span id="S2.SS2.p1.1.4" class="ltx_text ltx_font_bold">Global Model Aggregation.</span>
In this phase, each client, after completion of individual training, propagates their local model parameters to the server. Thereafter, the parameters are aggregated to construct the aggregated global model. These phases keep repeating until convergence.</p>
</div>
<figure id="S2.F2" class="ltx_figure"><img src="/html/2306.08402/assets/x2.png" id="S2.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="311" height="137" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>An Overview of Privacy-Preserving and Fairness in FL. (a) Privacy-Preserving in FL, and (b) Fairness in FL.</figcaption>
</figure>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Privacy Challenges in FL</span>
</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">The fundamental goal of a typical FL system is privacy preservation, as it enables systems or devices to jointly construct a global model while keeping all the training data locally on each individual system or device. Moreover, several clients perform concurrent local training on their own local data and communicate these gradients or weights procured during the local training phase to a central server. This process involves no private information in each client to be revealed, leading to a privacy-aware collaborative paradigm. Even though the primary goal is to hinder access to private or local data possessed by a particular client by other clients, several studies <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib119" title="" class="ltx_ref">119</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib122" title="" class="ltx_ref">122</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib166" title="" class="ltx_ref">166</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib187" title="" class="ltx_ref">187</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib191" title="" class="ltx_ref">191</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib224" title="" class="ltx_ref">224</a>]</cite> demonstrate that FL systems are susceptible to several kinds of privacy attacks, primarily during the model weight exchange phase. A privacy attack often aims to deduce private data from training datasets, such as membership and class representatives and other properties. Model updates might leak extra information about unwanted properties of participants’ private training data to hostile participants. Without possessing any prior knowledge of the training and regarding the model, an attacker can retrieve the original training samples by inferring labels from the shared gradients. Attacks made during the training in an FL model attempt to decipher, govern, or corrupt the entire model. The attacker might conduct model poisoning attacks or data poisoning attacks during the training phase to jeopardize the validity of the datasets used for training or to undermine the validity of the training procedure. The attacker is also able to execute a variety of inference attacks which are mainly evasion/exploratory assaults against a model’s individual or collective updates. Attacks during the inference phase are attacks which aim on producing incorrect outputs and gathering information on the model’s properties. Most privacy attacks occur during the inference phase. The inference attacks have the underlying assumption that the attackers possess unlimited computational resources, complex technical capabilities and full knowledge of the model. Inference attacks can be categorized mainly into the following types:
<br class="ltx_break"></p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span><span id="S3.SS1.1.1" class="ltx_text ltx_font_italic">Inferring Class Representatives</span>
</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">Inference for class representatives attempt to produce examples that would not stand out in the primary dataset. The attacker can discover a lot about the data by effectively producing such samples. This kind of attack <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite> leverages the advantage of real-time learning to enable the adversary to form a Generative Adversarial Network (GAN). This procures synthetic samples of the intended training set that was considered to be private, having the same distribution as the data reproduced.
<br class="ltx_break"></p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span><span id="S3.SS2.1.1" class="ltx_text ltx_font_italic">Inferring Membership</span>
</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">Membership inference attempts to assess with accuracy whether a particular sample was used to train the network and acts on all target samples concurrently. An attacker, for example, can deduce if a given patient profile, such as a Pneumonia affected patient was used to develop a classifier that can distinguish between lung-affected patients. In the active membership inference scenario, the adversary has the ability to alter the FL model and launch a stronger assault on more participants. The target model is compelled to decrease the loss by descending in the direction of its local model’s gradient by the gradient ascent attack. This can be used by the attackers to update the model parameters in the opposite direction of the loss gradient and can disseminate hostile updates and manipulate the model to reveal sensitive details about the local data of other players. In contrast, the attacker in the passive scenario observes the modified weights to make inferences and does not interfere with the learning process. 
<br class="ltx_break"></p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span><span id="S3.SS3.1.1" class="ltx_text ltx_font_italic">Inferring Data Properties</span>
</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">This sort of attack aims at deducing the meta-characteristics or the properties regarding the data being utilized. In case of an active adversary, multi-task learning can be leveraged and the FL model can be deceived to separate data with and without the target attribute in order to gather more data. Attacks of this type assume that supplemental training data are accurately labeled with the desired attribute by the adversary. A passive adversary can only keep track of the parameters and infer using a binary property classifier trained on them.
<br class="ltx_break"></p>
</div>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span><span id="S3.SS4.1.1" class="ltx_text ltx_font_italic">Inferring Samples / Labels</span>
</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p">This type of assault or attack seeks to precisely replicate training samples utilized at the time of training and/or related labels that were used during training (rather than reconstructing them). Deep Leakage from Gradients (DLG) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib240" title="" class="ltx_ref">240</a>]</cite> follows an optimization approach, and shows how sharing the gradients might expose sensitive training data and reveals dataset properties such as the training samples and labels. This occurs with a minimal number of iterations. To carry out the attack, a pair of synthetic or artificial inputs and labels are created. Then those dummy inputs and labels are optimized to diminish the gap between the artificial gradients and the original ones after deriving the artificial ones from the artificial data instead of maximizing model weights as in conventional training. GAN models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib186" title="" class="ltx_ref">186</a>]</cite> can also be used to synthesize pictures that resemble training data from the gradient but the attack is constrained and only functions when the victim and adversary share at least one common label, which is impractical in real life. Privacy leaks and assaults may originate from one or more attackers <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>. They may adopt the following forms:
<br class="ltx_break"><span id="S3.SS4.p1.1.1" class="ltx_text ltx_font_bold">Single Adversary.</span> Privacy leakages can occur due to a single, non-colluding opponent <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib119" title="" class="ltx_ref">119</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib190" title="" class="ltx_ref">190</a>]</cite> such as a Federated client, the global server, or a third party even though a single attacker rarely possesses a central servers’ attacking level.
<br class="ltx_break"><span id="S3.SS4.p1.1.2" class="ltx_text ltx_font_bold">Colluding Attackers.</span> Even though attacks can occur with or without the help of the central server, collaborating FL users and main servers often increases the chance of privacy leaks and can cause more heinous attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib119" title="" class="ltx_ref">119</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib141" title="" class="ltx_ref">141</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib221" title="" class="ltx_ref">221</a>]</cite>.</p>
</div>
<div id="S3.SS4.p2" class="ltx_para">
<p id="S3.SS4.p2.1" class="ltx_p">The following two main categories can be used to categorize the enemies’ capacity and role:
<br class="ltx_break"><span id="S3.SS4.p2.1.1" class="ltx_text ltx_font_bold">Passive Malicious Server or Client (Honest-But-Curious or Semi-Honest).</span>
An FL global model or server can become curious and can retrieve clients’ private data by observing the updates exchanged by the clients. Likewise, a curious FL client can retrieve private information about the system by observing the global parameters. These adversaries attempt to discover the personal information of honest individuals while adhering to the protocols of the system.
<br class="ltx_break"><span id="S3.SS4.p2.1.2" class="ltx_text ltx_font_bold">Active Malicious Server or Client (Malicious while the Context is Clear).</span>
These adversaries or attackers alter identity or send false messages to other parties, but have a chance to deviate from the protocol of the system anytime. An actively malicious server is capable of performing strong assaults since it can also manage how each client views the overall model. The aggregated updates from all other clients are accessible to an adversary malicious client, who can construct their own malicious parameters. This allows a malicious FL server or client to obtain inner details about a client or a server’s private data.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Privacy-Preservation in FL</span>
</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">The works on privacy preservation normally fall under four categories: 1) Cryptographic methods, 2) Anonymization methods, 3) Perturbative methods, and (4) Hybrid PPFL methods. Each of them are described below:</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span><span id="S4.SS1.1.1" class="ltx_text ltx_font_italic">Cryptographic Methods</span>
</h3>

<section id="S4.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.1 </span>Homomorphic Encryption (HE)</h4>

<div id="S4.SS1.SSS1.p1" class="ltx_para">
<p id="S4.SS1.SSS1.p1.15" class="ltx_p">By exchanging parameters inside the encryption method, HE safeguards user data privacy. In HE, data is encrypted into ciphertext using operations used to handle the original data. The manipulation of the plaintext in this process is analogous to linear algebraic operations and does not involve decryption. The data or model are not exchanged, and can not be inferred from the data of the opposite party. For two messages, <math id="S4.SS1.SSS1.p1.1.m1.1" class="ltx_Math" alttext="M_{1}" display="inline"><semantics id="S4.SS1.SSS1.p1.1.m1.1a"><msub id="S4.SS1.SSS1.p1.1.m1.1.1" xref="S4.SS1.SSS1.p1.1.m1.1.1.cmml"><mi id="S4.SS1.SSS1.p1.1.m1.1.1.2" xref="S4.SS1.SSS1.p1.1.m1.1.1.2.cmml">M</mi><mn id="S4.SS1.SSS1.p1.1.m1.1.1.3" xref="S4.SS1.SSS1.p1.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p1.1.m1.1b"><apply id="S4.SS1.SSS1.p1.1.m1.1.1.cmml" xref="S4.SS1.SSS1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS1.p1.1.m1.1.1.1.cmml" xref="S4.SS1.SSS1.p1.1.m1.1.1">subscript</csymbol><ci id="S4.SS1.SSS1.p1.1.m1.1.1.2.cmml" xref="S4.SS1.SSS1.p1.1.m1.1.1.2">𝑀</ci><cn type="integer" id="S4.SS1.SSS1.p1.1.m1.1.1.3.cmml" xref="S4.SS1.SSS1.p1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.p1.1.m1.1c">M_{1}</annotation></semantics></math> and <math id="S4.SS1.SSS1.p1.2.m2.1" class="ltx_Math" alttext="M_{2}" display="inline"><semantics id="S4.SS1.SSS1.p1.2.m2.1a"><msub id="S4.SS1.SSS1.p1.2.m2.1.1" xref="S4.SS1.SSS1.p1.2.m2.1.1.cmml"><mi id="S4.SS1.SSS1.p1.2.m2.1.1.2" xref="S4.SS1.SSS1.p1.2.m2.1.1.2.cmml">M</mi><mn id="S4.SS1.SSS1.p1.2.m2.1.1.3" xref="S4.SS1.SSS1.p1.2.m2.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p1.2.m2.1b"><apply id="S4.SS1.SSS1.p1.2.m2.1.1.cmml" xref="S4.SS1.SSS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS1.p1.2.m2.1.1.1.cmml" xref="S4.SS1.SSS1.p1.2.m2.1.1">subscript</csymbol><ci id="S4.SS1.SSS1.p1.2.m2.1.1.2.cmml" xref="S4.SS1.SSS1.p1.2.m2.1.1.2">𝑀</ci><cn type="integer" id="S4.SS1.SSS1.p1.2.m2.1.1.3.cmml" xref="S4.SS1.SSS1.p1.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.p1.2.m2.1c">M_{2}</annotation></semantics></math>, one can compute En (<math id="S4.SS1.SSS1.p1.3.m3.1" class="ltx_Math" alttext="M_{1}+M_{2}" display="inline"><semantics id="S4.SS1.SSS1.p1.3.m3.1a"><mrow id="S4.SS1.SSS1.p1.3.m3.1.1" xref="S4.SS1.SSS1.p1.3.m3.1.1.cmml"><msub id="S4.SS1.SSS1.p1.3.m3.1.1.2" xref="S4.SS1.SSS1.p1.3.m3.1.1.2.cmml"><mi id="S4.SS1.SSS1.p1.3.m3.1.1.2.2" xref="S4.SS1.SSS1.p1.3.m3.1.1.2.2.cmml">M</mi><mn id="S4.SS1.SSS1.p1.3.m3.1.1.2.3" xref="S4.SS1.SSS1.p1.3.m3.1.1.2.3.cmml">1</mn></msub><mo id="S4.SS1.SSS1.p1.3.m3.1.1.1" xref="S4.SS1.SSS1.p1.3.m3.1.1.1.cmml">+</mo><msub id="S4.SS1.SSS1.p1.3.m3.1.1.3" xref="S4.SS1.SSS1.p1.3.m3.1.1.3.cmml"><mi id="S4.SS1.SSS1.p1.3.m3.1.1.3.2" xref="S4.SS1.SSS1.p1.3.m3.1.1.3.2.cmml">M</mi><mn id="S4.SS1.SSS1.p1.3.m3.1.1.3.3" xref="S4.SS1.SSS1.p1.3.m3.1.1.3.3.cmml">2</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p1.3.m3.1b"><apply id="S4.SS1.SSS1.p1.3.m3.1.1.cmml" xref="S4.SS1.SSS1.p1.3.m3.1.1"><plus id="S4.SS1.SSS1.p1.3.m3.1.1.1.cmml" xref="S4.SS1.SSS1.p1.3.m3.1.1.1"></plus><apply id="S4.SS1.SSS1.p1.3.m3.1.1.2.cmml" xref="S4.SS1.SSS1.p1.3.m3.1.1.2"><csymbol cd="ambiguous" id="S4.SS1.SSS1.p1.3.m3.1.1.2.1.cmml" xref="S4.SS1.SSS1.p1.3.m3.1.1.2">subscript</csymbol><ci id="S4.SS1.SSS1.p1.3.m3.1.1.2.2.cmml" xref="S4.SS1.SSS1.p1.3.m3.1.1.2.2">𝑀</ci><cn type="integer" id="S4.SS1.SSS1.p1.3.m3.1.1.2.3.cmml" xref="S4.SS1.SSS1.p1.3.m3.1.1.2.3">1</cn></apply><apply id="S4.SS1.SSS1.p1.3.m3.1.1.3.cmml" xref="S4.SS1.SSS1.p1.3.m3.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.SSS1.p1.3.m3.1.1.3.1.cmml" xref="S4.SS1.SSS1.p1.3.m3.1.1.3">subscript</csymbol><ci id="S4.SS1.SSS1.p1.3.m3.1.1.3.2.cmml" xref="S4.SS1.SSS1.p1.3.m3.1.1.3.2">𝑀</ci><cn type="integer" id="S4.SS1.SSS1.p1.3.m3.1.1.3.3.cmml" xref="S4.SS1.SSS1.p1.3.m3.1.1.3.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.p1.3.m3.1c">M_{1}+M_{2}</annotation></semantics></math>, <math id="S4.SS1.SSS1.p1.4.m4.1" class="ltx_Math" alttext="p_{k}" display="inline"><semantics id="S4.SS1.SSS1.p1.4.m4.1a"><msub id="S4.SS1.SSS1.p1.4.m4.1.1" xref="S4.SS1.SSS1.p1.4.m4.1.1.cmml"><mi id="S4.SS1.SSS1.p1.4.m4.1.1.2" xref="S4.SS1.SSS1.p1.4.m4.1.1.2.cmml">p</mi><mi id="S4.SS1.SSS1.p1.4.m4.1.1.3" xref="S4.SS1.SSS1.p1.4.m4.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p1.4.m4.1b"><apply id="S4.SS1.SSS1.p1.4.m4.1.1.cmml" xref="S4.SS1.SSS1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS1.p1.4.m4.1.1.1.cmml" xref="S4.SS1.SSS1.p1.4.m4.1.1">subscript</csymbol><ci id="S4.SS1.SSS1.p1.4.m4.1.1.2.cmml" xref="S4.SS1.SSS1.p1.4.m4.1.1.2">𝑝</ci><ci id="S4.SS1.SSS1.p1.4.m4.1.1.3.cmml" xref="S4.SS1.SSS1.p1.4.m4.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.p1.4.m4.1c">p_{k}</annotation></semantics></math>) using En (<math id="S4.SS1.SSS1.p1.5.m5.2" class="ltx_Math" alttext="M_{1},p_{k}" display="inline"><semantics id="S4.SS1.SSS1.p1.5.m5.2a"><mrow id="S4.SS1.SSS1.p1.5.m5.2.2.2" xref="S4.SS1.SSS1.p1.5.m5.2.2.3.cmml"><msub id="S4.SS1.SSS1.p1.5.m5.1.1.1.1" xref="S4.SS1.SSS1.p1.5.m5.1.1.1.1.cmml"><mi id="S4.SS1.SSS1.p1.5.m5.1.1.1.1.2" xref="S4.SS1.SSS1.p1.5.m5.1.1.1.1.2.cmml">M</mi><mn id="S4.SS1.SSS1.p1.5.m5.1.1.1.1.3" xref="S4.SS1.SSS1.p1.5.m5.1.1.1.1.3.cmml">1</mn></msub><mo id="S4.SS1.SSS1.p1.5.m5.2.2.2.3" xref="S4.SS1.SSS1.p1.5.m5.2.2.3.cmml">,</mo><msub id="S4.SS1.SSS1.p1.5.m5.2.2.2.2" xref="S4.SS1.SSS1.p1.5.m5.2.2.2.2.cmml"><mi id="S4.SS1.SSS1.p1.5.m5.2.2.2.2.2" xref="S4.SS1.SSS1.p1.5.m5.2.2.2.2.2.cmml">p</mi><mi id="S4.SS1.SSS1.p1.5.m5.2.2.2.2.3" xref="S4.SS1.SSS1.p1.5.m5.2.2.2.2.3.cmml">k</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p1.5.m5.2b"><list id="S4.SS1.SSS1.p1.5.m5.2.2.3.cmml" xref="S4.SS1.SSS1.p1.5.m5.2.2.2"><apply id="S4.SS1.SSS1.p1.5.m5.1.1.1.1.cmml" xref="S4.SS1.SSS1.p1.5.m5.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS1.p1.5.m5.1.1.1.1.1.cmml" xref="S4.SS1.SSS1.p1.5.m5.1.1.1.1">subscript</csymbol><ci id="S4.SS1.SSS1.p1.5.m5.1.1.1.1.2.cmml" xref="S4.SS1.SSS1.p1.5.m5.1.1.1.1.2">𝑀</ci><cn type="integer" id="S4.SS1.SSS1.p1.5.m5.1.1.1.1.3.cmml" xref="S4.SS1.SSS1.p1.5.m5.1.1.1.1.3">1</cn></apply><apply id="S4.SS1.SSS1.p1.5.m5.2.2.2.2.cmml" xref="S4.SS1.SSS1.p1.5.m5.2.2.2.2"><csymbol cd="ambiguous" id="S4.SS1.SSS1.p1.5.m5.2.2.2.2.1.cmml" xref="S4.SS1.SSS1.p1.5.m5.2.2.2.2">subscript</csymbol><ci id="S4.SS1.SSS1.p1.5.m5.2.2.2.2.2.cmml" xref="S4.SS1.SSS1.p1.5.m5.2.2.2.2.2">𝑝</ci><ci id="S4.SS1.SSS1.p1.5.m5.2.2.2.2.3.cmml" xref="S4.SS1.SSS1.p1.5.m5.2.2.2.2.3">𝑘</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.p1.5.m5.2c">M_{1},p_{k}</annotation></semantics></math>) and En (<math id="S4.SS1.SSS1.p1.6.m6.2" class="ltx_Math" alttext="M_{2},p_{k}" display="inline"><semantics id="S4.SS1.SSS1.p1.6.m6.2a"><mrow id="S4.SS1.SSS1.p1.6.m6.2.2.2" xref="S4.SS1.SSS1.p1.6.m6.2.2.3.cmml"><msub id="S4.SS1.SSS1.p1.6.m6.1.1.1.1" xref="S4.SS1.SSS1.p1.6.m6.1.1.1.1.cmml"><mi id="S4.SS1.SSS1.p1.6.m6.1.1.1.1.2" xref="S4.SS1.SSS1.p1.6.m6.1.1.1.1.2.cmml">M</mi><mn id="S4.SS1.SSS1.p1.6.m6.1.1.1.1.3" xref="S4.SS1.SSS1.p1.6.m6.1.1.1.1.3.cmml">2</mn></msub><mo id="S4.SS1.SSS1.p1.6.m6.2.2.2.3" xref="S4.SS1.SSS1.p1.6.m6.2.2.3.cmml">,</mo><msub id="S4.SS1.SSS1.p1.6.m6.2.2.2.2" xref="S4.SS1.SSS1.p1.6.m6.2.2.2.2.cmml"><mi id="S4.SS1.SSS1.p1.6.m6.2.2.2.2.2" xref="S4.SS1.SSS1.p1.6.m6.2.2.2.2.2.cmml">p</mi><mi id="S4.SS1.SSS1.p1.6.m6.2.2.2.2.3" xref="S4.SS1.SSS1.p1.6.m6.2.2.2.2.3.cmml">k</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p1.6.m6.2b"><list id="S4.SS1.SSS1.p1.6.m6.2.2.3.cmml" xref="S4.SS1.SSS1.p1.6.m6.2.2.2"><apply id="S4.SS1.SSS1.p1.6.m6.1.1.1.1.cmml" xref="S4.SS1.SSS1.p1.6.m6.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS1.p1.6.m6.1.1.1.1.1.cmml" xref="S4.SS1.SSS1.p1.6.m6.1.1.1.1">subscript</csymbol><ci id="S4.SS1.SSS1.p1.6.m6.1.1.1.1.2.cmml" xref="S4.SS1.SSS1.p1.6.m6.1.1.1.1.2">𝑀</ci><cn type="integer" id="S4.SS1.SSS1.p1.6.m6.1.1.1.1.3.cmml" xref="S4.SS1.SSS1.p1.6.m6.1.1.1.1.3">2</cn></apply><apply id="S4.SS1.SSS1.p1.6.m6.2.2.2.2.cmml" xref="S4.SS1.SSS1.p1.6.m6.2.2.2.2"><csymbol cd="ambiguous" id="S4.SS1.SSS1.p1.6.m6.2.2.2.2.1.cmml" xref="S4.SS1.SSS1.p1.6.m6.2.2.2.2">subscript</csymbol><ci id="S4.SS1.SSS1.p1.6.m6.2.2.2.2.2.cmml" xref="S4.SS1.SSS1.p1.6.m6.2.2.2.2.2">𝑝</ci><ci id="S4.SS1.SSS1.p1.6.m6.2.2.2.2.3.cmml" xref="S4.SS1.SSS1.p1.6.m6.2.2.2.2.3">𝑘</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.p1.6.m6.2c">M_{2},p_{k}</annotation></semantics></math>) without knowing anything about <math id="S4.SS1.SSS1.p1.7.m7.1" class="ltx_Math" alttext="M_{1}" display="inline"><semantics id="S4.SS1.SSS1.p1.7.m7.1a"><msub id="S4.SS1.SSS1.p1.7.m7.1.1" xref="S4.SS1.SSS1.p1.7.m7.1.1.cmml"><mi id="S4.SS1.SSS1.p1.7.m7.1.1.2" xref="S4.SS1.SSS1.p1.7.m7.1.1.2.cmml">M</mi><mn id="S4.SS1.SSS1.p1.7.m7.1.1.3" xref="S4.SS1.SSS1.p1.7.m7.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p1.7.m7.1b"><apply id="S4.SS1.SSS1.p1.7.m7.1.1.cmml" xref="S4.SS1.SSS1.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS1.p1.7.m7.1.1.1.cmml" xref="S4.SS1.SSS1.p1.7.m7.1.1">subscript</csymbol><ci id="S4.SS1.SSS1.p1.7.m7.1.1.2.cmml" xref="S4.SS1.SSS1.p1.7.m7.1.1.2">𝑀</ci><cn type="integer" id="S4.SS1.SSS1.p1.7.m7.1.1.3.cmml" xref="S4.SS1.SSS1.p1.7.m7.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.p1.7.m7.1c">M_{1}</annotation></semantics></math> and <math id="S4.SS1.SSS1.p1.8.m8.1" class="ltx_Math" alttext="M_{2}" display="inline"><semantics id="S4.SS1.SSS1.p1.8.m8.1a"><msub id="S4.SS1.SSS1.p1.8.m8.1.1" xref="S4.SS1.SSS1.p1.8.m8.1.1.cmml"><mi id="S4.SS1.SSS1.p1.8.m8.1.1.2" xref="S4.SS1.SSS1.p1.8.m8.1.1.2.cmml">M</mi><mn id="S4.SS1.SSS1.p1.8.m8.1.1.3" xref="S4.SS1.SSS1.p1.8.m8.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p1.8.m8.1b"><apply id="S4.SS1.SSS1.p1.8.m8.1.1.cmml" xref="S4.SS1.SSS1.p1.8.m8.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS1.p1.8.m8.1.1.1.cmml" xref="S4.SS1.SSS1.p1.8.m8.1.1">subscript</csymbol><ci id="S4.SS1.SSS1.p1.8.m8.1.1.2.cmml" xref="S4.SS1.SSS1.p1.8.m8.1.1.2">𝑀</ci><cn type="integer" id="S4.SS1.SSS1.p1.8.m8.1.1.3.cmml" xref="S4.SS1.SSS1.p1.8.m8.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.p1.8.m8.1c">M_{2}</annotation></semantics></math>. Here, En (<math id="S4.SS1.SSS1.p1.9.m9.1" class="ltx_Math" alttext="\cdot" display="inline"><semantics id="S4.SS1.SSS1.p1.9.m9.1a"><mo id="S4.SS1.SSS1.p1.9.m9.1.1" xref="S4.SS1.SSS1.p1.9.m9.1.1.cmml">⋅</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p1.9.m9.1b"><ci id="S4.SS1.SSS1.p1.9.m9.1.1.cmml" xref="S4.SS1.SSS1.p1.9.m9.1.1">⋅</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.p1.9.m9.1c">\cdot</annotation></semantics></math>) refers to the encryption function and <math id="S4.SS1.SSS1.p1.10.m10.1" class="ltx_Math" alttext="p_{k}" display="inline"><semantics id="S4.SS1.SSS1.p1.10.m10.1a"><msub id="S4.SS1.SSS1.p1.10.m10.1.1" xref="S4.SS1.SSS1.p1.10.m10.1.1.cmml"><mi id="S4.SS1.SSS1.p1.10.m10.1.1.2" xref="S4.SS1.SSS1.p1.10.m10.1.1.2.cmml">p</mi><mi id="S4.SS1.SSS1.p1.10.m10.1.1.3" xref="S4.SS1.SSS1.p1.10.m10.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p1.10.m10.1b"><apply id="S4.SS1.SSS1.p1.10.m10.1.1.cmml" xref="S4.SS1.SSS1.p1.10.m10.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS1.p1.10.m10.1.1.1.cmml" xref="S4.SS1.SSS1.p1.10.m10.1.1">subscript</csymbol><ci id="S4.SS1.SSS1.p1.10.m10.1.1.2.cmml" xref="S4.SS1.SSS1.p1.10.m10.1.1.2">𝑝</ci><ci id="S4.SS1.SSS1.p1.10.m10.1.1.3.cmml" xref="S4.SS1.SSS1.p1.10.m10.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.p1.10.m10.1c">p_{k}</annotation></semantics></math> refers to the public key <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib118" title="" class="ltx_ref">118</a>]</cite>. By using the secret key <math id="S4.SS1.SSS1.p1.11.m11.1" class="ltx_Math" alttext="s_{k}" display="inline"><semantics id="S4.SS1.SSS1.p1.11.m11.1a"><msub id="S4.SS1.SSS1.p1.11.m11.1.1" xref="S4.SS1.SSS1.p1.11.m11.1.1.cmml"><mi id="S4.SS1.SSS1.p1.11.m11.1.1.2" xref="S4.SS1.SSS1.p1.11.m11.1.1.2.cmml">s</mi><mi id="S4.SS1.SSS1.p1.11.m11.1.1.3" xref="S4.SS1.SSS1.p1.11.m11.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p1.11.m11.1b"><apply id="S4.SS1.SSS1.p1.11.m11.1.1.cmml" xref="S4.SS1.SSS1.p1.11.m11.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS1.p1.11.m11.1.1.1.cmml" xref="S4.SS1.SSS1.p1.11.m11.1.1">subscript</csymbol><ci id="S4.SS1.SSS1.p1.11.m11.1.1.2.cmml" xref="S4.SS1.SSS1.p1.11.m11.1.1.2">𝑠</ci><ci id="S4.SS1.SSS1.p1.11.m11.1.1.3.cmml" xref="S4.SS1.SSS1.p1.11.m11.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.p1.11.m11.1c">s_{k}</annotation></semantics></math> and the appropriate decryption function Dec(<math id="S4.SS1.SSS1.p1.12.m12.1" class="ltx_Math" alttext="\cdot" display="inline"><semantics id="S4.SS1.SSS1.p1.12.m12.1a"><mo id="S4.SS1.SSS1.p1.12.m12.1.1" xref="S4.SS1.SSS1.p1.12.m12.1.1.cmml">⋅</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p1.12.m12.1b"><ci id="S4.SS1.SSS1.p1.12.m12.1.1.cmml" xref="S4.SS1.SSS1.p1.12.m12.1.1">⋅</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.p1.12.m12.1c">\cdot</annotation></semantics></math>), one can obtain <math id="S4.SS1.SSS1.p1.13.m13.1" class="ltx_Math" alttext="M_{1}+M_{2}" display="inline"><semantics id="S4.SS1.SSS1.p1.13.m13.1a"><mrow id="S4.SS1.SSS1.p1.13.m13.1.1" xref="S4.SS1.SSS1.p1.13.m13.1.1.cmml"><msub id="S4.SS1.SSS1.p1.13.m13.1.1.2" xref="S4.SS1.SSS1.p1.13.m13.1.1.2.cmml"><mi id="S4.SS1.SSS1.p1.13.m13.1.1.2.2" xref="S4.SS1.SSS1.p1.13.m13.1.1.2.2.cmml">M</mi><mn id="S4.SS1.SSS1.p1.13.m13.1.1.2.3" xref="S4.SS1.SSS1.p1.13.m13.1.1.2.3.cmml">1</mn></msub><mo id="S4.SS1.SSS1.p1.13.m13.1.1.1" xref="S4.SS1.SSS1.p1.13.m13.1.1.1.cmml">+</mo><msub id="S4.SS1.SSS1.p1.13.m13.1.1.3" xref="S4.SS1.SSS1.p1.13.m13.1.1.3.cmml"><mi id="S4.SS1.SSS1.p1.13.m13.1.1.3.2" xref="S4.SS1.SSS1.p1.13.m13.1.1.3.2.cmml">M</mi><mn id="S4.SS1.SSS1.p1.13.m13.1.1.3.3" xref="S4.SS1.SSS1.p1.13.m13.1.1.3.3.cmml">2</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p1.13.m13.1b"><apply id="S4.SS1.SSS1.p1.13.m13.1.1.cmml" xref="S4.SS1.SSS1.p1.13.m13.1.1"><plus id="S4.SS1.SSS1.p1.13.m13.1.1.1.cmml" xref="S4.SS1.SSS1.p1.13.m13.1.1.1"></plus><apply id="S4.SS1.SSS1.p1.13.m13.1.1.2.cmml" xref="S4.SS1.SSS1.p1.13.m13.1.1.2"><csymbol cd="ambiguous" id="S4.SS1.SSS1.p1.13.m13.1.1.2.1.cmml" xref="S4.SS1.SSS1.p1.13.m13.1.1.2">subscript</csymbol><ci id="S4.SS1.SSS1.p1.13.m13.1.1.2.2.cmml" xref="S4.SS1.SSS1.p1.13.m13.1.1.2.2">𝑀</ci><cn type="integer" id="S4.SS1.SSS1.p1.13.m13.1.1.2.3.cmml" xref="S4.SS1.SSS1.p1.13.m13.1.1.2.3">1</cn></apply><apply id="S4.SS1.SSS1.p1.13.m13.1.1.3.cmml" xref="S4.SS1.SSS1.p1.13.m13.1.1.3"><csymbol cd="ambiguous" id="S4.SS1.SSS1.p1.13.m13.1.1.3.1.cmml" xref="S4.SS1.SSS1.p1.13.m13.1.1.3">subscript</csymbol><ci id="S4.SS1.SSS1.p1.13.m13.1.1.3.2.cmml" xref="S4.SS1.SSS1.p1.13.m13.1.1.3.2">𝑀</ci><cn type="integer" id="S4.SS1.SSS1.p1.13.m13.1.1.3.3.cmml" xref="S4.SS1.SSS1.p1.13.m13.1.1.3.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.p1.13.m13.1c">M_{1}+M_{2}</annotation></semantics></math>. This is an example of an additive Homomorphic Encryption mechanism that consists of the key pair (<math id="S4.SS1.SSS1.p1.14.m14.1" class="ltx_Math" alttext="p_{k}" display="inline"><semantics id="S4.SS1.SSS1.p1.14.m14.1a"><msub id="S4.SS1.SSS1.p1.14.m14.1.1" xref="S4.SS1.SSS1.p1.14.m14.1.1.cmml"><mi id="S4.SS1.SSS1.p1.14.m14.1.1.2" xref="S4.SS1.SSS1.p1.14.m14.1.1.2.cmml">p</mi><mi id="S4.SS1.SSS1.p1.14.m14.1.1.3" xref="S4.SS1.SSS1.p1.14.m14.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p1.14.m14.1b"><apply id="S4.SS1.SSS1.p1.14.m14.1.1.cmml" xref="S4.SS1.SSS1.p1.14.m14.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS1.p1.14.m14.1.1.1.cmml" xref="S4.SS1.SSS1.p1.14.m14.1.1">subscript</csymbol><ci id="S4.SS1.SSS1.p1.14.m14.1.1.2.cmml" xref="S4.SS1.SSS1.p1.14.m14.1.1.2">𝑝</ci><ci id="S4.SS1.SSS1.p1.14.m14.1.1.3.cmml" xref="S4.SS1.SSS1.p1.14.m14.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.p1.14.m14.1c">p_{k}</annotation></semantics></math>, <math id="S4.SS1.SSS1.p1.15.m15.1" class="ltx_Math" alttext="s_{k}" display="inline"><semantics id="S4.SS1.SSS1.p1.15.m15.1a"><msub id="S4.SS1.SSS1.p1.15.m15.1.1" xref="S4.SS1.SSS1.p1.15.m15.1.1.cmml"><mi id="S4.SS1.SSS1.p1.15.m15.1.1.2" xref="S4.SS1.SSS1.p1.15.m15.1.1.2.cmml">s</mi><mi id="S4.SS1.SSS1.p1.15.m15.1.1.3" xref="S4.SS1.SSS1.p1.15.m15.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p1.15.m15.1b"><apply id="S4.SS1.SSS1.p1.15.m15.1.1.cmml" xref="S4.SS1.SSS1.p1.15.m15.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS1.p1.15.m15.1.1.1.cmml" xref="S4.SS1.SSS1.p1.15.m15.1.1">subscript</csymbol><ci id="S4.SS1.SSS1.p1.15.m15.1.1.2.cmml" xref="S4.SS1.SSS1.p1.15.m15.1.1.2">𝑠</ci><ci id="S4.SS1.SSS1.p1.15.m15.1.1.3.cmml" xref="S4.SS1.SSS1.p1.15.m15.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.p1.15.m15.1c">s_{k}</annotation></semantics></math>). Currently, the existing methods of HE may be classified into the following categories: 1) Fully Homomorphic Encryption (FHE), and 2) Partially Homomorphic Encryption (PHE). FHE is comparatively more efficient and supports large ciphertext sizes, although it requires heavy computation resulting in a slow process. On the contrary, PHE schemes are less efficient and support small ciphertext sizes but is a swift process which requires less computational power. The most common techniques include Paillier <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib139" title="" class="ltx_ref">139</a>]</cite>, CKKS, and FV <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite> schemes which are highly inefficient in terms of communicational and computational aspects. The CKKS technique adopts polynomial reductions and modular multiplications to encrypt real or complex numbers but only produces approximations. The Paillier and FV algorithms both use integers as the plaintext. Even though the FV and CKKS methods offer both adds and multiplications on ciphertexts, the Paillier technique allows only additions to be done on encrypted data. An additively homomorphic encryption-based secure method <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib88" title="" class="ltx_ref">88</a>]</cite> is introduced for safeguarding the training and forecasting data using a logistic regression (LR) model and is implemented the system using encryption algorithms such as Paillier, LWE-based, and ring-LWE. They also underline the advantages and disadvantages of every implementation. The resulting system was incredibly scalable in terms of dataset size as well as dimension, supporting large sizes like hundreds of millions of records (108s).</p>
</div>
</section>
<section id="S4.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.2 </span>SMC (Secure Multiparty Computation)</h4>

<div id="S4.SS1.SSS2.p1" class="ltx_para">
<p id="S4.SS1.SSS2.p1.1" class="ltx_p">SMC <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> involves multiple parties or clients with private inputs and executes a collaborative computation on individual data or inputs without any sort of disclosure of private information. SecureML <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib124" title="" class="ltx_ref">124</a>]</cite> uses secure two-party computation (2PC) so that data owners can encrypt, process and secretly distribute their data across two servers that are non-colluding. Falling under the two server-model category, it enables every single client to train different models on their combined data without having to disclose any sort of data or information besides the results. However, this poses substantial computational and communication overhead, which may deter players will to collaborate. This method is a fault-tolerant, speedy, and safe protocol for secure aggregation suggested by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>. In this process, devices can exchange updates with the assumption that the service provider views it only after it has been combined by averaging it with the updates of other devices. For instance, an SMC protocol facilitates data sharing among servers (as <math id="S4.SS1.SSS2.p1.1.m1.3" class="ltx_Math" alttext="S_{1},S_{2},S_{3}" display="inline"><semantics id="S4.SS1.SSS2.p1.1.m1.3a"><mrow id="S4.SS1.SSS2.p1.1.m1.3.3.3" xref="S4.SS1.SSS2.p1.1.m1.3.3.4.cmml"><msub id="S4.SS1.SSS2.p1.1.m1.1.1.1.1" xref="S4.SS1.SSS2.p1.1.m1.1.1.1.1.cmml"><mi id="S4.SS1.SSS2.p1.1.m1.1.1.1.1.2" xref="S4.SS1.SSS2.p1.1.m1.1.1.1.1.2.cmml">S</mi><mn id="S4.SS1.SSS2.p1.1.m1.1.1.1.1.3" xref="S4.SS1.SSS2.p1.1.m1.1.1.1.1.3.cmml">1</mn></msub><mo id="S4.SS1.SSS2.p1.1.m1.3.3.3.4" xref="S4.SS1.SSS2.p1.1.m1.3.3.4.cmml">,</mo><msub id="S4.SS1.SSS2.p1.1.m1.2.2.2.2" xref="S4.SS1.SSS2.p1.1.m1.2.2.2.2.cmml"><mi id="S4.SS1.SSS2.p1.1.m1.2.2.2.2.2" xref="S4.SS1.SSS2.p1.1.m1.2.2.2.2.2.cmml">S</mi><mn id="S4.SS1.SSS2.p1.1.m1.2.2.2.2.3" xref="S4.SS1.SSS2.p1.1.m1.2.2.2.2.3.cmml">2</mn></msub><mo id="S4.SS1.SSS2.p1.1.m1.3.3.3.5" xref="S4.SS1.SSS2.p1.1.m1.3.3.4.cmml">,</mo><msub id="S4.SS1.SSS2.p1.1.m1.3.3.3.3" xref="S4.SS1.SSS2.p1.1.m1.3.3.3.3.cmml"><mi id="S4.SS1.SSS2.p1.1.m1.3.3.3.3.2" xref="S4.SS1.SSS2.p1.1.m1.3.3.3.3.2.cmml">S</mi><mn id="S4.SS1.SSS2.p1.1.m1.3.3.3.3.3" xref="S4.SS1.SSS2.p1.1.m1.3.3.3.3.3.cmml">3</mn></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS2.p1.1.m1.3b"><list id="S4.SS1.SSS2.p1.1.m1.3.3.4.cmml" xref="S4.SS1.SSS2.p1.1.m1.3.3.3"><apply id="S4.SS1.SSS2.p1.1.m1.1.1.1.1.cmml" xref="S4.SS1.SSS2.p1.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS2.p1.1.m1.1.1.1.1.1.cmml" xref="S4.SS1.SSS2.p1.1.m1.1.1.1.1">subscript</csymbol><ci id="S4.SS1.SSS2.p1.1.m1.1.1.1.1.2.cmml" xref="S4.SS1.SSS2.p1.1.m1.1.1.1.1.2">𝑆</ci><cn type="integer" id="S4.SS1.SSS2.p1.1.m1.1.1.1.1.3.cmml" xref="S4.SS1.SSS2.p1.1.m1.1.1.1.1.3">1</cn></apply><apply id="S4.SS1.SSS2.p1.1.m1.2.2.2.2.cmml" xref="S4.SS1.SSS2.p1.1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S4.SS1.SSS2.p1.1.m1.2.2.2.2.1.cmml" xref="S4.SS1.SSS2.p1.1.m1.2.2.2.2">subscript</csymbol><ci id="S4.SS1.SSS2.p1.1.m1.2.2.2.2.2.cmml" xref="S4.SS1.SSS2.p1.1.m1.2.2.2.2.2">𝑆</ci><cn type="integer" id="S4.SS1.SSS2.p1.1.m1.2.2.2.2.3.cmml" xref="S4.SS1.SSS2.p1.1.m1.2.2.2.2.3">2</cn></apply><apply id="S4.SS1.SSS2.p1.1.m1.3.3.3.3.cmml" xref="S4.SS1.SSS2.p1.1.m1.3.3.3.3"><csymbol cd="ambiguous" id="S4.SS1.SSS2.p1.1.m1.3.3.3.3.1.cmml" xref="S4.SS1.SSS2.p1.1.m1.3.3.3.3">subscript</csymbol><ci id="S4.SS1.SSS2.p1.1.m1.3.3.3.3.2.cmml" xref="S4.SS1.SSS2.p1.1.m1.3.3.3.3.2">𝑆</ci><cn type="integer" id="S4.SS1.SSS2.p1.1.m1.3.3.3.3.3.cmml" xref="S4.SS1.SSS2.p1.1.m1.3.3.3.3.3">3</cn></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS2.p1.1.m1.3c">S_{1},S_{2},S_{3}</annotation></semantics></math>, etc.) in such a way that the data can only be reconstructed if the shared portions on n number of servers are known. The advantage of training models using this technique is that it guarantees that the server only learns data about specific users and no party learns anything beyond the aggregate of the inputs from a small number of trustworthy users. SMC techniques frequently give a high level of accuracy and privacy at the expense of significant computing and communication costs, limiting their capacity to attract participants, and concurrent involvement of all parties becomes a major challenge. In exchange for efficiency, it is possible to build a security model with fewer security requirements using SMC. Partial knowledge disclosure may be considered permissible if security guarantees are provided.</p>
</div>
</section>
<section id="S4.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.3 </span>Secret Sharing</h4>

<div id="S4.SS1.SSS3.p1" class="ltx_para">
<p id="S4.SS1.SSS3.p1.7" class="ltx_p">Secret sharing <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> refers to a cryptographic approach that ensures that a secret is made up of <math id="S4.SS1.SSS3.p1.1.m1.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S4.SS1.SSS3.p1.1.m1.1a"><mi id="S4.SS1.SSS3.p1.1.m1.1.1" xref="S4.SS1.SSS3.p1.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p1.1.m1.1b"><ci id="S4.SS1.SSS3.p1.1.m1.1.1.cmml" xref="S4.SS1.SSS3.p1.1.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p1.1.m1.1c">N</annotation></semantics></math> number of shares and can only be reconstructed if an adequate number of shares are joined. These techniques have been adopted by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib110" title="" class="ltx_ref">110</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib199" title="" class="ltx_ref">199</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite>. t-out-of-n <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib159" title="" class="ltx_ref">159</a>]</cite> technique demonstrates how to split a data (or secret) <math id="S4.SS1.SSS3.p1.2.m2.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S4.SS1.SSS3.p1.2.m2.1a"><mi id="S4.SS1.SSS3.p1.2.m2.1.1" xref="S4.SS1.SSS3.p1.2.m2.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p1.2.m2.1b"><ci id="S4.SS1.SSS3.p1.2.m2.1.1.cmml" xref="S4.SS1.SSS3.p1.2.m2.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p1.2.m2.1c">S</annotation></semantics></math> into <math id="S4.SS1.SSS3.p1.3.m3.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S4.SS1.SSS3.p1.3.m3.1a"><mi id="S4.SS1.SSS3.p1.3.m3.1.1" xref="S4.SS1.SSS3.p1.3.m3.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p1.3.m3.1b"><ci id="S4.SS1.SSS3.p1.3.m3.1.1.cmml" xref="S4.SS1.SSS3.p1.3.m3.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p1.3.m3.1c">n</annotation></semantics></math> parts so that <math id="S4.SS1.SSS3.p1.4.m4.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S4.SS1.SSS3.p1.4.m4.1a"><mi id="S4.SS1.SSS3.p1.4.m4.1.1" xref="S4.SS1.SSS3.p1.4.m4.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p1.4.m4.1b"><ci id="S4.SS1.SSS3.p1.4.m4.1.1.cmml" xref="S4.SS1.SSS3.p1.4.m4.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p1.4.m4.1c">S</annotation></semantics></math> may be readily reconstructed from any <math id="S4.SS1.SSS3.p1.5.m5.1" class="ltx_Math" alttext="m" display="inline"><semantics id="S4.SS1.SSS3.p1.5.m5.1a"><mi id="S4.SS1.SSS3.p1.5.m5.1.1" xref="S4.SS1.SSS3.p1.5.m5.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p1.5.m5.1b"><ci id="S4.SS1.SSS3.p1.5.m5.1.1.cmml" xref="S4.SS1.SSS3.p1.5.m5.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p1.5.m5.1c">m</annotation></semantics></math> pieces, but even complete knowledge of <math id="S4.SS1.SSS3.p1.6.m6.1" class="ltx_Math" alttext="m-1" display="inline"><semantics id="S4.SS1.SSS3.p1.6.m6.1a"><mrow id="S4.SS1.SSS3.p1.6.m6.1.1" xref="S4.SS1.SSS3.p1.6.m6.1.1.cmml"><mi id="S4.SS1.SSS3.p1.6.m6.1.1.2" xref="S4.SS1.SSS3.p1.6.m6.1.1.2.cmml">m</mi><mo id="S4.SS1.SSS3.p1.6.m6.1.1.1" xref="S4.SS1.SSS3.p1.6.m6.1.1.1.cmml">−</mo><mn id="S4.SS1.SSS3.p1.6.m6.1.1.3" xref="S4.SS1.SSS3.p1.6.m6.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p1.6.m6.1b"><apply id="S4.SS1.SSS3.p1.6.m6.1.1.cmml" xref="S4.SS1.SSS3.p1.6.m6.1.1"><minus id="S4.SS1.SSS3.p1.6.m6.1.1.1.cmml" xref="S4.SS1.SSS3.p1.6.m6.1.1.1"></minus><ci id="S4.SS1.SSS3.p1.6.m6.1.1.2.cmml" xref="S4.SS1.SSS3.p1.6.m6.1.1.2">𝑚</ci><cn type="integer" id="S4.SS1.SSS3.p1.6.m6.1.1.3.cmml" xref="S4.SS1.SSS3.p1.6.m6.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p1.6.m6.1c">m-1</annotation></semantics></math> piece reveals no information about <math id="S4.SS1.SSS3.p1.7.m7.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S4.SS1.SSS3.p1.7.m7.1a"><mi id="S4.SS1.SSS3.p1.7.m7.1.1" xref="S4.SS1.SSS3.p1.7.m7.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p1.7.m7.1b"><ci id="S4.SS1.SSS3.p1.7.m7.1.1.cmml" xref="S4.SS1.SSS3.p1.7.m7.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p1.7.m7.1c">S</annotation></semantics></math>. Using this methodology, strong key management schemes for cryptographic systems can be constructed that can continue to operate safely and reliably. SMC protocol was originally designed for securing aggregate gradients but its offline phase is quite complicated, and the system efficiency would be jeopardized if certain customers dropped out. Heterogeneous Federated Transfer Learning (HFTL) system <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite> uses a continuous privacy-preserving multi-party learning strategy with two variations based on HE and secret sharing mechanisms, respectively, and applied this technique for the case of mortality prediction in hospitals. PFK-means <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib110" title="" class="ltx_ref">110</a>]</cite>, a privacy-preserving federated k-means technique attempts at providing proactive caching in cellular networks. This algorithm is built on FL and secret sharing. To cope with the backdoor attacks during training, a set of secret sharing protocols are utilized, and in the meantime, the data regarding client dropout is rebuilt using Lagrange basis polynomials to respond to the dynamic user change. This process is extremely time-consuming but is less computationally expensive and lighter than cryptographic methods such as existing HE or blockchain-based systems. A parameter server <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib162" title="" class="ltx_ref">162</a>]</cite> distributes the model gradients across the clients during training. Although they considerably increase efficiency, gradient leaks potentially compromise security. VerifyNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib199" title="" class="ltx_ref">199</a>]</cite> is an FL system that uses the secret sharing and key agreement protocol to safeguard the confidentiality of the participants’ local gradients during the update phase. To secure the privacy of users’ local gradients during FL, they first used a double-masking approach. The cloud server then gives each user the evidence that the findings it has compiled are accurate. In this way, this scheme protects privacy and can be independently verified.</p>
</div>
</section>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span><span id="S4.SS2.1.1" class="ltx_text ltx_font_italic">Anonymization Methods</span>
</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">Anonymization or de-identification mechanisms work by deleting any personally identifiable or detectable information from data. This could include a person’s name, age, phone number, address, marital status, etc. These techniques have been employed by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib166" title="" class="ltx_ref">166</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib233" title="" class="ltx_ref">233</a>]</cite>. TorMentor <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite> facilitates private multi-party ML, by expanding on FL. This system facilitates learning abstraction such that, in an untrusted environment, it enables data sources to contribute to a globally shared model with verifiable privacy guarantees. Multi-task GAN - Auxiliary Identification (mGAN-AI) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib166" title="" class="ltx_ref">166</a>]</cite> combines GAN and a multi-task discriminator to concurrently distinguish between category and client identification of input. This system can retrieve user-specified private data and operates on the server side invisibly.
In addition, taking into account the anonymization approach for mGAN-AI mitigation, they suggests a linkability attack that re-identifies the anonymized updates by connecting the client representatives in advance. Furthermore, for determining the similarity of representatives, a brand-new Siamese network combining the identification and verification models is created.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">Anonymization methods are classified into three types: k-anonymity <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib170" title="" class="ltx_ref">170</a>]</cite>, l-diversity <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib122" title="" class="ltx_ref">122</a>]</cite>, and t-closeness <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib94" title="" class="ltx_ref">94</a>]</cite>. These are specifically constructed for tabular datasets consisting of multiple records. QIDs are qualities of a dataset that, when combined, can re-identify persons through triangulation attacks. However, syntactic techniques for centralized settings have been much more thoroughly examined than the distributed FL scenario. The client side’s original private data is anonymized using the k-anonymity algorithm as the first core component, and a global model is jointly trained using the anonymized data. A defendable degree of data privacy was provided by this approach such that it complies with regulatory requirements (such as the EU General Data Protection Regulation and the US Health Insurance Portability and Accountability Act). Unfortunately, k-anonymity cannot prevent linkage attacks in which a sensitive property is shared by a number of people who share the same QID. l-diversity extends k-anonymity to assure diversity among a group of people that share the same quasi-identifier <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>. t-closeness extends both of these strategies in order to retain the distribution of sensitive qualities across any group of individuals who share the same QID by diminishing the granularity of a data representation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib87" title="" class="ltx_ref">87</a>]</cite>. If the difference between the sensitive attribute distribution in an equivalent class and the attribute distribution over the whole table is less than a threshold <math id="S4.SS2.p2.1.m1.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S4.SS2.p2.1.m1.1a"><mi id="S4.SS2.p2.1.m1.1.1" xref="S4.SS2.p2.1.m1.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.1.m1.1b"><ci id="S4.SS2.p2.1.m1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.1.m1.1c">t</annotation></semantics></math>, the class is said to have t-closeness. A table is said to be t-close if all equivalence classes are t-close. All techniques, however, suffer when an attacker has some knowledge of the sensitive property. Privacy leakage is reduced <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib233" title="" class="ltx_ref">233</a>]</cite> by allowing exchanging a lesser amount of parameters between the global model and clients. Differential privacy (DP) techniques on communicated parameters were applied with a Gaussian mechanism to achieve privacy. Moreover, to achieve participant anonymity, they used a proxy server as the intermediary layer between the global model and clients in order to lower the communication strain on the FL server. Ad-hoc anonymization might reasonably remove names, gender, phone numbers, social passwords, addresses, and other identifiers from each users’ record(s), assuming that individuals cannot be identified within the changed dataset.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span><span id="S4.SS3.1.1" class="ltx_text ltx_font_italic">Perturbative Methods</span>
</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">Perturbation methods <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib204" title="" class="ltx_ref">204</a>]</cite> are simple and effective methods that require no prior knowledge of the data distribution and it prevents clients from acquiring real global model parameters and local gradients. It works by incorporating arbitrary random integers as noises to the data, similar to DP. This causes the data derived from the disturbed parameters statistically to be identical to the original ones. PEFL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib92" title="" class="ltx_ref">92</a>]</cite> uses long short-term memory-autoencoder approach and perturbation-based encoding to construct an FL-based gated recurrent unit neural network algorithm (FedGRU) for intrusion detection. These methods can be used to counter inquisitive clients’ reconstruction and membership inference assaults by choosing random integers as perturbed noises added to the global model parameters, like Differential Privacy, rendering it extremely effective and simple to use practically. But unlike Differential Privacy, Perturbation methods have no negative impact on learning accuracy as the server can retrieve the real gradients by deleting the introduced noises. However, these techniques are still susceptible to probabilistic privacy attacks. Mostly three kinds of separate perturbation techniques are often employed currently which are: 1) Differential privacy, 2) Additive Perturbation, and 3) Multiplicative Perturbation.</p>
</div>
<section id="S4.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.1 </span>Differential Privacy (DP)</h4>

<div id="S4.SS3.SSS1.p1" class="ltx_para">
<p id="S4.SS3.SSS1.p1.1" class="ltx_p">Differential privacy (DP) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib173" title="" class="ltx_ref">173</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib133" title="" class="ltx_ref">133</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib137" title="" class="ltx_ref">137</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite> is a technique that uses probabilistic statistical models to safeguard user privacy, and measures the level of private information disclosure of samples. Differential privacy mechanisms entail that privacy is achieved by introducing a small amount of Gaussian or exponentially distributed random noise or utilizing generalization techniques to hide specific sensitive qualities so that a third party is unable to differentiate the individual and the data can no longer be recovered. Even though the models are constructed after noise is injected, the DP approach is lossy, and can significantly lower performance in prediction accuracy, and the perfect tradeoff between accuracy and privacy is a challenge. DP can be categorized into the following categories:
<br class="ltx_break"><span id="S4.SS3.SSS1.p1.1.1" class="ltx_text ltx_font_bold">Centralized Differential Privacy (CDP).</span>
This process was primarily meant for a centralized situation in which there exists a trusted or reliable server, that is authorized to access all clients’ data and desires to respond to queries and publish statistics that protect user privacy by randomly generating query results. 
<br class="ltx_break"><span id="S4.SS3.SSS1.p1.1.2" class="ltx_text ltx_font_bold">Local Differential Privacy (LDP).</span>
When clients do not trust the server, LDP addresses CDP’s flaws and assures privacy. In this process, a differentially private alteration <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib235" title="" class="ltx_ref">235</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib118" title="" class="ltx_ref">118</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib84" title="" class="ltx_ref">84</a>]</cite> is applied to each client’s data before sharing it with the server, and this allows for DP to be achieved in absence of the central server’s participation. Because each party modifies its data independently, it is important to use LDP methods carefully to avoid having wrong predicted frequencies in the dataset. 
<br class="ltx_break"><span id="S4.SS3.SSS1.p1.1.3" class="ltx_text ltx_font_bold">Distributed Differential Privacy (DDP).</span>
In this process, the clients calculate and encrypt a brief, targeted report before sending the encoded reports to a secure computing function, the output of which is accessible to the central server. By the time the central server can view the output, it already complies with multiple privacy standards. To protect the clients’ privacy, the encoding is carried out. By using safe aggregations and secure shuffling, this privacy-preserving method may be put into practice. 
<br class="ltx_break"><span id="S4.SS3.SSS1.p1.1.4" class="ltx_text ltx_font_bold">Hybrid Differential Privacy (HDP).</span>
This process amalgamates various trust models by segmenting consumers according to their trust model choices. HDP-VFL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib178" title="" class="ltx_ref">178</a>]</cite>, the first ever hybrid differentially private (DP) framework for vertical federated learning (VFL), jointly trains a generalized linear model (GLM) from VFL with just minimal cost, compared to idealized non-private VFL. It relies on protocols like SMC and HE for privacy-preserving.</p>
</div>
</section>
<section id="S4.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.2 </span>Additive Perturbation Methods</h4>

<div id="S4.SS3.SSS2.p1" class="ltx_para">
<p id="S4.SS3.SSS2.p1.1" class="ltx_p">Additive perturbative techniques <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib107" title="" class="ltx_ref">107</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib102" title="" class="ltx_ref">102</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib104" title="" class="ltx_ref">104</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib131" title="" class="ltx_ref">131</a>]</cite> are simple and quick perturbation techniques that require no prior knowledge of data distribution and aims to incorporate random noise into the data from a certain distribution (such as a uniform distribution or Gaussian distribution) in order to maintain the privacy of the original data while preserving the statistical properties. A class of methods <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> are discussed for privacy-preserving data mining. These methods randomly disturb the data using random value additive perturbation methods while maintaining its underlying probabilistic features. By introducing random noise, this method attempts to maintain the privacy of the data while ensuring that the random noise retains the signal from the data, allowing for accurate estimation of the patterns. Additive perturbation methods are less costly, easy to apply, and can be applied to each data point. Yet, it could reduce the value of the data and might be susceptible to noise reduction.</p>
</div>
</section>
<section id="S4.SS3.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.3 </span>Multiplicative Perturbation Methods</h4>

<div id="S4.SS3.SSS3.p1" class="ltx_para">
<p id="S4.SS3.SSS3.p1.1" class="ltx_p">A multiplicative perturbation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib205" title="" class="ltx_ref">205</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib105" title="" class="ltx_ref">105</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> method employs a set of transformation-invariant models, such as rotation and translation, so that they can be directly applied to the perturbed data, rather than introducing random noise to data. It converts the original data space into another space while keeping task and model particular information, obtaining the requisite model accuracy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>. Plain additive perturbation methods are not sufficient, a combination of additive and multiplicative procedures eradicate the drawbacks of both, as demonstrated by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite>. POLAR-SGD (Private Optimization and Learning Algorithm with Stochastic Gradient Descent) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> causes clients to hide the gradients via coupled additive and multiplicative perturbations. These obscured gradients are sent to several servers, which subsequently train prediction models. This research offers DISTPAB, a distributed perturbation technique for the privacy preservation of HFL, as a solution to these problems. By spreading out the burden of privacy using resource asymmetry in a distributed environment, DISTPAB reduces computational bottlenecks. Obscuring data at each IoT item using independent Gaussian random projection trains a Deep Neural Network (DNN) at the global model or server using the data projected from the IoT-based clients or objects <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib107" title="" class="ltx_ref">107</a>]</cite>. This method shifts the majority of the effort to the coordinator, who has access to adequate computing resources and introduces a minimal calculation overhead to the IoT objects. They conducted several studies using support vector machines and additive noise reduction for differential privacy but their comparative analysis demonstrates that this strategy outperforms the other methods.</p>
</div>
</section>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span><span id="S4.SS4.1.1" class="ltx_text ltx_font_italic">Hardware-Based Protection</span>
</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p">Hardware-level privacy assurances or trusted execution environments (TEE) such as secure processors embedded in client devices also exit, which can guarantee privacy in the event of operating system kernel security flaws. It is likely that such system-based or hardware-based privacy-preserving mechanisms will become more common owing to the growing influence of hardware-level ML-based works. Gradient preserving is obtained when using trustworthy SGX processors for this operation, even though server side channel attack exploitation still remains an issue. ShuffleFL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib232" title="" class="ltx_ref">232</a>]</cite>, a gradient-preserving system combines random group structure with intra-group gradient segment aggregation to defend against assaults using trustworthy SGX processors. Likewise, FLASH <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib225" title="" class="ltx_ref">225</a>]</cite> also performs acceptable acceleration for cross-silo FL systems using hardware acceleration architecture. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib207" title="" class="ltx_ref">207</a>]</cite> performs Pailier homomorphic Encryption using Hardware Accelerator for Efficient Federated Learning, possessing rigorous processing clock cycle, resource utilization, and clock frequency optimization for the modular multiplication operation. Flatee <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib127" title="" class="ltx_ref">127</a>]</cite>, a productive, privacy-preserving FL-based platform spans TEEs and significantly cuts down on training and communication time.</p>
</div>
</section>
<section id="S4.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5 </span><span id="S4.SS5.1.1" class="ltx_text ltx_font_italic">Hybrid Privacy-Preserving Techniques</span>
</h3>

<div id="S4.SS5.p1" class="ltx_para">
<p id="S4.SS5.p1.1" class="ltx_p">Currently, hybrid privacy-preserving techniques approaches have been proposed to address the tradeoff between data privacy and data utility and to lessen computation and communication costs at the same time. The majority of FL systems employ the differential privacy approach which acts by perturbing values and ensures statistical indistinguishability for individual inputs. Differential privacy adds a layer of randomization so that attackers with more knowledge still do not know the true value. Hence, this addition of randomization compromises accuracy and model efficiency while protecting user privacy. So differential privacy lessens the danger of data leakage but does not completely eliminate its occurrence and also jeopardizes model accuracy. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib129" title="" class="ltx_ref">129</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite> battled against data leakage and tried to upgrade model efficiency using the combined efforts of differential privacy and cryptography. SMPAI <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib129" title="" class="ltx_ref">129</a>]</cite> uses SMC and DP and constructed models where the differentially private noise for each party is dispersed and created by other parties without any prior knowledge. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite> proposed Confidential and Private Collaborative (CaPC) learning and aimed to achieve both privacy and confidentiality in a collaborative situation, combining privately aggregated models with Secure Multi-party Computation (SMC), Homomorphic Encryption (HE), and other methods. Using this model, each party may increase model accuracy and fairness even in cases where each party has an overfitted model that produces good results on their own data only. This model is also suitable for situations where the data persists in a form that is not Independent and Identically Distributed(IID) and model architectures are variable across parties. This enables participants to cooperate without explicitly requiring them to connect their training sets or develop a central model. However, the computational costs are high.</p>
</div>
<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE I: </span><span id="S4.T1.2.1" class="ltx_text ltx_font_bold">A Summary on Privacy Techniques in FL.</span></figcaption>
<div id="S4.T1.3" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:493.1pt;height:375.3pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-82.2pt,62.6pt) scale(0.75,0.75) ;">
<table id="S4.T1.3.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T1.3.1.1.1" class="ltx_tr">
<th id="S4.T1.3.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S4.T1.3.1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.1.1.1.1.1.1" class="ltx_p" style="width:85.4pt;"><span id="S4.T1.3.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Privacy Preserving technique</span></span>
</span>
</th>
<th id="S4.T1.3.1.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S4.T1.3.1.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.1.1.1.2.1.1" class="ltx_p" style="width:142.3pt;"><span id="S4.T1.3.1.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Working Principle</span></span>
</span>
</th>
<th id="S4.T1.3.1.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S4.T1.3.1.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.1.1.1.3.1.1" class="ltx_p" style="width:113.8pt;"><span id="S4.T1.3.1.1.1.3.1.1.1" class="ltx_text ltx_font_bold">Existing studies</span></span>
</span>
</th>
<th id="S4.T1.3.1.1.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S4.T1.3.1.1.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.1.1.1.4.1.1" class="ltx_p" style="width:113.8pt;"><span id="S4.T1.3.1.1.1.4.1.1.1" class="ltx_text ltx_font_bold">Advantage</span></span>
</span>
</th>
<th id="S4.T1.3.1.1.1.5" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S4.T1.3.1.1.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.1.1.1.5.1.1" class="ltx_p" style="width:142.3pt;"><span id="S4.T1.3.1.1.1.5.1.1.1" class="ltx_text ltx_font_bold">Disadvantage</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T1.3.1.2.1" class="ltx_tr">
<td id="S4.T1.3.1.2.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S4.T1.3.1.2.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.1.2.1.1.1.1" class="ltx_p" style="width:85.4pt;">HE</span>
</span>
</td>
<td id="S4.T1.3.1.2.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S4.T1.3.1.2.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.1.2.1.2.1.1" class="ltx_p" style="width:142.3pt;">Cryptographic method that allows data to be processed mathematically as if it were unencrypted plain text, even though it has been encrypted.</span>
</span>
</td>
<td id="S4.T1.3.1.2.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S4.T1.3.1.2.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.1.2.1.3.1.1" class="ltx_p" style="width:113.8pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib227" title="" class="ltx_ref">227</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib136" title="" class="ltx_ref">136</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib145" title="" class="ltx_ref">145</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib120" title="" class="ltx_ref">120</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib216" title="" class="ltx_ref">216</a>]</cite></span>
</span>
</td>
<td id="S4.T1.3.1.2.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S4.T1.3.1.2.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.1.2.1.4.1.1" class="ltx_p" style="width:113.8pt;">The server is allowed to execute direct operations on encrypted data, and no decryption is required for operation executions.</span>
</span>
</td>
<td id="S4.T1.3.1.2.1.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S4.T1.3.1.2.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.1.2.1.5.1.1" class="ltx_p" style="width:142.3pt;">The encryption operation is computationally expensive and time-consuming.</span>
</span>
</td>
</tr>
<tr id="S4.T1.3.1.3.2" class="ltx_tr">
<td id="S4.T1.3.1.3.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S4.T1.3.1.3.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.1.3.2.1.1.1" class="ltx_p" style="width:85.4pt;">SMC</span>
</span>
</td>
<td id="S4.T1.3.1.3.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S4.T1.3.1.3.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.1.3.2.2.1.1" class="ltx_p" style="width:142.3pt;">A group of methods and protocols that allow two or more parties to divide up data among themselves and do joint calculations without letting any one party see the data.</span>
</span>
</td>
<td id="S4.T1.3.1.3.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S4.T1.3.1.3.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.1.3.2.3.1.1" class="ltx_p" style="width:113.8pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib128" title="" class="ltx_ref">128</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib100" title="" class="ltx_ref">100</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib200" title="" class="ltx_ref">200</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib114" title="" class="ltx_ref">114</a>]</cite></span>
</span>
</td>
<td id="S4.T1.3.1.3.2.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S4.T1.3.1.3.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.1.3.2.4.1.1" class="ltx_p" style="width:113.8pt;">The parties involved have no restrictions on the control of the data owned.</span>
</span>
</td>
<td id="S4.T1.3.1.3.2.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S4.T1.3.1.3.2.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.1.3.2.5.1.1" class="ltx_p" style="width:142.3pt;">Contains massive communication overhead.</span>
</span>
</td>
</tr>
<tr id="S4.T1.3.1.4.3" class="ltx_tr">
<td id="S4.T1.3.1.4.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S4.T1.3.1.4.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.1.4.3.1.1.1" class="ltx_p" style="width:85.4pt;">DP</span>
</span>
</td>
<td id="S4.T1.3.1.4.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S4.T1.3.1.4.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.1.4.3.2.1.1" class="ltx_p" style="width:142.3pt;">Obfuscation of individual data points in a dataset by modification or disruption while preserving limited interaction with the data.</span>
</span>
</td>
<td id="S4.T1.3.1.4.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S4.T1.3.1.4.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.1.4.3.3.1.1" class="ltx_p" style="width:113.8pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib188" title="" class="ltx_ref">188</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib171" title="" class="ltx_ref">171</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib158" title="" class="ltx_ref">158</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib235" title="" class="ltx_ref">235</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref">50</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib193" title="" class="ltx_ref">193</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib169" title="" class="ltx_ref">169</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib89" title="" class="ltx_ref">89</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib154" title="" class="ltx_ref">154</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib101" title="" class="ltx_ref">101</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib179" title="" class="ltx_ref">179</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>,
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib71" title="" class="ltx_ref">71</a>]</cite>,
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib230" title="" class="ltx_ref">230</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib198" title="" class="ltx_ref">198</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib99" title="" class="ltx_ref">99</a>]</cite></span>
</span>
</td>
<td id="S4.T1.3.1.4.3.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S4.T1.3.1.4.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.1.4.3.4.1.1" class="ltx_p" style="width:113.8pt;">Protection can be provided in the absence of prior background knowledge.</span>
</span>
</td>
<td id="S4.T1.3.1.4.3.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S4.T1.3.1.4.3.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.1.4.3.5.1.1" class="ltx_p" style="width:142.3pt;">There are chances of unwanted noise that jeopardizes the quality and availability of the model.</span>
</span>
</td>
</tr>
<tr id="S4.T1.3.1.5.4" class="ltx_tr">
<td id="S4.T1.3.1.5.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S4.T1.3.1.5.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.1.5.4.1.1.1" class="ltx_p" style="width:85.4pt;">Anonymization Methods</span>
</span>
</td>
<td id="S4.T1.3.1.5.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S4.T1.3.1.5.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.1.5.4.2.1.1" class="ltx_p" style="width:142.3pt;">Elimination of information that is personally identifiable such as race, gender, or name.</span>
</span>
</td>
<td id="S4.T1.3.1.5.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S4.T1.3.1.5.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.1.5.4.3.1.1" class="ltx_p" style="width:113.8pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>.</span>
</span>
</td>
<td id="S4.T1.3.1.5.4.4" class="ltx_td ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;"></td>
<td id="S4.T1.3.1.5.4.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S4.T1.3.1.5.4.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.1.5.4.5.1.1" class="ltx_p" style="width:142.3pt;">Contains heavy computation and it is difficult to examine which quasi-identifier to use at each site.</span>
</span>
</td>
</tr>
<tr id="S4.T1.3.1.6.5" class="ltx_tr">
<td id="S4.T1.3.1.6.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S4.T1.3.1.6.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.1.6.5.1.1.1" class="ltx_p" style="width:85.4pt;">Hardware-Based Techniques</span>
</span>
</td>
<td id="S4.T1.3.1.6.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S4.T1.3.1.6.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.1.6.5.2.1.1" class="ltx_p" style="width:142.3pt;">In the case of operating system kernel security flaws, hardware-level privacy guarantees or trusted execution environments, such as secure processors can also provide privacy.</span>
</span>
</td>
<td id="S4.T1.3.1.6.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S4.T1.3.1.6.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.1.6.5.3.1.1" class="ltx_p" style="width:113.8pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib232" title="" class="ltx_ref">232</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib208" title="" class="ltx_ref">208</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib225" title="" class="ltx_ref">225</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib207" title="" class="ltx_ref">207</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib231" title="" class="ltx_ref">231</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib127" title="" class="ltx_ref">127</a>]</cite></span>
</span>
</td>
<td id="S4.T1.3.1.6.5.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S4.T1.3.1.6.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.1.6.5.4.1.1" class="ltx_p" style="width:113.8pt;">This technique provides privacy and security in the case of operating system kernel flaws.</span>
</span>
</td>
<td id="S4.T1.3.1.6.5.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S4.T1.3.1.6.5.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.1.6.5.5.1.1" class="ltx_p" style="width:142.3pt;">Highly expensive and difficult setup.</span>
</span>
</td>
</tr>
<tr id="S4.T1.3.1.7.6" class="ltx_tr">
<td id="S4.T1.3.1.7.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S4.T1.3.1.7.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.1.7.6.1.1.1" class="ltx_p" style="width:85.4pt;">Hybrid Privacy-Preserving Techniques</span>
</span>
</td>
<td id="S4.T1.3.1.7.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S4.T1.3.1.7.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.1.7.6.2.1.1" class="ltx_p" style="width:142.3pt;">This technique combines two or more privacy-preserving mechanisms.</span>
</span>
</td>
<td id="S4.T1.3.1.7.6.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S4.T1.3.1.7.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.1.7.6.3.1.1" class="ltx_p" style="width:113.8pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib172" title="" class="ltx_ref">172</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib73" title="" class="ltx_ref">73</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib200" title="" class="ltx_ref">200</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib220" title="" class="ltx_ref">220</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib129" title="" class="ltx_ref">129</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite></span>
</span>
</td>
<td id="S4.T1.3.1.7.6.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S4.T1.3.1.7.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T1.3.1.7.6.4.1.1" class="ltx_p" style="width:113.8pt;">This technique tries to find a perfect balance between computational overhead, security, privacy leakage, etc.</span>
</span>
</td>
<td id="S4.T1.3.1.7.6.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;"></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Privacy Preserving Metrics</span>
</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">The metrics employed to assess the effectiveness of privacy-preserving techniques generally assess the loss of privacy of sensitive data and properties of the models or the dataset. Different methodologies measure privacy in different ways but a single metric might not qualify as the optimal tool for measurement. Aggregating multiple metrics can be useful if the aggregation preserves each metric’s strengths while lowering its inaccuracies. Metrics that assess privacy only based on specific data features, make the assumption that all sorts of adversaries or inference attacks would only rely on these qualities and metrics not considering other types of adversaries implicitly imply a weak adversary. The factors for choosing metrics should be in accordance with the adversary <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib177" title="" class="ltx_ref">177</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib176" title="" class="ltx_ref">176</a>]</cite> states around eighty privacy metrics and provides four categorizations on privacy metrics such as Adversary models, Data sources, Input, and Output. On the other hand, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib163" title="" class="ltx_ref">163</a>]</cite> considers the attacker’s accuracy, uncertainty, and correctness as viable metrics for measuring the loss of privacy in an FL system.
However, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib177" title="" class="ltx_ref">177</a>]</cite> aggregates metrics using techniques such as adding sensitivity ratings, normalizing metrics, and extending measures to new settings. Moreover, to verify the system security and privacy, membership inference attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib134" title="" class="ltx_ref">134</a>]</cite> or gradient inversion attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib68" title="" class="ltx_ref">68</a>]</cite> can be conducted and it can be verified by deducting the attacker’s/adversary’s success ratio. These assaults <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib134" title="" class="ltx_ref">134</a>]</cite> can be carried out in one of two ways: (1) A black-box attack <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib168" title="" class="ltx_ref">168</a>]</cite> is one in which the adversary has access to nothing except the final output model. (2) White-box attack <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib74" title="" class="ltx_ref">74</a>]</cite>: the adversary gets access to every model parameters that were traded during FL.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span><span id="S6.1.1" class="ltx_text ltx_font_smallcaps">Fairness in Federated Learning</span>
</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">To address the privacy challenges and inference attacks raised by traditional machine learning, federated learning works efficiently since it allows for a new implementation of distributed and decentralized private training over a large number of clients. Unlike traditional centralized learning, which gathers all local data samples and develops the model on a central server, federated learning trains local models on local data samples while local clients communicate parameters to construct a global model. However, because of this decentralized nature of Federated Learning and since training data in federated learning is frequently geo-distributed among many organizations, translating solutions for fair training is difficult and the models commonly become biased or unfair towards some protected groups or clients. The performance of a model may differ dramatically between devices due to the heterogeneity of the data in federated networks. If a particular model A is fairer than another model B, then the test performance distribution of model A is more uniform across the network than that of model B <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib97" title="" class="ltx_ref">97</a>]</cite>. In other words, the standard deviation of model A is less than that of B. The existing works on fairness have mainly designed fair machine-learning models in federated learning contexts. Some of the most common approaches attempt to make each client produce fair judgments for people regardless of their protected features such as gender and race, while others try making optimal client selection choices and evaluating client contribution properly. The majority of these efforts have focused mostly on client fairness, which aims to design algorithms that result in models that perform similarly across diverse clients.</p>
</div>
<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1 </span><span id="S6.SS1.1.1" class="ltx_text ltx_font_italic">Causes of Bias in FL</span>
</h3>

<div id="S6.SS1.p1" class="ltx_para">
<p id="S6.SS1.p1.1" class="ltx_p">The following causes exist for bias generation in FL.
<br class="ltx_break"><span id="S6.SS1.p1.1.1" class="ltx_text ltx_font_bold">Conventional Bias Sources.</span>
Generally, local training in an FL system is synonymous with training a model in a traditional ML system. The fundamental drivers of bias <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib79" title="" class="ltx_ref">79</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib80" title="" class="ltx_ref">80</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> in FL systems are also the same for ML, which are underestimation, prejudice, and negative legacy. Since FL involves several training sets, each participant will contribute its parameters (gradients or weights or biases) to the global model via shared model changes, the fairness of the final model is impacted due to the interactions among the clients and the server throughout the training phase. 
<br class="ltx_break"><span id="S6.SS1.p1.1.2" class="ltx_text ltx_font_bold">Sub-Sampling, Party Selection, and Dropouts.</span>
The aggregator queries participants in an FL process at each round of training to deliver their model changes, which the aggregator subsequently incorporates into the global federated model. Modern FL mechanisms do not evenly query all participants. The ability to engage in one round of FL training may be associated with sensitive traits, resulting in unintended bias. If a corporation utilizes cell phone data to train an FL model, network speed might influence whether or not a user’s data is captured, which is connected to socioeconomic status. 
<br class="ltx_break"><span id="S6.SS1.p1.1.3" class="ltx_text ltx_font_bold">Data Heterogeneity.</span>
Data may not always be distributed equally across devices in federated environments and has the potential of generating severe complications. If the training data is not disseminated evenly throughout the clients, i.e. if the data survives in a non-i.i.d. form, the convergence behavior is severely jeopardized. Even when all parties are queried, another difficult but understudied element of FL is that each party’s underlying data may differ. For instance, a branch near a women’s training institution would provide data that was largely made up of women, which would be significantly different from the general composition of the bank’s client information. 
<br class="ltx_break"><span id="S6.SS1.p1.1.4" class="ltx_text ltx_font_bold">Fusion Methodologies.</span>
An aggregator uses a method prescribed by a fusion algorithm to combine local model updates into the global federated model. Depending on whether the aggregator achieves an equal or weighted average, the fusion techniques employed by the aggregator to merge the parties’ model updates may introduce bias. FL methods may weigh heavier contributions for populations with more data i.e., heavy consumers of certain items, increasing the effects of over/under-representing specific groups in a dataset. 
<br class="ltx_break"><span id="S6.SS1.p1.1.5" class="ltx_text ltx_font_bold">Systems Heterogeneity.</span>
If models differ in terms of resource limits in federated contexts, unforeseen issues may occur. The battery power, network connectivity, hardware, and desire to participate in devices may vary. Furthermore, in FL, parties may be capable of dynamic participation, which allows them to drop out of an FL process and return later for a variety of reasons, such as connection constraints. As a result, the relative and overall data composition may be continually changing, affecting how the global model learns the bias.</p>
</div>
</section>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span><span id="S7.1.1" class="ltx_text ltx_font_smallcaps">Recent Works in FL-Fairness</span>
</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">In this section, we cover notable papers on fairness in the context of traditional Machine Learning, followed by a discussion of constructing fair models inside an FL framework. The several types of fairness in an FL system include:
<br class="ltx_break"><span id="S7.p1.1.1" class="ltx_text ltx_font_bold">Performance Fairness.</span>
Performance fairness aims to achieve equal accuracy distribution across participants. Various notions of fairness such as Accuracy Parity are based on this concept of fairness.
<br class="ltx_break"><span id="S7.p1.1.2" class="ltx_text ltx_font_bold">Collaboration Fairness.</span>
Collaboration fairness focuses on giving greater rewards/incentives to individuals with greater contributions. Notions of fairness such as Contribution Fairness aim to balance between Privacy-Preservation, Fairness, and Accuracy.
<br class="ltx_break"><span id="S7.p1.1.3" class="ltx_text ltx_font_bold">Model Fairness.</span> Model fairness aims at the protection of some specific characteristics while maintaining the perfect balance between accuracy and privacy preservation using FL. It helps to achieve overall model fairness despite having some unrepresented demographic groups (based on race, gender, class, etc).</p>
</div>
<div id="S7.p2" class="ltx_para">
<p id="S7.p2.1" class="ltx_p">Apparently, FL has focused on fitting a single global model <math id="S7.p2.1.m1.1" class="ltx_Math" alttext="m" display="inline"><semantics id="S7.p2.1.m1.1a"><mi id="S7.p2.1.m1.1.1" xref="S7.p2.1.m1.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S7.p2.1.m1.1b"><ci id="S7.p2.1.m1.1.1.cmml" xref="S7.p2.1.m1.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.p2.1.m1.1c">m</annotation></semantics></math>, to all local data in the network. The global objective is to solve the following equation:</p>
</div>
<div id="S7.p3" class="ltx_para">
<table id="S7.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S7.E1.m1.5" class="ltx_Math" alttext="\min_{m}\&gt;G(L_{1}(m),\&gt;L_{2}(m),\&gt;L_{3}(m)...\&gt;L_{N}(m))," display="block"><semantics id="S7.E1.m1.5a"><mrow id="S7.E1.m1.5.5.1" xref="S7.E1.m1.5.5.1.1.cmml"><mrow id="S7.E1.m1.5.5.1.1" xref="S7.E1.m1.5.5.1.1.cmml"><mrow id="S7.E1.m1.5.5.1.1.5" xref="S7.E1.m1.5.5.1.1.5.cmml"><munder id="S7.E1.m1.5.5.1.1.5.1" xref="S7.E1.m1.5.5.1.1.5.1.cmml"><mi id="S7.E1.m1.5.5.1.1.5.1.2" xref="S7.E1.m1.5.5.1.1.5.1.2.cmml">min</mi><mi id="S7.E1.m1.5.5.1.1.5.1.3" xref="S7.E1.m1.5.5.1.1.5.1.3.cmml">m</mi></munder><mo lspace="0.387em" id="S7.E1.m1.5.5.1.1.5a" xref="S7.E1.m1.5.5.1.1.5.cmml">⁡</mo><mi id="S7.E1.m1.5.5.1.1.5.2" xref="S7.E1.m1.5.5.1.1.5.2.cmml">G</mi></mrow><mo lspace="0em" rspace="0em" id="S7.E1.m1.5.5.1.1.4" xref="S7.E1.m1.5.5.1.1.4.cmml">​</mo><mrow id="S7.E1.m1.5.5.1.1.3.3" xref="S7.E1.m1.5.5.1.1.3.4.cmml"><mo stretchy="false" id="S7.E1.m1.5.5.1.1.3.3.4" xref="S7.E1.m1.5.5.1.1.3.4.cmml">(</mo><mrow id="S7.E1.m1.5.5.1.1.1.1.1" xref="S7.E1.m1.5.5.1.1.1.1.1.cmml"><msub id="S7.E1.m1.5.5.1.1.1.1.1.2" xref="S7.E1.m1.5.5.1.1.1.1.1.2.cmml"><mi id="S7.E1.m1.5.5.1.1.1.1.1.2.2" xref="S7.E1.m1.5.5.1.1.1.1.1.2.2.cmml">L</mi><mn id="S7.E1.m1.5.5.1.1.1.1.1.2.3" xref="S7.E1.m1.5.5.1.1.1.1.1.2.3.cmml">1</mn></msub><mo lspace="0em" rspace="0em" id="S7.E1.m1.5.5.1.1.1.1.1.1" xref="S7.E1.m1.5.5.1.1.1.1.1.1.cmml">​</mo><mrow id="S7.E1.m1.5.5.1.1.1.1.1.3.2" xref="S7.E1.m1.5.5.1.1.1.1.1.cmml"><mo stretchy="false" id="S7.E1.m1.5.5.1.1.1.1.1.3.2.1" xref="S7.E1.m1.5.5.1.1.1.1.1.cmml">(</mo><mi id="S7.E1.m1.1.1" xref="S7.E1.m1.1.1.cmml">m</mi><mo stretchy="false" id="S7.E1.m1.5.5.1.1.1.1.1.3.2.2" xref="S7.E1.m1.5.5.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo rspace="0.387em" id="S7.E1.m1.5.5.1.1.3.3.5" xref="S7.E1.m1.5.5.1.1.3.4.cmml">,</mo><mrow id="S7.E1.m1.5.5.1.1.2.2.2" xref="S7.E1.m1.5.5.1.1.2.2.2.cmml"><msub id="S7.E1.m1.5.5.1.1.2.2.2.2" xref="S7.E1.m1.5.5.1.1.2.2.2.2.cmml"><mi id="S7.E1.m1.5.5.1.1.2.2.2.2.2" xref="S7.E1.m1.5.5.1.1.2.2.2.2.2.cmml">L</mi><mn id="S7.E1.m1.5.5.1.1.2.2.2.2.3" xref="S7.E1.m1.5.5.1.1.2.2.2.2.3.cmml">2</mn></msub><mo lspace="0em" rspace="0em" id="S7.E1.m1.5.5.1.1.2.2.2.1" xref="S7.E1.m1.5.5.1.1.2.2.2.1.cmml">​</mo><mrow id="S7.E1.m1.5.5.1.1.2.2.2.3.2" xref="S7.E1.m1.5.5.1.1.2.2.2.cmml"><mo stretchy="false" id="S7.E1.m1.5.5.1.1.2.2.2.3.2.1" xref="S7.E1.m1.5.5.1.1.2.2.2.cmml">(</mo><mi id="S7.E1.m1.2.2" xref="S7.E1.m1.2.2.cmml">m</mi><mo stretchy="false" id="S7.E1.m1.5.5.1.1.2.2.2.3.2.2" xref="S7.E1.m1.5.5.1.1.2.2.2.cmml">)</mo></mrow></mrow><mo rspace="0.387em" id="S7.E1.m1.5.5.1.1.3.3.6" xref="S7.E1.m1.5.5.1.1.3.4.cmml">,</mo><mrow id="S7.E1.m1.5.5.1.1.3.3.3" xref="S7.E1.m1.5.5.1.1.3.3.3.cmml"><msub id="S7.E1.m1.5.5.1.1.3.3.3.2" xref="S7.E1.m1.5.5.1.1.3.3.3.2.cmml"><mi id="S7.E1.m1.5.5.1.1.3.3.3.2.2" xref="S7.E1.m1.5.5.1.1.3.3.3.2.2.cmml">L</mi><mn id="S7.E1.m1.5.5.1.1.3.3.3.2.3" xref="S7.E1.m1.5.5.1.1.3.3.3.2.3.cmml">3</mn></msub><mo lspace="0em" rspace="0em" id="S7.E1.m1.5.5.1.1.3.3.3.1" xref="S7.E1.m1.5.5.1.1.3.3.3.1.cmml">​</mo><mrow id="S7.E1.m1.5.5.1.1.3.3.3.3.2" xref="S7.E1.m1.5.5.1.1.3.3.3.cmml"><mo stretchy="false" id="S7.E1.m1.5.5.1.1.3.3.3.3.2.1" xref="S7.E1.m1.5.5.1.1.3.3.3.cmml">(</mo><mi id="S7.E1.m1.3.3" xref="S7.E1.m1.3.3.cmml">m</mi><mo stretchy="false" id="S7.E1.m1.5.5.1.1.3.3.3.3.2.2" xref="S7.E1.m1.5.5.1.1.3.3.3.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S7.E1.m1.5.5.1.1.3.3.3.1a" xref="S7.E1.m1.5.5.1.1.3.3.3.1.cmml">​</mo><mi mathvariant="normal" id="S7.E1.m1.5.5.1.1.3.3.3.4" xref="S7.E1.m1.5.5.1.1.3.3.3.4.cmml">…</mi><mo lspace="0.220em" rspace="0em" id="S7.E1.m1.5.5.1.1.3.3.3.1b" xref="S7.E1.m1.5.5.1.1.3.3.3.1.cmml">​</mo><msub id="S7.E1.m1.5.5.1.1.3.3.3.5" xref="S7.E1.m1.5.5.1.1.3.3.3.5.cmml"><mi id="S7.E1.m1.5.5.1.1.3.3.3.5.2" xref="S7.E1.m1.5.5.1.1.3.3.3.5.2.cmml">L</mi><mi id="S7.E1.m1.5.5.1.1.3.3.3.5.3" xref="S7.E1.m1.5.5.1.1.3.3.3.5.3.cmml">N</mi></msub><mo lspace="0em" rspace="0em" id="S7.E1.m1.5.5.1.1.3.3.3.1c" xref="S7.E1.m1.5.5.1.1.3.3.3.1.cmml">​</mo><mrow id="S7.E1.m1.5.5.1.1.3.3.3.6.2" xref="S7.E1.m1.5.5.1.1.3.3.3.cmml"><mo stretchy="false" id="S7.E1.m1.5.5.1.1.3.3.3.6.2.1" xref="S7.E1.m1.5.5.1.1.3.3.3.cmml">(</mo><mi id="S7.E1.m1.4.4" xref="S7.E1.m1.4.4.cmml">m</mi><mo stretchy="false" id="S7.E1.m1.5.5.1.1.3.3.3.6.2.2" xref="S7.E1.m1.5.5.1.1.3.3.3.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S7.E1.m1.5.5.1.1.3.3.7" xref="S7.E1.m1.5.5.1.1.3.4.cmml">)</mo></mrow></mrow><mo id="S7.E1.m1.5.5.1.2" xref="S7.E1.m1.5.5.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S7.E1.m1.5b"><apply id="S7.E1.m1.5.5.1.1.cmml" xref="S7.E1.m1.5.5.1"><times id="S7.E1.m1.5.5.1.1.4.cmml" xref="S7.E1.m1.5.5.1.1.4"></times><apply id="S7.E1.m1.5.5.1.1.5.cmml" xref="S7.E1.m1.5.5.1.1.5"><apply id="S7.E1.m1.5.5.1.1.5.1.cmml" xref="S7.E1.m1.5.5.1.1.5.1"><csymbol cd="ambiguous" id="S7.E1.m1.5.5.1.1.5.1.1.cmml" xref="S7.E1.m1.5.5.1.1.5.1">subscript</csymbol><min id="S7.E1.m1.5.5.1.1.5.1.2.cmml" xref="S7.E1.m1.5.5.1.1.5.1.2"></min><ci id="S7.E1.m1.5.5.1.1.5.1.3.cmml" xref="S7.E1.m1.5.5.1.1.5.1.3">𝑚</ci></apply><ci id="S7.E1.m1.5.5.1.1.5.2.cmml" xref="S7.E1.m1.5.5.1.1.5.2">𝐺</ci></apply><vector id="S7.E1.m1.5.5.1.1.3.4.cmml" xref="S7.E1.m1.5.5.1.1.3.3"><apply id="S7.E1.m1.5.5.1.1.1.1.1.cmml" xref="S7.E1.m1.5.5.1.1.1.1.1"><times id="S7.E1.m1.5.5.1.1.1.1.1.1.cmml" xref="S7.E1.m1.5.5.1.1.1.1.1.1"></times><apply id="S7.E1.m1.5.5.1.1.1.1.1.2.cmml" xref="S7.E1.m1.5.5.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S7.E1.m1.5.5.1.1.1.1.1.2.1.cmml" xref="S7.E1.m1.5.5.1.1.1.1.1.2">subscript</csymbol><ci id="S7.E1.m1.5.5.1.1.1.1.1.2.2.cmml" xref="S7.E1.m1.5.5.1.1.1.1.1.2.2">𝐿</ci><cn type="integer" id="S7.E1.m1.5.5.1.1.1.1.1.2.3.cmml" xref="S7.E1.m1.5.5.1.1.1.1.1.2.3">1</cn></apply><ci id="S7.E1.m1.1.1.cmml" xref="S7.E1.m1.1.1">𝑚</ci></apply><apply id="S7.E1.m1.5.5.1.1.2.2.2.cmml" xref="S7.E1.m1.5.5.1.1.2.2.2"><times id="S7.E1.m1.5.5.1.1.2.2.2.1.cmml" xref="S7.E1.m1.5.5.1.1.2.2.2.1"></times><apply id="S7.E1.m1.5.5.1.1.2.2.2.2.cmml" xref="S7.E1.m1.5.5.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S7.E1.m1.5.5.1.1.2.2.2.2.1.cmml" xref="S7.E1.m1.5.5.1.1.2.2.2.2">subscript</csymbol><ci id="S7.E1.m1.5.5.1.1.2.2.2.2.2.cmml" xref="S7.E1.m1.5.5.1.1.2.2.2.2.2">𝐿</ci><cn type="integer" id="S7.E1.m1.5.5.1.1.2.2.2.2.3.cmml" xref="S7.E1.m1.5.5.1.1.2.2.2.2.3">2</cn></apply><ci id="S7.E1.m1.2.2.cmml" xref="S7.E1.m1.2.2">𝑚</ci></apply><apply id="S7.E1.m1.5.5.1.1.3.3.3.cmml" xref="S7.E1.m1.5.5.1.1.3.3.3"><times id="S7.E1.m1.5.5.1.1.3.3.3.1.cmml" xref="S7.E1.m1.5.5.1.1.3.3.3.1"></times><apply id="S7.E1.m1.5.5.1.1.3.3.3.2.cmml" xref="S7.E1.m1.5.5.1.1.3.3.3.2"><csymbol cd="ambiguous" id="S7.E1.m1.5.5.1.1.3.3.3.2.1.cmml" xref="S7.E1.m1.5.5.1.1.3.3.3.2">subscript</csymbol><ci id="S7.E1.m1.5.5.1.1.3.3.3.2.2.cmml" xref="S7.E1.m1.5.5.1.1.3.3.3.2.2">𝐿</ci><cn type="integer" id="S7.E1.m1.5.5.1.1.3.3.3.2.3.cmml" xref="S7.E1.m1.5.5.1.1.3.3.3.2.3">3</cn></apply><ci id="S7.E1.m1.3.3.cmml" xref="S7.E1.m1.3.3">𝑚</ci><ci id="S7.E1.m1.5.5.1.1.3.3.3.4.cmml" xref="S7.E1.m1.5.5.1.1.3.3.3.4">…</ci><apply id="S7.E1.m1.5.5.1.1.3.3.3.5.cmml" xref="S7.E1.m1.5.5.1.1.3.3.3.5"><csymbol cd="ambiguous" id="S7.E1.m1.5.5.1.1.3.3.3.5.1.cmml" xref="S7.E1.m1.5.5.1.1.3.3.3.5">subscript</csymbol><ci id="S7.E1.m1.5.5.1.1.3.3.3.5.2.cmml" xref="S7.E1.m1.5.5.1.1.3.3.3.5.2">𝐿</ci><ci id="S7.E1.m1.5.5.1.1.3.3.3.5.3.cmml" xref="S7.E1.m1.5.5.1.1.3.3.3.5.3">𝑁</ci></apply><ci id="S7.E1.m1.4.4.cmml" xref="S7.E1.m1.4.4">𝑚</ci></apply></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.E1.m1.5c">\min_{m}\&gt;G(L_{1}(m),\&gt;L_{2}(m),\&gt;L_{3}(m)...\&gt;L_{N}(m)),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S7.p3.4" class="ltx_p">Here <math id="S7.p3.1.m1.1" class="ltx_Math" alttext="L_{n}(m)" display="inline"><semantics id="S7.p3.1.m1.1a"><mrow id="S7.p3.1.m1.1.2" xref="S7.p3.1.m1.1.2.cmml"><msub id="S7.p3.1.m1.1.2.2" xref="S7.p3.1.m1.1.2.2.cmml"><mi id="S7.p3.1.m1.1.2.2.2" xref="S7.p3.1.m1.1.2.2.2.cmml">L</mi><mi id="S7.p3.1.m1.1.2.2.3" xref="S7.p3.1.m1.1.2.2.3.cmml">n</mi></msub><mo lspace="0em" rspace="0em" id="S7.p3.1.m1.1.2.1" xref="S7.p3.1.m1.1.2.1.cmml">​</mo><mrow id="S7.p3.1.m1.1.2.3.2" xref="S7.p3.1.m1.1.2.cmml"><mo stretchy="false" id="S7.p3.1.m1.1.2.3.2.1" xref="S7.p3.1.m1.1.2.cmml">(</mo><mi id="S7.p3.1.m1.1.1" xref="S7.p3.1.m1.1.1.cmml">m</mi><mo stretchy="false" id="S7.p3.1.m1.1.2.3.2.2" xref="S7.p3.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S7.p3.1.m1.1b"><apply id="S7.p3.1.m1.1.2.cmml" xref="S7.p3.1.m1.1.2"><times id="S7.p3.1.m1.1.2.1.cmml" xref="S7.p3.1.m1.1.2.1"></times><apply id="S7.p3.1.m1.1.2.2.cmml" xref="S7.p3.1.m1.1.2.2"><csymbol cd="ambiguous" id="S7.p3.1.m1.1.2.2.1.cmml" xref="S7.p3.1.m1.1.2.2">subscript</csymbol><ci id="S7.p3.1.m1.1.2.2.2.cmml" xref="S7.p3.1.m1.1.2.2.2">𝐿</ci><ci id="S7.p3.1.m1.1.2.2.3.cmml" xref="S7.p3.1.m1.1.2.2.3">𝑛</ci></apply><ci id="S7.p3.1.m1.1.1.cmml" xref="S7.p3.1.m1.1.1">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.p3.1.m1.1c">L_{n}(m)</annotation></semantics></math> stands for the individual or local objective for device n and <math id="S7.p3.2.m2.1" class="ltx_Math" alttext="G(\cdot)" display="inline"><semantics id="S7.p3.2.m2.1a"><mrow id="S7.p3.2.m2.1.2" xref="S7.p3.2.m2.1.2.cmml"><mi id="S7.p3.2.m2.1.2.2" xref="S7.p3.2.m2.1.2.2.cmml">G</mi><mo lspace="0em" rspace="0em" id="S7.p3.2.m2.1.2.1" xref="S7.p3.2.m2.1.2.1.cmml">​</mo><mrow id="S7.p3.2.m2.1.2.3.2" xref="S7.p3.2.m2.1.2.cmml"><mo stretchy="false" id="S7.p3.2.m2.1.2.3.2.1" xref="S7.p3.2.m2.1.2.cmml">(</mo><mo lspace="0em" rspace="0em" id="S7.p3.2.m2.1.1" xref="S7.p3.2.m2.1.1.cmml">⋅</mo><mo stretchy="false" id="S7.p3.2.m2.1.2.3.2.2" xref="S7.p3.2.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S7.p3.2.m2.1b"><apply id="S7.p3.2.m2.1.2.cmml" xref="S7.p3.2.m2.1.2"><times id="S7.p3.2.m2.1.2.1.cmml" xref="S7.p3.2.m2.1.2.1"></times><ci id="S7.p3.2.m2.1.2.2.cmml" xref="S7.p3.2.m2.1.2.2">𝐺</ci><ci id="S7.p3.2.m2.1.1.cmml" xref="S7.p3.2.m2.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.p3.2.m2.1c">G(\cdot)</annotation></semantics></math> refers to the global model objective that aggregates the local goals from each device. <math id="S7.p3.3.m3.1" class="ltx_Math" alttext="G(\cdot)" display="inline"><semantics id="S7.p3.3.m3.1a"><mrow id="S7.p3.3.m3.1.2" xref="S7.p3.3.m3.1.2.cmml"><mi id="S7.p3.3.m3.1.2.2" xref="S7.p3.3.m3.1.2.2.cmml">G</mi><mo lspace="0em" rspace="0em" id="S7.p3.3.m3.1.2.1" xref="S7.p3.3.m3.1.2.1.cmml">​</mo><mrow id="S7.p3.3.m3.1.2.3.2" xref="S7.p3.3.m3.1.2.cmml"><mo stretchy="false" id="S7.p3.3.m3.1.2.3.2.1" xref="S7.p3.3.m3.1.2.cmml">(</mo><mo lspace="0em" rspace="0em" id="S7.p3.3.m3.1.1" xref="S7.p3.3.m3.1.1.cmml">⋅</mo><mo stretchy="false" id="S7.p3.3.m3.1.2.3.2.2" xref="S7.p3.3.m3.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S7.p3.3.m3.1b"><apply id="S7.p3.3.m3.1.2.cmml" xref="S7.p3.3.m3.1.2"><times id="S7.p3.3.m3.1.2.1.cmml" xref="S7.p3.3.m3.1.2.1"></times><ci id="S7.p3.3.m3.1.2.2.cmml" xref="S7.p3.3.m3.1.2.2">𝐺</ci><ci id="S7.p3.3.m3.1.1.cmml" xref="S7.p3.3.m3.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.p3.3.m3.1c">G(\cdot)</annotation></semantics></math> is commonly specified in FedAvg <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib122" title="" class="ltx_ref">122</a>]</cite> as the weighted average of all the individual or local client losses, i.e., <math id="S7.p3.4.m4.1" class="ltx_Math" alttext="\displaystyle\sum\limits_{n=1}^{N}f_{n}L_{n}(m)" display="inline"><semantics id="S7.p3.4.m4.1a"><mrow id="S7.p3.4.m4.1.2" xref="S7.p3.4.m4.1.2.cmml"><mstyle displaystyle="true" id="S7.p3.4.m4.1.2.1" xref="S7.p3.4.m4.1.2.1.cmml"><munderover id="S7.p3.4.m4.1.2.1a" xref="S7.p3.4.m4.1.2.1.cmml"><mo movablelimits="false" id="S7.p3.4.m4.1.2.1.2.2" xref="S7.p3.4.m4.1.2.1.2.2.cmml">∑</mo><mrow id="S7.p3.4.m4.1.2.1.2.3" xref="S7.p3.4.m4.1.2.1.2.3.cmml"><mi id="S7.p3.4.m4.1.2.1.2.3.2" xref="S7.p3.4.m4.1.2.1.2.3.2.cmml">n</mi><mo id="S7.p3.4.m4.1.2.1.2.3.1" xref="S7.p3.4.m4.1.2.1.2.3.1.cmml">=</mo><mn id="S7.p3.4.m4.1.2.1.2.3.3" xref="S7.p3.4.m4.1.2.1.2.3.3.cmml">1</mn></mrow><mi id="S7.p3.4.m4.1.2.1.3" xref="S7.p3.4.m4.1.2.1.3.cmml">N</mi></munderover></mstyle><mrow id="S7.p3.4.m4.1.2.2" xref="S7.p3.4.m4.1.2.2.cmml"><msub id="S7.p3.4.m4.1.2.2.2" xref="S7.p3.4.m4.1.2.2.2.cmml"><mi id="S7.p3.4.m4.1.2.2.2.2" xref="S7.p3.4.m4.1.2.2.2.2.cmml">f</mi><mi id="S7.p3.4.m4.1.2.2.2.3" xref="S7.p3.4.m4.1.2.2.2.3.cmml">n</mi></msub><mo lspace="0em" rspace="0em" id="S7.p3.4.m4.1.2.2.1" xref="S7.p3.4.m4.1.2.2.1.cmml">​</mo><msub id="S7.p3.4.m4.1.2.2.3" xref="S7.p3.4.m4.1.2.2.3.cmml"><mi id="S7.p3.4.m4.1.2.2.3.2" xref="S7.p3.4.m4.1.2.2.3.2.cmml">L</mi><mi id="S7.p3.4.m4.1.2.2.3.3" xref="S7.p3.4.m4.1.2.2.3.3.cmml">n</mi></msub><mo lspace="0em" rspace="0em" id="S7.p3.4.m4.1.2.2.1a" xref="S7.p3.4.m4.1.2.2.1.cmml">​</mo><mrow id="S7.p3.4.m4.1.2.2.4.2" xref="S7.p3.4.m4.1.2.2.cmml"><mo stretchy="false" id="S7.p3.4.m4.1.2.2.4.2.1" xref="S7.p3.4.m4.1.2.2.cmml">(</mo><mi id="S7.p3.4.m4.1.1" xref="S7.p3.4.m4.1.1.cmml">m</mi><mo stretchy="false" id="S7.p3.4.m4.1.2.2.4.2.2" xref="S7.p3.4.m4.1.2.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S7.p3.4.m4.1b"><apply id="S7.p3.4.m4.1.2.cmml" xref="S7.p3.4.m4.1.2"><apply id="S7.p3.4.m4.1.2.1.cmml" xref="S7.p3.4.m4.1.2.1"><csymbol cd="ambiguous" id="S7.p3.4.m4.1.2.1.1.cmml" xref="S7.p3.4.m4.1.2.1">superscript</csymbol><apply id="S7.p3.4.m4.1.2.1.2.cmml" xref="S7.p3.4.m4.1.2.1"><csymbol cd="ambiguous" id="S7.p3.4.m4.1.2.1.2.1.cmml" xref="S7.p3.4.m4.1.2.1">subscript</csymbol><sum id="S7.p3.4.m4.1.2.1.2.2.cmml" xref="S7.p3.4.m4.1.2.1.2.2"></sum><apply id="S7.p3.4.m4.1.2.1.2.3.cmml" xref="S7.p3.4.m4.1.2.1.2.3"><eq id="S7.p3.4.m4.1.2.1.2.3.1.cmml" xref="S7.p3.4.m4.1.2.1.2.3.1"></eq><ci id="S7.p3.4.m4.1.2.1.2.3.2.cmml" xref="S7.p3.4.m4.1.2.1.2.3.2">𝑛</ci><cn type="integer" id="S7.p3.4.m4.1.2.1.2.3.3.cmml" xref="S7.p3.4.m4.1.2.1.2.3.3">1</cn></apply></apply><ci id="S7.p3.4.m4.1.2.1.3.cmml" xref="S7.p3.4.m4.1.2.1.3">𝑁</ci></apply><apply id="S7.p3.4.m4.1.2.2.cmml" xref="S7.p3.4.m4.1.2.2"><times id="S7.p3.4.m4.1.2.2.1.cmml" xref="S7.p3.4.m4.1.2.2.1"></times><apply id="S7.p3.4.m4.1.2.2.2.cmml" xref="S7.p3.4.m4.1.2.2.2"><csymbol cd="ambiguous" id="S7.p3.4.m4.1.2.2.2.1.cmml" xref="S7.p3.4.m4.1.2.2.2">subscript</csymbol><ci id="S7.p3.4.m4.1.2.2.2.2.cmml" xref="S7.p3.4.m4.1.2.2.2.2">𝑓</ci><ci id="S7.p3.4.m4.1.2.2.2.3.cmml" xref="S7.p3.4.m4.1.2.2.2.3">𝑛</ci></apply><apply id="S7.p3.4.m4.1.2.2.3.cmml" xref="S7.p3.4.m4.1.2.2.3"><csymbol cd="ambiguous" id="S7.p3.4.m4.1.2.2.3.1.cmml" xref="S7.p3.4.m4.1.2.2.3">subscript</csymbol><ci id="S7.p3.4.m4.1.2.2.3.2.cmml" xref="S7.p3.4.m4.1.2.2.3.2">𝐿</ci><ci id="S7.p3.4.m4.1.2.2.3.3.cmml" xref="S7.p3.4.m4.1.2.2.3.3">𝑛</ci></apply><ci id="S7.p3.4.m4.1.1.cmml" xref="S7.p3.4.m4.1.1">𝑚</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.p3.4.m4.1c">\displaystyle\sum\limits_{n=1}^{N}f_{n}L_{n}(m)</annotation></semantics></math>,</p>
</div>
<div id="S7.p4" class="ltx_para">
<p id="S7.p4.2" class="ltx_p">Here <math id="S7.p4.1.m1.1" class="ltx_Math" alttext="f_{n}" display="inline"><semantics id="S7.p4.1.m1.1a"><msub id="S7.p4.1.m1.1.1" xref="S7.p4.1.m1.1.1.cmml"><mi id="S7.p4.1.m1.1.1.2" xref="S7.p4.1.m1.1.1.2.cmml">f</mi><mi id="S7.p4.1.m1.1.1.3" xref="S7.p4.1.m1.1.1.3.cmml">n</mi></msub><annotation-xml encoding="MathML-Content" id="S7.p4.1.m1.1b"><apply id="S7.p4.1.m1.1.1.cmml" xref="S7.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S7.p4.1.m1.1.1.1.cmml" xref="S7.p4.1.m1.1.1">subscript</csymbol><ci id="S7.p4.1.m1.1.1.2.cmml" xref="S7.p4.1.m1.1.1.2">𝑓</ci><ci id="S7.p4.1.m1.1.1.3.cmml" xref="S7.p4.1.m1.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.p4.1.m1.1c">f_{n}</annotation></semantics></math> is a positive weight so that <math id="S7.p4.2.m2.1" class="ltx_Math" alttext="\displaystyle\sum n\&gt;f_{n}(w)=1" display="inline"><semantics id="S7.p4.2.m2.1a"><mrow id="S7.p4.2.m2.1.2" xref="S7.p4.2.m2.1.2.cmml"><mstyle displaystyle="true" id="S7.p4.2.m2.1.2.2" xref="S7.p4.2.m2.1.2.2.cmml"><mrow id="S7.p4.2.m2.1.2.2a" xref="S7.p4.2.m2.1.2.2.cmml"><mo movablelimits="false" id="S7.p4.2.m2.1.2.2.1" xref="S7.p4.2.m2.1.2.2.1.cmml">∑</mo><mrow id="S7.p4.2.m2.1.2.2.2" xref="S7.p4.2.m2.1.2.2.2.cmml"><mi id="S7.p4.2.m2.1.2.2.2.2" xref="S7.p4.2.m2.1.2.2.2.2.cmml">n</mi><mo lspace="0.220em" rspace="0em" id="S7.p4.2.m2.1.2.2.2.1" xref="S7.p4.2.m2.1.2.2.2.1.cmml">​</mo><msub id="S7.p4.2.m2.1.2.2.2.3" xref="S7.p4.2.m2.1.2.2.2.3.cmml"><mi id="S7.p4.2.m2.1.2.2.2.3.2" xref="S7.p4.2.m2.1.2.2.2.3.2.cmml">f</mi><mi id="S7.p4.2.m2.1.2.2.2.3.3" xref="S7.p4.2.m2.1.2.2.2.3.3.cmml">n</mi></msub><mo lspace="0em" rspace="0em" id="S7.p4.2.m2.1.2.2.2.1a" xref="S7.p4.2.m2.1.2.2.2.1.cmml">​</mo><mrow id="S7.p4.2.m2.1.2.2.2.4.2" xref="S7.p4.2.m2.1.2.2.2.cmml"><mo stretchy="false" id="S7.p4.2.m2.1.2.2.2.4.2.1" xref="S7.p4.2.m2.1.2.2.2.cmml">(</mo><mi id="S7.p4.2.m2.1.1" xref="S7.p4.2.m2.1.1.cmml">w</mi><mo stretchy="false" id="S7.p4.2.m2.1.2.2.2.4.2.2" xref="S7.p4.2.m2.1.2.2.2.cmml">)</mo></mrow></mrow></mrow></mstyle><mo id="S7.p4.2.m2.1.2.1" xref="S7.p4.2.m2.1.2.1.cmml">=</mo><mn id="S7.p4.2.m2.1.2.3" xref="S7.p4.2.m2.1.2.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S7.p4.2.m2.1b"><apply id="S7.p4.2.m2.1.2.cmml" xref="S7.p4.2.m2.1.2"><eq id="S7.p4.2.m2.1.2.1.cmml" xref="S7.p4.2.m2.1.2.1"></eq><apply id="S7.p4.2.m2.1.2.2.cmml" xref="S7.p4.2.m2.1.2.2"><sum id="S7.p4.2.m2.1.2.2.1.cmml" xref="S7.p4.2.m2.1.2.2.1"></sum><apply id="S7.p4.2.m2.1.2.2.2.cmml" xref="S7.p4.2.m2.1.2.2.2"><times id="S7.p4.2.m2.1.2.2.2.1.cmml" xref="S7.p4.2.m2.1.2.2.2.1"></times><ci id="S7.p4.2.m2.1.2.2.2.2.cmml" xref="S7.p4.2.m2.1.2.2.2.2">𝑛</ci><apply id="S7.p4.2.m2.1.2.2.2.3.cmml" xref="S7.p4.2.m2.1.2.2.2.3"><csymbol cd="ambiguous" id="S7.p4.2.m2.1.2.2.2.3.1.cmml" xref="S7.p4.2.m2.1.2.2.2.3">subscript</csymbol><ci id="S7.p4.2.m2.1.2.2.2.3.2.cmml" xref="S7.p4.2.m2.1.2.2.2.3.2">𝑓</ci><ci id="S7.p4.2.m2.1.2.2.2.3.3.cmml" xref="S7.p4.2.m2.1.2.2.2.3.3">𝑛</ci></apply><ci id="S7.p4.2.m2.1.1.cmml" xref="S7.p4.2.m2.1.1">𝑤</ci></apply></apply><cn type="integer" id="S7.p4.2.m2.1.2.3.cmml" xref="S7.p4.2.m2.1.2.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.p4.2.m2.1c">\displaystyle\sum n\&gt;f_{n}(w)=1</annotation></semantics></math>.</p>
</div>
<section id="S7.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.1 </span><span id="S7.SS1.1.1" class="ltx_text ltx_font_italic">Fairness Challenges in Horizontal and Vertical Federated Settings</span>
</h3>

<div id="S7.SS1.p1" class="ltx_para">
<p id="S7.SS1.p1.1" class="ltx_p"><span id="S7.SS1.p1.1.1" class="ltx_text ltx_font_bold">Conflict Between Fair Model Training and FL.</span> Due to the conflicting inherent notions behind FL and fair model training, horizontal federated fair model training is difficult. For performing fair model training, getting access to all parties’ data and all the samples is necessary in order to accurately assess a model’s fairness. In contrast, Federated Learning requires that any access to any party’s private data should be prohibited in order to protect data privacy. Likewise, in Vertical Federated Learning, features are distributed among clients. To properly assess the fair model training, performance over all the features is mandatory but this violates the main idea of VFL. 
<br class="ltx_break"><span id="S7.SS1.p1.1.2" class="ltx_text ltx_font_bold">Lack of Appropriate Fairness Measurement.</span>
No well-defined fairness measurement has been developed for Horizontal Federated Learning. Access to all the data is needed for other fairness measuring techniques in ML, which is not possible in horizontal FL. 
<br class="ltx_break"><span id="S7.SS1.p1.1.3" class="ltx_text ltx_font_bold">Problem with Local Fairness Estimation.</span>
In HFL, implementing fairness requirements locally on each client would result in worse fairness performance or null solutions due to erroneous model fairness measurements derived locally and the consequent conflicts between local fairness constraints. In VFL, model fairness cannot be measured for (passive) clients who are unaware of the protected property. Measuring model fairness for (active) customers that know the protected characteristic results in poor fairness and accuracy owing to a lack of features. 
<br class="ltx_break"><span id="S7.SS1.p1.1.4" class="ltx_text ltx_font_bold">Unfairness Towards Groups.</span> In VFL, the final model might be unfairly biased against groups possessing sensitive attributes since one or parts of the active clients may end up protected attributes.
<br class="ltx_break"><span id="S7.SS1.p1.1.5" class="ltx_text ltx_font_bold">Imbalanced Processing Resources.</span> During the training process of a fair model in VFL, performance issues arise when enforcing every member to produce a single local update per communication round. There exists a lack of synchronization as different members may update in different time frames. The training process becomes increasingly difficult by the uneven distribution of processing resources among clients with varying attributes.</p>
</div>
<figure id="S7.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE II: </span><span id="S7.T2.2.1" class="ltx_text ltx_font_bold">Comparison Between Existing Works Focusing on Privacy in FL˙</span></figcaption>
<div id="S7.T2.3" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:369.0pt;height:290pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-20.5pt,16.1pt) scale(0.9,0.9) ;">
<table id="S7.T2.3.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S7.T2.3.1.1.1" class="ltx_tr">
<th id="S7.T2.3.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.1.1.1.1.1" class="ltx_p" style="width:54.1pt;"><span id="S7.T2.3.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">References</span></span>
</span>
</th>
<th id="S7.T2.3.1.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.1.1.2.1.1" class="ltx_p" style="width:85.4pt;"><span id="S7.T2.3.1.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Name of Model(s)</span></span>
</span>
</th>
<th id="S7.T2.3.1.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.1.1.3.1.1" class="ltx_p" style="width:79.7pt;"><span id="S7.T2.3.1.1.1.3.1.1.1" class="ltx_text ltx_font_bold">Implemented Model(s)</span></span>
</span>
</th>
<th id="S7.T2.3.1.1.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.1.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.1.1.4.1.1" class="ltx_p" style="width:79.7pt;"><span id="S7.T2.3.1.1.1.4.1.1.1" class="ltx_text ltx_font_bold">Data Partitioning</span></span>
</span>
</th>
<th id="S7.T2.3.1.1.1.5" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.1.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.1.1.5.1.1" class="ltx_p" style="width:51.2pt;"><span id="S7.T2.3.1.1.1.5.1.1.1" class="ltx_text ltx_font_bold">Privacy Mechanism</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S7.T2.3.1.2.1" class="ltx_tr">
<td id="S7.T2.3.1.2.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.2.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.2.1.1.1.1" class="ltx_p" style="width:54.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib203" title="" class="ltx_ref">203</a>]</cite></span>
</span>
</td>
<td id="S7.T2.3.1.2.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.2.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.2.1.2.1.1" class="ltx_p" style="width:85.4pt;">Logistic Regression FL</span>
</span>
</td>
<td id="S7.T2.3.1.2.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.2.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.2.1.3.1.1" class="ltx_p" style="width:79.7pt;">LM</span>
</span>
</td>
<td id="S7.T2.3.1.2.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.2.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.2.1.4.1.1" class="ltx_p" style="width:79.7pt;">Vertical</span>
</span>
</td>
<td id="S7.T2.3.1.2.1.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.2.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.2.1.5.1.1" class="ltx_p" style="width:51.2pt;">CM</span>
</span>
</td>
</tr>
<tr id="S7.T2.3.1.3.2" class="ltx_tr">
<td id="S7.T2.3.1.3.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.3.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.3.2.1.1.1" class="ltx_p" style="width:54.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib83" title="" class="ltx_ref">83</a>]</cite></span>
</span>
</td>
<td id="S7.T2.3.1.3.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.3.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.3.2.2.1.1" class="ltx_p" style="width:85.4pt;">SCAFFOLD</span>
</span>
</td>
<td id="S7.T2.3.1.3.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.3.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.3.2.3.1.1" class="ltx_p" style="width:79.7pt;">LM, NN</span>
</span>
</td>
<td id="S7.T2.3.1.3.2.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.3.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.3.2.4.1.1" class="ltx_p" style="width:79.7pt;">Vertical</span>
</span>
</td>
<td id="S7.T2.3.1.3.2.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.3.2.5.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.3.2.5.1.1" class="ltx_p" style="width:51.2pt;">CM</span>
</span>
</td>
</tr>
<tr id="S7.T2.3.1.4.3" class="ltx_tr">
<td id="S7.T2.3.1.4.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.4.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.4.3.1.1.1" class="ltx_p" style="width:54.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite></span>
</span>
</td>
<td id="S7.T2.3.1.4.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.4.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.4.3.2.1.1" class="ltx_p" style="width:85.4pt;">DT</span>
</span>
</td>
<td id="S7.T2.3.1.4.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.4.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.4.3.3.1.1" class="ltx_p" style="width:79.7pt;">LM</span>
</span>
</td>
<td id="S7.T2.3.1.4.3.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.4.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.4.3.4.1.1" class="ltx_p" style="width:79.7pt;">Vertical</span>
</span>
</td>
<td id="S7.T2.3.1.4.3.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.4.3.5.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.4.3.5.1.1" class="ltx_p" style="width:51.2pt;">CM</span>
</span>
</td>
</tr>
<tr id="S7.T2.3.1.5.4" class="ltx_tr">
<td id="S7.T2.3.1.5.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.5.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.5.4.1.1.1" class="ltx_p" style="width:54.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite></span>
</span>
</td>
<td id="S7.T2.3.1.5.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.5.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.5.4.2.1.1" class="ltx_p" style="width:85.4pt;">Local DP FL</span>
</span>
</td>
<td id="S7.T2.3.1.5.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.5.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.5.4.3.1.1" class="ltx_p" style="width:79.7pt;">LM, NN</span>
</span>
</td>
<td id="S7.T2.3.1.5.4.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.5.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.5.4.4.1.1" class="ltx_p" style="width:79.7pt;">Horizontal</span>
</span>
</td>
<td id="S7.T2.3.1.5.4.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.5.4.5.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.5.4.5.1.1" class="ltx_p" style="width:51.2pt;">DP</span>
</span>
</td>
</tr>
<tr id="S7.T2.3.1.6.5" class="ltx_tr">
<td id="S7.T2.3.1.6.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.6.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.6.5.1.1.1" class="ltx_p" style="width:54.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib221" title="" class="ltx_ref">221</a>]</cite></span>
</span>
</td>
<td id="S7.T2.3.1.6.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.6.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.6.5.2.1.1" class="ltx_p" style="width:85.4pt;">PEFL</span>
</span>
</td>
<td id="S7.T2.3.1.6.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.6.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.6.5.3.1.1" class="ltx_p" style="width:79.7pt;">DT, LM, NN</span>
</span>
</td>
<td id="S7.T2.3.1.6.5.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.6.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.6.5.4.1.1" class="ltx_p" style="width:79.7pt;">Horizontal</span>
</span>
</td>
<td id="S7.T2.3.1.6.5.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.6.5.5.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.6.5.5.1.1" class="ltx_p" style="width:51.2pt;">CP</span>
</span>
</td>
</tr>
<tr id="S7.T2.3.1.7.6" class="ltx_tr">
<td id="S7.T2.3.1.7.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.7.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.7.6.1.1.1" class="ltx_p" style="width:54.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib60" title="" class="ltx_ref">60</a>]</cite></span>
</span>
</td>
<td id="S7.T2.3.1.7.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.7.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.7.6.2.1.1" class="ltx_p" style="width:85.4pt;">OARF</span>
</span>
</td>
<td id="S7.T2.3.1.7.6.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.7.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.7.6.3.1.1" class="ltx_p" style="width:79.7pt;">NN</span>
</span>
</td>
<td id="S7.T2.3.1.7.6.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.7.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.7.6.4.1.1" class="ltx_p" style="width:79.7pt;">Horizontal</span>
</span>
</td>
<td id="S7.T2.3.1.7.6.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.7.6.5.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.7.6.5.1.1" class="ltx_p" style="width:51.2pt;">DP, CM</span>
</span>
</td>
</tr>
<tr id="S7.T2.3.1.8.7" class="ltx_tr">
<td id="S7.T2.3.1.8.7.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.8.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.8.7.1.1.1" class="ltx_p" style="width:54.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib76" title="" class="ltx_ref">76</a>]</cite></span>
</span>
</td>
<td id="S7.T2.3.1.8.7.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.8.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.8.7.2.1.1" class="ltx_p" style="width:85.4pt;">FLASHE</span>
</span>
</td>
<td id="S7.T2.3.1.8.7.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.8.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.8.7.3.1.1" class="ltx_p" style="width:79.7pt;">-</span>
</span>
</td>
<td id="S7.T2.3.1.8.7.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.8.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.8.7.4.1.1" class="ltx_p" style="width:79.7pt;">Horizontal</span>
</span>
</td>
<td id="S7.T2.3.1.8.7.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.8.7.5.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.8.7.5.1.1" class="ltx_p" style="width:51.2pt;">HE</span>
</span>
</td>
</tr>
<tr id="S7.T2.3.1.9.8" class="ltx_tr">
<td id="S7.T2.3.1.9.8.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.9.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.9.8.1.1.1" class="ltx_p" style="width:54.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib122" title="" class="ltx_ref">122</a>]</cite></span>
</span>
</td>
<td id="S7.T2.3.1.9.8.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.9.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.9.8.2.1.1" class="ltx_p" style="width:85.4pt;">FL-LSTM</span>
</span>
</td>
<td id="S7.T2.3.1.9.8.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.9.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.9.8.3.1.1" class="ltx_p" style="width:79.7pt;">NN</span>
</span>
</td>
<td id="S7.T2.3.1.9.8.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.9.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.9.8.4.1.1" class="ltx_p" style="width:79.7pt;">Horizontal</span>
</span>
</td>
<td id="S7.T2.3.1.9.8.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.9.8.5.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.9.8.5.1.1" class="ltx_p" style="width:51.2pt;">DP</span>
</span>
</td>
</tr>
<tr id="S7.T2.3.1.10.9" class="ltx_tr">
<td id="S7.T2.3.1.10.9.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.10.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.10.9.1.1.1" class="ltx_p" style="width:54.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite></span>
</span>
</td>
<td id="S7.T2.3.1.10.9.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.10.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.10.9.2.1.1" class="ltx_p" style="width:85.4pt;">Client-Level DP FL</span>
</span>
</td>
<td id="S7.T2.3.1.10.9.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.10.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.10.9.3.1.1" class="ltx_p" style="width:79.7pt;">NN</span>
</span>
</td>
<td id="S7.T2.3.1.10.9.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.10.9.4.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.10.9.4.1.1" class="ltx_p" style="width:79.7pt;">Horizontal</span>
</span>
</td>
<td id="S7.T2.3.1.10.9.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.10.9.5.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.10.9.5.1.1" class="ltx_p" style="width:51.2pt;">DP</span>
</span>
</td>
</tr>
<tr id="S7.T2.3.1.11.10" class="ltx_tr">
<td id="S7.T2.3.1.11.10.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.11.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.11.10.1.1.1" class="ltx_p" style="width:54.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib183" title="" class="ltx_ref">183</a>]</cite></span>
</span>
</td>
<td id="S7.T2.3.1.11.10.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.11.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.11.10.2.1.1" class="ltx_p" style="width:85.4pt;">NN</span>
</span>
</td>
<td id="S7.T2.3.1.11.10.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.11.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.11.10.3.1.1" class="ltx_p" style="width:79.7pt;">LM</span>
</span>
</td>
<td id="S7.T2.3.1.11.10.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.11.10.4.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.11.10.4.1.1" class="ltx_p" style="width:79.7pt;">Vertical</span>
</span>
</td>
<td id="S7.T2.3.1.11.10.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.11.10.5.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.11.10.5.1.1" class="ltx_p" style="width:51.2pt;">-</span>
</span>
</td>
</tr>
<tr id="S7.T2.3.1.12.11" class="ltx_tr">
<td id="S7.T2.3.1.12.11.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.12.11.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.12.11.1.1.1" class="ltx_p" style="width:54.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib197" title="" class="ltx_ref">197</a>]</cite></span>
</span>
</td>
<td id="S7.T2.3.1.12.11.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.12.11.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.12.11.2.1.1" class="ltx_p" style="width:85.4pt;">FedXGB</span>
</span>
</td>
<td id="S7.T2.3.1.12.11.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.12.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.12.11.3.1.1" class="ltx_p" style="width:79.7pt;">DT</span>
</span>
</td>
<td id="S7.T2.3.1.12.11.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.12.11.4.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.12.11.4.1.1" class="ltx_p" style="width:79.7pt;">Horizontal</span>
</span>
</td>
<td id="S7.T2.3.1.12.11.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.12.11.5.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.12.11.5.1.1" class="ltx_p" style="width:51.2pt;">CM</span>
</span>
</td>
</tr>
<tr id="S7.T2.3.1.13.12" class="ltx_tr">
<td id="S7.T2.3.1.13.12.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.13.12.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.13.12.1.1.1" class="ltx_p" style="width:54.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib153" title="" class="ltx_ref">153</a>]</cite></span>
</span>
</td>
<td id="S7.T2.3.1.13.12.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.13.12.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.13.12.2.1.1" class="ltx_p" style="width:85.4pt;">FedRecSys</span>
</span>
</td>
<td id="S7.T2.3.1.13.12.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.13.12.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.13.12.3.1.1" class="ltx_p" style="width:79.7pt;">LM, NN</span>
</span>
</td>
<td id="S7.T2.3.1.13.12.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.13.12.4.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.13.12.4.1.1" class="ltx_p" style="width:79.7pt;">Horizontal</span>
</span>
</td>
<td id="S7.T2.3.1.13.12.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.13.12.5.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.13.12.5.1.1" class="ltx_p" style="width:51.2pt;">CM</span>
</span>
</td>
</tr>
<tr id="S7.T2.3.1.14.13" class="ltx_tr">
<td id="S7.T2.3.1.14.13.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.14.13.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.14.13.1.1.1" class="ltx_p" style="width:54.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib213" title="" class="ltx_ref">213</a>]</cite></span>
</span>
</td>
<td id="S7.T2.3.1.14.13.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.14.13.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.14.13.2.1.1" class="ltx_p" style="width:85.4pt;">SimFL</span>
</span>
</td>
<td id="S7.T2.3.1.14.13.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.14.13.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.14.13.3.1.1" class="ltx_p" style="width:79.7pt;">DT</span>
</span>
</td>
<td id="S7.T2.3.1.14.13.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.14.13.4.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.14.13.4.1.1" class="ltx_p" style="width:79.7pt;">Horizontal</span>
</span>
</td>
<td id="S7.T2.3.1.14.13.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.14.13.5.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.14.13.5.1.1" class="ltx_p" style="width:51.2pt;">Hashing</span>
</span>
</td>
</tr>
<tr id="S7.T2.3.1.15.14" class="ltx_tr">
<td id="S7.T2.3.1.15.14.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.15.14.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.15.14.1.1.1" class="ltx_p" style="width:54.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib172" title="" class="ltx_ref">172</a>]</cite></span>
</span>
</td>
<td id="S7.T2.3.1.15.14.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.15.14.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.15.14.2.1.1" class="ltx_p" style="width:85.4pt;">Hybrid FL</span>
</span>
</td>
<td id="S7.T2.3.1.15.14.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.15.14.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.15.14.3.1.1" class="ltx_p" style="width:79.7pt;">LM, NN, DT</span>
</span>
</td>
<td id="S7.T2.3.1.15.14.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.15.14.4.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.15.14.4.1.1" class="ltx_p" style="width:79.7pt;">Horizontal</span>
</span>
</td>
<td id="S7.T2.3.1.15.14.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.15.14.5.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.15.14.5.1.1" class="ltx_p" style="width:51.2pt;">CM, DP</span>
</span>
</td>
</tr>
<tr id="S7.T2.3.1.16.15" class="ltx_tr">
<td id="S7.T2.3.1.16.15.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.16.15.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.16.15.1.1.1" class="ltx_p" style="width:54.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib109" title="" class="ltx_ref">109</a>]</cite></span>
</span>
</td>
<td id="S7.T2.3.1.16.15.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.16.15.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.16.15.2.1.1" class="ltx_p" style="width:85.4pt;">FedForest</span>
</span>
</td>
<td id="S7.T2.3.1.16.15.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.16.15.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.16.15.3.1.1" class="ltx_p" style="width:79.7pt;">DT</span>
</span>
</td>
<td id="S7.T2.3.1.16.15.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.16.15.4.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.16.15.4.1.1" class="ltx_p" style="width:79.7pt;">Horizontal</span>
</span>
</td>
<td id="S7.T2.3.1.16.15.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.16.15.5.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.16.15.5.1.1" class="ltx_p" style="width:51.2pt;">CM</span>
</span>
</td>
</tr>
<tr id="S7.T2.3.1.17.16" class="ltx_tr">
<td id="S7.T2.3.1.17.16.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.17.16.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.17.16.1.1.1" class="ltx_p" style="width:54.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib72" title="" class="ltx_ref">72</a>]</cite></span>
</span>
</td>
<td id="S7.T2.3.1.17.16.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.17.16.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.17.16.2.1.1" class="ltx_p" style="width:85.4pt;">-</span>
</span>
</td>
<td id="S7.T2.3.1.17.16.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.17.16.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.17.16.3.1.1" class="ltx_p" style="width:79.7pt;">-</span>
</span>
</td>
<td id="S7.T2.3.1.17.16.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.17.16.4.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.17.16.4.1.1" class="ltx_p" style="width:79.7pt;">Horizontal</span>
</span>
</td>
<td id="S7.T2.3.1.17.16.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_t" style="padding-top:4.25pt;padding-bottom:4.25pt;">
<span id="S7.T2.3.1.17.16.5.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T2.3.1.17.16.5.1.1" class="ltx_p" style="width:51.2pt;">DP, HE</span>
</span>
</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section id="S7.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.2 </span><span id="S7.SS2.1.1" class="ltx_text ltx_font_italic">Notions of Fairness in Federated Learning</span>
</h3>

<div id="S7.SS2.p1" class="ltx_para">
<p id="S7.SS2.p1.1" class="ltx_p">The following notions currently exist to achieve fairness in Federated settings:
<br class="ltx_break"><span id="S7.SS2.p1.1.1" class="ltx_text ltx_font_bold">Accuracy Parity.</span>
This notion focuses on increasing the fairness/uniformity of model performance across different clients while maintaining average performance overall. Generally, a fair classifier trained on centralized data has a better performance trade-off than a model built in Federated settings based on a simple FEDAVG-based fair learning method. The basic trade-off between fairness and accuracy has been examined in a number of works and there are various ways to address this issue of finding the optimal balance between accuracy and privacy via Federated Learning algorithms. Data heterogeneity is the primary reason behind FL inconsistent performance. Training a customized or personalized model mostly yield better results than training a global model. Due to the diversity of data in an FL system, accuracy and model efficiency may be compromised. Personalization is a logical strategy used to increase accuracy given the varying nature of data in an FL system across varying clients. FEDFB <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib214" title="" class="ltx_ref">214</a>]</cite> uses personalization by modifying the FEDAVG protocol and develops a privately developed fair learning algorithm using decentralized data and mimics centralized model training. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib125" title="" class="ltx_ref">125</a>]</cite> uses a new minimax optimization approach for federated settings called Agnostic Federated Learning(AFL). In AFL, the model is optimized for almost any kind of target distribution that is produced by a combination of varying data distributions among clients. The trained model does not overfit the data by favoring any particular client over others as it enhances the performance of the worst-performing or poorest device.
q-Fair Federated Learning (q-FFL), <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib97" title="" class="ltx_ref">97</a>]</cite> presents a unique optimization goal that promotes an equitable and uniform accuracy between devices in federated networks. They provide a communication-efficient approach for resolving q-FFL called q-FedAvg that is appropriate for federated networks. Re-weighting the objective by giving devices with poor performance higher weights would be a logical way to accomplish fairness as this would cause the distribution of accuracy in the network to move in the direction of greater homogeneity. The device performance heavily relies on the trained model. As the weights can not be guessed before training, therefore, dynamic re-weighting must be done. The foundation of this idea was laid by the idea of fair resource allocation in the context of wireless networks. For positive local cost functions <math id="S7.SS2.p1.1.m1.1" class="ltx_Math" alttext="L_{k}" display="inline"><semantics id="S7.SS2.p1.1.m1.1a"><msub id="S7.SS2.p1.1.m1.1.1" xref="S7.SS2.p1.1.m1.1.1.cmml"><mi id="S7.SS2.p1.1.m1.1.1.2" xref="S7.SS2.p1.1.m1.1.1.2.cmml">L</mi><mi id="S7.SS2.p1.1.m1.1.1.3" xref="S7.SS2.p1.1.m1.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S7.SS2.p1.1.m1.1b"><apply id="S7.SS2.p1.1.m1.1.1.cmml" xref="S7.SS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S7.SS2.p1.1.m1.1.1.1.cmml" xref="S7.SS2.p1.1.m1.1.1">subscript</csymbol><ci id="S7.SS2.p1.1.m1.1.1.2.cmml" xref="S7.SS2.p1.1.m1.1.1.2">𝐿</ci><ci id="S7.SS2.p1.1.m1.1.1.3.cmml" xref="S7.SS2.p1.1.m1.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.p1.1.m1.1c">L_{k}</annotation></semantics></math>, if parameter q is greater than 0, the q-Fair Federated Learning (q-FFL) optimization can be defined as:</p>
<table id="S7.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S7.E2.m1.2" class="ltx_Math" alttext="\min_{\theta}L_{q}(\theta)=\displaystyle\sum\limits_{k=1}^{N}\frac{p_{k}}{q+1}F_{k}^{q+1}(\theta)" display="block"><semantics id="S7.E2.m1.2a"><mrow id="S7.E2.m1.2.3" xref="S7.E2.m1.2.3.cmml"><mrow id="S7.E2.m1.2.3.2" xref="S7.E2.m1.2.3.2.cmml"><mrow id="S7.E2.m1.2.3.2.2" xref="S7.E2.m1.2.3.2.2.cmml"><munder id="S7.E2.m1.2.3.2.2.1" xref="S7.E2.m1.2.3.2.2.1.cmml"><mi id="S7.E2.m1.2.3.2.2.1.2" xref="S7.E2.m1.2.3.2.2.1.2.cmml">min</mi><mi id="S7.E2.m1.2.3.2.2.1.3" xref="S7.E2.m1.2.3.2.2.1.3.cmml">θ</mi></munder><mo lspace="0.167em" id="S7.E2.m1.2.3.2.2a" xref="S7.E2.m1.2.3.2.2.cmml">⁡</mo><msub id="S7.E2.m1.2.3.2.2.2" xref="S7.E2.m1.2.3.2.2.2.cmml"><mi id="S7.E2.m1.2.3.2.2.2.2" xref="S7.E2.m1.2.3.2.2.2.2.cmml">L</mi><mi id="S7.E2.m1.2.3.2.2.2.3" xref="S7.E2.m1.2.3.2.2.2.3.cmml">q</mi></msub></mrow><mo lspace="0em" rspace="0em" id="S7.E2.m1.2.3.2.1" xref="S7.E2.m1.2.3.2.1.cmml">​</mo><mrow id="S7.E2.m1.2.3.2.3.2" xref="S7.E2.m1.2.3.2.cmml"><mo stretchy="false" id="S7.E2.m1.2.3.2.3.2.1" xref="S7.E2.m1.2.3.2.cmml">(</mo><mi id="S7.E2.m1.1.1" xref="S7.E2.m1.1.1.cmml">θ</mi><mo stretchy="false" id="S7.E2.m1.2.3.2.3.2.2" xref="S7.E2.m1.2.3.2.cmml">)</mo></mrow></mrow><mo rspace="0.111em" id="S7.E2.m1.2.3.1" xref="S7.E2.m1.2.3.1.cmml">=</mo><mrow id="S7.E2.m1.2.3.3" xref="S7.E2.m1.2.3.3.cmml"><munderover id="S7.E2.m1.2.3.3.1" xref="S7.E2.m1.2.3.3.1.cmml"><mo movablelimits="false" id="S7.E2.m1.2.3.3.1.2.2" xref="S7.E2.m1.2.3.3.1.2.2.cmml">∑</mo><mrow id="S7.E2.m1.2.3.3.1.2.3" xref="S7.E2.m1.2.3.3.1.2.3.cmml"><mi id="S7.E2.m1.2.3.3.1.2.3.2" xref="S7.E2.m1.2.3.3.1.2.3.2.cmml">k</mi><mo id="S7.E2.m1.2.3.3.1.2.3.1" xref="S7.E2.m1.2.3.3.1.2.3.1.cmml">=</mo><mn id="S7.E2.m1.2.3.3.1.2.3.3" xref="S7.E2.m1.2.3.3.1.2.3.3.cmml">1</mn></mrow><mi id="S7.E2.m1.2.3.3.1.3" xref="S7.E2.m1.2.3.3.1.3.cmml">N</mi></munderover><mrow id="S7.E2.m1.2.3.3.2" xref="S7.E2.m1.2.3.3.2.cmml"><mfrac id="S7.E2.m1.2.3.3.2.2" xref="S7.E2.m1.2.3.3.2.2.cmml"><msub id="S7.E2.m1.2.3.3.2.2.2" xref="S7.E2.m1.2.3.3.2.2.2.cmml"><mi id="S7.E2.m1.2.3.3.2.2.2.2" xref="S7.E2.m1.2.3.3.2.2.2.2.cmml">p</mi><mi id="S7.E2.m1.2.3.3.2.2.2.3" xref="S7.E2.m1.2.3.3.2.2.2.3.cmml">k</mi></msub><mrow id="S7.E2.m1.2.3.3.2.2.3" xref="S7.E2.m1.2.3.3.2.2.3.cmml"><mi id="S7.E2.m1.2.3.3.2.2.3.2" xref="S7.E2.m1.2.3.3.2.2.3.2.cmml">q</mi><mo id="S7.E2.m1.2.3.3.2.2.3.1" xref="S7.E2.m1.2.3.3.2.2.3.1.cmml">+</mo><mn id="S7.E2.m1.2.3.3.2.2.3.3" xref="S7.E2.m1.2.3.3.2.2.3.3.cmml">1</mn></mrow></mfrac><mo lspace="0em" rspace="0em" id="S7.E2.m1.2.3.3.2.1" xref="S7.E2.m1.2.3.3.2.1.cmml">​</mo><msubsup id="S7.E2.m1.2.3.3.2.3" xref="S7.E2.m1.2.3.3.2.3.cmml"><mi id="S7.E2.m1.2.3.3.2.3.2.2" xref="S7.E2.m1.2.3.3.2.3.2.2.cmml">F</mi><mi id="S7.E2.m1.2.3.3.2.3.2.3" xref="S7.E2.m1.2.3.3.2.3.2.3.cmml">k</mi><mrow id="S7.E2.m1.2.3.3.2.3.3" xref="S7.E2.m1.2.3.3.2.3.3.cmml"><mi id="S7.E2.m1.2.3.3.2.3.3.2" xref="S7.E2.m1.2.3.3.2.3.3.2.cmml">q</mi><mo id="S7.E2.m1.2.3.3.2.3.3.1" xref="S7.E2.m1.2.3.3.2.3.3.1.cmml">+</mo><mn id="S7.E2.m1.2.3.3.2.3.3.3" xref="S7.E2.m1.2.3.3.2.3.3.3.cmml">1</mn></mrow></msubsup><mo lspace="0em" rspace="0em" id="S7.E2.m1.2.3.3.2.1a" xref="S7.E2.m1.2.3.3.2.1.cmml">​</mo><mrow id="S7.E2.m1.2.3.3.2.4.2" xref="S7.E2.m1.2.3.3.2.cmml"><mo stretchy="false" id="S7.E2.m1.2.3.3.2.4.2.1" xref="S7.E2.m1.2.3.3.2.cmml">(</mo><mi id="S7.E2.m1.2.2" xref="S7.E2.m1.2.2.cmml">θ</mi><mo stretchy="false" id="S7.E2.m1.2.3.3.2.4.2.2" xref="S7.E2.m1.2.3.3.2.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S7.E2.m1.2b"><apply id="S7.E2.m1.2.3.cmml" xref="S7.E2.m1.2.3"><eq id="S7.E2.m1.2.3.1.cmml" xref="S7.E2.m1.2.3.1"></eq><apply id="S7.E2.m1.2.3.2.cmml" xref="S7.E2.m1.2.3.2"><times id="S7.E2.m1.2.3.2.1.cmml" xref="S7.E2.m1.2.3.2.1"></times><apply id="S7.E2.m1.2.3.2.2.cmml" xref="S7.E2.m1.2.3.2.2"><apply id="S7.E2.m1.2.3.2.2.1.cmml" xref="S7.E2.m1.2.3.2.2.1"><csymbol cd="ambiguous" id="S7.E2.m1.2.3.2.2.1.1.cmml" xref="S7.E2.m1.2.3.2.2.1">subscript</csymbol><min id="S7.E2.m1.2.3.2.2.1.2.cmml" xref="S7.E2.m1.2.3.2.2.1.2"></min><ci id="S7.E2.m1.2.3.2.2.1.3.cmml" xref="S7.E2.m1.2.3.2.2.1.3">𝜃</ci></apply><apply id="S7.E2.m1.2.3.2.2.2.cmml" xref="S7.E2.m1.2.3.2.2.2"><csymbol cd="ambiguous" id="S7.E2.m1.2.3.2.2.2.1.cmml" xref="S7.E2.m1.2.3.2.2.2">subscript</csymbol><ci id="S7.E2.m1.2.3.2.2.2.2.cmml" xref="S7.E2.m1.2.3.2.2.2.2">𝐿</ci><ci id="S7.E2.m1.2.3.2.2.2.3.cmml" xref="S7.E2.m1.2.3.2.2.2.3">𝑞</ci></apply></apply><ci id="S7.E2.m1.1.1.cmml" xref="S7.E2.m1.1.1">𝜃</ci></apply><apply id="S7.E2.m1.2.3.3.cmml" xref="S7.E2.m1.2.3.3"><apply id="S7.E2.m1.2.3.3.1.cmml" xref="S7.E2.m1.2.3.3.1"><csymbol cd="ambiguous" id="S7.E2.m1.2.3.3.1.1.cmml" xref="S7.E2.m1.2.3.3.1">superscript</csymbol><apply id="S7.E2.m1.2.3.3.1.2.cmml" xref="S7.E2.m1.2.3.3.1"><csymbol cd="ambiguous" id="S7.E2.m1.2.3.3.1.2.1.cmml" xref="S7.E2.m1.2.3.3.1">subscript</csymbol><sum id="S7.E2.m1.2.3.3.1.2.2.cmml" xref="S7.E2.m1.2.3.3.1.2.2"></sum><apply id="S7.E2.m1.2.3.3.1.2.3.cmml" xref="S7.E2.m1.2.3.3.1.2.3"><eq id="S7.E2.m1.2.3.3.1.2.3.1.cmml" xref="S7.E2.m1.2.3.3.1.2.3.1"></eq><ci id="S7.E2.m1.2.3.3.1.2.3.2.cmml" xref="S7.E2.m1.2.3.3.1.2.3.2">𝑘</ci><cn type="integer" id="S7.E2.m1.2.3.3.1.2.3.3.cmml" xref="S7.E2.m1.2.3.3.1.2.3.3">1</cn></apply></apply><ci id="S7.E2.m1.2.3.3.1.3.cmml" xref="S7.E2.m1.2.3.3.1.3">𝑁</ci></apply><apply id="S7.E2.m1.2.3.3.2.cmml" xref="S7.E2.m1.2.3.3.2"><times id="S7.E2.m1.2.3.3.2.1.cmml" xref="S7.E2.m1.2.3.3.2.1"></times><apply id="S7.E2.m1.2.3.3.2.2.cmml" xref="S7.E2.m1.2.3.3.2.2"><divide id="S7.E2.m1.2.3.3.2.2.1.cmml" xref="S7.E2.m1.2.3.3.2.2"></divide><apply id="S7.E2.m1.2.3.3.2.2.2.cmml" xref="S7.E2.m1.2.3.3.2.2.2"><csymbol cd="ambiguous" id="S7.E2.m1.2.3.3.2.2.2.1.cmml" xref="S7.E2.m1.2.3.3.2.2.2">subscript</csymbol><ci id="S7.E2.m1.2.3.3.2.2.2.2.cmml" xref="S7.E2.m1.2.3.3.2.2.2.2">𝑝</ci><ci id="S7.E2.m1.2.3.3.2.2.2.3.cmml" xref="S7.E2.m1.2.3.3.2.2.2.3">𝑘</ci></apply><apply id="S7.E2.m1.2.3.3.2.2.3.cmml" xref="S7.E2.m1.2.3.3.2.2.3"><plus id="S7.E2.m1.2.3.3.2.2.3.1.cmml" xref="S7.E2.m1.2.3.3.2.2.3.1"></plus><ci id="S7.E2.m1.2.3.3.2.2.3.2.cmml" xref="S7.E2.m1.2.3.3.2.2.3.2">𝑞</ci><cn type="integer" id="S7.E2.m1.2.3.3.2.2.3.3.cmml" xref="S7.E2.m1.2.3.3.2.2.3.3">1</cn></apply></apply><apply id="S7.E2.m1.2.3.3.2.3.cmml" xref="S7.E2.m1.2.3.3.2.3"><csymbol cd="ambiguous" id="S7.E2.m1.2.3.3.2.3.1.cmml" xref="S7.E2.m1.2.3.3.2.3">superscript</csymbol><apply id="S7.E2.m1.2.3.3.2.3.2.cmml" xref="S7.E2.m1.2.3.3.2.3"><csymbol cd="ambiguous" id="S7.E2.m1.2.3.3.2.3.2.1.cmml" xref="S7.E2.m1.2.3.3.2.3">subscript</csymbol><ci id="S7.E2.m1.2.3.3.2.3.2.2.cmml" xref="S7.E2.m1.2.3.3.2.3.2.2">𝐹</ci><ci id="S7.E2.m1.2.3.3.2.3.2.3.cmml" xref="S7.E2.m1.2.3.3.2.3.2.3">𝑘</ci></apply><apply id="S7.E2.m1.2.3.3.2.3.3.cmml" xref="S7.E2.m1.2.3.3.2.3.3"><plus id="S7.E2.m1.2.3.3.2.3.3.1.cmml" xref="S7.E2.m1.2.3.3.2.3.3.1"></plus><ci id="S7.E2.m1.2.3.3.2.3.3.2.cmml" xref="S7.E2.m1.2.3.3.2.3.3.2">𝑞</ci><cn type="integer" id="S7.E2.m1.2.3.3.2.3.3.3.cmml" xref="S7.E2.m1.2.3.3.2.3.3.3">1</cn></apply></apply><ci id="S7.E2.m1.2.2.cmml" xref="S7.E2.m1.2.2">𝜃</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.E2.m1.2c">\min_{\theta}L_{q}(\theta)=\displaystyle\sum\limits_{k=1}^{N}\frac{p_{k}}{q+1}F_{k}^{q+1}(\theta)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S7.SS2.p1.7" class="ltx_p"><math id="S7.SS2.p1.2.m1.1" class="ltx_Math" alttext="L_{k}^{q+1}" display="inline"><semantics id="S7.SS2.p1.2.m1.1a"><msubsup id="S7.SS2.p1.2.m1.1.1" xref="S7.SS2.p1.2.m1.1.1.cmml"><mi id="S7.SS2.p1.2.m1.1.1.2.2" xref="S7.SS2.p1.2.m1.1.1.2.2.cmml">L</mi><mi id="S7.SS2.p1.2.m1.1.1.2.3" xref="S7.SS2.p1.2.m1.1.1.2.3.cmml">k</mi><mrow id="S7.SS2.p1.2.m1.1.1.3" xref="S7.SS2.p1.2.m1.1.1.3.cmml"><mi id="S7.SS2.p1.2.m1.1.1.3.2" xref="S7.SS2.p1.2.m1.1.1.3.2.cmml">q</mi><mo id="S7.SS2.p1.2.m1.1.1.3.1" xref="S7.SS2.p1.2.m1.1.1.3.1.cmml">+</mo><mn id="S7.SS2.p1.2.m1.1.1.3.3" xref="S7.SS2.p1.2.m1.1.1.3.3.cmml">1</mn></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S7.SS2.p1.2.m1.1b"><apply id="S7.SS2.p1.2.m1.1.1.cmml" xref="S7.SS2.p1.2.m1.1.1"><csymbol cd="ambiguous" id="S7.SS2.p1.2.m1.1.1.1.cmml" xref="S7.SS2.p1.2.m1.1.1">superscript</csymbol><apply id="S7.SS2.p1.2.m1.1.1.2.cmml" xref="S7.SS2.p1.2.m1.1.1"><csymbol cd="ambiguous" id="S7.SS2.p1.2.m1.1.1.2.1.cmml" xref="S7.SS2.p1.2.m1.1.1">subscript</csymbol><ci id="S7.SS2.p1.2.m1.1.1.2.2.cmml" xref="S7.SS2.p1.2.m1.1.1.2.2">𝐿</ci><ci id="S7.SS2.p1.2.m1.1.1.2.3.cmml" xref="S7.SS2.p1.2.m1.1.1.2.3">𝑘</ci></apply><apply id="S7.SS2.p1.2.m1.1.1.3.cmml" xref="S7.SS2.p1.2.m1.1.1.3"><plus id="S7.SS2.p1.2.m1.1.1.3.1.cmml" xref="S7.SS2.p1.2.m1.1.1.3.1"></plus><ci id="S7.SS2.p1.2.m1.1.1.3.2.cmml" xref="S7.SS2.p1.2.m1.1.1.3.2">𝑞</ci><cn type="integer" id="S7.SS2.p1.2.m1.1.1.3.3.cmml" xref="S7.SS2.p1.2.m1.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.p1.2.m1.1c">L_{k}^{q+1}</annotation></semantics></math> represents <math id="S7.SS2.p1.3.m2.1" class="ltx_Math" alttext="L_{k}" display="inline"><semantics id="S7.SS2.p1.3.m2.1a"><msub id="S7.SS2.p1.3.m2.1.1" xref="S7.SS2.p1.3.m2.1.1.cmml"><mi id="S7.SS2.p1.3.m2.1.1.2" xref="S7.SS2.p1.3.m2.1.1.2.cmml">L</mi><mi id="S7.SS2.p1.3.m2.1.1.3" xref="S7.SS2.p1.3.m2.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S7.SS2.p1.3.m2.1b"><apply id="S7.SS2.p1.3.m2.1.1.cmml" xref="S7.SS2.p1.3.m2.1.1"><csymbol cd="ambiguous" id="S7.SS2.p1.3.m2.1.1.1.cmml" xref="S7.SS2.p1.3.m2.1.1">subscript</csymbol><ci id="S7.SS2.p1.3.m2.1.1.2.cmml" xref="S7.SS2.p1.3.m2.1.1.2">𝐿</ci><ci id="S7.SS2.p1.3.m2.1.1.3.cmml" xref="S7.SS2.p1.3.m2.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.p1.3.m2.1c">L_{k}</annotation></semantics></math>(<math id="S7.SS2.p1.4.m3.1" class="ltx_Math" alttext="\cdot" display="inline"><semantics id="S7.SS2.p1.4.m3.1a"><mo id="S7.SS2.p1.4.m3.1.1" xref="S7.SS2.p1.4.m3.1.1.cmml">⋅</mo><annotation-xml encoding="MathML-Content" id="S7.SS2.p1.4.m3.1b"><ci id="S7.SS2.p1.4.m3.1.1.cmml" xref="S7.SS2.p1.4.m3.1.1">⋅</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.p1.4.m3.1c">\cdot</annotation></semantics></math>) to the power of (q+1), where q is a factor that controls the fairness level we want to enforce. A higher value of q indicates more favor against devices with greater empirical losses locally, <math id="S7.SS2.p1.5.m4.1" class="ltx_Math" alttext="L_{k}(\theta)" display="inline"><semantics id="S7.SS2.p1.5.m4.1a"><mrow id="S7.SS2.p1.5.m4.1.2" xref="S7.SS2.p1.5.m4.1.2.cmml"><msub id="S7.SS2.p1.5.m4.1.2.2" xref="S7.SS2.p1.5.m4.1.2.2.cmml"><mi id="S7.SS2.p1.5.m4.1.2.2.2" xref="S7.SS2.p1.5.m4.1.2.2.2.cmml">L</mi><mi id="S7.SS2.p1.5.m4.1.2.2.3" xref="S7.SS2.p1.5.m4.1.2.2.3.cmml">k</mi></msub><mo lspace="0em" rspace="0em" id="S7.SS2.p1.5.m4.1.2.1" xref="S7.SS2.p1.5.m4.1.2.1.cmml">​</mo><mrow id="S7.SS2.p1.5.m4.1.2.3.2" xref="S7.SS2.p1.5.m4.1.2.cmml"><mo stretchy="false" id="S7.SS2.p1.5.m4.1.2.3.2.1" xref="S7.SS2.p1.5.m4.1.2.cmml">(</mo><mi id="S7.SS2.p1.5.m4.1.1" xref="S7.SS2.p1.5.m4.1.1.cmml">θ</mi><mo stretchy="false" id="S7.SS2.p1.5.m4.1.2.3.2.2" xref="S7.SS2.p1.5.m4.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S7.SS2.p1.5.m4.1b"><apply id="S7.SS2.p1.5.m4.1.2.cmml" xref="S7.SS2.p1.5.m4.1.2"><times id="S7.SS2.p1.5.m4.1.2.1.cmml" xref="S7.SS2.p1.5.m4.1.2.1"></times><apply id="S7.SS2.p1.5.m4.1.2.2.cmml" xref="S7.SS2.p1.5.m4.1.2.2"><csymbol cd="ambiguous" id="S7.SS2.p1.5.m4.1.2.2.1.cmml" xref="S7.SS2.p1.5.m4.1.2.2">subscript</csymbol><ci id="S7.SS2.p1.5.m4.1.2.2.2.cmml" xref="S7.SS2.p1.5.m4.1.2.2.2">𝐿</ci><ci id="S7.SS2.p1.5.m4.1.2.2.3.cmml" xref="S7.SS2.p1.5.m4.1.2.2.3">𝑘</ci></apply><ci id="S7.SS2.p1.5.m4.1.1.cmml" xref="S7.SS2.p1.5.m4.1.1">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.p1.5.m4.1c">L_{k}(\theta)</annotation></semantics></math>. As a result, more uniformity is imposed on accuracy and fairness. Setting <math id="S7.SS2.p1.6.m5.1" class="ltx_Math" alttext="L_{q}(\theta)" display="inline"><semantics id="S7.SS2.p1.6.m5.1a"><mrow id="S7.SS2.p1.6.m5.1.2" xref="S7.SS2.p1.6.m5.1.2.cmml"><msub id="S7.SS2.p1.6.m5.1.2.2" xref="S7.SS2.p1.6.m5.1.2.2.cmml"><mi id="S7.SS2.p1.6.m5.1.2.2.2" xref="S7.SS2.p1.6.m5.1.2.2.2.cmml">L</mi><mi id="S7.SS2.p1.6.m5.1.2.2.3" xref="S7.SS2.p1.6.m5.1.2.2.3.cmml">q</mi></msub><mo lspace="0em" rspace="0em" id="S7.SS2.p1.6.m5.1.2.1" xref="S7.SS2.p1.6.m5.1.2.1.cmml">​</mo><mrow id="S7.SS2.p1.6.m5.1.2.3.2" xref="S7.SS2.p1.6.m5.1.2.cmml"><mo stretchy="false" id="S7.SS2.p1.6.m5.1.2.3.2.1" xref="S7.SS2.p1.6.m5.1.2.cmml">(</mo><mi id="S7.SS2.p1.6.m5.1.1" xref="S7.SS2.p1.6.m5.1.1.cmml">θ</mi><mo stretchy="false" id="S7.SS2.p1.6.m5.1.2.3.2.2" xref="S7.SS2.p1.6.m5.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S7.SS2.p1.6.m5.1b"><apply id="S7.SS2.p1.6.m5.1.2.cmml" xref="S7.SS2.p1.6.m5.1.2"><times id="S7.SS2.p1.6.m5.1.2.1.cmml" xref="S7.SS2.p1.6.m5.1.2.1"></times><apply id="S7.SS2.p1.6.m5.1.2.2.cmml" xref="S7.SS2.p1.6.m5.1.2.2"><csymbol cd="ambiguous" id="S7.SS2.p1.6.m5.1.2.2.1.cmml" xref="S7.SS2.p1.6.m5.1.2.2">subscript</csymbol><ci id="S7.SS2.p1.6.m5.1.2.2.2.cmml" xref="S7.SS2.p1.6.m5.1.2.2.2">𝐿</ci><ci id="S7.SS2.p1.6.m5.1.2.2.3.cmml" xref="S7.SS2.p1.6.m5.1.2.2.3">𝑞</ci></apply><ci id="S7.SS2.p1.6.m5.1.1.cmml" xref="S7.SS2.p1.6.m5.1.1">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.p1.6.m5.1c">L_{q}(\theta)</annotation></semantics></math> to a big enough q results in traditional minimax fairness <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib160" title="" class="ltx_ref">160</a>]</cite> as the device with the highest loss dominates the objective.
Since in practice, each device may create data using a different distribution, hence to account for this variability, approaches that develop customized, device-specific models such as <math id="S7.SS2.p1.7.m6.1" class="ltx_Math" alttext="v_{k}" display="inline"><semantics id="S7.SS2.p1.7.m6.1a"><msub id="S7.SS2.p1.7.m6.1.1" xref="S7.SS2.p1.7.m6.1.1.cmml"><mi id="S7.SS2.p1.7.m6.1.1.2" xref="S7.SS2.p1.7.m6.1.1.2.cmml">v</mi><mi id="S7.SS2.p1.7.m6.1.1.3" xref="S7.SS2.p1.7.m6.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S7.SS2.p1.7.m6.1b"><apply id="S7.SS2.p1.7.m6.1.1.cmml" xref="S7.SS2.p1.7.m6.1.1"><csymbol cd="ambiguous" id="S7.SS2.p1.7.m6.1.1.1.cmml" xref="S7.SS2.p1.7.m6.1.1">subscript</csymbol><ci id="S7.SS2.p1.7.m6.1.1.2.cmml" xref="S7.SS2.p1.7.m6.1.1.2">𝑣</ci><ci id="S7.SS2.p1.7.m6.1.1.3.cmml" xref="S7.SS2.p1.7.m6.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.p1.7.m6.1c">v_{k}</annotation></semantics></math> where k belongs to K, throughout the network are commonly considered.
A scalable federated multi-task learning system called Ditto <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib96" title="" class="ltx_ref">96</a>]</cite>, where the key concept is local training with regularization, motivates individualized models to as close as possible to the ideal server or global model. Ditto improves absolute test accuracy by 5% while decreasing variation among devices by an average of 10% across all datasets as compared to TERM (on clean data).</p>
</div>
<div id="S7.SS2.p2" class="ltx_para">
<p id="S7.SS2.p2.2" class="ltx_p">Ditto’s local goal or objective is <math id="S7.SS2.p2.1.m1.1" class="ltx_Math" alttext="L_{k}(v_{k})" display="inline"><semantics id="S7.SS2.p2.1.m1.1a"><mrow id="S7.SS2.p2.1.m1.1.1" xref="S7.SS2.p2.1.m1.1.1.cmml"><msub id="S7.SS2.p2.1.m1.1.1.3" xref="S7.SS2.p2.1.m1.1.1.3.cmml"><mi id="S7.SS2.p2.1.m1.1.1.3.2" xref="S7.SS2.p2.1.m1.1.1.3.2.cmml">L</mi><mi id="S7.SS2.p2.1.m1.1.1.3.3" xref="S7.SS2.p2.1.m1.1.1.3.3.cmml">k</mi></msub><mo lspace="0em" rspace="0em" id="S7.SS2.p2.1.m1.1.1.2" xref="S7.SS2.p2.1.m1.1.1.2.cmml">​</mo><mrow id="S7.SS2.p2.1.m1.1.1.1.1" xref="S7.SS2.p2.1.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="S7.SS2.p2.1.m1.1.1.1.1.2" xref="S7.SS2.p2.1.m1.1.1.1.1.1.cmml">(</mo><msub id="S7.SS2.p2.1.m1.1.1.1.1.1" xref="S7.SS2.p2.1.m1.1.1.1.1.1.cmml"><mi id="S7.SS2.p2.1.m1.1.1.1.1.1.2" xref="S7.SS2.p2.1.m1.1.1.1.1.1.2.cmml">v</mi><mi id="S7.SS2.p2.1.m1.1.1.1.1.1.3" xref="S7.SS2.p2.1.m1.1.1.1.1.1.3.cmml">k</mi></msub><mo stretchy="false" id="S7.SS2.p2.1.m1.1.1.1.1.3" xref="S7.SS2.p2.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S7.SS2.p2.1.m1.1b"><apply id="S7.SS2.p2.1.m1.1.1.cmml" xref="S7.SS2.p2.1.m1.1.1"><times id="S7.SS2.p2.1.m1.1.1.2.cmml" xref="S7.SS2.p2.1.m1.1.1.2"></times><apply id="S7.SS2.p2.1.m1.1.1.3.cmml" xref="S7.SS2.p2.1.m1.1.1.3"><csymbol cd="ambiguous" id="S7.SS2.p2.1.m1.1.1.3.1.cmml" xref="S7.SS2.p2.1.m1.1.1.3">subscript</csymbol><ci id="S7.SS2.p2.1.m1.1.1.3.2.cmml" xref="S7.SS2.p2.1.m1.1.1.3.2">𝐿</ci><ci id="S7.SS2.p2.1.m1.1.1.3.3.cmml" xref="S7.SS2.p2.1.m1.1.1.3.3">𝑘</ci></apply><apply id="S7.SS2.p2.1.m1.1.1.1.1.1.cmml" xref="S7.SS2.p2.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S7.SS2.p2.1.m1.1.1.1.1.1.1.cmml" xref="S7.SS2.p2.1.m1.1.1.1.1">subscript</csymbol><ci id="S7.SS2.p2.1.m1.1.1.1.1.1.2.cmml" xref="S7.SS2.p2.1.m1.1.1.1.1.1.2">𝑣</ci><ci id="S7.SS2.p2.1.m1.1.1.1.1.1.3.cmml" xref="S7.SS2.p2.1.m1.1.1.1.1.1.3">𝑘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.p2.1.m1.1c">L_{k}(v_{k})</annotation></semantics></math>. This mainly aims to build a model using just device m’s data and included a regularization term that pushes individualized models to be as near as possible to the best server or global model.
For every device <math id="S7.SS2.p2.2.m2.1" class="ltx_Math" alttext="m" display="inline"><semantics id="S7.SS2.p2.2.m2.1a"><mi id="S7.SS2.p2.2.m2.1.1" xref="S7.SS2.p2.2.m2.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S7.SS2.p2.2.m2.1b"><ci id="S7.SS2.p2.2.m2.1.1.cmml" xref="S7.SS2.p2.2.m2.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.p2.2.m2.1c">m</annotation></semantics></math>, the optimization objective of Ditto becomes:</p>
</div>
<div id="S7.SS2.p3" class="ltx_para">
<table id="S7.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S7.E3.m1.4" class="ltx_Math" alttext="\begin{array}[]{cl}\min_{v_{m}}&amp;h_{m}\left(v_{m};\theta^{*}\right):LF_{k}\left(v_{m}\right)+\frac{\lambda}{2}\left\|v_{m}-\theta^{*}\right\|^{2}\\
\end{array}" display="block"><semantics id="S7.E3.m1.4a"><mtable columnspacing="5pt" displaystyle="true" id="S7.E3.m1.4.4" xref="S7.E3.m1.4.4.cmml"><mtr id="S7.E3.m1.4.4a" xref="S7.E3.m1.4.4.cmml"><mtd id="S7.E3.m1.4.4b" xref="S7.E3.m1.4.4.cmml"><msub id="S7.E3.m1.4.4.4.5.1" xref="S7.E3.m1.4.4.4.5.1.cmml"><mi id="S7.E3.m1.4.4.4.5.1.2" xref="S7.E3.m1.4.4.4.5.1.2.cmml">min</mi><msub id="S7.E3.m1.4.4.4.5.1.3" xref="S7.E3.m1.4.4.4.5.1.3.cmml"><mi id="S7.E3.m1.4.4.4.5.1.3.2" xref="S7.E3.m1.4.4.4.5.1.3.2.cmml">v</mi><mi id="S7.E3.m1.4.4.4.5.1.3.3" xref="S7.E3.m1.4.4.4.5.1.3.3.cmml">m</mi></msub></msub></mtd><mtd class="ltx_align_left" columnalign="left" id="S7.E3.m1.4.4c" xref="S7.E3.m1.4.4.cmml"><mrow id="S7.E3.m1.4.4.4.4.4" xref="S7.E3.m1.4.4.4.4.4.cmml"><mrow id="S7.E3.m1.2.2.2.2.2.2" xref="S7.E3.m1.2.2.2.2.2.2.cmml"><msub id="S7.E3.m1.2.2.2.2.2.2.4" xref="S7.E3.m1.2.2.2.2.2.2.4.cmml"><mi id="S7.E3.m1.2.2.2.2.2.2.4.2" xref="S7.E3.m1.2.2.2.2.2.2.4.2.cmml">h</mi><mi id="S7.E3.m1.2.2.2.2.2.2.4.3" xref="S7.E3.m1.2.2.2.2.2.2.4.3.cmml">m</mi></msub><mo lspace="0em" rspace="0em" id="S7.E3.m1.2.2.2.2.2.2.3" xref="S7.E3.m1.2.2.2.2.2.2.3.cmml">​</mo><mrow id="S7.E3.m1.2.2.2.2.2.2.2.2" xref="S7.E3.m1.2.2.2.2.2.2.2.3.cmml"><mo id="S7.E3.m1.2.2.2.2.2.2.2.2.3" xref="S7.E3.m1.2.2.2.2.2.2.2.3.cmml">(</mo><msub id="S7.E3.m1.1.1.1.1.1.1.1.1.1" xref="S7.E3.m1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S7.E3.m1.1.1.1.1.1.1.1.1.1.2" xref="S7.E3.m1.1.1.1.1.1.1.1.1.1.2.cmml">v</mi><mi id="S7.E3.m1.1.1.1.1.1.1.1.1.1.3" xref="S7.E3.m1.1.1.1.1.1.1.1.1.1.3.cmml">m</mi></msub><mo id="S7.E3.m1.2.2.2.2.2.2.2.2.4" xref="S7.E3.m1.2.2.2.2.2.2.2.3.cmml">;</mo><msup id="S7.E3.m1.2.2.2.2.2.2.2.2.2" xref="S7.E3.m1.2.2.2.2.2.2.2.2.2.cmml"><mi id="S7.E3.m1.2.2.2.2.2.2.2.2.2.2" xref="S7.E3.m1.2.2.2.2.2.2.2.2.2.2.cmml">θ</mi><mo id="S7.E3.m1.2.2.2.2.2.2.2.2.2.3" xref="S7.E3.m1.2.2.2.2.2.2.2.2.2.3.cmml">∗</mo></msup><mo rspace="0.278em" id="S7.E3.m1.2.2.2.2.2.2.2.2.5" xref="S7.E3.m1.2.2.2.2.2.2.2.3.cmml">)</mo></mrow></mrow><mo rspace="0.278em" id="S7.E3.m1.4.4.4.4.4.5" xref="S7.E3.m1.4.4.4.4.4.5.cmml">:</mo><mrow id="S7.E3.m1.4.4.4.4.4.4" xref="S7.E3.m1.4.4.4.4.4.4.cmml"><mrow id="S7.E3.m1.3.3.3.3.3.3.1" xref="S7.E3.m1.3.3.3.3.3.3.1.cmml"><mi id="S7.E3.m1.3.3.3.3.3.3.1.3" xref="S7.E3.m1.3.3.3.3.3.3.1.3.cmml">L</mi><mo lspace="0em" rspace="0em" id="S7.E3.m1.3.3.3.3.3.3.1.2" xref="S7.E3.m1.3.3.3.3.3.3.1.2.cmml">​</mo><msub id="S7.E3.m1.3.3.3.3.3.3.1.4" xref="S7.E3.m1.3.3.3.3.3.3.1.4.cmml"><mi id="S7.E3.m1.3.3.3.3.3.3.1.4.2" xref="S7.E3.m1.3.3.3.3.3.3.1.4.2.cmml">F</mi><mi id="S7.E3.m1.3.3.3.3.3.3.1.4.3" xref="S7.E3.m1.3.3.3.3.3.3.1.4.3.cmml">k</mi></msub><mo lspace="0em" rspace="0em" id="S7.E3.m1.3.3.3.3.3.3.1.2a" xref="S7.E3.m1.3.3.3.3.3.3.1.2.cmml">​</mo><mrow id="S7.E3.m1.3.3.3.3.3.3.1.1.1" xref="S7.E3.m1.3.3.3.3.3.3.1.1.1.1.cmml"><mo id="S7.E3.m1.3.3.3.3.3.3.1.1.1.2" xref="S7.E3.m1.3.3.3.3.3.3.1.1.1.1.cmml">(</mo><msub id="S7.E3.m1.3.3.3.3.3.3.1.1.1.1" xref="S7.E3.m1.3.3.3.3.3.3.1.1.1.1.cmml"><mi id="S7.E3.m1.3.3.3.3.3.3.1.1.1.1.2" xref="S7.E3.m1.3.3.3.3.3.3.1.1.1.1.2.cmml">v</mi><mi id="S7.E3.m1.3.3.3.3.3.3.1.1.1.1.3" xref="S7.E3.m1.3.3.3.3.3.3.1.1.1.1.3.cmml">m</mi></msub><mo id="S7.E3.m1.3.3.3.3.3.3.1.1.1.3" xref="S7.E3.m1.3.3.3.3.3.3.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S7.E3.m1.4.4.4.4.4.4.3" xref="S7.E3.m1.4.4.4.4.4.4.3.cmml">+</mo><mrow id="S7.E3.m1.4.4.4.4.4.4.2" xref="S7.E3.m1.4.4.4.4.4.4.2.cmml"><mstyle displaystyle="false" id="S7.E3.m1.4.4.4.4.4.4.2.3" xref="S7.E3.m1.4.4.4.4.4.4.2.3.cmml"><mfrac id="S7.E3.m1.4.4.4.4.4.4.2.3a" xref="S7.E3.m1.4.4.4.4.4.4.2.3.cmml"><mi id="S7.E3.m1.4.4.4.4.4.4.2.3.2" xref="S7.E3.m1.4.4.4.4.4.4.2.3.2.cmml">λ</mi><mn id="S7.E3.m1.4.4.4.4.4.4.2.3.3" xref="S7.E3.m1.4.4.4.4.4.4.2.3.3.cmml">2</mn></mfrac></mstyle><mo lspace="0em" rspace="0em" id="S7.E3.m1.4.4.4.4.4.4.2.2" xref="S7.E3.m1.4.4.4.4.4.4.2.2.cmml">​</mo><msup id="S7.E3.m1.4.4.4.4.4.4.2.1" xref="S7.E3.m1.4.4.4.4.4.4.2.1.cmml"><mrow id="S7.E3.m1.4.4.4.4.4.4.2.1.1.1" xref="S7.E3.m1.4.4.4.4.4.4.2.1.1.2.cmml"><mo id="S7.E3.m1.4.4.4.4.4.4.2.1.1.1.2" xref="S7.E3.m1.4.4.4.4.4.4.2.1.1.2.1.cmml">‖</mo><mrow id="S7.E3.m1.4.4.4.4.4.4.2.1.1.1.1" xref="S7.E3.m1.4.4.4.4.4.4.2.1.1.1.1.cmml"><msub id="S7.E3.m1.4.4.4.4.4.4.2.1.1.1.1.2" xref="S7.E3.m1.4.4.4.4.4.4.2.1.1.1.1.2.cmml"><mi id="S7.E3.m1.4.4.4.4.4.4.2.1.1.1.1.2.2" xref="S7.E3.m1.4.4.4.4.4.4.2.1.1.1.1.2.2.cmml">v</mi><mi id="S7.E3.m1.4.4.4.4.4.4.2.1.1.1.1.2.3" xref="S7.E3.m1.4.4.4.4.4.4.2.1.1.1.1.2.3.cmml">m</mi></msub><mo id="S7.E3.m1.4.4.4.4.4.4.2.1.1.1.1.1" xref="S7.E3.m1.4.4.4.4.4.4.2.1.1.1.1.1.cmml">−</mo><msup id="S7.E3.m1.4.4.4.4.4.4.2.1.1.1.1.3" xref="S7.E3.m1.4.4.4.4.4.4.2.1.1.1.1.3.cmml"><mi id="S7.E3.m1.4.4.4.4.4.4.2.1.1.1.1.3.2" xref="S7.E3.m1.4.4.4.4.4.4.2.1.1.1.1.3.2.cmml">θ</mi><mo id="S7.E3.m1.4.4.4.4.4.4.2.1.1.1.1.3.3" xref="S7.E3.m1.4.4.4.4.4.4.2.1.1.1.1.3.3.cmml">∗</mo></msup></mrow><mo id="S7.E3.m1.4.4.4.4.4.4.2.1.1.1.3" xref="S7.E3.m1.4.4.4.4.4.4.2.1.1.2.1.cmml">‖</mo></mrow><mn id="S7.E3.m1.4.4.4.4.4.4.2.1.3" xref="S7.E3.m1.4.4.4.4.4.4.2.1.3.cmml">2</mn></msup></mrow></mrow></mrow></mtd></mtr></mtable><annotation-xml encoding="MathML-Content" id="S7.E3.m1.4b"><matrix id="S7.E3.m1.4.4.cmml" xref="S7.E3.m1.4.4"><matrixrow id="S7.E3.m1.4.4a.cmml" xref="S7.E3.m1.4.4"><apply id="S7.E3.m1.4.4.4.5.1.cmml" xref="S7.E3.m1.4.4.4.5.1"><csymbol cd="ambiguous" id="S7.E3.m1.4.4.4.5.1.1.cmml" xref="S7.E3.m1.4.4.4.5.1">subscript</csymbol><min id="S7.E3.m1.4.4.4.5.1.2.cmml" xref="S7.E3.m1.4.4.4.5.1.2"></min><apply id="S7.E3.m1.4.4.4.5.1.3.cmml" xref="S7.E3.m1.4.4.4.5.1.3"><csymbol cd="ambiguous" id="S7.E3.m1.4.4.4.5.1.3.1.cmml" xref="S7.E3.m1.4.4.4.5.1.3">subscript</csymbol><ci id="S7.E3.m1.4.4.4.5.1.3.2.cmml" xref="S7.E3.m1.4.4.4.5.1.3.2">𝑣</ci><ci id="S7.E3.m1.4.4.4.5.1.3.3.cmml" xref="S7.E3.m1.4.4.4.5.1.3.3">𝑚</ci></apply></apply><apply id="S7.E3.m1.4.4.4.4.4.cmml" xref="S7.E3.m1.4.4.4.4.4"><ci id="S7.E3.m1.4.4.4.4.4.5.cmml" xref="S7.E3.m1.4.4.4.4.4.5">:</ci><apply id="S7.E3.m1.2.2.2.2.2.2.cmml" xref="S7.E3.m1.2.2.2.2.2.2"><times id="S7.E3.m1.2.2.2.2.2.2.3.cmml" xref="S7.E3.m1.2.2.2.2.2.2.3"></times><apply id="S7.E3.m1.2.2.2.2.2.2.4.cmml" xref="S7.E3.m1.2.2.2.2.2.2.4"><csymbol cd="ambiguous" id="S7.E3.m1.2.2.2.2.2.2.4.1.cmml" xref="S7.E3.m1.2.2.2.2.2.2.4">subscript</csymbol><ci id="S7.E3.m1.2.2.2.2.2.2.4.2.cmml" xref="S7.E3.m1.2.2.2.2.2.2.4.2">ℎ</ci><ci id="S7.E3.m1.2.2.2.2.2.2.4.3.cmml" xref="S7.E3.m1.2.2.2.2.2.2.4.3">𝑚</ci></apply><list id="S7.E3.m1.2.2.2.2.2.2.2.3.cmml" xref="S7.E3.m1.2.2.2.2.2.2.2.2"><apply id="S7.E3.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S7.E3.m1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S7.E3.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S7.E3.m1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S7.E3.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S7.E3.m1.1.1.1.1.1.1.1.1.1.2">𝑣</ci><ci id="S7.E3.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S7.E3.m1.1.1.1.1.1.1.1.1.1.3">𝑚</ci></apply><apply id="S7.E3.m1.2.2.2.2.2.2.2.2.2.cmml" xref="S7.E3.m1.2.2.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S7.E3.m1.2.2.2.2.2.2.2.2.2.1.cmml" xref="S7.E3.m1.2.2.2.2.2.2.2.2.2">superscript</csymbol><ci id="S7.E3.m1.2.2.2.2.2.2.2.2.2.2.cmml" xref="S7.E3.m1.2.2.2.2.2.2.2.2.2.2">𝜃</ci><times id="S7.E3.m1.2.2.2.2.2.2.2.2.2.3.cmml" xref="S7.E3.m1.2.2.2.2.2.2.2.2.2.3"></times></apply></list></apply><apply id="S7.E3.m1.4.4.4.4.4.4.cmml" xref="S7.E3.m1.4.4.4.4.4.4"><plus id="S7.E3.m1.4.4.4.4.4.4.3.cmml" xref="S7.E3.m1.4.4.4.4.4.4.3"></plus><apply id="S7.E3.m1.3.3.3.3.3.3.1.cmml" xref="S7.E3.m1.3.3.3.3.3.3.1"><times id="S7.E3.m1.3.3.3.3.3.3.1.2.cmml" xref="S7.E3.m1.3.3.3.3.3.3.1.2"></times><ci id="S7.E3.m1.3.3.3.3.3.3.1.3.cmml" xref="S7.E3.m1.3.3.3.3.3.3.1.3">𝐿</ci><apply id="S7.E3.m1.3.3.3.3.3.3.1.4.cmml" xref="S7.E3.m1.3.3.3.3.3.3.1.4"><csymbol cd="ambiguous" id="S7.E3.m1.3.3.3.3.3.3.1.4.1.cmml" xref="S7.E3.m1.3.3.3.3.3.3.1.4">subscript</csymbol><ci id="S7.E3.m1.3.3.3.3.3.3.1.4.2.cmml" xref="S7.E3.m1.3.3.3.3.3.3.1.4.2">𝐹</ci><ci id="S7.E3.m1.3.3.3.3.3.3.1.4.3.cmml" xref="S7.E3.m1.3.3.3.3.3.3.1.4.3">𝑘</ci></apply><apply id="S7.E3.m1.3.3.3.3.3.3.1.1.1.1.cmml" xref="S7.E3.m1.3.3.3.3.3.3.1.1.1"><csymbol cd="ambiguous" id="S7.E3.m1.3.3.3.3.3.3.1.1.1.1.1.cmml" xref="S7.E3.m1.3.3.3.3.3.3.1.1.1">subscript</csymbol><ci id="S7.E3.m1.3.3.3.3.3.3.1.1.1.1.2.cmml" xref="S7.E3.m1.3.3.3.3.3.3.1.1.1.1.2">𝑣</ci><ci id="S7.E3.m1.3.3.3.3.3.3.1.1.1.1.3.cmml" xref="S7.E3.m1.3.3.3.3.3.3.1.1.1.1.3">𝑚</ci></apply></apply><apply id="S7.E3.m1.4.4.4.4.4.4.2.cmml" xref="S7.E3.m1.4.4.4.4.4.4.2"><times id="S7.E3.m1.4.4.4.4.4.4.2.2.cmml" xref="S7.E3.m1.4.4.4.4.4.4.2.2"></times><apply id="S7.E3.m1.4.4.4.4.4.4.2.3.cmml" xref="S7.E3.m1.4.4.4.4.4.4.2.3"><divide id="S7.E3.m1.4.4.4.4.4.4.2.3.1.cmml" xref="S7.E3.m1.4.4.4.4.4.4.2.3"></divide><ci id="S7.E3.m1.4.4.4.4.4.4.2.3.2.cmml" xref="S7.E3.m1.4.4.4.4.4.4.2.3.2">𝜆</ci><cn type="integer" id="S7.E3.m1.4.4.4.4.4.4.2.3.3.cmml" xref="S7.E3.m1.4.4.4.4.4.4.2.3.3">2</cn></apply><apply id="S7.E3.m1.4.4.4.4.4.4.2.1.cmml" xref="S7.E3.m1.4.4.4.4.4.4.2.1"><csymbol cd="ambiguous" id="S7.E3.m1.4.4.4.4.4.4.2.1.2.cmml" xref="S7.E3.m1.4.4.4.4.4.4.2.1">superscript</csymbol><apply id="S7.E3.m1.4.4.4.4.4.4.2.1.1.2.cmml" xref="S7.E3.m1.4.4.4.4.4.4.2.1.1.1"><csymbol cd="latexml" id="S7.E3.m1.4.4.4.4.4.4.2.1.1.2.1.cmml" xref="S7.E3.m1.4.4.4.4.4.4.2.1.1.1.2">norm</csymbol><apply id="S7.E3.m1.4.4.4.4.4.4.2.1.1.1.1.cmml" xref="S7.E3.m1.4.4.4.4.4.4.2.1.1.1.1"><minus id="S7.E3.m1.4.4.4.4.4.4.2.1.1.1.1.1.cmml" xref="S7.E3.m1.4.4.4.4.4.4.2.1.1.1.1.1"></minus><apply id="S7.E3.m1.4.4.4.4.4.4.2.1.1.1.1.2.cmml" xref="S7.E3.m1.4.4.4.4.4.4.2.1.1.1.1.2"><csymbol cd="ambiguous" id="S7.E3.m1.4.4.4.4.4.4.2.1.1.1.1.2.1.cmml" xref="S7.E3.m1.4.4.4.4.4.4.2.1.1.1.1.2">subscript</csymbol><ci id="S7.E3.m1.4.4.4.4.4.4.2.1.1.1.1.2.2.cmml" xref="S7.E3.m1.4.4.4.4.4.4.2.1.1.1.1.2.2">𝑣</ci><ci id="S7.E3.m1.4.4.4.4.4.4.2.1.1.1.1.2.3.cmml" xref="S7.E3.m1.4.4.4.4.4.4.2.1.1.1.1.2.3">𝑚</ci></apply><apply id="S7.E3.m1.4.4.4.4.4.4.2.1.1.1.1.3.cmml" xref="S7.E3.m1.4.4.4.4.4.4.2.1.1.1.1.3"><csymbol cd="ambiguous" id="S7.E3.m1.4.4.4.4.4.4.2.1.1.1.1.3.1.cmml" xref="S7.E3.m1.4.4.4.4.4.4.2.1.1.1.1.3">superscript</csymbol><ci id="S7.E3.m1.4.4.4.4.4.4.2.1.1.1.1.3.2.cmml" xref="S7.E3.m1.4.4.4.4.4.4.2.1.1.1.1.3.2">𝜃</ci><times id="S7.E3.m1.4.4.4.4.4.4.2.1.1.1.1.3.3.cmml" xref="S7.E3.m1.4.4.4.4.4.4.2.1.1.1.1.3.3"></times></apply></apply></apply><cn type="integer" id="S7.E3.m1.4.4.4.4.4.4.2.1.3.cmml" xref="S7.E3.m1.4.4.4.4.4.4.2.1.3">2</cn></apply></apply></apply></apply></matrixrow></matrix></annotation-xml><annotation encoding="application/x-tex" id="S7.E3.m1.4c">\begin{array}[]{cl}\min_{v_{m}}&amp;h_{m}\left(v_{m};\theta^{*}\right):LF_{k}\left(v_{m}\right)+\frac{\lambda}{2}\left\|v_{m}-\theta^{*}\right\|^{2}\\
\end{array}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
</div>
<div id="S7.SS2.p4" class="ltx_para">
<p id="S7.SS2.p4.1" class="ltx_p">In this case, the hyperparameter governs the balance between the global model and local models.
If the hyperparameter value is assigned to zero, Ditto is limited to training only the local models. In the contrary, when the hyperparameter value is assigned to a large value, it manages to recover the global model objective.</p>
</div>
<div id="S7.SS2.p5" class="ltx_para">
<p id="S7.SS2.p5.1" class="ltx_p">To investigate Ditto’s fairness, it was compared to TERM (Tilted Empirical Risk Minimization) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib95" title="" class="ltx_ref">95</a>]</cite>, which is an updates version of the q-FFL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib97" title="" class="ltx_ref">97</a>]</cite> objective for fair federated learning. TERM can be used for enforcing subgroup fairness, mitigating the impact of outliers, and dealing with class imbalance. To provide flexible trade-offs between fairness and accuracy, TERM employs a parameter t. Positive values of t can help promote fairness (for example, by learning fair representations) and provide variance reduction for better generalization.
<br class="ltx_break"><span id="S7.SS2.p5.1.1" class="ltx_text ltx_font_bold">Collaborative Fairness.</span>
Collaborative Fairness refers to a sort of distributed fairness notion that puts emphasis on the idea that a client’s compensation should be in accordance with its contribution to an FL system. This notion, however, is not concerned with improving the accuracy of the model. A highly contributing participant, according to this notion of fairness, should be given greater rewards and they may be rewarded with a better-performing local model.</p>
</div>
<div id="S7.SS2.p6" class="ltx_para">
<p id="S7.SS2.p6.7" class="ltx_p">For <math id="S7.SS2.p6.1.m1.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S7.SS2.p6.1.m1.1a"><mi id="S7.SS2.p6.1.m1.1.1" xref="S7.SS2.p6.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S7.SS2.p6.1.m1.1b"><ci id="S7.SS2.p6.1.m1.1.1.cmml" xref="S7.SS2.p6.1.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.p6.1.m1.1c">N</annotation></semantics></math> number of total participating clients, let <math id="S7.SS2.p6.2.m2.1" class="ltx_Math" alttext="w_{i}" display="inline"><semantics id="S7.SS2.p6.2.m2.1a"><msub id="S7.SS2.p6.2.m2.1.1" xref="S7.SS2.p6.2.m2.1.1.cmml"><mi id="S7.SS2.p6.2.m2.1.1.2" xref="S7.SS2.p6.2.m2.1.1.2.cmml">w</mi><mi id="S7.SS2.p6.2.m2.1.1.3" xref="S7.SS2.p6.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S7.SS2.p6.2.m2.1b"><apply id="S7.SS2.p6.2.m2.1.1.cmml" xref="S7.SS2.p6.2.m2.1.1"><csymbol cd="ambiguous" id="S7.SS2.p6.2.m2.1.1.1.cmml" xref="S7.SS2.p6.2.m2.1.1">subscript</csymbol><ci id="S7.SS2.p6.2.m2.1.1.2.cmml" xref="S7.SS2.p6.2.m2.1.1.2">𝑤</ci><ci id="S7.SS2.p6.2.m2.1.1.3.cmml" xref="S7.SS2.p6.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.p6.2.m2.1c">w_{i}</annotation></semantics></math> be the model’s weight after being trained at a client <math id="S7.SS2.p6.3.m3.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S7.SS2.p6.3.m3.1a"><mi id="S7.SS2.p6.3.m3.1.1" xref="S7.SS2.p6.3.m3.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S7.SS2.p6.3.m3.1b"><ci id="S7.SS2.p6.3.m3.1.1.cmml" xref="S7.SS2.p6.3.m3.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.p6.3.m3.1c">i</annotation></semantics></math>. At the end of round <math id="S7.SS2.p6.4.m4.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S7.SS2.p6.4.m4.1a"><mi id="S7.SS2.p6.4.m4.1.1" xref="S7.SS2.p6.4.m4.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S7.SS2.p6.4.m4.1b"><ci id="S7.SS2.p6.4.m4.1.1.cmml" xref="S7.SS2.p6.4.m4.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.p6.4.m4.1c">t</annotation></semantics></math>, the FL system’s contribution from client <math id="S7.SS2.p6.5.m5.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S7.SS2.p6.5.m5.1a"><mi id="S7.SS2.p6.5.m5.1.1" xref="S7.SS2.p6.5.m5.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S7.SS2.p6.5.m5.1b"><ci id="S7.SS2.p6.5.m5.1.1.cmml" xref="S7.SS2.p6.5.m5.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.p6.5.m5.1c">i</annotation></semantics></math>, if <math id="S7.SS2.p6.6.m6.1" class="ltx_Math" alttext="G(w_{t}^{i})" display="inline"><semantics id="S7.SS2.p6.6.m6.1a"><mrow id="S7.SS2.p6.6.m6.1.1" xref="S7.SS2.p6.6.m6.1.1.cmml"><mi id="S7.SS2.p6.6.m6.1.1.3" xref="S7.SS2.p6.6.m6.1.1.3.cmml">G</mi><mo lspace="0em" rspace="0em" id="S7.SS2.p6.6.m6.1.1.2" xref="S7.SS2.p6.6.m6.1.1.2.cmml">​</mo><mrow id="S7.SS2.p6.6.m6.1.1.1.1" xref="S7.SS2.p6.6.m6.1.1.1.1.1.cmml"><mo stretchy="false" id="S7.SS2.p6.6.m6.1.1.1.1.2" xref="S7.SS2.p6.6.m6.1.1.1.1.1.cmml">(</mo><msubsup id="S7.SS2.p6.6.m6.1.1.1.1.1" xref="S7.SS2.p6.6.m6.1.1.1.1.1.cmml"><mi id="S7.SS2.p6.6.m6.1.1.1.1.1.2.2" xref="S7.SS2.p6.6.m6.1.1.1.1.1.2.2.cmml">w</mi><mi id="S7.SS2.p6.6.m6.1.1.1.1.1.2.3" xref="S7.SS2.p6.6.m6.1.1.1.1.1.2.3.cmml">t</mi><mi id="S7.SS2.p6.6.m6.1.1.1.1.1.3" xref="S7.SS2.p6.6.m6.1.1.1.1.1.3.cmml">i</mi></msubsup><mo stretchy="false" id="S7.SS2.p6.6.m6.1.1.1.1.3" xref="S7.SS2.p6.6.m6.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S7.SS2.p6.6.m6.1b"><apply id="S7.SS2.p6.6.m6.1.1.cmml" xref="S7.SS2.p6.6.m6.1.1"><times id="S7.SS2.p6.6.m6.1.1.2.cmml" xref="S7.SS2.p6.6.m6.1.1.2"></times><ci id="S7.SS2.p6.6.m6.1.1.3.cmml" xref="S7.SS2.p6.6.m6.1.1.3">𝐺</ci><apply id="S7.SS2.p6.6.m6.1.1.1.1.1.cmml" xref="S7.SS2.p6.6.m6.1.1.1.1"><csymbol cd="ambiguous" id="S7.SS2.p6.6.m6.1.1.1.1.1.1.cmml" xref="S7.SS2.p6.6.m6.1.1.1.1">superscript</csymbol><apply id="S7.SS2.p6.6.m6.1.1.1.1.1.2.cmml" xref="S7.SS2.p6.6.m6.1.1.1.1"><csymbol cd="ambiguous" id="S7.SS2.p6.6.m6.1.1.1.1.1.2.1.cmml" xref="S7.SS2.p6.6.m6.1.1.1.1">subscript</csymbol><ci id="S7.SS2.p6.6.m6.1.1.1.1.1.2.2.cmml" xref="S7.SS2.p6.6.m6.1.1.1.1.1.2.2">𝑤</ci><ci id="S7.SS2.p6.6.m6.1.1.1.1.1.2.3.cmml" xref="S7.SS2.p6.6.m6.1.1.1.1.1.2.3">𝑡</ci></apply><ci id="S7.SS2.p6.6.m6.1.1.1.1.1.3.cmml" xref="S7.SS2.p6.6.m6.1.1.1.1.1.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.p6.6.m6.1c">G(w_{t}^{i})</annotation></semantics></math> is the gain from client <math id="S7.SS2.p6.7.m7.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S7.SS2.p6.7.m7.1a"><mi id="S7.SS2.p6.7.m7.1.1" xref="S7.SS2.p6.7.m7.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S7.SS2.p6.7.m7.1b"><ci id="S7.SS2.p6.7.m7.1.1.cmml" xref="S7.SS2.p6.7.m7.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.p6.7.m7.1c">i</annotation></semantics></math> becomes:</p>
<table id="S7.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S7.E4.m1.2" class="ltx_Math" alttext="P_{i}=\frac{G(w_{t}^{i})}{\displaystyle\sum\limits_{i=1}^{N}G(w_{t}^{j})}" display="block"><semantics id="S7.E4.m1.2a"><mrow id="S7.E4.m1.2.3" xref="S7.E4.m1.2.3.cmml"><msub id="S7.E4.m1.2.3.2" xref="S7.E4.m1.2.3.2.cmml"><mi id="S7.E4.m1.2.3.2.2" xref="S7.E4.m1.2.3.2.2.cmml">P</mi><mi id="S7.E4.m1.2.3.2.3" xref="S7.E4.m1.2.3.2.3.cmml">i</mi></msub><mo id="S7.E4.m1.2.3.1" xref="S7.E4.m1.2.3.1.cmml">=</mo><mfrac id="S7.E4.m1.2.2" xref="S7.E4.m1.2.2.cmml"><mrow id="S7.E4.m1.1.1.1" xref="S7.E4.m1.1.1.1.cmml"><mi id="S7.E4.m1.1.1.1.3" xref="S7.E4.m1.1.1.1.3.cmml">G</mi><mo lspace="0em" rspace="0em" id="S7.E4.m1.1.1.1.2" xref="S7.E4.m1.1.1.1.2.cmml">​</mo><mrow id="S7.E4.m1.1.1.1.1.1" xref="S7.E4.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S7.E4.m1.1.1.1.1.1.2" xref="S7.E4.m1.1.1.1.1.1.1.cmml">(</mo><msubsup id="S7.E4.m1.1.1.1.1.1.1" xref="S7.E4.m1.1.1.1.1.1.1.cmml"><mi id="S7.E4.m1.1.1.1.1.1.1.2.2" xref="S7.E4.m1.1.1.1.1.1.1.2.2.cmml">w</mi><mi id="S7.E4.m1.1.1.1.1.1.1.2.3" xref="S7.E4.m1.1.1.1.1.1.1.2.3.cmml">t</mi><mi id="S7.E4.m1.1.1.1.1.1.1.3" xref="S7.E4.m1.1.1.1.1.1.1.3.cmml">i</mi></msubsup><mo stretchy="false" id="S7.E4.m1.1.1.1.1.1.3" xref="S7.E4.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mrow id="S7.E4.m1.2.2.2" xref="S7.E4.m1.2.2.2.cmml"><mstyle displaystyle="true" id="S7.E4.m1.2.2.2.2" xref="S7.E4.m1.2.2.2.2.cmml"><munderover id="S7.E4.m1.2.2.2.2a" xref="S7.E4.m1.2.2.2.2.cmml"><mo movablelimits="false" id="S7.E4.m1.2.2.2.2.2.2" xref="S7.E4.m1.2.2.2.2.2.2.cmml">∑</mo><mrow id="S7.E4.m1.2.2.2.2.2.3" xref="S7.E4.m1.2.2.2.2.2.3.cmml"><mi id="S7.E4.m1.2.2.2.2.2.3.2" xref="S7.E4.m1.2.2.2.2.2.3.2.cmml">i</mi><mo id="S7.E4.m1.2.2.2.2.2.3.1" xref="S7.E4.m1.2.2.2.2.2.3.1.cmml">=</mo><mn id="S7.E4.m1.2.2.2.2.2.3.3" xref="S7.E4.m1.2.2.2.2.2.3.3.cmml">1</mn></mrow><mi id="S7.E4.m1.2.2.2.2.3" xref="S7.E4.m1.2.2.2.2.3.cmml">N</mi></munderover></mstyle><mrow id="S7.E4.m1.2.2.2.1" xref="S7.E4.m1.2.2.2.1.cmml"><mi id="S7.E4.m1.2.2.2.1.3" xref="S7.E4.m1.2.2.2.1.3.cmml">G</mi><mo lspace="0em" rspace="0em" id="S7.E4.m1.2.2.2.1.2" xref="S7.E4.m1.2.2.2.1.2.cmml">​</mo><mrow id="S7.E4.m1.2.2.2.1.1.1" xref="S7.E4.m1.2.2.2.1.1.1.1.cmml"><mo stretchy="false" id="S7.E4.m1.2.2.2.1.1.1.2" xref="S7.E4.m1.2.2.2.1.1.1.1.cmml">(</mo><msubsup id="S7.E4.m1.2.2.2.1.1.1.1" xref="S7.E4.m1.2.2.2.1.1.1.1.cmml"><mi id="S7.E4.m1.2.2.2.1.1.1.1.2.2" xref="S7.E4.m1.2.2.2.1.1.1.1.2.2.cmml">w</mi><mi id="S7.E4.m1.2.2.2.1.1.1.1.2.3" xref="S7.E4.m1.2.2.2.1.1.1.1.2.3.cmml">t</mi><mi id="S7.E4.m1.2.2.2.1.1.1.1.3" xref="S7.E4.m1.2.2.2.1.1.1.1.3.cmml">j</mi></msubsup><mo stretchy="false" id="S7.E4.m1.2.2.2.1.1.1.3" xref="S7.E4.m1.2.2.2.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S7.E4.m1.2b"><apply id="S7.E4.m1.2.3.cmml" xref="S7.E4.m1.2.3"><eq id="S7.E4.m1.2.3.1.cmml" xref="S7.E4.m1.2.3.1"></eq><apply id="S7.E4.m1.2.3.2.cmml" xref="S7.E4.m1.2.3.2"><csymbol cd="ambiguous" id="S7.E4.m1.2.3.2.1.cmml" xref="S7.E4.m1.2.3.2">subscript</csymbol><ci id="S7.E4.m1.2.3.2.2.cmml" xref="S7.E4.m1.2.3.2.2">𝑃</ci><ci id="S7.E4.m1.2.3.2.3.cmml" xref="S7.E4.m1.2.3.2.3">𝑖</ci></apply><apply id="S7.E4.m1.2.2.cmml" xref="S7.E4.m1.2.2"><divide id="S7.E4.m1.2.2.3.cmml" xref="S7.E4.m1.2.2"></divide><apply id="S7.E4.m1.1.1.1.cmml" xref="S7.E4.m1.1.1.1"><times id="S7.E4.m1.1.1.1.2.cmml" xref="S7.E4.m1.1.1.1.2"></times><ci id="S7.E4.m1.1.1.1.3.cmml" xref="S7.E4.m1.1.1.1.3">𝐺</ci><apply id="S7.E4.m1.1.1.1.1.1.1.cmml" xref="S7.E4.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S7.E4.m1.1.1.1.1.1.1.1.cmml" xref="S7.E4.m1.1.1.1.1.1">superscript</csymbol><apply id="S7.E4.m1.1.1.1.1.1.1.2.cmml" xref="S7.E4.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S7.E4.m1.1.1.1.1.1.1.2.1.cmml" xref="S7.E4.m1.1.1.1.1.1">subscript</csymbol><ci id="S7.E4.m1.1.1.1.1.1.1.2.2.cmml" xref="S7.E4.m1.1.1.1.1.1.1.2.2">𝑤</ci><ci id="S7.E4.m1.1.1.1.1.1.1.2.3.cmml" xref="S7.E4.m1.1.1.1.1.1.1.2.3">𝑡</ci></apply><ci id="S7.E4.m1.1.1.1.1.1.1.3.cmml" xref="S7.E4.m1.1.1.1.1.1.1.3">𝑖</ci></apply></apply><apply id="S7.E4.m1.2.2.2.cmml" xref="S7.E4.m1.2.2.2"><apply id="S7.E4.m1.2.2.2.2.cmml" xref="S7.E4.m1.2.2.2.2"><csymbol cd="ambiguous" id="S7.E4.m1.2.2.2.2.1.cmml" xref="S7.E4.m1.2.2.2.2">superscript</csymbol><apply id="S7.E4.m1.2.2.2.2.2.cmml" xref="S7.E4.m1.2.2.2.2"><csymbol cd="ambiguous" id="S7.E4.m1.2.2.2.2.2.1.cmml" xref="S7.E4.m1.2.2.2.2">subscript</csymbol><sum id="S7.E4.m1.2.2.2.2.2.2.cmml" xref="S7.E4.m1.2.2.2.2.2.2"></sum><apply id="S7.E4.m1.2.2.2.2.2.3.cmml" xref="S7.E4.m1.2.2.2.2.2.3"><eq id="S7.E4.m1.2.2.2.2.2.3.1.cmml" xref="S7.E4.m1.2.2.2.2.2.3.1"></eq><ci id="S7.E4.m1.2.2.2.2.2.3.2.cmml" xref="S7.E4.m1.2.2.2.2.2.3.2">𝑖</ci><cn type="integer" id="S7.E4.m1.2.2.2.2.2.3.3.cmml" xref="S7.E4.m1.2.2.2.2.2.3.3">1</cn></apply></apply><ci id="S7.E4.m1.2.2.2.2.3.cmml" xref="S7.E4.m1.2.2.2.2.3">𝑁</ci></apply><apply id="S7.E4.m1.2.2.2.1.cmml" xref="S7.E4.m1.2.2.2.1"><times id="S7.E4.m1.2.2.2.1.2.cmml" xref="S7.E4.m1.2.2.2.1.2"></times><ci id="S7.E4.m1.2.2.2.1.3.cmml" xref="S7.E4.m1.2.2.2.1.3">𝐺</ci><apply id="S7.E4.m1.2.2.2.1.1.1.1.cmml" xref="S7.E4.m1.2.2.2.1.1.1"><csymbol cd="ambiguous" id="S7.E4.m1.2.2.2.1.1.1.1.1.cmml" xref="S7.E4.m1.2.2.2.1.1.1">superscript</csymbol><apply id="S7.E4.m1.2.2.2.1.1.1.1.2.cmml" xref="S7.E4.m1.2.2.2.1.1.1"><csymbol cd="ambiguous" id="S7.E4.m1.2.2.2.1.1.1.1.2.1.cmml" xref="S7.E4.m1.2.2.2.1.1.1">subscript</csymbol><ci id="S7.E4.m1.2.2.2.1.1.1.1.2.2.cmml" xref="S7.E4.m1.2.2.2.1.1.1.1.2.2">𝑤</ci><ci id="S7.E4.m1.2.2.2.1.1.1.1.2.3.cmml" xref="S7.E4.m1.2.2.2.1.1.1.1.2.3">𝑡</ci></apply><ci id="S7.E4.m1.2.2.2.1.1.1.1.3.cmml" xref="S7.E4.m1.2.2.2.1.1.1.1.3">𝑗</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.E4.m1.2c">P_{i}=\frac{G(w_{t}^{i})}{\displaystyle\sum\limits_{i=1}^{N}G(w_{t}^{j})}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
</div>
<div id="S7.SS2.p7" class="ltx_para">
<p id="S7.SS2.p7.1" class="ltx_p">Regardless of contributions, the majority of works in FL let all parties obtain the same model during and at the end of each communication cycle. But practically, not all participants contribute equally for numerous reasons such as varying types and quantities of data that each member contains, and due to the differences in system and computational capacities of each participant.
As a result, although updates from some participants may improve the model, updates from others may potentially worsen the model’s performance. The fact that everyone has access to the same global model at the conclusion of the partnership, irrespective of their contributions is unfair and in a worst-case scenario, even free-riders may join the system and unjustly make use of the global model.
The absence of fairness could make robust parties exhibit a reduced willingness to participate.</p>
</div>
<div id="S7.SS2.p8" class="ltx_para">
<p id="S7.SS2.p8.1" class="ltx_p">Two difficulties and questions must be resolved in order to apply this notion, such as:</p>
<ul id="S7.I1" class="ltx_itemize">
<li id="S7.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S7.I1.i1.p1" class="ltx_para">
<p id="S7.I1.i1.p1.1" class="ltx_p">How to quantify an agent’s contribution to an FL system?</p>
</div>
</li>
<li id="S7.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S7.I1.i2.p1" class="ltx_para">
<p id="S7.I1.i2.p1.1" class="ltx_p">What kind of compensation should be given to the agents in order to accomplish fairness in proportion to their contribution?</p>
</div>
</li>
</ul>
</div>
<div id="S7.SS2.p9" class="ltx_para">
<p id="S7.SS2.p9.1" class="ltx_p">The current ways of evaluating FL contributions may be classified into the following types:
1) Self-Addressed data, 2) Individualized Assessment, 3) Shapley Value (SV), 4) Utility game, 5) Empirical Approach, and 6) Leave-Out-One method.
<br class="ltx_break"><span id="S7.SS2.p9.1.1" class="ltx_text ltx_font_bold">Self-Addressed Data.</span>
Here, client contributions are assessed based on the data provided by themselves. Information about their local datasets’ quality, quantity, collecting expenses, computational and communication resources that they pledge to FL are included in this information. These approaches make the assumption that customers are competent and reliable enough to accurately analyze their own circumstances and report the facts. However, this presumption is not applicable in practical scenarios. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib161" title="" class="ltx_ref">161</a>]</cite> requires data owners to disclose publicly verifiable parameters about individual local datasets to the FL server (e.g., data quality and quantity, data collecting cost, etc.). Afterward, the server assigns scores to the clients based on the provided data. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib150" title="" class="ltx_ref">150</a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib82" title="" class="ltx_ref">82</a>]</cite> employ self-reported information to design an FL incentive system based on Contract Theory <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib111" title="" class="ltx_ref">111</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib82" title="" class="ltx_ref">82</a>]</cite> in which the server synthesizes contract items and distributes them to data owners. Each contracted item includes the incentives as well as information on the clients’ local data. 
<br class="ltx_break"><span id="S7.SS2.p9.1.2" class="ltx_text ltx_font_bold">Individualized Assessment.</span> Individualized assessment methodologies prioritize individual performance over the overall FL model performance and it assesses a client’s contribution based on its success in individual activities. A reputation system is commonly employed to maintain track of an FL participant’s past participation. Client selection and incentive distribution methods might benefit from reputation procedures that represent the participant’s dependability and participation. Individual assessment techniques frequently use two assumptions: 1) FL server and the FL clients both can be equally trusted, and 2) a participant with a local model comparable to models from other participants (or with the global model) is regarded to contribute more. In actuality, these two assumptions may not hold true as it is established that the server and clients in FL can misbehave and can be greedy. Furthermore, in non-IID situations, clients often possess data with diverse or varying class distributions. 
<br class="ltx_break"><span id="S7.SS2.p9.1.3" class="ltx_text ltx_font_bold">Shapley Value.</span> Shapley Value (SV) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite>, an extremely computationally inefficient method with complexity O(N!), is a traditional method in cooperative game theory for allocating total profits produced by a group of players. Data Shapley is used to quantify data evaluation and machine learning training and it may be possible to use it to estimate the size of an agent’s contribution <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib132" title="" class="ltx_ref">132</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib236" title="" class="ltx_ref">236</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib194" title="" class="ltx_ref">194</a>]</cite>. A datums’ Shapley value is determined by averaging its marginal performance over all remaining subsets of data. The contribution of the agent may then be determined by adding up the Shapley value of all of its data. The Shapley value of an agent for a predetermined learning task might vary depending on the model that is selected and consequently, data Shapley becomes an unreliable indicator of an agent’s contribution to a given federated learning assignment. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib180" title="" class="ltx_ref">180</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib181" title="" class="ltx_ref">181</a>]</cite> uses an approach that uses Shapley Values to provide precise feature significance for host features and a unified important value for federated guest features, balancing the model interpretability and data privacy in vertical federated learning. Hence, due to perceived unfair treatment, Shapley value-based reward systems sometimes can cause the self-interested agents to quit the partnership. 
<br class="ltx_break"><span id="S7.SS2.p9.1.4" class="ltx_text ltx_font_bold">Utility Game.</span> Utility game-based Federated Learning approaches for evaluating contributions are closely connected to profit-sharing systems, which are sets of rules that translate the usefulness that players contribute into incentives. There are three popular profit-sharing programs:</p>
<ol id="S7.I2" class="ltx_enumerate">
<li id="S7.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S7.I2.i1.p1" class="ltx_para">
<p id="S7.I2.i1.p1.1" class="ltx_p"><span id="S7.I2.i1.p1.1.1" class="ltx_text ltx_font_bold">Egalitarian:</span> Each unit of utility created by a team is distributed equally among the team members.</p>
</div>
</li>
<li id="S7.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S7.I2.i2.p1" class="ltx_para">
<p id="S7.I2.i2.p1.1" class="ltx_p"><span id="S7.I2.i2.p1.1.1" class="ltx_text ltx_font_bold">Marginal Gain:</span> A participant’s reward is equal to the utility the team acquired when they joined the team.</p>
</div>
</li>
<li id="S7.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S7.I2.i3.p1" class="ltx_para">
<p id="S7.I2.i3.p1.1" class="ltx_p"><span id="S7.I2.i3.p1.1.1" class="ltx_text ltx_font_bold">Marginal Loss:</span> A participant’s payoff is equal to the utility they lost when they left the team.</p>
</div>
</li>
</ol>
</div>
<div id="S7.SS2.p10" class="ltx_para">
<p id="S7.SS2.p10.1" class="ltx_p">Among the three, the marginal loss scheme is the most widely utilized strategy in FL. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib187" title="" class="ltx_ref">187</a>]</cite> used the marginal loss technique to calculate the contributions of various stakeholders in Horizontal Federated Learning(HFL). The influence measurements are implemented using an approximation approach. To decrease communication and computation costs, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib135" title="" class="ltx_ref">135</a>]</cite> used a marginal loss approach to quantify the client contribution within a single FL training phase. 
<br class="ltx_break"><span id="S7.SS2.p10.1.1" class="ltx_text ltx_font_bold">Empiritical Approach.</span> Shapley Value, a data-based contribution assessment method, has generated encouraging results for FL contribution evaluation. Its promising scalability is hindered by its high processing costs and imprecision due to estimation. FedCCEA, proposed by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib164" title="" class="ltx_ref">164</a>]</cite>, learns the data quality of each customer by building an Accuracy Approximation Model (AAM) using sampling data size. This technique approximates the client’s contribution reliably and efficiently by utilizing the sampled data size, and it allows clients to participate by specifying the desired sizes of local data to be utilized during training. FedCCEA is now confined to simple FL tasks since AAM is built on a fairly rudimentary neural network architecture, rendering it less suitable for practical applications. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib226" title="" class="ltx_ref">226</a>]</cite> suggested using publicly verifiable characteristics of agents, such as task-related data volume, data range, data collecting cost, etc., to quantify participating agent contributions. And in terms of fair incentives, proportional reward scheme was suggested, in which agents judged more valuable receive more model updates. 
<br class="ltx_break"><span id="S7.SS2.p10.1.2" class="ltx_text ltx_font_bold">Leave-Out-One Method.</span> The Leave-Out-One(LOO) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib69" title="" class="ltx_ref">69</a>]</cite> approach quantifies the level of variance in a model’s performance or predictions if that datum was not utilized during training. The duplicate of a datum is assigned a zero value using the LOO technique. If two agents have the same data, the additional data is considered to have no value. Additionally, the LOO approach, similar to Shapley values is model-dependent. FL incentive schemes frequently use this notion to drive reward distribution and various works exist to solve this issue.</p>
</div>
<div id="S7.SS2.p11" class="ltx_para">
<p id="S7.SS2.p11.1" class="ltx_p">Collaborative Fair Federated Learning (CFFL) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib117" title="" class="ltx_ref">117</a>]</cite> uses reputation to push participants to converge to distinct models in order to achieve fairness without jeopardizing the predictive performance. A reputation list for each participant is maintained by the server in the CFFL framework, and it is updated based on how well each member’s gradients are uploaded throughout each communication cycle. Similarly, in order to accomplish collaborative fairness and adversarial robustness concurrently via a reputation system, Robust and Fair Federated Learning (RFFL) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib201" title="" class="ltx_ref">201</a>]</cite> assessed each participant’s contributions through their uploaded gradients (using vector similarity), and maintains a reputation for each participant and finds non-contributing or malicious players to be eliminated. Based on elements that may be publicly verified, such as data volume and quality, they identified agents’ contributions. Later, they created the Hierarchical Federated Learning framework, or HFL, which supports the idea of fairness since it rewards agents in accordance with their previously agreed-upon contribution levels. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib210" title="" class="ltx_ref">210</a>]</cite> formulated the payoff-sharing Federated Learning Incentivizer (FLI) system. By jointly maximizing the collective utility and reducing the inequality among the servers in terms of the payout earned and the waiting time for getting compensation, the strategy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib234" title="" class="ltx_ref">234</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib174" title="" class="ltx_ref">174</a>]</cite> dynamically allocates a given budget among the servers in a context-aware way. Fair and Differentially Private De-centralized Deep Learning framework enables collaborative fairness in collaborative learning (FDPDDL) as they used a unique two-stage reputation system, using digital tokens, local credibility, and differential privacy to assure justice and privacy. To mitigate privacy leakage, Differentially Private GAN (DPGAN) in the initialization stage and Differentially Private Stochastic Gradient Descent (DPSGD) in the update stage were used respectively.</p>
</div>
</section>
<section id="S7.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.3 </span><span id="S7.SS3.1.1" class="ltx_text ltx_font_italic">Client Selection</span>
</h3>

<div id="S7.SS3.p1" class="ltx_para">
<p id="S7.SS3.p1.1" class="ltx_p">By giving underrepresented or unrepresented customers a better chance to participate, this idea of fairness seeks to reduce the bias in an FL model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib238" title="" class="ltx_ref">238</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib70" title="" class="ltx_ref">70</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib239" title="" class="ltx_ref">239</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib66" title="" class="ltx_ref">66</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib67" title="" class="ltx_ref">67</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib151" title="" class="ltx_ref">151</a>]</cite>,
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib161" title="" class="ltx_ref">161</a>]</cite> achieved this by setting specific requirements such as long-term fairness constraints.
Unfairness may occur during the client selection step. Most of the existing works for client selection in FL hardly take the server’s interest into account. This may include factors such as increased convergence speed, or improved model performance. These works act in favor of clients who can reply fast or who can enhance the performance of the system overall and customers with lower capacities could not be allowed to participate in the FL system. Consequently, the likelihood of two things is lessened namely, a) the likelihood that weaker customers will receive a model that accurately represents their local data and (b) the likelihood that weaker customers will benefit from any associated incentives. From the global model’s standpoint, the final model might not generalize effectively since the omitted clients might have samples uncovered by the current model. FedMarl <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib229" title="" class="ltx_ref">229</a>]</cite>, an FL framework that depends on trained Multi-Agent Reinforcement Learning (MARL) agents to carry out effective client selection as it tackles control issues.</p>
</div>
<div id="S7.SS3.p2" class="ltx_para">
<p id="S7.SS3.p2.1" class="ltx_p">In the FedMarl <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib229" title="" class="ltx_ref">229</a>]</cite> procedure, three building blocks make up the central server: the Model storage block, which stores and updates the global DNN model, the MARL block, which runs the trained MARL agents and determines which clients to select, and the Statistics collection block, which collects data on client device statistics like processing latency and communication latency. The following steps constitute the workflow:</p>
</div>
<div id="S7.SS3.p3" class="ltx_para">
<ol id="S7.I3" class="ltx_enumerate">
<li id="S7.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S7.I3.i1.p1" class="ltx_para">
<p id="S7.I3.i1.p1.1" class="ltx_p"><span id="S7.I3.i1.p1.1.1" class="ltx_text ltx_font_bold">Step 1:</span> N client devices are selected from the client device pool for each training cycle.</p>
</div>
</li>
<li id="S7.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S7.I3.i2.p1" class="ltx_para">
<p id="S7.I3.i2.p1.1" class="ltx_p"><span id="S7.I3.i2.p1.1.1" class="ltx_text ltx_font_bold">Step 2:</span> The global Deep Neural Network(DNN) model is then copied to all the devices specified in the Model storage block.</p>
</div>
</li>
<li id="S7.I3.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S7.I3.i3.p1" class="ltx_para">
<p id="S7.I3.i3.p1.1" class="ltx_p"><span id="S7.I3.i3.p1.1.1" class="ltx_text ltx_font_bold">Step 3:</span> After doing the probing training, the client devices submit their probing losses to the MARL block.</p>
</div>
</li>
<li id="S7.I3.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="S7.I3.i4.p1" class="ltx_para">
<p id="S7.I3.i4.p1.1" class="ltx_p"><span id="S7.I3.i4.p1.1.1" class="ltx_text ltx_font_bold">Step 4:</span> Meanwhile, the client devices send the Statistics collection block their probing training latencies.</p>
</div>
</li>
<li id="S7.I3.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">5.</span> 
<div id="S7.I3.i5.p1" class="ltx_para">
<p id="S7.I3.i5.p1.1" class="ltx_p"><span id="S7.I3.i5.p1.1.1" class="ltx_text ltx_font_bold">Step 5:</span> After receiving all probing losses from clients, MARL agents combine these losses with historical data from the Statistics collecting block.</p>
</div>
</li>
<li id="S7.I3.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">6.</span> 
<div id="S7.I3.i6.p1" class="ltx_para">
<p id="S7.I3.i6.p1.1" class="ltx_p"><span id="S7.I3.i6.p1.1.1" class="ltx_text ltx_font_bold">Step 6:</span> The client selection decisions are made in this step</p>
</div>
</li>
<li id="S7.I3.i7" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">7.</span> 
<div id="S7.I3.i7.p1" class="ltx_para">
<p id="S7.I3.i7.p1.1" class="ltx_p"><span id="S7.I3.i7.p1.1.1" class="ltx_text ltx_font_bold">Step 7:</span> The chosen client devices then locally complete the remaining training and transmit the model parameters or weights to the Model storage block which applies the weight changes to the global DNN model.</p>
</div>
</li>
</ol>
</div>
<div id="S7.SS3.p4" class="ltx_para">
<p id="S7.SS3.p4.1" class="ltx_p">FedCS <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib135" title="" class="ltx_ref">135</a>]</cite>, a client-selection problem, which can efficiently operate FL while a mobile edge computing(MEC) framework operator actively controls the resources of diverse clients. This system considers the client’s computational resource restrictions, which they solved in a greedy fashion. FedCS, in particular, establishes a deadline for clients to perform operations such as downloading, updating, and uploading ML models. The operator then picks clients so that the global model may combine as many model updates as feasible in constrained time periods, making the whole training process more efficient and reducing the time necessary to train ML models. This process defines how many clients engage in the training process and when each client needs to complete the process.
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> presents POWER-OF-CHOICE, a client selection procedure that can flexibly balance between convergence speed and solution bias and quantified how the selection bias directly or indirectly influences the convergence speed of a Federated model. POWER-OF-CHOICE techniques converge up to three times quicker and provide 10% greater test accuracy than random selection. They presented the first federated optimization convergence study for biased client selection techniques and demonstrated how biased client selection works leads to faster error convergence when it works in favor of clients with larger local loss. In order to enhance learning performance, customers should be selected wisely by inspecting the correlations between their data. They proposed a context-aware Neural Contextual Combinatorial Bandit method(NCCB), that respects the combinatorial restrictions given by federated learning while tactfully handling the link between the extracted attributes and rewards. Their selection technique is divided into two parts: context feature extraction and client selection. To retain the correlation link among clients and decrease the profile space, separate clusters are initially generated based on these feature vectors in the client selection section. Oort <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib93" title="" class="ltx_ref">93</a>]</cite>, a typical multi-armed bandit problem, tackles the client selection issue without depending on contextual knowledge. It rather depends on local client training to estimate the local data quality, resulting in a protracted convergence time. Thus, Oort prioritizes clients who possess the ability of fast training and good quality data in order to facilitate model accuracy. CS-UCB-Q algorithm <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib196" title="" class="ltx_ref">196</a>]</cite>, based on UCB policy and virtual queue approach, tries to guarantee that each client can partake in training during a specified proportion of the communication rounds for dealing with cases of data present in a non-IID situation and imbalanced datasets. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib182" title="" class="ltx_ref">182</a>]</cite> introduced FAVOR, which employs a reinforcement learning method for device selection in addition to bandit-based techniques.</p>
</div>
<figure id="S7.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE III: </span><span id="S7.T3.2.1" class="ltx_text ltx_font_bold">Various Fairness Notions in FL.</span></figcaption>
<div id="S7.T3.3" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:352.5pt;height:438pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-19.6pt,24.3pt) scale(0.9,0.9) ;">
<table id="S7.T3.3.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S7.T3.3.1.1.1" class="ltx_tr">
<th id="S7.T3.3.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T3.3.1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T3.3.1.1.1.1.1.1" class="ltx_p" style="width:113.8pt;"><span id="S7.T3.3.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Fairness Notion</span></span>
</span>
</th>
<th id="S7.T3.3.1.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T3.3.1.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T3.3.1.1.1.2.1.1" class="ltx_p" style="width:170.7pt;"><span id="S7.T3.3.1.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Main Idea</span></span>
</span>
</th>
<th id="S7.T3.3.1.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T3.3.1.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T3.3.1.1.1.3.1.1" class="ltx_p" style="width:71.1pt;"><span id="S7.T3.3.1.1.1.3.1.1.1" class="ltx_text ltx_font_bold">References</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S7.T3.3.1.2.1" class="ltx_tr">
<td id="S7.T3.3.1.2.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T3.3.1.2.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T3.3.1.2.1.1.1.1" class="ltx_p" style="width:113.8pt;">Group Fairness</span>
</span>
</td>
<td id="S7.T3.3.1.2.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T3.3.1.2.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T3.3.1.2.1.2.1.1" class="ltx_p" style="width:170.7pt;">Reduces discrimination against a certain demographic(such as age, gender, societal class)</span>
</span>
</td>
<td id="S7.T3.3.1.2.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T3.3.1.2.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T3.3.1.2.1.3.1.1" class="ltx_p" style="width:71.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>,
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib217" title="" class="ltx_ref">217</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib218" title="" class="ltx_ref">218</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib144" title="" class="ltx_ref">144</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib106" title="" class="ltx_ref">106</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib157" title="" class="ltx_ref">157</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib143" title="" class="ltx_ref">143</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib147" title="" class="ltx_ref">147</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib206" title="" class="ltx_ref">206</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib77" title="" class="ltx_ref">77</a>]</cite></span>
</span>
</td>
</tr>
<tr id="S7.T3.3.1.3.2" class="ltx_tr">
<td id="S7.T3.3.1.3.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T3.3.1.3.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T3.3.1.3.2.1.1.1" class="ltx_p" style="width:113.8pt;">Accuracy Parity</span>
</span>
</td>
<td id="S7.T3.3.1.3.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T3.3.1.3.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T3.3.1.3.2.2.1.1" class="ltx_p" style="width:170.7pt;">This notion tries to establish the correct balance between accuracy and fairness</span>
</span>
</td>
<td id="S7.T3.3.1.3.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T3.3.1.3.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T3.3.1.3.2.3.1.1" class="ltx_p" style="width:71.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib192" title="" class="ltx_ref">192</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib130" title="" class="ltx_ref">130</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib97" title="" class="ltx_ref">97</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib121" title="" class="ltx_ref">121</a>]</cite></span>
</span>
</td>
</tr>
<tr id="S7.T3.3.1.4.3" class="ltx_tr">
<td id="S7.T3.3.1.4.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T3.3.1.4.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T3.3.1.4.3.1.1.1" class="ltx_p" style="width:113.8pt;">Contribution Fairness</span>
</span>
</td>
<td id="S7.T3.3.1.4.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T3.3.1.4.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T3.3.1.4.3.2.1.1" class="ltx_p" style="width:170.7pt;">This distributed fairness notion focuses on the idea that the clients’ payment must be in accordance with its contribution</span>
</span>
</td>
<td id="S7.T3.3.1.4.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T3.3.1.4.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T3.3.1.4.3.3.1.1" class="ltx_p" style="width:71.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib117" title="" class="ltx_ref">117</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib201" title="" class="ltx_ref">201</a>]</cite></span>
</span>
</td>
</tr>
<tr id="S7.T3.3.1.5.4" class="ltx_tr">
<td id="S7.T3.3.1.5.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T3.3.1.5.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T3.3.1.5.4.1.1.1" class="ltx_p" style="width:113.8pt;">Client Selection</span>
</span>
</td>
<td id="S7.T3.3.1.5.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T3.3.1.5.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T3.3.1.5.4.2.1.1" class="ltx_p" style="width:170.7pt;">This idea focuses on mitigating bias in a model by creating a suitable client selection mechanism and tries to enhance the probability of participation of underrepresented clients.</span>
</span>
</td>
<td id="S7.T3.3.1.5.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T3.3.1.5.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T3.3.1.5.4.3.1.1" class="ltx_p" style="width:71.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib238" title="" class="ltx_ref">238</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib70" title="" class="ltx_ref">70</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib239" title="" class="ltx_ref">239</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib66" title="" class="ltx_ref">66</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib67" title="" class="ltx_ref">67</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib151" title="" class="ltx_ref">151</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib161" title="" class="ltx_ref">161</a>]</cite></span>
</span>
</td>
</tr>
<tr id="S7.T3.3.1.6.5" class="ltx_tr">
<td id="S7.T3.3.1.6.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T3.3.1.6.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T3.3.1.6.5.1.1.1" class="ltx_p" style="width:113.8pt;">Good-Intent Fairness</span>
</span>
</td>
<td id="S7.T3.3.1.6.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T3.3.1.6.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T3.3.1.6.5.2.1.1" class="ltx_p" style="width:170.7pt;">This idea reduces the variation of model accuracy and efficiency among all the groups by optimizing the group that performs the poorest.</span>
</span>
</td>
<td id="S7.T3.3.1.6.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T3.3.1.6.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T3.3.1.6.5.3.1.1" class="ltx_p" style="width:71.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib126" title="" class="ltx_ref">126</a>]</cite></span>
</span>
</td>
</tr>
<tr id="S7.T3.3.1.7.6" class="ltx_tr">
<td id="S7.T3.3.1.7.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T3.3.1.7.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T3.3.1.7.6.1.1.1" class="ltx_p" style="width:113.8pt;">Regret
Distribution Fairness</span>
</span>
</td>
<td id="S7.T3.3.1.7.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T3.3.1.7.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T3.3.1.7.6.2.1.1" class="ltx_p" style="width:170.7pt;">This idea of fairness seeks to reduce the disparity in FL clients’ regret about having to wait to obtain incentive payout, taking into account the length of time the owner has been waiting to get the complete compensation.</span>
</span>
</td>
<td id="S7.T3.3.1.7.6.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T3.3.1.7.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T3.3.1.7.6.3.1.1" class="ltx_p" style="width:71.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib211" title="" class="ltx_ref">211</a>]</cite></span>
</span>
</td>
</tr>
<tr id="S7.T3.3.1.8.7" class="ltx_tr">
<td id="S7.T3.3.1.8.7.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T3.3.1.8.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T3.3.1.8.7.1.1.1" class="ltx_p" style="width:113.8pt;">Expectation Fairness</span>
</span>
</td>
<td id="S7.T3.3.1.8.7.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T3.3.1.8.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T3.3.1.8.7.2.1.1" class="ltx_p" style="width:170.7pt;">The regret distribution fairness serves as a foundation for this idea of fairness. Since incentive benefits are dispersed progressively over time, it seeks to reduce the disparity between clients at various times.</span>
</span>
</td>
<td id="S7.T3.3.1.8.7.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T3.3.1.8.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T3.3.1.8.7.3.1.1" class="ltx_p" style="width:71.1pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib211" title="" class="ltx_ref">211</a>]</cite></span>
</span>
</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section id="S7.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.4 </span><span id="S7.SS4.1.1" class="ltx_text ltx_font_italic">Group Fairness</span>
</h3>

<div id="S7.SS4.p1" class="ltx_para">
<p id="S7.SS4.p1.1" class="ltx_p">Group fairness, a key concept in ML, refers to the diminished bias in a trained models’ performance against specific protected demographic groups, which are specified based on sensitive characteristics of the population (e.g., gender, race). Unfairness against certain age groups can be caused due to various reasons. Unfairness regarding treatment may arise in many real-world situations where there might be inadequate data related to one or more groups, such that the overall model performance is affected. For instance, when different hospitals want to develop a machine learning model for medical diagnosis for classification between Pneumonia affected and unaffected patients, but they only possess limited training data from a few groups because of their under-representation in a particular geographic location, the overall model performance may get affected and the model might become biased towards the group whose data is present predominantly. Let us assume that each data point is associated with a sensitive binary property U, for instance, race or gender. The fairness of a binary prediction model can be assessed by comparing its performance to the underlying groups defined by their sensitive characteristics. Not much work has been developed successfully to demonstrate Group Fairness even though the concept has existed for quite a while in conventional ML. FedOPT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib152" title="" class="ltx_ref">152</a>]</cite> improves upon FedAvg and results in collaborative training of a highly performing aggregate model, but causes bias similar to traditional machine learning settings because it discriminates against a particular demographic group.</p>
</div>
</section>
<section id="S7.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.5 </span><span id="S7.SS5.1.1" class="ltx_text ltx_font_italic">Processing Algorithms for Eradicating Group Fairness</span>
</h3>

<div id="S7.SS5.p1" class="ltx_para">
<p id="S7.SS5.p1.1" class="ltx_p">Some preprocessing algorithms <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib219" title="" class="ltx_ref">219</a>]</cite> aimed to achieve group fairness in centralized Machine Learning. These are also gaining popularity in Fairness-Aware FL implementations. These can be grouped into three categories:
<br class="ltx_break"><span id="S7.SS5.p1.1.1" class="ltx_text ltx_font_bold">Pre-Processing Algorithms.</span> In this algorithm, prior to categorization, data is pre-processed to eliminate prejudice following techniques such as reweighing and optimized pre-processing. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib202" title="" class="ltx_ref">202</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> improves model fairness through data correction during training leveraging this technique. Equalized odds post-processing <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib123" title="" class="ltx_ref">123</a>]</cite> altered the dataset features beforehand to generate fair synthetic data. 
<br class="ltx_break"><span id="S7.SS5.p1.1.2" class="ltx_text ltx_font_bold">In-Processing Algorithms.</span> In this process, the dataset is separated into three parts here: training, validation, and testing.
After training, the trained system is optimized and validated on the validation set before being applied to the test set.
Some well-known works in this regard are Adversarial Debiasing <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib215" title="" class="ltx_ref">215</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite> and Prejudice Remover <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib79" title="" class="ltx_ref">79</a>]</cite>. 
<br class="ltx_break"><span id="S7.SS5.p1.1.3" class="ltx_text ltx_font_bold">Post-Processing Algorithms.</span> Here, some of the class labels are modified to lessen prejudice after classification by following methods such as Reject option classification <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> and Equalized odds post-processing <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib116" title="" class="ltx_ref">116</a>]</cite>. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib165" title="" class="ltx_ref">165</a>]</cite>. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib90" title="" class="ltx_ref">90</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib148" title="" class="ltx_ref">148</a>]</cite> improves the results of the system to provide more accurate predictions using post-processing.
<br class="ltx_break"><span id="S7.SS5.p1.1.4" class="ltx_text ltx_font_bold">Processing Algorithms in FL.</span>
PrivFairFL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib147" title="" class="ltx_ref">147</a>]</cite> uses SMC and DP in conjunction with FL, and used pre-processing and post-processing to mitigate the contradiction between fairness and privacy in FL and allowed cross-device FL training group-fair ML models under strict and official privacy protections. FairFed <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>, a methodology that allows for flexible usage of various local debiasing techniques among clients is server-side and independent of local debiasing.</p>
</div>
<figure id="S7.T4" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE IV: </span><span id="S7.T4.2.1" class="ltx_text ltx_font_bold">Existing Studies on Group Fairness in FL.</span></figcaption>
<div id="S7.T4.3" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:209.6pt;height:262.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-11.6pt,14.6pt) scale(0.9,0.9) ;">
<table id="S7.T4.3.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S7.T4.3.1.1.1" class="ltx_tr">
<th id="S7.T4.3.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t" style="padding-top:6.5pt;padding-bottom:6.5pt;">
<span id="S7.T4.3.1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T4.3.1.1.1.1.1.1" class="ltx_p" style="width:28.5pt;"><span id="S7.T4.3.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Reference</span></span>
</span>
</th>
<th id="S7.T4.3.1.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t" style="padding-top:6.5pt;padding-bottom:6.5pt;">
<span id="S7.T4.3.1.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T4.3.1.1.1.2.1.1" class="ltx_p" style="width:56.9pt;"><span id="S7.T4.3.1.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Model Name(s)</span></span>
</span>
</th>
<th id="S7.T4.3.1.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t" style="padding-top:6.5pt;padding-bottom:6.5pt;">
<span id="S7.T4.3.1.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T4.3.1.1.1.3.1.1" class="ltx_p" style="width:42.7pt;"><span id="S7.T4.3.1.1.1.3.1.1.1" class="ltx_text ltx_font_bold">Privacy</span></span>
</span>
</th>
<th id="S7.T4.3.1.1.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t" style="padding-top:6.5pt;padding-bottom:6.5pt;">
<span id="S7.T4.3.1.1.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T4.3.1.1.1.4.1.1" class="ltx_p" style="width:56.9pt;"><span id="S7.T4.3.1.1.1.4.1.1.1" class="ltx_text ltx_font_bold">Processing</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S7.T4.3.1.2.1" class="ltx_tr">
<td id="S7.T4.3.1.2.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:6.5pt;padding-bottom:6.5pt;">
<span id="S7.T4.3.1.2.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T4.3.1.2.1.1.1.1" class="ltx_p" style="width:28.5pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib147" title="" class="ltx_ref">147</a>]</cite></span>
</span>
</td>
<td id="S7.T4.3.1.2.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:6.5pt;padding-bottom:6.5pt;">
<span id="S7.T4.3.1.2.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T4.3.1.2.1.2.1.1" class="ltx_p" style="width:56.9pt;">PrivFairFL</span>
</span>
</td>
<td id="S7.T4.3.1.2.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:6.5pt;padding-bottom:6.5pt;">
<span id="S7.T4.3.1.2.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T4.3.1.2.1.3.1.1" class="ltx_p" style="width:42.7pt;">DP + SMC</span>
</span>
</td>
<td id="S7.T4.3.1.2.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:6.5pt;padding-bottom:6.5pt;">
<span id="S7.T4.3.1.2.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T4.3.1.2.1.4.1.1" class="ltx_p" style="width:56.9pt;">Pre-processing, Post-Processing</span>
</span>
</td>
</tr>
<tr id="S7.T4.3.1.3.2" class="ltx_tr">
<td id="S7.T4.3.1.3.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:6.5pt;padding-bottom:6.5pt;">
<span id="S7.T4.3.1.3.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T4.3.1.3.2.1.1.1" class="ltx_p" style="width:28.5pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite></span>
</span>
</td>
<td id="S7.T4.3.1.3.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:6.5pt;padding-bottom:6.5pt;">
<span id="S7.T4.3.1.3.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T4.3.1.3.2.2.1.1" class="ltx_p" style="width:56.9pt;">FairFed</span>
</span>
</td>
<td id="S7.T4.3.1.3.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:6.5pt;padding-bottom:6.5pt;">
<span id="S7.T4.3.1.3.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T4.3.1.3.2.3.1.1" class="ltx_p" style="width:42.7pt;">SMC</span>
</span>
</td>
<td id="S7.T4.3.1.3.2.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:6.5pt;padding-bottom:6.5pt;">
<span id="S7.T4.3.1.3.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T4.3.1.3.2.4.1.1" class="ltx_p" style="width:56.9pt;">In-Processing</span>
</span>
</td>
</tr>
<tr id="S7.T4.3.1.4.3" class="ltx_tr">
<td id="S7.T4.3.1.4.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:6.5pt;padding-bottom:6.5pt;">
<span id="S7.T4.3.1.4.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T4.3.1.4.3.1.1.1" class="ltx_p" style="width:28.5pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib143" title="" class="ltx_ref">143</a>]</cite></span>
</span>
</td>
<td id="S7.T4.3.1.4.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:6.5pt;padding-bottom:6.5pt;">
<span id="S7.T4.3.1.4.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T4.3.1.4.3.2.1.1" class="ltx_p" style="width:56.9pt;">-</span>
</span>
</td>
<td id="S7.T4.3.1.4.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:6.5pt;padding-bottom:6.5pt;">
<span id="S7.T4.3.1.4.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T4.3.1.4.3.3.1.1" class="ltx_p" style="width:42.7pt;">SMC</span>
</span>
</td>
<td id="S7.T4.3.1.4.3.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:6.5pt;padding-bottom:6.5pt;">
<span id="S7.T4.3.1.4.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T4.3.1.4.3.4.1.1" class="ltx_p" style="width:56.9pt;">In-Processing</span>
</span>
</td>
</tr>
<tr id="S7.T4.3.1.5.4" class="ltx_tr">
<td id="S7.T4.3.1.5.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:6.5pt;padding-bottom:6.5pt;">
<span id="S7.T4.3.1.5.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T4.3.1.5.4.1.1.1" class="ltx_p" style="width:28.5pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib81" title="" class="ltx_ref">81</a>]</cite></span>
</span>
</td>
<td id="S7.T4.3.1.5.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:6.5pt;padding-bottom:6.5pt;">
<span id="S7.T4.3.1.5.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T4.3.1.5.4.2.1.1" class="ltx_p" style="width:56.9pt;">F3</span>
</span>
</td>
<td id="S7.T4.3.1.5.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:6.5pt;padding-bottom:6.5pt;">
<span id="S7.T4.3.1.5.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T4.3.1.5.4.3.1.1" class="ltx_p" style="width:42.7pt;">-</span>
</span>
</td>
<td id="S7.T4.3.1.5.4.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:6.5pt;padding-bottom:6.5pt;">
<span id="S7.T4.3.1.5.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T4.3.1.5.4.4.1.1" class="ltx_p" style="width:56.9pt;">In-Processing</span>
</span>
</td>
</tr>
<tr id="S7.T4.3.1.6.5" class="ltx_tr">
<td id="S7.T4.3.1.6.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:6.5pt;padding-bottom:6.5pt;">
<span id="S7.T4.3.1.6.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T4.3.1.6.5.1.1.1" class="ltx_p" style="width:28.5pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib218" title="" class="ltx_ref">218</a>]</cite></span>
</span>
</td>
<td id="S7.T4.3.1.6.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:6.5pt;padding-bottom:6.5pt;">
<span id="S7.T4.3.1.6.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T4.3.1.6.5.2.1.1" class="ltx_p" style="width:56.9pt;">FMDA-M</span>
</span>
</td>
<td id="S7.T4.3.1.6.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:6.5pt;padding-bottom:6.5pt;">
<span id="S7.T4.3.1.6.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T4.3.1.6.5.3.1.1" class="ltx_p" style="width:42.7pt;">-</span>
</span>
</td>
<td id="S7.T4.3.1.6.5.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:6.5pt;padding-bottom:6.5pt;">
<span id="S7.T4.3.1.6.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T4.3.1.6.5.4.1.1" class="ltx_p" style="width:56.9pt;">-</span>
</span>
</td>
</tr>
<tr id="S7.T4.3.1.7.6" class="ltx_tr">
<td id="S7.T4.3.1.7.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:6.5pt;padding-bottom:6.5pt;">
<span id="S7.T4.3.1.7.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T4.3.1.7.6.1.1.1" class="ltx_p" style="width:28.5pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib155" title="" class="ltx_ref">155</a>]</cite></span>
</span>
</td>
<td id="S7.T4.3.1.7.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:6.5pt;padding-bottom:6.5pt;">
<span id="S7.T4.3.1.7.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T4.3.1.7.6.2.1.1" class="ltx_p" style="width:56.9pt;">FPFL</span>
</span>
</td>
<td id="S7.T4.3.1.7.6.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:6.5pt;padding-bottom:6.5pt;">
<span id="S7.T4.3.1.7.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T4.3.1.7.6.3.1.1" class="ltx_p" style="width:42.7pt;">DP</span>
</span>
</td>
<td id="S7.T4.3.1.7.6.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:6.5pt;padding-bottom:6.5pt;">
<span id="S7.T4.3.1.7.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T4.3.1.7.6.4.1.1" class="ltx_p" style="width:56.9pt;">In-Processing</span>
</span>
</td>
</tr>
<tr id="S7.T4.3.1.8.7" class="ltx_tr">
<td id="S7.T4.3.1.8.7.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:6.5pt;padding-bottom:6.5pt;">
<span id="S7.T4.3.1.8.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T4.3.1.8.7.1.1.1" class="ltx_p" style="width:28.5pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib212" title="" class="ltx_ref">212</a>]</cite></span>
</span>
</td>
<td id="S7.T4.3.1.8.7.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:6.5pt;padding-bottom:6.5pt;">
<span id="S7.T4.3.1.8.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T4.3.1.8.7.2.1.1" class="ltx_p" style="width:56.9pt;">GIFAIR-FL</span>
</span>
</td>
<td id="S7.T4.3.1.8.7.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:6.5pt;padding-bottom:6.5pt;">
<span id="S7.T4.3.1.8.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T4.3.1.8.7.3.1.1" class="ltx_p" style="width:42.7pt;">-</span>
</span>
</td>
<td id="S7.T4.3.1.8.7.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:6.5pt;padding-bottom:6.5pt;">
<span id="S7.T4.3.1.8.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T4.3.1.8.7.4.1.1" class="ltx_p" style="width:56.9pt;">In-Processing</span>
</span>
</td>
</tr>
<tr id="S7.T4.3.1.9.8" class="ltx_tr">
<td id="S7.T4.3.1.9.8.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:6.5pt;padding-bottom:6.5pt;">
<span id="S7.T4.3.1.9.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T4.3.1.9.8.1.1.1" class="ltx_p" style="width:28.5pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib237" title="" class="ltx_ref">237</a>]</cite></span>
</span>
</td>
<td id="S7.T4.3.1.9.8.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:6.5pt;padding-bottom:6.5pt;">
<span id="S7.T4.3.1.9.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T4.3.1.9.8.2.1.1" class="ltx_p" style="width:56.9pt;">FCFL</span>
</span>
</td>
<td id="S7.T4.3.1.9.8.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:6.5pt;padding-bottom:6.5pt;">
<span id="S7.T4.3.1.9.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T4.3.1.9.8.3.1.1" class="ltx_p" style="width:42.7pt;">-</span>
</span>
</td>
<td id="S7.T4.3.1.9.8.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:6.5pt;padding-bottom:6.5pt;">
<span id="S7.T4.3.1.9.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T4.3.1.9.8.4.1.1" class="ltx_p" style="width:56.9pt;">In-Processing</span>
</span>
</td>
</tr>
<tr id="S7.T4.3.1.10.9" class="ltx_tr">
<td id="S7.T4.3.1.10.9.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:6.5pt;padding-bottom:6.5pt;">
<span id="S7.T4.3.1.10.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T4.3.1.10.9.1.1.1" class="ltx_p" style="width:28.5pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib155" title="" class="ltx_ref">155</a>]</cite></span>
</span>
</td>
<td id="S7.T4.3.1.10.9.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:6.5pt;padding-bottom:6.5pt;">
<span id="S7.T4.3.1.10.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T4.3.1.10.9.2.1.1" class="ltx_p" style="width:56.9pt;">FPFL</span>
</span>
</td>
<td id="S7.T4.3.1.10.9.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:6.5pt;padding-bottom:6.5pt;">
<span id="S7.T4.3.1.10.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T4.3.1.10.9.3.1.1" class="ltx_p" style="width:42.7pt;">DP + SMC</span>
</span>
</td>
<td id="S7.T4.3.1.10.9.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:6.5pt;padding-bottom:6.5pt;">
<span id="S7.T4.3.1.10.9.4.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T4.3.1.10.9.4.1.1" class="ltx_p" style="width:56.9pt;">In-Processing</span>
</span>
</td>
</tr>
<tr id="S7.T4.3.1.11.10" class="ltx_tr">
<td id="S7.T4.3.1.11.10.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:6.5pt;padding-bottom:6.5pt;">
<span id="S7.T4.3.1.11.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T4.3.1.11.10.1.1.1" class="ltx_p" style="width:28.5pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite></span>
</span>
</td>
<td id="S7.T4.3.1.11.10.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:6.5pt;padding-bottom:6.5pt;">
<span id="S7.T4.3.1.11.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T4.3.1.11.10.2.1.1" class="ltx_p" style="width:56.9pt;">-</span>
</span>
</td>
<td id="S7.T4.3.1.11.10.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:6.5pt;padding-bottom:6.5pt;">
<span id="S7.T4.3.1.11.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T4.3.1.11.10.3.1.1" class="ltx_p" style="width:42.7pt;">DP</span>
</span>
</td>
<td id="S7.T4.3.1.11.10.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:6.5pt;padding-bottom:6.5pt;">
<span id="S7.T4.3.1.11.10.4.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T4.3.1.11.10.4.1.1" class="ltx_p" style="width:56.9pt;">Pre-processing, In-Preprocessing</span>
</span>
</td>
</tr>
<tr id="S7.T4.3.1.12.11" class="ltx_tr">
<td id="S7.T4.3.1.12.11.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_t" style="padding-top:6.5pt;padding-bottom:6.5pt;">
<span id="S7.T4.3.1.12.11.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T4.3.1.12.11.1.1.1" class="ltx_p" style="width:28.5pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite></span>
</span>
</td>
<td id="S7.T4.3.1.12.11.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_t" style="padding-top:6.5pt;padding-bottom:6.5pt;">
<span id="S7.T4.3.1.12.11.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T4.3.1.12.11.2.1.1" class="ltx_p" style="width:56.9pt;">FADE</span>
</span>
</td>
<td id="S7.T4.3.1.12.11.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_t" style="padding-top:6.5pt;padding-bottom:6.5pt;">
<span id="S7.T4.3.1.12.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T4.3.1.12.11.3.1.1" class="ltx_p" style="width:42.7pt;">-</span>
</span>
</td>
<td id="S7.T4.3.1.12.11.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_t" style="padding-top:6.5pt;padding-bottom:6.5pt;">
<span id="S7.T4.3.1.12.11.4.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T4.3.1.12.11.4.1.1" class="ltx_p" style="width:56.9pt;">In-Processing</span>
</span>
</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure id="S7.T5" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE V: </span><span id="S7.T5.2.1" class="ltx_text ltx_font_bold">Existing Studies on Fairness-Aware and Privacy-preserving FL.</span></figcaption>
<div id="S7.T5.3" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:512.8pt;height:442.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-64.1pt,55.3pt) scale(0.8,0.8) ;">
<table id="S7.T5.3.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S7.T5.3.1.1.1" class="ltx_tr">
<th id="S7.T5.3.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.1.1.1.1.1" class="ltx_p" style="width:56.9pt;"><span id="S7.T5.3.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">References</span></span>
</span>
</th>
<th id="S7.T5.3.1.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.1.1.2.1.1" class="ltx_p" style="width:85.4pt;"><span id="S7.T5.3.1.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Model name(s)</span></span>
</span>
</th>
<th id="S7.T5.3.1.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.1.1.3.1.1" class="ltx_p" style="width:85.4pt;"><span id="S7.T5.3.1.1.1.3.1.1.1" class="ltx_text ltx_font_bold">Fairness notion(s)</span></span>
</span>
</th>
<th id="S7.T5.3.1.1.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.1.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.1.1.4.1.1" class="ltx_p" style="width:113.8pt;"><span id="S7.T5.3.1.1.1.4.1.1.1" class="ltx_text ltx_font_bold">Privacy Mechanism(s)</span></span>
</span>
</th>
<th id="S7.T5.3.1.1.1.5" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.1.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.1.1.5.1.1" class="ltx_p" style="width:85.4pt;"><span id="S7.T5.3.1.1.1.5.1.1.1" class="ltx_text ltx_font_bold">Data Partitioning(s)</span></span>
</span>
</th>
<th id="S7.T5.3.1.1.1.6" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.1.1.6.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.1.1.6.1.1" class="ltx_p" style="width:142.3pt;"><span id="S7.T5.3.1.1.1.6.1.1.1" class="ltx_text ltx_font_bold">Remarks</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S7.T5.3.1.2.1" class="ltx_tr">
<td id="S7.T5.3.1.2.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.2.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.2.1.1.1.1" class="ltx_p" style="width:56.9pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite></span>
</span>
</td>
<td id="S7.T5.3.1.2.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.2.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.2.1.2.1.1" class="ltx_p" style="width:85.4pt;">FPFL</span>
</span>
</td>
<td id="S7.T5.3.1.2.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.2.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.2.1.3.1.1" class="ltx_p" style="width:85.4pt;">Accuracy Parity</span>
</span>
</td>
<td id="S7.T5.3.1.2.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.2.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.2.1.4.1.1" class="ltx_p" style="width:113.8pt;">DP</span>
</span>
</td>
<td id="S7.T5.3.1.2.1.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.2.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.2.1.5.1.1" class="ltx_p" style="width:85.4pt;">Horizontal</span>
</span>
</td>
<td id="S7.T5.3.1.2.1.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;"></td>
</tr>
<tr id="S7.T5.3.1.3.2" class="ltx_tr">
<td id="S7.T5.3.1.3.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.3.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.3.2.1.1.1" class="ltx_p" style="width:56.9pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib138" title="" class="ltx_ref">138</a>]</cite></span>
</span>
</td>
<td id="S7.T5.3.1.3.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.3.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.3.2.2.1.1" class="ltx_p" style="width:85.4pt;">-</span>
</span>
</td>
<td id="S7.T5.3.1.3.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.3.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.3.2.3.1.1" class="ltx_p" style="width:85.4pt;">Accuracy Parity</span>
</span>
</td>
<td id="S7.T5.3.1.3.2.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.3.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.3.2.4.1.1" class="ltx_p" style="width:113.8pt;">Metric privacy (variant of DP)</span>
</span>
</td>
<td id="S7.T5.3.1.3.2.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.3.2.5.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.3.2.5.1.1" class="ltx_p" style="width:85.4pt;">Horizontal</span>
</span>
</td>
<td id="S7.T5.3.1.3.2.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;"></td>
</tr>
<tr id="S7.T5.3.1.4.3" class="ltx_tr">
<td id="S7.T5.3.1.4.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.4.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.4.3.1.1.1" class="ltx_p" style="width:56.9pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib147" title="" class="ltx_ref">147</a>]</cite></span>
</span>
</td>
<td id="S7.T5.3.1.4.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.4.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.4.3.2.1.1" class="ltx_p" style="width:85.4pt;">PrivFairFL</span>
</span>
</td>
<td id="S7.T5.3.1.4.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.4.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.4.3.3.1.1" class="ltx_p" style="width:85.4pt;">Group Fairness</span>
</span>
</td>
<td id="S7.T5.3.1.4.3.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.4.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.4.3.4.1.1" class="ltx_p" style="width:113.8pt;">DP, SMC</span>
</span>
</td>
<td id="S7.T5.3.1.4.3.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.4.3.5.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.4.3.5.1.1" class="ltx_p" style="width:85.4pt;">Horizontal</span>
</span>
</td>
<td id="S7.T5.3.1.4.3.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.4.3.6.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.4.3.6.1.1" class="ltx_p" style="width:142.3pt;">The proposed method is not compatible with all concepts of fairness and is not suitable for application be applied in every sector</span>
</span>
</td>
</tr>
<tr id="S7.T5.3.1.5.4" class="ltx_tr">
<td id="S7.T5.3.1.5.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.5.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.5.4.1.1.1" class="ltx_p" style="width:56.9pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib195" title="" class="ltx_ref">195</a>]</cite></span>
</span>
</td>
<td id="S7.T5.3.1.5.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.5.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.5.4.2.1.1" class="ltx_p" style="width:85.4pt;">Cascade Vertical Federated Learning (CVFL)</span>
</span>
</td>
<td id="S7.T5.3.1.5.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.5.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.5.4.3.1.1" class="ltx_p" style="width:85.4pt;">Group Fairness</span>
</span>
</td>
<td id="S7.T5.3.1.5.4.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.5.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.5.4.4.1.1" class="ltx_p" style="width:113.8pt;">DP, SMC</span>
</span>
</td>
<td id="S7.T5.3.1.5.4.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.5.4.5.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.5.4.5.1.1" class="ltx_p" style="width:85.4pt;">Horizontal</span>
</span>
</td>
<td id="S7.T5.3.1.5.4.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;"></td>
</tr>
<tr id="S7.T5.3.1.6.5" class="ltx_tr">
<td id="S7.T5.3.1.6.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.6.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.6.5.1.1.1" class="ltx_p" style="width:56.9pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib91" title="" class="ltx_ref">91</a>]</cite></span>
</span>
</td>
<td id="S7.T5.3.1.6.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.6.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.6.5.2.1.1" class="ltx_p" style="width:85.4pt;">-</span>
</span>
</td>
<td id="S7.T5.3.1.6.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.6.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.6.5.3.1.1" class="ltx_p" style="width:85.4pt;">Contribution Fairness</span>
</span>
</td>
<td id="S7.T5.3.1.6.5.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.6.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.6.5.4.1.1" class="ltx_p" style="width:113.8pt;">DP</span>
</span>
</td>
<td id="S7.T5.3.1.6.5.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.6.5.5.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.6.5.5.1.1" class="ltx_p" style="width:85.4pt;">Horizontal</span>
</span>
</td>
<td id="S7.T5.3.1.6.5.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.6.5.6.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.6.5.6.1.1" class="ltx_p" style="width:142.3pt;">Mechanism design (MD) and DP are used for an incentive design based private Federated Learning system</span>
</span>
</td>
</tr>
<tr id="S7.T5.3.1.7.6" class="ltx_tr">
<td id="S7.T5.3.1.7.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.7.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.7.6.1.1.1" class="ltx_p" style="width:56.9pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib217" title="" class="ltx_ref">217</a>]</cite></span>
</span>
</td>
<td id="S7.T5.3.1.7.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.7.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.7.6.2.1.1" class="ltx_p" style="width:85.4pt;">FairFL</span>
</span>
</td>
<td id="S7.T5.3.1.7.6.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.7.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.7.6.3.1.1" class="ltx_p" style="width:85.4pt;">Accuracy Parity</span>
</span>
</td>
<td id="S7.T5.3.1.7.6.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.7.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.7.6.4.1.1" class="ltx_p" style="width:113.8pt;">Secure aggregation protocol, Deep multi-agent reinforcement learning</span>
</span>
</td>
<td id="S7.T5.3.1.7.6.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.7.6.5.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.7.6.5.1.1" class="ltx_p" style="width:85.4pt;">Horizontal</span>
</span>
</td>
<td id="S7.T5.3.1.7.6.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;"></td>
</tr>
<tr id="S7.T5.3.1.8.7" class="ltx_tr">
<td id="S7.T5.3.1.8.7.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.8.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.8.7.1.1.1" class="ltx_p" style="width:56.9pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib149" title="" class="ltx_ref">149</a>]</cite></span>
</span>
</td>
<td id="S7.T5.3.1.8.7.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.8.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.8.7.2.1.1" class="ltx_p" style="width:85.4pt;">FairVFL</span>
</span>
</td>
<td id="S7.T5.3.1.8.7.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.8.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.8.7.3.1.1" class="ltx_p" style="width:85.4pt;">Accuracy Parity</span>
</span>
</td>
<td id="S7.T5.3.1.8.7.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.8.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.8.7.4.1.1" class="ltx_p" style="width:113.8pt;">Contrastive adversarial learning, DP</span>
</span>
</td>
<td id="S7.T5.3.1.8.7.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.8.7.5.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.8.7.5.1.1" class="ltx_p" style="width:85.4pt;">Vertical</span>
</span>
</td>
<td id="S7.T5.3.1.8.7.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;"></td>
</tr>
<tr id="S7.T5.3.1.9.8" class="ltx_tr">
<td id="S7.T5.3.1.9.8.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.9.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.9.8.1.1.1" class="ltx_p" style="width:56.9pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib214" title="" class="ltx_ref">214</a>]</cite></span>
</span>
</td>
<td id="S7.T5.3.1.9.8.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.9.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.9.8.2.1.1" class="ltx_p" style="width:85.4pt;">FedFB,</span>
</span>
</td>
<td id="S7.T5.3.1.9.8.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.9.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.9.8.3.1.1" class="ltx_p" style="width:85.4pt;">Group Fairness</span>
</span>
</td>
<td id="S7.T5.3.1.9.8.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.9.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.9.8.4.1.1" class="ltx_p" style="width:113.8pt;">DP</span>
</span>
</td>
<td id="S7.T5.3.1.9.8.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.9.8.5.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.9.8.5.1.1" class="ltx_p" style="width:85.4pt;">Horizontal</span>
</span>
</td>
<td id="S7.T5.3.1.9.8.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.9.8.6.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.9.8.6.1.1" class="ltx_p" style="width:142.3pt;">This work lacks the establishment of a correct three-way tradeoff between fairness, accuracy, privacy.</span>
</span>
</td>
</tr>
<tr id="S7.T5.3.1.10.9" class="ltx_tr">
<td id="S7.T5.3.1.10.9.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.10.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.10.9.1.1.1" class="ltx_p" style="width:56.9pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib228" title="" class="ltx_ref">228</a>]</cite></span>
</span>
</td>
<td id="S7.T5.3.1.10.9.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.10.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.10.9.2.1.1" class="ltx_p" style="width:85.4pt;">Dubhe</span>
</span>
</td>
<td id="S7.T5.3.1.10.9.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.10.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.10.9.3.1.1" class="ltx_p" style="width:85.4pt;">Client Selection</span>
</span>
</td>
<td id="S7.T5.3.1.10.9.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.10.9.4.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.10.9.4.1.1" class="ltx_p" style="width:113.8pt;">HE</span>
</span>
</td>
<td id="S7.T5.3.1.10.9.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.10.9.5.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.10.9.5.1.1" class="ltx_p" style="width:85.4pt;">Horizontal</span>
</span>
</td>
<td id="S7.T5.3.1.10.9.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.10.9.6.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.10.9.6.1.1" class="ltx_p" style="width:142.3pt;">-</span>
</span>
</td>
</tr>
<tr id="S7.T5.3.1.11.10" class="ltx_tr">
<td id="S7.T5.3.1.11.10.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.11.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.11.10.1.1.1" class="ltx_p" style="width:56.9pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib184" title="" class="ltx_ref">184</a>]</cite></span>
</span>
</td>
<td id="S7.T5.3.1.11.10.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.11.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.11.10.2.1.1" class="ltx_p" style="width:85.4pt;">FedEBA+</span>
</span>
</td>
<td id="S7.T5.3.1.11.10.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.11.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.11.10.3.1.1" class="ltx_p" style="width:85.4pt;">Accuracy Parity</span>
</span>
</td>
<td id="S7.T5.3.1.11.10.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.11.10.4.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.11.10.4.1.1" class="ltx_p" style="width:113.8pt;">-</span>
</span>
</td>
<td id="S7.T5.3.1.11.10.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.11.10.5.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.11.10.5.1.1" class="ltx_p" style="width:85.4pt;">Horizontal</span>
</span>
</td>
<td id="S7.T5.3.1.11.10.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.11.10.6.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.11.10.6.1.1" class="ltx_p" style="width:142.3pt;">-</span>
</span>
</td>
</tr>
<tr id="S7.T5.3.1.12.11" class="ltx_tr">
<td id="S7.T5.3.1.12.11.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.12.11.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.12.11.1.1.1" class="ltx_p" style="width:56.9pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib63" title="" class="ltx_ref">63</a>]</cite></span>
</span>
</td>
<td id="S7.T5.3.1.12.11.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.12.11.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.12.11.2.1.1" class="ltx_p" style="width:85.4pt;">AFLPC</span>
</span>
</td>
<td id="S7.T5.3.1.12.11.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.12.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.12.11.3.1.1" class="ltx_p" style="width:85.4pt;">-</span>
</span>
</td>
<td id="S7.T5.3.1.12.11.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.12.11.4.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.12.11.4.1.1" class="ltx_p" style="width:113.8pt;">Adaptive DP</span>
</span>
</td>
<td id="S7.T5.3.1.12.11.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.12.11.5.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.12.11.5.1.1" class="ltx_p" style="width:85.4pt;">Horizontal</span>
</span>
</td>
<td id="S7.T5.3.1.12.11.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.12.11.6.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.12.11.6.1.1" class="ltx_p" style="width:142.3pt;">-</span>
</span>
</td>
</tr>
<tr id="S7.T5.3.1.13.12" class="ltx_tr">
<td id="S7.T5.3.1.13.12.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.13.12.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.13.12.1.1.1" class="ltx_p" style="width:56.9pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib146" title="" class="ltx_ref">146</a>]</cite></span>
</span>
</td>
<td id="S7.T5.3.1.13.12.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.13.12.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.13.12.2.1.1" class="ltx_p" style="width:85.4pt;">-</span>
</span>
</td>
<td id="S7.T5.3.1.13.12.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.13.12.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.13.12.3.1.1" class="ltx_p" style="width:85.4pt;">Blockchain</span>
</span>
</td>
<td id="S7.T5.3.1.13.12.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.13.12.4.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.13.12.4.1.1" class="ltx_p" style="width:113.8pt;">-</span>
</span>
</td>
<td id="S7.T5.3.1.13.12.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.13.12.5.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.13.12.5.1.1" class="ltx_p" style="width:85.4pt;">Horizontal</span>
</span>
</td>
<td id="S7.T5.3.1.13.12.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.13.12.6.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.13.12.6.1.1" class="ltx_p" style="width:142.3pt;">This mechanism involves discarding of data as a part of model poisoning attack prevention which yields loss of useful data. It also lacks proper reputation-based rewards system for ensuring fairness among clients.</span>
</span>
</td>
</tr>
<tr id="S7.T5.3.1.14.13" class="ltx_tr">
<td id="S7.T5.3.1.14.13.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.14.13.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.14.13.1.1.1" class="ltx_p" style="width:56.9pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib115" title="" class="ltx_ref">115</a>]</cite></span>
</span>
</td>
<td id="S7.T5.3.1.14.13.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.14.13.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.14.13.2.1.1" class="ltx_p" style="width:85.4pt;">-</span>
</span>
</td>
<td id="S7.T5.3.1.14.13.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.14.13.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.14.13.3.1.1" class="ltx_p" style="width:85.4pt;">Blockchain</span>
</span>
</td>
<td id="S7.T5.3.1.14.13.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.14.13.4.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.14.13.4.1.1" class="ltx_p" style="width:113.8pt;">-</span>
</span>
</td>
<td id="S7.T5.3.1.14.13.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.14.13.5.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.14.13.5.1.1" class="ltx_p" style="width:85.4pt;">Horizontal</span>
</span>
</td>
<td id="S7.T5.3.1.14.13.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.14.13.6.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.14.13.6.1.1" class="ltx_p" style="width:142.3pt;">-</span>
</span>
</td>
</tr>
<tr id="S7.T5.3.1.15.14" class="ltx_tr">
<td id="S7.T5.3.1.15.14.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.15.14.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.15.14.1.1.1" class="ltx_p" style="width:56.9pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite></span>
</span>
</td>
<td id="S7.T5.3.1.15.14.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.15.14.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.15.14.2.1.1" class="ltx_p" style="width:85.4pt;">-</span>
</span>
</td>
<td id="S7.T5.3.1.15.14.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.15.14.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.15.14.3.1.1" class="ltx_p" style="width:85.4pt;">Group Fairness</span>
</span>
</td>
<td id="S7.T5.3.1.15.14.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.15.14.4.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.15.14.4.1.1" class="ltx_p" style="width:113.8pt;">SMC</span>
</span>
</td>
<td id="S7.T5.3.1.15.14.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.15.14.5.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.15.14.5.1.1" class="ltx_p" style="width:85.4pt;">Horizontal</span>
</span>
</td>
<td id="S7.T5.3.1.15.14.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.15.14.6.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.15.14.6.1.1" class="ltx_p" style="width:142.3pt;">-</span>
</span>
</td>
</tr>
<tr id="S7.T5.3.1.16.15" class="ltx_tr">
<td id="S7.T5.3.1.16.15.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.16.15.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.16.15.1.1.1" class="ltx_p" style="width:56.9pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib96" title="" class="ltx_ref">96</a>]</cite></span>
</span>
</td>
<td id="S7.T5.3.1.16.15.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.16.15.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.16.15.2.1.1" class="ltx_p" style="width:85.4pt;">-</span>
</span>
</td>
<td id="S7.T5.3.1.16.15.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.16.15.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.16.15.3.1.1" class="ltx_p" style="width:85.4pt;">Accuracy Parity</span>
</span>
</td>
<td id="S7.T5.3.1.16.15.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.16.15.4.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.16.15.4.1.1" class="ltx_p" style="width:113.8pt;">-</span>
</span>
</td>
<td id="S7.T5.3.1.16.15.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.16.15.5.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.16.15.5.1.1" class="ltx_p" style="width:85.4pt;">Horizontal</span>
</span>
</td>
<td id="S7.T5.3.1.16.15.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.16.15.6.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.16.15.6.1.1" class="ltx_p" style="width:142.3pt;">-</span>
</span>
</td>
</tr>
<tr id="S7.T5.3.1.17.16" class="ltx_tr">
<td id="S7.T5.3.1.17.16.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.17.16.1.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.17.16.1.1.1" class="ltx_p" style="width:56.9pt;"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib143" title="" class="ltx_ref">143</a>]</cite></span>
</span>
</td>
<td id="S7.T5.3.1.17.16.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.17.16.2.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.17.16.2.1.1" class="ltx_p" style="width:85.4pt;">-</span>
</span>
</td>
<td id="S7.T5.3.1.17.16.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.17.16.3.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.17.16.3.1.1" class="ltx_p" style="width:85.4pt;">Group Fairness</span>
</span>
</td>
<td id="S7.T5.3.1.17.16.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.17.16.4.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.17.16.4.1.1" class="ltx_p" style="width:113.8pt;">SMC</span>
</span>
</td>
<td id="S7.T5.3.1.17.16.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.17.16.5.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.17.16.5.1.1" class="ltx_p" style="width:85.4pt;">Horizontal</span>
</span>
</td>
<td id="S7.T5.3.1.17.16.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_t" style="padding-top:5pt;padding-bottom:5pt;">
<span id="S7.T5.3.1.17.16.6.1" class="ltx_inline-block ltx_align_top">
<span id="S7.T5.3.1.17.16.6.1.1" class="ltx_p" style="width:142.3pt;">This technique requires exploration of privacy attacks and robustness</span>
</span>
</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div id="S7.SS5.p2" class="ltx_para">
<p id="S7.SS5.p2.1" class="ltx_p">The majority of these techniques rely on a single, publicly accessible training dataset, which violates data privacy and infringes on one of the main goals of an FL framework.</p>
</div>
</section>
<section id="S7.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.6 </span><span id="S7.SS6.1.1" class="ltx_text ltx_font_italic">Notions of Group Fairness</span>
</h3>

<div id="S7.SS6.p1" class="ltx_para">
<p id="S7.SS6.p1.8" class="ltx_p">At present, various notions of group fairness exist, such as Equal Opportunity, Statistical Parity. Let, the quantity of true positives be (<math id="S7.SS6.p1.1.m1.1" class="ltx_Math" alttext="TP_{ad}" display="inline"><semantics id="S7.SS6.p1.1.m1.1a"><mrow id="S7.SS6.p1.1.m1.1.1" xref="S7.SS6.p1.1.m1.1.1.cmml"><mi id="S7.SS6.p1.1.m1.1.1.2" xref="S7.SS6.p1.1.m1.1.1.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S7.SS6.p1.1.m1.1.1.1" xref="S7.SS6.p1.1.m1.1.1.1.cmml">​</mo><msub id="S7.SS6.p1.1.m1.1.1.3" xref="S7.SS6.p1.1.m1.1.1.3.cmml"><mi id="S7.SS6.p1.1.m1.1.1.3.2" xref="S7.SS6.p1.1.m1.1.1.3.2.cmml">P</mi><mrow id="S7.SS6.p1.1.m1.1.1.3.3" xref="S7.SS6.p1.1.m1.1.1.3.3.cmml"><mi id="S7.SS6.p1.1.m1.1.1.3.3.2" xref="S7.SS6.p1.1.m1.1.1.3.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S7.SS6.p1.1.m1.1.1.3.3.1" xref="S7.SS6.p1.1.m1.1.1.3.3.1.cmml">​</mo><mi id="S7.SS6.p1.1.m1.1.1.3.3.3" xref="S7.SS6.p1.1.m1.1.1.3.3.3.cmml">d</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S7.SS6.p1.1.m1.1b"><apply id="S7.SS6.p1.1.m1.1.1.cmml" xref="S7.SS6.p1.1.m1.1.1"><times id="S7.SS6.p1.1.m1.1.1.1.cmml" xref="S7.SS6.p1.1.m1.1.1.1"></times><ci id="S7.SS6.p1.1.m1.1.1.2.cmml" xref="S7.SS6.p1.1.m1.1.1.2">𝑇</ci><apply id="S7.SS6.p1.1.m1.1.1.3.cmml" xref="S7.SS6.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S7.SS6.p1.1.m1.1.1.3.1.cmml" xref="S7.SS6.p1.1.m1.1.1.3">subscript</csymbol><ci id="S7.SS6.p1.1.m1.1.1.3.2.cmml" xref="S7.SS6.p1.1.m1.1.1.3.2">𝑃</ci><apply id="S7.SS6.p1.1.m1.1.1.3.3.cmml" xref="S7.SS6.p1.1.m1.1.1.3.3"><times id="S7.SS6.p1.1.m1.1.1.3.3.1.cmml" xref="S7.SS6.p1.1.m1.1.1.3.3.1"></times><ci id="S7.SS6.p1.1.m1.1.1.3.3.2.cmml" xref="S7.SS6.p1.1.m1.1.1.3.3.2">𝑎</ci><ci id="S7.SS6.p1.1.m1.1.1.3.3.3.cmml" xref="S7.SS6.p1.1.m1.1.1.3.3.3">𝑑</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS6.p1.1.m1.1c">TP_{ad}</annotation></semantics></math> and <math id="S7.SS6.p1.2.m2.1" class="ltx_Math" alttext="TP_{dis}" display="inline"><semantics id="S7.SS6.p1.2.m2.1a"><mrow id="S7.SS6.p1.2.m2.1.1" xref="S7.SS6.p1.2.m2.1.1.cmml"><mi id="S7.SS6.p1.2.m2.1.1.2" xref="S7.SS6.p1.2.m2.1.1.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S7.SS6.p1.2.m2.1.1.1" xref="S7.SS6.p1.2.m2.1.1.1.cmml">​</mo><msub id="S7.SS6.p1.2.m2.1.1.3" xref="S7.SS6.p1.2.m2.1.1.3.cmml"><mi id="S7.SS6.p1.2.m2.1.1.3.2" xref="S7.SS6.p1.2.m2.1.1.3.2.cmml">P</mi><mrow id="S7.SS6.p1.2.m2.1.1.3.3" xref="S7.SS6.p1.2.m2.1.1.3.3.cmml"><mi id="S7.SS6.p1.2.m2.1.1.3.3.2" xref="S7.SS6.p1.2.m2.1.1.3.3.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="S7.SS6.p1.2.m2.1.1.3.3.1" xref="S7.SS6.p1.2.m2.1.1.3.3.1.cmml">​</mo><mi id="S7.SS6.p1.2.m2.1.1.3.3.3" xref="S7.SS6.p1.2.m2.1.1.3.3.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S7.SS6.p1.2.m2.1.1.3.3.1a" xref="S7.SS6.p1.2.m2.1.1.3.3.1.cmml">​</mo><mi id="S7.SS6.p1.2.m2.1.1.3.3.4" xref="S7.SS6.p1.2.m2.1.1.3.3.4.cmml">s</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S7.SS6.p1.2.m2.1b"><apply id="S7.SS6.p1.2.m2.1.1.cmml" xref="S7.SS6.p1.2.m2.1.1"><times id="S7.SS6.p1.2.m2.1.1.1.cmml" xref="S7.SS6.p1.2.m2.1.1.1"></times><ci id="S7.SS6.p1.2.m2.1.1.2.cmml" xref="S7.SS6.p1.2.m2.1.1.2">𝑇</ci><apply id="S7.SS6.p1.2.m2.1.1.3.cmml" xref="S7.SS6.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S7.SS6.p1.2.m2.1.1.3.1.cmml" xref="S7.SS6.p1.2.m2.1.1.3">subscript</csymbol><ci id="S7.SS6.p1.2.m2.1.1.3.2.cmml" xref="S7.SS6.p1.2.m2.1.1.3.2">𝑃</ci><apply id="S7.SS6.p1.2.m2.1.1.3.3.cmml" xref="S7.SS6.p1.2.m2.1.1.3.3"><times id="S7.SS6.p1.2.m2.1.1.3.3.1.cmml" xref="S7.SS6.p1.2.m2.1.1.3.3.1"></times><ci id="S7.SS6.p1.2.m2.1.1.3.3.2.cmml" xref="S7.SS6.p1.2.m2.1.1.3.3.2">𝑑</ci><ci id="S7.SS6.p1.2.m2.1.1.3.3.3.cmml" xref="S7.SS6.p1.2.m2.1.1.3.3.3">𝑖</ci><ci id="S7.SS6.p1.2.m2.1.1.3.3.4.cmml" xref="S7.SS6.p1.2.m2.1.1.3.3.4">𝑠</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS6.p1.2.m2.1c">TP_{dis}</annotation></semantics></math>) for the advantaged group (ad) and disadvantaged group (dis) respectively. And (<math id="S7.SS6.p1.3.m3.1" class="ltx_Math" alttext="TPR_{ad}" display="inline"><semantics id="S7.SS6.p1.3.m3.1a"><mrow id="S7.SS6.p1.3.m3.1.1" xref="S7.SS6.p1.3.m3.1.1.cmml"><mi id="S7.SS6.p1.3.m3.1.1.2" xref="S7.SS6.p1.3.m3.1.1.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S7.SS6.p1.3.m3.1.1.1" xref="S7.SS6.p1.3.m3.1.1.1.cmml">​</mo><mi id="S7.SS6.p1.3.m3.1.1.3" xref="S7.SS6.p1.3.m3.1.1.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="S7.SS6.p1.3.m3.1.1.1a" xref="S7.SS6.p1.3.m3.1.1.1.cmml">​</mo><msub id="S7.SS6.p1.3.m3.1.1.4" xref="S7.SS6.p1.3.m3.1.1.4.cmml"><mi id="S7.SS6.p1.3.m3.1.1.4.2" xref="S7.SS6.p1.3.m3.1.1.4.2.cmml">R</mi><mrow id="S7.SS6.p1.3.m3.1.1.4.3" xref="S7.SS6.p1.3.m3.1.1.4.3.cmml"><mi id="S7.SS6.p1.3.m3.1.1.4.3.2" xref="S7.SS6.p1.3.m3.1.1.4.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S7.SS6.p1.3.m3.1.1.4.3.1" xref="S7.SS6.p1.3.m3.1.1.4.3.1.cmml">​</mo><mi id="S7.SS6.p1.3.m3.1.1.4.3.3" xref="S7.SS6.p1.3.m3.1.1.4.3.3.cmml">d</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S7.SS6.p1.3.m3.1b"><apply id="S7.SS6.p1.3.m3.1.1.cmml" xref="S7.SS6.p1.3.m3.1.1"><times id="S7.SS6.p1.3.m3.1.1.1.cmml" xref="S7.SS6.p1.3.m3.1.1.1"></times><ci id="S7.SS6.p1.3.m3.1.1.2.cmml" xref="S7.SS6.p1.3.m3.1.1.2">𝑇</ci><ci id="S7.SS6.p1.3.m3.1.1.3.cmml" xref="S7.SS6.p1.3.m3.1.1.3">𝑃</ci><apply id="S7.SS6.p1.3.m3.1.1.4.cmml" xref="S7.SS6.p1.3.m3.1.1.4"><csymbol cd="ambiguous" id="S7.SS6.p1.3.m3.1.1.4.1.cmml" xref="S7.SS6.p1.3.m3.1.1.4">subscript</csymbol><ci id="S7.SS6.p1.3.m3.1.1.4.2.cmml" xref="S7.SS6.p1.3.m3.1.1.4.2">𝑅</ci><apply id="S7.SS6.p1.3.m3.1.1.4.3.cmml" xref="S7.SS6.p1.3.m3.1.1.4.3"><times id="S7.SS6.p1.3.m3.1.1.4.3.1.cmml" xref="S7.SS6.p1.3.m3.1.1.4.3.1"></times><ci id="S7.SS6.p1.3.m3.1.1.4.3.2.cmml" xref="S7.SS6.p1.3.m3.1.1.4.3.2">𝑎</ci><ci id="S7.SS6.p1.3.m3.1.1.4.3.3.cmml" xref="S7.SS6.p1.3.m3.1.1.4.3.3">𝑑</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS6.p1.3.m3.1c">TPR_{ad}</annotation></semantics></math> and <math id="S7.SS6.p1.4.m4.1" class="ltx_Math" alttext="TPR_{dis}" display="inline"><semantics id="S7.SS6.p1.4.m4.1a"><mrow id="S7.SS6.p1.4.m4.1.1" xref="S7.SS6.p1.4.m4.1.1.cmml"><mi id="S7.SS6.p1.4.m4.1.1.2" xref="S7.SS6.p1.4.m4.1.1.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S7.SS6.p1.4.m4.1.1.1" xref="S7.SS6.p1.4.m4.1.1.1.cmml">​</mo><mi id="S7.SS6.p1.4.m4.1.1.3" xref="S7.SS6.p1.4.m4.1.1.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="S7.SS6.p1.4.m4.1.1.1a" xref="S7.SS6.p1.4.m4.1.1.1.cmml">​</mo><msub id="S7.SS6.p1.4.m4.1.1.4" xref="S7.SS6.p1.4.m4.1.1.4.cmml"><mi id="S7.SS6.p1.4.m4.1.1.4.2" xref="S7.SS6.p1.4.m4.1.1.4.2.cmml">R</mi><mrow id="S7.SS6.p1.4.m4.1.1.4.3" xref="S7.SS6.p1.4.m4.1.1.4.3.cmml"><mi id="S7.SS6.p1.4.m4.1.1.4.3.2" xref="S7.SS6.p1.4.m4.1.1.4.3.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="S7.SS6.p1.4.m4.1.1.4.3.1" xref="S7.SS6.p1.4.m4.1.1.4.3.1.cmml">​</mo><mi id="S7.SS6.p1.4.m4.1.1.4.3.3" xref="S7.SS6.p1.4.m4.1.1.4.3.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S7.SS6.p1.4.m4.1.1.4.3.1a" xref="S7.SS6.p1.4.m4.1.1.4.3.1.cmml">​</mo><mi id="S7.SS6.p1.4.m4.1.1.4.3.4" xref="S7.SS6.p1.4.m4.1.1.4.3.4.cmml">s</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S7.SS6.p1.4.m4.1b"><apply id="S7.SS6.p1.4.m4.1.1.cmml" xref="S7.SS6.p1.4.m4.1.1"><times id="S7.SS6.p1.4.m4.1.1.1.cmml" xref="S7.SS6.p1.4.m4.1.1.1"></times><ci id="S7.SS6.p1.4.m4.1.1.2.cmml" xref="S7.SS6.p1.4.m4.1.1.2">𝑇</ci><ci id="S7.SS6.p1.4.m4.1.1.3.cmml" xref="S7.SS6.p1.4.m4.1.1.3">𝑃</ci><apply id="S7.SS6.p1.4.m4.1.1.4.cmml" xref="S7.SS6.p1.4.m4.1.1.4"><csymbol cd="ambiguous" id="S7.SS6.p1.4.m4.1.1.4.1.cmml" xref="S7.SS6.p1.4.m4.1.1.4">subscript</csymbol><ci id="S7.SS6.p1.4.m4.1.1.4.2.cmml" xref="S7.SS6.p1.4.m4.1.1.4.2">𝑅</ci><apply id="S7.SS6.p1.4.m4.1.1.4.3.cmml" xref="S7.SS6.p1.4.m4.1.1.4.3"><times id="S7.SS6.p1.4.m4.1.1.4.3.1.cmml" xref="S7.SS6.p1.4.m4.1.1.4.3.1"></times><ci id="S7.SS6.p1.4.m4.1.1.4.3.2.cmml" xref="S7.SS6.p1.4.m4.1.1.4.3.2">𝑑</ci><ci id="S7.SS6.p1.4.m4.1.1.4.3.3.cmml" xref="S7.SS6.p1.4.m4.1.1.4.3.3">𝑖</ci><ci id="S7.SS6.p1.4.m4.1.1.4.3.4.cmml" xref="S7.SS6.p1.4.m4.1.1.4.3.4">𝑠</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS6.p1.4.m4.1c">TPR_{dis}</annotation></semantics></math>) be the true positive rates and false positive rate (<math id="S7.SS6.p1.5.m5.1" class="ltx_Math" alttext="FPR_{ad}" display="inline"><semantics id="S7.SS6.p1.5.m5.1a"><mrow id="S7.SS6.p1.5.m5.1.1" xref="S7.SS6.p1.5.m5.1.1.cmml"><mi id="S7.SS6.p1.5.m5.1.1.2" xref="S7.SS6.p1.5.m5.1.1.2.cmml">F</mi><mo lspace="0em" rspace="0em" id="S7.SS6.p1.5.m5.1.1.1" xref="S7.SS6.p1.5.m5.1.1.1.cmml">​</mo><mi id="S7.SS6.p1.5.m5.1.1.3" xref="S7.SS6.p1.5.m5.1.1.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="S7.SS6.p1.5.m5.1.1.1a" xref="S7.SS6.p1.5.m5.1.1.1.cmml">​</mo><msub id="S7.SS6.p1.5.m5.1.1.4" xref="S7.SS6.p1.5.m5.1.1.4.cmml"><mi id="S7.SS6.p1.5.m5.1.1.4.2" xref="S7.SS6.p1.5.m5.1.1.4.2.cmml">R</mi><mrow id="S7.SS6.p1.5.m5.1.1.4.3" xref="S7.SS6.p1.5.m5.1.1.4.3.cmml"><mi id="S7.SS6.p1.5.m5.1.1.4.3.2" xref="S7.SS6.p1.5.m5.1.1.4.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S7.SS6.p1.5.m5.1.1.4.3.1" xref="S7.SS6.p1.5.m5.1.1.4.3.1.cmml">​</mo><mi id="S7.SS6.p1.5.m5.1.1.4.3.3" xref="S7.SS6.p1.5.m5.1.1.4.3.3.cmml">d</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S7.SS6.p1.5.m5.1b"><apply id="S7.SS6.p1.5.m5.1.1.cmml" xref="S7.SS6.p1.5.m5.1.1"><times id="S7.SS6.p1.5.m5.1.1.1.cmml" xref="S7.SS6.p1.5.m5.1.1.1"></times><ci id="S7.SS6.p1.5.m5.1.1.2.cmml" xref="S7.SS6.p1.5.m5.1.1.2">𝐹</ci><ci id="S7.SS6.p1.5.m5.1.1.3.cmml" xref="S7.SS6.p1.5.m5.1.1.3">𝑃</ci><apply id="S7.SS6.p1.5.m5.1.1.4.cmml" xref="S7.SS6.p1.5.m5.1.1.4"><csymbol cd="ambiguous" id="S7.SS6.p1.5.m5.1.1.4.1.cmml" xref="S7.SS6.p1.5.m5.1.1.4">subscript</csymbol><ci id="S7.SS6.p1.5.m5.1.1.4.2.cmml" xref="S7.SS6.p1.5.m5.1.1.4.2">𝑅</ci><apply id="S7.SS6.p1.5.m5.1.1.4.3.cmml" xref="S7.SS6.p1.5.m5.1.1.4.3"><times id="S7.SS6.p1.5.m5.1.1.4.3.1.cmml" xref="S7.SS6.p1.5.m5.1.1.4.3.1"></times><ci id="S7.SS6.p1.5.m5.1.1.4.3.2.cmml" xref="S7.SS6.p1.5.m5.1.1.4.3.2">𝑎</ci><ci id="S7.SS6.p1.5.m5.1.1.4.3.3.cmml" xref="S7.SS6.p1.5.m5.1.1.4.3.3">𝑑</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS6.p1.5.m5.1c">FPR_{ad}</annotation></semantics></math> and <math id="S7.SS6.p1.6.m6.1" class="ltx_Math" alttext="FPR_{dis}" display="inline"><semantics id="S7.SS6.p1.6.m6.1a"><mrow id="S7.SS6.p1.6.m6.1.1" xref="S7.SS6.p1.6.m6.1.1.cmml"><mi id="S7.SS6.p1.6.m6.1.1.2" xref="S7.SS6.p1.6.m6.1.1.2.cmml">F</mi><mo lspace="0em" rspace="0em" id="S7.SS6.p1.6.m6.1.1.1" xref="S7.SS6.p1.6.m6.1.1.1.cmml">​</mo><mi id="S7.SS6.p1.6.m6.1.1.3" xref="S7.SS6.p1.6.m6.1.1.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="S7.SS6.p1.6.m6.1.1.1a" xref="S7.SS6.p1.6.m6.1.1.1.cmml">​</mo><msub id="S7.SS6.p1.6.m6.1.1.4" xref="S7.SS6.p1.6.m6.1.1.4.cmml"><mi id="S7.SS6.p1.6.m6.1.1.4.2" xref="S7.SS6.p1.6.m6.1.1.4.2.cmml">R</mi><mrow id="S7.SS6.p1.6.m6.1.1.4.3" xref="S7.SS6.p1.6.m6.1.1.4.3.cmml"><mi id="S7.SS6.p1.6.m6.1.1.4.3.2" xref="S7.SS6.p1.6.m6.1.1.4.3.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="S7.SS6.p1.6.m6.1.1.4.3.1" xref="S7.SS6.p1.6.m6.1.1.4.3.1.cmml">​</mo><mi id="S7.SS6.p1.6.m6.1.1.4.3.3" xref="S7.SS6.p1.6.m6.1.1.4.3.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S7.SS6.p1.6.m6.1.1.4.3.1a" xref="S7.SS6.p1.6.m6.1.1.4.3.1.cmml">​</mo><mi id="S7.SS6.p1.6.m6.1.1.4.3.4" xref="S7.SS6.p1.6.m6.1.1.4.3.4.cmml">s</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S7.SS6.p1.6.m6.1b"><apply id="S7.SS6.p1.6.m6.1.1.cmml" xref="S7.SS6.p1.6.m6.1.1"><times id="S7.SS6.p1.6.m6.1.1.1.cmml" xref="S7.SS6.p1.6.m6.1.1.1"></times><ci id="S7.SS6.p1.6.m6.1.1.2.cmml" xref="S7.SS6.p1.6.m6.1.1.2">𝐹</ci><ci id="S7.SS6.p1.6.m6.1.1.3.cmml" xref="S7.SS6.p1.6.m6.1.1.3">𝑃</ci><apply id="S7.SS6.p1.6.m6.1.1.4.cmml" xref="S7.SS6.p1.6.m6.1.1.4"><csymbol cd="ambiguous" id="S7.SS6.p1.6.m6.1.1.4.1.cmml" xref="S7.SS6.p1.6.m6.1.1.4">subscript</csymbol><ci id="S7.SS6.p1.6.m6.1.1.4.2.cmml" xref="S7.SS6.p1.6.m6.1.1.4.2">𝑅</ci><apply id="S7.SS6.p1.6.m6.1.1.4.3.cmml" xref="S7.SS6.p1.6.m6.1.1.4.3"><times id="S7.SS6.p1.6.m6.1.1.4.3.1.cmml" xref="S7.SS6.p1.6.m6.1.1.4.3.1"></times><ci id="S7.SS6.p1.6.m6.1.1.4.3.2.cmml" xref="S7.SS6.p1.6.m6.1.1.4.3.2">𝑑</ci><ci id="S7.SS6.p1.6.m6.1.1.4.3.3.cmml" xref="S7.SS6.p1.6.m6.1.1.4.3.3">𝑖</ci><ci id="S7.SS6.p1.6.m6.1.1.4.3.4.cmml" xref="S7.SS6.p1.6.m6.1.1.4.3.4">𝑠</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS6.p1.6.m6.1c">FPR_{dis}</annotation></semantics></math>) for the advantaged and disadvantaged group respectively. 
<br class="ltx_break"><span id="S7.SS6.p1.8.1" class="ltx_text ltx_font_bold">Equal Opportunity.</span>
According to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite>, Equal Opportunity states that the predictor is deemed fair if the real positive rate is independent of the sensitive characteristic U. In other words, the False Negative Rate (FNR) of the system is not affected by the presence of a sensitive attribute U, ie. <math id="S7.SS6.p1.7.m7.1" class="ltx_Math" alttext="FNR_{U}" display="inline"><semantics id="S7.SS6.p1.7.m7.1a"><mrow id="S7.SS6.p1.7.m7.1.1" xref="S7.SS6.p1.7.m7.1.1.cmml"><mi id="S7.SS6.p1.7.m7.1.1.2" xref="S7.SS6.p1.7.m7.1.1.2.cmml">F</mi><mo lspace="0em" rspace="0em" id="S7.SS6.p1.7.m7.1.1.1" xref="S7.SS6.p1.7.m7.1.1.1.cmml">​</mo><mi id="S7.SS6.p1.7.m7.1.1.3" xref="S7.SS6.p1.7.m7.1.1.3.cmml">N</mi><mo lspace="0em" rspace="0em" id="S7.SS6.p1.7.m7.1.1.1a" xref="S7.SS6.p1.7.m7.1.1.1.cmml">​</mo><msub id="S7.SS6.p1.7.m7.1.1.4" xref="S7.SS6.p1.7.m7.1.1.4.cmml"><mi id="S7.SS6.p1.7.m7.1.1.4.2" xref="S7.SS6.p1.7.m7.1.1.4.2.cmml">R</mi><mi id="S7.SS6.p1.7.m7.1.1.4.3" xref="S7.SS6.p1.7.m7.1.1.4.3.cmml">U</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S7.SS6.p1.7.m7.1b"><apply id="S7.SS6.p1.7.m7.1.1.cmml" xref="S7.SS6.p1.7.m7.1.1"><times id="S7.SS6.p1.7.m7.1.1.1.cmml" xref="S7.SS6.p1.7.m7.1.1.1"></times><ci id="S7.SS6.p1.7.m7.1.1.2.cmml" xref="S7.SS6.p1.7.m7.1.1.2">𝐹</ci><ci id="S7.SS6.p1.7.m7.1.1.3.cmml" xref="S7.SS6.p1.7.m7.1.1.3">𝑁</ci><apply id="S7.SS6.p1.7.m7.1.1.4.cmml" xref="S7.SS6.p1.7.m7.1.1.4"><csymbol cd="ambiguous" id="S7.SS6.p1.7.m7.1.1.4.1.cmml" xref="S7.SS6.p1.7.m7.1.1.4">subscript</csymbol><ci id="S7.SS6.p1.7.m7.1.1.4.2.cmml" xref="S7.SS6.p1.7.m7.1.1.4.2">𝑅</ci><ci id="S7.SS6.p1.7.m7.1.1.4.3.cmml" xref="S7.SS6.p1.7.m7.1.1.4.3">𝑈</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS6.p1.7.m7.1c">FNR_{U}</annotation></semantics></math> =FNR, <math id="S7.SS6.p1.8.m8.1" class="ltx_Math" alttext="\forall{u}" display="inline"><semantics id="S7.SS6.p1.8.m8.1a"><mrow id="S7.SS6.p1.8.m8.1.1" xref="S7.SS6.p1.8.m8.1.1.cmml"><mo rspace="0.167em" id="S7.SS6.p1.8.m8.1.1.1" xref="S7.SS6.p1.8.m8.1.1.1.cmml">∀</mo><mi id="S7.SS6.p1.8.m8.1.1.2" xref="S7.SS6.p1.8.m8.1.1.2.cmml">u</mi></mrow><annotation-xml encoding="MathML-Content" id="S7.SS6.p1.8.m8.1b"><apply id="S7.SS6.p1.8.m8.1.1.cmml" xref="S7.SS6.p1.8.m8.1.1"><csymbol cd="latexml" id="S7.SS6.p1.8.m8.1.1.1.cmml" xref="S7.SS6.p1.8.m8.1.1.1">for-all</csymbol><ci id="S7.SS6.p1.8.m8.1.1.2.cmml" xref="S7.SS6.p1.8.m8.1.1.2">𝑢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS6.p1.8.m8.1c">\forall{u}</annotation></semantics></math>. Equality of opportunity tries to produce an equal probability that the probability of prediction using sensitive attributes is the same as non-sensitive attributes. Equal Opportunity difference (EOD) can be the difference between True Positive Rate (TPR) for each group. EOD can be stated in the following way:</p>
<table id="S7.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S7.E5.m1.1" class="ltx_Math" alttext="EOD=|TPR_{dis}-TPR_{ad}|" display="block"><semantics id="S7.E5.m1.1a"><mrow id="S7.E5.m1.1.1" xref="S7.E5.m1.1.1.cmml"><mrow id="S7.E5.m1.1.1.3" xref="S7.E5.m1.1.1.3.cmml"><mi id="S7.E5.m1.1.1.3.2" xref="S7.E5.m1.1.1.3.2.cmml">E</mi><mo lspace="0em" rspace="0em" id="S7.E5.m1.1.1.3.1" xref="S7.E5.m1.1.1.3.1.cmml">​</mo><mi id="S7.E5.m1.1.1.3.3" xref="S7.E5.m1.1.1.3.3.cmml">O</mi><mo lspace="0em" rspace="0em" id="S7.E5.m1.1.1.3.1a" xref="S7.E5.m1.1.1.3.1.cmml">​</mo><mi id="S7.E5.m1.1.1.3.4" xref="S7.E5.m1.1.1.3.4.cmml">D</mi></mrow><mo id="S7.E5.m1.1.1.2" xref="S7.E5.m1.1.1.2.cmml">=</mo><mrow id="S7.E5.m1.1.1.1.1" xref="S7.E5.m1.1.1.1.2.cmml"><mo stretchy="false" id="S7.E5.m1.1.1.1.1.2" xref="S7.E5.m1.1.1.1.2.1.cmml">|</mo><mrow id="S7.E5.m1.1.1.1.1.1" xref="S7.E5.m1.1.1.1.1.1.cmml"><mrow id="S7.E5.m1.1.1.1.1.1.2" xref="S7.E5.m1.1.1.1.1.1.2.cmml"><mi id="S7.E5.m1.1.1.1.1.1.2.2" xref="S7.E5.m1.1.1.1.1.1.2.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S7.E5.m1.1.1.1.1.1.2.1" xref="S7.E5.m1.1.1.1.1.1.2.1.cmml">​</mo><mi id="S7.E5.m1.1.1.1.1.1.2.3" xref="S7.E5.m1.1.1.1.1.1.2.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="S7.E5.m1.1.1.1.1.1.2.1a" xref="S7.E5.m1.1.1.1.1.1.2.1.cmml">​</mo><msub id="S7.E5.m1.1.1.1.1.1.2.4" xref="S7.E5.m1.1.1.1.1.1.2.4.cmml"><mi id="S7.E5.m1.1.1.1.1.1.2.4.2" xref="S7.E5.m1.1.1.1.1.1.2.4.2.cmml">R</mi><mrow id="S7.E5.m1.1.1.1.1.1.2.4.3" xref="S7.E5.m1.1.1.1.1.1.2.4.3.cmml"><mi id="S7.E5.m1.1.1.1.1.1.2.4.3.2" xref="S7.E5.m1.1.1.1.1.1.2.4.3.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="S7.E5.m1.1.1.1.1.1.2.4.3.1" xref="S7.E5.m1.1.1.1.1.1.2.4.3.1.cmml">​</mo><mi id="S7.E5.m1.1.1.1.1.1.2.4.3.3" xref="S7.E5.m1.1.1.1.1.1.2.4.3.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S7.E5.m1.1.1.1.1.1.2.4.3.1a" xref="S7.E5.m1.1.1.1.1.1.2.4.3.1.cmml">​</mo><mi id="S7.E5.m1.1.1.1.1.1.2.4.3.4" xref="S7.E5.m1.1.1.1.1.1.2.4.3.4.cmml">s</mi></mrow></msub></mrow><mo id="S7.E5.m1.1.1.1.1.1.1" xref="S7.E5.m1.1.1.1.1.1.1.cmml">−</mo><mrow id="S7.E5.m1.1.1.1.1.1.3" xref="S7.E5.m1.1.1.1.1.1.3.cmml"><mi id="S7.E5.m1.1.1.1.1.1.3.2" xref="S7.E5.m1.1.1.1.1.1.3.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S7.E5.m1.1.1.1.1.1.3.1" xref="S7.E5.m1.1.1.1.1.1.3.1.cmml">​</mo><mi id="S7.E5.m1.1.1.1.1.1.3.3" xref="S7.E5.m1.1.1.1.1.1.3.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="S7.E5.m1.1.1.1.1.1.3.1a" xref="S7.E5.m1.1.1.1.1.1.3.1.cmml">​</mo><msub id="S7.E5.m1.1.1.1.1.1.3.4" xref="S7.E5.m1.1.1.1.1.1.3.4.cmml"><mi id="S7.E5.m1.1.1.1.1.1.3.4.2" xref="S7.E5.m1.1.1.1.1.1.3.4.2.cmml">R</mi><mrow id="S7.E5.m1.1.1.1.1.1.3.4.3" xref="S7.E5.m1.1.1.1.1.1.3.4.3.cmml"><mi id="S7.E5.m1.1.1.1.1.1.3.4.3.2" xref="S7.E5.m1.1.1.1.1.1.3.4.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S7.E5.m1.1.1.1.1.1.3.4.3.1" xref="S7.E5.m1.1.1.1.1.1.3.4.3.1.cmml">​</mo><mi id="S7.E5.m1.1.1.1.1.1.3.4.3.3" xref="S7.E5.m1.1.1.1.1.1.3.4.3.3.cmml">d</mi></mrow></msub></mrow></mrow><mo stretchy="false" id="S7.E5.m1.1.1.1.1.3" xref="S7.E5.m1.1.1.1.2.1.cmml">|</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S7.E5.m1.1b"><apply id="S7.E5.m1.1.1.cmml" xref="S7.E5.m1.1.1"><eq id="S7.E5.m1.1.1.2.cmml" xref="S7.E5.m1.1.1.2"></eq><apply id="S7.E5.m1.1.1.3.cmml" xref="S7.E5.m1.1.1.3"><times id="S7.E5.m1.1.1.3.1.cmml" xref="S7.E5.m1.1.1.3.1"></times><ci id="S7.E5.m1.1.1.3.2.cmml" xref="S7.E5.m1.1.1.3.2">𝐸</ci><ci id="S7.E5.m1.1.1.3.3.cmml" xref="S7.E5.m1.1.1.3.3">𝑂</ci><ci id="S7.E5.m1.1.1.3.4.cmml" xref="S7.E5.m1.1.1.3.4">𝐷</ci></apply><apply id="S7.E5.m1.1.1.1.2.cmml" xref="S7.E5.m1.1.1.1.1"><abs id="S7.E5.m1.1.1.1.2.1.cmml" xref="S7.E5.m1.1.1.1.1.2"></abs><apply id="S7.E5.m1.1.1.1.1.1.cmml" xref="S7.E5.m1.1.1.1.1.1"><minus id="S7.E5.m1.1.1.1.1.1.1.cmml" xref="S7.E5.m1.1.1.1.1.1.1"></minus><apply id="S7.E5.m1.1.1.1.1.1.2.cmml" xref="S7.E5.m1.1.1.1.1.1.2"><times id="S7.E5.m1.1.1.1.1.1.2.1.cmml" xref="S7.E5.m1.1.1.1.1.1.2.1"></times><ci id="S7.E5.m1.1.1.1.1.1.2.2.cmml" xref="S7.E5.m1.1.1.1.1.1.2.2">𝑇</ci><ci id="S7.E5.m1.1.1.1.1.1.2.3.cmml" xref="S7.E5.m1.1.1.1.1.1.2.3">𝑃</ci><apply id="S7.E5.m1.1.1.1.1.1.2.4.cmml" xref="S7.E5.m1.1.1.1.1.1.2.4"><csymbol cd="ambiguous" id="S7.E5.m1.1.1.1.1.1.2.4.1.cmml" xref="S7.E5.m1.1.1.1.1.1.2.4">subscript</csymbol><ci id="S7.E5.m1.1.1.1.1.1.2.4.2.cmml" xref="S7.E5.m1.1.1.1.1.1.2.4.2">𝑅</ci><apply id="S7.E5.m1.1.1.1.1.1.2.4.3.cmml" xref="S7.E5.m1.1.1.1.1.1.2.4.3"><times id="S7.E5.m1.1.1.1.1.1.2.4.3.1.cmml" xref="S7.E5.m1.1.1.1.1.1.2.4.3.1"></times><ci id="S7.E5.m1.1.1.1.1.1.2.4.3.2.cmml" xref="S7.E5.m1.1.1.1.1.1.2.4.3.2">𝑑</ci><ci id="S7.E5.m1.1.1.1.1.1.2.4.3.3.cmml" xref="S7.E5.m1.1.1.1.1.1.2.4.3.3">𝑖</ci><ci id="S7.E5.m1.1.1.1.1.1.2.4.3.4.cmml" xref="S7.E5.m1.1.1.1.1.1.2.4.3.4">𝑠</ci></apply></apply></apply><apply id="S7.E5.m1.1.1.1.1.1.3.cmml" xref="S7.E5.m1.1.1.1.1.1.3"><times id="S7.E5.m1.1.1.1.1.1.3.1.cmml" xref="S7.E5.m1.1.1.1.1.1.3.1"></times><ci id="S7.E5.m1.1.1.1.1.1.3.2.cmml" xref="S7.E5.m1.1.1.1.1.1.3.2">𝑇</ci><ci id="S7.E5.m1.1.1.1.1.1.3.3.cmml" xref="S7.E5.m1.1.1.1.1.1.3.3">𝑃</ci><apply id="S7.E5.m1.1.1.1.1.1.3.4.cmml" xref="S7.E5.m1.1.1.1.1.1.3.4"><csymbol cd="ambiguous" id="S7.E5.m1.1.1.1.1.1.3.4.1.cmml" xref="S7.E5.m1.1.1.1.1.1.3.4">subscript</csymbol><ci id="S7.E5.m1.1.1.1.1.1.3.4.2.cmml" xref="S7.E5.m1.1.1.1.1.1.3.4.2">𝑅</ci><apply id="S7.E5.m1.1.1.1.1.1.3.4.3.cmml" xref="S7.E5.m1.1.1.1.1.1.3.4.3"><times id="S7.E5.m1.1.1.1.1.1.3.4.3.1.cmml" xref="S7.E5.m1.1.1.1.1.1.3.4.3.1"></times><ci id="S7.E5.m1.1.1.1.1.1.3.4.3.2.cmml" xref="S7.E5.m1.1.1.1.1.1.3.4.3.2">𝑎</ci><ci id="S7.E5.m1.1.1.1.1.1.3.4.3.3.cmml" xref="S7.E5.m1.1.1.1.1.1.3.4.3.3">𝑑</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.E5.m1.1c">EOD=|TPR_{dis}-TPR_{ad}|</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<p id="S7.SS6.p1.9" class="ltx_p"><span id="S7.SS6.p1.9.1" class="ltx_text ltx_font_bold">Statistical Parity.</span>
Statistical parity <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite> awards the classifier for correctly categorizing each group(groups that contain sensitive property and groups that lack any sensitive property) as positive at the same rate.
Hence, a model is considered fair from the standpoint of statistical parity, if it correctly identifies positive cases for both samples with sensitive and normal attributes.
Statistical parity difference (SPD) can be defined as the variation or difference in the proportion of successful outcomes for each group. SPD can be defined as:</p>
</div>
<div id="S7.SS6.p2" class="ltx_para">
<table id="S7.E6" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S7.E6.m1.3" class="ltx_Math" alttext="SPD=|(\frac{TP_{dis}}{N_{dis}})-(\frac{TP_{ad}}{N_{ad}})|" display="block"><semantics id="S7.E6.m1.3a"><mrow id="S7.E6.m1.3.3" xref="S7.E6.m1.3.3.cmml"><mrow id="S7.E6.m1.3.3.3" xref="S7.E6.m1.3.3.3.cmml"><mi id="S7.E6.m1.3.3.3.2" xref="S7.E6.m1.3.3.3.2.cmml">S</mi><mo lspace="0em" rspace="0em" id="S7.E6.m1.3.3.3.1" xref="S7.E6.m1.3.3.3.1.cmml">​</mo><mi id="S7.E6.m1.3.3.3.3" xref="S7.E6.m1.3.3.3.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="S7.E6.m1.3.3.3.1a" xref="S7.E6.m1.3.3.3.1.cmml">​</mo><mi id="S7.E6.m1.3.3.3.4" xref="S7.E6.m1.3.3.3.4.cmml">D</mi></mrow><mo id="S7.E6.m1.3.3.2" xref="S7.E6.m1.3.3.2.cmml">=</mo><mrow id="S7.E6.m1.3.3.1.1" xref="S7.E6.m1.3.3.1.2.cmml"><mo stretchy="false" id="S7.E6.m1.3.3.1.1.2" xref="S7.E6.m1.3.3.1.2.1.cmml">|</mo><mrow id="S7.E6.m1.3.3.1.1.1" xref="S7.E6.m1.3.3.1.1.1.cmml"><mrow id="S7.E6.m1.3.3.1.1.1.2.2" xref="S7.E6.m1.1.1.cmml"><mo stretchy="false" id="S7.E6.m1.3.3.1.1.1.2.2.1" xref="S7.E6.m1.1.1.cmml">(</mo><mfrac id="S7.E6.m1.1.1" xref="S7.E6.m1.1.1.cmml"><mrow id="S7.E6.m1.1.1.2" xref="S7.E6.m1.1.1.2.cmml"><mi id="S7.E6.m1.1.1.2.2" xref="S7.E6.m1.1.1.2.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S7.E6.m1.1.1.2.1" xref="S7.E6.m1.1.1.2.1.cmml">​</mo><msub id="S7.E6.m1.1.1.2.3" xref="S7.E6.m1.1.1.2.3.cmml"><mi id="S7.E6.m1.1.1.2.3.2" xref="S7.E6.m1.1.1.2.3.2.cmml">P</mi><mrow id="S7.E6.m1.1.1.2.3.3" xref="S7.E6.m1.1.1.2.3.3.cmml"><mi id="S7.E6.m1.1.1.2.3.3.2" xref="S7.E6.m1.1.1.2.3.3.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="S7.E6.m1.1.1.2.3.3.1" xref="S7.E6.m1.1.1.2.3.3.1.cmml">​</mo><mi id="S7.E6.m1.1.1.2.3.3.3" xref="S7.E6.m1.1.1.2.3.3.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S7.E6.m1.1.1.2.3.3.1a" xref="S7.E6.m1.1.1.2.3.3.1.cmml">​</mo><mi id="S7.E6.m1.1.1.2.3.3.4" xref="S7.E6.m1.1.1.2.3.3.4.cmml">s</mi></mrow></msub></mrow><msub id="S7.E6.m1.1.1.3" xref="S7.E6.m1.1.1.3.cmml"><mi id="S7.E6.m1.1.1.3.2" xref="S7.E6.m1.1.1.3.2.cmml">N</mi><mrow id="S7.E6.m1.1.1.3.3" xref="S7.E6.m1.1.1.3.3.cmml"><mi id="S7.E6.m1.1.1.3.3.2" xref="S7.E6.m1.1.1.3.3.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="S7.E6.m1.1.1.3.3.1" xref="S7.E6.m1.1.1.3.3.1.cmml">​</mo><mi id="S7.E6.m1.1.1.3.3.3" xref="S7.E6.m1.1.1.3.3.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S7.E6.m1.1.1.3.3.1a" xref="S7.E6.m1.1.1.3.3.1.cmml">​</mo><mi id="S7.E6.m1.1.1.3.3.4" xref="S7.E6.m1.1.1.3.3.4.cmml">s</mi></mrow></msub></mfrac><mo stretchy="false" id="S7.E6.m1.3.3.1.1.1.2.2.2" xref="S7.E6.m1.1.1.cmml">)</mo></mrow><mo id="S7.E6.m1.3.3.1.1.1.1" xref="S7.E6.m1.3.3.1.1.1.1.cmml">−</mo><mrow id="S7.E6.m1.3.3.1.1.1.3.2" xref="S7.E6.m1.2.2.cmml"><mo stretchy="false" id="S7.E6.m1.3.3.1.1.1.3.2.1" xref="S7.E6.m1.2.2.cmml">(</mo><mfrac id="S7.E6.m1.2.2" xref="S7.E6.m1.2.2.cmml"><mrow id="S7.E6.m1.2.2.2" xref="S7.E6.m1.2.2.2.cmml"><mi id="S7.E6.m1.2.2.2.2" xref="S7.E6.m1.2.2.2.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S7.E6.m1.2.2.2.1" xref="S7.E6.m1.2.2.2.1.cmml">​</mo><msub id="S7.E6.m1.2.2.2.3" xref="S7.E6.m1.2.2.2.3.cmml"><mi id="S7.E6.m1.2.2.2.3.2" xref="S7.E6.m1.2.2.2.3.2.cmml">P</mi><mrow id="S7.E6.m1.2.2.2.3.3" xref="S7.E6.m1.2.2.2.3.3.cmml"><mi id="S7.E6.m1.2.2.2.3.3.2" xref="S7.E6.m1.2.2.2.3.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S7.E6.m1.2.2.2.3.3.1" xref="S7.E6.m1.2.2.2.3.3.1.cmml">​</mo><mi id="S7.E6.m1.2.2.2.3.3.3" xref="S7.E6.m1.2.2.2.3.3.3.cmml">d</mi></mrow></msub></mrow><msub id="S7.E6.m1.2.2.3" xref="S7.E6.m1.2.2.3.cmml"><mi id="S7.E6.m1.2.2.3.2" xref="S7.E6.m1.2.2.3.2.cmml">N</mi><mrow id="S7.E6.m1.2.2.3.3" xref="S7.E6.m1.2.2.3.3.cmml"><mi id="S7.E6.m1.2.2.3.3.2" xref="S7.E6.m1.2.2.3.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S7.E6.m1.2.2.3.3.1" xref="S7.E6.m1.2.2.3.3.1.cmml">​</mo><mi id="S7.E6.m1.2.2.3.3.3" xref="S7.E6.m1.2.2.3.3.3.cmml">d</mi></mrow></msub></mfrac><mo stretchy="false" id="S7.E6.m1.3.3.1.1.1.3.2.2" xref="S7.E6.m1.2.2.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S7.E6.m1.3.3.1.1.3" xref="S7.E6.m1.3.3.1.2.1.cmml">|</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S7.E6.m1.3b"><apply id="S7.E6.m1.3.3.cmml" xref="S7.E6.m1.3.3"><eq id="S7.E6.m1.3.3.2.cmml" xref="S7.E6.m1.3.3.2"></eq><apply id="S7.E6.m1.3.3.3.cmml" xref="S7.E6.m1.3.3.3"><times id="S7.E6.m1.3.3.3.1.cmml" xref="S7.E6.m1.3.3.3.1"></times><ci id="S7.E6.m1.3.3.3.2.cmml" xref="S7.E6.m1.3.3.3.2">𝑆</ci><ci id="S7.E6.m1.3.3.3.3.cmml" xref="S7.E6.m1.3.3.3.3">𝑃</ci><ci id="S7.E6.m1.3.3.3.4.cmml" xref="S7.E6.m1.3.3.3.4">𝐷</ci></apply><apply id="S7.E6.m1.3.3.1.2.cmml" xref="S7.E6.m1.3.3.1.1"><abs id="S7.E6.m1.3.3.1.2.1.cmml" xref="S7.E6.m1.3.3.1.1.2"></abs><apply id="S7.E6.m1.3.3.1.1.1.cmml" xref="S7.E6.m1.3.3.1.1.1"><minus id="S7.E6.m1.3.3.1.1.1.1.cmml" xref="S7.E6.m1.3.3.1.1.1.1"></minus><apply id="S7.E6.m1.1.1.cmml" xref="S7.E6.m1.3.3.1.1.1.2.2"><divide id="S7.E6.m1.1.1.1.cmml" xref="S7.E6.m1.3.3.1.1.1.2.2"></divide><apply id="S7.E6.m1.1.1.2.cmml" xref="S7.E6.m1.1.1.2"><times id="S7.E6.m1.1.1.2.1.cmml" xref="S7.E6.m1.1.1.2.1"></times><ci id="S7.E6.m1.1.1.2.2.cmml" xref="S7.E6.m1.1.1.2.2">𝑇</ci><apply id="S7.E6.m1.1.1.2.3.cmml" xref="S7.E6.m1.1.1.2.3"><csymbol cd="ambiguous" id="S7.E6.m1.1.1.2.3.1.cmml" xref="S7.E6.m1.1.1.2.3">subscript</csymbol><ci id="S7.E6.m1.1.1.2.3.2.cmml" xref="S7.E6.m1.1.1.2.3.2">𝑃</ci><apply id="S7.E6.m1.1.1.2.3.3.cmml" xref="S7.E6.m1.1.1.2.3.3"><times id="S7.E6.m1.1.1.2.3.3.1.cmml" xref="S7.E6.m1.1.1.2.3.3.1"></times><ci id="S7.E6.m1.1.1.2.3.3.2.cmml" xref="S7.E6.m1.1.1.2.3.3.2">𝑑</ci><ci id="S7.E6.m1.1.1.2.3.3.3.cmml" xref="S7.E6.m1.1.1.2.3.3.3">𝑖</ci><ci id="S7.E6.m1.1.1.2.3.3.4.cmml" xref="S7.E6.m1.1.1.2.3.3.4">𝑠</ci></apply></apply></apply><apply id="S7.E6.m1.1.1.3.cmml" xref="S7.E6.m1.1.1.3"><csymbol cd="ambiguous" id="S7.E6.m1.1.1.3.1.cmml" xref="S7.E6.m1.1.1.3">subscript</csymbol><ci id="S7.E6.m1.1.1.3.2.cmml" xref="S7.E6.m1.1.1.3.2">𝑁</ci><apply id="S7.E6.m1.1.1.3.3.cmml" xref="S7.E6.m1.1.1.3.3"><times id="S7.E6.m1.1.1.3.3.1.cmml" xref="S7.E6.m1.1.1.3.3.1"></times><ci id="S7.E6.m1.1.1.3.3.2.cmml" xref="S7.E6.m1.1.1.3.3.2">𝑑</ci><ci id="S7.E6.m1.1.1.3.3.3.cmml" xref="S7.E6.m1.1.1.3.3.3">𝑖</ci><ci id="S7.E6.m1.1.1.3.3.4.cmml" xref="S7.E6.m1.1.1.3.3.4">𝑠</ci></apply></apply></apply><apply id="S7.E6.m1.2.2.cmml" xref="S7.E6.m1.3.3.1.1.1.3.2"><divide id="S7.E6.m1.2.2.1.cmml" xref="S7.E6.m1.3.3.1.1.1.3.2"></divide><apply id="S7.E6.m1.2.2.2.cmml" xref="S7.E6.m1.2.2.2"><times id="S7.E6.m1.2.2.2.1.cmml" xref="S7.E6.m1.2.2.2.1"></times><ci id="S7.E6.m1.2.2.2.2.cmml" xref="S7.E6.m1.2.2.2.2">𝑇</ci><apply id="S7.E6.m1.2.2.2.3.cmml" xref="S7.E6.m1.2.2.2.3"><csymbol cd="ambiguous" id="S7.E6.m1.2.2.2.3.1.cmml" xref="S7.E6.m1.2.2.2.3">subscript</csymbol><ci id="S7.E6.m1.2.2.2.3.2.cmml" xref="S7.E6.m1.2.2.2.3.2">𝑃</ci><apply id="S7.E6.m1.2.2.2.3.3.cmml" xref="S7.E6.m1.2.2.2.3.3"><times id="S7.E6.m1.2.2.2.3.3.1.cmml" xref="S7.E6.m1.2.2.2.3.3.1"></times><ci id="S7.E6.m1.2.2.2.3.3.2.cmml" xref="S7.E6.m1.2.2.2.3.3.2">𝑎</ci><ci id="S7.E6.m1.2.2.2.3.3.3.cmml" xref="S7.E6.m1.2.2.2.3.3.3">𝑑</ci></apply></apply></apply><apply id="S7.E6.m1.2.2.3.cmml" xref="S7.E6.m1.2.2.3"><csymbol cd="ambiguous" id="S7.E6.m1.2.2.3.1.cmml" xref="S7.E6.m1.2.2.3">subscript</csymbol><ci id="S7.E6.m1.2.2.3.2.cmml" xref="S7.E6.m1.2.2.3.2">𝑁</ci><apply id="S7.E6.m1.2.2.3.3.cmml" xref="S7.E6.m1.2.2.3.3"><times id="S7.E6.m1.2.2.3.3.1.cmml" xref="S7.E6.m1.2.2.3.3.1"></times><ci id="S7.E6.m1.2.2.3.3.2.cmml" xref="S7.E6.m1.2.2.3.3.2">𝑎</ci><ci id="S7.E6.m1.2.2.3.3.3.cmml" xref="S7.E6.m1.2.2.3.3.3">𝑑</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.E6.m1.3c">SPD=|(\frac{TP_{dis}}{N_{dis}})-(\frac{TP_{ad}}{N_{ad}})|</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
</div>
<div id="S7.SS6.p3" class="ltx_para">
<p id="S7.SS6.p3.1" class="ltx_p">Fairness is achieved in the case of values that are closer to zero for the EOD and SPD. If EOD and SPD yield positive results, it indicates that the disadvantaged group outperforms the advantaged group.</p>
</div>
</section>
</section>
<section id="S8" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8 </span><span id="S8.1.1" class="ltx_text ltx_font_smallcaps">Fairness Evaluation Metrics</span>
</h2>

<div id="S8.p1" class="ltx_para">
<p id="S8.p1.5" class="ltx_p">Establishing a set of performance assessment measures is crucial for the long-term viability of fairness-aware federated learning systems in order that the benefits of different proposed ways can be evaluated relatively.
Different metrics are generally used by different fairness-aware federated systems and are suitable for different scenarios and applications.
<br class="ltx_break"><span id="S8.p1.5.1" class="ltx_text ltx_font_bold">General Evaluation Metrics.</span>
Normally, accuracy is used as a general metric to quantify how well a model performs <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib85" title="" class="ltx_ref">85</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib117" title="" class="ltx_ref">117</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib142" title="" class="ltx_ref">142</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref">62</a>]</cite> and how each client contributes to the whole model so that an appropriate client selection scheme can be built <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib117" title="" class="ltx_ref">117</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref">62</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib164" title="" class="ltx_ref">164</a>]</cite>.
In contrast to accuracy, efficiency measures the performance of training, either by the number of rounds required during the training process or by the total training time taken. Some works attempt to lessen the training time <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib135" title="" class="ltx_ref">135</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib97" title="" class="ltx_ref">97</a>]</cite>, while others try to lessen the number of training rounds <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib185" title="" class="ltx_ref">185</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite>.
<br class="ltx_break"><span id="S8.p1.5.2" class="ltx_text ltx_font_bold">Evaluation of fairness.</span>
Fairness evaluation metrics such as Average Variance(AV), Pearson’s Correlation Coefficient, and various distance metrics are also used to evaluate fairness in Federated systems. Average Variance (AV) typically demonstrates how a particular algorithm or method varies over different systems or devices <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib97" title="" class="ltx_ref">97</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib185" title="" class="ltx_ref">185</a>]</cite>. A given system is considered fairer than another system if its AV is less than the other system.
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib117" title="" class="ltx_ref">117</a>]</cite> used the Pearson correlation coefficient for the quantification of collaboration fairness where the fairness range lies within [-1,1], with larger values signifying more fairness.</p>
<table id="S8.E7" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S8.E7.m1.3" class="ltx_Math" alttext="C_{ab}=\frac{\sum_{i=1}^{n}\left(a_{i}-\bar{a}\right)\left(b_{i}-\bar{b}\right)}{(N-1)std_{a}std_{b}}" display="block"><semantics id="S8.E7.m1.3a"><mrow id="S8.E7.m1.3.4" xref="S8.E7.m1.3.4.cmml"><msub id="S8.E7.m1.3.4.2" xref="S8.E7.m1.3.4.2.cmml"><mi id="S8.E7.m1.3.4.2.2" xref="S8.E7.m1.3.4.2.2.cmml">C</mi><mrow id="S8.E7.m1.3.4.2.3" xref="S8.E7.m1.3.4.2.3.cmml"><mi id="S8.E7.m1.3.4.2.3.2" xref="S8.E7.m1.3.4.2.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S8.E7.m1.3.4.2.3.1" xref="S8.E7.m1.3.4.2.3.1.cmml">​</mo><mi id="S8.E7.m1.3.4.2.3.3" xref="S8.E7.m1.3.4.2.3.3.cmml">b</mi></mrow></msub><mo id="S8.E7.m1.3.4.1" xref="S8.E7.m1.3.4.1.cmml">=</mo><mfrac id="S8.E7.m1.3.3" xref="S8.E7.m1.3.3.cmml"><mrow id="S8.E7.m1.2.2.2" xref="S8.E7.m1.2.2.2.cmml"><msubsup id="S8.E7.m1.2.2.2.3" xref="S8.E7.m1.2.2.2.3.cmml"><mo id="S8.E7.m1.2.2.2.3.2.2" xref="S8.E7.m1.2.2.2.3.2.2.cmml">∑</mo><mrow id="S8.E7.m1.2.2.2.3.2.3" xref="S8.E7.m1.2.2.2.3.2.3.cmml"><mi id="S8.E7.m1.2.2.2.3.2.3.2" xref="S8.E7.m1.2.2.2.3.2.3.2.cmml">i</mi><mo id="S8.E7.m1.2.2.2.3.2.3.1" xref="S8.E7.m1.2.2.2.3.2.3.1.cmml">=</mo><mn id="S8.E7.m1.2.2.2.3.2.3.3" xref="S8.E7.m1.2.2.2.3.2.3.3.cmml">1</mn></mrow><mi id="S8.E7.m1.2.2.2.3.3" xref="S8.E7.m1.2.2.2.3.3.cmml">n</mi></msubsup><mrow id="S8.E7.m1.2.2.2.2" xref="S8.E7.m1.2.2.2.2.cmml"><mrow id="S8.E7.m1.1.1.1.1.1.1" xref="S8.E7.m1.1.1.1.1.1.1.1.cmml"><mo lspace="0em" id="S8.E7.m1.1.1.1.1.1.1.2" xref="S8.E7.m1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S8.E7.m1.1.1.1.1.1.1.1" xref="S8.E7.m1.1.1.1.1.1.1.1.cmml"><msub id="S8.E7.m1.1.1.1.1.1.1.1.2" xref="S8.E7.m1.1.1.1.1.1.1.1.2.cmml"><mi id="S8.E7.m1.1.1.1.1.1.1.1.2.2" xref="S8.E7.m1.1.1.1.1.1.1.1.2.2.cmml">a</mi><mi id="S8.E7.m1.1.1.1.1.1.1.1.2.3" xref="S8.E7.m1.1.1.1.1.1.1.1.2.3.cmml">i</mi></msub><mo id="S8.E7.m1.1.1.1.1.1.1.1.1" xref="S8.E7.m1.1.1.1.1.1.1.1.1.cmml">−</mo><mover accent="true" id="S8.E7.m1.1.1.1.1.1.1.1.3" xref="S8.E7.m1.1.1.1.1.1.1.1.3.cmml"><mi id="S8.E7.m1.1.1.1.1.1.1.1.3.2" xref="S8.E7.m1.1.1.1.1.1.1.1.3.2.cmml">a</mi><mo id="S8.E7.m1.1.1.1.1.1.1.1.3.1" xref="S8.E7.m1.1.1.1.1.1.1.1.3.1.cmml">¯</mo></mover></mrow><mo id="S8.E7.m1.1.1.1.1.1.1.3" xref="S8.E7.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S8.E7.m1.2.2.2.2.3" xref="S8.E7.m1.2.2.2.2.3.cmml">​</mo><mrow id="S8.E7.m1.2.2.2.2.2.1" xref="S8.E7.m1.2.2.2.2.2.1.1.cmml"><mo id="S8.E7.m1.2.2.2.2.2.1.2" xref="S8.E7.m1.2.2.2.2.2.1.1.cmml">(</mo><mrow id="S8.E7.m1.2.2.2.2.2.1.1" xref="S8.E7.m1.2.2.2.2.2.1.1.cmml"><msub id="S8.E7.m1.2.2.2.2.2.1.1.2" xref="S8.E7.m1.2.2.2.2.2.1.1.2.cmml"><mi id="S8.E7.m1.2.2.2.2.2.1.1.2.2" xref="S8.E7.m1.2.2.2.2.2.1.1.2.2.cmml">b</mi><mi id="S8.E7.m1.2.2.2.2.2.1.1.2.3" xref="S8.E7.m1.2.2.2.2.2.1.1.2.3.cmml">i</mi></msub><mo id="S8.E7.m1.2.2.2.2.2.1.1.1" xref="S8.E7.m1.2.2.2.2.2.1.1.1.cmml">−</mo><mover accent="true" id="S8.E7.m1.2.2.2.2.2.1.1.3" xref="S8.E7.m1.2.2.2.2.2.1.1.3.cmml"><mi id="S8.E7.m1.2.2.2.2.2.1.1.3.2" xref="S8.E7.m1.2.2.2.2.2.1.1.3.2.cmml">b</mi><mo id="S8.E7.m1.2.2.2.2.2.1.1.3.1" xref="S8.E7.m1.2.2.2.2.2.1.1.3.1.cmml">¯</mo></mover></mrow><mo id="S8.E7.m1.2.2.2.2.2.1.3" xref="S8.E7.m1.2.2.2.2.2.1.1.cmml">)</mo></mrow></mrow></mrow><mrow id="S8.E7.m1.3.3.3" xref="S8.E7.m1.3.3.3.cmml"><mrow id="S8.E7.m1.3.3.3.1.1" xref="S8.E7.m1.3.3.3.1.1.1.cmml"><mo stretchy="false" id="S8.E7.m1.3.3.3.1.1.2" xref="S8.E7.m1.3.3.3.1.1.1.cmml">(</mo><mrow id="S8.E7.m1.3.3.3.1.1.1" xref="S8.E7.m1.3.3.3.1.1.1.cmml"><mi id="S8.E7.m1.3.3.3.1.1.1.2" xref="S8.E7.m1.3.3.3.1.1.1.2.cmml">N</mi><mo id="S8.E7.m1.3.3.3.1.1.1.1" xref="S8.E7.m1.3.3.3.1.1.1.1.cmml">−</mo><mn id="S8.E7.m1.3.3.3.1.1.1.3" xref="S8.E7.m1.3.3.3.1.1.1.3.cmml">1</mn></mrow><mo stretchy="false" id="S8.E7.m1.3.3.3.1.1.3" xref="S8.E7.m1.3.3.3.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S8.E7.m1.3.3.3.2" xref="S8.E7.m1.3.3.3.2.cmml">​</mo><mi id="S8.E7.m1.3.3.3.3" xref="S8.E7.m1.3.3.3.3.cmml">s</mi><mo lspace="0em" rspace="0em" id="S8.E7.m1.3.3.3.2a" xref="S8.E7.m1.3.3.3.2.cmml">​</mo><mi id="S8.E7.m1.3.3.3.4" xref="S8.E7.m1.3.3.3.4.cmml">t</mi><mo lspace="0em" rspace="0em" id="S8.E7.m1.3.3.3.2b" xref="S8.E7.m1.3.3.3.2.cmml">​</mo><msub id="S8.E7.m1.3.3.3.5" xref="S8.E7.m1.3.3.3.5.cmml"><mi id="S8.E7.m1.3.3.3.5.2" xref="S8.E7.m1.3.3.3.5.2.cmml">d</mi><mi id="S8.E7.m1.3.3.3.5.3" xref="S8.E7.m1.3.3.3.5.3.cmml">a</mi></msub><mo lspace="0em" rspace="0em" id="S8.E7.m1.3.3.3.2c" xref="S8.E7.m1.3.3.3.2.cmml">​</mo><mi id="S8.E7.m1.3.3.3.6" xref="S8.E7.m1.3.3.3.6.cmml">s</mi><mo lspace="0em" rspace="0em" id="S8.E7.m1.3.3.3.2d" xref="S8.E7.m1.3.3.3.2.cmml">​</mo><mi id="S8.E7.m1.3.3.3.7" xref="S8.E7.m1.3.3.3.7.cmml">t</mi><mo lspace="0em" rspace="0em" id="S8.E7.m1.3.3.3.2e" xref="S8.E7.m1.3.3.3.2.cmml">​</mo><msub id="S8.E7.m1.3.3.3.8" xref="S8.E7.m1.3.3.3.8.cmml"><mi id="S8.E7.m1.3.3.3.8.2" xref="S8.E7.m1.3.3.3.8.2.cmml">d</mi><mi id="S8.E7.m1.3.3.3.8.3" xref="S8.E7.m1.3.3.3.8.3.cmml">b</mi></msub></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S8.E7.m1.3b"><apply id="S8.E7.m1.3.4.cmml" xref="S8.E7.m1.3.4"><eq id="S8.E7.m1.3.4.1.cmml" xref="S8.E7.m1.3.4.1"></eq><apply id="S8.E7.m1.3.4.2.cmml" xref="S8.E7.m1.3.4.2"><csymbol cd="ambiguous" id="S8.E7.m1.3.4.2.1.cmml" xref="S8.E7.m1.3.4.2">subscript</csymbol><ci id="S8.E7.m1.3.4.2.2.cmml" xref="S8.E7.m1.3.4.2.2">𝐶</ci><apply id="S8.E7.m1.3.4.2.3.cmml" xref="S8.E7.m1.3.4.2.3"><times id="S8.E7.m1.3.4.2.3.1.cmml" xref="S8.E7.m1.3.4.2.3.1"></times><ci id="S8.E7.m1.3.4.2.3.2.cmml" xref="S8.E7.m1.3.4.2.3.2">𝑎</ci><ci id="S8.E7.m1.3.4.2.3.3.cmml" xref="S8.E7.m1.3.4.2.3.3">𝑏</ci></apply></apply><apply id="S8.E7.m1.3.3.cmml" xref="S8.E7.m1.3.3"><divide id="S8.E7.m1.3.3.4.cmml" xref="S8.E7.m1.3.3"></divide><apply id="S8.E7.m1.2.2.2.cmml" xref="S8.E7.m1.2.2.2"><apply id="S8.E7.m1.2.2.2.3.cmml" xref="S8.E7.m1.2.2.2.3"><csymbol cd="ambiguous" id="S8.E7.m1.2.2.2.3.1.cmml" xref="S8.E7.m1.2.2.2.3">superscript</csymbol><apply id="S8.E7.m1.2.2.2.3.2.cmml" xref="S8.E7.m1.2.2.2.3"><csymbol cd="ambiguous" id="S8.E7.m1.2.2.2.3.2.1.cmml" xref="S8.E7.m1.2.2.2.3">subscript</csymbol><sum id="S8.E7.m1.2.2.2.3.2.2.cmml" xref="S8.E7.m1.2.2.2.3.2.2"></sum><apply id="S8.E7.m1.2.2.2.3.2.3.cmml" xref="S8.E7.m1.2.2.2.3.2.3"><eq id="S8.E7.m1.2.2.2.3.2.3.1.cmml" xref="S8.E7.m1.2.2.2.3.2.3.1"></eq><ci id="S8.E7.m1.2.2.2.3.2.3.2.cmml" xref="S8.E7.m1.2.2.2.3.2.3.2">𝑖</ci><cn type="integer" id="S8.E7.m1.2.2.2.3.2.3.3.cmml" xref="S8.E7.m1.2.2.2.3.2.3.3">1</cn></apply></apply><ci id="S8.E7.m1.2.2.2.3.3.cmml" xref="S8.E7.m1.2.2.2.3.3">𝑛</ci></apply><apply id="S8.E7.m1.2.2.2.2.cmml" xref="S8.E7.m1.2.2.2.2"><times id="S8.E7.m1.2.2.2.2.3.cmml" xref="S8.E7.m1.2.2.2.2.3"></times><apply id="S8.E7.m1.1.1.1.1.1.1.1.cmml" xref="S8.E7.m1.1.1.1.1.1.1"><minus id="S8.E7.m1.1.1.1.1.1.1.1.1.cmml" xref="S8.E7.m1.1.1.1.1.1.1.1.1"></minus><apply id="S8.E7.m1.1.1.1.1.1.1.1.2.cmml" xref="S8.E7.m1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S8.E7.m1.1.1.1.1.1.1.1.2.1.cmml" xref="S8.E7.m1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S8.E7.m1.1.1.1.1.1.1.1.2.2.cmml" xref="S8.E7.m1.1.1.1.1.1.1.1.2.2">𝑎</ci><ci id="S8.E7.m1.1.1.1.1.1.1.1.2.3.cmml" xref="S8.E7.m1.1.1.1.1.1.1.1.2.3">𝑖</ci></apply><apply id="S8.E7.m1.1.1.1.1.1.1.1.3.cmml" xref="S8.E7.m1.1.1.1.1.1.1.1.3"><ci id="S8.E7.m1.1.1.1.1.1.1.1.3.1.cmml" xref="S8.E7.m1.1.1.1.1.1.1.1.3.1">¯</ci><ci id="S8.E7.m1.1.1.1.1.1.1.1.3.2.cmml" xref="S8.E7.m1.1.1.1.1.1.1.1.3.2">𝑎</ci></apply></apply><apply id="S8.E7.m1.2.2.2.2.2.1.1.cmml" xref="S8.E7.m1.2.2.2.2.2.1"><minus id="S8.E7.m1.2.2.2.2.2.1.1.1.cmml" xref="S8.E7.m1.2.2.2.2.2.1.1.1"></minus><apply id="S8.E7.m1.2.2.2.2.2.1.1.2.cmml" xref="S8.E7.m1.2.2.2.2.2.1.1.2"><csymbol cd="ambiguous" id="S8.E7.m1.2.2.2.2.2.1.1.2.1.cmml" xref="S8.E7.m1.2.2.2.2.2.1.1.2">subscript</csymbol><ci id="S8.E7.m1.2.2.2.2.2.1.1.2.2.cmml" xref="S8.E7.m1.2.2.2.2.2.1.1.2.2">𝑏</ci><ci id="S8.E7.m1.2.2.2.2.2.1.1.2.3.cmml" xref="S8.E7.m1.2.2.2.2.2.1.1.2.3">𝑖</ci></apply><apply id="S8.E7.m1.2.2.2.2.2.1.1.3.cmml" xref="S8.E7.m1.2.2.2.2.2.1.1.3"><ci id="S8.E7.m1.2.2.2.2.2.1.1.3.1.cmml" xref="S8.E7.m1.2.2.2.2.2.1.1.3.1">¯</ci><ci id="S8.E7.m1.2.2.2.2.2.1.1.3.2.cmml" xref="S8.E7.m1.2.2.2.2.2.1.1.3.2">𝑏</ci></apply></apply></apply></apply><apply id="S8.E7.m1.3.3.3.cmml" xref="S8.E7.m1.3.3.3"><times id="S8.E7.m1.3.3.3.2.cmml" xref="S8.E7.m1.3.3.3.2"></times><apply id="S8.E7.m1.3.3.3.1.1.1.cmml" xref="S8.E7.m1.3.3.3.1.1"><minus id="S8.E7.m1.3.3.3.1.1.1.1.cmml" xref="S8.E7.m1.3.3.3.1.1.1.1"></minus><ci id="S8.E7.m1.3.3.3.1.1.1.2.cmml" xref="S8.E7.m1.3.3.3.1.1.1.2">𝑁</ci><cn type="integer" id="S8.E7.m1.3.3.3.1.1.1.3.cmml" xref="S8.E7.m1.3.3.3.1.1.1.3">1</cn></apply><ci id="S8.E7.m1.3.3.3.3.cmml" xref="S8.E7.m1.3.3.3.3">𝑠</ci><ci id="S8.E7.m1.3.3.3.4.cmml" xref="S8.E7.m1.3.3.3.4">𝑡</ci><apply id="S8.E7.m1.3.3.3.5.cmml" xref="S8.E7.m1.3.3.3.5"><csymbol cd="ambiguous" id="S8.E7.m1.3.3.3.5.1.cmml" xref="S8.E7.m1.3.3.3.5">subscript</csymbol><ci id="S8.E7.m1.3.3.3.5.2.cmml" xref="S8.E7.m1.3.3.3.5.2">𝑑</ci><ci id="S8.E7.m1.3.3.3.5.3.cmml" xref="S8.E7.m1.3.3.3.5.3">𝑎</ci></apply><ci id="S8.E7.m1.3.3.3.6.cmml" xref="S8.E7.m1.3.3.3.6">𝑠</ci><ci id="S8.E7.m1.3.3.3.7.cmml" xref="S8.E7.m1.3.3.3.7">𝑡</ci><apply id="S8.E7.m1.3.3.3.8.cmml" xref="S8.E7.m1.3.3.3.8"><csymbol cd="ambiguous" id="S8.E7.m1.3.3.3.8.1.cmml" xref="S8.E7.m1.3.3.3.8">subscript</csymbol><ci id="S8.E7.m1.3.3.3.8.2.cmml" xref="S8.E7.m1.3.3.3.8.2">𝑑</ci><ci id="S8.E7.m1.3.3.3.8.3.cmml" xref="S8.E7.m1.3.3.3.8.3">𝑏</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S8.E7.m1.3c">C_{ab}=\frac{\sum_{i=1}^{n}\left(a_{i}-\bar{a}\right)\left(b_{i}-\bar{b}\right)}{(N-1)std_{a}std_{b}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(7)</span></td>
</tr></tbody>
</table>
<p id="S8.p1.4" class="ltx_p">A negative coefficient, on the other hand, indicates unequal treatment. Here, <math id="S8.p1.1.m1.1" class="ltx_Math" alttext="\bar{a}" display="inline"><semantics id="S8.p1.1.m1.1a"><mover accent="true" id="S8.p1.1.m1.1.1" xref="S8.p1.1.m1.1.1.cmml"><mi id="S8.p1.1.m1.1.1.2" xref="S8.p1.1.m1.1.1.2.cmml">a</mi><mo id="S8.p1.1.m1.1.1.1" xref="S8.p1.1.m1.1.1.1.cmml">¯</mo></mover><annotation-xml encoding="MathML-Content" id="S8.p1.1.m1.1b"><apply id="S8.p1.1.m1.1.1.cmml" xref="S8.p1.1.m1.1.1"><ci id="S8.p1.1.m1.1.1.1.cmml" xref="S8.p1.1.m1.1.1.1">¯</ci><ci id="S8.p1.1.m1.1.1.2.cmml" xref="S8.p1.1.m1.1.1.2">𝑎</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S8.p1.1.m1.1c">\bar{a}</annotation></semantics></math> and <math id="S8.p1.2.m2.1" class="ltx_Math" alttext="\bar{b}" display="inline"><semantics id="S8.p1.2.m2.1a"><mover accent="true" id="S8.p1.2.m2.1.1" xref="S8.p1.2.m2.1.1.cmml"><mi id="S8.p1.2.m2.1.1.2" xref="S8.p1.2.m2.1.1.2.cmml">b</mi><mo id="S8.p1.2.m2.1.1.1" xref="S8.p1.2.m2.1.1.1.cmml">¯</mo></mover><annotation-xml encoding="MathML-Content" id="S8.p1.2.m2.1b"><apply id="S8.p1.2.m2.1.1.cmml" xref="S8.p1.2.m2.1.1"><ci id="S8.p1.2.m2.1.1.1.cmml" xref="S8.p1.2.m2.1.1.1">¯</ci><ci id="S8.p1.2.m2.1.1.2.cmml" xref="S8.p1.2.m2.1.1.2">𝑏</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S8.p1.2.m2.1c">\bar{b}</annotation></semantics></math> are the sample means of a and b, respectively, while <math id="S8.p1.3.m3.1" class="ltx_Math" alttext="std_{a}" display="inline"><semantics id="S8.p1.3.m3.1a"><mrow id="S8.p1.3.m3.1.1" xref="S8.p1.3.m3.1.1.cmml"><mi id="S8.p1.3.m3.1.1.2" xref="S8.p1.3.m3.1.1.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S8.p1.3.m3.1.1.1" xref="S8.p1.3.m3.1.1.1.cmml">​</mo><mi id="S8.p1.3.m3.1.1.3" xref="S8.p1.3.m3.1.1.3.cmml">t</mi><mo lspace="0em" rspace="0em" id="S8.p1.3.m3.1.1.1a" xref="S8.p1.3.m3.1.1.1.cmml">​</mo><msub id="S8.p1.3.m3.1.1.4" xref="S8.p1.3.m3.1.1.4.cmml"><mi id="S8.p1.3.m3.1.1.4.2" xref="S8.p1.3.m3.1.1.4.2.cmml">d</mi><mi id="S8.p1.3.m3.1.1.4.3" xref="S8.p1.3.m3.1.1.4.3.cmml">a</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S8.p1.3.m3.1b"><apply id="S8.p1.3.m3.1.1.cmml" xref="S8.p1.3.m3.1.1"><times id="S8.p1.3.m3.1.1.1.cmml" xref="S8.p1.3.m3.1.1.1"></times><ci id="S8.p1.3.m3.1.1.2.cmml" xref="S8.p1.3.m3.1.1.2">𝑠</ci><ci id="S8.p1.3.m3.1.1.3.cmml" xref="S8.p1.3.m3.1.1.3">𝑡</ci><apply id="S8.p1.3.m3.1.1.4.cmml" xref="S8.p1.3.m3.1.1.4"><csymbol cd="ambiguous" id="S8.p1.3.m3.1.1.4.1.cmml" xref="S8.p1.3.m3.1.1.4">subscript</csymbol><ci id="S8.p1.3.m3.1.1.4.2.cmml" xref="S8.p1.3.m3.1.1.4.2">𝑑</ci><ci id="S8.p1.3.m3.1.1.4.3.cmml" xref="S8.p1.3.m3.1.1.4.3">𝑎</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S8.p1.3.m3.1c">std_{a}</annotation></semantics></math> and <math id="S8.p1.4.m4.1" class="ltx_Math" alttext="std_{b}" display="inline"><semantics id="S8.p1.4.m4.1a"><mrow id="S8.p1.4.m4.1.1" xref="S8.p1.4.m4.1.1.cmml"><mi id="S8.p1.4.m4.1.1.2" xref="S8.p1.4.m4.1.1.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S8.p1.4.m4.1.1.1" xref="S8.p1.4.m4.1.1.1.cmml">​</mo><mi id="S8.p1.4.m4.1.1.3" xref="S8.p1.4.m4.1.1.3.cmml">t</mi><mo lspace="0em" rspace="0em" id="S8.p1.4.m4.1.1.1a" xref="S8.p1.4.m4.1.1.1.cmml">​</mo><msub id="S8.p1.4.m4.1.1.4" xref="S8.p1.4.m4.1.1.4.cmml"><mi id="S8.p1.4.m4.1.1.4.2" xref="S8.p1.4.m4.1.1.4.2.cmml">d</mi><mi id="S8.p1.4.m4.1.1.4.3" xref="S8.p1.4.m4.1.1.4.3.cmml">b</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S8.p1.4.m4.1b"><apply id="S8.p1.4.m4.1.1.cmml" xref="S8.p1.4.m4.1.1"><times id="S8.p1.4.m4.1.1.1.cmml" xref="S8.p1.4.m4.1.1.1"></times><ci id="S8.p1.4.m4.1.1.2.cmml" xref="S8.p1.4.m4.1.1.2">𝑠</ci><ci id="S8.p1.4.m4.1.1.3.cmml" xref="S8.p1.4.m4.1.1.3">𝑡</ci><apply id="S8.p1.4.m4.1.1.4.cmml" xref="S8.p1.4.m4.1.1.4"><csymbol cd="ambiguous" id="S8.p1.4.m4.1.1.4.1.cmml" xref="S8.p1.4.m4.1.1.4">subscript</csymbol><ci id="S8.p1.4.m4.1.1.4.2.cmml" xref="S8.p1.4.m4.1.1.4.2">𝑑</ci><ci id="S8.p1.4.m4.1.1.4.3.cmml" xref="S8.p1.4.m4.1.1.4.3">𝑏</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S8.p1.4.m4.1c">std_{b}</annotation></semantics></math> are the corrected standard deviations.</p>
</div>
<div id="S8.p2" class="ltx_para">
<p id="S8.p2.1" class="ltx_p">Different distance metrics, for instance, Euclidean distance, Minkowski Distance and Manhattan distance, etc are also used to measure fairness between systems by evaluating the similarity/dissimilarity between their performance across different systems and for client contribution evaluation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib167" title="" class="ltx_ref">167</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib112" title="" class="ltx_ref">112</a>]</cite>.</p>
</div>
</section>
<section id="S9" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">9 </span><span id="S9.1.1" class="ltx_text ltx_font_smallcaps">Preserving Model Fairness, Accuracy and Privacy</span>
</h2>

<div id="S9.p1" class="ltx_para">
<p id="S9.p1.1" class="ltx_p">Machine learning applications are expanding exponentially, and with that growth comes a greater requirement to guarantee model fairness and accuracy while safeguarding user data privacy. These applications, however, may display unexpected behaviors, such as unfairness, which cause groups with certain sensitive features (for instance, race), to experience varying patterns of outcomes. It is important for ML systems to strike a reasonable balance between model fairness, privacy, and accuracy. Table 4 states some works that try to achieve both fairness and privacy.</p>
</div>
<div id="S9.p2" class="ltx_para">
<p id="S9.p2.1" class="ltx_p">FGFL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib98" title="" class="ltx_ref">98</a>]</cite> evaluates players based on reputation and contribution factors and produces a blockchain-based incentive governor for Federated Learning. The task publisher equitably pays clients in order to recruit efficient ones, while malicious ones are penalized and discarded. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref">61</a>]</cite> develops the concept of Bounded Group Loss as a theoretically informed approach to group fairness and provides a scalable federated optimization approach that optimizes the empirical risk under a number of group fairness requirements using this configuration. Based on a dynamic real-time worker evaluation process, FIFL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite> equitably compensates workers in order to attract trustworthy and efficient workers while punishing and removing malevolent ones.</p>
</div>
</section>
<section id="S10" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">10 </span><span id="S10.1.1" class="ltx_text ltx_font_smallcaps">Challenges and Future Directions in Fairness and Privacy Preservation in FL</span>
</h2>

<div id="S10.p1" class="ltx_para">
<p id="S10.p1.1" class="ltx_p"><span id="S10.p1.1.1" class="ltx_text ltx_font_bold">Lack of Metric to Measure Effort Costs in Contribution Evaluation.</span> There lies a transient discrepancy between the client contributions and rewards in FL because no notable metric exists to measure the temporal costs such as waiting time, cost of efforts, etc. Most contribution assessment studies in FL systems concentrate on assessing data collecting costs, data quality, model performance, total revenue generated, etc. For absolute fair treatment among clients, the temporal costs such as waiting times for getting the complete payout must be taken into consideration when the incentive for FL participants depends on future revenues generated. 
<br class="ltx_break"><span id="S10.p1.1.2" class="ltx_text ltx_font_bold">Missing or Limited Sensitive Features.</span>
In reality, sensitive qualities may not be disclosed or readily available, despite that most studies currently assume that that information is included in the dataset. Much of the sensitive attributes may be missing or limited due to limitations set by some regulations. In this scenario, it is required to achieve a balance between group fairness, individual fairness, and privacy despite lacking sensitive features explicitly. 
<br class="ltx_break"><span id="S10.p1.1.3" class="ltx_text ltx_font_bold">Issues in Vertical FL.</span>
Even though numerous privacy-preserving procedures, such as DP, secure multiparty computation (SMC), homomorphic encryption (HE), and their hybrid variations, have been widely employed in HFL, very few of these techniques have been investigated in VFL. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib189" title="" class="ltx_ref">189</a>]</cite> stated that the difficulty for VFL is the possession of secret properties or outputs by specific models caused by the splitting techniques. These properties tend to have an impact on the level of security and privacy of a model in FL.
The splitting design is easy for basic ML models like Logistic Regression (LR) and kernel models, but privacy-preserving techniques are quite difficult since the input is processed in an insecure linear way. Less private information will be exposed in the intermediate outputs if complicated neural networks, such as the Convolutional Neural Network, are used as the bottom model. This is due to the possibility of improving dispersed data privacy using a complicated nonlinear function. An important difficulty in privacy-preserving VFL systems is comprehending and causing adjustments between privacy, operational efficiency, and performance. 
<br class="ltx_break"><span id="S10.p1.1.4" class="ltx_text ltx_font_bold">Privacy Heterogeneity Among Devices.</span> Most current privacy-preserving FL systems take into account that all devices have the same privacy restrictions and employ the same techniques to protect model weights or gradients. Few works consider the notion of privacy heterogeneity in FL systems, which revolves around the idea that each party’s data cannot be used to its fullest potential provided that each party has different privacy restrictions. Systems that handle devices differently based on privacy needs should be established, and alternative measures should be taken to secure model parameters accordingly, to boost the learning capabilities of a model. 
<br class="ltx_break"><span id="S10.p1.1.5" class="ltx_text ltx_font_bold">Limitations of Non-Monopolistic FL settings.</span> Most existing works in Federated learning are based on a single server-multiple client scheme, resembling a monopolistic market. The server motivates the clients to take part in the federated model training and distributes incentives. Under this premise, only one server assigns tasks and this system does not promote parallel task execution from a server’s point of view. All the clients in these types of monopolistic systems are maintained by a single server and the clients have no choice to choose servers. They only have the option to choose whether or not to participate. Such a system hinders the advancement of fairness-conscious FL systems. A non-monopolistic system consisting of multiple servers involves parallel task assignment, global model updation, and execution. They can compete with one another to acquire more customers and more clients can gain the willingness to participate provided that they can choose their desired server. This also causes increased pressure to allocate more fair incentives, causing clients to gain motivation to join the scheme.
<br class="ltx_break"><span id="S10.p1.1.6" class="ltx_text ltx_font_bold">Computational Challenges in Privacy-Preserving Fairness-Aware FL.</span> Privacy-preserving fairness-aware FL systems are increasingly becoming computationally expensive and large models are particularly vulnerable to privacy assaults and fairness issues because they have high-dimensional parameter vectors and numerous sensitive attributes. This problem should be solved by facilitating local updating, curse of dimensionality reduction, and model compression. Training Federated networks on limited resources and low-power devices present unique obstacles such as massive computation, storage inadequacy, and battery limitations. Trusted execution environments(TEE) setups and maintenance are extremely costly and difficult. Other hardware-based encryption solutions should also be considered to protect data security and boost encryption efficiency, such as combining FL with new protection technologies such as blockchain to assure FL cross-domain learning security. A limited number of works have used such a method. It is crucial to do a thorough analysis of the trade-offs between accuracy, privacy, and communication for each strategy and facilitate inexpensive and easy parallel processing and TEE setup.
<br class="ltx_break"><span id="S10.p1.1.7" class="ltx_text ltx_font_bold">Need for Continual Learning Methods.</span> Training a machine learning model is a costly and time-consuming job, which can be exacerbated in a federated learning environment. A trained model’s performance degrades when data distributions change over time and when the available data per client is negligible or absent. To improve federated model learning capabilities, methods such as One-Shot Knowledge Distillation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib223" title="" class="ltx_ref">223</a>]</cite>, Data-Free knowledge Distillation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib241" title="" class="ltx_ref">241</a>]</cite> or a combination <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib222" title="" class="ltx_ref">222</a>]</cite> exist insufficiently, but should be made more common. To reduce the high cost of federated training, it is compulsory to investigate ways for improving federated model learning capacity over time. In that case, a limited amount of work exists concerning Meta-learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib75" title="" class="ltx_ref">75</a>]</cite>, online learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref">51</a>]</cite>, and continual learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib175" title="" class="ltx_ref">175</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> which will not impede a model’s performance and learning over time.
<br class="ltx_break"><span id="S10.p1.1.8" class="ltx_text ltx_font_bold">Tradeoff Between Privacy, Accuracy, and Fairness in FL.</span> At present, it has become increasingly difficult to strike a perfect balance between privacy, fairness, and accuracy in federated learning systems. 
<br class="ltx_break"><span id="S10.p1.1.9" class="ltx_text ltx_font_bold">Appropriate Privacy Preserving and Fairness Evaluation Metric.</span> Different systems require different privacy-preserving and fairness evaluation metrics and it is imperative to find the correct one that suits a particular situation since each metric might yield a different outcome.
<br class="ltx_break"><span id="S10.p1.1.10" class="ltx_text ltx_font_bold">Choosing the Right Privacy-Preserving Method.</span> Since each privacy-preserving technique possesses its own kind of advantage and disadvantage as discussed in Table 1, it is required to consider an aggregation of multiple techniques that benefits a particular scenario and yields the best results.</p>
</div>
</section>
<section id="S11" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">11 </span><span id="S11.1.1" class="ltx_text ltx_font_smallcaps">Conclusion</span>
</h2>

<div id="S11.p1" class="ltx_para">
<p id="S11.p1.1" class="ltx_p">This paper provides a summary of recent research on fairness and privacy concerns in FL, in addition to insights from earlier studies. We have also made an effort to provide some insights on challenges and issues related to the implementation of fairness-aware and privacy-preserving FL systems. Our work is intended to assist researchers in the field of FL in evaluating the current state of research on growing privacy and fairness-related concerns. We believe that AI practitioners and system designers will also benefit from this survey, as it provides a concise and understandable introduction to the topic. It is expected that significant efforts will be invested in FL research in the future for its potential as an alternative to centralized ML approaches in a variety of privacy and resource-critical scenarios. Privacy threats and fairness-related issues will continue to grow as the field of FL grows. We hope that significant efforts will be made in the future to overcome these obstacles, and we believe that our survey, the first of its kind to combine privacy and fairness concerns related to FL, will make a significant contribution in this regard.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_font_smallcaps ltx_title_section">Acknowledgments</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">This work was partly supported by (1) Institute of Information &amp; communications Technology Planning &amp; Evaluation (IITP) grant funded by the Korea government (MSIT) (No.2020-0-01373, Artificial Intelligence Graduate School Program (Hanyang University)) and (2) the Bio &amp; Medical Technology Development Program of the National Research Foundation (NRF) funded by the Korean government (MSIT) (No. NRF-2021M3E5D2A01021156).</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock"><span id="bib.bib1.1.1" class="ltx_text" style="font-size:90%;">
Annie Abay, Yi Zhou, Nathalie Baracaldo, Shashank Rajamoni, Ebube Chuba, and
Heiko Ludwig.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.2.1" class="ltx_text" style="font-size:90%;">Mitigating bias in federated learning, 2020.
</span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text" style="font-size:90%;">
Sawsan AbdulRahman, Hanine Tout, Hakima Ould-Slimane, Azzam Mourad, Chamseddine
Talhi, and Mohsen Guizani.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.2.1" class="ltx_text" style="font-size:90%;">A survey on federated learning: The journey from centralized to
distributed on-site learning and beyond.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Internet of Things Journal</span><span id="bib.bib2.4.2" class="ltx_text" style="font-size:90%;">, 8(7):5476–5497, 2020.
</span>
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text" style="font-size:90%;">
Mohammed Adnan, Shivam Kalra, Jesse C Cresswell, Graham W Taylor, and Hamid R
Tizhoosh.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.2.1" class="ltx_text" style="font-size:90%;">Federated learning and differential privacy for medical image
analysis.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Scientific reports</span><span id="bib.bib3.4.2" class="ltx_text" style="font-size:90%;">, 12(1):1953, 2022.
</span>
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock"><span id="bib.bib4.1.1" class="ltx_text" style="font-size:90%;">
Waqar Ali, Rajesh Kumar, Zhiyi Deng, Yansong Wang, and Jie Shao.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.2.1" class="ltx_text" style="font-size:90%;">A Federated Learning Approach for Privacy Protection in
Context-Aware Recommender Systems.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">The Computer Journal</span><span id="bib.bib4.4.2" class="ltx_text" style="font-size:90%;">, 64(7):1016–1027, 04 2021.
</span>
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text" style="font-size:90%;">
Saba Amiri, Adam Belloum, Eric Nalisnick, Sander Klous, and Leon Gommans.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.2.1" class="ltx_text" style="font-size:90%;">On the impact of non-iid data on the performance and fairness of
differentially private federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib5.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2022 52nd Annual IEEE/IFIP International Conference on
Dependable Systems and Networks Workshops (DSN-W)</span><span id="bib.bib5.5.3" class="ltx_text" style="font-size:90%;">, pages 52–58, 2022.
</span>
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text" style="font-size:90%;">
Cecilio Angulo and Cristóbal Raya.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.2.1" class="ltx_text" style="font-size:90%;">Synthetic data for anonymization in secure data spaces for federated
learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib6.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Artificial Intelligence Research and Development</span><span id="bib.bib6.5.3" class="ltx_text" style="font-size:90%;">, pages
91–94. IOS Press, 2022.
</span>
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text" style="font-size:90%;">
Pranjal Awasthi, Matthäus Kleindessner, and Jamie Morgenstern.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.2.1" class="ltx_text" style="font-size:90%;">Equalized odds postprocessing under imperfect group information,
2020.
</span>
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text" style="font-size:90%;">
Peter L Bartlett and Marten H Wegkamp.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.2.1" class="ltx_text" style="font-size:90%;">Classification with a reject option using a hinge loss.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Journal of Machine Learning Research</span><span id="bib.bib8.4.2" class="ltx_text" style="font-size:90%;">, 9(8), 2008.
</span>
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text" style="font-size:90%;">
Priyam Basu, Tiasa Singha Roy, Rakshit Naidu, Zumrut Muftuoglu, Sahib Singh,
and Fatemehsadat Mireshghallah.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.2.1" class="ltx_text" style="font-size:90%;">Benchmarking differential privacy and federated learning for bert
models.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2106.13973</span><span id="bib.bib9.4.2" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text" style="font-size:90%;">
Fattaneh Bayatbabolghani and Marina Blanton.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.2.1" class="ltx_text" style="font-size:90%;">Secure multi-party computation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib10.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the 2018 ACM SIGSAC conference on computer and
communications security</span><span id="bib.bib10.5.3" class="ltx_text" style="font-size:90%;">, pages 2157–2159, 2018.
</span>
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text" style="font-size:90%;">
Amos Beimel.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.2.1" class="ltx_text" style="font-size:90%;">Secret-sharing schemes: A survey.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib11.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Coding and Cryptology: Third International Workshop, IWCC
2011, Qingdao, China, May 30-June 3, 2011. Proceedings 3</span><span id="bib.bib11.5.3" class="ltx_text" style="font-size:90%;">, pages 11–46.
Springer, 2011.
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock"><span id="bib.bib12.1.1" class="ltx_text" style="font-size:90%;">
Claudio Bettini, X. Sean Wang, and Sushil Jajodia.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.2.1" class="ltx_text" style="font-size:90%;">The role of quasi-identifiers in k-anonymity revisited, 2006.
</span>
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text" style="font-size:90%;">
Abhishek Bhowmick, John Duchi, Julien Freudiger, Gaurav Kapoor, and Ryan
Rogers.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.2.1" class="ltx_text" style="font-size:90%;">Protection against reconstruction and its applications in private
federated learning, 2019.
</span>
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock"><span id="bib.bib14.1.1" class="ltx_text" style="font-size:90%;">
Vincent Bindschaedler, Shantanu Rane, Alejandro E. Brito, Vanishree Rao, and
Ersin Uzun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.2.1" class="ltx_text" style="font-size:90%;">Achieving differential privacy in secure multiparty data aggregation
protocols on star networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib14.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the Seventh ACM on Conference on Data and
Application Security and Privacy</span><span id="bib.bib14.5.3" class="ltx_text" style="font-size:90%;">, CODASPY ’17, page 115–125, New York, NY,
USA, 2017. Association for Computing Machinery.
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock"><span id="bib.bib15.1.1" class="ltx_text" style="font-size:90%;">
Sumon Biswas and Hridesh Rajan.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.2.1" class="ltx_text" style="font-size:90%;">Fair preprocessing: towards understanding compositional fairness of
data transformers in machine learning pipeline.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib15.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the 29th ACM Joint Meeting on European
Software Engineering Conference and Symposium on the Foundations of Software
Engineering</span><span id="bib.bib15.5.3" class="ltx_text" style="font-size:90%;">, pages 981–993, 2021.
</span>
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text" style="font-size:90%;">
Keith Bonawitz, Vladimir Ivanov, Ben Kreuter, Antonio Marcedone, H. Brendan
McMahan, Sarvar Patel, Daniel Ramage, Aaron Segal, and Karn Seth.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.2.1" class="ltx_text" style="font-size:90%;">Practical secure aggregation for federated learning on user-held
data, 2016.
</span>
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock"><span id="bib.bib17.1.1" class="ltx_text" style="font-size:90%;">
Flavio P. Calmon, Dennis Wei, Karthikeyan Natesan Ramamurthy, and Kush R.
Varshney.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.2.1" class="ltx_text" style="font-size:90%;">Optimized data pre-processing for discrimination prevention, 2017.
</span>
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock"><span id="bib.bib18.1.1" class="ltx_text" style="font-size:90%;">
Di Cao, Shan Chang, Zhijian Lin, Guohua Liu, and Donghong Sun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.2.1" class="ltx_text" style="font-size:90%;">Understanding distributed poisoning attack in federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib18.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2019 IEEE 25th International Conference on Parallel and
Distributed Systems (ICPADS)</span><span id="bib.bib18.5.3" class="ltx_text" style="font-size:90%;">, pages 233–239, 2019.
</span>
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock"><span id="bib.bib19.1.1" class="ltx_text" style="font-size:90%;">
Hui Cao, Shubo Liu, Renfang Zhao, and Xingxing Xiong.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.2.1" class="ltx_text" style="font-size:90%;">Ifed: A novel federated learning framework for local differential
privacy in power internet of things.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">International Journal of Distributed Sensor Networks</span><span id="bib.bib19.4.2" class="ltx_text" style="font-size:90%;">,
16(5):1550147720919698, 2020.
</span>
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock"><span id="bib.bib20.1.1" class="ltx_text" style="font-size:90%;">
Alycia N. Carey, Wei Du, and Xintao Wu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.2.1" class="ltx_text" style="font-size:90%;">Robust personalized federated learning under demographic fairness
heterogeneity.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib20.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2022 IEEE International Conference on Big Data (Big Data)</span><span id="bib.bib20.5.3" class="ltx_text" style="font-size:90%;">,
pages 1425–1434, 2022.
</span>
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock"><span id="bib.bib21.1.1" class="ltx_text" style="font-size:90%;">
Joymallya Chakraborty, Kewen Peng, and Tim Menzies.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.2.1" class="ltx_text" style="font-size:90%;">Making fair ML software using trustworthy explanation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib21.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the 35th IEEE/ACM International Conference
on Automated Software Engineering</span><span id="bib.bib21.5.3" class="ltx_text" style="font-size:90%;">. ACM, dec 2020.
</span>
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock"><span id="bib.bib22.1.1" class="ltx_text" style="font-size:90%;">
Javad Ghareh Chamani and Dimitrios Papadopoulos.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.2.1" class="ltx_text" style="font-size:90%;">Mitigating leakage in federated learning with trusted hardware, 2020.
</span>
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock"><span id="bib.bib23.1.1" class="ltx_text" style="font-size:90%;">
M.A.P. Chamikara, P. Bertok, I. Khalil, D. Liu, and S. Camtepe.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.2.1" class="ltx_text" style="font-size:90%;">Privacy preserving distributed machine learning with federated
learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Computer Communications</span><span id="bib.bib23.4.2" class="ltx_text" style="font-size:90%;">, 171:112–125, apr 2021.
</span>
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock"><span id="bib.bib24.1.1" class="ltx_text" style="font-size:90%;">
Hongyan Chang, Virat Shejwalkar, Reza Shokri, and Amir Houmansadr.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.2.1" class="ltx_text" style="font-size:90%;">Cronus: Robust and heterogeneous collaborative learning with
black-box knowledge transfer, 2019.
</span>
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock"><span id="bib.bib25.1.1" class="ltx_text" style="font-size:90%;">
Keke Chen and Ling Liu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.2.1" class="ltx_text" style="font-size:90%;">A survey of multiplicative perturbation for privacy-preserving data
mining.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Privacy-preserving data mining: models and algorithms</span><span id="bib.bib25.4.2" class="ltx_text" style="font-size:90%;">, pages
157–181, 2008.
</span>
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock"><span id="bib.bib26.1.1" class="ltx_text" style="font-size:90%;">
Shuzhen Chen, Dongxiao Yu, Yifei Zou, Jiguo Yu, and Xiuzhen Cheng.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.2.1" class="ltx_text" style="font-size:90%;">Decentralized wireless federated learning with differential privacy.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Industrial Informatics</span><span id="bib.bib26.4.2" class="ltx_text" style="font-size:90%;">, 18(9):6273–6282,
2022.
</span>
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock"><span id="bib.bib27.1.1" class="ltx_text" style="font-size:90%;">
Yao Chen, Yijie Gui, Hong Lin, Wensheng Gan, and Yongdong Wu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.2.1" class="ltx_text" style="font-size:90%;">Federated learning attacks and defenses: A survey, 2022.
</span>
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock"><span id="bib.bib28.1.1" class="ltx_text" style="font-size:90%;">
Yu Chen, Fang Luo, Tong Li, Tao Xiang, Zheli Liu, and Jin Li.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.2.1" class="ltx_text" style="font-size:90%;">A training-integrity privacy-preserving federated learning scheme
with trusted execution environment.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Information Sciences</span><span id="bib.bib28.4.2" class="ltx_text" style="font-size:90%;">, 522:69–79, 2020.
</span>
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock"><span id="bib.bib29.1.1" class="ltx_text" style="font-size:90%;">
Kewei Cheng, Tao Fan, Yilun Jin, Yang Liu, Tianjian Chen, Dimitrios
Papadopoulos, and Qiang Yang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.2.1" class="ltx_text" style="font-size:90%;">Secureboost: A lossless federated learning framework, 2021.
</span>
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock"><span id="bib.bib30.1.1" class="ltx_text" style="font-size:90%;">
Yae Jee Cho, Jianyu Wang, and Gauri Joshi.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.2.1" class="ltx_text" style="font-size:90%;">Client selection in federated learning: Convergence analysis and
power-of-choice selection strategies, 2020.
</span>
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock"><span id="bib.bib31.1.1" class="ltx_text" style="font-size:90%;">
Christopher A. Choquette-Choo, Natalie Dullerud, Adam Dziedzic, Yunxiang Zhang,
Somesh Jha, Nicolas Papernot, and Xiao Wang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.2.1" class="ltx_text" style="font-size:90%;">Capc learning: Confidential and private collaborative learning, 2021.
</span>
</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock"><span id="bib.bib32.1.1" class="ltx_text" style="font-size:90%;">
Olivia Choudhury, Aris Gkoulalas-Divanis, Theodoros Salonidis, Issa Sylla,
Yoonyoung Park, Grace Hsu, and Amar Das.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.2.1" class="ltx_text" style="font-size:90%;">Differential privacy-enabled federated learning for sensitive health
data.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1910.02578</span><span id="bib.bib32.4.2" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock"><span id="bib.bib33.1.1" class="ltx_text" style="font-size:90%;">
Olivia Choudhury, Aris Gkoulalas-Divanis, Theodoros Salonidis, Issa Sylla,
Yoonyoung Park, Grace Hsu, and Amar Das.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.2.1" class="ltx_text" style="font-size:90%;">Anonymizing data for privacy-preserving federated learning, 2020.
</span>
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock"><span id="bib.bib34.1.1" class="ltx_text" style="font-size:90%;">
Olivia Choudhury, Aris Gkoulalas-Divanis, Theodoros Salonidis, Issa Sylla,
Yoonyoung Park, Grace Hsu, and Amar Das.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.2.1" class="ltx_text" style="font-size:90%;">A syntactic approach for privacy-preserving federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib34.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ECAI 2020</span><span id="bib.bib34.5.3" class="ltx_text" style="font-size:90%;">, pages 1762–1769. IOS Press, 2020.
</span>
</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock"><span id="bib.bib35.1.1" class="ltx_text" style="font-size:90%;">
Marcos F Criado, Fernando E Casado, Roberto Iglesias, Carlos V Regueiro, and
Senén Barro.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.2.1" class="ltx_text" style="font-size:90%;">Non-iid data and continual learning processes in federated learning:
A long road ahead.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Information Fusion</span><span id="bib.bib35.4.2" class="ltx_text" style="font-size:90%;">, 88:263–280, 2022.
</span>
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock"><span id="bib.bib36.1.1" class="ltx_text" style="font-size:90%;">
Luke Darlow, Stanislaw Jastrzebski, and Amos Storkey.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.2.1" class="ltx_text" style="font-size:90%;">Latent adversarial debiasing: Mitigating collider bias in deep neural
networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2011.11486</span><span id="bib.bib36.4.2" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock"><span id="bib.bib37.1.1" class="ltx_text" style="font-size:90%;">
Cynthia Dwork, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Richard Zemel.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.2.1" class="ltx_text" style="font-size:90%;">Fairness through awareness.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib37.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the 3rd innovations in theoretical computer
science conference</span><span id="bib.bib37.5.3" class="ltx_text" style="font-size:90%;">, pages 214–226, 2012.
</span>
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock"><span id="bib.bib38.1.1" class="ltx_text" style="font-size:90%;">
Yahya H. Ezzeldin, Shen Yan, Chaoyang He, Emilio Ferrara, and Salman
Avestimehr.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.2.1" class="ltx_text" style="font-size:90%;">Fairfed: Enabling group fairness in federated learning, 2022.
</span>
</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock"><span id="bib.bib39.1.1" class="ltx_text" style="font-size:90%;">
Alireza Fallah, Aryan Mokhtari, and Asuman Ozdaglar.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.2.1" class="ltx_text" style="font-size:90%;">Personalized federated learning with theoretical guarantees: A
model-agnostic meta-learning approach.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Advances in Neural Information Processing Systems</span><span id="bib.bib39.4.2" class="ltx_text" style="font-size:90%;">,
33:3557–3568, 2020.
</span>
</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock"><span id="bib.bib40.1.1" class="ltx_text" style="font-size:90%;">
Junfeng Fan and Frederik Vercauteren.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.2.1" class="ltx_text" style="font-size:90%;">Somewhat practical fully homomorphic encryption.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Cryptology ePrint Archive</span><span id="bib.bib40.4.2" class="ltx_text" style="font-size:90%;">, 2012.
</span>
</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock"><span id="bib.bib41.1.1" class="ltx_text" style="font-size:90%;">
Zhenan Fan, Huang Fang, Zirui Zhou, Jian Pei, Michael P Friedlander, and Yong
Zhang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.2.1" class="ltx_text" style="font-size:90%;">Fair and efficient contribution valuation for vertical federated
learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2201.02658</span><span id="bib.bib41.4.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock"><span id="bib.bib42.1.1" class="ltx_text" style="font-size:90%;">
Sorelle A Friedler, Carlos Scheidegger, Suresh Venkatasubramanian, Sonam
Choudhary, Evan P Hamilton, and Derek Roth.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.2.1" class="ltx_text" style="font-size:90%;">A comparative study of fairness-enhancing interventions in machine
learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib42.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the conference on fairness, accountability,
and transparency</span><span id="bib.bib42.5.3" class="ltx_text" style="font-size:90%;">, pages 329–338, 2019.
</span>
</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock"><span id="bib.bib43.1.1" class="ltx_text" style="font-size:90%;">
Clement Fung, Jamie Koerner, Stewart Grant, and Ivan Beschastnikh.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.2.1" class="ltx_text" style="font-size:90%;">Dancing in the dark: Private multi-party machine learning in an
untrusted setting, 2019.
</span>
</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock"><span id="bib.bib44.1.1" class="ltx_text" style="font-size:90%;">
Shripad Gade and Nitin H. Vaidya.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib44.2.1" class="ltx_text" style="font-size:90%;">Privacy-preserving distributed learning via obfuscated stochastic
gradients.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib44.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib44.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2018 IEEE Conference on Decision and Control (CDC)</span><span id="bib.bib44.5.3" class="ltx_text" style="font-size:90%;">, pages
184–191, 2018.
</span>
</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock"><span id="bib.bib45.1.1" class="ltx_text" style="font-size:90%;">
Filippo Galli, Sayan Biswas, Kangsoo Jung, Tommaso Cucinotta, and Catuscia
Palamidessi.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib45.2.1" class="ltx_text" style="font-size:90%;">Group privacy for personalized federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib45.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib45.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the 9th International Conference on
Information Systems Security and Privacy</span><span id="bib.bib45.5.3" class="ltx_text" style="font-size:90%;">. SCITEPRESS - Science and
Technology Publications, 2023.
</span>
</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock"><span id="bib.bib46.1.1" class="ltx_text" style="font-size:90%;">
Dashan Gao, Yang Liu, Anbu Huang, Ce Ju, Han Yu, and Qiang Yang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib46.2.1" class="ltx_text" style="font-size:90%;">Privacy-preserving heterogeneous federated transfer learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib46.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib46.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2019 IEEE International Conference on Big Data (Big Data)</span><span id="bib.bib46.5.3" class="ltx_text" style="font-size:90%;">,
pages 2552–2559, 2019.
</span>
</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock"><span id="bib.bib47.1.1" class="ltx_text" style="font-size:90%;">
Liang Gao, Li Li, Yingwen Chen, Wenli Zheng, ChengZhong Xu, and Ming Xu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib47.2.1" class="ltx_text" style="font-size:90%;">Fifl: A fair incentive mechanism for federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib47.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib47.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the 50th International Conference on Parallel
Processing</span><span id="bib.bib47.5.3" class="ltx_text" style="font-size:90%;">, ICPP ’21, New York, NY, USA, 2021. Association for Computing
Machinery.
</span>
</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock"><span id="bib.bib48.1.1" class="ltx_text" style="font-size:90%;">
Robin C. Geyer, Tassilo Klein, and Moin Nabi.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib48.2.1" class="ltx_text" style="font-size:90%;">Differentially private federated learning: A client level
perspective, 2018.
</span>
</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock"><span id="bib.bib49.1.1" class="ltx_text" style="font-size:90%;">
Amirata Ghorbani and James Zou.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib49.2.1" class="ltx_text" style="font-size:90%;">Data shapley: Equitable valuation of data for machine learning, 2019.
</span>
</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock"><span id="bib.bib50.1.1" class="ltx_text" style="font-size:90%;">
Antonious Girgis, Deepesh Data, Suhas Diggavi, Peter Kairouz, and
Ananda Theertha Suresh.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib50.2.1" class="ltx_text" style="font-size:90%;">Shuffled model of differential privacy in federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib50.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib50.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">International Conference on Artificial Intelligence and
Statistics</span><span id="bib.bib50.5.3" class="ltx_text" style="font-size:90%;">, pages 2521–2529. PMLR, 2021.
</span>
</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock"><span id="bib.bib51.1.1" class="ltx_text" style="font-size:90%;">
Pengchao Han, Shiqiang Wang, and Kin K Leung.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib51.2.1" class="ltx_text" style="font-size:90%;">Adaptive gradient sparsification for efficient federated learning: An
online learning approach.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib51.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib51.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2020 IEEE 40th international conference on distributed
computing systems (ICDCS)</span><span id="bib.bib51.5.3" class="ltx_text" style="font-size:90%;">, pages 300–310. IEEE, 2020.
</span>
</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock"><span id="bib.bib52.1.1" class="ltx_text" style="font-size:90%;">
Weituo Hao, Nikhil Mehta, Kevin J. Liang, Pengyu Cheng, Mostafa El-Khamy, and
Lawrence Carin.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib52.2.1" class="ltx_text" style="font-size:90%;">Waffle: Weight anonymized factorization for federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib52.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Access</span><span id="bib.bib52.4.2" class="ltx_text" style="font-size:90%;">, 10:49207–49218, 2022.
</span>
</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock"><span id="bib.bib53.1.1" class="ltx_text" style="font-size:90%;">
Moritz Hardt, Eric Price, and Nathan Srebro.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib53.2.1" class="ltx_text" style="font-size:90%;">Equality of opportunity in supervised learning, 2016.
</span>
</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock"><span id="bib.bib54.1.1" class="ltx_text" style="font-size:90%;">
Radu Herbei and Marten H Wegkamp.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib54.2.1" class="ltx_text" style="font-size:90%;">Classification with reject option.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib54.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">The Canadian Journal of Statistics/La Revue Canadienne de
Statistique</span><span id="bib.bib54.4.2" class="ltx_text" style="font-size:90%;">, pages 709–721, 2006.
</span>
</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock"><span id="bib.bib55.1.1" class="ltx_text" style="font-size:90%;">
Briland Hitaj, Giuseppe Ateniese, and Fernando Perez-Cruz.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib55.2.1" class="ltx_text" style="font-size:90%;">Deep models under the gan: Information leakage from collaborative
deep learning, 2017.
</span>
</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock"><span id="bib.bib56.1.1" class="ltx_text" style="font-size:90%;">
Junyuan Hong, Zhuangdi Zhu, Shuyang Yu, Zhangyang Wang, Hiroko H Dodge, and
Jiayu Zhou.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib56.2.1" class="ltx_text" style="font-size:90%;">Federated adversarial debiasing for fair and transferable
representations.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib56.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib56.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the 27th ACM SIGKDD Conference on Knowledge
Discovery &amp; Data Mining</span><span id="bib.bib56.5.3" class="ltx_text" style="font-size:90%;">, pages 617–627, 2021.
</span>
</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock"><span id="bib.bib57.1.1" class="ltx_text" style="font-size:90%;">
Samuel Horvath, Stefanos Laskaridis, Mario Almeida, Ilias Leontiadis,
Stylianos I. Venieris, and Nicholas D. Lane.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib57.2.1" class="ltx_text" style="font-size:90%;">Fjord: Fair and accurate federated learning under heterogeneous
targets with ordered dropout, 2022.
</span>
</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock"><span id="bib.bib58.1.1" class="ltx_text" style="font-size:90%;">
Hongsheng Hu, Zoran Salcic, Lichao Sun, Gillian Dobbie, and Xuyun Zhang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib58.2.1" class="ltx_text" style="font-size:90%;">Source inference attacks in federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib58.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib58.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2021 IEEE International Conference on Data Mining (ICDM)</span><span id="bib.bib58.5.3" class="ltx_text" style="font-size:90%;">,
pages 1102–1107, 2021.
</span>
</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock"><span id="bib.bib59.1.1" class="ltx_text" style="font-size:90%;">
Rui Hu, Yuanxiong Guo, Hongning Li, Qingqi Pei, and Yanmin Gong.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib59.2.1" class="ltx_text" style="font-size:90%;">Personalized federated learning with differential privacy.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib59.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Internet of Things Journal</span><span id="bib.bib59.4.2" class="ltx_text" style="font-size:90%;">, 7(10):9530–9539, 2020.
</span>
</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock"><span id="bib.bib60.1.1" class="ltx_text" style="font-size:90%;">
Sixu Hu, Yuan Li, Xu Liu, Qinbin Li, Zhaomin Wu, and Bingsheng He.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib60.2.1" class="ltx_text" style="font-size:90%;">The OARF benchmark suite: Characterization and implications for
federated learning systems.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib60.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">ACM Transactions on Intelligent Systems and Technology</span><span id="bib.bib60.4.2" class="ltx_text" style="font-size:90%;">,
13(4):1–32, jun 2022.
</span>
</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock"><span id="bib.bib61.1.1" class="ltx_text" style="font-size:90%;">
Shengyuan Hu, Zhiwei Steven Wu, and Virginia Smith.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib61.2.1" class="ltx_text" style="font-size:90%;">Fair federated learning via bounded group loss, 2022.
</span>
</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[62]</span>
<span class="ltx_bibblock"><span id="bib.bib62.1.1" class="ltx_text" style="font-size:90%;">
Zeou Hu, Kiarash Shaloudegi, Guojun Zhang, and Yaoliang Yu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib62.2.1" class="ltx_text" style="font-size:90%;">Federated learning meets multi-objective optimization, 2023.
</span>
</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[63]</span>
<span class="ltx_bibblock"><span id="bib.bib63.1.1" class="ltx_text" style="font-size:90%;">
Jie Huang, Cheng Xu, Zhaohua Ji, Shan Xiao, Teng Liu, Nan Ma, and Qinghui Zhou.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib63.2.1" class="ltx_text" style="font-size:90%;">Aflpc: an asynchronous federated learning privacy-preserving
computing model applied to 5g-v2x.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib63.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Security and Communication Networks</span><span id="bib.bib63.4.2" class="ltx_text" style="font-size:90%;">, 2022, 2022.
</span>
</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[64]</span>
<span class="ltx_bibblock"><span id="bib.bib64.1.1" class="ltx_text" style="font-size:90%;">
Tiansheng Huang, Weiwei Lin, Li Shen, Keqin Li, and Albert Y. Zomaya.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib64.2.1" class="ltx_text" style="font-size:90%;">Stochastic client selection for federated learning with volatile
clients, 2022.
</span>
</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[65]</span>
<span class="ltx_bibblock"><span id="bib.bib65.1.1" class="ltx_text" style="font-size:90%;">
Tiansheng Huang, Weiwei Lin, Wentai Wu, Ligang He, Keqin Li, and Albert Zomaya.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib65.2.1" class="ltx_text" style="font-size:90%;">An efficiency-boosting client selection scheme for federated learning
with fairness guarantee.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib65.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Parallel and Distributed Systems</span><span id="bib.bib65.4.2" class="ltx_text" style="font-size:90%;">, pages
1–1, 2020.
</span>
</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[66]</span>
<span class="ltx_bibblock"><span id="bib.bib66.1.1" class="ltx_text" style="font-size:90%;">
Tiansheng Huang, Weiwei Lin, Wentai Wu, Ligang He, Keqin Li, and Albert Y.
Zomaya.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib66.2.1" class="ltx_text" style="font-size:90%;">An efficiency-boosting client selection scheme for federated learning
with fairness guarantee.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib66.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Parallel and Distributed Systems</span><span id="bib.bib66.4.2" class="ltx_text" style="font-size:90%;">,
32(7):1552–1564, 2021.
</span>
</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[67]</span>
<span class="ltx_bibblock"><span id="bib.bib67.1.1" class="ltx_text" style="font-size:90%;">
Wei Huang, Tianrui Li, Dexian Wang, Shengdong Du, and Junbo Zhang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib67.2.1" class="ltx_text" style="font-size:90%;">Fairness and accuracy in federated learning, 2020.
</span>
</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[68]</span>
<span class="ltx_bibblock"><span id="bib.bib68.1.1" class="ltx_text" style="font-size:90%;">
Yangsibo Huang, Samyak Gupta, Zhao Song, Kai Li, and Sanjeev Arora.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib68.2.1" class="ltx_text" style="font-size:90%;">Evaluating gradient inversion attacks and defenses in federated
learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib68.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Advances in Neural Information Processing Systems</span><span id="bib.bib68.4.2" class="ltx_text" style="font-size:90%;">,
34:7232–7241, 2021.
</span>
</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[69]</span>
<span class="ltx_bibblock"><span id="bib.bib69.1.1" class="ltx_text" style="font-size:90%;">
Selim Ickin, Konstantinos Vandikas, Farnaz Moradi, Jalil Taghia, and Wenfeng
Hu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib69.2.1" class="ltx_text" style="font-size:90%;">Ensemble-based synthetic data synthesis for federated qoe modeling.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib69.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib69.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2020 6th IEEE Conference on Network Softwarization
(NetSoft)</span><span id="bib.bib69.5.3" class="ltx_text" style="font-size:90%;">, pages 72–76, 2020.
</span>
</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[70]</span>
<span class="ltx_bibblock"><span id="bib.bib70.1.1" class="ltx_text" style="font-size:90%;">
Yae Jee Cho, Samarth Gupta, Gauri Joshi, and Osman Yağan.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib70.2.1" class="ltx_text" style="font-size:90%;">Bandit-based communication-efficient client selection strategies for
federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib70.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib70.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2020 54th Asilomar Conference on Signals, Systems, and
Computers</span><span id="bib.bib70.5.3" class="ltx_text" style="font-size:90%;">, pages 1066–1069, 2020.
</span>
</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[71]</span>
<span class="ltx_bibblock"><span id="bib.bib71.1.1" class="ltx_text" style="font-size:90%;">
Bin Jia, Xiaosong Zhang, Jiewen Liu, Yang Zhang, Ke Huang, and Yongquan Liang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib71.2.1" class="ltx_text" style="font-size:90%;">Blockchain-enabled federated learning data protection aggregation
scheme with differential privacy and homomorphic encryption in iiot.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib71.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Industrial Informatics</span><span id="bib.bib71.4.2" class="ltx_text" style="font-size:90%;">, 18(6):4049–4058,
2021.
</span>
</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[72]</span>
<span class="ltx_bibblock"><span id="bib.bib72.1.1" class="ltx_text" style="font-size:90%;">
Bin Jia, Xiaosong Zhang, Jiewen Liu, Yang Zhang, Ke Huang, and Yongquan Liang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib72.2.1" class="ltx_text" style="font-size:90%;">Blockchain-enabled federated learning data protection aggregation
scheme with differential privacy and homomorphic encryption in iiot.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib72.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Industrial Informatics</span><span id="bib.bib72.4.2" class="ltx_text" style="font-size:90%;">, 18(6):4049–4058,
2022.
</span>
</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[73]</span>
<span class="ltx_bibblock"><span id="bib.bib73.1.1" class="ltx_text" style="font-size:90%;">
Bin Jiang, Jianqiang Li, Huihui Wang, and Houbing Song.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib73.2.1" class="ltx_text" style="font-size:90%;">Privacy-preserving federated learning for industrial edge computing
via hybrid differential privacy and adaptive compression.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib73.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Industrial Informatics</span><span id="bib.bib73.4.2" class="ltx_text" style="font-size:90%;">, 19(2):1136–1144,
2021.
</span>
</span>
</li>
<li id="bib.bib74" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[74]</span>
<span class="ltx_bibblock"><span id="bib.bib74.1.1" class="ltx_text" style="font-size:90%;">
Xue Jiang, Xuebing Zhou, and Jens Grossklags.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib74.2.1" class="ltx_text" style="font-size:90%;">Comprehensive analysis of privacy leakage in vertical federated
learning during prediction.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib74.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Proc. Priv. Enhancing Technol.</span><span id="bib.bib74.4.2" class="ltx_text" style="font-size:90%;">, 2022(2):263–281, 2022.
</span>
</span>
</li>
<li id="bib.bib75" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[75]</span>
<span class="ltx_bibblock"><span id="bib.bib75.1.1" class="ltx_text" style="font-size:90%;">
Yihan Jiang, Jakub Konečnỳ, Keith Rush, and Sreeram Kannan.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib75.2.1" class="ltx_text" style="font-size:90%;">Improving federated learning personalization via model agnostic meta
learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib75.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1909.12488</span><span id="bib.bib75.4.2" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib76" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[76]</span>
<span class="ltx_bibblock"><span id="bib.bib76.1.1" class="ltx_text" style="font-size:90%;">
Zhifeng Jiang, Wei Wang, and Yang Liu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib76.2.1" class="ltx_text" style="font-size:90%;">Flashe: Additively symmetric homomorphic encryption for cross-silo
federated learning, 2021.
</span>
</span>
</li>
<li id="bib.bib77" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[77]</span>
<span class="ltx_bibblock"><span id="bib.bib77.1.1" class="ltx_text" style="font-size:90%;">
Marc Juarez and Aleksandra Korolova.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib77.2.1" class="ltx_text" style="font-size:90%;">”you can’t fix what you can’t measure”: Privately measuring
demographic performance disparities in federated learning, 2023.
</span>
</span>
</li>
<li id="bib.bib78" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[78]</span>
<span class="ltx_bibblock"><span id="bib.bib78.1.1" class="ltx_text" style="font-size:90%;">
Peter Kairouz, H. Brendan McMahan, Brendan Avent, Aurélien Bellet, Mehdi
Bennis, Arjun Nitin Bhagoji, Kallista Bonawitz, Zachary Charles, Graham
Cormode, Rachel Cummings, Rafael G. L. D’Oliveira, Hubert Eichner, Salim
El Rouayheb, David Evans, Josh Gardner, Zachary Garrett, Adrià
Gascón, Badih Ghazi, Phillip B. Gibbons, Marco Gruteser, Zaid Harchaoui,
Chaoyang He, Lie He, Zhouyuan Huo, Ben Hutchinson, Justin Hsu, Martin Jaggi,
Tara Javidi, Gauri Joshi, Mikhail Khodak, Jakub Konecný, Aleksandra
Korolova, Farinaz Koushanfar, Sanmi Koyejo, Tancrède Lepoint, Yang Liu,
Prateek Mittal, Mehryar Mohri, Richard Nock, Ayfer Özgür, Rasmus
Pagh, Hang Qi, Daniel Ramage, Ramesh Raskar, Mariana Raykova, Dawn Song,
Weikang Song, Sebastian U. Stich, Ziteng Sun, Ananda Theertha Suresh, Florian
Tramèr, Praneeth Vepakomma, Jianyu Wang, Li Xiong, Zheng Xu, Qiang Yang,
Felix X. Yu, Han Yu, and Sen Zhao.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib78.2.1" class="ltx_text" style="font-size:90%;">Advances and open problems in federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib78.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Found. Trends Mach. Learn.</span><span id="bib.bib78.4.2" class="ltx_text" style="font-size:90%;">, 14(1–2):1–210, jun 2021.
</span>
</span>
</li>
<li id="bib.bib79" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[79]</span>
<span class="ltx_bibblock"><span id="bib.bib79.1.1" class="ltx_text" style="font-size:90%;">
Toshihiro Kamishima, Shotaro Akaho, Hideki Asoh, and Jun Sakuma.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib79.2.1" class="ltx_text" style="font-size:90%;">Fairness-aware classifier with prejudice remover regularizer.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib79.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib79.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Machine Learning and Knowledge Discovery in Databases:
European Conference, ECML PKDD 2012, Bristol, UK, September 24-28, 2012.
Proceedings, Part II 23</span><span id="bib.bib79.5.3" class="ltx_text" style="font-size:90%;">, pages 35–50. Springer, 2012.
</span>
</span>
</li>
<li id="bib.bib80" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[80]</span>
<span class="ltx_bibblock"><span id="bib.bib80.1.1" class="ltx_text" style="font-size:90%;">
Toshihiro Kamishima, Shotaro Akaho, and Jun Sakuma.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib80.2.1" class="ltx_text" style="font-size:90%;">Fairness-aware learning through regularization approach.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib80.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib80.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2011 IEEE 11th International Conference on Data Mining
Workshops</span><span id="bib.bib80.5.3" class="ltx_text" style="font-size:90%;">, pages 643–650. IEEE, 2011.
</span>
</span>
</li>
<li id="bib.bib81" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[81]</span>
<span class="ltx_bibblock"><span id="bib.bib81.1.1" class="ltx_text" style="font-size:90%;">
Samhita Kanaparthy, Manisha Padala, Sankarshan Damle, Ravi Kiran
Sarvadevabhatla, and Sujit Gujar.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib81.2.1" class="ltx_text" style="font-size:90%;">F3: Fair and federated face attribute classification with
heterogeneous data, 2022.
</span>
</span>
</li>
<li id="bib.bib82" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[82]</span>
<span class="ltx_bibblock"><span id="bib.bib82.1.1" class="ltx_text" style="font-size:90%;">
Jiawen Kang, Zehui Xiong, Dusit Niyato, Han Yu, Ying-Chang Liang, and Dong In
Kim.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib82.2.1" class="ltx_text" style="font-size:90%;">Incentive design for efficient federated learning in mobile networks:
A contract theory approach, 2019.
</span>
</span>
</li>
<li id="bib.bib83" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[83]</span>
<span class="ltx_bibblock"><span id="bib.bib83.1.1" class="ltx_text" style="font-size:90%;">
Sai Praneeth Karimireddy, Satyen Kale, Mehryar Mohri, Sashank J. Reddi,
Sebastian U. Stich, and Ananda Theertha Suresh.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib83.2.1" class="ltx_text" style="font-size:90%;">Scaffold: Stochastic controlled averaging for federated learning,
2021.
</span>
</span>
</li>
<li id="bib.bib84" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[84]</span>
<span class="ltx_bibblock"><span id="bib.bib84.1.1" class="ltx_text" style="font-size:90%;">
Shiva Prasad Kasiviswanathan, Homin K. Lee, Kobbi Nissim, Sofya Raskhodnikova,
and Adam Smith.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib84.2.1" class="ltx_text" style="font-size:90%;">What can we learn privately?
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib84.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib84.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2008 49th Annual IEEE Symposium on Foundations of Computer
Science</span><span id="bib.bib84.5.3" class="ltx_text" style="font-size:90%;">, pages 531–540, 2008.
</span>
</span>
</li>
<li id="bib.bib85" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[85]</span>
<span class="ltx_bibblock"><span id="bib.bib85.1.1" class="ltx_text" style="font-size:90%;">
Latif U. Khan, Shashi Raj Pandey, Nguyen H. Tran, Walid Saad, Zhu Han, Minh
N. H. Nguyen, and Choong Seon Hong.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib85.2.1" class="ltx_text" style="font-size:90%;">Federated learning for edge networks: Resource optimization and
incentive mechanism.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib85.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Communications Magazine</span><span id="bib.bib85.4.2" class="ltx_text" style="font-size:90%;">, 58(10):88–93, 2020.
</span>
</span>
</li>
<li id="bib.bib86" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[86]</span>
<span class="ltx_bibblock"><span id="bib.bib86.1.1" class="ltx_text" style="font-size:90%;">
Latif U Khan, Walid Saad, Zhu Han, Ekram Hossain, and Choong Seon Hong.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib86.2.1" class="ltx_text" style="font-size:90%;">Federated learning for internet of things: Recent advances, taxonomy,
and open challenges.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib86.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Communications Surveys &amp; Tutorials</span><span id="bib.bib86.4.2" class="ltx_text" style="font-size:90%;">, 23(3):1759–1799,
2021.
</span>
</span>
</li>
<li id="bib.bib87" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[87]</span>
<span class="ltx_bibblock"><span id="bib.bib87.1.1" class="ltx_text" style="font-size:90%;">
Adam Kiersztyn, Paweł Karczmarek, Krystyna Kiersztyn, Rafał Łopucki,
Stanisław Grzegórski, and Witold Pedrycz.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib87.2.1" class="ltx_text" style="font-size:90%;">The concept of granular representation of the information potential
of variables.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib87.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib87.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2021 IEEE International Conference on Fuzzy Systems
(FUZZ-IEEE)</span><span id="bib.bib87.5.3" class="ltx_text" style="font-size:90%;">, pages 1–6. IEEE, 2021.
</span>
</span>
</li>
<li id="bib.bib88" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[88]</span>
<span class="ltx_bibblock"><span id="bib.bib88.1.1" class="ltx_text" style="font-size:90%;">
Andrey Kim, Yongsoo Song, Miran Kim, Keewoo Lee, and Jung Hee Cheon.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib88.2.1" class="ltx_text" style="font-size:90%;">Logistic regression model training based on the approximate
homomorphic encryption.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib88.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">BMC medical genomics</span><span id="bib.bib88.4.2" class="ltx_text" style="font-size:90%;">, 11(4):23–31, 2018.
</span>
</span>
</li>
<li id="bib.bib89" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[89]</span>
<span class="ltx_bibblock"><span id="bib.bib89.1.1" class="ltx_text" style="font-size:90%;">
Muah Kim, Onur Günlü, and Rafael F Schaefer.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib89.2.1" class="ltx_text" style="font-size:90%;">Federated learning with local differential privacy: Trade-offs
between privacy, utility, and communication.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib89.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib89.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICASSP 2021-2021 IEEE International Conference on Acoustics,
Speech and Signal Processing (ICASSP)</span><span id="bib.bib89.5.3" class="ltx_text" style="font-size:90%;">, pages 2650–2654. IEEE, 2021.
</span>
</span>
</li>
<li id="bib.bib90" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[90]</span>
<span class="ltx_bibblock"><span id="bib.bib90.1.1" class="ltx_text" style="font-size:90%;">
Michael P Kim, Amirata Ghorbani, and James Zou.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib90.2.1" class="ltx_text" style="font-size:90%;">Multiaccuracy: Black-box post-processing for fairness in
classification.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib90.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib90.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics,
and Society</span><span id="bib.bib90.5.3" class="ltx_text" style="font-size:90%;">, pages 247–254, 2019.
</span>
</span>
</li>
<li id="bib.bib91" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[91]</span>
<span class="ltx_bibblock"><span id="bib.bib91.1.1" class="ltx_text" style="font-size:90%;">
Sungwook Kim.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib91.2.1" class="ltx_text" style="font-size:90%;">Incentive design and differential privacy based federated learning: A
mechanism design perspective.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib91.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Access</span><span id="bib.bib91.4.2" class="ltx_text" style="font-size:90%;">, 8:187317–187325, 2020.
</span>
</span>
</li>
<li id="bib.bib92" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[92]</span>
<span class="ltx_bibblock"><span id="bib.bib92.1.1" class="ltx_text" style="font-size:90%;">
Prabhat Kumar, Govind P. Gupta, and Rakesh Tripathi.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib92.2.1" class="ltx_text" style="font-size:90%;">Pefl: Deep privacy-encoding-based federated learning framework for
smart agriculture.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib92.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Micro</span><span id="bib.bib92.4.2" class="ltx_text" style="font-size:90%;">, 42(1):33–40, 2022.
</span>
</span>
</li>
<li id="bib.bib93" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[93]</span>
<span class="ltx_bibblock"><span id="bib.bib93.1.1" class="ltx_text" style="font-size:90%;">
Fan Lai, Xiangfeng Zhu, Harsha V. Madhyastha, and Mosharaf Chowdhury.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib93.2.1" class="ltx_text" style="font-size:90%;">Oort: Efficient federated learning via guided participant selection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib93.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib93.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">15th USENIX Symposium on Operating Systems Design and
Implementation (OSDI 21)</span><span id="bib.bib93.5.3" class="ltx_text" style="font-size:90%;">, pages 19–35. USENIX Association, July 2021.
</span>
</span>
</li>
<li id="bib.bib94" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[94]</span>
<span class="ltx_bibblock"><span id="bib.bib94.1.1" class="ltx_text" style="font-size:90%;">
Ninghui Li, Tiancheng Li, and Suresh Venkatasubramanian.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib94.2.1" class="ltx_text" style="font-size:90%;">t-closeness: Privacy beyond k-anonymity and l-diversity.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib94.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib94.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2007 IEEE 23rd International Conference on Data Engineering</span><span id="bib.bib94.5.3" class="ltx_text" style="font-size:90%;">,
pages 106–115, 2007.
</span>
</span>
</li>
<li id="bib.bib95" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[95]</span>
<span class="ltx_bibblock"><span id="bib.bib95.1.1" class="ltx_text" style="font-size:90%;">
Tian Li, Ahmad Beirami, Maziar Sanjabi, and Virginia Smith.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib95.2.1" class="ltx_text" style="font-size:90%;">Tilted empirical risk minimization, 2021.
</span>
</span>
</li>
<li id="bib.bib96" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[96]</span>
<span class="ltx_bibblock"><span id="bib.bib96.1.1" class="ltx_text" style="font-size:90%;">
Tian Li, Shengyuan Hu, Ahmad Beirami, and Virginia Smith.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib96.2.1" class="ltx_text" style="font-size:90%;">Ditto: Fair and robust federated learning through personalization,
2021.
</span>
</span>
</li>
<li id="bib.bib97" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[97]</span>
<span class="ltx_bibblock"><span id="bib.bib97.1.1" class="ltx_text" style="font-size:90%;">
Tian Li, Maziar Sanjabi, Ahmad Beirami, and Virginia Smith.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib97.2.1" class="ltx_text" style="font-size:90%;">Fair resource allocation in federated learning, 2020.
</span>
</span>
</li>
<li id="bib.bib98" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[98]</span>
<span class="ltx_bibblock"><span id="bib.bib98.1.1" class="ltx_text" style="font-size:90%;">
Xiaoli Li, Siran Zhao, Chuan Chen, and Zibin Zheng.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib98.2.1" class="ltx_text" style="font-size:90%;">Heterogeneity-aware fair federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib98.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Information Sciences</span><span id="bib.bib98.4.2" class="ltx_text" style="font-size:90%;">, 619:968–986, 2023.
</span>
</span>
</li>
<li id="bib.bib99" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[99]</span>
<span class="ltx_bibblock"><span id="bib.bib99.1.1" class="ltx_text" style="font-size:90%;">
Yanan Li, Shusen Yang, Xuebin Ren, and Cong Zhao.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib99.2.1" class="ltx_text" style="font-size:90%;">Asynchronous federated learning with differential privacy for edge
intelligence.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib99.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1912.07902</span><span id="bib.bib99.4.2" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib100" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[100]</span>
<span class="ltx_bibblock"><span id="bib.bib100.1.1" class="ltx_text" style="font-size:90%;">
Yong Li, Yipeng Zhou, Alireza Jolfaei, Dongjin Yu, Gaochao Xu, and Xi Zheng.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib100.2.1" class="ltx_text" style="font-size:90%;">Privacy-preserving federated learning framework based on chained
secure multiparty computing.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib100.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Internet of Things Journal</span><span id="bib.bib100.4.2" class="ltx_text" style="font-size:90%;">, 8(8):6178–6186, 2020.
</span>
</span>
</li>
<li id="bib.bib101" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[101]</span>
<span class="ltx_bibblock"><span id="bib.bib101.1.1" class="ltx_text" style="font-size:90%;">
Zhuotao Lian, Weizheng Wang, and Chunhua Su.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib101.2.1" class="ltx_text" style="font-size:90%;">Cofel: Communication-efficient and optimized federated learning with
local differential privacy.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib101.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib101.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICC 2021-IEEE International Conference on Communications</span><span id="bib.bib101.5.3" class="ltx_text" style="font-size:90%;">,
pages 1–6. IEEE, 2021.
</span>
</span>
</li>
<li id="bib.bib102" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[102]</span>
<span class="ltx_bibblock"><span id="bib.bib102.1.1" class="ltx_text" style="font-size:90%;">
Jialing Liao, Zheng Chen, and Erik G. Larsson.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib102.2.1" class="ltx_text" style="font-size:90%;">Over-the-air federated learning with privacy protection via
correlated additive perturbations.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib102.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib102.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2022 58th Annual Allerton Conference on Communication,
Control, and Computing (Allerton)</span><span id="bib.bib102.5.3" class="ltx_text" style="font-size:90%;">, pages 1–8, 2022.
</span>
</span>
</li>
<li id="bib.bib103" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[103]</span>
<span class="ltx_bibblock"><span id="bib.bib103.1.1" class="ltx_text" style="font-size:90%;">
Ji Liu, Jizhou Huang, Yang Zhou, Xuhong Li, Shilei Ji, Haoyi Xiong, and Dejing
Dou.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib103.2.1" class="ltx_text" style="font-size:90%;">From distributed machine learning to federated learning: A survey.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib103.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Knowledge and Information Systems</span><span id="bib.bib103.4.2" class="ltx_text" style="font-size:90%;">, 64(4):885–917, 2022.
</span>
</span>
</li>
<li id="bib.bib104" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[104]</span>
<span class="ltx_bibblock"><span id="bib.bib104.1.1" class="ltx_text" style="font-size:90%;">
Kun Liu, Chris Giannella, and Hillol Kargupta.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib104.2.1" class="ltx_text" style="font-size:90%;">A survey of attack techniques on privacy-preserving data perturbation
methods.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib104.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Privacy-Preserving Data Mining: Models and Algorithms</span><span id="bib.bib104.4.2" class="ltx_text" style="font-size:90%;">, pages
359–381, 2008.
</span>
</span>
</li>
<li id="bib.bib105" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[105]</span>
<span class="ltx_bibblock"><span id="bib.bib105.1.1" class="ltx_text" style="font-size:90%;">
Kun Liu, H. Kargupta, and J. Ryan.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib105.2.1" class="ltx_text" style="font-size:90%;">Random projection-based multiplicative data perturbation for privacy
preserving distributed data mining.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib105.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Knowledge and Data Engineering</span><span id="bib.bib105.4.2" class="ltx_text" style="font-size:90%;">,
18(1):92–106, 2006.
</span>
</span>
</li>
<li id="bib.bib106" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[106]</span>
<span class="ltx_bibblock"><span id="bib.bib106.1.1" class="ltx_text" style="font-size:90%;">
Shuchang Liu, Yingqiang Ge, Shuyuan Xu, Yongfeng Zhang, and Amelie Marian.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib106.2.1" class="ltx_text" style="font-size:90%;">Fairness-aware federated matrix factorization.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib106.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib106.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the 16th ACM Conference on Recommender
Systems</span><span id="bib.bib106.5.3" class="ltx_text" style="font-size:90%;">, RecSys ’22, page 168–178, New York, NY, USA, 2022. Association
for Computing Machinery.
</span>
</span>
</li>
<li id="bib.bib107" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[107]</span>
<span class="ltx_bibblock"><span id="bib.bib107.1.1" class="ltx_text" style="font-size:90%;">
Tian Liu, Xueyang Hu, Hairuo Xu, Tao Shu, and Diep N. Nguyen.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib107.2.1" class="ltx_text" style="font-size:90%;">High-accuracy low-cost privacy-preserving federated learning in iot
systems via adaptive perturbation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib107.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Journal of Information Security and Applications</span><span id="bib.bib107.4.2" class="ltx_text" style="font-size:90%;">, 70:103309,
2022.
</span>
</span>
</li>
<li id="bib.bib108" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[108]</span>
<span class="ltx_bibblock"><span id="bib.bib108.1.1" class="ltx_text" style="font-size:90%;">
Yang Liu, Yan Kang, Chaoping Xing, Tianjian Chen, and Qiang Yang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib108.2.1" class="ltx_text" style="font-size:90%;">A secure federated transfer learning framework.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib108.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Intelligent Systems</span><span id="bib.bib108.4.2" class="ltx_text" style="font-size:90%;">, 35(4):70–82, jul 2020.
</span>
</span>
</li>
<li id="bib.bib109" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[109]</span>
<span class="ltx_bibblock"><span id="bib.bib109.1.1" class="ltx_text" style="font-size:90%;">
Yang Liu, Yingting Liu, Zhijie Liu, Yuxuan Liang, Chuishi Meng, Junbo Zhang,
and Yu Zheng.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib109.2.1" class="ltx_text" style="font-size:90%;">Federated forest.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib109.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Big Data</span><span id="bib.bib109.4.2" class="ltx_text" style="font-size:90%;">, 8(3):843–854, jun 2022.
</span>
</span>
</li>
<li id="bib.bib110" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[110]</span>
<span class="ltx_bibblock"><span id="bib.bib110.1.1" class="ltx_text" style="font-size:90%;">
Yang Liu, Zhuo Ma, Zheng Yan, Zhuzhu Wang, Ximeng Liu, and Jianfeng Ma.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib110.2.1" class="ltx_text" style="font-size:90%;">Privacy-preserving federated k-means for proactive caching in next
generation cellular networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib110.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Information Sciences</span><span id="bib.bib110.4.2" class="ltx_text" style="font-size:90%;">, 521:14–31, 2020.
</span>
</span>
</li>
<li id="bib.bib111" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[111]</span>
<span class="ltx_bibblock"><span id="bib.bib111.1.1" class="ltx_text" style="font-size:90%;">
Yuan Liu, Mengmeng Tian, Yuxin Chen, Zehui Xiong, Cyril Leung, and Chunyan
Miao.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib111.2.1" class="ltx_text" style="font-size:90%;">A contract theory based incentive mechanism for federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib111.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib111.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Federated and Transfer Learning</span><span id="bib.bib111.5.3" class="ltx_text" style="font-size:90%;">, pages 117–137. Springer,
2022.
</span>
</span>
</li>
<li id="bib.bib112" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[112]</span>
<span class="ltx_bibblock"><span id="bib.bib112.1.1" class="ltx_text" style="font-size:90%;">
Zelei Liu, Yuanyuan Chen, Han Yu, Yang Liu, and Lizhen Cui.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib112.2.1" class="ltx_text" style="font-size:90%;">Gtg-shapley: Efficient and accurate participant contribution
evaluation in federated learning, 2021.
</span>
</span>
</li>
<li id="bib.bib113" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[113]</span>
<span class="ltx_bibblock"><span id="bib.bib113.1.1" class="ltx_text" style="font-size:90%;">
Ziyao Liu, Jiale Guo, Wenzhuo Yang, Jiani Fan, Kwok-Yan Lam, and Jun Zhao.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib113.2.1" class="ltx_text" style="font-size:90%;">Privacy-preserving aggregation in federated learning: A survey, 2022.
</span>
</span>
</li>
<li id="bib.bib114" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[114]</span>
<span class="ltx_bibblock"><span id="bib.bib114.1.1" class="ltx_text" style="font-size:90%;">
Zaoxing Liu, Tian Li, Virginia Smith, and Vyas Sekar.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib114.2.1" class="ltx_text" style="font-size:90%;">Enhancing the privacy of federated learning with sketching.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib114.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1911.01812</span><span id="bib.bib114.4.2" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib115" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[115]</span>
<span class="ltx_bibblock"><span id="bib.bib115.1.1" class="ltx_text" style="font-size:90%;">
Sin Kit Lo, Yue Liu, Qinghua Lu, Chen Wang, Xiwei Xu, Hye-Young Paik, and
Liming Zhu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib115.2.1" class="ltx_text" style="font-size:90%;">Toward trustworthy ai: Blockchain-based architecture design for
accountability and fairness of federated learning systems.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib115.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Internet of Things Journal</span><span id="bib.bib115.4.2" class="ltx_text" style="font-size:90%;">, 10(4):3276–3284, 2023.
</span>
</span>
</li>
<li id="bib.bib116" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[116]</span>
<span class="ltx_bibblock"><span id="bib.bib116.1.1" class="ltx_text" style="font-size:90%;">
Pranay K Lohia, Karthikeyan Natesan Ramamurthy, Manish Bhide, Diptikalyan Saha,
Kush R Varshney, and Ruchir Puri.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib116.2.1" class="ltx_text" style="font-size:90%;">Bias mitigation post-processing for individual and group fairness.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib116.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib116.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Icassp 2019-2019 ieee international conference on acoustics,
speech and signal processing (icassp)</span><span id="bib.bib116.5.3" class="ltx_text" style="font-size:90%;">, pages 2847–2851. IEEE, 2019.
</span>
</span>
</li>
<li id="bib.bib117" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[117]</span>
<span class="ltx_bibblock"><span id="bib.bib117.1.1" class="ltx_text" style="font-size:90%;">
Lingjuan Lyu, Xinyi Xu, and Qian Wang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib117.2.1" class="ltx_text" style="font-size:90%;">Collaborative fairness in federated learning, 2020.
</span>
</span>
</li>
<li id="bib.bib118" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[118]</span>
<span class="ltx_bibblock"><span id="bib.bib118.1.1" class="ltx_text" style="font-size:90%;">
Lingjuan Lyu, Han Yu, Xingjun Ma, Chen Chen, Lichao Sun, Jun Zhao, Qiang Yang,
and Philip S. Yu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib118.2.1" class="ltx_text" style="font-size:90%;">Privacy and robustness in federated learning: Attacks and defenses,
2022.
</span>
</span>
</li>
<li id="bib.bib119" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[119]</span>
<span class="ltx_bibblock"><span id="bib.bib119.1.1" class="ltx_text" style="font-size:90%;">
Lingjuan Lyu, Han Yu, and Qiang Yang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib119.2.1" class="ltx_text" style="font-size:90%;">Threats to federated learning: A survey, 2020.
</span>
</span>
</li>
<li id="bib.bib120" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[120]</span>
<span class="ltx_bibblock"><span id="bib.bib120.1.1" class="ltx_text" style="font-size:90%;">
Jing Ma, Si-Ahmed Naas, Stephan Sigg, and Xixiang Lyu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib120.2.1" class="ltx_text" style="font-size:90%;">Privacy-preserving federated learning based on multi-key homomorphic
encryption, 2021.
</span>
</span>
</li>
<li id="bib.bib121" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[121]</span>
<span class="ltx_bibblock"><span id="bib.bib121.1.1" class="ltx_text" style="font-size:90%;">
Othmane Marfoq, Giovanni Neglia, Richard Vidal, and Laetitia Kameni.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib121.2.1" class="ltx_text" style="font-size:90%;">Personalized federated learning through local memorization.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib121.3.1" class="ltx_text" style="font-size:90%;">In Kamalika Chaudhuri, Stefanie Jegelka, Le Song, Csaba Szepesvari,
Gang Niu, and Sivan Sabato, editors, </span><span id="bib.bib121.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the 39th
International Conference on Machine Learning</span><span id="bib.bib121.5.3" class="ltx_text" style="font-size:90%;">, volume 162 of </span><span id="bib.bib121.6.4" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings
of Machine Learning Research</span><span id="bib.bib121.7.5" class="ltx_text" style="font-size:90%;">, pages 15070–15092. PMLR, 17–23 Jul 2022.
</span>
</span>
</li>
<li id="bib.bib122" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[122]</span>
<span class="ltx_bibblock"><span id="bib.bib122.1.1" class="ltx_text" style="font-size:90%;">
H. Brendan McMahan, Daniel Ramage, Kunal Talwar, and Li Zhang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib122.2.1" class="ltx_text" style="font-size:90%;">Learning differentially private recurrent language models, 2018.
</span>
</span>
</li>
<li id="bib.bib123" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[123]</span>
<span class="ltx_bibblock"><span id="bib.bib123.1.1" class="ltx_text" style="font-size:90%;">
Alan Mishler, Edward H Kennedy, and Alexandra Chouldechova.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib123.2.1" class="ltx_text" style="font-size:90%;">Fairness in risk assessment instruments: Post-processing to achieve
counterfactual equalized odds.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib123.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib123.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the 2021 ACM Conference on Fairness,
Accountability, and Transparency</span><span id="bib.bib123.5.3" class="ltx_text" style="font-size:90%;">, pages 386–400, 2021.
</span>
</span>
</li>
<li id="bib.bib124" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[124]</span>
<span class="ltx_bibblock"><span id="bib.bib124.1.1" class="ltx_text" style="font-size:90%;">
Payman Mohassel and Yupeng Zhang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib124.2.1" class="ltx_text" style="font-size:90%;">Secureml: A system for scalable privacy-preserving machine learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib124.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib124.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2017 IEEE Symposium on Security and Privacy (SP)</span><span id="bib.bib124.5.3" class="ltx_text" style="font-size:90%;">, pages
19–38, 2017.
</span>
</span>
</li>
<li id="bib.bib125" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[125]</span>
<span class="ltx_bibblock"><span id="bib.bib125.1.1" class="ltx_text" style="font-size:90%;">
Mehryar Mohri, Gary Sivek, and Ananda Theertha Suresh.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib125.2.1" class="ltx_text" style="font-size:90%;">Agnostic federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib125.3.1" class="ltx_text" style="font-size:90%;">In Kamalika Chaudhuri and Ruslan Salakhutdinov, editors, </span><span id="bib.bib125.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the 36th International Conference on Machine Learning</span><span id="bib.bib125.5.3" class="ltx_text" style="font-size:90%;">,
volume 97 of </span><span id="bib.bib125.6.4" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of Machine Learning Research</span><span id="bib.bib125.7.5" class="ltx_text" style="font-size:90%;">, pages
4615–4625. PMLR, 09–15 Jun 2019.
</span>
</span>
</li>
<li id="bib.bib126" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[126]</span>
<span class="ltx_bibblock"><span id="bib.bib126.1.1" class="ltx_text" style="font-size:90%;">
Mehryar Mohri, Gary Sivek, and Ananda Theertha Suresh.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib126.2.1" class="ltx_text" style="font-size:90%;">Agnostic federated learning, 2019.
</span>
</span>
</li>
<li id="bib.bib127" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[127]</span>
<span class="ltx_bibblock"><span id="bib.bib127.1.1" class="ltx_text" style="font-size:90%;">
Arup Mondal, Yash More, Ruthu Hulikal Rooparaghunath, and Debayan Gupta.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib127.2.1" class="ltx_text" style="font-size:90%;">Poster: Flatee: Federated learning across trusted execution
environments.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib127.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib127.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2021 IEEE European Symposium on Security and Privacy
(EuroS&amp;P)</span><span id="bib.bib127.5.3" class="ltx_text" style="font-size:90%;">, pages 707–709, 2021.
</span>
</span>
</li>
<li id="bib.bib128" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[128]</span>
<span class="ltx_bibblock"><span id="bib.bib128.1.1" class="ltx_text" style="font-size:90%;">
Wenhao Mou, Chunlei Fu, Yan Lei, and Chunqiang Hu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib128.2.1" class="ltx_text" style="font-size:90%;">A verifiable federated learning scheme based on secure multi-party
computation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib128.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib128.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Wireless Algorithms, Systems, and Applications: 16th
International Conference, WASA 2021, Nanjing, China, June 25–27, 2021,
Proceedings, Part II</span><span id="bib.bib128.5.3" class="ltx_text" style="font-size:90%;">, pages 198–209. Springer, 2021.
</span>
</span>
</li>
<li id="bib.bib129" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[129]</span>
<span class="ltx_bibblock"><span id="bib.bib129.1.1" class="ltx_text" style="font-size:90%;">
Vaikkunth Mugunthan, Antigoni Polychroniadou, David Byrd, and Tucker Hybinette
Balch.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib129.2.1" class="ltx_text" style="font-size:90%;">Smpai: Secure multi-party computation for federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib129.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib129.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the NeurIPS 2019 Workshop on Robust AI in
Financial Services</span><span id="bib.bib129.5.3" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib130" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[130]</span>
<span class="ltx_bibblock"><span id="bib.bib130.1.1" class="ltx_text" style="font-size:90%;">
Muhammad Tahir Munir, Muhammad Mustansar Saeed, Mahad Ali, Zafar Ayyub Qazi,
and Ihsan Ayyub Qazi.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib130.2.1" class="ltx_text" style="font-size:90%;">Fedprune: Towards inclusive federated learning, 2021.
</span>
</span>
</li>
<li id="bib.bib131" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[131]</span>
<span class="ltx_bibblock"><span id="bib.bib131.1.1" class="ltx_text" style="font-size:90%;">
Krishnamurty Muralidhar, Rahul Parsa, and Rathindra Sarathy.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib131.2.1" class="ltx_text" style="font-size:90%;">A general additive data perturbation method for database security.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib131.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">management science</span><span id="bib.bib131.4.2" class="ltx_text" style="font-size:90%;">, 45(10):1399–1415, 1999.
</span>
</span>
</li>
<li id="bib.bib132" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[132]</span>
<span class="ltx_bibblock"><span id="bib.bib132.1.1" class="ltx_text" style="font-size:90%;">
Lokesh Nagalapatti and Ramasuri Narayanam.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib132.2.1" class="ltx_text" style="font-size:90%;">Game of gradients: Mitigating irrelevant clients in federated
learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib132.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib132.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the AAAI Conference on Artificial
Intelligence</span><span id="bib.bib132.5.3" class="ltx_text" style="font-size:90%;">, pages 9046–9054, 2021.
</span>
</span>
</li>
<li id="bib.bib133" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[133]</span>
<span class="ltx_bibblock"><span id="bib.bib133.1.1" class="ltx_text" style="font-size:90%;">
Mohammad Naseri, Jamie Hayes, and Emiliano De Cristofaro.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib133.2.1" class="ltx_text" style="font-size:90%;">Local and central differential privacy for robustness and privacy in
federated learning, 2022.
</span>
</span>
</li>
<li id="bib.bib134" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[134]</span>
<span class="ltx_bibblock"><span id="bib.bib134.1.1" class="ltx_text" style="font-size:90%;">
Milad Nasr, Reza Shokri, and Amir Houmansadr.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib134.2.1" class="ltx_text" style="font-size:90%;">Comprehensive privacy analysis of deep learning: Passive and active
white-box inference attacks against centralized and federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib134.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib134.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2019 IEEE symposium on security and privacy (SP)</span><span id="bib.bib134.5.3" class="ltx_text" style="font-size:90%;">, pages
739–753. IEEE, 2019.
</span>
</span>
</li>
<li id="bib.bib135" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[135]</span>
<span class="ltx_bibblock"><span id="bib.bib135.1.1" class="ltx_text" style="font-size:90%;">
Takayuki Nishio and Ryo Yonetani.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib135.2.1" class="ltx_text" style="font-size:90%;">Client selection for federated learning with heterogeneous resources
in mobile edge.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib135.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib135.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICC 2019 - 2019 IEEE International Conference on
Communications (ICC)</span><span id="bib.bib135.5.3" class="ltx_text" style="font-size:90%;">. IEEE, may 2019.
</span>
</span>
</li>
<li id="bib.bib136" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[136]</span>
<span class="ltx_bibblock"><span id="bib.bib136.1.1" class="ltx_text" style="font-size:90%;">
Wei Ou, Jianhuan Zeng, Zijun Guo, Wanqin Yan, Dingwan Liu, and Stelios Fuentes.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib136.2.1" class="ltx_text" style="font-size:90%;">A homomorphic-encryption-based vertical federated learning scheme for
rick management.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib136.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Computer Science and Information Systems</span><span id="bib.bib136.4.2" class="ltx_text" style="font-size:90%;">, 17(3):819–834, 2020.
</span>
</span>
</li>
<li id="bib.bib137" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[137]</span>
<span class="ltx_bibblock"><span id="bib.bib137.1.1" class="ltx_text" style="font-size:90%;">
Ahmed El Ouadrhiri and Ahmed Abdelhadi.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib137.2.1" class="ltx_text" style="font-size:90%;">Differential privacy for deep and federated learning: A survey.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib137.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Access</span><span id="bib.bib137.4.2" class="ltx_text" style="font-size:90%;">, 10:22359–22380, 2022.
</span>
</span>
</li>
<li id="bib.bib138" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[138]</span>
<span class="ltx_bibblock"><span id="bib.bib138.1.1" class="ltx_text" style="font-size:90%;">
Manisha Padala, Sankarshan Damle, and Sujit Gujar.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib138.2.1" class="ltx_text" style="font-size:90%;">Federated learning meets fairness and differential privacy, 2021.
</span>
</span>
</li>
<li id="bib.bib139" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[139]</span>
<span class="ltx_bibblock"><span id="bib.bib139.1.1" class="ltx_text" style="font-size:90%;">
Pascal Paillier.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib139.2.1" class="ltx_text" style="font-size:90%;">Public-key cryptosystems based on composite degree residuosity
classes.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib139.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib139.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Advances in Cryptology—EUROCRYPT’99: International
Conference on the Theory and Application of Cryptographic Techniques Prague,
Czech Republic, May 2–6, 1999 Proceedings 18</span><span id="bib.bib139.5.3" class="ltx_text" style="font-size:90%;">, pages 223–238. Springer,
1999.
</span>
</span>
</li>
<li id="bib.bib140" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[140]</span>
<span class="ltx_bibblock"><span id="bib.bib140.1.1" class="ltx_text" style="font-size:90%;">
Sinno Jialin Pan and Qiang Yang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib140.2.1" class="ltx_text" style="font-size:90%;">A survey on transfer learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib140.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Knowledge and Data Engineering</span><span id="bib.bib140.4.2" class="ltx_text" style="font-size:90%;">,
22(10):1345–1359, 2010.
</span>
</span>
</li>
<li id="bib.bib141" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[141]</span>
<span class="ltx_bibblock"><span id="bib.bib141.1.1" class="ltx_text" style="font-size:90%;">
Ashwinee Panda, Saeed Mahloujifar, Arjun Nitin Bhagoji, Supriyo Chakraborty,
and Prateek Mittal.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib141.2.1" class="ltx_text" style="font-size:90%;">Sparsefed: Mitigating model poisoning attacks in federated learning
with sparsification.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib141.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib141.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">International Conference on Artificial Intelligence and
Statistics</span><span id="bib.bib141.5.3" class="ltx_text" style="font-size:90%;">, pages 7587–7624. PMLR, 2022.
</span>
</span>
</li>
<li id="bib.bib142" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[142]</span>
<span class="ltx_bibblock"><span id="bib.bib142.1.1" class="ltx_text" style="font-size:90%;">
Shashi Raj Pandey, Nguyen H. Tran, Mehdi Bennis, Yan Kyaw Tun, Aunas Manzoor,
and Choong Seon Hong.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib142.2.1" class="ltx_text" style="font-size:90%;">A crowdsourcing framework for on-device federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib142.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Wireless Communications</span><span id="bib.bib142.4.2" class="ltx_text" style="font-size:90%;">, 19(5):3241–3256,
2020.
</span>
</span>
</li>
<li id="bib.bib143" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[143]</span>
<span class="ltx_bibblock"><span id="bib.bib143.1.1" class="ltx_text" style="font-size:90%;">
Afroditi Papadaki, Natalia Martinez, Martin Bertran, Guillermo Sapiro, and
Miguel Rodrigues.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib143.2.1" class="ltx_text" style="font-size:90%;">Federating for learning group fair models, 2021.
</span>
</span>
</li>
<li id="bib.bib144" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[144]</span>
<span class="ltx_bibblock"><span id="bib.bib144.1.1" class="ltx_text" style="font-size:90%;">
Afroditi Papadaki, Natalia Martinez, Martin Bertran, Guillermo Sapiro, and
Miguel Rodrigues.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib144.2.1" class="ltx_text" style="font-size:90%;">Minimax demographic group fairness in federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib144.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib144.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2022 ACM Conference on Fairness, Accountability, and
Transparency</span><span id="bib.bib144.5.3" class="ltx_text" style="font-size:90%;">, FAccT ’22, page 142–159, New York, NY, USA, 2022.
Association for Computing Machinery.
</span>
</span>
</li>
<li id="bib.bib145" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[145]</span>
<span class="ltx_bibblock"><span id="bib.bib145.1.1" class="ltx_text" style="font-size:90%;">
Jaehyoung Park, Nam Yul Yu, and Hyuk Lim.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib145.2.1" class="ltx_text" style="font-size:90%;">Privacy-preserving federated learning using homomorphic encryption
with different encryption keys.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib145.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib145.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2022 13th International Conference on Information and
Communication Technology Convergence (ICTC)</span><span id="bib.bib145.5.3" class="ltx_text" style="font-size:90%;">, pages 1869–1871, 2022.
</span>
</span>
</li>
<li id="bib.bib146" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[146]</span>
<span class="ltx_bibblock"><span id="bib.bib146.1.1" class="ltx_text" style="font-size:90%;">
Jonathan Passerat-Palmbach, Tyler Farnan, Mike McCoy, Justin D Harris, Sean T
Manion, Heather Leigh Flannery, and Bill Gleim.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib146.2.1" class="ltx_text" style="font-size:90%;">Blockchain-orchestrated machine learning for privacy preserving
federated learning in electronic health data.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib146.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib146.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2020 IEEE International Conference on Blockchain
(Blockchain)</span><span id="bib.bib146.5.3" class="ltx_text" style="font-size:90%;">, pages 550–555. IEEE, 2020.
</span>
</span>
</li>
<li id="bib.bib147" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[147]</span>
<span class="ltx_bibblock"><span id="bib.bib147.1.1" class="ltx_text" style="font-size:90%;">
Sikha Pentyala, Nicola Neophytou, Anderson Nascimento, Martine De Cock, and
Golnoosh Farnadi.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib147.2.1" class="ltx_text" style="font-size:90%;">Privfairfl: Privacy-preserving group fairness in federated learning,
2022.
</span>
</span>
</li>
<li id="bib.bib148" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[148]</span>
<span class="ltx_bibblock"><span id="bib.bib148.1.1" class="ltx_text" style="font-size:90%;">
Preston Putzel and Scott Lee.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib148.2.1" class="ltx_text" style="font-size:90%;">Blackbox post-processing for multiclass fairness.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib148.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2201.04461</span><span id="bib.bib148.4.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib149" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[149]</span>
<span class="ltx_bibblock"><span id="bib.bib149.1.1" class="ltx_text" style="font-size:90%;">
Tao Qi, Fangzhao Wu, Chuhan Wu, Lingjuan Lyu, Tong Xu, Zhongliang Yang,
Yongfeng Huang, and Xing Xie.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib149.2.1" class="ltx_text" style="font-size:90%;">Fairvfl: A fair vertical federated learning framework with
contrastive adversarial learning, 2022.
</span>
</span>
</li>
<li id="bib.bib150" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[150]</span>
<span class="ltx_bibblock"><span id="bib.bib150.1.1" class="ltx_text" style="font-size:90%;">
Yang Qin, Hiroki Matsutani, and Masaaki Kondo.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib150.2.1" class="ltx_text" style="font-size:90%;">A selective model aggregation approach in federated learning for
online anomaly detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib150.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib150.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2020 International Conferences on Internet of Things
(iThings) and IEEE Green Computing and Communications (GreenCom) and IEEE
Cyber, Physical and Social Computing (CPSCom) and IEEE Smart Data (SmartData)
and IEEE Congress on Cybermatics (Cybermatics)</span><span id="bib.bib150.5.3" class="ltx_text" style="font-size:90%;">, pages 684–691, 2020.
</span>
</span>
</li>
<li id="bib.bib151" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[151]</span>
<span class="ltx_bibblock"><span id="bib.bib151.1.1" class="ltx_text" style="font-size:90%;">
Zhe Qu, Rui Duan, Lixing Chen, Jie Xu, Zhuo Lu, and Yao Liu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib151.2.1" class="ltx_text" style="font-size:90%;">Context-aware online client selection for hierarchical federated
learning, 2021.
</span>
</span>
</li>
<li id="bib.bib152" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[152]</span>
<span class="ltx_bibblock"><span id="bib.bib152.1.1" class="ltx_text" style="font-size:90%;">
Sashank Reddi, Zachary Charles, Manzil Zaheer, Zachary Garrett, Keith Rush,
Jakub Konečný, Sanjiv Kumar, and H. Brendan McMahan.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib152.2.1" class="ltx_text" style="font-size:90%;">Adaptive federated optimization, 2021.
</span>
</span>
</li>
<li id="bib.bib153" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[153]</span>
<span class="ltx_bibblock"><span id="bib.bib153.1.1" class="ltx_text" style="font-size:90%;">
Mónica Ribero, Jette Henderson, Sinead Williamson, and Haris Vikalo.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib153.2.1" class="ltx_text" style="font-size:90%;">Federating recommendations using differentially private prototypes.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib153.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Pattern Recognition</span><span id="bib.bib153.4.2" class="ltx_text" style="font-size:90%;">, 129:108746, 2022.
</span>
</span>
</li>
<li id="bib.bib154" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[154]</span>
<span class="ltx_bibblock"><span id="bib.bib154.1.1" class="ltx_text" style="font-size:90%;">
Nuria Rodríguez-Barroso, Goran Stipcich, Daniel Jiménez-López,
José Antonio Ruiz-Millán, Eugenio Martínez-Cámara, Gerardo
González-Seco, M Victoria Luzón, Miguel Angel Veganzones, and
Francisco Herrera.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib154.2.1" class="ltx_text" style="font-size:90%;">Federated learning and differential privacy: Software tools analysis,
the sherpa. ai fl framework and methodological guidelines for preserving data
privacy.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib154.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Information Fusion</span><span id="bib.bib154.4.2" class="ltx_text" style="font-size:90%;">, 64:270–292, 2020.
</span>
</span>
</li>
<li id="bib.bib155" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[155]</span>
<span class="ltx_bibblock"><span id="bib.bib155.1.1" class="ltx_text" style="font-size:90%;">
Borja Rodríguez-Gálvez, Filip Granqvist, Rogier van Dalen, and Matt Seigel.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib155.2.1" class="ltx_text" style="font-size:90%;">Enforcing fairness in private federated learning via the modified
method of differential multipliers, 2022.
</span>
</span>
</li>
<li id="bib.bib156" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[156]</span>
<span class="ltx_bibblock"><span id="bib.bib156.1.1" class="ltx_text" style="font-size:90%;">
Sudipan Saha and Tahir Ahmad.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib156.2.1" class="ltx_text" style="font-size:90%;">Federated transfer learning: concept and applications, 2021.
</span>
</span>
</li>
<li id="bib.bib157" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[157]</span>
<span class="ltx_bibblock"><span id="bib.bib157.1.1" class="ltx_text" style="font-size:90%;">
Teresa Salazar, Miguel Fernandes, Helder Araujo, and Pedro Henriques Abreu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib157.2.1" class="ltx_text" style="font-size:90%;">Fair-fate: Fair federated learning with momentum, 2022.
</span>
</span>
</li>
<li id="bib.bib158" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[158]</span>
<span class="ltx_bibblock"><span id="bib.bib158.1.1" class="ltx_text" style="font-size:90%;">
Mohamed Seif, Ravi Tandon, and Ming Li.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib158.2.1" class="ltx_text" style="font-size:90%;">Wireless federated learning with local differential privacy.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib158.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib158.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2020 IEEE International Symposium on Information Theory
(ISIT)</span><span id="bib.bib158.5.3" class="ltx_text" style="font-size:90%;">, pages 2604–2609. IEEE, 2020.
</span>
</span>
</li>
<li id="bib.bib159" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[159]</span>
<span class="ltx_bibblock"><span id="bib.bib159.1.1" class="ltx_text" style="font-size:90%;">
Adi Shamir.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib159.2.1" class="ltx_text" style="font-size:90%;">How to share a secret.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib159.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Commun. ACM</span><span id="bib.bib159.4.2" class="ltx_text" style="font-size:90%;">, 22(11):612–613, nov 1979.
</span>
</span>
</li>
<li id="bib.bib160" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[160]</span>
<span class="ltx_bibblock"><span id="bib.bib160.1.1" class="ltx_text" style="font-size:90%;">
Pranay Sharma, Rohan Panda, Gauri Joshi, and Pramod K. Varshney.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib160.2.1" class="ltx_text" style="font-size:90%;">Federated minimax optimization: Improved convergence analyses and
algorithms, 2022.
</span>
</span>
</li>
<li id="bib.bib161" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[161]</span>
<span class="ltx_bibblock"><span id="bib.bib161.1.1" class="ltx_text" style="font-size:90%;">
Yuxin Shi, Han Yu, and Cyril Leung.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib161.2.1" class="ltx_text" style="font-size:90%;">Towards fairness-aware federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib161.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Neural Networks and Learning Systems</span><span id="bib.bib161.4.2" class="ltx_text" style="font-size:90%;">,
pages 1–17, 2023.
</span>
</span>
</li>
<li id="bib.bib162" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[162]</span>
<span class="ltx_bibblock"><span id="bib.bib162.1.1" class="ltx_text" style="font-size:90%;">
Reza Shokri and Vitaly Shmatikov.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib162.2.1" class="ltx_text" style="font-size:90%;">Privacy-preserving deep learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib162.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib162.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the 22nd ACM SIGSAC conference on computer and
communications security</span><span id="bib.bib162.5.3" class="ltx_text" style="font-size:90%;">, pages 1310–1321, 2015.
</span>
</span>
</li>
<li id="bib.bib163" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[163]</span>
<span class="ltx_bibblock"><span id="bib.bib163.1.1" class="ltx_text" style="font-size:90%;">
Reza Shokri, George Theodorakopoulos, Jean-Yves Le Boudec, and Jean-Pierre
Hubaux.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib163.2.1" class="ltx_text" style="font-size:90%;">Quantifying location privacy.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib163.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib163.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2011 IEEE Symposium on Security and Privacy</span><span id="bib.bib163.5.3" class="ltx_text" style="font-size:90%;">, pages 247–262,
2011.
</span>
</span>
</li>
<li id="bib.bib164" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[164]</span>
<span class="ltx_bibblock"><span id="bib.bib164.1.1" class="ltx_text" style="font-size:90%;">
Sung Kuk Shyn, Donghee Kim, and Kwangsu Kim.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib164.2.1" class="ltx_text" style="font-size:90%;">Fedccea : A practical approach of client contribution evaluation for
federated learning, 2021.
</span>
</span>
</li>
<li id="bib.bib165" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[165]</span>
<span class="ltx_bibblock"><span id="bib.bib165.1.1" class="ltx_text" style="font-size:90%;">
Edward A Small, Kacper Sokol, Daniel Manning, Flora D Salim, and Jeffrey Chan.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib165.2.1" class="ltx_text" style="font-size:90%;">Equalised odds is not equal individual odds: Post-processing for
group and individual fairness.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib165.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2304.09779</span><span id="bib.bib165.4.2" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib166" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[166]</span>
<span class="ltx_bibblock"><span id="bib.bib166.1.1" class="ltx_text" style="font-size:90%;">
Mengkai Song, Zhibo Wang, Zhifei Zhang, Yang Song, Qian Wang, Ju Ren, and
Hairong Qi.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib166.2.1" class="ltx_text" style="font-size:90%;">Analyzing user-level privacy attack against federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib166.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Journal on Selected Areas in Communications</span><span id="bib.bib166.4.2" class="ltx_text" style="font-size:90%;">,
38(10):2430–2444, 2020.
</span>
</span>
</li>
<li id="bib.bib167" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[167]</span>
<span class="ltx_bibblock"><span id="bib.bib167.1.1" class="ltx_text" style="font-size:90%;">
Tianshu Song, Yongxin Tong, and Shuyue Wei.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib167.2.1" class="ltx_text" style="font-size:90%;">Profit allocation for federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib167.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib167.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2019 IEEE International Conference on Big Data (Big Data)</span><span id="bib.bib167.5.3" class="ltx_text" style="font-size:90%;">,
pages 2577–2586, 2019.
</span>
</span>
</li>
<li id="bib.bib168" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[168]</span>
<span class="ltx_bibblock"><span id="bib.bib168.1.1" class="ltx_text" style="font-size:90%;">
Tianqi Su, Meiqi Wang, and Zhongfeng Wang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib168.2.1" class="ltx_text" style="font-size:90%;">Federated regularization learning: an accurate and safe method for
federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib168.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib168.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2021 IEEE 3rd International Conference on Artificial
Intelligence Circuits and Systems (AICAS)</span><span id="bib.bib168.5.3" class="ltx_text" style="font-size:90%;">, pages 1–4, 2021.
</span>
</span>
</li>
<li id="bib.bib169" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[169]</span>
<span class="ltx_bibblock"><span id="bib.bib169.1.1" class="ltx_text" style="font-size:90%;">
Lichao Sun, Jianwei Qian, and Xun Chen.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib169.2.1" class="ltx_text" style="font-size:90%;">Ldp-fl: Practical private aggregation in federated learning with
local differential privacy.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib169.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2007.15789</span><span id="bib.bib169.4.2" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib170" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[170]</span>
<span class="ltx_bibblock"><span id="bib.bib170.1.1" class="ltx_text" style="font-size:90%;">
Latanya Sweeney.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib170.2.1" class="ltx_text" style="font-size:90%;">k-anonymity: A model for protecting privacy.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib170.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">International journal of uncertainty, fuzziness and
knowledge-based systems</span><span id="bib.bib170.4.2" class="ltx_text" style="font-size:90%;">, 10(05):557–570, 2002.
</span>
</span>
</li>
<li id="bib.bib171" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[171]</span>
<span class="ltx_bibblock"><span id="bib.bib171.1.1" class="ltx_text" style="font-size:90%;">
Aleksei Triastcyn and Boi Faltings.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib171.2.1" class="ltx_text" style="font-size:90%;">Federated learning with bayesian differential privacy.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib171.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib171.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2019 IEEE International Conference on Big Data (Big Data)</span><span id="bib.bib171.5.3" class="ltx_text" style="font-size:90%;">,
pages 2587–2596. IEEE, 2019.
</span>
</span>
</li>
<li id="bib.bib172" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[172]</span>
<span class="ltx_bibblock"><span id="bib.bib172.1.1" class="ltx_text" style="font-size:90%;">
Stacey Truex, Nathalie Baracaldo, Ali Anwar, Thomas Steinke, Heiko Ludwig, Rui
Zhang, and Yi Zhou.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib172.2.1" class="ltx_text" style="font-size:90%;">A hybrid approach to privacy-preserving federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib172.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib172.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the 12th ACM workshop on artificial
intelligence and security</span><span id="bib.bib172.5.3" class="ltx_text" style="font-size:90%;">, pages 1–11, 2019.
</span>
</span>
</li>
<li id="bib.bib173" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[173]</span>
<span class="ltx_bibblock"><span id="bib.bib173.1.1" class="ltx_text" style="font-size:90%;">
Stacey Truex, Ling Liu, Ka-Ho Chow, Mehmet Emre Gursoy, and Wenqi Wei.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib173.2.1" class="ltx_text" style="font-size:90%;">Ldp-fed: Federated learning with local differential privacy.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib173.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib173.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the Third ACM International Workshop on Edge
Systems, Analytics and Networking</span><span id="bib.bib173.5.3" class="ltx_text" style="font-size:90%;">, EdgeSys ’20, page 61–66, New York, NY,
USA, 2020. Association for Computing Machinery.
</span>
</span>
</li>
<li id="bib.bib174" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[174]</span>
<span class="ltx_bibblock"><span id="bib.bib174.1.1" class="ltx_text" style="font-size:90%;">
Xuezhen Tu, Kun Zhu, Nguyen Cong Luong, Dusit Niyato, Yang Zhang, and Juan Li.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib174.2.1" class="ltx_text" style="font-size:90%;">Incentive mechanisms for federated learning: From economic and game
theoretic perspective, 2021.
</span>
</span>
</li>
<li id="bib.bib175" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[175]</span>
<span class="ltx_bibblock"><span id="bib.bib175.1.1" class="ltx_text" style="font-size:90%;">
Anastasiia Usmanova, François Portet, Philippe Lalanda, and German Vega.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib175.2.1" class="ltx_text" style="font-size:90%;">A distillation-based approach integrating continual learning and
federated learning for pervasive services.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib175.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2109.04197</span><span id="bib.bib175.4.2" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib176" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[176]</span>
<span class="ltx_bibblock"><span id="bib.bib176.1.1" class="ltx_text" style="font-size:90%;">
Isabel Wagner.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib176.2.1" class="ltx_text" style="font-size:90%;">Evaluating the strength of genomic privacy metrics.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib176.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">ACM Transactions on Privacy and Security</span><span id="bib.bib176.4.2" class="ltx_text" style="font-size:90%;">, 20(1):1–34, jan
2017.
</span>
</span>
</li>
<li id="bib.bib177" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[177]</span>
<span class="ltx_bibblock"><span id="bib.bib177.1.1" class="ltx_text" style="font-size:90%;">
Isabel Wagner and David Eckhoff.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib177.2.1" class="ltx_text" style="font-size:90%;">Technical privacy metrics.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib177.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">ACM Computing Surveys</span><span id="bib.bib177.4.2" class="ltx_text" style="font-size:90%;">, 51(3):1–38, jun 2018.
</span>
</span>
</li>
<li id="bib.bib178" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[178]</span>
<span class="ltx_bibblock"><span id="bib.bib178.1.1" class="ltx_text" style="font-size:90%;">
Chang Wang, Jian Liang, Mingkai Huang, Bing Bai, Kun Bai, and Hao Li.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib178.2.1" class="ltx_text" style="font-size:90%;">Hybrid differentially private federated learning on vertically
partitioned data, 2020.
</span>
</span>
</li>
<li id="bib.bib179" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[179]</span>
<span class="ltx_bibblock"><span id="bib.bib179.1.1" class="ltx_text" style="font-size:90%;">
Chen Wang, Xinkui Wu, Gaoyang Liu, Tianping Deng, Kai Peng, and Shaohua Wan.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib179.2.1" class="ltx_text" style="font-size:90%;">Safeguarding cross-silo federated learning with local differential
privacy.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib179.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Digital Communications and Networks</span><span id="bib.bib179.4.2" class="ltx_text" style="font-size:90%;">, 8(4):446–454, 2022.
</span>
</span>
</li>
<li id="bib.bib180" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[180]</span>
<span class="ltx_bibblock"><span id="bib.bib180.1.1" class="ltx_text" style="font-size:90%;">
Guan Wang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib180.2.1" class="ltx_text" style="font-size:90%;">Interpret federated learning with shapley values.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib180.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1905.04519</span><span id="bib.bib180.4.2" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib181" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[181]</span>
<span class="ltx_bibblock"><span id="bib.bib181.1.1" class="ltx_text" style="font-size:90%;">
Guan Wang, Charlie Xiaoqian Dang, and Ziye Zhou.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib181.2.1" class="ltx_text" style="font-size:90%;">Measure contribution of participants in federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib181.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib181.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2019 IEEE International Conference on Big Data (Big Data)</span><span id="bib.bib181.5.3" class="ltx_text" style="font-size:90%;">,
pages 2597–2604, 2019.
</span>
</span>
</li>
<li id="bib.bib182" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[182]</span>
<span class="ltx_bibblock"><span id="bib.bib182.1.1" class="ltx_text" style="font-size:90%;">
Hao Wang, Zakhary Kaplan, Di Niu, and Baochun Li.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib182.2.1" class="ltx_text" style="font-size:90%;">Optimizing federated learning on non-iid data with reinforcement
learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib182.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib182.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE INFOCOM 2020 - IEEE Conference on Computer
Communications</span><span id="bib.bib182.5.3" class="ltx_text" style="font-size:90%;">, pages 1698–1707, 2020.
</span>
</span>
</li>
<li id="bib.bib183" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[183]</span>
<span class="ltx_bibblock"><span id="bib.bib183.1.1" class="ltx_text" style="font-size:90%;">
Hongyi Wang, Mikhail Yurochkin, Yuekai Sun, Dimitris Papailiopoulos, and
Yasaman Khazaeni.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib183.2.1" class="ltx_text" style="font-size:90%;">Federated learning with matched averaging, 2020.
</span>
</span>
</li>
<li id="bib.bib184" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[184]</span>
<span class="ltx_bibblock"><span id="bib.bib184.1.1" class="ltx_text" style="font-size:90%;">
Lin Wang, Zhichao Wang, and Xiaoying Tang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib184.2.1" class="ltx_text" style="font-size:90%;">Fedeba+: Towards fair and effective federated learning via
entropy-based model, 2023.
</span>
</span>
</li>
<li id="bib.bib185" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[185]</span>
<span class="ltx_bibblock"><span id="bib.bib185.1.1" class="ltx_text" style="font-size:90%;">
Zheng Wang, Xiaoliang Fan, Jianzhong Qi, Chenglu Wen, Cheng Wang, and Rongshan
Yu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib185.2.1" class="ltx_text" style="font-size:90%;">Federated learning with fair averaging, 2021.
</span>
</span>
</li>
<li id="bib.bib186" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[186]</span>
<span class="ltx_bibblock"><span id="bib.bib186.1.1" class="ltx_text" style="font-size:90%;">
Zhibo Wang, Mengkai Song, Zhifei Zhang, Yang Song, Qian Wang, and Hairong Qi.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib186.2.1" class="ltx_text" style="font-size:90%;">Beyond inferring class representatives: User-level privacy leakage
from federated learning, 2018.
</span>
</span>
</li>
<li id="bib.bib187" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[187]</span>
<span class="ltx_bibblock"><span id="bib.bib187.1.1" class="ltx_text" style="font-size:90%;">
Zhibo Wang, Mengkai Song, Zhifei Zhang, Yang Song, Qian Wang, and Hairong Qi.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib187.2.1" class="ltx_text" style="font-size:90%;">Beyond inferring class representatives: User-level privacy leakage
from federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib187.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib187.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE INFOCOM 2019-IEEE conference on computer
communications</span><span id="bib.bib187.5.3" class="ltx_text" style="font-size:90%;">, pages 2512–2520. IEEE, 2019.
</span>
</span>
</li>
<li id="bib.bib188" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[188]</span>
<span class="ltx_bibblock"><span id="bib.bib188.1.1" class="ltx_text" style="font-size:90%;">
Kang Wei, Jun Li, Ming Ding, Chuan Ma, Howard H Yang, Farhad Farokhi, Shi Jin,
Tony QS Quek, and H Vincent Poor.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib188.2.1" class="ltx_text" style="font-size:90%;">Federated learning with differential privacy: Algorithms and
performance analysis.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib188.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Information Forensics and Security</span><span id="bib.bib188.4.2" class="ltx_text" style="font-size:90%;">,
15:3454–3469, 2020.
</span>
</span>
</li>
<li id="bib.bib189" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[189]</span>
<span class="ltx_bibblock"><span id="bib.bib189.1.1" class="ltx_text" style="font-size:90%;">
Kang Wei, Jun Li, Chuan Ma, Ming Ding, Sha Wei, Fan Wu, Guihai Chen, and
Thilina Ranbaduge.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib189.2.1" class="ltx_text" style="font-size:90%;">Vertical federated learning: Challenges, methodologies and
experiments.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib189.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2202.04309</span><span id="bib.bib189.4.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib190" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[190]</span>
<span class="ltx_bibblock"><span id="bib.bib190.1.1" class="ltx_text" style="font-size:90%;">
Danye Wu, Miao Pan, Zhiwei Xu, Yujun Zhang, and Zhu Han.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib190.2.1" class="ltx_text" style="font-size:90%;">Towards efficient secure aggregation for model update in federated
learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib190.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib190.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">GLOBECOM 2020-2020 IEEE Global Communications Conference</span><span id="bib.bib190.5.3" class="ltx_text" style="font-size:90%;">,
pages 1–6. IEEE, 2020.
</span>
</span>
</li>
<li id="bib.bib191" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[191]</span>
<span class="ltx_bibblock"><span id="bib.bib191.1.1" class="ltx_text" style="font-size:90%;">
Jing Wu, Munawar Hayat, Mingyi Zhou, and Mehrtash Harandi.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib191.2.1" class="ltx_text" style="font-size:90%;">Defense against privacy leakage in federated learning, 2022.
</span>
</span>
</li>
<li id="bib.bib192" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[192]</span>
<span class="ltx_bibblock"><span id="bib.bib192.1.1" class="ltx_text" style="font-size:90%;">
Shanshan Wu, Tian Li, Zachary Charles, Yu Xiao, Ziyu Liu, Zheng Xu, and
Virginia Smith.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib192.2.1" class="ltx_text" style="font-size:90%;">Motley: Benchmarking heterogeneity and personalization in federated
learning, 2022.
</span>
</span>
</li>
<li id="bib.bib193" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[193]</span>
<span class="ltx_bibblock"><span id="bib.bib193.1.1" class="ltx_text" style="font-size:90%;">
Xiang Wu, Yongting Zhang, Minyu Shi, Pei Li, Ruirui Li, and Neal N Xiong.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib193.2.1" class="ltx_text" style="font-size:90%;">An adaptive federated learning scheme with differential privacy
preserving.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib193.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Future Generation Computer Systems</span><span id="bib.bib193.4.2" class="ltx_text" style="font-size:90%;">, 127:362–372, 2022.
</span>
</span>
</li>
<li id="bib.bib194" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[194]</span>
<span class="ltx_bibblock"><span id="bib.bib194.1.1" class="ltx_text" style="font-size:90%;">
Binhan Xi, Shaofeng Li, Jiachun Li, Hui Liu, Hong Liu, and Haojin Zhu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib194.2.1" class="ltx_text" style="font-size:90%;">Batfl: Backdoor detection on federated learning in e-health.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib194.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib194.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2021 IEEE/ACM 29th International Symposium on Quality of
Service (IWQOS)</span><span id="bib.bib194.5.3" class="ltx_text" style="font-size:90%;">, pages 1–10. IEEE, 2021.
</span>
</span>
</li>
<li id="bib.bib195" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[195]</span>
<span class="ltx_bibblock"><span id="bib.bib195.1.1" class="ltx_text" style="font-size:90%;">
Wensheng Xia, Ying Li, Lan Zhang, Zhonghai Wu, and Xiaoyong Yuan.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib195.2.1" class="ltx_text" style="font-size:90%;">A vertical federated learning framework for horizontally partitioned
labels, 2021.
</span>
</span>
</li>
<li id="bib.bib196" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[196]</span>
<span class="ltx_bibblock"><span id="bib.bib196.1.1" class="ltx_text" style="font-size:90%;">
Wenchao Xia, Tony Q. S. Quek, Kun Guo, Wanli Wen, Howard H. Yang, and Hongbo
Zhu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib196.2.1" class="ltx_text" style="font-size:90%;">Multi-armed bandit-based client scheduling for federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib196.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Wireless Communications</span><span id="bib.bib196.4.2" class="ltx_text" style="font-size:90%;">,
19(11):7108–7123, 2020.
</span>
</span>
</li>
<li id="bib.bib197" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[197]</span>
<span class="ltx_bibblock"><span id="bib.bib197.1.1" class="ltx_text" style="font-size:90%;">
Lunchen Xie, Jiaqi Liu, Songtao Lu, Tsung hui Chang, and Qingjiang Shi.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib197.2.1" class="ltx_text" style="font-size:90%;">An efficient learning framework for federated xgboost using secret
sharing and distributed optimization, 2021.
</span>
</span>
</li>
<li id="bib.bib198" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[198]</span>
<span class="ltx_bibblock"><span id="bib.bib198.1.1" class="ltx_text" style="font-size:90%;">
Bangzhou Xin, Wei Yang, Yangyang Geng, Sheng Chen, Shaowei Wang, and Liusheng
Huang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib198.2.1" class="ltx_text" style="font-size:90%;">Private fl-gan: Differential privacy synthetic data generation based
on federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib198.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib198.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">ICASSP 2020-2020 IEEE International Conference on Acoustics,
Speech and Signal Processing (ICASSP)</span><span id="bib.bib198.5.3" class="ltx_text" style="font-size:90%;">, pages 2927–2931. IEEE, 2020.
</span>
</span>
</li>
<li id="bib.bib199" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[199]</span>
<span class="ltx_bibblock"><span id="bib.bib199.1.1" class="ltx_text" style="font-size:90%;">
Guowen Xu, Hongwei Li, Sen Liu, Kan Yang, and Xiaodong Lin.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib199.2.1" class="ltx_text" style="font-size:90%;">Verifynet: Secure and verifiable federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib199.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Information Forensics and Security</span><span id="bib.bib199.4.2" class="ltx_text" style="font-size:90%;">,
15:911–926, 2020.
</span>
</span>
</li>
<li id="bib.bib200" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[200]</span>
<span class="ltx_bibblock"><span id="bib.bib200.1.1" class="ltx_text" style="font-size:90%;">
Runhua Xu, Nathalie Baracaldo, Yi Zhou, Ali Anwar, and Heiko Ludwig.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib200.2.1" class="ltx_text" style="font-size:90%;">Hybridalpha: An efficient approach for privacy-preserving federated
learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib200.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib200.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the 12th ACM workshop on artificial
intelligence and security</span><span id="bib.bib200.5.3" class="ltx_text" style="font-size:90%;">, pages 13–23, 2019.
</span>
</span>
</li>
<li id="bib.bib201" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[201]</span>
<span class="ltx_bibblock"><span id="bib.bib201.1.1" class="ltx_text" style="font-size:90%;">
Xinyi Xu and Lingjuan Lyu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib201.2.1" class="ltx_text" style="font-size:90%;">A reputation mechanism is all you need: Collaborative fairness and
adversarial robustness in federated learning, 2021.
</span>
</span>
</li>
<li id="bib.bib202" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[202]</span>
<span class="ltx_bibblock"><span id="bib.bib202.1.1" class="ltx_text" style="font-size:90%;">
Ke Yang, Biao Huang, Julia Stoyanovich, and Sebastian Schelter.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib202.2.1" class="ltx_text" style="font-size:90%;">Fairness-aware instrumentation of preprocessing~ pipelines for
machine learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib202.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib202.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Workshop on Human-In-the-Loop Data Analytics (HILDA’20)</span><span id="bib.bib202.5.3" class="ltx_text" style="font-size:90%;">,
2020.
</span>
</span>
</li>
<li id="bib.bib203" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[203]</span>
<span class="ltx_bibblock"><span id="bib.bib203.1.1" class="ltx_text" style="font-size:90%;">
Shengwen Yang, Bing Ren, Xuhui Zhou, and Liping Liu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib203.2.1" class="ltx_text" style="font-size:90%;">Parallel distributed logistic regression for vertical federated
learning without third-party coordinator, 2019.
</span>
</span>
</li>
<li id="bib.bib204" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[204]</span>
<span class="ltx_bibblock"><span id="bib.bib204.1.1" class="ltx_text" style="font-size:90%;">
Xue Yang, Yan Feng, Weijun Fang, Jun Shao, Xiaohu Tang, Shu-Tao Xia, and
Rongxing Lu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib204.2.1" class="ltx_text" style="font-size:90%;">An accuracy-lossless perturbation method for defending privacy
attacks in federated learning, 2021.
</span>
</span>
</li>
<li id="bib.bib205" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[205]</span>
<span class="ltx_bibblock"><span id="bib.bib205.1.1" class="ltx_text" style="font-size:90%;">
Xiulong Yang and Shihao Ji.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib205.2.1" class="ltx_text" style="font-size:90%;">Learning with multiplicative perturbations.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib205.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib205.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2020 25th International Conference on Pattern Recognition
(ICPR)</span><span id="bib.bib205.5.3" class="ltx_text" style="font-size:90%;">, pages 1321–1328. IEEE, 2021.
</span>
</span>
</li>
<li id="bib.bib206" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[206]</span>
<span class="ltx_bibblock"><span id="bib.bib206.1.1" class="ltx_text" style="font-size:90%;">
Yurui Yang and Bo Jiang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib206.2.1" class="ltx_text" style="font-size:90%;">Towards group fairness via semi-centralized adversarial training in
federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib206.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib206.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2022 23rd IEEE International Conference on Mobile Data
Management (MDM)</span><span id="bib.bib206.5.3" class="ltx_text" style="font-size:90%;">, pages 482–487, 2022.
</span>
</span>
</li>
<li id="bib.bib207" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[207]</span>
<span class="ltx_bibblock"><span id="bib.bib207.1.1" class="ltx_text" style="font-size:90%;">
Zhaoxiong Yang, Shuihai Hu, and Kai Chen.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib207.2.1" class="ltx_text" style="font-size:90%;">Fpga-based hardware accelerator of homomorphic encryption for
efficient federated learning, 2020.
</span>
</span>
</li>
<li id="bib.bib208" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[208]</span>
<span class="ltx_bibblock"><span id="bib.bib208.1.1" class="ltx_text" style="font-size:90%;">
Yunfan Ye, Shen Li, Fang Liu, Yonghao Tang, and Wanting Hu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib208.2.1" class="ltx_text" style="font-size:90%;">Edgefed: Optimized federated learning based on edge computing.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib208.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Access</span><span id="bib.bib208.4.2" class="ltx_text" style="font-size:90%;">, 8:209191–209198, 2020.
</span>
</span>
</li>
<li id="bib.bib209" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[209]</span>
<span class="ltx_bibblock"><span id="bib.bib209.1.1" class="ltx_text" style="font-size:90%;">
Xuefei Yin, Yanming Zhu, and Jiankun Hu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib209.2.1" class="ltx_text" style="font-size:90%;">A comprehensive survey of privacy-preserving federated learning: A
taxonomy, review, and future directions.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib209.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">ACM Comput. Surv.</span><span id="bib.bib209.4.2" class="ltx_text" style="font-size:90%;">, 54(6), jul 2021.
</span>
</span>
</li>
<li id="bib.bib210" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[210]</span>
<span class="ltx_bibblock"><span id="bib.bib210.1.1" class="ltx_text" style="font-size:90%;">
Han Yu, Zelei Liu, Yang Liu, Tianjian Chen, Mingshu Cong, Xi Weng, Dusit
Niyato, and Qiang Yang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib210.2.1" class="ltx_text" style="font-size:90%;">A fairness-aware incentive scheme for federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib210.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib210.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the AAAI/ACM Conference on AI, Ethics, and
Society</span><span id="bib.bib210.5.3" class="ltx_text" style="font-size:90%;">, AIES ’20, page 393–399, New York, NY, USA, 2020. Association for
Computing Machinery.
</span>
</span>
</li>
<li id="bib.bib211" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[211]</span>
<span class="ltx_bibblock"><span id="bib.bib211.1.1" class="ltx_text" style="font-size:90%;">
Han Yu, Zelei Liu, Yang Liu, Tianjian Chen, Mingshu Cong, Xi Weng, Dusit
Niyato, and Qiang Yang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib211.2.1" class="ltx_text" style="font-size:90%;">A fairness-aware incentive scheme for federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib211.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib211.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the AAAI/ACM Conference on AI, Ethics, and
Society</span><span id="bib.bib211.5.3" class="ltx_text" style="font-size:90%;">, pages 393–399, 2020.
</span>
</span>
</li>
<li id="bib.bib212" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[212]</span>
<span class="ltx_bibblock"><span id="bib.bib212.1.1" class="ltx_text" style="font-size:90%;">
Xubo Yue, Maher Nouiehed, and Raed Al Kontar.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib212.2.1" class="ltx_text" style="font-size:90%;">Gifair-fl: A framework for group and individual fairness in federated
learning, 2022.
</span>
</span>
</li>
<li id="bib.bib213" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[213]</span>
<span class="ltx_bibblock"><span id="bib.bib213.1.1" class="ltx_text" style="font-size:90%;">
Won Joon Yun, Yunseok Kwak, Hankyul Baek, Soyi Jung, Mingyue Ji, Mehdi Bennis,
Jihong Park, and Joongheon Kim.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib213.2.1" class="ltx_text" style="font-size:90%;">Slimfl: Federated learning with superposition coding over slimmable
neural networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib213.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE/ACM Transactions on Networking</span><span id="bib.bib213.4.2" class="ltx_text" style="font-size:90%;">, pages 1–16, 2022.
</span>
</span>
</li>
<li id="bib.bib214" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[214]</span>
<span class="ltx_bibblock"><span id="bib.bib214.1.1" class="ltx_text" style="font-size:90%;">
Yuchen Zeng, Hongxu Chen, and Kangwook Lee.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib214.2.1" class="ltx_text" style="font-size:90%;">Improving fairness via federated learning, 2022.
</span>
</span>
</li>
<li id="bib.bib215" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[215]</span>
<span class="ltx_bibblock"><span id="bib.bib215.1.1" class="ltx_text" style="font-size:90%;">
Brian Hu Zhang, Blake Lemoine, and Margaret Mitchell.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib215.2.1" class="ltx_text" style="font-size:90%;">Mitigating unwanted biases with adversarial learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib215.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib215.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics,
and Society</span><span id="bib.bib215.5.3" class="ltx_text" style="font-size:90%;">, pages 335–340, 2018.
</span>
</span>
</li>
<li id="bib.bib216" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[216]</span>
<span class="ltx_bibblock"><span id="bib.bib216.1.1" class="ltx_text" style="font-size:90%;">
Chengliang Zhang, Suyi Li, Junzhe Xia, Wei Wang, Feng Yan, and Yang Liu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib216.2.1" class="ltx_text" style="font-size:90%;">Batchcrypt: Efficient homomorphic encryption for cross-silo federated
learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib216.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib216.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the 2020 USENIX Annual Technical Conference
(USENIX ATC 2020)</span><span id="bib.bib216.5.3" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib217" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[217]</span>
<span class="ltx_bibblock"><span id="bib.bib217.1.1" class="ltx_text" style="font-size:90%;">
Daniel Yue Zhang, Ziyi Kou, and Dong Wang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib217.2.1" class="ltx_text" style="font-size:90%;">Fairfl: A fair federated learning approach to reducing demographic
bias in privacy-sensitive classification models.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib217.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib217.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2020 IEEE International Conference on Big Data (Big Data)</span><span id="bib.bib217.5.3" class="ltx_text" style="font-size:90%;">,
pages 1051–1060, 2020.
</span>
</span>
</li>
<li id="bib.bib218" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[218]</span>
<span class="ltx_bibblock"><span id="bib.bib218.1.1" class="ltx_text" style="font-size:90%;">
Fengda Zhang, Kun Kuang, Yuxuan Liu, Long Chen, Chao Wu, Fei Wu, Jiaxun Lu,
Yunfeng Shao, and Jun Xiao.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib218.2.1" class="ltx_text" style="font-size:90%;">Unified group fairness on federated learning, 2022.
</span>
</span>
</li>
<li id="bib.bib219" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[219]</span>
<span class="ltx_bibblock"><span id="bib.bib219.1.1" class="ltx_text" style="font-size:90%;">
Hantian Zhang, Xu Chu, Abolfazl Asudeh, and Shamkant B Navathe.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib219.2.1" class="ltx_text" style="font-size:90%;">Omnifair: A declarative system for model-agnostic group fairness in
machine learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib219.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib219.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the 2021 international conference on
management of data</span><span id="bib.bib219.5.3" class="ltx_text" style="font-size:90%;">, pages 2076–2088, 2021.
</span>
</span>
</li>
<li id="bib.bib220" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[220]</span>
<span class="ltx_bibblock"><span id="bib.bib220.1.1" class="ltx_text" style="font-size:90%;">
Haobo Zhang, Junyuan Hong, Fan Dong, Steve Drew, Liangjie Xue, and Jiayu Zhou.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib220.2.1" class="ltx_text" style="font-size:90%;">A privacy-preserving hybrid federated learning framework for
financial crime detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib220.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2302.03654</span><span id="bib.bib220.4.2" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib221" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[221]</span>
<span class="ltx_bibblock"><span id="bib.bib221.1.1" class="ltx_text" style="font-size:90%;">
Jiale Zhang, Bing Chen, Shui Yu, and Hai Deng.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib221.2.1" class="ltx_text" style="font-size:90%;">Pefl: A privacy-enhanced federated learning scheme for big data
analytics.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib221.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib221.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2019 IEEE Global Communications Conference (GLOBECOM)</span><span id="bib.bib221.5.3" class="ltx_text" style="font-size:90%;">, pages
1–6. IEEE, 2019.
</span>
</span>
</li>
<li id="bib.bib222" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[222]</span>
<span class="ltx_bibblock"><span id="bib.bib222.1.1" class="ltx_text" style="font-size:90%;">
Jie Zhang, Chen Chen, Bo Li, Lingjuan Lyu, Shuang Wu, Shouhong Ding, Chunhua
Shen, and Chao Wu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib222.2.1" class="ltx_text" style="font-size:90%;">Dense: Data-free one-shot federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib222.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Advances in Neural Information Processing Systems</span><span id="bib.bib222.4.2" class="ltx_text" style="font-size:90%;">,
35:21414–21428, 2022.
</span>
</span>
</li>
<li id="bib.bib223" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[223]</span>
<span class="ltx_bibblock"><span id="bib.bib223.1.1" class="ltx_text" style="font-size:90%;">
Jie Zhang, Chen Chen, Bo Li, Lingjuan Lyu, Shuang Wu, Jianghe Xu, Shouhong
Ding, and Chao Wu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib223.2.1" class="ltx_text" style="font-size:90%;">A practical data-free approach to one-shot federated learning with
heterogeneity.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib223.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2112.12371</span><span id="bib.bib223.4.2" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib224" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[224]</span>
<span class="ltx_bibblock"><span id="bib.bib224.1.1" class="ltx_text" style="font-size:90%;">
Jingyang Zhang, Yiran Chen, and Hai Li.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib224.2.1" class="ltx_text" style="font-size:90%;">Privacy leakage of adversarial training models in federated learning
systems, 2022.
</span>
</span>
</li>
<li id="bib.bib225" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[225]</span>
<span class="ltx_bibblock"><span id="bib.bib225.1.1" class="ltx_text" style="font-size:90%;">
Junxue Zhang, Xiaodian Cheng, Wei Wang, Liu Yang, Jinbin Hu, and Kai Chen.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib225.2.1" class="ltx_text" style="font-size:90%;">FLASH: Towards a high-performance hardware acceleration
architecture for cross-silo federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib225.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib225.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">20th USENIX Symposium on Networked Systems Design and
Implementation (NSDI 23)</span><span id="bib.bib225.5.3" class="ltx_text" style="font-size:90%;">, pages 1057–1079, Boston, MA, Apr. 2023. USENIX
Association.
</span>
</span>
</li>
<li id="bib.bib226" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[226]</span>
<span class="ltx_bibblock"><span id="bib.bib226.1.1" class="ltx_text" style="font-size:90%;">
Jingfeng Zhang, Cheng Li, Antonio Robles-Kelly, and Mohan Kankanhalli.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib226.2.1" class="ltx_text" style="font-size:90%;">Hierarchically fair federated learning, 2020.
</span>
</span>
</li>
<li id="bib.bib227" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[227]</span>
<span class="ltx_bibblock"><span id="bib.bib227.1.1" class="ltx_text" style="font-size:90%;">
Li Zhang, Jianbo Xu, Pandi Vijayakumar, Pradip Kumar Sharma, and Uttam Ghosh.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib227.2.1" class="ltx_text" style="font-size:90%;">Homomorphic encryption-based privacy-preserving federated learning in
iot-enabled healthcare system.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib227.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Network Science and Engineering</span><span id="bib.bib227.4.2" class="ltx_text" style="font-size:90%;">, pages
1–17, 2022.
</span>
</span>
</li>
<li id="bib.bib228" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[228]</span>
<span class="ltx_bibblock"><span id="bib.bib228.1.1" class="ltx_text" style="font-size:90%;">
Shulai Zhang, Zirui Li, Quan Chen, Wenli Zheng, Jingwen Leng, and Minyi Guo.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib228.2.1" class="ltx_text" style="font-size:90%;">Dubhe: Towards data unbiasedness with homomorphic encryption in
federated learning client selection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib228.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib228.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the 50th International Conference on Parallel
Processing</span><span id="bib.bib228.5.3" class="ltx_text" style="font-size:90%;">, ICPP ’21, New York, NY, USA, 2021. Association for Computing
Machinery.
</span>
</span>
</li>
<li id="bib.bib229" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[229]</span>
<span class="ltx_bibblock"><span id="bib.bib229.1.1" class="ltx_text" style="font-size:90%;">
Sai Qian Zhang, Jieyu Lin, and Qi Zhang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib229.2.1" class="ltx_text" style="font-size:90%;">A multi-agent reinforcement learning approach for efficient client
selection in federated learning, 2022.
</span>
</span>
</li>
<li id="bib.bib230" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[230]</span>
<span class="ltx_bibblock"><span id="bib.bib230.1.1" class="ltx_text" style="font-size:90%;">
Xinwei Zhang, Xiangyi Chen, Mingyi Hong, Zhiwei Steven Wu, and Jinfeng Yi.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib230.2.1" class="ltx_text" style="font-size:90%;">Understanding clipping for federated learning: Convergence and
client-level differential privacy.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib230.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib230.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">International Conference on Machine Learning, ICML 2022</span><span id="bib.bib230.5.3" class="ltx_text" style="font-size:90%;">,
2022.
</span>
</span>
</li>
<li id="bib.bib231" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[231]</span>
<span class="ltx_bibblock"><span id="bib.bib231.1.1" class="ltx_text" style="font-size:90%;">
Xiao-Yu Zhang, José-Rodrigo Córdoba-Pachón, Peiqian Guo, Chris Watkins, and
Stefanie Kuenzel.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib231.2.1" class="ltx_text" style="font-size:90%;">Privacy-preserving federated learning for value-added service model
in advanced metering infrastructure.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib231.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Computational Social Systems</span><span id="bib.bib231.4.2" class="ltx_text" style="font-size:90%;">, pages 1–15,
2022.
</span>
</span>
</li>
<li id="bib.bib232" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[232]</span>
<span class="ltx_bibblock"><span id="bib.bib232.1.1" class="ltx_text" style="font-size:90%;">
Yuhui Zhang, Zhiwei Wang, Jiangfeng Cao, Rui Hou, and Dan Meng.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib232.2.1" class="ltx_text" style="font-size:90%;">Shufflefl: Gradient-preserving federated learning using trusted
execution environment.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib232.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib232.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the 18th ACM International Conference on
Computing Frontiers</span><span id="bib.bib232.5.3" class="ltx_text" style="font-size:90%;">, CF ’21, page 161–168, New York, NY, USA, 2021.
Association for Computing Machinery.
</span>
</span>
</li>
<li id="bib.bib233" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[233]</span>
<span class="ltx_bibblock"><span id="bib.bib233.1.1" class="ltx_text" style="font-size:90%;">
Bin Zhao, Kai Fan, Kan Yang, Zilong Wang, Hui Li, and Yintang Yang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib233.2.1" class="ltx_text" style="font-size:90%;">Anonymous and privacy-preserving federated learning with industrial
big data.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib233.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Industrial Informatics</span><span id="bib.bib233.4.2" class="ltx_text" style="font-size:90%;">, 17(9):6314–6323,
2021.
</span>
</span>
</li>
<li id="bib.bib234" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[234]</span>
<span class="ltx_bibblock"><span id="bib.bib234.1.1" class="ltx_text" style="font-size:90%;">
Yuxi Zhao, Xiaowen Gong, and Shiwen Mao.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib234.2.1" class="ltx_text" style="font-size:90%;">Truthful incentive mechanism for federated learning with crowdsourced
data labeling, 2023.
</span>
</span>
</li>
<li id="bib.bib235" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[235]</span>
<span class="ltx_bibblock"><span id="bib.bib235.1.1" class="ltx_text" style="font-size:90%;">
Yang Zhao, Jun Zhao, Mengmeng Yang, Teng Wang, Ning Wang, Lingjuan Lyu, Dusit
Niyato, and Kwok-Yan Lam.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib235.2.1" class="ltx_text" style="font-size:90%;">Local differential privacy-based federated learning for internet of
things.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib235.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Internet of Things Journal</span><span id="bib.bib235.4.2" class="ltx_text" style="font-size:90%;">, 8(11):8836–8853, 2020.
</span>
</span>
</li>
<li id="bib.bib236" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[236]</span>
<span class="ltx_bibblock"><span id="bib.bib236.1.1" class="ltx_text" style="font-size:90%;">
Shuyuan Zheng, Yang Cao, and Masatoshi Yoshikawa.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib236.2.1" class="ltx_text" style="font-size:90%;">Secure shapley value for cross-silo federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib236.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2209.04856</span><span id="bib.bib236.4.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib237" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[237]</span>
<span class="ltx_bibblock"><span id="bib.bib237.1.1" class="ltx_text" style="font-size:90%;">
Pengyuan Zhou, Hengwei Xu, Lik Hang Lee, Pei Fang, and Pan Hui.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib237.2.1" class="ltx_text" style="font-size:90%;">Are you left out? an efficient and fair federated learning for
personalized profiles on wearable devices of inferior networking conditions.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib237.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.</span><span id="bib.bib237.4.2" class="ltx_text" style="font-size:90%;">, 6(2),
jul 2022.
</span>
</span>
</li>
<li id="bib.bib238" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[238]</span>
<span class="ltx_bibblock"><span id="bib.bib238.1.1" class="ltx_text" style="font-size:90%;">
Hongbin Zhu, Miao Yang, Junqian Kuang, Hua Qian, and Yong Zhou.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib238.2.1" class="ltx_text" style="font-size:90%;">Client selection for asynchronous federated learning with fairness
consideration.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib238.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib238.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2022 IEEE International Conference on Communications
Workshops (ICC Workshops)</span><span id="bib.bib238.5.3" class="ltx_text" style="font-size:90%;">, pages 800–805, 2022.
</span>
</span>
</li>
<li id="bib.bib239" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[239]</span>
<span class="ltx_bibblock"><span id="bib.bib239.1.1" class="ltx_text" style="font-size:90%;">
Hongbin Zhu, Yong Zhou, Hua Qian, Yuanming Shi, Xu Chen, and Yang Yang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib239.2.1" class="ltx_text" style="font-size:90%;">Online client selection for asynchronous federated learning with
fairness consideration.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib239.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Wireless Communications</span><span id="bib.bib239.4.2" class="ltx_text" style="font-size:90%;">, 22(4):2493–2506,
2023.
</span>
</span>
</li>
<li id="bib.bib240" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[240]</span>
<span class="ltx_bibblock"><span id="bib.bib240.1.1" class="ltx_text" style="font-size:90%;">
Ligeng Zhu, Zhijian Liu, and Song Han.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib240.2.1" class="ltx_text" style="font-size:90%;">Deep leakage from gradients, 2019.
</span>
</span>
</li>
<li id="bib.bib241" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[241]</span>
<span class="ltx_bibblock"><span id="bib.bib241.1.1" class="ltx_text" style="font-size:90%;">
Zhuangdi Zhu, Junyuan Hong, and Jiayu Zhou.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib241.2.1" class="ltx_text" style="font-size:90%;">Data-free knowledge distillation for heterogeneous federated
learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib241.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib241.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">International Conference on Machine Learning</span><span id="bib.bib241.5.3" class="ltx_text" style="font-size:90%;">, pages
12878–12889. PMLR, 2021.
</span>
</span>
</li>
</ul>
</section><div class="ltx_rdf" about="" property="dcterms:creator" content="Michael D. Shell"></div>
<div class="ltx_rdf" about="" property="dcterms:subject" content="Federated learning; privacy-preserving; fairness; distributed machine learning"></div>
<div class="ltx_rdf" about="" property="dcterms:subject" content="Typesetting"></div>
<div class="ltx_rdf" about="" property="dcterms:title" content="Fairness and Privacy-Preserving in Federated Learning: A Survey"></div>

</article>
</div>
<div class="ar5iv-footer"><a href="/html/2306.08401" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2306.08402" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2306.08402">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2306.08402" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2306.08403" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Feb 29 00:17:50 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
