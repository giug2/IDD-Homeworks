<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2312.12902] DXP: Billing Data Preparation for Big Data Analytics</title><meta property="og:description" content="In this paper, we present the data preparation activities that we performed for the Digital Experience Platform (DXP) project, commissioned and supervised by Doxee S.p.A..
DXP manages the billing data of the users of d…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="DXP: Billing Data Preparation for Big Data Analytics">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="DXP: Billing Data Preparation for Big Data Analytics">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2312.12902">

<!--Generated on Tue Feb 27 12:51:55 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="Big Data Integration Data Preparation Data Analytics">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line"><span id="id3" class="ltx_note ltx_role_institutetext"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">institutetext: </span>University of Modena and Reggio Emilia, <sup id="id3.3" class="ltx_sup">⋄</sup>Doxee S.p.A., Modena, Italy
<br class="ltx_break"><span id="id3.2" class="ltx_note ltx_role_email"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">email: </span><span id="id3.2.2" class="ltx_text ltx_font_typewriter">{name.surname}@unimore.it</span> <sup id="id3.2.3" class="ltx_sup">†</sup><span id="id3.2.1" class="ltx_text ltx_font_typewriter">279958@studenti.unimore.it
<br class="ltx_break"><sup id="id3.2.1.1" class="ltx_sup"><span id="id3.2.1.1.1" class="ltx_text ltx_font_serif">⋄</span></sup>{fmiselli,gmiano}@doxee.com</span></span></span></span>
</span></span></span>
<h1 class="ltx_title ltx_title_document">DXP: Billing Data Preparation
<br class="ltx_break">for Big Data Analytics</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Luca Gagliardelli
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Domenico Beneventano
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Marco Esposito<sup id="id7.2.id1" class="ltx_sup">†</sup>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Luca Zecchini
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Giovanni Simonini
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Sonia Bergamaschi
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Fabio Miselli<sup id="id8.2.id1" class="ltx_sup">⋄</sup>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Giuseppe Miano<sup id="id9.2.id1" class="ltx_sup">⋄</sup>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id10.id1" class="ltx_p">In this paper, we present the data preparation activities that we performed for the Digital Experience Platform (<span id="id10.id1.1" class="ltx_text ltx_font_typewriter">DXP</span>) project, commissioned and supervised by Doxee S.p.A..
<span id="id10.id1.2" class="ltx_text ltx_font_typewriter">DXP</span> manages the billing data of the <em id="id10.id1.3" class="ltx_emph ltx_font_italic">users</em> of different <em id="id10.id1.4" class="ltx_emph ltx_font_italic">companies</em>
operating in various sectors (electricity and gas, telephony, pay TV, etc.).
This data has to be processed to provide services to the users (e.g., interactive billing), but mainly to provide analytics to the companies (e.g., churn prediction or user segmentation).
We focus on the design of the data preparation pipeline, describing the challenges that we had to overcome in order to get the billing data ready to perform analysis on it.
We illustrate the lessons learned by highlighting the key points that could be transferred to similar projects.
Moreover, we report some interesting results and considerations derived from the preliminary analysis of the prepared data, also pointing out some possible future directions for the ongoing project, spacing from big data integration to privacy-preserving temporal record linkage.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Keywords: </h6>Big Data Integration Data Preparation Data Analytics
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Data quality represents one of the main goals of every (big) data integration process and constitutes an essential requirement to get consistent and useful results when operating on the obtained integrated data.
This is particularly evident for data analysis, which considers the integrated data as a starting point.
Of course, performing analysis on dirty data can only lead to poor-quality and potentially wrong results (<em id="S1.p1.1.1" class="ltx_emph ltx_font_italic">garbage in, garbage out</em>), impacting on the goodness of the choices deriving from data-driven decision-making processes.
Furthermore, with the increasing adoption of machine learning and deep learning models for big data analysis, it is of primary importance to ensure the quality of the data these models are trained on.
Recent developments in research community aim at moving from a model-centric to a <em id="S1.p1.1.2" class="ltx_emph ltx_font_italic">data-centric</em> approach to artificial intelligence<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a target="_blank" href="https://datacentricai.org" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://datacentricai.org</a></span></span></span>, putting the emphasis on data quality rather than on model refinement.
In fact, even state-of-the-art models fail to provide good results if the data is not properly prepared <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>.
Data preparation and cleaning often represent the heaviest burden for the data scientist.
This phases include a wide range of operations, generally combined into pipelines, which can only be partially automated <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">The ongoing Digital Experience Platform (<span id="S1.p2.1.1" class="ltx_text ltx_font_typewriter">DXP</span>) project
was commissioned by Doxee S.p.A.<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a target="_blank" href="https://www.doxee.com" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.doxee.com</a></span></span></span> to the Database Research Group (DBGroup<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a target="_blank" href="https://dbgroup.unimore.it" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://dbgroup.unimore.it</a></span></span></span>) of the University of Modena and Reggio Emilia in 2020, to leverage its experience in big data integration and analysis <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>, even in industrial scenarios <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>.
The goal of <span id="S1.p2.1.2" class="ltx_text ltx_font_typewriter">DXP</span> is to acquire the billing data provided by the suppliers (<em id="S1.p2.1.3" class="ltx_emph ltx_font_italic">companies</em>), then to process it to produce analytics for these companies (e.g., churn prediction or customer segmentation) and reports for their <em id="S1.p2.1.4" class="ltx_emph ltx_font_italic">users</em> (e.g., interactive billing).
As highlighted in Section <a href="#S2" title="2 Data Preparation Pipeline ‣ DXP: Billing Data Preparation for Big Data Analytics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, the acquired data needs an intensive preparation to get ready to be used in data analysis.
In this paper, we illustrate the data preparation pipeline conceived for the project, together with an overview of the preliminary analysis of the prepared data (providing some considerations about the main points that we found out) and some future directions for the project, concerning big data integration and privacy-preserving temporal record linkage issues.
We focus on lessons learned and on reproducible aspects of the project, aiming at transmitting to the reader a method that can be adopted to make these time-consuming steps easier while dealing with data analysis tasks.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Data Preparation Pipeline</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">The first step needed to obtain significant analytics from the available billing data was the design of a proper data preparation and cleaning pipeline.
This pipeline was required to be general purpose, to be employed for the billing data of the different companies managed by Doxee.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">During the starting phase of the project, we worked on a subset of about ten million bills of a single company, covering a period of six months (from January to June 2021).
Each bill is represented by a JSON file that is used by Doxee to provide the users with an electronic bill that can be accessed online.
The JSON files (one for each bill) are organized in folders (one for each month).
Each JSON file contains three types of information: <em id="S2.p2.1.1" class="ltx_emph ltx_font_italic">(i)</em> user data; <em id="S2.p2.1.2" class="ltx_emph ltx_font_italic">(ii)</em> Point Of Delivery (POD) data; <em id="S2.p2.1.3" class="ltx_emph ltx_font_italic">(iii)</em> specific bill information.
In the considered JSON files provided for the project, the personal data about the user are anonymized through a hashing function to be GDPR compliant. Since each value is represented by the same hash value, it is therefore possible to design the data preparation pipeline without accessing the personal information.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">The pipeline accepts as input the JSON files, producing as output three relational tables that contain the cleaned data about the bills, the PODs, and the users.
The relational tables are stored into an instance of Microsoft SQL Server, since Microsoft Power BI, chosen to perform the data analysis, can query it seamlessly.
The pipeline, composed of three phases, is depicted in Figure <a href="#S2.F1" title="Figure 1 ‣ 2 Data Preparation Pipeline ‣ DXP: Billing Data Preparation for Big Data Analytics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> and was developed with Python by using Apache Spark to be deployed on cloud services.</p>
</div>
<figure id="S2.F1" class="ltx_figure"><img src="/html/2312.12902/assets/figures/workflow1.png" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="212" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Data preparation pipeline. The table “Bill” reports the most relevant fields.</figcaption>
</figure>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p">The most challenging step was to identify the attributes to be extracted from the JSON files.
In fact, these files have high complexity and contain a lot of information which is used to generate the interactive electronic bills.
To overcome this issue, we used a sample bill with the related JSON file to identify the path (or the paths) corresponding to each attribute.
Moreover, a domain expert helped us to identify the fields of interest and the ones used as unique identifiers for each POD.
To make the process more flexible, we defined a spreadsheet that for each attribute of interest (Global Attribute, GAT) to extract defines the path where the attribute is located in the JSON file.
Thus, if a new attribute needs to be extracted, it just has to be added to this file.</p>
</div>
<div id="S2.p5" class="ltx_para">
<p id="S2.p5.1" class="ltx_p">The first step of the pipeline takes as input the spreadsheet with the paths and the folders that contain the JSON files, producing as output a columnar file that for each bill and each GAT reports the corresponding value contained in the bill.
To identify each bill, we chose to use its full path.
This makes it easier to debug the process in case of extraction problems, since we can immediately find the JSON file from which the values were extracted.</p>
</div>
<div id="S2.p6" class="ltx_para">
<p id="S2.p6.1" class="ltx_p">The second step of the pipeline is devised to clean the data.
In fact, the data extracted from the JSON files presents many issues, being formatted for viewing purposes.
For example, numerical data contains measure units to be removed and dots/commas to be normalized according to a common standard, in order to store it in a numerical format (e.g., the total amount of a bill is stored as “1.000,00 €”; thus, it has to be transformed into “1000.00” to be converted into a floating-point format).
Furthermore, the dates are written as “<span id="S2.p6.1.1" class="ltx_text ltx_font_italic">day month year</span>” (e.g., “10 January 2021”) and need to be converted into date format.
To face these issues, we prepared a set of custom functions to be applied to the value of each field according to the expected output type defined in a spreadsheet.
This makes it easier to perform future changes, such as adding new attributes to the extraction pipeline.
At the end of this step, we obtain a clean version of the data.</p>
</div>
<figure id="S2.F2" class="ltx_figure"><img src="/html/2312.12902/assets/figures/esempio_risoluzione.png" id="S2.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="269" height="100" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Data fusion.</figcaption>
</figure>
<div id="S2.p7" class="ltx_para">
<p id="S2.p7.1" class="ltx_p">The third and final step of the pipeline aims at generating the relational tables.
First, a pivot operation is performed on the data to obtain a table which contains a record for each bill.
The resulting table is denormalized: the data about a POD is repeated as many times as there are bills associated with it, while the data about a user is repeated as many times as there are PODs associated with them.
For example, if a user owns two PODs and for each POD three bills were emitted, the data about that user is repeated six times.
This representation presents several problems: <em id="S2.p7.1.1" class="ltx_emph ltx_font_italic">(i)</em> it is inefficient in terms of memory occupation, since the same values are repeated multiple times; <em id="S2.p7.1.2" class="ltx_emph ltx_font_italic">(ii)</em> it is inefficient to be queried (e.g., to find all the bills concerning the same POD it is necessary to scan the whole table, due to the lack of a foreign key referring to the POD); <em id="S2.p7.1.3" class="ltx_emph ltx_font_italic">(iii)</em> finally, there can be inconsistencies among the different records that refer to the same user/POD.
An example is shown in Figure <a href="#S2.F2" title="Figure 2 ‣ 2 Data Preparation Pipeline ‣ DXP: Billing Data Preparation for Big Data Analytics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, where for the same user the sex is missing in a bill and the age changes from one bill to another.
Then, after the pivoting, the fields are divided into three different relational tables according to what they refer to (user, POD, or bill), as shown in Figure <a href="#S2.F1" title="Figure 1 ‣ 2 Data Preparation Pipeline ‣ DXP: Billing Data Preparation for Big Data Analytics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
Finally, to overcome the inconsistencies, we adopted a resolution function that takes for each POD/user the most recent not null value for every attribute, computing the year of birth and considering it instead of the age, as shown in Figure <a href="#S2.F2" title="Figure 2 ‣ 2 Data Preparation Pipeline ‣ DXP: Billing Data Preparation for Big Data Analytics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>: the function takes “2000” for the age and ‘M’ for the sex because they are the most recent not null values according to the date of the bill.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Data Analysis</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">In this preliminary data analysis phase, we focused only on the electricity bills.
For these bills, each POD is associated to an offer that determines the cost of the electricity.
The offer is reported in each bill, and a user can decide to leave an offer for another one (e.g., to save money).
In some cases, the users may even decide to leave the current electricity supplier, choosing an offer by a different company.
The goal of our analysis was to perform a churn prediction, in order to forecast when a user may be interested in leaving the current offer, allowing the company to suggest a different one providing economic benefits, hopefully preventing the switching to a different supplier.
We decided to do this by using a classification model.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p">The first challenge was to construct a feature vector to feed the model.
The prediction task is related to each POD and to each offer present in the bills for that POD, so we had to create a feature vector depending on both elements, starting from the data contained in each bill.
For each POD-offer pair, we chose the following features: data of the user who owns the POD (i.e., <em id="S3.p2.1.1" class="ltx_emph ltx_font_italic">sex</em> and <em id="S3.p2.1.2" class="ltx_emph ltx_font_italic">age</em>), <em id="S3.p2.1.3" class="ltx_emph ltx_font_italic">municipality</em> where the POD is located, data of the bills related to that POD and that offer (<em id="S3.p2.1.4" class="ltx_emph ltx_font_italic">total consumption</em>, <em id="S3.p2.1.5" class="ltx_emph ltx_font_italic">total amount</em>, <em id="S3.p2.1.6" class="ltx_emph ltx_font_italic">total light amount</em>, <em id="S3.p2.1.7" class="ltx_emph ltx_font_italic">billed days</em>), and <em id="S3.p2.1.8" class="ltx_emph ltx_font_italic">churn</em>.
The <em id="S3.p2.1.9" class="ltx_emph ltx_font_italic">total consumption</em> is expressed in kilowatts, the <em id="S3.p2.1.10" class="ltx_emph ltx_font_italic">total light amount</em> denotes the cost of the consumed electricity, while the <em id="S3.p2.1.11" class="ltx_emph ltx_font_italic">total amount</em> represents the full cost, including extra fees.
The <span id="S3.p2.1.12" class="ltx_text ltx_font_italic">churn</span> is the target label (i.e., the variable to predict): it is set to 1 (i.e., the POD left the offer) if the last offer associated with that POD (i.e., the offer in the last available bill) is different from the offer that appears in the feature vector; otherwise, it is set to 0 (i.e., the POD maintained that offer).
All textual attributes (<em id="S3.p2.1.13" class="ltx_emph ltx_font_italic">offer</em>, <em id="S3.p2.1.14" class="ltx_emph ltx_font_italic">sex</em>, <em id="S3.p2.1.15" class="ltx_emph ltx_font_italic">municipality</em>) were transformed into numerical by using a categorical encoding, in order to be processed by the classification model.
We performed a correlation analysis on the features through Pearson correlation coefficient, finding a scarce correlation between them and the target variable.
However, we found a weak inverse correlation between the number of billed days and the churn, i.e., some users frequently change the offer to obtain better economic conditions.</p>
</div>
<div id="S3.p3" class="ltx_para">
<p id="S3.p3.3" class="ltx_p">Finally, we chose <em id="S3.p3.3.1" class="ltx_emph ltx_font_italic">random forest</em> as a classification model to enhance the accuracy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> (we also tried <em id="S3.p3.3.2" class="ltx_emph ltx_font_italic">logistic regression</em> and <em id="S3.p3.3.3" class="ltx_emph ltx_font_italic">SVM</em>), then we performed a cross-validation test to evaluate the performance of the model, which gained an accuracy of <math id="S3.p3.1.m1.1" class="ltx_Math" alttext="98.7\%" display="inline"><semantics id="S3.p3.1.m1.1a"><mrow id="S3.p3.1.m1.1.1" xref="S3.p3.1.m1.1.1.cmml"><mn id="S3.p3.1.m1.1.1.2" xref="S3.p3.1.m1.1.1.2.cmml">98.7</mn><mo id="S3.p3.1.m1.1.1.1" xref="S3.p3.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.p3.1.m1.1b"><apply id="S3.p3.1.m1.1.1.cmml" xref="S3.p3.1.m1.1.1"><csymbol cd="latexml" id="S3.p3.1.m1.1.1.1.cmml" xref="S3.p3.1.m1.1.1.1">percent</csymbol><cn type="float" id="S3.p3.1.m1.1.1.2.cmml" xref="S3.p3.1.m1.1.1.2">98.7</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.1.m1.1c">98.7\%</annotation></semantics></math>, but presenting an unsatisfactory recall of <math id="S3.p3.2.m2.1" class="ltx_Math" alttext="51\%" display="inline"><semantics id="S3.p3.2.m2.1a"><mrow id="S3.p3.2.m2.1.1" xref="S3.p3.2.m2.1.1.cmml"><mn id="S3.p3.2.m2.1.1.2" xref="S3.p3.2.m2.1.1.2.cmml">51</mn><mo id="S3.p3.2.m2.1.1.1" xref="S3.p3.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.p3.2.m2.1b"><apply id="S3.p3.2.m2.1.1.cmml" xref="S3.p3.2.m2.1.1"><csymbol cd="latexml" id="S3.p3.2.m2.1.1.1.cmml" xref="S3.p3.2.m2.1.1.1">percent</csymbol><cn type="integer" id="S3.p3.2.m2.1.1.2.cmml" xref="S3.p3.2.m2.1.1.2">51</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.2.m2.1c">51\%</annotation></semantics></math> on the users who changed the offer (i.e., <span id="S3.p3.3.4" class="ltx_text ltx_font_italic">churn</span> = 1).
This is mainly due to the high imbalance between the two classes present in the available data, since only <math id="S3.p3.3.m3.1" class="ltx_Math" alttext="1.8\%" display="inline"><semantics id="S3.p3.3.m3.1a"><mrow id="S3.p3.3.m3.1.1" xref="S3.p3.3.m3.1.1.cmml"><mn id="S3.p3.3.m3.1.1.2" xref="S3.p3.3.m3.1.1.2.cmml">1.8</mn><mo id="S3.p3.3.m3.1.1.1" xref="S3.p3.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.p3.3.m3.1b"><apply id="S3.p3.3.m3.1.1.cmml" xref="S3.p3.3.m3.1.1"><csymbol cd="latexml" id="S3.p3.3.m3.1.1.1.cmml" xref="S3.p3.3.m3.1.1.1">percent</csymbol><cn type="float" id="S3.p3.3.m3.1.1.2.cmml" xref="S3.p3.3.m3.1.1.2">1.8</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.3.m3.1c">1.8\%</annotation></semantics></math> of the records is related to users who changed their offer.
We also performed stratification to balance the training data, obtaining similar results.</p>
</div>
<div id="S3.p4" class="ltx_para">
<p id="S3.p4.1" class="ltx_p">The conclusion of this preliminary analysis was that more data is needed for this step.
In particular, the available data presents a lack of temporal depth: since for each POD a bill is usually emitted every two months, six months are not enough to obtain satisfactory results.
As a general principle, it is preferable to focus on the complete history of a significant and representative subset of users, since the study of these time series allows to understand the behavior of these users (or types of users), and in particular how it changes over time, detecting relevant patterns to train a significant model.</p>
</div>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Conclusion and Future Work</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In this paper, we described our experience in tackling a real-world project aimed at big data analysis, highlighting the importance of data preparation in order to obtain correct and significant results.
In particular, our paper is focused on the design of a data preparation pipeline, conceived dealing with the billing data of a specific company referring to a defined time interval, but with the purpose to be reusable for future billing data and generalizable to the billing data of any other company assisted by Doxee.
We also report some considerations derived from our preliminary analysis about the characteristics that input billing data needs to satisfy to allow the extraction of significant information from it.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p">We described the data preparation pipeline and the preliminary data analysis referring to the billing data of a single company. On the other hand, a key aspect of <span id="S4.p2.1.1" class="ltx_text ltx_font_typewriter">DXP</span> that will play a central role in its future developments is the analysis of the integrated data about the users, provided by the different companies. As user data contains private and confidential information,
the impact of privacy requirements and GDPR compliance on big data integration must be taken into account. The data integration techniques developed by the DBGroup will be extended in this direction; in particular, our entity resolution and blocking solutions will be enhanced to consider the <em id="S4.p2.1.2" class="ltx_emph ltx_font_italic">privacy-preserving temporal record linkage</em> scenario <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgements</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">We would like to thank Marcello Generali and Monia Gazzano from Doxee S.p.A. for their supervision and contributions.
The project Digital Experience Platform (<span id="Sx1.p1.1.1" class="ltx_text ltx_font_typewriter">DXP</span>) was funded by Regione Emilia-Romagna as part of the program for the promotion of companies’ development<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a target="_blank" href="https://bur.regione.emilia-romagna.it/dettaglio-inserzione?i=280032d4b5e7426b98eb92d955149e72" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://bur.regione.emilia-romagna.it/dettaglio-inserzione?i=280032d4b5e7426b98eb92d955149e72</a></span></span></span>.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Bergamaschi, S., Beneventano, D., Mandreoli, F., et al.: From Data Integration
to Big Data Integration. In: A Comprehensive Guide Through the Italian
Database Research Over the Last 25 Years, Studies in Big Data, vol. 31, pp.
43–59. Springer (2018)

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Gagliardelli, L., Zecchini, L., Beneventano, D., et al.: ECDP: A Big Data
Platform for the Smart Monitoring of Local Energy Communities. In: DataPlat.
CEUR Workshop Proceedings, vol. 3135. CEUR-WS.org (2022)

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Gagliardelli, L., Zhu, S., Simonini, G., Bergamaschi, S.: BigDedup: A Big Data
Integration Toolkit for Duplicate Detection in Industrial Scenarios. In: TE.
Advances in Transdisciplinary Engineering, vol. 7, pp. 1015–1023. IOS Press
(2018)

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Hameed, M., Naumann, F.: Data Preparation: A Survey of Commercial Tools.
SIGMOD Rec. <span id="bib.bib4.1.1" class="ltx_text ltx_font_bold">49</span>(3), 18–29 (2020)

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Li, H., Wu, D., Li, G., Ke, Y., Liu, W., Zheng, Y., Lin, X.: Enhancing Telco
Service Quality with Big Data Enabled Churn Analysis: Infrastructure, Model,
and Deployment. J. Comput. Sci. Technol. <span id="bib.bib5.1.1" class="ltx_text ltx_font_bold">30</span>(6), 1201–1214 (2015)

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Vatsalan, D., Sehili, Z., Christen, P., Rahm, E.: Privacy-Preserving Record
Linkage for Big Data: Current Approaches and Research Challenges. In:
Handbook of Big Data Technologies, pp. 851–895. Springer (2017)

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Zecchini, L., Simonini, G., Bergamaschi, S.: Entity Resolution on Camera
Records without Machine Learning. In: DI2KG. CEUR Workshop Proceedings,
vol. 2726. CEUR-WS.org (2020)

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2312.12901" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2312.12902" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2312.12902">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2312.12902" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2312.12903" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Tue Feb 27 12:51:55 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
